+ echo Logging output to experiments/5_28_original/logs/rfcn_end2end_ResNet-50_.txt.2018-05-28_17-09-55
Logging output to experiments/5_28_original/logs/rfcn_end2end_ResNet-50_.txt.2018-05-28_17-09-55
+ ./tools/train_net.py --gpu 1 --solver experiments/5_28_original/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_0712_trainval --iters 32000 --cfg experiments/5_28_original/rfcn_end2end_ohem.yml
Called with args:
Namespace(cfg_file='experiments/5_28_original/rfcn_end2end_ohem.yml', gpu_id=1, imdb_name='voc_0712_trainval', max_iters=32000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='experiments/5_28_original/solver_ohem.prototxt')
Using config:
{'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '5_28_original/model',
 'GPU_ID': 1,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [768],
          'SOFT_NMS': 1,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [640],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_0712_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
set00_V007_I01667
num_objs 6
set00_V014_I01340
num_objs 6
set04_V011_I00326
num_objs 1
set00_V009_I00233
num_objs 7
set02_V010_I01046
num_objs 1
set03_V008_I01793
num_objs 1
set03_V005_I00752
num_objs 1
set00_V008_I01340
num_objs 1
set01_V004_I00617
num_objs 4
set04_V006_I01493
num_objs 1
set01_V001_I00947
num_objs 1
set04_V006_I01553
num_objs 1
set04_V002_I01745
num_objs 2
set00_V004_I01151
num_objs 0
set02_V008_I01196
num_objs 0
set00_V007_I00299
num_objs 2
set03_V011_I01172
num_objs 1
set05_V003_I01766
num_objs 0
set03_V003_I00563
num_objs 2
set01_V002_I01385
num_objs 1
set02_V009_I00569
num_objs 2
set01_V005_I01781
num_objs 0
set01_V004_I00686
num_objs 1
set02_V010_I01100
num_objs 1
set05_V010_I00065
num_objs 1
set00_V007_I00755
num_objs 2
set00_V001_I01505
num_objs 6
set01_V002_I01394
num_objs 1
set04_V011_I00335
num_objs 1
set00_V010_I00284
num_objs 3
set00_V001_I00239
num_objs 3
set04_V011_I01145
num_objs 1
set05_V004_I00401
num_objs 1
set01_V000_I01457
num_objs 5
set02_V007_I00410
num_objs 1
set05_V011_I01307
num_objs 2
set04_V003_I00971
num_objs 4
set00_V006_I01871
num_objs 0
set03_V008_I00878
num_objs 1
set01_V005_I01190
num_objs 3
set03_V003_I00152
num_objs 2
set00_V010_I00992
num_objs 1
set03_V012_I01622
num_objs 1
set00_V000_I00329
num_objs 0
set03_V009_I01289
num_objs 0
set00_V013_I01247
num_objs 1
set03_V012_I00869
num_objs 0
set01_V004_I00776
num_objs 2
set02_V009_I00437
num_objs 1
set00_V007_I01346
num_objs 6
set05_V000_I00596
num_objs 1
set05_V007_I01178
num_objs 1
set04_V003_I01322
num_objs 4
set03_V005_I01553
num_objs 1
set03_V008_I01709
num_objs 2
set00_V011_I01442
num_objs 4
set00_V014_I01244
num_objs 4
set05_V005_I00137
num_objs 1
set02_V009_I00431
num_objs 1
set01_V000_I00590
num_objs 2
set01_V001_I00767
num_objs 1
set04_V007_I00695
num_objs 2
set00_V011_I01547
num_objs 0
set03_V003_I01346
num_objs 2
set01_V001_I00332
num_objs 4
set04_V001_I01670
num_objs 2
set00_V009_I01259
num_objs 0
set01_V002_I01439
num_objs 1
set00_V011_I01298
num_objs 5
set00_V012_I01043
num_objs 1
set00_V014_I00638
num_objs 3
set02_V007_I00473
num_objs 1
set00_V006_I00638
num_objs 3
set00_V009_I00368
num_objs 4
set03_V003_I00494
num_objs 2
set00_V007_I00407
num_objs 6
set04_V003_I01352
num_objs 3
set02_V009_I01112
num_objs 1
set00_V000_I00998
num_objs 0
set00_V011_I00680
num_objs 4
set02_V009_I00278
num_objs 2
set00_V004_I00545
num_objs 1
set00_V012_I00467
num_objs 1
set00_V001_I01283
num_objs 4
set01_V003_I01706
num_objs 3
set05_V007_I01445
num_objs 1
set00_V000_I00434
num_objs 6
set01_V005_I01001
num_objs 3
set04_V010_I01694
num_objs 2
set00_V004_I00377
num_objs 2
set00_V004_I01004
num_objs 2
set00_V001_I00635
num_objs 6
set04_V007_I01073
num_objs 2
set01_V001_I01199
num_objs 5
set02_V010_I01067
num_objs 1
set00_V009_I00125
num_objs 3
set03_V001_I00041
num_objs 1
set03_V009_I00041
num_objs 4
set00_V006_I01181
num_objs 3
set04_V002_I01715
num_objs 2
set05_V004_I00878
num_objs 0
set00_V008_I01451
num_objs 2
set05_V010_I00911
num_objs 2
set00_V001_I01226
num_objs 5
set00_V013_I01607
num_objs 2
set03_V012_I01556
num_objs 3
set00_V007_I01085
num_objs 6
set03_V008_I00179
num_objs 15
set00_V006_I01529
num_objs 1
set00_V004_I00185
num_objs 1
set04_V001_I00104
num_objs 1
set04_V006_I00872
num_objs 2
set01_V003_I00179
num_objs 6
set02_V010_I01058
num_objs 1
set05_V004_I00476
num_objs 2
set03_V005_I00689
num_objs 0
set01_V004_I00545
num_objs 1
set00_V004_I00854
num_objs 0
set01_V005_I01703
num_objs 0
set05_V007_I01406
num_objs 1
set02_V011_I00908
num_objs 1
set00_V007_I00917
num_objs 3
set05_V012_I00434
num_objs 3
set04_V006_I01571
num_objs 1
set00_V014_I00242
num_objs 1
set01_V004_I00740
num_objs 3
set05_V004_I00170
num_objs 3
set00_V006_I00476
num_objs 3
set03_V003_I00371
num_objs 1
set01_V000_I01199
num_objs 2
set00_V012_I00602
num_objs 0
set01_V003_I00509
num_objs 1
set02_V007_I00335
num_objs 1
set01_V000_I00287
num_objs 1
set05_V007_I01601
num_objs 0
set05_V000_I01700
num_objs 1
set05_V007_I01643
num_objs 0
set05_V003_I01211
num_objs 3
set04_V008_I00608
num_objs 1
set00_V002_I00152
num_objs 2
set01_V000_I01571
num_objs 4
set00_V013_I01610
num_objs 2
set03_V008_I01172
num_objs 1
set04_V008_I01124
num_objs 1
set03_V011_I00398
num_objs 5
set00_V010_I01190
num_objs 2
set05_V005_I01214
num_objs 1
set04_V006_I01610
num_objs 1
set04_V004_I00335
num_objs 0
set00_V013_I00203
num_objs 4
set05_V011_I01172
num_objs 4
set04_V003_I00530
num_objs 0
set00_V009_I00596
num_objs 2
set04_V004_I01025
num_objs 2
set05_V003_I00989
num_objs 1
set02_V009_I00443
num_objs 1
set00_V011_I00011
num_objs 6
set00_V011_I00452
num_objs 6
set04_V008_I01388
num_objs 1
set00_V009_I01418
num_objs 1
set00_V000_I00158
num_objs 1
set00_V000_I00377
num_objs 4
set01_V004_I00857
num_objs 3
set00_V007_I00749
num_objs 2
set03_V009_I01571
num_objs 2
set00_V006_I00500
num_objs 3
set04_V004_I01103
num_objs 3
set00_V004_I01274
num_objs 0
set01_V004_I01262
num_objs 0
set05_V011_I00806
num_objs 5
set02_V003_I00206
num_objs 1
set00_V002_I00641
num_objs 0
set00_V006_I01166
num_objs 5
set00_V007_I01484
num_objs 4
set05_V005_I00890
num_objs 1
set03_V003_I00107
num_objs 2
set04_V010_I00563
num_objs 1
set01_V000_I00215
num_objs 1
set00_V007_I00428
num_objs 6
set04_V002_I01676
num_objs 2
set01_V002_I01085
num_objs 3
set05_V007_I01364
num_objs 1
set00_V007_I00191
num_objs 4
set04_V007_I01670
num_objs 1
set03_V005_I00389
num_objs 1
set04_V002_I01334
num_objs 2
set00_V009_I00344
num_objs 4
set04_V010_I00479
num_objs 1
set00_V001_I00794
num_objs 3
set00_V013_I01370
num_objs 3
set00_V000_I01547
num_objs 1
set04_V007_I00950
num_objs 2
set05_V001_I00335
num_objs 0
set04_V007_I01094
num_objs 2
set00_V011_I00887
num_objs 0
set01_V003_I00503
num_objs 3
set01_V001_I00671
num_objs 3
set00_V000_I01787
num_objs 1
set00_V009_I00800
num_objs 2
set03_V009_I00893
num_objs 3
set05_V003_I01067
num_objs 1
set01_V002_I00164
num_objs 7
set00_V010_I00671
num_objs 2
set00_V008_I01058
num_objs 2
set00_V000_I01280
num_objs 1
set01_V002_I00899
num_objs 3
set00_V009_I00944
num_objs 4
set03_V005_I00350
num_objs 2
set05_V009_I00815
num_objs 1
set00_V010_I00188
num_objs 4
set00_V009_I01082
num_objs 1
set04_V007_I01571
num_objs 1
set03_V008_I00926
num_objs 1
set02_V010_I00407
num_objs 1
set01_V005_I01127
num_objs 4
set05_V007_I01562
num_objs 0
set03_V010_I00107
num_objs 1
set02_V010_I01778
num_objs 1
set03_V009_I00161
num_objs 5
set04_V004_I00287
num_objs 2
set03_V010_I01463
num_objs 2
set00_V003_I00041
num_objs 1
set00_V014_I00905
num_objs 4
set05_V003_I01061
num_objs 1
set00_V001_I00398
num_objs 2
set01_V005_I01319
num_objs 1
set03_V008_I01646
num_objs 2
set04_V001_I00095
num_objs 1
set02_V010_I00272
num_objs 1
set00_V002_I00482
num_objs 0
set03_V012_I01550
num_objs 3
set03_V003_I00002
num_objs 2
set01_V005_I00797
num_objs 2
set03_V010_I01415
num_objs 2
set01_V002_I00440
num_objs 5
set00_V000_I00533
num_objs 1
set00_V000_I01241
num_objs 2
set05_V005_I01202
num_objs 1
set04_V004_I00446
num_objs 3
set00_V006_I00536
num_objs 3
set00_V007_I00215
num_objs 5
set03_V009_I01214
num_objs 2
set05_V011_I01196
num_objs 3
set02_V010_I00143
num_objs 1
set04_V003_I01256
num_objs 3
set01_V005_I00239
num_objs 1
set00_V011_I01313
num_objs 5
set04_V007_I00611
num_objs 2
set00_V014_I00386
num_objs 5
set04_V010_I00458
num_objs 1
set04_V004_I00077
num_objs 1
set00_V007_I00845
num_objs 3
set00_V010_I00272
num_objs 3
set01_V000_I00830
num_objs 0
set05_V011_I01184
num_objs 4
set02_V010_I01001
num_objs 1
set01_V001_I01205
num_objs 7
set04_V002_I01478
num_objs 2
set03_V011_I00812
num_objs 2
set02_V011_I00617
num_objs 2
set04_V004_I01118
num_objs 3
set02_V010_I00866
num_objs 1
set04_V008_I01493
num_objs 1
set03_V009_I01538
num_objs 2
set03_V009_I00287
num_objs 2
set00_V011_I01097
num_objs 7
set05_V009_I00845
num_objs 1
set05_V000_I00476
num_objs 3
set00_V009_I00902
num_objs 4
set00_V009_I00908
num_objs 3
set03_V011_I01181
num_objs 1
set01_V004_I00083
num_objs 2
set00_V006_I00161
num_objs 3
set01_V000_I01328
num_objs 4
set02_V009_I01496
num_objs 1
set00_V010_I00074
num_objs 4
set00_V014_I01184
num_objs 4
set05_V004_I00413
num_objs 2
set05_V002_I00635
num_objs 1
set04_V005_I01226
num_objs 1
set00_V000_I01037
num_objs 0
set05_V005_I00095
num_objs 5
set00_V013_I00356
num_objs 4
set01_V004_I00074
num_objs 2
set01_V001_I00719
num_objs 1
set00_V014_I01409
num_objs 1
set01_V002_I00272
num_objs 8
set04_V006_I00653
num_objs 3
set03_V010_I01682
num_objs 3
set01_V005_I01067
num_objs 3
set05_V001_I00326
num_objs 0
set01_V002_I00224
num_objs 7
set01_V004_I00965
num_objs 2
set03_V010_I01034
num_objs 3
set02_V009_I01124
num_objs 1
set00_V005_I00854
num_objs 1
set04_V002_I01145
num_objs 2
set01_V002_I00125
num_objs 6
set00_V013_I01469
num_objs 5
set05_V009_I00842
num_objs 1
set00_V004_I01127
num_objs 0
set02_V011_I01838
num_objs 2
set02_V009_I01478
num_objs 1
set02_V009_I01121
num_objs 1
set04_V003_I00380
num_objs 1
set05_V011_I00881
num_objs 9
set00_V001_I01397
num_objs 3
set00_V009_I01238
num_objs 1
set03_V009_I01556
num_objs 2
set00_V007_I01640
num_objs 5
set05_V011_I01568
num_objs 1
set04_V005_I01685
num_objs 0
set04_V004_I00707
num_objs 2
set04_V002_I00791
num_objs 1
set02_V008_I01844
num_objs 0
set03_V011_I00389
num_objs 3
set04_V004_I01727
num_objs 1
set04_V007_I00497
num_objs 1
set03_V009_I00995
num_objs 2
set02_V003_I00710
num_objs 2
set03_V008_I01652
num_objs 2
set00_V003_I00152
num_objs 1
set04_V010_I00380
num_objs 1
set05_V003_I01655
num_objs 0
set03_V009_I01559
num_objs 2
set04_V004_I00575
num_objs 3
set05_V012_I00485
num_objs 3
set00_V011_I00017
num_objs 5
set00_V004_I00143
num_objs 1
set03_V003_I00440
num_objs 1
set02_V011_I00503
num_objs 2
set03_V001_I00020
num_objs 1
set01_V001_I01544
num_objs 9
set03_V010_I01760
num_objs 3
set00_V008_I00833
num_objs 1
set01_V003_I00893
num_objs 1
set04_V008_I01055
num_objs 1
set00_V011_I00410
num_objs 5
set01_V004_I01175
num_objs 1
set00_V009_I00875
num_objs 4
set02_V007_I00362
num_objs 1
set01_V004_I00464
num_objs 1
set04_V010_I00914
num_objs 2
set04_V007_I01208
num_objs 1
set00_V014_I00782
num_objs 5
set01_V003_I00713
num_objs 2
set00_V008_I00575
num_objs 5
set05_V003_I01748
num_objs 0
set00_V013_I00731
num_objs 1
set00_V006_I00848
num_objs 1
set03_V006_I00092
num_objs 1
set03_V010_I00185
num_objs 1
set00_V006_I00773
num_objs 1
set05_V007_I01574
num_objs 0
set05_V005_I00728
num_objs 1
set04_V005_I01202
num_objs 1
set00_V012_I01622
num_objs 1
set00_V011_I00413
num_objs 5
set03_V011_I00647
num_objs 3
set04_V007_I01235
num_objs 1
set01_V002_I00686
num_objs 6
set03_V008_I01181
num_objs 1
set04_V002_I00980
num_objs 2
set03_V005_I00860
num_objs 1
set01_V004_I00899
num_objs 6
set01_V004_I00920
num_objs 3
set04_V007_I01679
num_objs 1
set00_V006_I01193
num_objs 4
set05_V005_I01052
num_objs 1
set02_V007_I00137
num_objs 1
set03_V005_I01640
num_objs 1
set04_V005_I00758
num_objs 1
set01_V003_I00356
num_objs 3
set05_V004_I00881
num_objs 0
set01_V004_I01079
num_objs 3
set00_V010_I00887
num_objs 3
set00_V007_I00806
num_objs 3
set01_V004_I01412
num_objs 1
set05_V007_I01451
num_objs 1
set05_V000_I00266
num_objs 2
set01_V002_I01145
num_objs 1
set04_V005_I00845
num_objs 1
set04_V005_I01082
num_objs 2
set03_V008_I00767
num_objs 3
set01_V000_I01124
num_objs 4
set03_V008_I00719
num_objs 11
set03_V005_I01817
num_objs 2
set00_V002_I00233
num_objs 2
set02_V001_I01472
num_objs 1
set04_V005_I01133
num_objs 1
set03_V009_I00020
num_objs 3
set01_V005_I00086
num_objs 2
set03_V005_I00527
num_objs 3
set01_V005_I01232
num_objs 1
set04_V007_I01376
num_objs 1
set05_V011_I00827
num_objs 7
set03_V009_I01709
num_objs 0
set05_V007_I01463
num_objs 1
set02_V003_I00011
num_objs 0
set01_V004_I00635
num_objs 4
set01_V002_I00638
num_objs 7
set04_V005_I01058
num_objs 3
set01_V004_I00029
num_objs 2
set01_V000_I01667
num_objs 3
set05_V001_I00356
num_objs 0
set01_V002_I00230
num_objs 7
set05_V011_I00566
num_objs 5
set00_V008_I00479
num_objs 10
set05_V010_I00968
num_objs 1
set04_V007_I01307
num_objs 1
set02_V011_I00377
num_objs 2
set00_V001_I00062
num_objs 0
set04_V001_I00014
num_objs 1
set01_V000_I00641
num_objs 0
set00_V014_I00299
num_objs 2
set01_V004_I00935
num_objs 3
set05_V002_I01502
num_objs 1
set00_V004_I01196
num_objs 0
set05_V000_I00707
num_objs 1
set00_V014_I01013
num_objs 3
set00_V006_I01406
num_objs 4
set00_V001_I01256
num_objs 4
set00_V013_I00815
num_objs 1
set05_V007_I01772
num_objs 0
set01_V001_I01589
num_objs 1
set00_V001_I01556
num_objs 3
set03_V011_I00404
num_objs 5
set01_V005_I00908
num_objs 2
set04_V007_I01481
num_objs 1
set00_V004_I01370
num_objs 1
set02_V007_I00230
num_objs 1
set04_V004_I01223
num_objs 3
set02_V009_I00635
num_objs 2
set02_V010_I00737
num_objs 2
set01_V002_I00269
num_objs 5
set03_V008_I00005
num_objs 3
set00_V009_I00488
num_objs 2
set00_V000_I00272
num_objs 4
set01_V002_I01571
num_objs 2
set01_V004_I00071
num_objs 2
set01_V000_I00791
num_objs 1
set01_V004_I01295
num_objs 1
set00_V007_I01670
num_objs 6
set03_V012_I01313
num_objs 4
set02_V009_I00674
num_objs 2
set00_V012_I00890
num_objs 6
set00_V000_I01469
num_objs 3
set03_V005_I00545
num_objs 3
set00_V014_I01454
num_objs 4
set00_V014_I00785
num_objs 5
set04_V004_I01010
num_objs 2
set04_V004_I00554
num_objs 3
set05_V007_I01709
num_objs 0
set03_V007_I00329
num_objs 0
set02_V009_I00737
num_objs 2
set05_V004_I00185
num_objs 3
set05_V005_I00497
num_objs 2
set04_V005_I01589
num_objs 1
set00_V012_I00248
num_objs 3
set02_V010_I00344
num_objs 1
set05_V000_I01409
num_objs 0
set00_V012_I00884
num_objs 6
set04_V004_I00593
num_objs 3
set04_V003_I01754
num_objs 2
set05_V010_I01031
num_objs 1
set00_V004_I00893
num_objs 2
set00_V009_I01268
num_objs 1
set02_V003_I00746
num_objs 1
set00_V010_I01667
num_objs 1
set00_V001_I00890
num_objs 3
set05_V011_I01103
num_objs 5
set00_V013_I01046
num_objs 2
set00_V011_I00332
num_objs 2
set00_V004_I00548
num_objs 1
set01_V001_I00995
num_objs 1
set03_V008_I00344
num_objs 18
set02_V010_I00989
num_objs 0
set04_V004_I01022
num_objs 2
set05_V002_I00728
num_objs 1
set03_V008_I00404
num_objs 18
set04_V005_I00248
num_objs 1
set00_V008_I00347
num_objs 0
set04_V002_I01112
num_objs 2
set02_V009_I00314
num_objs 1
set00_V009_I00989
num_objs 2
set00_V002_I00620
num_objs 0
set00_V011_I00569
num_objs 1
set00_V014_I01745
num_objs 1
set00_V000_I01574
num_objs 2
set05_V000_I00713
num_objs 1
set04_V003_I00743
num_objs 1
set00_V009_I00155
num_objs 1
set05_V010_I01634
num_objs 1
set03_V010_I01712
num_objs 3
set00_V013_I01094
num_objs 3
set00_V013_I00044
num_objs 3
set01_V005_I01271
num_objs 1
set01_V000_I01280
num_objs 3
set00_V013_I00242
num_objs 3
set00_V011_I01193
num_objs 4
set05_V007_I01418
num_objs 1
set02_V011_I00866
num_objs 1
set01_V001_I00494
num_objs 3
set03_V008_I01391
num_objs 3
set03_V008_I00437
num_objs 19
set05_V010_I00644
num_objs 1
set04_V000_I00536
num_objs 2
set01_V005_I00236
num_objs 1
set00_V009_I00095
num_objs 5
set02_V001_I01688
num_objs 1
set00_V011_I00866
num_objs 0
set03_V008_I01202
num_objs 2
set00_V004_I01208
num_objs 0
set01_V005_I01493
num_objs 0
set05_V007_I01412
num_objs 1
set00_V014_I00494
num_objs 5
set00_V010_I01154
num_objs 2
set04_V006_I00893
num_objs 2
set02_V010_I00902
num_objs 1
set04_V001_I00011
num_objs 1
set02_V010_I01400
num_objs 1
set02_V010_I01139
num_objs 0
set01_V002_I01298
num_objs 5
set00_V000_I01463
num_objs 1
set00_V011_I00455
num_objs 6
set00_V014_I01211
num_objs 4
set03_V010_I01616
num_objs 2
set05_V000_I01406
num_objs 1
set00_V011_I00578
num_objs 3
set05_V000_I01673
num_objs 1
set03_V011_I01457
num_objs 2
set00_V011_I00296
num_objs 2
set00_V014_I00143
num_objs 1
set03_V011_I00191
num_objs 3
set03_V009_I01241
num_objs 2
set02_V009_I01811
num_objs 1
set00_V001_I01826
num_objs 1
set00_V006_I00887
num_objs 6
set03_V011_I00980
num_objs 1
set00_V006_I00782
num_objs 1
set01_V002_I01739
num_objs 3
set04_V010_I00644
num_objs 1
set01_V004_I01088
num_objs 3
set02_V010_I00266
num_objs 1
set04_V007_I01382
num_objs 1
set00_V010_I01151
num_objs 2
set01_V003_I01412
num_objs 1
set03_V008_I01511
num_objs 2
set04_V004_I00803
num_objs 2
set02_V009_I01397
num_objs 1
set00_V006_I01883
num_objs 0
set05_V005_I00188
num_objs 0
set03_V012_I00038
num_objs 1
set00_V002_I00860
num_objs 9
set03_V008_I01616
num_objs 2
set03_V005_I00296
num_objs 1
set02_V001_I01532
num_objs 1
set00_V010_I00620
num_objs 4
set03_V003_I00476
num_objs 2
set01_V002_I01832
num_objs 6
set04_V010_I00860
num_objs 2
set01_V003_I00368
num_objs 3
set04_V002_I00884
num_objs 1
set00_V002_I00644
num_objs 0
set00_V004_I00863
num_objs 1
set00_V001_I01514
num_objs 5
set05_V011_I01328
num_objs 2
set05_V007_I01520
num_objs 1
set00_V003_I00458
num_objs 1
set01_V005_I00563
num_objs 2
set04_V000_I00653
num_objs 3
set00_V004_I00008
num_objs 1
set00_V006_I00233
num_objs 3
set05_V004_I00161
num_objs 3
set00_V008_I01079
num_objs 1
set00_V010_I01265
num_objs 3
set04_V004_I00521
num_objs 3
set04_V002_I01580
num_objs 2
set04_V002_I00902
num_objs 1
set00_V006_I00086
num_objs 2
set00_V012_I00263
num_objs 3
set04_V008_I01070
num_objs 1
set00_V012_I01247
num_objs 0
set00_V013_I00683
num_objs 1
set00_V000_I00731
num_objs 2
set02_V010_I01766
num_objs 2
set00_V007_I00122
num_objs 0
set00_V003_I00107
num_objs 2
set05_V011_I01523
num_objs 1
set03_V003_I00932
num_objs 2
set03_V005_I00656
num_objs 2
set04_V007_I01187
num_objs 1
set00_V011_I00428
num_objs 5
set05_V010_I00590
num_objs 1
set01_V000_I00092
num_objs 3
set05_V010_I00803
num_objs 1
set00_V008_I01532
num_objs 1
set01_V005_I00293
num_objs 1
set02_V010_I00317
num_objs 1
set00_V007_I00617
num_objs 3
set05_V000_I00281
num_objs 2
set00_V014_I00563
num_objs 5
set00_V007_I01187
num_objs 9
set02_V010_I00563
num_objs 2
set04_V011_I01538
num_objs 1
set03_V001_I00092
num_objs 1
set02_V011_I01385
num_objs 2
set05_V005_I00599
num_objs 0
set03_V005_I01367
num_objs 1
set05_V005_I01160
num_objs 1
set04_V002_I01292
num_objs 2
set02_V010_I01646
num_objs 1
set00_V010_I00053
num_objs 4
set03_V011_I00863
num_objs 2
set00_V000_I00191
num_objs 3
set00_V003_I00125
num_objs 2
set04_V007_I00770
num_objs 2
set05_V003_I01673
num_objs 0
set00_V004_I01310
num_objs 1
set03_V008_I01241
num_objs 2
set05_V000_I00230
num_objs 2
set04_V003_I01721
num_objs 1
set01_V000_I00461
num_objs 1
set00_V002_I00662
num_objs 1
set04_V005_I01463
num_objs 2
set01_V002_I00389
num_objs 3
set04_V010_I00800
num_objs 1
set00_V001_I01730
num_objs 1
set02_V003_I00128
num_objs 1
set00_V011_I00272
num_objs 1
set04_V007_I00269
num_objs 0
set04_V005_I00215
num_objs 1
set03_V010_I01796
num_objs 3
set00_V006_I01190
num_objs 4
set01_V000_I01385
num_objs 3
set00_V007_I01055
num_objs 4
set02_V011_I00365
num_objs 2
set04_V008_I01418
num_objs 1
set00_V009_I00422
num_objs 2
set03_V008_I00158
num_objs 12
set03_V010_I01427
num_objs 2
set04_V008_I00611
num_objs 1
set00_V000_I01508
num_objs 1
set00_V014_I00269
num_objs 1
set01_V001_I01628
num_objs 5
set04_V005_I01511
num_objs 2
set05_V010_I00062
num_objs 1
set00_V002_I00899
num_objs 10
set00_V011_I00263
num_objs 1
set00_V009_I00986
num_objs 5
set00_V013_I00485
num_objs 2
set04_V004_I00401
num_objs 2
set05_V001_I00329
num_objs 0
set03_V001_I00065
num_objs 1
set04_V001_I01745
num_objs 1
set03_V009_I00746
num_objs 2
set00_V007_I00308
num_objs 6
set03_V009_I01271
num_objs 2
set04_V005_I00083
num_objs 1
set02_V010_I00995
num_objs 1
set04_V008_I01544
num_objs 1
set04_V004_I00635
num_objs 2
set00_V011_I00095
num_objs 4
set00_V011_I00203
num_objs 1
set04_V002_I00086
num_objs 1
set00_V010_I00479
num_objs 2
set05_V010_I00458
num_objs 1
set04_V007_I01166
num_objs 1
set03_V011_I00488
num_objs 5
set01_V001_I00092
num_objs 3
set05_V007_I01208
num_objs 1
set01_V005_I00476
num_objs 3
set00_V010_I01247
num_objs 3
set04_V004_I00857
num_objs 2
set00_V011_I01127
num_objs 6
set03_V009_I00122
num_objs 5
set03_V003_I00425
num_objs 1
set05_V005_I01049
num_objs 0
set01_V002_I00950
num_objs 4
set02_V010_I00779
num_objs 1
set02_V009_I01286
num_objs 1
set05_V005_I00260
num_objs 1
set05_V005_I00086
num_objs 5
set01_V003_I00956
num_objs 2
set05_V002_I00611
num_objs 1
set01_V000_I01583
num_objs 4
set03_V011_I00755
num_objs 2
set04_V002_I01340
num_objs 2
set01_V001_I00107
num_objs 3
set04_V008_I01385
num_objs 1
set01_V004_I00848
num_objs 3
set04_V000_I00800
num_objs 1
set00_V014_I00860
num_objs 4
set05_V001_I00437
num_objs 0
set00_V009_I00830
num_objs 3
set00_V013_I00074
num_objs 4
set04_V006_I00866
num_objs 2
set00_V002_I00326
num_objs 1
set00_V001_I00866
num_objs 3
set01_V003_I00095
num_objs 5
set01_V003_I01307
num_objs 1
set01_V004_I00137
num_objs 2
set03_V010_I00785
num_objs 0
set02_V010_I01130
num_objs 1
set00_V008_I01367
num_objs 1
set02_V009_I00497
num_objs 1
set05_V003_I01286
num_objs 2
set00_V009_I00872
num_objs 4
set02_V011_I00452
num_objs 1
set01_V000_I00359
num_objs 1
set03_V001_I00026
num_objs 1
set03_V012_I01370
num_objs 5
set03_V010_I00941
num_objs 1
set03_V008_I01505
num_objs 2
set02_V007_I00485
num_objs 1
set04_V005_I01097
num_objs 1
set02_V009_I01823
num_objs 2
set04_V005_I01109
num_objs 1
set02_V010_I01550
num_objs 1
set03_V005_I01436
num_objs 1
set04_V000_I00980
num_objs 1
set05_V000_I01607
num_objs 1
set00_V003_I00503
num_objs 0
set00_V014_I01490
num_objs 5
set01_V000_I01631
num_objs 3
set03_V006_I00191
num_objs 0
set04_V006_I01118
num_objs 1
set05_V000_I00329
num_objs 2
set03_V005_I01568
num_objs 1
set04_V003_I01316
num_objs 4
set05_V001_I00185
num_objs 1
set03_V003_I00470
num_objs 2
set05_V010_I01559
num_objs 1
set04_V007_I00353
num_objs 1
set05_V000_I00539
num_objs 1
set00_V009_I00377
num_objs 2
set00_V009_I00494
num_objs 2
set03_V002_I01646
num_objs 2
set00_V006_I01670
num_objs 0
set00_V006_I00179
num_objs 2
set00_V011_I00623
num_objs 3
set05_V012_I00356
num_objs 3
set03_V003_I01454
num_objs 2
set04_V005_I00719
num_objs 1
set05_V000_I00302
num_objs 4
set01_V005_I00380
num_objs 3
set04_V004_I01289
num_objs 1
set03_V008_I00533
num_objs 13
set04_V004_I00275
num_objs 2
set05_V011_I00008
num_objs 1
set01_V000_I01688
num_objs 2
set03_V003_I00482
num_objs 2
set03_V009_I01196
num_objs 3
set00_V014_I00032
num_objs 3
set05_V005_I00989
num_objs 0
set04_V003_I01646
num_objs 1
set04_V011_I01826
num_objs 1
set01_V004_I01334
num_objs 1
set00_V001_I01355
num_objs 2
set03_V010_I00164
num_objs 2
set01_V001_I00605
num_objs 3
set00_V012_I00755
num_objs 0
set02_V007_I00317
num_objs 1
set00_V014_I01148
num_objs 3
set00_V007_I01586
num_objs 7
set05_V003_I01001
num_objs 1
set04_V006_I00917
num_objs 2
set05_V011_I01232
num_objs 3
set01_V005_I01256
num_objs 1
set03_V003_I00479
num_objs 2
set04_V003_I01580
num_objs 1
set03_V008_I00128
num_objs 11
set04_V010_I00557
num_objs 1
set01_V005_I01544
num_objs 0
set00_V001_I01634
num_objs 2
set02_V009_I01214
num_objs 2
set00_V006_I01136
num_objs 7
set00_V004_I01094
num_objs 1
set02_V008_I01133
num_objs 0
set00_V007_I00479
num_objs 2
set00_V012_I00935
num_objs 6
set03_V005_I00602
num_objs 3
set03_V008_I01454
num_objs 3
set05_V003_I01751
num_objs 0
set04_V010_I00875
num_objs 2
set00_V013_I00407
num_objs 3
set02_V011_I00632
num_objs 2
set02_V009_I00290
num_objs 1
set00_V013_I01385
num_objs 2
set00_V006_I00914
num_objs 4
set03_V008_I00104
num_objs 8
set00_V013_I01631
num_objs 2
set03_V008_I00737
num_objs 3
set00_V008_I01106
num_objs 0
set00_V010_I00248
num_objs 1
set02_V009_I01622
num_objs 2
set02_V011_I00686
num_objs 1
set01_V001_I00707
num_objs 2
set05_V000_I01547
num_objs 1
set00_V004_I00977
num_objs 3
set04_V004_I01664
num_objs 3
set04_V004_I01106
num_objs 3
set04_V002_I00659
num_objs 1
set00_V012_I01649
num_objs 1
set03_V003_I00293
num_objs 1
set04_V006_I01502
num_objs 1
set02_V001_I01511
num_objs 1
set03_V003_I01448
num_objs 2
set05_V002_I00683
num_objs 1
set05_V000_I01703
num_objs 1
set05_V001_I00347
num_objs 0
set01_V000_I01118
num_objs 4
set03_V005_I00260
num_objs 1
set02_V010_I01430
num_objs 1
set04_V004_I00116
num_objs 1
set01_V005_I00101
num_objs 2
set00_V010_I01118
num_objs 2
set02_V011_I01805
num_objs 2
set01_V002_I01643
num_objs 4
set04_V004_I00188
num_objs 2
set01_V001_I00761
num_objs 1
set05_V011_I00629
num_objs 1
set04_V005_I00323
num_objs 1
set05_V002_I01580
num_objs 1
set00_V008_I01178
num_objs 0
set03_V012_I00914
num_objs 1
set00_V000_I00080
num_objs 1
set03_V009_I01796
num_objs 4
set02_V010_I00875
num_objs 1
set02_V001_I01529
num_objs 0
set03_V003_I01268
num_objs 2
set01_V003_I00626
num_objs 2
set01_V001_I00881
num_objs 1
set00_V013_I01004
num_objs 1
set00_V001_I00545
num_objs 3
set05_V011_I01637
num_objs 1
set02_V009_I00215
num_objs 2
set03_V004_I00056
num_objs 1
set01_V005_I01268
num_objs 1
set03_V009_I01049
num_objs 3
set03_V009_I00641
num_objs 3
set04_V002_I01625
num_objs 2
set00_V011_I00593
num_objs 3
set00_V001_I00326
num_objs 5
set04_V001_I01652
num_objs 2
set00_V002_I00518
num_objs 0
set04_V010_I00425
num_objs 1
set03_V011_I00179
num_objs 1
set05_V003_I01550
num_objs 0
set00_V010_I01034
num_objs 0
set04_V004_I01766
num_objs 1
set03_V003_I01124
num_objs 2
set00_V014_I01616
num_objs 4
set05_V011_I01646
num_objs 1
set00_V007_I00746
num_objs 2
set05_V012_I00575
num_objs 0
set00_V010_I00473
num_objs 7
set02_V010_I01343
num_objs 1
set00_V011_I00245
num_objs 1
set03_V008_I00746
num_objs 3
set00_V009_I00179
num_objs 8
set00_V011_I01268
num_objs 3
set04_V002_I00968
num_objs 2
set01_V001_I00236
num_objs 1
set00_V008_I00353
num_objs 0
set05_V002_I00716
num_objs 1
set04_V001_I01793
num_objs 1
set01_V001_I01142
num_objs 2
set05_V010_I00989
num_objs 0
set01_V003_I00995
num_objs 1
set00_V003_I00014
num_objs 1
set01_V004_I01001
num_objs 3
set00_V006_I00758
num_objs 0
set04_V008_I00614
num_objs 1
set00_V003_I00110
num_objs 2
set01_V001_I00350
num_objs 4
set00_V013_I00689
num_objs 0
set05_V010_I00806
num_objs 2
set01_V005_I01778
num_objs 0
set00_V008_I00332
num_objs 0
set00_V006_I00647
num_objs 2
set01_V000_I01346
num_objs 4
set00_V006_I01058
num_objs 4
set00_V011_I00278
num_objs 1
set01_V002_I00614
num_objs 7
set00_V007_I00245
num_objs 6
set01_V002_I01307
num_objs 5
set01_V001_I01208
num_objs 7
set00_V007_I01889
num_objs 1
set00_V010_I00989
num_objs 3
set03_V011_I00221
num_objs 3
set00_V008_I00566
num_objs 5
set00_V014_I00095
num_objs 4
set03_V003_I01139
num_objs 1
set04_V001_I01535
num_objs 1
set05_V009_I00971
num_objs 1
set03_V008_I01220
num_objs 2
set04_V002_I01169
num_objs 1
set01_V001_I01091
num_objs 1
set00_V006_I00608
num_objs 4
set03_V011_I01358
num_objs 1
set01_V003_I01727
num_objs 3
set05_V011_I01622
num_objs 1
set02_V010_I01706
num_objs 1
set03_V003_I00446
num_objs 1
set00_V006_I00011
num_objs 1
set00_V002_I00464
num_objs 0
set04_V002_I01751
num_objs 2
set03_V008_I00311
num_objs 18
set00_V004_I01244
num_objs 0
set05_V012_I01007
num_objs 1
set02_V010_I01148
num_objs 1
set00_V012_I01178
num_objs 1
set03_V003_I00041
num_objs 2
set04_V010_I00653
num_objs 1
set04_V007_I00887
num_objs 2
set02_V010_I01115
num_objs 1
set00_V001_I00017
num_objs 2
set00_V010_I01481
num_objs 4
set03_V010_I00890
num_objs 1
set03_V009_I00458
num_objs 3
set03_V003_I00671
num_objs 2
set00_V001_I00995
num_objs 12
set01_V000_I01451
num_objs 5
set00_V007_I01367
num_objs 4
set00_V004_I00278
num_objs 1
set00_V003_I00017
num_objs 0
set04_V003_I01592
num_objs 1
set00_V010_I01130
num_objs 2
set01_V001_I00272
num_objs 2
set00_V000_I01016
num_objs 0
set03_V003_I01028
num_objs 2
set02_V007_I00521
num_objs 1
set01_V005_I01265
num_objs 1
set02_V008_I00506
num_objs 1
set04_V008_I01550
num_objs 1
set01_V005_I00218
num_objs 2
set05_V007_I01688
num_objs 0
set03_V003_I01508
num_objs 2
set00_V009_I00350
num_objs 4
set03_V003_I00434
num_objs 1
set02_V001_I01445
num_objs 1
set00_V012_I01682
num_objs 1
set00_V006_I00926
num_objs 5
set00_V007_I01178
num_objs 9
set00_V004_I01178
num_objs 0
set01_V002_I00002
num_objs 3
set04_V008_I01403
num_objs 1
set00_V000_I01778
num_objs 1
set04_V004_I00617
num_objs 2
set00_V004_I00848
num_objs 1
set03_V003_I01520
num_objs 2
set00_V008_I01307
num_objs 0
set04_V007_I01691
num_objs 1
set02_V009_I00887
num_objs 1
set00_V000_I00116
num_objs 1
set04_V005_I01538
num_objs 2
set03_V012_I00938
num_objs 1
set04_V007_I01328
num_objs 1
set05_V004_I00443
num_objs 2
set00_V002_I01247
num_objs 0
set00_V000_I00338
num_objs 2
set00_V007_I00128
num_objs 0
set00_V014_I01730
num_objs 2
set01_V000_I00809
num_objs 0
set02_V010_I00572
num_objs 2
set02_V010_I01106
num_objs 1
set01_V004_I00728
num_objs 3
set03_V008_I00188
num_objs 12
set03_V008_I00362
num_objs 18
set02_V011_I01676
num_objs 2
set05_V000_I01724
num_objs 1
set00_V010_I01175
num_objs 2
set00_V001_I01196
num_objs 4
set04_V003_I00518
num_objs 0
set00_V001_I01259
num_objs 1
set00_V006_I01526
num_objs 2
set05_V002_I01607
num_objs 1
set05_V010_I00500
num_objs 1
set05_V005_I00806
num_objs 1
set03_V009_I01784
num_objs 4
set00_V000_I01106
num_objs 0
set05_V011_I00779
num_objs 0
set03_V009_I00038
num_objs 3
set01_V004_I00089
num_objs 2
set03_V012_I01508
num_objs 3
set05_V004_I00872
num_objs 0
set03_V002_I01622
num_objs 1
set00_V014_I01565
num_objs 5
set00_V014_I00830
num_objs 5
set00_V002_I00827
num_objs 8
set00_V001_I00263
num_objs 5
set01_V005_I01367
num_objs 1
set00_V006_I00710
num_objs 2
set02_V001_I01583
num_objs 1
set04_V007_I00803
num_objs 2
set05_V005_I00761
num_objs 1
set01_V004_I01451
num_objs 1
set02_V011_I01640
num_objs 2
set00_V006_I00731
num_objs 1
set03_V003_I01463
num_objs 2
set03_V009_I01565
num_objs 2
set00_V006_I01802
num_objs 0
set01_V003_I00539
num_objs 1
set05_V011_I00857
num_objs 7
set05_V005_I01181
num_objs 1
set01_V003_I01625
num_objs 1
set00_V012_I01550
num_objs 2
set04_V006_I01490
num_objs 1
set00_V001_I01436
num_objs 4
set03_V004_I00038
num_objs 1
set00_V013_I01100
num_objs 3
set02_V007_I00524
num_objs 1
set01_V001_I00083
num_objs 3
set00_V009_I00317
num_objs 6
set03_V005_I01304
num_objs 1
set00_V007_I00968
num_objs 3
set00_V006_I00257
num_objs 3
set00_V010_I00902
num_objs 2
set00_V000_I00800
num_objs 0
set00_V014_I01619
num_objs 5
set00_V011_I00092
num_objs 4
set00_V011_I00797
num_objs 1
set03_V009_I00080
num_objs 5
set01_V000_I00512
num_objs 1
set01_V005_I00728
num_objs 2
set03_V008_I00839
num_objs 6
set05_V010_I00008
num_objs 1
set03_V004_I00464
num_objs 1
set03_V012_I00017
num_objs 1
set05_V004_I00920
num_objs 1
set00_V001_I00173
num_objs 2
set00_V014_I01817
num_objs 2
set00_V014_I00347
num_objs 3
set00_V013_I00539
num_objs 3
set05_V003_I01553
num_objs 0
set00_V010_I00179
num_objs 2
set04_V004_I01868
num_objs 1
set04_V004_I01337
num_objs 1
set03_V003_I00272
num_objs 1
set03_V005_I01229
num_objs 0
set00_V007_I00551
num_objs 5
set04_V002_I00617
num_objs 1
set05_V010_I01088
num_objs 1
set02_V009_I00194
num_objs 2
set02_V009_I01778
num_objs 1
set03_V009_I00215
num_objs 5
set00_V009_I00578
num_objs 1
set00_V009_I01052
num_objs 1
set01_V003_I00494
num_objs 5
set04_V007_I01241
num_objs 1
set00_V014_I00545
num_objs 5
set02_V008_I01208
num_objs 1
set01_V002_I01568
num_objs 2
set01_V005_I01013
num_objs 3
set00_V011_I00323
num_objs 2
set05_V005_I00665
num_objs 1
set01_V005_I00974
num_objs 3
set02_V010_I00323
num_objs 1
set05_V010_I00464
num_objs 1
set03_V005_I00785
num_objs 1
set03_V009_I00044
num_objs 4
set03_V009_I01046
num_objs 6
set05_V004_I00173
num_objs 3
set02_V010_I01097
num_objs 1
set03_V010_I00938
num_objs 1
set01_V005_I00512
num_objs 2
set02_V009_I00509
num_objs 0
set03_V009_I00836
num_objs 0
set01_V002_I00554
num_objs 8
set02_V011_I00851
num_objs 1
set02_V011_I00920
num_objs 1
set00_V012_I01016
num_objs 2
set05_V000_I01634
num_objs 1
set00_V000_I01151
num_objs 0
set04_V002_I01361
num_objs 2
set05_V010_I01649
num_objs 1
set03_V010_I01478
num_objs 2
set00_V014_I00371
num_objs 4
set00_V008_I01382
num_objs 1
set00_V001_I00095
num_objs 3
set00_V013_I00728
num_objs 1
set00_V007_I00380
num_objs 6
set00_V014_I00281
num_objs 3
set04_V003_I01619
num_objs 1
set05_V005_I00602
num_objs 1
set05_V007_I01757
num_objs 0
set00_V007_I01226
num_objs 8
set03_V011_I00959
num_objs 1
set03_V003_I00335
num_objs 1
set01_V001_I00167
num_objs 3
set02_V007_I00206
num_objs 1
set04_V011_I01754
num_objs 1
set02_V010_I00899
num_objs 0
set00_V014_I00653
num_objs 3
set02_V010_I00185
num_objs 1
set01_V005_I01520
num_objs 0
set00_V008_I00389
num_objs 6
set05_V000_I01721
num_objs 1
set05_V005_I00518
num_objs 1
set00_V004_I01193
num_objs 0
set00_V000_I00233
num_objs 4
set02_V011_I00524
num_objs 2
set03_V003_I00077
num_objs 2
set00_V000_I01061
num_objs 0
set00_V010_I00815
num_objs 4
set03_V003_I00926
num_objs 2
set03_V009_I01631
num_objs 2
set01_V000_I00551
num_objs 2
set05_V003_I01637
num_objs 0
set04_V004_I01649
num_objs 0
set01_V005_I00725
num_objs 2
set04_V007_I01430
num_objs 1
set04_V004_I01730
num_objs 1
set00_V001_I01520
num_objs 5
set04_V007_I00389
num_objs 0
set00_V010_I01520
num_objs 3
set05_V003_I01601
num_objs 0
set04_V007_I00737
num_objs 2
set02_V010_I01805
num_objs 1
set01_V000_I01496
num_objs 5
set00_V003_I00185
num_objs 1
set03_V008_I01166
num_objs 1
set00_V014_I01640
num_objs 4
set00_V008_I01253
num_objs 2
set02_V010_I01163
num_objs 1
set05_V008_I01835
num_objs 1
set02_V008_I00998
num_objs 1
set04_V002_I01283
num_objs 2
set00_V006_I01496
num_objs 2
set01_V001_I00197
num_objs 2
set00_V008_I00659
num_objs 4
set01_V003_I01763
num_objs 1
set00_V002_I01256
num_objs 0
set00_V009_I00794
num_objs 1
set04_V008_I00560
num_objs 1
set00_V012_I01478
num_objs 3
set00_V009_I00632
num_objs 1
set01_V000_I01370
num_objs 4
set04_V006_I01547
num_objs 1
set00_V012_I01679
num_objs 1
set02_V007_I00305
num_objs 1
set04_V003_I01760
num_objs 2
set01_V001_I01349
num_objs 1
set03_V005_I01064
num_objs 1
set05_V003_I01559
num_objs 0
set04_V004_I01346
num_objs 1
set01_V004_I00305
num_objs 0
set04_V003_I01127
num_objs 3
set05_V005_I00005
num_objs 3
set04_V008_I00542
num_objs 1
set00_V001_I00731
num_objs 3
set03_V009_I00533
num_objs 4
set01_V002_I01166
num_objs 2
set05_V005_I00284
num_objs 2
set00_V007_I01322
num_objs 8
set04_V007_I00974
num_objs 2
set04_V010_I00566
num_objs 1
set00_V012_I00806
num_objs 3
set00_V004_I01142
num_objs 0
set04_V004_I00182
num_objs 2
set00_V006_I00995
num_objs 3
set03_V010_I01040
num_objs 3
set00_V010_I01241
num_objs 3
set05_V011_I00968
num_objs 8
set00_V013_I00506
num_objs 2
set02_V011_I00953
num_objs 1
set01_V002_I01814
num_objs 4
set00_V008_I00005
num_objs 4
set05_V000_I01562
num_objs 1
set04_V006_I01625
num_objs 2
set04_V007_I00467
num_objs 1
set03_V010_I01739
num_objs 2
set03_V010_I00896
num_objs 1
set01_V000_I00041
num_objs 1
set00_V010_I00662
num_objs 2
set05_V001_I00182
num_objs 1
set05_V009_I00788
num_objs 1
set04_V002_I01301
num_objs 2
set00_V010_I00656
num_objs 2
set04_V002_I00827
num_objs 1
set03_V011_I00506
num_objs 5
set04_V006_I00722
num_objs 1
set02_V010_I01085
num_objs 1
set00_V007_I00011
num_objs 1
set05_V005_I01115
num_objs 1
set03_V001_I00131
num_objs 1
set00_V014_I00191
num_objs 1
set03_V009_I00680
num_objs 3
set03_V010_I01376
num_objs 2
set01_V003_I01508
num_objs 1
set04_V005_I00887
num_objs 1
set02_V008_I00893
num_objs 2
set01_V001_I00440
num_objs 3
set01_V004_I01454
num_objs 1
set00_V011_I00719
num_objs 1
set01_V001_I00035
num_objs 2
set03_V010_I01592
num_objs 3
set02_V010_I01331
num_objs 1
set00_V013_I00140
num_objs 5
set00_V002_I00422
num_objs 0
set00_V001_I01391
num_objs 3
set04_V004_I01172
num_objs 3
set00_V010_I01460
num_objs 4
set01_V004_I00863
num_objs 2
set03_V009_I00593
num_objs 4
set01_V001_I01580
num_objs 7
set00_V007_I00116
num_objs 1
set01_V004_I01400
num_objs 1
set03_V011_I01430
num_objs 2
set02_V008_I01250
num_objs 1
set04_V003_I00107
num_objs 0
set00_V007_I00986
num_objs 2
set03_V012_I00881
num_objs 1
set04_V008_I01325
num_objs 1
set03_V008_I01163
num_objs 1
set00_V014_I01802
num_objs 1
set05_V000_I00590
num_objs 1
set04_V003_I01694
num_objs 1
set00_V004_I00995
num_objs 3
set04_V005_I01493
num_objs 2
set05_V012_I00719
num_objs 0
set00_V008_I00704
num_objs 3
set01_V000_I01049
num_objs 0
set00_V012_I00368
num_objs 0
set04_V007_I01637
num_objs 1
set00_V000_I01607
num_objs 2
set02_V009_I01628
num_objs 2
set02_V007_I00323
num_objs 1
set00_V013_I00980
num_objs 1
set02_V010_I00428
num_objs 1
set00_V011_I00101
num_objs 4
set03_V005_I00623
num_objs 3
set01_V004_I01529
num_objs 2
set04_V005_I00311
num_objs 1
set00_V011_I00542
num_objs 4
set02_V010_I00464
num_objs 1
set04_V004_I01196
num_objs 3
set05_V005_I01250
num_objs 1
set05_V011_I01550
num_objs 1
set04_V007_I00317
num_objs 1
set01_V005_I01181
num_objs 3
set04_V003_I01196
num_objs 3
set00_V000_I01655
num_objs 1
set03_V001_I00851
num_objs 1
set04_V005_I00815
num_objs 1
set01_V000_I00950
num_objs 2
set00_V000_I01709
num_objs 1
set00_V004_I01376
num_objs 1
set04_V005_I01241
num_objs 2
set01_V002_I00443
num_objs 5
set05_V001_I00191
num_objs 1
set04_V002_I00098
num_objs 0
set00_V009_I00674
num_objs 2
set01_V004_I00134
num_objs 2
set01_V002_I00296
num_objs 8
set02_V010_I00671
num_objs 2
set00_V010_I00488
num_objs 5
set01_V005_I00746
num_objs 2
set02_V010_I01574
num_objs 1
set00_V006_I01607
num_objs 2
set04_V011_I01595
num_objs 1
set01_V003_I00980
num_objs 1
set05_V011_I00884
num_objs 9
set04_V003_I01670
num_objs 1
set00_V009_I01544
num_objs 4
set04_V010_I01658
num_objs 2
set01_V005_I01604
num_objs 0
set01_V003_I00476
num_objs 5
set04_V007_I01298
num_objs 1
set05_V000_I00503
num_objs 3
set03_V009_I00920
num_objs 4
set00_V009_I01454
num_objs 3
set00_V010_I01094
num_objs 1
set01_V001_I00467
num_objs 4
set00_V006_I01133
num_objs 8
set00_V013_I01625
num_objs 2
set00_V004_I01445
num_objs 2
set01_V001_I01214
num_objs 9
set05_V010_I00413
num_objs 1
set05_V010_I00830
num_objs 2
set02_V010_I01733
num_objs 1
set05_V007_I01439
num_objs 1
set00_V010_I00755
num_objs 3
set05_V010_I00965
num_objs 1
set03_V010_I01349
num_objs 0
set05_V005_I00323
num_objs 2
set04_V006_I00656
num_objs 3
set05_V007_I01205
num_objs 1
set00_V000_I01100
num_objs 0
set00_V005_I00842
num_objs 2
set02_V001_I01448
num_objs 1
set04_V003_I01526
num_objs 1
set01_V002_I00482
num_objs 5
set03_V010_I00155
num_objs 2
set04_V002_I01550
num_objs 2
set03_V009_I00464
num_objs 3
set03_V011_I00515
num_objs 5
set00_V014_I01052
num_objs 2
set02_V010_I00629
num_objs 0
set05_V003_I01769
num_objs 0
set02_V008_I00524
num_objs 1
set03_V005_I00890
num_objs 1
set00_V011_I00611
num_objs 3
set02_V011_I01316
num_objs 1
set05_V011_I01541
num_objs 1
set03_V010_I01688
num_objs 3
set02_V009_I00188
num_objs 2
set03_V008_I01649
num_objs 2
set04_V003_I01046
num_objs 4
set01_V002_I01664
num_objs 4
set00_V013_I01562
num_objs 5
set01_V005_I01739
num_objs 1
set00_V007_I01271
num_objs 8
set03_V008_I00458
num_objs 18
set00_V000_I00146
num_objs 1
set03_V003_I00869
num_objs 0
set01_V005_I00674
num_objs 2
set03_V009_I00722
num_objs 2
set03_V003_I01097
num_objs 2
set00_V011_I01136
num_objs 6
set00_V011_I01562
num_objs 0
set02_V010_I00575
num_objs 2
set00_V008_I01061
num_objs 2
set00_V006_I00980
num_objs 1
set03_V004_I00446
num_objs 1
set03_V008_I01019
num_objs 1
set03_V010_I01829
num_objs 1
set00_V001_I01304
num_objs 4
set04_V007_I00968
num_objs 2
set03_V003_I01199
num_objs 0
set01_V000_I01691
num_objs 2
set03_V005_I01739
num_objs 1
set00_V001_I00347
num_objs 5
set04_V005_I01235
num_objs 2
set01_V002_I01136
num_objs 1
set05_V007_I01694
num_objs 0
set01_V002_I00569
num_objs 5
set00_V001_I00500
num_objs 4
set04_V005_I00062
num_objs 1
set04_V000_I00692
num_objs 3
set02_V010_I00296
num_objs 1
set05_V009_I00812
num_objs 1
set01_V000_I01679
num_objs 1
set00_V013_I01115
num_objs 4
set01_V004_I00242
num_objs 2
set04_V003_I00023
num_objs 0
set01_V003_I00056
num_objs 5
set05_V010_I00638
num_objs 1
set00_V002_I00683
num_objs 1
set00_V003_I00407
num_objs 1
set00_V001_I01085
num_objs 9
set03_V008_I00233
num_objs 15
set05_V005_I00083
num_objs 5
set00_V009_I00296
num_objs 6
set01_V000_I00761
num_objs 1
set05_V010_I01610
num_objs 1
set00_V001_I01595
num_objs 3
set04_V000_I00815
num_objs 1
set00_V000_I00083
num_objs 1
set05_V010_I00005
num_objs 1
set03_V012_I01481
num_objs 3
set00_V011_I00596
num_objs 3
set05_V005_I00038
num_objs 3
set00_V013_I00614
num_objs 3
set00_V010_I01235
num_objs 3
set02_V010_I01745
num_objs 1
set04_V002_I01166
num_objs 2
set03_V009_I00659
num_objs 4
set00_V003_I00026
num_objs 0
set01_V000_I01520
num_objs 4
set00_V008_I01292
num_objs 1
set03_V006_I01718
num_objs 1
set04_V001_I00056
num_objs 1
set04_V002_I01124
num_objs 2
set02_V008_I00929
num_objs 1
set03_V001_I00059
num_objs 1
set04_V002_I01505
num_objs 2
set02_V010_I00329
num_objs 0
set00_V001_I01400
num_objs 3
set03_V002_I01412
num_objs 1
set04_V004_I00839
num_objs 0
set02_V008_I01094
num_objs 0
set03_V008_I00506
num_objs 16
set04_V005_I00854
num_objs 1
set00_V000_I01166
num_objs 0
set05_V010_I01514
num_objs 1
set05_V007_I01640
num_objs 0
set00_V013_I01517
num_objs 3
set03_V004_I00572
num_objs 1
set00_V008_I00458
num_objs 8
set04_V004_I01079
num_objs 2
set03_V011_I01424
num_objs 1
set03_V010_I01061
num_objs 1
set00_V013_I00035
num_objs 4
set03_V003_I00263
num_objs 1
set00_V001_I00608
num_objs 1
set04_V003_I01616
num_objs 1
set01_V002_I00947
num_objs 4
set05_V001_I00380
num_objs 0
set04_V007_I01202
num_objs 1
set00_V010_I00299
num_objs 3
set03_V009_I01586
num_objs 2
set05_V003_I01049
num_objs 1
set05_V004_I00875
num_objs 0
set05_V012_I00479
num_objs 3
set01_V002_I01025
num_objs 2
set04_V010_I00959
num_objs 1
set02_V010_I00518
num_objs 2
set02_V010_I01337
num_objs 1
set00_V010_I01634
num_objs 0
set04_V007_I00365
num_objs 1
set00_V001_I00485
num_objs 1
set04_V004_I00131
num_objs 1
set00_V009_I01073
num_objs 1
set01_V005_I01052
num_objs 3
set05_V010_I00524
num_objs 1
set00_V004_I01385
num_objs 2
set00_V014_I00725
num_objs 3
set03_V002_I01610
num_objs 1
set03_V001_I00173
num_objs 1
set02_V009_I00920
num_objs 1
set01_V002_I00080
num_objs 4
set00_V010_I01688
num_objs 1
set04_V005_I01211
num_objs 1
set04_V002_I00896
num_objs 1
set02_V010_I01532
num_objs 1
set03_V008_I00791
num_objs 3
set02_V007_I00248
num_objs 1
set05_V002_I00764
num_objs 1
set01_V004_I00284
num_objs 2
set00_V007_I01661
num_objs 6
set03_V002_I01649
num_objs 2
set01_V003_I01286
num_objs 1
set05_V002_I01571
num_objs 1
set01_V005_I01157
num_objs 3
set02_V010_I01187
num_objs 1
set00_V004_I01664
num_objs 1
set01_V000_I01418
num_objs 4
set00_V011_I01271
num_objs 3
set01_V002_I00629
num_objs 3
set03_V002_I01535
num_objs 1
set00_V007_I00206
num_objs 4
set03_V012_I00029
num_objs 1
set01_V003_I01799
num_objs 6
set05_V002_I01544
num_objs 1
set03_V010_I01508
num_objs 2
set00_V012_I00983
num_objs 4
set01_V000_I00902
num_objs 1
set01_V001_I01187
num_objs 3
set00_V003_I00122
num_objs 2
set03_V007_I00356
num_objs 1
set03_V002_I01577
num_objs 1
set04_V010_I00512
num_objs 1
set05_V005_I01232
num_objs 1
set02_V010_I01118
num_objs 1
set05_V004_I00284
num_objs 1
set03_V008_I01382
num_objs 3
set00_V008_I00512
num_objs 5
set00_V001_I00986
num_objs 9
set03_V012_I01514
num_objs 3
set04_V011_I01082
num_objs 2
set00_V008_I01436
num_objs 1
set04_V000_I00533
num_objs 2
set03_V003_I00134
num_objs 2
set00_V013_I01169
num_objs 2
set00_V014_I00923
num_objs 2
set05_V004_I00902
num_objs 0
set02_V011_I01610
num_objs 2
set05_V009_I00752
num_objs 1
set01_V000_I00008
num_objs 1
set01_V005_I00956
num_objs 3
set00_V013_I00272
num_objs 5
set05_V005_I01274
num_objs 1
set00_V001_I00455
num_objs 1
set00_V001_I00899
num_objs 1
set05_V000_I01619
num_objs 0
set02_V010_I01544
num_objs 1
set00_V009_I01409
num_objs 2
set04_V007_I00509
num_objs 0
set00_V008_I01274
num_objs 1
set00_V009_I00083
num_objs 5
set01_V001_I00314
num_objs 4
set00_V008_I01469
num_objs 1
set04_V010_I01610
num_objs 2
set00_V009_I00260
num_objs 7
set01_V005_I00566
num_objs 2
set05_V003_I01640
num_objs 0
set00_V003_I00404
num_objs 1
set04_V004_I00461
num_objs 3
set03_V008_I00659
num_objs 14
set00_V003_I00011
num_objs 1
set00_V008_I01007
num_objs 1
set00_V014_I00434
num_objs 5
set05_V009_I00956
num_objs 1
set03_V010_I01745
num_objs 3
set01_V001_I01313
num_objs 10
set01_V003_I00170
num_objs 8
set03_V012_I01478
num_objs 3
set04_V010_I01688
num_objs 2
set03_V011_I00446
num_objs 5
set05_V005_I00203
num_objs 0
set01_V003_I01337
num_objs 1
set01_V004_I00731
num_objs 3
set01_V002_I00182
num_objs 7
set05_V005_I00275
num_objs 2
set00_V012_I00626
num_objs 0
set05_V004_I00119
num_objs 1
set04_V010_I00689
num_objs 1
set03_V003_I00527
num_objs 2
set04_V010_I00713
num_objs 1
set00_V006_I01679
num_objs 0
set04_V010_I00419
num_objs 1
set02_V011_I01547
num_objs 2
set05_V011_I01658
num_objs 1
set04_V007_I00284
num_objs 1
set01_V000_I00119
num_objs 1
set05_V002_I01496
num_objs 1
set03_V009_I00707
num_objs 2
set02_V003_I00749
num_objs 0
set00_V009_I00974
num_objs 5
set02_V009_I01523
num_objs 1
set05_V002_I00509
num_objs 0
set02_V010_I00206
num_objs 1
set00_V006_I00893
num_objs 6
set00_V001_I00371
num_objs 5
set04_V005_I01256
num_objs 1
set00_V001_I00737
num_objs 3
set05_V000_I01382
num_objs 2
set01_V000_I01091
num_objs 4
set01_V001_I00929
num_objs 0
set04_V008_I01370
num_objs 1
set01_V004_I00185
num_objs 1
set01_V004_I01607
num_objs 1
set00_V011_I00122
num_objs 3
set02_V011_I00392
num_objs 2
set05_V011_I00557
num_objs 4
set04_V000_I00974
num_objs 1
set05_V000_I00728
num_objs 1
set03_V005_I00788
num_objs 1
set05_V000_I00227
num_objs 2
set01_V004_I00041
num_objs 2
set00_V006_I01772
num_objs 0
set00_V001_I00920
num_objs 6
set01_V004_I01382
num_objs 1
set01_V000_I00221
num_objs 1
set00_V001_I00956
num_objs 8
set00_V011_I01103
num_objs 7
set00_V001_I01784
num_objs 5
set00_V013_I00848
num_objs 2
set00_V009_I00362
num_objs 4
set05_V011_I00905
num_objs 9
set01_V005_I01274
num_objs 1
set01_V001_I00134
num_objs 4
set01_V001_I00221
num_objs 2
set00_V002_I00779
num_objs 2
set02_V011_I01322
num_objs 1
set04_V004_I01715
num_objs 1
set00_V004_I00953
num_objs 2
set01_V002_I00689
num_objs 4
set00_V011_I00965
num_objs 10
set03_V005_I00278
num_objs 1
set02_V003_I00221
num_objs 1
set03_V008_I01076
num_objs 1
set04_V003_I01205
num_objs 3
set05_V012_I01103
num_objs 1
set05_V011_I01457
num_objs 3
set00_V010_I01523
num_objs 3
set03_V011_I00872
num_objs 2
set00_V011_I00572
num_objs 3
set03_V003_I00854
num_objs 2
set05_V002_I00149
num_objs 0
set00_V000_I00992
num_objs 0
set02_V011_I00656
num_objs 2
set04_V010_I00776
num_objs 1
set03_V001_I00098
num_objs 1
set00_V002_I00818
num_objs 7
set01_V005_I00458
num_objs 4
set05_V000_I01574
num_objs 1
set00_V012_I01319
num_objs 1
set00_V007_I00410
num_objs 6
set01_V004_I01430
num_objs 1
set03_V003_I00059
num_objs 2
set02_V009_I00677
num_objs 2
set00_V003_I00461
num_objs 1
set03_V009_I00875
num_objs 2
set03_V007_I00323
num_objs 1
set03_V011_I00521
num_objs 5
set03_V003_I00701
num_objs 2
set05_V001_I00452
num_objs 0
set00_V004_I01502
num_objs 0
set04_V004_I00956
num_objs 2
set04_V004_I00923
num_objs 2
set03_V006_I01724
num_objs 1
set04_V003_I00923
num_objs 1
set02_V011_I01592
num_objs 2
set00_V014_I00776
num_objs 4
set05_V009_I00851
num_objs 1
set03_V001_I00830
num_objs 1
set02_V003_I00215
num_objs 1
set00_V013_I00794
num_objs 2
set00_V011_I00515
num_objs 5
set00_V014_I01613
num_objs 4
set02_V009_I00680
num_objs 2
set03_V005_I00815
num_objs 1
set00_V006_I00569
num_objs 2
set01_V005_I00734
num_objs 2
set05_V007_I01241
num_objs 1
set01_V000_I00785
num_objs 1
set00_V006_I01805
num_objs 0
set03_V006_I01775
num_objs 1
set05_V010_I00833
num_objs 2
set00_V011_I00236
num_objs 1
set01_V003_I00149
num_objs 10
set03_V005_I00974
num_objs 1
set01_V002_I00413
num_objs 5
set00_V007_I01139
num_objs 3
set04_V003_I01499
num_objs 0
set04_V006_I00548
num_objs 1
set05_V004_I00254
num_objs 1
set00_V004_I00002
num_objs 1
set04_V007_I01301
num_objs 1
set01_V000_I01184
num_objs 3
set00_V001_I00824
num_objs 3
set00_V010_I01166
num_objs 2
set04_V000_I00758
num_objs 3
set03_V008_I01508
num_objs 2
set01_V003_I00602
num_objs 1
set04_V003_I01043
num_objs 4
set02_V010_I00848
num_objs 2
set03_V005_I01667
num_objs 1
set01_V005_I01790
num_objs 0
set01_V000_I00656
num_objs 0
set05_V012_I01094
num_objs 1
set00_V001_I00980
num_objs 9
set00_V011_I00860
num_objs 0
set04_V006_I01109
num_objs 0
set04_V002_I00839
num_objs 1
set05_V009_I00998
num_objs 1
set00_V013_I01295
num_objs 2
set00_V012_I00062
num_objs 1
set03_V005_I00557
num_objs 3
set05_V005_I01016
num_objs 1
set03_V009_I01184
num_objs 2
set04_V011_I01628
num_objs 1
set00_V000_I00719
num_objs 2
set05_V000_I00614
num_objs 1
set00_V007_I00377
num_objs 6
set03_V003_I00221
num_objs 1
set00_V014_I00014
num_objs 3
set01_V000_I00539
num_objs 1
set00_V001_I00605
num_objs 1
set00_V007_I00758
num_objs 2
set03_V009_I01511
num_objs 2
set00_V012_I01532
num_objs 2
set00_V011_I00347
num_objs 2
set03_V009_I00050
num_objs 5
set03_V003_I00992
num_objs 2
set00_V011_I00698
num_objs 4
set00_V014_I00743
num_objs 2
set02_V008_I01097
num_objs 0
set02_V009_I01676
num_objs 1
set05_V005_I00818
num_objs 1
set01_V003_I01622
num_objs 1
set00_V014_I01895
num_objs 1
set02_V008_I00878
num_objs 2
set01_V002_I00818
num_objs 7
set03_V010_I01019
num_objs 1
set05_V002_I01637
num_objs 1
set03_V008_I01322
num_objs 3
set04_V010_I00671
num_objs 1
set01_V002_I00392
num_objs 5
set03_V006_I01772
num_objs 1
set02_V001_I01661
num_objs 1
set04_V003_I01376
num_objs 3
set01_V002_I01241
num_objs 4
set04_V007_I00971
num_objs 2
set03_V003_I00266
num_objs 1
set00_V007_I01784
num_objs 3
set05_V000_I01553
num_objs 1
set00_V011_I00902
num_objs 2
set00_V007_I00305
num_objs 6
set01_V002_I00152
num_objs 7
set00_V011_I00725
num_objs 2
set03_V003_I00044
num_objs 2
set05_V004_I01037
num_objs 1
set00_V008_I00935
num_objs 1
set02_V010_I01715
num_objs 1
set04_V002_I01061
num_objs 2
set05_V005_I00377
num_objs 1
set00_V006_I01700
num_objs 0
set04_V010_I01571
num_objs 2
set05_V005_I00044
num_objs 4
set05_V005_I00506
num_objs 2
set01_V002_I01781
num_objs 4
set05_V000_I00740
num_objs 1
set05_V003_I01283
num_objs 2
set00_V006_I00314
num_objs 4
set04_V010_I00755
num_objs 1
set02_V010_I01793
num_objs 1
set05_V002_I00734
num_objs 1
set03_V004_I00068
num_objs 1
set00_V003_I00080
num_objs 1
set03_V008_I00971
num_objs 1
set03_V008_I01568
num_objs 1
set01_V000_I00029
num_objs 2
set00_V007_I01052
num_objs 4
set00_V002_I00500
num_objs 0
set00_V000_I01025
num_objs 0
set04_V006_I01058
num_objs 1
set03_V004_I00167
num_objs 1
set01_V003_I00407
num_objs 3
set05_V011_I00740
num_objs 2
set00_V000_I01532
num_objs 1
set04_V010_I00611
num_objs 1
set05_V012_I01052
num_objs 1
set00_V006_I00863
num_objs 3
set02_V009_I01190
num_objs 2
set03_V003_I00572
num_objs 2
set02_V003_I00254
num_objs 1
set03_V008_I00440
num_objs 19
set02_V010_I01436
num_objs 1
set04_V003_I00242
num_objs 1
set00_V008_I00590
num_objs 5
set02_V009_I00911
num_objs 1
set04_V003_I00227
num_objs 0
set05_V005_I01175
num_objs 1
set00_V010_I00836
num_objs 4
set00_V014_I00869
num_objs 2
set00_V009_I00305
num_objs 6
set05_V002_I01622
num_objs 1
set05_V010_I01595
num_objs 1
set02_V001_I01526
num_objs 1
set04_V005_I00878
num_objs 1
set01_V004_I00047
num_objs 2
set00_V001_I00740
num_objs 3
set00_V010_I01367
num_objs 4
set00_V013_I01589
num_objs 4
set03_V011_I00161
num_objs 2
set00_V013_I01682
num_objs 0
set02_V009_I00782
num_objs 2
set00_V004_I01112
num_objs 1
set04_V004_I00818
num_objs 2
set00_V004_I01235
num_objs 0
set00_V010_I01454
num_objs 5
set02_V010_I00122
num_objs 1
set00_V004_I00371
num_objs 2
set04_V007_I01145
num_objs 2
set01_V002_I01637
num_objs 4
set01_V001_I00938
num_objs 1
set03_V005_I00440
num_objs 2
set04_V000_I00965
num_objs 1
set00_V008_I00950
num_objs 1
set00_V006_I01268
num_objs 6
set01_V004_I01403
num_objs 1
set00_V008_I00605
num_objs 3
set00_V013_I00743
num_objs 1
set04_V010_I01556
num_objs 2
set00_V013_I00311
num_objs 6
set00_V006_I00449
num_objs 2
set00_V010_I00872
num_objs 3
set03_V009_I00329
num_objs 2
set04_V007_I01367
num_objs 1
set02_V001_I01463
num_objs 1
set05_V011_I00950
num_objs 8
set03_V003_I00650
num_objs 2
set03_V009_I01712
num_objs 3
set03_V006_I00149
num_objs 0
set04_V002_I01157
num_objs 2
set01_V000_I00938
num_objs 2
set03_V008_I01490
num_objs 2
set05_V007_I01190
num_objs 1
set00_V014_I00254
num_objs 2
set00_V013_I01526
num_objs 4
set01_V005_I00776
num_objs 2
set00_V000_I01658
num_objs 1
set00_V007_I01301
num_objs 9
set00_V014_I00557
num_objs 5
set00_V013_I01256
num_objs 1
set04_V007_I01055
num_objs 2
set00_V000_I01781
num_objs 1
set04_V011_I01625
num_objs 1
set00_V000_I00395
num_objs 4
set05_V005_I00737
num_objs 1
set00_V013_I01325
num_objs 4
set00_V011_I00275
num_objs 1
set00_V000_I01478
num_objs 1
set01_V002_I01190
num_objs 2
set00_V001_I01295
num_objs 4
set05_V000_I00458
num_objs 3
set00_V010_I00827
num_objs 4
set02_V003_I00302
num_objs 1
set02_V010_I00935
num_objs 1
set01_V002_I00098
num_objs 5
set04_V002_I01067
num_objs 2
set00_V007_I01046
num_objs 4
set00_V013_I00158
num_objs 4
set00_V010_I00350
num_objs 6
set04_V002_I01733
num_objs 3
set03_V011_I00686
num_objs 2
set04_V003_I01232
num_objs 3
set04_V007_I01628
num_objs 1
set04_V011_I01037
num_objs 2
set03_V008_I00083
num_objs 7
set00_V006_I01499
num_objs 1
set02_V010_I01808
num_objs 1
set01_V005_I01628
num_objs 0
set00_V012_I01190
num_objs 0
set03_V009_I00719
num_objs 2
set03_V002_I01568
num_objs 1
set04_V003_I01163
num_objs 3
set00_V014_I01301
num_objs 6
set00_V008_I00146
num_objs 2
set04_V003_I00347
num_objs 1
set00_V014_I01100
num_objs 2
set00_V008_I01277
num_objs 1
set01_V000_I00569
num_objs 4
set03_V003_I01319
num_objs 0
set00_V007_I00098
num_objs 1
set03_V003_I00731
num_objs 2
set01_V001_I01730
num_objs 2
set04_V007_I01721
num_objs 1
set05_V012_I00554
num_objs 0
set03_V003_I00320
num_objs 1
set02_V009_I00608
num_objs 2
set00_V009_I01601
num_objs 4
set03_V004_I00215
num_objs 1
set05_V007_I01484
num_objs 1
set00_V007_I00629
num_objs 1
set03_V009_I00806
num_objs 2
set02_V009_I00212
num_objs 2
set05_V005_I01196
num_objs 1
set01_V001_I00932
num_objs 1
set04_V003_I01391
num_objs 3
set01_V005_I01463
num_objs 0
set04_V002_I01730
num_objs 3
set05_V007_I01211
num_objs 1
set01_V001_I01514
num_objs 11
set04_V008_I01436
num_objs 1
set00_V009_I00734
num_objs 3
set04_V003_I01244
num_objs 3
set01_V004_I01475
num_objs 2
set03_V009_I01676
num_objs 3
set04_V011_I01127
num_objs 1
set00_V013_I01580
num_objs 2
set04_V006_I00629
num_objs 1
set03_V003_I00149
num_objs 2
set00_V013_I00851
num_objs 2
set03_V004_I00449
num_objs 1
set05_V011_I00926
num_objs 8
set00_V000_I00965
num_objs 0
set00_V001_I01532
num_objs 5
set05_V009_I00875
num_objs 1
set05_V000_I00569
num_objs 2
set00_V003_I00365
num_objs 1
set04_V005_I00146
num_objs 1
set05_V009_I00836
num_objs 1
set05_V007_I01622
num_objs 0
set04_V005_I00164
num_objs 1
set02_V007_I00161
num_objs 1
set00_V009_I00953
num_objs 5
set01_V004_I00821
num_objs 3
set03_V009_I00356
num_objs 4
set00_V011_I00209
num_objs 1
set05_V010_I00425
num_objs 1
set04_V002_I01295
num_objs 2
set03_V005_I00434
num_objs 2
set00_V008_I00383
num_objs 2
set00_V001_I01763
num_objs 3
set00_V008_I01505
num_objs 3
set03_V003_I01004
num_objs 2
set05_V007_I01661
num_objs 0
set00_V007_I01151
num_objs 8
set00_V013_I01484
num_objs 4
set02_V010_I00470
num_objs 1
set03_V009_I00245
num_objs 4
set03_V006_I00029
num_objs 0
set01_V003_I00221
num_objs 7
set04_V004_I01394
num_objs 1
set00_V008_I01088
num_objs 0
set04_V003_I01238
num_objs 4
set00_V009_I00323
num_objs 6
set05_V011_I01265
num_objs 3
set03_V003_I00857
num_objs 2
set05_V010_I01592
num_objs 1
set04_V002_I01475
num_objs 2
set00_V014_I00635
num_objs 3
set00_V012_I01121
num_objs 0
set00_V013_I01175
num_objs 1
set02_V009_I00218
num_objs 2
set02_V007_I00128
num_objs 1
set01_V002_I00902
num_objs 4
set03_V004_I00569
num_objs 1
set05_V010_I00683
num_objs 1
set00_V012_I00362
num_objs 0
set04_V003_I01541
num_objs 1
set05_V011_I00953
num_objs 8
set02_V001_I01658
num_objs 1
set00_V011_I00791
num_objs 1
set00_V008_I01271
num_objs 1
set04_V004_I01190
num_objs 3
set00_V000_I00932
num_objs 0
set04_V008_I01406
num_objs 1
set04_V011_I01571
num_objs 1
set05_V003_I01193
num_objs 3
set00_V006_I00908
num_objs 4
set00_V012_I01523
num_objs 1
set00_V009_I01511
num_objs 3
set02_V009_I01760
num_objs 1
set05_V010_I00593
num_objs 1
set00_V004_I01139
num_objs 12
set05_V012_I00359
num_objs 1
set01_V005_I01115
num_objs 4
set04_V010_I01598
num_objs 2
set01_V003_I00575
num_objs 1
set05_V005_I00650
num_objs 1
set03_V006_I01817
num_objs 1
set04_V007_I01007
num_objs 2
set00_V000_I01319
num_objs 1
set03_V011_I00725
num_objs 1
set04_V006_I00725
num_objs 1
set03_V004_I00593
num_objs 1
set03_V008_I01229
num_objs 4
set02_V010_I01724
num_objs 1
set00_V011_I00341
num_objs 2
set04_V011_I01142
num_objs 1
set04_V002_I01331
num_objs 2
set00_V012_I00545
num_objs 1
set00_V007_I01031
num_objs 1
set03_V005_I01235
num_objs 2
set05_V000_I00650
num_objs 1
set00_V012_I00779
num_objs 3
set05_V004_I00941
num_objs 2
set03_V010_I01715
num_objs 3
set03_V008_I00251
num_objs 18
set05_V005_I01271
num_objs 1
set00_V006_I01388
num_objs 4
set05_V005_I00056
num_objs 4
set03_V009_I00980
num_objs 2
set00_V008_I00260
num_objs 0
set03_V008_I01637
num_objs 2
set05_V012_I01037
num_objs 1
set00_V011_I01202
num_objs 3
set04_V004_I00206
num_objs 2
set03_V005_I00251
num_objs 1
set00_V010_I01610
num_objs 0
set00_V010_I00560
num_objs 5
set00_V001_I00296
num_objs 6
set03_V010_I01619
num_objs 0
set00_V014_I00428
num_objs 6
set03_V009_I01505
num_objs 2
set01_V001_I00590
num_objs 3
set00_V006_I00071
num_objs 2
set00_V010_I00185
num_objs 4
set02_V008_I00542
num_objs 1
set02_V010_I01334
num_objs 1
set04_V004_I01067
num_objs 2
set04_V002_I00866
num_objs 1
set00_V009_I01307
num_objs 1
set05_V007_I01781
num_objs 0
set05_V011_I00854
num_objs 7
set01_V001_I01235
num_objs 10
set03_V002_I01595
num_objs 1
set05_V011_I00518
num_objs 1
set00_V008_I01247
num_objs 2
set01_V001_I00194
num_objs 2
set03_V005_I00980
num_objs 1
set04_V002_I00992
num_objs 2
set00_V012_I00239
num_objs 3
set04_V003_I01373
num_objs 3
set04_V003_I00440
num_objs 1
set00_V001_I01055
num_objs 12
set02_V003_I00131
num_objs 1
set03_V009_I01517
num_objs 2
set00_V013_I01364
num_objs 3
set00_V003_I00086
num_objs 1
set04_V003_I01121
num_objs 3
set01_V001_I01067
num_objs 1
set03_V008_I01046
num_objs 1
set00_V008_I00311
num_objs 0
set01_V002_I00107
num_objs 5
set00_V007_I01724
num_objs 4
set02_V010_I01340
num_objs 1
set05_V010_I00098
num_objs 1
set04_V008_I00983
num_objs 1
set01_V000_I00674
num_objs 0
set00_V007_I00668
num_objs 2
set00_V006_I01094
num_objs 10
set05_V000_I00260
num_objs 2
set00_V001_I00812
num_objs 3
set00_V012_I01508
num_objs 1
set01_V005_I00830
num_objs 2
set03_V010_I01460
num_objs 2
set01_V004_I01097
num_objs 4
set00_V001_I00089
num_objs 0
set00_V006_I00365
num_objs 4
set05_V003_I01754
num_objs 0
set02_V010_I00110
num_objs 1
set00_V000_I01628
num_objs 1
set01_V003_I01343
num_objs 1
set05_V004_I00992
num_objs 1
set05_V009_I00758
num_objs 1
set02_V009_I01073
num_objs 1
set00_V014_I00017
num_objs 3
set05_V002_I01469
num_objs 0
set00_V012_I00650
num_objs 0
set02_V003_I00287
num_objs 1
set03_V003_I00914
num_objs 2
set02_V001_I00077
num_objs 0
set00_V007_I01043
num_objs 4
set00_V010_I00611
num_objs 4
set05_V002_I00464
num_objs 1
set02_V001_I00128
num_objs 0
set05_V004_I00152
num_objs 3
set03_V011_I00998
num_objs 1
set01_V002_I00380
num_objs 5
set04_V005_I00893
num_objs 1
set04_V004_I00734
num_objs 2
set04_V005_I01457
num_objs 2
set01_V003_I00734
num_objs 2
set05_V003_I01073
num_objs 1
set01_V002_I01724
num_objs 5
set01_V000_I00794
num_objs 1
set03_V012_I01544
num_objs 4
set03_V004_I00515
num_objs 1
set00_V013_I00542
num_objs 5
set03_V004_I00083
num_objs 1
set03_V003_I00545
num_objs 2
set04_V004_I00749
num_objs 2
set00_V013_I00200
num_objs 4
set05_V000_I00437
num_objs 2
set00_V012_I01112
num_objs 0
set00_V013_I00302
num_objs 6
set00_V014_I00407
num_objs 5
set00_V014_I00644
num_objs 3
set05_V002_I00443
num_objs 1
set01_V001_I00749
num_objs 2
set01_V000_I00020
num_objs 1
set01_V000_I01172
num_objs 3
set01_V003_I00881
num_objs 1
set00_V013_I00533
num_objs 4
set05_V012_I00476
num_objs 3
set00_V006_I00674
num_objs 2
set00_V000_I00518
num_objs 1
set00_V008_I01109
num_objs 1
set00_V014_I01238
num_objs 4
set02_V008_I00824
num_objs 1
set05_V011_I01289
num_objs 2
set00_V012_I01040
num_objs 1
set05_V003_I01367
num_objs 2
set04_V002_I01493
num_objs 2
set04_V003_I01622
num_objs 1
set00_V011_I01535
num_objs 1
set04_V007_I00581
num_objs 2
set00_V006_I00032
num_objs 1
set04_V007_I01112
num_objs 2
set00_V012_I01022
num_objs 2
set03_V009_I01661
num_objs 3
set03_V005_I01538
num_objs 1
set00_V008_I00731
num_objs 2
set04_V007_I01583
num_objs 1
set05_V003_I01721
num_objs 0
set05_V005_I01040
num_objs 1
set04_V010_I01661
num_objs 2
set00_V002_I01049
num_objs 0
set03_V008_I00422
num_objs 17
set00_V013_I00893
num_objs 1
set05_V000_I01358
num_objs 2
set05_V002_I01613
num_objs 1
set03_V007_I00293
num_objs 1
set01_V005_I00977
num_objs 3
set02_V008_I01262
num_objs 1
set01_V005_I01208
num_objs 3
set00_V013_I01529
num_objs 5
set00_V001_I01238
num_objs 5
set04_V002_I01304
num_objs 2
set03_V005_I00632
num_objs 3
set00_V000_I01223
num_objs 2
set01_V003_I00872
num_objs 1
set00_V007_I00080
num_objs 1
set04_V004_I01130
num_objs 3
set00_V008_I00344
num_objs 0
set04_V000_I00761
num_objs 3
set00_V013_I00512
num_objs 3
set00_V009_I01634
num_objs 3
set02_V003_I00734
num_objs 2
set02_V009_I00287
num_objs 1
set05_V008_I01796
num_objs 1
set03_V008_I00986
num_objs 1
set04_V005_I00224
num_objs 1
set00_V008_I00971
num_objs 1
set01_V005_I00266
num_objs 1
set00_V007_I00821
num_objs 3
set00_V007_I00563
num_objs 5
set02_V011_I01514
num_objs 2
set00_V007_I00791
num_objs 2
set00_V010_I01295
num_objs 3
set00_V006_I01814
num_objs 0
set03_V008_I01601
num_objs 2
set03_V008_I01388
num_objs 3
set00_V001_I01346
num_objs 3
set03_V012_I01466
num_objs 3
set04_V003_I00917
num_objs 1
set04_V002_I01337
num_objs 2
set01_V004_I00716
num_objs 2
set00_V010_I01577
num_objs 1
set00_V011_I01277
num_objs 3
set04_V010_I00758
num_objs 1
set01_V003_I01805
num_objs 1
set02_V011_I01310
num_objs 1
set01_V002_I00143
num_objs 7
set00_V009_I00251
num_objs 7
set04_V002_I01037
num_objs 2
set05_V005_I01055
num_objs 1
set01_V000_I01178
num_objs 3
set00_V008_I01004
num_objs 1
set05_V011_I00548
num_objs 3
set03_V009_I01193
num_objs 3
set00_V004_I01391
num_objs 2
set05_V011_I01049
num_objs 5
set00_V012_I00614
num_objs 0
set04_V004_I00422
num_objs 2
set03_V009_I01028
num_objs 5
set01_V004_I00593
num_objs 3
set03_V012_I01331
num_objs 4
set00_V006_I01826
num_objs 0
set00_V009_I01472
num_objs 2
set01_V005_I01352
num_objs 1
set00_V001_I01700
num_objs 1
set00_V007_I00794
num_objs 2
set00_V013_I00563
num_objs 3
set01_V002_I00938
num_objs 4
set00_V011_I00449
num_objs 4
set02_V011_I01793
num_objs 2
set05_V007_I01385
num_objs 1
set03_V011_I01175
num_objs 1
set01_V001_I01079
num_objs 1
set05_V005_I00362
num_objs 2
set04_V010_I00899
num_objs 2
set03_V008_I01808
num_objs 1
set00_V010_I00242
num_objs 1
set02_V010_I01121
num_objs 1
set02_V009_I01517
num_objs 1
set05_V010_I00881
num_objs 1
set00_V013_I00065
num_objs 3
set04_V002_I01574
num_objs 1
set02_V003_I00239
num_objs 0
set01_V003_I01814
num_objs 1
set00_V007_I01118
num_objs 11
set01_V001_I00611
num_objs 3
set00_V008_I00533
num_objs 6
set05_V010_I00506
num_objs 1
set04_V003_I01637
num_objs 1
set00_V011_I00920
num_objs 4
set00_V014_I00803
num_objs 5
set03_V008_I00743
num_objs 3
set03_V005_I01349
num_objs 1
set03_V009_I00146
num_objs 5
set04_V002_I01055
num_objs 2
set00_V006_I01472
num_objs 3
set01_V001_I00098
num_objs 3
set04_V004_I00599
num_objs 0
set02_V009_I00683
num_objs 2
set04_V011_I01103
num_objs 2
set00_V010_I01217
num_objs 2
set00_V007_I01763
num_objs 4
set01_V001_I00647
num_objs 3
set02_V011_I00896
num_objs 1
set00_V000_I00350
num_objs 2
set04_V010_I00707
num_objs 1
set01_V005_I00287
num_objs 1
set03_V005_I01433
num_objs 1
set00_V004_I01268
num_objs 0
set01_V002_I01256
num_objs 4
set05_V007_I01676
num_objs 0
set01_V001_I00533
num_objs 3
set04_V010_I00851
num_objs 2
set00_V011_I00788
num_objs 1
set01_V002_I00473
num_objs 5
set05_V012_I00416
num_objs 3
set01_V004_I01268
num_objs 0
set01_V004_I00764
num_objs 2
set00_V001_I01286
num_objs 4
set05_V000_I01682
num_objs 1
set03_V009_I00692
num_objs 3
set00_V007_I01700
num_objs 5
set05_V000_I01685
num_objs 1
set00_V006_I01235
num_objs 6
set00_V014_I01070
num_objs 2
set00_V013_I00935
num_objs 1
set01_V003_I00986
num_objs 1
set03_V003_I01370
num_objs 2
set00_V006_I00245
num_objs 3
set02_V010_I00812
num_objs 2
set00_V001_I00503
num_objs 4
set00_V013_I00908
num_objs 1
set02_V011_I00881
num_objs 1
set02_V011_I00527
num_objs 2
set04_V003_I00551
num_objs 0
set02_V003_I00230
num_objs 1
set04_V005_I00896
num_objs 1
set02_V009_I00863
num_objs 1
set01_V003_I00161
num_objs 8
set00_V006_I01586
num_objs 2
set00_V006_I00041
num_objs 2
set05_V004_I00155
num_objs 3
set01_V001_I01001
num_objs 1
set00_V000_I00737
num_objs 2
set00_V014_I00416
num_objs 5
set00_V008_I00272
num_objs 0
set00_V008_I01454
num_objs 2
set01_V003_I01001
num_objs 2
set04_V005_I01196
num_objs 1
set01_V002_I00128
num_objs 6
set00_V012_I00290
num_objs 3
set03_V008_I01109
num_objs 0
set00_V001_I00992
num_objs 10
set02_V007_I00116
num_objs 1
set03_V008_I01379
num_objs 0
set00_V004_I00149
num_objs 1
set04_V006_I00887
num_objs 2
set01_V005_I00659
num_objs 2
set03_V009_I01163
num_objs 2
set01_V000_I01553
num_objs 4
set01_V000_I01250
num_objs 3
set05_V002_I00653
num_objs 1
set05_V011_I01661
num_objs 1
set02_V009_I01679
num_objs 0
set03_V010_I00965
num_objs 2
set01_V002_I01220
num_objs 3
set01_V004_I00890
num_objs 1
set00_V001_I01181
num_objs 3
set05_V007_I01610
num_objs 0
set00_V004_I00929
num_objs 1
set03_V008_I00887
num_objs 1
set00_V013_I01490
num_objs 4
set03_V009_I00779
num_objs 0
set00_V006_I00395
num_objs 4
set05_V005_I01241
num_objs 1
set05_V002_I01160
num_objs 1
set05_V010_I00488
num_objs 1
set00_V002_I00242
num_objs 2
set05_V007_I01223
num_objs 1
set01_V004_I00638
num_objs 4
set02_V010_I00179
num_objs 1
set04_V002_I01220
num_objs 2
set01_V001_I00323
num_objs 4
set04_V007_I00899
num_objs 1
set02_V010_I00320
num_objs 1
set04_V004_I00125
num_objs 1
set01_V005_I01235
num_objs 1
set05_V005_I01199
num_objs 0
set01_V001_I00593
num_objs 3
set05_V005_I00185
num_objs 0
set05_V010_I00704
num_objs 1
set02_V011_I01319
num_objs 0
set05_V010_I01652
num_objs 1
set01_V005_I00809
num_objs 2
set00_V012_I01145
num_objs 0
set00_V011_I01451
num_objs 4
set04_V011_I01757
num_objs 1
set00_V009_I00938
num_objs 4
set03_V008_I01118
num_objs 1
set02_V011_I01721
num_objs 2
set03_V002_I01643
num_objs 2
set05_V003_I01760
num_objs 0
set00_V003_I00071
num_objs 0
set02_V009_I00842
num_objs 1
set01_V005_I00041
num_objs 2
set00_V013_I01319
num_objs 5
set03_V010_I01448
num_objs 2
set03_V008_I00680
num_objs 3
set05_V004_I00233
num_objs 2
set00_V000_I00212
num_objs 4
set00_V008_I01214
num_objs 2
set01_V004_I01271
num_objs 0
set04_V001_I01538
num_objs 1
set04_V000_I00596
num_objs 3
set00_V010_I00803
num_objs 4
set03_V004_I00482
num_objs 1
set05_V005_I00533
num_objs 1
set04_V006_I00662
num_objs 3
set02_V011_I00596
num_objs 2
set00_V001_I00881
num_objs 3
set05_V002_I00671
num_objs 1
set04_V007_I01121
num_objs 2
set03_V008_I00557
num_objs 11
set03_V008_I00653
num_objs 4
set00_V006_I01223
num_objs 5
set03_V003_I00410
num_objs 1
set02_V009_I00425
num_objs 1
set04_V004_I00845
num_objs 2
set00_V007_I01862
num_objs 7
set04_V010_I00416
num_objs 1
set01_V001_I00839
num_objs 0
set02_V010_I00713
num_objs 2
set04_V003_I01328
num_objs 3
set04_V002_I00101
num_objs 0
set00_V009_I00947
num_objs 4
set02_V010_I01589
num_objs 0
set00_V008_I00131
num_objs 5
set00_V004_I00275
num_objs 1
set03_V008_I01301
num_objs 3
set00_V013_I01685
num_objs 0
set04_V006_I01073
num_objs 1
set00_V012_I01397
num_objs 1
set00_V008_I01397
num_objs 1
set00_V002_I00806
num_objs 4
set00_V013_I00308
num_objs 6
set03_V004_I00461
num_objs 1
set05_V012_I00419
num_objs 1
set05_V007_I01454
num_objs 1
set02_V008_I01088
num_objs 0
set04_V004_I00101
num_objs 1
set01_V005_I00611
num_objs 3
set00_V006_I01508
num_objs 2
set05_V002_I00533
num_objs 1
set01_V002_I00722
num_objs 6
set02_V009_I01061
num_objs 1
set01_V002_I01115
num_objs 3
set03_V010_I01535
num_objs 3
set03_V009_I00320
num_objs 4
set01_V005_I00584
num_objs 3
set02_V008_I00995
num_objs 1
set01_V002_I00350
num_objs 7
set04_V003_I00170
num_objs 0
set05_V011_I01127
num_objs 5
set04_V007_I00428
num_objs 1
set00_V008_I01238
num_objs 2
set01_V003_I00452
num_objs 4
set00_V012_I01640
num_objs 1
set00_V006_I01619
num_objs 0
set02_V010_I00308
num_objs 1
set03_V008_I01061
num_objs 1
set02_V009_I01784
num_objs 1
set00_V012_I00668
num_objs 0
set01_V001_I00824
num_objs 1
set01_V002_I00587
num_objs 7
set02_V009_I01670
num_objs 1
set00_V011_I00491
num_objs 5
set01_V005_I00452
num_objs 4
set01_V002_I00422
num_objs 5
set04_V007_I01577
num_objs 1
set02_V003_I00281
num_objs 1
set00_V011_I00824
num_objs 0
set01_V005_I01490
num_objs 0
set05_V005_I00092
num_objs 5
set00_V001_I00728
num_objs 3
set04_V008_I00617
num_objs 1
set00_V012_I01586
num_objs 2
set03_V005_I00293
num_objs 1
set01_V000_I00047
num_objs 1
set04_V002_I01790
num_objs 1
set00_V014_I01223
num_objs 4
set00_V010_I00929
num_objs 1
set00_V009_I00437
num_objs 2
set03_V004_I00617
num_objs 1
set01_V004_I01106
num_objs 4
set05_V003_I01343
num_objs 2
set03_V008_I01805
num_objs 1
set04_V003_I01685
num_objs 1
set01_V000_I00422
num_objs 2
set02_V011_I00593
num_objs 2
set04_V004_I00293
num_objs 2
set03_V008_I01751
num_objs 1
set00_V006_I00008
num_objs 1
set04_V011_I01781
num_objs 1
set05_V010_I00671
num_objs 1
set00_V009_I00371
num_objs 4
set01_V005_I00572
num_objs 3
set04_V011_I01031
num_objs 2
set05_V004_I00404
num_objs 1
set04_V003_I00314
num_objs 1
set05_V007_I01730
num_objs 0
set05_V002_I00746
num_objs 1
set05_V000_I01478
num_objs 1
set05_V003_I01406
num_objs 1
set00_V014_I01103
num_objs 2
set00_V011_I01199
num_objs 3
set00_V011_I00242
num_objs 1
set03_V008_I01526
num_objs 2
set02_V011_I00698
num_objs 1
set00_V010_I01508
num_objs 3
set05_V002_I01610
num_objs 1
set01_V001_I00053
num_objs 2
set00_V013_I01601
num_objs 2
set03_V008_I01031
num_objs 1
set01_V001_I00803
num_objs 1
set01_V002_I00053
num_objs 3
set05_V010_I00053
num_objs 1
set04_V003_I01094
num_objs 4
set00_V008_I00572
num_objs 4
set00_V011_I00182
num_objs 2
set00_V010_I01250
num_objs 3
set00_V014_I01400
num_objs 6
set03_V005_I00437
num_objs 2
set05_V002_I00689
num_objs 1
set04_V006_I00584
num_objs 1
set03_V010_I01823
num_objs 2
set00_V014_I00512
num_objs 4
set00_V014_I01544
num_objs 5
set00_V008_I00851
num_objs 1
set00_V001_I00923
num_objs 6
set00_V004_I01262
num_objs 0
set00_V006_I00410
num_objs 3
set04_V007_I00917
num_objs 2
set00_V010_I01652
num_objs 0
set00_V002_I00770
num_objs 2
set03_V008_I00227
num_objs 15
set03_V008_I00236
num_objs 16
set05_V004_I00290
num_objs 1
set00_V012_I00677
num_objs 0
set03_V008_I00566
num_objs 11
set03_V004_I00050
num_objs 1
set02_V007_I00935
num_objs 1
set01_V003_I00254
num_objs 4
set03_V011_I00914
num_objs 1
set00_V011_I00779
num_objs 1
set05_V010_I00341
num_objs 1
set00_V014_I00710
num_objs 3
set00_V013_I00659
num_objs 1
set05_V011_I01463
num_objs 3
set00_V013_I00104
num_objs 4
set03_V011_I00476
num_objs 5
set02_V001_I01592
num_objs 1
set00_V009_I01499
num_objs 6
set01_V000_I00818
num_objs 1
set00_V006_I00089
num_objs 3
set02_V007_I00143
num_objs 1
set02_V007_I00281
num_objs 1
set00_V006_I01238
num_objs 6
set00_V004_I01679
num_objs 0
set00_V001_I00338
num_objs 5
set04_V006_I01517
num_objs 1
set01_V000_I01610
num_objs 3
set03_V008_I01571
num_objs 1
set04_V004_I01169
num_objs 2
set01_V003_I01076
num_objs 1
set05_V011_I00671
num_objs 2
set00_V008_I00791
num_objs 2
set01_V002_I01196
num_objs 2
set00_V009_I00608
num_objs 2
set05_V005_I00179
num_objs 0
set00_V011_I01310
num_objs 5
set04_V003_I01265
num_objs 3
set00_V011_I00059
num_objs 4
set05_V003_I01361
num_objs 2
set03_V003_I00206
num_objs 1
set01_V005_I01379
num_objs 2
set00_V001_I01232
num_objs 5
set00_V002_I01226
num_objs 1
set05_V000_I01586
num_objs 1
set04_V007_I00914
num_objs 2
set05_V002_I00473
num_objs 1
set00_V012_I01580
num_objs 2
set00_V012_I00113
num_objs 0
set03_V001_I00809
num_objs 0
set05_V012_I00509
num_objs 1
set00_V014_I00566
num_objs 5
set01_V004_I01337
num_objs 1
set05_V010_I01046
num_objs 1
set04_V007_I00848
num_objs 2
set05_V005_I00488
num_objs 2
set01_V002_I00716
num_objs 6
set01_V001_I00851
num_objs 1
set02_V008_I01166
num_objs 0
set05_V005_I00422
num_objs 1
set05_V007_I01376
num_objs 1
set00_V010_I01031
num_objs 0
set03_V010_I01754
num_objs 3
set04_V008_I01451
num_objs 1
set05_V007_I01235
num_objs 1
set05_V003_I01043
num_objs 1
set05_V011_I01064
num_objs 8
set00_V008_I00977
num_objs 0
set00_V001_I01301
num_objs 4
set00_V001_I00509
num_objs 3
set03_V006_I00170
num_objs 1
set04_V007_I00413
num_objs 1
set05_V005_I00134
num_objs 1
set04_V004_I00689
num_objs 0
set01_V005_I00464
num_objs 4
set02_V009_I00167
num_objs 2
set03_V010_I00998
num_objs 3
set02_V010_I00332
num_objs 1
set04_V000_I00572
num_objs 3
set04_V005_I00173
num_objs 1
set00_V001_I00092
num_objs 3
set00_V006_I01013
num_objs 2
set01_V002_I00455
num_objs 5
set01_V003_I00899
num_objs 6
set00_V002_I00266
num_objs 2
set03_V009_I00047
num_objs 4
set05_V000_I01487
num_objs 1
set04_V007_I01508
num_objs 1
set02_V003_I00170
num_objs 1
set01_V000_I01010
num_objs 0
set00_V012_I00335
num_objs 1
set05_V011_I00650
num_objs 3
set01_V003_I00050
num_objs 4
set00_V000_I01706
num_objs 2
set05_V000_I01697
num_objs 1
set00_V006_I01601
num_objs 2
set04_V002_I01532
num_objs 3
set03_V008_I00467
num_objs 17
set00_V007_I00614
num_objs 3
set00_V007_I01064
num_objs 4
set04_V007_I01010
num_objs 2
set01_V003_I00392
num_objs 3
set02_V009_I01094
num_objs 1
set05_V000_I00191
num_objs 2
set04_V004_I01115
num_objs 3
set00_V001_I00968
num_objs 9
set00_V000_I00314
num_objs 1
set05_V011_I00887
num_objs 9
set01_V005_I00758
num_objs 2
set03_V005_I01427
num_objs 1
set04_V005_I01172
num_objs 1
set02_V009_I01643
num_objs 1
set03_V011_I00287
num_objs 4
set05_V004_I00146
num_objs 3
set03_V003_I01439
num_objs 0
set00_V001_I01274
num_objs 4
set04_V004_I00596
num_objs 3
set04_V007_I00980
num_objs 2
set01_V001_I00437
num_objs 3
set00_V010_I01379
num_objs 5
set00_V010_I00758
num_objs 3
set00_V000_I01118
num_objs 0
set02_V010_I01727
num_objs 1
set00_V009_I00521
num_objs 2
set05_V005_I00674
num_objs 1
set05_V011_I01274
num_objs 3
set00_V000_I01310
num_objs 1
set05_V010_I01601
num_objs 1
set00_V011_I00377
num_objs 3
set04_V003_I01658
num_objs 1
set03_V010_I01499
num_objs 1
set04_V002_I01619
num_objs 2
set01_V001_I00728
num_objs 2
set02_V003_I00101
num_objs 1
set04_V003_I01202
num_objs 3
set04_V007_I00266
num_objs 2
set03_V003_I01433
num_objs 2
set00_V011_I00065
num_objs 4
set01_V001_I00953
num_objs 1
set01_V002_I01319
num_objs 6
set00_V009_I00635
num_objs 1
set00_V006_I00902
num_objs 4
set00_V003_I00170
num_objs 1
set04_V005_I01067
num_objs 3
set02_V010_I00692
num_objs 2
set00_V007_I00884
num_objs 3
set00_V011_I01484
num_objs 2
set05_V010_I00725
num_objs 1
set00_V000_I01259
num_objs 0
set05_V011_I00914
num_objs 9
set02_V011_I00572
num_objs 2
set00_V001_I01418
num_objs 4
set05_V005_I00539
num_objs 1
set05_V011_I00986
num_objs 8
set03_V009_I01148
num_objs 2
set03_V008_I01460
num_objs 3
set02_V010_I00086
num_objs 1
set04_V004_I01292
num_objs 1
set00_V007_I01736
num_objs 5
set02_V009_I01256
num_objs 1
set04_V004_I00953
num_objs 2
set05_V002_I01556
num_objs 1
set02_V009_I01283
num_objs 1
set01_V001_I00206
num_objs 2
set00_V013_I01400
num_objs 2
set03_V008_I01661
num_objs 2
set00_V008_I00545
num_objs 5
set05_V005_I00827
num_objs 2
set00_V007_I00872
num_objs 3
set00_V009_I01529
num_objs 7
set00_V004_I00992
num_objs 3
set01_V001_I00239
num_objs 0
set04_V003_I00434
num_objs 1
set03_V008_I01463
num_objs 3
set04_V000_I00599
num_objs 0
set03_V010_I01757
num_objs 3
set03_V005_I00302
num_objs 1
set03_V004_I00041
num_objs 1
set00_V012_I00959
num_objs 5
set04_V007_I00512
num_objs 1
set00_V002_I01232
num_objs 1
set01_V002_I00548
num_objs 8
set00_V004_I01694
num_objs 1
set02_V011_I00911
num_objs 1
set00_V010_I00884
num_objs 3
set00_V006_I00932
num_objs 3
set00_V007_I00152
num_objs 1
set02_V008_I01271
num_objs 1
set05_V011_I00497
num_objs 1
set00_V000_I00701
num_objs 2
set03_V008_I01304
num_objs 3
set00_V014_I01517
num_objs 3
set04_V002_I00788
num_objs 1
set00_V009_I00311
num_objs 6
set03_V008_I00893
num_objs 1
set01_V000_I01694
num_objs 2
set00_V011_I00929
num_objs 3
set03_V009_I01733
num_objs 4
set04_V011_I01193
num_objs 1
set01_V000_I01229
num_objs 2
set05_V000_I01610
num_objs 1
set02_V007_I00950
num_objs 1
set02_V008_I00548
num_objs 1
set03_V011_I00527
num_objs 5
set00_V006_I00551
num_objs 4
set01_V001_I01070
num_objs 1
set04_V010_I01607
num_objs 2
set00_V010_I01004
num_objs 0
set01_V000_I01469
num_objs 3
set03_V011_I00560
num_objs 5
set01_V004_I00956
num_objs 3
set05_V010_I01556
num_objs 1
set03_V010_I01343
num_objs 1
set03_V011_I01214
num_objs 1
set03_V005_I00734
num_objs 1
set00_V008_I00206
num_objs 1
set03_V006_I00056
num_objs 1
set02_V007_I00110
num_objs 1
set03_V005_I00668
num_objs 1
set04_V005_I01496
num_objs 2
set01_V000_I00158
num_objs 1
set02_V011_I01685
num_objs 2
set05_V000_I01691
num_objs 1
set04_V004_I01043
num_objs 2
set03_V010_I00983
num_objs 3
set00_V007_I01268
num_objs 8
set03_V003_I01079
num_objs 1
set02_V009_I01799
num_objs 0
set00_V008_I00980
num_objs 0
set00_V005_I00851
num_objs 1
set02_V010_I01490
num_objs 2
set00_V006_I01295
num_objs 5
set03_V008_I00389
num_objs 13
set03_V008_I00167
num_objs 12
set00_V014_I00464
num_objs 4
set03_V008_I01214
num_objs 2
set00_V006_I01145
num_objs 5
set02_V011_I01589
num_objs 2
set01_V004_I00872
num_objs 2
set05_V000_I00383
num_objs 2
set03_V007_I00278
num_objs 1
set04_V011_I01850
num_objs 1
set05_V012_I00305
num_objs 1
set04_V006_I01106
num_objs 1
set04_V005_I00032
num_objs 1
set05_V012_I00542
num_objs 1
set04_V007_I00248
num_objs 2
set00_V009_I00761
num_objs 3
set05_V010_I00137
num_objs 1
set03_V010_I01826
num_objs 2
set03_V005_I01733
num_objs 2
set01_V003_I01406
num_objs 1
set04_V003_I01703
num_objs 1
set01_V005_I00044
num_objs 2
set04_V003_I01730
num_objs 1
set00_V014_I00365
num_objs 3
set02_V009_I00533
num_objs 1
set00_V009_I01556
num_objs 4
set01_V005_I00389
num_objs 2
set00_V007_I00458
num_objs 5
set00_V009_I01277
num_objs 1
set05_V005_I00635
num_objs 1
set01_V002_I01088
num_objs 3
set05_V003_I01793
num_objs 0
set03_V011_I01391
num_objs 1
set01_V005_I01697
num_objs 0
set05_V002_I01562
num_objs 1
set00_V006_I00680
num_objs 2
set02_V011_I00422
num_objs 1
set00_V012_I01646
num_objs 1
set01_V003_I00002
num_objs 4
set01_V000_I00113
num_objs 1
set03_V008_I00245
num_objs 17
set03_V011_I00260
num_objs 4
set05_V002_I00140
num_objs 1
set01_V001_I01427
num_objs 13
set03_V009_I00212
num_objs 5
set00_V001_I00290
num_objs 5
set03_V007_I01499
num_objs 0
set00_V010_I00791
num_objs 4
set05_V005_I01124
num_objs 1
set02_V011_I00857
num_objs 1
set02_V010_I00530
num_objs 2
set03_V002_I01448
num_objs 1
set03_V008_I00935
num_objs 1
set03_V009_I00026
num_objs 3
set03_V012_I00023
num_objs 1
set05_V012_I00407
num_objs 3
set05_V009_I00818
num_objs 1
set03_V011_I01406
num_objs 1
set00_V009_I00335
num_objs 5
set05_V000_I00746
num_objs 1
set01_V003_I00155
num_objs 8
set03_V003_I00875
num_objs 2
set01_V001_I01157
num_objs 3
set00_V013_I01421
num_objs 2
set00_V010_I01526
num_objs 3
set02_V010_I00746
num_objs 2
set00_V000_I00638
num_objs 0
set00_V001_I00248
num_objs 5
set03_V005_I01046
num_objs 1
set05_V005_I00446
num_objs 1
set03_V008_I01745
num_objs 1
set04_V004_I01187
num_objs 3
set00_V010_I01484
num_objs 4
set03_V005_I00578
num_objs 3
set00_V008_I00059
num_objs 7
set03_V009_I01754
num_objs 4
set02_V010_I00263
num_objs 1
set03_V005_I00998
num_objs 1
set04_V011_I01796
num_objs 1
set01_V003_I01037
num_objs 2
set03_V010_I00191
num_objs 1
set03_V005_I01742
num_objs 2
set00_V013_I01298
num_objs 3
set03_V009_I01250
num_objs 3
set00_V000_I01316
num_objs 1
set03_V011_I00710
num_objs 1
set00_V012_I00911
num_objs 6
set03_V002_I01592
num_objs 1
set04_V005_I00962
num_objs 1
set00_V002_I00377
num_objs 1
set00_V004_I00383
num_objs 1
set05_V007_I01268
num_objs 1
set02_V010_I00425
num_objs 1
set04_V003_I01691
num_objs 1
set04_V007_I00722
num_objs 2
set04_V007_I00431
num_objs 1
set04_V004_I01064
num_objs 2
set01_V002_I00416
num_objs 5
set01_V004_I00866
num_objs 2
set03_V009_I01220
num_objs 2
set00_V000_I00239
num_objs 3
set03_V003_I00392
num_objs 1
set04_V003_I01457
num_objs 4
set03_V008_I00140
num_objs 12
set00_V010_I00278
num_objs 3
set03_V009_I01715
num_objs 3
set03_V009_I00374
num_objs 4
set00_V009_I01076
num_objs 1
set05_V011_I01247
num_objs 3
set00_V007_I01247
num_objs 8
set00_V008_I01349
num_objs 2
set00_V014_I00263
num_objs 2
set01_V004_I01328
num_objs 1
set04_V006_I00944
num_objs 2
set04_V008_I01391
num_objs 1
set04_V006_I01637
num_objs 2
set04_V004_I01391
num_objs 1
set01_V001_I00281
num_objs 3
set02_V009_I00494
num_objs 1
set04_V003_I01052
num_objs 4
set02_V003_I00083
num_objs 1
set04_V006_I01034
num_objs 1
set05_V007_I01358
num_objs 1
set04_V002_I00647
num_objs 2
set00_V006_I01727
num_objs 0
set00_V014_I01472
num_objs 3
set05_V011_I00917
num_objs 9
set01_V003_I00425
num_objs 3
set04_V004_I00917
num_objs 2
set04_V007_I00788
num_objs 2
set03_V003_I01085
num_objs 2
set00_V009_I01505
num_objs 3
set00_V014_I00449
num_objs 1
set04_V007_I00551
num_objs 1
set00_V006_I01739
num_objs 1
set01_V001_I01700
num_objs 2
set00_V006_I01571
num_objs 2
set03_V008_I00494
num_objs 16
set05_V001_I00386
num_objs 0
set03_V009_I01499
num_objs 2
set05_V010_I01544
num_objs 1
set03_V010_I01358
num_objs 2
set05_V010_I00482
num_objs 1
set00_V013_I01406
num_objs 2
set00_V012_I00923
num_objs 6
set02_V011_I00344
num_objs 3
set01_V003_I00290
num_objs 4
set03_V005_I00476
num_objs 2
set02_V009_I01709
num_objs 0
set04_V004_I00680
num_objs 2
set00_V001_I01262
num_objs 4
set05_V012_I01046
num_objs 1
set03_V011_I00512
num_objs 5
set03_V008_I01190
num_objs 1
set01_V004_I00626
num_objs 4
set00_V014_I00662
num_objs 3
set02_V009_I00311
num_objs 1
set02_V011_I00905
num_objs 1
set04_V003_I00050
num_objs 0
set00_V009_I00581
num_objs 1
set01_V001_I00854
num_objs 1
set00_V012_I01475
num_objs 3
set04_V010_I00404
num_objs 1
set04_V007_I01079
num_objs 1
set00_V006_I01757
num_objs 1
set02_V010_I00314
num_objs 1
set02_V001_I01574
num_objs 2
set02_V009_I00110
num_objs 1
set04_V006_I01589
num_objs 1
set03_V008_I01799
num_objs 1
set04_V002_I00743
num_objs 2
set04_V007_I01217
num_objs 1
set04_V000_I00902
num_objs 1
set05_V000_I01481
num_objs 1
set04_V004_I00536
num_objs 3
set04_V002_I00914
num_objs 1
set00_V013_I01661
num_objs 2
set00_V001_I01094
num_objs 8
set00_V007_I00653
num_objs 2
set05_V003_I01202
num_objs 3
set00_V010_I00335
num_objs 5
set00_V009_I00959
num_objs 2
set02_V009_I01613
num_objs 2
set02_V011_I01655
num_objs 2
set01_V005_I00950
num_objs 3
set01_V002_I01259
num_objs 2
set03_V011_I01421
num_objs 1
set00_V004_I00815
num_objs 2
set04_V003_I01676
num_objs 1
set00_V000_I00218
num_objs 4
set03_V003_I00815
num_objs 2
set00_V006_I00971
num_objs 1
set03_V003_I00707
num_objs 2
set04_V007_I01277
num_objs 1
set00_V007_I01016
num_objs 0
set04_V003_I00398
num_objs 1
set02_V009_I01247
num_objs 2
set00_V010_I01286
num_objs 3
set04_V001_I01787
num_objs 1
set02_V010_I01460
num_objs 1
set01_V001_I01499
num_objs 2
set02_V010_I01838
num_objs 1
set01_V002_I01700
num_objs 4
set03_V011_I01436
num_objs 2
set01_V003_I00158
num_objs 8
set00_V008_I01415
num_objs 1
set00_V008_I00407
num_objs 2
set05_V002_I00608
num_objs 1
set03_V008_I00992
num_objs 1
set01_V005_I00098
num_objs 2
set00_V013_I01541
num_objs 3
set04_V002_I00059
num_objs 0
set05_V010_I00920
num_objs 2
set00_V000_I01190
num_objs 1
set03_V009_I00578
num_objs 4
set00_V007_I01895
num_objs 3
set00_V014_I01622
num_objs 4
set02_V009_I00098
num_objs 1
set02_V001_I01496
num_objs 1
set00_V013_I00482
num_objs 2
set00_V002_I01229
num_objs 1
set03_V009_I01346
num_objs 1
set00_V006_I00581
num_objs 5
set03_V012_I01613
num_objs 3
set03_V005_I00410
num_objs 2
set02_V009_I00581
num_objs 2
set00_V010_I00167
num_objs 1
set03_V003_I00431
num_objs 1
set04_V007_I00995
num_objs 2
set05_V003_I01373
num_objs 2
set00_V008_I00305
num_objs 0
set04_V002_I01382
num_objs 3
set00_V000_I01028
num_objs 0
set02_V011_I01301
num_objs 1
set04_V002_I00851
num_objs 1
set01_V002_I01673
num_objs 3
set00_V014_I00560
num_objs 5
set01_V001_I00902
num_objs 1
set00_V008_I00725
num_objs 3
set02_V003_I00008
num_objs 1
set00_V008_I00203
num_objs 1
set00_V001_I01724
num_objs 1
set00_V012_I01133
num_objs 0
set05_V011_I01598
num_objs 1
set03_V005_I00569
num_objs 3
set01_V004_I00266
num_objs 2
set05_V002_I01511
num_objs 1
set04_V010_I01691
num_objs 2
set00_V001_I01250
num_objs 4
set01_V005_I00569
num_objs 2
set04_V002_I01571
num_objs 2
set00_V000_I00089
num_objs 0
set00_V011_I00755
num_objs 1
set01_V004_I01259
num_objs 7
set03_V003_I00203
num_objs 1
set03_V009_I00107
num_objs 5
set00_V000_I00734
num_objs 2
set04_V003_I00284
num_objs 1
set00_V006_I00539
num_objs 2
set03_V011_I00311
num_objs 4
set04_V005_I00869
num_objs 1
set02_V011_I01421
num_objs 2
set03_V003_I00488
num_objs 2
set04_V000_I00803
num_objs 1
set00_V009_I01478
num_objs 2
set00_V002_I00113
num_objs 1
set05_V012_I01058
num_objs 1
set03_V008_I00755
num_objs 3
set00_V004_I00239
num_objs 0
set00_V007_I00719
num_objs 1
set00_V006_I01703
num_objs 0
set04_V001_I01619
num_objs 0
set04_V004_I01646
num_objs 1
set03_V006_I00035
num_objs 1
set02_V009_I01322
num_objs 1
set00_V006_I00023
num_objs 1
set00_V004_I01211
num_objs 0
set00_V009_I00920
num_objs 2
set00_V014_I00152
num_objs 1
set00_V008_I00155
num_objs 2
set04_V007_I01334
num_objs 1
set04_V003_I01430
num_objs 3
set02_V007_I00392
num_objs 1
set01_V002_I01082
num_objs 3
set00_V006_I01541
num_objs 2
set02_V011_I01550
num_objs 2
set00_V007_I00971
num_objs 3
set05_V005_I01004
num_objs 1
set01_V000_I00497
num_objs 0
set00_V000_I01577
num_objs 2
set00_V014_I00104
num_objs 3
set00_V012_I00815
num_objs 3
set00_V007_I00929
num_objs 3
set00_V000_I00458
num_objs 2
set03_V009_I00092
num_objs 5
set01_V002_I00644
num_objs 7
set01_V000_I00926
num_objs 4
set02_V010_I00482
num_objs 1
set00_V001_I00722
num_objs 3
set03_V005_I00551
num_objs 3
set04_V007_I00965
num_objs 2
set03_V003_I00485
num_objs 2
set00_V008_I01181
num_objs 0
set00_V004_I01670
num_objs 1
set00_V003_I00008
num_objs 1
set02_V011_I01820
num_objs 2
set03_V010_I01382
num_objs 2
set00_V001_I01448
num_objs 4
set05_V007_I01400
num_objs 1
set00_V002_I00197
num_objs 2
set00_V011_I00314
num_objs 2
set01_V004_I01052
num_objs 3
set04_V010_I00635
num_objs 1
set01_V004_I00887
num_objs 2
set04_V005_I00038
num_objs 1
set01_V004_I01346
num_objs 1
set00_V004_I01226
num_objs 0
set01_V000_I01196
num_objs 3
set01_V002_I00626
num_objs 7
set03_V003_I00629
num_objs 2
set00_V014_I01133
num_objs 3
set04_V010_I00686
num_objs 1
set00_V001_I01031
num_objs 13
set01_V003_I01379
num_objs 1
set05_V002_I01121
num_objs 2
set00_V006_I00224
num_objs 3
set02_V007_I00233
num_objs 1
set00_V007_I01343
num_objs 6
set00_V014_I01556
num_objs 6
set00_V014_I00188
num_objs 1
set00_V014_I01415
num_objs 4
set05_V001_I00359
num_objs 0
set00_V008_I00782
num_objs 2
set00_V004_I01238
num_objs 0
set03_V003_I00884
num_objs 2
set00_V010_I01142
num_objs 2
set00_V014_I00998
num_objs 3
set00_V009_I01490
num_objs 2
set01_V003_I00761
num_objs 2
set05_V000_I00377
num_objs 2
set03_V003_I00257
num_objs 1
set01_V001_I00524
num_objs 3
set01_V001_I00821
num_objs 1
set00_V012_I00479
num_objs 5
set04_V004_I01184
num_objs 3
set00_V007_I01433
num_objs 4
set05_V011_I00962
num_objs 8
set04_V003_I01298
num_objs 4
set03_V012_I01442
num_objs 3
set04_V008_I01082
num_objs 1
set03_V005_I01232
num_objs 2
set00_V001_I01790
num_objs 5
set00_V010_I01619
num_objs 1
set00_V007_I00773
num_objs 2
set04_V002_I01232
num_objs 2
set03_V009_I00446
num_objs 3
set01_V000_I01061
num_objs 2
set05_V002_I00587
num_objs 1
set03_V012_I01577
num_objs 3
set04_V010_I00773
num_objs 1
set04_V010_I01553
num_objs 2
set00_V010_I01283
num_objs 3
set04_V008_I01139
num_objs 1
set00_V004_I00380
num_objs 2
set03_V008_I00329
num_objs 13
set05_V010_I00086
num_objs 1
set00_V010_I01409
num_objs 3
set00_V004_I01037
num_objs 0
set05_V010_I00551
num_objs 1
set02_V003_I00311
num_objs 1
set01_V004_I00968
num_objs 1
set01_V004_I00239
num_objs 2
set05_V007_I01556
num_objs 0
set03_V010_I01703
num_objs 3
set04_V002_I01370
num_objs 2
set03_V009_I01604
num_objs 2
set05_V004_I00956
num_objs 1
set05_V012_I01145
num_objs 1
set00_V000_I00170
num_objs 3
set01_V000_I01169
num_objs 2
set01_V004_I00503
num_objs 1
set03_V005_I00617
num_objs 3
set00_V012_I01451
num_objs 3
set04_V004_I01058
num_objs 2
set01_V005_I01214
num_objs 3
set03_V009_I00611
num_objs 4
set00_V012_I00680
num_objs 0
set03_V007_I00290
num_objs 1
set01_V003_I01607
num_objs 1
set01_V004_I01265
num_objs 0
set01_V003_I01760
num_objs 1
set04_V000_I00569
num_objs 1
set04_V004_I00650
num_objs 2
set00_V014_I00587
num_objs 5
set00_V007_I01793
num_objs 2
set00_V010_I01340
num_objs 5
set01_V000_I00086
num_objs 3
set00_V002_I00215
num_objs 2
set05_V005_I00566
num_objs 1
set00_V007_I01112
num_objs 10
set00_V013_I01427
num_objs 3
set00_V003_I00440
num_objs 1
set01_V003_I00110
num_objs 7
set00_V008_I00767
num_objs 2
set02_V010_I01694
num_objs 1
set01_V001_I00941
num_objs 1
set01_V001_I00539
num_objs 1
set00_V001_I00287
num_objs 5
set03_V005_I00728
num_objs 1
set00_V001_I01658
num_objs 2
set00_V012_I01442
num_objs 2
set04_V005_I01187
num_objs 2
set01_V005_I01160
num_objs 3
set05_V000_I00551
num_objs 2
set00_V004_I01529
num_objs 7
set01_V004_I00224
num_objs 0
set01_V004_I00818
num_objs 3
set02_V009_I01826
num_objs 2
set00_V010_I01133
num_objs 2
set02_V011_I00479
num_objs 2
set05_V003_I01583
num_objs 0
set00_V000_I01235
num_objs 2
set00_V012_I01439
num_objs 2
set04_V002_I01448
num_objs 2
set03_V005_I01247
num_objs 2
set00_V006_I01568
num_objs 2
set04_V005_I00185
num_objs 1
set05_V011_I00797
num_objs 5
set04_V000_I00500
num_objs 2
set02_V009_I00743
num_objs 2
set01_V005_I00860
num_objs 2
set01_V000_I00095
num_objs 3
set00_V001_I01328
num_objs 4
set05_V002_I01499
num_objs 0
set00_V011_I01091
num_objs 7
set02_V007_I00467
num_objs 1
set03_V009_I00167
num_objs 5
set00_V004_I01250
num_objs 0
set00_V002_I00236
num_objs 2
set03_V010_I01067
num_objs 1
set00_V004_I01325
num_objs 1
set05_V012_I00695
num_objs 1
set00_V011_I01316
num_objs 5
set04_V000_I00926
num_objs 1
set00_V008_I00161
num_objs 3
set05_V004_I00410
num_objs 2
set03_V002_I01481
num_objs 1
set03_V008_I01055
num_objs 1
set00_V000_I00725
num_objs 2
set04_V004_I00890
num_objs 2
set03_V008_I00056
num_objs 4
set03_V008_I00860
num_objs 1
set00_V002_I00587
num_objs 0
set04_V011_I01136
num_objs 1
set04_V011_I01835
num_objs 1
set04_V004_I00443
num_objs 2
set02_V011_I00917
num_objs 1
set02_V009_I00302
num_objs 1
set05_V000_I00521
num_objs 3
set01_V005_I01664
num_objs 0
set00_V004_I01640
num_objs 1
set03_V005_I01676
num_objs 1
set00_V000_I01277
num_objs 1
set05_V010_I00905
num_objs 2
set03_V003_I00251
num_objs 1
set00_V000_I00419
num_objs 3
set00_V013_I01499
num_objs 4
set01_V001_I01724
num_objs 2
set03_V011_I01259
num_objs 1
set04_V005_I01655
num_objs 1
set00_V004_I00344
num_objs 2
set00_V001_I01565
num_objs 3
set03_V009_I01703
num_objs 3
set05_V005_I00503
num_objs 2
set01_V000_I00983
num_objs 0
set02_V011_I01436
num_objs 2
set00_V013_I01001
num_objs 1
set01_V000_I00797
num_objs 1
set00_V006_I01664
num_objs 0
set04_V010_I00770
num_objs 1
set05_V005_I00617
num_objs 1
set00_V001_I01289
num_objs 0
set02_V010_I00647
num_objs 2
set04_V002_I01142
num_objs 2
set03_V008_I00089
num_objs 13
set01_V003_I00830
num_objs 2
set04_V004_I01319
num_objs 1
set00_V014_I01466
num_objs 3
set01_V005_I00590
num_objs 3
set01_V004_I00644
num_objs 4
set00_V000_I00905
num_objs 0
set05_V005_I00161
num_objs 0
set00_V007_I00194
num_objs 4
set03_V008_I01271
num_objs 2
set01_V005_I01391
num_objs 1
set01_V003_I00743
num_objs 2
set00_V007_I01349
num_objs 3
set03_V005_I01469
num_objs 0
set00_V002_I00485
num_objs 0
set02_V007_I00956
num_objs 1
set00_V013_I00764
num_objs 1
set04_V002_I00977
num_objs 2
set03_V009_I01262
num_objs 2
set01_V002_I01790
num_objs 5
set05_V000_I01679
num_objs 0
set00_V008_I01445
num_objs 1
set04_V010_I00836
num_objs 2
set00_V000_I01247
num_objs 1
set01_V000_I01514
num_objs 4
set00_V010_I01685
num_objs 1
set00_V004_I00938
num_objs 2
set00_V000_I00431
num_objs 6
set00_V010_I01160
num_objs 2
set00_V001_I01388
num_objs 3
set04_V005_I00974
num_objs 1
set01_V004_I01484
num_objs 2
set03_V011_I00815
num_objs 2
set03_V001_I00845
num_objs 1
set02_V003_I00164
num_objs 1
set00_V014_I01094
num_objs 2
set02_V010_I00749
num_objs 2
set01_V003_I01685
num_objs 3
set00_V011_I01124
num_objs 6
set04_V004_I00851
num_objs 2
set03_V003_I01547
num_objs 2
set02_V011_I00737
num_objs 1
set01_V001_I01307
num_objs 11
set00_V007_I01208
num_objs 7
set01_V003_I00710
num_objs 2
set02_V001_I01586
num_objs 1
set00_V002_I00890
num_objs 6
set04_V004_I01655
num_objs 2
set01_V003_I01679
num_objs 3
set01_V001_I01367
num_objs 9
set01_V005_I00053
num_objs 2
set00_V010_I00845
num_objs 3
set01_V004_I00209
num_objs 0
set03_V011_I00701
num_objs 1
set01_V000_I00389
num_objs 1
set00_V003_I00416
num_objs 1
set01_V005_I00509
num_objs 1
set03_V008_I01262
num_objs 2
set01_V002_I00101
num_objs 6
set04_V008_I01379
num_objs 0
set00_V001_I01067
num_objs 10
set01_V003_I00551
num_objs 1
set04_V005_I01427
num_objs 1
set04_V003_I00197
num_objs 0
set00_V014_I00779
num_objs 4
set00_V008_I01316
num_objs 0
set00_V003_I00482
num_objs 1
set01_V004_I01391
num_objs 1
set00_V004_I00215
num_objs 1
set04_V007_I00671
num_objs 2
set02_V011_I00611
num_objs 2
set03_V005_I00515
num_objs 2
set04_V011_I01181
num_objs 1
set01_V004_I00056
num_objs 2
set03_V012_I01583
num_objs 3
set05_V010_I00743
num_objs 1
set00_V002_I00503
num_objs 0
set01_V001_I00152
num_objs 3
set04_V003_I00221
num_objs 0
set03_V008_I00785
num_objs 3
set01_V002_I00476
num_objs 5
set00_V006_I01514
num_objs 2
set04_V005_I00746
num_objs 1
set04_V008_I01472
num_objs 1
set00_V006_I00020
num_objs 1
set03_V005_I01382
num_objs 1
set03_V003_I00395
num_objs 1
set00_V006_I00029
num_objs 3
set02_V007_I00404
num_objs 1
set00_V000_I00866
num_objs 0
set03_V006_I01802
num_objs 1
set00_V009_I01508
num_objs 3
set00_V002_I00473
num_objs 0
set00_V010_I00206
num_objs 4
set03_V012_I01190
num_objs 1
set03_V011_I00365
num_objs 5
set01_V000_I01148
num_objs 4
set00_V007_I01313
num_objs 8
set00_V011_I00971
num_objs 10
set04_V004_I00086
num_objs 1
set02_V008_I01256
num_objs 1
set01_V003_I00614
num_objs 1
set00_V001_I00224
num_objs 5
set03_V010_I01661
num_objs 4
set03_V001_I00836
num_objs 1
set00_V001_I00851
num_objs 3
set03_V011_I00248
num_objs 3
set01_V005_I00113
num_objs 2
set00_V001_I01148
num_objs 5
set03_V012_I00992
num_objs 1
set00_V006_I01301
num_objs 5
set02_V011_I00380
num_objs 2
set04_V004_I00683
num_objs 2
set00_V011_I01232
num_objs 4
set00_V000_I00494
num_objs 1
set00_V011_I01445
num_objs 4
set00_V006_I01919
num_objs 1
set00_V002_I01280
num_objs 0
set04_V003_I00251
num_objs 1
set00_V000_I01202
num_objs 2
set01_V000_I01589
num_objs 3
set03_V006_I01736
num_objs 1
set05_V004_I00986
num_objs 1
set01_V001_I01277
num_objs 11
set00_V002_I00122
num_objs 1
set04_V001_I01613
num_objs 2
set04_V002_I01352
num_objs 2
set04_V007_I01784
num_objs 1
set00_V010_I01631
num_objs 0
set00_V001_I00533
num_objs 3
set00_V004_I01253
num_objs 0
set00_V008_I00401
num_objs 2
set04_V005_I00740
num_objs 1
set00_V011_I00872
num_objs 0
set01_V003_I01628
num_objs 1
set03_V007_I01526
num_objs 0
set00_V007_I00125
num_objs 0
set01_V002_I01688
num_objs 3
set00_V007_I01364
num_objs 5
set03_V008_I00608
num_objs 7
set01_V001_I00002
num_objs 1
set02_V011_I01460
num_objs 2
set00_V009_I00797
num_objs 2
set05_V011_I00554
num_objs 4
set03_V008_I01742
num_objs 1
set05_V010_I00050
num_objs 1
set05_V008_I00224
num_objs 2
set00_V002_I00659
num_objs 0
set05_V010_I00641
num_objs 1
set04_V004_I01748
num_objs 1
set00_V001_I00377
num_objs 5
set04_V005_I01454
num_objs 2
set03_V012_I01385
num_objs 5
set03_V005_I01655
num_objs 1
set04_V003_I01034
num_objs 4
set03_V003_I00086
num_objs 2
set00_V010_I00704
num_objs 2
set00_V008_I00992
num_objs 1
set02_V010_I00698
num_objs 2
set00_V011_I00098
num_objs 4
set00_V006_I01574
num_objs 2
set03_V009_I01697
num_objs 3
set05_V005_I00968
num_objs 1
set00_V000_I01652
num_objs 1
set02_V001_I00071
num_objs 0
set00_V007_I00356
num_objs 5
set01_V005_I00617
num_objs 3
set02_V009_I01340
num_objs 1
set00_V005_I00839
num_objs 1
set04_V007_I00272
num_objs 2
set04_V008_I01415
num_objs 1
set00_V006_I00575
num_objs 5
set02_V010_I01517
num_objs 2
set01_V001_I00662
num_objs 3
set00_V007_I00005
num_objs 1
set05_V007_I01670
num_objs 0
set02_V009_I00149
num_objs 0
set02_V011_I01382
num_objs 2
set03_V011_I00317
num_objs 4
set04_V004_I00887
num_objs 2
set02_V011_I00899
num_objs 0
set03_V011_I00176
num_objs 3
set05_V005_I01139
num_objs 0
set04_V005_I01514
num_objs 2
set03_V002_I01589
num_objs 1
set03_V003_I00776
num_objs 2
set00_V000_I01811
num_objs 0
set03_V003_I00095
num_objs 2
set00_V007_I01706
num_objs 5
set01_V005_I00995
num_objs 3
set02_V010_I01547
num_objs 1
set01_V005_I01133
num_objs 4
set03_V003_I01217
num_objs 2
set03_V010_I01340
num_objs 1
set04_V007_I00707
num_objs 2
set00_V012_I00848
num_objs 4
set04_V007_I01337
num_objs 1
set02_V010_I01061
num_objs 1
set00_V014_I01379
num_objs 0
set03_V011_I01166
num_objs 1
set00_V012_I00371
num_objs 0
set04_V011_I01034
num_objs 2
set02_V011_I01340
num_objs 1
set02_V009_I01373
num_objs 1
set00_V011_I00308
num_objs 2
set00_V006_I01397
num_objs 4
set03_V011_I00758
num_objs 2
set00_V000_I00818
num_objs 0
set02_V009_I00797
num_objs 2
set00_V014_I00278
num_objs 3
set03_V005_I00806
num_objs 1
set04_V002_I00887
num_objs 1
set05_V011_I01517
num_objs 2
set02_V010_I01661
num_objs 1
set03_V003_I00245
num_objs 1
set04_V002_I01403
num_objs 3
set03_V005_I01499
num_objs 0
set01_V004_I00050
num_objs 2
set00_V007_I00575
num_objs 5
set00_V008_I01112
num_objs 0
set04_V011_I01529
num_objs 0
set05_V012_I01196
num_objs 1
set03_V005_I01160
num_objs 2
set01_V000_I00014
num_objs 1
set00_V014_I00872
num_objs 5
set04_V002_I00908
num_objs 1
set01_V004_I00125
num_objs 2
set03_V003_I00722
num_objs 2
set04_V007_I01220
num_objs 1
set02_V009_I01295
num_objs 1
set02_V001_I01550
num_objs 1
set00_V001_I01754
num_objs 1
set00_V012_I00845
num_objs 4
set00_V000_I00308
num_objs 1
set04_V011_I01574
num_objs 1
set00_V002_I00926
num_objs 2
set05_V000_I00149
num_objs 0
set04_V000_I00731
num_objs 3
set04_V006_I00971
num_objs 2
set04_V004_I01316
num_objs 1
set00_V007_I01304
num_objs 9
set04_V008_I01349
num_objs 0
set04_V002_I00134
num_objs 0
set00_V014_I01691
num_objs 3
set00_V000_I00491
num_objs 1
set01_V005_I01196
num_objs 3
set00_V008_I00431
num_objs 7
set04_V005_I00305
num_objs 1
set04_V006_I00704
num_objs 3
set00_V008_I00662
num_objs 3
set00_V011_I01235
num_objs 4
set05_V003_I01781
num_objs 0
set00_V010_I00389
num_objs 6
set02_V011_I01829
num_objs 0
set03_V005_I01352
num_objs 1
set00_V013_I01130
num_objs 4
set04_V002_I00641
num_objs 1
set01_V001_I00056
num_objs 2
set05_V010_I00350
num_objs 1
set00_V014_I00881
num_objs 5
set04_V001_I01679
num_objs 1
set01_V004_I00656
num_objs 2
set05_V003_I01562
num_objs 0
set00_V012_I00164
num_objs 1
set04_V003_I00116
num_objs 0
set05_V005_I00830
num_objs 2
set04_V008_I01013
num_objs 1
set00_V007_I00077
num_objs 1
set01_V002_I00059
num_objs 1
set00_V012_I01601
num_objs 1
set01_V005_I00515
num_objs 2
set03_V008_I00545
num_objs 12
set05_V009_I01001
num_objs 1
set03_V003_I01331
num_objs 2
set02_V009_I01592
num_objs 2
set04_V005_I01157
num_objs 1
set01_V003_I01052
num_objs 2
set03_V003_I01163
num_objs 2
set00_V013_I00425
num_objs 3
set00_V001_I01415
num_objs 4
set03_V011_I00455
num_objs 5
set00_V007_I00569
num_objs 3
set00_V006_I00617
num_objs 4
set03_V009_I01232
num_objs 2
set04_V003_I01412
num_objs 3
set04_V002_I00065
num_objs 1
set05_V005_I01037
num_objs 1
set00_V007_I00251
num_objs 6
set02_V009_I00242
num_objs 2
set01_V005_I01793
num_objs 0
set04_V005_I00200
num_objs 1
set02_V008_I01145
num_objs 0
set02_V010_I00758
num_objs 3
set02_V007_I00398
num_objs 1
set00_V001_I01100
num_objs 8
set04_V003_I00467
num_objs 0
set02_V011_I01772
num_objs 2
set04_V011_I01805
num_objs 1
set04_V007_I00746
num_objs 2
set03_V008_I01298
num_objs 3
set03_V009_I00224
num_objs 5
set03_V010_I01790
num_objs 3
set05_V004_I00125
num_objs 3
set04_V004_I01739
num_objs 0
set01_V000_I01307
num_objs 3
set00_V011_I01538
num_objs 0
set00_V012_I00269
num_objs 3
set02_V011_I01724
num_objs 2
set04_V006_I00605
num_objs 1
set03_V003_I00782
num_objs 2
set00_V004_I00923
num_objs 2
set00_V004_I00869
num_objs 0
set03_V005_I01571
num_objs 1
set00_V014_I00089
num_objs 3
set00_V002_I01064
num_objs 0
set00_V013_I01472
num_objs 4
set04_V011_I01829
num_objs 1
set04_V010_I01655
num_objs 2
set00_V013_I00824
num_objs 2
set05_V003_I01364
num_objs 2
set02_V009_I00317
num_objs 1
set05_V002_I01475
num_objs 1
set04_V010_I00596
num_objs 1
set05_V007_I01706
num_objs 0
set05_V000_I00350
num_objs 3
set03_V005_I01604
num_objs 1
set03_V008_I00491
num_objs 16
set02_V010_I00821
num_objs 2
set02_V009_I01736
num_objs 1
set03_V008_I01361
num_objs 3
set00_V001_I01370
num_objs 3
set00_V010_I00428
num_objs 8
set00_V006_I00947
num_objs 1
set00_V009_I01370
num_objs 0
set01_V002_I00623
num_objs 7
set05_V000_I00530
num_objs 3
set00_V014_I01025
num_objs 3
set04_V006_I01583
num_objs 1
set01_V001_I00626
num_objs 3
set01_V002_I00113
num_objs 5
set01_V000_I00332
num_objs 1
set03_V001_I00839
num_objs 1
set01_V000_I01358
num_objs 4
set00_V004_I01202
num_objs 0
set00_V008_I01031
num_objs 3
set00_V002_I00200
num_objs 2
set00_V006_I00938
num_objs 3
set04_V003_I01349
num_objs 2
set01_V005_I00371
num_objs 3
set02_V009_I00740
num_objs 2
set00_V003_I00155
num_objs 1
set01_V005_I01226
num_objs 1
set00_V001_I01121
num_objs 7
set04_V000_I00878
num_objs 1
set00_V013_I00527
num_objs 4
set04_V006_I00716
num_objs 2
set00_V011_I00947
num_objs 8
set05_V000_I00176
num_objs 4
set04_V003_I01178
num_objs 3
set01_V002_I00140
num_objs 6
set00_V006_I00737
num_objs 1
set02_V003_I00323
num_objs 1
set05_V002_I00461
num_objs 1
set03_V009_I01043
num_objs 6
set03_V010_I01436
num_objs 2
set05_V010_I00455
num_objs 1
set05_V011_I00971
num_objs 8
set03_V010_I01457
num_objs 2
set02_V010_I00608
num_objs 2
set05_V000_I00251
num_objs 2
set02_V003_I00107
num_objs 1
set00_V014_I00575
num_objs 5
set04_V008_I01355
num_objs 1
set00_V009_I00569
num_objs 2
set00_V006_I00413
num_objs 3
set00_V011_I01577
num_objs 0
set02_V009_I00629
num_objs 2
set00_V012_I00854
num_objs 4
set02_V009_I01205
num_objs 2
set01_V001_I00209
num_objs 1
set00_V000_I00251
num_objs 5
set00_V014_I00590
num_objs 5
set00_V010_I00926
num_objs 1
set03_V005_I01823
num_objs 2
set03_V009_I00617
num_objs 4
set04_V001_I01688
num_objs 2
set04_V007_I00755
num_objs 2
set00_V014_I01109
num_objs 2
set03_V005_I00347
num_objs 2
set05_V011_I01076
num_objs 6
set01_V001_I01046
num_objs 1
set01_V004_I00689
num_objs 1
set02_V009_I00566
num_objs 2
set04_V007_I01685
num_objs 1
set01_V002_I00890
num_objs 4
set02_V003_I00251
num_objs 1
set03_V005_I00266
num_objs 1
set01_V001_I00782
num_objs 2
set04_V007_I01466
num_objs 1
set05_V003_I01229
num_objs 3
set00_V014_I01778
num_objs 1
set01_V004_I00797
num_objs 2
set00_V008_I01304
num_objs 1
set05_V000_I01373
num_objs 2
set03_V011_I01352
num_objs 1
set00_V009_I01658
num_objs 2
set00_V002_I00245
num_objs 2
set02_V007_I00356
num_objs 1
set00_V001_I00203
num_objs 2
set04_V005_I00197
num_objs 1
set03_V012_I01532
num_objs 4
set01_V000_I00071
num_objs 3
set00_V014_I00917
num_objs 2
set01_V003_I00113
num_objs 7
set05_V000_I00050
num_objs 2
set04_V007_I00569
num_objs 1
set02_V009_I01505
num_objs 1
set00_V009_I00278
num_objs 5
set00_V007_I00302
num_objs 6
set02_V010_I01124
num_objs 1
set04_V005_I00278
num_objs 1
set00_V004_I00818
num_objs 2
set00_V012_I01211
num_objs 0
set04_V003_I01091
num_objs 4
set04_V010_I00809
num_objs 1
set04_V003_I01415
num_objs 3
set00_V006_I00278
num_objs 3
set00_V001_I01061
num_objs 10
set04_V002_I01004
num_objs 2
set03_V009_I01595
num_objs 2
set00_V012_I00089
num_objs 0
set03_V005_I00962
num_objs 1
set04_V003_I00293
num_objs 1
set00_V001_I01760
num_objs 3
set03_V005_I00491
num_objs 2
set00_V008_I01043
num_objs 3
set03_V009_I00971
num_objs 2
set01_V005_I01298
num_objs 1
set05_V000_I00464
num_objs 3
set02_V010_I00335
num_objs 1
set01_V001_I01373
num_objs 9
set00_V011_I00023
num_objs 5
set05_V010_I01535
num_objs 2
set00_V002_I00542
num_objs 0
set03_V004_I00104
num_objs 1
set00_V002_I01052
num_objs 0
set03_V010_I01781
num_objs 3
set00_V013_I01097
num_objs 3
set00_V000_I01739
num_objs 0
set04_V003_I00764
num_objs 1
set05_V000_I00563
num_objs 2
set03_V005_I00629
num_objs 2
set00_V007_I00347
num_objs 5
set01_V000_I01580
num_objs 4
set05_V007_I01613
num_objs 0
set02_V009_I00374
num_objs 2
set00_V006_I00929
num_objs 3
set01_V005_I01601
num_objs 0
set01_V001_I00074
num_objs 2
set00_V007_I00743
num_objs 2
set05_V005_I01154
num_objs 1
set01_V005_I00125
num_objs 2
set00_V010_I00830
num_objs 4
set00_V001_I01217
num_objs 4
set02_V010_I00275
num_objs 1
set04_V007_I00440
num_objs 1
set01_V005_I00341
num_objs 3
set04_V010_I01679
num_objs 0
set03_V010_I01442
num_objs 2
set01_V002_I01442
num_objs 0
set01_V005_I01547
num_objs 0
set00_V000_I01682
num_objs 2
set00_V008_I00644
num_objs 4
set01_V001_I01484
num_objs 10
set01_V001_I01421
num_objs 12
set03_V008_I00947
num_objs 1
set00_V012_I01676
num_objs 1
set02_V009_I00206
num_objs 2
set05_V005_I00542
num_objs 1
set04_V007_I00383
num_objs 1
set00_V013_I01466
num_objs 4
set03_V008_I00137
num_objs 11
set02_V008_I01832
num_objs 0
set03_V003_I00704
num_objs 2
set01_V000_I00971
num_objs 0
set00_V010_I00170
num_objs 1
set01_V002_I00206
num_objs 7
set04_V006_I00689
num_objs 0
set03_V011_I01385
num_objs 1
set02_V009_I00197
num_objs 2
set00_V011_I00188
num_objs 1
set00_V004_I01475
num_objs 0
set01_V003_I00611
num_objs 1
set04_V003_I00437
num_objs 1
set04_V004_I00770
num_objs 2
set00_V007_I00398
num_objs 6
set04_V007_I00224
num_objs 1
set00_V008_I00665
num_objs 3
set01_V000_I01052
num_objs 1
set04_V002_I01688
num_objs 2
set00_V013_I01487
num_objs 4
set00_V007_I00254
num_objs 6
set05_V010_I01067
num_objs 1
set00_V014_I01688
num_objs 3
set00_V007_I01631
num_objs 5
set04_V008_I01145
num_objs 1
set01_V003_I00086
num_objs 5
set04_V011_I01010
num_objs 2
set01_V004_I00911
num_objs 3
set04_V001_I01760
num_objs 1
set02_V008_I00971
num_objs 0
set01_V004_I01223
num_objs 0
set00_V002_I00572
num_objs 0
set00_V004_I00935
num_objs 2
set04_V007_I00863
num_objs 2
set00_V008_I01520
num_objs 1
set00_V000_I01334
num_objs 1
set00_V004_I01076
num_objs 1
set01_V001_I01232
num_objs 10
set00_V013_I01595
num_objs 3
set00_V002_I00338
num_objs 1
set01_V005_I00719
num_objs 2
set01_V005_I01532
num_objs 0
set04_V003_I00146
num_objs 0
set00_V008_I00629
num_objs 4
set03_V003_I00797
num_objs 2
set05_V002_I00680
num_objs 1
set03_V006_I00062
num_objs 1
set00_V008_I00236
num_objs 0
set04_V002_I01649
num_objs 2
set00_V008_I01697
num_objs 0
set03_V009_I01691
num_objs 3
set05_V005_I00347
num_objs 2
set01_V002_I00299
num_objs 5
set02_V003_I00698
num_objs 2
set03_V002_I01640
num_objs 2
set03_V003_I01259
num_objs 0
set05_V007_I01760
num_objs 0
set04_V003_I00206
num_objs 0
set00_V002_I00341
num_objs 1
set03_V003_I00800
num_objs 2
set03_V011_I01340
num_objs 1
set00_V014_I00323
num_objs 3
set01_V005_I01325
num_objs 1
set02_V009_I00269
num_objs 0
set03_V004_I00590
num_objs 1
set03_V003_I00374
num_objs 1
set05_V005_I00563
num_objs 1
set05_V003_I01808
num_objs 0
set00_V013_I00698
num_objs 1
set01_V005_I00377
num_objs 3
set03_V009_I01760
num_objs 4
set04_V007_I00662
num_objs 2
set05_V011_I00644
num_objs 4
set00_V014_I00149
num_objs 2
set03_V005_I01634
num_objs 1
set04_V005_I00332
num_objs 1
set00_V004_I01466
num_objs 0
set01_V000_I00629
num_objs 3
set00_V012_I01115
num_objs 0
set03_V006_I00041
num_objs 1
set04_V002_I00674
num_objs 2
set03_V011_I00320
num_objs 5
set00_V013_I00641
num_objs 2
set00_V000_I01127
num_objs 0
set04_V000_I00812
num_objs 1
set01_V005_I00200
num_objs 2
set00_V013_I00635
num_objs 3
set05_V011_I01385
num_objs 2
set00_V007_I01775
num_objs 4
set03_V005_I00425
num_objs 2
set05_V010_I00614
num_objs 1
set05_V000_I00257
num_objs 2
set01_V005_I00692
num_objs 2
set02_V010_I00887
num_objs 1
set01_V003_I00515
num_objs 3
set05_V003_I01349
num_objs 2
set04_V002_I01454
num_objs 2
set00_V014_I00056
num_objs 3
set04_V003_I00104
num_objs 0
set03_V003_I01301
num_objs 2
set01_V000_I00782
num_objs 1
set05_V003_I01700
num_objs 0
set04_V003_I00299
num_objs 0
set05_V007_I01433
num_objs 1
set02_V010_I01601
num_objs 1
set01_V003_I01259
num_objs 0
set00_V002_I00608
num_objs 0
set00_V010_I01529
num_objs 2
set04_V005_I01622
num_objs 2
set03_V003_I00437
num_objs 1
set02_V010_I00044
num_objs 0
set03_V005_I00431
num_objs 2
set00_V001_I00383
num_objs 4
set03_V002_I01415
num_objs 1
set04_V005_I01280
num_objs 1
set00_V004_I01469
num_objs 7
set05_V012_I00269
num_objs 0
set03_V003_I00608
num_objs 2
set05_V011_I01043
num_objs 8
set03_V003_I00119
num_objs 2
set01_V004_I00620
num_objs 4
set03_V009_I00443
num_objs 3
set04_V003_I01649
num_objs 1
set05_V012_I00722
num_objs 2
set03_V008_I01706
num_objs 2
set00_V013_I00269
num_objs 6
set05_V000_I01355
num_objs 1
set00_V011_I01100
num_objs 7
set00_V012_I01094
num_objs 0
set02_V009_I01157
num_objs 1
set03_V003_I00641
num_objs 2
set00_V004_I01190
num_objs 0
set02_V009_I00464
num_objs 1
set04_V005_I01592
num_objs 2
set02_V007_I00176
num_objs 1
set02_V009_I00761
num_objs 2
set00_V011_I01037
num_objs 10
set00_V003_I00485
num_objs 1
set00_V012_I00953
num_objs 6
set05_V003_I01250
num_objs 3
set00_V010_I00908
num_objs 2
set00_V012_I00506
num_objs 2
set05_V012_I00665
num_objs 1
set05_V005_I00713
num_objs 1
set00_V007_I01808
num_objs 3
set01_V003_I00218
num_objs 7
set03_V001_I00062
num_objs 1
set00_V000_I01271
num_objs 1
set00_V013_I01397
num_objs 2
set05_V000_I00647
num_objs 1
set01_V005_I01295
num_objs 1
set00_V010_I00305
num_objs 3
set03_V004_I00527
num_objs 1
set00_V009_I00038
num_objs 2
set01_V002_I01502
num_objs 0
set05_V007_I01721
num_objs 0
set01_V004_I00953
num_objs 3
set04_V004_I01250
num_objs 2
set03_V008_I01253
num_objs 2
set04_V004_I00659
num_objs 2
set01_V004_I00101
num_objs 2
set05_V002_I00497
num_objs 1
set03_V009_I00308
num_objs 3
set05_V003_I01598
num_objs 0
set00_V012_I00311
num_objs 3
set05_V004_I00266
num_objs 1
set04_V004_I01352
num_objs 1
set01_V002_I01388
num_objs 1
set04_V007_I00767
num_objs 2
set01_V004_I00947
num_objs 3
set00_V014_I00959
num_objs 1
set00_V012_I00992
num_objs 4
set03_V005_I01814
num_objs 2
set03_V009_I00335
num_objs 4
set03_V005_I01622
num_objs 1
set00_V004_I00251
num_objs 1
set04_V010_I00536
num_objs 1
set04_V000_I00482
num_objs 1
set00_V006_I00266
num_objs 3
set00_V010_I00548
num_objs 6
set00_V012_I00596
num_objs 0
set01_V004_I01124
num_objs 4
set04_V007_I00446
num_objs 1
set04_V007_I00419
num_objs 0
set00_V004_I01148
num_objs 0
set02_V009_I01301
num_objs 1
set00_V000_I01250
num_objs 1
set04_V001_I00128
num_objs 1
set00_V007_I01067
num_objs 4
set00_V014_I01364
num_objs 7
set03_V012_I00926
num_objs 1
set05_V005_I00455
num_objs 1
set02_V009_I00380
num_objs 2
set03_V012_I00839
num_objs 0
set03_V005_I01805
num_objs 2
set03_V008_I01583
num_objs 2
set00_V008_I01373
num_objs 1
set01_V001_I00950
num_objs 1
set00_V008_I00812
num_objs 2
set00_V006_I01811
num_objs 0
set04_V007_I00410
num_objs 1
set00_V000_I00179
num_objs 0
set03_V009_I00725
num_objs 2
set04_V005_I01436
num_objs 2
set01_V004_I00812
num_objs 1
set05_V011_I01559
num_objs 0
set00_V014_I01547
num_objs 5
set04_V004_I00791
num_objs 2
set01_V002_I00704
num_objs 6
set02_V009_I01229
num_objs 0
set00_V007_I01613
num_objs 6
set00_V009_I00065
num_objs 3
set01_V002_I01370
num_objs 2
set00_V012_I00938
num_objs 6
set04_V004_I00539
num_objs 0
set00_V006_I00683
num_objs 2
set02_V009_I01571
num_objs 1
set00_V011_I00068
num_objs 4
set03_V009_I01166
num_objs 2
set03_V011_I00284
num_objs 4
set03_V008_I00713
num_objs 3
set05_V001_I00158
num_objs 1
set00_V001_I00998
num_objs 12
set03_V011_I01148
num_objs 1
set00_V001_I00026
num_objs 2
set04_V000_I00971
num_objs 1
set00_V014_I00134
num_objs 2
set03_V005_I01664
num_objs 1
set05_V012_I00341
num_objs 2
set00_V010_I00173
num_objs 1
set03_V009_I01673
num_objs 3
set03_V005_I01688
num_objs 1
set05_V010_I00941
num_objs 2
set02_V011_I01637
num_objs 2
set04_V002_I00626
num_objs 1
set04_V010_I00782
num_objs 1
set00_V011_I00128
num_objs 3
set00_V000_I00404
num_objs 3
set02_V009_I00530
num_objs 1
set00_V002_I00431
num_objs 0
set02_V001_I00344
num_objs 1
set00_V008_I00425
num_objs 3
set01_V003_I00983
num_objs 1
set04_V010_I00620
num_objs 1
set02_V009_I00488
num_objs 1
set03_V009_I00953
num_objs 4
set00_V007_I01406
num_objs 5
set02_V011_I01490
num_objs 2
set02_V009_I00923
num_objs 1
set03_V009_I00509
num_objs 1
set04_V005_I01079
num_objs 1
set00_V008_I01046
num_objs 3
set01_V001_I00695
num_objs 3
set00_V002_I00278
num_objs 1
set02_V010_I00659
num_objs 0
set05_V011_I00737
num_objs 2
set03_V005_I01394
num_objs 1
set02_V009_I01805
num_objs 1
set00_V007_I00497
num_objs 4
set04_V007_I00947
num_objs 2
set03_V008_I00500
num_objs 16
set03_V010_I01772
num_objs 3
set00_V014_I00674
num_objs 3
set02_V011_I00434
num_objs 1
set00_V001_I00965
num_objs 9
set00_V013_I01199
num_objs 1
set03_V003_I00764
num_objs 2
set00_V010_I01571
num_objs 1
set02_V010_I00740
num_objs 2
set00_V006_I01625
num_objs 1
set03_V008_I01736
num_objs 1
set01_V003_I00590
num_objs 1
set01_V003_I00866
num_objs 1
set03_V004_I00602
num_objs 1
set01_V000_I01523
num_objs 4
set03_V003_I00104
num_objs 2
set01_V005_I01436
num_objs 0
set04_V010_I00947
num_objs 1
set03_V003_I01151
num_objs 2
set02_V010_I00923
num_objs 1
set00_V008_I01256
num_objs 2
set01_V000_I00653
num_objs 0
set01_V004_I01316
num_objs 1
set05_V005_I00128
num_objs 2
set00_V001_I01625
num_objs 3
set04_V003_I01283
num_objs 4
set00_V001_I00212
num_objs 3
set01_V003_I01028
num_objs 2
set00_V001_I01364
num_objs 2
set00_V004_I01133
num_objs 0
set02_V009_I00248
num_objs 2
set04_V008_I00554
num_objs 1
set00_V007_I01058
num_objs 4
set03_V008_I00809
num_objs 12
set00_V014_I01625
num_objs 4
set01_V003_I00947
num_objs 2
set04_V005_I01616
num_objs 2
set03_V005_I01271
num_objs 2
set01_V003_I01757
num_objs 1
set05_V005_I00791
num_objs 1
set01_V000_I00599
num_objs 4
set05_V012_I01085
num_objs 1
set00_V011_I00464
num_objs 6
set00_V007_I00131
num_objs 1
set01_V005_I00683
num_objs 2
set03_V003_I01043
num_objs 2
set02_V009_I00602
num_objs 2
set05_V012_I00272
num_objs 1
set04_V000_I00548
num_objs 3
set04_V010_I00506
num_objs 1
set00_V012_I00539
num_objs 2
set04_V011_I01577
num_objs 1
set04_V003_I01058
num_objs 4
set03_V009_I00656
num_objs 3
set05_V010_I00509
num_objs 0
set04_V007_I01475
num_objs 1
set01_V005_I01787
num_objs 0
set00_V014_I01265
num_objs 4
set04_V005_I00785
num_objs 1
set04_V004_I00605
num_objs 3
set03_V005_I00332
num_objs 2
set00_V013_I00707
num_objs 1
set00_V007_I00956
num_objs 3
set03_V009_I00119
num_objs 3
set00_V000_I01256
num_objs 1
set00_V000_I01184
num_objs 1
set05_V012_I00689
num_objs 1
set02_V008_I00992
num_objs 1
set01_V003_I01388
num_objs 1
set02_V010_I01223
num_objs 1
set01_V002_I01772
num_objs 4
set00_V007_I01424
num_objs 5
set05_V010_I00131
num_objs 1
set00_V000_I01040
num_objs 0
set00_V012_I00659
num_objs 1
set02_V011_I00872
num_objs 1
set02_V009_I01433
num_objs 1
set02_V009_I01052
num_objs 1
set00_V003_I00098
num_objs 1
set03_V008_I01397
num_objs 3
set03_V005_I00710
num_objs 1
set00_V007_I00842
num_objs 3
set01_V004_I01172
num_objs 2
set00_V000_I00692
num_objs 1
set00_V001_I00530
num_objs 3
set03_V003_I00356
num_objs 1
set00_V013_I00143
num_objs 4
set00_V012_I00488
num_objs 1
set00_V014_I01247
num_objs 4
set04_V007_I01148
num_objs 2
set00_V000_I01625
num_objs 1
set03_V009_I00482
num_objs 3
set04_V002_I00815
num_objs 1
set01_V002_I00917
num_objs 4
set00_V006_I01199
num_objs 1
set00_V010_I00980
num_objs 1
set05_V005_I01121
num_objs 1
set05_V004_I00998
num_objs 1
set01_V000_I00860
num_objs 0
set00_V002_I01235
num_objs 1
set03_V008_I01523
num_objs 2
set01_V002_I01487
num_objs 0
set04_V008_I01115
num_objs 1
set01_V004_I00227
num_objs 0
set01_V004_I01574
num_objs 2
set05_V005_I00197
num_objs 0
set02_V011_I00725
num_objs 1
set02_V010_I01202
num_objs 1
set05_V007_I01703
num_objs 0
set05_V011_I01154
num_objs 5
set02_V011_I00338
num_objs 3
set03_V010_I01355
num_objs 2
set01_V005_I00134
num_objs 2
set00_V006_I01556
num_objs 2
set00_V014_I00728
num_objs 3
set01_V000_I00836
num_objs 0
set01_V002_I00317
num_objs 7
set00_V011_I00551
num_objs 3
set01_V004_I00254
num_objs 2
set02_V010_I01781
num_objs 1
set05_V009_I00953
num_objs 1
set00_V000_I01094
num_objs 0
set05_V005_I00470
num_objs 1
set04_V005_I00905
num_objs 1
set00_V007_I01262
num_objs 8
set05_V011_I01055
num_objs 8
set00_V013_I01151
num_objs 4
set05_V000_I00398
num_objs 2
set00_V007_I01571
num_objs 7
set04_V004_I00392
num_objs 2
set02_V008_I00572
num_objs 1
set01_V003_I01811
num_objs 1
set01_V004_I01037
num_objs 3
set04_V005_I01127
num_objs 1
set00_V004_I00980
num_objs 3
set00_V011_I01526
num_objs 2
set05_V010_I00899
num_objs 0
set01_V005_I01193
num_objs 3
set00_V013_I01349
num_objs 4
set00_V014_I00284
num_objs 3
set01_V003_I01316
num_objs 1
set00_V014_I01580
num_objs 4
set01_V000_I00104
num_objs 1
set00_V006_I00776
num_objs 1
set01_V005_I00473
num_objs 4
set03_V005_I01484
num_objs 1
set04_V005_I01508
num_objs 2
set01_V003_I01784
num_objs 1
set05_V005_I00536
num_objs 1
set04_V007_I01631
num_objs 1
set00_V011_I00116
num_objs 4
set00_V013_I01418
num_objs 2
set01_V005_I00890
num_objs 2
set03_V004_I00119
num_objs 0
set04_V005_I01583
num_objs 2
set05_V002_I00107
num_objs 1
set01_V005_I00866
num_objs 2
set02_V007_I00359
num_objs 1
set03_V010_I00995
num_objs 3
set00_V000_I00524
num_objs 1
set01_V001_I01559
num_objs 2
set01_V000_I01214
num_objs 3
set00_V001_I00197
num_objs 2
set05_V005_I00356
num_objs 2
set00_V013_I00692
num_objs 1
set00_V004_I00392
num_objs 1
set05_V000_I01532
num_objs 1
set03_V006_I00071
num_objs 1
set00_V009_I00503
num_objs 2
set02_V010_I01010
num_objs 1
set01_V002_I00104
num_objs 6
set00_V011_I00227
num_objs 1
set03_V005_I00368
num_objs 1
set04_V007_I01157
num_objs 1
set05_V000_I01694
num_objs 1
set01_V004_I01100
num_objs 4
set00_V011_I01325
num_objs 4
set00_V003_I00488
num_objs 1
set01_V001_I00401
num_objs 4
set01_V001_I01271
num_objs 11
set00_V009_I00587
num_objs 2
set03_V010_I01367
num_objs 2
set05_V001_I00170
num_objs 1
set00_V012_I00551
num_objs 1
set03_V012_I00920
num_objs 1
set02_V010_I00932
num_objs 1
set00_V001_I00311
num_objs 6
set00_V006_I01460
num_objs 4
set00_V014_I01910
num_objs 1
set03_V001_I00812
num_objs 1
set00_V014_I00740
num_objs 2
set04_V005_I01286
num_objs 1
set05_V011_I00668
num_objs 2
set04_V004_I00995
num_objs 2
set02_V010_I01433
num_objs 1
set02_V001_I01421
num_objs 1
set05_V005_I00269
num_objs 1
set02_V010_I01742
num_objs 1
set03_V008_I00638
num_objs 6
set02_V003_I00098
num_objs 1
set03_V010_I00902
num_objs 1
set00_V012_I01151
num_objs 0
set00_V009_I00446
num_objs 2
set01_V000_I01652
num_objs 3
set02_V010_I01835
num_objs 1
set00_V011_I00218
num_objs 1
set03_V009_I00365
num_objs 4
set00_V001_I00764
num_objs 3
set02_V010_I00155
num_objs 1
set03_V009_I01082
num_objs 6
set00_V001_I01643
num_objs 2
set00_V013_I01280
num_objs 2
set00_V014_I01586
num_objs 4
set02_V009_I01115
num_objs 1
set05_V002_I01568
num_objs 1
set03_V005_I01502
num_objs 1
set02_V003_I00341
num_objs 1
set00_V001_I00353
num_objs 5
set00_V011_I00734
num_objs 2
set00_V012_I01124
num_objs 0
set00_V009_I00812
num_objs 2
set02_V008_I00494
num_objs 1
set05_V010_I00542
num_objs 1
set00_V013_I00383
num_objs 4
set04_V010_I01568
num_objs 2
set00_V008_I00917
num_objs 1
set02_V007_I00218
num_objs 1
set04_V004_I00209
num_objs 0
set05_V003_I01817
num_objs 0
set02_V010_I00434
num_objs 1
set04_V002_I00695
num_objs 3
set05_V010_I00386
num_objs 2
set02_V011_I00578
num_objs 2
set03_V006_I00095
num_objs 1
set02_V011_I01325
num_objs 1
set02_V008_I00587
num_objs 1
set05_V000_I01655
num_objs 1
set02_V007_I00188
num_objs 1
set04_V004_I00830
num_objs 2
set00_V004_I00224
num_objs 1
set00_V014_I00866
num_objs 4
set00_V014_I01442
num_objs 4
set00_V013_I00647
num_objs 3
set01_V004_I00998
num_objs 1
set03_V009_I01706
num_objs 3
set03_V009_I00923
num_objs 4
set05_V012_I01193
num_objs 1
set02_V011_I00335
num_objs 2
set03_V003_I00017
num_objs 2
set04_V004_I01379
num_objs 1
set00_V007_I00149
num_objs 0
set03_V005_I01442
num_objs 1
set03_V009_I00185
num_objs 5
set00_V001_I01781
num_objs 5
set00_V014_I00614
num_objs 4
set04_V005_I00965
num_objs 1
set01_V003_I01832
num_objs 1
set04_V007_I00785
num_objs 2
set00_V002_I00809
num_objs 5
set03_V006_I00110
num_objs 1
set00_V002_I00629
num_objs 0
set01_V003_I01370
num_objs 1
set00_V012_I00029
num_objs 0
set03_V008_I00317
num_objs 18
set05_V011_I01346
num_objs 1
set05_V004_I01025
num_objs 1
set00_V014_I01610
num_objs 4
set00_V004_I01472
num_objs 0
set04_V003_I01487
num_objs 2
set00_V007_I00110
num_objs 1
set01_V002_I00932
num_objs 4
set00_V013_I01532
num_objs 4
set00_V000_I00893
num_objs 0
set04_V007_I01697
num_objs 1
set05_V005_I00680
num_objs 1
set04_V006_I01484
num_objs 1
set01_V001_I00407
num_objs 4
set00_V001_I01079
num_objs 0
set00_V006_I01901
num_objs 0
set05_V002_I01625
num_objs 1
set04_V006_I00827
num_objs 2
set01_V000_I00446
num_objs 2
set00_V014_I00209
num_objs 4
set00_V008_I00122
num_objs 5
set01_V004_I00791
num_objs 2
set03_V008_I00446
num_objs 18
set01_V000_I00098
num_objs 3
set00_V011_I00104
num_objs 4
set01_V003_I00428
num_objs 3
set03_V009_I00461
num_objs 3
set05_V011_I00851
num_objs 7
set00_V006_I00725
num_objs 1
set01_V005_I00080
num_objs 2
set03_V004_I00071
num_objs 1
set04_V003_I00032
num_objs 0
set01_V003_I01046
num_objs 2
set04_V010_I00473
num_objs 1
set01_V004_I01352
num_objs 1
set02_V009_I00548
num_objs 2
set00_V006_I01547
num_objs 2
set00_V009_I01241
num_objs 1
set04_V006_I00563
num_objs 1
set05_V005_I00755
num_objs 1
set04_V002_I01172
num_objs 2
set04_V010_I01712
num_objs 1
set00_V013_I01658
num_objs 2
set03_V008_I01010
num_objs 1
set00_V011_I00710
num_objs 4
set01_V005_I01589
num_objs 0
set00_V007_I00119
num_objs 0
set00_V014_I01871
num_objs 1
set04_V007_I00683
num_objs 2
set05_V010_I00887
num_objs 1
set00_V010_I00257
num_objs 2
set00_V014_I00569
num_objs 7
set03_V010_I00986
num_objs 3
set04_V005_I00755
num_objs 1
set00_V010_I00068
num_objs 5
set04_V004_I01268
num_objs 1
set03_V008_I01697
num_objs 2
set00_V011_I00167
num_objs 3
set03_V012_I01586
num_objs 3
set04_V007_I00731
num_objs 2
set03_V003_I00980
num_objs 2
set00_V001_I00848
num_objs 3
set03_V008_I00476
num_objs 16
set00_V001_I00056
num_objs 0
set04_V002_I00629
num_objs 1
set02_V010_I01577
num_objs 1
set01_V005_I00281
num_objs 1
set03_V011_I00851
num_objs 2
set03_V009_I00188
num_objs 5
set00_V014_I00965
num_objs 3
set04_V007_I01316
num_objs 1
set03_V006_I01790
num_objs 1
set04_V003_I01433
num_objs 3
set00_V009_I00479
num_objs 2
set01_V001_I00173
num_objs 3
set02_V011_I01472
num_objs 2
set05_V012_I00413
num_objs 3
set01_V004_I00122
num_objs 2
set04_V002_I00893
num_objs 1
set05_V003_I01676
num_objs 0
set00_V007_I00737
num_objs 2
set04_V004_I00740
num_objs 2
set02_V009_I00095
num_objs 1
set01_V002_I00536
num_objs 8
set01_V004_I01385
num_objs 1
set03_V003_I00953
num_objs 2
set03_V009_I00194
num_objs 5
set01_V005_I00350
num_objs 3
set03_V006_I00083
num_objs 1
set03_V003_I01466
num_objs 2
set04_V000_I00611
num_objs 3
set02_V007_I00158
num_objs 1
set00_V006_I00443
num_objs 4
set00_V008_I01313
num_objs 0
set00_V007_I00515
num_objs 4
set05_V003_I00998
num_objs 1
set03_V005_I00809
num_objs 1
set04_V007_I00395
num_objs 1
set03_V009_I01169
num_objs 2
set04_V010_I00668
num_objs 1
set03_V003_I01436
num_objs 2
set05_V002_I00665
num_objs 1
set04_V002_I01706
num_objs 2
set02_V011_I01634
num_objs 2
set00_V007_I01298
num_objs 9
set03_V008_I01313
num_objs 3
set00_V008_I00029
num_objs 5
set05_V005_I00872
num_objs 2
set04_V007_I01256
num_objs 1
set04_V004_I01328
num_objs 1
set03_V008_I01073
num_objs 1
set03_V008_I01565
num_objs 1
set01_V000_I00578
num_objs 1
set01_V001_I01487
num_objs 10
set03_V011_I00266
num_objs 4
set03_V008_I00098
num_objs 7
set02_V010_I00488
num_objs 1
set03_V011_I00461
num_objs 5
set00_V012_I00902
num_objs 6
set03_V003_I00035
num_objs 2
set03_V005_I00473
num_objs 2
set02_V009_I01814
num_objs 1
set02_V010_I00794
num_objs 2
set02_V009_I00764
num_objs 2
set05_V004_I00434
num_objs 2
set00_V007_I01277
num_objs 8
set04_V005_I00035
num_objs 1
set00_V014_I01559
num_objs 2
set04_V005_I01544
num_objs 2
set03_V011_I00857
num_objs 2
set00_V012_I00188
num_objs 1
set04_V011_I01811
num_objs 1
set01_V005_I00047
num_objs 2
set03_V005_I00749
num_objs 0
set04_V011_I01655
num_objs 1
set05_V012_I00458
num_objs 3
set00_V009_I01691
num_objs 0
set00_V001_I00617
num_objs 2
set03_V009_I01583
num_objs 2
set05_V010_I00029
num_objs 1
set03_V010_I00968
num_objs 3
set01_V003_I01574
num_objs 1
set05_V012_I00371
num_objs 3
set02_V011_I01439
num_objs 0
set00_V003_I00113
num_objs 2
set02_V009_I00914
num_objs 1
set00_V009_I00134
num_objs 2
set05_V000_I01550
num_objs 1
set02_V009_I00755
num_objs 2
set00_V000_I01694
num_objs 2
set04_V007_I00986
num_objs 2
set03_V003_I00170
num_objs 2
set03_V012_I01361
num_objs 4
set04_V005_I00866
num_objs 1
set00_V006_I00728
num_objs 1
set00_V005_I00794
num_objs 1
set00_V013_I00725
num_objs 1
set00_V013_I00446
num_objs 2
set04_V003_I00920
num_objs 1
set04_V010_I00503
num_objs 1
set00_V009_I01403
num_objs 1
set01_V004_I01610
num_objs 1
set01_V003_I00020
num_objs 4
set01_V004_I01217
num_objs 0
set00_V006_I01001
num_objs 3
set04_V003_I01778
num_objs 2
set05_V003_I01718
num_objs 0
set02_V009_I00362
num_objs 2
set02_V010_I00245
num_objs 1
set00_V011_I00944
num_objs 7
set01_V005_I01667
num_objs 0
set05_V002_I01517
num_objs 1
set05_V005_I00548
num_objs 1
set01_V001_I00572
num_objs 4
set04_V002_I00836
num_objs 1
set05_V011_I01004
num_objs 8
set04_V004_I01661
num_objs 3
set04_V004_I00179
num_objs 0
set01_V004_I01499
num_objs 2
set00_V007_I01868
num_objs 7
set04_V002_I00899
num_objs 1
set05_V010_I00428
num_objs 1
set00_V004_I01241
num_objs 0
set04_V004_I00509
num_objs 0
set02_V011_I00521
num_objs 2
set04_V003_I00995
num_objs 4
set03_V008_I00797
num_objs 2
set00_V001_I00281
num_objs 5
set05_V012_I00533
num_objs 1
set00_V009_I00962
num_objs 4
set01_V002_I00599
num_objs 5
set04_V003_I00482
num_objs 0
set03_V010_I01775
num_objs 3
set04_V006_I01529
num_objs 1
set04_V007_I01424
num_objs 1
set02_V010_I00845
num_objs 2
set04_V005_I00086
num_objs 1
set04_V007_I00704
num_objs 2
set05_V010_I00893
num_objs 2
set00_V008_I00434
num_objs 8
set01_V001_I00668
num_objs 3
set04_V005_I00131
num_objs 1
set03_V012_I00014
num_objs 1
set01_V004_I01022
num_objs 3
set02_V008_I01226
num_objs 1
set00_V012_I00875
num_objs 5
set05_V009_I00926
num_objs 1
set01_V000_I01079
num_objs 1
set00_V007_I01610
num_objs 6
set00_V009_I00926
num_objs 3
set05_V010_I00119
num_objs 1
set05_V003_I01790
num_objs 0
set00_V013_I01382
num_objs 3
set02_V007_I00374
num_objs 1
set00_V009_I00710
num_objs 4
set04_V003_I00176
num_objs 0
set03_V010_I01403
num_objs 2
set00_V012_I01085
num_objs 0
set04_V008_I01523
num_objs 1
set03_V009_I00734
num_objs 2
set05_V005_I00344
num_objs 2
set02_V010_I01013
num_objs 1
set03_V006_I00167
num_objs 1
set00_V013_I00413
num_objs 3
set03_V005_I01253
num_objs 2
set02_V007_I00389
num_objs 0
set05_V002_I00575
num_objs 1
set02_V009_I01553
num_objs 1
set04_V003_I00461
num_objs 0
set01_V003_I00653
num_objs 2
set05_V007_I01784
num_objs 0
set01_V003_I00449
num_objs 2
set03_V008_I01589
num_objs 3
set02_V011_I01292
num_objs 1
set01_V001_I01259
num_objs 2
set00_V011_I00689
num_objs 1
set02_V010_I01571
num_objs 1
set01_V001_I00599
num_objs 2
set04_V001_I01607
num_objs 2
set00_V004_I01019
num_objs 1
set05_V007_I01655
num_objs 0
set03_V005_I01322
num_objs 1
set02_V010_I01322
num_objs 1
set00_V011_I00704
num_objs 4
set00_V014_I01292
num_objs 5
set01_V000_I00110
num_objs 1
set00_V000_I00467
num_objs 2
set01_V002_I00386
num_objs 5
set05_V009_I00992
num_objs 1
set05_V001_I00152
num_objs 1
set04_V007_I01214
num_objs 1
set03_V003_I01328
num_objs 2
set02_V009_I00476
num_objs 1
set00_V009_I00308
num_objs 6
set00_V006_I00944
num_objs 1
set05_V004_I00422
num_objs 2
set05_V001_I00401
num_objs 0
set00_V002_I00419
num_objs 0
set00_V011_I01418
num_objs 2
set04_V003_I00218
num_objs 0
set05_V005_I01028
num_objs 1
set02_V010_I01451
num_objs 1
set05_V011_I00794
num_objs 5
set00_V001_I01598
num_objs 3
set00_V004_I01439
num_objs 13
set02_V003_I00743
num_objs 1
set04_V007_I00380
num_objs 1
set04_V010_I00731
num_objs 1
set05_V009_I00773
num_objs 1
set00_V006_I00800
num_objs 2
set00_V007_I01496
num_objs 4
set03_V005_I00599
num_objs 2
set03_V005_I01406
num_objs 1
set05_V003_I01784
num_objs 0
set00_V011_I00161
num_objs 2
set04_V007_I01676
num_objs 1
set03_V003_I00602
num_objs 2
set05_V000_I01559
num_objs 0
set05_V003_I01631
num_objs 0
set04_V004_I00527
num_objs 3
set00_V014_I00425
num_objs 6
set00_V009_I01262
num_objs 1
set00_V001_I00839
num_objs 1
set00_V007_I01082
num_objs 6
set00_V012_I01223
num_objs 0
set00_V013_I01277
num_objs 2
set01_V001_I00005
num_objs 1
set03_V010_I01364
num_objs 2
set00_V001_I00785
num_objs 3
set00_V010_I00863
num_objs 3
set00_V000_I01751
num_objs 1
set01_V002_I01091
num_objs 3
set02_V001_I00104
num_objs 0
set00_V010_I00140
num_objs 4
set04_V010_I01574
num_objs 2
set04_V005_I00884
num_objs 1
set00_V004_I01172
num_objs 0
set01_V004_I00533
num_objs 1
set05_V010_I01016
num_objs 1
set04_V007_I00638
num_objs 2
set02_V001_I01568
num_objs 2
set03_V006_I00059
num_objs 0
set03_V011_I01331
num_objs 1
set03_V009_I01829
num_objs 0
set00_V012_I01244
num_objs 0
set05_V011_I00005
num_objs 1
set04_V011_I01565
num_objs 1
set00_V012_I00251
num_objs 3
set00_V010_I00365
num_objs 6
set02_V009_I00626
num_objs 2
set00_V012_I01409
num_objs 3
set00_V014_I00212
num_objs 2
set01_V003_I01319
num_objs 0
set01_V003_I00674
num_objs 2
set01_V005_I01112
num_objs 4
set00_V006_I01520
num_objs 2
set00_V009_I00524
num_objs 2
set05_V010_I01616
num_objs 1
set03_V005_I00776
num_objs 1
set03_V005_I00659
num_objs 0
set01_V004_I00782
num_objs 2
set01_V004_I01619
num_objs 0
set00_V013_I01649
num_objs 1
set04_V001_I01544
num_objs 2
set00_V013_I00938
num_objs 1
set00_V008_I01514
num_objs 2
set03_V003_I01037
num_objs 2
set00_V002_I00923
num_objs 2
set05_V000_I00575
num_objs 2
set01_V000_I01277
num_objs 3
set00_V008_I00860
num_objs 1
set04_V010_I00377
num_objs 1
set04_V011_I01733
num_objs 1
set00_V013_I01550
num_objs 4
set03_V008_I00764
num_objs 3
set05_V011_I01655
num_objs 1
set01_V003_I01544
num_objs 1
set00_V007_I01841
num_objs 5
set04_V003_I01124
num_objs 3
set00_V012_I01613
num_objs 1
set03_V002_I01469
num_objs 0
set00_V010_I00302
num_objs 3
set00_V002_I00248
num_objs 2
set01_V000_I00314
num_objs 1
set03_V002_I01538
num_objs 1
set00_V007_I01802
num_objs 3
set04_V004_I00854
num_objs 2
set00_V012_I00428
num_objs 0
set02_V009_I01511
num_objs 1
set00_V004_I00845
num_objs 1
set02_V010_I00971
num_objs 1
set02_V009_I01439
num_objs 0
set03_V005_I00944
num_objs 1
set03_V003_I00542
num_objs 2
set04_V010_I01562
num_objs 2
set00_V010_I00026
num_objs 4
set05_V012_I01247
num_objs 1
set04_V006_I00857
num_objs 2
set03_V003_I00332
num_objs 1
set05_V012_I00350
num_objs 3
set04_V008_I00989
num_objs 0
set01_V003_I00902
num_objs 2
set04_V000_I00746
num_objs 3
set04_V003_I01295
num_objs 4
set00_V014_I00185
num_objs 1
set00_V000_I00698
num_objs 1
set02_V007_I00197
num_objs 1
set01_V003_I00341
num_objs 3
set00_V004_I01493
num_objs 0
set00_V014_I00656
num_objs 3
set00_V001_I00200
num_objs 2
set03_V005_I01631
num_objs 1
set03_V009_I01025
num_objs 3
set00_V014_I01136
num_objs 3
set03_V004_I00161
num_objs 1
set00_V008_I00488
num_objs 5
set00_V009_I01439
num_objs 0
set02_V008_I01244
num_objs 1
set05_V000_I00404
num_objs 2
set03_V010_I00197
num_objs 1
set00_V014_I00554
num_objs 5
set03_V001_I00158
num_objs 1
set01_V004_I01463
num_objs 1
set04_V000_I00557
num_objs 3
set01_V002_I00731
num_objs 6
set01_V000_I01352
num_objs 4
set05_V002_I01574
num_objs 1
set00_V000_I00758
num_objs 2
set00_V007_I01229
num_objs 2
set00_V013_I01475
num_objs 4
set02_V008_I00881
num_objs 2
set05_V002_I00467
num_objs 1
set01_V003_I00920
num_objs 2
set00_V007_I01637
num_objs 5
set05_V005_I00104
num_objs 3
set04_V011_I01772
num_objs 1
set01_V000_I00416
num_objs 2
set05_V010_I00863
num_objs 1
set00_V013_I01082
num_objs 2
set02_V011_I01661
num_objs 2
set04_V001_I01781
num_objs 1
set00_V004_I00146
num_objs 1
set05_V003_I01730
num_objs 0
set03_V008_I00383
num_objs 19
set01_V000_I01109
num_objs 1
set01_V002_I01061
num_objs 2
set03_V003_I01145
num_objs 2
set02_V008_I00515
num_objs 1
set00_V014_I01190
num_objs 4
set00_V007_I01721
num_objs 4
set03_V005_I01745
num_objs 2
set02_V009_I01448
num_objs 1
set05_V005_I01034
num_objs 1
set03_V003_I00956
num_objs 2
set00_V014_I00770
num_objs 4
set01_V005_I01772
num_objs 0
set00_V002_I00626
num_objs 0
set02_V008_I00866
num_objs 2
set05_V012_I00383
num_objs 3
set03_V005_I01337
num_objs 1
set03_V005_I00716
num_objs 1
set01_V005_I00197
num_objs 2
set05_V011_I01082
num_objs 6
set05_V010_I00155
num_objs 1
set02_V003_I00014
num_objs 0
set00_V011_I01205
num_objs 3
set05_V001_I00350
num_objs 0
set03_V009_I00488
num_objs 3
set01_V000_I01133
num_objs 4
set03_V008_I01655
num_objs 2
set01_V005_I00425
num_objs 4
set05_V010_I00677
num_objs 1
set04_V004_I01370
num_objs 1
set01_V005_I00608
num_objs 3
set00_V009_I00626
num_objs 2
set01_V001_I01532
num_objs 10
set05_V002_I01109
num_objs 1
set00_V001_I00128
num_objs 2
set03_V011_I00329
num_objs 5
set04_V010_I00395
num_objs 1
set00_V012_I00218
num_objs 2
set02_V008_I00500
num_objs 1
set05_V004_I00134
num_objs 3
set02_V007_I00320
num_objs 1
set05_V002_I01142
num_objs 2
set04_V006_I00512
num_objs 1
set04_V007_I00251
num_objs 2
set01_V002_I00884
num_objs 6
set04_V002_I00590
num_objs 1
set01_V003_I00125
num_objs 8
set03_V004_I00065
num_objs 1
set04_V000_I00821
num_objs 1
set01_V000_I01055
num_objs 1
set05_V010_I00083
num_objs 1
set04_V004_I00338
num_objs 0
set00_V011_I00875
num_objs 0
set03_V012_I01553
num_objs 3
set00_V008_I00515
num_objs 5
set00_V006_I00098
num_objs 2
set00_V000_I00923
num_objs 0
set02_V011_I00605
num_objs 2
set02_V010_I01193
num_objs 1
set00_V006_I00209
num_objs 1
set00_V007_I01403
num_objs 5
set00_V008_I01001
num_objs 1
set00_V009_I01061
num_objs 1
set04_V010_I00818
num_objs 1
set01_V001_I00653
num_objs 3
set00_V001_I00914
num_objs 5
set00_V004_I01412
num_objs 2
set00_V009_I00776
num_objs 2
set05_V012_I00449
num_objs 2
set03_V008_I00977
num_objs 1
set03_V011_I01397
num_objs 1
set04_V002_I01406
num_objs 3
set00_V014_I00704
num_objs 3
set01_V003_I00035
num_objs 4
set03_V012_I01208
num_objs 1
set04_V002_I01343
num_objs 2
set00_V007_I01562
num_objs 7
set04_V004_I01691
num_objs 2
set00_V014_I00773
num_objs 4
set00_V000_I01487
num_objs 1
set01_V002_I00815
num_objs 7
set05_V010_I00944
num_objs 2
set00_V006_I01835
num_objs 0
set00_V008_I00101
num_objs 7
set05_V004_I00953
num_objs 1
set05_V005_I00062
num_objs 4
set01_V001_I00137
num_objs 4
set00_V008_I00845
num_objs 1
set03_V002_I01490
num_objs 1
set00_V008_I00224
num_objs 0
set03_V009_I00155
num_objs 5
set00_V009_I00047
num_objs 3
set03_V011_I00878
num_objs 2
set01_V003_I00140
num_objs 8
set05_V011_I01580
num_objs 1
set00_V006_I01616
num_objs 2
set00_V007_I00539
num_objs 2
set01_V005_I01007
num_objs 3
set00_V012_I00236
num_objs 2
set00_V011_I01046
num_objs 10
set05_V009_I00830
num_objs 1
set03_V009_I01823
num_objs 4
set01_V004_I00767
num_objs 2
set03_V008_I01622
num_objs 2
set03_V005_I00374
num_objs 1
set00_V009_I01406
num_objs 1
set03_V008_I00995
num_objs 1
set00_V008_I00467
num_objs 8
set01_V004_I00188
num_objs 1
set04_V005_I00269
num_objs 1
set00_V006_I01247
num_objs 7
set00_V001_I00725
num_objs 3
set00_V011_I00281
num_objs 2
set05_V002_I01136
num_objs 2
set04_V004_I00107
num_objs 1
set02_V009_I01436
num_objs 1
set04_V000_I00602
num_objs 3
set03_V005_I01190
num_objs 3
set03_V010_I01538
num_objs 3
set05_V005_I00644
num_objs 1
set05_V005_I00389
num_objs 0
set04_V005_I01526
num_objs 2
set05_V002_I01130
num_objs 2
set03_V006_I01781
num_objs 1
set03_V011_I01226
num_objs 1
set03_V011_I00986
num_objs 1
set04_V001_I00026
num_objs 1
set00_V012_I00107
num_objs 0
set01_V002_I00014
num_objs 3
set05_V007_I01682
num_objs 0
set03_V004_I00140
num_objs 1
set05_V003_I01304
num_objs 2
set03_V008_I01496
num_objs 2
set03_V005_I01187
num_objs 3
set05_V001_I00449
num_objs 0
set03_V008_I00395
num_objs 19
set01_V000_I01430
num_objs 4
set00_V014_I01700
num_objs 3
set00_V014_I00884
num_objs 5
set00_V010_I00812
num_objs 4
set00_V004_I01460
num_objs 1
set04_V000_I00740
num_objs 3
set00_V002_I00506
num_objs 0
set01_V005_I01172
num_objs 3
set00_V000_I00803
num_objs 0
set01_V003_I00380
num_objs 3
set00_V009_I00332
num_objs 5
set04_V011_I01016
num_objs 2
set04_V001_I00170
num_objs 1
set04_V008_I01376
num_objs 1
set00_V004_I01256
num_objs 0
set00_V014_I01346
num_objs 6
set04_V004_I00434
num_objs 2
set03_V008_I01037
num_objs 1
set00_V006_I01163
num_objs 5
set00_V011_I00530
num_objs 4
set04_V003_I01442
num_objs 4
set01_V001_I00431
num_objs 3
set03_V009_I00620
num_objs 4
set03_V005_I00674
num_objs 1
set01_V004_I00770
num_objs 2
set04_V002_I00797
num_objs 1
set04_V008_I01469
num_objs 1
set00_V001_I01688
num_objs 2
set02_V003_I00116
num_objs 1
set03_V011_I01223
num_objs 1
set00_V006_I01088
num_objs 10
set01_V000_I01220
num_objs 3
set03_V011_I00554
num_objs 5
set01_V004_I00158
num_objs 1
set00_V009_I00014
num_objs 1
set04_V005_I00191
num_objs 1
set00_V001_I00704
num_objs 3
set00_V012_I00326
num_objs 1
set00_V006_I00458
num_objs 5
set01_V000_I00335
num_objs 1
set00_V006_I01274
num_objs 6
set01_V002_I01265
num_objs 4
set01_V003_I00677
num_objs 2
set00_V010_I00425
num_objs 8
set00_V001_I00611
num_objs 1
set00_V012_I00689
num_objs 0
set01_V002_I00344
num_objs 7
set00_V006_I01928
num_objs 0
set04_V000_I00716
num_objs 3
set02_V011_I00497
num_objs 2
set00_V007_I01091
num_objs 6
set03_V011_I00575
num_objs 4
set05_V011_I01169
num_objs 1
set03_V012_I01355
num_objs 4
set00_V001_I01814
num_objs 3
set00_V007_I01835
num_objs 5
set04_V008_I01499
num_objs 1
set05_V000_I00308
num_objs 4
set05_V004_I00884
num_objs 0
set00_V000_I01640
num_objs 1
set04_V002_I00095
num_objs 1
set03_V009_I00668
num_objs 3
set00_V009_I00143
num_objs 1
set00_V010_I00923
num_objs 1
set00_V010_I00509
num_objs 3
set00_V011_I00827
num_objs 0
set00_V009_I01610
num_objs 3
set04_V007_I00476
num_objs 1
set03_V001_I00176
num_objs 1
set01_V002_I00086
num_objs 4
set03_V009_I00083
num_objs 5
set03_V001_I00074
num_objs 1
set00_V007_I01499
num_objs 1
set03_V009_I01145
num_objs 2
set00_V009_I01442
num_objs 2
set05_V010_I01070
num_objs 1
set04_V006_I01640
num_objs 2
set03_V005_I00695
num_objs 1
set04_V002_I00050
num_objs 1
set01_V005_I01187
num_objs 3
set02_V010_I01499
num_objs 1
set01_V005_I00554
num_objs 2
set02_V010_I01505
num_objs 2
set04_V003_I00419
num_objs 0
set03_V009_I01763
num_objs 4
set02_V011_I00590
num_objs 2
set03_V003_I01403
num_objs 2
set00_V012_I01250
num_objs 0
set00_V004_I01352
num_objs 1
set01_V000_I01424
num_objs 4
set05_V011_I00878
num_objs 9
set03_V008_I00071
num_objs 7
set01_V002_I00863
num_objs 9
set05_V005_I00176
num_objs 0
set04_V002_I00710
num_objs 3
set01_V002_I00116
num_objs 5
set00_V000_I01019
num_objs 0
set03_V009_I01361
num_objs 1
set00_V010_I00521
num_objs 4
set04_V005_I00125
num_objs 1
set02_V010_I01298
num_objs 1
set01_V004_I01139
num_objs 3
set03_V008_I01142
num_objs 1
set01_V002_I01157
num_objs 1
set00_V010_I01589
num_objs 2
set00_V002_I01259
num_objs 0
set05_V011_I00692
num_objs 2
set03_V004_I00080
num_objs 1
set05_V003_I00983
num_objs 1
set04_V003_I00569
num_objs 1
set00_V006_I01469
num_objs 0
set04_V000_I00848
num_objs 1
set00_V006_I00965
num_objs 1
set01_V000_I00788
num_objs 1
set02_V009_I01457
num_objs 1
set01_V000_I01628
num_objs 3
set00_V014_I00467
num_objs 4
set05_V005_I01229
num_objs 0
set03_V008_I00425
num_objs 19
set04_V007_I01532
num_objs 1
set00_V006_I01415
num_objs 4
set00_V013_I01106
num_objs 4
set04_V005_I01043
num_objs 3
set00_V009_I00758
num_objs 3
set00_V008_I01457
num_objs 2
set00_V002_I00701
num_objs 1
set03_V009_I00344
num_objs 4
set04_V007_I00998
num_objs 2
set02_V011_I00677
num_objs 2
set00_V006_I01559
num_objs 2
set05_V009_I00938
num_objs 1
set03_V009_I01337
num_objs 0
set05_V010_I01082
num_objs 1
set05_V004_I00215
num_objs 3
set02_V009_I01583
num_objs 1
set03_V003_I00803
num_objs 2
set05_V005_I00071
num_objs 4
set00_V013_I00464
num_objs 2
set02_V010_I01175
num_objs 1
set05_V008_I01805
num_objs 1
set04_V007_I01247
num_objs 1
set00_V001_I00521
num_objs 3
set00_V012_I00095
num_objs 0
set02_V011_I00500
num_objs 2
set00_V008_I00233
num_objs 0
set04_V003_I00080
num_objs 0
set00_V003_I00179
num_objs 0
set03_V009_I00266
num_objs 3
set00_V006_I01886
num_objs 0
set01_V001_I01667
num_objs 2
set00_V010_I00530
num_objs 4
set03_V003_I01226
num_objs 2
set01_V001_I01640
num_objs 4
set01_V001_I01448
num_objs 14
set05_V005_I00938
num_objs 1
set00_V002_I00323
num_objs 1
set00_V013_I01205
num_objs 1
set04_V004_I00863
num_objs 2
set04_V002_I00845
num_objs 1
set05_V000_I00659
num_objs 0
set01_V001_I00602
num_objs 3
set00_V011_I00353
num_objs 3
set00_V014_I01676
num_objs 4
set02_V009_I01661
num_objs 1
set03_V010_I00137
num_objs 2
set00_V011_I01142
num_objs 5
set05_V005_I00899
num_objs 0
set01_V005_I01745
num_objs 0
set04_V004_I00485
num_objs 3
set05_V012_I00548
num_objs 1
set03_V008_I00332
num_objs 18
set00_V008_I01427
num_objs 1
set02_V003_I00218
num_objs 1
set04_V004_I00395
num_objs 2
set00_V008_I00551
num_objs 6
set04_V002_I00092
num_objs 1
set00_V007_I01331
num_objs 7
set00_V001_I00512
num_objs 3
set01_V005_I01022
num_objs 3
set04_V004_I00692
num_objs 2
set04_V001_I01682
num_objs 2
set04_V002_I01673
num_objs 2
set05_V004_I01004
num_objs 1
set03_V010_I00176
num_objs 1
set02_V003_I00062
num_objs 1
set01_V004_I00551
num_objs 1
set03_V005_I00311
num_objs 2
set00_V007_I01913
num_objs 3
set00_V006_I01610
num_objs 2
set05_V011_I00614
num_objs 4
set00_V003_I00470
num_objs 1
set04_V007_I00545
num_objs 1
set00_V013_I00461
num_objs 2
set02_V011_I01466
num_objs 2
set04_V007_I01355
num_objs 1
set00_V014_I00068
num_objs 4
set04_V002_I01079
num_objs 1
set03_V010_I01052
num_objs 2
set03_V004_I00149
num_objs 0
set00_V012_I01358
num_objs 0
set00_V012_I00374
num_objs 0
set05_V005_I00524
num_objs 1
set00_V008_I00902
num_objs 1
set04_V005_I00302
num_objs 1
set00_V000_I00842
num_objs 0
set04_V007_I01352
num_objs 1
set04_V003_I00257
num_objs 1
set04_V002_I01577
num_objs 2
set02_V009_I00632
num_objs 2
set05_V000_I00773
num_objs 1
set04_V005_I01691
num_objs 0
set04_V011_I01589
num_objs 1
set02_V010_I00065
num_objs 1
set01_V001_I00710
num_objs 2
set02_V009_I00260
num_objs 2
set02_V008_I00566
num_objs 1
set00_V011_I01541
num_objs 0
set03_V009_I01808
num_objs 4
set03_V008_I01352
num_objs 3
set02_V010_I00725
num_objs 2
set05_V005_I00848
num_objs 2
set00_V001_I01010
num_objs 12
set00_V009_I01592
num_objs 4
set02_V009_I01313
num_objs 1
set03_V004_I00143
num_objs 1
set03_V011_I00908
num_objs 1
set00_V007_I01544
num_objs 4
set01_V000_I00404
num_objs 2
set01_V004_I00128
num_objs 2
set04_V005_I00053
num_objs 1
set00_V008_I00602
num_objs 4
set04_V000_I00605
num_objs 3
set05_V002_I01466
num_objs 1
set00_V000_I00122
num_objs 1
set03_V011_I00848
num_objs 2
set05_V012_I00740
num_objs 2
set01_V001_I01124
num_objs 1
set05_V011_I01610
num_objs 1
set01_V004_I01613
num_objs 1
set03_V003_I01070
num_objs 2
set00_V004_I00266
num_objs 1
set03_V008_I01430
num_objs 3
set02_V011_I00602
num_objs 2
set00_V007_I00104
num_objs 1
set03_V008_I01013
num_objs 1
set03_V005_I00872
num_objs 1
set04_V011_I01799
num_objs 1
set03_V003_I00413
num_objs 1
set05_V001_I00392
num_objs 0
set03_V003_I00968
num_objs 2
set00_V011_I00299
num_objs 1
set04_V004_I00407
num_objs 2
set00_V013_I01613
num_objs 1
set03_V005_I01808
num_objs 2
set02_V003_I00731
num_objs 2
set04_V002_I01046
num_objs 2
set00_V010_I00824
num_objs 3
set04_V007_I01175
num_objs 1
set03_V001_I00071
num_objs 1
set01_V001_I00791
num_objs 2
set05_V004_I00950
num_objs 1
set01_V000_I00764
num_objs 1
set04_V000_I00767
num_objs 2
set05_V012_I00389
num_objs 2
set00_V008_I01406
num_objs 1
set00_V007_I00674
num_objs 2
set00_V014_I01418
num_objs 4
set05_V009_I00923
num_objs 1
set02_V010_I00392
num_objs 1
set04_V003_I00089
num_objs 0
set05_V012_I00338
num_objs 1
set01_V004_I01553
num_objs 1
set01_V003_I01073
num_objs 1
set05_V000_I00449
num_objs 1
set05_V007_I01166
num_objs 1
set02_V010_I01388
num_objs 1
set01_V000_I00125
num_objs 1
set02_V011_I00446
num_objs 1
set03_V005_I01439
num_objs 0
set03_V009_I00059
num_objs 1
set00_V009_I00836
num_objs 3
set00_V010_I01268
num_objs 3
set00_V011_I01052
num_objs 9
set05_V010_I01640
num_objs 1
set01_V004_I00824
num_objs 3
set00_V000_I01697
num_objs 2
set00_V014_I01496
num_objs 5
set01_V005_I01184
num_objs 3
set03_V008_I00482
num_objs 16
set00_V013_I01556
num_objs 4
set03_V006_I01835
num_objs 1
set05_V011_I00743
num_objs 2
set05_V011_I00536
num_objs 1
set01_V004_I00722
num_objs 2
set03_V008_I00086
num_objs 7
set03_V003_I00911
num_objs 2
set04_V004_I00653
num_objs 2
set02_V011_I01766
num_objs 2
set05_V007_I01745
num_objs 0
set01_V002_I01364
num_objs 2
set00_V000_I01841
num_objs 1
set00_V007_I00656
num_objs 2
set00_V011_I00146
num_objs 2
set00_V009_I00662
num_objs 2
set00_V011_I00932
num_objs 4
set03_V005_I00320
num_objs 2
set01_V003_I01340
num_objs 1
set03_V003_I01340
num_objs 2
set03_V003_I00728
num_objs 2
set01_V002_I00218
num_objs 7
set03_V009_I00647
num_objs 3
set00_V006_I01733
num_objs 0
set02_V008_I00884
num_objs 2
set00_V006_I01337
num_objs 4
set03_V012_I01298
num_objs 2
set05_V005_I00509
num_objs 0
set03_V007_I00305
num_objs 1
set04_V010_I01559
num_objs 1
set04_V000_I00833
num_objs 1
set04_V007_I00443
num_objs 1
set05_V005_I00164
num_objs 0
set00_V006_I01313
num_objs 4
set05_V011_I01670
num_objs 1
set00_V007_I01217
num_objs 8
set01_V005_I01808
num_objs 0
set04_V010_I00704
num_objs 1
set01_V001_I01691
num_objs 2
set03_V008_I00197
num_objs 11
set02_V007_I00968
num_objs 1
set05_V005_I00329
num_objs 0
set01_V000_I01661
num_objs 3
set03_V004_I00440
num_objs 1
set00_V009_I01070
num_objs 1
set01_V002_I01391
num_objs 1
set00_V001_I00947
num_objs 8
set00_V010_I00002
num_objs 5
set00_V009_I00383
num_objs 1
set04_V001_I01562
num_objs 2
set00_V009_I00854
num_objs 2
set00_V013_I01055
num_objs 2
set01_V005_I00269
num_objs 1
set02_V010_I00050
num_objs 0
set00_V010_I01658
num_objs 1
set02_V011_I01538
num_objs 2
set00_V014_I01256
num_objs 4
set04_V005_I00737
num_objs 1
set00_V014_I01550
num_objs 6
set02_V010_I01328
num_objs 1
set05_V000_I00242
num_objs 2
set01_V004_I01034
num_objs 3
set04_V010_I00977
num_objs 1
set03_V008_I01550
num_objs 1
set04_V004_I01034
num_objs 2
set02_V001_I01457
num_objs 1
set03_V010_I01568
num_objs 3
set01_V001_I00473
num_objs 4
set00_V010_I00392
num_objs 6
set05_V005_I00257
num_objs 1
set02_V008_I00545
num_objs 1
set01_V000_I00773
num_objs 1
set00_V006_I00794
num_objs 2
set01_V001_I01595
num_objs 5
set00_V007_I01400
num_objs 5
set00_V011_I00626
num_objs 3
set03_V010_I01373
num_objs 2
set02_V011_I01562
num_objs 2
set04_V007_I01673
num_objs 1
set02_V009_I00146
num_objs 1
set03_V005_I01703
num_objs 1
set01_V002_I00776
num_objs 7
set00_V014_I00962
num_objs 3
set00_V004_I01667
num_objs 1
set05_V005_I00068
num_objs 4
set03_V009_I00371
num_objs 4
set00_V008_I00182
num_objs 2
set00_V008_I00635
num_objs 4
set02_V003_I00035
num_objs 1
set03_V011_I00707
num_objs 1
set03_V005_I01073
num_objs 1
set00_V000_I01163
num_objs 0
set02_V008_I00560
num_objs 1
set05_V010_I00122
num_objs 1
set02_V008_I00872
num_objs 2
set01_V005_I00161
num_objs 2
set03_V011_I01253
num_objs 1
set01_V005_I01691
num_objs 0
set00_V004_I00986
num_objs 3
set01_V002_I00800
num_objs 7
set00_V008_I01208
num_objs 1
set02_V009_I00851
num_objs 1
set05_V004_I01055
num_objs 1
set01_V003_I00839
num_objs 7
set05_V012_I00752
num_objs 1
set04_V007_I00533
num_objs 1
set00_V010_I00263
num_objs 3
set05_V011_I01322
num_objs 2
set03_V008_I00191
num_objs 12
set04_V010_I00497
num_objs 1
set00_V002_I01262
num_objs 0
set04_V007_I01211
num_objs 1
set04_V001_I01505
num_objs 1
set00_V007_I00446
num_objs 5
set01_V004_I00005
num_objs 2
set02_V008_I01130
num_objs 0
set03_V007_I00338
num_objs 1
set01_V002_I00770
num_objs 9
set02_V007_I00407
num_objs 1
set00_V008_I01379
num_objs 0
set03_V003_I00155
num_objs 2
set00_V014_I00389
num_objs 3
set04_V002_I01373
num_objs 3
set00_V009_I00527
num_objs 2
set04_V008_I01091
num_objs 1
set03_V005_I00932
num_objs 1
set03_V003_I00743
num_objs 2
set00_V009_I01652
num_objs 2
set00_V001_I00362
num_objs 5
set00_V001_I00149
num_objs 0
set02_V010_I01376
num_objs 1
set05_V005_I01073
num_objs 1
set01_V002_I01418
num_objs 0
set00_V006_I01211
num_objs 5
set00_V006_I00662
num_objs 2
set00_V008_I00842
num_objs 1
set01_V003_I01061
num_objs 1
set01_V004_I01442
num_objs 1
set00_V010_I00008
num_objs 5
set04_V005_I01124
num_objs 1
set00_V011_I00548
num_objs 3
set02_V003_I00056
num_objs 1
set04_V007_I00278
num_objs 2
set04_V008_I00551
num_objs 1
set03_V012_I00947
num_objs 1
set00_V001_I01604
num_objs 3
set05_V010_I00410
num_objs 1
set04_V002_I00698
num_objs 3
set05_V010_I00872
num_objs 1
set00_V008_I00200
num_objs 1
set04_V001_I01502
num_objs 1
set00_V011_I01586
num_objs 0
set03_V008_I00593
num_objs 9
set03_V009_I00431
num_objs 3
set04_V001_I01580
num_objs 2
set01_V002_I00488
num_objs 5
set01_V002_I01019
num_objs 0
set01_V005_I01577
num_objs 0
set04_V004_I00176
num_objs 2
set03_V003_I00290
num_objs 1
set02_V009_I01775
num_objs 1
set03_V005_I01529
num_objs 0
set01_V001_I00968
num_objs 1
set00_V012_I01445
num_objs 2
set00_V008_I01085
num_objs 0
set00_V009_I00128
num_objs 2
set02_V011_I00350
num_objs 3
set01_V001_I01331
num_objs 10
set00_V008_I00113
num_objs 6
set02_V010_I00674
num_objs 2
set00_V007_I01511
num_objs 3
set03_V005_I01178
num_objs 2
set03_V009_I01355
num_objs 1
set04_V008_I01067
num_objs 1
set00_V006_I00305
num_objs 4
set03_V005_I01766
num_objs 2
set01_V000_I01655
num_objs 3
set03_V002_I01523
num_objs 1
set00_V006_I01361
num_objs 4
set00_V006_I00296
num_objs 4
set00_V007_I00692
num_objs 1
set01_V003_I00353
num_objs 3
set02_V011_I00824
num_objs 1
set01_V000_I01115
num_objs 4
set00_V001_I01607
num_objs 3
set02_V007_I00122
num_objs 1
set00_V013_I01379
num_objs 3
set00_V008_I01337
num_objs 1
set00_V014_I01598
num_objs 4
set00_V013_I00593
num_objs 3
set05_V012_I00707
num_objs 1
set00_V006_I01400
num_objs 4
set05_V011_I00602
num_objs 5
set02_V003_I00191
num_objs 1
set03_V004_I00623
num_objs 1
set05_V003_I01178
num_objs 3
set03_V009_I00764
num_objs 1
set03_V003_I01100
num_objs 2
set01_V002_I00404
num_objs 5
set00_V012_I01052
num_objs 0
set03_V003_I00473
num_objs 2
set01_V000_I00824
num_objs 1
set05_V007_I01598
num_objs 0
set00_V000_I00197
num_objs 3
set00_V010_I01088
num_objs 1
set01_V004_I01343
num_objs 1
set04_V003_I00755
num_objs 1
set03_V008_I01730
num_objs 1
set05_V010_I01820
num_objs 0
set01_V000_I01238
num_objs 3
set04_V010_I01529
num_objs 0
set00_V008_I00377
num_objs 2
set04_V004_I01163
num_objs 3
set01_V002_I01766
num_objs 5
set00_V005_I00848
num_objs 2
set04_V002_I01196
num_objs 2
set00_V012_I00458
num_objs 0
set05_V011_I00593
num_objs 5
set00_V011_I01358
num_objs 3
set00_V011_I00539
num_objs 2
set04_V008_I01547
num_objs 1
set00_V008_I01115
num_objs 0
set01_V001_I01223
num_objs 10
set01_V005_I00056
num_objs 2
set01_V005_I00740
num_objs 2
set00_V012_I00758
num_objs 0
set02_V011_I01757
num_objs 2
set00_V013_I01565
num_objs 5
set05_V002_I01478
num_objs 1
set04_V004_I00623
num_objs 2
set03_V004_I00194
num_objs 1
set00_V000_I00707
num_objs 2
set02_V011_I01583
num_objs 2
set00_V008_I01082
num_objs 0
set05_V005_I00911
num_objs 1
set03_V009_I00227
num_objs 5
set00_V010_I00716
num_objs 2
set04_V002_I00911
num_objs 1
set00_V014_I00506
num_objs 5
set00_V006_I00374
num_objs 4
set02_V009_I01586
num_objs 1
set00_V008_I00125
num_objs 5
set05_V012_I00497
num_objs 2
set05_V012_I01169
num_objs 0
set03_V011_I00947
num_objs 1
set00_V014_I01382
num_objs 7
set00_V008_I00569
num_objs 6
set03_V003_I01019
num_objs 0
set05_V000_I01661
num_objs 1
set00_V007_I00878
num_objs 3
set00_V006_I01535
num_objs 2
set02_V009_I01349
num_objs 0
set03_V005_I00956
num_objs 1
set00_V014_I00065
num_objs 4
set01_V004_I00065
num_objs 2
set03_V012_I01454
num_objs 3
set00_V013_I00749
num_objs 1
set04_V011_I01097
num_objs 2
set02_V009_I01484
num_objs 1
set03_V011_I01355
num_objs 1
set01_V002_I00464
num_objs 5
set01_V001_I00383
num_objs 3
set05_V002_I01583
num_objs 1
set01_V000_I00065
num_objs 3
set05_V010_I01040
num_objs 1
set04_V003_I01520
num_objs 1
set00_V013_I00062
num_objs 3
set03_V005_I01010
num_objs 1
set00_V007_I01097
num_objs 7
set04_V002_I00995
num_objs 2
set01_V002_I01382
num_objs 1
set01_V002_I00809
num_objs 5
set03_V002_I01676
num_objs 1
set00_V012_I00947
num_objs 6
set05_V009_I00893
num_objs 1
set00_V007_I01019
num_objs 1
set03_V009_I00392
num_objs 3
set04_V002_I01280
num_objs 2
set00_V012_I01196
num_objs 0
set04_V007_I01280
num_objs 1
set04_V000_I00824
num_objs 1
set01_V000_I01577
num_objs 4
set00_V001_I01646
num_objs 2
set03_V008_I00758
num_objs 3
set04_V010_I01634
num_objs 2
set05_V010_I00851
num_objs 1
set00_V006_I00521
num_objs 3
set00_V004_I01556
num_objs 0
set00_V007_I01457
num_objs 5
set04_V005_I01520
num_objs 2
set02_V001_I01610
num_objs 1
set04_V002_I00854
num_objs 1
set01_V004_I01145
num_objs 4
set04_V007_I01283
num_objs 1
set04_V002_I01742
num_objs 3
set04_V004_I01883
num_objs 1
set00_V008_I00041
num_objs 7
set00_V000_I01328
num_objs 1
set05_V012_I00425
num_objs 3
set02_V003_I00074
num_objs 1
set00_V008_I01025
num_objs 3
set04_V011_I01601
num_objs 1
set00_V006_I00668
num_objs 2
set05_V005_I00824
num_objs 2
set04_V003_I01784
num_objs 2
set04_V004_I01205
num_objs 3
set04_V005_I00152
num_objs 1
set05_V011_I01631
num_objs 1
set04_V001_I01775
num_objs 1
set03_V003_I01325
num_objs 2
set00_V004_I00194
num_objs 1
set01_V003_I00584
num_objs 1
set00_V008_I00452
num_objs 8
set00_V010_I01040
num_objs 0
set04_V011_I01652
num_objs 1
set00_V000_I01115
num_objs 0
set03_V009_I00290
num_objs 3
set00_V007_I01232
num_objs 8
set00_V009_I00719
num_objs 4
set04_V011_I01166
num_objs 1
set02_V009_I01580
num_objs 1
set02_V009_I01370
num_objs 1
set00_V009_I00821
num_objs 3
set05_V011_I01481
num_objs 3
set02_V009_I01832
num_objs 2
set01_V001_I00326
num_objs 4
set00_V010_I01232
num_objs 3
set01_V002_I00905
num_objs 4
set00_V007_I00896
num_objs 4
set00_V000_I00401
num_objs 4
set01_V001_I00614
num_objs 3
set04_V008_I01079
num_objs 1
set04_V003_I00161
num_objs 0
set00_V006_I00791
num_objs 2
set00_V009_I01202
num_objs 1
set00_V009_I01604
num_objs 3
set04_V001_I00035
num_objs 1
set00_V007_I01580
num_objs 7
set00_V009_I00647
num_objs 2
set00_V009_I00158
num_objs 1
set03_V008_I01136
num_objs 1
set01_V002_I01805
num_objs 4
set00_V000_I01217
num_objs 2
set04_V004_I00797
num_objs 2
set01_V003_I00542
num_objs 2
set00_V006_I01832
num_objs 0
set04_V004_I01298
num_objs 1
set03_V003_I00500
num_objs 2
set05_V004_I00890
num_objs 0
set04_V008_I01529
num_objs 1
set03_V002_I01670
num_objs 2
set00_V012_I00404
num_objs 0
set02_V011_I00407
num_objs 2
set00_V014_I00686
num_objs 3
set03_V003_I01076
num_objs 2
set01_V002_I01346
num_objs 4
set00_V012_I01379
num_objs 2
set00_V006_I00986
num_objs 2
set00_V011_I00809
num_objs 1
set04_V002_I01367
num_objs 2
set01_V005_I01229
num_objs 1
set03_V009_I00770
num_objs 1
set04_V001_I00146
num_objs 1
set01_V003_I00599
num_objs 4
set02_V009_I00143
num_objs 1
set01_V001_I00587
num_objs 3
set00_V007_I00680
num_objs 1
set04_V002_I00953
num_objs 2
set03_V012_I01391
num_objs 5
set00_V009_I00086
num_objs 5
set00_V000_I00068
num_objs 1
set02_V009_I01151
num_objs 1
set00_V005_I00809
num_objs 1
set05_V001_I00344
num_objs 0
set05_V009_I00881
num_objs 1
set04_V002_I01103
num_objs 2
set00_V013_I00335
num_objs 6
set04_V000_I00854
num_objs 1
set01_V000_I01472
num_objs 5
set05_V011_I01505
num_objs 2
set03_V006_I00101
num_objs 1
set02_V010_I00863
num_objs 1
set05_V007_I01619
num_objs 0
set05_V002_I00698
num_objs 1
set00_V014_I00161
num_objs 1
set02_V007_I00284
num_objs 1
set04_V002_I00071
num_objs 1
set00_V002_I00704
num_objs 1
set04_V007_I00959
num_objs 1
set04_V005_I00734
num_objs 1
set01_V004_I00596
num_objs 3
set03_V003_I00518
num_objs 2
set03_V008_I01409
num_objs 4
set01_V002_I00839
num_objs 8
set00_V013_I00395
num_objs 4
set01_V004_I01592
num_objs 1
set00_V008_I00023
num_objs 4
set03_V008_I01292
num_objs 3
set00_V007_I01871
num_objs 7
set00_V008_I00746
num_objs 1
set05_V002_I00638
num_objs 1
set05_V003_I01742
num_objs 0
set05_V005_I00428
num_objs 1
set00_V011_I00368
num_objs 3
set04_V003_I01109
num_objs 2
set05_V002_I01589
num_objs 1
set01_V000_I00281
num_objs 1
set01_V005_I01769
num_objs 0
set00_V014_I01697
num_objs 3
set04_V007_I00593
num_objs 2
set02_V009_I01346
num_objs 1
set01_V001_I01379
num_objs 2
set00_V014_I00230
num_objs 3
set04_V007_I01259
num_objs 0
set01_V003_I00287
num_objs 4
set00_V003_I00035
num_objs 1
set04_V008_I00539
num_objs 1
set01_V002_I00284
num_objs 8
set01_V002_I01412
num_objs 0
set02_V008_I00518
num_objs 1
set01_V005_I01655
num_objs 0
set02_V001_I01478
num_objs 1
set02_V008_I01856
num_objs 0
set01_V003_I01298
num_objs 1
set00_V014_I00698
num_objs 3
set00_V006_I01139
num_objs 2
set04_V003_I01190
num_objs 3
set00_V010_I01292
num_objs 3
set04_V001_I01601
num_objs 2
set04_V004_I00908
num_objs 2
set00_V001_I01376
num_objs 3
set05_V010_I00818
num_objs 2
set00_V004_I01505
num_objs 0
set00_V006_I01310
num_objs 6
set00_V010_I01499
num_objs 2
set02_V009_I00821
num_objs 2
set00_V007_I01259
num_objs 3
set00_V012_I01538
num_objs 2
set00_V004_I00527
num_objs 1
set03_V005_I00464
num_objs 2
set05_V010_I00527
num_objs 1
set02_V003_I00197
num_objs 1
set02_V007_I00515
num_objs 1
set04_V003_I01697
num_objs 1
set00_V007_I00527
num_objs 4
set00_V010_I01544
num_objs 2
set00_V009_I00041
num_objs 2
set05_V001_I00323
num_objs 0
set04_V003_I00944
num_objs 1
set01_V004_I00980
num_objs 1
set02_V008_I01268
num_objs 1
set00_V013_I00521
num_objs 4
set00_V011_I00212
num_objs 1
set02_V010_I00644
num_objs 2
set03_V011_I01208
num_objs 1
set00_V014_I01061
num_objs 2
set03_V009_I00401
num_objs 2
set00_V010_I01319
num_objs 5
set00_V009_I00401
num_objs 2
set05_V000_I00779
num_objs 0
set00_V008_I01199
num_objs 1
set03_V007_I00272
num_objs 1
set02_V009_I01589
num_objs 0
set05_V010_I01625
num_objs 1
set03_V008_I00026
num_objs 3
set04_V008_I00596
num_objs 1
set05_V005_I00980
num_objs 1
set03_V010_I01634
num_objs 3
set00_V014_I00854
num_objs 5
set00_V009_I00137
num_objs 1
set04_V002_I01598
num_objs 2
set03_V011_I00650
num_objs 3
set01_V003_I01325
num_objs 1
set01_V004_I01418
num_objs 1
set01_V003_I00959
num_objs 3
set04_V011_I01502
num_objs 1
set04_V004_I01427
num_objs 1
set03_V005_I01649
num_objs 1
set00_V007_I00242
num_objs 6
set05_V000_I01733
num_objs 1
set05_V003_I01031
num_objs 1
set03_V008_I00917
num_objs 1
set00_V000_I00896
num_objs 0
set01_V003_I00929
num_objs 5
set00_V013_I00755
num_objs 1
set05_V011_I00521
num_objs 1
set00_V008_I00356
num_objs 0
set00_V012_I01457
num_objs 3
set05_V005_I00248
num_objs 1
set02_V009_I01619
num_objs 0
set01_V004_I01595
num_objs 1
set04_V008_I01121
num_objs 1
set03_V010_I00170
num_objs 2
set01_V002_I00353
num_objs 7
set03_V003_I00224
num_objs 1
set00_V000_I01829
num_objs 1
set02_V009_I00281
num_objs 1
set03_V005_I01475
num_objs 1
set00_V002_I00854
num_objs 10
set04_V004_I01286
num_objs 1
set05_V012_I00248
num_objs 1
set05_V011_I01448
num_objs 3
set05_V011_I01547
num_objs 1
set03_V011_I00407
num_objs 5
set03_V012_I01433
num_objs 4
set00_V003_I00494
num_objs 0
set00_V014_I00431
num_objs 5
set05_V000_I01664
num_objs 1
set05_V011_I00695
num_objs 2
set04_V004_I01166
num_objs 3
set00_V009_I00263
num_objs 6
set00_V001_I00458
num_objs 1
set00_V001_I01640
num_objs 2
set00_V002_I00344
num_objs 1
set00_V012_I00530
num_objs 2
set00_V007_I00137
num_objs 1
set04_V003_I01019
num_objs 4
set04_V007_I00761
num_objs 2
set00_V004_I01526
num_objs 0
set05_V010_I00371
num_objs 1
set05_V000_I00332
num_objs 3
set01_V000_I00911
num_objs 2
set00_V011_I01076
num_objs 9
set00_V001_I01820
num_objs 1
set00_V002_I01205
num_objs 1
set00_V000_I01295
num_objs 1
set00_V002_I00575
num_objs 0
set01_V001_I01439
num_objs 4
set02_V001_I01466
num_objs 1
set03_V003_I00344
num_objs 1
set00_V000_I01022
num_objs 0
set01_V000_I00089
num_objs 3
set00_V009_I00935
num_objs 5
set00_V011_I01004
num_objs 11
set00_V002_I00449
num_objs 0
set00_V004_I00908
num_objs 2
set05_V002_I01535
num_objs 1
set01_V003_I00143
num_objs 8
set05_V007_I01394
num_objs 1
set01_V005_I01097
num_objs 3
set03_V010_I01574
num_objs 3
set05_V010_I00356
num_objs 1
set00_V008_I00419
num_objs 4
set02_V009_I00620
num_objs 2
set00_V000_I00077
num_objs 1
set04_V003_I01235
num_objs 3
set03_V010_I00179
num_objs 0
set03_V008_I01070
num_objs 1
set03_V008_I01115
num_objs 1
set03_V009_I00398
num_objs 2
set00_V010_I00563
num_objs 5
set04_V007_I00941
num_objs 2
set00_V013_I00398
num_objs 3
set05_V009_I01013
num_objs 1
set01_V003_I01313
num_objs 1
set00_V007_I01145
num_objs 9
set01_V002_I00812
num_objs 7
set05_V010_I00002
num_objs 1
set00_V001_I01649
num_objs 0
set03_V011_I00239
num_objs 2
set01_V004_I01562
num_objs 1
set04_V006_I00524
num_objs 1
set00_V001_I01703
num_objs 2
set00_V006_I01232
num_objs 6
set02_V011_I00560
num_objs 2
set03_V009_I00098
num_objs 5
set01_V000_I01442
num_objs 5
set01_V000_I01568
num_objs 4
set04_V004_I01154
num_objs 3
set03_V012_I01628
num_objs 1
set01_V005_I01346
num_objs 1
set00_V009_I00266
num_objs 6
set03_V009_I00503
num_objs 3
set05_V000_I00113
num_objs 2
set00_V007_I00278
num_objs 6
set03_V008_I01712
num_objs 2
set00_V008_I00611
num_objs 3
set01_V003_I01289
num_objs 0
set00_V000_I00425
num_objs 6
set04_V003_I00215
num_objs 0
set04_V002_I00734
num_objs 2
set05_V004_I00947
num_objs 1
set00_V013_I00266
num_objs 5
set01_V000_I01550
num_objs 4
set01_V004_I00062
num_objs 2
set04_V002_I00872
num_objs 1
set03_V005_I01340
num_objs 1
set01_V001_I01055
num_objs 1
set00_V004_I00518
num_objs 1
set05_V002_I00599
num_objs 1
set05_V010_I01028
num_objs 1
set05_V010_I00992
num_objs 1
set00_V008_I01424
num_objs 1
set04_V003_I01718
num_objs 1
set02_V011_I01517
num_objs 2
set05_V005_I00278
num_objs 2
set00_V001_I01637
num_objs 2
set02_V009_I01376
num_objs 1
set01_V002_I00506
num_objs 6
set00_V004_I00968
num_objs 3
set03_V006_I01787
num_objs 1
set01_V000_I01076
num_objs 3
set01_V004_I00173
num_objs 1
set00_V007_I00908
num_objs 3
set01_V003_I00974
num_objs 1
set04_V004_I00218
num_objs 2
set02_V010_I01784
num_objs 1
set03_V003_I01265
num_objs 2
set02_V007_I00419
num_objs 1
set00_V008_I00689
num_objs 3
set05_V002_I00644
num_objs 1
set05_V005_I00716
num_objs 1
set00_V008_I01448
num_objs 1
set04_V008_I00548
num_objs 1
set00_V011_I00935
num_objs 5
set03_V006_I00044
num_objs 1
set00_V004_I01433
num_objs 2
set05_V000_I00164
num_objs 3
set00_V013_I00926
num_objs 1
set00_V004_I01130
num_objs 0
set01_V005_I00500
num_objs 3
set00_V014_I00215
num_objs 3
set00_V014_I00344
num_objs 3
set04_V002_I01697
num_objs 2
set00_V013_I00233
num_objs 3
set03_V005_I00338
num_objs 2
set00_V000_I01748
num_objs 1
set04_V003_I00557
num_objs 0
set04_V005_I01451
num_objs 2
set04_V003_I00749
num_objs 0
set04_V007_I01169
num_objs 1
set00_V010_I00386
num_objs 6
set00_V000_I01346
num_objs 1
set03_V008_I00698
num_objs 3
set04_V006_I00824
num_objs 2
set05_V007_I01517
num_objs 1
set04_V007_I00983
num_objs 2
set00_V000_I01484
num_objs 1
set05_V002_I01172
num_objs 1
set05_V003_I01076
num_objs 1
set01_V003_I00326
num_objs 2
set01_V003_I00107
num_objs 7
set04_V010_I00680
num_objs 1
set00_V013_I01637
num_objs 2
set00_V004_I01661
num_objs 1
set01_V003_I01553
num_objs 1
set00_V003_I00353
num_objs 1
set00_V005_I00827
num_objs 2
set01_V003_I01691
num_objs 3
set01_V002_I00851
num_objs 9
set00_V001_I00419
num_objs 1
set00_V012_I01067
num_objs 0
set02_V003_I00701
num_objs 2
set05_V011_I01025
num_objs 8
set00_V007_I01328
num_objs 7
set02_V010_I01373
num_objs 1
set00_V001_I01568
num_objs 3
set01_V004_I00578
num_objs 1
set00_V002_I01217
num_objs 1
set00_V009_I01322
num_objs 1
set01_V004_I00665
num_objs 2
set05_V000_I00218
num_objs 2
set04_V003_I00422
num_objs 1
set05_V001_I00137
num_objs 1
set01_V005_I00749
num_objs 1
set00_V006_I00878
num_objs 5
set02_V010_I00239
num_objs 1
set00_V013_I00023
num_objs 4
set00_V007_I01907
num_objs 3
set04_V002_I01049
num_objs 2
set03_V003_I00497
num_objs 2
set00_V001_I01439
num_objs 0
set00_V009_I00599
num_objs 1
set00_V007_I01466
num_objs 5
set02_V001_I01649
num_objs 1
set03_V011_I00929
num_objs 0
set01_V005_I01073
num_objs 2
set04_V010_I00953
num_objs 1
set03_V008_I01682
num_objs 2
set03_V004_I00146
num_objs 1
set00_V014_I00524
num_objs 5
set05_V003_I01379
num_objs 2
set00_V011_I00911
num_objs 3
set05_V000_I00482
num_objs 3
set00_V011_I00239
num_objs 1
set00_V014_I01268
num_objs 4
set03_V010_I00929
num_objs 0
set04_V004_I01718
num_objs 1
set02_V011_I00671
num_objs 2
set01_V000_I00131
num_objs 1
set03_V011_I00443
num_objs 5
set03_V008_I00407
num_objs 17
set04_V004_I00437
num_objs 2
set03_V003_I00512
num_objs 2
set01_V003_I00776
num_objs 2
set03_V011_I00377
num_objs 5
set01_V003_I00773
num_objs 2
set03_V009_I01694
num_objs 3
set03_V001_I00842
num_objs 1
set05_V004_I00191
num_objs 3
set01_V004_I01010
num_objs 3
set03_V011_I00269
num_objs 4
set02_V010_I00998
num_objs 1
set00_V000_I01838
num_objs 1
set03_V011_I00458
num_objs 5
set04_V006_I01526
num_objs 1
set00_V011_I00107
num_objs 4
set02_V010_I00539
num_objs 2
set01_V003_I01694
num_objs 3
set03_V009_I00662
num_objs 3
set00_V006_I01913
num_objs 0
set04_V003_I00401
num_objs 1
set05_V005_I01061
num_objs 1
set02_V009_I00833
num_objs 2
set01_V003_I00815
num_objs 2
set05_V010_I00554
num_objs 1
set00_V009_I00980
num_objs 5
set02_V007_I00296
num_objs 1
set00_V000_I01784
num_objs 1
set05_V011_I01577
num_objs 1
set00_V003_I00464
num_objs 1
set03_V009_I00440
num_objs 3
set04_V002_I00782
num_objs 2
set04_V004_I01277
num_objs 1
set05_V005_I00440
num_objs 1
set04_V002_I01190
num_objs 2
set00_V014_I00047
num_objs 3
set04_V005_I00875
num_objs 1
set01_V002_I01754
num_objs 5
set00_V012_I00101
num_objs 0
set00_V007_I00512
num_objs 4
set05_V005_I01100
num_objs 1
set00_V014_I01439
num_objs 0
set01_V001_I01610
num_objs 3
set00_V010_I01682
num_objs 1
set00_V006_I00422
num_objs 2
set04_V003_I00110
num_objs 0
set04_V007_I01499
num_objs 0
set05_V009_I00866
num_objs 1
set03_V003_I01064
num_objs 2
set00_V006_I00254
num_objs 3
set05_V005_I00302
num_objs 2
set00_V008_I00806
num_objs 2
set00_V009_I01532
num_objs 3
set02_V003_I00242
num_objs 1
set04_V004_I01862
num_objs 1
set00_V014_I00074
num_objs 4
set01_V004_I00929
num_objs 5
set05_V005_I00491
num_objs 2
set00_V000_I00683
num_objs 1
set00_V010_I01169
num_objs 4
set05_V005_I00239
num_objs 0
set01_V002_I00875
num_objs 8
set00_V011_I01280
num_objs 3
set01_V003_I00299
num_objs 6
set00_V004_I00551
num_objs 1
set04_V001_I01571
num_objs 2
set04_V006_I00929
num_objs 1
set00_V006_I00323
num_objs 4
set05_V010_I00443
num_objs 1
set05_V007_I01733
num_objs 0
set00_V007_I01310
num_objs 8
set04_V005_I00275
num_objs 1
set04_V005_I01244
num_objs 2
set01_V001_I00773
num_objs 1
set00_V014_I01868
num_objs 0
set01_V005_I00833
num_objs 2
set00_V001_I00779
num_objs 1
set05_V000_I00155
num_objs 3
set05_V005_I00638
num_objs 1
set00_V008_I00251
num_objs 0
set02_V007_I00140
num_objs 1
set01_V002_I01304
num_objs 5
set03_V005_I00494
num_objs 2
set00_V001_I01280
num_objs 4
set00_V012_I00173
num_objs 1
set03_V008_I00134
num_objs 11
set02_V011_I00374
num_objs 2
set01_V005_I00332
num_objs 3
set01_V004_I01235
num_objs 0
set05_V005_I01235
num_objs 1
set04_V010_I00383
num_objs 1
set00_V008_I00230
num_objs 0
set01_V005_I01595
num_objs 0
set03_V008_I00674
num_objs 3
set00_V007_I01739
num_objs 2
set03_V003_I00536
num_objs 2
set05_V003_I01298
num_objs 2
set03_V009_I00422
num_objs 3
set02_V010_I01319
num_objs 0
set04_V010_I00968
num_objs 1
set01_V000_I00623
num_objs 3
set03_V003_I00026
num_objs 2
set00_V011_I00509
num_objs 4
set04_V010_I00896
num_objs 2
set00_V014_I00668
num_objs 3
set03_V011_I00944
num_objs 1
set02_V010_I01316
num_objs 1
set03_V008_I01787
num_objs 2
set03_V003_I00851
num_objs 2
set01_V001_I00218
num_objs 2
set05_V005_I00668
num_objs 1
set03_V009_I00908
num_objs 4
set00_V001_I00845
num_objs 3
set00_V008_I01430
num_objs 1
set00_V010_I01163
num_objs 2
set05_V011_I01652
num_objs 1
set03_V004_I00107
num_objs 1
set00_V000_I00527
num_objs 1
set00_V007_I01004
num_objs 2
set05_V011_I01676
num_objs 1
set03_V012_I00965
num_objs 1
set01_V005_I00665
num_objs 2
set00_V001_I01616
num_objs 2
set00_V010_I00512
num_objs 4
set05_V005_I01178
num_objs 1
set01_V005_I01217
num_objs 3
set00_V007_I00932
num_objs 3
set00_V004_I00791
num_objs 2
set05_V005_I01019
num_objs 0
set04_V007_I00488
num_objs 1
set05_V000_I00284
num_objs 2
set00_V002_I00695
num_objs 1
set04_V002_I01622
num_objs 2
set02_V007_I00245
num_objs 1
set04_V001_I01736
num_objs 1
set04_V002_I01085
num_objs 2
set00_V009_I01214
num_objs 1
set04_V003_I00296
num_objs 1
set05_V007_I01403
num_objs 1
set03_V005_I00485
num_objs 2
set00_V013_I00866
num_objs 2
set00_V000_I00872
num_objs 0
set00_V011_I00977
num_objs 10
set03_V003_I00449
num_objs 1
set00_V011_I00983
num_objs 10
set01_V002_I00746
num_objs 8
set02_V010_I00215
num_objs 1
set00_V002_I00746
num_objs 2
set04_V002_I00599
num_objs 1
set05_V005_I00623
num_objs 1
set01_V005_I01313
num_objs 1
set04_V011_I00383
num_objs 1
set04_V007_I01469
num_objs 0
set00_V000_I00248
num_objs 5
set00_V000_I00326
num_objs 1
set01_V001_I00896
num_objs 1
set04_V010_I00407
num_objs 1
set03_V006_I01748
num_objs 1
set03_V008_I00074
num_objs 7
set00_V014_I01505
num_objs 3
set04_V002_I01139
num_objs 2
set00_V009_I00770
num_objs 3
set02_V009_I01604
num_objs 2
set00_V012_I00380
num_objs 0
set00_V001_I00215
num_objs 3
set01_V004_I00851
num_objs 3
set00_V004_I01436
num_objs 2
set03_V012_I01535
num_objs 4
set00_V009_I01094
num_objs 1
set04_V002_I01022
num_objs 2
set00_V000_I00650
num_objs 1
set01_V004_I01220
num_objs 0
set02_V010_I00707
num_objs 2
set01_V005_I00620
num_objs 3
set03_V009_I00296
num_objs 3
set04_V006_I00920
num_objs 2
set00_V006_I00488
num_objs 3
set00_V007_I00608
num_objs 3
set01_V000_I01223
num_objs 3
set01_V000_I00002
num_objs 1
set03_V011_I00413
num_objs 5
set00_V012_I01049
num_objs 2
set03_V010_I01454
num_objs 2
set00_V013_I00818
num_objs 2
set00_V009_I01580
num_objs 4
set03_V009_I01004
num_objs 2
set03_V005_I00845
num_objs 1
set00_V004_I00911
num_objs 2
set04_V002_I01775
num_objs 1
set04_V006_I00608
num_objs 1
set04_V003_I01583
num_objs 1
set00_V008_I01286
num_objs 1
set00_V000_I00914
num_objs 0
set04_V007_I01013
num_objs 2
set00_V013_I00752
num_objs 1
set05_V000_I00428
num_objs 2
set04_V002_I00107
num_objs 0
set01_V005_I01397
num_objs 0
set05_V012_I01100
num_objs 1
set05_V002_I01490
num_objs 1
set03_V003_I01196
num_objs 2
set00_V007_I00920
num_objs 3
set01_V001_I01433
num_objs 13
set05_V010_I00761
num_objs 1
set00_V013_I00110
num_objs 4
set00_V001_I01676
num_objs 1
set02_V003_I00125
num_objs 1
set00_V006_I00167
num_objs 3
set02_V009_I01262
num_objs 1
set03_V009_I00557
num_objs 4
set00_V014_I00791
num_objs 5
set04_V008_I01064
num_objs 1
set05_V004_I00251
num_objs 1
set03_V005_I00314
num_objs 2
set02_V009_I00185
num_objs 2
set02_V010_I00626
num_objs 2
set02_V007_I00488
num_objs 1
set03_V005_I01691
num_objs 1
set01_V003_I00455
num_objs 4
set01_V005_I00782
num_objs 2
set04_V000_I00635
num_objs 3
set00_V007_I01904
num_objs 3
set04_V001_I01655
num_objs 2
set01_V005_I00251
num_objs 1
set00_V008_I00578
num_objs 5
set00_V000_I01745
num_objs 1
set05_V007_I01523
num_objs 1
set04_V005_I00122
num_objs 1
set00_V007_I00857
num_objs 3
set00_V008_I01352
num_objs 1
set01_V005_I00029
num_objs 0
set00_V006_I00722
num_objs 2
set02_V010_I00614
num_objs 2
set00_V014_I00044
num_objs 3
set04_V000_I00851
num_objs 1
set00_V001_I01421
num_objs 4
set00_V014_I00701
num_objs 3
set03_V010_I00911
num_objs 1
set03_V004_I00233
num_objs 1
set01_V001_I00104
num_objs 3
set00_V007_I00542
num_objs 5
set01_V002_I00254
num_objs 7
set04_V003_I01727
num_objs 1
set00_V000_I00788
num_objs 0
set00_V011_I01583
num_objs 0
set04_V004_I01880
num_objs 1
set05_V001_I00440
num_objs 0
set04_V001_I01631
num_objs 3
set02_V011_I00386
num_objs 2
set00_V006_I01016
num_objs 1
set00_V013_I01091
num_objs 3
set01_V004_I01121
num_objs 4
set01_V003_I00191
num_objs 8
set00_V011_I01166
num_objs 4
set00_V001_I01034
num_objs 13
set02_V011_I01448
num_objs 2
set01_V005_I01064
num_objs 3
set04_V005_I00203
num_objs 1
set05_V012_I01049
num_objs 1
set03_V010_I01808
num_objs 2
set01_V004_I00647
num_objs 3
set00_V000_I00455
num_objs 2
set05_V012_I01214
num_objs 1
set00_V004_I01655
num_objs 1
set01_V001_I00983
num_objs 1
set05_V012_I01172
num_objs 1
set02_V011_I01457
num_objs 2
set05_V004_I00926
num_objs 2
set01_V005_I01304
num_objs 1
set04_V003_I01394
num_objs 3
set02_V010_I01559
num_objs 0
set05_V012_I01163
num_objs 1
set01_V002_I00137
num_objs 6
set02_V010_I01535
num_objs 1
set02_V008_I00935
num_objs 0
set00_V014_I00008
num_objs 4
set03_V003_I01361
num_objs 2
set04_V006_I00644
num_objs 3
set00_V009_I00281
num_objs 5
set02_V009_I01175
num_objs 2
set00_V006_I01712
num_objs 0
set00_V000_I01490
num_objs 1
set03_V005_I00902
num_objs 1
set04_V010_I00884
num_objs 2
set02_V011_I00347
num_objs 3
set00_V013_I00014
num_objs 4
set00_V008_I00413
num_objs 2
set00_V007_I01733
num_objs 5
set00_V011_I01163
num_objs 4
set03_V005_I01199
num_objs 1
set04_V001_I00080
num_objs 1
set00_V006_I01202
num_objs 5
set01_V005_I01088
num_objs 3
set01_V000_I00587
num_objs 2
set01_V001_I00548
num_objs 4
set03_V005_I01277
num_objs 1
set02_V010_I01394
num_objs 1
set00_V006_I00191
num_objs 3
set00_V006_I01481
num_objs 3
set04_V004_I01193
num_objs 3
set04_V005_I01214
num_objs 1
set04_V004_I01112
num_objs 3
set00_V010_I00536
num_objs 4
set04_V002_I01082
num_objs 2
set00_V012_I00254
num_objs 3
set03_V003_I01409
num_objs 0
set05_V010_I00530
num_objs 1
set01_V004_I01202
num_objs 0
set05_V005_I01010
num_objs 1
set05_V011_I00680
num_objs 2
set01_V002_I00758
num_objs 7
set01_V004_I00053
num_objs 2
set01_V000_I01256
num_objs 3
set00_V010_I00125
num_objs 3
set03_V003_I01529
num_objs 0
set03_V003_I00995
num_objs 2
set00_V014_I00395
num_objs 5
set03_V009_I00788
num_objs 2
set03_V008_I00869
num_objs 3
set00_V004_I00866
num_objs 1
set01_V001_I00512
num_objs 4
set01_V000_I01142
num_objs 4
set00_V002_I00452
num_objs 0
set03_V005_I00650
num_objs 2
set04_V007_I00320
num_objs 1
set04_V004_I00893
num_objs 2
set03_V010_I00149
num_objs 0
set01_V004_I00629
num_objs 3
set01_V000_I01241
num_objs 3
set04_V010_I00539
num_objs 1
set04_V006_I00908
num_objs 2
set02_V008_I00521
num_objs 1
set00_V012_I01061
num_objs 0
set04_V005_I00245
num_objs 1
set01_V004_I01415
num_objs 1
set00_V014_I00947
num_objs 3
set01_V004_I00542
num_objs 1
set00_V001_I01772
num_objs 5
set00_V007_I01748
num_objs 5
set00_V012_I00860
num_objs 4
set00_V004_I01349
num_objs 8
set03_V009_I01766
num_objs 4
set00_V013_I00710
num_objs 1
set02_V007_I00290
num_objs 1
set04_V003_I00488
num_objs 0
set05_V000_I00356
num_objs 3
set04_V007_I01268
num_objs 1
set03_V003_I00506
num_objs 2
set02_V010_I01814
num_objs 1
set04_V010_I00431
num_objs 1
set03_V011_I00203
num_objs 3
set01_V001_I00785
num_objs 2
set01_V005_I00014
num_objs 2
set05_V011_I00863
num_objs 9
set01_V005_I01373
num_objs 1
set00_V002_I00206
num_objs 2
set01_V003_I00569
num_objs 0
set00_V007_I01652
num_objs 5
set03_V007_I00317
num_objs 1
set00_V008_I00608
num_objs 3
set02_V010_I00500
num_objs 1
set01_V004_I01031
num_objs 3
set05_V002_I01463
num_objs 1
set05_V007_I01748
num_objs 0
set03_V010_I01004
num_objs 3
set05_V011_I00782
num_objs 5
set04_V004_I00257
num_objs 1
set04_V005_I01178
num_objs 1
set04_V000_I00491
num_objs 2
set02_V010_I01757
num_objs 1
set00_V013_I00833
num_objs 2
set05_V009_I00977
num_objs 1
set03_V008_I00113
num_objs 10
set01_V000_I01130
num_objs 4
set04_V007_I01760
num_objs 1
set05_V005_I00725
num_objs 1
set01_V000_I01193
num_objs 3
set00_V007_I00335
num_objs 6
set00_V014_I00041
num_objs 3
set00_V011_I01571
num_objs 0
set00_V007_I01772
num_objs 4
set00_V011_I00665
num_objs 4
set04_V002_I00833
num_objs 1
set05_V008_I01802
num_objs 1
set00_V007_I01790
num_objs 3
set01_V001_I00425
num_objs 3
set05_V011_I01625
num_objs 1
set01_V000_I01301
num_objs 3
set03_V009_I01514
num_objs 2
set04_V005_I01430
num_objs 2
set01_V000_I00410
num_objs 2
set00_V010_I00596
num_objs 5
set03_V011_I00995
num_objs 1
set05_V004_I00116
num_objs 3
set03_V004_I00092
num_objs 1
set01_V000_I00122
num_objs 1
set05_V005_I00368
num_objs 2
set02_V001_I01619
num_objs 0
set03_V007_I00284
num_objs 1
set03_V006_I01784
num_objs 1
set04_V004_I01742
num_objs 1
set01_V003_I01022
num_objs 2
set01_V005_I00209
num_objs 2
set01_V002_I01172
num_objs 1
set00_V012_I01136
num_objs 0
set02_V009_I00698
num_objs 2
set03_V012_I01460
num_objs 3
set02_V009_I01700
num_objs 1
set00_V010_I00935
num_objs 1
set02_V010_I01826
num_objs 1
set03_V005_I00416
num_objs 2
set01_V001_I01565
num_objs 8
set01_V003_I00128
num_objs 8
set04_V005_I00182
num_objs 1
set02_V011_I01823
num_objs 2
set00_V003_I00023
num_objs 0
set03_V009_I00485
num_objs 3
set00_V014_I01904
num_objs 1
set00_V001_I01601
num_objs 3
set01_V004_I00893
num_objs 1
set03_V009_I01055
num_objs 6
set05_V002_I00719
num_objs 0
set00_V011_I00191
num_objs 1
set01_V005_I00137
num_objs 2
set01_V004_I01292
num_objs 1
set00_V007_I00359
num_objs 2
set04_V005_I01166
num_objs 1
set02_V010_I01136
num_objs 1
set00_V010_I00041
num_objs 4
set03_V008_I01319
num_objs 4
set00_V002_I00722
num_objs 2
set04_V004_I00278
num_objs 2
set00_V006_I00260
num_objs 3
set00_V006_I01604
num_objs 2
set03_V011_I00305
num_objs 4
set00_V008_I00050
num_objs 6
set00_V003_I00029
num_objs 0
set05_V005_I00140
num_objs 1
set03_V009_I01076
num_objs 6
set00_V009_I00893
num_objs 5
set00_V009_I00506
num_objs 2
set00_V000_I01529
num_objs 1
set04_V000_I00656
num_objs 3
set00_V000_I00278
num_objs 4
set00_V001_I01508
num_objs 6
set00_V010_I00875
num_objs 2
set02_V007_I00251
num_objs 1
set04_V004_I01421
num_objs 1
set00_V011_I01475
num_objs 4
set01_V000_I00992
num_objs 0
set03_V011_I00449
num_objs 4
set00_V010_I00944
num_objs 1
set02_V007_I00434
num_objs 1
set00_V011_I00962
num_objs 10
set03_V008_I00131
num_objs 11
set00_V010_I00146
num_objs 4
set03_V001_I00164
num_objs 1
set05_V003_I01322
num_objs 2
set04_V004_I00398
num_objs 2
set04_V007_I00812
num_objs 2
set00_V013_I00812
num_objs 1
set03_V008_I00122
num_objs 11
set04_V004_I01232
num_objs 2
set03_V009_I00350
num_objs 4
set05_V005_I00731
num_objs 1
set00_V002_I00776
num_objs 2
set00_V010_I01049
num_objs 1
set00_V014_I01274
num_objs 4
set00_V007_I00686
num_objs 1
set01_V005_I00524
num_objs 2
set03_V009_I01523
num_objs 2
set04_V004_I01175
num_objs 3
set00_V004_I00200
num_objs 1
set02_V009_I00329
num_objs 0
set03_V011_I01169
num_objs 1
set00_V001_I01787
num_objs 5
set04_V010_I00560
num_objs 1
set02_V010_I01682
num_objs 1
set03_V005_I01715
num_objs 1
set00_V014_I01298
num_objs 6
set01_V002_I01343
num_objs 4
set03_V001_I00818
num_objs 1
set03_V003_I01364
num_objs 2
set00_V010_I01532
num_objs 3
set00_V000_I01238
num_objs 2
set05_V000_I00359
num_objs 1
set04_V001_I01715
num_objs 1
set02_V009_I01250
num_objs 2
set00_V012_I00533
num_objs 2
set00_V007_I00887
num_objs 4
set02_V009_I01427
num_objs 1
set00_V010_I01361
num_objs 4
set01_V003_I00194
num_objs 8
set02_V001_I00080
num_objs 0
set00_V009_I01019
num_objs 0
set03_V010_I01709
num_objs 1
set02_V008_I00974
num_objs 0
set05_V000_I00206
num_objs 2
set00_V001_I00662
num_objs 3
set00_V013_I00722
num_objs 1
set02_V008_I01214
num_objs 2
set03_V009_I00455
num_objs 3
set04_V000_I00872
num_objs 1
set04_V011_I01607
num_objs 1
set00_V006_I01493
num_objs 2
set03_V011_I00950
num_objs 1
set01_V005_I00701
num_objs 2
set03_V005_I00272
num_objs 1
set05_V000_I00605
num_objs 1
set04_V003_I01007
num_objs 4
set03_V008_I00902
num_objs 1
set04_V004_I01400
num_objs 1
set03_V011_I00164
num_objs 3
set01_V004_I00836
num_objs 2
set04_V004_I00251
num_objs 1
set01_V004_I00506
num_objs 1
set05_V002_I00596
num_objs 1
set04_V005_I00071
num_objs 1
set05_V011_I01415
num_objs 3
set03_V003_I00248
num_objs 1
set00_V010_I01328
num_objs 4
set02_V010_I00806
num_objs 2
set03_V005_I01466
num_objs 1
set04_V010_I00470
num_objs 1
set02_V011_I00341
num_objs 3
set00_V009_I01397
num_objs 0
set01_V003_I00512
num_objs 3
set03_V006_I00152
num_objs 1
set04_V006_I00896
num_objs 2
set04_V004_I00836
num_objs 2
set04_V004_I00647
num_objs 2
set01_V001_I00011
num_objs 2
set01_V004_I00257
num_objs 2
set00_V009_I00806
num_objs 2
set05_V000_I00185
num_objs 2
set01_V002_I00305
num_objs 7
set01_V005_I00800
num_objs 2
set05_V011_I01034
num_objs 8
set02_V009_I01382
num_objs 1
set01_V004_I00572
num_objs 1
set00_V007_I01682
num_objs 5
set03_V008_I00095
num_objs 7
set00_V006_I01217
num_objs 5
set04_V002_I01628
num_objs 2
set04_V003_I00992
num_objs 4
set00_V007_I01757
num_objs 5
set04_V006_I00635
num_objs 1
set05_V000_I00254
num_objs 2
set00_V009_I00824
num_objs 3
set03_V005_I00827
num_objs 1
set04_V004_I00572
num_objs 3
set00_V012_I01364
num_objs 0
set05_V005_I00578
num_objs 1
set05_V003_I01325
num_objs 2
set03_V003_I00350
num_objs 1
set04_V008_I01442
num_objs 1
set02_V009_I01520
num_objs 1
set00_V001_I00494
num_objs 3
set01_V005_I00167
num_objs 2
set00_V009_I00998
num_objs 4
set03_V001_I00794
num_objs 1
set00_V004_I01634
num_objs 1
set03_V009_I00368
num_objs 4
set03_V009_I01313
num_objs 0
set01_V002_I00854
num_objs 9
set01_V003_I01592
num_objs 1
set02_V007_I00470
num_objs 1
set03_V009_I00590
num_objs 4
set00_V011_I00290
num_objs 2
set05_V011_I00689
num_objs 0
set05_V010_I00974
num_objs 1
set03_V004_I00182
num_objs 1
set00_V001_I01427
num_objs 4
set04_V010_I00521
num_objs 1
set02_V010_I00191
num_objs 1
set05_V012_I00380
num_objs 3
set00_V008_I00359
num_objs 0
set05_V005_I00251
num_objs 1
set01_V002_I00401
num_objs 5
set03_V011_I01337
num_objs 1
set00_V008_I00800
num_objs 2
set01_V005_I00224
num_objs 2
set00_V013_I00182
num_objs 4
set00_V010_I01697
num_objs 1
set01_V003_I00416
num_objs 3
set01_V002_I00737
num_objs 7
set04_V005_I01475
num_objs 1
set04_V007_I01364
num_objs 1
set00_V012_I01373
num_objs 0
set02_V009_I01133
num_objs 1
set01_V001_I01283
num_objs 11
set01_V002_I01604
num_objs 3
set02_V003_I00155
num_objs 1
set00_V008_I00293
num_objs 0
set03_V012_I00863
num_objs 1
set05_V000_I00200
num_objs 2
set00_V007_I00404
num_objs 6
set00_V012_I00497
num_objs 2
set04_V006_I00545
num_objs 1
set00_V010_I01073
num_objs 0
set03_V007_I00287
num_objs 1
set00_V014_I00287
num_objs 4
set02_V009_I00896
num_objs 1
set00_V000_I01634
num_objs 1
set00_V012_I01400
num_objs 1
set01_V004_I00827
num_objs 3
set03_V006_I01730
num_objs 1
set01_V000_I01403
num_objs 4
set00_V002_I00563
num_objs 0
set00_V013_I00410
num_objs 3
set00_V009_I01328
num_objs 1
set04_V004_I00245
num_objs 1
set00_V011_I00995
num_objs 11
set01_V001_I01625
num_objs 5
set04_V011_I01508
num_objs 1
set01_V002_I00509
num_objs 1
set00_V006_I01091
num_objs 10
set05_V003_I01658
num_objs 0
set00_V008_I00071
num_objs 6
set04_V007_I00893
num_objs 2
set02_V009_I00665
num_objs 2
set03_V010_I00182
num_objs 1
set02_V003_I00236
num_objs 1
set00_V001_I01457
num_objs 4
set04_V002_I01052
num_objs 2
set03_V005_I00878
num_objs 1
set03_V011_I01382
num_objs 1
set03_V010_I01064
num_objs 1
set02_V003_I00119
num_objs 0
set02_V008_I01217
num_objs 2
set00_V012_I00098
num_objs 0
set01_V001_I00848
num_objs 1
set00_V007_I01280
num_objs 8
set04_V007_I01427
num_objs 1
set01_V002_I00845
num_objs 9
set02_V009_I00230
num_objs 2
set00_V008_I00302
num_objs 0
set04_V005_I01610
num_objs 2
set00_V008_I00908
num_objs 1
set04_V006_I01520
num_objs 1
set01_V001_I00584
num_objs 3
set01_V003_I00389
num_objs 2
set05_V011_I01337
num_objs 1
set03_V011_I01466
num_objs 2
set02_V010_I01754
num_objs 1
set00_V010_I00779
num_objs 2
set03_V005_I00947
num_objs 1
set00_V001_I01727
num_objs 1
set00_V009_I01223
num_objs 1
set00_V014_I01271
num_objs 4
set00_V011_I00956
num_objs 9
set00_V012_I00221
num_objs 2
set05_V005_I01109
num_objs 1
set00_V006_I01178
num_objs 4
set05_V002_I00518
num_objs 1
set00_V006_I01391
num_objs 4
set00_V000_I00515
num_objs 1
set01_V000_I01121
num_objs 4
set05_V002_I00782
num_objs 1
set03_V011_I00818
num_objs 2
set03_V009_I00341
num_objs 4
set03_V010_I01562
num_objs 3
set01_V001_I01571
num_objs 7
set03_V009_I01619
num_objs 0
set00_V013_I00713
num_objs 1
set04_V007_I01517
num_objs 1
set00_V011_I00110
num_objs 4
set00_V010_I01172
num_objs 2
set00_V011_I00173
num_objs 3
set02_V011_I00275
num_objs 0
set03_V011_I00308
num_objs 4
set05_V001_I00377
num_objs 0
set01_V005_I00398
num_objs 4
set00_V009_I00059
num_objs 1
set03_V002_I01532
num_objs 1
set04_V000_I00485
num_objs 2
set04_V000_I00743
num_objs 3
set01_V002_I00857
num_objs 9
set00_V008_I00239
num_objs 0
set03_V005_I01280
num_objs 1
set00_V007_I00593
num_objs 3
set01_V005_I00395
num_objs 4
set00_V004_I00557
num_objs 1
set01_V005_I00755
num_objs 2
set01_V002_I01661
num_objs 4
set04_V010_I00389
num_objs 1
set01_V005_I00839
num_objs 1
set02_V011_I01673
num_objs 2
set00_V009_I00011
num_objs 1
set02_V009_I00359
num_objs 1
set00_V003_I00341
num_objs 1
set03_V003_I00314
num_objs 1
set01_V001_I01136
num_objs 2
set00_V014_I00536
num_objs 5
set03_V009_I00881
num_objs 2
set00_V003_I00065
num_objs 0
set00_V008_I00596
num_objs 5
set04_V001_I00053
num_objs 1
set03_V009_I00869
num_objs 0
set01_V005_I00431
num_objs 4
set02_V009_I00410
num_objs 2
set02_V007_I00428
num_objs 1
set02_V009_I00182
num_objs 2
set01_V004_I01082
num_objs 3
set00_V012_I00764
num_objs 0
set04_V007_I01100
num_objs 2
set00_V004_I01307
num_objs 0
set01_V005_I01619
num_objs 0
set05_V012_I00563
num_objs 0
set01_V005_I00071
num_objs 2
set00_V004_I01322
num_objs 1
set00_V014_I00863
num_objs 4
set00_V007_I00578
num_objs 4
set00_V008_I00491
num_objs 5
set01_V001_I01826
num_objs 1
set02_V009_I00659
num_objs 2
set00_V006_I01409
num_objs 3
set00_V012_I00296
num_objs 3
set05_V005_I00608
num_objs 1
set04_V006_I00668
num_objs 3
set04_V003_I01292
num_objs 4
set03_V003_I00692
num_objs 2
set04_V007_I00374
num_objs 1
set02_V007_I00944
num_objs 1
set00_V011_I01304
num_objs 5
set00_V000_I00668
num_objs 1
set03_V004_I00095
num_objs 1
set05_V011_I01508
num_objs 2
set03_V008_I01703
num_objs 2
set00_V014_I00827
num_objs 5
set02_V009_I01532
num_objs 1
set02_V010_I01154
num_objs 1
set00_V002_I00623
num_objs 0
set04_V000_I00566
num_objs 3
set02_V009_I01703
num_objs 1
set01_V001_I01082
num_objs 1
set05_V008_I01829
num_objs 1
set00_V014_I00821
num_objs 5
set00_V010_I00293
num_objs 3
set00_V006_I01034
num_objs 3
set04_V004_I00782
num_objs 2
set00_V002_I00917
num_objs 5
set02_V007_I00455
num_objs 1
set04_V006_I00947
num_objs 2
set00_V006_I01622
num_objs 1
set01_V003_I00938
num_objs 2
set00_V007_I00431
num_objs 6
set02_V010_I00683
num_objs 2
set03_V009_I01106
num_objs 6
set04_V004_I00713
num_objs 2
set02_V010_I00290
num_objs 1
set03_V008_I00788
num_objs 3
set05_V000_I01628
num_objs 1
set03_V009_I00494
num_objs 3
set04_V004_I00473
num_objs 3
set03_V005_I00248
num_objs 1
set04_V000_I00521
num_objs 2
set00_V013_I00152
num_objs 4
set05_V012_I01130
num_objs 1
set03_V003_I01025
num_objs 2
set00_V008_I01364
num_objs 1
set01_V000_I01619
num_objs 3
set05_V007_I01547
num_objs 0
set00_V008_I00890
num_objs 1
set05_V005_I00206
num_objs 0
set04_V002_I00677
num_objs 2
set02_V011_I01799
num_objs 1
set00_V000_I00071
num_objs 1
set01_V001_I00731
num_objs 2
set04_V011_I01076
num_objs 2
set01_V004_I00494
num_objs 1
set02_V011_I00530
num_objs 2
set03_V009_I00671
num_objs 3
set00_V011_I00653
num_objs 3
set05_V007_I01691
num_objs 0
set02_V009_I01202
num_objs 2
set00_V007_I00977
num_objs 3
set01_V000_I01037
num_objs 2
set03_V009_I01685
num_objs 3
set05_V007_I01259
num_objs 0
set01_V005_I00542
num_objs 2
set00_V007_I00875
num_objs 3
set01_V001_I00242
num_objs 1
set02_V009_I00827
num_objs 2
set05_V004_I00200
num_objs 3
set00_V007_I00503
num_objs 4
set00_V013_I00353
num_objs 4
set00_V006_I00824
num_objs 2
set04_V007_I01385
num_objs 1
set03_V010_I01412
num_objs 2
set05_V010_I01604
num_objs 1
set02_V009_I00905
num_objs 1
set05_V010_I01577
num_objs 1
set05_V011_I01532
num_objs 1
set00_V006_I01685
num_objs 0
set00_V001_I00275
num_objs 5
set00_V014_I00980
num_objs 3
set00_V002_I00416
num_objs 0
set03_V002_I01607
num_objs 1
set05_V003_I01271
num_objs 2
set03_V005_I01580
num_objs 1
set00_V011_I00383
num_objs 3
set00_V002_I00260
num_objs 2
set01_V005_I00791
num_objs 2
set03_V010_I01541
num_objs 3
set03_V008_I01022
num_objs 1
set00_V014_I01022
num_objs 3
set00_V013_I01109
num_objs 4
set00_V002_I00389
num_objs 0
set03_V011_I01184
num_objs 1
set01_V003_I00470
num_objs 5
set03_V009_I01370
num_objs 1
set00_V008_I00092
num_objs 7
set01_V005_I01400
num_objs 0
set00_V012_I00299
num_objs 3
set00_V012_I01073
num_objs 0
set05_V010_I01598
num_objs 1
set03_V011_I00362
num_objs 5
set05_V002_I00506
num_objs 1
set00_V007_I00788
num_objs 2
set01_V000_I01613
num_objs 3
set01_V002_I00368
num_objs 5
set01_V002_I00929
num_objs 4
set01_V001_I00836
num_objs 1
set01_V001_I01613
num_objs 3
set01_V000_I01649
num_objs 3
set01_V004_I01112
num_objs 4
set03_V004_I00578
num_objs 1
set02_V011_I00779
num_objs 0
set00_V014_I00509
num_objs 4
set00_V004_I01523
num_objs 0
set04_V002_I01238
num_objs 2
set04_V003_I01673
num_objs 1
set00_V007_I00944
num_objs 3
set01_V003_I00935
num_objs 2
set02_V010_I00782
num_objs 2
set00_V007_I00962
num_objs 3
set00_V008_I01295
num_objs 1
set04_V000_I00608
num_objs 3
set03_V007_I00248
num_objs 1
set02_V010_I00404
num_objs 1
set00_V001_I01382
num_objs 3
set04_V002_I01193
num_objs 2
set00_V013_I00929
num_objs 1
set04_V007_I01205
num_objs 1
set04_V003_I00767
num_objs 1
set00_V011_I01073
num_objs 9
set01_V002_I00785
num_objs 7
set00_V012_I00944
num_objs 6
set00_V013_I00299
num_objs 5
set01_V005_I00899
num_objs 1
set00_V006_I00698
num_objs 2
set00_V014_I01031
num_objs 3
set01_V003_I01673
num_objs 2
set04_V011_I01523
num_objs 1
set00_V012_I00956
num_objs 6
set04_V005_I01271
num_objs 1
set01_V004_I00761
num_objs 2
set05_V000_I00461
num_objs 3
set05_V003_I01577
num_objs 0
set01_V002_I01508
num_objs 0
set04_V004_I01757
num_objs 1
set02_V010_I01031
num_objs 1
set02_V010_I01664
num_objs 1
set05_V009_I00899
num_objs 1
set00_V001_I01562
num_objs 3
set01_V001_I00296
num_objs 4
set03_V008_I00038
num_objs 4
set00_V006_I01226
num_objs 5
set03_V008_I00710
num_objs 3
set04_V002_I01499
num_objs 2
set05_V012_I01055
num_objs 1
set05_V000_I00128
num_objs 4
set02_V009_I01220
num_objs 2
set04_V004_I01226
num_objs 3
set00_V001_I00299
num_objs 4
set02_V009_I00104
num_objs 1
set01_V001_I00887
num_objs 1
set00_V007_I00203
num_objs 4
set04_V001_I01628
num_objs 3
set01_V003_I00332
num_objs 3
set00_V013_I00194
num_objs 4
set04_V003_I00356
num_objs 1
set00_V012_I01490
num_objs 1
set00_V002_I01016
num_objs 0
set03_V005_I01250
num_objs 2
set00_V004_I00962
num_objs 3
set03_V012_I01400
num_objs 5
set05_V011_I00674
num_objs 2
set04_V011_I00344
num_objs 1
set00_V002_I00665
num_objs 1
set04_V004_I00386
num_objs 1
set02_V011_I00731
num_objs 1
set04_V007_I00878
num_objs 2
set03_V009_I00476
num_objs 3
set04_V007_I01745
num_objs 1
set03_V012_I01511
num_objs 3
set04_V007_I01658
num_objs 1
set02_V009_I00809
num_objs 2
set00_V004_I01301
num_objs 0
set00_V001_I01817
num_objs 3
set01_V000_I00644
num_objs 0
set02_V003_I00275
num_objs 1
set05_V005_I00350
num_objs 2
set02_V009_I00824
num_objs 2
set01_V005_I00632
num_objs 3
set01_V005_I01163
num_objs 3
set02_V010_I01454
num_objs 1
set02_V009_I00125
num_objs 1
set04_V010_I00887
num_objs 2
set02_V009_I00545
num_objs 2
set00_V014_I00920
num_objs 2
set02_V010_I00716
num_objs 2
set01_V004_I00068
num_objs 2
set05_V012_I00734
num_objs 2
set01_V005_I00704
num_objs 2
set02_V001_I01502
num_objs 1
set05_V005_I00839
num_objs 0
set05_V010_I01094
num_objs 1
set02_V009_I00770
num_objs 2
set05_V012_I00539
num_objs 1
set00_V012_I01091
num_objs 0
set00_V006_I01817
num_objs 0
set03_V009_I00587
num_objs 4
set04_V002_I01163
num_objs 2
set00_V000_I01769
num_objs 1
set01_V001_I00293
num_objs 4
set02_V009_I01655
num_objs 1
set00_V001_I00749
num_objs 1
set04_V005_I00026
num_objs 1
set01_V001_I00977
num_objs 1
set03_V003_I00299
num_objs 1
set01_V002_I01280
num_objs 4
set00_V012_I00395
num_objs 0
set03_V003_I00689
num_objs 0
set03_V011_I00704
num_objs 1
set01_V005_I00191
num_objs 2
set05_V000_I00725
num_objs 1
set05_V004_I00452
num_objs 2
set01_V003_I00878
num_objs 1
set00_V009_I00020
num_objs 1
set01_V000_I01019
num_objs 0
set01_V002_I00260
num_objs 7
set03_V005_I00620
num_objs 3
set01_V005_I01580
num_objs 0
set04_V003_I00158
num_objs 0
set00_V010_I01370
num_objs 4
set05_V011_I00551
num_objs 3
set05_V011_I00749
num_objs 0
set00_V002_I00428
num_objs 0
set04_V003_I00554
num_objs 0
set03_V003_I01544
num_objs 2
set03_V005_I00281
num_objs 1
set03_V008_I00524
num_objs 15
set00_V014_I00932
num_objs 3
set04_V003_I00254
num_objs 1
set03_V010_I01418
num_objs 2
set05_V011_I01022
num_objs 8
set05_V004_I00917
num_objs 1
set00_V011_I01019
num_objs 13
set04_V003_I01664
num_objs 1
set00_V010_I00224
num_objs 2
set05_V010_I00452
num_objs 1
set04_V002_I01289
num_objs 0
set04_V008_I00584
num_objs 1
set01_V000_I00194
num_objs 1
set01_V003_I01397
num_objs 1
set00_V008_I00197
num_objs 1
set02_V010_I00941
num_objs 1
set01_V004_I00719
num_objs 1
set00_V000_I00092
num_objs 1
set00_V002_I00962
num_objs 2
set03_V009_I00632
num_objs 3
set03_V011_I00341
num_objs 5
set03_V006_I00077
num_objs 1
set01_V004_I00902
num_objs 3
set00_V013_I00992
num_objs 1
set04_V004_I00578
num_objs 3
set02_V010_I01736
num_objs 1
set04_V003_I01688
num_objs 1
set00_V006_I00779
num_objs 2
set05_V002_I00701
num_objs 1
set04_V007_I01391
num_objs 1
set00_V001_I01058
num_objs 11
set00_V014_I00650
num_objs 3
set01_V003_I01739
num_objs 4
set00_V011_I00293
num_objs 2
set01_V002_I00683
num_objs 6
set00_V004_I00950
num_objs 2
set04_V007_I00491
num_objs 1
set04_V000_I00962
num_objs 1
set05_V010_I01076
num_objs 1
set04_V002_I01802
num_objs 1
set00_V008_I00209
num_objs 2
set00_V008_I00539
num_objs 9
set00_V009_I00896
num_objs 5
set00_V010_I01382
num_objs 3
set04_V001_I01667
num_objs 2
set04_V003_I01424
num_objs 3
set04_V004_I00962
num_objs 2
set03_V005_I01736
num_objs 2
set05_V010_I00470
num_objs 1
set04_V008_I00602
num_objs 1
set05_V011_I01061
num_objs 8
set00_V014_I00380
num_objs 4
set01_V003_I00632
num_objs 2
set04_V011_I01133
num_objs 1
set05_V003_I01010
num_objs 1
set00_V001_I01103
num_objs 8
set00_V007_I01859
num_objs 4
set01_V001_I01541
num_objs 9
set00_V014_I00146
num_objs 1
set00_V010_I00686
num_objs 2
set00_V007_I00524
num_objs 4
set00_V001_I00449
num_objs 1
set05_V000_I00401
num_objs 2
set00_V010_I01103
num_objs 2
set05_V005_I00689
num_objs 1
set00_V014_I00902
num_objs 4
set01_V003_I01664
num_objs 2
set04_V004_I01301
num_objs 1
set02_V010_I00509
num_objs 1
set05_V011_I00026
num_objs 1
set03_V005_I01022
num_objs 1
set00_V004_I00881
num_objs 2
set02_V010_I01289
num_objs 0
set00_V009_I01112
num_objs 1
set03_V009_I01487
num_objs 1
set05_V011_I01208
num_objs 3
set05_V008_I00218
num_objs 2
set05_V005_I00053
num_objs 4
set04_V003_I01553
num_objs 1
set01_V004_I00182
num_objs 1
set01_V002_I01463
num_objs 0
set02_V010_I00809
num_objs 0
set04_V002_I01175
num_objs 2
set05_V002_I00668
num_objs 1
set01_V005_I01721
num_objs 0
set00_V014_I01667
num_objs 4
set01_V003_I01511
num_objs 1
set05_V007_I01220
num_objs 1
set05_V002_I01559
num_objs 1
set05_V011_I01199
num_objs 1
set00_V012_I01394
num_objs 1
set00_V011_I00587
num_objs 3
set00_V006_I01229
num_objs 3
set00_V010_I00014
num_objs 5
set04_V004_I01637
num_objs 1
set04_V005_I01469
num_objs 0
set00_V011_I00479
num_objs 3
set04_V004_I00374
num_objs 1
set00_V000_I01733
num_objs 1
set00_V000_I00302
num_objs 1
set01_V002_I00848
num_objs 9
set04_V005_I00806
num_objs 1
set01_V005_I01382
num_objs 1
set00_V001_I00260
num_objs 5
set03_V003_I01415
num_objs 2
set03_V011_I00332
num_objs 5
set00_V009_I00071
num_objs 4
set03_V005_I00383
num_objs 1
set05_V011_I00872
num_objs 9
set04_V005_I01664
num_objs 1
set03_V009_I00887
num_objs 2
set01_V005_I00335
num_objs 3
set02_V008_I00539
num_objs 0
set05_V005_I00425
num_objs 1
set03_V012_I01211
num_objs 1
set01_V005_I01526
num_objs 0
set00_V011_I01349
num_objs 2
set00_V010_I00161
num_objs 1
set05_V001_I00368
num_objs 0
set04_V007_I00806
num_objs 2
set00_V008_I00449
num_objs 17
set00_V006_I00344
num_objs 4
set04_V003_I01388
num_objs 3
set01_V004_I00830
num_objs 3
set00_V004_I01001
num_objs 2
set04_V007_I01640
num_objs 1
set04_V003_I01709
num_objs 0
set03_V008_I01307
num_objs 3
set01_V003_I00581
num_objs 1
set01_V002_I01244
num_objs 4
set00_V009_I01577
num_objs 4
set00_V014_I01010
num_objs 3
set02_V009_I00854
num_objs 1
set04_V004_I00230
num_objs 2
set04_V003_I01802
num_objs 2
set04_V011_I01544
num_objs 1
set03_V005_I00242
num_objs 1
set00_V004_I01040
num_objs 1
set03_V009_I01574
num_objs 2
set03_V012_I01334
num_objs 4
set01_V004_I00659
num_objs 1
set00_V006_I00053
num_objs 2
set00_V009_I01448
num_objs 3
set02_V003_I00200
num_objs 1
set04_V007_I00584
num_objs 2
set03_V003_I01229
num_objs 0
set00_V004_I01676
num_objs 1
set05_V012_I00743
num_objs 2
set01_V001_I00212
num_objs 2
set03_V008_I01337
num_objs 3
set00_V001_I01091
num_objs 8
set00_V013_I00260
num_objs 4
set00_V012_I00224
num_objs 2
set02_V009_I00725
num_objs 2
set04_V003_I01628
num_objs 1
set04_V002_I00947
num_objs 2
set00_V012_I00419
num_objs 2
set00_V006_I00752
num_objs 0
set01_V001_I00068
num_objs 2
set03_V007_I00260
num_objs 1
set01_V000_I01265
num_objs 3
set00_V001_I01586
num_objs 4
set03_V009_I00977
num_objs 2
set04_V010_I00410
num_objs 1
set04_V007_I01361
num_objs 1
set00_V014_I01121
num_objs 3
set00_V013_I01163
num_objs 1
set00_V007_I00533
num_objs 4
set00_V006_I01061
num_objs 4
set00_V004_I00767
num_objs 1
set05_V010_I00662
num_objs 1
set03_V011_I00368
num_objs 5
set02_V009_I01418
num_objs 1
set02_V009_I00353
num_objs 2
set05_V010_I00986
num_objs 1
set01_V002_I01007
num_objs 1
set00_V004_I00554
num_objs 1
set00_V013_I01640
num_objs 2
set00_V007_I01526
num_objs 3
set03_V009_I01481
num_objs 1
set00_V004_I01541
num_objs 0
set00_V012_I00446
num_objs 0
set00_V001_I00638
num_objs 6
set05_V005_I00932
num_objs 1
set05_V011_I00698
num_objs 2
set01_V004_I00119
num_objs 2
set03_V009_I00683
num_objs 3
set01_V001_I01148
num_objs 3
set01_V005_I01031
num_objs 3
set02_V010_I00218
num_objs 1
set05_V002_I00524
num_objs 1
set04_V005_I01658
num_objs 1
set00_V009_I00353
num_objs 4
set05_V012_I00386
num_objs 3
set04_V010_I00863
num_objs 2
set00_V009_I01595
num_objs 4
set00_V010_I00038
num_objs 3
set05_V011_I01133
num_objs 4
set01_V001_I00158
num_objs 3
set01_V003_I00521
num_objs 3
set00_V014_I01433
num_objs 5
set02_V011_I01289
num_objs 0
set01_V001_I01172
num_objs 3
set02_V007_I00329
num_objs 0
set03_V008_I01451
num_objs 3
set01_V003_I00842
num_objs 2
set05_V011_I01031
num_objs 8
set00_V006_I01676
num_objs 0
set03_V011_I00434
num_objs 5
set01_V002_I00557
num_objs 8
set04_V010_I00548
num_objs 1
set00_V000_I01289
num_objs 1
set00_V013_I00254
num_objs 4
set00_V006_I00398
num_objs 4
set00_V014_I01124
num_objs 3
set03_V008_I00254
num_objs 18
set04_V000_I00578
num_objs 3
set05_V004_I00257
num_objs 1
set00_V014_I01388
num_objs 6
set00_V010_I00311
num_objs 4
set00_V006_I01283
num_objs 5
set05_V004_I00224
num_objs 3
set05_V011_I01529
num_objs 1
set02_V011_I00800
num_objs 0
set00_V009_I00164
num_objs 3
set04_V003_I01385
num_objs 3
set01_V000_I01637
num_objs 3
set05_V007_I01751
num_objs 0
set03_V009_I00989
num_objs 1
set00_V013_I00170
num_objs 4
set05_V007_I01382
num_objs 1
set02_V009_I00116
num_objs 1
set00_V010_I00434
num_objs 8
set00_V008_I00824
num_objs 1
set03_V008_I00017
num_objs 3
set01_V001_I01037
num_objs 1
set01_V004_I00800
num_objs 2
set01_V003_I00779
num_objs 3
set05_V012_I00728
num_objs 2
set05_V007_I01673
num_objs 0
set03_V005_I00509
num_objs 1
set01_V002_I00971
num_objs 3
set00_V006_I01874
num_objs 0
set01_V003_I00845
num_objs 1
set01_V000_I01160
num_objs 4
set05_V000_I00140
num_objs 5
set03_V008_I00110
num_objs 9
set04_V007_I01097
num_objs 2
set00_V012_I00833
num_objs 4
set00_V004_I01337
num_objs 1
set04_V011_I01847
num_objs 1
set00_V012_I01553
num_objs 2
set00_V014_I00611
num_objs 5
set02_V007_I00431
num_objs 1
set04_V005_I00140
num_objs 1
set00_V011_I00659
num_objs 1
set04_V010_I00926
num_objs 2
set00_V012_I00818
num_objs 3
set00_V012_I00500
num_objs 2
set00_V002_I00347
num_objs 1
set01_V003_I01301
num_objs 1
set02_V011_I00821
num_objs 0
set03_V011_I00608
num_objs 4
set00_V006_I00170
num_objs 3
set00_V007_I00950
num_objs 3
set04_V007_I00749
num_objs 0
set04_V007_I01598
num_objs 1
set02_V010_I01079
num_objs 0
set00_V008_I01226
num_objs 2
set05_V012_I00290
num_objs 1
set00_V001_I00305
num_objs 6
set00_V008_I00941
num_objs 1
set03_V008_I01079
num_objs 3
set05_V000_I01517
num_objs 1
set05_V001_I00338
num_objs 0
set00_V013_I01667
num_objs 1
set03_V003_I01067
num_objs 2
set00_V014_I00761
num_objs 3
set04_V005_I01013
num_objs 3
set01_V000_I00986
num_objs 0
set01_V000_I00935
num_objs 3
set00_V007_I00731
num_objs 2
set02_V010_I01016
num_objs 1
set00_V006_I00149
num_objs 2
set00_V008_I00017
num_objs 4
set00_V001_I00020
num_objs 2
set00_V000_I00371
num_objs 4
set02_V010_I01367
num_objs 1
set04_V002_I01088
num_objs 2
set03_V002_I01496
num_objs 1
set05_V010_I01823
num_objs 0
set04_V003_I01787
num_objs 2
set02_V009_I00662
num_objs 2
set03_V003_I00452
num_objs 1
set00_V001_I00101
num_objs 3
set01_V001_I01220
num_objs 10
set00_V006_I01916
num_objs 0
set00_V010_I01178
num_objs 2
set03_V005_I01019
num_objs 0
set00_V004_I01514
num_objs 0
set05_V003_I01616
num_objs 0
set03_V001_I00053
num_objs 1
set02_V003_I00263
num_objs 1
set00_V011_I00026
num_objs 5
set01_V003_I01010
num_objs 2
set00_V001_I00653
num_objs 3
set02_V011_I01679
num_objs 2
set03_V003_I00746
num_objs 2
set00_V006_I01475
num_objs 3
set02_V010_I00884
num_objs 1
set00_V013_I01052
num_objs 2
set00_V008_I01190
num_objs 0
set00_V012_I00569
num_objs 0
set05_V000_I00680
num_objs 1
set01_V001_I00452
num_objs 4
set00_V014_I01883
num_objs 1
set00_V013_I01403
num_objs 2
set03_V005_I01793
num_objs 2
set01_V004_I01280
num_objs 1
set05_V011_I01010
num_objs 8
set02_V003_I00002
num_objs 1
set03_V011_I00263
num_objs 4
set00_V008_I00527
num_objs 6
set00_V009_I01085
num_objs 1
set05_V005_I00464
num_objs 1
set04_V002_I01379
num_objs 2
set01_V003_I01079
num_objs 3
set05_V010_I01517
num_objs 1
set05_V003_I01376
num_objs 2
set03_V004_I00188
num_objs 1
set00_V001_I00863
num_objs 3
set00_V004_I01199
num_objs 8
set04_V006_I00965
num_objs 2
set00_V000_I01688
num_objs 2
set00_V004_I01049
num_objs 1
set03_V011_I00938
num_objs 1
set04_V005_I01238
num_objs 2
set02_V010_I01385
num_objs 1
set02_V011_I00836
num_objs 1
set02_V009_I00899
num_objs 1
set02_V008_I01220
num_objs 1
set04_V006_I00860
num_objs 2
set01_V004_I01532
num_objs 2
set04_V007_I00797
num_objs 2
set05_V012_I00281
num_objs 1
set01_V000_I01700
num_objs 2
set01_V003_I00800
num_objs 1
set03_V004_I00614
num_objs 1
set04_V007_I00518
num_objs 1
set00_V010_I00878
num_objs 2
set05_V009_I00860
num_objs 1
set03_V004_I00596
num_objs 1
set04_V011_I01634
num_objs 1
set01_V003_I00257
num_objs 4
set04_V010_I00719
num_objs 1
set04_V001_I01526
num_objs 1
set03_V010_I01337
num_objs 1
set01_V005_I01508
num_objs 0
set04_V003_I00410
num_objs 1
set03_V010_I01727
num_objs 3
set02_V007_I00416
num_objs 1
set03_V003_I00269
num_objs 1
set03_V003_I00524
num_objs 2
set04_V003_I01079
num_objs 3
set01_V002_I01736
num_objs 5
set00_V013_I00338
num_objs 5
set00_V010_I01439
num_objs 2
set00_V001_I00440
num_objs 1
set01_V001_I00356
num_objs 4
set00_V001_I00209
num_objs 1
set05_V011_I01217
num_objs 3
set00_V009_I00068
num_objs 3
set01_V004_I01565
num_objs 1
set05_V000_I00677
num_objs 1
set04_V005_I01607
num_objs 1
set02_V009_I01802
num_objs 1
set00_V002_I00533
num_objs 0
set00_V008_I01481
num_objs 0
set01_V004_I00962
num_objs 3
set00_V014_I00722
num_objs 3
set00_V012_I00281
num_objs 3
set03_V008_I00374
num_objs 19
set00_V001_I00482
num_objs 1
set04_V010_I00890
num_objs 2
set05_V009_I00821
num_objs 1
set04_V004_I01094
num_objs 2
set05_V007_I01442
num_objs 1
set05_V002_I00722
num_objs 1
set00_V001_I01733
num_objs 1
set01_V000_I00023
num_objs 1
set01_V000_I00803
num_objs 1
set03_V003_I01550
num_objs 2
set02_V009_I01574
num_objs 1
set04_V010_I00518
num_objs 1
set04_V003_I01790
num_objs 2
set05_V003_I01094
num_objs 1
set02_V007_I00311
num_objs 1
set05_V005_I01247
num_objs 1
set03_V010_I00158
num_objs 2
set01_V001_I00284
num_objs 3
set05_V005_I00962
num_objs 1
set02_V003_I00317
num_objs 1
set00_V011_I00194
num_objs 1
set00_V013_I01061
num_objs 2
set00_V004_I01007
num_objs 2
set02_V010_I01790
num_objs 1
set04_V001_I01730
num_objs 1
set00_V014_I00683
num_objs 3
set00_V014_I00968
num_objs 4
set02_V010_I00542
num_objs 2
set00_V006_I01082
num_objs 8
set02_V011_I01523
num_objs 2
set00_V004_I01022
num_objs 1
set01_V000_I01001
num_objs 0
set05_V003_I01403
num_objs 1
set00_V000_I01451
num_objs 1
set05_V007_I01646
num_objs 0
set04_V005_I01640
num_objs 2
set04_V000_I00890
num_objs 1
set04_V003_I00239
num_objs 1
set03_V005_I01043
num_objs 1
set04_V002_I01460
num_objs 2
set00_V006_I00185
num_objs 3
set00_V006_I01784
num_objs 0
set04_V004_I00503
num_objs 3
set01_V001_I01247
num_objs 11
set00_V008_I00065
num_objs 6
set03_V012_I00896
num_objs 1
set03_V008_I01367
num_objs 3
set00_V002_I00359
num_objs 1
set00_V003_I00362
num_objs 1
set02_V010_I00512
num_objs 2
set01_V002_I01016
num_objs 2
set00_V014_I00101
num_objs 4
set00_V003_I00167
num_objs 1
set04_V011_I01013
num_objs 2
set00_V012_I00470
num_objs 1
set01_V000_I00167
num_objs 1
set03_V011_I00974
num_objs 1
set00_V007_I01856
num_objs 6
set00_V009_I00443
num_objs 2
set00_V000_I01313
num_objs 1
set01_V001_I00389
num_objs 3
set03_V009_I00740
num_objs 2
set00_V013_I00479
num_objs 2
set03_V003_I01193
num_objs 2
set05_V007_I01337
num_objs 1
set00_V007_I01370
num_objs 4
set03_V005_I01583
num_objs 1
set04_V002_I01010
num_objs 2
set03_V003_I01310
num_objs 2
set00_V012_I01574
num_objs 2
set04_V005_I01100
num_objs 1
set04_V004_I00989
num_objs 2
set04_V003_I01514
num_objs 1
set01_V002_I01445
num_objs 0
set00_V011_I01238
num_objs 4
set03_V011_I01409
num_objs 1
set04_V001_I01556
num_objs 2
set01_V004_I01007
num_objs 3
set00_V011_I01424
num_objs 3
set04_V004_I01763
num_objs 1
set02_V009_I00122
num_objs 1
set05_V005_I00050
num_objs 4
set01_V004_I01253
num_objs 0
set00_V007_I00071
num_objs 1
set03_V012_I00986
num_objs 1
set01_V002_I00998
num_objs 1
set04_V001_I01709
num_objs 1
set04_V004_I01877
num_objs 1
set03_V011_I01364
num_objs 1
set04_V002_I00920
num_objs 1
set03_V008_I00488
num_objs 16
set01_V005_I01310
num_objs 1
set00_V004_I00464
num_objs 1
set03_V011_I00503
num_objs 5
set01_V004_I01163
num_objs 2
set05_V012_I00353
num_objs 3
set00_V001_I00413
num_objs 2
set00_V010_I00401
num_objs 7
set00_V008_I00221
num_objs 0
set05_V002_I01487
num_objs 1
set03_V009_I00827
num_objs 0
set04_V007_I01550
num_objs 1
set03_V005_I01589
num_objs 1
set01_V002_I00083
num_objs 4
set04_V005_I01283
num_objs 1
set04_V001_I01586
num_objs 2
set03_V009_I01757
num_objs 4
set00_V005_I00857
num_objs 1
set02_V010_I00665
num_objs 2
set00_V009_I00431
num_objs 2
set04_V007_I01232
num_objs 1
set03_V005_I01067
num_objs 1
set03_V009_I01325
num_objs 0
set02_V011_I01352
num_objs 2
set05_V003_I01607
num_objs 0
set01_V005_I00005
num_objs 2
set00_V004_I00236
num_objs 1
set05_V004_I00500
num_objs 1
set00_V011_I00440
num_objs 6
set00_V012_I00245
num_objs 3
set02_V007_I00380
num_objs 1
set04_V011_I00986
num_objs 2
set01_V005_I00533
num_objs 2
set01_V003_I01652
num_objs 2
set04_V002_I00728
num_objs 2
set00_V003_I00047
num_objs 1
set01_V000_I01604
num_objs 4
set05_V003_I01205
num_objs 3
set03_V003_I00197
num_objs 1
set01_V004_I01049
num_objs 2
set03_V011_I00524
num_objs 5
set00_V004_I00782
num_objs 1
set05_V001_I00425
num_objs 0
set00_V014_I00908
num_objs 3
set04_V005_I01631
num_objs 2
set01_V004_I01361
num_objs 1
set00_V006_I01172
num_objs 4
set00_V007_I00272
num_objs 6
set00_V009_I01256
num_objs 1
set00_V010_I00455
num_objs 8
set03_V008_I01250
num_objs 2
set00_V007_I01130
num_objs 9
set00_V007_I00167
num_objs 1
set00_V008_I00554
num_objs 6
set03_V003_I01424
num_objs 2
set01_V005_I01784
num_objs 0
set00_V000_I01481
num_objs 1
set03_V010_I01037
num_objs 3
set04_V007_I00926
num_objs 2
set03_V005_I01391
num_objs 1
set05_V000_I01544
num_objs 1
set00_V000_I00878
num_objs 0
set03_V011_I01448
num_objs 2
set04_V004_I01310
num_objs 1
set00_V011_I00149
num_objs 1
set04_V008_I01466
num_objs 1
set03_V008_I01289
num_objs 2
set00_V006_I01280
num_objs 5
set00_V000_I01031
num_objs 0
set03_V004_I00209
num_objs 0
set01_V005_I01742
num_objs 0
set05_V012_I00713
num_objs 2
set00_V006_I01847
num_objs 0
set00_V000_I01712
num_objs 2
set03_V008_I01157
num_objs 1
set00_V010_I00482
num_objs 5
set00_V009_I00269
num_objs 7
set03_V004_I00524
num_objs 1
set00_V007_I00659
num_objs 1
set04_V004_I01349
num_objs 1
set05_V010_I00932
num_objs 2
set01_V003_I01577
num_objs 1
set04_V003_I01421
num_objs 3
set04_V011_I01568
num_objs 1
set01_V001_I00923
num_objs 1
set00_V002_I00512
num_objs 0
set03_V003_I00830
num_objs 2
set05_V005_I00929
num_objs 1
set04_V003_I01253
num_objs 3
set00_V000_I00710
num_objs 2
set04_V007_I01436
num_objs 1
set05_V010_I01112
num_objs 1
set02_V001_I01601
num_objs 1
set00_V008_I00692
num_objs 3
set01_V002_I01577
num_objs 2
set03_V009_I01466
num_objs 0
set02_V001_I01430
num_objs 1
set03_V010_I01520
num_objs 3
set00_V003_I00506
num_objs 0
set05_V010_I01007
num_objs 1
set00_V001_I01292
num_objs 4
set04_V005_I00857
num_objs 1
set00_V000_I01790
num_objs 1
set03_V008_I00470
num_objs 16
set03_V005_I00959
num_objs 0
set04_V003_I01532
num_objs 1
set03_V009_I00317
num_objs 4
set05_V009_I00755
num_objs 1
set00_V008_I00323
num_objs 0
set02_V010_I00368
num_objs 1
set04_V004_I00113
num_objs 1
set02_V001_I01484
num_objs 1
set03_V010_I01664
num_objs 4
set00_V004_I00218
num_objs 1
set01_V002_I00209
num_objs 4
set05_V011_I00869
num_objs 4
set02_V010_I00527
num_objs 2
set05_V005_I00098
num_objs 5
set01_V003_I01742
num_objs 1
set00_V001_I00467
num_objs 1
set05_V010_I01508
num_objs 1
set05_V003_I01337
num_objs 2
set00_V009_I01616
num_objs 3
set03_V008_I01199
num_objs 0
set00_V010_I01061
num_objs 0
set01_V005_I00914
num_objs 2
set05_V002_I00602
num_objs 1
set04_V007_I01490
num_objs 1
set01_V002_I00974
num_objs 3
set02_V007_I00518
num_objs 1
set01_V003_I00764
num_objs 2
set02_V011_I00674
num_objs 2
set00_V002_I00212
num_objs 2
set03_V009_I00743
num_objs 2
set00_V002_I00515
num_objs 0
set04_V010_I01580
num_objs 2
set03_V005_I01757
num_objs 2
set03_V003_I01307
num_objs 2
set05_V012_I01229
num_objs 0
set04_V003_I00407
num_objs 1
set01_V000_I00269
num_objs 0
set03_V011_I00374
num_objs 5
set00_V008_I00911
num_objs 1
set04_V000_I00989
num_objs 0
set00_V011_I01151
num_objs 5
set01_V001_I00920
num_objs 1
set04_V000_I00920
num_objs 1
set02_V007_I00254
num_objs 1
set05_V011_I01565
num_objs 1
set00_V006_I00473
num_objs 3
set00_V010_I00695
num_objs 3
set02_V003_I00029
num_objs 0
set04_V007_I01778
num_objs 1
set01_V004_I01514
num_objs 2
set04_V000_I00659
num_objs 1
set01_V004_I00608
num_objs 3
set03_V005_I01478
num_objs 1
set00_V006_I00719
num_objs 4
set00_V001_I00833
num_objs 3
set05_V011_I00911
num_objs 9
set01_V004_I00218
num_objs 0
set02_V010_I01049
num_objs 0
set02_V009_I01733
num_objs 1
set05_V007_I01388
num_objs 1
set01_V001_I01463
num_objs 12
set03_V009_I01553
num_objs 2
set04_V003_I00431
num_objs 1
set05_V005_I00860
num_objs 2
set03_V012_I01463
num_objs 3
set02_V007_I00107
num_objs 1
set00_V001_I01745
num_objs 1
set04_V004_I00560
num_objs 3
set03_V005_I01091
num_objs 1
set00_V004_I01553
num_objs 0
set05_V008_I00227
num_objs 2
set00_V014_I01445
num_objs 4
set03_V009_I00926
num_objs 4
set01_V005_I00722
num_objs 2
set03_V003_I01103
num_objs 2
set00_V011_I01220
num_objs 3
set01_V005_I01142
num_objs 4
set03_V002_I01652
num_objs 2
set04_V002_I00113
num_objs 0
set00_V014_I01436
num_objs 5
set03_V010_I01643
num_objs 3
set01_V005_I00626
num_objs 3
set02_V011_I00710
num_objs 1
set04_V005_I01205
num_objs 1
set05_V000_I00233
num_objs 2
set00_V012_I00710
num_objs 0
set00_V008_I00854
num_objs 1
set05_V010_I00935
num_objs 2
set00_V006_I01277
num_objs 5
set00_V004_I01292
num_objs 0
set00_V012_I00662
num_objs 0
set01_V000_I00440
num_objs 3
set04_V003_I01004
num_objs 4
set04_V003_I01184
num_objs 3
set01_V002_I01685
num_objs 3
set00_V012_I01547
num_objs 2
set01_V005_I00422
num_objs 4
set00_V001_I00236
num_objs 6
set05_V010_I00938
num_objs 2
set05_V010_I00128
num_objs 1
set00_V006_I00239
num_objs 3
set03_V003_I00311
num_objs 1
set01_V003_I00593
num_objs 1
set03_V009_I01730
num_objs 4
set00_V003_I00083
num_objs 1
set00_V010_I01121
num_objs 2
set00_V002_I00842
num_objs 10
set03_V012_I01607
num_objs 3
set00_V008_I00743
num_objs 1
set00_V001_I00071
num_objs 2
set00_V011_I01415
num_objs 1
set00_V014_I00983
num_objs 3
set03_V012_I00848
num_objs 1
set00_V000_I00479
num_objs 1
set03_V010_I00908
num_objs 1
set01_V003_I01568
num_objs 1
set05_V011_I00017
num_objs 1
set00_V013_I00842
num_objs 2
set02_V009_I00224
num_objs 2
set00_V009_I01445
num_objs 2
set00_V002_I00794
num_objs 4
set00_V004_I01217
num_objs 0
set00_V000_I01181
num_objs 1
set00_V004_I00374
num_objs 2
set00_V011_I01331
num_objs 4
set00_V010_I01424
num_objs 4
set04_V004_I00269
num_objs 0
set03_V008_I00185
num_objs 11
set00_V010_I01550
num_objs 2
set00_V004_I01136
num_objs 0
set05_V012_I00302
num_objs 1
set00_V007_I01559
num_objs 3
set05_V012_I00344
num_objs 3
set03_V009_I01223
num_objs 2
set05_V005_I00020
num_objs 3
set01_V004_I00230
num_objs 1
set05_V009_I00854
num_objs 1
set05_V010_I00419
num_objs 1
set00_V014_I01766
num_objs 0
set02_V009_I01637
num_objs 2
set02_V011_I00506
num_objs 2
set05_V010_I00335
num_objs 1
set03_V005_I00884
num_objs 1
set03_V008_I01457
num_objs 3
set04_V002_I00842
num_objs 1
set00_V008_I00737
num_objs 2
set01_V001_I01562
num_objs 8
set04_V007_I01238
num_objs 1
set02_V011_I00272
num_objs 0
set00_V010_I01646
num_objs 0
set03_V008_I01784
num_objs 2
set03_V011_I00482
num_objs 5
set05_V012_I01121
num_objs 1
set01_V002_I01526
num_objs 0
set03_V011_I00353
num_objs 5
set04_V002_I01154
num_objs 2
set03_V005_I01040
num_objs 1
set02_V003_I00209
num_objs 0
set02_V009_I01508
num_objs 1
set04_V005_I01478
num_objs 1
set04_V005_I01139
num_objs 0
set00_V013_I00656
num_objs 3
set00_V009_I01331
num_objs 1
set01_V000_I01433
num_objs 4
set00_V010_I00383
num_objs 6
set00_V011_I00497
num_objs 5
set04_V007_I00686
num_objs 2
set00_V011_I00074
num_objs 4
set04_V000_I00713
num_objs 3
set00_V014_I01880
num_objs 1
set00_V008_I00176
num_objs 2
set01_V000_I00296
num_objs 1
set03_V008_I01778
num_objs 2
set00_V013_I00965
num_objs 1
set00_V011_I00674
num_objs 4
set00_V014_I01082
num_objs 2
set05_V011_I01298
num_objs 2
set04_V003_I00392
num_objs 1
set04_V011_I01184
num_objs 1
set03_V011_I00209
num_objs 2
set05_V007_I01628
num_objs 0
set03_V010_I01550
num_objs 3
set00_V013_I00212
num_objs 4
set00_V010_I00104
num_objs 4
set00_V012_I00920
num_objs 6
set00_V011_I00986
num_objs 10
set00_V007_I00854
num_objs 3
set00_V010_I00431
num_objs 8
set00_V013_I00761
num_objs 1
set01_V003_I00077
num_objs 5
set00_V012_I00929
num_objs 6
set03_V008_I01403
num_objs 3
set01_V003_I01040
num_objs 2
set03_V003_I01373
num_objs 2
set05_V011_I01640
num_objs 1
set00_V007_I00998
num_objs 2
set05_V005_I01130
num_objs 1
set04_V003_I01022
num_objs 4
set01_V005_I00089
num_objs 1
set01_V002_I00662
num_objs 7
set00_V014_I00461
num_objs 4
set02_V010_I00548
num_objs 2
set02_V009_I00872
num_objs 1
set00_V000_I01214
num_objs 2
set00_V007_I01532
num_objs 3
set01_V004_I00668
num_objs 2
set04_V008_I01448
num_objs 1
set03_V008_I00521
num_objs 15
set02_V009_I00404
num_objs 2
set01_V002_I00524
num_objs 8
set00_V008_I00335
num_objs 0
set01_V003_I00728
num_objs 2
set00_V014_I00596
num_objs 5
set05_V011_I00029
num_objs 0
set01_V001_I00986
num_objs 1
set05_V000_I00767
num_objs 1
set02_V010_I00422
num_objs 1
set05_V002_I01103
num_objs 1
set01_V003_I00824
num_objs 2
set02_V010_I01775
num_objs 1
set01_V002_I00251
num_objs 7
set03_V008_I01595
num_objs 2
set00_V010_I00821
num_objs 3
set03_V005_I01268
num_objs 2
set01_V002_I00215
num_objs 7
set03_V007_I01490
num_objs 0
set00_V001_I01118
num_objs 7
set00_V001_I01247
num_objs 5
set04_V006_I00713
num_objs 2
set00_V014_I01628
num_objs 4
set04_V002_I00665
num_objs 2
set02_V003_I00161
num_objs 1
set02_V008_I01292
num_objs 1
set00_V013_I01481
num_objs 4
set00_V007_I01439
num_objs 3
set05_V003_I01733
num_objs 0
set00_V002_I01211
num_objs 1
set01_V005_I01010
num_objs 3
set00_V012_I00563
num_objs 0
set05_V005_I00173
num_objs 0
set00_V000_I01307
num_objs 1
set03_V002_I01520
num_objs 1
set04_V003_I01280
num_objs 3
set00_V014_I01799
num_objs 6
set05_V002_I00092
num_objs 1
set03_V008_I01481
num_objs 2
set00_V001_I00602
num_objs 1
set00_V013_I00554
num_objs 3
set03_V010_I01589
num_objs 1
set05_V003_I01802
num_objs 0
set01_V001_I01739
num_objs 2
set03_V005_I00287
num_objs 1
set03_V005_I01592
num_objs 1
set02_V008_I01241
num_objs 1
set01_V002_I00995
num_objs 1
set04_V004_I00212
num_objs 1
set00_V012_I00851
num_objs 4
set00_V004_I00269
num_objs 0
set03_V009_I01682
num_objs 3
set00_V008_I00989
num_objs 3
set03_V012_I01472
num_objs 3
set05_V012_I00656
num_objs 1
set04_V007_I00791
num_objs 2
set00_V008_I01103
num_objs 0
set03_V010_I00920
num_objs 1
set00_V000_I00263
num_objs 5
set03_V003_I00011
num_objs 2
set03_V010_I01334
num_objs 1
set00_V013_I00890
num_objs 1
set05_V000_I00209
num_objs 2
set05_V007_I01589
num_objs 0
set01_V005_I00932
num_objs 3
set00_V004_I01316
num_objs 1
set00_V013_I01103
num_objs 4
set05_V011_I01361
num_objs 1
set00_V000_I01292
num_objs 1
set05_V003_I01649
num_objs 0
set05_V011_I01157
num_objs 5
set00_V009_I00218
num_objs 7
set04_V000_I00620
num_objs 3
set00_V014_I01226
num_objs 4
set04_V010_I01541
num_objs 2
set04_V007_I01106
num_objs 2
set01_V003_I00767
num_objs 2
set00_V006_I01721
num_objs 0
set02_V011_I00278
num_objs 0
set00_V008_I01301
num_objs 1
set01_V002_I01499
num_objs 1
set01_V000_I00848
num_objs 0
set05_V010_I00596
num_objs 1
set01_V002_I01031
num_objs 1
set00_V004_I01025
num_objs 0
set00_V012_I01424
num_objs 2
set00_V001_I01469
num_objs 1
set00_V003_I00032
num_objs 0
set01_V005_I01388
num_objs 1
set01_V005_I00110
num_objs 2
set00_V004_I00152
num_objs 1
set01_V001_I01130
num_objs 1
set00_V000_I00980
num_objs 0
set05_V000_I01421
num_objs 0
set03_V003_I00383
num_objs 1
set00_V006_I00083
num_objs 2
set00_V002_I00725
num_objs 2
set01_V005_I00854
num_objs 2
set04_V010_I00821
num_objs 1
set04_V004_I01019
num_objs 2
set03_V009_I00821
num_objs 0
set04_V002_I00785
num_objs 2
set04_V008_I01520
num_objs 1
set01_V004_I00515
num_objs 1
set00_V011_I01286
num_objs 3
set00_V001_I01178
num_objs 3
set01_V001_I01097
num_objs 1
set03_V009_I01115
num_objs 6
set00_V007_I00635
num_objs 3
set05_V011_I01238
num_objs 3
set05_V009_I00908
num_objs 1
set03_V011_I00326
num_objs 5
set02_V010_I00722
num_objs 2
set04_V005_I00161
num_objs 1
set02_V010_I01196
num_objs 1
set02_V010_I01181
num_objs 1
set00_V008_I00008
num_objs 4
set00_V007_I00665
num_objs 2
set02_V007_I00971
num_objs 1
set04_V007_I00470
num_objs 1
set00_V013_I00887
num_objs 1
set01_V001_I00965
num_objs 1
set04_V002_I00818
num_objs 1
set00_V010_I00794
num_objs 4
set01_V002_I01325
num_objs 7
set01_V000_I00341
num_objs 2
set00_V011_I01016
num_objs 11
set00_V011_I00557
num_objs 3
set02_V010_I00491
num_objs 1
set00_V010_I01553
num_objs 2
set01_V002_I00959
num_objs 2
set01_V001_I01418
num_objs 12
set00_V004_I01481
num_objs 0
set05_V012_I01091
num_objs 1
set00_V002_I01223
num_objs 1
set03_V008_I00950
num_objs 1
set04_V007_I01703
num_objs 1
set00_V011_I00500
num_objs 5
set04_V011_I01112
num_objs 2
set00_V013_I00740
num_objs 1
set01_V003_I00059
num_objs 14
set00_V004_I01121
num_objs 0
set03_V001_I00146
num_objs 1
set00_V011_I00737
num_objs 2
set00_V013_I00368
num_objs 4
set02_V011_I01628
num_objs 2
set04_V006_I01628
num_objs 2
set03_V003_I01262
num_objs 2
set03_V003_I00074
num_objs 2
set03_V005_I01595
num_objs 1
set00_V000_I01160
num_objs 0
set04_V007_I01184
num_objs 1
set01_V004_I00974
num_objs 1
set02_V009_I01127
num_objs 1
set03_V010_I01466
num_objs 2
set00_V004_I01010
num_objs 2
set05_V000_I01349
num_objs 0
set00_V006_I01589
num_objs 1
set03_V005_I00461
num_objs 2
set04_V003_I00305
num_objs 0
set04_V004_I01331
num_objs 1
set00_V012_I00398
num_objs 0
set03_V010_I01559
num_objs 1
set00_V000_I01691
num_objs 2
set04_V003_I01700
num_objs 1
set00_V004_I00797
num_objs 2
set04_V004_I01745
num_objs 1
set00_V012_I00275
num_objs 3
set01_V004_I00755
num_objs 3
set03_V005_I00512
num_objs 2
set05_V010_I00947
num_objs 1
set03_V008_I00368
num_objs 18
set01_V003_I01616
num_objs 1
set05_V011_I00515
num_objs 1
set00_V002_I00584
num_objs 0
set05_V000_I01379
num_objs 2
set01_V005_I01502
num_objs 0
set03_V005_I01550
num_objs 1
set04_V010_I00413
num_objs 1
set02_V009_I00482
num_objs 1
set00_V011_I00713
num_objs 4
set00_V014_I00515
num_objs 4
set00_V011_I00761
num_objs 1
set05_V000_I00692
num_objs 1
set04_V002_I00689
num_objs 1
set00_V006_I00599
num_objs 3
set00_V003_I00392
num_objs 0
set04_V004_I00161
num_objs 2
set03_V009_I00416
num_objs 3
set02_V010_I00950
num_objs 1
set04_V003_I01355
num_objs 3
set00_V013_I00185
num_objs 4
set03_V007_I00251
num_objs 1
set03_V008_I01124
num_objs 1
set00_V014_I00518
num_objs 5
set04_V007_I01736
num_objs 1
set05_V011_I00701
num_objs 2
set04_V005_I00281
num_objs 1
set04_V007_I00527
num_objs 1
set01_V004_I00557
num_objs 1
set04_V003_I01100
num_objs 3
set05_V011_I01007
num_objs 8
set04_V004_I00380
num_objs 1
set02_V011_I00683
num_objs 2
set03_V008_I00941
num_objs 1
set03_V007_I00353
num_objs 1
set00_V011_I01058
num_objs 10
set02_V010_I00356
num_objs 1
set00_V006_I00839
num_objs 0
set02_V009_I01481
num_objs 1
set03_V011_I01463
num_objs 2
set00_V007_I00218
num_objs 5
set01_V004_I00116
num_objs 2
set00_V001_I01109
num_objs 1
set01_V004_I01064
num_objs 3
set03_V005_I01730
num_objs 2
set02_V003_I00095
num_objs 1
set04_V003_I01751
num_objs 2
set03_V008_I00434
num_objs 19
set04_V007_I00674
num_objs 2
set05_V001_I00188
num_objs 1
set05_V011_I00722
num_objs 2
set04_V005_I01103
num_objs 1
set02_V008_I00584
num_objs 1
set05_V007_I01226
num_objs 1
set00_V014_I00368
num_objs 3
set01_V003_I00203
num_objs 7
set00_V006_I00518
num_objs 3
set05_V010_I00587
num_objs 1
set00_V014_I01241
num_objs 4
set00_V009_I01481
num_objs 2
set04_V004_I00998
num_objs 2
set00_V002_I00425
num_objs 0
set05_V012_I01202
num_objs 1
set00_V013_I01241
num_objs 1
set01_V001_I00470
num_objs 4
set00_V014_I00275
num_objs 3
set00_V013_I00650
num_objs 3
set02_V009_I01808
num_objs 1
set02_V008_I01001
num_objs 1
set04_V008_I01367
num_objs 1
set03_V003_I01208
num_objs 2
set00_V000_I00194
num_objs 3
set00_V013_I00458
num_objs 2
set04_V003_I00077
num_objs 0
set00_V012_I00725
num_objs 0
set03_V001_I00032
num_objs 1
set03_V005_I00881
num_objs 1
set03_V012_I01199
num_objs 0
set00_V004_I01091
num_objs 1
set04_V011_I01730
num_objs 1
set03_V003_I00146
num_objs 2
set04_V005_I01070
num_objs 3
set02_V011_I01520
num_objs 2
set00_V006_I00182
num_objs 3
set00_V009_I00023
num_objs 1
set00_V013_I00860
num_objs 2
set00_V011_I00644
num_objs 3
set04_V002_I01115
num_objs 2
set04_V003_I01505
num_objs 2
set02_V010_I00557
num_objs 2
set03_V005_I01274
num_objs 2
set05_V005_I00785
num_objs 1
set01_V000_I01181
num_objs 3
set02_V010_I00632
num_objs 2
set00_V013_I01208
num_objs 1
set00_V012_I00185
num_objs 1
set00_V010_I01331
num_objs 4
set02_V007_I00443
num_objs 1
set04_V005_I01064
num_objs 3
set01_V002_I00566
num_objs 8
set01_V005_I00836
num_objs 2
set01_V002_I00605
num_objs 7
set00_V010_I01637
num_objs 0
set04_V004_I01244
num_objs 2
set04_V007_I00458
num_objs 1
set00_V013_I00662
num_objs 2
set00_V013_I00569
num_objs 0
set00_V014_I01220
num_objs 4
set03_V011_I00302
num_objs 4
set01_V005_I00470
num_objs 4
set02_V010_I00302
num_objs 1
set03_V003_I01427
num_objs 2
set03_V003_I00110
num_objs 2
set04_V002_I00704
num_objs 3
set01_V000_I01319
num_objs 3
set01_V001_I00233
num_objs 1
set03_V012_I01289
num_objs 0
set05_V005_I00077
num_objs 5
set05_V009_I00767
num_objs 1
set04_V007_I00929
num_objs 1
set05_V005_I00191
num_objs 0
set04_V002_I01763
num_objs 1
set00_V001_I01244
num_objs 5
set05_V000_I00296
num_objs 3
set04_V007_I00629
num_objs 0
set00_V007_I00425
num_objs 6
set00_V007_I01451
num_objs 5
set00_V009_I00359
num_objs 2
set00_V014_I01712
num_objs 2
set04_V002_I01709
num_objs 2
set04_V010_I01535
num_objs 2
set04_V005_I00899
num_objs 0
set04_V002_I01685
num_objs 2
set00_V014_I00125
num_objs 2
set00_V000_I00674
num_objs 1
set04_V003_I01586
num_objs 1
set00_V008_I00932
num_objs 1
set05_V010_I00800
num_objs 1
set03_V003_I00113
num_objs 2
set01_V002_I00149
num_objs 4
set00_V013_I00026
num_objs 4
set00_V013_I01334
num_objs 4
set05_V009_I00776
num_objs 1
set02_V009_I01145
num_objs 1
set03_V003_I00287
num_objs 1
set00_V004_I00812
num_objs 2
set02_V010_I00203
num_objs 1
set04_V003_I01406
num_objs 3
set03_V005_I01697
num_objs 1
set00_V007_I01811
num_objs 4
set00_V001_I00743
num_objs 3
set00_V006_I01829
num_objs 1
set00_V006_I00251
num_objs 3
set03_V009_I00959
num_objs 2
set00_V010_I01676
num_objs 1
set00_V012_I00083
num_objs 1
set00_V007_I00461
num_objs 5
set04_V002_I01229
num_objs 1
set05_V010_I01643
num_objs 1
set00_V014_I01499
num_objs 2
set04_V004_I00980
num_objs 2
set03_V012_I01517
num_objs 3
set03_V008_I01700
num_objs 2
set05_V010_I00692
num_objs 1
set02_V009_I01616
num_objs 2
set00_V007_I00293
num_objs 6
set03_V009_I00233
num_objs 5
set00_V006_I00284
num_objs 3
set00_V008_I00797
num_objs 2
set00_V012_I01034
num_objs 2
set04_V011_I00992
num_objs 2
set01_V002_I00407
num_objs 5
set05_V012_I01211
num_objs 1
set04_V006_I00902
num_objs 2
set02_V011_I01718
num_objs 2
set00_V009_I00668
num_objs 2
set05_V005_I01157
num_objs 1
set03_V010_I01025
num_objs 3
set00_V009_I01622
num_objs 3
set00_V000_I01265
num_objs 1
set02_V010_I01247
num_objs 1
set02_V010_I01565
num_objs 1
set01_V002_I00278
num_objs 8
set00_V013_I00983
num_objs 1
set00_V000_I00392
num_objs 4
set05_V012_I00332
num_objs 1
set04_V001_I01748
num_objs 1
set02_V003_I00017
num_objs 0
set05_V000_I00641
num_objs 1
set00_V006_I00899
num_objs 1
set00_V006_I01907
num_objs 0
set04_V007_I00290
num_objs 1
set01_V000_I01460
num_objs 5
set05_V003_I01022
num_objs 1
set04_V007_I00842
num_objs 2
set02_V009_I00779
num_objs 1
set04_V000_I00545
num_objs 3
set02_V010_I00842
num_objs 2
set02_V008_I00536
num_objs 1
set01_V001_I00890
num_objs 1
set00_V010_I00287
num_objs 3
set00_V010_I01007
num_objs 0
set00_V013_I00518
num_objs 4
set03_V008_I00923
num_objs 1
set05_V011_I01445
num_objs 3
set01_V002_I00833
num_objs 8
set02_V011_I00680
num_objs 2
set03_V011_I00533
num_objs 5
set02_V007_I00962
num_objs 1
set02_V011_I01574
num_objs 2
set03_V011_I00356
num_objs 5
set05_V001_I00407
num_objs 0
set02_V010_I01205
num_objs 1
set00_V006_I00470
num_objs 3
set01_V001_I01262
num_objs 11
set05_V010_I00107
num_objs 1
set02_V007_I00332
num_objs 1
set01_V005_I00743
num_objs 2
set04_V007_I00614
num_objs 2
set01_V003_I01058
num_objs 1
set01_V003_I00911
num_objs 2
set00_V014_I00626
num_objs 4
set04_V003_I01172
num_objs 3
set00_V009_I01226
num_objs 1
set04_V001_I00179
num_objs 0
set03_V003_I00260
num_objs 1
set00_V007_I01829
num_objs 2
set01_V002_I00521
num_objs 7
set01_V002_I01373
num_objs 2
set04_V008_I01148
num_objs 1
set04_V002_I01718
num_objs 2
set01_V000_I00758
num_objs 1
set00_V006_I01316
num_objs 4
set04_V005_I00110
num_objs 1
set05_V000_I00710
num_objs 1
set00_V008_I00044
num_objs 7
set04_V008_I01400
num_objs 1
set02_V009_I00119
num_objs 0
set02_V011_I01463
num_objs 2
set00_V012_I01334
num_objs 0
set02_V010_I01286
num_objs 1
set05_V010_I01532
num_objs 2
set00_V010_I00035
num_objs 4
set05_V010_I01106
num_objs 1
set00_V013_I00164
num_objs 3
set04_V008_I01151
num_objs 1
set03_V004_I00053
num_objs 1
set00_V002_I00194
num_objs 2
set00_V011_I01565
num_objs 0
set02_V008_I01253
num_objs 1
set01_V004_I01568
num_objs 1
set04_V010_I00857
num_objs 2
set02_V003_I00338
num_objs 1
set00_V009_I01694
num_objs 0
set00_V007_I00500
num_objs 4
set03_V003_I01493
num_objs 2
set01_V005_I00989
num_objs 4
set04_V003_I01310
num_objs 4
set04_V003_I01040
num_objs 4
set05_V010_I00866
num_objs 1
set02_V010_I00347
num_objs 1
set05_V000_I00314
num_objs 4
set05_V004_I00887
num_objs 0
set02_V010_I01613
num_objs 1
set00_V007_I01616
num_objs 6
set00_V002_I00734
num_objs 2
set00_V006_I00197
num_objs 3
set02_V001_I00089
num_objs 0
set01_V003_I00245
num_objs 5
set00_V001_I00665
num_objs 3
set05_V002_I00434
num_objs 1
set04_V007_I00548
num_objs 1
set04_V007_I00530
num_objs 1
set00_V014_I01028
num_objs 3
set02_V011_I01568
num_objs 2
set05_V009_I00884
num_objs 1
set03_V009_I00428
num_objs 3
set04_V002_I00713
num_objs 3
set01_V002_I01163
num_objs 1
set02_V011_I01712
num_objs 2
set00_V014_I01553
num_objs 6
set00_V009_I00227
num_objs 7
set01_V000_I01145
num_objs 4
set05_V000_I00431
num_objs 2
set05_V005_I00584
num_objs 1
set02_V010_I00083
num_objs 1
set00_V012_I01241
num_objs 0
set00_V000_I00779
num_objs 0
set05_V012_I00545
num_objs 1
set03_V006_I00116
num_objs 1
set05_V007_I01217
num_objs 1
set00_V004_I00842
num_objs 1
set03_V011_I00296
num_objs 4
set03_V003_I00353
num_objs 1
set03_V007_I01541
num_objs 0
set05_V010_I01043
num_objs 1
set04_V000_I00560
num_objs 3
set01_V003_I00398
num_objs 3
set00_V013_I00032
num_objs 4
set05_V001_I00416
num_objs 0
set00_V011_I00728
num_objs 2
set05_V005_I00881
num_objs 1
set02_V009_I01835
num_objs 2
set03_V008_I00398
num_objs 19
set04_V007_I00308
num_objs 1
set00_V013_I01679
num_objs 0
set04_V007_I00668
num_objs 2
set02_V001_I01535
num_objs 1
set00_V001_I01694
num_objs 1
set02_V008_I01859
num_objs 0
set02_V009_I01268
num_objs 1
set04_V008_I01481
num_objs 1
set03_V003_I01031
num_objs 2
set00_V007_I01214
num_objs 7
set05_V012_I00503
num_objs 2
set03_V012_I00998
num_objs 1
set02_V007_I00146
num_objs 1
set01_V005_I00026
num_objs 2
set05_V003_I01319
num_objs 2
set00_V007_I00353
num_objs 5
set00_V013_I00173
num_objs 4
set01_V005_I00851
num_objs 2
set00_V013_I00677
num_objs 1
set05_V004_I00995
num_objs 1
set03_V006_I01811
num_objs 1
set05_V009_I00794
num_objs 1
set00_V012_I00617
num_objs 0
set00_V007_I00296
num_objs 6
set04_V011_I01766
num_objs 1
set04_V010_I00746
num_objs 1
set03_V003_I01130
num_objs 2
set05_V003_I01265
num_objs 3
set00_V001_I00791
num_objs 3
set05_V001_I00446
num_objs 0
set05_V012_I01136
num_objs 1
set02_V010_I00521
num_objs 2
set05_V000_I00326
num_objs 3
set02_V010_I00032
num_objs 0
set03_V008_I00293
num_objs 17
set00_V014_I00257
num_objs 2
set00_V009_I00950
num_objs 5
set00_V014_I00992
num_objs 3
set04_V008_I00629
num_objs 1
set03_V012_I01457
num_objs 3
set03_V005_I01646
num_objs 1
set00_V009_I00374
num_objs 3
set01_V001_I00815
num_objs 1
set05_V007_I01181
num_objs 1
set04_V007_I01448
num_objs 1
set04_V003_I00041
num_objs 0
set05_V001_I00149
num_objs 1
set03_V011_I00887
num_objs 1
set04_V008_I00605
num_objs 1
set05_V010_I01628
num_objs 1
set05_V012_I01082
num_objs 1
set04_V004_I01682
num_objs 2
set02_V010_I00254
num_objs 1
set02_V008_I01193
num_objs 0
set00_V014_I01826
num_objs 1
set00_V010_I00542
num_objs 6
set04_V003_I01301
num_objs 4
set03_V011_I01235
num_objs 1
set05_V004_I00179
num_objs 0
set02_V007_I00149
num_objs 1
set02_V011_I01607
num_objs 2
set01_V004_I00023
num_objs 2
set04_V005_I01091
num_objs 1
set03_V011_I00410
num_objs 5
set00_V014_I01811
num_objs 2
set05_V000_I01652
num_objs 1
set04_V007_I00305
num_objs 1
set00_V000_I00740
num_objs 2
set00_V006_I01853
num_objs 0
set04_V004_I01667
num_objs 3
set05_V011_I00500
num_objs 1
set02_V007_I00938
num_objs 1
set04_V004_I01760
num_objs 1
set01_V004_I01046
num_objs 3
set04_V003_I00062
num_objs 0
set05_V003_I01331
num_objs 2
set00_V008_I00191
num_objs 1
set05_V012_I01217
num_objs 1
set05_V005_I00296
num_objs 2
set05_V010_I00362
num_objs 1
set01_V003_I00473
num_objs 5
set00_V014_I01367
num_objs 7
set03_V005_I01574
num_objs 1
set03_V008_I00308
num_objs 18
set00_V009_I01565
num_objs 4
set03_V003_I01382
num_objs 2
set02_V009_I00338
num_objs 2
set00_V014_I01694
num_objs 3
set03_V003_I00620
num_objs 2
set00_V014_I01757
num_objs 0
set00_V009_I00458
num_objs 2
set00_V014_I00794
num_objs 5
set05_V003_I00971
num_objs 1
set04_V003_I00035
num_objs 0
set05_V003_I01199
num_objs 3
set05_V012_I00260
num_objs 1
set04_V003_I01538
num_objs 1
set04_V010_I01700
num_objs 2
set01_V004_I00983
num_objs 1
set05_V010_I00575
num_objs 1
set01_V004_I01154
num_objs 3
set03_V004_I00500
num_objs 1
set03_V009_I00539
num_objs 4
set05_V005_I00386
num_objs 1
set04_V007_I00275
num_objs 2
set04_V004_I00200
num_objs 2
set02_V010_I00251
num_objs 1
set00_V012_I00671
num_objs 0
set02_V009_I00395
num_objs 2
set05_V005_I00494
num_objs 2
set00_V001_I01535
num_objs 5
set04_V001_I00044
num_objs 1
set00_V009_I00044
num_objs 3
set00_V012_I00800
num_objs 2
set00_V004_I00134
num_objs 1
set02_V010_I00389
num_objs 1
set00_V012_I00620
num_objs 0
set03_V010_I01514
num_objs 2
set04_V005_I00908
num_objs 1
set04_V002_I00638
num_objs 1
set00_V014_I00239
num_objs 0
set00_V014_I01328
num_objs 6
set05_V002_I00626
num_objs 1
set05_V012_I01109
num_objs 0
set03_V008_I01541
num_objs 1
set04_V008_I01112
num_objs 1
set04_V000_I00626
num_objs 3
set05_V004_I00491
num_objs 2
set04_V004_I01382
num_objs 1
set00_V009_I01697
num_objs 0
set00_V014_I00053
num_objs 3
set01_V001_I01160
num_objs 3
set03_V011_I00920
num_objs 1
set01_V001_I01682
num_objs 2
set00_V006_I00896
num_objs 5
set03_V009_I00362
num_objs 4
set03_V011_I00581
num_objs 4
set05_V011_I01442
num_objs 3
set00_V014_I01151
num_objs 3
set00_V009_I01676
num_objs 1
set01_V001_I00260
num_objs 2
set03_V003_I00323
num_objs 1
set00_V008_I00392
num_objs 1
set00_V004_I01028
num_objs 0
set02_V010_I00926
num_objs 1
set00_V007_I00086
num_objs 1
set02_V010_I00284
num_objs 1
set03_V008_I00833
num_objs 2
set00_V012_I00962
num_objs 5
set02_V010_I01556
num_objs 1
set02_V009_I01361
num_objs 1
set01_V004_I00641
num_objs 4
set04_V004_I00281
num_objs 2
set01_V002_I00680
num_objs 6
set02_V009_I01277
num_objs 1
set03_V004_I00599
num_objs 1
set03_V006_I01754
num_objs 1
set00_V001_I01550
num_objs 3
set05_V005_I00758
num_objs 1
set00_V007_I01334
num_objs 7
set04_V003_I01247
num_objs 3
set00_V000_I00641
num_objs 0
set01_V001_I00959
num_objs 0
set00_V014_I01589
num_objs 1
set01_V003_I01733
num_objs 3
set04_V002_I01328
num_objs 2
set05_V000_I01400
num_objs 1
set05_V005_I00215
num_objs 0
set00_V006_I00176
num_objs 3
set00_V007_I01730
num_objs 4
set00_V014_I01751
num_objs 1
set03_V006_I00146
num_objs 1
set03_V010_I00944
num_objs 1
set01_V001_I01043
num_objs 1
set03_V009_I00737
num_objs 2
set04_V011_I01160
num_objs 1
set00_V007_I00833
num_objs 3
set04_V007_I01595
num_objs 1
set04_V010_I00545
num_objs 1
set00_V010_I00896
num_objs 2
set00_V014_I01853
num_objs 0
set00_V011_I00311
num_objs 2
set05_V000_I00776
num_objs 1
set03_V011_I00620
num_objs 4
set00_V007_I01574
num_objs 8
set03_V007_I01529
num_objs 0
set02_V007_I00215
num_objs 1
set00_V013_I00632
num_objs 3
set00_V007_I01502
num_objs 4
set04_V007_I01730
num_objs 1
set02_V010_I00620
num_objs 2
set00_V014_I00629
num_objs 8
set00_V014_I00845
num_objs 6
set03_V011_I01211
num_objs 1
set04_V007_I01544
num_objs 1
set03_V008_I01283
num_objs 3
set04_V001_I01550
num_objs 2
set00_V014_I01322
num_objs 6
set01_V000_I00137
num_objs 1
set05_V010_I00785
num_objs 1
set03_V008_I01346
num_objs 3
set00_V000_I00941
num_objs 0
set00_V007_I01547
num_objs 5
set00_V014_I01574
num_objs 5
set04_V002_I00917
num_objs 1
set00_V011_I00185
num_objs 2
set05_V010_I00884
num_objs 1
set01_V003_I00413
num_objs 3
set04_V002_I01721
num_objs 3
set00_V010_I01280
num_objs 3
set05_V005_I00449
num_objs 1
set05_V012_I00293
num_objs 1
set02_V009_I00512
num_objs 1
set03_V008_I00449
num_objs 12
set01_V001_I00680
num_objs 3
set04_V000_I00587
num_objs 3
set00_V008_I00098
num_objs 7
set00_V001_I00887
num_objs 3
set03_V009_I00689
num_objs 3
set00_V004_I00959
num_objs 1
set00_V013_I00113
num_objs 4
set00_V006_I00341
num_objs 4
set05_V011_I01673
num_objs 1
set01_V003_I00557
num_objs 1
set01_V003_I01361
num_objs 1
set03_V005_I00539
num_objs 3
set05_V010_I00719
num_objs 0
set02_V010_I00587
num_objs 2
set00_V013_I01289
num_objs 5
set04_V010_I01706
num_objs 2
set00_V009_I01667
num_objs 1
set01_V001_I01670
num_objs 2
set00_V000_I00749
num_objs 1
set00_V014_I01847
num_objs 0
set04_V003_I01559
num_objs 1
set00_V009_I00905
num_objs 4
set00_V010_I00698
num_objs 2
set00_V002_I00218
num_objs 2
set00_V010_I00110
num_objs 3
set05_V000_I00761
num_objs 1
set03_V009_I01670
num_objs 3
set00_V013_I00161
num_objs 3
set00_V007_I00779
num_objs 1
set05_V012_I00308
num_objs 1
set03_V006_I00038
num_objs 1
set01_V000_I00947
num_objs 2
set00_V004_I01109
num_objs 1
set04_V008_I00566
num_objs 1
set01_V002_I01610
num_objs 3
set01_V000_I00524
num_objs 2
set04_V007_I01541
num_objs 1
set03_V009_I01130
num_objs 5
set00_V014_I00485
num_objs 5
set04_V000_I00827
num_objs 1
set03_V005_I01709
num_objs 1
set04_V004_I00755
num_objs 2
set03_V005_I01385
num_objs 1
set04_V004_I00668
num_objs 2
set00_V009_I00845
num_objs 3
set00_V007_I01070
num_objs 4
set00_V006_I01049
num_objs 3
set05_V010_I00467
num_objs 1
set04_V005_I01184
num_objs 2
set00_V006_I01334
num_objs 4
set00_V006_I01748
num_objs 0
set03_V003_I00131
num_objs 2
set03_V001_I00821
num_objs 1
set02_V009_I00500
num_objs 1
set00_V010_I00338
num_objs 5
set01_V002_I00374
num_objs 5
set00_V011_I01226
num_objs 4
set02_V007_I00338
num_objs 1
set00_V011_I01289
num_objs 3
set01_V002_I00008
num_objs 3
set00_V012_I00698
num_objs 0
set04_V000_I00914
num_objs 1
set01_V000_I00212
num_objs 1
set03_V008_I00890
num_objs 1
set00_V012_I00713
num_objs 0
set00_V004_I00536
num_objs 1
set01_V005_I01019
num_objs 2
set00_V014_I00020
num_objs 3
set00_V010_I01076
num_objs 0
set00_V014_I01145
num_objs 3
set05_V011_I00653
num_objs 3
set05_V000_I00704
num_objs 1
set00_V006_I01517
num_objs 2
set04_V002_I01514
num_objs 3
set00_V012_I00020
num_objs 0
set05_V009_I00947
num_objs 1
set05_V010_I00074
num_objs 1
set00_V012_I01496
num_objs 1
set00_V008_I00440
num_objs 8
set01_V005_I00257
num_objs 1
set03_V010_I01073
num_objs 1
set00_V009_I00941
num_objs 4
set01_V005_I00941
num_objs 3
set01_V005_I00188
num_objs 2
set03_V003_I00401
num_objs 1
set00_V003_I00425
num_objs 1
set00_V010_I01136
num_objs 2
set00_V006_I01544
num_objs 2
set04_V002_I00800
num_objs 1
set02_V008_I00557
num_objs 1
set02_V007_I00503
num_objs 1
set04_V011_I01553
num_objs 1
set02_V009_I01199
num_objs 0
set04_V006_I00983
num_objs 1
set04_V007_I01655
num_objs 1
set00_V010_I00230
num_objs 2
set00_V009_I01247
num_objs 1
set03_V008_I01796
num_objs 1
set04_V004_I01874
num_objs 1
set00_V007_I01307
num_objs 8
set02_V010_I01199
num_objs 0
set02_V009_I01232
num_objs 2
set00_V014_I01208
num_objs 4
set03_V005_I01013
num_objs 1
set00_V012_I01265
num_objs 0
set05_V011_I01067
num_objs 8
set04_V001_I01625
num_objs 3
set05_V010_I00416
num_objs 1
set01_V003_I00638
num_objs 2
set00_V008_I00548
num_objs 5
set00_V000_I00296
num_objs 1
set01_V001_I01286
num_objs 11
set02_V001_I01523
num_objs 1
set00_V010_I01145
num_objs 2
set05_V011_I01499
num_objs 2
set00_V009_I00689
num_objs 4
set03_V008_I00956
num_objs 1
set03_V004_I00494
num_objs 1
set05_V003_I01280
num_objs 2
set04_V008_I01052
num_objs 1
set00_V009_I00899
num_objs 4
set05_V000_I00491
num_objs 3
set05_V001_I00464
num_objs 0
set01_V002_I00383
num_objs 5
set01_V004_I01115
num_objs 4
set00_V008_I00140
num_objs 3
set01_V000_I01592
num_objs 4
set00_V001_I01541
num_objs 3
set03_V003_I00935
num_objs 2
set00_V008_I00677
num_objs 3
set02_V009_I01055
num_objs 1
set03_V003_I00785
num_objs 2
set04_V008_I00557
num_objs 1
set02_V011_I01811
num_objs 2
set03_V002_I01475
num_objs 1
set01_V002_I00500
num_objs 6
set00_V000_I00389
num_objs 2
set00_V001_I01709
num_objs 1
set02_V010_I01133
num_objs 1
set04_V003_I00164
num_objs 0
set00_V001_I00452
num_objs 1
set05_V005_I00941
num_objs 1
set01_V002_I01475
num_objs 0
set00_V008_I00047
num_objs 6
set00_V010_I00995
num_objs 0
set04_V007_I01538
num_objs 1
set01_V000_I00650
num_objs 0
set03_V009_I00791
num_objs 2
set01_V005_I00296
num_objs 1
set04_V007_I01304
num_objs 1
set02_V009_I01352
num_objs 1
set05_V010_I00908
num_objs 2
set05_V010_I00353
num_objs 1
set00_V014_I01016
num_objs 3
set04_V007_I00338
num_objs 1
set03_V010_I01361
num_objs 2
set01_V005_I01058
num_objs 3
set05_V012_I01166
num_objs 1
set00_V012_I01616
num_objs 1
set04_V002_I01712
num_objs 2
set00_V012_I00461
num_objs 0
set05_V009_I00848
num_objs 1
set04_V003_I00959
num_objs 0
set01_V005_I00329
num_objs 3
set05_V000_I00734
num_objs 1
set00_V009_I00887
num_objs 6
set03_V003_I00812
num_objs 2
set00_V008_I01022
num_objs 2
set04_V004_I01433
num_objs 1
set00_V009_I01619
num_objs 3
set00_V000_I01643
num_objs 1
set05_V005_I00710
num_objs 1
set04_V004_I01640
num_objs 1
set05_V005_I00110
num_objs 3
set00_V008_I00614
num_objs 3
set01_V001_I00638
num_objs 3
set05_V011_I00725
num_objs 2
set00_V001_I01622
num_objs 2
set00_V014_I01229
num_objs 0
set05_V005_I00224
num_objs 0
set00_V008_I01334
num_objs 1
set01_V000_I01175
num_objs 3
set00_V013_I00191
num_objs 4
set00_V004_I01499
num_objs 8
set04_V001_I01700
num_objs 2
set01_V000_I00566
num_objs 2
set00_V001_I01499
num_objs 1
set00_V007_I01172
num_objs 9
set03_V009_I01724
num_objs 4
set00_V001_I00368
num_objs 5
set01_V005_I01427
num_objs 0
set04_V004_I00731
num_objs 2
set00_V000_I01466
num_objs 1
set03_V008_I01445
num_objs 3
set03_V008_I00338
num_objs 18
set00_V002_I00221
num_objs 2
set01_V000_I01187
num_objs 3
set00_V006_I00716
num_objs 2
set03_V009_I01520
num_objs 2
set01_V005_I01598
num_objs 0
set05_V007_I01631
num_objs 0
set00_V002_I00617
num_objs 0
set00_V011_I01022
num_objs 11
set04_V008_I01361
num_objs 1
set00_V002_I01220
num_objs 1
set03_V010_I01649
num_objs 0
set00_V001_I01718
num_objs 1
set01_V004_I01226
num_objs 0
set05_V007_I01466
num_objs 1
set00_V007_I01007
num_objs 1
set03_V009_I00512
num_objs 3
set03_V003_I01211
num_objs 2
set02_V010_I00089
num_objs 2
set05_V010_I00521
num_objs 1
set04_V001_I00050
num_objs 1
set01_V002_I00062
num_objs 3
set03_V004_I00035
num_objs 1
set00_V000_I00437
num_objs 6
set00_V007_I01283
num_objs 8
set01_V003_I01595
num_objs 1
set04_V002_I01151
num_objs 2
set00_V008_I01034
num_objs 3
set04_V005_I00722
num_objs 1
set04_V004_I00119
num_objs 0
set04_V004_I00716
num_objs 2
set00_V000_I01178
num_objs 1
set01_V000_I00407
num_objs 2
set02_V003_I00248
num_objs 1
set03_V009_I00035
num_objs 3
set05_V010_I01553
num_objs 1
set04_V002_I00974
num_objs 2
set05_V009_I00902
num_objs 1
set04_V003_I01361
num_objs 3
set05_V011_I01367
num_objs 1
set01_V005_I00356
num_objs 3
set00_V008_I01265
num_objs 2
set00_V012_I00482
num_objs 1
set02_V010_I01529
num_objs 0
set02_V009_I01499
num_objs 0
set00_V011_I00560
num_objs 3
set02_V010_I01823
num_objs 1
set00_V007_I01658
num_objs 6
set05_V005_I01172
num_objs 1
set00_V011_I00248
num_objs 1
set00_V013_I01238
num_objs 1
set00_V014_I00926
num_objs 3
set00_V004_I01424
num_objs 2
set03_V009_I00596
num_objs 4
set01_V001_I01181
num_objs 3
set02_V010_I01007
num_objs 1
set05_V005_I00782
num_objs 1
set03_V009_I00986
num_objs 2
set00_V008_I00755
num_objs 2
set00_V007_I01325
num_objs 7
set02_V009_I01271
num_objs 1
set04_V011_I00977
num_objs 2
set00_V000_I00311
num_objs 1
set04_V001_I01520
num_objs 1
set01_V005_I00845
num_objs 2
set00_V008_I00212
num_objs 1
set03_V009_I00095
num_objs 5
set04_V002_I00056
num_objs 1
set05_V012_I00470
num_objs 3
set03_V002_I01550
num_objs 1
set00_V012_I00278
num_objs 3
set05_V011_I01244
num_objs 3
set03_V011_I00644
num_objs 3
set02_V010_I01748
num_objs 1
set01_V000_I01244
num_objs 3
set04_V003_I00056
num_objs 0
set02_V010_I00986
num_objs 1
set02_V009_I01658
num_objs 1
set02_V009_I01634
num_objs 2
set03_V004_I00575
num_objs 1
set02_V010_I00227
num_objs 1
set03_V002_I01472
num_objs 1
set03_V008_I01484
num_objs 2
set00_V011_I00839
num_objs 0
set03_V003_I00458
num_objs 2
set00_V014_I01481
num_objs 4
set02_V010_I00371
num_objs 1
set00_V007_I01541
num_objs 4
set04_V010_I00881
num_objs 2
set00_V013_I00821
num_objs 2
set02_V009_I01238
num_objs 2
set00_V012_I01097
num_objs 0
set01_V000_I00383
num_objs 3
set01_V005_I01700
num_objs 0
set04_V005_I00725
num_objs 1
set01_V004_I01502
num_objs 2
set00_V008_I00761
num_objs 2
set05_V002_I00536
num_objs 1
set05_V010_I00782
num_objs 1
set00_V008_I01121
num_objs 0
set00_V007_I00650
num_objs 2
set04_V007_I00281
num_objs 2
set02_V008_I01148
num_objs 0
set01_V002_I01595
num_objs 3
set03_V005_I00698
num_objs 1
set00_V007_I00197
num_objs 4
set04_V002_I00941
num_objs 2
set00_V012_I01007
num_objs 2
set00_V001_I00284
num_objs 5
set02_V009_I01406
num_objs 1
set00_V014_I00266
num_objs 2
set00_V008_I00164
num_objs 3
set00_V009_I00764
num_objs 3
set01_V000_I00272
num_objs 1
set00_V010_I01556
num_objs 2
set04_V011_I01484
num_objs 1
set05_V000_I01385
num_objs 2
set03_V005_I01325
num_objs 1
set03_V006_I01796
num_objs 1
set02_V010_I00461
num_objs 1
set01_V000_I00062
num_objs 3
set02_V010_I00305
num_objs 1
set02_V001_I01604
num_objs 1
set03_V012_I01496
num_objs 3
set00_V013_I01568
num_objs 4
set04_V005_I00188
num_objs 1
set00_V006_I00218
num_objs 3
set03_V010_I01421
num_objs 2
set00_V014_I01451
num_objs 4
set02_V011_I01535
num_objs 2
set00_V000_I01193
num_objs 1
set03_V011_I00599
num_objs 3
set04_V000_I00542
num_objs 2
set04_V011_I01043
num_objs 2
set00_V001_I00119
num_objs 0
set02_V009_I01079
num_objs 0
set00_V004_I01205
num_objs 0
set00_V007_I01805
num_objs 3
set01_V002_I00602
num_objs 7
set04_V007_I01535
num_objs 1
set01_V004_I00032
num_objs 2
set03_V010_I01802
num_objs 2
set04_V004_I00815
num_objs 2
set00_V004_I01511
num_objs 0
set00_V006_I00866
num_objs 3
set00_V010_I01202
num_objs 2
set00_V008_I00167
num_objs 3
set03_V001_I00179
num_objs 0
set01_V005_I01259
num_objs 0
set04_V002_I01391
num_objs 3
set00_V007_I00263
num_objs 6
set00_V002_I00383
num_objs 0
set00_V010_I00326
num_objs 5
set04_V002_I01694
num_objs 2
set00_V003_I00044
num_objs 1
set00_V000_I01670
num_objs 2
set04_V004_I00329
num_objs 0
set03_V011_I01475
num_objs 1
set03_V003_I00929
num_objs 0
set00_V011_I00344
num_objs 2
set03_V011_I00428
num_objs 5
set00_V004_I01430
num_objs 2
set04_V001_I01790
num_objs 1
set00_V006_I01856
num_objs 0
set01_V005_I01811
num_objs 0
set03_V011_I00440
num_objs 5
set00_V007_I00953
num_objs 3
set00_V000_I00539
num_objs 1
set04_V000_I00488
num_objs 2
set05_V004_I00212
num_objs 3
set03_V008_I01412
num_objs 3
set05_V005_I00554
num_objs 1
set01_V001_I00752
num_objs 2
set05_V005_I00482
num_objs 2
set03_V003_I01337
num_objs 2
set05_V007_I01724
num_objs 0
set00_V006_I00509
num_objs 2
set01_V000_I01391
num_objs 3
set02_V007_I00494
num_objs 1
set00_V006_I01769
num_objs 1
set00_V007_I01382
num_objs 3
set02_V010_I00638
num_objs 2
set04_V005_I01055
num_objs 3
set01_V002_I00887
num_objs 5
set03_V011_I00923
num_objs 1
set00_V012_I00386
num_objs 0
set00_V012_I00008
num_objs 0
set04_V004_I01385
num_objs 1
set02_V011_I00827
num_objs 1
set03_V011_I00989
num_objs 0
set05_V002_I00605
num_objs 1
set00_V000_I00227
num_objs 5
set00_V009_I00971
num_objs 5
set04_V003_I00497
num_objs 0
set02_V011_I00554
num_objs 2
set04_V005_I00989
num_objs 1
set01_V002_I00941
num_objs 4
set00_V011_I01343
num_objs 3
set00_V003_I00149
num_objs 1
set04_V003_I00203
num_objs 0
set00_V000_I00230
num_objs 5
set05_V005_I00701
num_objs 1
set03_V008_I01016
num_objs 1
set05_V001_I00362
num_objs 0
set03_V001_I00170
num_objs 1
set00_V014_I01793
num_objs 1
set04_V007_I00800
num_objs 2
set02_V009_I00653
num_objs 2
set02_V009_I00323
num_objs 2
set03_V009_I01793
num_objs 4
set04_V003_I01103
num_objs 3
set00_V013_I01301
num_objs 3
set00_V010_I00164
num_objs 1
set04_V010_I00905
num_objs 2
set03_V003_I00578
num_objs 2
set05_V005_I00527
num_objs 1
set03_V010_I01583
num_objs 3
set05_V002_I00773
num_objs 1
set01_V001_I00632
num_objs 3
set01_V002_I01379
num_objs 2
set04_V007_I00515
num_objs 1
set00_V000_I00728
num_objs 2
set03_V009_I01628
num_objs 2
set03_V008_I00965
num_objs 1
set03_V002_I01664
num_objs 2
set04_V006_I00833
num_objs 2
set04_V005_I01604
num_objs 2
set01_V001_I00275
num_objs 2
set03_V001_I00077
num_objs 1
set01_V004_I00110
num_objs 2
set00_V007_I00587
num_objs 4
set02_V010_I00818
num_objs 2
set05_V000_I01613
num_objs 1
set05_V004_I00182
num_objs 3
set02_V008_I01181
num_objs 0
set00_V005_I00821
num_objs 1
set05_V011_I00704
num_objs 2
set04_V010_I01649
num_objs 1
set00_V006_I01463
num_objs 4
set03_V005_I01079
num_objs 1
set05_V007_I01355
num_objs 1
set01_V005_I01685
num_objs 0
set02_V008_I00509
num_objs 0
set04_V005_I01268
num_objs 1
set00_V000_I00443
num_objs 5
set04_V010_I00848
num_objs 2
set03_V006_I00089
num_objs 0
set01_V004_I01367
num_objs 1
set00_V012_I01529
num_objs 0
set04_V011_I01739
num_objs 1
set01_V002_I01301
num_objs 5
set01_V000_I00548
num_objs 2
set05_V011_I01142
num_objs 4
set00_V003_I00068
num_objs 0
set01_V003_I00359
num_objs 2
set00_V008_I00218
num_objs 0
set01_V004_I00671
num_objs 2
set01_V002_I00791
num_objs 7
set00_V008_I00653
num_objs 3
set00_V006_I00389
num_objs 4
set04_V007_I01772
num_objs 1
set00_V001_I00407
num_objs 2
set00_V002_I00839
num_objs 8
set02_V007_I00446
num_objs 1
set03_V012_I01325
num_objs 4
set02_V010_I01217
num_objs 1
set02_V011_I01814
num_objs 2
set01_V002_I01250
num_objs 4
set03_V004_I00581
num_objs 1
set00_V010_I01604
num_objs 0
set00_V010_I00776
num_objs 3
set00_V001_I00053
num_objs 0
set05_V003_I01313
num_objs 2
set01_V001_I00557
num_objs 4
set05_V003_I01187
num_objs 3
set03_V004_I00098
num_objs 1
set02_V009_I01502
num_objs 1
set00_V013_I00128
num_objs 4
set00_V007_I00062
num_objs 0
set02_V009_I01325
num_objs 1
set03_V003_I00974
num_objs 2
set00_V007_I01154
num_objs 8
set00_V006_I01775
num_objs 0
set03_V009_I01085
num_objs 6
set05_V003_I01355
num_objs 2
set03_V011_I00713
num_objs 1
set03_V009_I00305
num_objs 3
set00_V014_I00548
num_objs 5
set02_V010_I01082
num_objs 1
set00_V009_I00326
num_objs 5
set03_V009_I00581
num_objs 4
set04_V004_I01751
num_objs 1
set03_V011_I00200
num_objs 3
set03_V004_I00152
num_objs 1
set04_V008_I01004
num_objs 1
set00_V014_I00986
num_objs 3
set00_V013_I01331
num_objs 4
set03_V005_I01520
num_objs 1
set00_V014_I00680
num_objs 3
set02_V011_I00362
num_objs 2
set00_V009_I00929
num_objs 3
set04_V004_I00488
num_objs 3
set01_V000_I01211
num_objs 3
set01_V004_I01127
num_objs 4
set00_V006_I00542
num_objs 3
set00_V006_I00035
num_objs 2
set05_V003_I01727
num_objs 0
set02_V010_I00164
num_objs 1
set04_V002_I01739
num_objs 3
set00_V010_I01313
num_objs 3
set01_V005_I00935
num_objs 3
set00_V010_I01514
num_objs 3
set05_V012_I00446
num_objs 3
set04_V005_I00221
num_objs 1
set04_V007_I00608
num_objs 2
set05_V004_I00143
num_objs 3
set05_V002_I00731
num_objs 1
set00_V006_I01550
num_objs 2
set01_V004_I00662
num_objs 2
set00_V000_I00938
num_objs 0
set00_V006_I01490
num_objs 3
set00_V009_I00539
num_objs 2
set05_V000_I00731
num_objs 1
set04_V010_I00941
num_objs 1
set03_V008_I01685
num_objs 2
set03_V003_I00278
num_objs 1
set00_V007_I00416
num_objs 6
set05_V002_I00767
num_objs 1
set01_V005_I00785
num_objs 2
set04_V001_I01673
num_objs 2
set00_V007_I01589
num_objs 4
set01_V002_I01484
num_objs 0
set02_V010_I01424
num_objs 1
set04_V005_I00761
num_objs 1
set00_V014_I00194
num_objs 1
set00_V011_I01025
num_objs 10
set00_V001_I00134
num_objs 1
set04_V004_I00083
num_objs 1
set04_V007_I00344
num_objs 1
set00_V011_I01466
num_objs 4
set00_V009_I01205
num_objs 1
set05_V005_I00842
num_objs 2
set03_V005_I01487
num_objs 1
set01_V003_I00620
num_objs 1
set01_V002_I01520
num_objs 0
set01_V003_I00803
num_objs 1
set00_V007_I00599
num_objs 1
set04_V000_I00515
num_objs 2
set00_V007_I01655
num_objs 6
set01_V004_I00308
num_objs 0
set03_V003_I00686
num_objs 2
set00_V006_I00890
num_objs 6
set04_V004_I00656
num_objs 2
set01_V005_I01433
num_objs 0
set04_V002_I01259
num_objs 1
set00_V007_I01517
num_objs 3
set00_V008_I00398
num_objs 1
set05_V011_I00038
num_objs 1
set01_V005_I00344
num_objs 3
set03_V008_I00020
num_objs 3
set03_V003_I00062
num_objs 2
set05_V004_I01016
num_objs 1
set04_V004_I00809
num_objs 3
set01_V004_I00278
num_objs 2
set00_V002_I01046
num_objs 0
set01_V004_I00263
num_objs 2
set01_V000_I00449
num_objs 1
set00_V005_I00860
num_objs 1
set02_V009_I01355
num_objs 1
set03_V003_I00581
num_objs 2
set03_V005_I01493
num_objs 1
set00_V001_I01478
num_objs 5
set03_V011_I01451
num_objs 2
set04_V007_I00830
num_objs 2
set04_V004_I00233
num_objs 2
set05_V003_I01220
num_objs 3
set04_V004_I00929
num_objs 2
set01_V001_I01634
num_objs 5
set02_V011_I00551
num_objs 2
set04_V006_I00641
num_objs 2
set00_V007_I00716
num_objs 1
set03_V012_I01616
num_objs 3
set00_V011_I00602
num_objs 3
set00_V002_I00539
num_objs 0
set04_V007_I01181
num_objs 1
set00_V004_I00806
num_objs 2
set01_V002_I00920
num_objs 4
set05_V000_I01370
num_objs 2
set01_V003_I01034
num_objs 2
set04_V004_I00404
num_objs 2
set00_V010_I00638
num_objs 4
set01_V001_I01469
num_objs 4
set00_V010_I01112
num_objs 2
set00_V013_I00920
num_objs 1
set00_V009_I00671
num_objs 2
set01_V004_I01070
num_objs 3
set04_V003_I01571
num_objs 1
set00_V001_I01460
num_objs 4
set05_V011_I01370
num_objs 2
set04_V006_I00602
num_objs 1
set00_V007_I00776
num_objs 2
set00_V002_I00458
num_objs 0
set00_V002_I00674
num_objs 1
set03_V010_I01595
num_objs 2
set03_V002_I01559
num_objs 1
set04_V007_I01652
num_objs 1
set01_V002_I00827
num_objs 8
set03_V003_I01532
num_objs 2
set03_V012_I01388
num_objs 5
set00_V002_I00380
num_objs 1
set04_V000_I00899
num_objs 1
set00_V011_I00953
num_objs 9
set00_V001_I01298
num_objs 4
set00_V001_I00929
num_objs 3
set00_V010_I01472
num_objs 4
set00_V011_I01292
num_objs 3
set04_V008_I01031
num_objs 1
set05_V000_I00749
num_objs 1
set00_V014_I00953
num_objs 3
set00_V007_I00485
num_objs 5
set02_V003_I00104
num_objs 1
set04_V006_I00638
num_objs 1
set04_V003_I00137
num_objs 0
set02_V010_I00152
num_objs 1
set00_V012_I00452
num_objs 0
set00_V007_I01256
num_objs 8
set00_V000_I00506
num_objs 1
set01_V000_I00260
num_objs 1
set01_V001_I01370
num_objs 9
set00_V014_I01832
num_objs 1
set03_V005_I01196
num_objs 3
set01_V000_I01043
num_objs 1
set04_V001_I01496
num_objs 1
set03_V009_I00269
num_objs 4
set03_V010_I01046
num_objs 3
set00_V008_I01217
num_objs 2
set01_V004_I01559
num_objs 0
set00_V004_I00248
num_objs 1
set04_V003_I01097
num_objs 4
set05_V002_I00512
num_objs 1
set04_V004_I01274
num_objs 1
set03_V011_I00344
num_objs 5
set04_V001_I00176
num_objs 1
set00_V001_I00689
num_objs 2
set00_V001_I00869
num_objs 1
set00_V001_I00392
num_objs 3
set01_V001_I00497
num_objs 3
set01_V005_I00254
num_objs 1
set03_V009_I00716
num_objs 2
set00_V006_I01760
num_objs 1
set00_V011_I00221
num_objs 1
set04_V007_I01025
num_objs 2
set05_V010_I01829
num_objs 0
set02_V010_I01580
num_objs 1
set01_V005_I00095
num_objs 2
set00_V007_I01094
num_objs 7
set00_V006_I00836
num_objs 2
set03_V008_I01472
num_objs 3
set04_V004_I01028
num_objs 2
set00_V014_I01169
num_objs 0
set01_V000_I01436
num_objs 5
set03_V012_I01367
num_objs 4
set01_V004_I01469
num_objs 2
set00_V012_I00821
num_objs 4
set00_V003_I00146
num_objs 2
set05_V009_I00980
num_objs 1
set03_V009_I01721
num_objs 4
set01_V004_I00677
num_objs 2
set00_V008_I00410
num_objs 2
set00_V004_I00131
num_objs 1
set04_V011_I01151
num_objs 1
set03_V005_I01001
num_objs 1
set00_V014_I01721
num_objs 2
set03_V002_I01571
num_objs 1
set04_V001_I01706
num_objs 2
set01_V005_I00917
num_objs 3
set00_V014_I01166
num_objs 3
set04_V008_I01394
num_objs 1
set03_V011_I01379
num_objs 1
set05_V012_I00428
num_objs 3
set01_V001_I00359
num_objs 2
set00_V009_I00002
num_objs 1
set02_V010_I01172
num_objs 1
set05_V011_I01472
num_objs 3
set00_V004_I01484
num_objs 0
set00_V002_I00551
num_objs 0
set01_V000_I00356
num_objs 2
set01_V003_I00698
num_objs 2
set00_V008_I00536
num_objs 6
set04_V011_I01064
num_objs 2
set00_V001_I00809
num_objs 1
set05_V010_I00446
num_objs 1
set00_V009_I00722
num_objs 3
set05_V005_I01262
num_objs 1
set00_V004_I00272
num_objs 1
set00_V010_I01493
num_objs 3
set00_V010_I00575
num_objs 5
set05_V011_I01544
num_objs 1
set00_V006_I00311
num_objs 4
set00_V006_I00119
num_objs 3
set02_V011_I00491
num_objs 2
set01_V005_I00038
num_objs 2
set02_V010_I01763
num_objs 2
set04_V004_I00197
num_objs 2
set02_V010_I00590
num_objs 2
set00_V012_I00416
num_objs 0
set00_V011_I01250
num_objs 3
set02_V010_I01484
num_objs 2
set02_V010_I00815
num_objs 2
set05_V012_I01022
num_objs 1
set04_V005_I00047
num_objs 1
set01_V000_I00977
num_objs 0
set03_V003_I00695
num_objs 2
set05_V011_I01649
num_objs 1
set03_V008_I01604
num_objs 2
set00_V014_I00092
num_objs 4
set02_V009_I01673
num_objs 1
set00_V000_I00797
num_objs 0
set03_V005_I00554
num_objs 3
set00_V014_I00887
num_objs 4
set00_V011_I01550
num_objs 0
set03_V011_I00632
num_objs 3
set03_V010_I01007
num_objs 3
set03_V003_I00455
num_objs 1
set04_V007_I00758
num_objs 2
set00_V009_I01004
num_objs 4
set00_V009_I00752
num_objs 3
set01_V001_I00476
num_objs 3
set03_V006_I01760
num_objs 1
set00_V001_I01685
num_objs 2
set03_V010_I00791
num_objs 0
set01_V003_I00941
num_objs 2
set04_V003_I01010
num_objs 4
set00_V007_I00368
num_objs 5
set04_V007_I01061
num_objs 2
set02_V008_I01172
num_objs 0
set01_V005_I00242
num_objs 1
set00_V002_I00935
num_objs 2
set00_V014_I00077
num_objs 4
set05_V000_I00134
num_objs 5
set03_V011_I00977
num_objs 1
set03_V011_I00692
num_objs 1
set03_V005_I01379
num_objs 1
set00_V008_I00887
num_objs 1
set00_V004_I01184
num_objs 0
set04_V010_I00626
num_objs 1
set02_V010_I00125
num_objs 0
set03_V002_I01613
num_objs 1
set03_V011_I00767
num_objs 2
set03_V008_I00665
num_objs 4
set04_V003_I01733
num_objs 2
set04_V008_I01478
num_objs 1
set01_V004_I00905
num_objs 3
set00_V000_I00368
num_objs 5
set05_V010_I00611
num_objs 1
set04_V007_I01001
num_objs 2
set00_V006_I01412
num_objs 4
set04_V003_I01370
num_objs 3
set05_V010_I00740
num_objs 1
set03_V012_I00875
num_objs 1
set04_V007_I01250
num_objs 1
set03_V002_I01541
num_objs 1
set04_V002_I00137
num_objs 0
set00_V010_I01187
num_objs 2
set04_V002_I00038
num_objs 1
set01_V003_I00365
num_objs 3
set02_V011_I00356
num_objs 3
set00_V011_I01274
num_objs 3
set00_V013_I01235
num_objs 1
set04_V006_I01097
num_objs 1
set05_V002_I01493
num_objs 1
set00_V012_I00494
num_objs 2
set03_V009_I00797
num_objs 2
set03_V009_I01061
num_objs 6
set03_V005_I01184
num_objs 3
set04_V003_I00269
num_objs 1
set05_V010_I00845
num_objs 1
set00_V011_I00836
num_objs 0
set02_V011_I00557
num_objs 2
set05_V000_I00116
num_objs 2
set03_V003_I00938
num_objs 2
set00_V008_I01460
num_objs 2
set00_V000_I00422
num_objs 5
set00_V009_I01475
num_objs 2
set03_V010_I01604
num_objs 2
set00_V004_I00473
num_objs 1
set02_V011_I00368
num_objs 2
set00_V013_I01646
num_objs 2
set04_V003_I01589
num_objs 1
set05_V000_I00479
num_objs 1
set05_V000_I00245
num_objs 2
set03_V002_I01493
num_objs 1
set02_V008_I00530
num_objs 1
set00_V000_I01514
num_objs 1
set04_V010_I00830
num_objs 1
set02_V011_I01496
num_objs 2
set00_V006_I01355
num_objs 4
set04_V003_I01325
num_objs 4
set03_V011_I01472
num_objs 1
set05_V011_I00731
num_objs 2
set04_V004_I00695
num_objs 2
set00_V006_I00767
num_objs 0
set01_V004_I01109
num_objs 1
set03_V003_I00539
num_objs 1
set01_V004_I00020
num_objs 2
set04_V005_I01199
num_objs 0
set00_V006_I01244
num_objs 7
set00_V006_I01850
num_objs 0
set00_V010_I01406
num_objs 3
set01_V002_I00674
num_objs 6
set03_V011_I00359
num_objs 3
set00_V010_I00911
num_objs 2
set05_V012_I00683
num_objs 1
set00_V006_I00302
num_objs 4
set03_V011_I00530
num_objs 5
set03_V009_I01229
num_objs 0
set00_V000_I00134
num_objs 1
set00_V010_I01511
num_objs 3
set03_V008_I00119
num_objs 15
set03_V008_I00770
num_objs 3
set00_V004_I00188
num_objs 1
set00_V004_I00776
num_objs 1
set00_V006_I00827
num_objs 2
set05_V002_I00449
num_objs 1
set03_V005_I01523
num_objs 1
set03_V012_I01349
num_objs 3
set01_V002_I00926
num_objs 4
set01_V001_I00833
num_objs 1
set01_V002_I00023
num_objs 2
set01_V001_I00770
num_objs 1
set00_V001_I00935
num_objs 6
set00_V009_I00827
num_objs 3
set00_V007_I00449
num_objs 1
set00_V009_I00839
num_objs 3
set03_V011_I00743
num_objs 2
set03_V006_I01838
num_objs 1
set03_V011_I00830
num_objs 2
set02_V007_I00377
num_objs 1
set04_V011_I01865
num_objs 1
set02_V009_I01430
num_objs 1
set05_V000_I01511
num_objs 1
set05_V012_I00329
num_objs 0
set05_V012_I00551
num_objs 1
set01_V002_I01742
num_objs 5
set05_V011_I01379
num_objs 2
set03_V008_I01232
num_objs 2
set01_V003_I00809
num_objs 4
set01_V002_I01397
num_objs 1
set05_V005_I00383
num_objs 1
set00_V000_I00920
num_objs 0
set03_V006_I00014
num_objs 1
set03_V010_I01607
num_objs 2
set00_V014_I00749
num_objs 3
set05_V011_I01145
num_objs 4
set05_V004_I00158
num_objs 3
set02_V011_I01373
num_objs 2
set03_V010_I01673
num_objs 4
set04_V010_I00476
num_objs 1
set00_V010_I00932
num_objs 1
set01_V004_I00653
num_objs 2
set04_V000_I00806
num_objs 1
set00_V001_I00944
num_objs 7
set04_V002_I01631
num_objs 2
set05_V010_I00503
num_objs 1
set05_V003_I01070
num_objs 1
set03_V009_I00704
num_objs 2
set03_V008_I00485
num_objs 16
set01_V002_I00734
num_objs 7
set01_V002_I00461
num_objs 5
set05_V011_I01403
num_objs 3
set00_V009_I00428
num_objs 3
set01_V002_I00029
num_objs 1
set01_V001_I01016
num_objs 1
set05_V000_I00323
num_objs 3
set00_V002_I01070
num_objs 0
set04_V011_I01802
num_objs 1
set03_V002_I01517
num_objs 1
set00_V010_I00458
num_objs 7
set05_V005_I00551
num_objs 1
set00_V007_I00839
num_objs 2
set02_V010_I01145
num_objs 1
set04_V010_I00974
num_objs 1
set02_V011_I01451
num_objs 2
set00_V004_I01490
num_objs 0
set00_V006_I01502
num_objs 2
set00_V014_I00659
num_objs 6
set00_V009_I00704
num_objs 4
set05_V012_I00668
num_objs 1
set04_V005_I00098
num_objs 1
set00_V007_I00782
num_objs 2
set00_V012_I00566
num_objs 0
set04_V007_I00392
num_objs 1
set03_V008_I01487
num_objs 2
set03_V001_I00854
num_objs 1
set00_V007_I01121
num_objs 11
set03_V009_I00650
num_objs 3
set03_V012_I01202
num_objs 1
set04_V002_I00803
num_objs 1
set04_V004_I01361
num_objs 1
set00_V000_I01496
num_objs 1
set03_V009_I01253
num_objs 3
set04_V005_I01661
num_objs 1
set00_V011_I01523
num_objs 2
set05_V004_I00419
num_objs 1
set00_V001_I00107
num_objs 3
set00_V010_I00119
num_objs 2
set03_V005_I00824
num_objs 1
set05_V002_I00614
num_objs 1
set01_V001_I00368
num_objs 4
set00_V014_I00140
num_objs 1
set00_V000_I01091
num_objs 0
set01_V001_I01697
num_objs 2
set04_V005_I00326
num_objs 1
set05_V012_I01067
num_objs 1
set00_V010_I00860
num_objs 3
set01_V003_I00992
num_objs 1
set04_V007_I00464
num_objs 1
set04_V003_I00338
num_objs 1
set05_V000_I01688
num_objs 1
set00_V010_I00590
num_objs 5
set01_V001_I00317
num_objs 4
set01_V002_I01730
num_objs 5
set02_V007_I00965
num_objs 1
set04_V007_I01127
num_objs 2
set01_V001_I00059
num_objs 0
set03_V005_I00935
num_objs 1
set03_V011_I00242
num_objs 3
set04_V010_I01625
num_objs 2
set04_V005_I01016
num_objs 3
set04_V005_I00023
num_objs 1
set00_V012_I01583
num_objs 2
set00_V006_I00392
num_objs 4
set00_V003_I00491
num_objs 1
set05_V002_I00110
num_objs 1
set01_V002_I01601
num_objs 3
set03_V003_I00158
num_objs 2
set04_V006_I00932
num_objs 2
set04_V003_I00494
num_objs 0
set05_V003_I01382
num_objs 2
set03_V009_I01607
num_objs 2
set01_V004_I00584
num_objs 1
set03_V009_I01817
num_objs 4
set04_V002_I01121
num_objs 2
set00_V012_I00896
num_objs 6
set03_V009_I01664
num_objs 3
set03_V005_I01256
num_objs 2
set00_V009_I00467
num_objs 2
set02_V010_I01229
num_objs 0
set02_V009_I00848
num_objs 1
set01_V002_I00341
num_objs 7
set04_V002_I01007
num_objs 2
set00_V008_I01523
num_objs 1
set00_V000_I00827
num_objs 0
set00_V001_I00077
num_objs 3
set00_V012_I00284
num_objs 3
set01_V003_I00962
num_objs 2
set03_V008_I00800
num_objs 2
set04_V007_I01487
num_objs 1
set01_V005_I00326
num_objs 3
set01_V001_I01253
num_objs 11
set05_V007_I01718
num_objs 0
set03_V009_I00272
num_objs 3
set00_V012_I00410
num_objs 0
set03_V005_I00236
num_objs 1
set02_V009_I01142
num_objs 1
set03_V012_I01430
num_objs 3
set00_V001_I00596
num_objs 1
set03_V008_I01004
num_objs 1
set02_V009_I01688
num_objs 1
set00_V012_I00623
num_objs 0
set01_V005_I01646
num_objs 0
set00_V008_I00194
num_objs 1
set01_V004_I00554
num_objs 1
set04_V010_I00590
num_objs 1
set00_V004_I01355
num_objs 1
set01_V005_I01283
num_objs 1
set00_V010_I00650
num_objs 2
set00_V014_I01484
num_objs 4
set04_V011_I01592
num_objs 1
set05_V003_I01739
num_objs 0
set01_V003_I00641
num_objs 2
set05_V000_I01676
num_objs 1
set00_V012_I01157
num_objs 1
set01_V005_I01364
num_objs 1
set00_V001_I00527
num_objs 3
set03_V003_I01304
num_objs 2
set05_V012_I00680
num_objs 1
set03_V011_I00803
num_objs 2
set00_V014_I01307
num_objs 6
set00_V006_I00911
num_objs 4
set03_V012_I01547
num_objs 4
set01_V005_I00323
num_objs 3
set00_V006_I00857
num_objs 2
set01_V001_I00101
num_objs 3
set04_V004_I01253
num_objs 1
set05_V011_I01664
num_objs 1
set02_V010_I00068
num_objs 1
set00_V001_I01655
num_objs 2
set00_V013_I01196
num_objs 0
set02_V010_I01586
num_objs 1
set00_V007_I01448
num_objs 5
set00_V009_I01067
num_objs 1
set04_V006_I00905
num_objs 2
set01_V005_I00173
num_objs 2
set02_V009_I01715
num_objs 1
set00_V009_I01589
num_objs 5
set00_V010_I01580
num_objs 1
set03_V004_I00128
num_objs 1
set04_V000_I00836
num_objs 1
set02_V010_I01277
num_objs 1
set02_V011_I01571
num_objs 2
set03_V010_I01475
num_objs 2
set00_V007_I00905
num_objs 4
set01_V002_I00338
num_objs 7
set04_V005_I01076
num_objs 2
set01_V005_I00386
num_objs 4
set00_V001_I01025
num_objs 12
set04_V007_I00710
num_objs 2
set00_V004_I00125
num_objs 1
set03_V012_I00890
num_objs 1
set00_V014_I01607
num_objs 4
set05_V009_I00740
num_objs 1
set04_V005_I00284
num_objs 1
set04_V002_I01766
num_objs 1
set02_V009_I00599
num_objs 2
set05_V002_I00551
num_objs 1
set05_V005_I01259
num_objs 1
set01_V001_I01211
num_objs 7
set00_V001_I00677
num_objs 3
set04_V006_I01586
num_objs 1
set00_V006_I00554
num_objs 4
set05_V000_I00443
num_objs 3
set02_V010_I00497
num_objs 1
set00_V009_I01613
num_objs 3
set00_V014_I01406
num_objs 5
set05_V005_I00419
num_objs 0
set05_V010_I01034
num_objs 1
set00_V004_I01088
num_objs 1
set01_V002_I01580
num_objs 2
set00_V009_I00683
num_objs 3
set00_V013_I00770
num_objs 2
set02_V007_I00344
num_objs 1
set02_V010_I00077
num_objs 1
set03_V003_I00593
num_objs 2
set04_V000_I00701
num_objs 3
set00_V012_I00908
num_objs 6
set00_V004_I01052
num_objs 1
set03_V009_I01598
num_objs 2
set00_V004_I00011
num_objs 1
set01_V003_I01589
num_objs 2
set01_V002_I00767
num_objs 9
set05_V010_I00983
num_objs 1
set00_V009_I00611
num_objs 2
set00_V012_I00977
num_objs 5
set01_V000_I00413
num_objs 2
set03_V003_I00896
num_objs 2
set01_V002_I01514
num_objs 0
set05_V011_I01601
num_objs 1
set01_V003_I01043
num_objs 2
set03_V010_I00956
num_objs 1
set00_V013_I01439
num_objs 4
set02_V009_I01769
num_objs 0
set03_V012_I01412
num_objs 4
set00_V003_I00395
num_objs 0
set04_V004_I00419
num_objs 0
set01_V002_I01274
num_objs 4
set01_V000_I00557
num_objs 2
set04_V011_I01868
num_objs 1
set00_V001_I01331
num_objs 4
set00_V014_I01508
num_objs 3
set04_V003_I00236
num_objs 1
set01_V003_I01262
num_objs 1
set05_V012_I00557
num_objs 0
set00_V009_I01385
num_objs 0
set00_V007_I00836
num_objs 3
set00_V014_I01046
num_objs 3
set02_V003_I00032
num_objs 1
set00_V006_I00383
num_objs 4
set02_V011_I00806
num_objs 0
set03_V004_I00539
num_objs 1
set00_V014_I00824
num_objs 5
set02_V010_I00833
num_objs 2
set05_V008_I00242
num_objs 2
set03_V004_I00542
num_objs 1
set01_V003_I01565
num_objs 1
set03_V005_I00422
num_objs 2
set04_V005_I00227
num_objs 1
set00_V001_I00932
num_objs 6
set01_V003_I00731
num_objs 2
set01_V002_I00935
num_objs 4
set00_V012_I01160
num_objs 1
set04_V006_I01100
num_objs 1
set05_V002_I01553
num_objs 1
set00_V007_I01910
num_objs 3
set05_V000_I01667
num_objs 1
set02_V011_I00815
num_objs 0
set04_V004_I00899
num_objs 2
set04_V007_I01313
num_objs 1
set04_V002_I01547
num_objs 2
set00_V004_I00770
num_objs 1
set01_V002_I01547
num_objs 1
set02_V007_I00224
num_objs 1
set05_V004_I00242
num_objs 1
set00_V001_I01052
num_objs 12
set01_V002_I01139
num_objs 1
set02_V009_I01067
num_objs 1
set00_V004_I01673
num_objs 1
set02_V001_I01622
num_objs 1
set00_V012_I00212
num_objs 1
set03_V003_I00779
num_objs 0
set00_V013_I01424
num_objs 2
set03_V002_I01628
num_objs 2
set04_V006_I01565
num_objs 1
set04_V010_I00569
num_objs 0
set05_V012_I00320
num_objs 1
set00_V010_I01037
num_objs 0
set04_V002_I01187
num_objs 2
set01_V002_I00764
num_objs 10
set04_V004_I00965
num_objs 2
set01_V004_I00599
num_objs 0
set01_V005_I01100
num_objs 3
set05_V002_I01124
num_objs 2
set04_V011_I00338
num_objs 1
set01_V003_I00545
num_objs 2
set01_V001_I00884
num_objs 1
set00_V009_I01679
num_objs 5
set01_V004_I00854
num_objs 3
set03_V011_I00425
num_objs 5
set03_V008_I00380
num_objs 19
set00_V000_I00242
num_objs 4
set03_V004_I00512
num_objs 1
set03_V010_I01532
num_objs 3
set05_V000_I00527
num_objs 3
set00_V010_I00107
num_objs 4
set01_V000_I01556
num_objs 4
set01_V002_I00377
num_objs 5
set01_V000_I01058
num_objs 2
set01_V005_I00614
num_objs 3
set01_V005_I00536
num_objs 2
set01_V005_I00761
num_objs 2
set04_V006_I01508
num_objs 1
set00_V009_I00215
num_objs 7
set01_V004_I00473
num_objs 1
set00_V006_I00419
num_objs 4
set05_V011_I00494
num_objs 1
set00_V002_I00191
num_objs 2
set01_V004_I01496
num_objs 2
set04_V005_I00137
num_objs 1
set03_V010_I00926
num_objs 1
set03_V010_I01553
num_objs 3
set04_V003_I00740
num_objs 1
set00_V001_I00374
num_objs 5
set01_V001_I00536
num_objs 4
set00_V013_I00230
num_objs 3
set04_V002_I01772
num_objs 1
set03_V003_I00821
num_objs 2
set04_V003_I01400
num_objs 3
set01_V004_I01250
num_objs 0
set03_V003_I00941
num_objs 2
set04_V006_I00890
num_objs 2
set01_V002_I01064
num_objs 3
set04_V010_I00932
num_objs 2
set04_V005_I00158
num_objs 1
set04_V006_I01613
num_objs 1
set03_V005_I00308
num_objs 1
set03_V007_I00281
num_objs 1
set03_V004_I00497
num_objs 1
set04_V010_I00524
num_objs 1
set03_V004_I00176
num_objs 1
set00_V006_I01064
num_objs 5
set05_V002_I01505
num_objs 1
set05_V007_I01604
num_objs 0
set01_V000_I01298
num_objs 3
set01_V003_I01670
num_objs 2
set00_V007_I00698
num_objs 1
set05_V011_I01286
num_objs 2
set03_V004_I00434
num_objs 1
set04_V006_I01544
num_objs 1
set03_V008_I01268
num_objs 2
set01_V005_I00593
num_objs 3
set00_V001_I00950
num_objs 8
set00_V007_I01193
num_objs 8
set03_V003_I00791
num_objs 2
set03_V009_I01775
num_objs 4
set03_V005_I00356
num_objs 2
set00_V007_I00275
num_objs 6
set04_V007_I01496
num_objs 1
set04_V008_I01352
num_objs 1
set05_V010_I00626
num_objs 1
set01_V002_I00803
num_objs 7
set05_V004_I00278
num_objs 1
set05_V010_I00650
num_objs 1
set03_V006_I00128
num_objs 1
set00_V014_I00218
num_objs 3
set04_V010_I00923
num_objs 2
set01_V005_I01121
num_objs 4
set00_V011_I01067
num_objs 10
set00_V002_I00269
num_objs 1
set04_V003_I01490
num_objs 2
set01_V004_I00860
num_objs 3
set01_V001_I00998
num_objs 1
set00_V012_I00287
num_objs 3
set00_V014_I00206
num_objs 2
set05_V003_I01604
num_objs 0
set01_V005_I00602
num_objs 3
set00_V009_I00755
num_objs 3
set02_V009_I01307
num_objs 1
set03_V008_I00146
num_objs 11
set03_V008_I00908
num_objs 1
set00_V012_I01235
num_objs 0
set00_V009_I01661
num_objs 2
set01_V001_I01694
num_objs 2
set05_V005_I00410
num_objs 1
set03_V009_I00917
num_objs 4
set03_V010_I01484
num_objs 2
set03_V005_I00920
num_objs 1
set05_V012_I00701
num_objs 1
set01_V004_I00746
num_objs 3
set02_V010_I01274
num_objs 1
set00_V001_I00902
num_objs 3
set03_V002_I01667
num_objs 2
set05_V000_I01538
num_objs 1
set04_V003_I00989
num_objs 4
set04_V005_I00020
num_objs 1
set05_V000_I00758
num_objs 1
set00_V001_I01574
num_objs 3
set03_V009_I00353
num_objs 4
set02_V007_I00947
num_objs 1
set03_V009_I01547
num_objs 2
set00_V009_I00584
num_objs 1
set02_V011_I01469
num_objs 2
set03_V003_I00098
num_objs 2
set04_V002_I00701
num_objs 3
set00_V008_I01541
num_objs 1
set03_V005_I01319
num_objs 1
set00_V007_I01475
num_objs 5
set00_V014_I01397
num_objs 6
set04_V004_I00767
num_objs 2
set02_V010_I00338
num_objs 1
set03_V010_I00974
num_objs 3
set00_V002_I00812
num_objs 6
set02_V010_I01796
num_objs 1
set05_V005_I00101
num_objs 4
set00_V001_I00185
num_objs 2
set04_V000_I00632
num_objs 3
set05_V011_I00755
num_objs 2
set00_V001_I00566
num_objs 2
set01_V000_I01382
num_objs 3
set00_V012_I01325
num_objs 0
set02_V011_I01586
num_objs 2
set03_V009_I01577
num_objs 2
set04_V005_I00320
num_objs 1
set02_V009_I01403
num_objs 1
set00_V009_I00092
num_objs 5
set01_V004_I01196
num_objs 0
set00_V001_I00152
num_objs 1
set01_V004_I01523
num_objs 2
set00_V014_I01487
num_objs 4
set01_V003_I00431
num_objs 3
set02_V010_I01235
num_objs 1
set05_V007_I01526
num_objs 1
set00_V010_I00194
num_objs 4
set00_V000_I01337
num_objs 1
set00_V000_I00935
num_objs 0
set03_V003_I00863
num_objs 2
set00_V000_I01661
num_objs 1
set03_V008_I01574
num_objs 1
set01_V002_I01001
num_objs 1
set03_V009_I00566
num_objs 4
set00_V007_I00590
num_objs 4
set05_V010_I00773
num_objs 1
set00_V008_I00242
num_objs 0
set03_V005_I01535
num_objs 1
set01_V002_I01496
num_objs 0
set01_V003_I00344
num_objs 3
set00_V013_I01523
num_objs 4
set04_V001_I01778
num_objs 1
set02_V009_I00695
num_objs 2
set01_V005_I01286
num_objs 1
set03_V006_I00005
num_objs 1
set03_V004_I00158
num_objs 1
set01_V005_I00869
num_objs 1
set00_V004_I00356
num_objs 2
set04_V003_I01151
num_objs 3
set00_V006_I01577
num_objs 2
set00_V008_I01358
num_objs 1
set04_V001_I01757
num_objs 1
set00_V001_I00176
num_objs 2
set05_V001_I00443
num_objs 0
set04_V004_I00932
num_objs 2
set04_V006_I00830
num_objs 2
set03_V003_I00899
num_objs 1
set04_V003_I01145
num_objs 3
set00_V002_I00833
num_objs 8
set01_V000_I00833
num_objs 0
set01_V002_I00551
num_objs 8
set01_V001_I00245
num_objs 1
set02_V010_I00650
num_objs 2
set04_V010_I01670
num_objs 2
set01_V002_I01529
num_objs 0
set03_V012_I00830
num_objs 1
set00_V009_I01559
num_objs 3
set00_V009_I01607
num_objs 3
set04_V004_I01685
num_objs 2
set02_V001_I00338
num_objs 1
set05_V010_I00860
num_objs 1
set00_V009_I00347
num_objs 4
set00_V012_I01427
num_objs 2
set02_V008_I01295
num_objs 1
set05_V003_I01679
num_objs 1
set04_V005_I00998
num_objs 3
set01_V005_I00176
num_objs 2
set02_V001_I01631
num_objs 1
set03_V011_I01439
num_objs 2
set00_V008_I00329
num_objs 0
set01_V004_I01580
num_objs 1
set00_V007_I01928
num_objs 2
set02_V003_I00089
num_objs 0
set04_V008_I01028
num_objs 1
set03_V012_I00035
num_objs 1
set03_V010_I01694
num_objs 3
set03_V001_I00152
num_objs 1
set01_V001_I01400
num_objs 10
set00_V014_I00116
num_objs 3
set03_V006_I00176
num_objs 0
set01_V004_I01397
num_objs 1
set03_V009_I01688
num_objs 3
set00_V013_I00602
num_objs 3
set00_V006_I01208
num_objs 5
set00_V014_I01889
num_objs 1
set01_V002_I01757
num_objs 5
set00_V009_I01043
num_objs 1
set01_V005_I00983
num_objs 3
set04_V003_I00563
num_objs 0
set00_V007_I01106
num_objs 7
set00_V006_I00515
num_objs 3
set05_V000_I01388
num_objs 2
set00_V004_I00524
num_objs 1
set02_V010_I00830
num_objs 2
set01_V000_I00149
num_objs 3
set05_V010_I01526
num_objs 2
set00_V009_I01253
num_objs 1
set05_V010_I01103
num_objs 1
set00_V006_I00275
num_objs 3
set04_V002_I00776
num_objs 2
set03_V008_I01769
num_objs 1
set04_V006_I00692
num_objs 3
set01_V005_I00887
num_objs 2
set04_V004_I00785
num_objs 2
set05_V003_I01328
num_objs 2
set00_V007_I01838
num_objs 5
set02_V009_I01442
num_objs 1
set01_V000_I01706
num_objs 2
set04_V007_I00587
num_objs 2
set00_V000_I01613
num_objs 1
set01_V005_I01625
num_objs 0
set01_V002_I01670
num_objs 4
set04_V002_I01481
num_objs 2
set02_V008_I01283
num_objs 1
set02_V011_I00842
num_objs 1
set04_V008_I01430
num_objs 1
set00_V010_I00959
num_objs 1
set00_V004_I01451
num_objs 2
set00_V004_I01160
num_objs 0
set03_V009_I01073
num_objs 6
set03_V008_I00704
num_objs 3
set03_V012_I01562
num_objs 3
set05_V000_I01730
num_objs 1
set02_V001_I01685
num_objs 1
set04_V003_I00362
num_objs 1
set02_V003_I00080
num_objs 1
set03_V004_I00536
num_objs 1
set00_V012_I00824
num_objs 4
set05_V010_I00764
num_objs 1
set00_V007_I00695
num_objs 1
set00_V000_I01067
num_objs 0
set05_V010_I01061
num_objs 1
set03_V009_I01151
num_objs 1
set00_V014_I00842
num_objs 5
set04_V006_I01619
num_objs 1
set03_V003_I01046
num_objs 2
set04_V005_I00104
num_objs 1
set05_V003_I01397
num_objs 2
set01_V002_I00740
num_objs 7
set03_V011_I00563
num_objs 5
set00_V010_I01475
num_objs 4
set05_V004_I00236
num_objs 1
set00_V001_I01124
num_objs 7
set04_V003_I01808
num_objs 1
set03_V005_I01361
num_objs 1
set03_V009_I01175
num_objs 2
set03_V003_I00737
num_objs 2
set00_V011_I01133
num_objs 6
set00_V004_I01409
num_objs 8
set03_V009_I01616
num_objs 2
set01_V005_I01082
num_objs 2
set00_V011_I00416
num_objs 5
set03_V005_I00644
num_objs 2
set02_V011_I00461
num_objs 1
set00_V001_I01778
num_objs 5
set00_V010_I01469
num_objs 2
set00_V011_I00914
num_objs 3
set05_V012_I00287
num_objs 1
set00_V014_I00197
num_objs 1
set00_V009_I00167
num_objs 3
set04_V008_I00635
num_objs 1
set05_V000_I00701
num_objs 1
set04_V010_I01697
num_objs 2
set00_V012_I01079
num_objs 1
set04_V007_I01139
num_objs 1
set00_V002_I00773
num_objs 2
set03_V012_I00878
num_objs 1
set01_V003_I00440
num_objs 4
set03_V008_I01643
num_objs 2
set00_V010_I01223
num_objs 2
set04_V007_I00263
num_objs 2
set02_V010_I01073
num_objs 1
set01_V005_I01316
num_objs 1
set01_V002_I00314
num_objs 7
set04_V006_I01532
num_objs 1
set03_V009_I01532
num_objs 2
set00_V008_I00686
num_objs 3
set05_V012_I00584
num_objs 0
set00_V008_I00032
num_objs 7
set05_V010_I00041
num_objs 1
set00_V001_I01115
num_objs 8
set03_V011_I00809
num_objs 1
set00_V012_I00581
num_objs 0
set05_V005_I00719
num_objs 1
set00_V007_I01034
num_objs 1
set03_V012_I00974
num_objs 1
set05_V010_I01568
num_objs 1
set03_V008_I00821
num_objs 2
set02_V010_I01472
num_objs 1
set02_V011_I01508
num_objs 2
set02_V009_I00335
num_objs 2
set01_V005_I01220
num_objs 3
set04_V003_I01187
num_objs 3
set03_V003_I00281
num_objs 1
set04_V003_I00746
num_objs 1
set00_V007_I00248
num_objs 6
set00_V014_I01112
num_objs 3
set04_V007_I00836
num_objs 2
set03_V011_I01469
num_objs 2
set00_V010_I00191
num_objs 4
set04_V007_I00860
num_objs 2
set04_V006_I00989
num_objs 1
set00_V011_I00926
num_objs 4
set00_V011_I01559
num_objs 0
set05_V005_I00212
num_objs 0
set01_V003_I01349
num_objs 0
set02_V011_I00788
num_objs 0
set03_V011_I00737
num_objs 1
set00_V014_I01601
num_objs 4
set00_V008_I00620
num_objs 4
set00_V012_I01268
num_objs 0
set00_V014_I00392
num_objs 5
set00_V001_I01319
num_objs 1
set00_V011_I01148
num_objs 5
set03_V009_I00572
num_objs 4
set04_V004_I01238
num_objs 2
set03_V010_I01622
num_objs 2
set03_V008_I00002
num_objs 3
set00_V007_I01412
num_objs 4
set00_V004_I00479
num_objs 1
set01_V001_I00935
num_objs 1
set01_V002_I01160
num_objs 1
set01_V001_I01403
num_objs 10
set01_V005_I00305
num_objs 1
set00_V012_I01169
num_objs 2
set04_V000_I00668
num_objs 3
set00_V010_I00233
num_objs 2
set00_V000_I00452
num_objs 4
set00_V000_I01724
num_objs 1
set04_V011_I01091
num_objs 2
set05_V002_I01529
num_objs 0
set03_V011_I01412
num_objs 1
set05_V011_I01118
num_objs 5
set02_V003_I00257
num_objs 1
set01_V005_I00764
num_objs 2
set05_V004_I00485
num_objs 2
set00_V007_I00482
num_objs 5
set00_V000_I00074
num_objs 1
set01_V002_I01217
num_objs 3
set02_V003_I00143
num_objs 1
set05_V010_I00035
num_objs 1
set04_V005_I00971
num_objs 1
set00_V012_I01163
num_objs 1
set01_V001_I01058
num_objs 1
set04_V000_I00773
num_objs 1
set03_V002_I01430
num_objs 1
set00_V001_I00620
num_objs 3
set01_V001_I00320
num_objs 4
set04_V001_I00086
num_objs 1
set00_V008_I00641
num_objs 4
set00_V007_I01649
num_objs 4
set03_V004_I00629
num_objs 1
set01_V001_I00899
num_objs 0
set00_V009_I01235
num_objs 1
set03_V009_I00800
num_objs 2
set02_V010_I00524
num_objs 2
set00_V007_I01718
num_objs 4
set00_V010_I01106
num_objs 2
set04_V005_I01193
num_objs 1
set01_V003_I00485
num_objs 5
set02_V008_I01136
num_objs 0
set01_V004_I00917
num_objs 3
set01_V004_I00152
num_objs 1
set00_V006_I01289
num_objs 6
set00_V013_I01376
num_objs 3
set05_V011_I00746
num_objs 2
set01_V001_I00434
num_objs 3
set00_V013_I01508
num_objs 4
set01_V005_I00299
num_objs 2
set03_V009_I00251
num_objs 3
set01_V005_I00314
num_objs 3
set00_V006_I01265
num_objs 6
set00_V001_I00626
num_objs 5
set03_V009_I00137
num_objs 5
set04_V007_I00923
num_objs 2
set00_V011_I00896
num_objs 2
set05_V012_I01106
num_objs 1
set03_V012_I01376
num_objs 5
set01_V000_I00812
num_objs 1
set04_V007_I00386
num_objs 1
set00_V010_I00998
num_objs 0
set00_V004_I01106
num_objs 1
set04_V007_I00590
num_objs 2
set03_V011_I00968
num_objs 1
set00_V009_I01586
num_objs 4
set02_V010_I00374
num_objs 1
set00_V009_I00482
num_objs 2
set05_V004_I00869
num_objs 0
set00_V012_I01262
num_objs 0
set00_V006_I01457
num_objs 4
set02_V009_I01466
num_objs 1
set00_V010_I00584
num_objs 5
set01_V005_I00530
num_objs 2
set00_V009_I00857
num_objs 2
set00_V003_I00434
num_objs 1
set03_V008_I00092
num_objs 7
set02_V009_I00434
num_objs 1
set05_V011_I01343
num_objs 1
set03_V004_I00479
num_objs 1
set04_V002_I01178
num_objs 2
set00_V004_I00365
num_objs 2
set00_V011_I00749
num_objs 0
set04_V010_I00743
num_objs 1
set04_V008_I01340
num_objs 1
set00_V014_I01304
num_objs 6
set00_V008_I00794
num_objs 2
set01_V000_I00989
num_objs 0
set01_V003_I01766
num_objs 1
set02_V011_I00509
num_objs 0
set04_V010_I00665
num_objs 1
set00_V011_I01001
num_objs 11
set05_V011_I01421
num_objs 3
set03_V008_I01130
num_objs 1
set04_V004_I01082
num_objs 2
set01_V002_I00179
num_objs 0
set04_V002_I01439
num_objs 2
set04_V006_I01046
num_objs 1
set02_V009_I01088
num_objs 1
set02_V009_I01829
num_objs 0
set03_V008_I01406
num_objs 3
set00_V014_I01673
num_objs 4
set02_V010_I00410
num_objs 1
set00_V013_I01460
num_objs 4
set00_V000_I00836
num_objs 0
set03_V011_I00536
num_objs 5
set03_V011_I00785
num_objs 2
set03_V001_I00086
num_objs 1
set00_V001_I00767
num_objs 3
set05_V007_I01457
num_objs 1
set03_V009_I01013
num_objs 4
set03_V008_I01247
num_objs 2
set04_V005_I00842
num_objs 1
set05_V010_I00473
num_objs 1
set00_V006_I00875
num_objs 4
set00_V014_I01592
num_objs 4
set05_V010_I00557
num_objs 1
set04_V003_I00287
num_objs 1
set03_V012_I01304
num_objs 2
set02_V007_I00131
num_objs 1
set05_V000_I00236
num_objs 2
set03_V005_I01169
num_objs 0
set00_V011_I00047
num_objs 4
set00_V007_I00827
num_objs 3
set01_V002_I01733
num_objs 5
set05_V000_I01523
num_objs 1
set00_V012_I00989
num_objs 5
set01_V002_I01625
num_objs 4
set01_V002_I00065
num_objs 3
set02_V008_I00533
num_objs 1
set00_V013_I01166
num_objs 1
set00_V004_I00209
num_objs 0
set02_V008_I00860
num_objs 2
set05_V010_I00962
num_objs 1
set00_V010_I01124
num_objs 2
set03_V005_I01403
num_objs 1
set05_V009_I00914
num_objs 1
set00_V004_I00533
num_objs 1
set00_V014_I00155
num_objs 1
set02_V010_I00140
num_objs 1
set00_V003_I00050
num_objs 1
set02_V009_I00704
num_objs 2
set01_V005_I00671
num_objs 2
set00_V003_I00386
num_objs 1
set04_V006_I00560
num_objs 1
set03_V007_I00296
num_objs 1
set02_V010_I00662
num_objs 2
set03_V003_I00590
num_objs 2
set03_V010_I01586
num_objs 4
set01_V005_I01616
num_objs 0
set01_V003_I00524
num_objs 3
set00_V002_I01190
num_objs 0
set02_V011_I01652
num_objs 2
set03_V003_I00773
num_objs 2
set03_V011_I00548
num_objs 5
set01_V003_I01070
num_objs 1
set05_V007_I01244
num_objs 1
set05_V002_I00095
num_objs 1
set03_V011_I00902
num_objs 1
set02_V001_I01499
num_objs 0
set00_V013_I00785
num_objs 1
set00_V006_I01067
num_objs 5
set02_V010_I00860
num_objs 1
set02_V003_I00212
num_objs 1
set00_V012_I00350
num_objs 0
set00_V003_I00350
num_objs 1
set04_V002_I00962
num_objs 2
set05_V001_I00179
num_objs 1
set00_V012_I00701
num_objs 0
set02_V011_I00719
num_objs 0
set01_V002_I00050
num_objs 3
set02_V010_I00443
num_objs 1
set03_V009_I00614
num_objs 4
set04_V005_I01163
num_objs 1
set00_V008_I00308
num_objs 0
set00_V013_I00611
num_objs 3
set03_V010_I00134
num_objs 2
set04_V005_I00218
num_objs 1
set02_V010_I00104
num_objs 1
set01_V001_I00509
num_objs 1
set05_V002_I01481
num_objs 1
set02_V010_I00593
num_objs 2
set02_V009_I01706
num_objs 1
set03_V008_I00416
num_objs 17
set02_V010_I01103
num_objs 1
set03_V008_I00536
num_objs 12
set01_V000_I00317
num_objs 1
set00_V010_I01025
num_objs 0
set05_V011_I01487
num_objs 3
set00_V000_I00152
num_objs 1
set01_V003_I01514
num_objs 1
set02_V009_I01193
num_objs 2
set05_V005_I00632
num_objs 1
set01_V005_I01457
num_objs 0
set02_V009_I00878
num_objs 1
set01_V001_I01568
num_objs 8
set01_V000_I01154
num_objs 4
set00_V006_I01070
num_objs 6
set05_V005_I00884
num_objs 1
set05_V011_I01121
num_objs 5
set03_V003_I01394
num_objs 2
set03_V008_I00761
num_objs 3
set00_V007_I00068
num_objs 1
set00_V013_I00050
num_objs 3
set00_V001_I00830
num_objs 3
set00_V010_I00368
num_objs 6
set01_V002_I00830
num_objs 8
set00_V006_I00116
num_objs 3
set04_V007_I01451
num_objs 1
set03_V011_I01388
num_objs 1
set01_V004_I00524
num_objs 1
set02_V003_I00722
num_objs 2
set00_V001_I00080
num_objs 3
set01_V004_I01358
num_objs 1
set04_V010_I01583
num_objs 2
set04_V002_I00719
num_objs 2
set00_V011_I01319
num_objs 3
set01_V004_I00698
num_objs 1
set00_V013_I00224
num_objs 4
set03_V008_I00209
num_objs 13
set05_V012_I00311
num_objs 1
set03_V009_I01298
num_objs 0
set00_V014_I01286
num_objs 4
set03_V010_I01691
num_objs 3
set00_V014_I00857
num_objs 5
set05_V008_I00239
num_objs 2
set00_V000_I01229
num_objs 1
set03_V009_I00206
num_objs 5
set00_V000_I00149
num_objs 0
set00_V006_I00425
num_objs 2
set00_V001_I01394
num_objs 3
set01_V005_I00497
num_objs 3
set02_V010_I00158
num_objs 1
set05_V007_I01352
num_objs 1
set04_V002_I00068
num_objs 1
set04_V007_I00911
num_objs 2
set02_V010_I00827
num_objs 2
set03_V006_I01805
num_objs 1
set05_V000_I00422
num_objs 2
set00_V010_I00767
num_objs 3
set00_V012_I00422
num_objs 0
set00_V011_I00590
num_objs 3
set02_V003_I00335
num_objs 1
set05_V005_I00836
num_objs 2
set01_V002_I01022
num_objs 2
set05_V002_I00146
num_objs 1
set04_V007_I01457
num_objs 1
set00_V011_I00038
num_objs 5
set01_V004_I00167
num_objs 1
set00_V014_I01469
num_objs 0
set01_V005_I00737
num_objs 2
set03_V011_I00953
num_objs 1
set00_V011_I00815
num_objs 1
set00_V001_I00230
num_objs 6
set01_V002_I01199
num_objs 1
set01_V002_I01769
num_objs 2
set04_V005_I01523
num_objs 2
set02_V009_I00668
num_objs 2
set04_V005_I01154
num_objs 1
set03_V007_I00344
num_objs 1
set00_V001_I01361
num_objs 2
set04_V005_I01688
num_objs 0
set03_V006_I00122
num_objs 1
set04_V005_I01679
num_objs 1
set02_V001_I01424
num_objs 1
set03_V003_I00143
num_objs 2
set01_V005_I01223
num_objs 2
set04_V006_I01616
num_objs 1
set04_V002_I00923
num_objs 1
set03_V003_I01352
num_objs 2
set05_V004_I00980
num_objs 1
set02_V010_I00965
num_objs 1
set01_V000_I00560
num_objs 2
set00_V014_I01532
num_objs 4
set00_V009_I00248
num_objs 7
set00_V008_I01439
num_objs 1
set03_V011_I01151
num_objs 1
set04_V007_I00596
num_objs 2
set01_V003_I00185
num_objs 8
set01_V005_I00152
num_objs 2
set02_V011_I00545
num_objs 2
set03_V008_I00203
num_objs 13
set03_V008_I01205
num_objs 2
set04_V003_I00983
num_objs 4
set02_V010_I01019
num_objs 0
set03_V009_I00197
num_objs 5
set05_V011_I00977
num_objs 8
set00_V008_I00380
num_objs 2
set05_V001_I00164
num_objs 1
set05_V011_I01430
num_objs 3
set02_V007_I00101
num_objs 1
set01_V003_I01520
num_objs 1
set04_V001_I00068
num_objs 1
set00_V002_I00953
num_objs 2
set05_V011_I00035
num_objs 1
set01_V003_I01322
num_objs 1
set05_V003_I01196
num_objs 3
set00_V008_I00869
num_objs 1
set04_V003_I01130
num_objs 3
set00_V006_I00269
num_objs 3
set00_V001_I00905
num_objs 4
set03_V007_I01517
num_objs 0
set02_V009_I00875
num_objs 1
set03_V010_I00914
num_objs 1
set00_V009_I00590
num_objs 2
set05_V010_I00977
num_objs 1
set00_V010_I00029
num_objs 6
set04_V010_I00725
num_objs 1
set05_V003_I01217
num_objs 3
set02_V009_I00752
num_objs 2
set03_V010_I00125
num_objs 2
set00_V001_I01214
num_objs 3
set00_V014_I01535
num_objs 4
set02_V008_I01277
num_objs 1
set01_V005_I00716
num_objs 2
set01_V001_I00701
num_objs 2
set05_V005_I00743
num_objs 1
set04_V003_I00470
num_objs 0
set05_V000_I00452
num_objs 3
set03_V005_I00851
num_objs 1
set00_V006_I00125
num_objs 3
set04_V011_I01586
num_objs 1
set01_V001_I00542
num_objs 4
set02_V001_I01538
num_objs 1
set01_V004_I00104
num_objs 2
set00_V010_I00395
num_objs 6
set00_V012_I00191
num_objs 1
set02_V010_I01841
num_objs 1
set02_V011_I01298
num_objs 1
set03_V005_I01241
num_objs 2
set00_V004_I01319
num_objs 10
set05_V000_I00125
num_objs 2
set01_V003_I01631
num_objs 1
set00_V014_I00875
num_objs 5
set00_V009_I01637
num_objs 3
set05_V000_I00545
num_objs 3
set05_V005_I00029
num_objs 1
set04_V005_I00029
num_objs 0
set05_V005_I00788
num_objs 1
set01_V000_I00320
num_objs 1
set00_V013_I00911
num_objs 1
set00_V006_I00845
num_objs 1
set00_V006_I01808
num_objs 0
set01_V001_I00110
num_objs 3
set04_V007_I00236
num_objs 2
set00_V004_I01406
num_objs 2
set00_V000_I01220
num_objs 2
set04_V002_I01754
num_objs 1
set00_V002_I00305
num_objs 1
set01_V001_I01217
num_objs 9
set00_V011_I00857
num_objs 0
set00_V014_I01511
num_objs 3
set01_V004_I01169
num_objs 6
set00_V006_I00998
num_objs 3
set00_V007_I01592
num_objs 6
set01_V003_I00419
num_objs 3
set03_V010_I00953
num_objs 1
set03_V009_I00110
num_objs 5
set03_V008_I01607
num_objs 2
set04_V002_I01274
num_objs 2
set00_V014_I01670
num_objs 4
set01_V000_I00593
num_objs 3
set00_V010_I01565
num_objs 1
set02_V009_I01058
num_objs 1
set01_V003_I00491
num_objs 5
set03_V012_I00953
num_objs 1
set00_V006_I00707
num_objs 2
set05_V000_I01490
num_objs 1
set01_V001_I01664
num_objs 2
set00_V004_I00257
num_objs 1
set02_V007_I00113
num_objs 1
set00_V007_I01202
num_objs 9
set01_V004_I00200
num_objs 1
set03_V008_I00650
num_objs 5
set05_V005_I00155
num_objs 0
set03_V004_I00218
num_objs 1
set05_V010_I00431
num_objs 1
set01_V000_I00632
num_objs 2
set04_V007_I01043
num_objs 2
set05_V011_I01400
num_objs 2
set00_V014_I00173
num_objs 1
set04_V002_I01760
num_objs 1
set01_V003_I00887
num_objs 1
set00_V004_I01538
num_objs 0
set05_V005_I00647
num_objs 1
set00_V008_I00119
num_objs 5
set04_V004_I00530
num_objs 3
set05_V011_I00998
num_objs 8
set04_V004_I01136
num_objs 3
set02_V011_I01802
num_objs 2
set03_V012_I01403
num_objs 4
set05_V003_I00968
num_objs 1
set02_V011_I01553
num_objs 2
set03_V010_I01628
num_objs 2
set04_V010_I00659
num_objs 0
set00_V009_I00272
num_objs 6
set04_V004_I00440
num_objs 2
set02_V010_I01184
num_objs 1
set01_V001_I01022
num_objs 1
set04_V003_I01346
num_objs 3
set02_V003_I00278
num_objs 1
set00_V000_I00476
num_objs 1
set01_V002_I00575
num_objs 8
set03_V005_I00275
num_objs 1
set03_V009_I01652
num_objs 2
set00_V009_I00284
num_objs 5
set03_V009_I00866
num_objs 2
set04_V004_I00983
num_objs 2
set05_V011_I01595
num_objs 1
set00_V008_I01250
num_objs 2
set01_V000_I01445
num_objs 5
set01_V004_I00482
num_objs 1
set04_V003_I01445
num_objs 4
set02_V007_I00308
num_objs 1
set00_V010_I01640
num_objs 0
set05_V005_I00896
num_objs 1
set01_V000_I01040
num_objs 2
set02_V010_I01283
num_objs 1
set00_V010_I00398
num_objs 6
set00_V009_I01571
num_objs 4
set05_V010_I00953
num_objs 1
set05_V005_I00473
num_objs 2
set04_V010_I00542
num_objs 1
set05_V011_I01016
num_objs 8
set05_V000_I01352
num_objs 1
set01_V005_I00374
num_objs 3
set00_V004_I00926
num_objs 2
set00_V013_I00902
num_objs 1
set00_V006_I01346
num_objs 4
set00_V001_I00131
num_objs 1
set00_V000_I00446
num_objs 4
set00_V013_I01451
num_objs 4
set00_V006_I00143
num_objs 3
set04_V007_I01178
num_objs 1
set00_V014_I00296
num_objs 4
set00_V008_I01475
num_objs 1
set05_V000_I00446
num_objs 3
set00_V000_I00104
num_objs 1
set03_V009_I01778
num_objs 4
set00_V011_I00740
num_objs 2
set05_V004_I00140
num_objs 3
set01_V004_I01076
num_objs 3
set01_V003_I00065
num_objs 5
set01_V004_I01016
num_objs 3
set05_V010_I00512
num_objs 1
set03_V003_I01034
num_objs 2
set05_V010_I00095
num_objs 1
set05_V010_I00404
num_objs 2
set03_V003_I01442
num_objs 2
set00_V010_I01082
num_objs 0
set00_V007_I00830
num_objs 3
set00_V006_I00524
num_objs 3
set00_V008_I00089
num_objs 5
set00_V011_I01454
num_objs 4
set05_V005_I01208
num_objs 1
set03_V009_I00176
num_objs 5
set03_V001_I00110
num_objs 1
set01_V003_I01826
num_objs 1
set04_V001_I01718
num_objs 1
set04_V007_I01292
num_objs 1
set04_V007_I00821
num_objs 2
set03_V010_I00188
num_objs 1
set02_V001_I01694
num_objs 1
set00_V012_I00827
num_objs 4
set01_V002_I01676
num_objs 3
set03_V009_I01079
num_objs 5
set00_V007_I01166
num_objs 9
set01_V001_I01556
num_objs 8
set00_V008_I01346
num_objs 1
set05_V011_I00818
num_objs 5
set01_V005_I01199
num_objs 4
set04_V010_I00515
num_objs 1
set04_V001_I01739
num_objs 0
set01_V005_I00437
num_objs 4
set05_V007_I01571
num_objs 0
set03_V008_I00044
num_objs 4
set04_V010_I01709
num_objs 1
set05_V000_I00755
num_objs 1
set00_V001_I00872
num_objs 3
set03_V010_I01565
num_objs 3
set02_V009_I00524
num_objs 1
set00_V006_I00959
num_objs 0
set00_V013_I00638
num_objs 2
set04_V005_I00872
num_objs 1
set00_V007_I00764
num_objs 2
set00_V010_I00947
num_objs 1
set05_V003_I01172
num_objs 3
set03_V009_I01769
num_objs 0
set01_V001_I01382
num_objs 9
set05_V000_I00119
num_objs 2
set00_V011_I01352
num_objs 4
set00_V002_I00656
num_objs 0
set05_V005_I00611
num_objs 1
set02_V009_I00542
num_objs 2
set05_V011_I01538
num_objs 1
set01_V000_I00572
num_objs 1
set00_V010_I00569
num_objs 3
set01_V001_I00143
num_objs 3
set01_V004_I01232
num_objs 0
set03_V008_I00455
num_objs 18
set00_V010_I00341
num_objs 5
set01_V000_I01670
num_objs 3
set00_V006_I01799
num_objs 3
set04_V011_I01073
num_objs 2
set01_V000_I01067
num_objs 2
set03_V011_I01178
num_objs 1
set03_V009_I00053
num_objs 5
set05_V009_I00761
num_objs 1
set05_V002_I01091
num_objs 1
set00_V011_I01040
num_objs 10
set02_V011_I00620
num_objs 2
set01_V000_I01517
num_objs 4
set05_V010_I00338
num_objs 1
set03_V005_I00833
num_objs 1
set01_V005_I01331
num_objs 1
set05_V002_I00656
num_objs 1
set04_V004_I00776
num_objs 2
set05_V002_I00770
num_objs 1
set03_V003_I00860
num_objs 2
set00_V011_I01568
num_objs 0
set05_V010_I01013
num_objs 1
set00_V007_I00281
num_objs 6
set03_V011_I00683
num_objs 2
set03_V006_I00050
num_objs 1
set02_V009_I01445
num_objs 1
set03_V003_I00905
num_objs 2
set04_V008_I01136
num_objs 1
set04_V004_I00869
num_objs 2
set02_V011_I00476
num_objs 2
set05_V000_I01397
num_objs 1
set00_V007_I01832
num_objs 5
set04_V000_I00929
num_objs 1
set05_V002_I01526
num_objs 1
set02_V010_I01520
num_objs 1
set00_V001_I01793
num_objs 5
set00_V001_I01664
num_objs 1
set05_V012_I00326
num_objs 1
set00_V007_I00311
num_objs 6
set03_V003_I00218
num_objs 1
set03_V009_I01208
num_objs 3
set02_V010_I01190
num_objs 1
set00_V008_I00365
num_objs 1
set00_V013_I01583
num_objs 2
set00_V008_I00020
num_objs 4
set00_V001_I01517
num_objs 5
set02_V003_I00110
num_objs 1
set03_V010_I01487
num_objs 2
set00_V007_I01820
num_objs 4
set05_V000_I00335
num_objs 3
set00_V013_I01352
num_objs 3
set01_V001_I00716
num_objs 2
set05_V002_I01550
num_objs 1
set03_V008_I01544
num_objs 1
set00_V006_I00917
num_objs 4
set00_V012_I00914
num_objs 6
set04_V004_I00515
num_objs 3
set01_V005_I00383
num_objs 4
set02_V011_I00419
num_objs 0
set02_V009_I01160
num_objs 1
set04_V011_I00353
num_objs 1
set03_V011_I00485
num_objs 5
set04_V006_I01550
num_objs 1
set05_V007_I01550
num_objs 0
set00_V011_I00722
num_objs 2
set05_V011_I01205
num_objs 3
set03_V005_I00839
num_objs 0
set01_V001_I00257
num_objs 2
set05_V011_I00935
num_objs 8
set04_V003_I00455
num_objs 0
set04_V006_I01595
num_objs 1
set00_V000_I01601
num_objs 1
set03_V011_I00788
num_objs 2
set02_V009_I00455
num_objs 1
set01_V001_I00251
num_objs 1
set02_V009_I01130
num_objs 1
set00_V014_I00944
num_objs 3
set00_V011_I00527
num_objs 4
set00_V001_I01157
num_objs 4
set00_V003_I00419
num_objs 0
set01_V000_I00905
num_objs 1
set00_V013_I01274
num_objs 2
set00_V004_I00386
num_objs 1
set03_V004_I00059
num_objs 0
set05_V010_I00797
num_objs 1
set00_V006_I00686
num_objs 2
set01_V000_I01643
num_objs 3
set03_V010_I01526
num_objs 3
set04_V008_I01475
num_objs 1
set03_V008_I00155
num_objs 12
set03_V009_I00347
num_objs 4
set01_V004_I01013
num_objs 3
set04_V001_I00074
num_objs 1
set00_V012_I00761
num_objs 0
set02_V009_I01529
num_objs 0
set00_V003_I00143
num_objs 2
set00_V008_I00521
num_objs 6
set05_V000_I00263
num_objs 2
set00_V012_I00242
num_objs 3
set00_V007_I01184
num_objs 9
set00_V007_I00536
num_objs 5
set03_V009_I00359
num_objs 1
set03_V008_I01538
num_objs 1
set00_V013_I00767
num_objs 2
set01_V000_I00278
num_objs 1
set00_V007_I01454
num_objs 5
set03_V009_I00242
num_objs 4
set01_V001_I01355
num_objs 10
set02_V010_I00197
num_objs 1
set00_V007_I01817
num_objs 4
set01_V004_I01043
num_objs 3
set01_V000_I01616
num_objs 3
set05_V003_I01184
num_objs 3
set04_V006_I01481
num_objs 1
set00_V010_I00377
num_objs 6
set02_V008_I01274
num_objs 1
set03_V003_I00965
num_objs 2
set01_V001_I01352
num_objs 10
set00_V013_I00167
num_objs 3
set00_V001_I00083
num_objs 3
set04_V004_I01679
num_objs 0
set04_V011_I01526
num_objs 1
set00_V004_I01124
num_objs 0
set04_V005_I01037
num_objs 3
set00_V010_I00113
num_objs 3
set05_V000_I01529
num_objs 0
set03_V003_I00359
num_objs 1
set03_V008_I00371
num_objs 19
set00_V001_I00479
num_objs 1
set01_V004_I00113
num_objs 2
set05_V010_I01655
num_objs 1
set02_V010_I00896
num_objs 1
set01_V000_I00152
num_objs 1
set04_V004_I01202
num_objs 3
set05_V011_I01316
num_objs 2
set03_V012_I01316
num_objs 4
set04_V003_I01547
num_objs 1
set00_V014_I01058
num_objs 2
set04_V008_I01016
num_objs 1
set05_V004_I00968
num_objs 1
set05_V002_I00116
num_objs 1
set05_V009_I00929
num_objs 1
set04_V011_I00389
num_objs 1
set00_V011_I00863
num_objs 0
set01_V002_I00032
num_objs 2
set00_V001_I01016
num_objs 12
set00_V014_I00233
num_objs 3
set04_V000_I00506
num_objs 2
set00_V006_I01580
num_objs 2
set05_V002_I00674
num_objs 1
set02_V008_I01112
num_objs 0
set01_V002_I01253
num_objs 4
set00_V008_I00035
num_objs 7
set01_V004_I01487
num_objs 2
set00_V011_I00392
num_objs 3
set00_V011_I00461
num_objs 6
set01_V001_I01748
num_objs 1
set03_V008_I00515
num_objs 16
set03_V003_I00038
num_objs 2
set04_V003_I01364
num_objs 3
set00_V013_I00905
num_objs 1
set00_V000_I00677
num_objs 1
set02_V009_I00347
num_objs 2
set00_V003_I00476
num_objs 1
set05_V003_I01622
num_objs 0
set01_V005_I01355
num_objs 1
set01_V004_I01535
num_objs 2
set04_V001_I01658
num_objs 2
set02_V009_I00176
num_objs 2
set00_V009_I00224
num_objs 7
set05_V003_I01595
num_objs 0
set03_V008_I00911
num_objs 1
set01_V003_I00518
num_objs 3
set00_V006_I00764
num_objs 0
set03_V009_I01283
num_objs 0
set03_V009_I01037
num_objs 6
set00_V001_I00491
num_objs 3
set01_V001_I00341
num_objs 5
set05_V010_I00710
num_objs 1
set03_V008_I00473
num_objs 16
set00_V013_I00986
num_objs 1
set04_V010_I01667
num_objs 2
set00_V007_I01355
num_objs 6
set01_V005_I00092
num_objs 2
set05_V011_I00734
num_objs 2
set01_V000_I00107
num_objs 1
set00_V001_I00536
num_objs 3
set00_V008_I00698
num_objs 3
set04_V008_I01010
num_objs 1
set03_V003_I00071
num_objs 2
set02_V001_I01556
num_objs 1
set05_V007_I01586
num_objs 0
set02_V010_I00287
num_objs 1
set00_V009_I00275
num_objs 5
set01_V001_I01733
num_objs 2
set05_V012_I00737
num_objs 2
set04_V005_I00041
num_objs 1
set00_V001_I00194
num_objs 2
set00_V009_I01211
num_objs 1
set00_V007_I00290
num_objs 6
set01_V004_I00059
num_objs 2
set04_V002_I01643
num_objs 2
set04_V007_I01346
num_objs 1
set01_V002_I01589
num_objs 3
set03_V012_I01541
num_objs 4
set03_V003_I00575
num_objs 2
set03_V001_I00101
num_objs 1
set00_V006_I01532
num_objs 2
set01_V001_I01280
num_objs 11
set04_V002_I01025
num_objs 2
set04_V004_I00500
num_objs 3
set00_V009_I01319
num_objs 1
set05_V010_I00680
num_objs 1
set05_V011_I00569
num_objs 1
set02_V010_I00380
num_objs 1
set04_V003_I01112
num_objs 3
set01_V000_I01202
num_objs 3
set01_V003_I00260
num_objs 4
set00_V006_I01562
num_objs 2
set01_V005_I00272
num_objs 1
set04_V004_I00497
num_objs 3
set01_V004_I01364
num_objs 1
set00_V007_I00713
num_objs 1
set01_V001_I00875
num_objs 1
set03_V003_I01523
num_objs 2
set00_V012_I00518
num_objs 2
set01_V004_I01604
num_objs 1
set01_V004_I00044
num_objs 2
set04_V005_I01073
num_objs 3
set05_V005_I00935
num_objs 1
set03_V009_I00560
num_objs 4
set01_V004_I00287
num_objs 2
set04_V006_I00665
num_objs 3
set02_V009_I00836
num_objs 1
set05_V010_I01079
num_objs 0
set04_V002_I01127
num_objs 2
set00_V014_I01334
num_objs 6
set04_V011_I00329
num_objs 1
set00_V000_I00653
num_objs 1
set04_V007_I01781
num_objs 1
set04_V003_I01193
num_objs 3
set04_V010_I00740
num_objs 1
set04_V001_I00185
num_objs 1
set03_V009_I00569
num_objs 2
set04_V003_I00914
num_objs 1
set03_V005_I01685
num_objs 1
set00_V000_I00509
num_objs 1
set03_V008_I01676
num_objs 2
set00_V008_I01421
num_objs 1
set02_V009_I01409
num_objs 0
set00_V001_I00686
num_objs 3
set03_V008_I00968
num_objs 1
set04_V001_I00125
num_objs 1
set03_V005_I01166
num_objs 2
set02_V008_I00575
num_objs 1
set01_V004_I01520
num_objs 2
set01_V005_I01517
num_objs 0
set00_V011_I00287
num_objs 2
set03_V005_I01070
num_objs 1
set04_V010_I00629
num_objs 0
set05_V010_I00545
num_objs 1
set04_V010_I00734
num_objs 1
set03_V009_I01790
num_objs 4
set00_V010_I01301
num_objs 3
set05_V010_I00548
num_objs 1
set05_V005_I00944
num_objs 1
set03_V004_I00476
num_objs 1
set04_V007_I01349
num_objs 0
set01_V005_I01670
num_objs 0
set04_V008_I01358
num_objs 1
set00_V002_I00863
num_objs 9
set00_V004_I00890
num_objs 2
set00_V003_I00368
num_objs 1
set01_V004_I00938
num_objs 3
set00_V012_I01436
num_objs 2
set00_V004_I01103
num_objs 1
set04_V010_I01592
num_objs 2
set05_V000_I00656
num_objs 1
set01_V002_I00452
num_objs 5
set04_V007_I00437
num_objs 1
set01_V003_I01265
num_objs 1
set03_V005_I00893
num_objs 1
set04_V002_I00686
num_objs 2
set04_V004_I00920
num_objs 2
set00_V001_I00302
num_objs 6
set04_V006_I01535
num_objs 1
set01_V001_I00917
num_objs 1
set05_V011_I01355
num_objs 1
set00_V011_I00164
num_objs 2
set01_V002_I00131
num_objs 6
set00_V006_I01484
num_objs 3
set00_V011_I00851
num_objs 0
set04_V002_I01415
num_objs 3
set00_V010_I01211
num_objs 2
set01_V003_I01640
num_objs 2
set02_V003_I00305
num_objs 1
set05_V010_I00653
num_objs 1
set00_V000_I01844
num_objs 1
set03_V002_I01406
num_objs 1
set01_V003_I00131
num_objs 8
set05_V011_I01301
num_objs 2
set04_V004_I01658
num_objs 3
set00_V008_I00965
num_objs 1
set04_V002_I01286
num_objs 2
set00_V001_I00599
num_objs 2
set03_V002_I01553
num_objs 1
set03_V008_I00542
num_objs 12
set02_V011_I01577
num_objs 2
set01_V003_I00701
num_objs 2
set01_V000_I01412
num_objs 4
set00_V012_I00785
num_objs 2
set00_V004_I00263
num_objs 1
set00_V006_I01214
num_objs 5
set03_V005_I01652
num_objs 1
set04_V010_I01643
num_objs 2
set01_V004_I00914
num_objs 3
set04_V005_I00809
num_objs 0
set05_V008_I01832
num_objs 1
set00_V004_I01421
num_objs 2
set02_V007_I00119
num_objs 1
set00_V011_I00878
num_objs 0
set01_V000_I00839
num_objs 0
set01_V004_I01199
num_objs 7
set01_V003_I01529
num_objs 1
set05_V011_I01106
num_objs 5
set03_V005_I00779
num_objs 0
set04_V001_I01685
num_objs 2
set00_V014_I01361
num_objs 7
set01_V005_I01262
num_objs 1
set01_V001_I00797
num_objs 1
set01_V004_I01472
num_objs 2
set04_V003_I00275
num_objs 1
set05_V010_I00707
num_objs 1
set01_V003_I00242
num_objs 5
set04_V007_I01253
num_objs 1
set03_V008_I01586
num_objs 2
set05_V000_I01670
num_objs 1
set01_V003_I01523
num_objs 1
set04_V007_I00239
num_objs 1
set03_V003_I00632
num_objs 2
set00_V008_I00404
num_objs 2
set04_V004_I00089
num_objs 0
set04_V008_I00626
num_objs 1
set05_V009_I00878
num_objs 1
set00_V008_I01091
num_objs 0
set03_V001_I00068
num_objs 1
set03_V005_I00818
num_objs 1
set04_V006_I01499
num_objs 1
set01_V000_I01166
num_objs 3
set04_V003_I01259
num_objs 2
set03_V005_I01490
num_objs 1
set01_V002_I01262
num_objs 4
set00_V006_I01697
num_objs 0
set02_V011_I00734
num_objs 1
set00_V014_I01325
num_objs 6
set05_V012_I00662
num_objs 1
set00_V001_I00218
num_objs 4
set05_V005_I01013
num_objs 1
set00_V007_I01109
num_objs 1
set03_V005_I00665
num_objs 1
set01_V002_I01106
num_objs 3
set02_V009_I01367
num_objs 1
set01_V005_I00911
num_objs 2
set03_V005_I01202
num_objs 3
set00_V009_I00470
num_objs 2
set00_V012_I00635
num_objs 0
set03_V011_I01403
num_objs 1
set00_V000_I00686
num_objs 1
set01_V001_I00722
num_objs 2
set03_V008_I00452
num_objs 18
set05_V012_I00590
num_objs 0
set03_V011_I01190
num_objs 1
set00_V000_I01823
num_objs 1
set01_V005_I00446
num_objs 4
set00_V006_I01838
num_objs 0
set03_V012_I01574
num_objs 3
set01_V003_I01604
num_objs 1
set04_V000_I00614
num_objs 3
set04_V005_I01028
num_objs 3
set00_V007_I00212
num_objs 5
set03_V003_I01367
num_objs 2
set04_V008_I01487
num_objs 1
set04_V005_I00167
num_objs 1
set04_V007_I00605
num_objs 2
set00_V013_I00671
num_objs 1
set02_V010_I00128
num_objs 0
set05_V010_I01073
num_objs 1
set01_V002_I01010
num_objs 1
set02_V010_I00872
num_objs 1
set03_V005_I01772
num_objs 2
set04_V001_I01649
num_objs 1
set00_V013_I01085
num_objs 2
set00_V014_I01163
num_objs 3
set00_V008_I00482
num_objs 6
set04_V007_I00689
num_objs 0
set02_V007_I00368
num_objs 1
set00_V001_I00659
num_objs 1
set03_V003_I01022
num_objs 2
set03_V005_I01601
num_objs 1
set02_V003_I00137
num_objs 1
set00_V010_I00614
num_objs 4
set02_V011_I00923
num_objs 1
set04_V004_I00236
num_objs 1
set02_V010_I00908
num_objs 1
set02_V009_I01556
num_objs 1
set04_V006_I00953
num_objs 2
set00_V007_I01373
num_objs 4
set05_V004_I00131
num_objs 3
set04_V002_I01256
num_objs 2
set02_V011_I00608
num_objs 2
set04_V002_I01634
num_objs 2
set00_V004_I01115
num_objs 1
set02_V011_I01691
num_objs 2
set01_V005_I01730
num_objs 0
set02_V009_I00560
num_objs 2
set00_V013_I01520
num_objs 4
set00_V002_I00884
num_objs 8
set04_V006_I00683
num_objs 3
set01_V002_I00620
num_objs 7
set00_V010_I00245
num_objs 1
set03_V008_I00428
num_objs 19
set04_V007_I01109
num_objs 1
set02_V001_I00341
num_objs 1
set00_V014_I01655
num_objs 4
set00_V010_I01358
num_objs 4
set00_V011_I01517
num_objs 4
set01_V001_I01574
num_objs 7
set00_V004_I01073
num_objs 1
set04_V003_I01154
num_objs 3
set01_V002_I00491
num_objs 6
set04_V002_I00650
num_objs 2
set03_V009_I01529
num_objs 0
set03_V005_I01820
num_objs 2
set00_V001_I01076
num_objs 9
set00_V007_I00941
num_objs 3
set03_V012_I00041
num_objs 1
set00_V008_I01010
num_objs 1
set04_V007_I00692
num_objs 2
set00_V012_I00359
num_objs 0
set00_V006_I01160
num_objs 5
set00_V011_I00143
num_objs 2
set05_V005_I00959
num_objs 0
set04_V007_I01037
num_objs 2
set03_V003_I01538
num_objs 2
set01_V000_I00515
num_objs 1
set04_V000_I00638
num_objs 3
set03_V005_I01193
num_objs 3
set00_V008_I01241
num_objs 2
set05_V007_I01754
num_objs 0
set01_V003_I01274
num_objs 1
set00_V006_I01076
num_objs 7
set00_V012_I01415
num_objs 2
set01_V004_I00095
num_objs 2
set05_V011_I01703
num_objs 1
set05_V003_I00980
num_objs 1
set03_V008_I01238
num_objs 2
set00_V012_I00194
num_objs 1
set03_V008_I01748
num_objs 1
set00_V013_I00830
num_objs 2
set00_V007_I01481
num_objs 4
set00_V014_I00341
num_objs 3
set04_V004_I00080
num_objs 1
set03_V003_I01088
num_objs 2
set05_V003_I01256
num_objs 3
set03_V009_I00527
num_objs 4
set04_V003_I00485
num_objs 0
set01_V004_I00941
num_objs 3
set00_V006_I01904
num_objs 0
set00_V013_I00365
num_objs 4
set04_V011_I00377
num_objs 1
set03_V004_I00164
num_objs 1
set04_V001_I01517
num_objs 1
set00_V010_I00905
num_objs 2
set04_V011_I01862
num_objs 1
set03_V003_I00833
num_objs 2
set01_V004_I00944
num_objs 3
set00_V014_I01355
num_objs 6
set02_V008_I01238
num_objs 1
set03_V007_I00275
num_objs 1
set00_V003_I00380
num_objs 1
set00_V001_I00140
num_objs 1
set05_V010_I00479
num_objs 0
set00_V009_I01496
num_objs 3
set05_V000_I00587
num_objs 1
set01_V002_I00635
num_objs 7
set01_V003_I01004
num_objs 2
set03_V011_I00845
num_objs 2
set04_V004_I01037
num_objs 2
set00_V008_I00557
num_objs 6
set03_V006_I00143
num_objs 1
set00_V013_I01316
num_objs 5
set02_V009_I00440
num_objs 1
set05_V010_I00566
num_objs 1
set03_V008_I00032
num_objs 4
set00_V001_I00068
num_objs 1
set00_V013_I00071
num_objs 4
set00_V012_I00443
num_objs 0
set03_V001_I00824
num_objs 1
set02_V001_I00074
num_objs 0
set02_V001_I00101
num_objs 0
set03_V009_I00383
num_objs 3
set00_V013_I01535
num_objs 4
set00_V014_I01043
num_objs 3
set05_V005_I00461
num_objs 1
set03_V011_I00251
num_objs 3
set02_V010_I00014
num_objs 0
set03_V003_I00128
num_objs 2
set00_V004_I01397
num_objs 2
set02_V009_I00518
num_objs 1
set04_V000_I00704
num_objs 3
set01_V001_I01310
num_objs 11
set05_V005_I00413
num_objs 1
set03_V006_I00032
num_objs 1
set03_V003_I00014
num_objs 2
set00_V001_I01691
num_objs 1
set03_V009_I01748
num_objs 4
set01_V001_I00032
num_objs 2
set00_V007_I00848
num_objs 3
set03_V010_I01388
num_objs 2
set03_V011_I00233
num_objs 3
set01_V005_I01607
num_objs 0
set00_V007_I01244
num_objs 8
set00_V001_I00266
num_objs 5
set01_V000_I01163
num_objs 3
set00_V009_I00392
num_objs 1
set02_V003_I00194
num_objs 1
set00_V008_I00734
num_objs 2
set00_V007_I01013
num_objs 1
set03_V009_I01295
num_objs 0
set04_V007_I01748
num_objs 1
set05_V011_I01241
num_objs 3
set01_V002_I00668
num_objs 6
set02_V008_I00815
num_objs 1
set01_V002_I01457
num_objs 0
set00_V014_I00251
num_objs 1
set00_V006_I00350
num_objs 4
set04_V004_I00905
num_objs 2
set01_V001_I00992
num_objs 1
set04_V004_I00170
num_objs 2
set03_V008_I01553
num_objs 1
set00_V002_I00203
num_objs 2
set03_V009_I01508
num_objs 2
set00_V007_I01625
num_objs 6
set00_V011_I01214
num_objs 3
set05_V010_I00434
num_objs 1
set05_V011_I00770
num_objs 4
set01_V001_I00290
num_objs 3
set01_V002_I01667
num_objs 4
set01_V000_I01511
num_objs 4
set00_V010_I01436
num_objs 4
set03_V003_I00092
num_objs 2
set02_V011_I00404
num_objs 2
set02_V011_I00797
num_objs 0
set00_V007_I00890
num_objs 4
set02_V011_I01667
num_objs 2
set02_V010_I00437
num_objs 1
set04_V003_I00071
num_objs 0
set02_V009_I00728
num_objs 2
set00_V009_I01493
num_objs 3
set02_V007_I00497
num_objs 1
set00_V002_I00404
num_objs 0
set02_V010_I01448
num_objs 1
set05_V003_I01226
num_objs 3
set04_V011_I01124
num_objs 1
set02_V011_I00329
num_objs 0
set00_V004_I00260
num_objs 1
set03_V008_I01658
num_objs 2
set05_V011_I00947
num_objs 8
set04_V008_I01085
num_objs 1
set01_V005_I00644
num_objs 2
set00_V000_I01055
num_objs 0
set00_V010_I01157
num_objs 2
set02_V010_I01787
num_objs 1
set01_V005_I00689
num_objs 2
set04_V003_I00026
num_objs 0
set02_V003_I00059
num_objs 0
set05_V000_I01520
num_objs 1
set03_V012_I01337
num_objs 4
set00_V002_I00557
num_objs 0
set05_V011_I01130
num_objs 5
set05_V005_I00620
num_objs 1
set03_V003_I00230
num_objs 1
set04_V002_I01601
num_objs 2
set03_V012_I01268
num_objs 0
set04_V011_I00365
num_objs 1
set04_V010_I00581
num_objs 1
set04_V007_I01589
num_objs 1
set00_V002_I00650
num_objs 0
set00_V011_I00785
num_objs 1
set03_V007_I01514
num_objs 0
set01_V003_I01649
num_objs 6
set00_V010_I00158
num_objs 2
set04_V007_I01625
num_objs 1
set03_V008_I01280
num_objs 3
set04_V003_I00188
num_objs 0
set04_V004_I00602
num_objs 3
set01_V001_I01034
num_objs 1
set01_V004_I00500
num_objs 1
set00_V011_I00230
num_objs 1
set04_V010_I01616
num_objs 2
set01_V004_I00176
num_objs 1
set01_V003_I01667
num_objs 2
set03_V006_I00182
num_objs 0
set03_V010_I00116
num_objs 2
set00_V003_I00449
num_objs 0
set05_V011_I01013
num_objs 8
set04_V010_I00491
num_objs 1
set03_V008_I00998
num_objs 1
set03_V003_I00587
num_objs 2
set05_V005_I00833
num_objs 2
set04_V010_I00617
num_objs 1
set00_V001_I00875
num_objs 3
set00_V006_I01766
num_objs 1
set04_V002_I00983
num_objs 2
set02_V011_I00575
num_objs 2
set02_V009_I00866
num_objs 1
set00_V014_I00527
num_objs 5
set01_V001_I01415
num_objs 12
set02_V009_I00251
num_objs 2
set00_V008_I01526
num_objs 1
set03_V009_I01340
num_objs 1
set00_V001_I01112
num_objs 8
set01_V004_I00002
num_objs 2
set01_V005_I01337
num_objs 1
set05_V009_I00905
num_objs 1
set04_V003_I01064
num_objs 4
set03_V008_I00479
num_objs 16
set02_V009_I00734
num_objs 2
set00_V008_I00863
num_objs 1
set01_V003_I01643
num_objs 2
set03_V012_I00044
num_objs 1
set05_V001_I00428
num_objs 0
set05_V010_I01541
num_objs 1
set01_V002_I01028
num_objs 1
set05_V011_I01382
num_objs 2
set00_V000_I01538
num_objs 1
set00_V010_I00938
num_objs 1
set04_V011_I01784
num_objs 1
set01_V002_I00089
num_objs 1
set03_V004_I00134
num_objs 1
set04_V000_I00887
num_objs 1
set03_V003_I01343
num_objs 2
set02_V011_I00635
num_objs 2
set03_V003_I00065
num_objs 2
set01_V000_I00932
num_objs 2
set03_V009_I00653
num_objs 3
set04_V006_I00590
num_objs 1
set02_V010_I00893
num_objs 1
set00_V013_I01127
num_objs 4
set04_V004_I01415
num_objs 1
set00_V011_I00782
num_objs 1
set03_V003_I01490
num_objs 2
set03_V009_I00470
num_objs 3
set00_V000_I00407
num_objs 3
set00_V007_I00314
num_objs 6
set00_V013_I01178
num_objs 1
set02_V010_I01391
num_objs 1
set00_V014_I01193
num_objs 4
set03_V008_I00413
num_objs 16
set03_V011_I00419
num_objs 4
set04_V011_I00350
num_objs 1
set01_V000_I00368
num_objs 2
set00_V009_I01487
num_objs 2
set00_V013_I00041
num_objs 3
set03_V003_I00908
num_objs 2
set00_V000_I00098
num_objs 1
set04_V002_I01562
num_objs 1
set01_V004_I01466
num_objs 1
set01_V003_I00068
num_objs 5
set04_V010_I00422
num_objs 1
set04_V007_I01160
num_objs 1
set00_V008_I00671
num_objs 3
set01_V000_I01364
num_objs 4
set02_V001_I00137
num_objs 0
set00_V010_I01445
num_objs 4
set00_V007_I00320
num_objs 6
set00_V004_I01100
num_objs 1
set01_V005_I00965
num_objs 3
set04_V007_I01322
num_objs 1
set04_V011_I00320
num_objs 1
set03_V001_I00083
num_objs 1
set00_V000_I01562
num_objs 2
set00_V001_I00032
num_objs 2
set00_V004_I01154
num_objs 0
set00_V004_I01379
num_objs 9
set04_V006_I01541
num_objs 1
set03_V008_I00848
num_objs 1
set04_V005_I01643
num_objs 1
set04_V004_I00941
num_objs 2
set02_V011_I01334
num_objs 1
set01_V002_I01037
num_objs 1
set05_V004_I01043
num_objs 1
set04_V011_I01616
num_objs 1
set00_V007_I00413
num_objs 6
set01_V005_I01673
num_objs 0
set01_V001_I00698
num_objs 3
set00_V012_I00881
num_objs 6
set00_V009_I00743
num_objs 3
set00_V011_I01421
num_objs 2
set00_V000_I01169
num_objs 0
set04_V007_I00890
num_objs 2
set03_V005_I00479
num_objs 2
set05_V010_I00896
num_objs 2
set02_V008_I00497
num_objs 1
set00_V007_I01520
num_objs 3
set00_V014_I00452
num_objs 4
set05_V000_I00509
num_objs 0
set00_V008_I00683
num_objs 3
set03_V011_I00623
num_objs 3
set00_V007_I01478
num_objs 4
set01_V005_I01037
num_objs 3
set00_V001_I01628
num_objs 3
set04_V010_I01565
num_objs 2
set00_V010_I00080
num_objs 4
set00_V006_I00326
num_objs 4
set02_V009_I01625
num_objs 2
set02_V009_I00293
num_objs 1
set00_V007_I00419
num_objs 3
set02_V011_I01775
num_objs 2
set05_V005_I01217
num_objs 1
set02_V009_I01394
num_objs 1
set01_V001_I00113
num_objs 4
set04_V002_I00761
num_objs 2
set04_V004_I00545
num_objs 3
set01_V005_I00107
num_objs 2
set03_V009_I00956
num_objs 3
set00_V013_I01367
num_objs 3
set03_V005_I00584
num_objs 3
set01_V000_I00164
num_objs 1
set03_V003_I00296
num_objs 1
set04_V000_I00710
num_objs 3
set03_V010_I01556
num_objs 3
set00_V010_I00452
num_objs 7
set00_V000_I00260
num_objs 5
set05_V011_I00503
num_objs 1
set04_V005_I01049
num_objs 2
set00_V014_I01874
num_objs 1
set05_V011_I01583
num_objs 1
set00_V010_I00056
num_objs 3
set05_V007_I01481
num_objs 1
set01_V005_I00959
num_objs 3
set01_V005_I01574
num_objs 0
set00_V009_I00212
num_objs 7
set00_V014_I01463
num_objs 3
set03_V005_I00677
num_objs 1
set03_V008_I00572
num_objs 10
set00_V012_I00425
num_objs 0
set00_V009_I00119
num_objs 2
set02_V009_I01601
num_objs 2
set02_V009_I01526
num_objs 1
set04_V002_I01409
num_objs 0
set01_V004_I01616
num_objs 1
set04_V005_I00077
num_objs 1
set01_V001_I00629
num_objs 3
set02_V001_I00146
num_objs 0
set04_V008_I01517
num_objs 1
set00_V004_I01448
num_objs 2
set04_V004_I00842
num_objs 2
set00_V006_I00173
num_objs 3
set02_V010_I00020
num_objs 0
set00_V012_I01037
num_objs 1
set01_V005_I00605
num_objs 3
set00_V011_I00968
num_objs 10
set01_V001_I00830
num_objs 1
set00_V010_I00137
num_objs 5
set03_V009_I00998
num_objs 2
set03_V011_I00173
num_objs 3
set03_V005_I00566
num_objs 3
set00_V008_I01487
num_objs 0
set00_V009_I00398
num_objs 1
set02_V010_I01304
num_objs 1
set03_V010_I01424
num_objs 2
set02_V010_I00431
num_objs 1
set02_V010_I00890
num_objs 1
set00_V001_I00884
num_objs 3
set04_V007_I00359
num_objs 0
set04_V003_I00185
num_objs 0
set03_V012_I01424
num_objs 3
set05_V011_I00524
num_objs 1
set00_V008_I01547
num_objs 1
set00_V010_I00743
num_objs 1
set00_V001_I00143
num_objs 1
set00_V009_I00206
num_objs 7
set05_V002_I01595
num_objs 1
set01_V005_I01418
num_objs 0
set00_V006_I00842
num_objs 2
set03_V005_I00896
num_objs 1
set05_V010_I00980
num_objs 1
set00_V000_I00854
num_objs 0
set01_V005_I01424
num_objs 0
set04_V007_I00218
num_objs 1
set03_V009_I00239
num_objs 4
set01_V003_I00917
num_objs 2
set04_V002_I01691
num_objs 2
set00_V006_I01157
num_objs 5
set05_V010_I00722
num_objs 1
set00_V008_I00227
num_objs 0
set02_V010_I00236
num_objs 1
set00_V012_I01199
num_objs 4
set04_V006_I00701
num_objs 3
set04_V007_I01088
num_objs 2
set04_V002_I01268
num_objs 2
set00_V001_I00206
num_objs 3
set03_V012_I01382
num_objs 5
set01_V001_I01175
num_objs 3
set00_V001_I00938
num_objs 6
set01_V000_I00026
num_objs 1
set05_V005_I00677
num_objs 1
set00_V009_I00302
num_objs 6
set03_V001_I00029
num_objs 0
set03_V012_I01319
num_objs 2
set00_V004_I01343
num_objs 1
set05_V005_I00560
num_objs 1
set00_V014_I01064
num_objs 2
set03_V011_I00674
num_objs 2
set00_V012_I00986
num_objs 4
set05_V001_I00389
num_objs 0
set03_V009_I01181
num_objs 2
set04_V000_I00917
num_objs 1
set05_V005_I00794
num_objs 1
set03_V009_I00812
num_objs 2
set05_V000_I00311
num_objs 4
set00_V001_I00170
num_objs 2
set03_V006_I00011
num_objs 1
set01_V002_I01646
num_objs 4
set04_V003_I00326
num_objs 1
set00_V008_I00749
num_objs 1
set01_V004_I01151
num_objs 4
set03_V008_I00818
num_objs 2
set02_V001_I00155
num_objs 0
set04_V011_I00359
num_objs 1
set04_V003_I00329
num_objs 0
set00_V010_I00296
num_objs 3
set03_V008_I00419
num_objs 14
set00_V013_I00248
num_objs 4
set01_V002_I01169
num_objs 3
set00_V010_I01355
num_objs 4
set04_V011_I01157
num_objs 1
set04_V011_I00974
num_objs 1
set00_V002_I00368
num_objs 1
set02_V010_I00011
num_objs 0
set01_V001_I01523
num_objs 11
set05_V010_I00578
num_objs 1
set00_V001_I01367
num_objs 3
set04_V002_I00716
num_objs 3
set02_V007_I00179
num_objs 0
set03_V005_I00404
num_objs 2
set04_V003_I00224
num_objs 0
set03_V012_I01502
num_objs 3
set03_V008_I01376
num_objs 3
set01_V005_I00788
num_objs 2
set00_V001_I01796
num_objs 5
set00_V001_I00464
num_objs 1
set05_V003_I01394
num_objs 2
set01_V001_I01601
num_objs 3
set04_V002_I00632
num_objs 1
set04_V007_I01478
num_objs 1
set00_V001_I01769
num_objs 2
set05_V001_I00365
num_objs 0
set04_V004_I00470
num_objs 3
set03_V006_I00155
num_objs 1
set04_V011_I01520
num_objs 1
set01_V001_I00455
num_objs 4
set04_V004_I01865
num_objs 1
set04_V002_I01262
num_objs 2
set03_V007_I01535
num_objs 0
set03_V005_I01076
num_objs 1
set04_V003_I01496
num_objs 2
set04_V003_I01769
num_objs 1
set00_V004_I00860
num_objs 1
set00_V011_I00350
num_objs 3
set05_V005_I01211
num_objs 1
set00_V012_I00227
num_objs 2
set00_V013_I01193
num_objs 0
set02_V009_I00485
num_objs 1
set03_V009_I00554
num_objs 4
set01_V002_I00653
num_objs 7
set00_V011_I01094
num_objs 7
set02_V011_I00455
num_objs 1
set05_V012_I00263
num_objs 1
set03_V004_I00221
num_objs 1
set05_V007_I01343
num_objs 1
set04_V002_I00878
num_objs 1
set02_V011_I01442
num_objs 2
set01_V005_I01016
num_objs 3
set00_V006_I01142
num_objs 5
set05_V010_I01646
num_objs 1
set00_V006_I00803
num_objs 2
set01_V005_I01205
num_objs 3
set00_V012_I00365
num_objs 0
set00_V006_I00605
num_objs 4
set03_V003_I01430
num_objs 2
set04_V007_I00575
num_objs 2
set00_V005_I00812
num_objs 1
set04_V007_I01529
num_objs 1
set01_V003_I01829
num_objs 6
set01_V002_I01517
num_objs 0
set05_V007_I01199
num_objs 1
set02_V003_I00047
num_objs 1
set01_V005_I00365
num_objs 3
set01_V002_I00110
num_objs 5
set05_V001_I00353
num_objs 0
set00_V011_I00158
num_objs 2
set01_V002_I01187
num_objs 2
set04_V010_I00614
num_objs 1
set05_V012_I01154
num_objs 1
set04_V007_I01688
num_objs 1
set02_V008_I00551
num_objs 1
set05_V012_I00482
num_objs 3
set05_V002_I00650
num_objs 1
set00_V007_I01556
num_objs 7
set05_V007_I01511
num_objs 1
set04_V003_I01001
num_objs 4
set02_V009_I00173
num_objs 2
set03_V006_I00026
num_objs 1
set00_V009_I00680
num_objs 2
set01_V000_I01676
num_objs 3
set04_V002_I00812
num_objs 1
set02_V001_I01418
num_objs 1
set01_V002_I00533
num_objs 8
set04_V006_I00515
num_objs 1
set05_V005_I00629
num_objs 1
set03_V006_I01823
num_objs 1
set00_V001_I01073
num_objs 10
set01_V002_I00467
num_objs 5
set02_V011_I01556
num_objs 2
set01_V004_I00476
num_objs 1
set01_V002_I00677
num_objs 6
set04_V003_I00320
num_objs 1
set04_V000_I00680
num_objs 3
set01_V004_I00146
num_objs 2
set02_V011_I01376
num_objs 2
set02_V010_I00773
num_objs 2
set00_V000_I01511
num_objs 1
set04_V003_I01076
num_objs 4
set00_V001_I01451
num_objs 4
set03_V012_I01559
num_objs 2
set04_V007_I00623
num_objs 2
set01_V000_I01658
num_objs 3
set02_V009_I00398
num_objs 2
set04_V003_I01226
num_objs 3
set00_V011_I00419
num_objs 0
set04_V001_I01499
num_objs 1
set03_V004_I00563
num_objs 1
set03_V009_I00419
num_objs 2
set01_V001_I01742
num_objs 2
set04_V003_I00521
num_objs 0
set04_V011_I01496
num_objs 1
set05_V009_I00764
num_objs 1
set04_V011_I01172
num_objs 1
set00_V002_I00209
num_objs 2
set01_V002_I00593
num_objs 7
set00_V004_I00467
num_objs 1
set00_V004_I00158
num_objs 1
set01_V005_I01139
num_objs 5
set04_V003_I00194
num_objs 0
set02_V010_I00878
num_objs 1
set00_V001_I00122
num_objs 3
set04_V004_I01031
num_objs 2
set03_V006_I01697
num_objs 1
set00_V013_I01121
num_objs 4
set05_V010_I01571
num_objs 1
set03_V008_I00563
num_objs 11
set02_V011_I01601
num_objs 2
set01_V003_I00404
num_objs 3
set04_V005_I00170
num_objs 1
set00_V011_I01544
num_objs 0
set00_V006_I00833
num_objs 2
set00_V000_I01664
num_objs 2
set05_V011_I00989
num_objs 4
set03_V007_I00263
num_objs 1
set04_V002_I01511
num_objs 3
set05_V002_I00647
num_objs 1
set01_V005_I00548
num_objs 2
set00_V010_I00599
num_objs 5
set01_V001_I00704
num_objs 2
set01_V004_I00512
num_objs 1
set00_V007_I00383
num_objs 6
set02_V009_I00692
num_objs 2
set03_V009_I00665
num_objs 3
set00_V010_I00404
num_objs 8
set00_V000_I01754
num_objs 1
set00_V000_I00776
num_objs 0
set01_V003_I00758
num_objs 2
set01_V000_I00116
num_objs 1
set04_V010_I00962
num_objs 1
set01_V000_I01493
num_objs 5
set05_V011_I01694
num_objs 1
set00_V004_I00773
num_objs 1
set04_V007_I01196
num_objs 1
set03_V005_I01424
num_objs 1
set02_V009_I01763
num_objs 1
set04_V010_I00950
num_objs 1
set00_V014_I01763
num_objs 0
set05_V010_I01826
num_objs 0
set04_V007_I01409
num_objs 0
set04_V003_I01799
num_objs 0
set00_V011_I00395
num_objs 3
set03_V003_I00089
num_objs 2
set00_V007_I01679
num_objs 3
set05_V010_I00011
num_objs 1
set04_V004_I00764
num_objs 2
set01_V002_I01691
num_objs 4
set00_V013_I00566
num_objs 2
set00_V012_I01148
num_objs 0
set04_V011_I01154
num_objs 1
set04_V003_I00119
num_objs 0
set00_V009_I00992
num_objs 4
set05_V000_I00221
num_objs 2
set00_V009_I01016
num_objs 2
set05_V010_I00365
num_objs 1
set00_V014_I00311
num_objs 5
set04_V011_I00374
num_objs 1
set03_V010_I01769
num_objs 2
set00_V008_I00284
num_objs 0
set03_V005_I01307
num_objs 1
set04_V003_I01523
num_objs 1
set04_V005_I00101
num_objs 1
set00_V009_I01583
num_objs 4
set00_V007_I01766
num_objs 4
set00_V007_I01241
num_objs 8
set00_V012_I01610
num_objs 1
set00_V012_I01031
num_objs 2
set05_V012_I00530
num_objs 1
set04_V006_I00968
num_objs 2
set00_V011_I00884
num_objs 0
set00_V013_I00788
num_objs 1
set01_V002_I00908
num_objs 4
set00_V001_I00332
num_objs 5
set03_V008_I01727
num_objs 1
set00_V009_I01700
num_objs 0
set01_V002_I01835
num_objs 6
set03_V008_I00845
num_objs 1
set02_V001_I00113
num_objs 0
set03_V009_I00758
num_objs 2
set05_V011_I00767
num_objs 4
set04_V003_I00044
num_objs 0
set03_V008_I01097
num_objs 1
set05_V005_I00242
num_objs 1
set04_V003_I01358
num_objs 3
set00_V014_I00110
num_objs 3
set03_V005_I01799
num_objs 2
set01_V002_I00479
num_objs 2
set00_V010_I01451
num_objs 5
set00_V011_I00470
num_objs 5
set01_V003_I00134
num_objs 8
set03_V003_I00998
num_objs 2
set01_V000_I00059
num_objs 2
set00_V007_I01394
num_objs 3
set03_V008_I01385
num_objs 3
set01_V002_I00896
num_objs 4
set01_V004_I01433
num_objs 1
set04_V002_I00860
num_objs 1
set00_V012_I00314
num_objs 2
set01_V004_I00497
num_objs 1
set03_V009_I00755
num_objs 2
set01_V003_I01748
num_objs 1
set04_V000_I00983
num_objs 1
set03_V005_I00524
num_objs 3
set01_V001_I00362
num_objs 4
set03_V003_I00710
num_objs 2
set02_V011_I01502
num_objs 2
set02_V008_I00803
num_objs 1
set01_V000_I00434
num_objs 3
set05_V010_I01055
num_objs 1
set00_V002_I00908
num_objs 5
set05_V002_I00632
num_objs 1
set01_V004_I00518
num_objs 1
set05_V000_I00611
num_objs 1
set01_V005_I00539
num_objs 1
set04_V003_I00962
num_objs 4
set00_V004_I00830
num_objs 1
set01_V002_I01229
num_objs 3
set02_V010_I01511
num_objs 2
set03_V004_I00032
num_objs 1
set02_V003_I00071
num_objs 1
set03_V010_I01406
num_objs 2
set00_V014_I01205
num_objs 4
set00_V013_I01286
num_objs 2
set03_V009_I00248
num_objs 3
set03_V010_I00917
num_objs 1
set05_V003_I01244
num_objs 3
set00_V009_I01640
num_objs 3
set01_V005_I00320
num_objs 3
set04_V004_I00410
num_objs 2
set03_V010_I01811
num_objs 2
set01_V001_I01040
num_objs 1
set04_V011_I01085
num_objs 2
set00_V010_I00641
num_objs 4
set03_V008_I00023
num_objs 3
set04_V004_I00977
num_objs 2
set00_V013_I00284
num_objs 5
set00_V011_I00575
num_objs 3
set00_V007_I00107
num_objs 1
set01_V003_I00029
num_objs 6
set05_V000_I00410
num_objs 2
set00_V003_I00053
num_objs 1
set00_V000_I01139
num_objs 0
set05_V003_I01190
num_objs 3
set00_V002_I01022
num_objs 0
set00_V012_I01070
num_objs 0
set01_V005_I01289
num_objs 0
set03_V006_I00086
num_objs 1
set05_V000_I01496
num_objs 1
set01_V000_I00602
num_objs 4
set05_V003_I01823
num_objs 0
set05_V000_I00170
num_objs 3
set00_V007_I01742
num_objs 5
set00_V001_I00581
num_objs 1
set00_V003_I00497
num_objs 0
set01_V000_I00392
num_objs 2
set00_V007_I01850
num_objs 5
set04_V008_I01397
num_objs 1
set04_V003_I00095
num_objs 0
set00_V010_I00410
num_objs 7
set05_V000_I00374
num_objs 2
set05_V000_I00671
num_objs 1
set03_V002_I01400
num_objs 1
set00_V014_I00356
num_objs 3
set05_V000_I00347
num_objs 3
set05_V011_I00512
num_objs 1
set00_V007_I00470
num_objs 5
set00_V004_I01682
num_objs 1
set01_V001_I01430
num_objs 13
set03_V003_I01010
num_objs 2
set00_V004_I00785
num_objs 2
set01_V002_I00968
num_objs 3
set00_V000_I01775
num_objs 1
set03_V009_I01640
num_objs 2
set05_V000_I01709
num_objs 1
set04_V011_I01067
num_objs 2
set02_V009_I01106
num_objs 1
set01_V000_I01283
num_objs 3
set03_V008_I00269
num_objs 15
set02_V009_I01184
num_objs 2
set03_V011_I00932
num_objs 1
set01_V000_I01478
num_objs 5
set05_V010_I00809
num_objs 0
set00_V002_I00332
num_objs 1
set01_V000_I01505
num_objs 4
set03_V007_I00341
num_objs 1
set05_V005_I00575
num_objs 1
set03_V012_I00821
num_objs 1
set05_V010_I00395
num_objs 2
set01_V005_I01148
num_objs 4
set00_V012_I00353
num_objs 0
set02_V009_I00572
num_objs 2
set00_V008_I00281
num_objs 0
set00_V006_I00407
num_objs 3
set01_V004_I00170
num_objs 1
set04_V002_I01250
num_objs 2
set02_V009_I00266
num_objs 2
set00_V008_I00599
num_objs 7
set03_V011_I00539
num_objs 2
set03_V011_I00899
num_objs 1
set01_V005_I01460
num_objs 0
set00_V009_I00551
num_objs 2
set05_V012_I01190
num_objs 1
set00_V011_I01256
num_objs 3
set02_V011_I01532
num_objs 2
set00_V006_I00227
num_objs 3
set00_V008_I00830
num_objs 1
set05_V005_I00065
num_objs 4
set05_V007_I01367
num_objs 1
set00_V002_I00632
num_objs 0
set01_V005_I00848
num_objs 2
set03_V007_I00314
num_objs 1
set02_V011_I00584
num_objs 2
set00_V010_I00260
num_objs 2
set05_V005_I00146
num_objs 0
set05_V007_I01409
num_objs 1
set01_V004_I00590
num_objs 3
set04_V010_I00509
num_objs 1
set00_V012_I00077
num_objs 1
set04_V002_I01592
num_objs 2
set00_V006_I00110
num_objs 2
set00_V010_I00728
num_objs 1
set04_V007_I01373
num_objs 1
set04_V002_I01310
num_objs 2
set05_V000_I00572
num_objs 2
set03_V009_I00002
num_objs 2
set05_V000_I01556
num_objs 1
set04_V005_I00113
num_objs 1
set03_V009_I00254
num_objs 3
set01_V003_I01790
num_objs 1
set03_V003_I00818
num_objs 2
set05_V010_I00380
num_objs 2
set00_V006_I01079
num_objs 3
set02_V011_I01478
num_objs 2
set02_V010_I00440
num_objs 1
set00_V001_I01349
num_objs 1
set04_V010_I01631
num_objs 2
set01_V000_I00191
num_objs 1
set04_V003_I01508
num_objs 1
set00_V002_I01040
num_objs 0
set05_V003_I01223
num_objs 3
set03_V009_I01373
num_objs 1
set04_V003_I00155
num_objs 0
set01_V000_I00425
num_objs 2
set03_V003_I01526
num_objs 2
set05_V009_I00932
num_objs 1
set01_V001_I01520
num_objs 11
set05_V010_I00746
num_objs 1
set03_V003_I00893
num_objs 2
set05_V000_I01643
num_objs 1
set01_V005_I00338
num_objs 3
set00_V010_I01505
num_objs 3
set00_V008_I01124
num_objs 0
set03_V008_I00230
num_objs 15
set03_V009_I00023
num_objs 3
set04_V006_I00521
num_objs 1
set02_V009_I01421
num_objs 1
set05_V000_I00683
num_objs 1
set03_V009_I01235
num_objs 2
set01_V002_I00056
num_objs 3
set04_V005_I01550
num_objs 2
set01_V005_I01328
num_objs 1
set01_V001_I01298
num_objs 11
set00_V014_I01007
num_objs 3
set00_V002_I00530
num_objs 0
set04_V003_I00404
num_objs 1
set00_V002_I00443
num_objs 0
set02_V009_I01796
num_objs 1
set00_V014_I01907
num_objs 1
set02_V008_I00578
num_objs 1
set00_V011_I01118
num_objs 6
set04_V006_I01649
num_objs 0
set00_V014_I01160
num_objs 3
set01_V002_I01448
num_objs 0
set00_V012_I01463
num_objs 3
set00_V002_I00173
num_objs 2
set02_V007_I00365
num_objs 1
set03_V011_I00194
num_objs 3
set01_V004_I00107
num_objs 2
set03_V005_I01727
num_objs 2
set04_V002_I00140
num_objs 0
set00_V004_I00221
num_objs 1
set01_V002_I00326
num_objs 7
set01_V001_I01250
num_objs 11
set00_V000_I01619
num_objs 1
set00_V010_I00362
num_objs 5
set05_V012_I01223
num_objs 1
set01_V004_I00581
num_objs 1
set02_V011_I00875
num_objs 1
set00_V010_I00515
num_objs 4
set05_V000_I00167
num_objs 3
set00_V009_I01028
num_objs 1
set04_V007_I01766
num_objs 1
set03_V008_I01535
num_objs 1
set00_V007_I00257
num_objs 6
set04_V010_I00374
num_objs 1
set00_V010_I01199
num_objs 2
set04_V005_I00143
num_objs 1
set03_V004_I00437
num_objs 1
set05_V000_I01565
num_objs 1
set04_V002_I01130
num_objs 2
set00_V002_I01277
num_objs 0
set05_V003_I01238
num_objs 3
set03_V012_I01568
num_objs 3
set04_V006_I00530
num_objs 1
set00_V013_I00989
num_objs 1
set04_V010_I00695
num_objs 1
set01_V000_I00617
num_objs 4
set02_V011_I01430
num_objs 2
set01_V003_I00578
num_objs 1
set00_V008_I00563
num_objs 6
set03_V009_I01592
num_objs 2
set00_V011_I00029
num_objs 2
set02_V011_I00494
num_objs 2
set00_V014_I00890
num_objs 4
set01_V003_I01778
num_objs 1
set04_V010_I00764
num_objs 1
set00_V011_I01175
num_objs 4
set00_V007_I01694
num_objs 5
set04_V002_I00929
num_objs 1
set01_V002_I01409
num_objs 1
set04_V002_I00857
num_objs 1
set00_V011_I00326
num_objs 2
set00_V002_I00161
num_objs 2
set05_V005_I00569
num_objs 1
set04_V002_I01610
num_objs 2
set00_V000_I01475
num_objs 1
set03_V003_I01238
num_objs 2
set01_V000_I00371
num_objs 3
set04_V005_I00788
num_objs 1
set02_V009_I01685
num_objs 1
set00_V003_I00446
num_objs 1
set00_V014_I01682
num_objs 4
set01_V004_I01427
num_objs 1
set00_V013_I00377
num_objs 4
set00_V004_I00140
num_objs 1
set04_V008_I01022
num_objs 1
set01_V005_I00902
num_objs 2
set05_V012_I00392
num_objs 3
set05_V000_I00488
num_objs 3
set00_V009_I01034
num_objs 1
set01_V001_I01658
num_objs 3
set00_V008_I00857
num_objs 1
set00_V012_I00995
num_objs 4
set01_V003_I01772
num_objs 1
set04_V002_I01073
num_objs 2
set04_V000_I00866
num_objs 1
set01_V001_I00545
num_objs 4
set01_V005_I00770
num_objs 2
set04_V011_I01139
num_objs 1
set03_V010_I01814
num_objs 2
set03_V009_I01649
num_objs 0
set00_V003_I00092
num_objs 1
set05_V011_I00902
num_objs 9
set00_V014_I01478
num_objs 4
set01_V004_I01448
num_objs 1
set00_V009_I00932
num_objs 3
set05_V002_I00428
num_objs 1
set04_V004_I01325
num_objs 1
set03_V009_I01058
num_objs 6
set02_V011_I00425
num_objs 1
set00_V013_I01226
num_objs 1
set00_V007_I01223
num_objs 8
set04_V007_I01559
num_objs 1
set00_V014_I00200
num_objs 1
set04_V002_I01412
num_objs 3
set01_V002_I01784
num_objs 4
set05_V009_I00935
num_objs 1
set04_V004_I00290
num_objs 2
set05_V007_I01607
num_objs 0
set03_V009_I00542
num_objs 4
set00_V014_I00035
num_objs 3
set02_V007_I00260
num_objs 1
set04_V007_I00827
num_objs 2
set01_V001_I00164
num_objs 3
set00_V001_I00836
num_objs 3
set04_V010_I00833
num_objs 1
set05_V003_I01643
num_objs 0
set02_V009_I00272
num_objs 2
set03_V008_I01499
num_objs 4
set00_V013_I00095
num_objs 5
set05_V011_I00752
num_objs 2
set04_V004_I01850
num_objs 1
set04_V003_I00752
num_objs 1
set00_V000_I01766
num_objs 1
set01_V003_I00017
num_objs 4
set01_V004_I00293
num_objs 2
set01_V002_I01841
num_objs 6
set04_V000_I00689
num_objs 1
set00_V006_I01466
num_objs 4
set00_V006_I01175
num_objs 4
set02_V009_I00701
num_objs 2
set05_V010_I00377
num_objs 1
set00_V012_I01595
num_objs 1
set00_V009_I00176
num_objs 4
set03_V012_I00032
num_objs 1
set04_V006_I00950
num_objs 2
set03_V003_I00557
num_objs 2
set03_V001_I00038
num_objs 1
set01_V000_I01208
num_objs 3
set05_V011_I01556
num_objs 1
set02_V009_I00200
num_objs 2
set03_V009_I00473
num_objs 3
set00_V013_I01409
num_objs 3
set00_V002_I00689
num_objs 0
set05_V012_I00653
num_objs 1
set02_V003_I00725
num_objs 2
set00_V001_I00497
num_objs 4
set00_V006_I01787
num_objs 0
set00_V010_I00737
num_objs 1
set00_V010_I01016
num_objs 0
set00_V006_I01169
num_objs 4
set02_V003_I00266
num_objs 1
set03_V008_I01358
num_objs 3
set02_V011_I00722
num_objs 1
set00_V013_I01622
num_objs 2
set02_V010_I01445
num_objs 1
set00_V009_I01055
num_objs 1
set04_V000_I00647
num_objs 3
set01_V000_I00770
num_objs 1
set00_V014_I00029
num_objs 2
set05_V011_I00965
num_objs 8
set00_V014_I00221
num_objs 3
set03_V009_I00818
num_objs 1
set00_V011_I00257
num_objs 1
set05_V005_I01067
num_objs 1
set04_V003_I00353
num_objs 1
set00_V006_I01043
num_objs 3
set04_V004_I01334
num_objs 1
set05_V000_I00392
num_objs 2
set01_V001_I01319
num_objs 0
set01_V000_I01487
num_objs 5
set04_V001_I01622
num_objs 3
set04_V008_I00569
num_objs 1
set00_V009_I00389
num_objs 1
set03_V009_I00506
num_objs 3
set01_V003_I01754
num_objs 1
set03_V002_I01661
num_objs 2
set04_V002_I01490
num_objs 2
set05_V003_I01619
num_objs 0
set00_V012_I00407
num_objs 0
set05_V012_I00671
num_objs 1
set00_V010_I01100
num_objs 1
set05_V002_I01157
num_objs 1
set05_V012_I00374
num_objs 3
set01_V000_I00995
num_objs 0
set02_V010_I01769
num_objs 0
set00_V014_I01724
num_objs 2
set03_V012_I00050
num_objs 1
set02_V011_I00299
num_objs 1
set00_V012_I00905
num_objs 6
set01_V002_I01148
num_objs 1
set00_V013_I01373
num_objs 3
set02_V001_I01487
num_objs 1
set03_V009_I00104
num_objs 5
set00_V000_I01541
num_objs 1
set04_V010_I00806
num_objs 1
set00_V008_I00002
num_objs 4
set05_V004_I01001
num_objs 1
set04_V001_I00032
num_objs 1
set00_V003_I00158
num_objs 1
set02_V010_I00038
num_objs 0
set00_V001_I00518
num_objs 3
set00_V004_I01277
num_objs 0
set00_V002_I01037
num_objs 0
set00_V014_I00293
num_objs 4
set01_V001_I01511
num_objs 11
set04_V007_I00455
num_objs 1
set04_V004_I00467
num_objs 3
set00_V012_I00356
num_objs 0
set00_V012_I01076
num_objs 0
set00_V006_I01130
num_objs 8
set01_V002_I01652
num_objs 4
set00_V012_I00836
num_objs 4
set03_V008_I00782
num_objs 3
set00_V011_I00266
num_objs 1
set01_V005_I00821
num_objs 2
set04_V004_I00266
num_objs 2
set01_V004_I00077
num_objs 2
set01_V000_I00257
num_objs 1
set00_V010_I00356
num_objs 5
set00_V002_I00140
num_objs 1
set02_V010_I00770
num_objs 2
set03_V012_I01439
num_objs 1
set03_V002_I01655
num_objs 2
set00_V008_I01502
num_objs 3
set01_V003_I00623
num_objs 1
set04_V003_I00449
num_objs 0
set00_V014_I00956
num_objs 3
set02_V011_I01715
num_objs 2
set01_V003_I01613
num_objs 1
set01_V005_I01103
num_objs 3
set00_V001_I01241
num_objs 5
set05_V002_I01112
num_objs 1
set05_V003_I01709
num_objs 1
set04_V003_I01148
num_objs 3
set00_V002_I00410
num_objs 0
set00_V002_I01019
num_objs 0
set00_V009_I00593
num_objs 2
set03_V005_I01547
num_objs 1
set02_V010_I00170
num_objs 1
set05_V002_I00641
num_objs 1
set05_V003_I01268
num_objs 2
set00_V008_I00248
num_objs 0
set05_V000_I00542
num_objs 3
set00_V009_I00476
num_objs 2
set05_V001_I00146
num_objs 1
set01_V004_I01229
num_objs 3
set00_V000_I00764
num_objs 1
set04_V010_I00386
num_objs 1
set00_V008_I01418
num_objs 1
set04_V007_I00641
num_objs 2
set00_V006_I00650
num_objs 2
set01_V003_I00335
num_objs 3
set00_V007_I00074
num_objs 1
set05_V010_I00788
num_objs 1
set05_V010_I01538
num_objs 2
set00_V000_I00530
num_objs 1
set03_V011_I00254
num_objs 3
set00_V011_I01511
num_objs 4
set00_V011_I00269
num_objs 1
set01_V005_I01106
num_objs 3
set00_V001_I00488
num_objs 1
set05_V011_I01325
num_objs 2
set03_V010_I01655
num_objs 3
set04_V002_I01133
num_objs 2
set03_V008_I01766
num_objs 2
set01_V004_I00713
num_objs 2
set00_V014_I00176
num_objs 1
set00_V000_I00887
num_objs 0
set00_V014_I00974
num_objs 4
set00_V006_I00077
num_objs 2
set00_V011_I00284
num_objs 2
set01_V005_I01613
num_objs 0
set04_V003_I00260
num_objs 1
set05_V010_I00449
num_objs 0
set03_V012_I01379
num_objs 3
set04_V003_I01133
num_objs 3
set01_V002_I01004
num_objs 1
set01_V002_I01433
num_objs 0
set05_V010_I00038
num_objs 1
set03_V011_I00380
num_objs 5
set00_V001_I01811
num_objs 3
set00_V013_I01493
num_objs 4
set00_V006_I00128
num_objs 3
set01_V004_I00737
num_objs 3
set03_V005_I01283
num_objs 1
set00_V012_I00527
num_objs 2
set02_V008_I01163
num_objs 0
set03_V006_I00137
num_objs 1
set01_V005_I00638
num_objs 3
set03_V008_I01613
num_objs 2
set03_V003_I01478
num_objs 2
set02_V010_I01265
num_objs 1
set03_V009_I00728
num_objs 2
set04_V006_I01040
num_objs 1
set04_V004_I00896
num_objs 2
set01_V000_I01421
num_objs 4
set00_V006_I01292
num_objs 5
set00_V013_I01253
num_objs 1
set00_V008_I00707
num_objs 3
set04_V002_I00656
num_objs 2
set00_V008_I00770
num_objs 2
set00_V001_I00557
num_objs 3
set00_V013_I00884
num_objs 1
set00_V000_I00473
num_objs 2
set00_V002_I00137
num_objs 1
set03_V004_I00185
num_objs 1
set00_V009_I01217
num_objs 1
set00_V000_I01568
num_objs 2
set02_V009_I00449
num_objs 0
set01_V005_I00875
num_objs 2
set04_V000_I00839
num_objs 0
set00_V009_I00314
num_objs 6
set05_V009_I00944
num_objs 1
set04_V008_I01346
num_objs 1
set00_V002_I00284
num_objs 1
set00_V012_I00080
num_objs 1
set01_V000_I00326
num_objs 1
set04_V003_I00059
num_objs 0
set05_V010_I00089
num_objs 1
set00_V011_I00140
num_objs 2
set03_V008_I00149
num_objs 11
set00_V008_I00518
num_objs 5
set05_V011_I01181
num_objs 4
set03_V012_I00887
num_objs 1
set00_V011_I00899
num_objs 2
set04_V003_I01436
num_objs 3
set04_V003_I01085
num_objs 4
set02_V009_I01550
num_objs 1
set00_V002_I00158
num_objs 2
set02_V009_I01820
num_objs 2
set04_V001_I01568
num_objs 2
set05_V010_I00368
num_objs 1
set01_V003_I00506
num_objs 3
set00_V000_I00971
num_objs 0
set02_V009_I01304
num_objs 1
set00_V010_I01649
num_objs 1
set01_V001_I00188
num_objs 2
set00_V006_I00656
num_objs 2
set01_V002_I00365
num_objs 5
set03_V003_I01241
num_objs 2
set05_V011_I01553
num_objs 1
set04_V007_I01040
num_objs 2
set05_V005_I00287
num_objs 2
set00_V004_I00824
num_objs 1
set04_V011_I01088
num_objs 2
set05_V000_I01403
num_objs 1
set00_V008_I01202
num_objs 0
set05_V011_I01040
num_objs 8
set01_V005_I00479
num_objs 1
set01_V000_I00362
num_objs 2
set00_V013_I00524
num_objs 4
set05_V007_I01652
num_objs 0
set03_V008_I00341
num_objs 18
set04_V005_I01502
num_objs 2
set00_V010_I01013
num_objs 0
set00_V013_I00500
num_objs 2
set05_V011_I01073
num_objs 7
set00_V013_I00998
num_objs 1
set01_V003_I00890
num_objs 1
set05_V010_I00839
num_objs 0
set03_V011_I00797
num_objs 2
set04_V003_I01562
num_objs 1
set00_V013_I00080
num_objs 4
set05_V011_I00941
num_objs 8
set00_V007_I00146
num_objs 1
set04_V003_I01517
num_objs 1
set02_V009_I00419
num_objs 0
set02_V011_I01400
num_objs 2
set01_V000_I00518
num_objs 2
set05_V009_I00920
num_objs 1
set01_V003_I00014
num_objs 4
set03_V008_I00551
num_objs 12
set00_V014_I01214
num_objs 4
set01_V001_I00266
num_objs 2
set03_V009_I00005
num_objs 2
set00_V014_I01841
num_objs 0
set00_V011_I00656
num_objs 3
set04_V002_I01781
num_objs 1
set02_V010_I00449
num_objs 0
set01_V004_I01355
num_objs 1
set04_V007_I01082
num_objs 2
set02_V011_I01619
num_objs 0
set04_V007_I01592
num_objs 1
set00_V001_I01631
num_objs 3
set04_V002_I00863
num_objs 1
set00_V009_I00173
num_objs 4
set02_V011_I00812
num_objs 0
set05_V009_I00857
num_objs 1
set04_V010_I01652
num_objs 2
set00_V000_I00224
num_objs 5
set04_V010_I01523
num_objs 2
set00_V010_I01661
num_objs 1
set02_V011_I00536
num_objs 2
set05_V003_I01253
num_objs 3
set04_V011_I01640
num_objs 1
set00_V004_I00788
num_objs 2
set00_V013_I00473
num_objs 2
set00_V011_I00359
num_objs 0
set02_V007_I00314
num_objs 1
set00_V011_I00974
num_objs 10
set01_V005_I00905
num_objs 2
set02_V011_I00416
num_objs 2
set02_V011_I01709
num_objs 0
set03_V009_I01031
num_objs 6
set04_V003_I01166
num_objs 3
set04_V002_I01355
num_objs 2
set00_V013_I00530
num_objs 4
set02_V009_I00131
num_objs 1
set03_V001_I00155
num_objs 1
set03_V011_I00509
num_objs 2
set03_V011_I00182
num_objs 3
set00_V010_I00071
num_objs 4
set00_V008_I00524
num_objs 6
set04_V007_I00728
num_objs 2
set00_V001_I00008
num_objs 2
set04_V002_I00146
num_objs 0
set00_V010_I01304
num_objs 3
set05_V007_I01370
num_objs 1
set00_V014_I01862
num_objs 0
set01_V000_I00143
num_objs 1
set04_V007_I00872
num_objs 2
set01_V001_I00620
num_objs 3
set01_V000_I00908
num_objs 2
set03_V005_I00518
num_objs 3
set05_V005_I00170
num_objs 0
set03_V003_I00845
num_objs 2
set04_V011_I01130
num_objs 1
set00_V014_I00131
num_objs 2
set05_V012_I01034
num_objs 1
set00_V007_I01685
num_objs 5
set03_V012_I01196
num_objs 1
set00_V000_I01583
num_objs 1
set01_V005_I00485
num_objs 3
set05_V004_I00893
num_objs 0
set02_V010_I01271
num_objs 1
set02_V010_I01415
num_objs 1
set02_V010_I01595
num_objs 1
set04_V007_I01319
num_objs 0
set03_V011_I01265
num_objs 1
set03_V012_I01364
num_objs 4
set01_V002_I01706
num_objs 4
set00_V010_I00914
num_objs 2
set01_V001_I01586
num_objs 6
set00_V008_I00719
num_objs 3
set01_V002_I00446
num_objs 5
set03_V008_I01421
num_objs 3
set04_V006_I01523
num_objs 1
set00_V004_I01286
num_objs 0
set03_V005_I01328
num_objs 1
set05_V001_I00434
num_objs 0
set04_V004_I01670
num_objs 3
set04_V011_I00317
num_objs 1
set05_V009_I01007
num_objs 1
set02_V010_I00161
num_objs 1
set00_V014_I01343
num_objs 6
set03_V009_I00029
num_objs 1
set02_V009_I00392
num_objs 2
set05_V007_I01415
num_objs 1
set01_V001_I00740
num_objs 2
set00_V001_I00476
num_objs 1
set00_V000_I01544
num_objs 1
set00_V006_I00452
num_objs 5
set02_V010_I01295
num_objs 1
set05_V011_I00023
num_objs 1
set01_V004_I00710
num_objs 2
set00_V006_I01205
num_objs 5
set00_V002_I00467
num_objs 0
set02_V011_I01790
num_objs 2
set03_V012_I00905
num_objs 1
set02_V010_I01214
num_objs 1
set00_V011_I00695
num_objs 4
set03_V011_I00905
num_objs 1
set01_V000_I01097
num_objs 3
set01_V004_I00203
num_objs 1
set02_V010_I00653
num_objs 2
set05_V010_I01001
num_objs 1
set05_V007_I01496
num_objs 1
set04_V005_I00308
num_objs 1
set04_V010_I00575
num_objs 1
set03_V009_I01280
num_objs 0
set04_V007_I01103
num_objs 2
set04_V007_I01613
num_objs 1
set04_V010_I00902
num_objs 2
set03_V004_I00533
num_objs 1
set03_V009_I01478
num_objs 1
set01_V005_I01529
num_objs 0
set05_V003_I01016
num_objs 1
set02_V010_I00131
num_objs 1
set03_V003_I00674
num_objs 2
set00_V007_I01157
num_objs 8
set05_V003_I01574
num_objs 0
set00_V000_I00806
num_objs 0
set00_V013_I00839
num_objs 1
set04_V007_I00401
num_objs 1
set05_V012_I01181
num_objs 1
set05_V005_I00965
num_objs 1
set00_V005_I00824
num_objs 1
set00_V000_I00656
num_objs 1
set04_V002_I01484
num_objs 2
set03_V004_I00110
num_objs 1
set05_V000_I00593
num_objs 1
set02_V009_I00806
num_objs 2
set04_V003_I01478
num_objs 2
set05_V000_I00317
num_objs 3
set05_V000_I01484
num_objs 1
set02_V011_I00443
num_objs 1
set03_V005_I00290
num_objs 1
set05_V003_I01787
num_objs 0
set01_V002_I01559
num_objs 1
set00_V009_I00404
num_objs 2
set02_V003_I00146
num_objs 1
set04_V004_I01211
num_objs 3
set04_V007_I01142
num_objs 2
set02_V009_I01718
num_objs 1
set01_V000_I01595
num_objs 4
set00_V009_I00131
num_objs 2
set00_V007_I01469
num_objs 4
set03_V001_I00116
num_objs 1
set01_V002_I00359
num_objs 5
set01_V000_I00671
num_objs 0
set04_V008_I00590
num_objs 1
set00_V000_I01598
num_objs 1
set02_V011_I00569
num_objs 1
set02_V010_I01502
num_objs 2
set00_V014_I00083
num_objs 4
set00_V000_I00188
num_objs 3
set03_V010_I00992
num_objs 3
set01_V005_I01358
num_objs 1
set03_V001_I00134
num_objs 1
set00_V003_I00356
num_objs 1
set00_V013_I01505
num_objs 4
set00_V010_I00218
num_objs 2
set04_V006_I00836
num_objs 2
set02_V010_I00755
num_objs 3
set05_V011_I00014
num_objs 1
set04_V007_I01724
num_objs 1
set04_V005_I01568
num_objs 2
set00_V008_I01331
num_objs 1
set03_V009_I01364
num_objs 1
set03_V009_I00158
num_objs 5
set05_V005_I00986
num_objs 1
set01_V003_I00209
num_objs 8
set00_V002_I00596
num_objs 0
set00_V014_I00359
num_objs 2
set03_V012_I01625
num_objs 1
set00_V013_I00239
num_objs 2
set00_V014_I00530
num_objs 5
set05_V005_I01223
num_objs 1
set00_V010_I00494
num_objs 4
set03_V009_I01625
num_objs 2
set01_V003_I00011
num_objs 4
set00_V010_I01679
num_objs 4
set00_V000_I00875
num_objs 0
set00_V001_I00548
num_objs 3
set04_V006_I00698
num_objs 3
set03_V011_I00170
num_objs 3
set01_V003_I01532
num_objs 1
set01_V001_I01364
num_objs 9
set02_V003_I00167
num_objs 1
set02_V011_I00845
num_objs 1
set05_V010_I00017
num_objs 1
set00_V010_I00371
num_objs 6
set04_V004_I00482
num_objs 3
set04_V002_I01226
num_objs 2
set01_V002_I01124
num_objs 2
set03_V004_I00443
num_objs 1
set01_V004_I01286
num_objs 1
set04_V000_I00923
num_objs 1
set04_V001_I01523
num_objs 1
set02_V010_I00680
num_objs 2
set04_V011_I01499
num_objs 0
set05_V010_I00563
num_objs 1
set02_V011_I00914
num_objs 1
set05_V005_I01148
num_objs 1
set02_V008_I00569
num_objs 0
set04_V008_I00593
num_objs 1
set00_V012_I00899
num_objs 6
set00_V006_I00467
num_objs 4
set01_V004_I01313
num_objs 1
set03_V005_I00908
num_objs 1
set01_V003_I01271
num_objs 1
set04_V002_I00809
num_objs 1
set05_V005_I01064
num_objs 1
set00_V010_I00050
num_objs 4
set05_V002_I01118
num_objs 1
set04_V005_I01274
num_objs 1
set00_V000_I01262
num_objs 1
set00_V011_I01469
num_objs 4
set00_V006_I00062
num_objs 2
set01_V005_I00806
num_objs 2
set04_V006_I00542
num_objs 1
set00_V014_I00602
num_objs 5
set02_V010_I01178
num_objs 1
set02_V009_I01253
num_objs 2
set03_V008_I00929
num_objs 5
set04_V003_I01763
num_objs 2
set00_V002_I00374
num_objs 1
set02_V011_I00401
num_objs 2
set02_V010_I00668
num_objs 2
set05_V001_I00395
num_objs 0
set05_V011_I00980
num_objs 8
set02_V007_I00422
num_objs 1
set04_V002_I01799
num_objs 1
set00_V004_I01247
num_objs 0
set03_V005_I00365
num_objs 2
set00_V007_I01163
num_objs 9
set02_V008_I00977
num_objs 0
set01_V005_I00668
num_objs 2
set03_V009_I01493
num_objs 2
set04_V007_I00314
num_objs 1
set00_V009_I00419
num_objs 1
set03_V011_I00941
num_objs 1
set00_V001_I01721
num_objs 1
set00_V011_I00398
num_objs 3
set05_V005_I01184
num_objs 1
set00_V007_I00443
num_objs 5
set04_V008_I00581
num_objs 1
set00_V006_I01373
num_objs 5
set00_V014_I00086
num_objs 4
set02_V011_I01727
num_objs 2
set03_V011_I00896
num_objs 1
set03_V010_I00161
num_objs 2
set05_V011_I01124
num_objs 5
set00_V006_I01031
num_objs 3
set00_V011_I01496
num_objs 3
set00_V002_I00170
num_objs 2
set04_V000_I00698
num_objs 3
set00_V000_I00545
num_objs 1
set00_V010_I00083
num_objs 3
set02_V010_I00605
num_objs 2
set03_V005_I01619
num_objs 1
set01_V001_I01814
num_objs 1
set04_V001_I00110
num_objs 1
set05_V005_I00917
num_objs 1
set00_V002_I00671
num_objs 1
set03_V005_I00773
num_objs 1
set00_V007_I00710
num_objs 1
set02_V010_I01076
num_objs 1
set05_V011_I01394
num_objs 2
set00_V012_I01472
num_objs 3
set03_V009_I00404
num_objs 3
set04_V003_I00938
num_objs 1
set05_V005_I01133
num_objs 1
set04_V007_I00233
num_objs 1
set05_V011_I00824
num_objs 7
set03_V008_I00836
num_objs 1
set04_V001_I01493
num_objs 1
set00_V012_I01355
num_objs 0
set01_V003_I00311
num_objs 2
set04_V003_I01742
num_objs 2
set01_V003_I01334
num_objs 1
set05_V003_I01046
num_objs 1
set03_V010_I00113
num_objs 2
set00_V014_I01055
num_objs 2
set05_V010_I01004
num_objs 1
set00_V012_I00464
num_objs 1
set00_V004_I01283
num_objs 0
set00_V012_I00665
num_objs 0
set05_V004_I00275
num_objs 1
set02_V010_I00182
num_objs 1
set01_V002_I00233
num_objs 7
set05_V004_I01010
num_objs 1
set03_V009_I00257
num_objs 3
set04_V003_I00152
num_objs 0
set01_V001_I01343
num_objs 10
set01_V003_I00302
num_objs 3
set04_V003_I00539
num_objs 0
set00_V000_I00770
num_objs 1
set01_V005_I01280
num_objs 1
set01_V000_I00155
num_objs 1
set00_V012_I01193
num_objs 0
set00_V013_I00227
num_objs 3
set01_V001_I01745
num_objs 1
set01_V004_I00548
num_objs 1
set00_V012_I00179
num_objs 1
set03_V008_I00728
num_objs 3
set03_V010_I01670
num_objs 4
set02_V011_I00860
num_objs 1
set00_V012_I00023
num_objs 0
set01_V003_I00182
num_objs 7
set00_V014_I01394
num_objs 6
set00_V014_I00848
num_objs 6
set00_V013_I00017
num_objs 5
set04_V003_I01454
num_objs 3
set00_V003_I00371
num_objs 1
set04_V004_I00914
num_objs 2
set03_V009_I00530
num_objs 4
set00_V006_I00137
num_objs 3
set05_V005_I00266
num_objs 1
set01_V005_I01505
num_objs 0
set03_V009_I00152
num_objs 5
set04_V004_I00134
num_objs 1
set04_V010_I01682
num_objs 2
set00_V009_I00089
num_objs 2
set00_V012_I00002
num_objs 0
set00_V006_I00881
num_objs 6
set00_V001_I00974
num_objs 9
set05_V002_I00122
num_objs 1
set04_V005_I00212
num_objs 1
set00_V000_I01559
num_objs 1
set05_V009_I00770
num_objs 1
set00_V009_I00515
num_objs 2
set02_V010_I00299
num_objs 0
set00_V012_I00857
num_objs 4
set01_V004_I00611
num_objs 4
set00_V001_I00086
num_objs 3
set04_V004_I00632
num_objs 2
set02_V009_I00164
num_objs 2
set01_V004_I00695
num_objs 1
set00_V014_I00677
num_objs 3
set05_V011_I01685
num_objs 1
set00_V009_I00707
num_objs 4
set04_V002_I00749
num_objs 1
set03_V008_I01640
num_objs 2
set05_V010_I00077
num_objs 1
set04_V007_I01556
num_objs 1
set00_V007_I01235
num_objs 7
set01_V003_I00536
num_objs 3
set04_V011_I01853
num_objs 1
set00_V009_I00200
num_objs 5
set02_V007_I00194
num_objs 1
set01_V000_I01373
num_objs 3
set04_V011_I00980
num_objs 2
set03_V012_I00923
num_objs 1
set05_V010_I00749
num_objs 0
set02_V010_I00962
num_objs 1
set00_V004_I01157
num_objs 0
set03_V010_I00173
num_objs 1
set03_V003_I00236
num_objs 1
set05_V000_I00653
num_objs 1
set04_V008_I01454
num_objs 1
set04_V000_I00509
num_objs 1
set00_V006_I01187
num_objs 4
set01_V002_I01556
num_objs 1
set00_V007_I01604
num_objs 6
set00_V013_I00845
num_objs 2
set02_V009_I00815
num_objs 2
set05_V005_I01136
num_objs 1
set02_V001_I01595
num_objs 1
set00_V006_I00059
num_objs 9
set00_V010_I00344
num_objs 5
set01_V001_I00305
num_objs 4
set00_V011_I01229
num_objs 1
set04_V011_I01493
num_objs 1
set02_V011_I00599
num_objs 2
set03_V009_I01334
num_objs 0
set03_V005_I01316
num_objs 1
set05_V007_I01637
num_objs 0
set00_V010_I01052
num_objs 0
set00_V008_I00290
num_objs 0
set05_V002_I00743
num_objs 1
set00_V000_I00824
num_objs 0
set02_V011_I00863
num_objs 1
set00_V002_I00134
num_objs 1
set04_V002_I00143
num_objs 0
set05_V005_I00749
num_objs 0
set00_V000_I00269
num_objs 2
set04_V004_I01052
num_objs 2
set00_V002_I00602
num_objs 0
set00_V002_I00791
num_objs 4
set01_V001_I01538
num_objs 10
set01_V001_I00827
num_objs 1
set00_V013_I00872
num_objs 2
set05_V012_I00365
num_objs 3
set04_V002_I01595
num_objs 2
set05_V011_I01484
num_objs 3
set03_V001_I00095
num_objs 1
set04_V002_I01757
num_objs 1
set01_V003_I01787
num_objs 1
set02_V009_I00563
num_objs 2
set04_V005_I01094
num_objs 1
set00_V003_I00443
num_objs 1
set00_V006_I01376
num_objs 5
set01_V005_I01322
num_objs 1
set04_V003_I01055
num_objs 4
set04_V010_I00752
num_objs 1
set00_V006_I01865
num_objs 0
set03_V011_I00542
num_objs 5
set00_V012_I00320
num_objs 1
set03_V011_I00782
num_objs 2
set00_V013_I00476
num_objs 2
set03_V004_I00566
num_objs 1
set05_V004_I00929
num_objs 2
set02_V010_I01370
num_objs 1
set00_V011_I00005
num_objs 6
set00_V000_I01472
num_objs 1
set00_V010_I00965
num_objs 1
set02_V011_I01484
num_objs 2
set00_V011_I01508
num_objs 4
set00_V012_I00686
num_objs 0
set02_V008_I00932
num_objs 0
set01_V001_I00551
num_objs 4
set03_V010_I01799
num_objs 1
set01_V004_I00215
num_objs 0
set04_V005_I01490
num_objs 2
set02_V009_I00416
num_objs 1
set00_V010_I00359
num_objs 5
set00_V010_I01694
num_objs 1
set01_V005_I00017
num_objs 2
set01_V001_I01322
num_objs 10
set00_V006_I01250
num_objs 8
set04_V006_I00818
num_objs 1
set05_V005_I00722
num_objs 1
set05_V000_I01361
num_objs 3
set00_V014_I00893
num_objs 4
set04_V003_I01565
num_objs 1
set00_V014_I00851
num_objs 5
set04_V006_I00980
num_objs 2
set03_V005_I01811
num_objs 2
set04_V004_I00146
num_objs 2
set04_V004_I01076
num_objs 2
set00_V013_I00320
num_objs 6
set04_V007_I00539
num_objs 1
set05_V003_I01391
num_objs 2
set04_V003_I01028
num_objs 4
set01_V000_I01454
num_objs 5
set02_V003_I00158
num_objs 1
set03_V003_I01214
num_objs 2
set00_V004_I01403
num_objs 2
set04_V007_I00920
num_objs 2
set05_V010_I00674
num_objs 1
set01_V004_I00191
num_objs 1
set01_V003_I00644
num_objs 2
set00_V007_I01409
num_objs 3
set03_V008_I01469
num_objs 1
set02_V009_I00713
num_objs 2
set03_V008_I00953
num_objs 1
set03_V005_I00533
num_objs 3
set00_V001_I01211
num_objs 3
set00_V000_I00341
num_objs 2
set03_V011_I01376
num_objs 1
set00_V012_I00512
num_objs 2
set03_V004_I00587
num_objs 1
set01_V001_I01385
num_objs 9
set00_V006_I01682
num_objs 0
set00_V009_I01535
num_objs 3
set02_V010_I01421
num_objs 1
set03_V011_I00437
num_objs 5
set01_V005_I01688
num_objs 0
set04_V007_I01502
num_objs 1
set00_V010_I00047
num_objs 4
set00_V002_I00611
num_objs 0
set03_V011_I00962
num_objs 1
set04_V005_I00089
num_objs 1
set01_V002_I01679
num_objs 3
set02_V008_I01247
num_objs 1
set01_V005_I01445
num_objs 0
set00_V010_I00983
num_objs 1
set01_V001_I00308
num_objs 4
set00_V007_I00161
num_objs 1
set04_V001_I00119
num_objs 0
set04_V007_I00572
num_objs 2
set00_V001_I00515
num_objs 3
set03_V006_I01727
num_objs 1
set03_V008_I00863
num_objs 1
set04_V000_I00644
num_objs 3
set00_V001_I00893
num_objs 3
set03_V010_I00131
num_objs 2
set04_V001_I00062
num_objs 1
set00_V007_I01049
num_objs 2
set03_V009_I00884
num_objs 2
set04_V010_I00638
num_objs 1
set01_V005_I01472
num_objs 0
set00_V002_I01013
num_objs 0
set01_V003_I00908
num_objs 2
set01_V000_I01331
num_objs 4
set00_V003_I00119
num_objs 1
set01_V001_I01598
num_objs 5
set04_V002_I01640
num_objs 2
set04_V002_I01529
num_objs 2
set03_V011_I00584
num_objs 4
set04_V011_I01121
num_objs 1
set00_V006_I00272
num_objs 3
set00_V008_I00275
num_objs 0
set00_V001_I00323
num_objs 5
set02_V011_I01415
num_objs 2
set02_V008_I01151
num_objs 0
set00_V006_I00101
num_objs 2
set00_V002_I00524
num_objs 0
set00_V014_I01088
num_objs 2
set00_V013_I01187
num_objs 0
set02_V011_I00353
num_objs 3
set03_V009_I00776
num_objs 2
set03_V008_I00053
num_objs 4
set00_V004_I00878
num_objs 2
set05_V011_I01334
num_objs 1
set01_V003_I01409
num_objs 1
set01_V001_I01838
num_objs 1
set04_V010_I00551
num_objs 1
set03_V011_I00869
num_objs 0
set05_V003_I01013
num_objs 1
set00_V014_I00332
num_objs 3
set04_V003_I01331
num_objs 3
set00_V014_I01316
num_objs 6
set04_V008_I01484
num_objs 1
set00_V006_I00416
num_objs 2
set01_V003_I00443
num_objs 4
set02_V009_I01280
num_objs 1
set00_V007_I00728
num_objs 2
set00_V011_I01130
num_objs 6
set00_V006_I00596
num_objs 4
set03_V005_I00941
num_objs 1
set02_V009_I00239
num_objs 0
set03_V011_I01199
num_objs 0
set00_V014_I01295
num_objs 6
set05_V011_I01469
num_objs 3
set01_V003_I00533
num_objs 3
set00_V006_I00242
num_objs 3
set01_V000_I00200
num_objs 1
set04_V003_I00029
num_objs 0
set00_V000_I01685
num_objs 2
set03_V003_I00080
num_objs 2
set04_V008_I01133
num_objs 1
set05_V000_I00380
num_objs 2
set04_V003_I00737
num_objs 1
set03_V009_I01739
num_objs 2
set03_V012_I01418
num_objs 3
set05_V010_I00113
num_objs 1
set02_V008_I01139
num_objs 1
set00_V006_I01841
num_objs 0
set02_V009_I01682
num_objs 1
set04_V005_I01229
num_objs 0
set01_V005_I01202
num_objs 3
set00_V014_I00812
num_objs 5
set01_V000_I00464
num_objs 1
set03_V004_I00173
num_objs 1
set03_V005_I00626
num_objs 3
set02_V010_I01313
num_objs 1
set03_V008_I00350
num_objs 18
set00_V011_I00200
num_objs 1
set01_V001_I00140
num_objs 4
set00_V010_I00818
num_objs 3
set02_V010_I01514
num_objs 2
set02_V007_I00155
num_objs 1
set03_V008_I00518
num_objs 15
set05_V010_I01547
num_objs 1
set00_V006_I00065
num_objs 2
set00_V008_I00143
num_objs 2
set04_V008_I00572
num_objs 1
set05_V012_I00686
num_objs 1
set00_V013_I00653
num_objs 2
set02_V011_I01433
num_objs 2
set01_V001_I00086
num_objs 3
set00_V002_I00638
num_objs 0
set03_V011_I00668
num_objs 3
set03_V005_I00398
num_objs 2
set05_V011_I01340
num_objs 1
set00_V009_I00731
num_objs 3
set05_V002_I00521
num_objs 1
set04_V004_I01304
num_objs 1
set04_V006_I00839
num_objs 0
set00_V012_I00167
num_objs 1
set00_V010_I01010
num_objs 0
set03_V009_I01064
num_objs 6
set01_V003_I01025
num_objs 2
set00_V012_I00866
num_objs 4
set03_V005_I01769
num_objs 1
set03_V005_I00284
num_objs 1
set01_V005_I01766
num_objs 0
set05_V000_I00365
num_objs 3
set00_V012_I01025
num_objs 2
set00_V000_I00959
num_objs 0
set01_V000_I01484
num_objs 5
set04_V003_I00131
num_objs 0
set02_V001_I01646
num_objs 1
set01_V004_I01301
num_objs 1
set03_V008_I01577
num_objs 1
set00_V001_I00410
num_objs 2
set03_V010_I01598
num_objs 2
set01_V005_I00131
num_objs 2
set01_V003_I01718
num_objs 3
set03_V012_I00911
num_objs 1
set03_V008_I00359
num_objs 12
set00_V001_I00314
num_objs 5
set04_V005_I01628
num_objs 2
set03_V005_I00680
num_objs 1
set00_V009_I00890
num_objs 5
set04_V003_I00149
num_objs 0
set00_V009_I01340
num_objs 1
set04_V007_I00557
num_objs 1
set04_V003_I01343
num_objs 3
set00_V012_I00413
num_objs 0
set03_V008_I00206
num_objs 12
set05_V012_I00746
num_objs 2
set00_V000_I00881
num_objs 0
set00_V012_I01637
num_objs 1
set05_V011_I00974
num_objs 8
set03_V012_I01571
num_objs 3
set03_V009_I01772
num_objs 4
set02_V010_I00350
num_objs 1
set00_V008_I01343
num_objs 1
set03_V003_I00422
num_objs 1
set01_V004_I00248
num_objs 2
set05_V011_I01211
num_objs 3
set03_V008_I01049
num_objs 0
set02_V010_I01040
num_objs 1
set00_V006_I01196
num_objs 5
set03_V005_I00407
num_objs 2
set05_V010_I00605
num_objs 1
set02_V010_I01670
num_objs 1
set00_V001_I00023
num_objs 2
set00_V000_I00512
num_objs 1
set04_V011_I00311
num_objs 1
set05_V004_I00440
num_objs 2
set00_V010_I01085
num_objs 0
set05_V012_I00473
num_objs 3
set00_V013_I00296
num_objs 6
set02_V010_I01382
num_objs 1
set03_V005_I01628
num_objs 1
set00_V010_I00785
num_objs 3
set02_V009_I01319
num_objs 0
set01_V000_I00923
num_objs 4
set03_V011_I00158
num_objs 2
set05_V010_I00668
num_objs 1
set05_V002_I01100
num_objs 1
set05_V007_I01715
num_objs 0
set02_V011_I01835
num_objs 2
set04_V007_I01547
num_objs 1
set00_V007_I00866
num_objs 3
set04_V005_I00290
num_objs 1
set00_V004_I01070
num_objs 1
set00_V011_I00833
num_objs 0
set05_V002_I01163
num_objs 1
set04_V010_I00701
num_objs 1
set02_V010_I01292
num_objs 1
set02_V009_I00368
num_objs 2
set03_V012_I01520
num_objs 3
set03_V004_I00206
num_objs 1
set02_V011_I01454
num_objs 2
set04_V004_I01055
num_objs 2
set03_V003_I01334
num_objs 2
set03_V009_I01622
num_objs 2
set00_V004_I01697
num_objs 1
set02_V001_I00065
num_objs 0
set01_V005_I01643
num_objs 0
set05_V005_I00395
num_objs 1
set02_V011_I00647
num_objs 2
set01_V002_I00824
num_objs 7
set04_V008_I00977
num_objs 1
set00_V001_I00614
num_objs 2
set00_V011_I00404
num_objs 4
set02_V008_I01157
num_objs 0
set03_V009_I01637
num_objs 2
set00_V003_I00431
num_objs 1
set00_V012_I00869
num_objs 6
set00_V013_I01160
num_objs 1
set05_V002_I00629
num_objs 0
set05_V000_I01601
num_objs 1
set00_V001_I01538
num_objs 3
set01_V004_I00155
num_objs 1
set01_V000_I01337
num_objs 4
set00_V013_I00263
num_objs 4
set03_V007_I01496
num_objs 0
set00_V014_I01457
num_objs 4
set00_V000_I00137
num_objs 1
set01_V002_I00719
num_objs 4
set05_V012_I01175
num_objs 1
set00_V002_I00353
num_objs 1
set02_V011_I01769
num_objs 2
set00_V006_I00623
num_objs 4
set03_V010_I01433
num_objs 2
set04_V003_I00443
num_objs 1
set01_V003_I01373
num_objs 1
set04_V006_I01511
num_objs 1
set04_V011_I00347
num_objs 1
set00_V008_I00461
num_objs 7
set00_V013_I00827
num_objs 2
set03_V003_I00950
num_objs 2
set00_V013_I00854
num_objs 2
set03_V009_I00935
num_objs 4
set00_V010_I00623
num_objs 4
set05_V000_I00716
num_objs 1
set00_V002_I00713
num_objs 1
set00_V008_I00752
num_objs 2
set01_V005_I00812
num_objs 2
set01_V005_I01043
num_objs 3
set00_V006_I00941
num_objs 3
set03_V003_I01400
num_objs 2
set03_V005_I00743
num_objs 1
set04_V010_I00971
num_objs 1
set04_V005_I00107
num_objs 1
set00_V009_I00956
num_objs 4
set01_V001_I01526
num_objs 11
set05_V009_I00959
num_objs 1
set02_V011_I01418
num_objs 2
set01_V000_I01034
num_objs 2
set05_V010_I00125
num_objs 1
set04_V000_I00590
num_objs 3
set03_V006_I00002
num_objs 1
set00_V006_I00560
num_objs 4
set01_V005_I01610
num_objs 0
set05_V002_I01619
num_objs 1
set05_V002_I00119
num_objs 0
set03_V008_I00257
num_objs 18
set00_V013_I00494
num_objs 2
set00_V014_I00818
num_objs 5
set00_V009_I01436
num_objs 1
set00_V014_I01253
num_objs 4
set01_V000_I01427
num_objs 4
set01_V000_I01562
num_objs 4
set04_V002_I01559
num_objs 1
set04_V005_I00287
num_objs 1
set00_V014_I00308
num_objs 5
set04_V002_I01058
num_objs 2
set00_V010_I00833
num_objs 4
set00_V002_I00185
num_objs 3
set00_V009_I00299
num_objs 5
set00_V009_I00239
num_objs 7
set00_V007_I01124
num_objs 10
set03_V008_I01274
num_objs 2
set00_V002_I00149
num_objs 0
set04_V006_I01055
num_objs 1
set00_V009_I00254
num_objs 7
set02_V011_I01529
num_objs 0
set00_V012_I00323
num_objs 1
set00_V014_I01679
num_objs 5
set03_V008_I01058
num_objs 1
set05_V005_I00695
num_objs 1
set03_V010_I01493
num_objs 2
set02_V010_I01622
num_objs 1
set00_V000_I00410
num_objs 3
set01_V004_I00932
num_objs 3
set04_V006_I01082
num_objs 1
set03_V012_I00902
num_objs 1
set01_V001_I01445
num_objs 13
set01_V001_I01202
num_objs 7
set03_V009_I01238
num_objs 2
set01_V004_I00014
num_objs 2
set03_V012_I00833
num_objs 1
set00_V007_I01568
num_objs 7
set04_V006_I01061
num_objs 1
set02_V010_I00260
num_objs 1
set05_V003_I00962
num_objs 1
set02_V010_I00035
num_objs 0
set01_V005_I00695
num_objs 2
set04_V005_I00773
num_objs 1
set04_V003_I00524
num_objs 0
set03_V012_I00959
num_objs 0
set00_V009_I00152
num_objs 1
set01_V002_I00503
num_objs 6
set03_V008_I00530
num_objs 13
set05_V002_I01484
num_objs 1
set04_V010_I01586
num_objs 2
set03_V008_I01442
num_objs 3
set00_V006_I00338
num_objs 4
set03_V005_I00764
num_objs 1
set02_V009_I01712
num_objs 1
set03_V005_I01004
num_objs 1
set01_V005_I01634
num_objs 0
set00_V001_I01547
num_objs 3
set05_V003_I01736
num_objs 0
set01_V003_I00482
num_objs 5
set00_V002_I01274
num_objs 0
set05_V010_I00116
num_objs 1
set00_V013_I01445
num_objs 4
set00_V011_I01085
num_objs 8
set04_V003_I01556
num_objs 1
set00_V011_I00503
num_objs 5
set02_V010_I01628
num_objs 1
set01_V001_I01754
num_objs 1
set00_V011_I00905
num_objs 2
set02_V009_I00320
num_objs 1
set00_V013_I00068
num_objs 3
set00_V006_I00602
num_objs 3
set04_V005_I00134
num_objs 1
set05_V011_I01520
num_objs 1
set05_V012_I01028
num_objs 1
set03_V010_I01445
num_objs 2
set00_V012_I01673
num_objs 1
set01_V001_I00581
num_objs 3
set03_V002_I01637
num_objs 2
set01_V000_I00005
num_objs 1
set00_V013_I01310
num_objs 4
set05_V007_I01262
num_objs 1
set01_V005_I01211
num_objs 3
set02_V001_I00158
num_objs 0
set00_V006_I01439
num_objs 3
set00_V012_I01118
num_objs 0
set01_V001_I00254
num_objs 2
set00_V003_I00455
num_objs 1
set03_V008_I01532
num_objs 2
set04_V000_I00944
num_objs 1
set03_V010_I00962
num_objs 1
set03_V006_I00185
num_objs 0
set03_V005_I01643
num_objs 1
set04_V005_I01634
num_objs 2
set02_V010_I00911
num_objs 1
set01_V000_I01673
num_objs 3
set00_V012_I00584
num_objs 0
set00_V014_I00497
num_objs 5
set05_V010_I00071
num_objs 1
set02_V009_I00578
num_objs 2
set03_V009_I00191
num_objs 5
set05_V007_I01580
num_objs 0
set02_V007_I00200
num_objs 1
set04_V003_I00173
num_objs 0
set01_V002_I00347
num_objs 7
set03_V003_I01190
num_objs 2
set00_V007_I00221
num_objs 5
set00_V000_I01049
num_objs 0
set04_V002_I01418
num_objs 3
set00_V008_I00809
num_objs 1
set02_V001_I01493
num_objs 1
set03_V008_I01193
num_objs 1
set03_V009_I01811
num_objs 4
set05_V012_I01187
num_objs 1
set00_V011_I00494
num_objs 5
set04_V003_I00263
num_objs 1
set02_V007_I00266
num_objs 1
set00_V002_I00857
num_objs 9
set01_V004_I00470
num_objs 1
set05_V002_I01508
num_objs 1
set04_V004_I00677
num_objs 2
set01_V004_I00650
num_objs 3
set00_V013_I00491
num_objs 2
set00_V002_I00128
num_objs 1
set03_V003_I01349
num_objs 1
set03_V010_I01076
num_objs 1
set05_V012_I01151
num_objs 1
set00_V012_I01142
num_objs 0
set05_V003_I01772
num_objs 0
set05_V004_I00464
num_objs 2
set02_V003_I00329
num_objs 1
set04_V007_I01610
num_objs 1
set02_V003_I00134
num_objs 1
set04_V005_I01442
num_objs 2
set02_V010_I00452
num_objs 1
set00_V001_I00755
num_objs 3
set02_V011_I00512
num_objs 2
set03_V003_I00275
num_objs 1
set05_V002_I01115
num_objs 1
set01_V001_I00311
num_objs 4
set02_V009_I01838
num_objs 2
set00_V010_I00950
num_objs 1
set05_V011_I00683
num_objs 2
set01_V003_I00122
num_objs 8
set02_V003_I00716
num_objs 2
set01_V003_I00563
num_objs 1
set05_V002_I00515
num_objs 1
set01_V002_I01094
num_objs 3
set02_V010_I00776
num_objs 2
set05_V011_I01235
num_objs 3
set04_V003_I01793
num_objs 2
set01_V005_I00647
num_objs 2
set01_V002_I00842
num_objs 9
set00_V009_I00386
num_objs 1
set02_V010_I00623
num_objs 2
set05_V005_I00734
num_objs 1
set00_V000_I00380
num_objs 4
set04_V006_I00647
num_objs 3
set03_V008_I00896
num_objs 1
set01_V004_I01103
num_objs 4
set00_V000_I01154
num_objs 0
set00_V008_I01232
num_objs 2
set05_V012_I00455
num_objs 3
set03_V004_I00560
num_objs 1
set05_V005_I00845
num_objs 2
set04_V008_I01049
num_objs 1
set03_V005_I00635
num_objs 3
set02_V011_I01742
num_objs 2
set04_V002_I01469
num_objs 2
set03_V008_I00623
num_objs 7
set03_V003_I00749
num_objs 0
set04_V007_I01004
num_objs 2
set03_V008_I01670
num_objs 2
set05_V011_I00764
num_objs 4
set00_V000_I00536
num_objs 1
set00_V013_I00011
num_objs 4
set00_V013_I00599
num_objs 2
set00_V006_I00572
num_objs 4
set02_V010_I01730
num_objs 1
set02_V007_I00449
num_objs 0
set00_V000_I01493
num_objs 1
set00_V012_I00797
num_objs 2
set03_V009_I01601
num_objs 2
set03_V009_I00173
num_objs 5
set02_V010_I01259
num_objs 0
set00_V014_I01427
num_objs 4
set02_V011_I00458
num_objs 1
set03_V003_I01223
num_objs 2
set02_V007_I00476
num_objs 1
set04_V011_I01619
num_objs 0
set05_V004_I00965
num_objs 1
set00_V012_I01361
num_objs 0
set04_V003_I01049
num_objs 4
set05_V010_I00755
num_objs 1
set04_V007_I00425
num_objs 1
set00_V004_I00254
num_objs 1
set05_V002_I01631
num_objs 1
set05_V007_I01229
num_objs 1
set00_V014_I01313
num_objs 6
set02_V009_I01187
num_objs 2
set00_V002_I00131
num_objs 1
set04_V007_I01433
num_objs 1
set02_V008_I00830
num_objs 1
set01_V002_I01622
num_objs 4
set04_V001_I01751
num_objs 1
set02_V009_I00539
num_objs 0
set01_V004_I01238
num_objs 0
set01_V002_I00458
num_objs 5
set02_V010_I01028
num_objs 1
set02_V001_I00092
num_objs 0
set00_V012_I00155
num_objs 1
set00_V013_I01415
num_objs 2
set00_V010_I01208
num_objs 2
set03_V011_I00893
num_objs 1
set05_V002_I00704
num_objs 1
set01_V004_I00785
num_objs 2
set00_V004_I01298
num_objs 0
set05_V004_I00470
num_objs 2
set05_V004_I00899
num_objs 0
set05_V000_I00434
num_objs 2
set04_V007_I01085
num_objs 2
set03_V003_I01511
num_objs 2
set02_V011_I00626
num_objs 2
set05_V000_I01415
num_objs 0
set01_V002_I01100
num_objs 3
set02_V008_I00887
num_objs 2
set00_V014_I01571
num_objs 5
set02_V010_I00545
num_objs 2
set00_V013_I00899
num_objs 0
set00_V006_I01898
num_objs 0
set03_V005_I01211
num_objs 3
set04_V007_I00653
num_objs 2
set00_V011_I00431
num_objs 5
set01_V002_I00659
num_objs 4
set00_V004_I01271
num_objs 0
set01_V004_I01277
num_objs 1
set01_V001_I01178
num_objs 3
set02_V010_I00173
num_objs 1
set03_V004_I00548
num_objs 1
set01_V005_I01430
num_objs 0
set03_V009_I01358
num_objs 1
set02_V009_I00788
num_objs 2
set04_V004_I01406
num_objs 1
set00_V012_I00842
num_objs 4
set04_V004_I00986
num_objs 2
set00_V008_I00317
num_objs 0
set04_V004_I00950
num_objs 2
set04_V011_I01793
num_objs 1
set04_V002_I01298
num_objs 2
set03_V003_I01271
num_objs 2
set01_V000_I01070
num_objs 2
set00_V010_I00554
num_objs 5
set00_V002_I00800
num_objs 4
set01_V001_I01649
num_objs 2
set01_V005_I01244
num_objs 1
set00_V003_I00089
num_objs 0
set03_V012_I01490
num_objs 3
set00_V013_I00560
num_objs 3
set03_V011_I00500
num_objs 5
set00_V008_I01067
num_objs 2
set01_V001_I01481
num_objs 10
set05_V010_I00560
num_objs 1
set05_V007_I01583
num_objs 0
set00_V010_I00734
num_objs 1
set04_V002_I01496
num_objs 2
set00_V013_I00605
num_objs 3
set03_V006_I01700
num_objs 1
set00_V008_I00959
num_objs 1
set03_V012_I01634
num_objs 1
set03_V012_I01505
num_objs 3
set01_V000_I01466
num_objs 5
set00_V001_I01001
num_objs 12
set03_V002_I01586
num_objs 1
set04_V003_I01466
num_objs 3
set03_V011_I00677
num_objs 2
set03_V003_I00680
num_objs 2
set02_V008_I01109
num_objs 0
set00_V004_I01496
num_objs 0
set03_V008_I00875
num_objs 1
set01_V003_I00239
num_objs 6
set00_V006_I01112
num_objs 9
set01_V005_I01394
num_objs 0
set03_V003_I00971
num_objs 2
set05_V000_I00389
num_objs 0
set03_V005_I01679
num_objs 1
set04_V007_I00764
num_objs 2
set02_V009_I00776
num_objs 2
set00_V006_I01220
num_objs 5
set01_V004_I01028
num_objs 3
set00_V006_I00356
num_objs 4
set03_V010_I01751
num_objs 3
set05_V004_I00989
num_objs 0
set01_V005_I00413
num_objs 4
set03_V008_I01628
num_objs 2
set04_V006_I01094
num_objs 1
set03_V005_I01613
num_objs 1
set00_V010_I00329
num_objs 3
set01_V002_I01460
num_objs 0
set00_V004_I00884
num_objs 2
set03_V009_I00545
num_objs 4
set04_V004_I00878
num_objs 2
set05_V012_I00452
num_objs 3
set04_V002_I01793
num_objs 1
set00_V010_I00254
num_objs 1
set02_V010_I00551
num_objs 2
set00_V002_I01253
num_objs 0
set04_V007_I01400
num_objs 1
set05_V010_I00407
num_objs 1
set00_V013_I00578
num_objs 3
set00_V012_I00524
num_objs 2
set05_V000_I01364
num_objs 3
set04_V007_I01067
num_objs 2
set01_V002_I01034
num_objs 1
set00_V000_I00383
num_objs 4
set02_V010_I00743
num_objs 2
set00_V002_I00932
num_objs 2
set04_V007_I01394
num_objs 1
set00_V000_I00464
num_objs 2
set04_V007_I00482
num_objs 1
set03_V009_I00635
num_objs 3
set04_V003_I00413
num_objs 1
set04_V005_I00860
num_objs 1
set03_V011_I01217
num_objs 1
set00_V001_I01805
num_objs 4
set02_V010_I01562
num_objs 1
set00_V006_I00590
num_objs 5
set04_V007_I01562
num_objs 1
set01_V002_I01400
num_objs 1
set03_V003_I00302
num_objs 1
set05_V002_I00620
num_objs 1
set04_V007_I01229
num_objs 1
set00_V010_I00956
num_objs 1
set00_V007_I00284
num_objs 6
set03_V003_I01166
num_objs 2
set05_V003_I01586
num_objs 0
set01_V001_I01109
num_objs 1
set03_V008_I01724
num_objs 1
set00_V007_I00434
num_objs 5
set02_V001_I00131
num_objs 0
set03_V003_I01202
num_objs 2
set03_V003_I01487
num_objs 2
set00_V006_I01889
num_objs 3
set03_V008_I00266
num_objs 14
set05_V005_I00281
num_objs 2
set01_V000_I01697
num_objs 2
set00_V000_I00911
num_objs 0
set00_V014_I00617
num_objs 4
set04_V006_I00719
num_objs 0
set00_V014_I00542
num_objs 5
set00_V002_I01244
num_objs 0
set00_V000_I01199
num_objs 0
set00_V014_I00620
num_objs 4
set00_V001_I00380
num_objs 5
set01_V000_I01226
num_objs 3
set05_V011_I01688
num_objs 1
set04_V002_I01106
num_objs 2
set05_V001_I00431
num_objs 0
set05_V005_I00779
num_objs 1
set00_V013_I01073
num_objs 2
set00_V006_I00335
num_objs 4
set05_V000_I00494
num_objs 3
set00_V007_I01787
num_objs 3
set01_V005_I00467
num_objs 4
set04_V008_I00578
num_objs 1
set00_V010_I01193
num_objs 2
set04_V007_I01124
num_objs 2
set00_V001_I01253
num_objs 4
set05_V011_I00617
num_objs 4
set02_V008_I00833
num_objs 1
set00_V014_I01277
num_objs 4
set01_V003_I01601
num_objs 1
set00_V014_I00665
num_objs 3
set03_V008_I01757
num_objs 1
set01_V003_I01394
num_objs 1
set01_V002_I00026
num_objs 2
set01_V001_I01736
num_objs 2
set03_V008_I01127
num_objs 1
set00_V003_I00479
num_objs 1
set05_V012_I00725
num_objs 2
set01_V003_I00083
num_objs 5
set00_V002_I00887
num_objs 7
set01_V004_I01289
num_objs 5
set04_V010_I01703
num_objs 2
set01_V001_I00080
num_objs 3
set00_V009_I00716
num_objs 4
set00_V012_I00644
num_objs 0
set05_V002_I00584
num_objs 1
set03_V005_I01244
num_objs 2
set01_V004_I00971
num_objs 1
set02_V009_I01139
num_objs 0
set00_V008_I00437
num_objs 8
set00_V009_I00029
num_objs 2
set05_V007_I01736
num_objs 0
set03_V008_I00008
num_objs 3
set00_V011_I00518
num_objs 5
set00_V000_I00206
num_objs 4
set00_V009_I00518
num_objs 2
set05_V003_I01088
num_objs 1
set03_V010_I01001
num_objs 3
set00_V001_I01592
num_objs 3
set04_V007_I00227
num_objs 1
set00_V009_I01673
num_objs 1
set00_V011_I00683
num_objs 4
set00_V002_I00317
num_objs 1
set00_V007_I01712
num_objs 5
set04_V002_I00593
num_objs 1
set00_V000_I00143
num_objs 1
set00_V001_I01493
num_objs 5
set00_V002_I01058
num_objs 0
set03_V006_I00113
num_objs 1
set01_V005_I00494
num_objs 3
set00_V007_I01598
num_objs 6
set02_V008_I01211
num_objs 2
set03_V008_I00803
num_objs 2
set04_V005_I00848
num_objs 1
set00_V014_I00473
num_objs 4
set04_V010_I00662
num_objs 1
set03_V010_I01706
num_objs 3
set05_V011_I01667
num_objs 1
set05_V005_I00767
num_objs 1
set00_V013_I00176
num_objs 4
set01_V000_I00863
num_objs 0
set00_V007_I00803
num_objs 3
set02_V010_I00137
num_objs 1
set03_V005_I00914
num_objs 1
set00_V008_I00983
num_objs 0
set03_V005_I01508
num_objs 1
set03_V008_I00629
num_objs 15
set02_V011_I00695
num_objs 1
set04_V002_I00890
num_objs 1
set00_V008_I00395
num_objs 1
set00_V002_I00893
num_objs 6
set00_V001_I01523
num_objs 5
set03_V008_I00725
num_objs 3
set03_V005_I00950
num_objs 1
set01_V003_I01364
num_objs 1
set05_V005_I00032
num_objs 3
set03_V010_I01010
num_objs 3
set02_V010_I00377
num_objs 1
set05_V011_I01376
num_objs 2
set01_V005_I01091
num_objs 3
set00_V014_I00734
num_objs 3
set01_V005_I00407
num_objs 4
set00_V000_I00890
num_objs 0
set04_V002_I00611
num_objs 1
set02_V010_I01463
num_objs 1
set04_V002_I00959
num_objs 2
set04_V003_I01634
num_objs 1
set05_V005_I01094
num_objs 1
set04_V007_I01418
num_objs 1
set05_V002_I00554
num_objs 1
set01_V003_I00527
num_objs 3
set04_V011_I01163
num_objs 1
set01_V005_I00773
num_objs 2
set01_V000_I00767
num_objs 1
set01_V001_I00644
num_objs 3
set02_V003_I00308
num_objs 1
set01_V004_I01541
num_objs 2
set00_V009_I00773
num_objs 2
set03_V005_I00329
num_objs 0
set00_V012_I01202
num_objs 0
set03_V003_I00215
num_objs 1
set04_V004_I01088
num_objs 2
set02_V009_I01085
num_objs 1
set00_V011_I00317
num_objs 2
set05_V002_I00557
num_objs 1
set01_V004_I00692
num_objs 1
set00_V011_I01247
num_objs 3
set01_V005_I00857
num_objs 2
set00_V011_I00356
num_objs 3
set05_V005_I00002
num_objs 3
set03_V008_I00497
num_objs 16
set03_V005_I00572
num_objs 3
set00_V014_I00179
num_objs 1
set03_V005_I01682
num_objs 1
set01_V003_I00176
num_objs 7
set04_V007_I01274
num_objs 1
set01_V005_I00416
num_objs 4
set04_V010_I00602
num_objs 1
set00_V007_I00965
num_objs 3
set00_V014_I01076
num_objs 2
set00_V006_I00884
num_objs 6
set00_V006_I00548
num_objs 4
set03_V005_I00836
num_objs 1
set05_V002_I01586
num_objs 1
set03_V003_I01379
num_objs 0
set02_V007_I00413
num_objs 1
set01_V005_I01469
num_objs 0
set00_V010_I00587
num_objs 5
set02_V001_I00095
num_objs 0
set03_V010_I00887
num_objs 1
set00_V007_I01853
num_objs 6
set03_V011_I00245
num_objs 3
set01_V001_I00371
num_objs 4
set01_V004_I00566
num_objs 1
set00_V012_I00608
num_objs 0
set01_V005_I01343
num_objs 1
set00_V002_I00164
num_objs 2
set03_V003_I01505
num_objs 2
set05_V000_I00173
num_objs 3
set00_V014_I00752
num_objs 2
set04_V004_I00581
num_objs 3
set01_V005_I00827
num_objs 2
set01_V003_I01400
num_objs 1
set04_V003_I01712
num_objs 1
set02_V010_I01238
num_objs 1
set05_V011_I00002
num_objs 1
set01_V001_I00395
num_objs 4
set03_V008_I00392
num_objs 19
set00_V004_I01145
num_objs 0
set04_V003_I00086
num_objs 0
set05_V010_I00608
num_objs 1
set05_V008_I00230
num_objs 2
set01_V002_I00047
num_objs 3
set00_V014_I00836
num_objs 5
set00_V013_I00419
num_objs 3
set03_V005_I01175
num_objs 2
set04_V005_I00914
num_objs 1
set00_V010_I00215
num_objs 2
set03_V011_I00662
num_objs 3
set00_V004_I01388
num_objs 2
set02_V011_I00548
num_objs 2
set00_V007_I00134
num_objs 1
set04_V004_I01109
num_objs 2
set04_V010_I01664
num_objs 2
set04_V008_I01445
num_objs 1
set00_V007_I01823
num_objs 4
set04_V000_I00662
num_objs 3
set03_V005_I00938
num_objs 1
set00_V006_I00815
num_objs 3
set00_V010_I00782
num_objs 3
set01_V002_I00134
num_objs 6
set03_V011_I01367
num_objs 1
set03_V010_I00122
num_objs 2
set00_V011_I01178
num_objs 4
set00_V013_I00392
num_objs 4
set05_V000_I00269
num_objs 1
set00_V010_I01373
num_objs 4
set00_V013_I00437
num_objs 2
set01_V001_I00050
num_objs 2
set02_V011_I00848
num_objs 1
set04_V003_I01268
num_objs 3
set03_V008_I00707
num_objs 3
set00_V013_I00155
num_objs 4
set04_V004_I01091
num_objs 2
set01_V003_I01781
num_objs 1
set04_V002_I00764
num_objs 2
set00_V007_I00185
num_objs 4
set00_V010_I00155
num_objs 3
set05_V001_I00341
num_objs 0
set03_V011_I00350
num_objs 5
set01_V001_I00725
num_objs 2
set05_V000_I00341
num_objs 3
set03_V005_I00866
num_objs 1
set03_V011_I00821
num_objs 2
set01_V005_I00794
num_objs 2
set00_V010_I00134
num_objs 5
set03_V003_I00347
num_objs 1
set00_V008_I00341
num_objs 0
set00_V006_I01325
num_objs 4
set01_V002_I00170
num_objs 7
set00_V009_I01343
num_objs 1
set00_V011_I00746
num_objs 2
set04_V011_I01040
num_objs 2
set00_V004_I01331
num_objs 1
set05_V011_I00587
num_objs 5
set01_V001_I01049
num_objs 1
set05_V005_I00605
num_objs 1
set00_V006_I00527
num_objs 3
set01_V001_I00575
num_objs 4
set02_V003_I00185
num_objs 1
set05_V012_I00467
num_objs 3
set04_V005_I01499
num_objs 1
set05_V000_I00602
num_objs 1
set01_V002_I01697
num_objs 4
set00_V001_I01307
num_objs 4
set03_V010_I01631
num_objs 3
set01_V004_I00614
num_objs 4
set02_V009_I00671
num_objs 2
set03_V001_I00137
num_objs 1
set02_V008_I00962
num_objs 0
set01_V000_I00455
num_objs 2
set04_V004_I00092
num_objs 1
set01_V005_I00971
num_objs 3
set00_V001_I00584
num_objs 1
set00_V001_I01484
num_objs 5
set00_V006_I00194
num_objs 3
set01_V003_I00080
num_objs 5
set00_V011_I01514
num_objs 4
set04_V002_I00104
num_objs 0
set00_V014_I01019
num_objs 1
set03_V005_I01085
num_objs 1
set00_V007_I00707
num_objs 1
set02_V010_I01655
num_objs 1
set00_V007_I01274
num_objs 8
set01_V002_I01829
num_objs 4
set03_V009_I00074
num_objs 5
set00_V007_I01238
num_objs 8
set04_V005_I01619
num_objs 2
set00_V000_I00950
num_objs 0
set00_V013_I00995
num_objs 1
set00_V013_I00863
num_objs 2
set04_V005_I00263
num_objs 1
set03_V009_I01718
num_objs 3
set00_V013_I00791
num_objs 2
set03_V008_I00794
num_objs 2
set03_V009_I01259
num_objs 0
set02_V010_I00617
num_objs 2
set04_V008_I01343
num_objs 1
set05_V012_I00347
num_objs 3
set02_V008_I01841
num_objs 0
set00_V008_I00068
num_objs 6
set00_V004_I01358
num_objs 1
set01_V005_I00035
num_objs 2
set04_V011_I01004
num_objs 2
set04_V002_I00152
num_objs 0
set03_V008_I01436
num_objs 3
set01_V000_I00347
num_objs 2
set04_V010_I00728
num_objs 1
set05_V000_I00137
num_objs 5
set03_V004_I00113
num_objs 1
set00_V013_I00107
num_objs 4
set00_V005_I00836
num_objs 2
set01_V003_I01067
num_objs 1
set00_V009_I00101
num_objs 4
set00_V007_I01292
num_objs 9
set00_V011_I01184
num_objs 4
set01_V005_I01514
num_objs 0
set01_V005_I01025
num_objs 3
set01_V003_I01793
num_objs 1
set00_V007_I01673
num_objs 6
set03_V005_I01223
num_objs 2
set02_V009_I01337
num_objs 1
set00_V007_I01079
num_objs 2
set00_V012_I00605
num_objs 0
set04_V006_I00536
num_objs 1
set05_V011_I01058
num_objs 8
set04_V001_I00155
num_objs 1
set03_V009_I00380
num_objs 3
set03_V008_I00842
num_objs 1
set00_V007_I00260
num_objs 6
set00_V000_I00470
num_objs 2
set00_V010_I01028
num_objs 0
set03_V012_I01406
num_objs 4
set03_V005_I00371
num_objs 1
set04_V007_I00416
num_objs 1
set04_V006_I00821
num_objs 2
set02_V009_I01379
num_objs 0
set04_V008_I01109
num_objs 1
set03_V003_I00734
num_objs 2
set02_V007_I00185
num_objs 1
set03_V008_I01025
num_objs 1
set02_V010_I01667
num_objs 1
set00_V009_I00107
num_objs 3
set01_V001_I01289
num_objs 3
set02_V010_I00242
num_objs 1
set01_V002_I01205
num_objs 3
set00_V007_I00473
num_objs 5
set00_V003_I00056
num_objs 1
set00_V001_I01184
num_objs 4
set05_V003_I01274
num_objs 2
set00_V009_I00509
num_objs 2
set01_V005_I01040
num_objs 3
set03_V008_I01226
num_objs 2
set04_V004_I00518
num_objs 3
set04_V003_I00368
num_objs 1
set00_V010_I00986
num_objs 1
set01_V003_I00926
num_objs 2
set02_V011_I00659
num_objs 1
set05_V004_I00260
num_objs 1
set05_V005_I00947
num_objs 1
set05_V005_I00752
num_objs 1
set02_V001_I01436
num_objs 1
set00_V008_I01433
num_objs 1
set03_V003_I00398
num_objs 1
set00_V010_I00764
num_objs 3
set01_V004_I01601
num_objs 1
set03_V009_I00101
num_objs 5
set01_V002_I01694
num_objs 4
set04_V003_I00038
num_objs 0
set00_V007_I00812
num_objs 3
set00_V008_I00530
num_objs 6
set00_V007_I01664
num_objs 6
set03_V003_I01253
num_objs 2
set00_V011_I01433
num_objs 3
set02_V010_I01310
num_objs 1
set02_V011_I00785
num_objs 0
set02_V010_I00992
num_objs 1
set00_V014_I01844
num_objs 0
set00_V013_I01043
num_objs 1
set03_V009_I00968
num_objs 2
set03_V012_I01271
num_objs 0
set05_V003_I01580
num_objs 0
set04_V005_I01034
num_objs 3
set04_V004_I00260
num_objs 1
set04_V003_I01025
num_objs 4
set04_V007_I01601
num_objs 1
set02_V009_I00503
num_objs 1
set01_V005_I01169
num_objs 2
set02_V010_I00221
num_objs 1
set01_V005_I00404
num_objs 4
set03_V009_I00905
num_objs 4
set00_V014_I01289
num_objs 0
set00_V012_I01604
num_objs 1
set04_V007_I00221
num_objs 1
set04_V003_I00350
num_objs 1
set02_V011_I01604
num_objs 2
set05_V011_I01319
num_objs 2
set00_V010_I00707
num_objs 2
set01_V002_I00431
num_objs 5
set03_V008_I01631
num_objs 2
set00_V001_I01589
num_objs 0
set02_V011_I00629
num_objs 1
set04_V003_I00935
num_objs 1
set02_V009_I01070
num_objs 1
set04_V003_I01550
num_objs 1
set00_V014_I01034
num_objs 3
set00_V011_I00608
num_objs 3
set02_V010_I01538
num_objs 1
set03_V012_I00047
num_objs 1
set03_V003_I01040
num_objs 2
set00_V002_I01187
num_objs 0
set03_V003_I01289
num_objs 2
set00_V009_I00050
num_objs 3
set04_V005_I01169
num_objs 1
set00_V011_I00701
num_objs 4
set05_V009_I01004
num_objs 1
set03_V006_I00020
num_objs 1
set04_V011_I01643
num_objs 1
set03_V011_I00752
num_objs 2
set03_V006_I00074
num_objs 1
set01_V002_I00749
num_objs 6
set05_V012_I00758
num_objs 1
set03_V012_I01610
num_objs 3
set00_V012_I01403
num_objs 1
set01_V003_I00041
num_objs 4
set04_V010_I01685
num_objs 2
set04_V007_I00287
num_objs 1
set02_V010_I00929
num_objs 0
set03_V008_I01133
num_objs 1
set05_V004_I00263
num_objs 1
set02_V010_I00641
num_objs 2
set05_V003_I01307
num_objs 2
set00_V010_I00647
num_objs 2
set02_V001_I01442
num_objs 1
set00_V014_I00911
num_objs 3
set02_V009_I00641
num_objs 2
set00_V000_I00356
num_objs 3
set00_V013_I01547
num_objs 3
set00_V012_I01643
num_objs 1
set02_V010_I00119
num_objs 1
set02_V003_I00053
num_objs 1
set04_V003_I00479
num_objs 0
set03_V004_I00224
num_objs 1
set00_V011_I00818
num_objs 1
set00_V012_I00440
num_objs 0
set03_V009_I01286
num_objs 0
set05_V010_I01037
num_objs 1
set00_V011_I01211
num_objs 3
set00_V010_I00617
num_objs 4
set05_V005_I01001
num_objs 1
set03_V010_I01409
num_objs 1
set05_V003_I00992
num_objs 1
set04_V004_I00191
num_objs 2
set04_V001_I01643
num_objs 3
set05_V010_I00929
num_objs 0
set03_V009_I00449
num_objs 2
set03_V002_I01580
num_objs 1
set05_V010_I00485
num_objs 1
set03_V004_I00227
num_objs 1
set02_V007_I00272
num_objs 1
set05_V007_I01487
num_objs 1
set04_V002_I01214
num_objs 2
set04_V003_I00542
num_objs 0
set04_V004_I00149
num_objs 0
set00_V007_I01076
num_objs 5
set04_V007_I00851
num_objs 2
set05_V005_I00614
num_objs 1
set01_V002_I01406
num_objs 0
set04_V004_I00104
num_objs 1
set02_V011_I01331
num_objs 1
set04_V000_I00581
num_objs 3
set03_V008_I01691
num_objs 2
set02_V007_I00401
num_objs 1
set03_V003_I01232
num_objs 2
set00_V012_I01421
num_objs 3
set04_V006_I00551
num_objs 1
set00_V001_I00470
num_objs 1
set04_V001_I01595
num_objs 2
set04_V002_I01442
num_objs 2
set05_V012_I01244
num_objs 1
set01_V005_I00491
num_objs 3
set00_V002_I01061
num_objs 0
set00_V006_I00332
num_objs 4
set03_V008_I01343
num_objs 3
set00_V002_I00293
num_objs 1
set04_V005_I00260
num_objs 1
set00_V000_I00275
num_objs 4
set03_V005_I01031
num_objs 1
set03_V004_I00611
num_objs 1
set00_V009_I01628
num_objs 3
set03_V009_I00497
num_objs 3
set03_V001_I00167
num_objs 1
set00_V008_I01478
num_objs 1
set03_V009_I00221
num_objs 5
set05_V010_I00437
num_objs 1
set00_V004_I01013
num_objs 2
set00_V000_I01226
num_objs 2
set02_V009_I01493
num_objs 1
set04_V006_I00881
num_objs 2
set01_V005_I01724
num_objs 0
set00_V007_I01415
num_objs 5
set00_V004_I01361
num_objs 1
set03_V011_I00590
num_objs 4
set02_V010_I01037
num_objs 1
set00_V013_I01619
num_objs 0
set04_V004_I01388
num_objs 1
set04_V007_I01715
num_objs 1
set04_V004_I01013
num_objs 2
set00_V013_I00737
num_objs 1
set00_V008_I00815
num_objs 1
set00_V000_I01814
num_objs 0
set01_V001_I00446
num_objs 3
set05_V005_I00545
num_objs 1
set00_V009_I00407
num_objs 2
set04_V007_I01052
num_objs 2
set05_V011_I00638
num_objs 4
set04_V002_I01523
num_objs 3
set00_V013_I01388
num_objs 2
set00_V006_I00677
num_objs 2
set01_V002_I00782
num_objs 7
set05_V012_I01148
num_objs 1
set00_V012_I00203
num_objs 1
set05_V000_I00407
num_objs 2
set00_V013_I01634
num_objs 2
set05_V000_I00578
num_objs 1
set00_V014_I00107
num_objs 3
set05_V011_I01190
num_objs 4
set04_V007_I01115
num_objs 2
set03_V011_I00224
num_objs 3
set03_V009_I01205
num_objs 3
set05_V012_I01139
num_objs 0
set05_V010_I00389
num_objs 0
set02_V007_I00437
num_objs 1
set04_V001_I01529
num_objs 1
set01_V001_I01127
num_objs 1
set00_V011_I01364
num_objs 1
set03_V011_I00452
num_objs 5
set00_V013_I01223
num_objs 1
set01_V001_I00149
num_objs 1
set04_V004_I00968
num_objs 2
set00_V014_I00608
num_objs 5
set01_V000_I00203
num_objs 1
set04_V004_I00254
num_objs 1
set00_V013_I01217
num_objs 1
set00_V007_I01445
num_objs 4
set00_V006_I01430
num_objs 3
set02_V008_I01184
num_objs 0
set01_V001_I00944
num_objs 1
set00_V014_I00815
num_objs 5
set05_V005_I00905
num_objs 1
set05_V005_I00209
num_objs 0
set04_V007_I01694
num_objs 1
set04_V002_I01205
num_objs 2
set00_V014_I01373
num_objs 7
set05_V009_I00743
num_objs 1
set04_V000_I00527
num_objs 2
set00_V010_I00659
num_objs 2
set01_V002_I00560
num_objs 8
set05_V011_I01490
num_objs 2
set00_V004_I00476
num_objs 1
set04_V004_I00881
num_objs 2
set00_V008_I01499
num_objs 1
set03_V007_I01523
num_objs 0
set00_V001_I01310
num_objs 4
set05_V004_I00971
num_objs 1
set05_V000_I01541
num_objs 1
set05_V009_I00746
num_objs 1
set05_V009_I00917
num_objs 1
set04_V003_I01115
num_objs 3
set04_V008_I01364
num_objs 1
set01_V002_I01193
num_objs 2
set03_V008_I01082
num_objs 1
set03_V003_I01244
num_objs 2
set05_V005_I00995
num_objs 1
set04_V005_I00800
num_objs 1
set00_V010_I00152
num_objs 4
set01_V004_I01061
num_objs 3
set00_V004_I00899
num_objs 1
set03_V011_I00593
num_objs 4
set04_V002_I00821
num_objs 1
set00_V012_I00926
num_objs 6
set01_V005_I00140
num_objs 2
set05_V010_I00059
num_objs 0
set01_V002_I00020
num_objs 3
set02_V008_I00818
num_objs 1
set01_V003_I00137
num_objs 8
set04_V000_I00539
num_objs 3
set04_V007_I01520
num_objs 1
set00_V010_I01643
num_objs 0
set00_V014_I01139
num_objs 1
set01_V002_I01013
num_objs 2
set00_V009_I00782
num_objs 2
set00_V002_I00614
num_objs 0
set01_V005_I01799
num_objs 0
set04_V007_I01607
num_objs 1
set00_V011_I00251
num_objs 1
set02_V009_I01082
num_objs 1
set00_V007_I00176
num_objs 1
set03_V011_I01445
num_objs 2
set03_V004_I00212
num_objs 1
set00_V010_I01430
num_objs 4
set03_V011_I00491
num_objs 5
set03_V011_I01232
num_objs 1
set02_V010_I00569
num_objs 2
set01_V005_I01151
num_objs 4
set00_V004_I00212
num_objs 1
set00_V001_I01064
num_objs 10
set00_V006_I00956
num_objs 1
set03_V003_I01286
num_objs 2
set01_V002_I00068
num_objs 3
set04_V000_I00518
num_objs 2
set01_V000_I01349
num_objs 3
set00_V006_I01370
num_objs 4
set05_V011_I01502
num_objs 2
set00_V014_I00290
num_objs 4
set05_V002_I00098
num_objs 1
set01_V004_I01517
num_objs 2
set02_V007_I00182
num_objs 1
set05_V003_I00977
num_objs 1
set02_V009_I01724
num_objs 1
set00_V004_I01220
num_objs 0
set05_V005_I00530
num_objs 1
set00_V008_I00326
num_objs 0
set00_V001_I00446
num_objs 1
set05_V001_I00194
num_objs 1
set01_V002_I00287
num_objs 8
set03_V006_I00161
num_objs 1
set00_V007_I01001
num_objs 2
set00_V014_I00248
num_objs 1
set04_V010_I00572
num_objs 1
set00_V008_I01100
num_objs 0
set04_V010_I00803
num_objs 1
set00_V007_I01442
num_objs 4
set00_V001_I01220
num_objs 4
set03_V011_I01238
num_objs 1
set05_V011_I01349
num_objs 1
set05_V005_I00626
num_objs 1
set04_V002_I01094
num_objs 2
set00_V009_I00500
num_objs 2
set04_V002_I01796
num_objs 1
set02_V010_I00326
num_objs 1
set00_V007_I00200
num_objs 4
set04_V004_I01160
num_objs 3
set04_V003_I01199
num_objs 3
set05_V011_I00815
num_objs 5
set04_V007_I00977
num_objs 2
set03_V011_I01250
num_objs 1
set05_V012_I01010
num_objs 1
set00_V011_I01010
num_objs 11
set04_V006_I00539
num_objs 0
set03_V010_I00194
num_objs 1
set04_V005_I01547
num_objs 2
set01_V001_I01004
num_objs 1
set02_V010_I00554
num_objs 2
set05_V011_I01607
num_objs 1
set00_V013_I01628
num_objs 2
set02_V009_I01472
num_objs 1
set01_V001_I01025
num_objs 1
set04_V006_I00707
num_objs 3
set01_V001_I00449
num_objs 3
set03_V009_I00773
num_objs 2
set01_V004_I00977
num_objs 1
set04_V006_I00599
num_objs 1
set04_V008_I01382
num_objs 1
set01_V002_I00761
num_objs 8
set01_V005_I00842
num_objs 2
set05_V003_I01706
num_objs 0
set00_V013_I01448
num_objs 4
set00_V007_I00509
num_objs 1
set00_V014_I00521
num_objs 5
set00_V003_I00389
num_objs 0
set02_V011_I00332
num_objs 2
set02_V010_I01691
num_objs 1
set00_V009_I00413
num_objs 2
set04_V007_I00875
num_objs 2
set01_V002_I00167
num_objs 7
set05_V002_I01097
num_objs 1
set05_V008_I01808
num_objs 1
set05_V012_I01016
num_objs 1
set00_V009_I00230
num_objs 7
set00_V014_I00797
num_objs 5
set02_V009_I00128
num_objs 1
set00_V003_I00137
num_objs 2
set05_V011_I00983
num_objs 8
set04_V005_I01637
num_objs 2
set01_V005_I01478
num_objs 0
set00_V007_I00893
num_objs 4
set05_V002_I00152
num_objs 1
set03_V011_I00749
num_objs 1
set04_V002_I01349
num_objs 1
set04_V004_I01643
num_objs 1
set01_V004_I00281
num_objs 2
set05_V003_I01025
num_objs 1
set00_V010_I00854
num_objs 3
set00_V006_I00206
num_objs 3
set04_V004_I00203
num_objs 2
set04_V005_I01262
num_objs 1
set01_V001_I00419
num_objs 2
set01_V000_I01274
num_objs 3
set03_V009_I00011
num_objs 3
set02_V010_I00788
num_objs 2
set03_V011_I00236
num_objs 3
set00_V013_I01361
num_objs 3
set04_V007_I01133
num_objs 2
set05_V003_I01592
num_objs 0
set05_V011_I00710
num_objs 2
set05_V012_I00578
num_objs 0
set04_V002_I00668
num_objs 2
set00_V007_I00089
num_objs 0
set00_V009_I01625
num_objs 3
set05_V000_I00554
num_objs 2
set03_V011_I00518
num_objs 5
set00_V006_I00653
num_objs 2
set03_V002_I01454
num_objs 1
set01_V001_I01052
num_objs 1
set00_V008_I01700
num_objs 0
set02_V010_I00503
num_objs 1
set04_V004_I01247
num_objs 2
set04_V003_I00266
num_objs 1
set03_V009_I00992
num_objs 2
set04_V003_I01679
num_objs 1
set00_V002_I00536
num_objs 0
set00_V008_I00443
num_objs 8
set00_V007_I01898
num_objs 3
set00_V002_I00296
num_objs 1
set05_V009_I00833
num_objs 1
set01_V005_I00116
num_objs 2
set05_V000_I00395
num_objs 2
set00_V004_I01304
num_objs 0
set02_V007_I00386
num_objs 1
set03_V003_I00836
num_objs 2
set04_V011_I01613
num_objs 1
set00_V001_I01202
num_objs 4
set00_V011_I00830
num_objs 0
set00_V001_I00365
num_objs 5
set00_V013_I01463
num_objs 4
set03_V003_I01055
num_objs 2
set00_V006_I01106
num_objs 9
set00_V010_I00653
num_objs 2
set05_V009_I00734
num_objs 1
set05_V009_I00824
num_objs 1
set05_V011_I01046
num_objs 8
set01_V001_I00224
num_objs 1
set00_V011_I01082
num_objs 9
set00_V011_I00473
num_objs 5
set04_V007_I00494
num_objs 1
set05_V003_I01262
num_objs 3
set03_V005_I01397
num_objs 1
set00_V001_I00962
num_objs 8
set01_V005_I01583
num_objs 0
set00_V013_I01544
num_objs 3
set03_V005_I00905
num_objs 1
set01_V001_I00128
num_objs 4
set02_V010_I00230
num_objs 1
set01_V004_I00602
num_objs 3
set05_V007_I01493
num_objs 1
set00_V007_I01883
num_objs 7
set01_V004_I00701
num_objs 2
set03_V008_I01187
num_objs 1
set05_V002_I00491
num_objs 1
set03_V009_I00947
num_objs 4
set00_V001_I01343
num_objs 3
set01_V003_I00464
num_objs 4
set03_V007_I01520
num_objs 0
set01_V002_I00512
num_objs 7
set03_V005_I01544
num_objs 1
set04_V007_I01622
num_objs 1
set00_V013_I01511
num_objs 3
set00_V001_I01322
num_objs 4
set03_V003_I00362
num_objs 1
set05_V012_I00335
num_objs 1
set01_V000_I00827
num_objs 0
set03_V007_I00266
num_objs 1
set02_V008_I00827
num_objs 1
set01_V001_I01763
num_objs 1
set02_V008_I00503
num_objs 1
set00_V001_I00539
num_objs 2
set04_V010_I01544
num_objs 2
set01_V000_I00353
num_objs 2
set01_V003_I00308
num_objs 3
set00_V014_I01331
num_objs 6
set01_V003_I00347
num_objs 3
set05_V011_I00890
num_objs 9
set03_V001_I00827
num_objs 1
set03_V007_I01547
num_objs 0
set02_V011_I01424
num_objs 2
set00_V014_I00713
num_objs 3
set04_V010_I00398
num_objs 1
set00_V009_I01091
num_objs 1
set02_V010_I00704
num_objs 2
set00_V004_I01214
num_objs 0
set04_V011_I01556
num_objs 1
set03_V010_I01571
num_objs 3
set01_V000_I01235
num_objs 3
set05_V010_I00827
num_objs 2
set04_V004_I00140
num_objs 1
set04_V010_I01526
num_objs 2
set03_V008_I00584
num_objs 9
set05_V009_I00872
num_objs 1
set01_V000_I01526
num_objs 4
set00_V012_I00794
num_objs 2
set03_V005_I01358
num_objs 1
set03_V008_I00260
num_objs 18
set04_V005_I00257
num_objs 1
set04_V005_I00818
num_objs 1
set04_V004_I01676
num_objs 3
set00_V007_I01826
num_objs 4
set00_V009_I00257
num_objs 7
set01_V001_I01637
num_objs 5
set00_V009_I00911
num_objs 3
set00_V007_I00422
num_objs 6
set04_V007_I00335
num_objs 1
set05_V011_I00581
num_objs 5
set04_V005_I01121
num_objs 1
set02_V010_I00836
num_objs 2
set04_V004_I01235
num_objs 2
set04_V007_I00368
num_objs 1
set04_V002_I00044
num_objs 1
set01_V001_I00176
num_objs 3
set03_V007_I00308
num_objs 1
set00_V010_I01115
num_objs 2
set03_V005_I00305
num_objs 1
set00_V013_I00404
num_objs 3
set04_V008_I00623
num_objs 1
set01_V002_I00005
num_objs 3
set00_V002_I00230
num_objs 2
set02_V001_I01607
num_objs 1
set03_V009_I01745
num_objs 4
set00_V010_I00440
num_objs 8
set00_V004_I00227
num_objs 1
set03_V005_I00254
num_objs 1
set00_V012_I01166
num_objs 1
set03_V012_I01205
num_objs 1
set03_V005_I00803
num_objs 1
set00_V002_I00497
num_objs 0
set00_V001_I00590
num_objs 1
set02_V003_I00092
num_objs 1
set01_V001_I01028
num_objs 1
set04_V003_I01781
num_objs 2
set01_V003_I01769
num_objs 5
set02_V010_I00584
num_objs 2
set00_V008_I00080
num_objs 6
set04_V008_I01034
num_objs 1
set04_V001_I00071
num_objs 1
set04_V000_I00842
num_objs 1
set04_V003_I01610
num_objs 1
set03_V006_I01703
num_objs 1
set01_V001_I00392
num_objs 4
set00_V011_I00686
num_objs 4
set00_V011_I00458
num_objs 6
set00_V006_I01706
num_objs 0
set01_V004_I01094
num_objs 4
set00_V001_I00896
num_objs 3
set01_V003_I00659
num_objs 2
set03_V012_I00917
num_objs 1
set05_V012_I00518
num_objs 1
set03_V008_I01517
num_objs 2
set01_V005_I00650
num_objs 2
set03_V004_I00131
num_objs 1
set01_V003_I00875
num_objs 1
set00_V013_I01283
num_objs 2
set03_V009_I01124
num_objs 6
set03_V008_I00212
num_objs 12
set03_V012_I01265
num_objs 0
set03_V009_I00323
num_objs 4
set00_V008_I00839
num_objs 1
set01_V004_I00839
num_objs 9
set04_V011_I00392
num_objs 1
set02_V001_I00143
num_objs 0
set00_V009_I00614
num_objs 2
set00_V010_I00809
num_objs 4
set04_V006_I01115
num_objs 1
set05_V012_I01064
num_objs 1
set04_V004_I01124
num_objs 3
set00_V011_I00389
num_objs 0
set04_V004_I01259
num_objs 1
set03_V009_I00068
num_objs 5
set05_V011_I00821
num_objs 5
set03_V010_I01817
num_objs 2
set01_V001_I00422
num_objs 3
set04_V004_I00158
num_objs 2
set03_V012_I00989
num_objs 0
set00_V012_I00536
num_objs 2
set00_V004_I01535
num_objs 0
set00_V012_I00305
num_objs 3
set00_V010_I01700
num_objs 1
set00_V010_I00443
num_objs 7
set02_V009_I00458
num_objs 1
set00_V004_I00542
num_objs 1
set00_V000_I01232
num_objs 2
set00_V001_I01430
num_objs 4
set00_V013_I01112
num_objs 4
set00_V007_I00548
num_objs 5
set02_V010_I00416
num_objs 1
set01_V004_I01298
num_objs 1
set05_V010_I00383
num_objs 2
set03_V003_I00635
num_objs 2
set04_V006_I01091
num_objs 1
set04_V002_I00605
num_objs 1
set02_V003_I00020
num_objs 0
set01_V004_I00038
num_objs 2
set01_V002_I01328
num_objs 7
set03_V009_I00983
num_objs 2
set04_V007_I00716
num_objs 2
set01_V001_I01472
num_objs 11
set02_V010_I01760
num_objs 1
set03_V010_I01055
num_objs 2
set02_V003_I00077
num_objs 1
set00_V006_I00977
num_objs 2
set00_V006_I00953
num_objs 1
set03_V003_I00533
num_objs 2
set01_V003_I00953
num_objs 2
set00_V011_I00041
num_objs 5
set00_V009_I01415
num_objs 1
set04_V007_I00578
num_objs 2
set00_V009_I00884
num_objs 6
set00_V012_I00839
num_objs 6
set00_V009_I01265
num_objs 1
set00_V014_I01790
num_objs 1
set00_V014_I01118
num_objs 3
set04_V003_I00068
num_objs 0
set01_V001_I00869
num_objs 0
set01_V001_I01661
num_objs 2
set02_V008_I01235
num_objs 1
set01_V003_I01280
num_objs 1
set00_V010_I00605
num_objs 5
set00_V007_I00332
num_objs 6
set02_V008_I00857
num_objs 2
set00_V014_I00224
num_objs 3
set03_V008_I00464
num_objs 17
set04_V011_I01487
num_objs 1
set00_V006_I00068
num_objs 2
set04_V002_I00989
num_objs 1
set04_V007_I00302
num_objs 1
set05_V010_I00629
num_objs 0
set04_V002_I01160
num_objs 2
set02_V007_I00263
num_objs 1
set05_V005_I00557
num_objs 1
set03_V009_I00131
num_objs 5
set01_V005_I00926
num_objs 3
set00_V000_I01088
num_objs 0
set00_V008_I00956
num_objs 1
set00_V006_I00611
num_objs 4
set00_V006_I00347
num_objs 4
set05_V005_I00200
num_objs 0
set04_V006_I01049
num_objs 1
set04_V004_I00884
num_objs 2
set00_V014_I01658
num_objs 4
set00_V014_I01715
num_objs 2
set04_V006_I00632
num_objs 1
set04_V011_I01190
num_objs 1
set04_V008_I01508
num_objs 1
set04_V004_I00428
num_objs 2
set05_V009_I01010
num_objs 1
set02_V009_I00452
num_objs 1
set00_V009_I00329
num_objs 3
set05_V002_I00455
num_objs 1
set03_V004_I00518
num_objs 1
set00_V006_I01046
num_objs 4
set00_V001_I01682
num_objs 2
set00_V010_I00203
num_objs 4
set02_V003_I00293
num_objs 2
set02_V010_I01250
num_objs 1
set05_V000_I01505
num_objs 1
set04_V007_I00656
num_objs 2
set00_V014_I00137
num_objs 2
set00_V002_I00125
num_objs 1
set01_V005_I00677
num_objs 2
set03_V005_I01706
num_objs 1
set05_V005_I00476
num_objs 2
set00_V011_I00671
num_objs 4
set00_V014_I01541
num_objs 4
set03_V002_I01547
num_objs 1
set00_V010_I01391
num_objs 4
set05_V000_I01571
num_objs 1
set02_V009_I00689
num_objs 1
set03_V011_I00800
num_objs 2
set04_V005_I01667
num_objs 1
set03_V008_I00776
num_objs 3
set00_V004_I01067
num_objs 1
set05_V011_I01310
num_objs 2
set00_V009_I01031
num_objs 1
set00_V004_I01520
num_objs 0
set05_V005_I00515
num_objs 1
set03_V008_I00830
num_objs 2
set01_V001_I01517
num_objs 11
set00_V008_I01028
num_objs 3
set01_V005_I01451
num_objs 0
set04_V002_I00824
num_objs 1
set02_V001_I01490
num_objs 1
set01_V003_I00071
num_objs 5
set00_V007_I01778
num_objs 4
set00_V010_I00236
num_objs 1
set00_V013_I01454
num_objs 4
set01_V000_I01073
num_objs 2
set03_V010_I01667
num_objs 4
set00_V013_I00293
num_objs 6
set04_V006_I00587
num_objs 1
set04_V000_I00830
num_objs 1
set02_V008_I00899
num_objs 2
set03_V009_I01052
num_objs 6
set03_V003_I00050
num_objs 2
set05_V012_I00710
num_objs 2
set01_V005_I00818
num_objs 2
set00_V014_I00599
num_objs 3
set00_V007_I01769
num_objs 2
set00_V009_I00536
num_objs 2
set03_V003_I00029
num_objs 2
set00_V010_I00374
num_objs 6
set01_V000_I00284
num_objs 1
set03_V005_I01721
num_objs 2
set04_V004_I00098
num_objs 1
set04_V008_I01100
num_objs 1
set00_V007_I00926
num_objs 3
set01_V003_I00740
num_objs 2
set00_V007_I01196
num_objs 8
set00_V000_I00335
num_objs 1
set05_V003_I01241
num_objs 3
set05_V002_I00125
num_objs 1
set03_V005_I01790
num_objs 2
set03_V005_I00899
num_objs 0
set03_V012_I00962
num_objs 1
set05_V011_I01175
num_objs 4
set00_V000_I01079
num_objs 0
set00_V013_I00455
num_objs 2
set00_V012_I00872
num_objs 5
set05_V010_I01613
num_objs 1
set01_V001_I00788
num_objs 2
set04_V003_I00317
num_objs 1
set03_V005_I01205
num_objs 3
set00_V011_I00371
num_objs 3
set00_V006_I00482
num_objs 3
set01_V001_I00905
num_objs 1
set02_V010_I01409
num_objs 0
set00_V011_I01013
num_objs 11
set00_V006_I00236
num_objs 3
set05_V005_I00797
num_objs 1
set04_V005_I01505
num_objs 2
set03_V005_I01409
num_objs 0
set00_V000_I01043
num_objs 0
set01_V001_I01547
num_objs 9
set00_V003_I00383
num_objs 1
set01_V002_I01211
num_objs 3
set00_V011_I00545
num_objs 3
set00_V002_I00320
num_objs 1
set00_V005_I00833
num_objs 2
set01_V004_I01325
num_objs 1
set01_V004_I01190
num_objs 0
set00_V009_I01670
num_objs 1
set05_V010_I00770
num_objs 1
set01_V002_I01619
num_objs 2
set01_V002_I01067
num_objs 3
set02_V008_I01103
num_objs 0
set05_V005_I01256
num_objs 1
set01_V004_I00149
num_objs 1
set05_V002_I00623
num_objs 1
set02_V001_I01433
num_objs 1
set01_V005_I00461
num_objs 4
set02_V003_I00026
num_objs 0
set01_V002_I01709
num_objs 2
set00_V001_I01013
num_objs 12
set05_V003_I01682
num_objs 0
set00_V011_I00374
num_objs 3
set01_V001_I01169
num_objs 1
set02_V007_I00299
num_objs 1
set05_V011_I01391
num_objs 2
set04_V000_I00896
num_objs 1
set05_V005_I00821
num_objs 2
set00_V005_I00818
num_objs 1
set02_V011_I00653
num_objs 2
set03_V003_I01556
num_objs 2
set01_V004_I00923
num_objs 3
set05_V010_I00620
num_objs 1
set00_V012_I00149
num_objs 1
set01_V004_I00131
num_objs 2
set00_V004_I01637
num_objs 1
set05_V005_I00131
num_objs 1
set01_V003_I01721
num_objs 3
set05_V004_I00272
num_objs 1
set04_V001_I00077
num_objs 1
set01_V005_I00992
num_objs 3
set01_V005_I01553
num_objs 0
set00_V005_I00830
num_objs 2
set03_V010_I01058
num_objs 2
set04_V006_I00914
num_objs 2
set05_V005_I00659
num_objs 1
set00_V004_I00857
num_objs 0
set00_V009_I01649
num_objs 5
set01_V001_I00806
num_objs 1
set00_V012_I01349
num_objs 1
set03_V009_I01040
num_objs 6
set00_V010_I00182
num_objs 4
set00_V009_I01346
num_objs 1
set03_V009_I01781
num_objs 4
set05_V003_I01400
num_objs 2
set05_V005_I00290
num_objs 2
set03_V008_I00335
num_objs 18
set00_V006_I01910
num_objs 0
set02_V010_I00905
num_objs 1
set04_V008_I01460
num_objs 1
set02_V009_I00101
num_objs 1
set00_V009_I00356
num_objs 4
set03_V008_I01634
num_objs 2
set05_V000_I00440
num_objs 3
set03_V009_I00056
num_objs 5
set04_V005_I00830
num_objs 1
set00_V010_I00470
num_objs 7
set00_V008_I00953
num_objs 1
set01_V000_I00500
num_objs 0
set03_V011_I00734
num_objs 1
set03_V005_I00968
num_objs 1
set00_V004_I00014
num_objs 1
set04_V006_I01577
num_objs 1
set05_V011_I00812
num_objs 5
set00_V014_I00050
num_objs 3
set02_V003_I00188
num_objs 1
set03_V009_I00896
num_objs 3
set05_V007_I01634
num_objs 0
set05_V010_I00149
num_objs 0
set00_V000_I00125
num_objs 1
set00_V007_I01427
num_objs 4
set03_V008_I00722
num_objs 3
set00_V008_I00158
num_objs 2
set01_V001_I00017
num_objs 2
set03_V002_I01409
num_objs 1
set03_V009_I00521
num_objs 3
set03_V003_I01007
num_objs 2
set05_V002_I00503
num_objs 1
set05_V003_I01685
num_objs 0
set04_V001_I00122
num_objs 1
set05_V000_I01592
num_objs 1
set00_V004_I00203
num_objs 1
set00_V007_I00395
num_objs 6
set03_V007_I01553
num_objs 0
set00_V007_I01760
num_objs 5
set04_V005_I01529
num_objs 1
set00_V011_I01070
num_objs 9
set01_V001_I00029
num_objs 0
set03_V008_I01718
num_objs 1
set00_V008_I00680
num_objs 3
set00_V013_I00587
num_objs 3
set03_V009_I00281
num_objs 3
set03_V005_I01637
num_objs 1
set01_V002_I01238
num_objs 4
set01_V003_I01019
num_objs 7
set03_V005_I00482
num_objs 2
set04_V002_I00755
num_objs 2
set02_V011_I00296
num_objs 0
set00_V011_I00641
num_objs 3
set00_V010_I00518
num_objs 4
set02_V009_I00731
num_objs 2
set00_V008_I00416
num_objs 2
set05_V007_I01424
num_objs 1
set04_V001_I00134
num_objs 1
set04_V007_I00815
num_objs 2
set02_V009_I01793
num_objs 1
set03_V011_I00293
num_objs 4
set03_V012_I01277
num_objs 0
set05_V011_I00635
num_objs 4
set00_V006_I01007
num_objs 2
set03_V009_I00536
num_objs 4
set03_V008_I00242
num_objs 17
set01_V001_I01064
num_objs 1
set00_V004_I00155
num_objs 1
set03_V010_I01640
num_objs 3
set01_V001_I00215
num_objs 2
set00_V004_I00245
num_objs 1
set01_V002_I01760
num_objs 5
set03_V009_I00608
num_objs 4
set04_V001_I01766
num_objs 1
set01_V005_I00065
num_objs 2
set00_V012_I00230
num_objs 2
set02_V010_I00560
num_objs 2
set00_V010_I01628
num_objs 0
set03_V008_I00062
num_objs 6
set05_V005_I00392
num_objs 1
set04_V004_I00743
num_objs 2
set00_V004_I00398
num_objs 1
set04_V002_I01682
num_objs 2
set00_V009_I00290
num_objs 5
set04_V000_I00992
num_objs 1
set00_V004_I00389
num_objs 1
set05_V012_I00284
num_objs 1
set03_V003_I00191
num_objs 1
set03_V011_I00866
num_objs 2
set03_V008_I00194
num_objs 11
set02_V008_I01124
num_objs 0
set02_V010_I00053
num_objs 0
set02_V009_I00092
num_objs 1
set00_V006_I01073
num_objs 7
set00_V014_I01892
num_objs 1
set01_V005_I01307
num_objs 1
set00_V007_I01142
num_objs 9
set01_V001_I01391
num_objs 9
set00_V000_I00095
num_objs 1
set02_V010_I01568
num_objs 1
set00_V008_I01484
num_objs 0
set00_V006_I00659
num_objs 2
set03_V012_I01397
num_objs 5
set00_V014_I01805
num_objs 2
set00_V012_I01598
num_objs 1
set03_V012_I01286
num_objs 0
set00_V013_I01268
num_objs 1
set02_V009_I00305
num_objs 1
set00_V007_I00239
num_objs 1
set02_V009_I00650
num_objs 2
set01_V004_I00086
num_objs 2
set01_V003_I00668
num_objs 2
set00_V009_I01526
num_objs 3
set00_V006_I00164
num_objs 3
set04_V005_I00329
num_objs 0
set04_V003_I01748
num_objs 2
set00_V001_I00989
num_objs 5
set05_V002_I00479
num_objs 1
set02_V010_I01355
num_objs 1
set05_V010_I00146
num_objs 1
set04_V011_I01541
num_objs 1
set01_V005_I01535
num_objs 0
set04_V003_I01271
num_objs 3
set00_V014_I00671
num_objs 3
set00_V008_I00026
num_objs 4
set00_V010_I00491
num_objs 4
set04_V003_I00512
num_objs 0
set01_V003_I01253
num_objs 1
set05_V005_I00926
num_objs 1
set01_V001_I00038
num_objs 2
set01_V003_I00884
num_objs 1
set03_V006_I00080
num_objs 1
set04_V006_I00611
num_objs 1
set03_V010_I01736
num_objs 3
set00_V000_I00722
num_objs 2
set04_V007_I00485
num_objs 1
set01_V004_I01457
num_objs 1
set03_V008_I01598
num_objs 2
set03_V005_I00263
num_objs 1
set00_V008_I00944
num_objs 1
set04_V006_I01622
num_objs 2
set03_V003_I01469
num_objs 0
set00_V001_I01823
num_objs 1
set05_V011_I00032
num_objs 1
set00_V012_I01535
num_objs 2
set03_V009_I00434
num_objs 3
set00_V013_I00047
num_objs 3
set04_V002_I01748
num_objs 2
set00_V010_I00752
num_objs 3
set05_V011_I00560
num_objs 4
set00_V013_I00782
num_objs 1
set03_V011_I01346
num_objs 1
set04_V007_I00434
num_objs 1
set01_V005_I01649
num_objs 0
set00_V007_I00140
num_objs 1
set01_V001_I01535
num_objs 10
set03_V005_I01586
num_objs 1
set00_V006_I00557
num_objs 4
set00_V012_I01232
num_objs 0
set02_V007_I00509
num_objs 1
set01_V002_I00236
num_objs 7
set00_V000_I00746
num_objs 2
set02_V008_I01205
num_objs 1
set01_V002_I01118
num_objs 3
set04_V002_I01544
num_objs 2
set03_V003_I01250
num_objs 2
set03_V003_I00530
num_objs 2
set01_V001_I01619
num_objs 1
set02_V011_I01337
num_objs 1
set03_V010_I00128
num_objs 2
set04_V004_I01121
num_objs 3
set01_V002_I00647
num_objs 7
set00_V008_I00494
num_objs 4
set00_V014_I00800
num_objs 5
set00_V001_I01802
num_objs 4
set04_V000_I00818
num_objs 1
set04_V002_I01181
num_objs 2
set01_V005_I00170
num_objs 2
set01_V003_I01751
num_objs 1
set02_V010_I00092
num_objs 1
set05_V003_I01724
num_objs 0
set03_V011_I00881
num_objs 1
set01_V004_I00299
num_objs 2
set02_V011_I01808
num_objs 2
set05_V005_I01238
num_objs 1
set00_V014_I01733
num_objs 2
set04_V007_I01574
num_objs 1
set03_V003_I00677
num_objs 2
set01_V003_I00467
num_objs 4
set05_V009_I00965
num_objs 1
set01_V004_I00143
num_objs 2
set01_V001_I00089
num_objs 1
set05_V007_I01169
num_objs 0
set01_V005_I01349
num_objs 1
set02_V009_I00386
num_objs 2
set01_V001_I00014
num_objs 2
set00_V012_I00071
num_objs 1
set00_V012_I00968
num_objs 5
set04_V006_I00710
num_objs 3
set00_V010_I00122
num_objs 3
set00_V007_I00770
num_objs 2
set03_V011_I00470
num_objs 5
set01_V001_I00500
num_objs 3
set03_V004_I00509
num_objs 1
set04_V002_I01394
num_objs 3
set03_V010_I01748
num_objs 3
set02_V009_I00527
num_objs 1
set05_V009_I00785
num_objs 1
set03_V011_I00371
num_objs 5
set03_V011_I00629
num_objs 2
set04_V002_I01658
num_objs 2
set01_V001_I01196
num_objs 7
set04_V010_I00878
num_objs 2
set04_V003_I01031
num_objs 4
set04_V004_I00860
num_objs 2
set02_V010_I00968
num_objs 1
set02_V003_I00719
num_objs 0
set03_V009_I01832
num_objs 4
set03_V006_I01820
num_objs 1
set03_V009_I01136
num_objs 4
set05_V005_I00431
num_objs 1
set00_V000_I00791
num_objs 0
set01_V003_I01385
num_objs 1
set03_V005_I00353
num_objs 2
set03_V008_I00686
num_objs 3
set03_V008_I01160
num_objs 1
set00_V013_I01181
num_objs 1
set00_V008_I00287
num_objs 0
set00_V012_I00974
num_objs 5
set04_V004_I00944
num_objs 2
set00_V014_I00113
num_objs 3
set00_V000_I01322
num_objs 1
set00_V009_I00473
num_objs 2
set02_V001_I01553
num_objs 1
set03_V009_I01658
num_objs 2
set00_V010_I00866
num_objs 3
set05_V005_I01097
num_objs 1
set00_V008_I00581
num_objs 5
set05_V004_I00488
num_objs 2
set05_V004_I00914
num_objs 1
set02_V010_I01262
num_objs 1
set01_V004_I00035
num_objs 2
set01_V001_I00617
num_objs 3
set04_V004_I01241
num_objs 2
set00_V008_I01472
num_objs 1
set00_V009_I00380
num_objs 2
set03_V008_I01244
num_objs 2
set04_V007_I00536
num_objs 1
set05_V010_I00728
num_objs 1
set00_V011_I01355
num_objs 4
set04_V010_I01628
num_objs 2
set01_V003_I00704
num_objs 1
set01_V001_I00170
num_objs 3
set01_V002_I01472
num_objs 0
set04_V004_I00458
num_objs 3
set03_V012_I01307
num_objs 3
set04_V007_I01370
num_objs 1
set00_V004_I00989
num_objs 3
set03_V010_I00932
num_objs 1
set00_V013_I00962
num_objs 1
set03_V008_I00632
num_objs 6
set01_V000_I01601
num_objs 4
set03_V011_I00764
num_objs 2
set00_V014_I00929
num_objs 1
set03_V011_I00911
num_objs 1
set01_V002_I01070
num_objs 3
set05_V011_I01574
num_objs 1
set05_V005_I01145
num_objs 1
set00_V003_I00347
num_objs 1
set04_V010_I00434
num_objs 1
set00_V013_I00416
num_objs 3
set04_V005_I01595
num_objs 2
set00_V001_I00776
num_objs 3
set05_V007_I01535
num_objs 1
set00_V011_I01487
num_objs 3
set00_V009_I00194
num_objs 5
set00_V006_I00047
num_objs 2
set00_V007_I00008
num_objs 1
set02_V011_I00464
num_objs 1
set04_V002_I01034
num_objs 2
set01_V002_I00965
num_objs 3
set05_V007_I01505
num_objs 1
set03_V008_I00959
num_objs 6
set00_V010_I00485
num_objs 6
set05_V003_I01646
num_objs 0
set00_V000_I00689
num_objs 2
set05_V003_I01232
num_objs 3
set00_V014_I00272
num_objs 2
set03_V009_I00575
num_objs 4
set00_V006_I01445
num_objs 3
set00_V006_I00263
num_objs 3
set04_V006_I00650
num_objs 3
set04_V010_I00845
num_objs 2
set03_V010_I01601
num_objs 2
set00_V011_I01340
num_objs 4
set00_V000_I01535
num_objs 1
set04_V008_I01514
num_objs 1
set00_V010_I01139
num_objs 5
set02_V003_I00314
num_objs 1
set03_V010_I01658
num_objs 3
set03_V005_I00713
num_objs 1
set04_V003_I01175
num_objs 3
set00_V002_I00581
num_objs 0
set03_V005_I00965
num_objs 1
set00_V001_I00716
num_objs 3
set00_V008_I01511
num_objs 2
set04_V010_I00599
num_objs 0
set01_V004_I01283
num_objs 1
set05_V011_I01202
num_objs 3
set00_V007_I00101
num_objs 1
set01_V005_I01658
num_objs 0
set01_V004_I01388
num_objs 1
set03_V005_I01055
num_objs 1
set01_V000_I00638
num_objs 1
set00_V014_I00878
num_objs 5
set00_V007_I00734
num_objs 2
set03_V010_I01505
num_objs 2
set00_V007_I00662
num_objs 2
set00_V006_I01322
num_objs 4
set04_V005_I00803
num_objs 1
set00_V012_I00722
num_objs 0
set03_V008_I01316
num_objs 3
set01_V001_I00047
num_objs 2
set03_V005_I00605
num_objs 3
set00_V009_I01313
num_objs 1
set05_V004_I00227
num_objs 3
set01_V004_I01019
num_objs 9
set05_V011_I00956
num_objs 8
set04_V007_I00602
num_objs 2
set03_V005_I01097
num_objs 1
set01_V001_I00962
num_objs 1
set01_V001_I01337
num_objs 10
set02_V010_I00467
num_objs 1
set00_V008_I00923
num_objs 1
set01_V002_I00329
num_objs 6
set00_V012_I00515
num_objs 2
set00_V006_I00950
num_objs 1
set00_V010_I00017
num_objs 4
set04_V008_I01463
num_objs 1
set00_V010_I01691
num_objs 1
set00_V002_I00314
num_objs 1
set03_V008_I00617
num_objs 7
set05_V007_I01577
num_objs 0
set01_V001_I00263
num_objs 2
set04_V008_I00995
num_objs 1
set01_V001_I00041
num_objs 2
set02_V010_I01802
num_objs 1
set03_V008_I01154
num_objs 1
set00_V013_I00059
num_objs 3
set00_V009_I00008
num_objs 1
set04_V007_I00869
num_objs 1
set00_V011_I01283
num_objs 3
set04_V002_I00869
num_objs 1
set03_V001_I00848
num_objs 1
set04_V004_I00959
num_objs 2
set00_V010_I00020
num_objs 4
set03_V005_I01052
num_objs 1
set00_V014_I01475
num_objs 4
set01_V004_I00290
num_objs 2
set03_V002_I01427
num_objs 1
set01_V003_I00836
num_objs 2
set04_V007_I00962
num_objs 2
set02_V010_I01151
num_objs 1
set03_V009_I00263
num_objs 3
set00_V014_I01814
num_objs 2
set04_V006_I01103
num_objs 1
set03_V012_I01328
num_objs 4
set03_V007_I01532
num_objs 0
set00_V010_I01001
num_objs 0
set03_V010_I01766
num_objs 3
set05_V012_I01205
num_objs 1
set01_V003_I01796
num_objs 1
set04_V003_I01313
num_objs 4
set00_V011_I00083
num_objs 4
set00_V002_I00569
num_objs 0
set00_V014_I01514
num_objs 3
set00_V010_I00770
num_objs 3
set00_V004_I00827
num_objs 1
set02_V011_I00662
num_objs 2
set02_V001_I01637
num_objs 1
set00_V006_I01343
num_objs 4
set01_V002_I01634
num_objs 4
set00_V002_I00782
num_objs 2
set01_V000_I00401
num_objs 2
set04_V007_I01445
num_objs 1
set03_V005_I00731
num_objs 1
set00_V012_I01460
num_objs 3
set04_V002_I00806
num_objs 1
set02_V007_I00341
num_objs 1
set05_V011_I00662
num_objs 2
set03_V011_I00860
num_objs 2
set04_V001_I01565
num_objs 2
set04_V006_I01514
num_objs 1
set04_V010_I01550
num_objs 2
set00_V000_I01103
num_objs 0
set03_V003_I00461
num_objs 2
set03_V001_I00800
num_objs 1
set00_V001_I00011
num_objs 2
set01_V001_I01304
num_objs 11
set00_V007_I01697
num_objs 5
set02_V010_I00017
num_objs 0
set02_V011_I01670
num_objs 2
set01_V002_I01316
num_objs 6
set01_V002_I01154
num_objs 1
set02_V009_I00299
num_objs 0
set02_V010_I01526
num_objs 1
set01_V005_I00815
num_objs 2
set05_V002_I00128
num_objs 1
set04_V004_I01424
num_objs 1
set04_V011_I01748
num_objs 1
set00_V008_I00257
num_objs 0
set00_V000_I01148
num_objs 0
set00_V014_I01709
num_objs 5
set04_V007_I00902
num_objs 2
set05_V010_I00104
num_objs 1
set02_V010_I00635
num_objs 2
set05_V012_I01133
num_objs 1
set00_V003_I00020
num_objs 0
set04_V003_I01529
num_objs 0
set00_V006_I00446
num_objs 4
set00_V014_I00755
num_objs 2
set01_V005_I00278
num_objs 1
set02_V009_I01598
num_objs 2
set05_V004_I00122
num_objs 3
set01_V000_I00386
num_objs 3
set01_V000_I00275
num_objs 1
set00_V010_I00740
num_objs 1
set01_V000_I00611
num_objs 4
set03_V012_I01295
num_objs 1
set05_V007_I01667
num_objs 0
set03_V011_I00971
num_objs 1
set01_V003_I00284
num_objs 3
set01_V003_I01655
num_objs 2
set01_V004_I01508
num_objs 2
set03_V003_I01001
num_objs 2
set03_V008_I00323
num_objs 18
set03_V004_I00458
num_objs 1
set01_V004_I00575
num_objs 1
set00_V011_I00635
num_objs 3
set01_V005_I01775
num_objs 0
set00_V006_I00281
num_objs 3
set05_V000_I00506
num_objs 3
set00_V009_I00779
num_objs 2
set03_V005_I01787
num_objs 2
set00_V004_I00230
num_objs 1
set05_V011_I01616
num_objs 1
set03_V005_I01061
num_objs 1
set02_V001_I01520
num_objs 1
set00_V010_I01214
num_objs 2
set01_V001_I00683
num_objs 3
set03_V008_I01688
num_objs 2
set00_V006_I00188
num_objs 3
set00_V011_I01499
num_objs 0
set00_V008_I01193
num_objs 0
set04_V004_I00758
num_objs 2
set03_V003_I00416
num_objs 1
set03_V003_I00194
num_objs 1
set00_V012_I00383
num_objs 0
set01_V002_I01775
num_objs 4
set04_V010_I00911
num_objs 2
set01_V004_I00779
num_objs 2
set00_V014_I01736
num_objs 2
set02_V010_I00167
num_objs 1
set03_V008_I00701
num_objs 3
set05_V000_I00248
num_objs 2
set01_V005_I01523
num_objs 0
set01_V000_I00032
num_objs 1
set04_V007_I01763
num_objs 1
set00_V011_I00707
num_objs 4
set00_V007_I00863
num_objs 3
set03_V005_I00758
num_objs 1
set04_V010_I00650
num_objs 1
set00_V000_I00320
num_objs 1
set04_V004_I01199
num_objs 3
set02_V010_I00791
num_objs 2
set00_V008_I00509
num_objs 10
set01_V004_I00986
num_objs 0
set05_V005_I00227
num_objs 1
set03_V003_I01169
num_objs 0
set03_V010_I01043
num_objs 3
set00_V009_I00485
num_objs 2
set05_V002_I00488
num_objs 1
set05_V000_I01577
num_objs 1
set00_V002_I00959
num_objs 3
set03_V005_I00506
num_objs 2
set05_V011_I00716
num_objs 1
set03_V010_I01652
num_objs 3
set01_V000_I01253
num_objs 3
set03_V003_I01121
num_objs 2
set04_V005_I01652
num_objs 1
set05_V010_I00734
num_objs 1
set02_V010_I00212
num_objs 1
set03_V012_I00842
num_objs 1
set00_V001_I01472
num_objs 5
set04_V004_I00824
num_objs 2
set04_V011_I01019
num_objs 1
set00_V009_I00740
num_objs 3
set00_V009_I00791
num_objs 2
set03_V011_I00992
num_objs 1
set02_V010_I00857
num_objs 1
set00_V000_I01499
num_objs 1
set04_V011_I01505
num_objs 1
set00_V000_I00107
num_objs 1
set01_V001_I00743
num_objs 2
set04_V005_I00296
num_objs 1
set00_V000_I01268
num_objs 1
set04_V006_I00938
num_objs 2
set04_V001_I01514
num_objs 1
set04_V010_I00854
num_objs 2
set00_V013_I01304
num_objs 3
set05_V010_I00602
num_objs 1
set00_V014_I00413
num_objs 5
set02_V007_I00293
num_objs 1
set03_V005_I01718
num_objs 1
set02_V011_I01826
num_objs 2
set04_V004_I00383
num_objs 1
set02_V009_I00191
num_objs 2
set05_V011_I00923
num_objs 8
set03_V008_I01286
num_objs 3
set00_V009_I00491
num_objs 2
set00_V010_I00683
num_objs 2
set00_V014_I01262
num_objs 4
set03_V009_I00275
num_objs 3
set00_V013_I00056
num_objs 3
set04_V000_I00953
num_objs 1
set00_V000_I00743
num_objs 2
set03_V011_I01460
num_objs 2
set01_V002_I00155
num_objs 7
set00_V014_I00488
num_objs 5
set02_V010_I00041
num_objs 0
set04_V003_I01409
num_objs 3
set00_V006_I00920
num_objs 5
set00_V011_I01361
num_objs 2
set00_V000_I01196
num_objs 1
set02_V010_I00767
num_objs 3
set00_V013_I01391
num_objs 2
set03_V012_I00935
num_objs 1
set00_V001_I01268
num_objs 4
set00_V010_I00974
num_objs 1
set03_V008_I00410
num_objs 17
set00_V001_I00710
num_objs 3
set00_V014_I01337
num_objs 6
set00_V011_I00869
num_objs 0
set03_V003_I00239
num_objs 1
set04_V010_I00797
num_objs 1
set00_V011_I00770
num_objs 1
set00_V014_I00374
num_objs 4
set01_V004_I01598
num_objs 1
set05_V005_I00998
num_objs 1
set02_V008_I00875
num_objs 2
set00_V011_I00335
num_objs 2
set02_V009_I00551
num_objs 2
set00_V006_I00056
num_objs 2
set00_V002_I00956
num_objs 2
set00_V000_I00200
num_objs 3
set00_V001_I01466
num_objs 5
set05_V005_I00656
num_objs 1
set00_V011_I01346
num_objs 3
set03_V003_I00308
num_objs 1
set05_V011_I01526
num_objs 1
set05_V011_I00761
num_objs 3
set03_V002_I01583
num_objs 1
set00_V011_I00362
num_objs 3
set03_V008_I01802
num_objs 1
set00_V006_I01628
num_objs 1
set04_V001_I00131
num_objs 1
set00_V012_I01238
num_objs 0
set02_V007_I00458
num_objs 1
set00_V012_I01130
num_objs 0
set03_V003_I00509
num_objs 2
set02_V009_I01727
num_objs 1
set00_V001_I01412
num_objs 4
set04_V006_I01631
num_objs 2
set01_V002_I01640
num_objs 4
set00_V011_I00089
num_objs 4
set00_V002_I00401
num_objs 0
set02_V009_I00263
num_objs 2
set03_V009_I00413
num_objs 3
set00_V001_I01106
num_objs 8
set04_V010_I00779
num_objs 0
set03_V005_I00239
num_objs 1
set04_V003_I00128
num_objs 0
set00_V004_I01280
num_objs 0
set03_V005_I01460
num_objs 1
set00_V013_I00923
num_objs 1
set00_V013_I01496
num_objs 4
set03_V010_I01679
num_objs 0
set04_V001_I01754
num_objs 1
set04_V001_I00167
num_objs 1
set05_V002_I01175
num_objs 1
set01_V001_I01622
num_objs 4
set01_V005_I01571
num_objs 0
set00_V009_I01100
num_objs 1
set01_V004_I01160
num_objs 2
set01_V002_I01703
num_objs 4
set05_V012_I01061
num_objs 1
set00_V010_I01562
num_objs 1
set04_V007_I01379
num_objs 1
set04_V008_I01037
num_objs 1
set00_V012_I01499
num_objs 0
set04_V007_I00479
num_objs 0
set01_V005_I00863
num_objs 2
set04_V003_I01805
num_objs 2
set00_V000_I01085
num_objs 0
set00_V010_I00842
num_objs 4
set02_V010_I01487
num_objs 2
set01_V001_I00863
num_objs 1
set00_V014_I00398
num_objs 5
set00_V002_I01193
num_objs 0
set00_V013_I00362
num_objs 4
set05_V012_I00491
num_objs 3
set05_V005_I00977
num_objs 1
set05_V005_I00983
num_objs 1
set00_V011_I00329
num_objs 0
set04_V002_I01427
num_objs 3
set04_V006_I00575
num_objs 1
set01_V004_I01193
num_objs 0
set00_V007_I01037
num_objs 3
set04_V004_I00701
num_objs 2
set03_V006_I01766
num_objs 1
set00_V010_I00644
num_objs 4
set00_V009_I01058
num_objs 1
set03_V012_I00020
num_objs 1
set05_V012_I00323
num_objs 1
set02_V010_I01232
num_objs 1
set03_V009_I00437
num_objs 3
set05_V010_I00020
num_objs 1
set04_V011_I01532
num_objs 1
set05_V005_I00182
num_objs 0
set00_V013_I00947
num_objs 1
set04_V006_I00863
num_objs 2
set03_V002_I01601
num_objs 1
set00_V013_I00803
num_objs 1
set04_V010_I00455
num_objs 1
set00_V007_I01460
num_objs 5
set04_V008_I01538
num_objs 1
set00_V009_I00140
num_objs 1
set01_V005_I00260
num_objs 1
set00_V000_I00398
num_objs 4
set02_V007_I00287
num_objs 1
set00_V008_I00905
num_objs 1
set03_V002_I01457
num_objs 1
set05_V005_I01205
num_objs 1
set00_V000_I01610
num_objs 2
set00_V011_I00197
num_objs 1
set00_V010_I00065
num_objs 3
set00_V006_I01895
num_objs 0
set00_V012_I00887
num_objs 6
set00_V014_I00119
num_objs 5
set00_V014_I01187
num_objs 4
set01_V001_I00635
num_objs 3
set05_V010_I00890
num_objs 1
set01_V001_I01505
num_objs 11
set01_V000_I00584
num_objs 1
set02_V010_I00365
num_objs 1
set05_V001_I00419
num_objs 0
set05_V007_I01679
num_objs 0
set00_V013_I01655
num_objs 2
set02_V011_I00728
num_objs 1
set00_V009_I00659
num_objs 4
set04_V003_I01706
num_objs 1
set03_V003_I00341
num_objs 1
set03_V010_I01370
num_objs 2
set05_V002_I00527
num_objs 1
set03_V010_I01778
num_objs 3
set00_V014_I00038
num_objs 3
set00_V001_I01277
num_objs 4
set02_V009_I01292
num_objs 1
set00_V008_I00632
num_objs 4
set00_V008_I00542
num_objs 6
set00_V006_I01778
num_objs 0
set01_V002_I01361
num_objs 1
set00_V010_I01364
num_objs 4
set04_V005_I01040
num_objs 3
set04_V002_I01661
num_objs 2
set04_V006_I01079
num_objs 0
set03_V010_I01718
num_objs 3
set05_V005_I01142
num_objs 1
set01_V001_I01715
num_objs 2
set03_V009_I01277
num_objs 1
set01_V005_I00059
num_objs 0
set05_V011_I01604
num_objs 1
set03_V011_I00659
num_objs 2
set03_V005_I00377
num_objs 1
set00_V008_I00137
num_objs 4
set00_V004_I01550
num_objs 0
set04_V005_I01136
num_objs 1
set05_V010_I01565
num_objs 1
set02_V010_I00578
num_objs 2
set04_V005_I01445
num_objs 2
set04_V001_I01724
num_objs 1
set03_V009_I01376
num_objs 1
set03_V006_I01808
num_objs 1
set04_V002_I01244
num_objs 2
set01_V000_I01082
num_objs 3
set05_V011_I00506
num_objs 1
set00_V014_I00716
num_objs 3
set00_V013_I00236
num_objs 3
set04_V003_I01493
num_objs 2
set00_V012_I00491
num_objs 1
set00_V007_I01925
num_objs 3
set02_V009_I00170
num_objs 2
set04_V002_I01136
num_objs 2
set00_V013_I00098
num_objs 5
set00_V006_I01691
num_objs 0
set01_V005_I00212
num_objs 2
set05_V010_I00101
num_objs 1
set00_V009_I00512
num_objs 2
set02_V009_I00428
num_objs 1
set00_V014_I00326
num_objs 3
set03_V011_I00839
num_objs 1
set00_V002_I00176
num_objs 2
set00_V008_I00503
num_objs 4
set03_V005_I00593
num_objs 3
set04_V003_I01037
num_objs 4
set00_V009_I01538
num_objs 4
set05_V004_I00194
num_objs 3
set00_V008_I01187
num_objs 0
set02_V010_I00098
num_objs 1
set01_V005_I01466
num_objs 0
set05_V007_I01397
num_objs 1
set05_V005_I00314
num_objs 2
set01_V002_I00728
num_objs 6
set04_V004_I00263
num_objs 1
set05_V005_I01058
num_objs 1
set00_V010_I00464
num_objs 7
set04_V005_I00731
num_objs 1
set05_V010_I01817
num_objs 0
set03_V003_I00503
num_objs 2
set04_V005_I00251
num_objs 1
set00_V013_I00626
num_objs 4
set02_V001_I00134
num_objs 0
set01_V004_I00674
num_objs 2
set03_V007_I00347
num_objs 1
set00_V000_I00287
num_objs 4
set03_V003_I00125
num_objs 2
set00_V008_I00764
num_objs 2
set05_V012_I01160
num_objs 1
set05_V010_I01529
num_objs 1
set03_V003_I00716
num_objs 2
set00_V002_I00947
num_objs 2
set03_V009_I00914
num_objs 4
set03_V001_I00014
num_objs 1
set04_V003_I00374
num_objs 1
set00_V008_I00740
num_objs 2
set05_V007_I01478
num_objs 1
set01_V005_I01706
num_objs 0
set04_V010_I00965
num_objs 1
set01_V004_I01406
num_objs 1
set04_V000_I00728
num_objs 3
set04_V003_I01511
num_objs 1
set03_V009_I01484
num_objs 1
set00_V014_I01772
num_objs 0
set04_V006_I01607
num_objs 1
set00_V011_I01472
num_objs 4
set05_V010_I00152
num_objs 1
set01_V003_I01358
num_objs 1
set04_V006_I01070
num_objs 1
set03_V008_I01169
num_objs 0
set00_V012_I01055
num_objs 0
set04_V004_I00812
num_objs 2
set00_V014_I01823
num_objs 2
set00_V001_I01160
num_objs 4
set01_V001_I00764
num_objs 1
set03_V003_I00923
num_objs 2
set05_V005_I00971
num_objs 1
set03_V011_I01145
num_objs 1
set00_V011_I00989
num_objs 12
set04_V002_I01568
num_objs 2
set04_V000_I00674
num_objs 3
set00_V011_I00305
num_objs 2
set02_V001_I00068
num_objs 0
set05_V008_I00221
num_objs 2
set03_V004_I00077
num_objs 1
set03_V005_I01625
num_objs 1
set00_V000_I01298
num_objs 1
set00_V006_I00380
num_objs 4
set00_V004_I00932
num_objs 2
set01_V005_I00998
num_objs 3
set04_V007_I01154
num_objs 2
set00_V000_I00128
num_objs 1
set04_V011_I01760
num_objs 1
set04_V002_I01316
num_objs 2
set00_V006_I00770
num_objs 0
set00_V006_I00530
num_objs 3
set01_V000_I01322
num_objs 4
set04_V007_I01076
num_objs 2
set00_V014_I00260
num_objs 2
set04_V003_I01217
num_objs 3
set04_V007_I00323
num_objs 1
set00_V014_I00935
num_objs 3
set00_V009_I00416
num_objs 2
set00_V013_I00797
num_objs 2
set03_V002_I01625
num_objs 2
set01_V002_I00362
num_objs 5
set04_V001_I00089
num_objs 0
set05_V011_I00995
num_objs 8
set00_V014_I01370
num_objs 7
set03_V008_I00647
num_objs 5
set00_V000_I01457
num_objs 1
set01_V001_I01010
num_objs 1
set01_V004_I00683
num_objs 1
set01_V000_I01463
num_objs 5
set03_V006_I01712
num_objs 1
set00_V011_I00536
num_objs 4
set03_V003_I00443
num_objs 1
set04_V002_I00731
num_objs 2
set05_V007_I01553
num_objs 0
set00_V014_I00446
num_objs 4
set00_V007_I01715
num_objs 5
set00_V011_I00803
num_objs 1
set02_V009_I00794
num_objs 2
set03_V009_I01301
num_objs 0
set00_V002_I00281
num_objs 1
set05_V002_I00740
num_objs 1
set01_V001_I00608
num_objs 3
set04_V004_I00662
num_objs 2
set02_V001_I01505
num_objs 1
set00_V000_I01646
num_objs 1
set01_V005_I00419
num_objs 2
set05_V005_I01151
num_objs 1
set00_V009_I00410
num_objs 2
set01_V001_I01766
num_objs 1
set04_V007_I01727
num_objs 1
set00_V000_I00995
num_objs 0
set00_V010_I00221
num_objs 3
set04_V000_I00752
num_objs 3
set03_V010_I00146
num_objs 2
set00_V012_I00917
num_objs 6
set00_V006_I00761
num_objs 0
set03_V009_I00551
num_objs 4
set04_V002_I01520
num_objs 3
set00_V003_I00566
num_objs 1
set01_V002_I01598
num_objs 3
set00_V006_I00431
num_objs 2
set00_V010_I00674
num_objs 2
set00_V001_I01169
num_objs 2
set01_V005_I01334
num_objs 1
set02_V011_I01355
num_objs 2
set03_V008_I00284
num_objs 16
set00_V000_I00860
num_objs 0
set04_V007_I01412
num_objs 1
set04_V007_I00362
num_objs 1
set03_V011_I00965
num_objs 1
set00_V000_I00503
num_objs 1
set04_V004_I00563
num_objs 3
set05_V012_I00536
num_objs 1
set01_V005_I00893
num_objs 2
set00_V009_I00914
num_objs 2
set03_V008_I00503
num_objs 16
set05_V003_I01763
num_objs 0
set03_V005_I01760
num_objs 2
set01_V004_I01322
num_objs 1
set02_V011_I00293
num_objs 0
set03_V005_I00869
num_objs 0
set00_V001_I00908
num_objs 4
set00_V001_I00647
num_objs 4
set00_V013_I00005
num_objs 4
set05_V011_I01256
num_objs 3
set03_V005_I01310
num_objs 1
set04_V008_I01373
num_objs 1
set04_V010_I00482
num_objs 1
set01_V002_I00836
num_objs 8
set00_V001_I00803
num_objs 3
set04_V003_I00122
num_objs 0
set04_V003_I00974
num_objs 4
set00_V010_I00701
num_objs 2
set00_V007_I00752
num_objs 2
set04_V008_I01322
num_objs 1
set02_V009_I00617
num_objs 2
set02_V010_I00719
num_objs 1
set00_V012_I01181
num_objs 1
set05_V010_I00374
num_objs 1
set03_V005_I00419
num_objs 2
set01_V002_I01592
num_objs 2
set05_V003_I01670
num_objs 0
set00_V007_I01115
num_objs 11
set00_V008_I00362
num_objs 1
set04_V007_I00644
num_objs 2
set00_V012_I01064
num_objs 0
set00_V012_I01226
num_objs 0
set03_V008_I00581
num_objs 10
set00_V001_I01808
num_objs 4
set00_V009_I00815
num_objs 2
set04_V005_I01001
num_objs 3
set02_V009_I00638
num_objs 2
set00_V010_I00449
num_objs 4
set03_V008_I01448
num_objs 3
set04_V005_I01046
num_objs 3
set04_V005_I00959
num_objs 1
set04_V010_I01640
num_objs 2
set03_V004_I00506
num_objs 1
set04_V005_I01646
num_objs 1
set00_V001_I00059
num_objs 0
set00_V011_I01244
num_objs 3
set02_V008_I01154
num_objs 0
set00_V006_I00368
num_objs 4
set00_V012_I00434
num_objs 0
set05_V000_I00293
num_objs 3
set03_V008_I00641
num_objs 6
set00_V012_I00014
num_objs 0
set00_V012_I00932
num_objs 6
set03_V006_I01778
num_objs 1
set00_V006_I01745
num_objs 0
set00_V010_I00044
num_objs 4
set00_V014_I01172
num_objs 3
set00_V007_I01205
num_objs 8
set01_V001_I00737
num_objs 2
set05_V005_I00671
num_objs 1
set00_V004_I00521
num_objs 1
set00_V011_I01061
num_objs 10
set02_V010_I00095
num_objs 1
set02_V009_I00161
num_objs 2
set00_V008_I00674
num_objs 3
set04_V003_I01652
num_objs 1
set04_V000_I00968
num_objs 1
set03_V005_I01796
num_objs 2
set02_V008_I00896
num_objs 1
set00_V004_I01289
num_objs 9
set03_V011_I00569
num_objs 2
set02_V010_I00506
num_objs 1
set04_V006_I00884
num_objs 2
set04_V001_I00029
num_objs 0
set00_V000_I00647
num_objs 1
set02_V009_I01100
num_objs 1
set01_V000_I01295
num_objs 3
set03_V010_I01502
num_objs 2
set00_V002_I00668
num_objs 1
set00_V007_I00389
num_objs 0
set04_V002_I01724
num_objs 3
set04_V003_I01502
num_objs 2
set00_V014_I00995
num_objs 3
set00_V014_I01358
num_objs 6
set04_V003_I01655
num_objs 1
set00_V014_I01829
num_objs 2
set00_V004_I00233
num_objs 1
set00_V013_I00332
num_objs 5
set03_V008_I00170
num_objs 13
set00_V010_I00419
num_objs 5
set03_V003_I01457
num_objs 2
set03_V008_I01475
num_objs 3
set04_V003_I00953
num_objs 2
set01_V003_I01295
num_objs 1
set03_V007_I00254
num_objs 1
set00_V000_I01211
num_objs 2
set02_V010_I00914
num_objs 1
set00_V002_I00866
num_objs 9
set00_V007_I00641
num_objs 2
set03_V010_I01079
num_objs 1
set00_V006_I01922
num_objs 0
set03_V003_I01256
num_objs 2
set01_V000_I00293
num_objs 1
set00_V006_I01742
num_objs 0
set00_V012_I01448
num_objs 2
set04_V003_I01160
num_objs 3
set01_V000_I01544
num_objs 4
set00_V008_I00077
num_objs 6
set03_V006_I00098
num_objs 1
set02_V011_I01706
num_objs 2
set02_V010_I01427
num_objs 1
set04_V006_I01496
num_objs 1
set05_V000_I01346
num_objs 1
set03_V008_I00386
num_objs 19
set03_V010_I00110
num_objs 1
set02_V001_I01691
num_objs 1
set01_V005_I01763
num_objs 0
set00_V011_I01007
num_objs 11
set04_V003_I01082
num_objs 4
set00_V011_I00485
num_objs 5
set01_V005_I01118
num_objs 4
set01_V000_I00521
num_objs 2
set04_V011_I01115
num_objs 2
set00_V000_I00440
num_objs 5
set04_V002_I01451
num_objs 2
set00_V009_I01664
num_objs 1
set02_V009_I00221
num_objs 2
set01_V001_I00755
num_objs 1
set02_V009_I01343
num_objs 1
set00_V007_I00785
num_objs 2
set03_V003_I00227
num_objs 1
set04_V000_I00875
num_objs 1
set01_V002_I00494
num_objs 6
set00_V013_I00557
num_objs 3
set00_V009_I01007
num_objs 4
set02_V011_I00383
num_objs 2
set03_V010_I00788
num_objs 0
set04_V002_I01322
num_objs 2
set05_V004_I00209
num_objs 0
set04_V001_I01727
num_objs 1
set03_V006_I00125
num_objs 1
set00_V013_I00932
num_objs 1
set00_V010_I01337
num_objs 5
set00_V013_I01214
num_objs 1
set00_V014_I00122
num_objs 3
set03_V010_I00893
num_objs 1
set00_V006_I01751
num_objs 0
set01_V005_I01175
num_objs 3
set05_V000_I00608
num_objs 1
set01_V005_I01442
num_objs 0
set03_V008_I01028
num_objs 1
set04_V003_I01397
num_objs 3
set01_V002_I01511
num_objs 0
set02_V009_I01649
num_objs 0
set04_V001_I01664
num_objs 2
set00_V011_I01436
num_objs 3
set03_V008_I01211
num_objs 2
set04_V011_I01001
num_objs 2
set05_V003_I01292
num_objs 2
set01_V002_I01811
num_objs 4
set03_V008_I00884
num_objs 1
set03_V011_I00617
num_objs 4
set01_V003_I00164
num_objs 8
set00_V006_I00005
num_objs 1
set04_V005_I01601
num_objs 2
set00_V007_I00761
num_objs 2
set04_V004_I00542
num_objs 3
set03_V012_I01217
num_objs 1
set01_V005_I00521
num_objs 2
set01_V001_I00818
num_objs 1
set05_V004_I00473
num_objs 2
set03_V009_I00731
num_objs 2
set04_V004_I00491
num_objs 3
set03_V009_I00902
num_objs 4
set00_V007_I01487
num_objs 4
set01_V001_I01466
num_objs 11
set00_V014_I01877
num_objs 1
set04_V002_I01043
num_objs 2
set03_V003_I00377
num_objs 1
set00_V014_I01280
num_objs 4
set04_V010_I00677
num_objs 1
set03_V009_I00326
num_objs 4
set00_V008_I00866
num_objs 1
set04_V003_I01643
num_objs 1
set00_V013_I00515
num_objs 4
set02_V010_I01412
num_objs 1
set00_V002_I00146
num_objs 1
set05_V004_I00176
num_objs 3
set01_V000_I00800
num_objs 1
set05_V011_I00713
num_objs 1
set01_V000_I00845
num_objs 0
set03_V001_I00143
num_objs 1
set05_V000_I00500
num_objs 3
set04_V005_I00992
num_objs 3
set00_V012_I01658
num_objs 1
set00_V012_I01217
num_objs 0
set05_V003_I01064
num_objs 1
set01_V005_I01640
num_objs 0
set02_V011_I01565
num_objs 2
set00_V007_I00809
num_objs 2
set02_V010_I01349
num_objs 0
set04_V002_I00767
num_objs 2
set04_V005_I01439
num_objs 1
set04_V008_I01424
num_objs 1
set01_V004_I00569
num_objs 1
set04_V007_I01649
num_objs 1
set00_V008_I00914
num_objs 1
set00_V007_I01181
num_objs 8
set04_V000_I00479
num_objs 1
set05_V000_I00386
num_objs 2
set00_V000_I01799
num_objs 0
set03_V009_I00974
num_objs 2
set01_V002_I00914
num_objs 4
set02_V010_I01673
num_objs 1
set00_V008_I00872
num_objs 1
set01_V000_I01013
num_objs 1
set00_V013_I01337
num_objs 3
set05_V005_I00773
num_objs 1
set00_V008_I01412
num_objs 1
set00_V006_I01121
num_objs 9
set01_V002_I00311
num_objs 7
set00_V004_I00956
num_objs 2
set00_V001_I00038
num_objs 1
set01_V003_I00671
num_objs 2
set04_V002_I00932
num_objs 1
set00_V011_I01295
num_objs 4
set01_V003_I00200
num_objs 7
set05_V005_I00404
num_objs 1
set05_V007_I01490
num_objs 1
set05_V010_I00698
num_objs 1
set00_V011_I00881
num_objs 0
set02_V009_I00623
num_objs 2
set00_V004_I00005
num_objs 1
set00_V014_I01412
num_objs 4
set00_V009_I01316
num_objs 1
set03_V011_I00347
num_objs 5
set05_V010_I01580
num_objs 1
set03_V009_I00203
num_objs 5
set04_V011_I01580
num_objs 1
set02_V011_I00539
num_objs 0
set01_V004_I01319
num_objs 5
set00_V014_I00026
num_objs 3
set01_V001_I00095
num_objs 3
set01_V002_I01430
num_objs 0
set02_V011_I01304
num_objs 1
set01_V005_I00062
num_objs 2
set01_V001_I00353
num_objs 4
set00_V007_I00269
num_objs 2
set02_V007_I00191
num_objs 1
set00_V001_I01490
num_objs 5
set05_V011_I01313
num_objs 2
set05_V003_I01208
num_objs 3
set03_V012_I01565
num_objs 3
set05_V011_I00623
num_objs 4
set01_V005_I01487
num_objs 0
set00_V006_I00563
num_objs 4
set00_V006_I01715
num_objs 0
set00_V000_I01001
num_objs 0
set05_V011_I00011
num_objs 1
set03_V003_I00569
num_objs 1
set04_V003_I01088
num_objs 4
set02_V009_I01178
num_objs 2
set03_V005_I00245
num_objs 1
set00_V001_I00698
num_objs 3
set00_V014_I00362
num_objs 3
set00_V003_I00422
num_objs 1
set00_V013_I00773
num_objs 2
set00_V010_I00971
num_objs 1
set02_V010_I00281
num_objs 1
set04_V003_I00926
num_objs 1
set03_V006_I01826
num_objs 1
set00_V013_I00971
num_objs 1
set01_V001_I00506
num_objs 3
set00_V002_I00455
num_objs 0
set00_V009_I01337
num_objs 1
set00_V000_I01460
num_objs 1
set01_V003_I00560
num_objs 1
set00_V008_I01535
num_objs 1
set02_V009_I00857
num_objs 1
set05_V009_I00890
num_objs 1
set05_V008_I00248
num_objs 1
set05_V005_I00335
num_objs 2
set00_V007_I01634
num_objs 5
set01_V001_I01115
num_objs 1
set00_V014_I01460
num_objs 3
set00_V006_I00050
num_objs 2
set00_V008_I00893
num_objs 1
set05_V012_I00506
num_objs 2
set00_V001_I01544
num_objs 3
set00_V007_I01508
num_objs 4
set04_V005_I01250
num_objs 1
set02_V007_I00269
num_objs 1
set02_V011_I01622
num_objs 2
set02_V010_I00047
num_objs 0
set00_V002_I00560
num_objs 0
set05_V011_I01586
num_objs 1
set00_V002_I00605
num_objs 0
set03_V001_I00023
num_objs 1
set04_V004_I00239
num_objs 0
set01_V001_I01100
num_objs 1
set04_V010_I00788
num_objs 1
set00_V008_I01211
num_objs 2
set00_V007_I01379
num_objs 3
set04_V004_I00452
num_objs 3
set00_V002_I00470
num_objs 0
set00_V012_I01481
num_objs 1
set01_V003_I00146
num_objs 8
set00_V008_I00173
num_objs 2
set05_V007_I01238
num_objs 1
set04_V011_I01559
num_objs 0
set02_V007_I00257
num_objs 1
set01_V002_I00371
num_objs 5
set00_V007_I00815
num_objs 3
set03_V008_I00989
num_objs 4
set04_V006_I00680
num_objs 3
set03_V008_I00752
num_objs 3
set01_V002_I01649
num_objs 5
set01_V000_I00968
num_objs 0
set03_V012_I01487
num_objs 3
set01_V001_I01451
num_objs 14
set00_V000_I00290
num_objs 4
set04_V008_I01061
num_objs 1
set03_V010_I01685
num_objs 3
set01_V005_I01277
num_objs 1
set00_V008_I01019
num_objs 1
set05_V010_I00440
num_objs 1
set01_V002_I01076
num_objs 3
set05_V004_I00149
num_objs 0
set03_V009_I00200
num_objs 5
set03_V008_I00320
num_objs 18
set04_V005_I01265
num_objs 1
set03_V010_I01394
num_objs 2
set03_V011_I01454
num_objs 2
set02_V011_I01427
num_objs 2
set05_V007_I01361
num_objs 1
set00_V008_I00368
num_objs 1
set03_V011_I00794
num_objs 2
set00_V004_I00128
num_objs 1
set01_V005_I00401
num_objs 4
set00_V012_I01028
num_objs 2
set00_V000_I00635
num_objs 0
set03_V003_I00584
num_objs 2
set05_V011_I01091
num_objs 6
set05_V010_I00959
num_objs 0
set03_V010_I01544
num_objs 3
set02_V011_I01784
num_objs 2
set00_V008_I01055
num_objs 2
set03_V003_I00611
num_objs 2
set04_V003_I01067
num_objs 4
set04_V004_I00095
num_objs 1
set02_V011_I00473
num_objs 2
set02_V010_I01493
num_objs 2
set01_V000_I00431
num_objs 3
set00_V006_I01592
num_objs 2
set00_V007_I01577
num_objs 8
set01_V004_I01214
num_objs 0
set00_V004_I00875
num_objs 1
set00_V002_I01031
num_objs 0
set04_V011_I00995
num_objs 2
set01_V000_I01388
num_objs 3
set00_V006_I01763
num_objs 1
set00_V006_I00821
num_objs 3
set03_V009_I00941
num_objs 4
set01_V002_I00290
num_objs 7
set05_V004_I00188
num_objs 3
set03_V010_I00947
num_objs 1
set05_V011_I01262
num_objs 3
set04_V007_I00824
num_objs 2
set01_V002_I00881
num_objs 7
set02_V009_I00389
num_objs 1
set03_V008_I00983
num_objs 1
set03_V002_I01514
num_objs 1
set03_V009_I01742
num_objs 4
set05_V000_I01508
num_objs 1
set04_V002_I01652
num_objs 2
set02_V011_I01745
num_objs 2
set02_V008_I01190
num_objs 0
set03_V012_I01604
num_objs 3
set05_V003_I01634
num_objs 0
set02_V010_I00494
num_objs 1
set03_V008_I00068
num_objs 6
set03_V008_I00296
num_objs 17
set01_V005_I01370
num_objs 1
set01_V001_I01406
num_objs 11
set02_V009_I01631
num_objs 2
set00_V006_I01340
num_objs 4
set03_V005_I01838
num_objs 2
set00_V012_I01004
num_objs 2
set00_V010_I01184
num_objs 2
set01_V003_I01547
num_objs 1
set01_V001_I00779
num_objs 1
set03_V003_I01235
num_objs 2
set00_V007_I01463
num_objs 5
set00_V007_I00467
num_objs 5
set04_V002_I00089
num_objs 1
set02_V007_I00212
num_objs 1
set00_V011_I00638
num_objs 3
set00_V009_I01379
num_objs 0
set00_V008_I00185
num_objs 1
set02_V010_I01508
num_objs 2
set00_V006_I00386
num_objs 4
set01_V001_I00482
num_objs 3
set00_V010_I00746
num_objs 1
set04_V007_I01130
num_objs 2
set04_V004_I00476
num_objs 3
set00_V006_I00812
num_objs 3
set00_V014_I01631
num_objs 4
set00_V001_I01610
num_objs 3
set03_V003_I00284
num_objs 1
set03_V004_I00545
num_objs 1
set04_V007_I00404
num_objs 1
set03_V008_I01145
num_objs 1
set00_V000_I01082
num_objs 0
set05_V011_I00842
num_objs 7
set00_V006_I01109
num_objs 5
set01_V001_I00071
num_objs 2
set00_V009_I01433
num_objs 1
set00_V012_I00332
num_objs 1
set01_V001_I00116
num_objs 4
set04_V010_I00605
num_objs 1
set00_V006_I01688
num_objs 0
set04_V004_I00926
num_objs 2
set03_V003_I00167
num_objs 2
set00_V010_I01262
num_objs 3
set00_V013_I01586
num_objs 3
set02_V010_I00602
num_objs 2
set04_V004_I00215
num_objs 2
set03_V011_I00653
num_objs 3
set03_V002_I01556
num_objs 1
set03_V009_I01643
num_objs 2
set01_V002_I01340
num_objs 5
set00_V011_I00566
num_objs 3
set00_V014_I01856
num_objs 0
set03_V009_I01322
num_objs 0
set00_V007_I01391
num_objs 3
set05_V010_I00491
num_objs 1
set00_V013_I01355
num_objs 3
set01_V002_I00200
num_objs 7
set02_V009_I01469
num_objs 0
set02_V010_I01679
num_objs 0
set04_V003_I01208
num_objs 3
set02_V010_I01403
num_objs 1
set04_V003_I01661
num_objs 1
set04_V002_I01616
num_objs 2
set00_V010_I00557
num_objs 5
set00_V014_I00167
num_objs 1
set00_V007_I00938
num_objs 3
set01_V003_I01376
num_objs 1
set00_V001_I00251
num_objs 5
set00_V011_I01154
num_objs 5
set01_V002_I01799
num_objs 3
set03_V012_I01214
num_objs 1
set01_V005_I01631
num_objs 0
set00_V014_I00731
num_objs 3
set04_V005_I00236
num_objs 1
set04_V005_I00155
num_objs 1
set04_V007_I01775
num_objs 1
set05_V011_I00563
num_objs 4
set03_V008_I01664
num_objs 2
set00_V007_I00182
num_objs 4
set01_V002_I00263
num_objs 7
set00_V012_I01577
num_objs 2
set03_V007_I00302
num_objs 1
set00_V012_I00782
num_objs 2
set00_V006_I01718
num_objs 0
set03_V005_I00842
num_objs 1
set02_V009_I01310
num_objs 1
set02_V009_I00473
num_objs 1
set05_V010_I00752
num_objs 1
set00_V010_I00323
num_objs 5
set04_V007_I01604
num_objs 1
set04_V000_I00755
num_objs 3
set02_V009_I00344
num_objs 2
set05_V009_I00869
num_objs 1
set01_V004_I01025
num_objs 3
set04_V007_I00944
num_objs 2
set03_V003_I00989
num_objs 0
set04_V010_I00467
num_objs 1
set03_V009_I01655
num_objs 2
set01_V003_I00410
num_objs 3
set02_V011_I00878
num_objs 1
set00_V002_I00308
num_objs 1
set04_V005_I00851
num_objs 1
set04_V000_I00941
num_objs 1
set00_V012_I01187
num_objs 1
set02_V010_I01127
num_objs 1
set01_V000_I01622
num_objs 3
set04_V001_I01559
num_objs 0
set03_V009_I01787
num_objs 4
set00_V011_I01079
num_objs 11
set00_V007_I00911
num_objs 3
set03_V003_I00683
num_objs 2
set04_V004_I01418
num_objs 1
set00_V007_I00173
num_objs 1
set00_V009_I00623
num_objs 2
set00_V000_I00236
num_objs 4
set04_V008_I00536
num_objs 1
set00_V013_I01154
num_objs 3
set04_V007_I01634
num_objs 1
set05_V012_I01220
num_objs 1
set04_V002_I01646
num_objs 2
set03_V008_I00944
num_objs 1
set00_V010_I00797
num_objs 4
set04_V001_I01508
num_objs 1
set01_V003_I00098
num_objs 5
set04_V004_I00974
num_objs 2
set04_V005_I01556
num_objs 2
set01_V002_I00632
num_objs 7
set05_V005_I01193
num_objs 1
set00_V011_I00125
num_objs 3
set05_V000_I01598
num_objs 1
set03_V008_I00716
num_objs 3
set00_V014_I01196
num_objs 4
set04_V002_I00944
num_objs 2
set03_V005_I01331
num_objs 1
set00_V000_I01517
num_objs 1
set00_V011_I01529
num_objs 5
set01_V001_I01193
num_objs 4
set01_V003_I01736
num_objs 1
set02_V010_I01799
num_objs 0
set01_V000_I01508
num_objs 4
set00_V013_I00956
num_objs 1
set04_V004_I00413
num_objs 2
set04_V007_I00554
num_objs 1
set05_V000_I01394
num_objs 2
set03_V008_I00734
num_objs 3
set03_V011_I01202
num_objs 1
set00_V011_I00806
num_objs 1
set05_V008_I00233
num_objs 2
set04_V005_I00791
num_objs 1
set04_V004_I01358
num_objs 1
set03_V008_I01064
num_objs 1
set03_V012_I00983
num_objs 1
set05_V011_I01628
num_objs 1
set03_V005_I00233
num_objs 1
set00_V001_I00359
num_objs 4
set00_V004_I01265
num_objs 0
set04_V003_I00383
num_objs 1
set00_V010_I00380
num_objs 6
set05_V010_I00665
num_objs 1
set00_V000_I01667
num_objs 2
set00_V009_I00557
num_objs 2
set04_V000_I00707
num_objs 3
set04_V010_I00920
num_objs 2
set00_V011_I00893
num_objs 0
set03_V008_I01694
num_objs 2
set01_V003_I01007
num_objs 2
set00_V000_I01832
num_objs 1
set03_V005_I01565
num_objs 1
set00_V001_I01751
num_objs 1
set04_V002_I00773
num_objs 2
set02_V011_I01346
num_objs 1
set04_V008_I01490
num_objs 1
set00_V014_I00578
num_objs 5
set01_V002_I00641
num_objs 7
set01_V002_I01310
num_objs 6
set03_V005_I01724
num_objs 2
set02_V011_I00956
num_objs 1
set03_V004_I00155
num_objs 1
set00_V014_I00317
num_objs 4
set01_V004_I01244
num_objs 0
set01_V001_I00974
num_objs 1
set01_V002_I00878
num_objs 7
set01_V002_I00281
num_objs 8
set02_V010_I00401
num_objs 1
set01_V005_I01796
num_objs 0
set00_V008_I01070
num_objs 2
set02_V011_I01817
num_objs 2
set00_V007_I01352
num_objs 6
set00_V001_I00818
num_objs 3
set01_V002_I00869
num_objs 6
set01_V005_I00653
num_objs 2
set04_V006_I01568
num_objs 1
set03_V008_I00299
num_objs 15
set04_V002_I00644
num_objs 1
set02_V009_I01196
num_objs 2
set03_V005_I00470
num_objs 2
set00_V004_I00560
num_objs 1
set02_V011_I00770
num_objs 0
set00_V000_I00284
num_objs 4
set00_V004_I01043
num_objs 1
set00_V006_I00437
num_objs 2
set05_V000_I01706
num_objs 1
set03_V003_I00185
num_objs 1
set05_V010_I00779
num_objs 0
set03_V005_I01556
num_objs 1
set00_V010_I01517
num_objs 3
set01_V002_I00530
num_objs 8
set05_V000_I00470
num_objs 3
set05_V003_I01259
num_objs 3
set00_V009_I01553
num_objs 4
set02_V008_I01853
num_objs 0
set04_V004_I00794
num_objs 2
set01_V000_I00443
num_objs 2
set03_V005_I01418
num_objs 1
set05_V005_I00866
num_objs 2
set04_V006_I01505
num_objs 1
set00_V006_I00626
num_objs 4
set00_V001_I00821
num_objs 3
set00_V012_I00200
num_objs 1
set00_V010_I01376
num_objs 3
set00_V008_I00929
num_objs 1
set04_V005_I00233
num_objs 1
set03_V011_I00719
num_objs 1
set02_V010_I01301
num_objs 1
set03_V008_I01349
num_objs 1
set04_V007_I01415
num_objs 1
set00_V012_I00206
num_objs 1
set00_V001_I01511
num_objs 5
set01_V000_I01574
num_objs 4
set00_V010_I01673
num_objs 1
set03_V003_I01496
num_objs 2
set05_V010_I00821
num_objs 2
set00_V008_I00788
num_objs 2
set03_V002_I01526
num_objs 1
set00_V007_I00317
num_objs 6
set00_V011_I00554
num_objs 3
set03_V009_I00938
num_objs 4
set03_V010_I00989
num_objs 1
set00_V007_I00494
num_objs 4
set00_V001_I00473
num_objs 1
set01_V005_I01676
num_objs 0
set03_V002_I01487
num_objs 1
set00_V000_I00449
num_objs 1
set04_V002_I01070
num_objs 2
set00_V008_I01223
num_objs 2
set05_V009_I00989
num_objs 0
set00_V012_I01205
num_objs 0
set02_V009_I00257
num_objs 2
set05_V002_I01616
num_objs 1
set00_V001_I01577
num_objs 3
set03_V003_I00806
num_objs 2
set03_V004_I00074
num_objs 1
set00_V014_I00479
num_objs 4
set00_V010_I00086
num_objs 3
set00_V006_I00074
num_objs 2
set02_V009_I00275
num_objs 2
set04_V000_I00629
num_objs 1
set00_V010_I00680
num_objs 2
set01_V003_I00680
num_objs 2
set00_V013_I01307
num_objs 4
set05_V011_I00590
num_objs 5
set00_V001_I00050
num_objs 1
set04_V006_I00581
num_objs 1
set04_V003_I01241
num_objs 3
set05_V001_I00383
num_objs 0
set02_V009_I01415
num_objs 1
set03_V009_I00128
num_objs 5
set03_V009_I01319
num_objs 0
set02_V011_I00488
num_objs 2
set03_V012_I01262
num_objs 0
set00_V007_I01289
num_objs 4
set00_V006_I01424
num_objs 4
set03_V011_I00935
num_objs 1
set00_V008_I01529
num_objs 1
set02_V011_I00518
num_objs 2
set00_V007_I00644
num_objs 2
set00_V012_I01013
num_objs 2
set02_V008_I01301
num_objs 1
set05_V012_I00515
num_objs 1
set00_V010_I01325
num_objs 4
set04_V003_I00500
num_objs 0
set00_V010_I01622
num_objs 0
set00_V006_I00749
num_objs 1
set04_V001_I01661
num_objs 2
set00_V001_I01799
num_objs 1
set04_V011_I01049
num_objs 0
set05_V012_I01115
num_objs 1
set05_V002_I01634
num_objs 1
set00_V006_I01118
num_objs 9
set02_V010_I00413
num_objs 1
set00_V011_I00980
num_objs 10
set05_V011_I01358
num_objs 1
set01_V005_I00596
num_objs 3
set01_V004_I01205
num_objs 0
set03_V008_I00824
num_objs 2
set03_V008_I01394
num_objs 3
set03_V008_I00815
num_objs 2
set02_V001_I00107
num_objs 0
set01_V005_I01301
num_objs 1
set00_V008_I00485
num_objs 6
set02_V009_I01841
num_objs 2
set00_V000_I00305
num_objs 1
set03_V012_I01259
num_objs 0
set00_V013_I00386
num_objs 4
set00_V004_I00470
num_objs 1
set00_V006_I00635
num_objs 3
set05_V005_I00338
num_objs 2
set00_V002_I00710
num_objs 1
set00_V001_I00506
num_objs 4
set02_V008_I00563
num_objs 1
set03_V005_I00821
num_objs 1
set04_V005_I01565
num_objs 2
set01_V005_I01412
num_objs 0
set04_V002_I00965
num_objs 2
set02_V011_I00449
num_objs 1
set01_V000_I01022
num_objs 1
set02_V011_I00359
num_objs 1
set01_V002_I01748
num_objs 5
set02_V010_I00803
num_objs 2
set00_V001_I01712
num_objs 1
set03_V008_I01370
num_objs 3
set05_V001_I00176
num_objs 1
set01_V001_I01334
num_objs 10
set01_V002_I00542
num_objs 8
set02_V007_I00350
num_objs 1
set01_V002_I00788
num_objs 7
set01_V004_I00269
num_objs 4
set01_V001_I01184
num_objs 3
set00_V004_I00563
num_objs 1
set00_V008_I00758
num_objs 2
set00_V010_I01535
num_objs 3
set01_V001_I01118
num_objs 1
set00_V006_I01085
num_objs 9
set05_V007_I01172
num_objs 1
set03_V005_I01778
num_objs 2
set01_V002_I00497
num_objs 6
set00_V008_I00266
num_objs 0
set00_V013_I00665
num_objs 2
set00_V006_I00002
num_objs 1
set04_V008_I01334
num_objs 1
set04_V004_I01061
num_objs 2
set00_V000_I00119
num_objs 0
set04_V002_I00041
num_objs 1
set00_V009_I00638
num_objs 1
set00_V008_I00626
num_objs 4
set00_V001_I01559
num_objs 0
set01_V003_I00233
num_objs 7
set01_V004_I00161
num_objs 1
set00_V011_I01427
num_objs 3
set05_V011_I01112
num_objs 5
set00_V014_I00914
num_objs 2
set05_V011_I00719
num_objs 0
set04_V001_I00140
num_objs 1
set00_V006_I00221
num_objs 3
set01_V003_I00401
num_objs 3
set04_V010_I00869
num_objs 2
set04_V002_I00602
num_objs 1
set03_V009_I00809
num_objs 0
set00_V011_I01520
num_objs 3
set04_V004_I01409
num_objs 1
set00_V013_I00305
num_objs 6
set00_V014_I00476
num_objs 4
set03_V009_I01268
num_objs 2
set01_V004_I00197
num_objs 1
set04_V000_I00494
num_objs 2
set02_V010_I01469
num_objs 0
set00_V013_I01328
num_objs 4
set00_V006_I01352
num_objs 4
set04_V004_I00806
num_objs 2
set05_V011_I00728
num_objs 2
set04_V002_I01787
num_objs 1
set01_V002_I01286
num_objs 4
set03_V005_I01763
num_objs 2
set00_V007_I01553
num_objs 6
set04_V002_I00950
num_objs 2
set01_V003_I00281
num_objs 3
set02_V011_I00839
num_objs 0
set00_V014_I00767
num_objs 4
set05_V011_I01418
num_objs 3
set01_V001_I00809
num_objs 0
set04_V005_I01148
num_objs 1
set04_V010_I00938
num_objs 1
set04_V000_I00809
num_objs 0
set05_V000_I01514
num_objs 1
set05_V005_I00800
num_objs 1
set00_V011_I00845
num_objs 0
set00_V001_I01742
num_objs 1
set00_V012_I00086
num_objs 1
set04_V011_I00971
num_objs 1
set00_V012_I00632
num_objs 0
set00_V013_I01064
num_objs 2
set03_V009_I00815
num_objs 2
set01_V001_I00521
num_objs 4
set02_V009_I01742
num_objs 1
set04_V011_I00341
num_objs 1
set01_V005_I01556
num_objs 0
set05_V000_I00239
num_objs 0
set00_V009_I00365
num_objs 4
set01_V002_I01613
num_objs 4
set00_V009_I00341
num_objs 4
set03_V009_I01139
num_objs 3
set05_V005_I00107
num_objs 3
set00_V000_I00500
num_objs 1
set03_V009_I01841
num_objs 4
set00_V000_I01742
num_objs 1
set05_V000_I00110
num_objs 2
set03_V009_I00311
num_objs 4
set00_V002_I00752
num_objs 2
set00_V006_I01598
num_objs 2
set03_V003_I00614
num_objs 2
set01_V001_I01673
num_objs 2
set05_V000_I00146
num_objs 3
set04_V002_I01700
num_objs 2
set02_V001_I01625
num_objs 1
set01_V004_I01073
num_objs 3
set04_V006_I00533
num_objs 1
set03_V010_I01016
num_objs 3
set02_V010_I00956
num_objs 1
set05_V009_I00995
num_objs 1
set01_V004_I01055
num_objs 3
set05_V000_I00524
num_objs 3
set00_V004_I01547
num_objs 0
set02_V011_I00893
num_objs 1
set05_V005_I00311
num_objs 2
set00_V001_I00713
num_objs 3
set03_V003_I01292
num_objs 2
set03_V007_I01505
num_objs 0
set03_V011_I00416
num_objs 5
set01_V004_I01211
num_objs 0
set00_V008_I01013
num_objs 1
set04_V001_I01610
num_objs 2
set00_V014_I01157
num_objs 3
set00_V014_I01349
num_objs 0
set05_V004_I01049
num_objs 0
set03_V005_I01220
num_objs 3
set00_V010_I01307
num_objs 3
set01_V003_I01328
num_objs 1
set00_V000_I01835
num_objs 1
set02_V010_I01607
num_objs 1
set00_V004_I00347
num_objs 2
set01_V003_I00869
num_objs 2
set01_V004_I00884
num_objs 2
set00_V010_I00869
num_objs 3
set01_V001_I00665
num_objs 3
set00_V013_I00431
num_objs 3
set03_V011_I00335
num_objs 5
set03_V008_I01673
num_objs 2
set03_V003_I00200
num_objs 1
set00_V000_I00977
num_objs 0
set00_V009_I01022
num_objs 1
set00_V014_I01049
num_objs 1
set02_V009_I01757
num_objs 1
set03_V003_I00725
num_objs 2
set00_V014_I01820
num_objs 2
set00_V007_I01535
num_objs 3
set00_V004_I00539
num_objs 1
set05_V005_I00113
num_objs 3
set04_V010_I00749
num_objs 0
set04_V010_I00737
num_objs 1
set02_V011_I01778
num_objs 2
set04_V011_I01562
num_objs 1
set05_V010_I01520
num_objs 1
set00_V013_I00470
num_objs 2
set04_V007_I01664
num_objs 1
set04_V010_I00866
num_objs 2
set04_V002_I01001
num_objs 2
set03_V001_I00161
num_objs 1
set01_V005_I01415
num_objs 0
set02_V008_I01286
num_objs 1
set00_V007_I00164
num_objs 1
set00_V010_I00635
num_objs 4
set01_V003_I01697
num_objs 3
set00_V011_I00488
num_objs 5
set04_V004_I01148
num_objs 3
set00_V000_I01826
num_objs 1
set02_V008_I01175
num_objs 0
set01_V002_I01247
num_objs 4
set00_V008_I01229
num_objs 2
set02_V010_I01676
num_objs 1
set00_V006_I00287
num_objs 3
set00_V014_I01430
num_objs 4
set00_V014_I00437
num_objs 5
set01_V003_I01709
num_objs 5
set02_V009_I01463
num_objs 1
set00_V002_I00590
num_objs 0
set00_V002_I00902
num_objs 5
set02_V011_I00326
num_objs 1
set00_V001_I01340
num_objs 3
set00_V004_I00353
num_objs 2
set00_V009_I01001
num_objs 4
set05_V002_I00569
num_objs 1
set02_V010_I00113
num_objs 1
set03_V003_I00329
num_objs 1
set04_V006_I01655
num_objs 1
set00_V011_I00176
num_objs 2
set01_V005_I01511
num_objs 0
set00_V009_I01244
num_objs 1
set05_V007_I01499
num_objs 1
set01_V002_I01427
num_objs 0
set00_V009_I01463
num_objs 2
set04_V005_I01151
num_objs 1
set03_V003_I01535
num_objs 2
set02_V010_I01160
num_objs 1
set04_V008_I00545
num_objs 1
set03_V005_I01700
num_objs 1
set05_V005_I00236
num_objs 1
set05_V012_I01112
num_objs 1
set00_V001_I00401
num_objs 2
set00_V011_I00614
num_objs 3
set03_V003_I00605
num_objs 2
set03_V011_I00167
num_objs 3
set04_V006_I01634
num_objs 2
set02_V011_I00692
num_objs 1
set05_V002_I00482
num_objs 1
set03_V009_I01613
num_objs 2
set00_V013_I00215
num_objs 4
set00_V014_I00833
num_objs 5
set05_V010_I00659
num_objs 0
set00_V007_I00881
num_objs 3
set00_V006_I01259
num_objs 5
set05_V000_I00584
num_objs 1
set01_V005_I01499
num_objs 0
set05_V010_I00398
num_objs 2
set00_V002_I01034
num_objs 0
set00_V000_I01727
num_objs 1
set04_V004_I00506
num_objs 3
set01_V005_I01760
num_objs 0
set01_V000_I00074
num_objs 3
set04_V002_I00905
num_objs 1
set02_V009_I01274
num_objs 1
set04_V010_I00815
num_objs 1
set00_V012_I00809
num_objs 5
set05_V005_I00596
num_objs 1
set00_V012_I01367
num_objs 0
set00_V009_I01460
num_objs 2
set00_V009_I00695
num_objs 4
set03_V005_I00701
num_objs 1
set04_V003_I00098
num_objs 0
set01_V002_I01466
num_objs 0
set00_V004_I01517
num_objs 0
set04_V001_I01583
num_objs 2
set04_V001_I01646
num_objs 3
set04_V002_I01271
num_objs 2
set05_V005_I00857
num_objs 2
set03_V006_I01742
num_objs 1
set00_V006_I00746
num_objs 0
set02_V001_I01517
num_objs 1
set00_V014_I00320
num_objs 4
set00_V013_I00197
num_objs 4
set03_V009_I01307
num_objs 0
set04_V003_I00371
num_objs 1
set05_V005_I00158
num_objs 0
set04_V003_I01631
num_objs 1
set04_V003_I00272
num_objs 1
set05_V004_I00281
num_objs 1
set00_V006_I00113
num_objs 3
set05_V009_I00737
num_objs 1
set00_V006_I00671
num_objs 2
set00_V007_I01877
num_objs 7
set00_V001_I00188
num_objs 2
set00_V010_I01487
num_objs 4
set04_V001_I00041
num_objs 1
set05_V005_I01220
num_objs 1
set04_V002_I01013
num_objs 2
set00_V000_I00281
num_objs 4
set01_V003_I00458
num_objs 4
set02_V001_I01628
num_objs 1
set03_V007_I00311
num_objs 1
set04_V003_I01451
num_objs 3
set03_V008_I00377
num_objs 19
set03_V008_I01493
num_objs 2
set02_V010_I00764
num_objs 3
set04_V007_I01289
num_objs 0
set03_V008_I01085
num_objs 1
set00_V011_I00056
num_objs 4
set00_V007_I01874
num_objs 7
set00_V000_I00926
num_objs 0
set03_V003_I00161
num_objs 2
set05_V010_I00695
num_objs 1
set02_V009_I01754
num_objs 1
set00_V009_I00644
num_objs 2
set00_V010_I00500
num_objs 4
set01_V003_I00092
num_objs 5
set05_V009_I00731
num_objs 1
set05_V005_I00359
num_objs 1
set04_V010_I00944
num_objs 1
set02_V010_I01439
num_objs 0
set00_V008_I01544
num_objs 1
set00_V001_I00113
num_objs 3
set04_V002_I00725
num_objs 3
set02_V009_I00554
num_objs 2
set01_V003_I01367
num_objs 1
set04_V008_I01316
num_objs 1
set05_V007_I01202
num_objs 1
set03_V004_I00200
num_objs 1
set01_V004_I01505
num_objs 2
set00_V007_I00560
num_objs 5
set03_V001_I00806
num_objs 1
set01_V001_I01226
num_objs 10
set00_V011_I00002
num_objs 6
set04_V004_I01046
num_objs 2
set00_V010_I00713
num_objs 2
set00_V006_I00434
num_objs 2
set01_V001_I00413
num_objs 4
set03_V010_I01013
num_objs 3
set03_V002_I01460
num_objs 1
set04_V002_I01109
num_objs 1
set00_V009_I01109
num_objs 0
set04_V007_I00296
num_objs 1
set02_V010_I00824
num_objs 2
set00_V000_I01637
num_objs 1
set05_V003_I01715
num_objs 0
set05_V000_I00599
num_objs 1
set01_V004_I00680
num_objs 1
set00_V000_I01760
num_objs 1
set03_V005_I01694
num_objs 1
set05_V009_I00896
num_objs 1
set03_V008_I01328
num_objs 3
set02_V008_I00821
num_objs 1
set05_V011_I01295
num_objs 2
set00_V006_I01877
num_objs 0
set00_V007_I00329
num_objs 2
set04_V002_I01637
num_objs 2
set04_V001_I01784
num_objs 1
set03_V005_I00737
num_objs 1
set04_V000_I00593
num_objs 3
set01_V004_I00749
num_objs 2
set05_V000_I00674
num_objs 1
set04_V011_I01109
num_objs 0
set03_V005_I00662
num_objs 1
set00_V014_I01232
num_objs 4
set05_V000_I01535
num_objs 1
set02_V011_I01613
num_objs 2
set04_V008_I01427
num_objs 1
set04_V005_I00983
num_objs 2
set04_V002_I01526
num_objs 3
set05_V005_I01265
num_objs 1
set05_V005_I00320
num_objs 2
set02_V009_I01781
num_objs 1
set00_V014_I01502
num_objs 3
set05_V010_I01550
num_objs 1
set05_V011_I01451
num_objs 3
set03_V010_I01784
num_objs 3
set00_V001_I01139
num_objs 1
set04_V001_I01694
num_objs 2
set01_V003_I00707
num_objs 2
set04_V006_I01556
num_objs 1
set04_V002_I00881
num_objs 1
set01_V003_I01661
num_objs 2
set03_V011_I00218
num_objs 3
set03_V009_I01316
num_objs 0
set00_V001_I01403
num_objs 3
set00_V013_I00800
num_objs 1
set05_V012_I01124
num_objs 1
set01_V005_I00962
num_objs 3
set04_V007_I01193
num_objs 1
set01_V002_I00515
num_objs 7
set00_V007_I00602
num_objs 3
set04_V002_I01508
num_objs 3
set00_V000_I00815
num_objs 0
set00_V012_I00656
num_objs 0
set03_V004_I00491
num_objs 1
set00_V000_I01523
num_objs 1
set02_V008_I00581
num_objs 1
set02_V010_I01112
num_objs 1
set03_V008_I00365
num_objs 18
set01_V002_I01181
num_objs 2
set00_V000_I00755
num_objs 2
set00_V002_I00488
num_objs 0
set03_V008_I00107
num_objs 9
set04_V005_I01625
num_objs 2
set01_V000_I00542
num_objs 2
set01_V000_I01532
num_objs 4
set04_V010_I00917
num_objs 2
set01_V000_I01325
num_objs 4
set05_V010_I00476
num_objs 1
set02_V009_I01646
num_objs 1
set05_V000_I00158
num_objs 3
set01_V000_I00068
num_objs 3
set04_V005_I01106
num_objs 1
set02_V007_I00227
num_objs 1
set00_V014_I01004
num_objs 3
set01_V005_I01562
num_objs 0
set02_V011_I00707
num_objs 1
set01_V001_I00203
num_objs 2
set00_V004_I00965
num_objs 3
set01_V001_I01583
num_objs 7
set00_V002_I00386
num_objs 0
set00_V014_I00314
num_objs 5
set00_V013_I01673
num_objs 0
set01_V000_I01406
num_objs 4
set02_V011_I01505
num_objs 2
set02_V009_I00767
num_objs 2
set04_V001_I01604
num_objs 2
set00_V010_I01316
num_objs 2
set03_V010_I01523
num_objs 3
set04_V008_I01019
num_objs 1
set02_V010_I00734
num_objs 2
set01_V004_I01445
num_objs 1
set01_V000_I00374
num_objs 3
set04_V004_I00479
num_objs 1
set03_V005_I00692
num_objs 1
set00_V009_I00677
num_objs 2
set00_V006_I00665
num_objs 2
set00_V007_I00632
num_objs 3
set00_V011_I01574
num_objs 0
set00_V006_I00104
num_objs 2
set01_V002_I00611
num_objs 7
set03_V005_I01541
num_objs 1
set02_V010_I00701
num_objs 2
set04_V003_I00323
num_objs 1
set03_V009_I01265
num_objs 2
set03_V011_I00281
num_objs 4
set03_V009_I00008
num_objs 2
set02_V010_I01025
num_objs 1
set03_V003_I00842
num_objs 2
set00_V007_I01619
num_objs 2
set00_V006_I00131
num_objs 3
set03_V003_I00902
num_objs 2
set01_V005_I01448
num_objs 0
set02_V011_I00641
num_objs 2
set03_V011_I00656
num_objs 3
set03_V005_I00794
num_objs 1
set04_V004_I00110
num_objs 1
set02_V010_I00533
num_objs 2
set00_V008_I00014
num_objs 4
set03_V008_I01559
num_objs 4
set03_V009_I00794
num_objs 2
set02_V009_I00491
num_objs 1
set04_V006_I01646
num_objs 1
set02_V009_I00356
num_objs 2
set00_V014_I00581
num_objs 6
set01_V000_I01094
num_objs 3
set01_V002_I00017
num_objs 3
set05_V010_I00056
num_objs 1
set00_V014_I00758
num_objs 2
set01_V001_I01145
num_objs 3
set04_V001_I00152
num_objs 1
set00_V008_I01409
num_objs 1
set02_V003_I00140
num_objs 1
set01_V005_I00311
num_objs 3
set03_V009_I00899
num_objs 0
set00_V012_I01634
num_objs 1
set01_V001_I00857
num_objs 1
set00_V012_I00056
num_objs 1
set04_V004_I00548
num_objs 3
set05_V001_I00161
num_objs 1
set05_V003_I01169
num_objs 2
set04_V005_I00239
num_objs 0
set05_V003_I01814
num_objs 0
set01_V005_I01622
num_objs 0
set04_V005_I00782
num_objs 1
set00_V009_I01514
num_objs 3
set02_V010_I00953
num_objs 1
set03_V009_I01526
num_objs 2
set04_V002_I01778
num_objs 1
set04_V000_I00722
num_objs 3
set04_V007_I01460
num_objs 1
set01_V000_I00980
num_objs 0
set01_V002_I01712
num_objs 5
set04_V011_I01778
num_objs 1
set02_V011_I00398
num_objs 2
set04_V002_I01445
num_objs 2
set00_V014_I01493
num_objs 5
set01_V003_I00914
num_objs 2
set03_V004_I00452
num_objs 1
set03_V012_I00857
num_objs 1
set05_V007_I01625
num_objs 0
set05_V011_I00992
num_objs 8
set05_V010_I01631
num_objs 1
set01_V000_I01304
num_objs 3
set05_V011_I00893
num_objs 9
set04_V005_I01472
num_objs 1
set03_V005_I00791
num_objs 1
set03_V010_I01346
num_objs 1
set02_V011_I00389
num_objs 0
set01_V003_I00197
num_objs 7
set02_V001_I00086
num_objs 0
set00_V009_I01547
num_objs 3
set05_V000_I00416
num_objs 2
set01_V001_I01346
num_objs 10
set04_V001_I00113
num_objs 1
set00_V002_I00803
num_objs 4
set04_V003_I01334
num_objs 3
set04_V002_I00614
num_objs 1
set00_V010_I01421
num_objs 4
set02_V001_I01571
num_objs 2
set02_V011_I00773
num_objs 0
set04_V011_I00983
num_objs 2
set01_V002_I01718
num_objs 5
set00_V006_I01448
num_objs 3
set00_V001_I01046
num_objs 12
set04_V003_I00506
num_objs 0
set00_V001_I00245
num_objs 5
set00_V000_I00809
num_objs 0
set04_V002_I01265
num_objs 2
set00_V014_I01643
num_objs 4
set02_V008_I00512
num_objs 1
set04_V005_I01115
num_objs 1
set01_V005_I00290
num_objs 1
set01_V002_I01796
num_objs 5
set03_V011_I00464
num_objs 5
set00_V014_I00572
num_objs 5
set00_V002_I00224
num_objs 2
set00_V010_I00023
num_objs 4
set00_V006_I01103
num_objs 10
set03_V004_I00203
num_objs 1
set00_V007_I01880
num_objs 7
set01_V000_I01157
num_objs 4
set00_V000_I01073
num_objs 0
set05_V002_I01514
num_objs 1
set00_V001_I00644
num_objs 6
set05_V000_I01583
num_objs 1
set04_V004_I01151
num_objs 3
set04_V004_I01856
num_objs 1
set05_V005_I00851
num_objs 2
set03_V005_I00857
num_objs 1
set05_V011_I01331
num_objs 1
set00_V008_I00728
num_objs 3
set01_V003_I00047
num_objs 4
set01_V002_I01271
num_objs 4
set04_V004_I01070
num_objs 2
set01_V002_I00518
num_objs 7
set01_V001_I00911
num_objs 1
set02_V009_I00839
num_objs 1
set01_V004_I01085
num_objs 3
set04_V002_I00047
num_objs 1
set00_V003_I00338
num_objs 1
set04_V005_I00341
num_objs 1
set05_V012_I01013
num_objs 1
set01_V001_I01718
num_objs 2
set03_V010_I01430
num_objs 2
set05_V011_I00830
num_objs 7
set03_V009_I01568
num_objs 2
set00_V010_I00269
num_objs 2
set04_V010_I00494
num_objs 1
set04_V004_I01859
num_objs 0
set05_V012_I01208
num_objs 1
set02_V008_I00806
num_objs 1
set00_V013_I01538
num_objs 3
set00_V001_I00350
num_objs 5
set02_V010_I00353
num_objs 1
set05_V011_I00626
num_objs 4
set01_V003_I00689
num_objs 3
set00_V012_I00176
num_objs 1
set03_V008_I01265
num_objs 2
set03_V008_I00740
num_objs 3
set00_V001_I00341
num_objs 5
set00_V000_I00266
num_objs 5
set01_V005_I01754
num_objs 0
set04_V003_I01481
num_objs 2
set00_V010_I00131
num_objs 4
set00_V009_I01424
num_objs 1
set00_V001_I01142
num_objs 5
set04_V005_I01670
num_objs 0
set03_V003_I00056
num_objs 2
set04_V006_I00554
num_objs 1
set00_V003_I00500
num_objs 0
set00_V014_I01142
num_objs 3
set02_V010_I01829
num_objs 0
set00_V009_I01013
num_objs 3
set00_V000_I00245
num_objs 4
set00_V014_I01175
num_objs 4
set02_V011_I01361
num_objs 2
set00_V004_I01061
num_objs 1
set01_V004_I01247
num_objs 0
set04_V005_I00902
num_objs 1
set02_V009_I01223
num_objs 2
set00_V006_I01304
num_objs 5
set04_V002_I00053
num_objs 1
set02_V010_I00134
num_objs 1
set00_V012_I00017
num_objs 0
set03_V011_I00779
num_objs 1
set02_V009_I01790
num_objs 1
set00_V013_I01148
num_objs 4
set03_V008_I01040
num_objs 1
set03_V006_I01715
num_objs 1
set02_V010_I00359
num_objs 1
set04_V002_I00128
num_objs 0
set03_V003_I01118
num_objs 2
set04_V005_I00770
num_objs 1
set04_V010_I00956
num_objs 1
set03_V011_I00596
num_objs 4
set00_V006_I01433
num_objs 3
set01_V000_I01664
num_objs 3
set03_V004_I00191
num_objs 1
set05_V000_I01658
num_objs 1
set01_V003_I00821
num_objs 2
set03_V009_I00950
num_objs 4
set01_V002_I00212
num_objs 7
set03_V005_I00563
num_objs 3
set04_V005_I01010
num_objs 3
set04_V002_I01586
num_objs 2
set00_V006_I01253
num_objs 7
set02_V010_I00311
num_objs 1
set00_V014_I00236
num_objs 3
set03_V005_I00443
num_objs 2
set03_V005_I00683
num_objs 1
set00_V001_I00563
num_objs 2
set04_V000_I00671
num_objs 3
set04_V003_I01211
num_objs 3
set04_V002_I01211
num_objs 2
set03_V009_I01244
num_objs 3
set00_V014_I01217
num_objs 4
set04_V003_I00395
num_objs 1
set00_V012_I00593
num_objs 0
set00_V002_I00110
num_objs 1
set03_V008_I00065
num_objs 6
set05_V012_I01127
num_objs 1
set01_V003_I00725
num_objs 2
set00_V013_I00179
num_objs 4
set00_V007_I00554
num_objs 5
set00_V000_I00899
num_objs 0
set01_V003_I01535
num_objs 1
set02_V010_I01640
num_objs 1
set03_V010_I01835
num_objs 2
set05_V010_I00926
num_objs 2
set02_V009_I01694
num_objs 1
set02_V010_I01604
num_objs 1
set00_V008_I00584
num_objs 5
set04_V003_I01304
num_objs 4
set00_V011_I00086
num_objs 4
set00_V001_I01463
num_objs 4
set04_V003_I00047
num_objs 0
set00_V010_I01091
num_objs 1
set05_V007_I01160
num_objs 1
set03_V003_I00386
num_objs 1
set01_V002_I00395
num_objs 5
set00_V000_I00752
num_objs 2
set00_V001_I01235
num_objs 5
set05_V003_I01316
num_objs 2
set00_V013_I01049
num_objs 3
set03_V009_I00278
num_objs 3
set00_V001_I01136
num_objs 6
set01_V002_I00074
num_objs 3
set03_V005_I00614
num_objs 3
set05_V000_I01622
num_objs 1
set02_V003_I00149
num_objs 0
set02_V001_I01460
num_objs 1
set03_V008_I00602
num_objs 8
set01_V005_I00002
num_objs 2
set01_V001_I00893
num_objs 1
set04_V004_I01673
num_objs 3
set00_V001_I00386
num_objs 4
set02_V003_I00179
num_objs 0
set00_V006_I01037
num_objs 3
set02_V010_I00611
num_objs 2
set03_V008_I00305
num_objs 18
set04_V011_I01583
num_objs 1
set04_V011_I00989
num_objs 1
set05_V004_I00974
num_objs 1
set05_V000_I00455
num_objs 3
set01_V001_I00287
num_objs 3
set01_V001_I00659
num_objs 3
set01_V004_I00707
num_objs 2
set05_V002_I00101
num_objs 1
set01_V000_I01112
num_objs 4
set05_V000_I00662
num_objs 1
set01_V004_I01589
num_objs 0
set04_V005_I01574
num_objs 2
set02_V010_I01631
num_objs 1
set01_V001_I00845
num_objs 1
set00_V007_I00797
num_objs 2
set00_V013_I00359
num_objs 5
set04_V004_I00074
num_objs 1
set05_V010_I00869
num_objs 0
set00_V014_I01706
num_objs 2
set05_V003_I01556
num_objs 0
set00_V013_I01559
num_objs 7
set00_V001_I01583
num_objs 4
set02_V010_I00983
num_objs 1
set00_V004_I00896
num_objs 2
set03_V005_I00953
num_objs 1
set03_V008_I00281
num_objs 15
set03_V005_I01364
num_objs 1
set00_V012_I01589
num_objs 0
set01_V004_I01208
num_objs 0
set03_V010_I01610
num_objs 2
set04_V005_I01025
num_objs 3
set03_V008_I01733
num_objs 1
set01_V004_I00845
num_objs 3
set00_V001_I00806
num_objs 3
set05_V004_I00479
num_objs 2
set02_V011_I00701
num_objs 1
set03_V009_I00086
num_objs 5
set01_V002_I01313
num_objs 6
set00_V012_I00521
num_objs 2
set00_V004_I01328
num_objs 1
set01_V000_I01247
num_objs 3
set03_V003_I00872
num_objs 2
set02_V010_I00383
num_objs 1
set05_V005_I01082
num_objs 1
set02_V010_I01169
num_objs 0
set00_V012_I01388
num_objs 1
set00_V010_I01670
num_objs 1
set00_V013_I00020
num_objs 5
set05_V004_I00269
num_objs 0
set04_V003_I01544
num_objs 1
set03_V005_I00269
num_objs 0
set05_V009_I00863
num_objs 1
set03_V009_I00698
num_objs 2
set05_V004_I00458
num_objs 2
set04_V004_I00557
num_objs 3
set02_V011_I01739
num_objs 0
set03_V006_I01763
num_objs 1
set00_V001_I01613
num_objs 3
set04_V005_I00230
num_objs 1
set03_V010_I00140
num_objs 2
set03_V011_I00272
num_objs 4
set03_V011_I00665
num_objs 3
set03_V012_I00956
num_objs 1
set02_V010_I01649
num_objs 0
set00_V006_I01394
num_objs 4
set00_V007_I01340
num_objs 6
set00_V009_I00497
num_objs 2
set03_V009_I01247
num_objs 3
set00_V007_I01250
num_objs 8
set01_V004_I01370
num_objs 1
set00_V011_I01328
num_objs 4
set04_V007_I00905
num_objs 2
set01_V000_I00170
num_objs 1
set00_V012_I00110
num_objs 0
set05_V002_I00458
num_objs 1
set03_V008_I00587
num_objs 9
set05_V011_I01460
num_objs 3
set00_V013_I00776
num_objs 2
set00_V006_I01298
num_objs 5
set05_V012_I00299
num_objs 0
set01_V001_I01478
num_objs 11
set05_V011_I01619
num_objs 1
set03_V008_I00932
num_objs 1
set00_V008_I00476
num_objs 8
set00_V007_I01844
num_objs 5
set01_V005_I00503
num_objs 2
set04_V003_I00515
num_objs 0
set00_V014_I01424
num_objs 4
set04_V005_I01088
num_objs 1
set00_V002_I00731
num_objs 2
set02_V010_I01811
num_objs 1
set00_V002_I00950
num_objs 2
set03_V005_I00686
num_objs 1
set02_V011_I00833
num_objs 1
set05_V010_I00518
num_objs 1
set03_V005_I00317
num_objs 2
set00_V009_I01271
num_objs 1
set00_V009_I01421
num_objs 1
set01_V005_I01805
num_objs 0
set04_V006_I01601
num_objs 1
set00_V011_I01457
num_objs 4
set05_V007_I01430
num_objs 1
set00_V007_I00266
num_objs 6
set00_V003_I00452
num_objs 1
set02_V011_I00287
num_objs 0
set00_V002_I01055
num_objs 0
set00_V006_I00734
num_objs 1
set02_V010_I00728
num_objs 2
set03_V003_I00986
num_objs 2
set05_V004_I00896
num_objs 0
set05_V005_I01163
num_objs 1
set03_V006_I00119
num_objs 0
set02_V008_I01121
num_objs 0
set01_V005_I01484
num_objs 0
set01_V003_I01031
num_objs 2
set01_V005_I01679
num_objs 0
set00_V000_I00761
num_objs 2
set02_V010_I00851
num_objs 2
set00_V003_I00374
num_objs 1
set01_V003_I00296
num_objs 3
set04_V002_I01202
num_objs 2
set01_V004_I00467
num_objs 1
set00_V011_I00854
num_objs 0
set00_V007_I00236
num_objs 5
set05_V005_I00437
num_objs 1
set01_V000_I00344
num_objs 2
set05_V000_I00536
num_objs 3
set01_V004_I00260
num_objs 2
set00_V000_I01715
num_objs 2
set03_V011_I00917
num_objs 1
set02_V011_I01751
num_objs 2
set05_V007_I01727
num_objs 0
set01_V002_I00485
num_objs 5
set04_V005_I01541
num_objs 2
set01_V001_I00374
num_objs 4
set03_V002_I01508
num_objs 1
set00_V004_I00920
num_objs 2
set03_V011_I01163
num_objs 1
set00_V000_I01145
num_objs 0
set05_V003_I01340
num_objs 2
set01_V000_I01607
num_objs 3
set04_V004_I00788
num_objs 2
set00_V002_I00848
num_objs 11
set00_V013_I01271
num_objs 1
set03_V011_I01220
num_objs 1
set04_V003_I00134
num_objs 0
set00_V001_I00593
num_objs 1
set01_V002_I00410
num_objs 5
set05_V005_I00593
num_objs 1
set03_V008_I01139
num_objs 4
set00_V000_I00857
num_objs 0
set04_V002_I01016
num_objs 2
set04_V002_I01466
num_objs 2
set02_V009_I00758
num_objs 2
set00_V013_I00875
num_objs 1
set05_V003_I00974
num_objs 1
set04_V007_I00698
num_objs 2
set02_V008_I00800
num_objs 1
set03_V011_I00827
num_objs 2
set03_V005_I01007
num_objs 1
set05_V005_I00035
num_objs 3
set04_V007_I00782
num_objs 2
set03_V009_I01160
num_objs 2
set00_V012_I01346
num_objs 0
set02_V009_I01265
num_objs 1
set03_V003_I00944
num_objs 2
set02_V009_I00605
num_objs 2
set00_V002_I00728
num_objs 2
set03_V005_I01388
num_objs 1
set03_V008_I00611
num_objs 7
set00_V014_I01073
num_objs 2
set02_V009_I00575
num_objs 2
set00_V002_I00476
num_objs 0
set00_V002_I00311
num_objs 1
set01_V000_I01475
num_objs 5
set00_V008_I01538
num_objs 1
set00_V011_I01481
num_objs 3
set04_V004_I00752
num_objs 2
set05_V007_I01163
num_objs 1
set04_V005_I01694
num_objs 0
set01_V001_I01529
num_objs 7
set00_V014_I01448
num_objs 4
set00_V014_I00593
num_objs 5
set02_V009_I00479
num_objs 0
set01_V003_I01310
num_objs 1
set00_V010_I00413
num_objs 8
set01_V001_I00491
num_objs 3
set00_V013_I00857
num_objs 2
set03_V009_I01367
num_objs 1
set00_V011_I00179
num_objs 1
set04_V004_I01439
num_objs 1
set03_V005_I00341
num_objs 2
set02_V009_I00233
num_objs 2
set00_V006_I01367
num_objs 4
set05_V005_I00707
num_objs 1
set02_V011_I01511
num_objs 2
set00_V008_I00650
num_objs 3
set04_V003_I00425
num_objs 1
set04_V004_I01754
num_objs 2
set03_V009_I00338
num_objs 4
set00_V006_I01451
num_objs 3
set03_V002_I01544
num_objs 1
set00_V002_I00413
num_objs 0
set04_V004_I00641
num_objs 2
set05_V005_I00152
num_objs 0
set03_V011_I00578
num_objs 4
set03_V005_I00923
num_objs 1
set00_V013_I00896
num_objs 1
set01_V002_I00983
num_objs 1
set04_V011_I01028
num_objs 2
set01_V005_I00824
num_objs 2
set00_V006_I01709
num_objs 1
set03_V011_I01433
num_objs 2
set05_V007_I01538
num_objs 1
set04_V007_I00992
num_objs 2
set03_V004_I00608
num_objs 1
set00_V013_I00914
num_objs 1
set02_V009_I01424
num_objs 1
set03_V012_I01631
num_objs 1
set01_V004_I01340
num_objs 1
set05_V005_I00149
num_objs 0
set00_V002_I00227
num_objs 2
set02_V011_I00713
num_objs 1
set02_V010_I01418
num_objs 1
set02_V009_I00818
num_objs 2
set00_V014_I00641
num_objs 3
set04_V010_I00893
num_objs 2
set01_V000_I00224
num_objs 1
set02_V009_I00902
num_objs 1
set02_V008_I00809
num_objs 0
set00_V008_I00497
num_objs 4
set03_V008_I01721
num_objs 1
set00_V000_I01820
num_objs 0
set03_V005_I00596
num_objs 3
set00_V000_I01793
num_objs 1
set04_V003_I01577
num_objs 1
set03_V008_I00218
num_objs 12
set04_V001_I00161
num_objs 1
set04_V004_I01007
num_objs 2
set00_V009_I00698
num_objs 4
set00_V013_I00137
num_objs 5
set04_V002_I00131
num_objs 0
set04_V004_I00827
num_objs 2
set00_V008_I00998
num_objs 1
set00_V010_I01259
num_objs 6
set00_V010_I01415
num_objs 3
set00_V013_I00209
num_objs 2
set00_V013_I00278
num_objs 5
set00_V012_I01127
num_objs 0
set00_V011_I01208
num_objs 3
set02_V010_I00689
num_objs 2
set01_V001_I01643
num_objs 4
set00_V002_I00119
num_objs 0
set03_V005_I00326
num_objs 2
set04_V005_I00749
num_objs 1
set02_V009_I00746
num_objs 2
set00_V006_I00860
num_objs 2
set05_V012_I01226
num_objs 1
set01_V005_I01004
num_objs 3
set05_V000_I00371
num_objs 3
set04_V002_I00938
num_objs 1
set01_V001_I01457
num_objs 13
set00_V007_I00386
num_objs 6
set00_V008_I00374
num_objs 2
set05_V011_I01109
num_objs 3
set00_V007_I01892
num_objs 3
set00_V006_I00371
num_objs 4
set01_V002_I00470
num_objs 5
set00_V008_I00188
num_objs 1
set05_V007_I01472
num_objs 1
set03_V008_I01679
num_objs 1
set02_V010_I01043
num_objs 1
set02_V011_I01370
num_objs 2
set05_V005_I00119
num_objs 1
set05_V011_I00785
num_objs 5
set00_V008_I00506
num_objs 5
set00_V011_I01049
num_objs 10
set00_V006_I01010
num_objs 2
set04_V003_I00416
num_objs 1
set05_V001_I00422
num_objs 0
set00_V009_I00863
num_objs 2
set00_V010_I00545
num_objs 6
set01_V002_I00980
num_objs 2
set05_V011_I01454
num_objs 3
set03_V008_I00635
num_objs 6
set02_V011_I01781
num_objs 2
set04_V001_I01511
num_objs 1
set01_V005_I01070
num_objs 2
set02_V010_I00854
num_objs 2
set00_V009_I00629
num_objs 2
set00_V010_I00593
num_objs 5
set00_V004_I01031
num_objs 0
set03_V008_I00914
num_objs 1
set02_V010_I00599
num_objs 2
set00_V011_I00206
num_objs 1
set00_V008_I01052
num_objs 2
set04_V007_I01295
num_objs 1
set04_V007_I00677
num_objs 2
set05_V005_I00893
num_objs 1
set02_V007_I00464
num_objs 1
set01_V001_I00800
num_objs 1
set01_V000_I00605
num_objs 4
set00_V008_I01298
num_objs 1
set00_V008_I01094
num_objs 0
set00_V014_I00623
num_objs 4
set00_V010_I01574
num_objs 1
set00_V001_I01082
num_objs 9
set05_V010_I01058
num_objs 1
set01_V002_I01493
num_objs 0
set00_V010_I01496
num_objs 3
set01_V005_I00428
num_objs 4
set05_V002_I00578
num_objs 1
set01_V003_I00548
num_objs 2
set05_V002_I00494
num_objs 1
set01_V003_I00212
num_objs 7
set04_V002_I01040
num_objs 2
set04_V010_I00908
num_objs 2
set01_V003_I00971
num_objs 2
set00_V010_I01394
num_objs 4
set03_V003_I01484
num_objs 2
set01_V004_I00995
num_objs 1
set05_V005_I01031
num_objs 1
set00_V002_I00944
num_objs 2
set05_V002_I00686
num_objs 1
set03_V003_I01073
num_objs 2
set05_V011_I01433
num_objs 3
set05_V002_I00113
num_objs 1
set00_V004_I01532
num_objs 0
set05_V002_I00581
num_objs 1
set05_V012_I00422
num_objs 3
set02_V001_I01634
num_objs 1
set01_V000_I01415
num_objs 4
set01_V003_I00635
num_objs 2
set01_V004_I00605
num_objs 3
set00_V011_I01265
num_objs 3
set05_V000_I01727
num_objs 1
set02_V011_I01649
num_objs 0
set02_V009_I00401
num_objs 2
set05_V011_I01166
num_objs 5
set04_V007_I00854
num_objs 2
set03_V009_I00878
num_objs 2
set01_V003_I00818
num_objs 2
set05_V004_I00239
num_objs 1
set03_V008_I00200
num_objs 12
set02_V001_I01613
num_objs 1
set01_V000_I01535
num_objs 4
set05_V011_I00527
num_objs 1
set00_V001_I01007
num_objs 12
set04_V004_I01100
num_objs 2
set01_V000_I01064
num_objs 2
set04_V006_I00557
num_objs 1
set03_V011_I00467
num_objs 5
set02_V011_I00704
num_objs 1
set03_V003_I00698
num_objs 2
set02_V010_I01325
num_objs 1
set01_V005_I00011
num_objs 2
set00_V010_I01583
num_objs 1
set05_V010_I00422
num_objs 1
set01_V002_I00695
num_objs 6
set01_V000_I01640
num_objs 3
set03_V010_I01733
num_objs 3
set04_V008_I00620
num_objs 1
set02_V007_I00152
num_objs 1
set03_V006_I01769
num_objs 0
set01_V000_I00776
num_objs 1
set00_V007_I00626
num_objs 3
set02_V010_I01364
num_objs 1
set04_V003_I01250
num_objs 3
set02_V001_I01643
num_objs 1
set00_V011_I00224
num_objs 1
set02_V011_I01544
num_objs 2
set05_V005_I00740
num_objs 1
set03_V012_I00968
num_objs 1
set03_V003_I00977
num_objs 2
set01_V002_I01334
num_objs 6
set01_V000_I00665
num_objs 0
set02_V011_I01682
num_objs 2
set01_V001_I00596
num_objs 3
set01_V005_I00872
num_objs 2
set00_V008_I00617
num_objs 4
set05_V003_I01388
num_objs 2
set03_V005_I01802
num_objs 2
set03_V012_I01445
num_objs 3
set00_V008_I00821
num_objs 1
set05_V005_I00008
num_objs 3
set00_V000_I00323
num_objs 1
set00_V013_I01058
num_objs 2
set01_V005_I00713
num_objs 2
set00_V004_I01334
num_objs 1
set01_V001_I00380
num_objs 3
set01_V005_I01124
num_objs 4
set02_V009_I00422
num_objs 1
set04_V006_I00845
num_objs 2
set04_V008_I01421
num_objs 1
set02_V009_I00152
num_objs 2
set03_V008_I00221
num_objs 12
set04_V004_I01208
num_objs 3
set04_V008_I01025
num_objs 1
set02_V011_I01397
num_objs 2
set00_V004_I00395
num_objs 1
set05_V001_I00413
num_objs 0
set04_V005_I00956
num_objs 1
set04_V001_I00149
num_objs 0
set04_V010_I00392
num_objs 1
set00_V009_I00293
num_objs 6
set00_V001_I01775
num_objs 5
set00_V014_I00551
num_objs 5
set01_V005_I01409
num_objs 2
set00_V011_I00776
num_objs 1
set04_V000_I00908
num_objs 1
set00_V013_I01118
num_objs 4
set05_V000_I01646
num_objs 1
set01_V001_I00044
num_objs 2
set00_V009_I00320
num_objs 6
set03_V012_I01589
num_objs 1
set00_V002_I00329
num_objs 1
set00_V009_I01688
num_objs 0
set03_V011_I00395
num_objs 5
set02_V008_I01223
num_objs 1
set03_V005_I00719
num_objs 0
set00_V012_I00170
num_objs 1
set02_V009_I00812
num_objs 2
set00_V006_I00614
num_objs 4
set00_V013_I00746
num_objs 1
set00_V006_I01823
num_objs 0
set05_V010_I00515
num_objs 1
set00_V006_I00320
num_objs 4
set05_V005_I00653
num_objs 1
set03_V008_I00401
num_objs 18
set04_V003_I01403
num_objs 3
set03_V009_I01700
num_objs 3
set00_V009_I00842
num_objs 3
set00_V004_I01313
num_objs 1
set02_V003_I00272
num_objs 1
set00_V012_I01559
num_objs 0
set05_V000_I00224
num_objs 2
set01_V000_I00620
num_objs 3
set05_V003_I01310
num_objs 2
set02_V011_I01763
num_objs 2
set00_V001_I01127
num_objs 6
set00_V009_I01646
num_objs 3
set03_V008_I00302
num_objs 18
set00_V013_I00341
num_objs 5
set04_V004_I00221
num_objs 2
set00_V007_I00800
num_objs 3
set00_V012_I00575
num_objs 0
set04_V011_I01118
num_objs 2
set00_V000_I00101
num_objs 1
set05_V005_I00974
num_objs 1
set05_V000_I00275
num_objs 2
set00_V004_I01457
num_objs 1
set04_V004_I00608
num_objs 3
set02_V009_I01244
num_objs 2
set00_V007_I00362
num_objs 5
set04_V004_I01127
num_objs 3
set00_V011_I01043
num_objs 10
set04_V007_I01733
num_objs 1
set03_V005_I00704
num_objs 1
set02_V009_I01652
num_objs 1
set02_V009_I00155
num_objs 2
set00_V008_I01118
num_objs 0
set00_V000_I01757
num_objs 1
set02_V010_I00248
num_objs 1
set00_V010_I01226
num_objs 2
set01_V002_I01322
num_objs 6
set02_V009_I01400
num_objs 1
set03_V012_I01310
num_objs 4
set04_V011_I01790
num_objs 1
set05_V011_I01691
num_objs 1
set05_V008_I01811
num_objs 1
set00_V001_I00671
num_objs 3
set00_V013_I00119
num_objs 4
set03_V009_I00284
num_objs 3
set05_V003_I01085
num_objs 1
set03_V003_I01187
num_objs 2
set01_V002_I01616
num_objs 4
set00_V010_I00806
num_objs 4
set00_V009_I00182
num_objs 4
set03_V009_I00929
num_objs 2
set01_V005_I00347
num_objs 3
set01_V002_I01349
num_objs 5
set00_V001_I01424
num_objs 4
set03_V002_I01574
num_objs 1
set01_V005_I01652
num_objs 0
set00_V010_I01064
num_objs 0
set01_V000_I01103
num_objs 3
set02_V003_I00173
num_objs 1
set01_V003_I01559
num_objs 4
set01_V005_I01034
num_objs 3
set03_V003_I00212
num_objs 1
set00_V007_I00113
num_objs 1
set04_V002_I00080
num_objs 1
set05_V004_I00959
num_objs 1
set02_V007_I00236
num_objs 1
set03_V011_I00728
num_objs 1
set03_V006_I00053
num_objs 1
set01_V003_I01556
num_objs 1
set03_V009_I01610
num_objs 2
set00_V009_I01394
num_objs 0
set05_V009_I00887
num_objs 1
set03_V008_I00683
num_objs 3
set05_V009_I00941
num_objs 1
set05_V003_I01625
num_objs 0
set03_V009_I00833
num_objs 0
set01_V004_I00815
num_objs 3
set03_V002_I01463
num_objs 1
set05_V011_I00875
num_objs 9
set00_V014_I01796
num_objs 1
set01_V003_I00074
num_objs 5
set03_V003_I01406
num_objs 2
set00_V013_I00422
num_objs 3
set03_V005_I01754
num_objs 2
set04_V007_I00680
num_objs 2
set03_V005_I01313
num_objs 1
set05_V004_I00203
num_objs 3
set00_V013_I00953
num_objs 1
set00_V011_I00152
num_objs 2
set00_V014_I01391
num_objs 6
set00_V008_I00152
num_objs 2
set05_V002_I00545
num_objs 1
set00_V002_I00635
num_objs 0
set03_V008_I01364
num_objs 3
set02_V011_I01832
num_objs 2
set02_V011_I00323
num_objs 1
set01_V002_I01358
num_objs 1
set00_V000_I00086
num_objs 1
set00_V001_I00815
num_objs 3
set00_V012_I01433
num_objs 2
set00_V010_I01343
num_objs 5
set00_V004_I01082
num_objs 1
set00_V005_I00800
num_objs 1
set03_V010_I01481
num_objs 2
set02_V010_I00566
num_objs 2
set02_V009_I00371
num_objs 2
set00_V012_I00812
num_objs 3
set05_V000_I01502
num_objs 1
set00_V009_I00032
num_objs 2
set04_V005_I00833
num_objs 1
set00_V010_I01205
num_objs 2
set05_V000_I00512
num_objs 3
set02_V010_I00176
num_objs 1
set00_V008_I00710
num_objs 3
set01_V002_I00185
num_objs 7
set04_V002_I01811
num_objs 1
set04_V006_I01604
num_objs 1
set03_V010_I00977
num_objs 3
set04_V003_I01016
num_objs 4
set03_V007_I01508
num_objs 0
set03_V008_I00080
num_objs 7
set02_V008_I00527
num_objs 1
set01_V004_I00950
num_objs 3
set01_V001_I01328
num_objs 10
set00_V000_I01649
num_objs 0
set00_V012_I01514
num_objs 1
set04_V003_I00932
num_objs 1
set02_V011_I00638
num_objs 2
set05_V004_I00983
num_objs 1
set05_V003_I01007
num_objs 1
set00_V008_I00134
num_objs 4
set00_V001_I01766
num_objs 4
set00_V013_I00257
num_objs 4
set04_V005_I01448
num_objs 2
set04_V003_I01136
num_objs 3
set00_V002_I01181
num_objs 0
set04_V008_I00632
num_objs 1
set00_V009_I00728
num_objs 3
set04_V003_I00290
num_objs 1
set05_V007_I01184
num_objs 1
set00_V012_I00392
num_objs 0
set01_V000_I00920
num_objs 4
set00_V011_I01430
num_objs 3
set01_V002_I01727
num_objs 5
set03_V001_I00128
num_objs 1
set00_V004_I01175
num_objs 0
set02_V010_I00797
num_objs 2
set00_V001_I01193
num_objs 3
set00_V001_I01358
num_objs 2
set01_V000_I01547
num_objs 4
set03_V010_I00923
num_objs 1
set03_V012_I00866
num_objs 1
set04_V000_I00476
num_objs 1
set05_V005_I00407
num_objs 1
set03_V009_I00782
num_objs 2
set00_V002_I00398
num_objs 0
set05_V004_I00248
num_objs 1
set04_V006_I00659
num_objs 0
set05_V010_I00776
num_objs 1
set00_V004_I01400
num_objs 2
set05_V011_I00836
num_objs 7
set00_V010_I01019
num_objs 1
set03_V009_I00629
num_objs 2
set04_V007_I01742
num_objs 1
set04_V002_I01502
num_objs 2
set03_V003_I00548
num_objs 2
set02_V009_I00644
num_objs 2
set04_V002_I00077
num_objs 1
set05_V005_I00809
num_objs 1
set01_V000_I00998
num_objs 0
set02_V011_I00410
num_objs 2
set00_V013_I00290
num_objs 6
set01_V003_I00338
num_objs 3
set01_V005_I00779
num_objs 1
set03_V010_I01511
num_objs 2
set00_V009_I00701
num_objs 4
set05_V007_I01592
num_objs 0
set00_V009_I00017
num_objs 1
set05_V011_I00632
num_objs 4
set05_V000_I00143
num_objs 3
set05_V002_I00776
num_objs 1
set01_V004_I01304
num_objs 1
set05_V012_I01019
num_objs 1
set03_V011_I00587
num_objs 4
set00_V007_I00158
num_objs 1
set05_V000_I00188
num_objs 2
set04_V007_I00818
num_objs 2
set03_V009_I00623
num_objs 4
set03_V008_I00215
num_objs 12
set01_V003_I00587
num_objs 1
set00_V012_I00266
num_objs 3
set00_V012_I00707
num_objs 0
set00_V014_I00164
num_objs 1
set02_V010_I01064
num_objs 1
set00_V006_I01151
num_objs 5
set04_V002_I01247
num_objs 2
set00_V008_I01496
num_objs 3
set05_V005_I00878
num_objs 1
set00_V012_I01619
num_objs 0
set01_V000_I01031
num_objs 2
set00_V009_I01010
num_objs 3
set04_V008_I01532
num_objs 1
set00_V011_I00908
num_objs 2
set01_V005_I00149
num_objs 2
set00_V014_I00647
num_objs 3
set04_V004_I01322
num_objs 1
set05_V012_I00569
num_objs 1
set02_V001_I00119
num_objs 0
set03_V004_I00626
num_objs 1
set02_V009_I01226
num_objs 2
set05_V002_I01145
num_objs 2
set04_V007_I00341
num_objs 1
set00_V000_I00671
num_objs 1
set04_V004_I01016
num_objs 2
set01_V004_I01436
num_objs 1
set00_V006_I00464
num_objs 4
set01_V004_I01133
num_objs 4
set00_V000_I00299
num_objs 0
set04_V005_I01571
num_objs 2
set00_V000_I00869
num_objs 0
set00_V007_I00959
num_objs 3
set00_V010_I01067
num_objs 0
set02_V001_I00083
num_objs 0
set04_V010_I00824
num_objs 1
set02_V010_I00233
num_objs 1
set05_V012_I00731
num_objs 2
set04_V002_I01463
num_objs 2
set03_V008_I00290
num_objs 16
set04_V006_I00854
num_objs 2
set00_V008_I01394
num_objs 1
set00_V008_I00314
num_objs 0
set00_V001_I01673
num_objs 1
set03_V010_I00959
num_objs 1
set00_V000_I01556
num_objs 2
set03_V011_I00401
num_objs 5
set04_V001_I00083
num_objs 1
set00_V012_I00329
num_objs 1
set05_V001_I00332
num_objs 0
set04_V007_I01526
num_objs 1
set00_V002_I00692
num_objs 1
set00_V009_I00545
num_objs 2
set01_V001_I00689
num_objs 3
set02_V011_I00794
num_objs 0
set03_V009_I00452
num_objs 3
set05_V012_I00443
num_objs 3
set05_V007_I01250
num_objs 1
set04_V007_I00452
num_objs 1
set00_V010_I00212
num_objs 3
set05_V002_I00143
num_objs 1
set03_V005_I00983
num_objs 1
set00_V009_I01049
num_objs 0
set00_V013_I00644
num_objs 3
set04_V005_I00335
num_objs 1
set04_V007_I01019
num_objs 1
set03_V008_I00443
num_objs 19
set00_V009_I00803
num_objs 2
set00_V011_I00629
num_objs 3
set02_V009_I01289
num_objs 0
set00_V014_I01352
num_objs 6
set00_V012_I00092
num_objs 0
set05_V002_I00530
num_objs 1
set00_V004_I01118
num_objs 1
set02_V010_I00062
num_objs 0
set04_V004_I00614
num_objs 2
set02_V010_I01634
num_objs 1
set00_V010_I00953
num_objs 1
set05_V012_I00692
num_objs 1
set04_V002_I01541
num_objs 2
set05_V011_I01304
num_objs 2
set00_V000_I00695
num_objs 1
set04_V008_I01007
num_objs 1
set01_V005_I01247
num_objs 1
set00_V000_I01796
num_objs 1
set01_V003_I00044
num_objs 4
set00_V014_I01859
num_objs 2
set01_V004_I00206
num_objs 0
set05_V007_I01544
num_objs 0
set01_V005_I00518
num_objs 2
set03_V009_I01022
num_objs 3
set01_V002_I00077
num_objs 3
set00_V006_I00566
num_objs 4
set03_V010_I01613
num_objs 2
set01_V005_I00083
num_objs 2
set01_V003_I01049
num_objs 4
set04_V006_I01592
num_objs 1
set01_V005_I01241
num_objs 1
set05_V010_I01049
num_objs 0
set00_V006_I00818
num_objs 3
set00_V013_I00008
num_objs 4
set00_V010_I00266
num_objs 3
set03_V003_I00338
num_objs 1
set00_V009_I00560
num_objs 2
set00_V007_I00521
num_objs 4
set03_V011_I00635
num_objs 3
set01_V005_I00599
num_objs 2
set03_V003_I00179
num_objs 1
set00_V007_I00818
num_objs 3
set04_V007_I01646
num_objs 1
set00_V004_I00137
num_objs 1
set00_V007_I00083
num_objs 1
set01_V000_I00467
num_objs 1
set05_V003_I01295
num_objs 2
set04_V010_I00500
num_objs 1
set03_V005_I00653
num_objs 2
set01_V004_I00164
num_objs 1
set01_V004_I00959
num_objs 7
set00_V013_I01211
num_objs 1
set03_V006_I01757
num_objs 1
set03_V005_I01514
num_objs 1
set03_V009_I01199
num_objs 1
set00_V010_I01298
num_objs 3
set04_V002_I00671
num_objs 2
set03_V008_I01373
num_objs 3
set03_V009_I00389
num_objs 0
set00_V002_I00869
num_objs 9
set00_V001_I01553
num_objs 3
set01_V002_I01565
num_objs 2
set04_V002_I01376
num_objs 3
set05_V010_I00956
num_objs 1
set00_V006_I00584
num_objs 5
set03_V005_I01034
num_objs 1
set00_V013_I00149
num_objs 3
set03_V009_I01202
num_objs 3
set04_V002_I00623
num_objs 1
set00_V013_I01232
num_objs 1
set00_V014_I01376
num_objs 7
set05_V011_I01253
num_objs 3
set00_V007_I00341
num_objs 6
set05_V005_I01112
num_objs 1
set01_V003_I00998
num_objs 1
set04_V002_I00125
num_objs 0
set03_V005_I01577
num_objs 1
set05_V005_I00125
num_objs 3
set01_V000_I00140
num_objs 1
set00_V011_I01106
num_objs 7
set00_V012_I01655
num_objs 1
set00_V002_I00365
num_objs 1
set05_V005_I00245
num_objs 1
set00_V004_I01478
num_objs 0
set03_V004_I00473
num_objs 1
set00_V014_I00011
num_objs 4
set05_V011_I01571
num_objs 1
set01_V000_I00452
num_objs 2
set00_V010_I00317
num_objs 3
set00_V000_I01304
num_objs 1
set04_V006_I00875
num_objs 2
set03_V010_I01676
num_objs 4
set00_V007_I01073
num_objs 4
set03_V012_I01358
num_objs 4
set01_V001_I00692
num_objs 3
set01_V005_I00275
num_objs 1
set04_V000_I00938
num_objs 1
set01_V003_I00605
num_objs 1
set03_V010_I01352
num_objs 2
set05_V000_I00752
num_objs 1
set02_V010_I01220
num_objs 1
set02_V001_I00152
num_objs 0
set00_V001_I01028
num_objs 13
set05_V011_I01214
num_objs 3
set04_V003_I00503
num_objs 0
set03_V009_I01034
num_objs 6
set05_V010_I00110
num_objs 1
set04_V003_I00191
num_objs 0
set03_V004_I00488
num_objs 1
set00_V000_I01679
num_objs 2
set00_V001_I00272
num_objs 5
set00_V000_I01673
num_objs 2
set04_V006_I00671
num_objs 3
set00_V009_I01250
num_objs 1
set04_V011_I01046
num_objs 2
set00_V007_I01436
num_objs 4
set03_V005_I01226
num_objs 2
set05_V003_I01805
num_objs 0
set00_V011_I00917
num_objs 3
set05_V011_I01187
num_objs 4
set03_V009_I01475
num_objs 1
set05_V010_I01562
num_objs 1
set00_V008_I00713
num_objs 3
set05_V010_I00584
num_objs 1
set00_V003_I00173
num_objs 2
set02_V011_I01598
num_objs 2
set03_V003_I00182
num_objs 1
set00_V013_I01442
num_objs 4
set05_V010_I00533
num_objs 1
set03_V008_I01151
num_objs 1
set05_V004_I00230
num_objs 2
set03_V009_I00710
num_objs 2
set00_V012_I00971
num_objs 5
set04_V003_I01418
num_objs 3
set00_V003_I00116
num_objs 2
set01_V003_I00695
num_objs 2
set05_V004_I00467
num_objs 2
set05_V011_I01706
num_objs 1
set02_V009_I00803
num_objs 2
set00_V009_I01046
num_objs 1
set01_V005_I01751
num_objs 0
set00_V012_I00449
num_objs 4
set00_V002_I01241
num_objs 0
set01_V005_I01538
num_objs 0
set00_V006_I01511
num_objs 2
set01_V003_I00782
num_objs 2
set00_V010_I00200
num_objs 4
set00_V006_I01505
num_objs 2
set04_V006_I00518
num_objs 1
set05_V000_I00338
num_objs 3
set00_V007_I00677
num_objs 2
set03_V005_I00977
num_objs 1
set00_V000_I00482
num_objs 1
set01_V001_I00530
num_objs 3
set00_V012_I01010
num_objs 2
set00_V001_I00035
num_objs 2
set00_V014_I01742
num_objs 1
set04_V000_I00881
num_objs 1
set00_V013_I00374
num_objs 4
set03_V004_I00089
num_objs 0
set00_V010_I01607
num_objs 0
set00_V008_I01325
num_objs 1
set00_V010_I01253
num_objs 3
set00_V001_I01166
num_objs 4
set00_V000_I00947
num_objs 0
set03_V004_I00620
num_objs 1
set05_V011_I01100
num_objs 5
set04_V010_I00692
num_objs 1
set00_V011_I01301
num_objs 5
set00_V014_I01718
num_objs 2
set00_V006_I00704
num_objs 2
set05_V007_I01232
num_objs 1
set05_V007_I01775
num_objs 0
set05_V003_I01757
num_objs 0
set00_V010_I00632
num_objs 4
set00_V001_I00857
num_objs 3
set01_V002_I01268
num_objs 4
set00_V013_I01553
num_objs 4
set02_V003_I00326
num_objs 1
set03_V002_I01442
num_objs 1
set00_V014_I01646
num_objs 4
set05_V007_I01763
num_objs 0
set00_V014_I01649
num_objs 3
set05_V005_I00863
num_objs 2
set05_V005_I00479
num_objs 2
set00_V004_I00182
num_objs 1
set03_V011_I00875
num_objs 2
set02_V011_I00902
num_objs 1
set00_V013_I01079
num_objs 3
set00_V004_I00944
num_objs 2
set00_V012_I01502
num_objs 1
set00_V012_I00161
num_objs 1
set00_V011_I01505
num_objs 4
set00_V007_I00326
num_objs 6
set01_V005_I00551
num_objs 2
set04_V003_I00758
num_objs 1
set04_V003_I00929
num_objs 0
set01_V004_I01493
num_objs 2
set02_V003_I00176
num_objs 1
set04_V007_I00719
num_objs 0
set00_V000_I01676
num_objs 2
set02_V010_I01496
num_objs 2
set00_V002_I01028
num_objs 0
set05_V000_I00212
num_objs 2
set00_V007_I00584
num_objs 4
set05_V008_I01820
num_objs 1
set02_V009_I00656
num_objs 2
set05_V011_I01259
num_objs 2
set00_V011_I00794
num_objs 1
set02_V011_I01760
num_objs 2
set01_V005_I01439
num_objs 0
set04_V002_I01421
num_objs 3
set03_V005_I00548
num_objs 3
set03_V012_I01373
num_objs 5
set02_V011_I00887
num_objs 1
set04_V003_I01625
num_objs 1
set01_V003_I01064
num_objs 1
set05_V005_I00698
num_objs 1
set01_V002_I01808
num_objs 4
set03_V008_I00548
num_objs 12
set04_V002_I01097
num_objs 2
set03_V012_I00932
num_objs 1
set04_V005_I00980
num_objs 2
set00_V001_I00656
num_objs 3
set00_V004_I01364
num_objs 1
set00_V008_I01220
num_objs 2
set00_V007_I00983
num_objs 3
set03_V006_I00017
num_objs 1
set04_V011_I01007
num_objs 2
set01_V001_I01019
num_objs 1
set00_V004_I00983
num_objs 3
set00_V001_I01502
num_objs 6
set05_V007_I01436
num_objs 1
set00_V012_I01184
num_objs 1
set05_V003_I01214
num_objs 3
set00_V009_I01103
num_objs 1
set02_V009_I01391
num_objs 1
set03_V005_I00587
num_objs 3
set03_V009_I00302
num_objs 3
set04_V002_I01433
num_objs 2
set03_V011_I00227
num_objs 3
set04_V011_I01025
num_objs 2
set04_V000_I00734
num_objs 3
set03_V012_I01523
num_objs 4
set00_V002_I00785
num_objs 3
set00_V000_I00884
num_objs 0
set04_V004_I00455
num_objs 3
set01_V003_I00806
num_objs 1
set01_V002_I01553
num_objs 1
set04_V004_I00194
num_objs 2
set00_V014_I01085
num_objs 2
set05_V011_I00908
num_objs 9
set00_V013_I00488
num_objs 2
set05_V003_I01571
num_objs 0
set00_V007_I00530
num_objs 4
set01_V000_I00308
num_objs 1
set00_V014_I00329
num_objs 2
set01_V000_I00635
num_objs 2
set01_V000_I00815
num_objs 1
set00_V012_I00788
num_objs 2
set03_V009_I00377
num_objs 4
set03_V009_I01838
num_objs 4
set00_V000_I01340
num_objs 1
set03_V003_I01277
num_objs 2
set03_V003_I00101
num_objs 2
set04_V004_I01097
num_objs 2
set05_V005_I00992
num_objs 1
set01_V000_I00101
num_objs 3
set02_V003_I00233
num_objs 1
set01_V004_I00296
num_objs 1
set00_V014_I00899
num_objs 1
set00_V014_I01781
num_objs 1
set00_V006_I00503
num_objs 3
set00_V013_I01688
num_objs 0
set00_V011_I01190
num_objs 4
set01_V002_I01586
num_objs 3
set05_V012_I00440
num_objs 3
set00_V001_I00629
num_objs 4
set00_V008_I01235
num_objs 2
set02_V003_I00290
num_objs 2
set05_V011_I00776
num_objs 4
set00_V009_I01568
num_objs 4
set00_V011_I00425
num_objs 5
set00_V010_I01046
num_objs 0
set04_V005_I00890
num_objs 1
set03_V003_I01157
num_objs 2
set03_V008_I01106
num_objs 1
set02_V011_I01388
num_objs 2
set00_V001_I00746
num_objs 3
set04_V004_I01340
num_objs 1
set01_V002_I01574
num_objs 2
set01_V004_I00806
num_objs 1
set05_V005_I00230
num_objs 1
set04_V006_I00728
num_objs 1
set00_V014_I00005
num_objs 4
set03_V004_I00197
num_objs 1
set01_V003_I00023
num_objs 4
set05_V004_I00431
num_objs 2
set04_V003_I00245
num_objs 1
set00_V004_I00851
num_objs 1
set00_V014_I00746
num_objs 2
set00_V003_I00377
num_objs 1
set03_V011_I01334
num_objs 1
set04_V011_I01490
num_objs 1
set00_V012_I00347
num_objs 0
set00_V009_I01685
num_objs 0
set00_V010_I00629
num_objs 5
set05_V005_I00500
num_objs 2
set01_V002_I01628
num_objs 4
set01_V003_I00278
num_objs 4
set01_V004_I01544
num_objs 2
set05_V005_I00293
num_objs 2
set04_V003_I01598
num_objs 1
set03_V007_I00320
num_objs 1
set03_V008_I00671
num_objs 4
set00_V014_I00482
num_objs 5
set04_V002_I01241
num_objs 2
set05_V011_I00578
num_objs 5
set03_V009_I00314
num_objs 4
set03_V006_I00104
num_objs 1
set03_V005_I01400
num_objs 1
set01_V005_I00929
num_objs 6
set02_V011_I01367
num_objs 2
set04_V003_I00491
num_objs 0
set05_V011_I00707
num_objs 2
set00_V004_I00833
num_objs 1
set00_V001_I01130
num_objs 6
set01_V001_I01604
num_objs 3
set04_V003_I01181
num_objs 3
set04_V002_I00746
num_objs 2
set04_V011_I00368
num_objs 1
set03_V003_I01553
num_objs 2
set05_V011_I01148
num_objs 4
set01_V000_I01625
num_objs 3
set04_V005_I00242
num_objs 1
set04_V005_I00797
num_objs 1
set00_V000_I00359
num_objs 1
set04_V004_I01073
num_objs 2
set02_V010_I00980
num_objs 1
set04_V004_I01280
num_objs 1
set00_V013_I01229
num_objs 1
set05_V000_I01736
num_objs 1
set04_V008_I00587
num_objs 1
set01_V001_I00404
num_objs 4
set05_V005_I00305
num_objs 2
set00_V006_I00851
num_objs 1
set03_V009_I01580
num_objs 2
set00_V001_I00983
num_objs 8
set04_V005_I01112
num_objs 1
set02_V011_I00668
num_objs 2
set00_V009_I00767
num_objs 3
set04_V007_I01523
num_objs 1
set00_V011_I01115
num_objs 6
set05_V005_I00299
num_objs 1
set05_V005_I00683
num_objs 1
set04_V003_I01337
num_objs 3
set00_V012_I01541
num_objs 2
set00_V006_I01307
num_objs 5
set05_V001_I00167
num_objs 1
set00_V008_I00245
num_objs 0
set05_V012_I01199
num_objs 0
set05_V010_I01511
num_objs 1
set02_V001_I01451
num_objs 1
set03_V011_I00824
num_objs 2
set00_V012_I00542
num_objs 2
set03_V003_I01142
num_objs 2
set01_V005_I00578
num_objs 3
set03_V005_I00536
num_objs 3
set03_V003_I01391
num_objs 2
set05_V000_I00413
num_objs 2
set00_V007_I00899
num_objs 4
set01_V000_I01685
num_objs 2
set00_V001_I00953
num_objs 8
set03_V011_I00275
num_objs 4
set00_V001_I00356
num_objs 5
set03_V003_I01175
num_objs 2
set01_V005_I00245
num_objs 1
set02_V007_I00512
num_objs 1
set01_V002_I00428
num_objs 5
set05_V005_I00401
num_objs 1
set03_V003_I00752
num_objs 2
set04_V010_I01637
num_objs 2
set01_V000_I01028
num_objs 2
set04_V006_I00869
num_objs 0
set01_V004_I00212
num_objs 0
set00_V011_I01160
num_objs 4
set04_V005_I01223
num_objs 1
set00_V012_I01487
num_objs 1
set04_V010_I01538
num_objs 2
set00_V007_I00704
num_objs 1
set00_V014_I01754
num_objs 0
set00_V014_I01664
num_objs 4
set00_V002_I00698
num_objs 1
set05_V001_I00374
num_objs 0
set04_V003_I00545
num_objs 0
set05_V012_I00587
num_objs 0
set05_V005_I00272
num_objs 1
set00_V001_I00461
num_objs 1
set05_V005_I00263
num_objs 1
set05_V007_I01265
num_objs 1
set04_V011_I01022
num_objs 2
set00_V011_I00524
num_objs 5
set00_V014_I00377
num_objs 4
set03_V004_I00467
num_objs 1
set01_V003_I00275
num_objs 4
set01_V001_I00569
num_objs 2
set05_V011_I00575
num_objs 5
set04_V004_I00341
num_objs 0
set03_V007_I00299
num_objs 0
set04_V010_I01601
num_objs 2
set00_V008_I00056
num_objs 6
set04_V001_I00023
num_objs 1
set01_V003_I00323
num_objs 2
set05_V012_I00593
num_objs 0
set01_V003_I00749
num_objs 3
set00_V001_I00320
num_objs 5
set03_V005_I00875
num_objs 1
set02_V009_I01172
num_objs 2
set04_V011_I01079
num_objs 0
set02_V010_I01688
num_objs 1
set03_V011_I00614
num_objs 4
set04_V007_I00794
num_objs 2
set00_V013_I01676
num_objs 0
set04_V000_I00617
num_objs 3
set04_V003_I01229
num_objs 2
set01_V002_I00335
num_objs 7
set05_V012_I00251
num_objs 1
set04_V001_I01697
num_objs 2
set00_V002_I00155
num_objs 2
set01_V000_I01271
num_objs 3
set01_V005_I01166
num_objs 3
set02_V008_I01127
num_objs 0
set05_V004_I01013
num_objs 1
set04_V000_I00503
num_objs 2
set02_V003_I00350
num_objs 1
set00_V014_I00539
num_objs 5
set01_V003_I01580
num_objs 1
set01_V001_I01094
num_objs 1
set00_V007_I01100
num_objs 7
set03_V003_I00005
num_objs 2
set00_V011_I01196
num_objs 4
set02_V011_I01733
num_objs 2
set05_V002_I01133
num_objs 2
set00_V012_I01466
num_objs 3
set00_V002_I00566
num_objs 0
set03_V009_I01550
num_objs 2
set00_V010_I01148
num_objs 2
set04_V004_I00590
num_objs 3
set00_V009_I00185
num_objs 4
set01_V002_I00161
num_objs 7
set00_V004_I00341
num_objs 2
set05_V011_I01088
num_objs 6
set03_V005_I00722
num_objs 1
set00_V006_I00152
num_objs 3
set01_V000_I01376
num_objs 3
set00_V000_I00488
num_objs 1
set05_V003_I00986
num_objs 1
set04_V006_I00596
num_objs 1
set04_V010_I00698
num_objs 1
set05_V003_I01055
num_objs 1
set05_V011_I01115
num_objs 5
set03_V010_I01391
num_objs 2
set03_V009_I01535
num_objs 2
set05_V010_I01574
num_objs 1
set04_V010_I00761
num_objs 1
set02_V011_I01307
num_objs 1
set05_V003_I01691
num_objs 0
set00_V006_I00353
num_objs 4
set00_V007_I01319
num_objs 5
set00_V001_I00860
num_objs 3
set00_V011_I01187
num_objs 4
set04_V004_I00122
num_objs 1
set00_V009_I00977
num_objs 5
set05_V000_I00419
num_objs 1
set01_V005_I00881
num_objs 2
set02_V007_I00302
num_objs 1
set00_V000_I01580
num_objs 2
set00_V011_I00632
num_objs 3
set03_V003_I01316
num_objs 2
set00_V001_I01679
num_objs 1
set02_V010_I01616
num_objs 1
set01_V005_I00953
num_objs 3
set00_V009_I00122
num_objs 3
set03_V009_I01751
num_objs 4
set00_V008_I01385
num_objs 1
set05_V012_I00317
num_objs 1
set00_V006_I00122
num_objs 3
set00_V014_I00500
num_objs 5
set01_V003_I01292
num_objs 1
set05_V009_I00986
num_objs 1
set05_V005_I01226
num_objs 1
set00_V006_I01028
num_objs 2
set00_V004_I00794
num_objs 2
set03_V008_I00578
num_objs 10
set00_V013_I01313
num_objs 5
set00_V010_I00308
num_objs 4
set02_V011_I00854
num_objs 1
set02_V011_I01787
num_objs 2
set00_V013_I00101
num_objs 5
set01_V000_I01682
num_objs 2
set04_V007_I01310
num_objs 1
set00_V011_I01553
num_objs 0
set04_V008_I00563
num_objs 1
set02_V010_I01004
num_objs 1
set03_V003_I01499
num_objs 0
set00_V014_I00062
num_objs 4
set03_V003_I00188
num_objs 1
set04_V006_I00851
num_objs 2
set01_V004_I00251
num_objs 2
set05_V010_I00359
num_objs 0
set00_V011_I01334
num_objs 4
set03_V008_I01400
num_objs 3
set01_V001_I00065
num_objs 2
set01_V005_I00248
num_objs 1
set00_V001_I00668
num_objs 3
set05_V011_I01613
num_objs 1
set00_V001_I01454
num_objs 4
set01_V001_I01823
num_objs 1
set00_V012_I00503
num_objs 2
set00_V006_I00461
num_objs 4
set02_V009_I00254
num_objs 2
set00_V013_I00758
num_objs 1
set05_V012_I01178
num_objs 1
set04_V007_I01226
num_objs 1
set05_V003_I01385
num_objs 2
set03_V003_I01313
num_objs 2
set05_V003_I01547
num_objs 0
set04_V004_I01229
num_objs 2
set00_V003_I00131
num_objs 2
set04_V003_I00200
num_objs 0
set04_V000_I00650
num_objs 3
set01_V001_I00515
num_objs 4
set03_V002_I01403
num_objs 1
set00_V011_I00386
num_objs 3
set03_V005_I00854
num_objs 1
set04_V011_I01598
num_objs 1
set03_V005_I00755
num_objs 1
set05_V005_I01076
num_objs 1
set04_V010_I00767
num_objs 1
set00_V001_I01316
num_objs 4
set04_V005_I01481
num_objs 1
set04_V002_I01670
num_objs 2
set03_V008_I00614
num_objs 7
set00_V006_I01667
num_objs 0
set05_V000_I01595
num_objs 1
set00_V013_I01070
num_objs 2
set01_V004_I00833
num_objs 3
set03_V008_I01355
num_objs 3
set04_V002_I01703
num_objs 2
set03_V005_I01172
num_objs 2
set03_V003_I00890
num_objs 2
set02_V010_I00080
num_objs 1
set00_V008_I00695
num_objs 3
set04_V005_I00839
num_objs 1
set04_V005_I00044
num_objs 1
set05_V010_I00791
num_objs 1
set00_V013_I01652
num_objs 2
set00_V013_I01220
num_objs 1
set03_V008_I01466
num_objs 3
set04_V007_I00743
num_objs 2
set00_V011_I01490
num_objs 3
set04_V003_I01262
num_objs 3
set00_V001_I00854
num_objs 3
set05_V001_I00140
num_objs 1
set04_V002_I01679
num_objs 2
set03_V008_I01112
num_objs 1
set01_V003_I00500
num_objs 4
set04_V007_I01271
num_objs 1
set02_V009_I01610
num_objs 2
set05_V001_I00371
num_objs 0
set04_V003_I01796
num_objs 2
set00_V010_I00467
num_objs 7
set00_V006_I00308
num_objs 4
set03_V005_I01058
num_objs 1
set01_V001_I01646
num_objs 4
set03_V005_I00929
num_objs 1
set00_V007_I01175
num_objs 9
set03_V009_I00515
num_objs 3
set03_V003_I00083
num_objs 2
set02_V001_I01541
num_objs 1
set04_V006_I00695
num_objs 3
set05_V012_I01118
num_objs 1
set05_V000_I00518
num_objs 3
set02_V008_I01115
num_objs 0
set03_V012_I01469
num_objs 1
set03_V008_I00749
num_objs 11
set02_V008_I00890
num_objs 2
set02_V011_I00437
num_objs 1
set05_V010_I00032
num_objs 1
set04_V007_I01325
num_objs 1
set00_V005_I00863
num_objs 1
set00_V007_I01493
num_objs 4
set00_V001_I00269
num_objs 4
set00_V014_I01787
num_objs 1
set01_V003_I00722
num_objs 2
set04_V010_I00839
num_objs 2
set00_V007_I00935
num_objs 3
set00_V010_I01490
num_objs 3
set01_V002_I00242
num_objs 7
set05_V011_I01094
num_objs 6
set03_V008_I00011
num_objs 3
set01_V002_I01562
num_objs 2
set04_V007_I00773
num_objs 2
set04_V006_I00986
num_objs 1
set01_V003_I00770
num_objs 2
set00_V002_I00263
num_objs 2
set00_V013_I01592
num_objs 3
set03_V005_I00413
num_objs 2
set05_V010_I00716
num_objs 1
set02_V010_I00458
num_objs 1
set05_V002_I00758
num_objs 1
set05_V011_I00809
num_objs 1
set00_V000_I01808
num_objs 0
set02_V010_I01022
num_objs 1
set00_V012_I00803
num_objs 2
set00_V011_I00533
num_objs 4
set01_V002_I00578
num_objs 8
set01_V002_I01655
num_objs 4
set03_V001_I00803
num_objs 1
set05_V004_I01019
num_objs 0
set00_V012_I01667
num_objs 1
set00_V011_I01139
num_objs 10
set03_V002_I01634
num_objs 2
set04_V004_I00644
num_objs 2
set01_V001_I01301
num_objs 11
set04_V007_I01286
num_objs 1
set00_V006_I01184
num_objs 3
set03_V005_I01610
num_objs 1
set02_V009_I00521
num_objs 1
set03_V008_I01088
num_objs 1
set00_V014_I01127
num_objs 3
set01_V005_I00440
num_objs 4
set04_V002_I01436
num_objs 2
set00_V013_I00323
num_objs 6
set00_V008_I00986
num_objs 1
set01_V003_I00305
num_objs 3
set00_V001_I00959
num_objs 4
set00_V007_I00620
num_objs 3
set01_V002_I00122
num_objs 6
set02_V011_I00566
num_objs 2
set00_V010_I00089
num_objs 2
set00_V010_I00851
num_objs 3
set00_V007_I01583
num_objs 7
set01_V004_I00479
num_objs 1
set04_V007_I00407
num_objs 1
set04_V004_I01085
num_objs 2
set00_V010_I00857
num_objs 3
set03_V008_I00599
num_objs 15
set01_V001_I01655
num_objs 3
set04_V005_I00065
num_objs 1
set05_V000_I01391
num_objs 2
set05_V005_I00194
num_objs 0
set01_V004_I01526
num_objs 2
set03_V009_I00182
num_objs 5
set05_V000_I00497
num_objs 3
set02_V010_I01361
num_objs 1
set00_V002_I01184
num_objs 0
set03_V010_I01697
num_objs 3
set00_V013_I00623
num_objs 4
set03_V003_I00740
num_objs 2
set05_V007_I01595
num_objs 0
set04_V010_I00485
num_objs 1
set04_V010_I00554
num_objs 1
set00_V013_I00251
num_objs 4
set01_V003_I00683
num_objs 2
set02_V010_I00656
num_objs 2
set05_V002_I01472
num_objs 1
set03_V009_I01496
num_objs 2
set00_V011_I00563
num_objs 3
set04_V010_I00785
num_objs 1
set00_V002_I00896
num_objs 6
set01_V004_I00488
num_objs 1
set04_V011_I01169
num_objs 1
set05_V007_I01427
num_objs 1
set03_V004_I00554
num_objs 1
set04_V007_I00809
num_objs 0
set01_V002_I00176
num_objs 7
set02_V010_I00341
num_objs 1
set01_V003_I00923
num_objs 2
set04_V004_I01694
num_objs 2
set04_V005_I00794
num_objs 1
set02_V011_I00869
num_objs 0
set01_V003_I00248
num_objs 4
set04_V004_I00866
num_objs 2
set00_V012_I01517
num_objs 1
set00_V012_I01670
num_objs 1
set00_V002_I01214
num_objs 1
set03_V003_I01115
num_objs 2
set00_V010_I00527
num_objs 4
set03_V005_I00386
num_objs 2
set00_V000_I01718
num_objs 2
set03_V008_I00695
num_objs 3
set00_V009_I01469
num_objs 6
set05_V002_I00158
num_objs 1
set04_V006_I01124
num_objs 1
set03_V009_I01349
num_objs 1
set04_V008_I01040
num_objs 1
set03_V009_I00113
num_objs 5
set01_V001_I01550
num_objs 9
set01_V002_I00701
num_objs 6
set04_V000_I00563
num_objs 3
set05_V011_I00788
num_objs 5
set02_V008_I01838
num_objs 0
set01_V000_I01262
num_objs 3
set05_V005_I00221
num_objs 0
set01_V001_I01103
num_objs 1
set00_V004_I00197
num_objs 1
set05_V003_I01037
num_objs 1
set00_V001_I00074
num_objs 3
set04_V004_I00272
num_objs 2
set02_V010_I00149
num_objs 1
set03_V009_I01217
num_objs 2
set01_V002_I01823
num_objs 4
set01_V005_I01550
num_objs 0
set02_V011_I00776
num_objs 0
set05_V010_I01097
num_objs 1
set02_V011_I00485
num_objs 2
set04_V004_I00137
num_objs 1
set01_V003_I01682
num_objs 3
set00_V010_I00209
num_objs 0
set03_V009_I01016
num_objs 4
set04_V010_I00674
num_objs 1
set02_V007_I00164
num_objs 1
set01_V001_I00926
num_objs 1
set04_V002_I01727
num_objs 3
set05_V000_I00152
num_objs 3
set00_V012_I00590
num_objs 0
set00_V007_I00740
num_objs 2
set03_V005_I00800
num_objs 1
set01_V003_I01016
num_objs 2
set04_V003_I00998
num_objs 4
set04_V002_I01325
num_objs 2
set00_V007_I01514
num_objs 3
set00_V000_I01616
num_objs 1
set04_V005_I01130
num_objs 1
set01_V003_I00446
num_objs 4
set01_V000_I01046
num_objs 1
set03_V009_I01328
num_objs 0
set01_V002_I00320
num_objs 7
set01_V002_I01721
num_objs 5
set03_V008_I00596
num_objs 9
set03_V008_I01775
num_objs 2
set01_V004_I01583
num_objs 1
set00_V009_I01517
num_objs 3
set00_V002_I00494
num_objs 0
set00_V006_I00203
num_objs 3
set03_V011_I01205
num_objs 1
set00_V006_I01880
num_objs 0
set05_V002_I01106
num_objs 1
set01_V004_I01409
num_objs 1
set00_V000_I01526
num_objs 1
set04_V004_I01652
num_objs 2
set01_V002_I00713
num_objs 6
set03_V009_I00170
num_objs 5
set01_V001_I01268
num_objs 11
set00_V000_I01274
num_objs 1
set03_V009_I01001
num_objs 2
set04_V008_I00599
num_objs 1
set04_V003_I00476
num_objs 0
set00_V008_I01196
num_objs 0
set05_V003_I01181
num_objs 3
set00_V010_I01547
num_objs 2
set04_V002_I00770
num_objs 2
set00_V011_I01172
num_objs 4
set01_V005_I00158
num_objs 2
set03_V008_I00773
num_objs 3
set01_V001_I00248
num_objs 1
set00_V013_I00716
num_objs 2
set00_V009_I00575
num_objs 1
set00_V006_I01100
num_objs 10
set00_V012_I00704
num_objs 0
set03_V008_I00689
num_objs 14
set04_V003_I01757
num_objs 2
set03_V008_I01520
num_objs 2
set01_V003_I00206
num_objs 7
set04_V010_I00791
num_objs 1
set01_V001_I01376
num_objs 9
set00_V000_I01064
num_objs 0
set03_V005_I00323
num_objs 2
set03_V001_I00056
num_objs 1
set00_V000_I00983
num_objs 0
set05_V007_I01532
num_objs 1
set01_V002_I00911
num_objs 4
set01_V002_I00146
num_objs 7
set05_V010_I00497
num_objs 1
set01_V000_I01343
num_objs 4
set03_V012_I00860
num_objs 1
set00_V006_I01358
num_objs 4
set04_V002_I00794
num_objs 1
set00_V000_I00908
num_objs 0
set05_V003_I01352
num_objs 2
set02_V009_I01562
num_objs 1
set03_V011_I00746
num_objs 2
set04_V007_I01070
num_objs 2
set03_V009_I00518
num_objs 3
set00_V001_I00041
num_objs 1
set00_V006_I01331
num_objs 4
set03_V005_I00542
num_objs 3
set03_V007_I01511
num_objs 0
set00_V007_I01550
num_objs 6
set00_V011_I00077
num_objs 4
set00_V013_I00245
num_objs 4
set01_V002_I01142
num_objs 1
set00_V010_I00578
num_objs 5
set00_V014_I01319
num_objs 0
set00_V013_I01262
num_objs 1
set04_V002_I00596
num_objs 1
set00_V010_I00320
num_objs 5
set01_V001_I00302
num_objs 4
set01_V001_I01727
num_objs 2
set00_V012_I00578
num_objs 0
set00_V001_I00797
num_objs 3
set02_V009_I01739
num_objs 0
set00_V006_I01241
num_objs 6
set00_V006_I01040
num_objs 3
set00_V012_I01484
num_objs 1
set00_V001_I01406
num_objs 3
set00_V011_I00008
num_objs 6
set05_V000_I01418
num_objs 0
set02_V009_I00383
num_objs 2
set01_V003_I01838
num_objs 1
set04_V002_I01208
num_objs 2
set05_V004_I01052
num_objs 1
set00_V011_I01439
num_objs 4
set00_V000_I01010
num_objs 0
set04_V003_I01724
num_objs 1
set02_V010_I00362
num_objs 1
set04_V008_I00980
num_objs 1
set00_V006_I00317
num_objs 4
set04_V002_I01217
num_objs 2
set01_V005_I01715
num_objs 0
set00_V010_I00551
num_objs 6
set04_V002_I01736
num_objs 3
set02_V007_I00974
num_objs 1
set01_V005_I00206
num_objs 2
set03_V005_I00530
num_objs 3
set00_V012_I01406
num_objs 1
set00_V009_I01484
num_objs 2
set04_V000_I00893
num_objs 1
set00_V014_I01760
num_objs 0
set04_V003_I00947
num_objs 1
set05_V010_I00536
num_objs 1
set03_V003_I00617
num_objs 2
set04_V010_I01595
num_objs 2
set04_V005_I01577
num_objs 2
set03_V008_I01580
num_objs 2
set03_V009_I00407
num_objs 3
set04_V008_I01433
num_objs 1
set00_V008_I01244
num_objs 2
set03_V008_I00182
num_objs 11
set04_V007_I00311
num_objs 1
set03_V012_I01493
num_objs 3
set01_V000_I01025
num_objs 2
set03_V003_I00881
num_objs 2
set01_V000_I01400
num_objs 4
set01_V001_I00734
num_objs 2
set04_V001_I00116
num_objs 1
set05_V000_I00689
num_objs 1
set01_V001_I01088
num_objs 1
set02_V010_I01346
num_objs 1
set00_V007_I01703
num_objs 5
set04_V000_I00860
num_objs 1
set00_V014_I01583
num_objs 4
set00_V000_I01553
num_objs 1
set03_V009_I01472
num_objs 1
set00_V014_I01637
num_objs 4
set03_V003_I01172
num_objs 2
set01_V002_I01103
num_objs 3
set00_V010_I00602
num_objs 5
set00_V001_I00650
num_objs 3
set03_V009_I01304
num_objs 0
set03_V003_I01514
num_objs 2
set03_V003_I00566
num_objs 2
set00_V007_I01088
num_objs 6
set02_V008_I00968
num_objs 0
set04_V010_I00710
num_objs 1
set04_V007_I00230
num_objs 1
set00_V010_I01418
num_objs 3
set00_V011_I00302
num_objs 2
set04_V002_I01604
num_objs 2
set01_V001_I01007
num_objs 1
set03_V008_I00035
num_objs 4
set00_V001_I00674
num_objs 3
set00_V011_I01322
num_objs 5
set00_V001_I01496
num_objs 5
set01_V004_I01331
num_objs 1
set05_V011_I01250
num_objs 3
set02_V011_I01730
num_objs 2
set05_V010_I00836
num_objs 2
set00_V001_I00443
num_objs 1
set04_V000_I00551
num_objs 3
set00_V007_I00638
num_objs 2
set03_V008_I01256
num_objs 2
set02_V009_I00332
num_objs 2
set00_V008_I00962
num_objs 1
set00_V014_I01634
num_objs 4
set05_V011_I00773
num_objs 4
set01_V004_I00908
num_objs 3
set01_V005_I00032
num_objs 2
set03_V008_I01043
num_objs 1
set04_V005_I01673
num_objs 0
set01_V000_I00209
num_objs 1
set04_V004_I00686
num_objs 2
set05_V005_I00953
num_objs 1
set00_V013_I01202
num_objs 1
set04_V008_I01313
num_objs 1
set05_V007_I01448
num_objs 1
set03_V008_I01052
num_objs 1
set05_V000_I01649
num_objs 0
set05_V009_I00983
num_objs 1
set00_V000_I00521
num_objs 1
set04_V000_I00986
num_objs 1
set03_V008_I00077
num_objs 7
set00_V002_I00824
num_objs 8
set00_V008_I01508
num_objs 3
set01_V000_I01481
num_objs 5
set00_V006_I00629
num_objs 2
set00_V010_I00761
num_objs 3
set00_V006_I00491
num_objs 3
set00_V013_I00347
num_objs 5
set01_V004_I01481
num_objs 2
set00_V000_I00902
num_objs 0
set00_V001_I01223
num_objs 5
set04_V004_I00746
num_objs 2
set01_V003_I00422
num_objs 3
set01_V001_I00980
num_objs 1
set04_V002_I01319
num_objs 1
set03_V009_I01154
num_objs 1
set02_V010_I00056
num_objs 0
set05_V005_I00704
num_objs 1
set04_V003_I01223
num_objs 3
set01_V003_I00362
num_objs 3
set00_V012_I00272
num_objs 3
set05_V004_I00962
num_objs 1
set03_V005_I00497
num_objs 2
set03_V005_I01448
num_objs 1
set03_V012_I01352
num_objs 4
set00_V010_I00524
num_objs 4
set01_V005_I01748
num_objs 0
set00_V000_I00962
num_objs 0
set02_V003_I00065
num_objs 1
set02_V010_I00446
num_objs 1
set01_V002_I01175
num_objs 1
set00_V003_I00359
num_objs 1
set00_V000_I00848
num_objs 0
set00_V013_I00959
num_objs 1
set00_V014_I00422
num_objs 6
set00_V012_I00638
num_objs 0
set00_V006_I00968
num_objs 1
set03_V009_I00965
num_objs 2
set01_V003_I01598
num_objs 1
set00_V000_I01730
num_objs 1
set02_V010_I01088
num_objs 1
set00_V010_I01079
num_objs 2
set01_V005_I01586
num_objs 0
set04_V007_I01358
num_objs 1
set04_V002_I00740
num_objs 2
set00_V000_I00257
num_objs 5
set04_V010_I00446
num_objs 1
set01_V002_I00323
num_objs 7
set00_V008_I00884
num_objs 1
set03_V005_I01751
num_objs 2
set04_V007_I00779
num_objs 1
set00_V007_I00683
num_objs 1
set01_V000_I01268
num_objs 3
set05_V002_I00692
num_objs 1
set05_V007_I01712
num_objs 0
set05_V005_I00308
num_objs 2
set05_V011_I00959
num_objs 4
set02_V009_I00716
num_objs 2
set04_V001_I01547
num_objs 2
set01_V003_I00746
num_objs 2
set00_V014_I01850
num_objs 0
set02_V010_I01685
num_objs 1
set00_V000_I01283
num_objs 1
set01_V002_I01151
num_objs 1
set00_V001_I00257
num_objs 5
set00_V012_I00260
num_objs 3
set00_V012_I00980
num_objs 4
set00_V008_I01184
num_objs 0
set00_V009_I01220
num_objs 1
set03_V011_I00155
num_objs 2
set03_V008_I01007
num_objs 1
set03_V009_I00500
num_objs 3
set01_V000_I00038
num_objs 1
set01_V004_I00794
num_objs 2
set03_V010_I01724
num_objs 3
set03_V001_I00017
num_objs 1
set00_V006_I01379
num_objs 4
set01_V002_I00860
num_objs 9
set03_V005_I00767
num_objs 1
set00_V014_I00707
num_objs 3
set04_V005_I00179
num_objs 0
set02_V009_I00557
num_objs 2
set04_V007_I00659
num_objs 1
set03_V007_I01502
num_objs 0
set01_V000_I00575
num_objs 1
set00_V012_I01058
num_objs 0
set00_V003_I00161
num_objs 1
set05_V005_I00233
num_objs 1
set00_V000_I00344
num_objs 2
set00_V014_I01091
num_objs 2
set04_V011_I01070
num_objs 2
set03_V003_I00962
num_objs 2
set00_V006_I01565
num_objs 2
set02_V009_I00470
num_objs 1
set00_V004_I00839
num_objs 1
set00_V007_I01316
num_objs 8
set03_V009_I00143
num_objs 5
set00_V000_I00833
num_objs 0
set00_V006_I01487
num_objs 3
set01_V001_I01436
num_objs 13
set04_V002_I01808
num_objs 1
set05_V000_I00362
num_objs 3
set01_V000_I01397
num_objs 3
set04_V008_I01076
num_objs 1
set01_V004_I00080
num_objs 2
set04_V002_I00662
num_objs 2
set00_V001_I01043
num_objs 13
set03_V004_I00137
num_objs 1
set02_V008_I01232
num_objs 1
set01_V005_I00488
num_objs 3
set03_V002_I01451
num_objs 1
set04_V006_I00593
num_objs 1
set00_V012_I00941
num_objs 6
set00_V012_I01469
num_objs 2
set04_V008_I01088
num_objs 1
set02_V009_I00134
num_objs 1
set05_V000_I01712
num_objs 1
set01_V003_I01268
num_objs 1
set01_V000_I00503
num_objs 0
set00_V000_I01046
num_objs 0
set04_V000_I00932
num_objs 1
set01_V003_I01403
num_objs 1
set02_V001_I01559
num_objs 0
set05_V005_I00143
num_objs 1
set01_V003_I01562
num_objs 1
set05_V012_I00494
num_objs 3
set01_V003_I00785
num_objs 2
set04_V002_I00149
num_objs 0
set00_V000_I01454
num_objs 1
set04_V003_I00344
num_objs 1
set03_V009_I00911
num_objs 4
set02_V009_I00908
num_objs 1
set00_V014_I00950
num_objs 3
set03_V003_I01052
num_objs 2
set01_V000_I00914
num_objs 3
set01_V003_I00857
num_objs 1
set05_V005_I00692
num_objs 1
set05_V002_I01547
num_objs 1
set00_V006_I00134
num_objs 3
set00_V007_I00611
num_objs 3
set00_V001_I01019
num_objs 5
set00_V009_I00554
num_objs 2
set00_V012_I01322
num_objs 0
set05_V002_I00452
num_objs 1
set03_V009_I01010
num_objs 3
set00_V014_I00788
num_objs 5
set02_V003_I00740
num_objs 2
set04_V001_I00143
num_objs 1
set03_V009_I01157
num_objs 1
set05_V000_I00194
num_objs 2
set03_V008_I00644
num_objs 5
set03_V003_I01049
num_objs 0
set03_V003_I01517
num_objs 2
set01_V002_I01583
num_objs 2
set03_V008_I01235
num_objs 2
set01_V005_I00164
num_objs 2
set03_V006_I00023
num_objs 1
set04_V007_I01058
num_objs 2
set01_V004_I00194
num_objs 1
set03_V003_I00140
num_objs 2
set05_V000_I00695
num_objs 1
set02_V011_I00791
num_objs 0
set00_V013_I00206
num_objs 4
set03_V001_I00080
num_objs 1
set00_V010_I01433
num_objs 4
set03_V005_I00359
num_objs 0
set01_V004_I00563
num_objs 1
set02_V011_I00884
num_objs 1
set03_V006_I00047
num_objs 1
set00_V006_I00869
num_objs 0
set05_V002_I01094
num_objs 1
set03_V007_I00257
num_objs 1
set01_V005_I00767
num_objs 2
set00_V008_I00074
num_objs 6
set00_V012_I01631
num_objs 1
set02_V009_I01664
num_objs 1
set01_V003_I00848
num_objs 1
set05_V003_I01811
num_objs 0
set01_V001_I00641
num_objs 3
set00_V007_I00671
num_objs 2
set04_V008_I01043
num_objs 1
set01_V002_I01763
num_objs 5
set00_V011_I00134
num_objs 3
set04_V002_I01364
num_objs 2
set01_V001_I00794
num_objs 1
set00_V008_I00470
num_objs 8
set03_V010_I01022
num_objs 3
set04_V007_I01034
num_objs 2
set00_V011_I00668
num_objs 4
set02_V009_I01451
num_objs 1
set03_V009_I01679
num_objs 2
set00_V008_I00938
num_objs 1
set00_V000_I00782
num_objs 0
set01_V003_I00944
num_objs 2
set00_V000_I01721
num_objs 2
set00_V002_I00845
num_objs 11
set04_V003_I00980
num_objs 4
set05_V005_I00014
num_objs 3
set00_V007_I00350
num_objs 5
set00_V002_I01268
num_objs 0
set04_V004_I01262
num_objs 1
set03_V003_I01058
num_objs 2
set03_V011_I01361
num_objs 1
set01_V005_I00581
num_objs 3
set03_V003_I00554
num_objs 2
set05_V010_I00995
num_objs 1
set02_V009_I00407
num_objs 2
set00_V006_I01148
num_objs 5
set04_V004_I00911
num_objs 2
set00_V013_I00809
num_objs 0
set01_V005_I01079
num_objs 0
set02_V001_I00125
num_objs 0
set00_V009_I00788
num_objs 2
set03_V003_I00758
num_objs 2
set02_V008_I01100
num_objs 0
set00_V001_I00782
num_objs 3
set01_V004_I00017
num_objs 2
set04_V003_I00092
num_objs 0
set00_V002_I00479
num_objs 0
set04_V003_I00209
num_objs 0
set00_V009_I00170
num_objs 3
set03_V008_I01739
num_objs 0
set00_V007_I01418
num_objs 5
set03_V002_I01598
num_objs 1
set02_V011_I00482
num_objs 2
set00_V009_I00080
num_objs 5
set00_V002_I01265
num_objs 0
set04_V004_I01178
num_objs 3
set01_V001_I01061
num_objs 1
set05_V011_I01085
num_objs 6
set03_V004_I00485
num_objs 1
set05_V011_I00920
num_objs 8
set04_V004_I00224
num_objs 2
set01_V001_I00554
num_objs 4
set04_V007_I01568
num_objs 1
set04_V007_I00734
num_objs 2
set04_V002_I01664
num_objs 2
set03_V003_I00719
num_objs 1
set03_V011_I00152
num_objs 2
set05_V011_I01439
num_objs 3
set01_V003_I00833
num_objs 2
set04_V003_I01463
num_objs 3
set03_V003_I01385
num_objs 2
set01_V001_I01292
num_objs 11
set04_V005_I00266
num_objs 1
set00_V007_I01814
num_objs 4
set02_V011_I01394
num_objs 2
set00_V011_I00053
num_objs 4
set03_V001_I00035
num_objs 1
set04_V002_I00848
num_objs 1
set00_V008_I01040
num_objs 3
set00_V007_I01781
num_objs 3
set01_V000_I00941
num_objs 2
set05_V010_I00998
num_objs 1
set00_V002_I01202
num_objs 1
set03_V001_I00089
num_objs 0
set00_V014_I01604
num_objs 4
set01_V004_I00632
num_objs 4
set04_V005_I01118
num_objs 1
set03_V010_I01832
num_objs 2
set03_V012_I01283
num_objs 0
set01_V002_I00596
num_objs 7
set04_V003_I01289
num_objs 2
set01_V003_I01610
num_objs 1
set05_V002_I01139
num_objs 2
set01_V004_I00896
num_objs 1
set03_V008_I01715
num_objs 2
set04_V010_I01676
num_objs 2
set05_V010_I00815
num_objs 2
set01_V000_I00614
num_objs 4
set02_V011_I01526
num_objs 2
set03_V006_I01721
num_objs 1
set01_V005_I01733
num_objs 0
set04_V004_I01364
num_objs 1
set01_V005_I00710
num_objs 2
set05_V011_I01052
num_objs 8
set00_V000_I00332
num_objs 1
set00_V006_I00155
num_objs 3
set00_V007_I00170
num_objs 1
set00_V000_I01253
num_objs 1
set03_V005_I01826
num_objs 2
set05_V012_I00560
num_objs 0
set01_V003_I00104
num_objs 5
set05_V005_I00776
num_objs 1
set00_V012_I00257
num_objs 3
set03_V005_I00446
num_objs 2
set01_V002_I00581
num_objs 8
set00_V006_I01868
num_objs 0
set04_V003_I00566
num_objs 0
set05_V000_I00161
num_objs 3
set02_V011_I00371
num_objs 2
set05_V011_I01160
num_objs 5
set00_V000_I00773
num_objs 0
set01_V001_I00335
num_objs 4
set05_V002_I00695
num_objs 1
set00_V000_I01736
num_objs 1
set02_V009_I00845
num_objs 1
set01_V000_I00854
num_objs 0
set00_V006_I00494
num_objs 3
set00_V009_I00146
num_objs 1
set03_V006_I01829
num_objs 0
set04_V007_I00701
num_objs 2
set00_V011_I00380
num_objs 3
set00_V008_I01259
num_objs 2
set00_V006_I00212
num_objs 3
set00_V012_I01229
num_objs 2
set00_V012_I00548
num_objs 1
set00_V011_I00014
num_objs 6
set02_V010_I00920
num_objs 1
set01_V001_I00971
num_objs 1
set03_V005_I01217
num_objs 3
set04_V004_I00704
num_objs 2
set00_V003_I00164
num_objs 1
set04_V010_I00587
num_objs 1
set03_V003_I01322
num_objs 2
set03_V008_I00560
num_objs 11
set00_V004_I00809
num_objs 2
set00_V008_I00053
num_objs 6
set05_V003_I01610
num_objs 0
set05_V008_I01799
num_objs 0
set01_V004_I00539
num_objs 1
set00_V001_I00641
num_objs 6
set01_V002_I00257
num_objs 7
set00_V000_I00353
num_objs 3
set04_V003_I00308
num_objs 1
set02_V010_I00257
num_objs 1
set04_V005_I01031
num_objs 3
set01_V004_I00773
num_objs 2
set05_V010_I00824
num_objs 2
set00_V000_I00794
num_objs 0
set01_V001_I00077
num_objs 2
set03_V003_I00794
num_objs 2
set00_V004_I00800
num_objs 2
set02_V008_I01178
num_objs 0
set05_V002_I01565
num_objs 1
set00_V007_I01595
num_objs 6
set02_V003_I00245
num_objs 1
set03_V006_I00188
num_objs 0
set01_V004_I01040
num_objs 3
set05_V003_I01667
num_objs 0
set00_V012_I00431
num_objs 0
set04_V008_I01073
num_objs 1
set05_V004_I00935
num_objs 2
set01_V005_I00455
num_objs 4
set03_V003_I01355
num_objs 2
set00_V007_I00902
num_objs 4
set00_V009_I01451
num_objs 3
set00_V010_I01109
num_objs 4
set00_V009_I00866
num_objs 4
set02_V009_I01331
num_objs 1
set01_V002_I00035
num_objs 2
set04_V005_I00080
num_objs 1
set03_V009_I01172
num_objs 2
set04_V010_I00929
num_objs 2
set00_V007_I01709
num_objs 4
set03_V005_I01355
num_objs 1
set01_V003_I01283
num_objs 1
set00_V001_I00182
num_objs 2
set05_V002_I00749
num_objs 0
set05_V007_I01568
num_objs 0
set00_V006_I01673
num_objs 0
set02_V011_I00428
num_objs 1
set00_V010_I00893
num_objs 3
set01_V005_I01406
num_objs 0
set01_V001_I00563
num_objs 4
set00_V010_I00890
num_objs 3
set01_V000_I00050
num_objs 1
set05_V000_I00197
num_objs 2
set03_V006_I01832
num_objs 1
set02_V009_I00773
num_objs 2
set01_V004_I01586
num_objs 1
set01_V002_I00866
num_objs 9
set03_V002_I01502
num_objs 1
set03_V009_I00605
num_objs 4
set00_V000_I00461
num_objs 2
set00_V011_I00620
num_objs 3
set00_V013_I01322
num_objs 5
set00_V002_I00362
num_objs 1
set00_V007_I01523
num_objs 3
set05_V007_I01346
num_objs 1
set01_V005_I01178
num_objs 3
set00_V001_I00242
num_objs 6
set02_V007_I00941
num_objs 1
set00_V001_I01433
num_objs 4
set00_V010_I00920
num_objs 1
set00_V004_I00836
num_objs 1
set00_V010_I00962
num_objs 1
set00_V009_I00005
num_objs 1
set00_V011_I01241
num_objs 3
set00_V000_I00182
num_objs 3
set05_V012_I01241
num_objs 1
set03_V010_I01049
num_objs 1
set01_V001_I00872
num_objs 1
set00_V004_I00917
num_objs 2
set00_V006_I01820
num_objs 0
set04_V003_I00956
num_objs 3
set01_V000_I01439
num_objs 5
set05_V005_I01088
num_objs 1
set00_V012_I00074
num_objs 1
set03_V005_I01616
num_objs 1
set04_V004_I00464
num_objs 3
set01_V003_I01637
num_objs 1
set03_V008_I01478
num_objs 2
set00_V000_I00386
num_objs 4
set00_V006_I01892
num_objs 0
set01_V005_I00317
num_objs 3
set00_V007_I01472
num_objs 5
set03_V011_I00740
num_objs 2
set01_V003_I01802
num_objs 1
set05_V002_I01148
num_objs 1
set01_V003_I00530
num_objs 3
set03_V007_I00335
num_objs 1
set00_V006_I01454
num_objs 4
set03_V003_I01298
num_objs 2
set03_V011_I00806
num_objs 2
set03_V007_I01493
num_objs 0
set03_V012_I00836
num_objs 1
set00_V008_I00968
num_objs 1
set02_V010_I01817
num_objs 1
set00_V001_I01409
num_objs 2
set01_V003_I01676
num_objs 3
set04_V005_I01142
num_objs 1
set02_V009_I00707
num_objs 2
set00_V002_I00905
num_objs 5
set00_V008_I00878
num_objs 1
set02_V011_I00689
num_objs 0
set05_V012_I00401
num_objs 3
set03_V012_I01409
num_objs 4
set02_V007_I00440
num_objs 1
set00_V006_I00017
num_objs 1
set02_V010_I00974
num_objs 1
set00_V007_I00557
num_objs 5
set03_V010_I00797
num_objs 0
set00_V006_I00215
num_objs 3
set04_V005_I01484
num_objs 1
set01_V000_I00380
num_objs 3
set05_V003_I00965
num_objs 1
set00_V001_I01652
num_objs 2
set02_V011_I01625
num_objs 2
set00_V010_I01412
num_objs 3
set05_V000_I01640
num_objs 1
set01_V002_I01184
num_objs 2
set05_V000_I00722
num_objs 1
set00_V004_I01649
num_objs 0
set01_V001_I00686
num_objs 3
set01_V005_I00752
num_objs 2
set01_V001_I01190
num_objs 4
set01_V002_I00962
num_objs 3
set04_V008_I01511
num_objs 1
set01_V002_I00245
num_objs 7
set00_V009_I00026
num_objs 2
set00_V011_I00233
num_objs 1
set01_V000_I01646
num_objs 3
set05_V007_I01529
num_objs 1
set01_V004_I00992
num_objs 1
set04_V011_I01820
num_objs 1
set05_V012_I00581
num_objs 0
set03_V008_I00980
num_objs 1
set00_V007_I00440
num_objs 5
set00_V009_I01457
num_objs 2
set05_V005_I00458
num_objs 1
set04_V007_I00908
num_objs 2
set00_V001_I01271
num_objs 4
set05_V003_I01745
num_objs 0
set01_V005_I01637
num_objs 0
set05_V011_I01139
num_objs 2
set02_V009_I00506
num_objs 1
set00_V006_I00014
num_objs 1
set04_V006_I01475
num_objs 1
set02_V001_I00140
num_objs 0
set02_V008_I01850
num_objs 0
set00_V007_I00518
num_objs 4
set00_V001_I01715
num_objs 1
set01_V004_I00989
num_objs 6
set03_V001_I00050
num_objs 1
set04_V003_I01772
num_objs 2
set03_V009_I01100
num_objs 6
set00_V001_I00941
num_objs 7
set02_V001_I01439
num_objs 0
set05_V005_I00902
num_objs 1
set01_V000_I00662
num_objs 0
set02_V010_I00800
num_objs 2
set00_V007_I01607
num_objs 6
set05_V011_I00020
num_objs 1
set05_V011_I00866
num_objs 9
set03_V008_I01094
num_objs 1
set00_V012_I01253
num_objs 0
set01_V001_I00155
num_objs 3
set00_V008_I01517
num_objs 2
set00_V007_I00476
num_objs 5
set00_V009_I01106
num_objs 1
set00_V006_I00872
num_objs 4
set04_V007_I01505
num_objs 1
set03_V002_I01529
num_objs 1
set00_V006_I01844
num_objs 0
set05_V002_I01592
num_objs 1
set04_V003_I00986
num_objs 4
set00_V000_I00821
num_objs 0
set01_V005_I01421
num_objs 0
set03_V008_I01763
num_objs 2
set03_V006_I01733
num_objs 1
set04_V003_I01286
num_objs 4
set02_V011_I00782
num_objs 0
set00_V013_I00434
num_objs 2
set03_V004_I00122
num_objs 1
set01_V004_I00011
num_objs 2
set00_V006_I01754
num_objs 1
set00_V014_I01838
num_objs 0
set04_V007_I00845
num_objs 2
set03_V011_I00698
num_objs 1
set00_V000_I01550
num_objs 1
set03_V005_I01445
num_objs 1
set00_V012_I01562
num_objs 2
set00_V010_I01310
num_objs 3
set00_V012_I00197
num_objs 1
set05_V005_I01106
num_objs 1
set05_V000_I00425
num_objs 2
set01_V005_I00185
num_objs 2
set03_V008_I01217
num_objs 2
set05_V010_I00635
num_objs 1
set01_V001_I00416
num_objs 4
set01_V005_I01454
num_objs 0
set01_V001_I00377
num_objs 5
set01_V003_I00896
num_objs 1
set05_V011_I01466
num_objs 3
set04_V003_I00950
num_objs 2
set00_V011_I01253
num_objs 3
set00_V010_I01655
num_objs 0
set01_V005_I01028
num_objs 3
set04_V004_I00665
num_objs 2
set02_V008_I01829
num_objs 0
set01_V000_I00053
num_objs 1
set05_V012_I00512
num_objs 1
set01_V004_I00140
num_objs 2
set05_V010_I00461
num_objs 1
set00_V007_I00365
num_objs 5
set00_V001_I00587
num_objs 1
set00_V009_I00965
num_objs 4
set01_V002_I01223
num_objs 4
set00_V007_I00233
num_objs 5
set00_V011_I00320
num_objs 2
set00_V004_I00362
num_objs 2
set03_V008_I01625
num_objs 2
set05_V005_I01079
num_objs 0
set01_V003_I00617
num_objs 1
set00_V002_I01025
num_objs 0
set03_V009_I00149
num_objs 2
set03_V008_I01529
num_objs 4
set00_V011_I00476
num_objs 5
set01_V002_I00671
num_objs 6
set03_V009_I01178
num_objs 2
set04_V002_I01583
num_objs 2
set00_V010_I00710
num_objs 2
set00_V002_I00851
num_objs 11
set02_V009_I01766
num_objs 1
set03_V009_I01463
num_objs 0
set05_V010_I00134
num_objs 1
set01_V003_I00173
num_objs 7
set03_V003_I00827
num_objs 2
set02_V010_I01457
num_objs 1
set04_V003_I00065
num_objs 0
set02_V001_I00116
num_objs 0
set02_V010_I01772
num_objs 1
set03_V005_I00812
num_objs 1
set00_V001_I01172
num_objs 4
set04_V007_I00833
num_objs 2
set04_V007_I00881
num_objs 2
set00_V014_I01097
num_objs 2
set01_V004_I00527
num_objs 1
set03_V004_I00557
num_objs 1
set00_V000_I00173
num_objs 3
set03_V009_I00386
num_objs 3
set05_V011_I00659
num_objs 0
set00_V010_I00059
num_objs 2
set05_V004_I00494
num_objs 2
set01_V001_I01361
num_objs 9
set01_V005_I01496
num_objs 0
set05_V005_I01070
num_objs 1
set00_V000_I01802
num_objs 1
set04_V006_I00959
num_objs 1
set02_V011_I00623
num_objs 2
set00_V006_I01523
num_objs 2
set00_V006_I01595
num_objs 2
set01_V004_I00725
num_objs 3
set02_V001_I01697
num_objs 1
set01_V004_I01118
num_objs 4
set04_V001_I00101
num_objs 1
set03_V003_I00917
num_objs 2
set00_V013_I01292
num_objs 2
set00_V014_I01115
num_objs 3
set02_V010_I01643
num_objs 1
set04_V001_I01592
num_objs 2
set01_V004_I00875
num_objs 2
set00_V013_I00287
num_objs 5
set01_V002_I00563
num_objs 8
set00_V011_I01223
num_objs 4
set02_V011_I01481
num_objs 2
set00_V005_I00806
num_objs 1
set03_V009_I01352
num_objs 1
set02_V011_I01697
num_objs 2
set00_V001_I00047
num_objs 1
set03_V006_I00131
num_objs 1
set05_V008_I01823
num_objs 1
set05_V005_I00764
num_objs 1
set03_V004_I00044
num_objs 1
set01_V005_I00587
num_objs 3
set04_V004_I00719
num_objs 1
set00_V004_I01427
num_objs 2
set01_V003_I00269
num_objs 4
set00_V010_I01388
num_objs 4
set01_V002_I01481
num_objs 0
set04_V003_I01220
num_objs 3
set01_V002_I01403
num_objs 1
set02_V011_I01406
num_objs 2
set04_V004_I01403
num_objs 1
set03_V003_I00023
num_objs 2
set04_V011_I01787
num_objs 1
set04_V007_I01022
num_objs 2
set04_V003_I00773
num_objs 1
set00_V000_I00317
num_objs 1
set02_V010_I01244
num_objs 1
set01_V002_I01112
num_objs 3
set00_V007_I01601
num_objs 6
set04_V010_I00593
num_objs 1
set03_V008_I01667
num_objs 2
set01_V003_I01700
num_objs 3
set03_V008_I00539
num_objs 17
set00_V009_I00617
num_objs 2
set04_V006_I00677
num_objs 3
set03_V003_I01220
num_objs 2
set00_V004_I00902
num_objs 2
set00_V010_I01559
num_objs 1
set05_V002_I00161
num_objs 1
set02_V003_I00728
num_objs 2
set05_V007_I01253
num_objs 1
set00_V006_I00689
num_objs 2
set00_V006_I01349
num_objs 3
set00_V002_I00788
num_objs 4
set00_V006_I00512
num_objs 3
set04_V002_I01472
num_objs 2
set05_V011_I00608
num_objs 4
set03_V011_I00731
num_objs 1
set03_V003_I01412
num_objs 2
set00_V012_I00011
num_objs 0
set00_V004_I01442
num_objs 2
set01_V004_I01307
num_objs 1
set02_V011_I01286
num_objs 1
set00_V006_I00983
num_objs 1
set00_V013_I01346
num_objs 3
set05_V012_I00275
num_objs 1
set03_V011_I00299
num_objs 3
set01_V002_I00608
num_objs 7
set05_V007_I01565
num_objs 0
set04_V007_I00293
num_objs 1
set02_V010_I00473
num_objs 1
set02_V011_I00716
num_objs 1
set01_V003_I00089
num_objs 10
set03_V003_I01112
num_objs 2
set03_V011_I00689
num_objs 0
set00_V002_I00743
num_objs 2
set01_V003_I01352
num_objs 1
set01_V004_I01547
num_objs 2
set00_V005_I00797
num_objs 1
set04_V004_I00584
num_objs 3
set00_V008_I00773
num_objs 2
set03_V008_I00806
num_objs 2
set03_V005_I01496
num_objs 1
set00_V000_I00215
num_objs 4
set03_V005_I00707
num_objs 1
set04_V010_I00980
num_objs 1
set00_V007_I01028
num_objs 1
set04_V007_I01340
num_objs 1
set00_V006_I01154
num_objs 5
set00_V013_I01433
num_objs 3
set00_V012_I00773
num_objs 1
set04_V004_I01133
num_objs 3
set02_V003_I00737
num_objs 2
set01_V000_I00218
num_objs 1
set00_V011_I00599
num_objs 1
set05_V010_I00344
num_objs 1
set00_V009_I00995
num_objs 4
set00_V009_I01643
num_objs 3
set04_V005_I00911
num_objs 1
set00_V006_I01385
num_objs 5
set05_V003_I01703
num_objs 0
set00_V008_I00320
num_objs 0
set00_V010_I00665
num_objs 2
set00_V006_I00935
num_objs 3
set01_V005_I00698
num_objs 2
set03_V008_I00278
num_objs 15
set04_V008_I01502
num_objs 1
set02_V011_I00959
num_objs 0
set00_V000_I00839
num_objs 0
set05_V005_I01091
num_objs 1
set00_V006_I00989
num_objs 0
set05_V011_I01562
num_objs 1
set01_V000_I01499
num_objs 1
set00_V009_I00725
num_objs 3
set02_V009_I00749
num_objs 2
set01_V005_I01592
num_objs 0
set03_V009_I01646
num_objs 2
set05_V011_I00929
num_objs 5
set00_V008_I01490
num_objs 3
set03_V004_I00530
num_objs 1
set00_V008_I01319
num_objs 1
set00_V002_I00392
num_objs 0
set05_V011_I00641
num_objs 4
set03_V011_I00323
num_objs 5
set00_V001_I01208
num_objs 4
set02_V009_I00245
num_objs 2
set00_V001_I00719
num_objs 2
set05_V010_I00857
num_objs 1
set00_V011_I00032
num_objs 5
set00_V014_I01421
num_objs 4
set00_V011_I00890
num_objs 0
set04_V003_I01739
num_objs 1
set04_V001_I01532
num_objs 1
set04_V008_I00992
num_objs 1
set01_V005_I00623
num_objs 3
set04_V010_I00656
num_objs 1
set03_V002_I01631
num_objs 2
set04_V007_I01739
num_objs 0
set00_V012_I01328
num_objs 0
set04_V004_I01142
num_objs 3
set00_V001_I01151
num_objs 4
set00_V013_I01598
num_objs 3
set02_V011_I01646
num_objs 2
set02_V010_I01475
num_objs 1
set05_V010_I00737
num_objs 1
set02_V011_I01703
num_objs 2
set00_V003_I00140
num_objs 2
set00_V014_I00632
num_objs 3
set04_V010_I01532
num_objs 2
set04_V004_I01157
num_objs 3
set00_V013_I01457
num_objs 4
set01_V001_I00191
num_objs 2
set00_V002_I00272
num_objs 1
set02_V011_I00515
num_objs 2
set00_V002_I00578
num_objs 0
set03_V005_I01526
num_objs 1
set03_V005_I01082
num_objs 1
set05_V003_I01799
num_objs 0
set03_V002_I01421
num_objs 1
set01_V004_I01166
num_objs 2
set05_V002_I01538
num_objs 1
set00_V004_I00905
num_objs 2
set03_V009_I00017
num_objs 3
set02_V010_I00071
num_objs 1
set04_V003_I01382
num_objs 3
set01_V002_I01793
num_objs 5
set00_V009_I00548
num_objs 2
set04_V003_I01484
num_objs 2
set01_V005_I00434
num_objs 4
set02_V011_I01295
num_objs 1
set03_V012_I00872
num_objs 1
set05_V005_I00914
num_objs 1
set00_V011_I00581
num_objs 3
set01_V005_I01481
num_objs 0
set00_V001_I01385
num_objs 3
set02_V009_I00365
num_objs 2
set03_V011_I00671
num_objs 3
set00_V006_I00293
num_objs 4
set02_V009_I01136
num_objs 1
set01_V005_I00230
num_objs 1
set01_V002_I01523
num_objs 0
set03_V009_I00638
num_objs 3
set05_V010_I00758
num_objs 1
set01_V003_I00038
num_objs 4
set04_V011_I01547
num_objs 1
set03_V012_I01301
num_objs 2
set01_V002_I00173
num_objs 7
set02_V009_I01118
num_objs 1
set04_V004_I00779
num_objs 3
set01_V002_I01121
num_objs 3
set05_V002_I00617
num_objs 1
set00_V002_I00182
num_objs 3
set05_V002_I00563
num_objs 1
set02_V009_I01787
num_objs 1
set05_V011_I01163
num_objs 5
set00_V001_I00752
num_objs 3
set02_V010_I00752
num_objs 3
set00_V010_I01043
num_objs 0
set02_V009_I01358
num_objs 1
set05_V003_I01289
num_objs 2
set00_V006_I01124
num_objs 8
set01_V005_I01385
num_objs 1
set05_V002_I00659
num_objs 0
set02_V001_I01589
num_objs 0
set01_V002_I01421
num_objs 0
set04_V003_I01319
num_objs 3
set00_V013_I00077
num_objs 4
set00_V000_I01130
num_objs 0
set01_V002_I00308
num_objs 7
set05_V010_I00401
num_objs 2
set03_V009_I01070
num_objs 6
set00_V000_I01109
num_objs 0
set01_V001_I00578
num_objs 3
set01_V001_I01388
num_objs 9
set00_V002_I00911
num_objs 5
set00_V002_I00167
num_objs 2
set00_V001_I01313
num_objs 4
set01_V001_I00758
num_objs 1
set04_V006_I00674
num_objs 3
set00_V002_I00179
num_objs 1
set03_V008_I01295
num_objs 3
set03_V003_I00767
num_objs 2
set00_V008_I00269
num_objs 0
set00_V013_I01133
num_objs 4
set01_V000_I00545
num_objs 2
set05_V012_I00749
num_objs 1
set03_V001_I00149
num_objs 1
set05_V005_I00317
num_objs 2
set00_V006_I00146
num_objs 3
set02_V010_I01211
num_objs 1
set05_V005_I00812
num_objs 1
set03_V010_I01031
num_objs 3
set01_V000_I01340
num_objs 4
set03_V008_I00059
num_objs 13
set03_V005_I00782
num_objs 1
set05_V000_I01475
num_objs 1
set00_V008_I00170
num_objs 3
set01_V004_I01058
num_objs 3
set04_V004_I01139
num_objs 3
set04_V002_I00062
num_objs 1
set00_V006_I01097
num_objs 10
set00_V000_I00659
num_objs 0
set01_V005_I00302
num_objs 1
set00_V014_I00383
num_objs 5
set02_V001_I01682
num_objs 1
set05_V003_I01568
num_objs 0
set03_V006_I00194
num_objs 0
set05_V010_I00599
num_objs 0
set01_V000_I00011
num_objs 1
set03_V003_I00020
num_objs 2
set04_V007_I01769
num_objs 0
set04_V002_I01784
num_objs 1
set00_V013_I00575
num_objs 3
set04_V004_I00638
num_objs 2
set01_V001_I01151
num_objs 3
set05_V005_I00326
num_objs 2
set01_V005_I01682
num_objs 0
set03_V011_I01196
num_objs 1
set04_V007_I00620
num_objs 2
set03_V009_I00164
num_objs 5
set02_V009_I00722
num_objs 2
set00_V010_I01595
num_objs 1
set00_V013_I00122
num_objs 4
set00_V008_I01280
num_objs 1
set05_V002_I00104
num_objs 1
set00_V000_I00716
num_objs 2
set05_V003_I01040
num_objs 1
set01_V000_I00506
num_objs 1
set04_V003_I01106
num_objs 3
set01_V003_I00812
num_objs 2
set00_V011_I00401
num_objs 3
set05_V009_I00809
num_objs 0
set00_V004_I01544
num_objs 0
set02_V009_I01535
num_objs 1
set00_V012_I00026
num_objs 0
set01_V005_I00227
num_objs 2
set03_V008_I01277
num_objs 2
set04_V003_I01460
num_objs 3
set00_V013_I01139
num_objs 3
set00_V012_I00647
num_objs 0
set01_V003_I00827
num_objs 2
set04_V006_I00686
num_objs 3
set00_V008_I00296
num_objs 0
set00_V004_I01232
num_objs 0
set02_V010_I00059
num_objs 0
set00_V000_I01805
num_objs 0
set03_V009_I00674
num_objs 3
set03_V008_I01334
num_objs 3
set03_V003_I00122
num_objs 2
set00_V011_I00959
num_objs 5
set02_V009_I00377
num_objs 2
set00_V012_I01001
num_objs 2
set04_V006_I00977
num_objs 2
set02_V009_I00350
num_objs 2
set01_V001_I00131
num_objs 4
set03_V008_I00605
num_objs 7
set02_V007_I00500
num_objs 1
set00_V010_I00692
num_objs 2
set05_V008_I00236
num_objs 2
set00_V014_I00455
num_objs 4
set00_V013_I00092
num_objs 5
set04_V003_I01277
num_objs 3
set00_V002_I01199
num_objs 1
set04_V002_I01487
num_objs 2
set00_V010_I01568
num_objs 1
set03_V011_I00842
num_objs 2
set03_V012_I01592
num_objs 3
set01_V002_I01214
num_objs 3
set02_V009_I01328
num_objs 1
set05_V012_I01043
num_objs 1
set03_V003_I00866
num_objs 2
set03_V009_I00479
num_objs 1
set04_V007_I01643
num_objs 1
set00_V007_I01025
num_objs 1
set05_V002_I01598
num_objs 1
set00_V006_I01862
num_objs 0
set03_V009_I00134
num_objs 5
set01_V002_I00977
num_objs 3
set05_V000_I01499
num_objs 0
set05_V000_I00665
num_objs 1
set00_V008_I00668
num_objs 3
set00_V007_I01376
num_objs 3
set00_V006_I00485
num_objs 3
set02_V010_I00224
num_objs 1
set00_V012_I00653
num_objs 0
set00_V012_I00473
num_objs 1
set05_V008_I00245
num_objs 2
set04_V001_I00098
num_objs 1
set05_V011_I00800
num_objs 5
set04_V010_I00632
num_objs 1
set00_V002_I00653
num_objs 0
set03_V009_I01274
num_objs 1
set00_V006_I00692
num_objs 2
set00_V003_I00182
num_objs 1
set00_V013_I00440
num_objs 2
set00_V002_I00941
num_objs 2
set02_V003_I00347
num_objs 1
set03_V009_I00209
num_objs 3
set02_V010_I01739
num_objs 0
set04_V007_I01163
num_objs 1
set03_V008_I01184
num_objs 1
set04_V007_I01682
num_objs 1
set05_V005_I00869
num_objs 1
set05_V008_I01814
num_objs 1
set04_V010_I01604
num_objs 2
set03_V008_I01259
num_objs 0
set01_V002_I01682
num_objs 3
set00_V007_I00392
num_objs 6
set05_V002_I00137
num_objs 1
set04_V006_I01598
num_objs 1
set03_V012_I01538
num_objs 4
set01_V002_I01778
num_objs 4
set04_V006_I01121
num_objs 1
set03_V003_I00404
num_objs 1
set05_V007_I01559
num_objs 0
set00_V011_I00434
num_objs 6
set00_V004_I01559
num_objs 0
set04_V007_I01136
num_objs 2
set03_V012_I00827
num_objs 1
set01_V000_I00311
num_objs 1
set00_V010_I00227
num_objs 2
set01_V001_I01244
num_objs 11
set00_V010_I00347
num_objs 6
set05_V009_I00782
num_objs 1
set00_V011_I00758
num_objs 1
set03_V012_I00980
num_objs 1
set00_V013_I00086
num_objs 5
set04_V000_I00737
num_objs 3
set00_V013_I01340
num_objs 3
set02_V001_I00161
num_objs 0
set00_V006_I01790
num_objs 0
set03_V012_I00950
num_objs 1
set00_V004_I01223
num_objs 0
set01_V000_I01004
num_objs 0
set01_V000_I01634
num_objs 3
set02_V009_I00830
num_objs 2
set01_V003_I01703
num_objs 3
set02_V011_I01580
num_objs 2
set04_V005_I00194
num_objs 1
set00_V014_I00338
num_objs 3
set01_V001_I00182
num_objs 2
set03_V008_I01760
num_objs 1
set00_V013_I00083
num_objs 5
set00_V000_I01700
num_objs 2
set03_V011_I00473
num_objs 5
set05_V007_I01649
num_objs 0
set03_V011_I00188
num_objs 3
set03_V011_I01370
num_objs 1
set03_V009_I01190
num_objs 3
set02_V011_I01487
num_objs 2
set00_V014_I01727
num_objs 2
set01_V005_I01145
num_objs 4
set03_V005_I01781
num_objs 2
set00_V000_I00713
num_objs 2
set00_V011_I00941
num_objs 6
set05_V011_I01019
num_objs 4
set03_V011_I00338
num_objs 5
set00_V007_I01751
num_objs 5
set04_V003_I01379
num_objs 3
set05_V004_I00932
num_objs 2
set00_V002_I00686
num_objs 1
set03_V009_I00761
num_objs 2
set04_V003_I00278
num_objs 1
set05_V009_I00827
num_objs 1
set00_V000_I01571
num_objs 2
set00_V011_I00842
num_objs 0
set01_V001_I00344
num_objs 4
set00_V012_I00005
num_objs 0
set00_V013_I00695
num_objs 1
set04_V011_I01637
num_objs 1
set05_V003_I01694
num_objs 0
set04_V004_I01313
num_objs 1
set01_V002_I00755
num_objs 8
set03_V009_I00701
num_objs 2
set00_V000_I00209
num_objs 0
set05_V010_I00014
num_objs 1
set02_V009_I00296
num_objs 1
set01_V003_I00572
num_objs 1
set01_V005_I00410
num_objs 4
set01_V003_I00329
num_objs 1
set00_V007_I00572
num_objs 5
set00_V006_I01052
num_objs 4
set02_V009_I01259
num_objs 0
set03_V008_I01103
num_objs 1
set04_V005_I01019
num_objs 1
set01_V003_I01055
num_objs 1
set01_V001_I01757
num_objs 1
set04_V006_I01037
num_objs 1
set05_V005_I00803
num_objs 1
set01_V002_I00692
num_objs 6
set04_V004_I01853
num_objs 1
set04_V005_I01553
num_objs 2
set00_V009_I00968
num_objs 4
set02_V011_I00587
num_objs 2
set00_V013_I01244
num_objs 1
set04_V010_I00623
num_objs 1
set04_V006_I01574
num_objs 1
set00_V001_I00221
num_objs 5
set03_V008_I00509
num_objs 12
set00_V012_I00878
num_objs 5
set02_V011_I00440
num_objs 1
set04_V000_I00884
num_objs 1
set00_V013_I00590
num_objs 3
set00_V011_I00767
num_objs 1
set05_V000_I00557
num_objs 2
set01_V004_I01439
num_objs 1
set00_V012_I01526
num_objs 1
set01_V001_I01133
num_objs 2
set02_V011_I00614
num_objs 2
set01_V005_I01076
num_objs 2
set05_V012_I01088
num_objs 1
set03_V008_I00287
num_objs 16
set00_V013_I00596
num_objs 3
set03_V003_I00305
num_objs 1
set00_V011_I00521
num_objs 5
set04_V005_I00716
num_objs 1
set05_V012_I00410
num_objs 3
set03_V008_I01001
num_objs 1
set03_V009_I00830
num_objs 0
set00_V008_I00818
num_objs 1
set04_V007_I01709
num_objs 1
set01_V001_I01832
num_objs 1
set00_V007_I00824
num_objs 3
set03_V010_I00143
num_objs 2
set03_V008_I00881
num_objs 1
set00_V001_I00335
num_objs 5
set00_V012_I01259
num_objs 1
set04_V003_I01118
num_objs 3
set00_V013_I00443
num_objs 2
set04_V002_I01118
num_objs 2
set01_V005_I00803
num_objs 2
set00_V013_I00941
num_objs 1
set03_V003_I01541
num_objs 2
set03_V007_I01544
num_objs 0
set00_V010_I00533
num_objs 4
set04_V011_I01856
num_objs 1
set00_V010_I00251
num_objs 1
set00_V011_I00800
num_objs 1
set03_V008_I00239
num_objs 12
set00_V010_I00461
num_objs 7
set02_V008_I01289
num_objs 0
set02_V003_I00050
num_objs 1
set00_V014_I00695
num_objs 3
set03_V012_I00899
num_objs 0
set04_V003_I00302
num_objs 0
set05_V000_I01469
num_objs 0
set00_V002_I00290
num_objs 1
set04_V003_I00389
num_objs 0
set01_V001_I01709
num_objs 2
set00_V010_I01274
num_objs 3
set00_V013_I00779
num_objs 1
set04_V004_I01001
num_objs 2
set04_V000_I00770
num_objs 2
set03_V005_I01421
num_objs 1
set00_V006_I00080
num_objs 2
set00_V007_I01253
num_objs 8
set05_V012_I00437
num_objs 3
set04_V007_I00935
num_objs 2
set01_V005_I00884
num_objs 2
set01_V001_I00179
num_objs 1
set02_V001_I01469
num_objs 0
set00_V013_I00344
num_objs 5
set01_V001_I00410
num_objs 4
set05_V010_I01619
num_objs 1
set01_V000_I00128
num_objs 1
set00_V013_I00617
num_objs 4
set04_V011_I01631
num_objs 1
set03_V010_I01028
num_objs 3
set01_V002_I01355
num_objs 3
set01_V003_I00788
num_objs 0
set04_V010_I00527
num_objs 1
set01_V000_I01205
num_objs 3
set00_V006_I01859
num_objs 2
set00_V009_I00035
num_objs 2
set00_V013_I00674
num_objs 1
set02_V007_I00491
num_objs 1
set00_V007_I01133
num_objs 10
set00_V012_I01331
num_objs 0
set03_V005_I00746
num_objs 1
set00_V012_I00611
num_objs 0
set01_V002_I00797
num_objs 7
set04_V008_I00575
num_objs 1
set04_V003_I00113
num_objs 0
set05_V011_I00665
num_objs 2
set00_V008_I00587
num_objs 5
set05_V010_I00632
num_objs 1
set01_V001_I00461
num_objs 4
set00_V009_I01520
num_objs 3
set03_V004_I00470
num_objs 1
set01_V003_I00737
num_objs 2
set00_V006_I00092
num_objs 2
set03_V002_I01616
num_objs 1
set03_V008_I00692
num_objs 3
set03_V005_I00500
num_objs 2
set00_V007_I00596
num_objs 3
set05_V000_I01472
num_objs 1
set00_V012_I00572
num_objs 0
set01_V002_I01820
num_objs 4
set04_V007_I00299
num_objs 0
set05_V012_I00659
num_objs 1
set00_V012_I01106
num_objs 0
set00_V011_I00338
num_objs 2
set00_V009_I01391
num_objs 0
set00_V007_I01745
num_objs 5
set00_V000_I00221
num_objs 5
set00_V009_I00221
num_objs 7
set03_V009_I00824
num_objs 0
set00_V004_I01508
num_objs 0
set04_V007_I00356
num_objs 1
set03_V012_I00893
num_objs 1
set00_V010_I01466
num_objs 4
set01_V004_I00743
num_objs 3
set04_V006_I01064
num_objs 1
set04_V005_I01085
num_objs 2
set00_V012_I01340
num_objs 0
set04_V003_I00074
num_objs 0
set05_V003_I01370
num_objs 2
set03_V011_I00431
num_objs 5
set00_V003_I00410
num_objs 1
set00_V006_I00497
num_objs 3
set00_V013_I01574
num_objs 3
set04_V004_I00128
num_objs 1
set00_V008_I00446
num_objs 8
set05_V000_I00107
num_objs 2
set04_V011_I00371
num_objs 1
set00_V009_I00983
num_objs 5
set04_V002_I01667
num_objs 2
set04_V000_I00683
num_objs 3
set03_V010_I01496
num_objs 2
set05_V007_I01247
num_objs 1
set01_V002_I00434
num_objs 5
set00_V010_I00788
num_objs 3
set01_V005_I01661
num_objs 0
set03_V012_I00884
num_objs 1
set03_V009_I00749
num_objs 2
set05_V011_I00572
num_objs 5
set05_V005_I01025
num_objs 1
set05_V011_I01193
num_objs 3
set05_V011_I01277
num_objs 3
set00_V011_I01259
num_objs 2
set03_V003_I00008
num_objs 2
set04_V003_I01775
num_objs 2
set00_V006_I00248
num_objs 3
set00_V004_I01346
num_objs 1
set03_V008_I01178
num_objs 1
set04_V011_I01745
num_objs 1
set00_V006_I00506
num_objs 3
set05_V001_I00458
num_objs 0
set05_V011_I00509
num_objs 0
set04_V011_I01094
num_objs 2
set05_V012_I00257
num_objs 1
set00_V014_I01250
num_objs 4
set00_V007_I00851
num_objs 3
set01_V001_I00026
num_objs 2
set01_V004_I01091
num_objs 3
set04_V005_I01580
num_objs 2
set05_V011_I01409
num_objs 2
set01_V002_I00779
num_objs 6
set01_V001_I00677
num_objs 3
set04_V006_I00941
num_objs 2
set00_V010_I00239
num_objs 1
set03_V003_I00380
num_objs 1
set02_V009_I00158
num_objs 2
set00_V014_I00839
num_objs 2
set01_V000_I00626
num_objs 3
set00_V007_I01529
num_objs 1
set05_V002_I01628
num_objs 1
set00_V001_I01739
num_objs 1
set00_V001_I00773
num_objs 3
set00_V008_I00062
num_objs 6
set04_V007_I01028
num_objs 2
set03_V003_I01445
num_objs 2
set00_V001_I00560
num_objs 2
set03_V012_I01223
num_objs 1
set05_V002_I00572
num_objs 1
set03_V008_I01415
num_objs 3
set00_V011_I00119
num_objs 3
set00_V013_I00134
num_objs 4
set02_V009_I00596
num_objs 2
set00_V001_I01697
num_objs 1
set04_V004_I01724
num_objs 1
set03_V003_I00368
num_objs 1
set01_V000_I00083
num_objs 3
set04_V003_I00386
num_objs 1
set03_V008_I00569
num_objs 12
set00_V010_I00677
num_objs 2
set00_V014_I01652
num_objs 4
set00_V011_I00950
num_objs 8
set01_V002_I01505
num_objs 0
set01_V000_I01232
num_objs 3
set04_V006_I01067
num_objs 1
set04_V003_I01613
num_objs 1
set02_V008_I00989
num_objs 0
set05_V007_I01742
num_objs 0
set03_V008_I01196
num_objs 1
set00_V009_I00572
num_objs 1
set01_V001_I00338
num_objs 5
set00_V014_I00098
num_objs 4
set02_V009_I00584
num_objs 2
set01_V003_I01586
num_objs 1
set04_V001_I01772
num_objs 1
set00_V007_I00947
num_objs 3
set05_V011_I01229
num_objs 1
set02_V009_I01541
num_objs 1
set00_V009_I00665
num_objs 2
set04_V004_I00167
num_objs 2
set00_V012_I00830
num_objs 4
set03_V011_I00680
num_objs 2
set04_V002_I01076
num_objs 2
set03_V011_I01442
num_objs 2
set05_V012_I00362
num_objs 3
set03_V009_I00524
num_objs 4
set03_V012_I00929
num_objs 0
set01_V003_I00989
num_objs 0
set05_V010_I00701
num_objs 1
set05_V005_I01046
num_objs 1
set00_V011_I00692
num_objs 4
set05_V009_I00974
num_objs 1
set05_V003_I01661
num_objs 0
set00_V012_I00059
num_objs 0
set00_V004_I00350
num_objs 2
set04_V007_I01046
num_objs 2
set05_V000_I00686
num_objs 1
set04_V002_I00758
num_objs 2
set01_V003_I00317
num_objs 2
set01_V001_I00227
num_objs 1
set05_V011_I01097
num_objs 5
set03_V003_I00638
num_objs 2
set00_V014_I00170
num_objs 1
set05_V000_I00764
num_objs 1
set04_V003_I01715
num_objs 1
set00_V012_I01565
num_objs 2
set00_V013_I00467
num_objs 2
set04_V005_I01649
num_objs 2
set03_V009_I00686
num_objs 3
set04_V007_I00632
num_objs 2
set04_V003_I00536
num_objs 0
set04_V008_I01331
num_objs 1
set04_V006_I01112
num_objs 1
set00_V007_I00605
num_objs 3
set05_V005_I01190
num_objs 1
set00_V008_I00110
num_objs 6
set00_V012_I00587
num_objs 0
set00_V011_I01367
num_objs 1
set04_V004_I01436
num_objs 1
set03_V005_I01670
num_objs 1
set05_V011_I01070
num_objs 7
set00_V002_I00521
num_objs 0
set00_V002_I00491
num_objs 0
set04_V005_I01586
num_objs 2
set02_V009_I00593
num_objs 2
set02_V010_I01157
num_objs 1
set02_V010_I01478
num_objs 2
set03_V008_I00668
num_objs 4
set03_V002_I01499
num_objs 1
set04_V004_I00935
num_objs 2
set05_V011_I00530
num_objs 1
set02_V010_I01307
num_objs 1
set01_V001_I00230
num_objs 1
set01_V004_I00008
num_objs 2
set03_V009_I00125
num_objs 5
set04_V006_I01538
num_objs 1
set01_V002_I01838
num_objs 6
set00_V000_I00968
num_objs 0
set04_V003_I00140
num_objs 0
set00_V006_I00713
num_objs 2
set04_V002_I01556
num_objs 1
set00_V008_I00623
num_objs 4
set00_V010_I00476
num_objs 7
set05_V002_I01541
num_objs 1
set00_V001_I01529
num_objs 0
set02_V010_I01226
num_objs 1
set04_V000_I00959
num_objs 1
set01_V000_I00161
num_objs 1
set05_V000_I00215
num_objs 2
set00_V008_I00095
num_objs 7
set04_V004_I01271
num_objs 1
set00_V001_I00911
num_objs 4
set04_V011_I00386
num_objs 1
set04_V008_I01001
num_objs 1
set01_V002_I01295
num_objs 5
set01_V000_I00437
num_objs 3
set03_V009_I00584
num_objs 4
set02_V009_I01235
num_objs 2
set00_V014_I00938
num_objs 3
set00_V002_I00143
num_objs 1
set02_V010_I01583
num_objs 1
set04_V005_I00881
num_objs 1
set00_V009_I00434
num_objs 2
set05_V000_I01715
num_objs 1
set02_V011_I01358
num_objs 2
set05_V001_I00410
num_objs 0
set01_V001_I01358
num_objs 9
set05_V002_I00446
num_objs 1
set02_V011_I00644
num_objs 2
set02_V007_I00452
num_objs 1
set00_V008_I00926
num_objs 1
set04_V004_I00431
num_objs 2
set02_V003_I00227
num_objs 1
set03_V011_I01373
num_objs 1
set03_V008_I00050
num_objs 4
set05_V010_I00902
num_objs 2
set00_V009_I01088
num_objs 1
set03_V003_I01136
num_objs 2
set00_V001_I01667
num_objs 1
set00_V008_I00464
num_objs 8
set01_V001_I01751
num_objs 1
set03_V006_I00068
num_objs 1
set00_V004_I00191
num_objs 1
set05_V000_I00182
num_objs 2
set03_V003_I00464
num_objs 2
set00_V013_I00944
num_objs 1
set05_V012_I00266
num_objs 1
set00_V013_I00029
num_objs 3
set04_V003_I00083
num_objs 0
set00_V011_I00617
num_objs 3
set02_V007_I00326
num_objs 1
set04_V008_I00998
num_objs 1
set01_V001_I01166
num_objs 3
set03_V001_I00833
num_objs 1
set00_V013_I00221
num_objs 4
set05_V011_I01412
num_objs 3
set02_V009_I00893
num_objs 1
set01_V004_I00758
num_objs 2
set01_V002_I00332
num_objs 7
set01_V005_I00707
num_objs 2
set00_V007_I01628
num_objs 5
set01_V005_I01361
num_objs 1
set00_V006_I01262
num_objs 6
set01_V002_I00893
num_objs 4
set02_V003_I00068
num_objs 1
set03_V009_I00089
num_objs 1
set00_V013_I01643
num_objs 2
set03_V009_I01310
num_objs 0
set02_V009_I00587
num_objs 2
set00_V013_I01076
num_objs 2
set04_V003_I00182
num_objs 0
set04_V007_I01667
num_objs 1
set00_V003_I00401
num_objs 0
set00_V001_I01097
num_objs 8
set01_V002_I01367
num_objs 2
set02_V010_I01592
num_objs 1
set01_V005_I01403
num_objs 0
set01_V001_I00746
num_objs 2
set01_V000_I01286
num_objs 3
set00_V006_I01736
num_objs 0
set04_V003_I01601
num_objs 1
set00_V002_I00749
num_objs 0
set05_V005_I00923
num_objs 1
set04_V007_I01421
num_objs 1
set00_V000_I01565
num_objs 2
set05_V007_I01196
num_objs 1
set00_V006_I00806
num_objs 3
set01_V004_I01157
num_objs 2
set00_V010_I01058
num_objs 0
set01_V002_I01202
num_objs 3
set02_V010_I01712
num_objs 1
set04_V000_I00677
num_objs 3
set01_V001_I01577
num_objs 7
set05_V010_I01505
num_objs 1
set00_V008_I00500
num_objs 4
set01_V005_I00284
num_objs 1
set00_V000_I00164
num_objs 2
set04_V011_I01550
num_objs 1
set03_V005_I00455
num_objs 2
set03_V005_I01208
num_objs 3
set00_V009_I01334
num_objs 1
set01_V001_I01631
num_objs 5
set00_V001_I01445
num_objs 4
set05_V001_I00455
num_objs 0
set05_V000_I00131
num_objs 4
set03_V009_I01727
num_objs 4
set04_V003_I00359
num_objs 0
set03_V009_I00410
num_objs 3
set05_V004_I00455
num_objs 2
set00_V002_I01208
num_objs 1
set04_V007_I00524
num_objs 1
set04_V004_I01442
num_objs 1
set00_V013_I00329
num_objs 5
set04_V003_I01469
num_objs 0
set00_V008_I00011
num_objs 4
set02_V001_I01652
num_objs 1
set03_V003_I00656
num_objs 2
set04_V003_I00020
num_objs 0
set01_V005_I00068
num_objs 2
set00_V001_I00788
num_objs 3
set01_V000_I01310
num_objs 3
set00_V002_I00407
num_objs 0
set00_V001_I00179
num_objs 0
set05_V012_I00296
num_objs 1
set00_V006_I00962
num_objs 1
set01_V002_I01745
num_objs 5
set05_V005_I00467
num_objs 1
set03_V010_I01742
num_objs 3
set00_V007_I00581
num_objs 4
set04_V007_I00650
num_objs 2
set00_V012_I00437
num_objs 0
set00_V011_I00650
num_objs 3
set05_V008_I01826
num_objs 1
set01_V005_I00392
num_objs 4
set05_V010_I01637
num_objs 1
set00_V012_I00719
num_objs 2
set05_V007_I01508
num_objs 1
set03_V008_I01175
num_objs 1
set02_V001_I01577
num_objs 2
set00_V006_I01328
num_objs 4
set02_V009_I01487
num_objs 1
set03_V002_I01436
num_objs 1
set02_V010_I01709
num_objs 0
set00_V007_I00371
num_objs 6
set02_V009_I00686
num_objs 2
set03_V004_I00230
num_objs 1
set00_V014_I01568
num_objs 5
set02_V010_I00881
num_objs 1
set01_V002_I00293
num_objs 8
set00_V003_I00437
num_objs 1
set01_V002_I00119
num_objs 2
set05_V002_I00131
num_objs 1
set00_V007_I01901
num_objs 3
set02_V007_I00425
num_objs 1
set02_V009_I01076
num_objs 1
set03_V009_I00752
num_objs 2
set00_V010_I00353
num_objs 5
set00_V001_I00569
num_objs 1
set04_V010_I00647
num_objs 1
set00_V014_I01181
num_objs 4
set04_V001_I01721
num_objs 1
set04_V010_I01646
num_objs 2
set04_V007_I01223
num_objs 1
set00_V002_I00527
num_objs 0
set01_V001_I00119
num_objs 1
set00_V004_I01166
num_objs 0
set05_V005_I00116
num_objs 3
set04_V007_I01403
num_objs 1
set01_V002_I01817
num_objs 4
set03_V012_I01292
num_objs 0
set01_V005_I00074
num_objs 2
set02_V009_I01169
num_objs 0
set03_V011_I00185
num_objs 3
set01_V003_I00794
num_objs 0
set01_V003_I01715
num_objs 3
set04_V007_I01754
num_objs 1
set01_V000_I00509
num_objs 0
set03_V003_I00623
num_objs 2
set00_V010_I00149
num_objs 3
set04_V007_I00245
num_objs 2
set00_V009_I00818
num_objs 2
set01_V001_I00518
num_objs 4
set00_V008_I01466
num_objs 1
set00_V000_I01004
num_objs 0
set01_V002_I00227
num_objs 7
set04_V003_I01472
num_objs 2
set02_V009_I01298
num_objs 1
set00_V004_I01058
num_objs 1
set00_V010_I01397
num_objs 3
set00_V010_I00077
num_objs 4
set00_V008_I01283
num_objs 1
set01_V000_I00647
num_objs 0
set02_V010_I00026
num_objs 0
set02_V010_I01379
num_objs 0
set00_V010_I01022
num_objs 0
set05_V012_I00404
num_objs 3
set04_V000_I00764
num_objs 3
set01_V001_I00200
num_objs 2
set04_V006_I00899
num_objs 0
set00_V007_I00155
num_objs 1
set00_V008_I01289
num_objs 1
set05_V002_I00485
num_objs 1
set03_V012_I01484
num_objs 3
set03_V003_I01421
num_objs 2
set04_V007_I01439
num_objs 0
set05_V000_I01343
num_objs 1
set04_V005_I00968
num_objs 1
set04_V007_I01199
num_objs 1
set00_V001_I00029
num_objs 2
set04_V006_I00509
num_objs 0
set03_V011_I00230
num_objs 3
set00_V011_I00260
num_objs 1
set01_V003_I00686
num_objs 2
set03_V012_I01475
num_objs 3
set04_V011_I00323
num_objs 1
set00_V001_I01337
num_objs 3
set00_V010_I00176
num_objs 1
set02_V010_I01721
num_objs 1
set03_V010_I01385
num_objs 2
set03_V009_I00695
num_objs 2
set05_V005_I00017
num_objs 3
set04_V004_I01307
num_objs 1
set00_V002_I00836
num_objs 7
set03_V005_I00986
num_objs 1
set00_V010_I00722
num_objs 2
set00_V013_I01577
num_objs 3
set01_V002_I00794
num_objs 8
set00_V013_I01394
num_objs 2
set00_V011_I01145
num_objs 5
set01_V001_I01553
num_objs 8
set04_V007_I00242
num_objs 2
set00_V006_I01796
num_objs 0
set03_V005_I00641
num_objs 2
set03_V005_I00458
num_objs 2
set04_V000_I00749
num_objs 0
set01_V004_I01256
num_objs 0
set05_V005_I00089
num_objs 1
set00_V013_I01265
num_objs 1
set01_V001_I00269
num_objs 1
set05_V007_I01340
num_objs 1
set00_V008_I00920
num_objs 1
set01_V005_I00662
num_objs 2
set00_V007_I00344
num_objs 5
set00_V002_I00356
num_objs 1
set02_V010_I00476
num_objs 1
set00_V004_I00821
num_objs 1
set03_V003_I01013
num_objs 2
set00_V001_I00554
num_objs 3
set00_V013_I01142
num_objs 4
set00_V000_I01097
num_objs 0
set05_V005_I00587
num_objs 1
set01_V005_I01712
num_objs 0
set00_V006_I01055
num_objs 4
set02_V009_I01148
num_objs 1
set05_V005_I00059
num_objs 2
set02_V009_I01730
num_objs 1
set02_V010_I00977
num_objs 1
set04_V004_I00698
num_objs 2
set01_V002_I00425
num_objs 5
set04_V008_I01526
num_objs 1
set03_V005_I00740
num_objs 1
set00_V003_I00002
num_objs 1
set00_V012_I01568
num_objs 2
set04_V003_I00446
num_objs 0
set05_V005_I00887
num_objs 1
set03_V002_I01511
num_objs 1
set00_V008_I01268
num_objs 2
set00_V007_I01265
num_objs 8
set01_V004_I00236
num_objs 1
set00_V008_I00995
num_objs 1
set04_V005_I01181
num_objs 1
set01_V005_I00008
num_objs 2
set04_V003_I00311
num_objs 1
set05_V004_I01046
num_objs 1
set01_V004_I00842
num_objs 2
set03_V009_I00548
num_objs 4
set00_V002_I01196
num_objs 0
set01_V002_I01097
num_objs 3
set00_V010_I00275
num_objs 3
set02_V007_I00173
num_objs 1
set03_V003_I00551
num_objs 2
set04_V004_I01004
num_objs 2
set00_V011_I00506
num_objs 5
set00_V006_I01730
num_objs 0
set05_V000_I01616
num_objs 1
set00_V000_I00131
num_objs 1
set01_V003_I01775
num_objs 1
set03_V009_I01469
num_objs 1
set05_V004_I00221
num_objs 3
set05_V005_I00122
num_objs 3
set02_V003_I00713
num_objs 2
set02_V009_I01595
num_objs 2
set05_V003_I01652
num_objs 0
set00_V014_I00023
num_objs 3
set05_V012_I00254
num_objs 1
set01_V005_I00944
num_objs 3
set01_V003_I01355
num_objs 1
set05_V002_I00725
num_objs 1
set00_V009_I00713
num_objs 4
set03_V005_I00725
num_objs 1
set00_V014_I01526
num_objs 3
set04_V001_I01712
num_objs 2
set00_V012_I01520
num_objs 1
set04_V003_I01139
num_objs 3
set03_V009_I01331
num_objs 0
set02_V010_I00194
num_objs 1
set04_V003_I01340
num_objs 3
set02_V007_I00347
num_objs 1
set04_V000_I00512
num_objs 2
set00_V009_I00917
num_objs 2
set05_V000_I01493
num_objs 1
set00_V010_I00098
num_objs 4
set04_V007_I00857
num_objs 2
set05_V012_I01097
num_objs 1
set04_V007_I00713
num_objs 2
set00_V002_I01073
num_objs 0
set04_V001_I00182
num_objs 1
set01_V000_I01139
num_objs 1
set03_V008_I00461
num_objs 18
set01_V001_I00161
num_objs 3
set03_V006_I01706
num_objs 1
set01_V002_I01235
num_objs 4
set05_V010_I00848
num_objs 1
set01_V001_I00656
num_objs 3
set02_V007_I00278
num_objs 1
set05_V000_I01718
num_objs 1
set04_V011_I01610
num_objs 1
set05_V005_I01244
num_objs 1
set00_V008_I00083
num_objs 6
set04_V007_I01388
num_objs 1
set01_V004_I01181
num_objs 1
set05_V012_I00566
num_objs 0
set00_V009_I00605
num_objs 2
set00_V010_I01196
num_objs 2
set02_V011_I01643
num_objs 2
set00_V009_I01502
num_objs 3
set00_V013_I00326
num_objs 6
set04_V010_I00827
num_objs 1
set04_V007_I01091
num_objs 2
set00_V008_I00371
num_objs 2
set01_V002_I01550
num_objs 1
set00_V003_I00074
num_objs 1
set04_V011_I01775
num_objs 1
set00_V001_I01748
num_objs 1
set05_V010_I00950
num_objs 1
set01_V003_I00266
num_objs 4
set00_V012_I00401
num_objs 0
set01_V000_I01559
num_objs 3
set00_V012_I01688
num_objs 1
set00_V002_I01076
num_objs 0
set00_V014_I00071
num_objs 4
set01_V004_I00869
num_objs 5
set00_V001_I00827
num_objs 3
set03_V010_I01763
num_objs 3
set01_V002_I00698
num_objs 6
set05_V007_I01790
num_objs 0
set05_V002_I00761
num_objs 1
set04_V002_I00074
num_objs 1
set01_V002_I01232
num_objs 4
set02_V011_I00281
num_objs 0
set04_V003_I00968
num_objs 4
set00_V013_I00449
num_objs 2
set02_V011_I01445
num_objs 2
set04_V002_I01535
num_objs 3
set04_V007_I00752
num_objs 2
set01_V002_I01376
num_objs 2
set03_V010_I01625
num_objs 2
set00_V014_I01154
num_objs 3
set04_V007_I00347
num_objs 1
set01_V003_I00227
num_objs 7
set01_V004_I00881
num_objs 2
set05_V012_I00278
num_objs 1
set00_V000_I01034
num_objs 0
set00_V008_I00716
num_objs 3
set00_V007_I00545
num_objs 5
set05_V011_I01493
num_objs 2
set03_V010_I00971
num_objs 3
set00_V012_I01343
num_objs 0
set01_V001_I01076
num_objs 1
set01_V000_I01355
num_objs 4
set05_V012_I00398
num_objs 3
set00_V001_I01475
num_objs 5
set03_V009_I00767
num_objs 1
set04_V003_I01439
num_objs 1
set00_V003_I00062
num_objs 0
set00_V009_I01274
num_objs 1
set00_V009_I01382
num_objs 0
set01_V003_I00629
num_objs 3
set00_V007_I01136
num_objs 9
set05_V012_I01157
num_objs 1
set04_V004_I00284
num_objs 2
set03_V003_I01376
num_objs 2
set01_V000_I01217
num_objs 3
set03_V001_I00797
num_objs 1
set00_V012_I00716
num_objs 0
set00_V011_I00254
num_objs 1
set05_V003_I01160
num_objs 1
set03_V011_I00722
num_objs 1
set05_V000_I00320
num_objs 3
set01_V001_I01106
num_objs 1
set03_V009_I01502
num_objs 2
set00_V010_I00005
num_objs 5
set00_V009_I01376
num_objs 0
set05_V002_I00737
num_objs 1
set04_V011_I01844
num_objs 1
set01_V003_I01550
num_objs 1
set05_V000_I00179
num_objs 1
set00_V002_I00461
num_objs 0
set04_V003_I00533
num_objs 0
set01_V003_I00053
num_objs 5
set03_V010_I00950
num_objs 1
set04_V002_I01148
num_objs 2
set02_V010_I00596
num_objs 2
set00_V012_I01556
num_objs 2
set04_V003_I00212
num_objs 0
set03_V009_I00932
num_objs 4
set05_V009_I00806
num_objs 1
set00_V011_I00407
num_objs 5
set04_V007_I01511
num_objs 1
set00_V010_I00539
num_objs 5
set04_V003_I00281
num_objs 1
set00_V011_I00446
num_objs 6
set03_V009_I01109
num_objs 5
set05_V011_I01283
num_objs 2
set04_V011_I01175
num_objs 1
set03_V005_I01835
num_objs 2
set02_V011_I01754
num_objs 2
set00_V013_I01067
num_objs 2
set00_V013_I00734
num_objs 1
set00_V009_I00602
num_objs 2
set05_V012_I00461
num_objs 3
set04_V003_I01142
num_objs 3
set02_V003_I00005
num_objs 1
set04_V008_I01535
num_objs 1
set04_V003_I01745
num_objs 2
set03_V003_I00878
num_objs 2
set00_V008_I00647
num_objs 3
set04_V008_I01553
num_objs 1
set01_V005_I01154
num_objs 3
set01_V005_I00155
num_objs 2
set00_V008_I00116
num_objs 6
set05_V000_I00272
num_objs 2
set02_V009_I01490
num_objs 1
set00_V011_I00422
num_objs 5
set01_V003_I00905
num_objs 2
set03_V009_I00230
num_objs 5
set04_V003_I00761
num_objs 1
set01_V005_I00308
num_objs 2
set04_V007_I00866
num_objs 2
set02_V011_I00962
num_objs 1
set05_V011_I01397
num_objs 2
set00_V010_I00497
num_objs 4
set02_V007_I00371
num_objs 1
set03_V011_I01400
num_objs 1
set05_V003_I01058
num_objs 1
set01_V000_I00254
num_objs 1
set03_V009_I01490
num_objs 2
set03_V008_I00620
num_objs 7
set04_V006_I00566
num_objs 1
set00_V008_I01361
num_objs 1
set00_V010_I01538
num_objs 3
set02_V009_I01817
num_objs 2
set05_V004_I01034
num_objs 1
set04_V004_I00611
num_objs 2
set04_V005_I01022
num_objs 3
set01_V005_I01565
num_objs 0
set00_V011_I00992
num_objs 11
set03_V008_I01331
num_objs 3
set04_V007_I01700
num_objs 1
set05_V007_I01658
num_objs 0
set03_V011_I00494
num_objs 5
set05_V011_I00938
num_objs 8
set02_V010_I00479
num_objs 1
set03_V005_I01238
num_objs 2
set04_V000_I00719
num_objs 1
set00_V004_I00401
num_objs 1
set02_V001_I01544
num_objs 1
set04_V002_I00653
num_objs 2
set00_V007_I01799
num_objs 1
set00_V001_I01571
num_objs 3
set00_V007_I01160
num_objs 9
set05_V003_I01052
num_objs 1
set05_V003_I01019
num_objs 1
set01_V005_I00122
num_objs 2
set00_V008_I00422
num_objs 3
set04_V004_I00551
num_objs 3
set02_V009_I00284
num_objs 1
set05_V009_I00839
num_objs 1
set02_V001_I01655
num_objs 1
set04_V006_I00572
num_objs 1
set00_V000_I00680
num_objs 1
set05_V010_I01052
num_objs 1
set00_V010_I00941
num_objs 1
set00_V013_I00371
num_objs 4
set02_V007_I00506
num_objs 1
set02_V010_I01091
num_objs 1
set03_V011_I01241
num_objs 1
set00_V013_I00350
num_objs 4
set05_V011_I00686
num_objs 2
set01_V000_I01361
num_objs 4
set02_V011_I00809
num_objs 0
set03_V012_I01421
num_objs 3
set01_V003_I00005
num_objs 4
set00_V012_I01046
num_objs 0
set04_V004_I00296
num_objs 1
set05_V011_I01151
num_objs 5
set04_V002_I01358
num_objs 2
set03_V011_I00572
num_objs 4
set00_V006_I00455
num_objs 5
set01_V001_I01835
num_objs 1
set00_V009_I00203
num_objs 7
set01_V005_I01253
num_objs 1
set03_V006_I00008
num_objs 1
set00_V009_I00878
num_objs 5
set00_V006_I00797
num_objs 2
set01_V002_I00437
num_objs 5
set00_V014_I01178
num_objs 4
set04_V006_I00527
num_objs 1
set02_V007_I00209
num_objs 0
set04_V008_I00986
num_objs 1
set01_V003_I01619
num_objs 3
set03_V004_I00062
num_objs 1
set03_V008_I00143
num_objs 11
set01_V001_I00347
num_objs 4
set04_V011_I00314
num_objs 1
set00_V010_I01463
num_objs 4
set00_V010_I00968
num_objs 1
set02_V009_I00719
num_objs 2
set00_V011_I00044
num_objs 5
set00_V013_I01664
num_objs 1
set05_V004_I00446
num_objs 2
set03_V005_I01373
num_objs 1
set02_V011_I01796
num_objs 2
set03_V010_I01472
num_objs 2
set00_V004_I01085
num_objs 1
set04_V004_I01145
num_objs 3
set03_V003_I00116
num_objs 2
set02_V009_I01334
num_objs 1
set01_V004_I01379
num_objs 3
set04_V007_I01244
num_objs 1
set03_V002_I01604
num_objs 1
set00_V007_I01490
num_objs 4
set01_V001_I00503
num_objs 3
set02_V009_I00926
num_objs 1
set05_V003_I01301
num_objs 2
set00_V014_I01748
num_objs 1
set00_V008_I00263
num_objs 0
set03_V003_I01472
num_objs 2
set05_V002_I01601
num_objs 1
set01_V001_I01424
num_objs 12
set00_V008_I00875
num_objs 1
set03_V008_I00164
num_objs 12
set00_V007_I01286
num_objs 8
set03_V008_I00173
num_objs 12
set02_V011_I01559
num_objs 2
set02_V007_I00125
num_objs 1
set00_V001_I01526
num_objs 5
set01_V004_I00026
num_objs 2
set00_V000_I00989
num_objs 0
set00_V007_I01397
num_objs 4
set02_V010_I01820
num_objs 1
set02_V009_I01103
num_objs 1
set01_V002_I01469
num_objs 1
set01_V005_I00077
num_objs 2
set05_V001_I00467
num_objs 0
set03_V005_I01598
num_objs 1
set04_V005_I00812
num_objs 1
set00_V006_I00026
num_objs 1
set00_V014_I00335
num_objs 3
set02_V010_I00710
num_objs 2
set02_V003_I00044
num_objs 1
set01_V003_I00437
num_objs 4
set04_V004_I00626
num_objs 2
set04_V007_I01751
num_objs 1
set05_V010_I00329
num_objs 0
set02_V010_I01070
num_objs 1
set03_V008_I01208
num_objs 2
set03_V009_I00299
num_objs 2
set03_V011_I00695
num_objs 1
set05_V003_I01277
num_objs 2
set03_V003_I01154
num_objs 2
set05_V007_I01778
num_objs 0
set02_V011_I01364
num_objs 2
set00_V010_I00800
num_objs 4
set01_V001_I00299
num_objs 0
set05_V002_I00560
num_objs 1
set00_V004_I01097
num_objs 1
set03_V009_I00077
num_objs 5
set00_V007_I01421
num_objs 5
set00_V007_I01220
num_objs 8
set00_V010_I00977
num_objs 1
set01_V005_I00182
num_objs 2
set00_V012_I00998
num_objs 2
set03_V005_I01517
num_objs 1
set05_V012_I01031
num_objs 1
set03_V004_I00551
num_objs 1
set01_V005_I00560
num_objs 2
set03_V004_I00236
num_objs 1
set01_V002_I01331
num_objs 6
set00_V010_I01448
num_objs 4
set01_V001_I00812
num_objs 1
set03_V012_I00815
num_objs 1
set00_V014_I00605
num_objs 5
set00_V008_I01391
num_objs 1
set05_V010_I01091
num_objs 1
set00_V010_I00314
num_objs 3
set00_V006_I01127
num_objs 8
set00_V000_I00485
num_objs 1
set05_V000_I00515
num_objs 3
set00_V014_I01130
num_objs 3
set03_V009_I00062
num_objs 5
set01_V001_I01397
num_objs 9
set01_V004_I00530
num_objs 1
set00_V009_I01400
num_objs 1
set00_V013_I00806
num_objs 1
set04_V002_I01346
num_objs 2
set01_V000_I00944
num_objs 2
set01_V001_I01820
num_objs 1
set02_V009_I00614
num_objs 2
set05_V010_I00686
num_objs 1
set04_V002_I01400
num_objs 3
set00_V004_I01487
num_objs 0
set00_V009_I00653
num_objs 2
set00_V005_I00866
num_objs 1
set00_V012_I00509
num_objs 3
set03_V003_I00419
num_objs 1
set00_V008_I00947
num_objs 1
set00_V008_I00722
num_objs 3
set00_V006_I00578
num_objs 5
set02_V009_I01544
num_objs 1
set00_V001_I00977
num_objs 9
set03_V003_I01184
num_objs 2
set05_V002_I00566
num_objs 1
set00_V013_I00836
num_objs 3
set00_V000_I00161
num_objs 1
set04_V005_I01487
num_objs 1
set04_V005_I00827
num_objs 1
set01_V005_I01049
num_objs 2
set01_V000_I00323
num_objs 1
set00_V008_I00881
num_objs 1
set00_V010_I01502
num_objs 3
set01_V002_I01490
num_objs 0
set02_V011_I00650
num_objs 2
set01_V003_I00965
num_objs 2
set01_V000_I00350
num_objs 2
set00_V012_I01352
num_objs 0
set00_V009_I00098
num_objs 5
set00_V012_I01214
num_objs 0
set01_V005_I00179
num_objs 1
set00_V011_I01028
num_objs 10
set04_V005_I00743
num_objs 1
set04_V002_I00683
num_objs 2
set03_V005_I01028
num_objs 1
set00_V009_I00923
num_objs 2
set02_V008_I00959
num_objs 0
set01_V003_I00314
num_objs 2
set03_V008_I00014
num_objs 3
set00_V014_I00443
num_objs 5
set02_V010_I01055
num_objs 1
set04_V005_I01232
num_objs 2
set03_V008_I00872
num_objs 1
set01_V003_I00152
num_objs 8
set04_V007_I01331
num_objs 1
set01_V002_I01436
num_objs 0
set00_V008_I01442
num_objs 1
set05_V000_I00473
num_objs 3
set03_V003_I01133
num_objs 2
set02_V007_I00275
num_objs 1
set04_V004_I00728
num_objs 2
set00_V002_I01067
num_objs 0
set00_V007_I00974
num_objs 3
set05_V007_I01616
num_objs 0
set05_V004_I01031
num_objs 1
set03_V009_I00563
num_objs 4
set05_V005_I00254
num_objs 1
set01_V003_I00719
num_objs 2
set04_V007_I01265
num_objs 1
set00_V011_I01157
num_objs 5
set01_V000_I00563
num_objs 2
set04_V000_I00584
num_objs 3
set00_V002_I00881
num_objs 8
set00_V009_I00848
num_objs 3
set00_V012_I01175
num_objs 1
set03_V005_I01559
num_objs 0
set02_V008_I00863
num_objs 2
set04_V005_I00299
num_objs 0
set00_V004_I00206
num_objs 1
set01_V003_I00497
num_objs 4
set00_V000_I00986
num_objs 0
set02_V008_I01106
num_objs 0
set00_V001_I01049
num_objs 4
set03_V008_I00731
num_objs 3
set01_V005_I00203
num_objs 2
set00_V002_I00554
num_objs 0
set01_V004_I01622
num_objs 1
set04_V002_I01517
num_objs 3
set03_V012_I01451
num_objs 3
set03_V002_I01673
num_objs 1
set00_V013_I01172
num_objs 1
set01_V003_I00272
num_objs 4
set00_V013_I01343
num_objs 3
set03_V009_I00236
num_objs 5
set05_V005_I00026
num_objs 3
set05_V002_I01178
num_objs 1
set02_V008_I01118
num_objs 0
set00_V002_I00755
num_objs 1
set05_V003_I01235
num_objs 3
set00_V009_I00692
num_objs 4
set02_V009_I01751
num_objs 1
set05_V009_I00800
num_objs 1
set04_V010_I00722
num_objs 1
set00_V014_I00203
num_objs 2
set03_V005_I00761
num_objs 1
set01_V002_I00275
num_objs 8
set00_V012_I00068
num_objs 1
set00_V013_I00218
num_objs 4
set00_V013_I00131
num_objs 4
set00_V001_I01070
num_objs 11
set01_V000_I01106
num_objs 2
set04_V002_I00635
num_objs 1
set03_V010_I01439
num_objs 1
set01_V003_I00026
num_objs 4
set01_V004_I00521
num_objs 1
set00_V013_I00968
num_objs 1
set00_V006_I00107
num_objs 2
set05_V011_I00539
num_objs 0
set00_V009_I00881
num_objs 6
set03_V005_I01658
num_objs 1
set01_V002_I00248
num_objs 7
set00_V012_I00158
num_objs 1
set05_V011_I01364
num_objs 1
set03_V008_I00152
num_objs 12
set02_V009_I01577
num_objs 1
set04_V001_I01553
num_objs 2
set00_V014_I00302
num_objs 4
set01_V002_I01226
num_objs 4
set01_V000_I00419
num_objs 1
set01_V004_I01067
num_objs 3
set00_V002_I00938
num_objs 2
set03_V009_I01799
num_objs 2
set04_V011_I01736
num_objs 1
set04_V004_I00992
num_objs 2
set00_V008_I00107
num_objs 7
set05_V011_I00803
num_objs 5
set00_V001_I01481
num_objs 5
set00_V014_I01106
num_objs 3
set00_V010_I00101
num_objs 4
set04_V008_I01142
num_objs 1
set01_V001_I01229
num_objs 2
set01_V003_I00224
num_objs 7
set04_V007_I01472
num_objs 1
set03_V005_I01262
num_objs 2
set05_V005_I00572
num_objs 1
set04_V010_I00488
num_objs 1
set00_V009_I01631
num_objs 3
set00_V013_I00089
num_objs 4
set00_V003_I00128
num_objs 2
set00_V011_I00050
num_objs 4
set05_V000_I00581
num_objs 1
set00_V010_I00899
num_objs 2
set00_V008_I00254
num_objs 0
set05_V000_I01604
num_objs 1
set05_V012_I00677
num_objs 1
set02_V009_I00647
num_objs 2
set00_V011_I00662
num_objs 3
set05_V010_I01502
num_objs 1
set01_V002_I00773
num_objs 7
set00_V011_I00437
num_objs 6
set00_V004_I01187
num_objs 0
set01_V001_I00956
num_objs 1
set03_V004_I00116
num_objs 1
set03_V010_I00152
num_objs 2
set00_V012_I00182
num_objs 1
set04_V004_I01214
num_objs 3
set00_V009_I01550
num_objs 3
set01_V005_I00353
num_objs 3
set05_V000_I01376
num_objs 2
set05_V011_I01511
num_objs 2
set00_V006_I01427
num_objs 4
set02_V009_I01559
num_objs 0
set04_V002_I01091
num_objs 2
set00_V011_I00764
num_objs 1
set04_V003_I01070
num_objs 4
set03_V005_I01265
num_objs 2
set05_V000_I00719
num_objs 0
set01_V004_I00752
num_objs 3
set03_V012_I01220
num_objs 1
set01_V005_I01136
num_objs 4
set03_V011_I00602
num_objs 4
set00_V006_I00401
num_objs 4
set05_V003_I01028
num_objs 1
set05_V003_I01775
num_objs 0
set04_V010_I01547
num_objs 2
set01_V005_I01541
num_objs 0
set00_V006_I00854
num_objs 1
set00_V006_I00740
num_objs 0
set03_V005_I01415
num_objs 1
set04_V000_I00641
num_objs 3
set00_V006_I01403
num_objs 4
set05_V011_I01424
num_objs 3
set02_V010_I00947
num_objs 1
set00_V006_I00140
num_objs 3
set05_V012_I00431
num_objs 3
set01_V004_I00560
num_objs 1
set02_V001_I00335
num_objs 1
set03_V005_I00926
num_objs 1
set01_V002_I01826
num_objs 4
set00_V012_I01412
num_objs 2
set01_V005_I01718
num_objs 0
set01_V003_I00188
num_objs 8
set00_V014_I00002
num_objs 4
set05_V012_I00716
num_objs 2
set05_V012_I00314
num_objs 1
set01_V004_I01478
num_objs 2
set00_V010_I00446
num_objs 7
set01_V001_I01721
num_objs 2
set00_V002_I00509
num_objs 0
set04_V007_I01553
num_objs 1
set01_V001_I00398
num_objs 4
set05_V002_I01151
num_objs 1
set01_V003_I01820
num_objs 1
set01_V000_I00659
num_objs 1
set00_V006_I00593
num_objs 5
set05_V011_I00599
num_objs 2
set05_V010_I01607
num_objs 1
set00_V004_I00359
num_objs 1
set02_V010_I00146
num_objs 1
set05_V012_I01235
num_objs 1
set00_V011_I00482
num_objs 5
set04_V002_I01607
num_objs 2
set04_V002_I01100
num_objs 2
set01_V005_I00680
num_objs 2
set00_V011_I01370
num_objs 1
set00_V014_I00350
num_objs 3
set03_V003_I01475
num_objs 2
set04_V004_I01772
num_objs 1
set02_V011_I01664
num_objs 2
set03_V011_I00149
num_objs 0
set03_V009_I01112
num_objs 6
set02_V010_I01352
num_objs 1
set04_V010_I00530
num_objs 1
set05_V004_I01022
num_objs 1
set02_V011_I01349
num_objs 0
set05_V010_I01085
num_objs 1
set05_V003_I01688
num_objs 0
set05_V005_I00365
num_objs 2
set04_V005_I01217
num_objs 1
set05_V010_I00713
num_objs 1
set00_V001_I00317
num_objs 5
set00_V011_I00035
num_objs 5
set01_V001_I01013
num_objs 1
set00_V007_I01337
num_objs 6
set03_V003_I01109
num_objs 1
set04_V002_I01028
num_objs 2
set04_V002_I00752
num_objs 2
set03_V009_I01826
num_objs 4
set05_V010_I01109
num_objs 0
set03_V008_I01091
num_objs 1
set02_V011_I00413
num_objs 2
set03_V012_I00851
num_objs 1
set04_V007_I00665
num_objs 2
set03_V008_I01502
num_objs 2
set03_V005_I00299
num_objs 0
set00_V011_I00812
num_objs 1
set00_V006_I01781
num_objs 0
set00_V012_I01103
num_objs 0
set01_V003_I00320
num_objs 2
set02_V011_I00818
num_objs 0
set04_V003_I01535
num_objs 1
set00_V007_I00065
num_objs 1
set00_V013_I01040
num_objs 0
set00_V003_I00038
num_objs 1
set00_V002_I00914
num_objs 5
set00_V007_I01010
num_objs 1
set04_V007_I01118
num_objs 2
set00_V013_I00275
num_objs 5
set03_V008_I01418
num_objs 3
set04_V003_I01367
num_objs 3
set05_V004_I00977
num_objs 1
set05_V000_I00299
num_objs 1
set01_V003_I00977
num_objs 1
set03_V012_I01394
num_objs 5
set02_V001_I01580
num_objs 2
set01_V004_I00302
num_objs 1
set04_V003_I01766
num_objs 2
set04_V011_I01052
num_objs 2
set01_V000_I01007
num_objs 0
set00_V011_I01181
num_objs 4
set01_V000_I00134
num_objs 1
set03_V011_I00215
num_objs 3
set05_V003_I01079
num_objs 1
set04_V004_I01376
num_objs 1
set04_V011_I01622
num_objs 1
set03_V005_I01661
num_objs 1
set02_V009_I00209
num_objs 0
set01_V002_I00038
num_objs 2
set00_V008_I00338
num_objs 0
set00_V000_I00542
num_objs 1
set01_V004_I00788
num_objs 2
set05_V002_I00707
num_objs 1
set00_V007_I01358
num_objs 6
set00_V007_I00095
num_objs 1
set01_V000_I00929
num_objs 3
set05_V001_I00404
num_objs 0
set00_V008_I01322
num_objs 0
set00_V009_I01430
num_objs 1
set00_V011_I00137
num_objs 2
set01_V000_I01289
num_objs 3
set04_V006_I00848
num_objs 2
set00_V006_I01382
num_objs 5
set01_V000_I00458
num_objs 2
set00_V001_I01379
num_objs 2
set05_V005_I01277
num_objs 1
set05_V005_I00434
num_objs 1
set03_V002_I01445
num_objs 1
set04_V001_I01676
num_objs 2
set00_V002_I00821
num_objs 8
set01_V000_I00044
num_objs 1
set04_V010_I00443
num_objs 1
set03_V009_I00599
num_objs 3
set03_V009_I00890
num_objs 3
set05_V005_I01103
num_objs 1
set04_V004_I00821
num_objs 2
set00_V013_I01502
num_objs 4
set00_V012_I01109
num_objs 2
set00_V006_I01583
num_objs 2
set01_V002_I00944
num_objs 4
set04_V003_I00464
num_objs 0
set01_V003_I00662
num_objs 2
set05_V011_I01634
num_objs 1
set03_V003_I01181
num_objs 2
set00_V000_I01301
num_objs 1
set00_V003_I00428
num_objs 1
set02_V010_I01358
num_objs 1
set05_V010_I00023
num_objs 1
set04_V004_I01430
num_objs 1
set04_V007_I01565
num_objs 1
set02_V009_I00308
num_objs 1
set05_V000_I00287
num_objs 2
set00_V009_I01541
num_objs 4
set03_V003_I00242
num_objs 1
set00_V006_I00038
num_objs 2
set00_V001_I00065
num_objs 1
set00_V013_I00668
num_objs 2
set03_V003_I01148
num_objs 2
set03_V008_I01514
num_objs 2
set03_V005_I00335
num_objs 2
set03_V001_I00119
num_objs 1
set02_V011_I01409
num_objs 0
set03_V005_I00917
num_objs 1
set04_V008_I01439
num_objs 0
set00_V004_I01463
num_objs 0
set01_V005_I00368
num_objs 3
set01_V003_I00251
num_objs 4
set04_V005_I01433
num_objs 2
set03_V009_I01343
num_objs 1
set02_V007_I00104
num_objs 1
set00_V007_I01919
num_objs 0
set00_V006_I00533
num_objs 3
set04_V004_I00173
num_objs 2
set01_V001_I00122
num_objs 4
set01_V005_I00938
num_objs 3
set01_V001_I01490
num_objs 11
set00_V012_I01607
num_objs 1
set04_V005_I00776
num_objs 1
set00_V010_I01322
num_objs 2
set03_V008_I01340
num_objs 3
set04_V007_I01712
num_objs 1
set00_V013_I01088
num_objs 3
set00_V001_I01037
num_objs 13
set04_V008_I01541
num_objs 1
set01_V003_I01082
num_objs 0
set03_V011_I01343
num_objs 1
set03_V003_I00668
num_objs 2
set00_V012_I00233
num_objs 2
set04_V001_I01733
num_objs 1
set00_V011_I00647
num_objs 3
set05_V002_I00548
num_objs 1
set00_V000_I01604
num_objs 2
set03_V005_I00392
num_objs 2
set00_V014_I01037
num_objs 3
set00_V008_I00179
num_objs 2
set01_V002_I00710
num_objs 6
set02_V009_I00881
num_objs 1
set05_V011_I01514
num_objs 2
set00_V009_I00461
num_objs 2
set04_V010_I00983
num_objs 1
set01_V005_I01061
num_objs 3
set03_V009_I00065
num_objs 5
set03_V003_I01295
num_objs 2
set00_V001_I01205
num_objs 4
set00_V006_I00290
num_objs 4
set02_V009_I00413
num_objs 1
set03_V003_I00515
num_objs 2
set00_V006_I01115
num_objs 9
set03_V009_I01067
num_objs 6
set00_V002_I00707
num_objs 1
set00_V014_I01523
num_objs 3
set00_V007_I00287
num_objs 6
set00_V008_I00215
num_objs 0
set03_V003_I00173
num_objs 1
set00_V009_I00191
num_objs 5
set00_V011_I01121
num_objs 6
set03_V011_I00314
num_objs 4
set01_V001_I00989
num_objs 0
set00_V006_I00587
num_objs 5
set03_V003_I00467
num_objs 2
set04_V005_I00728
num_objs 1
set02_V009_I00227
num_objs 2
set02_V010_I00188
num_objs 1
set01_V002_I00527
num_objs 8
set05_V010_I01010
num_objs 1
set02_V009_I01721
num_objs 1
set00_V001_I00926
num_objs 6
set01_V005_I01475
num_objs 0
set01_V001_I01394
num_objs 9
set00_V006_I00440
num_objs 4
set04_V008_I01103
num_objs 1
set00_V001_I00293
num_objs 5
set01_V005_I01340
num_objs 1
set00_V002_I00251
num_objs 2
set03_V012_I00944
num_objs 1
set00_V013_I01478
num_objs 4
set03_V012_I01253
num_objs 0
set00_V000_I00785
num_objs 0
set01_V000_I00395
num_objs 2
set00_V014_I01661
num_objs 4
set03_V003_I00770
num_objs 2
set03_V005_I01412
num_objs 1
set01_V005_I01559
num_objs 0
set00_V004_I00242
num_objs 1
set00_V006_I00359
num_objs 1
set05_V000_I00782
num_objs 1
set01_V003_I00263
num_objs 4
set00_V007_I01505
num_objs 4
set04_V001_I00164
num_objs 1
set05_V012_I01040
num_objs 1
set01_V001_I00866
num_objs 1
set05_V004_I00110
num_objs 3
set01_V000_I00779
num_objs 0
set03_V003_I00647
num_objs 2
set02_V001_I00332
num_objs 1
set04_V000_I00554
num_objs 3
set01_V002_I00956
num_objs 4
set00_V004_I01373
num_objs 1
set04_V007_I00725
num_objs 2
set03_V006_I00065
num_objs 1
set01_V005_I00986
num_objs 3
set00_V006_I01271
num_objs 6
set00_V000_I01121
num_objs 0
set03_V005_I01472
num_objs 1
set00_V001_I00683
num_objs 3
set05_V012_I00488
num_objs 3
set05_V003_I01613
num_objs 0
set00_V011_I00716
num_objs 4
set04_V011_I01763
num_objs 1
set04_V004_I00629
num_objs 0
set00_V000_I00113
num_objs 1
set00_V001_I00734
num_objs 3
set01_V000_I01367
num_objs 4
set05_V012_I00377
num_objs 3
set01_V001_I00878
num_objs 1
set03_V005_I00863
num_objs 1
set00_V004_I01685
num_objs 1
set01_V004_I01577
num_objs 1
set04_V010_I01622
num_objs 2
set05_V010_I01811
num_objs 0
set04_V003_I00125
num_objs 0
set03_V005_I00590
num_objs 3
set01_V003_I01526
num_objs 1
set04_V011_I01535
num_objs 1
set00_V008_I00428
num_objs 3
set01_V005_I01130
num_objs 4
set00_V001_I01190
num_objs 3
set05_V000_I00770
num_objs 1
set02_V008_I01259
num_objs 1
set01_V001_I01841
num_objs 1
set00_V014_I01259
num_objs 0
set03_V008_I00974
num_objs 1
set00_V009_I00110
num_objs 3
set05_V005_I00380
num_objs 1
set00_V003_I00059
num_objs 0
set03_V008_I00899
num_objs 9
set01_V004_I01538
num_objs 2
set00_V010_I01346
num_objs 5
set01_V004_I00491
num_objs 1
set04_V010_I00449
num_objs 1
set02_V008_I01265
num_objs 1
set04_V004_I01295
num_objs 1
set03_V011_I00197
num_objs 3
set03_V001_I00104
num_objs 1
set04_V010_I00437
num_objs 1
set03_V009_I00491
num_objs 3
set00_V013_I00188
num_objs 4
set00_V011_I00743
num_objs 2
set00_V000_I01070
num_objs 0
set03_V002_I01658
num_objs 2
set03_V008_I00590
num_objs 9
set04_V002_I00608
num_objs 1
set04_V007_I01442
num_objs 1
set00_V000_I01172
num_objs 1
set01_V005_I00731
num_objs 2
set05_V005_I01022
num_objs 1
set00_V007_I00374
num_objs 6
set00_V010_I00032
num_objs 4
set00_V013_I00701
num_objs 1
set00_V009_I00749
num_objs 5
set00_V013_I00869
num_objs 1
set04_V011_I01055
num_objs 2
set00_V009_I00533
num_objs 2
set05_V002_I00590
num_objs 1
set04_V001_I01598
num_objs 2
set03_V009_I00962
num_objs 2
set00_V004_I00779
num_objs 1
set04_V001_I01763
num_objs 1
set04_V007_I00503
num_objs 1
set01_V003_I00791
num_objs 0
set00_V012_I00065
num_objs 1
set03_V001_I00047
num_objs 1
set00_V011_I01109
num_objs 9
set00_V007_I01169
num_objs 5
set03_V005_I00257
num_objs 1
set05_V009_I00803
num_objs 1
set00_V014_I01886
num_objs 1
set00_V004_I00971
num_objs 3
set05_V003_I01796
num_objs 0
set05_V011_I00845
num_objs 7
set04_V003_I00053
num_objs 0
set04_V005_I01682
num_objs 0
set01_V004_I00233
num_objs 1
set02_V010_I01442
num_objs 1
set02_V010_I00419
num_objs 0
set03_V009_I00944
num_objs 4
set04_V007_I00506
num_objs 1
set05_V007_I01373
num_objs 1
set05_V002_I01523
num_objs 1
set05_V002_I01577
num_objs 1
set04_V002_I01235
num_objs 2
set02_V003_I00704
num_objs 2
set03_V011_I00479
num_objs 3
set03_V012_I01580
num_objs 3
set02_V010_I01523
num_objs 1
set01_V005_I00878
num_objs 2
set03_V006_I01799
num_objs 0
set03_V003_I00137
num_objs 2
set02_V010_I00074
num_objs 1
set02_V011_I01412
num_objs 2
set04_V002_I00116
num_objs 0
set04_V007_I00326
num_objs 1
set05_V010_I00026
num_objs 1
set05_V011_I00944
num_objs 8
set03_V003_I00983
num_objs 2
set05_V011_I01700
num_objs 1
set02_V011_I01541
num_objs 2
set00_V012_I01685
num_objs 1
set04_V006_I00578
num_objs 1
set03_V003_I01481
num_objs 2
set00_V001_I01487
num_objs 5
set05_V005_I01007
num_objs 1
set00_V012_I00476
num_objs 1
set00_V007_I00722
num_objs 1
set03_V002_I01562
num_objs 1
set03_V009_I00032
num_objs 3
set00_V007_I00995
num_objs 2
set01_V001_I01829
num_objs 0
set01_V000_I00821
num_objs 1
set03_V004_I00125
num_objs 1
set02_V009_I00326
num_objs 2
set00_V007_I01646
num_objs 4
set01_V000_I01292
num_objs 3
set01_V000_I00608
num_objs 4
set01_V001_I01460
num_objs 12
set04_V007_I00560
num_objs 1
set04_V005_I01007
num_objs 3
set03_V003_I00209
num_objs 1
set04_V007_I01484
num_objs 1
set00_V012_I00950
num_objs 6
set04_V006_I01643
num_objs 1
set05_V009_I00962
num_objs 1
set03_V011_I00956
num_objs 1
set03_V009_I01211
num_objs 2
set04_V010_I00533
num_objs 1
set00_V013_I00680
num_objs 1
set01_V003_I00119
num_objs 11
set02_V011_I01313
num_objs 1
set04_V005_I01559
num_objs 0
set00_V008_I01073
num_objs 1
set00_V007_I01754
num_objs 5
set04_V004_I00710
num_objs 2
set05_V009_I00791
num_objs 1
set01_V002_I00449
num_objs 2
set00_V008_I01376
num_objs 1
set03_V009_I00071
num_objs 5
set03_V012_I01619
num_objs 1
set00_V007_I00647
num_objs 2
set00_V006_I01421
num_objs 4
set00_V004_I01229
num_objs 13
set02_V009_I00890
num_objs 1
set04_V008_I01118
num_objs 1
set00_V014_I01898
num_objs 1
set04_V004_I01733
num_objs 1
set04_V005_I00128
num_objs 1
set00_V006_I00299
num_objs 3
set05_V007_I01502
num_objs 1
set00_V001_I01004
num_objs 12
set04_V010_I00584
num_objs 1
set04_V007_I01151
num_objs 2
set00_V007_I01865
num_objs 7
set00_V009_I00449
num_objs 1
set00_V009_I01466
num_objs 2
set00_V013_I01136
num_objs 4
set05_V007_I01700
num_objs 0
set03_V012_I01499
num_objs 1
set05_V003_I01664
num_objs 0
set00_V012_I01544
num_objs 2
set00_V001_I00227
num_objs 6
set04_V007_I01031
num_objs 2
set05_V000_I00698
num_objs 1
set01_V005_I00362
num_objs 3
set03_V003_I00053
num_objs 2
set04_V005_I00059
num_objs 1
set04_V003_I01061
num_objs 4
set01_V005_I00449
num_objs 2
set00_V013_I01184
num_objs 0
set00_V011_I00062
num_objs 4
set00_V006_I00404
num_objs 3
set03_V009_I01256
num_objs 3
set00_V004_I01079
num_objs 1
set01_V005_I00023
num_objs 2
set00_V007_I01127
num_objs 10
set03_V009_I01667
num_objs 3
set04_V000_I00623
num_objs 3
set04_V004_I00494
num_objs 3
set00_V004_I01691
num_objs 1
set03_V009_I01133
num_objs 4
set00_V011_I00080
num_objs 4
set02_V010_I00869
num_objs 0
set00_V009_I00620
num_objs 2
set04_V007_I00422
num_objs 1
set04_V002_I01031
num_objs 2
set01_V005_I00215
num_objs 2
set00_V005_I00845
num_objs 2
set04_V003_I00458
num_objs 0
set00_V007_I00914
num_objs 3
set03_V003_I00626
num_objs 2
set02_V001_I01562
num_objs 2
set03_V008_I00176
num_objs 12
set01_V003_I00650
num_objs 2
set01_V001_I01616
num_objs 3
set00_V001_I01757
num_objs 2
set05_V010_I01583
num_objs 1
set03_V005_I01829
num_objs 1
set01_V005_I00119
num_objs 1
set00_V008_I00638
num_objs 4
set03_V010_I01580
num_objs 3
set05_V005_I00023
num_objs 3
set04_V006_I00974
num_objs 2
set00_V010_I01664
num_objs 1
set00_V001_I01175
num_objs 3
set01_V004_I01187
num_objs 0
set00_V007_I01388
num_objs 3
set02_V010_I01637
num_objs 1
set00_V007_I00143
num_objs 1
set00_V014_I00227
num_objs 3
set04_V002_I00779
num_objs 1
set03_V004_I00584
num_objs 1
set04_V004_I00377
num_objs 1
set00_V002_I00302
num_objs 1
set05_V005_I01085
num_objs 1
set02_V003_I00269
num_objs 0
set02_V009_I00203
num_objs 2
set00_V011_I01262
num_objs 3
set04_V000_I00530
num_objs 2
set00_V007_I01211
num_objs 7
set02_V010_I01652
num_objs 1
set00_V000_I01331
num_objs 1
set04_V008_I01319
num_objs 0
set03_V009_I00626
num_objs 4
set00_V002_I00920
num_objs 4
set00_V011_I00731
num_objs 2
set00_V013_I01358
num_objs 3
set00_V002_I00440
num_objs 0
set05_V011_I00899
num_objs 5
set00_V011_I01502
num_objs 4
set02_V008_I00554
num_objs 1
set03_V003_I01127
num_objs 2
set00_V008_I00593
num_objs 5
set00_V000_I01502
num_objs 1
set01_V001_I00623
num_objs 3
set04_V004_I00761
num_objs 2
set00_V000_I00185
num_objs 3
set00_V014_I00689
num_objs 6
set03_V003_I00887
num_objs 2
set00_V004_I00368
num_objs 2
set03_V009_I00602
num_objs 4
set00_V012_I01652
num_objs 1
set00_V006_I01418
num_objs 4
set03_V007_I00350
num_objs 1
set00_V009_I00338
num_objs 5
set02_V011_I01283
num_objs 1
set04_V008_I01106
num_objs 1
set05_V011_I01280
num_objs 3
set02_V003_I00122
num_objs 1
set03_V003_I00317
num_objs 1
set05_V012_I00500
num_objs 2
set00_V004_I00914
num_objs 2
set05_V010_I00581
num_objs 1
set05_V004_I00287
num_objs 1
set00_V001_I00758
num_objs 3
set00_V011_I00113
num_objs 4
set04_V011_I01514
num_objs 1
set02_V009_I00536
num_objs 2
set03_V011_I01394
num_objs 1
set03_V010_I01637
num_objs 3
set00_V014_I00971
num_objs 4
set04_V002_I01253
num_objs 2
set00_V002_I00680
num_objs 1
set00_V003_I00467
num_objs 1
set00_V014_I00977
num_objs 4
set05_V002_I00470
num_objs 1
set03_V006_I00179
num_objs 0
set00_V001_I00395
num_objs 3
set00_V008_I01493
num_objs 3
set02_V011_I01736
num_objs 2
set02_V009_I01217
num_objs 2
set00_V013_I01124
num_objs 4
set00_V006_I00329
num_objs 3
set05_V002_I00710
num_objs 1
set01_V001_I01256
num_objs 11
set03_V002_I01484
num_objs 1
set04_V002_I00998
num_objs 2
set04_V011_I01187
num_objs 1
set02_V011_I01403
num_objs 2
set02_V009_I01181
num_objs 2
set03_V012_I01274
num_objs 0
set01_V001_I01703
num_objs 2
set02_V007_I00479
num_objs 1
set03_V012_I01256
num_objs 0
set01_V000_I01379
num_objs 3
set04_V008_I01457
num_objs 1
set00_V010_I00281
num_objs 3
set05_V011_I00620
num_objs 4
set00_V004_I01382
num_objs 2
set04_V005_I01535
num_objs 2
set00_V013_I00608
num_objs 3
set00_V009_I00062
num_objs 3
set04_V004_I00566
num_objs 3
set00_V007_I00338
num_objs 6
set00_V013_I00053
num_objs 3
set00_V007_I00437
num_objs 5
set00_V010_I01613
num_objs 0
set04_V005_I00050
num_objs 1
set00_V014_I01538
num_objs 4
set00_V008_I01262
num_objs 2
set02_V008_I01298
num_objs 1
set02_V011_I01694
num_objs 2
set01_V005_I00143
num_objs 2
set02_V011_I00284
num_objs 0
set00_V011_I00848
num_objs 0
set00_V007_I01385
num_objs 3
set01_V002_I00095
num_objs 4
set00_V002_I00719
num_objs 1
set00_V009_I01427
num_objs 1
set03_V003_I01106
num_objs 2
set05_V011_I01682
num_objs 1
set04_V002_I00110
num_objs 0
set01_V002_I00707
num_objs 6
set04_V011_I01106
num_objs 2
set04_V005_I00206
num_objs 1
set01_V001_I01508
num_objs 11
set04_V007_I00521
num_objs 1
set03_V005_I01376
num_objs 1
set03_V003_I00848
num_objs 2
set05_V000_I00566
num_objs 2
set01_V001_I00125
num_objs 4
set01_V005_I00980
num_objs 3
set04_V011_I01742
num_objs 1
set03_V008_I00116
num_objs 11
set00_V013_I00719
num_objs 0
set04_V003_I01448
num_objs 3
set03_V008_I01424
num_objs 3
set02_V010_I01619
num_objs 0
set00_V010_I01457
num_objs 4
set00_V000_I00917
num_objs 0
set04_V007_I01016
num_objs 2
set02_V008_I01091
num_objs 0
set00_V011_I01055
num_objs 9
set04_V004_I00152
num_objs 2
set00_V001_I01229
num_objs 0
set04_V008_I01046
num_objs 1
set03_V005_I00848
num_objs 1
set01_V000_I01088
num_objs 4
set03_V012_I01598
num_objs 3
set05_V011_I01136
num_objs 4
set04_V003_I01214
num_objs 3
set03_V008_I00866
num_objs 1
set03_V003_I00959
num_objs 0
set00_V013_I01514
num_objs 3
set00_V002_I00299
num_objs 1
set05_V004_I00437
num_objs 2
set04_V010_I00452
num_objs 1
set03_V003_I00947
num_objs 2
set03_V002_I01478
num_objs 1
set02_V010_I01751
num_objs 1
set00_V004_I00530
num_objs 1
set00_V000_I00845
num_objs 0
set04_V011_I00362
num_objs 1
set01_V003_I00383
num_objs 3
set00_V014_I01199
num_objs 0
set03_V003_I00665
num_objs 2
set03_V012_I01595
num_objs 3
set05_V005_I01169
num_objs 0
set05_V010_I00971
num_objs 1
set04_V003_I01013
num_objs 4
set04_V003_I01169
num_objs 3
set00_V007_I00725
num_objs 1
set05_V010_I00914
num_objs 2
set04_V007_I01586
num_objs 1
set05_V005_I00815
num_objs 1
set00_V010_I01277
num_objs 3
set05_V002_I00431
num_objs 1
set04_V007_I01406
num_objs 1
set05_V005_I00746
num_objs 1
set04_V005_I00254
num_objs 1
set04_V010_I00428
num_objs 1
set03_V011_I00206
num_objs 3
set04_V006_I01478
num_objs 1
set03_V008_I00101
num_objs 7
set04_V002_I01064
num_objs 2
set02_V009_I00179
num_objs 1
set00_V013_I00620
num_objs 4
set00_V004_I01295
num_objs 0
set03_V010_I01400
num_objs 2
set05_V003_I01589
num_objs 0
set04_V003_I00560
num_objs 0
set00_V012_I01100
num_objs 0
set03_V008_I00527
num_objs 14
set00_V000_I00944
num_objs 0
set04_V011_I01769
num_objs 1
set02_V008_I01847
num_objs 0
set00_V014_I00401
num_objs 5
set02_V001_I01514
num_objs 1
set05_V009_I00728
num_objs 1
set01_V002_I00584
num_objs 8
set03_V003_I00713
num_objs 2
set04_V003_I00167
num_objs 0
set03_V009_I01835
num_objs 4
set02_V010_I00209
num_objs 1
set04_V004_I00227
num_objs 2
set04_V004_I00389
num_objs 0
set01_V004_I01184
num_objs 1
set05_V004_I01028
num_objs 1
set05_V010_I00794
num_objs 1
set00_V001_I00014
num_objs 2
set00_V010_I00608
num_objs 4
set04_V001_I00092
num_objs 1
set04_V005_I01562
num_objs 2
set00_V007_I01565
num_objs 7
set01_V001_I00566
num_objs 4
set05_V007_I01541
num_objs 0
set02_V008_I01199
num_objs 0
set03_V010_I00167
num_objs 2
set02_V010_I00785
num_objs 2
set04_V007_I00626
num_objs 2
set04_V005_I00767
num_objs 1
set03_V011_I00773
num_objs 2
set05_V010_I00689
num_objs 0
set00_V010_I01349
num_objs 7
set05_V005_I00218
num_objs 0
set03_V009_I00218
num_objs 5
set02_V010_I01625
num_objs 1
set04_V007_I00839
num_objs 0
set01_V000_I00668
num_objs 0
set05_V011_I01079
num_objs 4
set03_V006_I00107
num_objs 1
set02_V010_I01256
num_objs 1
set04_V004_I01283
num_objs 1
set01_V003_I01541
num_objs 1
set00_V002_I00830
num_objs 8
set04_V004_I00416
num_objs 2
set00_V001_I00692
num_objs 3
set01_V002_I01352
num_objs 4
set03_V008_I00347
num_objs 18
set00_V009_I01562
num_objs 4
set00_V012_I01454
num_objs 3
set00_V008_I00785
num_objs 2
set02_V010_I01034
num_objs 1
set01_V005_I00527
num_objs 2
set04_V010_I00812
num_objs 1
set02_V010_I01253
num_objs 1
set00_V014_I01001
num_objs 3
set00_V010_I00848
num_objs 3
set01_V005_I01046
num_objs 3
set01_V003_I00656
num_objs 2
set00_V004_I01394
num_objs 2
set01_V001_I00062
num_objs 2
set04_V010_I01673
num_objs 2
set04_V005_I00821
num_objs 1
set02_V010_I01553
num_objs 1
set00_V005_I00803
num_objs 1
set03_V012_I01322
num_objs 4
set00_V000_I00167
num_objs 3
set01_V000_I00554
num_objs 2
set01_V000_I00365
num_objs 2
set04_V004_I01736
num_objs 1
set01_V002_I00743
num_objs 7
set00_V008_I00827
num_objs 1
set05_V011_I00596
num_objs 5
set03_V011_I01349
num_objs 1
set05_V007_I01475
num_objs 1
set01_V001_I01112
num_objs 1
set00_V010_I01541
num_objs 3
set01_V005_I00194
num_objs 2
set04_V005_I00074
num_objs 1
set00_V010_I01586
num_objs 1
set05_V005_I00011
num_objs 3
set04_V001_I00065
num_objs 1
set04_V006_I01043
num_objs 1
set00_V009_I01310
num_objs 1
set03_V011_I01418
num_objs 1
set01_V004_I00623
num_objs 4
set00_V007_I00179
num_objs 0
set04_V002_I01769
num_objs 0
set00_V012_I01082
num_objs 0
set04_V005_I00209
num_objs 0
set00_V014_I01067
num_objs 2
set04_V006_I00842
num_objs 2
set04_V005_I01598
num_objs 2
set00_V013_I00545
num_objs 5
set00_V010_I00773
num_objs 3
set01_V000_I00851
num_objs 0
set01_V003_I00932
num_objs 2
set00_V006_I00377
num_objs 4
set02_V008_I01280
num_objs 1
set05_V010_I00347
num_objs 1
set04_V010_I01613
num_objs 2
set03_V012_I00824
num_objs 1
set04_V001_I01490
num_objs 1
set02_V010_I01541
num_objs 1
set05_V004_I00206
num_objs 3
set02_V011_I00665
num_objs 2
set05_V010_I00392
num_objs 2
set00_V002_I00437
num_objs 0
set01_V005_I00635
num_objs 3
set04_V002_I00830
num_objs 1
set00_V006_I00644
num_objs 2
set00_V004_I00998
num_objs 2
set04_V002_I00956
num_objs 2
set04_V007_I01514
num_objs 1
set00_V006_I00923
num_objs 5
set05_V005_I00416
num_objs 1
set03_V009_I00425
num_objs 3
set03_V012_I01343
num_objs 4
set03_V003_I00176
num_objs 1
set05_V009_I00779
num_objs 0
set05_V010_I00332
num_objs 1
set00_V000_I00665
num_objs 1
set02_V011_I01379
num_objs 2
set02_V009_I01514
num_objs 1
set00_V014_I00764
num_objs 3
set05_V003_I01004
num_objs 1
set05_V011_I01268
num_objs 3
set04_V006_I01052
num_objs 1
set00_V009_I01097
num_objs 1
set01_V004_I00803
num_objs 2
set02_V010_I00116
num_objs 1
set02_V010_I01208
num_objs 1
set05_V012_I00572
num_objs 0
set02_V011_I00542
num_objs 2
set00_V011_I00365
num_objs 3
set03_V002_I01505
num_objs 1
set01_V002_I00872
num_objs 8
set00_V009_I01037
num_objs 1
set04_V006_I00956
num_objs 2
set01_V003_I01538
num_objs 1
set04_V003_I00527
num_objs 0
set05_V004_I00407
num_objs 2
set00_V001_I00707
num_objs 3
set00_V004_I01064
num_objs 1
set01_V003_I01517
num_objs 1
set01_V004_I00704
num_objs 2
set03_V012_I01193
num_objs 1
set01_V002_I00665
num_objs 7
set00_V010_I00128
num_objs 4
set00_V010_I01427
num_objs 4
set03_V010_I01787
num_objs 3
set00_V000_I01772
num_objs 1
set04_V003_I00941
num_objs 1
set04_V007_I00332
num_objs 1
set01_V002_I01178
num_objs 2
set00_V012_I01418
num_objs 2
set03_V011_I00497
num_objs 5
set01_V004_I00221
num_objs 0
set03_V008_I00248
num_objs 18
set02_V003_I00152
num_objs 1
set00_V001_I00542
num_objs 3
set00_V009_I01598
num_objs 4
set04_V010_I01619
num_objs 1
set02_V001_I01415
num_objs 1
set03_V009_I00179
num_objs 2
set03_V008_I00275
num_objs 15
set03_V011_I01154
num_objs 1
set03_V011_I00557
num_objs 5
set01_V002_I00650
num_objs 7
set02_V010_I00200
num_objs 1
set00_V013_I00629
num_objs 1
set00_V011_I00821
num_objs 1
set04_V004_I00800
num_objs 2
set03_V010_I01700
num_objs 3
set00_V011_I00773
num_objs 1
set00_V012_I01220
num_objs 0
set00_V007_I00701
num_objs 1
set04_V005_I00863
num_objs 1
set00_V007_I00989
num_objs 2
set03_V010_I00980
num_objs 3
set04_V002_I01589
num_objs 1
set00_V007_I01847
num_objs 5
set00_V013_I00548
num_objs 3
set01_V005_I01757
num_objs 0
set00_V004_I01646
num_objs 1
set01_V003_I00236
num_objs 6
set03_V003_I01274
num_objs 2
set03_V008_I01433
num_objs 3
set01_V003_I00215
num_objs 7
set00_V007_I00689
num_objs 1
set01_V002_I01073
num_objs 3
set02_V009_I01607
num_objs 2
set03_V009_I01634
num_objs 2
set03_V011_I00983
num_objs 1
set02_V011_I01748
num_objs 2
set01_V001_I00485
num_objs 4
set05_V010_I01658
num_objs 1
set00_V010_I00116
num_objs 3
set00_V001_I00098
num_objs 3
set00_V012_I01208
num_objs 0
set04_V007_I01706
num_objs 1
set04_V004_I00722
num_objs 2
set04_V007_I00461
num_objs 1
set04_V004_I00155
num_objs 2
set03_V005_I00830
num_objs 1
set02_V008_I01835
num_objs 0
set00_V004_I00887
num_objs 2
set03_V010_I01577
num_objs 3
set01_V001_I01238
num_objs 10
set01_V003_I01256
num_objs 1
set01_V003_I00101
num_objs 5
set00_V001_I00878
num_objs 3
set03_V005_I00488
num_objs 2
set00_V001_I01373
num_objs 3
set05_V010_I00092
num_objs 1
set03_V003_I00659
num_objs 0
set01_V003_I00950
num_objs 2
set00_V000_I01112
num_objs 0
set03_V005_I00449
num_objs 2
set01_V003_I00968
num_objs 2
set01_V001_I00674
num_objs 3
set03_V008_I00272
num_objs 14
set03_V008_I00512
num_objs 16
set00_V000_I01286
num_objs 1
set00_V002_I00545
num_objs 0
set00_V014_I00584
num_objs 5
set00_V008_I00803
num_objs 2
set00_V012_I00377
num_objs 0
set00_V002_I00239
num_objs 2
set01_V005_I01568
num_objs 0
set03_V010_I00119
num_objs 0
set05_V011_I00848
num_objs 7
set04_V007_I00398
num_objs 1
set04_V005_I01061
num_objs 3
set02_V003_I00224
num_objs 1
set00_V014_I01808
num_objs 2
set00_V008_I01076
num_objs 0
set02_V001_I01547
num_objs 1
set00_V007_I00452
num_objs 5
set00_V009_I00077
num_objs 5
set00_V000_I01187
num_objs 1
set00_V001_I00632
num_objs 5
set00_V009_I00113
num_objs 3
set04_V003_I00233
num_objs 1
set05_V005_I01253
num_objs 1
set00_V012_I01256
num_objs 0
set03_V003_I00788
num_objs 2
set01_V000_I01598
num_objs 4
set01_V005_I00506
num_objs 2
set00_V014_I00503
num_objs 5
set04_V004_I01397
num_objs 1
set00_V001_I01661
num_objs 1
set01_V002_I01289
num_objs 5
set00_V006_I00158
num_objs 3
set00_V001_I01334
num_objs 3
set00_V007_I00869
num_objs 2
set05_V011_I00860
num_objs 9
set04_V004_I00449
num_objs 2
set04_V003_I00248
num_objs 1
set03_V008_I01811
num_objs 1
set00_V007_I00401
num_objs 6
set04_V004_I01412
num_objs 1
set00_V009_I01325
num_objs 1
set03_V009_I01544
num_objs 2
set04_V005_I01160
num_objs 1
set00_V002_I00287
num_objs 1
set00_V001_I00308
num_objs 6
set05_V000_I00305
num_objs 4
set00_V014_I00896
num_objs 4
set04_V007_I00566
num_objs 1
set01_V000_I00077
num_objs 3
set00_V002_I00116
num_objs 1
set03_V009_I01187
num_objs 3
set00_V007_I01361
num_objs 5
set05_V007_I01391
num_objs 1
set03_V003_I01418
num_objs 2
set04_V002_I01313
num_objs 2
set05_V001_I00143
num_objs 1
set00_V002_I00335
num_objs 1
set01_V003_I01013
num_objs 2
set04_V005_I00068
num_objs 1
set01_V005_I00221
num_objs 2
set05_V000_I00368
num_objs 3
set00_V000_I01622
num_objs 1
set04_V008_I01097
num_objs 1
set03_V009_I00644
num_objs 3
set00_V012_I00893
num_objs 6
set00_V001_I01325
num_objs 4
set04_V004_I00848
num_objs 2
set00_V001_I00116
num_objs 3
set00_V013_I00314
num_objs 6
set01_V001_I01412
num_objs 12
set04_V007_I00956
num_objs 2
set01_V002_I00203
num_objs 7
set04_V008_I01058
num_objs 1
set00_V006_I01925
num_objs 0
set02_V009_I01208
num_objs 2
set02_V003_I00041
num_objs 1
set05_V003_I01091
num_objs 1
set01_V000_I00974
num_objs 0
set03_V001_I00107
num_objs 1
set02_V007_I00167
num_objs 1
set05_V002_I00713
num_objs 1
set02_V008_I01187
num_objs 0
set03_V008_I00656
num_objs 4
set04_V005_I01175
num_objs 1
set01_V001_I01475
num_objs 11
set00_V013_I00146
num_objs 4
set01_V001_I01265
num_objs 11
set03_V003_I01283
num_objs 2
set05_V000_I01589
num_objs 1
set03_V003_I01205
num_objs 2
set00_V013_I01412
num_objs 2
set00_V003_I00005
num_objs 1
set03_V005_I00452
num_objs 2
set03_V012_I01427
num_objs 3
set00_V014_I01775
num_objs 1
set04_V003_I00230
num_objs 1
set05_V000_I00203
num_objs 2
set00_V009_I00737
num_objs 3
set05_V004_I00923
num_objs 2
set00_V014_I00059
num_objs 2
set01_V004_I01136
num_objs 4
set00_V009_I00104
num_objs 4
set03_V003_I01091
num_objs 2
set00_V009_I00188
num_objs 4
set00_V010_I00581
num_objs 5
set05_V007_I01769
num_objs 0
set01_V002_I00221
num_objs 7
set04_V005_I00272
num_objs 1
set03_V005_I01214
num_objs 3
set00_V001_I00329
num_objs 4
set05_V000_I01625
num_objs 1
set04_V005_I00836
num_objs 1
set03_V001_I00140
num_objs 1
set05_V011_I00611
num_objs 4
set01_V000_I01448
num_objs 5
set00_V008_I00455
num_objs 8
set01_V004_I01130
num_objs 4
set04_V002_I00122
num_objs 0
set00_V010_I00062
num_objs 3
set05_V004_I00911
num_objs 1
set04_V010_I00935
num_objs 1
set00_V006_I01025
num_objs 1
set03_V011_I00833
num_objs 2
set02_V008_I01142
num_objs 0
set00_V013_I00536
num_objs 5
set01_V004_I01490
num_objs 2
set02_V007_I00353
num_objs 1
set03_V004_I00170
num_objs 1
set01_V003_I00863
num_objs 1
set00_V000_I00416
num_objs 5
set00_V001_I00254
num_objs 5
set03_V004_I00455
num_objs 1
set01_V005_I00050
num_objs 2
set01_V000_I00146
num_objs 1
set01_V000_I01313
num_objs 4
set03_V011_I00626
num_objs 3
set05_V011_I01223
num_objs 3
set05_V011_I01475
num_objs 3
set04_V003_I01274
num_objs 3
set04_V005_I00977
num_objs 2
set00_V000_I01142
num_objs 0
set02_V009_I00710
num_objs 2
set01_V002_I01130
num_objs 1
set05_V011_I00542
num_objs 1
set05_V011_I01388
num_objs 2
set02_V011_I00830
num_objs 1
set03_V005_I01037
num_objs 1
set01_V005_I00629
num_objs 3
set01_V003_I00692
num_objs 2
set05_V000_I01580
num_objs 1
set05_V010_I00047
num_objs 1
set01_V002_I00239
num_objs 1
set04_V001_I01616
num_objs 2
set01_V000_I01529
num_objs 2
set00_V010_I00416
num_objs 8
set04_V010_I00464
num_objs 1
set05_V004_I00164
num_objs 3
set00_V009_I00056
num_objs 3
set04_V011_I01832
num_objs 1
set01_V001_I01652
num_objs 3
set03_V011_I01262
num_objs 1
set05_V001_I00398
num_objs 0
set01_V000_I00398
num_objs 2
set03_V008_I00662
num_objs 4
set05_V011_I01001
num_objs 8
set01_V001_I01496
num_objs 11
set01_V002_I00572
num_objs 8
set00_V013_I00389
num_objs 4
set05_V011_I01535
num_objs 1
set03_V007_I00326
num_objs 1
set00_V007_I01688
num_objs 5
set02_V011_I01343
num_objs 1
set03_V011_I00770
num_objs 2
set01_V003_I00755
num_objs 2
set04_V001_I00047
num_objs 1
set03_V009_I01541
num_objs 2
set02_V011_I00563
num_objs 2
set02_V009_I01568
num_objs 1
set00_V008_I00128
num_objs 5
set04_V002_I01307
num_objs 2
set03_V005_I00887
num_objs 1
set00_V010_I00407
num_objs 8
set04_V011_I00380
num_objs 1
set00_V002_I00875
num_objs 8
set03_V012_I00026
num_objs 1
set03_V002_I01466
num_objs 1
set05_V007_I01739
num_objs 0
set02_V009_I00590
num_objs 2
set00_V009_I00149
num_objs 1
set05_V004_I00461
num_objs 2
set05_V011_I01373
num_objs 2
set03_V005_I00797
num_objs 1
set02_V009_I01691
num_objs 1
set00_V012_I00152
num_objs 1
set03_V003_I00326
num_objs 1
set00_V007_I00227
num_objs 5
set04_V004_I01373
num_objs 1
set04_V004_I00323
num_objs 0
set00_V009_I00053
num_objs 3
set00_V004_I01688
num_objs 1
set00_V004_I01340
num_objs 1
set02_V009_I00113
num_objs 1
set00_V000_I00851
num_objs 0
set05_V010_I00617
num_objs 1
set02_V009_I00791
num_objs 2
set00_V004_I01169
num_objs 9
set00_V006_I00701
num_objs 2
set01_V001_I00842
num_objs 1
set02_V011_I00467
num_objs 1
set03_V010_I01490
num_objs 2
set03_V009_I01142
num_objs 2
set02_V009_I01154
num_objs 1
set01_V005_I00359
num_objs 2
set00_V013_I00002
num_objs 4
set00_V014_I01769
num_objs 3
set00_V006_I00755
num_objs 0
set05_V007_I01469
num_objs 1
set02_V009_I01748
num_objs 1
set03_V008_I00263
num_objs 17
set01_V005_I00575
num_objs 3
set04_V004_I00875
num_objs 2
set04_V011_I01817
num_objs 1
set01_V002_I00266
num_objs 8
set05_V000_I00485
num_objs 3
set01_V001_I01712
num_objs 2
set01_V001_I01811
num_objs 1
set00_V011_I01478
num_objs 3
set00_V010_I00332
num_objs 5
set01_V004_I01349
num_objs 2
set00_V000_I00953
num_objs 0
set04_V008_I01505
num_objs 1
set04_V002_I01199
num_objs 1
set03_V008_I00224
num_objs 13
set04_V007_I00254
num_objs 2
set00_V013_I00551
num_objs 3
set00_V011_I01169
num_objs 8
set04_V010_I00641
num_objs 1
set04_V005_I00176
num_objs 1
set00_V002_I00434
num_objs 0
set00_V011_I00467
num_objs 6
set03_V001_I00122
num_objs 1
set00_V002_I01271
num_objs 0
set02_V009_I00467
num_objs 1
set03_V009_I01814
num_objs 4
set05_V002_I01127
num_objs 2
set04_V002_I01019
num_objs 2
set03_V005_I01370
num_objs 1
set03_V011_I00422
num_objs 5
set01_V003_I01808
num_objs 1
set01_V005_I00545
num_objs 2
set02_V003_I00182
num_objs 1
set05_V010_I00080
num_objs 1
set00_V006_I01478
num_objs 3
set00_V007_I00992
num_objs 2
set00_V004_I01418
num_objs 2
set03_V004_I00503
num_objs 1
set05_V003_I01778
num_objs 0
set00_V014_I01784
num_objs 1
set00_V011_I01493
num_objs 3
set04_V003_I01307
num_objs 4
set00_V007_I01199
num_objs 6
set02_V009_I01697
num_objs 1
set00_V013_I01190
num_objs 0
set04_V011_I01751
num_objs 1
set03_V005_I01532
num_objs 1
set04_V005_I00317
num_objs 1
set00_V009_I01655
num_objs 2
set00_V007_I01643
num_objs 4
set01_V004_I01241
num_objs 0
set01_V005_I00104
num_objs 2
set05_V002_I00752
num_objs 1
set03_V008_I01754
num_objs 1
set00_V009_I01040
num_objs 1
set05_V003_I01346
num_objs 2
set00_V013_I00281
num_objs 5
set00_V007_I00767
num_objs 2
set04_V000_I00575
num_objs 3
set01_V000_I00530
num_objs 2
set00_V012_I01172
num_objs 1
set02_V009_I01538
num_objs 1
set04_V004_I00674
num_objs 2
set01_V002_I01337
num_objs 5
set04_V000_I00725
num_objs 3
set01_V005_I00482
num_objs 3
set00_V006_I01442
num_objs 3
set04_V010_I01577
num_objs 2
set00_V009_I00464
num_objs 2
set04_V005_I01004
num_objs 3
set00_V009_I00287
num_objs 5
set05_V012_I01238
num_objs 1
set01_V002_I00188
num_objs 7
set02_V011_I00395
num_objs 2
set00_V004_I00974
num_objs 3
set01_V001_I01031
num_objs 1
set00_V002_I01250
num_objs 0
set01_V002_I01802
num_objs 4
set04_V004_I00326
num_objs 0
set05_V010_I00812
num_objs 2
set00_V008_I00656
num_objs 3
set01_V002_I00419
num_objs 3
set04_V004_I00242
num_objs 1
set00_V000_I00497
num_objs 1
set05_V005_I00581
num_objs 1
set04_V007_I00563
num_objs 1
set00_V003_I00134
num_objs 2
set01_V003_I00032
num_objs 4
set03_V006_I01814
num_objs 1
set03_V005_I01049
num_objs 0
set03_V005_I01334
num_objs 1
set00_V000_I00293
num_objs 3
set04_V003_I01157
num_objs 3
set01_V000_I01085
num_objs 4
set04_V002_I01223
num_objs 2
set04_V003_I01604
num_objs 1
set05_V007_I01193
num_objs 1
set00_V001_I00125
num_objs 2
set00_V014_I00353
num_objs 3
set04_V007_I01454
num_objs 1
set00_V014_I01520
num_objs 3
set01_V004_I00878
num_objs 2
set00_V007_I01430
num_objs 4
set04_V007_I01343
num_objs 1
set04_V004_I01049
num_objs 2
set05_V010_I00875
num_objs 1
set01_V001_I00185
num_objs 2
set03_V008_I01067
num_objs 1
set02_V001_I01427
num_objs 1
set00_V000_I01589
num_objs 2
set00_V009_I00851
num_objs 3
set03_V008_I00125
num_objs 11
set00_V007_I00860
num_objs 3
set01_V002_I00617
num_objs 7
set00_V010_I01256
num_objs 3
set04_V011_I00998
num_objs 2
set04_V007_I00740
num_objs 2
set03_V011_I01244
num_objs 1
set02_V009_I01667
num_objs 1
set04_V005_I01253
num_objs 1
set00_V009_I00242
num_objs 7
set01_V005_I00920
num_objs 3
set01_V002_I00356
num_objs 5
set04_V004_I00185
num_objs 2
set03_V009_I01103
num_objs 6
set01_V000_I00917
num_objs 3
set05_V002_I00437
num_objs 1
set02_V011_I01499
num_objs 0
set01_V004_I01142
num_objs 4
set01_V001_I01760
num_objs 1
set00_V007_I01022
num_objs 1
set03_V005_I00395
num_objs 2
set00_V012_I01628
num_objs 1
set03_V011_I00716
num_objs 1
set02_V008_I00869
num_objs 2
set03_V003_I00599
num_objs 0
set05_V000_I00533
num_objs 3
set00_V012_I01382
num_objs 1
set04_V005_I00119
num_objs 0
set04_V007_I01463
num_objs 1
set00_V000_I01052
num_objs 0
set05_V009_I00749
num_objs 0
set01_V004_I01274
num_objs 1
set04_V003_I00428
num_objs 1
set02_V010_I01268
num_objs 1
set00_V013_I00584
num_objs 3
set04_V000_I00947
num_objs 1
set00_V011_I01217
num_objs 3
set04_V002_I01184
num_objs 2
set00_V001_I00701
num_objs 3
set01_V003_I00752
num_objs 2
set00_V002_I00737
num_objs 2
set04_V007_I00329
num_objs 0
set03_V005_I00428
num_objs 2
set04_V010_I01589
num_objs 2
set00_V012_I01571
num_objs 2
set00_V001_I00404
num_objs 2
set00_V003_I00176
num_objs 1
set01_V001_I01607
num_objs 3
set05_V005_I00374
num_objs 2
set00_V013_I00452
num_objs 2
set04_V002_I01430
num_objs 2
set00_V014_I00458
num_objs 4
set00_V011_I00170
num_objs 3
set05_V012_I00698
num_objs 1
set05_V010_I00878
num_objs 1
set01_V002_I01715
num_objs 5
set02_V009_I01211
num_objs 2
set04_V005_I01676
num_objs 0
set00_V007_I00506
num_objs 4
set04_V001_I00020
num_objs 1
set05_V002_I00593
num_objs 1
set01_V005_I01694
num_objs 0
set01_V004_I01310
num_objs 1
set04_V003_I00332
num_objs 1
set01_V000_I00197
num_objs 1
set00_V013_I00503
num_objs 2
set01_V003_I00860
num_objs 1
set05_V010_I00647
num_objs 1
set00_V008_I01370
num_objs 1
set02_V010_I00944
num_objs 1
set01_V001_I01502
num_objs 11
set00_V014_I01529
num_objs 0
set00_V001_I00572
num_objs 1
set03_V008_I00905
num_objs 1
set02_V010_I01142
num_objs 1
set01_V002_I01787
num_objs 5
set00_V013_I00917
num_objs 1
set05_V002_I00500
num_objs 1
set05_V004_I00497
num_objs 2
set00_V010_I01238
num_objs 3
set00_V002_I00275
num_objs 1
set00_V014_I00941
num_objs 3
set02_V011_I01475
num_objs 2
set03_V006_I01739
num_objs 0
set00_V013_I00380
num_objs 4
set05_V007_I01460
num_objs 1
set05_V005_I01268
num_objs 1
set05_V010_I00923
num_objs 2
set04_V007_I00500
num_objs 1
set03_V010_I01646
num_objs 3
set01_V000_I00080
num_objs 3
set00_V012_I00455
num_objs 0
set05_V005_I00341
num_objs 2
set01_V003_I00116
num_objs 7
set00_V006_I00428
num_objs 2
set04_V003_I01640
num_objs 1
set05_V005_I00080
num_objs 5
set02_V009_I00869
num_objs 1
set00_V012_I00683
num_objs 0
set02_V001_I00164
num_objs 0
set03_V003_I01178
num_objs 2
set01_V004_I00926
num_objs 3
set04_V004_I00947
num_objs 2
set04_V004_I01721
num_objs 1
set03_V009_I00332
num_objs 4
set01_V001_I01085
num_objs 1
set01_V004_I00536
num_objs 1
set04_V005_I01208
num_objs 1
set02_V010_I00398
num_objs 1
set05_V003_I01175
num_objs 3
set05_V011_I00758
num_objs 3
set01_V001_I00020
num_objs 2
set04_V011_I01649
num_objs 1
set03_V010_I01547
num_objs 3
set03_V003_I01502
num_objs 2
set00_V012_I00599
num_objs 0
set00_V014_I00440
num_objs 5
set01_V002_I01478
num_objs 0
set05_V011_I01271
num_objs 3
set01_V000_I00596
num_objs 4
set02_V009_I01109
num_objs 0
set00_V002_I00350
num_objs 1
set02_V007_I00242
num_objs 1
set00_V010_I00668
num_objs 2
set00_V011_I00584
num_objs 3
set00_V013_I01616
num_objs 2
set00_V009_I00440
num_objs 2
set00_V002_I00878
num_objs 8
set02_V010_I00515
num_objs 2
set05_V012_I01232
num_objs 1
set05_V004_I00482
num_objs 2
set03_V002_I01433
num_objs 1
set04_V003_I00101
num_objs 0
set03_V006_I00158
num_objs 1
set04_V005_I01460
num_objs 2
set04_V006_I01559
num_objs 1
set05_V011_I01478
num_objs 3
set04_V001_I01577
num_objs 2
set02_V009_I01412
num_objs 1
set01_V002_I01751
num_objs 5
set04_V004_I00533
num_objs 3
set00_V001_I01736
num_objs 1
set04_V005_I00764
num_objs 1
set00_V011_I00998
num_objs 11
set01_V003_I01745
num_objs 1
set03_V006_I01751
num_objs 1
set00_V000_I01343
num_objs 1
set00_V006_I00620
num_objs 4
set00_V004_I00947
num_objs 2
set03_V002_I01565
num_objs 1
set04_V011_I00332
num_objs 1
set00_V009_I00530
num_objs 2
set04_V006_I00911
num_objs 2
set03_V008_I01547
num_objs 1
set03_V003_I00920
num_objs 2
set03_V008_I00857
num_objs 1
set00_V007_I01040
num_objs 3
set03_V009_I01121
num_objs 6
set02_V009_I00515
num_objs 1
set00_V009_I00542
num_objs 2
set01_V004_I00587
num_objs 2
set00_V013_I00974
num_objs 1
set04_V004_I00332
num_objs 0
set00_V001_I01154
num_objs 4
set02_V010_I01481
num_objs 2
set00_V010_I00092
num_objs 4
set03_V012_I01415
num_objs 4
set02_V010_I01241
num_objs 1
set04_V004_I00671
num_objs 2
set02_V011_I00533
num_objs 2
set00_V008_I00386
num_objs 2
set02_V007_I00959
num_objs 0
set04_V010_I00842
num_objs 2
set00_V001_I00761
num_objs 3
set02_V009_I00860
num_objs 1
set03_V005_I01607
num_objs 1
set00_V010_I01598
num_objs 0
set04_V001_I00059
num_objs 0
set01_V005_I01727
num_objs 0
set03_V005_I01094
num_objs 1
set05_V010_I01064
num_objs 1
set04_V002_I01385
num_objs 3
set04_V011_I01178
num_objs 1
set00_V007_I00980
num_objs 3
set00_V000_I00704
num_objs 2
set01_V005_I00263
num_objs 1
set05_V005_I01043
num_objs 1
set05_V000_I00560
num_objs 2
set05_V012_I00464
num_objs 3
set01_V001_I01592
num_objs 5
set00_V001_I00695
num_objs 3
set04_V001_I01541
num_objs 1
set05_V011_I01697
num_objs 1
set05_V009_I00950
num_objs 1
set01_V001_I01121
num_objs 1
set00_V010_I00437
num_objs 8
set04_V003_I00341
num_objs 1
set00_V014_I01562
num_objs 5
set00_V010_I01400
num_objs 3
set01_V001_I00527
num_objs 3
set00_V014_I01739
num_objs 5
set00_V009_I01373
num_objs 0
set03_V008_I01592
num_objs 2
set00_V000_I01703
num_objs 2
set04_V004_I00737
num_objs 2
set00_V010_I01289
num_objs 5
set02_V007_I00134
num_objs 1
set03_V003_I01082
num_objs 2
set01_V003_I00062
num_objs 5
set00_V001_I01265
num_objs 4
set03_V005_I00971
num_objs 1
set02_V010_I00293
num_objs 1
set01_V005_I00947
num_objs 3
set02_V001_I00149
num_objs 0
set03_V005_I00560
num_objs 3
set00_V001_I01040
num_objs 13
set00_V014_I00491
num_objs 5
set00_V009_I01574
num_objs 4
set05_V002_I00542
num_objs 1
set00_V001_I01133
num_objs 6
set00_V008_I00086
num_objs 6
set05_V005_I00641
num_objs 1
set00_V010_I01271
num_objs 3
set03_V008_I01772
num_objs 2
set05_V010_I01025
num_objs 1
set00_V004_I00803
num_objs 2
set05_V002_I01166
num_objs 1
set00_V013_I00704
num_objs 1
set04_V004_I00248
num_objs 1
set03_V011_I00641
num_objs 3
set03_V009_I01820
num_objs 4
set03_V003_I00068
num_objs 2
set03_V003_I00428
num_objs 1
set03_V005_I00380
num_objs 1
set03_V009_I00395
num_objs 2
set04_V004_I01256
num_objs 1
set04_V010_I00794
num_objs 1
set01_V001_I00023
num_objs 2
set00_V001_I01187
num_objs 3
set03_V012_I01601
num_objs 3
set00_V012_I01019
num_objs 4
set01_V001_I01817
num_objs 1
set04_V007_I01262
num_objs 1
set05_V010_I00569
num_objs 0
set03_V009_I01019
num_objs 1
set05_V004_I00944
num_objs 2
set03_V008_I00575
num_objs 10
set04_V002_I00083
num_objs 1
set05_V012_I01184
num_objs 1
set00_V001_I00917
num_objs 5
set05_V000_I00467
num_objs 3
set00_V007_I00566
num_objs 5
set05_V011_I01592
num_objs 1
set05_V005_I00770
num_objs 1
set05_V012_I00527
num_objs 1
set00_V014_I01595
num_objs 4
set00_V010_I00689
num_objs 2
set00_V008_I00779
num_objs 1
set00_V012_I00302
num_objs 3
set02_V010_I01466
num_objs 1
set05_V003_I01628
num_objs 0
set04_V005_I00986
num_objs 3
set05_V010_I00140
num_objs 1
set02_V003_I00320
num_objs 1
set01_V005_I01736
num_objs 0
set00_V002_I00371
num_objs 1
set05_V005_I00167
num_objs 0
set00_V001_I01352
num_objs 2
set01_V002_I00398
num_objs 5
set00_V011_I00512
num_objs 5
set00_V008_I01037
num_objs 3
set03_V008_I00677
num_objs 3
set05_V011_I00584
num_objs 5
set00_V008_I01016
num_objs 1
set04_V004_I01847
num_objs 1
set00_V000_I01586
num_objs 1
set05_V007_I01379
num_objs 1
set02_V001_I01616
num_objs 1
set01_V000_I01541
num_objs 4
set05_V011_I01406
num_objs 3
set04_V001_I01640
num_objs 3
set00_V007_I00923
num_objs 3
set00_V010_I00749
num_objs 1
set00_V006_I00200
num_objs 3
set01_V001_I00146
num_objs 3
set02_V010_I01610
num_objs 1
set02_V010_I01406
num_objs 1
set02_V010_I01094
num_objs 1
set00_V010_I00572
num_objs 5
set00_V011_I00020
num_objs 5
set03_V006_I01793
num_objs 1
set03_V001_I00113
num_objs 1
set00_V010_I00881
num_objs 2
set05_V011_I01679
num_objs 1
set00_V014_I01385
num_objs 7
set01_V005_I01094
num_objs 3
set04_V002_I00935
num_objs 1
set00_V000_I01817
num_objs 0
set00_V000_I00347
num_objs 2
set00_V012_I01088
num_objs 0
set04_V004_I00425
num_objs 2
set00_V014_I00305
num_objs 5
set01_V000_I00527
num_objs 2
set04_V011_I00395
num_objs 1
set00_V013_I00116
num_objs 4
set00_V011_I01031
num_objs 10
set04_V005_I00116
num_objs 1
set00_V008_I00836
num_objs 1
set03_V011_I00776
num_objs 2
set03_V009_I00116
num_objs 5
set02_V009_I01388
num_objs 1
set03_V003_I00596
num_objs 2
set00_V002_I00188
num_objs 2
set02_V010_I00101
num_objs 1
set05_V004_I00908
num_objs 1
set05_V010_I01523
num_objs 2
set02_V010_I00938
num_objs 1
set00_V013_I00686
num_objs 1
set01_V001_I01154
num_objs 3
set00_V004_I01034
num_objs 0
set03_V003_I00755
num_objs 2
set05_V002_I00677
num_objs 1
set01_V005_I00233
num_objs 1
set03_V011_I00761
num_objs 2
set01_V002_I01277
num_objs 4
set01_V002_I01127
num_objs 2
set01_V003_I01391
num_objs 1
set00_V002_I00254
num_objs 2
set01_V002_I01658
num_objs 4
set00_V011_I01580
num_objs 0
set00_V012_I00389
num_objs 2
set03_V009_I01802
num_objs 4
set05_V009_I00911
num_objs 1
set00_V001_I00104
num_objs 3
set00_V007_I01538
num_objs 4
set00_V002_I00929
num_objs 5
set05_V002_I00440
num_objs 1
set04_V002_I01397
num_objs 3
set04_V003_I00335
num_objs 1
set05_V010_I01814
num_objs 0
set00_V009_I00452
num_objs 2
set01_V005_I00641
num_objs 2
set04_V007_I01757
num_objs 1
set01_V001_I00386
num_objs 4
set00_V009_I01367
num_objs 0
set05_V003_I01334
num_objs 2
set02_V009_I01166
num_objs 2
set02_V011_I01595
num_objs 2
set02_V010_I01397
num_objs 1
set01_V003_I00230
num_objs 7
set05_V011_I00932
num_objs 8
set00_V007_I00488
num_objs 5
set03_V008_I01619
num_objs 2
set04_V008_I01337
num_objs 1
set05_V002_I01520
num_objs 1
set05_V011_I01427
num_objs 3
set00_V009_I00245
num_objs 7
set03_V008_I00356
num_objs 18
set05_V003_I01166
num_objs 2
set02_V010_I01832
num_objs 1
set00_V000_I01076
num_objs 0
set00_V008_I00899
num_objs 1
set00_V014_I01202
num_objs 4
set00_V010_I00290
num_objs 3
set03_V010_I01805
num_objs 2
set00_V007_I01148
num_objs 8
set04_V004_I01265
num_objs 1
set01_V003_I01646
num_objs 2
set00_V000_I00203
num_objs 3
set00_V010_I01625
num_objs 0
set00_V008_I00848
num_objs 1
set03_V005_I01463
num_objs 1
set02_V010_I00278
num_objs 1
set03_V004_I00029
num_objs 0
set00_V013_I00881
num_objs 1
set00_V008_I00473
num_objs 8
set04_V003_I00548
num_objs 0
set05_V000_I00122
num_objs 2
set00_V006_I00632
num_objs 3
set04_V001_I00173
num_objs 1
set02_V011_I00890
num_objs 1
set00_V012_I00776
num_objs 1
set00_V008_I00278
num_objs 0
set03_V009_I01091
num_objs 6
set01_V002_I00590
num_objs 7
set04_V005_I00338
num_objs 1
set00_V012_I01505
num_objs 1
set01_V000_I00056
num_objs 1
set00_V011_I01532
num_objs 1
set04_V008_I01127
num_objs 1
set03_V001_I00815
num_objs 1
set03_V002_I01439
num_objs 1
set01_V000_I01259
num_objs 3
set00_V003_I00473
num_objs 1
set05_V010_I00842
num_objs 1
set05_V002_I01169
num_objs 1
set01_V000_I01190
num_objs 3
set00_V000_I01208
num_objs 2
set01_V002_I00656
num_objs 7
set04_V002_I01805
num_objs 1
set01_V004_I01424
num_objs 1
set01_V003_I00479
num_objs 3
set02_V010_I01598
num_objs 1
set04_V007_I00377
num_objs 1
set03_V005_I00581
num_objs 3
set04_V010_I00716
num_objs 1
set01_V004_I01373
num_objs 1
set00_V008_I01463
num_objs 1
set00_V012_I00317
num_objs 1
set01_V001_I00329
num_objs 0
set05_V005_I00353
num_objs 2
set04_V004_I00773
num_objs 2
set00_V008_I00350
num_objs 0
set00_V006_I01256
num_objs 6
set03_V012_I01448
num_objs 3
set04_V006_I01085
num_objs 1
set00_V012_I00965
num_objs 5
set04_V005_I00293
num_objs 1
set03_V002_I01619
num_objs 1
set01_V001_I00650
num_objs 3
set03_V007_I01550
num_objs 0
set00_V010_I01244
num_objs 3
set05_V005_I00875
num_objs 2
set03_V008_I00041
num_objs 4
set00_V012_I00692
num_objs 0
set00_V004_I00872
num_objs 1
set01_V001_I01163
num_objs 3
set04_V005_I01532
num_objs 2
set03_V011_I01157
num_objs 1
set00_V008_I00776
num_objs 2
set03_V011_I00611
num_objs 4
set02_V009_I00800
num_objs 2
set01_V001_I01073
num_objs 1
set00_V012_I01154
num_objs 0
set00_V013_I00878
num_objs 1
set00_V004_I01643
num_objs 1
set03_V003_I01388
num_objs 2
set01_V002_I00011
num_objs 3
set00_V013_I01430
num_objs 3
set00_V008_I01049
num_objs 2
set00_V000_I01592
num_objs 1
set02_V010_I00395
num_objs 1
set05_V005_I01118
num_objs 1
set01_V000_I01538
num_objs 4
set05_V003_I01712
num_objs 0
set01_V005_I01292
num_objs 1
set02_V009_I01241
num_objs 2
set00_V014_I01310
num_objs 6
set01_V003_I00008
num_objs 4
set04_V004_I01709
num_objs 0
set05_V000_I00290
num_objs 3
set00_V000_I00767
num_objs 1
set00_V012_I00791
num_objs 2
set03_V005_I00647
num_objs 2
set01_V003_I01817
num_objs 1
set00_V014_I01079
num_objs 2
set02_V009_I00917
num_objs 1
set00_V008_I00701
num_objs 3
set04_V003_I01574
num_objs 1
set00_V011_I01460
num_objs 4
set03_V005_I01163
num_objs 2
set04_V002_I01613
num_objs 2
set00_V013_I01604
num_objs 2
set02_V009_I01385
num_objs 1
set05_V007_I01685
num_objs 0
set04_V003_I00977
num_objs 4
set01_V002_I01292
num_objs 5
set00_V008_I01388
num_objs 1
set05_V003_I01034
num_objs 1
set01_V005_I01085
num_objs 2
set03_V012_I00977
num_objs 1
set00_V000_I00110
num_objs 1
set00_V001_I00524
num_objs 3
set02_V010_I00269
num_objs 0
set03_V003_I00032
num_objs 2
set02_V003_I00260
num_objs 1
set01_V001_I00860
num_objs 1
set00_V002_I00815
num_objs 6
set02_V009_I01565
num_objs 1
set04_V003_I01736
num_objs 2
set00_V013_I00428
num_objs 3
set00_V004_I01046
num_objs 1
set02_V011_I00470
num_objs 2
set05_V002_I01604
num_objs 1
set03_V005_I01457
num_objs 1
set03_V006_I01745
num_objs 1
set05_V010_I00767
num_objs 1
set04_V007_I01190
num_objs 1
set01_V005_I00923
num_objs 3
set00_V010_I00095
num_objs 4
set04_V003_I00770
num_objs 1
set03_V005_I01346
num_objs 1
set04_V003_I01475
num_objs 2
set01_V004_I01511
num_objs 2
set01_V003_I00377
num_objs 3
set00_V014_I00182
num_objs 1
set01_V002_I01631
num_objs 4
set00_V000_I00812
num_objs 0
set01_V003_I01823
num_objs 1
set05_V004_I00113
num_objs 3
set01_V002_I00821
num_objs 7
set01_V001_I00428
num_objs 3
set02_V009_I01547
num_objs 1
set02_V010_I00959
num_objs 0
set00_V010_I00626
num_objs 5
set00_V002_I01043
num_objs 0
set00_V008_I00896
num_objs 1
set00_V006_I01022
num_objs 1
set04_V001_I01769
num_objs 0
set00_V009_I00809
num_objs 3
set03_V008_I00962
num_objs 1
set04_V006_I00935
num_objs 2
set04_V000_I00935
num_objs 1
set03_V011_I00836
num_objs 2
set00_V009_I00209
num_objs 4
set01_V000_I00377
num_objs 3
set00_V010_I01442
num_objs 4
set04_V008_I01496
num_objs 1
set00_V000_I00413
num_objs 5
set03_V011_I01229
num_objs 0
set02_V009_I01454
num_objs 1
set05_V000_I01568
num_objs 1
set01_V003_I00461
num_objs 4
set05_V011_I01028
num_objs 8
set00_V006_I01364
num_objs 4
set04_V004_I00725
num_objs 2
set05_V004_I00197
num_objs 3
set00_V013_I00497
num_objs 2
set04_V011_I01823
num_objs 1
set00_V009_I00395
num_objs 1
set00_V013_I00038
num_objs 4
set03_V008_I00827
num_objs 2
set05_V010_I01589
num_objs 1
set04_V001_I00137
num_objs 1
set03_V010_I00935
num_objs 1
set04_V008_I01409
num_objs 0
set04_V001_I01637
num_objs 3
set05_V007_I01766
num_objs 0
set00_V000_I00365
num_objs 5
set03_V009_I01094
num_objs 6
set03_V005_I00401
num_objs 2
set03_V011_I00212
num_objs 3
set03_V009_I01589
num_objs 0
set01_V004_I01178
num_objs 1
set01_V003_I00851
num_objs 1
set03_V010_I01397
num_objs 2
set00_V009_I00686
num_objs 3
set04_V005_I01259
num_objs 0
set03_V011_I01193
num_objs 1
set03_V003_I00521
num_objs 2
set05_V003_I01163
num_objs 1
set00_V000_I01013
num_objs 0
set00_V007_I01796
num_objs 2
set03_V012_I01526
num_objs 4
set00_V001_I00137
num_objs 1
set00_V000_I00956
num_objs 0
set01_V004_I01004
num_objs 3
set01_V001_I01325
num_objs 10
set05_V007_I01334
num_objs 1
set04_V002_I01277
num_objs 2
set05_V005_I00371
num_objs 2
set04_V007_I01493
num_objs 1
set01_V003_I00350
num_objs 3
set05_V007_I01175
num_objs 1
set04_V007_I00647
num_objs 2
set04_V005_I00824
num_objs 1
set02_V009_I01640
num_objs 1
set02_V007_I00239
num_objs 1
set04_V007_I00350
num_objs 1
set01_V000_I01565
num_objs 4
set02_V009_I01364
num_objs 1
set05_V010_I00494
num_objs 1
set00_V009_I01079
num_objs 0
set03_V001_I00044
num_objs 1
set03_V006_I01709
num_objs 0
set03_V008_I01427
num_objs 3
set05_V007_I01421
num_objs 1
set05_V012_I00524
num_objs 1
set04_V005_I01145
num_objs 1
set00_V014_I00533
num_objs 5
set05_V007_I01664
num_objs 0
set01_V002_I00092
num_objs 4
set00_V013_I00581
num_objs 3
set00_V007_I00230
num_objs 5
set04_V005_I01517
num_objs 2
set00_V010_I01403
num_objs 3
set02_V009_I00341
num_objs 2
set00_V001_I00146
num_objs 1
set01_V001_I01295
num_objs 11
set05_V008_I01838
num_objs 1
set00_V009_I01523
num_objs 3
set05_V004_I00416
num_objs 2
set02_V010_I00023
num_objs 0
set02_V008_I01169
num_objs 0
set01_V001_I01706
num_objs 2
set00_V002_I00965
num_objs 1
set05_V002_I00662
num_objs 1
set00_V008_I00038
num_objs 7
set03_V008_I01223
num_objs 2
set04_V011_I01511
num_objs 1
set00_V012_I01592
num_objs 2
set01_V002_I01058
num_objs 1
set05_V012_I00395
num_objs 3
set02_V010_I01052
num_objs 1
set00_V008_I00299
num_objs 0
set01_V001_I01676
num_objs 2
set00_V008_I00104
num_objs 7
set00_V007_I01886
num_objs 7
set03_V008_I00029
num_objs 10
set03_V003_I01358
num_objs 2
set04_V010_I00578
num_objs 1
set02_V001_I01454
num_objs 1
set00_V012_I01370
num_objs 0
set05_V000_I00668
num_objs 1
set00_V000_I00662
num_objs 1
set00_V014_I01685
num_objs 4
set05_V004_I01007
num_objs 1
set00_V000_I01520
num_objs 1
set00_V003_I00413
num_objs 1
set03_V008_I01439
num_objs 5
set02_V007_I00482
num_objs 1
set00_V002_I00548
num_objs 0
set04_V002_I00707
num_objs 3
set00_V011_I00605
num_objs 3
set04_V002_I01553
num_objs 2
set00_V014_I01283
num_objs 4
set02_V010_I00107
num_objs 1
set03_V011_I01187
num_objs 1
set04_V006_I00878
num_objs 2
set00_V010_I00839
num_objs 3
set04_V000_I00869
num_objs 1
set00_V011_I00443
num_objs 6
set04_V007_I00953
num_objs 2
set04_V004_I00143
num_objs 1
set05_V010_I01019
num_objs 0
set01_V002_I00923
num_objs 4
set03_V005_I01673
num_objs 1
set05_V005_I00041
num_objs 3
set03_V010_I01529
num_objs 1
set01_V004_I01460
num_objs 1
set00_V002_I00647
num_objs 0
set00_V006_I00785
num_objs 2
set04_V001_I00038
num_objs 1
set05_V003_I01358
num_objs 2
set04_V006_I01076
num_objs 1
set05_V004_I00449
num_objs 2
set01_V003_I00488
num_objs 5
set05_V005_I00662
num_objs 1
set03_V005_I01088
num_objs 1
set04_V001_I00017
num_objs 1
set03_V003_I01460
num_objs 2
set00_V008_I01064
num_objs 2
set04_V004_I01220
num_objs 3
set03_V009_I01127
num_objs 6
set00_V012_I00863
num_objs 4
set03_V003_I00233
num_objs 1
set04_V000_I00857
num_objs 1
set05_V011_I00839
num_objs 2
set00_V012_I00629
num_objs 0
set03_V003_I00491
num_objs 2
set03_V011_I00551
num_objs 5
set02_V003_I00284
num_objs 1
set03_V005_I00638
num_objs 2
set03_V010_I01517
num_objs 2
set00_V007_I01190
num_objs 8
set02_V001_I01475
num_objs 1
set00_V010_I01601
num_objs 0
set01_V003_I00608
num_objs 1
set01_V001_I01442
num_objs 13
set00_V009_I00455
num_objs 2
set00_V004_I01415
num_objs 2
set03_V012_I00971
num_objs 1
set04_V011_I01841
num_objs 1
set00_V000_I00362
num_objs 4
set03_V010_I01793
num_objs 3
set04_V011_I01061
num_objs 2
set00_V009_I00650
num_objs 2
set01_V003_I00386
num_objs 3
set01_V001_I01493
num_objs 11
set04_V003_I01073
num_objs 4
set00_V010_I01616
num_objs 0
set00_V007_I01061
num_objs 4
set04_V000_I00686
num_objs 3
set01_V004_I01394
num_objs 1
set02_V003_I00023
num_objs 0
set02_V009_I00611
num_objs 2
set00_V014_I00809
num_objs 1
set00_V003_I00344
num_objs 1
set05_V004_I00137
num_objs 3
set00_V011_I01448
num_objs 4
set00_V001_I00800
num_objs 3
set03_V009_I00677
num_objs 3
set05_V003_I01697
num_objs 0
set01_V000_I01703
num_objs 2
set01_V005_I00896
num_objs 2
set04_V002_I00986
num_objs 2
set03_V003_I00662
num_objs 2
set01_V001_I00365
num_objs 4
set01_V001_I01316
num_objs 10
set03_V008_I00851
num_objs 1
set03_V001_I00125
num_objs 1
set04_V002_I00680
num_objs 2
set05_V005_I00398
num_objs 1
set00_V000_I00176
num_objs 3
set01_V001_I00443
num_objs 3
set05_V004_I00167
num_objs 3
set03_V005_I00608
num_objs 3
set03_V010_I01070
num_objs 1
set05_V003_I01082
num_objs 1
set00_V007_I00188
num_objs 4
set03_V003_I01160
num_objs 2
set04_V004_I00569
num_objs 0
set04_V005_I00779
num_objs 0
set05_V010_I00656
num_objs 1
set02_V010_I01718
num_objs 1
set05_V012_I00755
num_objs 1
set03_V009_I00140
num_objs 5
set03_V011_I01001
num_objs 1
set04_V010_I00461
num_objs 1
set03_V005_I01259
num_objs 2
set00_V006_I00830
num_objs 2
set04_V004_I01217
num_objs 3
set04_V004_I00902
num_objs 2
set05_V001_I00173
num_objs 1
set04_V002_I01388
num_objs 3
set00_V002_I00872
num_objs 8
set05_V005_I01127
num_objs 1
set05_V007_I01187
num_objs 1
set04_V004_I01367
num_objs 1
set04_V006_I01580
num_objs 1
set03_V008_I00812
num_objs 2
set02_V011_I00290
num_objs 0
set00_V007_I00464
num_objs 5
set02_V009_I01745
num_objs 1
set00_V006_I01436
num_objs 3
set02_V003_I00296
num_objs 2
set00_V010_I00143
num_objs 4
set01_V002_I01454
num_objs 0
set04_V003_I01667
num_objs 1
set01_V003_I01382
num_objs 1
set04_V000_I00863
num_objs 1
set05_V001_I00155
num_objs 1
set04_V000_I00956
num_objs 1
set03_V008_I01121
num_objs 1
set03_V005_I01748
num_objs 2
set03_V010_I00905
num_objs 1
set00_V010_I00503
num_objs 4
set00_V000_I01007
num_objs 0
set00_V002_I00257
num_objs 2
set03_V009_I00785
num_objs 2
set03_V003_I00389
num_objs 1
set03_V008_I01610
num_objs 2
set02_V003_I00203
num_objs 1
set03_V010_I01721
num_objs 3
set01_V001_I00278
num_objs 3
set00_V014_I00158
num_objs 1
set00_V002_I00593
num_objs 0
set00_V012_I00767
num_objs 0
set01_V001_I00713
num_objs 2
set04_V002_I01424
num_objs 3
set03_V005_I01481
num_objs 1
set03_V005_I01511
num_objs 1
set00_V009_I00746
num_objs 3
set02_V010_I00485
num_objs 1
set04_V006_I00926
num_objs 2
set00_V008_I01310
num_objs 0
set01_V005_I01109
num_objs 2
set02_V001_I01565
num_objs 2
set00_V004_I00941
num_objs 2
set00_V007_I00224
num_objs 5
set04_V011_I01658
num_objs 1
set02_V008_I01160
num_objs 0
set01_V004_I00272
num_objs 2
set05_V002_I01532
num_objs 1
set03_V003_I00560
num_objs 2
set01_V002_I00539
num_objs 7
set03_V005_I01454
num_objs 1
set04_V011_I01148
num_objs 1
set00_V000_I01058
num_objs 0
set04_V007_I01619
num_objs 1
set00_V000_I01595
num_objs 1
set00_V010_I00197
num_objs 4
set01_V003_I00596
num_objs 1
set01_V001_I00914
num_objs 1
set05_V005_I00956
num_objs 1
set04_V007_I00449
num_objs 0
set01_V005_I00686
num_objs 2
set03_V006_I00164
num_objs 1
set05_V002_I01154
num_objs 1
set05_V003_I00995
num_objs 1
set00_V007_I01103
num_objs 7
set00_V008_I00149
num_objs 1
set02_V003_I00086
num_objs 1
set05_V011_I01178
num_objs 4
set01_V003_I01835
num_objs 1
set01_V003_I01277
num_objs 1
set03_V012_I01280
num_objs 0
set00_V013_I00572
num_objs 2
set00_V000_I00428
num_objs 6
set03_V008_I00047
num_objs 4
set04_V001_I00158
num_objs 1
set01_V002_I00044
num_objs 3
set00_V014_I01865
num_objs 0
set01_V003_I00854
num_objs 1
set00_V009_I00197
num_objs 5
set00_V000_I00374
num_objs 4
set00_V009_I00074
num_objs 4
set03_V005_I00344
num_objs 2
set03_V004_I00179
num_objs 0
set01_V001_I01688
num_objs 2
set01_V003_I00566
num_objs 1
set03_V003_I00653
num_objs 2
set04_V003_I01427
num_objs 3
set05_V000_I00644
num_objs 1
set00_V012_I00308
num_objs 3
set00_V012_I01664
num_objs 1
set05_V008_I01817
num_objs 1
set01_V001_I01679
num_objs 2
set04_V005_I01247
num_objs 2
set03_V009_I01805
num_objs 4
set00_V010_I00011
num_objs 5
set01_V003_I01634
num_objs 1
set05_V000_I01637
num_objs 1
set00_V011_I00131
num_objs 3
set04_V005_I00344
num_objs 1
set05_V005_I00920
num_objs 1
set01_V000_I00533
num_objs 2
set04_V011_I01517
num_objs 1
set05_V000_I01367
num_objs 3
set05_V003_I01820
num_objs 0
set01_V001_I01139
num_objs 1
set01_V001_I00464
num_objs 4
set04_V008_I01412
num_objs 1
set02_V008_I00965
num_objs 0
set04_V004_I01040
num_objs 2
set02_V011_I00431
num_objs 1
set02_V008_I01229
num_objs 1
set03_V005_I00230
num_objs 1
set04_V004_I01712
num_objs 1
set03_V004_I00101
num_objs 1
set03_V005_I01430
num_objs 1
set02_V009_I01772
num_objs 1
set00_V007_I00002
num_objs 3
set00_V007_I00092
num_objs 1
set04_V003_I00509
num_objs 0
set00_V012_I00215
num_objs 1
set02_V010_I01703
num_objs 1
set00_V011_I00071
num_objs 4
set03_V011_I01256
num_objs 1
set02_V010_I00839
num_objs 0
set01_V002_I01208
num_objs 3
set01_V000_I00017
num_objs 1
set00_V014_I00128
num_objs 2
set04_V007_I01172
num_objs 1
set05_V012_I00521
num_objs 1
set00_V002_I00797
num_objs 4
set04_V004_I00587
num_objs 3
set03_V003_I01397
num_objs 2
set04_V003_I00965
num_objs 4
set04_V003_I00143
num_objs 0
set01_V005_I00968
num_objs 3
set02_V009_I00107
num_objs 1
set02_V003_I00299
num_objs 1
set01_V001_I01274
num_objs 11
set02_V011_I00581
num_objs 2
set00_V002_I00446
num_objs 0
set02_V010_I00536
num_objs 2
set03_V005_I01343
num_objs 1
set00_V000_I01205
num_objs 2
set01_V003_I01730
num_objs 3
set04_V007_I00896
num_objs 2
set02_V011_I01631
num_objs 2
set01_V004_I00092
num_objs 2
set04_V007_I01049
num_objs 1
set04_V003_I01607
num_objs 1
set00_V010_I00731
num_objs 1
set04_V001_I01742
num_objs 1
set01_V002_I00302
num_objs 7
set01_V003_I00665
num_objs 2
set02_V009_I01460
num_objs 1
set00_V007_I00455
num_objs 5
set03_V011_I00791
num_objs 2
set04_V004_I01343
num_objs 1
set00_V009_I00785
num_objs 2
set04_V001_I01691
num_objs 2
set00_V000_I01133
num_objs 0
set01_V003_I01583
num_objs 1
set00_V001_I01619
num_objs 0
set04_V005_I00056
num_objs 1
set05_V010_I00068
num_objs 1
set00_V009_I00116
num_objs 3
set04_V010_I00401
num_objs 1
set00_V006_I00743
num_objs 0
set03_V006_I00134
num_objs 1
set03_V006_I00140
num_objs 1
set00_V013_I00950
num_objs 1
set05_V009_I00797
num_objs 1
set04_V000_I00695
num_objs 3
set00_V001_I00680
num_objs 3
set00_V007_I00209
num_objs 0
set00_V004_I00461
num_objs 1
set05_V004_I00128
num_objs 3
set00_V000_I00644
num_objs 1
set00_V000_I01136
num_objs 0
set02_V009_I01163
num_objs 2
set00_V013_I01145
num_objs 4
set04_V007_I00542
num_objs 1
set05_V004_I00905
num_objs 0
set05_V007_I01514
num_objs 1
set05_V000_I00548
num_objs 3
set02_V010_I00029
num_objs 0
set05_V000_I00278
num_objs 2
set00_V009_I00566
num_objs 2
set02_V001_I00110
num_objs 0
set02_V010_I01109
num_objs 0
set03_V011_I00386
num_objs 5
set00_V011_I00155
num_objs 2
set04_V002_I00692
num_objs 3
set01_V001_I01454
num_objs 14
set01_V003_I00434
num_objs 3
set00_V004_I00764
num_objs 1
set04_V006_I00962
num_objs 2
set01_V000_I01490
num_objs 5
set02_V009_I01475
num_objs 1
set03_V008_I01310
num_objs 3
set01_V000_I00581
num_objs 1
set00_V001_I00044
num_objs 1
set00_V006_I00479
num_objs 2
set03_V009_I00713
num_objs 2
set00_V010_I01097
num_objs 1
set00_V009_I00860
num_objs 2
set02_V007_I00461
num_objs 1
set02_V010_I00581
num_objs 2
set05_V003_I01247
num_objs 3
set00_V012_I00293
num_objs 3
set00_V000_I01763
num_objs 1
set00_V001_I01022
num_objs 12
set03_V010_I00899
num_objs 0
set04_V008_I01094
num_objs 1
set02_V003_I00332
num_objs 1
set03_V011_I00854
num_objs 2
set03_V005_I00467
num_objs 2
set01_V000_I00266
num_objs 1
set03_V012_I01001
num_objs 1
set04_V002_I00119
num_objs 0
set04_V007_I00932
num_objs 2
set03_V010_I01451
num_objs 2
set03_V009_I01118
num_objs 6
set03_V005_I01562
num_objs 1
set03_V007_I00269
num_objs 0
set01_V002_I00194
num_objs 7
set04_V002_I00620
num_objs 1
set00_V008_I00560
num_objs 6
set03_V004_I00521
num_objs 1
set03_V005_I01775
num_objs 2
set04_V005_I01277
num_objs 1
set00_V009_I00236
num_objs 7
set00_V006_I00992
num_objs 2
set03_V008_I01781
num_objs 2
set03_V003_I01094
num_objs 2
set05_V000_I00743
num_objs 1
set04_V005_I01466
num_objs 2
set03_V008_I00626
num_objs 6
set03_V012_I00854
num_objs 1
set05_V010_I00917
num_objs 2
set00_V012_I00485
num_objs 1
set03_V009_I01292
num_objs 0
set03_V005_I00575
num_objs 3
set04_V005_I00995
num_objs 3
set00_V007_I01727
num_objs 4
set03_V005_I00992
num_objs 1
set04_V008_I01328
num_objs 1
set01_V004_I00245
num_objs 2
set01_V000_I01334
num_objs 4
set02_V010_I00695
num_objs 2
set05_V011_I01352
num_objs 1
set03_V009_I01562
num_objs 2
set04_V011_I01814
num_objs 1
set00_V006_I00230
num_objs 3
set00_V010_I01220
num_objs 2
set03_V010_I01838
num_objs 2
set00_V001_I00191
num_objs 2
set00_V012_I00209
num_objs 1
set04_V002_I00737
num_objs 2
set00_V011_I00677
num_objs 4
set00_V011_I00923
num_objs 4
set05_V005_I01187
num_objs 1
set00_V007_I01691
num_objs 5
set03_V005_I01505
num_objs 1
set01_V003_I01571
num_objs 1
set01_V000_I01394
num_objs 3
set04_V004_I01181
num_objs 3
set04_V007_I00617
num_objs 2
set02_V007_I00953
num_objs 1
set00_V009_I01064
num_objs 1
set04_V011_I01604
num_objs 1
set05_V007_I01271
num_objs 1
set05_V004_I00938
num_objs 2
set05_V010_I00044
num_objs 1
set02_V009_I00137
num_objs 1
set04_V002_I01538
num_objs 2
set00_V002_I01238
num_objs 0
set00_V010_I00506
num_objs 4
set01_V004_I00179
num_objs 2
set04_V000_I00497
num_objs 2
set03_V005_I01712
num_objs 1
set05_V003_I01829
num_objs 0
set03_V003_I00761
num_objs 2
set03_V009_I01736
num_objs 4
set03_V011_I01247
num_objs 1
set00_V006_I01538
num_objs 2
set00_V010_I01070
num_objs 0
set04_V002_I01457
num_objs 2
set05_V011_I00791
num_objs 5
set00_V000_I00863
num_objs 0
set01_V003_I00647
num_objs 2
set03_V009_I00014
num_objs 3
set00_V000_I00140
num_objs 1
set03_V003_I00839
num_objs 0
set00_V001_I01580
num_objs 4
set00_V002_I00599
num_objs 0
set04_V004_I01871
num_objs 1
set02_V007_I00203
num_objs 1
set00_V001_I00842
num_objs 3
set00_V011_I01034
num_objs 10
set02_V003_I00344
num_objs 1
set00_V002_I00740
num_objs 2
set04_V004_I00512
num_objs 3
set01_V002_I00197
num_objs 7
set04_V007_I00371
num_objs 1
set03_V005_I01784
num_objs 2
set04_V007_I01616
num_objs 1
set00_V000_I01244
num_objs 2
set00_V014_I01835
num_objs 0
set00_V013_I00125
num_objs 4
set00_V012_I01391
num_objs 1
set04_V007_I00884
num_objs 2
set00_V007_I01622
num_objs 6
set00_V010_I00422
num_objs 9
set00_V002_I00395
num_objs 0
set04_V003_I00365
num_objs 1
set05_V001_I00470
num_objs 0
set01_V004_I01571
num_objs 2
set04_V007_I01397
num_objs 1
set00_V009_I00161
num_objs 3
set05_V000_I00353
num_objs 3
set05_V000_I01631
num_objs 1
set03_V005_I00770
num_objs 1
set00_V009_I00563
num_objs 2
set05_V008_I01841
num_objs 1
set03_V009_I00293
num_objs 3
set00_V006_I00641
num_objs 2
set01_V004_I00275
num_objs 2
set00_V005_I00815
num_objs 1
set03_V010_I01820
num_objs 2
set00_V001_I00002
num_objs 2
set01_V001_I00776
num_objs 1
set00_V010_I00725
num_objs 2
set03_V008_I00314
num_objs 18
set00_V010_I00566
num_objs 6
set00_V001_I00971
num_objs 9
set04_V010_I00683
num_objs 1
set01_V001_I00458
num_objs 4
set05_V010_I00539
num_objs 0
set00_V014_I00989
num_objs 0
set02_V009_I00884
num_objs 1
set00_V012_I01430
num_objs 2
set04_V005_I00149
num_objs 0
set01_V004_I00461
num_objs 1
set00_V006_I00788
num_objs 2
set00_V011_I01463
num_objs 4
set00_V014_I00719
num_objs 5
set01_V000_I01586
num_objs 4
set04_V011_I01058
num_objs 2
set00_V012_I01139
num_objs 2
set04_V003_I01595
num_objs 1
set05_V004_I01040
num_objs 1
set00_V006_I00044
num_objs 2
set04_V002_I01565
num_objs 1
set03_V008_I00326
num_objs 18
set00_V009_I01229
num_objs 0
set01_V002_I00158
num_objs 7
set04_V011_I01646
num_objs 1
set00_V004_I01454
num_objs 2
set04_V000_I00950
num_objs 1
set03_V012_I00941
num_objs 1
set00_V001_I00770
num_objs 3
set00_V011_I00752
num_objs 2
set03_V005_I00989
num_objs 0
set05_V011_I01643
num_objs 1
set00_V009_I01232
num_objs 1
set00_V007_I00491
num_objs 4
set01_V005_I01238
num_objs 1
set05_V011_I01292
num_objs 2
set03_V003_I00407
num_objs 1
set02_V010_I01697
num_objs 1
set04_V004_I00524
num_objs 3
set04_V004_I00971
num_objs 2
set00_V000_I00155
num_objs 1
set05_V005_I00452
num_objs 1
set01_V005_I00146
num_objs 2
set02_V011_I01328
num_objs 1
set01_V003_I00374
num_objs 3
set05_V011_I00896
num_objs 9
set01_V000_I01409
num_objs 1
set04_V004_I00938
num_objs 2
set04_V007_I00599
num_objs 1
set01_V002_I01283
num_objs 4
set01_V002_I01133
num_objs 1
set03_V008_I00854
num_objs 1
set00_V011_I01556
num_objs 0
set00_V003_I00398
num_objs 0
set01_V003_I01304
num_objs 1
set00_V012_I01511
num_objs 1
set03_V008_I00938
num_objs 1
set04_V002_I00926
num_objs 1
set05_V000_I01412
num_objs 0
set00_V001_I00110
num_objs 3
set00_V006_I01286
num_objs 5
set02_V001_I01481
num_objs 1
set03_V005_I00671
num_objs 1
set02_V009_I00236
num_objs 2
set04_V000_I00524
num_objs 2
set05_V007_I01787
num_objs 0
set00_V000_I00974
num_objs 0
set01_V000_I01100
num_objs 3
set02_V010_I00917
num_objs 1
set00_V010_I01127
num_objs 2
set05_V010_I01622
num_objs 1
set03_V011_I01427
num_objs 2
set02_V003_I00113
num_objs 1
set00_V013_I01250
num_objs 1
set00_V001_I01442
num_objs 4
set01_V004_I01556
num_objs 1
set05_V007_I01214
num_objs 1
set00_V003_I00095
num_objs 1
set03_V009_I01226
num_objs 2
set04_V005_I01190
num_objs 2
set02_V007_I00383
num_objs 1
set00_V004_I01259
num_objs 11
set03_V005_I00362
num_objs 2
set05_V005_I00521
num_objs 1
set01_V004_I00485
num_objs 1
set01_V000_I00536
num_objs 2
set02_V001_I01598
num_objs 1
set02_V009_I01097
num_objs 1
set00_V009_I00656
num_objs 2
set05_V012_I00704
num_objs 1
set05_V004_I00428
num_objs 2
set03_V005_I00503
num_objs 2
set01_V002_I01415
num_objs 0
set02_V011_I01700
num_objs 2
set05_V002_I00755
num_objs 1
set03_V011_I00566
num_objs 5
set00_V014_I00404
num_objs 5
set00_V013_I00317
num_objs 7
set03_V003_I00047
num_objs 2
set05_V010_I01586
num_objs 1
set04_V007_I00635
num_objs 2
set00_V006_I00545
num_objs 3
set00_V010_I01385
num_objs 4
set01_V000_I00290
num_objs 1
set04_V005_I00752
num_objs 1
set01_V003_I01712
num_objs 3
set03_V005_I01451
num_objs 1
set04_V005_I01220
num_objs 1
set03_V011_I00638
num_objs 3
set05_V010_I00854
num_objs 1
set00_V013_I00401
num_objs 3
set03_V012_I01436
num_objs 4
set00_V013_I01571
num_objs 3
set03_V011_I00383
num_objs 5
set04_V005_I01289
num_objs 0
set03_V009_I00803
num_objs 2
set00_V000_I01631
num_objs 1
set01_V005_I01250
num_objs 1
set04_V006_I01487
num_objs 1
set02_V001_I00122
num_objs 0
set01_V004_I01550
num_objs 1
set03_V003_I01247
num_objs 2
set00_V007_I01922
num_objs 3
set04_V005_I01613
num_objs 2
set04_V006_I00569
num_objs 1
set00_V010_I01334
num_objs 4
set03_V011_I01160
num_objs 1
set04_V005_I00314
num_objs 1
set05_V010_I00731
num_objs 1
set00_V014_I00806
num_objs 5
set01_V002_I01451
num_objs 0
set03_V012_I01529
num_objs 1
set01_V003_I01658
num_objs 2
set04_V011_I01100
num_objs 2
set00_V012_I01493
num_objs 1
set05_V011_I00533
num_objs 1
set01_V001_I00488
num_objs 4
set03_V011_I00884
num_objs 1
set00_V001_I00551
num_objs 3
set05_V010_I00143
num_objs 1
set00_V012_I00104
num_objs 0
set00_V014_I01703
num_objs 2
set03_V005_I01025
num_objs 1
set04_V003_I00452
num_objs 0
set01_V000_I00428
num_objs 2
set04_V003_I01682
num_objs 1
set05_V009_I00968
num_objs 1
set04_V007_I01661
num_objs 1
set02_V009_I00140
num_objs 1
set00_V010_I01592
num_objs 1
set03_V011_I00257
num_objs 3
set05_V011_I00647
num_objs 4
set04_V005_I01052
num_objs 3
set00_V006_I01793
num_objs 0
set01_V002_I01109
num_objs 3
set01_V003_I00371
num_objs 3
set04_V002_I01655
num_objs 2
set00_V001_I01706
num_objs 1
set03_V010_I01469
num_objs 1
set00_V006_I01019
num_objs 0
set04_V001_I01589
num_objs 1
set02_V009_I01091
num_objs 1
set02_V003_I00707
num_objs 2
set04_V001_I01634
num_objs 3
set04_V001_I00107
num_objs 1
set02_V007_I00221
num_objs 1
set00_V012_I01625
num_objs 1
set00_V001_I00416
num_objs 1
set02_V010_I00386
num_objs 1
set03_V004_I00047
num_objs 1
set03_V008_I01148
num_objs 1
set03_V010_I01379
num_objs 1
set00_V004_I01016
num_objs 2
set00_V011_I00215
num_objs 1
set02_V011_I01493
num_objs 2
set04_V004_I00620
num_objs 2
set01_V001_I01241
num_objs 10
set03_V012_I01346
num_objs 4
set01_V000_I00857
num_objs 0
set03_V008_I00353
num_objs 18
set00_V012_I00641
num_objs 0
set04_V010_I00608
num_objs 1
set04_V010_I00440
num_objs 1
set01_V003_I00293
num_objs 4
set01_V005_I00557
num_objs 2
set04_V007_I00776
num_objs 2
set02_V011_I01688
num_objs 2
set00_V011_I01112
num_objs 7
set04_V007_I00257
num_objs 2
set02_V010_I01280
num_objs 1
set05_V002_I00539
num_objs 0
set01_V000_I00035
num_objs 1
set00_V009_I00833
num_objs 3
set04_V011_I01859
num_objs 1
set04_V007_I00260
num_objs 2
set00_V012_I00770
num_objs 1
set00_V004_I01658
num_objs 1
set03_V004_I00086
num_objs 1
set01_V000_I00806
num_objs 1
set01_V005_I01055
num_objs 3
set01_V005_I00020
num_objs 2
set04_V004_I01769
num_objs 0
set04_V003_I00179
num_objs 0
set05_V011_I01589
num_objs 1
set01_V000_I01127
num_objs 4
set02_V011_I00803
num_objs 0
set01_V004_I00809
num_objs 1
set00_V010_I01352
num_objs 4
set03_V003_I00365
num_objs 1
set03_V005_I00611
num_objs 3
set00_V006_I00905
num_objs 3
set02_V010_I00677
num_objs 2
set05_V002_I00779
num_objs 0
set04_V000_I00845
num_objs 1
set02_V001_I01508
num_objs 1
set03_V003_I01451
num_objs 2
set05_V005_I00047
num_objs 4
set00_V001_I00005
num_objs 2
set01_V003_I01346
num_objs 1
set01_V002_I00071
num_objs 3
set03_V012_I00995
num_objs 1
set02_V008_I00812
num_objs 1
set00_V006_I01004
num_objs 3
set00_V000_I01157
num_objs 0
set03_V003_I01280
num_objs 2
set00_V011_I01064
num_objs 10
set04_V003_I00473
num_objs 0
set03_V003_I00644
num_objs 2
set05_V012_I00674
num_objs 1
set04_V002_I00722
num_objs 3
set01_V005_I01376
num_objs 1
set05_V000_I01526
num_objs 1
set03_V005_I00995
num_objs 1
set02_V011_I01616
num_objs 2
set04_V007_I01064
num_objs 2
set01_V002_I00191
num_objs 7
set00_V011_I01307
num_objs 5
set03_V008_I01562
num_objs 1
set03_V008_I00920
num_objs 1
set00_V011_I00938
num_objs 6
set05_V011_I01226
num_objs 3
set00_V006_I00362
num_objs 4
set00_V000_I01175
num_objs 1
set03_V003_I00254
num_objs 1
set00_V013_I01436
num_objs 4
set03_V012_I01340
num_objs 4
set00_V008_I01328
num_objs 1
set04_V004_I01688
num_objs 2
set05_V011_I01037
num_objs 8
set03_V007_I01538
num_objs 0
set00_V009_I01388
num_objs 0
set01_V000_I01151
num_objs 4
set01_V002_I00041
num_objs 2
set00_V014_I00245
num_objs 1
set00_V001_I01088
num_objs 8
set03_V010_I00794
num_objs 0
set04_V000_I00905
num_objs 1
set01_V003_I01688
num_objs 3
set04_V004_I01355
num_objs 1
set01_V001_I00560
num_objs 4
set00_V011_I01337
num_objs 4
set00_V007_I01916
num_objs 3
set03_V012_I00908
num_objs 1
set01_V005_I00443
num_objs 4
set00_V001_I00344
num_objs 5
set02_V007_I00170
num_objs 1
set01_V000_I00842
num_objs 0
set00_V010_I00719
num_objs 2
set00_V009_I01682
num_objs 1
set00_V006_I00095
num_objs 2
set02_V001_I00098
num_objs 0
set03_V005_I01016
num_objs 1
set00_V012_I00695
num_objs 0
set03_V011_I00278
num_objs 4
set04_V001_I01703
num_objs 2
set00_V006_I01553
num_objs 2
set01_V003_I00395
num_objs 3
set01_V001_I01340
num_objs 10
set01_V003_I01724
num_objs 3
set04_V000_I00911
num_objs 1
set04_V004_I00164
num_objs 2
set01_V000_I01316
num_objs 4
set02_V011_I01391
num_objs 2
set03_V012_I00818
num_objs 1
set00_V009_I01412
num_objs 1
set00_V006_I00809
num_objs 1
set01_V003_I00167
num_objs 8
set05_V011_I01436
num_objs 3
set05_V010_I01100
num_objs 1
set04_V011_I01808
num_objs 1
set01_V004_I01148
num_objs 4
set01_V000_I00338
num_objs 1
set05_V012_I01142
num_objs 1
set04_V007_I00938
num_objs 2
set00_V006_I01613
num_objs 2
set04_V002_I00875
num_objs 1
set04_V000_I00665
num_objs 3
set03_V008_I00554
num_objs 11
set01_V001_I01685
num_objs 2
set01_V003_I00797
num_objs 0
set01_V003_I00716
num_objs 2
set00_V012_I01385
num_objs 1
set00_V012_I01337
num_objs 0
set03_V005_I01832
num_objs 2
set05_V005_I00512
num_objs 2
set00_V004_I01367
num_objs 0
set00_V006_I00974
num_objs 2
set00_V001_I00233
num_objs 6
set05_V005_I00443
num_objs 1
set03_V008_I01790
num_objs 1
set04_V007_I00989
num_objs 1
set03_V008_I00779
num_objs 10
set04_V007_I01580
num_objs 1
set04_V007_I00215
num_objs 1
set03_V008_I01556
num_objs 1
set03_V004_I00605
num_objs 1
set01_V002_I01079
num_objs 3
set00_V009_I01025
num_objs 1
set00_V007_I01295
num_objs 10
set02_V010_I01166
num_objs 1
set05_V010_I00623
num_objs 1
set05_V005_I00908
num_objs 1
set00_V003_I00101
num_objs 1
set05_V012_I00368
num_objs 3
set01_V004_I00734
num_objs 3
set04_V008_I01130
num_objs 1
set00_V012_I01661
num_objs 1
set02_V009_I01316
num_objs 1
set00_V008_I01097
num_objs 0
set00_V000_I00929
num_objs 0
set00_V010_I01181
num_objs 2
set02_V001_I01640
num_objs 1
set05_V002_I00476
num_objs 1
set02_V003_I00038
num_objs 1
set01_V002_I00752
num_objs 7
set01_V001_I00908
num_objs 1
set03_V011_I00545
num_objs 5
set00_V007_I01676
num_objs 6
set03_V005_I01181
num_objs 2
set01_V005_I00656
num_objs 2
set05_V011_I00545
num_objs 3
set01_V001_I00008
num_objs 1
set05_V011_I00677
num_objs 2
set03_V003_I00824
num_objs 2
set00_V014_I01577
num_objs 5
set00_V009_I00425
num_objs 3
set00_V001_I00389
num_objs 3
set03_V011_I01415
num_objs 1
set02_V010_I00686
num_objs 2
set04_V011_I01838
num_objs 1
set00_V013_I01157
num_objs 1
set01_V004_I01421
num_objs 1
set03_V009_I01097
num_objs 6
set05_V004_I00425
num_objs 2
set02_V009_I00461
num_objs 1
set03_V009_I00467
num_objs 3
set00_V000_I01325
num_objs 1
set05_V011_I00833
num_objs 7
set00_V014_I01901
num_objs 1
set03_V003_I01061
num_objs 2
set00_V006_I01694
num_objs 0
set02_V007_I00395
num_objs 1
set00_V013_I00977
num_objs 1
set05_V012_I01025
num_objs 1
set03_V011_I00392
num_objs 5
set02_V010_I00455
num_objs 1
set03_V011_I00605
num_objs 4
set01_V002_I00725
num_objs 6
set03_V009_I00872
num_objs 2
set04_V002_I00971
num_objs 2
set03_V008_I00431
num_objs 19
set00_V014_I01403
num_objs 6
set03_V012_I00845
num_objs 1
set00_V002_I00716
num_objs 1
set00_V008_I01355
num_objs 1
set04_V006_I01652
num_objs 1
set05_V005_I00074
num_objs 4
set04_V003_I00377
num_objs 1
set00_V014_I00080
num_objs 4
set02_V011_I01658
num_objs 2
set05_V011_I01220
num_objs 3
set04_V005_I00095
num_objs 1
set00_V003_I00077
num_objs 1
set01_V000_I00263
num_objs 1
set00_V009_I00641
num_objs 2
set01_V001_I00479
num_objs 2
set05_V004_I00245
num_objs 1
set00_V010_I01229
num_objs 5
set03_V003_I00809
num_objs 0
set00_V001_I01145
num_objs 5
set03_V011_I00290
num_objs 4
set01_V005_I01802
num_objs 0
set05_V005_I01166
num_objs 1
set05_V010_I00572
num_objs 1
set03_V002_I01418
num_objs 1
set00_V014_I00470
num_objs 4
set05_V005_I00950
num_objs 1
set04_V011_I00356
num_objs 1
set05_V007_I01256
num_objs 1
set05_V007_I01697
num_objs 0
set00_V004_I01652
num_objs 1
set02_V010_I00731
num_objs 2
set05_V005_I00332
num_objs 2
set04_V007_I00473
num_objs 1
set00_V011_I01088
num_objs 7
set03_V010_I01730
num_objs 3
set00_V006_I00695
num_objs 2
set01_V002_I00806
num_objs 7
set05_V005_I00686
num_objs 1
set03_V008_I01100
num_objs 1
set05_V010_I01022
num_objs 1
set02_V010_I01658
num_objs 1
set01_V002_I01424
num_objs 0
set03_V011_I00890
num_objs 1
set00_V013_I00509
num_objs 4
set02_V009_I00785
num_objs 2
set05_V005_I00854
num_objs 2
set04_V001_I01574
num_objs 2
set01_V000_I01016
num_objs 1
set00_V003_I00104
num_objs 1
set01_V001_I01409
num_objs 5
set01_V004_I00509
num_objs 1
set00_V010_I01055
num_objs 0
set00_V004_I01163
num_objs 0
set05_V003_I01826
num_objs 0
set00_V009_I00869
num_objs 4
set05_V002_I00134
num_objs 1
set01_V004_I00098
num_objs 2
set04_V006_I00923
num_objs 2
set00_V014_I01040
num_objs 3
set01_V000_I01709
num_objs 2
set01_V002_I01607
num_objs 3
set03_V008_I01034
num_objs 1
set00_V010_I00917
num_objs 1
set00_V014_I00419
num_objs 3
set05_V003_I01565
num_objs 0
set00_V004_I01181
num_objs 0
set00_V006_I01319
num_objs 3
set05_V007_I01349
num_objs 1
set00_V000_I00830
num_objs 0
set02_V010_I01700
num_objs 1
set00_V007_I00323
num_objs 6
set00_V014_I00737
num_objs 2
set04_V006_I01088
num_objs 1
set02_V009_I00446
num_objs 1
set03_V007_I00332
num_objs 1
set00_V010_I01478
num_objs 4
set00_V002_I00677
num_objs 1
set00_V001_I01163
num_objs 4
set03_V005_I00911
num_objs 1
set03_V005_I00521
num_objs 3
set02_V010_I00761
num_objs 3
set04_V003_I01568
num_objs 1
set00_V001_I00278
num_objs 5
set01_V000_I00329
num_objs 0
set05_V001_I00461
num_objs 0
set02_V009_I01064
num_objs 1
set03_V011_I00926
num_objs 1
set00_V000_I01505
num_objs 1
set01_V003_I00554
num_objs 1
set05_V011_I00605
num_objs 4
set03_V003_I00164
num_objs 2
set01_V005_I01709
num_objs 2
set00_V014_I00692
num_objs 3
set04_V010_I00872
num_objs 2
set00_V012_I01376
num_objs 0
set00_V001_I01199
num_objs 1
set00_V014_I00410
num_objs 5
set01_V002_I00953
num_objs 4
set00_V007_I00623
num_objs 3
set05_V005_I00590
num_objs 1
set04_V004_I00833
num_objs 2
set05_V011_I00656
num_objs 3
set00_V000_I00254
num_objs 5
set05_V004_I00218
num_objs 3
set04_V011_I01661
num_objs 1
set04_V006_I01562
num_objs 1
set04_V007_I01718
num_objs 1
set05_V000_I00737
num_objs 1
set01_V000_I01502
num_objs 4
set05_V005_I00485
num_objs 2
set03_V003_I01016
num_objs 2
set00_V012_I00674
num_objs 0
set00_V009_I01208
num_objs 1
set04_V000_I00977
num_objs 1
set00_V000_I01124
num_objs 0
set01_V000_I01136
num_objs 4
set00_V014_I01235
num_objs 4
set05_V011_I01496
num_objs 2
set01_V002_I00545
num_objs 8
set03_V008_I01325
num_objs 3
set01_V004_I01376
num_objs 1
set00_V002_I01079
num_objs 0
set00_V006_I01724
num_objs 0
set00_V013_I01259
num_objs 3
set05_V000_I00344
num_objs 3
set03_V002_I01424
num_objs 1
set03_V009_I00260
num_objs 3
set00_V004_I01055
num_objs 1
set03_V009_I01007
num_objs 2
set04_V004_I00872
num_objs 2
set01_V000_I00206
num_objs 1
set01_V005_I00128
num_objs 2
set00_V001_I00623
num_objs 3
set03_V009_I01088
num_objs 6
set03_V008_I00161
num_objs 12
wrote gt roidb to /home/user/Disk1.8T/py-R-FCN/data/cache/voc_0712_trainval_gt_roidb.pkl
done
Preparing training data...
done
44712 roidb entries
Output will be saved to `/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model`
Filtered 4858 roidb entries: 44712 -> 39854
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0528 17:10:13.580927 10644 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/train_agnostic_ohem.prototxt"
base_lr: 0.0002
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "resnet50_rfcn_ohem"
iter_size: 8
I0528 17:10:13.580965 10644 solver.cpp:81] Creating training net from train_net file: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/train_agnostic_ohem.prototxt
I0528 17:10:13.583539 10644 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "res4c_
I0528 17:10:13.585358 10644 layer_factory.hpp:77] Creating layer input-data
I0528 17:10:13.622452 10644 net.cpp:100] Creating Layer input-data
I0528 17:10:13.622476 10644 net.cpp:418] input-data -> data
I0528 17:10:13.622514 10644 net.cpp:418] input-data -> im_info
I0528 17:10:13.622531 10644 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0528 17:10:13.645073 10644 net.cpp:150] Setting up input-data
I0528 17:10:13.645100 10644 net.cpp:157] Top shape: 1 3 640 1280 (2457600)
I0528 17:10:13.645107 10644 net.cpp:157] Top shape: 1 3 (3)
I0528 17:10:13.645110 10644 net.cpp:157] Top shape: 1 4 (4)
I0528 17:10:13.645112 10644 net.cpp:165] Memory required for data: 9830428
I0528 17:10:13.645128 10644 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0528 17:10:13.645162 10644 net.cpp:100] Creating Layer data_input-data_0_split
I0528 17:10:13.645174 10644 net.cpp:444] data_input-data_0_split <- data
I0528 17:10:13.645195 10644 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I0528 17:10:13.645217 10644 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I0528 17:10:13.645267 10644 net.cpp:150] Setting up data_input-data_0_split
I0528 17:10:13.645275 10644 net.cpp:157] Top shape: 1 3 640 1280 (2457600)
I0528 17:10:13.645282 10644 net.cpp:157] Top shape: 1 3 640 1280 (2457600)
I0528 17:10:13.645285 10644 net.cpp:165] Memory required for data: 29491228
I0528 17:10:13.645289 10644 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0528 17:10:13.645301 10644 net.cpp:100] Creating Layer im_info_input-data_1_split
I0528 17:10:13.645306 10644 net.cpp:444] im_info_input-data_1_split <- im_info
I0528 17:10:13.645318 10644 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0528 17:10:13.645330 10644 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0528 17:10:13.645370 10644 net.cpp:150] Setting up im_info_input-data_1_split
I0528 17:10:13.645376 10644 net.cpp:157] Top shape: 1 3 (3)
I0528 17:10:13.645381 10644 net.cpp:157] Top shape: 1 3 (3)
I0528 17:10:13.645383 10644 net.cpp:165] Memory required for data: 29491252
I0528 17:10:13.645387 10644 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0528 17:10:13.645396 10644 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I0528 17:10:13.645401 10644 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I0528 17:10:13.645412 10644 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0528 17:10:13.645426 10644 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0528 17:10:13.645465 10644 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0528 17:10:13.645473 10644 net.cpp:157] Top shape: 1 4 (4)
I0528 17:10:13.645479 10644 net.cpp:157] Top shape: 1 4 (4)
I0528 17:10:13.645483 10644 net.cpp:165] Memory required for data: 29491284
I0528 17:10:13.645486 10644 layer_factory.hpp:77] Creating layer conv1
I0528 17:10:13.645510 10644 net.cpp:100] Creating Layer conv1
I0528 17:10:13.645516 10644 net.cpp:444] conv1 <- data_input-data_0_split_0
I0528 17:10:13.645531 10644 net.cpp:418] conv1 -> conv1
I0528 17:10:13.939103 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3686424
I0528 17:10:13.939357 10644 net.cpp:150] Setting up conv1
I0528 17:10:13.939375 10644 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0528 17:10:13.939378 10644 net.cpp:165] Memory required for data: 81920084
I0528 17:10:13.939433 10644 layer_factory.hpp:77] Creating layer bn_conv1
I0528 17:10:13.939460 10644 net.cpp:100] Creating Layer bn_conv1
I0528 17:10:13.939468 10644 net.cpp:444] bn_conv1 <- conv1
I0528 17:10:13.939482 10644 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0528 17:10:13.939966 10644 net.cpp:150] Setting up bn_conv1
I0528 17:10:13.939973 10644 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0528 17:10:13.939975 10644 net.cpp:165] Memory required for data: 134348884
I0528 17:10:13.939997 10644 layer_factory.hpp:77] Creating layer scale_conv1
I0528 17:10:13.940012 10644 net.cpp:100] Creating Layer scale_conv1
I0528 17:10:13.940017 10644 net.cpp:444] scale_conv1 <- conv1
I0528 17:10:13.940028 10644 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0528 17:10:13.940083 10644 layer_factory.hpp:77] Creating layer scale_conv1
I0528 17:10:13.941429 10644 net.cpp:150] Setting up scale_conv1
I0528 17:10:13.941440 10644 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0528 17:10:13.941442 10644 net.cpp:165] Memory required for data: 186777684
I0528 17:10:13.941453 10644 layer_factory.hpp:77] Creating layer conv1_relu
I0528 17:10:13.941465 10644 net.cpp:100] Creating Layer conv1_relu
I0528 17:10:13.941470 10644 net.cpp:444] conv1_relu <- conv1
I0528 17:10:13.941481 10644 net.cpp:405] conv1_relu -> conv1 (in-place)
I0528 17:10:13.941642 10644 net.cpp:150] Setting up conv1_relu
I0528 17:10:13.941648 10644 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0528 17:10:13.941650 10644 net.cpp:165] Memory required for data: 239206484
I0528 17:10:13.941653 10644 layer_factory.hpp:77] Creating layer pool1
I0528 17:10:13.941673 10644 net.cpp:100] Creating Layer pool1
I0528 17:10:13.941678 10644 net.cpp:444] pool1 <- conv1
I0528 17:10:13.941689 10644 net.cpp:418] pool1 -> pool1
I0528 17:10:13.941742 10644 net.cpp:150] Setting up pool1
I0528 17:10:13.941751 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.941752 10644 net.cpp:165] Memory required for data: 252313684
I0528 17:10:13.941756 10644 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0528 17:10:13.941764 10644 net.cpp:100] Creating Layer pool1_pool1_0_split
I0528 17:10:13.941768 10644 net.cpp:444] pool1_pool1_0_split <- pool1
I0528 17:10:13.941776 10644 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0528 17:10:13.941787 10644 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0528 17:10:13.941829 10644 net.cpp:150] Setting up pool1_pool1_0_split
I0528 17:10:13.941836 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.941839 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.941841 10644 net.cpp:165] Memory required for data: 278528084
I0528 17:10:13.941844 10644 layer_factory.hpp:77] Creating layer res2a_branch1
I0528 17:10:13.941860 10644 net.cpp:100] Creating Layer res2a_branch1
I0528 17:10:13.941864 10644 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0528 17:10:13.941876 10644 net.cpp:418] res2a_branch1 -> res2a_branch1
I0528 17:10:13.942757 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.944481 10644 net.cpp:150] Setting up res2a_branch1
I0528 17:10:13.944494 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.944496 10644 net.cpp:165] Memory required for data: 330956884
I0528 17:10:13.944507 10644 layer_factory.hpp:77] Creating layer bn2a_branch1
I0528 17:10:13.944520 10644 net.cpp:100] Creating Layer bn2a_branch1
I0528 17:10:13.944525 10644 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0528 17:10:13.944537 10644 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0528 17:10:13.945518 10644 net.cpp:150] Setting up bn2a_branch1
I0528 17:10:13.945525 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.945528 10644 net.cpp:165] Memory required for data: 383385684
I0528 17:10:13.945557 10644 layer_factory.hpp:77] Creating layer scale2a_branch1
I0528 17:10:13.945572 10644 net.cpp:100] Creating Layer scale2a_branch1
I0528 17:10:13.945578 10644 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0528 17:10:13.945590 10644 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0528 17:10:13.945649 10644 layer_factory.hpp:77] Creating layer scale2a_branch1
I0528 17:10:13.945905 10644 net.cpp:150] Setting up scale2a_branch1
I0528 17:10:13.945912 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.945914 10644 net.cpp:165] Memory required for data: 435814484
I0528 17:10:13.945922 10644 layer_factory.hpp:77] Creating layer res2a_branch2a
I0528 17:10:13.945935 10644 net.cpp:100] Creating Layer res2a_branch2a
I0528 17:10:13.945940 10644 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0528 17:10:13.945950 10644 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0528 17:10:13.947450 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.947468 10644 net.cpp:150] Setting up res2a_branch2a
I0528 17:10:13.947476 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.947479 10644 net.cpp:165] Memory required for data: 448921684
I0528 17:10:13.947487 10644 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0528 17:10:13.947501 10644 net.cpp:100] Creating Layer bn2a_branch2a
I0528 17:10:13.947507 10644 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0528 17:10:13.947544 10644 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0528 17:10:13.947832 10644 net.cpp:150] Setting up bn2a_branch2a
I0528 17:10:13.947839 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.947841 10644 net.cpp:165] Memory required for data: 462028884
I0528 17:10:13.947863 10644 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0528 17:10:13.947877 10644 net.cpp:100] Creating Layer scale2a_branch2a
I0528 17:10:13.947882 10644 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0528 17:10:13.947891 10644 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0528 17:10:13.947954 10644 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0528 17:10:13.948223 10644 net.cpp:150] Setting up scale2a_branch2a
I0528 17:10:13.948230 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.948233 10644 net.cpp:165] Memory required for data: 475136084
I0528 17:10:13.948246 10644 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0528 17:10:13.948263 10644 net.cpp:100] Creating Layer res2a_branch2a_relu
I0528 17:10:13.948271 10644 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0528 17:10:13.948282 10644 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0528 17:10:13.948413 10644 net.cpp:150] Setting up res2a_branch2a_relu
I0528 17:10:13.948421 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.948423 10644 net.cpp:165] Memory required for data: 488243284
I0528 17:10:13.948427 10644 layer_factory.hpp:77] Creating layer res2a_branch2b
I0528 17:10:13.948442 10644 net.cpp:100] Creating Layer res2a_branch2b
I0528 17:10:13.948448 10644 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0528 17:10:13.948462 10644 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0528 17:10:13.949419 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0528 17:10:13.949765 10644 net.cpp:150] Setting up res2a_branch2b
I0528 17:10:13.949776 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.949779 10644 net.cpp:165] Memory required for data: 501350484
I0528 17:10:13.949789 10644 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0528 17:10:13.949800 10644 net.cpp:100] Creating Layer bn2a_branch2b
I0528 17:10:13.949805 10644 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0528 17:10:13.949815 10644 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0528 17:10:13.950096 10644 net.cpp:150] Setting up bn2a_branch2b
I0528 17:10:13.950103 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.950104 10644 net.cpp:165] Memory required for data: 514457684
I0528 17:10:13.950117 10644 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0528 17:10:13.950127 10644 net.cpp:100] Creating Layer scale2a_branch2b
I0528 17:10:13.950132 10644 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0528 17:10:13.950141 10644 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0528 17:10:13.950191 10644 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0528 17:10:13.950454 10644 net.cpp:150] Setting up scale2a_branch2b
I0528 17:10:13.950461 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.950464 10644 net.cpp:165] Memory required for data: 527564884
I0528 17:10:13.950477 10644 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0528 17:10:13.950489 10644 net.cpp:100] Creating Layer res2a_branch2b_relu
I0528 17:10:13.950495 10644 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0528 17:10:13.950507 10644 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0528 17:10:13.950956 10644 net.cpp:150] Setting up res2a_branch2b_relu
I0528 17:10:13.950983 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.950992 10644 net.cpp:165] Memory required for data: 540672084
I0528 17:10:13.951005 10644 layer_factory.hpp:77] Creating layer res2a_branch2c
I0528 17:10:13.951035 10644 net.cpp:100] Creating Layer res2a_branch2c
I0528 17:10:13.951050 10644 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0528 17:10:13.951076 10644 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0528 17:10:13.952209 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.952225 10644 net.cpp:150] Setting up res2a_branch2c
I0528 17:10:13.952237 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.952240 10644 net.cpp:165] Memory required for data: 593100884
I0528 17:10:13.952252 10644 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0528 17:10:13.952270 10644 net.cpp:100] Creating Layer bn2a_branch2c
I0528 17:10:13.952277 10644 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0528 17:10:13.952291 10644 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0528 17:10:13.953398 10644 net.cpp:150] Setting up bn2a_branch2c
I0528 17:10:13.953410 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.953413 10644 net.cpp:165] Memory required for data: 645529684
I0528 17:10:13.953438 10644 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0528 17:10:13.953459 10644 net.cpp:100] Creating Layer scale2a_branch2c
I0528 17:10:13.953469 10644 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0528 17:10:13.953485 10644 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0528 17:10:13.953553 10644 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0528 17:10:13.953820 10644 net.cpp:150] Setting up scale2a_branch2c
I0528 17:10:13.953829 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.953831 10644 net.cpp:165] Memory required for data: 697958484
I0528 17:10:13.953843 10644 layer_factory.hpp:77] Creating layer res2a
I0528 17:10:13.953855 10644 net.cpp:100] Creating Layer res2a
I0528 17:10:13.953861 10644 net.cpp:444] res2a <- res2a_branch1
I0528 17:10:13.953873 10644 net.cpp:444] res2a <- res2a_branch2c
I0528 17:10:13.953883 10644 net.cpp:418] res2a -> res2a
I0528 17:10:13.953925 10644 net.cpp:150] Setting up res2a
I0528 17:10:13.953934 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.953938 10644 net.cpp:165] Memory required for data: 750387284
I0528 17:10:13.953943 10644 layer_factory.hpp:77] Creating layer res2a_relu
I0528 17:10:13.953954 10644 net.cpp:100] Creating Layer res2a_relu
I0528 17:10:13.953959 10644 net.cpp:444] res2a_relu <- res2a
I0528 17:10:13.953971 10644 net.cpp:405] res2a_relu -> res2a (in-place)
I0528 17:10:13.954136 10644 net.cpp:150] Setting up res2a_relu
I0528 17:10:13.954144 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.954147 10644 net.cpp:165] Memory required for data: 802816084
I0528 17:10:13.954151 10644 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0528 17:10:13.954164 10644 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0528 17:10:13.954169 10644 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0528 17:10:13.954182 10644 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0528 17:10:13.954198 10644 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0528 17:10:13.954248 10644 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0528 17:10:13.954257 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.954263 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.954267 10644 net.cpp:165] Memory required for data: 907673684
I0528 17:10:13.954272 10644 layer_factory.hpp:77] Creating layer res2b_branch2a
I0528 17:10:13.954288 10644 net.cpp:100] Creating Layer res2b_branch2a
I0528 17:10:13.954294 10644 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0528 17:10:13.954310 10644 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0528 17:10:13.955265 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.955524 10644 net.cpp:150] Setting up res2b_branch2a
I0528 17:10:13.955534 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.955539 10644 net.cpp:165] Memory required for data: 920780884
I0528 17:10:13.955552 10644 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0528 17:10:13.955569 10644 net.cpp:100] Creating Layer bn2b_branch2a
I0528 17:10:13.955575 10644 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0528 17:10:13.955591 10644 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0528 17:10:13.955883 10644 net.cpp:150] Setting up bn2b_branch2a
I0528 17:10:13.955893 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.955895 10644 net.cpp:165] Memory required for data: 933888084
I0528 17:10:13.955926 10644 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0528 17:10:13.955943 10644 net.cpp:100] Creating Layer scale2b_branch2a
I0528 17:10:13.955950 10644 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0528 17:10:13.955963 10644 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0528 17:10:13.956027 10644 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0528 17:10:13.956312 10644 net.cpp:150] Setting up scale2b_branch2a
I0528 17:10:13.956321 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.956323 10644 net.cpp:165] Memory required for data: 946995284
I0528 17:10:13.956336 10644 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0528 17:10:13.956347 10644 net.cpp:100] Creating Layer res2b_branch2a_relu
I0528 17:10:13.956353 10644 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0528 17:10:13.956367 10644 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0528 17:10:13.956514 10644 net.cpp:150] Setting up res2b_branch2a_relu
I0528 17:10:13.956521 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.956524 10644 net.cpp:165] Memory required for data: 960102484
I0528 17:10:13.956529 10644 layer_factory.hpp:77] Creating layer res2b_branch2b
I0528 17:10:13.956547 10644 net.cpp:100] Creating Layer res2b_branch2b
I0528 17:10:13.956552 10644 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0528 17:10:13.956570 10644 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0528 17:10:13.957490 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0528 17:10:13.957511 10644 net.cpp:150] Setting up res2b_branch2b
I0528 17:10:13.957520 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.957523 10644 net.cpp:165] Memory required for data: 973209684
I0528 17:10:13.957535 10644 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0528 17:10:13.957557 10644 net.cpp:100] Creating Layer bn2b_branch2b
I0528 17:10:13.957564 10644 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0528 17:10:13.957581 10644 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0528 17:10:13.957867 10644 net.cpp:150] Setting up bn2b_branch2b
I0528 17:10:13.957875 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.957877 10644 net.cpp:165] Memory required for data: 986316884
I0528 17:10:13.957895 10644 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0528 17:10:13.957908 10644 net.cpp:100] Creating Layer scale2b_branch2b
I0528 17:10:13.957916 10644 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0528 17:10:13.957929 10644 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0528 17:10:13.957989 10644 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0528 17:10:13.958264 10644 net.cpp:150] Setting up scale2b_branch2b
I0528 17:10:13.958272 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.958276 10644 net.cpp:165] Memory required for data: 999424084
I0528 17:10:13.958287 10644 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0528 17:10:13.958298 10644 net.cpp:100] Creating Layer res2b_branch2b_relu
I0528 17:10:13.958304 10644 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0528 17:10:13.958317 10644 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0528 17:10:13.958686 10644 net.cpp:150] Setting up res2b_branch2b_relu
I0528 17:10:13.958695 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.958698 10644 net.cpp:165] Memory required for data: 1012531284
I0528 17:10:13.958703 10644 layer_factory.hpp:77] Creating layer res2b_branch2c
I0528 17:10:13.958721 10644 net.cpp:100] Creating Layer res2b_branch2c
I0528 17:10:13.958727 10644 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0528 17:10:13.958744 10644 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0528 17:10:13.959594 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.959828 10644 net.cpp:150] Setting up res2b_branch2c
I0528 17:10:13.959841 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.959844 10644 net.cpp:165] Memory required for data: 1064960084
I0528 17:10:13.959856 10644 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0528 17:10:13.959869 10644 net.cpp:100] Creating Layer bn2b_branch2c
I0528 17:10:13.959877 10644 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0528 17:10:13.959892 10644 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0528 17:10:13.960834 10644 net.cpp:150] Setting up bn2b_branch2c
I0528 17:10:13.960842 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.960845 10644 net.cpp:165] Memory required for data: 1117388884
I0528 17:10:13.960863 10644 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0528 17:10:13.960880 10644 net.cpp:100] Creating Layer scale2b_branch2c
I0528 17:10:13.960887 10644 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0528 17:10:13.960903 10644 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0528 17:10:13.960981 10644 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0528 17:10:13.961256 10644 net.cpp:150] Setting up scale2b_branch2c
I0528 17:10:13.961264 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.961267 10644 net.cpp:165] Memory required for data: 1169817684
I0528 17:10:13.961279 10644 layer_factory.hpp:77] Creating layer res2b
I0528 17:10:13.961292 10644 net.cpp:100] Creating Layer res2b
I0528 17:10:13.961298 10644 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0528 17:10:13.961309 10644 net.cpp:444] res2b <- res2b_branch2c
I0528 17:10:13.961320 10644 net.cpp:418] res2b -> res2b
I0528 17:10:13.961360 10644 net.cpp:150] Setting up res2b
I0528 17:10:13.961369 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.961374 10644 net.cpp:165] Memory required for data: 1222246484
I0528 17:10:13.961377 10644 layer_factory.hpp:77] Creating layer res2b_relu
I0528 17:10:13.961388 10644 net.cpp:100] Creating Layer res2b_relu
I0528 17:10:13.961395 10644 net.cpp:444] res2b_relu <- res2b
I0528 17:10:13.961407 10644 net.cpp:405] res2b_relu -> res2b (in-place)
I0528 17:10:13.961549 10644 net.cpp:150] Setting up res2b_relu
I0528 17:10:13.961556 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.961560 10644 net.cpp:165] Memory required for data: 1274675284
I0528 17:10:13.961565 10644 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0528 17:10:13.961575 10644 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0528 17:10:13.961581 10644 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0528 17:10:13.961596 10644 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0528 17:10:13.961611 10644 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0528 17:10:13.961664 10644 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0528 17:10:13.961673 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.961678 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.961683 10644 net.cpp:165] Memory required for data: 1379532884
I0528 17:10:13.961686 10644 layer_factory.hpp:77] Creating layer res2c_branch2a
I0528 17:10:13.961702 10644 net.cpp:100] Creating Layer res2c_branch2a
I0528 17:10:13.961709 10644 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0528 17:10:13.961724 10644 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0528 17:10:13.962600 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.962620 10644 net.cpp:150] Setting up res2c_branch2a
I0528 17:10:13.962630 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.962632 10644 net.cpp:165] Memory required for data: 1392640084
I0528 17:10:13.962644 10644 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0528 17:10:13.962658 10644 net.cpp:100] Creating Layer bn2c_branch2a
I0528 17:10:13.962666 10644 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0528 17:10:13.962682 10644 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0528 17:10:13.962980 10644 net.cpp:150] Setting up bn2c_branch2a
I0528 17:10:13.962986 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.962990 10644 net.cpp:165] Memory required for data: 1405747284
I0528 17:10:13.963006 10644 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0528 17:10:13.963021 10644 net.cpp:100] Creating Layer scale2c_branch2a
I0528 17:10:13.963027 10644 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0528 17:10:13.963040 10644 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0528 17:10:13.963101 10644 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0528 17:10:13.963377 10644 net.cpp:150] Setting up scale2c_branch2a
I0528 17:10:13.963384 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.963388 10644 net.cpp:165] Memory required for data: 1418854484
I0528 17:10:13.963400 10644 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0528 17:10:13.963412 10644 net.cpp:100] Creating Layer res2c_branch2a_relu
I0528 17:10:13.963418 10644 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0528 17:10:13.963431 10644 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0528 17:10:13.963564 10644 net.cpp:150] Setting up res2c_branch2a_relu
I0528 17:10:13.963572 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.963574 10644 net.cpp:165] Memory required for data: 1431961684
I0528 17:10:13.963579 10644 layer_factory.hpp:77] Creating layer res2c_branch2b
I0528 17:10:13.963595 10644 net.cpp:100] Creating Layer res2c_branch2b
I0528 17:10:13.963601 10644 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0528 17:10:13.963618 10644 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0528 17:10:13.964516 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0528 17:10:13.964766 10644 net.cpp:150] Setting up res2c_branch2b
I0528 17:10:13.964776 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.964781 10644 net.cpp:165] Memory required for data: 1445068884
I0528 17:10:13.964793 10644 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0528 17:10:13.964810 10644 net.cpp:100] Creating Layer bn2c_branch2b
I0528 17:10:13.964818 10644 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0528 17:10:13.964833 10644 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0528 17:10:13.965140 10644 net.cpp:150] Setting up bn2c_branch2b
I0528 17:10:13.965148 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.965152 10644 net.cpp:165] Memory required for data: 1458176084
I0528 17:10:13.965167 10644 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0528 17:10:13.965183 10644 net.cpp:100] Creating Layer scale2c_branch2b
I0528 17:10:13.965189 10644 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0528 17:10:13.965204 10644 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0528 17:10:13.965265 10644 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0528 17:10:13.965543 10644 net.cpp:150] Setting up scale2c_branch2b
I0528 17:10:13.965550 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.965553 10644 net.cpp:165] Memory required for data: 1471283284
I0528 17:10:13.965565 10644 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0528 17:10:13.965579 10644 net.cpp:100] Creating Layer res2c_branch2b_relu
I0528 17:10:13.965585 10644 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0528 17:10:13.965597 10644 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0528 17:10:13.965741 10644 net.cpp:150] Setting up res2c_branch2b_relu
I0528 17:10:13.965749 10644 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0528 17:10:13.965751 10644 net.cpp:165] Memory required for data: 1484390484
I0528 17:10:13.965756 10644 layer_factory.hpp:77] Creating layer res2c_branch2c
I0528 17:10:13.965773 10644 net.cpp:100] Creating Layer res2c_branch2c
I0528 17:10:13.965780 10644 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0528 17:10:13.965804 10644 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0528 17:10:13.966712 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0528 17:10:13.966727 10644 net.cpp:150] Setting up res2c_branch2c
I0528 17:10:13.966737 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.966740 10644 net.cpp:165] Memory required for data: 1536819284
I0528 17:10:13.966753 10644 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0528 17:10:13.966768 10644 net.cpp:100] Creating Layer bn2c_branch2c
I0528 17:10:13.966774 10644 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0528 17:10:13.966791 10644 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0528 17:10:13.967770 10644 net.cpp:150] Setting up bn2c_branch2c
I0528 17:10:13.967779 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.967783 10644 net.cpp:165] Memory required for data: 1589248084
I0528 17:10:13.967823 10644 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0528 17:10:13.967841 10644 net.cpp:100] Creating Layer scale2c_branch2c
I0528 17:10:13.967849 10644 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0528 17:10:13.967864 10644 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0528 17:10:13.967927 10644 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0528 17:10:13.968196 10644 net.cpp:150] Setting up scale2c_branch2c
I0528 17:10:13.968204 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.968206 10644 net.cpp:165] Memory required for data: 1641676884
I0528 17:10:13.968219 10644 layer_factory.hpp:77] Creating layer res2c
I0528 17:10:13.968230 10644 net.cpp:100] Creating Layer res2c
I0528 17:10:13.968237 10644 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0528 17:10:13.968248 10644 net.cpp:444] res2c <- res2c_branch2c
I0528 17:10:13.968261 10644 net.cpp:418] res2c -> res2c
I0528 17:10:13.968299 10644 net.cpp:150] Setting up res2c
I0528 17:10:13.968308 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.968312 10644 net.cpp:165] Memory required for data: 1694105684
I0528 17:10:13.968317 10644 layer_factory.hpp:77] Creating layer res2c_relu
I0528 17:10:13.968328 10644 net.cpp:100] Creating Layer res2c_relu
I0528 17:10:13.968333 10644 net.cpp:444] res2c_relu <- res2c
I0528 17:10:13.968346 10644 net.cpp:405] res2c_relu -> res2c (in-place)
I0528 17:10:13.968739 10644 net.cpp:150] Setting up res2c_relu
I0528 17:10:13.968746 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.968750 10644 net.cpp:165] Memory required for data: 1746534484
I0528 17:10:13.968755 10644 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0528 17:10:13.968768 10644 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0528 17:10:13.968775 10644 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0528 17:10:13.968789 10644 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0528 17:10:13.968807 10644 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0528 17:10:13.968861 10644 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0528 17:10:13.968870 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.968876 10644 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0528 17:10:13.968880 10644 net.cpp:165] Memory required for data: 1851392084
I0528 17:10:13.968885 10644 layer_factory.hpp:77] Creating layer res3a_branch1
I0528 17:10:13.968902 10644 net.cpp:100] Creating Layer res3a_branch1
I0528 17:10:13.968909 10644 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0528 17:10:13.968933 10644 net.cpp:418] res3a_branch1 -> res3a_branch1
I0528 17:10:13.970712 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 230424
I0528 17:10:13.970973 10644 net.cpp:150] Setting up res3a_branch1
I0528 17:10:13.970990 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.970994 10644 net.cpp:165] Memory required for data: 1877606484
I0528 17:10:13.971011 10644 layer_factory.hpp:77] Creating layer bn3a_branch1
I0528 17:10:13.971036 10644 net.cpp:100] Creating Layer bn3a_branch1
I0528 17:10:13.971047 10644 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0528 17:10:13.971067 10644 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0528 17:10:13.972059 10644 net.cpp:150] Setting up bn3a_branch1
I0528 17:10:13.972070 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.972074 10644 net.cpp:165] Memory required for data: 1903820884
I0528 17:10:13.972095 10644 layer_factory.hpp:77] Creating layer scale3a_branch1
I0528 17:10:13.972115 10644 net.cpp:100] Creating Layer scale3a_branch1
I0528 17:10:13.972121 10644 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0528 17:10:13.972137 10644 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0528 17:10:13.972200 10644 layer_factory.hpp:77] Creating layer scale3a_branch1
I0528 17:10:13.972385 10644 net.cpp:150] Setting up scale3a_branch1
I0528 17:10:13.972393 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.972396 10644 net.cpp:165] Memory required for data: 1930035284
I0528 17:10:13.972409 10644 layer_factory.hpp:77] Creating layer res3a_branch2a
I0528 17:10:13.972426 10644 net.cpp:100] Creating Layer res3a_branch2a
I0528 17:10:13.972434 10644 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0528 17:10:13.972448 10644 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0528 17:10:13.973446 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 230424
I0528 17:10:13.973464 10644 net.cpp:150] Setting up res3a_branch2a
I0528 17:10:13.973474 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.973476 10644 net.cpp:165] Memory required for data: 1936588884
I0528 17:10:13.973489 10644 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0528 17:10:13.973505 10644 net.cpp:100] Creating Layer bn3a_branch2a
I0528 17:10:13.973511 10644 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0528 17:10:13.973526 10644 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0528 17:10:13.973767 10644 net.cpp:150] Setting up bn3a_branch2a
I0528 17:10:13.973773 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.973776 10644 net.cpp:165] Memory required for data: 1943142484
I0528 17:10:13.973793 10644 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0528 17:10:13.973809 10644 net.cpp:100] Creating Layer scale3a_branch2a
I0528 17:10:13.973814 10644 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0528 17:10:13.973827 10644 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0528 17:10:13.973886 10644 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0528 17:10:13.974058 10644 net.cpp:150] Setting up scale3a_branch2a
I0528 17:10:13.974066 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.974069 10644 net.cpp:165] Memory required for data: 1949696084
I0528 17:10:13.974081 10644 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0528 17:10:13.974092 10644 net.cpp:100] Creating Layer res3a_branch2a_relu
I0528 17:10:13.974099 10644 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0528 17:10:13.974113 10644 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0528 17:10:13.974247 10644 net.cpp:150] Setting up res3a_branch2a_relu
I0528 17:10:13.974256 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.974258 10644 net.cpp:165] Memory required for data: 1956249684
I0528 17:10:13.974263 10644 layer_factory.hpp:77] Creating layer res3a_branch2b
I0528 17:10:13.974278 10644 net.cpp:100] Creating Layer res3a_branch2b
I0528 17:10:13.974284 10644 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0528 17:10:13.974300 10644 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0528 17:10:13.975368 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0528 17:10:13.975613 10644 net.cpp:150] Setting up res3a_branch2b
I0528 17:10:13.975625 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.975628 10644 net.cpp:165] Memory required for data: 1962803284
I0528 17:10:13.975641 10644 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0528 17:10:13.975656 10644 net.cpp:100] Creating Layer bn3a_branch2b
I0528 17:10:13.975663 10644 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0528 17:10:13.975678 10644 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0528 17:10:13.975922 10644 net.cpp:150] Setting up bn3a_branch2b
I0528 17:10:13.975929 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.975932 10644 net.cpp:165] Memory required for data: 1969356884
I0528 17:10:13.975950 10644 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0528 17:10:13.975975 10644 net.cpp:100] Creating Layer scale3a_branch2b
I0528 17:10:13.975981 10644 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0528 17:10:13.975994 10644 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0528 17:10:13.976054 10644 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0528 17:10:13.976230 10644 net.cpp:150] Setting up scale3a_branch2b
I0528 17:10:13.976238 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.976240 10644 net.cpp:165] Memory required for data: 1975910484
I0528 17:10:13.976254 10644 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0528 17:10:13.976267 10644 net.cpp:100] Creating Layer res3a_branch2b_relu
I0528 17:10:13.976274 10644 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0528 17:10:13.976286 10644 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0528 17:10:13.976424 10644 net.cpp:150] Setting up res3a_branch2b_relu
I0528 17:10:13.976431 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.976434 10644 net.cpp:165] Memory required for data: 1982464084
I0528 17:10:13.976439 10644 layer_factory.hpp:77] Creating layer res3a_branch2c
I0528 17:10:13.976455 10644 net.cpp:100] Creating Layer res3a_branch2c
I0528 17:10:13.976461 10644 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0528 17:10:13.976477 10644 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0528 17:10:13.977421 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:13.977439 10644 net.cpp:150] Setting up res3a_branch2c
I0528 17:10:13.977448 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.977452 10644 net.cpp:165] Memory required for data: 2008678484
I0528 17:10:13.977463 10644 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0528 17:10:13.977478 10644 net.cpp:100] Creating Layer bn3a_branch2c
I0528 17:10:13.977485 10644 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0528 17:10:13.977500 10644 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0528 17:10:13.977744 10644 net.cpp:150] Setting up bn3a_branch2c
I0528 17:10:13.977751 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.977754 10644 net.cpp:165] Memory required for data: 2034892884
I0528 17:10:13.977771 10644 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0528 17:10:13.977787 10644 net.cpp:100] Creating Layer scale3a_branch2c
I0528 17:10:13.977792 10644 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0528 17:10:13.977807 10644 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0528 17:10:13.977861 10644 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0528 17:10:13.978041 10644 net.cpp:150] Setting up scale3a_branch2c
I0528 17:10:13.978049 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.978051 10644 net.cpp:165] Memory required for data: 2061107284
I0528 17:10:13.978063 10644 layer_factory.hpp:77] Creating layer res3a
I0528 17:10:13.978075 10644 net.cpp:100] Creating Layer res3a
I0528 17:10:13.978081 10644 net.cpp:444] res3a <- res3a_branch1
I0528 17:10:13.978093 10644 net.cpp:444] res3a <- res3a_branch2c
I0528 17:10:13.978106 10644 net.cpp:418] res3a -> res3a
I0528 17:10:13.978143 10644 net.cpp:150] Setting up res3a
I0528 17:10:13.978152 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.978155 10644 net.cpp:165] Memory required for data: 2087321684
I0528 17:10:13.978160 10644 layer_factory.hpp:77] Creating layer res3a_relu
I0528 17:10:13.978173 10644 net.cpp:100] Creating Layer res3a_relu
I0528 17:10:13.978178 10644 net.cpp:444] res3a_relu <- res3a
I0528 17:10:13.978190 10644 net.cpp:405] res3a_relu -> res3a (in-place)
I0528 17:10:13.978557 10644 net.cpp:150] Setting up res3a_relu
I0528 17:10:13.978565 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.978569 10644 net.cpp:165] Memory required for data: 2113536084
I0528 17:10:13.978574 10644 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0528 17:10:13.978587 10644 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0528 17:10:13.978593 10644 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0528 17:10:13.978610 10644 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0528 17:10:13.978626 10644 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0528 17:10:13.978682 10644 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0528 17:10:13.978690 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.978695 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.978698 10644 net.cpp:165] Memory required for data: 2165964884
I0528 17:10:13.978703 10644 layer_factory.hpp:77] Creating layer res3b_branch2a
I0528 17:10:13.978719 10644 net.cpp:100] Creating Layer res3b_branch2a
I0528 17:10:13.978726 10644 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0528 17:10:13.978742 10644 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0528 17:10:13.979666 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:13.979687 10644 net.cpp:150] Setting up res3b_branch2a
I0528 17:10:13.979696 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.979699 10644 net.cpp:165] Memory required for data: 2172518484
I0528 17:10:13.979710 10644 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0528 17:10:13.979723 10644 net.cpp:100] Creating Layer bn3b_branch2a
I0528 17:10:13.979730 10644 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0528 17:10:13.979746 10644 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0528 17:10:13.979995 10644 net.cpp:150] Setting up bn3b_branch2a
I0528 17:10:13.980001 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.980005 10644 net.cpp:165] Memory required for data: 2179072084
I0528 17:10:13.980021 10644 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0528 17:10:13.980036 10644 net.cpp:100] Creating Layer scale3b_branch2a
I0528 17:10:13.980042 10644 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0528 17:10:13.980057 10644 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0528 17:10:13.980116 10644 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0528 17:10:13.980289 10644 net.cpp:150] Setting up scale3b_branch2a
I0528 17:10:13.980296 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.980299 10644 net.cpp:165] Memory required for data: 2185625684
I0528 17:10:13.980311 10644 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0528 17:10:13.980322 10644 net.cpp:100] Creating Layer res3b_branch2a_relu
I0528 17:10:13.980329 10644 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0528 17:10:13.980341 10644 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0528 17:10:13.980478 10644 net.cpp:150] Setting up res3b_branch2a_relu
I0528 17:10:13.980484 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.980487 10644 net.cpp:165] Memory required for data: 2192179284
I0528 17:10:13.980492 10644 layer_factory.hpp:77] Creating layer res3b_branch2b
I0528 17:10:13.980509 10644 net.cpp:100] Creating Layer res3b_branch2b
I0528 17:10:13.980515 10644 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0528 17:10:13.980530 10644 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0528 17:10:13.981818 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0528 17:10:13.982059 10644 net.cpp:150] Setting up res3b_branch2b
I0528 17:10:13.982070 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.982074 10644 net.cpp:165] Memory required for data: 2198732884
I0528 17:10:13.982086 10644 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0528 17:10:13.982101 10644 net.cpp:100] Creating Layer bn3b_branch2b
I0528 17:10:13.982108 10644 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0528 17:10:13.982125 10644 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0528 17:10:13.982376 10644 net.cpp:150] Setting up bn3b_branch2b
I0528 17:10:13.982383 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.982386 10644 net.cpp:165] Memory required for data: 2205286484
I0528 17:10:13.982403 10644 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0528 17:10:13.982419 10644 net.cpp:100] Creating Layer scale3b_branch2b
I0528 17:10:13.982424 10644 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0528 17:10:13.982437 10644 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0528 17:10:13.982498 10644 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0528 17:10:13.982677 10644 net.cpp:150] Setting up scale3b_branch2b
I0528 17:10:13.982684 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.982687 10644 net.cpp:165] Memory required for data: 2211840084
I0528 17:10:13.982699 10644 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0528 17:10:13.982710 10644 net.cpp:100] Creating Layer res3b_branch2b_relu
I0528 17:10:13.982717 10644 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0528 17:10:13.982729 10644 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0528 17:10:13.982870 10644 net.cpp:150] Setting up res3b_branch2b_relu
I0528 17:10:13.982877 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.982880 10644 net.cpp:165] Memory required for data: 2218393684
I0528 17:10:13.982885 10644 layer_factory.hpp:77] Creating layer res3b_branch2c
I0528 17:10:13.982903 10644 net.cpp:100] Creating Layer res3b_branch2c
I0528 17:10:13.982909 10644 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0528 17:10:13.982925 10644 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0528 17:10:13.983861 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:13.983881 10644 net.cpp:150] Setting up res3b_branch2c
I0528 17:10:13.983891 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.983894 10644 net.cpp:165] Memory required for data: 2244608084
I0528 17:10:13.983906 10644 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0528 17:10:13.983920 10644 net.cpp:100] Creating Layer bn3b_branch2c
I0528 17:10:13.983927 10644 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0528 17:10:13.983942 10644 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0528 17:10:13.984189 10644 net.cpp:150] Setting up bn3b_branch2c
I0528 17:10:13.984196 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.984200 10644 net.cpp:165] Memory required for data: 2270822484
I0528 17:10:13.984216 10644 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0528 17:10:13.984230 10644 net.cpp:100] Creating Layer scale3b_branch2c
I0528 17:10:13.984236 10644 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0528 17:10:13.984251 10644 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0528 17:10:13.984306 10644 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0528 17:10:13.984490 10644 net.cpp:150] Setting up scale3b_branch2c
I0528 17:10:13.984498 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.984501 10644 net.cpp:165] Memory required for data: 2297036884
I0528 17:10:13.984513 10644 layer_factory.hpp:77] Creating layer res3b
I0528 17:10:13.984524 10644 net.cpp:100] Creating Layer res3b
I0528 17:10:13.984530 10644 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0528 17:10:13.984542 10644 net.cpp:444] res3b <- res3b_branch2c
I0528 17:10:13.984553 10644 net.cpp:418] res3b -> res3b
I0528 17:10:13.984593 10644 net.cpp:150] Setting up res3b
I0528 17:10:13.984601 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.984606 10644 net.cpp:165] Memory required for data: 2323251284
I0528 17:10:13.984611 10644 layer_factory.hpp:77] Creating layer res3b_relu
I0528 17:10:13.984621 10644 net.cpp:100] Creating Layer res3b_relu
I0528 17:10:13.984627 10644 net.cpp:444] res3b_relu <- res3b
I0528 17:10:13.984639 10644 net.cpp:405] res3b_relu -> res3b (in-place)
I0528 17:10:13.986297 10644 net.cpp:150] Setting up res3b_relu
I0528 17:10:13.986306 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.986310 10644 net.cpp:165] Memory required for data: 2349465684
I0528 17:10:13.986315 10644 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0528 17:10:13.986330 10644 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0528 17:10:13.986335 10644 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0528 17:10:13.986351 10644 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0528 17:10:13.986368 10644 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0528 17:10:13.986425 10644 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0528 17:10:13.986433 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.986439 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.986443 10644 net.cpp:165] Memory required for data: 2401894484
I0528 17:10:13.986446 10644 layer_factory.hpp:77] Creating layer res3c_branch2a
I0528 17:10:13.986464 10644 net.cpp:100] Creating Layer res3c_branch2a
I0528 17:10:13.986470 10644 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0528 17:10:13.986485 10644 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0528 17:10:13.987423 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:13.987443 10644 net.cpp:150] Setting up res3c_branch2a
I0528 17:10:13.987452 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.987455 10644 net.cpp:165] Memory required for data: 2408448084
I0528 17:10:13.987466 10644 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0528 17:10:13.987481 10644 net.cpp:100] Creating Layer bn3c_branch2a
I0528 17:10:13.987488 10644 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0528 17:10:13.987504 10644 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0528 17:10:13.987751 10644 net.cpp:150] Setting up bn3c_branch2a
I0528 17:10:13.987757 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.987761 10644 net.cpp:165] Memory required for data: 2415001684
I0528 17:10:13.987777 10644 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0528 17:10:13.987792 10644 net.cpp:100] Creating Layer scale3c_branch2a
I0528 17:10:13.987798 10644 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0528 17:10:13.987812 10644 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0528 17:10:13.987871 10644 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0528 17:10:13.988050 10644 net.cpp:150] Setting up scale3c_branch2a
I0528 17:10:13.988059 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.988061 10644 net.cpp:165] Memory required for data: 2421555284
I0528 17:10:13.988073 10644 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0528 17:10:13.988085 10644 net.cpp:100] Creating Layer res3c_branch2a_relu
I0528 17:10:13.988090 10644 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0528 17:10:13.988103 10644 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0528 17:10:13.988237 10644 net.cpp:150] Setting up res3c_branch2a_relu
I0528 17:10:13.988245 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.988247 10644 net.cpp:165] Memory required for data: 2428108884
I0528 17:10:13.988252 10644 layer_factory.hpp:77] Creating layer res3c_branch2b
I0528 17:10:13.988270 10644 net.cpp:100] Creating Layer res3c_branch2b
I0528 17:10:13.988276 10644 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0528 17:10:13.988291 10644 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0528 17:10:13.990092 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0528 17:10:13.990337 10644 net.cpp:150] Setting up res3c_branch2b
I0528 17:10:13.990350 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.990355 10644 net.cpp:165] Memory required for data: 2434662484
I0528 17:10:13.990370 10644 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0528 17:10:13.990387 10644 net.cpp:100] Creating Layer bn3c_branch2b
I0528 17:10:13.990396 10644 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0528 17:10:13.990412 10644 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0528 17:10:13.990670 10644 net.cpp:150] Setting up bn3c_branch2b
I0528 17:10:13.990679 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.990681 10644 net.cpp:165] Memory required for data: 2441216084
I0528 17:10:13.990697 10644 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0528 17:10:13.990713 10644 net.cpp:100] Creating Layer scale3c_branch2b
I0528 17:10:13.990720 10644 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0528 17:10:13.990733 10644 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0528 17:10:13.990797 10644 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0528 17:10:13.990978 10644 net.cpp:150] Setting up scale3c_branch2b
I0528 17:10:13.990986 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.990989 10644 net.cpp:165] Memory required for data: 2447769684
I0528 17:10:13.991001 10644 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0528 17:10:13.991013 10644 net.cpp:100] Creating Layer res3c_branch2b_relu
I0528 17:10:13.991019 10644 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0528 17:10:13.991031 10644 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0528 17:10:13.991174 10644 net.cpp:150] Setting up res3c_branch2b_relu
I0528 17:10:13.991183 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.991186 10644 net.cpp:165] Memory required for data: 2454323284
I0528 17:10:13.991191 10644 layer_factory.hpp:77] Creating layer res3c_branch2c
I0528 17:10:13.991225 10644 net.cpp:100] Creating Layer res3c_branch2c
I0528 17:10:13.991231 10644 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0528 17:10:13.991245 10644 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0528 17:10:13.992220 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:13.992238 10644 net.cpp:150] Setting up res3c_branch2c
I0528 17:10:13.992245 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.992249 10644 net.cpp:165] Memory required for data: 2480537684
I0528 17:10:13.992256 10644 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0528 17:10:13.992269 10644 net.cpp:100] Creating Layer bn3c_branch2c
I0528 17:10:13.992274 10644 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0528 17:10:13.992286 10644 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0528 17:10:13.992534 10644 net.cpp:150] Setting up bn3c_branch2c
I0528 17:10:13.992540 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.992542 10644 net.cpp:165] Memory required for data: 2506752084
I0528 17:10:13.992555 10644 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0528 17:10:13.992566 10644 net.cpp:100] Creating Layer scale3c_branch2c
I0528 17:10:13.992571 10644 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0528 17:10:13.992581 10644 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0528 17:10:13.992635 10644 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0528 17:10:13.992857 10644 net.cpp:150] Setting up scale3c_branch2c
I0528 17:10:13.992877 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.992887 10644 net.cpp:165] Memory required for data: 2532966484
I0528 17:10:13.992905 10644 layer_factory.hpp:77] Creating layer res3c
I0528 17:10:13.992964 10644 net.cpp:100] Creating Layer res3c
I0528 17:10:13.992977 10644 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0528 17:10:13.992995 10644 net.cpp:444] res3c <- res3c_branch2c
I0528 17:10:13.993012 10644 net.cpp:418] res3c -> res3c
I0528 17:10:13.993069 10644 net.cpp:150] Setting up res3c
I0528 17:10:13.993085 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.993094 10644 net.cpp:165] Memory required for data: 2559180884
I0528 17:10:13.993105 10644 layer_factory.hpp:77] Creating layer res3c_relu
I0528 17:10:13.993121 10644 net.cpp:100] Creating Layer res3c_relu
I0528 17:10:13.993134 10644 net.cpp:444] res3c_relu <- res3c
I0528 17:10:13.993151 10644 net.cpp:405] res3c_relu -> res3c (in-place)
I0528 17:10:13.993331 10644 net.cpp:150] Setting up res3c_relu
I0528 17:10:13.993348 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.993358 10644 net.cpp:165] Memory required for data: 2585395284
I0528 17:10:13.993365 10644 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0528 17:10:13.993376 10644 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0528 17:10:13.993382 10644 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0528 17:10:13.993397 10644 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0528 17:10:13.993414 10644 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0528 17:10:13.993474 10644 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0528 17:10:13.993482 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.993487 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:13.993489 10644 net.cpp:165] Memory required for data: 2637824084
I0528 17:10:13.993495 10644 layer_factory.hpp:77] Creating layer res3d_branch2a
I0528 17:10:13.993512 10644 net.cpp:100] Creating Layer res3d_branch2a
I0528 17:10:13.993518 10644 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0528 17:10:13.993535 10644 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0528 17:10:13.995376 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:13.995402 10644 net.cpp:150] Setting up res3d_branch2a
I0528 17:10:13.995414 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.995417 10644 net.cpp:165] Memory required for data: 2644377684
I0528 17:10:13.995432 10644 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0528 17:10:13.995453 10644 net.cpp:100] Creating Layer bn3d_branch2a
I0528 17:10:13.995461 10644 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0528 17:10:13.995477 10644 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0528 17:10:13.995736 10644 net.cpp:150] Setting up bn3d_branch2a
I0528 17:10:13.995743 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.995746 10644 net.cpp:165] Memory required for data: 2650931284
I0528 17:10:13.995787 10644 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0528 17:10:13.995805 10644 net.cpp:100] Creating Layer scale3d_branch2a
I0528 17:10:13.995810 10644 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0528 17:10:13.995826 10644 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0528 17:10:13.995887 10644 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0528 17:10:13.996727 10644 net.cpp:150] Setting up scale3d_branch2a
I0528 17:10:13.996737 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.996739 10644 net.cpp:165] Memory required for data: 2657484884
I0528 17:10:13.996753 10644 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0528 17:10:13.996767 10644 net.cpp:100] Creating Layer res3d_branch2a_relu
I0528 17:10:13.996773 10644 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0528 17:10:13.996788 10644 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0528 17:10:13.997189 10644 net.cpp:150] Setting up res3d_branch2a_relu
I0528 17:10:13.997198 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.997201 10644 net.cpp:165] Memory required for data: 2664038484
I0528 17:10:13.997207 10644 layer_factory.hpp:77] Creating layer res3d_branch2b
I0528 17:10:13.997226 10644 net.cpp:100] Creating Layer res3d_branch2b
I0528 17:10:13.997233 10644 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0528 17:10:13.997251 10644 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0528 17:10:13.998404 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0528 17:10:13.998656 10644 net.cpp:150] Setting up res3d_branch2b
I0528 17:10:13.998667 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.998672 10644 net.cpp:165] Memory required for data: 2670592084
I0528 17:10:13.998684 10644 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0528 17:10:13.998702 10644 net.cpp:100] Creating Layer bn3d_branch2b
I0528 17:10:13.998708 10644 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0528 17:10:13.998724 10644 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0528 17:10:13.998982 10644 net.cpp:150] Setting up bn3d_branch2b
I0528 17:10:13.998991 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.998993 10644 net.cpp:165] Memory required for data: 2677145684
I0528 17:10:13.999011 10644 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0528 17:10:13.999024 10644 net.cpp:100] Creating Layer scale3d_branch2b
I0528 17:10:13.999030 10644 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0528 17:10:13.999045 10644 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0528 17:10:13.999107 10644 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0528 17:10:13.999290 10644 net.cpp:150] Setting up scale3d_branch2b
I0528 17:10:13.999297 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.999300 10644 net.cpp:165] Memory required for data: 2683699284
I0528 17:10:13.999313 10644 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0528 17:10:13.999325 10644 net.cpp:100] Creating Layer res3d_branch2b_relu
I0528 17:10:13.999331 10644 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0528 17:10:13.999346 10644 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0528 17:10:13.999491 10644 net.cpp:150] Setting up res3d_branch2b_relu
I0528 17:10:13.999498 10644 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0528 17:10:13.999501 10644 net.cpp:165] Memory required for data: 2690252884
I0528 17:10:13.999506 10644 layer_factory.hpp:77] Creating layer res3d_branch2c
I0528 17:10:13.999523 10644 net.cpp:100] Creating Layer res3d_branch2c
I0528 17:10:13.999529 10644 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0528 17:10:13.999557 10644 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0528 17:10:14.000571 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0528 17:10:14.000829 10644 net.cpp:150] Setting up res3d_branch2c
I0528 17:10:14.000840 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.000845 10644 net.cpp:165] Memory required for data: 2716467284
I0528 17:10:14.000857 10644 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0528 17:10:14.000872 10644 net.cpp:100] Creating Layer bn3d_branch2c
I0528 17:10:14.000879 10644 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0528 17:10:14.000895 10644 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0528 17:10:14.001173 10644 net.cpp:150] Setting up bn3d_branch2c
I0528 17:10:14.001181 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.001184 10644 net.cpp:165] Memory required for data: 2742681684
I0528 17:10:14.001201 10644 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0528 17:10:14.001217 10644 net.cpp:100] Creating Layer scale3d_branch2c
I0528 17:10:14.001224 10644 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0528 17:10:14.001238 10644 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0528 17:10:14.001299 10644 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0528 17:10:14.001482 10644 net.cpp:150] Setting up scale3d_branch2c
I0528 17:10:14.001489 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.001492 10644 net.cpp:165] Memory required for data: 2768896084
I0528 17:10:14.001504 10644 layer_factory.hpp:77] Creating layer res3d
I0528 17:10:14.001516 10644 net.cpp:100] Creating Layer res3d
I0528 17:10:14.001523 10644 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0528 17:10:14.001534 10644 net.cpp:444] res3d <- res3d_branch2c
I0528 17:10:14.001546 10644 net.cpp:418] res3d -> res3d
I0528 17:10:14.001587 10644 net.cpp:150] Setting up res3d
I0528 17:10:14.001596 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.001600 10644 net.cpp:165] Memory required for data: 2795110484
I0528 17:10:14.001605 10644 layer_factory.hpp:77] Creating layer res3d_relu
I0528 17:10:14.001616 10644 net.cpp:100] Creating Layer res3d_relu
I0528 17:10:14.001621 10644 net.cpp:444] res3d_relu <- res3d
I0528 17:10:14.001636 10644 net.cpp:405] res3d_relu -> res3d (in-place)
I0528 17:10:14.001777 10644 net.cpp:150] Setting up res3d_relu
I0528 17:10:14.001785 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.001788 10644 net.cpp:165] Memory required for data: 2821324884
I0528 17:10:14.001792 10644 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0528 17:10:14.001804 10644 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0528 17:10:14.001811 10644 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0528 17:10:14.001826 10644 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0528 17:10:14.001842 10644 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0528 17:10:14.001899 10644 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0528 17:10:14.001906 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.001911 10644 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0528 17:10:14.001914 10644 net.cpp:165] Memory required for data: 2873753684
I0528 17:10:14.001919 10644 layer_factory.hpp:77] Creating layer res4a_branch1
I0528 17:10:14.001933 10644 net.cpp:100] Creating Layer res4a_branch1
I0528 17:10:14.001940 10644 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0528 17:10:14.001955 10644 net.cpp:418] res4a_branch1 -> res4a_branch1
I0528 17:10:14.004340 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0528 17:10:14.004361 10644 net.cpp:150] Setting up res4a_branch1
I0528 17:10:14.004374 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.004379 10644 net.cpp:165] Memory required for data: 2886860884
I0528 17:10:14.004396 10644 layer_factory.hpp:77] Creating layer bn4a_branch1
I0528 17:10:14.004422 10644 net.cpp:100] Creating Layer bn4a_branch1
I0528 17:10:14.004432 10644 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0528 17:10:14.004451 10644 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0528 17:10:14.004710 10644 net.cpp:150] Setting up bn4a_branch1
I0528 17:10:14.004717 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.004721 10644 net.cpp:165] Memory required for data: 2899968084
I0528 17:10:14.004739 10644 layer_factory.hpp:77] Creating layer scale4a_branch1
I0528 17:10:14.004755 10644 net.cpp:100] Creating Layer scale4a_branch1
I0528 17:10:14.004761 10644 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0528 17:10:14.004776 10644 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0528 17:10:14.004838 10644 layer_factory.hpp:77] Creating layer scale4a_branch1
I0528 17:10:14.005010 10644 net.cpp:150] Setting up scale4a_branch1
I0528 17:10:14.005018 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.005022 10644 net.cpp:165] Memory required for data: 2913075284
I0528 17:10:14.005033 10644 layer_factory.hpp:77] Creating layer res4a_branch2a
I0528 17:10:14.005050 10644 net.cpp:100] Creating Layer res4a_branch2a
I0528 17:10:14.005057 10644 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0528 17:10:14.005074 10644 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0528 17:10:14.006213 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0528 17:10:14.006228 10644 net.cpp:150] Setting up res4a_branch2a
I0528 17:10:14.006238 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.006242 10644 net.cpp:165] Memory required for data: 2916352084
I0528 17:10:14.006253 10644 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0528 17:10:14.006268 10644 net.cpp:100] Creating Layer bn4a_branch2a
I0528 17:10:14.006276 10644 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0528 17:10:14.006292 10644 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0528 17:10:14.006533 10644 net.cpp:150] Setting up bn4a_branch2a
I0528 17:10:14.006541 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.006543 10644 net.cpp:165] Memory required for data: 2919628884
I0528 17:10:14.006559 10644 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0528 17:10:14.006574 10644 net.cpp:100] Creating Layer scale4a_branch2a
I0528 17:10:14.006580 10644 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0528 17:10:14.006594 10644 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0528 17:10:14.006657 10644 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0528 17:10:14.006814 10644 net.cpp:150] Setting up scale4a_branch2a
I0528 17:10:14.006821 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.006824 10644 net.cpp:165] Memory required for data: 2922905684
I0528 17:10:14.006836 10644 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0528 17:10:14.006848 10644 net.cpp:100] Creating Layer res4a_branch2a_relu
I0528 17:10:14.006855 10644 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0528 17:10:14.006866 10644 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0528 17:10:14.007285 10644 net.cpp:150] Setting up res4a_branch2a_relu
I0528 17:10:14.007293 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.007297 10644 net.cpp:165] Memory required for data: 2926182484
I0528 17:10:14.007302 10644 layer_factory.hpp:77] Creating layer res4a_branch2b
I0528 17:10:14.007319 10644 net.cpp:100] Creating Layer res4a_branch2b
I0528 17:10:14.007326 10644 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0528 17:10:14.007344 10644 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0528 17:10:14.010613 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0528 17:10:14.010890 10644 net.cpp:150] Setting up res4a_branch2b
I0528 17:10:14.010906 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.010910 10644 net.cpp:165] Memory required for data: 2929459284
I0528 17:10:14.010924 10644 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0528 17:10:14.010944 10644 net.cpp:100] Creating Layer bn4a_branch2b
I0528 17:10:14.010953 10644 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0528 17:10:14.010970 10644 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0528 17:10:14.011235 10644 net.cpp:150] Setting up bn4a_branch2b
I0528 17:10:14.011243 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.011245 10644 net.cpp:165] Memory required for data: 2932736084
I0528 17:10:14.011262 10644 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0528 17:10:14.011278 10644 net.cpp:100] Creating Layer scale4a_branch2b
I0528 17:10:14.011286 10644 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0528 17:10:14.011299 10644 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0528 17:10:14.011363 10644 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0528 17:10:14.011523 10644 net.cpp:150] Setting up scale4a_branch2b
I0528 17:10:14.011529 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.011533 10644 net.cpp:165] Memory required for data: 2936012884
I0528 17:10:14.011544 10644 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0528 17:10:14.011556 10644 net.cpp:100] Creating Layer res4a_branch2b_relu
I0528 17:10:14.011564 10644 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0528 17:10:14.011575 10644 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0528 17:10:14.011721 10644 net.cpp:150] Setting up res4a_branch2b_relu
I0528 17:10:14.011729 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.011732 10644 net.cpp:165] Memory required for data: 2939289684
I0528 17:10:14.011737 10644 layer_factory.hpp:77] Creating layer res4a_branch2c
I0528 17:10:14.011754 10644 net.cpp:100] Creating Layer res4a_branch2c
I0528 17:10:14.011761 10644 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0528 17:10:14.011777 10644 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0528 17:10:14.013725 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.013743 10644 net.cpp:150] Setting up res4a_branch2c
I0528 17:10:14.013754 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.013758 10644 net.cpp:165] Memory required for data: 2952396884
I0528 17:10:14.013770 10644 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0528 17:10:14.013787 10644 net.cpp:100] Creating Layer bn4a_branch2c
I0528 17:10:14.013794 10644 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0528 17:10:14.013809 10644 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0528 17:10:14.014065 10644 net.cpp:150] Setting up bn4a_branch2c
I0528 17:10:14.014072 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.014077 10644 net.cpp:165] Memory required for data: 2965504084
I0528 17:10:14.014094 10644 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0528 17:10:14.014108 10644 net.cpp:100] Creating Layer scale4a_branch2c
I0528 17:10:14.014114 10644 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0528 17:10:14.014128 10644 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0528 17:10:14.014190 10644 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0528 17:10:14.014358 10644 net.cpp:150] Setting up scale4a_branch2c
I0528 17:10:14.014365 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.014369 10644 net.cpp:165] Memory required for data: 2978611284
I0528 17:10:14.014381 10644 layer_factory.hpp:77] Creating layer res4a
I0528 17:10:14.014406 10644 net.cpp:100] Creating Layer res4a
I0528 17:10:14.014413 10644 net.cpp:444] res4a <- res4a_branch1
I0528 17:10:14.014425 10644 net.cpp:444] res4a <- res4a_branch2c
I0528 17:10:14.014436 10644 net.cpp:418] res4a -> res4a
I0528 17:10:14.014477 10644 net.cpp:150] Setting up res4a
I0528 17:10:14.014487 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.014490 10644 net.cpp:165] Memory required for data: 2991718484
I0528 17:10:14.014498 10644 layer_factory.hpp:77] Creating layer res4a_relu
I0528 17:10:14.014508 10644 net.cpp:100] Creating Layer res4a_relu
I0528 17:10:14.014514 10644 net.cpp:444] res4a_relu <- res4a
I0528 17:10:14.014526 10644 net.cpp:405] res4a_relu -> res4a (in-place)
I0528 17:10:14.014670 10644 net.cpp:150] Setting up res4a_relu
I0528 17:10:14.014678 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.014680 10644 net.cpp:165] Memory required for data: 3004825684
I0528 17:10:14.014685 10644 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0528 17:10:14.014698 10644 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0528 17:10:14.014703 10644 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0528 17:10:14.014719 10644 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0528 17:10:14.014734 10644 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0528 17:10:14.014791 10644 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0528 17:10:14.014799 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.014806 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.014808 10644 net.cpp:165] Memory required for data: 3031040084
I0528 17:10:14.014814 10644 layer_factory.hpp:77] Creating layer res4b_branch2a
I0528 17:10:14.014829 10644 net.cpp:100] Creating Layer res4b_branch2a
I0528 17:10:14.014837 10644 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0528 17:10:14.014852 10644 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0528 17:10:14.016088 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.016103 10644 net.cpp:150] Setting up res4b_branch2a
I0528 17:10:14.016114 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.016119 10644 net.cpp:165] Memory required for data: 3034316884
I0528 17:10:14.016130 10644 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0528 17:10:14.016144 10644 net.cpp:100] Creating Layer bn4b_branch2a
I0528 17:10:14.016150 10644 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0528 17:10:14.016166 10644 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0528 17:10:14.016412 10644 net.cpp:150] Setting up bn4b_branch2a
I0528 17:10:14.016419 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.016422 10644 net.cpp:165] Memory required for data: 3037593684
I0528 17:10:14.016438 10644 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0528 17:10:14.016453 10644 net.cpp:100] Creating Layer scale4b_branch2a
I0528 17:10:14.016459 10644 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0528 17:10:14.016475 10644 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0528 17:10:14.016537 10644 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0528 17:10:14.016698 10644 net.cpp:150] Setting up scale4b_branch2a
I0528 17:10:14.016705 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.016708 10644 net.cpp:165] Memory required for data: 3040870484
I0528 17:10:14.016721 10644 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0528 17:10:14.016732 10644 net.cpp:100] Creating Layer res4b_branch2a_relu
I0528 17:10:14.016738 10644 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0528 17:10:14.016752 10644 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0528 17:10:14.017148 10644 net.cpp:150] Setting up res4b_branch2a_relu
I0528 17:10:14.017158 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.017160 10644 net.cpp:165] Memory required for data: 3044147284
I0528 17:10:14.017166 10644 layer_factory.hpp:77] Creating layer res4b_branch2b
I0528 17:10:14.017184 10644 net.cpp:100] Creating Layer res4b_branch2b
I0528 17:10:14.017190 10644 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0528 17:10:14.017206 10644 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0528 17:10:14.019634 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0528 17:10:14.019894 10644 net.cpp:150] Setting up res4b_branch2b
I0528 17:10:14.019907 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.019912 10644 net.cpp:165] Memory required for data: 3047424084
I0528 17:10:14.019927 10644 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0528 17:10:14.019945 10644 net.cpp:100] Creating Layer bn4b_branch2b
I0528 17:10:14.019953 10644 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0528 17:10:14.019970 10644 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0528 17:10:14.020228 10644 net.cpp:150] Setting up bn4b_branch2b
I0528 17:10:14.020236 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.020238 10644 net.cpp:165] Memory required for data: 3050700884
I0528 17:10:14.020256 10644 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0528 17:10:14.020272 10644 net.cpp:100] Creating Layer scale4b_branch2b
I0528 17:10:14.020278 10644 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0528 17:10:14.020293 10644 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0528 17:10:14.020359 10644 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0528 17:10:14.020519 10644 net.cpp:150] Setting up scale4b_branch2b
I0528 17:10:14.020527 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.020530 10644 net.cpp:165] Memory required for data: 3053977684
I0528 17:10:14.020543 10644 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0528 17:10:14.020560 10644 net.cpp:100] Creating Layer res4b_branch2b_relu
I0528 17:10:14.020566 10644 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0528 17:10:14.020581 10644 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0528 17:10:14.020728 10644 net.cpp:150] Setting up res4b_branch2b_relu
I0528 17:10:14.020735 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.020738 10644 net.cpp:165] Memory required for data: 3057254484
I0528 17:10:14.020743 10644 layer_factory.hpp:77] Creating layer res4b_branch2c
I0528 17:10:14.020761 10644 net.cpp:100] Creating Layer res4b_branch2c
I0528 17:10:14.020768 10644 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0528 17:10:14.020784 10644 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0528 17:10:14.022970 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.022987 10644 net.cpp:150] Setting up res4b_branch2c
I0528 17:10:14.022997 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.023001 10644 net.cpp:165] Memory required for data: 3070361684
I0528 17:10:14.023015 10644 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0528 17:10:14.023036 10644 net.cpp:100] Creating Layer bn4b_branch2c
I0528 17:10:14.023043 10644 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0528 17:10:14.023061 10644 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0528 17:10:14.023324 10644 net.cpp:150] Setting up bn4b_branch2c
I0528 17:10:14.023331 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.023334 10644 net.cpp:165] Memory required for data: 3083468884
I0528 17:10:14.023350 10644 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0528 17:10:14.023366 10644 net.cpp:100] Creating Layer scale4b_branch2c
I0528 17:10:14.023373 10644 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0528 17:10:14.023386 10644 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0528 17:10:14.023448 10644 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0528 17:10:14.023623 10644 net.cpp:150] Setting up scale4b_branch2c
I0528 17:10:14.023632 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.023634 10644 net.cpp:165] Memory required for data: 3096576084
I0528 17:10:14.023646 10644 layer_factory.hpp:77] Creating layer res4b
I0528 17:10:14.023660 10644 net.cpp:100] Creating Layer res4b
I0528 17:10:14.023667 10644 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0528 17:10:14.023679 10644 net.cpp:444] res4b <- res4b_branch2c
I0528 17:10:14.023690 10644 net.cpp:418] res4b -> res4b
I0528 17:10:14.023731 10644 net.cpp:150] Setting up res4b
I0528 17:10:14.023741 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.023744 10644 net.cpp:165] Memory required for data: 3109683284
I0528 17:10:14.023748 10644 layer_factory.hpp:77] Creating layer res4b_relu
I0528 17:10:14.023761 10644 net.cpp:100] Creating Layer res4b_relu
I0528 17:10:14.023767 10644 net.cpp:444] res4b_relu <- res4b
I0528 17:10:14.023779 10644 net.cpp:405] res4b_relu -> res4b (in-place)
I0528 17:10:14.023926 10644 net.cpp:150] Setting up res4b_relu
I0528 17:10:14.023933 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.023936 10644 net.cpp:165] Memory required for data: 3122790484
I0528 17:10:14.023941 10644 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0528 17:10:14.023952 10644 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0528 17:10:14.023958 10644 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0528 17:10:14.023972 10644 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0528 17:10:14.023988 10644 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0528 17:10:14.024045 10644 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0528 17:10:14.024055 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.024060 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.024065 10644 net.cpp:165] Memory required for data: 3149004884
I0528 17:10:14.024068 10644 layer_factory.hpp:77] Creating layer res4c_branch2a
I0528 17:10:14.024085 10644 net.cpp:100] Creating Layer res4c_branch2a
I0528 17:10:14.024091 10644 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0528 17:10:14.024106 10644 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0528 17:10:14.025375 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.025391 10644 net.cpp:150] Setting up res4c_branch2a
I0528 17:10:14.025400 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.025404 10644 net.cpp:165] Memory required for data: 3152281684
I0528 17:10:14.025415 10644 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0528 17:10:14.025431 10644 net.cpp:100] Creating Layer bn4c_branch2a
I0528 17:10:14.025439 10644 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0528 17:10:14.025454 10644 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0528 17:10:14.025703 10644 net.cpp:150] Setting up bn4c_branch2a
I0528 17:10:14.025710 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.025713 10644 net.cpp:165] Memory required for data: 3155558484
I0528 17:10:14.025730 10644 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0528 17:10:14.025745 10644 net.cpp:100] Creating Layer scale4c_branch2a
I0528 17:10:14.025751 10644 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0528 17:10:14.025764 10644 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0528 17:10:14.025828 10644 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0528 17:10:14.025991 10644 net.cpp:150] Setting up scale4c_branch2a
I0528 17:10:14.025998 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.026001 10644 net.cpp:165] Memory required for data: 3158835284
I0528 17:10:14.026015 10644 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0528 17:10:14.026026 10644 net.cpp:100] Creating Layer res4c_branch2a_relu
I0528 17:10:14.026032 10644 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0528 17:10:14.026046 10644 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0528 17:10:14.026186 10644 net.cpp:150] Setting up res4c_branch2a_relu
I0528 17:10:14.026195 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.026197 10644 net.cpp:165] Memory required for data: 3162112084
I0528 17:10:14.026202 10644 layer_factory.hpp:77] Creating layer res4c_branch2b
I0528 17:10:14.026218 10644 net.cpp:100] Creating Layer res4c_branch2b
I0528 17:10:14.026224 10644 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0528 17:10:14.026240 10644 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0528 17:10:14.028998 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0528 17:10:14.029407 10644 net.cpp:150] Setting up res4c_branch2b
I0528 17:10:14.029428 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.029433 10644 net.cpp:165] Memory required for data: 3165388884
I0528 17:10:14.029458 10644 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0528 17:10:14.029485 10644 net.cpp:100] Creating Layer bn4c_branch2b
I0528 17:10:14.029494 10644 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0528 17:10:14.029512 10644 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0528 17:10:14.029842 10644 net.cpp:150] Setting up bn4c_branch2b
I0528 17:10:14.029861 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.029870 10644 net.cpp:165] Memory required for data: 3168665684
I0528 17:10:14.029897 10644 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0528 17:10:14.029928 10644 net.cpp:100] Creating Layer scale4c_branch2b
I0528 17:10:14.029943 10644 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0528 17:10:14.029964 10644 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0528 17:10:14.030038 10644 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0528 17:10:14.030244 10644 net.cpp:150] Setting up scale4c_branch2b
I0528 17:10:14.030252 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.030256 10644 net.cpp:165] Memory required for data: 3171942484
I0528 17:10:14.030269 10644 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0528 17:10:14.030282 10644 net.cpp:100] Creating Layer res4c_branch2b_relu
I0528 17:10:14.030288 10644 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0528 17:10:14.030302 10644 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0528 17:10:14.030841 10644 net.cpp:150] Setting up res4c_branch2b_relu
I0528 17:10:14.030850 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.030853 10644 net.cpp:165] Memory required for data: 3175219284
I0528 17:10:14.030859 10644 layer_factory.hpp:77] Creating layer res4c_branch2c
I0528 17:10:14.030879 10644 net.cpp:100] Creating Layer res4c_branch2c
I0528 17:10:14.030885 10644 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0528 17:10:14.030902 10644 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0528 17:10:14.033042 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.033061 10644 net.cpp:150] Setting up res4c_branch2c
I0528 17:10:14.033071 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.033076 10644 net.cpp:165] Memory required for data: 3188326484
I0528 17:10:14.033092 10644 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0528 17:10:14.033113 10644 net.cpp:100] Creating Layer bn4c_branch2c
I0528 17:10:14.033121 10644 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0528 17:10:14.033139 10644 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0528 17:10:14.033416 10644 net.cpp:150] Setting up bn4c_branch2c
I0528 17:10:14.033422 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.033426 10644 net.cpp:165] Memory required for data: 3201433684
I0528 17:10:14.033443 10644 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0528 17:10:14.033459 10644 net.cpp:100] Creating Layer scale4c_branch2c
I0528 17:10:14.033466 10644 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0528 17:10:14.033490 10644 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0528 17:10:14.033560 10644 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0528 17:10:14.033736 10644 net.cpp:150] Setting up scale4c_branch2c
I0528 17:10:14.033744 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.033747 10644 net.cpp:165] Memory required for data: 3214540884
I0528 17:10:14.033761 10644 layer_factory.hpp:77] Creating layer res4c
I0528 17:10:14.033773 10644 net.cpp:100] Creating Layer res4c
I0528 17:10:14.033780 10644 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0528 17:10:14.033792 10644 net.cpp:444] res4c <- res4c_branch2c
I0528 17:10:14.033804 10644 net.cpp:418] res4c -> res4c
I0528 17:10:14.033849 10644 net.cpp:150] Setting up res4c
I0528 17:10:14.033859 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.033862 10644 net.cpp:165] Memory required for data: 3227648084
I0528 17:10:14.033867 10644 layer_factory.hpp:77] Creating layer res4c_relu
I0528 17:10:14.033880 10644 net.cpp:100] Creating Layer res4c_relu
I0528 17:10:14.033886 10644 net.cpp:444] res4c_relu <- res4c
I0528 17:10:14.033900 10644 net.cpp:405] res4c_relu -> res4c (in-place)
I0528 17:10:14.034054 10644 net.cpp:150] Setting up res4c_relu
I0528 17:10:14.034061 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.034065 10644 net.cpp:165] Memory required for data: 3240755284
I0528 17:10:14.034070 10644 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0528 17:10:14.034082 10644 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0528 17:10:14.034088 10644 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0528 17:10:14.034103 10644 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0528 17:10:14.034121 10644 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0528 17:10:14.034180 10644 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0528 17:10:14.034188 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.034195 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.034198 10644 net.cpp:165] Memory required for data: 3266969684
I0528 17:10:14.034204 10644 layer_factory.hpp:77] Creating layer res4d_branch2a
I0528 17:10:14.034220 10644 net.cpp:100] Creating Layer res4d_branch2a
I0528 17:10:14.034227 10644 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0528 17:10:14.034243 10644 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0528 17:10:14.035725 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.035743 10644 net.cpp:150] Setting up res4d_branch2a
I0528 17:10:14.035753 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.035756 10644 net.cpp:165] Memory required for data: 3270246484
I0528 17:10:14.035770 10644 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0528 17:10:14.035789 10644 net.cpp:100] Creating Layer bn4d_branch2a
I0528 17:10:14.035799 10644 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0528 17:10:14.035815 10644 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0528 17:10:14.036090 10644 net.cpp:150] Setting up bn4d_branch2a
I0528 17:10:14.036098 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.036101 10644 net.cpp:165] Memory required for data: 3273523284
I0528 17:10:14.036118 10644 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0528 17:10:14.036136 10644 net.cpp:100] Creating Layer scale4d_branch2a
I0528 17:10:14.036142 10644 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0528 17:10:14.036156 10644 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0528 17:10:14.036222 10644 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0528 17:10:14.036396 10644 net.cpp:150] Setting up scale4d_branch2a
I0528 17:10:14.036402 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.036406 10644 net.cpp:165] Memory required for data: 3276800084
I0528 17:10:14.036418 10644 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0528 17:10:14.036429 10644 net.cpp:100] Creating Layer res4d_branch2a_relu
I0528 17:10:14.036435 10644 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0528 17:10:14.036449 10644 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0528 17:10:14.036599 10644 net.cpp:150] Setting up res4d_branch2a_relu
I0528 17:10:14.036607 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.036609 10644 net.cpp:165] Memory required for data: 3280076884
I0528 17:10:14.036614 10644 layer_factory.hpp:77] Creating layer res4d_branch2b
I0528 17:10:14.036631 10644 net.cpp:100] Creating Layer res4d_branch2b
I0528 17:10:14.036638 10644 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0528 17:10:14.036654 10644 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0528 17:10:14.039283 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0528 17:10:14.039584 10644 net.cpp:150] Setting up res4d_branch2b
I0528 17:10:14.039602 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.039605 10644 net.cpp:165] Memory required for data: 3283353684
I0528 17:10:14.039626 10644 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0528 17:10:14.039654 10644 net.cpp:100] Creating Layer bn4d_branch2b
I0528 17:10:14.039664 10644 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0528 17:10:14.039685 10644 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0528 17:10:14.039968 10644 net.cpp:150] Setting up bn4d_branch2b
I0528 17:10:14.039975 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.039978 10644 net.cpp:165] Memory required for data: 3286630484
I0528 17:10:14.039995 10644 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0528 17:10:14.040011 10644 net.cpp:100] Creating Layer scale4d_branch2b
I0528 17:10:14.040017 10644 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0528 17:10:14.040032 10644 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0528 17:10:14.040099 10644 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0528 17:10:14.040267 10644 net.cpp:150] Setting up scale4d_branch2b
I0528 17:10:14.040275 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.040277 10644 net.cpp:165] Memory required for data: 3289907284
I0528 17:10:14.040290 10644 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0528 17:10:14.040302 10644 net.cpp:100] Creating Layer res4d_branch2b_relu
I0528 17:10:14.040308 10644 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0528 17:10:14.040321 10644 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0528 17:10:14.040717 10644 net.cpp:150] Setting up res4d_branch2b_relu
I0528 17:10:14.040726 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.040729 10644 net.cpp:165] Memory required for data: 3293184084
I0528 17:10:14.040735 10644 layer_factory.hpp:77] Creating layer res4d_branch2c
I0528 17:10:14.040753 10644 net.cpp:100] Creating Layer res4d_branch2c
I0528 17:10:14.040760 10644 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0528 17:10:14.040777 10644 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0528 17:10:14.042778 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.042796 10644 net.cpp:150] Setting up res4d_branch2c
I0528 17:10:14.042807 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.042811 10644 net.cpp:165] Memory required for data: 3306291284
I0528 17:10:14.042824 10644 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0528 17:10:14.042842 10644 net.cpp:100] Creating Layer bn4d_branch2c
I0528 17:10:14.042850 10644 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0528 17:10:14.042866 10644 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0528 17:10:14.043141 10644 net.cpp:150] Setting up bn4d_branch2c
I0528 17:10:14.043148 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.043153 10644 net.cpp:165] Memory required for data: 3319398484
I0528 17:10:14.043169 10644 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0528 17:10:14.043184 10644 net.cpp:100] Creating Layer scale4d_branch2c
I0528 17:10:14.043190 10644 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0528 17:10:14.043205 10644 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0528 17:10:14.043268 10644 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0528 17:10:14.043442 10644 net.cpp:150] Setting up scale4d_branch2c
I0528 17:10:14.043448 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.043452 10644 net.cpp:165] Memory required for data: 3332505684
I0528 17:10:14.043464 10644 layer_factory.hpp:77] Creating layer res4d
I0528 17:10:14.043478 10644 net.cpp:100] Creating Layer res4d
I0528 17:10:14.043483 10644 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0528 17:10:14.043495 10644 net.cpp:444] res4d <- res4d_branch2c
I0528 17:10:14.043506 10644 net.cpp:418] res4d -> res4d
I0528 17:10:14.043550 10644 net.cpp:150] Setting up res4d
I0528 17:10:14.043558 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.043562 10644 net.cpp:165] Memory required for data: 3345612884
I0528 17:10:14.043567 10644 layer_factory.hpp:77] Creating layer res4d_relu
I0528 17:10:14.043578 10644 net.cpp:100] Creating Layer res4d_relu
I0528 17:10:14.043584 10644 net.cpp:444] res4d_relu <- res4d
I0528 17:10:14.043597 10644 net.cpp:405] res4d_relu -> res4d (in-place)
I0528 17:10:14.043741 10644 net.cpp:150] Setting up res4d_relu
I0528 17:10:14.043748 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.043751 10644 net.cpp:165] Memory required for data: 3358720084
I0528 17:10:14.043756 10644 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0528 17:10:14.043768 10644 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0528 17:10:14.043774 10644 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0528 17:10:14.043788 10644 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0528 17:10:14.043805 10644 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0528 17:10:14.043864 10644 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0528 17:10:14.043874 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.043879 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.043884 10644 net.cpp:165] Memory required for data: 3384934484
I0528 17:10:14.043887 10644 layer_factory.hpp:77] Creating layer res4e_branch2a
I0528 17:10:14.043905 10644 net.cpp:100] Creating Layer res4e_branch2a
I0528 17:10:14.043910 10644 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0528 17:10:14.043926 10644 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0528 17:10:14.045202 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.045217 10644 net.cpp:150] Setting up res4e_branch2a
I0528 17:10:14.045226 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.045230 10644 net.cpp:165] Memory required for data: 3388211284
I0528 17:10:14.045241 10644 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0528 17:10:14.045256 10644 net.cpp:100] Creating Layer bn4e_branch2a
I0528 17:10:14.045264 10644 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0528 17:10:14.045279 10644 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0528 17:10:14.045538 10644 net.cpp:150] Setting up bn4e_branch2a
I0528 17:10:14.045545 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.045548 10644 net.cpp:165] Memory required for data: 3391488084
I0528 17:10:14.045565 10644 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0528 17:10:14.045580 10644 net.cpp:100] Creating Layer scale4e_branch2a
I0528 17:10:14.045586 10644 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0528 17:10:14.045601 10644 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0528 17:10:14.045665 10644 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0528 17:10:14.045831 10644 net.cpp:150] Setting up scale4e_branch2a
I0528 17:10:14.045838 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.045841 10644 net.cpp:165] Memory required for data: 3394764884
I0528 17:10:14.045855 10644 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0528 17:10:14.045866 10644 net.cpp:100] Creating Layer res4e_branch2a_relu
I0528 17:10:14.045871 10644 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0528 17:10:14.045884 10644 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0528 17:10:14.046030 10644 net.cpp:150] Setting up res4e_branch2a_relu
I0528 17:10:14.046036 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.046039 10644 net.cpp:165] Memory required for data: 3398041684
I0528 17:10:14.046044 10644 layer_factory.hpp:77] Creating layer res4e_branch2b
I0528 17:10:14.046061 10644 net.cpp:100] Creating Layer res4e_branch2b
I0528 17:10:14.046067 10644 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0528 17:10:14.046084 10644 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0528 17:10:14.049747 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0528 17:10:14.050037 10644 net.cpp:150] Setting up res4e_branch2b
I0528 17:10:14.050052 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.050056 10644 net.cpp:165] Memory required for data: 3401318484
I0528 17:10:14.050073 10644 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0528 17:10:14.050098 10644 net.cpp:100] Creating Layer bn4e_branch2b
I0528 17:10:14.050108 10644 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0528 17:10:14.050127 10644 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0528 17:10:14.050405 10644 net.cpp:150] Setting up bn4e_branch2b
I0528 17:10:14.050415 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.050417 10644 net.cpp:165] Memory required for data: 3404595284
I0528 17:10:14.050434 10644 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0528 17:10:14.050449 10644 net.cpp:100] Creating Layer scale4e_branch2b
I0528 17:10:14.050456 10644 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0528 17:10:14.050470 10644 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0528 17:10:14.050537 10644 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0528 17:10:14.050707 10644 net.cpp:150] Setting up scale4e_branch2b
I0528 17:10:14.050715 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.050719 10644 net.cpp:165] Memory required for data: 3407872084
I0528 17:10:14.050730 10644 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0528 17:10:14.050742 10644 net.cpp:100] Creating Layer res4e_branch2b_relu
I0528 17:10:14.050748 10644 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0528 17:10:14.050761 10644 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0528 17:10:14.051159 10644 net.cpp:150] Setting up res4e_branch2b_relu
I0528 17:10:14.051169 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.051173 10644 net.cpp:165] Memory required for data: 3411148884
I0528 17:10:14.051178 10644 layer_factory.hpp:77] Creating layer res4e_branch2c
I0528 17:10:14.051198 10644 net.cpp:100] Creating Layer res4e_branch2c
I0528 17:10:14.051204 10644 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0528 17:10:14.051221 10644 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0528 17:10:14.053200 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.053218 10644 net.cpp:150] Setting up res4e_branch2c
I0528 17:10:14.053230 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.053233 10644 net.cpp:165] Memory required for data: 3424256084
I0528 17:10:14.053247 10644 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0528 17:10:14.053263 10644 net.cpp:100] Creating Layer bn4e_branch2c
I0528 17:10:14.053270 10644 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0528 17:10:14.053292 10644 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0528 17:10:14.053568 10644 net.cpp:150] Setting up bn4e_branch2c
I0528 17:10:14.053575 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.053580 10644 net.cpp:165] Memory required for data: 3437363284
I0528 17:10:14.053596 10644 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0528 17:10:14.053611 10644 net.cpp:100] Creating Layer scale4e_branch2c
I0528 17:10:14.053618 10644 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0528 17:10:14.053633 10644 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0528 17:10:14.053695 10644 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0528 17:10:14.053867 10644 net.cpp:150] Setting up scale4e_branch2c
I0528 17:10:14.053875 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.053879 10644 net.cpp:165] Memory required for data: 3450470484
I0528 17:10:14.053891 10644 layer_factory.hpp:77] Creating layer res4e
I0528 17:10:14.053903 10644 net.cpp:100] Creating Layer res4e
I0528 17:10:14.053910 10644 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0528 17:10:14.053921 10644 net.cpp:444] res4e <- res4e_branch2c
I0528 17:10:14.053933 10644 net.cpp:418] res4e -> res4e
I0528 17:10:14.053977 10644 net.cpp:150] Setting up res4e
I0528 17:10:14.053985 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.053989 10644 net.cpp:165] Memory required for data: 3463577684
I0528 17:10:14.053994 10644 layer_factory.hpp:77] Creating layer res4e_relu
I0528 17:10:14.054005 10644 net.cpp:100] Creating Layer res4e_relu
I0528 17:10:14.054011 10644 net.cpp:444] res4e_relu <- res4e
I0528 17:10:14.054023 10644 net.cpp:405] res4e_relu -> res4e (in-place)
I0528 17:10:14.054170 10644 net.cpp:150] Setting up res4e_relu
I0528 17:10:14.054177 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.054180 10644 net.cpp:165] Memory required for data: 3476684884
I0528 17:10:14.054185 10644 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0528 17:10:14.054198 10644 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0528 17:10:14.054203 10644 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0528 17:10:14.054217 10644 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0528 17:10:14.054234 10644 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0528 17:10:14.054293 10644 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0528 17:10:14.054302 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.054308 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.054312 10644 net.cpp:165] Memory required for data: 3502899284
I0528 17:10:14.054317 10644 layer_factory.hpp:77] Creating layer res4f_branch2a
I0528 17:10:14.054333 10644 net.cpp:100] Creating Layer res4f_branch2a
I0528 17:10:14.054339 10644 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0528 17:10:14.054355 10644 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0528 17:10:14.055649 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.055665 10644 net.cpp:150] Setting up res4f_branch2a
I0528 17:10:14.055675 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.055678 10644 net.cpp:165] Memory required for data: 3506176084
I0528 17:10:14.055689 10644 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0528 17:10:14.055703 10644 net.cpp:100] Creating Layer bn4f_branch2a
I0528 17:10:14.055711 10644 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0528 17:10:14.055725 10644 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0528 17:10:14.055994 10644 net.cpp:150] Setting up bn4f_branch2a
I0528 17:10:14.056000 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.056004 10644 net.cpp:165] Memory required for data: 3509452884
I0528 17:10:14.056020 10644 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0528 17:10:14.056035 10644 net.cpp:100] Creating Layer scale4f_branch2a
I0528 17:10:14.056041 10644 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0528 17:10:14.056057 10644 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0528 17:10:14.056123 10644 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0528 17:10:14.056293 10644 net.cpp:150] Setting up scale4f_branch2a
I0528 17:10:14.056300 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.056303 10644 net.cpp:165] Memory required for data: 3512729684
I0528 17:10:14.056315 10644 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0528 17:10:14.056326 10644 net.cpp:100] Creating Layer res4f_branch2a_relu
I0528 17:10:14.056334 10644 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0528 17:10:14.056346 10644 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0528 17:10:14.056491 10644 net.cpp:150] Setting up res4f_branch2a_relu
I0528 17:10:14.056499 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.056502 10644 net.cpp:165] Memory required for data: 3516006484
I0528 17:10:14.056507 10644 layer_factory.hpp:77] Creating layer res4f_branch2b
I0528 17:10:14.056524 10644 net.cpp:100] Creating Layer res4f_branch2b
I0528 17:10:14.056530 10644 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0528 17:10:14.056546 10644 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0528 17:10:14.059028 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0528 17:10:14.059303 10644 net.cpp:150] Setting up res4f_branch2b
I0528 17:10:14.059319 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.059322 10644 net.cpp:165] Memory required for data: 3519283284
I0528 17:10:14.059339 10644 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0528 17:10:14.059356 10644 net.cpp:100] Creating Layer bn4f_branch2b
I0528 17:10:14.059365 10644 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0528 17:10:14.059383 10644 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0528 17:10:14.059662 10644 net.cpp:150] Setting up bn4f_branch2b
I0528 17:10:14.059669 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.059672 10644 net.cpp:165] Memory required for data: 3522560084
I0528 17:10:14.059689 10644 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0528 17:10:14.059705 10644 net.cpp:100] Creating Layer scale4f_branch2b
I0528 17:10:14.059710 10644 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0528 17:10:14.059725 10644 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0528 17:10:14.059792 10644 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0528 17:10:14.059964 10644 net.cpp:150] Setting up scale4f_branch2b
I0528 17:10:14.059972 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.059974 10644 net.cpp:165] Memory required for data: 3525836884
I0528 17:10:14.059986 10644 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0528 17:10:14.059999 10644 net.cpp:100] Creating Layer res4f_branch2b_relu
I0528 17:10:14.060006 10644 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0528 17:10:14.060019 10644 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0528 17:10:14.060168 10644 net.cpp:150] Setting up res4f_branch2b_relu
I0528 17:10:14.060176 10644 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0528 17:10:14.060179 10644 net.cpp:165] Memory required for data: 3529113684
I0528 17:10:14.060184 10644 layer_factory.hpp:77] Creating layer res4f_branch2c
I0528 17:10:14.060202 10644 net.cpp:100] Creating Layer res4f_branch2c
I0528 17:10:14.060209 10644 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0528 17:10:14.060225 10644 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0528 17:10:14.062506 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.062525 10644 net.cpp:150] Setting up res4f_branch2c
I0528 17:10:14.062536 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.062541 10644 net.cpp:165] Memory required for data: 3542220884
I0528 17:10:14.062556 10644 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0528 17:10:14.062573 10644 net.cpp:100] Creating Layer bn4f_branch2c
I0528 17:10:14.062582 10644 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0528 17:10:14.062599 10644 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0528 17:10:14.062881 10644 net.cpp:150] Setting up bn4f_branch2c
I0528 17:10:14.062889 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.062892 10644 net.cpp:165] Memory required for data: 3555328084
I0528 17:10:14.062942 10644 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0528 17:10:14.062959 10644 net.cpp:100] Creating Layer scale4f_branch2c
I0528 17:10:14.062966 10644 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0528 17:10:14.062979 10644 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0528 17:10:14.063043 10644 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0528 17:10:14.063223 10644 net.cpp:150] Setting up scale4f_branch2c
I0528 17:10:14.063230 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.063233 10644 net.cpp:165] Memory required for data: 3568435284
I0528 17:10:14.063246 10644 layer_factory.hpp:77] Creating layer res4f
I0528 17:10:14.063258 10644 net.cpp:100] Creating Layer res4f
I0528 17:10:14.063266 10644 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0528 17:10:14.063277 10644 net.cpp:444] res4f <- res4f_branch2c
I0528 17:10:14.063288 10644 net.cpp:418] res4f -> res4f
I0528 17:10:14.063331 10644 net.cpp:150] Setting up res4f
I0528 17:10:14.063341 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.063344 10644 net.cpp:165] Memory required for data: 3581542484
I0528 17:10:14.063349 10644 layer_factory.hpp:77] Creating layer res4f_relu
I0528 17:10:14.063360 10644 net.cpp:100] Creating Layer res4f_relu
I0528 17:10:14.063366 10644 net.cpp:444] res4f_relu <- res4f
I0528 17:10:14.063379 10644 net.cpp:405] res4f_relu -> res4f (in-place)
I0528 17:10:14.063799 10644 net.cpp:150] Setting up res4f_relu
I0528 17:10:14.063808 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.063812 10644 net.cpp:165] Memory required for data: 3594649684
I0528 17:10:14.063817 10644 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0528 17:10:14.063830 10644 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0528 17:10:14.063836 10644 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0528 17:10:14.063853 10644 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0528 17:10:14.063870 10644 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0528 17:10:14.063884 10644 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0528 17:10:14.063962 10644 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0528 17:10:14.063972 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.063978 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.063983 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.063987 10644 net.cpp:165] Memory required for data: 3633971284
I0528 17:10:14.063992 10644 layer_factory.hpp:77] Creating layer res5a_branch1
I0528 17:10:14.064007 10644 net.cpp:100] Creating Layer res5a_branch1
I0528 17:10:14.064014 10644 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0528 17:10:14.064030 10644 net.cpp:418] res5a_branch1 -> res5a_branch1
I0528 17:10:14.069736 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0528 17:10:14.069761 10644 net.cpp:150] Setting up res5a_branch1
I0528 17:10:14.069777 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.069780 10644 net.cpp:165] Memory required for data: 3660185684
I0528 17:10:14.069803 10644 layer_factory.hpp:77] Creating layer bn5a_branch1
I0528 17:10:14.069835 10644 net.cpp:100] Creating Layer bn5a_branch1
I0528 17:10:14.069847 10644 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0528 17:10:14.069867 10644 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0528 17:10:14.070175 10644 net.cpp:150] Setting up bn5a_branch1
I0528 17:10:14.070183 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.070185 10644 net.cpp:165] Memory required for data: 3686400084
I0528 17:10:14.070204 10644 layer_factory.hpp:77] Creating layer scale5a_branch1
I0528 17:10:14.070222 10644 net.cpp:100] Creating Layer scale5a_branch1
I0528 17:10:14.070230 10644 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0528 17:10:14.070243 10644 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0528 17:10:14.070317 10644 layer_factory.hpp:77] Creating layer scale5a_branch1
I0528 17:10:14.070508 10644 net.cpp:150] Setting up scale5a_branch1
I0528 17:10:14.070515 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.070518 10644 net.cpp:165] Memory required for data: 3712614484
I0528 17:10:14.070530 10644 layer_factory.hpp:77] Creating layer res5a_branch2a
I0528 17:10:14.070551 10644 net.cpp:100] Creating Layer res5a_branch2a
I0528 17:10:14.070559 10644 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0528 17:10:14.070574 10644 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0528 17:10:14.073349 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.073372 10644 net.cpp:150] Setting up res5a_branch2a
I0528 17:10:14.073387 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.073390 10644 net.cpp:165] Memory required for data: 3719168084
I0528 17:10:14.073411 10644 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0528 17:10:14.073441 10644 net.cpp:100] Creating Layer bn5a_branch2a
I0528 17:10:14.073451 10644 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0528 17:10:14.073473 10644 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0528 17:10:14.073778 10644 net.cpp:150] Setting up bn5a_branch2a
I0528 17:10:14.073786 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.073789 10644 net.cpp:165] Memory required for data: 3725721684
I0528 17:10:14.073807 10644 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0528 17:10:14.073824 10644 net.cpp:100] Creating Layer scale5a_branch2a
I0528 17:10:14.073832 10644 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0528 17:10:14.073845 10644 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0528 17:10:14.073913 10644 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0528 17:10:14.074096 10644 net.cpp:150] Setting up scale5a_branch2a
I0528 17:10:14.074105 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.074106 10644 net.cpp:165] Memory required for data: 3732275284
I0528 17:10:14.074120 10644 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0528 17:10:14.074131 10644 net.cpp:100] Creating Layer res5a_branch2a_relu
I0528 17:10:14.074137 10644 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0528 17:10:14.074151 10644 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0528 17:10:14.074302 10644 net.cpp:150] Setting up res5a_branch2a_relu
I0528 17:10:14.074311 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.074313 10644 net.cpp:165] Memory required for data: 3738828884
I0528 17:10:14.074318 10644 layer_factory.hpp:77] Creating layer res5a_branch2b
I0528 17:10:14.074335 10644 net.cpp:100] Creating Layer res5a_branch2b
I0528 17:10:14.074342 10644 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0528 17:10:14.074358 10644 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0528 17:10:14.079818 10644 net.cpp:150] Setting up res5a_branch2b
I0528 17:10:14.079849 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.079852 10644 net.cpp:165] Memory required for data: 3745382484
I0528 17:10:14.079877 10644 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0528 17:10:14.079911 10644 net.cpp:100] Creating Layer bn5a_branch2b
I0528 17:10:14.079924 10644 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0528 17:10:14.079946 10644 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0528 17:10:14.080256 10644 net.cpp:150] Setting up bn5a_branch2b
I0528 17:10:14.080263 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.080266 10644 net.cpp:165] Memory required for data: 3751936084
I0528 17:10:14.080284 10644 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0528 17:10:14.080301 10644 net.cpp:100] Creating Layer scale5a_branch2b
I0528 17:10:14.080307 10644 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0528 17:10:14.080320 10644 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0528 17:10:14.080389 10644 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0528 17:10:14.080574 10644 net.cpp:150] Setting up scale5a_branch2b
I0528 17:10:14.080582 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.080585 10644 net.cpp:165] Memory required for data: 3758489684
I0528 17:10:14.080597 10644 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0528 17:10:14.080610 10644 net.cpp:100] Creating Layer res5a_branch2b_relu
I0528 17:10:14.080616 10644 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0528 17:10:14.080631 10644 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0528 17:10:14.080826 10644 net.cpp:150] Setting up res5a_branch2b_relu
I0528 17:10:14.080834 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.080837 10644 net.cpp:165] Memory required for data: 3765043284
I0528 17:10:14.080842 10644 layer_factory.hpp:77] Creating layer res5a_branch2c
I0528 17:10:14.080862 10644 net.cpp:100] Creating Layer res5a_branch2c
I0528 17:10:14.080868 10644 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0528 17:10:14.080884 10644 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0528 17:10:14.084568 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0528 17:10:14.084595 10644 net.cpp:150] Setting up res5a_branch2c
I0528 17:10:14.084614 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.084620 10644 net.cpp:165] Memory required for data: 3791257684
I0528 17:10:14.084645 10644 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0528 17:10:14.084676 10644 net.cpp:100] Creating Layer bn5a_branch2c
I0528 17:10:14.084688 10644 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0528 17:10:14.084712 10644 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0528 17:10:14.085023 10644 net.cpp:150] Setting up bn5a_branch2c
I0528 17:10:14.085031 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.085033 10644 net.cpp:165] Memory required for data: 3817472084
I0528 17:10:14.085052 10644 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0528 17:10:14.085069 10644 net.cpp:100] Creating Layer scale5a_branch2c
I0528 17:10:14.085077 10644 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0528 17:10:14.085091 10644 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0528 17:10:14.085160 10644 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0528 17:10:14.085342 10644 net.cpp:150] Setting up scale5a_branch2c
I0528 17:10:14.085350 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.085353 10644 net.cpp:165] Memory required for data: 3843686484
I0528 17:10:14.085366 10644 layer_factory.hpp:77] Creating layer res5a
I0528 17:10:14.085378 10644 net.cpp:100] Creating Layer res5a
I0528 17:10:14.085384 10644 net.cpp:444] res5a <- res5a_branch1
I0528 17:10:14.085397 10644 net.cpp:444] res5a <- res5a_branch2c
I0528 17:10:14.085407 10644 net.cpp:418] res5a -> res5a
I0528 17:10:14.085453 10644 net.cpp:150] Setting up res5a
I0528 17:10:14.085463 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.085466 10644 net.cpp:165] Memory required for data: 3869900884
I0528 17:10:14.085471 10644 layer_factory.hpp:77] Creating layer res5a_relu
I0528 17:10:14.085482 10644 net.cpp:100] Creating Layer res5a_relu
I0528 17:10:14.085489 10644 net.cpp:444] res5a_relu <- res5a
I0528 17:10:14.085502 10644 net.cpp:405] res5a_relu -> res5a (in-place)
I0528 17:10:14.086688 10644 net.cpp:150] Setting up res5a_relu
I0528 17:10:14.086697 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.086701 10644 net.cpp:165] Memory required for data: 3896115284
I0528 17:10:14.086707 10644 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0528 17:10:14.086721 10644 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0528 17:10:14.086729 10644 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0528 17:10:14.086743 10644 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0528 17:10:14.086761 10644 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0528 17:10:14.086829 10644 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0528 17:10:14.086839 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.086845 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.086849 10644 net.cpp:165] Memory required for data: 3948544084
I0528 17:10:14.086854 10644 layer_factory.hpp:77] Creating layer res5b_branch2a
I0528 17:10:14.086871 10644 net.cpp:100] Creating Layer res5b_branch2a
I0528 17:10:14.086877 10644 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0528 17:10:14.086894 10644 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0528 17:10:14.090466 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.090489 10644 net.cpp:150] Setting up res5b_branch2a
I0528 17:10:14.090503 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.090507 10644 net.cpp:165] Memory required for data: 3955097684
I0528 17:10:14.090528 10644 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0528 17:10:14.090556 10644 net.cpp:100] Creating Layer bn5b_branch2a
I0528 17:10:14.090567 10644 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0528 17:10:14.090587 10644 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0528 17:10:14.090888 10644 net.cpp:150] Setting up bn5b_branch2a
I0528 17:10:14.090895 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.090898 10644 net.cpp:165] Memory required for data: 3961651284
I0528 17:10:14.090915 10644 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0528 17:10:14.090931 10644 net.cpp:100] Creating Layer scale5b_branch2a
I0528 17:10:14.090939 10644 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0528 17:10:14.090952 10644 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0528 17:10:14.091020 10644 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0528 17:10:14.091207 10644 net.cpp:150] Setting up scale5b_branch2a
I0528 17:10:14.091215 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.091218 10644 net.cpp:165] Memory required for data: 3968204884
I0528 17:10:14.091230 10644 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0528 17:10:14.091243 10644 net.cpp:100] Creating Layer res5b_branch2a_relu
I0528 17:10:14.091249 10644 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0528 17:10:14.091261 10644 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0528 17:10:14.091413 10644 net.cpp:150] Setting up res5b_branch2a_relu
I0528 17:10:14.091421 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.091424 10644 net.cpp:165] Memory required for data: 3974758484
I0528 17:10:14.091429 10644 layer_factory.hpp:77] Creating layer res5b_branch2b
I0528 17:10:14.091447 10644 net.cpp:100] Creating Layer res5b_branch2b
I0528 17:10:14.091454 10644 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0528 17:10:14.091470 10644 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0528 17:10:14.097380 10644 net.cpp:150] Setting up res5b_branch2b
I0528 17:10:14.097414 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.097419 10644 net.cpp:165] Memory required for data: 3981312084
I0528 17:10:14.097442 10644 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0528 17:10:14.097481 10644 net.cpp:100] Creating Layer bn5b_branch2b
I0528 17:10:14.097496 10644 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0528 17:10:14.097517 10644 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0528 17:10:14.097829 10644 net.cpp:150] Setting up bn5b_branch2b
I0528 17:10:14.097836 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.097839 10644 net.cpp:165] Memory required for data: 3987865684
I0528 17:10:14.097857 10644 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0528 17:10:14.097873 10644 net.cpp:100] Creating Layer scale5b_branch2b
I0528 17:10:14.097880 10644 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0528 17:10:14.097895 10644 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0528 17:10:14.097965 10644 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0528 17:10:14.098150 10644 net.cpp:150] Setting up scale5b_branch2b
I0528 17:10:14.098156 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.098160 10644 net.cpp:165] Memory required for data: 3994419284
I0528 17:10:14.098171 10644 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0528 17:10:14.098183 10644 net.cpp:100] Creating Layer res5b_branch2b_relu
I0528 17:10:14.098189 10644 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0528 17:10:14.098202 10644 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0528 17:10:14.098387 10644 net.cpp:150] Setting up res5b_branch2b_relu
I0528 17:10:14.098394 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.098397 10644 net.cpp:165] Memory required for data: 4000972884
I0528 17:10:14.098402 10644 layer_factory.hpp:77] Creating layer res5b_branch2c
I0528 17:10:14.098421 10644 net.cpp:100] Creating Layer res5b_branch2c
I0528 17:10:14.098428 10644 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0528 17:10:14.098445 10644 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0528 17:10:14.103169 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0528 17:10:14.103194 10644 net.cpp:150] Setting up res5b_branch2c
I0528 17:10:14.103212 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.103215 10644 net.cpp:165] Memory required for data: 4027187284
I0528 17:10:14.103241 10644 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0528 17:10:14.103271 10644 net.cpp:100] Creating Layer bn5b_branch2c
I0528 17:10:14.103283 10644 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0528 17:10:14.103305 10644 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0528 17:10:14.103606 10644 net.cpp:150] Setting up bn5b_branch2c
I0528 17:10:14.103615 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.103616 10644 net.cpp:165] Memory required for data: 4053401684
I0528 17:10:14.103633 10644 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0528 17:10:14.103651 10644 net.cpp:100] Creating Layer scale5b_branch2c
I0528 17:10:14.103657 10644 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0528 17:10:14.103672 10644 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0528 17:10:14.103739 10644 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0528 17:10:14.103929 10644 net.cpp:150] Setting up scale5b_branch2c
I0528 17:10:14.103935 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.103938 10644 net.cpp:165] Memory required for data: 4079616084
I0528 17:10:14.103951 10644 layer_factory.hpp:77] Creating layer res5b
I0528 17:10:14.103965 10644 net.cpp:100] Creating Layer res5b
I0528 17:10:14.103972 10644 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0528 17:10:14.103984 10644 net.cpp:444] res5b <- res5b_branch2c
I0528 17:10:14.103996 10644 net.cpp:418] res5b -> res5b
I0528 17:10:14.104043 10644 net.cpp:150] Setting up res5b
I0528 17:10:14.104053 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.104055 10644 net.cpp:165] Memory required for data: 4105830484
I0528 17:10:14.104060 10644 layer_factory.hpp:77] Creating layer res5b_relu
I0528 17:10:14.104073 10644 net.cpp:100] Creating Layer res5b_relu
I0528 17:10:14.104079 10644 net.cpp:444] res5b_relu <- res5b
I0528 17:10:14.104090 10644 net.cpp:405] res5b_relu -> res5b (in-place)
I0528 17:10:14.104573 10644 net.cpp:150] Setting up res5b_relu
I0528 17:10:14.104581 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.104584 10644 net.cpp:165] Memory required for data: 4132044884
I0528 17:10:14.104590 10644 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0528 17:10:14.104604 10644 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0528 17:10:14.104611 10644 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0528 17:10:14.104626 10644 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0528 17:10:14.104645 10644 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0528 17:10:14.104710 10644 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0528 17:10:14.104720 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.104725 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.104729 10644 net.cpp:165] Memory required for data: 4184473684
I0528 17:10:14.104734 10644 layer_factory.hpp:77] Creating layer res5c_branch2a
I0528 17:10:14.104753 10644 net.cpp:100] Creating Layer res5c_branch2a
I0528 17:10:14.104759 10644 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0528 17:10:14.104773 10644 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0528 17:10:14.108461 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.108485 10644 net.cpp:150] Setting up res5c_branch2a
I0528 17:10:14.108500 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.108503 10644 net.cpp:165] Memory required for data: 4191027284
I0528 17:10:14.108525 10644 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0528 17:10:14.108556 10644 net.cpp:100] Creating Layer bn5c_branch2a
I0528 17:10:14.108567 10644 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0528 17:10:14.108590 10644 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0528 17:10:14.108896 10644 net.cpp:150] Setting up bn5c_branch2a
I0528 17:10:14.108902 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.108906 10644 net.cpp:165] Memory required for data: 4197580884
I0528 17:10:14.108937 10644 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0528 17:10:14.108956 10644 net.cpp:100] Creating Layer scale5c_branch2a
I0528 17:10:14.108963 10644 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0528 17:10:14.108979 10644 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0528 17:10:14.109058 10644 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0528 17:10:14.109246 10644 net.cpp:150] Setting up scale5c_branch2a
I0528 17:10:14.109253 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.109257 10644 net.cpp:165] Memory required for data: 4204134484
I0528 17:10:14.109269 10644 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0528 17:10:14.109282 10644 net.cpp:100] Creating Layer res5c_branch2a_relu
I0528 17:10:14.109288 10644 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0528 17:10:14.109302 10644 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0528 17:10:14.109454 10644 net.cpp:150] Setting up res5c_branch2a_relu
I0528 17:10:14.109462 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.109464 10644 net.cpp:165] Memory required for data: 4210688084
I0528 17:10:14.109470 10644 layer_factory.hpp:77] Creating layer res5c_branch2b
I0528 17:10:14.109488 10644 net.cpp:100] Creating Layer res5c_branch2b
I0528 17:10:14.109494 10644 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0528 17:10:14.109510 10644 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0528 17:10:14.115190 10644 net.cpp:150] Setting up res5c_branch2b
I0528 17:10:14.115229 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.115233 10644 net.cpp:165] Memory required for data: 4217241684
I0528 17:10:14.115263 10644 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0528 17:10:14.115306 10644 net.cpp:100] Creating Layer bn5c_branch2b
I0528 17:10:14.115320 10644 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0528 17:10:14.115346 10644 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0528 17:10:14.115665 10644 net.cpp:150] Setting up bn5c_branch2b
I0528 17:10:14.115672 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.115675 10644 net.cpp:165] Memory required for data: 4223795284
I0528 17:10:14.115694 10644 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0528 17:10:14.115710 10644 net.cpp:100] Creating Layer scale5c_branch2b
I0528 17:10:14.115718 10644 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0528 17:10:14.115731 10644 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0528 17:10:14.115799 10644 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0528 17:10:14.115984 10644 net.cpp:150] Setting up scale5c_branch2b
I0528 17:10:14.115993 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.115995 10644 net.cpp:165] Memory required for data: 4230348884
I0528 17:10:14.116008 10644 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0528 17:10:14.116019 10644 net.cpp:100] Creating Layer res5c_branch2b_relu
I0528 17:10:14.116026 10644 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0528 17:10:14.116040 10644 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0528 17:10:14.116231 10644 net.cpp:150] Setting up res5c_branch2b_relu
I0528 17:10:14.116240 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.116242 10644 net.cpp:165] Memory required for data: 4236902484
I0528 17:10:14.116247 10644 layer_factory.hpp:77] Creating layer res5c_branch2c
I0528 17:10:14.116266 10644 net.cpp:100] Creating Layer res5c_branch2c
I0528 17:10:14.116271 10644 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0528 17:10:14.116289 10644 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0528 17:10:14.119978 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0528 17:10:14.120004 10644 net.cpp:150] Setting up res5c_branch2c
I0528 17:10:14.120018 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.120023 10644 net.cpp:165] Memory required for data: 4263116884
I0528 17:10:14.120044 10644 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0528 17:10:14.120072 10644 net.cpp:100] Creating Layer bn5c_branch2c
I0528 17:10:14.120085 10644 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0528 17:10:14.120103 10644 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0528 17:10:14.120401 10644 net.cpp:150] Setting up bn5c_branch2c
I0528 17:10:14.120409 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.120411 10644 net.cpp:165] Memory required for data: 4289331284
I0528 17:10:14.120429 10644 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0528 17:10:14.120445 10644 net.cpp:100] Creating Layer scale5c_branch2c
I0528 17:10:14.120452 10644 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0528 17:10:14.120466 10644 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0528 17:10:14.120537 10644 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0528 17:10:14.120723 10644 net.cpp:150] Setting up scale5c_branch2c
I0528 17:10:14.120729 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.120733 10644 net.cpp:165] Memory required for data: 4315545684
I0528 17:10:14.120745 10644 layer_factory.hpp:77] Creating layer res5c
I0528 17:10:14.120756 10644 net.cpp:100] Creating Layer res5c
I0528 17:10:14.120764 10644 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0528 17:10:14.120775 10644 net.cpp:444] res5c <- res5c_branch2c
I0528 17:10:14.120786 10644 net.cpp:418] res5c -> res5c
I0528 17:10:14.120831 10644 net.cpp:150] Setting up res5c
I0528 17:10:14.120841 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.120843 10644 net.cpp:165] Memory required for data: 4341760084
I0528 17:10:14.120849 10644 layer_factory.hpp:77] Creating layer res5c_relu
I0528 17:10:14.120860 10644 net.cpp:100] Creating Layer res5c_relu
I0528 17:10:14.120867 10644 net.cpp:444] res5c_relu <- res5c
I0528 17:10:14.120879 10644 net.cpp:405] res5c_relu -> res5c (in-place)
I0528 17:10:14.121042 10644 net.cpp:150] Setting up res5c_relu
I0528 17:10:14.121049 10644 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0528 17:10:14.121052 10644 net.cpp:165] Memory required for data: 4367974484
I0528 17:10:14.121057 10644 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0528 17:10:14.121078 10644 net.cpp:100] Creating Layer rpn_conv/3x3
I0528 17:10:14.121085 10644 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0528 17:10:14.121103 10644 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0528 17:10:14.600833 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.600865 10644 net.cpp:150] Setting up rpn_conv/3x3
I0528 17:10:14.600888 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.600891 10644 net.cpp:165] Memory required for data: 4374528084
I0528 17:10:14.600932 10644 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0528 17:10:14.600972 10644 net.cpp:100] Creating Layer rpn_relu/3x3
I0528 17:10:14.600991 10644 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0528 17:10:14.601016 10644 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0528 17:10:14.601526 10644 net.cpp:150] Setting up rpn_relu/3x3
I0528 17:10:14.601536 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.601538 10644 net.cpp:165] Memory required for data: 4381081684
I0528 17:10:14.601544 10644 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0528 17:10:14.601558 10644 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0528 17:10:14.601565 10644 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0528 17:10:14.601581 10644 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0528 17:10:14.601599 10644 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0528 17:10:14.601671 10644 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0528 17:10:14.601680 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.601686 10644 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0528 17:10:14.601689 10644 net.cpp:165] Memory required for data: 4394188884
I0528 17:10:14.601694 10644 layer_factory.hpp:77] Creating layer rpn_cls_score
I0528 17:10:14.601717 10644 net.cpp:100] Creating Layer rpn_cls_score
I0528 17:10:14.601723 10644 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0528 17:10:14.601742 10644 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0528 17:10:14.603996 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.604012 10644 net.cpp:150] Setting up rpn_cls_score
I0528 17:10:14.604020 10644 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0528 17:10:14.604023 10644 net.cpp:165] Memory required for data: 4394470484
I0528 17:10:14.604037 10644 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0528 17:10:14.604049 10644 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0528 17:10:14.604056 10644 net.cpp:444] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0528 17:10:14.604070 10644 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0528 17:10:14.604087 10644 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0528 17:10:14.604149 10644 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0528 17:10:14.604158 10644 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0528 17:10:14.604164 10644 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0528 17:10:14.604167 10644 net.cpp:165] Memory required for data: 4395033684
I0528 17:10:14.604172 10644 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0528 17:10:14.604190 10644 net.cpp:100] Creating Layer rpn_bbox_pred
I0528 17:10:14.604197 10644 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0528 17:10:14.604213 10644 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0528 17:10:14.607666 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.607684 10644 net.cpp:150] Setting up rpn_bbox_pred
I0528 17:10:14.607692 10644 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0528 17:10:14.607695 10644 net.cpp:165] Memory required for data: 4395596884
I0528 17:10:14.607709 10644 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0528 17:10:14.607722 10644 net.cpp:100] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0528 17:10:14.607728 10644 net.cpp:444] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0528 17:10:14.607743 10644 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0528 17:10:14.607758 10644 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0528 17:10:14.607817 10644 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0528 17:10:14.607826 10644 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0528 17:10:14.607832 10644 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0528 17:10:14.607836 10644 net.cpp:165] Memory required for data: 4396723284
I0528 17:10:14.607841 10644 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0528 17:10:14.607856 10644 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0528 17:10:14.607862 10644 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0528 17:10:14.607877 10644 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0528 17:10:14.607923 10644 net.cpp:150] Setting up rpn_cls_score_reshape
I0528 17:10:14.607933 10644 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0528 17:10:14.607935 10644 net.cpp:165] Memory required for data: 4397004884
I0528 17:10:14.607940 10644 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0528 17:10:14.607950 10644 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0528 17:10:14.607956 10644 net.cpp:444] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0528 17:10:14.607970 10644 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0528 17:10:14.607986 10644 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0528 17:10:14.608043 10644 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0528 17:10:14.608052 10644 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0528 17:10:14.608057 10644 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0528 17:10:14.608062 10644 net.cpp:165] Memory required for data: 4397568084
I0528 17:10:14.608065 10644 layer_factory.hpp:77] Creating layer rpn-data
I0528 17:10:14.617314 10644 net.cpp:100] Creating Layer rpn-data
I0528 17:10:14.617343 10644 net.cpp:444] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0528 17:10:14.617370 10644 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I0528 17:10:14.617380 10644 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I0528 17:10:14.617388 10644 net.cpp:444] rpn-data <- data_input-data_0_split_1
I0528 17:10:14.617403 10644 net.cpp:418] rpn-data -> rpn_labels
I0528 17:10:14.617427 10644 net.cpp:418] rpn-data -> rpn_bbox_targets
I0528 17:10:14.617444 10644 net.cpp:418] rpn-data -> rpn_bbox_inside_weights
I0528 17:10:14.617460 10644 net.cpp:418] rpn-data -> rpn_bbox_outside_weights
I0528 17:10:14.618073 10644 net.cpp:150] Setting up rpn-data
I0528 17:10:14.618091 10644 net.cpp:157] Top shape: 1 1 440 80 (35200)
I0528 17:10:14.618098 10644 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0528 17:10:14.618103 10644 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0528 17:10:14.618108 10644 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0528 17:10:14.618110 10644 net.cpp:165] Memory required for data: 4399398484
I0528 17:10:14.618119 10644 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0528 17:10:14.618137 10644 net.cpp:100] Creating Layer rpn_loss_cls
I0528 17:10:14.618144 10644 net.cpp:444] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0528 17:10:14.618157 10644 net.cpp:444] rpn_loss_cls <- rpn_labels
I0528 17:10:14.618170 10644 net.cpp:418] rpn_loss_cls -> rpn_cls_loss
I0528 17:10:14.618204 10644 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0528 17:10:14.618644 10644 net.cpp:150] Setting up rpn_loss_cls
I0528 17:10:14.618655 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.618659 10644 net.cpp:160]     with loss weight 1
I0528 17:10:14.618669 10644 net.cpp:165] Memory required for data: 4399398488
I0528 17:10:14.618674 10644 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0528 17:10:14.618707 10644 net.cpp:100] Creating Layer rpn_loss_bbox
I0528 17:10:14.618716 10644 net.cpp:444] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0528 17:10:14.618728 10644 net.cpp:444] rpn_loss_bbox <- rpn_bbox_targets
I0528 17:10:14.618736 10644 net.cpp:444] rpn_loss_bbox <- rpn_bbox_inside_weights
I0528 17:10:14.618744 10644 net.cpp:444] rpn_loss_bbox <- rpn_bbox_outside_weights
I0528 17:10:14.618754 10644 net.cpp:418] rpn_loss_bbox -> rpn_loss_bbox
I0528 17:10:14.621389 10644 net.cpp:150] Setting up rpn_loss_bbox
I0528 17:10:14.621412 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.621414 10644 net.cpp:160]     with loss weight 1
I0528 17:10:14.621426 10644 net.cpp:165] Memory required for data: 4399398492
I0528 17:10:14.621448 10644 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0528 17:10:14.621474 10644 net.cpp:100] Creating Layer rpn_cls_prob
I0528 17:10:14.621485 10644 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0528 17:10:14.621510 10644 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0528 17:10:14.622248 10644 net.cpp:150] Setting up rpn_cls_prob
I0528 17:10:14.622261 10644 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0528 17:10:14.622264 10644 net.cpp:165] Memory required for data: 4399680092
I0528 17:10:14.622270 10644 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0528 17:10:14.622290 10644 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0528 17:10:14.622298 10644 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0528 17:10:14.622314 10644 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0528 17:10:14.622367 10644 net.cpp:150] Setting up rpn_cls_prob_reshape
I0528 17:10:14.622375 10644 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0528 17:10:14.622380 10644 net.cpp:165] Memory required for data: 4399961692
I0528 17:10:14.622385 10644 layer_factory.hpp:77] Creating layer proposal
I0528 17:10:14.622887 10644 net.cpp:100] Creating Layer proposal
I0528 17:10:14.622898 10644 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0528 17:10:14.622911 10644 net.cpp:444] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0528 17:10:14.622921 10644 net.cpp:444] proposal <- im_info_input-data_1_split_1
I0528 17:10:14.622933 10644 net.cpp:418] proposal -> rpn_rois
I0528 17:10:14.624366 10644 net.cpp:150] Setting up proposal
I0528 17:10:14.624378 10644 net.cpp:157] Top shape: 1 5 (5)
I0528 17:10:14.624383 10644 net.cpp:165] Memory required for data: 4399961712
I0528 17:10:14.624389 10644 layer_factory.hpp:77] Creating layer roi-data
I0528 17:10:14.624831 10644 net.cpp:100] Creating Layer roi-data
I0528 17:10:14.624842 10644 net.cpp:444] roi-data <- rpn_rois
I0528 17:10:14.624861 10644 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I0528 17:10:14.624873 10644 net.cpp:418] roi-data -> rois
I0528 17:10:14.624893 10644 net.cpp:418] roi-data -> labels
I0528 17:10:14.624908 10644 net.cpp:418] roi-data -> bbox_targets
I0528 17:10:14.624986 10644 net.cpp:418] roi-data -> bbox_inside_weights
I0528 17:10:14.625000 10644 net.cpp:418] roi-data -> bbox_outside_weights
I0528 17:10:14.625435 10644 net.cpp:150] Setting up roi-data
I0528 17:10:14.625449 10644 net.cpp:157] Top shape: 1 5 1 1 (5)
I0528 17:10:14.625455 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.625460 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.625465 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.625470 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.625474 10644 net.cpp:165] Memory required for data: 4399961832
I0528 17:10:14.625480 10644 layer_factory.hpp:77] Creating layer rois_roi-data_0_split
I0528 17:10:14.625494 10644 net.cpp:100] Creating Layer rois_roi-data_0_split
I0528 17:10:14.625501 10644 net.cpp:444] rois_roi-data_0_split <- rois
I0528 17:10:14.625517 10644 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_0
I0528 17:10:14.625535 10644 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_1
I0528 17:10:14.625548 10644 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_2
I0528 17:10:14.625632 10644 net.cpp:150] Setting up rois_roi-data_0_split
I0528 17:10:14.625641 10644 net.cpp:157] Top shape: 1 5 1 1 (5)
I0528 17:10:14.625646 10644 net.cpp:157] Top shape: 1 5 1 1 (5)
I0528 17:10:14.625651 10644 net.cpp:157] Top shape: 1 5 1 1 (5)
I0528 17:10:14.625654 10644 net.cpp:165] Memory required for data: 4399961892
I0528 17:10:14.625659 10644 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0528 17:10:14.625670 10644 net.cpp:100] Creating Layer labels_roi-data_1_split
I0528 17:10:14.625677 10644 net.cpp:444] labels_roi-data_1_split <- labels
I0528 17:10:14.625690 10644 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0528 17:10:14.625705 10644 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0528 17:10:14.625761 10644 net.cpp:150] Setting up labels_roi-data_1_split
I0528 17:10:14.625771 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.625775 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.625779 10644 net.cpp:165] Memory required for data: 4399961900
I0528 17:10:14.625783 10644 layer_factory.hpp:77] Creating layer bbox_targets_roi-data_2_split
I0528 17:10:14.625793 10644 net.cpp:100] Creating Layer bbox_targets_roi-data_2_split
I0528 17:10:14.625798 10644 net.cpp:444] bbox_targets_roi-data_2_split <- bbox_targets
I0528 17:10:14.625811 10644 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_0
I0528 17:10:14.625828 10644 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_1
I0528 17:10:14.625882 10644 net.cpp:150] Setting up bbox_targets_roi-data_2_split
I0528 17:10:14.625891 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.625896 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.625900 10644 net.cpp:165] Memory required for data: 4399961964
I0528 17:10:14.625905 10644 layer_factory.hpp:77] Creating layer bbox_inside_weights_roi-data_3_split
I0528 17:10:14.625914 10644 net.cpp:100] Creating Layer bbox_inside_weights_roi-data_3_split
I0528 17:10:14.625921 10644 net.cpp:444] bbox_inside_weights_roi-data_3_split <- bbox_inside_weights
I0528 17:10:14.625932 10644 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_0
I0528 17:10:14.625948 10644 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_1
I0528 17:10:14.626004 10644 net.cpp:150] Setting up bbox_inside_weights_roi-data_3_split
I0528 17:10:14.626013 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.626019 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.626021 10644 net.cpp:165] Memory required for data: 4399962028
I0528 17:10:14.626025 10644 layer_factory.hpp:77] Creating layer conv_new_1
I0528 17:10:14.626049 10644 net.cpp:100] Creating Layer conv_new_1
I0528 17:10:14.626056 10644 net.cpp:444] conv_new_1 <- res5c
I0528 17:10:14.626071 10644 net.cpp:418] conv_new_1 -> conv_new_1
I0528 17:10:14.840524 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.840548 10644 net.cpp:150] Setting up conv_new_1
I0528 17:10:14.840561 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.840565 10644 net.cpp:165] Memory required for data: 4413069228
I0528 17:10:14.840587 10644 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0528 17:10:14.840615 10644 net.cpp:100] Creating Layer conv_new_1_relu
I0528 17:10:14.840627 10644 net.cpp:444] conv_new_1_relu <- conv_new_1
I0528 17:10:14.840646 10644 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0528 17:10:14.841135 10644 net.cpp:150] Setting up conv_new_1_relu
I0528 17:10:14.841145 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.841147 10644 net.cpp:165] Memory required for data: 4426176428
I0528 17:10:14.841152 10644 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0528 17:10:14.841166 10644 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0528 17:10:14.841171 10644 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0528 17:10:14.841187 10644 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0528 17:10:14.841207 10644 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0528 17:10:14.841275 10644 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0528 17:10:14.841285 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.841291 10644 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0528 17:10:14.841295 10644 net.cpp:165] Memory required for data: 4452390828
I0528 17:10:14.841300 10644 layer_factory.hpp:77] Creating layer rfcn_cls
I0528 17:10:14.841322 10644 net.cpp:100] Creating Layer rfcn_cls
I0528 17:10:14.841329 10644 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0528 17:10:14.841346 10644 net.cpp:418] rfcn_cls -> rfcn_cls
I0528 17:10:14.852834 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.852856 10644 net.cpp:150] Setting up rfcn_cls
I0528 17:10:14.852871 10644 net.cpp:157] Top shape: 1 98 40 80 (313600)
I0528 17:10:14.852874 10644 net.cpp:165] Memory required for data: 4453645228
I0528 17:10:14.852895 10644 layer_factory.hpp:77] Creating layer rfcn_bbox
I0528 17:10:14.852936 10644 net.cpp:100] Creating Layer rfcn_bbox
I0528 17:10:14.852948 10644 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0528 17:10:14.852972 10644 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0528 17:10:14.895823 10644 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0528 17:10:14.895848 10644 net.cpp:150] Setting up rfcn_bbox
I0528 17:10:14.895862 10644 net.cpp:157] Top shape: 1 392 40 80 (1254400)
I0528 17:10:14.895866 10644 net.cpp:165] Memory required for data: 4458662828
I0528 17:10:14.895889 10644 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0528 17:10:14.895917 10644 net.cpp:100] Creating Layer psroipooled_cls_rois
I0528 17:10:14.895929 10644 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0528 17:10:14.895951 10644 net.cpp:444] psroipooled_cls_rois <- rois_roi-data_0_split_0
I0528 17:10:14.895967 10644 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0528 17:10:14.895992 10644 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0528 17:10:14.896077 10644 net.cpp:150] Setting up psroipooled_cls_rois
I0528 17:10:14.896088 10644 net.cpp:157] Top shape: 1 2 7 7 (98)
I0528 17:10:14.896091 10644 net.cpp:165] Memory required for data: 4458663220
I0528 17:10:14.896096 10644 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0528 17:10:14.896113 10644 net.cpp:100] Creating Layer ave_cls_score_rois
I0528 17:10:14.896119 10644 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0528 17:10:14.896136 10644 net.cpp:418] ave_cls_score_rois -> cls_score
I0528 17:10:14.896323 10644 net.cpp:150] Setting up ave_cls_score_rois
I0528 17:10:14.896332 10644 net.cpp:157] Top shape: 1 2 1 1 (2)
I0528 17:10:14.896337 10644 net.cpp:165] Memory required for data: 4458663228
I0528 17:10:14.896342 10644 layer_factory.hpp:77] Creating layer cls_score_ave_cls_score_rois_0_split
I0528 17:10:14.896355 10644 net.cpp:100] Creating Layer cls_score_ave_cls_score_rois_0_split
I0528 17:10:14.896363 10644 net.cpp:444] cls_score_ave_cls_score_rois_0_split <- cls_score
I0528 17:10:14.896378 10644 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_0
I0528 17:10:14.896399 10644 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_1
I0528 17:10:14.896416 10644 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_2
I0528 17:10:14.896502 10644 net.cpp:150] Setting up cls_score_ave_cls_score_rois_0_split
I0528 17:10:14.896510 10644 net.cpp:157] Top shape: 1 2 1 1 (2)
I0528 17:10:14.896517 10644 net.cpp:157] Top shape: 1 2 1 1 (2)
I0528 17:10:14.896522 10644 net.cpp:157] Top shape: 1 2 1 1 (2)
I0528 17:10:14.896525 10644 net.cpp:165] Memory required for data: 4458663252
I0528 17:10:14.896530 10644 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0528 17:10:14.896543 10644 net.cpp:100] Creating Layer psroipooled_loc_rois
I0528 17:10:14.896550 10644 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0528 17:10:14.896562 10644 net.cpp:444] psroipooled_loc_rois <- rois_roi-data_0_split_1
I0528 17:10:14.896575 10644 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0528 17:10:14.896592 10644 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0528 17:10:14.896657 10644 net.cpp:150] Setting up psroipooled_loc_rois
I0528 17:10:14.896667 10644 net.cpp:157] Top shape: 1 8 7 7 (392)
I0528 17:10:14.896670 10644 net.cpp:165] Memory required for data: 4458664820
I0528 17:10:14.896675 10644 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0528 17:10:14.896688 10644 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0528 17:10:14.896695 10644 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0528 17:10:14.896713 10644 net.cpp:418] ave_bbox_pred_rois -> bbox_pred
I0528 17:10:14.896888 10644 net.cpp:150] Setting up ave_bbox_pred_rois
I0528 17:10:14.896898 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.896903 10644 net.cpp:165] Memory required for data: 4458664852
I0528 17:10:14.896908 10644 layer_factory.hpp:77] Creating layer bbox_pred_ave_bbox_pred_rois_0_split
I0528 17:10:14.896924 10644 net.cpp:100] Creating Layer bbox_pred_ave_bbox_pred_rois_0_split
I0528 17:10:14.896932 10644 net.cpp:444] bbox_pred_ave_bbox_pred_rois_0_split <- bbox_pred
I0528 17:10:14.896948 10644 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_0
I0528 17:10:14.896967 10644 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_1
I0528 17:10:14.897037 10644 net.cpp:150] Setting up bbox_pred_ave_bbox_pred_rois_0_split
I0528 17:10:14.897044 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.897049 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.897053 10644 net.cpp:165] Memory required for data: 4458664916
I0528 17:10:14.897058 10644 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0528 17:10:14.897073 10644 net.cpp:100] Creating Layer per_roi_loss_cls
I0528 17:10:14.897079 10644 net.cpp:444] per_roi_loss_cls <- cls_score_ave_cls_score_rois_0_split_0
I0528 17:10:14.897092 10644 net.cpp:444] per_roi_loss_cls <- labels_roi-data_1_split_0
I0528 17:10:14.897107 10644 net.cpp:418] per_roi_loss_cls -> temp_loss_cls
I0528 17:10:14.897125 10644 net.cpp:418] per_roi_loss_cls -> temp_prob_cls
I0528 17:10:14.897143 10644 net.cpp:418] per_roi_loss_cls -> per_roi_loss_cls
I0528 17:10:14.897161 10644 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0528 17:10:14.897780 10644 net.cpp:150] Setting up per_roi_loss_cls
I0528 17:10:14.897790 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.897796 10644 net.cpp:157] Top shape: 1 2 1 1 (2)
I0528 17:10:14.897801 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.897804 10644 net.cpp:165] Memory required for data: 4458664932
I0528 17:10:14.897810 10644 layer_factory.hpp:77] Creating layer per_roi_loss_bbox
I0528 17:10:14.897825 10644 net.cpp:100] Creating Layer per_roi_loss_bbox
I0528 17:10:14.897832 10644 net.cpp:444] per_roi_loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_0
I0528 17:10:14.897847 10644 net.cpp:444] per_roi_loss_bbox <- bbox_targets_roi-data_2_split_0
I0528 17:10:14.897858 10644 net.cpp:444] per_roi_loss_bbox <- bbox_inside_weights_roi-data_3_split_0
I0528 17:10:14.897872 10644 net.cpp:418] per_roi_loss_bbox -> temp_loss_bbox
I0528 17:10:14.897892 10644 net.cpp:418] per_roi_loss_bbox -> per_roi_loss_bbox
I0528 17:10:14.897990 10644 net.cpp:150] Setting up per_roi_loss_bbox
I0528 17:10:14.898000 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.898005 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.898007 10644 net.cpp:165] Memory required for data: 4458664940
I0528 17:10:14.898013 10644 layer_factory.hpp:77] Creating layer per_roi_loss
I0528 17:10:14.898026 10644 net.cpp:100] Creating Layer per_roi_loss
I0528 17:10:14.898032 10644 net.cpp:444] per_roi_loss <- per_roi_loss_cls
I0528 17:10:14.898046 10644 net.cpp:444] per_roi_loss <- per_roi_loss_bbox
I0528 17:10:14.898058 10644 net.cpp:418] per_roi_loss -> per_roi_loss
I0528 17:10:14.898108 10644 net.cpp:150] Setting up per_roi_loss
I0528 17:10:14.898115 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.898119 10644 net.cpp:165] Memory required for data: 4458664944
I0528 17:10:14.898124 10644 layer_factory.hpp:77] Creating layer annotator_detector
I0528 17:10:14.898140 10644 net.cpp:100] Creating Layer annotator_detector
I0528 17:10:14.898146 10644 net.cpp:444] annotator_detector <- rois_roi-data_0_split_2
I0528 17:10:14.898159 10644 net.cpp:444] annotator_detector <- per_roi_loss
I0528 17:10:14.898169 10644 net.cpp:444] annotator_detector <- labels_roi-data_1_split_1
I0528 17:10:14.898177 10644 net.cpp:444] annotator_detector <- bbox_inside_weights_roi-data_3_split_1
I0528 17:10:14.898191 10644 net.cpp:418] annotator_detector -> labels_ohem
I0528 17:10:14.898210 10644 net.cpp:418] annotator_detector -> bbox_loss_weights_ohem
I0528 17:10:14.898279 10644 net.cpp:150] Setting up annotator_detector
I0528 17:10:14.898288 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.898293 10644 net.cpp:157] Top shape: 1 8 1 1 (8)
I0528 17:10:14.898296 10644 net.cpp:165] Memory required for data: 4458664980
I0528 17:10:14.898301 10644 layer_factory.hpp:77] Creating layer labels_ohem_annotator_detector_0_split
I0528 17:10:14.898313 10644 net.cpp:100] Creating Layer labels_ohem_annotator_detector_0_split
I0528 17:10:14.898320 10644 net.cpp:444] labels_ohem_annotator_detector_0_split <- labels_ohem
I0528 17:10:14.898334 10644 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_0
I0528 17:10:14.898352 10644 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_1
I0528 17:10:14.898417 10644 net.cpp:150] Setting up labels_ohem_annotator_detector_0_split
I0528 17:10:14.898425 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.898430 10644 net.cpp:157] Top shape: 1 1 1 1 (1)
I0528 17:10:14.898433 10644 net.cpp:165] Memory required for data: 4458664988
I0528 17:10:14.898438 10644 layer_factory.hpp:77] Creating layer silence
I0528 17:10:14.898449 10644 net.cpp:100] Creating Layer silence
I0528 17:10:14.898456 10644 net.cpp:444] silence <- bbox_outside_weights
I0528 17:10:14.898469 10644 net.cpp:444] silence <- temp_loss_cls
I0528 17:10:14.898479 10644 net.cpp:444] silence <- temp_prob_cls
I0528 17:10:14.898488 10644 net.cpp:444] silence <- temp_loss_bbox
I0528 17:10:14.898494 10644 net.cpp:150] Setting up silence
I0528 17:10:14.898499 10644 net.cpp:165] Memory required for data: 4458664988
I0528 17:10:14.898504 10644 layer_factory.hpp:77] Creating layer loss
I0528 17:10:14.898517 10644 net.cpp:100] Creating Layer loss
I0528 17:10:14.898524 10644 net.cpp:444] loss <- cls_score_ave_cls_score_rois_0_split_1
I0528 17:10:14.898533 10644 net.cpp:444] loss <- labels_ohem_annotator_detector_0_split_0
I0528 17:10:14.898546 10644 net.cpp:418] loss -> loss_cls
I0528 17:10:14.898566 10644 layer_factory.hpp:77] Creating layer loss
I0528 17:10:14.898852 10644 net.cpp:150] Setting up loss
I0528 17:10:14.898860 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.898864 10644 net.cpp:160]     with loss weight 1
I0528 17:10:14.898869 10644 net.cpp:165] Memory required for data: 4458664992
I0528 17:10:14.898874 10644 layer_factory.hpp:77] Creating layer accuarcy
I0528 17:10:14.898890 10644 net.cpp:100] Creating Layer accuarcy
I0528 17:10:14.898896 10644 net.cpp:444] accuarcy <- cls_score_ave_cls_score_rois_0_split_2
I0528 17:10:14.898910 10644 net.cpp:444] accuarcy <- labels_ohem_annotator_detector_0_split_1
I0528 17:10:14.898924 10644 net.cpp:418] accuarcy -> accuarcy
I0528 17:10:14.898947 10644 net.cpp:150] Setting up accuarcy
I0528 17:10:14.898955 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.898958 10644 net.cpp:165] Memory required for data: 4458664996
I0528 17:10:14.898963 10644 layer_factory.hpp:77] Creating layer loss_bbox
I0528 17:10:14.898977 10644 net.cpp:100] Creating Layer loss_bbox
I0528 17:10:14.898983 10644 net.cpp:444] loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_1
I0528 17:10:14.898995 10644 net.cpp:444] loss_bbox <- bbox_targets_roi-data_2_split_1
I0528 17:10:14.899004 10644 net.cpp:444] loss_bbox <- bbox_loss_weights_ohem
I0528 17:10:14.899019 10644 net.cpp:418] loss_bbox -> loss_bbox
I0528 17:10:14.899113 10644 net.cpp:150] Setting up loss_bbox
I0528 17:10:14.899121 10644 net.cpp:157] Top shape: (1)
I0528 17:10:14.899123 10644 net.cpp:160]     with loss weight 1
I0528 17:10:14.899128 10644 net.cpp:165] Memory required for data: 4458665000
I0528 17:10:14.899134 10644 net.cpp:226] loss_bbox needs backward computation.
I0528 17:10:14.899143 10644 net.cpp:228] accuarcy does not need backward computation.
I0528 17:10:14.899148 10644 net.cpp:226] loss needs backward computation.
I0528 17:10:14.899157 10644 net.cpp:228] silence does not need backward computation.
I0528 17:10:14.899163 10644 net.cpp:228] labels_ohem_annotator_detector_0_split does not need backward computation.
I0528 17:10:14.899169 10644 net.cpp:228] annotator_detector does not need backward computation.
I0528 17:10:14.899178 10644 net.cpp:228] per_roi_loss does not need backward computation.
I0528 17:10:14.899186 10644 net.cpp:228] per_roi_loss_bbox does not need backward computation.
I0528 17:10:14.899196 10644 net.cpp:228] per_roi_loss_cls does not need backward computation.
I0528 17:10:14.899204 10644 net.cpp:226] bbox_pred_ave_bbox_pred_rois_0_split needs backward computation.
I0528 17:10:14.899209 10644 net.cpp:226] ave_bbox_pred_rois needs backward computation.
I0528 17:10:14.899212 10644 net.cpp:226] psroipooled_loc_rois needs backward computation.
I0528 17:10:14.899219 10644 net.cpp:226] cls_score_ave_cls_score_rois_0_split needs backward computation.
I0528 17:10:14.899224 10644 net.cpp:226] ave_cls_score_rois needs backward computation.
I0528 17:10:14.899229 10644 net.cpp:226] psroipooled_cls_rois needs backward computation.
I0528 17:10:14.899235 10644 net.cpp:226] rfcn_bbox needs backward computation.
I0528 17:10:14.899240 10644 net.cpp:226] rfcn_cls needs backward computation.
I0528 17:10:14.899246 10644 net.cpp:226] conv_new_1_conv_new_1_relu_0_split needs backward computation.
I0528 17:10:14.899251 10644 net.cpp:226] conv_new_1_relu needs backward computation.
I0528 17:10:14.899255 10644 net.cpp:226] conv_new_1 needs backward computation.
I0528 17:10:14.899262 10644 net.cpp:228] bbox_inside_weights_roi-data_3_split does not need backward computation.
I0528 17:10:14.899268 10644 net.cpp:228] bbox_targets_roi-data_2_split does not need backward computation.
I0528 17:10:14.899276 10644 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0528 17:10:14.899281 10644 net.cpp:226] rois_roi-data_0_split needs backward computation.
I0528 17:10:14.899286 10644 net.cpp:226] roi-data needs backward computation.
I0528 17:10:14.899293 10644 net.cpp:226] proposal needs backward computation.
I0528 17:10:14.899302 10644 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0528 17:10:14.899307 10644 net.cpp:226] rpn_cls_prob needs backward computation.
I0528 17:10:14.899313 10644 net.cpp:226] rpn_loss_bbox needs backward computation.
I0528 17:10:14.899322 10644 net.cpp:226] rpn_loss_cls needs backward computation.
I0528 17:10:14.899328 10644 net.cpp:226] rpn-data needs backward computation.
I0528 17:10:14.899339 10644 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0528 17:10:14.899345 10644 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0528 17:10:14.899350 10644 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0528 17:10:14.899355 10644 net.cpp:226] rpn_bbox_pred needs backward computation.
I0528 17:10:14.899361 10644 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0528 17:10:14.899368 10644 net.cpp:226] rpn_cls_score needs backward computation.
I0528 17:10:14.899374 10644 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0528 17:10:14.899379 10644 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0528 17:10:14.899384 10644 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0528 17:10:14.899389 10644 net.cpp:226] res5c_relu needs backward computation.
I0528 17:10:14.899394 10644 net.cpp:226] res5c needs backward computation.
I0528 17:10:14.899399 10644 net.cpp:226] scale5c_branch2c needs backward computation.
I0528 17:10:14.899404 10644 net.cpp:226] bn5c_branch2c needs backward computation.
I0528 17:10:14.899408 10644 net.cpp:226] res5c_branch2c needs backward computation.
I0528 17:10:14.899413 10644 net.cpp:226] res5c_branch2b_relu needs backward computation.
I0528 17:10:14.899418 10644 net.cpp:226] scale5c_branch2b needs backward computation.
I0528 17:10:14.899422 10644 net.cpp:226] bn5c_branch2b needs backward computation.
I0528 17:10:14.899427 10644 net.cpp:226] res5c_branch2b needs backward computation.
I0528 17:10:14.899432 10644 net.cpp:226] res5c_branch2a_relu needs backward computation.
I0528 17:10:14.899436 10644 net.cpp:226] scale5c_branch2a needs backward computation.
I0528 17:10:14.899441 10644 net.cpp:226] bn5c_branch2a needs backward computation.
I0528 17:10:14.899446 10644 net.cpp:226] res5c_branch2a needs backward computation.
I0528 17:10:14.899451 10644 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I0528 17:10:14.899456 10644 net.cpp:226] res5b_relu needs backward computation.
I0528 17:10:14.899461 10644 net.cpp:226] res5b needs backward computation.
I0528 17:10:14.899467 10644 net.cpp:226] scale5b_branch2c needs backward computation.
I0528 17:10:14.899472 10644 net.cpp:226] bn5b_branch2c needs backward computation.
I0528 17:10:14.899477 10644 net.cpp:226] res5b_branch2c needs backward computation.
I0528 17:10:14.899482 10644 net.cpp:226] res5b_branch2b_relu needs backward computation.
I0528 17:10:14.899487 10644 net.cpp:226] scale5b_branch2b needs backward computation.
I0528 17:10:14.899492 10644 net.cpp:226] bn5b_branch2b needs backward computation.
I0528 17:10:14.899495 10644 net.cpp:226] res5b_branch2b needs backward computation.
I0528 17:10:14.899500 10644 net.cpp:226] res5b_branch2a_relu needs backward computation.
I0528 17:10:14.899505 10644 net.cpp:226] scale5b_branch2a needs backward computation.
I0528 17:10:14.899510 10644 net.cpp:226] bn5b_branch2a needs backward computation.
I0528 17:10:14.899514 10644 net.cpp:226] res5b_branch2a needs backward computation.
I0528 17:10:14.899520 10644 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I0528 17:10:14.899525 10644 net.cpp:226] res5a_relu needs backward computation.
I0528 17:10:14.899530 10644 net.cpp:226] res5a needs backward computation.
I0528 17:10:14.899536 10644 net.cpp:226] scale5a_branch2c needs backward computation.
I0528 17:10:14.899541 10644 net.cpp:226] bn5a_branch2c needs backward computation.
I0528 17:10:14.899545 10644 net.cpp:226] res5a_branch2c needs backward computation.
I0528 17:10:14.899554 10644 net.cpp:226] res5a_branch2b_relu needs backward computation.
I0528 17:10:14.899559 10644 net.cpp:226] scale5a_branch2b needs backward computation.
I0528 17:10:14.899564 10644 net.cpp:226] bn5a_branch2b needs backward computation.
I0528 17:10:14.899569 10644 net.cpp:226] res5a_branch2b needs backward computation.
I0528 17:10:14.899574 10644 net.cpp:226] res5a_branch2a_relu needs backward computation.
I0528 17:10:14.899577 10644 net.cpp:226] scale5a_branch2a needs backward computation.
I0528 17:10:14.899582 10644 net.cpp:226] bn5a_branch2a needs backward computation.
I0528 17:10:14.899587 10644 net.cpp:226] res5a_branch2a needs backward computation.
I0528 17:10:14.899592 10644 net.cpp:226] scale5a_branch1 needs backward computation.
I0528 17:10:14.899597 10644 net.cpp:226] bn5a_branch1 needs backward computation.
I0528 17:10:14.899602 10644 net.cpp:226] res5a_branch1 needs backward computation.
I0528 17:10:14.899608 10644 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I0528 17:10:14.899613 10644 net.cpp:226] res4f_relu needs backward computation.
I0528 17:10:14.899618 10644 net.cpp:226] res4f needs backward computation.
I0528 17:10:14.899626 10644 net.cpp:226] scale4f_branch2c needs backward computation.
I0528 17:10:14.899629 10644 net.cpp:226] bn4f_branch2c needs backward computation.
I0528 17:10:14.899634 10644 net.cpp:226] res4f_branch2c needs backward computation.
I0528 17:10:14.899639 10644 net.cpp:226] res4f_branch2b_relu needs backward computation.
I0528 17:10:14.899644 10644 net.cpp:226] scale4f_branch2b needs backward computation.
I0528 17:10:14.899649 10644 net.cpp:226] bn4f_branch2b needs backward computation.
I0528 17:10:14.899654 10644 net.cpp:226] res4f_branch2b needs backward computation.
I0528 17:10:14.899659 10644 net.cpp:226] res4f_branch2a_relu needs backward computation.
I0528 17:10:14.899664 10644 net.cpp:226] scale4f_branch2a needs backward computation.
I0528 17:10:14.899669 10644 net.cpp:226] bn4f_branch2a needs backward computation.
I0528 17:10:14.899673 10644 net.cpp:226] res4f_branch2a needs backward computation.
I0528 17:10:14.899678 10644 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I0528 17:10:14.899684 10644 net.cpp:226] res4e_relu needs backward computation.
I0528 17:10:14.899689 10644 net.cpp:226] res4e needs backward computation.
I0528 17:10:14.899695 10644 net.cpp:226] scale4e_branch2c needs backward computation.
I0528 17:10:14.899700 10644 net.cpp:226] bn4e_branch2c needs backward computation.
I0528 17:10:14.899704 10644 net.cpp:226] res4e_branch2c needs backward computation.
I0528 17:10:14.899710 10644 net.cpp:226] res4e_branch2b_relu needs backward computation.
I0528 17:10:14.899714 10644 net.cpp:226] scale4e_branch2b needs backward computation.
I0528 17:10:14.899719 10644 net.cpp:226] bn4e_branch2b needs backward computation.
I0528 17:10:14.899724 10644 net.cpp:226] res4e_branch2b needs backward computation.
I0528 17:10:14.899729 10644 net.cpp:226] res4e_branch2a_relu needs backward computation.
I0528 17:10:14.899734 10644 net.cpp:226] scale4e_branch2a needs backward computation.
I0528 17:10:14.899739 10644 net.cpp:226] bn4e_branch2a needs backward computation.
I0528 17:10:14.899742 10644 net.cpp:226] res4e_branch2a needs backward computation.
I0528 17:10:14.899749 10644 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I0528 17:10:14.899754 10644 net.cpp:226] res4d_relu needs backward computation.
I0528 17:10:14.899757 10644 net.cpp:226] res4d needs backward computation.
I0528 17:10:14.899763 10644 net.cpp:226] scale4d_branch2c needs backward computation.
I0528 17:10:14.899768 10644 net.cpp:226] bn4d_branch2c needs backward computation.
I0528 17:10:14.899772 10644 net.cpp:226] res4d_branch2c needs backward computation.
I0528 17:10:14.899777 10644 net.cpp:226] res4d_branch2b_relu needs backward computation.
I0528 17:10:14.899781 10644 net.cpp:226] scale4d_branch2b needs backward computation.
I0528 17:10:14.899786 10644 net.cpp:226] bn4d_branch2b needs backward computation.
I0528 17:10:14.899791 10644 net.cpp:226] res4d_branch2b needs backward computation.
I0528 17:10:14.899796 10644 net.cpp:226] res4d_branch2a_relu needs backward computation.
I0528 17:10:14.899801 10644 net.cpp:226] scale4d_branch2a needs backward computation.
I0528 17:10:14.899806 10644 net.cpp:226] bn4d_branch2a needs backward computation.
I0528 17:10:14.899809 10644 net.cpp:226] res4d_branch2a needs backward computation.
I0528 17:10:14.899814 10644 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I0528 17:10:14.899821 10644 net.cpp:226] res4c_relu needs backward computation.
I0528 17:10:14.899824 10644 net.cpp:226] res4c needs backward computation.
I0528 17:10:14.899832 10644 net.cpp:226] scale4c_branch2c needs backward computation.
I0528 17:10:14.899837 10644 net.cpp:226] bn4c_branch2c needs backward computation.
I0528 17:10:14.899842 10644 net.cpp:226] res4c_branch2c needs backward computation.
I0528 17:10:14.899847 10644 net.cpp:226] res4c_branch2b_relu needs backward computation.
I0528 17:10:14.899850 10644 net.cpp:226] scale4c_branch2b needs backward computation.
I0528 17:10:14.899854 10644 net.cpp:226] bn4c_branch2b needs backward computation.
I0528 17:10:14.899859 10644 net.cpp:226] res4c_branch2b needs backward computation.
I0528 17:10:14.899864 10644 net.cpp:226] res4c_branch2a_relu needs backward computation.
I0528 17:10:14.899868 10644 net.cpp:226] scale4c_branch2a needs backward computation.
I0528 17:10:14.899873 10644 net.cpp:226] bn4c_branch2a needs backward computation.
I0528 17:10:14.899878 10644 net.cpp:226] res4c_branch2a needs backward computation.
I0528 17:10:14.899883 10644 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I0528 17:10:14.899888 10644 net.cpp:226] res4b_relu needs backward computation.
I0528 17:10:14.899893 10644 net.cpp:226] res4b needs backward computation.
I0528 17:10:14.899899 10644 net.cpp:226] scale4b_branch2c needs backward computation.
I0528 17:10:14.899904 10644 net.cpp:226] bn4b_branch2c needs backward computation.
I0528 17:10:14.899909 10644 net.cpp:226] res4b_branch2c needs backward computation.
I0528 17:10:14.899914 10644 net.cpp:226] res4b_branch2b_relu needs backward computation.
I0528 17:10:14.899919 10644 net.cpp:226] scale4b_branch2b needs backward computation.
I0528 17:10:14.899924 10644 net.cpp:226] bn4b_branch2b needs backward computation.
I0528 17:10:14.899929 10644 net.cpp:226] res4b_branch2b needs backward computation.
I0528 17:10:14.899933 10644 net.cpp:226] res4b_branch2a_relu needs backward computation.
I0528 17:10:14.899938 10644 net.cpp:226] scale4b_branch2a needs backward computation.
I0528 17:10:14.899943 10644 net.cpp:226] bn4b_branch2a needs backward computation.
I0528 17:10:14.899948 10644 net.cpp:226] res4b_branch2a needs backward computation.
I0528 17:10:14.899952 10644 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I0528 17:10:14.899958 10644 net.cpp:226] res4a_relu needs backward computation.
I0528 17:10:14.899963 10644 net.cpp:226] res4a needs backward computation.
I0528 17:10:14.899969 10644 net.cpp:226] scale4a_branch2c needs backward computation.
I0528 17:10:14.899974 10644 net.cpp:226] bn4a_branch2c needs backward computation.
I0528 17:10:14.899978 10644 net.cpp:226] res4a_branch2c needs backward computation.
I0528 17:10:14.899984 10644 net.cpp:226] res4a_branch2b_relu needs backward computation.
I0528 17:10:14.899989 10644 net.cpp:226] scale4a_branch2b needs backward computation.
I0528 17:10:14.899993 10644 net.cpp:226] bn4a_branch2b needs backward computation.
I0528 17:10:14.899998 10644 net.cpp:226] res4a_branch2b needs backward computation.
I0528 17:10:14.900004 10644 net.cpp:226] res4a_branch2a_relu needs backward computation.
I0528 17:10:14.900008 10644 net.cpp:226] scale4a_branch2a needs backward computation.
I0528 17:10:14.900013 10644 net.cpp:226] bn4a_branch2a needs backward computation.
I0528 17:10:14.900018 10644 net.cpp:226] res4a_branch2a needs backward computation.
I0528 17:10:14.900024 10644 net.cpp:226] scale4a_branch1 needs backward computation.
I0528 17:10:14.900029 10644 net.cpp:226] bn4a_branch1 needs backward computation.
I0528 17:10:14.900033 10644 net.cpp:226] res4a_branch1 needs backward computation.
I0528 17:10:14.900039 10644 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I0528 17:10:14.900045 10644 net.cpp:226] res3d_relu needs backward computation.
I0528 17:10:14.900049 10644 net.cpp:226] res3d needs backward computation.
I0528 17:10:14.900056 10644 net.cpp:226] scale3d_branch2c needs backward computation.
I0528 17:10:14.900061 10644 net.cpp:226] bn3d_branch2c needs backward computation.
I0528 17:10:14.900066 10644 net.cpp:226] res3d_branch2c needs backward computation.
I0528 17:10:14.900071 10644 net.cpp:226] res3d_branch2b_relu needs backward computation.
I0528 17:10:14.900076 10644 net.cpp:226] scale3d_branch2b needs backward computation.
I0528 17:10:14.900081 10644 net.cpp:226] bn3d_branch2b needs backward computation.
I0528 17:10:14.900086 10644 net.cpp:226] res3d_branch2b needs backward computation.
I0528 17:10:14.900091 10644 net.cpp:226] res3d_branch2a_relu needs backward computation.
I0528 17:10:14.900096 10644 net.cpp:226] scale3d_branch2a needs backward computation.
I0528 17:10:14.900101 10644 net.cpp:226] bn3d_branch2a needs backward computation.
I0528 17:10:14.900106 10644 net.cpp:226] res3d_branch2a needs backward computation.
I0528 17:10:14.900111 10644 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I0528 17:10:14.900117 10644 net.cpp:226] res3c_relu needs backward computation.
I0528 17:10:14.900121 10644 net.cpp:226] res3c needs backward computation.
I0528 17:10:14.900128 10644 net.cpp:226] scale3c_branch2c needs backward computation.
I0528 17:10:14.900133 10644 net.cpp:226] bn3c_branch2c needs backward computation.
I0528 17:10:14.900137 10644 net.cpp:226] res3c_branch2c needs backward computation.
I0528 17:10:14.900143 10644 net.cpp:226] res3c_branch2b_relu needs backward computation.
I0528 17:10:14.900148 10644 net.cpp:226] scale3c_branch2b needs backward computation.
I0528 17:10:14.900153 10644 net.cpp:226] bn3c_branch2b needs backward computation.
I0528 17:10:14.900157 10644 net.cpp:226] res3c_branch2b needs backward computation.
I0528 17:10:14.900162 10644 net.cpp:226] res3c_branch2a_relu needs backward computation.
I0528 17:10:14.900168 10644 net.cpp:226] scale3c_branch2a needs backward computation.
I0528 17:10:14.900173 10644 net.cpp:226] bn3c_branch2a needs backward computation.
I0528 17:10:14.900178 10644 net.cpp:226] res3c_branch2a needs backward computation.
I0528 17:10:14.900183 10644 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I0528 17:10:14.900189 10644 net.cpp:226] res3b_relu needs backward computation.
I0528 17:10:14.900193 10644 net.cpp:226] res3b needs backward computation.
I0528 17:10:14.900200 10644 net.cpp:226] scale3b_branch2c needs backward computation.
I0528 17:10:14.900205 10644 net.cpp:226] bn3b_branch2c needs backward computation.
I0528 17:10:14.900210 10644 net.cpp:226] res3b_branch2c needs backward computation.
I0528 17:10:14.900215 10644 net.cpp:226] res3b_branch2b_relu needs backward computation.
I0528 17:10:14.900220 10644 net.cpp:226] scale3b_branch2b needs backward computation.
I0528 17:10:14.900224 10644 net.cpp:226] bn3b_branch2b needs backward computation.
I0528 17:10:14.900229 10644 net.cpp:226] res3b_branch2b needs backward computation.
I0528 17:10:14.900234 10644 net.cpp:226] res3b_branch2a_relu needs backward computation.
I0528 17:10:14.900239 10644 net.cpp:226] scale3b_branch2a needs backward computation.
I0528 17:10:14.900244 10644 net.cpp:226] bn3b_branch2a needs backward computation.
I0528 17:10:14.900249 10644 net.cpp:226] res3b_branch2a needs backward computation.
I0528 17:10:14.900254 10644 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I0528 17:10:14.900259 10644 net.cpp:226] res3a_relu needs backward computation.
I0528 17:10:14.900262 10644 net.cpp:226] res3a needs backward computation.
I0528 17:10:14.900269 10644 net.cpp:226] scale3a_branch2c needs backward computation.
I0528 17:10:14.900272 10644 net.cpp:226] bn3a_branch2c needs backward computation.
I0528 17:10:14.900276 10644 net.cpp:226] res3a_branch2c needs backward computation.
I0528 17:10:14.900281 10644 net.cpp:226] res3a_branch2b_relu needs backward computation.
I0528 17:10:14.900285 10644 net.cpp:226] scale3a_branch2b needs backward computation.
I0528 17:10:14.900290 10644 net.cpp:226] bn3a_branch2b needs backward computation.
I0528 17:10:14.900293 10644 net.cpp:226] res3a_branch2b needs backward computation.
I0528 17:10:14.900298 10644 net.cpp:226] res3a_branch2a_relu needs backward computation.
I0528 17:10:14.900302 10644 net.cpp:226] scale3a_branch2a needs backward computation.
I0528 17:10:14.900306 10644 net.cpp:226] bn3a_branch2a needs backward computation.
I0528 17:10:14.900310 10644 net.cpp:226] res3a_branch2a needs backward computation.
I0528 17:10:14.900316 10644 net.cpp:226] scale3a_branch1 needs backward computation.
I0528 17:10:14.900321 10644 net.cpp:226] bn3a_branch1 needs backward computation.
I0528 17:10:14.900324 10644 net.cpp:226] res3a_branch1 needs backward computation.
I0528 17:10:14.900332 10644 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0528 17:10:14.900337 10644 net.cpp:228] res2c_relu does not need backward computation.
I0528 17:10:14.900341 10644 net.cpp:228] res2c does not need backward computation.
I0528 17:10:14.900348 10644 net.cpp:228] scale2c_branch2c does not need backward computation.
I0528 17:10:14.900353 10644 net.cpp:228] bn2c_branch2c does not need backward computation.
I0528 17:10:14.900357 10644 net.cpp:228] res2c_branch2c does not need backward computation.
I0528 17:10:14.900362 10644 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0528 17:10:14.900367 10644 net.cpp:228] scale2c_branch2b does not need backward computation.
I0528 17:10:14.900372 10644 net.cpp:228] bn2c_branch2b does not need backward computation.
I0528 17:10:14.900377 10644 net.cpp:228] res2c_branch2b does not need backward computation.
I0528 17:10:14.900383 10644 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0528 17:10:14.900388 10644 net.cpp:228] scale2c_branch2a does not need backward computation.
I0528 17:10:14.900393 10644 net.cpp:228] bn2c_branch2a does not need backward computation.
I0528 17:10:14.900396 10644 net.cpp:228] res2c_branch2a does not need backward computation.
I0528 17:10:14.900403 10644 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0528 17:10:14.900408 10644 net.cpp:228] res2b_relu does not need backward computation.
I0528 17:10:14.900413 10644 net.cpp:228] res2b does not need backward computation.
I0528 17:10:14.900420 10644 net.cpp:228] scale2b_branch2c does not need backward computation.
I0528 17:10:14.900425 10644 net.cpp:228] bn2b_branch2c does not need backward computation.
I0528 17:10:14.900430 10644 net.cpp:228] res2b_branch2c does not need backward computation.
I0528 17:10:14.900436 10644 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0528 17:10:14.900441 10644 net.cpp:228] scale2b_branch2b does not need backward computation.
I0528 17:10:14.900446 10644 net.cpp:228] bn2b_branch2b does not need backward computation.
I0528 17:10:14.900450 10644 net.cpp:228] res2b_branch2b does not need backward computation.
I0528 17:10:14.900456 10644 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0528 17:10:14.900460 10644 net.cpp:228] scale2b_branch2a does not need backward computation.
I0528 17:10:14.900465 10644 net.cpp:228] bn2b_branch2a does not need backward computation.
I0528 17:10:14.900470 10644 net.cpp:228] res2b_branch2a does not need backward computation.
I0528 17:10:14.900477 10644 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0528 17:10:14.900483 10644 net.cpp:228] res2a_relu does not need backward computation.
I0528 17:10:14.900487 10644 net.cpp:228] res2a does not need backward computation.
I0528 17:10:14.900494 10644 net.cpp:228] scale2a_branch2c does not need backward computation.
I0528 17:10:14.900499 10644 net.cpp:228] bn2a_branch2c does not need backward computation.
I0528 17:10:14.900504 10644 net.cpp:228] res2a_branch2c does not need backward computation.
I0528 17:10:14.900511 10644 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0528 17:10:14.900516 10644 net.cpp:228] scale2a_branch2b does not need backward computation.
I0528 17:10:14.900521 10644 net.cpp:228] bn2a_branch2b does not need backward computation.
I0528 17:10:14.900526 10644 net.cpp:228] res2a_branch2b does not need backward computation.
I0528 17:10:14.900530 10644 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0528 17:10:14.900535 10644 net.cpp:228] scale2a_branch2a does not need backward computation.
I0528 17:10:14.900540 10644 net.cpp:228] bn2a_branch2a does not need backward computation.
I0528 17:10:14.900544 10644 net.cpp:228] res2a_branch2a does not need backward computation.
I0528 17:10:14.900552 10644 net.cpp:228] scale2a_branch1 does not need backward computation.
I0528 17:10:14.900555 10644 net.cpp:228] bn2a_branch1 does not need backward computation.
I0528 17:10:14.900560 10644 net.cpp:228] res2a_branch1 does not need backward computation.
I0528 17:10:14.900568 10644 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0528 17:10:14.900573 10644 net.cpp:228] pool1 does not need backward computation.
I0528 17:10:14.900578 10644 net.cpp:228] conv1_relu does not need backward computation.
I0528 17:10:14.900583 10644 net.cpp:228] scale_conv1 does not need backward computation.
I0528 17:10:14.900588 10644 net.cpp:228] bn_conv1 does not need backward computation.
I0528 17:10:14.900591 10644 net.cpp:228] conv1 does not need backward computation.
I0528 17:10:14.900599 10644 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0528 17:10:14.900606 10644 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0528 17:10:14.900612 10644 net.cpp:228] data_input-data_0_split does not need backward computation.
I0528 17:10:14.900619 10644 net.cpp:228] input-data does not need backward computation.
I0528 17:10:14.900620 10644 net.cpp:270] This network produces output accuarcy
I0528 17:10:14.900626 10644 net.cpp:270] This network produces output loss_bbox
I0528 17:10:14.900630 10644 net.cpp:270] This network produces output loss_cls
I0528 17:10:14.900633 10644 net.cpp:270] This network produces output rpn_cls_loss
I0528 17:10:14.900636 10644 net.cpp:270] This network produces output rpn_loss_bbox
I0528 17:10:14.901015 10644 net.cpp:283] Network initialization done.
I0528 17:10:14.901535 10644 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I0528 17:10:15.425040 10644 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I0528 17:10:15.425058 10644 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0528 17:10:15.425061 10644 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0528 17:10:15.425066 10644 net.cpp:774] Copying source layer conv1
I0528 17:10:15.425200 10644 net.cpp:774] Copying source layer bn_conv1
I0528 17:10:15.425211 10644 net.cpp:774] Copying source layer scale_conv1
I0528 17:10:15.425220 10644 net.cpp:774] Copying source layer conv1_relu
I0528 17:10:15.425223 10644 net.cpp:774] Copying source layer pool1
I0528 17:10:15.425226 10644 net.cpp:774] Copying source layer pool1_pool1_0_split
I0528 17:10:15.425230 10644 net.cpp:774] Copying source layer res2a_branch1
I0528 17:10:15.425346 10644 net.cpp:774] Copying source layer bn2a_branch1
I0528 17:10:15.425359 10644 net.cpp:774] Copying source layer scale2a_branch1
I0528 17:10:15.425369 10644 net.cpp:774] Copying source layer res2a_branch2a
I0528 17:10:15.425405 10644 net.cpp:774] Copying source layer bn2a_branch2a
I0528 17:10:15.425413 10644 net.cpp:774] Copying source layer scale2a_branch2a
I0528 17:10:15.425421 10644 net.cpp:774] Copying source layer res2a_branch2a_relu
I0528 17:10:15.425424 10644 net.cpp:774] Copying source layer res2a_branch2b
I0528 17:10:15.425680 10644 net.cpp:774] Copying source layer bn2a_branch2b
I0528 17:10:15.425690 10644 net.cpp:774] Copying source layer scale2a_branch2b
I0528 17:10:15.425698 10644 net.cpp:774] Copying source layer res2a_branch2b_relu
I0528 17:10:15.425701 10644 net.cpp:774] Copying source layer res2a_branch2c
I0528 17:10:15.425817 10644 net.cpp:774] Copying source layer bn2a_branch2c
I0528 17:10:15.425829 10644 net.cpp:774] Copying source layer scale2a_branch2c
I0528 17:10:15.425839 10644 net.cpp:774] Copying source layer res2a
I0528 17:10:15.425843 10644 net.cpp:774] Copying source layer res2a_relu
I0528 17:10:15.425846 10644 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0528 17:10:15.425849 10644 net.cpp:774] Copying source layer res2b_branch2a
I0528 17:10:15.425968 10644 net.cpp:774] Copying source layer bn2b_branch2a
I0528 17:10:15.425978 10644 net.cpp:774] Copying source layer scale2b_branch2a
I0528 17:10:15.425987 10644 net.cpp:774] Copying source layer res2b_branch2a_relu
I0528 17:10:15.425990 10644 net.cpp:774] Copying source layer res2b_branch2b
I0528 17:10:15.426245 10644 net.cpp:774] Copying source layer bn2b_branch2b
I0528 17:10:15.426255 10644 net.cpp:774] Copying source layer scale2b_branch2b
I0528 17:10:15.426265 10644 net.cpp:774] Copying source layer res2b_branch2b_relu
I0528 17:10:15.426267 10644 net.cpp:774] Copying source layer res2b_branch2c
I0528 17:10:15.426384 10644 net.cpp:774] Copying source layer bn2b_branch2c
I0528 17:10:15.426398 10644 net.cpp:774] Copying source layer scale2b_branch2c
I0528 17:10:15.426409 10644 net.cpp:774] Copying source layer res2b
I0528 17:10:15.426411 10644 net.cpp:774] Copying source layer res2b_relu
I0528 17:10:15.426415 10644 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0528 17:10:15.426419 10644 net.cpp:774] Copying source layer res2c_branch2a
I0528 17:10:15.426535 10644 net.cpp:774] Copying source layer bn2c_branch2a
I0528 17:10:15.426544 10644 net.cpp:774] Copying source layer scale2c_branch2a
I0528 17:10:15.426553 10644 net.cpp:774] Copying source layer res2c_branch2a_relu
I0528 17:10:15.426556 10644 net.cpp:774] Copying source layer res2c_branch2b
I0528 17:10:15.426813 10644 net.cpp:774] Copying source layer bn2c_branch2b
I0528 17:10:15.426822 10644 net.cpp:774] Copying source layer scale2c_branch2b
I0528 17:10:15.426831 10644 net.cpp:774] Copying source layer res2c_branch2b_relu
I0528 17:10:15.426836 10644 net.cpp:774] Copying source layer res2c_branch2c
I0528 17:10:15.426952 10644 net.cpp:774] Copying source layer bn2c_branch2c
I0528 17:10:15.426964 10644 net.cpp:774] Copying source layer scale2c_branch2c
I0528 17:10:15.426976 10644 net.cpp:774] Copying source layer res2c
I0528 17:10:15.426981 10644 net.cpp:774] Copying source layer res2c_relu
I0528 17:10:15.426985 10644 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0528 17:10:15.426990 10644 net.cpp:774] Copying source layer res3a_branch1
I0528 17:10:15.427882 10644 net.cpp:774] Copying source layer bn3a_branch1
I0528 17:10:15.427899 10644 net.cpp:774] Copying source layer scale3a_branch1
I0528 17:10:15.427913 10644 net.cpp:774] Copying source layer res3a_branch2a
I0528 17:10:15.428143 10644 net.cpp:774] Copying source layer bn3a_branch2a
I0528 17:10:15.428153 10644 net.cpp:774] Copying source layer scale3a_branch2a
I0528 17:10:15.428162 10644 net.cpp:774] Copying source layer res3a_branch2a_relu
I0528 17:10:15.428166 10644 net.cpp:774] Copying source layer res3a_branch2b
I0528 17:10:15.429185 10644 net.cpp:774] Copying source layer bn3a_branch2b
I0528 17:10:15.429199 10644 net.cpp:774] Copying source layer scale3a_branch2b
I0528 17:10:15.429209 10644 net.cpp:774] Copying source layer res3a_branch2b_relu
I0528 17:10:15.429214 10644 net.cpp:774] Copying source layer res3a_branch2c
I0528 17:10:15.429664 10644 net.cpp:774] Copying source layer bn3a_branch2c
I0528 17:10:15.429683 10644 net.cpp:774] Copying source layer scale3a_branch2c
I0528 17:10:15.429698 10644 net.cpp:774] Copying source layer res3a
I0528 17:10:15.429703 10644 net.cpp:774] Copying source layer res3a_relu
I0528 17:10:15.429708 10644 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0528 17:10:15.429711 10644 net.cpp:774] Copying source layer res3b_branch2a
I0528 17:10:15.430162 10644 net.cpp:774] Copying source layer bn3b_branch2a
I0528 17:10:15.430174 10644 net.cpp:774] Copying source layer scale3b_branch2a
I0528 17:10:15.430184 10644 net.cpp:774] Copying source layer res3b_branch2a_relu
I0528 17:10:15.430189 10644 net.cpp:774] Copying source layer res3b_branch2b
I0528 17:10:15.431193 10644 net.cpp:774] Copying source layer bn3b_branch2b
I0528 17:10:15.431206 10644 net.cpp:774] Copying source layer scale3b_branch2b
I0528 17:10:15.431216 10644 net.cpp:774] Copying source layer res3b_branch2b_relu
I0528 17:10:15.431221 10644 net.cpp:774] Copying source layer res3b_branch2c
I0528 17:10:15.431673 10644 net.cpp:774] Copying source layer bn3b_branch2c
I0528 17:10:15.431689 10644 net.cpp:774] Copying source layer scale3b_branch2c
I0528 17:10:15.431705 10644 net.cpp:774] Copying source layer res3b
I0528 17:10:15.431710 10644 net.cpp:774] Copying source layer res3b_relu
I0528 17:10:15.431715 10644 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0528 17:10:15.431718 10644 net.cpp:774] Copying source layer res3c_branch2a
I0528 17:10:15.432175 10644 net.cpp:774] Copying source layer bn3c_branch2a
I0528 17:10:15.432188 10644 net.cpp:774] Copying source layer scale3c_branch2a
I0528 17:10:15.432199 10644 net.cpp:774] Copying source layer res3c_branch2a_relu
I0528 17:10:15.432204 10644 net.cpp:774] Copying source layer res3c_branch2b
I0528 17:10:15.433212 10644 net.cpp:774] Copying source layer bn3c_branch2b
I0528 17:10:15.433225 10644 net.cpp:774] Copying source layer scale3c_branch2b
I0528 17:10:15.433236 10644 net.cpp:774] Copying source layer res3c_branch2b_relu
I0528 17:10:15.433241 10644 net.cpp:774] Copying source layer res3c_branch2c
I0528 17:10:15.433692 10644 net.cpp:774] Copying source layer bn3c_branch2c
I0528 17:10:15.433709 10644 net.cpp:774] Copying source layer scale3c_branch2c
I0528 17:10:15.433725 10644 net.cpp:774] Copying source layer res3c
I0528 17:10:15.433730 10644 net.cpp:774] Copying source layer res3c_relu
I0528 17:10:15.433737 10644 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0528 17:10:15.433742 10644 net.cpp:774] Copying source layer res3d_branch2a
I0528 17:10:15.434193 10644 net.cpp:774] Copying source layer bn3d_branch2a
I0528 17:10:15.434206 10644 net.cpp:774] Copying source layer scale3d_branch2a
I0528 17:10:15.434217 10644 net.cpp:774] Copying source layer res3d_branch2a_relu
I0528 17:10:15.434222 10644 net.cpp:774] Copying source layer res3d_branch2b
I0528 17:10:15.435228 10644 net.cpp:774] Copying source layer bn3d_branch2b
I0528 17:10:15.435241 10644 net.cpp:774] Copying source layer scale3d_branch2b
I0528 17:10:15.435252 10644 net.cpp:774] Copying source layer res3d_branch2b_relu
I0528 17:10:15.435257 10644 net.cpp:774] Copying source layer res3d_branch2c
I0528 17:10:15.435709 10644 net.cpp:774] Copying source layer bn3d_branch2c
I0528 17:10:15.435727 10644 net.cpp:774] Copying source layer scale3d_branch2c
I0528 17:10:15.435742 10644 net.cpp:774] Copying source layer res3d
I0528 17:10:15.435747 10644 net.cpp:774] Copying source layer res3d_relu
I0528 17:10:15.435753 10644 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0528 17:10:15.435760 10644 net.cpp:774] Copying source layer res4a_branch1
I0528 17:10:15.439362 10644 net.cpp:774] Copying source layer bn4a_branch1
I0528 17:10:15.439404 10644 net.cpp:774] Copying source layer scale4a_branch1
I0528 17:10:15.439429 10644 net.cpp:774] Copying source layer res4a_branch2a
I0528 17:10:15.440323 10644 net.cpp:774] Copying source layer bn4a_branch2a
I0528 17:10:15.440340 10644 net.cpp:774] Copying source layer scale4a_branch2a
I0528 17:10:15.440354 10644 net.cpp:774] Copying source layer res4a_branch2a_relu
I0528 17:10:15.440359 10644 net.cpp:774] Copying source layer res4a_branch2b
I0528 17:10:15.444538 10644 net.cpp:774] Copying source layer bn4a_branch2b
I0528 17:10:15.444558 10644 net.cpp:774] Copying source layer scale4a_branch2b
I0528 17:10:15.444572 10644 net.cpp:774] Copying source layer res4a_branch2b_relu
I0528 17:10:15.444578 10644 net.cpp:774] Copying source layer res4a_branch2c
I0528 17:10:15.447124 10644 net.cpp:774] Copying source layer bn4a_branch2c
I0528 17:10:15.447154 10644 net.cpp:774] Copying source layer scale4a_branch2c
I0528 17:10:15.447177 10644 net.cpp:774] Copying source layer res4a
I0528 17:10:15.447182 10644 net.cpp:774] Copying source layer res4a_relu
I0528 17:10:15.447190 10644 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0528 17:10:15.447194 10644 net.cpp:774] Copying source layer res4b_branch2a
I0528 17:10:15.448992 10644 net.cpp:774] Copying source layer bn4b_branch2a
I0528 17:10:15.449010 10644 net.cpp:774] Copying source layer scale4b_branch2a
I0528 17:10:15.449024 10644 net.cpp:774] Copying source layer res4b_branch2a_relu
I0528 17:10:15.449030 10644 net.cpp:774] Copying source layer res4b_branch2b
I0528 17:10:15.453094 10644 net.cpp:774] Copying source layer bn4b_branch2b
I0528 17:10:15.453125 10644 net.cpp:774] Copying source layer scale4b_branch2b
I0528 17:10:15.453143 10644 net.cpp:774] Copying source layer res4b_branch2b_relu
I0528 17:10:15.453150 10644 net.cpp:774] Copying source layer res4b_branch2c
I0528 17:10:15.454936 10644 net.cpp:774] Copying source layer bn4b_branch2c
I0528 17:10:15.454962 10644 net.cpp:774] Copying source layer scale4b_branch2c
I0528 17:10:15.454987 10644 net.cpp:774] Copying source layer res4b
I0528 17:10:15.454991 10644 net.cpp:774] Copying source layer res4b_relu
I0528 17:10:15.454998 10644 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0528 17:10:15.455003 10644 net.cpp:774] Copying source layer res4c_branch2a
I0528 17:10:15.456785 10644 net.cpp:774] Copying source layer bn4c_branch2a
I0528 17:10:15.456800 10644 net.cpp:774] Copying source layer scale4c_branch2a
I0528 17:10:15.456815 10644 net.cpp:774] Copying source layer res4c_branch2a_relu
I0528 17:10:15.456820 10644 net.cpp:774] Copying source layer res4c_branch2b
I0528 17:10:15.460825 10644 net.cpp:774] Copying source layer bn4c_branch2b
I0528 17:10:15.460852 10644 net.cpp:774] Copying source layer scale4c_branch2b
I0528 17:10:15.460868 10644 net.cpp:774] Copying source layer res4c_branch2b_relu
I0528 17:10:15.460875 10644 net.cpp:774] Copying source layer res4c_branch2c
I0528 17:10:15.462661 10644 net.cpp:774] Copying source layer bn4c_branch2c
I0528 17:10:15.462685 10644 net.cpp:774] Copying source layer scale4c_branch2c
I0528 17:10:15.462710 10644 net.cpp:774] Copying source layer res4c
I0528 17:10:15.462715 10644 net.cpp:774] Copying source layer res4c_relu
I0528 17:10:15.462723 10644 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0528 17:10:15.462728 10644 net.cpp:774] Copying source layer res4d_branch2a
I0528 17:10:15.464509 10644 net.cpp:774] Copying source layer bn4d_branch2a
I0528 17:10:15.464524 10644 net.cpp:774] Copying source layer scale4d_branch2a
I0528 17:10:15.464538 10644 net.cpp:774] Copying source layer res4d_branch2a_relu
I0528 17:10:15.464545 10644 net.cpp:774] Copying source layer res4d_branch2b
I0528 17:10:15.468559 10644 net.cpp:774] Copying source layer bn4d_branch2b
I0528 17:10:15.468575 10644 net.cpp:774] Copying source layer scale4d_branch2b
I0528 17:10:15.468588 10644 net.cpp:774] Copying source layer res4d_branch2b_relu
I0528 17:10:15.468595 10644 net.cpp:774] Copying source layer res4d_branch2c
I0528 17:10:15.470383 10644 net.cpp:774] Copying source layer bn4d_branch2c
I0528 17:10:15.470410 10644 net.cpp:774] Copying source layer scale4d_branch2c
I0528 17:10:15.470434 10644 net.cpp:774] Copying source layer res4d
I0528 17:10:15.470440 10644 net.cpp:774] Copying source layer res4d_relu
I0528 17:10:15.470448 10644 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0528 17:10:15.470453 10644 net.cpp:774] Copying source layer res4e_branch2a
I0528 17:10:15.472235 10644 net.cpp:774] Copying source layer bn4e_branch2a
I0528 17:10:15.472250 10644 net.cpp:774] Copying source layer scale4e_branch2a
I0528 17:10:15.472265 10644 net.cpp:774] Copying source layer res4e_branch2a_relu
I0528 17:10:15.472270 10644 net.cpp:774] Copying source layer res4e_branch2b
I0528 17:10:15.476277 10644 net.cpp:774] Copying source layer bn4e_branch2b
I0528 17:10:15.476297 10644 net.cpp:774] Copying source layer scale4e_branch2b
I0528 17:10:15.476310 10644 net.cpp:774] Copying source layer res4e_branch2b_relu
I0528 17:10:15.476317 10644 net.cpp:774] Copying source layer res4e_branch2c
I0528 17:10:15.478101 10644 net.cpp:774] Copying source layer bn4e_branch2c
I0528 17:10:15.478128 10644 net.cpp:774] Copying source layer scale4e_branch2c
I0528 17:10:15.478152 10644 net.cpp:774] Copying source layer res4e
I0528 17:10:15.478158 10644 net.cpp:774] Copying source layer res4e_relu
I0528 17:10:15.478166 10644 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0528 17:10:15.478173 10644 net.cpp:774] Copying source layer res4f_branch2a
I0528 17:10:15.479954 10644 net.cpp:774] Copying source layer bn4f_branch2a
I0528 17:10:15.479970 10644 net.cpp:774] Copying source layer scale4f_branch2a
I0528 17:10:15.479984 10644 net.cpp:774] Copying source layer res4f_branch2a_relu
I0528 17:10:15.479990 10644 net.cpp:774] Copying source layer res4f_branch2b
I0528 17:10:15.483990 10644 net.cpp:774] Copying source layer bn4f_branch2b
I0528 17:10:15.484009 10644 net.cpp:774] Copying source layer scale4f_branch2b
I0528 17:10:15.484022 10644 net.cpp:774] Copying source layer res4f_branch2b_relu
I0528 17:10:15.484028 10644 net.cpp:774] Copying source layer res4f_branch2c
I0528 17:10:15.485874 10644 net.cpp:774] Copying source layer bn4f_branch2c
I0528 17:10:15.485909 10644 net.cpp:774] Copying source layer scale4f_branch2c
I0528 17:10:15.485934 10644 net.cpp:774] Copying source layer res4f
I0528 17:10:15.485940 10644 net.cpp:774] Copying source layer res4f_relu
I0528 17:10:15.485949 10644 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0528 17:10:15.485955 10644 net.cpp:774] Copying source layer res5a_branch1
I0528 17:10:15.500237 10644 net.cpp:774] Copying source layer bn5a_branch1
I0528 17:10:15.500298 10644 net.cpp:774] Copying source layer scale5a_branch1
I0528 17:10:15.500339 10644 net.cpp:774] Copying source layer res5a_branch2a
I0528 17:10:15.503895 10644 net.cpp:774] Copying source layer bn5a_branch2a
I0528 17:10:15.503921 10644 net.cpp:774] Copying source layer scale5a_branch2a
I0528 17:10:15.503940 10644 net.cpp:774] Copying source layer res5a_branch2a_relu
I0528 17:10:15.503947 10644 net.cpp:774] Copying source layer res5a_branch2b
I0528 17:10:15.520514 10644 net.cpp:774] Copying source layer bn5a_branch2b
I0528 17:10:15.520561 10644 net.cpp:774] Copying source layer scale5a_branch2b
I0528 17:10:15.520583 10644 net.cpp:774] Copying source layer res5a_branch2b_relu
I0528 17:10:15.520591 10644 net.cpp:774] Copying source layer res5a_branch2c
I0528 17:10:15.527894 10644 net.cpp:774] Copying source layer bn5a_branch2c
I0528 17:10:15.527961 10644 net.cpp:774] Copying source layer scale5a_branch2c
I0528 17:10:15.528002 10644 net.cpp:774] Copying source layer res5a
I0528 17:10:15.528007 10644 net.cpp:774] Copying source layer res5a_relu
I0528 17:10:15.528017 10644 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0528 17:10:15.528023 10644 net.cpp:774] Copying source layer res5b_branch2a
I0528 17:10:15.535157 10644 net.cpp:774] Copying source layer bn5b_branch2a
I0528 17:10:15.535183 10644 net.cpp:774] Copying source layer scale5b_branch2a
I0528 17:10:15.535204 10644 net.cpp:774] Copying source layer res5b_branch2a_relu
I0528 17:10:15.535212 10644 net.cpp:774] Copying source layer res5b_branch2b
I0528 17:10:15.551301 10644 net.cpp:774] Copying source layer bn5b_branch2b
I0528 17:10:15.551340 10644 net.cpp:774] Copying source layer scale5b_branch2b
I0528 17:10:15.551364 10644 net.cpp:774] Copying source layer res5b_branch2b_relu
I0528 17:10:15.551371 10644 net.cpp:774] Copying source layer res5b_branch2c
I0528 17:10:15.558539 10644 net.cpp:774] Copying source layer bn5b_branch2c
I0528 17:10:15.558600 10644 net.cpp:774] Copying source layer scale5b_branch2c
I0528 17:10:15.558641 10644 net.cpp:774] Copying source layer res5b
I0528 17:10:15.558648 10644 net.cpp:774] Copying source layer res5b_relu
I0528 17:10:15.558656 10644 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0528 17:10:15.558663 10644 net.cpp:774] Copying source layer res5c_branch2a
I0528 17:10:15.565949 10644 net.cpp:774] Copying source layer bn5c_branch2a
I0528 17:10:15.565990 10644 net.cpp:774] Copying source layer scale5c_branch2a
I0528 17:10:15.566013 10644 net.cpp:774] Copying source layer res5c_branch2a_relu
I0528 17:10:15.566020 10644 net.cpp:774] Copying source layer res5c_branch2b
I0528 17:10:15.582474 10644 net.cpp:774] Copying source layer bn5c_branch2b
I0528 17:10:15.582512 10644 net.cpp:774] Copying source layer scale5c_branch2b
I0528 17:10:15.582537 10644 net.cpp:774] Copying source layer res5c_branch2b_relu
I0528 17:10:15.582545 10644 net.cpp:774] Copying source layer res5c_branch2c
I0528 17:10:15.589748 10644 net.cpp:774] Copying source layer bn5c_branch2c
I0528 17:10:15.589823 10644 net.cpp:774] Copying source layer scale5c_branch2c
I0528 17:10:15.589864 10644 net.cpp:774] Copying source layer res5c
I0528 17:10:15.589871 10644 net.cpp:774] Copying source layer res5c_relu
I0528 17:10:15.589880 10644 net.cpp:771] Ignoring source layer pool5
I0528 17:10:15.589887 10644 net.cpp:771] Ignoring source layer fc1000
I0528 17:10:15.589895 10644 net.cpp:771] Ignoring source layer prob
Solving...
I0528 17:10:17.931238 10644 solver.cpp:228] Iteration 0, loss = 1.45713
I0528 17:10:17.931267 10644 solver.cpp:244]     Train net output #0: accuarcy = 0
I0528 17:10:17.931277 10644 solver.cpp:244]     Train net output #1: loss_bbox = 6.89928e-05 (* 1 = 6.89928e-05 loss)
I0528 17:10:17.931283 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.702885 (* 1 = 0.702885 loss)
I0528 17:10:17.931288 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.677366 (* 1 = 0.677366 loss)
I0528 17:10:17.931293 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128022 (* 1 = 0.128022 loss)
I0528 17:10:17.931300 10644 sgd_solver.cpp:106] Iteration 0, lr = 0.0002
I0528 17:11:05.731190 10644 solver.cpp:228] Iteration 20, loss = 1.18807
I0528 17:11:05.731215 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:11:05.731222 10644 solver.cpp:244]     Train net output #1: loss_bbox = 2.23567e-05 (* 1 = 2.23567e-05 loss)
I0528 17:11:05.731226 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.681106 (* 1 = 0.681106 loss)
I0528 17:11:05.731230 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.477412 (* 1 = 0.477412 loss)
I0528 17:11:05.731233 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028096 (* 1 = 0.028096 loss)
I0528 17:11:05.731238 10644 sgd_solver.cpp:106] Iteration 20, lr = 0.0002
I0528 17:11:53.782070 10644 solver.cpp:228] Iteration 40, loss = 0.946772
I0528 17:11:53.782095 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:11:53.782102 10644 solver.cpp:244]     Train net output #1: loss_bbox = 1.06677e-05 (* 1 = 1.06677e-05 loss)
I0528 17:11:53.782106 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.651759 (* 1 = 0.651759 loss)
I0528 17:11:53.782109 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.265685 (* 1 = 0.265685 loss)
I0528 17:11:53.782114 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205911 (* 1 = 0.0205911 loss)
I0528 17:11:53.782119 10644 sgd_solver.cpp:106] Iteration 40, lr = 0.0002
I0528 17:12:41.803778 10644 solver.cpp:228] Iteration 60, loss = 0.864826
I0528 17:12:41.803804 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:12:41.803812 10644 solver.cpp:244]     Train net output #1: loss_bbox = 2.02998e-05 (* 1 = 2.02998e-05 loss)
I0528 17:12:41.803815 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.611434 (* 1 = 0.611434 loss)
I0528 17:12:41.803819 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.15298 (* 1 = 0.15298 loss)
I0528 17:12:41.803822 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240041 (* 1 = 0.0240041 loss)
I0528 17:12:41.803827 10644 sgd_solver.cpp:106] Iteration 60, lr = 0.0002
I0528 17:13:29.962965 10644 solver.cpp:228] Iteration 80, loss = 0.91974
I0528 17:13:29.962990 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:13:29.962998 10644 solver.cpp:244]     Train net output #1: loss_bbox = 3.22894e-05 (* 1 = 3.22894e-05 loss)
I0528 17:13:29.963004 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.573413 (* 1 = 0.573413 loss)
I0528 17:13:29.963008 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.101728 (* 1 = 0.101728 loss)
I0528 17:13:29.963013 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291632 (* 1 = 0.0291632 loss)
I0528 17:13:29.963021 10644 sgd_solver.cpp:106] Iteration 80, lr = 0.0002
I0528 17:14:18.218633 10644 solver.cpp:228] Iteration 100, loss = 0.622675
I0528 17:14:18.218657 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:14:18.218664 10644 solver.cpp:244]     Train net output #1: loss_bbox = 4.45981e-06 (* 1 = 4.45981e-06 loss)
I0528 17:14:18.218668 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.478858 (* 1 = 0.478858 loss)
I0528 17:14:18.218672 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0614105 (* 1 = 0.0614105 loss)
I0528 17:14:18.218674 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224618 (* 1 = 0.0224618 loss)
I0528 17:14:18.218679 10644 sgd_solver.cpp:106] Iteration 100, lr = 0.0002
I0528 17:15:06.435818 10644 solver.cpp:228] Iteration 120, loss = 0.380084
I0528 17:15:06.435843 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:15:06.435850 10644 solver.cpp:244]     Train net output #1: loss_bbox = 5.50965e-05 (* 1 = 5.50965e-05 loss)
I0528 17:15:06.435854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.26448 (* 1 = 0.26448 loss)
I0528 17:15:06.435858 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0417663 (* 1 = 0.0417663 loss)
I0528 17:15:06.435860 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00839672 (* 1 = 0.00839672 loss)
I0528 17:15:06.435864 10644 sgd_solver.cpp:106] Iteration 120, lr = 0.0002
I0528 17:15:54.537696 10644 solver.cpp:228] Iteration 140, loss = 0.552746
I0528 17:15:54.537724 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 17:15:54.537731 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0848609 (* 1 = 0.0848609 loss)
I0528 17:15:54.537734 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.172458 (* 1 = 0.172458 loss)
I0528 17:15:54.537739 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.209142 (* 1 = 0.209142 loss)
I0528 17:15:54.537741 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.070821 (* 1 = 0.070821 loss)
I0528 17:15:54.537746 10644 sgd_solver.cpp:106] Iteration 140, lr = 0.0002
/home/user/Disk1.8T/py-R-FCN/tools/../lib/fast_rcnn/bbox_transform.py:23: RuntimeWarning: invalid value encountered in log
  targets_dw = np.log(gt_widths / ex_widths)
I0528 17:16:42.729380 10644 solver.cpp:228] Iteration 160, loss = 0.184179
I0528 17:16:42.729413 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:16:42.729420 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000149231 (* 1 = 0.000149231 loss)
I0528 17:16:42.729424 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0507591 (* 1 = 0.0507591 loss)
I0528 17:16:42.729427 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342211 (* 1 = 0.0342211 loss)
I0528 17:16:42.729431 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195738 (* 1 = 0.0195738 loss)
I0528 17:16:42.729436 10644 sgd_solver.cpp:106] Iteration 160, lr = 0.0002
I0528 17:17:31.062038 10644 solver.cpp:228] Iteration 180, loss = 0.209734
I0528 17:17:31.062063 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:17:31.062070 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000109815 (* 1 = 0.000109815 loss)
I0528 17:17:31.062074 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.099593 (* 1 = 0.099593 loss)
I0528 17:17:31.062078 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0895821 (* 1 = 0.0895821 loss)
I0528 17:17:31.062081 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0885662 (* 1 = 0.0885662 loss)
I0528 17:17:31.062086 10644 sgd_solver.cpp:106] Iteration 180, lr = 0.0002
speed: 2.408s / iter
I0528 17:18:19.594123 10644 solver.cpp:228] Iteration 200, loss = 0.200712
I0528 17:18:19.594152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:18:19.594164 10644 solver.cpp:244]     Train net output #1: loss_bbox = 2.66776e-05 (* 1 = 2.66776e-05 loss)
I0528 17:18:19.594174 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0606189 (* 1 = 0.0606189 loss)
I0528 17:18:19.594182 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0452834 (* 1 = 0.0452834 loss)
I0528 17:18:19.594189 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181689 (* 1 = 0.0181689 loss)
I0528 17:18:19.594197 10644 sgd_solver.cpp:106] Iteration 200, lr = 0.0002
I0528 17:19:08.247373 10644 solver.cpp:228] Iteration 220, loss = 0.213484
I0528 17:19:08.247398 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:19:08.247407 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000107565 (* 1 = 0.000107565 loss)
I0528 17:19:08.247413 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0726516 (* 1 = 0.0726516 loss)
I0528 17:19:08.247419 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0722905 (* 1 = 0.0722905 loss)
I0528 17:19:08.247424 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0780557 (* 1 = 0.0780557 loss)
I0528 17:19:08.247431 10644 sgd_solver.cpp:106] Iteration 220, lr = 0.0002
I0528 17:19:56.925884 10644 solver.cpp:228] Iteration 240, loss = 0.152036
I0528 17:19:56.925910 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:19:56.925920 10644 solver.cpp:244]     Train net output #1: loss_bbox = 7.0369e-06 (* 1 = 7.0369e-06 loss)
I0528 17:19:56.925927 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0280758 (* 1 = 0.0280758 loss)
I0528 17:19:56.925933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251282 (* 1 = 0.0251282 loss)
I0528 17:19:56.925940 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00620867 (* 1 = 0.00620867 loss)
I0528 17:19:56.925946 10644 sgd_solver.cpp:106] Iteration 240, lr = 0.0002
I0528 17:20:45.540112 10644 solver.cpp:228] Iteration 260, loss = 0.644866
I0528 17:20:45.540143 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:20:45.540150 10644 solver.cpp:244]     Train net output #1: loss_bbox = 9.65806e-05 (* 1 = 9.65806e-05 loss)
I0528 17:20:45.540155 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0935071 (* 1 = 0.0935071 loss)
I0528 17:20:45.540158 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0599559 (* 1 = 0.0599559 loss)
I0528 17:20:45.540163 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445126 (* 1 = 0.0445126 loss)
I0528 17:20:45.540169 10644 sgd_solver.cpp:106] Iteration 260, lr = 0.0002
I0528 17:21:34.125336 10644 solver.cpp:228] Iteration 280, loss = 0.350357
I0528 17:21:34.125363 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 17:21:34.125373 10644 solver.cpp:244]     Train net output #1: loss_bbox = 3.02207e-05 (* 1 = 3.02207e-05 loss)
I0528 17:21:34.125380 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.107493 (* 1 = 0.107493 loss)
I0528 17:21:34.125385 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103017 (* 1 = 0.103017 loss)
I0528 17:21:34.125389 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13168 (* 1 = 0.13168 loss)
I0528 17:21:34.125396 10644 sgd_solver.cpp:106] Iteration 280, lr = 0.0002
I0528 17:22:22.855289 10644 solver.cpp:228] Iteration 300, loss = 0.189403
I0528 17:22:22.855314 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:22:22.855319 10644 solver.cpp:244]     Train net output #1: loss_bbox = 5.63395e-06 (* 1 = 5.63395e-06 loss)
I0528 17:22:22.855324 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0487987 (* 1 = 0.0487987 loss)
I0528 17:22:22.855327 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0398385 (* 1 = 0.0398385 loss)
I0528 17:22:22.855330 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274904 (* 1 = 0.0274904 loss)
I0528 17:22:22.855335 10644 sgd_solver.cpp:106] Iteration 300, lr = 0.0002
I0528 17:23:11.433244 10644 solver.cpp:228] Iteration 320, loss = 0.680258
I0528 17:23:11.433272 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 17:23:11.433281 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.333221 (* 1 = 0.333221 loss)
I0528 17:23:11.433288 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.620739 (* 1 = 0.620739 loss)
I0528 17:23:11.433293 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.419309 (* 1 = 0.419309 loss)
I0528 17:23:11.433300 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.340391 (* 1 = 0.340391 loss)
I0528 17:23:11.433306 10644 sgd_solver.cpp:106] Iteration 320, lr = 0.0002
I0528 17:24:00.178138 10644 solver.cpp:228] Iteration 340, loss = 0.486285
I0528 17:24:00.178162 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:24:00.178169 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.057516 (* 1 = 0.057516 loss)
I0528 17:24:00.178174 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0860224 (* 1 = 0.0860224 loss)
I0528 17:24:00.178177 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265436 (* 1 = 0.0265436 loss)
I0528 17:24:00.178180 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00732024 (* 1 = 0.00732024 loss)
I0528 17:24:00.178185 10644 sgd_solver.cpp:106] Iteration 340, lr = 0.0002
I0528 17:24:48.790355 10644 solver.cpp:228] Iteration 360, loss = 0.141513
I0528 17:24:48.790385 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:24:48.790395 10644 solver.cpp:244]     Train net output #1: loss_bbox = 3.74124e-05 (* 1 = 3.74124e-05 loss)
I0528 17:24:48.790402 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0360546 (* 1 = 0.0360546 loss)
I0528 17:24:48.790407 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0412265 (* 1 = 0.0412265 loss)
I0528 17:24:48.790412 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222613 (* 1 = 0.0222613 loss)
I0528 17:24:48.790419 10644 sgd_solver.cpp:106] Iteration 360, lr = 0.0002
I0528 17:25:37.392606 10644 solver.cpp:228] Iteration 380, loss = 0.314261
I0528 17:25:37.392632 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:25:37.392638 10644 solver.cpp:244]     Train net output #1: loss_bbox = 6.15679e-06 (* 1 = 6.15679e-06 loss)
I0528 17:25:37.392643 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0453686 (* 1 = 0.0453686 loss)
I0528 17:25:37.392647 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266473 (* 1 = 0.0266473 loss)
I0528 17:25:37.392652 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119748 (* 1 = 0.0119748 loss)
I0528 17:25:37.392657 10644 sgd_solver.cpp:106] Iteration 380, lr = 0.0002
speed: 2.420s / iter
I0528 17:26:26.005336 10644 solver.cpp:228] Iteration 400, loss = 0.221602
I0528 17:26:26.005364 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 17:26:26.005374 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374628 (* 1 = 0.0374628 loss)
I0528 17:26:26.005380 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.125256 (* 1 = 0.125256 loss)
I0528 17:26:26.005386 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0457839 (* 1 = 0.0457839 loss)
I0528 17:26:26.005393 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329176 (* 1 = 0.0329176 loss)
I0528 17:26:26.005400 10644 sgd_solver.cpp:106] Iteration 400, lr = 0.0002
I0528 17:27:14.675046 10644 solver.cpp:228] Iteration 420, loss = 0.232717
I0528 17:27:14.675088 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:27:14.675106 10644 solver.cpp:244]     Train net output #1: loss_bbox = 3.7905e-06 (* 1 = 3.7905e-06 loss)
I0528 17:27:14.675117 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.050544 (* 1 = 0.050544 loss)
I0528 17:27:14.675125 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263078 (* 1 = 0.0263078 loss)
I0528 17:27:14.675134 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00948865 (* 1 = 0.00948865 loss)
I0528 17:27:14.675177 10644 sgd_solver.cpp:106] Iteration 420, lr = 0.0002
I0528 17:28:03.546133 10644 solver.cpp:228] Iteration 440, loss = 0.245736
I0528 17:28:03.546159 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:28:03.546166 10644 solver.cpp:244]     Train net output #1: loss_bbox = 9.84737e-05 (* 1 = 9.84737e-05 loss)
I0528 17:28:03.546171 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0545393 (* 1 = 0.0545393 loss)
I0528 17:28:03.546175 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0511265 (* 1 = 0.0511265 loss)
I0528 17:28:03.546180 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512597 (* 1 = 0.0512597 loss)
I0528 17:28:03.546185 10644 sgd_solver.cpp:106] Iteration 440, lr = 0.0002
I0528 17:28:52.113726 10644 solver.cpp:228] Iteration 460, loss = 0.579022
I0528 17:28:52.113751 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 17:28:52.113759 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.351011 (* 1 = 0.351011 loss)
I0528 17:28:52.113764 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.723662 (* 1 = 0.723662 loss)
I0528 17:28:52.113767 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.411164 (* 1 = 0.411164 loss)
I0528 17:28:52.113770 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.238185 (* 1 = 0.238185 loss)
I0528 17:28:52.113776 10644 sgd_solver.cpp:106] Iteration 460, lr = 0.0002
I0528 17:29:40.798220 10644 solver.cpp:228] Iteration 480, loss = 0.416285
I0528 17:29:40.798244 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:29:40.798251 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384759 (* 1 = 0.0384759 loss)
I0528 17:29:40.798255 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0713863 (* 1 = 0.0713863 loss)
I0528 17:29:40.798259 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221903 (* 1 = 0.0221903 loss)
I0528 17:29:40.798262 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105491 (* 1 = 0.0105491 loss)
I0528 17:29:40.798269 10644 sgd_solver.cpp:106] Iteration 480, lr = 0.0002
I0528 17:30:29.504886 10644 solver.cpp:228] Iteration 500, loss = 0.287373
I0528 17:30:29.504917 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:30:29.504926 10644 solver.cpp:244]     Train net output #1: loss_bbox = 2.82513e-05 (* 1 = 2.82513e-05 loss)
I0528 17:30:29.504930 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0200328 (* 1 = 0.0200328 loss)
I0528 17:30:29.504933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252789 (* 1 = 0.0252789 loss)
I0528 17:30:29.504937 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149491 (* 1 = 0.0149491 loss)
I0528 17:30:29.504943 10644 sgd_solver.cpp:106] Iteration 500, lr = 0.0002
I0528 17:31:18.129766 10644 solver.cpp:228] Iteration 520, loss = 0.373917
I0528 17:31:18.129796 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:31:18.129806 10644 solver.cpp:244]     Train net output #1: loss_bbox = 3.3351e-05 (* 1 = 3.3351e-05 loss)
I0528 17:31:18.129812 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0923826 (* 1 = 0.0923826 loss)
I0528 17:31:18.129817 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0512617 (* 1 = 0.0512617 loss)
I0528 17:31:18.129822 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017866 (* 1 = 0.017866 loss)
I0528 17:31:18.129827 10644 sgd_solver.cpp:106] Iteration 520, lr = 0.0002
I0528 17:32:06.789866 10644 solver.cpp:228] Iteration 540, loss = 0.446105
I0528 17:32:06.789892 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:32:06.789899 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140229 (* 1 = 0.0140229 loss)
I0528 17:32:06.789902 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0565344 (* 1 = 0.0565344 loss)
I0528 17:32:06.789906 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263222 (* 1 = 0.0263222 loss)
I0528 17:32:06.789909 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120345 (* 1 = 0.0120345 loss)
I0528 17:32:06.789914 10644 sgd_solver.cpp:106] Iteration 540, lr = 0.0002
I0528 17:32:55.410542 10644 solver.cpp:228] Iteration 560, loss = 0.222867
I0528 17:32:55.410567 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 17:32:55.410576 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0646264 (* 1 = 0.0646264 loss)
I0528 17:32:55.410583 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134691 (* 1 = 0.134691 loss)
I0528 17:32:55.410588 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246696 (* 1 = 0.0246696 loss)
I0528 17:32:55.410594 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00868722 (* 1 = 0.00868722 loss)
I0528 17:32:55.410600 10644 sgd_solver.cpp:106] Iteration 560, lr = 0.0002
I0528 17:33:44.027551 10644 solver.cpp:228] Iteration 580, loss = 0.339523
I0528 17:33:44.027580 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:33:44.027591 10644 solver.cpp:244]     Train net output #1: loss_bbox = 8.76216e-05 (* 1 = 8.76216e-05 loss)
I0528 17:33:44.027597 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.148672 (* 1 = 0.148672 loss)
I0528 17:33:44.027602 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0479409 (* 1 = 0.0479409 loss)
I0528 17:33:44.027607 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0313715 (* 1 = 0.0313715 loss)
I0528 17:33:44.027617 10644 sgd_solver.cpp:106] Iteration 580, lr = 0.0002
speed: 2.424s / iter
I0528 17:34:32.582957 10644 solver.cpp:228] Iteration 600, loss = 0.409344
I0528 17:34:32.582983 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 17:34:32.582990 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.164982 (* 1 = 0.164982 loss)
I0528 17:34:32.582994 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.3136 (* 1 = 0.3136 loss)
I0528 17:34:32.582998 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0881731 (* 1 = 0.0881731 loss)
I0528 17:34:32.583000 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663188 (* 1 = 0.0663188 loss)
I0528 17:34:32.583006 10644 sgd_solver.cpp:106] Iteration 600, lr = 0.0002
I0528 17:35:21.212288 10644 solver.cpp:228] Iteration 620, loss = 0.441063
I0528 17:35:21.212312 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 17:35:21.212319 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0802479 (* 1 = 0.0802479 loss)
I0528 17:35:21.212323 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.206144 (* 1 = 0.206144 loss)
I0528 17:35:21.212327 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018742 (* 1 = 0.018742 loss)
I0528 17:35:21.212330 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00285939 (* 1 = 0.00285939 loss)
I0528 17:35:21.212335 10644 sgd_solver.cpp:106] Iteration 620, lr = 0.0002
I0528 17:36:09.779955 10644 solver.cpp:228] Iteration 640, loss = 0.392806
I0528 17:36:09.779979 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 17:36:09.779986 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0620698 (* 1 = 0.0620698 loss)
I0528 17:36:09.779990 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.220634 (* 1 = 0.220634 loss)
I0528 17:36:09.779994 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0621142 (* 1 = 0.0621142 loss)
I0528 17:36:09.779997 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495972 (* 1 = 0.0495972 loss)
I0528 17:36:09.780004 10644 sgd_solver.cpp:106] Iteration 640, lr = 0.0002
I0528 17:36:58.432705 10644 solver.cpp:228] Iteration 660, loss = 0.520667
I0528 17:36:58.432730 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:36:58.432737 10644 solver.cpp:244]     Train net output #1: loss_bbox = 4.87015e-05 (* 1 = 4.87015e-05 loss)
I0528 17:36:58.432741 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0481913 (* 1 = 0.0481913 loss)
I0528 17:36:58.432744 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0423765 (* 1 = 0.0423765 loss)
I0528 17:36:58.432749 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037164 (* 1 = 0.037164 loss)
I0528 17:36:58.432754 10644 sgd_solver.cpp:106] Iteration 660, lr = 0.0002
I0528 17:37:47.044235 10644 solver.cpp:228] Iteration 680, loss = 0.31166
I0528 17:37:47.044263 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:37:47.044271 10644 solver.cpp:244]     Train net output #1: loss_bbox = 6.04492e-05 (* 1 = 6.04492e-05 loss)
I0528 17:37:47.044276 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0432006 (* 1 = 0.0432006 loss)
I0528 17:37:47.044281 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0452152 (* 1 = 0.0452152 loss)
I0528 17:37:47.044284 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136782 (* 1 = 0.0136782 loss)
I0528 17:37:47.044291 10644 sgd_solver.cpp:106] Iteration 680, lr = 0.0002
I0528 17:38:35.589221 10644 solver.cpp:228] Iteration 700, loss = 0.392073
I0528 17:38:35.589246 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 17:38:35.589253 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843934 (* 1 = 0.0843934 loss)
I0528 17:38:35.589257 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255726 (* 1 = 0.255726 loss)
I0528 17:38:35.589262 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0443143 (* 1 = 0.0443143 loss)
I0528 17:38:35.589265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281311 (* 1 = 0.0281311 loss)
I0528 17:38:35.589270 10644 sgd_solver.cpp:106] Iteration 700, lr = 0.0002
I0528 17:39:24.195914 10644 solver.cpp:228] Iteration 720, loss = 0.213093
I0528 17:39:24.195941 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:39:24.195948 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157166 (* 1 = 0.0157166 loss)
I0528 17:39:24.195952 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0727745 (* 1 = 0.0727745 loss)
I0528 17:39:24.195956 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188372 (* 1 = 0.0188372 loss)
I0528 17:39:24.195960 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119323 (* 1 = 0.0119323 loss)
I0528 17:39:24.195966 10644 sgd_solver.cpp:106] Iteration 720, lr = 0.0002
I0528 17:40:12.765667 10644 solver.cpp:228] Iteration 740, loss = 0.583189
I0528 17:40:12.765692 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 17:40:12.765700 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0550004 (* 1 = 0.0550004 loss)
I0528 17:40:12.765704 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.184374 (* 1 = 0.184374 loss)
I0528 17:40:12.765708 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364241 (* 1 = 0.0364241 loss)
I0528 17:40:12.765712 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346275 (* 1 = 0.0346275 loss)
I0528 17:40:12.765718 10644 sgd_solver.cpp:106] Iteration 740, lr = 0.0002
I0528 17:41:01.315680 10644 solver.cpp:228] Iteration 760, loss = 0.380461
I0528 17:41:01.315707 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 17:41:01.315716 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.175226 (* 1 = 0.175226 loss)
I0528 17:41:01.315719 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.462862 (* 1 = 0.462862 loss)
I0528 17:41:01.315723 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.154906 (* 1 = 0.154906 loss)
I0528 17:41:01.315726 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.152058 (* 1 = 0.152058 loss)
I0528 17:41:01.315732 10644 sgd_solver.cpp:106] Iteration 760, lr = 0.0002
I0528 17:41:49.894932 10644 solver.cpp:228] Iteration 780, loss = 0.314962
I0528 17:41:49.894956 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 17:41:49.894964 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0706024 (* 1 = 0.0706024 loss)
I0528 17:41:49.894968 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.164548 (* 1 = 0.164548 loss)
I0528 17:41:49.894973 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188651 (* 1 = 0.0188651 loss)
I0528 17:41:49.894976 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0064157 (* 1 = 0.0064157 loss)
I0528 17:41:49.894982 10644 sgd_solver.cpp:106] Iteration 780, lr = 0.0002
speed: 2.426s / iter
I0528 17:42:38.463338 10644 solver.cpp:228] Iteration 800, loss = 0.353453
I0528 17:42:38.463368 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 17:42:38.463378 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.164369 (* 1 = 0.164369 loss)
I0528 17:42:38.463384 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.272863 (* 1 = 0.272863 loss)
I0528 17:42:38.463392 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214375 (* 1 = 0.0214375 loss)
I0528 17:42:38.463399 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018039 (* 1 = 0.018039 loss)
I0528 17:42:38.463407 10644 sgd_solver.cpp:106] Iteration 800, lr = 0.0002
I0528 17:43:27.049016 10644 solver.cpp:228] Iteration 820, loss = 0.386389
I0528 17:43:27.049041 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 17:43:27.049048 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.150814 (* 1 = 0.150814 loss)
I0528 17:43:27.049052 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.322386 (* 1 = 0.322386 loss)
I0528 17:43:27.049057 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0464024 (* 1 = 0.0464024 loss)
I0528 17:43:27.049059 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0709497 (* 1 = 0.0709497 loss)
I0528 17:43:27.049065 10644 sgd_solver.cpp:106] Iteration 820, lr = 0.0002
I0528 17:44:15.590143 10644 solver.cpp:228] Iteration 840, loss = 0.594399
I0528 17:44:15.590167 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 17:44:15.590174 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.187547 (* 1 = 0.187547 loss)
I0528 17:44:15.590178 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.423026 (* 1 = 0.423026 loss)
I0528 17:44:15.590183 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0781079 (* 1 = 0.0781079 loss)
I0528 17:44:15.590185 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0473467 (* 1 = 0.0473467 loss)
I0528 17:44:15.590190 10644 sgd_solver.cpp:106] Iteration 840, lr = 0.0002
I0528 17:45:04.137248 10644 solver.cpp:228] Iteration 860, loss = 0.488056
I0528 17:45:04.137271 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 17:45:04.137279 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0568963 (* 1 = 0.0568963 loss)
I0528 17:45:04.137281 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152187 (* 1 = 0.152187 loss)
I0528 17:45:04.137285 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0404236 (* 1 = 0.0404236 loss)
I0528 17:45:04.137289 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0531102 (* 1 = 0.0531102 loss)
I0528 17:45:04.137292 10644 sgd_solver.cpp:106] Iteration 860, lr = 0.0002
I0528 17:45:52.674093 10644 solver.cpp:228] Iteration 880, loss = 0.244492
I0528 17:45:52.674119 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 17:45:52.674126 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0797197 (* 1 = 0.0797197 loss)
I0528 17:45:52.674130 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.183293 (* 1 = 0.183293 loss)
I0528 17:45:52.674134 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268366 (* 1 = 0.0268366 loss)
I0528 17:45:52.674137 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031125 (* 1 = 0.031125 loss)
I0528 17:45:52.674141 10644 sgd_solver.cpp:106] Iteration 880, lr = 0.0002
I0528 17:46:41.222858 10644 solver.cpp:228] Iteration 900, loss = 0.503087
I0528 17:46:41.222883 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0528 17:46:41.222890 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.244288 (* 1 = 0.244288 loss)
I0528 17:46:41.222893 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.466699 (* 1 = 0.466699 loss)
I0528 17:46:41.222896 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0729086 (* 1 = 0.0729086 loss)
I0528 17:46:41.222900 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0698903 (* 1 = 0.0698903 loss)
I0528 17:46:41.222905 10644 sgd_solver.cpp:106] Iteration 900, lr = 0.0002
I0528 17:47:29.764367 10644 solver.cpp:228] Iteration 920, loss = 0.417369
I0528 17:47:29.764394 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 17:47:29.764400 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628098 (* 1 = 0.0628098 loss)
I0528 17:47:29.764405 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.18137 (* 1 = 0.18137 loss)
I0528 17:47:29.764408 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378113 (* 1 = 0.0378113 loss)
I0528 17:47:29.764411 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267891 (* 1 = 0.0267891 loss)
I0528 17:47:29.764416 10644 sgd_solver.cpp:106] Iteration 920, lr = 0.0002
I0528 17:48:18.353443 10644 solver.cpp:228] Iteration 940, loss = 0.417008
I0528 17:48:18.353466 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 17:48:18.353473 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.103139 (* 1 = 0.103139 loss)
I0528 17:48:18.353477 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.291156 (* 1 = 0.291156 loss)
I0528 17:48:18.353482 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0386712 (* 1 = 0.0386712 loss)
I0528 17:48:18.353484 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185082 (* 1 = 0.0185082 loss)
I0528 17:48:18.353489 10644 sgd_solver.cpp:106] Iteration 940, lr = 0.0002
I0528 17:49:06.924787 10644 solver.cpp:228] Iteration 960, loss = 0.342955
I0528 17:49:06.924816 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 17:49:06.924823 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795827 (* 1 = 0.0795827 loss)
I0528 17:49:06.924827 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157242 (* 1 = 0.157242 loss)
I0528 17:49:06.924831 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206847 (* 1 = 0.0206847 loss)
I0528 17:49:06.924834 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940533 (* 1 = 0.00940533 loss)
I0528 17:49:06.924840 10644 sgd_solver.cpp:106] Iteration 960, lr = 0.0002
I0528 17:49:55.497234 10644 solver.cpp:228] Iteration 980, loss = 0.520088
I0528 17:49:55.497262 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 17:49:55.497268 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0885771 (* 1 = 0.0885771 loss)
I0528 17:49:55.497273 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.158836 (* 1 = 0.158836 loss)
I0528 17:49:55.497277 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030185 (* 1 = 0.030185 loss)
I0528 17:49:55.497280 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234744 (* 1 = 0.0234744 loss)
I0528 17:49:55.497287 10644 sgd_solver.cpp:106] Iteration 980, lr = 0.0002
speed: 2.426s / iter
I0528 17:50:44.069705 10644 solver.cpp:228] Iteration 1000, loss = 0.476814
I0528 17:50:44.069730 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 17:50:44.069737 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.155135 (* 1 = 0.155135 loss)
I0528 17:50:44.069742 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.32384 (* 1 = 0.32384 loss)
I0528 17:50:44.069746 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0388636 (* 1 = 0.0388636 loss)
I0528 17:50:44.069749 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319911 (* 1 = 0.0319911 loss)
I0528 17:50:44.069754 10644 sgd_solver.cpp:106] Iteration 1000, lr = 0.0002
I0528 17:51:32.634974 10644 solver.cpp:228] Iteration 1020, loss = 0.383732
I0528 17:51:32.634999 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0528 17:51:32.635005 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.317573 (* 1 = 0.317573 loss)
I0528 17:51:32.635010 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.563209 (* 1 = 0.563209 loss)
I0528 17:51:32.635013 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0736047 (* 1 = 0.0736047 loss)
I0528 17:51:32.635017 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0569224 (* 1 = 0.0569224 loss)
I0528 17:51:32.635023 10644 sgd_solver.cpp:106] Iteration 1020, lr = 0.0002
I0528 17:52:21.204140 10644 solver.cpp:228] Iteration 1040, loss = 0.176232
I0528 17:52:21.204167 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:52:21.204175 10644 solver.cpp:244]     Train net output #1: loss_bbox = 5.12621e-05 (* 1 = 5.12621e-05 loss)
I0528 17:52:21.204180 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0494242 (* 1 = 0.0494242 loss)
I0528 17:52:21.204183 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203458 (* 1 = 0.0203458 loss)
I0528 17:52:21.204188 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00796563 (* 1 = 0.00796563 loss)
I0528 17:52:21.204195 10644 sgd_solver.cpp:106] Iteration 1040, lr = 0.0002
I0528 17:53:09.786510 10644 solver.cpp:228] Iteration 1060, loss = 0.869067
I0528 17:53:09.786536 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0528 17:53:09.786545 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.341741 (* 1 = 0.341741 loss)
I0528 17:53:09.786550 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.774126 (* 1 = 0.774126 loss)
I0528 17:53:09.786552 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.496913 (* 1 = 0.496913 loss)
I0528 17:53:09.786556 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.504763 (* 1 = 0.504763 loss)
I0528 17:53:09.786562 10644 sgd_solver.cpp:106] Iteration 1060, lr = 0.0002
I0528 17:53:58.334578 10644 solver.cpp:228] Iteration 1080, loss = 0.536964
I0528 17:53:58.334602 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 17:53:58.334609 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.269248 (* 1 = 0.269248 loss)
I0528 17:53:58.334614 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.437157 (* 1 = 0.437157 loss)
I0528 17:53:58.334619 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0562305 (* 1 = 0.0562305 loss)
I0528 17:53:58.334622 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109734 (* 1 = 0.109734 loss)
I0528 17:53:58.334626 10644 sgd_solver.cpp:106] Iteration 1080, lr = 0.0002
I0528 17:54:46.908458 10644 solver.cpp:228] Iteration 1100, loss = 0.211118
I0528 17:54:46.908489 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 17:54:46.908498 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278647 (* 1 = 0.0278647 loss)
I0528 17:54:46.908501 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0764539 (* 1 = 0.0764539 loss)
I0528 17:54:46.908505 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173821 (* 1 = 0.0173821 loss)
I0528 17:54:46.908509 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126242 (* 1 = 0.0126242 loss)
I0528 17:54:46.908514 10644 sgd_solver.cpp:106] Iteration 1100, lr = 0.0002
I0528 17:55:35.515034 10644 solver.cpp:228] Iteration 1120, loss = 0.487137
I0528 17:55:35.515058 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:55:35.515066 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162246 (* 1 = 0.0162246 loss)
I0528 17:55:35.515071 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113479 (* 1 = 0.113479 loss)
I0528 17:55:35.515074 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0248163 (* 1 = 0.0248163 loss)
I0528 17:55:35.515079 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333221 (* 1 = 0.0333221 loss)
I0528 17:55:35.515084 10644 sgd_solver.cpp:106] Iteration 1120, lr = 0.0002
I0528 17:56:24.079741 10644 solver.cpp:228] Iteration 1140, loss = 0.364469
I0528 17:56:24.079785 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 17:56:24.079797 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0525503 (* 1 = 0.0525503 loss)
I0528 17:56:24.079803 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.14636 (* 1 = 0.14636 loss)
I0528 17:56:24.079808 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0391044 (* 1 = 0.0391044 loss)
I0528 17:56:24.079813 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485202 (* 1 = 0.0485202 loss)
I0528 17:56:24.079823 10644 sgd_solver.cpp:106] Iteration 1140, lr = 0.0002
I0528 17:57:12.655627 10644 solver.cpp:228] Iteration 1160, loss = 0.601338
I0528 17:57:12.655655 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 17:57:12.655663 10644 solver.cpp:244]     Train net output #1: loss_bbox = 3.58229e-05 (* 1 = 3.58229e-05 loss)
I0528 17:57:12.655668 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0539675 (* 1 = 0.0539675 loss)
I0528 17:57:12.655670 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133935 (* 1 = 0.0133935 loss)
I0528 17:57:12.655673 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180614 (* 1 = 0.0180614 loss)
I0528 17:57:12.655678 10644 sgd_solver.cpp:106] Iteration 1160, lr = 0.0002
I0528 17:58:01.243420 10644 solver.cpp:228] Iteration 1180, loss = 0.323428
I0528 17:58:01.243446 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 17:58:01.243453 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737383 (* 1 = 0.0737383 loss)
I0528 17:58:01.243456 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.163568 (* 1 = 0.163568 loss)
I0528 17:58:01.243460 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019252 (* 1 = 0.019252 loss)
I0528 17:58:01.243463 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105033 (* 1 = 0.0105033 loss)
I0528 17:58:01.243468 10644 sgd_solver.cpp:106] Iteration 1180, lr = 0.0002
speed: 2.427s / iter
I0528 17:58:49.811425 10644 solver.cpp:228] Iteration 1200, loss = 0.388228
I0528 17:58:49.811451 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 17:58:49.811460 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293894 (* 1 = 0.0293894 loss)
I0528 17:58:49.811465 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.138185 (* 1 = 0.138185 loss)
I0528 17:58:49.811470 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160116 (* 1 = 0.0160116 loss)
I0528 17:58:49.811476 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117125 (* 1 = 0.0117125 loss)
I0528 17:58:49.811482 10644 sgd_solver.cpp:106] Iteration 1200, lr = 0.0002
I0528 17:59:38.388703 10644 solver.cpp:228] Iteration 1220, loss = 0.228406
I0528 17:59:38.388730 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 17:59:38.388736 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.165217 (* 1 = 0.165217 loss)
I0528 17:59:38.388739 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.297447 (* 1 = 0.297447 loss)
I0528 17:59:38.388742 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0355142 (* 1 = 0.0355142 loss)
I0528 17:59:38.388746 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663054 (* 1 = 0.0663054 loss)
I0528 17:59:38.388751 10644 sgd_solver.cpp:106] Iteration 1220, lr = 0.0002
I0528 18:00:26.956845 10644 solver.cpp:228] Iteration 1240, loss = 0.675704
I0528 18:00:26.956882 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 18:00:26.956890 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305098 (* 1 = 0.0305098 loss)
I0528 18:00:26.956897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0923454 (* 1 = 0.0923454 loss)
I0528 18:00:26.956899 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327429 (* 1 = 0.0327429 loss)
I0528 18:00:26.956902 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0425766 (* 1 = 0.0425766 loss)
I0528 18:00:26.956917 10644 sgd_solver.cpp:106] Iteration 1240, lr = 0.0002
I0528 18:01:15.534440 10644 solver.cpp:228] Iteration 1260, loss = 0.518266
I0528 18:01:15.534469 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 18:01:15.534477 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297246 (* 1 = 0.0297246 loss)
I0528 18:01:15.534482 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.195626 (* 1 = 0.195626 loss)
I0528 18:01:15.534484 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364022 (* 1 = 0.0364022 loss)
I0528 18:01:15.534487 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289226 (* 1 = 0.0289226 loss)
I0528 18:01:15.534493 10644 sgd_solver.cpp:106] Iteration 1260, lr = 0.0002
I0528 18:02:04.107535 10644 solver.cpp:228] Iteration 1280, loss = 0.449985
I0528 18:02:04.107561 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:02:04.107568 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481497 (* 1 = 0.0481497 loss)
I0528 18:02:04.107573 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145971 (* 1 = 0.145971 loss)
I0528 18:02:04.107575 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231576 (* 1 = 0.0231576 loss)
I0528 18:02:04.107579 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196191 (* 1 = 0.0196191 loss)
I0528 18:02:04.107583 10644 sgd_solver.cpp:106] Iteration 1280, lr = 0.0002
I0528 18:02:52.675456 10644 solver.cpp:228] Iteration 1300, loss = 0.373241
I0528 18:02:52.675487 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 18:02:52.675498 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.130195 (* 1 = 0.130195 loss)
I0528 18:02:52.675504 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.281514 (* 1 = 0.281514 loss)
I0528 18:02:52.675509 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0367521 (* 1 = 0.0367521 loss)
I0528 18:02:52.675515 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481574 (* 1 = 0.0481574 loss)
I0528 18:02:52.675523 10644 sgd_solver.cpp:106] Iteration 1300, lr = 0.0002
I0528 18:03:41.245245 10644 solver.cpp:228] Iteration 1320, loss = 0.277659
I0528 18:03:41.245272 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 18:03:41.245282 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173838 (* 1 = 0.0173838 loss)
I0528 18:03:41.245290 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128091 (* 1 = 0.128091 loss)
I0528 18:03:41.245296 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152655 (* 1 = 0.0152655 loss)
I0528 18:03:41.245301 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123743 (* 1 = 0.0123743 loss)
I0528 18:03:41.245308 10644 sgd_solver.cpp:106] Iteration 1320, lr = 0.0002
I0528 18:04:29.799621 10644 solver.cpp:228] Iteration 1340, loss = 0.873514
I0528 18:04:29.799646 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0528 18:04:29.799654 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.622361 (* 1 = 0.622361 loss)
I0528 18:04:29.799659 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.787948 (* 1 = 0.787948 loss)
I0528 18:04:29.799662 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.125189 (* 1 = 0.125189 loss)
I0528 18:04:29.799665 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.428318 (* 1 = 0.428318 loss)
I0528 18:04:29.799671 10644 sgd_solver.cpp:106] Iteration 1340, lr = 0.0002
I0528 18:05:18.425204 10644 solver.cpp:228] Iteration 1360, loss = 0.462357
I0528 18:05:18.425235 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0528 18:05:18.425245 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.228484 (* 1 = 0.228484 loss)
I0528 18:05:18.425251 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.406883 (* 1 = 0.406883 loss)
I0528 18:05:18.425257 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039681 (* 1 = 0.039681 loss)
I0528 18:05:18.425263 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0550418 (* 1 = 0.0550418 loss)
I0528 18:05:18.425271 10644 sgd_solver.cpp:106] Iteration 1360, lr = 0.0002
I0528 18:06:06.999429 10644 solver.cpp:228] Iteration 1380, loss = 0.506965
I0528 18:06:06.999456 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:06:06.999464 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595335 (* 1 = 0.0595335 loss)
I0528 18:06:06.999469 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152294 (* 1 = 0.152294 loss)
I0528 18:06:06.999472 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114605 (* 1 = 0.0114605 loss)
I0528 18:06:06.999476 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00817017 (* 1 = 0.00817017 loss)
I0528 18:06:06.999482 10644 sgd_solver.cpp:106] Iteration 1380, lr = 0.0002
speed: 2.427s / iter
I0528 18:06:55.558594 10644 solver.cpp:228] Iteration 1400, loss = 0.38252
I0528 18:06:55.558624 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 18:06:55.558634 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.1047 (* 1 = 0.1047 loss)
I0528 18:06:55.558641 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.197201 (* 1 = 0.197201 loss)
I0528 18:06:55.558647 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214244 (* 1 = 0.0214244 loss)
I0528 18:06:55.558653 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00752188 (* 1 = 0.00752188 loss)
I0528 18:06:55.558661 10644 sgd_solver.cpp:106] Iteration 1400, lr = 0.0002
I0528 18:07:44.156843 10644 solver.cpp:228] Iteration 1420, loss = 0.674299
I0528 18:07:44.156868 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 18:07:44.156877 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0738842 (* 1 = 0.0738842 loss)
I0528 18:07:44.156880 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.163678 (* 1 = 0.163678 loss)
I0528 18:07:44.156884 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103071 (* 1 = 0.0103071 loss)
I0528 18:07:44.156888 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00909217 (* 1 = 0.00909217 loss)
I0528 18:07:44.156893 10644 sgd_solver.cpp:106] Iteration 1420, lr = 0.0002
I0528 18:08:32.716269 10644 solver.cpp:228] Iteration 1440, loss = 0.388501
I0528 18:08:32.716292 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:08:32.716300 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000163392 (* 1 = 0.000163392 loss)
I0528 18:08:32.716303 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0768654 (* 1 = 0.0768654 loss)
I0528 18:08:32.716307 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.022675 (* 1 = 0.022675 loss)
I0528 18:08:32.716310 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00843468 (* 1 = 0.00843468 loss)
I0528 18:08:32.716315 10644 sgd_solver.cpp:106] Iteration 1440, lr = 0.0002
I0528 18:09:21.384047 10644 solver.cpp:228] Iteration 1460, loss = 0.274636
I0528 18:09:21.384075 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 18:09:21.384086 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0313871 (* 1 = 0.0313871 loss)
I0528 18:09:21.384093 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.103556 (* 1 = 0.103556 loss)
I0528 18:09:21.384099 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296289 (* 1 = 0.0296289 loss)
I0528 18:09:21.384104 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272424 (* 1 = 0.0272424 loss)
I0528 18:09:21.384111 10644 sgd_solver.cpp:106] Iteration 1460, lr = 0.0002
I0528 18:10:10.057677 10644 solver.cpp:228] Iteration 1480, loss = 0.312401
I0528 18:10:10.057701 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 18:10:10.057708 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334381 (* 1 = 0.0334381 loss)
I0528 18:10:10.057713 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.192716 (* 1 = 0.192716 loss)
I0528 18:10:10.057716 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251401 (* 1 = 0.0251401 loss)
I0528 18:10:10.057719 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190202 (* 1 = 0.0190202 loss)
I0528 18:10:10.057724 10644 sgd_solver.cpp:106] Iteration 1480, lr = 0.0002
I0528 18:10:58.720077 10644 solver.cpp:228] Iteration 1500, loss = 0.301716
I0528 18:10:58.720104 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:10:58.720115 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00291766 (* 1 = 0.00291766 loss)
I0528 18:10:58.720121 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0620674 (* 1 = 0.0620674 loss)
I0528 18:10:58.720129 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0333145 (* 1 = 0.0333145 loss)
I0528 18:10:58.720134 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0603387 (* 1 = 0.0603387 loss)
I0528 18:10:58.720140 10644 sgd_solver.cpp:106] Iteration 1500, lr = 0.0002
I0528 18:11:47.318640 10644 solver.cpp:228] Iteration 1520, loss = 0.495278
I0528 18:11:47.318666 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 18:11:47.318673 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0969706 (* 1 = 0.0969706 loss)
I0528 18:11:47.318678 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.231274 (* 1 = 0.231274 loss)
I0528 18:11:47.318681 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166155 (* 1 = 0.0166155 loss)
I0528 18:11:47.318686 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342805 (* 1 = 0.0342805 loss)
I0528 18:11:47.318691 10644 sgd_solver.cpp:106] Iteration 1520, lr = 0.0002
I0528 18:12:35.925575 10644 solver.cpp:228] Iteration 1540, loss = 0.59117
I0528 18:12:35.925602 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:12:35.925611 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0686181 (* 1 = 0.0686181 loss)
I0528 18:12:35.925616 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160121 (* 1 = 0.160121 loss)
I0528 18:12:35.925619 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0736861 (* 1 = 0.0736861 loss)
I0528 18:12:35.925623 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329277 (* 1 = 0.0329277 loss)
I0528 18:12:35.925629 10644 sgd_solver.cpp:106] Iteration 1540, lr = 0.0002
I0528 18:13:24.577481 10644 solver.cpp:228] Iteration 1560, loss = 0.32188
I0528 18:13:24.577512 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 18:13:24.577522 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890438 (* 1 = 0.0890438 loss)
I0528 18:13:24.577529 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.211876 (* 1 = 0.211876 loss)
I0528 18:13:24.577535 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144976 (* 1 = 0.0144976 loss)
I0528 18:13:24.577541 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323444 (* 1 = 0.0323444 loss)
I0528 18:13:24.577548 10644 sgd_solver.cpp:106] Iteration 1560, lr = 0.0002
I0528 18:14:13.257099 10644 solver.cpp:228] Iteration 1580, loss = 0.436664
I0528 18:14:13.257128 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:14:13.257136 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0011022 (* 1 = 0.0011022 loss)
I0528 18:14:13.257141 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0477568 (* 1 = 0.0477568 loss)
I0528 18:14:13.257145 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219228 (* 1 = 0.0219228 loss)
I0528 18:14:13.257149 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00432491 (* 1 = 0.00432491 loss)
I0528 18:14:13.257155 10644 sgd_solver.cpp:106] Iteration 1580, lr = 0.0002
speed: 2.427s / iter
I0528 18:15:01.884307 10644 solver.cpp:228] Iteration 1600, loss = 0.309682
I0528 18:15:01.884336 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:15:01.884344 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00190575 (* 1 = 0.00190575 loss)
I0528 18:15:01.884348 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0735499 (* 1 = 0.0735499 loss)
I0528 18:15:01.884352 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0369715 (* 1 = 0.0369715 loss)
I0528 18:15:01.884356 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00514011 (* 1 = 0.00514011 loss)
I0528 18:15:01.884362 10644 sgd_solver.cpp:106] Iteration 1600, lr = 0.0002
I0528 18:15:50.543866 10644 solver.cpp:228] Iteration 1620, loss = 0.360384
I0528 18:15:50.543893 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 18:15:50.543901 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.134466 (* 1 = 0.134466 loss)
I0528 18:15:50.543905 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.317395 (* 1 = 0.317395 loss)
I0528 18:15:50.543910 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0229892 (* 1 = 0.0229892 loss)
I0528 18:15:50.543913 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0472006 (* 1 = 0.0472006 loss)
I0528 18:15:50.543918 10644 sgd_solver.cpp:106] Iteration 1620, lr = 0.0002
I0528 18:16:39.272681 10644 solver.cpp:228] Iteration 1640, loss = 0.440388
I0528 18:16:39.272711 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 18:16:39.272720 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0771481 (* 1 = 0.0771481 loss)
I0528 18:16:39.272725 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.227527 (* 1 = 0.227527 loss)
I0528 18:16:39.272730 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160217 (* 1 = 0.0160217 loss)
I0528 18:16:39.272734 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206704 (* 1 = 0.0206704 loss)
I0528 18:16:39.272740 10644 sgd_solver.cpp:106] Iteration 1640, lr = 0.0002
I0528 18:17:27.978248 10644 solver.cpp:228] Iteration 1660, loss = 0.610261
I0528 18:17:27.978276 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 18:17:27.978282 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.159039 (* 1 = 0.159039 loss)
I0528 18:17:27.978286 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.330524 (* 1 = 0.330524 loss)
I0528 18:17:27.978291 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0535508 (* 1 = 0.0535508 loss)
I0528 18:17:27.978293 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0843382 (* 1 = 0.0843382 loss)
I0528 18:17:27.978299 10644 sgd_solver.cpp:106] Iteration 1660, lr = 0.0002
I0528 18:18:16.636862 10644 solver.cpp:228] Iteration 1680, loss = 0.559597
I0528 18:18:16.636893 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 18:18:16.636900 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0951812 (* 1 = 0.0951812 loss)
I0528 18:18:16.636904 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.350161 (* 1 = 0.350161 loss)
I0528 18:18:16.636907 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327477 (* 1 = 0.0327477 loss)
I0528 18:18:16.636916 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197278 (* 1 = 0.0197278 loss)
I0528 18:18:16.636922 10644 sgd_solver.cpp:106] Iteration 1680, lr = 0.0002
I0528 18:19:05.317569 10644 solver.cpp:228] Iteration 1700, loss = 0.410031
I0528 18:19:05.317598 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 18:19:05.317610 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245059 (* 1 = 0.0245059 loss)
I0528 18:19:05.317616 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0712814 (* 1 = 0.0712814 loss)
I0528 18:19:05.317622 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166725 (* 1 = 0.0166725 loss)
I0528 18:19:05.317628 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177408 (* 1 = 0.0177408 loss)
I0528 18:19:05.317636 10644 sgd_solver.cpp:106] Iteration 1700, lr = 0.0002
I0528 18:19:54.066134 10644 solver.cpp:228] Iteration 1720, loss = 0.558951
I0528 18:19:54.066166 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 18:19:54.066175 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.010821 (* 1 = 0.010821 loss)
I0528 18:19:54.066182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0726812 (* 1 = 0.0726812 loss)
I0528 18:19:54.066187 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116216 (* 1 = 0.0116216 loss)
I0528 18:19:54.066192 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104245 (* 1 = 0.0104245 loss)
I0528 18:19:54.066200 10644 sgd_solver.cpp:106] Iteration 1720, lr = 0.0002
I0528 18:20:42.659188 10644 solver.cpp:228] Iteration 1740, loss = 0.457451
I0528 18:20:42.659215 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 18:20:42.659224 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.119888 (* 1 = 0.119888 loss)
I0528 18:20:42.659230 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.301967 (* 1 = 0.301967 loss)
I0528 18:20:42.659235 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0280869 (* 1 = 0.0280869 loss)
I0528 18:20:42.659241 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0518759 (* 1 = 0.0518759 loss)
I0528 18:20:42.659247 10644 sgd_solver.cpp:106] Iteration 1740, lr = 0.0002
I0528 18:21:31.278651 10644 solver.cpp:228] Iteration 1760, loss = 0.640266
I0528 18:21:31.278676 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0528 18:21:31.278683 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.497793 (* 1 = 0.497793 loss)
I0528 18:21:31.278687 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.702383 (* 1 = 0.702383 loss)
I0528 18:21:31.278690 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.608182 (* 1 = 0.608182 loss)
I0528 18:21:31.278694 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.956384 (* 1 = 0.956384 loss)
I0528 18:21:31.278699 10644 sgd_solver.cpp:106] Iteration 1760, lr = 0.0002
I0528 18:22:20.023278 10644 solver.cpp:228] Iteration 1780, loss = 0.298011
I0528 18:22:20.023306 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 18:22:20.023317 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.091957 (* 1 = 0.091957 loss)
I0528 18:22:20.023324 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.177826 (* 1 = 0.177826 loss)
I0528 18:22:20.023330 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143669 (* 1 = 0.0143669 loss)
I0528 18:22:20.023336 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147189 (* 1 = 0.0147189 loss)
I0528 18:22:20.023344 10644 sgd_solver.cpp:106] Iteration 1780, lr = 0.0002
speed: 2.428s / iter
I0528 18:23:08.708868 10644 solver.cpp:228] Iteration 1800, loss = 0.420411
I0528 18:23:08.708892 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0528 18:23:08.708899 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.171014 (* 1 = 0.171014 loss)
I0528 18:23:08.708904 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.361908 (* 1 = 0.361908 loss)
I0528 18:23:08.708907 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0710342 (* 1 = 0.0710342 loss)
I0528 18:23:08.708914 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117616 (* 1 = 0.117616 loss)
I0528 18:23:08.708920 10644 sgd_solver.cpp:106] Iteration 1800, lr = 0.0002
I0528 18:23:57.505632 10644 solver.cpp:228] Iteration 1820, loss = 0.205601
I0528 18:23:57.505661 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:23:57.505669 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0164679 (* 1 = 0.0164679 loss)
I0528 18:23:57.505672 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.127117 (* 1 = 0.127117 loss)
I0528 18:23:57.505676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00614879 (* 1 = 0.00614879 loss)
I0528 18:23:57.505681 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00831749 (* 1 = 0.00831749 loss)
I0528 18:23:57.505686 10644 sgd_solver.cpp:106] Iteration 1820, lr = 0.0002
I0528 18:24:46.231752 10644 solver.cpp:228] Iteration 1840, loss = 0.627588
I0528 18:24:46.231786 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:24:46.231796 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337948 (* 1 = 0.0337948 loss)
I0528 18:24:46.231803 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.137962 (* 1 = 0.137962 loss)
I0528 18:24:46.231809 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00607769 (* 1 = 0.00607769 loss)
I0528 18:24:46.231817 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00456328 (* 1 = 0.00456328 loss)
I0528 18:24:46.231823 10644 sgd_solver.cpp:106] Iteration 1840, lr = 0.0002
I0528 18:25:34.866185 10644 solver.cpp:228] Iteration 1860, loss = 0.270021
I0528 18:25:34.866214 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 18:25:34.866221 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399191 (* 1 = 0.0399191 loss)
I0528 18:25:34.866226 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.183766 (* 1 = 0.183766 loss)
I0528 18:25:34.866230 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0089563 (* 1 = 0.0089563 loss)
I0528 18:25:34.866233 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00410348 (* 1 = 0.00410348 loss)
I0528 18:25:34.866240 10644 sgd_solver.cpp:106] Iteration 1860, lr = 0.0002
I0528 18:26:23.511195 10644 solver.cpp:228] Iteration 1880, loss = 0.352345
I0528 18:26:23.511222 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:26:23.511230 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00267562 (* 1 = 0.00267562 loss)
I0528 18:26:23.511235 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0496344 (* 1 = 0.0496344 loss)
I0528 18:26:23.511240 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0389854 (* 1 = 0.0389854 loss)
I0528 18:26:23.511242 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214687 (* 1 = 0.0214687 loss)
I0528 18:26:23.511247 10644 sgd_solver.cpp:106] Iteration 1880, lr = 0.0002
I0528 18:27:12.147040 10644 solver.cpp:228] Iteration 1900, loss = 0.65838
I0528 18:27:12.147076 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0528 18:27:12.147085 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.430974 (* 1 = 0.430974 loss)
I0528 18:27:12.147089 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.658093 (* 1 = 0.658093 loss)
I0528 18:27:12.147094 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.067167 (* 1 = 0.067167 loss)
I0528 18:27:12.147099 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108927 (* 1 = 0.108927 loss)
I0528 18:27:12.147106 10644 sgd_solver.cpp:106] Iteration 1900, lr = 0.0002
I0528 18:28:00.839449 10644 solver.cpp:228] Iteration 1920, loss = 0.334025
I0528 18:28:00.839478 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 18:28:00.839488 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324295 (* 1 = 0.0324295 loss)
I0528 18:28:00.839494 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160603 (* 1 = 0.160603 loss)
I0528 18:28:00.839500 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201412 (* 1 = 0.0201412 loss)
I0528 18:28:00.839507 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563819 (* 1 = 0.0563819 loss)
I0528 18:28:00.839514 10644 sgd_solver.cpp:106] Iteration 1920, lr = 0.0002
I0528 18:28:49.496001 10644 solver.cpp:228] Iteration 1940, loss = 0.356954
I0528 18:28:49.496028 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:28:49.496037 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.054193 (* 1 = 0.054193 loss)
I0528 18:28:49.496040 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144657 (* 1 = 0.144657 loss)
I0528 18:28:49.496044 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255556 (* 1 = 0.0255556 loss)
I0528 18:28:49.496047 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183881 (* 1 = 0.0183881 loss)
I0528 18:28:49.496053 10644 sgd_solver.cpp:106] Iteration 1940, lr = 0.0002
I0528 18:29:38.201056 10644 solver.cpp:228] Iteration 1960, loss = 0.1664
I0528 18:29:38.201082 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 18:29:38.201089 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0552247 (* 1 = 0.0552247 loss)
I0528 18:29:38.201093 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0995974 (* 1 = 0.0995974 loss)
I0528 18:29:38.201097 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00981539 (* 1 = 0.00981539 loss)
I0528 18:29:38.201100 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160834 (* 1 = 0.0160834 loss)
I0528 18:29:38.201105 10644 sgd_solver.cpp:106] Iteration 1960, lr = 0.0002
I0528 18:30:26.839061 10644 solver.cpp:228] Iteration 1980, loss = 0.465865
I0528 18:30:26.839094 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 18:30:26.839107 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0918513 (* 1 = 0.0918513 loss)
I0528 18:30:26.839114 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.378052 (* 1 = 0.378052 loss)
I0528 18:30:26.839120 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0551374 (* 1 = 0.0551374 loss)
I0528 18:30:26.839125 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101477 (* 1 = 0.101477 loss)
I0528 18:30:26.839133 10644 sgd_solver.cpp:106] Iteration 1980, lr = 0.0002
speed: 2.429s / iter
I0528 18:31:15.492609 10644 solver.cpp:228] Iteration 2000, loss = 0.309291
I0528 18:31:15.492636 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 18:31:15.492643 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.073127 (* 1 = 0.073127 loss)
I0528 18:31:15.492647 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178401 (* 1 = 0.178401 loss)
I0528 18:31:15.492650 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011287 (* 1 = 0.011287 loss)
I0528 18:31:15.492653 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108227 (* 1 = 0.0108227 loss)
I0528 18:31:15.492658 10644 sgd_solver.cpp:106] Iteration 2000, lr = 0.0002
I0528 18:32:04.099337 10644 solver.cpp:228] Iteration 2020, loss = 0.586439
I0528 18:32:04.099360 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 18:32:04.099369 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.245504 (* 1 = 0.245504 loss)
I0528 18:32:04.099372 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.432333 (* 1 = 0.432333 loss)
I0528 18:32:04.099375 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212658 (* 1 = 0.0212658 loss)
I0528 18:32:04.099380 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.042289 (* 1 = 0.042289 loss)
I0528 18:32:04.099385 10644 sgd_solver.cpp:106] Iteration 2020, lr = 0.0002
I0528 18:32:52.853888 10644 solver.cpp:228] Iteration 2040, loss = 0.404661
I0528 18:32:52.853926 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 18:32:52.853936 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00496882 (* 1 = 0.00496882 loss)
I0528 18:32:52.853941 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0938749 (* 1 = 0.0938749 loss)
I0528 18:32:52.853946 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231559 (* 1 = 0.0231559 loss)
I0528 18:32:52.853950 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512557 (* 1 = 0.0512557 loss)
I0528 18:32:52.853957 10644 sgd_solver.cpp:106] Iteration 2040, lr = 0.0002
I0528 18:33:41.485141 10644 solver.cpp:228] Iteration 2060, loss = 0.251791
I0528 18:33:41.485169 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 18:33:41.485177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.160239 (* 1 = 0.160239 loss)
I0528 18:33:41.485182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.294794 (* 1 = 0.294794 loss)
I0528 18:33:41.485185 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256471 (* 1 = 0.0256471 loss)
I0528 18:33:41.485189 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491441 (* 1 = 0.0491441 loss)
I0528 18:33:41.485195 10644 sgd_solver.cpp:106] Iteration 2060, lr = 0.0002
I0528 18:34:30.152034 10644 solver.cpp:228] Iteration 2080, loss = 0.509225
I0528 18:34:30.152060 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:34:30.152070 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00171772 (* 1 = 0.00171772 loss)
I0528 18:34:30.152076 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.054303 (* 1 = 0.054303 loss)
I0528 18:34:30.152078 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015533 (* 1 = 0.015533 loss)
I0528 18:34:30.152082 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0476329 (* 1 = 0.0476329 loss)
I0528 18:34:30.152088 10644 sgd_solver.cpp:106] Iteration 2080, lr = 0.0002
I0528 18:35:18.778501 10644 solver.cpp:228] Iteration 2100, loss = 0.446195
I0528 18:35:18.778532 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 18:35:18.778539 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.170907 (* 1 = 0.170907 loss)
I0528 18:35:18.778544 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.345279 (* 1 = 0.345279 loss)
I0528 18:35:18.778550 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0240988 (* 1 = 0.0240988 loss)
I0528 18:35:18.778556 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449501 (* 1 = 0.0449501 loss)
I0528 18:35:18.778563 10644 sgd_solver.cpp:106] Iteration 2100, lr = 0.0002
I0528 18:36:07.417080 10644 solver.cpp:228] Iteration 2120, loss = 0.419596
I0528 18:36:07.417106 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 18:36:07.417114 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.267448 (* 1 = 0.267448 loss)
I0528 18:36:07.417119 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.4638 (* 1 = 0.4638 loss)
I0528 18:36:07.417121 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0384119 (* 1 = 0.0384119 loss)
I0528 18:36:07.417125 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0626149 (* 1 = 0.0626149 loss)
I0528 18:36:07.417129 10644 sgd_solver.cpp:106] Iteration 2120, lr = 0.0002
I0528 18:36:55.986102 10644 solver.cpp:228] Iteration 2140, loss = 0.540959
I0528 18:36:55.986130 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0528 18:36:55.986138 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.302821 (* 1 = 0.302821 loss)
I0528 18:36:55.986141 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.505184 (* 1 = 0.505184 loss)
I0528 18:36:55.986145 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0626571 (* 1 = 0.0626571 loss)
I0528 18:36:55.986148 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164004 (* 1 = 0.164004 loss)
I0528 18:36:55.986153 10644 sgd_solver.cpp:106] Iteration 2140, lr = 0.0002
I0528 18:37:44.505872 10644 solver.cpp:228] Iteration 2160, loss = 0.321988
I0528 18:37:44.505897 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 18:37:44.505904 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.142776 (* 1 = 0.142776 loss)
I0528 18:37:44.505909 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.323034 (* 1 = 0.323034 loss)
I0528 18:37:44.505915 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0507253 (* 1 = 0.0507253 loss)
I0528 18:37:44.505920 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.059535 (* 1 = 0.059535 loss)
I0528 18:37:44.505925 10644 sgd_solver.cpp:106] Iteration 2160, lr = 0.0002
I0528 18:38:32.953326 10644 solver.cpp:228] Iteration 2180, loss = 0.240241
I0528 18:38:32.953353 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 18:38:32.953361 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142192 (* 1 = 0.0142192 loss)
I0528 18:38:32.953366 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0718797 (* 1 = 0.0718797 loss)
I0528 18:38:32.953368 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149161 (* 1 = 0.0149161 loss)
I0528 18:38:32.953372 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127883 (* 1 = 0.0127883 loss)
I0528 18:38:32.953377 10644 sgd_solver.cpp:106] Iteration 2180, lr = 0.0002
speed: 2.429s / iter
I0528 18:39:21.567922 10644 solver.cpp:228] Iteration 2200, loss = 0.707544
I0528 18:39:21.567950 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:39:21.567957 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00184035 (* 1 = 0.00184035 loss)
I0528 18:39:21.567963 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.051518 (* 1 = 0.051518 loss)
I0528 18:39:21.567968 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0277303 (* 1 = 0.0277303 loss)
I0528 18:39:21.567973 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00860436 (* 1 = 0.00860436 loss)
I0528 18:39:21.567979 10644 sgd_solver.cpp:106] Iteration 2200, lr = 0.0002
I0528 18:40:10.201114 10644 solver.cpp:228] Iteration 2220, loss = 0.308134
I0528 18:40:10.201141 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:40:10.201150 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0303984 (* 1 = 0.0303984 loss)
I0528 18:40:10.201156 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.161719 (* 1 = 0.161719 loss)
I0528 18:40:10.201162 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184073 (* 1 = 0.0184073 loss)
I0528 18:40:10.201167 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134897 (* 1 = 0.0134897 loss)
I0528 18:40:10.201174 10644 sgd_solver.cpp:106] Iteration 2220, lr = 0.0002
I0528 18:40:58.933735 10644 solver.cpp:228] Iteration 2240, loss = 0.360883
I0528 18:40:58.933761 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0528 18:40:58.933768 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.220703 (* 1 = 0.220703 loss)
I0528 18:40:58.933773 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.478269 (* 1 = 0.478269 loss)
I0528 18:40:58.933778 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.108283 (* 1 = 0.108283 loss)
I0528 18:40:58.933781 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0974505 (* 1 = 0.0974505 loss)
I0528 18:40:58.933786 10644 sgd_solver.cpp:106] Iteration 2240, lr = 0.0002
I0528 18:41:47.500301 10644 solver.cpp:228] Iteration 2260, loss = 0.434909
I0528 18:41:47.500326 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 18:41:47.500334 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912654 (* 1 = 0.0912654 loss)
I0528 18:41:47.500339 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.237169 (* 1 = 0.237169 loss)
I0528 18:41:47.500342 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155956 (* 1 = 0.0155956 loss)
I0528 18:41:47.500345 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266618 (* 1 = 0.0266618 loss)
I0528 18:41:47.500350 10644 sgd_solver.cpp:106] Iteration 2260, lr = 0.0002
I0528 18:42:36.117611 10644 solver.cpp:228] Iteration 2280, loss = 0.38691
I0528 18:42:36.117640 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:42:36.117648 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286532 (* 1 = 0.0286532 loss)
I0528 18:42:36.117653 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170252 (* 1 = 0.170252 loss)
I0528 18:42:36.117656 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107581 (* 1 = 0.0107581 loss)
I0528 18:42:36.117660 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00806258 (* 1 = 0.00806258 loss)
I0528 18:42:36.117666 10644 sgd_solver.cpp:106] Iteration 2280, lr = 0.0002
I0528 18:43:24.978345 10644 solver.cpp:228] Iteration 2300, loss = 0.294727
I0528 18:43:24.978371 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:43:24.978379 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827345 (* 1 = 0.0827345 loss)
I0528 18:43:24.978381 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160599 (* 1 = 0.160599 loss)
I0528 18:43:24.978385 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0285473 (* 1 = 0.0285473 loss)
I0528 18:43:24.978389 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181466 (* 1 = 0.0181466 loss)
I0528 18:43:24.978394 10644 sgd_solver.cpp:106] Iteration 2300, lr = 0.0002
I0528 18:44:13.600281 10644 solver.cpp:228] Iteration 2320, loss = 0.557734
I0528 18:44:13.600307 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 18:44:13.600314 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0557177 (* 1 = 0.0557177 loss)
I0528 18:44:13.600318 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142634 (* 1 = 0.142634 loss)
I0528 18:44:13.600322 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0369924 (* 1 = 0.0369924 loss)
I0528 18:44:13.600325 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306277 (* 1 = 0.0306277 loss)
I0528 18:44:13.600332 10644 sgd_solver.cpp:106] Iteration 2320, lr = 0.0002
I0528 18:45:02.259865 10644 solver.cpp:228] Iteration 2340, loss = 0.516316
I0528 18:45:02.259891 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 18:45:02.259898 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486665 (* 1 = 0.0486665 loss)
I0528 18:45:02.259902 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1556 (* 1 = 0.1556 loss)
I0528 18:45:02.259905 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136715 (* 1 = 0.0136715 loss)
I0528 18:45:02.259909 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383263 (* 1 = 0.0383263 loss)
I0528 18:45:02.259915 10644 sgd_solver.cpp:106] Iteration 2340, lr = 0.0002
I0528 18:45:50.899335 10644 solver.cpp:228] Iteration 2360, loss = 0.487064
I0528 18:45:50.899363 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 18:45:50.899370 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.157189 (* 1 = 0.157189 loss)
I0528 18:45:50.899374 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.377421 (* 1 = 0.377421 loss)
I0528 18:45:50.899379 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0524796 (* 1 = 0.0524796 loss)
I0528 18:45:50.899382 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0530609 (* 1 = 0.0530609 loss)
I0528 18:45:50.899387 10644 sgd_solver.cpp:106] Iteration 2360, lr = 0.0002
I0528 18:46:39.895830 10644 solver.cpp:228] Iteration 2380, loss = 0.379696
I0528 18:46:39.895864 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 18:46:39.895875 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0754576 (* 1 = 0.0754576 loss)
I0528 18:46:39.895881 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.309585 (* 1 = 0.309585 loss)
I0528 18:46:39.895889 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.155234 (* 1 = 0.155234 loss)
I0528 18:46:39.895895 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0928351 (* 1 = 0.0928351 loss)
I0528 18:46:39.895902 10644 sgd_solver.cpp:106] Iteration 2380, lr = 0.0002
speed: 2.429s / iter
I0528 18:47:28.574374 10644 solver.cpp:228] Iteration 2400, loss = 0.430492
I0528 18:47:28.574401 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 18:47:28.574410 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.255472 (* 1 = 0.255472 loss)
I0528 18:47:28.574414 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.356185 (* 1 = 0.356185 loss)
I0528 18:47:28.574419 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0354801 (* 1 = 0.0354801 loss)
I0528 18:47:28.574422 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624054 (* 1 = 0.0624054 loss)
I0528 18:47:28.574429 10644 sgd_solver.cpp:106] Iteration 2400, lr = 0.0002
I0528 18:48:17.203897 10644 solver.cpp:228] Iteration 2420, loss = 0.408017
I0528 18:48:17.203927 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:48:17.203934 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397382 (* 1 = 0.0397382 loss)
I0528 18:48:17.203939 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.143788 (* 1 = 0.143788 loss)
I0528 18:48:17.203943 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154166 (* 1 = 0.0154166 loss)
I0528 18:48:17.203948 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00979728 (* 1 = 0.00979728 loss)
I0528 18:48:17.203953 10644 sgd_solver.cpp:106] Iteration 2420, lr = 0.0002
I0528 18:49:05.935298 10644 solver.cpp:228] Iteration 2440, loss = 0.261799
I0528 18:49:05.935324 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 18:49:05.935333 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.15975 (* 1 = 0.15975 loss)
I0528 18:49:05.935336 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.285363 (* 1 = 0.285363 loss)
I0528 18:49:05.935340 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0404618 (* 1 = 0.0404618 loss)
I0528 18:49:05.935343 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439949 (* 1 = 0.0439949 loss)
I0528 18:49:05.935348 10644 sgd_solver.cpp:106] Iteration 2440, lr = 0.0002
I0528 18:49:54.624629 10644 solver.cpp:228] Iteration 2460, loss = 0.334543
I0528 18:49:54.624660 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 18:49:54.624670 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115867 (* 1 = 0.115867 loss)
I0528 18:49:54.624675 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.171706 (* 1 = 0.171706 loss)
I0528 18:49:54.624680 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.029308 (* 1 = 0.029308 loss)
I0528 18:49:54.624686 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177336 (* 1 = 0.0177336 loss)
I0528 18:49:54.624691 10644 sgd_solver.cpp:106] Iteration 2460, lr = 0.0002
I0528 18:50:43.264195 10644 solver.cpp:228] Iteration 2480, loss = 0.449742
I0528 18:50:43.264223 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 18:50:43.264232 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.176366 (* 1 = 0.176366 loss)
I0528 18:50:43.264238 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.344659 (* 1 = 0.344659 loss)
I0528 18:50:43.264243 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016798 (* 1 = 0.016798 loss)
I0528 18:50:43.264248 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315269 (* 1 = 0.0315269 loss)
I0528 18:50:43.264255 10644 sgd_solver.cpp:106] Iteration 2480, lr = 0.0002
I0528 18:51:31.949949 10644 solver.cpp:228] Iteration 2500, loss = 0.274894
I0528 18:51:31.949976 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 18:51:31.949986 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00148532 (* 1 = 0.00148532 loss)
I0528 18:51:31.949993 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101839 (* 1 = 0.101839 loss)
I0528 18:51:31.949998 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199767 (* 1 = 0.0199767 loss)
I0528 18:51:31.950003 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358831 (* 1 = 0.0358831 loss)
I0528 18:51:31.950011 10644 sgd_solver.cpp:106] Iteration 2500, lr = 0.0002
I0528 18:52:20.824689 10644 solver.cpp:228] Iteration 2520, loss = 0.346968
I0528 18:52:20.824759 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0528 18:52:20.824779 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.163031 (* 1 = 0.163031 loss)
I0528 18:52:20.824793 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.355568 (* 1 = 0.355568 loss)
I0528 18:52:20.824806 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0446603 (* 1 = 0.0446603 loss)
I0528 18:52:20.824820 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566889 (* 1 = 0.0566889 loss)
I0528 18:52:20.824836 10644 sgd_solver.cpp:106] Iteration 2520, lr = 0.0002
I0528 18:53:09.582463 10644 solver.cpp:228] Iteration 2540, loss = 0.354365
I0528 18:53:09.582490 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:53:09.582499 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434733 (* 1 = 0.0434733 loss)
I0528 18:53:09.582502 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.172248 (* 1 = 0.172248 loss)
I0528 18:53:09.582506 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141631 (* 1 = 0.0141631 loss)
I0528 18:53:09.582510 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0294488 (* 1 = 0.0294488 loss)
I0528 18:53:09.582515 10644 sgd_solver.cpp:106] Iteration 2540, lr = 0.0002
I0528 18:53:58.254215 10644 solver.cpp:228] Iteration 2560, loss = 0.401793
I0528 18:53:58.254245 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 18:53:58.254251 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.120037 (* 1 = 0.120037 loss)
I0528 18:53:58.254256 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.283183 (* 1 = 0.283183 loss)
I0528 18:53:58.254261 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145641 (* 1 = 0.0145641 loss)
I0528 18:53:58.254264 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129807 (* 1 = 0.0129807 loss)
I0528 18:53:58.254269 10644 sgd_solver.cpp:106] Iteration 2560, lr = 0.0002
I0528 18:54:47.064944 10644 solver.cpp:228] Iteration 2580, loss = 0.375519
I0528 18:54:47.064973 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 18:54:47.064981 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.182515 (* 1 = 0.182515 loss)
I0528 18:54:47.064985 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.324258 (* 1 = 0.324258 loss)
I0528 18:54:47.064990 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176783 (* 1 = 0.0176783 loss)
I0528 18:54:47.064994 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346686 (* 1 = 0.0346686 loss)
I0528 18:54:47.065001 10644 sgd_solver.cpp:106] Iteration 2580, lr = 0.0002
speed: 2.430s / iter
I0528 18:55:35.776387 10644 solver.cpp:228] Iteration 2600, loss = 0.686317
I0528 18:55:35.776458 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 18:55:35.776480 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0727937 (* 1 = 0.0727937 loss)
I0528 18:55:35.776506 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.191681 (* 1 = 0.191681 loss)
I0528 18:55:35.776515 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130429 (* 1 = 0.0130429 loss)
I0528 18:55:35.776520 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0413253 (* 1 = 0.0413253 loss)
I0528 18:55:35.776525 10644 sgd_solver.cpp:106] Iteration 2600, lr = 0.0002
I0528 18:56:24.389715 10644 solver.cpp:228] Iteration 2620, loss = 0.439835
I0528 18:56:24.389740 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 18:56:24.389747 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000400939 (* 1 = 0.000400939 loss)
I0528 18:56:24.389751 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0721786 (* 1 = 0.0721786 loss)
I0528 18:56:24.389755 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260076 (* 1 = 0.0260076 loss)
I0528 18:56:24.389758 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00931666 (* 1 = 0.00931666 loss)
I0528 18:56:24.389763 10644 sgd_solver.cpp:106] Iteration 2620, lr = 0.0002
I0528 18:57:13.010913 10644 solver.cpp:228] Iteration 2640, loss = 0.377881
I0528 18:57:13.010938 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 18:57:13.010946 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.111266 (* 1 = 0.111266 loss)
I0528 18:57:13.010949 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.246195 (* 1 = 0.246195 loss)
I0528 18:57:13.010953 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191594 (* 1 = 0.0191594 loss)
I0528 18:57:13.010957 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180388 (* 1 = 0.0180388 loss)
I0528 18:57:13.010962 10644 sgd_solver.cpp:106] Iteration 2640, lr = 0.0002
I0528 18:58:01.877745 10644 solver.cpp:228] Iteration 2660, loss = 0.259882
I0528 18:58:01.877777 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 18:58:01.877789 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.189755 (* 1 = 0.189755 loss)
I0528 18:58:01.877794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.34698 (* 1 = 0.34698 loss)
I0528 18:58:01.877799 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268883 (* 1 = 0.0268883 loss)
I0528 18:58:01.877804 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275651 (* 1 = 0.0275651 loss)
I0528 18:58:01.877811 10644 sgd_solver.cpp:106] Iteration 2660, lr = 0.0002
I0528 18:58:50.481484 10644 solver.cpp:228] Iteration 2680, loss = 0.27065
I0528 18:58:50.481508 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 18:58:50.481515 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.093835 (* 1 = 0.093835 loss)
I0528 18:58:50.481520 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.218078 (* 1 = 0.218078 loss)
I0528 18:58:50.481523 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011937 (* 1 = 0.011937 loss)
I0528 18:58:50.481528 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321067 (* 1 = 0.0321067 loss)
I0528 18:58:50.481532 10644 sgd_solver.cpp:106] Iteration 2680, lr = 0.0002
I0528 18:59:39.141562 10644 solver.cpp:228] Iteration 2700, loss = 0.283746
I0528 18:59:39.141587 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 18:59:39.141594 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0664448 (* 1 = 0.0664448 loss)
I0528 18:59:39.141598 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170526 (* 1 = 0.170526 loss)
I0528 18:59:39.141602 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073445 (* 1 = 0.0073445 loss)
I0528 18:59:39.141605 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140799 (* 1 = 0.0140799 loss)
I0528 18:59:39.141609 10644 sgd_solver.cpp:106] Iteration 2700, lr = 0.0002
I0528 19:00:27.772375 10644 solver.cpp:228] Iteration 2720, loss = 0.487747
I0528 19:00:27.772404 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:00:27.772413 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0657786 (* 1 = 0.0657786 loss)
I0528 19:00:27.772418 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.118481 (* 1 = 0.118481 loss)
I0528 19:00:27.772423 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0081782 (* 1 = 0.0081782 loss)
I0528 19:00:27.772428 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00931347 (* 1 = 0.00931347 loss)
I0528 19:00:27.772433 10644 sgd_solver.cpp:106] Iteration 2720, lr = 0.0002
I0528 19:01:16.496875 10644 solver.cpp:228] Iteration 2740, loss = 0.595887
I0528 19:01:16.496901 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0528 19:01:16.496908 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.306424 (* 1 = 0.306424 loss)
I0528 19:01:16.496917 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.55583 (* 1 = 0.55583 loss)
I0528 19:01:16.496920 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.31681 (* 1 = 0.31681 loss)
I0528 19:01:16.496923 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.262754 (* 1 = 0.262754 loss)
I0528 19:01:16.496929 10644 sgd_solver.cpp:106] Iteration 2740, lr = 0.0002
I0528 19:02:05.152276 10644 solver.cpp:228] Iteration 2760, loss = 0.551409
I0528 19:02:05.152304 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 19:02:05.152312 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.110588 (* 1 = 0.110588 loss)
I0528 19:02:05.152315 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.248166 (* 1 = 0.248166 loss)
I0528 19:02:05.152318 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174242 (* 1 = 0.0174242 loss)
I0528 19:02:05.152323 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.048003 (* 1 = 0.048003 loss)
I0528 19:02:05.152328 10644 sgd_solver.cpp:106] Iteration 2760, lr = 0.0002
I0528 19:02:53.799760 10644 solver.cpp:228] Iteration 2780, loss = 0.325605
I0528 19:02:53.799787 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 19:02:53.799794 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.102065 (* 1 = 0.102065 loss)
I0528 19:02:53.799798 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.327786 (* 1 = 0.327786 loss)
I0528 19:02:53.799803 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0717646 (* 1 = 0.0717646 loss)
I0528 19:02:53.799805 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0509948 (* 1 = 0.0509948 loss)
I0528 19:02:53.799811 10644 sgd_solver.cpp:106] Iteration 2780, lr = 0.0002
speed: 2.430s / iter
I0528 19:03:42.394677 10644 solver.cpp:228] Iteration 2800, loss = 0.435046
I0528 19:03:42.394702 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:03:42.394709 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595992 (* 1 = 0.0595992 loss)
I0528 19:03:42.394713 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.165972 (* 1 = 0.165972 loss)
I0528 19:03:42.394716 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110884 (* 1 = 0.0110884 loss)
I0528 19:03:42.394721 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150514 (* 1 = 0.0150514 loss)
I0528 19:03:42.394724 10644 sgd_solver.cpp:106] Iteration 2800, lr = 0.0002
I0528 19:04:31.042529 10644 solver.cpp:228] Iteration 2820, loss = 0.503759
I0528 19:04:31.042556 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0528 19:04:31.042563 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.280962 (* 1 = 0.280962 loss)
I0528 19:04:31.042567 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.423876 (* 1 = 0.423876 loss)
I0528 19:04:31.042570 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024692 (* 1 = 0.024692 loss)
I0528 19:04:31.042574 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395084 (* 1 = 0.0395084 loss)
I0528 19:04:31.042579 10644 sgd_solver.cpp:106] Iteration 2820, lr = 0.0002
I0528 19:05:19.784660 10644 solver.cpp:228] Iteration 2840, loss = 0.264819
I0528 19:05:19.784687 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 19:05:19.784693 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.140561 (* 1 = 0.140561 loss)
I0528 19:05:19.784698 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.233245 (* 1 = 0.233245 loss)
I0528 19:05:19.784701 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00932485 (* 1 = 0.00932485 loss)
I0528 19:05:19.784704 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0382848 (* 1 = 0.0382848 loss)
I0528 19:05:19.784709 10644 sgd_solver.cpp:106] Iteration 2840, lr = 0.0002
I0528 19:06:08.431999 10644 solver.cpp:228] Iteration 2860, loss = 0.419146
I0528 19:06:08.432026 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 19:06:08.432035 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.176565 (* 1 = 0.176565 loss)
I0528 19:06:08.432041 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.224524 (* 1 = 0.224524 loss)
I0528 19:06:08.432047 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00732585 (* 1 = 0.00732585 loss)
I0528 19:06:08.432052 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191923 (* 1 = 0.0191923 loss)
I0528 19:06:08.432059 10644 sgd_solver.cpp:106] Iteration 2860, lr = 0.0002
I0528 19:06:57.015135 10644 solver.cpp:228] Iteration 2880, loss = 0.33167
I0528 19:06:57.015161 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:06:57.015168 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220568 (* 1 = 0.0220568 loss)
I0528 19:06:57.015172 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.189176 (* 1 = 0.189176 loss)
I0528 19:06:57.015175 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166906 (* 1 = 0.0166906 loss)
I0528 19:06:57.015179 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00664322 (* 1 = 0.00664322 loss)
I0528 19:06:57.015184 10644 sgd_solver.cpp:106] Iteration 2880, lr = 0.0002
I0528 19:07:45.540046 10644 solver.cpp:228] Iteration 2900, loss = 0.3137
I0528 19:07:45.540071 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:07:45.540079 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191924 (* 1 = 0.0191924 loss)
I0528 19:07:45.540083 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115706 (* 1 = 0.115706 loss)
I0528 19:07:45.540086 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692804 (* 1 = 0.00692804 loss)
I0528 19:07:45.540091 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0094254 (* 1 = 0.0094254 loss)
I0528 19:07:45.540096 10644 sgd_solver.cpp:106] Iteration 2900, lr = 0.0002
I0528 19:08:34.079668 10644 solver.cpp:228] Iteration 2920, loss = 0.399352
I0528 19:08:34.079699 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 19:08:34.079706 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.11866 (* 1 = 0.11866 loss)
I0528 19:08:34.079710 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.30689 (* 1 = 0.30689 loss)
I0528 19:08:34.079715 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170219 (* 1 = 0.0170219 loss)
I0528 19:08:34.079717 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0328015 (* 1 = 0.0328015 loss)
I0528 19:08:34.079722 10644 sgd_solver.cpp:106] Iteration 2920, lr = 0.0002
I0528 19:09:22.627811 10644 solver.cpp:228] Iteration 2940, loss = 0.316439
I0528 19:09:22.627838 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 19:09:22.627846 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0873279 (* 1 = 0.0873279 loss)
I0528 19:09:22.627849 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.291745 (* 1 = 0.291745 loss)
I0528 19:09:22.627853 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.052414 (* 1 = 0.052414 loss)
I0528 19:09:22.627856 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0943891 (* 1 = 0.0943891 loss)
I0528 19:09:22.627861 10644 sgd_solver.cpp:106] Iteration 2940, lr = 0.0002
I0528 19:10:11.191658 10644 solver.cpp:228] Iteration 2960, loss = 0.294727
I0528 19:10:11.191684 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 19:10:11.191691 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.101103 (* 1 = 0.101103 loss)
I0528 19:10:11.191695 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.225332 (* 1 = 0.225332 loss)
I0528 19:10:11.191699 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130997 (* 1 = 0.0130997 loss)
I0528 19:10:11.191702 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020196 (* 1 = 0.020196 loss)
I0528 19:10:11.191707 10644 sgd_solver.cpp:106] Iteration 2960, lr = 0.0002
I0528 19:10:59.832108 10644 solver.cpp:228] Iteration 2980, loss = 0.412798
I0528 19:10:59.832135 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:10:59.832144 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233543 (* 1 = 0.0233543 loss)
I0528 19:10:59.832149 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0831125 (* 1 = 0.0831125 loss)
I0528 19:10:59.832151 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124404 (* 1 = 0.0124404 loss)
I0528 19:10:59.832155 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157682 (* 1 = 0.0157682 loss)
I0528 19:10:59.832161 10644 sgd_solver.cpp:106] Iteration 2980, lr = 0.0002
speed: 2.430s / iter
I0528 19:11:48.365787 10644 solver.cpp:228] Iteration 3000, loss = 0.323603
I0528 19:11:48.365815 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 19:11:48.365825 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0773302 (* 1 = 0.0773302 loss)
I0528 19:11:48.365830 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.241932 (* 1 = 0.241932 loss)
I0528 19:11:48.365836 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141609 (* 1 = 0.0141609 loss)
I0528 19:11:48.365841 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315202 (* 1 = 0.0315202 loss)
I0528 19:11:48.365849 10644 sgd_solver.cpp:106] Iteration 3000, lr = 0.0002
I0528 19:12:36.927731 10644 solver.cpp:228] Iteration 3020, loss = 0.546838
I0528 19:12:36.927754 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 19:12:36.927762 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.148933 (* 1 = 0.148933 loss)
I0528 19:12:36.927764 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.240293 (* 1 = 0.240293 loss)
I0528 19:12:36.927768 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115688 (* 1 = 0.0115688 loss)
I0528 19:12:36.927772 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126258 (* 1 = 0.0126258 loss)
I0528 19:12:36.927776 10644 sgd_solver.cpp:106] Iteration 3020, lr = 0.0002
I0528 19:13:25.527858 10644 solver.cpp:228] Iteration 3040, loss = 0.538794
I0528 19:13:25.527884 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0528 19:13:25.527891 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.564817 (* 1 = 0.564817 loss)
I0528 19:13:25.527895 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.68393 (* 1 = 0.68393 loss)
I0528 19:13:25.527899 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.268248 (* 1 = 0.268248 loss)
I0528 19:13:25.527901 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.939424 (* 1 = 0.939424 loss)
I0528 19:13:25.527906 10644 sgd_solver.cpp:106] Iteration 3040, lr = 0.0002
I0528 19:14:14.137523 10644 solver.cpp:228] Iteration 3060, loss = 0.29392
I0528 19:14:14.137547 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 19:14:14.137555 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.110252 (* 1 = 0.110252 loss)
I0528 19:14:14.137562 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.281736 (* 1 = 0.281736 loss)
I0528 19:14:14.137567 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171728 (* 1 = 0.0171728 loss)
I0528 19:14:14.137571 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0651452 (* 1 = 0.0651452 loss)
I0528 19:14:14.137578 10644 sgd_solver.cpp:106] Iteration 3060, lr = 0.0002
I0528 19:15:02.741248 10644 solver.cpp:228] Iteration 3080, loss = 0.350583
I0528 19:15:02.741312 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:15:02.741333 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0535041 (* 1 = 0.0535041 loss)
I0528 19:15:02.741345 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109862 (* 1 = 0.109862 loss)
I0528 19:15:02.741358 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0056067 (* 1 = 0.0056067 loss)
I0528 19:15:02.741372 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00418642 (* 1 = 0.00418642 loss)
I0528 19:15:02.741386 10644 sgd_solver.cpp:106] Iteration 3080, lr = 0.0002
I0528 19:15:51.422437 10644 solver.cpp:228] Iteration 3100, loss = 0.272515
I0528 19:15:51.422464 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:15:51.422474 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133409 (* 1 = 0.0133409 loss)
I0528 19:15:51.422482 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0761491 (* 1 = 0.0761491 loss)
I0528 19:15:51.422487 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00836649 (* 1 = 0.00836649 loss)
I0528 19:15:51.422493 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223664 (* 1 = 0.0223664 loss)
I0528 19:15:51.422499 10644 sgd_solver.cpp:106] Iteration 3100, lr = 0.0002
I0528 19:16:40.095088 10644 solver.cpp:228] Iteration 3120, loss = 0.551505
I0528 19:16:40.095116 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 19:16:40.095124 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189753 (* 1 = 0.0189753 loss)
I0528 19:16:40.095127 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.159617 (* 1 = 0.159617 loss)
I0528 19:16:40.095131 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106914 (* 1 = 0.0106914 loss)
I0528 19:16:40.095134 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245232 (* 1 = 0.0245232 loss)
I0528 19:16:40.095139 10644 sgd_solver.cpp:106] Iteration 3120, lr = 0.0002
I0528 19:17:28.746866 10644 solver.cpp:228] Iteration 3140, loss = 0.305153
I0528 19:17:28.746892 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 19:17:28.746901 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0831186 (* 1 = 0.0831186 loss)
I0528 19:17:28.746904 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.132267 (* 1 = 0.132267 loss)
I0528 19:17:28.746908 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00427986 (* 1 = 0.00427986 loss)
I0528 19:17:28.746912 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178771 (* 1 = 0.0178771 loss)
I0528 19:17:28.746918 10644 sgd_solver.cpp:106] Iteration 3140, lr = 0.0002
I0528 19:18:17.417433 10644 solver.cpp:228] Iteration 3160, loss = 0.518151
I0528 19:18:17.417459 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:18:17.417467 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526329 (* 1 = 0.0526329 loss)
I0528 19:18:17.417471 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.156546 (* 1 = 0.156546 loss)
I0528 19:18:17.417475 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135421 (* 1 = 0.0135421 loss)
I0528 19:18:17.417479 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168353 (* 1 = 0.0168353 loss)
I0528 19:18:17.417484 10644 sgd_solver.cpp:106] Iteration 3160, lr = 0.0002
I0528 19:19:06.068598 10644 solver.cpp:228] Iteration 3180, loss = 0.324548
I0528 19:19:06.068624 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 19:19:06.068631 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494504 (* 1 = 0.0494504 loss)
I0528 19:19:06.068635 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0942983 (* 1 = 0.0942983 loss)
I0528 19:19:06.068640 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00868351 (* 1 = 0.00868351 loss)
I0528 19:19:06.068645 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135102 (* 1 = 0.0135102 loss)
I0528 19:19:06.068650 10644 sgd_solver.cpp:106] Iteration 3180, lr = 0.0002
speed: 2.430s / iter
I0528 19:19:54.634047 10644 solver.cpp:228] Iteration 3200, loss = 0.383868
I0528 19:19:54.634074 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 19:19:54.634083 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115407 (* 1 = 0.115407 loss)
I0528 19:19:54.634086 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.270694 (* 1 = 0.270694 loss)
I0528 19:19:54.634090 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0499144 (* 1 = 0.0499144 loss)
I0528 19:19:54.634094 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327698 (* 1 = 0.0327698 loss)
I0528 19:19:54.634099 10644 sgd_solver.cpp:106] Iteration 3200, lr = 0.0002
I0528 19:20:43.252076 10644 solver.cpp:228] Iteration 3220, loss = 0.3105
I0528 19:20:43.252106 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 19:20:43.252117 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816464 (* 1 = 0.0816464 loss)
I0528 19:20:43.252125 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.210432 (* 1 = 0.210432 loss)
I0528 19:20:43.252130 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112579 (* 1 = 0.0112579 loss)
I0528 19:20:43.252136 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181009 (* 1 = 0.0181009 loss)
I0528 19:20:43.252144 10644 sgd_solver.cpp:106] Iteration 3220, lr = 0.0002
I0528 19:21:31.868870 10644 solver.cpp:228] Iteration 3240, loss = 0.2857
I0528 19:21:31.868898 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 19:21:31.868906 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.18366 (* 1 = 0.18366 loss)
I0528 19:21:31.868916 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.380334 (* 1 = 0.380334 loss)
I0528 19:21:31.868923 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151671 (* 1 = 0.0151671 loss)
I0528 19:21:31.868929 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207102 (* 1 = 0.0207102 loss)
I0528 19:21:31.868937 10644 sgd_solver.cpp:106] Iteration 3240, lr = 0.0002
I0528 19:22:20.572253 10644 solver.cpp:228] Iteration 3260, loss = 0.343805
I0528 19:22:20.572278 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 19:22:20.572284 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115036 (* 1 = 0.115036 loss)
I0528 19:22:20.572288 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.223028 (* 1 = 0.223028 loss)
I0528 19:22:20.572293 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234611 (* 1 = 0.0234611 loss)
I0528 19:22:20.572295 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240641 (* 1 = 0.0240641 loss)
I0528 19:22:20.572300 10644 sgd_solver.cpp:106] Iteration 3260, lr = 0.0002
I0528 19:23:09.302711 10644 solver.cpp:228] Iteration 3280, loss = 0.260107
I0528 19:23:09.302736 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 19:23:09.302744 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.12554 (* 1 = 0.12554 loss)
I0528 19:23:09.302748 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.322239 (* 1 = 0.322239 loss)
I0528 19:23:09.302752 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0677761 (* 1 = 0.0677761 loss)
I0528 19:23:09.302755 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153657 (* 1 = 0.153657 loss)
I0528 19:23:09.302762 10644 sgd_solver.cpp:106] Iteration 3280, lr = 0.0002
I0528 19:23:58.109175 10644 solver.cpp:228] Iteration 3300, loss = 0.40941
I0528 19:23:58.109207 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0528 19:23:58.109216 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.306546 (* 1 = 0.306546 loss)
I0528 19:23:58.109220 10644 solver.cpp:244]     Train net output #2: loss_cls = 1.10797 (* 1 = 1.10797 loss)
I0528 19:23:58.109225 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.052553 (* 1 = 0.052553 loss)
I0528 19:23:58.109227 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107594 (* 1 = 0.107594 loss)
I0528 19:23:58.109233 10644 sgd_solver.cpp:106] Iteration 3300, lr = 0.0002
I0528 19:24:46.812595 10644 solver.cpp:228] Iteration 3320, loss = 0.438852
I0528 19:24:46.812628 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 19:24:46.812634 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.158636 (* 1 = 0.158636 loss)
I0528 19:24:46.812639 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.211983 (* 1 = 0.211983 loss)
I0528 19:24:46.812644 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956899 (* 1 = 0.00956899 loss)
I0528 19:24:46.812647 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.046362 (* 1 = 0.046362 loss)
I0528 19:24:46.812654 10644 sgd_solver.cpp:106] Iteration 3320, lr = 0.0002
I0528 19:25:35.384765 10644 solver.cpp:228] Iteration 3340, loss = 0.403942
I0528 19:25:35.384801 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 19:25:35.384811 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181141 (* 1 = 0.0181141 loss)
I0528 19:25:35.384816 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120466 (* 1 = 0.120466 loss)
I0528 19:25:35.384820 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027137 (* 1 = 0.027137 loss)
I0528 19:25:35.384824 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161965 (* 1 = 0.0161965 loss)
I0528 19:25:35.384831 10644 sgd_solver.cpp:106] Iteration 3340, lr = 0.0002
I0528 19:26:24.068380 10644 solver.cpp:228] Iteration 3360, loss = 0.464538
I0528 19:26:24.068410 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:26:24.068419 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843138 (* 1 = 0.0843138 loss)
I0528 19:26:24.068425 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1865 (* 1 = 0.1865 loss)
I0528 19:26:24.068431 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.114988 (* 1 = 0.114988 loss)
I0528 19:26:24.068436 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0499621 (* 1 = 0.0499621 loss)
I0528 19:26:24.068444 10644 sgd_solver.cpp:106] Iteration 3360, lr = 0.0002
I0528 19:27:12.622464 10644 solver.cpp:228] Iteration 3380, loss = 0.50951
I0528 19:27:12.622489 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 19:27:12.622498 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0783742 (* 1 = 0.0783742 loss)
I0528 19:27:12.622501 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.23528 (* 1 = 0.23528 loss)
I0528 19:27:12.622504 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0708382 (* 1 = 0.0708382 loss)
I0528 19:27:12.622508 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0455918 (* 1 = 0.0455918 loss)
I0528 19:27:12.622514 10644 sgd_solver.cpp:106] Iteration 3380, lr = 0.0002
speed: 2.430s / iter
I0528 19:28:01.171622 10644 solver.cpp:228] Iteration 3400, loss = 0.247599
I0528 19:28:01.171658 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 19:28:01.171667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.083922 (* 1 = 0.083922 loss)
I0528 19:28:01.171672 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.213645 (* 1 = 0.213645 loss)
I0528 19:28:01.171676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013829 (* 1 = 0.013829 loss)
I0528 19:28:01.171679 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331161 (* 1 = 0.0331161 loss)
I0528 19:28:01.171684 10644 sgd_solver.cpp:106] Iteration 3400, lr = 0.0002
I0528 19:28:49.743563 10644 solver.cpp:228] Iteration 3420, loss = 0.326412
I0528 19:28:49.743592 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:28:49.743600 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318209 (* 1 = 0.0318209 loss)
I0528 19:28:49.743604 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.14884 (* 1 = 0.14884 loss)
I0528 19:28:49.743608 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196264 (* 1 = 0.0196264 loss)
I0528 19:28:49.743613 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225252 (* 1 = 0.0225252 loss)
I0528 19:28:49.743618 10644 sgd_solver.cpp:106] Iteration 3420, lr = 0.0002
I0528 19:29:38.327618 10644 solver.cpp:228] Iteration 3440, loss = 0.39108
I0528 19:29:38.327649 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 19:29:38.327657 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272228 (* 1 = 0.0272228 loss)
I0528 19:29:38.327662 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0744274 (* 1 = 0.0744274 loss)
I0528 19:29:38.327666 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221648 (* 1 = 0.0221648 loss)
I0528 19:29:38.327670 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00432619 (* 1 = 0.00432619 loss)
I0528 19:29:38.327677 10644 sgd_solver.cpp:106] Iteration 3440, lr = 0.0002
I0528 19:30:27.062549 10644 solver.cpp:228] Iteration 3460, loss = 0.549735
I0528 19:30:27.062585 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 19:30:27.062593 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115875 (* 1 = 0.115875 loss)
I0528 19:30:27.062597 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.2296 (* 1 = 0.2296 loss)
I0528 19:30:27.062600 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024742 (* 1 = 0.024742 loss)
I0528 19:30:27.062604 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102271 (* 1 = 0.0102271 loss)
I0528 19:30:27.062610 10644 sgd_solver.cpp:106] Iteration 3460, lr = 0.0002
I0528 19:31:16.053108 10644 solver.cpp:228] Iteration 3480, loss = 0.318687
I0528 19:31:16.053135 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:31:16.053143 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0581288 (* 1 = 0.0581288 loss)
I0528 19:31:16.053148 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157153 (* 1 = 0.157153 loss)
I0528 19:31:16.053150 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164022 (* 1 = 0.0164022 loss)
I0528 19:31:16.053154 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137961 (* 1 = 0.0137961 loss)
I0528 19:31:16.053159 10644 sgd_solver.cpp:106] Iteration 3480, lr = 0.0002
I0528 19:32:04.880882 10644 solver.cpp:228] Iteration 3500, loss = 0.313453
I0528 19:32:04.880908 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 19:32:04.880920 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.09913 (* 1 = 0.09913 loss)
I0528 19:32:04.880924 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.153443 (* 1 = 0.153443 loss)
I0528 19:32:04.880929 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00815106 (* 1 = 0.00815106 loss)
I0528 19:32:04.880933 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00952966 (* 1 = 0.00952966 loss)
I0528 19:32:04.880939 10644 sgd_solver.cpp:106] Iteration 3500, lr = 0.0002
I0528 19:32:53.622505 10644 solver.cpp:228] Iteration 3520, loss = 0.253419
I0528 19:32:53.622531 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:32:53.622537 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00368731 (* 1 = 0.00368731 loss)
I0528 19:32:53.622542 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0800509 (* 1 = 0.0800509 loss)
I0528 19:32:53.622545 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0504746 (* 1 = 0.0504746 loss)
I0528 19:32:53.622550 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168645 (* 1 = 0.0168645 loss)
I0528 19:32:53.622555 10644 sgd_solver.cpp:106] Iteration 3520, lr = 0.0002
I0528 19:33:42.449262 10644 solver.cpp:228] Iteration 3540, loss = 0.352323
I0528 19:33:42.449286 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 19:33:42.449295 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0403146 (* 1 = 0.0403146 loss)
I0528 19:33:42.449298 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.249521 (* 1 = 0.249521 loss)
I0528 19:33:42.449302 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208773 (* 1 = 0.0208773 loss)
I0528 19:33:42.449306 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114486 (* 1 = 0.0114486 loss)
I0528 19:33:42.449311 10644 sgd_solver.cpp:106] Iteration 3540, lr = 0.0002
I0528 19:34:31.265283 10644 solver.cpp:228] Iteration 3560, loss = 0.247179
I0528 19:34:31.265306 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 19:34:31.265313 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166006 (* 1 = 0.0166006 loss)
I0528 19:34:31.265317 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.132708 (* 1 = 0.132708 loss)
I0528 19:34:31.265321 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140042 (* 1 = 0.0140042 loss)
I0528 19:34:31.265324 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0507775 (* 1 = 0.0507775 loss)
I0528 19:34:31.265329 10644 sgd_solver.cpp:106] Iteration 3560, lr = 0.0002
I0528 19:35:20.038959 10644 solver.cpp:228] Iteration 3580, loss = 0.406082
I0528 19:35:20.038983 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:35:20.038991 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0469024 (* 1 = 0.0469024 loss)
I0528 19:35:20.038997 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.22199 (* 1 = 0.22199 loss)
I0528 19:35:20.039005 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00979486 (* 1 = 0.00979486 loss)
I0528 19:35:20.039010 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00911973 (* 1 = 0.00911973 loss)
I0528 19:35:20.039014 10644 sgd_solver.cpp:106] Iteration 3580, lr = 0.0002
speed: 2.431s / iter
I0528 19:36:08.851531 10644 solver.cpp:228] Iteration 3600, loss = 0.391822
I0528 19:36:08.851557 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:36:08.851567 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0367828 (* 1 = 0.0367828 loss)
I0528 19:36:08.851572 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160094 (* 1 = 0.160094 loss)
I0528 19:36:08.851577 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0470211 (* 1 = 0.0470211 loss)
I0528 19:36:08.851583 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481526 (* 1 = 0.0481526 loss)
I0528 19:36:08.851588 10644 sgd_solver.cpp:106] Iteration 3600, lr = 0.0002
I0528 19:36:57.489032 10644 solver.cpp:228] Iteration 3620, loss = 0.434347
I0528 19:36:57.489060 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 19:36:57.489068 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0792651 (* 1 = 0.0792651 loss)
I0528 19:36:57.489073 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.21913 (* 1 = 0.21913 loss)
I0528 19:36:57.489076 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577673 (* 1 = 0.00577673 loss)
I0528 19:36:57.489080 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0416264 (* 1 = 0.0416264 loss)
I0528 19:36:57.489086 10644 sgd_solver.cpp:106] Iteration 3620, lr = 0.0002
I0528 19:37:46.233631 10644 solver.cpp:228] Iteration 3640, loss = 0.806864
I0528 19:37:46.233656 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 19:37:46.233662 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204427 (* 1 = 0.0204427 loss)
I0528 19:37:46.233667 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0963051 (* 1 = 0.0963051 loss)
I0528 19:37:46.233670 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00773363 (* 1 = 0.00773363 loss)
I0528 19:37:46.233675 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293082 (* 1 = 0.0293082 loss)
I0528 19:37:46.233680 10644 sgd_solver.cpp:106] Iteration 3640, lr = 0.0002
I0528 19:38:34.926820 10644 solver.cpp:228] Iteration 3660, loss = 0.535456
I0528 19:38:34.926861 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:38:34.926869 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0718663 (* 1 = 0.0718663 loss)
I0528 19:38:34.926873 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.123148 (* 1 = 0.123148 loss)
I0528 19:38:34.926878 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00515475 (* 1 = 0.00515475 loss)
I0528 19:38:34.926882 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100933 (* 1 = 0.0100933 loss)
I0528 19:38:34.926890 10644 sgd_solver.cpp:106] Iteration 3660, lr = 0.0002
I0528 19:39:23.547942 10644 solver.cpp:228] Iteration 3680, loss = 0.326894
I0528 19:39:23.547972 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:39:23.547981 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384458 (* 1 = 0.0384458 loss)
I0528 19:39:23.547988 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.206872 (* 1 = 0.206872 loss)
I0528 19:39:23.547994 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012908 (* 1 = 0.012908 loss)
I0528 19:39:23.548000 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102862 (* 1 = 0.0102862 loss)
I0528 19:39:23.548007 10644 sgd_solver.cpp:106] Iteration 3680, lr = 0.0002
I0528 19:40:12.228453 10644 solver.cpp:228] Iteration 3700, loss = 0.433062
I0528 19:40:12.228480 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:40:12.228489 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498853 (* 1 = 0.0498853 loss)
I0528 19:40:12.228495 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.165687 (* 1 = 0.165687 loss)
I0528 19:40:12.228500 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0253437 (* 1 = 0.0253437 loss)
I0528 19:40:12.228505 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228249 (* 1 = 0.0228249 loss)
I0528 19:40:12.228513 10644 sgd_solver.cpp:106] Iteration 3700, lr = 0.0002
I0528 19:41:00.926625 10644 solver.cpp:228] Iteration 3720, loss = 0.293855
I0528 19:41:00.926654 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:41:00.926664 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113285 (* 1 = 0.0113285 loss)
I0528 19:41:00.926671 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0892619 (* 1 = 0.0892619 loss)
I0528 19:41:00.926676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128759 (* 1 = 0.0128759 loss)
I0528 19:41:00.926681 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00787762 (* 1 = 0.00787762 loss)
I0528 19:41:00.926687 10644 sgd_solver.cpp:106] Iteration 3720, lr = 0.0002
I0528 19:41:49.626283 10644 solver.cpp:228] Iteration 3740, loss = 0.294905
I0528 19:41:49.626308 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 19:41:49.626315 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.126231 (* 1 = 0.126231 loss)
I0528 19:41:49.626319 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.258945 (* 1 = 0.258945 loss)
I0528 19:41:49.626323 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262634 (* 1 = 0.0262634 loss)
I0528 19:41:49.626327 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259982 (* 1 = 0.0259982 loss)
I0528 19:41:49.626332 10644 sgd_solver.cpp:106] Iteration 3740, lr = 0.0002
I0528 19:42:38.188480 10644 solver.cpp:228] Iteration 3760, loss = 0.2424
I0528 19:42:38.188506 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:42:38.188513 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0585725 (* 1 = 0.0585725 loss)
I0528 19:42:38.188516 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0877122 (* 1 = 0.0877122 loss)
I0528 19:42:38.188520 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00669595 (* 1 = 0.00669595 loss)
I0528 19:42:38.188524 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102396 (* 1 = 0.0102396 loss)
I0528 19:42:38.188529 10644 sgd_solver.cpp:106] Iteration 3760, lr = 0.0002
I0528 19:43:26.836182 10644 solver.cpp:228] Iteration 3780, loss = 0.278519
I0528 19:43:26.836210 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:43:26.836218 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465515 (* 1 = 0.0465515 loss)
I0528 19:43:26.836222 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.173557 (* 1 = 0.173557 loss)
I0528 19:43:26.836226 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0295934 (* 1 = 0.0295934 loss)
I0528 19:43:26.836230 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300928 (* 1 = 0.0300928 loss)
I0528 19:43:26.836236 10644 sgd_solver.cpp:106] Iteration 3780, lr = 0.0002
speed: 2.431s / iter
I0528 19:44:15.404144 10644 solver.cpp:228] Iteration 3800, loss = 0.32179
I0528 19:44:15.404170 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 19:44:15.404177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0411261 (* 1 = 0.0411261 loss)
I0528 19:44:15.404182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112914 (* 1 = 0.112914 loss)
I0528 19:44:15.404186 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00881288 (* 1 = 0.00881288 loss)
I0528 19:44:15.404191 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132638 (* 1 = 0.0132638 loss)
I0528 19:44:15.404196 10644 sgd_solver.cpp:106] Iteration 3800, lr = 0.0002
I0528 19:45:03.968647 10644 solver.cpp:228] Iteration 3820, loss = 0.311048
I0528 19:45:03.968672 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 19:45:03.968679 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562579 (* 1 = 0.0562579 loss)
I0528 19:45:03.968684 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151918 (* 1 = 0.151918 loss)
I0528 19:45:03.968688 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00845311 (* 1 = 0.00845311 loss)
I0528 19:45:03.968693 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237443 (* 1 = 0.0237443 loss)
I0528 19:45:03.968698 10644 sgd_solver.cpp:106] Iteration 3820, lr = 0.0002
I0528 19:45:52.526289 10644 solver.cpp:228] Iteration 3840, loss = 0.35055
I0528 19:45:52.526319 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:45:52.526327 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295736 (* 1 = 0.0295736 loss)
I0528 19:45:52.526332 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114515 (* 1 = 0.114515 loss)
I0528 19:45:52.526335 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219348 (* 1 = 0.0219348 loss)
I0528 19:45:52.526340 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0921633 (* 1 = 0.0921633 loss)
I0528 19:45:52.526345 10644 sgd_solver.cpp:106] Iteration 3840, lr = 0.0002
I0528 19:46:41.070530 10644 solver.cpp:228] Iteration 3860, loss = 0.253611
I0528 19:46:41.070556 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 19:46:41.070564 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.108279 (* 1 = 0.108279 loss)
I0528 19:46:41.070569 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.210455 (* 1 = 0.210455 loss)
I0528 19:46:41.070574 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00917998 (* 1 = 0.00917998 loss)
I0528 19:46:41.070576 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142808 (* 1 = 0.0142808 loss)
I0528 19:46:41.070582 10644 sgd_solver.cpp:106] Iteration 3860, lr = 0.0002
I0528 19:47:29.637552 10644 solver.cpp:228] Iteration 3880, loss = 0.283677
I0528 19:47:29.637578 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:47:29.637585 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00331275 (* 1 = 0.00331275 loss)
I0528 19:47:29.637590 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.105108 (* 1 = 0.105108 loss)
I0528 19:47:29.637594 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119095 (* 1 = 0.0119095 loss)
I0528 19:47:29.637598 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213801 (* 1 = 0.0213801 loss)
I0528 19:47:29.637603 10644 sgd_solver.cpp:106] Iteration 3880, lr = 0.0002
I0528 19:48:18.274695 10644 solver.cpp:228] Iteration 3900, loss = 0.479523
I0528 19:48:18.274722 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:48:18.274729 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0581277 (* 1 = 0.0581277 loss)
I0528 19:48:18.274734 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170288 (* 1 = 0.170288 loss)
I0528 19:48:18.274737 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0194559 (* 1 = 0.0194559 loss)
I0528 19:48:18.274741 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315643 (* 1 = 0.0315643 loss)
I0528 19:48:18.274746 10644 sgd_solver.cpp:106] Iteration 3900, lr = 0.0002
I0528 19:49:06.856688 10644 solver.cpp:228] Iteration 3920, loss = 0.340201
I0528 19:49:06.856714 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0528 19:49:06.856721 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.300216 (* 1 = 0.300216 loss)
I0528 19:49:06.856725 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.584829 (* 1 = 0.584829 loss)
I0528 19:49:06.856729 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0307534 (* 1 = 0.0307534 loss)
I0528 19:49:06.856732 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443559 (* 1 = 0.0443559 loss)
I0528 19:49:06.856739 10644 sgd_solver.cpp:106] Iteration 3920, lr = 0.0002
I0528 19:49:55.441962 10644 solver.cpp:228] Iteration 3940, loss = 0.334446
I0528 19:49:55.441988 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 19:49:55.441995 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224744 (* 1 = 0.0224744 loss)
I0528 19:49:55.442000 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.11432 (* 1 = 0.11432 loss)
I0528 19:49:55.442004 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017603 (* 1 = 0.017603 loss)
I0528 19:49:55.442008 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.048777 (* 1 = 0.048777 loss)
I0528 19:49:55.442013 10644 sgd_solver.cpp:106] Iteration 3940, lr = 0.0002
I0528 19:50:43.999447 10644 solver.cpp:228] Iteration 3960, loss = 0.798701
I0528 19:50:43.999470 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:50:43.999477 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262756 (* 1 = 0.0262756 loss)
I0528 19:50:43.999481 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0905736 (* 1 = 0.0905736 loss)
I0528 19:50:43.999485 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191537 (* 1 = 0.0191537 loss)
I0528 19:50:43.999488 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137985 (* 1 = 0.0137985 loss)
I0528 19:50:43.999492 10644 sgd_solver.cpp:106] Iteration 3960, lr = 0.0002
I0528 19:51:32.634979 10644 solver.cpp:228] Iteration 3980, loss = 0.864671
I0528 19:51:32.635004 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:51:32.635010 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.022199 (* 1 = 0.022199 loss)
I0528 19:51:32.635015 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10308 (* 1 = 0.10308 loss)
I0528 19:51:32.635018 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00557298 (* 1 = 0.00557298 loss)
I0528 19:51:32.635021 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116478 (* 1 = 0.0116478 loss)
I0528 19:51:32.635026 10644 sgd_solver.cpp:106] Iteration 3980, lr = 0.0002
speed: 2.431s / iter
I0528 19:52:21.195493 10644 solver.cpp:228] Iteration 4000, loss = 0.355879
I0528 19:52:21.195519 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 19:52:21.195528 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0753542 (* 1 = 0.0753542 loss)
I0528 19:52:21.195531 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101676 (* 1 = 0.101676 loss)
I0528 19:52:21.195534 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807959 (* 1 = 0.00807959 loss)
I0528 19:52:21.195538 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00927007 (* 1 = 0.00927007 loss)
I0528 19:52:21.195544 10644 sgd_solver.cpp:106] Iteration 4000, lr = 0.0002
I0528 19:53:09.740633 10644 solver.cpp:228] Iteration 4020, loss = 0.614056
I0528 19:53:09.740660 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0528 19:53:09.740669 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.335427 (* 1 = 0.335427 loss)
I0528 19:53:09.740672 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.454433 (* 1 = 0.454433 loss)
I0528 19:53:09.740675 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0859054 (* 1 = 0.0859054 loss)
I0528 19:53:09.740679 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.147825 (* 1 = 0.147825 loss)
I0528 19:53:09.740684 10644 sgd_solver.cpp:106] Iteration 4020, lr = 0.0002
I0528 19:53:58.250524 10644 solver.cpp:228] Iteration 4040, loss = 0.305761
I0528 19:53:58.250550 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 19:53:58.250557 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0152895 (* 1 = 0.0152895 loss)
I0528 19:53:58.250562 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0664868 (* 1 = 0.0664868 loss)
I0528 19:53:58.250566 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00999267 (* 1 = 0.00999267 loss)
I0528 19:53:58.250569 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134632 (* 1 = 0.0134632 loss)
I0528 19:53:58.250576 10644 sgd_solver.cpp:106] Iteration 4040, lr = 0.0002
I0528 19:54:46.806080 10644 solver.cpp:228] Iteration 4060, loss = 0.321937
I0528 19:54:46.806107 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 19:54:46.806115 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286595 (* 1 = 0.0286595 loss)
I0528 19:54:46.806119 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109959 (* 1 = 0.109959 loss)
I0528 19:54:46.806124 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00804662 (* 1 = 0.00804662 loss)
I0528 19:54:46.806128 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149107 (* 1 = 0.0149107 loss)
I0528 19:54:46.806133 10644 sgd_solver.cpp:106] Iteration 4060, lr = 0.0002
I0528 19:55:35.364403 10644 solver.cpp:228] Iteration 4080, loss = 0.385197
I0528 19:55:35.364429 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 19:55:35.364439 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.234671 (* 1 = 0.234671 loss)
I0528 19:55:35.364445 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.387728 (* 1 = 0.387728 loss)
I0528 19:55:35.364450 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0580971 (* 1 = 0.0580971 loss)
I0528 19:55:35.364457 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.331079 (* 1 = 0.331079 loss)
I0528 19:55:35.364464 10644 sgd_solver.cpp:106] Iteration 4080, lr = 0.0002
I0528 19:56:23.971700 10644 solver.cpp:228] Iteration 4100, loss = 0.552764
I0528 19:56:23.971727 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 19:56:23.971738 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.224379 (* 1 = 0.224379 loss)
I0528 19:56:23.971745 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.452122 (* 1 = 0.452122 loss)
I0528 19:56:23.971750 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0405238 (* 1 = 0.0405238 loss)
I0528 19:56:23.971756 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117349 (* 1 = 0.117349 loss)
I0528 19:56:23.971763 10644 sgd_solver.cpp:106] Iteration 4100, lr = 0.0002
I0528 19:57:12.596176 10644 solver.cpp:228] Iteration 4120, loss = 0.338068
I0528 19:57:12.596201 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 19:57:12.596210 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.292592 (* 1 = 0.292592 loss)
I0528 19:57:12.596213 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.374241 (* 1 = 0.374241 loss)
I0528 19:57:12.596217 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0397037 (* 1 = 0.0397037 loss)
I0528 19:57:12.596221 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0582601 (* 1 = 0.0582601 loss)
I0528 19:57:12.596226 10644 sgd_solver.cpp:106] Iteration 4120, lr = 0.0002
I0528 19:58:01.154314 10644 solver.cpp:228] Iteration 4140, loss = 0.39387
I0528 19:58:01.154351 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:58:01.154366 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0394963 (* 1 = 0.0394963 loss)
I0528 19:58:01.154374 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.15919 (* 1 = 0.15919 loss)
I0528 19:58:01.154381 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0781774 (* 1 = 0.0781774 loss)
I0528 19:58:01.154388 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433877 (* 1 = 0.0433877 loss)
I0528 19:58:01.154431 10644 sgd_solver.cpp:106] Iteration 4140, lr = 0.0002
I0528 19:58:49.789970 10644 solver.cpp:228] Iteration 4160, loss = 0.431019
I0528 19:58:49.789996 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 19:58:49.790004 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433338 (* 1 = 0.0433338 loss)
I0528 19:58:49.790009 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0955673 (* 1 = 0.0955673 loss)
I0528 19:58:49.790014 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00937462 (* 1 = 0.00937462 loss)
I0528 19:58:49.790017 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118332 (* 1 = 0.0118332 loss)
I0528 19:58:49.790022 10644 sgd_solver.cpp:106] Iteration 4160, lr = 0.0002
I0528 19:59:38.528630 10644 solver.cpp:228] Iteration 4180, loss = 0.442274
I0528 19:59:38.528657 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 19:59:38.528667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0883655 (* 1 = 0.0883655 loss)
I0528 19:59:38.528672 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.173676 (* 1 = 0.173676 loss)
I0528 19:59:38.528676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0607625 (* 1 = 0.0607625 loss)
I0528 19:59:38.528681 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345722 (* 1 = 0.0345722 loss)
I0528 19:59:38.528687 10644 sgd_solver.cpp:106] Iteration 4180, lr = 0.0002
speed: 2.431s / iter
I0528 20:00:27.294126 10644 solver.cpp:228] Iteration 4200, loss = 0.343976
I0528 20:00:27.294162 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:00:27.294173 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549612 (* 1 = 0.0549612 loss)
I0528 20:00:27.294180 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.238559 (* 1 = 0.238559 loss)
I0528 20:00:27.294186 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182922 (* 1 = 0.0182922 loss)
I0528 20:00:27.294193 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0037547 (* 1 = 0.0037547 loss)
I0528 20:00:27.294201 10644 sgd_solver.cpp:106] Iteration 4200, lr = 0.0002
I0528 20:01:16.022763 10644 solver.cpp:228] Iteration 4220, loss = 0.169041
I0528 20:01:16.022789 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:01:16.022799 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176328 (* 1 = 0.0176328 loss)
I0528 20:01:16.022805 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.076787 (* 1 = 0.076787 loss)
I0528 20:01:16.022811 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120291 (* 1 = 0.0120291 loss)
I0528 20:01:16.022817 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155309 (* 1 = 0.0155309 loss)
I0528 20:01:16.022825 10644 sgd_solver.cpp:106] Iteration 4220, lr = 0.0002
I0528 20:02:04.837863 10644 solver.cpp:228] Iteration 4240, loss = 0.49097
I0528 20:02:04.837899 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 20:02:04.837910 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.266569 (* 1 = 0.266569 loss)
I0528 20:02:04.837915 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.445555 (* 1 = 0.445555 loss)
I0528 20:02:04.837921 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197603 (* 1 = 0.0197603 loss)
I0528 20:02:04.837926 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683453 (* 1 = 0.0683453 loss)
I0528 20:02:04.837935 10644 sgd_solver.cpp:106] Iteration 4240, lr = 0.0002
I0528 20:02:53.582787 10644 solver.cpp:228] Iteration 4260, loss = 0.377286
I0528 20:02:53.582814 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:02:53.582825 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258352 (* 1 = 0.0258352 loss)
I0528 20:02:53.582832 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0592041 (* 1 = 0.0592041 loss)
I0528 20:02:53.582839 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156022 (* 1 = 0.0156022 loss)
I0528 20:02:53.582844 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140185 (* 1 = 0.0140185 loss)
I0528 20:02:53.582851 10644 sgd_solver.cpp:106] Iteration 4260, lr = 0.0002
I0528 20:03:42.302050 10644 solver.cpp:228] Iteration 4280, loss = 0.363556
I0528 20:03:42.302076 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 20:03:42.302083 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587411 (* 1 = 0.0587411 loss)
I0528 20:03:42.302088 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170853 (* 1 = 0.170853 loss)
I0528 20:03:42.302091 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165107 (* 1 = 0.0165107 loss)
I0528 20:03:42.302094 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301447 (* 1 = 0.0301447 loss)
I0528 20:03:42.302099 10644 sgd_solver.cpp:106] Iteration 4280, lr = 0.0002
I0528 20:04:31.217252 10644 solver.cpp:228] Iteration 4300, loss = 0.429354
I0528 20:04:31.217281 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:04:31.217289 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0364206 (* 1 = 0.0364206 loss)
I0528 20:04:31.217294 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0904697 (* 1 = 0.0904697 loss)
I0528 20:04:31.217298 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153859 (* 1 = 0.0153859 loss)
I0528 20:04:31.217303 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119651 (* 1 = 0.0119651 loss)
I0528 20:04:31.217308 10644 sgd_solver.cpp:106] Iteration 4300, lr = 0.0002
I0528 20:05:19.829432 10644 solver.cpp:228] Iteration 4320, loss = 0.313459
I0528 20:05:19.829458 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:05:19.829466 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259435 (* 1 = 0.0259435 loss)
I0528 20:05:19.829470 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.093529 (* 1 = 0.093529 loss)
I0528 20:05:19.829474 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.041666 (* 1 = 0.041666 loss)
I0528 20:05:19.829478 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221213 (* 1 = 0.0221213 loss)
I0528 20:05:19.829483 10644 sgd_solver.cpp:106] Iteration 4320, lr = 0.0002
I0528 20:06:08.459054 10644 solver.cpp:228] Iteration 4340, loss = 0.35018
I0528 20:06:08.459084 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:06:08.459091 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00124271 (* 1 = 0.00124271 loss)
I0528 20:06:08.459096 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0777747 (* 1 = 0.0777747 loss)
I0528 20:06:08.459100 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293094 (* 1 = 0.0293094 loss)
I0528 20:06:08.459103 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.074872 (* 1 = 0.074872 loss)
I0528 20:06:08.459110 10644 sgd_solver.cpp:106] Iteration 4340, lr = 0.0002
I0528 20:06:57.250541 10644 solver.cpp:228] Iteration 4360, loss = 0.237534
I0528 20:06:57.250566 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 20:06:57.250573 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432938 (* 1 = 0.0432938 loss)
I0528 20:06:57.250577 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0948386 (* 1 = 0.0948386 loss)
I0528 20:06:57.250581 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00985516 (* 1 = 0.00985516 loss)
I0528 20:06:57.250584 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325625 (* 1 = 0.0325625 loss)
I0528 20:06:57.250589 10644 sgd_solver.cpp:106] Iteration 4360, lr = 0.0002
I0528 20:07:45.887818 10644 solver.cpp:228] Iteration 4380, loss = 0.356767
I0528 20:07:45.887847 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 20:07:45.887856 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0462984 (* 1 = 0.0462984 loss)
I0528 20:07:45.887861 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.221779 (* 1 = 0.221779 loss)
I0528 20:07:45.887864 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148253 (* 1 = 0.0148253 loss)
I0528 20:07:45.887867 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177248 (* 1 = 0.0177248 loss)
I0528 20:07:45.887873 10644 sgd_solver.cpp:106] Iteration 4380, lr = 0.0002
speed: 2.431s / iter
I0528 20:08:34.460330 10644 solver.cpp:228] Iteration 4400, loss = 0.46607
I0528 20:08:34.460356 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:08:34.460363 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.024238 (* 1 = 0.024238 loss)
I0528 20:08:34.460367 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0847934 (* 1 = 0.0847934 loss)
I0528 20:08:34.460371 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116429 (* 1 = 0.0116429 loss)
I0528 20:08:34.460376 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138429 (* 1 = 0.0138429 loss)
I0528 20:08:34.460381 10644 sgd_solver.cpp:106] Iteration 4400, lr = 0.0002
I0528 20:09:23.027633 10644 solver.cpp:228] Iteration 4420, loss = 0.458134
I0528 20:09:23.027660 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:09:23.027668 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128861 (* 1 = 0.0128861 loss)
I0528 20:09:23.027673 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0799894 (* 1 = 0.0799894 loss)
I0528 20:09:23.027675 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016729 (* 1 = 0.016729 loss)
I0528 20:09:23.027678 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127538 (* 1 = 0.0127538 loss)
I0528 20:09:23.027684 10644 sgd_solver.cpp:106] Iteration 4420, lr = 0.0002
I0528 20:10:11.555863 10644 solver.cpp:228] Iteration 4440, loss = 0.27882
I0528 20:10:11.555894 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 20:10:11.555904 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0338545 (* 1 = 0.0338545 loss)
I0528 20:10:11.555910 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145019 (* 1 = 0.145019 loss)
I0528 20:10:11.555915 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00914499 (* 1 = 0.00914499 loss)
I0528 20:10:11.555920 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024468 (* 1 = 0.024468 loss)
I0528 20:10:11.555927 10644 sgd_solver.cpp:106] Iteration 4440, lr = 0.0002
I0528 20:11:00.194208 10644 solver.cpp:228] Iteration 4460, loss = 0.471849
I0528 20:11:00.194236 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 20:11:00.194242 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590133 (* 1 = 0.0590133 loss)
I0528 20:11:00.194247 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128027 (* 1 = 0.128027 loss)
I0528 20:11:00.194252 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234506 (* 1 = 0.0234506 loss)
I0528 20:11:00.194254 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0347734 (* 1 = 0.0347734 loss)
I0528 20:11:00.194260 10644 sgd_solver.cpp:106] Iteration 4460, lr = 0.0002
I0528 20:11:49.179378 10644 solver.cpp:228] Iteration 4480, loss = 0.303356
I0528 20:11:49.179404 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 20:11:49.179412 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.22104 (* 1 = 0.22104 loss)
I0528 20:11:49.179419 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.32847 (* 1 = 0.32847 loss)
I0528 20:11:49.179424 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120721 (* 1 = 0.0120721 loss)
I0528 20:11:49.179428 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0523049 (* 1 = 0.0523049 loss)
I0528 20:11:49.179435 10644 sgd_solver.cpp:106] Iteration 4480, lr = 0.0002
I0528 20:12:37.964218 10644 solver.cpp:228] Iteration 4500, loss = 0.336704
I0528 20:12:37.964259 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:12:37.964269 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0313153 (* 1 = 0.0313153 loss)
I0528 20:12:37.964274 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0891612 (* 1 = 0.0891612 loss)
I0528 20:12:37.964277 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108825 (* 1 = 0.0108825 loss)
I0528 20:12:37.964282 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115062 (* 1 = 0.0115062 loss)
I0528 20:12:37.964289 10644 sgd_solver.cpp:106] Iteration 4500, lr = 0.0002
I0528 20:13:26.817425 10644 solver.cpp:228] Iteration 4520, loss = 0.276443
I0528 20:13:26.817454 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:13:26.817464 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00322078 (* 1 = 0.00322078 loss)
I0528 20:13:26.817471 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0586334 (* 1 = 0.0586334 loss)
I0528 20:13:26.817476 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263538 (* 1 = 0.0263538 loss)
I0528 20:13:26.817481 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303257 (* 1 = 0.0303257 loss)
I0528 20:13:26.817487 10644 sgd_solver.cpp:106] Iteration 4520, lr = 0.0002
I0528 20:14:15.734201 10644 solver.cpp:228] Iteration 4540, loss = 0.600932
I0528 20:14:15.734227 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:14:15.734235 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00364674 (* 1 = 0.00364674 loss)
I0528 20:14:15.734237 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0752577 (* 1 = 0.0752577 loss)
I0528 20:14:15.734241 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261804 (* 1 = 0.0261804 loss)
I0528 20:14:15.734244 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0409468 (* 1 = 0.0409468 loss)
I0528 20:14:15.734248 10644 sgd_solver.cpp:106] Iteration 4540, lr = 0.0002
I0528 20:15:04.382372 10644 solver.cpp:228] Iteration 4560, loss = 0.433549
I0528 20:15:04.382400 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 20:15:04.382408 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614594 (* 1 = 0.0614594 loss)
I0528 20:15:04.382412 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101435 (* 1 = 0.101435 loss)
I0528 20:15:04.382416 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00515165 (* 1 = 0.00515165 loss)
I0528 20:15:04.382419 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113805 (* 1 = 0.0113805 loss)
I0528 20:15:04.382424 10644 sgd_solver.cpp:106] Iteration 4560, lr = 0.0002
I0528 20:15:53.166643 10644 solver.cpp:228] Iteration 4580, loss = 0.304401
I0528 20:15:53.166674 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 20:15:53.166683 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.256413 (* 1 = 0.256413 loss)
I0528 20:15:53.166688 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.508812 (* 1 = 0.508812 loss)
I0528 20:15:53.166693 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0574705 (* 1 = 0.0574705 loss)
I0528 20:15:53.166697 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0660872 (* 1 = 0.0660872 loss)
I0528 20:15:53.166703 10644 sgd_solver.cpp:106] Iteration 4580, lr = 0.0002
speed: 2.431s / iter
I0528 20:16:41.909323 10644 solver.cpp:228] Iteration 4600, loss = 0.2123
I0528 20:16:41.909355 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:16:41.909364 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0177626 (* 1 = 0.0177626 loss)
I0528 20:16:41.909368 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0650026 (* 1 = 0.0650026 loss)
I0528 20:16:41.909373 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105397 (* 1 = 0.0105397 loss)
I0528 20:16:41.909377 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012709 (* 1 = 0.012709 loss)
I0528 20:16:41.909384 10644 sgd_solver.cpp:106] Iteration 4600, lr = 0.0002
I0528 20:17:30.478122 10644 solver.cpp:228] Iteration 4620, loss = 0.303544
I0528 20:17:30.478152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 20:17:30.478158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.135448 (* 1 = 0.135448 loss)
I0528 20:17:30.478163 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.335556 (* 1 = 0.335556 loss)
I0528 20:17:30.478166 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00974068 (* 1 = 0.00974068 loss)
I0528 20:17:30.478170 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419342 (* 1 = 0.0419342 loss)
I0528 20:17:30.478176 10644 sgd_solver.cpp:106] Iteration 4620, lr = 0.0002
I0528 20:18:19.182148 10644 solver.cpp:228] Iteration 4640, loss = 0.437869
I0528 20:18:19.182173 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 20:18:19.182179 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.133986 (* 1 = 0.133986 loss)
I0528 20:18:19.182183 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.296997 (* 1 = 0.296997 loss)
I0528 20:18:19.182186 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0290923 (* 1 = 0.0290923 loss)
I0528 20:18:19.182190 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401002 (* 1 = 0.0401002 loss)
I0528 20:18:19.182195 10644 sgd_solver.cpp:106] Iteration 4640, lr = 0.0002
I0528 20:19:07.818246 10644 solver.cpp:228] Iteration 4660, loss = 0.474169
I0528 20:19:07.818274 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 20:19:07.818282 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.103643 (* 1 = 0.103643 loss)
I0528 20:19:07.818287 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.302015 (* 1 = 0.302015 loss)
I0528 20:19:07.818290 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0227753 (* 1 = 0.0227753 loss)
I0528 20:19:07.818295 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402536 (* 1 = 0.0402536 loss)
I0528 20:19:07.818300 10644 sgd_solver.cpp:106] Iteration 4660, lr = 0.0002
I0528 20:19:56.503289 10644 solver.cpp:228] Iteration 4680, loss = 0.439354
I0528 20:19:56.503317 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:19:56.503325 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279522 (* 1 = 0.0279522 loss)
I0528 20:19:56.503329 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142722 (* 1 = 0.142722 loss)
I0528 20:19:56.503334 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00559815 (* 1 = 0.00559815 loss)
I0528 20:19:56.503337 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117503 (* 1 = 0.0117503 loss)
I0528 20:19:56.503342 10644 sgd_solver.cpp:106] Iteration 4680, lr = 0.0002
I0528 20:20:45.103014 10644 solver.cpp:228] Iteration 4700, loss = 0.44963
I0528 20:20:45.103039 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:20:45.103047 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191983 (* 1 = 0.0191983 loss)
I0528 20:20:45.103052 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.122983 (* 1 = 0.122983 loss)
I0528 20:20:45.103056 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00362649 (* 1 = 0.00362649 loss)
I0528 20:20:45.103060 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118393 (* 1 = 0.0118393 loss)
I0528 20:20:45.103066 10644 sgd_solver.cpp:106] Iteration 4700, lr = 0.0002
I0528 20:21:33.706210 10644 solver.cpp:228] Iteration 4720, loss = 0.273545
I0528 20:21:33.706236 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:21:33.706243 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268743 (* 1 = 0.0268743 loss)
I0528 20:21:33.706248 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0789879 (* 1 = 0.0789879 loss)
I0528 20:21:33.706251 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00469223 (* 1 = 0.00469223 loss)
I0528 20:21:33.706255 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205405 (* 1 = 0.0205405 loss)
I0528 20:21:33.706260 10644 sgd_solver.cpp:106] Iteration 4720, lr = 0.0002
I0528 20:22:22.218542 10644 solver.cpp:228] Iteration 4740, loss = 0.251904
I0528 20:22:22.218564 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 20:22:22.218571 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.157568 (* 1 = 0.157568 loss)
I0528 20:22:22.218575 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.301215 (* 1 = 0.301215 loss)
I0528 20:22:22.218580 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142767 (* 1 = 0.0142767 loss)
I0528 20:22:22.218583 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248598 (* 1 = 0.0248598 loss)
I0528 20:22:22.218588 10644 sgd_solver.cpp:106] Iteration 4740, lr = 0.0002
I0528 20:23:10.677925 10644 solver.cpp:228] Iteration 4760, loss = 0.22154
I0528 20:23:10.677954 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:23:10.677964 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0458453 (* 1 = 0.0458453 loss)
I0528 20:23:10.677971 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.129666 (* 1 = 0.129666 loss)
I0528 20:23:10.677978 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300239 (* 1 = 0.00300239 loss)
I0528 20:23:10.677983 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00539834 (* 1 = 0.00539834 loss)
I0528 20:23:10.677991 10644 sgd_solver.cpp:106] Iteration 4760, lr = 0.0002
I0528 20:23:59.370918 10644 solver.cpp:228] Iteration 4780, loss = 0.504172
I0528 20:23:59.370954 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 20:23:59.370965 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.168767 (* 1 = 0.168767 loss)
I0528 20:23:59.370973 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.432526 (* 1 = 0.432526 loss)
I0528 20:23:59.370981 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0298658 (* 1 = 0.0298658 loss)
I0528 20:23:59.370988 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0767288 (* 1 = 0.0767288 loss)
I0528 20:23:59.370997 10644 sgd_solver.cpp:106] Iteration 4780, lr = 0.0002
speed: 2.431s / iter
I0528 20:24:48.147866 10644 solver.cpp:228] Iteration 4800, loss = 0.665321
I0528 20:24:48.147897 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 20:24:48.147905 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.132672 (* 1 = 0.132672 loss)
I0528 20:24:48.147912 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.277496 (* 1 = 0.277496 loss)
I0528 20:24:48.147918 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262516 (* 1 = 0.0262516 loss)
I0528 20:24:48.147923 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434381 (* 1 = 0.0434381 loss)
I0528 20:24:48.147930 10644 sgd_solver.cpp:106] Iteration 4800, lr = 0.0002
I0528 20:25:36.779456 10644 solver.cpp:228] Iteration 4820, loss = 0.300123
I0528 20:25:36.779495 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 20:25:36.779506 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000111748 (* 1 = 0.000111748 loss)
I0528 20:25:36.779512 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0462735 (* 1 = 0.0462735 loss)
I0528 20:25:36.779517 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0339742 (* 1 = 0.0339742 loss)
I0528 20:25:36.779521 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03664 (* 1 = 0.03664 loss)
I0528 20:25:36.779531 10644 sgd_solver.cpp:106] Iteration 4820, lr = 0.0002
I0528 20:26:25.422997 10644 solver.cpp:228] Iteration 4840, loss = 0.444912
I0528 20:26:25.423022 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:26:25.423030 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0665813 (* 1 = 0.0665813 loss)
I0528 20:26:25.423035 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170088 (* 1 = 0.170088 loss)
I0528 20:26:25.423038 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508847 (* 1 = 0.00508847 loss)
I0528 20:26:25.423043 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227331 (* 1 = 0.0227331 loss)
I0528 20:26:25.423048 10644 sgd_solver.cpp:106] Iteration 4840, lr = 0.0002
I0528 20:27:13.950122 10644 solver.cpp:228] Iteration 4860, loss = 0.318172
I0528 20:27:13.950148 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:27:13.950158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.105254 (* 1 = 0.105254 loss)
I0528 20:27:13.950165 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.163707 (* 1 = 0.163707 loss)
I0528 20:27:13.950171 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.007636 (* 1 = 0.007636 loss)
I0528 20:27:13.950177 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00647388 (* 1 = 0.00647388 loss)
I0528 20:27:13.950184 10644 sgd_solver.cpp:106] Iteration 4860, lr = 0.0002
I0528 20:28:02.565579 10644 solver.cpp:228] Iteration 4880, loss = 0.342215
I0528 20:28:02.565603 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:28:02.565611 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537847 (* 1 = 0.0537847 loss)
I0528 20:28:02.565615 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136551 (* 1 = 0.136551 loss)
I0528 20:28:02.565618 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114705 (* 1 = 0.0114705 loss)
I0528 20:28:02.565623 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231137 (* 1 = 0.0231137 loss)
I0528 20:28:02.565627 10644 sgd_solver.cpp:106] Iteration 4880, lr = 0.0002
I0528 20:28:51.140708 10644 solver.cpp:228] Iteration 4900, loss = 0.361413
I0528 20:28:51.140738 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:28:51.140744 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390412 (* 1 = 0.0390412 loss)
I0528 20:28:51.140749 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115641 (* 1 = 0.115641 loss)
I0528 20:28:51.140753 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00261108 (* 1 = 0.00261108 loss)
I0528 20:28:51.140756 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127436 (* 1 = 0.0127436 loss)
I0528 20:28:51.140763 10644 sgd_solver.cpp:106] Iteration 4900, lr = 0.0002
I0528 20:29:39.677665 10644 solver.cpp:228] Iteration 4920, loss = 0.333753
I0528 20:29:39.677695 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:29:39.677703 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179721 (* 1 = 0.0179721 loss)
I0528 20:29:39.677711 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.073729 (* 1 = 0.073729 loss)
I0528 20:29:39.677716 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00750326 (* 1 = 0.00750326 loss)
I0528 20:29:39.677721 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00801968 (* 1 = 0.00801968 loss)
I0528 20:29:39.677727 10644 sgd_solver.cpp:106] Iteration 4920, lr = 0.0002
I0528 20:30:28.222635 10644 solver.cpp:228] Iteration 4940, loss = 0.362939
I0528 20:30:28.222659 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:30:28.222666 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0348074 (* 1 = 0.0348074 loss)
I0528 20:30:28.222671 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0958104 (* 1 = 0.0958104 loss)
I0528 20:30:28.222676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00897616 (* 1 = 0.00897616 loss)
I0528 20:30:28.222679 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335259 (* 1 = 0.0335259 loss)
I0528 20:30:28.222684 10644 sgd_solver.cpp:106] Iteration 4940, lr = 0.0002
I0528 20:31:16.999833 10644 solver.cpp:228] Iteration 4960, loss = 0.63113
I0528 20:31:16.999862 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:31:16.999872 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308586 (* 1 = 0.0308586 loss)
I0528 20:31:16.999879 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0955572 (* 1 = 0.0955572 loss)
I0528 20:31:16.999884 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115687 (* 1 = 0.0115687 loss)
I0528 20:31:16.999891 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00937531 (* 1 = 0.00937531 loss)
I0528 20:31:16.999899 10644 sgd_solver.cpp:106] Iteration 4960, lr = 0.0002
I0528 20:32:05.505264 10644 solver.cpp:228] Iteration 4980, loss = 0.386691
I0528 20:32:05.505292 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 20:32:05.505300 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.11061 (* 1 = 0.11061 loss)
I0528 20:32:05.505304 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.347957 (* 1 = 0.347957 loss)
I0528 20:32:05.505308 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0460615 (* 1 = 0.0460615 loss)
I0528 20:32:05.505312 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563719 (* 1 = 0.0563719 loss)
I0528 20:32:05.505318 10644 sgd_solver.cpp:106] Iteration 4980, lr = 0.0002
speed: 2.431s / iter
I0528 20:32:51.773950 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_5000.caffemodel
I0528 20:32:54.827245 10644 solver.cpp:228] Iteration 5000, loss = 0.455627
I0528 20:32:54.827272 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 20:32:54.827280 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.108158 (* 1 = 0.108158 loss)
I0528 20:32:54.827284 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.214023 (* 1 = 0.214023 loss)
I0528 20:32:54.827288 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00969744 (* 1 = 0.00969744 loss)
I0528 20:32:54.827292 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403714 (* 1 = 0.0403714 loss)
I0528 20:32:54.827297 10644 sgd_solver.cpp:106] Iteration 5000, lr = 0.0002
I0528 20:33:43.373261 10644 solver.cpp:228] Iteration 5020, loss = 0.37912
I0528 20:33:43.373287 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:33:43.373294 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144028 (* 1 = 0.0144028 loss)
I0528 20:33:43.373298 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0795114 (* 1 = 0.0795114 loss)
I0528 20:33:43.373302 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124039 (* 1 = 0.0124039 loss)
I0528 20:33:43.373306 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139872 (* 1 = 0.0139872 loss)
I0528 20:33:43.373312 10644 sgd_solver.cpp:106] Iteration 5020, lr = 0.0002
I0528 20:34:31.928052 10644 solver.cpp:228] Iteration 5040, loss = 0.283939
I0528 20:34:31.928086 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:34:31.928093 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0956574 (* 1 = 0.0956574 loss)
I0528 20:34:31.928097 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.262193 (* 1 = 0.262193 loss)
I0528 20:34:31.928102 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184619 (* 1 = 0.0184619 loss)
I0528 20:34:31.928107 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206495 (* 1 = 0.0206495 loss)
I0528 20:34:31.928112 10644 sgd_solver.cpp:106] Iteration 5040, lr = 0.0002
I0528 20:35:20.441298 10644 solver.cpp:228] Iteration 5060, loss = 0.408477
I0528 20:35:20.441323 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:35:20.441330 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0534029 (* 1 = 0.0534029 loss)
I0528 20:35:20.441334 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.155435 (* 1 = 0.155435 loss)
I0528 20:35:20.441337 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111725 (* 1 = 0.0111725 loss)
I0528 20:35:20.441340 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190875 (* 1 = 0.0190875 loss)
I0528 20:35:20.441345 10644 sgd_solver.cpp:106] Iteration 5060, lr = 0.0002
I0528 20:36:08.966800 10644 solver.cpp:228] Iteration 5080, loss = 0.801048
I0528 20:36:08.966823 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0528 20:36:08.966830 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.754107 (* 1 = 0.754107 loss)
I0528 20:36:08.966835 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.828389 (* 1 = 0.828389 loss)
I0528 20:36:08.966837 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.211328 (* 1 = 0.211328 loss)
I0528 20:36:08.966840 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.438436 (* 1 = 0.438436 loss)
I0528 20:36:08.966846 10644 sgd_solver.cpp:106] Iteration 5080, lr = 0.0002
I0528 20:36:57.519886 10644 solver.cpp:228] Iteration 5100, loss = 0.372218
I0528 20:36:57.519927 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:36:57.519935 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0754043 (* 1 = 0.0754043 loss)
I0528 20:36:57.519939 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.156502 (* 1 = 0.156502 loss)
I0528 20:36:57.519943 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00886299 (* 1 = 0.00886299 loss)
I0528 20:36:57.519946 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154905 (* 1 = 0.0154905 loss)
I0528 20:36:57.519954 10644 sgd_solver.cpp:106] Iteration 5100, lr = 0.0002
I0528 20:37:46.092592 10644 solver.cpp:228] Iteration 5120, loss = 0.353769
I0528 20:37:46.092617 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 20:37:46.092624 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0948581 (* 1 = 0.0948581 loss)
I0528 20:37:46.092628 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.201198 (* 1 = 0.201198 loss)
I0528 20:37:46.092633 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162917 (* 1 = 0.0162917 loss)
I0528 20:37:46.092635 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179528 (* 1 = 0.0179528 loss)
I0528 20:37:46.092639 10644 sgd_solver.cpp:106] Iteration 5120, lr = 0.0002
I0528 20:38:34.611302 10644 solver.cpp:228] Iteration 5140, loss = 0.233533
I0528 20:38:34.611325 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:38:34.611333 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0554853 (* 1 = 0.0554853 loss)
I0528 20:38:34.611336 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151577 (* 1 = 0.151577 loss)
I0528 20:38:34.611340 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0080222 (* 1 = 0.0080222 loss)
I0528 20:38:34.611344 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128886 (* 1 = 0.0128886 loss)
I0528 20:38:34.611349 10644 sgd_solver.cpp:106] Iteration 5140, lr = 0.0002
I0528 20:39:23.164188 10644 solver.cpp:228] Iteration 5160, loss = 0.366429
I0528 20:39:23.164232 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 20:39:23.164243 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0211477 (* 1 = 0.0211477 loss)
I0528 20:39:23.164250 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.12028 (* 1 = 0.12028 loss)
I0528 20:39:23.164255 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140351 (* 1 = 0.0140351 loss)
I0528 20:39:23.164261 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155319 (* 1 = 0.0155319 loss)
I0528 20:39:23.164269 10644 sgd_solver.cpp:106] Iteration 5160, lr = 0.0002
I0528 20:40:11.664602 10644 solver.cpp:228] Iteration 5180, loss = 0.342694
I0528 20:40:11.664628 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:40:11.664634 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00445924 (* 1 = 0.00445924 loss)
I0528 20:40:11.664638 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144865 (* 1 = 0.144865 loss)
I0528 20:40:11.664643 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0459019 (* 1 = 0.0459019 loss)
I0528 20:40:11.664645 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525488 (* 1 = 0.0525488 loss)
I0528 20:40:11.664650 10644 sgd_solver.cpp:106] Iteration 5180, lr = 0.0002
speed: 2.431s / iter
I0528 20:41:00.217813 10644 solver.cpp:228] Iteration 5200, loss = 0.372264
I0528 20:41:00.217842 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0528 20:41:00.217849 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.372288 (* 1 = 0.372288 loss)
I0528 20:41:00.217854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.510423 (* 1 = 0.510423 loss)
I0528 20:41:00.217857 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.144181 (* 1 = 0.144181 loss)
I0528 20:41:00.217860 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.204933 (* 1 = 0.204933 loss)
I0528 20:41:00.217865 10644 sgd_solver.cpp:106] Iteration 5200, lr = 0.0002
I0528 20:41:48.761106 10644 solver.cpp:228] Iteration 5220, loss = 0.466694
I0528 20:41:48.761134 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:41:48.761142 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609223 (* 1 = 0.0609223 loss)
I0528 20:41:48.761147 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110033 (* 1 = 0.110033 loss)
I0528 20:41:48.761150 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00517627 (* 1 = 0.00517627 loss)
I0528 20:41:48.761153 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421231 (* 1 = 0.0421231 loss)
I0528 20:41:48.761159 10644 sgd_solver.cpp:106] Iteration 5220, lr = 0.0002
I0528 20:42:37.300310 10644 solver.cpp:228] Iteration 5240, loss = 0.574871
I0528 20:42:37.300335 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0528 20:42:37.300344 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.241562 (* 1 = 0.241562 loss)
I0528 20:42:37.300348 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.42576 (* 1 = 0.42576 loss)
I0528 20:42:37.300352 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214874 (* 1 = 0.0214874 loss)
I0528 20:42:37.300355 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0906973 (* 1 = 0.0906973 loss)
I0528 20:42:37.300361 10644 sgd_solver.cpp:106] Iteration 5240, lr = 0.0002
I0528 20:43:25.837870 10644 solver.cpp:228] Iteration 5260, loss = 0.231604
I0528 20:43:25.837901 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:43:25.837909 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314603 (* 1 = 0.0314603 loss)
I0528 20:43:25.837914 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113061 (* 1 = 0.113061 loss)
I0528 20:43:25.837918 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00839372 (* 1 = 0.00839372 loss)
I0528 20:43:25.837923 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00995353 (* 1 = 0.00995353 loss)
I0528 20:43:25.837929 10644 sgd_solver.cpp:106] Iteration 5260, lr = 0.0002
I0528 20:44:14.383729 10644 solver.cpp:228] Iteration 5280, loss = 0.192315
I0528 20:44:14.383754 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:44:14.383761 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0469353 (* 1 = 0.0469353 loss)
I0528 20:44:14.383765 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.099354 (* 1 = 0.099354 loss)
I0528 20:44:14.383769 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184956 (* 1 = 0.0184956 loss)
I0528 20:44:14.383774 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165061 (* 1 = 0.0165061 loss)
I0528 20:44:14.383780 10644 sgd_solver.cpp:106] Iteration 5280, lr = 0.0002
I0528 20:45:02.979724 10644 solver.cpp:228] Iteration 5300, loss = 0.50319
I0528 20:45:02.979755 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 20:45:02.979766 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0845768 (* 1 = 0.0845768 loss)
I0528 20:45:02.979773 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.211414 (* 1 = 0.211414 loss)
I0528 20:45:02.979779 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00443711 (* 1 = 0.00443711 loss)
I0528 20:45:02.979785 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408383 (* 1 = 0.0408383 loss)
I0528 20:45:02.979792 10644 sgd_solver.cpp:106] Iteration 5300, lr = 0.0002
I0528 20:45:51.740028 10644 solver.cpp:228] Iteration 5320, loss = 0.374912
I0528 20:45:51.740056 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 20:45:51.740062 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0897252 (* 1 = 0.0897252 loss)
I0528 20:45:51.740067 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.172643 (* 1 = 0.172643 loss)
I0528 20:45:51.740070 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00395287 (* 1 = 0.00395287 loss)
I0528 20:45:51.740073 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172515 (* 1 = 0.0172515 loss)
I0528 20:45:51.740078 10644 sgd_solver.cpp:106] Iteration 5320, lr = 0.0002
I0528 20:46:40.300103 10644 solver.cpp:228] Iteration 5340, loss = 0.511769
I0528 20:46:40.300130 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 20:46:40.300138 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381416 (* 1 = 0.0381416 loss)
I0528 20:46:40.300143 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1048 (* 1 = 0.1048 loss)
I0528 20:46:40.300145 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0099995 (* 1 = 0.0099995 loss)
I0528 20:46:40.300149 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00874991 (* 1 = 0.00874991 loss)
I0528 20:46:40.300154 10644 sgd_solver.cpp:106] Iteration 5340, lr = 0.0002
I0528 20:47:28.882971 10644 solver.cpp:228] Iteration 5360, loss = 0.557261
I0528 20:47:28.882995 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:47:28.883002 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331591 (* 1 = 0.0331591 loss)
I0528 20:47:28.883007 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128956 (* 1 = 0.128956 loss)
I0528 20:47:28.883010 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252506 (* 1 = 0.0252506 loss)
I0528 20:47:28.883013 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362578 (* 1 = 0.0362578 loss)
I0528 20:47:28.883018 10644 sgd_solver.cpp:106] Iteration 5360, lr = 0.0002
I0528 20:48:17.484187 10644 solver.cpp:228] Iteration 5380, loss = 0.329531
I0528 20:48:17.484217 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:48:17.484225 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549585 (* 1 = 0.0549585 loss)
I0528 20:48:17.484230 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0946932 (* 1 = 0.0946932 loss)
I0528 20:48:17.484233 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0083172 (* 1 = 0.0083172 loss)
I0528 20:48:17.484238 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010623 (* 1 = 0.010623 loss)
I0528 20:48:17.484243 10644 sgd_solver.cpp:106] Iteration 5380, lr = 0.0002
speed: 2.431s / iter
I0528 20:49:06.162032 10644 solver.cpp:228] Iteration 5400, loss = 0.306062
I0528 20:49:06.162060 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 20:49:06.162067 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000840211 (* 1 = 0.000840211 loss)
I0528 20:49:06.162072 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0410947 (* 1 = 0.0410947 loss)
I0528 20:49:06.162076 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692733 (* 1 = 0.00692733 loss)
I0528 20:49:06.162080 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0518559 (* 1 = 0.0518559 loss)
I0528 20:49:06.162086 10644 sgd_solver.cpp:106] Iteration 5400, lr = 0.0002
I0528 20:49:54.735666 10644 solver.cpp:228] Iteration 5420, loss = 0.524173
I0528 20:49:54.735692 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 20:49:54.735698 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115568 (* 1 = 0.115568 loss)
I0528 20:49:54.735703 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112152 (* 1 = 0.112152 loss)
I0528 20:49:54.735707 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130812 (* 1 = 0.0130812 loss)
I0528 20:49:54.735710 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142564 (* 1 = 0.0142564 loss)
I0528 20:49:54.735715 10644 sgd_solver.cpp:106] Iteration 5420, lr = 0.0002
I0528 20:50:43.355389 10644 solver.cpp:228] Iteration 5440, loss = 0.3258
I0528 20:50:43.355419 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 20:50:43.355429 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.135895 (* 1 = 0.135895 loss)
I0528 20:50:43.355437 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.283925 (* 1 = 0.283925 loss)
I0528 20:50:43.355443 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342639 (* 1 = 0.0342639 loss)
I0528 20:50:43.355448 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0413348 (* 1 = 0.0413348 loss)
I0528 20:50:43.355455 10644 sgd_solver.cpp:106] Iteration 5440, lr = 0.0002
I0528 20:51:31.999959 10644 solver.cpp:228] Iteration 5460, loss = 0.326523
I0528 20:51:31.999985 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:51:31.999994 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0253833 (* 1 = 0.0253833 loss)
I0528 20:51:31.999999 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.047467 (* 1 = 0.047467 loss)
I0528 20:51:32.000005 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0616635 (* 1 = 0.0616635 loss)
I0528 20:51:32.000011 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157068 (* 1 = 0.157068 loss)
I0528 20:51:32.000017 10644 sgd_solver.cpp:106] Iteration 5460, lr = 0.0002
I0528 20:52:20.697562 10644 solver.cpp:228] Iteration 5480, loss = 0.412084
I0528 20:52:20.697595 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 20:52:20.697607 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318571 (* 1 = 0.0318571 loss)
I0528 20:52:20.697613 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.143176 (* 1 = 0.143176 loss)
I0528 20:52:20.697619 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0402877 (* 1 = 0.0402877 loss)
I0528 20:52:20.697625 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176294 (* 1 = 0.0176294 loss)
I0528 20:52:20.697634 10644 sgd_solver.cpp:106] Iteration 5480, lr = 0.0002
I0528 20:53:09.292498 10644 solver.cpp:228] Iteration 5500, loss = 0.371157
I0528 20:53:09.292526 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 20:53:09.292536 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00147943 (* 1 = 0.00147943 loss)
I0528 20:53:09.292541 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0447254 (* 1 = 0.0447254 loss)
I0528 20:53:09.292544 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176986 (* 1 = 0.0176986 loss)
I0528 20:53:09.292548 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0672833 (* 1 = 0.0672833 loss)
I0528 20:53:09.292554 10644 sgd_solver.cpp:106] Iteration 5500, lr = 0.0002
I0528 20:53:57.848999 10644 solver.cpp:228] Iteration 5520, loss = 0.890794
I0528 20:53:57.849021 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 20:53:57.849028 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.17227 (* 1 = 0.17227 loss)
I0528 20:53:57.849031 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.183893 (* 1 = 0.183893 loss)
I0528 20:53:57.849035 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132519 (* 1 = 0.0132519 loss)
I0528 20:53:57.849040 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379821 (* 1 = 0.0379821 loss)
I0528 20:53:57.849043 10644 sgd_solver.cpp:106] Iteration 5520, lr = 0.0002
I0528 20:54:46.436328 10644 solver.cpp:228] Iteration 5540, loss = 0.363574
I0528 20:54:46.436352 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 20:54:46.436359 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247208 (* 1 = 0.0247208 loss)
I0528 20:54:46.436363 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109299 (* 1 = 0.109299 loss)
I0528 20:54:46.436367 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00715215 (* 1 = 0.00715215 loss)
I0528 20:54:46.436370 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00350871 (* 1 = 0.00350871 loss)
I0528 20:54:46.436375 10644 sgd_solver.cpp:106] Iteration 5540, lr = 0.0002
I0528 20:55:35.147140 10644 solver.cpp:228] Iteration 5560, loss = 0.275237
I0528 20:55:35.147166 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 20:55:35.147177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415106 (* 1 = 0.0415106 loss)
I0528 20:55:35.147184 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0635456 (* 1 = 0.0635456 loss)
I0528 20:55:35.147191 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0045399 (* 1 = 0.0045399 loss)
I0528 20:55:35.147197 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104562 (* 1 = 0.0104562 loss)
I0528 20:55:35.147204 10644 sgd_solver.cpp:106] Iteration 5560, lr = 0.0002
I0528 20:56:23.987700 10644 solver.cpp:228] Iteration 5580, loss = 0.374199
I0528 20:56:23.987726 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 20:56:23.987733 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.193314 (* 1 = 0.193314 loss)
I0528 20:56:23.987737 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.240641 (* 1 = 0.240641 loss)
I0528 20:56:23.987741 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164261 (* 1 = 0.0164261 loss)
I0528 20:56:23.987746 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03294 (* 1 = 0.03294 loss)
I0528 20:56:23.987751 10644 sgd_solver.cpp:106] Iteration 5580, lr = 0.0002
speed: 2.431s / iter
I0528 20:57:12.736536 10644 solver.cpp:228] Iteration 5600, loss = 0.323676
I0528 20:57:12.736565 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 20:57:12.736572 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.140133 (* 1 = 0.140133 loss)
I0528 20:57:12.736577 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.294353 (* 1 = 0.294353 loss)
I0528 20:57:12.736580 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00757079 (* 1 = 0.00757079 loss)
I0528 20:57:12.736584 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016978 (* 1 = 0.016978 loss)
I0528 20:57:12.736589 10644 sgd_solver.cpp:106] Iteration 5600, lr = 0.0002
I0528 20:58:01.409456 10644 solver.cpp:228] Iteration 5620, loss = 0.28392
I0528 20:58:01.409483 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 20:58:01.409490 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0134541 (* 1 = 0.0134541 loss)
I0528 20:58:01.409494 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101801 (* 1 = 0.101801 loss)
I0528 20:58:01.409497 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136358 (* 1 = 0.0136358 loss)
I0528 20:58:01.409502 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00764702 (* 1 = 0.00764702 loss)
I0528 20:58:01.409507 10644 sgd_solver.cpp:106] Iteration 5620, lr = 0.0002
I0528 20:58:50.114765 10644 solver.cpp:228] Iteration 5640, loss = 0.36722
I0528 20:58:50.114804 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0528 20:58:50.114811 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.24459 (* 1 = 0.24459 loss)
I0528 20:58:50.114817 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.392045 (* 1 = 0.392045 loss)
I0528 20:58:50.114823 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0473659 (* 1 = 0.0473659 loss)
I0528 20:58:50.114830 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040225 (* 1 = 0.040225 loss)
I0528 20:58:50.114837 10644 sgd_solver.cpp:106] Iteration 5640, lr = 0.0002
I0528 20:59:38.775817 10644 solver.cpp:228] Iteration 5660, loss = 0.386051
I0528 20:59:38.775847 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 20:59:38.775856 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00261316 (* 1 = 0.00261316 loss)
I0528 20:59:38.775862 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0815303 (* 1 = 0.0815303 loss)
I0528 20:59:38.775866 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128794 (* 1 = 0.0128794 loss)
I0528 20:59:38.775871 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452412 (* 1 = 0.0452412 loss)
I0528 20:59:38.775879 10644 sgd_solver.cpp:106] Iteration 5660, lr = 0.0002
I0528 21:00:27.573242 10644 solver.cpp:228] Iteration 5680, loss = 0.339678
I0528 21:00:27.573267 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 21:00:27.573274 10644 solver.cpp:244]     Train net output #1: loss_bbox = 9.11689e-05 (* 1 = 9.11689e-05 loss)
I0528 21:00:27.573278 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0409207 (* 1 = 0.0409207 loss)
I0528 21:00:27.573282 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200381 (* 1 = 0.0200381 loss)
I0528 21:00:27.573285 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304969 (* 1 = 0.0304969 loss)
I0528 21:00:27.573290 10644 sgd_solver.cpp:106] Iteration 5680, lr = 0.0002
I0528 21:01:16.159462 10644 solver.cpp:228] Iteration 5700, loss = 0.34309
I0528 21:01:16.159509 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0528 21:01:16.159518 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0954518 (* 1 = 0.0954518 loss)
I0528 21:01:16.159523 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.242509 (* 1 = 0.242509 loss)
I0528 21:01:16.159526 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126522 (* 1 = 0.0126522 loss)
I0528 21:01:16.159530 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193474 (* 1 = 0.0193474 loss)
I0528 21:01:16.159538 10644 sgd_solver.cpp:106] Iteration 5700, lr = 0.0002
I0528 21:02:04.919201 10644 solver.cpp:228] Iteration 5720, loss = 0.65084
I0528 21:02:04.919230 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 21:02:04.919237 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0575084 (* 1 = 0.0575084 loss)
I0528 21:02:04.919241 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.319767 (* 1 = 0.319767 loss)
I0528 21:02:04.919245 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0566631 (* 1 = 0.0566631 loss)
I0528 21:02:04.919248 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345458 (* 1 = 0.0345458 loss)
I0528 21:02:04.919255 10644 sgd_solver.cpp:106] Iteration 5720, lr = 0.0002
I0528 21:02:53.550045 10644 solver.cpp:228] Iteration 5740, loss = 0.334118
I0528 21:02:53.550070 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 21:02:53.550078 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.10819 (* 1 = 0.10819 loss)
I0528 21:02:53.550084 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.280486 (* 1 = 0.280486 loss)
I0528 21:02:53.550089 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0352861 (* 1 = 0.0352861 loss)
I0528 21:02:53.550094 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0446234 (* 1 = 0.0446234 loss)
I0528 21:02:53.550101 10644 sgd_solver.cpp:106] Iteration 5740, lr = 0.0002
I0528 21:03:42.363927 10644 solver.cpp:228] Iteration 5760, loss = 0.29744
I0528 21:03:42.363955 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:03:42.363963 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.130931 (* 1 = 0.130931 loss)
I0528 21:03:42.363967 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150039 (* 1 = 0.150039 loss)
I0528 21:03:42.363971 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00684628 (* 1 = 0.00684628 loss)
I0528 21:03:42.363976 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0564619 (* 1 = 0.0564619 loss)
I0528 21:03:42.363981 10644 sgd_solver.cpp:106] Iteration 5760, lr = 0.0002
I0528 21:04:30.984441 10644 solver.cpp:228] Iteration 5780, loss = 0.321097
I0528 21:04:30.984472 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 21:04:30.984478 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.123861 (* 1 = 0.123861 loss)
I0528 21:04:30.984483 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.158691 (* 1 = 0.158691 loss)
I0528 21:04:30.984486 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119616 (* 1 = 0.0119616 loss)
I0528 21:04:30.984490 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207757 (* 1 = 0.0207757 loss)
I0528 21:04:30.984498 10644 sgd_solver.cpp:106] Iteration 5780, lr = 0.0002
speed: 2.431s / iter
I0528 21:05:19.577288 10644 solver.cpp:228] Iteration 5800, loss = 0.264129
I0528 21:05:19.577316 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 21:05:19.577327 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0217605 (* 1 = 0.0217605 loss)
I0528 21:05:19.577333 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.117512 (* 1 = 0.117512 loss)
I0528 21:05:19.577340 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00770699 (* 1 = 0.00770699 loss)
I0528 21:05:19.577347 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105325 (* 1 = 0.0105325 loss)
I0528 21:05:19.577354 10644 sgd_solver.cpp:106] Iteration 5800, lr = 0.0002
I0528 21:06:08.171887 10644 solver.cpp:228] Iteration 5820, loss = 0.170149
I0528 21:06:08.171913 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:06:08.171921 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00154245 (* 1 = 0.00154245 loss)
I0528 21:06:08.171926 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0801054 (* 1 = 0.0801054 loss)
I0528 21:06:08.171929 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0375548 (* 1 = 0.0375548 loss)
I0528 21:06:08.171933 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242306 (* 1 = 0.0242306 loss)
I0528 21:06:08.171938 10644 sgd_solver.cpp:106] Iteration 5820, lr = 0.0002
I0528 21:06:56.951504 10644 solver.cpp:228] Iteration 5840, loss = 0.2651
I0528 21:06:56.951534 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 21:06:56.951541 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00107268 (* 1 = 0.00107268 loss)
I0528 21:06:56.951546 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0390076 (* 1 = 0.0390076 loss)
I0528 21:06:56.951550 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00871876 (* 1 = 0.00871876 loss)
I0528 21:06:56.951555 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0641311 (* 1 = 0.0641311 loss)
I0528 21:06:56.951560 10644 sgd_solver.cpp:106] Iteration 5840, lr = 0.0002
I0528 21:07:45.693491 10644 solver.cpp:228] Iteration 5860, loss = 0.197306
I0528 21:07:45.693521 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 21:07:45.693531 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0874068 (* 1 = 0.0874068 loss)
I0528 21:07:45.693538 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.316344 (* 1 = 0.316344 loss)
I0528 21:07:45.693544 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0304214 (* 1 = 0.0304214 loss)
I0528 21:07:45.693550 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439218 (* 1 = 0.0439218 loss)
I0528 21:07:45.693558 10644 sgd_solver.cpp:106] Iteration 5860, lr = 0.0002
I0528 21:08:34.258711 10644 solver.cpp:228] Iteration 5880, loss = 0.223716
I0528 21:08:34.258738 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 21:08:34.258745 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0218388 (* 1 = 0.0218388 loss)
I0528 21:08:34.258749 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.161855 (* 1 = 0.161855 loss)
I0528 21:08:34.258754 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0413948 (* 1 = 0.0413948 loss)
I0528 21:08:34.258757 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243312 (* 1 = 0.0243312 loss)
I0528 21:08:34.258762 10644 sgd_solver.cpp:106] Iteration 5880, lr = 0.0002
I0528 21:09:22.884222 10644 solver.cpp:228] Iteration 5900, loss = 0.48782
I0528 21:09:22.884256 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 21:09:22.884265 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0774554 (* 1 = 0.0774554 loss)
I0528 21:09:22.884271 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.293423 (* 1 = 0.293423 loss)
I0528 21:09:22.884277 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200849 (* 1 = 0.0200849 loss)
I0528 21:09:22.884281 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272243 (* 1 = 0.0272243 loss)
I0528 21:09:22.884289 10644 sgd_solver.cpp:106] Iteration 5900, lr = 0.0002
I0528 21:10:11.669883 10644 solver.cpp:228] Iteration 5920, loss = 0.215466
I0528 21:10:11.669906 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:10:11.669914 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155506 (* 1 = 0.0155506 loss)
I0528 21:10:11.669919 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0801121 (* 1 = 0.0801121 loss)
I0528 21:10:11.669922 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014191 (* 1 = 0.014191 loss)
I0528 21:10:11.669926 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142717 (* 1 = 0.0142717 loss)
I0528 21:10:11.669931 10644 sgd_solver.cpp:106] Iteration 5920, lr = 0.0002
I0528 21:11:00.499254 10644 solver.cpp:228] Iteration 5940, loss = 0.248544
I0528 21:11:00.499285 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 21:11:00.499295 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259345 (* 1 = 0.0259345 loss)
I0528 21:11:00.499300 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.090513 (* 1 = 0.090513 loss)
I0528 21:11:00.499305 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104733 (* 1 = 0.0104733 loss)
I0528 21:11:00.499311 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168689 (* 1 = 0.0168689 loss)
I0528 21:11:00.499318 10644 sgd_solver.cpp:106] Iteration 5940, lr = 0.0002
I0528 21:11:49.139828 10644 solver.cpp:228] Iteration 5960, loss = 0.3048
I0528 21:11:49.139854 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 21:11:49.139864 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.124457 (* 1 = 0.124457 loss)
I0528 21:11:49.139871 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.36433 (* 1 = 0.36433 loss)
I0528 21:11:49.139878 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294078 (* 1 = 0.0294078 loss)
I0528 21:11:49.139883 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0682048 (* 1 = 0.0682048 loss)
I0528 21:11:49.139890 10644 sgd_solver.cpp:106] Iteration 5960, lr = 0.0002
I0528 21:12:37.834594 10644 solver.cpp:228] Iteration 5980, loss = 0.367645
I0528 21:12:37.834625 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0528 21:12:37.834633 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.170566 (* 1 = 0.170566 loss)
I0528 21:12:37.834640 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.407548 (* 1 = 0.407548 loss)
I0528 21:12:37.834645 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0302908 (* 1 = 0.0302908 loss)
I0528 21:12:37.834650 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373202 (* 1 = 0.0373202 loss)
I0528 21:12:37.834656 10644 sgd_solver.cpp:106] Iteration 5980, lr = 0.0002
speed: 2.431s / iter
I0528 21:13:26.503801 10644 solver.cpp:228] Iteration 6000, loss = 0.211882
I0528 21:13:26.503825 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:13:26.503832 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.018683 (* 1 = 0.018683 loss)
I0528 21:13:26.503836 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.062789 (* 1 = 0.062789 loss)
I0528 21:13:26.503840 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0321451 (* 1 = 0.0321451 loss)
I0528 21:13:26.503844 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204447 (* 1 = 0.0204447 loss)
I0528 21:13:26.503847 10644 sgd_solver.cpp:106] Iteration 6000, lr = 0.0002
I0528 21:14:15.131163 10644 solver.cpp:228] Iteration 6020, loss = 0.188527
I0528 21:14:15.131191 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 21:14:15.131199 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0573658 (* 1 = 0.0573658 loss)
I0528 21:14:15.131203 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10178 (* 1 = 0.10178 loss)
I0528 21:14:15.131207 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126915 (* 1 = 0.0126915 loss)
I0528 21:14:15.131211 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185399 (* 1 = 0.0185399 loss)
I0528 21:14:15.131217 10644 sgd_solver.cpp:106] Iteration 6020, lr = 0.0002
I0528 21:15:03.727872 10644 solver.cpp:228] Iteration 6040, loss = 0.35771
I0528 21:15:03.727902 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:15:03.727910 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.105351 (* 1 = 0.105351 loss)
I0528 21:15:03.727915 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.204849 (* 1 = 0.204849 loss)
I0528 21:15:03.727918 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103481 (* 1 = 0.103481 loss)
I0528 21:15:03.727921 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0612225 (* 1 = 0.0612225 loss)
I0528 21:15:03.727928 10644 sgd_solver.cpp:106] Iteration 6040, lr = 0.0002
I0528 21:15:52.333631 10644 solver.cpp:228] Iteration 6060, loss = 0.282362
I0528 21:15:52.333657 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:15:52.333663 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702269 (* 1 = 0.0702269 loss)
I0528 21:15:52.333668 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.201017 (* 1 = 0.201017 loss)
I0528 21:15:52.333672 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024518 (* 1 = 0.024518 loss)
I0528 21:15:52.333675 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190836 (* 1 = 0.0190836 loss)
I0528 21:15:52.333681 10644 sgd_solver.cpp:106] Iteration 6060, lr = 0.0002
I0528 21:16:40.982941 10644 solver.cpp:228] Iteration 6080, loss = 0.276421
I0528 21:16:40.982975 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 21:16:40.982985 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.121023 (* 1 = 0.121023 loss)
I0528 21:16:40.982992 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0799121 (* 1 = 0.0799121 loss)
I0528 21:16:40.983000 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00428565 (* 1 = 0.00428565 loss)
I0528 21:16:40.983005 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146428 (* 1 = 0.0146428 loss)
I0528 21:16:40.983011 10644 sgd_solver.cpp:106] Iteration 6080, lr = 0.0002
I0528 21:17:29.702656 10644 solver.cpp:228] Iteration 6100, loss = 0.282583
I0528 21:17:29.702684 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:17:29.702693 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0543868 (* 1 = 0.0543868 loss)
I0528 21:17:29.702699 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.196418 (* 1 = 0.196418 loss)
I0528 21:17:29.702708 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244306 (* 1 = 0.0244306 loss)
I0528 21:17:29.702715 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101105 (* 1 = 0.101105 loss)
I0528 21:17:29.702721 10644 sgd_solver.cpp:106] Iteration 6100, lr = 0.0002
I0528 21:18:18.331362 10644 solver.cpp:228] Iteration 6120, loss = 0.489726
I0528 21:18:18.331400 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 21:18:18.331413 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.229064 (* 1 = 0.229064 loss)
I0528 21:18:18.331423 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.402075 (* 1 = 0.402075 loss)
I0528 21:18:18.331430 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0698776 (* 1 = 0.0698776 loss)
I0528 21:18:18.331439 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0957655 (* 1 = 0.0957655 loss)
I0528 21:18:18.331449 10644 sgd_solver.cpp:106] Iteration 6120, lr = 0.0002
I0528 21:19:06.932476 10644 solver.cpp:228] Iteration 6140, loss = 0.571136
I0528 21:19:06.932500 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 21:19:06.932507 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0632096 (* 1 = 0.0632096 loss)
I0528 21:19:06.932512 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0897492 (* 1 = 0.0897492 loss)
I0528 21:19:06.932515 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0081917 (* 1 = 0.0081917 loss)
I0528 21:19:06.932518 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143893 (* 1 = 0.0143893 loss)
I0528 21:19:06.932524 10644 sgd_solver.cpp:106] Iteration 6140, lr = 0.0002
I0528 21:19:55.492497 10644 solver.cpp:228] Iteration 6160, loss = 0.412895
I0528 21:19:55.492524 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 21:19:55.492530 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0765976 (* 1 = 0.0765976 loss)
I0528 21:19:55.492534 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151696 (* 1 = 0.151696 loss)
I0528 21:19:55.492542 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00716628 (* 1 = 0.00716628 loss)
I0528 21:19:55.492547 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178796 (* 1 = 0.0178796 loss)
I0528 21:19:55.492552 10644 sgd_solver.cpp:106] Iteration 6160, lr = 0.0002
I0528 21:20:44.169389 10644 solver.cpp:228] Iteration 6180, loss = 0.414647
I0528 21:20:44.169416 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 21:20:44.169425 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0854529 (* 1 = 0.0854529 loss)
I0528 21:20:44.169428 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.218785 (* 1 = 0.218785 loss)
I0528 21:20:44.169432 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199919 (* 1 = 0.0199919 loss)
I0528 21:20:44.169436 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0477639 (* 1 = 0.0477639 loss)
I0528 21:20:44.169441 10644 sgd_solver.cpp:106] Iteration 6180, lr = 0.0002
speed: 2.431s / iter
I0528 21:21:32.736011 10644 solver.cpp:228] Iteration 6200, loss = 0.317691
I0528 21:21:32.736038 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0528 21:21:32.736047 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.244504 (* 1 = 0.244504 loss)
I0528 21:21:32.736050 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.432466 (* 1 = 0.432466 loss)
I0528 21:21:32.736054 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0467692 (* 1 = 0.0467692 loss)
I0528 21:21:32.736057 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624148 (* 1 = 0.0624148 loss)
I0528 21:21:32.736063 10644 sgd_solver.cpp:106] Iteration 6200, lr = 0.0002
I0528 21:22:21.298188 10644 solver.cpp:228] Iteration 6220, loss = 0.487652
I0528 21:22:21.298218 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:22:21.298225 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.10986 (* 1 = 0.10986 loss)
I0528 21:22:21.298230 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.261222 (* 1 = 0.261222 loss)
I0528 21:22:21.298235 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00723998 (* 1 = 0.00723998 loss)
I0528 21:22:21.298239 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150973 (* 1 = 0.0150973 loss)
I0528 21:22:21.298245 10644 sgd_solver.cpp:106] Iteration 6220, lr = 0.0002
I0528 21:23:09.940776 10644 solver.cpp:228] Iteration 6240, loss = 0.283178
I0528 21:23:09.940804 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:23:09.940811 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0211827 (* 1 = 0.0211827 loss)
I0528 21:23:09.940816 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0849243 (* 1 = 0.0849243 loss)
I0528 21:23:09.940820 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00998619 (* 1 = 0.00998619 loss)
I0528 21:23:09.940824 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157175 (* 1 = 0.0157175 loss)
I0528 21:23:09.940830 10644 sgd_solver.cpp:106] Iteration 6240, lr = 0.0002
I0528 21:23:58.601608 10644 solver.cpp:228] Iteration 6260, loss = 0.370094
I0528 21:23:58.601636 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 21:23:58.601644 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.030918 (* 1 = 0.030918 loss)
I0528 21:23:58.601649 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152062 (* 1 = 0.152062 loss)
I0528 21:23:58.601652 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136759 (* 1 = 0.0136759 loss)
I0528 21:23:58.601656 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418072 (* 1 = 0.0418072 loss)
I0528 21:23:58.601661 10644 sgd_solver.cpp:106] Iteration 6260, lr = 0.0002
I0528 21:24:47.172999 10644 solver.cpp:228] Iteration 6280, loss = 0.397359
I0528 21:24:47.173027 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 21:24:47.173035 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0388937 (* 1 = 0.0388937 loss)
I0528 21:24:47.173039 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0848742 (* 1 = 0.0848742 loss)
I0528 21:24:47.173043 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101782 (* 1 = 0.0101782 loss)
I0528 21:24:47.173045 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018826 (* 1 = 0.018826 loss)
I0528 21:24:47.173051 10644 sgd_solver.cpp:106] Iteration 6280, lr = 0.0002
I0528 21:25:35.746356 10644 solver.cpp:228] Iteration 6300, loss = 0.325189
I0528 21:25:35.746381 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 21:25:35.746387 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0303331 (* 1 = 0.0303331 loss)
I0528 21:25:35.746392 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0947833 (* 1 = 0.0947833 loss)
I0528 21:25:35.746394 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179565 (* 1 = 0.0179565 loss)
I0528 21:25:35.746397 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125977 (* 1 = 0.0125977 loss)
I0528 21:25:35.746403 10644 sgd_solver.cpp:106] Iteration 6300, lr = 0.0002
I0528 21:26:24.247664 10644 solver.cpp:228] Iteration 6320, loss = 0.170768
I0528 21:26:24.247694 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:26:24.247701 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0145208 (* 1 = 0.0145208 loss)
I0528 21:26:24.247705 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0636581 (* 1 = 0.0636581 loss)
I0528 21:26:24.247709 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00490999 (* 1 = 0.00490999 loss)
I0528 21:26:24.247712 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158071 (* 1 = 0.0158071 loss)
I0528 21:26:24.247719 10644 sgd_solver.cpp:106] Iteration 6320, lr = 0.0002
I0528 21:27:12.783174 10644 solver.cpp:228] Iteration 6340, loss = 0.31888
I0528 21:27:12.783200 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:27:12.783206 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114755 (* 1 = 0.114755 loss)
I0528 21:27:12.783210 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.227944 (* 1 = 0.227944 loss)
I0528 21:27:12.783215 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00777278 (* 1 = 0.00777278 loss)
I0528 21:27:12.783218 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132908 (* 1 = 0.0132908 loss)
I0528 21:27:12.783223 10644 sgd_solver.cpp:106] Iteration 6340, lr = 0.0002
I0528 21:28:01.342555 10644 solver.cpp:228] Iteration 6360, loss = 0.4342
I0528 21:28:01.342581 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:28:01.342592 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316499 (* 1 = 0.0316499 loss)
I0528 21:28:01.342599 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178556 (* 1 = 0.178556 loss)
I0528 21:28:01.342605 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0270853 (* 1 = 0.0270853 loss)
I0528 21:28:01.342612 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00548906 (* 1 = 0.00548906 loss)
I0528 21:28:01.342617 10644 sgd_solver.cpp:106] Iteration 6360, lr = 0.0002
I0528 21:28:49.914755 10644 solver.cpp:228] Iteration 6380, loss = 0.30775
I0528 21:28:49.914782 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 21:28:49.914789 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441633 (* 1 = 0.0441633 loss)
I0528 21:28:49.914794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0812066 (* 1 = 0.0812066 loss)
I0528 21:28:49.914798 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156995 (* 1 = 0.0156995 loss)
I0528 21:28:49.914801 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308121 (* 1 = 0.0308121 loss)
I0528 21:28:49.914808 10644 sgd_solver.cpp:106] Iteration 6380, lr = 0.0002
speed: 2.431s / iter
I0528 21:29:38.449095 10644 solver.cpp:228] Iteration 6400, loss = 0.465532
I0528 21:29:38.449124 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 21:29:38.449132 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117706 (* 1 = 0.117706 loss)
I0528 21:29:38.449136 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.40277 (* 1 = 0.40277 loss)
I0528 21:29:38.449141 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938429 (* 1 = 0.00938429 loss)
I0528 21:29:38.449144 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0526738 (* 1 = 0.0526738 loss)
I0528 21:29:38.449151 10644 sgd_solver.cpp:106] Iteration 6400, lr = 0.0002
I0528 21:30:26.981474 10644 solver.cpp:228] Iteration 6420, loss = 0.501188
I0528 21:30:26.981501 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 21:30:26.981509 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399452 (* 1 = 0.0399452 loss)
I0528 21:30:26.981513 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.164513 (* 1 = 0.164513 loss)
I0528 21:30:26.981518 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151365 (* 1 = 0.0151365 loss)
I0528 21:30:26.981521 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241221 (* 1 = 0.0241221 loss)
I0528 21:30:26.981526 10644 sgd_solver.cpp:106] Iteration 6420, lr = 0.0002
I0528 21:31:15.538079 10644 solver.cpp:228] Iteration 6440, loss = 0.511167
I0528 21:31:15.538108 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 21:31:15.538116 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.038218 (* 1 = 0.038218 loss)
I0528 21:31:15.538121 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0787775 (* 1 = 0.0787775 loss)
I0528 21:31:15.538125 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103282 (* 1 = 0.0103282 loss)
I0528 21:31:15.538130 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149122 (* 1 = 0.0149122 loss)
I0528 21:31:15.538136 10644 sgd_solver.cpp:106] Iteration 6440, lr = 0.0002
I0528 21:32:04.065624 10644 solver.cpp:228] Iteration 6460, loss = 0.303896
I0528 21:32:04.065650 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 21:32:04.065659 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0527608 (* 1 = 0.0527608 loss)
I0528 21:32:04.065662 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.165548 (* 1 = 0.165548 loss)
I0528 21:32:04.065666 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342336 (* 1 = 0.0342336 loss)
I0528 21:32:04.065670 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330986 (* 1 = 0.0330986 loss)
I0528 21:32:04.065675 10644 sgd_solver.cpp:106] Iteration 6460, lr = 0.0002
I0528 21:32:52.595052 10644 solver.cpp:228] Iteration 6480, loss = 0.436307
I0528 21:32:52.595080 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 21:32:52.595089 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0846025 (* 1 = 0.0846025 loss)
I0528 21:32:52.595095 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.209507 (* 1 = 0.209507 loss)
I0528 21:32:52.595100 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115215 (* 1 = 0.0115215 loss)
I0528 21:32:52.595105 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107487 (* 1 = 0.0107487 loss)
I0528 21:32:52.595113 10644 sgd_solver.cpp:106] Iteration 6480, lr = 0.0002
I0528 21:33:41.372737 10644 solver.cpp:228] Iteration 6500, loss = 0.35833
I0528 21:33:41.372763 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 21:33:41.372771 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.300636 (* 1 = 0.300636 loss)
I0528 21:33:41.372774 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.427928 (* 1 = 0.427928 loss)
I0528 21:33:41.372778 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0826873 (* 1 = 0.0826873 loss)
I0528 21:33:41.372782 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.104792 (* 1 = 0.104792 loss)
I0528 21:33:41.372786 10644 sgd_solver.cpp:106] Iteration 6500, lr = 0.0002
I0528 21:34:30.096897 10644 solver.cpp:228] Iteration 6520, loss = 0.750392
I0528 21:34:30.096927 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 21:34:30.096935 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.085211 (* 1 = 0.085211 loss)
I0528 21:34:30.096940 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.172087 (* 1 = 0.172087 loss)
I0528 21:34:30.096942 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0341513 (* 1 = 0.0341513 loss)
I0528 21:34:30.096946 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221774 (* 1 = 0.0221774 loss)
I0528 21:34:30.096951 10644 sgd_solver.cpp:106] Iteration 6520, lr = 0.0002
I0528 21:35:18.780277 10644 solver.cpp:228] Iteration 6540, loss = 0.305242
I0528 21:35:18.780304 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 21:35:18.780311 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00218912 (* 1 = 0.00218912 loss)
I0528 21:35:18.780316 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0549672 (* 1 = 0.0549672 loss)
I0528 21:35:18.780319 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146178 (* 1 = 0.0146178 loss)
I0528 21:35:18.780323 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226457 (* 1 = 0.0226457 loss)
I0528 21:35:18.780328 10644 sgd_solver.cpp:106] Iteration 6540, lr = 0.0002
I0528 21:36:07.644608 10644 solver.cpp:228] Iteration 6560, loss = 0.25412
I0528 21:36:07.644631 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 21:36:07.644639 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.109284 (* 1 = 0.109284 loss)
I0528 21:36:07.644642 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144738 (* 1 = 0.144738 loss)
I0528 21:36:07.644646 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0036001 (* 1 = 0.0036001 loss)
I0528 21:36:07.644649 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00970109 (* 1 = 0.00970109 loss)
I0528 21:36:07.644654 10644 sgd_solver.cpp:106] Iteration 6560, lr = 0.0002
I0528 21:36:56.444960 10644 solver.cpp:228] Iteration 6580, loss = 0.353897
I0528 21:36:56.444985 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 21:36:56.444993 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.137253 (* 1 = 0.137253 loss)
I0528 21:36:56.444996 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.41077 (* 1 = 0.41077 loss)
I0528 21:36:56.444999 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0367024 (* 1 = 0.0367024 loss)
I0528 21:36:56.445003 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449112 (* 1 = 0.0449112 loss)
I0528 21:36:56.445008 10644 sgd_solver.cpp:106] Iteration 6580, lr = 0.0002
speed: 2.431s / iter
I0528 21:37:45.198072 10644 solver.cpp:228] Iteration 6600, loss = 0.305887
I0528 21:37:45.198103 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 21:37:45.198112 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748609 (* 1 = 0.0748609 loss)
I0528 21:37:45.198115 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.345135 (* 1 = 0.345135 loss)
I0528 21:37:45.198119 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306929 (* 1 = 0.0306929 loss)
I0528 21:37:45.198123 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030441 (* 1 = 0.030441 loss)
I0528 21:37:45.198129 10644 sgd_solver.cpp:106] Iteration 6600, lr = 0.0002
I0528 21:38:33.976122 10644 solver.cpp:228] Iteration 6620, loss = 0.400543
I0528 21:38:33.976152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 21:38:33.976164 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.045929 (* 1 = 0.045929 loss)
I0528 21:38:33.976171 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.11888 (* 1 = 0.11888 loss)
I0528 21:38:33.976177 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0457 (* 1 = 0.0457 loss)
I0528 21:38:33.976183 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109186 (* 1 = 0.109186 loss)
I0528 21:38:33.976188 10644 sgd_solver.cpp:106] Iteration 6620, lr = 0.0002
I0528 21:39:22.831557 10644 solver.cpp:228] Iteration 6640, loss = 0.251556
I0528 21:39:22.831584 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 21:39:22.831594 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353059 (* 1 = 0.0353059 loss)
I0528 21:39:22.831600 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0973749 (* 1 = 0.0973749 loss)
I0528 21:39:22.831606 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134674 (* 1 = 0.0134674 loss)
I0528 21:39:22.831611 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114461 (* 1 = 0.0114461 loss)
I0528 21:39:22.831617 10644 sgd_solver.cpp:106] Iteration 6640, lr = 0.0002
I0528 21:40:11.521590 10644 solver.cpp:228] Iteration 6660, loss = 0.497252
I0528 21:40:11.521618 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 21:40:11.521625 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118613 (* 1 = 0.118613 loss)
I0528 21:40:11.521630 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234276 (* 1 = 0.234276 loss)
I0528 21:40:11.521632 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.034788 (* 1 = 0.034788 loss)
I0528 21:40:11.521636 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0785523 (* 1 = 0.0785523 loss)
I0528 21:40:11.521641 10644 sgd_solver.cpp:106] Iteration 6660, lr = 0.0002
I0528 21:41:00.255234 10644 solver.cpp:228] Iteration 6680, loss = 0.548588
I0528 21:41:00.255267 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 21:41:00.255278 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.176882 (* 1 = 0.176882 loss)
I0528 21:41:00.255283 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.28831 (* 1 = 0.28831 loss)
I0528 21:41:00.255288 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0315603 (* 1 = 0.0315603 loss)
I0528 21:41:00.255293 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169917 (* 1 = 0.0169917 loss)
I0528 21:41:00.255300 10644 sgd_solver.cpp:106] Iteration 6680, lr = 0.0002
I0528 21:41:48.900189 10644 solver.cpp:228] Iteration 6700, loss = 0.538639
I0528 21:41:48.900216 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 21:41:48.900226 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.224827 (* 1 = 0.224827 loss)
I0528 21:41:48.900233 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.370701 (* 1 = 0.370701 loss)
I0528 21:41:48.900238 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0373238 (* 1 = 0.0373238 loss)
I0528 21:41:48.900243 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0756809 (* 1 = 0.0756809 loss)
I0528 21:41:48.900249 10644 sgd_solver.cpp:106] Iteration 6700, lr = 0.0002
I0528 21:42:37.520509 10644 solver.cpp:228] Iteration 6720, loss = 0.502183
I0528 21:42:37.520534 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 21:42:37.520542 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.112592 (* 1 = 0.112592 loss)
I0528 21:42:37.520548 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.185517 (* 1 = 0.185517 loss)
I0528 21:42:37.520553 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182154 (* 1 = 0.0182154 loss)
I0528 21:42:37.520558 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370128 (* 1 = 0.0370128 loss)
I0528 21:42:37.520565 10644 sgd_solver.cpp:106] Iteration 6720, lr = 0.0002
I0528 21:43:26.155645 10644 solver.cpp:228] Iteration 6740, loss = 0.600004
I0528 21:43:26.155673 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 21:43:26.155679 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0570976 (* 1 = 0.0570976 loss)
I0528 21:43:26.155683 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.265598 (* 1 = 0.265598 loss)
I0528 21:43:26.155686 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214098 (* 1 = 0.0214098 loss)
I0528 21:43:26.155690 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116788 (* 1 = 0.0116788 loss)
I0528 21:43:26.155694 10644 sgd_solver.cpp:106] Iteration 6740, lr = 0.0002
I0528 21:44:14.758870 10644 solver.cpp:228] Iteration 6760, loss = 0.304457
I0528 21:44:14.758894 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:44:14.758901 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.126306 (* 1 = 0.126306 loss)
I0528 21:44:14.758905 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.279852 (* 1 = 0.279852 loss)
I0528 21:44:14.758908 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215743 (* 1 = 0.0215743 loss)
I0528 21:44:14.758911 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0791833 (* 1 = 0.0791833 loss)
I0528 21:44:14.758918 10644 sgd_solver.cpp:106] Iteration 6760, lr = 0.0002
I0528 21:45:03.429751 10644 solver.cpp:228] Iteration 6780, loss = 0.448877
I0528 21:45:03.429781 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0528 21:45:03.429790 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.256243 (* 1 = 0.256243 loss)
I0528 21:45:03.429795 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.384985 (* 1 = 0.384985 loss)
I0528 21:45:03.429798 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208631 (* 1 = 0.0208631 loss)
I0528 21:45:03.429802 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0535657 (* 1 = 0.0535657 loss)
I0528 21:45:03.429808 10644 sgd_solver.cpp:106] Iteration 6780, lr = 0.0002
speed: 2.431s / iter
I0528 21:45:52.078034 10644 solver.cpp:228] Iteration 6800, loss = 0.335444
I0528 21:45:52.078063 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0528 21:45:52.078070 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.258956 (* 1 = 0.258956 loss)
I0528 21:45:52.078074 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.477818 (* 1 = 0.477818 loss)
I0528 21:45:52.078078 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0465946 (* 1 = 0.0465946 loss)
I0528 21:45:52.078083 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.151711 (* 1 = 0.151711 loss)
I0528 21:45:52.078088 10644 sgd_solver.cpp:106] Iteration 6800, lr = 0.0002
I0528 21:46:40.736161 10644 solver.cpp:228] Iteration 6820, loss = 0.542104
I0528 21:46:40.736189 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 21:46:40.736202 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0812189 (* 1 = 0.0812189 loss)
I0528 21:46:40.736208 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.233627 (* 1 = 0.233627 loss)
I0528 21:46:40.736215 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00706985 (* 1 = 0.00706985 loss)
I0528 21:46:40.736223 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371511 (* 1 = 0.0371511 loss)
I0528 21:46:40.736232 10644 sgd_solver.cpp:106] Iteration 6820, lr = 0.0002
I0528 21:47:29.302155 10644 solver.cpp:228] Iteration 6840, loss = 0.68938
I0528 21:47:29.302186 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0528 21:47:29.302197 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.13499 (* 1 = 0.13499 loss)
I0528 21:47:29.302203 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.304877 (* 1 = 0.304877 loss)
I0528 21:47:29.302211 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226971 (* 1 = 0.0226971 loss)
I0528 21:47:29.302215 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0703842 (* 1 = 0.0703842 loss)
I0528 21:47:29.302223 10644 sgd_solver.cpp:106] Iteration 6840, lr = 0.0002
I0528 21:48:17.831831 10644 solver.cpp:228] Iteration 6860, loss = 0.313717
I0528 21:48:17.831861 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 21:48:17.831871 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00128272 (* 1 = 0.00128272 loss)
I0528 21:48:17.831876 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0261258 (* 1 = 0.0261258 loss)
I0528 21:48:17.831878 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0627968 (* 1 = 0.0627968 loss)
I0528 21:48:17.831882 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208663 (* 1 = 0.0208663 loss)
I0528 21:48:17.831887 10644 sgd_solver.cpp:106] Iteration 6860, lr = 0.0002
I0528 21:49:06.369645 10644 solver.cpp:228] Iteration 6880, loss = 0.551004
I0528 21:49:06.369674 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 21:49:06.369683 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.126864 (* 1 = 0.126864 loss)
I0528 21:49:06.369686 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.283932 (* 1 = 0.283932 loss)
I0528 21:49:06.369691 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00948702 (* 1 = 0.00948702 loss)
I0528 21:49:06.369695 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275042 (* 1 = 0.0275042 loss)
I0528 21:49:06.369700 10644 sgd_solver.cpp:106] Iteration 6880, lr = 0.0002
I0528 21:49:54.882287 10644 solver.cpp:228] Iteration 6900, loss = 0.272518
I0528 21:49:54.882313 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 21:49:54.882320 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474929 (* 1 = 0.0474929 loss)
I0528 21:49:54.882325 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115535 (* 1 = 0.115535 loss)
I0528 21:49:54.882329 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140652 (* 1 = 0.0140652 loss)
I0528 21:49:54.882333 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311563 (* 1 = 0.0311563 loss)
I0528 21:49:54.882339 10644 sgd_solver.cpp:106] Iteration 6900, lr = 0.0002
I0528 21:50:43.397689 10644 solver.cpp:228] Iteration 6920, loss = 0.249235
I0528 21:50:43.397716 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 21:50:43.397723 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0289055 (* 1 = 0.0289055 loss)
I0528 21:50:43.397727 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0773668 (* 1 = 0.0773668 loss)
I0528 21:50:43.397732 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377263 (* 1 = 0.00377263 loss)
I0528 21:50:43.397735 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109377 (* 1 = 0.0109377 loss)
I0528 21:50:43.397742 10644 sgd_solver.cpp:106] Iteration 6920, lr = 0.0002
I0528 21:51:32.031893 10644 solver.cpp:228] Iteration 6940, loss = 0.407258
I0528 21:51:32.031919 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 21:51:32.031926 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448866 (* 1 = 0.0448866 loss)
I0528 21:51:32.031930 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.162609 (* 1 = 0.162609 loss)
I0528 21:51:32.031934 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00980777 (* 1 = 0.00980777 loss)
I0528 21:51:32.031937 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120614 (* 1 = 0.0120614 loss)
I0528 21:51:32.031942 10644 sgd_solver.cpp:106] Iteration 6940, lr = 0.0002
I0528 21:52:20.577508 10644 solver.cpp:228] Iteration 6960, loss = 0.444935
I0528 21:52:20.577534 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 21:52:20.577543 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0620208 (* 1 = 0.0620208 loss)
I0528 21:52:20.577549 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.135974 (* 1 = 0.135974 loss)
I0528 21:52:20.577555 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104639 (* 1 = 0.0104639 loss)
I0528 21:52:20.577560 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276019 (* 1 = 0.0276019 loss)
I0528 21:52:20.577565 10644 sgd_solver.cpp:106] Iteration 6960, lr = 0.0002
I0528 21:53:09.193956 10644 solver.cpp:228] Iteration 6980, loss = 0.216295
I0528 21:53:09.193980 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 21:53:09.193989 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0869624 (* 1 = 0.0869624 loss)
I0528 21:53:09.193995 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.159261 (* 1 = 0.159261 loss)
I0528 21:53:09.194000 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179486 (* 1 = 0.0179486 loss)
I0528 21:53:09.194006 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276373 (* 1 = 0.0276373 loss)
I0528 21:53:09.194012 10644 sgd_solver.cpp:106] Iteration 6980, lr = 0.0002
speed: 2.431s / iter
I0528 21:53:57.765432 10644 solver.cpp:228] Iteration 7000, loss = 0.278089
I0528 21:53:57.765461 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 21:53:57.765471 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.145972 (* 1 = 0.145972 loss)
I0528 21:53:57.765480 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.30304 (* 1 = 0.30304 loss)
I0528 21:53:57.765486 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136357 (* 1 = 0.0136357 loss)
I0528 21:53:57.765491 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301173 (* 1 = 0.0301173 loss)
I0528 21:53:57.765499 10644 sgd_solver.cpp:106] Iteration 7000, lr = 0.0002
I0528 21:54:46.307379 10644 solver.cpp:228] Iteration 7020, loss = 0.2752
I0528 21:54:46.307410 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 21:54:46.307421 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561172 (* 1 = 0.0561172 loss)
I0528 21:54:46.307428 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113927 (* 1 = 0.113927 loss)
I0528 21:54:46.307435 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398574 (* 1 = 0.00398574 loss)
I0528 21:54:46.307440 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00554024 (* 1 = 0.00554024 loss)
I0528 21:54:46.307447 10644 sgd_solver.cpp:106] Iteration 7020, lr = 0.0002
I0528 21:55:34.953450 10644 solver.cpp:228] Iteration 7040, loss = 0.473302
I0528 21:55:34.953475 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 21:55:34.953483 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0919346 (* 1 = 0.0919346 loss)
I0528 21:55:34.953487 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.198669 (* 1 = 0.198669 loss)
I0528 21:55:34.953490 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00446542 (* 1 = 0.00446542 loss)
I0528 21:55:34.953495 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259473 (* 1 = 0.0259473 loss)
I0528 21:55:34.953500 10644 sgd_solver.cpp:106] Iteration 7040, lr = 0.0002
I0528 21:56:23.572543 10644 solver.cpp:228] Iteration 7060, loss = 0.204053
I0528 21:56:23.572573 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 21:56:23.572582 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117665 (* 1 = 0.117665 loss)
I0528 21:56:23.572585 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.223524 (* 1 = 0.223524 loss)
I0528 21:56:23.572589 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00920713 (* 1 = 0.00920713 loss)
I0528 21:56:23.572593 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185546 (* 1 = 0.0185546 loss)
I0528 21:56:23.572599 10644 sgd_solver.cpp:106] Iteration 7060, lr = 0.0002
I0528 21:57:12.088665 10644 solver.cpp:228] Iteration 7080, loss = 0.597255
I0528 21:57:12.088737 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 21:57:12.088759 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0429964 (* 1 = 0.0429964 loss)
I0528 21:57:12.088776 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.149176 (* 1 = 0.149176 loss)
I0528 21:57:12.088793 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132457 (* 1 = 0.0132457 loss)
I0528 21:57:12.088806 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00457039 (* 1 = 0.00457039 loss)
I0528 21:57:12.088822 10644 sgd_solver.cpp:106] Iteration 7080, lr = 0.0002
I0528 21:58:00.639375 10644 solver.cpp:228] Iteration 7100, loss = 0.181717
I0528 21:58:00.639403 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 21:58:00.639411 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117228 (* 1 = 0.117228 loss)
I0528 21:58:00.639416 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.173911 (* 1 = 0.173911 loss)
I0528 21:58:00.639420 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013608 (* 1 = 0.013608 loss)
I0528 21:58:00.639423 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380324 (* 1 = 0.0380324 loss)
I0528 21:58:00.639430 10644 sgd_solver.cpp:106] Iteration 7100, lr = 0.0002
I0528 21:58:49.270582 10644 solver.cpp:228] Iteration 7120, loss = 0.402611
I0528 21:58:49.270611 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 21:58:49.270619 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0806141 (* 1 = 0.0806141 loss)
I0528 21:58:49.270624 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.11159 (* 1 = 0.11159 loss)
I0528 21:58:49.270630 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00415112 (* 1 = 0.00415112 loss)
I0528 21:58:49.270634 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138165 (* 1 = 0.0138165 loss)
I0528 21:58:49.270640 10644 sgd_solver.cpp:106] Iteration 7120, lr = 0.0002
I0528 21:59:37.829464 10644 solver.cpp:228] Iteration 7140, loss = 0.237388
I0528 21:59:37.829490 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 21:59:37.829497 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237823 (* 1 = 0.0237823 loss)
I0528 21:59:37.829501 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.129291 (* 1 = 0.129291 loss)
I0528 21:59:37.829504 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252654 (* 1 = 0.0252654 loss)
I0528 21:59:37.829509 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371131 (* 1 = 0.0371131 loss)
I0528 21:59:37.829512 10644 sgd_solver.cpp:106] Iteration 7140, lr = 0.0002
I0528 22:00:26.389473 10644 solver.cpp:228] Iteration 7160, loss = 0.420496
I0528 22:00:26.389499 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 22:00:26.389506 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455248 (* 1 = 0.0455248 loss)
I0528 22:00:26.389511 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.119848 (* 1 = 0.119848 loss)
I0528 22:00:26.389515 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0217754 (* 1 = 0.0217754 loss)
I0528 22:00:26.389518 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210903 (* 1 = 0.0210903 loss)
I0528 22:00:26.389525 10644 sgd_solver.cpp:106] Iteration 7160, lr = 0.0002
I0528 22:01:15.047785 10644 solver.cpp:228] Iteration 7180, loss = 0.536823
I0528 22:01:15.047812 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 22:01:15.047819 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.263314 (* 1 = 0.263314 loss)
I0528 22:01:15.047823 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.337563 (* 1 = 0.337563 loss)
I0528 22:01:15.047827 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00514736 (* 1 = 0.00514736 loss)
I0528 22:01:15.047830 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335014 (* 1 = 0.0335014 loss)
I0528 22:01:15.047837 10644 sgd_solver.cpp:106] Iteration 7180, lr = 0.0002
speed: 2.431s / iter
I0528 22:02:03.610900 10644 solver.cpp:228] Iteration 7200, loss = 0.394827
I0528 22:02:03.610926 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 22:02:03.610932 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.233213 (* 1 = 0.233213 loss)
I0528 22:02:03.610936 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.329976 (* 1 = 0.329976 loss)
I0528 22:02:03.610940 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00645619 (* 1 = 0.00645619 loss)
I0528 22:02:03.610944 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481828 (* 1 = 0.0481828 loss)
I0528 22:02:03.610949 10644 sgd_solver.cpp:106] Iteration 7200, lr = 0.0002
I0528 22:02:52.177523 10644 solver.cpp:228] Iteration 7220, loss = 0.27995
I0528 22:02:52.177549 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:02:52.177559 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.070202 (* 1 = 0.070202 loss)
I0528 22:02:52.177565 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.156155 (* 1 = 0.156155 loss)
I0528 22:02:52.177570 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0285254 (* 1 = 0.0285254 loss)
I0528 22:02:52.177575 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325561 (* 1 = 0.0325561 loss)
I0528 22:02:52.177582 10644 sgd_solver.cpp:106] Iteration 7220, lr = 0.0002
I0528 22:03:40.724366 10644 solver.cpp:228] Iteration 7240, loss = 0.193475
I0528 22:03:40.724391 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 22:03:40.724400 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.101757 (* 1 = 0.101757 loss)
I0528 22:03:40.724403 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.167621 (* 1 = 0.167621 loss)
I0528 22:03:40.724406 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0341612 (* 1 = 0.0341612 loss)
I0528 22:03:40.724409 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0381231 (* 1 = 0.0381231 loss)
I0528 22:03:40.724414 10644 sgd_solver.cpp:106] Iteration 7240, lr = 0.0002
I0528 22:04:29.286175 10644 solver.cpp:228] Iteration 7260, loss = 0.273574
I0528 22:04:29.286201 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:04:29.286207 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261283 (* 1 = 0.0261283 loss)
I0528 22:04:29.286211 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.135191 (* 1 = 0.135191 loss)
I0528 22:04:29.286216 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129374 (* 1 = 0.0129374 loss)
I0528 22:04:29.286218 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00840135 (* 1 = 0.00840135 loss)
I0528 22:04:29.286223 10644 sgd_solver.cpp:106] Iteration 7260, lr = 0.0002
I0528 22:05:17.860714 10644 solver.cpp:228] Iteration 7280, loss = 0.605516
I0528 22:05:17.860740 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0528 22:05:17.860747 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.364435 (* 1 = 0.364435 loss)
I0528 22:05:17.860751 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.42622 (* 1 = 0.42622 loss)
I0528 22:05:17.860755 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00836426 (* 1 = 0.00836426 loss)
I0528 22:05:17.860759 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0646119 (* 1 = 0.0646119 loss)
I0528 22:05:17.860764 10644 sgd_solver.cpp:106] Iteration 7280, lr = 0.0002
I0528 22:06:06.302714 10644 solver.cpp:228] Iteration 7300, loss = 0.321041
I0528 22:06:06.302738 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0528 22:06:06.302745 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.159827 (* 1 = 0.159827 loss)
I0528 22:06:06.302749 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.364724 (* 1 = 0.364724 loss)
I0528 22:06:06.302753 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139717 (* 1 = 0.0139717 loss)
I0528 22:06:06.302757 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0381047 (* 1 = 0.0381047 loss)
I0528 22:06:06.302763 10644 sgd_solver.cpp:106] Iteration 7300, lr = 0.0002
I0528 22:06:54.761397 10644 solver.cpp:228] Iteration 7320, loss = 0.529638
I0528 22:06:54.761423 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 22:06:54.761431 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179878 (* 1 = 0.0179878 loss)
I0528 22:06:54.761435 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0440657 (* 1 = 0.0440657 loss)
I0528 22:06:54.761440 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00553597 (* 1 = 0.00553597 loss)
I0528 22:06:54.761443 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144435 (* 1 = 0.0144435 loss)
I0528 22:06:54.761449 10644 sgd_solver.cpp:106] Iteration 7320, lr = 0.0002
I0528 22:07:43.315841 10644 solver.cpp:228] Iteration 7340, loss = 0.41026
I0528 22:07:43.315867 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 22:07:43.315876 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.16643 (* 1 = 0.16643 loss)
I0528 22:07:43.315879 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.300525 (* 1 = 0.300525 loss)
I0528 22:07:43.315883 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200889 (* 1 = 0.0200889 loss)
I0528 22:07:43.315887 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028815 (* 1 = 0.028815 loss)
I0528 22:07:43.315892 10644 sgd_solver.cpp:106] Iteration 7340, lr = 0.0002
I0528 22:08:31.878942 10644 solver.cpp:228] Iteration 7360, loss = 0.238379
I0528 22:08:31.878968 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 22:08:31.878974 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.128704 (* 1 = 0.128704 loss)
I0528 22:08:31.878978 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.243952 (* 1 = 0.243952 loss)
I0528 22:08:31.878983 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0423585 (* 1 = 0.0423585 loss)
I0528 22:08:31.878986 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0432698 (* 1 = 0.0432698 loss)
I0528 22:08:31.878991 10644 sgd_solver.cpp:106] Iteration 7360, lr = 0.0002
I0528 22:09:20.415055 10644 solver.cpp:228] Iteration 7380, loss = 0.2542
I0528 22:09:20.415086 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 22:09:20.415096 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591634 (* 1 = 0.0591634 loss)
I0528 22:09:20.415103 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.198306 (* 1 = 0.198306 loss)
I0528 22:09:20.415108 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0264345 (* 1 = 0.0264345 loss)
I0528 22:09:20.415114 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269895 (* 1 = 0.0269895 loss)
I0528 22:09:20.415122 10644 sgd_solver.cpp:106] Iteration 7380, lr = 0.0002
speed: 2.431s / iter
I0528 22:10:08.958111 10644 solver.cpp:228] Iteration 7400, loss = 0.689514
I0528 22:10:08.958137 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 22:10:08.958144 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.184556 (* 1 = 0.184556 loss)
I0528 22:10:08.958149 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.397832 (* 1 = 0.397832 loss)
I0528 22:10:08.958153 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0576184 (* 1 = 0.0576184 loss)
I0528 22:10:08.958156 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.225938 (* 1 = 0.225938 loss)
I0528 22:10:08.958161 10644 sgd_solver.cpp:106] Iteration 7400, lr = 0.0002
I0528 22:10:57.508117 10644 solver.cpp:228] Iteration 7420, loss = 0.394401
I0528 22:10:57.508142 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:10:57.508150 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0516565 (* 1 = 0.0516565 loss)
I0528 22:10:57.508154 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112019 (* 1 = 0.112019 loss)
I0528 22:10:57.508158 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330902 (* 1 = 0.00330902 loss)
I0528 22:10:57.508162 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159043 (* 1 = 0.0159043 loss)
I0528 22:10:57.508167 10644 sgd_solver.cpp:106] Iteration 7420, lr = 0.0002
I0528 22:11:46.056031 10644 solver.cpp:228] Iteration 7440, loss = 0.349202
I0528 22:11:46.056059 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 22:11:46.056067 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.157116 (* 1 = 0.157116 loss)
I0528 22:11:46.056071 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.313871 (* 1 = 0.313871 loss)
I0528 22:11:46.056076 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0325364 (* 1 = 0.0325364 loss)
I0528 22:11:46.056079 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0828124 (* 1 = 0.0828124 loss)
I0528 22:11:46.056084 10644 sgd_solver.cpp:106] Iteration 7440, lr = 0.0002
I0528 22:12:34.570684 10644 solver.cpp:228] Iteration 7460, loss = 0.313971
I0528 22:12:34.570713 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 22:12:34.570722 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.202152 (* 1 = 0.202152 loss)
I0528 22:12:34.570729 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.412876 (* 1 = 0.412876 loss)
I0528 22:12:34.570735 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0317209 (* 1 = 0.0317209 loss)
I0528 22:12:34.570741 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0870164 (* 1 = 0.0870164 loss)
I0528 22:12:34.570749 10644 sgd_solver.cpp:106] Iteration 7460, lr = 0.0002
I0528 22:13:23.094122 10644 solver.cpp:228] Iteration 7480, loss = 0.579775
I0528 22:13:23.094151 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 22:13:23.094161 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.21417 (* 1 = 0.21417 loss)
I0528 22:13:23.094167 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.500344 (* 1 = 0.500344 loss)
I0528 22:13:23.094172 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187878 (* 1 = 0.0187878 loss)
I0528 22:13:23.094178 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308792 (* 1 = 0.0308792 loss)
I0528 22:13:23.094184 10644 sgd_solver.cpp:106] Iteration 7480, lr = 0.0002
I0528 22:14:11.643635 10644 solver.cpp:228] Iteration 7500, loss = 0.24857
I0528 22:14:11.643661 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:14:11.643668 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437932 (* 1 = 0.0437932 loss)
I0528 22:14:11.643672 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.173735 (* 1 = 0.173735 loss)
I0528 22:14:11.643676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00304798 (* 1 = 0.00304798 loss)
I0528 22:14:11.643679 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100764 (* 1 = 0.0100764 loss)
I0528 22:14:11.643685 10644 sgd_solver.cpp:106] Iteration 7500, lr = 0.0002
I0528 22:15:00.205651 10644 solver.cpp:228] Iteration 7520, loss = 0.519236
I0528 22:15:00.205677 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 22:15:00.205683 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0940569 (* 1 = 0.0940569 loss)
I0528 22:15:00.205687 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0756614 (* 1 = 0.0756614 loss)
I0528 22:15:00.205691 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202087 (* 1 = 0.00202087 loss)
I0528 22:15:00.205694 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119423 (* 1 = 0.0119423 loss)
I0528 22:15:00.205700 10644 sgd_solver.cpp:106] Iteration 7520, lr = 0.0002
I0528 22:15:48.768963 10644 solver.cpp:228] Iteration 7540, loss = 0.328162
I0528 22:15:48.769004 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0528 22:15:48.769014 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.40939 (* 1 = 0.40939 loss)
I0528 22:15:48.769019 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.598464 (* 1 = 0.598464 loss)
I0528 22:15:48.769026 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0466938 (* 1 = 0.0466938 loss)
I0528 22:15:48.769031 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115911 (* 1 = 0.115911 loss)
I0528 22:15:48.769037 10644 sgd_solver.cpp:106] Iteration 7540, lr = 0.0002
I0528 22:16:37.313087 10644 solver.cpp:228] Iteration 7560, loss = 0.352139
I0528 22:16:37.313114 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:16:37.313124 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0657007 (* 1 = 0.0657007 loss)
I0528 22:16:37.313130 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178787 (* 1 = 0.178787 loss)
I0528 22:16:37.313135 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128904 (* 1 = 0.0128904 loss)
I0528 22:16:37.313140 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0279623 (* 1 = 0.0279623 loss)
I0528 22:16:37.313148 10644 sgd_solver.cpp:106] Iteration 7560, lr = 0.0002
I0528 22:17:26.103543 10644 solver.cpp:228] Iteration 7580, loss = 0.583626
I0528 22:17:26.103569 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0528 22:17:26.103574 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.197348 (* 1 = 0.197348 loss)
I0528 22:17:26.103579 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.375128 (* 1 = 0.375128 loss)
I0528 22:17:26.103581 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0321002 (* 1 = 0.0321002 loss)
I0528 22:17:26.103585 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0682938 (* 1 = 0.0682938 loss)
I0528 22:17:26.103590 10644 sgd_solver.cpp:106] Iteration 7580, lr = 0.0002
speed: 2.431s / iter
I0528 22:18:14.796984 10644 solver.cpp:228] Iteration 7600, loss = 0.385839
I0528 22:18:14.797010 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:18:14.797017 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0514379 (* 1 = 0.0514379 loss)
I0528 22:18:14.797021 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112077 (* 1 = 0.112077 loss)
I0528 22:18:14.797024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00693763 (* 1 = 0.00693763 loss)
I0528 22:18:14.797029 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00634884 (* 1 = 0.00634884 loss)
I0528 22:18:14.797032 10644 sgd_solver.cpp:106] Iteration 7600, lr = 0.0002
I0528 22:19:03.466109 10644 solver.cpp:228] Iteration 7620, loss = 0.27721
I0528 22:19:03.466135 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 22:19:03.466142 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0123888 (* 1 = 0.0123888 loss)
I0528 22:19:03.466146 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0357003 (* 1 = 0.0357003 loss)
I0528 22:19:03.466150 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000709415 (* 1 = 0.000709415 loss)
I0528 22:19:03.466154 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00409405 (* 1 = 0.00409405 loss)
I0528 22:19:03.466159 10644 sgd_solver.cpp:106] Iteration 7620, lr = 0.0002
I0528 22:19:52.116598 10644 solver.cpp:228] Iteration 7640, loss = 0.431234
I0528 22:19:52.116624 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:19:52.116632 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.04981 (* 1 = 0.04981 loss)
I0528 22:19:52.116636 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142461 (* 1 = 0.142461 loss)
I0528 22:19:52.116641 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00720252 (* 1 = 0.00720252 loss)
I0528 22:19:52.116644 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00859666 (* 1 = 0.00859666 loss)
I0528 22:19:52.116650 10644 sgd_solver.cpp:106] Iteration 7640, lr = 0.0002
I0528 22:20:40.798893 10644 solver.cpp:228] Iteration 7660, loss = 0.562599
I0528 22:20:40.798969 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 22:20:40.798992 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.217484 (* 1 = 0.217484 loss)
I0528 22:20:40.799010 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.316845 (* 1 = 0.316845 loss)
I0528 22:20:40.799027 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0323962 (* 1 = 0.0323962 loss)
I0528 22:20:40.799044 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0726186 (* 1 = 0.0726186 loss)
I0528 22:20:40.799064 10644 sgd_solver.cpp:106] Iteration 7660, lr = 0.0002
I0528 22:21:29.552474 10644 solver.cpp:228] Iteration 7680, loss = 0.489266
I0528 22:21:29.552502 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 22:21:29.552511 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00945569 (* 1 = 0.00945569 loss)
I0528 22:21:29.552516 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1179 (* 1 = 0.1179 loss)
I0528 22:21:29.552521 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0175863 (* 1 = 0.0175863 loss)
I0528 22:21:29.552526 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275171 (* 1 = 0.0275171 loss)
I0528 22:21:29.552532 10644 sgd_solver.cpp:106] Iteration 7680, lr = 0.0002
I0528 22:22:18.181274 10644 solver.cpp:228] Iteration 7700, loss = 0.416199
I0528 22:22:18.181303 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 22:22:18.181310 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.230846 (* 1 = 0.230846 loss)
I0528 22:22:18.181314 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.247422 (* 1 = 0.247422 loss)
I0528 22:22:18.181318 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0240473 (* 1 = 0.0240473 loss)
I0528 22:22:18.181321 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0507032 (* 1 = 0.0507032 loss)
I0528 22:22:18.181327 10644 sgd_solver.cpp:106] Iteration 7700, lr = 0.0002
I0528 22:23:06.771889 10644 solver.cpp:228] Iteration 7720, loss = 0.294273
I0528 22:23:06.771916 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 22:23:06.771924 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241142 (* 1 = 0.0241142 loss)
I0528 22:23:06.771929 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109722 (* 1 = 0.109722 loss)
I0528 22:23:06.771934 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0225673 (* 1 = 0.0225673 loss)
I0528 22:23:06.771940 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00871959 (* 1 = 0.00871959 loss)
I0528 22:23:06.771945 10644 sgd_solver.cpp:106] Iteration 7720, lr = 0.0002
I0528 22:23:55.448451 10644 solver.cpp:228] Iteration 7740, loss = 0.327986
I0528 22:23:55.448479 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:23:55.448489 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0895964 (* 1 = 0.0895964 loss)
I0528 22:23:55.448494 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.223665 (* 1 = 0.223665 loss)
I0528 22:23:55.448498 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00915646 (* 1 = 0.00915646 loss)
I0528 22:23:55.448503 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235726 (* 1 = 0.0235726 loss)
I0528 22:23:55.448508 10644 sgd_solver.cpp:106] Iteration 7740, lr = 0.0002
I0528 22:24:44.172786 10644 solver.cpp:228] Iteration 7760, loss = 0.341127
I0528 22:24:44.172811 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 22:24:44.172819 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00463206 (* 1 = 0.00463206 loss)
I0528 22:24:44.172823 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0690444 (* 1 = 0.0690444 loss)
I0528 22:24:44.172827 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0517119 (* 1 = 0.0517119 loss)
I0528 22:24:44.172830 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940943 (* 1 = 0.00940943 loss)
I0528 22:24:44.172835 10644 sgd_solver.cpp:106] Iteration 7760, lr = 0.0002
I0528 22:25:32.910681 10644 solver.cpp:228] Iteration 7780, loss = 0.616462
I0528 22:25:32.910707 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:25:32.910717 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0712668 (* 1 = 0.0712668 loss)
I0528 22:25:32.910720 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.238633 (* 1 = 0.238633 loss)
I0528 22:25:32.910724 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260225 (* 1 = 0.0260225 loss)
I0528 22:25:32.910727 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196543 (* 1 = 0.0196543 loss)
I0528 22:25:32.910733 10644 sgd_solver.cpp:106] Iteration 7780, lr = 0.0002
speed: 2.431s / iter
I0528 22:26:21.542795 10644 solver.cpp:228] Iteration 7800, loss = 0.294918
I0528 22:26:21.542826 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 22:26:21.542836 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.141528 (* 1 = 0.141528 loss)
I0528 22:26:21.542843 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157161 (* 1 = 0.157161 loss)
I0528 22:26:21.542850 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00630983 (* 1 = 0.00630983 loss)
I0528 22:26:21.542855 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309132 (* 1 = 0.0309132 loss)
I0528 22:26:21.542863 10644 sgd_solver.cpp:106] Iteration 7800, lr = 0.0002
I0528 22:27:10.197638 10644 solver.cpp:228] Iteration 7820, loss = 0.326248
I0528 22:27:10.197664 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0528 22:27:10.197671 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.282737 (* 1 = 0.282737 loss)
I0528 22:27:10.197675 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.253621 (* 1 = 0.253621 loss)
I0528 22:27:10.197679 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00454932 (* 1 = 0.00454932 loss)
I0528 22:27:10.197684 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0605421 (* 1 = 0.0605421 loss)
I0528 22:27:10.197688 10644 sgd_solver.cpp:106] Iteration 7820, lr = 0.0002
I0528 22:27:58.766265 10644 solver.cpp:228] Iteration 7840, loss = 0.493793
I0528 22:27:58.766293 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:27:58.766299 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0531253 (* 1 = 0.0531253 loss)
I0528 22:27:58.766304 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.140634 (* 1 = 0.140634 loss)
I0528 22:27:58.766307 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0070502 (* 1 = 0.0070502 loss)
I0528 22:27:58.766311 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00746323 (* 1 = 0.00746323 loss)
I0528 22:27:58.766316 10644 sgd_solver.cpp:106] Iteration 7840, lr = 0.0002
I0528 22:28:47.402623 10644 solver.cpp:228] Iteration 7860, loss = 0.370104
I0528 22:28:47.402652 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 22:28:47.402662 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.124606 (* 1 = 0.124606 loss)
I0528 22:28:47.402665 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.198229 (* 1 = 0.198229 loss)
I0528 22:28:47.402669 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144794 (* 1 = 0.0144794 loss)
I0528 22:28:47.402673 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021963 (* 1 = 0.021963 loss)
I0528 22:28:47.402678 10644 sgd_solver.cpp:106] Iteration 7860, lr = 0.0002
I0528 22:29:36.212406 10644 solver.cpp:228] Iteration 7880, loss = 0.613793
I0528 22:29:36.212436 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.460938
I0528 22:29:36.212447 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.860007 (* 1 = 0.860007 loss)
I0528 22:29:36.212453 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.787042 (* 1 = 0.787042 loss)
I0528 22:29:36.212460 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.196147 (* 1 = 0.196147 loss)
I0528 22:29:36.212466 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.898341 (* 1 = 0.898341 loss)
I0528 22:29:36.212473 10644 sgd_solver.cpp:106] Iteration 7880, lr = 0.0002
I0528 22:30:24.882942 10644 solver.cpp:228] Iteration 7900, loss = 0.322907
I0528 22:30:24.882972 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 22:30:24.882982 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000704052 (* 1 = 0.000704052 loss)
I0528 22:30:24.882988 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.039888 (* 1 = 0.039888 loss)
I0528 22:30:24.882994 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00502291 (* 1 = 0.00502291 loss)
I0528 22:30:24.883000 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0458544 (* 1 = 0.0458544 loss)
I0528 22:30:24.883008 10644 sgd_solver.cpp:106] Iteration 7900, lr = 0.0002
I0528 22:31:13.575510 10644 solver.cpp:228] Iteration 7920, loss = 0.381715
I0528 22:31:13.575536 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 22:31:13.575543 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0802767 (* 1 = 0.0802767 loss)
I0528 22:31:13.575547 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.164332 (* 1 = 0.164332 loss)
I0528 22:31:13.575551 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110764 (* 1 = 0.0110764 loss)
I0528 22:31:13.575554 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311259 (* 1 = 0.0311259 loss)
I0528 22:31:13.575561 10644 sgd_solver.cpp:106] Iteration 7920, lr = 0.0002
I0528 22:32:02.145746 10644 solver.cpp:228] Iteration 7940, loss = 0.435137
I0528 22:32:02.145771 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0528 22:32:02.145779 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.267088 (* 1 = 0.267088 loss)
I0528 22:32:02.145783 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.445043 (* 1 = 0.445043 loss)
I0528 22:32:02.145787 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135665 (* 1 = 0.0135665 loss)
I0528 22:32:02.145790 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0777205 (* 1 = 0.0777205 loss)
I0528 22:32:02.145797 10644 sgd_solver.cpp:106] Iteration 7940, lr = 0.0002
I0528 22:32:50.697243 10644 solver.cpp:228] Iteration 7960, loss = 0.28456
I0528 22:32:50.697274 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:32:50.697283 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540774 (* 1 = 0.0540774 loss)
I0528 22:32:50.697286 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0698709 (* 1 = 0.0698709 loss)
I0528 22:32:50.697290 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00255267 (* 1 = 0.00255267 loss)
I0528 22:32:50.697294 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257945 (* 1 = 0.0257945 loss)
I0528 22:32:50.697300 10644 sgd_solver.cpp:106] Iteration 7960, lr = 0.0002
I0528 22:33:39.245743 10644 solver.cpp:228] Iteration 7980, loss = 0.422808
I0528 22:33:39.245774 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 22:33:39.245781 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00317731 (* 1 = 0.00317731 loss)
I0528 22:33:39.245786 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0994263 (* 1 = 0.0994263 loss)
I0528 22:33:39.245793 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219183 (* 1 = 0.0219183 loss)
I0528 22:33:39.245800 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.20606 (* 1 = 0.20606 loss)
I0528 22:33:39.245805 10644 sgd_solver.cpp:106] Iteration 7980, lr = 0.0002
speed: 2.431s / iter
I0528 22:34:27.819447 10644 solver.cpp:228] Iteration 8000, loss = 0.256452
I0528 22:34:27.819473 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:34:27.819481 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0979349 (* 1 = 0.0979349 loss)
I0528 22:34:27.819486 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.133836 (* 1 = 0.133836 loss)
I0528 22:34:27.819489 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00950471 (* 1 = 0.00950471 loss)
I0528 22:34:27.819494 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.09233 (* 1 = 0.09233 loss)
I0528 22:34:27.819499 10644 sgd_solver.cpp:106] Iteration 8000, lr = 0.0002
I0528 22:35:16.411530 10644 solver.cpp:228] Iteration 8020, loss = 0.274432
I0528 22:35:16.411554 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 22:35:16.411561 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.207354 (* 1 = 0.207354 loss)
I0528 22:35:16.411566 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.375223 (* 1 = 0.375223 loss)
I0528 22:35:16.411569 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254749 (* 1 = 0.0254749 loss)
I0528 22:35:16.411572 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353127 (* 1 = 0.0353127 loss)
I0528 22:35:16.411577 10644 sgd_solver.cpp:106] Iteration 8020, lr = 0.0002
I0528 22:36:04.970162 10644 solver.cpp:228] Iteration 8040, loss = 0.417324
I0528 22:36:04.970187 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 22:36:04.970194 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.21305 (* 1 = 0.21305 loss)
I0528 22:36:04.970198 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.331863 (* 1 = 0.331863 loss)
I0528 22:36:04.970201 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0346822 (* 1 = 0.0346822 loss)
I0528 22:36:04.970204 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0679674 (* 1 = 0.0679674 loss)
I0528 22:36:04.970209 10644 sgd_solver.cpp:106] Iteration 8040, lr = 0.0002
I0528 22:36:53.519333 10644 solver.cpp:228] Iteration 8060, loss = 0.256746
I0528 22:36:53.519358 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:36:53.519367 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0930642 (* 1 = 0.0930642 loss)
I0528 22:36:53.519373 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136305 (* 1 = 0.136305 loss)
I0528 22:36:53.519378 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00723342 (* 1 = 0.00723342 loss)
I0528 22:36:53.519384 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00730378 (* 1 = 0.00730378 loss)
I0528 22:36:53.519390 10644 sgd_solver.cpp:106] Iteration 8060, lr = 0.0002
I0528 22:37:42.088171 10644 solver.cpp:228] Iteration 8080, loss = 0.41805
I0528 22:37:42.088204 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 22:37:42.088212 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.132794 (* 1 = 0.132794 loss)
I0528 22:37:42.088214 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.291981 (* 1 = 0.291981 loss)
I0528 22:37:42.088218 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0299462 (* 1 = 0.0299462 loss)
I0528 22:37:42.088222 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0804077 (* 1 = 0.0804077 loss)
I0528 22:37:42.088228 10644 sgd_solver.cpp:106] Iteration 8080, lr = 0.0002
I0528 22:38:30.670604 10644 solver.cpp:228] Iteration 8100, loss = 0.278348
I0528 22:38:30.670629 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:38:30.670635 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430602 (* 1 = 0.0430602 loss)
I0528 22:38:30.670639 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0904911 (* 1 = 0.0904911 loss)
I0528 22:38:30.670644 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00988059 (* 1 = 0.00988059 loss)
I0528 22:38:30.670646 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164475 (* 1 = 0.0164475 loss)
I0528 22:38:30.670651 10644 sgd_solver.cpp:106] Iteration 8100, lr = 0.0002
I0528 22:39:19.243474 10644 solver.cpp:228] Iteration 8120, loss = 0.325654
I0528 22:39:19.243500 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:39:19.243507 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0759958 (* 1 = 0.0759958 loss)
I0528 22:39:19.243511 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120144 (* 1 = 0.120144 loss)
I0528 22:39:19.243515 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00589822 (* 1 = 0.00589822 loss)
I0528 22:39:19.243518 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139932 (* 1 = 0.0139932 loss)
I0528 22:39:19.243523 10644 sgd_solver.cpp:106] Iteration 8120, lr = 0.0002
I0528 22:40:07.809499 10644 solver.cpp:228] Iteration 8140, loss = 0.322774
I0528 22:40:07.809535 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 22:40:07.809542 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118286 (* 1 = 0.118286 loss)
I0528 22:40:07.809546 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.193369 (* 1 = 0.193369 loss)
I0528 22:40:07.809551 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132461 (* 1 = 0.0132461 loss)
I0528 22:40:07.809553 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0657916 (* 1 = 0.0657916 loss)
I0528 22:40:07.809558 10644 sgd_solver.cpp:106] Iteration 8140, lr = 0.0002
I0528 22:40:56.358211 10644 solver.cpp:228] Iteration 8160, loss = 0.287034
I0528 22:40:56.358235 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 22:40:56.358243 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702261 (* 1 = 0.0702261 loss)
I0528 22:40:56.358247 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144543 (* 1 = 0.144543 loss)
I0528 22:40:56.358252 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228777 (* 1 = 0.00228777 loss)
I0528 22:40:56.358255 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00960449 (* 1 = 0.00960449 loss)
I0528 22:40:56.358261 10644 sgd_solver.cpp:106] Iteration 8160, lr = 0.0002
I0528 22:41:44.919939 10644 solver.cpp:228] Iteration 8180, loss = 0.297165
I0528 22:41:44.919965 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:41:44.919973 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0993103 (* 1 = 0.0993103 loss)
I0528 22:41:44.919978 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145664 (* 1 = 0.145664 loss)
I0528 22:41:44.919981 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052718 (* 1 = 0.0052718 loss)
I0528 22:41:44.919986 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242064 (* 1 = 0.0242064 loss)
I0528 22:41:44.919991 10644 sgd_solver.cpp:106] Iteration 8180, lr = 0.0002
speed: 2.431s / iter
I0528 22:42:33.585608 10644 solver.cpp:228] Iteration 8200, loss = 0.372572
I0528 22:42:33.585649 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 22:42:33.585659 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.189944 (* 1 = 0.189944 loss)
I0528 22:42:33.585664 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.309494 (* 1 = 0.309494 loss)
I0528 22:42:33.585666 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0096161 (* 1 = 0.0096161 loss)
I0528 22:42:33.585670 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445427 (* 1 = 0.0445427 loss)
I0528 22:42:33.585678 10644 sgd_solver.cpp:106] Iteration 8200, lr = 0.0002
I0528 22:43:22.148373 10644 solver.cpp:228] Iteration 8220, loss = 0.357055
I0528 22:43:22.148398 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:43:22.148406 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0749614 (* 1 = 0.0749614 loss)
I0528 22:43:22.148409 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134493 (* 1 = 0.134493 loss)
I0528 22:43:22.148413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00797893 (* 1 = 0.00797893 loss)
I0528 22:43:22.148416 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012432 (* 1 = 0.012432 loss)
I0528 22:43:22.148422 10644 sgd_solver.cpp:106] Iteration 8220, lr = 0.0002
I0528 22:44:10.716420 10644 solver.cpp:228] Iteration 8240, loss = 0.351283
I0528 22:44:10.716445 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 22:44:10.716452 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0370592 (* 1 = 0.0370592 loss)
I0528 22:44:10.716456 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234501 (* 1 = 0.234501 loss)
I0528 22:44:10.716459 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00539497 (* 1 = 0.00539497 loss)
I0528 22:44:10.716464 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197376 (* 1 = 0.0197376 loss)
I0528 22:44:10.716469 10644 sgd_solver.cpp:106] Iteration 8240, lr = 0.0002
I0528 22:44:59.268400 10644 solver.cpp:228] Iteration 8260, loss = 0.417276
I0528 22:44:59.268429 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 22:44:59.268436 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.141296 (* 1 = 0.141296 loss)
I0528 22:44:59.268440 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.24912 (* 1 = 0.24912 loss)
I0528 22:44:59.268443 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110365 (* 1 = 0.0110365 loss)
I0528 22:44:59.268446 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0685184 (* 1 = 0.0685184 loss)
I0528 22:44:59.268452 10644 sgd_solver.cpp:106] Iteration 8260, lr = 0.0002
I0528 22:45:47.821846 10644 solver.cpp:228] Iteration 8280, loss = 0.346464
I0528 22:45:47.821874 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:45:47.821882 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319796 (* 1 = 0.0319796 loss)
I0528 22:45:47.821885 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.117631 (* 1 = 0.117631 loss)
I0528 22:45:47.821889 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00477557 (* 1 = 0.00477557 loss)
I0528 22:45:47.821892 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0060174 (* 1 = 0.0060174 loss)
I0528 22:45:47.821897 10644 sgd_solver.cpp:106] Iteration 8280, lr = 0.0002
I0528 22:46:36.370115 10644 solver.cpp:228] Iteration 8300, loss = 0.514292
I0528 22:46:36.370157 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:46:36.370165 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743643 (* 1 = 0.0743643 loss)
I0528 22:46:36.370169 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110195 (* 1 = 0.110195 loss)
I0528 22:46:36.370172 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135176 (* 1 = 0.0135176 loss)
I0528 22:46:36.370177 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00836554 (* 1 = 0.00836554 loss)
I0528 22:46:36.370182 10644 sgd_solver.cpp:106] Iteration 8300, lr = 0.0002
I0528 22:47:24.935731 10644 solver.cpp:228] Iteration 8320, loss = 0.303183
I0528 22:47:24.935757 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0528 22:47:24.935765 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.106275 (* 1 = 0.106275 loss)
I0528 22:47:24.935770 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.298091 (* 1 = 0.298091 loss)
I0528 22:47:24.935773 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015831 (* 1 = 0.015831 loss)
I0528 22:47:24.935776 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.04093 (* 1 = 0.04093 loss)
I0528 22:47:24.935783 10644 sgd_solver.cpp:106] Iteration 8320, lr = 0.0002
I0528 22:48:13.505802 10644 solver.cpp:228] Iteration 8340, loss = 0.728898
I0528 22:48:13.505831 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:48:13.505838 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.106604 (* 1 = 0.106604 loss)
I0528 22:48:13.505843 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.17359 (* 1 = 0.17359 loss)
I0528 22:48:13.505846 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382782 (* 1 = 0.00382782 loss)
I0528 22:48:13.505851 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145493 (* 1 = 0.0145493 loss)
I0528 22:48:13.505856 10644 sgd_solver.cpp:106] Iteration 8340, lr = 0.0002
I0528 22:49:02.083570 10644 solver.cpp:228] Iteration 8360, loss = 0.751422
I0528 22:49:02.083595 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 22:49:02.083601 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.269466 (* 1 = 0.269466 loss)
I0528 22:49:02.083606 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.372902 (* 1 = 0.372902 loss)
I0528 22:49:02.083609 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0650466 (* 1 = 0.0650466 loss)
I0528 22:49:02.083613 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.22305 (* 1 = 0.22305 loss)
I0528 22:49:02.083618 10644 sgd_solver.cpp:106] Iteration 8360, lr = 0.0002
I0528 22:49:50.622032 10644 solver.cpp:228] Iteration 8380, loss = 0.286295
I0528 22:49:50.622059 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:49:50.622067 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0962465 (* 1 = 0.0962465 loss)
I0528 22:49:50.622071 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.122227 (* 1 = 0.122227 loss)
I0528 22:49:50.622076 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00288586 (* 1 = 0.00288586 loss)
I0528 22:49:50.622079 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150085 (* 1 = 0.0150085 loss)
I0528 22:49:50.622084 10644 sgd_solver.cpp:106] Iteration 8380, lr = 0.0002
speed: 2.431s / iter
I0528 22:50:39.185554 10644 solver.cpp:228] Iteration 8400, loss = 0.288604
I0528 22:50:39.185623 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0528 22:50:39.185645 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.184548 (* 1 = 0.184548 loss)
I0528 22:50:39.185662 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.381045 (* 1 = 0.381045 loss)
I0528 22:50:39.185678 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016699 (* 1 = 0.016699 loss)
I0528 22:50:39.185695 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0719078 (* 1 = 0.0719078 loss)
I0528 22:50:39.185712 10644 sgd_solver.cpp:106] Iteration 8400, lr = 0.0002
I0528 22:51:27.755815 10644 solver.cpp:228] Iteration 8420, loss = 0.26944
I0528 22:51:27.755842 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 22:51:27.755851 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0382618 (* 1 = 0.0382618 loss)
I0528 22:51:27.755856 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.162435 (* 1 = 0.162435 loss)
I0528 22:51:27.755858 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017197 (* 1 = 0.017197 loss)
I0528 22:51:27.755862 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0598737 (* 1 = 0.0598737 loss)
I0528 22:51:27.755867 10644 sgd_solver.cpp:106] Iteration 8420, lr = 0.0002
I0528 22:52:16.302441 10644 solver.cpp:228] Iteration 8440, loss = 0.30843
I0528 22:52:16.302470 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:52:16.302480 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0477668 (* 1 = 0.0477668 loss)
I0528 22:52:16.302487 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0533453 (* 1 = 0.0533453 loss)
I0528 22:52:16.302495 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00551545 (* 1 = 0.00551545 loss)
I0528 22:52:16.302500 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00874233 (* 1 = 0.00874233 loss)
I0528 22:52:16.302507 10644 sgd_solver.cpp:106] Iteration 8440, lr = 0.0002
I0528 22:53:04.891782 10644 solver.cpp:228] Iteration 8460, loss = 0.380545
I0528 22:53:04.891808 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 22:53:04.891816 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.161293 (* 1 = 0.161293 loss)
I0528 22:53:04.891822 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.319205 (* 1 = 0.319205 loss)
I0528 22:53:04.891829 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00603045 (* 1 = 0.00603045 loss)
I0528 22:53:04.891834 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021898 (* 1 = 0.021898 loss)
I0528 22:53:04.891841 10644 sgd_solver.cpp:106] Iteration 8460, lr = 0.0002
I0528 22:53:53.469962 10644 solver.cpp:228] Iteration 8480, loss = 0.399573
I0528 22:53:53.469987 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 22:53:53.469995 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.135745 (* 1 = 0.135745 loss)
I0528 22:53:53.469997 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.27603 (* 1 = 0.27603 loss)
I0528 22:53:53.470001 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136667 (* 1 = 0.0136667 loss)
I0528 22:53:53.470005 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021298 (* 1 = 0.021298 loss)
I0528 22:53:53.470010 10644 sgd_solver.cpp:106] Iteration 8480, lr = 0.0002
I0528 22:54:42.013125 10644 solver.cpp:228] Iteration 8500, loss = 0.376652
I0528 22:54:42.013152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 22:54:42.013159 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.227095 (* 1 = 0.227095 loss)
I0528 22:54:42.013164 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234646 (* 1 = 0.234646 loss)
I0528 22:54:42.013166 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114451 (* 1 = 0.0114451 loss)
I0528 22:54:42.013170 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0349094 (* 1 = 0.0349094 loss)
I0528 22:54:42.013175 10644 sgd_solver.cpp:106] Iteration 8500, lr = 0.0002
I0528 22:55:30.572173 10644 solver.cpp:228] Iteration 8520, loss = 0.462995
I0528 22:55:30.572196 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 22:55:30.572204 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.112292 (* 1 = 0.112292 loss)
I0528 22:55:30.572208 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.284631 (* 1 = 0.284631 loss)
I0528 22:55:30.572211 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00461618 (* 1 = 0.00461618 loss)
I0528 22:55:30.572216 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307647 (* 1 = 0.0307647 loss)
I0528 22:55:30.572221 10644 sgd_solver.cpp:106] Iteration 8520, lr = 0.0002
I0528 22:56:19.132197 10644 solver.cpp:228] Iteration 8540, loss = 0.345137
I0528 22:56:19.132221 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 22:56:19.132228 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464891 (* 1 = 0.0464891 loss)
I0528 22:56:19.132232 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151364 (* 1 = 0.151364 loss)
I0528 22:56:19.132236 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124284 (* 1 = 0.0124284 loss)
I0528 22:56:19.132238 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224713 (* 1 = 0.0224713 loss)
I0528 22:56:19.132243 10644 sgd_solver.cpp:106] Iteration 8540, lr = 0.0002
I0528 22:57:07.702994 10644 solver.cpp:228] Iteration 8560, loss = 0.351928
I0528 22:57:07.703021 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:57:07.703028 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0332639 (* 1 = 0.0332639 loss)
I0528 22:57:07.703032 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114564 (* 1 = 0.114564 loss)
I0528 22:57:07.703035 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00946344 (* 1 = 0.00946344 loss)
I0528 22:57:07.703039 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00626192 (* 1 = 0.00626192 loss)
I0528 22:57:07.703044 10644 sgd_solver.cpp:106] Iteration 8560, lr = 0.0002
I0528 22:57:56.272095 10644 solver.cpp:228] Iteration 8580, loss = 0.331577
I0528 22:57:56.272121 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 22:57:56.272130 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371729 (* 1 = 0.0371729 loss)
I0528 22:57:56.272133 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.086395 (* 1 = 0.086395 loss)
I0528 22:57:56.272136 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00941352 (* 1 = 0.00941352 loss)
I0528 22:57:56.272140 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00616183 (* 1 = 0.00616183 loss)
I0528 22:57:56.272145 10644 sgd_solver.cpp:106] Iteration 8580, lr = 0.0002
speed: 2.431s / iter
I0528 22:58:44.846349 10644 solver.cpp:228] Iteration 8600, loss = 0.400908
I0528 22:58:44.846374 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 22:58:44.846381 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00122125 (* 1 = 0.00122125 loss)
I0528 22:58:44.846385 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0300447 (* 1 = 0.0300447 loss)
I0528 22:58:44.846390 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766325 (* 1 = 0.00766325 loss)
I0528 22:58:44.846392 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276304 (* 1 = 0.0276304 loss)
I0528 22:58:44.846398 10644 sgd_solver.cpp:106] Iteration 8600, lr = 0.0002
I0528 22:59:33.389303 10644 solver.cpp:228] Iteration 8620, loss = 0.305269
I0528 22:59:33.389328 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 22:59:33.389336 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0706404 (* 1 = 0.0706404 loss)
I0528 22:59:33.389341 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.221074 (* 1 = 0.221074 loss)
I0528 22:59:33.389345 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00888639 (* 1 = 0.00888639 loss)
I0528 22:59:33.389349 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304784 (* 1 = 0.0304784 loss)
I0528 22:59:33.389354 10644 sgd_solver.cpp:106] Iteration 8620, lr = 0.0002
I0528 23:00:21.947001 10644 solver.cpp:228] Iteration 8640, loss = 0.313195
I0528 23:00:21.947028 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0528 23:00:21.947036 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.119963 (* 1 = 0.119963 loss)
I0528 23:00:21.947039 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.235932 (* 1 = 0.235932 loss)
I0528 23:00:21.947043 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212893 (* 1 = 0.0212893 loss)
I0528 23:00:21.947047 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106789 (* 1 = 0.0106789 loss)
I0528 23:00:21.947052 10644 sgd_solver.cpp:106] Iteration 8640, lr = 0.0002
I0528 23:01:10.499369 10644 solver.cpp:228] Iteration 8660, loss = 0.304628
I0528 23:01:10.499394 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 23:01:10.499402 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.123141 (* 1 = 0.123141 loss)
I0528 23:01:10.499408 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.225001 (* 1 = 0.225001 loss)
I0528 23:01:10.499410 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165447 (* 1 = 0.0165447 loss)
I0528 23:01:10.499414 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247356 (* 1 = 0.0247356 loss)
I0528 23:01:10.499419 10644 sgd_solver.cpp:106] Iteration 8660, lr = 0.0002
I0528 23:01:59.202679 10644 solver.cpp:228] Iteration 8680, loss = 0.295429
I0528 23:01:59.202706 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:01:59.202716 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00271068 (* 1 = 0.00271068 loss)
I0528 23:01:59.202723 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0624113 (* 1 = 0.0624113 loss)
I0528 23:01:59.202728 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807305 (* 1 = 0.00807305 loss)
I0528 23:01:59.202733 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190922 (* 1 = 0.0190922 loss)
I0528 23:01:59.202739 10644 sgd_solver.cpp:106] Iteration 8680, lr = 0.0002
I0528 23:02:47.788893 10644 solver.cpp:228] Iteration 8700, loss = 0.378415
I0528 23:02:47.788921 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0528 23:02:47.788928 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.403622 (* 1 = 0.403622 loss)
I0528 23:02:47.788933 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.525146 (* 1 = 0.525146 loss)
I0528 23:02:47.788935 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0580349 (* 1 = 0.0580349 loss)
I0528 23:02:47.788939 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121202 (* 1 = 0.121202 loss)
I0528 23:02:47.788944 10644 sgd_solver.cpp:106] Iteration 8700, lr = 0.0002
I0528 23:03:36.349849 10644 solver.cpp:228] Iteration 8720, loss = 0.567462
I0528 23:03:36.349874 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 23:03:36.349882 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.212665 (* 1 = 0.212665 loss)
I0528 23:03:36.349886 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.307766 (* 1 = 0.307766 loss)
I0528 23:03:36.349889 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015216 (* 1 = 0.015216 loss)
I0528 23:03:36.349892 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0579509 (* 1 = 0.0579509 loss)
I0528 23:03:36.349898 10644 sgd_solver.cpp:106] Iteration 8720, lr = 0.0002
I0528 23:04:24.909390 10644 solver.cpp:228] Iteration 8740, loss = 0.231538
I0528 23:04:24.909415 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 23:04:24.909421 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0584966 (* 1 = 0.0584966 loss)
I0528 23:04:24.909425 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.122957 (* 1 = 0.122957 loss)
I0528 23:04:24.909430 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082262 (* 1 = 0.0082262 loss)
I0528 23:04:24.909433 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0073977 (* 1 = 0.0073977 loss)
I0528 23:04:24.909437 10644 sgd_solver.cpp:106] Iteration 8740, lr = 0.0002
I0528 23:05:13.461068 10644 solver.cpp:228] Iteration 8760, loss = 0.247323
I0528 23:05:13.461094 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 23:05:13.461102 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272233 (* 1 = 0.0272233 loss)
I0528 23:05:13.461104 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109585 (* 1 = 0.109585 loss)
I0528 23:05:13.461108 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759194 (* 1 = 0.00759194 loss)
I0528 23:05:13.461112 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0447394 (* 1 = 0.0447394 loss)
I0528 23:05:13.461117 10644 sgd_solver.cpp:106] Iteration 8760, lr = 0.0002
I0528 23:06:02.041653 10644 solver.cpp:228] Iteration 8780, loss = 0.529544
I0528 23:06:02.041680 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:06:02.041690 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413638 (* 1 = 0.0413638 loss)
I0528 23:06:02.041697 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0731762 (* 1 = 0.0731762 loss)
I0528 23:06:02.041702 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128605 (* 1 = 0.0128605 loss)
I0528 23:06:02.041708 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0088189 (* 1 = 0.0088189 loss)
I0528 23:06:02.041715 10644 sgd_solver.cpp:106] Iteration 8780, lr = 0.0002
speed: 2.431s / iter
I0528 23:06:50.568186 10644 solver.cpp:228] Iteration 8800, loss = 0.346308
I0528 23:06:50.568212 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 23:06:50.568219 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.129638 (* 1 = 0.129638 loss)
I0528 23:06:50.568223 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.273022 (* 1 = 0.273022 loss)
I0528 23:06:50.568228 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108354 (* 1 = 0.0108354 loss)
I0528 23:06:50.568231 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0483636 (* 1 = 0.0483636 loss)
I0528 23:06:50.568236 10644 sgd_solver.cpp:106] Iteration 8800, lr = 0.0002
I0528 23:07:39.144021 10644 solver.cpp:228] Iteration 8820, loss = 0.295123
I0528 23:07:39.144049 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 23:07:39.144058 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729729 (* 1 = 0.0729729 loss)
I0528 23:07:39.144065 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.122858 (* 1 = 0.122858 loss)
I0528 23:07:39.144071 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00640506 (* 1 = 0.00640506 loss)
I0528 23:07:39.144078 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162647 (* 1 = 0.0162647 loss)
I0528 23:07:39.144084 10644 sgd_solver.cpp:106] Iteration 8820, lr = 0.0002
I0528 23:08:27.664613 10644 solver.cpp:228] Iteration 8840, loss = 0.314787
I0528 23:08:27.664639 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 23:08:27.664649 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.141659 (* 1 = 0.141659 loss)
I0528 23:08:27.664656 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.262702 (* 1 = 0.262702 loss)
I0528 23:08:27.664662 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156576 (* 1 = 0.0156576 loss)
I0528 23:08:27.664669 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241303 (* 1 = 0.0241303 loss)
I0528 23:08:27.664675 10644 sgd_solver.cpp:106] Iteration 8840, lr = 0.0002
I0528 23:09:16.292568 10644 solver.cpp:228] Iteration 8860, loss = 0.401333
I0528 23:09:16.292594 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 23:09:16.292601 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.077951 (* 1 = 0.077951 loss)
I0528 23:09:16.292605 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.309447 (* 1 = 0.309447 loss)
I0528 23:09:16.292608 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155004 (* 1 = 0.0155004 loss)
I0528 23:09:16.292613 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198024 (* 1 = 0.0198024 loss)
I0528 23:09:16.292618 10644 sgd_solver.cpp:106] Iteration 8860, lr = 0.0002
I0528 23:10:04.823892 10644 solver.cpp:228] Iteration 8880, loss = 0.277998
I0528 23:10:04.823916 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 23:10:04.823923 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337014 (* 1 = 0.0337014 loss)
I0528 23:10:04.823927 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115577 (* 1 = 0.115577 loss)
I0528 23:10:04.823933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00827976 (* 1 = 0.00827976 loss)
I0528 23:10:04.823938 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145047 (* 1 = 0.0145047 loss)
I0528 23:10:04.823945 10644 sgd_solver.cpp:106] Iteration 8880, lr = 0.0002
I0528 23:10:53.357861 10644 solver.cpp:228] Iteration 8900, loss = 0.575945
I0528 23:10:53.357887 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:10:53.357894 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00245065 (* 1 = 0.00245065 loss)
I0528 23:10:53.357898 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0834668 (* 1 = 0.0834668 loss)
I0528 23:10:53.357903 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164829 (* 1 = 0.0164829 loss)
I0528 23:10:53.357905 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0442784 (* 1 = 0.0442784 loss)
I0528 23:10:53.357910 10644 sgd_solver.cpp:106] Iteration 8900, lr = 0.0002
I0528 23:11:41.890163 10644 solver.cpp:228] Iteration 8920, loss = 0.333328
I0528 23:11:41.890185 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0528 23:11:41.890192 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.241456 (* 1 = 0.241456 loss)
I0528 23:11:41.890197 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.35329 (* 1 = 0.35329 loss)
I0528 23:11:41.890202 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00925284 (* 1 = 0.00925284 loss)
I0528 23:11:41.890205 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285607 (* 1 = 0.0285607 loss)
I0528 23:11:41.890210 10644 sgd_solver.cpp:106] Iteration 8920, lr = 0.0002
I0528 23:12:30.457284 10644 solver.cpp:228] Iteration 8940, loss = 0.367237
I0528 23:12:30.457310 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0528 23:12:30.457319 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.267947 (* 1 = 0.267947 loss)
I0528 23:12:30.457322 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.545418 (* 1 = 0.545418 loss)
I0528 23:12:30.457326 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010524 (* 1 = 0.010524 loss)
I0528 23:12:30.457330 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0396201 (* 1 = 0.0396201 loss)
I0528 23:12:30.457335 10644 sgd_solver.cpp:106] Iteration 8940, lr = 0.0002
I0528 23:13:18.994810 10644 solver.cpp:228] Iteration 8960, loss = 0.351495
I0528 23:13:18.994837 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 23:13:18.994845 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0714867 (* 1 = 0.0714867 loss)
I0528 23:13:18.994849 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0830945 (* 1 = 0.0830945 loss)
I0528 23:13:18.994853 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134033 (* 1 = 0.0134033 loss)
I0528 23:13:18.994856 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102397 (* 1 = 0.0102397 loss)
I0528 23:13:18.994861 10644 sgd_solver.cpp:106] Iteration 8960, lr = 0.0002
I0528 23:14:07.563786 10644 solver.cpp:228] Iteration 8980, loss = 0.248688
I0528 23:14:07.563823 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0528 23:14:07.563832 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.09674 (* 1 = 0.09674 loss)
I0528 23:14:07.563836 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.292771 (* 1 = 0.292771 loss)
I0528 23:14:07.563840 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.008665 (* 1 = 0.008665 loss)
I0528 23:14:07.563844 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0404463 (* 1 = 0.0404463 loss)
I0528 23:14:07.563850 10644 sgd_solver.cpp:106] Iteration 8980, lr = 0.0002
speed: 2.431s / iter
I0528 23:14:56.108657 10644 solver.cpp:228] Iteration 9000, loss = 0.29992
I0528 23:14:56.108685 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:14:56.108692 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169056 (* 1 = 0.0169056 loss)
I0528 23:14:56.108696 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0857354 (* 1 = 0.0857354 loss)
I0528 23:14:56.108700 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190289 (* 1 = 0.0190289 loss)
I0528 23:14:56.108703 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013962 (* 1 = 0.013962 loss)
I0528 23:14:56.108708 10644 sgd_solver.cpp:106] Iteration 9000, lr = 0.0002
I0528 23:15:44.656586 10644 solver.cpp:228] Iteration 9020, loss = 0.560348
I0528 23:15:44.656615 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 23:15:44.656623 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590042 (* 1 = 0.0590042 loss)
I0528 23:15:44.656630 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.140443 (* 1 = 0.140443 loss)
I0528 23:15:44.656635 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112915 (* 1 = 0.0112915 loss)
I0528 23:15:44.656642 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251196 (* 1 = 0.0251196 loss)
I0528 23:15:44.656649 10644 sgd_solver.cpp:106] Iteration 9020, lr = 0.0002
I0528 23:16:33.174175 10644 solver.cpp:228] Iteration 9040, loss = 0.299513
I0528 23:16:33.174202 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:16:33.174211 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0669424 (* 1 = 0.0669424 loss)
I0528 23:16:33.174214 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0599694 (* 1 = 0.0599694 loss)
I0528 23:16:33.174218 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000809274 (* 1 = 0.000809274 loss)
I0528 23:16:33.174222 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158621 (* 1 = 0.0158621 loss)
I0528 23:16:33.174227 10644 sgd_solver.cpp:106] Iteration 9040, lr = 0.0002
I0528 23:17:21.730002 10644 solver.cpp:228] Iteration 9060, loss = 0.439089
I0528 23:17:21.730026 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 23:17:21.730033 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.128652 (* 1 = 0.128652 loss)
I0528 23:17:21.730038 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255991 (* 1 = 0.255991 loss)
I0528 23:17:21.730041 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271742 (* 1 = 0.0271742 loss)
I0528 23:17:21.730046 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0972311 (* 1 = 0.0972311 loss)
I0528 23:17:21.730051 10644 sgd_solver.cpp:106] Iteration 9060, lr = 0.0002
I0528 23:18:10.409205 10644 solver.cpp:228] Iteration 9080, loss = 0.699475
I0528 23:18:10.409236 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 23:18:10.409246 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0780942 (* 1 = 0.0780942 loss)
I0528 23:18:10.409253 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.188838 (* 1 = 0.188838 loss)
I0528 23:18:10.409260 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193112 (* 1 = 0.0193112 loss)
I0528 23:18:10.409265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260512 (* 1 = 0.0260512 loss)
I0528 23:18:10.409271 10644 sgd_solver.cpp:106] Iteration 9080, lr = 0.0002
I0528 23:18:58.933207 10644 solver.cpp:228] Iteration 9100, loss = 0.272599
I0528 23:18:58.933233 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:18:58.933240 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0401468 (* 1 = 0.0401468 loss)
I0528 23:18:58.933245 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178221 (* 1 = 0.178221 loss)
I0528 23:18:58.933248 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0175659 (* 1 = 0.0175659 loss)
I0528 23:18:58.933253 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037517 (* 1 = 0.037517 loss)
I0528 23:18:58.933257 10644 sgd_solver.cpp:106] Iteration 9100, lr = 0.0002
I0528 23:19:47.474156 10644 solver.cpp:228] Iteration 9120, loss = 0.48418
I0528 23:19:47.474184 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0528 23:19:47.474195 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.300099 (* 1 = 0.300099 loss)
I0528 23:19:47.474201 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.278027 (* 1 = 0.278027 loss)
I0528 23:19:47.474207 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0441846 (* 1 = 0.0441846 loss)
I0528 23:19:47.474213 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.075968 (* 1 = 0.075968 loss)
I0528 23:19:47.474220 10644 sgd_solver.cpp:106] Iteration 9120, lr = 0.0002
I0528 23:20:36.040609 10644 solver.cpp:228] Iteration 9140, loss = 0.290645
I0528 23:20:36.040637 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0528 23:20:36.040643 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.139773 (* 1 = 0.139773 loss)
I0528 23:20:36.040648 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.336415 (* 1 = 0.336415 loss)
I0528 23:20:36.040652 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143149 (* 1 = 0.0143149 loss)
I0528 23:20:36.040655 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351506 (* 1 = 0.0351506 loss)
I0528 23:20:36.040663 10644 sgd_solver.cpp:106] Iteration 9140, lr = 0.0002
I0528 23:21:24.600708 10644 solver.cpp:228] Iteration 9160, loss = 0.548549
I0528 23:21:24.600733 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0528 23:21:24.600741 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.222699 (* 1 = 0.222699 loss)
I0528 23:21:24.600746 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.499915 (* 1 = 0.499915 loss)
I0528 23:21:24.600750 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0358693 (* 1 = 0.0358693 loss)
I0528 23:21:24.600754 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0776724 (* 1 = 0.0776724 loss)
I0528 23:21:24.600760 10644 sgd_solver.cpp:106] Iteration 9160, lr = 0.0002
I0528 23:22:13.142349 10644 solver.cpp:228] Iteration 9180, loss = 0.429481
I0528 23:22:13.142387 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 23:22:13.142396 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0409801 (* 1 = 0.0409801 loss)
I0528 23:22:13.142400 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.198189 (* 1 = 0.198189 loss)
I0528 23:22:13.142405 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173735 (* 1 = 0.0173735 loss)
I0528 23:22:13.142408 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215441 (* 1 = 0.0215441 loss)
I0528 23:22:13.142416 10644 sgd_solver.cpp:106] Iteration 9180, lr = 0.0002
speed: 2.431s / iter
I0528 23:23:01.686318 10644 solver.cpp:228] Iteration 9200, loss = 0.302994
I0528 23:23:01.686347 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:23:01.686355 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0699336 (* 1 = 0.0699336 loss)
I0528 23:23:01.686359 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0795131 (* 1 = 0.0795131 loss)
I0528 23:23:01.686363 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0037943 (* 1 = 0.0037943 loss)
I0528 23:23:01.686367 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137006 (* 1 = 0.0137006 loss)
I0528 23:23:01.686372 10644 sgd_solver.cpp:106] Iteration 9200, lr = 0.0002
I0528 23:23:50.205031 10644 solver.cpp:228] Iteration 9220, loss = 0.246518
I0528 23:23:50.205058 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 23:23:50.205066 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0914316 (* 1 = 0.0914316 loss)
I0528 23:23:50.205070 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.186145 (* 1 = 0.186145 loss)
I0528 23:23:50.205075 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00639166 (* 1 = 0.00639166 loss)
I0528 23:23:50.205078 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372133 (* 1 = 0.0372133 loss)
I0528 23:23:50.205085 10644 sgd_solver.cpp:106] Iteration 9220, lr = 0.0002
I0528 23:24:38.738266 10644 solver.cpp:228] Iteration 9240, loss = 0.392498
I0528 23:24:38.738293 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 23:24:38.738301 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.228436 (* 1 = 0.228436 loss)
I0528 23:24:38.738304 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.356398 (* 1 = 0.356398 loss)
I0528 23:24:38.738308 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104547 (* 1 = 0.0104547 loss)
I0528 23:24:38.738312 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306298 (* 1 = 0.0306298 loss)
I0528 23:24:38.738317 10644 sgd_solver.cpp:106] Iteration 9240, lr = 0.0002
I0528 23:25:27.262370 10644 solver.cpp:228] Iteration 9260, loss = 0.34931
I0528 23:25:27.262394 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 23:25:27.262403 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0505643 (* 1 = 0.0505643 loss)
I0528 23:25:27.262406 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152494 (* 1 = 0.152494 loss)
I0528 23:25:27.262409 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00912033 (* 1 = 0.00912033 loss)
I0528 23:25:27.262413 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0882121 (* 1 = 0.0882121 loss)
I0528 23:25:27.262418 10644 sgd_solver.cpp:106] Iteration 9260, lr = 0.0002
I0528 23:26:15.828943 10644 solver.cpp:228] Iteration 9280, loss = 0.389881
I0528 23:26:15.828974 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 23:26:15.828980 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0762608 (* 1 = 0.0762608 loss)
I0528 23:26:15.828984 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108606 (* 1 = 0.108606 loss)
I0528 23:26:15.828989 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.006853 (* 1 = 0.006853 loss)
I0528 23:26:15.828991 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00554302 (* 1 = 0.00554302 loss)
I0528 23:26:15.828996 10644 sgd_solver.cpp:106] Iteration 9280, lr = 0.0002
I0528 23:27:04.354629 10644 solver.cpp:228] Iteration 9300, loss = 0.434469
I0528 23:27:04.354661 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0528 23:27:04.354668 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.122494 (* 1 = 0.122494 loss)
I0528 23:27:04.354673 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.213769 (* 1 = 0.213769 loss)
I0528 23:27:04.354676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00734322 (* 1 = 0.00734322 loss)
I0528 23:27:04.354681 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024266 (* 1 = 0.024266 loss)
I0528 23:27:04.354686 10644 sgd_solver.cpp:106] Iteration 9300, lr = 0.0002
I0528 23:27:52.881317 10644 solver.cpp:228] Iteration 9320, loss = 0.194872
I0528 23:27:52.881345 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 23:27:52.881353 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533655 (* 1 = 0.0533655 loss)
I0528 23:27:52.881357 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120125 (* 1 = 0.120125 loss)
I0528 23:27:52.881361 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00572896 (* 1 = 0.00572896 loss)
I0528 23:27:52.881366 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167248 (* 1 = 0.0167248 loss)
I0528 23:27:52.881371 10644 sgd_solver.cpp:106] Iteration 9320, lr = 0.0002
I0528 23:28:41.418821 10644 solver.cpp:228] Iteration 9340, loss = 0.516876
I0528 23:28:41.418846 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:28:41.418853 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292519 (* 1 = 0.0292519 loss)
I0528 23:28:41.418857 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114334 (* 1 = 0.114334 loss)
I0528 23:28:41.418860 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271789 (* 1 = 0.0271789 loss)
I0528 23:28:41.418864 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00705123 (* 1 = 0.00705123 loss)
I0528 23:28:41.418869 10644 sgd_solver.cpp:106] Iteration 9340, lr = 0.0002
I0528 23:29:29.942718 10644 solver.cpp:228] Iteration 9360, loss = 0.403666
I0528 23:29:29.942759 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 23:29:29.942770 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310935 (* 1 = 0.0310935 loss)
I0528 23:29:29.942773 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.050758 (* 1 = 0.050758 loss)
I0528 23:29:29.942777 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00234154 (* 1 = 0.00234154 loss)
I0528 23:29:29.942781 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148735 (* 1 = 0.0148735 loss)
I0528 23:29:29.942790 10644 sgd_solver.cpp:106] Iteration 9360, lr = 0.0002
I0528 23:30:18.510217 10644 solver.cpp:228] Iteration 9380, loss = 0.228735
I0528 23:30:18.510244 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0528 23:30:18.510251 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.104366 (* 1 = 0.104366 loss)
I0528 23:30:18.510257 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.25844 (* 1 = 0.25844 loss)
I0528 23:30:18.510260 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00642739 (* 1 = 0.00642739 loss)
I0528 23:30:18.510263 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240029 (* 1 = 0.0240029 loss)
I0528 23:30:18.510268 10644 sgd_solver.cpp:106] Iteration 9380, lr = 0.0002
speed: 2.431s / iter
I0528 23:31:07.075300 10644 solver.cpp:228] Iteration 9400, loss = 0.332814
I0528 23:31:07.075328 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 23:31:07.075336 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373954 (* 1 = 0.0373954 loss)
I0528 23:31:07.075340 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0890445 (* 1 = 0.0890445 loss)
I0528 23:31:07.075345 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00858874 (* 1 = 0.00858874 loss)
I0528 23:31:07.075350 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013543 (* 1 = 0.013543 loss)
I0528 23:31:07.075356 10644 sgd_solver.cpp:106] Iteration 9400, lr = 0.0002
I0528 23:31:55.612301 10644 solver.cpp:228] Iteration 9420, loss = 0.610758
I0528 23:31:55.612326 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 23:31:55.612334 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0504653 (* 1 = 0.0504653 loss)
I0528 23:31:55.612339 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.104598 (* 1 = 0.104598 loss)
I0528 23:31:55.612342 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474252 (* 1 = 0.00474252 loss)
I0528 23:31:55.612346 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00677412 (* 1 = 0.00677412 loss)
I0528 23:31:55.612352 10644 sgd_solver.cpp:106] Iteration 9420, lr = 0.0002
I0528 23:32:44.168771 10644 solver.cpp:228] Iteration 9440, loss = 0.545274
I0528 23:32:44.168798 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 23:32:44.168807 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0398079 (* 1 = 0.0398079 loss)
I0528 23:32:44.168812 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0579601 (* 1 = 0.0579601 loss)
I0528 23:32:44.168815 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00339369 (* 1 = 0.00339369 loss)
I0528 23:32:44.168820 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00769327 (* 1 = 0.00769327 loss)
I0528 23:32:44.168826 10644 sgd_solver.cpp:106] Iteration 9440, lr = 0.0002
I0528 23:33:32.713371 10644 solver.cpp:228] Iteration 9460, loss = 0.388292
I0528 23:33:32.713397 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 23:33:32.713405 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269962 (* 1 = 0.0269962 loss)
I0528 23:33:32.713409 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.12673 (* 1 = 0.12673 loss)
I0528 23:33:32.713413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122193 (* 1 = 0.0122193 loss)
I0528 23:33:32.713418 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00429486 (* 1 = 0.00429486 loss)
I0528 23:33:32.713423 10644 sgd_solver.cpp:106] Iteration 9460, lr = 0.0002
I0528 23:34:21.260030 10644 solver.cpp:228] Iteration 9480, loss = 0.327229
I0528 23:34:21.260056 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:34:21.260064 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393513 (* 1 = 0.0393513 loss)
I0528 23:34:21.260069 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0990718 (* 1 = 0.0990718 loss)
I0528 23:34:21.260073 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116546 (* 1 = 0.0116546 loss)
I0528 23:34:21.260076 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00427415 (* 1 = 0.00427415 loss)
I0528 23:34:21.260082 10644 sgd_solver.cpp:106] Iteration 9480, lr = 0.0002
I0528 23:35:09.803297 10644 solver.cpp:228] Iteration 9500, loss = 0.411516
I0528 23:35:09.803323 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 23:35:09.803329 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0227516 (* 1 = 0.0227516 loss)
I0528 23:35:09.803333 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.141566 (* 1 = 0.141566 loss)
I0528 23:35:09.803337 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143373 (* 1 = 0.0143373 loss)
I0528 23:35:09.803341 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245084 (* 1 = 0.0245084 loss)
I0528 23:35:09.803346 10644 sgd_solver.cpp:106] Iteration 9500, lr = 0.0002
I0528 23:35:58.350262 10644 solver.cpp:228] Iteration 9520, loss = 0.707027
I0528 23:35:58.350288 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 23:35:58.350296 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445262 (* 1 = 0.0445262 loss)
I0528 23:35:58.350301 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0863307 (* 1 = 0.0863307 loss)
I0528 23:35:58.350306 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281563 (* 1 = 0.00281563 loss)
I0528 23:35:58.350308 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00814929 (* 1 = 0.00814929 loss)
I0528 23:35:58.350314 10644 sgd_solver.cpp:106] Iteration 9520, lr = 0.0002
I0528 23:36:46.908360 10644 solver.cpp:228] Iteration 9540, loss = 0.235084
I0528 23:36:46.908391 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:36:46.908402 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0427568 (* 1 = 0.0427568 loss)
I0528 23:36:46.908409 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134609 (* 1 = 0.134609 loss)
I0528 23:36:46.908416 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00440322 (* 1 = 0.00440322 loss)
I0528 23:36:46.908422 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103149 (* 1 = 0.0103149 loss)
I0528 23:36:46.908429 10644 sgd_solver.cpp:106] Iteration 9540, lr = 0.0002
I0528 23:37:35.500593 10644 solver.cpp:228] Iteration 9560, loss = 0.240007
I0528 23:37:35.500622 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0528 23:37:35.500629 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.177545 (* 1 = 0.177545 loss)
I0528 23:37:35.500633 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.291601 (* 1 = 0.291601 loss)
I0528 23:37:35.500638 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162316 (* 1 = 0.0162316 loss)
I0528 23:37:35.500640 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362327 (* 1 = 0.0362327 loss)
I0528 23:37:35.500645 10644 sgd_solver.cpp:106] Iteration 9560, lr = 0.0002
I0528 23:38:24.039605 10644 solver.cpp:228] Iteration 9580, loss = 0.461852
I0528 23:38:24.039629 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 23:38:24.039636 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0747396 (* 1 = 0.0747396 loss)
I0528 23:38:24.039640 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178343 (* 1 = 0.178343 loss)
I0528 23:38:24.039644 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174566 (* 1 = 0.0174566 loss)
I0528 23:38:24.039647 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129378 (* 1 = 0.0129378 loss)
I0528 23:38:24.039651 10644 sgd_solver.cpp:106] Iteration 9580, lr = 0.0002
speed: 2.431s / iter
I0528 23:39:12.597486 10644 solver.cpp:228] Iteration 9600, loss = 0.404098
I0528 23:39:12.597512 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0528 23:39:12.597520 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0249725 (* 1 = 0.0249725 loss)
I0528 23:39:12.597524 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0546658 (* 1 = 0.0546658 loss)
I0528 23:39:12.597527 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00584534 (* 1 = 0.00584534 loss)
I0528 23:39:12.597532 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010567 (* 1 = 0.010567 loss)
I0528 23:39:12.597537 10644 sgd_solver.cpp:106] Iteration 9600, lr = 0.0002
I0528 23:40:01.144850 10644 solver.cpp:228] Iteration 9620, loss = 0.39671
I0528 23:40:01.144878 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 23:40:01.144887 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0152148 (* 1 = 0.0152148 loss)
I0528 23:40:01.144894 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0628064 (* 1 = 0.0628064 loss)
I0528 23:40:01.144899 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00523331 (* 1 = 0.00523331 loss)
I0528 23:40:01.144906 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152122 (* 1 = 0.0152122 loss)
I0528 23:40:01.144915 10644 sgd_solver.cpp:106] Iteration 9620, lr = 0.0002
I0528 23:40:49.694720 10644 solver.cpp:228] Iteration 9640, loss = 0.328613
I0528 23:40:49.694746 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 23:40:49.694753 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392087 (* 1 = 0.0392087 loss)
I0528 23:40:49.694757 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.192841 (* 1 = 0.192841 loss)
I0528 23:40:49.694761 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.031263 (* 1 = 0.031263 loss)
I0528 23:40:49.694764 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212793 (* 1 = 0.0212793 loss)
I0528 23:40:49.694769 10644 sgd_solver.cpp:106] Iteration 9640, lr = 0.0002
I0528 23:41:38.249442 10644 solver.cpp:228] Iteration 9660, loss = 0.652871
I0528 23:41:38.249475 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0528 23:41:38.249482 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.053698 (* 1 = 0.053698 loss)
I0528 23:41:38.249486 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.141216 (* 1 = 0.141216 loss)
I0528 23:41:38.249490 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00683754 (* 1 = 0.00683754 loss)
I0528 23:41:38.249493 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110134 (* 1 = 0.0110134 loss)
I0528 23:41:38.249500 10644 sgd_solver.cpp:106] Iteration 9660, lr = 0.0002
I0528 23:42:26.825605 10644 solver.cpp:228] Iteration 9680, loss = 0.293501
I0528 23:42:26.825631 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:42:26.825639 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291333 (* 1 = 0.0291333 loss)
I0528 23:42:26.825644 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136555 (* 1 = 0.136555 loss)
I0528 23:42:26.825646 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164091 (* 1 = 0.0164091 loss)
I0528 23:42:26.825649 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292154 (* 1 = 0.0292154 loss)
I0528 23:42:26.825655 10644 sgd_solver.cpp:106] Iteration 9680, lr = 0.0002
I0528 23:43:15.398203 10644 solver.cpp:228] Iteration 9700, loss = 0.287857
I0528 23:43:15.398229 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:43:15.398236 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0338209 (* 1 = 0.0338209 loss)
I0528 23:43:15.398241 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112496 (* 1 = 0.112496 loss)
I0528 23:43:15.398244 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00693471 (* 1 = 0.00693471 loss)
I0528 23:43:15.398247 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010102 (* 1 = 0.010102 loss)
I0528 23:43:15.398252 10644 sgd_solver.cpp:106] Iteration 9700, lr = 0.0002
I0528 23:44:03.945827 10644 solver.cpp:228] Iteration 9720, loss = 0.275276
I0528 23:44:03.945865 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:44:03.945874 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325531 (* 1 = 0.0325531 loss)
I0528 23:44:03.945878 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0892143 (* 1 = 0.0892143 loss)
I0528 23:44:03.945883 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0059458 (* 1 = 0.0059458 loss)
I0528 23:44:03.945888 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116028 (* 1 = 0.0116028 loss)
I0528 23:44:03.945895 10644 sgd_solver.cpp:106] Iteration 9720, lr = 0.0002
I0528 23:44:52.603408 10644 solver.cpp:228] Iteration 9740, loss = 0.3175
I0528 23:44:52.603437 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0528 23:44:52.603447 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.156725 (* 1 = 0.156725 loss)
I0528 23:44:52.603452 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.133352 (* 1 = 0.133352 loss)
I0528 23:44:52.603457 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0333597 (* 1 = 0.0333597 loss)
I0528 23:44:52.603462 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.051604 (* 1 = 0.051604 loss)
I0528 23:44:52.603469 10644 sgd_solver.cpp:106] Iteration 9740, lr = 0.0002
I0528 23:45:41.238183 10644 solver.cpp:228] Iteration 9760, loss = 0.374731
I0528 23:45:41.238210 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0528 23:45:41.238219 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.308072 (* 1 = 0.308072 loss)
I0528 23:45:41.238222 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.558053 (* 1 = 0.558053 loss)
I0528 23:45:41.238226 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0338442 (* 1 = 0.0338442 loss)
I0528 23:45:41.238229 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0904629 (* 1 = 0.0904629 loss)
I0528 23:45:41.238235 10644 sgd_solver.cpp:106] Iteration 9760, lr = 0.0002
I0528 23:46:29.825119 10644 solver.cpp:228] Iteration 9780, loss = 0.602688
I0528 23:46:29.825158 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0528 23:46:29.825166 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.616825 (* 1 = 0.616825 loss)
I0528 23:46:29.825171 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.636603 (* 1 = 0.636603 loss)
I0528 23:46:29.825176 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0392271 (* 1 = 0.0392271 loss)
I0528 23:46:29.825178 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.259192 (* 1 = 0.259192 loss)
I0528 23:46:29.825186 10644 sgd_solver.cpp:106] Iteration 9780, lr = 0.0002
speed: 2.431s / iter
I0528 23:47:18.359216 10644 solver.cpp:228] Iteration 9800, loss = 0.181362
I0528 23:47:18.359246 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0528 23:47:18.359256 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265965 (* 1 = 0.0265965 loss)
I0528 23:47:18.359262 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.132734 (* 1 = 0.132734 loss)
I0528 23:47:18.359268 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00689286 (* 1 = 0.00689286 loss)
I0528 23:47:18.359274 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159356 (* 1 = 0.0159356 loss)
I0528 23:47:18.359282 10644 sgd_solver.cpp:106] Iteration 9800, lr = 0.0002
I0528 23:48:06.824914 10644 solver.cpp:228] Iteration 9820, loss = 0.360092
I0528 23:48:06.824937 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0528 23:48:06.824946 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.232953 (* 1 = 0.232953 loss)
I0528 23:48:06.824954 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.529575 (* 1 = 0.529575 loss)
I0528 23:48:06.824959 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0324495 (* 1 = 0.0324495 loss)
I0528 23:48:06.824965 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0680509 (* 1 = 0.0680509 loss)
I0528 23:48:06.824971 10644 sgd_solver.cpp:106] Iteration 9820, lr = 0.0002
I0528 23:48:55.231184 10644 solver.cpp:228] Iteration 9840, loss = 0.256683
I0528 23:48:55.231211 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 23:48:55.231222 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368831 (* 1 = 0.0368831 loss)
I0528 23:48:55.231228 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.053716 (* 1 = 0.053716 loss)
I0528 23:48:55.231235 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235323 (* 1 = 0.00235323 loss)
I0528 23:48:55.231240 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136538 (* 1 = 0.0136538 loss)
I0528 23:48:55.231248 10644 sgd_solver.cpp:106] Iteration 9840, lr = 0.0002
I0528 23:49:43.804375 10644 solver.cpp:228] Iteration 9860, loss = 0.155701
I0528 23:49:43.804400 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 23:49:43.804409 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0953898 (* 1 = 0.0953898 loss)
I0528 23:49:43.804414 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.213516 (* 1 = 0.213516 loss)
I0528 23:49:43.804417 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0687603 (* 1 = 0.0687603 loss)
I0528 23:49:43.804420 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0631882 (* 1 = 0.0631882 loss)
I0528 23:49:43.804426 10644 sgd_solver.cpp:106] Iteration 9860, lr = 0.0002
I0528 23:50:32.328424 10644 solver.cpp:228] Iteration 9880, loss = 0.349165
I0528 23:50:32.328449 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0528 23:50:32.328455 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.196685 (* 1 = 0.196685 loss)
I0528 23:50:32.328459 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.42177 (* 1 = 0.42177 loss)
I0528 23:50:32.328464 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016952 (* 1 = 0.016952 loss)
I0528 23:50:32.328466 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.056706 (* 1 = 0.056706 loss)
I0528 23:50:32.328471 10644 sgd_solver.cpp:106] Iteration 9880, lr = 0.0002
I0528 23:51:20.915127 10644 solver.cpp:228] Iteration 9900, loss = 0.311777
I0528 23:51:20.915150 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0528 23:51:20.915158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.140941 (* 1 = 0.140941 loss)
I0528 23:51:20.915161 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.251366 (* 1 = 0.251366 loss)
I0528 23:51:20.915165 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128356 (* 1 = 0.0128356 loss)
I0528 23:51:20.915169 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233741 (* 1 = 0.0233741 loss)
I0528 23:51:20.915174 10644 sgd_solver.cpp:106] Iteration 9900, lr = 0.0002
I0528 23:52:09.483078 10644 solver.cpp:228] Iteration 9920, loss = 0.177943
I0528 23:52:09.483106 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0528 23:52:09.483114 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115083 (* 1 = 0.115083 loss)
I0528 23:52:09.483117 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160327 (* 1 = 0.160327 loss)
I0528 23:52:09.483121 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294221 (* 1 = 0.00294221 loss)
I0528 23:52:09.483124 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010428 (* 1 = 0.010428 loss)
I0528 23:52:09.483130 10644 sgd_solver.cpp:106] Iteration 9920, lr = 0.0002
I0528 23:52:58.059584 10644 solver.cpp:228] Iteration 9940, loss = 0.200767
I0528 23:52:58.059612 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:52:58.059618 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.113193 (* 1 = 0.113193 loss)
I0528 23:52:58.059623 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0794319 (* 1 = 0.0794319 loss)
I0528 23:52:58.059625 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016631 (* 1 = 0.016631 loss)
I0528 23:52:58.059629 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260931 (* 1 = 0.0260931 loss)
I0528 23:52:58.059634 10644 sgd_solver.cpp:106] Iteration 9940, lr = 0.0002
I0528 23:53:46.624053 10644 solver.cpp:228] Iteration 9960, loss = 0.368993
I0528 23:53:46.624078 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0528 23:53:46.624088 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649279 (* 1 = 0.0649279 loss)
I0528 23:53:46.624091 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.126061 (* 1 = 0.126061 loss)
I0528 23:53:46.624095 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114947 (* 1 = 0.0114947 loss)
I0528 23:53:46.624099 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151118 (* 1 = 0.0151118 loss)
I0528 23:53:46.624104 10644 sgd_solver.cpp:106] Iteration 9960, lr = 0.0002
I0528 23:54:35.169395 10644 solver.cpp:228] Iteration 9980, loss = 0.266394
I0528 23:54:35.169431 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0528 23:54:35.169440 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0927961 (* 1 = 0.0927961 loss)
I0528 23:54:35.169443 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.202356 (* 1 = 0.202356 loss)
I0528 23:54:35.169446 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00563631 (* 1 = 0.00563631 loss)
I0528 23:54:35.169451 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194261 (* 1 = 0.0194261 loss)
I0528 23:54:35.169457 10644 sgd_solver.cpp:106] Iteration 9980, lr = 0.0002
speed: 2.430s / iter
I0528 23:55:21.428900 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_10000.caffemodel
I0528 23:55:24.444916 10644 solver.cpp:228] Iteration 10000, loss = 0.411556
I0528 23:55:24.444944 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0528 23:55:24.444952 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000233966 (* 1 = 0.000233966 loss)
I0528 23:55:24.444957 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0708381 (* 1 = 0.0708381 loss)
I0528 23:55:24.444960 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364252 (* 1 = 0.0364252 loss)
I0528 23:55:24.444964 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.086193 (* 1 = 0.086193 loss)
I0528 23:55:24.444969 10644 sgd_solver.cpp:106] Iteration 10000, lr = 0.0002
I0528 23:56:12.998251 10644 solver.cpp:228] Iteration 10020, loss = 0.451233
I0528 23:56:12.998280 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0528 23:56:12.998287 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.180226 (* 1 = 0.180226 loss)
I0528 23:56:12.998292 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.44439 (* 1 = 0.44439 loss)
I0528 23:56:12.998296 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00810875 (* 1 = 0.00810875 loss)
I0528 23:56:12.998301 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0607226 (* 1 = 0.0607226 loss)
I0528 23:56:12.998307 10644 sgd_solver.cpp:106] Iteration 10020, lr = 0.0002
I0528 23:57:01.574766 10644 solver.cpp:228] Iteration 10040, loss = 0.332401
I0528 23:57:01.574796 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:57:01.574805 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346003 (* 1 = 0.0346003 loss)
I0528 23:57:01.574810 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174703 (* 1 = 0.174703 loss)
I0528 23:57:01.574813 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00719392 (* 1 = 0.00719392 loss)
I0528 23:57:01.574816 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00821044 (* 1 = 0.00821044 loss)
I0528 23:57:01.574822 10644 sgd_solver.cpp:106] Iteration 10040, lr = 0.0002
I0528 23:57:50.109611 10644 solver.cpp:228] Iteration 10060, loss = 0.354998
I0528 23:57:50.109635 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:57:50.109643 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276623 (* 1 = 0.0276623 loss)
I0528 23:57:50.109647 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0944332 (* 1 = 0.0944332 loss)
I0528 23:57:50.109652 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109374 (* 1 = 0.0109374 loss)
I0528 23:57:50.109655 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00807132 (* 1 = 0.00807132 loss)
I0528 23:57:50.109660 10644 sgd_solver.cpp:106] Iteration 10060, lr = 0.0002
I0528 23:58:38.669860 10644 solver.cpp:228] Iteration 10080, loss = 0.25305
I0528 23:58:38.669886 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0528 23:58:38.669893 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0693766 (* 1 = 0.0693766 loss)
I0528 23:58:38.669898 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0842928 (* 1 = 0.0842928 loss)
I0528 23:58:38.669901 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127664 (* 1 = 0.0127664 loss)
I0528 23:58:38.669905 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107851 (* 1 = 0.0107851 loss)
I0528 23:58:38.669911 10644 sgd_solver.cpp:106] Iteration 10080, lr = 0.0002
I0528 23:59:27.242818 10644 solver.cpp:228] Iteration 10100, loss = 0.239745
I0528 23:59:27.242846 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0528 23:59:27.242853 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171272 (* 1 = 0.0171272 loss)
I0528 23:59:27.242857 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0716329 (* 1 = 0.0716329 loss)
I0528 23:59:27.242861 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00659726 (* 1 = 0.00659726 loss)
I0528 23:59:27.242866 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00128293 (* 1 = 0.00128293 loss)
I0528 23:59:27.242871 10644 sgd_solver.cpp:106] Iteration 10100, lr = 0.0002
I0529 00:00:15.784314 10644 solver.cpp:228] Iteration 10120, loss = 0.283817
I0529 00:00:15.784353 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 00:00:15.784361 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.226816 (* 1 = 0.226816 loss)
I0529 00:00:15.784366 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.355002 (* 1 = 0.355002 loss)
I0529 00:00:15.784370 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0313564 (* 1 = 0.0313564 loss)
I0529 00:00:15.784374 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10308 (* 1 = 0.10308 loss)
I0529 00:00:15.784379 10644 sgd_solver.cpp:106] Iteration 10120, lr = 0.0002
I0529 00:01:04.325875 10644 solver.cpp:228] Iteration 10140, loss = 0.350259
I0529 00:01:04.325901 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 00:01:04.325908 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0572286 (* 1 = 0.0572286 loss)
I0529 00:01:04.325913 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0460213 (* 1 = 0.0460213 loss)
I0529 00:01:04.325917 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00574838 (* 1 = 0.00574838 loss)
I0529 00:01:04.325920 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132358 (* 1 = 0.0132358 loss)
I0529 00:01:04.325927 10644 sgd_solver.cpp:106] Iteration 10140, lr = 0.0002
I0529 00:01:52.873391 10644 solver.cpp:228] Iteration 10160, loss = 0.37983
I0529 00:01:52.873423 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 00:01:52.873433 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.185162 (* 1 = 0.185162 loss)
I0529 00:01:52.873440 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.30948 (* 1 = 0.30948 loss)
I0529 00:01:52.873445 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00715083 (* 1 = 0.00715083 loss)
I0529 00:01:52.873451 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213901 (* 1 = 0.0213901 loss)
I0529 00:01:52.873459 10644 sgd_solver.cpp:106] Iteration 10160, lr = 0.0002
I0529 00:02:41.419361 10644 solver.cpp:228] Iteration 10180, loss = 0.299989
I0529 00:02:41.419384 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 00:02:41.419391 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00402015 (* 1 = 0.00402015 loss)
I0529 00:02:41.419395 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0398518 (* 1 = 0.0398518 loss)
I0529 00:02:41.419399 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00285358 (* 1 = 0.00285358 loss)
I0529 00:02:41.419402 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00182947 (* 1 = 0.00182947 loss)
I0529 00:02:41.419406 10644 sgd_solver.cpp:106] Iteration 10180, lr = 0.0002
speed: 2.430s / iter
I0529 00:03:29.955060 10644 solver.cpp:228] Iteration 10200, loss = 0.522087
I0529 00:03:29.955087 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 00:03:29.955094 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.242953 (* 1 = 0.242953 loss)
I0529 00:03:29.955098 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.458583 (* 1 = 0.458583 loss)
I0529 00:03:29.955102 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.145097 (* 1 = 0.145097 loss)
I0529 00:03:29.955106 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.487822 (* 1 = 0.487822 loss)
I0529 00:03:29.955111 10644 sgd_solver.cpp:106] Iteration 10200, lr = 0.0002
I0529 00:04:18.489799 10644 solver.cpp:228] Iteration 10220, loss = 0.371515
I0529 00:04:18.489825 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 00:04:18.489835 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524267 (* 1 = 0.0524267 loss)
I0529 00:04:18.489841 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0575254 (* 1 = 0.0575254 loss)
I0529 00:04:18.489847 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00280646 (* 1 = 0.00280646 loss)
I0529 00:04:18.489852 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00917664 (* 1 = 0.00917664 loss)
I0529 00:04:18.489859 10644 sgd_solver.cpp:106] Iteration 10220, lr = 0.0002
I0529 00:05:07.028798 10644 solver.cpp:228] Iteration 10240, loss = 0.2634
I0529 00:05:07.028821 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 00:05:07.028827 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295503 (* 1 = 0.0295503 loss)
I0529 00:05:07.028831 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.100476 (* 1 = 0.100476 loss)
I0529 00:05:07.028836 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119341 (* 1 = 0.0119341 loss)
I0529 00:05:07.028838 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174174 (* 1 = 0.0174174 loss)
I0529 00:05:07.028843 10644 sgd_solver.cpp:106] Iteration 10240, lr = 0.0002
I0529 00:05:55.535670 10644 solver.cpp:228] Iteration 10260, loss = 0.58445
I0529 00:05:55.535696 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:05:55.535704 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.105579 (* 1 = 0.105579 loss)
I0529 00:05:55.535711 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.184306 (* 1 = 0.184306 loss)
I0529 00:05:55.535715 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00928687 (* 1 = 0.00928687 loss)
I0529 00:05:55.535722 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109139 (* 1 = 0.0109139 loss)
I0529 00:05:55.535728 10644 sgd_solver.cpp:106] Iteration 10260, lr = 0.0002
I0529 00:06:44.100915 10644 solver.cpp:228] Iteration 10280, loss = 0.403195
I0529 00:06:44.100944 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 00:06:44.100951 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.201834 (* 1 = 0.201834 loss)
I0529 00:06:44.100955 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.292897 (* 1 = 0.292897 loss)
I0529 00:06:44.100958 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366699 (* 1 = 0.0366699 loss)
I0529 00:06:44.100962 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103859 (* 1 = 0.103859 loss)
I0529 00:06:44.100966 10644 sgd_solver.cpp:106] Iteration 10280, lr = 0.0002
I0529 00:07:32.651209 10644 solver.cpp:228] Iteration 10300, loss = 0.320504
I0529 00:07:32.651234 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 00:07:32.651243 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.134641 (* 1 = 0.134641 loss)
I0529 00:07:32.651249 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.257818 (* 1 = 0.257818 loss)
I0529 00:07:32.651255 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00290002 (* 1 = 0.00290002 loss)
I0529 00:07:32.651260 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166794 (* 1 = 0.0166794 loss)
I0529 00:07:32.651268 10644 sgd_solver.cpp:106] Iteration 10300, lr = 0.0002
I0529 00:08:21.202306 10644 solver.cpp:228] Iteration 10320, loss = 0.408634
I0529 00:08:21.202332 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 00:08:21.202339 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0974958 (* 1 = 0.0974958 loss)
I0529 00:08:21.202344 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.127535 (* 1 = 0.127535 loss)
I0529 00:08:21.202348 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00574837 (* 1 = 0.00574837 loss)
I0529 00:08:21.202353 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.042441 (* 1 = 0.042441 loss)
I0529 00:08:21.202361 10644 sgd_solver.cpp:106] Iteration 10320, lr = 0.0002
I0529 00:09:09.743818 10644 solver.cpp:228] Iteration 10340, loss = nan
I0529 00:09:09.743842 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:09:09.743851 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276603 (* 1 = 0.0276603 loss)
I0529 00:09:09.743856 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0630437 (* 1 = 0.0630437 loss)
I0529 00:09:09.743860 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189281 (* 1 = 0.00189281 loss)
I0529 00:09:09.743863 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229815 (* 1 = 0.00229815 loss)
I0529 00:09:09.743870 10644 sgd_solver.cpp:106] Iteration 10340, lr = 0.0002
I0529 00:09:58.317219 10644 solver.cpp:228] Iteration 10360, loss = 0.347748
I0529 00:09:58.317245 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 00:09:58.317253 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0717165 (* 1 = 0.0717165 loss)
I0529 00:09:58.317258 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.186323 (* 1 = 0.186323 loss)
I0529 00:09:58.317262 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0348835 (* 1 = 0.0348835 loss)
I0529 00:09:58.317266 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0976567 (* 1 = 0.0976567 loss)
I0529 00:09:58.317272 10644 sgd_solver.cpp:106] Iteration 10360, lr = 0.0002
I0529 00:10:46.878584 10644 solver.cpp:228] Iteration 10380, loss = 0.238882
I0529 00:10:46.878609 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 00:10:46.878618 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0403408 (* 1 = 0.0403408 loss)
I0529 00:10:46.878623 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0706897 (* 1 = 0.0706897 loss)
I0529 00:10:46.878629 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00800002 (* 1 = 0.00800002 loss)
I0529 00:10:46.878633 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129242 (* 1 = 0.0129242 loss)
I0529 00:10:46.878638 10644 sgd_solver.cpp:106] Iteration 10380, lr = 0.0002
speed: 2.430s / iter
I0529 00:11:35.426946 10644 solver.cpp:228] Iteration 10400, loss = 0.428989
I0529 00:11:35.426975 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:11:35.426983 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0420692 (* 1 = 0.0420692 loss)
I0529 00:11:35.426987 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.141276 (* 1 = 0.141276 loss)
I0529 00:11:35.426991 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0069894 (* 1 = 0.0069894 loss)
I0529 00:11:35.426995 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00463973 (* 1 = 0.00463973 loss)
I0529 00:11:35.427000 10644 sgd_solver.cpp:106] Iteration 10400, lr = 0.0002
I0529 00:12:23.986922 10644 solver.cpp:228] Iteration 10420, loss = 0.293866
I0529 00:12:23.986949 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 00:12:23.986958 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100845 (* 1 = 0.100845 loss)
I0529 00:12:23.986963 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234416 (* 1 = 0.234416 loss)
I0529 00:12:23.986965 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0323084 (* 1 = 0.0323084 loss)
I0529 00:12:23.986969 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0957891 (* 1 = 0.0957891 loss)
I0529 00:12:23.986975 10644 sgd_solver.cpp:106] Iteration 10420, lr = 0.0002
I0529 00:13:12.522990 10644 solver.cpp:228] Iteration 10440, loss = 0.399728
I0529 00:13:12.523018 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:13:12.523026 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190354 (* 1 = 0.0190354 loss)
I0529 00:13:12.523031 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.24945 (* 1 = 0.24945 loss)
I0529 00:13:12.523035 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0470637 (* 1 = 0.0470637 loss)
I0529 00:13:12.523038 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0424663 (* 1 = 0.0424663 loss)
I0529 00:13:12.523043 10644 sgd_solver.cpp:106] Iteration 10440, lr = 0.0002
I0529 00:14:01.078012 10644 solver.cpp:228] Iteration 10460, loss = 0.808985
I0529 00:14:01.078038 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0529 00:14:01.078047 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.349913 (* 1 = 0.349913 loss)
I0529 00:14:01.078050 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.532975 (* 1 = 0.532975 loss)
I0529 00:14:01.078054 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364912 (* 1 = 0.0364912 loss)
I0529 00:14:01.078058 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0910234 (* 1 = 0.0910234 loss)
I0529 00:14:01.078065 10644 sgd_solver.cpp:106] Iteration 10460, lr = 0.0002
I0529 00:14:49.611462 10644 solver.cpp:228] Iteration 10480, loss = 0.481102
I0529 00:14:49.611487 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:14:49.611495 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0788852 (* 1 = 0.0788852 loss)
I0529 00:14:49.611498 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144661 (* 1 = 0.144661 loss)
I0529 00:14:49.611501 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351678 (* 1 = 0.00351678 loss)
I0529 00:14:49.611505 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00647264 (* 1 = 0.00647264 loss)
I0529 00:14:49.611510 10644 sgd_solver.cpp:106] Iteration 10480, lr = 0.0002
I0529 00:15:38.176514 10644 solver.cpp:228] Iteration 10500, loss = 0.343266
I0529 00:15:38.176539 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:15:38.176546 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.064252 (* 1 = 0.064252 loss)
I0529 00:15:38.176550 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.187918 (* 1 = 0.187918 loss)
I0529 00:15:38.176553 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016773 (* 1 = 0.016773 loss)
I0529 00:15:38.176556 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359297 (* 1 = 0.0359297 loss)
I0529 00:15:38.176563 10644 sgd_solver.cpp:106] Iteration 10500, lr = 0.0002
I0529 00:16:26.709066 10644 solver.cpp:228] Iteration 10520, loss = 0.483576
I0529 00:16:26.709091 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 00:16:26.709098 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.330571 (* 1 = 0.330571 loss)
I0529 00:16:26.709102 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174831 (* 1 = 0.174831 loss)
I0529 00:16:26.709106 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113564 (* 1 = 0.0113564 loss)
I0529 00:16:26.709110 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0555098 (* 1 = 0.0555098 loss)
I0529 00:16:26.709115 10644 sgd_solver.cpp:106] Iteration 10520, lr = 0.0002
I0529 00:17:15.265470 10644 solver.cpp:228] Iteration 10540, loss = 0.282684
I0529 00:17:15.265496 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 00:17:15.265503 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.12531 (* 1 = 0.12531 loss)
I0529 00:17:15.265507 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.233014 (* 1 = 0.233014 loss)
I0529 00:17:15.265511 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00927803 (* 1 = 0.00927803 loss)
I0529 00:17:15.265514 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0612801 (* 1 = 0.0612801 loss)
I0529 00:17:15.265519 10644 sgd_solver.cpp:106] Iteration 10540, lr = 0.0002
I0529 00:18:03.818467 10644 solver.cpp:228] Iteration 10560, loss = 0.537687
I0529 00:18:03.818493 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 00:18:03.818500 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.116077 (* 1 = 0.116077 loss)
I0529 00:18:03.818505 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.206176 (* 1 = 0.206176 loss)
I0529 00:18:03.818507 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106775 (* 1 = 0.0106775 loss)
I0529 00:18:03.818513 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240818 (* 1 = 0.0240818 loss)
I0529 00:18:03.818521 10644 sgd_solver.cpp:106] Iteration 10560, lr = 0.0002
I0529 00:18:52.349606 10644 solver.cpp:228] Iteration 10580, loss = 0.295644
I0529 00:18:52.349630 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 00:18:52.349638 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0512869 (* 1 = 0.0512869 loss)
I0529 00:18:52.349643 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.149378 (* 1 = 0.149378 loss)
I0529 00:18:52.349648 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150299 (* 1 = 0.00150299 loss)
I0529 00:18:52.349653 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115917 (* 1 = 0.0115917 loss)
I0529 00:18:52.349659 10644 sgd_solver.cpp:106] Iteration 10580, lr = 0.0002
speed: 2.430s / iter
I0529 00:19:40.912001 10644 solver.cpp:228] Iteration 10600, loss = 0.277422
I0529 00:19:40.912025 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 00:19:40.912034 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173666 (* 1 = 0.0173666 loss)
I0529 00:19:40.912040 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.076938 (* 1 = 0.076938 loss)
I0529 00:19:40.912046 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257489 (* 1 = 0.00257489 loss)
I0529 00:19:40.912052 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183791 (* 1 = 0.0183791 loss)
I0529 00:19:40.912058 10644 sgd_solver.cpp:106] Iteration 10600, lr = 0.0002
I0529 00:20:29.482905 10644 solver.cpp:228] Iteration 10620, loss = 0.347566
I0529 00:20:29.482929 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:20:29.482937 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340381 (* 1 = 0.0340381 loss)
I0529 00:20:29.482940 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1618 (* 1 = 0.1618 loss)
I0529 00:20:29.482944 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.035588 (* 1 = 0.035588 loss)
I0529 00:20:29.482947 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374492 (* 1 = 0.0374492 loss)
I0529 00:20:29.482952 10644 sgd_solver.cpp:106] Iteration 10620, lr = 0.0002
I0529 00:21:18.069985 10644 solver.cpp:228] Iteration 10640, loss = 0.46515
I0529 00:21:18.070014 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 00:21:18.070022 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.315001 (* 1 = 0.315001 loss)
I0529 00:21:18.070027 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.393899 (* 1 = 0.393899 loss)
I0529 00:21:18.070030 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.105553 (* 1 = 0.105553 loss)
I0529 00:21:18.070034 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.199346 (* 1 = 0.199346 loss)
I0529 00:21:18.070040 10644 sgd_solver.cpp:106] Iteration 10640, lr = 0.0002
I0529 00:22:06.641162 10644 solver.cpp:228] Iteration 10660, loss = 0.349897
I0529 00:22:06.641193 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 00:22:06.641204 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150474 (* 1 = 0.0150474 loss)
I0529 00:22:06.641211 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0511606 (* 1 = 0.0511606 loss)
I0529 00:22:06.641217 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000560555 (* 1 = 0.000560555 loss)
I0529 00:22:06.641222 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00302509 (* 1 = 0.00302509 loss)
I0529 00:22:06.641230 10644 sgd_solver.cpp:106] Iteration 10660, lr = 0.0002
I0529 00:22:55.232987 10644 solver.cpp:228] Iteration 10680, loss = 0.312694
I0529 00:22:55.233014 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 00:22:55.233022 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.157127 (* 1 = 0.157127 loss)
I0529 00:22:55.233026 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.251902 (* 1 = 0.251902 loss)
I0529 00:22:55.233031 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0236831 (* 1 = 0.0236831 loss)
I0529 00:22:55.233033 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0582814 (* 1 = 0.0582814 loss)
I0529 00:22:55.233038 10644 sgd_solver.cpp:106] Iteration 10680, lr = 0.0002
I0529 00:23:43.820574 10644 solver.cpp:228] Iteration 10700, loss = 0.263672
I0529 00:23:43.820603 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 00:23:43.820613 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0965225 (* 1 = 0.0965225 loss)
I0529 00:23:43.820621 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150333 (* 1 = 0.150333 loss)
I0529 00:23:43.820627 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00943538 (* 1 = 0.00943538 loss)
I0529 00:23:43.820633 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0472413 (* 1 = 0.0472413 loss)
I0529 00:23:43.820641 10644 sgd_solver.cpp:106] Iteration 10700, lr = 0.0002
I0529 00:24:32.376983 10644 solver.cpp:228] Iteration 10720, loss = 0.289767
I0529 00:24:32.377010 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 00:24:32.377017 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.087654 (* 1 = 0.087654 loss)
I0529 00:24:32.377022 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.283698 (* 1 = 0.283698 loss)
I0529 00:24:32.377025 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00401606 (* 1 = 0.00401606 loss)
I0529 00:24:32.377029 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108168 (* 1 = 0.0108168 loss)
I0529 00:24:32.377035 10644 sgd_solver.cpp:106] Iteration 10720, lr = 0.0002
I0529 00:25:20.882011 10644 solver.cpp:228] Iteration 10740, loss = 0.472924
I0529 00:25:20.882036 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 00:25:20.882045 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0583655 (* 1 = 0.0583655 loss)
I0529 00:25:20.882050 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0574717 (* 1 = 0.0574717 loss)
I0529 00:25:20.882053 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00396217 (* 1 = 0.00396217 loss)
I0529 00:25:20.882057 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00207919 (* 1 = 0.00207919 loss)
I0529 00:25:20.882063 10644 sgd_solver.cpp:106] Iteration 10740, lr = 0.0002
I0529 00:26:09.428351 10644 solver.cpp:228] Iteration 10760, loss = 0.241753
I0529 00:26:09.428377 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 00:26:09.428385 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0387251 (* 1 = 0.0387251 loss)
I0529 00:26:09.428390 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121776 (* 1 = 0.121776 loss)
I0529 00:26:09.428393 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198373 (* 1 = 0.0198373 loss)
I0529 00:26:09.428396 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192983 (* 1 = 0.0192983 loss)
I0529 00:26:09.428402 10644 sgd_solver.cpp:106] Iteration 10760, lr = 0.0002
I0529 00:26:58.002238 10644 solver.cpp:228] Iteration 10780, loss = 0.4267
I0529 00:26:58.002269 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 00:26:58.002277 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0306225 (* 1 = 0.0306225 loss)
I0529 00:26:58.002281 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.057267 (* 1 = 0.057267 loss)
I0529 00:26:58.002286 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511048 (* 1 = 0.00511048 loss)
I0529 00:26:58.002290 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0032818 (* 1 = 0.0032818 loss)
I0529 00:26:58.002296 10644 sgd_solver.cpp:106] Iteration 10780, lr = 0.0002
speed: 2.430s / iter
I0529 00:27:46.565675 10644 solver.cpp:228] Iteration 10800, loss = 0.384987
I0529 00:27:46.565701 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:27:46.565707 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571954 (* 1 = 0.0571954 loss)
I0529 00:27:46.565711 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.232918 (* 1 = 0.232918 loss)
I0529 00:27:46.565714 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108663 (* 1 = 0.0108663 loss)
I0529 00:27:46.565718 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0344367 (* 1 = 0.0344367 loss)
I0529 00:27:46.565723 10644 sgd_solver.cpp:106] Iteration 10800, lr = 0.0002
I0529 00:28:35.212193 10644 solver.cpp:228] Iteration 10820, loss = 0.343504
I0529 00:28:35.212224 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:28:35.212232 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292959 (* 1 = 0.0292959 loss)
I0529 00:28:35.212236 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.104195 (* 1 = 0.104195 loss)
I0529 00:28:35.212240 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00303803 (* 1 = 0.00303803 loss)
I0529 00:28:35.212244 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00965795 (* 1 = 0.00965795 loss)
I0529 00:28:35.212250 10644 sgd_solver.cpp:106] Iteration 10820, lr = 0.0002
I0529 00:29:23.759974 10644 solver.cpp:228] Iteration 10840, loss = 0.322445
I0529 00:29:23.759999 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:29:23.760006 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.045111 (* 1 = 0.045111 loss)
I0529 00:29:23.760011 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.139152 (* 1 = 0.139152 loss)
I0529 00:29:23.760015 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00979745 (* 1 = 0.00979745 loss)
I0529 00:29:23.760020 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00611661 (* 1 = 0.00611661 loss)
I0529 00:29:23.760025 10644 sgd_solver.cpp:106] Iteration 10840, lr = 0.0002
I0529 00:30:12.291023 10644 solver.cpp:228] Iteration 10860, loss = 0.231187
I0529 00:30:12.291049 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 00:30:12.291056 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.112719 (* 1 = 0.112719 loss)
I0529 00:30:12.291060 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.25577 (* 1 = 0.25577 loss)
I0529 00:30:12.291064 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160306 (* 1 = 0.0160306 loss)
I0529 00:30:12.291069 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0398606 (* 1 = 0.0398606 loss)
I0529 00:30:12.291074 10644 sgd_solver.cpp:106] Iteration 10860, lr = 0.0002
I0529 00:31:00.859022 10644 solver.cpp:228] Iteration 10880, loss = 0.41501
I0529 00:31:00.859050 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:31:00.859058 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743797 (* 1 = 0.0743797 loss)
I0529 00:31:00.859063 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0660524 (* 1 = 0.0660524 loss)
I0529 00:31:00.859067 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179059 (* 1 = 0.00179059 loss)
I0529 00:31:00.859071 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115374 (* 1 = 0.0115374 loss)
I0529 00:31:00.859076 10644 sgd_solver.cpp:106] Iteration 10880, lr = 0.0002
I0529 00:31:49.425024 10644 solver.cpp:228] Iteration 10900, loss = 0.435928
I0529 00:31:49.425050 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 00:31:49.425056 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.295115 (* 1 = 0.295115 loss)
I0529 00:31:49.425061 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.315654 (* 1 = 0.315654 loss)
I0529 00:31:49.425065 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190865 (* 1 = 0.0190865 loss)
I0529 00:31:49.425070 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0925666 (* 1 = 0.0925666 loss)
I0529 00:31:49.425076 10644 sgd_solver.cpp:106] Iteration 10900, lr = 0.0002
I0529 00:32:37.952450 10644 solver.cpp:228] Iteration 10920, loss = 0.34856
I0529 00:32:37.952486 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:32:37.952494 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.151468 (* 1 = 0.151468 loss)
I0529 00:32:37.952499 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.107792 (* 1 = 0.107792 loss)
I0529 00:32:37.952503 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541775 (* 1 = 0.00541775 loss)
I0529 00:32:37.952507 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133184 (* 1 = 0.0133184 loss)
I0529 00:32:37.952515 10644 sgd_solver.cpp:106] Iteration 10920, lr = 0.0002
I0529 00:33:26.477942 10644 solver.cpp:228] Iteration 10940, loss = 0.477517
I0529 00:33:26.477967 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 00:33:26.477975 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.210787 (* 1 = 0.210787 loss)
I0529 00:33:26.477982 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.182281 (* 1 = 0.182281 loss)
I0529 00:33:26.477988 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00451026 (* 1 = 0.00451026 loss)
I0529 00:33:26.477993 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0459038 (* 1 = 0.0459038 loss)
I0529 00:33:26.477998 10644 sgd_solver.cpp:106] Iteration 10940, lr = 0.0002
I0529 00:34:15.016531 10644 solver.cpp:228] Iteration 10960, loss = 0.327355
I0529 00:34:15.016557 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0529 00:34:15.016566 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.318716 (* 1 = 0.318716 loss)
I0529 00:34:15.016572 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.416717 (* 1 = 0.416717 loss)
I0529 00:34:15.016577 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0385901 (* 1 = 0.0385901 loss)
I0529 00:34:15.016582 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0705092 (* 1 = 0.0705092 loss)
I0529 00:34:15.016589 10644 sgd_solver.cpp:106] Iteration 10960, lr = 0.0002
I0529 00:35:03.560899 10644 solver.cpp:228] Iteration 10980, loss = 0.4585
I0529 00:35:03.560932 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 00:35:03.560942 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.26505 (* 1 = 0.26505 loss)
I0529 00:35:03.560950 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.252445 (* 1 = 0.252445 loss)
I0529 00:35:03.560956 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126009 (* 1 = 0.0126009 loss)
I0529 00:35:03.560961 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045136 (* 1 = 0.045136 loss)
I0529 00:35:03.560968 10644 sgd_solver.cpp:106] Iteration 10980, lr = 0.0002
speed: 2.430s / iter
I0529 00:35:52.094544 10644 solver.cpp:228] Iteration 11000, loss = 0.316098
I0529 00:35:52.094573 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:35:52.094579 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279137 (* 1 = 0.0279137 loss)
I0529 00:35:52.094583 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120728 (* 1 = 0.120728 loss)
I0529 00:35:52.094588 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0283331 (* 1 = 0.0283331 loss)
I0529 00:35:52.094590 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170392 (* 1 = 0.0170392 loss)
I0529 00:35:52.094595 10644 sgd_solver.cpp:106] Iteration 11000, lr = 0.0002
I0529 00:36:40.647269 10644 solver.cpp:228] Iteration 11020, loss = 0.345475
I0529 00:36:40.647298 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 00:36:40.647305 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.158856 (* 1 = 0.158856 loss)
I0529 00:36:40.647308 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.327704 (* 1 = 0.327704 loss)
I0529 00:36:40.647312 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178634 (* 1 = 0.0178634 loss)
I0529 00:36:40.647316 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267769 (* 1 = 0.0267769 loss)
I0529 00:36:40.647320 10644 sgd_solver.cpp:106] Iteration 11020, lr = 0.0002
I0529 00:37:29.184454 10644 solver.cpp:228] Iteration 11040, loss = 0.323776
I0529 00:37:29.184478 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:37:29.184485 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341151 (* 1 = 0.0341151 loss)
I0529 00:37:29.184489 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178347 (* 1 = 0.178347 loss)
I0529 00:37:29.184494 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00495591 (* 1 = 0.00495591 loss)
I0529 00:37:29.184496 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00827475 (* 1 = 0.00827475 loss)
I0529 00:37:29.184501 10644 sgd_solver.cpp:106] Iteration 11040, lr = 0.0002
I0529 00:38:17.723763 10644 solver.cpp:228] Iteration 11060, loss = 0.344283
I0529 00:38:17.723790 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:38:17.723798 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0689554 (* 1 = 0.0689554 loss)
I0529 00:38:17.723801 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145419 (* 1 = 0.145419 loss)
I0529 00:38:17.723804 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130152 (* 1 = 0.0130152 loss)
I0529 00:38:17.723807 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309601 (* 1 = 0.0309601 loss)
I0529 00:38:17.723812 10644 sgd_solver.cpp:106] Iteration 11060, lr = 0.0002
I0529 00:39:06.263257 10644 solver.cpp:228] Iteration 11080, loss = 0.347423
I0529 00:39:06.263283 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:39:06.263293 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324352 (* 1 = 0.0324352 loss)
I0529 00:39:06.263299 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0917036 (* 1 = 0.0917036 loss)
I0529 00:39:06.263304 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00461375 (* 1 = 0.00461375 loss)
I0529 00:39:06.263309 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00378407 (* 1 = 0.00378407 loss)
I0529 00:39:06.263315 10644 sgd_solver.cpp:106] Iteration 11080, lr = 0.0002
I0529 00:39:54.768947 10644 solver.cpp:228] Iteration 11100, loss = 0.206196
I0529 00:39:54.768975 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 00:39:54.768985 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576021 (* 1 = 0.0576021 loss)
I0529 00:39:54.768990 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.129665 (* 1 = 0.129665 loss)
I0529 00:39:54.768996 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00254635 (* 1 = 0.00254635 loss)
I0529 00:39:54.769001 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026385 (* 1 = 0.026385 loss)
I0529 00:39:54.769008 10644 sgd_solver.cpp:106] Iteration 11100, lr = 0.0002
I0529 00:40:43.286118 10644 solver.cpp:228] Iteration 11120, loss = 0.301016
I0529 00:40:43.286147 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:40:43.286157 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383674 (* 1 = 0.0383674 loss)
I0529 00:40:43.286164 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.133556 (* 1 = 0.133556 loss)
I0529 00:40:43.286170 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144919 (* 1 = 0.0144919 loss)
I0529 00:40:43.286176 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373995 (* 1 = 0.0373995 loss)
I0529 00:40:43.286183 10644 sgd_solver.cpp:106] Iteration 11120, lr = 0.0002
I0529 00:41:31.819221 10644 solver.cpp:228] Iteration 11140, loss = 0.406219
I0529 00:41:31.819254 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:41:31.819263 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.038224 (* 1 = 0.038224 loss)
I0529 00:41:31.819267 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128302 (* 1 = 0.128302 loss)
I0529 00:41:31.819272 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241716 (* 1 = 0.0241716 loss)
I0529 00:41:31.819275 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0343577 (* 1 = 0.0343577 loss)
I0529 00:41:31.819283 10644 sgd_solver.cpp:106] Iteration 11140, lr = 0.0002
I0529 00:42:20.379752 10644 solver.cpp:228] Iteration 11160, loss = 0.69464
I0529 00:42:20.379777 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 00:42:20.379786 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.329637 (* 1 = 0.329637 loss)
I0529 00:42:20.379789 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.392968 (* 1 = 0.392968 loss)
I0529 00:42:20.379793 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181832 (* 1 = 0.0181832 loss)
I0529 00:42:20.379797 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0688712 (* 1 = 0.0688712 loss)
I0529 00:42:20.379802 10644 sgd_solver.cpp:106] Iteration 11160, lr = 0.0002
I0529 00:43:08.922996 10644 solver.cpp:228] Iteration 11180, loss = 0.346812
I0529 00:43:08.923024 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0529 00:43:08.923032 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.404951 (* 1 = 0.404951 loss)
I0529 00:43:08.923036 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.535199 (* 1 = 0.535199 loss)
I0529 00:43:08.923040 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0601159 (* 1 = 0.0601159 loss)
I0529 00:43:08.923044 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112918 (* 1 = 0.112918 loss)
I0529 00:43:08.923049 10644 sgd_solver.cpp:106] Iteration 11180, lr = 0.0002
speed: 2.430s / iter
I0529 00:43:57.483453 10644 solver.cpp:228] Iteration 11200, loss = 0.237288
I0529 00:43:57.483479 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:43:57.483487 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0951416 (* 1 = 0.0951416 loss)
I0529 00:43:57.483491 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121985 (* 1 = 0.121985 loss)
I0529 00:43:57.483495 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00615308 (* 1 = 0.00615308 loss)
I0529 00:43:57.483500 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290918 (* 1 = 0.0290918 loss)
I0529 00:43:57.483505 10644 sgd_solver.cpp:106] Iteration 11200, lr = 0.0002
I0529 00:44:46.016182 10644 solver.cpp:228] Iteration 11220, loss = 0.39471
I0529 00:44:46.016209 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 00:44:46.016217 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.203297 (* 1 = 0.203297 loss)
I0529 00:44:46.016222 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.307944 (* 1 = 0.307944 loss)
I0529 00:44:46.016225 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104483 (* 1 = 0.0104483 loss)
I0529 00:44:46.016229 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485813 (* 1 = 0.0485813 loss)
I0529 00:44:46.016234 10644 sgd_solver.cpp:106] Iteration 11220, lr = 0.0002
I0529 00:45:34.528242 10644 solver.cpp:228] Iteration 11240, loss = 0.403847
I0529 00:45:34.528268 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 00:45:34.528277 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266703 (* 1 = 0.0266703 loss)
I0529 00:45:34.528281 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.181782 (* 1 = 0.181782 loss)
I0529 00:45:34.528285 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262425 (* 1 = 0.0262425 loss)
I0529 00:45:34.528290 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00992397 (* 1 = 0.00992397 loss)
I0529 00:45:34.528295 10644 sgd_solver.cpp:106] Iteration 11240, lr = 0.0002
I0529 00:46:23.088347 10644 solver.cpp:228] Iteration 11260, loss = 0.467413
I0529 00:46:23.088379 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:46:23.088387 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0421684 (* 1 = 0.0421684 loss)
I0529 00:46:23.088392 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157252 (* 1 = 0.157252 loss)
I0529 00:46:23.088395 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148244 (* 1 = 0.0148244 loss)
I0529 00:46:23.088399 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00119708 (* 1 = 0.00119708 loss)
I0529 00:46:23.088405 10644 sgd_solver.cpp:106] Iteration 11260, lr = 0.0002
I0529 00:47:11.618468 10644 solver.cpp:228] Iteration 11280, loss = 0.683955
I0529 00:47:11.618494 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 00:47:11.618500 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.266929 (* 1 = 0.266929 loss)
I0529 00:47:11.618505 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.435117 (* 1 = 0.435117 loss)
I0529 00:47:11.618507 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0385284 (* 1 = 0.0385284 loss)
I0529 00:47:11.618511 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0833239 (* 1 = 0.0833239 loss)
I0529 00:47:11.618516 10644 sgd_solver.cpp:106] Iteration 11280, lr = 0.0002
I0529 00:48:00.169332 10644 solver.cpp:228] Iteration 11300, loss = 0.34037
I0529 00:48:00.169358 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:48:00.169368 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397399 (* 1 = 0.0397399 loss)
I0529 00:48:00.169374 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144909 (* 1 = 0.144909 loss)
I0529 00:48:00.169379 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182291 (* 1 = 0.0182291 loss)
I0529 00:48:00.169384 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161376 (* 1 = 0.0161376 loss)
I0529 00:48:00.169391 10644 sgd_solver.cpp:106] Iteration 11300, lr = 0.0002
I0529 00:48:48.702977 10644 solver.cpp:228] Iteration 11320, loss = 0.283913
I0529 00:48:48.703003 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 00:48:48.703012 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.137677 (* 1 = 0.137677 loss)
I0529 00:48:48.703019 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.188712 (* 1 = 0.188712 loss)
I0529 00:48:48.703024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00751165 (* 1 = 0.00751165 loss)
I0529 00:48:48.703029 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286269 (* 1 = 0.0286269 loss)
I0529 00:48:48.703037 10644 sgd_solver.cpp:106] Iteration 11320, lr = 0.0002
I0529 00:49:37.236671 10644 solver.cpp:228] Iteration 11340, loss = 0.293797
I0529 00:49:37.236694 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 00:49:37.236702 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.146432 (* 1 = 0.146432 loss)
I0529 00:49:37.236706 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.175743 (* 1 = 0.175743 loss)
I0529 00:49:37.236711 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00951027 (* 1 = 0.00951027 loss)
I0529 00:49:37.236713 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00822334 (* 1 = 0.00822334 loss)
I0529 00:49:37.236717 10644 sgd_solver.cpp:106] Iteration 11340, lr = 0.0002
I0529 00:50:25.794466 10644 solver.cpp:228] Iteration 11360, loss = 0.446153
I0529 00:50:25.794497 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 00:50:25.794507 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433288 (* 1 = 0.0433288 loss)
I0529 00:50:25.794512 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110648 (* 1 = 0.110648 loss)
I0529 00:50:25.794518 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00943348 (* 1 = 0.00943348 loss)
I0529 00:50:25.794524 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.119727 (* 1 = 0.119727 loss)
I0529 00:50:25.794531 10644 sgd_solver.cpp:106] Iteration 11360, lr = 0.0002
I0529 00:51:14.328774 10644 solver.cpp:228] Iteration 11380, loss = 0.29453
I0529 00:51:14.328814 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 00:51:14.328824 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0903033 (* 1 = 0.0903033 loss)
I0529 00:51:14.328827 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.204795 (* 1 = 0.204795 loss)
I0529 00:51:14.328831 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170608 (* 1 = 0.0170608 loss)
I0529 00:51:14.328835 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262709 (* 1 = 0.0262709 loss)
I0529 00:51:14.328841 10644 sgd_solver.cpp:106] Iteration 11380, lr = 0.0002
speed: 2.430s / iter
I0529 00:52:02.881898 10644 solver.cpp:228] Iteration 11400, loss = 0.297367
I0529 00:52:02.881924 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 00:52:02.881933 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0731705 (* 1 = 0.0731705 loss)
I0529 00:52:02.881939 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.240238 (* 1 = 0.240238 loss)
I0529 00:52:02.881944 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0316105 (* 1 = 0.0316105 loss)
I0529 00:52:02.881949 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243797 (* 1 = 0.0243797 loss)
I0529 00:52:02.881956 10644 sgd_solver.cpp:106] Iteration 11400, lr = 0.0002
I0529 00:52:51.427604 10644 solver.cpp:228] Iteration 11420, loss = 0.227448
I0529 00:52:51.427630 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 00:52:51.427639 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190694 (* 1 = 0.0190694 loss)
I0529 00:52:51.427645 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134898 (* 1 = 0.134898 loss)
I0529 00:52:51.427650 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147636 (* 1 = 0.0147636 loss)
I0529 00:52:51.427655 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126272 (* 1 = 0.0126272 loss)
I0529 00:52:51.427662 10644 sgd_solver.cpp:106] Iteration 11420, lr = 0.0002
I0529 00:53:40.008510 10644 solver.cpp:228] Iteration 11440, loss = 0.43708
I0529 00:53:40.008539 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 00:53:40.008549 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.217269 (* 1 = 0.217269 loss)
I0529 00:53:40.008555 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.358815 (* 1 = 0.358815 loss)
I0529 00:53:40.008561 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00740478 (* 1 = 0.00740478 loss)
I0529 00:53:40.008569 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234958 (* 1 = 0.0234958 loss)
I0529 00:53:40.008575 10644 sgd_solver.cpp:106] Iteration 11440, lr = 0.0002
I0529 00:54:28.572351 10644 solver.cpp:228] Iteration 11460, loss = 0.345908
I0529 00:54:28.572381 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 00:54:28.572392 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.139749 (* 1 = 0.139749 loss)
I0529 00:54:28.572398 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.226163 (* 1 = 0.226163 loss)
I0529 00:54:28.572404 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119995 (* 1 = 0.0119995 loss)
I0529 00:54:28.572410 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0739665 (* 1 = 0.0739665 loss)
I0529 00:54:28.572418 10644 sgd_solver.cpp:106] Iteration 11460, lr = 0.0002
I0529 00:55:17.130412 10644 solver.cpp:228] Iteration 11480, loss = 0.254051
I0529 00:55:17.130437 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 00:55:17.130445 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.120856 (* 1 = 0.120856 loss)
I0529 00:55:17.130451 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.226128 (* 1 = 0.226128 loss)
I0529 00:55:17.130457 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0516841 (* 1 = 0.0516841 loss)
I0529 00:55:17.130463 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0748632 (* 1 = 0.0748632 loss)
I0529 00:55:17.130470 10644 sgd_solver.cpp:106] Iteration 11480, lr = 0.0002
I0529 00:56:05.666307 10644 solver.cpp:228] Iteration 11500, loss = 0.453068
I0529 00:56:05.666337 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 00:56:05.666344 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.252876 (* 1 = 0.252876 loss)
I0529 00:56:05.666349 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.449158 (* 1 = 0.449158 loss)
I0529 00:56:05.666354 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133662 (* 1 = 0.0133662 loss)
I0529 00:56:05.666358 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0696499 (* 1 = 0.0696499 loss)
I0529 00:56:05.666364 10644 sgd_solver.cpp:106] Iteration 11500, lr = 0.0002
I0529 00:56:54.232933 10644 solver.cpp:228] Iteration 11520, loss = 0.180598
I0529 00:56:54.232967 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 00:56:54.232978 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336732 (* 1 = 0.0336732 loss)
I0529 00:56:54.232985 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.074193 (* 1 = 0.074193 loss)
I0529 00:56:54.232991 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105842 (* 1 = 0.0105842 loss)
I0529 00:56:54.232997 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017042 (* 1 = 0.017042 loss)
I0529 00:56:54.233006 10644 sgd_solver.cpp:106] Iteration 11520, lr = 0.0002
I0529 00:57:42.778015 10644 solver.cpp:228] Iteration 11540, loss = 0.272364
I0529 00:57:42.778038 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 00:57:42.778046 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0238143 (* 1 = 0.0238143 loss)
I0529 00:57:42.778050 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0660495 (* 1 = 0.0660495 loss)
I0529 00:57:42.778053 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0045024 (* 1 = 0.0045024 loss)
I0529 00:57:42.778056 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153572 (* 1 = 0.0153572 loss)
I0529 00:57:42.778061 10644 sgd_solver.cpp:106] Iteration 11540, lr = 0.0002
I0529 00:58:31.306767 10644 solver.cpp:228] Iteration 11560, loss = 0.36387
I0529 00:58:31.306792 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 00:58:31.306799 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494087 (* 1 = 0.0494087 loss)
I0529 00:58:31.306804 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.138356 (* 1 = 0.138356 loss)
I0529 00:58:31.306807 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0697591 (* 1 = 0.0697591 loss)
I0529 00:58:31.306810 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118551 (* 1 = 0.118551 loss)
I0529 00:58:31.306815 10644 sgd_solver.cpp:106] Iteration 11560, lr = 0.0002
I0529 00:59:19.878331 10644 solver.cpp:228] Iteration 11580, loss = 0.403695
I0529 00:59:19.878355 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 00:59:19.878365 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627556 (* 1 = 0.0627556 loss)
I0529 00:59:19.878371 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.23959 (* 1 = 0.23959 loss)
I0529 00:59:19.878376 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206965 (* 1 = 0.0206965 loss)
I0529 00:59:19.878381 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258494 (* 1 = 0.0258494 loss)
I0529 00:59:19.878387 10644 sgd_solver.cpp:106] Iteration 11580, lr = 0.0002
speed: 2.430s / iter
I0529 01:00:08.413110 10644 solver.cpp:228] Iteration 11600, loss = 0.570907
I0529 01:00:08.413136 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 01:00:08.413142 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0618773 (* 1 = 0.0618773 loss)
I0529 01:00:08.413146 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0747043 (* 1 = 0.0747043 loss)
I0529 01:00:08.413151 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382633 (* 1 = 0.00382633 loss)
I0529 01:00:08.413153 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125618 (* 1 = 0.0125618 loss)
I0529 01:00:08.413158 10644 sgd_solver.cpp:106] Iteration 11600, lr = 0.0002
I0529 01:00:56.964768 10644 solver.cpp:228] Iteration 11620, loss = 0.449276
I0529 01:00:56.964795 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 01:00:56.964803 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.070253 (* 1 = 0.070253 loss)
I0529 01:00:56.964807 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.179217 (* 1 = 0.179217 loss)
I0529 01:00:56.964810 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0529764 (* 1 = 0.0529764 loss)
I0529 01:00:56.964813 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0920385 (* 1 = 0.0920385 loss)
I0529 01:00:56.964819 10644 sgd_solver.cpp:106] Iteration 11620, lr = 0.0002
I0529 01:01:45.509716 10644 solver.cpp:228] Iteration 11640, loss = 0.387577
I0529 01:01:45.509742 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 01:01:45.509748 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.137023 (* 1 = 0.137023 loss)
I0529 01:01:45.509752 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.302129 (* 1 = 0.302129 loss)
I0529 01:01:45.509757 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169021 (* 1 = 0.0169021 loss)
I0529 01:01:45.509763 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0757858 (* 1 = 0.0757858 loss)
I0529 01:01:45.509769 10644 sgd_solver.cpp:106] Iteration 11640, lr = 0.0002
I0529 01:02:34.067701 10644 solver.cpp:228] Iteration 11660, loss = 0.221467
I0529 01:02:34.067730 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 01:02:34.067737 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0943584 (* 1 = 0.0943584 loss)
I0529 01:02:34.067741 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.165808 (* 1 = 0.165808 loss)
I0529 01:02:34.067745 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00676613 (* 1 = 0.00676613 loss)
I0529 01:02:34.067749 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335825 (* 1 = 0.0335825 loss)
I0529 01:02:34.067754 10644 sgd_solver.cpp:106] Iteration 11660, lr = 0.0002
I0529 01:03:22.616127 10644 solver.cpp:228] Iteration 11680, loss = 0.261297
I0529 01:03:22.616152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 01:03:22.616158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443561 (* 1 = 0.0443561 loss)
I0529 01:03:22.616163 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.100035 (* 1 = 0.100035 loss)
I0529 01:03:22.616165 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00272447 (* 1 = 0.00272447 loss)
I0529 01:03:22.616169 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00734293 (* 1 = 0.00734293 loss)
I0529 01:03:22.616174 10644 sgd_solver.cpp:106] Iteration 11680, lr = 0.0002
I0529 01:04:11.178694 10644 solver.cpp:228] Iteration 11700, loss = 0.211765
I0529 01:04:11.178719 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 01:04:11.178727 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0667556 (* 1 = 0.0667556 loss)
I0529 01:04:11.178731 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.176526 (* 1 = 0.176526 loss)
I0529 01:04:11.178735 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013074 (* 1 = 0.013074 loss)
I0529 01:04:11.178738 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111848 (* 1 = 0.111848 loss)
I0529 01:04:11.178743 10644 sgd_solver.cpp:106] Iteration 11700, lr = 0.0002
I0529 01:04:59.735625 10644 solver.cpp:228] Iteration 11720, loss = 0.250163
I0529 01:04:59.735651 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 01:04:59.735657 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00995258 (* 1 = 0.00995258 loss)
I0529 01:04:59.735662 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0867882 (* 1 = 0.0867882 loss)
I0529 01:04:59.735666 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0865904 (* 1 = 0.0865904 loss)
I0529 01:04:59.735668 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0674419 (* 1 = 0.0674419 loss)
I0529 01:04:59.735673 10644 sgd_solver.cpp:106] Iteration 11720, lr = 0.0002
I0529 01:05:48.307793 10644 solver.cpp:228] Iteration 11740, loss = 0.400963
I0529 01:05:48.307821 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 01:05:48.307828 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.102189 (* 1 = 0.102189 loss)
I0529 01:05:48.307832 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.246357 (* 1 = 0.246357 loss)
I0529 01:05:48.307837 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0715141 (* 1 = 0.0715141 loss)
I0529 01:05:48.307840 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0775004 (* 1 = 0.0775004 loss)
I0529 01:05:48.307845 10644 sgd_solver.cpp:106] Iteration 11740, lr = 0.0002
I0529 01:06:36.847200 10644 solver.cpp:228] Iteration 11760, loss = 0.499001
I0529 01:06:36.847225 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 01:06:36.847234 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494112 (* 1 = 0.0494112 loss)
I0529 01:06:36.847237 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.177992 (* 1 = 0.177992 loss)
I0529 01:06:36.847241 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120583 (* 1 = 0.0120583 loss)
I0529 01:06:36.847245 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105856 (* 1 = 0.0105856 loss)
I0529 01:06:36.847250 10644 sgd_solver.cpp:106] Iteration 11760, lr = 0.0002
I0529 01:07:25.413599 10644 solver.cpp:228] Iteration 11780, loss = 0.378055
I0529 01:07:25.413625 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:07:25.413632 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.044719 (* 1 = 0.044719 loss)
I0529 01:07:25.413636 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121424 (* 1 = 0.121424 loss)
I0529 01:07:25.413640 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00380459 (* 1 = 0.00380459 loss)
I0529 01:07:25.413645 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217405 (* 1 = 0.0217405 loss)
I0529 01:07:25.413650 10644 sgd_solver.cpp:106] Iteration 11780, lr = 0.0002
speed: 2.430s / iter
I0529 01:08:14.009814 10644 solver.cpp:228] Iteration 11800, loss = 0.28292
I0529 01:08:14.009845 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 01:08:14.009852 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247574 (* 1 = 0.0247574 loss)
I0529 01:08:14.009857 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0476692 (* 1 = 0.0476692 loss)
I0529 01:08:14.009861 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00278462 (* 1 = 0.00278462 loss)
I0529 01:08:14.009865 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00756986 (* 1 = 0.00756986 loss)
I0529 01:08:14.009871 10644 sgd_solver.cpp:106] Iteration 11800, lr = 0.0002
I0529 01:09:02.568483 10644 solver.cpp:228] Iteration 11820, loss = 0.33614
I0529 01:09:02.568511 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 01:09:02.568518 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0793182 (* 1 = 0.0793182 loss)
I0529 01:09:02.568522 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.125986 (* 1 = 0.125986 loss)
I0529 01:09:02.568526 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016397 (* 1 = 0.016397 loss)
I0529 01:09:02.568531 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160415 (* 1 = 0.0160415 loss)
I0529 01:09:02.568536 10644 sgd_solver.cpp:106] Iteration 11820, lr = 0.0002
I0529 01:09:51.147857 10644 solver.cpp:228] Iteration 11840, loss = 0.3199
I0529 01:09:51.147884 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:09:51.147892 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0522049 (* 1 = 0.0522049 loss)
I0529 01:09:51.147897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0926965 (* 1 = 0.0926965 loss)
I0529 01:09:51.147900 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105409 (* 1 = 0.0105409 loss)
I0529 01:09:51.147904 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0355751 (* 1 = 0.0355751 loss)
I0529 01:09:51.147910 10644 sgd_solver.cpp:106] Iteration 11840, lr = 0.0002
I0529 01:10:39.710155 10644 solver.cpp:228] Iteration 11860, loss = 0.569414
I0529 01:10:39.710181 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:10:39.710189 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325135 (* 1 = 0.0325135 loss)
I0529 01:10:39.710194 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.123635 (* 1 = 0.123635 loss)
I0529 01:10:39.710197 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203674 (* 1 = 0.0203674 loss)
I0529 01:10:39.710201 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199172 (* 1 = 0.0199172 loss)
I0529 01:10:39.710207 10644 sgd_solver.cpp:106] Iteration 11860, lr = 0.0002
I0529 01:11:28.297747 10644 solver.cpp:228] Iteration 11880, loss = 0.195446
I0529 01:11:28.297775 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 01:11:28.297785 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0865467 (* 1 = 0.0865467 loss)
I0529 01:11:28.297793 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.12882 (* 1 = 0.12882 loss)
I0529 01:11:28.297798 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012555 (* 1 = 0.012555 loss)
I0529 01:11:28.297804 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172452 (* 1 = 0.0172452 loss)
I0529 01:11:28.297811 10644 sgd_solver.cpp:106] Iteration 11880, lr = 0.0002
I0529 01:12:16.824651 10644 solver.cpp:228] Iteration 11900, loss = 0.370005
I0529 01:12:16.824678 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:12:16.824688 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378467 (* 1 = 0.0378467 loss)
I0529 01:12:16.824694 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.125474 (* 1 = 0.125474 loss)
I0529 01:12:16.824700 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162243 (* 1 = 0.00162243 loss)
I0529 01:12:16.824705 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00938805 (* 1 = 0.00938805 loss)
I0529 01:12:16.824712 10644 sgd_solver.cpp:106] Iteration 11900, lr = 0.0002
I0529 01:13:05.353724 10644 solver.cpp:228] Iteration 11920, loss = 0.213916
I0529 01:13:05.353750 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 01:13:05.353757 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0152378 (* 1 = 0.0152378 loss)
I0529 01:13:05.353761 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0736267 (* 1 = 0.0736267 loss)
I0529 01:13:05.353765 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110358 (* 1 = 0.0110358 loss)
I0529 01:13:05.353768 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229397 (* 1 = 0.0229397 loss)
I0529 01:13:05.353775 10644 sgd_solver.cpp:106] Iteration 11920, lr = 0.0002
I0529 01:13:53.902060 10644 solver.cpp:228] Iteration 11940, loss = 0.439278
I0529 01:13:53.902086 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 01:13:53.902092 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.198579 (* 1 = 0.198579 loss)
I0529 01:13:53.902096 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.411714 (* 1 = 0.411714 loss)
I0529 01:13:53.902099 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102685 (* 1 = 0.0102685 loss)
I0529 01:13:53.902102 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0287591 (* 1 = 0.0287591 loss)
I0529 01:13:53.902107 10644 sgd_solver.cpp:106] Iteration 11940, lr = 0.0002
I0529 01:14:42.493513 10644 solver.cpp:228] Iteration 11960, loss = 0.38758
I0529 01:14:42.493538 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:14:42.493546 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0704174 (* 1 = 0.0704174 loss)
I0529 01:14:42.493551 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0979192 (* 1 = 0.0979192 loss)
I0529 01:14:42.493554 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00431096 (* 1 = 0.00431096 loss)
I0529 01:14:42.493557 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121047 (* 1 = 0.0121047 loss)
I0529 01:14:42.493562 10644 sgd_solver.cpp:106] Iteration 11960, lr = 0.0002
I0529 01:15:31.056429 10644 solver.cpp:228] Iteration 11980, loss = 0.414394
I0529 01:15:31.056452 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 01:15:31.056459 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000605628 (* 1 = 0.000605628 loss)
I0529 01:15:31.056463 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.046351 (* 1 = 0.046351 loss)
I0529 01:15:31.056468 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174109 (* 1 = 0.0174109 loss)
I0529 01:15:31.056470 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040592 (* 1 = 0.040592 loss)
I0529 01:15:31.056475 10644 sgd_solver.cpp:106] Iteration 11980, lr = 0.0002
speed: 2.430s / iter
I0529 01:16:19.627739 10644 solver.cpp:228] Iteration 12000, loss = 0.283312
I0529 01:16:19.627768 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 01:16:19.627775 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.11255 (* 1 = 0.11255 loss)
I0529 01:16:19.627779 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.260096 (* 1 = 0.260096 loss)
I0529 01:16:19.627782 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114813 (* 1 = 0.0114813 loss)
I0529 01:16:19.627786 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186206 (* 1 = 0.0186206 loss)
I0529 01:16:19.627791 10644 sgd_solver.cpp:106] Iteration 12000, lr = 0.0002
I0529 01:17:08.233494 10644 solver.cpp:228] Iteration 12020, loss = 0.381628
I0529 01:17:08.233518 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 01:17:08.233526 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.220995 (* 1 = 0.220995 loss)
I0529 01:17:08.233530 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.353477 (* 1 = 0.353477 loss)
I0529 01:17:08.233534 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00887379 (* 1 = 0.00887379 loss)
I0529 01:17:08.233537 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481551 (* 1 = 0.0481551 loss)
I0529 01:17:08.233542 10644 sgd_solver.cpp:106] Iteration 12020, lr = 0.0002
I0529 01:17:56.786092 10644 solver.cpp:228] Iteration 12040, loss = 0.389476
I0529 01:17:56.786119 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:17:56.786129 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494301 (* 1 = 0.0494301 loss)
I0529 01:17:56.786135 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0785641 (* 1 = 0.0785641 loss)
I0529 01:17:56.786140 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00242076 (* 1 = 0.00242076 loss)
I0529 01:17:56.786146 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00722555 (* 1 = 0.00722555 loss)
I0529 01:17:56.786152 10644 sgd_solver.cpp:106] Iteration 12040, lr = 0.0002
I0529 01:18:45.340785 10644 solver.cpp:228] Iteration 12060, loss = 0.39278
I0529 01:18:45.340812 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 01:18:45.340821 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.283805 (* 1 = 0.283805 loss)
I0529 01:18:45.340824 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.522836 (* 1 = 0.522836 loss)
I0529 01:18:45.340828 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112719 (* 1 = 0.0112719 loss)
I0529 01:18:45.340832 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0413776 (* 1 = 0.0413776 loss)
I0529 01:18:45.340837 10644 sgd_solver.cpp:106] Iteration 12060, lr = 0.0002
I0529 01:19:33.883352 10644 solver.cpp:228] Iteration 12080, loss = 0.278668
I0529 01:19:33.883385 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:19:33.883394 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369113 (* 1 = 0.0369113 loss)
I0529 01:19:33.883400 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.184621 (* 1 = 0.184621 loss)
I0529 01:19:33.883406 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153351 (* 1 = 0.0153351 loss)
I0529 01:19:33.883412 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241208 (* 1 = 0.0241208 loss)
I0529 01:19:33.883421 10644 sgd_solver.cpp:106] Iteration 12080, lr = 0.0002
I0529 01:20:22.429863 10644 solver.cpp:228] Iteration 12100, loss = 0.438086
I0529 01:20:22.429890 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 01:20:22.429898 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0996788 (* 1 = 0.0996788 loss)
I0529 01:20:22.429903 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.248554 (* 1 = 0.248554 loss)
I0529 01:20:22.429906 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0734749 (* 1 = 0.0734749 loss)
I0529 01:20:22.429910 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300978 (* 1 = 0.0300978 loss)
I0529 01:20:22.429915 10644 sgd_solver.cpp:106] Iteration 12100, lr = 0.0002
I0529 01:21:10.987843 10644 solver.cpp:228] Iteration 12120, loss = 0.417408
I0529 01:21:10.987872 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:21:10.987879 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.141457 (* 1 = 0.141457 loss)
I0529 01:21:10.987884 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128563 (* 1 = 0.128563 loss)
I0529 01:21:10.987888 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938084 (* 1 = 0.00938084 loss)
I0529 01:21:10.987891 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438261 (* 1 = 0.0438261 loss)
I0529 01:21:10.987898 10644 sgd_solver.cpp:106] Iteration 12120, lr = 0.0002
I0529 01:21:59.546892 10644 solver.cpp:228] Iteration 12140, loss = 0.399057
I0529 01:21:59.546916 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 01:21:59.546924 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0705312 (* 1 = 0.0705312 loss)
I0529 01:21:59.546929 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.238865 (* 1 = 0.238865 loss)
I0529 01:21:59.546933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.033228 (* 1 = 0.033228 loss)
I0529 01:21:59.546936 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402491 (* 1 = 0.0402491 loss)
I0529 01:21:59.546941 10644 sgd_solver.cpp:106] Iteration 12140, lr = 0.0002
I0529 01:22:48.104879 10644 solver.cpp:228] Iteration 12160, loss = 0.235091
I0529 01:22:48.104907 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 01:22:48.104918 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.229036 (* 1 = 0.229036 loss)
I0529 01:22:48.104921 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.240779 (* 1 = 0.240779 loss)
I0529 01:22:48.104925 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266826 (* 1 = 0.00266826 loss)
I0529 01:22:48.104929 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0376585 (* 1 = 0.0376585 loss)
I0529 01:22:48.104935 10644 sgd_solver.cpp:106] Iteration 12160, lr = 0.0002
I0529 01:23:36.636605 10644 solver.cpp:228] Iteration 12180, loss = 0.378665
I0529 01:23:36.636628 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 01:23:36.636636 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.112073 (* 1 = 0.112073 loss)
I0529 01:23:36.636641 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.129584 (* 1 = 0.129584 loss)
I0529 01:23:36.636644 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00813836 (* 1 = 0.00813836 loss)
I0529 01:23:36.636648 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0820201 (* 1 = 0.0820201 loss)
I0529 01:23:36.636653 10644 sgd_solver.cpp:106] Iteration 12180, lr = 0.0002
speed: 2.430s / iter
I0529 01:24:25.159991 10644 solver.cpp:228] Iteration 12200, loss = 0.235458
I0529 01:24:25.160017 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 01:24:25.160023 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.197431 (* 1 = 0.197431 loss)
I0529 01:24:25.160028 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.269952 (* 1 = 0.269952 loss)
I0529 01:24:25.160032 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0370832 (* 1 = 0.0370832 loss)
I0529 01:24:25.160035 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035958 (* 1 = 0.035958 loss)
I0529 01:24:25.160040 10644 sgd_solver.cpp:106] Iteration 12200, lr = 0.0002
I0529 01:25:13.715840 10644 solver.cpp:228] Iteration 12220, loss = 0.271109
I0529 01:25:13.715865 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 01:25:13.715873 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172273 (* 1 = 0.0172273 loss)
I0529 01:25:13.715878 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0533704 (* 1 = 0.0533704 loss)
I0529 01:25:13.715880 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00733047 (* 1 = 0.00733047 loss)
I0529 01:25:13.715884 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134201 (* 1 = 0.0134201 loss)
I0529 01:25:13.715889 10644 sgd_solver.cpp:106] Iteration 12220, lr = 0.0002
I0529 01:26:02.220751 10644 solver.cpp:228] Iteration 12240, loss = 0.220136
I0529 01:26:02.220777 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 01:26:02.220782 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392695 (* 1 = 0.0392695 loss)
I0529 01:26:02.220787 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0580543 (* 1 = 0.0580543 loss)
I0529 01:26:02.220790 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00525986 (* 1 = 0.00525986 loss)
I0529 01:26:02.220793 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0056507 (* 1 = 0.0056507 loss)
I0529 01:26:02.220798 10644 sgd_solver.cpp:106] Iteration 12240, lr = 0.0002
I0529 01:26:50.738044 10644 solver.cpp:228] Iteration 12260, loss = 0.376538
I0529 01:26:50.738070 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 01:26:50.738076 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.111267 (* 1 = 0.111267 loss)
I0529 01:26:50.738080 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.322354 (* 1 = 0.322354 loss)
I0529 01:26:50.738083 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0417234 (* 1 = 0.0417234 loss)
I0529 01:26:50.738086 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301238 (* 1 = 0.0301238 loss)
I0529 01:26:50.738092 10644 sgd_solver.cpp:106] Iteration 12260, lr = 0.0002
I0529 01:27:39.273382 10644 solver.cpp:228] Iteration 12280, loss = 0.358225
I0529 01:27:39.273411 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 01:27:39.273417 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00424111 (* 1 = 0.00424111 loss)
I0529 01:27:39.273422 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108736 (* 1 = 0.108736 loss)
I0529 01:27:39.273424 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0388334 (* 1 = 0.0388334 loss)
I0529 01:27:39.273428 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302491 (* 1 = 0.0302491 loss)
I0529 01:27:39.273433 10644 sgd_solver.cpp:106] Iteration 12280, lr = 0.0002
I0529 01:28:27.743614 10644 solver.cpp:228] Iteration 12300, loss = 0.338964
I0529 01:28:27.743635 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 01:28:27.743643 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529965 (* 1 = 0.0529965 loss)
I0529 01:28:27.743645 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.175621 (* 1 = 0.175621 loss)
I0529 01:28:27.743649 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154361 (* 1 = 0.0154361 loss)
I0529 01:28:27.743654 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00860089 (* 1 = 0.00860089 loss)
I0529 01:28:27.743657 10644 sgd_solver.cpp:106] Iteration 12300, lr = 0.0002
I0529 01:29:16.149410 10644 solver.cpp:228] Iteration 12320, loss = 0.287264
I0529 01:29:16.149435 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 01:29:16.149443 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.10478 (* 1 = 0.10478 loss)
I0529 01:29:16.149449 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.156758 (* 1 = 0.156758 loss)
I0529 01:29:16.149454 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142171 (* 1 = 0.0142171 loss)
I0529 01:29:16.149461 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321352 (* 1 = 0.0321352 loss)
I0529 01:29:16.149466 10644 sgd_solver.cpp:106] Iteration 12320, lr = 0.0002
I0529 01:30:04.718078 10644 solver.cpp:228] Iteration 12340, loss = 0.573191
I0529 01:30:04.718103 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:30:04.718111 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0655126 (* 1 = 0.0655126 loss)
I0529 01:30:04.718114 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.177127 (* 1 = 0.177127 loss)
I0529 01:30:04.718117 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136629 (* 1 = 0.0136629 loss)
I0529 01:30:04.718120 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293536 (* 1 = 0.0293536 loss)
I0529 01:30:04.718125 10644 sgd_solver.cpp:106] Iteration 12340, lr = 0.0002
I0529 01:30:53.239935 10644 solver.cpp:228] Iteration 12360, loss = 0.257416
I0529 01:30:53.239964 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 01:30:53.239971 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000868566 (* 1 = 0.000868566 loss)
I0529 01:30:53.239975 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0416101 (* 1 = 0.0416101 loss)
I0529 01:30:53.239979 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.029947 (* 1 = 0.029947 loss)
I0529 01:30:53.239982 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570842 (* 1 = 0.00570842 loss)
I0529 01:30:53.239987 10644 sgd_solver.cpp:106] Iteration 12360, lr = 0.0002
I0529 01:31:41.777860 10644 solver.cpp:228] Iteration 12380, loss = 0.277471
I0529 01:31:41.777887 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 01:31:41.777895 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433618 (* 1 = 0.0433618 loss)
I0529 01:31:41.777899 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.102165 (* 1 = 0.102165 loss)
I0529 01:31:41.777904 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00429704 (* 1 = 0.00429704 loss)
I0529 01:31:41.777907 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102031 (* 1 = 0.0102031 loss)
I0529 01:31:41.777912 10644 sgd_solver.cpp:106] Iteration 12380, lr = 0.0002
speed: 2.430s / iter
I0529 01:32:30.325381 10644 solver.cpp:228] Iteration 12400, loss = 0.42594
I0529 01:32:30.325407 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:32:30.325414 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0281167 (* 1 = 0.0281167 loss)
I0529 01:32:30.325418 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0765454 (* 1 = 0.0765454 loss)
I0529 01:32:30.325423 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00963892 (* 1 = 0.00963892 loss)
I0529 01:32:30.325426 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110101 (* 1 = 0.0110101 loss)
I0529 01:32:30.325431 10644 sgd_solver.cpp:106] Iteration 12400, lr = 0.0002
I0529 01:33:18.878648 10644 solver.cpp:228] Iteration 12420, loss = 0.41824
I0529 01:33:18.878672 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0529 01:33:18.878680 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.440159 (* 1 = 0.440159 loss)
I0529 01:33:18.878684 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.540005 (* 1 = 0.540005 loss)
I0529 01:33:18.878688 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016176 (* 1 = 0.016176 loss)
I0529 01:33:18.878692 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0852337 (* 1 = 0.0852337 loss)
I0529 01:33:18.878697 10644 sgd_solver.cpp:106] Iteration 12420, lr = 0.0002
I0529 01:34:07.432832 10644 solver.cpp:228] Iteration 12440, loss = 0.184052
I0529 01:34:07.432907 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 01:34:07.432957 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0344354 (* 1 = 0.0344354 loss)
I0529 01:34:07.432974 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.093785 (* 1 = 0.093785 loss)
I0529 01:34:07.432991 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00449197 (* 1 = 0.00449197 loss)
I0529 01:34:07.433006 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134482 (* 1 = 0.0134482 loss)
I0529 01:34:07.433023 10644 sgd_solver.cpp:106] Iteration 12440, lr = 0.0002
I0529 01:34:55.973542 10644 solver.cpp:228] Iteration 12460, loss = 0.575207
I0529 01:34:55.973569 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0529 01:34:55.973577 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.519572 (* 1 = 0.519572 loss)
I0529 01:34:55.973582 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.621732 (* 1 = 0.621732 loss)
I0529 01:34:55.973585 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0233764 (* 1 = 0.0233764 loss)
I0529 01:34:55.973588 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.237365 (* 1 = 0.237365 loss)
I0529 01:34:55.973594 10644 sgd_solver.cpp:106] Iteration 12460, lr = 0.0002
I0529 01:35:44.525753 10644 solver.cpp:228] Iteration 12480, loss = 0.450004
I0529 01:35:44.525777 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:35:44.525784 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.065745 (* 1 = 0.065745 loss)
I0529 01:35:44.525789 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0824635 (* 1 = 0.0824635 loss)
I0529 01:35:44.525791 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118915 (* 1 = 0.0118915 loss)
I0529 01:35:44.525795 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353405 (* 1 = 0.0353405 loss)
I0529 01:35:44.525799 10644 sgd_solver.cpp:106] Iteration 12480, lr = 0.0002
I0529 01:36:33.041189 10644 solver.cpp:228] Iteration 12500, loss = 0.399656
I0529 01:36:33.041214 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 01:36:33.041223 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000458216 (* 1 = 0.000458216 loss)
I0529 01:36:33.041226 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0443206 (* 1 = 0.0443206 loss)
I0529 01:36:33.041229 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196565 (* 1 = 0.0196565 loss)
I0529 01:36:33.041234 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111844 (* 1 = 0.0111844 loss)
I0529 01:36:33.041239 10644 sgd_solver.cpp:106] Iteration 12500, lr = 0.0002
I0529 01:37:21.570623 10644 solver.cpp:228] Iteration 12520, loss = 0.341382
I0529 01:37:21.570648 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:37:21.570655 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0290593 (* 1 = 0.0290593 loss)
I0529 01:37:21.570659 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114034 (* 1 = 0.114034 loss)
I0529 01:37:21.570663 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00284083 (* 1 = 0.00284083 loss)
I0529 01:37:21.570667 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141615 (* 1 = 0.0141615 loss)
I0529 01:37:21.570672 10644 sgd_solver.cpp:106] Iteration 12520, lr = 0.0002
I0529 01:38:10.100450 10644 solver.cpp:228] Iteration 12540, loss = 0.310672
I0529 01:38:10.100476 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 01:38:10.100483 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.074173 (* 1 = 0.074173 loss)
I0529 01:38:10.100487 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0672754 (* 1 = 0.0672754 loss)
I0529 01:38:10.100492 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00533078 (* 1 = 0.00533078 loss)
I0529 01:38:10.100495 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00421029 (* 1 = 0.00421029 loss)
I0529 01:38:10.100500 10644 sgd_solver.cpp:106] Iteration 12540, lr = 0.0002
I0529 01:38:58.638375 10644 solver.cpp:228] Iteration 12560, loss = 0.384412
I0529 01:38:58.638401 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 01:38:58.638408 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.32051 (* 1 = 0.32051 loss)
I0529 01:38:58.638412 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.435407 (* 1 = 0.435407 loss)
I0529 01:38:58.638415 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118957 (* 1 = 0.0118957 loss)
I0529 01:38:58.638420 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0800043 (* 1 = 0.0800043 loss)
I0529 01:38:58.638425 10644 sgd_solver.cpp:106] Iteration 12560, lr = 0.0002
I0529 01:39:47.199599 10644 solver.cpp:228] Iteration 12580, loss = 0.458749
I0529 01:39:47.199622 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 01:39:47.199630 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.104159 (* 1 = 0.104159 loss)
I0529 01:39:47.199635 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.259495 (* 1 = 0.259495 loss)
I0529 01:39:47.199640 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0314938 (* 1 = 0.0314938 loss)
I0529 01:39:47.199642 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421448 (* 1 = 0.0421448 loss)
I0529 01:39:47.199648 10644 sgd_solver.cpp:106] Iteration 12580, lr = 0.0002
speed: 2.430s / iter
I0529 01:40:35.733904 10644 solver.cpp:228] Iteration 12600, loss = 0.406463
I0529 01:40:35.733930 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 01:40:35.733938 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108429 (* 1 = 0.0108429 loss)
I0529 01:40:35.733943 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0792174 (* 1 = 0.0792174 loss)
I0529 01:40:35.733947 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00979625 (* 1 = 0.00979625 loss)
I0529 01:40:35.733952 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238372 (* 1 = 0.0238372 loss)
I0529 01:40:35.733955 10644 sgd_solver.cpp:106] Iteration 12600, lr = 0.0002
I0529 01:41:24.277289 10644 solver.cpp:228] Iteration 12620, loss = 0.401787
I0529 01:41:24.277318 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 01:41:24.277325 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.161174 (* 1 = 0.161174 loss)
I0529 01:41:24.277329 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.23849 (* 1 = 0.23849 loss)
I0529 01:41:24.277333 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114391 (* 1 = 0.0114391 loss)
I0529 01:41:24.277338 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254006 (* 1 = 0.0254006 loss)
I0529 01:41:24.277343 10644 sgd_solver.cpp:106] Iteration 12620, lr = 0.0002
I0529 01:42:12.815040 10644 solver.cpp:228] Iteration 12640, loss = 0.526485
I0529 01:42:12.815114 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0529 01:42:12.815140 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.279868 (* 1 = 0.279868 loss)
I0529 01:42:12.815156 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.460371 (* 1 = 0.460371 loss)
I0529 01:42:12.815171 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00910832 (* 1 = 0.00910832 loss)
I0529 01:42:12.815189 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0774508 (* 1 = 0.0774508 loss)
I0529 01:42:12.815207 10644 sgd_solver.cpp:106] Iteration 12640, lr = 0.0002
I0529 01:43:01.348857 10644 solver.cpp:228] Iteration 12660, loss = 0.185217
I0529 01:43:01.348884 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 01:43:01.348892 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0929961 (* 1 = 0.0929961 loss)
I0529 01:43:01.348897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.161958 (* 1 = 0.161958 loss)
I0529 01:43:01.348901 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00329028 (* 1 = 0.00329028 loss)
I0529 01:43:01.348904 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298366 (* 1 = 0.0298366 loss)
I0529 01:43:01.348913 10644 sgd_solver.cpp:106] Iteration 12660, lr = 0.0002
I0529 01:43:49.884523 10644 solver.cpp:228] Iteration 12680, loss = 0.283867
I0529 01:43:49.884553 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 01:43:49.884562 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0428473 (* 1 = 0.0428473 loss)
I0529 01:43:49.884567 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0621458 (* 1 = 0.0621458 loss)
I0529 01:43:49.884570 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00754578 (* 1 = 0.00754578 loss)
I0529 01:43:49.884574 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132946 (* 1 = 0.0132946 loss)
I0529 01:43:49.884582 10644 sgd_solver.cpp:106] Iteration 12680, lr = 0.0002
I0529 01:44:38.417516 10644 solver.cpp:228] Iteration 12700, loss = 0.239354
I0529 01:44:38.417541 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 01:44:38.417548 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0556532 (* 1 = 0.0556532 loss)
I0529 01:44:38.417552 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144102 (* 1 = 0.144102 loss)
I0529 01:44:38.417557 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00733154 (* 1 = 0.00733154 loss)
I0529 01:44:38.417559 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156489 (* 1 = 0.0156489 loss)
I0529 01:44:38.417565 10644 sgd_solver.cpp:106] Iteration 12700, lr = 0.0002
I0529 01:45:26.933562 10644 solver.cpp:228] Iteration 12720, loss = 0.389461
I0529 01:45:26.933586 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 01:45:26.933596 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0806722 (* 1 = 0.0806722 loss)
I0529 01:45:26.933601 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151545 (* 1 = 0.151545 loss)
I0529 01:45:26.933607 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00214475 (* 1 = 0.00214475 loss)
I0529 01:45:26.933612 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00604566 (* 1 = 0.00604566 loss)
I0529 01:45:26.933619 10644 sgd_solver.cpp:106] Iteration 12720, lr = 0.0002
I0529 01:46:15.487619 10644 solver.cpp:228] Iteration 12740, loss = 0.508745
I0529 01:46:15.487646 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 01:46:15.487653 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.270305 (* 1 = 0.270305 loss)
I0529 01:46:15.487658 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.331798 (* 1 = 0.331798 loss)
I0529 01:46:15.487660 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0250275 (* 1 = 0.0250275 loss)
I0529 01:46:15.487664 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.053123 (* 1 = 0.053123 loss)
I0529 01:46:15.487669 10644 sgd_solver.cpp:106] Iteration 12740, lr = 0.0002
I0529 01:47:04.047629 10644 solver.cpp:228] Iteration 12760, loss = 0.200138
I0529 01:47:04.047653 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:47:04.047662 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0577548 (* 1 = 0.0577548 loss)
I0529 01:47:04.047665 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0870827 (* 1 = 0.0870827 loss)
I0529 01:47:04.047668 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0024536 (* 1 = 0.0024536 loss)
I0529 01:47:04.047672 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102352 (* 1 = 0.0102352 loss)
I0529 01:47:04.047677 10644 sgd_solver.cpp:106] Iteration 12760, lr = 0.0002
I0529 01:47:52.573691 10644 solver.cpp:228] Iteration 12780, loss = 0.355602
I0529 01:47:52.573717 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 01:47:52.573727 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.146558 (* 1 = 0.146558 loss)
I0529 01:47:52.573734 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.252654 (* 1 = 0.252654 loss)
I0529 01:47:52.573740 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636177 (* 1 = 0.00636177 loss)
I0529 01:47:52.573745 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372371 (* 1 = 0.0372371 loss)
I0529 01:47:52.573751 10644 sgd_solver.cpp:106] Iteration 12780, lr = 0.0002
speed: 2.430s / iter
I0529 01:48:41.147418 10644 solver.cpp:228] Iteration 12800, loss = 0.289828
I0529 01:48:41.147446 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 01:48:41.147454 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.136439 (* 1 = 0.136439 loss)
I0529 01:48:41.147459 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.143434 (* 1 = 0.143434 loss)
I0529 01:48:41.147461 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403182 (* 1 = 0.00403182 loss)
I0529 01:48:41.147465 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175931 (* 1 = 0.0175931 loss)
I0529 01:48:41.147471 10644 sgd_solver.cpp:106] Iteration 12800, lr = 0.0002
I0529 01:49:29.699730 10644 solver.cpp:228] Iteration 12820, loss = 0.394736
I0529 01:49:29.699765 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 01:49:29.699776 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.307055 (* 1 = 0.307055 loss)
I0529 01:49:29.699782 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.379769 (* 1 = 0.379769 loss)
I0529 01:49:29.699790 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261028 (* 1 = 0.0261028 loss)
I0529 01:49:29.699795 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.258615 (* 1 = 0.258615 loss)
I0529 01:49:29.699802 10644 sgd_solver.cpp:106] Iteration 12820, lr = 0.0002
I0529 01:50:18.222223 10644 solver.cpp:228] Iteration 12840, loss = 0.316582
I0529 01:50:18.222252 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 01:50:18.222260 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.030092 (* 1 = 0.030092 loss)
I0529 01:50:18.222265 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0948907 (* 1 = 0.0948907 loss)
I0529 01:50:18.222270 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00496913 (* 1 = 0.00496913 loss)
I0529 01:50:18.222273 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00256096 (* 1 = 0.00256096 loss)
I0529 01:50:18.222280 10644 sgd_solver.cpp:106] Iteration 12840, lr = 0.0002
I0529 01:51:06.748828 10644 solver.cpp:228] Iteration 12860, loss = 0.314548
I0529 01:51:06.748854 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 01:51:06.748862 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100598 (* 1 = 0.100598 loss)
I0529 01:51:06.748867 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142103 (* 1 = 0.142103 loss)
I0529 01:51:06.748872 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604843 (* 1 = 0.00604843 loss)
I0529 01:51:06.748874 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00887675 (* 1 = 0.00887675 loss)
I0529 01:51:06.748879 10644 sgd_solver.cpp:106] Iteration 12860, lr = 0.0002
I0529 01:51:55.270527 10644 solver.cpp:228] Iteration 12880, loss = 0.305825
I0529 01:51:55.270551 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 01:51:55.270558 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.127168 (* 1 = 0.127168 loss)
I0529 01:51:55.270561 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234377 (* 1 = 0.234377 loss)
I0529 01:51:55.270565 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00564822 (* 1 = 0.00564822 loss)
I0529 01:51:55.270568 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228275 (* 1 = 0.0228275 loss)
I0529 01:51:55.270573 10644 sgd_solver.cpp:106] Iteration 12880, lr = 0.0002
I0529 01:52:43.824754 10644 solver.cpp:228] Iteration 12900, loss = 0.269591
I0529 01:52:43.824779 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 01:52:43.824786 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.159504 (* 1 = 0.159504 loss)
I0529 01:52:43.824790 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.30662 (* 1 = 0.30662 loss)
I0529 01:52:43.824795 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0329496 (* 1 = 0.0329496 loss)
I0529 01:52:43.824797 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127432 (* 1 = 0.127432 loss)
I0529 01:52:43.824802 10644 sgd_solver.cpp:106] Iteration 12900, lr = 0.0002
I0529 01:53:32.374848 10644 solver.cpp:228] Iteration 12920, loss = 0.289269
I0529 01:53:32.374873 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 01:53:32.374881 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.217253 (* 1 = 0.217253 loss)
I0529 01:53:32.374884 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.327718 (* 1 = 0.327718 loss)
I0529 01:53:32.374888 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112421 (* 1 = 0.0112421 loss)
I0529 01:53:32.374891 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0420994 (* 1 = 0.0420994 loss)
I0529 01:53:32.374897 10644 sgd_solver.cpp:106] Iteration 12920, lr = 0.0002
I0529 01:54:20.887418 10644 solver.cpp:228] Iteration 12940, loss = 0.38779
I0529 01:54:20.887445 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 01:54:20.887452 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.160981 (* 1 = 0.160981 loss)
I0529 01:54:20.887456 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.442906 (* 1 = 0.442906 loss)
I0529 01:54:20.887460 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00554238 (* 1 = 0.00554238 loss)
I0529 01:54:20.887464 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314705 (* 1 = 0.0314705 loss)
I0529 01:54:20.887470 10644 sgd_solver.cpp:106] Iteration 12940, lr = 0.0002
I0529 01:55:09.424429 10644 solver.cpp:228] Iteration 12960, loss = 0.347439
I0529 01:55:09.424458 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 01:55:09.424464 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.145134 (* 1 = 0.145134 loss)
I0529 01:55:09.424468 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.177975 (* 1 = 0.177975 loss)
I0529 01:55:09.424471 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541682 (* 1 = 0.00541682 loss)
I0529 01:55:09.424475 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303541 (* 1 = 0.0303541 loss)
I0529 01:55:09.424480 10644 sgd_solver.cpp:106] Iteration 12960, lr = 0.0002
I0529 01:55:57.995002 10644 solver.cpp:228] Iteration 12980, loss = 0.410901
I0529 01:55:57.995028 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 01:55:57.995035 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.243591 (* 1 = 0.243591 loss)
I0529 01:55:57.995039 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.397407 (* 1 = 0.397407 loss)
I0529 01:55:57.995043 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0291479 (* 1 = 0.0291479 loss)
I0529 01:55:57.995046 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100512 (* 1 = 0.100512 loss)
I0529 01:55:57.995052 10644 sgd_solver.cpp:106] Iteration 12980, lr = 0.0002
speed: 2.430s / iter
I0529 01:56:46.546751 10644 solver.cpp:228] Iteration 13000, loss = 0.300243
I0529 01:56:46.546777 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 01:56:46.546782 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.154619 (* 1 = 0.154619 loss)
I0529 01:56:46.546787 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.329405 (* 1 = 0.329405 loss)
I0529 01:56:46.546790 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0477686 (* 1 = 0.0477686 loss)
I0529 01:56:46.546793 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0391971 (* 1 = 0.0391971 loss)
I0529 01:56:46.546798 10644 sgd_solver.cpp:106] Iteration 13000, lr = 0.0002
I0529 01:57:35.071241 10644 solver.cpp:228] Iteration 13020, loss = 0.361237
I0529 01:57:35.071266 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 01:57:35.071274 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.102607 (* 1 = 0.102607 loss)
I0529 01:57:35.071276 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.233675 (* 1 = 0.233675 loss)
I0529 01:57:35.071280 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00415898 (* 1 = 0.00415898 loss)
I0529 01:57:35.071285 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307736 (* 1 = 0.0307736 loss)
I0529 01:57:35.071290 10644 sgd_solver.cpp:106] Iteration 13020, lr = 0.0002
I0529 01:58:23.631197 10644 solver.cpp:228] Iteration 13040, loss = 0.378651
I0529 01:58:23.631224 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 01:58:23.631232 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524854 (* 1 = 0.0524854 loss)
I0529 01:58:23.631237 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142686 (* 1 = 0.142686 loss)
I0529 01:58:23.631242 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00332507 (* 1 = 0.00332507 loss)
I0529 01:58:23.631245 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00613637 (* 1 = 0.00613637 loss)
I0529 01:58:23.631250 10644 sgd_solver.cpp:106] Iteration 13040, lr = 0.0002
I0529 01:59:12.162092 10644 solver.cpp:228] Iteration 13060, loss = 0.293897
I0529 01:59:12.162122 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 01:59:12.162132 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0343758 (* 1 = 0.0343758 loss)
I0529 01:59:12.162137 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142381 (* 1 = 0.142381 loss)
I0529 01:59:12.162140 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00544141 (* 1 = 0.00544141 loss)
I0529 01:59:12.162144 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00775671 (* 1 = 0.00775671 loss)
I0529 01:59:12.162150 10644 sgd_solver.cpp:106] Iteration 13060, lr = 0.0002
I0529 02:00:00.713603 10644 solver.cpp:228] Iteration 13080, loss = 0.386967
I0529 02:00:00.713637 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 02:00:00.713649 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322309 (* 1 = 0.0322309 loss)
I0529 02:00:00.713654 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110515 (* 1 = 0.110515 loss)
I0529 02:00:00.713660 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00613495 (* 1 = 0.00613495 loss)
I0529 02:00:00.713666 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00891864 (* 1 = 0.00891864 loss)
I0529 02:00:00.713673 10644 sgd_solver.cpp:106] Iteration 13080, lr = 0.0002
I0529 02:00:49.307426 10644 solver.cpp:228] Iteration 13100, loss = 0.437434
I0529 02:00:49.307456 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 02:00:49.307463 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.151702 (* 1 = 0.151702 loss)
I0529 02:00:49.307467 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255967 (* 1 = 0.255967 loss)
I0529 02:00:49.307471 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245888 (* 1 = 0.0245888 loss)
I0529 02:00:49.307476 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0751892 (* 1 = 0.0751892 loss)
I0529 02:00:49.307482 10644 sgd_solver.cpp:106] Iteration 13100, lr = 0.0002
I0529 02:01:37.886940 10644 solver.cpp:228] Iteration 13120, loss = 0.22353
I0529 02:01:37.886965 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:01:37.886973 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.020496 (* 1 = 0.020496 loss)
I0529 02:01:37.886978 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.176959 (* 1 = 0.176959 loss)
I0529 02:01:37.886981 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0257729 (* 1 = 0.0257729 loss)
I0529 02:01:37.886986 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107992 (* 1 = 0.0107992 loss)
I0529 02:01:37.886991 10644 sgd_solver.cpp:106] Iteration 13120, lr = 0.0002
I0529 02:02:26.440142 10644 solver.cpp:228] Iteration 13140, loss = 0.300893
I0529 02:02:26.440171 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:02:26.440177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0350763 (* 1 = 0.0350763 loss)
I0529 02:02:26.440182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0936959 (* 1 = 0.0936959 loss)
I0529 02:02:26.440186 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314026 (* 1 = 0.00314026 loss)
I0529 02:02:26.440189 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120485 (* 1 = 0.0120485 loss)
I0529 02:02:26.440194 10644 sgd_solver.cpp:106] Iteration 13140, lr = 0.0002
I0529 02:03:14.979791 10644 solver.cpp:228] Iteration 13160, loss = 0.304483
I0529 02:03:14.979820 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0529 02:03:14.979827 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.362216 (* 1 = 0.362216 loss)
I0529 02:03:14.979831 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.625255 (* 1 = 0.625255 loss)
I0529 02:03:14.979836 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130805 (* 1 = 0.0130805 loss)
I0529 02:03:14.979840 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0653889 (* 1 = 0.0653889 loss)
I0529 02:03:14.979846 10644 sgd_solver.cpp:106] Iteration 13160, lr = 0.0002
I0529 02:04:03.536448 10644 solver.cpp:228] Iteration 13180, loss = 0.404035
I0529 02:04:03.536474 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 02:04:03.536480 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.173774 (* 1 = 0.173774 loss)
I0529 02:04:03.536484 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.243747 (* 1 = 0.243747 loss)
I0529 02:04:03.536489 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0608685 (* 1 = 0.0608685 loss)
I0529 02:04:03.536491 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107703 (* 1 = 0.107703 loss)
I0529 02:04:03.536496 10644 sgd_solver.cpp:106] Iteration 13180, lr = 0.0002
speed: 2.430s / iter
I0529 02:04:52.042814 10644 solver.cpp:228] Iteration 13200, loss = 0.374094
I0529 02:04:52.042856 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 02:04:52.042865 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.174242 (* 1 = 0.174242 loss)
I0529 02:04:52.042868 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.239835 (* 1 = 0.239835 loss)
I0529 02:04:52.042872 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00895435 (* 1 = 0.00895435 loss)
I0529 02:04:52.042876 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0615925 (* 1 = 0.0615925 loss)
I0529 02:04:52.042884 10644 sgd_solver.cpp:106] Iteration 13200, lr = 0.0002
I0529 02:05:40.576552 10644 solver.cpp:228] Iteration 13220, loss = 0.269227
I0529 02:05:40.576577 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 02:05:40.576584 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549198 (* 1 = 0.0549198 loss)
I0529 02:05:40.576588 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0733643 (* 1 = 0.0733643 loss)
I0529 02:05:40.576592 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354599 (* 1 = 0.00354599 loss)
I0529 02:05:40.576596 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00339094 (* 1 = 0.00339094 loss)
I0529 02:05:40.576601 10644 sgd_solver.cpp:106] Iteration 13220, lr = 0.0002
I0529 02:06:29.153353 10644 solver.cpp:228] Iteration 13240, loss = 0.546709
I0529 02:06:29.153378 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 02:06:29.153384 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0416167 (* 1 = 0.0416167 loss)
I0529 02:06:29.153388 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.15477 (* 1 = 0.15477 loss)
I0529 02:06:29.153391 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121526 (* 1 = 0.0121526 loss)
I0529 02:06:29.153394 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00724879 (* 1 = 0.00724879 loss)
I0529 02:06:29.153400 10644 sgd_solver.cpp:106] Iteration 13240, lr = 0.0002
I0529 02:07:17.692170 10644 solver.cpp:228] Iteration 13260, loss = 0.268131
I0529 02:07:17.692199 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:07:17.692209 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0883935 (* 1 = 0.0883935 loss)
I0529 02:07:17.692214 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.172733 (* 1 = 0.172733 loss)
I0529 02:07:17.692219 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116288 (* 1 = 0.0116288 loss)
I0529 02:07:17.692225 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144832 (* 1 = 0.0144832 loss)
I0529 02:07:17.692231 10644 sgd_solver.cpp:106] Iteration 13260, lr = 0.0002
I0529 02:08:06.218838 10644 solver.cpp:228] Iteration 13280, loss = 0.385321
I0529 02:08:06.218863 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 02:08:06.218870 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0345009 (* 1 = 0.0345009 loss)
I0529 02:08:06.218874 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157617 (* 1 = 0.157617 loss)
I0529 02:08:06.218878 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00847323 (* 1 = 0.00847323 loss)
I0529 02:08:06.218881 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290465 (* 1 = 0.0290465 loss)
I0529 02:08:06.218886 10644 sgd_solver.cpp:106] Iteration 13280, lr = 0.0002
I0529 02:08:54.762538 10644 solver.cpp:228] Iteration 13300, loss = 0.343883
I0529 02:08:54.762565 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 02:08:54.762573 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.071079 (* 1 = 0.071079 loss)
I0529 02:08:54.762578 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0822035 (* 1 = 0.0822035 loss)
I0529 02:08:54.762581 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221581 (* 1 = 0.00221581 loss)
I0529 02:08:54.762584 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00737645 (* 1 = 0.00737645 loss)
I0529 02:08:54.762590 10644 sgd_solver.cpp:106] Iteration 13300, lr = 0.0002
I0529 02:09:43.309522 10644 solver.cpp:228] Iteration 13320, loss = 0.231172
I0529 02:09:43.309548 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 02:09:43.309556 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0884418 (* 1 = 0.0884418 loss)
I0529 02:09:43.309559 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.229207 (* 1 = 0.229207 loss)
I0529 02:09:43.309563 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0362462 (* 1 = 0.0362462 loss)
I0529 02:09:43.309566 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049193 (* 1 = 0.049193 loss)
I0529 02:09:43.309571 10644 sgd_solver.cpp:106] Iteration 13320, lr = 0.0002
I0529 02:10:31.838630 10644 solver.cpp:228] Iteration 13340, loss = 0.335537
I0529 02:10:31.838655 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 02:10:31.838662 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.125548 (* 1 = 0.125548 loss)
I0529 02:10:31.838666 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.197476 (* 1 = 0.197476 loss)
I0529 02:10:31.838670 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00765975 (* 1 = 0.00765975 loss)
I0529 02:10:31.838675 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318706 (* 1 = 0.0318706 loss)
I0529 02:10:31.838680 10644 sgd_solver.cpp:106] Iteration 13340, lr = 0.0002
I0529 02:11:20.376389 10644 solver.cpp:228] Iteration 13360, loss = 0.309635
I0529 02:11:20.376418 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:11:20.376426 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320411 (* 1 = 0.0320411 loss)
I0529 02:11:20.376430 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0512216 (* 1 = 0.0512216 loss)
I0529 02:11:20.376435 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162244 (* 1 = 0.00162244 loss)
I0529 02:11:20.376438 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142577 (* 1 = 0.0142577 loss)
I0529 02:11:20.376444 10644 sgd_solver.cpp:106] Iteration 13360, lr = 0.0002
I0529 02:12:08.954152 10644 solver.cpp:228] Iteration 13380, loss = 0.344057
I0529 02:12:08.954186 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 02:12:08.954197 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473787 (* 1 = 0.0473787 loss)
I0529 02:12:08.954205 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0809993 (* 1 = 0.0809993 loss)
I0529 02:12:08.954212 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257638 (* 1 = 0.00257638 loss)
I0529 02:12:08.954218 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00364736 (* 1 = 0.00364736 loss)
I0529 02:12:08.954226 10644 sgd_solver.cpp:106] Iteration 13380, lr = 0.0002
speed: 2.430s / iter
I0529 02:12:57.495331 10644 solver.cpp:228] Iteration 13400, loss = 0.320149
I0529 02:12:57.495357 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 02:12:57.495365 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.146352 (* 1 = 0.146352 loss)
I0529 02:12:57.495369 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.17617 (* 1 = 0.17617 loss)
I0529 02:12:57.495373 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140988 (* 1 = 0.0140988 loss)
I0529 02:12:57.495378 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025764 (* 1 = 0.025764 loss)
I0529 02:12:57.495383 10644 sgd_solver.cpp:106] Iteration 13400, lr = 0.0002
I0529 02:13:46.013478 10644 solver.cpp:228] Iteration 13420, loss = 0.327469
I0529 02:13:46.013504 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 02:13:46.013511 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114744 (* 1 = 0.114744 loss)
I0529 02:13:46.013515 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.239654 (* 1 = 0.239654 loss)
I0529 02:13:46.013520 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294503 (* 1 = 0.0294503 loss)
I0529 02:13:46.013522 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117536 (* 1 = 0.117536 loss)
I0529 02:13:46.013528 10644 sgd_solver.cpp:106] Iteration 13420, lr = 0.0002
I0529 02:14:34.540168 10644 solver.cpp:228] Iteration 13440, loss = 0.205486
I0529 02:14:34.540195 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 02:14:34.540204 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201411 (* 1 = 0.0201411 loss)
I0529 02:14:34.540207 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.126893 (* 1 = 0.126893 loss)
I0529 02:14:34.540211 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0087581 (* 1 = 0.0087581 loss)
I0529 02:14:34.540215 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0076607 (* 1 = 0.0076607 loss)
I0529 02:14:34.540221 10644 sgd_solver.cpp:106] Iteration 13440, lr = 0.0002
I0529 02:15:23.109027 10644 solver.cpp:228] Iteration 13460, loss = 0.386895
I0529 02:15:23.109066 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 02:15:23.109077 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.184104 (* 1 = 0.184104 loss)
I0529 02:15:23.109084 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.199234 (* 1 = 0.199234 loss)
I0529 02:15:23.109091 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00899717 (* 1 = 0.00899717 loss)
I0529 02:15:23.109095 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0625284 (* 1 = 0.0625284 loss)
I0529 02:15:23.109105 10644 sgd_solver.cpp:106] Iteration 13460, lr = 0.0002
I0529 02:16:11.651296 10644 solver.cpp:228] Iteration 13480, loss = 0.3528
I0529 02:16:11.651324 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 02:16:11.651331 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393543 (* 1 = 0.0393543 loss)
I0529 02:16:11.651335 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150863 (* 1 = 0.150863 loss)
I0529 02:16:11.651340 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026582 (* 1 = 0.026582 loss)
I0529 02:16:11.651343 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214094 (* 1 = 0.0214094 loss)
I0529 02:16:11.651347 10644 sgd_solver.cpp:106] Iteration 13480, lr = 0.0002
I0529 02:17:00.205687 10644 solver.cpp:228] Iteration 13500, loss = 0.290804
I0529 02:17:00.205710 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 02:17:00.205716 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.174289 (* 1 = 0.174289 loss)
I0529 02:17:00.205720 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.273943 (* 1 = 0.273943 loss)
I0529 02:17:00.205724 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203742 (* 1 = 0.0203742 loss)
I0529 02:17:00.205727 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0363348 (* 1 = 0.0363348 loss)
I0529 02:17:00.205732 10644 sgd_solver.cpp:106] Iteration 13500, lr = 0.0002
I0529 02:17:48.737926 10644 solver.cpp:228] Iteration 13520, loss = 0.167504
I0529 02:17:48.737951 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:17:48.737960 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475756 (* 1 = 0.0475756 loss)
I0529 02:17:48.737965 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.042077 (* 1 = 0.042077 loss)
I0529 02:17:48.737972 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028271 (* 1 = 0.0028271 loss)
I0529 02:17:48.737977 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274079 (* 1 = 0.0274079 loss)
I0529 02:17:48.737982 10644 sgd_solver.cpp:106] Iteration 13520, lr = 0.0002
I0529 02:18:37.288990 10644 solver.cpp:228] Iteration 13540, loss = 0.332383
I0529 02:18:37.289018 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 02:18:37.289027 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.124725 (* 1 = 0.124725 loss)
I0529 02:18:37.289033 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.244686 (* 1 = 0.244686 loss)
I0529 02:18:37.289038 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011217 (* 1 = 0.011217 loss)
I0529 02:18:37.289044 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272356 (* 1 = 0.0272356 loss)
I0529 02:18:37.289050 10644 sgd_solver.cpp:106] Iteration 13540, lr = 0.0002
I0529 02:19:25.846983 10644 solver.cpp:228] Iteration 13560, loss = 0.265052
I0529 02:19:25.847009 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:19:25.847017 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.041068 (* 1 = 0.041068 loss)
I0529 02:19:25.847020 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0894877 (* 1 = 0.0894877 loss)
I0529 02:19:25.847024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228687 (* 1 = 0.00228687 loss)
I0529 02:19:25.847028 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113347 (* 1 = 0.0113347 loss)
I0529 02:19:25.847033 10644 sgd_solver.cpp:106] Iteration 13560, lr = 0.0002
I0529 02:20:14.389334 10644 solver.cpp:228] Iteration 13580, loss = 0.461378
I0529 02:20:14.389362 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 02:20:14.389371 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.15806 (* 1 = 0.15806 loss)
I0529 02:20:14.389377 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.250203 (* 1 = 0.250203 loss)
I0529 02:20:14.389382 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378326 (* 1 = 0.0378326 loss)
I0529 02:20:14.389389 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351351 (* 1 = 0.0351351 loss)
I0529 02:20:14.389394 10644 sgd_solver.cpp:106] Iteration 13580, lr = 0.0002
speed: 2.430s / iter
I0529 02:21:02.916223 10644 solver.cpp:228] Iteration 13600, loss = 0.287403
I0529 02:21:02.916249 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:21:02.916258 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485845 (* 1 = 0.0485845 loss)
I0529 02:21:02.916265 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0906288 (* 1 = 0.0906288 loss)
I0529 02:21:02.916270 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00470773 (* 1 = 0.00470773 loss)
I0529 02:21:02.916275 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00667083 (* 1 = 0.00667083 loss)
I0529 02:21:02.916282 10644 sgd_solver.cpp:106] Iteration 13600, lr = 0.0002
I0529 02:21:51.444135 10644 solver.cpp:228] Iteration 13620, loss = 0.246089
I0529 02:21:51.444160 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:21:51.444169 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293516 (* 1 = 0.0293516 loss)
I0529 02:21:51.444176 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109709 (* 1 = 0.109709 loss)
I0529 02:21:51.444181 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140555 (* 1 = 0.0140555 loss)
I0529 02:21:51.444186 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110772 (* 1 = 0.0110772 loss)
I0529 02:21:51.444192 10644 sgd_solver.cpp:106] Iteration 13620, lr = 0.0002
I0529 02:22:39.980787 10644 solver.cpp:228] Iteration 13640, loss = 0.320972
I0529 02:22:39.980813 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 02:22:39.980819 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0828177 (* 1 = 0.0828177 loss)
I0529 02:22:39.980823 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128493 (* 1 = 0.128493 loss)
I0529 02:22:39.980828 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00973583 (* 1 = 0.00973583 loss)
I0529 02:22:39.980830 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112265 (* 1 = 0.0112265 loss)
I0529 02:22:39.980835 10644 sgd_solver.cpp:106] Iteration 13640, lr = 0.0002
I0529 02:23:28.543658 10644 solver.cpp:228] Iteration 13660, loss = 0.30774
I0529 02:23:28.543685 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 02:23:28.543692 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0635052 (* 1 = 0.0635052 loss)
I0529 02:23:28.543696 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.094196 (* 1 = 0.094196 loss)
I0529 02:23:28.543699 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026938 (* 1 = 0.026938 loss)
I0529 02:23:28.543704 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172105 (* 1 = 0.0172105 loss)
I0529 02:23:28.543709 10644 sgd_solver.cpp:106] Iteration 13660, lr = 0.0002
I0529 02:24:17.099161 10644 solver.cpp:228] Iteration 13680, loss = 0.363744
I0529 02:24:17.099190 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 02:24:17.099198 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0922396 (* 1 = 0.0922396 loss)
I0529 02:24:17.099202 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.273265 (* 1 = 0.273265 loss)
I0529 02:24:17.099206 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00792792 (* 1 = 0.00792792 loss)
I0529 02:24:17.099210 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242967 (* 1 = 0.0242967 loss)
I0529 02:24:17.099216 10644 sgd_solver.cpp:106] Iteration 13680, lr = 0.0002
I0529 02:25:05.627321 10644 solver.cpp:228] Iteration 13700, loss = 0.21247
I0529 02:25:05.627346 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:25:05.627352 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0684526 (* 1 = 0.0684526 loss)
I0529 02:25:05.627357 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160667 (* 1 = 0.160667 loss)
I0529 02:25:05.627360 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00970029 (* 1 = 0.00970029 loss)
I0529 02:25:05.627363 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218551 (* 1 = 0.0218551 loss)
I0529 02:25:05.627368 10644 sgd_solver.cpp:106] Iteration 13700, lr = 0.0002
I0529 02:25:54.152860 10644 solver.cpp:228] Iteration 13720, loss = 0.229166
I0529 02:25:54.152886 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:25:54.152894 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0277582 (* 1 = 0.0277582 loss)
I0529 02:25:54.152897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0499477 (* 1 = 0.0499477 loss)
I0529 02:25:54.152901 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233237 (* 1 = 0.00233237 loss)
I0529 02:25:54.152905 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0048725 (* 1 = 0.0048725 loss)
I0529 02:25:54.152914 10644 sgd_solver.cpp:106] Iteration 13720, lr = 0.0002
I0529 02:26:42.701010 10644 solver.cpp:228] Iteration 13740, loss = 0.540437
I0529 02:26:42.701037 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 02:26:42.701045 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.127723 (* 1 = 0.127723 loss)
I0529 02:26:42.701048 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.295303 (* 1 = 0.295303 loss)
I0529 02:26:42.701051 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252849 (* 1 = 0.0252849 loss)
I0529 02:26:42.701056 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0673025 (* 1 = 0.0673025 loss)
I0529 02:26:42.701061 10644 sgd_solver.cpp:106] Iteration 13740, lr = 0.0002
I0529 02:27:31.241482 10644 solver.cpp:228] Iteration 13760, loss = 0.33553
I0529 02:27:31.241508 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 02:27:31.241514 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475558 (* 1 = 0.0475558 loss)
I0529 02:27:31.241518 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109017 (* 1 = 0.109017 loss)
I0529 02:27:31.241521 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0097025 (* 1 = 0.0097025 loss)
I0529 02:27:31.241524 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0469766 (* 1 = 0.0469766 loss)
I0529 02:27:31.241530 10644 sgd_solver.cpp:106] Iteration 13760, lr = 0.0002
I0529 02:28:19.787479 10644 solver.cpp:228] Iteration 13780, loss = 0.511622
I0529 02:28:19.787504 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:28:19.787511 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00205663 (* 1 = 0.00205663 loss)
I0529 02:28:19.787515 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0763338 (* 1 = 0.0763338 loss)
I0529 02:28:19.787519 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00371248 (* 1 = 0.00371248 loss)
I0529 02:28:19.787523 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197551 (* 1 = 0.0197551 loss)
I0529 02:28:19.787528 10644 sgd_solver.cpp:106] Iteration 13780, lr = 0.0002
speed: 2.430s / iter
I0529 02:29:08.342205 10644 solver.cpp:228] Iteration 13800, loss = 0.553526
I0529 02:29:08.342232 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:29:08.342239 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.108324 (* 1 = 0.108324 loss)
I0529 02:29:08.342243 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134174 (* 1 = 0.134174 loss)
I0529 02:29:08.342247 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00463005 (* 1 = 0.00463005 loss)
I0529 02:29:08.342252 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.009676 (* 1 = 0.009676 loss)
I0529 02:29:08.342257 10644 sgd_solver.cpp:106] Iteration 13800, lr = 0.0002
I0529 02:29:56.867660 10644 solver.cpp:228] Iteration 13820, loss = 0.306346
I0529 02:29:56.867684 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:29:56.867692 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511818 (* 1 = 0.0511818 loss)
I0529 02:29:56.867696 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0871059 (* 1 = 0.0871059 loss)
I0529 02:29:56.867699 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00549757 (* 1 = 0.00549757 loss)
I0529 02:29:56.867703 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100601 (* 1 = 0.0100601 loss)
I0529 02:29:56.867707 10644 sgd_solver.cpp:106] Iteration 13820, lr = 0.0002
I0529 02:30:45.399053 10644 solver.cpp:228] Iteration 13840, loss = 0.372633
I0529 02:30:45.399085 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:30:45.399096 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0431736 (* 1 = 0.0431736 loss)
I0529 02:30:45.399103 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0791852 (* 1 = 0.0791852 loss)
I0529 02:30:45.399109 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604655 (* 1 = 0.00604655 loss)
I0529 02:30:45.399116 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115932 (* 1 = 0.0115932 loss)
I0529 02:30:45.399123 10644 sgd_solver.cpp:106] Iteration 13840, lr = 0.0002
I0529 02:31:33.963461 10644 solver.cpp:228] Iteration 13860, loss = 0.254381
I0529 02:31:33.963486 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:31:33.963495 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251824 (* 1 = 0.0251824 loss)
I0529 02:31:33.963498 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0746173 (* 1 = 0.0746173 loss)
I0529 02:31:33.963502 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105057 (* 1 = 0.0105057 loss)
I0529 02:31:33.963506 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00861071 (* 1 = 0.00861071 loss)
I0529 02:31:33.963512 10644 sgd_solver.cpp:106] Iteration 13860, lr = 0.0002
I0529 02:32:22.511567 10644 solver.cpp:228] Iteration 13880, loss = 0.319895
I0529 02:32:22.511592 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 02:32:22.511600 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.110792 (* 1 = 0.110792 loss)
I0529 02:32:22.511606 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142025 (* 1 = 0.142025 loss)
I0529 02:32:22.511613 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00635617 (* 1 = 0.00635617 loss)
I0529 02:32:22.511618 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0299465 (* 1 = 0.0299465 loss)
I0529 02:32:22.511624 10644 sgd_solver.cpp:106] Iteration 13880, lr = 0.0002
I0529 02:33:11.069663 10644 solver.cpp:228] Iteration 13900, loss = 0.315684
I0529 02:33:11.069691 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0529 02:33:11.069699 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.398728 (* 1 = 0.398728 loss)
I0529 02:33:11.069702 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.461168 (* 1 = 0.461168 loss)
I0529 02:33:11.069706 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186729 (* 1 = 0.0186729 loss)
I0529 02:33:11.069710 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106016 (* 1 = 0.106016 loss)
I0529 02:33:11.069715 10644 sgd_solver.cpp:106] Iteration 13900, lr = 0.0002
I0529 02:33:59.623612 10644 solver.cpp:228] Iteration 13920, loss = 0.435895
I0529 02:33:59.623775 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 02:33:59.623836 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0793323 (* 1 = 0.0793323 loss)
I0529 02:33:59.623890 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.194355 (* 1 = 0.194355 loss)
I0529 02:33:59.623945 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0220298 (* 1 = 0.0220298 loss)
I0529 02:33:59.623984 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283737 (* 1 = 0.0283737 loss)
I0529 02:33:59.624003 10644 sgd_solver.cpp:106] Iteration 13920, lr = 0.0002
I0529 02:34:48.180022 10644 solver.cpp:228] Iteration 13940, loss = 0.262904
I0529 02:34:48.180047 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:34:48.180055 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.027367 (* 1 = 0.027367 loss)
I0529 02:34:48.180063 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0749971 (* 1 = 0.0749971 loss)
I0529 02:34:48.180068 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127831 (* 1 = 0.0127831 loss)
I0529 02:34:48.180074 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180568 (* 1 = 0.0180568 loss)
I0529 02:34:48.180080 10644 sgd_solver.cpp:106] Iteration 13940, lr = 0.0002
I0529 02:35:36.726289 10644 solver.cpp:228] Iteration 13960, loss = 0.432931
I0529 02:35:36.726316 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:35:36.726326 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533202 (* 1 = 0.0533202 loss)
I0529 02:35:36.726332 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120868 (* 1 = 0.120868 loss)
I0529 02:35:36.726339 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183968 (* 1 = 0.0183968 loss)
I0529 02:35:36.726344 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309012 (* 1 = 0.0309012 loss)
I0529 02:35:36.726352 10644 sgd_solver.cpp:106] Iteration 13960, lr = 0.0002
I0529 02:36:25.270146 10644 solver.cpp:228] Iteration 13980, loss = 0.294021
I0529 02:36:25.270175 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:36:25.270184 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.103017 (* 1 = 0.103017 loss)
I0529 02:36:25.270187 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.146798 (* 1 = 0.146798 loss)
I0529 02:36:25.270191 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692503 (* 1 = 0.00692503 loss)
I0529 02:36:25.270195 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136831 (* 1 = 0.0136831 loss)
I0529 02:36:25.270201 10644 sgd_solver.cpp:106] Iteration 13980, lr = 0.0002
speed: 2.430s / iter
I0529 02:37:13.826602 10644 solver.cpp:228] Iteration 14000, loss = 0.285599
I0529 02:37:13.826632 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 02:37:13.826638 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.155499 (* 1 = 0.155499 loss)
I0529 02:37:13.826642 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.196405 (* 1 = 0.196405 loss)
I0529 02:37:13.826647 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0049204 (* 1 = 0.0049204 loss)
I0529 02:37:13.826649 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361349 (* 1 = 0.0361349 loss)
I0529 02:37:13.826654 10644 sgd_solver.cpp:106] Iteration 14000, lr = 0.0002
I0529 02:38:02.404671 10644 solver.cpp:228] Iteration 14020, loss = 0.357209
I0529 02:38:02.404695 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 02:38:02.404703 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0962393 (* 1 = 0.0962393 loss)
I0529 02:38:02.404707 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.173413 (* 1 = 0.173413 loss)
I0529 02:38:02.404711 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0230167 (* 1 = 0.0230167 loss)
I0529 02:38:02.404713 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0769233 (* 1 = 0.0769233 loss)
I0529 02:38:02.404718 10644 sgd_solver.cpp:106] Iteration 14020, lr = 0.0002
I0529 02:38:50.964102 10644 solver.cpp:228] Iteration 14040, loss = 0.197715
I0529 02:38:50.964128 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 02:38:50.964136 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118168 (* 1 = 0.118168 loss)
I0529 02:38:50.964139 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0893742 (* 1 = 0.0893742 loss)
I0529 02:38:50.964143 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.029913 (* 1 = 0.029913 loss)
I0529 02:38:50.964146 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563484 (* 1 = 0.0563484 loss)
I0529 02:38:50.964151 10644 sgd_solver.cpp:106] Iteration 14040, lr = 0.0002
I0529 02:39:39.513618 10644 solver.cpp:228] Iteration 14060, loss = 0.365307
I0529 02:39:39.513653 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0529 02:39:39.513660 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.311784 (* 1 = 0.311784 loss)
I0529 02:39:39.513666 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.41772 (* 1 = 0.41772 loss)
I0529 02:39:39.513671 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0858855 (* 1 = 0.0858855 loss)
I0529 02:39:39.513676 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0830955 (* 1 = 0.0830955 loss)
I0529 02:39:39.513684 10644 sgd_solver.cpp:106] Iteration 14060, lr = 0.0002
I0529 02:40:28.073334 10644 solver.cpp:228] Iteration 14080, loss = 0.281159
I0529 02:40:28.073376 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 02:40:28.073385 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108063 (* 1 = 0.0108063 loss)
I0529 02:40:28.073390 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108095 (* 1 = 0.108095 loss)
I0529 02:40:28.073393 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00702681 (* 1 = 0.00702681 loss)
I0529 02:40:28.073396 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00511251 (* 1 = 0.00511251 loss)
I0529 02:40:28.073405 10644 sgd_solver.cpp:106] Iteration 14080, lr = 0.0002
I0529 02:41:16.608170 10644 solver.cpp:228] Iteration 14100, loss = 0.259397
I0529 02:41:16.608196 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 02:41:16.608202 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0695463 (* 1 = 0.0695463 loss)
I0529 02:41:16.608207 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.111965 (* 1 = 0.111965 loss)
I0529 02:41:16.608211 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00278243 (* 1 = 0.00278243 loss)
I0529 02:41:16.608214 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114613 (* 1 = 0.0114613 loss)
I0529 02:41:16.608219 10644 sgd_solver.cpp:106] Iteration 14100, lr = 0.0002
I0529 02:42:05.166982 10644 solver.cpp:228] Iteration 14120, loss = 0.235498
I0529 02:42:05.167009 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 02:42:05.167016 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392509 (* 1 = 0.0392509 loss)
I0529 02:42:05.167021 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.179037 (* 1 = 0.179037 loss)
I0529 02:42:05.167024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00802987 (* 1 = 0.00802987 loss)
I0529 02:42:05.167027 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00984689 (* 1 = 0.00984689 loss)
I0529 02:42:05.167032 10644 sgd_solver.cpp:106] Iteration 14120, lr = 0.0002
I0529 02:42:53.733542 10644 solver.cpp:228] Iteration 14140, loss = 0.296005
I0529 02:42:53.733570 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 02:42:53.733578 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0021753 (* 1 = 0.0021753 loss)
I0529 02:42:53.733583 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.044154 (* 1 = 0.044154 loss)
I0529 02:42:53.733587 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184901 (* 1 = 0.0184901 loss)
I0529 02:42:53.733590 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144744 (* 1 = 0.0144744 loss)
I0529 02:42:53.733595 10644 sgd_solver.cpp:106] Iteration 14140, lr = 0.0002
I0529 02:43:42.313381 10644 solver.cpp:228] Iteration 14160, loss = 0.276162
I0529 02:43:42.313408 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 02:43:42.313416 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268549 (* 1 = 0.0268549 loss)
I0529 02:43:42.313421 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0591966 (* 1 = 0.0591966 loss)
I0529 02:43:42.313424 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00608305 (* 1 = 0.00608305 loss)
I0529 02:43:42.313428 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111272 (* 1 = 0.0111272 loss)
I0529 02:43:42.313433 10644 sgd_solver.cpp:106] Iteration 14160, lr = 0.0002
I0529 02:44:30.853582 10644 solver.cpp:228] Iteration 14180, loss = 0.219634
I0529 02:44:30.853612 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 02:44:30.853621 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0698858 (* 1 = 0.0698858 loss)
I0529 02:44:30.853626 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.143589 (* 1 = 0.143589 loss)
I0529 02:44:30.853631 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00357254 (* 1 = 0.00357254 loss)
I0529 02:44:30.853633 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00482476 (* 1 = 0.00482476 loss)
I0529 02:44:30.853639 10644 sgd_solver.cpp:106] Iteration 14180, lr = 0.0002
speed: 2.430s / iter
I0529 02:45:19.374023 10644 solver.cpp:228] Iteration 14200, loss = 0.279978
I0529 02:45:19.374052 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 02:45:19.374058 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0354353 (* 1 = 0.0354353 loss)
I0529 02:45:19.374063 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0498545 (* 1 = 0.0498545 loss)
I0529 02:45:19.374068 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508558 (* 1 = 0.00508558 loss)
I0529 02:45:19.374071 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00870842 (* 1 = 0.00870842 loss)
I0529 02:45:19.374078 10644 sgd_solver.cpp:106] Iteration 14200, lr = 0.0002
I0529 02:46:07.953678 10644 solver.cpp:228] Iteration 14220, loss = 0.298903
I0529 02:46:07.953706 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:46:07.953714 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224071 (* 1 = 0.0224071 loss)
I0529 02:46:07.953718 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0831824 (* 1 = 0.0831824 loss)
I0529 02:46:07.953724 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484364 (* 1 = 0.00484364 loss)
I0529 02:46:07.953732 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00291246 (* 1 = 0.00291246 loss)
I0529 02:46:07.953738 10644 sgd_solver.cpp:106] Iteration 14220, lr = 0.0002
I0529 02:46:56.482177 10644 solver.cpp:228] Iteration 14240, loss = 0.412647
I0529 02:46:56.482203 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0529 02:46:56.482210 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.480984 (* 1 = 0.480984 loss)
I0529 02:46:56.482215 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.593747 (* 1 = 0.593747 loss)
I0529 02:46:56.482218 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030152 (* 1 = 0.030152 loss)
I0529 02:46:56.482223 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120643 (* 1 = 0.120643 loss)
I0529 02:46:56.482228 10644 sgd_solver.cpp:106] Iteration 14240, lr = 0.0002
I0529 02:47:45.020223 10644 solver.cpp:228] Iteration 14260, loss = 0.369142
I0529 02:47:45.020251 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 02:47:45.020262 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.053604 (* 1 = 0.053604 loss)
I0529 02:47:45.020268 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0435781 (* 1 = 0.0435781 loss)
I0529 02:47:45.020274 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00657712 (* 1 = 0.00657712 loss)
I0529 02:47:45.020279 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103451 (* 1 = 0.0103451 loss)
I0529 02:47:45.020287 10644 sgd_solver.cpp:106] Iteration 14260, lr = 0.0002
I0529 02:48:33.581190 10644 solver.cpp:228] Iteration 14280, loss = 0.217198
I0529 02:48:33.581218 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 02:48:33.581228 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0577978 (* 1 = 0.0577978 loss)
I0529 02:48:33.581234 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0732507 (* 1 = 0.0732507 loss)
I0529 02:48:33.581241 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00902316 (* 1 = 0.00902316 loss)
I0529 02:48:33.581246 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00737456 (* 1 = 0.00737456 loss)
I0529 02:48:33.581254 10644 sgd_solver.cpp:106] Iteration 14280, lr = 0.0002
I0529 02:49:22.124258 10644 solver.cpp:228] Iteration 14300, loss = 0.450237
I0529 02:49:22.124284 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 02:49:22.124290 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.212981 (* 1 = 0.212981 loss)
I0529 02:49:22.124294 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.333054 (* 1 = 0.333054 loss)
I0529 02:49:22.124297 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0559644 (* 1 = 0.0559644 loss)
I0529 02:49:22.124300 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0623151 (* 1 = 0.0623151 loss)
I0529 02:49:22.124305 10644 sgd_solver.cpp:106] Iteration 14300, lr = 0.0002
I0529 02:50:10.671265 10644 solver.cpp:228] Iteration 14320, loss = 0.176032
I0529 02:50:10.671294 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 02:50:10.671303 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00103868 (* 1 = 0.00103868 loss)
I0529 02:50:10.671306 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0231699 (* 1 = 0.0231699 loss)
I0529 02:50:10.671310 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00693868 (* 1 = 0.00693868 loss)
I0529 02:50:10.671314 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346658 (* 1 = 0.0346658 loss)
I0529 02:50:10.671319 10644 sgd_solver.cpp:106] Iteration 14320, lr = 0.0002
I0529 02:50:59.208966 10644 solver.cpp:228] Iteration 14340, loss = 0.450624
I0529 02:50:59.208993 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:50:59.209000 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0678257 (* 1 = 0.0678257 loss)
I0529 02:50:59.209004 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.054638 (* 1 = 0.054638 loss)
I0529 02:50:59.209007 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126208 (* 1 = 0.0126208 loss)
I0529 02:50:59.209012 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00903325 (* 1 = 0.00903325 loss)
I0529 02:50:59.209017 10644 sgd_solver.cpp:106] Iteration 14340, lr = 0.0002
I0529 02:51:47.767177 10644 solver.cpp:228] Iteration 14360, loss = 0.221532
I0529 02:51:47.767216 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 02:51:47.767225 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0927349 (* 1 = 0.0927349 loss)
I0529 02:51:47.767228 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.225603 (* 1 = 0.225603 loss)
I0529 02:51:47.767233 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00564621 (* 1 = 0.00564621 loss)
I0529 02:51:47.767237 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275157 (* 1 = 0.0275157 loss)
I0529 02:51:47.767244 10644 sgd_solver.cpp:106] Iteration 14360, lr = 0.0002
I0529 02:52:36.315027 10644 solver.cpp:228] Iteration 14380, loss = 0.218677
I0529 02:52:36.315055 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:52:36.315062 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0143359 (* 1 = 0.0143359 loss)
I0529 02:52:36.315068 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0657916 (* 1 = 0.0657916 loss)
I0529 02:52:36.315070 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.007975 (* 1 = 0.007975 loss)
I0529 02:52:36.315075 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255114 (* 1 = 0.0255114 loss)
I0529 02:52:36.315081 10644 sgd_solver.cpp:106] Iteration 14380, lr = 0.0002
speed: 2.430s / iter
I0529 02:53:24.864856 10644 solver.cpp:228] Iteration 14400, loss = 0.307336
I0529 02:53:24.864883 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 02:53:24.864892 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00141761 (* 1 = 0.00141761 loss)
I0529 02:53:24.864897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0315252 (* 1 = 0.0315252 loss)
I0529 02:53:24.864899 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0360477 (* 1 = 0.0360477 loss)
I0529 02:53:24.864903 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00526953 (* 1 = 0.00526953 loss)
I0529 02:53:24.864908 10644 sgd_solver.cpp:106] Iteration 14400, lr = 0.0002
I0529 02:54:13.400256 10644 solver.cpp:228] Iteration 14420, loss = 0.469775
I0529 02:54:13.400283 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0529 02:54:13.400291 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.398872 (* 1 = 0.398872 loss)
I0529 02:54:13.400295 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.941535 (* 1 = 0.941535 loss)
I0529 02:54:13.400300 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263816 (* 1 = 0.0263816 loss)
I0529 02:54:13.400303 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0703618 (* 1 = 0.0703618 loss)
I0529 02:54:13.400308 10644 sgd_solver.cpp:106] Iteration 14420, lr = 0.0002
I0529 02:55:01.933311 10644 solver.cpp:228] Iteration 14440, loss = 0.406457
I0529 02:55:01.933337 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 02:55:01.933346 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0970759 (* 1 = 0.0970759 loss)
I0529 02:55:01.933349 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.13754 (* 1 = 0.13754 loss)
I0529 02:55:01.933353 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145698 (* 1 = 0.0145698 loss)
I0529 02:55:01.933357 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281415 (* 1 = 0.0281415 loss)
I0529 02:55:01.933362 10644 sgd_solver.cpp:106] Iteration 14440, lr = 0.0002
I0529 02:55:50.440523 10644 solver.cpp:228] Iteration 14460, loss = 0.352137
I0529 02:55:50.440552 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 02:55:50.440559 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0896304 (* 1 = 0.0896304 loss)
I0529 02:55:50.440563 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.209073 (* 1 = 0.209073 loss)
I0529 02:55:50.440567 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153123 (* 1 = 0.0153123 loss)
I0529 02:55:50.440570 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0462516 (* 1 = 0.0462516 loss)
I0529 02:55:50.440575 10644 sgd_solver.cpp:106] Iteration 14460, lr = 0.0002
I0529 02:56:38.964767 10644 solver.cpp:228] Iteration 14480, loss = 0.318741
I0529 02:56:38.964793 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:56:38.964802 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0149532 (* 1 = 0.0149532 loss)
I0529 02:56:38.964805 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.076631 (* 1 = 0.076631 loss)
I0529 02:56:38.964809 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00456718 (* 1 = 0.00456718 loss)
I0529 02:56:38.964812 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118912 (* 1 = 0.0118912 loss)
I0529 02:56:38.964818 10644 sgd_solver.cpp:106] Iteration 14480, lr = 0.0002
I0529 02:57:27.527257 10644 solver.cpp:228] Iteration 14500, loss = 0.237653
I0529 02:57:27.527287 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 02:57:27.527297 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0617801 (* 1 = 0.0617801 loss)
I0529 02:57:27.527302 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115025 (* 1 = 0.115025 loss)
I0529 02:57:27.527308 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00569136 (* 1 = 0.00569136 loss)
I0529 02:57:27.527313 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106401 (* 1 = 0.0106401 loss)
I0529 02:57:27.527321 10644 sgd_solver.cpp:106] Iteration 14500, lr = 0.0002
I0529 02:58:16.059201 10644 solver.cpp:228] Iteration 14520, loss = 0.384225
I0529 02:58:16.059226 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 02:58:16.059232 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.129121 (* 1 = 0.129121 loss)
I0529 02:58:16.059237 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.154591 (* 1 = 0.154591 loss)
I0529 02:58:16.059240 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213072 (* 1 = 0.00213072 loss)
I0529 02:58:16.059243 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135045 (* 1 = 0.0135045 loss)
I0529 02:58:16.059248 10644 sgd_solver.cpp:106] Iteration 14520, lr = 0.0002
I0529 02:59:04.598012 10644 solver.cpp:228] Iteration 14540, loss = 0.426744
I0529 02:59:04.598045 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 02:59:04.598057 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443339 (* 1 = 0.0443339 loss)
I0529 02:59:04.598063 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0506325 (* 1 = 0.0506325 loss)
I0529 02:59:04.598070 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00129565 (* 1 = 0.00129565 loss)
I0529 02:59:04.598078 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00198029 (* 1 = 0.00198029 loss)
I0529 02:59:04.598085 10644 sgd_solver.cpp:106] Iteration 14540, lr = 0.0002
I0529 02:59:53.159484 10644 solver.cpp:228] Iteration 14560, loss = 0.307093
I0529 02:59:53.159508 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 02:59:53.159517 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113694 (* 1 = 0.0113694 loss)
I0529 02:59:53.159520 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0664316 (* 1 = 0.0664316 loss)
I0529 02:59:53.159524 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00379885 (* 1 = 0.00379885 loss)
I0529 02:59:53.159528 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00495323 (* 1 = 0.00495323 loss)
I0529 02:59:53.159533 10644 sgd_solver.cpp:106] Iteration 14560, lr = 0.0002
I0529 03:00:41.684625 10644 solver.cpp:228] Iteration 14580, loss = 0.219004
I0529 03:00:41.684653 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:00:41.684664 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00036774 (* 1 = 0.00036774 loss)
I0529 03:00:41.684670 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0594657 (* 1 = 0.0594657 loss)
I0529 03:00:41.684677 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171119 (* 1 = 0.0171119 loss)
I0529 03:00:41.684682 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018785 (* 1 = 0.018785 loss)
I0529 03:00:41.684689 10644 sgd_solver.cpp:106] Iteration 14580, lr = 0.0002
speed: 2.429s / iter
I0529 03:01:30.213680 10644 solver.cpp:228] Iteration 14600, loss = 0.40977
I0529 03:01:30.213707 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 03:01:30.213716 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.313398 (* 1 = 0.313398 loss)
I0529 03:01:30.213719 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.374551 (* 1 = 0.374551 loss)
I0529 03:01:30.213723 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00835138 (* 1 = 0.00835138 loss)
I0529 03:01:30.213727 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0389344 (* 1 = 0.0389344 loss)
I0529 03:01:30.213732 10644 sgd_solver.cpp:106] Iteration 14600, lr = 0.0002
I0529 03:02:18.744830 10644 solver.cpp:228] Iteration 14620, loss = 0.599905
I0529 03:02:18.744860 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0529 03:02:18.744868 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.349471 (* 1 = 0.349471 loss)
I0529 03:02:18.744874 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.615554 (* 1 = 0.615554 loss)
I0529 03:02:18.744879 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204918 (* 1 = 0.0204918 loss)
I0529 03:02:18.744885 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.172465 (* 1 = 0.172465 loss)
I0529 03:02:18.744891 10644 sgd_solver.cpp:106] Iteration 14620, lr = 0.0002
I0529 03:03:07.310652 10644 solver.cpp:228] Iteration 14640, loss = 0.262613
I0529 03:03:07.310679 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 03:03:07.310688 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0304542 (* 1 = 0.0304542 loss)
I0529 03:03:07.310691 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.127561 (* 1 = 0.127561 loss)
I0529 03:03:07.310695 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014579 (* 1 = 0.014579 loss)
I0529 03:03:07.310699 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00324284 (* 1 = 0.00324284 loss)
I0529 03:03:07.310705 10644 sgd_solver.cpp:106] Iteration 14640, lr = 0.0002
I0529 03:03:55.861429 10644 solver.cpp:228] Iteration 14660, loss = 0.330495
I0529 03:03:55.861459 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 03:03:55.861469 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627156 (* 1 = 0.0627156 loss)
I0529 03:03:55.861476 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.29093 (* 1 = 0.29093 loss)
I0529 03:03:55.861482 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0315688 (* 1 = 0.0315688 loss)
I0529 03:03:55.861488 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024334 (* 1 = 0.024334 loss)
I0529 03:03:55.861495 10644 sgd_solver.cpp:106] Iteration 14660, lr = 0.0002
I0529 03:04:44.410518 10644 solver.cpp:228] Iteration 14680, loss = 0.334114
I0529 03:04:44.410544 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 03:04:44.410552 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.17069 (* 1 = 0.17069 loss)
I0529 03:04:44.410557 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.208131 (* 1 = 0.208131 loss)
I0529 03:04:44.410560 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133931 (* 1 = 0.0133931 loss)
I0529 03:04:44.410564 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030654 (* 1 = 0.030654 loss)
I0529 03:04:44.410569 10644 sgd_solver.cpp:106] Iteration 14680, lr = 0.0002
I0529 03:05:32.975378 10644 solver.cpp:228] Iteration 14700, loss = 0.322506
I0529 03:05:32.975405 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 03:05:32.975415 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0643761 (* 1 = 0.0643761 loss)
I0529 03:05:32.975422 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145722 (* 1 = 0.145722 loss)
I0529 03:05:32.975428 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385769 (* 1 = 0.00385769 loss)
I0529 03:05:32.975435 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110736 (* 1 = 0.0110736 loss)
I0529 03:05:32.975441 10644 sgd_solver.cpp:106] Iteration 14700, lr = 0.0002
I0529 03:06:21.535660 10644 solver.cpp:228] Iteration 14720, loss = 0.49066
I0529 03:06:21.535686 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 03:06:21.535696 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758747 (* 1 = 0.0758747 loss)
I0529 03:06:21.535703 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.17237 (* 1 = 0.17237 loss)
I0529 03:06:21.535709 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00561016 (* 1 = 0.00561016 loss)
I0529 03:06:21.535714 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161484 (* 1 = 0.0161484 loss)
I0529 03:06:21.535722 10644 sgd_solver.cpp:106] Iteration 14720, lr = 0.0002
I0529 03:07:10.051501 10644 solver.cpp:228] Iteration 14740, loss = 0.266196
I0529 03:07:10.051522 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:07:10.051530 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0577676 (* 1 = 0.0577676 loss)
I0529 03:07:10.051534 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.166018 (* 1 = 0.166018 loss)
I0529 03:07:10.051538 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119745 (* 1 = 0.0119745 loss)
I0529 03:07:10.051542 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122201 (* 1 = 0.0122201 loss)
I0529 03:07:10.051548 10644 sgd_solver.cpp:106] Iteration 14740, lr = 0.0002
I0529 03:07:58.456758 10644 solver.cpp:228] Iteration 14760, loss = 0.346183
I0529 03:07:58.456782 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 03:07:58.456790 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0745608 (* 1 = 0.0745608 loss)
I0529 03:07:58.456794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.197365 (* 1 = 0.197365 loss)
I0529 03:07:58.456799 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134906 (* 1 = 0.0134906 loss)
I0529 03:07:58.456802 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0616572 (* 1 = 0.0616572 loss)
I0529 03:07:58.456807 10644 sgd_solver.cpp:106] Iteration 14760, lr = 0.0002
I0529 03:08:46.951050 10644 solver.cpp:228] Iteration 14780, loss = 0.686449
I0529 03:08:46.951077 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:08:46.951086 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00101402 (* 1 = 0.00101402 loss)
I0529 03:08:46.951089 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0503981 (* 1 = 0.0503981 loss)
I0529 03:08:46.951093 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105352 (* 1 = 0.0105352 loss)
I0529 03:08:46.951097 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176745 (* 1 = 0.0176745 loss)
I0529 03:08:46.951102 10644 sgd_solver.cpp:106] Iteration 14780, lr = 0.0002
speed: 2.429s / iter
I0529 03:09:35.528493 10644 solver.cpp:228] Iteration 14800, loss = 0.249269
I0529 03:09:35.528520 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:09:35.528529 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0288166 (* 1 = 0.0288166 loss)
I0529 03:09:35.528535 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0848705 (* 1 = 0.0848705 loss)
I0529 03:09:35.528540 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167491 (* 1 = 0.00167491 loss)
I0529 03:09:35.528545 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00586906 (* 1 = 0.00586906 loss)
I0529 03:09:35.528551 10644 sgd_solver.cpp:106] Iteration 14800, lr = 0.0002
I0529 03:10:24.080090 10644 solver.cpp:228] Iteration 14820, loss = 0.217089
I0529 03:10:24.080114 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:10:24.080121 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.049023 (* 1 = 0.049023 loss)
I0529 03:10:24.080127 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0779709 (* 1 = 0.0779709 loss)
I0529 03:10:24.080129 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257725 (* 1 = 0.00257725 loss)
I0529 03:10:24.080132 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00843569 (* 1 = 0.00843569 loss)
I0529 03:10:24.080137 10644 sgd_solver.cpp:106] Iteration 14820, lr = 0.0002
I0529 03:11:12.615954 10644 solver.cpp:228] Iteration 14840, loss = 0.484007
I0529 03:11:12.615981 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 03:11:12.615988 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0559884 (* 1 = 0.0559884 loss)
I0529 03:11:12.615993 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.125366 (* 1 = 0.125366 loss)
I0529 03:11:12.615998 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157845 (* 1 = 0.0157845 loss)
I0529 03:11:12.616000 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123488 (* 1 = 0.0123488 loss)
I0529 03:11:12.616006 10644 sgd_solver.cpp:106] Iteration 14840, lr = 0.0002
I0529 03:12:01.168869 10644 solver.cpp:228] Iteration 14860, loss = 0.436865
I0529 03:12:01.168896 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 03:12:01.168903 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.017534 (* 1 = 0.017534 loss)
I0529 03:12:01.168908 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0410873 (* 1 = 0.0410873 loss)
I0529 03:12:01.168915 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359805 (* 1 = 0.00359805 loss)
I0529 03:12:01.168920 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172229 (* 1 = 0.0172229 loss)
I0529 03:12:01.168926 10644 sgd_solver.cpp:106] Iteration 14860, lr = 0.0002
I0529 03:12:49.734359 10644 solver.cpp:228] Iteration 14880, loss = 0.272444
I0529 03:12:49.734447 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 03:12:49.734460 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.092021 (* 1 = 0.092021 loss)
I0529 03:12:49.734467 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.247761 (* 1 = 0.247761 loss)
I0529 03:12:49.734474 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213297 (* 1 = 0.0213297 loss)
I0529 03:12:49.734480 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275254 (* 1 = 0.0275254 loss)
I0529 03:12:49.734489 10644 sgd_solver.cpp:106] Iteration 14880, lr = 0.0002
I0529 03:13:38.289093 10644 solver.cpp:228] Iteration 14900, loss = 0.272648
I0529 03:13:38.289124 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 03:13:38.289134 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0350833 (* 1 = 0.0350833 loss)
I0529 03:13:38.289140 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.116858 (* 1 = 0.116858 loss)
I0529 03:13:38.289146 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356339 (* 1 = 0.00356339 loss)
I0529 03:13:38.289152 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939334 (* 1 = 0.00939334 loss)
I0529 03:13:38.289160 10644 sgd_solver.cpp:106] Iteration 14900, lr = 0.0002
I0529 03:14:26.845540 10644 solver.cpp:228] Iteration 14920, loss = 0.379607
I0529 03:14:26.845576 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 03:14:26.845587 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.22094 (* 1 = 0.22094 loss)
I0529 03:14:26.845593 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.528687 (* 1 = 0.528687 loss)
I0529 03:14:26.845600 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.070471 (* 1 = 0.070471 loss)
I0529 03:14:26.845607 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0711432 (* 1 = 0.0711432 loss)
I0529 03:14:26.845615 10644 sgd_solver.cpp:106] Iteration 14920, lr = 0.0002
I0529 03:15:15.394799 10644 solver.cpp:228] Iteration 14940, loss = 0.486092
I0529 03:15:15.394830 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:15:15.394839 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000302252 (* 1 = 0.000302252 loss)
I0529 03:15:15.394843 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0283558 (* 1 = 0.0283558 loss)
I0529 03:15:15.394846 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181766 (* 1 = 0.0181766 loss)
I0529 03:15:15.394850 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371484 (* 1 = 0.0371484 loss)
I0529 03:15:15.394856 10644 sgd_solver.cpp:106] Iteration 14940, lr = 0.0002
I0529 03:16:03.960629 10644 solver.cpp:228] Iteration 14960, loss = 0.470108
I0529 03:16:03.960657 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:16:03.960667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327642 (* 1 = 0.0327642 loss)
I0529 03:16:03.960674 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113558 (* 1 = 0.113558 loss)
I0529 03:16:03.960678 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00534025 (* 1 = 0.00534025 loss)
I0529 03:16:03.960685 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194556 (* 1 = 0.0194556 loss)
I0529 03:16:03.960690 10644 sgd_solver.cpp:106] Iteration 14960, lr = 0.0002
I0529 03:16:52.518038 10644 solver.cpp:228] Iteration 14980, loss = 0.320243
I0529 03:16:52.518062 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 03:16:52.518069 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0471352 (* 1 = 0.0471352 loss)
I0529 03:16:52.518074 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.208876 (* 1 = 0.208876 loss)
I0529 03:16:52.518076 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131315 (* 1 = 0.0131315 loss)
I0529 03:16:52.518079 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00696147 (* 1 = 0.00696147 loss)
I0529 03:16:52.518085 10644 sgd_solver.cpp:106] Iteration 14980, lr = 0.0002
speed: 2.429s / iter
I0529 03:17:38.796818 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_15000.caffemodel
I0529 03:17:41.875617 10644 solver.cpp:228] Iteration 15000, loss = 0.338189
I0529 03:17:41.875643 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 03:17:41.875653 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.17445 (* 1 = 0.17445 loss)
I0529 03:17:41.875658 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.182696 (* 1 = 0.182696 loss)
I0529 03:17:41.875661 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010705 (* 1 = 0.010705 loss)
I0529 03:17:41.875666 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0427747 (* 1 = 0.0427747 loss)
I0529 03:17:41.875672 10644 sgd_solver.cpp:106] Iteration 15000, lr = 0.0002
I0529 03:18:30.434316 10644 solver.cpp:228] Iteration 15020, loss = 0.291883
I0529 03:18:30.434340 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:18:30.434347 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0200505 (* 1 = 0.0200505 loss)
I0529 03:18:30.434351 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0514231 (* 1 = 0.0514231 loss)
I0529 03:18:30.434355 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00509074 (* 1 = 0.00509074 loss)
I0529 03:18:30.434358 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00463502 (* 1 = 0.00463502 loss)
I0529 03:18:30.434362 10644 sgd_solver.cpp:106] Iteration 15020, lr = 0.0002
I0529 03:19:18.996942 10644 solver.cpp:228] Iteration 15040, loss = 0.240058
I0529 03:19:18.996973 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 03:19:18.996979 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0038542 (* 1 = 0.0038542 loss)
I0529 03:19:18.996984 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0872355 (* 1 = 0.0872355 loss)
I0529 03:19:18.996986 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0055605 (* 1 = 0.0055605 loss)
I0529 03:19:18.996990 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00392278 (* 1 = 0.00392278 loss)
I0529 03:19:18.996996 10644 sgd_solver.cpp:106] Iteration 15040, lr = 0.0002
I0529 03:20:07.550102 10644 solver.cpp:228] Iteration 15060, loss = 0.40671
I0529 03:20:07.550130 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 03:20:07.550139 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.147933 (* 1 = 0.147933 loss)
I0529 03:20:07.550145 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108797 (* 1 = 0.108797 loss)
I0529 03:20:07.550150 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275138 (* 1 = 0.00275138 loss)
I0529 03:20:07.550156 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121832 (* 1 = 0.0121832 loss)
I0529 03:20:07.550163 10644 sgd_solver.cpp:106] Iteration 15060, lr = 0.0002
I0529 03:20:56.132187 10644 solver.cpp:228] Iteration 15080, loss = 0.249862
I0529 03:20:56.132215 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 03:20:56.132225 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.17705 (* 1 = 0.17705 loss)
I0529 03:20:56.132231 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.272752 (* 1 = 0.272752 loss)
I0529 03:20:56.132237 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192713 (* 1 = 0.0192713 loss)
I0529 03:20:56.132242 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445767 (* 1 = 0.0445767 loss)
I0529 03:20:56.132251 10644 sgd_solver.cpp:106] Iteration 15080, lr = 0.0002
I0529 03:21:44.678488 10644 solver.cpp:228] Iteration 15100, loss = 0.219555
I0529 03:21:44.678514 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:21:44.678522 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206828 (* 1 = 0.0206828 loss)
I0529 03:21:44.678527 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0460759 (* 1 = 0.0460759 loss)
I0529 03:21:44.678531 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0045962 (* 1 = 0.0045962 loss)
I0529 03:21:44.678534 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161621 (* 1 = 0.0161621 loss)
I0529 03:21:44.678540 10644 sgd_solver.cpp:106] Iteration 15100, lr = 0.0002
I0529 03:22:33.233085 10644 solver.cpp:228] Iteration 15120, loss = 0.224424
I0529 03:22:33.233111 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:22:33.233119 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0572678 (* 1 = 0.0572678 loss)
I0529 03:22:33.233124 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0738087 (* 1 = 0.0738087 loss)
I0529 03:22:33.233127 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0043288 (* 1 = 0.0043288 loss)
I0529 03:22:33.233131 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129912 (* 1 = 0.0129912 loss)
I0529 03:22:33.233136 10644 sgd_solver.cpp:106] Iteration 15120, lr = 0.0002
I0529 03:23:21.780869 10644 solver.cpp:228] Iteration 15140, loss = 0.286671
I0529 03:23:21.780896 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 03:23:21.780907 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.137132 (* 1 = 0.137132 loss)
I0529 03:23:21.780917 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.243971 (* 1 = 0.243971 loss)
I0529 03:23:21.780925 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104176 (* 1 = 0.0104176 loss)
I0529 03:23:21.780930 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100946 (* 1 = 0.0100946 loss)
I0529 03:23:21.780938 10644 sgd_solver.cpp:106] Iteration 15140, lr = 0.0002
I0529 03:24:10.345669 10644 solver.cpp:228] Iteration 15160, loss = 0.269713
I0529 03:24:10.345695 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 03:24:10.345703 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0894223 (* 1 = 0.0894223 loss)
I0529 03:24:10.345708 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.224426 (* 1 = 0.224426 loss)
I0529 03:24:10.345711 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00839345 (* 1 = 0.00839345 loss)
I0529 03:24:10.345715 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160432 (* 1 = 0.0160432 loss)
I0529 03:24:10.345721 10644 sgd_solver.cpp:106] Iteration 15160, lr = 0.0002
I0529 03:24:58.908701 10644 solver.cpp:228] Iteration 15180, loss = 0.29056
I0529 03:24:58.908726 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:24:58.908735 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159162 (* 1 = 0.0159162 loss)
I0529 03:24:58.908738 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0792247 (* 1 = 0.0792247 loss)
I0529 03:24:58.908742 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0217209 (* 1 = 0.0217209 loss)
I0529 03:24:58.908746 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325477 (* 1 = 0.0325477 loss)
I0529 03:24:58.908751 10644 sgd_solver.cpp:106] Iteration 15180, lr = 0.0002
speed: 2.429s / iter
I0529 03:25:47.429255 10644 solver.cpp:228] Iteration 15200, loss = 0.185624
I0529 03:25:47.429286 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 03:25:47.429293 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0597482 (* 1 = 0.0597482 loss)
I0529 03:25:47.429298 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120092 (* 1 = 0.120092 loss)
I0529 03:25:47.429301 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00747937 (* 1 = 0.00747937 loss)
I0529 03:25:47.429306 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121828 (* 1 = 0.0121828 loss)
I0529 03:25:47.429311 10644 sgd_solver.cpp:106] Iteration 15200, lr = 0.0002
I0529 03:26:35.984732 10644 solver.cpp:228] Iteration 15220, loss = 0.417465
I0529 03:26:35.984758 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 03:26:35.984767 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0370769 (* 1 = 0.0370769 loss)
I0529 03:26:35.984771 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.179586 (* 1 = 0.179586 loss)
I0529 03:26:35.984776 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114973 (* 1 = 0.0114973 loss)
I0529 03:26:35.984779 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00761201 (* 1 = 0.00761201 loss)
I0529 03:26:35.984784 10644 sgd_solver.cpp:106] Iteration 15220, lr = 0.0002
I0529 03:27:24.517536 10644 solver.cpp:228] Iteration 15240, loss = 0.196482
I0529 03:27:24.517565 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 03:27:24.517572 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0615228 (* 1 = 0.0615228 loss)
I0529 03:27:24.517577 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144272 (* 1 = 0.144272 loss)
I0529 03:27:24.517580 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318904 (* 1 = 0.00318904 loss)
I0529 03:27:24.517583 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00594307 (* 1 = 0.00594307 loss)
I0529 03:27:24.517588 10644 sgd_solver.cpp:106] Iteration 15240, lr = 0.0002
I0529 03:28:13.041440 10644 solver.cpp:228] Iteration 15260, loss = 0.193556
I0529 03:28:13.041463 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:28:13.041471 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0285162 (* 1 = 0.0285162 loss)
I0529 03:28:13.041474 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0636379 (* 1 = 0.0636379 loss)
I0529 03:28:13.041477 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00285405 (* 1 = 0.00285405 loss)
I0529 03:28:13.041481 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00850976 (* 1 = 0.00850976 loss)
I0529 03:28:13.041486 10644 sgd_solver.cpp:106] Iteration 15260, lr = 0.0002
I0529 03:29:01.611588 10644 solver.cpp:228] Iteration 15280, loss = 0.38985
I0529 03:29:01.611615 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:29:01.611623 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274778 (* 1 = 0.0274778 loss)
I0529 03:29:01.611627 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0910723 (* 1 = 0.0910723 loss)
I0529 03:29:01.611631 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115662 (* 1 = 0.0115662 loss)
I0529 03:29:01.611634 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127626 (* 1 = 0.0127626 loss)
I0529 03:29:01.611640 10644 sgd_solver.cpp:106] Iteration 15280, lr = 0.0002
I0529 03:29:50.187568 10644 solver.cpp:228] Iteration 15300, loss = 0.302075
I0529 03:29:50.187595 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0529 03:29:50.187607 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.224043 (* 1 = 0.224043 loss)
I0529 03:29:50.187613 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.417738 (* 1 = 0.417738 loss)
I0529 03:29:50.187618 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208441 (* 1 = 0.0208441 loss)
I0529 03:29:50.187624 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0678415 (* 1 = 0.0678415 loss)
I0529 03:29:50.187633 10644 sgd_solver.cpp:106] Iteration 15300, lr = 0.0002
I0529 03:30:38.736389 10644 solver.cpp:228] Iteration 15320, loss = 0.476865
I0529 03:30:38.736418 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:30:38.736426 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0785889 (* 1 = 0.0785889 loss)
I0529 03:30:38.736431 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0733118 (* 1 = 0.0733118 loss)
I0529 03:30:38.736435 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00254987 (* 1 = 0.00254987 loss)
I0529 03:30:38.736439 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104712 (* 1 = 0.0104712 loss)
I0529 03:30:38.736445 10644 sgd_solver.cpp:106] Iteration 15320, lr = 0.0002
I0529 03:31:27.287367 10644 solver.cpp:228] Iteration 15340, loss = 0.338217
I0529 03:31:27.287395 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 03:31:27.287403 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0820944 (* 1 = 0.0820944 loss)
I0529 03:31:27.287407 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.146913 (* 1 = 0.146913 loss)
I0529 03:31:27.287411 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338178 (* 1 = 0.00338178 loss)
I0529 03:31:27.287415 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173774 (* 1 = 0.0173774 loss)
I0529 03:31:27.287421 10644 sgd_solver.cpp:106] Iteration 15340, lr = 0.0002
I0529 03:32:15.798710 10644 solver.cpp:228] Iteration 15360, loss = 0.318388
I0529 03:32:15.798737 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 03:32:15.798743 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0764673 (* 1 = 0.0764673 loss)
I0529 03:32:15.798748 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.079955 (* 1 = 0.079955 loss)
I0529 03:32:15.798750 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0051968 (* 1 = 0.0051968 loss)
I0529 03:32:15.798753 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108074 (* 1 = 0.0108074 loss)
I0529 03:32:15.798758 10644 sgd_solver.cpp:106] Iteration 15360, lr = 0.0002
I0529 03:33:04.370983 10644 solver.cpp:228] Iteration 15380, loss = 0.315141
I0529 03:33:04.371008 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:33:04.371016 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.043921 (* 1 = 0.043921 loss)
I0529 03:33:04.371019 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0492643 (* 1 = 0.0492643 loss)
I0529 03:33:04.371023 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165042 (* 1 = 0.00165042 loss)
I0529 03:33:04.371026 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160453 (* 1 = 0.0160453 loss)
I0529 03:33:04.371031 10644 sgd_solver.cpp:106] Iteration 15380, lr = 0.0002
speed: 2.429s / iter
I0529 03:33:52.934906 10644 solver.cpp:228] Iteration 15400, loss = 0.536551
I0529 03:33:52.934937 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 03:33:52.934945 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0127814 (* 1 = 0.0127814 loss)
I0529 03:33:52.934949 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0537213 (* 1 = 0.0537213 loss)
I0529 03:33:52.934953 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016246 (* 1 = 0.016246 loss)
I0529 03:33:52.934957 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133331 (* 1 = 0.0133331 loss)
I0529 03:33:52.934962 10644 sgd_solver.cpp:106] Iteration 15400, lr = 0.0002
I0529 03:34:41.508919 10644 solver.cpp:228] Iteration 15420, loss = 0.32081
I0529 03:34:41.508963 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 03:34:41.508975 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.22497 (* 1 = 0.22497 loss)
I0529 03:34:41.508980 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.449427 (* 1 = 0.449427 loss)
I0529 03:34:41.508986 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0450013 (* 1 = 0.0450013 loss)
I0529 03:34:41.508992 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658544 (* 1 = 0.0658544 loss)
I0529 03:34:41.508999 10644 sgd_solver.cpp:106] Iteration 15420, lr = 0.0002
I0529 03:35:30.068879 10644 solver.cpp:228] Iteration 15440, loss = 0.808368
I0529 03:35:30.068905 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0529 03:35:30.068919 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.436448 (* 1 = 0.436448 loss)
I0529 03:35:30.068927 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.569093 (* 1 = 0.569093 loss)
I0529 03:35:30.068933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211464 (* 1 = 0.0211464 loss)
I0529 03:35:30.068939 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.07116 (* 1 = 0.07116 loss)
I0529 03:35:30.068946 10644 sgd_solver.cpp:106] Iteration 15440, lr = 0.0002
I0529 03:36:18.631552 10644 solver.cpp:228] Iteration 15460, loss = 0.371605
I0529 03:36:18.631582 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:36:18.631593 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00071246 (* 1 = 0.00071246 loss)
I0529 03:36:18.631600 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.043409 (* 1 = 0.043409 loss)
I0529 03:36:18.631606 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00673413 (* 1 = 0.00673413 loss)
I0529 03:36:18.631613 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239927 (* 1 = 0.0239927 loss)
I0529 03:36:18.631619 10644 sgd_solver.cpp:106] Iteration 15460, lr = 0.0002
I0529 03:37:07.199054 10644 solver.cpp:228] Iteration 15480, loss = 0.24852
I0529 03:37:07.199080 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:37:07.199090 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324895 (* 1 = 0.0324895 loss)
I0529 03:37:07.199093 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.154383 (* 1 = 0.154383 loss)
I0529 03:37:07.199097 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0634563 (* 1 = 0.0634563 loss)
I0529 03:37:07.199100 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0801056 (* 1 = 0.0801056 loss)
I0529 03:37:07.199106 10644 sgd_solver.cpp:106] Iteration 15480, lr = 0.0002
I0529 03:37:55.744916 10644 solver.cpp:228] Iteration 15500, loss = 0.379679
I0529 03:37:55.744941 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 03:37:55.744947 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0972897 (* 1 = 0.0972897 loss)
I0529 03:37:55.744951 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.187327 (* 1 = 0.187327 loss)
I0529 03:37:55.744956 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116006 (* 1 = 0.0116006 loss)
I0529 03:37:55.744958 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0680895 (* 1 = 0.0680895 loss)
I0529 03:37:55.744963 10644 sgd_solver.cpp:106] Iteration 15500, lr = 0.0002
I0529 03:38:44.288038 10644 solver.cpp:228] Iteration 15520, loss = 0.280237
I0529 03:38:44.288077 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 03:38:44.288086 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360661 (* 1 = 0.0360661 loss)
I0529 03:38:44.288090 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0407527 (* 1 = 0.0407527 loss)
I0529 03:38:44.288094 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193632 (* 1 = 0.00193632 loss)
I0529 03:38:44.288097 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0046192 (* 1 = 0.0046192 loss)
I0529 03:38:44.288103 10644 sgd_solver.cpp:106] Iteration 15520, lr = 0.0002
I0529 03:39:32.820232 10644 solver.cpp:228] Iteration 15540, loss = 0.267162
I0529 03:39:32.820260 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 03:39:32.820267 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.191612 (* 1 = 0.191612 loss)
I0529 03:39:32.820271 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.323072 (* 1 = 0.323072 loss)
I0529 03:39:32.820276 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0300114 (* 1 = 0.0300114 loss)
I0529 03:39:32.820279 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319155 (* 1 = 0.0319155 loss)
I0529 03:39:32.820284 10644 sgd_solver.cpp:106] Iteration 15540, lr = 0.0002
I0529 03:40:21.372231 10644 solver.cpp:228] Iteration 15560, loss = 0.51148
I0529 03:40:21.372257 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:40:21.372265 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000203009 (* 1 = 0.000203009 loss)
I0529 03:40:21.372269 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0252017 (* 1 = 0.0252017 loss)
I0529 03:40:21.372274 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00891812 (* 1 = 0.00891812 loss)
I0529 03:40:21.372277 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317136 (* 1 = 0.0317136 loss)
I0529 03:40:21.372282 10644 sgd_solver.cpp:106] Iteration 15560, lr = 0.0002
I0529 03:41:09.903652 10644 solver.cpp:228] Iteration 15580, loss = 0.287518
I0529 03:41:09.903679 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 03:41:09.903687 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.217798 (* 1 = 0.217798 loss)
I0529 03:41:09.903692 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.287316 (* 1 = 0.287316 loss)
I0529 03:41:09.903700 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254711 (* 1 = 0.0254711 loss)
I0529 03:41:09.903707 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421262 (* 1 = 0.0421262 loss)
I0529 03:41:09.903714 10644 sgd_solver.cpp:106] Iteration 15580, lr = 0.0002
speed: 2.429s / iter
I0529 03:41:58.453927 10644 solver.cpp:228] Iteration 15600, loss = 0.246511
I0529 03:41:58.453956 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 03:41:58.453965 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0896664 (* 1 = 0.0896664 loss)
I0529 03:41:58.453969 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.200895 (* 1 = 0.200895 loss)
I0529 03:41:58.453974 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106705 (* 1 = 0.0106705 loss)
I0529 03:41:58.453977 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319658 (* 1 = 0.0319658 loss)
I0529 03:41:58.453984 10644 sgd_solver.cpp:106] Iteration 15600, lr = 0.0002
I0529 03:42:46.977185 10644 solver.cpp:228] Iteration 15620, loss = 0.38109
I0529 03:42:46.977210 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 03:42:46.977217 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150709 (* 1 = 0.0150709 loss)
I0529 03:42:46.977221 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.091574 (* 1 = 0.091574 loss)
I0529 03:42:46.977226 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133286 (* 1 = 0.00133286 loss)
I0529 03:42:46.977229 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.008833 (* 1 = 0.008833 loss)
I0529 03:42:46.977234 10644 sgd_solver.cpp:106] Iteration 15620, lr = 0.0002
I0529 03:43:35.536413 10644 solver.cpp:228] Iteration 15640, loss = 0.446819
I0529 03:43:35.536456 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 03:43:35.536464 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.183838 (* 1 = 0.183838 loss)
I0529 03:43:35.536469 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.361768 (* 1 = 0.361768 loss)
I0529 03:43:35.536473 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242239 (* 1 = 0.0242239 loss)
I0529 03:43:35.536476 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0639012 (* 1 = 0.0639012 loss)
I0529 03:43:35.536484 10644 sgd_solver.cpp:106] Iteration 15640, lr = 0.0002
I0529 03:44:24.040591 10644 solver.cpp:228] Iteration 15660, loss = 0.393762
I0529 03:44:24.040621 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 03:44:24.040632 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.225463 (* 1 = 0.225463 loss)
I0529 03:44:24.040637 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.307593 (* 1 = 0.307593 loss)
I0529 03:44:24.040644 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00856954 (* 1 = 0.00856954 loss)
I0529 03:44:24.040650 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.06366 (* 1 = 0.06366 loss)
I0529 03:44:24.040657 10644 sgd_solver.cpp:106] Iteration 15660, lr = 0.0002
I0529 03:45:12.571156 10644 solver.cpp:228] Iteration 15680, loss = 0.291097
I0529 03:45:12.571182 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 03:45:12.571189 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0527179 (* 1 = 0.0527179 loss)
I0529 03:45:12.571194 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0563818 (* 1 = 0.0563818 loss)
I0529 03:45:12.571197 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271966 (* 1 = 0.00271966 loss)
I0529 03:45:12.571202 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169598 (* 1 = 0.0169598 loss)
I0529 03:45:12.571208 10644 sgd_solver.cpp:106] Iteration 15680, lr = 0.0002
I0529 03:46:01.084791 10644 solver.cpp:228] Iteration 15700, loss = 0.427079
I0529 03:46:01.084817 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0529 03:46:01.084826 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.792978 (* 1 = 0.792978 loss)
I0529 03:46:01.084832 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.625479 (* 1 = 0.625479 loss)
I0529 03:46:01.084837 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0748494 (* 1 = 0.0748494 loss)
I0529 03:46:01.084842 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.399814 (* 1 = 0.399814 loss)
I0529 03:46:01.084849 10644 sgd_solver.cpp:106] Iteration 15700, lr = 0.0002
I0529 03:46:49.644768 10644 solver.cpp:228] Iteration 15720, loss = 0.243099
I0529 03:46:49.644799 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:46:49.644809 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.042458 (* 1 = 0.042458 loss)
I0529 03:46:49.644816 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110385 (* 1 = 0.110385 loss)
I0529 03:46:49.644822 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00539453 (* 1 = 0.00539453 loss)
I0529 03:46:49.644827 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118312 (* 1 = 0.0118312 loss)
I0529 03:46:49.644834 10644 sgd_solver.cpp:106] Iteration 15720, lr = 0.0002
I0529 03:47:38.216184 10644 solver.cpp:228] Iteration 15740, loss = 0.39696
I0529 03:47:38.216212 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0529 03:47:38.216218 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.586448 (* 1 = 0.586448 loss)
I0529 03:47:38.216223 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.634485 (* 1 = 0.634485 loss)
I0529 03:47:38.216226 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182567 (* 1 = 0.0182567 loss)
I0529 03:47:38.216230 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.251349 (* 1 = 0.251349 loss)
I0529 03:47:38.216236 10644 sgd_solver.cpp:106] Iteration 15740, lr = 0.0002
I0529 03:48:26.771761 10644 solver.cpp:228] Iteration 15760, loss = 0.27114
I0529 03:48:26.771790 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:48:26.771797 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0646329 (* 1 = 0.0646329 loss)
I0529 03:48:26.771801 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0434064 (* 1 = 0.0434064 loss)
I0529 03:48:26.771806 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00492413 (* 1 = 0.00492413 loss)
I0529 03:48:26.771811 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106739 (* 1 = 0.0106739 loss)
I0529 03:48:26.771816 10644 sgd_solver.cpp:106] Iteration 15760, lr = 0.0002
I0529 03:49:15.332190 10644 solver.cpp:228] Iteration 15780, loss = 0.20877
I0529 03:49:15.332214 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 03:49:15.332223 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0394912 (* 1 = 0.0394912 loss)
I0529 03:49:15.332227 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0528776 (* 1 = 0.0528776 loss)
I0529 03:49:15.332231 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00069558 (* 1 = 0.00069558 loss)
I0529 03:49:15.332234 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172057 (* 1 = 0.0172057 loss)
I0529 03:49:15.332240 10644 sgd_solver.cpp:106] Iteration 15780, lr = 0.0002
speed: 2.429s / iter
I0529 03:50:03.849792 10644 solver.cpp:228] Iteration 15800, loss = 0.271739
I0529 03:50:03.849818 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 03:50:03.849826 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690593 (* 1 = 0.0690593 loss)
I0529 03:50:03.849831 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.168918 (* 1 = 0.168918 loss)
I0529 03:50:03.849834 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.007092 (* 1 = 0.007092 loss)
I0529 03:50:03.849838 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154392 (* 1 = 0.0154392 loss)
I0529 03:50:03.849844 10644 sgd_solver.cpp:106] Iteration 15800, lr = 0.0002
I0529 03:50:52.397083 10644 solver.cpp:228] Iteration 15820, loss = 0.394674
I0529 03:50:52.397107 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:50:52.397115 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359321 (* 1 = 0.0359321 loss)
I0529 03:50:52.397119 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0624575 (* 1 = 0.0624575 loss)
I0529 03:50:52.397125 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00594577 (* 1 = 0.00594577 loss)
I0529 03:50:52.397127 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00715948 (* 1 = 0.00715948 loss)
I0529 03:50:52.397133 10644 sgd_solver.cpp:106] Iteration 15820, lr = 0.0002
I0529 03:51:40.961709 10644 solver.cpp:228] Iteration 15840, loss = 0.284271
I0529 03:51:40.961735 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:51:40.961742 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203115 (* 1 = 0.0203115 loss)
I0529 03:51:40.961747 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0384773 (* 1 = 0.0384773 loss)
I0529 03:51:40.961750 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000806048 (* 1 = 0.000806048 loss)
I0529 03:51:40.961755 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00925385 (* 1 = 0.00925385 loss)
I0529 03:51:40.961760 10644 sgd_solver.cpp:106] Iteration 15840, lr = 0.0002
I0529 03:52:29.532840 10644 solver.cpp:228] Iteration 15860, loss = 0.421345
I0529 03:52:29.532866 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 03:52:29.532876 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.356516 (* 1 = 0.356516 loss)
I0529 03:52:29.532882 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.497596 (* 1 = 0.497596 loss)
I0529 03:52:29.532887 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366625 (* 1 = 0.0366625 loss)
I0529 03:52:29.532892 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.141981 (* 1 = 0.141981 loss)
I0529 03:52:29.532899 10644 sgd_solver.cpp:106] Iteration 15860, lr = 0.0002
I0529 03:53:18.078644 10644 solver.cpp:228] Iteration 15880, loss = 0.264476
I0529 03:53:18.078670 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 03:53:18.078678 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0959712 (* 1 = 0.0959712 loss)
I0529 03:53:18.078682 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.330674 (* 1 = 0.330674 loss)
I0529 03:53:18.078686 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00753478 (* 1 = 0.00753478 loss)
I0529 03:53:18.078689 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364484 (* 1 = 0.0364484 loss)
I0529 03:53:18.078696 10644 sgd_solver.cpp:106] Iteration 15880, lr = 0.0002
I0529 03:54:06.622557 10644 solver.cpp:228] Iteration 15900, loss = 0.382477
I0529 03:54:06.622581 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 03:54:06.622589 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.107427 (* 1 = 0.107427 loss)
I0529 03:54:06.622593 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.341323 (* 1 = 0.341323 loss)
I0529 03:54:06.622597 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0372567 (* 1 = 0.0372567 loss)
I0529 03:54:06.622601 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0616883 (* 1 = 0.0616883 loss)
I0529 03:54:06.622606 10644 sgd_solver.cpp:106] Iteration 15900, lr = 0.0002
I0529 03:54:55.192986 10644 solver.cpp:228] Iteration 15920, loss = 0.214212
I0529 03:54:55.193015 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 03:54:55.193023 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.132299 (* 1 = 0.132299 loss)
I0529 03:54:55.193027 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.239185 (* 1 = 0.239185 loss)
I0529 03:54:55.193032 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00574597 (* 1 = 0.00574597 loss)
I0529 03:54:55.193035 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220081 (* 1 = 0.0220081 loss)
I0529 03:54:55.193042 10644 sgd_solver.cpp:106] Iteration 15920, lr = 0.0002
I0529 03:55:43.715545 10644 solver.cpp:228] Iteration 15940, loss = 0.247768
I0529 03:55:43.715571 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 03:55:43.715579 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593875 (* 1 = 0.0593875 loss)
I0529 03:55:43.715584 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.159584 (* 1 = 0.159584 loss)
I0529 03:55:43.715587 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0463378 (* 1 = 0.0463378 loss)
I0529 03:55:43.715592 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139893 (* 1 = 0.0139893 loss)
I0529 03:55:43.715598 10644 sgd_solver.cpp:106] Iteration 15940, lr = 0.0002
I0529 03:56:32.290287 10644 solver.cpp:228] Iteration 15960, loss = 0.399387
I0529 03:56:32.290321 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 03:56:32.290331 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589544 (* 1 = 0.0589544 loss)
I0529 03:56:32.290339 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.146587 (* 1 = 0.146587 loss)
I0529 03:56:32.290346 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00688836 (* 1 = 0.00688836 loss)
I0529 03:56:32.290351 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318283 (* 1 = 0.0318283 loss)
I0529 03:56:32.290360 10644 sgd_solver.cpp:106] Iteration 15960, lr = 0.0002
I0529 03:57:20.852954 10644 solver.cpp:228] Iteration 15980, loss = 0.248442
I0529 03:57:20.852994 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 03:57:20.853005 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454611 (* 1 = 0.0454611 loss)
I0529 03:57:20.853013 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.106213 (* 1 = 0.106213 loss)
I0529 03:57:20.853019 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00656198 (* 1 = 0.00656198 loss)
I0529 03:57:20.853024 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123703 (* 1 = 0.0123703 loss)
I0529 03:57:20.853032 10644 sgd_solver.cpp:106] Iteration 15980, lr = 0.0002
speed: 2.429s / iter
I0529 03:58:09.411679 10644 solver.cpp:228] Iteration 16000, loss = 0.399097
I0529 03:58:09.411710 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 03:58:09.411717 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0800996 (* 1 = 0.0800996 loss)
I0529 03:58:09.411721 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174109 (* 1 = 0.174109 loss)
I0529 03:58:09.411725 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00322098 (* 1 = 0.00322098 loss)
I0529 03:58:09.411729 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265468 (* 1 = 0.0265468 loss)
I0529 03:58:09.411736 10644 sgd_solver.cpp:106] Iteration 16000, lr = 0.0002
I0529 03:58:57.952076 10644 solver.cpp:228] Iteration 16020, loss = 0.309496
I0529 03:58:57.952102 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 03:58:57.952111 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536097 (* 1 = 0.0536097 loss)
I0529 03:58:57.952114 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0411271 (* 1 = 0.0411271 loss)
I0529 03:58:57.952117 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00212152 (* 1 = 0.00212152 loss)
I0529 03:58:57.952121 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187685 (* 1 = 0.0187685 loss)
I0529 03:58:57.952126 10644 sgd_solver.cpp:106] Iteration 16020, lr = 0.0002
I0529 03:59:46.513954 10644 solver.cpp:228] Iteration 16040, loss = 0.493054
I0529 03:59:46.513979 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0529 03:59:46.513986 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.342967 (* 1 = 0.342967 loss)
I0529 03:59:46.513990 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.591954 (* 1 = 0.591954 loss)
I0529 03:59:46.513994 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262991 (* 1 = 0.0262991 loss)
I0529 03:59:46.513998 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149094 (* 1 = 0.149094 loss)
I0529 03:59:46.514003 10644 sgd_solver.cpp:106] Iteration 16040, lr = 0.0002
I0529 04:00:35.094691 10644 solver.cpp:228] Iteration 16060, loss = 0.441527
I0529 04:00:35.094717 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:00:35.094723 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0139154 (* 1 = 0.0139154 loss)
I0529 04:00:35.094727 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0399085 (* 1 = 0.0399085 loss)
I0529 04:00:35.094732 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00328187 (* 1 = 0.00328187 loss)
I0529 04:00:35.094735 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00828074 (* 1 = 0.00828074 loss)
I0529 04:00:35.094740 10644 sgd_solver.cpp:106] Iteration 16060, lr = 0.0002
I0529 04:01:23.616605 10644 solver.cpp:228] Iteration 16080, loss = 0.296639
I0529 04:01:23.616631 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 04:01:23.616638 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0517898 (* 1 = 0.0517898 loss)
I0529 04:01:23.616642 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.133704 (* 1 = 0.133704 loss)
I0529 04:01:23.616647 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281672 (* 1 = 0.00281672 loss)
I0529 04:01:23.616649 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166896 (* 1 = 0.0166896 loss)
I0529 04:01:23.616654 10644 sgd_solver.cpp:106] Iteration 16080, lr = 0.0002
I0529 04:02:12.174345 10644 solver.cpp:228] Iteration 16100, loss = 0.240265
I0529 04:02:12.174369 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 04:02:12.174376 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.021591 (* 1 = 0.021591 loss)
I0529 04:02:12.174381 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0638445 (* 1 = 0.0638445 loss)
I0529 04:02:12.174383 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116573 (* 1 = 0.0116573 loss)
I0529 04:02:12.174386 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144415 (* 1 = 0.0144415 loss)
I0529 04:02:12.174391 10644 sgd_solver.cpp:106] Iteration 16100, lr = 0.0002
I0529 04:03:00.715479 10644 solver.cpp:228] Iteration 16120, loss = 0.199605
I0529 04:03:00.715502 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 04:03:00.715509 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327119 (* 1 = 0.0327119 loss)
I0529 04:03:00.715513 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0863909 (* 1 = 0.0863909 loss)
I0529 04:03:00.715517 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127383 (* 1 = 0.00127383 loss)
I0529 04:03:00.715520 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00446095 (* 1 = 0.00446095 loss)
I0529 04:03:00.715525 10644 sgd_solver.cpp:106] Iteration 16120, lr = 0.0002
I0529 04:03:49.247234 10644 solver.cpp:228] Iteration 16140, loss = 0.250578
I0529 04:03:49.247256 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 04:03:49.247263 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.14349 (* 1 = 0.14349 loss)
I0529 04:03:49.247267 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.186051 (* 1 = 0.186051 loss)
I0529 04:03:49.247272 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032162 (* 1 = 0.0032162 loss)
I0529 04:03:49.247274 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252542 (* 1 = 0.0252542 loss)
I0529 04:03:49.247278 10644 sgd_solver.cpp:106] Iteration 16140, lr = 0.0002
I0529 04:04:37.845295 10644 solver.cpp:228] Iteration 16160, loss = 0.349233
I0529 04:04:37.845320 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 04:04:37.845327 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365971 (* 1 = 0.0365971 loss)
I0529 04:04:37.845331 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.135376 (* 1 = 0.135376 loss)
I0529 04:04:37.845335 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193065 (* 1 = 0.0193065 loss)
I0529 04:04:37.845338 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024445 (* 1 = 0.024445 loss)
I0529 04:04:37.845342 10644 sgd_solver.cpp:106] Iteration 16160, lr = 0.0002
I0529 04:05:26.395721 10644 solver.cpp:228] Iteration 16180, loss = 0.295465
I0529 04:05:26.395750 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 04:05:26.395758 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323677 (* 1 = 0.0323677 loss)
I0529 04:05:26.395763 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.130087 (* 1 = 0.130087 loss)
I0529 04:05:26.395766 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350892 (* 1 = 0.00350892 loss)
I0529 04:05:26.395771 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00579042 (* 1 = 0.00579042 loss)
I0529 04:05:26.395778 10644 sgd_solver.cpp:106] Iteration 16180, lr = 0.0002
speed: 2.429s / iter
I0529 04:06:14.934512 10644 solver.cpp:228] Iteration 16200, loss = 0.238351
I0529 04:06:14.934540 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 04:06:14.934546 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0463292 (* 1 = 0.0463292 loss)
I0529 04:06:14.934551 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0988746 (* 1 = 0.0988746 loss)
I0529 04:06:14.934556 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119364 (* 1 = 0.0119364 loss)
I0529 04:06:14.934558 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123696 (* 1 = 0.0123696 loss)
I0529 04:06:14.934564 10644 sgd_solver.cpp:106] Iteration 16200, lr = 0.0002
I0529 04:07:03.474710 10644 solver.cpp:228] Iteration 16220, loss = 0.25543
I0529 04:07:03.474740 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:07:03.474748 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.082769 (* 1 = 0.082769 loss)
I0529 04:07:03.474753 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.201136 (* 1 = 0.201136 loss)
I0529 04:07:03.474757 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327893 (* 1 = 0.0327893 loss)
I0529 04:07:03.474761 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213005 (* 1 = 0.0213005 loss)
I0529 04:07:03.474766 10644 sgd_solver.cpp:106] Iteration 16220, lr = 0.0002
I0529 04:07:52.061126 10644 solver.cpp:228] Iteration 16240, loss = 0.242192
I0529 04:07:52.061153 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 04:07:52.061161 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000287584 (* 1 = 0.000287584 loss)
I0529 04:07:52.061167 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0389199 (* 1 = 0.0389199 loss)
I0529 04:07:52.061170 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170403 (* 1 = 0.0170403 loss)
I0529 04:07:52.061174 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147193 (* 1 = 0.0147193 loss)
I0529 04:07:52.061179 10644 sgd_solver.cpp:106] Iteration 16240, lr = 0.0002
I0529 04:08:40.616150 10644 solver.cpp:228] Iteration 16260, loss = 0.266062
I0529 04:08:40.616180 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:08:40.616190 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0668235 (* 1 = 0.0668235 loss)
I0529 04:08:40.616197 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0964082 (* 1 = 0.0964082 loss)
I0529 04:08:40.616204 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012816 (* 1 = 0.012816 loss)
I0529 04:08:40.616209 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247534 (* 1 = 0.0247534 loss)
I0529 04:08:40.616215 10644 sgd_solver.cpp:106] Iteration 16260, lr = 0.0002
I0529 04:09:29.179011 10644 solver.cpp:228] Iteration 16280, loss = 0.163984
I0529 04:09:29.179036 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:09:29.179044 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441578 (* 1 = 0.0441578 loss)
I0529 04:09:29.179049 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0666312 (* 1 = 0.0666312 loss)
I0529 04:09:29.179052 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000768028 (* 1 = 0.000768028 loss)
I0529 04:09:29.179056 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00926276 (* 1 = 0.00926276 loss)
I0529 04:09:29.179061 10644 sgd_solver.cpp:106] Iteration 16280, lr = 0.0002
I0529 04:10:17.752499 10644 solver.cpp:228] Iteration 16300, loss = 0.344293
I0529 04:10:17.752527 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:10:17.752535 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.126888 (* 1 = 0.126888 loss)
I0529 04:10:17.752540 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120584 (* 1 = 0.120584 loss)
I0529 04:10:17.752547 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0194283 (* 1 = 0.0194283 loss)
I0529 04:10:17.752552 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100433 (* 1 = 0.0100433 loss)
I0529 04:10:17.752558 10644 sgd_solver.cpp:106] Iteration 16300, lr = 0.0002
I0529 04:11:06.301633 10644 solver.cpp:228] Iteration 16320, loss = 0.301668
I0529 04:11:06.301659 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 04:11:06.301667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0826867 (* 1 = 0.0826867 loss)
I0529 04:11:06.301671 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.156965 (* 1 = 0.156965 loss)
I0529 04:11:06.301676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0043009 (* 1 = 0.0043009 loss)
I0529 04:11:06.301681 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192979 (* 1 = 0.0192979 loss)
I0529 04:11:06.301687 10644 sgd_solver.cpp:106] Iteration 16320, lr = 0.0002
I0529 04:11:54.860692 10644 solver.cpp:228] Iteration 16340, loss = 0.283285
I0529 04:11:54.860716 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 04:11:54.860724 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729637 (* 1 = 0.0729637 loss)
I0529 04:11:54.860728 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.240708 (* 1 = 0.240708 loss)
I0529 04:11:54.860731 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00801816 (* 1 = 0.00801816 loss)
I0529 04:11:54.860734 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109751 (* 1 = 0.0109751 loss)
I0529 04:11:54.860739 10644 sgd_solver.cpp:106] Iteration 16340, lr = 0.0002
I0529 04:12:43.411947 10644 solver.cpp:228] Iteration 16360, loss = 0.330858
I0529 04:12:43.411970 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:12:43.411978 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320122 (* 1 = 0.0320122 loss)
I0529 04:12:43.411983 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.081644 (* 1 = 0.081644 loss)
I0529 04:12:43.411985 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140808 (* 1 = 0.00140808 loss)
I0529 04:12:43.411989 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00440481 (* 1 = 0.00440481 loss)
I0529 04:12:43.411993 10644 sgd_solver.cpp:106] Iteration 16360, lr = 0.0002
I0529 04:13:31.976873 10644 solver.cpp:228] Iteration 16380, loss = 0.271321
I0529 04:13:31.976904 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 04:13:31.976958 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.178666 (* 1 = 0.178666 loss)
I0529 04:13:31.976963 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.266192 (* 1 = 0.266192 loss)
I0529 04:13:31.976969 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00891799 (* 1 = 0.00891799 loss)
I0529 04:13:31.976971 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488122 (* 1 = 0.0488122 loss)
I0529 04:13:31.976977 10644 sgd_solver.cpp:106] Iteration 16380, lr = 0.0002
speed: 2.429s / iter
I0529 04:14:20.552408 10644 solver.cpp:228] Iteration 16400, loss = 0.283937
I0529 04:14:20.552433 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:14:20.552439 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265149 (* 1 = 0.0265149 loss)
I0529 04:14:20.552443 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0624649 (* 1 = 0.0624649 loss)
I0529 04:14:20.552448 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00210706 (* 1 = 0.00210706 loss)
I0529 04:14:20.552450 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00308622 (* 1 = 0.00308622 loss)
I0529 04:14:20.552456 10644 sgd_solver.cpp:106] Iteration 16400, lr = 0.0002
I0529 04:15:09.107132 10644 solver.cpp:228] Iteration 16420, loss = 0.563714
I0529 04:15:09.107161 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:15:09.107168 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0863817 (* 1 = 0.0863817 loss)
I0529 04:15:09.107172 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.141606 (* 1 = 0.141606 loss)
I0529 04:15:09.107175 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759993 (* 1 = 0.00759993 loss)
I0529 04:15:09.107178 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133521 (* 1 = 0.0133521 loss)
I0529 04:15:09.107184 10644 sgd_solver.cpp:106] Iteration 16420, lr = 0.0002
I0529 04:15:57.657949 10644 solver.cpp:228] Iteration 16440, loss = 0.22892
I0529 04:15:57.657974 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 04:15:57.657981 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0963665 (* 1 = 0.0963665 loss)
I0529 04:15:57.657985 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.194368 (* 1 = 0.194368 loss)
I0529 04:15:57.657989 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00749703 (* 1 = 0.00749703 loss)
I0529 04:15:57.657992 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0385435 (* 1 = 0.0385435 loss)
I0529 04:15:57.657997 10644 sgd_solver.cpp:106] Iteration 16440, lr = 0.0002
I0529 04:16:46.205201 10644 solver.cpp:228] Iteration 16460, loss = 0.150872
I0529 04:16:46.205227 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 04:16:46.205235 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0664892 (* 1 = 0.0664892 loss)
I0529 04:16:46.205237 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0778299 (* 1 = 0.0778299 loss)
I0529 04:16:46.205241 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00749719 (* 1 = 0.00749719 loss)
I0529 04:16:46.205245 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151621 (* 1 = 0.0151621 loss)
I0529 04:16:46.205250 10644 sgd_solver.cpp:106] Iteration 16460, lr = 0.0002
I0529 04:17:34.751498 10644 solver.cpp:228] Iteration 16480, loss = 0.268112
I0529 04:17:34.751528 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0529 04:17:34.751535 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.354672 (* 1 = 0.354672 loss)
I0529 04:17:34.751538 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.500866 (* 1 = 0.500866 loss)
I0529 04:17:34.751543 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0459623 (* 1 = 0.0459623 loss)
I0529 04:17:34.751545 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0781249 (* 1 = 0.0781249 loss)
I0529 04:17:34.751551 10644 sgd_solver.cpp:106] Iteration 16480, lr = 0.0002
I0529 04:18:23.309510 10644 solver.cpp:228] Iteration 16500, loss = 0.340806
I0529 04:18:23.309537 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0529 04:18:23.309545 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.422681 (* 1 = 0.422681 loss)
I0529 04:18:23.309550 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.491867 (* 1 = 0.491867 loss)
I0529 04:18:23.309553 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143107 (* 1 = 0.0143107 loss)
I0529 04:18:23.309556 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0968659 (* 1 = 0.0968659 loss)
I0529 04:18:23.309562 10644 sgd_solver.cpp:106] Iteration 16500, lr = 0.0002
I0529 04:19:11.875566 10644 solver.cpp:228] Iteration 16520, loss = 0.280635
I0529 04:19:11.875589 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:19:11.875597 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286631 (* 1 = 0.0286631 loss)
I0529 04:19:11.875602 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.117982 (* 1 = 0.117982 loss)
I0529 04:19:11.875607 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0216974 (* 1 = 0.0216974 loss)
I0529 04:19:11.875609 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.047509 (* 1 = 0.047509 loss)
I0529 04:19:11.875615 10644 sgd_solver.cpp:106] Iteration 16520, lr = 0.0002
I0529 04:20:00.426319 10644 solver.cpp:228] Iteration 16540, loss = 0.350151
I0529 04:20:00.426349 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 04:20:00.426358 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000503043 (* 1 = 0.000503043 loss)
I0529 04:20:00.426362 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0520303 (* 1 = 0.0520303 loss)
I0529 04:20:00.426367 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00750003 (* 1 = 0.00750003 loss)
I0529 04:20:00.426371 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495313 (* 1 = 0.0495313 loss)
I0529 04:20:00.426378 10644 sgd_solver.cpp:106] Iteration 16540, lr = 0.0002
I0529 04:20:48.980828 10644 solver.cpp:228] Iteration 16560, loss = 0.428604
I0529 04:20:48.980854 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 04:20:48.980862 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0874971 (* 1 = 0.0874971 loss)
I0529 04:20:48.980866 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.168044 (* 1 = 0.168044 loss)
I0529 04:20:48.980870 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00855324 (* 1 = 0.00855324 loss)
I0529 04:20:48.980875 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197645 (* 1 = 0.0197645 loss)
I0529 04:20:48.980880 10644 sgd_solver.cpp:106] Iteration 16560, lr = 0.0002
I0529 04:21:37.521836 10644 solver.cpp:228] Iteration 16580, loss = 0.261287
I0529 04:21:37.521863 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 04:21:37.521872 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336028 (* 1 = 0.0336028 loss)
I0529 04:21:37.521876 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.100962 (* 1 = 0.100962 loss)
I0529 04:21:37.521880 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00787022 (* 1 = 0.00787022 loss)
I0529 04:21:37.521884 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00670311 (* 1 = 0.00670311 loss)
I0529 04:21:37.521890 10644 sgd_solver.cpp:106] Iteration 16580, lr = 0.0002
speed: 2.429s / iter
I0529 04:22:26.081113 10644 solver.cpp:228] Iteration 16600, loss = 0.287275
I0529 04:22:26.081140 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:22:26.081148 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593832 (* 1 = 0.0593832 loss)
I0529 04:22:26.081152 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0903208 (* 1 = 0.0903208 loss)
I0529 04:22:26.081157 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00497518 (* 1 = 0.00497518 loss)
I0529 04:22:26.081161 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156946 (* 1 = 0.0156946 loss)
I0529 04:22:26.081166 10644 sgd_solver.cpp:106] Iteration 16600, lr = 0.0002
I0529 04:23:14.625282 10644 solver.cpp:228] Iteration 16620, loss = 0.320458
I0529 04:23:14.625308 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:23:14.625316 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0515645 (* 1 = 0.0515645 loss)
I0529 04:23:14.625320 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0606592 (* 1 = 0.0606592 loss)
I0529 04:23:14.625324 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00640061 (* 1 = 0.00640061 loss)
I0529 04:23:14.625329 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014402 (* 1 = 0.014402 loss)
I0529 04:23:14.625334 10644 sgd_solver.cpp:106] Iteration 16620, lr = 0.0002
I0529 04:24:03.154532 10644 solver.cpp:228] Iteration 16640, loss = 0.186359
I0529 04:24:03.154561 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:24:03.154568 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314444 (* 1 = 0.0314444 loss)
I0529 04:24:03.154572 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0573395 (* 1 = 0.0573395 loss)
I0529 04:24:03.154577 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207778 (* 1 = 0.00207778 loss)
I0529 04:24:03.154580 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148978 (* 1 = 0.0148978 loss)
I0529 04:24:03.154587 10644 sgd_solver.cpp:106] Iteration 16640, lr = 0.0002
I0529 04:24:51.695684 10644 solver.cpp:228] Iteration 16660, loss = 0.186849
I0529 04:24:51.695708 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 04:24:51.695715 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272196 (* 1 = 0.0272196 loss)
I0529 04:24:51.695719 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0262534 (* 1 = 0.0262534 loss)
I0529 04:24:51.695724 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00763904 (* 1 = 0.00763904 loss)
I0529 04:24:51.695726 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00399048 (* 1 = 0.00399048 loss)
I0529 04:24:51.695731 10644 sgd_solver.cpp:106] Iteration 16660, lr = 0.0002
I0529 04:25:40.238149 10644 solver.cpp:228] Iteration 16680, loss = 0.283021
I0529 04:25:40.238174 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 04:25:40.238181 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.17656 (* 1 = 0.17656 loss)
I0529 04:25:40.238185 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.387611 (* 1 = 0.387611 loss)
I0529 04:25:40.238188 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0365479 (* 1 = 0.0365479 loss)
I0529 04:25:40.238193 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0934168 (* 1 = 0.0934168 loss)
I0529 04:25:40.238198 10644 sgd_solver.cpp:106] Iteration 16680, lr = 0.0002
I0529 04:26:28.789685 10644 solver.cpp:228] Iteration 16700, loss = 0.340788
I0529 04:26:28.789712 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 04:26:28.789719 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.115541 (* 1 = 0.115541 loss)
I0529 04:26:28.789722 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.211327 (* 1 = 0.211327 loss)
I0529 04:26:28.789726 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00673111 (* 1 = 0.00673111 loss)
I0529 04:26:28.789731 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0098909 (* 1 = 0.0098909 loss)
I0529 04:26:28.789736 10644 sgd_solver.cpp:106] Iteration 16700, lr = 0.0002
I0529 04:27:17.325364 10644 solver.cpp:228] Iteration 16720, loss = 0.409875
I0529 04:27:17.325389 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:27:17.325399 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400639 (* 1 = 0.0400639 loss)
I0529 04:27:17.325405 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0588199 (* 1 = 0.0588199 loss)
I0529 04:27:17.325410 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00981548 (* 1 = 0.00981548 loss)
I0529 04:27:17.325415 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139403 (* 1 = 0.0139403 loss)
I0529 04:27:17.325422 10644 sgd_solver.cpp:106] Iteration 16720, lr = 0.0002
I0529 04:28:05.866230 10644 solver.cpp:228] Iteration 16740, loss = 0.256114
I0529 04:28:05.866258 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:28:05.866266 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0944685 (* 1 = 0.0944685 loss)
I0529 04:28:05.866271 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.219138 (* 1 = 0.219138 loss)
I0529 04:28:05.866273 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0374715 (* 1 = 0.0374715 loss)
I0529 04:28:05.866277 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0521716 (* 1 = 0.0521716 loss)
I0529 04:28:05.866282 10644 sgd_solver.cpp:106] Iteration 16740, lr = 0.0002
I0529 04:28:54.375983 10644 solver.cpp:228] Iteration 16760, loss = 0.364026
I0529 04:28:54.376008 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:28:54.376015 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0394454 (* 1 = 0.0394454 loss)
I0529 04:28:54.376019 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0939278 (* 1 = 0.0939278 loss)
I0529 04:28:54.376024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00610845 (* 1 = 0.00610845 loss)
I0529 04:28:54.376026 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175942 (* 1 = 0.0175942 loss)
I0529 04:28:54.376031 10644 sgd_solver.cpp:106] Iteration 16760, lr = 0.0002
I0529 04:29:42.935010 10644 solver.cpp:228] Iteration 16780, loss = 0.320741
I0529 04:29:42.935035 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 04:29:42.935042 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.12387 (* 1 = 0.12387 loss)
I0529 04:29:42.935046 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.354594 (* 1 = 0.354594 loss)
I0529 04:29:42.935050 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0225323 (* 1 = 0.0225323 loss)
I0529 04:29:42.935055 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269554 (* 1 = 0.0269554 loss)
I0529 04:29:42.935058 10644 sgd_solver.cpp:106] Iteration 16780, lr = 0.0002
speed: 2.429s / iter
I0529 04:30:31.468448 10644 solver.cpp:228] Iteration 16800, loss = 0.176598
I0529 04:30:31.468474 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 04:30:31.468482 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0146291 (* 1 = 0.0146291 loss)
I0529 04:30:31.468485 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0352725 (* 1 = 0.0352725 loss)
I0529 04:30:31.468489 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00531318 (* 1 = 0.00531318 loss)
I0529 04:30:31.468492 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00211787 (* 1 = 0.00211787 loss)
I0529 04:30:31.468498 10644 sgd_solver.cpp:106] Iteration 16800, lr = 0.0002
I0529 04:31:19.990504 10644 solver.cpp:228] Iteration 16820, loss = 0.261263
I0529 04:31:19.990528 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 04:31:19.990536 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118671 (* 1 = 0.118671 loss)
I0529 04:31:19.990540 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.277927 (* 1 = 0.277927 loss)
I0529 04:31:19.990545 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182776 (* 1 = 0.0182776 loss)
I0529 04:31:19.990548 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0528286 (* 1 = 0.0528286 loss)
I0529 04:31:19.990553 10644 sgd_solver.cpp:106] Iteration 16820, lr = 0.0002
I0529 04:32:08.526813 10644 solver.cpp:228] Iteration 16840, loss = 0.261532
I0529 04:32:08.526844 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:32:08.526851 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537191 (* 1 = 0.0537191 loss)
I0529 04:32:08.526856 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0912505 (* 1 = 0.0912505 loss)
I0529 04:32:08.526859 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162201 (* 1 = 0.00162201 loss)
I0529 04:32:08.526863 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00658276 (* 1 = 0.00658276 loss)
I0529 04:32:08.526868 10644 sgd_solver.cpp:106] Iteration 16840, lr = 0.0002
I0529 04:32:57.049417 10644 solver.cpp:228] Iteration 16860, loss = 0.284382
I0529 04:32:57.049443 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 04:32:57.049450 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00470041 (* 1 = 0.00470041 loss)
I0529 04:32:57.049455 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0361015 (* 1 = 0.0361015 loss)
I0529 04:32:57.049459 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026962 (* 1 = 0.0026962 loss)
I0529 04:32:57.049463 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169277 (* 1 = 0.0169277 loss)
I0529 04:32:57.049468 10644 sgd_solver.cpp:106] Iteration 16860, lr = 0.0002
I0529 04:33:45.601703 10644 solver.cpp:228] Iteration 16880, loss = 0.374114
I0529 04:33:45.601730 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 04:33:45.601737 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.194785 (* 1 = 0.194785 loss)
I0529 04:33:45.601742 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.346119 (* 1 = 0.346119 loss)
I0529 04:33:45.601745 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306051 (* 1 = 0.0306051 loss)
I0529 04:33:45.601749 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0480606 (* 1 = 0.0480606 loss)
I0529 04:33:45.601755 10644 sgd_solver.cpp:106] Iteration 16880, lr = 0.0002
I0529 04:34:34.160315 10644 solver.cpp:228] Iteration 16900, loss = 0.331604
I0529 04:34:34.160343 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 04:34:34.160352 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0833742 (* 1 = 0.0833742 loss)
I0529 04:34:34.160356 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.137437 (* 1 = 0.137437 loss)
I0529 04:34:34.160359 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149925 (* 1 = 0.0149925 loss)
I0529 04:34:34.160363 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142934 (* 1 = 0.0142934 loss)
I0529 04:34:34.160369 10644 sgd_solver.cpp:106] Iteration 16900, lr = 0.0002
I0529 04:35:22.690546 10644 solver.cpp:228] Iteration 16920, loss = 0.347801
I0529 04:35:22.690573 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:35:22.690583 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628452 (* 1 = 0.0628452 loss)
I0529 04:35:22.690589 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.15129 (* 1 = 0.15129 loss)
I0529 04:35:22.690595 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164875 (* 1 = 0.0164875 loss)
I0529 04:35:22.690601 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0953266 (* 1 = 0.0953266 loss)
I0529 04:35:22.690608 10644 sgd_solver.cpp:106] Iteration 16920, lr = 0.0002
I0529 04:36:11.229487 10644 solver.cpp:228] Iteration 16940, loss = 0.210491
I0529 04:36:11.229512 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 04:36:11.229521 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168752 (* 1 = 0.0168752 loss)
I0529 04:36:11.229524 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0495428 (* 1 = 0.0495428 loss)
I0529 04:36:11.229529 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00308668 (* 1 = 0.00308668 loss)
I0529 04:36:11.229532 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0031239 (* 1 = 0.0031239 loss)
I0529 04:36:11.229538 10644 sgd_solver.cpp:106] Iteration 16940, lr = 0.0002
I0529 04:36:59.729737 10644 solver.cpp:228] Iteration 16960, loss = 0.31038
I0529 04:36:59.729763 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 04:36:59.729770 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.254616 (* 1 = 0.254616 loss)
I0529 04:36:59.729774 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.356259 (* 1 = 0.356259 loss)
I0529 04:36:59.729779 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279296 (* 1 = 0.0279296 loss)
I0529 04:36:59.729782 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.048596 (* 1 = 0.048596 loss)
I0529 04:36:59.729787 10644 sgd_solver.cpp:106] Iteration 16960, lr = 0.0002
I0529 04:37:48.272817 10644 solver.cpp:228] Iteration 16980, loss = 0.466561
I0529 04:37:48.272845 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 04:37:48.272852 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.119671 (* 1 = 0.119671 loss)
I0529 04:37:48.272856 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.227656 (* 1 = 0.227656 loss)
I0529 04:37:48.272859 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212314 (* 1 = 0.0212314 loss)
I0529 04:37:48.272862 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491678 (* 1 = 0.0491678 loss)
I0529 04:37:48.272868 10644 sgd_solver.cpp:106] Iteration 16980, lr = 0.0002
speed: 2.429s / iter
I0529 04:38:36.822728 10644 solver.cpp:228] Iteration 17000, loss = 0.236552
I0529 04:38:36.822768 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 04:38:36.822777 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.150905 (* 1 = 0.150905 loss)
I0529 04:38:36.822780 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.395539 (* 1 = 0.395539 loss)
I0529 04:38:36.822784 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166679 (* 1 = 0.0166679 loss)
I0529 04:38:36.822788 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449273 (* 1 = 0.0449273 loss)
I0529 04:38:36.822795 10644 sgd_solver.cpp:106] Iteration 17000, lr = 0.0002
I0529 04:39:25.362041 10644 solver.cpp:228] Iteration 17020, loss = 0.289199
I0529 04:39:25.362066 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:39:25.362073 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.17573 (* 1 = 0.17573 loss)
I0529 04:39:25.362077 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.200806 (* 1 = 0.200806 loss)
I0529 04:39:25.362082 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318609 (* 1 = 0.00318609 loss)
I0529 04:39:25.362084 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345321 (* 1 = 0.0345321 loss)
I0529 04:39:25.362089 10644 sgd_solver.cpp:106] Iteration 17020, lr = 0.0002
I0529 04:40:13.877368 10644 solver.cpp:228] Iteration 17040, loss = 0.506464
I0529 04:40:13.877394 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 04:40:13.877401 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.383114 (* 1 = 0.383114 loss)
I0529 04:40:13.877405 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.376894 (* 1 = 0.376894 loss)
I0529 04:40:13.877408 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.072801 (* 1 = 0.072801 loss)
I0529 04:40:13.877413 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0773534 (* 1 = 0.0773534 loss)
I0529 04:40:13.877418 10644 sgd_solver.cpp:106] Iteration 17040, lr = 0.0002
I0529 04:41:02.409827 10644 solver.cpp:228] Iteration 17060, loss = 0.318437
I0529 04:41:02.409852 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 04:41:02.409860 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393181 (* 1 = 0.0393181 loss)
I0529 04:41:02.409864 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0594236 (* 1 = 0.0594236 loss)
I0529 04:41:02.409868 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124166 (* 1 = 0.0124166 loss)
I0529 04:41:02.409871 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115172 (* 1 = 0.0115172 loss)
I0529 04:41:02.409876 10644 sgd_solver.cpp:106] Iteration 17060, lr = 0.0002
I0529 04:41:50.962846 10644 solver.cpp:228] Iteration 17080, loss = 0.38128
I0529 04:41:50.962872 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 04:41:50.962879 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.182794 (* 1 = 0.182794 loss)
I0529 04:41:50.962883 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.3781 (* 1 = 0.3781 loss)
I0529 04:41:50.962888 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136348 (* 1 = 0.0136348 loss)
I0529 04:41:50.962890 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514557 (* 1 = 0.0514557 loss)
I0529 04:41:50.962898 10644 sgd_solver.cpp:106] Iteration 17080, lr = 0.0002
I0529 04:42:39.515877 10644 solver.cpp:228] Iteration 17100, loss = 0.322126
I0529 04:42:39.515904 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:42:39.515914 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440118 (* 1 = 0.0440118 loss)
I0529 04:42:39.515920 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142616 (* 1 = 0.142616 loss)
I0529 04:42:39.515925 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234153 (* 1 = 0.0234153 loss)
I0529 04:42:39.515931 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00374803 (* 1 = 0.00374803 loss)
I0529 04:42:39.515938 10644 sgd_solver.cpp:106] Iteration 17100, lr = 0.0002
I0529 04:43:28.078789 10644 solver.cpp:228] Iteration 17120, loss = 0.261165
I0529 04:43:28.078814 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:43:28.078822 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0766418 (* 1 = 0.0766418 loss)
I0529 04:43:28.078825 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0574169 (* 1 = 0.0574169 loss)
I0529 04:43:28.078830 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0022538 (* 1 = 0.0022538 loss)
I0529 04:43:28.078832 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0083189 (* 1 = 0.0083189 loss)
I0529 04:43:28.078837 10644 sgd_solver.cpp:106] Iteration 17120, lr = 0.0002
I0529 04:44:16.612392 10644 solver.cpp:228] Iteration 17140, loss = 0.234307
I0529 04:44:16.612422 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 04:44:16.612431 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254179 (* 1 = 0.0254179 loss)
I0529 04:44:16.612435 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10159 (* 1 = 0.10159 loss)
I0529 04:44:16.612438 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150656 (* 1 = 0.0150656 loss)
I0529 04:44:16.612442 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0083023 (* 1 = 0.0083023 loss)
I0529 04:44:16.612448 10644 sgd_solver.cpp:106] Iteration 17140, lr = 0.0002
I0529 04:45:05.180548 10644 solver.cpp:228] Iteration 17160, loss = 0.423895
I0529 04:45:05.180577 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:45:05.180588 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373496 (* 1 = 0.0373496 loss)
I0529 04:45:05.180594 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128718 (* 1 = 0.128718 loss)
I0529 04:45:05.180600 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0439639 (* 1 = 0.0439639 loss)
I0529 04:45:05.180606 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164277 (* 1 = 0.0164277 loss)
I0529 04:45:05.180613 10644 sgd_solver.cpp:106] Iteration 17160, lr = 0.0002
I0529 04:45:53.769429 10644 solver.cpp:228] Iteration 17180, loss = 0.325718
I0529 04:45:53.769454 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 04:45:53.769461 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187576 (* 1 = 0.0187576 loss)
I0529 04:45:53.769465 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0428419 (* 1 = 0.0428419 loss)
I0529 04:45:53.769469 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128027 (* 1 = 0.00128027 loss)
I0529 04:45:53.769474 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207395 (* 1 = 0.0207395 loss)
I0529 04:45:53.769479 10644 sgd_solver.cpp:106] Iteration 17180, lr = 0.0002
speed: 2.429s / iter
I0529 04:46:42.261132 10644 solver.cpp:228] Iteration 17200, loss = 0.303213
I0529 04:46:42.261157 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 04:46:42.261164 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.13373 (* 1 = 0.13373 loss)
I0529 04:46:42.261169 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.23195 (* 1 = 0.23195 loss)
I0529 04:46:42.261173 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208791 (* 1 = 0.0208791 loss)
I0529 04:46:42.261176 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254406 (* 1 = 0.0254406 loss)
I0529 04:46:42.261183 10644 sgd_solver.cpp:106] Iteration 17200, lr = 0.0002
I0529 04:47:30.668056 10644 solver.cpp:228] Iteration 17220, loss = 0.268451
I0529 04:47:30.668083 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:47:30.668090 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321456 (* 1 = 0.0321456 loss)
I0529 04:47:30.668097 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115015 (* 1 = 0.115015 loss)
I0529 04:47:30.668102 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0311664 (* 1 = 0.0311664 loss)
I0529 04:47:30.668107 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116993 (* 1 = 0.0116993 loss)
I0529 04:47:30.668112 10644 sgd_solver.cpp:106] Iteration 17220, lr = 0.0002
I0529 04:48:19.213901 10644 solver.cpp:228] Iteration 17240, loss = 0.31605
I0529 04:48:19.213929 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:48:19.213937 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627538 (* 1 = 0.0627538 loss)
I0529 04:48:19.213941 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.122251 (* 1 = 0.122251 loss)
I0529 04:48:19.213945 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101468 (* 1 = 0.0101468 loss)
I0529 04:48:19.213948 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172626 (* 1 = 0.0172626 loss)
I0529 04:48:19.213954 10644 sgd_solver.cpp:106] Iteration 17240, lr = 0.0002
I0529 04:49:07.804947 10644 solver.cpp:228] Iteration 17260, loss = 0.34424
I0529 04:49:07.804978 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 04:49:07.804986 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.239008 (* 1 = 0.239008 loss)
I0529 04:49:07.804989 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.188677 (* 1 = 0.188677 loss)
I0529 04:49:07.804994 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00690788 (* 1 = 0.00690788 loss)
I0529 04:49:07.804998 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433756 (* 1 = 0.0433756 loss)
I0529 04:49:07.805004 10644 sgd_solver.cpp:106] Iteration 17260, lr = 0.0002
I0529 04:49:56.351858 10644 solver.cpp:228] Iteration 17280, loss = 0.274203
I0529 04:49:56.351884 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 04:49:56.351892 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0389659 (* 1 = 0.0389659 loss)
I0529 04:49:56.351897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.116396 (* 1 = 0.116396 loss)
I0529 04:49:56.351902 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160212 (* 1 = 0.0160212 loss)
I0529 04:49:56.351905 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430181 (* 1 = 0.0430181 loss)
I0529 04:49:56.351910 10644 sgd_solver.cpp:106] Iteration 17280, lr = 0.0002
I0529 04:50:44.903298 10644 solver.cpp:228] Iteration 17300, loss = 0.332861
I0529 04:50:44.903326 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 04:50:44.903332 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0877905 (* 1 = 0.0877905 loss)
I0529 04:50:44.903337 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.122788 (* 1 = 0.122788 loss)
I0529 04:50:44.903340 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00526425 (* 1 = 0.00526425 loss)
I0529 04:50:44.903343 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101291 (* 1 = 0.0101291 loss)
I0529 04:50:44.903348 10644 sgd_solver.cpp:106] Iteration 17300, lr = 0.0002
I0529 04:51:33.446192 10644 solver.cpp:228] Iteration 17320, loss = 0.427445
I0529 04:51:33.446218 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 04:51:33.446225 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.338189 (* 1 = 0.338189 loss)
I0529 04:51:33.446228 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234941 (* 1 = 0.234941 loss)
I0529 04:51:33.446233 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00599466 (* 1 = 0.00599466 loss)
I0529 04:51:33.446236 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452517 (* 1 = 0.0452517 loss)
I0529 04:51:33.446240 10644 sgd_solver.cpp:106] Iteration 17320, lr = 0.0002
I0529 04:52:22.037084 10644 solver.cpp:228] Iteration 17340, loss = 0.356685
I0529 04:52:22.037112 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 04:52:22.037118 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.152612 (* 1 = 0.152612 loss)
I0529 04:52:22.037122 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.268893 (* 1 = 0.268893 loss)
I0529 04:52:22.037127 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00339629 (* 1 = 0.00339629 loss)
I0529 04:52:22.037130 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0386351 (* 1 = 0.0386351 loss)
I0529 04:52:22.037134 10644 sgd_solver.cpp:106] Iteration 17340, lr = 0.0002
I0529 04:53:10.556427 10644 solver.cpp:228] Iteration 17360, loss = 0.264471
I0529 04:53:10.556452 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 04:53:10.556460 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0250325 (* 1 = 0.0250325 loss)
I0529 04:53:10.556464 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0419221 (* 1 = 0.0419221 loss)
I0529 04:53:10.556468 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110031 (* 1 = 0.0110031 loss)
I0529 04:53:10.556470 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213384 (* 1 = 0.0213384 loss)
I0529 04:53:10.556476 10644 sgd_solver.cpp:106] Iteration 17360, lr = 0.0002
I0529 04:53:59.100744 10644 solver.cpp:228] Iteration 17380, loss = 0.182241
I0529 04:53:59.100769 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:53:59.100775 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0512042 (* 1 = 0.0512042 loss)
I0529 04:53:59.100780 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108654 (* 1 = 0.108654 loss)
I0529 04:53:59.100782 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133319 (* 1 = 0.0133319 loss)
I0529 04:53:59.100785 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157975 (* 1 = 0.0157975 loss)
I0529 04:53:59.100790 10644 sgd_solver.cpp:106] Iteration 17380, lr = 0.0002
speed: 2.429s / iter
I0529 04:54:47.627454 10644 solver.cpp:228] Iteration 17400, loss = 0.416204
I0529 04:54:47.627480 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 04:54:47.627486 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591845 (* 1 = 0.0591845 loss)
I0529 04:54:47.627490 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.147468 (* 1 = 0.147468 loss)
I0529 04:54:47.627494 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0401395 (* 1 = 0.0401395 loss)
I0529 04:54:47.627497 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0299715 (* 1 = 0.0299715 loss)
I0529 04:54:47.627502 10644 sgd_solver.cpp:106] Iteration 17400, lr = 0.0002
I0529 04:55:36.187717 10644 solver.cpp:228] Iteration 17420, loss = 0.247001
I0529 04:55:36.187742 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 04:55:36.187749 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0263845 (* 1 = 0.0263845 loss)
I0529 04:55:36.187753 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.137107 (* 1 = 0.137107 loss)
I0529 04:55:36.187757 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00199282 (* 1 = 0.00199282 loss)
I0529 04:55:36.187760 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00429747 (* 1 = 0.00429747 loss)
I0529 04:55:36.187765 10644 sgd_solver.cpp:106] Iteration 17420, lr = 0.0002
I0529 04:56:24.733559 10644 solver.cpp:228] Iteration 17440, loss = 0.36158
I0529 04:56:24.733583 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 04:56:24.733592 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432529 (* 1 = 0.0432529 loss)
I0529 04:56:24.733595 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0405767 (* 1 = 0.0405767 loss)
I0529 04:56:24.733598 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00279886 (* 1 = 0.00279886 loss)
I0529 04:56:24.733602 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132334 (* 1 = 0.0132334 loss)
I0529 04:56:24.733608 10644 sgd_solver.cpp:106] Iteration 17440, lr = 0.0002
I0529 04:57:13.255192 10644 solver.cpp:228] Iteration 17460, loss = 0.183273
I0529 04:57:13.255221 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 04:57:13.255228 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.132962 (* 1 = 0.132962 loss)
I0529 04:57:13.255233 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.254354 (* 1 = 0.254354 loss)
I0529 04:57:13.255236 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164117 (* 1 = 0.0164117 loss)
I0529 04:57:13.255240 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0407992 (* 1 = 0.0407992 loss)
I0529 04:57:13.255246 10644 sgd_solver.cpp:106] Iteration 17460, lr = 0.0002
I0529 04:58:01.818224 10644 solver.cpp:228] Iteration 17480, loss = 0.261752
I0529 04:58:01.818253 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 04:58:01.818261 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244769 (* 1 = 0.0244769 loss)
I0529 04:58:01.818267 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0720249 (* 1 = 0.0720249 loss)
I0529 04:58:01.818274 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128122 (* 1 = 0.00128122 loss)
I0529 04:58:01.818280 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00627455 (* 1 = 0.00627455 loss)
I0529 04:58:01.818287 10644 sgd_solver.cpp:106] Iteration 17480, lr = 0.0002
I0529 04:58:50.346583 10644 solver.cpp:228] Iteration 17500, loss = 0.295361
I0529 04:58:50.346611 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 04:58:50.346619 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0704948 (* 1 = 0.0704948 loss)
I0529 04:58:50.346623 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0932102 (* 1 = 0.0932102 loss)
I0529 04:58:50.346627 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00894498 (* 1 = 0.00894498 loss)
I0529 04:58:50.346632 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00799621 (* 1 = 0.00799621 loss)
I0529 04:58:50.346637 10644 sgd_solver.cpp:106] Iteration 17500, lr = 0.0002
I0529 04:59:38.891278 10644 solver.cpp:228] Iteration 17520, loss = 0.374305
I0529 04:59:38.891306 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 04:59:38.891314 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335835 (* 1 = 0.0335835 loss)
I0529 04:59:38.891319 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.070122 (* 1 = 0.070122 loss)
I0529 04:59:38.891322 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00520034 (* 1 = 0.00520034 loss)
I0529 04:59:38.891326 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00446406 (* 1 = 0.00446406 loss)
I0529 04:59:38.891331 10644 sgd_solver.cpp:106] Iteration 17520, lr = 0.0002
I0529 05:00:27.446465 10644 solver.cpp:228] Iteration 17540, loss = 0.224061
I0529 05:00:27.446491 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 05:00:27.446501 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.131468 (* 1 = 0.131468 loss)
I0529 05:00:27.446508 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.214386 (* 1 = 0.214386 loss)
I0529 05:00:27.446514 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174066 (* 1 = 0.0174066 loss)
I0529 05:00:27.446519 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029871 (* 1 = 0.029871 loss)
I0529 05:00:27.446527 10644 sgd_solver.cpp:106] Iteration 17540, lr = 0.0002
I0529 05:01:16.015172 10644 solver.cpp:228] Iteration 17560, loss = 0.202818
I0529 05:01:16.015203 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 05:01:16.015213 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0779026 (* 1 = 0.0779026 loss)
I0529 05:01:16.015219 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.16386 (* 1 = 0.16386 loss)
I0529 05:01:16.015226 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00886566 (* 1 = 0.00886566 loss)
I0529 05:01:16.015233 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115569 (* 1 = 0.0115569 loss)
I0529 05:01:16.015239 10644 sgd_solver.cpp:106] Iteration 17560, lr = 0.0002
I0529 05:02:04.563738 10644 solver.cpp:228] Iteration 17580, loss = 0.448905
I0529 05:02:04.563766 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 05:02:04.563774 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.137505 (* 1 = 0.137505 loss)
I0529 05:02:04.563778 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174469 (* 1 = 0.174469 loss)
I0529 05:02:04.563782 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00655282 (* 1 = 0.00655282 loss)
I0529 05:02:04.563786 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193556 (* 1 = 0.0193556 loss)
I0529 05:02:04.563792 10644 sgd_solver.cpp:106] Iteration 17580, lr = 0.0002
speed: 2.429s / iter
I0529 05:02:53.105542 10644 solver.cpp:228] Iteration 17600, loss = 0.255448
I0529 05:02:53.105567 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:02:53.105576 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0202842 (* 1 = 0.0202842 loss)
I0529 05:02:53.105581 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.070072 (* 1 = 0.070072 loss)
I0529 05:02:53.105584 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00823857 (* 1 = 0.00823857 loss)
I0529 05:02:53.105587 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130621 (* 1 = 0.0130621 loss)
I0529 05:02:53.105593 10644 sgd_solver.cpp:106] Iteration 17600, lr = 0.0002
I0529 05:03:41.672727 10644 solver.cpp:228] Iteration 17620, loss = 0.264736
I0529 05:03:41.672756 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 05:03:41.672766 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.195408 (* 1 = 0.195408 loss)
I0529 05:03:41.672772 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.285185 (* 1 = 0.285185 loss)
I0529 05:03:41.672778 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130797 (* 1 = 0.0130797 loss)
I0529 05:03:41.672783 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356008 (* 1 = 0.0356008 loss)
I0529 05:03:41.672791 10644 sgd_solver.cpp:106] Iteration 17620, lr = 0.0002
I0529 05:04:30.219475 10644 solver.cpp:228] Iteration 17640, loss = 0.334316
I0529 05:04:30.219501 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 05:04:30.219507 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.10447 (* 1 = 0.10447 loss)
I0529 05:04:30.219511 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0926642 (* 1 = 0.0926642 loss)
I0529 05:04:30.219516 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00290674 (* 1 = 0.00290674 loss)
I0529 05:04:30.219518 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00890517 (* 1 = 0.00890517 loss)
I0529 05:04:30.219523 10644 sgd_solver.cpp:106] Iteration 17640, lr = 0.0002
I0529 05:05:18.760893 10644 solver.cpp:228] Iteration 17660, loss = 0.256936
I0529 05:05:18.760926 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:05:18.760933 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468176 (* 1 = 0.0468176 loss)
I0529 05:05:18.760937 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0629064 (* 1 = 0.0629064 loss)
I0529 05:05:18.760941 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216539 (* 1 = 0.00216539 loss)
I0529 05:05:18.760944 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189003 (* 1 = 0.0189003 loss)
I0529 05:05:18.760949 10644 sgd_solver.cpp:106] Iteration 17660, lr = 0.0002
I0529 05:06:07.289281 10644 solver.cpp:228] Iteration 17680, loss = 0.269318
I0529 05:06:07.289305 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 05:06:07.289314 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0738182 (* 1 = 0.0738182 loss)
I0529 05:06:07.289317 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.199306 (* 1 = 0.199306 loss)
I0529 05:06:07.289320 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00707062 (* 1 = 0.00707062 loss)
I0529 05:06:07.289324 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284347 (* 1 = 0.0284347 loss)
I0529 05:06:07.289330 10644 sgd_solver.cpp:106] Iteration 17680, lr = 0.0002
I0529 05:06:55.834734 10644 solver.cpp:228] Iteration 17700, loss = 0.264349
I0529 05:06:55.834763 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:06:55.834770 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562105 (* 1 = 0.0562105 loss)
I0529 05:06:55.834774 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0735516 (* 1 = 0.0735516 loss)
I0529 05:06:55.834777 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491802 (* 1 = 0.00491802 loss)
I0529 05:06:55.834781 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174767 (* 1 = 0.0174767 loss)
I0529 05:06:55.834786 10644 sgd_solver.cpp:106] Iteration 17700, lr = 0.0002
I0529 05:07:44.379693 10644 solver.cpp:228] Iteration 17720, loss = 0.462735
I0529 05:07:44.379717 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 05:07:44.379724 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0732512 (* 1 = 0.0732512 loss)
I0529 05:07:44.379729 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.241944 (* 1 = 0.241944 loss)
I0529 05:07:44.379732 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281543 (* 1 = 0.0281543 loss)
I0529 05:07:44.379735 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0076864 (* 1 = 0.0076864 loss)
I0529 05:07:44.379740 10644 sgd_solver.cpp:106] Iteration 17720, lr = 0.0002
I0529 05:08:32.937831 10644 solver.cpp:228] Iteration 17740, loss = 0.410188
I0529 05:08:32.937856 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 05:08:32.937863 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0670039 (* 1 = 0.0670039 loss)
I0529 05:08:32.937867 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151478 (* 1 = 0.151478 loss)
I0529 05:08:32.937870 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140777 (* 1 = 0.0140777 loss)
I0529 05:08:32.937873 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0521227 (* 1 = 0.0521227 loss)
I0529 05:08:32.937880 10644 sgd_solver.cpp:106] Iteration 17740, lr = 0.0002
I0529 05:09:21.510637 10644 solver.cpp:228] Iteration 17760, loss = 0.377474
I0529 05:09:21.510661 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:09:21.510668 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415113 (* 1 = 0.0415113 loss)
I0529 05:09:21.510674 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0579089 (* 1 = 0.0579089 loss)
I0529 05:09:21.510680 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105193 (* 1 = 0.00105193 loss)
I0529 05:09:21.510684 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106245 (* 1 = 0.0106245 loss)
I0529 05:09:21.510689 10644 sgd_solver.cpp:106] Iteration 17760, lr = 0.0002
I0529 05:10:10.039153 10644 solver.cpp:228] Iteration 17780, loss = 0.320578
I0529 05:10:10.039181 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 05:10:10.039189 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.097893 (* 1 = 0.097893 loss)
I0529 05:10:10.039193 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.33948 (* 1 = 0.33948 loss)
I0529 05:10:10.039197 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015429 (* 1 = 0.015429 loss)
I0529 05:10:10.039201 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372588 (* 1 = 0.0372588 loss)
I0529 05:10:10.039206 10644 sgd_solver.cpp:106] Iteration 17780, lr = 0.0002
speed: 2.429s / iter
I0529 05:10:58.553922 10644 solver.cpp:228] Iteration 17800, loss = 0.283556
I0529 05:10:58.553947 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 05:10:58.553956 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912941 (* 1 = 0.0912941 loss)
I0529 05:10:58.553959 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.159125 (* 1 = 0.159125 loss)
I0529 05:10:58.553963 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880282 (* 1 = 0.00880282 loss)
I0529 05:10:58.553967 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323047 (* 1 = 0.0323047 loss)
I0529 05:10:58.553972 10644 sgd_solver.cpp:106] Iteration 17800, lr = 0.0002
I0529 05:11:47.102864 10644 solver.cpp:228] Iteration 17820, loss = 0.246865
I0529 05:11:47.102891 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 05:11:47.102900 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.06522 (* 1 = 0.06522 loss)
I0529 05:11:47.102903 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0915561 (* 1 = 0.0915561 loss)
I0529 05:11:47.102907 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00425408 (* 1 = 0.00425408 loss)
I0529 05:11:47.102912 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019967 (* 1 = 0.019967 loss)
I0529 05:11:47.102917 10644 sgd_solver.cpp:106] Iteration 17820, lr = 0.0002
I0529 05:12:35.655738 10644 solver.cpp:228] Iteration 17840, loss = 0.21173
I0529 05:12:35.655764 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:12:35.655772 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0603221 (* 1 = 0.0603221 loss)
I0529 05:12:35.655776 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0546099 (* 1 = 0.0546099 loss)
I0529 05:12:35.655781 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114298 (* 1 = 0.0114298 loss)
I0529 05:12:35.655784 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272947 (* 1 = 0.0272947 loss)
I0529 05:12:35.655791 10644 sgd_solver.cpp:106] Iteration 17840, lr = 0.0002
I0529 05:13:24.199110 10644 solver.cpp:228] Iteration 17860, loss = 0.398394
I0529 05:13:24.199136 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 05:13:24.199143 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433146 (* 1 = 0.0433146 loss)
I0529 05:13:24.199148 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.217336 (* 1 = 0.217336 loss)
I0529 05:13:24.199151 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0412097 (* 1 = 0.0412097 loss)
I0529 05:13:24.199156 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314142 (* 1 = 0.0314142 loss)
I0529 05:13:24.199160 10644 sgd_solver.cpp:106] Iteration 17860, lr = 0.0002
I0529 05:14:12.753626 10644 solver.cpp:228] Iteration 17880, loss = 0.323442
I0529 05:14:12.753657 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:14:12.753667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843541 (* 1 = 0.0843541 loss)
I0529 05:14:12.753674 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0599925 (* 1 = 0.0599925 loss)
I0529 05:14:12.753680 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00471207 (* 1 = 0.00471207 loss)
I0529 05:14:12.753686 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182164 (* 1 = 0.0182164 loss)
I0529 05:14:12.753693 10644 sgd_solver.cpp:106] Iteration 17880, lr = 0.0002
I0529 05:15:01.326781 10644 solver.cpp:228] Iteration 17900, loss = 0.409123
I0529 05:15:01.326809 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:15:01.326817 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0211634 (* 1 = 0.0211634 loss)
I0529 05:15:01.326822 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0678098 (* 1 = 0.0678098 loss)
I0529 05:15:01.326825 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00441155 (* 1 = 0.00441155 loss)
I0529 05:15:01.326829 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121399 (* 1 = 0.0121399 loss)
I0529 05:15:01.326835 10644 sgd_solver.cpp:106] Iteration 17900, lr = 0.0002
I0529 05:15:49.884371 10644 solver.cpp:228] Iteration 17920, loss = 0.282949
I0529 05:15:49.884397 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 05:15:49.884404 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0503541 (* 1 = 0.0503541 loss)
I0529 05:15:49.884409 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.081595 (* 1 = 0.081595 loss)
I0529 05:15:49.884413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171781 (* 1 = 0.00171781 loss)
I0529 05:15:49.884416 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00842695 (* 1 = 0.00842695 loss)
I0529 05:15:49.884423 10644 sgd_solver.cpp:106] Iteration 17920, lr = 0.0002
I0529 05:16:38.416973 10644 solver.cpp:228] Iteration 17940, loss = 0.346044
I0529 05:16:38.417006 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 05:16:38.417016 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0967613 (* 1 = 0.0967613 loss)
I0529 05:16:38.417022 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.183506 (* 1 = 0.183506 loss)
I0529 05:16:38.417027 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100099 (* 1 = 0.0100099 loss)
I0529 05:16:38.417032 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142427 (* 1 = 0.0142427 loss)
I0529 05:16:38.417039 10644 sgd_solver.cpp:106] Iteration 17940, lr = 0.0002
I0529 05:17:26.977310 10644 solver.cpp:228] Iteration 17960, loss = 0.385761
I0529 05:17:26.977336 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 05:17:26.977345 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526946 (* 1 = 0.0526946 loss)
I0529 05:17:26.977350 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0789319 (* 1 = 0.0789319 loss)
I0529 05:17:26.977356 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00661425 (* 1 = 0.00661425 loss)
I0529 05:17:26.977362 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00628022 (* 1 = 0.00628022 loss)
I0529 05:17:26.977368 10644 sgd_solver.cpp:106] Iteration 17960, lr = 0.0002
I0529 05:18:15.528465 10644 solver.cpp:228] Iteration 17980, loss = 0.37355
I0529 05:18:15.528489 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 05:18:15.528496 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117456 (* 1 = 0.117456 loss)
I0529 05:18:15.528501 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.183322 (* 1 = 0.183322 loss)
I0529 05:18:15.528503 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00725858 (* 1 = 0.00725858 loss)
I0529 05:18:15.528507 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274511 (* 1 = 0.0274511 loss)
I0529 05:18:15.528512 10644 sgd_solver.cpp:106] Iteration 17980, lr = 0.0002
speed: 2.429s / iter
I0529 05:19:04.080844 10644 solver.cpp:228] Iteration 18000, loss = 0.421427
I0529 05:19:04.080871 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 05:19:04.080880 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822388 (* 1 = 0.0822388 loss)
I0529 05:19:04.080886 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.165973 (* 1 = 0.165973 loss)
I0529 05:19:04.080893 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600702 (* 1 = 0.00600702 loss)
I0529 05:19:04.080898 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138784 (* 1 = 0.0138784 loss)
I0529 05:19:04.080904 10644 sgd_solver.cpp:106] Iteration 18000, lr = 0.0002
I0529 05:19:52.608698 10644 solver.cpp:228] Iteration 18020, loss = 0.302272
I0529 05:19:52.608723 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:19:52.608731 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278009 (* 1 = 0.0278009 loss)
I0529 05:19:52.608736 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0716576 (* 1 = 0.0716576 loss)
I0529 05:19:52.608738 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168193 (* 1 = 0.00168193 loss)
I0529 05:19:52.608742 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00432317 (* 1 = 0.00432317 loss)
I0529 05:19:52.608747 10644 sgd_solver.cpp:106] Iteration 18020, lr = 0.0002
I0529 05:20:41.124794 10644 solver.cpp:228] Iteration 18040, loss = 0.461009
I0529 05:20:41.124819 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 05:20:41.124828 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0850603 (* 1 = 0.0850603 loss)
I0529 05:20:41.124835 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.171363 (* 1 = 0.171363 loss)
I0529 05:20:41.124840 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00839342 (* 1 = 0.00839342 loss)
I0529 05:20:41.124846 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226577 (* 1 = 0.0226577 loss)
I0529 05:20:41.124852 10644 sgd_solver.cpp:106] Iteration 18040, lr = 0.0002
I0529 05:21:29.671313 10644 solver.cpp:228] Iteration 18060, loss = 0.390981
I0529 05:21:29.671337 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 05:21:29.671344 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.253466 (* 1 = 0.253466 loss)
I0529 05:21:29.671347 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.423429 (* 1 = 0.423429 loss)
I0529 05:21:29.671351 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0901842 (* 1 = 0.0901842 loss)
I0529 05:21:29.671355 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.245017 (* 1 = 0.245017 loss)
I0529 05:21:29.671360 10644 sgd_solver.cpp:106] Iteration 18060, lr = 0.0002
I0529 05:22:18.224179 10644 solver.cpp:228] Iteration 18080, loss = 0.337554
I0529 05:22:18.224205 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 05:22:18.224211 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.196702 (* 1 = 0.196702 loss)
I0529 05:22:18.224215 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.335011 (* 1 = 0.335011 loss)
I0529 05:22:18.224220 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0687646 (* 1 = 0.0687646 loss)
I0529 05:22:18.224222 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102564 (* 1 = 0.102564 loss)
I0529 05:22:18.224227 10644 sgd_solver.cpp:106] Iteration 18080, lr = 0.0002
I0529 05:23:06.741829 10644 solver.cpp:228] Iteration 18100, loss = 0.372315
I0529 05:23:06.741854 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:23:06.741863 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106622 (* 1 = 0.0106622 loss)
I0529 05:23:06.741868 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0897424 (* 1 = 0.0897424 loss)
I0529 05:23:06.741871 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330193 (* 1 = 0.00330193 loss)
I0529 05:23:06.741874 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00221411 (* 1 = 0.00221411 loss)
I0529 05:23:06.741880 10644 sgd_solver.cpp:106] Iteration 18100, lr = 0.0002
I0529 05:23:55.295567 10644 solver.cpp:228] Iteration 18120, loss = 0.471912
I0529 05:23:55.295591 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 05:23:55.295600 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.127397 (* 1 = 0.127397 loss)
I0529 05:23:55.295604 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.216695 (* 1 = 0.216695 loss)
I0529 05:23:55.295608 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00954377 (* 1 = 0.00954377 loss)
I0529 05:23:55.295611 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142839 (* 1 = 0.0142839 loss)
I0529 05:23:55.295616 10644 sgd_solver.cpp:106] Iteration 18120, lr = 0.0002
I0529 05:24:43.863149 10644 solver.cpp:228] Iteration 18140, loss = 0.339541
I0529 05:24:43.863178 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 05:24:43.863186 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0512542 (* 1 = 0.0512542 loss)
I0529 05:24:43.863190 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109376 (* 1 = 0.109376 loss)
I0529 05:24:43.863194 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113107 (* 1 = 0.0113107 loss)
I0529 05:24:43.863198 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229628 (* 1 = 0.0229628 loss)
I0529 05:24:43.863204 10644 sgd_solver.cpp:106] Iteration 18140, lr = 0.0002
I0529 05:25:32.415323 10644 solver.cpp:228] Iteration 18160, loss = 0.339176
I0529 05:25:32.415349 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:25:32.415355 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521191 (* 1 = 0.0521191 loss)
I0529 05:25:32.415360 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113612 (* 1 = 0.113612 loss)
I0529 05:25:32.415364 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0238188 (* 1 = 0.0238188 loss)
I0529 05:25:32.415367 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301478 (* 1 = 0.0301478 loss)
I0529 05:25:32.415372 10644 sgd_solver.cpp:106] Iteration 18160, lr = 0.0002
I0529 05:26:20.988993 10644 solver.cpp:228] Iteration 18180, loss = 0.37181
I0529 05:26:20.989019 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:26:20.989027 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276942 (* 1 = 0.0276942 loss)
I0529 05:26:20.989032 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0411147 (* 1 = 0.0411147 loss)
I0529 05:26:20.989035 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00468004 (* 1 = 0.00468004 loss)
I0529 05:26:20.989039 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00175573 (* 1 = 0.00175573 loss)
I0529 05:26:20.989044 10644 sgd_solver.cpp:106] Iteration 18180, lr = 0.0002
speed: 2.429s / iter
I0529 05:27:09.535755 10644 solver.cpp:228] Iteration 18200, loss = 0.243123
I0529 05:27:09.535787 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 05:27:09.535796 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649382 (* 1 = 0.0649382 loss)
I0529 05:27:09.535800 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.132006 (* 1 = 0.132006 loss)
I0529 05:27:09.535804 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424733 (* 1 = 0.00424733 loss)
I0529 05:27:09.535809 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283515 (* 1 = 0.0283515 loss)
I0529 05:27:09.535815 10644 sgd_solver.cpp:106] Iteration 18200, lr = 0.0002
I0529 05:27:58.050652 10644 solver.cpp:228] Iteration 18220, loss = 0.313396
I0529 05:27:58.050679 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 05:27:58.050688 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0893754 (* 1 = 0.0893754 loss)
I0529 05:27:58.050691 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.127849 (* 1 = 0.127849 loss)
I0529 05:27:58.050695 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00473399 (* 1 = 0.00473399 loss)
I0529 05:27:58.050699 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182683 (* 1 = 0.0182683 loss)
I0529 05:27:58.050704 10644 sgd_solver.cpp:106] Iteration 18220, lr = 0.0002
I0529 05:28:46.607317 10644 solver.cpp:228] Iteration 18240, loss = 0.314733
I0529 05:28:46.607345 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:28:46.607353 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336889 (* 1 = 0.0336889 loss)
I0529 05:28:46.607357 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0517508 (* 1 = 0.0517508 loss)
I0529 05:28:46.607362 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00622929 (* 1 = 0.00622929 loss)
I0529 05:28:46.607367 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273143 (* 1 = 0.0273143 loss)
I0529 05:28:46.607372 10644 sgd_solver.cpp:106] Iteration 18240, lr = 0.0002
I0529 05:29:35.185286 10644 solver.cpp:228] Iteration 18260, loss = 0.30981
I0529 05:29:35.185313 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 05:29:35.185320 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0919327 (* 1 = 0.0919327 loss)
I0529 05:29:35.185325 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.15847 (* 1 = 0.15847 loss)
I0529 05:29:35.185328 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102043 (* 1 = 0.0102043 loss)
I0529 05:29:35.185331 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271135 (* 1 = 0.0271135 loss)
I0529 05:29:35.185338 10644 sgd_solver.cpp:106] Iteration 18260, lr = 0.0002
I0529 05:30:23.716616 10644 solver.cpp:228] Iteration 18280, loss = 0.234607
I0529 05:30:23.716644 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 05:30:23.716650 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0908769 (* 1 = 0.0908769 loss)
I0529 05:30:23.716655 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.332268 (* 1 = 0.332268 loss)
I0529 05:30:23.716658 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212766 (* 1 = 0.0212766 loss)
I0529 05:30:23.716661 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274082 (* 1 = 0.0274082 loss)
I0529 05:30:23.716666 10644 sgd_solver.cpp:106] Iteration 18280, lr = 0.0002
I0529 05:31:12.264369 10644 solver.cpp:228] Iteration 18300, loss = 0.309005
I0529 05:31:12.264394 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:31:12.264402 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0425373 (* 1 = 0.0425373 loss)
I0529 05:31:12.264408 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0965426 (* 1 = 0.0965426 loss)
I0529 05:31:12.264413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376561 (* 1 = 0.00376561 loss)
I0529 05:31:12.264420 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104349 (* 1 = 0.0104349 loss)
I0529 05:31:12.264426 10644 sgd_solver.cpp:106] Iteration 18300, lr = 0.0002
I0529 05:32:00.827327 10644 solver.cpp:228] Iteration 18320, loss = 0.232934
I0529 05:32:00.827353 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:32:00.827360 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229446 (* 1 = 0.0229446 loss)
I0529 05:32:00.827364 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0545317 (* 1 = 0.0545317 loss)
I0529 05:32:00.827368 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338703 (* 1 = 0.00338703 loss)
I0529 05:32:00.827371 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00872319 (* 1 = 0.00872319 loss)
I0529 05:32:00.827378 10644 sgd_solver.cpp:106] Iteration 18320, lr = 0.0002
I0529 05:32:49.381836 10644 solver.cpp:228] Iteration 18340, loss = 0.242584
I0529 05:32:49.381862 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 05:32:49.381870 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.120217 (* 1 = 0.120217 loss)
I0529 05:32:49.381873 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.299688 (* 1 = 0.299688 loss)
I0529 05:32:49.381876 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0582082 (* 1 = 0.0582082 loss)
I0529 05:32:49.381880 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315827 (* 1 = 0.0315827 loss)
I0529 05:32:49.381884 10644 sgd_solver.cpp:106] Iteration 18340, lr = 0.0002
I0529 05:33:37.899701 10644 solver.cpp:228] Iteration 18360, loss = 0.245014
I0529 05:33:37.899730 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 05:33:37.899739 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0429354 (* 1 = 0.0429354 loss)
I0529 05:33:37.899745 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.107079 (* 1 = 0.107079 loss)
I0529 05:33:37.899751 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00472459 (* 1 = 0.00472459 loss)
I0529 05:33:37.899756 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176741 (* 1 = 0.0176741 loss)
I0529 05:33:37.899763 10644 sgd_solver.cpp:106] Iteration 18360, lr = 0.0002
I0529 05:34:26.448151 10644 solver.cpp:228] Iteration 18380, loss = 0.369509
I0529 05:34:26.448176 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 05:34:26.448185 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251263 (* 1 = 0.0251263 loss)
I0529 05:34:26.448191 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.06506 (* 1 = 0.06506 loss)
I0529 05:34:26.448196 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00871514 (* 1 = 0.00871514 loss)
I0529 05:34:26.448202 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00793669 (* 1 = 0.00793669 loss)
I0529 05:34:26.448209 10644 sgd_solver.cpp:106] Iteration 18380, lr = 0.0002
speed: 2.429s / iter
I0529 05:35:15.023785 10644 solver.cpp:228] Iteration 18400, loss = 0.374538
I0529 05:35:15.023811 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 05:35:15.023819 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0019416 (* 1 = 0.0019416 loss)
I0529 05:35:15.023824 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0434052 (* 1 = 0.0434052 loss)
I0529 05:35:15.023830 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00582608 (* 1 = 0.00582608 loss)
I0529 05:35:15.023833 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138642 (* 1 = 0.0138642 loss)
I0529 05:35:15.023838 10644 sgd_solver.cpp:106] Iteration 18400, lr = 0.0002
I0529 05:36:03.557353 10644 solver.cpp:228] Iteration 18420, loss = 0.256025
I0529 05:36:03.557380 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 05:36:03.557389 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467235 (* 1 = 0.0467235 loss)
I0529 05:36:03.557394 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.119921 (* 1 = 0.119921 loss)
I0529 05:36:03.557397 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035894 (* 1 = 0.0035894 loss)
I0529 05:36:03.557400 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00358918 (* 1 = 0.00358918 loss)
I0529 05:36:03.557406 10644 sgd_solver.cpp:106] Iteration 18420, lr = 0.0002
I0529 05:36:52.107002 10644 solver.cpp:228] Iteration 18440, loss = 0.350294
I0529 05:36:52.107033 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 05:36:52.107041 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0569401 (* 1 = 0.0569401 loss)
I0529 05:36:52.107045 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.212378 (* 1 = 0.212378 loss)
I0529 05:36:52.107049 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256212 (* 1 = 0.0256212 loss)
I0529 05:36:52.107053 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338285 (* 1 = 0.0338285 loss)
I0529 05:36:52.107059 10644 sgd_solver.cpp:106] Iteration 18440, lr = 0.0002
I0529 05:37:40.663036 10644 solver.cpp:228] Iteration 18460, loss = 0.218263
I0529 05:37:40.663066 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 05:37:40.663076 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0446685 (* 1 = 0.0446685 loss)
I0529 05:37:40.663084 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0997353 (* 1 = 0.0997353 loss)
I0529 05:37:40.663090 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147583 (* 1 = 0.0147583 loss)
I0529 05:37:40.663096 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245573 (* 1 = 0.0245573 loss)
I0529 05:37:40.663103 10644 sgd_solver.cpp:106] Iteration 18460, lr = 0.0002
I0529 05:38:29.193769 10644 solver.cpp:228] Iteration 18480, loss = 0.388787
I0529 05:38:29.193796 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 05:38:29.193806 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.235399 (* 1 = 0.235399 loss)
I0529 05:38:29.193814 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.162327 (* 1 = 0.162327 loss)
I0529 05:38:29.193819 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154862 (* 1 = 0.0154862 loss)
I0529 05:38:29.193825 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0581869 (* 1 = 0.0581869 loss)
I0529 05:38:29.193833 10644 sgd_solver.cpp:106] Iteration 18480, lr = 0.0002
I0529 05:39:17.752326 10644 solver.cpp:228] Iteration 18500, loss = 0.47251
I0529 05:39:17.752352 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 05:39:17.752360 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.16045 (* 1 = 0.16045 loss)
I0529 05:39:17.752365 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.355743 (* 1 = 0.355743 loss)
I0529 05:39:17.752368 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0403914 (* 1 = 0.0403914 loss)
I0529 05:39:17.752372 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600249 (* 1 = 0.0600249 loss)
I0529 05:39:17.752377 10644 sgd_solver.cpp:106] Iteration 18500, lr = 0.0002
I0529 05:40:06.298869 10644 solver.cpp:228] Iteration 18520, loss = 0.295792
I0529 05:40:06.298897 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 05:40:06.298905 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.049843 (* 1 = 0.049843 loss)
I0529 05:40:06.298909 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101131 (* 1 = 0.101131 loss)
I0529 05:40:06.298914 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00340686 (* 1 = 0.00340686 loss)
I0529 05:40:06.298918 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151901 (* 1 = 0.0151901 loss)
I0529 05:40:06.298923 10644 sgd_solver.cpp:106] Iteration 18520, lr = 0.0002
I0529 05:40:54.851097 10644 solver.cpp:228] Iteration 18540, loss = 0.205315
I0529 05:40:54.851124 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 05:40:54.851131 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318924 (* 1 = 0.0318924 loss)
I0529 05:40:54.851138 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.119156 (* 1 = 0.119156 loss)
I0529 05:40:54.851142 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0076492 (* 1 = 0.0076492 loss)
I0529 05:40:54.851146 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183446 (* 1 = 0.0183446 loss)
I0529 05:40:54.851152 10644 sgd_solver.cpp:106] Iteration 18540, lr = 0.0002
I0529 05:41:43.424568 10644 solver.cpp:228] Iteration 18560, loss = 0.250862
I0529 05:41:43.424594 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:41:43.424602 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430779 (* 1 = 0.0430779 loss)
I0529 05:41:43.424607 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.059344 (* 1 = 0.059344 loss)
I0529 05:41:43.424610 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0463775 (* 1 = 0.0463775 loss)
I0529 05:41:43.424614 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176962 (* 1 = 0.0176962 loss)
I0529 05:41:43.424620 10644 sgd_solver.cpp:106] Iteration 18560, lr = 0.0002
I0529 05:42:31.973484 10644 solver.cpp:228] Iteration 18580, loss = 0.183615
I0529 05:42:31.973508 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:42:31.973515 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400218 (* 1 = 0.0400218 loss)
I0529 05:42:31.973520 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0879875 (* 1 = 0.0879875 loss)
I0529 05:42:31.973523 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014982 (* 1 = 0.014982 loss)
I0529 05:42:31.973526 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237553 (* 1 = 0.0237553 loss)
I0529 05:42:31.973531 10644 sgd_solver.cpp:106] Iteration 18580, lr = 0.0002
speed: 2.429s / iter
I0529 05:43:20.518543 10644 solver.cpp:228] Iteration 18600, loss = 0.323514
I0529 05:43:20.518571 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 05:43:20.518580 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.159842 (* 1 = 0.159842 loss)
I0529 05:43:20.518586 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.48056 (* 1 = 0.48056 loss)
I0529 05:43:20.518591 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.065038 (* 1 = 0.065038 loss)
I0529 05:43:20.518596 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.126933 (* 1 = 0.126933 loss)
I0529 05:43:20.518604 10644 sgd_solver.cpp:106] Iteration 18600, lr = 0.0002
I0529 05:44:09.064554 10644 solver.cpp:228] Iteration 18620, loss = 0.202072
I0529 05:44:09.064579 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:44:09.064586 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00893368 (* 1 = 0.00893368 loss)
I0529 05:44:09.064590 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0442281 (* 1 = 0.0442281 loss)
I0529 05:44:09.064594 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102971 (* 1 = 0.0102971 loss)
I0529 05:44:09.064597 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00693821 (* 1 = 0.00693821 loss)
I0529 05:44:09.064604 10644 sgd_solver.cpp:106] Iteration 18620, lr = 0.0002
I0529 05:44:57.606916 10644 solver.cpp:228] Iteration 18640, loss = 0.277271
I0529 05:44:57.606942 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 05:44:57.606950 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0377777 (* 1 = 0.0377777 loss)
I0529 05:44:57.606953 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114687 (* 1 = 0.114687 loss)
I0529 05:44:57.606957 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195202 (* 1 = 0.0195202 loss)
I0529 05:44:57.606961 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0496477 (* 1 = 0.0496477 loss)
I0529 05:44:57.606966 10644 sgd_solver.cpp:106] Iteration 18640, lr = 0.0002
I0529 05:45:46.138460 10644 solver.cpp:228] Iteration 18660, loss = 0.235218
I0529 05:45:46.138487 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 05:45:46.138494 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.059359 (* 1 = 0.059359 loss)
I0529 05:45:46.138499 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.130801 (* 1 = 0.130801 loss)
I0529 05:45:46.138502 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0085674 (* 1 = 0.0085674 loss)
I0529 05:45:46.138505 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167558 (* 1 = 0.0167558 loss)
I0529 05:45:46.138510 10644 sgd_solver.cpp:106] Iteration 18660, lr = 0.0002
I0529 05:46:34.677834 10644 solver.cpp:228] Iteration 18680, loss = 0.313148
I0529 05:46:34.677863 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 05:46:34.677872 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0408121 (* 1 = 0.0408121 loss)
I0529 05:46:34.677878 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157562 (* 1 = 0.157562 loss)
I0529 05:46:34.677884 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105384 (* 1 = 0.0105384 loss)
I0529 05:46:34.677889 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107083 (* 1 = 0.0107083 loss)
I0529 05:46:34.677896 10644 sgd_solver.cpp:106] Iteration 18680, lr = 0.0002
I0529 05:47:23.237377 10644 solver.cpp:228] Iteration 18700, loss = 0.282526
I0529 05:47:23.237411 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 05:47:23.237421 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.159391 (* 1 = 0.159391 loss)
I0529 05:47:23.237426 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.262035 (* 1 = 0.262035 loss)
I0529 05:47:23.237432 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00844424 (* 1 = 0.00844424 loss)
I0529 05:47:23.237439 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0641035 (* 1 = 0.0641035 loss)
I0529 05:47:23.237447 10644 sgd_solver.cpp:106] Iteration 18700, lr = 0.0002
I0529 05:48:11.781332 10644 solver.cpp:228] Iteration 18720, loss = 0.332769
I0529 05:48:11.781357 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 05:48:11.781363 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.143224 (* 1 = 0.143224 loss)
I0529 05:48:11.781368 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.205808 (* 1 = 0.205808 loss)
I0529 05:48:11.781370 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017293 (* 1 = 0.017293 loss)
I0529 05:48:11.781373 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0459409 (* 1 = 0.0459409 loss)
I0529 05:48:11.781378 10644 sgd_solver.cpp:106] Iteration 18720, lr = 0.0002
I0529 05:49:00.309984 10644 solver.cpp:228] Iteration 18740, loss = 0.24265
I0529 05:49:00.310009 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 05:49:00.310017 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0810877 (* 1 = 0.0810877 loss)
I0529 05:49:00.310021 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.191691 (* 1 = 0.191691 loss)
I0529 05:49:00.310025 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174383 (* 1 = 0.0174383 loss)
I0529 05:49:00.310029 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180751 (* 1 = 0.0180751 loss)
I0529 05:49:00.310034 10644 sgd_solver.cpp:106] Iteration 18740, lr = 0.0002
I0529 05:49:48.864981 10644 solver.cpp:228] Iteration 18760, loss = 0.216201
I0529 05:49:48.865008 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 05:49:48.865020 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0230075 (* 1 = 0.0230075 loss)
I0529 05:49:48.865025 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0244546 (* 1 = 0.0244546 loss)
I0529 05:49:48.865032 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00477632 (* 1 = 0.00477632 loss)
I0529 05:49:48.865038 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166812 (* 1 = 0.0166812 loss)
I0529 05:49:48.865046 10644 sgd_solver.cpp:106] Iteration 18760, lr = 0.0002
I0529 05:50:37.412330 10644 solver.cpp:228] Iteration 18780, loss = 0.381347
I0529 05:50:37.412355 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 05:50:37.412364 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.186949 (* 1 = 0.186949 loss)
I0529 05:50:37.412369 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.166667 (* 1 = 0.166667 loss)
I0529 05:50:37.412372 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128902 (* 1 = 0.00128902 loss)
I0529 05:50:37.412376 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353249 (* 1 = 0.0353249 loss)
I0529 05:50:37.412382 10644 sgd_solver.cpp:106] Iteration 18780, lr = 0.0002
speed: 2.429s / iter
I0529 05:51:25.941721 10644 solver.cpp:228] Iteration 18800, loss = 0.410524
I0529 05:51:25.941747 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 05:51:25.941757 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.284429 (* 1 = 0.284429 loss)
I0529 05:51:25.941764 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.396427 (* 1 = 0.396427 loss)
I0529 05:51:25.941771 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0509589 (* 1 = 0.0509589 loss)
I0529 05:51:25.941776 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0719304 (* 1 = 0.0719304 loss)
I0529 05:51:25.941783 10644 sgd_solver.cpp:106] Iteration 18800, lr = 0.0002
I0529 05:52:14.471191 10644 solver.cpp:228] Iteration 18820, loss = 0.370831
I0529 05:52:14.471217 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:52:14.471227 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00482496 (* 1 = 0.00482496 loss)
I0529 05:52:14.471235 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0365239 (* 1 = 0.0365239 loss)
I0529 05:52:14.471240 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315089 (* 1 = 0.00315089 loss)
I0529 05:52:14.471246 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00384539 (* 1 = 0.00384539 loss)
I0529 05:52:14.471253 10644 sgd_solver.cpp:106] Iteration 18820, lr = 0.0002
I0529 05:53:03.013659 10644 solver.cpp:228] Iteration 18840, loss = 0.308163
I0529 05:53:03.013684 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 05:53:03.013692 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.033895 (* 1 = 0.033895 loss)
I0529 05:53:03.013696 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.199379 (* 1 = 0.199379 loss)
I0529 05:53:03.013700 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199291 (* 1 = 0.0199291 loss)
I0529 05:53:03.013705 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0706915 (* 1 = 0.0706915 loss)
I0529 05:53:03.013710 10644 sgd_solver.cpp:106] Iteration 18840, lr = 0.0002
I0529 05:53:51.557586 10644 solver.cpp:228] Iteration 18860, loss = 0.239943
I0529 05:53:51.557612 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 05:53:51.557621 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.221167 (* 1 = 0.221167 loss)
I0529 05:53:51.557626 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.260796 (* 1 = 0.260796 loss)
I0529 05:53:51.557632 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00707817 (* 1 = 0.00707817 loss)
I0529 05:53:51.557637 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0363473 (* 1 = 0.0363473 loss)
I0529 05:53:51.557643 10644 sgd_solver.cpp:106] Iteration 18860, lr = 0.0002
I0529 05:54:40.080250 10644 solver.cpp:228] Iteration 18880, loss = 0.414675
I0529 05:54:40.080276 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 05:54:40.080284 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.319029 (* 1 = 0.319029 loss)
I0529 05:54:40.080291 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.372147 (* 1 = 0.372147 loss)
I0529 05:54:40.080296 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00885569 (* 1 = 0.00885569 loss)
I0529 05:54:40.080302 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0917228 (* 1 = 0.0917228 loss)
I0529 05:54:40.080308 10644 sgd_solver.cpp:106] Iteration 18880, lr = 0.0002
I0529 05:55:28.631255 10644 solver.cpp:228] Iteration 18900, loss = 0.181395
I0529 05:55:28.631284 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 05:55:28.631291 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00043867 (* 1 = 0.00043867 loss)
I0529 05:55:28.631296 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0510404 (* 1 = 0.0510404 loss)
I0529 05:55:28.631300 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260803 (* 1 = 0.0260803 loss)
I0529 05:55:28.631304 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0476553 (* 1 = 0.0476553 loss)
I0529 05:55:28.631309 10644 sgd_solver.cpp:106] Iteration 18900, lr = 0.0002
I0529 05:56:17.198621 10644 solver.cpp:228] Iteration 18920, loss = 0.206755
I0529 05:56:17.198648 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 05:56:17.198655 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435601 (* 1 = 0.0435601 loss)
I0529 05:56:17.198660 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.106851 (* 1 = 0.106851 loss)
I0529 05:56:17.198664 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00974963 (* 1 = 0.00974963 loss)
I0529 05:56:17.198668 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260101 (* 1 = 0.0260101 loss)
I0529 05:56:17.198673 10644 sgd_solver.cpp:106] Iteration 18920, lr = 0.0002
I0529 05:57:05.744153 10644 solver.cpp:228] Iteration 18940, loss = 0.392974
I0529 05:57:05.744180 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 05:57:05.744187 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189388 (* 1 = 0.0189388 loss)
I0529 05:57:05.744191 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0448927 (* 1 = 0.0448927 loss)
I0529 05:57:05.744196 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00327629 (* 1 = 0.00327629 loss)
I0529 05:57:05.744201 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00228053 (* 1 = 0.00228053 loss)
I0529 05:57:05.744207 10644 sgd_solver.cpp:106] Iteration 18940, lr = 0.0002
I0529 05:57:54.325865 10644 solver.cpp:228] Iteration 18960, loss = 0.339289
I0529 05:57:54.325896 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 05:57:54.325903 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682866 (* 1 = 0.0682866 loss)
I0529 05:57:54.325907 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0753417 (* 1 = 0.0753417 loss)
I0529 05:57:54.325911 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00743547 (* 1 = 0.00743547 loss)
I0529 05:57:54.325915 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171103 (* 1 = 0.0171103 loss)
I0529 05:57:54.325922 10644 sgd_solver.cpp:106] Iteration 18960, lr = 0.0002
I0529 05:58:42.880419 10644 solver.cpp:228] Iteration 18980, loss = 0.25692
I0529 05:58:42.880442 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 05:58:42.880451 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.101178 (* 1 = 0.101178 loss)
I0529 05:58:42.880455 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151415 (* 1 = 0.151415 loss)
I0529 05:58:42.880460 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117003 (* 1 = 0.0117003 loss)
I0529 05:58:42.880463 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.051738 (* 1 = 0.051738 loss)
I0529 05:58:42.880468 10644 sgd_solver.cpp:106] Iteration 18980, lr = 0.0002
speed: 2.429s / iter
I0529 05:59:31.402248 10644 solver.cpp:228] Iteration 19000, loss = 0.618619
I0529 05:59:31.402274 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 05:59:31.402282 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00239207 (* 1 = 0.00239207 loss)
I0529 05:59:31.402287 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0390817 (* 1 = 0.0390817 loss)
I0529 05:59:31.402290 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027538 (* 1 = 0.027538 loss)
I0529 05:59:31.402294 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130748 (* 1 = 0.0130748 loss)
I0529 05:59:31.402299 10644 sgd_solver.cpp:106] Iteration 19000, lr = 0.0002
I0529 06:00:19.944316 10644 solver.cpp:228] Iteration 19020, loss = 0.210336
I0529 06:00:19.944344 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:00:19.944350 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0491645 (* 1 = 0.0491645 loss)
I0529 06:00:19.944355 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0647599 (* 1 = 0.0647599 loss)
I0529 06:00:19.944358 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00285516 (* 1 = 0.00285516 loss)
I0529 06:00:19.944362 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00625649 (* 1 = 0.00625649 loss)
I0529 06:00:19.944368 10644 sgd_solver.cpp:106] Iteration 19020, lr = 0.0002
I0529 06:01:08.524971 10644 solver.cpp:228] Iteration 19040, loss = 0.208775
I0529 06:01:08.525002 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:01:08.525012 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172898 (* 1 = 0.0172898 loss)
I0529 06:01:08.525018 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0503924 (* 1 = 0.0503924 loss)
I0529 06:01:08.525024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00574955 (* 1 = 0.00574955 loss)
I0529 06:01:08.525030 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113754 (* 1 = 0.0113754 loss)
I0529 06:01:08.525038 10644 sgd_solver.cpp:106] Iteration 19040, lr = 0.0002
I0529 06:01:57.050652 10644 solver.cpp:228] Iteration 19060, loss = 0.303029
I0529 06:01:57.050676 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:01:57.050683 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0451667 (* 1 = 0.0451667 loss)
I0529 06:01:57.050688 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0851866 (* 1 = 0.0851866 loss)
I0529 06:01:57.050691 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00302689 (* 1 = 0.00302689 loss)
I0529 06:01:57.050695 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151139 (* 1 = 0.0151139 loss)
I0529 06:01:57.050699 10644 sgd_solver.cpp:106] Iteration 19060, lr = 0.0002
I0529 06:02:45.594023 10644 solver.cpp:228] Iteration 19080, loss = 0.308008
I0529 06:02:45.594049 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:02:45.594058 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402075 (* 1 = 0.0402075 loss)
I0529 06:02:45.594061 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0389513 (* 1 = 0.0389513 loss)
I0529 06:02:45.594065 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00311645 (* 1 = 0.00311645 loss)
I0529 06:02:45.594069 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00896348 (* 1 = 0.00896348 loss)
I0529 06:02:45.594074 10644 sgd_solver.cpp:106] Iteration 19080, lr = 0.0002
I0529 06:03:34.153308 10644 solver.cpp:228] Iteration 19100, loss = 0.329236
I0529 06:03:34.153336 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 06:03:34.153342 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000916263 (* 1 = 0.000916263 loss)
I0529 06:03:34.153347 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0489345 (* 1 = 0.0489345 loss)
I0529 06:03:34.153349 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00768974 (* 1 = 0.00768974 loss)
I0529 06:03:34.153353 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254616 (* 1 = 0.0254616 loss)
I0529 06:03:34.153358 10644 sgd_solver.cpp:106] Iteration 19100, lr = 0.0002
I0529 06:04:22.747462 10644 solver.cpp:228] Iteration 19120, loss = 0.416371
I0529 06:04:22.747488 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 06:04:22.747495 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.203094 (* 1 = 0.203094 loss)
I0529 06:04:22.747499 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.428191 (* 1 = 0.428191 loss)
I0529 06:04:22.747503 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188338 (* 1 = 0.0188338 loss)
I0529 06:04:22.747505 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036008 (* 1 = 0.036008 loss)
I0529 06:04:22.747511 10644 sgd_solver.cpp:106] Iteration 19120, lr = 0.0002
I0529 06:05:11.319510 10644 solver.cpp:228] Iteration 19140, loss = 0.343992
I0529 06:05:11.319535 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 06:05:11.319542 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.076503 (* 1 = 0.076503 loss)
I0529 06:05:11.319546 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0932683 (* 1 = 0.0932683 loss)
I0529 06:05:11.319550 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00247455 (* 1 = 0.00247455 loss)
I0529 06:05:11.319553 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150506 (* 1 = 0.0150506 loss)
I0529 06:05:11.319558 10644 sgd_solver.cpp:106] Iteration 19140, lr = 0.0002
I0529 06:05:59.882660 10644 solver.cpp:228] Iteration 19160, loss = 0.442312
I0529 06:05:59.882689 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 06:05:59.882696 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.101952 (* 1 = 0.101952 loss)
I0529 06:05:59.882700 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.130565 (* 1 = 0.130565 loss)
I0529 06:05:59.882704 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01078 (* 1 = 0.01078 loss)
I0529 06:05:59.882707 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014777 (* 1 = 0.014777 loss)
I0529 06:05:59.882714 10644 sgd_solver.cpp:106] Iteration 19160, lr = 0.0002
I0529 06:06:48.437542 10644 solver.cpp:228] Iteration 19180, loss = 0.239692
I0529 06:06:48.437568 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:06:48.437577 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0307777 (* 1 = 0.0307777 loss)
I0529 06:06:48.437579 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0631406 (* 1 = 0.0631406 loss)
I0529 06:06:48.437583 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275669 (* 1 = 0.00275669 loss)
I0529 06:06:48.437587 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322434 (* 1 = 0.00322434 loss)
I0529 06:06:48.437592 10644 sgd_solver.cpp:106] Iteration 19180, lr = 0.0002
speed: 2.429s / iter
I0529 06:07:36.998663 10644 solver.cpp:228] Iteration 19200, loss = 0.358342
I0529 06:07:36.998697 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:07:36.998708 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276186 (* 1 = 0.0276186 loss)
I0529 06:07:36.998715 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0515205 (* 1 = 0.0515205 loss)
I0529 06:07:36.998720 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028409 (* 1 = 0.0028409 loss)
I0529 06:07:36.998726 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149538 (* 1 = 0.0149538 loss)
I0529 06:07:36.998734 10644 sgd_solver.cpp:106] Iteration 19200, lr = 0.0002
I0529 06:08:25.514755 10644 solver.cpp:228] Iteration 19220, loss = 0.26522
I0529 06:08:25.514782 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 06:08:25.514789 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118941 (* 1 = 0.118941 loss)
I0529 06:08:25.514794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.202425 (* 1 = 0.202425 loss)
I0529 06:08:25.514798 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00605612 (* 1 = 0.00605612 loss)
I0529 06:08:25.514802 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124148 (* 1 = 0.0124148 loss)
I0529 06:08:25.514807 10644 sgd_solver.cpp:106] Iteration 19220, lr = 0.0002
I0529 06:09:14.090682 10644 solver.cpp:228] Iteration 19240, loss = 0.493611
I0529 06:09:14.090709 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 06:09:14.090718 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.148803 (* 1 = 0.148803 loss)
I0529 06:09:14.090721 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.202284 (* 1 = 0.202284 loss)
I0529 06:09:14.090726 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106313 (* 1 = 0.0106313 loss)
I0529 06:09:14.090729 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0595214 (* 1 = 0.0595214 loss)
I0529 06:09:14.090735 10644 sgd_solver.cpp:106] Iteration 19240, lr = 0.0002
I0529 06:10:02.636291 10644 solver.cpp:228] Iteration 19260, loss = 0.40639
I0529 06:10:02.636327 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:10:02.636334 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839538 (* 1 = 0.0839538 loss)
I0529 06:10:02.636338 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.162677 (* 1 = 0.162677 loss)
I0529 06:10:02.636343 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0365122 (* 1 = 0.0365122 loss)
I0529 06:10:02.636346 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337934 (* 1 = 0.0337934 loss)
I0529 06:10:02.636353 10644 sgd_solver.cpp:106] Iteration 19260, lr = 0.0002
I0529 06:10:51.173493 10644 solver.cpp:228] Iteration 19280, loss = 0.264974
I0529 06:10:51.173523 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:10:51.173534 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0418017 (* 1 = 0.0418017 loss)
I0529 06:10:51.173540 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0499437 (* 1 = 0.0499437 loss)
I0529 06:10:51.173547 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238892 (* 1 = 0.00238892 loss)
I0529 06:10:51.173552 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00442919 (* 1 = 0.00442919 loss)
I0529 06:10:51.173560 10644 sgd_solver.cpp:106] Iteration 19280, lr = 0.0002
I0529 06:11:39.721813 10644 solver.cpp:228] Iteration 19300, loss = 0.622478
I0529 06:11:39.721843 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:11:39.721850 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430274 (* 1 = 0.0430274 loss)
I0529 06:11:39.721854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0837607 (* 1 = 0.0837607 loss)
I0529 06:11:39.721858 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00328548 (* 1 = 0.00328548 loss)
I0529 06:11:39.721863 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144849 (* 1 = 0.0144849 loss)
I0529 06:11:39.721868 10644 sgd_solver.cpp:106] Iteration 19300, lr = 0.0002
I0529 06:12:28.276069 10644 solver.cpp:228] Iteration 19320, loss = 0.227988
I0529 06:12:28.276113 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:12:28.276121 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0970815 (* 1 = 0.0970815 loss)
I0529 06:12:28.276125 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.141367 (* 1 = 0.141367 loss)
I0529 06:12:28.276130 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00973162 (* 1 = 0.00973162 loss)
I0529 06:12:28.276134 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566726 (* 1 = 0.0566726 loss)
I0529 06:12:28.276142 10644 sgd_solver.cpp:106] Iteration 19320, lr = 0.0002
I0529 06:13:16.842814 10644 solver.cpp:228] Iteration 19340, loss = 0.294242
I0529 06:13:16.842841 10644 solver.cpp:244]     Train net output #0: accuarcy = 1
I0529 06:13:16.842849 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189872 (* 1 = 0.0189872 loss)
I0529 06:13:16.842854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0469972 (* 1 = 0.0469972 loss)
I0529 06:13:16.842859 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00280066 (* 1 = 0.00280066 loss)
I0529 06:13:16.842862 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00745644 (* 1 = 0.00745644 loss)
I0529 06:13:16.842867 10644 sgd_solver.cpp:106] Iteration 19340, lr = 0.0002
I0529 06:14:05.421794 10644 solver.cpp:228] Iteration 19360, loss = 0.373473
I0529 06:14:05.421819 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:14:05.421828 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245263 (* 1 = 0.0245263 loss)
I0529 06:14:05.421834 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0598006 (* 1 = 0.0598006 loss)
I0529 06:14:05.421839 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128447 (* 1 = 0.0128447 loss)
I0529 06:14:05.421844 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162599 (* 1 = 0.0162599 loss)
I0529 06:14:05.421850 10644 sgd_solver.cpp:106] Iteration 19360, lr = 0.0002
I0529 06:14:53.996641 10644 solver.cpp:228] Iteration 19380, loss = 0.445366
I0529 06:14:53.996670 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 06:14:53.996676 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.098945 (* 1 = 0.098945 loss)
I0529 06:14:53.996680 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151096 (* 1 = 0.151096 loss)
I0529 06:14:53.996685 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00791755 (* 1 = 0.00791755 loss)
I0529 06:14:53.996687 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127643 (* 1 = 0.0127643 loss)
I0529 06:14:53.996692 10644 sgd_solver.cpp:106] Iteration 19380, lr = 0.0002
speed: 2.429s / iter
I0529 06:15:42.551251 10644 solver.cpp:228] Iteration 19400, loss = 0.278943
I0529 06:15:42.551277 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 06:15:42.551285 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.232021 (* 1 = 0.232021 loss)
I0529 06:15:42.551288 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.323491 (* 1 = 0.323491 loss)
I0529 06:15:42.551292 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00796747 (* 1 = 0.00796747 loss)
I0529 06:15:42.551296 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289449 (* 1 = 0.0289449 loss)
I0529 06:15:42.551301 10644 sgd_solver.cpp:106] Iteration 19400, lr = 0.0002
I0529 06:16:31.094779 10644 solver.cpp:228] Iteration 19420, loss = 0.318269
I0529 06:16:31.094805 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:16:31.094812 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.242423 (* 1 = 0.242423 loss)
I0529 06:16:31.094818 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.180377 (* 1 = 0.180377 loss)
I0529 06:16:31.094825 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00593669 (* 1 = 0.00593669 loss)
I0529 06:16:31.094830 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0442475 (* 1 = 0.0442475 loss)
I0529 06:16:31.094836 10644 sgd_solver.cpp:106] Iteration 19420, lr = 0.0002
I0529 06:17:19.633617 10644 solver.cpp:228] Iteration 19440, loss = 0.244953
I0529 06:17:19.633642 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 06:17:19.633649 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.164529 (* 1 = 0.164529 loss)
I0529 06:17:19.633653 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.235957 (* 1 = 0.235957 loss)
I0529 06:17:19.633656 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109339 (* 1 = 0.0109339 loss)
I0529 06:17:19.633659 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142593 (* 1 = 0.0142593 loss)
I0529 06:17:19.633666 10644 sgd_solver.cpp:106] Iteration 19440, lr = 0.0002
I0529 06:18:08.175473 10644 solver.cpp:228] Iteration 19460, loss = 0.388061
I0529 06:18:08.175498 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0529 06:18:08.175504 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.68243 (* 1 = 0.68243 loss)
I0529 06:18:08.175508 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.648509 (* 1 = 0.648509 loss)
I0529 06:18:08.175513 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0371467 (* 1 = 0.0371467 loss)
I0529 06:18:08.175515 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.22047 (* 1 = 0.22047 loss)
I0529 06:18:08.175520 10644 sgd_solver.cpp:106] Iteration 19460, lr = 0.0002
I0529 06:18:56.736057 10644 solver.cpp:228] Iteration 19480, loss = 0.336421
I0529 06:18:56.736081 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 06:18:56.736088 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.329373 (* 1 = 0.329373 loss)
I0529 06:18:56.736093 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.498058 (* 1 = 0.498058 loss)
I0529 06:18:56.736096 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0309793 (* 1 = 0.0309793 loss)
I0529 06:18:56.736099 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.098209 (* 1 = 0.098209 loss)
I0529 06:18:56.736104 10644 sgd_solver.cpp:106] Iteration 19480, lr = 0.0002
I0529 06:19:45.310940 10644 solver.cpp:228] Iteration 19500, loss = 0.323562
I0529 06:19:45.310966 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 06:19:45.310973 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513249 (* 1 = 0.0513249 loss)
I0529 06:19:45.310977 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152221 (* 1 = 0.152221 loss)
I0529 06:19:45.310981 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103623 (* 1 = 0.0103623 loss)
I0529 06:19:45.310984 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224228 (* 1 = 0.0224228 loss)
I0529 06:19:45.310989 10644 sgd_solver.cpp:106] Iteration 19500, lr = 0.0002
I0529 06:20:33.876073 10644 solver.cpp:228] Iteration 19520, loss = 0.565131
I0529 06:20:33.876101 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 06:20:33.876109 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.27646 (* 1 = 0.27646 loss)
I0529 06:20:33.876113 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.379904 (* 1 = 0.379904 loss)
I0529 06:20:33.876117 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203756 (* 1 = 0.0203756 loss)
I0529 06:20:33.876121 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0769709 (* 1 = 0.0769709 loss)
I0529 06:20:33.876127 10644 sgd_solver.cpp:106] Iteration 19520, lr = 0.0002
I0529 06:21:22.425217 10644 solver.cpp:228] Iteration 19540, loss = 0.278858
I0529 06:21:22.425246 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 06:21:22.425256 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.16781 (* 1 = 0.16781 loss)
I0529 06:21:22.425262 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.269547 (* 1 = 0.269547 loss)
I0529 06:21:22.425268 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143741 (* 1 = 0.00143741 loss)
I0529 06:21:22.425274 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0447205 (* 1 = 0.0447205 loss)
I0529 06:21:22.425282 10644 sgd_solver.cpp:106] Iteration 19540, lr = 0.0002
I0529 06:22:10.961067 10644 solver.cpp:228] Iteration 19560, loss = 0.374947
I0529 06:22:10.961094 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:22:10.961102 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454432 (* 1 = 0.0454432 loss)
I0529 06:22:10.961107 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.138821 (* 1 = 0.138821 loss)
I0529 06:22:10.961110 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134767 (* 1 = 0.0134767 loss)
I0529 06:22:10.961113 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167424 (* 1 = 0.0167424 loss)
I0529 06:22:10.961119 10644 sgd_solver.cpp:106] Iteration 19560, lr = 0.0002
I0529 06:22:59.519135 10644 solver.cpp:228] Iteration 19580, loss = 0.258668
I0529 06:22:59.519163 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 06:22:59.519172 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.111229 (* 1 = 0.111229 loss)
I0529 06:22:59.519178 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.234599 (* 1 = 0.234599 loss)
I0529 06:22:59.519184 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160086 (* 1 = 0.0160086 loss)
I0529 06:22:59.519191 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176462 (* 1 = 0.0176462 loss)
I0529 06:22:59.519198 10644 sgd_solver.cpp:106] Iteration 19580, lr = 0.0002
speed: 2.429s / iter
I0529 06:23:48.061980 10644 solver.cpp:228] Iteration 19600, loss = 0.276076
I0529 06:23:48.062010 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:23:48.062019 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254217 (* 1 = 0.0254217 loss)
I0529 06:23:48.062026 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0539095 (* 1 = 0.0539095 loss)
I0529 06:23:48.062032 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275703 (* 1 = 0.00275703 loss)
I0529 06:23:48.062038 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00475362 (* 1 = 0.00475362 loss)
I0529 06:23:48.062047 10644 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I0529 06:24:36.634508 10644 solver.cpp:228] Iteration 19620, loss = 0.382448
I0529 06:24:36.634538 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:24:36.634546 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181614 (* 1 = 0.0181614 loss)
I0529 06:24:36.634552 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0617117 (* 1 = 0.0617117 loss)
I0529 06:24:36.634555 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149913 (* 1 = 0.00149913 loss)
I0529 06:24:36.634560 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00959276 (* 1 = 0.00959276 loss)
I0529 06:24:36.634567 10644 sgd_solver.cpp:106] Iteration 19620, lr = 0.0002
I0529 06:25:25.168009 10644 solver.cpp:228] Iteration 19640, loss = 0.344921
I0529 06:25:25.168037 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 06:25:25.168047 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.109704 (* 1 = 0.109704 loss)
I0529 06:25:25.168054 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.17699 (* 1 = 0.17699 loss)
I0529 06:25:25.168061 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00934317 (* 1 = 0.00934317 loss)
I0529 06:25:25.168066 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036583 (* 1 = 0.036583 loss)
I0529 06:25:25.168073 10644 sgd_solver.cpp:106] Iteration 19640, lr = 0.0002
I0529 06:26:13.661664 10644 solver.cpp:228] Iteration 19660, loss = 0.271685
I0529 06:26:13.661689 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:26:13.661697 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312179 (* 1 = 0.0312179 loss)
I0529 06:26:13.661701 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0723202 (* 1 = 0.0723202 loss)
I0529 06:26:13.661705 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00655343 (* 1 = 0.00655343 loss)
I0529 06:26:13.661710 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100773 (* 1 = 0.0100773 loss)
I0529 06:26:13.661715 10644 sgd_solver.cpp:106] Iteration 19660, lr = 0.0002
I0529 06:27:02.089226 10644 solver.cpp:228] Iteration 19680, loss = 0.280188
I0529 06:27:02.089248 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:27:02.089256 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402242 (* 1 = 0.0402242 loss)
I0529 06:27:02.089262 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0577901 (* 1 = 0.0577901 loss)
I0529 06:27:02.089267 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00566041 (* 1 = 0.00566041 loss)
I0529 06:27:02.089272 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189936 (* 1 = 0.0189936 loss)
I0529 06:27:02.089277 10644 sgd_solver.cpp:106] Iteration 19680, lr = 0.0002
I0529 06:27:50.634555 10644 solver.cpp:228] Iteration 19700, loss = 0.219729
I0529 06:27:50.634580 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:27:50.634588 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229076 (* 1 = 0.0229076 loss)
I0529 06:27:50.634591 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0886498 (* 1 = 0.0886498 loss)
I0529 06:27:50.634595 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210648 (* 1 = 0.0210648 loss)
I0529 06:27:50.634598 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219417 (* 1 = 0.0219417 loss)
I0529 06:27:50.634603 10644 sgd_solver.cpp:106] Iteration 19700, lr = 0.0002
I0529 06:28:39.189857 10644 solver.cpp:228] Iteration 19720, loss = 0.239372
I0529 06:28:39.189884 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:28:39.189891 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.184287 (* 1 = 0.184287 loss)
I0529 06:28:39.189894 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142199 (* 1 = 0.142199 loss)
I0529 06:28:39.189898 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00489123 (* 1 = 0.00489123 loss)
I0529 06:28:39.189901 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163723 (* 1 = 0.0163723 loss)
I0529 06:28:39.189906 10644 sgd_solver.cpp:106] Iteration 19720, lr = 0.0002
I0529 06:29:27.734088 10644 solver.cpp:228] Iteration 19740, loss = 0.183788
I0529 06:29:27.734113 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 06:29:27.734119 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0904425 (* 1 = 0.0904425 loss)
I0529 06:29:27.734123 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.162564 (* 1 = 0.162564 loss)
I0529 06:29:27.734127 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111308 (* 1 = 0.0111308 loss)
I0529 06:29:27.734130 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128062 (* 1 = 0.0128062 loss)
I0529 06:29:27.734135 10644 sgd_solver.cpp:106] Iteration 19740, lr = 0.0002
I0529 06:30:16.262692 10644 solver.cpp:228] Iteration 19760, loss = 0.221242
I0529 06:30:16.262719 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:30:16.262727 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0669198 (* 1 = 0.0669198 loss)
I0529 06:30:16.262730 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0607555 (* 1 = 0.0607555 loss)
I0529 06:30:16.262733 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.020275 (* 1 = 0.020275 loss)
I0529 06:30:16.262737 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175563 (* 1 = 0.0175563 loss)
I0529 06:30:16.262742 10644 sgd_solver.cpp:106] Iteration 19760, lr = 0.0002
I0529 06:31:04.832857 10644 solver.cpp:228] Iteration 19780, loss = 0.186083
I0529 06:31:04.832883 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:31:04.832893 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.01234 (* 1 = 0.01234 loss)
I0529 06:31:04.832901 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0531678 (* 1 = 0.0531678 loss)
I0529 06:31:04.832906 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766271 (* 1 = 0.00766271 loss)
I0529 06:31:04.832917 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00918107 (* 1 = 0.00918107 loss)
I0529 06:31:04.832928 10644 sgd_solver.cpp:106] Iteration 19780, lr = 0.0002
speed: 2.429s / iter
I0529 06:31:53.398061 10644 solver.cpp:228] Iteration 19800, loss = 0.351081
I0529 06:31:53.398088 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:31:53.398095 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.110476 (* 1 = 0.110476 loss)
I0529 06:31:53.398099 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.139599 (* 1 = 0.139599 loss)
I0529 06:31:53.398102 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140561 (* 1 = 0.0140561 loss)
I0529 06:31:53.398105 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162385 (* 1 = 0.0162385 loss)
I0529 06:31:53.398110 10644 sgd_solver.cpp:106] Iteration 19800, lr = 0.0002
I0529 06:32:41.948078 10644 solver.cpp:228] Iteration 19820, loss = 0.556545
I0529 06:32:41.948104 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 06:32:41.948112 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729861 (* 1 = 0.0729861 loss)
I0529 06:32:41.948115 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.186587 (* 1 = 0.186587 loss)
I0529 06:32:41.948119 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00251934 (* 1 = 0.00251934 loss)
I0529 06:32:41.948122 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130686 (* 1 = 0.0130686 loss)
I0529 06:32:41.948127 10644 sgd_solver.cpp:106] Iteration 19820, lr = 0.0002
I0529 06:33:30.471568 10644 solver.cpp:228] Iteration 19840, loss = 0.286164
I0529 06:33:30.471596 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:33:30.471603 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0662956 (* 1 = 0.0662956 loss)
I0529 06:33:30.471608 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0621641 (* 1 = 0.0621641 loss)
I0529 06:33:30.471612 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110242 (* 1 = 0.00110242 loss)
I0529 06:33:30.471616 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00907123 (* 1 = 0.00907123 loss)
I0529 06:33:30.471623 10644 sgd_solver.cpp:106] Iteration 19840, lr = 0.0002
I0529 06:34:19.026487 10644 solver.cpp:228] Iteration 19860, loss = 0.379387
I0529 06:34:19.026520 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:34:19.026530 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0421555 (* 1 = 0.0421555 loss)
I0529 06:34:19.026537 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0964655 (* 1 = 0.0964655 loss)
I0529 06:34:19.026543 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0585054 (* 1 = 0.0585054 loss)
I0529 06:34:19.026548 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208314 (* 1 = 0.0208314 loss)
I0529 06:34:19.026556 10644 sgd_solver.cpp:106] Iteration 19860, lr = 0.0002
I0529 06:35:07.565963 10644 solver.cpp:228] Iteration 19880, loss = 0.327852
I0529 06:35:07.565986 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:35:07.565994 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513896 (* 1 = 0.0513896 loss)
I0529 06:35:07.565999 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.149696 (* 1 = 0.149696 loss)
I0529 06:35:07.566002 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196929 (* 1 = 0.0196929 loss)
I0529 06:35:07.566006 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512981 (* 1 = 0.0512981 loss)
I0529 06:35:07.566011 10644 sgd_solver.cpp:106] Iteration 19880, lr = 0.0002
I0529 06:35:56.145417 10644 solver.cpp:228] Iteration 19900, loss = 0.321457
I0529 06:35:56.145447 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:35:56.145457 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437403 (* 1 = 0.0437403 loss)
I0529 06:35:56.145463 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0460093 (* 1 = 0.0460093 loss)
I0529 06:35:56.145469 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155758 (* 1 = 0.00155758 loss)
I0529 06:35:56.145476 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010946 (* 1 = 0.010946 loss)
I0529 06:35:56.145483 10644 sgd_solver.cpp:106] Iteration 19900, lr = 0.0002
I0529 06:36:44.674980 10644 solver.cpp:228] Iteration 19920, loss = 0.286002
I0529 06:36:44.675007 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:36:44.675015 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365561 (* 1 = 0.0365561 loss)
I0529 06:36:44.675019 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.056101 (* 1 = 0.056101 loss)
I0529 06:36:44.675024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347049 (* 1 = 0.00347049 loss)
I0529 06:36:44.675027 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00288146 (* 1 = 0.00288146 loss)
I0529 06:36:44.675034 10644 sgd_solver.cpp:106] Iteration 19920, lr = 0.0002
I0529 06:37:33.237457 10644 solver.cpp:228] Iteration 19940, loss = 0.329076
I0529 06:37:33.237484 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 06:37:33.237493 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.223438 (* 1 = 0.223438 loss)
I0529 06:37:33.237496 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.301075 (* 1 = 0.301075 loss)
I0529 06:37:33.237500 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113765 (* 1 = 0.0113765 loss)
I0529 06:37:33.237504 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431474 (* 1 = 0.0431474 loss)
I0529 06:37:33.237509 10644 sgd_solver.cpp:106] Iteration 19940, lr = 0.0002
I0529 06:38:21.785322 10644 solver.cpp:228] Iteration 19960, loss = 0.258553
I0529 06:38:21.785349 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:38:21.785359 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481162 (* 1 = 0.0481162 loss)
I0529 06:38:21.785367 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0985743 (* 1 = 0.0985743 loss)
I0529 06:38:21.785372 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188628 (* 1 = 0.0188628 loss)
I0529 06:38:21.785378 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100635 (* 1 = 0.0100635 loss)
I0529 06:38:21.785387 10644 sgd_solver.cpp:106] Iteration 19960, lr = 0.0002
I0529 06:39:10.317708 10644 solver.cpp:228] Iteration 19980, loss = 0.336765
I0529 06:39:10.317736 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:39:10.317746 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355061 (* 1 = 0.0355061 loss)
I0529 06:39:10.317754 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0723822 (* 1 = 0.0723822 loss)
I0529 06:39:10.317759 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000486991 (* 1 = 0.000486991 loss)
I0529 06:39:10.317765 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00545292 (* 1 = 0.00545292 loss)
I0529 06:39:10.317772 10644 sgd_solver.cpp:106] Iteration 19980, lr = 0.0002
speed: 2.429s / iter
I0529 06:39:56.609077 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_20000.caffemodel
I0529 06:39:59.697471 10644 solver.cpp:228] Iteration 20000, loss = 0.294684
I0529 06:39:59.697516 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 06:39:59.697527 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466463 (* 1 = 0.0466463 loss)
I0529 06:39:59.697535 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.213385 (* 1 = 0.213385 loss)
I0529 06:39:59.697540 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0309976 (* 1 = 0.0309976 loss)
I0529 06:39:59.697546 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264624 (* 1 = 0.0264624 loss)
I0529 06:39:59.697556 10644 sgd_solver.cpp:106] Iteration 20000, lr = 0.0002
I0529 06:40:48.250012 10644 solver.cpp:228] Iteration 20020, loss = 0.186867
I0529 06:40:48.250041 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:40:48.250049 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0422007 (* 1 = 0.0422007 loss)
I0529 06:40:48.250053 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0789 (* 1 = 0.0789 loss)
I0529 06:40:48.250057 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484158 (* 1 = 0.00484158 loss)
I0529 06:40:48.250061 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323589 (* 1 = 0.0323589 loss)
I0529 06:40:48.250067 10644 sgd_solver.cpp:106] Iteration 20020, lr = 0.0002
I0529 06:41:36.770479 10644 solver.cpp:228] Iteration 20040, loss = 0.267826
I0529 06:41:36.770520 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:41:36.770531 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807661 (* 1 = 0.0807661 loss)
I0529 06:41:36.770537 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0549114 (* 1 = 0.0549114 loss)
I0529 06:41:36.770543 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109607 (* 1 = 0.0109607 loss)
I0529 06:41:36.770550 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00433907 (* 1 = 0.00433907 loss)
I0529 06:41:36.770557 10644 sgd_solver.cpp:106] Iteration 20040, lr = 0.0002
I0529 06:42:25.339339 10644 solver.cpp:228] Iteration 20060, loss = 0.245922
I0529 06:42:25.339365 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:42:25.339373 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310037 (* 1 = 0.0310037 loss)
I0529 06:42:25.339377 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.047171 (* 1 = 0.047171 loss)
I0529 06:42:25.339382 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00152492 (* 1 = 0.00152492 loss)
I0529 06:42:25.339385 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131212 (* 1 = 0.0131212 loss)
I0529 06:42:25.339391 10644 sgd_solver.cpp:106] Iteration 20060, lr = 0.0002
I0529 06:43:13.879009 10644 solver.cpp:228] Iteration 20080, loss = 0.446759
I0529 06:43:13.879037 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:43:13.879045 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0255449 (* 1 = 0.0255449 loss)
I0529 06:43:13.879050 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108329 (* 1 = 0.108329 loss)
I0529 06:43:13.879053 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200239 (* 1 = 0.0200239 loss)
I0529 06:43:13.879056 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100495 (* 1 = 0.100495 loss)
I0529 06:43:13.879062 10644 sgd_solver.cpp:106] Iteration 20080, lr = 0.0002
I0529 06:44:02.456507 10644 solver.cpp:228] Iteration 20100, loss = 0.28423
I0529 06:44:02.456538 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:44:02.456550 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.049104 (* 1 = 0.049104 loss)
I0529 06:44:02.456557 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0663068 (* 1 = 0.0663068 loss)
I0529 06:44:02.456563 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00261637 (* 1 = 0.00261637 loss)
I0529 06:44:02.456570 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00733002 (* 1 = 0.00733002 loss)
I0529 06:44:02.456578 10644 sgd_solver.cpp:106] Iteration 20100, lr = 0.0002
I0529 06:44:51.028174 10644 solver.cpp:228] Iteration 20120, loss = 0.410161
I0529 06:44:51.028200 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:44:51.028209 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140396 (* 1 = 0.0140396 loss)
I0529 06:44:51.028215 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0534339 (* 1 = 0.0534339 loss)
I0529 06:44:51.028221 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00450332 (* 1 = 0.00450332 loss)
I0529 06:44:51.028226 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0071408 (* 1 = 0.0071408 loss)
I0529 06:44:51.028234 10644 sgd_solver.cpp:106] Iteration 20120, lr = 0.0002
I0529 06:45:39.583667 10644 solver.cpp:228] Iteration 20140, loss = 0.199848
I0529 06:45:39.583693 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 06:45:39.583698 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000680775 (* 1 = 0.000680775 loss)
I0529 06:45:39.583703 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0242457 (* 1 = 0.0242457 loss)
I0529 06:45:39.583706 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00507583 (* 1 = 0.00507583 loss)
I0529 06:45:39.583709 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348093 (* 1 = 0.0348093 loss)
I0529 06:45:39.583714 10644 sgd_solver.cpp:106] Iteration 20140, lr = 0.0002
I0529 06:46:28.128576 10644 solver.cpp:228] Iteration 20160, loss = 0.192843
I0529 06:46:28.128603 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 06:46:28.128610 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0756171 (* 1 = 0.0756171 loss)
I0529 06:46:28.128614 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.183665 (* 1 = 0.183665 loss)
I0529 06:46:28.128618 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183619 (* 1 = 0.0183619 loss)
I0529 06:46:28.128621 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133682 (* 1 = 0.0133682 loss)
I0529 06:46:28.128626 10644 sgd_solver.cpp:106] Iteration 20160, lr = 0.0002
I0529 06:47:16.685093 10644 solver.cpp:228] Iteration 20180, loss = 0.332852
I0529 06:47:16.685122 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:47:16.685129 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0608282 (* 1 = 0.0608282 loss)
I0529 06:47:16.685133 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0870859 (* 1 = 0.0870859 loss)
I0529 06:47:16.685137 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00564498 (* 1 = 0.00564498 loss)
I0529 06:47:16.685140 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283799 (* 1 = 0.0283799 loss)
I0529 06:47:16.685145 10644 sgd_solver.cpp:106] Iteration 20180, lr = 0.0002
speed: 2.429s / iter
I0529 06:48:05.254179 10644 solver.cpp:228] Iteration 20200, loss = 0.409137
I0529 06:48:05.254204 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:48:05.254209 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100457 (* 1 = 0.100457 loss)
I0529 06:48:05.254214 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.164853 (* 1 = 0.164853 loss)
I0529 06:48:05.254217 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281064 (* 1 = 0.0281064 loss)
I0529 06:48:05.254221 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151176 (* 1 = 0.0151176 loss)
I0529 06:48:05.254225 10644 sgd_solver.cpp:106] Iteration 20200, lr = 0.0002
I0529 06:48:53.819841 10644 solver.cpp:228] Iteration 20220, loss = 0.247351
I0529 06:48:53.819869 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 06:48:53.819877 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455664 (* 1 = 0.0455664 loss)
I0529 06:48:53.819883 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0556277 (* 1 = 0.0556277 loss)
I0529 06:48:53.819890 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00519127 (* 1 = 0.00519127 loss)
I0529 06:48:53.819895 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0299736 (* 1 = 0.0299736 loss)
I0529 06:48:53.819900 10644 sgd_solver.cpp:106] Iteration 20220, lr = 0.0002
I0529 06:49:42.358484 10644 solver.cpp:228] Iteration 20240, loss = 0.218919
I0529 06:49:42.358522 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:49:42.358531 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447911 (* 1 = 0.0447911 loss)
I0529 06:49:42.358536 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.077813 (* 1 = 0.077813 loss)
I0529 06:49:42.358541 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00550448 (* 1 = 0.00550448 loss)
I0529 06:49:42.358544 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175028 (* 1 = 0.0175028 loss)
I0529 06:49:42.358551 10644 sgd_solver.cpp:106] Iteration 20240, lr = 0.0002
I0529 06:50:30.865810 10644 solver.cpp:228] Iteration 20260, loss = 0.28008
I0529 06:50:30.865836 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 06:50:30.865844 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.226507 (* 1 = 0.226507 loss)
I0529 06:50:30.865847 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.31272 (* 1 = 0.31272 loss)
I0529 06:50:30.865850 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165975 (* 1 = 0.0165975 loss)
I0529 06:50:30.865854 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0797012 (* 1 = 0.0797012 loss)
I0529 06:50:30.865859 10644 sgd_solver.cpp:106] Iteration 20260, lr = 0.0002
I0529 06:51:19.416245 10644 solver.cpp:228] Iteration 20280, loss = 0.221813
I0529 06:51:19.416317 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 06:51:19.416330 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.143965 (* 1 = 0.143965 loss)
I0529 06:51:19.416337 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.308892 (* 1 = 0.308892 loss)
I0529 06:51:19.416343 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150481 (* 1 = 0.0150481 loss)
I0529 06:51:19.416348 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0606491 (* 1 = 0.0606491 loss)
I0529 06:51:19.416354 10644 sgd_solver.cpp:106] Iteration 20280, lr = 0.0002
I0529 06:52:07.963784 10644 solver.cpp:228] Iteration 20300, loss = 0.148194
I0529 06:52:07.963810 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 06:52:07.963817 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0153375 (* 1 = 0.0153375 loss)
I0529 06:52:07.963821 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0985796 (* 1 = 0.0985796 loss)
I0529 06:52:07.963824 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0096065 (* 1 = 0.0096065 loss)
I0529 06:52:07.963829 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00754607 (* 1 = 0.00754607 loss)
I0529 06:52:07.963834 10644 sgd_solver.cpp:106] Iteration 20300, lr = 0.0002
I0529 06:52:56.486948 10644 solver.cpp:228] Iteration 20320, loss = 0.425244
I0529 06:52:56.486974 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 06:52:56.486982 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.145456 (* 1 = 0.145456 loss)
I0529 06:52:56.486986 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.266729 (* 1 = 0.266729 loss)
I0529 06:52:56.486989 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00899958 (* 1 = 0.00899958 loss)
I0529 06:52:56.486994 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.065543 (* 1 = 0.065543 loss)
I0529 06:52:56.486999 10644 sgd_solver.cpp:106] Iteration 20320, lr = 0.0002
I0529 06:53:44.980353 10644 solver.cpp:228] Iteration 20340, loss = 0.44101
I0529 06:53:44.980379 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 06:53:44.980386 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0982268 (* 1 = 0.0982268 loss)
I0529 06:53:44.980391 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152583 (* 1 = 0.152583 loss)
I0529 06:53:44.980393 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163835 (* 1 = 0.0163835 loss)
I0529 06:53:44.980397 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448059 (* 1 = 0.0448059 loss)
I0529 06:53:44.980402 10644 sgd_solver.cpp:106] Iteration 20340, lr = 0.0002
I0529 06:54:33.551221 10644 solver.cpp:228] Iteration 20360, loss = 0.459476
I0529 06:54:33.551246 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:54:33.551254 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.017484 (* 1 = 0.017484 loss)
I0529 06:54:33.551259 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0270616 (* 1 = 0.0270616 loss)
I0529 06:54:33.551261 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245529 (* 1 = 0.00245529 loss)
I0529 06:54:33.551265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00989393 (* 1 = 0.00989393 loss)
I0529 06:54:33.551270 10644 sgd_solver.cpp:106] Iteration 20360, lr = 0.0002
I0529 06:55:22.094878 10644 solver.cpp:228] Iteration 20380, loss = 0.116678
I0529 06:55:22.094902 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 06:55:22.094909 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155615 (* 1 = 0.0155615 loss)
I0529 06:55:22.094913 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0446731 (* 1 = 0.0446731 loss)
I0529 06:55:22.094918 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356997 (* 1 = 0.00356997 loss)
I0529 06:55:22.094920 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117693 (* 1 = 0.0117693 loss)
I0529 06:55:22.094925 10644 sgd_solver.cpp:106] Iteration 20380, lr = 0.0002
speed: 2.429s / iter
I0529 06:56:10.619503 10644 solver.cpp:228] Iteration 20400, loss = 0.248332
I0529 06:56:10.619531 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 06:56:10.619539 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0484911 (* 1 = 0.0484911 loss)
I0529 06:56:10.619542 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.086132 (* 1 = 0.086132 loss)
I0529 06:56:10.619546 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158619 (* 1 = 0.00158619 loss)
I0529 06:56:10.619550 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151116 (* 1 = 0.0151116 loss)
I0529 06:56:10.619555 10644 sgd_solver.cpp:106] Iteration 20400, lr = 0.0002
I0529 06:56:59.171176 10644 solver.cpp:228] Iteration 20420, loss = 0.212222
I0529 06:56:59.171200 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 06:56:59.171208 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0742312 (* 1 = 0.0742312 loss)
I0529 06:56:59.171212 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.162583 (* 1 = 0.162583 loss)
I0529 06:56:59.171216 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00518189 (* 1 = 0.00518189 loss)
I0529 06:56:59.171218 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0279805 (* 1 = 0.0279805 loss)
I0529 06:56:59.171224 10644 sgd_solver.cpp:106] Iteration 20420, lr = 0.0002
I0529 06:57:47.689185 10644 solver.cpp:228] Iteration 20440, loss = 0.284917
I0529 06:57:47.689211 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:57:47.689219 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0638225 (* 1 = 0.0638225 loss)
I0529 06:57:47.689224 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0832414 (* 1 = 0.0832414 loss)
I0529 06:57:47.689226 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00321228 (* 1 = 0.00321228 loss)
I0529 06:57:47.689230 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021357 (* 1 = 0.021357 loss)
I0529 06:57:47.689235 10644 sgd_solver.cpp:106] Iteration 20440, lr = 0.0002
I0529 06:58:36.248771 10644 solver.cpp:228] Iteration 20460, loss = 0.251873
I0529 06:58:36.248800 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 06:58:36.248807 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.038055 (* 1 = 0.038055 loss)
I0529 06:58:36.248811 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.180522 (* 1 = 0.180522 loss)
I0529 06:58:36.248816 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183497 (* 1 = 0.0183497 loss)
I0529 06:58:36.248819 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00831711 (* 1 = 0.00831711 loss)
I0529 06:58:36.248826 10644 sgd_solver.cpp:106] Iteration 20460, lr = 0.0002
I0529 06:59:24.780372 10644 solver.cpp:228] Iteration 20480, loss = 0.227372
I0529 06:59:24.780398 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 06:59:24.780405 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369427 (* 1 = 0.0369427 loss)
I0529 06:59:24.780409 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0965551 (* 1 = 0.0965551 loss)
I0529 06:59:24.780413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00372566 (* 1 = 0.00372566 loss)
I0529 06:59:24.780417 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00465929 (* 1 = 0.00465929 loss)
I0529 06:59:24.780423 10644 sgd_solver.cpp:106] Iteration 20480, lr = 0.0002
I0529 07:00:13.345197 10644 solver.cpp:228] Iteration 20500, loss = 0.361645
I0529 07:00:13.345224 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:00:13.345232 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0799562 (* 1 = 0.0799562 loss)
I0529 07:00:13.345237 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.177961 (* 1 = 0.177961 loss)
I0529 07:00:13.345240 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169344 (* 1 = 0.0169344 loss)
I0529 07:00:13.345243 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485498 (* 1 = 0.0485498 loss)
I0529 07:00:13.345249 10644 sgd_solver.cpp:106] Iteration 20500, lr = 0.0002
I0529 07:01:02.032618 10644 solver.cpp:228] Iteration 20520, loss = 0.210229
I0529 07:01:02.032645 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 07:01:02.032652 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292794 (* 1 = 0.0292794 loss)
I0529 07:01:02.032656 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.044018 (* 1 = 0.044018 loss)
I0529 07:01:02.032660 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00297334 (* 1 = 0.00297334 loss)
I0529 07:01:02.032663 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171727 (* 1 = 0.0171727 loss)
I0529 07:01:02.032668 10644 sgd_solver.cpp:106] Iteration 20520, lr = 0.0002
I0529 07:01:50.585178 10644 solver.cpp:228] Iteration 20540, loss = 0.531086
I0529 07:01:50.585207 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0529 07:01:50.585216 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.706035 (* 1 = 0.706035 loss)
I0529 07:01:50.585219 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.706051 (* 1 = 0.706051 loss)
I0529 07:01:50.585222 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0510555 (* 1 = 0.0510555 loss)
I0529 07:01:50.585227 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.393639 (* 1 = 0.393639 loss)
I0529 07:01:50.585230 10644 sgd_solver.cpp:106] Iteration 20540, lr = 0.0002
I0529 07:02:39.137064 10644 solver.cpp:228] Iteration 20560, loss = 0.177124
I0529 07:02:39.137092 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 07:02:39.137102 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0762858 (* 1 = 0.0762858 loss)
I0529 07:02:39.137107 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0571243 (* 1 = 0.0571243 loss)
I0529 07:02:39.137114 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00513928 (* 1 = 0.00513928 loss)
I0529 07:02:39.137118 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00581851 (* 1 = 0.00581851 loss)
I0529 07:02:39.137125 10644 sgd_solver.cpp:106] Iteration 20560, lr = 0.0002
I0529 07:03:27.652027 10644 solver.cpp:228] Iteration 20580, loss = 0.224425
I0529 07:03:27.652052 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 07:03:27.652060 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649538 (* 1 = 0.0649538 loss)
I0529 07:03:27.652062 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145111 (* 1 = 0.145111 loss)
I0529 07:03:27.652066 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00994059 (* 1 = 0.00994059 loss)
I0529 07:03:27.652070 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408386 (* 1 = 0.0408386 loss)
I0529 07:03:27.652076 10644 sgd_solver.cpp:106] Iteration 20580, lr = 0.0002
speed: 2.429s / iter
I0529 07:04:16.191196 10644 solver.cpp:228] Iteration 20600, loss = 0.210448
I0529 07:04:16.191220 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:04:16.191228 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0597761 (* 1 = 0.0597761 loss)
I0529 07:04:16.191233 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150248 (* 1 = 0.150248 loss)
I0529 07:04:16.191237 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00573608 (* 1 = 0.00573608 loss)
I0529 07:04:16.191241 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00497581 (* 1 = 0.00497581 loss)
I0529 07:04:16.191246 10644 sgd_solver.cpp:106] Iteration 20600, lr = 0.0002
I0529 07:05:04.737862 10644 solver.cpp:228] Iteration 20620, loss = 0.267701
I0529 07:05:04.737888 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:05:04.737895 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0893286 (* 1 = 0.0893286 loss)
I0529 07:05:04.737900 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0909534 (* 1 = 0.0909534 loss)
I0529 07:05:04.737903 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00770061 (* 1 = 0.00770061 loss)
I0529 07:05:04.737907 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229354 (* 1 = 0.0229354 loss)
I0529 07:05:04.737912 10644 sgd_solver.cpp:106] Iteration 20620, lr = 0.0002
I0529 07:05:53.265094 10644 solver.cpp:228] Iteration 20640, loss = 0.385476
I0529 07:05:53.265122 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:05:53.265130 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0644732 (* 1 = 0.0644732 loss)
I0529 07:05:53.265135 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0808177 (* 1 = 0.0808177 loss)
I0529 07:05:53.265139 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00288685 (* 1 = 0.00288685 loss)
I0529 07:05:53.265143 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200439 (* 1 = 0.0200439 loss)
I0529 07:05:53.265148 10644 sgd_solver.cpp:106] Iteration 20640, lr = 0.0002
I0529 07:06:41.808593 10644 solver.cpp:228] Iteration 20660, loss = 0.300242
I0529 07:06:41.808622 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 07:06:41.808631 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.169821 (* 1 = 0.169821 loss)
I0529 07:06:41.808635 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.366219 (* 1 = 0.366219 loss)
I0529 07:06:41.808640 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177916 (* 1 = 0.0177916 loss)
I0529 07:06:41.808642 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040691 (* 1 = 0.040691 loss)
I0529 07:06:41.808648 10644 sgd_solver.cpp:106] Iteration 20660, lr = 0.0002
I0529 07:07:30.391535 10644 solver.cpp:228] Iteration 20680, loss = 0.182261
I0529 07:07:30.391556 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 07:07:30.391563 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0775708 (* 1 = 0.0775708 loss)
I0529 07:07:30.391567 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0514448 (* 1 = 0.0514448 loss)
I0529 07:07:30.391571 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00795292 (* 1 = 0.00795292 loss)
I0529 07:07:30.391574 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00594974 (* 1 = 0.00594974 loss)
I0529 07:07:30.391579 10644 sgd_solver.cpp:106] Iteration 20680, lr = 0.0002
I0529 07:08:18.940168 10644 solver.cpp:228] Iteration 20700, loss = 0.416285
I0529 07:08:18.940198 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 07:08:18.940205 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.378388 (* 1 = 0.378388 loss)
I0529 07:08:18.940210 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.45945 (* 1 = 0.45945 loss)
I0529 07:08:18.940214 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0216807 (* 1 = 0.0216807 loss)
I0529 07:08:18.940217 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.146134 (* 1 = 0.146134 loss)
I0529 07:08:18.940223 10644 sgd_solver.cpp:106] Iteration 20700, lr = 0.0002
I0529 07:09:07.485270 10644 solver.cpp:228] Iteration 20720, loss = 0.321272
I0529 07:09:07.485298 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 07:09:07.485306 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.294955 (* 1 = 0.294955 loss)
I0529 07:09:07.485309 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.317369 (* 1 = 0.317369 loss)
I0529 07:09:07.485313 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0363928 (* 1 = 0.0363928 loss)
I0529 07:09:07.485318 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0785099 (* 1 = 0.0785099 loss)
I0529 07:09:07.485324 10644 sgd_solver.cpp:106] Iteration 20720, lr = 0.0002
I0529 07:09:55.994316 10644 solver.cpp:228] Iteration 20740, loss = 0.259394
I0529 07:09:55.994346 10644 solver.cpp:244]     Train net output #0: accuarcy = 1
I0529 07:09:55.994354 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291068 (* 1 = 0.0291068 loss)
I0529 07:09:55.994359 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0177731 (* 1 = 0.0177731 loss)
I0529 07:09:55.994364 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00562535 (* 1 = 0.00562535 loss)
I0529 07:09:55.994367 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00277866 (* 1 = 0.00277866 loss)
I0529 07:09:55.994374 10644 sgd_solver.cpp:106] Iteration 20740, lr = 0.0002
I0529 07:10:44.532336 10644 solver.cpp:228] Iteration 20760, loss = 0.263072
I0529 07:10:44.532362 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 07:10:44.532369 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.318691 (* 1 = 0.318691 loss)
I0529 07:10:44.532373 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.281086 (* 1 = 0.281086 loss)
I0529 07:10:44.532377 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00586776 (* 1 = 0.00586776 loss)
I0529 07:10:44.532380 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332929 (* 1 = 0.0332929 loss)
I0529 07:10:44.532385 10644 sgd_solver.cpp:106] Iteration 20760, lr = 0.0002
I0529 07:11:33.090252 10644 solver.cpp:228] Iteration 20780, loss = 0.448412
I0529 07:11:33.090276 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 07:11:33.090283 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.235511 (* 1 = 0.235511 loss)
I0529 07:11:33.090287 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.422815 (* 1 = 0.422815 loss)
I0529 07:11:33.090291 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.057689 (* 1 = 0.057689 loss)
I0529 07:11:33.090294 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.262623 (* 1 = 0.262623 loss)
I0529 07:11:33.090299 10644 sgd_solver.cpp:106] Iteration 20780, lr = 0.0002
speed: 2.429s / iter
I0529 07:12:21.631546 10644 solver.cpp:228] Iteration 20800, loss = 0.296791
I0529 07:12:21.631572 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:12:21.631577 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.152662 (* 1 = 0.152662 loss)
I0529 07:12:21.631582 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.169225 (* 1 = 0.169225 loss)
I0529 07:12:21.631585 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00891326 (* 1 = 0.00891326 loss)
I0529 07:12:21.631589 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0462915 (* 1 = 0.0462915 loss)
I0529 07:12:21.631594 10644 sgd_solver.cpp:106] Iteration 20800, lr = 0.0002
I0529 07:13:10.168534 10644 solver.cpp:228] Iteration 20820, loss = 0.386029
I0529 07:13:10.168562 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:13:10.168570 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229553 (* 1 = 0.0229553 loss)
I0529 07:13:10.168573 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0954778 (* 1 = 0.0954778 loss)
I0529 07:13:10.168577 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00957396 (* 1 = 0.00957396 loss)
I0529 07:13:10.168581 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112494 (* 1 = 0.0112494 loss)
I0529 07:13:10.168586 10644 sgd_solver.cpp:106] Iteration 20820, lr = 0.0002
I0529 07:13:58.722605 10644 solver.cpp:228] Iteration 20840, loss = 0.393542
I0529 07:13:58.722633 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 07:13:58.722640 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.122074 (* 1 = 0.122074 loss)
I0529 07:13:58.722645 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.364818 (* 1 = 0.364818 loss)
I0529 07:13:58.722648 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226712 (* 1 = 0.0226712 loss)
I0529 07:13:58.722651 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0829686 (* 1 = 0.0829686 loss)
I0529 07:13:58.722657 10644 sgd_solver.cpp:106] Iteration 20840, lr = 0.0002
I0529 07:14:47.264379 10644 solver.cpp:228] Iteration 20860, loss = 0.408235
I0529 07:14:47.264447 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 07:14:47.264467 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00440438 (* 1 = 0.00440438 loss)
I0529 07:14:47.264482 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.123409 (* 1 = 0.123409 loss)
I0529 07:14:47.264495 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0387143 (* 1 = 0.0387143 loss)
I0529 07:14:47.264508 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0661553 (* 1 = 0.0661553 loss)
I0529 07:14:47.264521 10644 sgd_solver.cpp:106] Iteration 20860, lr = 0.0002
I0529 07:15:35.775867 10644 solver.cpp:228] Iteration 20880, loss = 0.313684
I0529 07:15:35.775894 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:15:35.775902 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297088 (* 1 = 0.0297088 loss)
I0529 07:15:35.775907 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112854 (* 1 = 0.112854 loss)
I0529 07:15:35.775909 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108303 (* 1 = 0.0108303 loss)
I0529 07:15:35.775913 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106501 (* 1 = 0.0106501 loss)
I0529 07:15:35.775918 10644 sgd_solver.cpp:106] Iteration 20880, lr = 0.0002
I0529 07:16:24.352044 10644 solver.cpp:228] Iteration 20900, loss = 0.267714
I0529 07:16:24.352071 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 07:16:24.352080 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0870676 (* 1 = 0.0870676 loss)
I0529 07:16:24.352087 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.267065 (* 1 = 0.267065 loss)
I0529 07:16:24.352093 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00608508 (* 1 = 0.00608508 loss)
I0529 07:16:24.352099 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233069 (* 1 = 0.0233069 loss)
I0529 07:16:24.352107 10644 sgd_solver.cpp:106] Iteration 20900, lr = 0.0002
I0529 07:17:12.893126 10644 solver.cpp:228] Iteration 20920, loss = 0.195784
I0529 07:17:12.893154 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 07:17:12.893162 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000494233 (* 1 = 0.000494233 loss)
I0529 07:17:12.893167 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0283447 (* 1 = 0.0283447 loss)
I0529 07:17:12.893170 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00685403 (* 1 = 0.00685403 loss)
I0529 07:17:12.893174 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020077 (* 1 = 0.020077 loss)
I0529 07:17:12.893179 10644 sgd_solver.cpp:106] Iteration 20920, lr = 0.0002
I0529 07:18:01.425796 10644 solver.cpp:228] Iteration 20940, loss = 0.274412
I0529 07:18:01.425824 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:18:01.425832 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.127984 (* 1 = 0.127984 loss)
I0529 07:18:01.425837 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.119689 (* 1 = 0.119689 loss)
I0529 07:18:01.425840 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00734911 (* 1 = 0.00734911 loss)
I0529 07:18:01.425844 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303808 (* 1 = 0.0303808 loss)
I0529 07:18:01.425851 10644 sgd_solver.cpp:106] Iteration 20940, lr = 0.0002
I0529 07:18:49.962219 10644 solver.cpp:228] Iteration 20960, loss = 0.14714
I0529 07:18:49.962249 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:18:49.962256 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248311 (* 1 = 0.0248311 loss)
I0529 07:18:49.962260 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0561652 (* 1 = 0.0561652 loss)
I0529 07:18:49.962265 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.002081 (* 1 = 0.002081 loss)
I0529 07:18:49.962268 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00258629 (* 1 = 0.00258629 loss)
I0529 07:18:49.962273 10644 sgd_solver.cpp:106] Iteration 20960, lr = 0.0002
I0529 07:19:38.486860 10644 solver.cpp:228] Iteration 20980, loss = 0.197696
I0529 07:19:38.486886 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 07:19:38.486894 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000954999 (* 1 = 0.000954999 loss)
I0529 07:19:38.486899 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0298363 (* 1 = 0.0298363 loss)
I0529 07:19:38.486902 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119723 (* 1 = 0.0119723 loss)
I0529 07:19:38.486907 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182859 (* 1 = 0.0182859 loss)
I0529 07:19:38.486912 10644 sgd_solver.cpp:106] Iteration 20980, lr = 0.0002
speed: 2.429s / iter
I0529 07:20:27.078716 10644 solver.cpp:228] Iteration 21000, loss = 0.256122
I0529 07:20:27.078745 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:20:27.078757 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593596 (* 1 = 0.0593596 loss)
I0529 07:20:27.078763 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0569742 (* 1 = 0.0569742 loss)
I0529 07:20:27.078769 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00679852 (* 1 = 0.00679852 loss)
I0529 07:20:27.078775 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00517821 (* 1 = 0.00517821 loss)
I0529 07:20:27.078783 10644 sgd_solver.cpp:106] Iteration 21000, lr = 0.0002
I0529 07:21:15.626227 10644 solver.cpp:228] Iteration 21020, loss = 0.215954
I0529 07:21:15.626252 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:21:15.626260 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309283 (* 1 = 0.0309283 loss)
I0529 07:21:15.626265 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0947911 (* 1 = 0.0947911 loss)
I0529 07:21:15.626268 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00453409 (* 1 = 0.00453409 loss)
I0529 07:21:15.626272 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0025621 (* 1 = 0.0025621 loss)
I0529 07:21:15.626277 10644 sgd_solver.cpp:106] Iteration 21020, lr = 0.0002
I0529 07:22:04.158566 10644 solver.cpp:228] Iteration 21040, loss = 0.379835
I0529 07:22:04.158592 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 07:22:04.158599 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.464119 (* 1 = 0.464119 loss)
I0529 07:22:04.158604 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.460317 (* 1 = 0.460317 loss)
I0529 07:22:04.158607 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118918 (* 1 = 0.0118918 loss)
I0529 07:22:04.158612 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.152223 (* 1 = 0.152223 loss)
I0529 07:22:04.158617 10644 sgd_solver.cpp:106] Iteration 21040, lr = 0.0002
I0529 07:22:52.710861 10644 solver.cpp:228] Iteration 21060, loss = 0.266906
I0529 07:22:52.710888 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 07:22:52.710896 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0438247 (* 1 = 0.0438247 loss)
I0529 07:22:52.710901 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0755241 (* 1 = 0.0755241 loss)
I0529 07:22:52.710903 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00148807 (* 1 = 0.00148807 loss)
I0529 07:22:52.710907 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00661317 (* 1 = 0.00661317 loss)
I0529 07:22:52.710911 10644 sgd_solver.cpp:106] Iteration 21060, lr = 0.0002
I0529 07:23:41.288394 10644 solver.cpp:228] Iteration 21080, loss = 0.359406
I0529 07:23:41.288421 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 07:23:41.288429 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.200924 (* 1 = 0.200924 loss)
I0529 07:23:41.288432 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.227647 (* 1 = 0.227647 loss)
I0529 07:23:41.288436 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109168 (* 1 = 0.0109168 loss)
I0529 07:23:41.288439 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0913254 (* 1 = 0.0913254 loss)
I0529 07:23:41.288444 10644 sgd_solver.cpp:106] Iteration 21080, lr = 0.0002
I0529 07:24:29.832778 10644 solver.cpp:228] Iteration 21100, loss = 0.177824
I0529 07:24:29.832808 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 07:24:29.832816 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0879771 (* 1 = 0.0879771 loss)
I0529 07:24:29.832819 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.158332 (* 1 = 0.158332 loss)
I0529 07:24:29.832823 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136543 (* 1 = 0.0136543 loss)
I0529 07:24:29.832826 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296875 (* 1 = 0.0296875 loss)
I0529 07:24:29.832832 10644 sgd_solver.cpp:106] Iteration 21100, lr = 0.0002
I0529 07:25:18.390537 10644 solver.cpp:228] Iteration 21120, loss = 0.314517
I0529 07:25:18.390563 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 07:25:18.390570 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100183 (* 1 = 0.100183 loss)
I0529 07:25:18.390574 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.11925 (* 1 = 0.11925 loss)
I0529 07:25:18.390578 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00908309 (* 1 = 0.00908309 loss)
I0529 07:25:18.390581 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0447997 (* 1 = 0.0447997 loss)
I0529 07:25:18.390586 10644 sgd_solver.cpp:106] Iteration 21120, lr = 0.0002
I0529 07:26:06.925678 10644 solver.cpp:228] Iteration 21140, loss = 0.293196
I0529 07:26:06.925709 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 07:26:06.925719 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.215273 (* 1 = 0.215273 loss)
I0529 07:26:06.925724 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.409214 (* 1 = 0.409214 loss)
I0529 07:26:06.925729 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00756649 (* 1 = 0.00756649 loss)
I0529 07:26:06.925735 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0575819 (* 1 = 0.0575819 loss)
I0529 07:26:06.925742 10644 sgd_solver.cpp:106] Iteration 21140, lr = 0.0002
I0529 07:26:55.471618 10644 solver.cpp:228] Iteration 21160, loss = 0.265368
I0529 07:26:55.471688 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 07:26:55.471710 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0471358 (* 1 = 0.0471358 loss)
I0529 07:26:55.471726 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113351 (* 1 = 0.113351 loss)
I0529 07:26:55.471741 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170138 (* 1 = 0.0170138 loss)
I0529 07:26:55.471755 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116379 (* 1 = 0.0116379 loss)
I0529 07:26:55.471771 10644 sgd_solver.cpp:106] Iteration 21160, lr = 0.0002
I0529 07:27:43.994007 10644 solver.cpp:228] Iteration 21180, loss = 0.264225
I0529 07:27:43.994037 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 07:27:43.994047 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.269053 (* 1 = 0.269053 loss)
I0529 07:27:43.994055 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.416622 (* 1 = 0.416622 loss)
I0529 07:27:43.994060 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0492735 (* 1 = 0.0492735 loss)
I0529 07:27:43.994066 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0975658 (* 1 = 0.0975658 loss)
I0529 07:27:43.994072 10644 sgd_solver.cpp:106] Iteration 21180, lr = 0.0002
speed: 2.429s / iter
I0529 07:28:32.522652 10644 solver.cpp:228] Iteration 21200, loss = 0.233414
I0529 07:28:32.522681 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 07:28:32.522691 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.140424 (* 1 = 0.140424 loss)
I0529 07:28:32.522697 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.293201 (* 1 = 0.293201 loss)
I0529 07:28:32.522703 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014807 (* 1 = 0.014807 loss)
I0529 07:28:32.522709 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228562 (* 1 = 0.0228562 loss)
I0529 07:28:32.522717 10644 sgd_solver.cpp:106] Iteration 21200, lr = 0.0002
I0529 07:29:21.073709 10644 solver.cpp:228] Iteration 21220, loss = 0.310288
I0529 07:29:21.073738 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 07:29:21.073748 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114406 (* 1 = 0.114406 loss)
I0529 07:29:21.073755 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.147533 (* 1 = 0.147533 loss)
I0529 07:29:21.073760 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0250199 (* 1 = 0.0250199 loss)
I0529 07:29:21.073766 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297414 (* 1 = 0.0297414 loss)
I0529 07:29:21.073773 10644 sgd_solver.cpp:106] Iteration 21220, lr = 0.0002
I0529 07:30:09.598907 10644 solver.cpp:228] Iteration 21240, loss = 0.32789
I0529 07:30:09.598935 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 07:30:09.598948 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400232 (* 1 = 0.0400232 loss)
I0529 07:30:09.598954 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.13519 (* 1 = 0.13519 loss)
I0529 07:30:09.598961 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00572571 (* 1 = 0.00572571 loss)
I0529 07:30:09.598965 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00499496 (* 1 = 0.00499496 loss)
I0529 07:30:09.598973 10644 sgd_solver.cpp:106] Iteration 21240, lr = 0.0002
I0529 07:30:58.119832 10644 solver.cpp:228] Iteration 21260, loss = 0.187739
I0529 07:30:58.119861 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:30:58.119869 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890315 (* 1 = 0.0890315 loss)
I0529 07:30:58.119874 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.125033 (* 1 = 0.125033 loss)
I0529 07:30:58.119879 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00864367 (* 1 = 0.00864367 loss)
I0529 07:30:58.119882 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164098 (* 1 = 0.0164098 loss)
I0529 07:30:58.119887 10644 sgd_solver.cpp:106] Iteration 21260, lr = 0.0002
I0529 07:31:46.644832 10644 solver.cpp:228] Iteration 21280, loss = 0.635389
I0529 07:31:46.644858 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:31:46.644866 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0219283 (* 1 = 0.0219283 loss)
I0529 07:31:46.644870 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0618584 (* 1 = 0.0618584 loss)
I0529 07:31:46.644877 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363058 (* 1 = 0.00363058 loss)
I0529 07:31:46.644883 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00419593 (* 1 = 0.00419593 loss)
I0529 07:31:46.644889 10644 sgd_solver.cpp:106] Iteration 21280, lr = 0.0002
I0529 07:32:35.183343 10644 solver.cpp:228] Iteration 21300, loss = 0.36405
I0529 07:32:35.183370 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 07:32:35.183378 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827343 (* 1 = 0.0827343 loss)
I0529 07:32:35.183382 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.192352 (* 1 = 0.192352 loss)
I0529 07:32:35.183387 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266507 (* 1 = 0.00266507 loss)
I0529 07:32:35.183390 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141569 (* 1 = 0.0141569 loss)
I0529 07:32:35.183395 10644 sgd_solver.cpp:106] Iteration 21300, lr = 0.0002
I0529 07:33:23.730227 10644 solver.cpp:228] Iteration 21320, loss = 0.229952
I0529 07:33:23.730254 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 07:33:23.730262 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.124835 (* 1 = 0.124835 loss)
I0529 07:33:23.730267 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.225299 (* 1 = 0.225299 loss)
I0529 07:33:23.730270 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00884959 (* 1 = 0.00884959 loss)
I0529 07:33:23.730274 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210795 (* 1 = 0.0210795 loss)
I0529 07:33:23.730279 10644 sgd_solver.cpp:106] Iteration 21320, lr = 0.0002
I0529 07:34:12.284220 10644 solver.cpp:228] Iteration 21340, loss = 0.198261
I0529 07:34:12.284248 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:34:12.284255 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0246276 (* 1 = 0.0246276 loss)
I0529 07:34:12.284260 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0764062 (* 1 = 0.0764062 loss)
I0529 07:34:12.284263 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186904 (* 1 = 0.00186904 loss)
I0529 07:34:12.284266 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00496556 (* 1 = 0.00496556 loss)
I0529 07:34:12.284271 10644 sgd_solver.cpp:106] Iteration 21340, lr = 0.0002
I0529 07:35:00.818859 10644 solver.cpp:228] Iteration 21360, loss = 0.177683
I0529 07:35:00.818884 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 07:35:00.818892 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220531 (* 1 = 0.0220531 loss)
I0529 07:35:00.818895 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0549978 (* 1 = 0.0549978 loss)
I0529 07:35:00.818898 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00503048 (* 1 = 0.00503048 loss)
I0529 07:35:00.818902 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129053 (* 1 = 0.0129053 loss)
I0529 07:35:00.818907 10644 sgd_solver.cpp:106] Iteration 21360, lr = 0.0002
I0529 07:35:49.354763 10644 solver.cpp:228] Iteration 21380, loss = 0.354399
I0529 07:35:49.354790 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 07:35:49.354799 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566137 (* 1 = 0.0566137 loss)
I0529 07:35:49.354801 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0732029 (* 1 = 0.0732029 loss)
I0529 07:35:49.354805 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00517136 (* 1 = 0.00517136 loss)
I0529 07:35:49.354809 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188404 (* 1 = 0.0188404 loss)
I0529 07:35:49.354815 10644 sgd_solver.cpp:106] Iteration 21380, lr = 0.0002
speed: 2.429s / iter
I0529 07:36:37.894065 10644 solver.cpp:228] Iteration 21400, loss = 0.350387
I0529 07:36:37.894090 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:36:37.894098 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0223682 (* 1 = 0.0223682 loss)
I0529 07:36:37.894101 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0505356 (* 1 = 0.0505356 loss)
I0529 07:36:37.894104 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146425 (* 1 = 0.0146425 loss)
I0529 07:36:37.894107 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125588 (* 1 = 0.0125588 loss)
I0529 07:36:37.894112 10644 sgd_solver.cpp:106] Iteration 21400, lr = 0.0002
I0529 07:37:26.463452 10644 solver.cpp:228] Iteration 21420, loss = 0.345026
I0529 07:37:26.463479 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 07:37:26.463490 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00110956 (* 1 = 0.00110956 loss)
I0529 07:37:26.463496 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0452591 (* 1 = 0.0452591 loss)
I0529 07:37:26.463502 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200629 (* 1 = 0.0200629 loss)
I0529 07:37:26.463507 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153936 (* 1 = 0.0153936 loss)
I0529 07:37:26.463515 10644 sgd_solver.cpp:106] Iteration 21420, lr = 0.0002
I0529 07:38:15.049240 10644 solver.cpp:228] Iteration 21440, loss = 0.194196
I0529 07:38:15.049268 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:38:15.049278 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305203 (* 1 = 0.0305203 loss)
I0529 07:38:15.049284 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.113121 (* 1 = 0.113121 loss)
I0529 07:38:15.049290 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192686 (* 1 = 0.0192686 loss)
I0529 07:38:15.049296 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226247 (* 1 = 0.0226247 loss)
I0529 07:38:15.049304 10644 sgd_solver.cpp:106] Iteration 21440, lr = 0.0002
I0529 07:39:03.635620 10644 solver.cpp:228] Iteration 21460, loss = 0.432181
I0529 07:39:03.635649 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 07:39:03.635659 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758646 (* 1 = 0.0758646 loss)
I0529 07:39:03.635666 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.100464 (* 1 = 0.100464 loss)
I0529 07:39:03.635673 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121627 (* 1 = 0.0121627 loss)
I0529 07:39:03.635677 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186458 (* 1 = 0.0186458 loss)
I0529 07:39:03.635685 10644 sgd_solver.cpp:106] Iteration 21460, lr = 0.0002
I0529 07:39:52.222034 10644 solver.cpp:228] Iteration 21480, loss = 0.261873
I0529 07:39:52.222062 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:39:52.222071 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0338441 (* 1 = 0.0338441 loss)
I0529 07:39:52.222075 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.154673 (* 1 = 0.154673 loss)
I0529 07:39:52.222079 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109083 (* 1 = 0.0109083 loss)
I0529 07:39:52.222084 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193554 (* 1 = 0.0193554 loss)
I0529 07:39:52.222090 10644 sgd_solver.cpp:106] Iteration 21480, lr = 0.0002
I0529 07:40:40.755658 10644 solver.cpp:228] Iteration 21500, loss = 0.303487
I0529 07:40:40.755684 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 07:40:40.755692 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0180722 (* 1 = 0.0180722 loss)
I0529 07:40:40.755697 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0742729 (* 1 = 0.0742729 loss)
I0529 07:40:40.755700 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134956 (* 1 = 0.0134956 loss)
I0529 07:40:40.755705 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00793237 (* 1 = 0.00793237 loss)
I0529 07:40:40.755712 10644 sgd_solver.cpp:106] Iteration 21500, lr = 0.0002
I0529 07:41:29.318184 10644 solver.cpp:228] Iteration 21520, loss = 0.40217
I0529 07:41:29.318212 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 07:41:29.318219 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.247263 (* 1 = 0.247263 loss)
I0529 07:41:29.318223 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.249403 (* 1 = 0.249403 loss)
I0529 07:41:29.318228 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00712743 (* 1 = 0.00712743 loss)
I0529 07:41:29.318231 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031506 (* 1 = 0.031506 loss)
I0529 07:41:29.318238 10644 sgd_solver.cpp:106] Iteration 21520, lr = 0.0002
I0529 07:42:17.845661 10644 solver.cpp:228] Iteration 21540, loss = 0.145938
I0529 07:42:17.845686 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 07:42:17.845693 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274967 (* 1 = 0.0274967 loss)
I0529 07:42:17.845697 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0657811 (* 1 = 0.0657811 loss)
I0529 07:42:17.845701 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113319 (* 1 = 0.00113319 loss)
I0529 07:42:17.845705 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322428 (* 1 = 0.00322428 loss)
I0529 07:42:17.845710 10644 sgd_solver.cpp:106] Iteration 21540, lr = 0.0002
I0529 07:43:06.377004 10644 solver.cpp:228] Iteration 21560, loss = 0.410861
I0529 07:43:06.377032 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:43:06.377040 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0177096 (* 1 = 0.0177096 loss)
I0529 07:43:06.377044 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0614457 (* 1 = 0.0614457 loss)
I0529 07:43:06.377048 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213588 (* 1 = 0.00213588 loss)
I0529 07:43:06.377053 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104185 (* 1 = 0.0104185 loss)
I0529 07:43:06.377058 10644 sgd_solver.cpp:106] Iteration 21560, lr = 0.0002
I0529 07:43:54.933915 10644 solver.cpp:228] Iteration 21580, loss = 0.267988
I0529 07:43:54.933941 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 07:43:54.933949 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386325 (* 1 = 0.0386325 loss)
I0529 07:43:54.933954 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0461006 (* 1 = 0.0461006 loss)
I0529 07:43:54.933959 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130029 (* 1 = 0.00130029 loss)
I0529 07:43:54.933962 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00597302 (* 1 = 0.00597302 loss)
I0529 07:43:54.933967 10644 sgd_solver.cpp:106] Iteration 21580, lr = 0.0002
speed: 2.429s / iter
I0529 07:44:43.515777 10644 solver.cpp:228] Iteration 21600, loss = 0.412641
I0529 07:44:43.515807 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 07:44:43.515816 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0554396 (* 1 = 0.0554396 loss)
I0529 07:44:43.515823 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136673 (* 1 = 0.136673 loss)
I0529 07:44:43.515830 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215816 (* 1 = 0.00215816 loss)
I0529 07:44:43.515836 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00861589 (* 1 = 0.00861589 loss)
I0529 07:44:43.515842 10644 sgd_solver.cpp:106] Iteration 21600, lr = 0.0002
I0529 07:45:32.045918 10644 solver.cpp:228] Iteration 21620, loss = 0.261611
I0529 07:45:32.045948 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 07:45:32.045958 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.210543 (* 1 = 0.210543 loss)
I0529 07:45:32.045961 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.196582 (* 1 = 0.196582 loss)
I0529 07:45:32.045964 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0615632 (* 1 = 0.0615632 loss)
I0529 07:45:32.045969 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.220076 (* 1 = 0.220076 loss)
I0529 07:45:32.045974 10644 sgd_solver.cpp:106] Iteration 21620, lr = 0.0002
I0529 07:46:20.617908 10644 solver.cpp:228] Iteration 21640, loss = 0.349954
I0529 07:46:20.617944 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 07:46:20.617955 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.194897 (* 1 = 0.194897 loss)
I0529 07:46:20.617962 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.217307 (* 1 = 0.217307 loss)
I0529 07:46:20.617969 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00335528 (* 1 = 0.00335528 loss)
I0529 07:46:20.617974 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028595 (* 1 = 0.028595 loss)
I0529 07:46:20.617982 10644 sgd_solver.cpp:106] Iteration 21640, lr = 0.0002
I0529 07:47:09.167116 10644 solver.cpp:228] Iteration 21660, loss = 0.203044
I0529 07:47:09.167142 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 07:47:09.167150 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165607 (* 1 = 0.0165607 loss)
I0529 07:47:09.167153 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0604626 (* 1 = 0.0604626 loss)
I0529 07:47:09.167158 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00931786 (* 1 = 0.00931786 loss)
I0529 07:47:09.167161 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100916 (* 1 = 0.0100916 loss)
I0529 07:47:09.167166 10644 sgd_solver.cpp:106] Iteration 21660, lr = 0.0002
I0529 07:47:57.690739 10644 solver.cpp:228] Iteration 21680, loss = 0.499254
I0529 07:47:57.690764 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:47:57.690771 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448 (* 1 = 0.0448 loss)
I0529 07:47:57.690775 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.142288 (* 1 = 0.142288 loss)
I0529 07:47:57.690778 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0277763 (* 1 = 0.0277763 loss)
I0529 07:47:57.690783 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329756 (* 1 = 0.0329756 loss)
I0529 07:47:57.690786 10644 sgd_solver.cpp:106] Iteration 21680, lr = 0.0002
I0529 07:48:46.212954 10644 solver.cpp:228] Iteration 21700, loss = 0.2894
I0529 07:48:46.212980 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 07:48:46.212986 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0760038 (* 1 = 0.0760038 loss)
I0529 07:48:46.212990 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.176054 (* 1 = 0.176054 loss)
I0529 07:48:46.212993 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012808 (* 1 = 0.012808 loss)
I0529 07:48:46.212996 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298219 (* 1 = 0.0298219 loss)
I0529 07:48:46.213001 10644 sgd_solver.cpp:106] Iteration 21700, lr = 0.0002
I0529 07:49:34.788668 10644 solver.cpp:228] Iteration 21720, loss = 0.417359
I0529 07:49:34.788698 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 07:49:34.788708 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0979939 (* 1 = 0.0979939 loss)
I0529 07:49:34.788715 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.166832 (* 1 = 0.166832 loss)
I0529 07:49:34.788722 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171452 (* 1 = 0.00171452 loss)
I0529 07:49:34.788727 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159061 (* 1 = 0.0159061 loss)
I0529 07:49:34.788735 10644 sgd_solver.cpp:106] Iteration 21720, lr = 0.0002
I0529 07:50:23.371124 10644 solver.cpp:228] Iteration 21740, loss = 0.142501
I0529 07:50:23.371150 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 07:50:23.371158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496184 (* 1 = 0.0496184 loss)
I0529 07:50:23.371162 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0860089 (* 1 = 0.0860089 loss)
I0529 07:50:23.371167 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00789228 (* 1 = 0.00789228 loss)
I0529 07:50:23.371170 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172797 (* 1 = 0.0172797 loss)
I0529 07:50:23.371176 10644 sgd_solver.cpp:106] Iteration 21740, lr = 0.0002
I0529 07:51:11.900853 10644 solver.cpp:228] Iteration 21760, loss = 0.518115
I0529 07:51:11.900890 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:51:11.900900 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.044017 (* 1 = 0.044017 loss)
I0529 07:51:11.900905 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0548327 (* 1 = 0.0548327 loss)
I0529 07:51:11.900909 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00664439 (* 1 = 0.00664439 loss)
I0529 07:51:11.900918 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00427038 (* 1 = 0.00427038 loss)
I0529 07:51:11.900923 10644 sgd_solver.cpp:106] Iteration 21760, lr = 0.0002
I0529 07:52:00.439493 10644 solver.cpp:228] Iteration 21780, loss = 0.31067
I0529 07:52:00.439522 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:52:00.439529 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.024512 (* 1 = 0.024512 loss)
I0529 07:52:00.439533 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0494538 (* 1 = 0.0494538 loss)
I0529 07:52:00.439538 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012353 (* 1 = 0.0012353 loss)
I0529 07:52:00.439541 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00717194 (* 1 = 0.00717194 loss)
I0529 07:52:00.439548 10644 sgd_solver.cpp:106] Iteration 21780, lr = 0.0002
speed: 2.429s / iter
I0529 07:52:48.954084 10644 solver.cpp:228] Iteration 21800, loss = 0.576502
I0529 07:52:48.954110 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:52:48.954118 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.057133 (* 1 = 0.057133 loss)
I0529 07:52:48.954123 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.061604 (* 1 = 0.061604 loss)
I0529 07:52:48.954126 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00578256 (* 1 = 0.00578256 loss)
I0529 07:52:48.954131 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01687 (* 1 = 0.01687 loss)
I0529 07:52:48.954136 10644 sgd_solver.cpp:106] Iteration 21800, lr = 0.0002
I0529 07:53:37.484107 10644 solver.cpp:228] Iteration 21820, loss = 0.380698
I0529 07:53:37.484134 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 07:53:37.484141 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.290529 (* 1 = 0.290529 loss)
I0529 07:53:37.484145 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.342339 (* 1 = 0.342339 loss)
I0529 07:53:37.484149 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0096993 (* 1 = 0.0096993 loss)
I0529 07:53:37.484153 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0626857 (* 1 = 0.0626857 loss)
I0529 07:53:37.484158 10644 sgd_solver.cpp:106] Iteration 21820, lr = 0.0002
I0529 07:54:26.021477 10644 solver.cpp:228] Iteration 21840, loss = 0.277083
I0529 07:54:26.021507 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:54:26.021515 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341172 (* 1 = 0.0341172 loss)
I0529 07:54:26.021519 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0472706 (* 1 = 0.0472706 loss)
I0529 07:54:26.021523 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00589282 (* 1 = 0.00589282 loss)
I0529 07:54:26.021528 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0027162 (* 1 = 0.0027162 loss)
I0529 07:54:26.021533 10644 sgd_solver.cpp:106] Iteration 21840, lr = 0.0002
I0529 07:55:14.553791 10644 solver.cpp:228] Iteration 21860, loss = 0.248466
I0529 07:55:14.553818 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 07:55:14.553827 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231538 (* 1 = 0.0231538 loss)
I0529 07:55:14.553831 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121519 (* 1 = 0.121519 loss)
I0529 07:55:14.553835 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00559741 (* 1 = 0.00559741 loss)
I0529 07:55:14.553839 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173125 (* 1 = 0.0173125 loss)
I0529 07:55:14.553844 10644 sgd_solver.cpp:106] Iteration 21860, lr = 0.0002
I0529 07:56:03.107020 10644 solver.cpp:228] Iteration 21880, loss = 0.36084
I0529 07:56:03.107049 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 07:56:03.107059 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.23849 (* 1 = 0.23849 loss)
I0529 07:56:03.107065 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.331028 (* 1 = 0.331028 loss)
I0529 07:56:03.107071 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00989825 (* 1 = 0.00989825 loss)
I0529 07:56:03.107076 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0477988 (* 1 = 0.0477988 loss)
I0529 07:56:03.107084 10644 sgd_solver.cpp:106] Iteration 21880, lr = 0.0002
I0529 07:56:51.625382 10644 solver.cpp:228] Iteration 21900, loss = 0.214973
I0529 07:56:51.625411 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:56:51.625418 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675569 (* 1 = 0.0675569 loss)
I0529 07:56:51.625422 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134556 (* 1 = 0.134556 loss)
I0529 07:56:51.625425 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166512 (* 1 = 0.0166512 loss)
I0529 07:56:51.625429 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0347193 (* 1 = 0.0347193 loss)
I0529 07:56:51.625434 10644 sgd_solver.cpp:106] Iteration 21900, lr = 0.0002
I0529 07:57:40.152819 10644 solver.cpp:228] Iteration 21920, loss = 0.313881
I0529 07:57:40.152853 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 07:57:40.152860 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0976975 (* 1 = 0.0976975 loss)
I0529 07:57:40.152864 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255887 (* 1 = 0.255887 loss)
I0529 07:57:40.152868 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00708236 (* 1 = 0.00708236 loss)
I0529 07:57:40.152873 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040975 (* 1 = 0.040975 loss)
I0529 07:57:40.152878 10644 sgd_solver.cpp:106] Iteration 21920, lr = 0.0002
I0529 07:58:28.692654 10644 solver.cpp:228] Iteration 21940, loss = 0.182372
I0529 07:58:28.692683 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 07:58:28.692692 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.105311 (* 1 = 0.105311 loss)
I0529 07:58:28.692695 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0710156 (* 1 = 0.0710156 loss)
I0529 07:58:28.692699 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00317447 (* 1 = 0.00317447 loss)
I0529 07:58:28.692703 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144665 (* 1 = 0.0144665 loss)
I0529 07:58:28.692710 10644 sgd_solver.cpp:106] Iteration 21940, lr = 0.0002
I0529 07:59:17.223891 10644 solver.cpp:228] Iteration 21960, loss = 0.271436
I0529 07:59:17.223918 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 07:59:17.223929 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523902 (* 1 = 0.0523902 loss)
I0529 07:59:17.223937 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0857272 (* 1 = 0.0857272 loss)
I0529 07:59:17.223942 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00791371 (* 1 = 0.00791371 loss)
I0529 07:59:17.223948 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348239 (* 1 = 0.0348239 loss)
I0529 07:59:17.223955 10644 sgd_solver.cpp:106] Iteration 21960, lr = 0.0002
I0529 08:00:05.755403 10644 solver.cpp:228] Iteration 21980, loss = 0.214513
I0529 08:00:05.755427 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 08:00:05.755434 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0111834 (* 1 = 0.0111834 loss)
I0529 08:00:05.755439 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0933573 (* 1 = 0.0933573 loss)
I0529 08:00:05.755442 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0099845 (* 1 = 0.0099845 loss)
I0529 08:00:05.755445 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226094 (* 1 = 0.0226094 loss)
I0529 08:00:05.755450 10644 sgd_solver.cpp:106] Iteration 21980, lr = 0.0002
speed: 2.429s / iter
I0529 08:00:54.297803 10644 solver.cpp:228] Iteration 22000, loss = 0.221334
I0529 08:00:54.297830 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:00:54.297837 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0575861 (* 1 = 0.0575861 loss)
I0529 08:00:54.297842 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0321721 (* 1 = 0.0321721 loss)
I0529 08:00:54.297844 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363067 (* 1 = 0.00363067 loss)
I0529 08:00:54.297848 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00627871 (* 1 = 0.00627871 loss)
I0529 08:00:54.297853 10644 sgd_solver.cpp:106] Iteration 22000, lr = 0.0002
I0529 08:01:42.848728 10644 solver.cpp:228] Iteration 22020, loss = 0.292222
I0529 08:01:42.848753 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 08:01:42.848760 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.152176 (* 1 = 0.152176 loss)
I0529 08:01:42.848764 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.199687 (* 1 = 0.199687 loss)
I0529 08:01:42.848768 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737236 (* 1 = 0.00737236 loss)
I0529 08:01:42.848772 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.053977 (* 1 = 0.053977 loss)
I0529 08:01:42.848778 10644 sgd_solver.cpp:106] Iteration 22020, lr = 0.0002
I0529 08:02:31.377557 10644 solver.cpp:228] Iteration 22040, loss = 0.282833
I0529 08:02:31.377586 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 08:02:31.377593 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0808081 (* 1 = 0.0808081 loss)
I0529 08:02:31.377598 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.24457 (* 1 = 0.24457 loss)
I0529 08:02:31.377600 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138834 (* 1 = 0.0138834 loss)
I0529 08:02:31.377604 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035487 (* 1 = 0.035487 loss)
I0529 08:02:31.377609 10644 sgd_solver.cpp:106] Iteration 22040, lr = 0.0002
I0529 08:03:19.941387 10644 solver.cpp:228] Iteration 22060, loss = 0.363381
I0529 08:03:19.941413 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 08:03:19.941421 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0887657 (* 1 = 0.0887657 loss)
I0529 08:03:19.941426 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.153349 (* 1 = 0.153349 loss)
I0529 08:03:19.941429 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00874112 (* 1 = 0.00874112 loss)
I0529 08:03:19.941433 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394361 (* 1 = 0.0394361 loss)
I0529 08:03:19.941438 10644 sgd_solver.cpp:106] Iteration 22060, lr = 0.0002
I0529 08:04:08.456869 10644 solver.cpp:228] Iteration 22080, loss = 0.270359
I0529 08:04:08.456892 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 08:04:08.456899 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.107262 (* 1 = 0.107262 loss)
I0529 08:04:08.456903 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.186032 (* 1 = 0.186032 loss)
I0529 08:04:08.456907 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0287766 (* 1 = 0.0287766 loss)
I0529 08:04:08.456913 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0646513 (* 1 = 0.0646513 loss)
I0529 08:04:08.456918 10644 sgd_solver.cpp:106] Iteration 22080, lr = 0.0002
I0529 08:04:57.036897 10644 solver.cpp:228] Iteration 22100, loss = 0.281547
I0529 08:04:57.036931 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:04:57.036939 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391311 (* 1 = 0.0391311 loss)
I0529 08:04:57.036944 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0518356 (* 1 = 0.0518356 loss)
I0529 08:04:57.036947 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305488 (* 1 = 0.00305488 loss)
I0529 08:04:57.036952 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0024742 (* 1 = 0.0024742 loss)
I0529 08:04:57.036957 10644 sgd_solver.cpp:106] Iteration 22100, lr = 0.0002
I0529 08:05:45.483090 10644 solver.cpp:228] Iteration 22120, loss = 0.321523
I0529 08:05:45.483116 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:05:45.483124 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182564 (* 1 = 0.0182564 loss)
I0529 08:05:45.483129 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0244404 (* 1 = 0.0244404 loss)
I0529 08:05:45.483134 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126917 (* 1 = 0.00126917 loss)
I0529 08:05:45.483136 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00714284 (* 1 = 0.00714284 loss)
I0529 08:05:45.483141 10644 sgd_solver.cpp:106] Iteration 22120, lr = 0.0002
I0529 08:06:33.946939 10644 solver.cpp:228] Iteration 22140, loss = 0.254375
I0529 08:06:33.946966 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:06:33.946974 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0588398 (* 1 = 0.0588398 loss)
I0529 08:06:33.946977 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108612 (* 1 = 0.108612 loss)
I0529 08:06:33.946981 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146437 (* 1 = 0.0146437 loss)
I0529 08:06:33.946985 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132682 (* 1 = 0.0132682 loss)
I0529 08:06:33.946990 10644 sgd_solver.cpp:106] Iteration 22140, lr = 0.0002
I0529 08:07:22.501731 10644 solver.cpp:228] Iteration 22160, loss = 0.26832
I0529 08:07:22.501757 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:07:22.501765 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410381 (* 1 = 0.0410381 loss)
I0529 08:07:22.501770 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0263671 (* 1 = 0.0263671 loss)
I0529 08:07:22.501772 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103597 (* 1 = 0.0103597 loss)
I0529 08:07:22.501777 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00560281 (* 1 = 0.00560281 loss)
I0529 08:07:22.501782 10644 sgd_solver.cpp:106] Iteration 22160, lr = 0.0002
I0529 08:08:11.033447 10644 solver.cpp:228] Iteration 22180, loss = 0.344511
I0529 08:08:11.033474 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 08:08:11.033483 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0624779 (* 1 = 0.0624779 loss)
I0529 08:08:11.033486 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.140878 (* 1 = 0.140878 loss)
I0529 08:08:11.033490 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109699 (* 1 = 0.0109699 loss)
I0529 08:08:11.033494 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117892 (* 1 = 0.0117892 loss)
I0529 08:08:11.033499 10644 sgd_solver.cpp:106] Iteration 22180, lr = 0.0002
speed: 2.429s / iter
I0529 08:08:59.574903 10644 solver.cpp:228] Iteration 22200, loss = 0.442782
I0529 08:08:59.574939 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:08:59.574947 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499911 (* 1 = 0.0499911 loss)
I0529 08:08:59.574952 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.096974 (* 1 = 0.096974 loss)
I0529 08:08:59.574956 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000541126 (* 1 = 0.000541126 loss)
I0529 08:08:59.574960 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00559674 (* 1 = 0.00559674 loss)
I0529 08:08:59.574966 10644 sgd_solver.cpp:106] Iteration 22200, lr = 0.0002
I0529 08:09:48.120260 10644 solver.cpp:228] Iteration 22220, loss = 0.348182
I0529 08:09:48.120288 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:09:48.120297 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355839 (* 1 = 0.0355839 loss)
I0529 08:09:48.120303 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109633 (* 1 = 0.109633 loss)
I0529 08:09:48.120308 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120214 (* 1 = 0.0120214 loss)
I0529 08:09:48.120313 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135212 (* 1 = 0.0135212 loss)
I0529 08:09:48.120321 10644 sgd_solver.cpp:106] Iteration 22220, lr = 0.0002
I0529 08:10:36.670208 10644 solver.cpp:228] Iteration 22240, loss = 0.306631
I0529 08:10:36.670233 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 08:10:36.670239 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0974024 (* 1 = 0.0974024 loss)
I0529 08:10:36.670243 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151905 (* 1 = 0.151905 loss)
I0529 08:10:36.670246 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00521162 (* 1 = 0.00521162 loss)
I0529 08:10:36.670250 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340859 (* 1 = 0.0340859 loss)
I0529 08:10:36.670255 10644 sgd_solver.cpp:106] Iteration 22240, lr = 0.0002
I0529 08:11:25.221406 10644 solver.cpp:228] Iteration 22260, loss = 0.3086
I0529 08:11:25.221431 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 08:11:25.221439 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316266 (* 1 = 0.0316266 loss)
I0529 08:11:25.221443 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.111546 (* 1 = 0.111546 loss)
I0529 08:11:25.221446 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0248025 (* 1 = 0.0248025 loss)
I0529 08:11:25.221449 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016911 (* 1 = 0.016911 loss)
I0529 08:11:25.221454 10644 sgd_solver.cpp:106] Iteration 22260, lr = 0.0002
I0529 08:12:13.777678 10644 solver.cpp:228] Iteration 22280, loss = 0.253233
I0529 08:12:13.777704 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 08:12:13.777710 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0672081 (* 1 = 0.0672081 loss)
I0529 08:12:13.777714 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.175727 (* 1 = 0.175727 loss)
I0529 08:12:13.777717 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187881 (* 1 = 0.0187881 loss)
I0529 08:12:13.777721 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122472 (* 1 = 0.0122472 loss)
I0529 08:12:13.777726 10644 sgd_solver.cpp:106] Iteration 22280, lr = 0.0002
I0529 08:13:02.325291 10644 solver.cpp:228] Iteration 22300, loss = 0.303909
I0529 08:13:02.325320 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 08:13:02.325326 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0809712 (* 1 = 0.0809712 loss)
I0529 08:13:02.325330 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.158999 (* 1 = 0.158999 loss)
I0529 08:13:02.325335 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00840232 (* 1 = 0.00840232 loss)
I0529 08:13:02.325338 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214055 (* 1 = 0.0214055 loss)
I0529 08:13:02.325343 10644 sgd_solver.cpp:106] Iteration 22300, lr = 0.0002
I0529 08:13:50.858919 10644 solver.cpp:228] Iteration 22320, loss = 0.385138
I0529 08:13:50.858949 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 08:13:50.858955 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.149983 (* 1 = 0.149983 loss)
I0529 08:13:50.858959 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.212902 (* 1 = 0.212902 loss)
I0529 08:13:50.858963 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0209696 (* 1 = 0.0209696 loss)
I0529 08:13:50.858968 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112771 (* 1 = 0.0112771 loss)
I0529 08:13:50.858973 10644 sgd_solver.cpp:106] Iteration 22320, lr = 0.0002
I0529 08:14:39.403378 10644 solver.cpp:228] Iteration 22340, loss = 0.27641
I0529 08:14:39.403404 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 08:14:39.403414 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.106681 (* 1 = 0.106681 loss)
I0529 08:14:39.403420 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108885 (* 1 = 0.108885 loss)
I0529 08:14:39.403426 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00383838 (* 1 = 0.00383838 loss)
I0529 08:14:39.403432 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146467 (* 1 = 0.0146467 loss)
I0529 08:14:39.403440 10644 sgd_solver.cpp:106] Iteration 22340, lr = 0.0002
I0529 08:15:27.932678 10644 solver.cpp:228] Iteration 22360, loss = 0.143046
I0529 08:15:27.932705 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:15:27.932713 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334658 (* 1 = 0.0334658 loss)
I0529 08:15:27.932718 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.041951 (* 1 = 0.041951 loss)
I0529 08:15:27.932721 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00211553 (* 1 = 0.00211553 loss)
I0529 08:15:27.932725 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00958061 (* 1 = 0.00958061 loss)
I0529 08:15:27.932730 10644 sgd_solver.cpp:106] Iteration 22360, lr = 0.0002
I0529 08:16:16.487670 10644 solver.cpp:228] Iteration 22380, loss = 0.267079
I0529 08:16:16.487699 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 08:16:16.487705 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533954 (* 1 = 0.0533954 loss)
I0529 08:16:16.487709 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.127265 (* 1 = 0.127265 loss)
I0529 08:16:16.487713 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251226 (* 1 = 0.0251226 loss)
I0529 08:16:16.487716 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035866 (* 1 = 0.035866 loss)
I0529 08:16:16.487721 10644 sgd_solver.cpp:106] Iteration 22380, lr = 0.0002
speed: 2.429s / iter
I0529 08:17:05.026032 10644 solver.cpp:228] Iteration 22400, loss = 0.248013
I0529 08:17:05.026057 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 08:17:05.026064 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0417304 (* 1 = 0.0417304 loss)
I0529 08:17:05.026067 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.277908 (* 1 = 0.277908 loss)
I0529 08:17:05.026072 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.138638 (* 1 = 0.138638 loss)
I0529 08:17:05.026074 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0620838 (* 1 = 0.0620838 loss)
I0529 08:17:05.026079 10644 sgd_solver.cpp:106] Iteration 22400, lr = 0.0002
I0529 08:17:53.579092 10644 solver.cpp:228] Iteration 22420, loss = 0.356579
I0529 08:17:53.579118 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 08:17:53.579124 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.158745 (* 1 = 0.158745 loss)
I0529 08:17:53.579128 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.311681 (* 1 = 0.311681 loss)
I0529 08:17:53.579131 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115493 (* 1 = 0.0115493 loss)
I0529 08:17:53.579134 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0779669 (* 1 = 0.0779669 loss)
I0529 08:17:53.579140 10644 sgd_solver.cpp:106] Iteration 22420, lr = 0.0002
I0529 08:18:42.161794 10644 solver.cpp:228] Iteration 22440, loss = 0.349224
I0529 08:18:42.161818 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 08:18:42.161824 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0602308 (* 1 = 0.0602308 loss)
I0529 08:18:42.161828 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1663 (* 1 = 0.1663 loss)
I0529 08:18:42.161833 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146575 (* 1 = 0.0146575 loss)
I0529 08:18:42.161836 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00933105 (* 1 = 0.00933105 loss)
I0529 08:18:42.161840 10644 sgd_solver.cpp:106] Iteration 22440, lr = 0.0002
I0529 08:19:30.734861 10644 solver.cpp:228] Iteration 22460, loss = 0.326346
I0529 08:19:30.734890 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 08:19:30.734899 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0143149 (* 1 = 0.0143149 loss)
I0529 08:19:30.734905 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.19006 (* 1 = 0.19006 loss)
I0529 08:19:30.734910 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00409008 (* 1 = 0.00409008 loss)
I0529 08:19:30.734916 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010035 (* 1 = 0.010035 loss)
I0529 08:19:30.734923 10644 sgd_solver.cpp:106] Iteration 22460, lr = 0.0002
I0529 08:20:19.293035 10644 solver.cpp:228] Iteration 22480, loss = 0.398105
I0529 08:20:19.293059 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:20:19.293068 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126397 (* 1 = 0.0126397 loss)
I0529 08:20:19.293074 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134078 (* 1 = 0.134078 loss)
I0529 08:20:19.293081 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00370483 (* 1 = 0.00370483 loss)
I0529 08:20:19.293085 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00347432 (* 1 = 0.00347432 loss)
I0529 08:20:19.293092 10644 sgd_solver.cpp:106] Iteration 22480, lr = 0.0002
I0529 08:21:07.834684 10644 solver.cpp:228] Iteration 22500, loss = 0.300344
I0529 08:21:07.834709 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 08:21:07.834717 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0930109 (* 1 = 0.0930109 loss)
I0529 08:21:07.834722 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.184259 (* 1 = 0.184259 loss)
I0529 08:21:07.834724 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00261941 (* 1 = 0.00261941 loss)
I0529 08:21:07.834728 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0422496 (* 1 = 0.0422496 loss)
I0529 08:21:07.834733 10644 sgd_solver.cpp:106] Iteration 22500, lr = 0.0002
I0529 08:21:56.371989 10644 solver.cpp:228] Iteration 22520, loss = 0.556017
I0529 08:21:56.372014 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0529 08:21:56.372022 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.795111 (* 1 = 0.795111 loss)
I0529 08:21:56.372025 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.807258 (* 1 = 0.807258 loss)
I0529 08:21:56.372030 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0575359 (* 1 = 0.0575359 loss)
I0529 08:21:56.372032 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.398875 (* 1 = 0.398875 loss)
I0529 08:21:56.372037 10644 sgd_solver.cpp:106] Iteration 22520, lr = 0.0002
I0529 08:22:44.939654 10644 solver.cpp:228] Iteration 22540, loss = 0.353851
I0529 08:22:44.939680 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 08:22:44.939688 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.323975 (* 1 = 0.323975 loss)
I0529 08:22:44.939692 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.401114 (* 1 = 0.401114 loss)
I0529 08:22:44.939697 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.110436 (* 1 = 0.110436 loss)
I0529 08:22:44.939700 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185479 (* 1 = 0.185479 loss)
I0529 08:22:44.939705 10644 sgd_solver.cpp:106] Iteration 22540, lr = 0.0002
I0529 08:23:33.476757 10644 solver.cpp:228] Iteration 22560, loss = 0.360266
I0529 08:23:33.476783 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:23:33.476790 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.082151 (* 1 = 0.082151 loss)
I0529 08:23:33.476794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.097897 (* 1 = 0.097897 loss)
I0529 08:23:33.476799 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00211103 (* 1 = 0.00211103 loss)
I0529 08:23:33.476802 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0048255 (* 1 = 0.0048255 loss)
I0529 08:23:33.476807 10644 sgd_solver.cpp:106] Iteration 22560, lr = 0.0002
I0529 08:24:22.033812 10644 solver.cpp:228] Iteration 22580, loss = 0.20764
I0529 08:24:22.033841 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 08:24:22.033850 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272868 (* 1 = 0.0272868 loss)
I0529 08:24:22.033854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0846415 (* 1 = 0.0846415 loss)
I0529 08:24:22.033859 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204092 (* 1 = 0.00204092 loss)
I0529 08:24:22.033862 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00785105 (* 1 = 0.00785105 loss)
I0529 08:24:22.033869 10644 sgd_solver.cpp:106] Iteration 22580, lr = 0.0002
speed: 2.429s / iter
I0529 08:25:10.599704 10644 solver.cpp:228] Iteration 22600, loss = 0.300191
I0529 08:25:10.599731 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:25:10.599738 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346388 (* 1 = 0.0346388 loss)
I0529 08:25:10.599743 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.063218 (* 1 = 0.063218 loss)
I0529 08:25:10.599748 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135421 (* 1 = 0.00135421 loss)
I0529 08:25:10.599751 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104347 (* 1 = 0.0104347 loss)
I0529 08:25:10.599756 10644 sgd_solver.cpp:106] Iteration 22600, lr = 0.0002
I0529 08:25:59.127768 10644 solver.cpp:228] Iteration 22620, loss = 0.231907
I0529 08:25:59.127799 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:25:59.127810 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524845 (* 1 = 0.0524845 loss)
I0529 08:25:59.127817 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0869127 (* 1 = 0.0869127 loss)
I0529 08:25:59.127823 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00545721 (* 1 = 0.00545721 loss)
I0529 08:25:59.127830 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.006185 (* 1 = 0.006185 loss)
I0529 08:25:59.127837 10644 sgd_solver.cpp:106] Iteration 22620, lr = 0.0002
I0529 08:26:47.678108 10644 solver.cpp:228] Iteration 22640, loss = 0.27216
I0529 08:26:47.678148 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 08:26:47.678156 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0624734 (* 1 = 0.0624734 loss)
I0529 08:26:47.678160 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101836 (* 1 = 0.101836 loss)
I0529 08:26:47.678164 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186374 (* 1 = 0.0186374 loss)
I0529 08:26:47.678169 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151171 (* 1 = 0.0151171 loss)
I0529 08:26:47.678176 10644 sgd_solver.cpp:106] Iteration 22640, lr = 0.0002
I0529 08:27:36.200634 10644 solver.cpp:228] Iteration 22660, loss = 0.373084
I0529 08:27:36.200659 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 08:27:36.200668 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.245877 (* 1 = 0.245877 loss)
I0529 08:27:36.200672 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.258896 (* 1 = 0.258896 loss)
I0529 08:27:36.200676 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00321333 (* 1 = 0.00321333 loss)
I0529 08:27:36.200680 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249266 (* 1 = 0.0249266 loss)
I0529 08:27:36.200686 10644 sgd_solver.cpp:106] Iteration 22660, lr = 0.0002
I0529 08:28:24.764756 10644 solver.cpp:228] Iteration 22680, loss = 0.347782
I0529 08:28:24.764782 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 08:28:24.764789 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.113797 (* 1 = 0.113797 loss)
I0529 08:28:24.764794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10738 (* 1 = 0.10738 loss)
I0529 08:28:24.764798 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00353248 (* 1 = 0.00353248 loss)
I0529 08:28:24.764802 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336032 (* 1 = 0.0336032 loss)
I0529 08:28:24.764806 10644 sgd_solver.cpp:106] Iteration 22680, lr = 0.0002
I0529 08:29:13.289340 10644 solver.cpp:228] Iteration 22700, loss = 0.189128
I0529 08:29:13.289366 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 08:29:13.289373 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186078 (* 1 = 0.0186078 loss)
I0529 08:29:13.289377 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0649182 (* 1 = 0.0649182 loss)
I0529 08:29:13.289381 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0079641 (* 1 = 0.0079641 loss)
I0529 08:29:13.289386 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00618224 (* 1 = 0.00618224 loss)
I0529 08:29:13.289391 10644 sgd_solver.cpp:106] Iteration 22700, lr = 0.0002
I0529 08:30:01.862049 10644 solver.cpp:228] Iteration 22720, loss = 0.154797
I0529 08:30:01.862074 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 08:30:01.862082 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675616 (* 1 = 0.0675616 loss)
I0529 08:30:01.862088 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.172946 (* 1 = 0.172946 loss)
I0529 08:30:01.862093 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115076 (* 1 = 0.0115076 loss)
I0529 08:30:01.862098 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024755 (* 1 = 0.024755 loss)
I0529 08:30:01.862105 10644 sgd_solver.cpp:106] Iteration 22720, lr = 0.0002
I0529 08:30:50.415452 10644 solver.cpp:228] Iteration 22740, loss = 0.692454
I0529 08:30:50.415477 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:30:50.415484 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00120893 (* 1 = 0.00120893 loss)
I0529 08:30:50.415488 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0453341 (* 1 = 0.0453341 loss)
I0529 08:30:50.415491 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0524431 (* 1 = 0.0524431 loss)
I0529 08:30:50.415495 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113259 (* 1 = 0.0113259 loss)
I0529 08:30:50.415499 10644 sgd_solver.cpp:106] Iteration 22740, lr = 0.0002
I0529 08:31:38.983130 10644 solver.cpp:228] Iteration 22760, loss = 0.401262
I0529 08:31:38.983153 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 08:31:38.983160 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.226305 (* 1 = 0.226305 loss)
I0529 08:31:38.983165 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.268272 (* 1 = 0.268272 loss)
I0529 08:31:38.983168 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157358 (* 1 = 0.0157358 loss)
I0529 08:31:38.983171 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394571 (* 1 = 0.0394571 loss)
I0529 08:31:38.983176 10644 sgd_solver.cpp:106] Iteration 22760, lr = 0.0002
I0529 08:32:27.527629 10644 solver.cpp:228] Iteration 22780, loss = 0.295267
I0529 08:32:27.527659 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 08:32:27.527667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.172358 (* 1 = 0.172358 loss)
I0529 08:32:27.527670 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.186787 (* 1 = 0.186787 loss)
I0529 08:32:27.527674 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0561871 (* 1 = 0.0561871 loss)
I0529 08:32:27.527678 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383256 (* 1 = 0.0383256 loss)
I0529 08:32:27.527683 10644 sgd_solver.cpp:106] Iteration 22780, lr = 0.0002
speed: 2.429s / iter
I0529 08:33:16.074945 10644 solver.cpp:228] Iteration 22800, loss = 0.343885
I0529 08:33:16.074970 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:33:16.074978 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00800085 (* 1 = 0.00800085 loss)
I0529 08:33:16.074982 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0450039 (* 1 = 0.0450039 loss)
I0529 08:33:16.074985 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00083512 (* 1 = 0.00083512 loss)
I0529 08:33:16.074990 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00474408 (* 1 = 0.00474408 loss)
I0529 08:33:16.074995 10644 sgd_solver.cpp:106] Iteration 22800, lr = 0.0002
I0529 08:34:04.657274 10644 solver.cpp:228] Iteration 22820, loss = 0.361925
I0529 08:34:04.657301 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 08:34:04.657308 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117227 (* 1 = 0.117227 loss)
I0529 08:34:04.657312 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.17202 (* 1 = 0.17202 loss)
I0529 08:34:04.657315 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.031606 (* 1 = 0.031606 loss)
I0529 08:34:04.657320 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335263 (* 1 = 0.0335263 loss)
I0529 08:34:04.657325 10644 sgd_solver.cpp:106] Iteration 22820, lr = 0.0002
I0529 08:34:53.238103 10644 solver.cpp:228] Iteration 22840, loss = 0.337324
I0529 08:34:53.238131 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 08:34:53.238138 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128098 (* 1 = 0.0128098 loss)
I0529 08:34:53.238143 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0568691 (* 1 = 0.0568691 loss)
I0529 08:34:53.238147 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318896 (* 1 = 0.00318896 loss)
I0529 08:34:53.238152 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00751971 (* 1 = 0.00751971 loss)
I0529 08:34:53.238157 10644 sgd_solver.cpp:106] Iteration 22840, lr = 0.0002
I0529 08:35:41.787633 10644 solver.cpp:228] Iteration 22860, loss = 0.330756
I0529 08:35:41.787662 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 08:35:41.787672 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114092 (* 1 = 0.114092 loss)
I0529 08:35:41.787678 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.251957 (* 1 = 0.251957 loss)
I0529 08:35:41.787683 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0531637 (* 1 = 0.0531637 loss)
I0529 08:35:41.787689 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157349 (* 1 = 0.157349 loss)
I0529 08:35:41.787696 10644 sgd_solver.cpp:106] Iteration 22860, lr = 0.0002
I0529 08:36:30.321957 10644 solver.cpp:228] Iteration 22880, loss = 0.377615
I0529 08:36:30.321985 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 08:36:30.321991 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.132446 (* 1 = 0.132446 loss)
I0529 08:36:30.321995 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.197836 (* 1 = 0.197836 loss)
I0529 08:36:30.322000 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111212 (* 1 = 0.0111212 loss)
I0529 08:36:30.322003 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352721 (* 1 = 0.0352721 loss)
I0529 08:36:30.322010 10644 sgd_solver.cpp:106] Iteration 22880, lr = 0.0002
I0529 08:37:18.878829 10644 solver.cpp:228] Iteration 22900, loss = 0.238519
I0529 08:37:18.878856 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 08:37:18.878865 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467268 (* 1 = 0.0467268 loss)
I0529 08:37:18.878868 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121428 (* 1 = 0.121428 loss)
I0529 08:37:18.878872 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424231 (* 1 = 0.00424231 loss)
I0529 08:37:18.878876 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222707 (* 1 = 0.0222707 loss)
I0529 08:37:18.878881 10644 sgd_solver.cpp:106] Iteration 22900, lr = 0.0002
I0529 08:38:07.440347 10644 solver.cpp:228] Iteration 22920, loss = 0.186531
I0529 08:38:07.440373 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:38:07.440382 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0196362 (* 1 = 0.0196362 loss)
I0529 08:38:07.440385 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0364281 (* 1 = 0.0364281 loss)
I0529 08:38:07.440389 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052491 (* 1 = 0.0052491 loss)
I0529 08:38:07.440393 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00574124 (* 1 = 0.00574124 loss)
I0529 08:38:07.440397 10644 sgd_solver.cpp:106] Iteration 22920, lr = 0.0002
I0529 08:38:56.021782 10644 solver.cpp:228] Iteration 22940, loss = 0.269875
I0529 08:38:56.021809 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 08:38:56.021817 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0951111 (* 1 = 0.0951111 loss)
I0529 08:38:56.021822 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.116653 (* 1 = 0.116653 loss)
I0529 08:38:56.021826 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128407 (* 1 = 0.00128407 loss)
I0529 08:38:56.021832 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178022 (* 1 = 0.0178022 loss)
I0529 08:38:56.021837 10644 sgd_solver.cpp:106] Iteration 22940, lr = 0.0002
I0529 08:39:44.566581 10644 solver.cpp:228] Iteration 22960, loss = 0.404725
I0529 08:39:44.566612 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:39:44.566622 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0394533 (* 1 = 0.0394533 loss)
I0529 08:39:44.566625 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0351438 (* 1 = 0.0351438 loss)
I0529 08:39:44.566629 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00244306 (* 1 = 0.00244306 loss)
I0529 08:39:44.566634 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00168657 (* 1 = 0.00168657 loss)
I0529 08:39:44.566640 10644 sgd_solver.cpp:106] Iteration 22960, lr = 0.0002
I0529 08:40:33.093992 10644 solver.cpp:228] Iteration 22980, loss = 0.231203
I0529 08:40:33.094018 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 08:40:33.094027 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0842733 (* 1 = 0.0842733 loss)
I0529 08:40:33.094032 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.086851 (* 1 = 0.086851 loss)
I0529 08:40:33.094035 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00340896 (* 1 = 0.00340896 loss)
I0529 08:40:33.094038 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122587 (* 1 = 0.0122587 loss)
I0529 08:40:33.094044 10644 sgd_solver.cpp:106] Iteration 22980, lr = 0.0002
speed: 2.429s / iter
I0529 08:41:21.628422 10644 solver.cpp:228] Iteration 23000, loss = 0.286351
I0529 08:41:21.628448 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 08:41:21.628456 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117396 (* 1 = 0.117396 loss)
I0529 08:41:21.628460 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136552 (* 1 = 0.136552 loss)
I0529 08:41:21.628464 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.020606 (* 1 = 0.020606 loss)
I0529 08:41:21.628468 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258967 (* 1 = 0.0258967 loss)
I0529 08:41:21.628473 10644 sgd_solver.cpp:106] Iteration 23000, lr = 0.0002
I0529 08:42:10.155323 10644 solver.cpp:228] Iteration 23020, loss = 0.633255
I0529 08:42:10.155349 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 08:42:10.155356 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258242 (* 1 = 0.0258242 loss)
I0529 08:42:10.155360 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109215 (* 1 = 0.109215 loss)
I0529 08:42:10.155364 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403915 (* 1 = 0.00403915 loss)
I0529 08:42:10.155367 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00749164 (* 1 = 0.00749164 loss)
I0529 08:42:10.155373 10644 sgd_solver.cpp:106] Iteration 23020, lr = 0.0002
I0529 08:42:58.676774 10644 solver.cpp:228] Iteration 23040, loss = 0.514886
I0529 08:42:58.676800 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:42:58.676807 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0403068 (* 1 = 0.0403068 loss)
I0529 08:42:58.676811 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121077 (* 1 = 0.121077 loss)
I0529 08:42:58.676815 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177878 (* 1 = 0.0177878 loss)
I0529 08:42:58.676818 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020864 (* 1 = 0.020864 loss)
I0529 08:42:58.676823 10644 sgd_solver.cpp:106] Iteration 23040, lr = 0.0002
I0529 08:43:47.229498 10644 solver.cpp:228] Iteration 23060, loss = 0.364449
I0529 08:43:47.229526 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 08:43:47.229533 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.105216 (* 1 = 0.105216 loss)
I0529 08:43:47.229537 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.229037 (* 1 = 0.229037 loss)
I0529 08:43:47.229540 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271953 (* 1 = 0.0271953 loss)
I0529 08:43:47.229543 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658129 (* 1 = 0.0658129 loss)
I0529 08:43:47.229549 10644 sgd_solver.cpp:106] Iteration 23060, lr = 0.0002
I0529 08:44:35.779253 10644 solver.cpp:228] Iteration 23080, loss = 0.419897
I0529 08:44:35.779281 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0529 08:44:35.779290 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.281436 (* 1 = 0.281436 loss)
I0529 08:44:35.779296 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.437986 (* 1 = 0.437986 loss)
I0529 08:44:35.779302 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.104219 (* 1 = 0.104219 loss)
I0529 08:44:35.779307 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.422148 (* 1 = 0.422148 loss)
I0529 08:44:35.779314 10644 sgd_solver.cpp:106] Iteration 23080, lr = 0.0002
I0529 08:45:24.340634 10644 solver.cpp:228] Iteration 23100, loss = 0.167973
I0529 08:45:24.340659 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:45:24.340668 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0487123 (* 1 = 0.0487123 loss)
I0529 08:45:24.340674 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.134423 (* 1 = 0.134423 loss)
I0529 08:45:24.340679 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00887451 (* 1 = 0.00887451 loss)
I0529 08:45:24.340685 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00827855 (* 1 = 0.00827855 loss)
I0529 08:45:24.340692 10644 sgd_solver.cpp:106] Iteration 23100, lr = 0.0002
I0529 08:46:12.894222 10644 solver.cpp:228] Iteration 23120, loss = 0.343244
I0529 08:46:12.894246 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:46:12.894254 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272151 (* 1 = 0.0272151 loss)
I0529 08:46:12.894260 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.084214 (* 1 = 0.084214 loss)
I0529 08:46:12.894265 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00595982 (* 1 = 0.00595982 loss)
I0529 08:46:12.894271 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00950589 (* 1 = 0.00950589 loss)
I0529 08:46:12.894278 10644 sgd_solver.cpp:106] Iteration 23120, lr = 0.0002
I0529 08:47:01.417207 10644 solver.cpp:228] Iteration 23140, loss = 0.20302
I0529 08:47:01.417233 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:47:01.417241 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00369545 (* 1 = 0.00369545 loss)
I0529 08:47:01.417245 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0445158 (* 1 = 0.0445158 loss)
I0529 08:47:01.417249 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01785 (* 1 = 0.01785 loss)
I0529 08:47:01.417253 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293074 (* 1 = 0.0293074 loss)
I0529 08:47:01.417258 10644 sgd_solver.cpp:106] Iteration 23140, lr = 0.0002
I0529 08:47:49.969878 10644 solver.cpp:228] Iteration 23160, loss = 0.373561
I0529 08:47:49.969905 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 08:47:49.969914 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855854 (* 1 = 0.0855854 loss)
I0529 08:47:49.969919 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.167684 (* 1 = 0.167684 loss)
I0529 08:47:49.969923 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169868 (* 1 = 0.00169868 loss)
I0529 08:47:49.969928 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434263 (* 1 = 0.0434263 loss)
I0529 08:47:49.969933 10644 sgd_solver.cpp:106] Iteration 23160, lr = 0.0002
I0529 08:48:38.512486 10644 solver.cpp:228] Iteration 23180, loss = 0.172339
I0529 08:48:38.512516 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 08:48:38.512524 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0482458 (* 1 = 0.0482458 loss)
I0529 08:48:38.512528 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0507942 (* 1 = 0.0507942 loss)
I0529 08:48:38.512533 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00279946 (* 1 = 0.00279946 loss)
I0529 08:48:38.512537 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00927898 (* 1 = 0.00927898 loss)
I0529 08:48:38.512542 10644 sgd_solver.cpp:106] Iteration 23180, lr = 0.0002
speed: 2.429s / iter
I0529 08:49:27.063062 10644 solver.cpp:228] Iteration 23200, loss = 0.284416
I0529 08:49:27.063091 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 08:49:27.063098 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0502378 (* 1 = 0.0502378 loss)
I0529 08:49:27.063102 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1236 (* 1 = 0.1236 loss)
I0529 08:49:27.063107 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102341 (* 1 = 0.0102341 loss)
I0529 08:49:27.063109 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181025 (* 1 = 0.0181025 loss)
I0529 08:49:27.063115 10644 sgd_solver.cpp:106] Iteration 23200, lr = 0.0002
I0529 08:50:15.639747 10644 solver.cpp:228] Iteration 23220, loss = 0.199418
I0529 08:50:15.639775 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 08:50:15.639781 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0267718 (* 1 = 0.0267718 loss)
I0529 08:50:15.639786 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0472582 (* 1 = 0.0472582 loss)
I0529 08:50:15.639789 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152379 (* 1 = 0.0152379 loss)
I0529 08:50:15.639793 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00498247 (* 1 = 0.00498247 loss)
I0529 08:50:15.639799 10644 sgd_solver.cpp:106] Iteration 23220, lr = 0.0002
I0529 08:51:04.179831 10644 solver.cpp:228] Iteration 23240, loss = 0.290237
I0529 08:51:04.179857 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 08:51:04.179864 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0798362 (* 1 = 0.0798362 loss)
I0529 08:51:04.179869 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.16663 (* 1 = 0.16663 loss)
I0529 08:51:04.179873 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0337782 (* 1 = 0.0337782 loss)
I0529 08:51:04.179877 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0856862 (* 1 = 0.0856862 loss)
I0529 08:51:04.179883 10644 sgd_solver.cpp:106] Iteration 23240, lr = 0.0002
I0529 08:51:52.742175 10644 solver.cpp:228] Iteration 23260, loss = 0.217352
I0529 08:51:52.742202 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:51:52.742213 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.043183 (* 1 = 0.043183 loss)
I0529 08:51:52.742218 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.046974 (* 1 = 0.046974 loss)
I0529 08:51:52.742225 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305917 (* 1 = 0.00305917 loss)
I0529 08:51:52.742230 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00396538 (* 1 = 0.00396538 loss)
I0529 08:51:52.742238 10644 sgd_solver.cpp:106] Iteration 23260, lr = 0.0002
I0529 08:52:41.313933 10644 solver.cpp:228] Iteration 23280, loss = 0.517033
I0529 08:52:41.313962 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 08:52:41.313972 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363351 (* 1 = 0.0363351 loss)
I0529 08:52:41.313978 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.283548 (* 1 = 0.283548 loss)
I0529 08:52:41.313985 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00528692 (* 1 = 0.00528692 loss)
I0529 08:52:41.313992 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132304 (* 1 = 0.0132304 loss)
I0529 08:52:41.313998 10644 sgd_solver.cpp:106] Iteration 23280, lr = 0.0002
I0529 08:53:29.871780 10644 solver.cpp:228] Iteration 23300, loss = 0.312765
I0529 08:53:29.871810 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:53:29.871821 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340466 (* 1 = 0.0340466 loss)
I0529 08:53:29.871829 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.049291 (* 1 = 0.049291 loss)
I0529 08:53:29.871834 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00676845 (* 1 = 0.00676845 loss)
I0529 08:53:29.871840 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167697 (* 1 = 0.0167697 loss)
I0529 08:53:29.871848 10644 sgd_solver.cpp:106] Iteration 23300, lr = 0.0002
I0529 08:54:18.425786 10644 solver.cpp:228] Iteration 23320, loss = 0.312006
I0529 08:54:18.425810 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 08:54:18.425819 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.076974 (* 1 = 0.076974 loss)
I0529 08:54:18.425825 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0768121 (* 1 = 0.0768121 loss)
I0529 08:54:18.425832 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00559782 (* 1 = 0.00559782 loss)
I0529 08:54:18.425837 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132176 (* 1 = 0.0132176 loss)
I0529 08:54:18.425843 10644 sgd_solver.cpp:106] Iteration 23320, lr = 0.0002
I0529 08:55:06.965481 10644 solver.cpp:228] Iteration 23340, loss = 0.485449
I0529 08:55:06.965507 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 08:55:06.965513 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.212283 (* 1 = 0.212283 loss)
I0529 08:55:06.965517 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.237702 (* 1 = 0.237702 loss)
I0529 08:55:06.965520 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00611315 (* 1 = 0.00611315 loss)
I0529 08:55:06.965524 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0690381 (* 1 = 0.0690381 loss)
I0529 08:55:06.965529 10644 sgd_solver.cpp:106] Iteration 23340, lr = 0.0002
I0529 08:55:55.532860 10644 solver.cpp:228] Iteration 23360, loss = 0.196152
I0529 08:55:55.532889 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:55:55.532899 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284799 (* 1 = 0.0284799 loss)
I0529 08:55:55.532905 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.058555 (* 1 = 0.058555 loss)
I0529 08:55:55.532913 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00230791 (* 1 = 0.00230791 loss)
I0529 08:55:55.532920 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00506296 (* 1 = 0.00506296 loss)
I0529 08:55:55.532927 10644 sgd_solver.cpp:106] Iteration 23360, lr = 0.0002
I0529 08:56:44.081818 10644 solver.cpp:228] Iteration 23380, loss = 0.274487
I0529 08:56:44.081848 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 08:56:44.081856 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191024 (* 1 = 0.0191024 loss)
I0529 08:56:44.081861 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0210045 (* 1 = 0.0210045 loss)
I0529 08:56:44.081864 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00176816 (* 1 = 0.00176816 loss)
I0529 08:56:44.081867 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163879 (* 1 = 0.0163879 loss)
I0529 08:56:44.081873 10644 sgd_solver.cpp:106] Iteration 23380, lr = 0.0002
speed: 2.429s / iter
I0529 08:57:32.611569 10644 solver.cpp:228] Iteration 23400, loss = 0.501099
I0529 08:57:32.611598 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 08:57:32.611604 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.103002 (* 1 = 0.103002 loss)
I0529 08:57:32.611608 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.20641 (* 1 = 0.20641 loss)
I0529 08:57:32.611613 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00453844 (* 1 = 0.00453844 loss)
I0529 08:57:32.611615 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.054549 (* 1 = 0.054549 loss)
I0529 08:57:32.611620 10644 sgd_solver.cpp:106] Iteration 23400, lr = 0.0002
I0529 08:58:21.178623 10644 solver.cpp:228] Iteration 23420, loss = 0.29645
I0529 08:58:21.178650 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:58:21.178658 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187148 (* 1 = 0.0187148 loss)
I0529 08:58:21.178661 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0464899 (* 1 = 0.0464899 loss)
I0529 08:58:21.178665 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00391329 (* 1 = 0.00391329 loss)
I0529 08:58:21.178669 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00502905 (* 1 = 0.00502905 loss)
I0529 08:58:21.178674 10644 sgd_solver.cpp:106] Iteration 23420, lr = 0.0002
I0529 08:59:09.760162 10644 solver.cpp:228] Iteration 23440, loss = 0.297946
I0529 08:59:09.760190 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 08:59:09.760197 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359429 (* 1 = 0.0359429 loss)
I0529 08:59:09.760201 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0537491 (* 1 = 0.0537491 loss)
I0529 08:59:09.760205 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00478567 (* 1 = 0.00478567 loss)
I0529 08:59:09.760208 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00297886 (* 1 = 0.00297886 loss)
I0529 08:59:09.760215 10644 sgd_solver.cpp:106] Iteration 23440, lr = 0.0002
I0529 08:59:58.315312 10644 solver.cpp:228] Iteration 23460, loss = 0.399348
I0529 08:59:58.315335 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 08:59:58.315342 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0696126 (* 1 = 0.0696126 loss)
I0529 08:59:58.315346 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0530036 (* 1 = 0.0530036 loss)
I0529 08:59:58.315351 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0018396 (* 1 = 0.0018396 loss)
I0529 08:59:58.315353 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0099763 (* 1 = 0.0099763 loss)
I0529 08:59:58.315358 10644 sgd_solver.cpp:106] Iteration 23460, lr = 0.0002
I0529 09:00:46.862659 10644 solver.cpp:228] Iteration 23480, loss = 0.207879
I0529 09:00:46.862684 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:00:46.862691 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360777 (* 1 = 0.0360777 loss)
I0529 09:00:46.862696 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0778204 (* 1 = 0.0778204 loss)
I0529 09:00:46.862700 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00383368 (* 1 = 0.00383368 loss)
I0529 09:00:46.862704 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00181306 (* 1 = 0.00181306 loss)
I0529 09:00:46.862710 10644 sgd_solver.cpp:106] Iteration 23480, lr = 0.0002
I0529 09:01:35.412572 10644 solver.cpp:228] Iteration 23500, loss = 0.237179
I0529 09:01:35.412598 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 09:01:35.412606 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0774378 (* 1 = 0.0774378 loss)
I0529 09:01:35.412611 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174743 (* 1 = 0.174743 loss)
I0529 09:01:35.412616 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00924912 (* 1 = 0.00924912 loss)
I0529 09:01:35.412618 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010397 (* 1 = 0.010397 loss)
I0529 09:01:35.412623 10644 sgd_solver.cpp:106] Iteration 23500, lr = 0.0002
I0529 09:02:23.935937 10644 solver.cpp:228] Iteration 23520, loss = 0.281002
I0529 09:02:23.935968 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 09:02:23.935976 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.1646 (* 1 = 0.1646 loss)
I0529 09:02:23.935981 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.293394 (* 1 = 0.293394 loss)
I0529 09:02:23.935984 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133904 (* 1 = 0.0133904 loss)
I0529 09:02:23.935988 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0974241 (* 1 = 0.0974241 loss)
I0529 09:02:23.935995 10644 sgd_solver.cpp:106] Iteration 23520, lr = 0.0002
I0529 09:03:12.463083 10644 solver.cpp:228] Iteration 23540, loss = 0.231874
I0529 09:03:12.463112 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 09:03:12.463120 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.13367 (* 1 = 0.13367 loss)
I0529 09:03:12.463124 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.165889 (* 1 = 0.165889 loss)
I0529 09:03:12.463129 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124116 (* 1 = 0.0124116 loss)
I0529 09:03:12.463132 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348185 (* 1 = 0.0348185 loss)
I0529 09:03:12.463138 10644 sgd_solver.cpp:106] Iteration 23540, lr = 0.0002
I0529 09:04:01.007625 10644 solver.cpp:228] Iteration 23560, loss = 0.292794
I0529 09:04:01.007652 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:04:01.007660 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561932 (* 1 = 0.0561932 loss)
I0529 09:04:01.007665 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.105956 (* 1 = 0.105956 loss)
I0529 09:04:01.007669 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474786 (* 1 = 0.00474786 loss)
I0529 09:04:01.007673 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0455539 (* 1 = 0.0455539 loss)
I0529 09:04:01.007678 10644 sgd_solver.cpp:106] Iteration 23560, lr = 0.0002
I0529 09:04:49.571938 10644 solver.cpp:228] Iteration 23580, loss = 0.330019
I0529 09:04:49.571962 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:04:49.571972 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0330866 (* 1 = 0.0330866 loss)
I0529 09:04:49.571979 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174262 (* 1 = 0.174262 loss)
I0529 09:04:49.571985 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138718 (* 1 = 0.0138718 loss)
I0529 09:04:49.571990 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180785 (* 1 = 0.0180785 loss)
I0529 09:04:49.571997 10644 sgd_solver.cpp:106] Iteration 23580, lr = 0.0002
speed: 2.429s / iter
I0529 09:05:38.141613 10644 solver.cpp:228] Iteration 23600, loss = 0.240621
I0529 09:05:38.141640 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:05:38.141649 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0582186 (* 1 = 0.0582186 loss)
I0529 09:05:38.141652 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0868218 (* 1 = 0.0868218 loss)
I0529 09:05:38.141656 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273839 (* 1 = 0.00273839 loss)
I0529 09:05:38.141660 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00759398 (* 1 = 0.00759398 loss)
I0529 09:05:38.141666 10644 sgd_solver.cpp:106] Iteration 23600, lr = 0.0002
I0529 09:06:26.680820 10644 solver.cpp:228] Iteration 23620, loss = 0.396456
I0529 09:06:26.680846 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:06:26.680855 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341452 (* 1 = 0.0341452 loss)
I0529 09:06:26.680858 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0703663 (* 1 = 0.0703663 loss)
I0529 09:06:26.680862 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648247 (* 1 = 0.00648247 loss)
I0529 09:06:26.680866 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00589213 (* 1 = 0.00589213 loss)
I0529 09:06:26.680872 10644 sgd_solver.cpp:106] Iteration 23620, lr = 0.0002
I0529 09:07:15.230051 10644 solver.cpp:228] Iteration 23640, loss = 0.276455
I0529 09:07:15.230080 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 09:07:15.230087 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.135097 (* 1 = 0.135097 loss)
I0529 09:07:15.230092 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.266291 (* 1 = 0.266291 loss)
I0529 09:07:15.230095 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0472002 (* 1 = 0.0472002 loss)
I0529 09:07:15.230098 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0503756 (* 1 = 0.0503756 loss)
I0529 09:07:15.230104 10644 sgd_solver.cpp:106] Iteration 23640, lr = 0.0002
I0529 09:08:03.757745 10644 solver.cpp:228] Iteration 23660, loss = 0.294153
I0529 09:08:03.757766 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 09:08:03.757773 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0765008 (* 1 = 0.0765008 loss)
I0529 09:08:03.757777 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.17088 (* 1 = 0.17088 loss)
I0529 09:08:03.757781 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000763777 (* 1 = 0.000763777 loss)
I0529 09:08:03.757784 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00493394 (* 1 = 0.00493394 loss)
I0529 09:08:03.757789 10644 sgd_solver.cpp:106] Iteration 23660, lr = 0.0002
I0529 09:08:52.294798 10644 solver.cpp:228] Iteration 23680, loss = 0.407963
I0529 09:08:52.294826 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 09:08:52.294836 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.218986 (* 1 = 0.218986 loss)
I0529 09:08:52.294842 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.44283 (* 1 = 0.44283 loss)
I0529 09:08:52.294847 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193285 (* 1 = 0.0193285 loss)
I0529 09:08:52.294852 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0441419 (* 1 = 0.0441419 loss)
I0529 09:08:52.294858 10644 sgd_solver.cpp:106] Iteration 23680, lr = 0.0002
I0529 09:09:40.852691 10644 solver.cpp:228] Iteration 23700, loss = 0.260085
I0529 09:09:40.852722 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:09:40.852733 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237945 (* 1 = 0.0237945 loss)
I0529 09:09:40.852740 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.102661 (* 1 = 0.102661 loss)
I0529 09:09:40.852746 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014464 (* 1 = 0.014464 loss)
I0529 09:09:40.852751 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0856243 (* 1 = 0.0856243 loss)
I0529 09:09:40.852761 10644 sgd_solver.cpp:106] Iteration 23700, lr = 0.0002
I0529 09:10:29.417960 10644 solver.cpp:228] Iteration 23720, loss = 0.143596
I0529 09:10:29.417989 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:10:29.417997 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0700726 (* 1 = 0.0700726 loss)
I0529 09:10:29.418001 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0955411 (* 1 = 0.0955411 loss)
I0529 09:10:29.418005 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938095 (* 1 = 0.00938095 loss)
I0529 09:10:29.418009 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0073673 (* 1 = 0.0073673 loss)
I0529 09:10:29.418014 10644 sgd_solver.cpp:106] Iteration 23720, lr = 0.0002
I0529 09:11:18.004701 10644 solver.cpp:228] Iteration 23740, loss = 0.291307
I0529 09:11:18.004729 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 09:11:18.004736 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.214622 (* 1 = 0.214622 loss)
I0529 09:11:18.004739 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.225383 (* 1 = 0.225383 loss)
I0529 09:11:18.004743 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00475366 (* 1 = 0.00475366 loss)
I0529 09:11:18.004747 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514696 (* 1 = 0.0514696 loss)
I0529 09:11:18.004751 10644 sgd_solver.cpp:106] Iteration 23740, lr = 0.0002
I0529 09:12:06.572226 10644 solver.cpp:228] Iteration 23760, loss = 0.51607
I0529 09:12:06.572250 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 09:12:06.572257 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.397998 (* 1 = 0.397998 loss)
I0529 09:12:06.572260 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.474055 (* 1 = 0.474055 loss)
I0529 09:12:06.572264 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0481866 (* 1 = 0.0481866 loss)
I0529 09:12:06.572268 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.065731 (* 1 = 0.065731 loss)
I0529 09:12:06.572273 10644 sgd_solver.cpp:106] Iteration 23760, lr = 0.0002
I0529 09:12:55.115814 10644 solver.cpp:228] Iteration 23780, loss = 0.25392
I0529 09:12:55.115841 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 09:12:55.115849 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.190382 (* 1 = 0.190382 loss)
I0529 09:12:55.115852 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.252456 (* 1 = 0.252456 loss)
I0529 09:12:55.115855 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0207904 (* 1 = 0.0207904 loss)
I0529 09:12:55.115859 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254884 (* 1 = 0.0254884 loss)
I0529 09:12:55.115865 10644 sgd_solver.cpp:106] Iteration 23780, lr = 0.0002
speed: 2.429s / iter
I0529 09:13:43.678282 10644 solver.cpp:228] Iteration 23800, loss = 0.454366
I0529 09:13:43.678308 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:13:43.678314 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.075084 (* 1 = 0.075084 loss)
I0529 09:13:43.678319 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0711048 (* 1 = 0.0711048 loss)
I0529 09:13:43.678323 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113389 (* 1 = 0.00113389 loss)
I0529 09:13:43.678328 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00678929 (* 1 = 0.00678929 loss)
I0529 09:13:43.678333 10644 sgd_solver.cpp:106] Iteration 23800, lr = 0.0002
I0529 09:14:32.218314 10644 solver.cpp:228] Iteration 23820, loss = 0.207304
I0529 09:14:32.218343 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:14:32.218350 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0678086 (* 1 = 0.0678086 loss)
I0529 09:14:32.218355 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0770601 (* 1 = 0.0770601 loss)
I0529 09:14:32.218359 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0030831 (* 1 = 0.0030831 loss)
I0529 09:14:32.218364 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126519 (* 1 = 0.0126519 loss)
I0529 09:14:32.218369 10644 sgd_solver.cpp:106] Iteration 23820, lr = 0.0002
I0529 09:15:20.751482 10644 solver.cpp:228] Iteration 23840, loss = 0.130305
I0529 09:15:20.751507 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:15:20.751515 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0799834 (* 1 = 0.0799834 loss)
I0529 09:15:20.751519 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.135966 (* 1 = 0.135966 loss)
I0529 09:15:20.751523 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00718284 (* 1 = 0.00718284 loss)
I0529 09:15:20.751528 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198106 (* 1 = 0.0198106 loss)
I0529 09:15:20.751533 10644 sgd_solver.cpp:106] Iteration 23840, lr = 0.0002
I0529 09:16:09.323410 10644 solver.cpp:228] Iteration 23860, loss = 0.320027
I0529 09:16:09.323436 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 09:16:09.323444 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0054815 (* 1 = 0.0054815 loss)
I0529 09:16:09.323448 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0262303 (* 1 = 0.0262303 loss)
I0529 09:16:09.323452 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541762 (* 1 = 0.00541762 loss)
I0529 09:16:09.323457 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00444754 (* 1 = 0.00444754 loss)
I0529 09:16:09.323462 10644 sgd_solver.cpp:106] Iteration 23860, lr = 0.0002
I0529 09:16:57.884443 10644 solver.cpp:228] Iteration 23880, loss = 0.196008
I0529 09:16:57.884470 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:16:57.884480 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320806 (* 1 = 0.0320806 loss)
I0529 09:16:57.884487 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0794024 (* 1 = 0.0794024 loss)
I0529 09:16:57.884493 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0297997 (* 1 = 0.0297997 loss)
I0529 09:16:57.884498 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212388 (* 1 = 0.0212388 loss)
I0529 09:16:57.884505 10644 sgd_solver.cpp:106] Iteration 23880, lr = 0.0002
I0529 09:17:46.459697 10644 solver.cpp:228] Iteration 23900, loss = 0.180672
I0529 09:17:46.459723 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:17:46.459730 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511256 (* 1 = 0.0511256 loss)
I0529 09:17:46.459734 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0577046 (* 1 = 0.0577046 loss)
I0529 09:17:46.459739 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00299432 (* 1 = 0.00299432 loss)
I0529 09:17:46.459743 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0093644 (* 1 = 0.0093644 loss)
I0529 09:17:46.459748 10644 sgd_solver.cpp:106] Iteration 23900, lr = 0.0002
I0529 09:18:35.034224 10644 solver.cpp:228] Iteration 23920, loss = 0.211457
I0529 09:18:35.034250 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:18:35.034260 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432445 (* 1 = 0.0432445 loss)
I0529 09:18:35.034266 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0911742 (* 1 = 0.0911742 loss)
I0529 09:18:35.034272 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011075 (* 1 = 0.011075 loss)
I0529 09:18:35.034278 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022528 (* 1 = 0.022528 loss)
I0529 09:18:35.034286 10644 sgd_solver.cpp:106] Iteration 23920, lr = 0.0002
I0529 09:19:23.614367 10644 solver.cpp:228] Iteration 23940, loss = 0.245787
I0529 09:19:23.614395 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:19:23.614403 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000909188 (* 1 = 0.000909188 loss)
I0529 09:19:23.614408 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0604258 (* 1 = 0.0604258 loss)
I0529 09:19:23.614413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114248 (* 1 = 0.0114248 loss)
I0529 09:19:23.614415 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323968 (* 1 = 0.0323968 loss)
I0529 09:19:23.614420 10644 sgd_solver.cpp:106] Iteration 23940, lr = 0.0002
I0529 09:20:12.141702 10644 solver.cpp:228] Iteration 23960, loss = 0.323306
I0529 09:20:12.141729 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:20:12.141738 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460012 (* 1 = 0.0460012 loss)
I0529 09:20:12.141746 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10309 (* 1 = 0.10309 loss)
I0529 09:20:12.141752 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108158 (* 1 = 0.0108158 loss)
I0529 09:20:12.141757 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150049 (* 1 = 0.0150049 loss)
I0529 09:20:12.141762 10644 sgd_solver.cpp:106] Iteration 23960, lr = 0.0002
I0529 09:21:00.657130 10644 solver.cpp:228] Iteration 23980, loss = 0.260694
I0529 09:21:00.657164 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 09:21:00.657177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000696554 (* 1 = 0.000696554 loss)
I0529 09:21:00.657186 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0228689 (* 1 = 0.0228689 loss)
I0529 09:21:00.657196 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254062 (* 1 = 0.0254062 loss)
I0529 09:21:00.657203 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119145 (* 1 = 0.0119145 loss)
I0529 09:21:00.657212 10644 sgd_solver.cpp:106] Iteration 23980, lr = 0.0002
speed: 2.429s / iter
I0529 09:21:49.268720 10644 solver.cpp:228] Iteration 24000, loss = 0.281218
I0529 09:21:49.268748 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:21:49.268755 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0981275 (* 1 = 0.0981275 loss)
I0529 09:21:49.268760 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.111454 (* 1 = 0.111454 loss)
I0529 09:21:49.268764 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034625 (* 1 = 0.0034625 loss)
I0529 09:21:49.268769 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133328 (* 1 = 0.0133328 loss)
I0529 09:21:49.268774 10644 sgd_solver.cpp:106] Iteration 24000, lr = 0.0002
I0529 09:22:37.797834 10644 solver.cpp:228] Iteration 24020, loss = 0.243037
I0529 09:22:37.797859 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 09:22:37.797868 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0546126 (* 1 = 0.0546126 loss)
I0529 09:22:37.797873 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.167609 (* 1 = 0.167609 loss)
I0529 09:22:37.797875 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178761 (* 1 = 0.0178761 loss)
I0529 09:22:37.797879 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139038 (* 1 = 0.0139038 loss)
I0529 09:22:37.797884 10644 sgd_solver.cpp:106] Iteration 24020, lr = 0.0002
I0529 09:23:26.338706 10644 solver.cpp:228] Iteration 24040, loss = 0.331899
I0529 09:23:26.338732 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 09:23:26.338739 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140004 (* 1 = 0.0140004 loss)
I0529 09:23:26.338743 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0462443 (* 1 = 0.0462443 loss)
I0529 09:23:26.338747 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165845 (* 1 = 0.00165845 loss)
I0529 09:23:26.338752 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00959786 (* 1 = 0.00959786 loss)
I0529 09:23:26.338757 10644 sgd_solver.cpp:106] Iteration 24040, lr = 0.0002
I0529 09:24:14.903290 10644 solver.cpp:228] Iteration 24060, loss = 0.227167
I0529 09:24:14.903316 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 09:24:14.903323 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0981574 (* 1 = 0.0981574 loss)
I0529 09:24:14.903328 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.221557 (* 1 = 0.221557 loss)
I0529 09:24:14.903332 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165455 (* 1 = 0.0165455 loss)
I0529 09:24:14.903336 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286354 (* 1 = 0.0286354 loss)
I0529 09:24:14.903340 10644 sgd_solver.cpp:106] Iteration 24060, lr = 0.0002
I0529 09:25:03.427610 10644 solver.cpp:228] Iteration 24080, loss = 0.24171
I0529 09:25:03.427644 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:25:03.427654 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0478036 (* 1 = 0.0478036 loss)
I0529 09:25:03.427659 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136468 (* 1 = 0.136468 loss)
I0529 09:25:03.427661 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0269574 (* 1 = 0.0269574 loss)
I0529 09:25:03.427665 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181291 (* 1 = 0.0181291 loss)
I0529 09:25:03.427671 10644 sgd_solver.cpp:106] Iteration 24080, lr = 0.0002
I0529 09:25:51.959830 10644 solver.cpp:228] Iteration 24100, loss = 0.355632
I0529 09:25:51.959859 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:25:51.959867 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.130531 (* 1 = 0.130531 loss)
I0529 09:25:51.959872 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120956 (* 1 = 0.120956 loss)
I0529 09:25:51.959875 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00417565 (* 1 = 0.00417565 loss)
I0529 09:25:51.959879 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240487 (* 1 = 0.0240487 loss)
I0529 09:25:51.959885 10644 sgd_solver.cpp:106] Iteration 24100, lr = 0.0002
I0529 09:26:40.472189 10644 solver.cpp:228] Iteration 24120, loss = 0.32336
I0529 09:26:40.472218 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 09:26:40.472224 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0838176 (* 1 = 0.0838176 loss)
I0529 09:26:40.472229 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.065387 (* 1 = 0.065387 loss)
I0529 09:26:40.472232 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00934287 (* 1 = 0.00934287 loss)
I0529 09:26:40.472235 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00784297 (* 1 = 0.00784297 loss)
I0529 09:26:40.472240 10644 sgd_solver.cpp:106] Iteration 24120, lr = 0.0002
I0529 09:27:29.017143 10644 solver.cpp:228] Iteration 24140, loss = 0.607501
I0529 09:27:29.017168 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 09:27:29.017177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.164622 (* 1 = 0.164622 loss)
I0529 09:27:29.017182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.262795 (* 1 = 0.262795 loss)
I0529 09:27:29.017189 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016777 (* 1 = 0.016777 loss)
I0529 09:27:29.017194 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0737781 (* 1 = 0.0737781 loss)
I0529 09:27:29.017200 10644 sgd_solver.cpp:106] Iteration 24140, lr = 0.0002
I0529 09:28:17.528302 10644 solver.cpp:228] Iteration 24160, loss = 0.371812
I0529 09:28:17.528328 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 09:28:17.528334 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100005 (* 1 = 0.100005 loss)
I0529 09:28:17.528338 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.158562 (* 1 = 0.158562 loss)
I0529 09:28:17.528342 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129817 (* 1 = 0.0129817 loss)
I0529 09:28:17.528345 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0835185 (* 1 = 0.0835185 loss)
I0529 09:28:17.528350 10644 sgd_solver.cpp:106] Iteration 24160, lr = 0.0002
I0529 09:29:06.036636 10644 solver.cpp:228] Iteration 24180, loss = 0.328424
I0529 09:29:06.036664 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:29:06.036670 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0271707 (* 1 = 0.0271707 loss)
I0529 09:29:06.036674 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.058903 (* 1 = 0.058903 loss)
I0529 09:29:06.036677 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113889 (* 1 = 0.0113889 loss)
I0529 09:29:06.036680 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141606 (* 1 = 0.0141606 loss)
I0529 09:29:06.036685 10644 sgd_solver.cpp:106] Iteration 24180, lr = 0.0002
speed: 2.429s / iter
I0529 09:29:54.590637 10644 solver.cpp:228] Iteration 24200, loss = 0.25362
I0529 09:29:54.590664 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:29:54.590672 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0899213 (* 1 = 0.0899213 loss)
I0529 09:29:54.590675 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.133683 (* 1 = 0.133683 loss)
I0529 09:29:54.590679 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00325324 (* 1 = 0.00325324 loss)
I0529 09:29:54.590683 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103456 (* 1 = 0.0103456 loss)
I0529 09:29:54.590688 10644 sgd_solver.cpp:106] Iteration 24200, lr = 0.0002
I0529 09:30:43.134670 10644 solver.cpp:228] Iteration 24220, loss = 0.320576
I0529 09:30:43.134692 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 09:30:43.134699 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0184687 (* 1 = 0.0184687 loss)
I0529 09:30:43.134703 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.222377 (* 1 = 0.222377 loss)
I0529 09:30:43.134707 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0229792 (* 1 = 0.0229792 loss)
I0529 09:30:43.134711 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176281 (* 1 = 0.0176281 loss)
I0529 09:30:43.134716 10644 sgd_solver.cpp:106] Iteration 24220, lr = 0.0002
I0529 09:31:31.650969 10644 solver.cpp:228] Iteration 24240, loss = 0.200523
I0529 09:31:31.650995 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:31:31.651002 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518431 (* 1 = 0.0518431 loss)
I0529 09:31:31.651006 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0680543 (* 1 = 0.0680543 loss)
I0529 09:31:31.651010 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00180758 (* 1 = 0.00180758 loss)
I0529 09:31:31.651013 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00463774 (* 1 = 0.00463774 loss)
I0529 09:31:31.651018 10644 sgd_solver.cpp:106] Iteration 24240, lr = 0.0002
I0529 09:32:20.198561 10644 solver.cpp:228] Iteration 24260, loss = 0.330964
I0529 09:32:20.198590 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 09:32:20.198598 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.193551 (* 1 = 0.193551 loss)
I0529 09:32:20.198602 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.280587 (* 1 = 0.280587 loss)
I0529 09:32:20.198606 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120813 (* 1 = 0.0120813 loss)
I0529 09:32:20.198609 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174746 (* 1 = 0.0174746 loss)
I0529 09:32:20.198614 10644 sgd_solver.cpp:106] Iteration 24260, lr = 0.0002
I0529 09:33:08.758301 10644 solver.cpp:228] Iteration 24280, loss = 0.477597
I0529 09:33:08.758327 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 09:33:08.758335 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.169616 (* 1 = 0.169616 loss)
I0529 09:33:08.758340 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.181875 (* 1 = 0.181875 loss)
I0529 09:33:08.758344 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00421424 (* 1 = 0.00421424 loss)
I0529 09:33:08.758348 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331116 (* 1 = 0.0331116 loss)
I0529 09:33:08.758353 10644 sgd_solver.cpp:106] Iteration 24280, lr = 0.0002
I0529 09:33:57.279132 10644 solver.cpp:228] Iteration 24300, loss = 0.375058
I0529 09:33:57.279160 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 09:33:57.279168 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0579819 (* 1 = 0.0579819 loss)
I0529 09:33:57.279172 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0453764 (* 1 = 0.0453764 loss)
I0529 09:33:57.279176 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0071009 (* 1 = 0.0071009 loss)
I0529 09:33:57.279181 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0423728 (* 1 = 0.0423728 loss)
I0529 09:33:57.279186 10644 sgd_solver.cpp:106] Iteration 24300, lr = 0.0002
I0529 09:34:45.825011 10644 solver.cpp:228] Iteration 24320, loss = 0.214531
I0529 09:34:45.825042 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 09:34:45.825049 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.03978 (* 1 = 0.03978 loss)
I0529 09:34:45.825053 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0451168 (* 1 = 0.0451168 loss)
I0529 09:34:45.825057 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010541 (* 1 = 0.0010541 loss)
I0529 09:34:45.825062 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00865665 (* 1 = 0.00865665 loss)
I0529 09:34:45.825067 10644 sgd_solver.cpp:106] Iteration 24320, lr = 0.0002
I0529 09:35:34.378901 10644 solver.cpp:228] Iteration 24340, loss = 0.279469
I0529 09:35:34.378929 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 09:35:34.378937 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.126047 (* 1 = 0.126047 loss)
I0529 09:35:34.378942 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0973379 (* 1 = 0.0973379 loss)
I0529 09:35:34.378947 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00274212 (* 1 = 0.00274212 loss)
I0529 09:35:34.378950 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00979323 (* 1 = 0.00979323 loss)
I0529 09:35:34.378955 10644 sgd_solver.cpp:106] Iteration 24340, lr = 0.0002
I0529 09:36:22.949210 10644 solver.cpp:228] Iteration 24360, loss = 0.139113
I0529 09:36:22.949247 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 09:36:22.949256 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0504705 (* 1 = 0.0504705 loss)
I0529 09:36:22.949260 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0470181 (* 1 = 0.0470181 loss)
I0529 09:36:22.949265 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00625 (* 1 = 0.00625 loss)
I0529 09:36:22.949268 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191904 (* 1 = 0.0191904 loss)
I0529 09:36:22.949276 10644 sgd_solver.cpp:106] Iteration 24360, lr = 0.0002
I0529 09:37:11.512145 10644 solver.cpp:228] Iteration 24380, loss = 0.243734
I0529 09:37:11.512171 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 09:37:11.512179 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0975763 (* 1 = 0.0975763 loss)
I0529 09:37:11.512184 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145501 (* 1 = 0.145501 loss)
I0529 09:37:11.512188 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350898 (* 1 = 0.00350898 loss)
I0529 09:37:11.512192 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146798 (* 1 = 0.0146798 loss)
I0529 09:37:11.512197 10644 sgd_solver.cpp:106] Iteration 24380, lr = 0.0002
speed: 2.429s / iter
I0529 09:38:00.080075 10644 solver.cpp:228] Iteration 24400, loss = 0.280801
I0529 09:38:00.080104 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:38:00.080112 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.131502 (* 1 = 0.131502 loss)
I0529 09:38:00.080116 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.14799 (* 1 = 0.14799 loss)
I0529 09:38:00.080121 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0359037 (* 1 = 0.0359037 loss)
I0529 09:38:00.080124 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00379994 (* 1 = 0.00379994 loss)
I0529 09:38:00.080130 10644 sgd_solver.cpp:106] Iteration 24400, lr = 0.0002
I0529 09:38:48.635749 10644 solver.cpp:228] Iteration 24420, loss = 0.293765
I0529 09:38:48.635774 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 09:38:48.635782 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0342276 (* 1 = 0.0342276 loss)
I0529 09:38:48.635787 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.139564 (* 1 = 0.139564 loss)
I0529 09:38:48.635790 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105434 (* 1 = 0.0105434 loss)
I0529 09:38:48.635793 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165597 (* 1 = 0.0165597 loss)
I0529 09:38:48.635799 10644 sgd_solver.cpp:106] Iteration 24420, lr = 0.0002
I0529 09:39:37.172117 10644 solver.cpp:228] Iteration 24440, loss = 0.297984
I0529 09:39:37.172140 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 09:39:37.172147 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0998748 (* 1 = 0.0998748 loss)
I0529 09:39:37.172152 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.148763 (* 1 = 0.148763 loss)
I0529 09:39:37.172155 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00921617 (* 1 = 0.00921617 loss)
I0529 09:39:37.172158 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252418 (* 1 = 0.0252418 loss)
I0529 09:39:37.172164 10644 sgd_solver.cpp:106] Iteration 24440, lr = 0.0002
I0529 09:40:25.700850 10644 solver.cpp:228] Iteration 24460, loss = 0.326168
I0529 09:40:25.700875 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:40:25.700882 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.147406 (* 1 = 0.147406 loss)
I0529 09:40:25.700886 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.111596 (* 1 = 0.111596 loss)
I0529 09:40:25.700889 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485673 (* 1 = 0.00485673 loss)
I0529 09:40:25.700893 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300961 (* 1 = 0.0300961 loss)
I0529 09:40:25.700898 10644 sgd_solver.cpp:106] Iteration 24460, lr = 0.0002
I0529 09:41:14.240707 10644 solver.cpp:228] Iteration 24480, loss = 0.320603
I0529 09:41:14.240736 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 09:41:14.240742 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.154673 (* 1 = 0.154673 loss)
I0529 09:41:14.240746 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.243869 (* 1 = 0.243869 loss)
I0529 09:41:14.240749 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00939934 (* 1 = 0.00939934 loss)
I0529 09:41:14.240753 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.046878 (* 1 = 0.046878 loss)
I0529 09:41:14.240758 10644 sgd_solver.cpp:106] Iteration 24480, lr = 0.0002
I0529 09:42:02.814976 10644 solver.cpp:228] Iteration 24500, loss = 0.359648
I0529 09:42:02.815004 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:42:02.815011 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0897897 (* 1 = 0.0897897 loss)
I0529 09:42:02.815016 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0608575 (* 1 = 0.0608575 loss)
I0529 09:42:02.815019 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133952 (* 1 = 0.00133952 loss)
I0529 09:42:02.815022 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00712989 (* 1 = 0.00712989 loss)
I0529 09:42:02.815028 10644 sgd_solver.cpp:106] Iteration 24500, lr = 0.0002
I0529 09:42:51.377581 10644 solver.cpp:228] Iteration 24520, loss = 0.216865
I0529 09:42:51.377606 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:42:51.377614 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0136202 (* 1 = 0.0136202 loss)
I0529 09:42:51.377617 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0492615 (* 1 = 0.0492615 loss)
I0529 09:42:51.377621 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00269315 (* 1 = 0.00269315 loss)
I0529 09:42:51.377624 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00496101 (* 1 = 0.00496101 loss)
I0529 09:42:51.377629 10644 sgd_solver.cpp:106] Iteration 24520, lr = 0.0002
I0529 09:43:39.956835 10644 solver.cpp:228] Iteration 24540, loss = 0.255576
I0529 09:43:39.956866 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:43:39.956876 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00974127 (* 1 = 0.00974127 loss)
I0529 09:43:39.956881 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0786202 (* 1 = 0.0786202 loss)
I0529 09:43:39.956887 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291173 (* 1 = 0.00291173 loss)
I0529 09:43:39.956892 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0039729 (* 1 = 0.0039729 loss)
I0529 09:43:39.956898 10644 sgd_solver.cpp:106] Iteration 24540, lr = 0.0002
I0529 09:44:28.511843 10644 solver.cpp:228] Iteration 24560, loss = 0.263444
I0529 09:44:28.511868 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:44:28.511874 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0352158 (* 1 = 0.0352158 loss)
I0529 09:44:28.511878 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.093727 (* 1 = 0.093727 loss)
I0529 09:44:28.511881 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184565 (* 1 = 0.0184565 loss)
I0529 09:44:28.511885 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205401 (* 1 = 0.0205401 loss)
I0529 09:44:28.511889 10644 sgd_solver.cpp:106] Iteration 24560, lr = 0.0002
I0529 09:45:16.901806 10644 solver.cpp:228] Iteration 24580, loss = 0.17228
I0529 09:45:16.901829 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 09:45:16.901835 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0873994 (* 1 = 0.0873994 loss)
I0529 09:45:16.901839 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170575 (* 1 = 0.170575 loss)
I0529 09:45:16.901842 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161089 (* 1 = 0.0161089 loss)
I0529 09:45:16.901845 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291747 (* 1 = 0.0291747 loss)
I0529 09:45:16.901850 10644 sgd_solver.cpp:106] Iteration 24580, lr = 0.0002
speed: 2.429s / iter
I0529 09:46:05.380926 10644 solver.cpp:228] Iteration 24600, loss = 0.335133
I0529 09:46:05.380996 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 09:46:05.381021 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.06381 (* 1 = 0.06381 loss)
I0529 09:46:05.381039 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.259918 (* 1 = 0.259918 loss)
I0529 09:46:05.381055 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00873386 (* 1 = 0.00873386 loss)
I0529 09:46:05.381070 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258914 (* 1 = 0.0258914 loss)
I0529 09:46:05.381085 10644 sgd_solver.cpp:106] Iteration 24600, lr = 0.0002
I0529 09:46:53.935430 10644 solver.cpp:228] Iteration 24620, loss = 0.374042
I0529 09:46:53.935456 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:46:53.935464 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434629 (* 1 = 0.0434629 loss)
I0529 09:46:53.935468 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0452655 (* 1 = 0.0452655 loss)
I0529 09:46:53.935473 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336045 (* 1 = 0.00336045 loss)
I0529 09:46:53.935477 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106423 (* 1 = 0.0106423 loss)
I0529 09:46:53.935482 10644 sgd_solver.cpp:106] Iteration 24620, lr = 0.0002
I0529 09:47:42.478320 10644 solver.cpp:228] Iteration 24640, loss = 0.183567
I0529 09:47:42.478348 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:47:42.478355 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524652 (* 1 = 0.0524652 loss)
I0529 09:47:42.478359 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0526671 (* 1 = 0.0526671 loss)
I0529 09:47:42.478363 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00416833 (* 1 = 0.00416833 loss)
I0529 09:47:42.478368 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185362 (* 1 = 0.0185362 loss)
I0529 09:47:42.478372 10644 sgd_solver.cpp:106] Iteration 24640, lr = 0.0002
I0529 09:48:31.049815 10644 solver.cpp:228] Iteration 24660, loss = 0.263923
I0529 09:48:31.049840 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 09:48:31.049849 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171318 (* 1 = 0.0171318 loss)
I0529 09:48:31.049854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.087989 (* 1 = 0.087989 loss)
I0529 09:48:31.049857 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778573 (* 1 = 0.00778573 loss)
I0529 09:48:31.049861 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0713513 (* 1 = 0.0713513 loss)
I0529 09:48:31.049866 10644 sgd_solver.cpp:106] Iteration 24660, lr = 0.0002
I0529 09:49:19.593282 10644 solver.cpp:228] Iteration 24680, loss = 0.328924
I0529 09:49:19.593314 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 09:49:19.593324 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.187852 (* 1 = 0.187852 loss)
I0529 09:49:19.593331 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.333144 (* 1 = 0.333144 loss)
I0529 09:49:19.593338 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542176 (* 1 = 0.00542176 loss)
I0529 09:49:19.593344 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232175 (* 1 = 0.0232175 loss)
I0529 09:49:19.593351 10644 sgd_solver.cpp:106] Iteration 24680, lr = 0.0002
I0529 09:50:08.142122 10644 solver.cpp:228] Iteration 24700, loss = 0.209909
I0529 09:50:08.142145 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:50:08.142153 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225138 (* 1 = 0.0225138 loss)
I0529 09:50:08.142158 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0805674 (* 1 = 0.0805674 loss)
I0529 09:50:08.142163 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115749 (* 1 = 0.0115749 loss)
I0529 09:50:08.142165 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153514 (* 1 = 0.0153514 loss)
I0529 09:50:08.142170 10644 sgd_solver.cpp:106] Iteration 24700, lr = 0.0002
I0529 09:50:56.715234 10644 solver.cpp:228] Iteration 24720, loss = 0.375675
I0529 09:50:56.715260 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 09:50:56.715267 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.113571 (* 1 = 0.113571 loss)
I0529 09:50:56.715272 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.146898 (* 1 = 0.146898 loss)
I0529 09:50:56.715276 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00324125 (* 1 = 0.00324125 loss)
I0529 09:50:56.715279 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169251 (* 1 = 0.0169251 loss)
I0529 09:50:56.715284 10644 sgd_solver.cpp:106] Iteration 24720, lr = 0.0002
I0529 09:51:45.264581 10644 solver.cpp:228] Iteration 24740, loss = 0.302541
I0529 09:51:45.264612 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 09:51:45.264621 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443618 (* 1 = 0.0443618 loss)
I0529 09:51:45.264624 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0203476 (* 1 = 0.0203476 loss)
I0529 09:51:45.264629 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00145645 (* 1 = 0.00145645 loss)
I0529 09:51:45.264632 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00458035 (* 1 = 0.00458035 loss)
I0529 09:51:45.264638 10644 sgd_solver.cpp:106] Iteration 24740, lr = 0.0002
I0529 09:52:33.834691 10644 solver.cpp:228] Iteration 24760, loss = 0.240354
I0529 09:52:33.834717 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:52:33.834724 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485521 (* 1 = 0.0485521 loss)
I0529 09:52:33.834728 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109685 (* 1 = 0.109685 loss)
I0529 09:52:33.834733 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00220786 (* 1 = 0.00220786 loss)
I0529 09:52:33.834735 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111464 (* 1 = 0.0111464 loss)
I0529 09:52:33.834740 10644 sgd_solver.cpp:106] Iteration 24760, lr = 0.0002
I0529 09:53:22.390043 10644 solver.cpp:228] Iteration 24780, loss = 0.358173
I0529 09:53:22.390066 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 09:53:22.390074 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312267 (* 1 = 0.0312267 loss)
I0529 09:53:22.390077 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0605425 (* 1 = 0.0605425 loss)
I0529 09:53:22.390081 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508727 (* 1 = 0.00508727 loss)
I0529 09:53:22.390084 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179383 (* 1 = 0.0179383 loss)
I0529 09:53:22.390089 10644 sgd_solver.cpp:106] Iteration 24780, lr = 0.0002
speed: 2.429s / iter
I0529 09:54:10.921375 10644 solver.cpp:228] Iteration 24800, loss = 0.271949
I0529 09:54:10.921401 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 09:54:10.921407 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0328302 (* 1 = 0.0328302 loss)
I0529 09:54:10.921411 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0796623 (* 1 = 0.0796623 loss)
I0529 09:54:10.921417 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150727 (* 1 = 0.00150727 loss)
I0529 09:54:10.921423 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117623 (* 1 = 0.0117623 loss)
I0529 09:54:10.921428 10644 sgd_solver.cpp:106] Iteration 24800, lr = 0.0002
I0529 09:54:59.480424 10644 solver.cpp:228] Iteration 24820, loss = 0.219499
I0529 09:54:59.480450 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 09:54:59.480458 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496339 (* 1 = 0.0496339 loss)
I0529 09:54:59.480461 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0684441 (* 1 = 0.0684441 loss)
I0529 09:54:59.480465 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00523631 (* 1 = 0.00523631 loss)
I0529 09:54:59.480468 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00446101 (* 1 = 0.00446101 loss)
I0529 09:54:59.480474 10644 sgd_solver.cpp:106] Iteration 24820, lr = 0.0002
I0529 09:55:48.030812 10644 solver.cpp:228] Iteration 24840, loss = 0.247924
I0529 09:55:48.030836 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 09:55:48.030844 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562573 (* 1 = 0.0562573 loss)
I0529 09:55:48.030848 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160026 (* 1 = 0.160026 loss)
I0529 09:55:48.030851 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189033 (* 1 = 0.0189033 loss)
I0529 09:55:48.030854 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0417701 (* 1 = 0.0417701 loss)
I0529 09:55:48.030859 10644 sgd_solver.cpp:106] Iteration 24840, lr = 0.0002
I0529 09:56:36.573827 10644 solver.cpp:228] Iteration 24860, loss = 0.289914
I0529 09:56:36.573853 10644 solver.cpp:244]     Train net output #0: accuarcy = 1
I0529 09:56:36.573860 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0202821 (* 1 = 0.0202821 loss)
I0529 09:56:36.573864 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0525932 (* 1 = 0.0525932 loss)
I0529 09:56:36.573868 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00432753 (* 1 = 0.00432753 loss)
I0529 09:56:36.573871 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00206277 (* 1 = 0.00206277 loss)
I0529 09:56:36.573878 10644 sgd_solver.cpp:106] Iteration 24860, lr = 0.0002
I0529 09:57:25.131716 10644 solver.cpp:228] Iteration 24880, loss = 0.346307
I0529 09:57:25.131739 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0529 09:57:25.131747 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.38059 (* 1 = 0.38059 loss)
I0529 09:57:25.131749 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.540965 (* 1 = 0.540965 loss)
I0529 09:57:25.131753 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.034459 (* 1 = 0.034459 loss)
I0529 09:57:25.131757 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.207941 (* 1 = 0.207941 loss)
I0529 09:57:25.131762 10644 sgd_solver.cpp:106] Iteration 24880, lr = 0.0002
I0529 09:58:13.695121 10644 solver.cpp:228] Iteration 24900, loss = 0.142434
I0529 09:58:13.695147 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 09:58:13.695155 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544136 (* 1 = 0.0544136 loss)
I0529 09:58:13.695161 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.065362 (* 1 = 0.065362 loss)
I0529 09:58:13.695166 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0057407 (* 1 = 0.0057407 loss)
I0529 09:58:13.695173 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00235148 (* 1 = 0.00235148 loss)
I0529 09:58:13.695178 10644 sgd_solver.cpp:106] Iteration 24900, lr = 0.0002
I0529 09:59:02.247473 10644 solver.cpp:228] Iteration 24920, loss = 0.570864
I0529 09:59:02.247500 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 09:59:02.247509 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743053 (* 1 = 0.0743053 loss)
I0529 09:59:02.247512 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.380892 (* 1 = 0.380892 loss)
I0529 09:59:02.247516 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276303 (* 1 = 0.0276303 loss)
I0529 09:59:02.247520 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124596 (* 1 = 0.124596 loss)
I0529 09:59:02.247525 10644 sgd_solver.cpp:106] Iteration 24920, lr = 0.0002
I0529 09:59:50.880522 10644 solver.cpp:228] Iteration 24940, loss = 0.194336
I0529 09:59:50.880549 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 09:59:50.880556 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151849 (* 1 = 0.0151849 loss)
I0529 09:59:50.880559 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0483537 (* 1 = 0.0483537 loss)
I0529 09:59:50.880563 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00853092 (* 1 = 0.00853092 loss)
I0529 09:59:50.880568 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109948 (* 1 = 0.0109948 loss)
I0529 09:59:50.880571 10644 sgd_solver.cpp:106] Iteration 24940, lr = 0.0002
I0529 10:00:39.520547 10644 solver.cpp:228] Iteration 24960, loss = 0.23698
I0529 10:00:39.520573 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 10:00:39.520581 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369724 (* 1 = 0.0369724 loss)
I0529 10:00:39.520586 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0570786 (* 1 = 0.0570786 loss)
I0529 10:00:39.520589 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128363 (* 1 = 0.00128363 loss)
I0529 10:00:39.520593 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00209275 (* 1 = 0.00209275 loss)
I0529 10:00:39.520598 10644 sgd_solver.cpp:106] Iteration 24960, lr = 0.0002
I0529 10:01:28.074277 10644 solver.cpp:228] Iteration 24980, loss = 0.174085
I0529 10:01:28.074303 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:01:28.074312 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00131432 (* 1 = 0.00131432 loss)
I0529 10:01:28.074316 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0285921 (* 1 = 0.0285921 loss)
I0529 10:01:28.074321 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491774 (* 1 = 0.00491774 loss)
I0529 10:01:28.074324 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195254 (* 1 = 0.0195254 loss)
I0529 10:01:28.074329 10644 sgd_solver.cpp:106] Iteration 24980, lr = 0.0002
speed: 2.429s / iter
I0529 10:02:14.358928 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_25000.caffemodel
I0529 10:02:17.451930 10644 solver.cpp:228] Iteration 25000, loss = 0.329486
I0529 10:02:17.451954 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:02:17.451962 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758742 (* 1 = 0.0758742 loss)
I0529 10:02:17.451967 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0730337 (* 1 = 0.0730337 loss)
I0529 10:02:17.451970 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130807 (* 1 = 0.0130807 loss)
I0529 10:02:17.451973 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276476 (* 1 = 0.0276476 loss)
I0529 10:02:17.451978 10644 sgd_solver.cpp:106] Iteration 25000, lr = 0.0002
I0529 10:03:05.981819 10644 solver.cpp:228] Iteration 25020, loss = 0.27285
I0529 10:03:05.981847 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:03:05.981854 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138778 (* 1 = 0.0138778 loss)
I0529 10:03:05.981858 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0856057 (* 1 = 0.0856057 loss)
I0529 10:03:05.981863 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109784 (* 1 = 0.0109784 loss)
I0529 10:03:05.981866 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00654907 (* 1 = 0.00654907 loss)
I0529 10:03:05.981871 10644 sgd_solver.cpp:106] Iteration 25020, lr = 0.0002
I0529 10:03:54.537528 10644 solver.cpp:228] Iteration 25040, loss = 0.222936
I0529 10:03:54.537551 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:03:54.537559 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0196205 (* 1 = 0.0196205 loss)
I0529 10:03:54.537562 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.029548 (* 1 = 0.029548 loss)
I0529 10:03:54.537566 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270423 (* 1 = 0.00270423 loss)
I0529 10:03:54.537569 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322254 (* 1 = 0.00322254 loss)
I0529 10:03:54.537573 10644 sgd_solver.cpp:106] Iteration 25040, lr = 0.0002
I0529 10:04:43.096257 10644 solver.cpp:228] Iteration 25060, loss = 0.27785
I0529 10:04:43.096287 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 10:04:43.096295 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.278461 (* 1 = 0.278461 loss)
I0529 10:04:43.096299 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.196469 (* 1 = 0.196469 loss)
I0529 10:04:43.096303 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00825327 (* 1 = 0.00825327 loss)
I0529 10:04:43.096307 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0367833 (* 1 = 0.0367833 loss)
I0529 10:04:43.096313 10644 sgd_solver.cpp:106] Iteration 25060, lr = 0.0002
I0529 10:05:31.656805 10644 solver.cpp:228] Iteration 25080, loss = 0.175173
I0529 10:05:31.656880 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:05:31.656906 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264157 (* 1 = 0.0264157 loss)
I0529 10:05:31.656947 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.111152 (* 1 = 0.111152 loss)
I0529 10:05:31.656967 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00780189 (* 1 = 0.00780189 loss)
I0529 10:05:31.656986 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0094027 (* 1 = 0.0094027 loss)
I0529 10:05:31.657004 10644 sgd_solver.cpp:106] Iteration 25080, lr = 0.0002
I0529 10:06:20.202841 10644 solver.cpp:228] Iteration 25100, loss = 0.565075
I0529 10:06:20.202916 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 10:06:20.202944 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.23474 (* 1 = 0.23474 loss)
I0529 10:06:20.202965 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.277763 (* 1 = 0.277763 loss)
I0529 10:06:20.202985 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0590387 (* 1 = 0.0590387 loss)
I0529 10:06:20.203002 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0685574 (* 1 = 0.0685574 loss)
I0529 10:06:20.203022 10644 sgd_solver.cpp:106] Iteration 25100, lr = 0.0002
I0529 10:07:08.747143 10644 solver.cpp:228] Iteration 25120, loss = 0.374197
I0529 10:07:08.747170 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 10:07:08.747179 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.170897 (* 1 = 0.170897 loss)
I0529 10:07:08.747182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.263213 (* 1 = 0.263213 loss)
I0529 10:07:08.747186 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00810337 (* 1 = 0.00810337 loss)
I0529 10:07:08.747190 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0472427 (* 1 = 0.0472427 loss)
I0529 10:07:08.747196 10644 sgd_solver.cpp:106] Iteration 25120, lr = 0.0002
I0529 10:07:57.287890 10644 solver.cpp:228] Iteration 25140, loss = 0.329319
I0529 10:07:57.287917 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:07:57.287925 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284464 (* 1 = 0.0284464 loss)
I0529 10:07:57.287930 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0310054 (* 1 = 0.0310054 loss)
I0529 10:07:57.287933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00677678 (* 1 = 0.00677678 loss)
I0529 10:07:57.287937 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00747838 (* 1 = 0.00747838 loss)
I0529 10:07:57.287942 10644 sgd_solver.cpp:106] Iteration 25140, lr = 0.0002
I0529 10:08:45.836357 10644 solver.cpp:228] Iteration 25160, loss = 0.272012
I0529 10:08:45.836386 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 10:08:45.836397 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.182606 (* 1 = 0.182606 loss)
I0529 10:08:45.836405 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.297278 (* 1 = 0.297278 loss)
I0529 10:08:45.836410 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00612617 (* 1 = 0.00612617 loss)
I0529 10:08:45.836416 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019699 (* 1 = 0.019699 loss)
I0529 10:08:45.836426 10644 sgd_solver.cpp:106] Iteration 25160, lr = 0.0002
I0529 10:09:34.403664 10644 solver.cpp:228] Iteration 25180, loss = 0.227222
I0529 10:09:34.403693 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:09:34.403702 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613596 (* 1 = 0.0613596 loss)
I0529 10:09:34.403705 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.106104 (* 1 = 0.106104 loss)
I0529 10:09:34.403709 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0404584 (* 1 = 0.0404584 loss)
I0529 10:09:34.403713 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265517 (* 1 = 0.0265517 loss)
I0529 10:09:34.403719 10644 sgd_solver.cpp:106] Iteration 25180, lr = 0.0002
speed: 2.429s / iter
I0529 10:10:22.962219 10644 solver.cpp:228] Iteration 25200, loss = 0.240236
I0529 10:10:22.962246 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 10:10:22.962254 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.113266 (* 1 = 0.113266 loss)
I0529 10:10:22.962258 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.240746 (* 1 = 0.240746 loss)
I0529 10:10:22.962262 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102809 (* 1 = 0.0102809 loss)
I0529 10:10:22.962265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214915 (* 1 = 0.0214915 loss)
I0529 10:10:22.962271 10644 sgd_solver.cpp:106] Iteration 25200, lr = 0.0002
I0529 10:11:11.503980 10644 solver.cpp:228] Iteration 25220, loss = 0.244956
I0529 10:11:11.504006 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 10:11:11.504014 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0990023 (* 1 = 0.0990023 loss)
I0529 10:11:11.504019 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.173596 (* 1 = 0.173596 loss)
I0529 10:11:11.504022 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0097336 (* 1 = 0.0097336 loss)
I0529 10:11:11.504026 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122863 (* 1 = 0.0122863 loss)
I0529 10:11:11.504032 10644 sgd_solver.cpp:106] Iteration 25220, lr = 0.0002
I0529 10:12:00.084426 10644 solver.cpp:228] Iteration 25240, loss = 0.392567
I0529 10:12:00.084455 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 10:12:00.084465 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190076 (* 1 = 0.0190076 loss)
I0529 10:12:00.084470 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0619018 (* 1 = 0.0619018 loss)
I0529 10:12:00.084473 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00498241 (* 1 = 0.00498241 loss)
I0529 10:12:00.084477 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118193 (* 1 = 0.0118193 loss)
I0529 10:12:00.084483 10644 sgd_solver.cpp:106] Iteration 25240, lr = 0.0002
I0529 10:12:48.616344 10644 solver.cpp:228] Iteration 25260, loss = 0.282081
I0529 10:12:48.616371 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:12:48.616379 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000337267 (* 1 = 0.000337267 loss)
I0529 10:12:48.616384 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0207151 (* 1 = 0.0207151 loss)
I0529 10:12:48.616387 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184925 (* 1 = 0.0184925 loss)
I0529 10:12:48.616391 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108218 (* 1 = 0.0108218 loss)
I0529 10:12:48.616396 10644 sgd_solver.cpp:106] Iteration 25260, lr = 0.0002
I0529 10:13:37.132556 10644 solver.cpp:228] Iteration 25280, loss = 0.383577
I0529 10:13:37.132585 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:13:37.132592 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132076 (* 1 = 0.0132076 loss)
I0529 10:13:37.132597 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0254797 (* 1 = 0.0254797 loss)
I0529 10:13:37.132601 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508927 (* 1 = 0.00508927 loss)
I0529 10:13:37.132606 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011021 (* 1 = 0.011021 loss)
I0529 10:13:37.132611 10644 sgd_solver.cpp:106] Iteration 25280, lr = 0.0002
I0529 10:14:25.672123 10644 solver.cpp:228] Iteration 25300, loss = 0.229223
I0529 10:14:25.672152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:14:25.672160 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474017 (* 1 = 0.0474017 loss)
I0529 10:14:25.672164 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0750695 (* 1 = 0.0750695 loss)
I0529 10:14:25.672168 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938713 (* 1 = 0.00938713 loss)
I0529 10:14:25.672173 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275167 (* 1 = 0.0275167 loss)
I0529 10:14:25.672178 10644 sgd_solver.cpp:106] Iteration 25300, lr = 0.0002
I0529 10:15:14.219003 10644 solver.cpp:228] Iteration 25320, loss = 0.243528
I0529 10:15:14.219028 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 10:15:14.219038 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410895 (* 1 = 0.0410895 loss)
I0529 10:15:14.219041 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.139244 (* 1 = 0.139244 loss)
I0529 10:15:14.219045 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00285946 (* 1 = 0.00285946 loss)
I0529 10:15:14.219048 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176753 (* 1 = 0.0176753 loss)
I0529 10:15:14.219054 10644 sgd_solver.cpp:106] Iteration 25320, lr = 0.0002
I0529 10:16:02.755409 10644 solver.cpp:228] Iteration 25340, loss = 0.237883
I0529 10:16:02.755437 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 10:16:02.755445 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.173392 (* 1 = 0.173392 loss)
I0529 10:16:02.755450 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.194871 (* 1 = 0.194871 loss)
I0529 10:16:02.755453 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00394056 (* 1 = 0.00394056 loss)
I0529 10:16:02.755457 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222303 (* 1 = 0.0222303 loss)
I0529 10:16:02.755462 10644 sgd_solver.cpp:106] Iteration 25340, lr = 0.0002
I0529 10:16:51.294689 10644 solver.cpp:228] Iteration 25360, loss = 0.254007
I0529 10:16:51.294713 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 10:16:51.294720 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.212824 (* 1 = 0.212824 loss)
I0529 10:16:51.294724 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.287164 (* 1 = 0.287164 loss)
I0529 10:16:51.294728 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169825 (* 1 = 0.00169825 loss)
I0529 10:16:51.294733 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445898 (* 1 = 0.0445898 loss)
I0529 10:16:51.294736 10644 sgd_solver.cpp:106] Iteration 25360, lr = 0.0002
I0529 10:17:39.828835 10644 solver.cpp:228] Iteration 25380, loss = 0.519707
I0529 10:17:39.828860 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 10:17:39.828866 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.347602 (* 1 = 0.347602 loss)
I0529 10:17:39.828871 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.408917 (* 1 = 0.408917 loss)
I0529 10:17:39.828873 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.020153 (* 1 = 0.020153 loss)
I0529 10:17:39.828877 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0938668 (* 1 = 0.0938668 loss)
I0529 10:17:39.828882 10644 sgd_solver.cpp:106] Iteration 25380, lr = 0.0002
speed: 2.429s / iter
I0529 10:18:28.393476 10644 solver.cpp:228] Iteration 25400, loss = 0.277581
I0529 10:18:28.393499 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:18:28.393507 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0520784 (* 1 = 0.0520784 loss)
I0529 10:18:28.393512 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0410581 (* 1 = 0.0410581 loss)
I0529 10:18:28.393514 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00161158 (* 1 = 0.00161158 loss)
I0529 10:18:28.393518 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00441884 (* 1 = 0.00441884 loss)
I0529 10:18:28.393523 10644 sgd_solver.cpp:106] Iteration 25400, lr = 0.0002
I0529 10:19:16.914830 10644 solver.cpp:228] Iteration 25420, loss = 0.193547
I0529 10:19:16.914862 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:19:16.914870 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494252 (* 1 = 0.0494252 loss)
I0529 10:19:16.914875 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0735565 (* 1 = 0.0735565 loss)
I0529 10:19:16.914878 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403328 (* 1 = 0.00403328 loss)
I0529 10:19:16.914881 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00816204 (* 1 = 0.00816204 loss)
I0529 10:19:16.914886 10644 sgd_solver.cpp:106] Iteration 25420, lr = 0.0002
I0529 10:20:05.417482 10644 solver.cpp:228] Iteration 25440, loss = 0.361483
I0529 10:20:05.417508 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:20:05.417518 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00188439 (* 1 = 0.00188439 loss)
I0529 10:20:05.417526 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0613823 (* 1 = 0.0613823 loss)
I0529 10:20:05.417531 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198883 (* 1 = 0.0198883 loss)
I0529 10:20:05.417537 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176783 (* 1 = 0.0176783 loss)
I0529 10:20:05.417544 10644 sgd_solver.cpp:106] Iteration 25440, lr = 0.0002
I0529 10:20:53.938931 10644 solver.cpp:228] Iteration 25460, loss = 0.371417
I0529 10:20:53.938958 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:20:53.938966 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472774 (* 1 = 0.0472774 loss)
I0529 10:20:53.938971 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0900572 (* 1 = 0.0900572 loss)
I0529 10:20:53.938976 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00400038 (* 1 = 0.00400038 loss)
I0529 10:20:53.938979 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011962 (* 1 = 0.011962 loss)
I0529 10:20:53.938984 10644 sgd_solver.cpp:106] Iteration 25460, lr = 0.0002
I0529 10:21:42.496623 10644 solver.cpp:228] Iteration 25480, loss = 0.200175
I0529 10:21:42.496664 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:21:42.496675 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308671 (* 1 = 0.0308671 loss)
I0529 10:21:42.496681 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0786827 (* 1 = 0.0786827 loss)
I0529 10:21:42.496687 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112739 (* 1 = 0.0112739 loss)
I0529 10:21:42.496692 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141439 (* 1 = 0.0141439 loss)
I0529 10:21:42.496701 10644 sgd_solver.cpp:106] Iteration 25480, lr = 0.0002
I0529 10:22:31.038694 10644 solver.cpp:228] Iteration 25500, loss = 0.189506
I0529 10:22:31.038722 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 10:22:31.038731 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312788 (* 1 = 0.0312788 loss)
I0529 10:22:31.038738 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.086774 (* 1 = 0.086774 loss)
I0529 10:22:31.038744 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00279874 (* 1 = 0.00279874 loss)
I0529 10:22:31.038750 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00565536 (* 1 = 0.00565536 loss)
I0529 10:22:31.038758 10644 sgd_solver.cpp:106] Iteration 25500, lr = 0.0002
I0529 10:23:19.606317 10644 solver.cpp:228] Iteration 25520, loss = 0.312797
I0529 10:23:19.606341 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:23:19.606348 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566887 (* 1 = 0.0566887 loss)
I0529 10:23:19.606353 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0603005 (* 1 = 0.0603005 loss)
I0529 10:23:19.606356 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00393711 (* 1 = 0.00393711 loss)
I0529 10:23:19.606359 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111527 (* 1 = 0.0111527 loss)
I0529 10:23:19.606364 10644 sgd_solver.cpp:106] Iteration 25520, lr = 0.0002
I0529 10:24:08.167001 10644 solver.cpp:228] Iteration 25540, loss = 0.29847
I0529 10:24:08.167027 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:24:08.167034 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000966097 (* 1 = 0.000966097 loss)
I0529 10:24:08.167038 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.043639 (* 1 = 0.043639 loss)
I0529 10:24:08.167042 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182399 (* 1 = 0.0182399 loss)
I0529 10:24:08.167045 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106098 (* 1 = 0.0106098 loss)
I0529 10:24:08.167050 10644 sgd_solver.cpp:106] Iteration 25540, lr = 0.0002
I0529 10:24:56.720381 10644 solver.cpp:228] Iteration 25560, loss = 0.191521
I0529 10:24:56.720407 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:24:56.720413 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265905 (* 1 = 0.0265905 loss)
I0529 10:24:56.720417 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.028275 (* 1 = 0.028275 loss)
I0529 10:24:56.720422 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354536 (* 1 = 0.00354536 loss)
I0529 10:24:56.720424 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145321 (* 1 = 0.0145321 loss)
I0529 10:24:56.720429 10644 sgd_solver.cpp:106] Iteration 25560, lr = 0.0002
I0529 10:25:45.263808 10644 solver.cpp:228] Iteration 25580, loss = 0.288487
I0529 10:25:45.263831 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:25:45.263839 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.035523 (* 1 = 0.035523 loss)
I0529 10:25:45.263842 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0609725 (* 1 = 0.0609725 loss)
I0529 10:25:45.263846 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112587 (* 1 = 0.0112587 loss)
I0529 10:25:45.263849 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01403 (* 1 = 0.01403 loss)
I0529 10:25:45.263855 10644 sgd_solver.cpp:106] Iteration 25580, lr = 0.0002
speed: 2.429s / iter
I0529 10:26:33.834179 10644 solver.cpp:228] Iteration 25600, loss = 0.281584
I0529 10:26:33.834203 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:26:33.834208 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0564657 (* 1 = 0.0564657 loss)
I0529 10:26:33.834213 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0677455 (* 1 = 0.0677455 loss)
I0529 10:26:33.834216 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154025 (* 1 = 0.00154025 loss)
I0529 10:26:33.834219 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135653 (* 1 = 0.0135653 loss)
I0529 10:26:33.834224 10644 sgd_solver.cpp:106] Iteration 25600, lr = 0.0002
I0529 10:27:22.345427 10644 solver.cpp:228] Iteration 25620, loss = 0.435814
I0529 10:27:22.345454 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 10:27:22.345461 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114386 (* 1 = 0.114386 loss)
I0529 10:27:22.345465 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1443 (* 1 = 0.1443 loss)
I0529 10:27:22.345469 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155429 (* 1 = 0.0155429 loss)
I0529 10:27:22.345472 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306009 (* 1 = 0.0306009 loss)
I0529 10:27:22.345477 10644 sgd_solver.cpp:106] Iteration 25620, lr = 0.0002
I0529 10:28:10.925580 10644 solver.cpp:228] Iteration 25640, loss = 0.369012
I0529 10:28:10.925607 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 10:28:10.925614 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.131809 (* 1 = 0.131809 loss)
I0529 10:28:10.925618 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160369 (* 1 = 0.160369 loss)
I0529 10:28:10.925621 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00556372 (* 1 = 0.00556372 loss)
I0529 10:28:10.925626 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318941 (* 1 = 0.0318941 loss)
I0529 10:28:10.925629 10644 sgd_solver.cpp:106] Iteration 25640, lr = 0.0002
I0529 10:28:59.468760 10644 solver.cpp:228] Iteration 25660, loss = 0.33838
I0529 10:28:59.468786 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 10:28:59.468793 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537576 (* 1 = 0.0537576 loss)
I0529 10:28:59.468797 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0620594 (* 1 = 0.0620594 loss)
I0529 10:28:59.468801 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0489581 (* 1 = 0.0489581 loss)
I0529 10:28:59.468804 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.175321 (* 1 = 0.175321 loss)
I0529 10:28:59.468809 10644 sgd_solver.cpp:106] Iteration 25660, lr = 0.0002
I0529 10:29:47.999104 10644 solver.cpp:228] Iteration 25680, loss = 0.123846
I0529 10:29:47.999130 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 10:29:47.999140 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0330063 (* 1 = 0.0330063 loss)
I0529 10:29:47.999147 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0656748 (* 1 = 0.0656748 loss)
I0529 10:29:47.999153 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00578108 (* 1 = 0.00578108 loss)
I0529 10:29:47.999159 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010689 (* 1 = 0.010689 loss)
I0529 10:29:47.999166 10644 sgd_solver.cpp:106] Iteration 25680, lr = 0.0002
I0529 10:30:36.575481 10644 solver.cpp:228] Iteration 25700, loss = 0.231842
I0529 10:30:36.575508 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:30:36.575516 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369037 (* 1 = 0.0369037 loss)
I0529 10:30:36.575520 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0529092 (* 1 = 0.0529092 loss)
I0529 10:30:36.575525 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157098 (* 1 = 0.00157098 loss)
I0529 10:30:36.575528 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00509183 (* 1 = 0.00509183 loss)
I0529 10:30:36.575534 10644 sgd_solver.cpp:106] Iteration 25700, lr = 0.0002
I0529 10:31:25.143406 10644 solver.cpp:228] Iteration 25720, loss = 0.343534
I0529 10:31:25.143431 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0529 10:31:25.143440 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.174287 (* 1 = 0.174287 loss)
I0529 10:31:25.143443 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.4394 (* 1 = 0.4394 loss)
I0529 10:31:25.143447 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0390652 (* 1 = 0.0390652 loss)
I0529 10:31:25.143451 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0617072 (* 1 = 0.0617072 loss)
I0529 10:31:25.143456 10644 sgd_solver.cpp:106] Iteration 25720, lr = 0.0002
I0529 10:32:13.721845 10644 solver.cpp:228] Iteration 25740, loss = 0.302256
I0529 10:32:13.721875 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 10:32:13.721884 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.101692 (* 1 = 0.101692 loss)
I0529 10:32:13.721889 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.191156 (* 1 = 0.191156 loss)
I0529 10:32:13.721892 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186522 (* 1 = 0.0186522 loss)
I0529 10:32:13.721896 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258958 (* 1 = 0.0258958 loss)
I0529 10:32:13.721901 10644 sgd_solver.cpp:106] Iteration 25740, lr = 0.0002
I0529 10:33:02.354080 10644 solver.cpp:228] Iteration 25760, loss = 0.251396
I0529 10:33:02.354110 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:33:02.354120 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0755392 (* 1 = 0.0755392 loss)
I0529 10:33:02.354125 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.102814 (* 1 = 0.102814 loss)
I0529 10:33:02.354128 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012422 (* 1 = 0.012422 loss)
I0529 10:33:02.354133 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.155654 (* 1 = 0.155654 loss)
I0529 10:33:02.354140 10644 sgd_solver.cpp:106] Iteration 25760, lr = 0.0002
I0529 10:33:50.924744 10644 solver.cpp:228] Iteration 25780, loss = 0.169267
I0529 10:33:50.924768 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:33:50.924775 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264662 (* 1 = 0.0264662 loss)
I0529 10:33:50.924779 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0263752 (* 1 = 0.0263752 loss)
I0529 10:33:50.924783 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00129642 (* 1 = 0.00129642 loss)
I0529 10:33:50.924787 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00437136 (* 1 = 0.00437136 loss)
I0529 10:33:50.924791 10644 sgd_solver.cpp:106] Iteration 25780, lr = 0.0002
speed: 2.429s / iter
I0529 10:34:39.467228 10644 solver.cpp:228] Iteration 25800, loss = 0.214377
I0529 10:34:39.467249 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 10:34:39.467257 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.101121 (* 1 = 0.101121 loss)
I0529 10:34:39.467260 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255551 (* 1 = 0.255551 loss)
I0529 10:34:39.467264 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00860903 (* 1 = 0.00860903 loss)
I0529 10:34:39.467267 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00782712 (* 1 = 0.00782712 loss)
I0529 10:34:39.467272 10644 sgd_solver.cpp:106] Iteration 25800, lr = 0.0002
I0529 10:35:28.013731 10644 solver.cpp:228] Iteration 25820, loss = 0.272034
I0529 10:35:28.013761 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:35:28.013769 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000765112 (* 1 = 0.000765112 loss)
I0529 10:35:28.013773 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0190149 (* 1 = 0.0190149 loss)
I0529 10:35:28.013777 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250032 (* 1 = 0.00250032 loss)
I0529 10:35:28.013782 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154454 (* 1 = 0.0154454 loss)
I0529 10:35:28.013787 10644 sgd_solver.cpp:106] Iteration 25820, lr = 0.0002
I0529 10:36:16.585552 10644 solver.cpp:228] Iteration 25840, loss = 0.22596
I0529 10:36:16.585579 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:36:16.585587 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0131772 (* 1 = 0.0131772 loss)
I0529 10:36:16.585592 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.058513 (* 1 = 0.058513 loss)
I0529 10:36:16.585595 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00914073 (* 1 = 0.00914073 loss)
I0529 10:36:16.585598 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133933 (* 1 = 0.0133933 loss)
I0529 10:36:16.585604 10644 sgd_solver.cpp:106] Iteration 25840, lr = 0.0002
I0529 10:37:05.135668 10644 solver.cpp:228] Iteration 25860, loss = 0.431253
I0529 10:37:05.135695 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 10:37:05.135702 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.130479 (* 1 = 0.130479 loss)
I0529 10:37:05.135707 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.160262 (* 1 = 0.160262 loss)
I0529 10:37:05.135711 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00563725 (* 1 = 0.00563725 loss)
I0529 10:37:05.135715 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139908 (* 1 = 0.0139908 loss)
I0529 10:37:05.135720 10644 sgd_solver.cpp:106] Iteration 25860, lr = 0.0002
I0529 10:37:53.670363 10644 solver.cpp:228] Iteration 25880, loss = 0.284976
I0529 10:37:53.670388 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 10:37:53.670397 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0281773 (* 1 = 0.0281773 loss)
I0529 10:37:53.670400 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0828461 (* 1 = 0.0828461 loss)
I0529 10:37:53.670404 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692438 (* 1 = 0.00692438 loss)
I0529 10:37:53.670408 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00636962 (* 1 = 0.00636962 loss)
I0529 10:37:53.670414 10644 sgd_solver.cpp:106] Iteration 25880, lr = 0.0002
I0529 10:38:42.221593 10644 solver.cpp:228] Iteration 25900, loss = 0.157948
I0529 10:38:42.221618 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:38:42.221626 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135947 (* 1 = 0.0135947 loss)
I0529 10:38:42.221633 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0902431 (* 1 = 0.0902431 loss)
I0529 10:38:42.221639 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361902 (* 1 = 0.00361902 loss)
I0529 10:38:42.221644 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00869178 (* 1 = 0.00869178 loss)
I0529 10:38:42.221649 10644 sgd_solver.cpp:106] Iteration 25900, lr = 0.0002
I0529 10:39:30.814379 10644 solver.cpp:228] Iteration 25920, loss = 0.515965
I0529 10:39:30.814404 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.507812
I0529 10:39:30.814411 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.930029 (* 1 = 0.930029 loss)
I0529 10:39:30.814415 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.796385 (* 1 = 0.796385 loss)
I0529 10:39:30.814419 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.136374 (* 1 = 0.136374 loss)
I0529 10:39:30.814424 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.630254 (* 1 = 0.630254 loss)
I0529 10:39:30.814429 10644 sgd_solver.cpp:106] Iteration 25920, lr = 0.0002
I0529 10:40:19.365492 10644 solver.cpp:228] Iteration 25940, loss = 0.369302
I0529 10:40:19.365517 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 10:40:19.365526 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160171 (* 1 = 0.0160171 loss)
I0529 10:40:19.365530 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0999494 (* 1 = 0.0999494 loss)
I0529 10:40:19.365535 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00190603 (* 1 = 0.00190603 loss)
I0529 10:40:19.365538 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013179 (* 1 = 0.013179 loss)
I0529 10:40:19.365543 10644 sgd_solver.cpp:106] Iteration 25940, lr = 0.0002
I0529 10:41:07.903669 10644 solver.cpp:228] Iteration 25960, loss = 0.438431
I0529 10:41:07.903695 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:41:07.903703 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498367 (* 1 = 0.0498367 loss)
I0529 10:41:07.903708 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150451 (* 1 = 0.150451 loss)
I0529 10:41:07.903712 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00872201 (* 1 = 0.00872201 loss)
I0529 10:41:07.903715 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175862 (* 1 = 0.0175862 loss)
I0529 10:41:07.903722 10644 sgd_solver.cpp:106] Iteration 25960, lr = 0.0002
I0529 10:41:56.490262 10644 solver.cpp:228] Iteration 25980, loss = 0.243075
I0529 10:41:56.490286 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:41:56.490293 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268743 (* 1 = 0.0268743 loss)
I0529 10:41:56.490298 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0542157 (* 1 = 0.0542157 loss)
I0529 10:41:56.490300 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0098249 (* 1 = 0.0098249 loss)
I0529 10:41:56.490304 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00614946 (* 1 = 0.00614946 loss)
I0529 10:41:56.490309 10644 sgd_solver.cpp:106] Iteration 25980, lr = 0.0002
speed: 2.429s / iter
I0529 10:42:45.019420 10644 solver.cpp:228] Iteration 26000, loss = 0.376926
I0529 10:42:45.019446 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0529 10:42:45.019454 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.3185 (* 1 = 0.3185 loss)
I0529 10:42:45.019457 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.440817 (* 1 = 0.440817 loss)
I0529 10:42:45.019460 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0435644 (* 1 = 0.0435644 loss)
I0529 10:42:45.019464 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168395 (* 1 = 0.168395 loss)
I0529 10:42:45.019469 10644 sgd_solver.cpp:106] Iteration 26000, lr = 0.0002
I0529 10:43:33.596402 10644 solver.cpp:228] Iteration 26020, loss = 0.472393
I0529 10:43:33.596432 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 10:43:33.596439 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0527992 (* 1 = 0.0527992 loss)
I0529 10:43:33.596443 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152618 (* 1 = 0.152618 loss)
I0529 10:43:33.596446 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131954 (* 1 = 0.0131954 loss)
I0529 10:43:33.596451 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137833 (* 1 = 0.0137833 loss)
I0529 10:43:33.596455 10644 sgd_solver.cpp:106] Iteration 26020, lr = 0.0002
I0529 10:44:22.165910 10644 solver.cpp:228] Iteration 26040, loss = 0.357402
I0529 10:44:22.165936 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0529 10:44:22.165943 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.667827 (* 1 = 0.667827 loss)
I0529 10:44:22.165947 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.625763 (* 1 = 0.625763 loss)
I0529 10:44:22.165951 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0704944 (* 1 = 0.0704944 loss)
I0529 10:44:22.165953 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191387 (* 1 = 0.191387 loss)
I0529 10:44:22.165958 10644 sgd_solver.cpp:106] Iteration 26040, lr = 0.0002
I0529 10:45:10.711889 10644 solver.cpp:228] Iteration 26060, loss = 0.366898
I0529 10:45:10.711911 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 10:45:10.711918 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.270776 (* 1 = 0.270776 loss)
I0529 10:45:10.711922 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.321894 (* 1 = 0.321894 loss)
I0529 10:45:10.711925 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0377332 (* 1 = 0.0377332 loss)
I0529 10:45:10.711928 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221803 (* 1 = 0.0221803 loss)
I0529 10:45:10.711933 10644 sgd_solver.cpp:106] Iteration 26060, lr = 0.0002
I0529 10:45:59.271880 10644 solver.cpp:228] Iteration 26080, loss = 0.601469
I0529 10:45:59.271908 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 10:45:59.271915 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.260953 (* 1 = 0.260953 loss)
I0529 10:45:59.271919 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.297537 (* 1 = 0.297537 loss)
I0529 10:45:59.271924 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124773 (* 1 = 0.0124773 loss)
I0529 10:45:59.271926 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0667129 (* 1 = 0.0667129 loss)
I0529 10:45:59.271931 10644 sgd_solver.cpp:106] Iteration 26080, lr = 0.0002
I0529 10:46:47.780772 10644 solver.cpp:228] Iteration 26100, loss = 0.226918
I0529 10:46:47.780798 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:46:47.780807 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294473 (* 1 = 0.0294473 loss)
I0529 10:46:47.780809 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0378023 (* 1 = 0.0378023 loss)
I0529 10:46:47.780813 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0216806 (* 1 = 0.0216806 loss)
I0529 10:46:47.780817 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00826881 (* 1 = 0.00826881 loss)
I0529 10:46:47.780822 10644 sgd_solver.cpp:106] Iteration 26100, lr = 0.0002
I0529 10:47:36.305565 10644 solver.cpp:228] Iteration 26120, loss = 0.446945
I0529 10:47:36.305591 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:47:36.305599 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0130631 (* 1 = 0.0130631 loss)
I0529 10:47:36.305603 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0508214 (* 1 = 0.0508214 loss)
I0529 10:47:36.305608 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00225061 (* 1 = 0.00225061 loss)
I0529 10:47:36.305611 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00379759 (* 1 = 0.00379759 loss)
I0529 10:47:36.305618 10644 sgd_solver.cpp:106] Iteration 26120, lr = 0.0002
I0529 10:48:24.842726 10644 solver.cpp:228] Iteration 26140, loss = 0.204609
I0529 10:48:24.842751 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:48:24.842757 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168758 (* 1 = 0.0168758 loss)
I0529 10:48:24.842761 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0707382 (* 1 = 0.0707382 loss)
I0529 10:48:24.842766 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412694 (* 1 = 0.00412694 loss)
I0529 10:48:24.842768 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00219153 (* 1 = 0.00219153 loss)
I0529 10:48:24.842774 10644 sgd_solver.cpp:106] Iteration 26140, lr = 0.0002
I0529 10:49:13.396571 10644 solver.cpp:228] Iteration 26160, loss = 0.160756
I0529 10:49:13.396600 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:49:13.396607 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407089 (* 1 = 0.0407089 loss)
I0529 10:49:13.396611 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0823157 (* 1 = 0.0823157 loss)
I0529 10:49:13.396615 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292616 (* 1 = 0.00292616 loss)
I0529 10:49:13.396618 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0397717 (* 1 = 0.0397717 loss)
I0529 10:49:13.396625 10644 sgd_solver.cpp:106] Iteration 26160, lr = 0.0002
I0529 10:50:01.952612 10644 solver.cpp:228] Iteration 26180, loss = 0.271183
I0529 10:50:01.952638 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 10:50:01.952646 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.110957 (* 1 = 0.110957 loss)
I0529 10:50:01.952648 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0671202 (* 1 = 0.0671202 loss)
I0529 10:50:01.952652 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103213 (* 1 = 0.00103213 loss)
I0529 10:50:01.952656 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00701852 (* 1 = 0.00701852 loss)
I0529 10:50:01.952661 10644 sgd_solver.cpp:106] Iteration 26180, lr = 0.0002
speed: 2.429s / iter
I0529 10:50:50.496515 10644 solver.cpp:228] Iteration 26200, loss = 0.263878
I0529 10:50:50.496539 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 10:50:50.496546 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0726385 (* 1 = 0.0726385 loss)
I0529 10:50:50.496551 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.104798 (* 1 = 0.104798 loss)
I0529 10:50:50.496554 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134651 (* 1 = 0.00134651 loss)
I0529 10:50:50.496557 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110353 (* 1 = 0.0110353 loss)
I0529 10:50:50.496562 10644 sgd_solver.cpp:106] Iteration 26200, lr = 0.0002
I0529 10:51:39.061753 10644 solver.cpp:228] Iteration 26220, loss = 0.135992
I0529 10:51:39.061779 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 10:51:39.061789 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309234 (* 1 = 0.0309234 loss)
I0529 10:51:39.061794 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0573485 (* 1 = 0.0573485 loss)
I0529 10:51:39.061800 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241253 (* 1 = 0.00241253 loss)
I0529 10:51:39.061805 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016959 (* 1 = 0.016959 loss)
I0529 10:51:39.061811 10644 sgd_solver.cpp:106] Iteration 26220, lr = 0.0002
I0529 10:52:27.614835 10644 solver.cpp:228] Iteration 26240, loss = 0.159582
I0529 10:52:27.614863 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 10:52:27.614872 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448814 (* 1 = 0.0448814 loss)
I0529 10:52:27.614878 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.126485 (* 1 = 0.126485 loss)
I0529 10:52:27.614884 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122959 (* 1 = 0.0122959 loss)
I0529 10:52:27.614889 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107987 (* 1 = 0.0107987 loss)
I0529 10:52:27.614897 10644 sgd_solver.cpp:106] Iteration 26240, lr = 0.0002
I0529 10:53:16.166929 10644 solver.cpp:228] Iteration 26260, loss = 0.203807
I0529 10:53:16.166955 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:53:16.166965 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0982425 (* 1 = 0.0982425 loss)
I0529 10:53:16.166971 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1598 (* 1 = 0.1598 loss)
I0529 10:53:16.166976 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0297106 (* 1 = 0.0297106 loss)
I0529 10:53:16.166981 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155224 (* 1 = 0.0155224 loss)
I0529 10:53:16.166988 10644 sgd_solver.cpp:106] Iteration 26260, lr = 0.0002
I0529 10:54:04.715626 10644 solver.cpp:228] Iteration 26280, loss = 0.554346
I0529 10:54:04.715651 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0529 10:54:04.715658 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.684694 (* 1 = 0.684694 loss)
I0529 10:54:04.715662 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.763587 (* 1 = 0.763587 loss)
I0529 10:54:04.715665 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0308839 (* 1 = 0.0308839 loss)
I0529 10:54:04.715668 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.293969 (* 1 = 0.293969 loss)
I0529 10:54:04.715673 10644 sgd_solver.cpp:106] Iteration 26280, lr = 0.0002
I0529 10:54:53.267129 10644 solver.cpp:228] Iteration 26300, loss = 0.181025
I0529 10:54:53.267169 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 10:54:53.267177 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0730684 (* 1 = 0.0730684 loss)
I0529 10:54:53.267182 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0839665 (* 1 = 0.0839665 loss)
I0529 10:54:53.267186 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00592154 (* 1 = 0.00592154 loss)
I0529 10:54:53.267190 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00551222 (* 1 = 0.00551222 loss)
I0529 10:54:53.267196 10644 sgd_solver.cpp:106] Iteration 26300, lr = 0.0002
I0529 10:55:41.847096 10644 solver.cpp:228] Iteration 26320, loss = 0.55899
I0529 10:55:41.847126 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 10:55:41.847136 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0875563 (* 1 = 0.0875563 loss)
I0529 10:55:41.847143 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151015 (* 1 = 0.151015 loss)
I0529 10:55:41.847151 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00890663 (* 1 = 0.00890663 loss)
I0529 10:55:41.847156 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195015 (* 1 = 0.0195015 loss)
I0529 10:55:41.847163 10644 sgd_solver.cpp:106] Iteration 26320, lr = 0.0002
I0529 10:56:30.404963 10644 solver.cpp:228] Iteration 26340, loss = 0.216502
I0529 10:56:30.405036 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 10:56:30.405061 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0834027 (* 1 = 0.0834027 loss)
I0529 10:56:30.405076 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0850146 (* 1 = 0.0850146 loss)
I0529 10:56:30.405091 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424051 (* 1 = 0.00424051 loss)
I0529 10:56:30.405105 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0046375 (* 1 = 0.0046375 loss)
I0529 10:56:30.405122 10644 sgd_solver.cpp:106] Iteration 26340, lr = 0.0002
I0529 10:57:18.931262 10644 solver.cpp:228] Iteration 26360, loss = 0.206718
I0529 10:57:18.931293 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 10:57:18.931300 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498728 (* 1 = 0.0498728 loss)
I0529 10:57:18.931304 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.174677 (* 1 = 0.174677 loss)
I0529 10:57:18.931308 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100134 (* 1 = 0.0100134 loss)
I0529 10:57:18.931311 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127908 (* 1 = 0.0127908 loss)
I0529 10:57:18.931318 10644 sgd_solver.cpp:106] Iteration 26360, lr = 0.0002
I0529 10:58:07.510099 10644 solver.cpp:228] Iteration 26380, loss = 0.350807
I0529 10:58:07.510123 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0529 10:58:07.510131 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.391156 (* 1 = 0.391156 loss)
I0529 10:58:07.510136 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.430326 (* 1 = 0.430326 loss)
I0529 10:58:07.510140 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00572403 (* 1 = 0.00572403 loss)
I0529 10:58:07.510143 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514305 (* 1 = 0.0514305 loss)
I0529 10:58:07.510149 10644 sgd_solver.cpp:106] Iteration 26380, lr = 0.0002
speed: 2.429s / iter
I0529 10:58:56.058358 10644 solver.cpp:228] Iteration 26400, loss = 0.177634
I0529 10:58:56.058390 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 10:58:56.058398 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00114206 (* 1 = 0.00114206 loss)
I0529 10:58:56.058403 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0368696 (* 1 = 0.0368696 loss)
I0529 10:58:56.058408 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188651 (* 1 = 0.0188651 loss)
I0529 10:58:56.058410 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156571 (* 1 = 0.0156571 loss)
I0529 10:58:56.058416 10644 sgd_solver.cpp:106] Iteration 26400, lr = 0.0002
I0529 10:59:44.617961 10644 solver.cpp:228] Iteration 26420, loss = 0.319414
I0529 10:59:44.617990 10644 solver.cpp:244]     Train net output #0: accuarcy = 1
I0529 10:59:44.618000 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0428161 (* 1 = 0.0428161 loss)
I0529 10:59:44.618006 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.026696 (* 1 = 0.026696 loss)
I0529 10:59:44.618013 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445742 (* 1 = 0.00445742 loss)
I0529 10:59:44.618019 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102497 (* 1 = 0.0102497 loss)
I0529 10:59:44.618027 10644 sgd_solver.cpp:106] Iteration 26420, lr = 0.0002
I0529 11:00:33.174121 10644 solver.cpp:228] Iteration 26440, loss = 0.185951
I0529 11:00:33.174149 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:00:33.174157 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445069 (* 1 = 0.0445069 loss)
I0529 11:00:33.174161 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.070953 (* 1 = 0.070953 loss)
I0529 11:00:33.174165 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00277023 (* 1 = 0.00277023 loss)
I0529 11:00:33.174170 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00927726 (* 1 = 0.00927726 loss)
I0529 11:00:33.174175 10644 sgd_solver.cpp:106] Iteration 26440, lr = 0.0002
I0529 11:01:21.722227 10644 solver.cpp:228] Iteration 26460, loss = 0.498687
I0529 11:01:21.722265 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 11:01:21.722272 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.258076 (* 1 = 0.258076 loss)
I0529 11:01:21.722276 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.407337 (* 1 = 0.407337 loss)
I0529 11:01:21.722280 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0222537 (* 1 = 0.0222537 loss)
I0529 11:01:21.722283 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149158 (* 1 = 0.149158 loss)
I0529 11:01:21.722290 10644 sgd_solver.cpp:106] Iteration 26460, lr = 0.0002
I0529 11:02:10.267305 10644 solver.cpp:228] Iteration 26480, loss = 0.168159
I0529 11:02:10.267330 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 11:02:10.267338 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299566 (* 1 = 0.0299566 loss)
I0529 11:02:10.267341 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0444468 (* 1 = 0.0444468 loss)
I0529 11:02:10.267345 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145689 (* 1 = 0.0145689 loss)
I0529 11:02:10.267349 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00256932 (* 1 = 0.00256932 loss)
I0529 11:02:10.267354 10644 sgd_solver.cpp:106] Iteration 26480, lr = 0.0002
I0529 11:02:58.782554 10644 solver.cpp:228] Iteration 26500, loss = 0.235498
I0529 11:02:58.782584 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:02:58.782591 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199498 (* 1 = 0.0199498 loss)
I0529 11:02:58.782595 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0590824 (* 1 = 0.0590824 loss)
I0529 11:02:58.782598 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249277 (* 1 = 0.00249277 loss)
I0529 11:02:58.782603 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00769906 (* 1 = 0.00769906 loss)
I0529 11:02:58.782608 10644 sgd_solver.cpp:106] Iteration 26500, lr = 0.0002
I0529 11:03:47.321671 10644 solver.cpp:228] Iteration 26520, loss = 0.213399
I0529 11:03:47.321698 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 11:03:47.321707 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.157837 (* 1 = 0.157837 loss)
I0529 11:03:47.321710 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.236441 (* 1 = 0.236441 loss)
I0529 11:03:47.321713 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109466 (* 1 = 0.0109466 loss)
I0529 11:03:47.321717 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0355807 (* 1 = 0.0355807 loss)
I0529 11:03:47.321722 10644 sgd_solver.cpp:106] Iteration 26520, lr = 0.0002
I0529 11:04:35.891604 10644 solver.cpp:228] Iteration 26540, loss = 0.266726
I0529 11:04:35.891630 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:04:35.891639 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0411544 (* 1 = 0.0411544 loss)
I0529 11:04:35.891645 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0750717 (* 1 = 0.0750717 loss)
I0529 11:04:35.891651 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139382 (* 1 = 0.0139382 loss)
I0529 11:04:35.891656 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015161 (* 1 = 0.015161 loss)
I0529 11:04:35.891664 10644 sgd_solver.cpp:106] Iteration 26540, lr = 0.0002
I0529 11:05:24.465236 10644 solver.cpp:228] Iteration 26560, loss = 0.296437
I0529 11:05:24.465263 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 11:05:24.465272 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.188208 (* 1 = 0.188208 loss)
I0529 11:05:24.465278 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.319223 (* 1 = 0.319223 loss)
I0529 11:05:24.465283 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271595 (* 1 = 0.0271595 loss)
I0529 11:05:24.465288 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242831 (* 1 = 0.0242831 loss)
I0529 11:05:24.465296 10644 sgd_solver.cpp:106] Iteration 26560, lr = 0.0002
I0529 11:06:13.044056 10644 solver.cpp:228] Iteration 26580, loss = 0.42192
I0529 11:06:13.044080 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 11:06:13.044090 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118338 (* 1 = 0.118338 loss)
I0529 11:06:13.044095 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.225123 (* 1 = 0.225123 loss)
I0529 11:06:13.044100 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155763 (* 1 = 0.0155763 loss)
I0529 11:06:13.044106 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244276 (* 1 = 0.0244276 loss)
I0529 11:06:13.044112 10644 sgd_solver.cpp:106] Iteration 26580, lr = 0.0002
speed: 2.429s / iter
I0529 11:07:01.615022 10644 solver.cpp:228] Iteration 26600, loss = 0.259721
I0529 11:07:01.615049 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 11:07:01.615057 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.147756 (* 1 = 0.147756 loss)
I0529 11:07:01.615061 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.241527 (* 1 = 0.241527 loss)
I0529 11:07:01.615064 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00434674 (* 1 = 0.00434674 loss)
I0529 11:07:01.615067 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0365491 (* 1 = 0.0365491 loss)
I0529 11:07:01.615072 10644 sgd_solver.cpp:106] Iteration 26600, lr = 0.0002
I0529 11:07:50.178036 10644 solver.cpp:228] Iteration 26620, loss = 0.214053
I0529 11:07:50.178063 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 11:07:50.178071 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175746 (* 1 = 0.0175746 loss)
I0529 11:07:50.178076 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0951985 (* 1 = 0.0951985 loss)
I0529 11:07:50.178079 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014036 (* 1 = 0.014036 loss)
I0529 11:07:50.178083 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00911378 (* 1 = 0.00911378 loss)
I0529 11:07:50.178088 10644 sgd_solver.cpp:106] Iteration 26620, lr = 0.0002
I0529 11:08:38.740823 10644 solver.cpp:228] Iteration 26640, loss = 0.210379
I0529 11:08:38.740851 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 11:08:38.740859 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0348501 (* 1 = 0.0348501 loss)
I0529 11:08:38.740865 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0388971 (* 1 = 0.0388971 loss)
I0529 11:08:38.740872 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00552434 (* 1 = 0.00552434 loss)
I0529 11:08:38.740877 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00697212 (* 1 = 0.00697212 loss)
I0529 11:08:38.740883 10644 sgd_solver.cpp:106] Iteration 26640, lr = 0.0002
I0529 11:09:27.285001 10644 solver.cpp:228] Iteration 26660, loss = 0.180394
I0529 11:09:27.285027 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 11:09:27.285035 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675437 (* 1 = 0.0675437 loss)
I0529 11:09:27.285039 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255485 (* 1 = 0.255485 loss)
I0529 11:09:27.285043 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291833 (* 1 = 0.00291833 loss)
I0529 11:09:27.285048 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00589467 (* 1 = 0.00589467 loss)
I0529 11:09:27.285053 10644 sgd_solver.cpp:106] Iteration 26660, lr = 0.0002
I0529 11:10:15.831168 10644 solver.cpp:228] Iteration 26680, loss = 0.369618
I0529 11:10:15.831194 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:10:15.831204 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.106415 (* 1 = 0.106415 loss)
I0529 11:10:15.831210 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.123131 (* 1 = 0.123131 loss)
I0529 11:10:15.831216 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00344575 (* 1 = 0.00344575 loss)
I0529 11:10:15.831223 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123628 (* 1 = 0.0123628 loss)
I0529 11:10:15.831230 10644 sgd_solver.cpp:106] Iteration 26680, lr = 0.0002
I0529 11:11:04.391603 10644 solver.cpp:228] Iteration 26700, loss = 0.226396
I0529 11:11:04.391633 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:11:04.391639 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326346 (* 1 = 0.0326346 loss)
I0529 11:11:04.391644 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0745187 (* 1 = 0.0745187 loss)
I0529 11:11:04.391649 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00505879 (* 1 = 0.00505879 loss)
I0529 11:11:04.391652 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00270156 (* 1 = 0.00270156 loss)
I0529 11:11:04.391657 10644 sgd_solver.cpp:106] Iteration 26700, lr = 0.0002
I0529 11:11:52.982030 10644 solver.cpp:228] Iteration 26720, loss = 0.224484
I0529 11:11:52.982056 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 11:11:52.982064 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0658606 (* 1 = 0.0658606 loss)
I0529 11:11:52.982069 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0725785 (* 1 = 0.0725785 loss)
I0529 11:11:52.982072 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00559831 (* 1 = 0.00559831 loss)
I0529 11:11:52.982076 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00665639 (* 1 = 0.00665639 loss)
I0529 11:11:52.982082 10644 sgd_solver.cpp:106] Iteration 26720, lr = 0.0002
I0529 11:12:41.572890 10644 solver.cpp:228] Iteration 26740, loss = 0.298681
I0529 11:12:41.572919 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 11:12:41.572927 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0514775 (* 1 = 0.0514775 loss)
I0529 11:12:41.572932 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101863 (* 1 = 0.101863 loss)
I0529 11:12:41.572935 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281829 (* 1 = 0.00281829 loss)
I0529 11:12:41.572940 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00321459 (* 1 = 0.00321459 loss)
I0529 11:12:41.572945 10644 sgd_solver.cpp:106] Iteration 26740, lr = 0.0002
I0529 11:13:30.174010 10644 solver.cpp:228] Iteration 26760, loss = 0.223907
I0529 11:13:30.174037 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 11:13:30.174046 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0580898 (* 1 = 0.0580898 loss)
I0529 11:13:30.174049 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.124758 (* 1 = 0.124758 loss)
I0529 11:13:30.174052 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00378722 (* 1 = 0.00378722 loss)
I0529 11:13:30.174057 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192873 (* 1 = 0.0192873 loss)
I0529 11:13:30.174062 10644 sgd_solver.cpp:106] Iteration 26760, lr = 0.0002
I0529 11:14:18.724527 10644 solver.cpp:228] Iteration 26780, loss = 0.263623
I0529 11:14:18.724552 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 11:14:18.724560 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0683615 (* 1 = 0.0683615 loss)
I0529 11:14:18.724563 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0782306 (* 1 = 0.0782306 loss)
I0529 11:14:18.724567 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00357498 (* 1 = 0.00357498 loss)
I0529 11:14:18.724570 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02127 (* 1 = 0.02127 loss)
I0529 11:14:18.724575 10644 sgd_solver.cpp:106] Iteration 26780, lr = 0.0002
speed: 2.429s / iter
I0529 11:15:07.307430 10644 solver.cpp:228] Iteration 26800, loss = 0.395169
I0529 11:15:07.307457 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 11:15:07.307467 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.23562 (* 1 = 0.23562 loss)
I0529 11:15:07.307473 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.467226 (* 1 = 0.467226 loss)
I0529 11:15:07.307478 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157305 (* 1 = 0.0157305 loss)
I0529 11:15:07.307483 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0424658 (* 1 = 0.0424658 loss)
I0529 11:15:07.307492 10644 sgd_solver.cpp:106] Iteration 26800, lr = 0.0002
I0529 11:15:55.837792 10644 solver.cpp:228] Iteration 26820, loss = 0.402034
I0529 11:15:55.837818 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:15:55.837826 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.032159 (* 1 = 0.032159 loss)
I0529 11:15:55.837829 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115043 (* 1 = 0.115043 loss)
I0529 11:15:55.837832 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024574 (* 1 = 0.024574 loss)
I0529 11:15:55.837836 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154414 (* 1 = 0.0154414 loss)
I0529 11:15:55.837841 10644 sgd_solver.cpp:106] Iteration 26820, lr = 0.0002
I0529 11:16:44.388535 10644 solver.cpp:228] Iteration 26840, loss = 0.411884
I0529 11:16:44.388559 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 11:16:44.388566 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0898216 (* 1 = 0.0898216 loss)
I0529 11:16:44.388571 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114768 (* 1 = 0.114768 loss)
I0529 11:16:44.388573 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00601324 (* 1 = 0.00601324 loss)
I0529 11:16:44.388577 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0502999 (* 1 = 0.0502999 loss)
I0529 11:16:44.388582 10644 sgd_solver.cpp:106] Iteration 26840, lr = 0.0002
I0529 11:17:33.079746 10644 solver.cpp:228] Iteration 26860, loss = 0.319709
I0529 11:17:33.079771 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 11:17:33.079778 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.150478 (* 1 = 0.150478 loss)
I0529 11:17:33.079782 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.325982 (* 1 = 0.325982 loss)
I0529 11:17:33.079787 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156546 (* 1 = 0.0156546 loss)
I0529 11:17:33.079790 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045194 (* 1 = 0.045194 loss)
I0529 11:17:33.079795 10644 sgd_solver.cpp:106] Iteration 26860, lr = 0.0002
I0529 11:18:21.610419 10644 solver.cpp:228] Iteration 26880, loss = 0.274327
I0529 11:18:21.610443 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:18:21.610452 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00421106 (* 1 = 0.00421106 loss)
I0529 11:18:21.610456 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110603 (* 1 = 0.110603 loss)
I0529 11:18:21.610460 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177688 (* 1 = 0.0177688 loss)
I0529 11:18:21.610463 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224627 (* 1 = 0.0224627 loss)
I0529 11:18:21.610469 10644 sgd_solver.cpp:106] Iteration 26880, lr = 0.0002
I0529 11:19:10.328186 10644 solver.cpp:228] Iteration 26900, loss = 0.251934
I0529 11:19:10.328217 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 11:19:10.328227 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.205705 (* 1 = 0.205705 loss)
I0529 11:19:10.328233 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.366764 (* 1 = 0.366764 loss)
I0529 11:19:10.328238 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0335381 (* 1 = 0.0335381 loss)
I0529 11:19:10.328243 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0646409 (* 1 = 0.0646409 loss)
I0529 11:19:10.328249 10644 sgd_solver.cpp:106] Iteration 26900, lr = 0.0002
I0529 11:19:58.882905 10644 solver.cpp:228] Iteration 26920, loss = 0.253901
I0529 11:19:58.882930 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:19:58.882941 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587931 (* 1 = 0.0587931 loss)
I0529 11:19:58.882946 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10067 (* 1 = 0.10067 loss)
I0529 11:19:58.882951 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0078947 (* 1 = 0.0078947 loss)
I0529 11:19:58.882957 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229027 (* 1 = 0.00229027 loss)
I0529 11:19:58.882964 10644 sgd_solver.cpp:106] Iteration 26920, lr = 0.0002
I0529 11:20:47.410272 10644 solver.cpp:228] Iteration 26940, loss = 0.177999
I0529 11:20:47.410298 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:20:47.410307 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0692137 (* 1 = 0.0692137 loss)
I0529 11:20:47.410313 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.127707 (* 1 = 0.127707 loss)
I0529 11:20:47.410318 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.025712 (* 1 = 0.025712 loss)
I0529 11:20:47.410323 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120928 (* 1 = 0.0120928 loss)
I0529 11:20:47.410329 10644 sgd_solver.cpp:106] Iteration 26940, lr = 0.0002
I0529 11:21:35.932997 10644 solver.cpp:228] Iteration 26960, loss = 0.314149
I0529 11:21:35.933024 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 11:21:35.933034 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.176309 (* 1 = 0.176309 loss)
I0529 11:21:35.933040 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.304568 (* 1 = 0.304568 loss)
I0529 11:21:35.933046 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186637 (* 1 = 0.00186637 loss)
I0529 11:21:35.933051 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338833 (* 1 = 0.0338833 loss)
I0529 11:21:35.933058 10644 sgd_solver.cpp:106] Iteration 26960, lr = 0.0002
I0529 11:22:24.462921 10644 solver.cpp:228] Iteration 26980, loss = 0.246345
I0529 11:22:24.462946 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 11:22:24.462956 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000708383 (* 1 = 0.000708383 loss)
I0529 11:22:24.462962 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0187906 (* 1 = 0.0187906 loss)
I0529 11:22:24.462967 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132904 (* 1 = 0.0132904 loss)
I0529 11:22:24.462972 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0426577 (* 1 = 0.0426577 loss)
I0529 11:22:24.462980 10644 sgd_solver.cpp:106] Iteration 26980, lr = 0.0002
speed: 2.429s / iter
I0529 11:23:13.021126 10644 solver.cpp:228] Iteration 27000, loss = 0.343221
I0529 11:23:13.021155 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:23:13.021163 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839493 (* 1 = 0.0839493 loss)
I0529 11:23:13.021167 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.101195 (* 1 = 0.101195 loss)
I0529 11:23:13.021170 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00468669 (* 1 = 0.00468669 loss)
I0529 11:23:13.021175 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225169 (* 1 = 0.0225169 loss)
I0529 11:23:13.021181 10644 sgd_solver.cpp:106] Iteration 27000, lr = 0.0002
I0529 11:24:01.584482 10644 solver.cpp:228] Iteration 27020, loss = 0.310962
I0529 11:24:01.584506 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 11:24:01.584514 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114252 (* 1 = 0.114252 loss)
I0529 11:24:01.584520 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.380937 (* 1 = 0.380937 loss)
I0529 11:24:01.584525 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00960254 (* 1 = 0.00960254 loss)
I0529 11:24:01.584532 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452608 (* 1 = 0.0452608 loss)
I0529 11:24:01.584537 10644 sgd_solver.cpp:106] Iteration 27020, lr = 0.0002
I0529 11:24:50.079012 10644 solver.cpp:228] Iteration 27040, loss = 0.175201
I0529 11:24:50.079033 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:24:50.079039 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183383 (* 1 = 0.0183383 loss)
I0529 11:24:50.079043 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.107717 (* 1 = 0.107717 loss)
I0529 11:24:50.079047 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179655 (* 1 = 0.0179655 loss)
I0529 11:24:50.079051 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182354 (* 1 = 0.0182354 loss)
I0529 11:24:50.079056 10644 sgd_solver.cpp:106] Iteration 27040, lr = 0.0002
I0529 11:25:38.539216 10644 solver.cpp:228] Iteration 27060, loss = 0.281535
I0529 11:25:38.539239 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:25:38.539247 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.061528 (* 1 = 0.061528 loss)
I0529 11:25:38.539252 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0686198 (* 1 = 0.0686198 loss)
I0529 11:25:38.539254 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105797 (* 1 = 0.00105797 loss)
I0529 11:25:38.539258 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942898 (* 1 = 0.00942898 loss)
I0529 11:25:38.539263 10644 sgd_solver.cpp:106] Iteration 27060, lr = 0.0002
I0529 11:26:27.051254 10644 solver.cpp:228] Iteration 27080, loss = 0.228214
I0529 11:26:27.051280 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 11:26:27.051287 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0814275 (* 1 = 0.0814275 loss)
I0529 11:26:27.051291 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.128776 (* 1 = 0.128776 loss)
I0529 11:26:27.051295 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155776 (* 1 = 0.0155776 loss)
I0529 11:26:27.051298 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255884 (* 1 = 0.0255884 loss)
I0529 11:26:27.051304 10644 sgd_solver.cpp:106] Iteration 27080, lr = 0.0002
I0529 11:27:15.620833 10644 solver.cpp:228] Iteration 27100, loss = 0.189254
I0529 11:27:15.620860 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 11:27:15.620868 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.291072 (* 1 = 0.291072 loss)
I0529 11:27:15.620872 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.256677 (* 1 = 0.256677 loss)
I0529 11:27:15.620877 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00548667 (* 1 = 0.00548667 loss)
I0529 11:27:15.620880 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0349887 (* 1 = 0.0349887 loss)
I0529 11:27:15.620885 10644 sgd_solver.cpp:106] Iteration 27100, lr = 0.0002
I0529 11:28:04.179895 10644 solver.cpp:228] Iteration 27120, loss = 0.254382
I0529 11:28:04.179922 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 11:28:04.179932 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0838087 (* 1 = 0.0838087 loss)
I0529 11:28:04.179939 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.121542 (* 1 = 0.121542 loss)
I0529 11:28:04.179945 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000429007 (* 1 = 0.000429007 loss)
I0529 11:28:04.179951 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116728 (* 1 = 0.0116728 loss)
I0529 11:28:04.179960 10644 sgd_solver.cpp:106] Iteration 27120, lr = 0.0002
I0529 11:28:52.732806 10644 solver.cpp:228] Iteration 27140, loss = 0.213011
I0529 11:28:52.732836 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:28:52.732844 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0487902 (* 1 = 0.0487902 loss)
I0529 11:28:52.732851 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0557132 (* 1 = 0.0557132 loss)
I0529 11:28:52.732857 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338065 (* 1 = 0.00338065 loss)
I0529 11:28:52.732863 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00673106 (* 1 = 0.00673106 loss)
I0529 11:28:52.732870 10644 sgd_solver.cpp:106] Iteration 27140, lr = 0.0002
I0529 11:29:41.282359 10644 solver.cpp:228] Iteration 27160, loss = 0.537539
I0529 11:29:41.282395 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.414062
I0529 11:29:41.282404 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.707057 (* 1 = 0.707057 loss)
I0529 11:29:41.282409 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.98338 (* 1 = 0.98338 loss)
I0529 11:29:41.282413 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.11514 (* 1 = 0.11514 loss)
I0529 11:29:41.282416 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.588326 (* 1 = 0.588326 loss)
I0529 11:29:41.282423 10644 sgd_solver.cpp:106] Iteration 27160, lr = 0.0002
I0529 11:30:29.839969 10644 solver.cpp:228] Iteration 27180, loss = 0.21953
I0529 11:30:29.840000 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:30:29.840010 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0493923 (* 1 = 0.0493923 loss)
I0529 11:30:29.840018 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0966163 (* 1 = 0.0966163 loss)
I0529 11:30:29.840023 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111188 (* 1 = 0.0111188 loss)
I0529 11:30:29.840029 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174339 (* 1 = 0.0174339 loss)
I0529 11:30:29.840036 10644 sgd_solver.cpp:106] Iteration 27180, lr = 0.0002
speed: 2.429s / iter
I0529 11:31:18.396867 10644 solver.cpp:228] Iteration 27200, loss = 0.463917
I0529 11:31:18.396893 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 11:31:18.396903 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0648834 (* 1 = 0.0648834 loss)
I0529 11:31:18.396908 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.152135 (* 1 = 0.152135 loss)
I0529 11:31:18.396919 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00610539 (* 1 = 0.00610539 loss)
I0529 11:31:18.396926 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00964135 (* 1 = 0.00964135 loss)
I0529 11:31:18.396934 10644 sgd_solver.cpp:106] Iteration 27200, lr = 0.0002
I0529 11:32:06.951789 10644 solver.cpp:228] Iteration 27220, loss = 0.261636
I0529 11:32:06.951818 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:32:06.951828 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309711 (* 1 = 0.0309711 loss)
I0529 11:32:06.951835 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0906351 (* 1 = 0.0906351 loss)
I0529 11:32:06.951841 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131364 (* 1 = 0.0131364 loss)
I0529 11:32:06.951846 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105344 (* 1 = 0.0105344 loss)
I0529 11:32:06.951854 10644 sgd_solver.cpp:106] Iteration 27220, lr = 0.0002
I0529 11:32:55.521205 10644 solver.cpp:228] Iteration 27240, loss = 0.342224
I0529 11:32:55.521232 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0529 11:32:55.521240 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.409266 (* 1 = 0.409266 loss)
I0529 11:32:55.521244 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.594912 (* 1 = 0.594912 loss)
I0529 11:32:55.521247 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0259233 (* 1 = 0.0259233 loss)
I0529 11:32:55.521250 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0645538 (* 1 = 0.0645538 loss)
I0529 11:32:55.521255 10644 sgd_solver.cpp:106] Iteration 27240, lr = 0.0002
I0529 11:33:44.071627 10644 solver.cpp:228] Iteration 27260, loss = 0.220674
I0529 11:33:44.071653 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 11:33:44.071660 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434371 (* 1 = 0.0434371 loss)
I0529 11:33:44.071665 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0957128 (* 1 = 0.0957128 loss)
I0529 11:33:44.071667 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301813 (* 1 = 0.00301813 loss)
I0529 11:33:44.071671 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00673897 (* 1 = 0.00673897 loss)
I0529 11:33:44.071676 10644 sgd_solver.cpp:106] Iteration 27260, lr = 0.0002
I0529 11:34:32.573072 10644 solver.cpp:228] Iteration 27280, loss = 0.265663
I0529 11:34:32.573098 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 11:34:32.573105 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284172 (* 1 = 0.0284172 loss)
I0529 11:34:32.573108 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0651202 (* 1 = 0.0651202 loss)
I0529 11:34:32.573112 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00410241 (* 1 = 0.00410241 loss)
I0529 11:34:32.573115 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00983733 (* 1 = 0.00983733 loss)
I0529 11:34:32.573122 10644 sgd_solver.cpp:106] Iteration 27280, lr = 0.0002
I0529 11:35:21.104600 10644 solver.cpp:228] Iteration 27300, loss = 0.259889
I0529 11:35:21.104624 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:35:21.104631 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435959 (* 1 = 0.0435959 loss)
I0529 11:35:21.104635 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1267 (* 1 = 0.1267 loss)
I0529 11:35:21.104638 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213096 (* 1 = 0.0213096 loss)
I0529 11:35:21.104641 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250794 (* 1 = 0.0250794 loss)
I0529 11:35:21.104647 10644 sgd_solver.cpp:106] Iteration 27300, lr = 0.0002
I0529 11:36:09.663056 10644 solver.cpp:228] Iteration 27320, loss = 0.518207
I0529 11:36:09.663084 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 11:36:09.663092 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.126439 (* 1 = 0.126439 loss)
I0529 11:36:09.663095 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.266314 (* 1 = 0.266314 loss)
I0529 11:36:09.663100 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015379 (* 1 = 0.015379 loss)
I0529 11:36:09.663102 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295477 (* 1 = 0.0295477 loss)
I0529 11:36:09.663107 10644 sgd_solver.cpp:106] Iteration 27320, lr = 0.0002
I0529 11:36:58.228724 10644 solver.cpp:228] Iteration 27340, loss = 0.150151
I0529 11:36:58.228749 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:36:58.228758 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0451455 (* 1 = 0.0451455 loss)
I0529 11:36:58.228765 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0560057 (* 1 = 0.0560057 loss)
I0529 11:36:58.228770 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00246956 (* 1 = 0.00246956 loss)
I0529 11:36:58.228775 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0046708 (* 1 = 0.0046708 loss)
I0529 11:36:58.228780 10644 sgd_solver.cpp:106] Iteration 27340, lr = 0.0002
I0529 11:37:46.775846 10644 solver.cpp:228] Iteration 27360, loss = 0.269674
I0529 11:37:46.775871 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 11:37:46.775878 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.154242 (* 1 = 0.154242 loss)
I0529 11:37:46.775882 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.153657 (* 1 = 0.153657 loss)
I0529 11:37:46.775887 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00279254 (* 1 = 0.00279254 loss)
I0529 11:37:46.775889 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180923 (* 1 = 0.0180923 loss)
I0529 11:37:46.775894 10644 sgd_solver.cpp:106] Iteration 27360, lr = 0.0002
I0529 11:38:35.298697 10644 solver.cpp:228] Iteration 27380, loss = 0.167341
I0529 11:38:35.298722 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:38:35.298728 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.036686 (* 1 = 0.036686 loss)
I0529 11:38:35.298732 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0539044 (* 1 = 0.0539044 loss)
I0529 11:38:35.298737 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00551131 (* 1 = 0.00551131 loss)
I0529 11:38:35.298739 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174222 (* 1 = 0.0174222 loss)
I0529 11:38:35.298744 10644 sgd_solver.cpp:106] Iteration 27380, lr = 0.0002
speed: 2.429s / iter
I0529 11:39:23.867790 10644 solver.cpp:228] Iteration 27400, loss = 0.381399
I0529 11:39:23.867817 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:39:23.867826 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0796134 (* 1 = 0.0796134 loss)
I0529 11:39:23.867830 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0951256 (* 1 = 0.0951256 loss)
I0529 11:39:23.867835 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00561551 (* 1 = 0.00561551 loss)
I0529 11:39:23.867838 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140568 (* 1 = 0.0140568 loss)
I0529 11:39:23.867843 10644 sgd_solver.cpp:106] Iteration 27400, lr = 0.0002
I0529 11:40:12.374583 10644 solver.cpp:228] Iteration 27420, loss = 0.325297
I0529 11:40:12.374610 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:40:12.374619 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0366898 (* 1 = 0.0366898 loss)
I0529 11:40:12.374622 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.108607 (* 1 = 0.108607 loss)
I0529 11:40:12.374626 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0098301 (* 1 = 0.0098301 loss)
I0529 11:40:12.374630 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0775668 (* 1 = 0.0775668 loss)
I0529 11:40:12.374636 10644 sgd_solver.cpp:106] Iteration 27420, lr = 0.0002
I0529 11:41:00.907037 10644 solver.cpp:228] Iteration 27440, loss = 0.488755
I0529 11:41:00.907061 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 11:41:00.907069 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.161915 (* 1 = 0.161915 loss)
I0529 11:41:00.907074 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.321138 (* 1 = 0.321138 loss)
I0529 11:41:00.907080 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0237716 (* 1 = 0.0237716 loss)
I0529 11:41:00.907086 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332913 (* 1 = 0.0332913 loss)
I0529 11:41:00.907091 10644 sgd_solver.cpp:106] Iteration 27440, lr = 0.0002
I0529 11:41:49.430196 10644 solver.cpp:228] Iteration 27460, loss = 0.228844
I0529 11:41:49.430220 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 11:41:49.430228 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.017405 (* 1 = 0.017405 loss)
I0529 11:41:49.430234 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0724302 (* 1 = 0.0724302 loss)
I0529 11:41:49.430240 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00926775 (* 1 = 0.00926775 loss)
I0529 11:41:49.430245 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111831 (* 1 = 0.0111831 loss)
I0529 11:41:49.430250 10644 sgd_solver.cpp:106] Iteration 27460, lr = 0.0002
I0529 11:42:37.966085 10644 solver.cpp:228] Iteration 27480, loss = 0.262927
I0529 11:42:37.966114 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 11:42:37.966122 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.114153 (* 1 = 0.114153 loss)
I0529 11:42:37.966127 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.137141 (* 1 = 0.137141 loss)
I0529 11:42:37.966130 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136084 (* 1 = 0.0136084 loss)
I0529 11:42:37.966135 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208757 (* 1 = 0.0208757 loss)
I0529 11:42:37.966140 10644 sgd_solver.cpp:106] Iteration 27480, lr = 0.0002
I0529 11:43:26.479856 10644 solver.cpp:228] Iteration 27500, loss = 0.279493
I0529 11:43:26.479883 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 11:43:26.479892 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0372477 (* 1 = 0.0372477 loss)
I0529 11:43:26.479897 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.181524 (* 1 = 0.181524 loss)
I0529 11:43:26.479900 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256904 (* 1 = 0.0256904 loss)
I0529 11:43:26.479904 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276682 (* 1 = 0.0276682 loss)
I0529 11:43:26.479910 10644 sgd_solver.cpp:106] Iteration 27500, lr = 0.0002
I0529 11:44:15.002712 10644 solver.cpp:228] Iteration 27520, loss = 0.165165
I0529 11:44:15.002737 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 11:44:15.002748 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397823 (* 1 = 0.0397823 loss)
I0529 11:44:15.002753 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.202748 (* 1 = 0.202748 loss)
I0529 11:44:15.002760 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191442 (* 1 = 0.0191442 loss)
I0529 11:44:15.002765 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00524098 (* 1 = 0.00524098 loss)
I0529 11:44:15.002773 10644 sgd_solver.cpp:106] Iteration 27520, lr = 0.0002
I0529 11:45:03.504853 10644 solver.cpp:228] Iteration 27540, loss = 0.169768
I0529 11:45:03.504879 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 11:45:03.504887 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0115351 (* 1 = 0.0115351 loss)
I0529 11:45:03.504891 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0474585 (* 1 = 0.0474585 loss)
I0529 11:45:03.504895 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00471195 (* 1 = 0.00471195 loss)
I0529 11:45:03.504899 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00775959 (* 1 = 0.00775959 loss)
I0529 11:45:03.504904 10644 sgd_solver.cpp:106] Iteration 27540, lr = 0.0002
I0529 11:45:52.077080 10644 solver.cpp:228] Iteration 27560, loss = 0.208823
I0529 11:45:52.077106 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 11:45:52.077116 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467102 (* 1 = 0.0467102 loss)
I0529 11:45:52.077122 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145639 (* 1 = 0.145639 loss)
I0529 11:45:52.077127 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170032 (* 1 = 0.0170032 loss)
I0529 11:45:52.077132 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0459212 (* 1 = 0.0459212 loss)
I0529 11:45:52.077138 10644 sgd_solver.cpp:106] Iteration 27560, lr = 0.0002
I0529 11:46:40.616281 10644 solver.cpp:228] Iteration 27580, loss = 0.222741
I0529 11:46:40.616308 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:46:40.616317 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368757 (* 1 = 0.0368757 loss)
I0529 11:46:40.616323 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0585244 (* 1 = 0.0585244 loss)
I0529 11:46:40.616329 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00477653 (* 1 = 0.00477653 loss)
I0529 11:46:40.616334 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00659086 (* 1 = 0.00659086 loss)
I0529 11:46:40.616341 10644 sgd_solver.cpp:106] Iteration 27580, lr = 0.0002
speed: 2.428s / iter
I0529 11:47:29.150661 10644 solver.cpp:228] Iteration 27600, loss = 0.289485
I0529 11:47:29.150689 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 11:47:29.150696 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.124653 (* 1 = 0.124653 loss)
I0529 11:47:29.150699 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.270334 (* 1 = 0.270334 loss)
I0529 11:47:29.150703 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203547 (* 1 = 0.0203547 loss)
I0529 11:47:29.150707 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359267 (* 1 = 0.0359267 loss)
I0529 11:47:29.150712 10644 sgd_solver.cpp:106] Iteration 27600, lr = 0.0002
I0529 11:48:17.716934 10644 solver.cpp:228] Iteration 27620, loss = 0.376536
I0529 11:48:17.716961 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:48:17.716971 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613546 (* 1 = 0.0613546 loss)
I0529 11:48:17.716977 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0745779 (* 1 = 0.0745779 loss)
I0529 11:48:17.716984 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282134 (* 1 = 0.00282134 loss)
I0529 11:48:17.716989 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00151604 (* 1 = 0.00151604 loss)
I0529 11:48:17.716996 10644 sgd_solver.cpp:106] Iteration 27620, lr = 0.0002
I0529 11:49:06.295615 10644 solver.cpp:228] Iteration 27640, loss = 0.288015
I0529 11:49:06.295640 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 11:49:06.295648 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00489742 (* 1 = 0.00489742 loss)
I0529 11:49:06.295652 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0724058 (* 1 = 0.0724058 loss)
I0529 11:49:06.295655 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0479283 (* 1 = 0.0479283 loss)
I0529 11:49:06.295660 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00892818 (* 1 = 0.00892818 loss)
I0529 11:49:06.295665 10644 sgd_solver.cpp:106] Iteration 27640, lr = 0.0002
I0529 11:49:54.851969 10644 solver.cpp:228] Iteration 27660, loss = 0.218781
I0529 11:49:54.851992 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 11:49:54.851999 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.323637 (* 1 = 0.323637 loss)
I0529 11:49:54.852003 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.314137 (* 1 = 0.314137 loss)
I0529 11:49:54.852006 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111744 (* 1 = 0.0111744 loss)
I0529 11:49:54.852010 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333907 (* 1 = 0.0333907 loss)
I0529 11:49:54.852015 10644 sgd_solver.cpp:106] Iteration 27660, lr = 0.0002
I0529 11:50:43.413691 10644 solver.cpp:228] Iteration 27680, loss = 0.411099
I0529 11:50:43.413720 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 11:50:43.413727 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356022 (* 1 = 0.0356022 loss)
I0529 11:50:43.413731 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0331752 (* 1 = 0.0331752 loss)
I0529 11:50:43.413735 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206057 (* 1 = 0.00206057 loss)
I0529 11:50:43.413738 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00721732 (* 1 = 0.00721732 loss)
I0529 11:50:43.413744 10644 sgd_solver.cpp:106] Iteration 27680, lr = 0.0002
I0529 11:51:31.954607 10644 solver.cpp:228] Iteration 27700, loss = 0.192617
I0529 11:51:31.954632 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 11:51:31.954639 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.050432 (* 1 = 0.050432 loss)
I0529 11:51:31.954643 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0581961 (* 1 = 0.0581961 loss)
I0529 11:51:31.954646 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00230581 (* 1 = 0.00230581 loss)
I0529 11:51:31.954649 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205653 (* 1 = 0.0205653 loss)
I0529 11:51:31.954655 10644 sgd_solver.cpp:106] Iteration 27700, lr = 0.0002
I0529 11:52:20.504276 10644 solver.cpp:228] Iteration 27720, loss = 0.286558
I0529 11:52:20.504302 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 11:52:20.504309 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339082 (* 1 = 0.0339082 loss)
I0529 11:52:20.504313 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0645612 (* 1 = 0.0645612 loss)
I0529 11:52:20.504317 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00070794 (* 1 = 0.00070794 loss)
I0529 11:52:20.504323 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00480286 (* 1 = 0.00480286 loss)
I0529 11:52:20.504328 10644 sgd_solver.cpp:106] Iteration 27720, lr = 0.0002
I0529 11:53:09.138924 10644 solver.cpp:228] Iteration 27740, loss = 0.204772
I0529 11:53:09.138962 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 11:53:09.138972 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0632424 (* 1 = 0.0632424 loss)
I0529 11:53:09.138976 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0518734 (* 1 = 0.0518734 loss)
I0529 11:53:09.138979 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00261727 (* 1 = 0.00261727 loss)
I0529 11:53:09.138983 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185986 (* 1 = 0.0185986 loss)
I0529 11:53:09.138988 10644 sgd_solver.cpp:106] Iteration 27740, lr = 0.0002
I0529 11:53:57.672756 10644 solver.cpp:228] Iteration 27760, loss = 0.249189
I0529 11:53:57.672782 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0529 11:53:57.672789 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.192801 (* 1 = 0.192801 loss)
I0529 11:53:57.672792 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.390956 (* 1 = 0.390956 loss)
I0529 11:53:57.672796 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144228 (* 1 = 0.0144228 loss)
I0529 11:53:57.672799 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348106 (* 1 = 0.0348106 loss)
I0529 11:53:57.672806 10644 sgd_solver.cpp:106] Iteration 27760, lr = 0.0002
I0529 11:54:46.209653 10644 solver.cpp:228] Iteration 27780, loss = 0.374957
I0529 11:54:46.209678 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 11:54:46.209686 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0657936 (* 1 = 0.0657936 loss)
I0529 11:54:46.209689 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150901 (* 1 = 0.150901 loss)
I0529 11:54:46.209693 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778091 (* 1 = 0.00778091 loss)
I0529 11:54:46.209697 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0623898 (* 1 = 0.0623898 loss)
I0529 11:54:46.209702 10644 sgd_solver.cpp:106] Iteration 27780, lr = 0.0002
speed: 2.428s / iter
I0529 11:55:34.755722 10644 solver.cpp:228] Iteration 27800, loss = 0.15575
I0529 11:55:34.755748 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 11:55:34.755755 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0761719 (* 1 = 0.0761719 loss)
I0529 11:55:34.755759 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0543993 (* 1 = 0.0543993 loss)
I0529 11:55:34.755762 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0018418 (* 1 = 0.0018418 loss)
I0529 11:55:34.755766 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00936154 (* 1 = 0.00936154 loss)
I0529 11:55:34.755770 10644 sgd_solver.cpp:106] Iteration 27800, lr = 0.0002
I0529 11:56:23.341230 10644 solver.cpp:228] Iteration 27820, loss = 0.275326
I0529 11:56:23.341255 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 11:56:23.341262 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.229078 (* 1 = 0.229078 loss)
I0529 11:56:23.341266 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.39678 (* 1 = 0.39678 loss)
I0529 11:56:23.341269 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015391 (* 1 = 0.015391 loss)
I0529 11:56:23.341274 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0836557 (* 1 = 0.0836557 loss)
I0529 11:56:23.341279 10644 sgd_solver.cpp:106] Iteration 27820, lr = 0.0002
I0529 11:57:11.902936 10644 solver.cpp:228] Iteration 27840, loss = 0.287879
I0529 11:57:11.902962 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 11:57:11.902969 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496484 (* 1 = 0.0496484 loss)
I0529 11:57:11.902973 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115888 (* 1 = 0.115888 loss)
I0529 11:57:11.902977 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148599 (* 1 = 0.0148599 loss)
I0529 11:57:11.902981 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317783 (* 1 = 0.0317783 loss)
I0529 11:57:11.902986 10644 sgd_solver.cpp:106] Iteration 27840, lr = 0.0002
I0529 11:58:00.461797 10644 solver.cpp:228] Iteration 27860, loss = 0.273167
I0529 11:58:00.461824 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 11:58:00.461832 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326499 (* 1 = 0.0326499 loss)
I0529 11:58:00.461835 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.168396 (* 1 = 0.168396 loss)
I0529 11:58:00.461838 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00602736 (* 1 = 0.00602736 loss)
I0529 11:58:00.461843 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224835 (* 1 = 0.0224835 loss)
I0529 11:58:00.461848 10644 sgd_solver.cpp:106] Iteration 27860, lr = 0.0002
I0529 11:58:49.018903 10644 solver.cpp:228] Iteration 27880, loss = 0.320012
I0529 11:58:49.018929 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 11:58:49.018937 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460613 (* 1 = 0.0460613 loss)
I0529 11:58:49.018941 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0385596 (* 1 = 0.0385596 loss)
I0529 11:58:49.018945 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00180511 (* 1 = 0.00180511 loss)
I0529 11:58:49.018949 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012547 (* 1 = 0.012547 loss)
I0529 11:58:49.018955 10644 sgd_solver.cpp:106] Iteration 27880, lr = 0.0002
I0529 11:59:37.570788 10644 solver.cpp:228] Iteration 27900, loss = 0.186777
I0529 11:59:37.570816 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 11:59:37.570823 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.153044 (* 1 = 0.153044 loss)
I0529 11:59:37.570828 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.192571 (* 1 = 0.192571 loss)
I0529 11:59:37.570832 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0040348 (* 1 = 0.0040348 loss)
I0529 11:59:37.570837 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230226 (* 1 = 0.0230226 loss)
I0529 11:59:37.570842 10644 sgd_solver.cpp:106] Iteration 27900, lr = 0.0002
I0529 12:00:26.079417 10644 solver.cpp:228] Iteration 27920, loss = 0.254929
I0529 12:00:26.079440 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 12:00:26.079448 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476173 (* 1 = 0.0476173 loss)
I0529 12:00:26.079452 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.178394 (* 1 = 0.178394 loss)
I0529 12:00:26.079457 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169338 (* 1 = 0.00169338 loss)
I0529 12:00:26.079461 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102795 (* 1 = 0.0102795 loss)
I0529 12:00:26.079466 10644 sgd_solver.cpp:106] Iteration 27920, lr = 0.0002
I0529 12:01:14.665064 10644 solver.cpp:228] Iteration 27940, loss = 0.514013
I0529 12:01:14.665091 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:01:14.665099 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262014 (* 1 = 0.0262014 loss)
I0529 12:01:14.665103 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0512578 (* 1 = 0.0512578 loss)
I0529 12:01:14.665107 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106546 (* 1 = 0.0106546 loss)
I0529 12:01:14.665112 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00991992 (* 1 = 0.00991992 loss)
I0529 12:01:14.665117 10644 sgd_solver.cpp:106] Iteration 27940, lr = 0.0002
I0529 12:02:03.214046 10644 solver.cpp:228] Iteration 27960, loss = 0.159491
I0529 12:02:03.214071 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:02:03.214079 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224005 (* 1 = 0.0224005 loss)
I0529 12:02:03.214083 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0549144 (* 1 = 0.0549144 loss)
I0529 12:02:03.214087 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0319313 (* 1 = 0.0319313 loss)
I0529 12:02:03.214090 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306508 (* 1 = 0.0306508 loss)
I0529 12:02:03.214097 10644 sgd_solver.cpp:106] Iteration 27960, lr = 0.0002
I0529 12:02:51.772014 10644 solver.cpp:228] Iteration 27980, loss = 0.33247
I0529 12:02:51.772043 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 12:02:51.772052 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0586118 (* 1 = 0.0586118 loss)
I0529 12:02:51.772055 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.109529 (* 1 = 0.109529 loss)
I0529 12:02:51.772059 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118295 (* 1 = 0.0118295 loss)
I0529 12:02:51.772063 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129916 (* 1 = 0.0129916 loss)
I0529 12:02:51.772068 10644 sgd_solver.cpp:106] Iteration 27980, lr = 0.0002
speed: 2.428s / iter
I0529 12:03:40.330276 10644 solver.cpp:228] Iteration 28000, loss = 0.280555
I0529 12:03:40.330310 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:03:40.330322 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226657 (* 1 = 0.0226657 loss)
I0529 12:03:40.330327 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0376359 (* 1 = 0.0376359 loss)
I0529 12:03:40.330334 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00549086 (* 1 = 0.00549086 loss)
I0529 12:03:40.330340 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00292403 (* 1 = 0.00292403 loss)
I0529 12:03:40.330348 10644 sgd_solver.cpp:106] Iteration 28000, lr = 0.0002
I0529 12:04:28.892671 10644 solver.cpp:228] Iteration 28020, loss = 0.278274
I0529 12:04:28.892698 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 12:04:28.892704 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.162477 (* 1 = 0.162477 loss)
I0529 12:04:28.892709 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.255925 (* 1 = 0.255925 loss)
I0529 12:04:28.892712 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00909887 (* 1 = 0.00909887 loss)
I0529 12:04:28.892715 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333678 (* 1 = 0.0333678 loss)
I0529 12:04:28.892721 10644 sgd_solver.cpp:106] Iteration 28020, lr = 0.0002
I0529 12:05:17.460243 10644 solver.cpp:228] Iteration 28040, loss = 0.438255
I0529 12:05:17.460268 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0529 12:05:17.460275 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.426876 (* 1 = 0.426876 loss)
I0529 12:05:17.460278 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.510754 (* 1 = 0.510754 loss)
I0529 12:05:17.460283 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181659 (* 1 = 0.0181659 loss)
I0529 12:05:17.460285 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.415272 (* 1 = 0.415272 loss)
I0529 12:05:17.460290 10644 sgd_solver.cpp:106] Iteration 28040, lr = 0.0002
I0529 12:06:05.989548 10644 solver.cpp:228] Iteration 28060, loss = 0.255947
I0529 12:06:05.989575 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:06:05.989583 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321399 (* 1 = 0.0321399 loss)
I0529 12:06:05.989590 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0504111 (* 1 = 0.0504111 loss)
I0529 12:06:05.989595 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032099 (* 1 = 0.0032099 loss)
I0529 12:06:05.989601 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130706 (* 1 = 0.0130706 loss)
I0529 12:06:05.989608 10644 sgd_solver.cpp:106] Iteration 28060, lr = 0.0002
I0529 12:06:54.576072 10644 solver.cpp:228] Iteration 28080, loss = 0.292898
I0529 12:06:54.576098 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:06:54.576105 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373477 (* 1 = 0.0373477 loss)
I0529 12:06:54.576109 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.06214 (* 1 = 0.06214 loss)
I0529 12:06:54.576112 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110401 (* 1 = 0.0110401 loss)
I0529 12:06:54.576117 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00869191 (* 1 = 0.00869191 loss)
I0529 12:06:54.576122 10644 sgd_solver.cpp:106] Iteration 28080, lr = 0.0002
I0529 12:07:43.100848 10644 solver.cpp:228] Iteration 28100, loss = 0.165405
I0529 12:07:43.100878 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 12:07:43.100886 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118991 (* 1 = 0.118991 loss)
I0529 12:07:43.100893 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.100869 (* 1 = 0.100869 loss)
I0529 12:07:43.100898 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00317082 (* 1 = 0.00317082 loss)
I0529 12:07:43.100904 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103769 (* 1 = 0.0103769 loss)
I0529 12:07:43.100914 10644 sgd_solver.cpp:106] Iteration 28100, lr = 0.0002
I0529 12:08:31.658810 10644 solver.cpp:228] Iteration 28120, loss = 0.340232
I0529 12:08:31.658839 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 12:08:31.658849 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.183126 (* 1 = 0.183126 loss)
I0529 12:08:31.658854 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.192358 (* 1 = 0.192358 loss)
I0529 12:08:31.658859 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0056509 (* 1 = 0.0056509 loss)
I0529 12:08:31.658864 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0638473 (* 1 = 0.0638473 loss)
I0529 12:08:31.658871 10644 sgd_solver.cpp:106] Iteration 28120, lr = 0.0002
I0529 12:09:20.299993 10644 solver.cpp:228] Iteration 28140, loss = 0.256271
I0529 12:09:20.300020 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 12:09:20.300029 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.094228 (* 1 = 0.094228 loss)
I0529 12:09:20.300034 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.242497 (* 1 = 0.242497 loss)
I0529 12:09:20.300037 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0310583 (* 1 = 0.0310583 loss)
I0529 12:09:20.300040 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408567 (* 1 = 0.0408567 loss)
I0529 12:09:20.300046 10644 sgd_solver.cpp:106] Iteration 28140, lr = 0.0002
I0529 12:10:08.841711 10644 solver.cpp:228] Iteration 28160, loss = 0.228108
I0529 12:10:08.841737 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:10:08.841743 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140757 (* 1 = 0.0140757 loss)
I0529 12:10:08.841748 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0625535 (* 1 = 0.0625535 loss)
I0529 12:10:08.841753 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188385 (* 1 = 0.0188385 loss)
I0529 12:10:08.841756 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190225 (* 1 = 0.0190225 loss)
I0529 12:10:08.841763 10644 sgd_solver.cpp:106] Iteration 28160, lr = 0.0002
I0529 12:10:57.393218 10644 solver.cpp:228] Iteration 28180, loss = 0.172016
I0529 12:10:57.393247 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 12:10:57.393254 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0987266 (* 1 = 0.0987266 loss)
I0529 12:10:57.393257 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.10496 (* 1 = 0.10496 loss)
I0529 12:10:57.393261 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00247266 (* 1 = 0.00247266 loss)
I0529 12:10:57.393265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419703 (* 1 = 0.0419703 loss)
I0529 12:10:57.393270 10644 sgd_solver.cpp:106] Iteration 28180, lr = 0.0002
speed: 2.428s / iter
I0529 12:11:45.954756 10644 solver.cpp:228] Iteration 28200, loss = 0.418831
I0529 12:11:45.954785 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 12:11:45.954794 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.153346 (* 1 = 0.153346 loss)
I0529 12:11:45.954800 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.324141 (* 1 = 0.324141 loss)
I0529 12:11:45.954805 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424359 (* 1 = 0.00424359 loss)
I0529 12:11:45.954812 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0360063 (* 1 = 0.0360063 loss)
I0529 12:11:45.954818 10644 sgd_solver.cpp:106] Iteration 28200, lr = 0.0002
I0529 12:12:34.508904 10644 solver.cpp:228] Iteration 28220, loss = 0.233251
I0529 12:12:34.508934 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:12:34.508942 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0112359 (* 1 = 0.0112359 loss)
I0529 12:12:34.508946 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0673717 (* 1 = 0.0673717 loss)
I0529 12:12:34.508949 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0430278 (* 1 = 0.0430278 loss)
I0529 12:12:34.508954 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276763 (* 1 = 0.0276763 loss)
I0529 12:12:34.508958 10644 sgd_solver.cpp:106] Iteration 28220, lr = 0.0002
I0529 12:13:23.060832 10644 solver.cpp:228] Iteration 28240, loss = 0.521431
I0529 12:13:23.060859 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 12:13:23.060866 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.111055 (* 1 = 0.111055 loss)
I0529 12:13:23.060870 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.281279 (* 1 = 0.281279 loss)
I0529 12:13:23.060874 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0061439 (* 1 = 0.0061439 loss)
I0529 12:13:23.060878 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512754 (* 1 = 0.0512754 loss)
I0529 12:13:23.060881 10644 sgd_solver.cpp:106] Iteration 28240, lr = 0.0002
I0529 12:14:11.602775 10644 solver.cpp:228] Iteration 28260, loss = 0.589428
I0529 12:14:11.602800 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:14:11.602807 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0238055 (* 1 = 0.0238055 loss)
I0529 12:14:11.602810 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0769327 (* 1 = 0.0769327 loss)
I0529 12:14:11.602814 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00371917 (* 1 = 0.00371917 loss)
I0529 12:14:11.602818 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100101 (* 1 = 0.0100101 loss)
I0529 12:14:11.602823 10644 sgd_solver.cpp:106] Iteration 28260, lr = 0.0002
I0529 12:15:00.154114 10644 solver.cpp:228] Iteration 28280, loss = 0.314395
I0529 12:15:00.154140 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 12:15:00.154148 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481695 (* 1 = 0.0481695 loss)
I0529 12:15:00.154151 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0555088 (* 1 = 0.0555088 loss)
I0529 12:15:00.154155 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00745591 (* 1 = 0.00745591 loss)
I0529 12:15:00.154158 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179588 (* 1 = 0.0179588 loss)
I0529 12:15:00.154165 10644 sgd_solver.cpp:106] Iteration 28280, lr = 0.0002
I0529 12:15:48.685803 10644 solver.cpp:228] Iteration 28300, loss = 0.254623
I0529 12:15:48.685829 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 12:15:48.685837 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.300616 (* 1 = 0.300616 loss)
I0529 12:15:48.685840 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.370732 (* 1 = 0.370732 loss)
I0529 12:15:48.685843 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200127 (* 1 = 0.0200127 loss)
I0529 12:15:48.685847 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405205 (* 1 = 0.0405205 loss)
I0529 12:15:48.685851 10644 sgd_solver.cpp:106] Iteration 28300, lr = 0.0002
I0529 12:16:37.222393 10644 solver.cpp:228] Iteration 28320, loss = 0.27721
I0529 12:16:37.222419 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:16:37.222426 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274228 (* 1 = 0.0274228 loss)
I0529 12:16:37.222430 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0882421 (* 1 = 0.0882421 loss)
I0529 12:16:37.222434 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244755 (* 1 = 0.0244755 loss)
I0529 12:16:37.222437 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03136 (* 1 = 0.03136 loss)
I0529 12:16:37.222442 10644 sgd_solver.cpp:106] Iteration 28320, lr = 0.0002
I0529 12:17:25.788908 10644 solver.cpp:228] Iteration 28340, loss = 0.210724
I0529 12:17:25.788942 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:17:25.788949 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.062851 (* 1 = 0.062851 loss)
I0529 12:17:25.788954 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0478799 (* 1 = 0.0478799 loss)
I0529 12:17:25.788959 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0083609 (* 1 = 0.0083609 loss)
I0529 12:17:25.788962 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139944 (* 1 = 0.0139944 loss)
I0529 12:17:25.788967 10644 sgd_solver.cpp:106] Iteration 28340, lr = 0.0002
I0529 12:18:14.326606 10644 solver.cpp:228] Iteration 28360, loss = 0.412665
I0529 12:18:14.326634 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 12:18:14.326642 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237805 (* 1 = 0.0237805 loss)
I0529 12:18:14.326647 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0698161 (* 1 = 0.0698161 loss)
I0529 12:18:14.326650 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00343231 (* 1 = 0.00343231 loss)
I0529 12:18:14.326654 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00298524 (* 1 = 0.00298524 loss)
I0529 12:18:14.326660 10644 sgd_solver.cpp:106] Iteration 28360, lr = 0.0002
I0529 12:19:02.854089 10644 solver.cpp:228] Iteration 28380, loss = 0.245328
I0529 12:19:02.854113 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 12:19:02.854121 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0606131 (* 1 = 0.0606131 loss)
I0529 12:19:02.854126 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0990675 (* 1 = 0.0990675 loss)
I0529 12:19:02.854130 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00434862 (* 1 = 0.00434862 loss)
I0529 12:19:02.854133 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00500492 (* 1 = 0.00500492 loss)
I0529 12:19:02.854138 10644 sgd_solver.cpp:106] Iteration 28380, lr = 0.0002
speed: 2.428s / iter
I0529 12:19:51.407074 10644 solver.cpp:228] Iteration 28400, loss = 0.564775
I0529 12:19:51.407102 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:19:51.407110 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.033109 (* 1 = 0.033109 loss)
I0529 12:19:51.407114 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.118861 (* 1 = 0.118861 loss)
I0529 12:19:51.407119 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00404212 (* 1 = 0.00404212 loss)
I0529 12:19:51.407122 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00463727 (* 1 = 0.00463727 loss)
I0529 12:19:51.407129 10644 sgd_solver.cpp:106] Iteration 28400, lr = 0.0002
I0529 12:20:39.929101 10644 solver.cpp:228] Iteration 28420, loss = 0.226718
I0529 12:20:39.929127 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 12:20:39.929136 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690234 (* 1 = 0.0690234 loss)
I0529 12:20:39.929139 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0926847 (* 1 = 0.0926847 loss)
I0529 12:20:39.929143 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159655 (* 1 = 0.0159655 loss)
I0529 12:20:39.929147 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233676 (* 1 = 0.0233676 loss)
I0529 12:20:39.929152 10644 sgd_solver.cpp:106] Iteration 28420, lr = 0.0002
I0529 12:21:28.494567 10644 solver.cpp:228] Iteration 28440, loss = 0.44612
I0529 12:21:28.494596 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 12:21:28.494603 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0938299 (* 1 = 0.0938299 loss)
I0529 12:21:28.494607 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.124642 (* 1 = 0.124642 loss)
I0529 12:21:28.494611 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00316288 (* 1 = 0.00316288 loss)
I0529 12:21:28.494616 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010179 (* 1 = 0.010179 loss)
I0529 12:21:28.494621 10644 sgd_solver.cpp:106] Iteration 28440, lr = 0.0002
I0529 12:22:17.053891 10644 solver.cpp:228] Iteration 28460, loss = 0.259319
I0529 12:22:17.053916 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:22:17.053925 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268843 (* 1 = 0.0268843 loss)
I0529 12:22:17.053930 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0643592 (* 1 = 0.0643592 loss)
I0529 12:22:17.053933 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171692 (* 1 = 0.00171692 loss)
I0529 12:22:17.053936 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010478 (* 1 = 0.010478 loss)
I0529 12:22:17.053941 10644 sgd_solver.cpp:106] Iteration 28460, lr = 0.0002
I0529 12:23:05.581898 10644 solver.cpp:228] Iteration 28480, loss = 0.320944
I0529 12:23:05.581938 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 12:23:05.581948 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.177582 (* 1 = 0.177582 loss)
I0529 12:23:05.581951 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.301655 (* 1 = 0.301655 loss)
I0529 12:23:05.581955 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179503 (* 1 = 0.0179503 loss)
I0529 12:23:05.581959 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13685 (* 1 = 0.13685 loss)
I0529 12:23:05.581966 10644 sgd_solver.cpp:106] Iteration 28480, lr = 0.0002
I0529 12:23:54.124172 10644 solver.cpp:228] Iteration 28500, loss = 0.211276
I0529 12:23:54.124199 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:23:54.124207 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00761779 (* 1 = 0.00761779 loss)
I0529 12:23:54.124210 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0614328 (* 1 = 0.0614328 loss)
I0529 12:23:54.124213 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164864 (* 1 = 0.0164864 loss)
I0529 12:23:54.124217 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0717965 (* 1 = 0.0717965 loss)
I0529 12:23:54.124222 10644 sgd_solver.cpp:106] Iteration 28500, lr = 0.0002
I0529 12:24:42.629649 10644 solver.cpp:228] Iteration 28520, loss = 0.303148
I0529 12:24:42.629673 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 12:24:42.629681 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.050229 (* 1 = 0.050229 loss)
I0529 12:24:42.629685 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.229846 (* 1 = 0.229846 loss)
I0529 12:24:42.629688 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511008 (* 1 = 0.00511008 loss)
I0529 12:24:42.629691 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121683 (* 1 = 0.0121683 loss)
I0529 12:24:42.629698 10644 sgd_solver.cpp:106] Iteration 28520, lr = 0.0002
I0529 12:25:31.211537 10644 solver.cpp:228] Iteration 28540, loss = 0.4176
I0529 12:25:31.211567 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 12:25:31.211575 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.233147 (* 1 = 0.233147 loss)
I0529 12:25:31.211578 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.218425 (* 1 = 0.218425 loss)
I0529 12:25:31.211582 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00397315 (* 1 = 0.00397315 loss)
I0529 12:25:31.211585 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0517093 (* 1 = 0.0517093 loss)
I0529 12:25:31.211591 10644 sgd_solver.cpp:106] Iteration 28540, lr = 0.0002
I0529 12:26:19.757381 10644 solver.cpp:228] Iteration 28560, loss = 0.22245
I0529 12:26:19.757407 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 12:26:19.757414 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363658 (* 1 = 0.0363658 loss)
I0529 12:26:19.757418 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0593152 (* 1 = 0.0593152 loss)
I0529 12:26:19.757422 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035795 (* 1 = 0.0035795 loss)
I0529 12:26:19.757426 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00727085 (* 1 = 0.00727085 loss)
I0529 12:26:19.757431 10644 sgd_solver.cpp:106] Iteration 28560, lr = 0.0002
I0529 12:27:08.302179 10644 solver.cpp:228] Iteration 28580, loss = 0.281825
I0529 12:27:08.302206 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 12:27:08.302214 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0570008 (* 1 = 0.0570008 loss)
I0529 12:27:08.302220 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.227197 (* 1 = 0.227197 loss)
I0529 12:27:08.302225 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.133518 (* 1 = 0.133518 loss)
I0529 12:27:08.302230 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.243063 (* 1 = 0.243063 loss)
I0529 12:27:08.302237 10644 sgd_solver.cpp:106] Iteration 28580, lr = 0.0002
speed: 2.428s / iter
I0529 12:27:56.855599 10644 solver.cpp:228] Iteration 28600, loss = 0.191205
I0529 12:27:56.855623 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:27:56.855629 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.030614 (* 1 = 0.030614 loss)
I0529 12:27:56.855633 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0393327 (* 1 = 0.0393327 loss)
I0529 12:27:56.855636 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0324507 (* 1 = 0.0324507 loss)
I0529 12:27:56.855639 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202876 (* 1 = 0.0202876 loss)
I0529 12:27:56.855644 10644 sgd_solver.cpp:106] Iteration 28600, lr = 0.0002
I0529 12:28:45.421972 10644 solver.cpp:228] Iteration 28620, loss = 0.291769
I0529 12:28:45.421998 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 12:28:45.422004 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384347 (* 1 = 0.0384347 loss)
I0529 12:28:45.422008 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.064218 (* 1 = 0.064218 loss)
I0529 12:28:45.422011 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00464615 (* 1 = 0.00464615 loss)
I0529 12:28:45.422015 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144017 (* 1 = 0.0144017 loss)
I0529 12:28:45.422020 10644 sgd_solver.cpp:106] Iteration 28620, lr = 0.0002
I0529 12:29:34.006621 10644 solver.cpp:228] Iteration 28640, loss = 0.337234
I0529 12:29:34.006647 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0529 12:29:34.006654 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.478933 (* 1 = 0.478933 loss)
I0529 12:29:34.006657 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.456831 (* 1 = 0.456831 loss)
I0529 12:29:34.006661 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164822 (* 1 = 0.0164822 loss)
I0529 12:29:34.006664 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0954888 (* 1 = 0.0954888 loss)
I0529 12:29:34.006669 10644 sgd_solver.cpp:106] Iteration 28640, lr = 0.0002
I0529 12:30:22.549509 10644 solver.cpp:228] Iteration 28660, loss = 0.299698
I0529 12:30:22.549536 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 12:30:22.549545 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0645892 (* 1 = 0.0645892 loss)
I0529 12:30:22.549548 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.148918 (* 1 = 0.148918 loss)
I0529 12:30:22.549552 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00670556 (* 1 = 0.00670556 loss)
I0529 12:30:22.549556 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318724 (* 1 = 0.0318724 loss)
I0529 12:30:22.549561 10644 sgd_solver.cpp:106] Iteration 28660, lr = 0.0002
I0529 12:31:11.118453 10644 solver.cpp:228] Iteration 28680, loss = 0.156389
I0529 12:31:11.118481 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:31:11.118489 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00114443 (* 1 = 0.00114443 loss)
I0529 12:31:11.118494 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0436389 (* 1 = 0.0436389 loss)
I0529 12:31:11.118497 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00407015 (* 1 = 0.00407015 loss)
I0529 12:31:11.118502 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158926 (* 1 = 0.0158926 loss)
I0529 12:31:11.118508 10644 sgd_solver.cpp:106] Iteration 28680, lr = 0.0002
I0529 12:31:59.661736 10644 solver.cpp:228] Iteration 28700, loss = 0.225185
I0529 12:31:59.661765 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 12:31:59.661775 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.180928 (* 1 = 0.180928 loss)
I0529 12:31:59.661782 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.181947 (* 1 = 0.181947 loss)
I0529 12:31:59.661787 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00646223 (* 1 = 0.00646223 loss)
I0529 12:31:59.661793 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234631 (* 1 = 0.0234631 loss)
I0529 12:31:59.661799 10644 sgd_solver.cpp:106] Iteration 28700, lr = 0.0002
I0529 12:32:48.269301 10644 solver.cpp:228] Iteration 28720, loss = 0.306799
I0529 12:32:48.269327 10644 solver.cpp:244]     Train net output #0: accuarcy = 1
I0529 12:32:48.269338 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410793 (* 1 = 0.0410793 loss)
I0529 12:32:48.269345 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0269118 (* 1 = 0.0269118 loss)
I0529 12:32:48.269351 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186349 (* 1 = 0.00186349 loss)
I0529 12:32:48.269358 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00881432 (* 1 = 0.00881432 loss)
I0529 12:32:48.269366 10644 sgd_solver.cpp:106] Iteration 28720, lr = 0.0002
I0529 12:33:36.822643 10644 solver.cpp:228] Iteration 28740, loss = 0.317852
I0529 12:33:36.822672 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 12:33:36.822680 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298084 (* 1 = 0.0298084 loss)
I0529 12:33:36.822685 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.102606 (* 1 = 0.102606 loss)
I0529 12:33:36.822688 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212032 (* 1 = 0.0212032 loss)
I0529 12:33:36.822692 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237364 (* 1 = 0.0237364 loss)
I0529 12:33:36.822698 10644 sgd_solver.cpp:106] Iteration 28740, lr = 0.0002
I0529 12:34:25.393555 10644 solver.cpp:228] Iteration 28760, loss = 0.170158
I0529 12:34:25.393581 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 12:34:25.393590 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.18552 (* 1 = 0.18552 loss)
I0529 12:34:25.393594 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.151629 (* 1 = 0.151629 loss)
I0529 12:34:25.393599 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00690687 (* 1 = 0.00690687 loss)
I0529 12:34:25.393602 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258572 (* 1 = 0.0258572 loss)
I0529 12:34:25.393607 10644 sgd_solver.cpp:106] Iteration 28760, lr = 0.0002
I0529 12:35:13.905912 10644 solver.cpp:228] Iteration 28780, loss = 0.334951
I0529 12:35:13.905941 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 12:35:13.905951 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0438507 (* 1 = 0.0438507 loss)
I0529 12:35:13.905957 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.195469 (* 1 = 0.195469 loss)
I0529 12:35:13.905964 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00531309 (* 1 = 0.00531309 loss)
I0529 12:35:13.905969 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00699248 (* 1 = 0.00699248 loss)
I0529 12:35:13.905977 10644 sgd_solver.cpp:106] Iteration 28780, lr = 0.0002
speed: 2.428s / iter
I0529 12:36:02.466210 10644 solver.cpp:228] Iteration 28800, loss = 0.387253
I0529 12:36:02.466235 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:36:02.466246 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0444633 (* 1 = 0.0444633 loss)
I0529 12:36:02.466253 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0884973 (* 1 = 0.0884973 loss)
I0529 12:36:02.466259 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207609 (* 1 = 0.00207609 loss)
I0529 12:36:02.466265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015098 (* 1 = 0.015098 loss)
I0529 12:36:02.466272 10644 sgd_solver.cpp:106] Iteration 28800, lr = 0.0002
I0529 12:36:51.026203 10644 solver.cpp:228] Iteration 28820, loss = 0.378735
I0529 12:36:51.026233 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 12:36:51.026243 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.211559 (* 1 = 0.211559 loss)
I0529 12:36:51.026248 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.244886 (* 1 = 0.244886 loss)
I0529 12:36:51.026254 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00695418 (* 1 = 0.00695418 loss)
I0529 12:36:51.026259 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0384086 (* 1 = 0.0384086 loss)
I0529 12:36:51.026266 10644 sgd_solver.cpp:106] Iteration 28820, lr = 0.0002
I0529 12:37:39.666868 10644 solver.cpp:228] Iteration 28840, loss = 0.40574
I0529 12:37:39.666895 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:37:39.666903 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00201973 (* 1 = 0.00201973 loss)
I0529 12:37:39.666908 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0482266 (* 1 = 0.0482266 loss)
I0529 12:37:39.666911 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189781 (* 1 = 0.0189781 loss)
I0529 12:37:39.666914 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125571 (* 1 = 0.0125571 loss)
I0529 12:37:39.666920 10644 sgd_solver.cpp:106] Iteration 28840, lr = 0.0002
I0529 12:38:28.231124 10644 solver.cpp:228] Iteration 28860, loss = 0.407346
I0529 12:38:28.231151 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 12:38:28.231159 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.080573 (* 1 = 0.080573 loss)
I0529 12:38:28.231164 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.145098 (* 1 = 0.145098 loss)
I0529 12:38:28.231168 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296435 (* 1 = 0.00296435 loss)
I0529 12:38:28.231171 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012235 (* 1 = 0.012235 loss)
I0529 12:38:28.231176 10644 sgd_solver.cpp:106] Iteration 28860, lr = 0.0002
I0529 12:39:16.925874 10644 solver.cpp:228] Iteration 28880, loss = 0.327904
I0529 12:39:16.925899 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 12:39:16.925906 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295063 (* 1 = 0.0295063 loss)
I0529 12:39:16.925910 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0627566 (* 1 = 0.0627566 loss)
I0529 12:39:16.925915 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00284048 (* 1 = 0.00284048 loss)
I0529 12:39:16.925917 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00577909 (* 1 = 0.00577909 loss)
I0529 12:39:16.925921 10644 sgd_solver.cpp:106] Iteration 28880, lr = 0.0002
I0529 12:40:05.488415 10644 solver.cpp:228] Iteration 28900, loss = 0.30042
I0529 12:40:05.488440 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 12:40:05.488446 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.279547 (* 1 = 0.279547 loss)
I0529 12:40:05.488451 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.329223 (* 1 = 0.329223 loss)
I0529 12:40:05.488453 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.008796 (* 1 = 0.008796 loss)
I0529 12:40:05.488457 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.078018 (* 1 = 0.078018 loss)
I0529 12:40:05.488462 10644 sgd_solver.cpp:106] Iteration 28900, lr = 0.0002
I0529 12:40:54.021281 10644 solver.cpp:228] Iteration 28920, loss = 0.370855
I0529 12:40:54.021306 10644 solver.cpp:244]     Train net output #0: accuarcy = 1
I0529 12:40:54.021312 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0342054 (* 1 = 0.0342054 loss)
I0529 12:40:54.021317 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0479958 (* 1 = 0.0479958 loss)
I0529 12:40:54.021319 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00612791 (* 1 = 0.00612791 loss)
I0529 12:40:54.021323 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00805654 (* 1 = 0.00805654 loss)
I0529 12:40:54.021328 10644 sgd_solver.cpp:106] Iteration 28920, lr = 0.0002
I0529 12:41:42.586097 10644 solver.cpp:228] Iteration 28940, loss = 0.443985
I0529 12:41:42.586122 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 12:41:42.586129 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737212 (* 1 = 0.0737212 loss)
I0529 12:41:42.586133 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.132884 (* 1 = 0.132884 loss)
I0529 12:41:42.586136 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00267853 (* 1 = 0.00267853 loss)
I0529 12:41:42.586140 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211267 (* 1 = 0.0211267 loss)
I0529 12:41:42.586145 10644 sgd_solver.cpp:106] Iteration 28940, lr = 0.0002
I0529 12:42:31.128826 10644 solver.cpp:228] Iteration 28960, loss = 0.263553
I0529 12:42:31.128854 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 12:42:31.128862 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486622 (* 1 = 0.0486622 loss)
I0529 12:42:31.128866 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.125914 (* 1 = 0.125914 loss)
I0529 12:42:31.128870 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157156 (* 1 = 0.0157156 loss)
I0529 12:42:31.128875 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030929 (* 1 = 0.030929 loss)
I0529 12:42:31.128878 10644 sgd_solver.cpp:106] Iteration 28960, lr = 0.0002
I0529 12:43:19.789378 10644 solver.cpp:228] Iteration 28980, loss = 0.307874
I0529 12:43:19.789407 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:43:19.789413 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000334763 (* 1 = 0.000334763 loss)
I0529 12:43:19.789417 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0426041 (* 1 = 0.0426041 loss)
I0529 12:43:19.789420 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105755 (* 1 = 0.0105755 loss)
I0529 12:43:19.789424 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0511324 (* 1 = 0.0511324 loss)
I0529 12:43:19.789429 10644 sgd_solver.cpp:106] Iteration 28980, lr = 0.0002
speed: 2.428s / iter
I0529 12:44:08.350551 10644 solver.cpp:228] Iteration 29000, loss = 0.276243
I0529 12:44:08.350576 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 12:44:08.350584 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.062353 (* 1 = 0.062353 loss)
I0529 12:44:08.350589 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.1681 (* 1 = 0.1681 loss)
I0529 12:44:08.350591 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124473 (* 1 = 0.0124473 loss)
I0529 12:44:08.350595 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229869 (* 1 = 0.0229869 loss)
I0529 12:44:08.350600 10644 sgd_solver.cpp:106] Iteration 29000, lr = 0.0002
I0529 12:44:56.918301 10644 solver.cpp:228] Iteration 29020, loss = 0.388362
I0529 12:44:56.918329 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 12:44:56.918335 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.182175 (* 1 = 0.182175 loss)
I0529 12:44:56.918339 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.266318 (* 1 = 0.266318 loss)
I0529 12:44:56.918342 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114409 (* 1 = 0.0114409 loss)
I0529 12:44:56.918345 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197203 (* 1 = 0.0197203 loss)
I0529 12:44:56.918350 10644 sgd_solver.cpp:106] Iteration 29020, lr = 0.0002
I0529 12:45:45.570396 10644 solver.cpp:228] Iteration 29040, loss = 0.497145
I0529 12:45:45.570423 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 12:45:45.570430 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.302395 (* 1 = 0.302395 loss)
I0529 12:45:45.570435 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.479379 (* 1 = 0.479379 loss)
I0529 12:45:45.570438 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152727 (* 1 = 0.0152727 loss)
I0529 12:45:45.570442 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.053059 (* 1 = 0.053059 loss)
I0529 12:45:45.570448 10644 sgd_solver.cpp:106] Iteration 29040, lr = 0.0002
I0529 12:46:34.145898 10644 solver.cpp:228] Iteration 29060, loss = 0.288356
I0529 12:46:34.145925 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:46:34.145931 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383377 (* 1 = 0.0383377 loss)
I0529 12:46:34.145936 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0354537 (* 1 = 0.0354537 loss)
I0529 12:46:34.145939 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00321071 (* 1 = 0.00321071 loss)
I0529 12:46:34.145946 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00986509 (* 1 = 0.00986509 loss)
I0529 12:46:34.145951 10644 sgd_solver.cpp:106] Iteration 29060, lr = 0.0002
I0529 12:47:22.697187 10644 solver.cpp:228] Iteration 29080, loss = 0.370397
I0529 12:47:22.697213 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 12:47:22.697221 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739834 (* 1 = 0.0739834 loss)
I0529 12:47:22.697226 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0863611 (* 1 = 0.0863611 loss)
I0529 12:47:22.697229 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00418706 (* 1 = 0.00418706 loss)
I0529 12:47:22.697233 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00720192 (* 1 = 0.00720192 loss)
I0529 12:47:22.697239 10644 sgd_solver.cpp:106] Iteration 29080, lr = 0.0002
I0529 12:48:11.233189 10644 solver.cpp:228] Iteration 29100, loss = 0.153852
I0529 12:48:11.233217 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:48:11.233224 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147198 (* 1 = 0.0147198 loss)
I0529 12:48:11.233228 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0360467 (* 1 = 0.0360467 loss)
I0529 12:48:11.233232 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00306444 (* 1 = 0.00306444 loss)
I0529 12:48:11.233235 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121056 (* 1 = 0.0121056 loss)
I0529 12:48:11.233242 10644 sgd_solver.cpp:106] Iteration 29100, lr = 0.0002
I0529 12:48:59.774138 10644 solver.cpp:228] Iteration 29120, loss = 0.606318
I0529 12:48:59.774164 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 12:48:59.774173 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.111913 (* 1 = 0.111913 loss)
I0529 12:48:59.774179 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.243646 (* 1 = 0.243646 loss)
I0529 12:48:59.774184 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254417 (* 1 = 0.0254417 loss)
I0529 12:48:59.774189 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0574348 (* 1 = 0.0574348 loss)
I0529 12:48:59.774196 10644 sgd_solver.cpp:106] Iteration 29120, lr = 0.0002
I0529 12:49:48.321686 10644 solver.cpp:228] Iteration 29140, loss = 0.203558
I0529 12:49:48.321713 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 12:49:48.321722 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.094203 (* 1 = 0.094203 loss)
I0529 12:49:48.321728 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.118576 (* 1 = 0.118576 loss)
I0529 12:49:48.321733 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113983 (* 1 = 0.00113983 loss)
I0529 12:49:48.321739 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188977 (* 1 = 0.0188977 loss)
I0529 12:49:48.321744 10644 sgd_solver.cpp:106] Iteration 29140, lr = 0.0002
I0529 12:50:36.892125 10644 solver.cpp:228] Iteration 29160, loss = 0.296693
I0529 12:50:36.892149 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 12:50:36.892158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0797873 (* 1 = 0.0797873 loss)
I0529 12:50:36.892161 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110225 (* 1 = 0.110225 loss)
I0529 12:50:36.892165 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00383473 (* 1 = 0.00383473 loss)
I0529 12:50:36.892168 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114424 (* 1 = 0.0114424 loss)
I0529 12:50:36.892174 10644 sgd_solver.cpp:106] Iteration 29160, lr = 0.0002
I0529 12:51:25.436981 10644 solver.cpp:228] Iteration 29180, loss = 0.324992
I0529 12:51:25.437011 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 12:51:25.437017 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0493835 (* 1 = 0.0493835 loss)
I0529 12:51:25.437021 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.144398 (* 1 = 0.144398 loss)
I0529 12:51:25.437024 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000532646 (* 1 = 0.000532646 loss)
I0529 12:51:25.437028 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00818428 (* 1 = 0.00818428 loss)
I0529 12:51:25.437032 10644 sgd_solver.cpp:106] Iteration 29180, lr = 0.0002
speed: 2.428s / iter
I0529 12:52:14.003108 10644 solver.cpp:228] Iteration 29200, loss = 0.291293
I0529 12:52:14.003132 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 12:52:14.003139 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135528 (* 1 = 0.0135528 loss)
I0529 12:52:14.003144 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0673635 (* 1 = 0.0673635 loss)
I0529 12:52:14.003147 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00197506 (* 1 = 0.00197506 loss)
I0529 12:52:14.003150 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00561089 (* 1 = 0.00561089 loss)
I0529 12:52:14.003155 10644 sgd_solver.cpp:106] Iteration 29200, lr = 0.0002
I0529 12:53:02.565819 10644 solver.cpp:228] Iteration 29220, loss = 0.304771
I0529 12:53:02.565846 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 12:53:02.565853 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185071 (* 1 = 0.0185071 loss)
I0529 12:53:02.565857 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0345135 (* 1 = 0.0345135 loss)
I0529 12:53:02.565861 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00493358 (* 1 = 0.00493358 loss)
I0529 12:53:02.565865 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00714488 (* 1 = 0.00714488 loss)
I0529 12:53:02.565870 10644 sgd_solver.cpp:106] Iteration 29220, lr = 0.0002
I0529 12:53:51.125361 10644 solver.cpp:228] Iteration 29240, loss = 0.262745
I0529 12:53:51.125391 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 12:53:51.125401 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0871543 (* 1 = 0.0871543 loss)
I0529 12:53:51.125404 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114952 (* 1 = 0.114952 loss)
I0529 12:53:51.125407 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188553 (* 1 = 0.0188553 loss)
I0529 12:53:51.125411 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321789 (* 1 = 0.0321789 loss)
I0529 12:53:51.125417 10644 sgd_solver.cpp:106] Iteration 29240, lr = 0.0002
I0529 12:54:39.685322 10644 solver.cpp:228] Iteration 29260, loss = 0.221477
I0529 12:54:39.685348 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 12:54:39.685359 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476485 (* 1 = 0.0476485 loss)
I0529 12:54:39.685365 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0737364 (* 1 = 0.0737364 loss)
I0529 12:54:39.685370 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00209248 (* 1 = 0.00209248 loss)
I0529 12:54:39.685376 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207036 (* 1 = 0.0207036 loss)
I0529 12:54:39.685384 10644 sgd_solver.cpp:106] Iteration 29260, lr = 0.0002
I0529 12:55:28.227777 10644 solver.cpp:228] Iteration 29280, loss = 0.349594
I0529 12:55:28.227804 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 12:55:28.227813 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.1149 (* 1 = 0.1149 loss)
I0529 12:55:28.227818 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.202045 (* 1 = 0.202045 loss)
I0529 12:55:28.227821 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00589684 (* 1 = 0.00589684 loss)
I0529 12:55:28.227825 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104901 (* 1 = 0.0104901 loss)
I0529 12:55:28.227831 10644 sgd_solver.cpp:106] Iteration 29280, lr = 0.0002
I0529 12:56:16.769675 10644 solver.cpp:228] Iteration 29300, loss = 0.621346
I0529 12:56:16.769702 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0529 12:56:16.769709 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.825738 (* 1 = 0.825738 loss)
I0529 12:56:16.769713 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.641838 (* 1 = 0.641838 loss)
I0529 12:56:16.769717 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0821713 (* 1 = 0.0821713 loss)
I0529 12:56:16.769721 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.592055 (* 1 = 0.592055 loss)
I0529 12:56:16.769726 10644 sgd_solver.cpp:106] Iteration 29300, lr = 0.0002
I0529 12:57:05.315228 10644 solver.cpp:228] Iteration 29320, loss = 0.185098
I0529 12:57:05.315253 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 12:57:05.315261 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000816614 (* 1 = 0.000816614 loss)
I0529 12:57:05.315265 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0429093 (* 1 = 0.0429093 loss)
I0529 12:57:05.315269 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011763 (* 1 = 0.011763 loss)
I0529 12:57:05.315273 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210917 (* 1 = 0.0210917 loss)
I0529 12:57:05.315279 10644 sgd_solver.cpp:106] Iteration 29320, lr = 0.0002
I0529 12:57:53.864464 10644 solver.cpp:228] Iteration 29340, loss = 0.23646
I0529 12:57:53.864490 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 12:57:53.864497 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272537 (* 1 = 0.0272537 loss)
I0529 12:57:53.864502 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0881421 (* 1 = 0.0881421 loss)
I0529 12:57:53.864506 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361413 (* 1 = 0.00361413 loss)
I0529 12:57:53.864511 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186049 (* 1 = 0.0186049 loss)
I0529 12:57:53.864516 10644 sgd_solver.cpp:106] Iteration 29340, lr = 0.0002
I0529 12:58:42.426025 10644 solver.cpp:228] Iteration 29360, loss = 0.303107
I0529 12:58:42.426049 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 12:58:42.426057 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0769683 (* 1 = 0.0769683 loss)
I0529 12:58:42.426061 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.112367 (* 1 = 0.112367 loss)
I0529 12:58:42.426065 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00287799 (* 1 = 0.00287799 loss)
I0529 12:58:42.426069 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178006 (* 1 = 0.0178006 loss)
I0529 12:58:42.426074 10644 sgd_solver.cpp:106] Iteration 29360, lr = 0.0002
I0529 12:59:30.961822 10644 solver.cpp:228] Iteration 29380, loss = 0.379313
I0529 12:59:30.961850 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 12:59:30.961858 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791292 (* 1 = 0.0791292 loss)
I0529 12:59:30.961863 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.235995 (* 1 = 0.235995 loss)
I0529 12:59:30.961866 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00609354 (* 1 = 0.00609354 loss)
I0529 12:59:30.961870 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0617941 (* 1 = 0.0617941 loss)
I0529 12:59:30.961875 10644 sgd_solver.cpp:106] Iteration 29380, lr = 0.0002
speed: 2.428s / iter
I0529 13:00:19.511767 10644 solver.cpp:228] Iteration 29400, loss = 0.158809
I0529 13:00:19.511795 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:00:19.511802 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0210013 (* 1 = 0.0210013 loss)
I0529 13:00:19.511806 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0862433 (* 1 = 0.0862433 loss)
I0529 13:00:19.511811 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236785 (* 1 = 0.00236785 loss)
I0529 13:00:19.511816 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166691 (* 1 = 0.0166691 loss)
I0529 13:00:19.511821 10644 sgd_solver.cpp:106] Iteration 29400, lr = 0.0002
I0529 13:01:08.070319 10644 solver.cpp:228] Iteration 29420, loss = 0.367926
I0529 13:01:08.070344 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:01:08.070351 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100844 (* 1 = 0.100844 loss)
I0529 13:01:08.070355 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0959952 (* 1 = 0.0959952 loss)
I0529 13:01:08.070359 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191911 (* 1 = 0.0191911 loss)
I0529 13:01:08.070363 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311674 (* 1 = 0.0311674 loss)
I0529 13:01:08.070367 10644 sgd_solver.cpp:106] Iteration 29420, lr = 0.0002
I0529 13:01:56.596516 10644 solver.cpp:228] Iteration 29440, loss = 0.151831
I0529 13:01:56.596544 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:01:56.596550 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649823 (* 1 = 0.0649823 loss)
I0529 13:01:56.596554 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.12669 (* 1 = 0.12669 loss)
I0529 13:01:56.596559 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00430681 (* 1 = 0.00430681 loss)
I0529 13:01:56.596561 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195356 (* 1 = 0.0195356 loss)
I0529 13:01:56.596567 10644 sgd_solver.cpp:106] Iteration 29440, lr = 0.0002
I0529 13:02:45.132021 10644 solver.cpp:228] Iteration 29460, loss = 0.189276
I0529 13:02:45.132045 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:02:45.132052 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518391 (* 1 = 0.0518391 loss)
I0529 13:02:45.132057 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0525171 (* 1 = 0.0525171 loss)
I0529 13:02:45.132063 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00592425 (* 1 = 0.00592425 loss)
I0529 13:02:45.132068 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00647229 (* 1 = 0.00647229 loss)
I0529 13:02:45.132073 10644 sgd_solver.cpp:106] Iteration 29460, lr = 0.0002
I0529 13:03:33.667397 10644 solver.cpp:228] Iteration 29480, loss = 0.291107
I0529 13:03:33.667424 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:03:33.667434 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0520348 (* 1 = 0.0520348 loss)
I0529 13:03:33.667440 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0589045 (* 1 = 0.0589045 loss)
I0529 13:03:33.667445 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144856 (* 1 = 0.0144856 loss)
I0529 13:03:33.667450 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176237 (* 1 = 0.0176237 loss)
I0529 13:03:33.667457 10644 sgd_solver.cpp:106] Iteration 29480, lr = 0.0002
I0529 13:04:22.235576 10644 solver.cpp:228] Iteration 29500, loss = 0.385449
I0529 13:04:22.235605 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 13:04:22.235613 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.140795 (* 1 = 0.140795 loss)
I0529 13:04:22.235617 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.211295 (* 1 = 0.211295 loss)
I0529 13:04:22.235620 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131295 (* 1 = 0.0131295 loss)
I0529 13:04:22.235623 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172829 (* 1 = 0.0172829 loss)
I0529 13:04:22.235630 10644 sgd_solver.cpp:106] Iteration 29500, lr = 0.0002
I0529 13:05:10.731487 10644 solver.cpp:228] Iteration 29520, loss = 0.257325
I0529 13:05:10.731513 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 13:05:10.731519 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117105 (* 1 = 0.117105 loss)
I0529 13:05:10.731524 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0817208 (* 1 = 0.0817208 loss)
I0529 13:05:10.731529 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110926 (* 1 = 0.0110926 loss)
I0529 13:05:10.731535 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209847 (* 1 = 0.0209847 loss)
I0529 13:05:10.731540 10644 sgd_solver.cpp:106] Iteration 29520, lr = 0.0002
I0529 13:05:59.129884 10644 solver.cpp:228] Iteration 29540, loss = 0.298807
I0529 13:05:59.129907 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:05:59.129917 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189745 (* 1 = 0.0189745 loss)
I0529 13:05:59.129923 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.146693 (* 1 = 0.146693 loss)
I0529 13:05:59.129928 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128232 (* 1 = 0.0128232 loss)
I0529 13:05:59.129935 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00996649 (* 1 = 0.00996649 loss)
I0529 13:05:59.129940 10644 sgd_solver.cpp:106] Iteration 29540, lr = 0.0002
I0529 13:06:47.315244 10644 solver.cpp:228] Iteration 29560, loss = 0.206995
I0529 13:06:47.315266 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:06:47.315274 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0673336 (* 1 = 0.0673336 loss)
I0529 13:06:47.315276 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0924241 (* 1 = 0.0924241 loss)
I0529 13:06:47.315280 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00430731 (* 1 = 0.00430731 loss)
I0529 13:06:47.315284 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207888 (* 1 = 0.0207888 loss)
I0529 13:06:47.315289 10644 sgd_solver.cpp:106] Iteration 29560, lr = 0.0002
I0529 13:07:35.473678 10644 solver.cpp:228] Iteration 29580, loss = 0.226761
I0529 13:07:35.473701 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 13:07:35.473707 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.245867 (* 1 = 0.245867 loss)
I0529 13:07:35.473711 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.325948 (* 1 = 0.325948 loss)
I0529 13:07:35.473716 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00353462 (* 1 = 0.00353462 loss)
I0529 13:07:35.473718 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.09636 (* 1 = 0.09636 loss)
I0529 13:07:35.473723 10644 sgd_solver.cpp:106] Iteration 29580, lr = 0.0002
speed: 2.428s / iter
I0529 13:08:23.647126 10644 solver.cpp:228] Iteration 29600, loss = 0.364545
I0529 13:08:23.647148 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 13:08:23.647156 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0763329 (* 1 = 0.0763329 loss)
I0529 13:08:23.647159 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.324478 (* 1 = 0.324478 loss)
I0529 13:08:23.647162 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0351626 (* 1 = 0.0351626 loss)
I0529 13:08:23.647166 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116288 (* 1 = 0.116288 loss)
I0529 13:08:23.647171 10644 sgd_solver.cpp:106] Iteration 29600, lr = 0.0002
I0529 13:09:11.827530 10644 solver.cpp:228] Iteration 29620, loss = 0.272569
I0529 13:09:11.827553 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:09:11.827560 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.103884 (* 1 = 0.103884 loss)
I0529 13:09:11.827564 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0570483 (* 1 = 0.0570483 loss)
I0529 13:09:11.827569 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00163985 (* 1 = 0.00163985 loss)
I0529 13:09:11.827572 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285916 (* 1 = 0.0285916 loss)
I0529 13:09:11.827576 10644 sgd_solver.cpp:106] Iteration 29620, lr = 0.0002
I0529 13:09:59.993065 10644 solver.cpp:228] Iteration 29640, loss = 0.327198
I0529 13:09:59.993088 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 13:09:59.993094 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.122033 (* 1 = 0.122033 loss)
I0529 13:09:59.993098 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.289874 (* 1 = 0.289874 loss)
I0529 13:09:59.993101 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0390194 (* 1 = 0.0390194 loss)
I0529 13:09:59.993104 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.095443 (* 1 = 0.095443 loss)
I0529 13:09:59.993109 10644 sgd_solver.cpp:106] Iteration 29640, lr = 0.0002
I0529 13:10:48.165307 10644 solver.cpp:228] Iteration 29660, loss = 0.279434
I0529 13:10:48.165328 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 13:10:48.165335 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0939997 (* 1 = 0.0939997 loss)
I0529 13:10:48.165339 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.170813 (* 1 = 0.170813 loss)
I0529 13:10:48.165343 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0264777 (* 1 = 0.0264777 loss)
I0529 13:10:48.165345 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0365945 (* 1 = 0.0365945 loss)
I0529 13:10:48.165350 10644 sgd_solver.cpp:106] Iteration 29660, lr = 0.0002
I0529 13:11:36.318699 10644 solver.cpp:228] Iteration 29680, loss = 0.162114
I0529 13:11:36.318722 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:11:36.318728 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00861083 (* 1 = 0.00861083 loss)
I0529 13:11:36.318732 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0403935 (* 1 = 0.0403935 loss)
I0529 13:11:36.318737 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00638917 (* 1 = 0.00638917 loss)
I0529 13:11:36.318739 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00980014 (* 1 = 0.00980014 loss)
I0529 13:11:36.318743 10644 sgd_solver.cpp:106] Iteration 29680, lr = 0.0002
I0529 13:12:24.471133 10644 solver.cpp:228] Iteration 29700, loss = 0.414636
I0529 13:12:24.471153 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:12:24.471174 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574343 (* 1 = 0.0574343 loss)
I0529 13:12:24.471179 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0608141 (* 1 = 0.0608141 loss)
I0529 13:12:24.471181 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00775973 (* 1 = 0.00775973 loss)
I0529 13:12:24.471184 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219455 (* 1 = 0.0219455 loss)
I0529 13:12:24.471190 10644 sgd_solver.cpp:106] Iteration 29700, lr = 0.0002
I0529 13:13:12.626600 10644 solver.cpp:228] Iteration 29720, loss = 0.370678
I0529 13:13:12.626634 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:13:12.626641 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0516465 (* 1 = 0.0516465 loss)
I0529 13:13:12.626644 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.191136 (* 1 = 0.191136 loss)
I0529 13:13:12.626648 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156546 (* 1 = 0.0156546 loss)
I0529 13:13:12.626652 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194422 (* 1 = 0.0194422 loss)
I0529 13:13:12.626655 10644 sgd_solver.cpp:106] Iteration 29720, lr = 0.0002
I0529 13:14:00.792222 10644 solver.cpp:228] Iteration 29740, loss = 0.21742
I0529 13:14:00.792243 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:14:00.792249 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454967 (* 1 = 0.0454967 loss)
I0529 13:14:00.792253 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0546802 (* 1 = 0.0546802 loss)
I0529 13:14:00.792256 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109689 (* 1 = 0.00109689 loss)
I0529 13:14:00.792260 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00851312 (* 1 = 0.00851312 loss)
I0529 13:14:00.792264 10644 sgd_solver.cpp:106] Iteration 29740, lr = 0.0002
I0529 13:14:48.949749 10644 solver.cpp:228] Iteration 29760, loss = 0.353558
I0529 13:14:48.949771 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 13:14:48.949779 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.165867 (* 1 = 0.165867 loss)
I0529 13:14:48.949782 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.41052 (* 1 = 0.41052 loss)
I0529 13:14:48.949785 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300011 (* 1 = 0.00300011 loss)
I0529 13:14:48.949790 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327086 (* 1 = 0.0327086 loss)
I0529 13:14:48.949793 10644 sgd_solver.cpp:106] Iteration 29760, lr = 0.0002
I0529 13:15:37.131175 10644 solver.cpp:228] Iteration 29780, loss = 0.32614
I0529 13:15:37.131197 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:15:37.131204 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0184317 (* 1 = 0.0184317 loss)
I0529 13:15:37.131208 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0580938 (* 1 = 0.0580938 loss)
I0529 13:15:37.131211 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143069 (* 1 = 0.0143069 loss)
I0529 13:15:37.131216 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159059 (* 1 = 0.0159059 loss)
I0529 13:15:37.131219 10644 sgd_solver.cpp:106] Iteration 29780, lr = 0.0002
speed: 2.428s / iter
I0529 13:16:25.296759 10644 solver.cpp:228] Iteration 29800, loss = 0.131225
I0529 13:16:25.296782 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:16:25.296788 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185648 (* 1 = 0.0185648 loss)
I0529 13:16:25.296792 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0624562 (* 1 = 0.0624562 loss)
I0529 13:16:25.296795 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0209318 (* 1 = 0.0209318 loss)
I0529 13:16:25.296798 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340555 (* 1 = 0.0340555 loss)
I0529 13:16:25.296803 10644 sgd_solver.cpp:106] Iteration 29800, lr = 0.0002
I0529 13:17:13.650640 10644 solver.cpp:228] Iteration 29820, loss = 0.179991
I0529 13:17:13.650663 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:17:13.650671 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855208 (* 1 = 0.0855208 loss)
I0529 13:17:13.650674 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.158434 (* 1 = 0.158434 loss)
I0529 13:17:13.650677 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00668147 (* 1 = 0.00668147 loss)
I0529 13:17:13.650681 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0417621 (* 1 = 0.0417621 loss)
I0529 13:17:13.650686 10644 sgd_solver.cpp:106] Iteration 29820, lr = 0.0002
I0529 13:18:02.056159 10644 solver.cpp:228] Iteration 29840, loss = 0.310635
I0529 13:18:02.056181 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:18:02.056188 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.117509 (* 1 = 0.117509 loss)
I0529 13:18:02.056192 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120579 (* 1 = 0.120579 loss)
I0529 13:18:02.056195 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00428475 (* 1 = 0.00428475 loss)
I0529 13:18:02.056200 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0083977 (* 1 = 0.0083977 loss)
I0529 13:18:02.056203 10644 sgd_solver.cpp:106] Iteration 29840, lr = 0.0002
I0529 13:18:50.459441 10644 solver.cpp:228] Iteration 29860, loss = 0.427014
I0529 13:18:50.459465 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 13:18:50.459471 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.371041 (* 1 = 0.371041 loss)
I0529 13:18:50.459475 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.312244 (* 1 = 0.312244 loss)
I0529 13:18:50.459480 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00621852 (* 1 = 0.00621852 loss)
I0529 13:18:50.459483 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0727754 (* 1 = 0.0727754 loss)
I0529 13:18:50.459487 10644 sgd_solver.cpp:106] Iteration 29860, lr = 0.0002
I0529 13:19:38.720136 10644 solver.cpp:228] Iteration 29880, loss = 0.349219
I0529 13:19:38.720160 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:19:38.720167 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0631447 (* 1 = 0.0631447 loss)
I0529 13:19:38.720171 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.110237 (* 1 = 0.110237 loss)
I0529 13:19:38.720175 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00313838 (* 1 = 0.00313838 loss)
I0529 13:19:38.720178 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00710904 (* 1 = 0.00710904 loss)
I0529 13:19:38.720183 10644 sgd_solver.cpp:106] Iteration 29880, lr = 0.0002
I0529 13:20:26.960842 10644 solver.cpp:228] Iteration 29900, loss = 0.254504
I0529 13:20:26.960865 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 13:20:26.960872 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201758 (* 1 = 0.0201758 loss)
I0529 13:20:26.960891 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.276523 (* 1 = 0.276523 loss)
I0529 13:20:26.960896 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00209094 (* 1 = 0.00209094 loss)
I0529 13:20:26.960901 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100372 (* 1 = 0.0100372 loss)
I0529 13:20:26.960907 10644 sgd_solver.cpp:106] Iteration 29900, lr = 0.0002
I0529 13:21:15.416040 10644 solver.cpp:228] Iteration 29920, loss = 0.258595
I0529 13:21:15.416075 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 13:21:15.416081 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.100959 (* 1 = 0.100959 loss)
I0529 13:21:15.416085 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.131463 (* 1 = 0.131463 loss)
I0529 13:21:15.416088 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301513 (* 1 = 0.00301513 loss)
I0529 13:21:15.416091 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124936 (* 1 = 0.0124936 loss)
I0529 13:21:15.416095 10644 sgd_solver.cpp:106] Iteration 29920, lr = 0.0002
I0529 13:22:03.977540 10644 solver.cpp:228] Iteration 29940, loss = 0.24123
I0529 13:22:03.977576 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 13:22:03.977582 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.130059 (* 1 = 0.130059 loss)
I0529 13:22:03.977586 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.212467 (* 1 = 0.212467 loss)
I0529 13:22:03.977588 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0473504 (* 1 = 0.0473504 loss)
I0529 13:22:03.977591 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390385 (* 1 = 0.0390385 loss)
I0529 13:22:03.977596 10644 sgd_solver.cpp:106] Iteration 29940, lr = 0.0002
I0529 13:22:52.540479 10644 solver.cpp:228] Iteration 29960, loss = 0.239092
I0529 13:22:52.540514 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:22:52.540521 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.027702 (* 1 = 0.027702 loss)
I0529 13:22:52.540525 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0796712 (* 1 = 0.0796712 loss)
I0529 13:22:52.540529 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0054441 (* 1 = 0.0054441 loss)
I0529 13:22:52.540531 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00483446 (* 1 = 0.00483446 loss)
I0529 13:22:52.540535 10644 sgd_solver.cpp:106] Iteration 29960, lr = 0.0002
I0529 13:23:41.006702 10644 solver.cpp:228] Iteration 29980, loss = 0.423782
I0529 13:23:41.006724 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 13:23:41.006731 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.169717 (* 1 = 0.169717 loss)
I0529 13:23:41.006736 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.263192 (* 1 = 0.263192 loss)
I0529 13:23:41.006739 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140013 (* 1 = 0.0140013 loss)
I0529 13:23:41.006742 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438034 (* 1 = 0.0438034 loss)
I0529 13:23:41.006747 10644 sgd_solver.cpp:106] Iteration 29980, lr = 0.0002
speed: 2.428s / iter
I0529 13:24:27.142913 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_30000.caffemodel
I0529 13:24:30.120555 10644 solver.cpp:228] Iteration 30000, loss = 0.234786
I0529 13:24:30.120579 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 13:24:30.120586 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0025705 (* 1 = 0.0025705 loss)
I0529 13:24:30.120590 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0154257 (* 1 = 0.0154257 loss)
I0529 13:24:30.120592 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.022206 (* 1 = 0.022206 loss)
I0529 13:24:30.120595 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199964 (* 1 = 0.0199964 loss)
I0529 13:24:30.120599 10644 sgd_solver.cpp:106] Iteration 30000, lr = 0.0002
I0529 13:25:18.678040 10644 solver.cpp:228] Iteration 30020, loss = 0.140915
I0529 13:25:18.678076 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 13:25:18.678081 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0426263 (* 1 = 0.0426263 loss)
I0529 13:25:18.678084 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0750218 (* 1 = 0.0750218 loss)
I0529 13:25:18.678088 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119797 (* 1 = 0.00119797 loss)
I0529 13:25:18.678092 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00393924 (* 1 = 0.00393924 loss)
I0529 13:25:18.678097 10644 sgd_solver.cpp:106] Iteration 30020, lr = 0.0002
I0529 13:26:07.088995 10644 solver.cpp:228] Iteration 30040, loss = 0.505999
I0529 13:26:07.089020 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:26:07.089026 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537381 (* 1 = 0.0537381 loss)
I0529 13:26:07.089030 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0518487 (* 1 = 0.0518487 loss)
I0529 13:26:07.089033 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0044909 (* 1 = 0.0044909 loss)
I0529 13:26:07.089036 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00531467 (* 1 = 0.00531467 loss)
I0529 13:26:07.089041 10644 sgd_solver.cpp:106] Iteration 30040, lr = 0.0002
I0529 13:26:55.479246 10644 solver.cpp:228] Iteration 30060, loss = 0.155723
I0529 13:26:55.479280 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:26:55.479286 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155164 (* 1 = 0.0155164 loss)
I0529 13:26:55.479290 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0315785 (* 1 = 0.0315785 loss)
I0529 13:26:55.479293 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130892 (* 1 = 0.0130892 loss)
I0529 13:26:55.479296 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123667 (* 1 = 0.0123667 loss)
I0529 13:26:55.479300 10644 sgd_solver.cpp:106] Iteration 30060, lr = 0.0002
I0529 13:27:44.032501 10644 solver.cpp:228] Iteration 30080, loss = 0.157522
I0529 13:27:44.032522 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:27:44.032543 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150245 (* 1 = 0.0150245 loss)
I0529 13:27:44.032547 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0588816 (* 1 = 0.0588816 loss)
I0529 13:27:44.032550 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674949 (* 1 = 0.00674949 loss)
I0529 13:27:44.032553 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00980642 (* 1 = 0.00980642 loss)
I0529 13:27:44.032557 10644 sgd_solver.cpp:106] Iteration 30080, lr = 0.0002
I0529 13:28:32.514569 10644 solver.cpp:228] Iteration 30100, loss = 0.272765
I0529 13:28:32.514590 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:28:32.514598 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183966 (* 1 = 0.0183966 loss)
I0529 13:28:32.514617 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0548747 (* 1 = 0.0548747 loss)
I0529 13:28:32.514622 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00223613 (* 1 = 0.00223613 loss)
I0529 13:28:32.514627 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0058325 (* 1 = 0.0058325 loss)
I0529 13:28:32.514633 10644 sgd_solver.cpp:106] Iteration 30100, lr = 0.0002
I0529 13:29:20.911561 10644 solver.cpp:228] Iteration 30120, loss = 0.463169
I0529 13:29:20.911583 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 13:29:20.911592 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.173833 (* 1 = 0.173833 loss)
I0529 13:29:20.911610 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.235637 (* 1 = 0.235637 loss)
I0529 13:29:20.911615 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127197 (* 1 = 0.0127197 loss)
I0529 13:29:20.911622 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308482 (* 1 = 0.0308482 loss)
I0529 13:29:20.911628 10644 sgd_solver.cpp:106] Iteration 30120, lr = 0.0002
I0529 13:30:09.353821 10644 solver.cpp:228] Iteration 30140, loss = 0.242463
I0529 13:30:09.353857 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 13:30:09.353863 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.158258 (* 1 = 0.158258 loss)
I0529 13:30:09.353866 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.209223 (* 1 = 0.209223 loss)
I0529 13:30:09.353869 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102617 (* 1 = 0.0102617 loss)
I0529 13:30:09.353873 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258099 (* 1 = 0.0258099 loss)
I0529 13:30:09.353878 10644 sgd_solver.cpp:106] Iteration 30140, lr = 0.0002
I0529 13:30:57.748628 10644 solver.cpp:228] Iteration 30160, loss = 0.368314
I0529 13:30:57.748651 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0529 13:30:57.748657 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.179309 (* 1 = 0.179309 loss)
I0529 13:30:57.748661 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.360739 (* 1 = 0.360739 loss)
I0529 13:30:57.748664 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102833 (* 1 = 0.0102833 loss)
I0529 13:30:57.748667 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0475986 (* 1 = 0.0475986 loss)
I0529 13:30:57.748672 10644 sgd_solver.cpp:106] Iteration 30160, lr = 0.0002
I0529 13:31:46.129662 10644 solver.cpp:228] Iteration 30180, loss = 0.146713
I0529 13:31:46.129685 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 13:31:46.129693 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541965 (* 1 = 0.0541965 loss)
I0529 13:31:46.129696 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0771283 (* 1 = 0.0771283 loss)
I0529 13:31:46.129699 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00476928 (* 1 = 0.00476928 loss)
I0529 13:31:46.129703 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171908 (* 1 = 0.0171908 loss)
I0529 13:31:46.129707 10644 sgd_solver.cpp:106] Iteration 30180, lr = 0.0002
speed: 2.428s / iter
I0529 13:32:34.402230 10644 solver.cpp:228] Iteration 30200, loss = 0.354485
I0529 13:32:34.402266 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 13:32:34.402272 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0967715 (* 1 = 0.0967715 loss)
I0529 13:32:34.402276 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.224799 (* 1 = 0.224799 loss)
I0529 13:32:34.402278 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231179 (* 1 = 0.0231179 loss)
I0529 13:32:34.402281 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0726471 (* 1 = 0.0726471 loss)
I0529 13:32:34.402285 10644 sgd_solver.cpp:106] Iteration 30200, lr = 0.0002
I0529 13:33:22.613453 10644 solver.cpp:228] Iteration 30220, loss = 0.275166
I0529 13:33:22.613489 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 13:33:22.613497 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0424803 (* 1 = 0.0424803 loss)
I0529 13:33:22.613499 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.114173 (* 1 = 0.114173 loss)
I0529 13:33:22.613502 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.028632 (* 1 = 0.028632 loss)
I0529 13:33:22.613505 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262726 (* 1 = 0.0262726 loss)
I0529 13:33:22.613510 10644 sgd_solver.cpp:106] Iteration 30220, lr = 0.0002
I0529 13:34:10.828780 10644 solver.cpp:228] Iteration 30240, loss = 0.284147
I0529 13:34:10.828804 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:34:10.828809 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356873 (* 1 = 0.0356873 loss)
I0529 13:34:10.828812 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0687944 (* 1 = 0.0687944 loss)
I0529 13:34:10.828816 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00263835 (* 1 = 0.00263835 loss)
I0529 13:34:10.828819 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159241 (* 1 = 0.0159241 loss)
I0529 13:34:10.828824 10644 sgd_solver.cpp:106] Iteration 30240, lr = 0.0002
I0529 13:34:59.044620 10644 solver.cpp:228] Iteration 30260, loss = 0.188815
I0529 13:34:59.044654 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:34:59.044661 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.031969 (* 1 = 0.031969 loss)
I0529 13:34:59.044664 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0780176 (* 1 = 0.0780176 loss)
I0529 13:34:59.044667 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149136 (* 1 = 0.00149136 loss)
I0529 13:34:59.044670 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00676433 (* 1 = 0.00676433 loss)
I0529 13:34:59.044674 10644 sgd_solver.cpp:106] Iteration 30260, lr = 0.0002
I0529 13:35:47.268643 10644 solver.cpp:228] Iteration 30280, loss = 0.143606
I0529 13:35:47.268681 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:35:47.268687 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0488131 (* 1 = 0.0488131 loss)
I0529 13:35:47.268690 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.080093 (* 1 = 0.080093 loss)
I0529 13:35:47.268693 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193904 (* 1 = 0.00193904 loss)
I0529 13:35:47.268697 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00267497 (* 1 = 0.00267497 loss)
I0529 13:35:47.268702 10644 sgd_solver.cpp:106] Iteration 30280, lr = 0.0002
I0529 13:36:35.489239 10644 solver.cpp:228] Iteration 30300, loss = 0.19614
I0529 13:36:35.489262 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 13:36:35.489269 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0439118 (* 1 = 0.0439118 loss)
I0529 13:36:35.489274 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0602632 (* 1 = 0.0602632 loss)
I0529 13:36:35.489276 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00943216 (* 1 = 0.00943216 loss)
I0529 13:36:35.489280 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119703 (* 1 = 0.0119703 loss)
I0529 13:36:35.489285 10644 sgd_solver.cpp:106] Iteration 30300, lr = 0.0002
I0529 13:37:23.708541 10644 solver.cpp:228] Iteration 30320, loss = 0.248816
I0529 13:37:23.708564 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 13:37:23.708570 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.262852 (* 1 = 0.262852 loss)
I0529 13:37:23.708575 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.471716 (* 1 = 0.471716 loss)
I0529 13:37:23.708578 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212873 (* 1 = 0.0212873 loss)
I0529 13:37:23.708581 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0560131 (* 1 = 0.0560131 loss)
I0529 13:37:23.708585 10644 sgd_solver.cpp:106] Iteration 30320, lr = 0.0002
I0529 13:38:11.938908 10644 solver.cpp:228] Iteration 30340, loss = 0.316126
I0529 13:38:11.938931 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 13:38:11.938937 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.081688 (* 1 = 0.081688 loss)
I0529 13:38:11.938941 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0992131 (* 1 = 0.0992131 loss)
I0529 13:38:11.938946 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00490924 (* 1 = 0.00490924 loss)
I0529 13:38:11.938948 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283527 (* 1 = 0.0283527 loss)
I0529 13:38:11.938952 10644 sgd_solver.cpp:106] Iteration 30340, lr = 0.0002
I0529 13:39:00.167923 10644 solver.cpp:228] Iteration 30360, loss = 0.262528
I0529 13:39:00.167946 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 13:39:00.167953 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.105072 (* 1 = 0.105072 loss)
I0529 13:39:00.167956 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157049 (* 1 = 0.157049 loss)
I0529 13:39:00.167960 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648618 (* 1 = 0.00648618 loss)
I0529 13:39:00.167963 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031909 (* 1 = 0.031909 loss)
I0529 13:39:00.167968 10644 sgd_solver.cpp:106] Iteration 30360, lr = 0.0002
I0529 13:39:48.380125 10644 solver.cpp:228] Iteration 30380, loss = 0.280627
I0529 13:39:48.380161 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 13:39:48.380168 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576887 (* 1 = 0.0576887 loss)
I0529 13:39:48.380172 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.188805 (* 1 = 0.188805 loss)
I0529 13:39:48.380174 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00381242 (* 1 = 0.00381242 loss)
I0529 13:39:48.380177 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177328 (* 1 = 0.0177328 loss)
I0529 13:39:48.380182 10644 sgd_solver.cpp:106] Iteration 30380, lr = 0.0002
speed: 2.428s / iter
I0529 13:40:36.608431 10644 solver.cpp:228] Iteration 30400, loss = 0.556736
I0529 13:40:36.608467 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 13:40:36.608474 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.122419 (* 1 = 0.122419 loss)
I0529 13:40:36.608479 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.150608 (* 1 = 0.150608 loss)
I0529 13:40:36.608481 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.029025 (* 1 = 0.029025 loss)
I0529 13:40:36.608484 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291744 (* 1 = 0.0291744 loss)
I0529 13:40:36.608489 10644 sgd_solver.cpp:106] Iteration 30400, lr = 0.0002
I0529 13:41:24.848625 10644 solver.cpp:228] Iteration 30420, loss = 0.281326
I0529 13:41:24.848646 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 13:41:24.848652 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147859 (* 1 = 0.0147859 loss)
I0529 13:41:24.848656 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0602895 (* 1 = 0.0602895 loss)
I0529 13:41:24.848659 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100482 (* 1 = 0.0100482 loss)
I0529 13:41:24.848662 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00255908 (* 1 = 0.00255908 loss)
I0529 13:41:24.848667 10644 sgd_solver.cpp:106] Iteration 30420, lr = 0.0002
I0529 13:42:13.056141 10644 solver.cpp:228] Iteration 30440, loss = 0.275864
I0529 13:42:13.056176 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:42:13.056183 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0382394 (* 1 = 0.0382394 loss)
I0529 13:42:13.056186 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.131772 (* 1 = 0.131772 loss)
I0529 13:42:13.056190 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00322152 (* 1 = 0.00322152 loss)
I0529 13:42:13.056193 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0053268 (* 1 = 0.0053268 loss)
I0529 13:42:13.056197 10644 sgd_solver.cpp:106] Iteration 30440, lr = 0.0002
I0529 13:43:01.222213 10644 solver.cpp:228] Iteration 30460, loss = 0.33311
I0529 13:43:01.222247 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:43:01.222254 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203949 (* 1 = 0.0203949 loss)
I0529 13:43:01.222259 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0540327 (* 1 = 0.0540327 loss)
I0529 13:43:01.222261 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00783981 (* 1 = 0.00783981 loss)
I0529 13:43:01.222265 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143394 (* 1 = 0.0143394 loss)
I0529 13:43:01.222270 10644 sgd_solver.cpp:106] Iteration 30460, lr = 0.0002
I0529 13:43:49.354905 10644 solver.cpp:228] Iteration 30480, loss = 0.207265
I0529 13:43:49.354940 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:43:49.354948 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0357472 (* 1 = 0.0357472 loss)
I0529 13:43:49.354951 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0660941 (* 1 = 0.0660941 loss)
I0529 13:43:49.354954 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00471938 (* 1 = 0.00471938 loss)
I0529 13:43:49.354957 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00798442 (* 1 = 0.00798442 loss)
I0529 13:43:49.354961 10644 sgd_solver.cpp:106] Iteration 30480, lr = 0.0002
I0529 13:44:37.492964 10644 solver.cpp:228] Iteration 30500, loss = 0.320314
I0529 13:44:37.493000 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 13:44:37.493005 10644 solver.cpp:244]     Train net output #1: loss_bbox = 5.59519e-05 (* 1 = 5.59519e-05 loss)
I0529 13:44:37.493010 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.035523 (* 1 = 0.035523 loss)
I0529 13:44:37.493012 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128233 (* 1 = 0.0128233 loss)
I0529 13:44:37.493016 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0477768 (* 1 = 0.0477768 loss)
I0529 13:44:37.493019 10644 sgd_solver.cpp:106] Iteration 30500, lr = 0.0002
I0529 13:45:25.630548 10644 solver.cpp:228] Iteration 30520, loss = 0.268692
I0529 13:45:25.630584 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 13:45:25.630590 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0812861 (* 1 = 0.0812861 loss)
I0529 13:45:25.630594 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.130711 (* 1 = 0.130711 loss)
I0529 13:45:25.630597 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0006485 (* 1 = 0.0006485 loss)
I0529 13:45:25.630600 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236661 (* 1 = 0.0236661 loss)
I0529 13:45:25.630604 10644 sgd_solver.cpp:106] Iteration 30520, lr = 0.0002
I0529 13:46:13.774801 10644 solver.cpp:228] Iteration 30540, loss = 0.164921
I0529 13:46:13.774822 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 13:46:13.774829 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.050701 (* 1 = 0.050701 loss)
I0529 13:46:13.774833 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0947362 (* 1 = 0.0947362 loss)
I0529 13:46:13.774837 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221173 (* 1 = 0.0221173 loss)
I0529 13:46:13.774839 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106111 (* 1 = 0.0106111 loss)
I0529 13:46:13.774844 10644 sgd_solver.cpp:106] Iteration 30540, lr = 0.0002
I0529 13:47:01.915024 10644 solver.cpp:228] Iteration 30560, loss = 0.460636
I0529 13:47:01.915046 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 13:47:01.915053 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.035456 (* 1 = 0.035456 loss)
I0529 13:47:01.915057 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0812599 (* 1 = 0.0812599 loss)
I0529 13:47:01.915061 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00625157 (* 1 = 0.00625157 loss)
I0529 13:47:01.915064 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138344 (* 1 = 0.0138344 loss)
I0529 13:47:01.915068 10644 sgd_solver.cpp:106] Iteration 30560, lr = 0.0002
I0529 13:47:50.053175 10644 solver.cpp:228] Iteration 30580, loss = 0.266415
I0529 13:47:50.053211 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:47:50.053217 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.060305 (* 1 = 0.060305 loss)
I0529 13:47:50.053221 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0963449 (* 1 = 0.0963449 loss)
I0529 13:47:50.053225 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00243404 (* 1 = 0.00243404 loss)
I0529 13:47:50.053227 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108812 (* 1 = 0.0108812 loss)
I0529 13:47:50.053231 10644 sgd_solver.cpp:106] Iteration 30580, lr = 0.0002
speed: 2.428s / iter
I0529 13:48:38.215813 10644 solver.cpp:228] Iteration 30600, loss = 0.25091
I0529 13:48:38.215849 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:48:38.215855 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.031756 (* 1 = 0.031756 loss)
I0529 13:48:38.215859 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.104507 (* 1 = 0.104507 loss)
I0529 13:48:38.215862 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000561886 (* 1 = 0.000561886 loss)
I0529 13:48:38.215867 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265056 (* 1 = 0.0265056 loss)
I0529 13:48:38.215870 10644 sgd_solver.cpp:106] Iteration 30600, lr = 0.0002
I0529 13:49:26.387536 10644 solver.cpp:228] Iteration 30620, loss = 0.264687
I0529 13:49:26.387557 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:49:26.387578 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.075066 (* 1 = 0.075066 loss)
I0529 13:49:26.387581 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.164223 (* 1 = 0.164223 loss)
I0529 13:49:26.387584 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00518385 (* 1 = 0.00518385 loss)
I0529 13:49:26.387588 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336132 (* 1 = 0.0336132 loss)
I0529 13:49:26.387591 10644 sgd_solver.cpp:106] Iteration 30620, lr = 0.0002
I0529 13:50:14.549933 10644 solver.cpp:228] Iteration 30640, loss = 0.299123
I0529 13:50:14.549968 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 13:50:14.549974 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391612 (* 1 = 0.0391612 loss)
I0529 13:50:14.549978 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0742289 (* 1 = 0.0742289 loss)
I0529 13:50:14.549981 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000691279 (* 1 = 0.000691279 loss)
I0529 13:50:14.549984 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00969349 (* 1 = 0.00969349 loss)
I0529 13:50:14.549989 10644 sgd_solver.cpp:106] Iteration 30640, lr = 0.0002
I0529 13:51:02.701231 10644 solver.cpp:228] Iteration 30660, loss = 0.365133
I0529 13:51:02.701267 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0529 13:51:02.701274 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.411724 (* 1 = 0.411724 loss)
I0529 13:51:02.701277 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.537566 (* 1 = 0.537566 loss)
I0529 13:51:02.701280 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0635493 (* 1 = 0.0635493 loss)
I0529 13:51:02.701283 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.15566 (* 1 = 0.15566 loss)
I0529 13:51:02.701288 10644 sgd_solver.cpp:106] Iteration 30660, lr = 0.0002
I0529 13:51:50.870934 10644 solver.cpp:228] Iteration 30680, loss = 0.470216
I0529 13:51:50.870970 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 13:51:50.870976 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0637888 (* 1 = 0.0637888 loss)
I0529 13:51:50.870980 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.130186 (* 1 = 0.130186 loss)
I0529 13:51:50.870983 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02652 (* 1 = 0.02652 loss)
I0529 13:51:50.870986 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431552 (* 1 = 0.0431552 loss)
I0529 13:51:50.870990 10644 sgd_solver.cpp:106] Iteration 30680, lr = 0.0002
I0529 13:52:39.039696 10644 solver.cpp:228] Iteration 30700, loss = 0.311334
I0529 13:52:39.039731 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 13:52:39.039738 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.139941 (* 1 = 0.139941 loss)
I0529 13:52:39.039742 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.229104 (* 1 = 0.229104 loss)
I0529 13:52:39.039746 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107395 (* 1 = 0.0107395 loss)
I0529 13:52:39.039748 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388139 (* 1 = 0.0388139 loss)
I0529 13:52:39.039752 10644 sgd_solver.cpp:106] Iteration 30700, lr = 0.0002
I0529 13:53:27.222314 10644 solver.cpp:228] Iteration 30720, loss = 0.28645
I0529 13:53:27.222337 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 13:53:27.222343 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474288 (* 1 = 0.0474288 loss)
I0529 13:53:27.222347 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.115059 (* 1 = 0.115059 loss)
I0529 13:53:27.222352 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00061679 (* 1 = 0.00061679 loss)
I0529 13:53:27.222354 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0089896 (* 1 = 0.0089896 loss)
I0529 13:53:27.222358 10644 sgd_solver.cpp:106] Iteration 30720, lr = 0.0002
I0529 13:54:15.404150 10644 solver.cpp:228] Iteration 30740, loss = 0.23537
I0529 13:54:15.404171 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 13:54:15.404178 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.271777 (* 1 = 0.271777 loss)
I0529 13:54:15.404198 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.311983 (* 1 = 0.311983 loss)
I0529 13:54:15.404203 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150335 (* 1 = 0.0150335 loss)
I0529 13:54:15.404208 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.144159 (* 1 = 0.144159 loss)
I0529 13:54:15.404213 10644 sgd_solver.cpp:106] Iteration 30740, lr = 0.0002
I0529 13:55:03.525918 10644 solver.cpp:228] Iteration 30760, loss = 0.331675
I0529 13:55:03.525940 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:55:03.525949 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0831836 (* 1 = 0.0831836 loss)
I0529 13:55:03.525969 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.168493 (* 1 = 0.168493 loss)
I0529 13:55:03.525972 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00877187 (* 1 = 0.00877187 loss)
I0529 13:55:03.525977 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0581608 (* 1 = 0.0581608 loss)
I0529 13:55:03.525984 10644 sgd_solver.cpp:106] Iteration 30760, lr = 0.0002
I0529 13:55:51.625828 10644 solver.cpp:228] Iteration 30780, loss = 0.245989
I0529 13:55:51.625850 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 13:55:51.625859 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0819203 (* 1 = 0.0819203 loss)
I0529 13:55:51.625864 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.136865 (* 1 = 0.136865 loss)
I0529 13:55:51.625869 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0099741 (* 1 = 0.0099741 loss)
I0529 13:55:51.625874 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223019 (* 1 = 0.0223019 loss)
I0529 13:55:51.625880 10644 sgd_solver.cpp:106] Iteration 30780, lr = 0.0002
speed: 2.428s / iter
I0529 13:56:39.737452 10644 solver.cpp:228] Iteration 30800, loss = 0.289967
I0529 13:56:39.737473 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 13:56:39.737481 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574334 (* 1 = 0.0574334 loss)
I0529 13:56:39.737501 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.154629 (* 1 = 0.154629 loss)
I0529 13:56:39.737505 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759844 (* 1 = 0.00759844 loss)
I0529 13:56:39.737510 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303778 (* 1 = 0.0303778 loss)
I0529 13:56:39.737516 10644 sgd_solver.cpp:106] Iteration 30800, lr = 0.0002
I0529 13:57:27.854086 10644 solver.cpp:228] Iteration 30820, loss = 0.301919
I0529 13:57:27.854107 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 13:57:27.854115 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518312 (* 1 = 0.0518312 loss)
I0529 13:57:27.854135 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0896555 (* 1 = 0.0896555 loss)
I0529 13:57:27.854140 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00703854 (* 1 = 0.00703854 loss)
I0529 13:57:27.854145 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246447 (* 1 = 0.0246447 loss)
I0529 13:57:27.854151 10644 sgd_solver.cpp:106] Iteration 30820, lr = 0.0002
I0529 13:58:15.979398 10644 solver.cpp:228] Iteration 30840, loss = 0.394952
I0529 13:58:15.979434 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 13:58:15.979441 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.364659 (* 1 = 0.364659 loss)
I0529 13:58:15.979444 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.37201 (* 1 = 0.37201 loss)
I0529 13:58:15.979449 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147134 (* 1 = 0.0147134 loss)
I0529 13:58:15.979451 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0793167 (* 1 = 0.0793167 loss)
I0529 13:58:15.979455 10644 sgd_solver.cpp:106] Iteration 30840, lr = 0.0002
I0529 13:59:04.145524 10644 solver.cpp:228] Iteration 30860, loss = 0.286179
I0529 13:59:04.145560 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 13:59:04.145570 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0903521 (* 1 = 0.0903521 loss)
I0529 13:59:04.145572 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.154474 (* 1 = 0.154474 loss)
I0529 13:59:04.145576 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286548 (* 1 = 0.00286548 loss)
I0529 13:59:04.145578 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178166 (* 1 = 0.0178166 loss)
I0529 13:59:04.145583 10644 sgd_solver.cpp:106] Iteration 30860, lr = 0.0002
I0529 13:59:52.309619 10644 solver.cpp:228] Iteration 30880, loss = 0.249705
I0529 13:59:52.309653 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 13:59:52.309660 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386424 (* 1 = 0.0386424 loss)
I0529 13:59:52.309664 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.157536 (* 1 = 0.157536 loss)
I0529 13:59:52.309667 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00671787 (* 1 = 0.00671787 loss)
I0529 13:59:52.309670 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024422 (* 1 = 0.024422 loss)
I0529 13:59:52.309674 10644 sgd_solver.cpp:106] Iteration 30880, lr = 0.0002
I0529 14:00:40.478372 10644 solver.cpp:228] Iteration 30900, loss = 0.194136
I0529 14:00:40.478410 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 14:00:40.478416 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0745311 (* 1 = 0.0745311 loss)
I0529 14:00:40.478420 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.139689 (* 1 = 0.139689 loss)
I0529 14:00:40.478423 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136154 (* 1 = 0.00136154 loss)
I0529 14:00:40.478426 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143449 (* 1 = 0.0143449 loss)
I0529 14:00:40.478430 10644 sgd_solver.cpp:106] Iteration 30900, lr = 0.0002
I0529 14:01:28.644949 10644 solver.cpp:228] Iteration 30920, loss = 0.305046
I0529 14:01:28.644984 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:01:28.644991 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00300763 (* 1 = 0.00300763 loss)
I0529 14:01:28.644995 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0347512 (* 1 = 0.0347512 loss)
I0529 14:01:28.644999 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0278748 (* 1 = 0.0278748 loss)
I0529 14:01:28.645001 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0517798 (* 1 = 0.0517798 loss)
I0529 14:01:28.645005 10644 sgd_solver.cpp:106] Iteration 30920, lr = 0.0002
I0529 14:02:16.811672 10644 solver.cpp:228] Iteration 30940, loss = 0.314247
I0529 14:02:16.811707 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 14:02:16.811715 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.211975 (* 1 = 0.211975 loss)
I0529 14:02:16.811718 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.248578 (* 1 = 0.248578 loss)
I0529 14:02:16.811722 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0227305 (* 1 = 0.0227305 loss)
I0529 14:02:16.811724 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129914 (* 1 = 0.129914 loss)
I0529 14:02:16.811729 10644 sgd_solver.cpp:106] Iteration 30940, lr = 0.0002
I0529 14:03:04.957123 10644 solver.cpp:228] Iteration 30960, loss = 0.257375
I0529 14:03:04.957145 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 14:03:04.957152 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.029227 (* 1 = 0.029227 loss)
I0529 14:03:04.957156 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.120442 (* 1 = 0.120442 loss)
I0529 14:03:04.957159 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112649 (* 1 = 0.0112649 loss)
I0529 14:03:04.957164 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238741 (* 1 = 0.0238741 loss)
I0529 14:03:04.957167 10644 sgd_solver.cpp:106] Iteration 30960, lr = 0.0002
I0529 14:03:53.309170 10644 solver.cpp:228] Iteration 30980, loss = 0.183519
I0529 14:03:53.309206 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:03:53.309213 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173572 (* 1 = 0.0173572 loss)
I0529 14:03:53.309216 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0302196 (* 1 = 0.0302196 loss)
I0529 14:03:53.309221 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320326 (* 1 = 0.00320326 loss)
I0529 14:03:53.309223 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143836 (* 1 = 0.0143836 loss)
I0529 14:03:53.309227 10644 sgd_solver.cpp:106] Iteration 30980, lr = 0.0002
speed: 2.428s / iter
I0529 14:04:41.590466 10644 solver.cpp:228] Iteration 31000, loss = 0.204987
I0529 14:04:41.590488 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:04:41.590495 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274601 (* 1 = 0.0274601 loss)
I0529 14:04:41.590499 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0307271 (* 1 = 0.0307271 loss)
I0529 14:04:41.590503 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00267705 (* 1 = 0.00267705 loss)
I0529 14:04:41.590507 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112702 (* 1 = 0.0112702 loss)
I0529 14:04:41.590512 10644 sgd_solver.cpp:106] Iteration 31000, lr = 0.0002
I0529 14:05:29.844754 10644 solver.cpp:228] Iteration 31020, loss = 0.316586
I0529 14:05:29.844779 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 14:05:29.844786 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0361045 (* 1 = 0.0361045 loss)
I0529 14:05:29.844789 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0681409 (* 1 = 0.0681409 loss)
I0529 14:05:29.844794 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198462 (* 1 = 0.0198462 loss)
I0529 14:05:29.844796 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139211 (* 1 = 0.0139211 loss)
I0529 14:05:29.844801 10644 sgd_solver.cpp:106] Iteration 31020, lr = 0.0002
I0529 14:06:18.085144 10644 solver.cpp:228] Iteration 31040, loss = 0.262066
I0529 14:06:18.085167 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 14:06:18.085175 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0564155 (* 1 = 0.0564155 loss)
I0529 14:06:18.085180 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.15527 (* 1 = 0.15527 loss)
I0529 14:06:18.085184 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110253 (* 1 = 0.0110253 loss)
I0529 14:06:18.085189 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0594403 (* 1 = 0.0594403 loss)
I0529 14:06:18.085196 10644 sgd_solver.cpp:106] Iteration 31040, lr = 0.0002
I0529 14:07:06.310518 10644 solver.cpp:228] Iteration 31060, loss = 0.275923
I0529 14:07:06.310542 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 14:07:06.310549 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.2101 (* 1 = 0.2101 loss)
I0529 14:07:06.310552 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.260927 (* 1 = 0.260927 loss)
I0529 14:07:06.310556 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00605854 (* 1 = 0.00605854 loss)
I0529 14:07:06.310560 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248793 (* 1 = 0.0248793 loss)
I0529 14:07:06.310565 10644 sgd_solver.cpp:106] Iteration 31060, lr = 0.0002
I0529 14:07:54.538126 10644 solver.cpp:228] Iteration 31080, loss = 0.232118
I0529 14:07:54.538152 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 14:07:54.538158 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.218356 (* 1 = 0.218356 loss)
I0529 14:07:54.538162 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.250764 (* 1 = 0.250764 loss)
I0529 14:07:54.538166 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0387894 (* 1 = 0.0387894 loss)
I0529 14:07:54.538169 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035203 (* 1 = 0.035203 loss)
I0529 14:07:54.538174 10644 sgd_solver.cpp:106] Iteration 31080, lr = 0.0002
I0529 14:08:42.801373 10644 solver.cpp:228] Iteration 31100, loss = 0.534337
I0529 14:08:42.801395 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 14:08:42.801403 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.11085 (* 1 = 0.11085 loss)
I0529 14:08:42.801406 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.289088 (* 1 = 0.289088 loss)
I0529 14:08:42.801409 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.127922 (* 1 = 0.127922 loss)
I0529 14:08:42.801414 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109182 (* 1 = 0.109182 loss)
I0529 14:08:42.801417 10644 sgd_solver.cpp:106] Iteration 31100, lr = 0.0002
I0529 14:09:31.051882 10644 solver.cpp:228] Iteration 31120, loss = 0.342521
I0529 14:09:31.051904 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:09:31.051911 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0376641 (* 1 = 0.0376641 loss)
I0529 14:09:31.051915 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0546015 (* 1 = 0.0546015 loss)
I0529 14:09:31.051919 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000985564 (* 1 = 0.000985564 loss)
I0529 14:09:31.051923 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140588 (* 1 = 0.0140588 loss)
I0529 14:09:31.051926 10644 sgd_solver.cpp:106] Iteration 31120, lr = 0.0002
I0529 14:10:19.269639 10644 solver.cpp:228] Iteration 31140, loss = 0.283618
I0529 14:10:19.269660 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:10:19.269667 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169573 (* 1 = 0.0169573 loss)
I0529 14:10:19.269670 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0345736 (* 1 = 0.0345736 loss)
I0529 14:10:19.269675 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195901 (* 1 = 0.0195901 loss)
I0529 14:10:19.269677 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199798 (* 1 = 0.0199798 loss)
I0529 14:10:19.269682 10644 sgd_solver.cpp:106] Iteration 31140, lr = 0.0002
I0529 14:11:07.504230 10644 solver.cpp:228] Iteration 31160, loss = 0.416524
I0529 14:11:07.504253 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 14:11:07.504261 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590079 (* 1 = 0.0590079 loss)
I0529 14:11:07.504264 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0988281 (* 1 = 0.0988281 loss)
I0529 14:11:07.504267 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00656921 (* 1 = 0.00656921 loss)
I0529 14:11:07.504271 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119943 (* 1 = 0.0119943 loss)
I0529 14:11:07.504276 10644 sgd_solver.cpp:106] Iteration 31160, lr = 0.0002
I0529 14:11:55.947577 10644 solver.cpp:228] Iteration 31180, loss = 0.268015
I0529 14:11:55.947598 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 14:11:55.947607 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151076 (* 1 = 0.0151076 loss)
I0529 14:11:55.947610 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.116846 (* 1 = 0.116846 loss)
I0529 14:11:55.947613 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255559 (* 1 = 0.0255559 loss)
I0529 14:11:55.947618 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939814 (* 1 = 0.00939814 loss)
I0529 14:11:55.947621 10644 sgd_solver.cpp:106] Iteration 31180, lr = 0.0002
speed: 2.428s / iter
I0529 14:12:44.332463 10644 solver.cpp:228] Iteration 31200, loss = 0.232931
I0529 14:12:44.332484 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:12:44.332491 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198617 (* 1 = 0.0198617 loss)
I0529 14:12:44.332495 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0575406 (* 1 = 0.0575406 loss)
I0529 14:12:44.332499 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00251089 (* 1 = 0.00251089 loss)
I0529 14:12:44.332502 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00332627 (* 1 = 0.00332627 loss)
I0529 14:12:44.332506 10644 sgd_solver.cpp:106] Iteration 31200, lr = 0.0002
I0529 14:13:32.606088 10644 solver.cpp:228] Iteration 31220, loss = 0.350105
I0529 14:13:32.606111 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 14:13:32.606117 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.106552 (* 1 = 0.106552 loss)
I0529 14:13:32.606122 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.192166 (* 1 = 0.192166 loss)
I0529 14:13:32.606124 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541331 (* 1 = 0.00541331 loss)
I0529 14:13:32.606128 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275113 (* 1 = 0.0275113 loss)
I0529 14:13:32.606132 10644 sgd_solver.cpp:106] Iteration 31220, lr = 0.0002
I0529 14:14:20.896849 10644 solver.cpp:228] Iteration 31240, loss = 0.439748
I0529 14:14:20.896876 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:14:20.896883 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174584 (* 1 = 0.0174584 loss)
I0529 14:14:20.896888 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0691725 (* 1 = 0.0691725 loss)
I0529 14:14:20.896891 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133282 (* 1 = 0.00133282 loss)
I0529 14:14:20.896895 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157649 (* 1 = 0.0157649 loss)
I0529 14:14:20.896900 10644 sgd_solver.cpp:106] Iteration 31240, lr = 0.0002
I0529 14:15:09.176967 10644 solver.cpp:228] Iteration 31260, loss = 0.238886
I0529 14:15:09.176990 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:15:09.176996 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807154 (* 1 = 0.0807154 loss)
I0529 14:15:09.177000 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0863465 (* 1 = 0.0863465 loss)
I0529 14:15:09.177003 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000536537 (* 1 = 0.000536537 loss)
I0529 14:15:09.177007 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130846 (* 1 = 0.0130846 loss)
I0529 14:15:09.177011 10644 sgd_solver.cpp:106] Iteration 31260, lr = 0.0002
I0529 14:15:57.438719 10644 solver.cpp:228] Iteration 31280, loss = 0.349689
I0529 14:15:57.438755 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 14:15:57.438761 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.062649 (* 1 = 0.062649 loss)
I0529 14:15:57.438766 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.117641 (* 1 = 0.117641 loss)
I0529 14:15:57.438768 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00607035 (* 1 = 0.00607035 loss)
I0529 14:15:57.438771 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014039 (* 1 = 0.014039 loss)
I0529 14:15:57.438776 10644 sgd_solver.cpp:106] Iteration 31280, lr = 0.0002
I0529 14:16:45.873425 10644 solver.cpp:228] Iteration 31300, loss = 0.228015
I0529 14:16:45.873446 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 14:16:45.873453 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571977 (* 1 = 0.0571977 loss)
I0529 14:16:45.873456 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.117684 (* 1 = 0.117684 loss)
I0529 14:16:45.873461 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00815226 (* 1 = 0.00815226 loss)
I0529 14:16:45.873464 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182036 (* 1 = 0.0182036 loss)
I0529 14:16:45.873468 10644 sgd_solver.cpp:106] Iteration 31300, lr = 0.0002
I0529 14:17:34.188827 10644 solver.cpp:228] Iteration 31320, loss = 0.216486
I0529 14:17:34.188849 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:17:34.188855 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179471 (* 1 = 0.0179471 loss)
I0529 14:17:34.188859 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0379008 (* 1 = 0.0379008 loss)
I0529 14:17:34.188863 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00837236 (* 1 = 0.00837236 loss)
I0529 14:17:34.188866 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140566 (* 1 = 0.0140566 loss)
I0529 14:17:34.188870 10644 sgd_solver.cpp:106] Iteration 31320, lr = 0.0002
I0529 14:18:22.507041 10644 solver.cpp:228] Iteration 31340, loss = 0.249241
I0529 14:18:22.507064 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0529 14:18:22.507071 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.188556 (* 1 = 0.188556 loss)
I0529 14:18:22.507076 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.35627 (* 1 = 0.35627 loss)
I0529 14:18:22.507078 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0318335 (* 1 = 0.0318335 loss)
I0529 14:18:22.507082 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.114083 (* 1 = 0.114083 loss)
I0529 14:18:22.507086 10644 sgd_solver.cpp:106] Iteration 31340, lr = 0.0002
I0529 14:19:10.824275 10644 solver.cpp:228] Iteration 31360, loss = 0.261379
I0529 14:19:10.824296 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:19:10.824303 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467968 (* 1 = 0.0467968 loss)
I0529 14:19:10.824307 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0760755 (* 1 = 0.0760755 loss)
I0529 14:19:10.824311 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0089715 (* 1 = 0.0089715 loss)
I0529 14:19:10.824314 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206341 (* 1 = 0.0206341 loss)
I0529 14:19:10.824318 10644 sgd_solver.cpp:106] Iteration 31360, lr = 0.0002
I0529 14:19:59.146760 10644 solver.cpp:228] Iteration 31380, loss = 0.327794
I0529 14:19:59.146796 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 14:19:59.146803 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.138805 (* 1 = 0.138805 loss)
I0529 14:19:59.146806 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.180135 (* 1 = 0.180135 loss)
I0529 14:19:59.146811 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00806878 (* 1 = 0.00806878 loss)
I0529 14:19:59.146813 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295956 (* 1 = 0.0295956 loss)
I0529 14:19:59.146817 10644 sgd_solver.cpp:106] Iteration 31380, lr = 0.0002
speed: 2.428s / iter
I0529 14:20:47.474786 10644 solver.cpp:228] Iteration 31400, loss = 0.268206
I0529 14:20:47.474807 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 14:20:47.474813 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0387539 (* 1 = 0.0387539 loss)
I0529 14:20:47.474817 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0557783 (* 1 = 0.0557783 loss)
I0529 14:20:47.474822 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00112446 (* 1 = 0.00112446 loss)
I0529 14:20:47.474824 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00899767 (* 1 = 0.00899767 loss)
I0529 14:20:47.474829 10644 sgd_solver.cpp:106] Iteration 31400, lr = 0.0002
I0529 14:21:35.802431 10644 solver.cpp:228] Iteration 31420, loss = 0.308991
I0529 14:21:35.802453 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 14:21:35.802460 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.137674 (* 1 = 0.137674 loss)
I0529 14:21:35.802464 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.16447 (* 1 = 0.16447 loss)
I0529 14:21:35.802467 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00601548 (* 1 = 0.00601548 loss)
I0529 14:21:35.802471 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257122 (* 1 = 0.0257122 loss)
I0529 14:21:35.802475 10644 sgd_solver.cpp:106] Iteration 31420, lr = 0.0002
I0529 14:22:24.139269 10644 solver.cpp:228] Iteration 31440, loss = 0.231211
I0529 14:22:24.139291 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:22:24.139298 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000681183 (* 1 = 0.000681183 loss)
I0529 14:22:24.139302 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0242841 (* 1 = 0.0242841 loss)
I0529 14:22:24.139307 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00299257 (* 1 = 0.00299257 loss)
I0529 14:22:24.139309 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173362 (* 1 = 0.0173362 loss)
I0529 14:22:24.139314 10644 sgd_solver.cpp:106] Iteration 31440, lr = 0.0002
I0529 14:23:12.467515 10644 solver.cpp:228] Iteration 31460, loss = 0.300364
I0529 14:23:12.467535 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 14:23:12.467556 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.118522 (* 1 = 0.118522 loss)
I0529 14:23:12.467561 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.274254 (* 1 = 0.274254 loss)
I0529 14:23:12.467563 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00950711 (* 1 = 0.00950711 loss)
I0529 14:23:12.467566 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0803984 (* 1 = 0.0803984 loss)
I0529 14:23:12.467571 10644 sgd_solver.cpp:106] Iteration 31460, lr = 0.0002
I0529 14:24:00.997133 10644 solver.cpp:228] Iteration 31480, loss = 0.245198
I0529 14:24:00.997156 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:24:00.997164 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0129774 (* 1 = 0.0129774 loss)
I0529 14:24:00.997166 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0484178 (* 1 = 0.0484178 loss)
I0529 14:24:00.997170 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00437495 (* 1 = 0.00437495 loss)
I0529 14:24:00.997174 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00569949 (* 1 = 0.00569949 loss)
I0529 14:24:00.997177 10644 sgd_solver.cpp:106] Iteration 31480, lr = 0.0002
I0529 14:24:49.343457 10644 solver.cpp:228] Iteration 31500, loss = 0.153337
I0529 14:24:49.343479 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 14:24:49.343487 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.092633 (* 1 = 0.092633 loss)
I0529 14:24:49.343490 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.131176 (* 1 = 0.131176 loss)
I0529 14:24:49.343494 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00656685 (* 1 = 0.00656685 loss)
I0529 14:24:49.343497 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.130129 (* 1 = 0.130129 loss)
I0529 14:24:49.343502 10644 sgd_solver.cpp:106] Iteration 31500, lr = 0.0002
I0529 14:25:37.876065 10644 solver.cpp:228] Iteration 31520, loss = 0.206842
I0529 14:25:37.876085 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:25:37.876092 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0429019 (* 1 = 0.0429019 loss)
I0529 14:25:37.876096 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0463339 (* 1 = 0.0463339 loss)
I0529 14:25:37.876101 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250273 (* 1 = 0.00250273 loss)
I0529 14:25:37.876103 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00660111 (* 1 = 0.00660111 loss)
I0529 14:25:37.876108 10644 sgd_solver.cpp:106] Iteration 31520, lr = 0.0002
I0529 14:26:26.340232 10644 solver.cpp:228] Iteration 31540, loss = 0.24857
I0529 14:26:26.340255 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 14:26:26.340262 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.08829 (* 1 = 0.08829 loss)
I0529 14:26:26.340266 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.203159 (* 1 = 0.203159 loss)
I0529 14:26:26.340270 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0194727 (* 1 = 0.0194727 loss)
I0529 14:26:26.340273 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370077 (* 1 = 0.0370077 loss)
I0529 14:26:26.340277 10644 sgd_solver.cpp:106] Iteration 31540, lr = 0.0002
I0529 14:27:14.853245 10644 solver.cpp:228] Iteration 31560, loss = 0.41272
I0529 14:27:14.853267 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 14:27:14.853273 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729061 (* 1 = 0.0729061 loss)
I0529 14:27:14.853277 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0895989 (* 1 = 0.0895989 loss)
I0529 14:27:14.853281 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00333298 (* 1 = 0.00333298 loss)
I0529 14:27:14.853284 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257762 (* 1 = 0.0257762 loss)
I0529 14:27:14.853289 10644 sgd_solver.cpp:106] Iteration 31560, lr = 0.0002
I0529 14:28:03.553072 10644 solver.cpp:228] Iteration 31580, loss = 0.405657
I0529 14:28:03.553107 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:28:03.553114 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000932263 (* 1 = 0.000932263 loss)
I0529 14:28:03.553117 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0398807 (* 1 = 0.0398807 loss)
I0529 14:28:03.553120 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211681 (* 1 = 0.0211681 loss)
I0529 14:28:03.553123 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421193 (* 1 = 0.0421193 loss)
I0529 14:28:03.553128 10644 sgd_solver.cpp:106] Iteration 31580, lr = 0.0002
speed: 2.427s / iter
I0529 14:28:52.100888 10644 solver.cpp:228] Iteration 31600, loss = 0.256828
I0529 14:28:52.100926 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:28:52.100934 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292257 (* 1 = 0.0292257 loss)
I0529 14:28:52.100937 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0371054 (* 1 = 0.0371054 loss)
I0529 14:28:52.100940 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00185361 (* 1 = 0.00185361 loss)
I0529 14:28:52.100944 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106068 (* 1 = 0.0106068 loss)
I0529 14:28:52.100947 10644 sgd_solver.cpp:106] Iteration 31600, lr = 0.0002
I0529 14:29:40.724189 10644 solver.cpp:228] Iteration 31620, loss = 0.354225
I0529 14:29:40.724225 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:29:40.724231 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182722 (* 1 = 0.0182722 loss)
I0529 14:29:40.724234 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0263712 (* 1 = 0.0263712 loss)
I0529 14:29:40.724237 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00306019 (* 1 = 0.00306019 loss)
I0529 14:29:40.724241 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269737 (* 1 = 0.0269737 loss)
I0529 14:29:40.724244 10644 sgd_solver.cpp:106] Iteration 31620, lr = 0.0002
I0529 14:30:29.282382 10644 solver.cpp:228] Iteration 31640, loss = 0.21555
I0529 14:30:29.282416 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 14:30:29.282423 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247278 (* 1 = 0.0247278 loss)
I0529 14:30:29.282428 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0614737 (* 1 = 0.0614737 loss)
I0529 14:30:29.282430 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00468868 (* 1 = 0.00468868 loss)
I0529 14:30:29.282434 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020463 (* 1 = 0.020463 loss)
I0529 14:30:29.282438 10644 sgd_solver.cpp:106] Iteration 31640, lr = 0.0002
I0529 14:31:17.866315 10644 solver.cpp:228] Iteration 31660, loss = 0.328428
I0529 14:31:17.866343 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:31:17.866349 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00130964 (* 1 = 0.00130964 loss)
I0529 14:31:17.866354 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0489358 (* 1 = 0.0489358 loss)
I0529 14:31:17.866358 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193389 (* 1 = 0.0193389 loss)
I0529 14:31:17.866361 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011954 (* 1 = 0.011954 loss)
I0529 14:31:17.866366 10644 sgd_solver.cpp:106] Iteration 31660, lr = 0.0002
I0529 14:32:06.378360 10644 solver.cpp:228] Iteration 31680, loss = 0.375585
I0529 14:32:06.378386 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 14:32:06.378392 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591686 (* 1 = 0.0591686 loss)
I0529 14:32:06.378397 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.147681 (* 1 = 0.147681 loss)
I0529 14:32:06.378401 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147657 (* 1 = 0.0147657 loss)
I0529 14:32:06.378403 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295596 (* 1 = 0.0295596 loss)
I0529 14:32:06.378408 10644 sgd_solver.cpp:106] Iteration 31680, lr = 0.0002
I0529 14:32:54.701014 10644 solver.cpp:228] Iteration 31700, loss = 0.175436
I0529 14:32:54.701035 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:32:54.701042 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373457 (* 1 = 0.0373457 loss)
I0529 14:32:54.701046 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0636728 (* 1 = 0.0636728 loss)
I0529 14:32:54.701050 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00459302 (* 1 = 0.00459302 loss)
I0529 14:32:54.701053 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00340114 (* 1 = 0.00340114 loss)
I0529 14:32:54.701057 10644 sgd_solver.cpp:106] Iteration 31700, lr = 0.0002
I0529 14:33:42.883004 10644 solver.cpp:228] Iteration 31720, loss = 0.293249
I0529 14:33:42.883028 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 14:33:42.883034 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0775797 (* 1 = 0.0775797 loss)
I0529 14:33:42.883038 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0827383 (* 1 = 0.0827383 loss)
I0529 14:33:42.883041 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147849 (* 1 = 0.0147849 loss)
I0529 14:33:42.883044 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128806 (* 1 = 0.0128806 loss)
I0529 14:33:42.883049 10644 sgd_solver.cpp:106] Iteration 31720, lr = 0.0002
I0529 14:34:31.052809 10644 solver.cpp:228] Iteration 31740, loss = 0.19559
I0529 14:34:31.052832 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 14:34:31.052841 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0875276 (* 1 = 0.0875276 loss)
I0529 14:34:31.052847 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.176337 (* 1 = 0.176337 loss)
I0529 14:34:31.052853 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00589215 (* 1 = 0.00589215 loss)
I0529 14:34:31.052858 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105799 (* 1 = 0.0105799 loss)
I0529 14:34:31.052865 10644 sgd_solver.cpp:106] Iteration 31740, lr = 0.0002
I0529 14:35:19.221909 10644 solver.cpp:228] Iteration 31760, loss = 0.178274
I0529 14:35:19.221930 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:35:19.221937 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00127773 (* 1 = 0.00127773 loss)
I0529 14:35:19.221941 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0632316 (* 1 = 0.0632316 loss)
I0529 14:35:19.221945 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119238 (* 1 = 0.0119238 loss)
I0529 14:35:19.221948 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0496551 (* 1 = 0.0496551 loss)
I0529 14:35:19.221952 10644 sgd_solver.cpp:106] Iteration 31760, lr = 0.0002
I0529 14:36:07.367651 10644 solver.cpp:228] Iteration 31780, loss = 0.298682
I0529 14:36:07.367674 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 14:36:07.367681 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0632857 (* 1 = 0.0632857 loss)
I0529 14:36:07.367686 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.156553 (* 1 = 0.156553 loss)
I0529 14:36:07.367688 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120649 (* 1 = 0.0120649 loss)
I0529 14:36:07.367692 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00558369 (* 1 = 0.00558369 loss)
I0529 14:36:07.367697 10644 sgd_solver.cpp:106] Iteration 31780, lr = 0.0002
speed: 2.427s / iter
I0529 14:36:55.529386 10644 solver.cpp:228] Iteration 31800, loss = 0.281222
I0529 14:36:55.529409 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 14:36:55.529415 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.103441 (* 1 = 0.103441 loss)
I0529 14:36:55.529419 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.188774 (* 1 = 0.188774 loss)
I0529 14:36:55.529422 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108533 (* 1 = 0.0108533 loss)
I0529 14:36:55.529426 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291795 (* 1 = 0.0291795 loss)
I0529 14:36:55.529430 10644 sgd_solver.cpp:106] Iteration 31800, lr = 0.0002
I0529 14:37:43.670907 10644 solver.cpp:228] Iteration 31820, loss = 0.248385
I0529 14:37:43.670928 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:37:43.670938 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.00194091 (* 1 = 0.00194091 loss)
I0529 14:37:43.670944 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0354045 (* 1 = 0.0354045 loss)
I0529 14:37:43.670949 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241756 (* 1 = 0.0241756 loss)
I0529 14:37:43.670954 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020916 (* 1 = 0.020916 loss)
I0529 14:37:43.670960 10644 sgd_solver.cpp:106] Iteration 31820, lr = 0.0002
I0529 14:38:31.816505 10644 solver.cpp:228] Iteration 31840, loss = 0.234841
I0529 14:38:31.816527 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 14:38:31.816536 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341528 (* 1 = 0.0341528 loss)
I0529 14:38:31.816542 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.116349 (* 1 = 0.116349 loss)
I0529 14:38:31.816548 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180525 (* 1 = 0.0180525 loss)
I0529 14:38:31.816553 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322703 (* 1 = 0.0322703 loss)
I0529 14:38:31.816560 10644 sgd_solver.cpp:106] Iteration 31840, lr = 0.0002
I0529 14:39:19.971745 10644 solver.cpp:228] Iteration 31860, loss = 0.273444
I0529 14:39:19.971767 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:39:19.971776 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0801975 (* 1 = 0.0801975 loss)
I0529 14:39:19.971782 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0910061 (* 1 = 0.0910061 loss)
I0529 14:39:19.971788 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245951 (* 1 = 0.0245951 loss)
I0529 14:39:19.971793 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0409783 (* 1 = 0.0409783 loss)
I0529 14:39:19.971799 10644 sgd_solver.cpp:106] Iteration 31860, lr = 0.0002
I0529 14:40:08.115917 10644 solver.cpp:228] Iteration 31880, loss = 0.338667
I0529 14:40:08.115941 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 14:40:08.115949 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437345 (* 1 = 0.0437345 loss)
I0529 14:40:08.115954 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0665676 (* 1 = 0.0665676 loss)
I0529 14:40:08.115960 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00802137 (* 1 = 0.00802137 loss)
I0529 14:40:08.115965 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00921391 (* 1 = 0.00921391 loss)
I0529 14:40:08.115972 10644 sgd_solver.cpp:106] Iteration 31880, lr = 0.0002
I0529 14:40:56.271682 10644 solver.cpp:228] Iteration 31900, loss = 0.373709
I0529 14:40:56.271705 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 14:40:56.271715 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0669987 (* 1 = 0.0669987 loss)
I0529 14:40:56.271721 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0988809 (* 1 = 0.0988809 loss)
I0529 14:40:56.271726 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00550817 (* 1 = 0.00550817 loss)
I0529 14:40:56.271731 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195733 (* 1 = 0.0195733 loss)
I0529 14:40:56.271739 10644 sgd_solver.cpp:106] Iteration 31900, lr = 0.0002
I0529 14:41:44.419852 10644 solver.cpp:228] Iteration 31920, loss = 0.277142
I0529 14:41:44.419873 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 14:41:44.419883 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.015642 (* 1 = 0.015642 loss)
I0529 14:41:44.419889 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0441707 (* 1 = 0.0441707 loss)
I0529 14:41:44.419895 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00131644 (* 1 = 0.00131644 loss)
I0529 14:41:44.419900 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00624934 (* 1 = 0.00624934 loss)
I0529 14:41:44.419905 10644 sgd_solver.cpp:106] Iteration 31920, lr = 0.0002
I0529 14:42:32.565452 10644 solver.cpp:228] Iteration 31940, loss = 0.241533
I0529 14:42:32.565475 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 14:42:32.565484 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.000301978 (* 1 = 0.000301978 loss)
I0529 14:42:32.565490 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0365383 (* 1 = 0.0365383 loss)
I0529 14:42:32.565495 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0224553 (* 1 = 0.0224553 loss)
I0529 14:42:32.565500 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00303112 (* 1 = 0.00303112 loss)
I0529 14:42:32.565507 10644 sgd_solver.cpp:106] Iteration 31940, lr = 0.0002
I0529 14:43:20.714576 10644 solver.cpp:228] Iteration 31960, loss = 0.243641
I0529 14:43:20.714601 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 14:43:20.714609 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.0288575 (* 1 = 0.0288575 loss)
I0529 14:43:20.714615 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.0550158 (* 1 = 0.0550158 loss)
I0529 14:43:20.714620 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235647 (* 1 = 0.00235647 loss)
I0529 14:43:20.714627 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00732833 (* 1 = 0.00732833 loss)
I0529 14:43:20.714632 10644 sgd_solver.cpp:106] Iteration 31960, lr = 0.0002
I0529 14:44:08.869194 10644 solver.cpp:228] Iteration 31980, loss = 0.292145
I0529 14:44:08.869217 10644 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0529 14:44:08.869226 10644 solver.cpp:244]     Train net output #1: loss_bbox = 0.272581 (* 1 = 0.272581 loss)
I0529 14:44:08.869231 10644 solver.cpp:244]     Train net output #2: loss_cls = 0.518555 (* 1 = 0.518555 loss)
I0529 14:44:08.869237 10644 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0568332 (* 1 = 0.0568332 loss)
I0529 14:44:08.869242 10644 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0797077 (* 1 = 0.0797077 loss)
I0529 14:44:08.869248 10644 sgd_solver.cpp:106] Iteration 31980, lr = 0.0002
speed: 2.427s / iter
I0529 14:44:54.769197 10644 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel
done solving

real	1295m0.767s
user	1078m55.208s
sys	227m31.176s
+ set +x
+ ./tools/test_net.py --gpu 1 --def experiments/5_28_original/test_agnostic.prototxt --net /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel --imdb voc_0712_test --cfg experiments/5_28_original/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel', cfg_file='experiments/5_28_original/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=1, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/5_28_original/test_agnostic.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '5_28_original/model',
 'GPU_ID': 1,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [768],
          'SOFT_NMS': 0,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [640],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0529 14:44:56.714758 30229 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0529 14:44:56.714781 30229 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0529 14:44:56.714783 30229 _caffe.cpp:125] Net('experiments/5_28_original/test_agnostic.prototxt', 1, weights='/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel')
I0529 14:44:56.716605 30229 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/5_28_original/test_agnostic.prototxt
I0529 14:44:56.716784 30229 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0529 14:44:56.716787 30229 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0529 14:44:56.717993 30229 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "r
I0529 14:44:56.719591 30229 layer_factory.hpp:77] Creating layer input
I0529 14:44:56.719617 30229 net.cpp:100] Creating Layer input
I0529 14:44:56.719624 30229 net.cpp:418] input -> data
I0529 14:44:56.719656 30229 net.cpp:418] input -> im_info
I0529 14:44:56.740003 30229 net.cpp:150] Setting up input
I0529 14:44:56.740033 30229 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0529 14:44:56.740039 30229 net.cpp:157] Top shape: 1 3 (3)
I0529 14:44:56.740041 30229 net.cpp:165] Memory required for data: 602124
I0529 14:44:56.740058 30229 layer_factory.hpp:77] Creating layer conv1
I0529 14:44:56.740106 30229 net.cpp:100] Creating Layer conv1
I0529 14:44:56.740118 30229 net.cpp:444] conv1 <- data
I0529 14:44:56.740140 30229 net.cpp:418] conv1 -> conv1
I0529 14:44:57.042778 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 225816
I0529 14:44:57.043040 30229 net.cpp:150] Setting up conv1
I0529 14:44:57.043061 30229 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0529 14:44:57.043062 30229 net.cpp:165] Memory required for data: 3813388
I0529 14:44:57.043109 30229 layer_factory.hpp:77] Creating layer bn_conv1
I0529 14:44:57.043140 30229 net.cpp:100] Creating Layer bn_conv1
I0529 14:44:57.043149 30229 net.cpp:444] bn_conv1 <- conv1
I0529 14:44:57.043162 30229 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0529 14:44:57.043406 30229 net.cpp:150] Setting up bn_conv1
I0529 14:44:57.043413 30229 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0529 14:44:57.043416 30229 net.cpp:165] Memory required for data: 7024652
I0529 14:44:57.043440 30229 layer_factory.hpp:77] Creating layer scale_conv1
I0529 14:44:57.043454 30229 net.cpp:100] Creating Layer scale_conv1
I0529 14:44:57.043460 30229 net.cpp:444] scale_conv1 <- conv1
I0529 14:44:57.043471 30229 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0529 14:44:57.043527 30229 layer_factory.hpp:77] Creating layer scale_conv1
I0529 14:44:57.043704 30229 net.cpp:150] Setting up scale_conv1
I0529 14:44:57.043711 30229 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0529 14:44:57.043714 30229 net.cpp:165] Memory required for data: 10235916
I0529 14:44:57.043723 30229 layer_factory.hpp:77] Creating layer conv1_relu
I0529 14:44:57.043735 30229 net.cpp:100] Creating Layer conv1_relu
I0529 14:44:57.043740 30229 net.cpp:444] conv1_relu <- conv1
I0529 14:44:57.043751 30229 net.cpp:405] conv1_relu -> conv1 (in-place)
I0529 14:44:57.043882 30229 net.cpp:150] Setting up conv1_relu
I0529 14:44:57.043889 30229 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0529 14:44:57.043890 30229 net.cpp:165] Memory required for data: 13447180
I0529 14:44:57.043895 30229 layer_factory.hpp:77] Creating layer pool1
I0529 14:44:57.043906 30229 net.cpp:100] Creating Layer pool1
I0529 14:44:57.043911 30229 net.cpp:444] pool1 <- conv1
I0529 14:44:57.043921 30229 net.cpp:418] pool1 -> pool1
I0529 14:44:57.043975 30229 net.cpp:150] Setting up pool1
I0529 14:44:57.043983 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.043987 30229 net.cpp:165] Memory required for data: 14249996
I0529 14:44:57.043989 30229 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0529 14:44:57.043998 30229 net.cpp:100] Creating Layer pool1_pool1_0_split
I0529 14:44:57.044003 30229 net.cpp:444] pool1_pool1_0_split <- pool1
I0529 14:44:57.044011 30229 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0529 14:44:57.044026 30229 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0529 14:44:57.044070 30229 net.cpp:150] Setting up pool1_pool1_0_split
I0529 14:44:57.044077 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.044081 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.044083 30229 net.cpp:165] Memory required for data: 15855628
I0529 14:44:57.044086 30229 layer_factory.hpp:77] Creating layer res2a_branch1
I0529 14:44:57.044101 30229 net.cpp:100] Creating Layer res2a_branch1
I0529 14:44:57.044106 30229 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0529 14:44:57.044117 30229 net.cpp:418] res2a_branch1 -> res2a_branch1
I0529 14:44:57.044963 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.044978 30229 net.cpp:150] Setting up res2a_branch1
I0529 14:44:57.044986 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.044988 30229 net.cpp:165] Memory required for data: 19066892
I0529 14:44:57.044998 30229 layer_factory.hpp:77] Creating layer bn2a_branch1
I0529 14:44:57.045015 30229 net.cpp:100] Creating Layer bn2a_branch1
I0529 14:44:57.045022 30229 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0529 14:44:57.045034 30229 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0529 14:44:57.045948 30229 net.cpp:150] Setting up bn2a_branch1
I0529 14:44:57.045958 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.045961 30229 net.cpp:165] Memory required for data: 22278156
I0529 14:44:57.045987 30229 layer_factory.hpp:77] Creating layer scale2a_branch1
I0529 14:44:57.046002 30229 net.cpp:100] Creating Layer scale2a_branch1
I0529 14:44:57.046007 30229 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0529 14:44:57.046020 30229 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0529 14:44:57.046082 30229 layer_factory.hpp:77] Creating layer scale2a_branch1
I0529 14:44:57.046236 30229 net.cpp:150] Setting up scale2a_branch1
I0529 14:44:57.046243 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.046247 30229 net.cpp:165] Memory required for data: 25489420
I0529 14:44:57.046257 30229 layer_factory.hpp:77] Creating layer res2a_branch2a
I0529 14:44:57.046270 30229 net.cpp:100] Creating Layer res2a_branch2a
I0529 14:44:57.046277 30229 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0529 14:44:57.046289 30229 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0529 14:44:57.047178 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.047192 30229 net.cpp:150] Setting up res2a_branch2a
I0529 14:44:57.047199 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.047201 30229 net.cpp:165] Memory required for data: 26292236
I0529 14:44:57.047211 30229 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0529 14:44:57.047224 30229 net.cpp:100] Creating Layer bn2a_branch2a
I0529 14:44:57.047230 30229 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0529 14:44:57.047243 30229 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0529 14:44:57.047475 30229 net.cpp:150] Setting up bn2a_branch2a
I0529 14:44:57.047482 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.047484 30229 net.cpp:165] Memory required for data: 27095052
I0529 14:44:57.047508 30229 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0529 14:44:57.047521 30229 net.cpp:100] Creating Layer scale2a_branch2a
I0529 14:44:57.047528 30229 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0529 14:44:57.047538 30229 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0529 14:44:57.047595 30229 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0529 14:44:57.047756 30229 net.cpp:150] Setting up scale2a_branch2a
I0529 14:44:57.047763 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.047766 30229 net.cpp:165] Memory required for data: 27897868
I0529 14:44:57.047775 30229 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0529 14:44:57.047785 30229 net.cpp:100] Creating Layer res2a_branch2a_relu
I0529 14:44:57.047791 30229 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0529 14:44:57.047801 30229 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0529 14:44:57.047936 30229 net.cpp:150] Setting up res2a_branch2a_relu
I0529 14:44:57.047943 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.047946 30229 net.cpp:165] Memory required for data: 28700684
I0529 14:44:57.047950 30229 layer_factory.hpp:77] Creating layer res2a_branch2b
I0529 14:44:57.047963 30229 net.cpp:100] Creating Layer res2a_branch2b
I0529 14:44:57.047968 30229 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0529 14:44:57.047982 30229 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0529 14:44:57.049588 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0529 14:44:57.049830 30229 net.cpp:150] Setting up res2a_branch2b
I0529 14:44:57.049841 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.049845 30229 net.cpp:165] Memory required for data: 29503500
I0529 14:44:57.049856 30229 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0529 14:44:57.049870 30229 net.cpp:100] Creating Layer bn2a_branch2b
I0529 14:44:57.049875 30229 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0529 14:44:57.049886 30229 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0529 14:44:57.050132 30229 net.cpp:150] Setting up bn2a_branch2b
I0529 14:44:57.050138 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.050140 30229 net.cpp:165] Memory required for data: 30306316
I0529 14:44:57.050155 30229 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0529 14:44:57.050173 30229 net.cpp:100] Creating Layer scale2a_branch2b
I0529 14:44:57.050179 30229 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0529 14:44:57.050189 30229 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0529 14:44:57.050247 30229 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0529 14:44:57.050413 30229 net.cpp:150] Setting up scale2a_branch2b
I0529 14:44:57.050420 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.050422 30229 net.cpp:165] Memory required for data: 31109132
I0529 14:44:57.050432 30229 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0529 14:44:57.050441 30229 net.cpp:100] Creating Layer res2a_branch2b_relu
I0529 14:44:57.050446 30229 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0529 14:44:57.050456 30229 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0529 14:44:57.050828 30229 net.cpp:150] Setting up res2a_branch2b_relu
I0529 14:44:57.050837 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.050839 30229 net.cpp:165] Memory required for data: 31911948
I0529 14:44:57.050843 30229 layer_factory.hpp:77] Creating layer res2a_branch2c
I0529 14:44:57.050858 30229 net.cpp:100] Creating Layer res2a_branch2c
I0529 14:44:57.050864 30229 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0529 14:44:57.050879 30229 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0529 14:44:57.051771 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.051787 30229 net.cpp:150] Setting up res2a_branch2c
I0529 14:44:57.051795 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.051797 30229 net.cpp:165] Memory required for data: 35123212
I0529 14:44:57.051807 30229 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0529 14:44:57.051820 30229 net.cpp:100] Creating Layer bn2a_branch2c
I0529 14:44:57.051825 30229 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0529 14:44:57.051837 30229 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0529 14:44:57.052069 30229 net.cpp:150] Setting up bn2a_branch2c
I0529 14:44:57.052075 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.052078 30229 net.cpp:165] Memory required for data: 38334476
I0529 14:44:57.052093 30229 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0529 14:44:57.052104 30229 net.cpp:100] Creating Layer scale2a_branch2c
I0529 14:44:57.052110 30229 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0529 14:44:57.052120 30229 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0529 14:44:57.052176 30229 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0529 14:44:57.052333 30229 net.cpp:150] Setting up scale2a_branch2c
I0529 14:44:57.052340 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.052342 30229 net.cpp:165] Memory required for data: 41545740
I0529 14:44:57.052352 30229 layer_factory.hpp:77] Creating layer res2a
I0529 14:44:57.052362 30229 net.cpp:100] Creating Layer res2a
I0529 14:44:57.052367 30229 net.cpp:444] res2a <- res2a_branch1
I0529 14:44:57.052376 30229 net.cpp:444] res2a <- res2a_branch2c
I0529 14:44:57.052386 30229 net.cpp:418] res2a -> res2a
I0529 14:44:57.052422 30229 net.cpp:150] Setting up res2a
I0529 14:44:57.052429 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.052433 30229 net.cpp:165] Memory required for data: 44757004
I0529 14:44:57.052435 30229 layer_factory.hpp:77] Creating layer res2a_relu
I0529 14:44:57.052444 30229 net.cpp:100] Creating Layer res2a_relu
I0529 14:44:57.052448 30229 net.cpp:444] res2a_relu <- res2a
I0529 14:44:57.052459 30229 net.cpp:405] res2a_relu -> res2a (in-place)
I0529 14:44:57.052598 30229 net.cpp:150] Setting up res2a_relu
I0529 14:44:57.052604 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.052608 30229 net.cpp:165] Memory required for data: 47968268
I0529 14:44:57.052611 30229 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0529 14:44:57.052619 30229 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0529 14:44:57.052623 30229 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0529 14:44:57.052635 30229 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0529 14:44:57.052649 30229 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0529 14:44:57.052698 30229 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0529 14:44:57.052706 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.052709 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.052711 30229 net.cpp:165] Memory required for data: 54390796
I0529 14:44:57.052714 30229 layer_factory.hpp:77] Creating layer res2b_branch2a
I0529 14:44:57.052727 30229 net.cpp:100] Creating Layer res2b_branch2a
I0529 14:44:57.052732 30229 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0529 14:44:57.052744 30229 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0529 14:44:57.053637 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.053653 30229 net.cpp:150] Setting up res2b_branch2a
I0529 14:44:57.053660 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.053663 30229 net.cpp:165] Memory required for data: 55193612
I0529 14:44:57.053673 30229 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0529 14:44:57.053685 30229 net.cpp:100] Creating Layer bn2b_branch2a
I0529 14:44:57.053691 30229 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0529 14:44:57.053704 30229 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0529 14:44:57.053946 30229 net.cpp:150] Setting up bn2b_branch2a
I0529 14:44:57.053952 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.053956 30229 net.cpp:165] Memory required for data: 55996428
I0529 14:44:57.053980 30229 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0529 14:44:57.053994 30229 net.cpp:100] Creating Layer scale2b_branch2a
I0529 14:44:57.054000 30229 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0529 14:44:57.054011 30229 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0529 14:44:57.054069 30229 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0529 14:44:57.054234 30229 net.cpp:150] Setting up scale2b_branch2a
I0529 14:44:57.054240 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.054242 30229 net.cpp:165] Memory required for data: 56799244
I0529 14:44:57.054252 30229 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0529 14:44:57.054261 30229 net.cpp:100] Creating Layer res2b_branch2a_relu
I0529 14:44:57.054266 30229 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0529 14:44:57.054278 30229 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0529 14:44:57.054419 30229 net.cpp:150] Setting up res2b_branch2a_relu
I0529 14:44:57.054425 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.054427 30229 net.cpp:165] Memory required for data: 57602060
I0529 14:44:57.054431 30229 layer_factory.hpp:77] Creating layer res2b_branch2b
I0529 14:44:57.054445 30229 net.cpp:100] Creating Layer res2b_branch2b
I0529 14:44:57.054450 30229 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0529 14:44:57.054463 30229 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0529 14:44:57.055428 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0529 14:44:57.055444 30229 net.cpp:150] Setting up res2b_branch2b
I0529 14:44:57.055451 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.055454 30229 net.cpp:165] Memory required for data: 58404876
I0529 14:44:57.055464 30229 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0529 14:44:57.055477 30229 net.cpp:100] Creating Layer bn2b_branch2b
I0529 14:44:57.055483 30229 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0529 14:44:57.055495 30229 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0529 14:44:57.055742 30229 net.cpp:150] Setting up bn2b_branch2b
I0529 14:44:57.055748 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.055750 30229 net.cpp:165] Memory required for data: 59207692
I0529 14:44:57.055765 30229 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0529 14:44:57.055778 30229 net.cpp:100] Creating Layer scale2b_branch2b
I0529 14:44:57.055783 30229 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0529 14:44:57.055793 30229 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0529 14:44:57.055850 30229 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0529 14:44:57.056015 30229 net.cpp:150] Setting up scale2b_branch2b
I0529 14:44:57.056022 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.056025 30229 net.cpp:165] Memory required for data: 60010508
I0529 14:44:57.056035 30229 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0529 14:44:57.056044 30229 net.cpp:100] Creating Layer res2b_branch2b_relu
I0529 14:44:57.056049 30229 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0529 14:44:57.056059 30229 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0529 14:44:57.056483 30229 net.cpp:150] Setting up res2b_branch2b_relu
I0529 14:44:57.056491 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.056494 30229 net.cpp:165] Memory required for data: 60813324
I0529 14:44:57.056499 30229 layer_factory.hpp:77] Creating layer res2b_branch2c
I0529 14:44:57.056520 30229 net.cpp:100] Creating Layer res2b_branch2c
I0529 14:44:57.056527 30229 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0529 14:44:57.056541 30229 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0529 14:44:57.057514 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.057533 30229 net.cpp:150] Setting up res2b_branch2c
I0529 14:44:57.057541 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.057544 30229 net.cpp:165] Memory required for data: 64024588
I0529 14:44:57.057556 30229 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0529 14:44:57.057574 30229 net.cpp:100] Creating Layer bn2b_branch2c
I0529 14:44:57.057579 30229 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0529 14:44:57.057592 30229 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0529 14:44:57.057833 30229 net.cpp:150] Setting up bn2b_branch2c
I0529 14:44:57.057839 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.057842 30229 net.cpp:165] Memory required for data: 67235852
I0529 14:44:57.057857 30229 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0529 14:44:57.057870 30229 net.cpp:100] Creating Layer scale2b_branch2c
I0529 14:44:57.057875 30229 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0529 14:44:57.057888 30229 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0529 14:44:57.057945 30229 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0529 14:44:57.058109 30229 net.cpp:150] Setting up scale2b_branch2c
I0529 14:44:57.058115 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.058117 30229 net.cpp:165] Memory required for data: 70447116
I0529 14:44:57.058127 30229 layer_factory.hpp:77] Creating layer res2b
I0529 14:44:57.058137 30229 net.cpp:100] Creating Layer res2b
I0529 14:44:57.058142 30229 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0529 14:44:57.058151 30229 net.cpp:444] res2b <- res2b_branch2c
I0529 14:44:57.058161 30229 net.cpp:418] res2b -> res2b
I0529 14:44:57.058203 30229 net.cpp:150] Setting up res2b
I0529 14:44:57.058212 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.058215 30229 net.cpp:165] Memory required for data: 73658380
I0529 14:44:57.058218 30229 layer_factory.hpp:77] Creating layer res2b_relu
I0529 14:44:57.058228 30229 net.cpp:100] Creating Layer res2b_relu
I0529 14:44:57.058233 30229 net.cpp:444] res2b_relu <- res2b
I0529 14:44:57.058243 30229 net.cpp:405] res2b_relu -> res2b (in-place)
I0529 14:44:57.058392 30229 net.cpp:150] Setting up res2b_relu
I0529 14:44:57.058398 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.058399 30229 net.cpp:165] Memory required for data: 76869644
I0529 14:44:57.058403 30229 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0529 14:44:57.058413 30229 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0529 14:44:57.058418 30229 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0529 14:44:57.058429 30229 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0529 14:44:57.058441 30229 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0529 14:44:57.058492 30229 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0529 14:44:57.058501 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.058504 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.058506 30229 net.cpp:165] Memory required for data: 83292172
I0529 14:44:57.058509 30229 layer_factory.hpp:77] Creating layer res2c_branch2a
I0529 14:44:57.058522 30229 net.cpp:100] Creating Layer res2c_branch2a
I0529 14:44:57.058526 30229 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0529 14:44:57.058540 30229 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0529 14:44:57.059490 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.059506 30229 net.cpp:150] Setting up res2c_branch2a
I0529 14:44:57.059514 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.059516 30229 net.cpp:165] Memory required for data: 84094988
I0529 14:44:57.059525 30229 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0529 14:44:57.059540 30229 net.cpp:100] Creating Layer bn2c_branch2a
I0529 14:44:57.059545 30229 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0529 14:44:57.059556 30229 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0529 14:44:57.059805 30229 net.cpp:150] Setting up bn2c_branch2a
I0529 14:44:57.059811 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.059814 30229 net.cpp:165] Memory required for data: 84897804
I0529 14:44:57.059829 30229 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0529 14:44:57.059842 30229 net.cpp:100] Creating Layer scale2c_branch2a
I0529 14:44:57.059847 30229 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0529 14:44:57.059857 30229 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0529 14:44:57.059916 30229 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0529 14:44:57.060086 30229 net.cpp:150] Setting up scale2c_branch2a
I0529 14:44:57.060092 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.060096 30229 net.cpp:165] Memory required for data: 85700620
I0529 14:44:57.060104 30229 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0529 14:44:57.060114 30229 net.cpp:100] Creating Layer res2c_branch2a_relu
I0529 14:44:57.060119 30229 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0529 14:44:57.060129 30229 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0529 14:44:57.060269 30229 net.cpp:150] Setting up res2c_branch2a_relu
I0529 14:44:57.060276 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.060279 30229 net.cpp:165] Memory required for data: 86503436
I0529 14:44:57.060282 30229 layer_factory.hpp:77] Creating layer res2c_branch2b
I0529 14:44:57.060297 30229 net.cpp:100] Creating Layer res2c_branch2b
I0529 14:44:57.060302 30229 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0529 14:44:57.060314 30229 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0529 14:44:57.061277 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0529 14:44:57.061547 30229 net.cpp:150] Setting up res2c_branch2b
I0529 14:44:57.061556 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.061559 30229 net.cpp:165] Memory required for data: 87306252
I0529 14:44:57.061569 30229 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0529 14:44:57.061583 30229 net.cpp:100] Creating Layer bn2c_branch2b
I0529 14:44:57.061588 30229 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0529 14:44:57.061600 30229 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0529 14:44:57.061851 30229 net.cpp:150] Setting up bn2c_branch2b
I0529 14:44:57.061858 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.061861 30229 net.cpp:165] Memory required for data: 88109068
I0529 14:44:57.061874 30229 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0529 14:44:57.061885 30229 net.cpp:100] Creating Layer scale2c_branch2b
I0529 14:44:57.061892 30229 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0529 14:44:57.061902 30229 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0529 14:44:57.061960 30229 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0529 14:44:57.062129 30229 net.cpp:150] Setting up scale2c_branch2b
I0529 14:44:57.062136 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.062139 30229 net.cpp:165] Memory required for data: 88911884
I0529 14:44:57.062149 30229 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0529 14:44:57.062157 30229 net.cpp:100] Creating Layer res2c_branch2b_relu
I0529 14:44:57.062163 30229 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0529 14:44:57.062173 30229 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0529 14:44:57.062324 30229 net.cpp:150] Setting up res2c_branch2b_relu
I0529 14:44:57.062331 30229 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0529 14:44:57.062335 30229 net.cpp:165] Memory required for data: 89714700
I0529 14:44:57.062338 30229 layer_factory.hpp:77] Creating layer res2c_branch2c
I0529 14:44:57.062351 30229 net.cpp:100] Creating Layer res2c_branch2c
I0529 14:44:57.062357 30229 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0529 14:44:57.062371 30229 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0529 14:44:57.063274 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0529 14:44:57.063289 30229 net.cpp:150] Setting up res2c_branch2c
I0529 14:44:57.063297 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.063298 30229 net.cpp:165] Memory required for data: 92925964
I0529 14:44:57.063308 30229 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0529 14:44:57.063321 30229 net.cpp:100] Creating Layer bn2c_branch2c
I0529 14:44:57.063326 30229 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0529 14:44:57.063340 30229 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0529 14:44:57.063580 30229 net.cpp:150] Setting up bn2c_branch2c
I0529 14:44:57.063586 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.063590 30229 net.cpp:165] Memory required for data: 96137228
I0529 14:44:57.063621 30229 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0529 14:44:57.063634 30229 net.cpp:100] Creating Layer scale2c_branch2c
I0529 14:44:57.063640 30229 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0529 14:44:57.063650 30229 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0529 14:44:57.063707 30229 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0529 14:44:57.063863 30229 net.cpp:150] Setting up scale2c_branch2c
I0529 14:44:57.063870 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.063872 30229 net.cpp:165] Memory required for data: 99348492
I0529 14:44:57.063882 30229 layer_factory.hpp:77] Creating layer res2c
I0529 14:44:57.063892 30229 net.cpp:100] Creating Layer res2c
I0529 14:44:57.063897 30229 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0529 14:44:57.063905 30229 net.cpp:444] res2c <- res2c_branch2c
I0529 14:44:57.063915 30229 net.cpp:418] res2c -> res2c
I0529 14:44:57.063951 30229 net.cpp:150] Setting up res2c
I0529 14:44:57.063957 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.063959 30229 net.cpp:165] Memory required for data: 102559756
I0529 14:44:57.063963 30229 layer_factory.hpp:77] Creating layer res2c_relu
I0529 14:44:57.063972 30229 net.cpp:100] Creating Layer res2c_relu
I0529 14:44:57.063977 30229 net.cpp:444] res2c_relu <- res2c
I0529 14:44:57.063987 30229 net.cpp:405] res2c_relu -> res2c (in-place)
I0529 14:44:57.064363 30229 net.cpp:150] Setting up res2c_relu
I0529 14:44:57.064370 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.064373 30229 net.cpp:165] Memory required for data: 105771020
I0529 14:44:57.064378 30229 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0529 14:44:57.064388 30229 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0529 14:44:57.064393 30229 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0529 14:44:57.064405 30229 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0529 14:44:57.064419 30229 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0529 14:44:57.064473 30229 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0529 14:44:57.064481 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.064484 30229 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0529 14:44:57.064486 30229 net.cpp:165] Memory required for data: 112193548
I0529 14:44:57.064491 30229 layer_factory.hpp:77] Creating layer res3a_branch1
I0529 14:44:57.064503 30229 net.cpp:100] Creating Layer res3a_branch1
I0529 14:44:57.064509 30229 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0529 14:44:57.064523 30229 net.cpp:418] res3a_branch1 -> res3a_branch1
I0529 14:44:57.066323 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0529 14:44:57.066572 30229 net.cpp:150] Setting up res3a_branch1
I0529 14:44:57.066583 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.066586 30229 net.cpp:165] Memory required for data: 113799180
I0529 14:44:57.066598 30229 layer_factory.hpp:77] Creating layer bn3a_branch1
I0529 14:44:57.066613 30229 net.cpp:100] Creating Layer bn3a_branch1
I0529 14:44:57.066619 30229 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0529 14:44:57.066632 30229 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0529 14:44:57.067553 30229 net.cpp:150] Setting up bn3a_branch1
I0529 14:44:57.067562 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.067564 30229 net.cpp:165] Memory required for data: 115404812
I0529 14:44:57.067581 30229 layer_factory.hpp:77] Creating layer scale3a_branch1
I0529 14:44:57.067596 30229 net.cpp:100] Creating Layer scale3a_branch1
I0529 14:44:57.067601 30229 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0529 14:44:57.067612 30229 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0529 14:44:57.067674 30229 layer_factory.hpp:77] Creating layer scale3a_branch1
I0529 14:44:57.067829 30229 net.cpp:150] Setting up scale3a_branch1
I0529 14:44:57.067836 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.067839 30229 net.cpp:165] Memory required for data: 117010444
I0529 14:44:57.067849 30229 layer_factory.hpp:77] Creating layer res3a_branch2a
I0529 14:44:57.067864 30229 net.cpp:100] Creating Layer res3a_branch2a
I0529 14:44:57.067870 30229 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0529 14:44:57.067883 30229 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0529 14:44:57.068858 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0529 14:44:57.068879 30229 net.cpp:150] Setting up res3a_branch2a
I0529 14:44:57.068887 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.068889 30229 net.cpp:165] Memory required for data: 117411852
I0529 14:44:57.068899 30229 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0529 14:44:57.068922 30229 net.cpp:100] Creating Layer bn3a_branch2a
I0529 14:44:57.068930 30229 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0529 14:44:57.068946 30229 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0529 14:44:57.069193 30229 net.cpp:150] Setting up bn3a_branch2a
I0529 14:44:57.069200 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.069202 30229 net.cpp:165] Memory required for data: 117813260
I0529 14:44:57.069216 30229 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0529 14:44:57.069229 30229 net.cpp:100] Creating Layer scale3a_branch2a
I0529 14:44:57.069236 30229 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0529 14:44:57.069245 30229 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0529 14:44:57.069304 30229 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0529 14:44:57.069468 30229 net.cpp:150] Setting up scale3a_branch2a
I0529 14:44:57.069475 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.069478 30229 net.cpp:165] Memory required for data: 118214668
I0529 14:44:57.069488 30229 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0529 14:44:57.069499 30229 net.cpp:100] Creating Layer res3a_branch2a_relu
I0529 14:44:57.069504 30229 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0529 14:44:57.069514 30229 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0529 14:44:57.069900 30229 net.cpp:150] Setting up res3a_branch2a_relu
I0529 14:44:57.069908 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.069911 30229 net.cpp:165] Memory required for data: 118616076
I0529 14:44:57.069916 30229 layer_factory.hpp:77] Creating layer res3a_branch2b
I0529 14:44:57.069929 30229 net.cpp:100] Creating Layer res3a_branch2b
I0529 14:44:57.069936 30229 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0529 14:44:57.069949 30229 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0529 14:44:57.071123 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 14:44:57.071378 30229 net.cpp:150] Setting up res3a_branch2b
I0529 14:44:57.071393 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.071395 30229 net.cpp:165] Memory required for data: 119017484
I0529 14:44:57.071408 30229 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0529 14:44:57.071421 30229 net.cpp:100] Creating Layer bn3a_branch2b
I0529 14:44:57.071426 30229 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0529 14:44:57.071440 30229 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0529 14:44:57.071689 30229 net.cpp:150] Setting up bn3a_branch2b
I0529 14:44:57.071696 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.071697 30229 net.cpp:165] Memory required for data: 119418892
I0529 14:44:57.071712 30229 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0529 14:44:57.071725 30229 net.cpp:100] Creating Layer scale3a_branch2b
I0529 14:44:57.071730 30229 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0529 14:44:57.071741 30229 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0529 14:44:57.071800 30229 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0529 14:44:57.071957 30229 net.cpp:150] Setting up scale3a_branch2b
I0529 14:44:57.071964 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.071966 30229 net.cpp:165] Memory required for data: 119820300
I0529 14:44:57.071976 30229 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0529 14:44:57.071986 30229 net.cpp:100] Creating Layer res3a_branch2b_relu
I0529 14:44:57.071990 30229 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0529 14:44:57.072000 30229 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0529 14:44:57.072142 30229 net.cpp:150] Setting up res3a_branch2b_relu
I0529 14:44:57.072149 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.072150 30229 net.cpp:165] Memory required for data: 120221708
I0529 14:44:57.072154 30229 layer_factory.hpp:77] Creating layer res3a_branch2c
I0529 14:44:57.072168 30229 net.cpp:100] Creating Layer res3a_branch2c
I0529 14:44:57.072172 30229 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0529 14:44:57.072185 30229 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0529 14:44:57.073225 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.073241 30229 net.cpp:150] Setting up res3a_branch2c
I0529 14:44:57.073248 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.073251 30229 net.cpp:165] Memory required for data: 121827340
I0529 14:44:57.073262 30229 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0529 14:44:57.073290 30229 net.cpp:100] Creating Layer bn3a_branch2c
I0529 14:44:57.073297 30229 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0529 14:44:57.073309 30229 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0529 14:44:57.073560 30229 net.cpp:150] Setting up bn3a_branch2c
I0529 14:44:57.073567 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.073570 30229 net.cpp:165] Memory required for data: 123432972
I0529 14:44:57.073585 30229 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0529 14:44:57.073598 30229 net.cpp:100] Creating Layer scale3a_branch2c
I0529 14:44:57.073604 30229 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0529 14:44:57.073614 30229 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0529 14:44:57.073675 30229 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0529 14:44:57.073835 30229 net.cpp:150] Setting up scale3a_branch2c
I0529 14:44:57.073843 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.073845 30229 net.cpp:165] Memory required for data: 125038604
I0529 14:44:57.073855 30229 layer_factory.hpp:77] Creating layer res3a
I0529 14:44:57.073866 30229 net.cpp:100] Creating Layer res3a
I0529 14:44:57.073873 30229 net.cpp:444] res3a <- res3a_branch1
I0529 14:44:57.073880 30229 net.cpp:444] res3a <- res3a_branch2c
I0529 14:44:57.073889 30229 net.cpp:418] res3a -> res3a
I0529 14:44:57.073927 30229 net.cpp:150] Setting up res3a
I0529 14:44:57.073935 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.073938 30229 net.cpp:165] Memory required for data: 126644236
I0529 14:44:57.073941 30229 layer_factory.hpp:77] Creating layer res3a_relu
I0529 14:44:57.073949 30229 net.cpp:100] Creating Layer res3a_relu
I0529 14:44:57.073954 30229 net.cpp:444] res3a_relu <- res3a
I0529 14:44:57.073963 30229 net.cpp:405] res3a_relu -> res3a (in-place)
I0529 14:44:57.074450 30229 net.cpp:150] Setting up res3a_relu
I0529 14:44:57.074458 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.074462 30229 net.cpp:165] Memory required for data: 128249868
I0529 14:44:57.074466 30229 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0529 14:44:57.074476 30229 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0529 14:44:57.074481 30229 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0529 14:44:57.074496 30229 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0529 14:44:57.074510 30229 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0529 14:44:57.074566 30229 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0529 14:44:57.074574 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.074579 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.074580 30229 net.cpp:165] Memory required for data: 131461132
I0529 14:44:57.074584 30229 layer_factory.hpp:77] Creating layer res3b_branch2a
I0529 14:44:57.074599 30229 net.cpp:100] Creating Layer res3b_branch2a
I0529 14:44:57.074604 30229 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0529 14:44:57.074617 30229 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0529 14:44:57.075652 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.075666 30229 net.cpp:150] Setting up res3b_branch2a
I0529 14:44:57.075676 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.075680 30229 net.cpp:165] Memory required for data: 131862540
I0529 14:44:57.075690 30229 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0529 14:44:57.075702 30229 net.cpp:100] Creating Layer bn3b_branch2a
I0529 14:44:57.075708 30229 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0529 14:44:57.075721 30229 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0529 14:44:57.075966 30229 net.cpp:150] Setting up bn3b_branch2a
I0529 14:44:57.075973 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.075975 30229 net.cpp:165] Memory required for data: 132263948
I0529 14:44:57.075990 30229 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0529 14:44:57.076004 30229 net.cpp:100] Creating Layer scale3b_branch2a
I0529 14:44:57.076009 30229 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0529 14:44:57.076020 30229 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0529 14:44:57.076079 30229 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0529 14:44:57.076236 30229 net.cpp:150] Setting up scale3b_branch2a
I0529 14:44:57.076243 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.076246 30229 net.cpp:165] Memory required for data: 132665356
I0529 14:44:57.076256 30229 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0529 14:44:57.076265 30229 net.cpp:100] Creating Layer res3b_branch2a_relu
I0529 14:44:57.076272 30229 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0529 14:44:57.076280 30229 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0529 14:44:57.076421 30229 net.cpp:150] Setting up res3b_branch2a_relu
I0529 14:44:57.076427 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.076431 30229 net.cpp:165] Memory required for data: 133066764
I0529 14:44:57.076434 30229 layer_factory.hpp:77] Creating layer res3b_branch2b
I0529 14:44:57.076447 30229 net.cpp:100] Creating Layer res3b_branch2b
I0529 14:44:57.076452 30229 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0529 14:44:57.076465 30229 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0529 14:44:57.077646 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 14:44:57.077898 30229 net.cpp:150] Setting up res3b_branch2b
I0529 14:44:57.077908 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.077910 30229 net.cpp:165] Memory required for data: 133468172
I0529 14:44:57.077921 30229 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0529 14:44:57.077935 30229 net.cpp:100] Creating Layer bn3b_branch2b
I0529 14:44:57.077941 30229 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0529 14:44:57.077953 30229 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0529 14:44:57.078212 30229 net.cpp:150] Setting up bn3b_branch2b
I0529 14:44:57.078218 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.078220 30229 net.cpp:165] Memory required for data: 133869580
I0529 14:44:57.078235 30229 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0529 14:44:57.078248 30229 net.cpp:100] Creating Layer scale3b_branch2b
I0529 14:44:57.078254 30229 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0529 14:44:57.078264 30229 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0529 14:44:57.078325 30229 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0529 14:44:57.078483 30229 net.cpp:150] Setting up scale3b_branch2b
I0529 14:44:57.078490 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.078493 30229 net.cpp:165] Memory required for data: 134270988
I0529 14:44:57.078503 30229 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0529 14:44:57.078514 30229 net.cpp:100] Creating Layer res3b_branch2b_relu
I0529 14:44:57.078519 30229 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0529 14:44:57.078529 30229 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0529 14:44:57.078675 30229 net.cpp:150] Setting up res3b_branch2b_relu
I0529 14:44:57.078681 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.078685 30229 net.cpp:165] Memory required for data: 134672396
I0529 14:44:57.078688 30229 layer_factory.hpp:77] Creating layer res3b_branch2c
I0529 14:44:57.078701 30229 net.cpp:100] Creating Layer res3b_branch2c
I0529 14:44:57.078706 30229 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0529 14:44:57.078719 30229 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0529 14:44:57.079736 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.079751 30229 net.cpp:150] Setting up res3b_branch2c
I0529 14:44:57.079758 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.079761 30229 net.cpp:165] Memory required for data: 136278028
I0529 14:44:57.079771 30229 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0529 14:44:57.079783 30229 net.cpp:100] Creating Layer bn3b_branch2c
I0529 14:44:57.079789 30229 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0529 14:44:57.079802 30229 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0529 14:44:57.080051 30229 net.cpp:150] Setting up bn3b_branch2c
I0529 14:44:57.080057 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.080060 30229 net.cpp:165] Memory required for data: 137883660
I0529 14:44:57.080075 30229 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0529 14:44:57.080087 30229 net.cpp:100] Creating Layer scale3b_branch2c
I0529 14:44:57.080092 30229 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0529 14:44:57.080103 30229 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0529 14:44:57.080163 30229 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0529 14:44:57.080320 30229 net.cpp:150] Setting up scale3b_branch2c
I0529 14:44:57.080327 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.080330 30229 net.cpp:165] Memory required for data: 139489292
I0529 14:44:57.080340 30229 layer_factory.hpp:77] Creating layer res3b
I0529 14:44:57.080350 30229 net.cpp:100] Creating Layer res3b
I0529 14:44:57.080356 30229 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0529 14:44:57.080364 30229 net.cpp:444] res3b <- res3b_branch2c
I0529 14:44:57.080373 30229 net.cpp:418] res3b -> res3b
I0529 14:44:57.080410 30229 net.cpp:150] Setting up res3b
I0529 14:44:57.080417 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.080420 30229 net.cpp:165] Memory required for data: 141094924
I0529 14:44:57.080423 30229 layer_factory.hpp:77] Creating layer res3b_relu
I0529 14:44:57.080432 30229 net.cpp:100] Creating Layer res3b_relu
I0529 14:44:57.080437 30229 net.cpp:444] res3b_relu <- res3b
I0529 14:44:57.080447 30229 net.cpp:405] res3b_relu -> res3b (in-place)
I0529 14:44:57.080837 30229 net.cpp:150] Setting up res3b_relu
I0529 14:44:57.080844 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.080847 30229 net.cpp:165] Memory required for data: 142700556
I0529 14:44:57.080852 30229 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0529 14:44:57.080862 30229 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0529 14:44:57.080866 30229 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0529 14:44:57.080879 30229 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0529 14:44:57.080894 30229 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0529 14:44:57.080966 30229 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0529 14:44:57.080974 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.080978 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.080981 30229 net.cpp:165] Memory required for data: 145911820
I0529 14:44:57.080984 30229 layer_factory.hpp:77] Creating layer res3c_branch2a
I0529 14:44:57.080997 30229 net.cpp:100] Creating Layer res3c_branch2a
I0529 14:44:57.081001 30229 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0529 14:44:57.081015 30229 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0529 14:44:57.082024 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.082039 30229 net.cpp:150] Setting up res3c_branch2a
I0529 14:44:57.082046 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.082049 30229 net.cpp:165] Memory required for data: 146313228
I0529 14:44:57.082059 30229 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0529 14:44:57.082072 30229 net.cpp:100] Creating Layer bn3c_branch2a
I0529 14:44:57.082077 30229 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0529 14:44:57.082090 30229 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0529 14:44:57.082340 30229 net.cpp:150] Setting up bn3c_branch2a
I0529 14:44:57.082345 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.082348 30229 net.cpp:165] Memory required for data: 146714636
I0529 14:44:57.082362 30229 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0529 14:44:57.082376 30229 net.cpp:100] Creating Layer scale3c_branch2a
I0529 14:44:57.082381 30229 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0529 14:44:57.082391 30229 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0529 14:44:57.082449 30229 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0529 14:44:57.082604 30229 net.cpp:150] Setting up scale3c_branch2a
I0529 14:44:57.082612 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.082614 30229 net.cpp:165] Memory required for data: 147116044
I0529 14:44:57.082624 30229 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0529 14:44:57.082633 30229 net.cpp:100] Creating Layer res3c_branch2a_relu
I0529 14:44:57.082638 30229 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0529 14:44:57.082649 30229 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0529 14:44:57.082794 30229 net.cpp:150] Setting up res3c_branch2a_relu
I0529 14:44:57.082801 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.082804 30229 net.cpp:165] Memory required for data: 147517452
I0529 14:44:57.082808 30229 layer_factory.hpp:77] Creating layer res3c_branch2b
I0529 14:44:57.082820 30229 net.cpp:100] Creating Layer res3c_branch2b
I0529 14:44:57.082825 30229 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0529 14:44:57.082839 30229 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0529 14:44:57.084673 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 14:44:57.084935 30229 net.cpp:150] Setting up res3c_branch2b
I0529 14:44:57.084949 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.084952 30229 net.cpp:165] Memory required for data: 147918860
I0529 14:44:57.084964 30229 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0529 14:44:57.084976 30229 net.cpp:100] Creating Layer bn3c_branch2b
I0529 14:44:57.084981 30229 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0529 14:44:57.084995 30229 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0529 14:44:57.085252 30229 net.cpp:150] Setting up bn3c_branch2b
I0529 14:44:57.085258 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.085261 30229 net.cpp:165] Memory required for data: 148320268
I0529 14:44:57.085275 30229 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0529 14:44:57.085286 30229 net.cpp:100] Creating Layer scale3c_branch2b
I0529 14:44:57.085290 30229 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0529 14:44:57.085301 30229 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0529 14:44:57.085361 30229 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0529 14:44:57.085520 30229 net.cpp:150] Setting up scale3c_branch2b
I0529 14:44:57.085526 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.085528 30229 net.cpp:165] Memory required for data: 148721676
I0529 14:44:57.085538 30229 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0529 14:44:57.085546 30229 net.cpp:100] Creating Layer res3c_branch2b_relu
I0529 14:44:57.085551 30229 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0529 14:44:57.085562 30229 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0529 14:44:57.085711 30229 net.cpp:150] Setting up res3c_branch2b_relu
I0529 14:44:57.085718 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.085721 30229 net.cpp:165] Memory required for data: 149123084
I0529 14:44:57.085724 30229 layer_factory.hpp:77] Creating layer res3c_branch2c
I0529 14:44:57.085737 30229 net.cpp:100] Creating Layer res3c_branch2c
I0529 14:44:57.085742 30229 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0529 14:44:57.085757 30229 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0529 14:44:57.086787 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.086802 30229 net.cpp:150] Setting up res3c_branch2c
I0529 14:44:57.086809 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.086812 30229 net.cpp:165] Memory required for data: 150728716
I0529 14:44:57.086822 30229 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0529 14:44:57.086835 30229 net.cpp:100] Creating Layer bn3c_branch2c
I0529 14:44:57.086840 30229 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0529 14:44:57.086854 30229 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0529 14:44:57.087106 30229 net.cpp:150] Setting up bn3c_branch2c
I0529 14:44:57.087112 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.087115 30229 net.cpp:165] Memory required for data: 152334348
I0529 14:44:57.087128 30229 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0529 14:44:57.087141 30229 net.cpp:100] Creating Layer scale3c_branch2c
I0529 14:44:57.087146 30229 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0529 14:44:57.087158 30229 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0529 14:44:57.087218 30229 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0529 14:44:57.087378 30229 net.cpp:150] Setting up scale3c_branch2c
I0529 14:44:57.087384 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.087388 30229 net.cpp:165] Memory required for data: 153939980
I0529 14:44:57.087397 30229 layer_factory.hpp:77] Creating layer res3c
I0529 14:44:57.087406 30229 net.cpp:100] Creating Layer res3c
I0529 14:44:57.087412 30229 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0529 14:44:57.087420 30229 net.cpp:444] res3c <- res3c_branch2c
I0529 14:44:57.087430 30229 net.cpp:418] res3c -> res3c
I0529 14:44:57.087467 30229 net.cpp:150] Setting up res3c
I0529 14:44:57.087476 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.087477 30229 net.cpp:165] Memory required for data: 155545612
I0529 14:44:57.087481 30229 layer_factory.hpp:77] Creating layer res3c_relu
I0529 14:44:57.087489 30229 net.cpp:100] Creating Layer res3c_relu
I0529 14:44:57.087494 30229 net.cpp:444] res3c_relu <- res3c
I0529 14:44:57.087503 30229 net.cpp:405] res3c_relu -> res3c (in-place)
I0529 14:44:57.087647 30229 net.cpp:150] Setting up res3c_relu
I0529 14:44:57.087654 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.087657 30229 net.cpp:165] Memory required for data: 157151244
I0529 14:44:57.087661 30229 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0529 14:44:57.087669 30229 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0529 14:44:57.087674 30229 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0529 14:44:57.087685 30229 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0529 14:44:57.087699 30229 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0529 14:44:57.087754 30229 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0529 14:44:57.087761 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.087765 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.087767 30229 net.cpp:165] Memory required for data: 160362508
I0529 14:44:57.087770 30229 layer_factory.hpp:77] Creating layer res3d_branch2a
I0529 14:44:57.087783 30229 net.cpp:100] Creating Layer res3d_branch2a
I0529 14:44:57.087788 30229 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0529 14:44:57.087801 30229 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0529 14:44:57.089517 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.089532 30229 net.cpp:150] Setting up res3d_branch2a
I0529 14:44:57.089540 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.089542 30229 net.cpp:165] Memory required for data: 160763916
I0529 14:44:57.089553 30229 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0529 14:44:57.089566 30229 net.cpp:100] Creating Layer bn3d_branch2a
I0529 14:44:57.089571 30229 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0529 14:44:57.089584 30229 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0529 14:44:57.089841 30229 net.cpp:150] Setting up bn3d_branch2a
I0529 14:44:57.089848 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.089850 30229 net.cpp:165] Memory required for data: 161165324
I0529 14:44:57.089889 30229 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0529 14:44:57.089902 30229 net.cpp:100] Creating Layer scale3d_branch2a
I0529 14:44:57.089910 30229 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0529 14:44:57.089920 30229 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0529 14:44:57.089982 30229 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0529 14:44:57.090143 30229 net.cpp:150] Setting up scale3d_branch2a
I0529 14:44:57.090150 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.090153 30229 net.cpp:165] Memory required for data: 161566732
I0529 14:44:57.090162 30229 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0529 14:44:57.090173 30229 net.cpp:100] Creating Layer res3d_branch2a_relu
I0529 14:44:57.090178 30229 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0529 14:44:57.090188 30229 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0529 14:44:57.090581 30229 net.cpp:150] Setting up res3d_branch2a_relu
I0529 14:44:57.090590 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.090593 30229 net.cpp:165] Memory required for data: 161968140
I0529 14:44:57.090597 30229 layer_factory.hpp:77] Creating layer res3d_branch2b
I0529 14:44:57.090611 30229 net.cpp:100] Creating Layer res3d_branch2b
I0529 14:44:57.090617 30229 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0529 14:44:57.090632 30229 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0529 14:44:57.091776 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 14:44:57.092027 30229 net.cpp:150] Setting up res3d_branch2b
I0529 14:44:57.092038 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.092041 30229 net.cpp:165] Memory required for data: 162369548
I0529 14:44:57.092052 30229 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0529 14:44:57.092067 30229 net.cpp:100] Creating Layer bn3d_branch2b
I0529 14:44:57.092072 30229 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0529 14:44:57.092085 30229 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0529 14:44:57.092347 30229 net.cpp:150] Setting up bn3d_branch2b
I0529 14:44:57.092353 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.092357 30229 net.cpp:165] Memory required for data: 162770956
I0529 14:44:57.092371 30229 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0529 14:44:57.092384 30229 net.cpp:100] Creating Layer scale3d_branch2b
I0529 14:44:57.092389 30229 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0529 14:44:57.092399 30229 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0529 14:44:57.092460 30229 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0529 14:44:57.092623 30229 net.cpp:150] Setting up scale3d_branch2b
I0529 14:44:57.092631 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.092634 30229 net.cpp:165] Memory required for data: 163172364
I0529 14:44:57.092644 30229 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0529 14:44:57.092653 30229 net.cpp:100] Creating Layer res3d_branch2b_relu
I0529 14:44:57.092658 30229 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0529 14:44:57.092669 30229 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0529 14:44:57.092815 30229 net.cpp:150] Setting up res3d_branch2b_relu
I0529 14:44:57.092823 30229 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0529 14:44:57.092825 30229 net.cpp:165] Memory required for data: 163573772
I0529 14:44:57.092829 30229 layer_factory.hpp:77] Creating layer res3d_branch2c
I0529 14:44:57.092841 30229 net.cpp:100] Creating Layer res3d_branch2c
I0529 14:44:57.092846 30229 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0529 14:44:57.092861 30229 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0529 14:44:57.093914 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0529 14:44:57.093928 30229 net.cpp:150] Setting up res3d_branch2c
I0529 14:44:57.093935 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.093938 30229 net.cpp:165] Memory required for data: 165179404
I0529 14:44:57.093948 30229 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0529 14:44:57.093962 30229 net.cpp:100] Creating Layer bn3d_branch2c
I0529 14:44:57.093967 30229 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0529 14:44:57.093979 30229 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0529 14:44:57.094233 30229 net.cpp:150] Setting up bn3d_branch2c
I0529 14:44:57.094240 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.094244 30229 net.cpp:165] Memory required for data: 166785036
I0529 14:44:57.094257 30229 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0529 14:44:57.094270 30229 net.cpp:100] Creating Layer scale3d_branch2c
I0529 14:44:57.094276 30229 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0529 14:44:57.094287 30229 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0529 14:44:57.094348 30229 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0529 14:44:57.094507 30229 net.cpp:150] Setting up scale3d_branch2c
I0529 14:44:57.094514 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.094516 30229 net.cpp:165] Memory required for data: 168390668
I0529 14:44:57.094527 30229 layer_factory.hpp:77] Creating layer res3d
I0529 14:44:57.094538 30229 net.cpp:100] Creating Layer res3d
I0529 14:44:57.094543 30229 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0529 14:44:57.094552 30229 net.cpp:444] res3d <- res3d_branch2c
I0529 14:44:57.094560 30229 net.cpp:418] res3d -> res3d
I0529 14:44:57.094597 30229 net.cpp:150] Setting up res3d
I0529 14:44:57.094604 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.094607 30229 net.cpp:165] Memory required for data: 169996300
I0529 14:44:57.094611 30229 layer_factory.hpp:77] Creating layer res3d_relu
I0529 14:44:57.094620 30229 net.cpp:100] Creating Layer res3d_relu
I0529 14:44:57.094625 30229 net.cpp:444] res3d_relu <- res3d
I0529 14:44:57.094635 30229 net.cpp:405] res3d_relu -> res3d (in-place)
I0529 14:44:57.094780 30229 net.cpp:150] Setting up res3d_relu
I0529 14:44:57.094787 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.094789 30229 net.cpp:165] Memory required for data: 171601932
I0529 14:44:57.094794 30229 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0529 14:44:57.094801 30229 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0529 14:44:57.094807 30229 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0529 14:44:57.094817 30229 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0529 14:44:57.094830 30229 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0529 14:44:57.094883 30229 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0529 14:44:57.094892 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.094897 30229 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0529 14:44:57.094898 30229 net.cpp:165] Memory required for data: 174813196
I0529 14:44:57.094902 30229 layer_factory.hpp:77] Creating layer res4a_branch1
I0529 14:44:57.094913 30229 net.cpp:100] Creating Layer res4a_branch1
I0529 14:44:57.094918 30229 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0529 14:44:57.094931 30229 net.cpp:418] res4a_branch1 -> res4a_branch1
I0529 14:44:57.097301 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7416
I0529 14:44:57.097326 30229 net.cpp:150] Setting up res4a_branch1
I0529 14:44:57.097333 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.097337 30229 net.cpp:165] Memory required for data: 175616012
I0529 14:44:57.097347 30229 layer_factory.hpp:77] Creating layer bn4a_branch1
I0529 14:44:57.097362 30229 net.cpp:100] Creating Layer bn4a_branch1
I0529 14:44:57.097368 30229 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0529 14:44:57.097381 30229 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0529 14:44:57.097653 30229 net.cpp:150] Setting up bn4a_branch1
I0529 14:44:57.097661 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.097662 30229 net.cpp:165] Memory required for data: 176418828
I0529 14:44:57.097676 30229 layer_factory.hpp:77] Creating layer scale4a_branch1
I0529 14:44:57.097689 30229 net.cpp:100] Creating Layer scale4a_branch1
I0529 14:44:57.097694 30229 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0529 14:44:57.097705 30229 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0529 14:44:57.097762 30229 layer_factory.hpp:77] Creating layer scale4a_branch1
I0529 14:44:57.097930 30229 net.cpp:150] Setting up scale4a_branch1
I0529 14:44:57.097937 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.097939 30229 net.cpp:165] Memory required for data: 177221644
I0529 14:44:57.097949 30229 layer_factory.hpp:77] Creating layer res4a_branch2a
I0529 14:44:57.097964 30229 net.cpp:100] Creating Layer res4a_branch2a
I0529 14:44:57.097970 30229 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0529 14:44:57.097981 30229 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0529 14:44:57.099097 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7032
I0529 14:44:57.099115 30229 net.cpp:150] Setting up res4a_branch2a
I0529 14:44:57.099123 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.099126 30229 net.cpp:165] Memory required for data: 177422348
I0529 14:44:57.099135 30229 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0529 14:44:57.099148 30229 net.cpp:100] Creating Layer bn4a_branch2a
I0529 14:44:57.099154 30229 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0529 14:44:57.099167 30229 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0529 14:44:57.099423 30229 net.cpp:150] Setting up bn4a_branch2a
I0529 14:44:57.099431 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.099433 30229 net.cpp:165] Memory required for data: 177623052
I0529 14:44:57.099448 30229 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0529 14:44:57.099459 30229 net.cpp:100] Creating Layer scale4a_branch2a
I0529 14:44:57.099464 30229 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0529 14:44:57.099476 30229 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0529 14:44:57.099537 30229 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0529 14:44:57.099699 30229 net.cpp:150] Setting up scale4a_branch2a
I0529 14:44:57.099704 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.099707 30229 net.cpp:165] Memory required for data: 177823756
I0529 14:44:57.099717 30229 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0529 14:44:57.099727 30229 net.cpp:100] Creating Layer res4a_branch2a_relu
I0529 14:44:57.099732 30229 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0529 14:44:57.099742 30229 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0529 14:44:57.100134 30229 net.cpp:150] Setting up res4a_branch2a_relu
I0529 14:44:57.100143 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.100145 30229 net.cpp:165] Memory required for data: 178024460
I0529 14:44:57.100150 30229 layer_factory.hpp:77] Creating layer res4a_branch2b
I0529 14:44:57.100164 30229 net.cpp:100] Creating Layer res4a_branch2b
I0529 14:44:57.100170 30229 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0529 14:44:57.100185 30229 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0529 14:44:57.102740 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 14:44:57.103001 30229 net.cpp:150] Setting up res4a_branch2b
I0529 14:44:57.103013 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.103015 30229 net.cpp:165] Memory required for data: 178225164
I0529 14:44:57.103029 30229 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0529 14:44:57.103044 30229 net.cpp:100] Creating Layer bn4a_branch2b
I0529 14:44:57.103051 30229 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0529 14:44:57.103065 30229 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0529 14:44:57.103332 30229 net.cpp:150] Setting up bn4a_branch2b
I0529 14:44:57.103338 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.103340 30229 net.cpp:165] Memory required for data: 178425868
I0529 14:44:57.103355 30229 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0529 14:44:57.103368 30229 net.cpp:100] Creating Layer scale4a_branch2b
I0529 14:44:57.103374 30229 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0529 14:44:57.103384 30229 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0529 14:44:57.103446 30229 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0529 14:44:57.103608 30229 net.cpp:150] Setting up scale4a_branch2b
I0529 14:44:57.103615 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.103617 30229 net.cpp:165] Memory required for data: 178626572
I0529 14:44:57.103626 30229 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0529 14:44:57.103637 30229 net.cpp:100] Creating Layer res4a_branch2b_relu
I0529 14:44:57.103642 30229 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0529 14:44:57.103652 30229 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0529 14:44:57.103811 30229 net.cpp:150] Setting up res4a_branch2b_relu
I0529 14:44:57.103818 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.103821 30229 net.cpp:165] Memory required for data: 178827276
I0529 14:44:57.103824 30229 layer_factory.hpp:77] Creating layer res4a_branch2c
I0529 14:44:57.103838 30229 net.cpp:100] Creating Layer res4a_branch2c
I0529 14:44:57.103844 30229 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0529 14:44:57.103857 30229 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0529 14:44:57.106043 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.106070 30229 net.cpp:150] Setting up res4a_branch2c
I0529 14:44:57.106082 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.106084 30229 net.cpp:165] Memory required for data: 179630092
I0529 14:44:57.106101 30229 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0529 14:44:57.106122 30229 net.cpp:100] Creating Layer bn4a_branch2c
I0529 14:44:57.106130 30229 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0529 14:44:57.106146 30229 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0529 14:44:57.106429 30229 net.cpp:150] Setting up bn4a_branch2c
I0529 14:44:57.106436 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.106438 30229 net.cpp:165] Memory required for data: 180432908
I0529 14:44:57.106452 30229 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0529 14:44:57.106467 30229 net.cpp:100] Creating Layer scale4a_branch2c
I0529 14:44:57.106472 30229 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0529 14:44:57.106484 30229 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0529 14:44:57.106545 30229 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0529 14:44:57.106722 30229 net.cpp:150] Setting up scale4a_branch2c
I0529 14:44:57.106729 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.106731 30229 net.cpp:165] Memory required for data: 181235724
I0529 14:44:57.106741 30229 layer_factory.hpp:77] Creating layer res4a
I0529 14:44:57.106751 30229 net.cpp:100] Creating Layer res4a
I0529 14:44:57.106756 30229 net.cpp:444] res4a <- res4a_branch1
I0529 14:44:57.106765 30229 net.cpp:444] res4a <- res4a_branch2c
I0529 14:44:57.106773 30229 net.cpp:418] res4a -> res4a
I0529 14:44:57.106814 30229 net.cpp:150] Setting up res4a
I0529 14:44:57.106822 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.106825 30229 net.cpp:165] Memory required for data: 182038540
I0529 14:44:57.106828 30229 layer_factory.hpp:77] Creating layer res4a_relu
I0529 14:44:57.106837 30229 net.cpp:100] Creating Layer res4a_relu
I0529 14:44:57.106842 30229 net.cpp:444] res4a_relu <- res4a
I0529 14:44:57.106853 30229 net.cpp:405] res4a_relu -> res4a (in-place)
I0529 14:44:57.107281 30229 net.cpp:150] Setting up res4a_relu
I0529 14:44:57.107290 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.107292 30229 net.cpp:165] Memory required for data: 182841356
I0529 14:44:57.107297 30229 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0529 14:44:57.107307 30229 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0529 14:44:57.107313 30229 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0529 14:44:57.107326 30229 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0529 14:44:57.107339 30229 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0529 14:44:57.107401 30229 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0529 14:44:57.107409 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.107414 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.107416 30229 net.cpp:165] Memory required for data: 184446988
I0529 14:44:57.107419 30229 layer_factory.hpp:77] Creating layer res4b_branch2a
I0529 14:44:57.107451 30229 net.cpp:100] Creating Layer res4b_branch2a
I0529 14:44:57.107457 30229 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0529 14:44:57.107471 30229 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0529 14:44:57.108868 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.108894 30229 net.cpp:150] Setting up res4b_branch2a
I0529 14:44:57.108903 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.108906 30229 net.cpp:165] Memory required for data: 184647692
I0529 14:44:57.108935 30229 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0529 14:44:57.108958 30229 net.cpp:100] Creating Layer bn4b_branch2a
I0529 14:44:57.108965 30229 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0529 14:44:57.108978 30229 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0529 14:44:57.109253 30229 net.cpp:150] Setting up bn4b_branch2a
I0529 14:44:57.109259 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.109262 30229 net.cpp:165] Memory required for data: 184848396
I0529 14:44:57.109278 30229 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0529 14:44:57.109292 30229 net.cpp:100] Creating Layer scale4b_branch2a
I0529 14:44:57.109298 30229 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0529 14:44:57.109309 30229 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0529 14:44:57.109374 30229 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0529 14:44:57.109539 30229 net.cpp:150] Setting up scale4b_branch2a
I0529 14:44:57.109546 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.109549 30229 net.cpp:165] Memory required for data: 185049100
I0529 14:44:57.109558 30229 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0529 14:44:57.109568 30229 net.cpp:100] Creating Layer res4b_branch2a_relu
I0529 14:44:57.109573 30229 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0529 14:44:57.109583 30229 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0529 14:44:57.109993 30229 net.cpp:150] Setting up res4b_branch2a_relu
I0529 14:44:57.110002 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.110004 30229 net.cpp:165] Memory required for data: 185249804
I0529 14:44:57.110008 30229 layer_factory.hpp:77] Creating layer res4b_branch2b
I0529 14:44:57.110024 30229 net.cpp:100] Creating Layer res4b_branch2b
I0529 14:44:57.110030 30229 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0529 14:44:57.110045 30229 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0529 14:44:57.112624 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 14:44:57.112901 30229 net.cpp:150] Setting up res4b_branch2b
I0529 14:44:57.112920 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.112924 30229 net.cpp:165] Memory required for data: 185450508
I0529 14:44:57.112941 30229 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0529 14:44:57.112965 30229 net.cpp:100] Creating Layer bn4b_branch2b
I0529 14:44:57.112974 30229 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0529 14:44:57.112992 30229 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0529 14:44:57.113271 30229 net.cpp:150] Setting up bn4b_branch2b
I0529 14:44:57.113278 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.113281 30229 net.cpp:165] Memory required for data: 185651212
I0529 14:44:57.113296 30229 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0529 14:44:57.113309 30229 net.cpp:100] Creating Layer scale4b_branch2b
I0529 14:44:57.113315 30229 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0529 14:44:57.113325 30229 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0529 14:44:57.113387 30229 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0529 14:44:57.113556 30229 net.cpp:150] Setting up scale4b_branch2b
I0529 14:44:57.113564 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.113566 30229 net.cpp:165] Memory required for data: 185851916
I0529 14:44:57.113576 30229 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0529 14:44:57.113585 30229 net.cpp:100] Creating Layer res4b_branch2b_relu
I0529 14:44:57.113591 30229 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0529 14:44:57.113600 30229 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0529 14:44:57.113756 30229 net.cpp:150] Setting up res4b_branch2b_relu
I0529 14:44:57.113765 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.113768 30229 net.cpp:165] Memory required for data: 186052620
I0529 14:44:57.113771 30229 layer_factory.hpp:77] Creating layer res4b_branch2c
I0529 14:44:57.113786 30229 net.cpp:100] Creating Layer res4b_branch2c
I0529 14:44:57.113792 30229 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0529 14:44:57.113806 30229 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0529 14:44:57.115862 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.115887 30229 net.cpp:150] Setting up res4b_branch2c
I0529 14:44:57.115896 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.115900 30229 net.cpp:165] Memory required for data: 186855436
I0529 14:44:57.115911 30229 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0529 14:44:57.115926 30229 net.cpp:100] Creating Layer bn4b_branch2c
I0529 14:44:57.115932 30229 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0529 14:44:57.115945 30229 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0529 14:44:57.116220 30229 net.cpp:150] Setting up bn4b_branch2c
I0529 14:44:57.116227 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.116230 30229 net.cpp:165] Memory required for data: 187658252
I0529 14:44:57.116245 30229 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0529 14:44:57.116257 30229 net.cpp:100] Creating Layer scale4b_branch2c
I0529 14:44:57.116262 30229 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0529 14:44:57.116273 30229 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0529 14:44:57.116333 30229 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0529 14:44:57.116506 30229 net.cpp:150] Setting up scale4b_branch2c
I0529 14:44:57.116513 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.116515 30229 net.cpp:165] Memory required for data: 188461068
I0529 14:44:57.116525 30229 layer_factory.hpp:77] Creating layer res4b
I0529 14:44:57.116535 30229 net.cpp:100] Creating Layer res4b
I0529 14:44:57.116540 30229 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0529 14:44:57.116549 30229 net.cpp:444] res4b <- res4b_branch2c
I0529 14:44:57.116557 30229 net.cpp:418] res4b -> res4b
I0529 14:44:57.116598 30229 net.cpp:150] Setting up res4b
I0529 14:44:57.116606 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.116609 30229 net.cpp:165] Memory required for data: 189263884
I0529 14:44:57.116612 30229 layer_factory.hpp:77] Creating layer res4b_relu
I0529 14:44:57.116621 30229 net.cpp:100] Creating Layer res4b_relu
I0529 14:44:57.116626 30229 net.cpp:444] res4b_relu <- res4b
I0529 14:44:57.116636 30229 net.cpp:405] res4b_relu -> res4b (in-place)
I0529 14:44:57.116783 30229 net.cpp:150] Setting up res4b_relu
I0529 14:44:57.116789 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.116792 30229 net.cpp:165] Memory required for data: 190066700
I0529 14:44:57.116796 30229 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0529 14:44:57.116806 30229 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0529 14:44:57.116811 30229 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0529 14:44:57.116820 30229 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0529 14:44:57.116833 30229 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0529 14:44:57.116890 30229 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0529 14:44:57.116899 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.116902 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.116904 30229 net.cpp:165] Memory required for data: 191672332
I0529 14:44:57.116907 30229 layer_factory.hpp:77] Creating layer res4c_branch2a
I0529 14:44:57.116927 30229 net.cpp:100] Creating Layer res4c_branch2a
I0529 14:44:57.116935 30229 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0529 14:44:57.116950 30229 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0529 14:44:57.118293 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.118314 30229 net.cpp:150] Setting up res4c_branch2a
I0529 14:44:57.118321 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.118324 30229 net.cpp:165] Memory required for data: 191873036
I0529 14:44:57.118335 30229 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0529 14:44:57.118347 30229 net.cpp:100] Creating Layer bn4c_branch2a
I0529 14:44:57.118353 30229 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0529 14:44:57.118366 30229 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0529 14:44:57.118633 30229 net.cpp:150] Setting up bn4c_branch2a
I0529 14:44:57.118639 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.118641 30229 net.cpp:165] Memory required for data: 192073740
I0529 14:44:57.118656 30229 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0529 14:44:57.118669 30229 net.cpp:100] Creating Layer scale4c_branch2a
I0529 14:44:57.118674 30229 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0529 14:44:57.118685 30229 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0529 14:44:57.118748 30229 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0529 14:44:57.118916 30229 net.cpp:150] Setting up scale4c_branch2a
I0529 14:44:57.118922 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.118924 30229 net.cpp:165] Memory required for data: 192274444
I0529 14:44:57.118934 30229 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0529 14:44:57.118945 30229 net.cpp:100] Creating Layer res4c_branch2a_relu
I0529 14:44:57.118950 30229 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0529 14:44:57.118962 30229 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0529 14:44:57.119105 30229 net.cpp:150] Setting up res4c_branch2a_relu
I0529 14:44:57.119112 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.119115 30229 net.cpp:165] Memory required for data: 192475148
I0529 14:44:57.119119 30229 layer_factory.hpp:77] Creating layer res4c_branch2b
I0529 14:44:57.119132 30229 net.cpp:100] Creating Layer res4c_branch2b
I0529 14:44:57.119138 30229 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0529 14:44:57.119153 30229 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0529 14:44:57.121747 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 14:44:57.122027 30229 net.cpp:150] Setting up res4c_branch2b
I0529 14:44:57.122040 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.122043 30229 net.cpp:165] Memory required for data: 192675852
I0529 14:44:57.122056 30229 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0529 14:44:57.122076 30229 net.cpp:100] Creating Layer bn4c_branch2b
I0529 14:44:57.122082 30229 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0529 14:44:57.122095 30229 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0529 14:44:57.122375 30229 net.cpp:150] Setting up bn4c_branch2b
I0529 14:44:57.122381 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.122385 30229 net.cpp:165] Memory required for data: 192876556
I0529 14:44:57.122398 30229 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0529 14:44:57.122411 30229 net.cpp:100] Creating Layer scale4c_branch2b
I0529 14:44:57.122416 30229 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0529 14:44:57.122427 30229 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0529 14:44:57.122493 30229 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0529 14:44:57.122658 30229 net.cpp:150] Setting up scale4c_branch2b
I0529 14:44:57.122665 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.122668 30229 net.cpp:165] Memory required for data: 193077260
I0529 14:44:57.122678 30229 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0529 14:44:57.122686 30229 net.cpp:100] Creating Layer res4c_branch2b_relu
I0529 14:44:57.122692 30229 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0529 14:44:57.122704 30229 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0529 14:44:57.123109 30229 net.cpp:150] Setting up res4c_branch2b_relu
I0529 14:44:57.123117 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.123119 30229 net.cpp:165] Memory required for data: 193277964
I0529 14:44:57.123124 30229 layer_factory.hpp:77] Creating layer res4c_branch2c
I0529 14:44:57.123139 30229 net.cpp:100] Creating Layer res4c_branch2c
I0529 14:44:57.123145 30229 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0529 14:44:57.123159 30229 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0529 14:44:57.125237 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.125262 30229 net.cpp:150] Setting up res4c_branch2c
I0529 14:44:57.125270 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.125273 30229 net.cpp:165] Memory required for data: 194080780
I0529 14:44:57.125284 30229 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0529 14:44:57.125298 30229 net.cpp:100] Creating Layer bn4c_branch2c
I0529 14:44:57.125304 30229 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0529 14:44:57.125317 30229 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0529 14:44:57.125607 30229 net.cpp:150] Setting up bn4c_branch2c
I0529 14:44:57.125614 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.125617 30229 net.cpp:165] Memory required for data: 194883596
I0529 14:44:57.125632 30229 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0529 14:44:57.125644 30229 net.cpp:100] Creating Layer scale4c_branch2c
I0529 14:44:57.125649 30229 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0529 14:44:57.125661 30229 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0529 14:44:57.125722 30229 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0529 14:44:57.125905 30229 net.cpp:150] Setting up scale4c_branch2c
I0529 14:44:57.125911 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.125913 30229 net.cpp:165] Memory required for data: 195686412
I0529 14:44:57.125923 30229 layer_factory.hpp:77] Creating layer res4c
I0529 14:44:57.125936 30229 net.cpp:100] Creating Layer res4c
I0529 14:44:57.125941 30229 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0529 14:44:57.125949 30229 net.cpp:444] res4c <- res4c_branch2c
I0529 14:44:57.125957 30229 net.cpp:418] res4c -> res4c
I0529 14:44:57.126000 30229 net.cpp:150] Setting up res4c
I0529 14:44:57.126008 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.126010 30229 net.cpp:165] Memory required for data: 196489228
I0529 14:44:57.126014 30229 layer_factory.hpp:77] Creating layer res4c_relu
I0529 14:44:57.126022 30229 net.cpp:100] Creating Layer res4c_relu
I0529 14:44:57.126027 30229 net.cpp:444] res4c_relu <- res4c
I0529 14:44:57.126036 30229 net.cpp:405] res4c_relu -> res4c (in-place)
I0529 14:44:57.126183 30229 net.cpp:150] Setting up res4c_relu
I0529 14:44:57.126189 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.126191 30229 net.cpp:165] Memory required for data: 197292044
I0529 14:44:57.126195 30229 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0529 14:44:57.126204 30229 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0529 14:44:57.126209 30229 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0529 14:44:57.126220 30229 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0529 14:44:57.126232 30229 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0529 14:44:57.126289 30229 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0529 14:44:57.126297 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.126302 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.126302 30229 net.cpp:165] Memory required for data: 198897676
I0529 14:44:57.126307 30229 layer_factory.hpp:77] Creating layer res4d_branch2a
I0529 14:44:57.126319 30229 net.cpp:100] Creating Layer res4d_branch2a
I0529 14:44:57.126324 30229 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0529 14:44:57.126338 30229 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0529 14:44:57.127683 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.127707 30229 net.cpp:150] Setting up res4d_branch2a
I0529 14:44:57.127713 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.127717 30229 net.cpp:165] Memory required for data: 199098380
I0529 14:44:57.127725 30229 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0529 14:44:57.127740 30229 net.cpp:100] Creating Layer bn4d_branch2a
I0529 14:44:57.127746 30229 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0529 14:44:57.127758 30229 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0529 14:44:57.128031 30229 net.cpp:150] Setting up bn4d_branch2a
I0529 14:44:57.128037 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.128041 30229 net.cpp:165] Memory required for data: 199299084
I0529 14:44:57.128054 30229 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0529 14:44:57.128065 30229 net.cpp:100] Creating Layer scale4d_branch2a
I0529 14:44:57.128072 30229 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0529 14:44:57.128082 30229 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0529 14:44:57.128145 30229 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0529 14:44:57.128314 30229 net.cpp:150] Setting up scale4d_branch2a
I0529 14:44:57.128319 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.128321 30229 net.cpp:165] Memory required for data: 199499788
I0529 14:44:57.128331 30229 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0529 14:44:57.128340 30229 net.cpp:100] Creating Layer res4d_branch2a_relu
I0529 14:44:57.128346 30229 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0529 14:44:57.128356 30229 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0529 14:44:57.128505 30229 net.cpp:150] Setting up res4d_branch2a_relu
I0529 14:44:57.128511 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.128515 30229 net.cpp:165] Memory required for data: 199700492
I0529 14:44:57.128518 30229 layer_factory.hpp:77] Creating layer res4d_branch2b
I0529 14:44:57.128531 30229 net.cpp:100] Creating Layer res4d_branch2b
I0529 14:44:57.128536 30229 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0529 14:44:57.128552 30229 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0529 14:44:57.131141 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 14:44:57.131417 30229 net.cpp:150] Setting up res4d_branch2b
I0529 14:44:57.131428 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.131431 30229 net.cpp:165] Memory required for data: 199901196
I0529 14:44:57.131443 30229 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0529 14:44:57.131459 30229 net.cpp:100] Creating Layer bn4d_branch2b
I0529 14:44:57.131465 30229 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0529 14:44:57.131479 30229 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0529 14:44:57.131762 30229 net.cpp:150] Setting up bn4d_branch2b
I0529 14:44:57.131768 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.131770 30229 net.cpp:165] Memory required for data: 200101900
I0529 14:44:57.131785 30229 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0529 14:44:57.131798 30229 net.cpp:100] Creating Layer scale4d_branch2b
I0529 14:44:57.131803 30229 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0529 14:44:57.131814 30229 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0529 14:44:57.131880 30229 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0529 14:44:57.132050 30229 net.cpp:150] Setting up scale4d_branch2b
I0529 14:44:57.132056 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.132058 30229 net.cpp:165] Memory required for data: 200302604
I0529 14:44:57.132068 30229 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0529 14:44:57.132078 30229 net.cpp:100] Creating Layer res4d_branch2b_relu
I0529 14:44:57.132083 30229 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0529 14:44:57.132092 30229 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0529 14:44:57.132503 30229 net.cpp:150] Setting up res4d_branch2b_relu
I0529 14:44:57.132510 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.132513 30229 net.cpp:165] Memory required for data: 200503308
I0529 14:44:57.132516 30229 layer_factory.hpp:77] Creating layer res4d_branch2c
I0529 14:44:57.132532 30229 net.cpp:100] Creating Layer res4d_branch2c
I0529 14:44:57.132537 30229 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0529 14:44:57.132552 30229 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0529 14:44:57.134676 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.134703 30229 net.cpp:150] Setting up res4d_branch2c
I0529 14:44:57.134714 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.134716 30229 net.cpp:165] Memory required for data: 201306124
I0529 14:44:57.134729 30229 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0529 14:44:57.134745 30229 net.cpp:100] Creating Layer bn4d_branch2c
I0529 14:44:57.134750 30229 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0529 14:44:57.134763 30229 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0529 14:44:57.135051 30229 net.cpp:150] Setting up bn4d_branch2c
I0529 14:44:57.135058 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.135061 30229 net.cpp:165] Memory required for data: 202108940
I0529 14:44:57.135076 30229 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0529 14:44:57.135088 30229 net.cpp:100] Creating Layer scale4d_branch2c
I0529 14:44:57.135094 30229 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0529 14:44:57.135105 30229 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0529 14:44:57.135167 30229 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0529 14:44:57.135347 30229 net.cpp:150] Setting up scale4d_branch2c
I0529 14:44:57.135355 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.135357 30229 net.cpp:165] Memory required for data: 202911756
I0529 14:44:57.135366 30229 layer_factory.hpp:77] Creating layer res4d
I0529 14:44:57.135377 30229 net.cpp:100] Creating Layer res4d
I0529 14:44:57.135383 30229 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0529 14:44:57.135392 30229 net.cpp:444] res4d <- res4d_branch2c
I0529 14:44:57.135401 30229 net.cpp:418] res4d -> res4d
I0529 14:44:57.135442 30229 net.cpp:150] Setting up res4d
I0529 14:44:57.135450 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.135453 30229 net.cpp:165] Memory required for data: 203714572
I0529 14:44:57.135457 30229 layer_factory.hpp:77] Creating layer res4d_relu
I0529 14:44:57.135465 30229 net.cpp:100] Creating Layer res4d_relu
I0529 14:44:57.135470 30229 net.cpp:444] res4d_relu <- res4d
I0529 14:44:57.135480 30229 net.cpp:405] res4d_relu -> res4d (in-place)
I0529 14:44:57.135627 30229 net.cpp:150] Setting up res4d_relu
I0529 14:44:57.135633 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.135635 30229 net.cpp:165] Memory required for data: 204517388
I0529 14:44:57.135639 30229 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0529 14:44:57.135648 30229 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0529 14:44:57.135653 30229 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0529 14:44:57.135664 30229 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0529 14:44:57.135677 30229 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0529 14:44:57.135735 30229 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0529 14:44:57.135745 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.135748 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.135751 30229 net.cpp:165] Memory required for data: 206123020
I0529 14:44:57.135754 30229 layer_factory.hpp:77] Creating layer res4e_branch2a
I0529 14:44:57.135766 30229 net.cpp:100] Creating Layer res4e_branch2a
I0529 14:44:57.135771 30229 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0529 14:44:57.135784 30229 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0529 14:44:57.137223 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.137248 30229 net.cpp:150] Setting up res4e_branch2a
I0529 14:44:57.137257 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.137260 30229 net.cpp:165] Memory required for data: 206323724
I0529 14:44:57.137272 30229 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0529 14:44:57.137287 30229 net.cpp:100] Creating Layer bn4e_branch2a
I0529 14:44:57.137295 30229 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0529 14:44:57.137308 30229 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0529 14:44:57.137591 30229 net.cpp:150] Setting up bn4e_branch2a
I0529 14:44:57.137598 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.137600 30229 net.cpp:165] Memory required for data: 206524428
I0529 14:44:57.137616 30229 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0529 14:44:57.137630 30229 net.cpp:100] Creating Layer scale4e_branch2a
I0529 14:44:57.137635 30229 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0529 14:44:57.137646 30229 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0529 14:44:57.137712 30229 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0529 14:44:57.137887 30229 net.cpp:150] Setting up scale4e_branch2a
I0529 14:44:57.137892 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.137895 30229 net.cpp:165] Memory required for data: 206725132
I0529 14:44:57.137904 30229 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0529 14:44:57.137914 30229 net.cpp:100] Creating Layer res4e_branch2a_relu
I0529 14:44:57.137918 30229 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0529 14:44:57.137929 30229 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0529 14:44:57.138077 30229 net.cpp:150] Setting up res4e_branch2a_relu
I0529 14:44:57.138084 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.138087 30229 net.cpp:165] Memory required for data: 206925836
I0529 14:44:57.138090 30229 layer_factory.hpp:77] Creating layer res4e_branch2b
I0529 14:44:57.138105 30229 net.cpp:100] Creating Layer res4e_branch2b
I0529 14:44:57.138110 30229 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0529 14:44:57.138125 30229 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0529 14:44:57.141021 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 14:44:57.141351 30229 net.cpp:150] Setting up res4e_branch2b
I0529 14:44:57.141368 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.141371 30229 net.cpp:165] Memory required for data: 207126540
I0529 14:44:57.141392 30229 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0529 14:44:57.141420 30229 net.cpp:100] Creating Layer bn4e_branch2b
I0529 14:44:57.141430 30229 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0529 14:44:57.141449 30229 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0529 14:44:57.141750 30229 net.cpp:150] Setting up bn4e_branch2b
I0529 14:44:57.141757 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.141759 30229 net.cpp:165] Memory required for data: 207327244
I0529 14:44:57.141774 30229 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0529 14:44:57.141789 30229 net.cpp:100] Creating Layer scale4e_branch2b
I0529 14:44:57.141794 30229 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0529 14:44:57.141805 30229 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0529 14:44:57.141873 30229 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0529 14:44:57.142051 30229 net.cpp:150] Setting up scale4e_branch2b
I0529 14:44:57.142058 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.142060 30229 net.cpp:165] Memory required for data: 207527948
I0529 14:44:57.142069 30229 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0529 14:44:57.142081 30229 net.cpp:100] Creating Layer res4e_branch2b_relu
I0529 14:44:57.142086 30229 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0529 14:44:57.142094 30229 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0529 14:44:57.142519 30229 net.cpp:150] Setting up res4e_branch2b_relu
I0529 14:44:57.142527 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.142529 30229 net.cpp:165] Memory required for data: 207728652
I0529 14:44:57.142534 30229 layer_factory.hpp:77] Creating layer res4e_branch2c
I0529 14:44:57.142550 30229 net.cpp:100] Creating Layer res4e_branch2c
I0529 14:44:57.142556 30229 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0529 14:44:57.142571 30229 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0529 14:44:57.144671 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.144697 30229 net.cpp:150] Setting up res4e_branch2c
I0529 14:44:57.144706 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.144708 30229 net.cpp:165] Memory required for data: 208531468
I0529 14:44:57.144719 30229 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0529 14:44:57.144732 30229 net.cpp:100] Creating Layer bn4e_branch2c
I0529 14:44:57.144739 30229 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0529 14:44:57.144753 30229 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0529 14:44:57.145068 30229 net.cpp:150] Setting up bn4e_branch2c
I0529 14:44:57.145076 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.145078 30229 net.cpp:165] Memory required for data: 209334284
I0529 14:44:57.145093 30229 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0529 14:44:57.145107 30229 net.cpp:100] Creating Layer scale4e_branch2c
I0529 14:44:57.145112 30229 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0529 14:44:57.145123 30229 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0529 14:44:57.145185 30229 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0529 14:44:57.145370 30229 net.cpp:150] Setting up scale4e_branch2c
I0529 14:44:57.145376 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.145380 30229 net.cpp:165] Memory required for data: 210137100
I0529 14:44:57.145390 30229 layer_factory.hpp:77] Creating layer res4e
I0529 14:44:57.145398 30229 net.cpp:100] Creating Layer res4e
I0529 14:44:57.145404 30229 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0529 14:44:57.145413 30229 net.cpp:444] res4e <- res4e_branch2c
I0529 14:44:57.145421 30229 net.cpp:418] res4e -> res4e
I0529 14:44:57.145464 30229 net.cpp:150] Setting up res4e
I0529 14:44:57.145473 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.145475 30229 net.cpp:165] Memory required for data: 210939916
I0529 14:44:57.145478 30229 layer_factory.hpp:77] Creating layer res4e_relu
I0529 14:44:57.145488 30229 net.cpp:100] Creating Layer res4e_relu
I0529 14:44:57.145491 30229 net.cpp:444] res4e_relu <- res4e
I0529 14:44:57.145503 30229 net.cpp:405] res4e_relu -> res4e (in-place)
I0529 14:44:57.145651 30229 net.cpp:150] Setting up res4e_relu
I0529 14:44:57.145658 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.145660 30229 net.cpp:165] Memory required for data: 211742732
I0529 14:44:57.145664 30229 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0529 14:44:57.145674 30229 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0529 14:44:57.145680 30229 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0529 14:44:57.145690 30229 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0529 14:44:57.145704 30229 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0529 14:44:57.145762 30229 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0529 14:44:57.145771 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.145774 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.145776 30229 net.cpp:165] Memory required for data: 213348364
I0529 14:44:57.145779 30229 layer_factory.hpp:77] Creating layer res4f_branch2a
I0529 14:44:57.145792 30229 net.cpp:100] Creating Layer res4f_branch2a
I0529 14:44:57.145797 30229 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0529 14:44:57.145810 30229 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0529 14:44:57.147178 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.147199 30229 net.cpp:150] Setting up res4f_branch2a
I0529 14:44:57.147207 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.147209 30229 net.cpp:165] Memory required for data: 213549068
I0529 14:44:57.147219 30229 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0529 14:44:57.147233 30229 net.cpp:100] Creating Layer bn4f_branch2a
I0529 14:44:57.147238 30229 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0529 14:44:57.147250 30229 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0529 14:44:57.147534 30229 net.cpp:150] Setting up bn4f_branch2a
I0529 14:44:57.147541 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.147543 30229 net.cpp:165] Memory required for data: 213749772
I0529 14:44:57.147557 30229 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0529 14:44:57.147570 30229 net.cpp:100] Creating Layer scale4f_branch2a
I0529 14:44:57.147575 30229 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0529 14:44:57.147588 30229 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0529 14:44:57.147651 30229 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0529 14:44:57.147826 30229 net.cpp:150] Setting up scale4f_branch2a
I0529 14:44:57.147833 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.147836 30229 net.cpp:165] Memory required for data: 213950476
I0529 14:44:57.147846 30229 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0529 14:44:57.147855 30229 net.cpp:100] Creating Layer res4f_branch2a_relu
I0529 14:44:57.147861 30229 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0529 14:44:57.147871 30229 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0529 14:44:57.148017 30229 net.cpp:150] Setting up res4f_branch2a_relu
I0529 14:44:57.148025 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.148026 30229 net.cpp:165] Memory required for data: 214151180
I0529 14:44:57.148030 30229 layer_factory.hpp:77] Creating layer res4f_branch2b
I0529 14:44:57.148043 30229 net.cpp:100] Creating Layer res4f_branch2b
I0529 14:44:57.148049 30229 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0529 14:44:57.148063 30229 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0529 14:44:57.150693 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 14:44:57.150975 30229 net.cpp:150] Setting up res4f_branch2b
I0529 14:44:57.150987 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.150990 30229 net.cpp:165] Memory required for data: 214351884
I0529 14:44:57.151005 30229 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0529 14:44:57.151021 30229 net.cpp:100] Creating Layer bn4f_branch2b
I0529 14:44:57.151027 30229 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0529 14:44:57.151041 30229 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0529 14:44:57.151335 30229 net.cpp:150] Setting up bn4f_branch2b
I0529 14:44:57.151341 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.151345 30229 net.cpp:165] Memory required for data: 214552588
I0529 14:44:57.151360 30229 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0529 14:44:57.151372 30229 net.cpp:100] Creating Layer scale4f_branch2b
I0529 14:44:57.151378 30229 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0529 14:44:57.151389 30229 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0529 14:44:57.151454 30229 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0529 14:44:57.151630 30229 net.cpp:150] Setting up scale4f_branch2b
I0529 14:44:57.151638 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.151640 30229 net.cpp:165] Memory required for data: 214753292
I0529 14:44:57.151649 30229 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0529 14:44:57.151661 30229 net.cpp:100] Creating Layer res4f_branch2b_relu
I0529 14:44:57.151666 30229 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0529 14:44:57.151676 30229 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0529 14:44:57.151830 30229 net.cpp:150] Setting up res4f_branch2b_relu
I0529 14:44:57.151836 30229 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0529 14:44:57.151839 30229 net.cpp:165] Memory required for data: 214953996
I0529 14:44:57.151844 30229 layer_factory.hpp:77] Creating layer res4f_branch2c
I0529 14:44:57.151857 30229 net.cpp:100] Creating Layer res4f_branch2c
I0529 14:44:57.151863 30229 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0529 14:44:57.151876 30229 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0529 14:44:57.154013 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.154040 30229 net.cpp:150] Setting up res4f_branch2c
I0529 14:44:57.154049 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.154052 30229 net.cpp:165] Memory required for data: 215756812
I0529 14:44:57.154065 30229 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0529 14:44:57.154081 30229 net.cpp:100] Creating Layer bn4f_branch2c
I0529 14:44:57.154088 30229 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0529 14:44:57.154103 30229 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0529 14:44:57.154402 30229 net.cpp:150] Setting up bn4f_branch2c
I0529 14:44:57.154408 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.154410 30229 net.cpp:165] Memory required for data: 216559628
I0529 14:44:57.154461 30229 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0529 14:44:57.154475 30229 net.cpp:100] Creating Layer scale4f_branch2c
I0529 14:44:57.154481 30229 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0529 14:44:57.154491 30229 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0529 14:44:57.154556 30229 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0529 14:44:57.154744 30229 net.cpp:150] Setting up scale4f_branch2c
I0529 14:44:57.154752 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.154753 30229 net.cpp:165] Memory required for data: 217362444
I0529 14:44:57.154764 30229 layer_factory.hpp:77] Creating layer res4f
I0529 14:44:57.154774 30229 net.cpp:100] Creating Layer res4f
I0529 14:44:57.154779 30229 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0529 14:44:57.154788 30229 net.cpp:444] res4f <- res4f_branch2c
I0529 14:44:57.154798 30229 net.cpp:418] res4f -> res4f
I0529 14:44:57.154839 30229 net.cpp:150] Setting up res4f
I0529 14:44:57.154846 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.154850 30229 net.cpp:165] Memory required for data: 218165260
I0529 14:44:57.154853 30229 layer_factory.hpp:77] Creating layer res4f_relu
I0529 14:44:57.154862 30229 net.cpp:100] Creating Layer res4f_relu
I0529 14:44:57.154867 30229 net.cpp:444] res4f_relu <- res4f
I0529 14:44:57.154876 30229 net.cpp:405] res4f_relu -> res4f (in-place)
I0529 14:44:57.155308 30229 net.cpp:150] Setting up res4f_relu
I0529 14:44:57.155315 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.155318 30229 net.cpp:165] Memory required for data: 218968076
I0529 14:44:57.155323 30229 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0529 14:44:57.155333 30229 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0529 14:44:57.155339 30229 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0529 14:44:57.155351 30229 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0529 14:44:57.155366 30229 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0529 14:44:57.155377 30229 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0529 14:44:57.155459 30229 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0529 14:44:57.155468 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.155472 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.155475 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.155478 30229 net.cpp:165] Memory required for data: 221376524
I0529 14:44:57.155480 30229 layer_factory.hpp:77] Creating layer res5a_branch1
I0529 14:44:57.155493 30229 net.cpp:100] Creating Layer res5a_branch1
I0529 14:44:57.155498 30229 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0529 14:44:57.155513 30229 net.cpp:418] res5a_branch1 -> res5a_branch1
I0529 14:44:57.161551 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 8568
I0529 14:44:57.161588 30229 net.cpp:150] Setting up res5a_branch1
I0529 14:44:57.161604 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.161607 30229 net.cpp:165] Memory required for data: 222982156
I0529 14:44:57.161628 30229 layer_factory.hpp:77] Creating layer bn5a_branch1
I0529 14:44:57.161655 30229 net.cpp:100] Creating Layer bn5a_branch1
I0529 14:44:57.161665 30229 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0529 14:44:57.161684 30229 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0529 14:44:57.162009 30229 net.cpp:150] Setting up bn5a_branch1
I0529 14:44:57.162015 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.162019 30229 net.cpp:165] Memory required for data: 224587788
I0529 14:44:57.162034 30229 layer_factory.hpp:77] Creating layer scale5a_branch1
I0529 14:44:57.162057 30229 net.cpp:100] Creating Layer scale5a_branch1
I0529 14:44:57.162063 30229 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0529 14:44:57.162076 30229 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0529 14:44:57.162144 30229 layer_factory.hpp:77] Creating layer scale5a_branch1
I0529 14:44:57.162336 30229 net.cpp:150] Setting up scale5a_branch1
I0529 14:44:57.162343 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.162346 30229 net.cpp:165] Memory required for data: 226193420
I0529 14:44:57.162355 30229 layer_factory.hpp:77] Creating layer res5a_branch2a
I0529 14:44:57.162372 30229 net.cpp:100] Creating Layer res5a_branch2a
I0529 14:44:57.162379 30229 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0529 14:44:57.162390 30229 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0529 14:44:57.165184 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.165208 30229 net.cpp:150] Setting up res5a_branch2a
I0529 14:44:57.165217 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.165220 30229 net.cpp:165] Memory required for data: 226594828
I0529 14:44:57.165231 30229 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0529 14:44:57.165246 30229 net.cpp:100] Creating Layer bn5a_branch2a
I0529 14:44:57.165251 30229 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0529 14:44:57.165266 30229 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0529 14:44:57.165561 30229 net.cpp:150] Setting up bn5a_branch2a
I0529 14:44:57.165568 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.165571 30229 net.cpp:165] Memory required for data: 226996236
I0529 14:44:57.165586 30229 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0529 14:44:57.165599 30229 net.cpp:100] Creating Layer scale5a_branch2a
I0529 14:44:57.165604 30229 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0529 14:44:57.165616 30229 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0529 14:44:57.165678 30229 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0529 14:44:57.165863 30229 net.cpp:150] Setting up scale5a_branch2a
I0529 14:44:57.165869 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.165871 30229 net.cpp:165] Memory required for data: 227397644
I0529 14:44:57.165881 30229 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0529 14:44:57.165891 30229 net.cpp:100] Creating Layer res5a_branch2a_relu
I0529 14:44:57.165897 30229 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0529 14:44:57.165906 30229 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0529 14:44:57.166059 30229 net.cpp:150] Setting up res5a_branch2a_relu
I0529 14:44:57.166064 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.166066 30229 net.cpp:165] Memory required for data: 227799052
I0529 14:44:57.166070 30229 layer_factory.hpp:77] Creating layer res5a_branch2b
I0529 14:44:57.166085 30229 net.cpp:100] Creating Layer res5a_branch2b
I0529 14:44:57.166090 30229 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0529 14:44:57.166105 30229 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0529 14:44:57.171978 30229 net.cpp:150] Setting up res5a_branch2b
I0529 14:44:57.172005 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.172008 30229 net.cpp:165] Memory required for data: 228200460
I0529 14:44:57.172029 30229 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0529 14:44:57.172057 30229 net.cpp:100] Creating Layer bn5a_branch2b
I0529 14:44:57.172068 30229 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0529 14:44:57.172086 30229 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0529 14:44:57.172407 30229 net.cpp:150] Setting up bn5a_branch2b
I0529 14:44:57.172415 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.172416 30229 net.cpp:165] Memory required for data: 228601868
I0529 14:44:57.172432 30229 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0529 14:44:57.172446 30229 net.cpp:100] Creating Layer scale5a_branch2b
I0529 14:44:57.172451 30229 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0529 14:44:57.172463 30229 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0529 14:44:57.172531 30229 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0529 14:44:57.172729 30229 net.cpp:150] Setting up scale5a_branch2b
I0529 14:44:57.172734 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.172737 30229 net.cpp:165] Memory required for data: 229003276
I0529 14:44:57.172747 30229 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0529 14:44:57.172756 30229 net.cpp:100] Creating Layer res5a_branch2b_relu
I0529 14:44:57.172761 30229 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0529 14:44:57.172771 30229 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0529 14:44:57.172983 30229 net.cpp:150] Setting up res5a_branch2b_relu
I0529 14:44:57.172991 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.172993 30229 net.cpp:165] Memory required for data: 229404684
I0529 14:44:57.172997 30229 layer_factory.hpp:77] Creating layer res5a_branch2c
I0529 14:44:57.173014 30229 net.cpp:100] Creating Layer res5a_branch2c
I0529 14:44:57.173019 30229 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0529 14:44:57.173032 30229 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0529 14:44:57.176982 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0529 14:44:57.177017 30229 net.cpp:150] Setting up res5a_branch2c
I0529 14:44:57.177031 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.177032 30229 net.cpp:165] Memory required for data: 231010316
I0529 14:44:57.177053 30229 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0529 14:44:57.177079 30229 net.cpp:100] Creating Layer bn5a_branch2c
I0529 14:44:57.177088 30229 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0529 14:44:57.177105 30229 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0529 14:44:57.177422 30229 net.cpp:150] Setting up bn5a_branch2c
I0529 14:44:57.177428 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.177430 30229 net.cpp:165] Memory required for data: 232615948
I0529 14:44:57.177445 30229 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0529 14:44:57.177459 30229 net.cpp:100] Creating Layer scale5a_branch2c
I0529 14:44:57.177464 30229 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0529 14:44:57.177476 30229 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0529 14:44:57.177541 30229 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0529 14:44:57.177736 30229 net.cpp:150] Setting up scale5a_branch2c
I0529 14:44:57.177742 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.177744 30229 net.cpp:165] Memory required for data: 234221580
I0529 14:44:57.177753 30229 layer_factory.hpp:77] Creating layer res5a
I0529 14:44:57.177762 30229 net.cpp:100] Creating Layer res5a
I0529 14:44:57.177767 30229 net.cpp:444] res5a <- res5a_branch1
I0529 14:44:57.177775 30229 net.cpp:444] res5a <- res5a_branch2c
I0529 14:44:57.177783 30229 net.cpp:418] res5a -> res5a
I0529 14:44:57.177825 30229 net.cpp:150] Setting up res5a
I0529 14:44:57.177834 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.177835 30229 net.cpp:165] Memory required for data: 235827212
I0529 14:44:57.177839 30229 layer_factory.hpp:77] Creating layer res5a_relu
I0529 14:44:57.177847 30229 net.cpp:100] Creating Layer res5a_relu
I0529 14:44:57.177851 30229 net.cpp:444] res5a_relu <- res5a
I0529 14:44:57.177862 30229 net.cpp:405] res5a_relu -> res5a (in-place)
I0529 14:44:57.178333 30229 net.cpp:150] Setting up res5a_relu
I0529 14:44:57.178342 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.178345 30229 net.cpp:165] Memory required for data: 237432844
I0529 14:44:57.178349 30229 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0529 14:44:57.178360 30229 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0529 14:44:57.178365 30229 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0529 14:44:57.178380 30229 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0529 14:44:57.178393 30229 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0529 14:44:57.178457 30229 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0529 14:44:57.178464 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.178468 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.178472 30229 net.cpp:165] Memory required for data: 240644108
I0529 14:44:57.178474 30229 layer_factory.hpp:77] Creating layer res5b_branch2a
I0529 14:44:57.178489 30229 net.cpp:100] Creating Layer res5b_branch2a
I0529 14:44:57.178494 30229 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0529 14:44:57.178508 30229 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0529 14:44:57.182206 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.182237 30229 net.cpp:150] Setting up res5b_branch2a
I0529 14:44:57.182248 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.182251 30229 net.cpp:165] Memory required for data: 241045516
I0529 14:44:57.182267 30229 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0529 14:44:57.182288 30229 net.cpp:100] Creating Layer bn5b_branch2a
I0529 14:44:57.182297 30229 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0529 14:44:57.182313 30229 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0529 14:44:57.182634 30229 net.cpp:150] Setting up bn5b_branch2a
I0529 14:44:57.182641 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.182644 30229 net.cpp:165] Memory required for data: 241446924
I0529 14:44:57.182659 30229 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0529 14:44:57.182673 30229 net.cpp:100] Creating Layer scale5b_branch2a
I0529 14:44:57.182679 30229 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0529 14:44:57.182689 30229 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0529 14:44:57.182755 30229 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0529 14:44:57.182945 30229 net.cpp:150] Setting up scale5b_branch2a
I0529 14:44:57.182953 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.182956 30229 net.cpp:165] Memory required for data: 241848332
I0529 14:44:57.182965 30229 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0529 14:44:57.182976 30229 net.cpp:100] Creating Layer res5b_branch2a_relu
I0529 14:44:57.182981 30229 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0529 14:44:57.182991 30229 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0529 14:44:57.183140 30229 net.cpp:150] Setting up res5b_branch2a_relu
I0529 14:44:57.183147 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.183151 30229 net.cpp:165] Memory required for data: 242249740
I0529 14:44:57.183156 30229 layer_factory.hpp:77] Creating layer res5b_branch2b
I0529 14:44:57.183171 30229 net.cpp:100] Creating Layer res5b_branch2b
I0529 14:44:57.183176 30229 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0529 14:44:57.183189 30229 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0529 14:44:57.189007 30229 net.cpp:150] Setting up res5b_branch2b
I0529 14:44:57.189036 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.189039 30229 net.cpp:165] Memory required for data: 242651148
I0529 14:44:57.189060 30229 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0529 14:44:57.189090 30229 net.cpp:100] Creating Layer bn5b_branch2b
I0529 14:44:57.189101 30229 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0529 14:44:57.189118 30229 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0529 14:44:57.189437 30229 net.cpp:150] Setting up bn5b_branch2b
I0529 14:44:57.189445 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.189447 30229 net.cpp:165] Memory required for data: 243052556
I0529 14:44:57.189463 30229 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0529 14:44:57.189477 30229 net.cpp:100] Creating Layer scale5b_branch2b
I0529 14:44:57.189482 30229 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0529 14:44:57.189493 30229 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0529 14:44:57.189560 30229 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0529 14:44:57.189752 30229 net.cpp:150] Setting up scale5b_branch2b
I0529 14:44:57.189759 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.189761 30229 net.cpp:165] Memory required for data: 243453964
I0529 14:44:57.189770 30229 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0529 14:44:57.189780 30229 net.cpp:100] Creating Layer res5b_branch2b_relu
I0529 14:44:57.189785 30229 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0529 14:44:57.189795 30229 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0529 14:44:57.189987 30229 net.cpp:150] Setting up res5b_branch2b_relu
I0529 14:44:57.189994 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.189996 30229 net.cpp:165] Memory required for data: 243855372
I0529 14:44:57.190001 30229 layer_factory.hpp:77] Creating layer res5b_branch2c
I0529 14:44:57.190014 30229 net.cpp:100] Creating Layer res5b_branch2c
I0529 14:44:57.190021 30229 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0529 14:44:57.190033 30229 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0529 14:44:57.193827 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0529 14:44:57.193857 30229 net.cpp:150] Setting up res5b_branch2c
I0529 14:44:57.193869 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.193872 30229 net.cpp:165] Memory required for data: 245461004
I0529 14:44:57.193888 30229 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0529 14:44:57.193909 30229 net.cpp:100] Creating Layer bn5b_branch2c
I0529 14:44:57.193918 30229 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0529 14:44:57.193934 30229 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0529 14:44:57.194257 30229 net.cpp:150] Setting up bn5b_branch2c
I0529 14:44:57.194263 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.194267 30229 net.cpp:165] Memory required for data: 247066636
I0529 14:44:57.194281 30229 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0529 14:44:57.194295 30229 net.cpp:100] Creating Layer scale5b_branch2c
I0529 14:44:57.194301 30229 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0529 14:44:57.194313 30229 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0529 14:44:57.194380 30229 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0529 14:44:57.194574 30229 net.cpp:150] Setting up scale5b_branch2c
I0529 14:44:57.194581 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.194583 30229 net.cpp:165] Memory required for data: 248672268
I0529 14:44:57.194593 30229 layer_factory.hpp:77] Creating layer res5b
I0529 14:44:57.194604 30229 net.cpp:100] Creating Layer res5b
I0529 14:44:57.194609 30229 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0529 14:44:57.194618 30229 net.cpp:444] res5b <- res5b_branch2c
I0529 14:44:57.194627 30229 net.cpp:418] res5b -> res5b
I0529 14:44:57.194669 30229 net.cpp:150] Setting up res5b
I0529 14:44:57.194677 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.194680 30229 net.cpp:165] Memory required for data: 250277900
I0529 14:44:57.194684 30229 layer_factory.hpp:77] Creating layer res5b_relu
I0529 14:44:57.194694 30229 net.cpp:100] Creating Layer res5b_relu
I0529 14:44:57.194699 30229 net.cpp:444] res5b_relu <- res5b
I0529 14:44:57.194707 30229 net.cpp:405] res5b_relu -> res5b (in-place)
I0529 14:44:57.195158 30229 net.cpp:150] Setting up res5b_relu
I0529 14:44:57.195168 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.195169 30229 net.cpp:165] Memory required for data: 251883532
I0529 14:44:57.195174 30229 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0529 14:44:57.195184 30229 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0529 14:44:57.195190 30229 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0529 14:44:57.195202 30229 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0529 14:44:57.195217 30229 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0529 14:44:57.195281 30229 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0529 14:44:57.195289 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.195293 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.195296 30229 net.cpp:165] Memory required for data: 255094796
I0529 14:44:57.195298 30229 layer_factory.hpp:77] Creating layer res5c_branch2a
I0529 14:44:57.195314 30229 net.cpp:100] Creating Layer res5c_branch2a
I0529 14:44:57.195320 30229 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0529 14:44:57.195333 30229 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0529 14:44:57.199020 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.199049 30229 net.cpp:150] Setting up res5c_branch2a
I0529 14:44:57.199060 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.199064 30229 net.cpp:165] Memory required for data: 255496204
I0529 14:44:57.199080 30229 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0529 14:44:57.199101 30229 net.cpp:100] Creating Layer bn5c_branch2a
I0529 14:44:57.199110 30229 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0529 14:44:57.199128 30229 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0529 14:44:57.199437 30229 net.cpp:150] Setting up bn5c_branch2a
I0529 14:44:57.199445 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.199446 30229 net.cpp:165] Memory required for data: 255897612
I0529 14:44:57.199462 30229 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0529 14:44:57.199476 30229 net.cpp:100] Creating Layer scale5c_branch2a
I0529 14:44:57.199481 30229 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0529 14:44:57.199492 30229 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0529 14:44:57.199556 30229 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0529 14:44:57.199750 30229 net.cpp:150] Setting up scale5c_branch2a
I0529 14:44:57.199757 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.199759 30229 net.cpp:165] Memory required for data: 256299020
I0529 14:44:57.199770 30229 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0529 14:44:57.199779 30229 net.cpp:100] Creating Layer res5c_branch2a_relu
I0529 14:44:57.199785 30229 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0529 14:44:57.199795 30229 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0529 14:44:57.199947 30229 net.cpp:150] Setting up res5c_branch2a_relu
I0529 14:44:57.199954 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.199956 30229 net.cpp:165] Memory required for data: 256700428
I0529 14:44:57.199960 30229 layer_factory.hpp:77] Creating layer res5c_branch2b
I0529 14:44:57.199975 30229 net.cpp:100] Creating Layer res5c_branch2b
I0529 14:44:57.199980 30229 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0529 14:44:57.199992 30229 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0529 14:44:57.205874 30229 net.cpp:150] Setting up res5c_branch2b
I0529 14:44:57.205904 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.205905 30229 net.cpp:165] Memory required for data: 257101836
I0529 14:44:57.205929 30229 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0529 14:44:57.205963 30229 net.cpp:100] Creating Layer bn5c_branch2b
I0529 14:44:57.205976 30229 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0529 14:44:57.205993 30229 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0529 14:44:57.206327 30229 net.cpp:150] Setting up bn5c_branch2b
I0529 14:44:57.206334 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.206336 30229 net.cpp:165] Memory required for data: 257503244
I0529 14:44:57.206351 30229 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0529 14:44:57.206367 30229 net.cpp:100] Creating Layer scale5c_branch2b
I0529 14:44:57.206370 30229 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0529 14:44:57.206382 30229 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0529 14:44:57.206452 30229 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0529 14:44:57.206651 30229 net.cpp:150] Setting up scale5c_branch2b
I0529 14:44:57.206658 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.206660 30229 net.cpp:165] Memory required for data: 257904652
I0529 14:44:57.206670 30229 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0529 14:44:57.206681 30229 net.cpp:100] Creating Layer res5c_branch2b_relu
I0529 14:44:57.206686 30229 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0529 14:44:57.206696 30229 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0529 14:44:57.206912 30229 net.cpp:150] Setting up res5c_branch2b_relu
I0529 14:44:57.206918 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.206921 30229 net.cpp:165] Memory required for data: 258306060
I0529 14:44:57.206925 30229 layer_factory.hpp:77] Creating layer res5c_branch2c
I0529 14:44:57.206941 30229 net.cpp:100] Creating Layer res5c_branch2c
I0529 14:44:57.206948 30229 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0529 14:44:57.206959 30229 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0529 14:44:57.210814 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0529 14:44:57.210847 30229 net.cpp:150] Setting up res5c_branch2c
I0529 14:44:57.210860 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.210863 30229 net.cpp:165] Memory required for data: 259911692
I0529 14:44:57.210881 30229 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0529 14:44:57.210904 30229 net.cpp:100] Creating Layer bn5c_branch2c
I0529 14:44:57.210913 30229 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0529 14:44:57.210929 30229 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0529 14:44:57.211257 30229 net.cpp:150] Setting up bn5c_branch2c
I0529 14:44:57.211264 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.211266 30229 net.cpp:165] Memory required for data: 261517324
I0529 14:44:57.211282 30229 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0529 14:44:57.211297 30229 net.cpp:100] Creating Layer scale5c_branch2c
I0529 14:44:57.211302 30229 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0529 14:44:57.211313 30229 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0529 14:44:57.211381 30229 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0529 14:44:57.211581 30229 net.cpp:150] Setting up scale5c_branch2c
I0529 14:44:57.211588 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.211591 30229 net.cpp:165] Memory required for data: 263122956
I0529 14:44:57.211602 30229 layer_factory.hpp:77] Creating layer res5c
I0529 14:44:57.211617 30229 net.cpp:100] Creating Layer res5c
I0529 14:44:57.211623 30229 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0529 14:44:57.211632 30229 net.cpp:444] res5c <- res5c_branch2c
I0529 14:44:57.211642 30229 net.cpp:418] res5c -> res5c
I0529 14:44:57.211685 30229 net.cpp:150] Setting up res5c
I0529 14:44:57.211694 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.211695 30229 net.cpp:165] Memory required for data: 264728588
I0529 14:44:57.211699 30229 layer_factory.hpp:77] Creating layer res5c_relu
I0529 14:44:57.211709 30229 net.cpp:100] Creating Layer res5c_relu
I0529 14:44:57.211714 30229 net.cpp:444] res5c_relu <- res5c
I0529 14:44:57.211724 30229 net.cpp:405] res5c_relu -> res5c (in-place)
I0529 14:44:57.211877 30229 net.cpp:150] Setting up res5c_relu
I0529 14:44:57.211884 30229 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0529 14:44:57.211886 30229 net.cpp:165] Memory required for data: 266334220
I0529 14:44:57.211890 30229 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0529 14:44:57.211907 30229 net.cpp:100] Creating Layer rpn_conv/3x3
I0529 14:44:57.211913 30229 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0529 14:44:57.211928 30229 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0529 14:44:57.738337 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0529 14:44:57.738672 30229 net.cpp:150] Setting up rpn_conv/3x3
I0529 14:44:57.738690 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.738692 30229 net.cpp:165] Memory required for data: 266735628
I0529 14:44:57.738714 30229 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0529 14:44:57.738736 30229 net.cpp:100] Creating Layer rpn_relu/3x3
I0529 14:44:57.738746 30229 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0529 14:44:57.738764 30229 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0529 14:44:57.739198 30229 net.cpp:150] Setting up rpn_relu/3x3
I0529 14:44:57.739207 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.739209 30229 net.cpp:165] Memory required for data: 267137036
I0529 14:44:57.739213 30229 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0529 14:44:57.739223 30229 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0529 14:44:57.739228 30229 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0529 14:44:57.739241 30229 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0529 14:44:57.739255 30229 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0529 14:44:57.739331 30229 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0529 14:44:57.739339 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.739342 30229 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0529 14:44:57.739344 30229 net.cpp:165] Memory required for data: 267939852
I0529 14:44:57.739348 30229 layer_factory.hpp:77] Creating layer rpn_cls_score
I0529 14:44:57.739367 30229 net.cpp:100] Creating Layer rpn_cls_score
I0529 14:44:57.739372 30229 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0529 14:44:57.739388 30229 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0529 14:44:57.741791 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.741816 30229 net.cpp:150] Setting up rpn_cls_score
I0529 14:44:57.741822 30229 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0529 14:44:57.741824 30229 net.cpp:165] Memory required for data: 267957100
I0529 14:44:57.741835 30229 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0529 14:44:57.741854 30229 net.cpp:100] Creating Layer rpn_bbox_pred
I0529 14:44:57.741861 30229 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0529 14:44:57.741875 30229 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0529 14:44:57.745528 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.745553 30229 net.cpp:150] Setting up rpn_bbox_pred
I0529 14:44:57.745559 30229 net.cpp:157] Top shape: 1 44 14 14 (8624)
I0529 14:44:57.745561 30229 net.cpp:165] Memory required for data: 267991596
I0529 14:44:57.745573 30229 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0529 14:44:57.745587 30229 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0529 14:44:57.745594 30229 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score
I0529 14:44:57.745605 30229 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0529 14:44:57.745651 30229 net.cpp:150] Setting up rpn_cls_score_reshape
I0529 14:44:57.745659 30229 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0529 14:44:57.745661 30229 net.cpp:165] Memory required for data: 268008844
I0529 14:44:57.745666 30229 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0529 14:44:57.745674 30229 net.cpp:100] Creating Layer rpn_cls_prob
I0529 14:44:57.745678 30229 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape
I0529 14:44:57.745688 30229 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0529 14:44:57.745936 30229 net.cpp:150] Setting up rpn_cls_prob
I0529 14:44:57.745945 30229 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0529 14:44:57.745949 30229 net.cpp:165] Memory required for data: 268026092
I0529 14:44:57.745954 30229 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0529 14:44:57.745963 30229 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0529 14:44:57.745968 30229 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0529 14:44:57.745980 30229 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0529 14:44:57.746026 30229 net.cpp:150] Setting up rpn_cls_prob_reshape
I0529 14:44:57.746034 30229 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0529 14:44:57.746037 30229 net.cpp:165] Memory required for data: 268043340
I0529 14:44:57.746040 30229 layer_factory.hpp:77] Creating layer proposal
I0529 14:44:57.746335 30229 net.cpp:100] Creating Layer proposal
I0529 14:44:57.746345 30229 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0529 14:44:57.746357 30229 net.cpp:444] proposal <- rpn_bbox_pred
I0529 14:44:57.746363 30229 net.cpp:444] proposal <- im_info
I0529 14:44:57.746373 30229 net.cpp:418] proposal -> rois
I0529 14:44:57.747509 30229 net.cpp:150] Setting up proposal
I0529 14:44:57.747521 30229 net.cpp:157] Top shape: 1 5 (5)
I0529 14:44:57.747524 30229 net.cpp:165] Memory required for data: 268043360
I0529 14:44:57.747529 30229 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0529 14:44:57.747539 30229 net.cpp:100] Creating Layer rois_proposal_0_split
I0529 14:44:57.747545 30229 net.cpp:444] rois_proposal_0_split <- rois
I0529 14:44:57.747558 30229 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_0
I0529 14:44:57.747572 30229 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_1
I0529 14:44:57.747634 30229 net.cpp:150] Setting up rois_proposal_0_split
I0529 14:44:57.747642 30229 net.cpp:157] Top shape: 1 5 (5)
I0529 14:44:57.747645 30229 net.cpp:157] Top shape: 1 5 (5)
I0529 14:44:57.747648 30229 net.cpp:165] Memory required for data: 268043400
I0529 14:44:57.747651 30229 layer_factory.hpp:77] Creating layer conv_new_1
I0529 14:44:57.747666 30229 net.cpp:100] Creating Layer conv_new_1
I0529 14:44:57.747673 30229 net.cpp:444] conv_new_1 <- res5c
I0529 14:44:57.747686 30229 net.cpp:418] conv_new_1 -> conv_new_1
I0529 14:44:57.982764 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.982800 30229 net.cpp:150] Setting up conv_new_1
I0529 14:44:57.982812 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.982815 30229 net.cpp:165] Memory required for data: 268846216
I0529 14:44:57.982836 30229 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0529 14:44:57.982856 30229 net.cpp:100] Creating Layer conv_new_1_relu
I0529 14:44:57.982867 30229 net.cpp:444] conv_new_1_relu <- conv_new_1
I0529 14:44:57.982884 30229 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0529 14:44:57.983039 30229 net.cpp:150] Setting up conv_new_1_relu
I0529 14:44:57.983045 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.983047 30229 net.cpp:165] Memory required for data: 269649032
I0529 14:44:57.983052 30229 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0529 14:44:57.983062 30229 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0529 14:44:57.983065 30229 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0529 14:44:57.983075 30229 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0529 14:44:57.983090 30229 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0529 14:44:57.983166 30229 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0529 14:44:57.983175 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.983177 30229 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0529 14:44:57.983180 30229 net.cpp:165] Memory required for data: 271254664
I0529 14:44:57.983182 30229 layer_factory.hpp:77] Creating layer rfcn_cls
I0529 14:44:57.983202 30229 net.cpp:100] Creating Layer rfcn_cls
I0529 14:44:57.983206 30229 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0529 14:44:57.983222 30229 net.cpp:418] rfcn_cls -> rfcn_cls
I0529 14:44:57.995563 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:57.995592 30229 net.cpp:150] Setting up rfcn_cls
I0529 14:44:57.995625 30229 net.cpp:157] Top shape: 1 98 14 14 (19208)
I0529 14:44:57.995628 30229 net.cpp:165] Memory required for data: 271331496
I0529 14:44:57.995643 30229 layer_factory.hpp:77] Creating layer rfcn_bbox
I0529 14:44:57.995692 30229 net.cpp:100] Creating Layer rfcn_bbox
I0529 14:44:57.995699 30229 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0529 14:44:57.995717 30229 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0529 14:44:58.042448 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0529 14:44:58.042480 30229 net.cpp:150] Setting up rfcn_bbox
I0529 14:44:58.042495 30229 net.cpp:157] Top shape: 1 392 14 14 (76832)
I0529 14:44:58.042497 30229 net.cpp:165] Memory required for data: 271638824
I0529 14:44:58.042520 30229 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0529 14:44:58.042543 30229 net.cpp:100] Creating Layer psroipooled_cls_rois
I0529 14:44:58.042552 30229 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0529 14:44:58.042567 30229 net.cpp:444] psroipooled_cls_rois <- rois_proposal_0_split_0
I0529 14:44:58.042577 30229 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0529 14:44:58.042596 30229 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0529 14:44:58.042671 30229 net.cpp:150] Setting up psroipooled_cls_rois
I0529 14:44:58.042678 30229 net.cpp:157] Top shape: 1 2 7 7 (98)
I0529 14:44:58.042680 30229 net.cpp:165] Memory required for data: 271639216
I0529 14:44:58.042685 30229 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0529 14:44:58.042695 30229 net.cpp:100] Creating Layer ave_cls_score_rois
I0529 14:44:58.042699 30229 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0529 14:44:58.042711 30229 net.cpp:418] ave_cls_score_rois -> cls_score
I0529 14:44:58.043236 30229 net.cpp:150] Setting up ave_cls_score_rois
I0529 14:44:58.043246 30229 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 14:44:58.043248 30229 net.cpp:165] Memory required for data: 271639224
I0529 14:44:58.043252 30229 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0529 14:44:58.043263 30229 net.cpp:100] Creating Layer psroipooled_loc_rois
I0529 14:44:58.043268 30229 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0529 14:44:58.043278 30229 net.cpp:444] psroipooled_loc_rois <- rois_proposal_0_split_1
I0529 14:44:58.043287 30229 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0529 14:44:58.043301 30229 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0529 14:44:58.043360 30229 net.cpp:150] Setting up psroipooled_loc_rois
I0529 14:44:58.043368 30229 net.cpp:157] Top shape: 1 8 7 7 (392)
I0529 14:44:58.043370 30229 net.cpp:165] Memory required for data: 271640792
I0529 14:44:58.043375 30229 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0529 14:44:58.043383 30229 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0529 14:44:58.043388 30229 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0529 14:44:58.043401 30229 net.cpp:418] ave_bbox_pred_rois -> bbox_pred_pre
I0529 14:44:58.043581 30229 net.cpp:150] Setting up ave_bbox_pred_rois
I0529 14:44:58.043589 30229 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 14:44:58.043592 30229 net.cpp:165] Memory required for data: 271640824
I0529 14:44:58.043596 30229 layer_factory.hpp:77] Creating layer cls_prob
I0529 14:44:58.043606 30229 net.cpp:100] Creating Layer cls_prob
I0529 14:44:58.043612 30229 net.cpp:444] cls_prob <- cls_score
I0529 14:44:58.043623 30229 net.cpp:418] cls_prob -> cls_prob_pre
I0529 14:44:58.043870 30229 net.cpp:150] Setting up cls_prob
I0529 14:44:58.043879 30229 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 14:44:58.043882 30229 net.cpp:165] Memory required for data: 271640832
I0529 14:44:58.043886 30229 layer_factory.hpp:77] Creating layer cls_prob_reshape
I0529 14:44:58.043900 30229 net.cpp:100] Creating Layer cls_prob_reshape
I0529 14:44:58.043905 30229 net.cpp:444] cls_prob_reshape <- cls_prob_pre
I0529 14:44:58.043916 30229 net.cpp:418] cls_prob_reshape -> cls_prob
I0529 14:44:58.043962 30229 net.cpp:150] Setting up cls_prob_reshape
I0529 14:44:58.043969 30229 net.cpp:157] Top shape: 1 2 (2)
I0529 14:44:58.043972 30229 net.cpp:165] Memory required for data: 271640840
I0529 14:44:58.043975 30229 layer_factory.hpp:77] Creating layer bbox_pred_reshape
I0529 14:44:58.043984 30229 net.cpp:100] Creating Layer bbox_pred_reshape
I0529 14:44:58.043988 30229 net.cpp:444] bbox_pred_reshape <- bbox_pred_pre
I0529 14:44:58.044000 30229 net.cpp:418] bbox_pred_reshape -> bbox_pred
I0529 14:44:58.044042 30229 net.cpp:150] Setting up bbox_pred_reshape
I0529 14:44:58.044049 30229 net.cpp:157] Top shape: 1 8 (8)
I0529 14:44:58.044051 30229 net.cpp:165] Memory required for data: 271640872
I0529 14:44:58.044055 30229 net.cpp:228] bbox_pred_reshape does not need backward computation.
I0529 14:44:58.044059 30229 net.cpp:228] cls_prob_reshape does not need backward computation.
I0529 14:44:58.044062 30229 net.cpp:228] cls_prob does not need backward computation.
I0529 14:44:58.044065 30229 net.cpp:228] ave_bbox_pred_rois does not need backward computation.
I0529 14:44:58.044067 30229 net.cpp:228] psroipooled_loc_rois does not need backward computation.
I0529 14:44:58.044071 30229 net.cpp:228] ave_cls_score_rois does not need backward computation.
I0529 14:44:58.044073 30229 net.cpp:228] psroipooled_cls_rois does not need backward computation.
I0529 14:44:58.044077 30229 net.cpp:228] rfcn_bbox does not need backward computation.
I0529 14:44:58.044080 30229 net.cpp:228] rfcn_cls does not need backward computation.
I0529 14:44:58.044085 30229 net.cpp:228] conv_new_1_conv_new_1_relu_0_split does not need backward computation.
I0529 14:44:58.044087 30229 net.cpp:228] conv_new_1_relu does not need backward computation.
I0529 14:44:58.044090 30229 net.cpp:228] conv_new_1 does not need backward computation.
I0529 14:44:58.044093 30229 net.cpp:228] rois_proposal_0_split does not need backward computation.
I0529 14:44:58.044096 30229 net.cpp:228] proposal does not need backward computation.
I0529 14:44:58.044102 30229 net.cpp:228] rpn_cls_prob_reshape does not need backward computation.
I0529 14:44:58.044106 30229 net.cpp:228] rpn_cls_prob does not need backward computation.
I0529 14:44:58.044108 30229 net.cpp:228] rpn_cls_score_reshape does not need backward computation.
I0529 14:44:58.044111 30229 net.cpp:228] rpn_bbox_pred does not need backward computation.
I0529 14:44:58.044116 30229 net.cpp:228] rpn_cls_score does not need backward computation.
I0529 14:44:58.044118 30229 net.cpp:228] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0529 14:44:58.044121 30229 net.cpp:228] rpn_relu/3x3 does not need backward computation.
I0529 14:44:58.044124 30229 net.cpp:228] rpn_conv/3x3 does not need backward computation.
I0529 14:44:58.044128 30229 net.cpp:228] res5c_relu does not need backward computation.
I0529 14:44:58.044131 30229 net.cpp:228] res5c does not need backward computation.
I0529 14:44:58.044134 30229 net.cpp:228] scale5c_branch2c does not need backward computation.
I0529 14:44:58.044138 30229 net.cpp:228] bn5c_branch2c does not need backward computation.
I0529 14:44:58.044142 30229 net.cpp:228] res5c_branch2c does not need backward computation.
I0529 14:44:58.044144 30229 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I0529 14:44:58.044147 30229 net.cpp:228] scale5c_branch2b does not need backward computation.
I0529 14:44:58.044149 30229 net.cpp:228] bn5c_branch2b does not need backward computation.
I0529 14:44:58.044152 30229 net.cpp:228] res5c_branch2b does not need backward computation.
I0529 14:44:58.044155 30229 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I0529 14:44:58.044157 30229 net.cpp:228] scale5c_branch2a does not need backward computation.
I0529 14:44:58.044160 30229 net.cpp:228] bn5c_branch2a does not need backward computation.
I0529 14:44:58.044163 30229 net.cpp:228] res5c_branch2a does not need backward computation.
I0529 14:44:58.044167 30229 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I0529 14:44:58.044169 30229 net.cpp:228] res5b_relu does not need backward computation.
I0529 14:44:58.044173 30229 net.cpp:228] res5b does not need backward computation.
I0529 14:44:58.044176 30229 net.cpp:228] scale5b_branch2c does not need backward computation.
I0529 14:44:58.044180 30229 net.cpp:228] bn5b_branch2c does not need backward computation.
I0529 14:44:58.044183 30229 net.cpp:228] res5b_branch2c does not need backward computation.
I0529 14:44:58.044185 30229 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I0529 14:44:58.044189 30229 net.cpp:228] scale5b_branch2b does not need backward computation.
I0529 14:44:58.044191 30229 net.cpp:228] bn5b_branch2b does not need backward computation.
I0529 14:44:58.044194 30229 net.cpp:228] res5b_branch2b does not need backward computation.
I0529 14:44:58.044198 30229 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I0529 14:44:58.044200 30229 net.cpp:228] scale5b_branch2a does not need backward computation.
I0529 14:44:58.044203 30229 net.cpp:228] bn5b_branch2a does not need backward computation.
I0529 14:44:58.044205 30229 net.cpp:228] res5b_branch2a does not need backward computation.
I0529 14:44:58.044209 30229 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I0529 14:44:58.044212 30229 net.cpp:228] res5a_relu does not need backward computation.
I0529 14:44:58.044215 30229 net.cpp:228] res5a does not need backward computation.
I0529 14:44:58.044219 30229 net.cpp:228] scale5a_branch2c does not need backward computation.
I0529 14:44:58.044221 30229 net.cpp:228] bn5a_branch2c does not need backward computation.
I0529 14:44:58.044224 30229 net.cpp:228] res5a_branch2c does not need backward computation.
I0529 14:44:58.044227 30229 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I0529 14:44:58.044230 30229 net.cpp:228] scale5a_branch2b does not need backward computation.
I0529 14:44:58.044232 30229 net.cpp:228] bn5a_branch2b does not need backward computation.
I0529 14:44:58.044235 30229 net.cpp:228] res5a_branch2b does not need backward computation.
I0529 14:44:58.044239 30229 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I0529 14:44:58.044241 30229 net.cpp:228] scale5a_branch2a does not need backward computation.
I0529 14:44:58.044243 30229 net.cpp:228] bn5a_branch2a does not need backward computation.
I0529 14:44:58.044246 30229 net.cpp:228] res5a_branch2a does not need backward computation.
I0529 14:44:58.044250 30229 net.cpp:228] scale5a_branch1 does not need backward computation.
I0529 14:44:58.044252 30229 net.cpp:228] bn5a_branch1 does not need backward computation.
I0529 14:44:58.044255 30229 net.cpp:228] res5a_branch1 does not need backward computation.
I0529 14:44:58.044260 30229 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I0529 14:44:58.044262 30229 net.cpp:228] res4f_relu does not need backward computation.
I0529 14:44:58.044265 30229 net.cpp:228] res4f does not need backward computation.
I0529 14:44:58.044270 30229 net.cpp:228] scale4f_branch2c does not need backward computation.
I0529 14:44:58.044272 30229 net.cpp:228] bn4f_branch2c does not need backward computation.
I0529 14:44:58.044275 30229 net.cpp:228] res4f_branch2c does not need backward computation.
I0529 14:44:58.044278 30229 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I0529 14:44:58.044281 30229 net.cpp:228] scale4f_branch2b does not need backward computation.
I0529 14:44:58.044284 30229 net.cpp:228] bn4f_branch2b does not need backward computation.
I0529 14:44:58.044286 30229 net.cpp:228] res4f_branch2b does not need backward computation.
I0529 14:44:58.044289 30229 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I0529 14:44:58.044292 30229 net.cpp:228] scale4f_branch2a does not need backward computation.
I0529 14:44:58.044296 30229 net.cpp:228] bn4f_branch2a does not need backward computation.
I0529 14:44:58.044297 30229 net.cpp:228] res4f_branch2a does not need backward computation.
I0529 14:44:58.044301 30229 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I0529 14:44:58.044304 30229 net.cpp:228] res4e_relu does not need backward computation.
I0529 14:44:58.044307 30229 net.cpp:228] res4e does not need backward computation.
I0529 14:44:58.044312 30229 net.cpp:228] scale4e_branch2c does not need backward computation.
I0529 14:44:58.044314 30229 net.cpp:228] bn4e_branch2c does not need backward computation.
I0529 14:44:58.044317 30229 net.cpp:228] res4e_branch2c does not need backward computation.
I0529 14:44:58.044320 30229 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I0529 14:44:58.044323 30229 net.cpp:228] scale4e_branch2b does not need backward computation.
I0529 14:44:58.044327 30229 net.cpp:228] bn4e_branch2b does not need backward computation.
I0529 14:44:58.044328 30229 net.cpp:228] res4e_branch2b does not need backward computation.
I0529 14:44:58.044332 30229 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I0529 14:44:58.044334 30229 net.cpp:228] scale4e_branch2a does not need backward computation.
I0529 14:44:58.044337 30229 net.cpp:228] bn4e_branch2a does not need backward computation.
I0529 14:44:58.044339 30229 net.cpp:228] res4e_branch2a does not need backward computation.
I0529 14:44:58.044342 30229 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I0529 14:44:58.044345 30229 net.cpp:228] res4d_relu does not need backward computation.
I0529 14:44:58.044348 30229 net.cpp:228] res4d does not need backward computation.
I0529 14:44:58.044353 30229 net.cpp:228] scale4d_branch2c does not need backward computation.
I0529 14:44:58.044358 30229 net.cpp:228] bn4d_branch2c does not need backward computation.
I0529 14:44:58.044359 30229 net.cpp:228] res4d_branch2c does not need backward computation.
I0529 14:44:58.044363 30229 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I0529 14:44:58.044365 30229 net.cpp:228] scale4d_branch2b does not need backward computation.
I0529 14:44:58.044368 30229 net.cpp:228] bn4d_branch2b does not need backward computation.
I0529 14:44:58.044371 30229 net.cpp:228] res4d_branch2b does not need backward computation.
I0529 14:44:58.044373 30229 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I0529 14:44:58.044376 30229 net.cpp:228] scale4d_branch2a does not need backward computation.
I0529 14:44:58.044379 30229 net.cpp:228] bn4d_branch2a does not need backward computation.
I0529 14:44:58.044381 30229 net.cpp:228] res4d_branch2a does not need backward computation.
I0529 14:44:58.044385 30229 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I0529 14:44:58.044389 30229 net.cpp:228] res4c_relu does not need backward computation.
I0529 14:44:58.044391 30229 net.cpp:228] res4c does not need backward computation.
I0529 14:44:58.044395 30229 net.cpp:228] scale4c_branch2c does not need backward computation.
I0529 14:44:58.044397 30229 net.cpp:228] bn4c_branch2c does not need backward computation.
I0529 14:44:58.044400 30229 net.cpp:228] res4c_branch2c does not need backward computation.
I0529 14:44:58.044404 30229 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I0529 14:44:58.044406 30229 net.cpp:228] scale4c_branch2b does not need backward computation.
I0529 14:44:58.044409 30229 net.cpp:228] bn4c_branch2b does not need backward computation.
I0529 14:44:58.044411 30229 net.cpp:228] res4c_branch2b does not need backward computation.
I0529 14:44:58.044414 30229 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I0529 14:44:58.044417 30229 net.cpp:228] scale4c_branch2a does not need backward computation.
I0529 14:44:58.044420 30229 net.cpp:228] bn4c_branch2a does not need backward computation.
I0529 14:44:58.044422 30229 net.cpp:228] res4c_branch2a does not need backward computation.
I0529 14:44:58.044425 30229 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I0529 14:44:58.044428 30229 net.cpp:228] res4b_relu does not need backward computation.
I0529 14:44:58.044431 30229 net.cpp:228] res4b does not need backward computation.
I0529 14:44:58.044435 30229 net.cpp:228] scale4b_branch2c does not need backward computation.
I0529 14:44:58.044440 30229 net.cpp:228] bn4b_branch2c does not need backward computation.
I0529 14:44:58.044442 30229 net.cpp:228] res4b_branch2c does not need backward computation.
I0529 14:44:58.044445 30229 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I0529 14:44:58.044448 30229 net.cpp:228] scale4b_branch2b does not need backward computation.
I0529 14:44:58.044451 30229 net.cpp:228] bn4b_branch2b does not need backward computation.
I0529 14:44:58.044453 30229 net.cpp:228] res4b_branch2b does not need backward computation.
I0529 14:44:58.044456 30229 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I0529 14:44:58.044459 30229 net.cpp:228] scale4b_branch2a does not need backward computation.
I0529 14:44:58.044462 30229 net.cpp:228] bn4b_branch2a does not need backward computation.
I0529 14:44:58.044466 30229 net.cpp:228] res4b_branch2a does not need backward computation.
I0529 14:44:58.044468 30229 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I0529 14:44:58.044471 30229 net.cpp:228] res4a_relu does not need backward computation.
I0529 14:44:58.044474 30229 net.cpp:228] res4a does not need backward computation.
I0529 14:44:58.044478 30229 net.cpp:228] scale4a_branch2c does not need backward computation.
I0529 14:44:58.044481 30229 net.cpp:228] bn4a_branch2c does not need backward computation.
I0529 14:44:58.044484 30229 net.cpp:228] res4a_branch2c does not need backward computation.
I0529 14:44:58.044487 30229 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I0529 14:44:58.044492 30229 net.cpp:228] scale4a_branch2b does not need backward computation.
I0529 14:44:58.044493 30229 net.cpp:228] bn4a_branch2b does not need backward computation.
I0529 14:44:58.044497 30229 net.cpp:228] res4a_branch2b does not need backward computation.
I0529 14:44:58.044500 30229 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I0529 14:44:58.044502 30229 net.cpp:228] scale4a_branch2a does not need backward computation.
I0529 14:44:58.044505 30229 net.cpp:228] bn4a_branch2a does not need backward computation.
I0529 14:44:58.044508 30229 net.cpp:228] res4a_branch2a does not need backward computation.
I0529 14:44:58.044512 30229 net.cpp:228] scale4a_branch1 does not need backward computation.
I0529 14:44:58.044514 30229 net.cpp:228] bn4a_branch1 does not need backward computation.
I0529 14:44:58.044517 30229 net.cpp:228] res4a_branch1 does not need backward computation.
I0529 14:44:58.044522 30229 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I0529 14:44:58.044524 30229 net.cpp:228] res3d_relu does not need backward computation.
I0529 14:44:58.044528 30229 net.cpp:228] res3d does not need backward computation.
I0529 14:44:58.044531 30229 net.cpp:228] scale3d_branch2c does not need backward computation.
I0529 14:44:58.044534 30229 net.cpp:228] bn3d_branch2c does not need backward computation.
I0529 14:44:58.044538 30229 net.cpp:228] res3d_branch2c does not need backward computation.
I0529 14:44:58.044540 30229 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I0529 14:44:58.044543 30229 net.cpp:228] scale3d_branch2b does not need backward computation.
I0529 14:44:58.044546 30229 net.cpp:228] bn3d_branch2b does not need backward computation.
I0529 14:44:58.044548 30229 net.cpp:228] res3d_branch2b does not need backward computation.
I0529 14:44:58.044551 30229 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I0529 14:44:58.044554 30229 net.cpp:228] scale3d_branch2a does not need backward computation.
I0529 14:44:58.044558 30229 net.cpp:228] bn3d_branch2a does not need backward computation.
I0529 14:44:58.044560 30229 net.cpp:228] res3d_branch2a does not need backward computation.
I0529 14:44:58.044564 30229 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I0529 14:44:58.044567 30229 net.cpp:228] res3c_relu does not need backward computation.
I0529 14:44:58.044569 30229 net.cpp:228] res3c does not need backward computation.
I0529 14:44:58.044574 30229 net.cpp:228] scale3c_branch2c does not need backward computation.
I0529 14:44:58.044576 30229 net.cpp:228] bn3c_branch2c does not need backward computation.
I0529 14:44:58.044579 30229 net.cpp:228] res3c_branch2c does not need backward computation.
I0529 14:44:58.044582 30229 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I0529 14:44:58.044585 30229 net.cpp:228] scale3c_branch2b does not need backward computation.
I0529 14:44:58.044589 30229 net.cpp:228] bn3c_branch2b does not need backward computation.
I0529 14:44:58.044591 30229 net.cpp:228] res3c_branch2b does not need backward computation.
I0529 14:44:58.044595 30229 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I0529 14:44:58.044597 30229 net.cpp:228] scale3c_branch2a does not need backward computation.
I0529 14:44:58.044600 30229 net.cpp:228] bn3c_branch2a does not need backward computation.
I0529 14:44:58.044603 30229 net.cpp:228] res3c_branch2a does not need backward computation.
I0529 14:44:58.044607 30229 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I0529 14:44:58.044611 30229 net.cpp:228] res3b_relu does not need backward computation.
I0529 14:44:58.044615 30229 net.cpp:228] res3b does not need backward computation.
I0529 14:44:58.044618 30229 net.cpp:228] scale3b_branch2c does not need backward computation.
I0529 14:44:58.044622 30229 net.cpp:228] bn3b_branch2c does not need backward computation.
I0529 14:44:58.044625 30229 net.cpp:228] res3b_branch2c does not need backward computation.
I0529 14:44:58.044628 30229 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I0529 14:44:58.044631 30229 net.cpp:228] scale3b_branch2b does not need backward computation.
I0529 14:44:58.044634 30229 net.cpp:228] bn3b_branch2b does not need backward computation.
I0529 14:44:58.044637 30229 net.cpp:228] res3b_branch2b does not need backward computation.
I0529 14:44:58.044641 30229 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I0529 14:44:58.044643 30229 net.cpp:228] scale3b_branch2a does not need backward computation.
I0529 14:44:58.044646 30229 net.cpp:228] bn3b_branch2a does not need backward computation.
I0529 14:44:58.044649 30229 net.cpp:228] res3b_branch2a does not need backward computation.
I0529 14:44:58.044652 30229 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I0529 14:44:58.044656 30229 net.cpp:228] res3a_relu does not need backward computation.
I0529 14:44:58.044658 30229 net.cpp:228] res3a does not need backward computation.
I0529 14:44:58.044662 30229 net.cpp:228] scale3a_branch2c does not need backward computation.
I0529 14:44:58.044665 30229 net.cpp:228] bn3a_branch2c does not need backward computation.
I0529 14:44:58.044668 30229 net.cpp:228] res3a_branch2c does not need backward computation.
I0529 14:44:58.044672 30229 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I0529 14:44:58.044675 30229 net.cpp:228] scale3a_branch2b does not need backward computation.
I0529 14:44:58.044678 30229 net.cpp:228] bn3a_branch2b does not need backward computation.
I0529 14:44:58.044682 30229 net.cpp:228] res3a_branch2b does not need backward computation.
I0529 14:44:58.044684 30229 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I0529 14:44:58.044687 30229 net.cpp:228] scale3a_branch2a does not need backward computation.
I0529 14:44:58.044690 30229 net.cpp:228] bn3a_branch2a does not need backward computation.
I0529 14:44:58.044692 30229 net.cpp:228] res3a_branch2a does not need backward computation.
I0529 14:44:58.044697 30229 net.cpp:228] scale3a_branch1 does not need backward computation.
I0529 14:44:58.044699 30229 net.cpp:228] bn3a_branch1 does not need backward computation.
I0529 14:44:58.044701 30229 net.cpp:228] res3a_branch1 does not need backward computation.
I0529 14:44:58.044705 30229 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0529 14:44:58.044708 30229 net.cpp:228] res2c_relu does not need backward computation.
I0529 14:44:58.044711 30229 net.cpp:228] res2c does not need backward computation.
I0529 14:44:58.044715 30229 net.cpp:228] scale2c_branch2c does not need backward computation.
I0529 14:44:58.044718 30229 net.cpp:228] bn2c_branch2c does not need backward computation.
I0529 14:44:58.044721 30229 net.cpp:228] res2c_branch2c does not need backward computation.
I0529 14:44:58.044724 30229 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0529 14:44:58.044726 30229 net.cpp:228] scale2c_branch2b does not need backward computation.
I0529 14:44:58.044729 30229 net.cpp:228] bn2c_branch2b does not need backward computation.
I0529 14:44:58.044733 30229 net.cpp:228] res2c_branch2b does not need backward computation.
I0529 14:44:58.044735 30229 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0529 14:44:58.044739 30229 net.cpp:228] scale2c_branch2a does not need backward computation.
I0529 14:44:58.044740 30229 net.cpp:228] bn2c_branch2a does not need backward computation.
I0529 14:44:58.044744 30229 net.cpp:228] res2c_branch2a does not need backward computation.
I0529 14:44:58.044747 30229 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0529 14:44:58.044750 30229 net.cpp:228] res2b_relu does not need backward computation.
I0529 14:44:58.044754 30229 net.cpp:228] res2b does not need backward computation.
I0529 14:44:58.044757 30229 net.cpp:228] scale2b_branch2c does not need backward computation.
I0529 14:44:58.044760 30229 net.cpp:228] bn2b_branch2c does not need backward computation.
I0529 14:44:58.044764 30229 net.cpp:228] res2b_branch2c does not need backward computation.
I0529 14:44:58.044766 30229 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0529 14:44:58.044770 30229 net.cpp:228] scale2b_branch2b does not need backward computation.
I0529 14:44:58.044772 30229 net.cpp:228] bn2b_branch2b does not need backward computation.
I0529 14:44:58.044775 30229 net.cpp:228] res2b_branch2b does not need backward computation.
I0529 14:44:58.044778 30229 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0529 14:44:58.044780 30229 net.cpp:228] scale2b_branch2a does not need backward computation.
I0529 14:44:58.044785 30229 net.cpp:228] bn2b_branch2a does not need backward computation.
I0529 14:44:58.044786 30229 net.cpp:228] res2b_branch2a does not need backward computation.
I0529 14:44:58.044790 30229 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0529 14:44:58.044795 30229 net.cpp:228] res2a_relu does not need backward computation.
I0529 14:44:58.044797 30229 net.cpp:228] res2a does not need backward computation.
I0529 14:44:58.044801 30229 net.cpp:228] scale2a_branch2c does not need backward computation.
I0529 14:44:58.044806 30229 net.cpp:228] bn2a_branch2c does not need backward computation.
I0529 14:44:58.044809 30229 net.cpp:228] res2a_branch2c does not need backward computation.
I0529 14:44:58.044812 30229 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0529 14:44:58.044816 30229 net.cpp:228] scale2a_branch2b does not need backward computation.
I0529 14:44:58.044818 30229 net.cpp:228] bn2a_branch2b does not need backward computation.
I0529 14:44:58.044821 30229 net.cpp:228] res2a_branch2b does not need backward computation.
I0529 14:44:58.044823 30229 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0529 14:44:58.044826 30229 net.cpp:228] scale2a_branch2a does not need backward computation.
I0529 14:44:58.044829 30229 net.cpp:228] bn2a_branch2a does not need backward computation.
I0529 14:44:58.044832 30229 net.cpp:228] res2a_branch2a does not need backward computation.
I0529 14:44:58.044836 30229 net.cpp:228] scale2a_branch1 does not need backward computation.
I0529 14:44:58.044839 30229 net.cpp:228] bn2a_branch1 does not need backward computation.
I0529 14:44:58.044842 30229 net.cpp:228] res2a_branch1 does not need backward computation.
I0529 14:44:58.044845 30229 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0529 14:44:58.044849 30229 net.cpp:228] pool1 does not need backward computation.
I0529 14:44:58.044852 30229 net.cpp:228] conv1_relu does not need backward computation.
I0529 14:44:58.044855 30229 net.cpp:228] scale_conv1 does not need backward computation.
I0529 14:44:58.044858 30229 net.cpp:228] bn_conv1 does not need backward computation.
I0529 14:44:58.044860 30229 net.cpp:228] conv1 does not need backward computation.
I0529 14:44:58.044864 30229 net.cpp:228] input does not need backward computation.
I0529 14:44:58.044867 30229 net.cpp:270] This network produces output bbox_pred
I0529 14:44:58.044872 30229 net.cpp:270] This network produces output cls_prob
I0529 14:44:58.045156 30229 net.cpp:283] Network initialization done.
I0529 14:44:58.148865 30229 net.cpp:771] Ignoring source layer input-data
I0529 14:44:58.148886 30229 net.cpp:771] Ignoring source layer data_input-data_0_split
I0529 14:44:58.148905 30229 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I0529 14:44:58.148910 30229 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I0529 14:44:58.148916 30229 net.cpp:774] Copying source layer conv1
I0529 14:44:58.149001 30229 net.cpp:774] Copying source layer bn_conv1
I0529 14:44:58.149008 30229 net.cpp:774] Copying source layer scale_conv1
I0529 14:44:58.149013 30229 net.cpp:774] Copying source layer conv1_relu
I0529 14:44:58.149014 30229 net.cpp:774] Copying source layer pool1
I0529 14:44:58.149016 30229 net.cpp:774] Copying source layer pool1_pool1_0_split
I0529 14:44:58.149019 30229 net.cpp:774] Copying source layer res2a_branch1
I0529 14:44:58.149145 30229 net.cpp:774] Copying source layer bn2a_branch1
I0529 14:44:58.149168 30229 net.cpp:774] Copying source layer scale2a_branch1
I0529 14:44:58.149178 30229 net.cpp:774] Copying source layer res2a_branch2a
I0529 14:44:58.149209 30229 net.cpp:774] Copying source layer bn2a_branch2a
I0529 14:44:58.149215 30229 net.cpp:774] Copying source layer scale2a_branch2a
I0529 14:44:58.149220 30229 net.cpp:774] Copying source layer res2a_branch2a_relu
I0529 14:44:58.149222 30229 net.cpp:774] Copying source layer res2a_branch2b
I0529 14:44:58.149485 30229 net.cpp:774] Copying source layer bn2a_branch2b
I0529 14:44:58.149507 30229 net.cpp:774] Copying source layer scale2a_branch2b
I0529 14:44:58.149513 30229 net.cpp:774] Copying source layer res2a_branch2b_relu
I0529 14:44:58.149514 30229 net.cpp:774] Copying source layer res2a_branch2c
I0529 14:44:58.149641 30229 net.cpp:774] Copying source layer bn2a_branch2c
I0529 14:44:58.149664 30229 net.cpp:774] Copying source layer scale2a_branch2c
I0529 14:44:58.149672 30229 net.cpp:774] Copying source layer res2a
I0529 14:44:58.149675 30229 net.cpp:774] Copying source layer res2a_relu
I0529 14:44:58.149677 30229 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0529 14:44:58.149679 30229 net.cpp:774] Copying source layer res2b_branch2a
I0529 14:44:58.149806 30229 net.cpp:774] Copying source layer bn2b_branch2a
I0529 14:44:58.149827 30229 net.cpp:774] Copying source layer scale2b_branch2a
I0529 14:44:58.149832 30229 net.cpp:774] Copying source layer res2b_branch2a_relu
I0529 14:44:58.149834 30229 net.cpp:774] Copying source layer res2b_branch2b
I0529 14:44:58.150096 30229 net.cpp:774] Copying source layer bn2b_branch2b
I0529 14:44:58.150117 30229 net.cpp:774] Copying source layer scale2b_branch2b
I0529 14:44:58.150123 30229 net.cpp:774] Copying source layer res2b_branch2b_relu
I0529 14:44:58.150125 30229 net.cpp:774] Copying source layer res2b_branch2c
I0529 14:44:58.150251 30229 net.cpp:774] Copying source layer bn2b_branch2c
I0529 14:44:58.150274 30229 net.cpp:774] Copying source layer scale2b_branch2c
I0529 14:44:58.150283 30229 net.cpp:774] Copying source layer res2b
I0529 14:44:58.150286 30229 net.cpp:774] Copying source layer res2b_relu
I0529 14:44:58.150288 30229 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0529 14:44:58.150290 30229 net.cpp:774] Copying source layer res2c_branch2a
I0529 14:44:58.150404 30229 net.cpp:774] Copying source layer bn2c_branch2a
I0529 14:44:58.150411 30229 net.cpp:774] Copying source layer scale2c_branch2a
I0529 14:44:58.150418 30229 net.cpp:774] Copying source layer res2c_branch2a_relu
I0529 14:44:58.150420 30229 net.cpp:774] Copying source layer res2c_branch2b
I0529 14:44:58.150674 30229 net.cpp:774] Copying source layer bn2c_branch2b
I0529 14:44:58.150681 30229 net.cpp:774] Copying source layer scale2c_branch2b
I0529 14:44:58.150688 30229 net.cpp:774] Copying source layer res2c_branch2b_relu
I0529 14:44:58.150691 30229 net.cpp:774] Copying source layer res2c_branch2c
I0529 14:44:58.150806 30229 net.cpp:774] Copying source layer bn2c_branch2c
I0529 14:44:58.150816 30229 net.cpp:774] Copying source layer scale2c_branch2c
I0529 14:44:58.150825 30229 net.cpp:774] Copying source layer res2c
I0529 14:44:58.150828 30229 net.cpp:774] Copying source layer res2c_relu
I0529 14:44:58.150831 30229 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0529 14:44:58.150835 30229 net.cpp:774] Copying source layer res3a_branch1
I0529 14:44:58.151726 30229 net.cpp:774] Copying source layer bn3a_branch1
I0529 14:44:58.151741 30229 net.cpp:774] Copying source layer scale3a_branch1
I0529 14:44:58.151752 30229 net.cpp:774] Copying source layer res3a_branch2a
I0529 14:44:58.151980 30229 net.cpp:774] Copying source layer bn3a_branch2a
I0529 14:44:58.151989 30229 net.cpp:774] Copying source layer scale3a_branch2a
I0529 14:44:58.151996 30229 net.cpp:774] Copying source layer res3a_branch2a_relu
I0529 14:44:58.151999 30229 net.cpp:774] Copying source layer res3a_branch2b
I0529 14:44:58.153007 30229 net.cpp:774] Copying source layer bn3a_branch2b
I0529 14:44:58.153015 30229 net.cpp:774] Copying source layer scale3a_branch2b
I0529 14:44:58.153023 30229 net.cpp:774] Copying source layer res3a_branch2b_relu
I0529 14:44:58.153026 30229 net.cpp:774] Copying source layer res3a_branch2c
I0529 14:44:58.153475 30229 net.cpp:774] Copying source layer bn3a_branch2c
I0529 14:44:58.153491 30229 net.cpp:774] Copying source layer scale3a_branch2c
I0529 14:44:58.153502 30229 net.cpp:774] Copying source layer res3a
I0529 14:44:58.153506 30229 net.cpp:774] Copying source layer res3a_relu
I0529 14:44:58.153509 30229 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0529 14:44:58.153512 30229 net.cpp:774] Copying source layer res3b_branch2a
I0529 14:44:58.153961 30229 net.cpp:774] Copying source layer bn3b_branch2a
I0529 14:44:58.153970 30229 net.cpp:774] Copying source layer scale3b_branch2a
I0529 14:44:58.153977 30229 net.cpp:774] Copying source layer res3b_branch2a_relu
I0529 14:44:58.153981 30229 net.cpp:774] Copying source layer res3b_branch2b
I0529 14:44:58.154985 30229 net.cpp:774] Copying source layer bn3b_branch2b
I0529 14:44:58.154994 30229 net.cpp:774] Copying source layer scale3b_branch2b
I0529 14:44:58.155001 30229 net.cpp:774] Copying source layer res3b_branch2b_relu
I0529 14:44:58.155005 30229 net.cpp:774] Copying source layer res3b_branch2c
I0529 14:44:58.155453 30229 net.cpp:774] Copying source layer bn3b_branch2c
I0529 14:44:58.155468 30229 net.cpp:774] Copying source layer scale3b_branch2c
I0529 14:44:58.155480 30229 net.cpp:774] Copying source layer res3b
I0529 14:44:58.155484 30229 net.cpp:774] Copying source layer res3b_relu
I0529 14:44:58.155488 30229 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0529 14:44:58.155490 30229 net.cpp:774] Copying source layer res3c_branch2a
I0529 14:44:58.155941 30229 net.cpp:774] Copying source layer bn3c_branch2a
I0529 14:44:58.155949 30229 net.cpp:774] Copying source layer scale3c_branch2a
I0529 14:44:58.155957 30229 net.cpp:774] Copying source layer res3c_branch2a_relu
I0529 14:44:58.155961 30229 net.cpp:774] Copying source layer res3c_branch2b
I0529 14:44:58.156966 30229 net.cpp:774] Copying source layer bn3c_branch2b
I0529 14:44:58.156976 30229 net.cpp:774] Copying source layer scale3c_branch2b
I0529 14:44:58.156985 30229 net.cpp:774] Copying source layer res3c_branch2b_relu
I0529 14:44:58.156987 30229 net.cpp:774] Copying source layer res3c_branch2c
I0529 14:44:58.157438 30229 net.cpp:774] Copying source layer bn3c_branch2c
I0529 14:44:58.157451 30229 net.cpp:774] Copying source layer scale3c_branch2c
I0529 14:44:58.157464 30229 net.cpp:774] Copying source layer res3c
I0529 14:44:58.157467 30229 net.cpp:774] Copying source layer res3c_relu
I0529 14:44:58.157471 30229 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0529 14:44:58.157475 30229 net.cpp:774] Copying source layer res3d_branch2a
I0529 14:44:58.157924 30229 net.cpp:774] Copying source layer bn3d_branch2a
I0529 14:44:58.157933 30229 net.cpp:774] Copying source layer scale3d_branch2a
I0529 14:44:58.157941 30229 net.cpp:774] Copying source layer res3d_branch2a_relu
I0529 14:44:58.157945 30229 net.cpp:774] Copying source layer res3d_branch2b
I0529 14:44:58.158949 30229 net.cpp:774] Copying source layer bn3d_branch2b
I0529 14:44:58.158959 30229 net.cpp:774] Copying source layer scale3d_branch2b
I0529 14:44:58.158967 30229 net.cpp:774] Copying source layer res3d_branch2b_relu
I0529 14:44:58.158972 30229 net.cpp:774] Copying source layer res3d_branch2c
I0529 14:44:58.159420 30229 net.cpp:774] Copying source layer bn3d_branch2c
I0529 14:44:58.159435 30229 net.cpp:774] Copying source layer scale3d_branch2c
I0529 14:44:58.159448 30229 net.cpp:774] Copying source layer res3d
I0529 14:44:58.159452 30229 net.cpp:774] Copying source layer res3d_relu
I0529 14:44:58.159456 30229 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0529 14:44:58.159459 30229 net.cpp:774] Copying source layer res4a_branch1
I0529 14:44:58.163064 30229 net.cpp:774] Copying source layer bn4a_branch1
I0529 14:44:58.163094 30229 net.cpp:774] Copying source layer scale4a_branch1
I0529 14:44:58.163115 30229 net.cpp:774] Copying source layer res4a_branch2a
I0529 14:44:58.164010 30229 net.cpp:774] Copying source layer bn4a_branch2a
I0529 14:44:58.164023 30229 net.cpp:774] Copying source layer scale4a_branch2a
I0529 14:44:58.164033 30229 net.cpp:774] Copying source layer res4a_branch2a_relu
I0529 14:44:58.164036 30229 net.cpp:774] Copying source layer res4a_branch2b
I0529 14:44:58.168045 30229 net.cpp:774] Copying source layer bn4a_branch2b
I0529 14:44:58.168059 30229 net.cpp:774] Copying source layer scale4a_branch2b
I0529 14:44:58.168069 30229 net.cpp:774] Copying source layer res4a_branch2b_relu
I0529 14:44:58.168072 30229 net.cpp:774] Copying source layer res4a_branch2c
I0529 14:44:58.169872 30229 net.cpp:774] Copying source layer bn4a_branch2c
I0529 14:44:58.169895 30229 net.cpp:774] Copying source layer scale4a_branch2c
I0529 14:44:58.169915 30229 net.cpp:774] Copying source layer res4a
I0529 14:44:58.169919 30229 net.cpp:774] Copying source layer res4a_relu
I0529 14:44:58.169924 30229 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0529 14:44:58.169926 30229 net.cpp:774] Copying source layer res4b_branch2a
I0529 14:44:58.171712 30229 net.cpp:774] Copying source layer bn4b_branch2a
I0529 14:44:58.171725 30229 net.cpp:774] Copying source layer scale4b_branch2a
I0529 14:44:58.171736 30229 net.cpp:774] Copying source layer res4b_branch2a_relu
I0529 14:44:58.171739 30229 net.cpp:774] Copying source layer res4b_branch2b
I0529 14:44:58.175768 30229 net.cpp:774] Copying source layer bn4b_branch2b
I0529 14:44:58.175787 30229 net.cpp:774] Copying source layer scale4b_branch2b
I0529 14:44:58.175797 30229 net.cpp:774] Copying source layer res4b_branch2b_relu
I0529 14:44:58.175801 30229 net.cpp:774] Copying source layer res4b_branch2c
I0529 14:44:58.177603 30229 net.cpp:774] Copying source layer bn4b_branch2c
I0529 14:44:58.177641 30229 net.cpp:774] Copying source layer scale4b_branch2c
I0529 14:44:58.177661 30229 net.cpp:774] Copying source layer res4b
I0529 14:44:58.177665 30229 net.cpp:774] Copying source layer res4b_relu
I0529 14:44:58.177670 30229 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0529 14:44:58.177672 30229 net.cpp:774] Copying source layer res4c_branch2a
I0529 14:44:58.179472 30229 net.cpp:774] Copying source layer bn4c_branch2a
I0529 14:44:58.179486 30229 net.cpp:774] Copying source layer scale4c_branch2a
I0529 14:44:58.179497 30229 net.cpp:774] Copying source layer res4c_branch2a_relu
I0529 14:44:58.179500 30229 net.cpp:774] Copying source layer res4c_branch2b
I0529 14:44:58.183528 30229 net.cpp:774] Copying source layer bn4c_branch2b
I0529 14:44:58.183544 30229 net.cpp:774] Copying source layer scale4c_branch2b
I0529 14:44:58.183555 30229 net.cpp:774] Copying source layer res4c_branch2b_relu
I0529 14:44:58.183559 30229 net.cpp:774] Copying source layer res4c_branch2c
I0529 14:44:58.185355 30229 net.cpp:774] Copying source layer bn4c_branch2c
I0529 14:44:58.185380 30229 net.cpp:774] Copying source layer scale4c_branch2c
I0529 14:44:58.185401 30229 net.cpp:774] Copying source layer res4c
I0529 14:44:58.185406 30229 net.cpp:774] Copying source layer res4c_relu
I0529 14:44:58.185410 30229 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0529 14:44:58.185415 30229 net.cpp:774] Copying source layer res4d_branch2a
I0529 14:44:58.187196 30229 net.cpp:774] Copying source layer bn4d_branch2a
I0529 14:44:58.187209 30229 net.cpp:774] Copying source layer scale4d_branch2a
I0529 14:44:58.187219 30229 net.cpp:774] Copying source layer res4d_branch2a_relu
I0529 14:44:58.187224 30229 net.cpp:774] Copying source layer res4d_branch2b
I0529 14:44:58.191246 30229 net.cpp:774] Copying source layer bn4d_branch2b
I0529 14:44:58.191262 30229 net.cpp:774] Copying source layer scale4d_branch2b
I0529 14:44:58.191272 30229 net.cpp:774] Copying source layer res4d_branch2b_relu
I0529 14:44:58.191277 30229 net.cpp:774] Copying source layer res4d_branch2c
I0529 14:44:58.193092 30229 net.cpp:774] Copying source layer bn4d_branch2c
I0529 14:44:58.193117 30229 net.cpp:774] Copying source layer scale4d_branch2c
I0529 14:44:58.193137 30229 net.cpp:774] Copying source layer res4d
I0529 14:44:58.193142 30229 net.cpp:774] Copying source layer res4d_relu
I0529 14:44:58.193146 30229 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0529 14:44:58.193151 30229 net.cpp:774] Copying source layer res4e_branch2a
I0529 14:44:58.194934 30229 net.cpp:774] Copying source layer bn4e_branch2a
I0529 14:44:58.194947 30229 net.cpp:774] Copying source layer scale4e_branch2a
I0529 14:44:58.194957 30229 net.cpp:774] Copying source layer res4e_branch2a_relu
I0529 14:44:58.194962 30229 net.cpp:774] Copying source layer res4e_branch2b
I0529 14:44:58.198966 30229 net.cpp:774] Copying source layer bn4e_branch2b
I0529 14:44:58.198982 30229 net.cpp:774] Copying source layer scale4e_branch2b
I0529 14:44:58.198992 30229 net.cpp:774] Copying source layer res4e_branch2b_relu
I0529 14:44:58.198997 30229 net.cpp:774] Copying source layer res4e_branch2c
I0529 14:44:58.200778 30229 net.cpp:774] Copying source layer bn4e_branch2c
I0529 14:44:58.200801 30229 net.cpp:774] Copying source layer scale4e_branch2c
I0529 14:44:58.200821 30229 net.cpp:774] Copying source layer res4e
I0529 14:44:58.200826 30229 net.cpp:774] Copying source layer res4e_relu
I0529 14:44:58.200831 30229 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0529 14:44:58.200835 30229 net.cpp:774] Copying source layer res4f_branch2a
I0529 14:44:58.202620 30229 net.cpp:774] Copying source layer bn4f_branch2a
I0529 14:44:58.202633 30229 net.cpp:774] Copying source layer scale4f_branch2a
I0529 14:44:58.202644 30229 net.cpp:774] Copying source layer res4f_branch2a_relu
I0529 14:44:58.202648 30229 net.cpp:774] Copying source layer res4f_branch2b
I0529 14:44:58.206653 30229 net.cpp:774] Copying source layer bn4f_branch2b
I0529 14:44:58.206668 30229 net.cpp:774] Copying source layer scale4f_branch2b
I0529 14:44:58.206679 30229 net.cpp:774] Copying source layer res4f_branch2b_relu
I0529 14:44:58.206683 30229 net.cpp:774] Copying source layer res4f_branch2c
I0529 14:44:58.208485 30229 net.cpp:774] Copying source layer bn4f_branch2c
I0529 14:44:58.208526 30229 net.cpp:774] Copying source layer scale4f_branch2c
I0529 14:44:58.208547 30229 net.cpp:774] Copying source layer res4f
I0529 14:44:58.208551 30229 net.cpp:774] Copying source layer res4f_relu
I0529 14:44:58.208557 30229 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0529 14:44:58.208561 30229 net.cpp:774] Copying source layer res5a_branch1
I0529 14:44:58.222699 30229 net.cpp:774] Copying source layer bn5a_branch1
I0529 14:44:58.222757 30229 net.cpp:774] Copying source layer scale5a_branch1
I0529 14:44:58.222793 30229 net.cpp:774] Copying source layer res5a_branch2a
I0529 14:44:58.226297 30229 net.cpp:774] Copying source layer bn5a_branch2a
I0529 14:44:58.226333 30229 net.cpp:774] Copying source layer scale5a_branch2a
I0529 14:44:58.226349 30229 net.cpp:774] Copying source layer res5a_branch2a_relu
I0529 14:44:58.226354 30229 net.cpp:774] Copying source layer res5a_branch2b
I0529 14:44:58.242302 30229 net.cpp:774] Copying source layer bn5a_branch2b
I0529 14:44:58.242336 30229 net.cpp:774] Copying source layer scale5a_branch2b
I0529 14:44:58.242352 30229 net.cpp:774] Copying source layer res5a_branch2b_relu
I0529 14:44:58.242357 30229 net.cpp:774] Copying source layer res5a_branch2c
I0529 14:44:58.249409 30229 net.cpp:774] Copying source layer bn5a_branch2c
I0529 14:44:58.249466 30229 net.cpp:774] Copying source layer scale5a_branch2c
I0529 14:44:58.249502 30229 net.cpp:774] Copying source layer res5a
I0529 14:44:58.249506 30229 net.cpp:774] Copying source layer res5a_relu
I0529 14:44:58.249512 30229 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0529 14:44:58.249517 30229 net.cpp:774] Copying source layer res5b_branch2a
I0529 14:44:58.256510 30229 net.cpp:774] Copying source layer bn5b_branch2a
I0529 14:44:58.256546 30229 net.cpp:774] Copying source layer scale5b_branch2a
I0529 14:44:58.256561 30229 net.cpp:774] Copying source layer res5b_branch2a_relu
I0529 14:44:58.256567 30229 net.cpp:774] Copying source layer res5b_branch2b
I0529 14:44:58.272526 30229 net.cpp:774] Copying source layer bn5b_branch2b
I0529 14:44:58.272550 30229 net.cpp:774] Copying source layer scale5b_branch2b
I0529 14:44:58.272565 30229 net.cpp:774] Copying source layer res5b_branch2b_relu
I0529 14:44:58.272570 30229 net.cpp:774] Copying source layer res5b_branch2c
I0529 14:44:58.279733 30229 net.cpp:774] Copying source layer bn5b_branch2c
I0529 14:44:58.279781 30229 net.cpp:774] Copying source layer scale5b_branch2c
I0529 14:44:58.279816 30229 net.cpp:774] Copying source layer res5b
I0529 14:44:58.279821 30229 net.cpp:774] Copying source layer res5b_relu
I0529 14:44:58.279827 30229 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0529 14:44:58.279832 30229 net.cpp:774] Copying source layer res5c_branch2a
I0529 14:44:58.286985 30229 net.cpp:774] Copying source layer bn5c_branch2a
I0529 14:44:58.287008 30229 net.cpp:774] Copying source layer scale5c_branch2a
I0529 14:44:58.287024 30229 net.cpp:774] Copying source layer res5c_branch2a_relu
I0529 14:44:58.287029 30229 net.cpp:774] Copying source layer res5c_branch2b
I0529 14:44:58.303841 30229 net.cpp:774] Copying source layer bn5c_branch2b
I0529 14:44:58.303884 30229 net.cpp:774] Copying source layer scale5c_branch2b
I0529 14:44:58.303900 30229 net.cpp:774] Copying source layer res5c_branch2b_relu
I0529 14:44:58.303906 30229 net.cpp:774] Copying source layer res5c_branch2c
I0529 14:44:58.310958 30229 net.cpp:774] Copying source layer bn5c_branch2c
I0529 14:44:58.311019 30229 net.cpp:774] Copying source layer scale5c_branch2c
I0529 14:44:58.311055 30229 net.cpp:774] Copying source layer res5c
I0529 14:44:58.311060 30229 net.cpp:774] Copying source layer res5c_relu
I0529 14:44:58.311064 30229 net.cpp:774] Copying source layer rpn_conv/3x3
I0529 14:44:58.343256 30229 net.cpp:774] Copying source layer rpn_relu/3x3
I0529 14:44:58.343276 30229 net.cpp:774] Copying source layer rpn/output_rpn_relu/3x3_0_split
I0529 14:44:58.343281 30229 net.cpp:774] Copying source layer rpn_cls_score
I0529 14:44:58.343391 30229 net.cpp:771] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0529 14:44:58.343397 30229 net.cpp:774] Copying source layer rpn_bbox_pred
I0529 14:44:58.343581 30229 net.cpp:771] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0529 14:44:58.343587 30229 net.cpp:774] Copying source layer rpn_cls_score_reshape
I0529 14:44:58.343591 30229 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0529 14:44:58.343595 30229 net.cpp:771] Ignoring source layer rpn-data
I0529 14:44:58.343613 30229 net.cpp:771] Ignoring source layer rpn_loss_cls
I0529 14:44:58.343618 30229 net.cpp:771] Ignoring source layer rpn_loss_bbox
I0529 14:44:58.343622 30229 net.cpp:774] Copying source layer rpn_cls_prob
I0529 14:44:58.343626 30229 net.cpp:774] Copying source layer rpn_cls_prob_reshape
I0529 14:44:58.343631 30229 net.cpp:774] Copying source layer proposal
I0529 14:44:58.343634 30229 net.cpp:771] Ignoring source layer roi-data
I0529 14:44:58.343639 30229 net.cpp:771] Ignoring source layer rois_roi-data_0_split
I0529 14:44:58.343643 30229 net.cpp:771] Ignoring source layer labels_roi-data_1_split
I0529 14:44:58.343647 30229 net.cpp:771] Ignoring source layer bbox_targets_roi-data_2_split
I0529 14:44:58.343652 30229 net.cpp:771] Ignoring source layer bbox_inside_weights_roi-data_3_split
I0529 14:44:58.343657 30229 net.cpp:774] Copying source layer conv_new_1
I0529 14:44:58.357964 30229 net.cpp:774] Copying source layer conv_new_1_relu
I0529 14:44:58.357972 30229 net.cpp:774] Copying source layer conv_new_1_conv_new_1_relu_0_split
I0529 14:44:58.357976 30229 net.cpp:774] Copying source layer rfcn_cls
I0529 14:44:58.358659 30229 net.cpp:774] Copying source layer rfcn_bbox
I0529 14:44:58.361373 30229 net.cpp:774] Copying source layer psroipooled_cls_rois
I0529 14:44:58.361394 30229 net.cpp:774] Copying source layer ave_cls_score_rois
I0529 14:44:58.361398 30229 net.cpp:771] Ignoring source layer cls_score_ave_cls_score_rois_0_split
I0529 14:44:58.361402 30229 net.cpp:774] Copying source layer psroipooled_loc_rois
I0529 14:44:58.361407 30229 net.cpp:774] Copying source layer ave_bbox_pred_rois
I0529 14:44:58.361410 30229 net.cpp:771] Ignoring source layer bbox_pred_ave_bbox_pred_rois_0_split
I0529 14:44:58.361421 30229 net.cpp:771] Ignoring source layer per_roi_loss_cls
I0529 14:44:58.361425 30229 net.cpp:771] Ignoring source layer per_roi_loss_bbox
I0529 14:44:58.361429 30229 net.cpp:771] Ignoring source layer per_roi_loss
I0529 14:44:58.361434 30229 net.cpp:771] Ignoring source layer annotator_detector
I0529 14:44:58.361438 30229 net.cpp:771] Ignoring source layer labels_ohem_annotator_detector_0_split
I0529 14:44:58.361441 30229 net.cpp:771] Ignoring source layer silence
I0529 14:44:58.361445 30229 net.cpp:771] Ignoring source layer loss
I0529 14:44:58.361449 30229 net.cpp:771] Ignoring source layer accuarcy
I0529 14:44:58.361454 30229 net.cpp:771] Ignoring source layer loss_bbox
I0529 14:44:58.665607 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3538968
I0529 14:44:58.675207 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.688695 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.698268 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.703634 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.713984 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.719830 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.730789 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 891288
I0529 14:44:58.737167 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 221208
I0529 14:44:58.745865 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 221208
I0529 14:44:58.751240 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.754374 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.760774 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.764199 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.770432 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.773725 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.780620 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 227736
I0529 14:44:58.783968 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55320
I0529 14:44:58.789237 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55320
I0529 14:44:58.796154 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.798455 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.803020 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.805341 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.809814 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.812109 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.816720 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.819026 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.823796 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.826143 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.830708 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.833032 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55320
I0529 14:44:58.839260 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.852187 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55320
I0529 14:44:58.856905 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.871423 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55320
I0529 14:44:58.875967 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.890615 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 55320
I0529 14:44:58.905768 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.906033 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.915671 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.919790 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
I0529 14:44:58.920217 30229 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 61848
im_detect: 1/4024 0.274s 0.001s
im_detect: 2/4024 0.228s 0.001s
im_detect: 3/4024 0.213s 0.001s
im_detect: 4/4024 0.205s 0.001s
im_detect: 5/4024 0.200s 0.001s
im_detect: 6/4024 0.197s 0.001s
im_detect: 7/4024 0.195s 0.001s
im_detect: 8/4024 0.193s 0.001s
im_detect: 9/4024 0.192s 0.001s
im_detect: 10/4024 0.191s 0.001s
im_detect: 11/4024 0.190s 0.001s
im_detect: 12/4024 0.189s 0.001s
im_detect: 13/4024 0.189s 0.001s
im_detect: 14/4024 0.188s 0.001s
im_detect: 15/4024 0.188s 0.001s
im_detect: 16/4024 0.187s 0.001s
im_detect: 17/4024 0.187s 0.001s
im_detect: 18/4024 0.187s 0.001s
im_detect: 19/4024 0.186s 0.001s
im_detect: 20/4024 0.186s 0.001s
im_detect: 21/4024 0.186s 0.001s
im_detect: 22/4024 0.186s 0.001s
im_detect: 23/4024 0.186s 0.001s
im_detect: 24/4024 0.185s 0.001s
im_detect: 25/4024 0.185s 0.001s
im_detect: 26/4024 0.185s 0.001s
im_detect: 27/4024 0.185s 0.001s
im_detect: 28/4024 0.185s 0.001s
im_detect: 29/4024 0.185s 0.001s
im_detect: 30/4024 0.185s 0.001s
im_detect: 31/4024 0.185s 0.001s
im_detect: 32/4024 0.185s 0.001s
im_detect: 33/4024 0.184s 0.001s
im_detect: 34/4024 0.184s 0.001s
im_detect: 35/4024 0.184s 0.001s
im_detect: 36/4024 0.184s 0.001s
im_detect: 37/4024 0.184s 0.001s
im_detect: 38/4024 0.184s 0.001s
im_detect: 39/4024 0.184s 0.001s
im_detect: 40/4024 0.184s 0.001s
im_detect: 41/4024 0.184s 0.001s
im_detect: 42/4024 0.184s 0.000s
im_detect: 43/4024 0.184s 0.000s
im_detect: 44/4024 0.184s 0.000s
im_detect: 45/4024 0.184s 0.000s
im_detect: 46/4024 0.184s 0.000s
im_detect: 47/4024 0.184s 0.000s
im_detect: 48/4024 0.184s 0.000s
im_detect: 49/4024 0.184s 0.000s
im_detect: 50/4024 0.183s 0.000s
im_detect: 51/4024 0.183s 0.000s
im_detect: 52/4024 0.183s 0.000s
im_detect: 53/4024 0.183s 0.000s
im_detect: 54/4024 0.183s 0.000s
im_detect: 55/4024 0.183s 0.000s
im_detect: 56/4024 0.183s 0.000s
im_detect: 57/4024 0.183s 0.000s
im_detect: 58/4024 0.183s 0.000s
im_detect: 59/4024 0.183s 0.000s
im_detect: 60/4024 0.183s 0.000s
im_detect: 61/4024 0.183s 0.000s
im_detect: 62/4024 0.183s 0.000s
im_detect: 63/4024 0.183s 0.000s
im_detect: 64/4024 0.183s 0.000s
im_detect: 65/4024 0.183s 0.000s
im_detect: 66/4024 0.183s 0.000s
im_detect: 67/4024 0.183s 0.000s
im_detect: 68/4024 0.183s 0.000s
im_detect: 69/4024 0.183s 0.000s
im_detect: 70/4024 0.183s 0.000s
im_detect: 71/4024 0.183s 0.000s
im_detect: 72/4024 0.183s 0.000s
im_detect: 73/4024 0.183s 0.000s
im_detect: 74/4024 0.183s 0.000s
im_detect: 75/4024 0.183s 0.000s
im_detect: 76/4024 0.183s 0.000s
im_detect: 77/4024 0.183s 0.000s
im_detect: 78/4024 0.183s 0.000s
im_detect: 79/4024 0.183s 0.000s
im_detect: 80/4024 0.183s 0.000s
im_detect: 81/4024 0.183s 0.000s
im_detect: 82/4024 0.183s 0.000s
im_detect: 83/4024 0.183s 0.000s
im_detect: 84/4024 0.183s 0.000s
im_detect: 85/4024 0.183s 0.000s
im_detect: 86/4024 0.183s 0.000s
im_detect: 87/4024 0.183s 0.000s
im_detect: 88/4024 0.183s 0.000s
im_detect: 89/4024 0.183s 0.000s
im_detect: 90/4024 0.183s 0.000s
im_detect: 91/4024 0.183s 0.000s
im_detect: 92/4024 0.183s 0.000s
im_detect: 93/4024 0.183s 0.000s
im_detect: 94/4024 0.183s 0.000s
im_detect: 95/4024 0.183s 0.000s
im_detect: 96/4024 0.183s 0.000s
im_detect: 97/4024 0.183s 0.000s
im_detect: 98/4024 0.183s 0.000s
im_detect: 99/4024 0.183s 0.000s
im_detect: 100/4024 0.183s 0.000s
im_detect: 101/4024 0.183s 0.000s
im_detect: 102/4024 0.182s 0.000s
im_detect: 103/4024 0.182s 0.000s
im_detect: 104/4024 0.182s 0.000s
im_detect: 105/4024 0.182s 0.000s
im_detect: 106/4024 0.182s 0.000s
im_detect: 107/4024 0.182s 0.000s
im_detect: 108/4024 0.182s 0.000s
im_detect: 109/4024 0.182s 0.000s
im_detect: 110/4024 0.182s 0.000s
im_detect: 111/4024 0.182s 0.000s
im_detect: 112/4024 0.182s 0.000s
im_detect: 113/4024 0.182s 0.000s
im_detect: 114/4024 0.182s 0.000s
im_detect: 115/4024 0.182s 0.000s
im_detect: 116/4024 0.182s 0.000s
im_detect: 117/4024 0.182s 0.000s
im_detect: 118/4024 0.182s 0.000s
im_detect: 119/4024 0.182s 0.000s
im_detect: 120/4024 0.182s 0.000s
im_detect: 121/4024 0.182s 0.000s
im_detect: 122/4024 0.182s 0.000s
im_detect: 123/4024 0.182s 0.000s
im_detect: 124/4024 0.182s 0.000s
im_detect: 125/4024 0.182s 0.000s
im_detect: 126/4024 0.182s 0.000s
im_detect: 127/4024 0.182s 0.000s
im_detect: 128/4024 0.182s 0.000s
im_detect: 129/4024 0.182s 0.000s
im_detect: 130/4024 0.182s 0.000s
im_detect: 131/4024 0.182s 0.000s
im_detect: 132/4024 0.182s 0.000s
im_detect: 133/4024 0.182s 0.000s
im_detect: 134/4024 0.182s 0.000s
im_detect: 135/4024 0.182s 0.000s
im_detect: 136/4024 0.182s 0.000s
im_detect: 137/4024 0.182s 0.000s
im_detect: 138/4024 0.182s 0.000s
im_detect: 139/4024 0.182s 0.000s
im_detect: 140/4024 0.182s 0.000s
im_detect: 141/4024 0.182s 0.000s
im_detect: 142/4024 0.182s 0.000s
im_detect: 143/4024 0.182s 0.000s
im_detect: 144/4024 0.182s 0.000s
im_detect: 145/4024 0.182s 0.000s
im_detect: 146/4024 0.182s 0.000s
im_detect: 147/4024 0.182s 0.000s
im_detect: 148/4024 0.182s 0.000s
im_detect: 149/4024 0.182s 0.000s
im_detect: 150/4024 0.182s 0.000s
im_detect: 151/4024 0.182s 0.000s
im_detect: 152/4024 0.182s 0.000s
im_detect: 153/4024 0.182s 0.000s
im_detect: 154/4024 0.182s 0.000s
im_detect: 155/4024 0.182s 0.000s
im_detect: 156/4024 0.182s 0.000s
im_detect: 157/4024 0.182s 0.000s
im_detect: 158/4024 0.182s 0.000s
im_detect: 159/4024 0.182s 0.000s
im_detect: 160/4024 0.182s 0.000s
im_detect: 161/4024 0.182s 0.000s
im_detect: 162/4024 0.182s 0.000s
im_detect: 163/4024 0.182s 0.000s
im_detect: 164/4024 0.182s 0.000s
im_detect: 165/4024 0.182s 0.000s
im_detect: 166/4024 0.182s 0.000s
im_detect: 167/4024 0.182s 0.000s
im_detect: 168/4024 0.182s 0.000s
im_detect: 169/4024 0.182s 0.000s
im_detect: 170/4024 0.182s 0.000s
im_detect: 171/4024 0.182s 0.000s
im_detect: 172/4024 0.182s 0.000s
im_detect: 173/4024 0.182s 0.000s
im_detect: 174/4024 0.182s 0.000s
im_detect: 175/4024 0.182s 0.000s
im_detect: 176/4024 0.182s 0.000s
im_detect: 177/4024 0.182s 0.000s
im_detect: 178/4024 0.182s 0.000s
im_detect: 179/4024 0.182s 0.000s
im_detect: 180/4024 0.182s 0.000s
im_detect: 181/4024 0.182s 0.000s
im_detect: 182/4024 0.182s 0.000s
im_detect: 183/4024 0.182s 0.000s
im_detect: 184/4024 0.182s 0.000s
im_detect: 185/4024 0.182s 0.000s
im_detect: 186/4024 0.182s 0.000s
im_detect: 187/4024 0.182s 0.000s
im_detect: 188/4024 0.182s 0.000s
im_detect: 189/4024 0.182s 0.000s
im_detect: 190/4024 0.182s 0.000s
im_detect: 191/4024 0.182s 0.000s
im_detect: 192/4024 0.182s 0.000s
im_detect: 193/4024 0.182s 0.000s
im_detect: 194/4024 0.182s 0.000s
im_detect: 195/4024 0.182s 0.000s
im_detect: 196/4024 0.182s 0.000s
im_detect: 197/4024 0.182s 0.000s
im_detect: 198/4024 0.182s 0.000s
im_detect: 199/4024 0.182s 0.000s
im_detect: 200/4024 0.182s 0.000s
im_detect: 201/4024 0.182s 0.000s
im_detect: 202/4024 0.182s 0.000s
im_detect: 203/4024 0.182s 0.000s
im_detect: 204/4024 0.182s 0.000s
im_detect: 205/4024 0.182s 0.000s
im_detect: 206/4024 0.182s 0.000s
im_detect: 207/4024 0.182s 0.000s
im_detect: 208/4024 0.182s 0.000s
im_detect: 209/4024 0.182s 0.000s
im_detect: 210/4024 0.182s 0.000s
im_detect: 211/4024 0.182s 0.000s
im_detect: 212/4024 0.182s 0.000s
im_detect: 213/4024 0.182s 0.000s
im_detect: 214/4024 0.182s 0.000s
im_detect: 215/4024 0.182s 0.000s
im_detect: 216/4024 0.182s 0.000s
im_detect: 217/4024 0.182s 0.000s
im_detect: 218/4024 0.182s 0.000s
im_detect: 219/4024 0.182s 0.000s
im_detect: 220/4024 0.182s 0.000s
im_detect: 221/4024 0.182s 0.000s
im_detect: 222/4024 0.182s 0.000s
im_detect: 223/4024 0.182s 0.000s
im_detect: 224/4024 0.182s 0.000s
im_detect: 225/4024 0.182s 0.000s
im_detect: 226/4024 0.182s 0.000s
im_detect: 227/4024 0.182s 0.000s
im_detect: 228/4024 0.182s 0.000s
im_detect: 229/4024 0.182s 0.000s
im_detect: 230/4024 0.182s 0.000s
im_detect: 231/4024 0.182s 0.000s
im_detect: 232/4024 0.182s 0.000s
im_detect: 233/4024 0.182s 0.000s
im_detect: 234/4024 0.182s 0.000s
im_detect: 235/4024 0.182s 0.000s
im_detect: 236/4024 0.182s 0.000s
im_detect: 237/4024 0.182s 0.000s
im_detect: 238/4024 0.182s 0.000s
im_detect: 239/4024 0.182s 0.000s
im_detect: 240/4024 0.182s 0.000s
im_detect: 241/4024 0.182s 0.000s
im_detect: 242/4024 0.182s 0.000s
im_detect: 243/4024 0.182s 0.000s
im_detect: 244/4024 0.182s 0.000s
im_detect: 245/4024 0.182s 0.000s
im_detect: 246/4024 0.182s 0.000s
im_detect: 247/4024 0.182s 0.000s
im_detect: 248/4024 0.182s 0.000s
im_detect: 249/4024 0.182s 0.000s
im_detect: 250/4024 0.182s 0.000s
im_detect: 251/4024 0.182s 0.000s
im_detect: 252/4024 0.182s 0.000s
im_detect: 253/4024 0.182s 0.000s
im_detect: 254/4024 0.182s 0.000s
im_detect: 255/4024 0.182s 0.000s
im_detect: 256/4024 0.182s 0.000s
im_detect: 257/4024 0.182s 0.000s
im_detect: 258/4024 0.182s 0.000s
im_detect: 259/4024 0.182s 0.000s
im_detect: 260/4024 0.182s 0.000s
im_detect: 261/4024 0.182s 0.000s
im_detect: 262/4024 0.182s 0.000s
im_detect: 263/4024 0.182s 0.000s
im_detect: 264/4024 0.182s 0.000s
im_detect: 265/4024 0.182s 0.000s
im_detect: 266/4024 0.182s 0.000s
im_detect: 267/4024 0.182s 0.000s
im_detect: 268/4024 0.182s 0.000s
im_detect: 269/4024 0.182s 0.000s
im_detect: 270/4024 0.182s 0.000s
im_detect: 271/4024 0.182s 0.000s
im_detect: 272/4024 0.182s 0.000s
im_detect: 273/4024 0.182s 0.000s
im_detect: 274/4024 0.182s 0.000s
im_detect: 275/4024 0.182s 0.000s
im_detect: 276/4024 0.182s 0.000s
im_detect: 277/4024 0.182s 0.000s
im_detect: 278/4024 0.182s 0.000s
im_detect: 279/4024 0.182s 0.000s
im_detect: 280/4024 0.182s 0.000s
im_detect: 281/4024 0.182s 0.000s
im_detect: 282/4024 0.182s 0.000s
im_detect: 283/4024 0.182s 0.000s
im_detect: 284/4024 0.182s 0.000s
im_detect: 285/4024 0.182s 0.000s
im_detect: 286/4024 0.182s 0.000s
im_detect: 287/4024 0.182s 0.000s
im_detect: 288/4024 0.182s 0.000s
im_detect: 289/4024 0.182s 0.000s
im_detect: 290/4024 0.182s 0.000s
im_detect: 291/4024 0.182s 0.000s
im_detect: 292/4024 0.182s 0.000s
im_detect: 293/4024 0.182s 0.000s
im_detect: 294/4024 0.182s 0.000s
im_detect: 295/4024 0.182s 0.000s
im_detect: 296/4024 0.182s 0.000s
im_detect: 297/4024 0.182s 0.000s
im_detect: 298/4024 0.182s 0.000s
im_detect: 299/4024 0.182s 0.000s
im_detect: 300/4024 0.182s 0.000s
im_detect: 301/4024 0.182s 0.000s
im_detect: 302/4024 0.182s 0.000s
im_detect: 303/4024 0.182s 0.000s
im_detect: 304/4024 0.182s 0.000s
im_detect: 305/4024 0.182s 0.000s
im_detect: 306/4024 0.182s 0.000s
im_detect: 307/4024 0.182s 0.000s
im_detect: 308/4024 0.182s 0.000s
im_detect: 309/4024 0.182s 0.000s
im_detect: 310/4024 0.182s 0.000s
im_detect: 311/4024 0.182s 0.000s
im_detect: 312/4024 0.182s 0.000s
im_detect: 313/4024 0.182s 0.000s
im_detect: 314/4024 0.182s 0.000s
im_detect: 315/4024 0.182s 0.000s
im_detect: 316/4024 0.182s 0.000s
im_detect: 317/4024 0.182s 0.000s
im_detect: 318/4024 0.182s 0.000s
im_detect: 319/4024 0.182s 0.000s
im_detect: 320/4024 0.182s 0.000s
im_detect: 321/4024 0.182s 0.000s
im_detect: 322/4024 0.182s 0.000s
im_detect: 323/4024 0.182s 0.000s
im_detect: 324/4024 0.182s 0.000s
im_detect: 325/4024 0.182s 0.000s
im_detect: 326/4024 0.182s 0.000s
im_detect: 327/4024 0.182s 0.000s
im_detect: 328/4024 0.182s 0.000s
im_detect: 329/4024 0.182s 0.000s
im_detect: 330/4024 0.182s 0.000s
im_detect: 331/4024 0.182s 0.000s
im_detect: 332/4024 0.182s 0.000s
im_detect: 333/4024 0.182s 0.000s
im_detect: 334/4024 0.182s 0.000s
im_detect: 335/4024 0.182s 0.000s
im_detect: 336/4024 0.182s 0.000s
im_detect: 337/4024 0.182s 0.000s
im_detect: 338/4024 0.182s 0.000s
im_detect: 339/4024 0.182s 0.000s
im_detect: 340/4024 0.182s 0.000s
im_detect: 341/4024 0.182s 0.000s
im_detect: 342/4024 0.182s 0.000s
im_detect: 343/4024 0.182s 0.000s
im_detect: 344/4024 0.182s 0.000s
im_detect: 345/4024 0.182s 0.000s
im_detect: 346/4024 0.182s 0.000s
im_detect: 347/4024 0.182s 0.000s
im_detect: 348/4024 0.182s 0.000s
im_detect: 349/4024 0.182s 0.000s
im_detect: 350/4024 0.182s 0.000s
im_detect: 351/4024 0.182s 0.000s
im_detect: 352/4024 0.182s 0.000s
im_detect: 353/4024 0.182s 0.000s
im_detect: 354/4024 0.182s 0.000s
im_detect: 355/4024 0.182s 0.000s
im_detect: 356/4024 0.182s 0.000s
im_detect: 357/4024 0.182s 0.000s
im_detect: 358/4024 0.182s 0.000s
im_detect: 359/4024 0.182s 0.000s
im_detect: 360/4024 0.182s 0.000s
im_detect: 361/4024 0.182s 0.000s
im_detect: 362/4024 0.182s 0.000s
im_detect: 363/4024 0.182s 0.000s
im_detect: 364/4024 0.182s 0.000s
im_detect: 365/4024 0.182s 0.000s
im_detect: 366/4024 0.182s 0.000s
im_detect: 367/4024 0.182s 0.000s
im_detect: 368/4024 0.182s 0.000s
im_detect: 369/4024 0.182s 0.000s
im_detect: 370/4024 0.182s 0.000s
im_detect: 371/4024 0.182s 0.000s
im_detect: 372/4024 0.182s 0.000s
im_detect: 373/4024 0.182s 0.000s
im_detect: 374/4024 0.182s 0.000s
im_detect: 375/4024 0.182s 0.000s
im_detect: 376/4024 0.182s 0.000s
im_detect: 377/4024 0.182s 0.000s
im_detect: 378/4024 0.182s 0.000s
im_detect: 379/4024 0.182s 0.000s
im_detect: 380/4024 0.182s 0.000s
im_detect: 381/4024 0.182s 0.000s
im_detect: 382/4024 0.182s 0.000s
im_detect: 383/4024 0.182s 0.000s
im_detect: 384/4024 0.182s 0.000s
im_detect: 385/4024 0.182s 0.000s
im_detect: 386/4024 0.182s 0.000s
im_detect: 387/4024 0.182s 0.000s
im_detect: 388/4024 0.182s 0.000s
im_detect: 389/4024 0.182s 0.000s
im_detect: 390/4024 0.182s 0.000s
im_detect: 391/4024 0.182s 0.000s
im_detect: 392/4024 0.182s 0.000s
im_detect: 393/4024 0.182s 0.000s
im_detect: 394/4024 0.182s 0.000s
im_detect: 395/4024 0.182s 0.000s
im_detect: 396/4024 0.182s 0.000s
im_detect: 397/4024 0.182s 0.000s
im_detect: 398/4024 0.182s 0.000s
im_detect: 399/4024 0.182s 0.000s
im_detect: 400/4024 0.182s 0.000s
im_detect: 401/4024 0.182s 0.000s
im_detect: 402/4024 0.182s 0.000s
im_detect: 403/4024 0.182s 0.000s
im_detect: 404/4024 0.182s 0.000s
im_detect: 405/4024 0.182s 0.000s
im_detect: 406/4024 0.182s 0.000s
im_detect: 407/4024 0.182s 0.000s
im_detect: 408/4024 0.182s 0.000s
im_detect: 409/4024 0.182s 0.000s
im_detect: 410/4024 0.182s 0.000s
im_detect: 411/4024 0.182s 0.000s
im_detect: 412/4024 0.182s 0.000s
im_detect: 413/4024 0.182s 0.000s
im_detect: 414/4024 0.182s 0.000s
im_detect: 415/4024 0.182s 0.000s
im_detect: 416/4024 0.182s 0.000s
im_detect: 417/4024 0.182s 0.000s
im_detect: 418/4024 0.182s 0.000s
im_detect: 419/4024 0.182s 0.000s
im_detect: 420/4024 0.182s 0.000s
im_detect: 421/4024 0.182s 0.000s
im_detect: 422/4024 0.182s 0.000s
im_detect: 423/4024 0.182s 0.000s
im_detect: 424/4024 0.182s 0.000s
im_detect: 425/4024 0.182s 0.000s
im_detect: 426/4024 0.182s 0.000s
im_detect: 427/4024 0.182s 0.000s
im_detect: 428/4024 0.182s 0.000s
im_detect: 429/4024 0.182s 0.000s
im_detect: 430/4024 0.182s 0.000s
im_detect: 431/4024 0.182s 0.000s
im_detect: 432/4024 0.182s 0.000s
im_detect: 433/4024 0.182s 0.000s
im_detect: 434/4024 0.182s 0.000s
im_detect: 435/4024 0.182s 0.000s
im_detect: 436/4024 0.182s 0.000s
im_detect: 437/4024 0.182s 0.000s
im_detect: 438/4024 0.182s 0.000s
im_detect: 439/4024 0.182s 0.000s
im_detect: 440/4024 0.182s 0.000s
im_detect: 441/4024 0.182s 0.000s
im_detect: 442/4024 0.182s 0.000s
im_detect: 443/4024 0.182s 0.000s
im_detect: 444/4024 0.182s 0.000s
im_detect: 445/4024 0.182s 0.000s
im_detect: 446/4024 0.182s 0.000s
im_detect: 447/4024 0.182s 0.000s
im_detect: 448/4024 0.182s 0.000s
im_detect: 449/4024 0.182s 0.000s
im_detect: 450/4024 0.182s 0.000s
im_detect: 451/4024 0.182s 0.000s
im_detect: 452/4024 0.182s 0.000s
im_detect: 453/4024 0.182s 0.000s
im_detect: 454/4024 0.182s 0.000s
im_detect: 455/4024 0.182s 0.000s
im_detect: 456/4024 0.182s 0.000s
im_detect: 457/4024 0.182s 0.000s
im_detect: 458/4024 0.182s 0.000s
im_detect: 459/4024 0.182s 0.000s
im_detect: 460/4024 0.182s 0.000s
im_detect: 461/4024 0.182s 0.000s
im_detect: 462/4024 0.182s 0.000s
im_detect: 463/4024 0.182s 0.000s
im_detect: 464/4024 0.182s 0.000s
im_detect: 465/4024 0.182s 0.000s
im_detect: 466/4024 0.182s 0.000s
im_detect: 467/4024 0.182s 0.000s
im_detect: 468/4024 0.182s 0.000s
im_detect: 469/4024 0.182s 0.000s
im_detect: 470/4024 0.182s 0.000s
im_detect: 471/4024 0.182s 0.000s
im_detect: 472/4024 0.182s 0.000s
im_detect: 473/4024 0.182s 0.000s
im_detect: 474/4024 0.182s 0.000s
im_detect: 475/4024 0.182s 0.000s
im_detect: 476/4024 0.182s 0.000s
im_detect: 477/4024 0.182s 0.000s
im_detect: 478/4024 0.182s 0.000s
im_detect: 479/4024 0.182s 0.000s
im_detect: 480/4024 0.182s 0.000s
im_detect: 481/4024 0.182s 0.000s
im_detect: 482/4024 0.182s 0.000s
im_detect: 483/4024 0.182s 0.000s
im_detect: 484/4024 0.182s 0.000s
im_detect: 485/4024 0.182s 0.000s
im_detect: 486/4024 0.182s 0.000s
im_detect: 487/4024 0.182s 0.000s
im_detect: 488/4024 0.182s 0.000s
im_detect: 489/4024 0.182s 0.000s
im_detect: 490/4024 0.182s 0.000s
im_detect: 491/4024 0.182s 0.000s
im_detect: 492/4024 0.182s 0.000s
im_detect: 493/4024 0.182s 0.000s
im_detect: 494/4024 0.182s 0.000s
im_detect: 495/4024 0.182s 0.000s
im_detect: 496/4024 0.182s 0.000s
im_detect: 497/4024 0.182s 0.000s
im_detect: 498/4024 0.182s 0.000s
im_detect: 499/4024 0.182s 0.000s
im_detect: 500/4024 0.182s 0.000s
im_detect: 501/4024 0.182s 0.000s
im_detect: 502/4024 0.182s 0.000s
im_detect: 503/4024 0.182s 0.000s
im_detect: 504/4024 0.182s 0.000s
im_detect: 505/4024 0.182s 0.000s
im_detect: 506/4024 0.182s 0.000s
im_detect: 507/4024 0.182s 0.000s
im_detect: 508/4024 0.182s 0.000s
im_detect: 509/4024 0.182s 0.000s
im_detect: 510/4024 0.182s 0.000s
im_detect: 511/4024 0.182s 0.000s
im_detect: 512/4024 0.182s 0.000s
im_detect: 513/4024 0.182s 0.000s
im_detect: 514/4024 0.182s 0.000s
im_detect: 515/4024 0.182s 0.000s
im_detect: 516/4024 0.182s 0.000s
im_detect: 517/4024 0.182s 0.000s
im_detect: 518/4024 0.182s 0.000s
im_detect: 519/4024 0.182s 0.000s
im_detect: 520/4024 0.182s 0.000s
im_detect: 521/4024 0.182s 0.000s
im_detect: 522/4024 0.182s 0.000s
im_detect: 523/4024 0.182s 0.000s
im_detect: 524/4024 0.182s 0.000s
im_detect: 525/4024 0.182s 0.000s
im_detect: 526/4024 0.182s 0.000s
im_detect: 527/4024 0.182s 0.000s
im_detect: 528/4024 0.182s 0.000s
im_detect: 529/4024 0.182s 0.000s
im_detect: 530/4024 0.182s 0.000s
im_detect: 531/4024 0.182s 0.000s
im_detect: 532/4024 0.182s 0.000s
im_detect: 533/4024 0.182s 0.000s
im_detect: 534/4024 0.182s 0.000s
im_detect: 535/4024 0.182s 0.000s
im_detect: 536/4024 0.182s 0.000s
im_detect: 537/4024 0.182s 0.000s
im_detect: 538/4024 0.182s 0.000s
im_detect: 539/4024 0.182s 0.000s
im_detect: 540/4024 0.182s 0.000s
im_detect: 541/4024 0.182s 0.000s
im_detect: 542/4024 0.182s 0.000s
im_detect: 543/4024 0.182s 0.000s
im_detect: 544/4024 0.182s 0.000s
im_detect: 545/4024 0.182s 0.000s
im_detect: 546/4024 0.182s 0.000s
im_detect: 547/4024 0.182s 0.000s
im_detect: 548/4024 0.182s 0.000s
im_detect: 549/4024 0.182s 0.000s
im_detect: 550/4024 0.182s 0.000s
im_detect: 551/4024 0.182s 0.000s
im_detect: 552/4024 0.182s 0.000s
im_detect: 553/4024 0.182s 0.000s
im_detect: 554/4024 0.182s 0.000s
im_detect: 555/4024 0.182s 0.000s
im_detect: 556/4024 0.182s 0.000s
im_detect: 557/4024 0.182s 0.000s
im_detect: 558/4024 0.182s 0.000s
im_detect: 559/4024 0.182s 0.000s
im_detect: 560/4024 0.182s 0.000s
im_detect: 561/4024 0.182s 0.000s
im_detect: 562/4024 0.182s 0.000s
im_detect: 563/4024 0.182s 0.000s
im_detect: 564/4024 0.182s 0.000s
im_detect: 565/4024 0.182s 0.000s
im_detect: 566/4024 0.182s 0.000s
im_detect: 567/4024 0.182s 0.000s
im_detect: 568/4024 0.182s 0.000s
im_detect: 569/4024 0.182s 0.000s
im_detect: 570/4024 0.182s 0.000s
im_detect: 571/4024 0.182s 0.000s
im_detect: 572/4024 0.182s 0.000s
im_detect: 573/4024 0.182s 0.000s
im_detect: 574/4024 0.182s 0.000s
im_detect: 575/4024 0.182s 0.000s
im_detect: 576/4024 0.182s 0.000s
im_detect: 577/4024 0.182s 0.000s
im_detect: 578/4024 0.182s 0.000s
im_detect: 579/4024 0.182s 0.000s
im_detect: 580/4024 0.182s 0.000s
im_detect: 581/4024 0.182s 0.000s
im_detect: 582/4024 0.182s 0.000s
im_detect: 583/4024 0.182s 0.000s
im_detect: 584/4024 0.182s 0.000s
im_detect: 585/4024 0.182s 0.000s
im_detect: 586/4024 0.182s 0.000s
im_detect: 587/4024 0.182s 0.000s
im_detect: 588/4024 0.182s 0.000s
im_detect: 589/4024 0.182s 0.000s
im_detect: 590/4024 0.182s 0.000s
im_detect: 591/4024 0.182s 0.000s
im_detect: 592/4024 0.182s 0.000s
im_detect: 593/4024 0.182s 0.000s
im_detect: 594/4024 0.182s 0.000s
im_detect: 595/4024 0.182s 0.000s
im_detect: 596/4024 0.182s 0.000s
im_detect: 597/4024 0.182s 0.000s
im_detect: 598/4024 0.182s 0.000s
im_detect: 599/4024 0.182s 0.000s
im_detect: 600/4024 0.182s 0.000s
im_detect: 601/4024 0.182s 0.000s
im_detect: 602/4024 0.182s 0.000s
im_detect: 603/4024 0.182s 0.000s
im_detect: 604/4024 0.182s 0.000s
im_detect: 605/4024 0.182s 0.000s
im_detect: 606/4024 0.182s 0.000s
im_detect: 607/4024 0.182s 0.000s
im_detect: 608/4024 0.182s 0.000s
im_detect: 609/4024 0.182s 0.000s
im_detect: 610/4024 0.182s 0.000s
im_detect: 611/4024 0.182s 0.000s
im_detect: 612/4024 0.182s 0.000s
im_detect: 613/4024 0.182s 0.000s
im_detect: 614/4024 0.182s 0.000s
im_detect: 615/4024 0.182s 0.000s
im_detect: 616/4024 0.182s 0.000s
im_detect: 617/4024 0.182s 0.000s
im_detect: 618/4024 0.182s 0.000s
im_detect: 619/4024 0.182s 0.000s
im_detect: 620/4024 0.182s 0.000s
im_detect: 621/4024 0.182s 0.000s
im_detect: 622/4024 0.182s 0.000s
im_detect: 623/4024 0.182s 0.000s
im_detect: 624/4024 0.182s 0.000s
im_detect: 625/4024 0.182s 0.000s
im_detect: 626/4024 0.182s 0.000s
im_detect: 627/4024 0.182s 0.000s
im_detect: 628/4024 0.182s 0.000s
im_detect: 629/4024 0.182s 0.000s
im_detect: 630/4024 0.182s 0.000s
im_detect: 631/4024 0.182s 0.000s
im_detect: 632/4024 0.182s 0.000s
im_detect: 633/4024 0.182s 0.000s
im_detect: 634/4024 0.182s 0.000s
im_detect: 635/4024 0.182s 0.000s
im_detect: 636/4024 0.182s 0.000s
im_detect: 637/4024 0.182s 0.000s
im_detect: 638/4024 0.182s 0.000s
im_detect: 639/4024 0.182s 0.000s
im_detect: 640/4024 0.182s 0.000s
im_detect: 641/4024 0.182s 0.000s
im_detect: 642/4024 0.182s 0.000s
im_detect: 643/4024 0.182s 0.000s
im_detect: 644/4024 0.182s 0.000s
im_detect: 645/4024 0.182s 0.000s
im_detect: 646/4024 0.182s 0.000s
im_detect: 647/4024 0.182s 0.000s
im_detect: 648/4024 0.182s 0.000s
im_detect: 649/4024 0.182s 0.000s
im_detect: 650/4024 0.182s 0.000s
im_detect: 651/4024 0.182s 0.000s
im_detect: 652/4024 0.182s 0.000s
im_detect: 653/4024 0.182s 0.000s
im_detect: 654/4024 0.182s 0.000s
im_detect: 655/4024 0.182s 0.000s
im_detect: 656/4024 0.182s 0.000s
im_detect: 657/4024 0.182s 0.000s
im_detect: 658/4024 0.182s 0.000s
im_detect: 659/4024 0.182s 0.000s
im_detect: 660/4024 0.182s 0.000s
im_detect: 661/4024 0.182s 0.000s
im_detect: 662/4024 0.182s 0.000s
im_detect: 663/4024 0.182s 0.000s
im_detect: 664/4024 0.182s 0.000s
im_detect: 665/4024 0.182s 0.000s
im_detect: 666/4024 0.182s 0.000s
im_detect: 667/4024 0.182s 0.000s
im_detect: 668/4024 0.182s 0.000s
im_detect: 669/4024 0.182s 0.000s
im_detect: 670/4024 0.182s 0.000s
im_detect: 671/4024 0.182s 0.000s
im_detect: 672/4024 0.182s 0.000s
im_detect: 673/4024 0.182s 0.000s
im_detect: 674/4024 0.182s 0.000s
im_detect: 675/4024 0.182s 0.000s
im_detect: 676/4024 0.182s 0.000s
im_detect: 677/4024 0.182s 0.000s
im_detect: 678/4024 0.182s 0.000s
im_detect: 679/4024 0.182s 0.000s
im_detect: 680/4024 0.182s 0.000s
im_detect: 681/4024 0.182s 0.000s
im_detect: 682/4024 0.182s 0.000s
im_detect: 683/4024 0.182s 0.000s
im_detect: 684/4024 0.182s 0.000s
im_detect: 685/4024 0.182s 0.000s
im_detect: 686/4024 0.182s 0.000s
im_detect: 687/4024 0.182s 0.000s
im_detect: 688/4024 0.182s 0.000s
im_detect: 689/4024 0.182s 0.000s
im_detect: 690/4024 0.182s 0.000s
im_detect: 691/4024 0.182s 0.000s
im_detect: 692/4024 0.182s 0.000s
im_detect: 693/4024 0.182s 0.000s
im_detect: 694/4024 0.182s 0.000s
im_detect: 695/4024 0.182s 0.000s
im_detect: 696/4024 0.182s 0.000s
im_detect: 697/4024 0.182s 0.000s
im_detect: 698/4024 0.182s 0.000s
im_detect: 699/4024 0.182s 0.000s
im_detect: 700/4024 0.182s 0.000s
im_detect: 701/4024 0.182s 0.000s
im_detect: 702/4024 0.182s 0.000s
im_detect: 703/4024 0.182s 0.000s
im_detect: 704/4024 0.182s 0.000s
im_detect: 705/4024 0.182s 0.000s
im_detect: 706/4024 0.182s 0.000s
im_detect: 707/4024 0.182s 0.000s
im_detect: 708/4024 0.182s 0.000s
im_detect: 709/4024 0.182s 0.000s
im_detect: 710/4024 0.182s 0.000s
im_detect: 711/4024 0.182s 0.000s
im_detect: 712/4024 0.182s 0.000s
im_detect: 713/4024 0.182s 0.000s
im_detect: 714/4024 0.182s 0.000s
im_detect: 715/4024 0.182s 0.000s
im_detect: 716/4024 0.182s 0.000s
im_detect: 717/4024 0.182s 0.000s
im_detect: 718/4024 0.182s 0.000s
im_detect: 719/4024 0.182s 0.000s
im_detect: 720/4024 0.182s 0.000s
im_detect: 721/4024 0.182s 0.000s
im_detect: 722/4024 0.182s 0.000s
im_detect: 723/4024 0.182s 0.000s
im_detect: 724/4024 0.182s 0.000s
im_detect: 725/4024 0.182s 0.000s
im_detect: 726/4024 0.182s 0.000s
im_detect: 727/4024 0.182s 0.000s
im_detect: 728/4024 0.182s 0.000s
im_detect: 729/4024 0.182s 0.000s
im_detect: 730/4024 0.182s 0.000s
im_detect: 731/4024 0.182s 0.000s
im_detect: 732/4024 0.182s 0.000s
im_detect: 733/4024 0.182s 0.000s
im_detect: 734/4024 0.182s 0.000s
im_detect: 735/4024 0.182s 0.000s
im_detect: 736/4024 0.182s 0.000s
im_detect: 737/4024 0.182s 0.000s
im_detect: 738/4024 0.182s 0.000s
im_detect: 739/4024 0.182s 0.000s
im_detect: 740/4024 0.182s 0.000s
im_detect: 741/4024 0.182s 0.000s
im_detect: 742/4024 0.182s 0.000s
im_detect: 743/4024 0.182s 0.000s
im_detect: 744/4024 0.182s 0.000s
im_detect: 745/4024 0.182s 0.000s
im_detect: 746/4024 0.182s 0.000s
im_detect: 747/4024 0.182s 0.000s
im_detect: 748/4024 0.182s 0.000s
im_detect: 749/4024 0.182s 0.000s
im_detect: 750/4024 0.182s 0.000s
im_detect: 751/4024 0.182s 0.000s
im_detect: 752/4024 0.182s 0.000s
im_detect: 753/4024 0.182s 0.000s
im_detect: 754/4024 0.182s 0.000s
im_detect: 755/4024 0.182s 0.000s
im_detect: 756/4024 0.182s 0.000s
im_detect: 757/4024 0.182s 0.000s
im_detect: 758/4024 0.182s 0.000s
im_detect: 759/4024 0.182s 0.000s
im_detect: 760/4024 0.182s 0.000s
im_detect: 761/4024 0.182s 0.000s
im_detect: 762/4024 0.182s 0.000s
im_detect: 763/4024 0.182s 0.000s
im_detect: 764/4024 0.182s 0.000s
im_detect: 765/4024 0.182s 0.000s
im_detect: 766/4024 0.182s 0.000s
im_detect: 767/4024 0.182s 0.000s
im_detect: 768/4024 0.182s 0.000s
im_detect: 769/4024 0.182s 0.000s
im_detect: 770/4024 0.182s 0.000s
im_detect: 771/4024 0.182s 0.000s
im_detect: 772/4024 0.182s 0.000s
im_detect: 773/4024 0.182s 0.000s
im_detect: 774/4024 0.182s 0.000s
im_detect: 775/4024 0.182s 0.000s
im_detect: 776/4024 0.182s 0.000s
im_detect: 777/4024 0.182s 0.000s
im_detect: 778/4024 0.182s 0.000s
im_detect: 779/4024 0.182s 0.000s
im_detect: 780/4024 0.182s 0.000s
im_detect: 781/4024 0.182s 0.000s
im_detect: 782/4024 0.182s 0.000s
im_detect: 783/4024 0.182s 0.000s
im_detect: 784/4024 0.182s 0.000s
im_detect: 785/4024 0.182s 0.000s
im_detect: 786/4024 0.182s 0.000s
im_detect: 787/4024 0.182s 0.000s
im_detect: 788/4024 0.182s 0.000s
im_detect: 789/4024 0.182s 0.000s
im_detect: 790/4024 0.182s 0.000s
im_detect: 791/4024 0.182s 0.000s
im_detect: 792/4024 0.182s 0.000s
im_detect: 793/4024 0.182s 0.000s
im_detect: 794/4024 0.182s 0.000s
im_detect: 795/4024 0.182s 0.000s
im_detect: 796/4024 0.182s 0.000s
im_detect: 797/4024 0.182s 0.000s
im_detect: 798/4024 0.182s 0.000s
im_detect: 799/4024 0.182s 0.000s
im_detect: 800/4024 0.182s 0.000s
im_detect: 801/4024 0.182s 0.000s
im_detect: 802/4024 0.182s 0.000s
im_detect: 803/4024 0.182s 0.000s
im_detect: 804/4024 0.182s 0.000s
im_detect: 805/4024 0.182s 0.000s
im_detect: 806/4024 0.182s 0.000s
im_detect: 807/4024 0.182s 0.000s
im_detect: 808/4024 0.182s 0.000s
im_detect: 809/4024 0.182s 0.000s
im_detect: 810/4024 0.182s 0.000s
im_detect: 811/4024 0.182s 0.000s
im_detect: 812/4024 0.182s 0.000s
im_detect: 813/4024 0.182s 0.000s
im_detect: 814/4024 0.182s 0.000s
im_detect: 815/4024 0.182s 0.000s
im_detect: 816/4024 0.182s 0.000s
im_detect: 817/4024 0.182s 0.000s
im_detect: 818/4024 0.182s 0.000s
im_detect: 819/4024 0.182s 0.000s
im_detect: 820/4024 0.182s 0.000s
im_detect: 821/4024 0.182s 0.000s
im_detect: 822/4024 0.182s 0.000s
im_detect: 823/4024 0.182s 0.000s
im_detect: 824/4024 0.182s 0.000s
im_detect: 825/4024 0.182s 0.000s
im_detect: 826/4024 0.182s 0.000s
im_detect: 827/4024 0.182s 0.000s
im_detect: 828/4024 0.182s 0.000s
im_detect: 829/4024 0.182s 0.000s
im_detect: 830/4024 0.182s 0.000s
im_detect: 831/4024 0.182s 0.000s
im_detect: 832/4024 0.182s 0.000s
im_detect: 833/4024 0.182s 0.000s
im_detect: 834/4024 0.182s 0.000s
im_detect: 835/4024 0.182s 0.000s
im_detect: 836/4024 0.182s 0.000s
im_detect: 837/4024 0.182s 0.000s
im_detect: 838/4024 0.182s 0.000s
im_detect: 839/4024 0.182s 0.000s
im_detect: 840/4024 0.182s 0.000s
im_detect: 841/4024 0.182s 0.000s
im_detect: 842/4024 0.182s 0.000s
im_detect: 843/4024 0.182s 0.000s
im_detect: 844/4024 0.182s 0.000s
im_detect: 845/4024 0.182s 0.000s
im_detect: 846/4024 0.182s 0.000s
im_detect: 847/4024 0.182s 0.000s
im_detect: 848/4024 0.182s 0.000s
im_detect: 849/4024 0.182s 0.000s
im_detect: 850/4024 0.182s 0.000s
im_detect: 851/4024 0.182s 0.000s
im_detect: 852/4024 0.182s 0.000s
im_detect: 853/4024 0.182s 0.000s
im_detect: 854/4024 0.182s 0.000s
im_detect: 855/4024 0.182s 0.000s
im_detect: 856/4024 0.182s 0.000s
im_detect: 857/4024 0.182s 0.000s
im_detect: 858/4024 0.182s 0.000s
im_detect: 859/4024 0.182s 0.000s
im_detect: 860/4024 0.182s 0.000s
im_detect: 861/4024 0.182s 0.000s
im_detect: 862/4024 0.182s 0.000s
im_detect: 863/4024 0.182s 0.000s
im_detect: 864/4024 0.182s 0.000s
im_detect: 865/4024 0.182s 0.000s
im_detect: 866/4024 0.182s 0.000s
im_detect: 867/4024 0.182s 0.000s
im_detect: 868/4024 0.182s 0.000s
im_detect: 869/4024 0.182s 0.000s
im_detect: 870/4024 0.182s 0.000s
im_detect: 871/4024 0.182s 0.000s
im_detect: 872/4024 0.182s 0.000s
im_detect: 873/4024 0.182s 0.000s
im_detect: 874/4024 0.182s 0.000s
im_detect: 875/4024 0.182s 0.000s
im_detect: 876/4024 0.182s 0.000s
im_detect: 877/4024 0.182s 0.000s
im_detect: 878/4024 0.182s 0.000s
im_detect: 879/4024 0.182s 0.000s
im_detect: 880/4024 0.182s 0.000s
im_detect: 881/4024 0.182s 0.000s
im_detect: 882/4024 0.182s 0.000s
im_detect: 883/4024 0.182s 0.000s
im_detect: 884/4024 0.182s 0.000s
im_detect: 885/4024 0.182s 0.000s
im_detect: 886/4024 0.182s 0.000s
im_detect: 887/4024 0.182s 0.000s
im_detect: 888/4024 0.182s 0.000s
im_detect: 889/4024 0.182s 0.000s
im_detect: 890/4024 0.182s 0.000s
im_detect: 891/4024 0.182s 0.000s
im_detect: 892/4024 0.182s 0.000s
im_detect: 893/4024 0.182s 0.000s
im_detect: 894/4024 0.182s 0.000s
im_detect: 895/4024 0.182s 0.000s
im_detect: 896/4024 0.182s 0.000s
im_detect: 897/4024 0.182s 0.000s
im_detect: 898/4024 0.182s 0.000s
im_detect: 899/4024 0.182s 0.000s
im_detect: 900/4024 0.182s 0.000s
im_detect: 901/4024 0.182s 0.000s
im_detect: 902/4024 0.182s 0.000s
im_detect: 903/4024 0.182s 0.000s
im_detect: 904/4024 0.182s 0.000s
im_detect: 905/4024 0.182s 0.000s
im_detect: 906/4024 0.182s 0.000s
im_detect: 907/4024 0.182s 0.000s
im_detect: 908/4024 0.182s 0.000s
im_detect: 909/4024 0.182s 0.000s
im_detect: 910/4024 0.182s 0.000s
im_detect: 911/4024 0.182s 0.000s
im_detect: 912/4024 0.182s 0.000s
im_detect: 913/4024 0.182s 0.000s
im_detect: 914/4024 0.182s 0.000s
im_detect: 915/4024 0.182s 0.000s
im_detect: 916/4024 0.182s 0.000s
im_detect: 917/4024 0.182s 0.000s
im_detect: 918/4024 0.182s 0.000s
im_detect: 919/4024 0.182s 0.000s
im_detect: 920/4024 0.182s 0.000s
im_detect: 921/4024 0.182s 0.000s
im_detect: 922/4024 0.182s 0.000s
im_detect: 923/4024 0.182s 0.000s
im_detect: 924/4024 0.182s 0.000s
im_detect: 925/4024 0.182s 0.000s
im_detect: 926/4024 0.182s 0.000s
im_detect: 927/4024 0.182s 0.000s
im_detect: 928/4024 0.182s 0.000s
im_detect: 929/4024 0.182s 0.000s
im_detect: 930/4024 0.182s 0.000s
im_detect: 931/4024 0.182s 0.000s
im_detect: 932/4024 0.182s 0.000s
im_detect: 933/4024 0.182s 0.000s
im_detect: 934/4024 0.182s 0.000s
im_detect: 935/4024 0.182s 0.000s
im_detect: 936/4024 0.182s 0.000s
im_detect: 937/4024 0.182s 0.000s
im_detect: 938/4024 0.182s 0.000s
im_detect: 939/4024 0.182s 0.000s
im_detect: 940/4024 0.182s 0.000s
im_detect: 941/4024 0.182s 0.000s
im_detect: 942/4024 0.182s 0.000s
im_detect: 943/4024 0.182s 0.000s
im_detect: 944/4024 0.182s 0.000s
im_detect: 945/4024 0.182s 0.000s
im_detect: 946/4024 0.182s 0.000s
im_detect: 947/4024 0.182s 0.000s
im_detect: 948/4024 0.182s 0.000s
im_detect: 949/4024 0.182s 0.000s
im_detect: 950/4024 0.182s 0.000s
im_detect: 951/4024 0.182s 0.000s
im_detect: 952/4024 0.182s 0.000s
im_detect: 953/4024 0.182s 0.000s
im_detect: 954/4024 0.182s 0.000s
im_detect: 955/4024 0.182s 0.000s
im_detect: 956/4024 0.182s 0.000s
im_detect: 957/4024 0.182s 0.000s
im_detect: 958/4024 0.182s 0.000s
im_detect: 959/4024 0.182s 0.000s
im_detect: 960/4024 0.182s 0.000s
im_detect: 961/4024 0.182s 0.000s
im_detect: 962/4024 0.182s 0.000s
im_detect: 963/4024 0.182s 0.000s
im_detect: 964/4024 0.182s 0.000s
im_detect: 965/4024 0.182s 0.000s
im_detect: 966/4024 0.182s 0.000s
im_detect: 967/4024 0.182s 0.000s
im_detect: 968/4024 0.182s 0.000s
im_detect: 969/4024 0.182s 0.000s
im_detect: 970/4024 0.182s 0.000s
im_detect: 971/4024 0.182s 0.000s
im_detect: 972/4024 0.182s 0.000s
im_detect: 973/4024 0.182s 0.000s
im_detect: 974/4024 0.182s 0.000s
im_detect: 975/4024 0.182s 0.000s
im_detect: 976/4024 0.182s 0.000s
im_detect: 977/4024 0.182s 0.000s
im_detect: 978/4024 0.182s 0.000s
im_detect: 979/4024 0.182s 0.000s
im_detect: 980/4024 0.182s 0.000s
im_detect: 981/4024 0.182s 0.000s
im_detect: 982/4024 0.182s 0.000s
im_detect: 983/4024 0.182s 0.000s
im_detect: 984/4024 0.182s 0.000s
im_detect: 985/4024 0.182s 0.000s
im_detect: 986/4024 0.182s 0.000s
im_detect: 987/4024 0.182s 0.000s
im_detect: 988/4024 0.182s 0.000s
im_detect: 989/4024 0.182s 0.000s
im_detect: 990/4024 0.182s 0.000s
im_detect: 991/4024 0.182s 0.000s
im_detect: 992/4024 0.182s 0.000s
im_detect: 993/4024 0.182s 0.000s
im_detect: 994/4024 0.182s 0.000s
im_detect: 995/4024 0.182s 0.000s
im_detect: 996/4024 0.182s 0.000s
im_detect: 997/4024 0.182s 0.000s
im_detect: 998/4024 0.182s 0.000s
im_detect: 999/4024 0.182s 0.000s
im_detect: 1000/4024 0.182s 0.000s
im_detect: 1001/4024 0.182s 0.000s
im_detect: 1002/4024 0.182s 0.000s
im_detect: 1003/4024 0.182s 0.000s
im_detect: 1004/4024 0.182s 0.000s
im_detect: 1005/4024 0.182s 0.000s
im_detect: 1006/4024 0.182s 0.000s
im_detect: 1007/4024 0.182s 0.000s
im_detect: 1008/4024 0.182s 0.000s
im_detect: 1009/4024 0.182s 0.000s
im_detect: 1010/4024 0.182s 0.000s
im_detect: 1011/4024 0.182s 0.000s
im_detect: 1012/4024 0.182s 0.000s
im_detect: 1013/4024 0.182s 0.000s
im_detect: 1014/4024 0.182s 0.000s
im_detect: 1015/4024 0.182s 0.000s
im_detect: 1016/4024 0.182s 0.000s
im_detect: 1017/4024 0.182s 0.000s
im_detect: 1018/4024 0.182s 0.000s
im_detect: 1019/4024 0.182s 0.000s
im_detect: 1020/4024 0.182s 0.000s
im_detect: 1021/4024 0.182s 0.000s
im_detect: 1022/4024 0.182s 0.000s
im_detect: 1023/4024 0.182s 0.000s
im_detect: 1024/4024 0.182s 0.000s
im_detect: 1025/4024 0.182s 0.000s
im_detect: 1026/4024 0.182s 0.000s
im_detect: 1027/4024 0.182s 0.000s
im_detect: 1028/4024 0.182s 0.000s
im_detect: 1029/4024 0.182s 0.000s
im_detect: 1030/4024 0.182s 0.000s
im_detect: 1031/4024 0.182s 0.000s
im_detect: 1032/4024 0.182s 0.000s
im_detect: 1033/4024 0.182s 0.000s
im_detect: 1034/4024 0.182s 0.000s
im_detect: 1035/4024 0.182s 0.000s
im_detect: 1036/4024 0.182s 0.000s
im_detect: 1037/4024 0.182s 0.000s
im_detect: 1038/4024 0.182s 0.000s
im_detect: 1039/4024 0.182s 0.000s
im_detect: 1040/4024 0.182s 0.000s
im_detect: 1041/4024 0.182s 0.000s
im_detect: 1042/4024 0.182s 0.000s
im_detect: 1043/4024 0.182s 0.000s
im_detect: 1044/4024 0.182s 0.000s
im_detect: 1045/4024 0.182s 0.000s
im_detect: 1046/4024 0.182s 0.000s
im_detect: 1047/4024 0.182s 0.000s
im_detect: 1048/4024 0.182s 0.000s
im_detect: 1049/4024 0.182s 0.000s
im_detect: 1050/4024 0.182s 0.000s
im_detect: 1051/4024 0.182s 0.000s
im_detect: 1052/4024 0.182s 0.000s
im_detect: 1053/4024 0.182s 0.000s
im_detect: 1054/4024 0.182s 0.000s
im_detect: 1055/4024 0.182s 0.000s
im_detect: 1056/4024 0.182s 0.000s
im_detect: 1057/4024 0.182s 0.000s
im_detect: 1058/4024 0.182s 0.000s
im_detect: 1059/4024 0.182s 0.000s
im_detect: 1060/4024 0.182s 0.000s
im_detect: 1061/4024 0.182s 0.000s
im_detect: 1062/4024 0.182s 0.000s
im_detect: 1063/4024 0.182s 0.000s
im_detect: 1064/4024 0.182s 0.000s
im_detect: 1065/4024 0.182s 0.000s
im_detect: 1066/4024 0.182s 0.000s
im_detect: 1067/4024 0.182s 0.000s
im_detect: 1068/4024 0.182s 0.000s
im_detect: 1069/4024 0.182s 0.000s
im_detect: 1070/4024 0.182s 0.000s
im_detect: 1071/4024 0.182s 0.000s
im_detect: 1072/4024 0.182s 0.000s
im_detect: 1073/4024 0.182s 0.000s
im_detect: 1074/4024 0.182s 0.000s
im_detect: 1075/4024 0.182s 0.000s
im_detect: 1076/4024 0.182s 0.000s
im_detect: 1077/4024 0.182s 0.000s
im_detect: 1078/4024 0.182s 0.000s
im_detect: 1079/4024 0.182s 0.000s
im_detect: 1080/4024 0.182s 0.000s
im_detect: 1081/4024 0.182s 0.000s
im_detect: 1082/4024 0.182s 0.000s
im_detect: 1083/4024 0.182s 0.000s
im_detect: 1084/4024 0.182s 0.000s
im_detect: 1085/4024 0.182s 0.000s
im_detect: 1086/4024 0.182s 0.000s
im_detect: 1087/4024 0.182s 0.000s
im_detect: 1088/4024 0.182s 0.000s
im_detect: 1089/4024 0.182s 0.000s
im_detect: 1090/4024 0.182s 0.000s
im_detect: 1091/4024 0.182s 0.000s
im_detect: 1092/4024 0.182s 0.000s
im_detect: 1093/4024 0.182s 0.000s
im_detect: 1094/4024 0.182s 0.000s
im_detect: 1095/4024 0.182s 0.000s
im_detect: 1096/4024 0.182s 0.000s
im_detect: 1097/4024 0.182s 0.000s
im_detect: 1098/4024 0.182s 0.000s
im_detect: 1099/4024 0.182s 0.000s
im_detect: 1100/4024 0.182s 0.000s
im_detect: 1101/4024 0.182s 0.000s
im_detect: 1102/4024 0.182s 0.000s
im_detect: 1103/4024 0.182s 0.000s
im_detect: 1104/4024 0.182s 0.000s
im_detect: 1105/4024 0.182s 0.000s
im_detect: 1106/4024 0.182s 0.000s
im_detect: 1107/4024 0.182s 0.000s
im_detect: 1108/4024 0.182s 0.000s
im_detect: 1109/4024 0.182s 0.000s
im_detect: 1110/4024 0.182s 0.000s
im_detect: 1111/4024 0.182s 0.000s
im_detect: 1112/4024 0.182s 0.000s
im_detect: 1113/4024 0.182s 0.000s
im_detect: 1114/4024 0.182s 0.000s
im_detect: 1115/4024 0.182s 0.000s
im_detect: 1116/4024 0.182s 0.000s
im_detect: 1117/4024 0.182s 0.000s
im_detect: 1118/4024 0.182s 0.000s
im_detect: 1119/4024 0.182s 0.000s
im_detect: 1120/4024 0.182s 0.000s
im_detect: 1121/4024 0.182s 0.000s
im_detect: 1122/4024 0.182s 0.000s
im_detect: 1123/4024 0.182s 0.000s
im_detect: 1124/4024 0.182s 0.000s
im_detect: 1125/4024 0.182s 0.000s
im_detect: 1126/4024 0.182s 0.000s
im_detect: 1127/4024 0.182s 0.000s
im_detect: 1128/4024 0.182s 0.000s
im_detect: 1129/4024 0.182s 0.000s
im_detect: 1130/4024 0.182s 0.000s
im_detect: 1131/4024 0.182s 0.000s
im_detect: 1132/4024 0.182s 0.000s
im_detect: 1133/4024 0.182s 0.000s
im_detect: 1134/4024 0.182s 0.000s
im_detect: 1135/4024 0.182s 0.000s
im_detect: 1136/4024 0.182s 0.000s
im_detect: 1137/4024 0.182s 0.000s
im_detect: 1138/4024 0.182s 0.000s
im_detect: 1139/4024 0.182s 0.000s
im_detect: 1140/4024 0.182s 0.000s
im_detect: 1141/4024 0.182s 0.000s
im_detect: 1142/4024 0.182s 0.000s
im_detect: 1143/4024 0.182s 0.000s
im_detect: 1144/4024 0.182s 0.000s
im_detect: 1145/4024 0.182s 0.000s
im_detect: 1146/4024 0.182s 0.000s
im_detect: 1147/4024 0.182s 0.000s
im_detect: 1148/4024 0.182s 0.000s
im_detect: 1149/4024 0.182s 0.000s
im_detect: 1150/4024 0.182s 0.000s
im_detect: 1151/4024 0.182s 0.000s
im_detect: 1152/4024 0.182s 0.000s
im_detect: 1153/4024 0.182s 0.000s
im_detect: 1154/4024 0.182s 0.000s
im_detect: 1155/4024 0.182s 0.000s
im_detect: 1156/4024 0.182s 0.000s
im_detect: 1157/4024 0.182s 0.000s
im_detect: 1158/4024 0.182s 0.000s
im_detect: 1159/4024 0.182s 0.000s
im_detect: 1160/4024 0.182s 0.000s
im_detect: 1161/4024 0.182s 0.000s
im_detect: 1162/4024 0.182s 0.000s
im_detect: 1163/4024 0.182s 0.000s
im_detect: 1164/4024 0.182s 0.000s
im_detect: 1165/4024 0.182s 0.000s
im_detect: 1166/4024 0.182s 0.000s
im_detect: 1167/4024 0.182s 0.000s
im_detect: 1168/4024 0.182s 0.000s
im_detect: 1169/4024 0.182s 0.000s
im_detect: 1170/4024 0.182s 0.000s
im_detect: 1171/4024 0.182s 0.000s
im_detect: 1172/4024 0.182s 0.000s
im_detect: 1173/4024 0.182s 0.000s
im_detect: 1174/4024 0.182s 0.000s
im_detect: 1175/4024 0.182s 0.000s
im_detect: 1176/4024 0.182s 0.000s
im_detect: 1177/4024 0.182s 0.000s
im_detect: 1178/4024 0.182s 0.000s
im_detect: 1179/4024 0.182s 0.000s
im_detect: 1180/4024 0.182s 0.000s
im_detect: 1181/4024 0.182s 0.000s
im_detect: 1182/4024 0.182s 0.000s
im_detect: 1183/4024 0.182s 0.000s
im_detect: 1184/4024 0.182s 0.000s
im_detect: 1185/4024 0.182s 0.000s
im_detect: 1186/4024 0.182s 0.000s
im_detect: 1187/4024 0.182s 0.000s
im_detect: 1188/4024 0.182s 0.000s
im_detect: 1189/4024 0.182s 0.000s
im_detect: 1190/4024 0.182s 0.000s
im_detect: 1191/4024 0.182s 0.000s
im_detect: 1192/4024 0.182s 0.000s
im_detect: 1193/4024 0.182s 0.000s
im_detect: 1194/4024 0.182s 0.000s
im_detect: 1195/4024 0.182s 0.000s
im_detect: 1196/4024 0.182s 0.000s
im_detect: 1197/4024 0.182s 0.000s
im_detect: 1198/4024 0.182s 0.000s
im_detect: 1199/4024 0.182s 0.000s
im_detect: 1200/4024 0.182s 0.000s
im_detect: 1201/4024 0.182s 0.000s
im_detect: 1202/4024 0.182s 0.000s
im_detect: 1203/4024 0.182s 0.000s
im_detect: 1204/4024 0.182s 0.000s
im_detect: 1205/4024 0.182s 0.000s
im_detect: 1206/4024 0.182s 0.000s
im_detect: 1207/4024 0.182s 0.000s
im_detect: 1208/4024 0.182s 0.000s
im_detect: 1209/4024 0.182s 0.000s
im_detect: 1210/4024 0.182s 0.000s
im_detect: 1211/4024 0.182s 0.000s
im_detect: 1212/4024 0.182s 0.000s
im_detect: 1213/4024 0.182s 0.000s
im_detect: 1214/4024 0.182s 0.000s
im_detect: 1215/4024 0.182s 0.000s
im_detect: 1216/4024 0.182s 0.000s
im_detect: 1217/4024 0.182s 0.000s
im_detect: 1218/4024 0.182s 0.000s
im_detect: 1219/4024 0.182s 0.000s
im_detect: 1220/4024 0.182s 0.000s
im_detect: 1221/4024 0.182s 0.000s
im_detect: 1222/4024 0.182s 0.000s
im_detect: 1223/4024 0.182s 0.000s
im_detect: 1224/4024 0.182s 0.000s
im_detect: 1225/4024 0.182s 0.000s
im_detect: 1226/4024 0.182s 0.000s
im_detect: 1227/4024 0.182s 0.000s
im_detect: 1228/4024 0.182s 0.000s
im_detect: 1229/4024 0.182s 0.000s
im_detect: 1230/4024 0.182s 0.000s
im_detect: 1231/4024 0.182s 0.000s
im_detect: 1232/4024 0.182s 0.000s
im_detect: 1233/4024 0.182s 0.000s
im_detect: 1234/4024 0.182s 0.000s
im_detect: 1235/4024 0.182s 0.000s
im_detect: 1236/4024 0.182s 0.000s
im_detect: 1237/4024 0.182s 0.000s
im_detect: 1238/4024 0.182s 0.000s
im_detect: 1239/4024 0.182s 0.000s
im_detect: 1240/4024 0.182s 0.000s
im_detect: 1241/4024 0.182s 0.000s
im_detect: 1242/4024 0.182s 0.000s
im_detect: 1243/4024 0.182s 0.000s
im_detect: 1244/4024 0.182s 0.000s
im_detect: 1245/4024 0.182s 0.000s
im_detect: 1246/4024 0.182s 0.000s
im_detect: 1247/4024 0.182s 0.000s
im_detect: 1248/4024 0.182s 0.000s
im_detect: 1249/4024 0.182s 0.000s
im_detect: 1250/4024 0.182s 0.000s
im_detect: 1251/4024 0.182s 0.000s
im_detect: 1252/4024 0.182s 0.000s
im_detect: 1253/4024 0.182s 0.000s
im_detect: 1254/4024 0.182s 0.000s
im_detect: 1255/4024 0.182s 0.000s
im_detect: 1256/4024 0.182s 0.000s
im_detect: 1257/4024 0.182s 0.000s
im_detect: 1258/4024 0.182s 0.000s
im_detect: 1259/4024 0.182s 0.000s
im_detect: 1260/4024 0.182s 0.000s
im_detect: 1261/4024 0.182s 0.000s
im_detect: 1262/4024 0.182s 0.000s
im_detect: 1263/4024 0.182s 0.000s
im_detect: 1264/4024 0.182s 0.000s
im_detect: 1265/4024 0.182s 0.000s
im_detect: 1266/4024 0.182s 0.000s
im_detect: 1267/4024 0.182s 0.000s
im_detect: 1268/4024 0.182s 0.000s
im_detect: 1269/4024 0.182s 0.000s
im_detect: 1270/4024 0.182s 0.000s
im_detect: 1271/4024 0.182s 0.000s
im_detect: 1272/4024 0.182s 0.000s
im_detect: 1273/4024 0.182s 0.000s
im_detect: 1274/4024 0.182s 0.000s
im_detect: 1275/4024 0.182s 0.000s
im_detect: 1276/4024 0.182s 0.000s
im_detect: 1277/4024 0.182s 0.000s
im_detect: 1278/4024 0.182s 0.000s
im_detect: 1279/4024 0.182s 0.000s
im_detect: 1280/4024 0.182s 0.000s
im_detect: 1281/4024 0.182s 0.000s
im_detect: 1282/4024 0.182s 0.000s
im_detect: 1283/4024 0.182s 0.000s
im_detect: 1284/4024 0.182s 0.000s
im_detect: 1285/4024 0.182s 0.000s
im_detect: 1286/4024 0.182s 0.000s
im_detect: 1287/4024 0.182s 0.000s
im_detect: 1288/4024 0.182s 0.000s
im_detect: 1289/4024 0.182s 0.000s
im_detect: 1290/4024 0.182s 0.000s
im_detect: 1291/4024 0.182s 0.000s
im_detect: 1292/4024 0.182s 0.000s
im_detect: 1293/4024 0.182s 0.000s
im_detect: 1294/4024 0.182s 0.000s
im_detect: 1295/4024 0.182s 0.000s
im_detect: 1296/4024 0.182s 0.000s
im_detect: 1297/4024 0.182s 0.000s
im_detect: 1298/4024 0.182s 0.000s
im_detect: 1299/4024 0.182s 0.000s
im_detect: 1300/4024 0.182s 0.000s
im_detect: 1301/4024 0.182s 0.000s
im_detect: 1302/4024 0.182s 0.000s
im_detect: 1303/4024 0.182s 0.000s
im_detect: 1304/4024 0.182s 0.000s
im_detect: 1305/4024 0.182s 0.000s
im_detect: 1306/4024 0.182s 0.000s
im_detect: 1307/4024 0.182s 0.000s
im_detect: 1308/4024 0.182s 0.000s
im_detect: 1309/4024 0.182s 0.000s
im_detect: 1310/4024 0.182s 0.000s
im_detect: 1311/4024 0.182s 0.000s
im_detect: 1312/4024 0.182s 0.000s
im_detect: 1313/4024 0.182s 0.000s
im_detect: 1314/4024 0.182s 0.000s
im_detect: 1315/4024 0.182s 0.000s
im_detect: 1316/4024 0.182s 0.000s
im_detect: 1317/4024 0.182s 0.000s
im_detect: 1318/4024 0.182s 0.000s
im_detect: 1319/4024 0.182s 0.000s
im_detect: 1320/4024 0.182s 0.000s
im_detect: 1321/4024 0.182s 0.000s
im_detect: 1322/4024 0.182s 0.000s
im_detect: 1323/4024 0.182s 0.000s
im_detect: 1324/4024 0.182s 0.000s
im_detect: 1325/4024 0.182s 0.000s
im_detect: 1326/4024 0.182s 0.000s
im_detect: 1327/4024 0.182s 0.000s
im_detect: 1328/4024 0.182s 0.000s
im_detect: 1329/4024 0.182s 0.000s
im_detect: 1330/4024 0.182s 0.000s
im_detect: 1331/4024 0.182s 0.000s
im_detect: 1332/4024 0.182s 0.000s
im_detect: 1333/4024 0.182s 0.000s
im_detect: 1334/4024 0.182s 0.000s
im_detect: 1335/4024 0.182s 0.000s
im_detect: 1336/4024 0.182s 0.000s
im_detect: 1337/4024 0.182s 0.000s
im_detect: 1338/4024 0.182s 0.000s
im_detect: 1339/4024 0.182s 0.000s
im_detect: 1340/4024 0.182s 0.000s
im_detect: 1341/4024 0.182s 0.000s
im_detect: 1342/4024 0.182s 0.000s
im_detect: 1343/4024 0.182s 0.000s
im_detect: 1344/4024 0.182s 0.000s
im_detect: 1345/4024 0.182s 0.000s
im_detect: 1346/4024 0.182s 0.000s
im_detect: 1347/4024 0.182s 0.000s
im_detect: 1348/4024 0.182s 0.000s
im_detect: 1349/4024 0.182s 0.000s
im_detect: 1350/4024 0.182s 0.000s
im_detect: 1351/4024 0.182s 0.000s
im_detect: 1352/4024 0.182s 0.000s
im_detect: 1353/4024 0.182s 0.000s
im_detect: 1354/4024 0.182s 0.000s
im_detect: 1355/4024 0.182s 0.000s
im_detect: 1356/4024 0.182s 0.000s
im_detect: 1357/4024 0.182s 0.000s
im_detect: 1358/4024 0.182s 0.000s
im_detect: 1359/4024 0.182s 0.000s
im_detect: 1360/4024 0.182s 0.000s
im_detect: 1361/4024 0.182s 0.000s
im_detect: 1362/4024 0.182s 0.000s
im_detect: 1363/4024 0.182s 0.000s
im_detect: 1364/4024 0.182s 0.000s
im_detect: 1365/4024 0.182s 0.000s
im_detect: 1366/4024 0.182s 0.000s
im_detect: 1367/4024 0.182s 0.000s
im_detect: 1368/4024 0.182s 0.000s
im_detect: 1369/4024 0.182s 0.000s
im_detect: 1370/4024 0.182s 0.000s
im_detect: 1371/4024 0.182s 0.000s
im_detect: 1372/4024 0.182s 0.000s
im_detect: 1373/4024 0.182s 0.000s
im_detect: 1374/4024 0.182s 0.000s
im_detect: 1375/4024 0.182s 0.000s
im_detect: 1376/4024 0.182s 0.000s
im_detect: 1377/4024 0.182s 0.000s
im_detect: 1378/4024 0.182s 0.000s
im_detect: 1379/4024 0.182s 0.000s
im_detect: 1380/4024 0.182s 0.000s
im_detect: 1381/4024 0.182s 0.000s
im_detect: 1382/4024 0.182s 0.000s
im_detect: 1383/4024 0.182s 0.000s
im_detect: 1384/4024 0.182s 0.000s
im_detect: 1385/4024 0.182s 0.000s
im_detect: 1386/4024 0.182s 0.000s
im_detect: 1387/4024 0.182s 0.000s
im_detect: 1388/4024 0.182s 0.000s
im_detect: 1389/4024 0.182s 0.000s
im_detect: 1390/4024 0.182s 0.000s
im_detect: 1391/4024 0.182s 0.000s
im_detect: 1392/4024 0.182s 0.000s
im_detect: 1393/4024 0.182s 0.000s
im_detect: 1394/4024 0.182s 0.000s
im_detect: 1395/4024 0.182s 0.000s
im_detect: 1396/4024 0.182s 0.000s
im_detect: 1397/4024 0.182s 0.000s
im_detect: 1398/4024 0.182s 0.000s
im_detect: 1399/4024 0.182s 0.000s
im_detect: 1400/4024 0.182s 0.000s
im_detect: 1401/4024 0.182s 0.000s
im_detect: 1402/4024 0.182s 0.000s
im_detect: 1403/4024 0.182s 0.000s
im_detect: 1404/4024 0.182s 0.000s
im_detect: 1405/4024 0.182s 0.000s
im_detect: 1406/4024 0.182s 0.000s
im_detect: 1407/4024 0.182s 0.000s
im_detect: 1408/4024 0.182s 0.000s
im_detect: 1409/4024 0.182s 0.000s
im_detect: 1410/4024 0.182s 0.000s
im_detect: 1411/4024 0.182s 0.000s
im_detect: 1412/4024 0.182s 0.000s
im_detect: 1413/4024 0.182s 0.000s
im_detect: 1414/4024 0.182s 0.000s
im_detect: 1415/4024 0.182s 0.000s
im_detect: 1416/4024 0.182s 0.000s
im_detect: 1417/4024 0.182s 0.000s
im_detect: 1418/4024 0.182s 0.000s
im_detect: 1419/4024 0.182s 0.000s
im_detect: 1420/4024 0.182s 0.000s
im_detect: 1421/4024 0.182s 0.000s
im_detect: 1422/4024 0.182s 0.000s
im_detect: 1423/4024 0.182s 0.000s
im_detect: 1424/4024 0.182s 0.000s
im_detect: 1425/4024 0.182s 0.000s
im_detect: 1426/4024 0.182s 0.000s
im_detect: 1427/4024 0.182s 0.000s
im_detect: 1428/4024 0.182s 0.000s
im_detect: 1429/4024 0.182s 0.000s
im_detect: 1430/4024 0.182s 0.000s
im_detect: 1431/4024 0.182s 0.000s
im_detect: 1432/4024 0.182s 0.000s
im_detect: 1433/4024 0.182s 0.000s
im_detect: 1434/4024 0.182s 0.000s
im_detect: 1435/4024 0.182s 0.000s
im_detect: 1436/4024 0.182s 0.000s
im_detect: 1437/4024 0.182s 0.000s
im_detect: 1438/4024 0.182s 0.000s
im_detect: 1439/4024 0.182s 0.000s
im_detect: 1440/4024 0.182s 0.000s
im_detect: 1441/4024 0.182s 0.000s
im_detect: 1442/4024 0.182s 0.000s
im_detect: 1443/4024 0.182s 0.000s
im_detect: 1444/4024 0.182s 0.000s
im_detect: 1445/4024 0.182s 0.000s
im_detect: 1446/4024 0.182s 0.000s
im_detect: 1447/4024 0.182s 0.000s
im_detect: 1448/4024 0.182s 0.000s
im_detect: 1449/4024 0.182s 0.000s
im_detect: 1450/4024 0.182s 0.000s
im_detect: 1451/4024 0.182s 0.000s
im_detect: 1452/4024 0.182s 0.000s
im_detect: 1453/4024 0.182s 0.000s
im_detect: 1454/4024 0.182s 0.000s
im_detect: 1455/4024 0.182s 0.000s
im_detect: 1456/4024 0.182s 0.000s
im_detect: 1457/4024 0.182s 0.000s
im_detect: 1458/4024 0.182s 0.000s
im_detect: 1459/4024 0.182s 0.000s
im_detect: 1460/4024 0.182s 0.000s
im_detect: 1461/4024 0.182s 0.000s
im_detect: 1462/4024 0.182s 0.000s
im_detect: 1463/4024 0.182s 0.000s
im_detect: 1464/4024 0.182s 0.000s
im_detect: 1465/4024 0.182s 0.000s
im_detect: 1466/4024 0.182s 0.000s
im_detect: 1467/4024 0.182s 0.000s
im_detect: 1468/4024 0.182s 0.000s
im_detect: 1469/4024 0.182s 0.000s
im_detect: 1470/4024 0.182s 0.000s
im_detect: 1471/4024 0.182s 0.000s
im_detect: 1472/4024 0.182s 0.000s
im_detect: 1473/4024 0.182s 0.000s
im_detect: 1474/4024 0.182s 0.000s
im_detect: 1475/4024 0.182s 0.000s
im_detect: 1476/4024 0.182s 0.000s
im_detect: 1477/4024 0.182s 0.000s
im_detect: 1478/4024 0.182s 0.000s
im_detect: 1479/4024 0.182s 0.000s
im_detect: 1480/4024 0.182s 0.000s
im_detect: 1481/4024 0.182s 0.000s
im_detect: 1482/4024 0.182s 0.000s
im_detect: 1483/4024 0.182s 0.000s
im_detect: 1484/4024 0.182s 0.000s
im_detect: 1485/4024 0.182s 0.000s
im_detect: 1486/4024 0.182s 0.000s
im_detect: 1487/4024 0.182s 0.000s
im_detect: 1488/4024 0.182s 0.000s
im_detect: 1489/4024 0.182s 0.000s
im_detect: 1490/4024 0.182s 0.000s
im_detect: 1491/4024 0.182s 0.000s
im_detect: 1492/4024 0.182s 0.000s
im_detect: 1493/4024 0.182s 0.000s
im_detect: 1494/4024 0.182s 0.000s
im_detect: 1495/4024 0.182s 0.000s
im_detect: 1496/4024 0.182s 0.000s
im_detect: 1497/4024 0.182s 0.000s
im_detect: 1498/4024 0.182s 0.000s
im_detect: 1499/4024 0.182s 0.000s
im_detect: 1500/4024 0.182s 0.000s
im_detect: 1501/4024 0.182s 0.000s
im_detect: 1502/4024 0.182s 0.000s
im_detect: 1503/4024 0.182s 0.000s
im_detect: 1504/4024 0.182s 0.000s
im_detect: 1505/4024 0.182s 0.000s
im_detect: 1506/4024 0.182s 0.000s
im_detect: 1507/4024 0.182s 0.000s
im_detect: 1508/4024 0.182s 0.000s
im_detect: 1509/4024 0.182s 0.000s
im_detect: 1510/4024 0.182s 0.000s
im_detect: 1511/4024 0.182s 0.000s
im_detect: 1512/4024 0.182s 0.000s
im_detect: 1513/4024 0.182s 0.000s
im_detect: 1514/4024 0.182s 0.000s
im_detect: 1515/4024 0.182s 0.000s
im_detect: 1516/4024 0.182s 0.000s
im_detect: 1517/4024 0.182s 0.000s
im_detect: 1518/4024 0.182s 0.000s
im_detect: 1519/4024 0.182s 0.000s
im_detect: 1520/4024 0.182s 0.000s
im_detect: 1521/4024 0.182s 0.000s
im_detect: 1522/4024 0.182s 0.000s
im_detect: 1523/4024 0.182s 0.000s
im_detect: 1524/4024 0.182s 0.000s
im_detect: 1525/4024 0.182s 0.000s
im_detect: 1526/4024 0.182s 0.000s
im_detect: 1527/4024 0.182s 0.000s
im_detect: 1528/4024 0.182s 0.000s
im_detect: 1529/4024 0.182s 0.000s
im_detect: 1530/4024 0.182s 0.000s
im_detect: 1531/4024 0.182s 0.000s
im_detect: 1532/4024 0.182s 0.000s
im_detect: 1533/4024 0.182s 0.000s
im_detect: 1534/4024 0.182s 0.000s
im_detect: 1535/4024 0.182s 0.000s
im_detect: 1536/4024 0.182s 0.000s
im_detect: 1537/4024 0.182s 0.000s
im_detect: 1538/4024 0.182s 0.000s
im_detect: 1539/4024 0.182s 0.000s
im_detect: 1540/4024 0.182s 0.000s
im_detect: 1541/4024 0.182s 0.000s
im_detect: 1542/4024 0.182s 0.000s
im_detect: 1543/4024 0.182s 0.000s
im_detect: 1544/4024 0.182s 0.000s
im_detect: 1545/4024 0.182s 0.000s
im_detect: 1546/4024 0.182s 0.000s
im_detect: 1547/4024 0.182s 0.000s
im_detect: 1548/4024 0.182s 0.000s
im_detect: 1549/4024 0.182s 0.000s
im_detect: 1550/4024 0.182s 0.000s
im_detect: 1551/4024 0.182s 0.000s
im_detect: 1552/4024 0.182s 0.000s
im_detect: 1553/4024 0.182s 0.000s
im_detect: 1554/4024 0.182s 0.000s
im_detect: 1555/4024 0.182s 0.000s
im_detect: 1556/4024 0.182s 0.000s
im_detect: 1557/4024 0.182s 0.000s
im_detect: 1558/4024 0.182s 0.000s
im_detect: 1559/4024 0.182s 0.000s
im_detect: 1560/4024 0.182s 0.000s
im_detect: 1561/4024 0.182s 0.000s
im_detect: 1562/4024 0.182s 0.000s
im_detect: 1563/4024 0.182s 0.000s
im_detect: 1564/4024 0.182s 0.000s
im_detect: 1565/4024 0.182s 0.000s
im_detect: 1566/4024 0.182s 0.000s
im_detect: 1567/4024 0.182s 0.000s
im_detect: 1568/4024 0.182s 0.000s
im_detect: 1569/4024 0.182s 0.000s
im_detect: 1570/4024 0.182s 0.000s
im_detect: 1571/4024 0.182s 0.000s
im_detect: 1572/4024 0.182s 0.000s
im_detect: 1573/4024 0.182s 0.000s
im_detect: 1574/4024 0.182s 0.000s
im_detect: 1575/4024 0.182s 0.000s
im_detect: 1576/4024 0.182s 0.000s
im_detect: 1577/4024 0.182s 0.000s
im_detect: 1578/4024 0.182s 0.000s
im_detect: 1579/4024 0.182s 0.000s
im_detect: 1580/4024 0.182s 0.000s
im_detect: 1581/4024 0.182s 0.000s
im_detect: 1582/4024 0.182s 0.000s
im_detect: 1583/4024 0.182s 0.000s
im_detect: 1584/4024 0.182s 0.000s
im_detect: 1585/4024 0.182s 0.000s
im_detect: 1586/4024 0.182s 0.000s
im_detect: 1587/4024 0.182s 0.000s
im_detect: 1588/4024 0.182s 0.000s
im_detect: 1589/4024 0.182s 0.000s
im_detect: 1590/4024 0.182s 0.000s
im_detect: 1591/4024 0.182s 0.000s
im_detect: 1592/4024 0.182s 0.000s
im_detect: 1593/4024 0.182s 0.000s
im_detect: 1594/4024 0.182s 0.000s
im_detect: 1595/4024 0.182s 0.000s
im_detect: 1596/4024 0.182s 0.000s
im_detect: 1597/4024 0.182s 0.000s
im_detect: 1598/4024 0.182s 0.000s
im_detect: 1599/4024 0.182s 0.000s
im_detect: 1600/4024 0.182s 0.000s
im_detect: 1601/4024 0.182s 0.000s
im_detect: 1602/4024 0.182s 0.000s
im_detect: 1603/4024 0.182s 0.000s
im_detect: 1604/4024 0.182s 0.000s
im_detect: 1605/4024 0.182s 0.000s
im_detect: 1606/4024 0.182s 0.000s
im_detect: 1607/4024 0.182s 0.000s
im_detect: 1608/4024 0.182s 0.000s
im_detect: 1609/4024 0.182s 0.000s
im_detect: 1610/4024 0.182s 0.000s
im_detect: 1611/4024 0.182s 0.000s
im_detect: 1612/4024 0.182s 0.000s
im_detect: 1613/4024 0.182s 0.000s
im_detect: 1614/4024 0.182s 0.000s
im_detect: 1615/4024 0.182s 0.000s
im_detect: 1616/4024 0.182s 0.000s
im_detect: 1617/4024 0.182s 0.000s
im_detect: 1618/4024 0.182s 0.000s
im_detect: 1619/4024 0.182s 0.000s
im_detect: 1620/4024 0.182s 0.000s
im_detect: 1621/4024 0.182s 0.000s
im_detect: 1622/4024 0.182s 0.000s
im_detect: 1623/4024 0.182s 0.000s
im_detect: 1624/4024 0.182s 0.000s
im_detect: 1625/4024 0.182s 0.000s
im_detect: 1626/4024 0.182s 0.000s
im_detect: 1627/4024 0.182s 0.000s
im_detect: 1628/4024 0.182s 0.000s
im_detect: 1629/4024 0.182s 0.000s
im_detect: 1630/4024 0.182s 0.000s
im_detect: 1631/4024 0.182s 0.000s
im_detect: 1632/4024 0.182s 0.000s
im_detect: 1633/4024 0.182s 0.000s
im_detect: 1634/4024 0.182s 0.000s
im_detect: 1635/4024 0.182s 0.000s
im_detect: 1636/4024 0.182s 0.000s
im_detect: 1637/4024 0.182s 0.000s
im_detect: 1638/4024 0.182s 0.000s
im_detect: 1639/4024 0.182s 0.000s
im_detect: 1640/4024 0.182s 0.000s
im_detect: 1641/4024 0.182s 0.000s
im_detect: 1642/4024 0.182s 0.000s
im_detect: 1643/4024 0.182s 0.000s
im_detect: 1644/4024 0.182s 0.000s
im_detect: 1645/4024 0.182s 0.000s
im_detect: 1646/4024 0.182s 0.000s
im_detect: 1647/4024 0.182s 0.000s
im_detect: 1648/4024 0.182s 0.000s
im_detect: 1649/4024 0.182s 0.000s
im_detect: 1650/4024 0.182s 0.000s
im_detect: 1651/4024 0.182s 0.000s
im_detect: 1652/4024 0.182s 0.000s
im_detect: 1653/4024 0.182s 0.000s
im_detect: 1654/4024 0.182s 0.000s
im_detect: 1655/4024 0.182s 0.000s
im_detect: 1656/4024 0.182s 0.000s
im_detect: 1657/4024 0.182s 0.000s
im_detect: 1658/4024 0.182s 0.000s
im_detect: 1659/4024 0.182s 0.000s
im_detect: 1660/4024 0.182s 0.000s
im_detect: 1661/4024 0.182s 0.000s
im_detect: 1662/4024 0.182s 0.000s
im_detect: 1663/4024 0.182s 0.000s
im_detect: 1664/4024 0.182s 0.000s
im_detect: 1665/4024 0.182s 0.000s
im_detect: 1666/4024 0.182s 0.000s
im_detect: 1667/4024 0.182s 0.000s
im_detect: 1668/4024 0.182s 0.000s
im_detect: 1669/4024 0.182s 0.000s
im_detect: 1670/4024 0.182s 0.000s
im_detect: 1671/4024 0.182s 0.000s
im_detect: 1672/4024 0.182s 0.000s
im_detect: 1673/4024 0.182s 0.000s
im_detect: 1674/4024 0.182s 0.000s
im_detect: 1675/4024 0.182s 0.000s
im_detect: 1676/4024 0.182s 0.000s
im_detect: 1677/4024 0.182s 0.000s
im_detect: 1678/4024 0.182s 0.000s
im_detect: 1679/4024 0.182s 0.000s
im_detect: 1680/4024 0.182s 0.000s
im_detect: 1681/4024 0.182s 0.000s
im_detect: 1682/4024 0.182s 0.000s
im_detect: 1683/4024 0.182s 0.000s
im_detect: 1684/4024 0.182s 0.000s
im_detect: 1685/4024 0.182s 0.000s
im_detect: 1686/4024 0.182s 0.000s
im_detect: 1687/4024 0.182s 0.000s
im_detect: 1688/4024 0.182s 0.000s
im_detect: 1689/4024 0.182s 0.000s
im_detect: 1690/4024 0.182s 0.000s
im_detect: 1691/4024 0.182s 0.000s
im_detect: 1692/4024 0.182s 0.000s
im_detect: 1693/4024 0.182s 0.000s
im_detect: 1694/4024 0.182s 0.000s
im_detect: 1695/4024 0.182s 0.000s
im_detect: 1696/4024 0.182s 0.000s
im_detect: 1697/4024 0.182s 0.000s
im_detect: 1698/4024 0.182s 0.000s
im_detect: 1699/4024 0.182s 0.000s
im_detect: 1700/4024 0.182s 0.000s
im_detect: 1701/4024 0.182s 0.000s
im_detect: 1702/4024 0.182s 0.000s
im_detect: 1703/4024 0.182s 0.000s
im_detect: 1704/4024 0.182s 0.000s
im_detect: 1705/4024 0.182s 0.000s
im_detect: 1706/4024 0.182s 0.000s
im_detect: 1707/4024 0.182s 0.000s
im_detect: 1708/4024 0.182s 0.000s
im_detect: 1709/4024 0.182s 0.000s
im_detect: 1710/4024 0.182s 0.000s
im_detect: 1711/4024 0.182s 0.000s
im_detect: 1712/4024 0.182s 0.000s
im_detect: 1713/4024 0.182s 0.000s
im_detect: 1714/4024 0.182s 0.000s
im_detect: 1715/4024 0.182s 0.000s
im_detect: 1716/4024 0.182s 0.000s
im_detect: 1717/4024 0.182s 0.000s
im_detect: 1718/4024 0.182s 0.000s
im_detect: 1719/4024 0.182s 0.000s
im_detect: 1720/4024 0.182s 0.000s
im_detect: 1721/4024 0.182s 0.000s
im_detect: 1722/4024 0.182s 0.000s
im_detect: 1723/4024 0.182s 0.000s
im_detect: 1724/4024 0.182s 0.000s
im_detect: 1725/4024 0.182s 0.000s
im_detect: 1726/4024 0.182s 0.000s
im_detect: 1727/4024 0.182s 0.000s
im_detect: 1728/4024 0.182s 0.000s
im_detect: 1729/4024 0.182s 0.000s
im_detect: 1730/4024 0.182s 0.000s
im_detect: 1731/4024 0.182s 0.000s
im_detect: 1732/4024 0.182s 0.000s
im_detect: 1733/4024 0.182s 0.000s
im_detect: 1734/4024 0.182s 0.000s
im_detect: 1735/4024 0.182s 0.000s
im_detect: 1736/4024 0.182s 0.000s
im_detect: 1737/4024 0.182s 0.000s
im_detect: 1738/4024 0.182s 0.000s
im_detect: 1739/4024 0.182s 0.000s
im_detect: 1740/4024 0.182s 0.000s
im_detect: 1741/4024 0.182s 0.000s
im_detect: 1742/4024 0.182s 0.000s
im_detect: 1743/4024 0.182s 0.000s
im_detect: 1744/4024 0.182s 0.000s
im_detect: 1745/4024 0.182s 0.000s
im_detect: 1746/4024 0.182s 0.000s
im_detect: 1747/4024 0.182s 0.000s
im_detect: 1748/4024 0.182s 0.000s
im_detect: 1749/4024 0.182s 0.000s
im_detect: 1750/4024 0.182s 0.000s
im_detect: 1751/4024 0.182s 0.000s
im_detect: 1752/4024 0.182s 0.000s
im_detect: 1753/4024 0.182s 0.000s
im_detect: 1754/4024 0.182s 0.000s
im_detect: 1755/4024 0.182s 0.000s
im_detect: 1756/4024 0.182s 0.000s
im_detect: 1757/4024 0.182s 0.000s
im_detect: 1758/4024 0.182s 0.000s
im_detect: 1759/4024 0.182s 0.000s
im_detect: 1760/4024 0.182s 0.000s
im_detect: 1761/4024 0.182s 0.000s
im_detect: 1762/4024 0.182s 0.000s
im_detect: 1763/4024 0.182s 0.000s
im_detect: 1764/4024 0.182s 0.000s
im_detect: 1765/4024 0.182s 0.000s
im_detect: 1766/4024 0.182s 0.000s
im_detect: 1767/4024 0.182s 0.000s
im_detect: 1768/4024 0.182s 0.000s
im_detect: 1769/4024 0.182s 0.000s
im_detect: 1770/4024 0.182s 0.000s
im_detect: 1771/4024 0.182s 0.000s
im_detect: 1772/4024 0.182s 0.000s
im_detect: 1773/4024 0.182s 0.000s
im_detect: 1774/4024 0.182s 0.000s
im_detect: 1775/4024 0.182s 0.000s
im_detect: 1776/4024 0.182s 0.000s
im_detect: 1777/4024 0.182s 0.000s
im_detect: 1778/4024 0.182s 0.000s
im_detect: 1779/4024 0.182s 0.000s
im_detect: 1780/4024 0.182s 0.000s
im_detect: 1781/4024 0.182s 0.000s
im_detect: 1782/4024 0.182s 0.000s
im_detect: 1783/4024 0.182s 0.000s
im_detect: 1784/4024 0.182s 0.000s
im_detect: 1785/4024 0.182s 0.000s
im_detect: 1786/4024 0.182s 0.000s
im_detect: 1787/4024 0.182s 0.000s
im_detect: 1788/4024 0.182s 0.000s
im_detect: 1789/4024 0.182s 0.000s
im_detect: 1790/4024 0.182s 0.000s
im_detect: 1791/4024 0.182s 0.000s
im_detect: 1792/4024 0.182s 0.000s
im_detect: 1793/4024 0.182s 0.000s
im_detect: 1794/4024 0.182s 0.000s
im_detect: 1795/4024 0.182s 0.000s
im_detect: 1796/4024 0.182s 0.000s
im_detect: 1797/4024 0.182s 0.000s
im_detect: 1798/4024 0.182s 0.000s
im_detect: 1799/4024 0.182s 0.000s
im_detect: 1800/4024 0.182s 0.000s
im_detect: 1801/4024 0.182s 0.000s
im_detect: 1802/4024 0.182s 0.000s
im_detect: 1803/4024 0.182s 0.000s
im_detect: 1804/4024 0.182s 0.000s
im_detect: 1805/4024 0.182s 0.000s
im_detect: 1806/4024 0.182s 0.000s
im_detect: 1807/4024 0.182s 0.000s
im_detect: 1808/4024 0.182s 0.000s
im_detect: 1809/4024 0.182s 0.000s
im_detect: 1810/4024 0.182s 0.000s
im_detect: 1811/4024 0.182s 0.000s
im_detect: 1812/4024 0.182s 0.000s
im_detect: 1813/4024 0.182s 0.000s
im_detect: 1814/4024 0.182s 0.000s
im_detect: 1815/4024 0.182s 0.000s
im_detect: 1816/4024 0.182s 0.000s
im_detect: 1817/4024 0.182s 0.000s
im_detect: 1818/4024 0.182s 0.000s
im_detect: 1819/4024 0.182s 0.000s
im_detect: 1820/4024 0.182s 0.000s
im_detect: 1821/4024 0.182s 0.000s
im_detect: 1822/4024 0.182s 0.000s
im_detect: 1823/4024 0.182s 0.000s
im_detect: 1824/4024 0.182s 0.000s
im_detect: 1825/4024 0.182s 0.000s
im_detect: 1826/4024 0.182s 0.000s
im_detect: 1827/4024 0.182s 0.000s
im_detect: 1828/4024 0.182s 0.000s
im_detect: 1829/4024 0.182s 0.000s
im_detect: 1830/4024 0.182s 0.000s
im_detect: 1831/4024 0.182s 0.000s
im_detect: 1832/4024 0.182s 0.000s
im_detect: 1833/4024 0.182s 0.000s
im_detect: 1834/4024 0.182s 0.000s
im_detect: 1835/4024 0.182s 0.000s
im_detect: 1836/4024 0.182s 0.000s
im_detect: 1837/4024 0.182s 0.000s
im_detect: 1838/4024 0.182s 0.000s
im_detect: 1839/4024 0.182s 0.000s
im_detect: 1840/4024 0.182s 0.000s
im_detect: 1841/4024 0.182s 0.000s
im_detect: 1842/4024 0.182s 0.000s
im_detect: 1843/4024 0.182s 0.000s
im_detect: 1844/4024 0.182s 0.000s
im_detect: 1845/4024 0.182s 0.000s
im_detect: 1846/4024 0.182s 0.000s
im_detect: 1847/4024 0.182s 0.000s
im_detect: 1848/4024 0.182s 0.000s
im_detect: 1849/4024 0.182s 0.000s
im_detect: 1850/4024 0.182s 0.000s
im_detect: 1851/4024 0.182s 0.000s
im_detect: 1852/4024 0.182s 0.000s
im_detect: 1853/4024 0.182s 0.000s
im_detect: 1854/4024 0.182s 0.000s
im_detect: 1855/4024 0.182s 0.000s
im_detect: 1856/4024 0.182s 0.000s
im_detect: 1857/4024 0.182s 0.000s
im_detect: 1858/4024 0.182s 0.000s
im_detect: 1859/4024 0.182s 0.000s
im_detect: 1860/4024 0.182s 0.000s
im_detect: 1861/4024 0.182s 0.000s
im_detect: 1862/4024 0.182s 0.000s
im_detect: 1863/4024 0.182s 0.000s
im_detect: 1864/4024 0.182s 0.000s
im_detect: 1865/4024 0.182s 0.000s
im_detect: 1866/4024 0.182s 0.000s
im_detect: 1867/4024 0.182s 0.000s
im_detect: 1868/4024 0.182s 0.000s
im_detect: 1869/4024 0.182s 0.000s
im_detect: 1870/4024 0.182s 0.000s
im_detect: 1871/4024 0.182s 0.000s
im_detect: 1872/4024 0.182s 0.000s
im_detect: 1873/4024 0.182s 0.000s
im_detect: 1874/4024 0.182s 0.000s
im_detect: 1875/4024 0.182s 0.000s
im_detect: 1876/4024 0.182s 0.000s
im_detect: 1877/4024 0.182s 0.000s
im_detect: 1878/4024 0.182s 0.000s
im_detect: 1879/4024 0.182s 0.000s
im_detect: 1880/4024 0.182s 0.000s
im_detect: 1881/4024 0.182s 0.000s
im_detect: 1882/4024 0.182s 0.000s
im_detect: 1883/4024 0.182s 0.000s
im_detect: 1884/4024 0.182s 0.000s
im_detect: 1885/4024 0.182s 0.000s
im_detect: 1886/4024 0.182s 0.000s
im_detect: 1887/4024 0.182s 0.000s
im_detect: 1888/4024 0.182s 0.000s
im_detect: 1889/4024 0.182s 0.000s
im_detect: 1890/4024 0.182s 0.000s
im_detect: 1891/4024 0.182s 0.000s
im_detect: 1892/4024 0.182s 0.000s
im_detect: 1893/4024 0.182s 0.000s
im_detect: 1894/4024 0.182s 0.000s
im_detect: 1895/4024 0.182s 0.000s
im_detect: 1896/4024 0.182s 0.000s
im_detect: 1897/4024 0.182s 0.000s
im_detect: 1898/4024 0.182s 0.000s
im_detect: 1899/4024 0.182s 0.000s
im_detect: 1900/4024 0.182s 0.000s
im_detect: 1901/4024 0.182s 0.000s
im_detect: 1902/4024 0.182s 0.000s
im_detect: 1903/4024 0.182s 0.000s
im_detect: 1904/4024 0.182s 0.000s
im_detect: 1905/4024 0.182s 0.000s
im_detect: 1906/4024 0.182s 0.000s
im_detect: 1907/4024 0.182s 0.000s
im_detect: 1908/4024 0.182s 0.000s
im_detect: 1909/4024 0.182s 0.000s
im_detect: 1910/4024 0.182s 0.000s
im_detect: 1911/4024 0.182s 0.000s
im_detect: 1912/4024 0.182s 0.000s
im_detect: 1913/4024 0.182s 0.000s
im_detect: 1914/4024 0.182s 0.000s
im_detect: 1915/4024 0.182s 0.000s
im_detect: 1916/4024 0.182s 0.000s
im_detect: 1917/4024 0.182s 0.000s
im_detect: 1918/4024 0.182s 0.000s
im_detect: 1919/4024 0.182s 0.000s
im_detect: 1920/4024 0.182s 0.000s
im_detect: 1921/4024 0.182s 0.000s
im_detect: 1922/4024 0.182s 0.000s
im_detect: 1923/4024 0.182s 0.000s
im_detect: 1924/4024 0.182s 0.000s
im_detect: 1925/4024 0.182s 0.000s
im_detect: 1926/4024 0.182s 0.000s
im_detect: 1927/4024 0.182s 0.000s
im_detect: 1928/4024 0.182s 0.000s
im_detect: 1929/4024 0.182s 0.000s
im_detect: 1930/4024 0.182s 0.000s
im_detect: 1931/4024 0.182s 0.000s
im_detect: 1932/4024 0.182s 0.000s
im_detect: 1933/4024 0.182s 0.000s
im_detect: 1934/4024 0.182s 0.000s
im_detect: 1935/4024 0.182s 0.000s
im_detect: 1936/4024 0.182s 0.000s
im_detect: 1937/4024 0.182s 0.000s
im_detect: 1938/4024 0.182s 0.000s
im_detect: 1939/4024 0.182s 0.000s
im_detect: 1940/4024 0.182s 0.000s
im_detect: 1941/4024 0.182s 0.000s
im_detect: 1942/4024 0.182s 0.000s
im_detect: 1943/4024 0.182s 0.000s
im_detect: 1944/4024 0.182s 0.000s
im_detect: 1945/4024 0.182s 0.000s
im_detect: 1946/4024 0.182s 0.000s
im_detect: 1947/4024 0.182s 0.000s
im_detect: 1948/4024 0.182s 0.000s
im_detect: 1949/4024 0.182s 0.000s
im_detect: 1950/4024 0.182s 0.000s
im_detect: 1951/4024 0.182s 0.000s
im_detect: 1952/4024 0.182s 0.000s
im_detect: 1953/4024 0.182s 0.000s
im_detect: 1954/4024 0.182s 0.000s
im_detect: 1955/4024 0.182s 0.000s
im_detect: 1956/4024 0.182s 0.000s
im_detect: 1957/4024 0.182s 0.000s
im_detect: 1958/4024 0.182s 0.000s
im_detect: 1959/4024 0.182s 0.000s
im_detect: 1960/4024 0.182s 0.000s
im_detect: 1961/4024 0.182s 0.000s
im_detect: 1962/4024 0.182s 0.000s
im_detect: 1963/4024 0.182s 0.000s
im_detect: 1964/4024 0.182s 0.000s
im_detect: 1965/4024 0.182s 0.000s
im_detect: 1966/4024 0.182s 0.000s
im_detect: 1967/4024 0.182s 0.000s
im_detect: 1968/4024 0.182s 0.000s
im_detect: 1969/4024 0.182s 0.000s
im_detect: 1970/4024 0.182s 0.000s
im_detect: 1971/4024 0.182s 0.000s
im_detect: 1972/4024 0.182s 0.000s
im_detect: 1973/4024 0.182s 0.000s
im_detect: 1974/4024 0.182s 0.000s
im_detect: 1975/4024 0.182s 0.000s
im_detect: 1976/4024 0.182s 0.000s
im_detect: 1977/4024 0.182s 0.000s
im_detect: 1978/4024 0.182s 0.000s
im_detect: 1979/4024 0.182s 0.000s
im_detect: 1980/4024 0.182s 0.000s
im_detect: 1981/4024 0.182s 0.000s
im_detect: 1982/4024 0.182s 0.000s
im_detect: 1983/4024 0.182s 0.000s
im_detect: 1984/4024 0.182s 0.000s
im_detect: 1985/4024 0.182s 0.000s
im_detect: 1986/4024 0.182s 0.000s
im_detect: 1987/4024 0.182s 0.000s
im_detect: 1988/4024 0.182s 0.000s
im_detect: 1989/4024 0.182s 0.000s
im_detect: 1990/4024 0.182s 0.000s
im_detect: 1991/4024 0.182s 0.000s
im_detect: 1992/4024 0.182s 0.000s
im_detect: 1993/4024 0.182s 0.000s
im_detect: 1994/4024 0.182s 0.000s
im_detect: 1995/4024 0.182s 0.000s
im_detect: 1996/4024 0.182s 0.000s
im_detect: 1997/4024 0.182s 0.000s
im_detect: 1998/4024 0.182s 0.000s
im_detect: 1999/4024 0.182s 0.000s
im_detect: 2000/4024 0.182s 0.000s
im_detect: 2001/4024 0.182s 0.000s
im_detect: 2002/4024 0.182s 0.000s
im_detect: 2003/4024 0.182s 0.000s
im_detect: 2004/4024 0.182s 0.000s
im_detect: 2005/4024 0.182s 0.000s
im_detect: 2006/4024 0.182s 0.000s
im_detect: 2007/4024 0.182s 0.000s
im_detect: 2008/4024 0.182s 0.000s
im_detect: 2009/4024 0.182s 0.000s
im_detect: 2010/4024 0.182s 0.000s
im_detect: 2011/4024 0.182s 0.000s
im_detect: 2012/4024 0.182s 0.000s
im_detect: 2013/4024 0.182s 0.000s
im_detect: 2014/4024 0.182s 0.000s
im_detect: 2015/4024 0.182s 0.000s
im_detect: 2016/4024 0.182s 0.000s
im_detect: 2017/4024 0.182s 0.000s
im_detect: 2018/4024 0.182s 0.000s
im_detect: 2019/4024 0.182s 0.000s
im_detect: 2020/4024 0.182s 0.000s
im_detect: 2021/4024 0.182s 0.000s
im_detect: 2022/4024 0.182s 0.000s
im_detect: 2023/4024 0.182s 0.000s
im_detect: 2024/4024 0.182s 0.000s
im_detect: 2025/4024 0.182s 0.000s
im_detect: 2026/4024 0.182s 0.000s
im_detect: 2027/4024 0.182s 0.000s
im_detect: 2028/4024 0.182s 0.000s
im_detect: 2029/4024 0.182s 0.000s
im_detect: 2030/4024 0.182s 0.000s
im_detect: 2031/4024 0.182s 0.000s
im_detect: 2032/4024 0.182s 0.000s
im_detect: 2033/4024 0.182s 0.000s
im_detect: 2034/4024 0.182s 0.000s
im_detect: 2035/4024 0.182s 0.000s
im_detect: 2036/4024 0.182s 0.000s
im_detect: 2037/4024 0.182s 0.000s
im_detect: 2038/4024 0.182s 0.000s
im_detect: 2039/4024 0.182s 0.000s
im_detect: 2040/4024 0.182s 0.000s
im_detect: 2041/4024 0.182s 0.000s
im_detect: 2042/4024 0.182s 0.000s
im_detect: 2043/4024 0.182s 0.000s
im_detect: 2044/4024 0.182s 0.000s
im_detect: 2045/4024 0.182s 0.000s
im_detect: 2046/4024 0.182s 0.000s
im_detect: 2047/4024 0.182s 0.000s
im_detect: 2048/4024 0.182s 0.000s
im_detect: 2049/4024 0.182s 0.000s
im_detect: 2050/4024 0.182s 0.000s
im_detect: 2051/4024 0.182s 0.000s
im_detect: 2052/4024 0.182s 0.000s
im_detect: 2053/4024 0.182s 0.000s
im_detect: 2054/4024 0.182s 0.000s
im_detect: 2055/4024 0.182s 0.000s
im_detect: 2056/4024 0.182s 0.000s
im_detect: 2057/4024 0.182s 0.000s
im_detect: 2058/4024 0.182s 0.000s
im_detect: 2059/4024 0.182s 0.000s
im_detect: 2060/4024 0.182s 0.000s
im_detect: 2061/4024 0.182s 0.000s
im_detect: 2062/4024 0.182s 0.000s
im_detect: 2063/4024 0.182s 0.000s
im_detect: 2064/4024 0.182s 0.000s
im_detect: 2065/4024 0.182s 0.000s
im_detect: 2066/4024 0.182s 0.000s
im_detect: 2067/4024 0.182s 0.000s
im_detect: 2068/4024 0.182s 0.000s
im_detect: 2069/4024 0.182s 0.000s
im_detect: 2070/4024 0.182s 0.000s
im_detect: 2071/4024 0.182s 0.000s
im_detect: 2072/4024 0.182s 0.000s
im_detect: 2073/4024 0.182s 0.000s
im_detect: 2074/4024 0.182s 0.000s
im_detect: 2075/4024 0.182s 0.000s
im_detect: 2076/4024 0.182s 0.000s
im_detect: 2077/4024 0.182s 0.000s
im_detect: 2078/4024 0.182s 0.000s
im_detect: 2079/4024 0.182s 0.000s
im_detect: 2080/4024 0.182s 0.000s
im_detect: 2081/4024 0.182s 0.000s
im_detect: 2082/4024 0.182s 0.000s
im_detect: 2083/4024 0.182s 0.000s
im_detect: 2084/4024 0.182s 0.000s
im_detect: 2085/4024 0.182s 0.000s
im_detect: 2086/4024 0.182s 0.000s
im_detect: 2087/4024 0.182s 0.000s
im_detect: 2088/4024 0.182s 0.000s
im_detect: 2089/4024 0.182s 0.000s
im_detect: 2090/4024 0.182s 0.000s
im_detect: 2091/4024 0.182s 0.000s
im_detect: 2092/4024 0.182s 0.000s
im_detect: 2093/4024 0.182s 0.000s
im_detect: 2094/4024 0.182s 0.000s
im_detect: 2095/4024 0.182s 0.000s
im_detect: 2096/4024 0.182s 0.000s
im_detect: 2097/4024 0.182s 0.000s
im_detect: 2098/4024 0.182s 0.000s
im_detect: 2099/4024 0.182s 0.000s
im_detect: 2100/4024 0.182s 0.000s
im_detect: 2101/4024 0.182s 0.000s
im_detect: 2102/4024 0.182s 0.000s
im_detect: 2103/4024 0.182s 0.000s
im_detect: 2104/4024 0.182s 0.000s
im_detect: 2105/4024 0.182s 0.000s
im_detect: 2106/4024 0.182s 0.000s
im_detect: 2107/4024 0.182s 0.000s
im_detect: 2108/4024 0.182s 0.000s
im_detect: 2109/4024 0.182s 0.000s
im_detect: 2110/4024 0.182s 0.000s
im_detect: 2111/4024 0.182s 0.000s
im_detect: 2112/4024 0.182s 0.000s
im_detect: 2113/4024 0.182s 0.000s
im_detect: 2114/4024 0.182s 0.000s
im_detect: 2115/4024 0.182s 0.000s
im_detect: 2116/4024 0.182s 0.000s
im_detect: 2117/4024 0.182s 0.000s
im_detect: 2118/4024 0.182s 0.000s
im_detect: 2119/4024 0.182s 0.000s
im_detect: 2120/4024 0.182s 0.000s
im_detect: 2121/4024 0.182s 0.000s
im_detect: 2122/4024 0.182s 0.000s
im_detect: 2123/4024 0.182s 0.000s
im_detect: 2124/4024 0.182s 0.000s
im_detect: 2125/4024 0.182s 0.000s
im_detect: 2126/4024 0.182s 0.000s
im_detect: 2127/4024 0.182s 0.000s
im_detect: 2128/4024 0.182s 0.000s
im_detect: 2129/4024 0.182s 0.000s
im_detect: 2130/4024 0.182s 0.000s
im_detect: 2131/4024 0.182s 0.000s
im_detect: 2132/4024 0.182s 0.000s
im_detect: 2133/4024 0.182s 0.000s
im_detect: 2134/4024 0.182s 0.000s
im_detect: 2135/4024 0.182s 0.000s
im_detect: 2136/4024 0.182s 0.000s
im_detect: 2137/4024 0.182s 0.000s
im_detect: 2138/4024 0.182s 0.000s
im_detect: 2139/4024 0.182s 0.000s
im_detect: 2140/4024 0.182s 0.000s
im_detect: 2141/4024 0.182s 0.000s
im_detect: 2142/4024 0.182s 0.000s
im_detect: 2143/4024 0.182s 0.000s
im_detect: 2144/4024 0.182s 0.000s
im_detect: 2145/4024 0.182s 0.000s
im_detect: 2146/4024 0.182s 0.000s
im_detect: 2147/4024 0.182s 0.000s
im_detect: 2148/4024 0.182s 0.000s
im_detect: 2149/4024 0.182s 0.000s
im_detect: 2150/4024 0.182s 0.000s
im_detect: 2151/4024 0.182s 0.000s
im_detect: 2152/4024 0.182s 0.000s
im_detect: 2153/4024 0.182s 0.000s
im_detect: 2154/4024 0.182s 0.000s
im_detect: 2155/4024 0.182s 0.000s
im_detect: 2156/4024 0.182s 0.000s
im_detect: 2157/4024 0.182s 0.000s
im_detect: 2158/4024 0.182s 0.000s
im_detect: 2159/4024 0.182s 0.000s
im_detect: 2160/4024 0.182s 0.000s
im_detect: 2161/4024 0.182s 0.000s
im_detect: 2162/4024 0.182s 0.000s
im_detect: 2163/4024 0.182s 0.000s
im_detect: 2164/4024 0.182s 0.000s
im_detect: 2165/4024 0.182s 0.000s
im_detect: 2166/4024 0.182s 0.000s
im_detect: 2167/4024 0.182s 0.000s
im_detect: 2168/4024 0.182s 0.000s
im_detect: 2169/4024 0.182s 0.000s
im_detect: 2170/4024 0.182s 0.000s
im_detect: 2171/4024 0.182s 0.000s
im_detect: 2172/4024 0.182s 0.000s
im_detect: 2173/4024 0.182s 0.000s
im_detect: 2174/4024 0.182s 0.000s
im_detect: 2175/4024 0.182s 0.000s
im_detect: 2176/4024 0.182s 0.000s
im_detect: 2177/4024 0.182s 0.000s
im_detect: 2178/4024 0.182s 0.000s
im_detect: 2179/4024 0.182s 0.000s
im_detect: 2180/4024 0.182s 0.000s
im_detect: 2181/4024 0.182s 0.000s
im_detect: 2182/4024 0.182s 0.000s
im_detect: 2183/4024 0.182s 0.000s
im_detect: 2184/4024 0.182s 0.000s
im_detect: 2185/4024 0.182s 0.000s
im_detect: 2186/4024 0.182s 0.000s
im_detect: 2187/4024 0.182s 0.000s
im_detect: 2188/4024 0.182s 0.000s
im_detect: 2189/4024 0.182s 0.000s
im_detect: 2190/4024 0.182s 0.000s
im_detect: 2191/4024 0.182s 0.000s
im_detect: 2192/4024 0.182s 0.000s
im_detect: 2193/4024 0.182s 0.000s
im_detect: 2194/4024 0.182s 0.000s
im_detect: 2195/4024 0.182s 0.000s
im_detect: 2196/4024 0.182s 0.000s
im_detect: 2197/4024 0.182s 0.000s
im_detect: 2198/4024 0.182s 0.000s
im_detect: 2199/4024 0.182s 0.000s
im_detect: 2200/4024 0.182s 0.000s
im_detect: 2201/4024 0.182s 0.000s
im_detect: 2202/4024 0.182s 0.000s
im_detect: 2203/4024 0.182s 0.000s
im_detect: 2204/4024 0.182s 0.000s
im_detect: 2205/4024 0.182s 0.000s
im_detect: 2206/4024 0.182s 0.000s
im_detect: 2207/4024 0.182s 0.000s
im_detect: 2208/4024 0.182s 0.000s
im_detect: 2209/4024 0.182s 0.000s
im_detect: 2210/4024 0.182s 0.000s
im_detect: 2211/4024 0.182s 0.000s
im_detect: 2212/4024 0.182s 0.000s
im_detect: 2213/4024 0.182s 0.000s
im_detect: 2214/4024 0.182s 0.000s
im_detect: 2215/4024 0.182s 0.000s
im_detect: 2216/4024 0.182s 0.000s
im_detect: 2217/4024 0.182s 0.000s
im_detect: 2218/4024 0.182s 0.000s
im_detect: 2219/4024 0.182s 0.000s
im_detect: 2220/4024 0.182s 0.000s
im_detect: 2221/4024 0.182s 0.000s
im_detect: 2222/4024 0.182s 0.000s
im_detect: 2223/4024 0.182s 0.000s
im_detect: 2224/4024 0.182s 0.000s
im_detect: 2225/4024 0.182s 0.000s
im_detect: 2226/4024 0.182s 0.000s
im_detect: 2227/4024 0.182s 0.000s
im_detect: 2228/4024 0.182s 0.000s
im_detect: 2229/4024 0.182s 0.000s
im_detect: 2230/4024 0.182s 0.000s
im_detect: 2231/4024 0.182s 0.000s
im_detect: 2232/4024 0.182s 0.000s
im_detect: 2233/4024 0.182s 0.000s
im_detect: 2234/4024 0.182s 0.000s
im_detect: 2235/4024 0.182s 0.000s
im_detect: 2236/4024 0.182s 0.000s
im_detect: 2237/4024 0.182s 0.000s
im_detect: 2238/4024 0.182s 0.000s
im_detect: 2239/4024 0.182s 0.000s
im_detect: 2240/4024 0.182s 0.000s
im_detect: 2241/4024 0.182s 0.000s
im_detect: 2242/4024 0.182s 0.000s
im_detect: 2243/4024 0.182s 0.000s
im_detect: 2244/4024 0.182s 0.000s
im_detect: 2245/4024 0.182s 0.000s
im_detect: 2246/4024 0.182s 0.000s
im_detect: 2247/4024 0.182s 0.000s
im_detect: 2248/4024 0.182s 0.000s
im_detect: 2249/4024 0.182s 0.000s
im_detect: 2250/4024 0.182s 0.000s
im_detect: 2251/4024 0.182s 0.000s
im_detect: 2252/4024 0.182s 0.000s
im_detect: 2253/4024 0.182s 0.000s
im_detect: 2254/4024 0.182s 0.000s
im_detect: 2255/4024 0.182s 0.000s
im_detect: 2256/4024 0.182s 0.000s
im_detect: 2257/4024 0.182s 0.000s
im_detect: 2258/4024 0.182s 0.000s
im_detect: 2259/4024 0.182s 0.000s
im_detect: 2260/4024 0.182s 0.000s
im_detect: 2261/4024 0.182s 0.000s
im_detect: 2262/4024 0.182s 0.000s
im_detect: 2263/4024 0.182s 0.000s
im_detect: 2264/4024 0.182s 0.000s
im_detect: 2265/4024 0.182s 0.000s
im_detect: 2266/4024 0.182s 0.000s
im_detect: 2267/4024 0.182s 0.000s
im_detect: 2268/4024 0.182s 0.000s
im_detect: 2269/4024 0.182s 0.000s
im_detect: 2270/4024 0.182s 0.000s
im_detect: 2271/4024 0.182s 0.000s
im_detect: 2272/4024 0.182s 0.000s
im_detect: 2273/4024 0.182s 0.000s
im_detect: 2274/4024 0.182s 0.000s
im_detect: 2275/4024 0.182s 0.000s
im_detect: 2276/4024 0.182s 0.000s
im_detect: 2277/4024 0.182s 0.000s
im_detect: 2278/4024 0.182s 0.000s
im_detect: 2279/4024 0.182s 0.000s
im_detect: 2280/4024 0.182s 0.000s
im_detect: 2281/4024 0.182s 0.000s
im_detect: 2282/4024 0.182s 0.000s
im_detect: 2283/4024 0.182s 0.000s
im_detect: 2284/4024 0.182s 0.000s
im_detect: 2285/4024 0.182s 0.000s
im_detect: 2286/4024 0.182s 0.000s
im_detect: 2287/4024 0.182s 0.000s
im_detect: 2288/4024 0.182s 0.000s
im_detect: 2289/4024 0.182s 0.000s
im_detect: 2290/4024 0.182s 0.000s
im_detect: 2291/4024 0.182s 0.000s
im_detect: 2292/4024 0.182s 0.000s
im_detect: 2293/4024 0.182s 0.000s
im_detect: 2294/4024 0.182s 0.000s
im_detect: 2295/4024 0.182s 0.000s
im_detect: 2296/4024 0.182s 0.000s
im_detect: 2297/4024 0.182s 0.000s
im_detect: 2298/4024 0.182s 0.000s
im_detect: 2299/4024 0.182s 0.000s
im_detect: 2300/4024 0.182s 0.000s
im_detect: 2301/4024 0.182s 0.000s
im_detect: 2302/4024 0.182s 0.000s
im_detect: 2303/4024 0.182s 0.000s
im_detect: 2304/4024 0.182s 0.000s
im_detect: 2305/4024 0.182s 0.000s
im_detect: 2306/4024 0.182s 0.000s
im_detect: 2307/4024 0.182s 0.000s
im_detect: 2308/4024 0.182s 0.000s
im_detect: 2309/4024 0.182s 0.000s
im_detect: 2310/4024 0.182s 0.000s
im_detect: 2311/4024 0.182s 0.000s
im_detect: 2312/4024 0.182s 0.000s
im_detect: 2313/4024 0.182s 0.000s
im_detect: 2314/4024 0.182s 0.000s
im_detect: 2315/4024 0.182s 0.000s
im_detect: 2316/4024 0.182s 0.000s
im_detect: 2317/4024 0.182s 0.000s
im_detect: 2318/4024 0.182s 0.000s
im_detect: 2319/4024 0.182s 0.000s
im_detect: 2320/4024 0.182s 0.000s
im_detect: 2321/4024 0.182s 0.000s
im_detect: 2322/4024 0.182s 0.000s
im_detect: 2323/4024 0.182s 0.000s
im_detect: 2324/4024 0.182s 0.000s
im_detect: 2325/4024 0.182s 0.000s
im_detect: 2326/4024 0.182s 0.000s
im_detect: 2327/4024 0.182s 0.000s
im_detect: 2328/4024 0.182s 0.000s
im_detect: 2329/4024 0.182s 0.000s
im_detect: 2330/4024 0.182s 0.000s
im_detect: 2331/4024 0.182s 0.000s
im_detect: 2332/4024 0.182s 0.000s
im_detect: 2333/4024 0.182s 0.000s
im_detect: 2334/4024 0.182s 0.000s
im_detect: 2335/4024 0.182s 0.000s
im_detect: 2336/4024 0.182s 0.000s
im_detect: 2337/4024 0.182s 0.000s
im_detect: 2338/4024 0.182s 0.000s
im_detect: 2339/4024 0.182s 0.000s
im_detect: 2340/4024 0.182s 0.000s
im_detect: 2341/4024 0.182s 0.000s
im_detect: 2342/4024 0.182s 0.000s
im_detect: 2343/4024 0.182s 0.000s
im_detect: 2344/4024 0.182s 0.000s
im_detect: 2345/4024 0.182s 0.000s
im_detect: 2346/4024 0.182s 0.000s
im_detect: 2347/4024 0.182s 0.000s
im_detect: 2348/4024 0.182s 0.000s
im_detect: 2349/4024 0.182s 0.000s
im_detect: 2350/4024 0.182s 0.000s
im_detect: 2351/4024 0.182s 0.000s
im_detect: 2352/4024 0.182s 0.000s
im_detect: 2353/4024 0.182s 0.000s
im_detect: 2354/4024 0.182s 0.000s
im_detect: 2355/4024 0.182s 0.000s
im_detect: 2356/4024 0.182s 0.000s
im_detect: 2357/4024 0.182s 0.000s
im_detect: 2358/4024 0.182s 0.000s
im_detect: 2359/4024 0.182s 0.000s
im_detect: 2360/4024 0.182s 0.000s
im_detect: 2361/4024 0.182s 0.000s
im_detect: 2362/4024 0.182s 0.000s
im_detect: 2363/4024 0.182s 0.000s
im_detect: 2364/4024 0.182s 0.000s
im_detect: 2365/4024 0.182s 0.000s
im_detect: 2366/4024 0.182s 0.000s
im_detect: 2367/4024 0.182s 0.000s
im_detect: 2368/4024 0.182s 0.000s
im_detect: 2369/4024 0.182s 0.000s
im_detect: 2370/4024 0.182s 0.000s
im_detect: 2371/4024 0.182s 0.000s
im_detect: 2372/4024 0.182s 0.000s
im_detect: 2373/4024 0.182s 0.000s
im_detect: 2374/4024 0.182s 0.000s
im_detect: 2375/4024 0.182s 0.000s
im_detect: 2376/4024 0.182s 0.000s
im_detect: 2377/4024 0.182s 0.000s
im_detect: 2378/4024 0.182s 0.000s
im_detect: 2379/4024 0.182s 0.000s
im_detect: 2380/4024 0.182s 0.000s
im_detect: 2381/4024 0.182s 0.000s
im_detect: 2382/4024 0.182s 0.000s
im_detect: 2383/4024 0.182s 0.000s
im_detect: 2384/4024 0.182s 0.000s
im_detect: 2385/4024 0.182s 0.000s
im_detect: 2386/4024 0.182s 0.000s
im_detect: 2387/4024 0.182s 0.000s
im_detect: 2388/4024 0.182s 0.000s
im_detect: 2389/4024 0.182s 0.000s
im_detect: 2390/4024 0.182s 0.000s
im_detect: 2391/4024 0.182s 0.000s
im_detect: 2392/4024 0.182s 0.000s
im_detect: 2393/4024 0.182s 0.000s
im_detect: 2394/4024 0.182s 0.000s
im_detect: 2395/4024 0.182s 0.000s
im_detect: 2396/4024 0.182s 0.000s
im_detect: 2397/4024 0.182s 0.000s
im_detect: 2398/4024 0.182s 0.000s
im_detect: 2399/4024 0.182s 0.000s
im_detect: 2400/4024 0.182s 0.000s
im_detect: 2401/4024 0.182s 0.000s
im_detect: 2402/4024 0.182s 0.000s
im_detect: 2403/4024 0.182s 0.000s
im_detect: 2404/4024 0.182s 0.000s
im_detect: 2405/4024 0.182s 0.000s
im_detect: 2406/4024 0.182s 0.000s
im_detect: 2407/4024 0.182s 0.000s
im_detect: 2408/4024 0.182s 0.000s
im_detect: 2409/4024 0.182s 0.000s
im_detect: 2410/4024 0.182s 0.000s
im_detect: 2411/4024 0.182s 0.000s
im_detect: 2412/4024 0.182s 0.000s
im_detect: 2413/4024 0.182s 0.000s
im_detect: 2414/4024 0.182s 0.000s
im_detect: 2415/4024 0.182s 0.000s
im_detect: 2416/4024 0.182s 0.000s
im_detect: 2417/4024 0.182s 0.000s
im_detect: 2418/4024 0.182s 0.000s
im_detect: 2419/4024 0.182s 0.000s
im_detect: 2420/4024 0.182s 0.000s
im_detect: 2421/4024 0.182s 0.000s
im_detect: 2422/4024 0.182s 0.000s
im_detect: 2423/4024 0.182s 0.000s
im_detect: 2424/4024 0.182s 0.000s
im_detect: 2425/4024 0.182s 0.000s
im_detect: 2426/4024 0.182s 0.000s
im_detect: 2427/4024 0.182s 0.000s
im_detect: 2428/4024 0.182s 0.000s
im_detect: 2429/4024 0.182s 0.000s
im_detect: 2430/4024 0.182s 0.000s
im_detect: 2431/4024 0.182s 0.000s
im_detect: 2432/4024 0.182s 0.000s
im_detect: 2433/4024 0.182s 0.000s
im_detect: 2434/4024 0.182s 0.000s
im_detect: 2435/4024 0.182s 0.000s
im_detect: 2436/4024 0.182s 0.000s
im_detect: 2437/4024 0.182s 0.000s
im_detect: 2438/4024 0.182s 0.000s
im_detect: 2439/4024 0.182s 0.000s
im_detect: 2440/4024 0.182s 0.000s
im_detect: 2441/4024 0.182s 0.000s
im_detect: 2442/4024 0.182s 0.000s
im_detect: 2443/4024 0.182s 0.000s
im_detect: 2444/4024 0.182s 0.000s
im_detect: 2445/4024 0.182s 0.000s
im_detect: 2446/4024 0.182s 0.000s
im_detect: 2447/4024 0.182s 0.000s
im_detect: 2448/4024 0.182s 0.000s
im_detect: 2449/4024 0.182s 0.000s
im_detect: 2450/4024 0.182s 0.000s
im_detect: 2451/4024 0.182s 0.000s
im_detect: 2452/4024 0.182s 0.000s
im_detect: 2453/4024 0.182s 0.000s
im_detect: 2454/4024 0.182s 0.000s
im_detect: 2455/4024 0.182s 0.000s
im_detect: 2456/4024 0.182s 0.000s
im_detect: 2457/4024 0.182s 0.000s
im_detect: 2458/4024 0.182s 0.000s
im_detect: 2459/4024 0.182s 0.000s
im_detect: 2460/4024 0.182s 0.000s
im_detect: 2461/4024 0.182s 0.000s
im_detect: 2462/4024 0.182s 0.000s
im_detect: 2463/4024 0.182s 0.000s
im_detect: 2464/4024 0.182s 0.000s
im_detect: 2465/4024 0.182s 0.000s
im_detect: 2466/4024 0.182s 0.000s
im_detect: 2467/4024 0.182s 0.000s
im_detect: 2468/4024 0.182s 0.000s
im_detect: 2469/4024 0.182s 0.000s
im_detect: 2470/4024 0.182s 0.000s
im_detect: 2471/4024 0.182s 0.000s
im_detect: 2472/4024 0.182s 0.000s
im_detect: 2473/4024 0.182s 0.000s
im_detect: 2474/4024 0.182s 0.000s
im_detect: 2475/4024 0.182s 0.000s
im_detect: 2476/4024 0.182s 0.000s
im_detect: 2477/4024 0.182s 0.000s
im_detect: 2478/4024 0.182s 0.000s
im_detect: 2479/4024 0.182s 0.000s
im_detect: 2480/4024 0.182s 0.000s
im_detect: 2481/4024 0.182s 0.000s
im_detect: 2482/4024 0.182s 0.000s
im_detect: 2483/4024 0.182s 0.000s
im_detect: 2484/4024 0.182s 0.000s
im_detect: 2485/4024 0.182s 0.000s
im_detect: 2486/4024 0.182s 0.000s
im_detect: 2487/4024 0.182s 0.000s
im_detect: 2488/4024 0.182s 0.000s
im_detect: 2489/4024 0.182s 0.000s
im_detect: 2490/4024 0.182s 0.000s
im_detect: 2491/4024 0.182s 0.000s
im_detect: 2492/4024 0.182s 0.000s
im_detect: 2493/4024 0.182s 0.000s
im_detect: 2494/4024 0.182s 0.000s
im_detect: 2495/4024 0.182s 0.000s
im_detect: 2496/4024 0.182s 0.000s
im_detect: 2497/4024 0.182s 0.000s
im_detect: 2498/4024 0.182s 0.000s
im_detect: 2499/4024 0.182s 0.000s
im_detect: 2500/4024 0.182s 0.000s
im_detect: 2501/4024 0.182s 0.000s
im_detect: 2502/4024 0.182s 0.000s
im_detect: 2503/4024 0.182s 0.000s
im_detect: 2504/4024 0.182s 0.000s
im_detect: 2505/4024 0.182s 0.000s
im_detect: 2506/4024 0.182s 0.000s
im_detect: 2507/4024 0.182s 0.000s
im_detect: 2508/4024 0.182s 0.000s
im_detect: 2509/4024 0.182s 0.000s
im_detect: 2510/4024 0.182s 0.000s
im_detect: 2511/4024 0.182s 0.000s
im_detect: 2512/4024 0.182s 0.000s
im_detect: 2513/4024 0.182s 0.000s
im_detect: 2514/4024 0.182s 0.000s
im_detect: 2515/4024 0.182s 0.000s
im_detect: 2516/4024 0.182s 0.000s
im_detect: 2517/4024 0.182s 0.000s
im_detect: 2518/4024 0.182s 0.000s
im_detect: 2519/4024 0.182s 0.000s
im_detect: 2520/4024 0.182s 0.000s
im_detect: 2521/4024 0.182s 0.000s
im_detect: 2522/4024 0.182s 0.000s
im_detect: 2523/4024 0.182s 0.000s
im_detect: 2524/4024 0.182s 0.000s
im_detect: 2525/4024 0.182s 0.000s
im_detect: 2526/4024 0.182s 0.000s
im_detect: 2527/4024 0.182s 0.000s
im_detect: 2528/4024 0.182s 0.000s
im_detect: 2529/4024 0.182s 0.000s
im_detect: 2530/4024 0.182s 0.000s
im_detect: 2531/4024 0.182s 0.000s
im_detect: 2532/4024 0.182s 0.000s
im_detect: 2533/4024 0.182s 0.000s
im_detect: 2534/4024 0.182s 0.000s
im_detect: 2535/4024 0.182s 0.000s
im_detect: 2536/4024 0.182s 0.000s
im_detect: 2537/4024 0.182s 0.000s
im_detect: 2538/4024 0.182s 0.000s
im_detect: 2539/4024 0.182s 0.000s
im_detect: 2540/4024 0.182s 0.000s
im_detect: 2541/4024 0.182s 0.000s
im_detect: 2542/4024 0.182s 0.000s
im_detect: 2543/4024 0.182s 0.000s
im_detect: 2544/4024 0.182s 0.000s
im_detect: 2545/4024 0.182s 0.000s
im_detect: 2546/4024 0.182s 0.000s
im_detect: 2547/4024 0.182s 0.000s
im_detect: 2548/4024 0.182s 0.000s
im_detect: 2549/4024 0.182s 0.000s
im_detect: 2550/4024 0.182s 0.000s
im_detect: 2551/4024 0.182s 0.000s
im_detect: 2552/4024 0.182s 0.000s
im_detect: 2553/4024 0.182s 0.000s
im_detect: 2554/4024 0.182s 0.000s
im_detect: 2555/4024 0.182s 0.000s
im_detect: 2556/4024 0.182s 0.000s
im_detect: 2557/4024 0.182s 0.000s
im_detect: 2558/4024 0.182s 0.000s
im_detect: 2559/4024 0.182s 0.000s
im_detect: 2560/4024 0.182s 0.000s
im_detect: 2561/4024 0.182s 0.000s
im_detect: 2562/4024 0.182s 0.000s
im_detect: 2563/4024 0.182s 0.000s
im_detect: 2564/4024 0.182s 0.000s
im_detect: 2565/4024 0.182s 0.000s
im_detect: 2566/4024 0.182s 0.000s
im_detect: 2567/4024 0.182s 0.000s
im_detect: 2568/4024 0.182s 0.000s
im_detect: 2569/4024 0.182s 0.000s
im_detect: 2570/4024 0.182s 0.000s
im_detect: 2571/4024 0.182s 0.000s
im_detect: 2572/4024 0.182s 0.000s
im_detect: 2573/4024 0.182s 0.000s
im_detect: 2574/4024 0.182s 0.000s
im_detect: 2575/4024 0.182s 0.000s
im_detect: 2576/4024 0.182s 0.000s
im_detect: 2577/4024 0.182s 0.000s
im_detect: 2578/4024 0.182s 0.000s
im_detect: 2579/4024 0.182s 0.000s
im_detect: 2580/4024 0.182s 0.000s
im_detect: 2581/4024 0.182s 0.000s
im_detect: 2582/4024 0.182s 0.000s
im_detect: 2583/4024 0.182s 0.000s
im_detect: 2584/4024 0.182s 0.000s
im_detect: 2585/4024 0.182s 0.000s
im_detect: 2586/4024 0.182s 0.000s
im_detect: 2587/4024 0.182s 0.000s
im_detect: 2588/4024 0.182s 0.000s
im_detect: 2589/4024 0.182s 0.000s
im_detect: 2590/4024 0.182s 0.000s
im_detect: 2591/4024 0.182s 0.000s
im_detect: 2592/4024 0.182s 0.000s
im_detect: 2593/4024 0.182s 0.000s
im_detect: 2594/4024 0.182s 0.000s
im_detect: 2595/4024 0.182s 0.000s
im_detect: 2596/4024 0.182s 0.000s
im_detect: 2597/4024 0.182s 0.000s
im_detect: 2598/4024 0.182s 0.000s
im_detect: 2599/4024 0.182s 0.000s
im_detect: 2600/4024 0.182s 0.000s
im_detect: 2601/4024 0.182s 0.000s
im_detect: 2602/4024 0.182s 0.000s
im_detect: 2603/4024 0.182s 0.000s
im_detect: 2604/4024 0.182s 0.000s
im_detect: 2605/4024 0.182s 0.000s
im_detect: 2606/4024 0.182s 0.000s
im_detect: 2607/4024 0.182s 0.000s
im_detect: 2608/4024 0.182s 0.000s
im_detect: 2609/4024 0.182s 0.000s
im_detect: 2610/4024 0.182s 0.000s
im_detect: 2611/4024 0.182s 0.000s
im_detect: 2612/4024 0.182s 0.000s
im_detect: 2613/4024 0.182s 0.000s
im_detect: 2614/4024 0.182s 0.000s
im_detect: 2615/4024 0.182s 0.000s
im_detect: 2616/4024 0.182s 0.000s
im_detect: 2617/4024 0.182s 0.000s
im_detect: 2618/4024 0.182s 0.000s
im_detect: 2619/4024 0.182s 0.000s
im_detect: 2620/4024 0.182s 0.000s
im_detect: 2621/4024 0.182s 0.000s
im_detect: 2622/4024 0.182s 0.000s
im_detect: 2623/4024 0.182s 0.000s
im_detect: 2624/4024 0.182s 0.000s
im_detect: 2625/4024 0.182s 0.000s
im_detect: 2626/4024 0.182s 0.000s
im_detect: 2627/4024 0.182s 0.000s
im_detect: 2628/4024 0.182s 0.000s
im_detect: 2629/4024 0.182s 0.000s
im_detect: 2630/4024 0.182s 0.000s
im_detect: 2631/4024 0.182s 0.000s
im_detect: 2632/4024 0.182s 0.000s
im_detect: 2633/4024 0.182s 0.000s
im_detect: 2634/4024 0.182s 0.000s
im_detect: 2635/4024 0.182s 0.000s
im_detect: 2636/4024 0.182s 0.000s
im_detect: 2637/4024 0.182s 0.000s
im_detect: 2638/4024 0.182s 0.000s
im_detect: 2639/4024 0.182s 0.000s
im_detect: 2640/4024 0.182s 0.000s
im_detect: 2641/4024 0.182s 0.000s
im_detect: 2642/4024 0.182s 0.000s
im_detect: 2643/4024 0.182s 0.000s
im_detect: 2644/4024 0.182s 0.000s
im_detect: 2645/4024 0.182s 0.000s
im_detect: 2646/4024 0.182s 0.000s
im_detect: 2647/4024 0.182s 0.000s
im_detect: 2648/4024 0.182s 0.000s
im_detect: 2649/4024 0.182s 0.000s
im_detect: 2650/4024 0.182s 0.000s
im_detect: 2651/4024 0.182s 0.000s
im_detect: 2652/4024 0.182s 0.000s
im_detect: 2653/4024 0.182s 0.000s
im_detect: 2654/4024 0.182s 0.000s
im_detect: 2655/4024 0.182s 0.000s
im_detect: 2656/4024 0.182s 0.000s
im_detect: 2657/4024 0.182s 0.000s
im_detect: 2658/4024 0.182s 0.000s
im_detect: 2659/4024 0.182s 0.000s
im_detect: 2660/4024 0.182s 0.000s
im_detect: 2661/4024 0.182s 0.000s
im_detect: 2662/4024 0.182s 0.000s
im_detect: 2663/4024 0.182s 0.000s
im_detect: 2664/4024 0.182s 0.000s
im_detect: 2665/4024 0.182s 0.000s
im_detect: 2666/4024 0.182s 0.000s
im_detect: 2667/4024 0.182s 0.000s
im_detect: 2668/4024 0.182s 0.000s
im_detect: 2669/4024 0.182s 0.000s
im_detect: 2670/4024 0.182s 0.000s
im_detect: 2671/4024 0.182s 0.000s
im_detect: 2672/4024 0.182s 0.000s
im_detect: 2673/4024 0.182s 0.000s
im_detect: 2674/4024 0.182s 0.000s
im_detect: 2675/4024 0.182s 0.000s
im_detect: 2676/4024 0.182s 0.000s
im_detect: 2677/4024 0.182s 0.000s
im_detect: 2678/4024 0.182s 0.000s
im_detect: 2679/4024 0.182s 0.000s
im_detect: 2680/4024 0.182s 0.000s
im_detect: 2681/4024 0.182s 0.000s
im_detect: 2682/4024 0.182s 0.000s
im_detect: 2683/4024 0.182s 0.000s
im_detect: 2684/4024 0.182s 0.000s
im_detect: 2685/4024 0.182s 0.000s
im_detect: 2686/4024 0.182s 0.000s
im_detect: 2687/4024 0.182s 0.000s
im_detect: 2688/4024 0.182s 0.000s
im_detect: 2689/4024 0.182s 0.000s
im_detect: 2690/4024 0.182s 0.000s
im_detect: 2691/4024 0.182s 0.000s
im_detect: 2692/4024 0.182s 0.000s
im_detect: 2693/4024 0.182s 0.000s
im_detect: 2694/4024 0.182s 0.000s
im_detect: 2695/4024 0.182s 0.000s
im_detect: 2696/4024 0.182s 0.000s
im_detect: 2697/4024 0.182s 0.000s
im_detect: 2698/4024 0.182s 0.000s
im_detect: 2699/4024 0.182s 0.000s
im_detect: 2700/4024 0.182s 0.000s
im_detect: 2701/4024 0.182s 0.000s
im_detect: 2702/4024 0.182s 0.000s
im_detect: 2703/4024 0.182s 0.000s
im_detect: 2704/4024 0.182s 0.000s
im_detect: 2705/4024 0.182s 0.000s
im_detect: 2706/4024 0.182s 0.000s
im_detect: 2707/4024 0.182s 0.000s
im_detect: 2708/4024 0.182s 0.000s
im_detect: 2709/4024 0.182s 0.000s
im_detect: 2710/4024 0.182s 0.000s
im_detect: 2711/4024 0.182s 0.000s
im_detect: 2712/4024 0.182s 0.000s
im_detect: 2713/4024 0.182s 0.000s
im_detect: 2714/4024 0.182s 0.000s
im_detect: 2715/4024 0.182s 0.000s
im_detect: 2716/4024 0.182s 0.000s
im_detect: 2717/4024 0.182s 0.000s
im_detect: 2718/4024 0.182s 0.000s
im_detect: 2719/4024 0.182s 0.000s
im_detect: 2720/4024 0.182s 0.000s
im_detect: 2721/4024 0.182s 0.000s
im_detect: 2722/4024 0.182s 0.000s
im_detect: 2723/4024 0.182s 0.000s
im_detect: 2724/4024 0.182s 0.000s
im_detect: 2725/4024 0.182s 0.000s
im_detect: 2726/4024 0.182s 0.000s
im_detect: 2727/4024 0.182s 0.000s
im_detect: 2728/4024 0.182s 0.000s
im_detect: 2729/4024 0.182s 0.000s
im_detect: 2730/4024 0.182s 0.000s
im_detect: 2731/4024 0.182s 0.000s
im_detect: 2732/4024 0.182s 0.000s
im_detect: 2733/4024 0.182s 0.000s
im_detect: 2734/4024 0.182s 0.000s
im_detect: 2735/4024 0.182s 0.000s
im_detect: 2736/4024 0.182s 0.000s
im_detect: 2737/4024 0.182s 0.000s
im_detect: 2738/4024 0.182s 0.000s
im_detect: 2739/4024 0.182s 0.000s
im_detect: 2740/4024 0.182s 0.000s
im_detect: 2741/4024 0.182s 0.000s
im_detect: 2742/4024 0.182s 0.000s
im_detect: 2743/4024 0.182s 0.000s
im_detect: 2744/4024 0.182s 0.000s
im_detect: 2745/4024 0.182s 0.000s
im_detect: 2746/4024 0.182s 0.000s
im_detect: 2747/4024 0.182s 0.000s
im_detect: 2748/4024 0.182s 0.000s
im_detect: 2749/4024 0.182s 0.000s
im_detect: 2750/4024 0.182s 0.000s
im_detect: 2751/4024 0.182s 0.000s
im_detect: 2752/4024 0.182s 0.000s
im_detect: 2753/4024 0.182s 0.000s
im_detect: 2754/4024 0.182s 0.000s
im_detect: 2755/4024 0.182s 0.000s
im_detect: 2756/4024 0.182s 0.000s
im_detect: 2757/4024 0.182s 0.000s
im_detect: 2758/4024 0.182s 0.000s
im_detect: 2759/4024 0.182s 0.000s
im_detect: 2760/4024 0.182s 0.000s
im_detect: 2761/4024 0.182s 0.000s
im_detect: 2762/4024 0.182s 0.000s
im_detect: 2763/4024 0.182s 0.000s
im_detect: 2764/4024 0.182s 0.000s
im_detect: 2765/4024 0.182s 0.000s
im_detect: 2766/4024 0.182s 0.000s
im_detect: 2767/4024 0.182s 0.000s
im_detect: 2768/4024 0.182s 0.000s
im_detect: 2769/4024 0.182s 0.000s
im_detect: 2770/4024 0.182s 0.000s
im_detect: 2771/4024 0.182s 0.000s
im_detect: 2772/4024 0.182s 0.000s
im_detect: 2773/4024 0.182s 0.000s
im_detect: 2774/4024 0.182s 0.000s
im_detect: 2775/4024 0.182s 0.000s
im_detect: 2776/4024 0.182s 0.000s
im_detect: 2777/4024 0.182s 0.000s
im_detect: 2778/4024 0.182s 0.000s
im_detect: 2779/4024 0.182s 0.000s
im_detect: 2780/4024 0.182s 0.000s
im_detect: 2781/4024 0.182s 0.000s
im_detect: 2782/4024 0.182s 0.000s
im_detect: 2783/4024 0.182s 0.000s
im_detect: 2784/4024 0.182s 0.000s
im_detect: 2785/4024 0.182s 0.000s
im_detect: 2786/4024 0.182s 0.000s
im_detect: 2787/4024 0.182s 0.000s
im_detect: 2788/4024 0.182s 0.000s
im_detect: 2789/4024 0.182s 0.000s
im_detect: 2790/4024 0.182s 0.000s
im_detect: 2791/4024 0.182s 0.000s
im_detect: 2792/4024 0.182s 0.000s
im_detect: 2793/4024 0.182s 0.000s
im_detect: 2794/4024 0.182s 0.000s
im_detect: 2795/4024 0.182s 0.000s
im_detect: 2796/4024 0.182s 0.000s
im_detect: 2797/4024 0.182s 0.000s
im_detect: 2798/4024 0.182s 0.000s
im_detect: 2799/4024 0.182s 0.000s
im_detect: 2800/4024 0.182s 0.000s
im_detect: 2801/4024 0.182s 0.000s
im_detect: 2802/4024 0.182s 0.000s
im_detect: 2803/4024 0.182s 0.000s
im_detect: 2804/4024 0.182s 0.000s
im_detect: 2805/4024 0.182s 0.000s
im_detect: 2806/4024 0.182s 0.000s
im_detect: 2807/4024 0.182s 0.000s
im_detect: 2808/4024 0.182s 0.000s
im_detect: 2809/4024 0.182s 0.000s
im_detect: 2810/4024 0.182s 0.000s
im_detect: 2811/4024 0.182s 0.000s
im_detect: 2812/4024 0.182s 0.000s
im_detect: 2813/4024 0.182s 0.000s
im_detect: 2814/4024 0.182s 0.000s
im_detect: 2815/4024 0.182s 0.000s
im_detect: 2816/4024 0.182s 0.000s
im_detect: 2817/4024 0.182s 0.000s
im_detect: 2818/4024 0.182s 0.000s
im_detect: 2819/4024 0.182s 0.000s
im_detect: 2820/4024 0.182s 0.000s
im_detect: 2821/4024 0.182s 0.000s
im_detect: 2822/4024 0.182s 0.000s
im_detect: 2823/4024 0.182s 0.000s
im_detect: 2824/4024 0.182s 0.000s
im_detect: 2825/4024 0.182s 0.000s
im_detect: 2826/4024 0.182s 0.000s
im_detect: 2827/4024 0.182s 0.000s
im_detect: 2828/4024 0.182s 0.000s
im_detect: 2829/4024 0.182s 0.000s
im_detect: 2830/4024 0.182s 0.000s
im_detect: 2831/4024 0.182s 0.000s
im_detect: 2832/4024 0.182s 0.000s
im_detect: 2833/4024 0.182s 0.000s
im_detect: 2834/4024 0.182s 0.000s
im_detect: 2835/4024 0.182s 0.000s
im_detect: 2836/4024 0.182s 0.000s
im_detect: 2837/4024 0.182s 0.000s
im_detect: 2838/4024 0.182s 0.000s
im_detect: 2839/4024 0.182s 0.000s
im_detect: 2840/4024 0.182s 0.000s
im_detect: 2841/4024 0.182s 0.000s
im_detect: 2842/4024 0.182s 0.000s
im_detect: 2843/4024 0.182s 0.000s
im_detect: 2844/4024 0.182s 0.000s
im_detect: 2845/4024 0.182s 0.000s
im_detect: 2846/4024 0.182s 0.000s
im_detect: 2847/4024 0.182s 0.000s
im_detect: 2848/4024 0.182s 0.000s
im_detect: 2849/4024 0.182s 0.000s
im_detect: 2850/4024 0.182s 0.000s
im_detect: 2851/4024 0.182s 0.000s
im_detect: 2852/4024 0.182s 0.000s
im_detect: 2853/4024 0.182s 0.000s
im_detect: 2854/4024 0.182s 0.000s
im_detect: 2855/4024 0.182s 0.000s
im_detect: 2856/4024 0.182s 0.000s
im_detect: 2857/4024 0.182s 0.000s
im_detect: 2858/4024 0.182s 0.000s
im_detect: 2859/4024 0.182s 0.000s
im_detect: 2860/4024 0.182s 0.000s
im_detect: 2861/4024 0.182s 0.000s
im_detect: 2862/4024 0.182s 0.000s
im_detect: 2863/4024 0.182s 0.000s
im_detect: 2864/4024 0.182s 0.000s
im_detect: 2865/4024 0.182s 0.000s
im_detect: 2866/4024 0.182s 0.000s
im_detect: 2867/4024 0.182s 0.000s
im_detect: 2868/4024 0.182s 0.000s
im_detect: 2869/4024 0.182s 0.000s
im_detect: 2870/4024 0.182s 0.000s
im_detect: 2871/4024 0.182s 0.000s
im_detect: 2872/4024 0.182s 0.000s
im_detect: 2873/4024 0.182s 0.000s
im_detect: 2874/4024 0.182s 0.000s
im_detect: 2875/4024 0.182s 0.000s
im_detect: 2876/4024 0.182s 0.000s
im_detect: 2877/4024 0.182s 0.000s
im_detect: 2878/4024 0.182s 0.000s
im_detect: 2879/4024 0.182s 0.000s
im_detect: 2880/4024 0.182s 0.000s
im_detect: 2881/4024 0.182s 0.000s
im_detect: 2882/4024 0.182s 0.000s
im_detect: 2883/4024 0.182s 0.000s
im_detect: 2884/4024 0.182s 0.000s
im_detect: 2885/4024 0.182s 0.000s
im_detect: 2886/4024 0.182s 0.000s
im_detect: 2887/4024 0.182s 0.000s
im_detect: 2888/4024 0.182s 0.000s
im_detect: 2889/4024 0.182s 0.000s
im_detect: 2890/4024 0.182s 0.000s
im_detect: 2891/4024 0.182s 0.000s
im_detect: 2892/4024 0.182s 0.000s
im_detect: 2893/4024 0.182s 0.000s
im_detect: 2894/4024 0.182s 0.000s
im_detect: 2895/4024 0.182s 0.000s
im_detect: 2896/4024 0.182s 0.000s
im_detect: 2897/4024 0.182s 0.000s
im_detect: 2898/4024 0.182s 0.000s
im_detect: 2899/4024 0.182s 0.000s
im_detect: 2900/4024 0.182s 0.000s
im_detect: 2901/4024 0.182s 0.000s
im_detect: 2902/4024 0.182s 0.000s
im_detect: 2903/4024 0.182s 0.000s
im_detect: 2904/4024 0.182s 0.000s
im_detect: 2905/4024 0.182s 0.000s
im_detect: 2906/4024 0.182s 0.000s
im_detect: 2907/4024 0.182s 0.000s
im_detect: 2908/4024 0.182s 0.000s
im_detect: 2909/4024 0.182s 0.000s
im_detect: 2910/4024 0.182s 0.000s
im_detect: 2911/4024 0.182s 0.000s
im_detect: 2912/4024 0.182s 0.000s
im_detect: 2913/4024 0.182s 0.000s
im_detect: 2914/4024 0.182s 0.000s
im_detect: 2915/4024 0.182s 0.000s
im_detect: 2916/4024 0.182s 0.000s
im_detect: 2917/4024 0.182s 0.000s
im_detect: 2918/4024 0.182s 0.000s
im_detect: 2919/4024 0.182s 0.000s
im_detect: 2920/4024 0.182s 0.000s
im_detect: 2921/4024 0.182s 0.000s
im_detect: 2922/4024 0.182s 0.000s
im_detect: 2923/4024 0.182s 0.000s
im_detect: 2924/4024 0.182s 0.000s
im_detect: 2925/4024 0.182s 0.000s
im_detect: 2926/4024 0.182s 0.000s
im_detect: 2927/4024 0.182s 0.000s
im_detect: 2928/4024 0.182s 0.000s
im_detect: 2929/4024 0.182s 0.000s
im_detect: 2930/4024 0.182s 0.000s
im_detect: 2931/4024 0.182s 0.000s
im_detect: 2932/4024 0.182s 0.000s
im_detect: 2933/4024 0.182s 0.000s
im_detect: 2934/4024 0.182s 0.000s
im_detect: 2935/4024 0.182s 0.000s
im_detect: 2936/4024 0.182s 0.000s
im_detect: 2937/4024 0.182s 0.000s
im_detect: 2938/4024 0.182s 0.000s
im_detect: 2939/4024 0.182s 0.000s
im_detect: 2940/4024 0.182s 0.000s
im_detect: 2941/4024 0.182s 0.000s
im_detect: 2942/4024 0.182s 0.000s
im_detect: 2943/4024 0.182s 0.000s
im_detect: 2944/4024 0.182s 0.000s
im_detect: 2945/4024 0.182s 0.000s
im_detect: 2946/4024 0.182s 0.000s
im_detect: 2947/4024 0.182s 0.000s
im_detect: 2948/4024 0.182s 0.000s
im_detect: 2949/4024 0.182s 0.000s
im_detect: 2950/4024 0.182s 0.000s
im_detect: 2951/4024 0.182s 0.000s
im_detect: 2952/4024 0.182s 0.000s
im_detect: 2953/4024 0.182s 0.000s
im_detect: 2954/4024 0.182s 0.000s
im_detect: 2955/4024 0.182s 0.000s
im_detect: 2956/4024 0.182s 0.000s
im_detect: 2957/4024 0.182s 0.000s
im_detect: 2958/4024 0.182s 0.000s
im_detect: 2959/4024 0.182s 0.000s
im_detect: 2960/4024 0.182s 0.000s
im_detect: 2961/4024 0.182s 0.000s
im_detect: 2962/4024 0.182s 0.000s
im_detect: 2963/4024 0.182s 0.000s
im_detect: 2964/4024 0.182s 0.000s
im_detect: 2965/4024 0.182s 0.000s
im_detect: 2966/4024 0.182s 0.000s
im_detect: 2967/4024 0.182s 0.000s
im_detect: 2968/4024 0.182s 0.000s
im_detect: 2969/4024 0.182s 0.000s
im_detect: 2970/4024 0.182s 0.000s
im_detect: 2971/4024 0.182s 0.000s
im_detect: 2972/4024 0.182s 0.000s
im_detect: 2973/4024 0.182s 0.000s
im_detect: 2974/4024 0.182s 0.000s
im_detect: 2975/4024 0.182s 0.000s
im_detect: 2976/4024 0.182s 0.000s
im_detect: 2977/4024 0.182s 0.000s
im_detect: 2978/4024 0.182s 0.000s
im_detect: 2979/4024 0.182s 0.000s
im_detect: 2980/4024 0.182s 0.000s
im_detect: 2981/4024 0.182s 0.000s
im_detect: 2982/4024 0.182s 0.000s
im_detect: 2983/4024 0.182s 0.000s
im_detect: 2984/4024 0.182s 0.000s
im_detect: 2985/4024 0.182s 0.000s
im_detect: 2986/4024 0.182s 0.000s
im_detect: 2987/4024 0.182s 0.000s
im_detect: 2988/4024 0.182s 0.000s
im_detect: 2989/4024 0.182s 0.000s
im_detect: 2990/4024 0.182s 0.000s
im_detect: 2991/4024 0.182s 0.000s
im_detect: 2992/4024 0.182s 0.000s
im_detect: 2993/4024 0.182s 0.000s
im_detect: 2994/4024 0.182s 0.000s
im_detect: 2995/4024 0.182s 0.000s
im_detect: 2996/4024 0.182s 0.000s
im_detect: 2997/4024 0.182s 0.000s
im_detect: 2998/4024 0.182s 0.000s
im_detect: 2999/4024 0.182s 0.000s
im_detect: 3000/4024 0.182s 0.000s
im_detect: 3001/4024 0.182s 0.000s
im_detect: 3002/4024 0.182s 0.000s
im_detect: 3003/4024 0.182s 0.000s
im_detect: 3004/4024 0.182s 0.000s
im_detect: 3005/4024 0.182s 0.000s
im_detect: 3006/4024 0.182s 0.000s
im_detect: 3007/4024 0.182s 0.000s
im_detect: 3008/4024 0.182s 0.000s
im_detect: 3009/4024 0.182s 0.000s
im_detect: 3010/4024 0.182s 0.000s
im_detect: 3011/4024 0.182s 0.000s
im_detect: 3012/4024 0.182s 0.000s
im_detect: 3013/4024 0.182s 0.000s
im_detect: 3014/4024 0.182s 0.000s
im_detect: 3015/4024 0.182s 0.000s
im_detect: 3016/4024 0.182s 0.000s
im_detect: 3017/4024 0.182s 0.000s
im_detect: 3018/4024 0.182s 0.000s
im_detect: 3019/4024 0.182s 0.000s
im_detect: 3020/4024 0.182s 0.000s
im_detect: 3021/4024 0.182s 0.000s
im_detect: 3022/4024 0.182s 0.000s
im_detect: 3023/4024 0.182s 0.000s
im_detect: 3024/4024 0.182s 0.000s
im_detect: 3025/4024 0.182s 0.000s
im_detect: 3026/4024 0.182s 0.000s
im_detect: 3027/4024 0.182s 0.000s
im_detect: 3028/4024 0.182s 0.000s
im_detect: 3029/4024 0.182s 0.000s
im_detect: 3030/4024 0.182s 0.000s
im_detect: 3031/4024 0.182s 0.000s
im_detect: 3032/4024 0.182s 0.000s
im_detect: 3033/4024 0.182s 0.000s
im_detect: 3034/4024 0.182s 0.000s
im_detect: 3035/4024 0.182s 0.000s
im_detect: 3036/4024 0.182s 0.000s
im_detect: 3037/4024 0.182s 0.000s
im_detect: 3038/4024 0.182s 0.000s
im_detect: 3039/4024 0.182s 0.000s
im_detect: 3040/4024 0.182s 0.000s
im_detect: 3041/4024 0.182s 0.000s
im_detect: 3042/4024 0.182s 0.000s
im_detect: 3043/4024 0.182s 0.000s
im_detect: 3044/4024 0.182s 0.000s
im_detect: 3045/4024 0.182s 0.000s
im_detect: 3046/4024 0.182s 0.000s
im_detect: 3047/4024 0.182s 0.000s
im_detect: 3048/4024 0.182s 0.000s
im_detect: 3049/4024 0.182s 0.000s
im_detect: 3050/4024 0.182s 0.000s
im_detect: 3051/4024 0.182s 0.000s
im_detect: 3052/4024 0.182s 0.000s
im_detect: 3053/4024 0.182s 0.000s
im_detect: 3054/4024 0.182s 0.000s
im_detect: 3055/4024 0.182s 0.000s
im_detect: 3056/4024 0.182s 0.000s
im_detect: 3057/4024 0.182s 0.000s
im_detect: 3058/4024 0.182s 0.000s
im_detect: 3059/4024 0.182s 0.000s
im_detect: 3060/4024 0.182s 0.000s
im_detect: 3061/4024 0.182s 0.000s
im_detect: 3062/4024 0.182s 0.000s
im_detect: 3063/4024 0.182s 0.000s
im_detect: 3064/4024 0.182s 0.000s
im_detect: 3065/4024 0.182s 0.000s
im_detect: 3066/4024 0.182s 0.000s
im_detect: 3067/4024 0.182s 0.000s
im_detect: 3068/4024 0.182s 0.000s
im_detect: 3069/4024 0.182s 0.000s
im_detect: 3070/4024 0.182s 0.000s
im_detect: 3071/4024 0.182s 0.000s
im_detect: 3072/4024 0.182s 0.000s
im_detect: 3073/4024 0.182s 0.000s
im_detect: 3074/4024 0.182s 0.000s
im_detect: 3075/4024 0.182s 0.000s
im_detect: 3076/4024 0.182s 0.000s
im_detect: 3077/4024 0.182s 0.000s
im_detect: 3078/4024 0.182s 0.000s
im_detect: 3079/4024 0.182s 0.000s
im_detect: 3080/4024 0.182s 0.000s
im_detect: 3081/4024 0.182s 0.000s
im_detect: 3082/4024 0.182s 0.000s
im_detect: 3083/4024 0.182s 0.000s
im_detect: 3084/4024 0.182s 0.000s
im_detect: 3085/4024 0.182s 0.000s
im_detect: 3086/4024 0.182s 0.000s
im_detect: 3087/4024 0.182s 0.000s
im_detect: 3088/4024 0.182s 0.000s
im_detect: 3089/4024 0.182s 0.000s
im_detect: 3090/4024 0.182s 0.000s
im_detect: 3091/4024 0.182s 0.000s
im_detect: 3092/4024 0.182s 0.000s
im_detect: 3093/4024 0.182s 0.000s
im_detect: 3094/4024 0.182s 0.000s
im_detect: 3095/4024 0.182s 0.000s
im_detect: 3096/4024 0.182s 0.000s
im_detect: 3097/4024 0.182s 0.000s
im_detect: 3098/4024 0.182s 0.000s
im_detect: 3099/4024 0.182s 0.000s
im_detect: 3100/4024 0.182s 0.000s
im_detect: 3101/4024 0.182s 0.000s
im_detect: 3102/4024 0.182s 0.000s
im_detect: 3103/4024 0.182s 0.000s
im_detect: 3104/4024 0.182s 0.000s
im_detect: 3105/4024 0.182s 0.000s
im_detect: 3106/4024 0.182s 0.000s
im_detect: 3107/4024 0.182s 0.000s
im_detect: 3108/4024 0.182s 0.000s
im_detect: 3109/4024 0.182s 0.000s
im_detect: 3110/4024 0.182s 0.000s
im_detect: 3111/4024 0.182s 0.000s
im_detect: 3112/4024 0.182s 0.000s
im_detect: 3113/4024 0.182s 0.000s
im_detect: 3114/4024 0.182s 0.000s
im_detect: 3115/4024 0.182s 0.000s
im_detect: 3116/4024 0.182s 0.000s
im_detect: 3117/4024 0.182s 0.000s
im_detect: 3118/4024 0.182s 0.000s
im_detect: 3119/4024 0.182s 0.000s
im_detect: 3120/4024 0.182s 0.000s
im_detect: 3121/4024 0.182s 0.000s
im_detect: 3122/4024 0.182s 0.000s
im_detect: 3123/4024 0.182s 0.000s
im_detect: 3124/4024 0.182s 0.000s
im_detect: 3125/4024 0.182s 0.000s
im_detect: 3126/4024 0.182s 0.000s
im_detect: 3127/4024 0.182s 0.000s
im_detect: 3128/4024 0.182s 0.000s
im_detect: 3129/4024 0.182s 0.000s
im_detect: 3130/4024 0.182s 0.000s
im_detect: 3131/4024 0.182s 0.000s
im_detect: 3132/4024 0.182s 0.000s
im_detect: 3133/4024 0.182s 0.000s
im_detect: 3134/4024 0.182s 0.000s
im_detect: 3135/4024 0.182s 0.000s
im_detect: 3136/4024 0.182s 0.000s
im_detect: 3137/4024 0.182s 0.000s
im_detect: 3138/4024 0.182s 0.000s
im_detect: 3139/4024 0.182s 0.000s
im_detect: 3140/4024 0.182s 0.000s
im_detect: 3141/4024 0.182s 0.000s
im_detect: 3142/4024 0.182s 0.000s
im_detect: 3143/4024 0.182s 0.000s
im_detect: 3144/4024 0.182s 0.000s
im_detect: 3145/4024 0.182s 0.000s
im_detect: 3146/4024 0.182s 0.000s
im_detect: 3147/4024 0.182s 0.000s
im_detect: 3148/4024 0.182s 0.000s
im_detect: 3149/4024 0.182s 0.000s
im_detect: 3150/4024 0.182s 0.000s
im_detect: 3151/4024 0.182s 0.000s
im_detect: 3152/4024 0.182s 0.000s
im_detect: 3153/4024 0.182s 0.000s
im_detect: 3154/4024 0.182s 0.000s
im_detect: 3155/4024 0.182s 0.000s
im_detect: 3156/4024 0.182s 0.000s
im_detect: 3157/4024 0.182s 0.000s
im_detect: 3158/4024 0.182s 0.000s
im_detect: 3159/4024 0.182s 0.000s
im_detect: 3160/4024 0.182s 0.000s
im_detect: 3161/4024 0.182s 0.000s
im_detect: 3162/4024 0.182s 0.000s
im_detect: 3163/4024 0.182s 0.000s
im_detect: 3164/4024 0.182s 0.000s
im_detect: 3165/4024 0.182s 0.000s
im_detect: 3166/4024 0.182s 0.000s
im_detect: 3167/4024 0.182s 0.000s
im_detect: 3168/4024 0.182s 0.000s
im_detect: 3169/4024 0.182s 0.000s
im_detect: 3170/4024 0.182s 0.000s
im_detect: 3171/4024 0.182s 0.000s
im_detect: 3172/4024 0.182s 0.000s
im_detect: 3173/4024 0.182s 0.000s
im_detect: 3174/4024 0.182s 0.000s
im_detect: 3175/4024 0.182s 0.000s
im_detect: 3176/4024 0.182s 0.000s
im_detect: 3177/4024 0.182s 0.000s
im_detect: 3178/4024 0.182s 0.000s
im_detect: 3179/4024 0.182s 0.000s
im_detect: 3180/4024 0.182s 0.000s
im_detect: 3181/4024 0.182s 0.000s
im_detect: 3182/4024 0.182s 0.000s
im_detect: 3183/4024 0.182s 0.000s
im_detect: 3184/4024 0.182s 0.000s
im_detect: 3185/4024 0.182s 0.000s
im_detect: 3186/4024 0.182s 0.000s
im_detect: 3187/4024 0.182s 0.000s
im_detect: 3188/4024 0.182s 0.000s
im_detect: 3189/4024 0.182s 0.000s
im_detect: 3190/4024 0.182s 0.000s
im_detect: 3191/4024 0.182s 0.000s
im_detect: 3192/4024 0.182s 0.000s
im_detect: 3193/4024 0.182s 0.000s
im_detect: 3194/4024 0.182s 0.000s
im_detect: 3195/4024 0.182s 0.000s
im_detect: 3196/4024 0.182s 0.000s
im_detect: 3197/4024 0.182s 0.000s
im_detect: 3198/4024 0.182s 0.000s
im_detect: 3199/4024 0.182s 0.000s
im_detect: 3200/4024 0.182s 0.000s
im_detect: 3201/4024 0.182s 0.000s
im_detect: 3202/4024 0.182s 0.000s
im_detect: 3203/4024 0.182s 0.000s
im_detect: 3204/4024 0.182s 0.000s
im_detect: 3205/4024 0.182s 0.000s
im_detect: 3206/4024 0.182s 0.000s
im_detect: 3207/4024 0.182s 0.000s
im_detect: 3208/4024 0.182s 0.000s
im_detect: 3209/4024 0.182s 0.000s
im_detect: 3210/4024 0.182s 0.000s
im_detect: 3211/4024 0.182s 0.000s
im_detect: 3212/4024 0.182s 0.000s
im_detect: 3213/4024 0.182s 0.000s
im_detect: 3214/4024 0.182s 0.000s
im_detect: 3215/4024 0.182s 0.000s
im_detect: 3216/4024 0.182s 0.000s
im_detect: 3217/4024 0.182s 0.000s
im_detect: 3218/4024 0.182s 0.000s
im_detect: 3219/4024 0.182s 0.000s
im_detect: 3220/4024 0.182s 0.000s
im_detect: 3221/4024 0.182s 0.000s
im_detect: 3222/4024 0.182s 0.000s
im_detect: 3223/4024 0.182s 0.000s
im_detect: 3224/4024 0.182s 0.000s
im_detect: 3225/4024 0.182s 0.000s
im_detect: 3226/4024 0.182s 0.000s
im_detect: 3227/4024 0.182s 0.000s
im_detect: 3228/4024 0.182s 0.000s
im_detect: 3229/4024 0.182s 0.000s
im_detect: 3230/4024 0.182s 0.000s
im_detect: 3231/4024 0.182s 0.000s
im_detect: 3232/4024 0.182s 0.000s
im_detect: 3233/4024 0.182s 0.000s
im_detect: 3234/4024 0.182s 0.000s
im_detect: 3235/4024 0.182s 0.000s
im_detect: 3236/4024 0.182s 0.000s
im_detect: 3237/4024 0.182s 0.000s
im_detect: 3238/4024 0.182s 0.000s
im_detect: 3239/4024 0.182s 0.000s
im_detect: 3240/4024 0.182s 0.000s
im_detect: 3241/4024 0.182s 0.000s
im_detect: 3242/4024 0.182s 0.000s
im_detect: 3243/4024 0.182s 0.000s
im_detect: 3244/4024 0.182s 0.000s
im_detect: 3245/4024 0.182s 0.000s
im_detect: 3246/4024 0.182s 0.000s
im_detect: 3247/4024 0.182s 0.000s
im_detect: 3248/4024 0.182s 0.000s
im_detect: 3249/4024 0.182s 0.000s
im_detect: 3250/4024 0.182s 0.000s
im_detect: 3251/4024 0.182s 0.000s
im_detect: 3252/4024 0.182s 0.000s
im_detect: 3253/4024 0.182s 0.000s
im_detect: 3254/4024 0.182s 0.000s
im_detect: 3255/4024 0.182s 0.000s
im_detect: 3256/4024 0.182s 0.000s
im_detect: 3257/4024 0.182s 0.000s
im_detect: 3258/4024 0.182s 0.000s
im_detect: 3259/4024 0.182s 0.000s
im_detect: 3260/4024 0.182s 0.000s
im_detect: 3261/4024 0.182s 0.000s
im_detect: 3262/4024 0.182s 0.000s
im_detect: 3263/4024 0.182s 0.000s
im_detect: 3264/4024 0.182s 0.000s
im_detect: 3265/4024 0.182s 0.000s
im_detect: 3266/4024 0.182s 0.000s
im_detect: 3267/4024 0.182s 0.000s
im_detect: 3268/4024 0.182s 0.000s
im_detect: 3269/4024 0.182s 0.000s
im_detect: 3270/4024 0.182s 0.000s
im_detect: 3271/4024 0.182s 0.000s
im_detect: 3272/4024 0.182s 0.000s
im_detect: 3273/4024 0.182s 0.000s
im_detect: 3274/4024 0.182s 0.000s
im_detect: 3275/4024 0.182s 0.000s
im_detect: 3276/4024 0.182s 0.000s
im_detect: 3277/4024 0.182s 0.000s
im_detect: 3278/4024 0.182s 0.000s
im_detect: 3279/4024 0.182s 0.000s
im_detect: 3280/4024 0.182s 0.000s
im_detect: 3281/4024 0.182s 0.000s
im_detect: 3282/4024 0.182s 0.000s
im_detect: 3283/4024 0.182s 0.000s
im_detect: 3284/4024 0.182s 0.000s
im_detect: 3285/4024 0.182s 0.000s
im_detect: 3286/4024 0.182s 0.000s
im_detect: 3287/4024 0.182s 0.000s
im_detect: 3288/4024 0.182s 0.000s
im_detect: 3289/4024 0.182s 0.000s
im_detect: 3290/4024 0.182s 0.000s
im_detect: 3291/4024 0.182s 0.000s
im_detect: 3292/4024 0.182s 0.000s
im_detect: 3293/4024 0.182s 0.000s
im_detect: 3294/4024 0.182s 0.000s
im_detect: 3295/4024 0.182s 0.000s
im_detect: 3296/4024 0.182s 0.000s
im_detect: 3297/4024 0.182s 0.000s
im_detect: 3298/4024 0.182s 0.000s
im_detect: 3299/4024 0.182s 0.000s
im_detect: 3300/4024 0.182s 0.000s
im_detect: 3301/4024 0.182s 0.000s
im_detect: 3302/4024 0.182s 0.000s
im_detect: 3303/4024 0.182s 0.000s
im_detect: 3304/4024 0.182s 0.000s
im_detect: 3305/4024 0.182s 0.000s
im_detect: 3306/4024 0.182s 0.000s
im_detect: 3307/4024 0.182s 0.000s
im_detect: 3308/4024 0.182s 0.000s
im_detect: 3309/4024 0.182s 0.000s
im_detect: 3310/4024 0.182s 0.000s
im_detect: 3311/4024 0.182s 0.000s
im_detect: 3312/4024 0.182s 0.000s
im_detect: 3313/4024 0.182s 0.000s
im_detect: 3314/4024 0.182s 0.000s
im_detect: 3315/4024 0.182s 0.000s
im_detect: 3316/4024 0.182s 0.000s
im_detect: 3317/4024 0.182s 0.000s
im_detect: 3318/4024 0.182s 0.000s
im_detect: 3319/4024 0.182s 0.000s
im_detect: 3320/4024 0.182s 0.000s
im_detect: 3321/4024 0.182s 0.000s
im_detect: 3322/4024 0.182s 0.000s
im_detect: 3323/4024 0.182s 0.000s
im_detect: 3324/4024 0.182s 0.000s
im_detect: 3325/4024 0.182s 0.000s
im_detect: 3326/4024 0.182s 0.000s
im_detect: 3327/4024 0.182s 0.000s
im_detect: 3328/4024 0.182s 0.000s
im_detect: 3329/4024 0.182s 0.000s
im_detect: 3330/4024 0.182s 0.000s
im_detect: 3331/4024 0.182s 0.000s
im_detect: 3332/4024 0.182s 0.000s
im_detect: 3333/4024 0.182s 0.000s
im_detect: 3334/4024 0.182s 0.000s
im_detect: 3335/4024 0.182s 0.000s
im_detect: 3336/4024 0.182s 0.000s
im_detect: 3337/4024 0.182s 0.000s
im_detect: 3338/4024 0.182s 0.000s
im_detect: 3339/4024 0.182s 0.000s
im_detect: 3340/4024 0.182s 0.000s
im_detect: 3341/4024 0.182s 0.000s
im_detect: 3342/4024 0.182s 0.000s
im_detect: 3343/4024 0.182s 0.000s
im_detect: 3344/4024 0.182s 0.000s
im_detect: 3345/4024 0.182s 0.000s
im_detect: 3346/4024 0.182s 0.000s
im_detect: 3347/4024 0.182s 0.000s
im_detect: 3348/4024 0.182s 0.000s
im_detect: 3349/4024 0.182s 0.000s
im_detect: 3350/4024 0.182s 0.000s
im_detect: 3351/4024 0.182s 0.000s
im_detect: 3352/4024 0.182s 0.000s
im_detect: 3353/4024 0.182s 0.000s
im_detect: 3354/4024 0.182s 0.000s
im_detect: 3355/4024 0.182s 0.000s
im_detect: 3356/4024 0.182s 0.000s
im_detect: 3357/4024 0.182s 0.000s
im_detect: 3358/4024 0.182s 0.000s
im_detect: 3359/4024 0.182s 0.000s
im_detect: 3360/4024 0.182s 0.000s
im_detect: 3361/4024 0.182s 0.000s
im_detect: 3362/4024 0.182s 0.000s
im_detect: 3363/4024 0.182s 0.000s
im_detect: 3364/4024 0.182s 0.000s
im_detect: 3365/4024 0.182s 0.000s
im_detect: 3366/4024 0.182s 0.000s
im_detect: 3367/4024 0.182s 0.000s
im_detect: 3368/4024 0.182s 0.000s
im_detect: 3369/4024 0.182s 0.000s
im_detect: 3370/4024 0.182s 0.000s
im_detect: 3371/4024 0.182s 0.000s
im_detect: 3372/4024 0.182s 0.000s
im_detect: 3373/4024 0.182s 0.000s
im_detect: 3374/4024 0.182s 0.000s
im_detect: 3375/4024 0.182s 0.000s
im_detect: 3376/4024 0.182s 0.000s
im_detect: 3377/4024 0.182s 0.000s
im_detect: 3378/4024 0.182s 0.000s
im_detect: 3379/4024 0.182s 0.000s
im_detect: 3380/4024 0.182s 0.000s
im_detect: 3381/4024 0.182s 0.000s
im_detect: 3382/4024 0.182s 0.000s
im_detect: 3383/4024 0.182s 0.000s
im_detect: 3384/4024 0.182s 0.000s
im_detect: 3385/4024 0.182s 0.000s
im_detect: 3386/4024 0.182s 0.000s
im_detect: 3387/4024 0.182s 0.000s
im_detect: 3388/4024 0.182s 0.000s
im_detect: 3389/4024 0.182s 0.000s
im_detect: 3390/4024 0.182s 0.000s
im_detect: 3391/4024 0.182s 0.000s
im_detect: 3392/4024 0.182s 0.000s
im_detect: 3393/4024 0.182s 0.000s
im_detect: 3394/4024 0.182s 0.000s
im_detect: 3395/4024 0.182s 0.000s
im_detect: 3396/4024 0.182s 0.000s
im_detect: 3397/4024 0.182s 0.000s
im_detect: 3398/4024 0.182s 0.000s
im_detect: 3399/4024 0.182s 0.000s
im_detect: 3400/4024 0.182s 0.000s
im_detect: 3401/4024 0.182s 0.000s
im_detect: 3402/4024 0.182s 0.000s
im_detect: 3403/4024 0.182s 0.000s
im_detect: 3404/4024 0.182s 0.000s
im_detect: 3405/4024 0.182s 0.000s
im_detect: 3406/4024 0.182s 0.000s
im_detect: 3407/4024 0.182s 0.000s
im_detect: 3408/4024 0.182s 0.000s
im_detect: 3409/4024 0.182s 0.000s
im_detect: 3410/4024 0.182s 0.000s
im_detect: 3411/4024 0.182s 0.000s
im_detect: 3412/4024 0.182s 0.000s
im_detect: 3413/4024 0.182s 0.000s
im_detect: 3414/4024 0.182s 0.000s
im_detect: 3415/4024 0.182s 0.000s
im_detect: 3416/4024 0.182s 0.000s
im_detect: 3417/4024 0.182s 0.000s
im_detect: 3418/4024 0.182s 0.000s
im_detect: 3419/4024 0.182s 0.000s
im_detect: 3420/4024 0.182s 0.000s
im_detect: 3421/4024 0.182s 0.000s
im_detect: 3422/4024 0.182s 0.000s
im_detect: 3423/4024 0.182s 0.000s
im_detect: 3424/4024 0.182s 0.000s
im_detect: 3425/4024 0.182s 0.000s
im_detect: 3426/4024 0.182s 0.000s
im_detect: 3427/4024 0.182s 0.000s
im_detect: 3428/4024 0.182s 0.000s
im_detect: 3429/4024 0.182s 0.000s
im_detect: 3430/4024 0.182s 0.000s
im_detect: 3431/4024 0.182s 0.000s
im_detect: 3432/4024 0.182s 0.000s
im_detect: 3433/4024 0.182s 0.000s
im_detect: 3434/4024 0.182s 0.000s
im_detect: 3435/4024 0.182s 0.000s
im_detect: 3436/4024 0.182s 0.000s
im_detect: 3437/4024 0.182s 0.000s
im_detect: 3438/4024 0.182s 0.000s
im_detect: 3439/4024 0.182s 0.000s
im_detect: 3440/4024 0.182s 0.000s
im_detect: 3441/4024 0.182s 0.000s
im_detect: 3442/4024 0.182s 0.000s
im_detect: 3443/4024 0.182s 0.000s
im_detect: 3444/4024 0.182s 0.000s
im_detect: 3445/4024 0.182s 0.000s
im_detect: 3446/4024 0.182s 0.000s
im_detect: 3447/4024 0.182s 0.000s
im_detect: 3448/4024 0.182s 0.000s
im_detect: 3449/4024 0.182s 0.000s
im_detect: 3450/4024 0.182s 0.000s
im_detect: 3451/4024 0.182s 0.000s
im_detect: 3452/4024 0.182s 0.000s
im_detect: 3453/4024 0.182s 0.000s
im_detect: 3454/4024 0.182s 0.000s
im_detect: 3455/4024 0.182s 0.000s
im_detect: 3456/4024 0.182s 0.000s
im_detect: 3457/4024 0.182s 0.000s
im_detect: 3458/4024 0.182s 0.000s
im_detect: 3459/4024 0.182s 0.000s
im_detect: 3460/4024 0.182s 0.000s
im_detect: 3461/4024 0.182s 0.000s
im_detect: 3462/4024 0.182s 0.000s
im_detect: 3463/4024 0.182s 0.000s
im_detect: 3464/4024 0.182s 0.000s
im_detect: 3465/4024 0.182s 0.000s
im_detect: 3466/4024 0.182s 0.000s
im_detect: 3467/4024 0.182s 0.000s
im_detect: 3468/4024 0.182s 0.000s
im_detect: 3469/4024 0.182s 0.000s
im_detect: 3470/4024 0.182s 0.000s
im_detect: 3471/4024 0.182s 0.000s
im_detect: 3472/4024 0.182s 0.000s
im_detect: 3473/4024 0.182s 0.000s
im_detect: 3474/4024 0.182s 0.000s
im_detect: 3475/4024 0.182s 0.000s
im_detect: 3476/4024 0.182s 0.000s
im_detect: 3477/4024 0.182s 0.000s
im_detect: 3478/4024 0.182s 0.000s
im_detect: 3479/4024 0.182s 0.000s
im_detect: 3480/4024 0.182s 0.000s
im_detect: 3481/4024 0.182s 0.000s
im_detect: 3482/4024 0.182s 0.000s
im_detect: 3483/4024 0.182s 0.000s
im_detect: 3484/4024 0.182s 0.000s
im_detect: 3485/4024 0.182s 0.000s
im_detect: 3486/4024 0.182s 0.000s
im_detect: 3487/4024 0.182s 0.000s
im_detect: 3488/4024 0.182s 0.000s
im_detect: 3489/4024 0.182s 0.000s
im_detect: 3490/4024 0.182s 0.000s
im_detect: 3491/4024 0.182s 0.000s
im_detect: 3492/4024 0.182s 0.000s
im_detect: 3493/4024 0.182s 0.000s
im_detect: 3494/4024 0.182s 0.000s
im_detect: 3495/4024 0.182s 0.000s
im_detect: 3496/4024 0.182s 0.000s
im_detect: 3497/4024 0.182s 0.000s
im_detect: 3498/4024 0.182s 0.000s
im_detect: 3499/4024 0.182s 0.000s
im_detect: 3500/4024 0.182s 0.000s
im_detect: 3501/4024 0.182s 0.000s
im_detect: 3502/4024 0.182s 0.000s
im_detect: 3503/4024 0.182s 0.000s
im_detect: 3504/4024 0.182s 0.000s
im_detect: 3505/4024 0.182s 0.000s
im_detect: 3506/4024 0.182s 0.000s
im_detect: 3507/4024 0.182s 0.000s
im_detect: 3508/4024 0.182s 0.000s
im_detect: 3509/4024 0.182s 0.000s
im_detect: 3510/4024 0.182s 0.000s
im_detect: 3511/4024 0.182s 0.000s
im_detect: 3512/4024 0.182s 0.000s
im_detect: 3513/4024 0.182s 0.000s
im_detect: 3514/4024 0.182s 0.000s
im_detect: 3515/4024 0.182s 0.000s
im_detect: 3516/4024 0.182s 0.000s
im_detect: 3517/4024 0.182s 0.000s
im_detect: 3518/4024 0.182s 0.000s
im_detect: 3519/4024 0.182s 0.000s
im_detect: 3520/4024 0.182s 0.000s
im_detect: 3521/4024 0.182s 0.000s
im_detect: 3522/4024 0.182s 0.000s
im_detect: 3523/4024 0.182s 0.000s
im_detect: 3524/4024 0.182s 0.000s
im_detect: 3525/4024 0.182s 0.000s
im_detect: 3526/4024 0.182s 0.000s
im_detect: 3527/4024 0.182s 0.000s
im_detect: 3528/4024 0.182s 0.000s
im_detect: 3529/4024 0.182s 0.000s
im_detect: 3530/4024 0.182s 0.000s
im_detect: 3531/4024 0.182s 0.000s
im_detect: 3532/4024 0.182s 0.000s
im_detect: 3533/4024 0.182s 0.000s
im_detect: 3534/4024 0.182s 0.000s
im_detect: 3535/4024 0.182s 0.000s
im_detect: 3536/4024 0.182s 0.000s
im_detect: 3537/4024 0.182s 0.000s
im_detect: 3538/4024 0.182s 0.000s
im_detect: 3539/4024 0.182s 0.000s
im_detect: 3540/4024 0.182s 0.000s
im_detect: 3541/4024 0.182s 0.000s
im_detect: 3542/4024 0.182s 0.000s
im_detect: 3543/4024 0.182s 0.000s
im_detect: 3544/4024 0.182s 0.000s
im_detect: 3545/4024 0.182s 0.000s
im_detect: 3546/4024 0.182s 0.000s
im_detect: 3547/4024 0.182s 0.000s
im_detect: 3548/4024 0.182s 0.000s
im_detect: 3549/4024 0.182s 0.000s
im_detect: 3550/4024 0.182s 0.000s
im_detect: 3551/4024 0.182s 0.000s
im_detect: 3552/4024 0.182s 0.000s
im_detect: 3553/4024 0.182s 0.000s
im_detect: 3554/4024 0.182s 0.000s
im_detect: 3555/4024 0.182s 0.000s
im_detect: 3556/4024 0.182s 0.000s
im_detect: 3557/4024 0.182s 0.000s
im_detect: 3558/4024 0.182s 0.000s
im_detect: 3559/4024 0.182s 0.000s
im_detect: 3560/4024 0.182s 0.000s
im_detect: 3561/4024 0.182s 0.000s
im_detect: 3562/4024 0.182s 0.000s
im_detect: 3563/4024 0.182s 0.000s
im_detect: 3564/4024 0.182s 0.000s
im_detect: 3565/4024 0.182s 0.000s
im_detect: 3566/4024 0.182s 0.000s
im_detect: 3567/4024 0.182s 0.000s
im_detect: 3568/4024 0.182s 0.000s
im_detect: 3569/4024 0.182s 0.000s
im_detect: 3570/4024 0.182s 0.000s
im_detect: 3571/4024 0.182s 0.000s
im_detect: 3572/4024 0.182s 0.000s
im_detect: 3573/4024 0.182s 0.000s
im_detect: 3574/4024 0.182s 0.000s
im_detect: 3575/4024 0.182s 0.000s
im_detect: 3576/4024 0.182s 0.000s
im_detect: 3577/4024 0.182s 0.000s
im_detect: 3578/4024 0.182s 0.000s
im_detect: 3579/4024 0.182s 0.000s
im_detect: 3580/4024 0.182s 0.000s
im_detect: 3581/4024 0.182s 0.000s
im_detect: 3582/4024 0.182s 0.000s
im_detect: 3583/4024 0.182s 0.000s
im_detect: 3584/4024 0.182s 0.000s
im_detect: 3585/4024 0.182s 0.000s
im_detect: 3586/4024 0.182s 0.000s
im_detect: 3587/4024 0.182s 0.000s
im_detect: 3588/4024 0.182s 0.000s
im_detect: 3589/4024 0.182s 0.000s
im_detect: 3590/4024 0.182s 0.000s
im_detect: 3591/4024 0.182s 0.000s
im_detect: 3592/4024 0.182s 0.000s
im_detect: 3593/4024 0.182s 0.000s
im_detect: 3594/4024 0.182s 0.000s
im_detect: 3595/4024 0.182s 0.000s
im_detect: 3596/4024 0.182s 0.000s
im_detect: 3597/4024 0.182s 0.000s
im_detect: 3598/4024 0.182s 0.000s
im_detect: 3599/4024 0.182s 0.000s
im_detect: 3600/4024 0.182s 0.000s
im_detect: 3601/4024 0.182s 0.000s
im_detect: 3602/4024 0.182s 0.000s
im_detect: 3603/4024 0.182s 0.000s
im_detect: 3604/4024 0.182s 0.000s
im_detect: 3605/4024 0.182s 0.000s
im_detect: 3606/4024 0.182s 0.000s
im_detect: 3607/4024 0.182s 0.000s
im_detect: 3608/4024 0.182s 0.000s
im_detect: 3609/4024 0.182s 0.000s
im_detect: 3610/4024 0.182s 0.000s
im_detect: 3611/4024 0.182s 0.000s
im_detect: 3612/4024 0.182s 0.000s
im_detect: 3613/4024 0.182s 0.000s
im_detect: 3614/4024 0.182s 0.000s
im_detect: 3615/4024 0.182s 0.000s
im_detect: 3616/4024 0.182s 0.000s
im_detect: 3617/4024 0.182s 0.000s
im_detect: 3618/4024 0.182s 0.000s
im_detect: 3619/4024 0.182s 0.000s
im_detect: 3620/4024 0.182s 0.000s
im_detect: 3621/4024 0.182s 0.000s
im_detect: 3622/4024 0.182s 0.000s
im_detect: 3623/4024 0.182s 0.000s
im_detect: 3624/4024 0.182s 0.000s
im_detect: 3625/4024 0.182s 0.000s
im_detect: 3626/4024 0.182s 0.000s
im_detect: 3627/4024 0.182s 0.000s
im_detect: 3628/4024 0.182s 0.000s
im_detect: 3629/4024 0.182s 0.000s
im_detect: 3630/4024 0.182s 0.000s
im_detect: 3631/4024 0.182s 0.000s
im_detect: 3632/4024 0.182s 0.000s
im_detect: 3633/4024 0.182s 0.000s
im_detect: 3634/4024 0.182s 0.000s
im_detect: 3635/4024 0.182s 0.000s
im_detect: 3636/4024 0.182s 0.000s
im_detect: 3637/4024 0.182s 0.000s
im_detect: 3638/4024 0.182s 0.000s
im_detect: 3639/4024 0.182s 0.000s
im_detect: 3640/4024 0.182s 0.000s
im_detect: 3641/4024 0.182s 0.000s
im_detect: 3642/4024 0.182s 0.000s
im_detect: 3643/4024 0.182s 0.000s
im_detect: 3644/4024 0.182s 0.000s
im_detect: 3645/4024 0.182s 0.000s
im_detect: 3646/4024 0.182s 0.000s
im_detect: 3647/4024 0.182s 0.000s
im_detect: 3648/4024 0.182s 0.000s
im_detect: 3649/4024 0.182s 0.000s
im_detect: 3650/4024 0.182s 0.000s
im_detect: 3651/4024 0.182s 0.000s
im_detect: 3652/4024 0.182s 0.000s
im_detect: 3653/4024 0.182s 0.000s
im_detect: 3654/4024 0.182s 0.000s
im_detect: 3655/4024 0.182s 0.000s
im_detect: 3656/4024 0.182s 0.000s
im_detect: 3657/4024 0.182s 0.000s
im_detect: 3658/4024 0.182s 0.000s
im_detect: 3659/4024 0.182s 0.000s
im_detect: 3660/4024 0.182s 0.000s
im_detect: 3661/4024 0.182s 0.000s
im_detect: 3662/4024 0.182s 0.000s
im_detect: 3663/4024 0.182s 0.000s
im_detect: 3664/4024 0.182s 0.000s
im_detect: 3665/4024 0.182s 0.000s
im_detect: 3666/4024 0.182s 0.000s
im_detect: 3667/4024 0.182s 0.000s
im_detect: 3668/4024 0.182s 0.000s
im_detect: 3669/4024 0.182s 0.000s
im_detect: 3670/4024 0.182s 0.000s
im_detect: 3671/4024 0.182s 0.000s
im_detect: 3672/4024 0.182s 0.000s
im_detect: 3673/4024 0.182s 0.000s
im_detect: 3674/4024 0.182s 0.000s
im_detect: 3675/4024 0.182s 0.000s
im_detect: 3676/4024 0.182s 0.000s
im_detect: 3677/4024 0.182s 0.000s
im_detect: 3678/4024 0.182s 0.000s
im_detect: 3679/4024 0.182s 0.000s
im_detect: 3680/4024 0.182s 0.000s
im_detect: 3681/4024 0.182s 0.000s
im_detect: 3682/4024 0.182s 0.000s
im_detect: 3683/4024 0.182s 0.000s
im_detect: 3684/4024 0.182s 0.000s
im_detect: 3685/4024 0.182s 0.000s
im_detect: 3686/4024 0.182s 0.000s
im_detect: 3687/4024 0.182s 0.000s
im_detect: 3688/4024 0.182s 0.000s
im_detect: 3689/4024 0.182s 0.000s
im_detect: 3690/4024 0.182s 0.000s
im_detect: 3691/4024 0.182s 0.000s
im_detect: 3692/4024 0.182s 0.000s
im_detect: 3693/4024 0.182s 0.000s
im_detect: 3694/4024 0.182s 0.000s
im_detect: 3695/4024 0.182s 0.000s
im_detect: 3696/4024 0.182s 0.000s
im_detect: 3697/4024 0.182s 0.000s
im_detect: 3698/4024 0.182s 0.000s
im_detect: 3699/4024 0.182s 0.000s
im_detect: 3700/4024 0.182s 0.000s
im_detect: 3701/4024 0.182s 0.000s
im_detect: 3702/4024 0.182s 0.000s
im_detect: 3703/4024 0.182s 0.000s
im_detect: 3704/4024 0.182s 0.000s
im_detect: 3705/4024 0.182s 0.000s
im_detect: 3706/4024 0.182s 0.000s
im_detect: 3707/4024 0.182s 0.000s
im_detect: 3708/4024 0.182s 0.000s
im_detect: 3709/4024 0.182s 0.000s
im_detect: 3710/4024 0.182s 0.000s
im_detect: 3711/4024 0.182s 0.000s
im_detect: 3712/4024 0.182s 0.000s
im_detect: 3713/4024 0.182s 0.000s
im_detect: 3714/4024 0.182s 0.000s
im_detect: 3715/4024 0.182s 0.000s
im_detect: 3716/4024 0.182s 0.000s
im_detect: 3717/4024 0.182s 0.000s
im_detect: 3718/4024 0.182s 0.000s
im_detect: 3719/4024 0.182s 0.000s
im_detect: 3720/4024 0.182s 0.000s
im_detect: 3721/4024 0.182s 0.000s
im_detect: 3722/4024 0.182s 0.000s
im_detect: 3723/4024 0.182s 0.000s
im_detect: 3724/4024 0.182s 0.000s
im_detect: 3725/4024 0.182s 0.000s
im_detect: 3726/4024 0.182s 0.000s
im_detect: 3727/4024 0.182s 0.000s
im_detect: 3728/4024 0.182s 0.000s
im_detect: 3729/4024 0.182s 0.000s
im_detect: 3730/4024 0.182s 0.000s
im_detect: 3731/4024 0.182s 0.000s
im_detect: 3732/4024 0.182s 0.000s
im_detect: 3733/4024 0.182s 0.000s
im_detect: 3734/4024 0.182s 0.000s
im_detect: 3735/4024 0.182s 0.000s
im_detect: 3736/4024 0.182s 0.000s
im_detect: 3737/4024 0.182s 0.000s
im_detect: 3738/4024 0.182s 0.000s
im_detect: 3739/4024 0.182s 0.000s
im_detect: 3740/4024 0.182s 0.000s
im_detect: 3741/4024 0.182s 0.000s
im_detect: 3742/4024 0.182s 0.000s
im_detect: 3743/4024 0.182s 0.000s
im_detect: 3744/4024 0.182s 0.000s
im_detect: 3745/4024 0.182s 0.000s
im_detect: 3746/4024 0.182s 0.000s
im_detect: 3747/4024 0.182s 0.000s
im_detect: 3748/4024 0.182s 0.000s
im_detect: 3749/4024 0.182s 0.000s
im_detect: 3750/4024 0.182s 0.000s
im_detect: 3751/4024 0.182s 0.000s
im_detect: 3752/4024 0.182s 0.000s
im_detect: 3753/4024 0.182s 0.000s
im_detect: 3754/4024 0.182s 0.000s
im_detect: 3755/4024 0.182s 0.000s
im_detect: 3756/4024 0.182s 0.000s
im_detect: 3757/4024 0.182s 0.000s
im_detect: 3758/4024 0.182s 0.000s
im_detect: 3759/4024 0.182s 0.000s
im_detect: 3760/4024 0.182s 0.000s
im_detect: 3761/4024 0.182s 0.000s
im_detect: 3762/4024 0.182s 0.000s
im_detect: 3763/4024 0.182s 0.000s
im_detect: 3764/4024 0.182s 0.000s
im_detect: 3765/4024 0.182s 0.000s
im_detect: 3766/4024 0.182s 0.000s
im_detect: 3767/4024 0.182s 0.000s
im_detect: 3768/4024 0.182s 0.000s
im_detect: 3769/4024 0.182s 0.000s
im_detect: 3770/4024 0.182s 0.000s
im_detect: 3771/4024 0.182s 0.000s
im_detect: 3772/4024 0.182s 0.000s
im_detect: 3773/4024 0.182s 0.000s
im_detect: 3774/4024 0.182s 0.000s
im_detect: 3775/4024 0.182s 0.000s
im_detect: 3776/4024 0.182s 0.000s
im_detect: 3777/4024 0.182s 0.000s
im_detect: 3778/4024 0.182s 0.000s
im_detect: 3779/4024 0.182s 0.000s
im_detect: 3780/4024 0.182s 0.000s
im_detect: 3781/4024 0.182s 0.000s
im_detect: 3782/4024 0.182s 0.000s
im_detect: 3783/4024 0.182s 0.000s
im_detect: 3784/4024 0.182s 0.000s
im_detect: 3785/4024 0.182s 0.000s
im_detect: 3786/4024 0.182s 0.000s
im_detect: 3787/4024 0.182s 0.000s
im_detect: 3788/4024 0.182s 0.000s
im_detect: 3789/4024 0.182s 0.000s
im_detect: 3790/4024 0.182s 0.000s
im_detect: 3791/4024 0.182s 0.000s
im_detect: 3792/4024 0.182s 0.000s
im_detect: 3793/4024 0.182s 0.000s
im_detect: 3794/4024 0.182s 0.000s
im_detect: 3795/4024 0.182s 0.000s
im_detect: 3796/4024 0.182s 0.000s
im_detect: 3797/4024 0.182s 0.000s
im_detect: 3798/4024 0.182s 0.000s
im_detect: 3799/4024 0.182s 0.000s
im_detect: 3800/4024 0.182s 0.000s
im_detect: 3801/4024 0.182s 0.000s
im_detect: 3802/4024 0.182s 0.000s
im_detect: 3803/4024 0.182s 0.000s
im_detect: 3804/4024 0.182s 0.000s
im_detect: 3805/4024 0.182s 0.000s
im_detect: 3806/4024 0.182s 0.000s
im_detect: 3807/4024 0.182s 0.000s
im_detect: 3808/4024 0.182s 0.000s
im_detect: 3809/4024 0.182s 0.000s
im_detect: 3810/4024 0.182s 0.000s
im_detect: 3811/4024 0.182s 0.000s
im_detect: 3812/4024 0.182s 0.000s
im_detect: 3813/4024 0.182s 0.000s
im_detect: 3814/4024 0.182s 0.000s
im_detect: 3815/4024 0.182s 0.000s
im_detect: 3816/4024 0.182s 0.000s
im_detect: 3817/4024 0.182s 0.000s
im_detect: 3818/4024 0.182s 0.000s
im_detect: 3819/4024 0.182s 0.000s
im_detect: 3820/4024 0.182s 0.000s
im_detect: 3821/4024 0.182s 0.000s
im_detect: 3822/4024 0.182s 0.000s
im_detect: 3823/4024 0.182s 0.000s
im_detect: 3824/4024 0.182s 0.000s
im_detect: 3825/4024 0.182s 0.000s
im_detect: 3826/4024 0.182s 0.000s
im_detect: 3827/4024 0.182s 0.000s
im_detect: 3828/4024 0.182s 0.000s
im_detect: 3829/4024 0.182s 0.000s
im_detect: 3830/4024 0.182s 0.000s
im_detect: 3831/4024 0.182s 0.000s
im_detect: 3832/4024 0.182s 0.000s
im_detect: 3833/4024 0.182s 0.000s
im_detect: 3834/4024 0.182s 0.000s
im_detect: 3835/4024 0.182s 0.000s
im_detect: 3836/4024 0.182s 0.000s
im_detect: 3837/4024 0.182s 0.000s
im_detect: 3838/4024 0.182s 0.000s
im_detect: 3839/4024 0.182s 0.000s
im_detect: 3840/4024 0.182s 0.000s
im_detect: 3841/4024 0.182s 0.000s
im_detect: 3842/4024 0.182s 0.000s
im_detect: 3843/4024 0.182s 0.000s
im_detect: 3844/4024 0.182s 0.000s
im_detect: 3845/4024 0.182s 0.000s
im_detect: 3846/4024 0.182s 0.000s
im_detect: 3847/4024 0.182s 0.000s
im_detect: 3848/4024 0.182s 0.000s
im_detect: 3849/4024 0.182s 0.000s
im_detect: 3850/4024 0.182s 0.000s
im_detect: 3851/4024 0.182s 0.000s
im_detect: 3852/4024 0.182s 0.000s
im_detect: 3853/4024 0.182s 0.000s
im_detect: 3854/4024 0.182s 0.000s
im_detect: 3855/4024 0.182s 0.000s
im_detect: 3856/4024 0.182s 0.000s
im_detect: 3857/4024 0.182s 0.000s
im_detect: 3858/4024 0.182s 0.000s
im_detect: 3859/4024 0.182s 0.000s
im_detect: 3860/4024 0.182s 0.000s
im_detect: 3861/4024 0.182s 0.000s
im_detect: 3862/4024 0.182s 0.000s
im_detect: 3863/4024 0.182s 0.000s
im_detect: 3864/4024 0.182s 0.000s
im_detect: 3865/4024 0.182s 0.000s
im_detect: 3866/4024 0.182s 0.000s
im_detect: 3867/4024 0.182s 0.000s
im_detect: 3868/4024 0.182s 0.000s
im_detect: 3869/4024 0.182s 0.000s
im_detect: 3870/4024 0.182s 0.000s
im_detect: 3871/4024 0.182s 0.000s
im_detect: 3872/4024 0.182s 0.000s
im_detect: 3873/4024 0.182s 0.000s
im_detect: 3874/4024 0.182s 0.000s
im_detect: 3875/4024 0.182s 0.000s
im_detect: 3876/4024 0.182s 0.000s
im_detect: 3877/4024 0.182s 0.000s
im_detect: 3878/4024 0.182s 0.000s
im_detect: 3879/4024 0.182s 0.000s
im_detect: 3880/4024 0.182s 0.000s
im_detect: 3881/4024 0.182s 0.000s
im_detect: 3882/4024 0.182s 0.000s
im_detect: 3883/4024 0.182s 0.000s
im_detect: 3884/4024 0.182s 0.000s
im_detect: 3885/4024 0.182s 0.000s
im_detect: 3886/4024 0.182s 0.000s
im_detect: 3887/4024 0.182s 0.000s
im_detect: 3888/4024 0.182s 0.000s
im_detect: 3889/4024 0.182s 0.000s
im_detect: 3890/4024 0.182s 0.000s
im_detect: 3891/4024 0.182s 0.000s
im_detect: 3892/4024 0.182s 0.000s
im_detect: 3893/4024 0.182s 0.000s
im_detect: 3894/4024 0.182s 0.000s
im_detect: 3895/4024 0.182s 0.000s
im_detect: 3896/4024 0.182s 0.000s
im_detect: 3897/4024 0.182s 0.000s
im_detect: 3898/4024 0.182s 0.000s
im_detect: 3899/4024 0.182s 0.000s
im_detect: 3900/4024 0.182s 0.000s
im_detect: 3901/4024 0.182s 0.000s
im_detect: 3902/4024 0.182s 0.000s
im_detect: 3903/4024 0.182s 0.000s
im_detect: 3904/4024 0.182s 0.000s
im_detect: 3905/4024 0.182s 0.000s
im_detect: 3906/4024 0.182s 0.000s
im_detect: 3907/4024 0.182s 0.000s
im_detect: 3908/4024 0.182s 0.000s
im_detect: 3909/4024 0.182s 0.000s
im_detect: 3910/4024 0.182s 0.000s
im_detect: 3911/4024 0.182s 0.000s
im_detect: 3912/4024 0.182s 0.000s
im_detect: 3913/4024 0.182s 0.000s
im_detect: 3914/4024 0.182s 0.000s
im_detect: 3915/4024 0.182s 0.000s
im_detect: 3916/4024 0.182s 0.000s
im_detect: 3917/4024 0.182s 0.000s
im_detect: 3918/4024 0.182s 0.000s
im_detect: 3919/4024 0.182s 0.000s
im_detect: 3920/4024 0.182s 0.000s
im_detect: 3921/4024 0.182s 0.000s
im_detect: 3922/4024 0.182s 0.000s
im_detect: 3923/4024 0.182s 0.000s
im_detect: 3924/4024 0.182s 0.000s
im_detect: 3925/4024 0.182s 0.000s
im_detect: 3926/4024 0.182s 0.000s
im_detect: 3927/4024 0.182s 0.000s
im_detect: 3928/4024 0.182s 0.000s
im_detect: 3929/4024 0.182s 0.000s
im_detect: 3930/4024 0.182s 0.000s
im_detect: 3931/4024 0.182s 0.000s
im_detect: 3932/4024 0.182s 0.000s
im_detect: 3933/4024 0.182s 0.000s
im_detect: 3934/4024 0.182s 0.000s
im_detect: 3935/4024 0.182s 0.000s
im_detect: 3936/4024 0.182s 0.000s
im_detect: 3937/4024 0.182s 0.000s
im_detect: 3938/4024 0.182s 0.000s
im_detect: 3939/4024 0.182s 0.000s
im_detect: 3940/4024 0.182s 0.000s
im_detect: 3941/4024 0.182s 0.000s
im_detect: 3942/4024 0.182s 0.000s
im_detect: 3943/4024 0.182s 0.000s
im_detect: 3944/4024 0.182s 0.000s
im_detect: 3945/4024 0.182s 0.000s
im_detect: 3946/4024 0.182s 0.000s
im_detect: 3947/4024 0.182s 0.000s
im_detect: 3948/4024 0.182s 0.000s
im_detect: 3949/4024 0.182s 0.000s
im_detect: 3950/4024 0.182s 0.000s
im_detect: 3951/4024 0.182s 0.000s
im_detect: 3952/4024 0.182s 0.000s
im_detect: 3953/4024 0.182s 0.000s
im_detect: 3954/4024 0.182s 0.000s
im_detect: 3955/4024 0.182s 0.000s
im_detect: 3956/4024 0.182s 0.000s
im_detect: 3957/4024 0.182s 0.000s
im_detect: 3958/4024 0.182s 0.000s
im_detect: 3959/4024 0.182s 0.000s
im_detect: 3960/4024 0.182s 0.000s
im_detect: 3961/4024 0.182s 0.000s
im_detect: 3962/4024 0.182s 0.000s
im_detect: 3963/4024 0.182s 0.000s
im_detect: 3964/4024 0.182s 0.000s
im_detect: 3965/4024 0.182s 0.000s
im_detect: 3966/4024 0.182s 0.000s
im_detect: 3967/4024 0.182s 0.000s
im_detect: 3968/4024 0.182s 0.000s
im_detect: 3969/4024 0.182s 0.000s
im_detect: 3970/4024 0.182s 0.000s
im_detect: 3971/4024 0.182s 0.000s
im_detect: 3972/4024 0.182s 0.000s
im_detect: 3973/4024 0.182s 0.000s
im_detect: 3974/4024 0.182s 0.000s
im_detect: 3975/4024 0.182s 0.000s
im_detect: 3976/4024 0.182s 0.000s
im_detect: 3977/4024 0.182s 0.000s
im_detect: 3978/4024 0.182s 0.000s
im_detect: 3979/4024 0.182s 0.000s
im_detect: 3980/4024 0.182s 0.000s
im_detect: 3981/4024 0.182s 0.000s
im_detect: 3982/4024 0.182s 0.000s
im_detect: 3983/4024 0.182s 0.000s
im_detect: 3984/4024 0.182s 0.000s
im_detect: 3985/4024 0.182s 0.000s
im_detect: 3986/4024 0.182s 0.000s
im_detect: 3987/4024 0.182s 0.000s
im_detect: 3988/4024 0.182s 0.000s
im_detect: 3989/4024 0.182s 0.000s
im_detect: 3990/4024 0.182s 0.000s
im_detect: 3991/4024 0.182s 0.000s
im_detect: 3992/4024 0.182s 0.000s
im_detect: 3993/4024 0.182s 0.000s
im_detect: 3994/4024 0.182s 0.000s
im_detect: 3995/4024 0.182s 0.000s
im_detect: 3996/4024 0.182s 0.000s
im_detect: 3997/4024 0.182s 0.000s
im_detect: 3998/4024 0.182s 0.000s
im_detect: 3999/4024 0.182s 0.000s
im_detect: 4000/4024 0.182s 0.000s
im_detect: 4001/4024 0.182s 0.000s
im_detect: 4002/4024 0.182s 0.000s
im_detect: 4003/4024 0.182s 0.000s
im_detect: 4004/4024 0.182s 0.000s
im_detect: 4005/4024 0.182s 0.000s
im_detect: 4006/4024 0.182s 0.000s
im_detect: 4007/4024 0.182s 0.000s
im_detect: 4008/4024 0.182s 0.000s
im_detect: 4009/4024 0.182s 0.000s
im_detect: 4010/4024 0.182s 0.000s
im_detect: 4011/4024 0.182s 0.000s
im_detect: 4012/4024 0.182s 0.000s
im_detect: 4013/4024 0.182s 0.000s
im_detect: 4014/4024 0.182s 0.000s
im_detect: 4015/4024 0.182s 0.000s
im_detect: 4016/4024 0.182s 0.000s
im_detect: 4017/4024 0.182s 0.000s
im_detect: 4018/4024 0.182s 0.000s
im_detect: 4019/4024 0.182s 0.000s
im_detect: 4020/4024 0.182s 0.000s
im_detect: 4021/4024 0.182s 0.000s
im_detect: 4022/4024 0.182s 0.000s
im_detect: 4023/4024 0.182s 0.000s
im_detect: 4024/4024 0.182s 0.000s
Evaluating detections
Writing person VOC results file
VOC07 metric? Yes
Reading annotation for 1/4024
Reading annotation for 101/4024
Reading annotation for 201/4024
Reading annotation for 301/4024
Reading annotation for 401/4024
Reading annotation for 501/4024
Reading annotation for 601/4024
Reading annotation for 701/4024
Reading annotation for 801/4024
Reading annotation for 901/4024
Reading annotation for 1001/4024
Reading annotation for 1101/4024
Reading annotation for 1201/4024
Reading annotation for 1301/4024
Reading annotation for 1401/4024
Reading annotation for 1501/4024
Reading annotation for 1601/4024
Reading annotation for 1701/4024
Reading annotation for 1801/4024
Reading annotation for 1901/4024
Reading annotation for 2001/4024
Reading annotation for 2101/4024
Reading annotation for 2201/4024
Reading annotation for 2301/4024
Reading annotation for 2401/4024
Reading annotation for 2501/4024
Reading annotation for 2601/4024
Reading annotation for 2701/4024
Reading annotation for 2801/4024
Reading annotation for 2901/4024
Reading annotation for 3001/4024
Reading annotation for 3101/4024
Reading annotation for 3201/4024
Reading annotation for 3301/4024
Reading annotation for 3401/4024
Reading annotation for 3501/4024
Reading annotation for 3601/4024
Reading annotation for 3701/4024
Reading annotation for 3801/4024
Reading annotation for 3901/4024
Reading annotation for 4001/4024
Saving cached annotations to /home/user/Disk1.8T/py-R-FCN/data/VOCdevkit0712/annotations_cache/annots.pkl
fp [    0.     0.     0. ... 29961. 29962. 29963.]
tp[1.000e+00 2.000e+00 3.000e+00 ... 2.926e+03 2.926e+03 2.926e+03]
npos: 4401
AP for person = 0.4251
Mean AP = 0.4251
~~~~~~~~
Results:
0.425
0.425
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	12m24.223s
user	10m37.800s
sys	2m3.176s
