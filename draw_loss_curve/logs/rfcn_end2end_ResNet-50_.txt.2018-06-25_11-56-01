+ echo Logging output to experiments/6_25_head/logs/rfcn_end2end_ResNet-50_.txt.2018-06-25_11-56-01
Logging output to experiments/6_25_head/logs/rfcn_end2end_ResNet-50_.txt.2018-06-25_11-56-01
+ ./tools/train_net.py --gpu 0 --solver experiments/6_25_head/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_0712_trainval --iters 32000 --cfg experiments/6_25_head/rfcn_end2end_ohem.yml
Called with args:
Namespace(cfg_file='experiments/6_25_head/rfcn_end2end_ohem.yml', gpu_id=0, imdb_name='voc_0712_trainval', max_iters=32000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='experiments/6_25_head/solver_ohem.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py_R_FCN_6_25/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '6_25_head/model',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py_R_FCN_6_25/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py_R_FCN_6_25',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SOFT_NMS': 1,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_0712_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
set03_V011_I01529
num_objs 0
set03_V010_I00449
num_objs 0
set02_V008_I00569
num_objs 0
set02_V001_I01049
num_objs 0
set03_V007_I01199
num_objs 0
set05_V001_I00569
num_objs 0
set00_V001_I00089
num_objs 0
set04_V006_I01049
num_objs 1
set03_V011_I01109
num_objs 0
set02_V007_I01469
num_objs 0
set00_V014_I00509
num_objs 4
set02_V004_I00239
num_objs 0
set05_V004_I00179
num_objs 0
set03_V004_I00659
num_objs 0
set02_V011_I00929
num_objs 0
set00_V001_I01439
num_objs 0
set04_V002_I00809
num_objs 1
set05_V010_I01409
num_objs 0
set05_V010_I01259
num_objs 0
set00_V002_I01259
num_objs 0
set01_V004_I00629
num_objs 3
set00_V007_I00239
num_objs 3
set05_V011_I00029
num_objs 0
set04_V007_I00149
num_objs 0
set05_V004_I00629
num_objs 0
set01_V001_I00839
num_objs 0
set05_V002_I01409
num_objs 0
set03_V000_I00359
num_objs 0
set05_V008_I00119
num_objs 0
set02_V004_I00119
num_objs 0
set05_V009_I00959
num_objs 1
set05_V001_I00239
num_objs 0
set02_V011_I00539
num_objs 0
set05_V011_I00929
num_objs 5
set05_V001_I01799
num_objs 0
set04_V006_I01679
num_objs 0
set03_V000_I01079
num_objs 0
set02_V006_I00839
num_objs 0
set04_V006_I00659
num_objs 0
set03_V004_I00029
num_objs 0
set00_V009_I01319
num_objs 1
set04_V000_I01559
num_objs 0
set00_V007_I00419
num_objs 3
set03_V009_I00719
num_objs 2
set00_V013_I00569
num_objs 0
set03_V007_I00689
num_objs 0
set01_V004_I01679
num_objs 0
set00_V008_I01589
num_objs 0
set00_V011_I01079
num_objs 13
set05_V010_I00059
num_objs 1
set02_V008_I01589
num_objs 0
set00_V008_I00119
num_objs 7
set02_V001_I01319
num_objs 0
set00_V005_I00539
num_objs 0
set01_V005_I01739
num_objs 1
set03_V001_I01679
num_objs 0
set04_V005_I00449
num_objs 0
set03_V003_I00389
num_objs 1
set04_V001_I00509
num_objs 0
set04_V009_I00779
num_objs 0
set02_V007_I01079
num_objs 0
set05_V006_I00899
num_objs 0
set00_V013_I00899
num_objs 1
set03_V012_I00509
num_objs 0
set04_V009_I01349
num_objs 0
set01_V003_I01829
num_objs 6
set00_V000_I01379
num_objs 0
set03_V002_I00539
num_objs 0
set01_V004_I01169
num_objs 7
set00_V013_I00479
num_objs 2
set04_V006_I00029
num_objs 0
set00_V001_I01379
num_objs 3
set00_V011_I00749
num_objs 0
set04_V007_I01589
num_objs 1
set05_V001_I00659
num_objs 0
set01_V000_I00599
num_objs 4
set01_V004_I00569
num_objs 1
set02_V006_I00029
num_objs 0
set03_V008_I01199
num_objs 4
set03_V012_I00299
num_objs 0
set02_V004_I00449
num_objs 0
set03_V007_I01499
num_objs 0
set02_V011_I01019
num_objs 0
set00_V005_I01289
num_objs 0
set02_V005_I01829
num_objs 0
set04_V001_I01199
num_objs 0
set05_V000_I01379
num_objs 2
set02_V009_I01319
num_objs 0
set05_V000_I01589
num_objs 1
set02_V005_I01619
num_objs 0
set03_V005_I00449
num_objs 2
set04_V000_I00449
num_objs 0
set03_V002_I01079
num_objs 0
set04_V011_I00749
num_objs 0
set05_V003_I00479
num_objs 0
set05_V008_I01349
num_objs 0
set03_V003_I00899
num_objs 1
set00_V006_I00869
num_objs 0
set05_V009_I01229
num_objs 0
set04_V011_I00329
num_objs 1
set02_V001_I00539
num_objs 0
set03_V000_I01379
num_objs 0
set00_V002_I00029
num_objs 0
set04_V001_I00179
num_objs 0
set03_V003_I01319
num_objs 0
set03_V003_I01079
num_objs 1
set03_V000_I00479
num_objs 0
set04_V006_I01109
num_objs 0
set05_V008_I00839
num_objs 0
set02_V007_I01589
num_objs 0
set04_V003_I01559
num_objs 1
set04_V002_I01289
num_objs 0
set05_V009_I01439
num_objs 0
set03_V000_I00419
num_objs 0
set05_V011_I00389
num_objs 0
set02_V005_I00269
num_objs 0
set00_V010_I01289
num_objs 7
set03_V004_I00209
num_objs 0
set03_V007_I00029
num_objs 0
set02_V009_I00569
num_objs 2
set04_V004_I01469
num_objs 0
set03_V008_I00929
num_objs 5
set00_V012_I00749
num_objs 2
set05_V009_I00599
num_objs 0
set04_V010_I01709
num_objs 1
set00_V008_I01259
num_objs 3
set04_V009_I01829
num_objs 0
set04_V006_I01799
num_objs 0
set05_V001_I01439
num_objs 0
set02_V005_I00149
num_objs 0
set03_V009_I00809
num_objs 0
set01_V004_I01499
num_objs 3
set02_V000_I00809
num_objs 0
set03_V001_I00989
num_objs 0
set00_V000_I00299
num_objs 0
set04_V002_I01499
num_objs 2
set02_V002_I00299
num_objs 0
set03_V009_I01439
num_objs 0
set04_V006_I01739
num_objs 0
set03_V000_I01349
num_objs 0
set03_V008_I00959
num_objs 6
set02_V005_I00869
num_objs 0
set00_V008_I01649
num_objs 0
set00_V013_I00269
num_objs 6
set03_V010_I01799
num_objs 1
set02_V004_I00989
num_objs 0
set05_V007_I00029
num_objs 0
set00_V005_I00839
num_objs 1
set02_V005_I00479
num_objs 0
set01_V000_I01169
num_objs 2
set00_V006_I01319
num_objs 3
set05_V008_I00149
num_objs 0
set04_V004_I00359
num_objs 0
set04_V002_I00419
num_objs 0
set00_V010_I00869
num_objs 3
set02_V009_I00239
num_objs 0
set02_V011_I01259
num_objs 0
set00_V008_I00449
num_objs 17
set00_V008_I01349
num_objs 2
set01_V002_I01529
num_objs 0
set02_V008_I01799
num_objs 0
set02_V007_I01409
num_objs 0
set04_V005_I01649
num_objs 2
set04_V010_I01739
num_objs 0
set05_V007_I00509
num_objs 0
set02_V006_I00389
num_objs 0
set05_V010_I00959
num_objs 0
set00_V005_I00149
num_objs 0
set01_V003_I01799
num_objs 7
set03_V004_I01649
num_objs 0
set05_V002_I01079
num_objs 0
set04_V001_I01289
num_objs 0
set03_V002_I00599
num_objs 0
set02_V008_I01019
num_objs 0
set04_V004_I00479
num_objs 1
set04_V005_I01559
num_objs 0
set04_V000_I00989
num_objs 1
set03_V012_I01619
num_objs 1
set05_V012_I01139
num_objs 0
set05_V003_I01349
num_objs 2
set00_V008_I00749
num_objs 1
set03_V012_I01289
num_objs 0
set01_V001_I01469
num_objs 5
set02_V001_I01799
num_objs 0
set02_V002_I01589
num_objs 0
set04_V009_I01529
num_objs 0
set03_V001_I01439
num_objs 0
set01_V000_I01409
num_objs 1
set05_V009_I01739
num_objs 0
set04_V003_I00659
num_objs 0
set05_V006_I00839
num_objs 0
set05_V009_I00449
num_objs 0
set03_V003_I00869
num_objs 0
set04_V008_I00659
num_objs 0
set03_V011_I00749
num_objs 1
set03_V011_I01799
num_objs 0
set02_V005_I01109
num_objs 0
set03_V009_I00479
num_objs 2
set02_V009_I01649
num_objs 0
set00_V011_I00119
num_objs 3
set02_V009_I00539
num_objs 0
set02_V010_I00779
num_objs 1
set00_V000_I00539
num_objs 1
set04_V004_I00659
num_objs 2
set01_V005_I01319
num_objs 1
set03_V003_I00209
num_objs 1
set00_V013_I00779
num_objs 1
set00_V004_I01319
num_objs 10
set00_V011_I01529
num_objs 5
set03_V005_I00239
num_objs 1
set01_V003_I01499
num_objs 1
set05_V012_I00779
num_objs 0
set00_V013_I00659
num_objs 2
set01_V004_I01709
num_objs 0
set03_V002_I00659
num_objs 0
set05_V003_I01439
num_objs 0
set02_V010_I01379
num_objs 0
set00_V005_I01739
num_objs 0
set01_V002_I01589
num_objs 3
set02_V000_I01049
num_objs 0
set00_V005_I01019
num_objs 0
set02_V001_I01019
num_objs 0
set03_V007_I01229
num_objs 0
set01_V001_I00509
num_objs 1
set01_V004_I00959
num_objs 9
set05_V005_I00659
num_objs 1
set05_V009_I00419
num_objs 0
set05_V007_I00899
num_objs 0
set04_V001_I00089
num_objs 0
set01_V002_I01469
num_objs 1
set03_V012_I01349
num_objs 3
set02_V004_I01739
num_objs 0
set04_V000_I00929
num_objs 1
set05_V005_I00149
num_objs 0
set04_V003_I01199
num_objs 3
set05_V003_I00239
num_objs 0
set03_V010_I01469
num_objs 1
set02_V000_I01769
num_objs 0
set04_V002_I00479
num_objs 0
set00_V001_I01139
num_objs 1
set02_V008_I00809
num_objs 0
set05_V005_I00809
num_objs 1
set01_V002_I00209
num_objs 4
set00_V011_I00029
num_objs 2
set02_V008_I01049
num_objs 0
set03_V001_I01499
num_objs 0
set02_V010_I00629
num_objs 0
set02_V001_I00959
num_objs 0
set04_V003_I01709
num_objs 0
set04_V010_I01589
num_objs 2
set03_V009_I00869
num_objs 0
set04_V002_I00869
num_objs 1
set05_V002_I01679
num_objs 0
set00_V002_I00209
num_objs 2
set04_V007_I00959
num_objs 1
set04_V005_I00539
num_objs 0
set02_V009_I00599
num_objs 2
set02_V000_I01799
num_objs 0
set00_V001_I00539
num_objs 2
set02_V010_I01559
num_objs 0
set05_V005_I01379
num_objs 0
set02_V008_I01139
num_objs 1
set00_V012_I00959
num_objs 8
set01_V001_I00089
num_objs 1
set05_V002_I01499
num_objs 0
set02_V006_I00659
num_objs 0
set03_V012_I00539
num_objs 0
set02_V009_I01439
num_objs 0
set00_V006_I00659
num_objs 3
set00_V010_I01379
num_objs 7
set03_V002_I01049
num_objs 0
set01_V005_I00359
num_objs 2
set02_V001_I00029
num_objs 0
set02_V008_I01559
num_objs 0
set02_V004_I01049
num_objs 0
set02_V001_I00209
num_objs 0
set05_V012_I00689
num_objs 1
set05_V001_I00719
num_objs 0
set05_V000_I01349
num_objs 0
set03_V004_I00629
num_objs 1
set02_V005_I00539
num_objs 0
set04_V001_I00389
num_objs 0
set05_V001_I01469
num_objs 0
set02_V001_I01589
num_objs 1
set04_V002_I00929
num_objs 1
set00_V000_I01199
num_objs 0
set03_V010_I00029
num_objs 0
set01_V005_I00899
num_objs 1
set02_V005_I00809
num_objs 0
set00_V014_I01349
num_objs 0
set03_V004_I00929
num_objs 0
set00_V010_I00029
num_objs 7
set00_V011_I01229
num_objs 2
set05_V012_I01379
num_objs 0
set00_V011_I00419
num_objs 1
set04_V005_I00839
num_objs 1
set03_V010_I01049
num_objs 1
set00_V012_I01589
num_objs 0
set04_V008_I01829
num_objs 0
set04_V005_I00029
num_objs 0
set02_V000_I01019
num_objs 0
set05_V010_I01229
num_objs 0
set00_V013_I00839
num_objs 1
set00_V002_I00239
num_objs 2
set02_V011_I01109
num_objs 0
set00_V011_I00779
num_objs 1
set03_V008_I01499
num_objs 4
set00_V011_I01049
num_objs 10
set00_V007_I00059
num_objs 0
set05_V008_I00869
num_objs 0
set00_V001_I00449
num_objs 1
set02_V009_I00329
num_objs 2
set03_V000_I01439
num_objs 0
set04_V004_I00389
num_objs 0
set05_V011_I00869
num_objs 6
set00_V001_I01019
num_objs 8
set05_V011_I01619
num_objs 1
set03_V002_I00779
num_objs 0
set03_V003_I00959
num_objs 0
set05_V012_I00359
num_objs 1
set03_V001_I00539
num_objs 0
set03_V010_I00239
num_objs 0
set02_V008_I00449
num_objs 0
set03_V002_I00749
num_objs 0
set00_V009_I01199
num_objs 0
set05_V006_I00569
num_objs 0
set02_V004_I01409
num_objs 0
set02_V008_I01169
num_objs 0
set03_V011_I00689
num_objs 1
set03_V011_I01049
num_objs 0
set00_V004_I01049
num_objs 1
set04_V011_I01679
num_objs 0
set03_V010_I01709
num_objs 1
set04_V010_I01109
num_objs 0
set05_V011_I00839
num_objs 2
set01_V002_I00899
num_objs 4
set03_V006_I00299
num_objs 0
set02_V008_I01379
num_objs 0
set02_V003_I01769
num_objs 0
set04_V005_I00089
num_objs 1
set04_V000_I00269
num_objs 0
set00_V003_I00389
num_objs 0
set00_V001_I00509
num_objs 3
set03_V005_I00359
num_objs 1
set05_V000_I00479
num_objs 1
set02_V007_I00029
num_objs 0
set03_V010_I00569
num_objs 0
set04_V005_I00269
num_objs 1
set00_V007_I01319
num_objs 5
set04_V011_I00089
num_objs 0
set00_V008_I00719
num_objs 3
set00_V008_I01379
num_objs 3
set01_V001_I01109
num_objs 1
set02_V007_I00479
num_objs 1
set04_V002_I01199
num_objs 1
set02_V001_I01379
num_objs 0
set05_V004_I01619
num_objs 0
set02_V004_I01259
num_objs 0
set00_V007_I00479
num_objs 2
set03_V009_I01559
num_objs 2
set03_V003_I00569
num_objs 3
set03_V012_I01319
num_objs 2
set04_V004_I01289
num_objs 1
set01_V002_I00599
num_objs 6
set05_V006_I00809
num_objs 0
set03_V009_I00599
num_objs 3
set05_V008_I01049
num_objs 0
set03_V005_I01739
num_objs 2
set03_V008_I00899
num_objs 9
set01_V002_I01319
num_objs 6
set05_V012_I00029
num_objs 0
set00_V002_I00809
num_objs 5
set05_V004_I01769
num_objs 0
set04_V004_I00419
num_objs 0
set02_V001_I01259
num_objs 0
set01_V001_I01589
num_objs 1
set00_V005_I01949
num_objs 0
set03_V003_I00269
num_objs 1
set03_V000_I00659
num_objs 0
set05_V011_I00149
num_objs 0
set03_V005_I00149
num_objs 0
set02_V006_I00929
num_objs 0
set00_V011_I00929
num_objs 3
set05_V003_I00179
num_objs 0
set04_V000_I01409
num_objs 0
set03_V009_I01799
num_objs 3
set05_V008_I00419
num_objs 0
set01_V000_I01649
num_objs 3
set02_V009_I01829
num_objs 0
set05_V010_I00689
num_objs 0
set02_V002_I00089
num_objs 0
set00_V008_I01109
num_objs 1
set05_V005_I01679
num_objs 0
set03_V004_I01079
num_objs 0
set03_V004_I01289
num_objs 0
set04_V008_I01049
num_objs 1
set03_V006_I00509
num_objs 0
set03_V010_I00329
num_objs 0
set02_V004_I01499
num_objs 0
set00_V002_I00089
num_objs 0
set00_V010_I01499
num_objs 2
set02_V003_I01649
num_objs 0
set05_V011_I00479
num_objs 0
set00_V000_I00659
num_objs 0
set05_V000_I00959
num_objs 0
set03_V003_I01499
num_objs 0
set05_V012_I00299
num_objs 0
set01_V004_I00719
num_objs 2
set00_V014_I01139
num_objs 1
set00_V014_I01679
num_objs 5
set03_V006_I00239
num_objs 0
set05_V006_I01139
num_objs 0
set00_V008_I00779
num_objs 2
set01_V002_I01139
num_objs 1
set03_V003_I01259
num_objs 0
set05_V009_I01589
num_objs 0
set05_V005_I01079
num_objs 1
set01_V004_I00179
num_objs 2
set02_V002_I00719
num_objs 0
set04_V001_I00659
num_objs 0
set03_V005_I01469
num_objs 1
set03_V006_I01139
num_objs 0
set05_V004_I01709
num_objs 0
set03_V000_I00989
num_objs 0
set03_V011_I01259
num_objs 1
set03_V001_I01829
num_objs 0
set03_V000_I01469
num_objs 0
set04_V010_I01199
num_objs 0
set05_V004_I01469
num_objs 0
set05_V004_I00869
num_objs 0
set03_V005_I00119
num_objs 0
set01_V004_I00239
num_objs 2
set02_V010_I01709
num_objs 0
set04_V005_I01199
num_objs 0
set00_V004_I01919
num_objs 0
set00_V012_I00059
num_objs 0
set05_V011_I01049
num_objs 5
set04_V001_I00299
num_objs 0
set03_V008_I00809
num_objs 13
set02_V005_I01799
num_objs 0
set02_V003_I00989
num_objs 0
set05_V004_I00479
num_objs 2
set05_V011_I01229
num_objs 1
set04_V005_I00599
num_objs 0
set01_V002_I00839
num_objs 8
set05_V010_I01649
num_objs 1
set01_V002_I00179
num_objs 1
set05_V005_I00299
num_objs 1
set02_V001_I00479
num_objs 0
set04_V003_I00779
num_objs 0
set02_V005_I00389
num_objs 0
set03_V004_I01799
num_objs 0
set00_V013_I00719
num_objs 1
set00_V007_I01619
num_objs 2
set04_V003_I01529
num_objs 0
set03_V009_I01109
num_objs 5
set03_V008_I00449
num_objs 14
set00_V012_I00509
num_objs 3
set02_V002_I00599
num_objs 0
set03_V009_I00569
num_objs 2
set04_V001_I01559
num_objs 0
set05_V000_I01259
num_objs 0
set00_V006_I01559
num_objs 2
set00_V011_I00269
num_objs 1
set04_V001_I01319
num_objs 0
set04_V001_I00359
num_objs 0
set00_V011_I00149
num_objs 1
set03_V005_I01019
num_objs 0
set00_V004_I01979
num_objs 0
set00_V009_I01019
num_objs 1
set05_V004_I01589
num_objs 0
set03_V004_I01589
num_objs 0
set04_V004_I01679
num_objs 0
set00_V010_I01049
num_objs 2
set04_V004_I01739
num_objs 0
set02_V006_I00329
num_objs 0
set02_V004_I00959
num_objs 0
set02_V005_I01319
num_objs 0
set00_V009_I01679
num_objs 7
set02_V003_I00209
num_objs 1
set00_V004_I00659
num_objs 0
set05_V004_I00509
num_objs 0
set04_V003_I01739
num_objs 2
set05_V010_I01139
num_objs 0
set05_V000_I00089
num_objs 0
set05_V004_I01529
num_objs 0
set03_V012_I00089
num_objs 0
set05_V000_I00869
num_objs 0
set00_V006_I00899
num_objs 2
set00_V011_I00299
num_objs 1
set05_V009_I00749
num_objs 0
set04_V005_I00719
num_objs 1
set00_V002_I00509
num_objs 0
set01_V002_I01679
num_objs 3
set00_V002_I00869
num_objs 9
set03_V003_I00059
num_objs 2
set04_V003_I00449
num_objs 1
set00_V010_I01529
num_objs 2
set03_V010_I00209
num_objs 0
set05_V001_I00299
num_objs 0
set02_V000_I00089
num_objs 0
set00_V007_I01829
num_objs 3
set00_V007_I01799
num_objs 3
set04_V003_I00599
num_objs 0
set03_V012_I00209
num_objs 0
set02_V009_I00029
num_objs 0
set05_V000_I00569
num_objs 2
set04_V004_I01259
num_objs 1
set00_V005_I00479
num_objs 0
set04_V011_I01799
num_objs 1
set05_V003_I00509
num_objs 0
set05_V003_I01229
num_objs 3
set03_V012_I01799
num_objs 0
set04_V002_I00269
num_objs 0
set00_V004_I01619
num_objs 0
set04_V000_I01589
num_objs 0
set05_V004_I01829
num_objs 0
set03_V010_I01109
num_objs 0
set03_V010_I01259
num_objs 0
set00_V012_I01679
num_objs 1
set03_V012_I00749
num_objs 0
set00_V011_I00689
num_objs 1
set05_V005_I00779
num_objs 1
set01_V005_I00569
num_objs 2
set04_V006_I00179
num_objs 0
set00_V008_I00269
num_objs 0
set03_V000_I00509
num_objs 0
set01_V000_I00389
num_objs 1
set00_V000_I00239
num_objs 3
set02_V008_I01829
num_objs 0
set01_V004_I01769
num_objs 0
set05_V007_I01139
num_objs 0
set05_V004_I01799
num_objs 0
set02_V000_I00569
num_objs 0
set02_V005_I00689
num_objs 0
set03_V007_I00059
num_objs 0
set05_V007_I00479
num_objs 0
set02_V002_I00689
num_objs 0
set04_V004_I00509
num_objs 0
set04_V007_I01409
num_objs 0
set00_V006_I00989
num_objs 0
set00_V002_I00299
num_objs 1
set00_V010_I01259
num_objs 6
set05_V002_I00569
num_objs 1
set00_V012_I01649
num_objs 1
set04_V009_I01379
num_objs 0
set00_V008_I00329
num_objs 0
set03_V006_I00569
num_objs 0
set05_V011_I00539
num_objs 0
set00_V010_I01439
num_objs 4
set04_V010_I01559
num_objs 1
set01_V003_I00959
num_objs 5
set00_V007_I01499
num_objs 2
set02_V000_I00929
num_objs 0
set03_V001_I01109
num_objs 0
set05_V009_I01529
num_objs 0
set05_V011_I00269
num_objs 0
set02_V010_I00209
num_objs 1
set00_V008_I00929
num_objs 1
set03_V001_I01349
num_objs 0
set05_V011_I01559
num_objs 0
set03_V005_I00599
num_objs 2
set02_V002_I00929
num_objs 0
set05_V010_I00809
num_objs 0
set05_V001_I01949
num_objs 0
set00_V001_I00389
num_objs 3
set01_V003_I00209
num_objs 8
set02_V009_I00779
num_objs 1
set01_V001_I01649
num_objs 2
set04_V000_I01499
num_objs 0
set04_V004_I00599
num_objs 2
set00_V000_I01589
num_objs 2
set00_V013_I01589
num_objs 4
set00_V014_I01409
num_objs 1
set05_V007_I00629
num_objs 0
set00_V013_I00119
num_objs 4
set02_V008_I00659
num_objs 0
set01_V000_I01049
num_objs 2
set04_V007_I00569
num_objs 1
set03_V009_I01829
num_objs 0
set04_V002_I00989
num_objs 2
set05_V007_I00119
num_objs 0
set02_V004_I00359
num_objs 0
set03_V004_I01559
num_objs 0
set00_V011_I00539
num_objs 2
set01_V004_I00329
num_objs 0
set01_V001_I01019
num_objs 1
set05_V004_I00569
num_objs 0
set04_V006_I00479
num_objs 0
set05_V008_I01529
num_objs 0
set00_V004_I01859
num_objs 0
set00_V006_I00179
num_objs 3
set01_V004_I00599
num_objs 1
set02_V011_I01559
num_objs 2
set04_V000_I00719
num_objs 2
set03_V005_I01349
num_objs 1
set03_V011_I00899
num_objs 1
set02_V002_I00629
num_objs 0
set03_V006_I00119
num_objs 0
set03_V012_I00899
num_objs 0
set04_V001_I01169
num_objs 0
set03_V006_I01739
num_objs 0
set02_V000_I01619
num_objs 0
set04_V011_I00809
num_objs 0
set02_V010_I01799
num_objs 0
set03_V012_I01829
num_objs 0
set02_V006_I01769
num_objs 0
set02_V007_I00539
num_objs 0
set03_V009_I01229
num_objs 0
set00_V012_I00479
num_objs 5
set02_V000_I01229
num_objs 0
set04_V001_I01139
num_objs 0
set05_V002_I01199
num_objs 0
set02_V011_I01769
num_objs 2
set02_V010_I00179
num_objs 1
set04_V006_I00749
num_objs 0
set03_V003_I01469
num_objs 0
set00_V013_I00209
num_objs 2
set04_V005_I00509
num_objs 0
set03_V001_I00869
num_objs 0
set05_V004_I00209
num_objs 0
set04_V002_I00779
num_objs 2
set00_V004_I02039
num_objs 0
set05_V006_I01739
num_objs 0
set00_V004_I00749
num_objs 0
set05_V008_I01769
num_objs 0
set03_V008_I01169
num_objs 0
set00_V008_I00089
num_objs 7
set00_V013_I01199
num_objs 1
set02_V011_I01169
num_objs 0
set03_V004_I00239
num_objs 0
set02_V003_I01109
num_objs 0
set02_V002_I01079
num_objs 0
set03_V006_I01799
num_objs 0
set02_V003_I01469
num_objs 0
set05_V010_I01769
num_objs 0
set00_V009_I00269
num_objs 11
set03_V003_I00659
num_objs 0
set00_V014_I00389
num_objs 3
set04_V004_I01769
num_objs 0
set03_V012_I01559
num_objs 2
set00_V003_I00419
num_objs 0
set05_V010_I00389
num_objs 0
set01_V002_I01379
num_objs 2
set00_V000_I01049
num_objs 0
set00_V002_I00929
num_objs 5
set02_V001_I01739
num_objs 0
set00_V004_I01439
num_objs 15
set04_V000_I00179
num_objs 0
set04_V007_I00269
num_objs 1
set00_V004_I00689
num_objs 0
set05_V005_I01589
num_objs 1
set02_V010_I00869
num_objs 0
set03_V009_I01679
num_objs 2
set00_V009_I00299
num_objs 6
set04_V002_I00149
num_objs 0
set02_V001_I00599
num_objs 0
set01_V005_I01079
num_objs 3
set05_V001_I01259
num_objs 0
set05_V000_I00629
num_objs 0
set04_V010_I00629
num_objs 0
set03_V006_I00959
num_objs 0
set04_V008_I00719
num_objs 0
set01_V005_I00239
num_objs 2
set03_V008_I00329
num_objs 14
set02_V007_I01499
num_objs 0
set01_V004_I00899
num_objs 7
set03_V010_I01229
num_objs 0
set02_V010_I00299
num_objs 0
set02_V008_I01649
num_objs 0
set01_V003_I00659
num_objs 2
set04_V002_I01319
num_objs 1
set02_V004_I01589
num_objs 0
set04_V002_I00209
num_objs 0
set03_V001_I00719
num_objs 0
set02_V011_I00419
num_objs 0
set03_V007_I00599
num_objs 0
set03_V000_I01169
num_objs 0
set04_V002_I01769
num_objs 0
set05_V005_I01199
num_objs 0
set05_V005_I01499
num_objs 0
set05_V012_I01019
num_objs 1
set01_V002_I01109
num_objs 3
set01_V000_I00479
num_objs 0
set00_V012_I00929
num_objs 7
set01_V005_I00509
num_objs 1
set00_V004_I00479
num_objs 1
set03_V012_I00989
num_objs 0
set05_V001_I01019
num_objs 0
set04_V003_I01769
num_objs 1
set03_V001_I00269
num_objs 0
set04_V005_I00899
num_objs 0
set04_V003_I00209
num_objs 0
set03_V002_I00719
num_objs 0
set04_V008_I00959
num_objs 0
set00_V004_I01799
num_objs 0
set01_V000_I00989
num_objs 0
set03_V000_I00089
num_objs 0
set04_V000_I00539
num_objs 3
set00_V001_I01829
num_objs 0
set02_V003_I00299
num_objs 2
set04_V001_I01589
num_objs 1
set05_V009_I00809
num_objs 0
set03_V012_I00119
num_objs 0
set03_V003_I00749
num_objs 1
set00_V007_I00029
num_objs 0
set05_V002_I01319
num_objs 0
set00_V012_I00029
num_objs 0
set05_V008_I00539
num_objs 0
set01_V002_I00239
num_objs 3
set05_V009_I00389
num_objs 0
set00_V006_I01259
num_objs 5
set03_V010_I00389
num_objs 0
set02_V007_I01439
num_objs 0
set03_V012_I00599
num_objs 0
set03_V000_I01229
num_objs 0
set03_V010_I01019
num_objs 1
set04_V005_I00299
num_objs 0
set01_V003_I01169
num_objs 0
set05_V004_I01079
num_objs 0
set02_V001_I01559
num_objs 0
set03_V011_I00959
num_objs 1
set00_V007_I00599
num_objs 1
set02_V011_I00569
num_objs 1
set00_V014_I00989
num_objs 0
set00_V007_I01679
num_objs 3
set01_V001_I00389
num_objs 3
set00_V008_I01499
num_objs 2
set03_V009_I00539
num_objs 4
set04_V001_I01679
num_objs 1
set01_V005_I01469
num_objs 0
set00_V000_I01409
num_objs 0
set00_V006_I00359
num_objs 1
set00_V010_I01469
num_objs 2
set02_V001_I01409
num_objs 0
set02_V010_I00149
num_objs 1
set05_V000_I00029
num_objs 0
set05_V002_I01649
num_objs 0
set03_V010_I01349
num_objs 0
set02_V006_I01619
num_objs 0
set05_V010_I00419
num_objs 1
set00_V009_I01619
num_objs 4
set03_V007_I00749
num_objs 0
set00_V003_I00119
num_objs 1
set05_V011_I00719
num_objs 0
set01_V002_I01739
num_objs 3
set05_V004_I00449
num_objs 2
set03_V007_I01739
num_objs 0
set00_V006_I00719
num_objs 4
set02_V002_I01709
num_objs 0
set00_V005_I02069
num_objs 0
set02_V005_I01529
num_objs 0
set04_V009_I00329
num_objs 0
set05_V008_I00569
num_objs 0
set02_V003_I01889
num_objs 0
set02_V006_I00359
num_objs 0
set05_V007_I01589
num_objs 0
set00_V012_I00569
num_objs 0
set03_V003_I00509
num_objs 2
set04_V002_I01709
num_objs 2
set03_V004_I01229
num_objs 0
set04_V008_I00989
num_objs 0
set04_V008_I00509
num_objs 0
set00_V004_I01409
num_objs 13
set02_V009_I00959
num_objs 0
set05_V012_I00509
num_objs 2
set00_V012_I00209
num_objs 1
set03_V003_I01649
num_objs 0
set03_V005_I00179
num_objs 0
set03_V010_I00929
num_objs 0
set01_V002_I00449
num_objs 2
set01_V005_I01139
num_objs 5
set05_V011_I00809
num_objs 1
set02_V008_I00479
num_objs 0
set02_V010_I01439
num_objs 0
set05_V004_I00269
num_objs 0
set05_V000_I01289
num_objs 0
set05_V001_I01409
num_objs 0
set02_V011_I01499
num_objs 0
set05_V001_I00989
num_objs 0
set04_V002_I00839
num_objs 1
set00_V013_I01439
num_objs 5
set04_V002_I01589
num_objs 1
set00_V011_I01019
num_objs 13
set04_V003_I01409
num_objs 3
set00_V004_I02099
num_objs 0
set05_V000_I01439
num_objs 0
set02_V007_I01679
num_objs 0
set00_V013_I00329
num_objs 5
set00_V008_I01019
num_objs 1
set05_V012_I00749
num_objs 1
set00_V010_I00449
num_objs 6
set04_V000_I01799
num_objs 0
set03_V007_I01049
num_objs 0
set04_V011_I00239
num_objs 0
set00_V014_I00449
num_objs 1
set04_V000_I00389
num_objs 0
set00_V010_I00269
num_objs 3
set03_V011_I00389
num_objs 3
set02_V005_I00419
num_objs 0
set02_V007_I00659
num_objs 0
set04_V004_I00119
num_objs 0
set04_V008_I00119
num_objs 0
set05_V001_I00929
num_objs 0
set00_V010_I00359
num_objs 5
set03_V012_I00059
num_objs 0
set01_V000_I01229
num_objs 2
set04_V007_I00599
num_objs 1
set05_V012_I00659
num_objs 1
set04_V006_I01079
num_objs 0
set04_V009_I01409
num_objs 0
set02_V004_I00599
num_objs 0
set03_V008_I00479
num_objs 19
set00_V014_I01649
num_objs 3
set04_V009_I01769
num_objs 0
set00_V011_I01289
num_objs 3
set01_V004_I00449
num_objs 0
set04_V010_I01409
num_objs 0
set02_V003_I01529
num_objs 0
set04_V011_I00659
num_objs 0
set00_V003_I00269
num_objs 0
set03_V000_I00929
num_objs 0
set00_V012_I00179
num_objs 1
set02_V008_I00269
num_objs 0
set01_V002_I01349
num_objs 5
set04_V005_I01409
num_objs 0
set00_V001_I01079
num_objs 3
set00_V004_I00449
num_objs 0
set04_V010_I00329
num_objs 0
set01_V000_I00659
num_objs 1
set00_V006_I01859
num_objs 4
set03_V000_I01739
num_objs 0
set04_V010_I00089
num_objs 0
set04_V005_I01259
num_objs 0
set02_V004_I01439
num_objs 0
set03_V008_I00539
num_objs 18
set03_V006_I00449
num_objs 0
set03_V000_I00809
num_objs 0
set01_V000_I01679
num_objs 1
set04_V011_I00059
num_objs 0
set03_V003_I00359
num_objs 1
set04_V002_I01559
num_objs 1
set03_V005_I00269
num_objs 0
set00_V014_I01709
num_objs 6
set05_V009_I01379
num_objs 0
set00_V004_I00029
num_objs 0
set00_V004_I00509
num_objs 0
set05_V006_I01289
num_objs 0
set05_V003_I00989
num_objs 1
set05_V002_I01109
num_objs 1
set03_V006_I00749
num_objs 0
set01_V000_I01439
num_objs 5
set04_V006_I00449
num_objs 0
set02_V011_I00629
num_objs 1
set03_V001_I01649
num_objs 0
set05_V009_I01679
num_objs 0
set04_V003_I00329
num_objs 0
set02_V005_I00059
num_objs 0
set01_V003_I00509
num_objs 1
set00_V003_I00509
num_objs 0
set02_V006_I01289
num_objs 0
set01_V005_I01259
num_objs 0
set01_V004_I01289
num_objs 6
set03_V000_I00029
num_objs 0
set00_V012_I01409
num_objs 5
set02_V011_I01199
num_objs 0
set04_V005_I00659
num_objs 0
set00_V007_I01649
num_objs 4
set00_V013_I01349
num_objs 5
set02_V009_I00419
num_objs 0
set05_V007_I00719
num_objs 0
set00_V012_I00629
num_objs 0
set01_V004_I00419
num_objs 0
set03_V011_I00929
num_objs 0
set03_V010_I01829
num_objs 2
set04_V001_I00029
num_objs 0
set05_V001_I00329
num_objs 0
set03_V007_I00419
num_objs 0
set04_V008_I01139
num_objs 1
set00_V001_I01499
num_objs 1
set03_V011_I01499
num_objs 0
set00_V006_I01799
num_objs 4
set05_V006_I01049
num_objs 0
set03_V005_I00089
num_objs 0
set03_V007_I00359
num_objs 0
set02_V004_I00749
num_objs 0
set03_V009_I00629
num_objs 2
set03_V001_I00809
num_objs 1
set03_V001_I01379
num_objs 0
set04_V004_I01589
num_objs 0
set04_V001_I00539
num_objs 0
set03_V009_I01469
num_objs 1
set05_V012_I01229
num_objs 0
set02_V004_I00539
num_objs 0
set05_V005_I00959
num_objs 0
set03_V005_I00689
num_objs 0
set03_V006_I00539
num_objs 0
set00_V004_I01529
num_objs 13
set00_V010_I00389
num_objs 6
set03_V008_I00119
num_objs 18
set02_V010_I00599
num_objs 2
set05_V001_I00839
num_objs 0
set05_V009_I00119
num_objs 0
set02_V001_I00659
num_objs 0
set04_V009_I00389
num_objs 0
set04_V011_I00509
num_objs 0
set00_V004_I01139
num_objs 14
set03_V006_I01259
num_objs 0
set04_V010_I00359
num_objs 0
set02_V008_I01499
num_objs 0
set01_V000_I01529
num_objs 2
set02_V003_I01589
num_objs 0
set01_V002_I00359
num_objs 5
set05_V001_I01589
num_objs 0
set02_V002_I00569
num_objs 0
set05_V009_I00839
num_objs 1
set00_V001_I00959
num_objs 5
set03_V007_I01139
num_objs 0
set05_V005_I00089
num_objs 1
set04_V001_I00239
num_objs 0
set00_V001_I00779
num_objs 2
set02_V001_I01679
num_objs 0
set05_V004_I00119
num_objs 1
set00_V009_I00449
num_objs 1
set01_V001_I00659
num_objs 3
set03_V011_I01079
num_objs 0
set02_V011_I00179
num_objs 0
set03_V009_I00689
num_objs 3
set00_V014_I00209
num_objs 4
set03_V004_I01439
num_objs 0
set01_V005_I00629
num_objs 3
set02_V011_I00029
num_objs 0
set00_V014_I01019
num_objs 2
set02_V003_I00389
num_objs 0
set01_V000_I00899
num_objs 1
set03_V011_I01019
num_objs 0
set00_V008_I00029
num_objs 5
set02_V009_I01739
num_objs 0
set03_V005_I00029
num_objs 0
set05_V002_I00479
num_objs 1
set05_V003_I01289
num_objs 2
set00_V010_I01019
num_objs 1
set05_V002_I00899
num_objs 0
set01_V004_I00809
num_objs 1
set03_V011_I00839
num_objs 1
set02_V011_I00329
num_objs 0
set04_V003_I00479
num_objs 0
set03_V001_I00239
num_objs 0
set00_V007_I01289
num_objs 6
set04_V010_I01079
num_objs 0
set00_V004_I02009
num_objs 0
set05_V005_I00539
num_objs 1
set00_V004_I00209
num_objs 0
set05_V010_I00509
num_objs 0
set00_V007_I00539
num_objs 2
set02_V006_I01559
num_objs 0
set04_V006_I01199
num_objs 0
set03_V003_I00479
num_objs 2
set04_V010_I00509
num_objs 1
set04_V007_I01619
num_objs 1
set04_V009_I00539
num_objs 0
set00_V001_I01259
num_objs 1
set05_V002_I00959
num_objs 0
set02_V009_I01199
num_objs 1
set02_V004_I00389
num_objs 0
set01_V003_I01139
num_objs 0
set02_V011_I00719
num_objs 0
set00_V000_I01709
num_objs 1
set05_V003_I01679
num_objs 1
set04_V001_I00119
num_objs 0
set05_V008_I01079
num_objs 0
set04_V009_I01049
num_objs 0
set02_V001_I00449
num_objs 0
set04_V007_I01229
num_objs 1
set05_V000_I01049
num_objs 0
set03_V008_I00659
num_objs 14
set03_V008_I01709
num_objs 2
set05_V007_I00209
num_objs 0
set04_V010_I00869
num_objs 2
set04_V010_I00599
num_objs 0
set02_V010_I00659
num_objs 0
set04_V011_I00299
num_objs 0
set03_V004_I00389
num_objs 0
set04_V009_I01019
num_objs 0
set05_V002_I00809
num_objs 0
set02_V004_I00659
num_objs 0
set00_V013_I01649
num_objs 1
set04_V008_I01079
num_objs 1
set04_V009_I00929
num_objs 0
set04_V000_I00239
num_objs 0
set03_V005_I01109
num_objs 0
set00_V007_I01709
num_objs 5
set05_V002_I00179
num_objs 0
set04_V007_I01079
num_objs 1
set05_V005_I01739
num_objs 0
set03_V004_I01529
num_objs 0
set02_V008_I00719
num_objs 0
set05_V007_I01709
num_objs 0
set05_V000_I00389
num_objs 0
set04_V001_I00959
num_objs 0
set02_V001_I00299
num_objs 0
set03_V003_I00149
num_objs 2
set05_V011_I01199
num_objs 1
set05_V008_I01709
num_objs 0
set00_V008_I00509
num_objs 10
set02_V005_I01049
num_objs 0
set03_V006_I01349
num_objs 0
set04_V008_I01589
num_objs 0
set04_V005_I01289
num_objs 0
set04_V006_I01559
num_objs 1
set04_V000_I00029
num_objs 0
set02_V011_I01799
num_objs 2
set04_V008_I00179
num_objs 0
set03_V000_I00749
num_objs 0
set03_V004_I00839
num_objs 0
set05_V002_I01769
num_objs 0
set00_V004_I01889
num_objs 0
set04_V000_I00329
num_objs 0
set04_V009_I00149
num_objs 0
set04_V000_I01259
num_objs 0
set02_V008_I01949
num_objs 0
set04_V008_I00779
num_objs 0
set00_V006_I01079
num_objs 3
set01_V004_I00509
num_objs 1
set00_V009_I00479
num_objs 2
set05_V009_I00569
num_objs 0
set03_V012_I01409
num_objs 4
set04_V000_I00869
num_objs 1
set00_V006_I01049
num_objs 3
set05_V005_I00449
num_objs 1
set02_V004_I00899
num_objs 0
set02_V004_I01379
num_objs 0
set03_V004_I00809
num_objs 0
set04_V007_I00479
num_objs 0
set01_V001_I01409
num_objs 5
set02_V009_I00059
num_objs 0
set00_V012_I01139
num_objs 3
set01_V000_I00539
num_objs 1
set04_V008_I00419
num_objs 0
set02_V001_I00149
num_objs 0
set02_V001_I01349
num_objs 0
set00_V013_I01529
num_objs 5
set00_V002_I00779
num_objs 2
set00_V011_I00569
num_objs 1
set02_V010_I01469
num_objs 0
set05_V006_I00599
num_objs 0
set00_V013_I01619
num_objs 2
set00_V005_I00359
num_objs 0
set05_V002_I00629
num_objs 0
set04_V003_I00419
num_objs 0
set04_V011_I01619
num_objs 0
set03_V005_I00779
num_objs 1
set02_V001_I01439
num_objs 1
set04_V009_I00899
num_objs 0
set04_V002_I00749
num_objs 1
set02_V011_I00989
num_objs 0
set04_V003_I00059
num_objs 0
set03_V010_I01559
num_objs 1
set05_V002_I00119
num_objs 1
set04_V003_I01109
num_objs 3
set00_V007_I01739
num_objs 2
set05_V008_I00059
num_objs 0
set03_V010_I00599
num_objs 0
set05_V009_I00689
num_objs 0
set03_V004_I00689
num_objs 0
set01_V001_I01529
num_objs 7
set02_V007_I00179
num_objs 0
set03_V005_I01229
num_objs 0
set04_V003_I01079
num_objs 3
set04_V006_I00899
num_objs 0
set02_V009_I01529
num_objs 0
set03_V006_I00779
num_objs 0
set05_V011_I01289
num_objs 2
set01_V005_I00599
num_objs 3
set03_V002_I00929
num_objs 0
set00_V014_I01289
num_objs 1
set00_V000_I00809
num_objs 0
set03_V001_I01409
num_objs 0
set00_V013_I00029
num_objs 3
set03_V007_I01829
num_objs 0
set04_V011_I01649
num_objs 1
set03_V000_I01829
num_objs 0
set05_V007_I01409
num_objs 1
set00_V006_I01649
num_objs 1
set03_V007_I01349
num_objs 0
set04_V002_I00179
num_objs 0
set05_V008_I01319
num_objs 0
set03_V012_I00929
num_objs 1
set04_V001_I00719
num_objs 0
set01_V000_I01199
num_objs 2
set04_V007_I01739
num_objs 0
set03_V001_I01469
num_objs 0
set01_V000_I00449
num_objs 1
set02_V010_I00269
num_objs 0
set03_V010_I00509
num_objs 0
set00_V014_I00839
num_objs 3
set02_V004_I01679
num_objs 0
set05_V010_I01799
num_objs 0
set03_V002_I00959
num_objs 0
set02_V004_I01709
num_objs 0
set04_V008_I01289
num_objs 0
set02_V008_I00989
num_objs 0
set01_V001_I00299
num_objs 0
set05_V012_I01679
num_objs 0
set05_V008_I00779
num_objs 0
set03_V004_I01709
num_objs 1
set00_V000_I00119
num_objs 0
set05_V004_I01679
num_objs 0
set05_V008_I00029
num_objs 0
set00_V006_I00269
num_objs 3
set00_V007_I00389
num_objs 0
set02_V011_I00839
num_objs 0
set01_V005_I00449
num_objs 3
set05_V001_I01859
num_objs 0
set02_V007_I00329
num_objs 0
set00_V004_I01589
num_objs 0
set03_V008_I01589
num_objs 4
set00_V013_I01469
num_objs 5
set04_V009_I01109
num_objs 0
set05_V007_I01799
num_objs 0
set03_V006_I00809
num_objs 0
set00_V011_I01499
num_objs 0
set03_V005_I00839
num_objs 0
set05_V000_I00269
num_objs 1
set04_V007_I01709
num_objs 1
set05_V010_I00749
num_objs 0
set04_V001_I00779
num_objs 0
set00_V013_I00869
num_objs 2
set00_V012_I01079
num_objs 1
set02_V004_I00569
num_objs 0
set02_V011_I01439
num_objs 0
set03_V004_I01049
num_objs 0
set00_V004_I01199
num_objs 8
set00_V006_I01409
num_objs 3
set00_V012_I01499
num_objs 0
set00_V006_I00569
num_objs 2
set03_V007_I00629
num_objs 0
set00_V000_I01499
num_objs 1
set02_V004_I00179
num_objs 0
set03_V003_I01709
num_objs 0
set00_V005_I01199
num_objs 0
set00_V006_I01229
num_objs 3
set01_V005_I00179
num_objs 1
set02_V010_I01769
num_objs 0
set05_V004_I00989
num_objs 0
set04_V001_I00749
num_objs 0
set01_V005_I00329
num_objs 3
set05_V003_I01199
num_objs 3
set02_V000_I01829
num_objs 0
set00_V010_I00839
num_objs 4
set04_V011_I00929
num_objs 0
set05_V009_I01559
num_objs 0
set00_V014_I00809
num_objs 3
set00_V010_I00119
num_objs 3
set05_V005_I01619
num_objs 1
set00_V001_I00119
num_objs 0
set00_V004_I00629
num_objs 0
set02_V002_I00209
num_objs 0
set05_V009_I00479
num_objs 0
set04_V005_I01319
num_objs 0
set05_V000_I01169
num_objs 0
set02_V010_I01409
num_objs 0
set05_V008_I01169
num_objs 0
set00_V012_I00419
num_objs 2
set02_V000_I00059
num_objs 0
set00_V010_I00239
num_objs 1
set04_V000_I01319
num_objs 0
set05_V001_I00149
num_objs 1
set00_V014_I00959
num_objs 1
set02_V005_I01709
num_objs 0
set02_V001_I00689
num_objs 0
set01_V002_I01019
num_objs 1
set05_V006_I01649
num_objs 0
set03_V006_I01109
num_objs 0
set00_V012_I01349
num_objs 1
set00_V001_I01649
num_objs 0
set04_V003_I01349
num_objs 2
set04_V011_I00719
num_objs 0
set04_V000_I01169
num_objs 0
set03_V005_I01199
num_objs 1
set00_V013_I00239
num_objs 3
set05_V006_I00329
num_objs 0
set04_V007_I01169
num_objs 1
set05_V002_I00419
num_objs 0
set00_V013_I00509
num_objs 4
set00_V002_I00389
num_objs 0
set03_V000_I00569
num_objs 0
set03_V003_I00779
num_objs 0
set04_V010_I01619
num_objs 2
set00_V014_I00419
num_objs 3
set05_V007_I01619
num_objs 0
set02_V001_I00179
num_objs 0
set04_V007_I00389
num_objs 0
set05_V001_I01619
num_objs 0
set00_V013_I01259
num_objs 4
set05_V011_I01079
num_objs 4
set05_V010_I01019
num_objs 0
set00_V005_I01319
num_objs 0
set05_V007_I00359
num_objs 0
set02_V003_I00959
num_objs 0
set02_V006_I01739
num_objs 0
set00_V002_I01229
num_objs 1
set03_V010_I01319
num_objs 0
set04_V008_I00929
num_objs 0
set02_V007_I01349
num_objs 0
set01_V002_I01649
num_objs 5
set05_V007_I00599
num_objs 0
set03_V011_I01379
num_objs 1
set03_V012_I01679
num_objs 0
set02_V002_I00959
num_objs 0
set03_V010_I00269
num_objs 0
set05_V002_I01469
num_objs 0
set05_V007_I00929
num_objs 0
set03_V010_I01499
num_objs 1
set05_V012_I00119
num_objs 0
set03_V007_I01529
num_objs 0
set00_V001_I00749
num_objs 2
set01_V004_I01079
num_objs 4
set02_V003_I01229
num_objs 0
set05_V000_I01559
num_objs 0
set02_V003_I00089
num_objs 1
set01_V000_I01559
num_objs 4
set03_V005_I01259
num_objs 2
set04_V005_I00179
num_objs 0
set03_V002_I01529
num_objs 1
set02_V003_I01019
num_objs 0
set00_V002_I01199
num_objs 1
set02_V000_I00179
num_objs 0
set00_V010_I00419
num_objs 6
set03_V006_I01049
num_objs 0
set01_V002_I01619
num_objs 2
set05_V002_I00599
num_objs 1
set02_V011_I01739
num_objs 1
set03_V002_I00509
num_objs 0
set04_V011_I01049
num_objs 1
set02_V010_I00059
num_objs 0
set05_V009_I01349
num_objs 0
set04_V004_I00959
num_objs 2
set03_V004_I01679
num_objs 0
set05_V010_I00779
num_objs 0
set04_V010_I01439
num_objs 0
set02_V009_I00659
num_objs 2
set00_V008_I01139
num_objs 0
set05_V010_I00359
num_objs 0
set00_V012_I01259
num_objs 1
set00_V006_I00389
num_objs 4
set02_V004_I01139
num_objs 0
set02_V006_I01679
num_objs 0
set02_V010_I00239
num_objs 1
set04_V003_I01799
num_objs 0
set01_V002_I00689
num_objs 4
set05_V011_I00419
num_objs 0
set01_V003_I00809
num_objs 4
set02_V008_I00929
num_objs 1
set03_V009_I01169
num_objs 2
set00_V006_I00209
num_objs 2
set05_V006_I01559
num_objs 0
set00_V008_I01679
num_objs 0
set05_V008_I01679
num_objs 0
set02_V003_I01349
num_objs 0
set03_V001_I00419
num_objs 0
set02_V005_I01259
num_objs 0
set05_V008_I00809
num_objs 0
set04_V008_I00059
num_objs 0
set04_V007_I00359
num_objs 1
set00_V012_I01049
num_objs 3
set02_V007_I00359
num_objs 1
set01_V001_I00569
num_objs 3
set05_V008_I01469
num_objs 0
set00_V001_I01529
num_objs 2
set05_V001_I00449
num_objs 0
set02_V003_I00719
num_objs 0
set00_V014_I00479
num_objs 4
set05_V010_I00029
num_objs 1
set02_V004_I00809
num_objs 0
set05_V001_I01769
num_objs 0
set05_V004_I00059
num_objs 0
set04_V007_I00989
num_objs 1
set04_V002_I01109
num_objs 1
set00_V005_I00209
num_objs 0
set05_V007_I01739
num_objs 0
set01_V002_I01409
num_objs 1
set00_V011_I01439
num_objs 4
set00_V007_I01859
num_objs 4
set04_V001_I00059
num_objs 0
set04_V011_I00599
num_objs 0
set02_V009_I01109
num_objs 0
set02_V004_I00719
num_objs 0
set00_V011_I01259
num_objs 2
set00_V007_I00509
num_objs 2
set04_V001_I01349
num_objs 0
set04_V007_I00119
num_objs 0
set03_V004_I00359
num_objs 0
set00_V009_I00959
num_objs 3
set05_V006_I01769
num_objs 0
set05_V010_I00719
num_objs 0
set03_V007_I00149
num_objs 0
set04_V011_I00479
num_objs 0
set04_V010_I00719
num_objs 1
set00_V011_I01559
num_objs 0
set05_V003_I01589
num_objs 0
set04_V002_I01169
num_objs 2
set00_V006_I01379
num_objs 4
set01_V003_I01079
num_objs 3
set05_V011_I01019
num_objs 5
set05_V009_I01409
num_objs 0
set03_V012_I01049
num_objs 0
set05_V007_I01379
num_objs 1
set02_V003_I01739
num_objs 0
set02_V000_I00899
num_objs 0
set04_V005_I01109
num_objs 1
set05_V012_I00959
num_objs 0
set00_V013_I01049
num_objs 4
set04_V002_I00569
num_objs 0
set03_V012_I00419
num_objs 0
set00_V000_I01649
num_objs 0
set02_V007_I00269
num_objs 1
set05_V005_I00569
num_objs 1
set02_V004_I01229
num_objs 0
set04_V005_I00419
num_objs 0
set05_V006_I00059
num_objs 0
set05_V000_I01649
num_objs 0
set05_V009_I00629
num_objs 0
set05_V000_I00179
num_objs 1
set00_V007_I01349
num_objs 4
set05_V009_I01319
num_objs 0
set04_V006_I00779
num_objs 0
set03_V002_I00419
num_objs 0
set00_V001_I00329
num_objs 4
set05_V011_I01139
num_objs 2
set00_V004_I00719
num_objs 0
set01_V005_I01199
num_objs 4
set00_V003_I00329
num_objs 0
set03_V006_I00269
num_objs 0
set04_V010_I00239
num_objs 0
set01_V001_I00899
num_objs 0
set05_V005_I01139
num_objs 0
set00_V013_I01019
num_objs 0
set03_V006_I01559
num_objs 0
set00_V005_I00689
num_objs 0
set00_V004_I01259
num_objs 12
set04_V007_I01679
num_objs 1
set00_V002_I00599
num_objs 0
set00_V013_I01139
num_objs 4
set02_V011_I01709
num_objs 1
set02_V011_I00659
num_objs 1
set00_V011_I00989
num_objs 13
set04_V004_I00449
num_objs 2
set04_V000_I00089
num_objs 0
set00_V004_I01469
num_objs 10
set05_V002_I00839
num_objs 0
set03_V002_I01709
num_objs 0
set00_V004_I00779
num_objs 1
set00_V013_I00059
num_objs 5
set05_V011_I01169
num_objs 1
set04_V001_I01709
num_objs 1
set00_V009_I01589
num_objs 7
set04_V008_I00809
num_objs 0
set03_V000_I00869
num_objs 0
set05_V003_I00899
num_objs 0
set03_V000_I01589
num_objs 0
set04_V006_I00059
num_objs 0
set04_V011_I00269
num_objs 0
set05_V010_I00269
num_objs 0
set03_V012_I00569
num_objs 0
set05_V005_I01439
num_objs 0
set02_V011_I00899
num_objs 0
set05_V006_I00029
num_objs 0
set02_V011_I01619
num_objs 1
set00_V004_I00149
num_objs 1
set00_V005_I00989
num_objs 0
set03_V006_I01199
num_objs 0
set00_V005_I02009
num_objs 0
set00_V006_I01169
num_objs 4
set05_V010_I01199
num_objs 0
set01_V005_I01589
num_objs 0
set02_V001_I01289
num_objs 0
set00_V013_I01559
num_objs 9
set01_V003_I00389
num_objs 5
set03_V010_I01529
num_objs 1
set00_V006_I01499
num_objs 2
set00_V000_I01109
num_objs 0
set02_V002_I00899
num_objs 0
set03_V003_I01139
num_objs 1
set02_V007_I00839
num_objs 0
set03_V006_I00929
num_objs 0
set03_V006_I00149
num_objs 0
set04_V010_I00809
num_objs 1
set02_V009_I00179
num_objs 1
set04_V003_I00749
num_objs 0
set05_V000_I00929
num_objs 0
set04_V002_I01619
num_objs 2
set05_V003_I01769
num_objs 0
set05_V003_I00119
num_objs 0
set02_V003_I00509
num_objs 0
set03_V005_I01619
num_objs 1
set05_V006_I01469
num_objs 0
set02_V007_I00929
num_objs 0
set04_V008_I00749
num_objs 0
set05_V006_I00089
num_objs 0
set00_V001_I01589
num_objs 0
set00_V007_I01019
num_objs 1
set02_V000_I00779
num_objs 0
set02_V009_I00989
num_objs 0
set02_V007_I01289
num_objs 0
set05_V005_I01349
num_objs 0
set03_V006_I01439
num_objs 0
set00_V013_I01379
num_objs 4
set04_V010_I00839
num_objs 2
set04_V002_I01529
num_objs 2
set01_V003_I00569
num_objs 0
set02_V000_I00839
num_objs 0
set03_V002_I00809
num_objs 0
set01_V002_I00569
num_objs 5
set05_V005_I01829
num_objs 0
set00_V006_I01469
num_objs 1
set00_V000_I00989
num_objs 0
set00_V014_I00119
num_objs 5
set04_V003_I01649
num_objs 1
set03_V004_I01319
num_objs 0
set04_V011_I01019
num_objs 1
set04_V006_I00389
num_objs 0
set03_V006_I01649
num_objs 0
set02_V001_I00419
num_objs 0
set05_V002_I00659
num_objs 0
set05_V001_I00479
num_objs 0
set01_V003_I00599
num_objs 4
set00_V007_I01139
num_objs 3
set04_V002_I01799
num_objs 1
set05_V012_I00059
num_objs 0
set04_V008_I01169
num_objs 0
set01_V005_I00779
num_objs 2
set04_V011_I01199
num_objs 0
set02_V011_I01049
num_objs 0
set03_V007_I00719
num_objs 0
set02_V003_I00809
num_objs 0
set03_V008_I00989
num_objs 4
set04_V010_I01349
num_objs 0
set02_V001_I00989
num_objs 0
set04_V002_I01139
num_objs 2
set05_V007_I01319
num_objs 0
set00_V009_I01049
num_objs 0
set04_V003_I00989
num_objs 4
set05_V003_I01109
num_objs 0
set04_V008_I01769
num_objs 0
set03_V012_I00629
num_objs 0
set05_V012_I00569
num_objs 2
set00_V010_I00659
num_objs 3
set04_V007_I00899
num_objs 1
set03_V010_I00089
num_objs 0
set00_V001_I00689
num_objs 3
set00_V013_I00929
num_objs 1
set01_V001_I01799
num_objs 0
set04_V008_I00479
num_objs 0
set04_V005_I00629
num_objs 0
set04_V011_I01559
num_objs 0
set05_V012_I00989
num_objs 0
set00_V000_I00749
num_objs 1
set00_V006_I00539
num_objs 2
set03_V004_I00749
num_objs 0
set00_V008_I01289
num_objs 2
set02_V009_I01799
num_objs 0
set03_V004_I00869
num_objs 0
set00_V008_I00899
num_objs 1
set00_V004_I01229
num_objs 19
set02_V001_I00749
num_objs 0
set00_V013_I01229
num_objs 1
set00_V007_I01379
num_objs 4
set05_V000_I00509
num_objs 0
set00_V001_I00869
num_objs 2
set04_V004_I00899
num_objs 2
set05_V000_I00899
num_objs 0
set02_V005_I00749
num_objs 0
set00_V010_I00719
num_objs 2
set04_V011_I01169
num_objs 1
set00_V001_I00719
num_objs 2
set00_V006_I01769
num_objs 2
set02_V002_I01529
num_objs 0
set03_V002_I01589
num_objs 1
set02_V003_I01289
num_objs 0
set05_V012_I00479
num_objs 3
set00_V009_I00719
num_objs 4
set05_V011_I01109
num_objs 3
set04_V011_I00869
num_objs 0
set05_V007_I01769
num_objs 0
set03_V006_I01589
num_objs 0
set04_V005_I00389
num_objs 0
set01_V005_I01109
num_objs 2
set00_V010_I00179
num_objs 3
set05_V000_I01619
num_objs 0
set03_V007_I01769
num_objs 0
set02_V002_I01559
num_objs 0
set04_V011_I01349
num_objs 0
set00_V001_I01229
num_objs 0
set05_V008_I01439
num_objs 0
set05_V003_I00269
num_objs 0
set05_V004_I01169
num_objs 0
set00_V004_I00239
num_objs 0
set02_V003_I01169
num_objs 0
set04_V007_I01529
num_objs 1
set03_V007_I00479
num_objs 0
set04_V010_I01259
num_objs 0
set01_V001_I00629
num_objs 3
set03_V005_I01769
num_objs 1
set02_V011_I01469
num_objs 2
set03_V000_I01319
num_objs 0
set00_V000_I00509
num_objs 1
set05_V009_I01469
num_objs 0
set01_V004_I00839
num_objs 9
set02_V001_I00389
num_objs 0
set00_V010_I01319
num_objs 6
set01_V002_I00869
num_objs 8
set00_V008_I01169
num_objs 0
set05_V012_I00809
num_objs 0
set02_V007_I00509
num_objs 1
set05_V009_I00329
num_objs 0
set00_V004_I00119
num_objs 0
set00_V000_I01349
num_objs 0
set01_V005_I00839
num_objs 1
set05_V008_I01799
num_objs 0
set02_V000_I01109
num_objs 0
set04_V007_I00449
num_objs 0
set02_V009_I00269
num_objs 0
set01_V005_I01619
num_objs 0
set01_V003_I00629
num_objs 3
set05_V000_I00149
num_objs 0
set02_V007_I00299
num_objs 1
set05_V003_I00959
num_objs 0
set03_V005_I00659
num_objs 1
set01_V005_I01019
num_objs 2
set03_V010_I00479
num_objs 0
set02_V006_I01229
num_objs 0
set03_V003_I01109
num_objs 1
set00_V005_I00929
num_objs 0
set03_V007_I00329
num_objs 1
set04_V005_I00239
num_objs 0
set01_V004_I00659
num_objs 2
set01_V004_I01349
num_objs 3
set03_V006_I00989
num_objs 0
set03_V006_I01169
num_objs 0
set03_V006_I00089
num_objs 0
set02_V006_I00809
num_objs 0
set02_V009_I00359
num_objs 1
set00_V011_I00959
num_objs 5
set04_V008_I00389
num_objs 0
set01_V000_I00569
num_objs 4
set00_V008_I00659
num_objs 5
set02_V010_I01049
num_objs 0
set05_V005_I00719
num_objs 1
set02_V009_I01679
num_objs 0
set03_V010_I00689
num_objs 0
set00_V005_I00419
num_objs 0
set00_V004_I00899
num_objs 1
set05_V004_I01229
num_objs 0
set03_V003_I01829
num_objs 0
set05_V012_I00419
num_objs 1
set04_V001_I00929
num_objs 0
set04_V004_I00929
num_objs 2
set04_V010_I01799
num_objs 0
set00_V003_I00359
num_objs 1
set04_V009_I01229
num_objs 0
set05_V008_I00629
num_objs 0
set04_V009_I00059
num_objs 0
set05_V004_I00689
num_objs 0
set02_V000_I01589
num_objs 0
set02_V003_I00749
num_objs 0
set00_V004_I01829
num_objs 0
set04_V006_I00089
num_objs 0
set00_V007_I00869
num_objs 2
set02_V004_I00689
num_objs 0
set02_V004_I00929
num_objs 0
set05_V011_I00089
num_objs 0
set00_V008_I01319
num_objs 1
set05_V008_I00299
num_objs 0
set00_V013_I00959
num_objs 1
set03_V006_I01319
num_objs 0
set00_V013_I01169
num_objs 4
set01_V004_I00209
num_objs 2
set03_V012_I01439
num_objs 1
set03_V001_I01529
num_objs 0
set02_V004_I00269
num_objs 0
set03_V008_I01829
num_objs 0
set04_V004_I01379
num_objs 1
set05_V010_I00929
num_objs 0
set05_V010_I00179
num_objs 0
set00_V013_I00419
num_objs 3
set05_V007_I00389
num_objs 0
set01_V000_I00719
num_objs 0
set02_V005_I00629
num_objs 0
set04_V007_I01799
num_objs 0
set02_V001_I00569
num_objs 0
set05_V001_I01679
num_objs 0
set05_V003_I00059
num_objs 0
set04_V009_I01139
num_objs 0
set02_V003_I00929
num_objs 0
set00_V008_I00389
num_objs 6
set04_V003_I00029
num_objs 0
set00_V013_I00089
num_objs 4
set02_V000_I00389
num_objs 0
set04_V002_I01439
num_objs 2
set05_V000_I00689
num_objs 1
set03_V010_I00659
num_objs 0
set02_V010_I01079
num_objs 0
set05_V010_I00329
num_objs 0
set02_V000_I00209
num_objs 0
set03_V011_I00059
num_objs 0
set00_V014_I01739
num_objs 5
set01_V003_I00419
num_objs 4
set05_V002_I01229
num_objs 0
set00_V006_I01439
num_objs 3
set02_V005_I01229
num_objs 0
set01_V000_I00509
num_objs 0
set04_V009_I00029
num_objs 0
set02_V003_I00029
num_objs 1
set04_V008_I00029
num_objs 0
set04_V000_I00839
num_objs 0
set02_V006_I01199
num_objs 0
set04_V008_I01559
num_objs 0
set03_V000_I00239
num_objs 0
set02_V004_I01799
num_objs 0
set05_V002_I01799
num_objs 0
set03_V000_I00269
num_objs 0
set03_V000_I01199
num_objs 0
set04_V005_I00119
num_objs 0
set01_V005_I00269
num_objs 1
set00_V001_I01049
num_objs 5
set03_V006_I00719
num_objs 0
set02_V002_I01289
num_objs 0
set02_V007_I00059
num_objs 0
set00_V002_I01319
num_objs 0
set00_V000_I01679
num_objs 2
set03_V002_I01169
num_objs 0
set04_V002_I01259
num_objs 1
set01_V002_I00149
num_objs 4
set03_V008_I00629
num_objs 15
set04_V000_I00959
num_objs 1
set04_V007_I01019
num_objs 1
set01_V001_I00599
num_objs 2
set00_V012_I01019
num_objs 5
set00_V006_I00749
num_objs 2
set00_V014_I00929
num_objs 1
set05_V001_I01289
num_objs 0
set02_V009_I01229
num_objs 0
set04_V008_I00149
num_objs 0
set05_V001_I00869
num_objs 0
set04_V008_I01739
num_objs 0
set02_V000_I01319
num_objs 0
set00_V014_I00149
num_objs 2
set03_V006_I00689
num_objs 0
set04_V008_I00329
num_objs 0
set02_V000_I01739
num_objs 0
set01_V005_I00809
num_objs 2
set01_V001_I00449
num_objs 3
set04_V008_I01649
num_objs 0
set03_V009_I00749
num_objs 2
set04_V006_I01529
num_objs 1
set04_V000_I01019
num_objs 0
set05_V007_I01499
num_objs 1
set00_V011_I00179
num_objs 1
set03_V000_I01679
num_objs 0
set00_V006_I00149
num_objs 3
set00_V012_I01379
num_objs 3
set00_V002_I01019
num_objs 0
set04_V006_I01439
num_objs 0
set05_V004_I01019
num_objs 0
set05_V006_I01109
num_objs 0
set04_V007_I01139
num_objs 1
set01_V005_I01709
num_objs 2
set04_V011_I01139
num_objs 1
set00_V014_I01229
num_objs 1
set00_V012_I01439
num_objs 2
set01_V001_I00029
num_objs 0
set04_V001_I01019
num_objs 0
set05_V003_I00029
num_objs 0
set02_V007_I01229
num_objs 0
set01_V004_I00359
num_objs 0
set05_V002_I00059
num_objs 0
set00_V007_I00359
num_objs 3
set05_V010_I00449
num_objs 0
set00_V010_I00959
num_objs 1
set04_V006_I01709
num_objs 0
set05_V010_I00089
num_objs 1
set00_V000_I00869
num_objs 0
set01_V005_I01799
num_objs 0
set05_V011_I01469
num_objs 3
set03_V003_I01049
num_objs 0
set00_V012_I00389
num_objs 2
set00_V002_I01289
num_objs 1
set05_V010_I00899
num_objs 0
set02_V001_I01649
num_objs 1
set05_V012_I00929
num_objs 0
set01_V004_I00119
num_objs 2
set03_V001_I01289
num_objs 0
set03_V010_I01079
num_objs 1
set01_V000_I00329
num_objs 0
set00_V014_I01769
num_objs 4
set04_V009_I01589
num_objs 0
set01_V000_I00839
num_objs 0
set05_V003_I01499
num_objs 0
set05_V008_I00959
num_objs 0
set03_V012_I01769
num_objs 0
set04_V004_I01169
num_objs 2
set02_V006_I01529
num_objs 0
set03_V008_I01379
num_objs 0
set02_V008_I01079
num_objs 0
set04_V005_I01139
num_objs 0
set04_V007_I01499
num_objs 1
set05_V004_I00359
num_objs 0
set05_V010_I00479
num_objs 0
set03_V006_I01679
num_objs 0
set00_V009_I00059
num_objs 1
set05_V002_I01379
num_objs 0
set05_V011_I00239
num_objs 0
set05_V008_I01409
num_objs 0
set04_V000_I01829
num_objs 0
set02_V003_I00899
num_objs 0
set04_V010_I01049
num_objs 0
set02_V004_I00479
num_objs 0
set03_V001_I00749
num_objs 0
set02_V001_I00329
num_objs 0
set04_V006_I01769
num_objs 0
set03_V003_I00809
num_objs 0
set00_V005_I01499
num_objs 0
set03_V002_I01379
num_objs 0
set02_V002_I00119
num_objs 0
set03_V006_I01619
num_objs 0
set00_V002_I00149
num_objs 1
set00_V004_I01559
num_objs 0
set03_V009_I00989
num_objs 1
set05_V011_I00059
num_objs 0
set04_V000_I00209
num_objs 0
set01_V004_I00089
num_objs 2
set04_V000_I00119
num_objs 0
set04_V007_I00509
num_objs 0
set03_V002_I00089
num_objs 0
set00_V003_I00149
num_objs 1
set00_V004_I00299
num_objs 0
set02_V003_I00359
num_objs 0
set04_V009_I00629
num_objs 0
set00_V005_I01169
num_objs 0
set01_V001_I01319
num_objs 0
set05_V008_I00509
num_objs 0
set00_V001_I00299
num_objs 4
set00_V010_I01559
num_objs 2
set04_V003_I01379
num_objs 3
set03_V012_I00479
num_objs 0
set00_V006_I00419
num_objs 4
set03_V009_I01529
num_objs 0
set00_V005_I00809
num_objs 1
set01_V001_I00419
num_objs 2
set04_V004_I01799
num_objs 0
set04_V009_I00839
num_objs 0
set01_V004_I01229
num_objs 7
set04_V007_I01109
num_objs 1
set05_V012_I01499
num_objs 0
set05_V002_I01349
num_objs 0
set03_V008_I00839
num_objs 6
set04_V006_I00299
num_objs 0
set05_V012_I00869
num_objs 0
set02_V006_I00209
num_objs 0
set00_V005_I01139
num_objs 0
set02_V009_I01019
num_objs 0
set05_V003_I00149
num_objs 0
set05_V000_I01109
num_objs 0
set00_V000_I00719
num_objs 2
set05_V012_I01199
num_objs 0
set01_V001_I00959
num_objs 0
set00_V007_I00779
num_objs 1
set02_V003_I01139
num_objs 0
set05_V001_I00209
num_objs 0
set00_V005_I00569
num_objs 0
set04_V004_I01109
num_objs 2
set00_V004_I00959
num_objs 1
set03_V009_I00899
num_objs 0
set03_V006_I00419
num_objs 0
set00_V009_I01079
num_objs 0
set05_V008_I00719
num_objs 0
set02_V004_I01349
num_objs 0
set00_V005_I01679
num_objs 0
set04_V010_I00209
num_objs 0
set04_V010_I01229
num_objs 0
set01_V003_I01319
num_objs 0
set02_V009_I00839
num_objs 1
set00_V005_I01649
num_objs 0
set05_V001_I01379
num_objs 0
set05_V012_I01409
num_objs 0
set03_V009_I01049
num_objs 4
set04_V011_I01469
num_objs 0
set03_V004_I00989
num_objs 0
set03_V002_I01319
num_objs 0
set03_V007_I00209
num_objs 0
set01_V002_I00299
num_objs 8
set00_V010_I01349
num_objs 8
set04_V005_I01169
num_objs 1
set04_V010_I00119
num_objs 0
set03_V008_I00599
num_objs 16
set03_V000_I00389
num_objs 0
set00_V011_I01409
num_objs 0
set00_V005_I00179
num_objs 0
set01_V003_I01649
num_objs 6
set03_V012_I01469
num_objs 1
set05_V006_I00299
num_objs 0
set03_V012_I00839
num_objs 0
set02_V001_I00899
num_objs 0
set03_V012_I01529
num_objs 1
set02_V004_I00059
num_objs 0
set02_V007_I01259
num_objs 0
set02_V004_I00209
num_objs 0
set04_V010_I00059
num_objs 0
set00_V005_I00449
num_objs 0
set03_V005_I01559
num_objs 0
set03_V009_I01649
num_objs 1
set03_V011_I01409
num_objs 1
set05_V002_I00689
num_objs 1
set00_V002_I00959
num_objs 3
set04_V005_I01469
num_objs 0
set03_V007_I01559
num_objs 0
set03_V001_I01709
num_objs 0
set04_V001_I01439
num_objs 0
set02_V007_I00089
num_objs 0
set04_V005_I00779
num_objs 0
set03_V007_I00899
num_objs 0
set03_V009_I00659
num_objs 4
set00_V004_I00059
num_objs 0
set04_V009_I01319
num_objs 0
set01_V005_I01049
num_objs 2
set05_V003_I01649
num_objs 0
set05_V003_I00779
num_objs 0
set03_V002_I01259
num_objs 0
set05_V008_I01619
num_objs 0
set04_V000_I01199
num_objs 0
set01_V002_I00509
num_objs 1
set04_V000_I01109
num_objs 0
set02_V006_I01589
num_objs 0
set05_V006_I00659
num_objs 0
set03_V011_I00509
num_objs 3
set03_V000_I00779
num_objs 0
set05_V001_I01739
num_objs 0
set00_V000_I00149
num_objs 0
set02_V002_I01649
num_objs 0
set02_V009_I00689
num_objs 1
set03_V007_I01409
num_objs 0
set03_V005_I00299
num_objs 0
set02_V003_I00659
num_objs 0
set03_V005_I00899
num_objs 0
set05_V003_I01169
num_objs 2
set05_V001_I01319
num_objs 0
set04_V002_I00629
num_objs 1
set02_V008_I01199
num_objs 0
set00_V007_I01589
num_objs 4
set04_V010_I01829
num_objs 0
set04_V001_I01379
num_objs 0
set02_V011_I00749
num_objs 0
set04_V007_I00299
num_objs 0
set03_V005_I00569
num_objs 3
set04_V009_I01679
num_objs 0
set02_V003_I01439
num_objs 0
set02_V005_I01559
num_objs 0
set03_V010_I01679
num_objs 0
set04_V003_I01619
num_objs 1
set01_V003_I01529
num_objs 1
set05_V007_I01019
num_objs 0
set01_V004_I01649
num_objs 0
set05_V010_I01469
num_objs 0
set00_V014_I01499
num_objs 3
set02_V000_I00869
num_objs 0
set04_V008_I00359
num_objs 0
set05_V011_I00989
num_objs 4
set05_V005_I00119
num_objs 1
set00_V005_I01889
num_objs 0
set03_V010_I00119
num_objs 0
set02_V002_I00809
num_objs 0
set04_V001_I00419
num_objs 0
set01_V003_I01409
num_objs 1
set03_V005_I00419
num_objs 2
set02_V009_I00509
num_objs 0
set05_V009_I00149
num_objs 0
set05_V007_I00449
num_objs 0
set02_V003_I01619
num_objs 0
set04_V000_I00779
num_objs 0
set01_V003_I00089
num_objs 10
set03_V012_I00959
num_objs 0
set03_V008_I00719
num_objs 12
set00_V012_I00359
num_objs 0
set04_V003_I00959
num_objs 0
set03_V007_I01799
num_objs 0
set02_V002_I01409
num_objs 0
set00_V004_I01679
num_objs 0
set04_V003_I01499
num_objs 0
set01_V003_I01379
num_objs 1
set00_V005_I01619
num_objs 0
set00_V010_I00479
num_objs 3
set05_V007_I00659
num_objs 0
set05_V002_I01589
num_objs 1
set03_V010_I01139
num_objs 0
set02_V007_I01829
num_objs 0
set02_V005_I00509
num_objs 0
set00_V002_I01109
num_objs 0
set00_V011_I00899
num_objs 2
set05_V001_I01499
num_objs 0
set04_V004_I00329
num_objs 0
set02_V006_I00479
num_objs 0
set03_V000_I00179
num_objs 0
set02_V003_I01559
num_objs 0
set00_V014_I00569
num_objs 7
set01_V002_I00779
num_objs 6
set00_V001_I00059
num_objs 0
set03_V004_I01349
num_objs 0
set05_V008_I01289
num_objs 0
set05_V000_I00209
num_objs 2
set00_V002_I00899
num_objs 11
set04_V006_I01169
num_objs 0
set03_V004_I01139
num_objs 0
set00_V002_I00449
num_objs 0
set05_V007_I00269
num_objs 0
set00_V007_I00899
num_objs 4
set05_V009_I01079
num_objs 0
set04_V004_I01319
num_objs 1
set01_V004_I00929
num_objs 5
set05_V006_I00629
num_objs 0
set03_V003_I00179
num_objs 1
set05_V005_I01109
num_objs 1
set04_V007_I01259
num_objs 0
set03_V007_I00269
num_objs 1
set04_V010_I01319
num_objs 0
set04_V005_I00869
num_objs 1
set00_V000_I01169
num_objs 0
set05_V005_I00869
num_objs 1
set05_V010_I01289
num_objs 0
set02_V008_I01229
num_objs 1
set00_V000_I00839
num_objs 0
set02_V003_I00419
num_objs 0
set00_V005_I00749
num_objs 0
set00_V014_I00749
num_objs 4
set03_V008_I00149
num_objs 14
set02_V003_I00149
num_objs 1
set05_V001_I00749
num_objs 0
set02_V000_I01199
num_objs 0
set03_V011_I00599
num_objs 3
set00_V008_I01469
num_objs 2
set02_V003_I00569
num_objs 0
set00_V002_I00359
num_objs 1
set05_V005_I00029
num_objs 1
set04_V006_I01829
num_objs 0
set00_V007_I00929
num_objs 3
set05_V010_I01559
num_objs 1
set05_V005_I00629
num_objs 1
set03_V000_I00899
num_objs 0
set05_V003_I01739
num_objs 0
set05_V012_I01169
num_objs 0
set00_V010_I00899
num_objs 2
set02_V000_I01139
num_objs 0
set05_V010_I00299
num_objs 0
set01_V005_I01529
num_objs 0
set03_V000_I00119
num_objs 0
set03_V010_I00839
num_objs 0
set03_V003_I01679
num_objs 0
set04_V000_I01529
num_objs 0
set05_V007_I01829
num_objs 0
set00_V009_I00419
num_objs 2
set04_V000_I00569
num_objs 1
set02_V001_I01709
num_objs 0
set02_V008_I00389
num_objs 0
set04_V010_I00569
num_objs 1
set05_V006_I00539
num_objs 0
set05_V001_I00089
num_objs 0
set02_V007_I00239
num_objs 1
set04_V002_I00059
num_objs 0
set01_V002_I00089
num_objs 4
set00_V007_I00809
num_objs 2
set03_V010_I01619
num_objs 0
set04_V009_I00569
num_objs 0
set03_V008_I01649
num_objs 2
set00_V006_I01289
num_objs 6
set01_V004_I01529
num_objs 2
set02_V009_I00119
num_objs 0
set04_V003_I00869
num_objs 0
set00_V005_I02039
num_objs 0
set03_V003_I01589
num_objs 0
set03_V002_I01499
num_objs 1
set03_V008_I01529
num_objs 4
set05_V003_I00329
num_objs 0
set01_V003_I01709
num_objs 5
set03_V001_I00659
num_objs 0
set03_V012_I01139
num_objs 0
set02_V005_I01169
num_objs 0
set00_V010_I00779
num_objs 3
set02_V007_I00119
num_objs 1
set02_V003_I01829
num_objs 0
set05_V009_I00059
num_objs 0
set04_V000_I01739
num_objs 0
set05_V004_I00239
num_objs 1
set05_V000_I00119
num_objs 2
set02_V007_I00869
num_objs 0
set00_V013_I00389
num_objs 4
set04_V003_I01169
num_objs 3
set00_V006_I00119
num_objs 4
set03_V007_I00989
num_objs 0
set04_V009_I00449
num_objs 0
set04_V008_I00629
num_objs 1
set00_V007_I00269
num_objs 2
set05_V009_I00359
num_objs 0
set00_V006_I01709
num_objs 1
set03_V011_I01709
num_objs 0
set05_V010_I00989
num_objs 0
set02_V005_I01649
num_objs 0
set05_V000_I01529
num_objs 0
set00_V009_I01379
num_objs 0
set04_V003_I00389
num_objs 0
set02_V006_I00779
num_objs 0
set02_V002_I01139
num_objs 0
set05_V008_I00599
num_objs 0
set03_V005_I01829
num_objs 2
set03_V001_I00119
num_objs 1
set04_V011_I00149
num_objs 0
set02_V009_I00389
num_objs 1
set02_V005_I00929
num_objs 0
set04_V006_I01289
num_objs 0
set03_V004_I00959
num_objs 0
set00_V014_I01829
num_objs 2
set02_V007_I00149
num_objs 1
set02_V009_I01169
num_objs 0
set02_V008_I01349
num_objs 0
set02_V001_I01769
num_objs 0
set04_V011_I00179
num_objs 0
set02_V006_I00509
num_objs 0
set00_V004_I01649
num_objs 0
set05_V009_I01259
num_objs 0
set05_V004_I01049
num_objs 0
set01_V003_I01229
num_objs 0
set02_V000_I01289
num_objs 0
set05_V009_I00209
num_objs 0
set05_V007_I00989
num_objs 0
set03_V004_I00269
num_objs 0
set03_V001_I00449
num_objs 0
set01_V001_I01199
num_objs 5
set04_V004_I01499
num_objs 0
set00_V000_I00329
num_objs 0
set01_V000_I00869
num_objs 0
set00_V007_I01439
num_objs 3
set02_V003_I01379
num_objs 0
set02_V005_I01589
num_objs 0
set00_V006_I01019
num_objs 0
set00_V008_I00599
num_objs 7
set05_V006_I00269
num_objs 0
set05_V007_I01079
num_objs 0
set01_V005_I00869
num_objs 1
set02_V003_I00599
num_objs 0
set02_V006_I01709
num_objs 0
set00_V001_I00479
num_objs 1
set05_V008_I01559
num_objs 0
set01_V002_I00929
num_objs 5
set03_V002_I00869
num_objs 0
set03_V012_I00389
num_objs 0
set00_V005_I01109
num_objs 0
set05_V009_I01649
num_objs 0
set03_V007_I00929
num_objs 0
set04_V003_I00359
num_objs 0
set04_V011_I00689
num_objs 0
set02_V009_I01469
num_objs 0
set02_V006_I00719
num_objs 0
set02_V003_I01499
num_objs 0
set04_V009_I00599
num_objs 0
set03_V008_I01079
num_objs 4
set04_V011_I01859
num_objs 1
set02_V007_I00209
num_objs 1
set03_V002_I01649
num_objs 2
set02_V001_I01469
num_objs 0
set05_V003_I01259
num_objs 3
set00_V000_I00269
num_objs 2
set03_V011_I00299
num_objs 4
set03_V001_I00839
num_objs 1
set01_V003_I00839
num_objs 7
set00_V007_I01079
num_objs 2
set03_V009_I00299
num_objs 2
set05_V008_I00659
num_objs 0
set05_V005_I01319
num_objs 0
set03_V002_I00029
num_objs 0
set02_V000_I00029
num_objs 0
set04_V001_I01649
num_objs 1
set02_V009_I00929
num_objs 0
set03_V009_I00419
num_objs 2
set05_V002_I01259
num_objs 0
set03_V004_I00179
num_objs 0
set00_V004_I01169
num_objs 11
set02_V011_I00449
num_objs 1
set04_V006_I01259
num_objs 0
set05_V012_I00839
num_objs 0
set05_V000_I01229
num_objs 0
set04_V003_I01589
num_objs 1
set00_V011_I00359
num_objs 0
set02_V000_I00959
num_objs 0
set00_V007_I00209
num_objs 1
set04_V002_I00539
num_objs 0
set05_V010_I01319
num_objs 0
set02_V007_I01169
num_objs 0
set02_V002_I00779
num_objs 0
set03_V011_I01589
num_objs 0
set03_V002_I01019
num_objs 0
set00_V000_I00209
num_objs 1
set03_V006_I01529
num_objs 0
set00_V006_I01109
num_objs 6
set01_V002_I00719
num_objs 4
set05_V000_I00329
num_objs 2
set00_V006_I01679
num_objs 0
set01_V003_I00119
num_objs 11
set00_V008_I01619
num_objs 0
set03_V002_I00299
num_objs 0
set01_V004_I00029
num_objs 2
set01_V002_I00419
num_objs 4
set04_V003_I00719
num_objs 0
set02_V006_I01409
num_objs 0
set00_V004_I00539
num_objs 1
set01_V005_I01349
num_objs 1
set02_V007_I00689
num_objs 0
set05_V004_I00839
num_objs 0
set00_V007_I00179
num_objs 0
set04_V011_I01709
num_objs 0
set03_V003_I00089
num_objs 2
set03_V008_I00059
num_objs 14
set02_V008_I00359
num_objs 0
set00_V002_I00539
num_objs 0
set03_V007_I01679
num_objs 0
set04_V006_I00869
num_objs 0
set02_V005_I00599
num_objs 0
set03_V003_I01379
num_objs 0
set00_V002_I00119
num_objs 0
set00_V003_I00059
num_objs 0
set05_V005_I00689
num_objs 1
set02_V004_I00839
num_objs 0
set00_V006_I00689
num_objs 3
set01_V005_I00419
num_objs 3
set05_V010_I00239
num_objs 0
set04_V006_I00569
num_objs 1
set03_V008_I00359
num_objs 14
set01_V001_I01379
num_objs 4
set03_V009_I01619
num_objs 1
set05_V004_I01109
num_objs 0
set05_V010_I00149
num_objs 1
set03_V007_I00509
num_objs 0
set01_V004_I01049
num_objs 2
set00_V002_I00569
num_objs 0
set01_V005_I00059
num_objs 0
set00_V004_I00419
num_objs 0
set05_V009_I01709
num_objs 0
set03_V004_I00569
num_objs 1
set02_V000_I00119
num_objs 0
set02_V001_I01169
num_objs 0
set04_V005_I01019
num_objs 1
set03_V005_I01589
num_objs 1
set02_V010_I01529
num_objs 0
set04_V010_I00989
num_objs 0
set02_V010_I00419
num_objs 0
set05_V010_I01529
num_objs 1
set02_V008_I00029
num_objs 0
set03_V004_I00779
num_objs 0
set05_V001_I00959
num_objs 0
set03_V004_I01499
num_objs 0
set01_V002_I01289
num_objs 5
set05_V003_I00689
num_objs 0
set00_V000_I00359
num_objs 1
set04_V008_I00539
num_objs 1
set00_V007_I01919
num_objs 1
set02_V007_I01769
num_objs 0
set03_V009_I01739
num_objs 4
set00_V002_I00659
num_objs 0
set03_V000_I00629
num_objs 0
set01_V003_I00539
num_objs 1
set04_V004_I00299
num_objs 0
set01_V003_I01289
num_objs 0
set05_V004_I01409
num_objs 0
set00_V013_I01289
num_objs 6
set02_V006_I01079
num_objs 0
set04_V008_I01679
num_objs 0
set05_V008_I01139
num_objs 0
set01_V003_I01739
num_objs 5
set05_V012_I00089
num_objs 0
set03_V004_I01739
num_objs 1
set05_V005_I01649
num_objs 0
set05_V011_I01679
num_objs 1
set04_V008_I01019
num_objs 1
set01_V004_I00989
num_objs 7
set01_V002_I00749
num_objs 6
set03_V010_I00869
num_objs 0
set04_V008_I01109
num_objs 1
set00_V006_I01919
num_objs 2
set04_V002_I01079
num_objs 1
set01_V001_I00329
num_objs 0
set05_V006_I00419
num_objs 0
set05_V000_I01709
num_objs 1
set03_V011_I01649
num_objs 0
set05_V007_I00089
num_objs 0
set05_V001_I00899
num_objs 0
set02_V003_I00539
num_objs 0
set05_V004_I00659
num_objs 0
set04_V003_I00179
num_objs 0
set02_V003_I00239
num_objs 0
set05_V008_I01229
num_objs 0
set02_V011_I01349
num_objs 0
set04_V010_I00449
num_objs 1
set05_V012_I01049
num_objs 1
set04_V006_I00419
num_objs 0
set03_V005_I00989
num_objs 0
set05_V000_I00539
num_objs 1
set01_V002_I01769
num_objs 2
set04_V002_I01019
num_objs 2
set00_V014_I01559
num_objs 2
set04_V005_I01589
num_objs 1
set01_V000_I01079
num_objs 4
set05_V009_I01049
num_objs 0
set00_V005_I00869
num_objs 0
set02_V000_I01649
num_objs 0
set04_V002_I00509
num_objs 0
set03_V005_I01079
num_objs 1
set04_V000_I01349
num_objs 0
set04_V011_I00899
num_objs 0
set02_V009_I00209
num_objs 0
set04_V000_I00629
num_objs 1
set01_V004_I01439
num_objs 1
set05_V002_I01049
num_objs 0
set00_V007_I00659
num_objs 1
set02_V003_I00869
num_objs 0
set04_V010_I01379
num_objs 0
set05_V003_I01559
num_objs 0
set05_V001_I00539
num_objs 0
set00_V008_I01199
num_objs 1
set05_V012_I01289
num_objs 0
set02_V009_I00449
num_objs 0
set05_V008_I01019
num_objs 0
set02_V007_I00989
num_objs 0
set04_V008_I00209
num_objs 0
set02_V004_I01019
num_objs 0
set03_V012_I00359
num_objs 0
set00_V006_I00299
num_objs 3
set02_V005_I01079
num_objs 0
set00_V000_I00929
num_objs 0
set03_V011_I01679
num_objs 0
set04_V005_I00209
num_objs 0
set04_V010_I00929
num_objs 2
set00_V004_I00929
num_objs 1
set03_V000_I01709
num_objs 0
set05_V011_I01499
num_objs 2
set00_V010_I00299
num_objs 3
set05_V012_I00539
num_objs 1
set05_V001_I00059
num_objs 0
set01_V001_I01619
num_objs 1
set03_V006_I01709
num_objs 0
set02_V002_I00389
num_objs 0
set00_V001_I00599
num_objs 2
set04_V005_I01499
num_objs 1
set00_V005_I00779
num_objs 0
set03_V002_I01559
num_objs 1
set00_V007_I01169
num_objs 5
set03_V001_I00569
num_objs 0
set05_V005_I01289
num_objs 0
set02_V006_I01319
num_objs 0
set00_V009_I00689
num_objs 4
set00_V013_I00149
num_objs 3
set03_V002_I00209
num_objs 0
set04_V005_I01679
num_objs 1
set02_V000_I00539
num_objs 0
set00_V000_I01229
num_objs 1
set03_V009_I01349
num_objs 1
set03_V001_I01229
num_objs 0
set00_V014_I00629
num_objs 9
set03_V000_I01259
num_objs 0
set02_V003_I01259
num_objs 0
set02_V002_I01469
num_objs 0
set04_V002_I01469
num_objs 2
set02_V002_I00479
num_objs 0
set05_V001_I01079
num_objs 0
set05_V004_I00749
num_objs 0
set05_V004_I00329
num_objs 0
set04_V003_I01049
num_objs 4
set05_V010_I01049
num_objs 0
set01_V003_I00899
num_objs 6
set05_V009_I00299
num_objs 0
set01_V000_I01499
num_objs 1
set02_V010_I00569
num_objs 2
set00_V011_I00629
num_objs 3
set02_V008_I00089
num_objs 0
set04_V003_I00629
num_objs 0
set02_V010_I00509
num_objs 1
set02_V005_I01409
num_objs 0
set05_V003_I00359
num_objs 0
set05_V005_I00419
num_objs 0
set01_V004_I00869
num_objs 5
set01_V001_I00689
num_objs 3
set04_V009_I00269
num_objs 0
set02_V001_I00119
num_objs 0
set00_V012_I00599
num_objs 0
set04_V001_I00479
num_objs 0
set00_V007_I00959
num_objs 3
set02_V004_I01829
num_objs 0
set00_V010_I00689
num_objs 3
set02_V002_I00539
num_objs 0
set03_V002_I01289
num_objs 0
set04_V001_I00329
num_objs 0
set00_V008_I00959
num_objs 1
set03_V002_I00149
num_objs 0
set03_V001_I01259
num_objs 0
set01_V002_I01499
num_objs 1
set04_V007_I01349
num_objs 0
set02_V001_I01529
num_objs 0
set03_V006_I01289
num_objs 0
set05_V011_I00509
num_objs 0
set05_V000_I01079
num_objs 0
set01_V001_I00209
num_objs 1
set05_V012_I01109
num_objs 0
set05_V011_I01319
num_objs 2
set03_V010_I01169
num_objs 0
set05_V002_I00029
num_objs 0
set00_V001_I00029
num_objs 2
set03_V006_I01229
num_objs 0
set00_V013_I00749
num_objs 1
set00_V006_I01739
num_objs 1
set02_V007_I00899
num_objs 0
set04_V000_I01679
num_objs 0
set05_V012_I00899
num_objs 0
set04_V008_I00089
num_objs 0
set04_V011_I00629
num_objs 0
set03_V010_I01199
num_objs 0
set00_V004_I02069
num_objs 0
set04_V007_I00179
num_objs 0
set00_V007_I01769
num_objs 2
set02_V006_I00959
num_objs 0
set01_V003_I00689
num_objs 3
set00_V006_I00839
num_objs 0
set02_V004_I01109
num_objs 0
set03_V011_I00659
num_objs 2
set04_V007_I01829
num_objs 0
set00_V005_I01979
num_objs 0
set02_V005_I01739
num_objs 0
set05_V006_I01199
num_objs 0
set00_V013_I00809
num_objs 0
set03_V005_I00389
num_objs 2
set00_V005_I00239
num_objs 0
set05_V011_I00329
num_objs 0
set05_V002_I00389
num_objs 0
set03_V012_I00689
num_objs 0
set03_V006_I00179
num_objs 0
set00_V004_I00329
num_objs 0
set03_V002_I00689
num_objs 0
set03_V009_I01019
num_objs 1
set00_V007_I00149
num_objs 0
set04_V004_I01049
num_objs 2
set04_V006_I00149
num_objs 0
set02_V006_I00569
num_objs 0
set03_V012_I01259
num_objs 0
set05_V008_I01379
num_objs 0
set01_V001_I00779
num_objs 1
set05_V002_I01019
num_objs 0
set00_V007_I00749
num_objs 2
set01_V003_I00059
num_objs 15
set02_V006_I00899
num_objs 0
set05_V005_I01529
num_objs 0
set01_V002_I01049
num_objs 0
set04_V004_I00839
num_objs 1
set04_V006_I01589
num_objs 1
set03_V001_I01769
num_objs 0
set01_V001_I00359
num_objs 2
set04_V011_I01109
num_objs 1
set05_V007_I00779
num_objs 0
set02_V010_I00929
num_objs 0
set02_V001_I00929
num_objs 0
set00_V000_I00059
num_objs 0
set05_V007_I00869
num_objs 0
set03_V002_I00449
num_objs 0
set01_V003_I00149
num_objs 10
set00_V001_I00629
num_objs 5
set00_V011_I00059
num_objs 4
set00_V005_I01259
num_objs 0
set02_V000_I01469
num_objs 0
set04_V011_I01259
num_objs 0
set05_V007_I00539
num_objs 0
set05_V004_I01499
num_objs 0
set03_V004_I01469
num_objs 0
set02_V008_I01619
num_objs 0
set01_V004_I00389
num_objs 0
set04_V004_I01019
num_objs 2
set04_V004_I00089
num_objs 0
set02_V011_I01139
num_objs 0
set00_V014_I00659
num_objs 6
set05_V001_I01169
num_objs 0
set00_V007_I00299
num_objs 2
set03_V001_I00599
num_objs 0
set03_V006_I00389
num_objs 0
set04_V005_I00749
num_objs 1
set03_V009_I01709
num_objs 0
set00_V009_I01109
num_objs 0
set00_V006_I01829
num_objs 1
set03_V003_I00539
num_objs 1
set05_V005_I00239
num_objs 0
set00_V000_I00479
num_objs 1
set01_V004_I00059
num_objs 2
set00_V001_I01409
num_objs 2
set00_V004_I00839
num_objs 1
set04_V005_I00809
num_objs 0
set02_V008_I01319
num_objs 0
set03_V009_I00059
num_objs 3
set05_V000_I00779
num_objs 0
set02_V002_I00449
num_objs 0
set04_V002_I00329
num_objs 0
set02_V007_I00749
num_objs 0
set00_V000_I00599
num_objs 0
set05_V006_I00149
num_objs 1
set04_V001_I00869
num_objs 0
set05_V000_I01019
num_objs 0
set01_V004_I01409
num_objs 2
set01_V002_I01229
num_objs 3
set02_V006_I00689
num_objs 0
set05_V000_I00449
num_objs 1
set04_V004_I00989
num_objs 2
set01_V004_I01619
num_objs 0
set04_V006_I00929
num_objs 1
set01_V001_I01139
num_objs 1
set02_V006_I00269
num_objs 0
set01_V003_I00479
num_objs 4
set05_V002_I00089
num_objs 0
set05_V000_I00989
num_objs 0
set05_V007_I00149
num_objs 0
set01_V000_I00179
num_objs 0
set00_V013_I00989
num_objs 1
set03_V003_I00839
num_objs 0
set02_V006_I01799
num_objs 0
set00_V004_I00269
num_objs 0
set03_V006_I01409
num_objs 0
set02_V005_I00029
num_objs 0
set03_V012_I01229
num_objs 0
set04_V007_I00029
num_objs 0
set02_V011_I00389
num_objs 0
set03_V009_I00119
num_objs 3
set05_V012_I01649
num_objs 0
set04_V010_I00689
num_objs 1
set02_V000_I00329
num_objs 0
set03_V004_I00599
num_objs 1
set00_V008_I01529
num_objs 1
set05_V006_I01829
num_objs 0
set04_V000_I00689
num_objs 2
set04_V002_I01229
num_objs 1
set05_V007_I01169
num_objs 0
set05_V008_I01109
num_objs 0
set02_V007_I01019
num_objs 0
set00_V000_I00029
num_objs 0
set01_V004_I01139
num_objs 5
set01_V002_I00029
num_objs 1
set04_V011_I00569
num_objs 0
set00_V008_I00149
num_objs 2
set04_V009_I01649
num_objs 0
set00_V008_I00179
num_objs 2
set02_V000_I00449
num_objs 0
set03_V003_I01199
num_objs 0
set04_V002_I01649
num_objs 2
set00_V003_I00179
num_objs 0
set00_V005_I00119
num_objs 0
set02_V003_I00779
num_objs 0
set04_V005_I00569
num_objs 0
set03_V010_I00719
num_objs 0
set05_V012_I00149
num_objs 0
set02_V010_I00989
num_objs 0
set02_V006_I01169
num_objs 0
set03_V002_I00629
num_objs 0
set00_V014_I01379
num_objs 0
set04_V003_I00509
num_objs 0
set05_V007_I01229
num_objs 1
set00_V000_I00449
num_objs 1
set05_V012_I01439
num_objs 0
set00_V009_I00389
num_objs 1
set03_V003_I00929
num_objs 0
set02_V008_I00629
num_objs 0
set05_V002_I00539
num_objs 0
set04_V009_I01469
num_objs 0
set05_V009_I00269
num_objs 0
set00_V011_I01169
num_objs 8
set02_V002_I01499
num_objs 0
set03_V011_I01349
num_objs 1
set02_V010_I01619
num_objs 0
set05_V009_I00089
num_objs 0
set05_V003_I01469
num_objs 0
set02_V010_I00119
num_objs 1
set04_V010_I01499
num_objs 0
set05_V002_I00749
num_objs 0
set00_V005_I01349
num_objs 0
set02_V010_I00539
num_objs 2
set04_V003_I00239
num_objs 1
set03_V009_I00149
num_objs 2
set02_V000_I00239
num_objs 0
set05_V012_I00719
num_objs 0
set05_V010_I01379
num_objs 0
set01_V005_I01439
num_objs 0
set01_V003_I01259
num_objs 0
set04_V006_I00629
num_objs 1
set03_V004_I00059
num_objs 0
set05_V004_I01349
num_objs 0
set04_V010_I00749
num_objs 0
set03_V000_I00689
num_objs 0
set05_V008_I00209
num_objs 0
set01_V003_I00869
num_objs 2
set05_V007_I01289
num_objs 0
set04_V003_I00689
num_objs 0
set04_V006_I01139
num_objs 0
set01_V000_I00419
num_objs 2
set00_V002_I01139
num_objs 0
set00_V004_I01379
num_objs 9
set05_V008_I00989
num_objs 0
set04_V001_I01409
num_objs 0
set02_V000_I00299
num_objs 0
set00_V001_I00209
num_objs 1
set02_V003_I01799
num_objs 0
set05_V000_I01319
num_objs 0
set00_V011_I00329
num_objs 0
set04_V007_I00839
num_objs 0
set02_V009_I01289
num_objs 0
set04_V000_I00359
num_objs 0
set00_V008_I00239
num_objs 1
set02_V002_I01019
num_objs 0
set04_V006_I00239
num_objs 0
set00_V009_I00149
num_objs 1
set03_V003_I01169
num_objs 0
set03_V002_I00899
num_objs 0
set05_V009_I01199
num_objs 0
set04_V008_I00869
num_objs 0
set04_V009_I01709
num_objs 0
set04_V006_I01379
num_objs 0
set03_V007_I00869
num_objs 0
set04_V003_I00119
num_objs 0
set05_V000_I00419
num_objs 1
set03_V003_I01739
num_objs 0
set00_V009_I00329
num_objs 5
set02_V006_I01349
num_objs 0
set04_V006_I01649
num_objs 0
set05_V004_I00029
num_objs 0
set05_V001_I00599
num_objs 0
set04_V009_I01439
num_objs 0
set03_V007_I00839
num_objs 0
set00_V002_I00059
num_objs 0
set02_V010_I00719
num_objs 1
set00_V010_I01229
num_objs 7
set05_V000_I00239
num_objs 0
set05_V002_I00719
num_objs 0
set04_V007_I00689
num_objs 0
set02_V002_I00659
num_objs 0
set03_V007_I01259
num_objs 0
set00_V009_I00179
num_objs 8
set05_V003_I00929
num_objs 0
set01_V003_I00329
num_objs 2
set00_V013_I00539
num_objs 3
set00_V012_I00659
num_objs 1
set04_V006_I00689
num_objs 0
set02_V011_I01589
num_objs 2
set04_V006_I01619
num_objs 1
set00_V014_I01529
num_objs 0
set03_V003_I00629
num_objs 2
set05_V010_I01709
num_objs 0
set02_V008_I01409
num_objs 0
set00_V013_I01319
num_objs 5
set05_V001_I01049
num_objs 0
set02_V003_I01409
num_objs 0
set03_V010_I01589
num_objs 3
set00_V001_I00659
num_objs 2
set05_V004_I01259
num_objs 0
set01_V000_I01709
num_objs 2
set00_V012_I00989
num_objs 6
set04_V011_I01079
num_objs 1
set02_V008_I01889
num_objs 0
set04_V004_I00719
num_objs 2
set00_V011_I01349
num_objs 2
set00_V000_I00689
num_objs 2
set00_V012_I00839
num_objs 7
set05_V010_I00569
num_objs 0
set05_V010_I00539
num_objs 0
set01_V005_I01169
num_objs 4
set00_V004_I01289
num_objs 11
set00_V002_I00689
num_objs 0
set03_V008_I00389
num_objs 17
set03_V011_I01319
num_objs 0
set00_V012_I00449
num_objs 4
set05_V003_I01799
num_objs 0
set04_V001_I01619
num_objs 1
set03_V011_I01439
num_objs 2
set03_V001_I00299
num_objs 0
set00_V009_I01289
num_objs 0
set03_V003_I00119
num_objs 2
set05_V010_I00119
num_objs 1
set01_V003_I01589
num_objs 2
set02_V009_I01049
num_objs 0
set00_V006_I01619
num_objs 0
set05_V012_I01559
num_objs 0
set03_V006_I01379
num_objs 0
set02_V011_I00599
num_objs 2
set03_V009_I00179
num_objs 2
set04_V006_I01349
num_objs 0
set02_V005_I00719
num_objs 0
set04_V007_I00209
num_objs 0
set05_V001_I00779
num_objs 0
set04_V003_I01469
num_objs 1
set00_V008_I00839
num_objs 1
set01_V003_I01109
num_objs 0
set03_V008_I01619
num_objs 2
set03_V003_I00689
num_objs 0
set03_V000_I01049
num_objs 0
set00_V003_I00299
num_objs 0
set00_V007_I01409
num_objs 4
set04_V005_I00329
num_objs 0
set03_V003_I01409
num_objs 1
set05_V004_I01139
num_objs 0
set05_V011_I00449
num_objs 0
set05_V000_I01469
num_objs 0
set02_V005_I01769
num_objs 0
set00_V007_I00719
num_objs 1
set04_V011_I00539
num_objs 0
set01_V002_I01799
num_objs 3
set04_V000_I00749
num_objs 1
set05_V006_I01679
num_objs 0
set00_V003_I00209
num_objs 0
set04_V002_I00599
num_objs 1
set04_V009_I01619
num_objs 0
set01_V004_I00479
num_objs 1
set04_V011_I01379
num_objs 0
set02_V005_I01499
num_objs 0
set00_V011_I00599
num_objs 1
set00_V010_I00569
num_objs 5
set04_V008_I00269
num_objs 0
set05_V007_I00749
num_objs 0
set00_V011_I00659
num_objs 1
set00_V007_I01469
num_objs 4
set03_V011_I01769
num_objs 0
set03_V001_I00359
num_objs 0
set00_V009_I01469
num_objs 6
set03_V000_I01649
num_objs 0
set05_V001_I00419
num_objs 0
set00_V000_I01319
num_objs 1
set04_V002_I00239
num_objs 0
set03_V002_I00389
num_objs 0
set05_V011_I00899
num_objs 5
set00_V012_I00689
num_objs 0
set05_V011_I00119
num_objs 0
set04_V009_I01289
num_objs 0
set04_V009_I00239
num_objs 0
set02_V001_I00869
num_objs 0
set04_V005_I01619
num_objs 2
set00_V013_I00359
num_objs 7
set00_V011_I00839
num_objs 0
set05_V007_I00329
num_objs 0
set04_V010_I00389
num_objs 1
set05_V002_I00869
num_objs 0
set01_V002_I01169
num_objs 4
set03_V006_I00869
num_objs 0
set03_V011_I00359
num_objs 5
set03_V001_I00629
num_objs 0
set01_V004_I00749
num_objs 2
set04_V011_I01589
num_objs 1
set05_V011_I00299
num_objs 0
set05_V002_I00779
num_objs 0
set02_V005_I01349
num_objs 0
set03_V003_I00239
num_objs 1
set04_V007_I00629
num_objs 0
set02_V004_I00089
num_objs 0
set01_V001_I01079
num_objs 1
set01_V003_I00929
num_objs 5
set03_V006_I00899
num_objs 0
set02_V007_I00959
num_objs 0
set03_V004_I01199
num_objs 0
set04_V003_I01319
num_objs 4
set00_V000_I00179
num_objs 0
set03_V009_I00929
num_objs 2
set00_V000_I00089
num_objs 0
set00_V002_I00419
num_objs 0
set03_V007_I01589
num_objs 0
set03_V012_I01739
num_objs 0
set02_V008_I01859
num_objs 0
set02_V011_I01079
num_objs 0
set04_V001_I01769
num_objs 0
set02_V001_I00779
num_objs 0
set02_V005_I01469
num_objs 0
set02_V007_I00719
num_objs 0
set03_V002_I01409
num_objs 1
set00_V008_I01559
num_objs 0
set04_V004_I00269
num_objs 0
set00_V014_I01799
num_objs 6
set05_V009_I01799
num_objs 0
set04_V000_I00599
num_objs 0
set02_V010_I01199
num_objs 0
set04_V004_I01349
num_objs 1
set00_V009_I00809
num_objs 3
set05_V001_I01709
num_objs 0
set00_V001_I01679
num_objs 1
set04_V000_I01769
num_objs 0
set02_V003_I01679
num_objs 0
set02_V011_I01409
num_objs 0
set01_V004_I00299
num_objs 2
set03_V001_I00149
num_objs 1
set03_V007_I01289
num_objs 0
set03_V005_I01289
num_objs 0
set03_V006_I00029
num_objs 0
set04_V011_I00779
num_objs 0
set03_V000_I00059
num_objs 0
set04_V009_I00179
num_objs 0
set02_V004_I01559
num_objs 0
set00_V011_I01139
num_objs 10
set04_V010_I00479
num_objs 1
set03_V000_I00599
num_objs 0
set03_V012_I00179
num_objs 0
set03_V004_I00539
num_objs 1
set00_V001_I01319
num_objs 1
set03_V007_I00179
num_objs 0
set02_V002_I00329
num_objs 0
set03_V009_I01319
num_objs 0
set04_V005_I00689
num_objs 0
set04_V000_I01139
num_objs 0
set03_V010_I00629
num_objs 0
set04_V002_I01349
num_objs 1
set05_V009_I00779
num_objs 0
set04_V011_I01289
num_objs 0
set04_V010_I01169
num_objs 0
set00_V012_I00329
num_objs 1
set00_V001_I00569
num_objs 1
set03_V002_I00569
num_objs 0
set00_V005_I01229
num_objs 0
set05_V004_I00779
num_objs 0
set03_V000_I00299
num_objs 0
set04_V009_I01079
num_objs 0
set03_V004_I00119
num_objs 0
set02_V006_I00539
num_objs 0
set04_V008_I00449
num_objs 0
set04_V002_I00029
num_objs 0
set04_V010_I01139
num_objs 0
set02_V010_I01319
num_objs 0
set03_V010_I00149
num_objs 0
set05_V000_I00359
num_objs 1
set01_V004_I01019
num_objs 9
set03_V010_I01409
num_objs 1
set00_V014_I01469
num_objs 0
set00_V012_I00239
num_objs 3
set03_V009_I01589
num_objs 0
set01_V003_I00269
num_objs 5
set03_V008_I01019
num_objs 6
set02_V007_I00389
num_objs 0
set01_V000_I00359
num_objs 1
set05_V001_I01649
num_objs 0
set00_V001_I00239
num_objs 3
set03_V012_I01589
num_objs 1
set02_V009_I01619
num_objs 1
set02_V002_I00509
num_objs 0
set02_V005_I01679
num_objs 0
set05_V005_I00839
num_objs 0
set00_V005_I00509
num_objs 0
set05_V006_I00119
num_objs 0
set05_V005_I00059
num_objs 2
set01_V003_I01679
num_objs 4
set04_V005_I00149
num_objs 0
set04_V001_I01079
num_objs 0
set02_V009_I01589
num_objs 1
set02_V011_I01289
num_objs 1
set04_V004_I00689
num_objs 0
set00_V007_I00329
num_objs 2
set02_V000_I01559
num_objs 0
set00_V014_I00719
num_objs 5
set05_V009_I00029
num_objs 0
set02_V004_I00509
num_objs 0
set00_V009_I01169
num_objs 0
set02_V006_I00449
num_objs 0
set02_V006_I00179
num_objs 0
set03_V012_I01379
num_objs 4
set02_V006_I00599
num_objs 0
set03_V000_I00449
num_objs 0
set03_V001_I00689
num_objs 0
set00_V007_I00689
num_objs 1
set02_V000_I00269
num_objs 0
set00_V009_I00899
num_objs 4
set00_V007_I01049
num_objs 2
set02_V005_I00839
num_objs 0
set01_V001_I00119
num_objs 1
set01_V001_I00719
num_objs 2
set01_V003_I01019
num_objs 8
set03_V012_I01199
num_objs 1
set04_V004_I00149
num_objs 0
set04_V010_I00899
num_objs 2
set03_V011_I00029
num_objs 0
set05_V012_I00599
num_objs 0
set00_V012_I00299
num_objs 3
set02_V011_I00809
num_objs 0
set05_V010_I01829
num_objs 0
set03_V009_I00329
num_objs 2
set00_V008_I01409
num_objs 1
set03_V000_I01769
num_objs 0
set00_V005_I00059
num_objs 0
set00_V014_I00299
num_objs 3
set02_V000_I00989
num_objs 0
set03_V003_I01799
num_objs 0
set05_V011_I00629
num_objs 1
set02_V006_I00419
num_objs 0
set01_V002_I00989
num_objs 0
set03_V012_I00869
num_objs 0
set03_V011_I00779
num_objs 1
set03_V008_I01049
num_objs 0
set02_V002_I01109
num_objs 0
set03_V006_I01769
num_objs 0
set03_V008_I00779
num_objs 11
set05_V000_I00809
num_objs 0
set05_V010_I01169
num_objs 0
set05_V008_I01499
num_objs 0
set00_V005_I00599
num_objs 0
set03_V007_I01379
num_objs 0
set01_V003_I00179
num_objs 7
set02_V008_I01679
num_objs 0
set00_V009_I00659
num_objs 4
set00_V005_I00959
num_objs 0
set05_V001_I01919
num_objs 0
set03_V012_I00149
num_objs 0
set05_V002_I00359
num_objs 0
set00_V014_I00329
num_objs 2
set03_V008_I00089
num_objs 13
set05_V005_I00509
num_objs 1
set03_V007_I01439
num_objs 0
set03_V002_I01679
num_objs 1
set01_V001_I01049
num_objs 1
set00_V000_I01769
num_objs 1
set03_V006_I01499
num_objs 0
set02_V000_I00719
num_objs 0
set05_V010_I01619
num_objs 1
set03_V001_I00479
num_objs 0
set01_V004_I01379
num_objs 3
set04_V004_I01199
num_objs 3
set02_V002_I00749
num_objs 0
set04_V005_I01349
num_objs 0
set00_V002_I00479
num_objs 0
set05_V005_I00599
num_objs 0
set00_V008_I00209
num_objs 2
set03_V008_I01739
num_objs 1
set01_V000_I00959
num_objs 0
set02_V002_I01049
num_objs 0
set03_V005_I01499
num_objs 0
set04_V006_I00509
num_objs 0
set04_V000_I00419
num_objs 0
set05_V003_I00749
num_objs 0
set04_V011_I01769
num_objs 1
set04_V007_I00659
num_objs 1
set02_V002_I00179
num_objs 0
set04_V006_I01499
num_objs 1
set03_V001_I00929
num_objs 0
set01_V005_I00959
num_objs 5
set03_V011_I01619
num_objs 0
set02_V003_I01859
num_objs 0
set05_V011_I01439
num_objs 3
set03_V002_I01829
num_objs 0
set05_V001_I01109
num_objs 0
set03_V003_I01229
num_objs 0
set01_V004_I00149
num_objs 2
set00_V007_I00569
num_objs 4
set01_V001_I01259
num_objs 2
set03_V009_I00779
num_objs 0
set02_V001_I01139
num_objs 0
set00_V000_I01289
num_objs 1
set00_V007_I00119
num_objs 0
set00_V014_I01109
num_objs 2
set00_V011_I01319
num_objs 5
set01_V005_I00719
num_objs 2
set02_V004_I01469
num_objs 0
set03_V003_I01559
num_objs 0
set00_V005_I00029
num_objs 0
set00_V010_I01679
num_objs 4
set02_V001_I00269
num_objs 0
set03_V011_I00539
num_objs 3
set04_V006_I00719
num_objs 1
set03_V009_I00389
num_objs 0
set02_V002_I00239
num_objs 0
set00_V004_I00869
num_objs 0
set04_V001_I00149
num_objs 0
set05_V012_I00209
num_objs 0
set00_V007_I01889
num_objs 4
set00_V006_I01529
num_objs 2
set05_V005_I00479
num_objs 2
set03_V007_I01619
num_objs 0
set00_V002_I00719
num_objs 1
set00_V001_I01559
num_objs 0
set05_V006_I00239
num_objs 0
set01_V000_I01019
num_objs 1
set04_V010_I00419
num_objs 1
set03_V008_I01679
num_objs 1
set00_V006_I01139
num_objs 3
set00_V001_I01739
num_objs 1
set03_V011_I01229
num_objs 0
set04_V011_I01829
num_objs 1
set01_V005_I00299
num_objs 2
set01_V002_I00539
num_objs 7
set02_V003_I00059
num_objs 0
set04_V010_I00659
num_objs 1
set03_V008_I00179
num_objs 17
set05_V011_I01409
num_objs 2
set04_V003_I01259
num_objs 3
set05_V011_I01349
num_objs 1
set01_V000_I01139
num_objs 2
set02_V008_I00599
num_objs 0
set01_V002_I00389
num_objs 4
set04_V010_I00779
num_objs 0
set04_V004_I01079
num_objs 2
set04_V008_I01199
num_objs 0
set00_V005_I00299
num_objs 0
set05_V002_I00509
num_objs 0
set05_V008_I00689
num_objs 0
set04_V007_I00869
num_objs 1
set05_V001_I01829
num_objs 0
set00_V007_I00629
num_objs 1
set03_V007_I00239
num_objs 0
set01_V005_I00659
num_objs 2
set00_V010_I01169
num_objs 5
set03_V012_I00719
num_objs 0
set05_V012_I01319
num_objs 0
set02_V003_I00179
num_objs 0
set04_V009_I00689
num_objs 0
set03_V001_I00329
num_objs 0
set00_V005_I01409
num_objs 0
set05_V002_I01439
num_objs 0
set03_V000_I01109
num_objs 0
set02_V008_I01439
num_objs 0
set03_V004_I01169
num_objs 0
set05_V004_I00539
num_objs 0
set03_V009_I01139
num_objs 4
set04_V009_I01559
num_objs 0
set02_V011_I01319
num_objs 0
set03_V004_I00479
num_objs 1
set04_V010_I00029
num_objs 0
set05_V006_I00719
num_objs 0
set00_V004_I01019
num_objs 1
set03_V009_I00269
num_objs 4
set00_V008_I00869
num_objs 1
set00_V002_I00989
num_objs 0
set05_V012_I01619
num_objs 0
set03_V007_I01319
num_objs 0
set01_V001_I00809
num_objs 0
set03_V001_I00089
num_objs 0
set04_V009_I00719
num_objs 0
set04_V010_I00269
num_objs 0
set02_V000_I00509
num_objs 0
set04_V007_I00089
num_objs 0
set00_V009_I01559
num_objs 5
set05_V006_I01079
num_objs 0
set00_V000_I00389
num_objs 2
set01_V005_I01679
num_objs 0
set01_V001_I00479
num_objs 2
set05_V012_I00269
num_objs 0
set00_V009_I00209
num_objs 6
set05_V012_I00629
num_objs 0
set01_V005_I00539
num_objs 1
set03_V008_I01559
num_objs 4
set01_V002_I00629
num_objs 3
set00_V006_I00779
num_objs 4
set02_V009_I00719
num_objs 2
set05_V001_I01199
num_objs 0
set00_V005_I02129
num_objs 0
set01_V001_I01829
num_objs 1
set01_V001_I01289
num_objs 3
set04_V009_I00359
num_objs 0
set03_V009_I00959
num_objs 2
set02_V004_I01319
num_objs 0
set03_V004_I01619
num_objs 0
set03_V011_I00719
num_objs 1
set02_V002_I00149
num_objs 0
set05_V000_I00659
num_objs 0
set02_V003_I00479
num_objs 0
set03_V008_I00569
num_objs 13
set05_V009_I01289
num_objs 0
set03_V010_I00179
num_objs 0
set00_V006_I00629
num_objs 2
set02_V007_I01139
num_objs 0
set05_V004_I00959
num_objs 1
set04_V004_I01619
num_objs 0
set02_V001_I00239
num_objs 0
set03_V011_I00569
num_objs 2
set00_V009_I00929
num_objs 3
set05_V005_I01229
num_objs 0
set03_V009_I01409
num_objs 0
set00_V005_I00089
num_objs 0
set04_V004_I01439
num_objs 1
set00_V005_I01919
num_objs 0
set03_V001_I01589
num_objs 0
set00_V014_I01589
num_objs 1
set04_V009_I00479
num_objs 0
set02_V010_I00089
num_objs 2
set00_V010_I01619
num_objs 1
set00_V010_I00599
num_objs 5
set04_V004_I00029
num_objs 0
set00_V011_I00389
num_objs 0
set00_V001_I01619
num_objs 0
set05_V007_I00179
num_objs 0
set05_V003_I00629
num_objs 0
set05_V003_I00599
num_objs 0
set05_V005_I01409
num_objs 0
set05_V001_I00629
num_objs 0
set00_V010_I00329
num_objs 4
set01_V000_I01589
num_objs 3
set02_V000_I01679
num_objs 0
set05_V002_I01169
num_objs 1
set00_V001_I00419
num_objs 1
set05_V001_I01349
num_objs 0
set05_V001_I00689
num_objs 0
set05_V012_I00389
num_objs 2
set02_V001_I00719
num_objs 0
set00_V000_I01529
num_objs 1
set04_V009_I01799
num_objs 0
set05_V006_I00389
num_objs 0
set05_V006_I00989
num_objs 0
set05_V011_I01259
num_objs 2
set02_V005_I01199
num_objs 0
set01_V003_I01439
num_objs 0
set04_V000_I00509
num_objs 1
set05_V000_I00299
num_objs 1
set03_V003_I00599
num_objs 0
set05_V001_I01889
num_objs 0
set01_V000_I00089
num_objs 3
set04_V000_I01229
num_objs 0
set05_V001_I00029
num_objs 0
set04_V004_I01859
num_objs 1
set00_V010_I00209
num_objs 3
set05_V003_I00389
num_objs 0
set00_V010_I01649
num_objs 1
set03_V001_I01049
num_objs 0
set04_V010_I00179
num_objs 0
set02_V007_I01709
num_objs 0
set02_V001_I01079
num_objs 0
set04_V005_I00479
num_objs 0
set02_V011_I00119
num_objs 0
set01_V003_I01049
num_objs 5
set05_V007_I00839
num_objs 0
set04_V003_I01289
num_objs 4
set03_V000_I00719
num_objs 0
set00_V001_I01349
num_objs 2
set01_V002_I00959
num_objs 3
set04_V010_I00959
num_objs 1
set00_V012_I01529
num_objs 0
set05_V006_I00689
num_objs 0
set04_V008_I01349
num_objs 0
set01_V003_I00239
num_objs 9
set03_V002_I01469
num_objs 0
set05_V005_I00269
num_objs 1
set05_V008_I00449
num_objs 0
set04_V000_I01079
num_objs 0
set00_V012_I01559
num_objs 0
set03_V005_I01169
num_objs 0
set01_V005_I01769
num_objs 0
set00_V001_I00809
num_objs 2
set04_V007_I01319
num_objs 0
set05_V000_I00839
num_objs 0
set03_V007_I01649
num_objs 0
set01_V002_I01439
num_objs 1
set02_V001_I00809
num_objs 0
set00_V000_I01739
num_objs 0
set00_V011_I00089
num_objs 4
set02_V005_I00449
num_objs 0
set00_V009_I00239
num_objs 9
set01_V001_I01679
num_objs 2
set04_V007_I00749
num_objs 0
set02_V007_I01109
num_objs 0
set04_V009_I01169
num_objs 0
set02_V010_I01349
num_objs 0
set04_V002_I00119
num_objs 0
set02_V009_I01139
num_objs 0
set05_V003_I01319
num_objs 2
set02_V000_I01349
num_objs 0
set04_V008_I01619
num_objs 0
set05_V004_I01199
num_objs 0
set01_V005_I00989
num_objs 4
set02_V005_I00899
num_objs 0
set03_V001_I00209
num_objs 0
set01_V005_I01499
num_objs 0
set05_V002_I01619
num_objs 1
set03_V006_I00209
num_objs 0
set03_V008_I00029
num_objs 11
set00_V010_I00059
num_objs 4
set04_V011_I00029
num_objs 0
set00_V014_I00899
num_objs 1
set05_V008_I00389
num_objs 0
set02_V007_I01529
num_objs 0
set03_V012_I00449
num_objs 0
set02_V011_I00509
num_objs 0
set00_V000_I01439
num_objs 0
set05_V003_I01379
num_objs 2
set04_V004_I01409
num_objs 1
set03_V005_I01409
num_objs 0
set05_V007_I00569
num_objs 0
set03_V009_I01769
num_objs 0
set02_V011_I00089
num_objs 0
set05_V011_I00209
num_objs 0
set00_V010_I00539
num_objs 5
set01_V003_I01619
num_objs 3
set02_V008_I01289
num_objs 0
set04_V002_I00719
num_objs 3
set02_V002_I00419
num_objs 0
set04_V007_I00419
num_objs 0
set00_V005_I01469
num_objs 0
set00_V008_I01229
num_objs 2
set03_V006_I00659
num_objs 0
set00_V014_I00779
num_objs 5
set03_V008_I00509
num_objs 15
set03_V000_I00539
num_objs 0
set00_V000_I01139
num_objs 0
set04_V010_I01019
num_objs 0
set04_V004_I00179
num_objs 0
set03_V009_I01079
num_objs 5
set04_V011_I00419
num_objs 0
set05_V006_I00179
num_objs 0
set05_V003_I01829
num_objs 0
set01_V005_I00029
num_objs 0
set02_V007_I01739
num_objs 0
set02_V009_I00899
num_objs 1
set01_V001_I01349
num_objs 1
set00_V001_I00839
num_objs 2
set02_V007_I00569
num_objs 0
set04_V010_I00149
num_objs 0
set04_V006_I01229
num_objs 0
set00_V005_I00719
num_objs 0
set04_V004_I01229
num_objs 2
set04_V010_I01529
num_objs 0
set02_V011_I01379
num_objs 2
set02_V011_I00059
num_objs 0
set04_V004_I01559
num_objs 0
set04_V000_I00899
num_objs 1
set00_V014_I01439
num_objs 1
set00_V009_I01439
num_objs 0
set02_V005_I00959
num_objs 0
set04_V005_I01529
num_objs 1
set01_V000_I01109
num_objs 2
set05_V000_I01409
num_objs 0
set05_V002_I00269
num_objs 0
set01_V004_I01319
num_objs 5
set05_V003_I01709
num_objs 2
set01_V002_I01079
num_objs 3
set05_V012_I01589
num_objs 0
set03_V008_I01139
num_objs 4
set02_V004_I00419
num_objs 0
set03_V004_I00509
num_objs 1
set02_V001_I00839
num_objs 0
set02_V004_I01289
num_objs 0
set02_V011_I00479
num_objs 2
set00_V008_I00299
num_objs 0
set04_V005_I00059
num_objs 1
set05_V005_I00929
num_objs 1
set00_V009_I00029
num_objs 3
set00_V014_I00179
num_objs 1
set02_V008_I00899
num_objs 3
set04_V002_I00089
num_objs 1
set00_V004_I02129
num_objs 0
set05_V009_I00179
num_objs 0
set02_V004_I00149
num_objs 0
set00_V000_I00899
num_objs 0
set03_V011_I01739
num_objs 0
set02_V003_I01049
num_objs 0
set02_V005_I00659
num_objs 0
set00_V007_I01529
num_objs 1
set04_V005_I01079
num_objs 1
set01_V000_I01289
num_objs 3
set05_V002_I00209
num_objs 0
set03_V008_I01769
num_objs 1
set02_V004_I01199
num_objs 0
set05_V007_I01649
num_objs 0
set03_V009_I01289
num_objs 0
set00_V001_I01199
num_objs 1
set01_V000_I00929
num_objs 3
set01_V003_I00029
num_objs 6
set02_V009_I01079
num_objs 0
set03_V004_I01379
num_objs 0
set01_V001_I00929
num_objs 0
set01_V002_I00809
num_objs 6
set02_V009_I00869
num_objs 1
set01_V000_I00149
num_objs 3
set04_V010_I00539
num_objs 1
set02_V008_I01529
num_objs 0
set05_V009_I01169
num_objs 0
set02_V003_I00629
num_objs 0
set00_V008_I00689
num_objs 3
set01_V005_I01409
num_objs 2
set00_V001_I01799
num_objs 1
set02_V006_I01649
num_objs 0
set01_V000_I00269
num_objs 0
set02_V011_I01829
num_objs 0
set04_V007_I00059
num_objs 0
set02_V008_I00689
num_objs 0
set04_V006_I00119
num_objs 0
set00_V011_I00449
num_objs 4
set05_V002_I01829
num_objs 0
set03_V006_I00329
num_objs 0
set03_V006_I01469
num_objs 0
set01_V004_I01799
num_objs 0
set02_V001_I00059
num_objs 0
set00_V012_I01289
num_objs 0
set05_V009_I01109
num_objs 0
set04_V006_I00959
num_objs 1
set03_V010_I00779
num_objs 0
set04_V001_I00689
num_objs 0
set01_V005_I00929
num_objs 6
set05_V006_I00359
num_objs 0
set00_V009_I00119
num_objs 2
set04_V009_I00809
num_objs 0
set05_V006_I00929
num_objs 0
set03_V008_I00689
num_objs 15
set03_V004_I00149
num_objs 0
set05_V005_I01469
num_objs 0
set03_V005_I00749
num_objs 0
set02_V003_I00269
num_objs 0
set02_V003_I01709
num_objs 0
set02_V006_I00059
num_objs 0
set00_V011_I01109
num_objs 11
set03_V010_I00419
num_objs 0
set04_V004_I00749
num_objs 2
set02_V011_I01529
num_objs 1
set00_V010_I00749
num_objs 2
set02_V010_I01229
num_objs 0
set02_V011_I00239
num_objs 0
set00_V010_I01409
num_objs 4
set04_V010_I00299
num_objs 0
set05_V009_I01139
num_objs 0
set04_V011_I01529
num_objs 0
set00_V014_I01619
num_objs 5
set05_V011_I00779
num_objs 0
set04_V000_I01379
num_objs 0
set04_V004_I00779
num_objs 3
set02_V000_I00599
num_objs 0
set04_V002_I00359
num_objs 0
set01_V000_I01349
num_objs 3
set03_V010_I01649
num_objs 0
set00_V002_I00329
num_objs 1
set04_V011_I01499
num_objs 0
set05_V002_I00329
num_objs 0
set03_V008_I01109
num_objs 0
set01_V003_I01199
num_objs 0
set03_V010_I00299
num_objs 0
set04_V011_I00839
num_objs 0
set01_V001_I00239
num_objs 0
set05_V003_I01139
num_objs 0
set03_V010_I00809
num_objs 0
set00_V014_I01169
num_objs 0
set03_V007_I00959
num_objs 0
set04_V007_I01769
num_objs 0
set00_V013_I00629
num_objs 2
set00_V005_I01379
num_objs 0
set04_V007_I01559
num_objs 1
set04_V009_I00659
num_objs 0
set04_V002_I00959
num_objs 2
set02_V000_I00749
num_objs 0
set02_V006_I01109
num_objs 0
set03_V003_I01349
num_objs 1
set00_V012_I00119
num_objs 0
set00_V013_I00599
num_objs 3
set04_V008_I00569
num_objs 1
set05_V009_I00869
num_objs 1
set04_V002_I00389
num_objs 0
set05_V009_I00659
num_objs 0
set03_V010_I00749
num_objs 0
set02_V011_I01229
num_objs 0
set03_V012_I01079
num_objs 0
set02_V007_I00809
num_objs 0
set04_V003_I01139
num_objs 3
set00_V009_I01499
num_objs 6
set00_V014_I00359
num_objs 2
set03_V010_I00359
num_objs 0
set04_V009_I00869
num_objs 0
set03_V011_I01139
num_objs 0
set03_V002_I01229
num_objs 0
set01_V000_I00749
num_objs 0
set02_V009_I00749
num_objs 2
set03_V001_I01739
num_objs 0
set05_V000_I00059
num_objs 0
set05_V006_I01529
num_objs 0
set03_V007_I00299
num_objs 1
set04_V009_I01199
num_objs 0
set02_V002_I01199
num_objs 0
set04_V000_I00659
num_objs 2
set05_V005_I01019
num_objs 0
set05_V007_I01679
num_objs 0
set03_V001_I00959
num_objs 0
set03_V005_I00479
num_objs 2
set00_V004_I00599
num_objs 0
set03_V001_I01199
num_objs 0
set04_V009_I00959
num_objs 0
set05_V003_I00659
num_objs 0
set01_V003_I01559
num_objs 4
set05_V008_I01259
num_objs 0
set03_V010_I01439
num_objs 1
set05_V007_I00959
num_objs 0
set01_V005_I00149
num_objs 2
set05_V004_I01379
num_objs 0
set04_V010_I01289
num_objs 0
set00_V014_I00059
num_objs 2
set02_V000_I01409
num_objs 0
set03_V006_I00059
num_objs 0
set03_V010_I00899
num_objs 0
set05_V003_I00449
num_objs 0
set00_V002_I00179
num_objs 1
set04_V006_I01019
num_objs 0
set00_V006_I01889
num_objs 6
set00_V004_I00359
num_objs 1
set02_V006_I01259
num_objs 0
set05_V010_I01439
num_objs 0
set00_V012_I00539
num_objs 2
set03_V009_I01259
num_objs 0
set05_V001_I00179
num_objs 1
set02_V010_I00479
num_objs 1
set00_V005_I01049
num_objs 0
set03_V002_I01739
num_objs 0
set02_V001_I01619
num_objs 1
set05_V011_I00689
num_objs 0
set03_V005_I00209
num_objs 0
set03_V000_I01799
num_objs 1
set04_V002_I01409
num_objs 1
set02_V010_I00839
num_objs 0
set05_V000_I01499
num_objs 0
set03_V012_I01649
num_objs 0
set04_V000_I01439
num_objs 0
set05_V012_I01469
num_objs 0
set03_V012_I01709
num_objs 0
set05_V000_I01199
num_objs 0
set04_V000_I01619
num_objs 0
set02_V011_I00149
num_objs 0
set00_V006_I00239
num_objs 3
set00_V002_I00839
num_objs 11
set04_V004_I01829
num_objs 0
set05_V008_I00179
num_objs 0
set02_V002_I01739
num_objs 0
set02_V010_I00689
num_objs 2
set00_V000_I01079
num_objs 0
set05_V006_I01259
num_objs 0
set03_V007_I01079
num_objs 0
set05_V012_I01529
num_objs 0
set00_V014_I01259
num_objs 3
set02_V007_I01379
num_objs 0
set00_V009_I01409
num_objs 4
set01_V005_I01559
num_objs 0
set00_V008_I00629
num_objs 5
set00_V009_I00089
num_objs 4
set02_V004_I01079
num_objs 0
set00_V010_I00149
num_objs 3
set02_V006_I00749
num_objs 0
set02_V008_I01769
num_objs 0
set00_V003_I00089
num_objs 0
set04_V008_I00899
num_objs 0
set01_V000_I01319
num_objs 3
set00_V010_I01109
num_objs 5
set03_V007_I01109
num_objs 0
set00_V004_I00089
num_objs 0
set05_V007_I00299
num_objs 0
set02_V004_I00869
num_objs 0
set05_V008_I01199
num_objs 0
set05_V002_I01529
num_objs 0
set00_V013_I00299
num_objs 6
set05_V006_I01439
num_objs 0
set00_V009_I00569
num_objs 2
set03_V008_I00209
num_objs 14
set04_V000_I00479
num_objs 1
set04_V009_I00989
num_objs 1
set00_V014_I01319
num_objs 0
set03_V002_I00269
num_objs 0
set02_V010_I01019
num_objs 1
set00_V006_I00599
num_objs 3
set01_V004_I00689
num_objs 1
set01_V004_I01739
num_objs 0
set02_V005_I00239
num_objs 0
set02_V008_I01259
num_objs 1
set03_V001_I00029
num_objs 0
set02_V002_I01319
num_objs 0
set00_V005_I00899
num_objs 0
set03_V005_I01799
num_objs 2
set03_V005_I01049
num_objs 0
set02_V009_I00479
num_objs 0
set05_V004_I00719
num_objs 0
set03_V009_I01379
num_objs 0
set03_V011_I01829
num_objs 0
set03_V007_I01169
num_objs 0
set04_V006_I00539
num_objs 0
set02_V009_I00809
num_objs 2
set02_V010_I00749
num_objs 2
set01_V005_I00389
num_objs 3
set03_V002_I01349
num_objs 0
set00_V014_I01079
num_objs 2
set03_V004_I00449
num_objs 1
set04_V011_I01889
num_objs 0
set04_V009_I00509
num_objs 0
set01_V004_I00539
num_objs 1
set04_V007_I00539
num_objs 1
set00_V013_I00179
num_objs 5
set04_V001_I01499
num_objs 1
set05_V007_I01349
num_objs 1
set01_V003_I00359
num_objs 3
set05_V006_I00869
num_objs 0
set01_V004_I01109
num_objs 2
set04_V003_I01679
num_objs 1
set01_V001_I00989
num_objs 0
set02_V002_I00359
num_objs 0
set00_V011_I00209
num_objs 1
set03_V006_I00629
num_objs 0
set03_V009_I00029
num_objs 2
set03_V009_I00509
num_objs 1
set05_V003_I01079
num_objs 1
set05_V012_I00329
num_objs 0
set04_V011_I00959
num_objs 0
set00_V000_I01469
num_objs 3
set04_V011_I00209
num_objs 0
set05_V005_I00899
num_objs 0
set04_V005_I00929
num_objs 0
set02_V002_I01679
num_objs 0
set05_V000_I00599
num_objs 1
set04_V007_I01289
num_objs 0
set04_V006_I00359
num_objs 0
set03_V001_I00389
num_objs 0
set05_V006_I01589
num_objs 0
set03_V005_I01139
num_objs 0
set04_V008_I00839
num_objs 0
set01_V003_I01349
num_objs 1
set02_V001_I01109
num_objs 0
set05_V011_I00359
num_objs 0
set03_V011_I01169
num_objs 1
set05_V008_I00749
num_objs 0
set03_V001_I01079
num_objs 0
set05_V001_I00269
num_objs 0
set05_V007_I00689
num_objs 0
set02_V003_I00839
num_objs 0
set05_V007_I01559
num_objs 0
set00_V005_I00659
num_objs 0
set04_V001_I01049
num_objs 0
set03_V004_I01019
num_objs 0
set00_V013_I01109
num_objs 7
set04_V008_I01709
num_objs 0
set04_V001_I01109
num_objs 0
set01_V002_I01199
num_objs 1
set00_V000_I01619
num_objs 1
set00_V013_I00449
num_objs 3
set03_V007_I00539
num_objs 0
set05_V002_I01139
num_objs 2
set01_V002_I00659
num_objs 5
set04_V007_I00719
num_objs 0
set03_V006_I01829
num_objs 0
set00_V008_I00989
num_objs 3
set03_V005_I00869
num_objs 0
set02_V010_I00809
num_objs 0
set01_V002_I01559
num_objs 1
set00_V003_I00029
num_objs 0
set04_V008_I01379
num_objs 0
set05_V003_I01409
num_objs 0
set01_V001_I01169
num_objs 1
set00_V007_I01109
num_objs 2
set00_V012_I01469
num_objs 3
set00_V001_I01709
num_objs 1
set00_V012_I01619
num_objs 0
set03_V000_I01559
num_objs 0
set00_V007_I00989
num_objs 2
set02_V004_I01619
num_objs 0
set04_V005_I01229
num_objs 0
set05_V006_I01349
num_objs 0
set02_V008_I01919
num_objs 0
set00_V004_I00389
num_objs 1
set05_V001_I01559
num_objs 0
set03_V002_I00479
num_objs 0
set04_V005_I01439
num_objs 1
set02_V002_I01439
num_objs 0
set04_V003_I01229
num_objs 3
set03_V011_I00179
num_objs 2
set00_V009_I00779
num_objs 2
set02_V002_I01229
num_objs 0
set01_V001_I01709
num_objs 2
set05_V002_I00149
num_objs 1
set00_V000_I00419
num_objs 4
set03_V005_I00629
num_objs 2
set05_V005_I00989
num_objs 0
set00_V014_I00089
num_objs 4
set03_V003_I01289
num_objs 2
set05_V003_I00209
num_objs 0
set05_V005_I01559
num_objs 0
set01_V002_I01829
num_objs 4
set05_V012_I00449
num_objs 2
set03_V002_I01769
num_objs 0
set03_V005_I00059
num_objs 0
set02_V010_I00029
num_objs 0
set03_V003_I00449
num_objs 1
set05_V007_I00239
num_objs 0
set02_V010_I01499
num_objs 1
set02_V011_I00299
num_objs 1
set02_V005_I00779
num_objs 0
set03_V004_I00089
num_objs 0
set02_V008_I00299
num_objs 0
set04_V004_I00209
num_objs 0
set05_V003_I00719
num_objs 0
set03_V001_I01019
num_objs 0
set05_V003_I01619
num_objs 0
set03_V009_I00089
num_objs 1
set01_V001_I00149
num_objs 1
set00_V012_I00089
num_objs 0
set00_V004_I01079
num_objs 1
set05_V000_I01139
num_objs 0
set01_V004_I01559
num_objs 0
set00_V008_I01439
num_objs 2
set04_V004_I01649
num_objs 1
set04_V009_I00749
num_objs 0
set03_V009_I01199
num_objs 2
set00_V009_I00839
num_objs 3
set02_V004_I00029
num_objs 0
set02_V005_I00299
num_objs 0
set04_V003_I00269
num_objs 1
set02_V008_I00419
num_objs 0
set00_V014_I01859
num_objs 2
set00_V008_I00479
num_objs 12
set05_V009_I01019
num_objs 0
set05_V005_I01169
num_objs 0
set00_V004_I01499
num_objs 10
set02_V001_I01229
num_objs 0
set03_V001_I00509
num_objs 0
set02_V009_I01409
num_objs 0
set03_V001_I01799
num_objs 0
set00_V001_I00179
num_objs 0
set00_V014_I00029
num_objs 2
set05_V005_I01259
num_objs 1
set01_V004_I00269
num_objs 4
set05_V010_I01079
num_objs 0
set00_V006_I00809
num_objs 2
set03_V002_I00989
num_objs 0
set05_V003_I00569
num_objs 0
set04_V002_I01049
num_objs 2
set03_V008_I01259
num_objs 0
set00_V000_I01019
num_objs 0
set03_V004_I00719
num_objs 0
set01_V004_I01469
num_objs 2
set02_V000_I01529
num_objs 0
set03_V008_I01469
num_objs 2
set00_V012_I00899
num_objs 7
set02_V007_I01199
num_objs 0
set04_V000_I01709
num_objs 0
set04_V000_I00059
num_objs 0
set04_V005_I00359
num_objs 0
set05_V004_I00899
num_objs 0
set03_V011_I00869
num_objs 1
set00_V004_I00569
num_objs 0
set02_V002_I01349
num_objs 0
set04_V001_I01469
num_objs 0
set05_V004_I00419
num_objs 1
set02_V000_I01499
num_objs 0
set05_V009_I01499
num_objs 0
set02_V008_I00869
num_objs 2
set03_V001_I00899
num_objs 0
set00_V000_I01799
num_objs 0
set05_V010_I01739
num_objs 0
set00_V006_I00959
num_objs 1
set04_V003_I01019
num_objs 4
set00_V011_I00479
num_objs 3
set05_V004_I00149
num_objs 0
set03_V002_I00359
num_objs 0
set02_V011_I00359
num_objs 1
set05_V006_I01019
num_objs 0
set02_V011_I00209
num_objs 0
set03_V012_I01169
num_objs 0
set05_V011_I00659
num_objs 0
set00_V001_I00359
num_objs 4
set04_V006_I00599
num_objs 1
set02_V003_I01319
num_objs 0
set02_V004_I01529
num_objs 0
set02_V005_I01139
num_objs 0
set02_V000_I01259
num_objs 0
set03_V006_I00599
num_objs 0
set00_V010_I00089
num_objs 2
set01_V001_I00869
num_objs 0
set00_V011_I00509
num_objs 4
set03_V000_I00839
num_objs 0
set00_V006_I00509
num_objs 2
set02_V003_I01949
num_objs 0
set00_V010_I01139
num_objs 6
set03_V010_I00989
num_objs 1
set02_V008_I00329
num_objs 0
set02_V011_I00269
num_objs 0
set05_V011_I00179
num_objs 0
set02_V009_I01499
num_objs 0
set03_V002_I01199
num_objs 0
set05_V010_I01499
num_objs 0
set01_V005_I00689
num_objs 2
set00_V012_I00869
num_objs 7
set04_V005_I01379
num_objs 0
set00_V013_I01079
num_objs 3
set02_V010_I01139
num_objs 0
set00_V006_I01349
num_objs 4
set01_V000_I00689
num_objs 0
set05_V001_I00119
num_objs 0
set02_V001_I00629
num_objs 0
set01_V004_I01199
num_objs 7
set02_V002_I00989
num_objs 0
set00_V012_I00149
num_objs 1
set03_V002_I01799
num_objs 0
set02_V007_I01319
num_objs 0
set00_V014_I00689
num_objs 7
set00_V009_I01529
num_objs 8
set04_V004_I00569
num_objs 0
set05_V009_I00239
num_objs 0
set03_V003_I01019
num_objs 0
set04_V011_I00989
num_objs 1
set00_V002_I01049
num_objs 0
set05_V006_I00509
num_objs 0
set02_V008_I00779
num_objs 0
set05_V005_I01049
num_objs 0
set03_V010_I01289
num_objs 0
set05_V005_I00749
num_objs 0
set00_V009_I01349
num_objs 0
set05_V005_I00389
num_objs 0
set03_V000_I01019
num_objs 0
set02_V005_I00989
num_objs 0
set05_V010_I00839
num_objs 0
set02_V007_I01559
num_objs 0
set04_V009_I00299
num_objs 0
set02_V007_I00449
num_objs 0
set03_V010_I01769
num_objs 2
set05_V008_I01829
num_objs 1
set02_V005_I01019
num_objs 0
set03_V006_I01079
num_objs 0
set02_V005_I01439
num_objs 0
set05_V011_I00749
num_objs 0
set05_V008_I01739
num_objs 0
set04_V004_I01139
num_objs 4
set03_V008_I00269
num_objs 16
set00_V007_I00449
num_objs 1
set03_V006_I00479
num_objs 0
set03_V005_I01319
num_objs 1
set03_V008_I00419
num_objs 18
set03_V012_I00779
num_objs 0
set05_V008_I00269
num_objs 0
set05_V004_I01739
num_objs 0
set00_V011_I00719
num_objs 1
set02_V010_I01829
num_objs 0
set04_V008_I00689
num_objs 0
set05_V004_I00299
num_objs 0
set05_V007_I00419
num_objs 0
set03_V002_I01619
num_objs 2
set04_V004_I01529
num_objs 0
set00_V005_I00329
num_objs 0
set04_V001_I01799
num_objs 0
set05_V008_I00359
num_objs 0
set00_V005_I00629
num_objs 0
set02_V003_I01919
num_objs 0
set02_V010_I01679
num_objs 0
set04_V001_I01529
num_objs 1
set00_V005_I01559
num_objs 0
set04_V005_I01049
num_objs 2
set02_V007_I00629
num_objs 0
set02_V000_I00479
num_objs 0
set03_V004_I00899
num_objs 0
set05_V009_I00929
num_objs 1
set05_V004_I00809
num_objs 0
set02_V006_I00989
num_objs 0
set00_V000_I00959
num_objs 0
set03_V005_I00719
num_objs 0
set03_V000_I01619
num_objs 0
set05_V003_I01019
num_objs 1
set04_V011_I01319
num_objs 0
set05_V004_I00929
num_objs 2
set00_V011_I00809
num_objs 1
set03_V005_I01649
num_objs 1
set04_V004_I00539
num_objs 0
set05_V006_I01499
num_objs 0
set02_V001_I01499
num_objs 1
set02_V002_I01259
num_objs 0
set03_V008_I01799
num_objs 1
set05_V001_I00359
num_objs 0
set03_V010_I00539
num_objs 0
set01_V001_I00179
num_objs 1
set04_V007_I01379
num_objs 1
set03_V001_I01319
num_objs 0
set04_V011_I01229
num_objs 0
set01_V003_I01769
num_objs 7
set00_V001_I01109
num_objs 3
set00_V007_I01559
num_objs 4
set01_V005_I00749
num_objs 1
set02_V009_I00149
num_objs 0
set02_V008_I00179
num_objs 0
set05_V006_I01379
num_objs 0
set03_V007_I00449
num_objs 0
set00_V004_I00179
num_objs 0
set03_V009_I01499
num_objs 2
set03_V007_I00779
num_objs 0
set04_V002_I00299
num_objs 0
set02_V006_I01829
num_objs 0
set04_V008_I01529
num_objs 1
set02_V008_I00539
num_objs 0
set03_V004_I00329
num_objs 0
set03_V001_I01139
num_objs 0
set02_V010_I00359
num_objs 1
set02_V003_I01079
num_objs 0
set02_V006_I00299
num_objs 0
set03_V003_I00029
num_objs 2
set00_V001_I00269
num_objs 4
set00_V004_I01709
num_objs 0
set02_V006_I00119
num_objs 0
set04_V001_I01829
num_objs 0
set02_V006_I01439
num_objs 0
set02_V001_I00359
num_objs 0
set02_V008_I01469
num_objs 0
set03_V002_I01109
num_objs 0
set04_V006_I00989
num_objs 1
set01_V003_I01469
num_objs 0
set02_V008_I01739
num_objs 0
set03_V011_I01289
num_objs 0
set02_V001_I00089
num_objs 0
set00_V002_I00749
num_objs 1
set01_V000_I00029
num_objs 2
set04_V007_I00329
num_objs 0
set01_V000_I01379
num_objs 3
set05_V009_I00719
num_objs 0
set03_V000_I00959
num_objs 0
set05_V007_I01199
num_objs 1
set04_V002_I01379
num_objs 2
set00_V004_I01949
num_objs 0
set01_V004_I00779
num_objs 2
set05_V003_I00419
num_objs 0
set03_V006_I00359
num_objs 0
set01_V001_I00749
num_objs 2
set02_V007_I01649
num_objs 0
set00_V011_I01379
num_objs 0
set04_V009_I00119
num_objs 0
set05_V007_I01529
num_objs 1
set04_V007_I01469
num_objs 0
set05_V008_I01589
num_objs 0
set03_V000_I01529
num_objs 0
set00_V008_I01049
num_objs 3
set00_V012_I00809
num_objs 5
set05_V005_I00329
num_objs 1
set05_V003_I01529
num_objs 0
set00_V001_I01469
num_objs 1
set02_V008_I00509
num_objs 0
set02_V006_I01379
num_objs 0
set02_V009_I01349
num_objs 0
set01_V005_I01379
num_objs 3
set01_V000_I00629
num_objs 5
set02_V007_I01049
num_objs 0
set01_V001_I01769
num_objs 0
set03_V011_I00269
num_objs 4
set02_V009_I00629
num_objs 2
set02_V002_I00869
num_objs 0
set00_V006_I00329
num_objs 3
set02_V006_I00629
num_objs 0
set02_V009_I00089
num_objs 0
set01_V001_I01229
num_objs 3
set00_V009_I00749
num_objs 5
set00_V008_I01079
num_objs 1
set03_V011_I00329
num_objs 5
set04_V008_I01409
num_objs 0
set00_V006_I00089
num_objs 4
set02_V000_I00359
num_objs 0
set04_V008_I01499
num_objs 1
set02_V000_I01079
num_objs 0
set05_V010_I00209
num_objs 0
set05_V010_I00869
num_objs 0
set05_V002_I01559
num_objs 1
set00_V006_I00449
num_objs 3
set00_V013_I01499
num_objs 4
set01_V003_I00299
num_objs 6
set03_V009_I00359
num_objs 2
set03_V000_I01139
num_objs 0
set03_V005_I01709
num_objs 1
set01_V003_I00749
num_objs 3
set03_V005_I00959
num_objs 0
set03_V012_I00659
num_objs 0
set00_V007_I00839
num_objs 2
set03_V005_I00539
num_objs 3
set05_V004_I00389
num_objs 0
set01_V000_I00779
num_objs 1
set05_V011_I01589
num_objs 1
set03_V003_I01529
num_objs 0
set04_V010_I01679
num_objs 0
set05_V006_I00449
num_objs 0
set05_V005_I01709
num_objs 0
set02_V000_I01709
num_objs 0
set00_V010_I00509
num_objs 4
set05_V005_I01799
num_objs 0
set04_V008_I01799
num_objs 0
set03_V007_I00389
num_objs 0
set00_V003_I00539
num_objs 0
set02_V003_I00329
num_objs 1
set05_V006_I00209
num_objs 0
set02_V004_I01769
num_objs 0
set05_V005_I01769
num_objs 0
set03_V007_I00569
num_objs 0
set00_V008_I00359
num_objs 0
set02_V007_I00779
num_objs 0
set05_V002_I00989
num_objs 0
set02_V004_I00329
num_objs 0
set05_V007_I01109
num_objs 0
set04_V006_I00809
num_objs 0
set04_V003_I00899
num_objs 0
set03_V011_I00989
num_objs 0
set05_V009_I00539
num_objs 0
set00_V011_I01199
num_objs 3
set02_V009_I01769
num_objs 0
set03_V000_I00149
num_objs 0
set04_V004_I00809
num_objs 3
set03_V010_I01739
num_objs 2
set04_V007_I01049
num_objs 1
set05_V012_I01079
num_objs 0
set04_V008_I01469
num_objs 1
set00_V001_I00989
num_objs 7
set00_V000_I00569
num_objs 0
set00_V008_I00539
num_objs 10
set03_V001_I00779
num_objs 0
set05_V002_I01709
num_objs 0
set03_V000_I00209
num_objs 0
set00_V009_I00539
num_objs 2
set04_V003_I00839
num_objs 0
set02_V008_I00209
num_objs 0
set04_V001_I01259
num_objs 0
set05_V006_I01169
num_objs 0
set02_V007_I01799
num_objs 0
set05_V011_I01649
num_objs 1
set04_V002_I00899
num_objs 1
set03_V007_I01709
num_objs 0
set02_V000_I00419
num_objs 0
set04_V007_I00929
num_objs 1
set00_V010_I00629
num_objs 5
set01_V005_I00209
num_objs 2
set03_V002_I00239
num_objs 0
set05_V000_I01679
num_objs 1
set03_V012_I01499
num_objs 1
set00_V004_I01349
num_objs 9
set02_V010_I01589
num_objs 0
set03_V000_I00329
num_objs 0
set00_V004_I00989
num_objs 3
set02_V007_I01619
num_objs 0
set02_V000_I01439
num_objs 0
set04_V003_I00089
num_objs 0
set02_V002_I00839
num_objs 0
set05_V004_I00599
num_objs 0
set04_V006_I01319
num_objs 0
set00_V005_I01439
num_objs 0
set02_V008_I01709
num_objs 0
set01_V000_I00809
num_objs 0
set00_V014_I00539
num_objs 5
set03_V011_I01199
num_objs 0
set04_V000_I00809
num_objs 0
set05_V008_I01649
num_objs 0
set04_V008_I01319
num_objs 0
set05_V005_I00359
num_objs 2
set00_V009_I01649
num_objs 7
set02_V005_I00179
num_objs 0
set00_V012_I01169
num_objs 2
set00_V010_I00929
num_objs 1
set05_V002_I00299
num_objs 0
set00_V001_I01169
num_objs 3
set00_V009_I00509
num_objs 2
set00_V005_I00389
num_objs 0
set02_V004_I00299
num_objs 0
set04_V008_I00239
num_objs 0
set05_V008_I00239
num_objs 2
set04_V003_I00539
num_objs 0
set01_V000_I01619
num_objs 3
set02_V002_I01619
num_objs 0
set05_V010_I01679
num_objs 0
set02_V003_I00449
num_objs 0
set02_V000_I01169
num_objs 0
set02_V010_I00329
num_objs 1
set00_V014_I01889
num_objs 2
set04_V007_I01649
num_objs 1
set04_V009_I01499
num_objs 0
set00_V001_I01289
num_objs 2
set05_V004_I01319
num_objs 0
set04_V001_I00569
num_objs 0
set03_V005_I00329
num_objs 1
set05_V010_I00599
num_objs 0
set05_V001_I01139
num_objs 0
set00_V005_I01799
num_objs 0
set00_V011_I00239
num_objs 2
set02_V005_I00569
num_objs 0
set05_V003_I00869
num_objs 0
set03_V011_I00629
num_objs 2
set01_V001_I01739
num_objs 2
set02_V008_I01109
num_objs 0
set00_V009_I00629
num_objs 2
set04_V007_I00779
num_objs 1
set02_V001_I00509
num_objs 0
set02_V010_I01109
num_objs 0
set02_V010_I00959
num_objs 0
set01_V000_I00239
num_objs 0
set02_V005_I00209
num_objs 0
set05_V002_I01289
num_objs 0
set05_V007_I01469
num_objs 1
set02_V010_I01259
num_objs 0
set02_V005_I01289
num_objs 0
set04_V007_I01439
num_objs 0
set02_V004_I01169
num_objs 0
set01_V003_I00989
num_objs 0
set00_V009_I01229
num_objs 0
set00_V000_I01829
num_objs 1
set04_V011_I00389
num_objs 1
set00_V007_I01199
num_objs 6
set05_V009_I00989
num_objs 0
set04_V005_I00959
num_objs 1
set02_V006_I01019
num_objs 0
set05_V001_I01229
num_objs 0
set03_V003_I01769
num_objs 0
set03_V004_I01829
num_objs 0
set02_V006_I01499
num_objs 0
set04_V001_I00599
num_objs 0
set04_V009_I00419
num_objs 0
set05_V000_I00719
num_objs 0
set04_V002_I00449
num_objs 0
set05_V003_I00299
num_objs 0
set02_V005_I01379
num_objs 0
set02_V009_I01709
num_objs 0
set00_V002_I01079
num_objs 0
set04_V010_I01469
num_objs 0
set03_V001_I01559
num_objs 0
set03_V000_I01499
num_objs 0
set04_V009_I01259
num_objs 0
set04_V000_I01649
num_objs 0
set05_V008_I00929
num_objs 0
set00_V012_I00269
num_objs 3
set04_V005_I00989
num_objs 1
set02_V002_I00029
num_objs 0
set02_V006_I00149
num_objs 0
set03_V005_I01439
num_objs 0
set00_V010_I00989
num_objs 3
set04_V001_I00809
num_objs 0
set03_V002_I01439
num_objs 1
set05_V007_I01049
num_objs 0
set05_V010_I01589
num_objs 1
set04_V001_I00449
num_objs 0
set04_V008_I01229
num_objs 0
set05_V008_I00329
num_objs 0
set03_V010_I01379
num_objs 1
set05_V010_I00659
num_objs 0
set00_V000_I01559
num_objs 1
set05_V011_I00599
num_objs 2
set05_V003_I00809
num_objs 0
set00_V014_I00269
num_objs 1
set01_V004_I01259
num_objs 7
set00_V014_I00599
num_objs 5
set03_V008_I01289
num_objs 4
set01_V005_I00479
num_objs 3
set04_V001_I00839
num_objs 0
set01_V003_I00719
num_objs 2
set01_V002_I00119
num_objs 3
set01_V005_I01289
num_objs 0
set03_V007_I01469
num_objs 0
set00_V012_I01109
num_objs 4
set03_V007_I00089
num_objs 0
set01_V000_I00209
num_objs 1
set00_V012_I01229
num_objs 2
set03_V004_I01409
num_objs 0
set00_V005_I01709
num_objs 0
set04_V002_I01739
num_objs 3
set02_V000_I00629
num_objs 0
set05_V005_I00209
num_objs 0
set02_V006_I01469
num_objs 0
set03_V011_I00809
num_objs 1
set03_V006_I01019
num_objs 0
set00_V006_I00029
num_objs 4
set02_V006_I01139
num_objs 0
set05_V006_I01319
num_objs 0
set00_V005_I01529
num_objs 0
set03_V011_I00149
num_objs 0
set02_V008_I00749
num_objs 0
set05_V000_I00749
num_objs 1
set02_V008_I00059
num_objs 0
set03_V004_I00299
num_objs 0
set04_V008_I00299
num_objs 0
set05_V010_I00629
num_objs 0
set03_V008_I01409
num_objs 5
set01_V000_I01259
num_objs 4
set03_V005_I01529
num_objs 0
set02_V001_I01829
num_objs 0
set05_V007_I00059
num_objs 0
set05_V011_I01529
num_objs 1
set03_V003_I00719
num_objs 1
set00_V009_I00359
num_objs 2
set02_V005_I00089
num_objs 0
set05_V006_I01409
num_objs 0
set00_V005_I02099
num_objs 0
set04_V004_I00239
num_objs 0
set03_V010_I00059
num_objs 0
set05_V008_I00089
num_objs 0
set04_V008_I01259
num_objs 0
set00_V007_I01229
num_objs 4
set00_V004_I00809
num_objs 2
set03_V002_I01139
num_objs 0
set03_V002_I00329
num_objs 0
set05_V010_I01109
num_objs 0
set04_V001_I00629
num_objs 0
set01_V004_I01589
num_objs 1
set00_V003_I00449
num_objs 0
set05_V001_I00389
num_objs 0
set04_V002_I00689
num_objs 1
set03_V011_I01559
num_objs 0
set03_V008_I01349
num_objs 1
set02_V000_I00149
num_objs 0
set03_V009_I00209
num_objs 5
set02_V011_I00779
num_objs 0
set03_V002_I00179
num_objs 0
set04_V000_I00149
num_objs 0
set04_V006_I00209
num_objs 0
set03_V004_I01109
num_objs 0
set00_V009_I01139
num_objs 0
set00_V008_I00419
num_objs 4
set05_V009_I01619
num_objs 0
set05_V009_I00509
num_objs 0
set03_V008_I00239
num_objs 16
set04_V009_I00209
num_objs 0
set01_V005_I00089
num_objs 1
set00_V002_I01169
num_objs 0
set01_V005_I01229
num_objs 1
set03_V009_I00239
num_objs 4
set03_V012_I00239
num_objs 0
set04_V000_I01049
num_objs 0
set03_V001_I00059
num_objs 1
set02_V009_I01559
num_objs 0
set02_V006_I00239
num_objs 0
set03_V003_I00299
num_objs 1
set00_V008_I00059
num_objs 7
set00_V000_I01259
num_objs 0
set04_V002_I00659
num_objs 1
set04_V007_I00809
num_objs 0
set00_V007_I01259
num_objs 4
set01_V003_I00779
num_objs 3
set01_V002_I00329
num_objs 6
set04_V011_I00359
num_objs 1
set02_V011_I00959
num_objs 0
set03_V011_I00449
num_objs 4
set05_V010_I01349
num_objs 0
set03_V007_I01019
num_objs 0
set00_V006_I01199
num_objs 3
set00_V007_I00089
num_objs 0
set01_V003_I00449
num_objs 4
set05_V006_I01799
num_objs 0
set00_V012_I01319
num_objs 1
set04_V004_I00059
num_objs 0
set05_V006_I01709
num_objs 0
set03_V008_I01439
num_objs 5
set00_V003_I00479
num_objs 1
set03_V005_I00809
num_objs 1
set03_V009_I00839
num_objs 0
set05_V004_I01559
num_objs 0
set03_V011_I00209
num_objs 3
set03_V003_I01439
num_objs 0
set00_V001_I01769
num_objs 2
set02_V010_I01739
num_objs 0
set00_V014_I01049
num_objs 1
set05_V006_I00479
num_objs 0
set02_V010_I00449
num_objs 0
set04_V011_I00449
num_objs 0
set04_V001_I00269
num_objs 0
set02_V002_I01379
num_objs 0
set05_V004_I01439
num_objs 0
set00_V004_I01769
num_objs 0
set02_V007_I00419
num_objs 1
set04_V011_I01739
num_objs 1
set02_V011_I00869
num_objs 0
set00_V006_I00059
num_objs 10
set03_V004_I01769
num_objs 0
set01_V001_I00539
num_objs 1
set01_V001_I01559
num_objs 3
set03_V001_I00179
num_objs 0
set01_V002_I00059
num_objs 3
set02_V008_I00959
num_objs 0
set05_V002_I01739
num_objs 0
set03_V004_I00419
num_objs 0
set03_V008_I01229
num_objs 4
set05_V002_I00449
num_objs 1
set02_V005_I00359
num_objs 0
set00_V009_I00869
num_objs 4
set03_V000_I01289
num_objs 0
set05_V011_I01379
num_objs 2
set01_V000_I00059
num_objs 2
set04_V008_I00599
num_objs 1
set04_V001_I00209
num_objs 0
set05_V003_I00089
num_objs 0
set01_V000_I01469
num_objs 3
set03_V012_I00809
num_objs 0
set02_V002_I00269
num_objs 0
set02_V004_I01649
num_objs 0
set02_V002_I00059
num_objs 0
set02_V003_I00689
num_objs 0
set04_V011_I01439
num_objs 0
set05_V004_I01649
num_objs 0
set01_V002_I01259
num_objs 4
set01_V000_I00119
num_objs 1
set04_V004_I01709
num_objs 0
set05_V007_I01259
num_objs 0
set00_V005_I01079
num_objs 0
set04_V004_I00869
num_objs 2
set00_V011_I00869
num_objs 0
set02_V003_I00119
num_objs 0
set05_V009_I00899
num_objs 1
set04_V011_I00119
num_objs 0
set00_V009_I00989
num_objs 3
set04_V007_I00239
num_objs 1
set00_V011_I01469
num_objs 4
set04_V003_I00299
num_objs 1
set03_V004_I01259
num_objs 0
set04_V007_I01199
num_objs 1
set02_V009_I00299
num_objs 0
set05_V004_I01289
num_objs 0
set04_V009_I00089
num_objs 0
set00_V005_I01859
num_objs 0
set00_V010_I00809
num_objs 4
set04_V006_I01409
num_objs 0
set02_V010_I01649
num_objs 0
set03_V012_I00269
num_objs 0
set03_V008_I01319
num_objs 5
set05_V001_I01529
num_objs 0
set00_V010_I01589
num_objs 3
set01_V002_I00269
num_objs 5
set05_V007_I00809
num_objs 0
set02_V004_I00629
num_objs 0
set00_V009_I00599
num_objs 1
set02_V008_I00149
num_objs 0
set05_V005_I00179
num_objs 0
set03_V009_I00449
num_objs 2
set05_V006_I01619
num_objs 0
set00_V003_I00239
num_objs 0
set03_V012_I00329
num_objs 0
set00_V013_I00689
num_objs 0
set02_V011_I00689
num_objs 0
set03_V002_I00839
num_objs 0
set00_V006_I00929
num_objs 4
set00_V009_I01259
num_objs 0
set03_V006_I00839
num_objs 0
set03_V001_I01619
num_objs 0
set03_V011_I00089
num_objs 0
set02_V005_I00119
num_objs 0
set00_V014_I00239
num_objs 0
set04_V008_I01439
num_objs 0
set05_V012_I00179
num_objs 0
set00_V001_I00149
num_objs 0
set00_V005_I01589
num_objs 0
set00_V006_I00479
num_objs 2
set04_V003_I00149
num_objs 0
set04_V003_I00929
num_objs 0
set02_V008_I00239
num_objs 0
set04_V006_I00269
num_objs 0
set05_V003_I00539
num_objs 0
set03_V011_I00419
num_objs 5
set03_V005_I01679
num_objs 1
set02_V000_I00659
num_objs 0
set04_V003_I01439
num_objs 3
set05_V011_I00959
num_objs 4
set05_V006_I00959
num_objs 0
set04_V001_I00899
num_objs 0
set03_V005_I00509
num_objs 1
set00_V002_I00629
num_objs 0
set03_V011_I00479
num_objs 4
set00_V005_I01829
num_objs 0
set04_V010_I01649
num_objs 1
set04_V010_I01769
num_objs 0
set02_V006_I01049
num_objs 0
set01_V002_I01709
num_objs 2
set03_V005_I01379
num_objs 1
set02_V001_I01199
num_objs 0
set03_V011_I00239
num_objs 2
set04_V011_I01409
num_objs 0
set00_V013_I01409
num_objs 5
set00_V008_I00569
num_objs 6
set01_V000_I00299
num_objs 0
set03_V010_I00959
num_objs 1
set03_V007_I00659
num_objs 0
set00_V000_I00779
num_objs 0
set03_V012_I01109
num_objs 0
set03_V002_I00119
num_objs 0
set03_V011_I01469
num_objs 2
set05_V008_I00479
num_objs 0
set05_V002_I00929
num_objs 0
set03_V012_I00029
num_objs 1
set02_V007_I00599
num_objs 0
set03_V005_I00929
num_objs 1
set00_V006_I01589
num_objs 2
set03_V011_I00119
num_objs 0
set05_V006_I01229
num_objs 0
set04_V006_I00329
num_objs 0
set03_V002_I00059
num_objs 0
set02_V011_I01679
num_objs 2
set01_V001_I00059
num_objs 0
set03_V003_I00419
num_objs 1
set02_V008_I00119
num_objs 0
set02_V010_I00389
num_objs 1
set00_V012_I00779
num_objs 3
set03_V000_I01409
num_objs 0
set04_V001_I01229
num_objs 0
set00_V005_I01769
num_objs 0
set04_V001_I01739
num_objs 0
set03_V003_I00329
num_objs 1
set01_V001_I01439
num_objs 6
set02_V011_I01649
num_objs 0
set02_V000_I01379
num_objs 0
set00_V012_I00719
num_objs 2
set00_V002_I00269
num_objs 2
set00_V000_I00629
num_objs 0
set05_V008_I00899
num_objs 0
set05_V012_I00239
num_objs 0
set03_V007_I00119
num_objs 0
set03_V003_I01619
num_objs 0
set04_V006_I00839
num_objs 0
set04_V001_I00989
num_objs 0
set03_V001_I01169
num_objs 0
set03_V008_I00299
num_objs 17
set00_V014_I01199
num_objs 0
set01_V001_I00269
num_objs 1
set03_V008_I00869
num_objs 4
set05_V001_I00809
num_objs 0
set02_V002_I01169
num_objs 0
set05_V002_I00239
num_objs 0
set02_V008_I00839
num_objs 0
set00_V001_I00899
num_objs 2
set05_V009_I01829
num_objs 0
set05_V012_I01259
num_objs 0
set04_V000_I01469
num_objs 0
set00_V012_I01199
num_objs 4
set05_V006_I00749
num_objs 0
set02_V009_I01259
num_objs 0
set05_V003_I00839
num_objs 0
set02_V009_I01379
num_objs 0
set02_V010_I00899
num_objs 0
set04_V003_I00569
num_objs 1
set00_V014_I00869
num_objs 2
set00_V008_I00809
num_objs 2
set05_V004_I00089
num_objs 0
set02_V004_I00779
num_objs 0
set00_V005_I00269
num_objs 0
set01_V001_I01499
num_objs 3
set05_V007_I01439
num_objs 1
set03_V008_I00749
num_objs 11
set04_V009_I01739
num_objs 0
set03_V012_I01019
num_objs 0
set04_V004_I00629
num_objs 0
set02_V010_I01289
num_objs 0
set00_V013_I01679
num_objs 0
set02_V000_I00689
num_objs 0
set05_V006_I00779
num_objs 0
set00_V001_I00929
num_objs 4
set00_V004_I01739
num_objs 0
set01_V005_I01649
num_objs 0
set00_V004_I01109
num_objs 1
set02_V006_I00869
num_objs 0
set05_V003_I01049
num_objs 1
set04_V006_I01469
num_objs 0
set03_V007_I00809
num_objs 0
set01_V002_I00479
num_objs 2
set05_V009_I01769
num_objs 0
set04_V002_I01679
num_objs 2
set05_V012_I01349
num_objs 0
set00_V010_I01199
num_objs 4
set03_V003_I00989
num_objs 0
set05_V001_I00509
num_objs 0
set02_V010_I01169
num_objs 0
set04_V000_I01289
num_objs 0
set05_V011_I00569
num_objs 2
set04_V003_I00809
num_objs 0
set02_V003_I01199
num_objs 0
set04_V000_I00299
num_objs 0
set01_V005_I00119
num_objs 1
set00_V010_I01079
num_objs 3
set02_V006_I00089
num_objs 0
set02_V005_I00329
num_objs 0
wrote gt roidb to /home/user/Disk1.8T/py_R_FCN_6_25/data/cache/voc_0712_trainval_gt_roidb.pkl
done
Preparing training data...
done
8500 roidb entries
Output will be saved to `/home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model`
Filtered 5314 roidb entries: 8500 -> 3186
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 11:56:04.066051  4216 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/train_agnostic_ohem.prototxt"
base_lr: 0.0002
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 0
snapshot_prefix: "resnet50_rfcn_ohem"
iter_size: 8
I0625 11:56:04.066094  4216 solver.cpp:81] Creating training net from train_net file: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/train_agnostic_ohem.prototxt
I0625 11:56:04.068032  4216 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "res4c_
I0625 11:56:04.069643  4216 layer_factory.hpp:77] Creating layer input-data
I0625 11:56:04.077958  4216 net.cpp:100] Creating Layer input-data
I0625 11:56:04.077977  4216 net.cpp:418] input-data -> data
I0625 11:56:04.078011  4216 net.cpp:418] input-data -> im_info
I0625 11:56:04.078025  4216 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0625 11:56:04.095683  4216 net.cpp:150] Setting up input-data
I0625 11:56:04.095705  4216 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0625 11:56:04.095710  4216 net.cpp:157] Top shape: 1 3 (3)
I0625 11:56:04.095713  4216 net.cpp:157] Top shape: 1 4 (4)
I0625 11:56:04.095715  4216 net.cpp:165] Memory required for data: 14745628
I0625 11:56:04.095731  4216 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 11:56:04.095757  4216 net.cpp:100] Creating Layer data_input-data_0_split
I0625 11:56:04.095767  4216 net.cpp:444] data_input-data_0_split <- data
I0625 11:56:04.095782  4216 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I0625 11:56:04.095800  4216 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I0625 11:56:04.095834  4216 net.cpp:150] Setting up data_input-data_0_split
I0625 11:56:04.095844  4216 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0625 11:56:04.095849  4216 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0625 11:56:04.095850  4216 net.cpp:165] Memory required for data: 44236828
I0625 11:56:04.095854  4216 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 11:56:04.095863  4216 net.cpp:100] Creating Layer im_info_input-data_1_split
I0625 11:56:04.095867  4216 net.cpp:444] im_info_input-data_1_split <- im_info
I0625 11:56:04.095877  4216 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 11:56:04.095888  4216 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 11:56:04.095913  4216 net.cpp:150] Setting up im_info_input-data_1_split
I0625 11:56:04.095919  4216 net.cpp:157] Top shape: 1 3 (3)
I0625 11:56:04.095922  4216 net.cpp:157] Top shape: 1 3 (3)
I0625 11:56:04.095924  4216 net.cpp:165] Memory required for data: 44236852
I0625 11:56:04.095927  4216 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 11:56:04.095933  4216 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I0625 11:56:04.095937  4216 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I0625 11:56:04.095947  4216 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 11:56:04.095957  4216 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 11:56:04.095983  4216 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 11:56:04.095990  4216 net.cpp:157] Top shape: 1 4 (4)
I0625 11:56:04.095994  4216 net.cpp:157] Top shape: 1 4 (4)
I0625 11:56:04.095996  4216 net.cpp:165] Memory required for data: 44236884
I0625 11:56:04.095999  4216 layer_factory.hpp:77] Creating layer conv1
I0625 11:56:04.096017  4216 net.cpp:100] Creating Layer conv1
I0625 11:56:04.096021  4216 net.cpp:444] conv1 <- data_input-data_0_split_0
I0625 11:56:04.096032  4216 net.cpp:418] conv1 -> conv1
I0625 11:56:04.382251  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5529624
I0625 11:56:04.382474  4216 net.cpp:150] Setting up conv1
I0625 11:56:04.382505  4216 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 11:56:04.382508  4216 net.cpp:165] Memory required for data: 122880084
I0625 11:56:04.382556  4216 layer_factory.hpp:77] Creating layer bn_conv1
I0625 11:56:04.382581  4216 net.cpp:100] Creating Layer bn_conv1
I0625 11:56:04.382591  4216 net.cpp:444] bn_conv1 <- conv1
I0625 11:56:04.382604  4216 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0625 11:56:04.383607  4216 net.cpp:150] Setting up bn_conv1
I0625 11:56:04.383615  4216 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 11:56:04.383631  4216 net.cpp:165] Memory required for data: 201523284
I0625 11:56:04.383658  4216 layer_factory.hpp:77] Creating layer scale_conv1
I0625 11:56:04.383673  4216 net.cpp:100] Creating Layer scale_conv1
I0625 11:56:04.383678  4216 net.cpp:444] scale_conv1 <- conv1
I0625 11:56:04.383688  4216 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0625 11:56:04.383731  4216 layer_factory.hpp:77] Creating layer scale_conv1
I0625 11:56:04.385555  4216 net.cpp:150] Setting up scale_conv1
I0625 11:56:04.385565  4216 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 11:56:04.385567  4216 net.cpp:165] Memory required for data: 280166484
I0625 11:56:04.385581  4216 layer_factory.hpp:77] Creating layer conv1_relu
I0625 11:56:04.385594  4216 net.cpp:100] Creating Layer conv1_relu
I0625 11:56:04.385601  4216 net.cpp:444] conv1_relu <- conv1
I0625 11:56:04.385612  4216 net.cpp:405] conv1_relu -> conv1 (in-place)
I0625 11:56:04.385766  4216 net.cpp:150] Setting up conv1_relu
I0625 11:56:04.385772  4216 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 11:56:04.385776  4216 net.cpp:165] Memory required for data: 358809684
I0625 11:56:04.385778  4216 layer_factory.hpp:77] Creating layer pool1
I0625 11:56:04.385797  4216 net.cpp:100] Creating Layer pool1
I0625 11:56:04.385802  4216 net.cpp:444] pool1 <- conv1
I0625 11:56:04.385813  4216 net.cpp:418] pool1 -> pool1
I0625 11:56:04.385855  4216 net.cpp:150] Setting up pool1
I0625 11:56:04.385864  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.385866  4216 net.cpp:165] Memory required for data: 378470484
I0625 11:56:04.385869  4216 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0625 11:56:04.385876  4216 net.cpp:100] Creating Layer pool1_pool1_0_split
I0625 11:56:04.385880  4216 net.cpp:444] pool1_pool1_0_split <- pool1
I0625 11:56:04.385890  4216 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0625 11:56:04.385900  4216 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0625 11:56:04.385931  4216 net.cpp:150] Setting up pool1_pool1_0_split
I0625 11:56:04.385936  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.385939  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.385941  4216 net.cpp:165] Memory required for data: 417792084
I0625 11:56:04.385944  4216 layer_factory.hpp:77] Creating layer res2a_branch1
I0625 11:56:04.385959  4216 net.cpp:100] Creating Layer res2a_branch1
I0625 11:56:04.385963  4216 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0625 11:56:04.385974  4216 net.cpp:418] res2a_branch1 -> res2a_branch1
I0625 11:56:04.386680  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.386876  4216 net.cpp:150] Setting up res2a_branch1
I0625 11:56:04.386886  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.386889  4216 net.cpp:165] Memory required for data: 496435284
I0625 11:56:04.386899  4216 layer_factory.hpp:77] Creating layer bn2a_branch1
I0625 11:56:04.386911  4216 net.cpp:100] Creating Layer bn2a_branch1
I0625 11:56:04.386915  4216 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0625 11:56:04.386927  4216 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0625 11:56:04.387152  4216 net.cpp:150] Setting up bn2a_branch1
I0625 11:56:04.387158  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.387161  4216 net.cpp:165] Memory required for data: 575078484
I0625 11:56:04.387181  4216 layer_factory.hpp:77] Creating layer scale2a_branch1
I0625 11:56:04.387193  4216 net.cpp:100] Creating Layer scale2a_branch1
I0625 11:56:04.387198  4216 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0625 11:56:04.387207  4216 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0625 11:56:04.387246  4216 layer_factory.hpp:77] Creating layer scale2a_branch1
I0625 11:56:04.387528  4216 net.cpp:150] Setting up scale2a_branch1
I0625 11:56:04.387534  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.387537  4216 net.cpp:165] Memory required for data: 653721684
I0625 11:56:04.387545  4216 layer_factory.hpp:77] Creating layer res2a_branch2a
I0625 11:56:04.387557  4216 net.cpp:100] Creating Layer res2a_branch2a
I0625 11:56:04.387562  4216 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0625 11:56:04.387573  4216 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0625 11:56:04.388716  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.388903  4216 net.cpp:150] Setting up res2a_branch2a
I0625 11:56:04.388912  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.388916  4216 net.cpp:165] Memory required for data: 673382484
I0625 11:56:04.388924  4216 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0625 11:56:04.388936  4216 net.cpp:100] Creating Layer bn2a_branch2a
I0625 11:56:04.388941  4216 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0625 11:56:04.388950  4216 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0625 11:56:04.389184  4216 net.cpp:150] Setting up bn2a_branch2a
I0625 11:56:04.389189  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.389191  4216 net.cpp:165] Memory required for data: 693043284
I0625 11:56:04.389212  4216 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0625 11:56:04.389225  4216 net.cpp:100] Creating Layer scale2a_branch2a
I0625 11:56:04.389228  4216 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0625 11:56:04.389237  4216 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0625 11:56:04.389276  4216 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0625 11:56:04.389565  4216 net.cpp:150] Setting up scale2a_branch2a
I0625 11:56:04.389572  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.389573  4216 net.cpp:165] Memory required for data: 712704084
I0625 11:56:04.389582  4216 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0625 11:56:04.389595  4216 net.cpp:100] Creating Layer res2a_branch2a_relu
I0625 11:56:04.389600  4216 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0625 11:56:04.389608  4216 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0625 11:56:04.389727  4216 net.cpp:150] Setting up res2a_branch2a_relu
I0625 11:56:04.389734  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.389735  4216 net.cpp:165] Memory required for data: 732364884
I0625 11:56:04.389739  4216 layer_factory.hpp:77] Creating layer res2a_branch2b
I0625 11:56:04.389750  4216 net.cpp:100] Creating Layer res2a_branch2b
I0625 11:56:04.389755  4216 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0625 11:56:04.389765  4216 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0625 11:56:04.390960  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0625 11:56:04.391149  4216 net.cpp:150] Setting up res2a_branch2b
I0625 11:56:04.391158  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.391161  4216 net.cpp:165] Memory required for data: 752025684
I0625 11:56:04.391170  4216 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0625 11:56:04.391181  4216 net.cpp:100] Creating Layer bn2a_branch2b
I0625 11:56:04.391186  4216 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0625 11:56:04.391196  4216 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0625 11:56:04.391436  4216 net.cpp:150] Setting up bn2a_branch2b
I0625 11:56:04.391443  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.391444  4216 net.cpp:165] Memory required for data: 771686484
I0625 11:56:04.391456  4216 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0625 11:56:04.391466  4216 net.cpp:100] Creating Layer scale2a_branch2b
I0625 11:56:04.391471  4216 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0625 11:56:04.391481  4216 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0625 11:56:04.391520  4216 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0625 11:56:04.392287  4216 net.cpp:150] Setting up scale2a_branch2b
I0625 11:56:04.392295  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.392297  4216 net.cpp:165] Memory required for data: 791347284
I0625 11:56:04.392308  4216 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0625 11:56:04.392318  4216 net.cpp:100] Creating Layer res2a_branch2b_relu
I0625 11:56:04.392323  4216 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0625 11:56:04.392331  4216 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0625 11:56:04.392649  4216 net.cpp:150] Setting up res2a_branch2b_relu
I0625 11:56:04.392657  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.392658  4216 net.cpp:165] Memory required for data: 811008084
I0625 11:56:04.392663  4216 layer_factory.hpp:77] Creating layer res2a_branch2c
I0625 11:56:04.392676  4216 net.cpp:100] Creating Layer res2a_branch2c
I0625 11:56:04.392680  4216 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0625 11:56:04.392693  4216 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0625 11:56:04.393430  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.393635  4216 net.cpp:150] Setting up res2a_branch2c
I0625 11:56:04.393658  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.393661  4216 net.cpp:165] Memory required for data: 889651284
I0625 11:56:04.393671  4216 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0625 11:56:04.393685  4216 net.cpp:100] Creating Layer bn2a_branch2c
I0625 11:56:04.393690  4216 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0625 11:56:04.393702  4216 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0625 11:56:04.393942  4216 net.cpp:150] Setting up bn2a_branch2c
I0625 11:56:04.393949  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.393962  4216 net.cpp:165] Memory required for data: 968294484
I0625 11:56:04.393975  4216 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0625 11:56:04.393987  4216 net.cpp:100] Creating Layer scale2a_branch2c
I0625 11:56:04.393991  4216 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0625 11:56:04.393999  4216 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0625 11:56:04.394039  4216 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0625 11:56:04.394326  4216 net.cpp:150] Setting up scale2a_branch2c
I0625 11:56:04.394332  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.394335  4216 net.cpp:165] Memory required for data: 1046937684
I0625 11:56:04.394343  4216 layer_factory.hpp:77] Creating layer res2a
I0625 11:56:04.394353  4216 net.cpp:100] Creating Layer res2a
I0625 11:56:04.394358  4216 net.cpp:444] res2a <- res2a_branch1
I0625 11:56:04.394366  4216 net.cpp:444] res2a <- res2a_branch2c
I0625 11:56:04.394372  4216 net.cpp:418] res2a -> res2a
I0625 11:56:04.394399  4216 net.cpp:150] Setting up res2a
I0625 11:56:04.394407  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.394408  4216 net.cpp:165] Memory required for data: 1125580884
I0625 11:56:04.394412  4216 layer_factory.hpp:77] Creating layer res2a_relu
I0625 11:56:04.394419  4216 net.cpp:100] Creating Layer res2a_relu
I0625 11:56:04.394423  4216 net.cpp:444] res2a_relu <- res2a
I0625 11:56:04.394431  4216 net.cpp:405] res2a_relu -> res2a (in-place)
I0625 11:56:04.394556  4216 net.cpp:150] Setting up res2a_relu
I0625 11:56:04.394562  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.394563  4216 net.cpp:165] Memory required for data: 1204224084
I0625 11:56:04.394567  4216 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0625 11:56:04.394575  4216 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0625 11:56:04.394579  4216 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0625 11:56:04.394588  4216 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0625 11:56:04.394599  4216 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0625 11:56:04.394632  4216 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0625 11:56:04.394639  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.394642  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.394644  4216 net.cpp:165] Memory required for data: 1361510484
I0625 11:56:04.394646  4216 layer_factory.hpp:77] Creating layer res2b_branch2a
I0625 11:56:04.394659  4216 net.cpp:100] Creating Layer res2b_branch2a
I0625 11:56:04.394662  4216 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0625 11:56:04.394672  4216 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0625 11:56:04.395457  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.395656  4216 net.cpp:150] Setting up res2b_branch2a
I0625 11:56:04.395666  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.395669  4216 net.cpp:165] Memory required for data: 1381171284
I0625 11:56:04.395679  4216 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0625 11:56:04.395694  4216 net.cpp:100] Creating Layer bn2b_branch2a
I0625 11:56:04.395699  4216 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0625 11:56:04.395709  4216 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0625 11:56:04.395956  4216 net.cpp:150] Setting up bn2b_branch2a
I0625 11:56:04.395961  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.395964  4216 net.cpp:165] Memory required for data: 1400832084
I0625 11:56:04.395987  4216 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0625 11:56:04.396001  4216 net.cpp:100] Creating Layer scale2b_branch2a
I0625 11:56:04.396006  4216 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0625 11:56:04.396018  4216 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0625 11:56:04.396059  4216 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0625 11:56:04.396848  4216 net.cpp:150] Setting up scale2b_branch2a
I0625 11:56:04.396857  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.396858  4216 net.cpp:165] Memory required for data: 1420492884
I0625 11:56:04.396869  4216 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0625 11:56:04.396879  4216 net.cpp:100] Creating Layer res2b_branch2a_relu
I0625 11:56:04.396884  4216 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0625 11:56:04.396894  4216 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0625 11:56:04.397033  4216 net.cpp:150] Setting up res2b_branch2a_relu
I0625 11:56:04.397039  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.397042  4216 net.cpp:165] Memory required for data: 1440153684
I0625 11:56:04.397044  4216 layer_factory.hpp:77] Creating layer res2b_branch2b
I0625 11:56:04.397059  4216 net.cpp:100] Creating Layer res2b_branch2b
I0625 11:56:04.397064  4216 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0625 11:56:04.397076  4216 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0625 11:56:04.397840  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0625 11:56:04.397852  4216 net.cpp:150] Setting up res2b_branch2b
I0625 11:56:04.397859  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.397861  4216 net.cpp:165] Memory required for data: 1459814484
I0625 11:56:04.397871  4216 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0625 11:56:04.397891  4216 net.cpp:100] Creating Layer bn2b_branch2b
I0625 11:56:04.397895  4216 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0625 11:56:04.397907  4216 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0625 11:56:04.398146  4216 net.cpp:150] Setting up bn2b_branch2b
I0625 11:56:04.398152  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.398154  4216 net.cpp:165] Memory required for data: 1479475284
I0625 11:56:04.398167  4216 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0625 11:56:04.398178  4216 net.cpp:100] Creating Layer scale2b_branch2b
I0625 11:56:04.398183  4216 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0625 11:56:04.398192  4216 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0625 11:56:04.398233  4216 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0625 11:56:04.398527  4216 net.cpp:150] Setting up scale2b_branch2b
I0625 11:56:04.398533  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.398535  4216 net.cpp:165] Memory required for data: 1499136084
I0625 11:56:04.398543  4216 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0625 11:56:04.398552  4216 net.cpp:100] Creating Layer res2b_branch2b_relu
I0625 11:56:04.398557  4216 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0625 11:56:04.398566  4216 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0625 11:56:04.398877  4216 net.cpp:150] Setting up res2b_branch2b_relu
I0625 11:56:04.398885  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.398888  4216 net.cpp:165] Memory required for data: 1518796884
I0625 11:56:04.398891  4216 layer_factory.hpp:77] Creating layer res2b_branch2c
I0625 11:56:04.398905  4216 net.cpp:100] Creating Layer res2b_branch2c
I0625 11:56:04.398910  4216 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0625 11:56:04.398923  4216 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0625 11:56:04.399646  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.399832  4216 net.cpp:150] Setting up res2b_branch2c
I0625 11:56:04.399842  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.399844  4216 net.cpp:165] Memory required for data: 1597440084
I0625 11:56:04.399854  4216 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0625 11:56:04.399865  4216 net.cpp:100] Creating Layer bn2b_branch2c
I0625 11:56:04.399869  4216 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0625 11:56:04.399879  4216 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0625 11:56:04.400120  4216 net.cpp:150] Setting up bn2b_branch2c
I0625 11:56:04.400126  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.400128  4216 net.cpp:165] Memory required for data: 1676083284
I0625 11:56:04.400141  4216 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0625 11:56:04.400151  4216 net.cpp:100] Creating Layer scale2b_branch2c
I0625 11:56:04.400156  4216 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0625 11:56:04.400166  4216 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0625 11:56:04.400207  4216 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0625 11:56:04.400985  4216 net.cpp:150] Setting up scale2b_branch2c
I0625 11:56:04.400995  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.400996  4216 net.cpp:165] Memory required for data: 1754726484
I0625 11:56:04.401006  4216 layer_factory.hpp:77] Creating layer res2b
I0625 11:56:04.401018  4216 net.cpp:100] Creating Layer res2b
I0625 11:56:04.401024  4216 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0625 11:56:04.401033  4216 net.cpp:444] res2b <- res2b_branch2c
I0625 11:56:04.401041  4216 net.cpp:418] res2b -> res2b
I0625 11:56:04.401077  4216 net.cpp:150] Setting up res2b
I0625 11:56:04.401084  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.401087  4216 net.cpp:165] Memory required for data: 1833369684
I0625 11:56:04.401089  4216 layer_factory.hpp:77] Creating layer res2b_relu
I0625 11:56:04.401098  4216 net.cpp:100] Creating Layer res2b_relu
I0625 11:56:04.401101  4216 net.cpp:444] res2b_relu <- res2b
I0625 11:56:04.401110  4216 net.cpp:405] res2b_relu -> res2b (in-place)
I0625 11:56:04.401243  4216 net.cpp:150] Setting up res2b_relu
I0625 11:56:04.401248  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.401252  4216 net.cpp:165] Memory required for data: 1912012884
I0625 11:56:04.401254  4216 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0625 11:56:04.401263  4216 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0625 11:56:04.401268  4216 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0625 11:56:04.401278  4216 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0625 11:56:04.401289  4216 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0625 11:56:04.401324  4216 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0625 11:56:04.401330  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.401335  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.401336  4216 net.cpp:165] Memory required for data: 2069299284
I0625 11:56:04.401340  4216 layer_factory.hpp:77] Creating layer res2c_branch2a
I0625 11:56:04.401351  4216 net.cpp:100] Creating Layer res2c_branch2a
I0625 11:56:04.401356  4216 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0625 11:56:04.401367  4216 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0625 11:56:04.402108  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.402302  4216 net.cpp:150] Setting up res2c_branch2a
I0625 11:56:04.402310  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.402313  4216 net.cpp:165] Memory required for data: 2088960084
I0625 11:56:04.402323  4216 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0625 11:56:04.402333  4216 net.cpp:100] Creating Layer bn2c_branch2a
I0625 11:56:04.402339  4216 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0625 11:56:04.402350  4216 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0625 11:56:04.402596  4216 net.cpp:150] Setting up bn2c_branch2a
I0625 11:56:04.402602  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.402604  4216 net.cpp:165] Memory required for data: 2108620884
I0625 11:56:04.402616  4216 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0625 11:56:04.402627  4216 net.cpp:100] Creating Layer scale2c_branch2a
I0625 11:56:04.402631  4216 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0625 11:56:04.402642  4216 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0625 11:56:04.402683  4216 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0625 11:56:04.402983  4216 net.cpp:150] Setting up scale2c_branch2a
I0625 11:56:04.402989  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.402992  4216 net.cpp:165] Memory required for data: 2128281684
I0625 11:56:04.403000  4216 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0625 11:56:04.403009  4216 net.cpp:100] Creating Layer res2c_branch2a_relu
I0625 11:56:04.403013  4216 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0625 11:56:04.403023  4216 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0625 11:56:04.403151  4216 net.cpp:150] Setting up res2c_branch2a_relu
I0625 11:56:04.403156  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.403158  4216 net.cpp:165] Memory required for data: 2147942484
I0625 11:56:04.403162  4216 layer_factory.hpp:77] Creating layer res2c_branch2b
I0625 11:56:04.403174  4216 net.cpp:100] Creating Layer res2c_branch2b
I0625 11:56:04.403179  4216 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0625 11:56:04.403192  4216 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0625 11:56:04.403945  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0625 11:56:04.404135  4216 net.cpp:150] Setting up res2c_branch2b
I0625 11:56:04.404145  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.404146  4216 net.cpp:165] Memory required for data: 2167603284
I0625 11:56:04.404155  4216 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0625 11:56:04.404166  4216 net.cpp:100] Creating Layer bn2c_branch2b
I0625 11:56:04.404171  4216 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0625 11:56:04.404183  4216 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0625 11:56:04.404428  4216 net.cpp:150] Setting up bn2c_branch2b
I0625 11:56:04.404433  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.404434  4216 net.cpp:165] Memory required for data: 2187264084
I0625 11:56:04.404446  4216 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0625 11:56:04.404458  4216 net.cpp:100] Creating Layer scale2c_branch2b
I0625 11:56:04.404461  4216 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0625 11:56:04.404469  4216 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0625 11:56:04.404510  4216 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0625 11:56:04.405294  4216 net.cpp:150] Setting up scale2c_branch2b
I0625 11:56:04.405303  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.405304  4216 net.cpp:165] Memory required for data: 2206924884
I0625 11:56:04.405316  4216 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0625 11:56:04.405326  4216 net.cpp:100] Creating Layer res2c_branch2b_relu
I0625 11:56:04.405331  4216 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0625 11:56:04.405342  4216 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0625 11:56:04.405481  4216 net.cpp:150] Setting up res2c_branch2b_relu
I0625 11:56:04.405488  4216 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 11:56:04.405489  4216 net.cpp:165] Memory required for data: 2226585684
I0625 11:56:04.405493  4216 layer_factory.hpp:77] Creating layer res2c_branch2c
I0625 11:56:04.405505  4216 net.cpp:100] Creating Layer res2c_branch2c
I0625 11:56:04.405510  4216 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0625 11:56:04.405521  4216 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0625 11:56:04.406257  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 11:56:04.406450  4216 net.cpp:150] Setting up res2c_branch2c
I0625 11:56:04.406458  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.406461  4216 net.cpp:165] Memory required for data: 2305228884
I0625 11:56:04.406469  4216 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0625 11:56:04.406481  4216 net.cpp:100] Creating Layer bn2c_branch2c
I0625 11:56:04.406487  4216 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0625 11:56:04.406498  4216 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0625 11:56:04.406739  4216 net.cpp:150] Setting up bn2c_branch2c
I0625 11:56:04.406744  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.406746  4216 net.cpp:165] Memory required for data: 2383872084
I0625 11:56:04.406774  4216 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0625 11:56:04.406785  4216 net.cpp:100] Creating Layer scale2c_branch2c
I0625 11:56:04.406790  4216 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0625 11:56:04.406800  4216 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0625 11:56:04.406842  4216 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0625 11:56:04.407145  4216 net.cpp:150] Setting up scale2c_branch2c
I0625 11:56:04.407152  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.407155  4216 net.cpp:165] Memory required for data: 2462515284
I0625 11:56:04.407162  4216 layer_factory.hpp:77] Creating layer res2c
I0625 11:56:04.407171  4216 net.cpp:100] Creating Layer res2c
I0625 11:56:04.407176  4216 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0625 11:56:04.407183  4216 net.cpp:444] res2c <- res2c_branch2c
I0625 11:56:04.407189  4216 net.cpp:418] res2c -> res2c
I0625 11:56:04.407217  4216 net.cpp:150] Setting up res2c
I0625 11:56:04.407223  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.407225  4216 net.cpp:165] Memory required for data: 2541158484
I0625 11:56:04.407228  4216 layer_factory.hpp:77] Creating layer res2c_relu
I0625 11:56:04.407235  4216 net.cpp:100] Creating Layer res2c_relu
I0625 11:56:04.407239  4216 net.cpp:444] res2c_relu <- res2c
I0625 11:56:04.407248  4216 net.cpp:405] res2c_relu -> res2c (in-place)
I0625 11:56:04.407558  4216 net.cpp:150] Setting up res2c_relu
I0625 11:56:04.407565  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.407567  4216 net.cpp:165] Memory required for data: 2619801684
I0625 11:56:04.407572  4216 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0625 11:56:04.407580  4216 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0625 11:56:04.407585  4216 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0625 11:56:04.407596  4216 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0625 11:56:04.407608  4216 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0625 11:56:04.407645  4216 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0625 11:56:04.407652  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.407655  4216 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 11:56:04.407657  4216 net.cpp:165] Memory required for data: 2777088084
I0625 11:56:04.407660  4216 layer_factory.hpp:77] Creating layer res3a_branch1
I0625 11:56:04.407672  4216 net.cpp:100] Creating Layer res3a_branch1
I0625 11:56:04.407677  4216 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0625 11:56:04.407688  4216 net.cpp:418] res3a_branch1 -> res3a_branch1
I0625 11:56:04.408571  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0625 11:56:04.408586  4216 net.cpp:150] Setting up res3a_branch1
I0625 11:56:04.408593  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.408596  4216 net.cpp:165] Memory required for data: 2816409684
I0625 11:56:04.408605  4216 layer_factory.hpp:77] Creating layer bn3a_branch1
I0625 11:56:04.408617  4216 net.cpp:100] Creating Layer bn3a_branch1
I0625 11:56:04.408622  4216 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0625 11:56:04.408634  4216 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0625 11:56:04.409351  4216 net.cpp:150] Setting up bn3a_branch1
I0625 11:56:04.409363  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.409363  4216 net.cpp:165] Memory required for data: 2855731284
I0625 11:56:04.409384  4216 layer_factory.hpp:77] Creating layer scale3a_branch1
I0625 11:56:04.409404  4216 net.cpp:100] Creating Layer scale3a_branch1
I0625 11:56:04.409409  4216 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0625 11:56:04.409420  4216 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0625 11:56:04.409468  4216 layer_factory.hpp:77] Creating layer scale3a_branch1
I0625 11:56:04.409618  4216 net.cpp:150] Setting up scale3a_branch1
I0625 11:56:04.409624  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.409626  4216 net.cpp:165] Memory required for data: 2895052884
I0625 11:56:04.409636  4216 layer_factory.hpp:77] Creating layer res3a_branch2a
I0625 11:56:04.409651  4216 net.cpp:100] Creating Layer res3a_branch2a
I0625 11:56:04.409656  4216 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0625 11:56:04.409667  4216 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0625 11:56:04.410475  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0625 11:56:04.410492  4216 net.cpp:150] Setting up res3a_branch2a
I0625 11:56:04.410498  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.410501  4216 net.cpp:165] Memory required for data: 2904883284
I0625 11:56:04.410511  4216 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0625 11:56:04.410523  4216 net.cpp:100] Creating Layer bn3a_branch2a
I0625 11:56:04.410528  4216 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0625 11:56:04.410538  4216 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0625 11:56:04.410707  4216 net.cpp:150] Setting up bn3a_branch2a
I0625 11:56:04.410713  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.410715  4216 net.cpp:165] Memory required for data: 2914713684
I0625 11:56:04.410728  4216 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0625 11:56:04.410738  4216 net.cpp:100] Creating Layer scale3a_branch2a
I0625 11:56:04.410743  4216 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0625 11:56:04.410753  4216 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0625 11:56:04.410792  4216 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0625 11:56:04.410974  4216 net.cpp:150] Setting up scale3a_branch2a
I0625 11:56:04.410980  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.410982  4216 net.cpp:165] Memory required for data: 2924544084
I0625 11:56:04.410991  4216 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0625 11:56:04.411001  4216 net.cpp:100] Creating Layer res3a_branch2a_relu
I0625 11:56:04.411006  4216 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0625 11:56:04.411015  4216 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0625 11:56:04.411145  4216 net.cpp:150] Setting up res3a_branch2a_relu
I0625 11:56:04.411152  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.411154  4216 net.cpp:165] Memory required for data: 2934374484
I0625 11:56:04.411157  4216 layer_factory.hpp:77] Creating layer res3a_branch2b
I0625 11:56:04.411168  4216 net.cpp:100] Creating Layer res3a_branch2b
I0625 11:56:04.411173  4216 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0625 11:56:04.411185  4216 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0625 11:56:04.412693  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 11:56:04.412897  4216 net.cpp:150] Setting up res3a_branch2b
I0625 11:56:04.412909  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.412911  4216 net.cpp:165] Memory required for data: 2944204884
I0625 11:56:04.412923  4216 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0625 11:56:04.412940  4216 net.cpp:100] Creating Layer bn3a_branch2b
I0625 11:56:04.412946  4216 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0625 11:56:04.412958  4216 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0625 11:56:04.413130  4216 net.cpp:150] Setting up bn3a_branch2b
I0625 11:56:04.413136  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.413137  4216 net.cpp:165] Memory required for data: 2954035284
I0625 11:56:04.413149  4216 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0625 11:56:04.413172  4216 net.cpp:100] Creating Layer scale3a_branch2b
I0625 11:56:04.413177  4216 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0625 11:56:04.413185  4216 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0625 11:56:04.413228  4216 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0625 11:56:04.413373  4216 net.cpp:150] Setting up scale3a_branch2b
I0625 11:56:04.413379  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.413381  4216 net.cpp:165] Memory required for data: 2963865684
I0625 11:56:04.413391  4216 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0625 11:56:04.413399  4216 net.cpp:100] Creating Layer res3a_branch2b_relu
I0625 11:56:04.413403  4216 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0625 11:56:04.413413  4216 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0625 11:56:04.413540  4216 net.cpp:150] Setting up res3a_branch2b_relu
I0625 11:56:04.413547  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.413547  4216 net.cpp:165] Memory required for data: 2973696084
I0625 11:56:04.413552  4216 layer_factory.hpp:77] Creating layer res3a_branch2c
I0625 11:56:04.413564  4216 net.cpp:100] Creating Layer res3a_branch2c
I0625 11:56:04.413569  4216 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0625 11:56:04.413580  4216 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0625 11:56:04.414386  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.414398  4216 net.cpp:150] Setting up res3a_branch2c
I0625 11:56:04.414404  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.414407  4216 net.cpp:165] Memory required for data: 3013017684
I0625 11:56:04.414414  4216 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0625 11:56:04.414427  4216 net.cpp:100] Creating Layer bn3a_branch2c
I0625 11:56:04.414432  4216 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0625 11:56:04.414443  4216 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0625 11:56:04.414609  4216 net.cpp:150] Setting up bn3a_branch2c
I0625 11:56:04.414614  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.414616  4216 net.cpp:165] Memory required for data: 3052339284
I0625 11:56:04.414629  4216 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0625 11:56:04.414640  4216 net.cpp:100] Creating Layer scale3a_branch2c
I0625 11:56:04.414644  4216 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0625 11:56:04.414654  4216 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0625 11:56:04.414691  4216 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0625 11:56:04.414839  4216 net.cpp:150] Setting up scale3a_branch2c
I0625 11:56:04.414844  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.414846  4216 net.cpp:165] Memory required for data: 3091660884
I0625 11:56:04.414855  4216 layer_factory.hpp:77] Creating layer res3a
I0625 11:56:04.414868  4216 net.cpp:100] Creating Layer res3a
I0625 11:56:04.414873  4216 net.cpp:444] res3a <- res3a_branch1
I0625 11:56:04.414881  4216 net.cpp:444] res3a <- res3a_branch2c
I0625 11:56:04.414888  4216 net.cpp:418] res3a -> res3a
I0625 11:56:04.414918  4216 net.cpp:150] Setting up res3a
I0625 11:56:04.414924  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.414925  4216 net.cpp:165] Memory required for data: 3130982484
I0625 11:56:04.414928  4216 layer_factory.hpp:77] Creating layer res3a_relu
I0625 11:56:04.414935  4216 net.cpp:100] Creating Layer res3a_relu
I0625 11:56:04.414940  4216 net.cpp:444] res3a_relu <- res3a
I0625 11:56:04.414950  4216 net.cpp:405] res3a_relu -> res3a (in-place)
I0625 11:56:04.415264  4216 net.cpp:150] Setting up res3a_relu
I0625 11:56:04.415272  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.415274  4216 net.cpp:165] Memory required for data: 3170304084
I0625 11:56:04.415278  4216 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0625 11:56:04.415288  4216 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0625 11:56:04.415293  4216 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0625 11:56:04.415304  4216 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0625 11:56:04.415316  4216 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0625 11:56:04.415354  4216 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0625 11:56:04.415361  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.415364  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.415366  4216 net.cpp:165] Memory required for data: 3248947284
I0625 11:56:04.415369  4216 layer_factory.hpp:77] Creating layer res3b_branch2a
I0625 11:56:04.415382  4216 net.cpp:100] Creating Layer res3b_branch2a
I0625 11:56:04.415387  4216 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0625 11:56:04.415398  4216 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0625 11:56:04.416195  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.416211  4216 net.cpp:150] Setting up res3b_branch2a
I0625 11:56:04.416218  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.416220  4216 net.cpp:165] Memory required for data: 3258777684
I0625 11:56:04.416229  4216 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0625 11:56:04.416240  4216 net.cpp:100] Creating Layer bn3b_branch2a
I0625 11:56:04.416245  4216 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0625 11:56:04.416257  4216 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0625 11:56:04.416426  4216 net.cpp:150] Setting up bn3b_branch2a
I0625 11:56:04.416432  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.416435  4216 net.cpp:165] Memory required for data: 3268608084
I0625 11:56:04.416447  4216 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0625 11:56:04.416457  4216 net.cpp:100] Creating Layer scale3b_branch2a
I0625 11:56:04.416462  4216 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0625 11:56:04.416471  4216 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0625 11:56:04.416513  4216 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0625 11:56:04.417165  4216 net.cpp:150] Setting up scale3b_branch2a
I0625 11:56:04.417172  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.417174  4216 net.cpp:165] Memory required for data: 3278438484
I0625 11:56:04.417186  4216 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0625 11:56:04.417194  4216 net.cpp:100] Creating Layer res3b_branch2a_relu
I0625 11:56:04.417201  4216 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0625 11:56:04.417209  4216 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0625 11:56:04.417346  4216 net.cpp:150] Setting up res3b_branch2a_relu
I0625 11:56:04.417352  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.417354  4216 net.cpp:165] Memory required for data: 3288268884
I0625 11:56:04.417358  4216 layer_factory.hpp:77] Creating layer res3b_branch2b
I0625 11:56:04.417371  4216 net.cpp:100] Creating Layer res3b_branch2b
I0625 11:56:04.417376  4216 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0625 11:56:04.417388  4216 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0625 11:56:04.418505  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 11:56:04.418701  4216 net.cpp:150] Setting up res3b_branch2b
I0625 11:56:04.418710  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.418712  4216 net.cpp:165] Memory required for data: 3298099284
I0625 11:56:04.418722  4216 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0625 11:56:04.418735  4216 net.cpp:100] Creating Layer bn3b_branch2b
I0625 11:56:04.418738  4216 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0625 11:56:04.418751  4216 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0625 11:56:04.418937  4216 net.cpp:150] Setting up bn3b_branch2b
I0625 11:56:04.418943  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.418946  4216 net.cpp:165] Memory required for data: 3307929684
I0625 11:56:04.418959  4216 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0625 11:56:04.418970  4216 net.cpp:100] Creating Layer scale3b_branch2b
I0625 11:56:04.418974  4216 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0625 11:56:04.418984  4216 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0625 11:56:04.419026  4216 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0625 11:56:04.419173  4216 net.cpp:150] Setting up scale3b_branch2b
I0625 11:56:04.419178  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.419180  4216 net.cpp:165] Memory required for data: 3317760084
I0625 11:56:04.419188  4216 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0625 11:56:04.419198  4216 net.cpp:100] Creating Layer res3b_branch2b_relu
I0625 11:56:04.419203  4216 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0625 11:56:04.419212  4216 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0625 11:56:04.419342  4216 net.cpp:150] Setting up res3b_branch2b_relu
I0625 11:56:04.419348  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.419349  4216 net.cpp:165] Memory required for data: 3327590484
I0625 11:56:04.419353  4216 layer_factory.hpp:77] Creating layer res3b_branch2c
I0625 11:56:04.419365  4216 net.cpp:100] Creating Layer res3b_branch2c
I0625 11:56:04.419369  4216 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0625 11:56:04.419381  4216 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0625 11:56:04.420183  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.420197  4216 net.cpp:150] Setting up res3b_branch2c
I0625 11:56:04.420202  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.420205  4216 net.cpp:165] Memory required for data: 3366912084
I0625 11:56:04.420213  4216 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0625 11:56:04.420224  4216 net.cpp:100] Creating Layer bn3b_branch2c
I0625 11:56:04.420229  4216 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0625 11:56:04.420241  4216 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0625 11:56:04.420414  4216 net.cpp:150] Setting up bn3b_branch2c
I0625 11:56:04.420419  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.420421  4216 net.cpp:165] Memory required for data: 3406233684
I0625 11:56:04.420434  4216 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0625 11:56:04.420444  4216 net.cpp:100] Creating Layer scale3b_branch2c
I0625 11:56:04.420449  4216 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0625 11:56:04.420460  4216 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0625 11:56:04.420498  4216 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0625 11:56:04.420645  4216 net.cpp:150] Setting up scale3b_branch2c
I0625 11:56:04.420651  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.420653  4216 net.cpp:165] Memory required for data: 3445555284
I0625 11:56:04.420662  4216 layer_factory.hpp:77] Creating layer res3b
I0625 11:56:04.420671  4216 net.cpp:100] Creating Layer res3b
I0625 11:56:04.420676  4216 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0625 11:56:04.420684  4216 net.cpp:444] res3b <- res3b_branch2c
I0625 11:56:04.420691  4216 net.cpp:418] res3b -> res3b
I0625 11:56:04.420720  4216 net.cpp:150] Setting up res3b
I0625 11:56:04.420727  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.420729  4216 net.cpp:165] Memory required for data: 3484876884
I0625 11:56:04.420732  4216 layer_factory.hpp:77] Creating layer res3b_relu
I0625 11:56:04.420739  4216 net.cpp:100] Creating Layer res3b_relu
I0625 11:56:04.420743  4216 net.cpp:444] res3b_relu <- res3b
I0625 11:56:04.420753  4216 net.cpp:405] res3b_relu -> res3b (in-place)
I0625 11:56:04.421069  4216 net.cpp:150] Setting up res3b_relu
I0625 11:56:04.421077  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.421078  4216 net.cpp:165] Memory required for data: 3524198484
I0625 11:56:04.421082  4216 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0625 11:56:04.421092  4216 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0625 11:56:04.421097  4216 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0625 11:56:04.421108  4216 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0625 11:56:04.421120  4216 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0625 11:56:04.421159  4216 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0625 11:56:04.421165  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.421169  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.421171  4216 net.cpp:165] Memory required for data: 3602841684
I0625 11:56:04.421175  4216 layer_factory.hpp:77] Creating layer res3c_branch2a
I0625 11:56:04.421186  4216 net.cpp:100] Creating Layer res3c_branch2a
I0625 11:56:04.421191  4216 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0625 11:56:04.421202  4216 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0625 11:56:04.422000  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.422016  4216 net.cpp:150] Setting up res3c_branch2a
I0625 11:56:04.422022  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.422025  4216 net.cpp:165] Memory required for data: 3612672084
I0625 11:56:04.422034  4216 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0625 11:56:04.422045  4216 net.cpp:100] Creating Layer bn3c_branch2a
I0625 11:56:04.422050  4216 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0625 11:56:04.422061  4216 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0625 11:56:04.422233  4216 net.cpp:150] Setting up bn3c_branch2a
I0625 11:56:04.422238  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.422241  4216 net.cpp:165] Memory required for data: 3622502484
I0625 11:56:04.422253  4216 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0625 11:56:04.422264  4216 net.cpp:100] Creating Layer scale3c_branch2a
I0625 11:56:04.422269  4216 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0625 11:56:04.422279  4216 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0625 11:56:04.422332  4216 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0625 11:56:04.422524  4216 net.cpp:150] Setting up scale3c_branch2a
I0625 11:56:04.422531  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.422534  4216 net.cpp:165] Memory required for data: 3632332884
I0625 11:56:04.422545  4216 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0625 11:56:04.422556  4216 net.cpp:100] Creating Layer res3c_branch2a_relu
I0625 11:56:04.422562  4216 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0625 11:56:04.422574  4216 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0625 11:56:04.422729  4216 net.cpp:150] Setting up res3c_branch2a_relu
I0625 11:56:04.422736  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.422739  4216 net.cpp:165] Memory required for data: 3642163284
I0625 11:56:04.422744  4216 layer_factory.hpp:77] Creating layer res3c_branch2b
I0625 11:56:04.422760  4216 net.cpp:100] Creating Layer res3c_branch2b
I0625 11:56:04.422765  4216 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0625 11:56:04.422780  4216 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0625 11:56:04.423940  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 11:56:04.424140  4216 net.cpp:150] Setting up res3c_branch2b
I0625 11:56:04.424149  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.424151  4216 net.cpp:165] Memory required for data: 3651993684
I0625 11:56:04.424161  4216 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0625 11:56:04.424173  4216 net.cpp:100] Creating Layer bn3c_branch2b
I0625 11:56:04.424177  4216 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0625 11:56:04.424190  4216 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0625 11:56:04.424365  4216 net.cpp:150] Setting up bn3c_branch2b
I0625 11:56:04.424371  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.424372  4216 net.cpp:165] Memory required for data: 3661824084
I0625 11:56:04.424386  4216 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0625 11:56:04.424396  4216 net.cpp:100] Creating Layer scale3c_branch2b
I0625 11:56:04.424399  4216 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0625 11:56:04.424409  4216 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0625 11:56:04.424453  4216 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0625 11:56:04.424599  4216 net.cpp:150] Setting up scale3c_branch2b
I0625 11:56:04.424605  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.424607  4216 net.cpp:165] Memory required for data: 3671654484
I0625 11:56:04.424615  4216 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0625 11:56:04.424623  4216 net.cpp:100] Creating Layer res3c_branch2b_relu
I0625 11:56:04.424628  4216 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0625 11:56:04.424636  4216 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0625 11:56:04.424770  4216 net.cpp:150] Setting up res3c_branch2b_relu
I0625 11:56:04.424777  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.424778  4216 net.cpp:165] Memory required for data: 3681484884
I0625 11:56:04.424782  4216 layer_factory.hpp:77] Creating layer res3c_branch2c
I0625 11:56:04.424793  4216 net.cpp:100] Creating Layer res3c_branch2c
I0625 11:56:04.424798  4216 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0625 11:56:04.424809  4216 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0625 11:56:04.425622  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.425633  4216 net.cpp:150] Setting up res3c_branch2c
I0625 11:56:04.425640  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.425642  4216 net.cpp:165] Memory required for data: 3720806484
I0625 11:56:04.425650  4216 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0625 11:56:04.425662  4216 net.cpp:100] Creating Layer bn3c_branch2c
I0625 11:56:04.425668  4216 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0625 11:56:04.425678  4216 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0625 11:56:04.425848  4216 net.cpp:150] Setting up bn3c_branch2c
I0625 11:56:04.425853  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.425855  4216 net.cpp:165] Memory required for data: 3760128084
I0625 11:56:04.425868  4216 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0625 11:56:04.425879  4216 net.cpp:100] Creating Layer scale3c_branch2c
I0625 11:56:04.425884  4216 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0625 11:56:04.425892  4216 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0625 11:56:04.425931  4216 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0625 11:56:04.426082  4216 net.cpp:150] Setting up scale3c_branch2c
I0625 11:56:04.426089  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.426090  4216 net.cpp:165] Memory required for data: 3799449684
I0625 11:56:04.426098  4216 layer_factory.hpp:77] Creating layer res3c
I0625 11:56:04.426106  4216 net.cpp:100] Creating Layer res3c
I0625 11:56:04.426110  4216 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0625 11:56:04.426118  4216 net.cpp:444] res3c <- res3c_branch2c
I0625 11:56:04.426127  4216 net.cpp:418] res3c -> res3c
I0625 11:56:04.426156  4216 net.cpp:150] Setting up res3c
I0625 11:56:04.426163  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.426165  4216 net.cpp:165] Memory required for data: 3838771284
I0625 11:56:04.426168  4216 layer_factory.hpp:77] Creating layer res3c_relu
I0625 11:56:04.426175  4216 net.cpp:100] Creating Layer res3c_relu
I0625 11:56:04.426179  4216 net.cpp:444] res3c_relu <- res3c
I0625 11:56:04.426188  4216 net.cpp:405] res3c_relu -> res3c (in-place)
I0625 11:56:04.426311  4216 net.cpp:150] Setting up res3c_relu
I0625 11:56:04.426317  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.426319  4216 net.cpp:165] Memory required for data: 3878092884
I0625 11:56:04.426323  4216 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0625 11:56:04.426331  4216 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0625 11:56:04.426335  4216 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0625 11:56:04.426347  4216 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0625 11:56:04.426358  4216 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0625 11:56:04.426394  4216 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0625 11:56:04.426400  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.426404  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.426406  4216 net.cpp:165] Memory required for data: 3956736084
I0625 11:56:04.426409  4216 layer_factory.hpp:77] Creating layer res3d_branch2a
I0625 11:56:04.426420  4216 net.cpp:100] Creating Layer res3d_branch2a
I0625 11:56:04.426425  4216 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0625 11:56:04.426436  4216 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0625 11:56:04.427759  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.427776  4216 net.cpp:150] Setting up res3d_branch2a
I0625 11:56:04.427783  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.427786  4216 net.cpp:165] Memory required for data: 3966566484
I0625 11:56:04.427795  4216 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0625 11:56:04.427809  4216 net.cpp:100] Creating Layer bn3d_branch2a
I0625 11:56:04.427814  4216 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0625 11:56:04.427826  4216 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0625 11:56:04.427999  4216 net.cpp:150] Setting up bn3d_branch2a
I0625 11:56:04.428005  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.428007  4216 net.cpp:165] Memory required for data: 3976396884
I0625 11:56:04.428041  4216 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0625 11:56:04.428053  4216 net.cpp:100] Creating Layer scale3d_branch2a
I0625 11:56:04.428058  4216 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0625 11:56:04.428067  4216 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0625 11:56:04.428112  4216 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0625 11:56:04.428261  4216 net.cpp:150] Setting up scale3d_branch2a
I0625 11:56:04.428267  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.428268  4216 net.cpp:165] Memory required for data: 3986227284
I0625 11:56:04.428277  4216 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0625 11:56:04.428285  4216 net.cpp:100] Creating Layer res3d_branch2a_relu
I0625 11:56:04.428289  4216 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0625 11:56:04.428299  4216 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0625 11:56:04.428622  4216 net.cpp:150] Setting up res3d_branch2a_relu
I0625 11:56:04.428629  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.428632  4216 net.cpp:165] Memory required for data: 3996057684
I0625 11:56:04.428635  4216 layer_factory.hpp:77] Creating layer res3d_branch2b
I0625 11:56:04.428649  4216 net.cpp:100] Creating Layer res3d_branch2b
I0625 11:56:04.428654  4216 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0625 11:56:04.428668  4216 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0625 11:56:04.430083  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 11:56:04.430279  4216 net.cpp:150] Setting up res3d_branch2b
I0625 11:56:04.430289  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.430291  4216 net.cpp:165] Memory required for data: 4005888084
I0625 11:56:04.430301  4216 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0625 11:56:04.430313  4216 net.cpp:100] Creating Layer bn3d_branch2b
I0625 11:56:04.430318  4216 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0625 11:56:04.430330  4216 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0625 11:56:04.430507  4216 net.cpp:150] Setting up bn3d_branch2b
I0625 11:56:04.430513  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.430516  4216 net.cpp:165] Memory required for data: 4015718484
I0625 11:56:04.430527  4216 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0625 11:56:04.430538  4216 net.cpp:100] Creating Layer scale3d_branch2b
I0625 11:56:04.430543  4216 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0625 11:56:04.430552  4216 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0625 11:56:04.430594  4216 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0625 11:56:04.430742  4216 net.cpp:150] Setting up scale3d_branch2b
I0625 11:56:04.430748  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.430750  4216 net.cpp:165] Memory required for data: 4025548884
I0625 11:56:04.430758  4216 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0625 11:56:04.430766  4216 net.cpp:100] Creating Layer res3d_branch2b_relu
I0625 11:56:04.430770  4216 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0625 11:56:04.430778  4216 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0625 11:56:04.430925  4216 net.cpp:150] Setting up res3d_branch2b_relu
I0625 11:56:04.430932  4216 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 11:56:04.430934  4216 net.cpp:165] Memory required for data: 4035379284
I0625 11:56:04.430938  4216 layer_factory.hpp:77] Creating layer res3d_branch2c
I0625 11:56:04.430950  4216 net.cpp:100] Creating Layer res3d_branch2c
I0625 11:56:04.430955  4216 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0625 11:56:04.430968  4216 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0625 11:56:04.431797  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 11:56:04.431809  4216 net.cpp:150] Setting up res3d_branch2c
I0625 11:56:04.431815  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.431818  4216 net.cpp:165] Memory required for data: 4074700884
I0625 11:56:04.431826  4216 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0625 11:56:04.431838  4216 net.cpp:100] Creating Layer bn3d_branch2c
I0625 11:56:04.431843  4216 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0625 11:56:04.431852  4216 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0625 11:56:04.432031  4216 net.cpp:150] Setting up bn3d_branch2c
I0625 11:56:04.432036  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.432039  4216 net.cpp:165] Memory required for data: 4114022484
I0625 11:56:04.432051  4216 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0625 11:56:04.432062  4216 net.cpp:100] Creating Layer scale3d_branch2c
I0625 11:56:04.432067  4216 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0625 11:56:04.432076  4216 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0625 11:56:04.432116  4216 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0625 11:56:04.432265  4216 net.cpp:150] Setting up scale3d_branch2c
I0625 11:56:04.432271  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.432273  4216 net.cpp:165] Memory required for data: 4153344084
I0625 11:56:04.432282  4216 layer_factory.hpp:77] Creating layer res3d
I0625 11:56:04.432291  4216 net.cpp:100] Creating Layer res3d
I0625 11:56:04.432296  4216 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0625 11:56:04.432304  4216 net.cpp:444] res3d <- res3d_branch2c
I0625 11:56:04.432312  4216 net.cpp:418] res3d -> res3d
I0625 11:56:04.432341  4216 net.cpp:150] Setting up res3d
I0625 11:56:04.432348  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.432350  4216 net.cpp:165] Memory required for data: 4192665684
I0625 11:56:04.432353  4216 layer_factory.hpp:77] Creating layer res3d_relu
I0625 11:56:04.432361  4216 net.cpp:100] Creating Layer res3d_relu
I0625 11:56:04.432365  4216 net.cpp:444] res3d_relu <- res3d
I0625 11:56:04.432374  4216 net.cpp:405] res3d_relu -> res3d (in-place)
I0625 11:56:04.432503  4216 net.cpp:150] Setting up res3d_relu
I0625 11:56:04.432509  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.432512  4216 net.cpp:165] Memory required for data: 4231987284
I0625 11:56:04.432515  4216 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0625 11:56:04.432524  4216 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0625 11:56:04.432528  4216 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0625 11:56:04.432538  4216 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0625 11:56:04.432549  4216 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0625 11:56:04.432586  4216 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0625 11:56:04.432593  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.432596  4216 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 11:56:04.432598  4216 net.cpp:165] Memory required for data: 4310630484
I0625 11:56:04.432602  4216 layer_factory.hpp:77] Creating layer res4a_branch1
I0625 11:56:04.432615  4216 net.cpp:100] Creating Layer res4a_branch1
I0625 11:56:04.432618  4216 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0625 11:56:04.432631  4216 net.cpp:418] res4a_branch1 -> res4a_branch1
I0625 11:56:04.434545  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 11:56:04.434751  4216 net.cpp:150] Setting up res4a_branch1
I0625 11:56:04.434762  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.434763  4216 net.cpp:165] Memory required for data: 4330291284
I0625 11:56:04.434777  4216 layer_factory.hpp:77] Creating layer bn4a_branch1
I0625 11:56:04.434792  4216 net.cpp:100] Creating Layer bn4a_branch1
I0625 11:56:04.434798  4216 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0625 11:56:04.434810  4216 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0625 11:56:04.434991  4216 net.cpp:150] Setting up bn4a_branch1
I0625 11:56:04.434998  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.434999  4216 net.cpp:165] Memory required for data: 4349952084
I0625 11:56:04.435012  4216 layer_factory.hpp:77] Creating layer scale4a_branch1
I0625 11:56:04.435024  4216 net.cpp:100] Creating Layer scale4a_branch1
I0625 11:56:04.435029  4216 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0625 11:56:04.435039  4216 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0625 11:56:04.435081  4216 layer_factory.hpp:77] Creating layer scale4a_branch1
I0625 11:56:04.435210  4216 net.cpp:150] Setting up scale4a_branch1
I0625 11:56:04.435216  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.435219  4216 net.cpp:165] Memory required for data: 4369612884
I0625 11:56:04.435226  4216 layer_factory.hpp:77] Creating layer res4a_branch2a
I0625 11:56:04.435240  4216 net.cpp:100] Creating Layer res4a_branch2a
I0625 11:56:04.435246  4216 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0625 11:56:04.435259  4216 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0625 11:56:04.436164  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 11:56:04.436180  4216 net.cpp:150] Setting up res4a_branch2a
I0625 11:56:04.436187  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.436189  4216 net.cpp:165] Memory required for data: 4374528084
I0625 11:56:04.436197  4216 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0625 11:56:04.436209  4216 net.cpp:100] Creating Layer bn4a_branch2a
I0625 11:56:04.436214  4216 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0625 11:56:04.436226  4216 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0625 11:56:04.436389  4216 net.cpp:150] Setting up bn4a_branch2a
I0625 11:56:04.436395  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.436398  4216 net.cpp:165] Memory required for data: 4379443284
I0625 11:56:04.436410  4216 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0625 11:56:04.436420  4216 net.cpp:100] Creating Layer scale4a_branch2a
I0625 11:56:04.436425  4216 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0625 11:56:04.436434  4216 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0625 11:56:04.436478  4216 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0625 11:56:04.436599  4216 net.cpp:150] Setting up scale4a_branch2a
I0625 11:56:04.436604  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.436607  4216 net.cpp:165] Memory required for data: 4384358484
I0625 11:56:04.436615  4216 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0625 11:56:04.436625  4216 net.cpp:100] Creating Layer res4a_branch2a_relu
I0625 11:56:04.436630  4216 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0625 11:56:04.436637  4216 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0625 11:56:04.436960  4216 net.cpp:150] Setting up res4a_branch2a_relu
I0625 11:56:04.436967  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.436970  4216 net.cpp:165] Memory required for data: 4389273684
I0625 11:56:04.436975  4216 layer_factory.hpp:77] Creating layer res4a_branch2b
I0625 11:56:04.436987  4216 net.cpp:100] Creating Layer res4a_branch2b
I0625 11:56:04.436992  4216 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0625 11:56:04.437005  4216 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0625 11:56:04.439071  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 11:56:04.439277  4216 net.cpp:150] Setting up res4a_branch2b
I0625 11:56:04.439288  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.439291  4216 net.cpp:165] Memory required for data: 4394188884
I0625 11:56:04.439302  4216 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0625 11:56:04.439318  4216 net.cpp:100] Creating Layer bn4a_branch2b
I0625 11:56:04.439324  4216 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0625 11:56:04.439337  4216 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0625 11:56:04.439509  4216 net.cpp:150] Setting up bn4a_branch2b
I0625 11:56:04.439514  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.439517  4216 net.cpp:165] Memory required for data: 4399104084
I0625 11:56:04.439529  4216 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0625 11:56:04.439541  4216 net.cpp:100] Creating Layer scale4a_branch2b
I0625 11:56:04.439546  4216 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0625 11:56:04.439555  4216 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0625 11:56:04.439599  4216 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0625 11:56:04.439723  4216 net.cpp:150] Setting up scale4a_branch2b
I0625 11:56:04.439728  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.439730  4216 net.cpp:165] Memory required for data: 4404019284
I0625 11:56:04.439739  4216 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0625 11:56:04.439749  4216 net.cpp:100] Creating Layer res4a_branch2b_relu
I0625 11:56:04.439754  4216 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0625 11:56:04.439762  4216 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0625 11:56:04.439909  4216 net.cpp:150] Setting up res4a_branch2b_relu
I0625 11:56:04.439915  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.439916  4216 net.cpp:165] Memory required for data: 4408934484
I0625 11:56:04.439920  4216 layer_factory.hpp:77] Creating layer res4a_branch2c
I0625 11:56:04.439934  4216 net.cpp:100] Creating Layer res4a_branch2c
I0625 11:56:04.439939  4216 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0625 11:56:04.439950  4216 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0625 11:56:04.441576  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.441596  4216 net.cpp:150] Setting up res4a_branch2c
I0625 11:56:04.441604  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.441606  4216 net.cpp:165] Memory required for data: 4428595284
I0625 11:56:04.441618  4216 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0625 11:56:04.441635  4216 net.cpp:100] Creating Layer bn4a_branch2c
I0625 11:56:04.441642  4216 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0625 11:56:04.441653  4216 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0625 11:56:04.441825  4216 net.cpp:150] Setting up bn4a_branch2c
I0625 11:56:04.441831  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.441833  4216 net.cpp:165] Memory required for data: 4448256084
I0625 11:56:04.441845  4216 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0625 11:56:04.441859  4216 net.cpp:100] Creating Layer scale4a_branch2c
I0625 11:56:04.441864  4216 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0625 11:56:04.441872  4216 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0625 11:56:04.441915  4216 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0625 11:56:04.442045  4216 net.cpp:150] Setting up scale4a_branch2c
I0625 11:56:04.442051  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.442054  4216 net.cpp:165] Memory required for data: 4467916884
I0625 11:56:04.442061  4216 layer_factory.hpp:77] Creating layer res4a
I0625 11:56:04.442085  4216 net.cpp:100] Creating Layer res4a
I0625 11:56:04.442090  4216 net.cpp:444] res4a <- res4a_branch1
I0625 11:56:04.442098  4216 net.cpp:444] res4a <- res4a_branch2c
I0625 11:56:04.442106  4216 net.cpp:418] res4a -> res4a
I0625 11:56:04.442147  4216 net.cpp:150] Setting up res4a
I0625 11:56:04.442155  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.442158  4216 net.cpp:165] Memory required for data: 4487577684
I0625 11:56:04.442167  4216 layer_factory.hpp:77] Creating layer res4a_relu
I0625 11:56:04.442178  4216 net.cpp:100] Creating Layer res4a_relu
I0625 11:56:04.442184  4216 net.cpp:444] res4a_relu <- res4a
I0625 11:56:04.442198  4216 net.cpp:405] res4a_relu -> res4a (in-place)
I0625 11:56:04.442338  4216 net.cpp:150] Setting up res4a_relu
I0625 11:56:04.442344  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.442347  4216 net.cpp:165] Memory required for data: 4507238484
I0625 11:56:04.442350  4216 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0625 11:56:04.442358  4216 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0625 11:56:04.442363  4216 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0625 11:56:04.442374  4216 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0625 11:56:04.442386  4216 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0625 11:56:04.442433  4216 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0625 11:56:04.442440  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.442443  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.442445  4216 net.cpp:165] Memory required for data: 4546560084
I0625 11:56:04.442448  4216 layer_factory.hpp:77] Creating layer res4b_branch2a
I0625 11:56:04.442462  4216 net.cpp:100] Creating Layer res4b_branch2a
I0625 11:56:04.442467  4216 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0625 11:56:04.442478  4216 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0625 11:56:04.443648  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.443670  4216 net.cpp:150] Setting up res4b_branch2a
I0625 11:56:04.443678  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.443681  4216 net.cpp:165] Memory required for data: 4551475284
I0625 11:56:04.443691  4216 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0625 11:56:04.443702  4216 net.cpp:100] Creating Layer bn4b_branch2a
I0625 11:56:04.443707  4216 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0625 11:56:04.443718  4216 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0625 11:56:04.443889  4216 net.cpp:150] Setting up bn4b_branch2a
I0625 11:56:04.443894  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.443897  4216 net.cpp:165] Memory required for data: 4556390484
I0625 11:56:04.443909  4216 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0625 11:56:04.443920  4216 net.cpp:100] Creating Layer scale4b_branch2a
I0625 11:56:04.443925  4216 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0625 11:56:04.443934  4216 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0625 11:56:04.443979  4216 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0625 11:56:04.444104  4216 net.cpp:150] Setting up scale4b_branch2a
I0625 11:56:04.444110  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.444113  4216 net.cpp:165] Memory required for data: 4561305684
I0625 11:56:04.444120  4216 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0625 11:56:04.444129  4216 net.cpp:100] Creating Layer res4b_branch2a_relu
I0625 11:56:04.444133  4216 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0625 11:56:04.444142  4216 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0625 11:56:04.444495  4216 net.cpp:150] Setting up res4b_branch2a_relu
I0625 11:56:04.444504  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.444505  4216 net.cpp:165] Memory required for data: 4566220884
I0625 11:56:04.444510  4216 layer_factory.hpp:77] Creating layer res4b_branch2b
I0625 11:56:04.444525  4216 net.cpp:100] Creating Layer res4b_branch2b
I0625 11:56:04.444530  4216 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0625 11:56:04.444542  4216 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0625 11:56:04.446668  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 11:56:04.446892  4216 net.cpp:150] Setting up res4b_branch2b
I0625 11:56:04.446904  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.446907  4216 net.cpp:165] Memory required for data: 4571136084
I0625 11:56:04.446919  4216 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0625 11:56:04.446938  4216 net.cpp:100] Creating Layer bn4b_branch2b
I0625 11:56:04.446944  4216 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0625 11:56:04.446959  4216 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0625 11:56:04.447139  4216 net.cpp:150] Setting up bn4b_branch2b
I0625 11:56:04.447144  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.447146  4216 net.cpp:165] Memory required for data: 4576051284
I0625 11:56:04.447160  4216 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0625 11:56:04.447172  4216 net.cpp:100] Creating Layer scale4b_branch2b
I0625 11:56:04.447177  4216 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0625 11:56:04.447186  4216 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0625 11:56:04.447232  4216 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0625 11:56:04.447358  4216 net.cpp:150] Setting up scale4b_branch2b
I0625 11:56:04.447365  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.447366  4216 net.cpp:165] Memory required for data: 4580966484
I0625 11:56:04.447376  4216 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0625 11:56:04.447384  4216 net.cpp:100] Creating Layer res4b_branch2b_relu
I0625 11:56:04.447388  4216 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0625 11:56:04.447397  4216 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0625 11:56:04.447535  4216 net.cpp:150] Setting up res4b_branch2b_relu
I0625 11:56:04.447540  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.447542  4216 net.cpp:165] Memory required for data: 4585881684
I0625 11:56:04.447546  4216 layer_factory.hpp:77] Creating layer res4b_branch2c
I0625 11:56:04.447558  4216 net.cpp:100] Creating Layer res4b_branch2c
I0625 11:56:04.447564  4216 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0625 11:56:04.447574  4216 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0625 11:56:04.449198  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.449216  4216 net.cpp:150] Setting up res4b_branch2c
I0625 11:56:04.449223  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449225  4216 net.cpp:165] Memory required for data: 4605542484
I0625 11:56:04.449234  4216 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0625 11:56:04.449246  4216 net.cpp:100] Creating Layer bn4b_branch2c
I0625 11:56:04.449252  4216 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0625 11:56:04.449264  4216 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0625 11:56:04.449439  4216 net.cpp:150] Setting up bn4b_branch2c
I0625 11:56:04.449443  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449445  4216 net.cpp:165] Memory required for data: 4625203284
I0625 11:56:04.449458  4216 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0625 11:56:04.449470  4216 net.cpp:100] Creating Layer scale4b_branch2c
I0625 11:56:04.449473  4216 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0625 11:56:04.449483  4216 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0625 11:56:04.449525  4216 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0625 11:56:04.449654  4216 net.cpp:150] Setting up scale4b_branch2c
I0625 11:56:04.449661  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449662  4216 net.cpp:165] Memory required for data: 4644864084
I0625 11:56:04.449671  4216 layer_factory.hpp:77] Creating layer res4b
I0625 11:56:04.449679  4216 net.cpp:100] Creating Layer res4b
I0625 11:56:04.449683  4216 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0625 11:56:04.449692  4216 net.cpp:444] res4b <- res4b_branch2c
I0625 11:56:04.449699  4216 net.cpp:418] res4b -> res4b
I0625 11:56:04.449729  4216 net.cpp:150] Setting up res4b
I0625 11:56:04.449735  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449738  4216 net.cpp:165] Memory required for data: 4664524884
I0625 11:56:04.449740  4216 layer_factory.hpp:77] Creating layer res4b_relu
I0625 11:56:04.449748  4216 net.cpp:100] Creating Layer res4b_relu
I0625 11:56:04.449753  4216 net.cpp:444] res4b_relu <- res4b
I0625 11:56:04.449761  4216 net.cpp:405] res4b_relu -> res4b (in-place)
I0625 11:56:04.449888  4216 net.cpp:150] Setting up res4b_relu
I0625 11:56:04.449894  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449896  4216 net.cpp:165] Memory required for data: 4684185684
I0625 11:56:04.449900  4216 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0625 11:56:04.449908  4216 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0625 11:56:04.449913  4216 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0625 11:56:04.449923  4216 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0625 11:56:04.449934  4216 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0625 11:56:04.449972  4216 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0625 11:56:04.449978  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449982  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.449985  4216 net.cpp:165] Memory required for data: 4723507284
I0625 11:56:04.449987  4216 layer_factory.hpp:77] Creating layer res4c_branch2a
I0625 11:56:04.450000  4216 net.cpp:100] Creating Layer res4c_branch2a
I0625 11:56:04.450004  4216 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0625 11:56:04.450016  4216 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0625 11:56:04.451126  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.451144  4216 net.cpp:150] Setting up res4c_branch2a
I0625 11:56:04.451150  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.451153  4216 net.cpp:165] Memory required for data: 4728422484
I0625 11:56:04.451162  4216 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0625 11:56:04.451174  4216 net.cpp:100] Creating Layer bn4c_branch2a
I0625 11:56:04.451179  4216 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0625 11:56:04.451190  4216 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0625 11:56:04.451361  4216 net.cpp:150] Setting up bn4c_branch2a
I0625 11:56:04.451366  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.451369  4216 net.cpp:165] Memory required for data: 4733337684
I0625 11:56:04.451381  4216 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0625 11:56:04.451392  4216 net.cpp:100] Creating Layer scale4c_branch2a
I0625 11:56:04.451397  4216 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0625 11:56:04.451406  4216 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0625 11:56:04.451452  4216 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0625 11:56:04.451578  4216 net.cpp:150] Setting up scale4c_branch2a
I0625 11:56:04.451584  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.451586  4216 net.cpp:165] Memory required for data: 4738252884
I0625 11:56:04.451596  4216 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0625 11:56:04.451603  4216 net.cpp:100] Creating Layer res4c_branch2a_relu
I0625 11:56:04.451607  4216 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0625 11:56:04.451617  4216 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0625 11:56:04.451747  4216 net.cpp:150] Setting up res4c_branch2a_relu
I0625 11:56:04.451753  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.451756  4216 net.cpp:165] Memory required for data: 4743168084
I0625 11:56:04.451758  4216 layer_factory.hpp:77] Creating layer res4c_branch2b
I0625 11:56:04.451771  4216 net.cpp:100] Creating Layer res4c_branch2b
I0625 11:56:04.451776  4216 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0625 11:56:04.451788  4216 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0625 11:56:04.454088  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 11:56:04.454303  4216 net.cpp:150] Setting up res4c_branch2b
I0625 11:56:04.454313  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.454316  4216 net.cpp:165] Memory required for data: 4748083284
I0625 11:56:04.454329  4216 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0625 11:56:04.454345  4216 net.cpp:100] Creating Layer bn4c_branch2b
I0625 11:56:04.454351  4216 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0625 11:56:04.454365  4216 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0625 11:56:04.454542  4216 net.cpp:150] Setting up bn4c_branch2b
I0625 11:56:04.454548  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.454550  4216 net.cpp:165] Memory required for data: 4752998484
I0625 11:56:04.454563  4216 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0625 11:56:04.454574  4216 net.cpp:100] Creating Layer scale4c_branch2b
I0625 11:56:04.454579  4216 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0625 11:56:04.454589  4216 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0625 11:56:04.454633  4216 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0625 11:56:04.454761  4216 net.cpp:150] Setting up scale4c_branch2b
I0625 11:56:04.454766  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.454768  4216 net.cpp:165] Memory required for data: 4757913684
I0625 11:56:04.454777  4216 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0625 11:56:04.454787  4216 net.cpp:100] Creating Layer res4c_branch2b_relu
I0625 11:56:04.454790  4216 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0625 11:56:04.454799  4216 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0625 11:56:04.455165  4216 net.cpp:150] Setting up res4c_branch2b_relu
I0625 11:56:04.455173  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.455176  4216 net.cpp:165] Memory required for data: 4762828884
I0625 11:56:04.455180  4216 layer_factory.hpp:77] Creating layer res4c_branch2c
I0625 11:56:04.455195  4216 net.cpp:100] Creating Layer res4c_branch2c
I0625 11:56:04.455200  4216 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0625 11:56:04.455214  4216 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0625 11:56:04.456849  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.456869  4216 net.cpp:150] Setting up res4c_branch2c
I0625 11:56:04.456876  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.456879  4216 net.cpp:165] Memory required for data: 4782489684
I0625 11:56:04.456889  4216 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0625 11:56:04.456903  4216 net.cpp:100] Creating Layer bn4c_branch2c
I0625 11:56:04.456908  4216 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0625 11:56:04.456919  4216 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0625 11:56:04.457100  4216 net.cpp:150] Setting up bn4c_branch2c
I0625 11:56:04.457106  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.457108  4216 net.cpp:165] Memory required for data: 4802150484
I0625 11:56:04.457121  4216 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0625 11:56:04.457132  4216 net.cpp:100] Creating Layer scale4c_branch2c
I0625 11:56:04.457136  4216 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0625 11:56:04.457145  4216 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0625 11:56:04.457190  4216 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0625 11:56:04.457321  4216 net.cpp:150] Setting up scale4c_branch2c
I0625 11:56:04.457327  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.457329  4216 net.cpp:165] Memory required for data: 4821811284
I0625 11:56:04.457339  4216 layer_factory.hpp:77] Creating layer res4c
I0625 11:56:04.457347  4216 net.cpp:100] Creating Layer res4c
I0625 11:56:04.457352  4216 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0625 11:56:04.457360  4216 net.cpp:444] res4c <- res4c_branch2c
I0625 11:56:04.457367  4216 net.cpp:418] res4c -> res4c
I0625 11:56:04.457399  4216 net.cpp:150] Setting up res4c
I0625 11:56:04.457406  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.457407  4216 net.cpp:165] Memory required for data: 4841472084
I0625 11:56:04.457412  4216 layer_factory.hpp:77] Creating layer res4c_relu
I0625 11:56:04.457418  4216 net.cpp:100] Creating Layer res4c_relu
I0625 11:56:04.457422  4216 net.cpp:444] res4c_relu <- res4c
I0625 11:56:04.457432  4216 net.cpp:405] res4c_relu -> res4c (in-place)
I0625 11:56:04.457561  4216 net.cpp:150] Setting up res4c_relu
I0625 11:56:04.457567  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.457569  4216 net.cpp:165] Memory required for data: 4861132884
I0625 11:56:04.457572  4216 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0625 11:56:04.457581  4216 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0625 11:56:04.457585  4216 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0625 11:56:04.457595  4216 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0625 11:56:04.457607  4216 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0625 11:56:04.457645  4216 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0625 11:56:04.457653  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.457655  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.457657  4216 net.cpp:165] Memory required for data: 4900454484
I0625 11:56:04.457660  4216 layer_factory.hpp:77] Creating layer res4d_branch2a
I0625 11:56:04.457672  4216 net.cpp:100] Creating Layer res4d_branch2a
I0625 11:56:04.457677  4216 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0625 11:56:04.457690  4216 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0625 11:56:04.458802  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.458819  4216 net.cpp:150] Setting up res4d_branch2a
I0625 11:56:04.458827  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.458828  4216 net.cpp:165] Memory required for data: 4905369684
I0625 11:56:04.458837  4216 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0625 11:56:04.458849  4216 net.cpp:100] Creating Layer bn4d_branch2a
I0625 11:56:04.458854  4216 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0625 11:56:04.458873  4216 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0625 11:56:04.459075  4216 net.cpp:150] Setting up bn4d_branch2a
I0625 11:56:04.459080  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.459082  4216 net.cpp:165] Memory required for data: 4910284884
I0625 11:56:04.459095  4216 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0625 11:56:04.459106  4216 net.cpp:100] Creating Layer scale4d_branch2a
I0625 11:56:04.459110  4216 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0625 11:56:04.459120  4216 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0625 11:56:04.459166  4216 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0625 11:56:04.459292  4216 net.cpp:150] Setting up scale4d_branch2a
I0625 11:56:04.459298  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.459300  4216 net.cpp:165] Memory required for data: 4915200084
I0625 11:56:04.459309  4216 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0625 11:56:04.459318  4216 net.cpp:100] Creating Layer res4d_branch2a_relu
I0625 11:56:04.459322  4216 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0625 11:56:04.459331  4216 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0625 11:56:04.459463  4216 net.cpp:150] Setting up res4d_branch2a_relu
I0625 11:56:04.459470  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.459472  4216 net.cpp:165] Memory required for data: 4920115284
I0625 11:56:04.459475  4216 layer_factory.hpp:77] Creating layer res4d_branch2b
I0625 11:56:04.459486  4216 net.cpp:100] Creating Layer res4d_branch2b
I0625 11:56:04.459491  4216 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0625 11:56:04.459504  4216 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0625 11:56:04.461624  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 11:56:04.461848  4216 net.cpp:150] Setting up res4d_branch2b
I0625 11:56:04.461858  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.461861  4216 net.cpp:165] Memory required for data: 4925030484
I0625 11:56:04.461874  4216 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0625 11:56:04.461890  4216 net.cpp:100] Creating Layer bn4d_branch2b
I0625 11:56:04.461896  4216 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0625 11:56:04.461908  4216 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0625 11:56:04.462095  4216 net.cpp:150] Setting up bn4d_branch2b
I0625 11:56:04.462100  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.462102  4216 net.cpp:165] Memory required for data: 4929945684
I0625 11:56:04.462116  4216 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0625 11:56:04.462126  4216 net.cpp:100] Creating Layer scale4d_branch2b
I0625 11:56:04.462131  4216 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0625 11:56:04.462139  4216 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0625 11:56:04.462188  4216 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0625 11:56:04.462314  4216 net.cpp:150] Setting up scale4d_branch2b
I0625 11:56:04.462321  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.462322  4216 net.cpp:165] Memory required for data: 4934860884
I0625 11:56:04.462332  4216 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0625 11:56:04.462339  4216 net.cpp:100] Creating Layer res4d_branch2b_relu
I0625 11:56:04.462344  4216 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0625 11:56:04.462354  4216 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0625 11:56:04.462699  4216 net.cpp:150] Setting up res4d_branch2b_relu
I0625 11:56:04.462707  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.462709  4216 net.cpp:165] Memory required for data: 4939776084
I0625 11:56:04.462713  4216 layer_factory.hpp:77] Creating layer res4d_branch2c
I0625 11:56:04.462728  4216 net.cpp:100] Creating Layer res4d_branch2c
I0625 11:56:04.462734  4216 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0625 11:56:04.462747  4216 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0625 11:56:04.464404  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.464423  4216 net.cpp:150] Setting up res4d_branch2c
I0625 11:56:04.464431  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.464432  4216 net.cpp:165] Memory required for data: 4959436884
I0625 11:56:04.464442  4216 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0625 11:56:04.464457  4216 net.cpp:100] Creating Layer bn4d_branch2c
I0625 11:56:04.464462  4216 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0625 11:56:04.464474  4216 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0625 11:56:04.464655  4216 net.cpp:150] Setting up bn4d_branch2c
I0625 11:56:04.464660  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.464663  4216 net.cpp:165] Memory required for data: 4979097684
I0625 11:56:04.464675  4216 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0625 11:56:04.464687  4216 net.cpp:100] Creating Layer scale4d_branch2c
I0625 11:56:04.464692  4216 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0625 11:56:04.464701  4216 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0625 11:56:04.464745  4216 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0625 11:56:04.464877  4216 net.cpp:150] Setting up scale4d_branch2c
I0625 11:56:04.464882  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.464885  4216 net.cpp:165] Memory required for data: 4998758484
I0625 11:56:04.464893  4216 layer_factory.hpp:77] Creating layer res4d
I0625 11:56:04.464903  4216 net.cpp:100] Creating Layer res4d
I0625 11:56:04.464908  4216 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0625 11:56:04.464916  4216 net.cpp:444] res4d <- res4d_branch2c
I0625 11:56:04.464924  4216 net.cpp:418] res4d -> res4d
I0625 11:56:04.464954  4216 net.cpp:150] Setting up res4d
I0625 11:56:04.464962  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.464963  4216 net.cpp:165] Memory required for data: 5018419284
I0625 11:56:04.464967  4216 layer_factory.hpp:77] Creating layer res4d_relu
I0625 11:56:04.464975  4216 net.cpp:100] Creating Layer res4d_relu
I0625 11:56:04.464979  4216 net.cpp:444] res4d_relu <- res4d
I0625 11:56:04.464988  4216 net.cpp:405] res4d_relu -> res4d (in-place)
I0625 11:56:04.465118  4216 net.cpp:150] Setting up res4d_relu
I0625 11:56:04.465124  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.465126  4216 net.cpp:165] Memory required for data: 5038080084
I0625 11:56:04.465129  4216 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0625 11:56:04.465138  4216 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0625 11:56:04.465142  4216 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0625 11:56:04.465153  4216 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0625 11:56:04.465164  4216 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0625 11:56:04.465204  4216 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0625 11:56:04.465210  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.465214  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.465215  4216 net.cpp:165] Memory required for data: 5077401684
I0625 11:56:04.465219  4216 layer_factory.hpp:77] Creating layer res4e_branch2a
I0625 11:56:04.465230  4216 net.cpp:100] Creating Layer res4e_branch2a
I0625 11:56:04.465235  4216 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0625 11:56:04.465246  4216 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0625 11:56:04.466361  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.466377  4216 net.cpp:150] Setting up res4e_branch2a
I0625 11:56:04.466383  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.466387  4216 net.cpp:165] Memory required for data: 5082316884
I0625 11:56:04.466395  4216 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0625 11:56:04.466408  4216 net.cpp:100] Creating Layer bn4e_branch2a
I0625 11:56:04.466413  4216 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0625 11:56:04.466424  4216 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0625 11:56:04.466603  4216 net.cpp:150] Setting up bn4e_branch2a
I0625 11:56:04.466608  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.466609  4216 net.cpp:165] Memory required for data: 5087232084
I0625 11:56:04.466622  4216 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0625 11:56:04.466634  4216 net.cpp:100] Creating Layer scale4e_branch2a
I0625 11:56:04.466639  4216 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0625 11:56:04.466647  4216 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0625 11:56:04.466693  4216 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0625 11:56:04.466821  4216 net.cpp:150] Setting up scale4e_branch2a
I0625 11:56:04.466827  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.466830  4216 net.cpp:165] Memory required for data: 5092147284
I0625 11:56:04.466838  4216 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0625 11:56:04.466846  4216 net.cpp:100] Creating Layer res4e_branch2a_relu
I0625 11:56:04.466850  4216 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0625 11:56:04.466876  4216 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0625 11:56:04.467026  4216 net.cpp:150] Setting up res4e_branch2a_relu
I0625 11:56:04.467032  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.467034  4216 net.cpp:165] Memory required for data: 5097062484
I0625 11:56:04.467038  4216 layer_factory.hpp:77] Creating layer res4e_branch2b
I0625 11:56:04.467051  4216 net.cpp:100] Creating Layer res4e_branch2b
I0625 11:56:04.467056  4216 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0625 11:56:04.467068  4216 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0625 11:56:04.469193  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 11:56:04.469424  4216 net.cpp:150] Setting up res4e_branch2b
I0625 11:56:04.469434  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.469437  4216 net.cpp:165] Memory required for data: 5101977684
I0625 11:56:04.469450  4216 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0625 11:56:04.469466  4216 net.cpp:100] Creating Layer bn4e_branch2b
I0625 11:56:04.469473  4216 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0625 11:56:04.469488  4216 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0625 11:56:04.469676  4216 net.cpp:150] Setting up bn4e_branch2b
I0625 11:56:04.469681  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.469683  4216 net.cpp:165] Memory required for data: 5106892884
I0625 11:56:04.469696  4216 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0625 11:56:04.469708  4216 net.cpp:100] Creating Layer scale4e_branch2b
I0625 11:56:04.469713  4216 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0625 11:56:04.469722  4216 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0625 11:56:04.469770  4216 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0625 11:56:04.469900  4216 net.cpp:150] Setting up scale4e_branch2b
I0625 11:56:04.469907  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.469908  4216 net.cpp:165] Memory required for data: 5111808084
I0625 11:56:04.469916  4216 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0625 11:56:04.469925  4216 net.cpp:100] Creating Layer res4e_branch2b_relu
I0625 11:56:04.469930  4216 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0625 11:56:04.469939  4216 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0625 11:56:04.470286  4216 net.cpp:150] Setting up res4e_branch2b_relu
I0625 11:56:04.470293  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.470295  4216 net.cpp:165] Memory required for data: 5116723284
I0625 11:56:04.470299  4216 layer_factory.hpp:77] Creating layer res4e_branch2c
I0625 11:56:04.470315  4216 net.cpp:100] Creating Layer res4e_branch2c
I0625 11:56:04.470320  4216 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0625 11:56:04.470335  4216 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0625 11:56:04.471999  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.472020  4216 net.cpp:150] Setting up res4e_branch2c
I0625 11:56:04.472028  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472030  4216 net.cpp:165] Memory required for data: 5136384084
I0625 11:56:04.472040  4216 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0625 11:56:04.472054  4216 net.cpp:100] Creating Layer bn4e_branch2c
I0625 11:56:04.472060  4216 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0625 11:56:04.472072  4216 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0625 11:56:04.472255  4216 net.cpp:150] Setting up bn4e_branch2c
I0625 11:56:04.472261  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472263  4216 net.cpp:165] Memory required for data: 5156044884
I0625 11:56:04.472276  4216 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0625 11:56:04.472287  4216 net.cpp:100] Creating Layer scale4e_branch2c
I0625 11:56:04.472292  4216 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0625 11:56:04.472302  4216 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0625 11:56:04.472345  4216 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0625 11:56:04.472479  4216 net.cpp:150] Setting up scale4e_branch2c
I0625 11:56:04.472486  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472487  4216 net.cpp:165] Memory required for data: 5175705684
I0625 11:56:04.472496  4216 layer_factory.hpp:77] Creating layer res4e
I0625 11:56:04.472504  4216 net.cpp:100] Creating Layer res4e
I0625 11:56:04.472509  4216 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0625 11:56:04.472517  4216 net.cpp:444] res4e <- res4e_branch2c
I0625 11:56:04.472525  4216 net.cpp:418] res4e -> res4e
I0625 11:56:04.472558  4216 net.cpp:150] Setting up res4e
I0625 11:56:04.472565  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472568  4216 net.cpp:165] Memory required for data: 5195366484
I0625 11:56:04.472570  4216 layer_factory.hpp:77] Creating layer res4e_relu
I0625 11:56:04.472578  4216 net.cpp:100] Creating Layer res4e_relu
I0625 11:56:04.472581  4216 net.cpp:444] res4e_relu <- res4e
I0625 11:56:04.472592  4216 net.cpp:405] res4e_relu -> res4e (in-place)
I0625 11:56:04.472724  4216 net.cpp:150] Setting up res4e_relu
I0625 11:56:04.472730  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472733  4216 net.cpp:165] Memory required for data: 5215027284
I0625 11:56:04.472735  4216 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0625 11:56:04.472743  4216 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0625 11:56:04.472748  4216 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0625 11:56:04.472759  4216 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0625 11:56:04.472770  4216 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0625 11:56:04.472810  4216 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0625 11:56:04.472816  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472820  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.472821  4216 net.cpp:165] Memory required for data: 5254348884
I0625 11:56:04.472824  4216 layer_factory.hpp:77] Creating layer res4f_branch2a
I0625 11:56:04.472836  4216 net.cpp:100] Creating Layer res4f_branch2a
I0625 11:56:04.472841  4216 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0625 11:56:04.472854  4216 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0625 11:56:04.473994  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.474014  4216 net.cpp:150] Setting up res4f_branch2a
I0625 11:56:04.474020  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.474022  4216 net.cpp:165] Memory required for data: 5259264084
I0625 11:56:04.474031  4216 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0625 11:56:04.474045  4216 net.cpp:100] Creating Layer bn4f_branch2a
I0625 11:56:04.474050  4216 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0625 11:56:04.474061  4216 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0625 11:56:04.474243  4216 net.cpp:150] Setting up bn4f_branch2a
I0625 11:56:04.474248  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.474251  4216 net.cpp:165] Memory required for data: 5264179284
I0625 11:56:04.474263  4216 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0625 11:56:04.474274  4216 net.cpp:100] Creating Layer scale4f_branch2a
I0625 11:56:04.474278  4216 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0625 11:56:04.474288  4216 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0625 11:56:04.474334  4216 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0625 11:56:04.474467  4216 net.cpp:150] Setting up scale4f_branch2a
I0625 11:56:04.474473  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.474475  4216 net.cpp:165] Memory required for data: 5269094484
I0625 11:56:04.474484  4216 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0625 11:56:04.474493  4216 net.cpp:100] Creating Layer res4f_branch2a_relu
I0625 11:56:04.474498  4216 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0625 11:56:04.474506  4216 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0625 11:56:04.474669  4216 net.cpp:150] Setting up res4f_branch2a_relu
I0625 11:56:04.474678  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.474679  4216 net.cpp:165] Memory required for data: 5274009684
I0625 11:56:04.474684  4216 layer_factory.hpp:77] Creating layer res4f_branch2b
I0625 11:56:04.474697  4216 net.cpp:100] Creating Layer res4f_branch2b
I0625 11:56:04.474704  4216 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0625 11:56:04.474717  4216 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0625 11:56:04.477010  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 11:56:04.477250  4216 net.cpp:150] Setting up res4f_branch2b
I0625 11:56:04.477265  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.477267  4216 net.cpp:165] Memory required for data: 5278924884
I0625 11:56:04.477285  4216 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0625 11:56:04.477305  4216 net.cpp:100] Creating Layer bn4f_branch2b
I0625 11:56:04.477313  4216 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0625 11:56:04.477327  4216 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0625 11:56:04.477525  4216 net.cpp:150] Setting up bn4f_branch2b
I0625 11:56:04.477530  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.477532  4216 net.cpp:165] Memory required for data: 5283840084
I0625 11:56:04.477546  4216 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0625 11:56:04.477558  4216 net.cpp:100] Creating Layer scale4f_branch2b
I0625 11:56:04.477562  4216 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0625 11:56:04.477573  4216 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0625 11:56:04.477619  4216 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0625 11:56:04.477754  4216 net.cpp:150] Setting up scale4f_branch2b
I0625 11:56:04.477761  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.477762  4216 net.cpp:165] Memory required for data: 5288755284
I0625 11:56:04.477771  4216 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0625 11:56:04.477780  4216 net.cpp:100] Creating Layer res4f_branch2b_relu
I0625 11:56:04.477784  4216 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0625 11:56:04.477794  4216 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0625 11:56:04.477938  4216 net.cpp:150] Setting up res4f_branch2b_relu
I0625 11:56:04.477944  4216 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 11:56:04.477946  4216 net.cpp:165] Memory required for data: 5293670484
I0625 11:56:04.477949  4216 layer_factory.hpp:77] Creating layer res4f_branch2c
I0625 11:56:04.477963  4216 net.cpp:100] Creating Layer res4f_branch2c
I0625 11:56:04.477968  4216 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0625 11:56:04.477982  4216 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0625 11:56:04.479665  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.479687  4216 net.cpp:150] Setting up res4f_branch2c
I0625 11:56:04.479696  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.479697  4216 net.cpp:165] Memory required for data: 5313331284
I0625 11:56:04.479708  4216 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0625 11:56:04.479724  4216 net.cpp:100] Creating Layer bn4f_branch2c
I0625 11:56:04.479730  4216 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0625 11:56:04.479743  4216 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0625 11:56:04.479931  4216 net.cpp:150] Setting up bn4f_branch2c
I0625 11:56:04.479938  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.479939  4216 net.cpp:165] Memory required for data: 5332992084
I0625 11:56:04.479984  4216 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0625 11:56:04.479995  4216 net.cpp:100] Creating Layer scale4f_branch2c
I0625 11:56:04.480000  4216 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0625 11:56:04.480010  4216 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0625 11:56:04.480056  4216 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0625 11:56:04.480190  4216 net.cpp:150] Setting up scale4f_branch2c
I0625 11:56:04.480195  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.480198  4216 net.cpp:165] Memory required for data: 5352652884
I0625 11:56:04.480207  4216 layer_factory.hpp:77] Creating layer res4f
I0625 11:56:04.480216  4216 net.cpp:100] Creating Layer res4f
I0625 11:56:04.480221  4216 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0625 11:56:04.480231  4216 net.cpp:444] res4f <- res4f_branch2c
I0625 11:56:04.480237  4216 net.cpp:418] res4f -> res4f
I0625 11:56:04.480269  4216 net.cpp:150] Setting up res4f
I0625 11:56:04.480275  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.480278  4216 net.cpp:165] Memory required for data: 5372313684
I0625 11:56:04.480281  4216 layer_factory.hpp:77] Creating layer res4f_relu
I0625 11:56:04.480290  4216 net.cpp:100] Creating Layer res4f_relu
I0625 11:56:04.480294  4216 net.cpp:444] res4f_relu <- res4f
I0625 11:56:04.480304  4216 net.cpp:405] res4f_relu -> res4f (in-place)
I0625 11:56:04.480659  4216 net.cpp:150] Setting up res4f_relu
I0625 11:56:04.480665  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.480669  4216 net.cpp:165] Memory required for data: 5391974484
I0625 11:56:04.480672  4216 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0625 11:56:04.480682  4216 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0625 11:56:04.480687  4216 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0625 11:56:04.480698  4216 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0625 11:56:04.480712  4216 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0625 11:56:04.480721  4216 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0625 11:56:04.480774  4216 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0625 11:56:04.480782  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.480785  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.480788  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:04.480790  4216 net.cpp:165] Memory required for data: 5450956884
I0625 11:56:04.480793  4216 layer_factory.hpp:77] Creating layer res5a_branch1
I0625 11:56:04.480806  4216 net.cpp:100] Creating Layer res5a_branch1
I0625 11:56:04.480810  4216 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0625 11:56:04.480823  4216 net.cpp:418] res5a_branch1 -> res5a_branch1
I0625 11:56:04.485910  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 11:56:04.485936  4216 net.cpp:150] Setting up res5a_branch1
I0625 11:56:04.485949  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.485951  4216 net.cpp:165] Memory required for data: 5490278484
I0625 11:56:04.485966  4216 layer_factory.hpp:77] Creating layer bn5a_branch1
I0625 11:56:04.485986  4216 net.cpp:100] Creating Layer bn5a_branch1
I0625 11:56:04.485993  4216 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0625 11:56:04.486008  4216 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0625 11:56:04.486209  4216 net.cpp:150] Setting up bn5a_branch1
I0625 11:56:04.486215  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.486217  4216 net.cpp:165] Memory required for data: 5529600084
I0625 11:56:04.486230  4216 layer_factory.hpp:77] Creating layer scale5a_branch1
I0625 11:56:04.486241  4216 net.cpp:100] Creating Layer scale5a_branch1
I0625 11:56:04.486246  4216 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0625 11:56:04.486256  4216 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0625 11:56:04.486304  4216 layer_factory.hpp:77] Creating layer scale5a_branch1
I0625 11:56:04.486443  4216 net.cpp:150] Setting up scale5a_branch1
I0625 11:56:04.486449  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.486451  4216 net.cpp:165] Memory required for data: 5568921684
I0625 11:56:04.486460  4216 layer_factory.hpp:77] Creating layer res5a_branch2a
I0625 11:56:04.486474  4216 net.cpp:100] Creating Layer res5a_branch2a
I0625 11:56:04.486480  4216 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0625 11:56:04.486492  4216 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0625 11:56:04.488549  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.488572  4216 net.cpp:150] Setting up res5a_branch2a
I0625 11:56:04.488580  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.488582  4216 net.cpp:165] Memory required for data: 5578752084
I0625 11:56:04.488595  4216 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0625 11:56:04.488608  4216 net.cpp:100] Creating Layer bn5a_branch2a
I0625 11:56:04.488615  4216 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0625 11:56:04.488627  4216 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0625 11:56:04.488816  4216 net.cpp:150] Setting up bn5a_branch2a
I0625 11:56:04.488822  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.488824  4216 net.cpp:165] Memory required for data: 5588582484
I0625 11:56:04.488837  4216 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0625 11:56:04.488849  4216 net.cpp:100] Creating Layer scale5a_branch2a
I0625 11:56:04.488853  4216 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0625 11:56:04.488862  4216 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0625 11:56:04.488905  4216 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0625 11:56:04.489042  4216 net.cpp:150] Setting up scale5a_branch2a
I0625 11:56:04.489048  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.489049  4216 net.cpp:165] Memory required for data: 5598412884
I0625 11:56:04.489058  4216 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0625 11:56:04.489068  4216 net.cpp:100] Creating Layer res5a_branch2a_relu
I0625 11:56:04.489071  4216 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0625 11:56:04.489080  4216 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0625 11:56:04.489215  4216 net.cpp:150] Setting up res5a_branch2a_relu
I0625 11:56:04.489222  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.489223  4216 net.cpp:165] Memory required for data: 5608243284
I0625 11:56:04.489228  4216 layer_factory.hpp:77] Creating layer res5a_branch2b
I0625 11:56:04.489240  4216 net.cpp:100] Creating Layer res5a_branch2b
I0625 11:56:04.489245  4216 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0625 11:56:04.489257  4216 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0625 11:56:04.494155  4216 net.cpp:150] Setting up res5a_branch2b
I0625 11:56:04.494179  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.494181  4216 net.cpp:165] Memory required for data: 5618073684
I0625 11:56:04.494213  4216 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0625 11:56:04.494238  4216 net.cpp:100] Creating Layer bn5a_branch2b
I0625 11:56:04.494247  4216 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0625 11:56:04.494262  4216 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0625 11:56:04.494467  4216 net.cpp:150] Setting up bn5a_branch2b
I0625 11:56:04.494473  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.494475  4216 net.cpp:165] Memory required for data: 5627904084
I0625 11:56:04.494488  4216 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0625 11:56:04.494500  4216 net.cpp:100] Creating Layer scale5a_branch2b
I0625 11:56:04.494505  4216 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0625 11:56:04.494514  4216 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0625 11:56:04.494560  4216 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0625 11:56:04.494696  4216 net.cpp:150] Setting up scale5a_branch2b
I0625 11:56:04.494702  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.494704  4216 net.cpp:165] Memory required for data: 5637734484
I0625 11:56:04.494712  4216 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0625 11:56:04.494721  4216 net.cpp:100] Creating Layer res5a_branch2b_relu
I0625 11:56:04.494727  4216 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0625 11:56:04.494736  4216 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0625 11:56:04.494940  4216 net.cpp:150] Setting up res5a_branch2b_relu
I0625 11:56:04.494947  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.494949  4216 net.cpp:165] Memory required for data: 5647564884
I0625 11:56:04.494953  4216 layer_factory.hpp:77] Creating layer res5a_branch2c
I0625 11:56:04.494968  4216 net.cpp:100] Creating Layer res5a_branch2c
I0625 11:56:04.494972  4216 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0625 11:56:04.494985  4216 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0625 11:56:04.498157  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 11:56:04.498183  4216 net.cpp:150] Setting up res5a_branch2c
I0625 11:56:04.498194  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.498198  4216 net.cpp:165] Memory required for data: 5686886484
I0625 11:56:04.498212  4216 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0625 11:56:04.498229  4216 net.cpp:100] Creating Layer bn5a_branch2c
I0625 11:56:04.498236  4216 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0625 11:56:04.498250  4216 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0625 11:56:04.498452  4216 net.cpp:150] Setting up bn5a_branch2c
I0625 11:56:04.498457  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.498459  4216 net.cpp:165] Memory required for data: 5726208084
I0625 11:56:04.498473  4216 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0625 11:56:04.498484  4216 net.cpp:100] Creating Layer scale5a_branch2c
I0625 11:56:04.498489  4216 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0625 11:56:04.498499  4216 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0625 11:56:04.498548  4216 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0625 11:56:04.498687  4216 net.cpp:150] Setting up scale5a_branch2c
I0625 11:56:04.498693  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.498695  4216 net.cpp:165] Memory required for data: 5765529684
I0625 11:56:04.498704  4216 layer_factory.hpp:77] Creating layer res5a
I0625 11:56:04.498713  4216 net.cpp:100] Creating Layer res5a
I0625 11:56:04.498718  4216 net.cpp:444] res5a <- res5a_branch1
I0625 11:56:04.498725  4216 net.cpp:444] res5a <- res5a_branch2c
I0625 11:56:04.498733  4216 net.cpp:418] res5a -> res5a
I0625 11:56:04.498765  4216 net.cpp:150] Setting up res5a
I0625 11:56:04.498772  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.498775  4216 net.cpp:165] Memory required for data: 5804851284
I0625 11:56:04.498778  4216 layer_factory.hpp:77] Creating layer res5a_relu
I0625 11:56:04.498785  4216 net.cpp:100] Creating Layer res5a_relu
I0625 11:56:04.498790  4216 net.cpp:444] res5a_relu <- res5a
I0625 11:56:04.498798  4216 net.cpp:405] res5a_relu -> res5a (in-place)
I0625 11:56:04.499187  4216 net.cpp:150] Setting up res5a_relu
I0625 11:56:04.499195  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.499197  4216 net.cpp:165] Memory required for data: 5844172884
I0625 11:56:04.499202  4216 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0625 11:56:04.499212  4216 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0625 11:56:04.499215  4216 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0625 11:56:04.499228  4216 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0625 11:56:04.499240  4216 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0625 11:56:04.499284  4216 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0625 11:56:04.499289  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.499294  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.499295  4216 net.cpp:165] Memory required for data: 5922816084
I0625 11:56:04.499299  4216 layer_factory.hpp:77] Creating layer res5b_branch2a
I0625 11:56:04.499312  4216 net.cpp:100] Creating Layer res5b_branch2a
I0625 11:56:04.499317  4216 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0625 11:56:04.499328  4216 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0625 11:56:04.502454  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.502480  4216 net.cpp:150] Setting up res5b_branch2a
I0625 11:56:04.502490  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.502491  4216 net.cpp:165] Memory required for data: 5932646484
I0625 11:56:04.502507  4216 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0625 11:56:04.502524  4216 net.cpp:100] Creating Layer bn5b_branch2a
I0625 11:56:04.502532  4216 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0625 11:56:04.502547  4216 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0625 11:56:04.502746  4216 net.cpp:150] Setting up bn5b_branch2a
I0625 11:56:04.502751  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.502753  4216 net.cpp:165] Memory required for data: 5942476884
I0625 11:56:04.502766  4216 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0625 11:56:04.502779  4216 net.cpp:100] Creating Layer scale5b_branch2a
I0625 11:56:04.502784  4216 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0625 11:56:04.502794  4216 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0625 11:56:04.502837  4216 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0625 11:56:04.502985  4216 net.cpp:150] Setting up scale5b_branch2a
I0625 11:56:04.502990  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.502993  4216 net.cpp:165] Memory required for data: 5952307284
I0625 11:56:04.503001  4216 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0625 11:56:04.503010  4216 net.cpp:100] Creating Layer res5b_branch2a_relu
I0625 11:56:04.503015  4216 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0625 11:56:04.503024  4216 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0625 11:56:04.503161  4216 net.cpp:150] Setting up res5b_branch2a_relu
I0625 11:56:04.503168  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.503170  4216 net.cpp:165] Memory required for data: 5962137684
I0625 11:56:04.503173  4216 layer_factory.hpp:77] Creating layer res5b_branch2b
I0625 11:56:04.503187  4216 net.cpp:100] Creating Layer res5b_branch2b
I0625 11:56:04.503192  4216 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0625 11:56:04.503204  4216 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0625 11:56:04.508134  4216 net.cpp:150] Setting up res5b_branch2b
I0625 11:56:04.508155  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.508157  4216 net.cpp:165] Memory required for data: 5971968084
I0625 11:56:04.508173  4216 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0625 11:56:04.508194  4216 net.cpp:100] Creating Layer bn5b_branch2b
I0625 11:56:04.508201  4216 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0625 11:56:04.508215  4216 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0625 11:56:04.508426  4216 net.cpp:150] Setting up bn5b_branch2b
I0625 11:56:04.508431  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.508433  4216 net.cpp:165] Memory required for data: 5981798484
I0625 11:56:04.508447  4216 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0625 11:56:04.508460  4216 net.cpp:100] Creating Layer scale5b_branch2b
I0625 11:56:04.508464  4216 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0625 11:56:04.508472  4216 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0625 11:56:04.508518  4216 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0625 11:56:04.508659  4216 net.cpp:150] Setting up scale5b_branch2b
I0625 11:56:04.508664  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.508666  4216 net.cpp:165] Memory required for data: 5991628884
I0625 11:56:04.508675  4216 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0625 11:56:04.508683  4216 net.cpp:100] Creating Layer res5b_branch2b_relu
I0625 11:56:04.508688  4216 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0625 11:56:04.508697  4216 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0625 11:56:04.508873  4216 net.cpp:150] Setting up res5b_branch2b_relu
I0625 11:56:04.508879  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.508882  4216 net.cpp:165] Memory required for data: 6001459284
I0625 11:56:04.508885  4216 layer_factory.hpp:77] Creating layer res5b_branch2c
I0625 11:56:04.508900  4216 net.cpp:100] Creating Layer res5b_branch2c
I0625 11:56:04.508905  4216 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0625 11:56:04.508918  4216 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0625 11:56:04.512115  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 11:56:04.512143  4216 net.cpp:150] Setting up res5b_branch2c
I0625 11:56:04.512156  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.512157  4216 net.cpp:165] Memory required for data: 6040780884
I0625 11:56:04.512172  4216 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0625 11:56:04.512193  4216 net.cpp:100] Creating Layer bn5b_branch2c
I0625 11:56:04.512202  4216 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0625 11:56:04.512215  4216 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0625 11:56:04.512423  4216 net.cpp:150] Setting up bn5b_branch2c
I0625 11:56:04.512428  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.512431  4216 net.cpp:165] Memory required for data: 6080102484
I0625 11:56:04.512445  4216 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0625 11:56:04.512457  4216 net.cpp:100] Creating Layer scale5b_branch2c
I0625 11:56:04.512461  4216 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0625 11:56:04.512470  4216 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0625 11:56:04.512517  4216 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0625 11:56:04.512660  4216 net.cpp:150] Setting up scale5b_branch2c
I0625 11:56:04.512666  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.512668  4216 net.cpp:165] Memory required for data: 6119424084
I0625 11:56:04.512676  4216 layer_factory.hpp:77] Creating layer res5b
I0625 11:56:04.512684  4216 net.cpp:100] Creating Layer res5b
I0625 11:56:04.512689  4216 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0625 11:56:04.512696  4216 net.cpp:444] res5b <- res5b_branch2c
I0625 11:56:04.512704  4216 net.cpp:418] res5b -> res5b
I0625 11:56:04.512737  4216 net.cpp:150] Setting up res5b
I0625 11:56:04.512743  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.512747  4216 net.cpp:165] Memory required for data: 6158745684
I0625 11:56:04.512749  4216 layer_factory.hpp:77] Creating layer res5b_relu
I0625 11:56:04.512758  4216 net.cpp:100] Creating Layer res5b_relu
I0625 11:56:04.512763  4216 net.cpp:444] res5b_relu <- res5b
I0625 11:56:04.512771  4216 net.cpp:405] res5b_relu -> res5b (in-place)
I0625 11:56:04.513149  4216 net.cpp:150] Setting up res5b_relu
I0625 11:56:04.513156  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.513159  4216 net.cpp:165] Memory required for data: 6198067284
I0625 11:56:04.513164  4216 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0625 11:56:04.513173  4216 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0625 11:56:04.513177  4216 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0625 11:56:04.513190  4216 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0625 11:56:04.513202  4216 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0625 11:56:04.513245  4216 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0625 11:56:04.513252  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.513257  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.513258  4216 net.cpp:165] Memory required for data: 6276710484
I0625 11:56:04.513262  4216 layer_factory.hpp:77] Creating layer res5c_branch2a
I0625 11:56:04.513274  4216 net.cpp:100] Creating Layer res5c_branch2a
I0625 11:56:04.513279  4216 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0625 11:56:04.513291  4216 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0625 11:56:04.516557  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:04.516582  4216 net.cpp:150] Setting up res5c_branch2a
I0625 11:56:04.516592  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.516594  4216 net.cpp:165] Memory required for data: 6286540884
I0625 11:56:04.516608  4216 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0625 11:56:04.516628  4216 net.cpp:100] Creating Layer bn5c_branch2a
I0625 11:56:04.516635  4216 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0625 11:56:04.516650  4216 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0625 11:56:04.516854  4216 net.cpp:150] Setting up bn5c_branch2a
I0625 11:56:04.516858  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.516860  4216 net.cpp:165] Memory required for data: 6296371284
I0625 11:56:04.516875  4216 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0625 11:56:04.516886  4216 net.cpp:100] Creating Layer scale5c_branch2a
I0625 11:56:04.516891  4216 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0625 11:56:04.516899  4216 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0625 11:56:04.516945  4216 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0625 11:56:04.517086  4216 net.cpp:150] Setting up scale5c_branch2a
I0625 11:56:04.517091  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.517093  4216 net.cpp:165] Memory required for data: 6306201684
I0625 11:56:04.517102  4216 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0625 11:56:04.517110  4216 net.cpp:100] Creating Layer res5c_branch2a_relu
I0625 11:56:04.517114  4216 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0625 11:56:04.517124  4216 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0625 11:56:04.517261  4216 net.cpp:150] Setting up res5c_branch2a_relu
I0625 11:56:04.517266  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.517268  4216 net.cpp:165] Memory required for data: 6316032084
I0625 11:56:04.517272  4216 layer_factory.hpp:77] Creating layer res5c_branch2b
I0625 11:56:04.517285  4216 net.cpp:100] Creating Layer res5c_branch2b
I0625 11:56:04.517290  4216 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0625 11:56:04.517302  4216 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0625 11:56:04.522246  4216 net.cpp:150] Setting up res5c_branch2b
I0625 11:56:04.522275  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.522279  4216 net.cpp:165] Memory required for data: 6325862484
I0625 11:56:04.522298  4216 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0625 11:56:04.522325  4216 net.cpp:100] Creating Layer bn5c_branch2b
I0625 11:56:04.522336  4216 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0625 11:56:04.522352  4216 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0625 11:56:04.522564  4216 net.cpp:150] Setting up bn5c_branch2b
I0625 11:56:04.522570  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.522572  4216 net.cpp:165] Memory required for data: 6335692884
I0625 11:56:04.522585  4216 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0625 11:56:04.522599  4216 net.cpp:100] Creating Layer scale5c_branch2b
I0625 11:56:04.522604  4216 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0625 11:56:04.522614  4216 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0625 11:56:04.522660  4216 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0625 11:56:04.522802  4216 net.cpp:150] Setting up scale5c_branch2b
I0625 11:56:04.522809  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.522811  4216 net.cpp:165] Memory required for data: 6345523284
I0625 11:56:04.522819  4216 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0625 11:56:04.522828  4216 net.cpp:100] Creating Layer res5c_branch2b_relu
I0625 11:56:04.522833  4216 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0625 11:56:04.522841  4216 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0625 11:56:04.523030  4216 net.cpp:150] Setting up res5c_branch2b_relu
I0625 11:56:04.523036  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:04.523038  4216 net.cpp:165] Memory required for data: 6355353684
I0625 11:56:04.523041  4216 layer_factory.hpp:77] Creating layer res5c_branch2c
I0625 11:56:04.523056  4216 net.cpp:100] Creating Layer res5c_branch2c
I0625 11:56:04.523061  4216 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0625 11:56:04.523073  4216 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0625 11:56:04.526224  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 11:56:04.526249  4216 net.cpp:150] Setting up res5c_branch2c
I0625 11:56:04.526259  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.526262  4216 net.cpp:165] Memory required for data: 6394675284
I0625 11:56:04.526274  4216 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0625 11:56:04.526291  4216 net.cpp:100] Creating Layer bn5c_branch2c
I0625 11:56:04.526298  4216 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0625 11:56:04.526310  4216 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0625 11:56:04.526515  4216 net.cpp:150] Setting up bn5c_branch2c
I0625 11:56:04.526521  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.526523  4216 net.cpp:165] Memory required for data: 6433996884
I0625 11:56:04.526536  4216 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0625 11:56:04.526548  4216 net.cpp:100] Creating Layer scale5c_branch2c
I0625 11:56:04.526553  4216 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0625 11:56:04.526563  4216 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0625 11:56:04.526612  4216 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0625 11:56:04.527307  4216 net.cpp:150] Setting up scale5c_branch2c
I0625 11:56:04.527315  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.527318  4216 net.cpp:165] Memory required for data: 6473318484
I0625 11:56:04.527328  4216 layer_factory.hpp:77] Creating layer res5c
I0625 11:56:04.527338  4216 net.cpp:100] Creating Layer res5c
I0625 11:56:04.527345  4216 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0625 11:56:04.527354  4216 net.cpp:444] res5c <- res5c_branch2c
I0625 11:56:04.527361  4216 net.cpp:418] res5c -> res5c
I0625 11:56:04.527398  4216 net.cpp:150] Setting up res5c
I0625 11:56:04.527405  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.527408  4216 net.cpp:165] Memory required for data: 6512640084
I0625 11:56:04.527411  4216 layer_factory.hpp:77] Creating layer res5c_relu
I0625 11:56:04.527420  4216 net.cpp:100] Creating Layer res5c_relu
I0625 11:56:04.527424  4216 net.cpp:444] res5c_relu <- res5c
I0625 11:56:04.527433  4216 net.cpp:405] res5c_relu -> res5c (in-place)
I0625 11:56:04.527582  4216 net.cpp:150] Setting up res5c_relu
I0625 11:56:04.527588  4216 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 11:56:04.527590  4216 net.cpp:165] Memory required for data: 6551961684
I0625 11:56:04.527593  4216 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 11:56:04.527611  4216 net.cpp:100] Creating Layer rpn_conv/3x3
I0625 11:56:04.527617  4216 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0625 11:56:04.527631  4216 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0625 11:56:04.999976  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:05.000005  4216 net.cpp:150] Setting up rpn_conv/3x3
I0625 11:56:05.000016  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:05.000020  4216 net.cpp:165] Memory required for data: 6561792084
I0625 11:56:05.000039  4216 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 11:56:05.000061  4216 net.cpp:100] Creating Layer rpn_relu/3x3
I0625 11:56:05.000071  4216 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0625 11:56:05.000087  4216 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0625 11:56:05.000495  4216 net.cpp:150] Setting up rpn_relu/3x3
I0625 11:56:05.000502  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:05.000505  4216 net.cpp:165] Memory required for data: 6571622484
I0625 11:56:05.000509  4216 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 11:56:05.000519  4216 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 11:56:05.000524  4216 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 11:56:05.000536  4216 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 11:56:05.000550  4216 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 11:56:05.000594  4216 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 11:56:05.000602  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:05.000604  4216 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 11:56:05.000607  4216 net.cpp:165] Memory required for data: 6591283284
I0625 11:56:05.000609  4216 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 11:56:05.000628  4216 net.cpp:100] Creating Layer rpn_cls_score
I0625 11:56:05.000633  4216 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 11:56:05.000646  4216 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0625 11:56:05.002668  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:05.002688  4216 net.cpp:150] Setting up rpn_cls_score
I0625 11:56:05.002694  4216 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 11:56:05.002696  4216 net.cpp:165] Memory required for data: 6591705684
I0625 11:56:05.002707  4216 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 11:56:05.002717  4216 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 11:56:05.002722  4216 net.cpp:444] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 11:56:05.002733  4216 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 11:56:05.002746  4216 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 11:56:05.002789  4216 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 11:56:05.002795  4216 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 11:56:05.002799  4216 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 11:56:05.002801  4216 net.cpp:165] Memory required for data: 6592550484
I0625 11:56:05.002804  4216 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 11:56:05.002820  4216 net.cpp:100] Creating Layer rpn_bbox_pred
I0625 11:56:05.002825  4216 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 11:56:05.002837  4216 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0625 11:56:05.005998  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:05.006234  4216 net.cpp:150] Setting up rpn_bbox_pred
I0625 11:56:05.006244  4216 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 11:56:05.006247  4216 net.cpp:165] Memory required for data: 6593395284
I0625 11:56:05.006258  4216 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 11:56:05.006268  4216 net.cpp:100] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 11:56:05.006273  4216 net.cpp:444] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 11:56:05.006284  4216 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 11:56:05.006299  4216 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 11:56:05.006342  4216 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 11:56:05.006350  4216 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 11:56:05.006352  4216 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 11:56:05.006356  4216 net.cpp:165] Memory required for data: 6595084884
I0625 11:56:05.006358  4216 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 11:56:05.006368  4216 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0625 11:56:05.006372  4216 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 11:56:05.006386  4216 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 11:56:05.006419  4216 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 11:56:05.006427  4216 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 11:56:05.006428  4216 net.cpp:165] Memory required for data: 6595507284
I0625 11:56:05.006433  4216 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 11:56:05.006439  4216 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 11:56:05.006444  4216 net.cpp:444] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 11:56:05.006454  4216 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 11:56:05.006466  4216 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 11:56:05.006508  4216 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 11:56:05.006515  4216 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 11:56:05.006518  4216 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 11:56:05.006520  4216 net.cpp:165] Memory required for data: 6596352084
I0625 11:56:05.006523  4216 layer_factory.hpp:77] Creating layer rpn-data
I0625 11:56:05.006820  4216 net.cpp:100] Creating Layer rpn-data
I0625 11:56:05.006829  4216 net.cpp:444] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 11:56:05.006840  4216 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I0625 11:56:05.006846  4216 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I0625 11:56:05.006852  4216 net.cpp:444] rpn-data <- data_input-data_0_split_1
I0625 11:56:05.006883  4216 net.cpp:418] rpn-data -> rpn_labels
I0625 11:56:05.006906  4216 net.cpp:418] rpn-data -> rpn_bbox_targets
I0625 11:56:05.006922  4216 net.cpp:418] rpn-data -> rpn_bbox_inside_weights
I0625 11:56:05.006937  4216 net.cpp:418] rpn-data -> rpn_bbox_outside_weights
I0625 11:56:05.007416  4216 net.cpp:150] Setting up rpn-data
I0625 11:56:05.007427  4216 net.cpp:157] Top shape: 1 1 660 80 (52800)
I0625 11:56:05.007431  4216 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 11:56:05.007433  4216 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 11:56:05.007436  4216 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 11:56:05.007438  4216 net.cpp:165] Memory required for data: 6599097684
I0625 11:56:05.007443  4216 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 11:56:05.007455  4216 net.cpp:100] Creating Layer rpn_loss_cls
I0625 11:56:05.007462  4216 net.cpp:444] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 11:56:05.007472  4216 net.cpp:444] rpn_loss_cls <- rpn_labels
I0625 11:56:05.007479  4216 net.cpp:418] rpn_loss_cls -> rpn_cls_loss
I0625 11:56:05.007508  4216 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 11:56:05.007910  4216 net.cpp:150] Setting up rpn_loss_cls
I0625 11:56:05.007920  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.007922  4216 net.cpp:160]     with loss weight 1
I0625 11:56:05.007928  4216 net.cpp:165] Memory required for data: 6599097688
I0625 11:56:05.007932  4216 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 11:56:05.007962  4216 net.cpp:100] Creating Layer rpn_loss_bbox
I0625 11:56:05.007968  4216 net.cpp:444] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 11:56:05.007979  4216 net.cpp:444] rpn_loss_bbox <- rpn_bbox_targets
I0625 11:56:05.007984  4216 net.cpp:444] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 11:56:05.007990  4216 net.cpp:444] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 11:56:05.007997  4216 net.cpp:418] rpn_loss_bbox -> rpn_loss_bbox
I0625 11:56:05.010550  4216 net.cpp:150] Setting up rpn_loss_bbox
I0625 11:56:05.010557  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.010560  4216 net.cpp:160]     with loss weight 1
I0625 11:56:05.010562  4216 net.cpp:165] Memory required for data: 6599097692
I0625 11:56:05.010568  4216 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 11:56:05.010576  4216 net.cpp:100] Creating Layer rpn_cls_prob
I0625 11:56:05.010581  4216 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 11:56:05.010591  4216 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0625 11:56:05.010787  4216 net.cpp:150] Setting up rpn_cls_prob
I0625 11:56:05.010794  4216 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 11:56:05.010797  4216 net.cpp:165] Memory required for data: 6599520092
I0625 11:56:05.010800  4216 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 11:56:05.010812  4216 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0625 11:56:05.010815  4216 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 11:56:05.010828  4216 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 11:56:05.010869  4216 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 11:56:05.010879  4216 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 11:56:05.010881  4216 net.cpp:165] Memory required for data: 6599942492
I0625 11:56:05.010887  4216 layer_factory.hpp:77] Creating layer proposal
I0625 11:56:05.011337  4216 net.cpp:100] Creating Layer proposal
I0625 11:56:05.011346  4216 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0625 11:56:05.011358  4216 net.cpp:444] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 11:56:05.011364  4216 net.cpp:444] proposal <- im_info_input-data_1_split_1
I0625 11:56:05.011373  4216 net.cpp:418] proposal -> rpn_rois
I0625 11:56:05.012818  4216 net.cpp:150] Setting up proposal
I0625 11:56:05.012830  4216 net.cpp:157] Top shape: 1 5 (5)
I0625 11:56:05.012833  4216 net.cpp:165] Memory required for data: 6599942512
I0625 11:56:05.012840  4216 layer_factory.hpp:77] Creating layer roi-data
I0625 11:56:05.012959  4216 net.cpp:100] Creating Layer roi-data
I0625 11:56:05.012969  4216 net.cpp:444] roi-data <- rpn_rois
I0625 11:56:05.012980  4216 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I0625 11:56:05.012990  4216 net.cpp:418] roi-data -> rois
I0625 11:56:05.013003  4216 net.cpp:418] roi-data -> labels
I0625 11:56:05.013013  4216 net.cpp:418] roi-data -> bbox_targets
I0625 11:56:05.013023  4216 net.cpp:418] roi-data -> bbox_inside_weights
I0625 11:56:05.013032  4216 net.cpp:418] roi-data -> bbox_outside_weights
I0625 11:56:05.013339  4216 net.cpp:150] Setting up roi-data
I0625 11:56:05.013350  4216 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 11:56:05.013353  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.013355  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013358  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013360  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013361  4216 net.cpp:165] Memory required for data: 6599942632
I0625 11:56:05.013366  4216 layer_factory.hpp:77] Creating layer rois_roi-data_0_split
I0625 11:56:05.013375  4216 net.cpp:100] Creating Layer rois_roi-data_0_split
I0625 11:56:05.013379  4216 net.cpp:444] rois_roi-data_0_split <- rois
I0625 11:56:05.013391  4216 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_0
I0625 11:56:05.013403  4216 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_1
I0625 11:56:05.013413  4216 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_2
I0625 11:56:05.013465  4216 net.cpp:150] Setting up rois_roi-data_0_split
I0625 11:56:05.013471  4216 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 11:56:05.013475  4216 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 11:56:05.013478  4216 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 11:56:05.013479  4216 net.cpp:165] Memory required for data: 6599942692
I0625 11:56:05.013483  4216 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0625 11:56:05.013489  4216 net.cpp:100] Creating Layer labels_roi-data_1_split
I0625 11:56:05.013494  4216 net.cpp:444] labels_roi-data_1_split <- labels
I0625 11:56:05.013504  4216 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0625 11:56:05.013515  4216 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0625 11:56:05.013553  4216 net.cpp:150] Setting up labels_roi-data_1_split
I0625 11:56:05.013559  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.013562  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.013564  4216 net.cpp:165] Memory required for data: 6599942700
I0625 11:56:05.013567  4216 layer_factory.hpp:77] Creating layer bbox_targets_roi-data_2_split
I0625 11:56:05.013573  4216 net.cpp:100] Creating Layer bbox_targets_roi-data_2_split
I0625 11:56:05.013577  4216 net.cpp:444] bbox_targets_roi-data_2_split <- bbox_targets
I0625 11:56:05.013586  4216 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_0
I0625 11:56:05.013597  4216 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_1
I0625 11:56:05.013634  4216 net.cpp:150] Setting up bbox_targets_roi-data_2_split
I0625 11:56:05.013640  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013643  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013645  4216 net.cpp:165] Memory required for data: 6599942764
I0625 11:56:05.013648  4216 layer_factory.hpp:77] Creating layer bbox_inside_weights_roi-data_3_split
I0625 11:56:05.013654  4216 net.cpp:100] Creating Layer bbox_inside_weights_roi-data_3_split
I0625 11:56:05.013659  4216 net.cpp:444] bbox_inside_weights_roi-data_3_split <- bbox_inside_weights
I0625 11:56:05.013669  4216 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_0
I0625 11:56:05.013680  4216 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_1
I0625 11:56:05.013717  4216 net.cpp:150] Setting up bbox_inside_weights_roi-data_3_split
I0625 11:56:05.013725  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013727  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.013728  4216 net.cpp:165] Memory required for data: 6599942828
I0625 11:56:05.013731  4216 layer_factory.hpp:77] Creating layer conv_new_1
I0625 11:56:05.013751  4216 net.cpp:100] Creating Layer conv_new_1
I0625 11:56:05.013756  4216 net.cpp:444] conv_new_1 <- res5c
I0625 11:56:05.013769  4216 net.cpp:418] conv_new_1 -> conv_new_1
I0625 11:56:05.224372  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:05.224412  4216 net.cpp:150] Setting up conv_new_1
I0625 11:56:05.224424  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:05.224426  4216 net.cpp:165] Memory required for data: 6619603628
I0625 11:56:05.224445  4216 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0625 11:56:05.224467  4216 net.cpp:100] Creating Layer conv_new_1_relu
I0625 11:56:05.224476  4216 net.cpp:444] conv_new_1_relu <- conv_new_1
I0625 11:56:05.224493  4216 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0625 11:56:05.224922  4216 net.cpp:150] Setting up conv_new_1_relu
I0625 11:56:05.224942  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:05.224944  4216 net.cpp:165] Memory required for data: 6639264428
I0625 11:56:05.224948  4216 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0625 11:56:05.224972  4216 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0625 11:56:05.224977  4216 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0625 11:56:05.224989  4216 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0625 11:56:05.225004  4216 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0625 11:56:05.225049  4216 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0625 11:56:05.225057  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:05.225060  4216 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 11:56:05.225061  4216 net.cpp:165] Memory required for data: 6678586028
I0625 11:56:05.225064  4216 layer_factory.hpp:77] Creating layer rfcn_cls
I0625 11:56:05.225083  4216 net.cpp:100] Creating Layer rfcn_cls
I0625 11:56:05.225087  4216 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0625 11:56:05.225101  4216 net.cpp:418] rfcn_cls -> rfcn_cls
I0625 11:56:05.236655  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:05.236680  4216 net.cpp:150] Setting up rfcn_cls
I0625 11:56:05.236687  4216 net.cpp:157] Top shape: 1 98 60 80 (470400)
I0625 11:56:05.236688  4216 net.cpp:165] Memory required for data: 6680467628
I0625 11:56:05.236704  4216 layer_factory.hpp:77] Creating layer rfcn_bbox
I0625 11:56:05.236728  4216 net.cpp:100] Creating Layer rfcn_bbox
I0625 11:56:05.236735  4216 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0625 11:56:05.236752  4216 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0625 11:56:05.278256  4216 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 11:56:05.278296  4216 net.cpp:150] Setting up rfcn_bbox
I0625 11:56:05.278307  4216 net.cpp:157] Top shape: 1 392 60 80 (1881600)
I0625 11:56:05.278309  4216 net.cpp:165] Memory required for data: 6687994028
I0625 11:56:05.278327  4216 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0625 11:56:05.278349  4216 net.cpp:100] Creating Layer psroipooled_cls_rois
I0625 11:56:05.278357  4216 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0625 11:56:05.278369  4216 net.cpp:444] psroipooled_cls_rois <- rois_roi-data_0_split_0
I0625 11:56:05.278379  4216 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0625 11:56:05.278398  4216 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0625 11:56:05.278445  4216 net.cpp:150] Setting up psroipooled_cls_rois
I0625 11:56:05.278450  4216 net.cpp:157] Top shape: 1 2 7 7 (98)
I0625 11:56:05.278451  4216 net.cpp:165] Memory required for data: 6687994420
I0625 11:56:05.278455  4216 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0625 11:56:05.278466  4216 net.cpp:100] Creating Layer ave_cls_score_rois
I0625 11:56:05.278471  4216 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0625 11:56:05.278482  4216 net.cpp:418] ave_cls_score_rois -> cls_score
I0625 11:56:05.278651  4216 net.cpp:150] Setting up ave_cls_score_rois
I0625 11:56:05.278673  4216 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 11:56:05.278676  4216 net.cpp:165] Memory required for data: 6687994428
I0625 11:56:05.278679  4216 layer_factory.hpp:77] Creating layer cls_score_ave_cls_score_rois_0_split
I0625 11:56:05.278688  4216 net.cpp:100] Creating Layer cls_score_ave_cls_score_rois_0_split
I0625 11:56:05.278692  4216 net.cpp:444] cls_score_ave_cls_score_rois_0_split <- cls_score
I0625 11:56:05.278704  4216 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_0
I0625 11:56:05.278717  4216 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_1
I0625 11:56:05.278726  4216 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_2
I0625 11:56:05.278779  4216 net.cpp:150] Setting up cls_score_ave_cls_score_rois_0_split
I0625 11:56:05.278784  4216 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 11:56:05.278789  4216 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 11:56:05.278790  4216 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 11:56:05.278792  4216 net.cpp:165] Memory required for data: 6687994452
I0625 11:56:05.278795  4216 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0625 11:56:05.278805  4216 net.cpp:100] Creating Layer psroipooled_loc_rois
I0625 11:56:05.278808  4216 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0625 11:56:05.278817  4216 net.cpp:444] psroipooled_loc_rois <- rois_roi-data_0_split_1
I0625 11:56:05.278825  4216 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0625 11:56:05.278836  4216 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0625 11:56:05.278888  4216 net.cpp:150] Setting up psroipooled_loc_rois
I0625 11:56:05.278898  4216 net.cpp:157] Top shape: 1 8 7 7 (392)
I0625 11:56:05.278900  4216 net.cpp:165] Memory required for data: 6687996020
I0625 11:56:05.278905  4216 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0625 11:56:05.278918  4216 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0625 11:56:05.278924  4216 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0625 11:56:05.278937  4216 net.cpp:418] ave_bbox_pred_rois -> bbox_pred
I0625 11:56:05.279094  4216 net.cpp:150] Setting up ave_bbox_pred_rois
I0625 11:56:05.279103  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.279104  4216 net.cpp:165] Memory required for data: 6687996052
I0625 11:56:05.279109  4216 layer_factory.hpp:77] Creating layer bbox_pred_ave_bbox_pred_rois_0_split
I0625 11:56:05.279117  4216 net.cpp:100] Creating Layer bbox_pred_ave_bbox_pred_rois_0_split
I0625 11:56:05.279122  4216 net.cpp:444] bbox_pred_ave_bbox_pred_rois_0_split <- bbox_pred
I0625 11:56:05.279134  4216 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_0
I0625 11:56:05.279145  4216 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_1
I0625 11:56:05.279186  4216 net.cpp:150] Setting up bbox_pred_ave_bbox_pred_rois_0_split
I0625 11:56:05.279193  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.279196  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.279198  4216 net.cpp:165] Memory required for data: 6687996116
I0625 11:56:05.279201  4216 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0625 11:56:05.279211  4216 net.cpp:100] Creating Layer per_roi_loss_cls
I0625 11:56:05.279214  4216 net.cpp:444] per_roi_loss_cls <- cls_score_ave_cls_score_rois_0_split_0
I0625 11:56:05.279223  4216 net.cpp:444] per_roi_loss_cls <- labels_roi-data_1_split_0
I0625 11:56:05.279232  4216 net.cpp:418] per_roi_loss_cls -> temp_loss_cls
I0625 11:56:05.279244  4216 net.cpp:418] per_roi_loss_cls -> temp_prob_cls
I0625 11:56:05.279253  4216 net.cpp:418] per_roi_loss_cls -> per_roi_loss_cls
I0625 11:56:05.279264  4216 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0625 11:56:05.279762  4216 net.cpp:150] Setting up per_roi_loss_cls
I0625 11:56:05.279772  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.279775  4216 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 11:56:05.279778  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.279779  4216 net.cpp:165] Memory required for data: 6687996132
I0625 11:56:05.279783  4216 layer_factory.hpp:77] Creating layer per_roi_loss_bbox
I0625 11:56:05.279793  4216 net.cpp:100] Creating Layer per_roi_loss_bbox
I0625 11:56:05.279798  4216 net.cpp:444] per_roi_loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_0
I0625 11:56:05.279808  4216 net.cpp:444] per_roi_loss_bbox <- bbox_targets_roi-data_2_split_0
I0625 11:56:05.279814  4216 net.cpp:444] per_roi_loss_bbox <- bbox_inside_weights_roi-data_3_split_0
I0625 11:56:05.279822  4216 net.cpp:418] per_roi_loss_bbox -> temp_loss_bbox
I0625 11:56:05.279835  4216 net.cpp:418] per_roi_loss_bbox -> per_roi_loss_bbox
I0625 11:56:05.279896  4216 net.cpp:150] Setting up per_roi_loss_bbox
I0625 11:56:05.279903  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.279906  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.279908  4216 net.cpp:165] Memory required for data: 6687996140
I0625 11:56:05.279911  4216 layer_factory.hpp:77] Creating layer per_roi_loss
I0625 11:56:05.279920  4216 net.cpp:100] Creating Layer per_roi_loss
I0625 11:56:05.279924  4216 net.cpp:444] per_roi_loss <- per_roi_loss_cls
I0625 11:56:05.279932  4216 net.cpp:444] per_roi_loss <- per_roi_loss_bbox
I0625 11:56:05.279942  4216 net.cpp:418] per_roi_loss -> per_roi_loss
I0625 11:56:05.279973  4216 net.cpp:150] Setting up per_roi_loss
I0625 11:56:05.279979  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.279981  4216 net.cpp:165] Memory required for data: 6687996144
I0625 11:56:05.279985  4216 layer_factory.hpp:77] Creating layer annotator_detector
I0625 11:56:05.279995  4216 net.cpp:100] Creating Layer annotator_detector
I0625 11:56:05.279999  4216 net.cpp:444] annotator_detector <- rois_roi-data_0_split_2
I0625 11:56:05.280007  4216 net.cpp:444] annotator_detector <- per_roi_loss
I0625 11:56:05.280014  4216 net.cpp:444] annotator_detector <- labels_roi-data_1_split_1
I0625 11:56:05.280019  4216 net.cpp:444] annotator_detector <- bbox_inside_weights_roi-data_3_split_1
I0625 11:56:05.280025  4216 net.cpp:418] annotator_detector -> labels_ohem
I0625 11:56:05.280037  4216 net.cpp:418] annotator_detector -> bbox_loss_weights_ohem
I0625 11:56:05.280082  4216 net.cpp:150] Setting up annotator_detector
I0625 11:56:05.280088  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.280092  4216 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 11:56:05.280093  4216 net.cpp:165] Memory required for data: 6687996180
I0625 11:56:05.280097  4216 layer_factory.hpp:77] Creating layer labels_ohem_annotator_detector_0_split
I0625 11:56:05.280104  4216 net.cpp:100] Creating Layer labels_ohem_annotator_detector_0_split
I0625 11:56:05.280108  4216 net.cpp:444] labels_ohem_annotator_detector_0_split <- labels_ohem
I0625 11:56:05.280119  4216 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_0
I0625 11:56:05.280130  4216 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_1
I0625 11:56:05.280169  4216 net.cpp:150] Setting up labels_ohem_annotator_detector_0_split
I0625 11:56:05.280176  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.280179  4216 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 11:56:05.280181  4216 net.cpp:165] Memory required for data: 6687996188
I0625 11:56:05.280184  4216 layer_factory.hpp:77] Creating layer silence
I0625 11:56:05.280191  4216 net.cpp:100] Creating Layer silence
I0625 11:56:05.280195  4216 net.cpp:444] silence <- bbox_outside_weights
I0625 11:56:05.280203  4216 net.cpp:444] silence <- temp_loss_cls
I0625 11:56:05.280210  4216 net.cpp:444] silence <- temp_prob_cls
I0625 11:56:05.280213  4216 net.cpp:444] silence <- temp_loss_bbox
I0625 11:56:05.280217  4216 net.cpp:150] Setting up silence
I0625 11:56:05.280220  4216 net.cpp:165] Memory required for data: 6687996188
I0625 11:56:05.280222  4216 layer_factory.hpp:77] Creating layer loss
I0625 11:56:05.280230  4216 net.cpp:100] Creating Layer loss
I0625 11:56:05.280233  4216 net.cpp:444] loss <- cls_score_ave_cls_score_rois_0_split_1
I0625 11:56:05.280241  4216 net.cpp:444] loss <- labels_ohem_annotator_detector_0_split_0
I0625 11:56:05.280248  4216 net.cpp:418] loss -> loss_cls
I0625 11:56:05.280261  4216 layer_factory.hpp:77] Creating layer loss
I0625 11:56:05.280485  4216 net.cpp:150] Setting up loss
I0625 11:56:05.280493  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.280495  4216 net.cpp:160]     with loss weight 1
I0625 11:56:05.280499  4216 net.cpp:165] Memory required for data: 6687996192
I0625 11:56:05.280503  4216 layer_factory.hpp:77] Creating layer accuarcy
I0625 11:56:05.280514  4216 net.cpp:100] Creating Layer accuarcy
I0625 11:56:05.280519  4216 net.cpp:444] accuarcy <- cls_score_ave_cls_score_rois_0_split_2
I0625 11:56:05.280527  4216 net.cpp:444] accuarcy <- labels_ohem_annotator_detector_0_split_1
I0625 11:56:05.280536  4216 net.cpp:418] accuarcy -> accuarcy
I0625 11:56:05.280551  4216 net.cpp:150] Setting up accuarcy
I0625 11:56:05.280557  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.280560  4216 net.cpp:165] Memory required for data: 6687996196
I0625 11:56:05.280562  4216 layer_factory.hpp:77] Creating layer loss_bbox
I0625 11:56:05.280570  4216 net.cpp:100] Creating Layer loss_bbox
I0625 11:56:05.280575  4216 net.cpp:444] loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_1
I0625 11:56:05.280582  4216 net.cpp:444] loss_bbox <- bbox_targets_roi-data_2_split_1
I0625 11:56:05.280587  4216 net.cpp:444] loss_bbox <- bbox_loss_weights_ohem
I0625 11:56:05.280596  4216 net.cpp:418] loss_bbox -> loss_bbox
I0625 11:56:05.280658  4216 net.cpp:150] Setting up loss_bbox
I0625 11:56:05.280663  4216 net.cpp:157] Top shape: (1)
I0625 11:56:05.280665  4216 net.cpp:160]     with loss weight 1
I0625 11:56:05.280668  4216 net.cpp:165] Memory required for data: 6687996200
I0625 11:56:05.280673  4216 net.cpp:226] loss_bbox needs backward computation.
I0625 11:56:05.280678  4216 net.cpp:228] accuarcy does not need backward computation.
I0625 11:56:05.280681  4216 net.cpp:226] loss needs backward computation.
I0625 11:56:05.280685  4216 net.cpp:228] silence does not need backward computation.
I0625 11:56:05.280690  4216 net.cpp:228] labels_ohem_annotator_detector_0_split does not need backward computation.
I0625 11:56:05.280694  4216 net.cpp:228] annotator_detector does not need backward computation.
I0625 11:56:05.280699  4216 net.cpp:228] per_roi_loss does not need backward computation.
I0625 11:56:05.280704  4216 net.cpp:228] per_roi_loss_bbox does not need backward computation.
I0625 11:56:05.280711  4216 net.cpp:228] per_roi_loss_cls does not need backward computation.
I0625 11:56:05.280716  4216 net.cpp:226] bbox_pred_ave_bbox_pred_rois_0_split needs backward computation.
I0625 11:56:05.280719  4216 net.cpp:226] ave_bbox_pred_rois needs backward computation.
I0625 11:56:05.280722  4216 net.cpp:226] psroipooled_loc_rois needs backward computation.
I0625 11:56:05.280726  4216 net.cpp:226] cls_score_ave_cls_score_rois_0_split needs backward computation.
I0625 11:56:05.280730  4216 net.cpp:226] ave_cls_score_rois needs backward computation.
I0625 11:56:05.280732  4216 net.cpp:226] psroipooled_cls_rois needs backward computation.
I0625 11:56:05.280737  4216 net.cpp:226] rfcn_bbox needs backward computation.
I0625 11:56:05.280740  4216 net.cpp:226] rfcn_cls needs backward computation.
I0625 11:56:05.280743  4216 net.cpp:226] conv_new_1_conv_new_1_relu_0_split needs backward computation.
I0625 11:56:05.280747  4216 net.cpp:226] conv_new_1_relu needs backward computation.
I0625 11:56:05.280750  4216 net.cpp:226] conv_new_1 needs backward computation.
I0625 11:56:05.280755  4216 net.cpp:228] bbox_inside_weights_roi-data_3_split does not need backward computation.
I0625 11:56:05.280757  4216 net.cpp:228] bbox_targets_roi-data_2_split does not need backward computation.
I0625 11:56:05.280762  4216 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0625 11:56:05.280766  4216 net.cpp:226] rois_roi-data_0_split needs backward computation.
I0625 11:56:05.280769  4216 net.cpp:226] roi-data needs backward computation.
I0625 11:56:05.280774  4216 net.cpp:226] proposal needs backward computation.
I0625 11:56:05.280781  4216 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 11:56:05.280783  4216 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 11:56:05.280786  4216 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 11:56:05.280792  4216 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 11:56:05.280797  4216 net.cpp:226] rpn-data needs backward computation.
I0625 11:56:05.280804  4216 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 11:56:05.280808  4216 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 11:56:05.280812  4216 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 11:56:05.280817  4216 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 11:56:05.280819  4216 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 11:56:05.280822  4216 net.cpp:226] rpn_cls_score needs backward computation.
I0625 11:56:05.280827  4216 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 11:56:05.280829  4216 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 11:56:05.280833  4216 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 11:56:05.280835  4216 net.cpp:226] res5c_relu needs backward computation.
I0625 11:56:05.280838  4216 net.cpp:226] res5c needs backward computation.
I0625 11:56:05.280843  4216 net.cpp:226] scale5c_branch2c needs backward computation.
I0625 11:56:05.280845  4216 net.cpp:226] bn5c_branch2c needs backward computation.
I0625 11:56:05.280848  4216 net.cpp:226] res5c_branch2c needs backward computation.
I0625 11:56:05.280850  4216 net.cpp:226] res5c_branch2b_relu needs backward computation.
I0625 11:56:05.280853  4216 net.cpp:226] scale5c_branch2b needs backward computation.
I0625 11:56:05.280856  4216 net.cpp:226] bn5c_branch2b needs backward computation.
I0625 11:56:05.280858  4216 net.cpp:226] res5c_branch2b needs backward computation.
I0625 11:56:05.280863  4216 net.cpp:226] res5c_branch2a_relu needs backward computation.
I0625 11:56:05.280865  4216 net.cpp:226] scale5c_branch2a needs backward computation.
I0625 11:56:05.280869  4216 net.cpp:226] bn5c_branch2a needs backward computation.
I0625 11:56:05.280871  4216 net.cpp:226] res5c_branch2a needs backward computation.
I0625 11:56:05.280874  4216 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I0625 11:56:05.280879  4216 net.cpp:226] res5b_relu needs backward computation.
I0625 11:56:05.280881  4216 net.cpp:226] res5b needs backward computation.
I0625 11:56:05.280885  4216 net.cpp:226] scale5b_branch2c needs backward computation.
I0625 11:56:05.280889  4216 net.cpp:226] bn5b_branch2c needs backward computation.
I0625 11:56:05.280890  4216 net.cpp:226] res5b_branch2c needs backward computation.
I0625 11:56:05.280894  4216 net.cpp:226] res5b_branch2b_relu needs backward computation.
I0625 11:56:05.280896  4216 net.cpp:226] scale5b_branch2b needs backward computation.
I0625 11:56:05.280900  4216 net.cpp:226] bn5b_branch2b needs backward computation.
I0625 11:56:05.280902  4216 net.cpp:226] res5b_branch2b needs backward computation.
I0625 11:56:05.280905  4216 net.cpp:226] res5b_branch2a_relu needs backward computation.
I0625 11:56:05.280907  4216 net.cpp:226] scale5b_branch2a needs backward computation.
I0625 11:56:05.280910  4216 net.cpp:226] bn5b_branch2a needs backward computation.
I0625 11:56:05.280913  4216 net.cpp:226] res5b_branch2a needs backward computation.
I0625 11:56:05.280917  4216 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I0625 11:56:05.280920  4216 net.cpp:226] res5a_relu needs backward computation.
I0625 11:56:05.280922  4216 net.cpp:226] res5a needs backward computation.
I0625 11:56:05.280926  4216 net.cpp:226] scale5a_branch2c needs backward computation.
I0625 11:56:05.280930  4216 net.cpp:226] bn5a_branch2c needs backward computation.
I0625 11:56:05.280932  4216 net.cpp:226] res5a_branch2c needs backward computation.
I0625 11:56:05.280936  4216 net.cpp:226] res5a_branch2b_relu needs backward computation.
I0625 11:56:05.280938  4216 net.cpp:226] scale5a_branch2b needs backward computation.
I0625 11:56:05.280941  4216 net.cpp:226] bn5a_branch2b needs backward computation.
I0625 11:56:05.280943  4216 net.cpp:226] res5a_branch2b needs backward computation.
I0625 11:56:05.280947  4216 net.cpp:226] res5a_branch2a_relu needs backward computation.
I0625 11:56:05.280951  4216 net.cpp:226] scale5a_branch2a needs backward computation.
I0625 11:56:05.280953  4216 net.cpp:226] bn5a_branch2a needs backward computation.
I0625 11:56:05.280956  4216 net.cpp:226] res5a_branch2a needs backward computation.
I0625 11:56:05.280961  4216 net.cpp:226] scale5a_branch1 needs backward computation.
I0625 11:56:05.280962  4216 net.cpp:226] bn5a_branch1 needs backward computation.
I0625 11:56:05.280966  4216 net.cpp:226] res5a_branch1 needs backward computation.
I0625 11:56:05.280970  4216 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I0625 11:56:05.280973  4216 net.cpp:226] res4f_relu needs backward computation.
I0625 11:56:05.280977  4216 net.cpp:226] res4f needs backward computation.
I0625 11:56:05.280980  4216 net.cpp:226] scale4f_branch2c needs backward computation.
I0625 11:56:05.280983  4216 net.cpp:226] bn4f_branch2c needs backward computation.
I0625 11:56:05.280987  4216 net.cpp:226] res4f_branch2c needs backward computation.
I0625 11:56:05.280989  4216 net.cpp:226] res4f_branch2b_relu needs backward computation.
I0625 11:56:05.280992  4216 net.cpp:226] scale4f_branch2b needs backward computation.
I0625 11:56:05.280997  4216 net.cpp:226] bn4f_branch2b needs backward computation.
I0625 11:56:05.280998  4216 net.cpp:226] res4f_branch2b needs backward computation.
I0625 11:56:05.281002  4216 net.cpp:226] res4f_branch2a_relu needs backward computation.
I0625 11:56:05.281003  4216 net.cpp:226] scale4f_branch2a needs backward computation.
I0625 11:56:05.281008  4216 net.cpp:226] bn4f_branch2a needs backward computation.
I0625 11:56:05.281010  4216 net.cpp:226] res4f_branch2a needs backward computation.
I0625 11:56:05.281013  4216 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I0625 11:56:05.281016  4216 net.cpp:226] res4e_relu needs backward computation.
I0625 11:56:05.281019  4216 net.cpp:226] res4e needs backward computation.
I0625 11:56:05.281023  4216 net.cpp:226] scale4e_branch2c needs backward computation.
I0625 11:56:05.281025  4216 net.cpp:226] bn4e_branch2c needs backward computation.
I0625 11:56:05.281028  4216 net.cpp:226] res4e_branch2c needs backward computation.
I0625 11:56:05.281033  4216 net.cpp:226] res4e_branch2b_relu needs backward computation.
I0625 11:56:05.281035  4216 net.cpp:226] scale4e_branch2b needs backward computation.
I0625 11:56:05.281038  4216 net.cpp:226] bn4e_branch2b needs backward computation.
I0625 11:56:05.281040  4216 net.cpp:226] res4e_branch2b needs backward computation.
I0625 11:56:05.281044  4216 net.cpp:226] res4e_branch2a_relu needs backward computation.
I0625 11:56:05.281047  4216 net.cpp:226] scale4e_branch2a needs backward computation.
I0625 11:56:05.281049  4216 net.cpp:226] bn4e_branch2a needs backward computation.
I0625 11:56:05.281052  4216 net.cpp:226] res4e_branch2a needs backward computation.
I0625 11:56:05.281056  4216 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I0625 11:56:05.281059  4216 net.cpp:226] res4d_relu needs backward computation.
I0625 11:56:05.281062  4216 net.cpp:226] res4d needs backward computation.
I0625 11:56:05.281066  4216 net.cpp:226] scale4d_branch2c needs backward computation.
I0625 11:56:05.281070  4216 net.cpp:226] bn4d_branch2c needs backward computation.
I0625 11:56:05.281072  4216 net.cpp:226] res4d_branch2c needs backward computation.
I0625 11:56:05.281075  4216 net.cpp:226] res4d_branch2b_relu needs backward computation.
I0625 11:56:05.281078  4216 net.cpp:226] scale4d_branch2b needs backward computation.
I0625 11:56:05.281081  4216 net.cpp:226] bn4d_branch2b needs backward computation.
I0625 11:56:05.281085  4216 net.cpp:226] res4d_branch2b needs backward computation.
I0625 11:56:05.281087  4216 net.cpp:226] res4d_branch2a_relu needs backward computation.
I0625 11:56:05.281090  4216 net.cpp:226] scale4d_branch2a needs backward computation.
I0625 11:56:05.281093  4216 net.cpp:226] bn4d_branch2a needs backward computation.
I0625 11:56:05.281096  4216 net.cpp:226] res4d_branch2a needs backward computation.
I0625 11:56:05.281100  4216 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I0625 11:56:05.281103  4216 net.cpp:226] res4c_relu needs backward computation.
I0625 11:56:05.281106  4216 net.cpp:226] res4c needs backward computation.
I0625 11:56:05.281110  4216 net.cpp:226] scale4c_branch2c needs backward computation.
I0625 11:56:05.281113  4216 net.cpp:226] bn4c_branch2c needs backward computation.
I0625 11:56:05.281116  4216 net.cpp:226] res4c_branch2c needs backward computation.
I0625 11:56:05.281118  4216 net.cpp:226] res4c_branch2b_relu needs backward computation.
I0625 11:56:05.281122  4216 net.cpp:226] scale4c_branch2b needs backward computation.
I0625 11:56:05.281124  4216 net.cpp:226] bn4c_branch2b needs backward computation.
I0625 11:56:05.281127  4216 net.cpp:226] res4c_branch2b needs backward computation.
I0625 11:56:05.281131  4216 net.cpp:226] res4c_branch2a_relu needs backward computation.
I0625 11:56:05.281133  4216 net.cpp:226] scale4c_branch2a needs backward computation.
I0625 11:56:05.281136  4216 net.cpp:226] bn4c_branch2a needs backward computation.
I0625 11:56:05.281139  4216 net.cpp:226] res4c_branch2a needs backward computation.
I0625 11:56:05.281142  4216 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I0625 11:56:05.281147  4216 net.cpp:226] res4b_relu needs backward computation.
I0625 11:56:05.281148  4216 net.cpp:226] res4b needs backward computation.
I0625 11:56:05.281152  4216 net.cpp:226] scale4b_branch2c needs backward computation.
I0625 11:56:05.281155  4216 net.cpp:226] bn4b_branch2c needs backward computation.
I0625 11:56:05.281158  4216 net.cpp:226] res4b_branch2c needs backward computation.
I0625 11:56:05.281162  4216 net.cpp:226] res4b_branch2b_relu needs backward computation.
I0625 11:56:05.281163  4216 net.cpp:226] scale4b_branch2b needs backward computation.
I0625 11:56:05.281167  4216 net.cpp:226] bn4b_branch2b needs backward computation.
I0625 11:56:05.281169  4216 net.cpp:226] res4b_branch2b needs backward computation.
I0625 11:56:05.281172  4216 net.cpp:226] res4b_branch2a_relu needs backward computation.
I0625 11:56:05.281175  4216 net.cpp:226] scale4b_branch2a needs backward computation.
I0625 11:56:05.281178  4216 net.cpp:226] bn4b_branch2a needs backward computation.
I0625 11:56:05.281183  4216 net.cpp:226] res4b_branch2a needs backward computation.
I0625 11:56:05.281185  4216 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I0625 11:56:05.281188  4216 net.cpp:226] res4a_relu needs backward computation.
I0625 11:56:05.281191  4216 net.cpp:226] res4a needs backward computation.
I0625 11:56:05.281194  4216 net.cpp:226] scale4a_branch2c needs backward computation.
I0625 11:56:05.281198  4216 net.cpp:226] bn4a_branch2c needs backward computation.
I0625 11:56:05.281200  4216 net.cpp:226] res4a_branch2c needs backward computation.
I0625 11:56:05.281203  4216 net.cpp:226] res4a_branch2b_relu needs backward computation.
I0625 11:56:05.281206  4216 net.cpp:226] scale4a_branch2b needs backward computation.
I0625 11:56:05.281209  4216 net.cpp:226] bn4a_branch2b needs backward computation.
I0625 11:56:05.281213  4216 net.cpp:226] res4a_branch2b needs backward computation.
I0625 11:56:05.281216  4216 net.cpp:226] res4a_branch2a_relu needs backward computation.
I0625 11:56:05.281219  4216 net.cpp:226] scale4a_branch2a needs backward computation.
I0625 11:56:05.281221  4216 net.cpp:226] bn4a_branch2a needs backward computation.
I0625 11:56:05.281224  4216 net.cpp:226] res4a_branch2a needs backward computation.
I0625 11:56:05.281227  4216 net.cpp:226] scale4a_branch1 needs backward computation.
I0625 11:56:05.281231  4216 net.cpp:226] bn4a_branch1 needs backward computation.
I0625 11:56:05.281234  4216 net.cpp:226] res4a_branch1 needs backward computation.
I0625 11:56:05.281239  4216 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I0625 11:56:05.281242  4216 net.cpp:226] res3d_relu needs backward computation.
I0625 11:56:05.281244  4216 net.cpp:226] res3d needs backward computation.
I0625 11:56:05.281250  4216 net.cpp:226] scale3d_branch2c needs backward computation.
I0625 11:56:05.281252  4216 net.cpp:226] bn3d_branch2c needs backward computation.
I0625 11:56:05.281255  4216 net.cpp:226] res3d_branch2c needs backward computation.
I0625 11:56:05.281258  4216 net.cpp:226] res3d_branch2b_relu needs backward computation.
I0625 11:56:05.281261  4216 net.cpp:226] scale3d_branch2b needs backward computation.
I0625 11:56:05.281265  4216 net.cpp:226] bn3d_branch2b needs backward computation.
I0625 11:56:05.281267  4216 net.cpp:226] res3d_branch2b needs backward computation.
I0625 11:56:05.281270  4216 net.cpp:226] res3d_branch2a_relu needs backward computation.
I0625 11:56:05.281273  4216 net.cpp:226] scale3d_branch2a needs backward computation.
I0625 11:56:05.281276  4216 net.cpp:226] bn3d_branch2a needs backward computation.
I0625 11:56:05.281280  4216 net.cpp:226] res3d_branch2a needs backward computation.
I0625 11:56:05.281285  4216 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I0625 11:56:05.281287  4216 net.cpp:226] res3c_relu needs backward computation.
I0625 11:56:05.281291  4216 net.cpp:226] res3c needs backward computation.
I0625 11:56:05.281294  4216 net.cpp:226] scale3c_branch2c needs backward computation.
I0625 11:56:05.281297  4216 net.cpp:226] bn3c_branch2c needs backward computation.
I0625 11:56:05.281301  4216 net.cpp:226] res3c_branch2c needs backward computation.
I0625 11:56:05.281303  4216 net.cpp:226] res3c_branch2b_relu needs backward computation.
I0625 11:56:05.281306  4216 net.cpp:226] scale3c_branch2b needs backward computation.
I0625 11:56:05.281309  4216 net.cpp:226] bn3c_branch2b needs backward computation.
I0625 11:56:05.281312  4216 net.cpp:226] res3c_branch2b needs backward computation.
I0625 11:56:05.281316  4216 net.cpp:226] res3c_branch2a_relu needs backward computation.
I0625 11:56:05.281319  4216 net.cpp:226] scale3c_branch2a needs backward computation.
I0625 11:56:05.281322  4216 net.cpp:226] bn3c_branch2a needs backward computation.
I0625 11:56:05.281325  4216 net.cpp:226] res3c_branch2a needs backward computation.
I0625 11:56:05.281328  4216 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I0625 11:56:05.281332  4216 net.cpp:226] res3b_relu needs backward computation.
I0625 11:56:05.281334  4216 net.cpp:226] res3b needs backward computation.
I0625 11:56:05.281338  4216 net.cpp:226] scale3b_branch2c needs backward computation.
I0625 11:56:05.281342  4216 net.cpp:226] bn3b_branch2c needs backward computation.
I0625 11:56:05.281344  4216 net.cpp:226] res3b_branch2c needs backward computation.
I0625 11:56:05.281347  4216 net.cpp:226] res3b_branch2b_relu needs backward computation.
I0625 11:56:05.281352  4216 net.cpp:226] scale3b_branch2b needs backward computation.
I0625 11:56:05.281353  4216 net.cpp:226] bn3b_branch2b needs backward computation.
I0625 11:56:05.281357  4216 net.cpp:226] res3b_branch2b needs backward computation.
I0625 11:56:05.281360  4216 net.cpp:226] res3b_branch2a_relu needs backward computation.
I0625 11:56:05.281363  4216 net.cpp:226] scale3b_branch2a needs backward computation.
I0625 11:56:05.281366  4216 net.cpp:226] bn3b_branch2a needs backward computation.
I0625 11:56:05.281369  4216 net.cpp:226] res3b_branch2a needs backward computation.
I0625 11:56:05.281373  4216 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I0625 11:56:05.281375  4216 net.cpp:226] res3a_relu needs backward computation.
I0625 11:56:05.281378  4216 net.cpp:226] res3a needs backward computation.
I0625 11:56:05.281381  4216 net.cpp:226] scale3a_branch2c needs backward computation.
I0625 11:56:05.281384  4216 net.cpp:226] bn3a_branch2c needs backward computation.
I0625 11:56:05.281388  4216 net.cpp:226] res3a_branch2c needs backward computation.
I0625 11:56:05.281390  4216 net.cpp:226] res3a_branch2b_relu needs backward computation.
I0625 11:56:05.281394  4216 net.cpp:226] scale3a_branch2b needs backward computation.
I0625 11:56:05.281396  4216 net.cpp:226] bn3a_branch2b needs backward computation.
I0625 11:56:05.281399  4216 net.cpp:226] res3a_branch2b needs backward computation.
I0625 11:56:05.281402  4216 net.cpp:226] res3a_branch2a_relu needs backward computation.
I0625 11:56:05.281406  4216 net.cpp:226] scale3a_branch2a needs backward computation.
I0625 11:56:05.281409  4216 net.cpp:226] bn3a_branch2a needs backward computation.
I0625 11:56:05.281412  4216 net.cpp:226] res3a_branch2a needs backward computation.
I0625 11:56:05.281416  4216 net.cpp:226] scale3a_branch1 needs backward computation.
I0625 11:56:05.281419  4216 net.cpp:226] bn3a_branch1 needs backward computation.
I0625 11:56:05.281422  4216 net.cpp:226] res3a_branch1 needs backward computation.
I0625 11:56:05.281427  4216 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0625 11:56:05.281431  4216 net.cpp:228] res2c_relu does not need backward computation.
I0625 11:56:05.281435  4216 net.cpp:228] res2c does not need backward computation.
I0625 11:56:05.281440  4216 net.cpp:228] scale2c_branch2c does not need backward computation.
I0625 11:56:05.281445  4216 net.cpp:228] bn2c_branch2c does not need backward computation.
I0625 11:56:05.281446  4216 net.cpp:228] res2c_branch2c does not need backward computation.
I0625 11:56:05.281450  4216 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0625 11:56:05.281455  4216 net.cpp:228] scale2c_branch2b does not need backward computation.
I0625 11:56:05.281457  4216 net.cpp:228] bn2c_branch2b does not need backward computation.
I0625 11:56:05.281461  4216 net.cpp:228] res2c_branch2b does not need backward computation.
I0625 11:56:05.281466  4216 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0625 11:56:05.281469  4216 net.cpp:228] scale2c_branch2a does not need backward computation.
I0625 11:56:05.281473  4216 net.cpp:228] bn2c_branch2a does not need backward computation.
I0625 11:56:05.281476  4216 net.cpp:228] res2c_branch2a does not need backward computation.
I0625 11:56:05.281481  4216 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0625 11:56:05.281486  4216 net.cpp:228] res2b_relu does not need backward computation.
I0625 11:56:05.281488  4216 net.cpp:228] res2b does not need backward computation.
I0625 11:56:05.281493  4216 net.cpp:228] scale2b_branch2c does not need backward computation.
I0625 11:56:05.281497  4216 net.cpp:228] bn2b_branch2c does not need backward computation.
I0625 11:56:05.281500  4216 net.cpp:228] res2b_branch2c does not need backward computation.
I0625 11:56:05.281504  4216 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0625 11:56:05.281507  4216 net.cpp:228] scale2b_branch2b does not need backward computation.
I0625 11:56:05.281512  4216 net.cpp:228] bn2b_branch2b does not need backward computation.
I0625 11:56:05.281514  4216 net.cpp:228] res2b_branch2b does not need backward computation.
I0625 11:56:05.281519  4216 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0625 11:56:05.281523  4216 net.cpp:228] scale2b_branch2a does not need backward computation.
I0625 11:56:05.281527  4216 net.cpp:228] bn2b_branch2a does not need backward computation.
I0625 11:56:05.281530  4216 net.cpp:228] res2b_branch2a does not need backward computation.
I0625 11:56:05.281535  4216 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0625 11:56:05.281539  4216 net.cpp:228] res2a_relu does not need backward computation.
I0625 11:56:05.281543  4216 net.cpp:228] res2a does not need backward computation.
I0625 11:56:05.281548  4216 net.cpp:228] scale2a_branch2c does not need backward computation.
I0625 11:56:05.281551  4216 net.cpp:228] bn2a_branch2c does not need backward computation.
I0625 11:56:05.281554  4216 net.cpp:228] res2a_branch2c does not need backward computation.
I0625 11:56:05.281559  4216 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0625 11:56:05.281563  4216 net.cpp:228] scale2a_branch2b does not need backward computation.
I0625 11:56:05.281566  4216 net.cpp:228] bn2a_branch2b does not need backward computation.
I0625 11:56:05.281569  4216 net.cpp:228] res2a_branch2b does not need backward computation.
I0625 11:56:05.281574  4216 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0625 11:56:05.281577  4216 net.cpp:228] scale2a_branch2a does not need backward computation.
I0625 11:56:05.281580  4216 net.cpp:228] bn2a_branch2a does not need backward computation.
I0625 11:56:05.281584  4216 net.cpp:228] res2a_branch2a does not need backward computation.
I0625 11:56:05.281589  4216 net.cpp:228] scale2a_branch1 does not need backward computation.
I0625 11:56:05.281592  4216 net.cpp:228] bn2a_branch1 does not need backward computation.
I0625 11:56:05.281595  4216 net.cpp:228] res2a_branch1 does not need backward computation.
I0625 11:56:05.281600  4216 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0625 11:56:05.281605  4216 net.cpp:228] pool1 does not need backward computation.
I0625 11:56:05.281608  4216 net.cpp:228] conv1_relu does not need backward computation.
I0625 11:56:05.281612  4216 net.cpp:228] scale_conv1 does not need backward computation.
I0625 11:56:05.281615  4216 net.cpp:228] bn_conv1 does not need backward computation.
I0625 11:56:05.281618  4216 net.cpp:228] conv1 does not need backward computation.
I0625 11:56:05.281623  4216 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 11:56:05.281628  4216 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 11:56:05.281633  4216 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 11:56:05.281639  4216 net.cpp:228] input-data does not need backward computation.
I0625 11:56:05.281641  4216 net.cpp:270] This network produces output accuarcy
I0625 11:56:05.281646  4216 net.cpp:270] This network produces output loss_bbox
I0625 11:56:05.281651  4216 net.cpp:270] This network produces output loss_cls
I0625 11:56:05.281654  4216 net.cpp:270] This network produces output rpn_cls_loss
I0625 11:56:05.281657  4216 net.cpp:270] This network produces output rpn_loss_bbox
I0625 11:56:05.281953  4216 net.cpp:283] Network initialization done.
I0625 11:56:05.282377  4216 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I0625 11:56:05.373922  4216 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I0625 11:56:05.373957  4216 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0625 11:56:05.373960  4216 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0625 11:56:05.373965  4216 net.cpp:774] Copying source layer conv1
I0625 11:56:05.374052  4216 net.cpp:774] Copying source layer bn_conv1
I0625 11:56:05.374058  4216 net.cpp:774] Copying source layer scale_conv1
I0625 11:56:05.374063  4216 net.cpp:774] Copying source layer conv1_relu
I0625 11:56:05.374064  4216 net.cpp:774] Copying source layer pool1
I0625 11:56:05.374065  4216 net.cpp:774] Copying source layer pool1_pool1_0_split
I0625 11:56:05.374068  4216 net.cpp:774] Copying source layer res2a_branch1
I0625 11:56:05.374194  4216 net.cpp:774] Copying source layer bn2a_branch1
I0625 11:56:05.374217  4216 net.cpp:774] Copying source layer scale2a_branch1
I0625 11:56:05.374224  4216 net.cpp:774] Copying source layer res2a_branch2a
I0625 11:56:05.374255  4216 net.cpp:774] Copying source layer bn2a_branch2a
I0625 11:56:05.374261  4216 net.cpp:774] Copying source layer scale2a_branch2a
I0625 11:56:05.374266  4216 net.cpp:774] Copying source layer res2a_branch2a_relu
I0625 11:56:05.374269  4216 net.cpp:774] Copying source layer res2a_branch2b
I0625 11:56:05.374531  4216 net.cpp:774] Copying source layer bn2a_branch2b
I0625 11:56:05.374537  4216 net.cpp:774] Copying source layer scale2a_branch2b
I0625 11:56:05.374557  4216 net.cpp:774] Copying source layer res2a_branch2b_relu
I0625 11:56:05.374558  4216 net.cpp:774] Copying source layer res2a_branch2c
I0625 11:56:05.374673  4216 net.cpp:774] Copying source layer bn2a_branch2c
I0625 11:56:05.374682  4216 net.cpp:774] Copying source layer scale2a_branch2c
I0625 11:56:05.374691  4216 net.cpp:774] Copying source layer res2a
I0625 11:56:05.374692  4216 net.cpp:774] Copying source layer res2a_relu
I0625 11:56:05.374694  4216 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0625 11:56:05.374696  4216 net.cpp:774] Copying source layer res2b_branch2a
I0625 11:56:05.374824  4216 net.cpp:774] Copying source layer bn2b_branch2a
I0625 11:56:05.374830  4216 net.cpp:774] Copying source layer scale2b_branch2a
I0625 11:56:05.374850  4216 net.cpp:774] Copying source layer res2b_branch2a_relu
I0625 11:56:05.374851  4216 net.cpp:774] Copying source layer res2b_branch2b
I0625 11:56:05.375140  4216 net.cpp:774] Copying source layer bn2b_branch2b
I0625 11:56:05.375149  4216 net.cpp:774] Copying source layer scale2b_branch2b
I0625 11:56:05.375154  4216 net.cpp:774] Copying source layer res2b_branch2b_relu
I0625 11:56:05.375156  4216 net.cpp:774] Copying source layer res2b_branch2c
I0625 11:56:05.375272  4216 net.cpp:774] Copying source layer bn2b_branch2c
I0625 11:56:05.375282  4216 net.cpp:774] Copying source layer scale2b_branch2c
I0625 11:56:05.375289  4216 net.cpp:774] Copying source layer res2b
I0625 11:56:05.375293  4216 net.cpp:774] Copying source layer res2b_relu
I0625 11:56:05.375294  4216 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0625 11:56:05.375296  4216 net.cpp:774] Copying source layer res2c_branch2a
I0625 11:56:05.375411  4216 net.cpp:774] Copying source layer bn2c_branch2a
I0625 11:56:05.375418  4216 net.cpp:774] Copying source layer scale2c_branch2a
I0625 11:56:05.375423  4216 net.cpp:774] Copying source layer res2c_branch2a_relu
I0625 11:56:05.375427  4216 net.cpp:774] Copying source layer res2c_branch2b
I0625 11:56:05.375681  4216 net.cpp:774] Copying source layer bn2c_branch2b
I0625 11:56:05.375689  4216 net.cpp:774] Copying source layer scale2c_branch2b
I0625 11:56:05.375694  4216 net.cpp:774] Copying source layer res2c_branch2b_relu
I0625 11:56:05.375696  4216 net.cpp:774] Copying source layer res2c_branch2c
I0625 11:56:05.375813  4216 net.cpp:774] Copying source layer bn2c_branch2c
I0625 11:56:05.375823  4216 net.cpp:774] Copying source layer scale2c_branch2c
I0625 11:56:05.375830  4216 net.cpp:774] Copying source layer res2c
I0625 11:56:05.375833  4216 net.cpp:774] Copying source layer res2c_relu
I0625 11:56:05.375835  4216 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0625 11:56:05.375838  4216 net.cpp:774] Copying source layer res3a_branch1
I0625 11:56:05.376735  4216 net.cpp:774] Copying source layer bn3a_branch1
I0625 11:56:05.376749  4216 net.cpp:774] Copying source layer scale3a_branch1
I0625 11:56:05.376762  4216 net.cpp:774] Copying source layer res3a_branch2a
I0625 11:56:05.376991  4216 net.cpp:774] Copying source layer bn3a_branch2a
I0625 11:56:05.376999  4216 net.cpp:774] Copying source layer scale3a_branch2a
I0625 11:56:05.377005  4216 net.cpp:774] Copying source layer res3a_branch2a_relu
I0625 11:56:05.377008  4216 net.cpp:774] Copying source layer res3a_branch2b
I0625 11:56:05.378018  4216 net.cpp:774] Copying source layer bn3a_branch2b
I0625 11:56:05.378027  4216 net.cpp:774] Copying source layer scale3a_branch2b
I0625 11:56:05.378034  4216 net.cpp:774] Copying source layer res3a_branch2b_relu
I0625 11:56:05.378036  4216 net.cpp:774] Copying source layer res3a_branch2c
I0625 11:56:05.378495  4216 net.cpp:774] Copying source layer bn3a_branch2c
I0625 11:56:05.378523  4216 net.cpp:774] Copying source layer scale3a_branch2c
I0625 11:56:05.378536  4216 net.cpp:774] Copying source layer res3a
I0625 11:56:05.378538  4216 net.cpp:774] Copying source layer res3a_relu
I0625 11:56:05.378541  4216 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0625 11:56:05.378545  4216 net.cpp:774] Copying source layer res3b_branch2a
I0625 11:56:05.379024  4216 net.cpp:774] Copying source layer bn3b_branch2a
I0625 11:56:05.379047  4216 net.cpp:774] Copying source layer scale3b_branch2a
I0625 11:56:05.379055  4216 net.cpp:774] Copying source layer res3b_branch2a_relu
I0625 11:56:05.379056  4216 net.cpp:774] Copying source layer res3b_branch2b
I0625 11:56:05.380120  4216 net.cpp:774] Copying source layer bn3b_branch2b
I0625 11:56:05.380141  4216 net.cpp:774] Copying source layer scale3b_branch2b
I0625 11:56:05.380148  4216 net.cpp:774] Copying source layer res3b_branch2b_relu
I0625 11:56:05.380151  4216 net.cpp:774] Copying source layer res3b_branch2c
I0625 11:56:05.380609  4216 net.cpp:774] Copying source layer bn3b_branch2c
I0625 11:56:05.380636  4216 net.cpp:774] Copying source layer scale3b_branch2c
I0625 11:56:05.380650  4216 net.cpp:774] Copying source layer res3b
I0625 11:56:05.380652  4216 net.cpp:774] Copying source layer res3b_relu
I0625 11:56:05.380656  4216 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0625 11:56:05.380658  4216 net.cpp:774] Copying source layer res3c_branch2a
I0625 11:56:05.381114  4216 net.cpp:774] Copying source layer bn3c_branch2a
I0625 11:56:05.381137  4216 net.cpp:774] Copying source layer scale3c_branch2a
I0625 11:56:05.381145  4216 net.cpp:774] Copying source layer res3c_branch2a_relu
I0625 11:56:05.381146  4216 net.cpp:774] Copying source layer res3c_branch2b
I0625 11:56:05.382149  4216 net.cpp:774] Copying source layer bn3c_branch2b
I0625 11:56:05.382172  4216 net.cpp:774] Copying source layer scale3c_branch2b
I0625 11:56:05.382179  4216 net.cpp:774] Copying source layer res3c_branch2b_relu
I0625 11:56:05.382184  4216 net.cpp:774] Copying source layer res3c_branch2c
I0625 11:56:05.382640  4216 net.cpp:774] Copying source layer bn3c_branch2c
I0625 11:56:05.382668  4216 net.cpp:774] Copying source layer scale3c_branch2c
I0625 11:56:05.382681  4216 net.cpp:774] Copying source layer res3c
I0625 11:56:05.382685  4216 net.cpp:774] Copying source layer res3c_relu
I0625 11:56:05.382688  4216 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0625 11:56:05.382691  4216 net.cpp:774] Copying source layer res3d_branch2a
I0625 11:56:05.383152  4216 net.cpp:774] Copying source layer bn3d_branch2a
I0625 11:56:05.383174  4216 net.cpp:774] Copying source layer scale3d_branch2a
I0625 11:56:05.383183  4216 net.cpp:774] Copying source layer res3d_branch2a_relu
I0625 11:56:05.383185  4216 net.cpp:774] Copying source layer res3d_branch2b
I0625 11:56:05.384186  4216 net.cpp:774] Copying source layer bn3d_branch2b
I0625 11:56:05.384196  4216 net.cpp:774] Copying source layer scale3d_branch2b
I0625 11:56:05.384217  4216 net.cpp:774] Copying source layer res3d_branch2b_relu
I0625 11:56:05.384219  4216 net.cpp:774] Copying source layer res3d_branch2c
I0625 11:56:05.384671  4216 net.cpp:774] Copying source layer bn3d_branch2c
I0625 11:56:05.384685  4216 net.cpp:774] Copying source layer scale3d_branch2c
I0625 11:56:05.384698  4216 net.cpp:774] Copying source layer res3d
I0625 11:56:05.384701  4216 net.cpp:774] Copying source layer res3d_relu
I0625 11:56:05.384704  4216 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0625 11:56:05.384707  4216 net.cpp:774] Copying source layer res4a_branch1
I0625 11:56:05.388340  4216 net.cpp:774] Copying source layer bn4a_branch1
I0625 11:56:05.388386  4216 net.cpp:774] Copying source layer scale4a_branch1
I0625 11:56:05.388406  4216 net.cpp:774] Copying source layer res4a_branch2a
I0625 11:56:05.389299  4216 net.cpp:774] Copying source layer bn4a_branch2a
I0625 11:56:05.389312  4216 net.cpp:774] Copying source layer scale4a_branch2a
I0625 11:56:05.389334  4216 net.cpp:774] Copying source layer res4a_branch2a_relu
I0625 11:56:05.389338  4216 net.cpp:774] Copying source layer res4a_branch2b
I0625 11:56:05.393337  4216 net.cpp:774] Copying source layer bn4a_branch2b
I0625 11:56:05.393352  4216 net.cpp:774] Copying source layer scale4a_branch2b
I0625 11:56:05.393376  4216 net.cpp:774] Copying source layer res4a_branch2b_relu
I0625 11:56:05.393379  4216 net.cpp:774] Copying source layer res4a_branch2c
I0625 11:56:05.395207  4216 net.cpp:774] Copying source layer bn4a_branch2c
I0625 11:56:05.395242  4216 net.cpp:774] Copying source layer scale4a_branch2c
I0625 11:56:05.395262  4216 net.cpp:774] Copying source layer res4a
I0625 11:56:05.395265  4216 net.cpp:774] Copying source layer res4a_relu
I0625 11:56:05.395269  4216 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0625 11:56:05.395272  4216 net.cpp:774] Copying source layer res4b_branch2a
I0625 11:56:05.397064  4216 net.cpp:774] Copying source layer bn4b_branch2a
I0625 11:56:05.397076  4216 net.cpp:774] Copying source layer scale4b_branch2a
I0625 11:56:05.397086  4216 net.cpp:774] Copying source layer res4b_branch2a_relu
I0625 11:56:05.397090  4216 net.cpp:774] Copying source layer res4b_branch2b
I0625 11:56:05.401140  4216 net.cpp:774] Copying source layer bn4b_branch2b
I0625 11:56:05.401157  4216 net.cpp:774] Copying source layer scale4b_branch2b
I0625 11:56:05.401167  4216 net.cpp:774] Copying source layer res4b_branch2b_relu
I0625 11:56:05.401172  4216 net.cpp:774] Copying source layer res4b_branch2c
I0625 11:56:05.402967  4216 net.cpp:774] Copying source layer bn4b_branch2c
I0625 11:56:05.402990  4216 net.cpp:774] Copying source layer scale4b_branch2c
I0625 11:56:05.403012  4216 net.cpp:774] Copying source layer res4b
I0625 11:56:05.403015  4216 net.cpp:774] Copying source layer res4b_relu
I0625 11:56:05.403019  4216 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0625 11:56:05.403023  4216 net.cpp:774] Copying source layer res4c_branch2a
I0625 11:56:05.404815  4216 net.cpp:774] Copying source layer bn4c_branch2a
I0625 11:56:05.404827  4216 net.cpp:774] Copying source layer scale4c_branch2a
I0625 11:56:05.404837  4216 net.cpp:774] Copying source layer res4c_branch2a_relu
I0625 11:56:05.404841  4216 net.cpp:774] Copying source layer res4c_branch2b
I0625 11:56:05.408870  4216 net.cpp:774] Copying source layer bn4c_branch2b
I0625 11:56:05.408885  4216 net.cpp:774] Copying source layer scale4c_branch2b
I0625 11:56:05.408895  4216 net.cpp:774] Copying source layer res4c_branch2b_relu
I0625 11:56:05.408898  4216 net.cpp:774] Copying source layer res4c_branch2c
I0625 11:56:05.410691  4216 net.cpp:774] Copying source layer bn4c_branch2c
I0625 11:56:05.410714  4216 net.cpp:774] Copying source layer scale4c_branch2c
I0625 11:56:05.410734  4216 net.cpp:774] Copying source layer res4c
I0625 11:56:05.410738  4216 net.cpp:774] Copying source layer res4c_relu
I0625 11:56:05.410743  4216 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0625 11:56:05.410748  4216 net.cpp:774] Copying source layer res4d_branch2a
I0625 11:56:05.412542  4216 net.cpp:774] Copying source layer bn4d_branch2a
I0625 11:56:05.412554  4216 net.cpp:774] Copying source layer scale4d_branch2a
I0625 11:56:05.412564  4216 net.cpp:774] Copying source layer res4d_branch2a_relu
I0625 11:56:05.412569  4216 net.cpp:774] Copying source layer res4d_branch2b
I0625 11:56:05.416585  4216 net.cpp:774] Copying source layer bn4d_branch2b
I0625 11:56:05.416599  4216 net.cpp:774] Copying source layer scale4d_branch2b
I0625 11:56:05.416623  4216 net.cpp:774] Copying source layer res4d_branch2b_relu
I0625 11:56:05.416627  4216 net.cpp:774] Copying source layer res4d_branch2c
I0625 11:56:05.418396  4216 net.cpp:774] Copying source layer bn4d_branch2c
I0625 11:56:05.418433  4216 net.cpp:774] Copying source layer scale4d_branch2c
I0625 11:56:05.418454  4216 net.cpp:774] Copying source layer res4d
I0625 11:56:05.418458  4216 net.cpp:774] Copying source layer res4d_relu
I0625 11:56:05.418462  4216 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0625 11:56:05.418467  4216 net.cpp:774] Copying source layer res4e_branch2a
I0625 11:56:05.420262  4216 net.cpp:774] Copying source layer bn4e_branch2a
I0625 11:56:05.420274  4216 net.cpp:774] Copying source layer scale4e_branch2a
I0625 11:56:05.420298  4216 net.cpp:774] Copying source layer res4e_branch2a_relu
I0625 11:56:05.420302  4216 net.cpp:774] Copying source layer res4e_branch2b
I0625 11:56:05.424690  4216 net.cpp:774] Copying source layer bn4e_branch2b
I0625 11:56:05.424726  4216 net.cpp:774] Copying source layer scale4e_branch2b
I0625 11:56:05.424736  4216 net.cpp:774] Copying source layer res4e_branch2b_relu
I0625 11:56:05.424741  4216 net.cpp:774] Copying source layer res4e_branch2c
I0625 11:56:05.426509  4216 net.cpp:774] Copying source layer bn4e_branch2c
I0625 11:56:05.426548  4216 net.cpp:774] Copying source layer scale4e_branch2c
I0625 11:56:05.426568  4216 net.cpp:774] Copying source layer res4e
I0625 11:56:05.426573  4216 net.cpp:774] Copying source layer res4e_relu
I0625 11:56:05.426576  4216 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0625 11:56:05.426580  4216 net.cpp:774] Copying source layer res4f_branch2a
I0625 11:56:05.428359  4216 net.cpp:774] Copying source layer bn4f_branch2a
I0625 11:56:05.428373  4216 net.cpp:774] Copying source layer scale4f_branch2a
I0625 11:56:05.428397  4216 net.cpp:774] Copying source layer res4f_branch2a_relu
I0625 11:56:05.428402  4216 net.cpp:774] Copying source layer res4f_branch2b
I0625 11:56:05.432461  4216 net.cpp:774] Copying source layer bn4f_branch2b
I0625 11:56:05.432480  4216 net.cpp:774] Copying source layer scale4f_branch2b
I0625 11:56:05.432492  4216 net.cpp:774] Copying source layer res4f_branch2b_relu
I0625 11:56:05.432497  4216 net.cpp:774] Copying source layer res4f_branch2c
I0625 11:56:05.434294  4216 net.cpp:774] Copying source layer bn4f_branch2c
I0625 11:56:05.434319  4216 net.cpp:774] Copying source layer scale4f_branch2c
I0625 11:56:05.434340  4216 net.cpp:774] Copying source layer res4f
I0625 11:56:05.434345  4216 net.cpp:774] Copying source layer res4f_relu
I0625 11:56:05.434350  4216 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0625 11:56:05.434355  4216 net.cpp:774] Copying source layer res5a_branch1
I0625 11:56:05.448680  4216 net.cpp:774] Copying source layer bn5a_branch1
I0625 11:56:05.448719  4216 net.cpp:774] Copying source layer scale5a_branch1
I0625 11:56:05.448755  4216 net.cpp:774] Copying source layer res5a_branch2a
I0625 11:56:05.452339  4216 net.cpp:774] Copying source layer bn5a_branch2a
I0625 11:56:05.452358  4216 net.cpp:774] Copying source layer scale5a_branch2a
I0625 11:56:05.452373  4216 net.cpp:774] Copying source layer res5a_branch2a_relu
I0625 11:56:05.452378  4216 net.cpp:774] Copying source layer res5a_branch2b
I0625 11:56:05.468438  4216 net.cpp:774] Copying source layer bn5a_branch2b
I0625 11:56:05.468484  4216 net.cpp:774] Copying source layer scale5a_branch2b
I0625 11:56:05.468500  4216 net.cpp:774] Copying source layer res5a_branch2b_relu
I0625 11:56:05.468505  4216 net.cpp:774] Copying source layer res5a_branch2c
I0625 11:56:05.475611  4216 net.cpp:774] Copying source layer bn5a_branch2c
I0625 11:56:05.475668  4216 net.cpp:774] Copying source layer scale5a_branch2c
I0625 11:56:05.475703  4216 net.cpp:774] Copying source layer res5a
I0625 11:56:05.475708  4216 net.cpp:774] Copying source layer res5a_relu
I0625 11:56:05.475713  4216 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0625 11:56:05.475718  4216 net.cpp:774] Copying source layer res5b_branch2a
I0625 11:56:05.482877  4216 net.cpp:774] Copying source layer bn5b_branch2a
I0625 11:56:05.482897  4216 net.cpp:774] Copying source layer scale5b_branch2a
I0625 11:56:05.482913  4216 net.cpp:774] Copying source layer res5b_branch2a_relu
I0625 11:56:05.482918  4216 net.cpp:774] Copying source layer res5b_branch2b
I0625 11:56:05.498972  4216 net.cpp:774] Copying source layer bn5b_branch2b
I0625 11:56:05.499019  4216 net.cpp:774] Copying source layer scale5b_branch2b
I0625 11:56:05.499035  4216 net.cpp:774] Copying source layer res5b_branch2b_relu
I0625 11:56:05.499040  4216 net.cpp:774] Copying source layer res5b_branch2c
I0625 11:56:05.506108  4216 net.cpp:774] Copying source layer bn5b_branch2c
I0625 11:56:05.506162  4216 net.cpp:774] Copying source layer scale5b_branch2c
I0625 11:56:05.506197  4216 net.cpp:774] Copying source layer res5b
I0625 11:56:05.506202  4216 net.cpp:774] Copying source layer res5b_relu
I0625 11:56:05.506208  4216 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0625 11:56:05.506212  4216 net.cpp:774] Copying source layer res5c_branch2a
I0625 11:56:05.513308  4216 net.cpp:774] Copying source layer bn5c_branch2a
I0625 11:56:05.513340  4216 net.cpp:774] Copying source layer scale5c_branch2a
I0625 11:56:05.513355  4216 net.cpp:774] Copying source layer res5c_branch2a_relu
I0625 11:56:05.513360  4216 net.cpp:774] Copying source layer res5c_branch2b
I0625 11:56:05.529327  4216 net.cpp:774] Copying source layer bn5c_branch2b
I0625 11:56:05.529347  4216 net.cpp:774] Copying source layer scale5c_branch2b
I0625 11:56:05.529362  4216 net.cpp:774] Copying source layer res5c_branch2b_relu
I0625 11:56:05.529367  4216 net.cpp:774] Copying source layer res5c_branch2c
I0625 11:56:05.536381  4216 net.cpp:774] Copying source layer bn5c_branch2c
I0625 11:56:05.536435  4216 net.cpp:774] Copying source layer scale5c_branch2c
I0625 11:56:05.536470  4216 net.cpp:774] Copying source layer res5c
I0625 11:56:05.536475  4216 net.cpp:774] Copying source layer res5c_relu
I0625 11:56:05.536480  4216 net.cpp:771] Ignoring source layer pool5
I0625 11:56:05.536484  4216 net.cpp:771] Ignoring source layer fc1000
I0625 11:56:05.536489  4216 net.cpp:771] Ignoring source layer prob
Solving...
I0625 11:56:10.132596  4216 solver.cpp:228] Iteration 0, loss = 1.39479
I0625 11:56:10.132632  4216 solver.cpp:244]     Train net output #0: accuarcy = 0
I0625 11:56:10.132638  4216 solver.cpp:244]     Train net output #1: loss_bbox = 2.47733e-05 (* 1 = 2.47733e-05 loss)
I0625 11:56:10.132642  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.705372 (* 1 = 0.705372 loss)
I0625 11:56:10.132645  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.663276 (* 1 = 0.663276 loss)
I0625 11:56:10.132649  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408705 (* 1 = 0.0408705 loss)
I0625 11:56:10.132653  4216 sgd_solver.cpp:106] Iteration 0, lr = 0.0002
I0625 11:57:47.423784  4216 solver.cpp:228] Iteration 20, loss = 1.23938
I0625 11:57:47.423820  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 11:57:47.423827  4216 solver.cpp:244]     Train net output #1: loss_bbox = 1.83296e-05 (* 1 = 1.83296e-05 loss)
I0625 11:57:47.423831  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.680242 (* 1 = 0.680242 loss)
I0625 11:57:47.423835  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.522252 (* 1 = 0.522252 loss)
I0625 11:57:47.423837  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0744791 (* 1 = 0.0744791 loss)
I0625 11:57:47.423842  4216 sgd_solver.cpp:106] Iteration 20, lr = 0.0002
I0625 11:59:24.881764  4216 solver.cpp:228] Iteration 40, loss = 1.07364
I0625 11:59:24.881803  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 11:59:24.881809  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333679 (* 1 = 0.0333679 loss)
I0625 11:59:24.881814  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.648694 (* 1 = 0.648694 loss)
I0625 11:59:24.881816  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.390512 (* 1 = 0.390512 loss)
I0625 11:59:24.881820  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.176051 (* 1 = 0.176051 loss)
I0625 11:59:24.881824  4216 sgd_solver.cpp:106] Iteration 40, lr = 0.0002
I0625 12:01:02.834759  4216 solver.cpp:228] Iteration 60, loss = 0.833424
I0625 12:01:02.834796  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:01:02.834803  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000138589 (* 1 = 0.000138589 loss)
I0625 12:01:02.834806  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.610781 (* 1 = 0.610781 loss)
I0625 12:01:02.834810  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.179038 (* 1 = 0.179038 loss)
I0625 12:01:02.834813  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00734033 (* 1 = 0.00734033 loss)
I0625 12:01:02.834818  4216 sgd_solver.cpp:106] Iteration 60, lr = 0.0002
I0625 12:02:41.140077  4216 solver.cpp:228] Iteration 80, loss = 0.746466
I0625 12:02:41.140113  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:02:41.140120  4216 solver.cpp:244]     Train net output #1: loss_bbox = 9.05481e-05 (* 1 = 9.05481e-05 loss)
I0625 12:02:41.140125  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.582101 (* 1 = 0.582101 loss)
I0625 12:02:41.140127  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.113883 (* 1 = 0.113883 loss)
I0625 12:02:41.140131  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00814583 (* 1 = 0.00814583 loss)
I0625 12:02:41.140136  4216 sgd_solver.cpp:106] Iteration 80, lr = 0.0002
I0625 12:04:19.576999  4216 solver.cpp:228] Iteration 100, loss = 0.667535
I0625 12:04:19.577021  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 12:04:19.577029  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00023006 (* 1 = 0.00023006 loss)
I0625 12:04:19.577035  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.56147 (* 1 = 0.56147 loss)
I0625 12:04:19.577039  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.132272 (* 1 = 0.132272 loss)
I0625 12:04:19.577044  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127092 (* 1 = 0.127092 loss)
I0625 12:04:19.577049  4216 sgd_solver.cpp:106] Iteration 100, lr = 0.0002
I0625 12:05:58.288188  4216 solver.cpp:228] Iteration 120, loss = 0.428665
I0625 12:05:58.288226  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 12:05:58.288233  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000297746 (* 1 = 0.000297746 loss)
I0625 12:05:58.288236  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.354014 (* 1 = 0.354014 loss)
I0625 12:05:58.288239  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.102714 (* 1 = 0.102714 loss)
I0625 12:05:58.288244  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.091089 (* 1 = 0.091089 loss)
I0625 12:05:58.288247  4216 sgd_solver.cpp:106] Iteration 120, lr = 0.0002
I0625 12:07:37.105962  4216 solver.cpp:228] Iteration 140, loss = 0.260525
I0625 12:07:37.105998  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:07:37.106005  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000423752 (* 1 = 0.000423752 loss)
I0625 12:07:37.106009  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108412 (* 1 = 0.108412 loss)
I0625 12:07:37.106012  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0490497 (* 1 = 0.0490497 loss)
I0625 12:07:37.106016  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0661138 (* 1 = 0.0661138 loss)
I0625 12:07:37.106020  4216 sgd_solver.cpp:106] Iteration 140, lr = 0.0002
I0625 12:09:16.008975  4216 solver.cpp:228] Iteration 160, loss = 0.203127
I0625 12:09:16.009011  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:09:16.009018  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000172557 (* 1 = 0.000172557 loss)
I0625 12:09:16.009022  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0627225 (* 1 = 0.0627225 loss)
I0625 12:09:16.009025  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271864 (* 1 = 0.0271864 loss)
I0625 12:09:16.009029  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00886272 (* 1 = 0.00886272 loss)
I0625 12:09:16.009033  4216 sgd_solver.cpp:106] Iteration 160, lr = 0.0002
I0625 12:10:54.917661  4216 solver.cpp:228] Iteration 180, loss = 0.333042
I0625 12:10:54.917685  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 12:10:54.917695  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00059932 (* 1 = 0.00059932 loss)
I0625 12:10:54.917713  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.157692 (* 1 = 0.157692 loss)
I0625 12:10:54.917719  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0904304 (* 1 = 0.0904304 loss)
I0625 12:10:54.917724  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.123569 (* 1 = 0.123569 loss)
I0625 12:10:54.917731  4216 sgd_solver.cpp:106] Iteration 180, lr = 0.0002
speed: 4.920s / iter
I0625 12:12:34.134424  4216 solver.cpp:228] Iteration 200, loss = 0.190234
I0625 12:12:34.134449  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 12:12:34.134454  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0290247 (* 1 = 0.0290247 loss)
I0625 12:12:34.134459  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.135896 (* 1 = 0.135896 loss)
I0625 12:12:34.134461  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.063137 (* 1 = 0.063137 loss)
I0625 12:12:34.134464  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.060051 (* 1 = 0.060051 loss)
I0625 12:12:34.134469  4216 sgd_solver.cpp:106] Iteration 200, lr = 0.0002
I0625 12:14:12.982795  4216 solver.cpp:228] Iteration 220, loss = 0.21039
I0625 12:14:12.982834  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 12:14:12.982843  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511779 (* 1 = 0.0511779 loss)
I0625 12:14:12.982848  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.175009 (* 1 = 0.175009 loss)
I0625 12:14:12.982853  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0575056 (* 1 = 0.0575056 loss)
I0625 12:14:12.982862  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301739 (* 1 = 0.0301739 loss)
I0625 12:14:12.982869  4216 sgd_solver.cpp:106] Iteration 220, lr = 0.0002
I0625 12:15:52.095721  4216 solver.cpp:228] Iteration 240, loss = 0.203065
I0625 12:15:52.095757  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 12:15:52.095765  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703344 (* 1 = 0.0703344 loss)
I0625 12:15:52.095768  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.330222 (* 1 = 0.330222 loss)
I0625 12:15:52.095772  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103505 (* 1 = 0.103505 loss)
I0625 12:15:52.095775  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101196 (* 1 = 0.101196 loss)
I0625 12:15:52.095779  4216 sgd_solver.cpp:106] Iteration 240, lr = 0.0002
I0625 12:17:31.251152  4216 solver.cpp:228] Iteration 260, loss = 0.176386
I0625 12:17:31.251176  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 12:17:31.251183  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0768003 (* 1 = 0.0768003 loss)
I0625 12:17:31.251188  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.165872 (* 1 = 0.165872 loss)
I0625 12:17:31.251190  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0527579 (* 1 = 0.0527579 loss)
I0625 12:17:31.251194  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402332 (* 1 = 0.0402332 loss)
I0625 12:17:31.251197  4216 sgd_solver.cpp:106] Iteration 260, lr = 0.0002
I0625 12:19:10.530983  4216 solver.cpp:228] Iteration 280, loss = 0.210949
I0625 12:19:10.531021  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:19:10.531028  4216 solver.cpp:244]     Train net output #1: loss_bbox = 6.75951e-05 (* 1 = 6.75951e-05 loss)
I0625 12:19:10.531033  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0604203 (* 1 = 0.0604203 loss)
I0625 12:19:10.531035  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021689 (* 1 = 0.021689 loss)
I0625 12:19:10.531038  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00596093 (* 1 = 0.00596093 loss)
I0625 12:19:10.531042  4216 sgd_solver.cpp:106] Iteration 280, lr = 0.0002
I0625 12:20:50.045469  4216 solver.cpp:228] Iteration 300, loss = 0.279055
I0625 12:20:50.045495  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 12:20:50.045505  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0710193 (* 1 = 0.0710193 loss)
I0625 12:20:50.045511  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.246365 (* 1 = 0.246365 loss)
I0625 12:20:50.045516  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.045843 (* 1 = 0.045843 loss)
I0625 12:20:50.045521  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262583 (* 1 = 0.0262583 loss)
I0625 12:20:50.045527  4216 sgd_solver.cpp:106] Iteration 300, lr = 0.0002
I0625 12:22:29.811008  4216 solver.cpp:228] Iteration 320, loss = 0.383638
I0625 12:22:29.811031  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:22:29.811038  4216 solver.cpp:244]     Train net output #1: loss_bbox = 2.50095e-05 (* 1 = 2.50095e-05 loss)
I0625 12:22:29.811043  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0916049 (* 1 = 0.0916049 loss)
I0625 12:22:29.811048  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0277756 (* 1 = 0.0277756 loss)
I0625 12:22:29.811053  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110284 (* 1 = 0.0110284 loss)
I0625 12:22:29.811060  4216 sgd_solver.cpp:106] Iteration 320, lr = 0.0002
I0625 12:24:09.338946  4216 solver.cpp:228] Iteration 340, loss = 0.46787
I0625 12:24:09.338995  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:24:09.339002  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251023 (* 1 = 0.0251023 loss)
I0625 12:24:09.339006  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0670245 (* 1 = 0.0670245 loss)
I0625 12:24:09.339010  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188924 (* 1 = 0.0188924 loss)
I0625 12:24:09.339012  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188625 (* 1 = 0.0188625 loss)
I0625 12:24:09.339017  4216 sgd_solver.cpp:106] Iteration 340, lr = 0.0002
I0625 12:25:48.985411  4216 solver.cpp:228] Iteration 360, loss = 0.410615
I0625 12:25:48.985435  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 12:25:48.985440  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.18741 (* 1 = 0.18741 loss)
I0625 12:25:48.985445  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.420139 (* 1 = 0.420139 loss)
I0625 12:25:48.985447  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0741925 (* 1 = 0.0741925 loss)
I0625 12:25:48.985451  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0841078 (* 1 = 0.0841078 loss)
I0625 12:25:48.985455  4216 sgd_solver.cpp:106] Iteration 360, lr = 0.0002
I0625 12:27:28.626899  4216 solver.cpp:228] Iteration 380, loss = 0.588714
I0625 12:27:28.626921  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 12:27:28.626929  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00375484 (* 1 = 0.00375484 loss)
I0625 12:27:28.626933  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.114576 (* 1 = 0.114576 loss)
I0625 12:27:28.626936  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293635 (* 1 = 0.0293635 loss)
I0625 12:27:28.626940  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191415 (* 1 = 0.0191415 loss)
I0625 12:27:28.626945  4216 sgd_solver.cpp:106] Iteration 380, lr = 0.0002
speed: 4.945s / iter
I0625 12:29:08.066471  4216 solver.cpp:228] Iteration 400, loss = 0.237629
I0625 12:29:08.066509  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:29:08.066516  4216 solver.cpp:244]     Train net output #1: loss_bbox = 4.31029e-05 (* 1 = 4.31029e-05 loss)
I0625 12:29:08.066520  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0621723 (* 1 = 0.0621723 loss)
I0625 12:29:08.066524  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169313 (* 1 = 0.0169313 loss)
I0625 12:29:08.066527  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177916 (* 1 = 0.0177916 loss)
I0625 12:29:08.066532  4216 sgd_solver.cpp:106] Iteration 400, lr = 0.0002
I0625 12:30:47.751456  4216 solver.cpp:228] Iteration 420, loss = 0.234983
I0625 12:30:47.751478  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:30:47.751487  4216 solver.cpp:244]     Train net output #1: loss_bbox = 8.32176e-05 (* 1 = 8.32176e-05 loss)
I0625 12:30:47.751490  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0522807 (* 1 = 0.0522807 loss)
I0625 12:30:47.751494  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189488 (* 1 = 0.0189488 loss)
I0625 12:30:47.751497  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342368 (* 1 = 0.0342368 loss)
I0625 12:30:47.751502  4216 sgd_solver.cpp:106] Iteration 420, lr = 0.0002
I0625 12:32:27.765035  4216 solver.cpp:228] Iteration 440, loss = 0.303854
I0625 12:32:27.765072  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 12:32:27.765079  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0469995 (* 1 = 0.0469995 loss)
I0625 12:32:27.765082  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.142892 (* 1 = 0.142892 loss)
I0625 12:32:27.765085  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0345498 (* 1 = 0.0345498 loss)
I0625 12:32:27.765089  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.054226 (* 1 = 0.054226 loss)
I0625 12:32:27.765094  4216 sgd_solver.cpp:106] Iteration 440, lr = 0.0002
I0625 12:34:07.573509  4216 solver.cpp:228] Iteration 460, loss = 0.366035
I0625 12:34:07.573546  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 12:34:07.573554  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368746 (* 1 = 0.0368746 loss)
I0625 12:34:07.573556  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.10582 (* 1 = 0.10582 loss)
I0625 12:34:07.573560  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169591 (* 1 = 0.0169591 loss)
I0625 12:34:07.573563  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113351 (* 1 = 0.0113351 loss)
I0625 12:34:07.573568  4216 sgd_solver.cpp:106] Iteration 460, lr = 0.0002
I0625 12:35:47.734035  4216 solver.cpp:228] Iteration 480, loss = 0.325351
I0625 12:35:47.734058  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:35:47.734066  4216 solver.cpp:244]     Train net output #1: loss_bbox = 5.8532e-05 (* 1 = 5.8532e-05 loss)
I0625 12:35:47.734069  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0317177 (* 1 = 0.0317177 loss)
I0625 12:35:47.734072  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164237 (* 1 = 0.0164237 loss)
I0625 12:35:47.734076  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209952 (* 1 = 0.0209952 loss)
I0625 12:35:47.734081  4216 sgd_solver.cpp:106] Iteration 480, lr = 0.0002
I0625 12:37:27.753392  4216 solver.cpp:228] Iteration 500, loss = 0.364325
I0625 12:37:27.753415  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 12:37:27.753422  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0517278 (* 1 = 0.0517278 loss)
I0625 12:37:27.753428  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.130888 (* 1 = 0.130888 loss)
I0625 12:37:27.753433  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234832 (* 1 = 0.0234832 loss)
I0625 12:37:27.753437  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164576 (* 1 = 0.0164576 loss)
I0625 12:37:27.753443  4216 sgd_solver.cpp:106] Iteration 500, lr = 0.0002
I0625 12:39:07.743067  4216 solver.cpp:228] Iteration 520, loss = 0.558913
I0625 12:39:07.743103  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 12:39:07.743110  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430001 (* 1 = 0.0430001 loss)
I0625 12:39:07.743113  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.116153 (* 1 = 0.116153 loss)
I0625 12:39:07.743118  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137219 (* 1 = 0.0137219 loss)
I0625 12:39:07.743120  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00731252 (* 1 = 0.00731252 loss)
I0625 12:39:07.743124  4216 sgd_solver.cpp:106] Iteration 520, lr = 0.0002
I0625 12:40:47.581475  4216 solver.cpp:228] Iteration 540, loss = 0.460419
I0625 12:40:47.581514  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:40:47.581521  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244043 (* 1 = 0.0244043 loss)
I0625 12:40:47.581526  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0897395 (* 1 = 0.0897395 loss)
I0625 12:40:47.581528  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228763 (* 1 = 0.0228763 loss)
I0625 12:40:47.581532  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162814 (* 1 = 0.0162814 loss)
I0625 12:40:47.581537  4216 sgd_solver.cpp:106] Iteration 540, lr = 0.0002
I0625 12:42:27.415971  4216 solver.cpp:228] Iteration 560, loss = 0.275347
I0625 12:42:27.416007  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 12:42:27.416015  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0794732 (* 1 = 0.0794732 loss)
I0625 12:42:27.416019  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.22202 (* 1 = 0.22202 loss)
I0625 12:42:27.416023  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0258097 (* 1 = 0.0258097 loss)
I0625 12:42:27.416025  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160328 (* 1 = 0.0160328 loss)
I0625 12:42:27.416030  4216 sgd_solver.cpp:106] Iteration 560, lr = 0.0002
I0625 12:44:07.417044  4216 solver.cpp:228] Iteration 580, loss = 0.13707
I0625 12:44:07.417080  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:44:07.417088  4216 solver.cpp:244]     Train net output #1: loss_bbox = 1.33928e-05 (* 1 = 1.33928e-05 loss)
I0625 12:44:07.417093  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0522196 (* 1 = 0.0522196 loss)
I0625 12:44:07.417096  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124885 (* 1 = 0.0124885 loss)
I0625 12:44:07.417099  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199124 (* 1 = 0.0199124 loss)
I0625 12:44:07.417104  4216 sgd_solver.cpp:106] Iteration 580, lr = 0.0002
speed: 4.962s / iter
I0625 12:45:47.279639  4216 solver.cpp:228] Iteration 600, loss = 0.234423
I0625 12:45:47.279676  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:45:47.279682  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.015222 (* 1 = 0.015222 loss)
I0625 12:45:47.279686  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0796737 (* 1 = 0.0796737 loss)
I0625 12:45:47.279690  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012424 (* 1 = 0.012424 loss)
I0625 12:45:47.279693  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131378 (* 1 = 0.0131378 loss)
I0625 12:45:47.279697  4216 sgd_solver.cpp:106] Iteration 600, lr = 0.0002
I0625 12:47:27.172366  4216 solver.cpp:228] Iteration 620, loss = 0.472125
I0625 12:47:27.172389  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 12:47:27.172396  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104579 (* 1 = 0.104579 loss)
I0625 12:47:27.172400  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.232236 (* 1 = 0.232236 loss)
I0625 12:47:27.172403  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0352325 (* 1 = 0.0352325 loss)
I0625 12:47:27.172407  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176363 (* 1 = 0.0176363 loss)
I0625 12:47:27.172412  4216 sgd_solver.cpp:106] Iteration 620, lr = 0.0002
I0625 12:49:06.924844  4216 solver.cpp:228] Iteration 640, loss = 0.315441
I0625 12:49:06.924868  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 12:49:06.924876  4216 solver.cpp:244]     Train net output #1: loss_bbox = 5.14226e-05 (* 1 = 5.14226e-05 loss)
I0625 12:49:06.924880  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0632105 (* 1 = 0.0632105 loss)
I0625 12:49:06.924885  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0217886 (* 1 = 0.0217886 loss)
I0625 12:49:06.924887  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170186 (* 1 = 0.0170186 loss)
I0625 12:49:06.924892  4216 sgd_solver.cpp:106] Iteration 640, lr = 0.0002
I0625 12:50:46.651948  4216 solver.cpp:228] Iteration 660, loss = 0.538841
I0625 12:50:46.651969  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 12:50:46.651976  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.203016 (* 1 = 0.203016 loss)
I0625 12:50:46.651980  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.345936 (* 1 = 0.345936 loss)
I0625 12:50:46.651983  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378772 (* 1 = 0.0378772 loss)
I0625 12:50:46.651988  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0347589 (* 1 = 0.0347589 loss)
I0625 12:50:46.651990  4216 sgd_solver.cpp:106] Iteration 660, lr = 0.0002
I0625 12:52:26.316958  4216 solver.cpp:228] Iteration 680, loss = 0.398204
I0625 12:52:26.316996  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 12:52:26.317003  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0296137 (* 1 = 0.0296137 loss)
I0625 12:52:26.317008  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.10978 (* 1 = 0.10978 loss)
I0625 12:52:26.317010  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162153 (* 1 = 0.0162153 loss)
I0625 12:52:26.317014  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142837 (* 1 = 0.0142837 loss)
I0625 12:52:26.317018  4216 sgd_solver.cpp:106] Iteration 680, lr = 0.0002
I0625 12:54:05.757596  4216 solver.cpp:228] Iteration 700, loss = 0.318311
I0625 12:54:05.757633  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:54:05.757640  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00241071 (* 1 = 0.00241071 loss)
I0625 12:54:05.757644  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0891905 (* 1 = 0.0891905 loss)
I0625 12:54:05.757649  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134987 (* 1 = 0.0134987 loss)
I0625 12:54:05.757655  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00259643 (* 1 = 0.00259643 loss)
I0625 12:54:05.757660  4216 sgd_solver.cpp:106] Iteration 700, lr = 0.0002
I0625 12:55:45.081606  4216 solver.cpp:228] Iteration 720, loss = 0.380741
I0625 12:55:45.081629  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 12:55:45.081635  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000109449 (* 1 = 0.000109449 loss)
I0625 12:55:45.081640  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0900762 (* 1 = 0.0900762 loss)
I0625 12:55:45.081642  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262242 (* 1 = 0.0262242 loss)
I0625 12:55:45.081646  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319741 (* 1 = 0.0319741 loss)
I0625 12:55:45.081650  4216 sgd_solver.cpp:106] Iteration 720, lr = 0.0002
I0625 12:57:24.417407  4216 solver.cpp:228] Iteration 740, loss = 0.508134
I0625 12:57:24.417443  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 12:57:24.417449  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0184005 (* 1 = 0.0184005 loss)
I0625 12:57:24.417454  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129061 (* 1 = 0.129061 loss)
I0625 12:57:24.417456  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131198 (* 1 = 0.0131198 loss)
I0625 12:57:24.417460  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159342 (* 1 = 0.0159342 loss)
I0625 12:57:24.417464  4216 sgd_solver.cpp:106] Iteration 740, lr = 0.0002
I0625 12:59:03.785748  4216 solver.cpp:228] Iteration 760, loss = 0.501241
I0625 12:59:03.785771  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 12:59:03.785778  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0854604 (* 1 = 0.0854604 loss)
I0625 12:59:03.785782  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.348788 (* 1 = 0.348788 loss)
I0625 12:59:03.785785  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.115178 (* 1 = 0.115178 loss)
I0625 12:59:03.785789  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102147 (* 1 = 0.102147 loss)
I0625 12:59:03.785794  4216 sgd_solver.cpp:106] Iteration 760, lr = 0.0002
I0625 13:00:43.154902  4216 solver.cpp:228] Iteration 780, loss = 0.450477
I0625 13:00:43.154925  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 13:00:43.154933  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0908657 (* 1 = 0.0908657 loss)
I0625 13:00:43.154937  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.238851 (* 1 = 0.238851 loss)
I0625 13:00:43.154940  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0334625 (* 1 = 0.0334625 loss)
I0625 13:00:43.154944  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0484554 (* 1 = 0.0484554 loss)
I0625 13:00:43.154949  4216 sgd_solver.cpp:106] Iteration 780, lr = 0.0002
speed: 4.965s / iter
I0625 13:02:22.416957  4216 solver.cpp:228] Iteration 800, loss = 0.288235
I0625 13:02:22.416980  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 13:02:22.416986  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.113263 (* 1 = 0.113263 loss)
I0625 13:02:22.416990  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.343673 (* 1 = 0.343673 loss)
I0625 13:02:22.416993  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0531729 (* 1 = 0.0531729 loss)
I0625 13:02:22.416996  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0674007 (* 1 = 0.0674007 loss)
I0625 13:02:22.417001  4216 sgd_solver.cpp:106] Iteration 800, lr = 0.0002
I0625 13:04:01.536440  4216 solver.cpp:228] Iteration 820, loss = 0.489385
I0625 13:04:01.536463  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 13:04:01.536470  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0660026 (* 1 = 0.0660026 loss)
I0625 13:04:01.536474  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.212938 (* 1 = 0.212938 loss)
I0625 13:04:01.536478  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133929 (* 1 = 0.0133929 loss)
I0625 13:04:01.536483  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00752733 (* 1 = 0.00752733 loss)
I0625 13:04:01.536486  4216 sgd_solver.cpp:106] Iteration 820, lr = 0.0002
I0625 13:05:40.893532  4216 solver.cpp:228] Iteration 840, loss = 0.461962
I0625 13:05:40.893569  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 13:05:40.893576  4216 solver.cpp:244]     Train net output #1: loss_bbox = 4.07556e-05 (* 1 = 4.07556e-05 loss)
I0625 13:05:40.893580  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0559045 (* 1 = 0.0559045 loss)
I0625 13:05:40.893584  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0229288 (* 1 = 0.0229288 loss)
I0625 13:05:40.893587  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0474044 (* 1 = 0.0474044 loss)
I0625 13:05:40.893591  4216 sgd_solver.cpp:106] Iteration 840, lr = 0.0002
I0625 13:07:20.074812  4216 solver.cpp:228] Iteration 860, loss = 0.509076
I0625 13:07:20.074849  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0625 13:07:20.074857  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.299022 (* 1 = 0.299022 loss)
I0625 13:07:20.074864  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.677836 (* 1 = 0.677836 loss)
I0625 13:07:20.074867  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.203312 (* 1 = 0.203312 loss)
I0625 13:07:20.074870  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.240718 (* 1 = 0.240718 loss)
I0625 13:07:20.074875  4216 sgd_solver.cpp:106] Iteration 860, lr = 0.0002
I0625 13:08:59.499137  4216 solver.cpp:228] Iteration 880, loss = 0.279913
I0625 13:08:59.499161  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 13:08:59.499166  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340345 (* 1 = 0.0340345 loss)
I0625 13:08:59.499171  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.148191 (* 1 = 0.148191 loss)
I0625 13:08:59.499173  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0230214 (* 1 = 0.0230214 loss)
I0625 13:08:59.499176  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193347 (* 1 = 0.0193347 loss)
I0625 13:08:59.499181  4216 sgd_solver.cpp:106] Iteration 880, lr = 0.0002
I0625 13:10:38.832330  4216 solver.cpp:228] Iteration 900, loss = 0.221253
I0625 13:10:38.832355  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 13:10:38.832361  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00263595 (* 1 = 0.00263595 loss)
I0625 13:10:38.832365  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0847026 (* 1 = 0.0847026 loss)
I0625 13:10:38.832370  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144009 (* 1 = 0.0144009 loss)
I0625 13:10:38.832372  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205357 (* 1 = 0.0205357 loss)
I0625 13:10:38.832376  4216 sgd_solver.cpp:106] Iteration 900, lr = 0.0002
I0625 13:12:18.245096  4216 solver.cpp:228] Iteration 920, loss = 0.441851
I0625 13:12:18.245131  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 13:12:18.245138  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.017055 (* 1 = 0.017055 loss)
I0625 13:12:18.245141  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0798063 (* 1 = 0.0798063 loss)
I0625 13:12:18.245146  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129178 (* 1 = 0.0129178 loss)
I0625 13:12:18.245148  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012652 (* 1 = 0.012652 loss)
I0625 13:12:18.245152  4216 sgd_solver.cpp:106] Iteration 920, lr = 0.0002
I0625 13:13:57.471613  4216 solver.cpp:228] Iteration 940, loss = 0.37877
I0625 13:13:57.471652  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 13:13:57.471658  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206008 (* 1 = 0.0206008 loss)
I0625 13:13:57.471662  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0740964 (* 1 = 0.0740964 loss)
I0625 13:13:57.471664  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171866 (* 1 = 0.0171866 loss)
I0625 13:13:57.471668  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140296 (* 1 = 0.0140296 loss)
I0625 13:13:57.471673  4216 sgd_solver.cpp:106] Iteration 940, lr = 0.0002
I0625 13:15:36.824545  4216 solver.cpp:228] Iteration 960, loss = 0.476268
I0625 13:15:36.824581  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 13:15:36.824589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 3.30873e-05 (* 1 = 3.30873e-05 loss)
I0625 13:15:36.824592  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0684699 (* 1 = 0.0684699 loss)
I0625 13:15:36.824596  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0392796 (* 1 = 0.0392796 loss)
I0625 13:15:36.824599  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163016 (* 1 = 0.0163016 loss)
I0625 13:15:36.824604  4216 sgd_solver.cpp:106] Iteration 960, lr = 0.0002
I0625 13:17:16.303833  4216 solver.cpp:228] Iteration 980, loss = 0.352214
I0625 13:17:16.303854  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 13:17:16.303861  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.131253 (* 1 = 0.131253 loss)
I0625 13:17:16.303865  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.238136 (* 1 = 0.238136 loss)
I0625 13:17:16.303869  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125198 (* 1 = 0.0125198 loss)
I0625 13:17:16.303874  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00429178 (* 1 = 0.00429178 loss)
I0625 13:17:16.303877  4216 sgd_solver.cpp:106] Iteration 980, lr = 0.0002
speed: 4.966s / iter
I0625 13:18:55.844899  4216 solver.cpp:228] Iteration 1000, loss = 0.442403
I0625 13:18:55.844935  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 13:18:55.844943  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310407 (* 1 = 0.0310407 loss)
I0625 13:18:55.844946  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.12017 (* 1 = 0.12017 loss)
I0625 13:18:55.844949  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169181 (* 1 = 0.0169181 loss)
I0625 13:18:55.844954  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031122 (* 1 = 0.031122 loss)
I0625 13:18:55.844957  4216 sgd_solver.cpp:106] Iteration 1000, lr = 0.0002
I0625 13:20:35.329392  4216 solver.cpp:228] Iteration 1020, loss = 0.296305
I0625 13:20:35.329414  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 13:20:35.329421  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135739 (* 1 = 0.0135739 loss)
I0625 13:20:35.329425  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0677567 (* 1 = 0.0677567 loss)
I0625 13:20:35.329428  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133113 (* 1 = 0.0133113 loss)
I0625 13:20:35.329432  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102013 (* 1 = 0.0102013 loss)
I0625 13:20:35.329437  4216 sgd_solver.cpp:106] Iteration 1020, lr = 0.0002
I0625 13:22:14.687922  4216 solver.cpp:228] Iteration 1040, loss = 0.511648
I0625 13:22:14.687959  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 13:22:14.687966  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.125006 (* 1 = 0.125006 loss)
I0625 13:22:14.687970  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.273217 (* 1 = 0.273217 loss)
I0625 13:22:14.687973  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158859 (* 1 = 0.0158859 loss)
I0625 13:22:14.687976  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247975 (* 1 = 0.0247975 loss)
I0625 13:22:14.687981  4216 sgd_solver.cpp:106] Iteration 1040, lr = 0.0002
I0625 13:23:54.275662  4216 solver.cpp:228] Iteration 1060, loss = 0.496121
I0625 13:23:54.275686  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 13:23:54.275692  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00632583 (* 1 = 0.00632583 loss)
I0625 13:23:54.275697  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.131585 (* 1 = 0.131585 loss)
I0625 13:23:54.275701  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156177 (* 1 = 0.0156177 loss)
I0625 13:23:54.275704  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224056 (* 1 = 0.0224056 loss)
I0625 13:23:54.275708  4216 sgd_solver.cpp:106] Iteration 1060, lr = 0.0002
I0625 13:25:33.812113  4216 solver.cpp:228] Iteration 1080, loss = 0.435142
I0625 13:25:33.812139  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 13:25:33.812145  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609414 (* 1 = 0.0609414 loss)
I0625 13:25:33.812150  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.168791 (* 1 = 0.168791 loss)
I0625 13:25:33.812153  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759761 (* 1 = 0.00759761 loss)
I0625 13:25:33.812157  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229034 (* 1 = 0.0229034 loss)
I0625 13:25:33.812162  4216 sgd_solver.cpp:106] Iteration 1080, lr = 0.0002
I0625 13:27:13.310298  4216 solver.cpp:228] Iteration 1100, loss = 0.380127
I0625 13:27:13.310322  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 13:27:13.310328  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.117449 (* 1 = 0.117449 loss)
I0625 13:27:13.310333  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.178524 (* 1 = 0.178524 loss)
I0625 13:27:13.310336  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103383 (* 1 = 0.0103383 loss)
I0625 13:27:13.310339  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00636378 (* 1 = 0.00636378 loss)
I0625 13:27:13.310344  4216 sgd_solver.cpp:106] Iteration 1100, lr = 0.0002
I0625 13:28:52.914213  4216 solver.cpp:228] Iteration 1120, loss = 0.499513
I0625 13:28:52.914235  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 13:28:52.914254  4216 solver.cpp:244]     Train net output #1: loss_bbox = 5.07345e-05 (* 1 = 5.07345e-05 loss)
I0625 13:28:52.914273  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0576396 (* 1 = 0.0576396 loss)
I0625 13:28:52.914276  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147625 (* 1 = 0.0147625 loss)
I0625 13:28:52.914279  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177976 (* 1 = 0.0177976 loss)
I0625 13:28:52.914283  4216 sgd_solver.cpp:106] Iteration 1120, lr = 0.0002
I0625 13:30:32.283545  4216 solver.cpp:228] Iteration 1140, loss = 0.550496
I0625 13:30:32.283582  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 13:30:32.283589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000170942 (* 1 = 0.000170942 loss)
I0625 13:30:32.283592  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0665369 (* 1 = 0.0665369 loss)
I0625 13:30:32.283596  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018501 (* 1 = 0.018501 loss)
I0625 13:30:32.283599  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019126 (* 1 = 0.019126 loss)
I0625 13:30:32.283603  4216 sgd_solver.cpp:106] Iteration 1140, lr = 0.0002
I0625 13:32:11.740808  4216 solver.cpp:228] Iteration 1160, loss = 0.209622
I0625 13:32:11.740844  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 13:32:11.740850  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00291216 (* 1 = 0.00291216 loss)
I0625 13:32:11.740854  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0615439 (* 1 = 0.0615439 loss)
I0625 13:32:11.740857  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119881 (* 1 = 0.0119881 loss)
I0625 13:32:11.740861  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00438574 (* 1 = 0.00438574 loss)
I0625 13:32:11.740865  4216 sgd_solver.cpp:106] Iteration 1160, lr = 0.0002
I0625 13:33:51.359586  4216 solver.cpp:228] Iteration 1180, loss = 0.373421
I0625 13:33:51.359622  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 13:33:51.359628  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00026482 (* 1 = 0.00026482 loss)
I0625 13:33:51.359632  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0510312 (* 1 = 0.0510312 loss)
I0625 13:33:51.359635  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167491 (* 1 = 0.0167491 loss)
I0625 13:33:51.359639  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0079913 (* 1 = 0.0079913 loss)
I0625 13:33:51.359644  4216 sgd_solver.cpp:106] Iteration 1180, lr = 0.0002
speed: 4.967s / iter
I0625 13:35:31.015578  4216 solver.cpp:228] Iteration 1200, loss = 0.366817
I0625 13:35:31.015606  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 13:35:31.015614  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.013035 (* 1 = 0.013035 loss)
I0625 13:35:31.015619  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0623004 (* 1 = 0.0623004 loss)
I0625 13:35:31.015621  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127715 (* 1 = 0.0127715 loss)
I0625 13:35:31.015625  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00962484 (* 1 = 0.00962484 loss)
I0625 13:35:31.015630  4216 sgd_solver.cpp:106] Iteration 1200, lr = 0.0002
I0625 13:37:10.695217  4216 solver.cpp:228] Iteration 1220, loss = 0.421701
I0625 13:37:10.695255  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 13:37:10.695263  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121016 (* 1 = 0.121016 loss)
I0625 13:37:10.695268  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.296568 (* 1 = 0.296568 loss)
I0625 13:37:10.695272  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0225605 (* 1 = 0.0225605 loss)
I0625 13:37:10.695276  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0697643 (* 1 = 0.0697643 loss)
I0625 13:37:10.695282  4216 sgd_solver.cpp:106] Iteration 1220, lr = 0.0002
I0625 13:38:50.236814  4216 solver.cpp:228] Iteration 1240, loss = 0.590503
I0625 13:38:50.236851  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.617188
I0625 13:38:50.236858  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.428521 (* 1 = 0.428521 loss)
I0625 13:38:50.236862  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.805196 (* 1 = 0.805196 loss)
I0625 13:38:50.236865  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0503949 (* 1 = 0.0503949 loss)
I0625 13:38:50.236869  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105243 (* 1 = 0.105243 loss)
I0625 13:38:50.236873  4216 sgd_solver.cpp:106] Iteration 1240, lr = 0.0002
I0625 13:40:29.995225  4216 solver.cpp:228] Iteration 1260, loss = 0.458082
I0625 13:40:29.995249  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 13:40:29.995256  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0495571 (* 1 = 0.0495571 loss)
I0625 13:40:29.995260  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.178105 (* 1 = 0.178105 loss)
I0625 13:40:29.995265  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0249961 (* 1 = 0.0249961 loss)
I0625 13:40:29.995267  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433031 (* 1 = 0.0433031 loss)
I0625 13:40:29.995272  4216 sgd_solver.cpp:106] Iteration 1260, lr = 0.0002
I0625 13:42:09.668416  4216 solver.cpp:228] Iteration 1280, loss = 0.257958
I0625 13:42:09.668452  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 13:42:09.668459  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.183084 (* 1 = 0.183084 loss)
I0625 13:42:09.668463  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.481344 (* 1 = 0.481344 loss)
I0625 13:42:09.668467  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0859322 (* 1 = 0.0859322 loss)
I0625 13:42:09.668469  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.152362 (* 1 = 0.152362 loss)
I0625 13:42:09.668474  4216 sgd_solver.cpp:106] Iteration 1280, lr = 0.0002
I0625 13:43:49.305297  4216 solver.cpp:228] Iteration 1300, loss = 0.5168
I0625 13:43:49.305333  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 13:43:49.305341  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.261541 (* 1 = 0.261541 loss)
I0625 13:43:49.305344  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.400735 (* 1 = 0.400735 loss)
I0625 13:43:49.305347  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158187 (* 1 = 0.0158187 loss)
I0625 13:43:49.305351  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414857 (* 1 = 0.0414857 loss)
I0625 13:43:49.305356  4216 sgd_solver.cpp:106] Iteration 1300, lr = 0.0002
I0625 13:45:28.912994  4216 solver.cpp:228] Iteration 1320, loss = 0.328226
I0625 13:45:28.913017  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 13:45:28.913024  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.251546 (* 1 = 0.251546 loss)
I0625 13:45:28.913028  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.462507 (* 1 = 0.462507 loss)
I0625 13:45:28.913031  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0423201 (* 1 = 0.0423201 loss)
I0625 13:45:28.913035  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.062304 (* 1 = 0.062304 loss)
I0625 13:45:28.913040  4216 sgd_solver.cpp:106] Iteration 1320, lr = 0.0002
I0625 13:47:08.587219  4216 solver.cpp:228] Iteration 1340, loss = 0.474673
I0625 13:47:08.587245  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 13:47:08.587252  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00605469 (* 1 = 0.00605469 loss)
I0625 13:47:08.587257  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0554367 (* 1 = 0.0554367 loss)
I0625 13:47:08.587261  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759908 (* 1 = 0.00759908 loss)
I0625 13:47:08.587265  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00545434 (* 1 = 0.00545434 loss)
I0625 13:47:08.587270  4216 sgd_solver.cpp:106] Iteration 1340, lr = 0.0002
I0625 13:48:48.468180  4216 solver.cpp:228] Iteration 1360, loss = 0.290637
I0625 13:48:48.468216  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 13:48:48.468222  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198266 (* 1 = 0.0198266 loss)
I0625 13:48:48.468227  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0960863 (* 1 = 0.0960863 loss)
I0625 13:48:48.468230  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133964 (* 1 = 0.0133964 loss)
I0625 13:48:48.468233  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374782 (* 1 = 0.0374782 loss)
I0625 13:48:48.468237  4216 sgd_solver.cpp:106] Iteration 1360, lr = 0.0002
I0625 13:50:28.349313  4216 solver.cpp:228] Iteration 1380, loss = 0.533618
I0625 13:50:28.349336  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 13:50:28.349344  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839177 (* 1 = 0.0839177 loss)
I0625 13:50:28.349349  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.198179 (* 1 = 0.198179 loss)
I0625 13:50:28.349352  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00946752 (* 1 = 0.00946752 loss)
I0625 13:50:28.349355  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019902 (* 1 = 0.019902 loss)
I0625 13:50:28.349360  4216 sgd_solver.cpp:106] Iteration 1380, lr = 0.0002
speed: 4.970s / iter
I0625 13:52:08.500809  4216 solver.cpp:228] Iteration 1400, loss = 0.321176
I0625 13:52:08.500846  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 13:52:08.500852  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000191425 (* 1 = 0.000191425 loss)
I0625 13:52:08.500856  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0440064 (* 1 = 0.0440064 loss)
I0625 13:52:08.500859  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155305 (* 1 = 0.0155305 loss)
I0625 13:52:08.500864  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418932 (* 1 = 0.0418932 loss)
I0625 13:52:08.500867  4216 sgd_solver.cpp:106] Iteration 1400, lr = 0.0002
I0625 13:53:48.723712  4216 solver.cpp:228] Iteration 1420, loss = 0.502753
I0625 13:53:48.723736  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 13:53:48.723742  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466131 (* 1 = 0.0466131 loss)
I0625 13:53:48.723747  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108346 (* 1 = 0.108346 loss)
I0625 13:53:48.723750  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0064548 (* 1 = 0.0064548 loss)
I0625 13:53:48.723753  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197543 (* 1 = 0.0197543 loss)
I0625 13:53:48.723758  4216 sgd_solver.cpp:106] Iteration 1420, lr = 0.0002
I0625 13:55:28.767659  4216 solver.cpp:228] Iteration 1440, loss = 0.379815
I0625 13:55:28.767694  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 13:55:28.767702  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.176894 (* 1 = 0.176894 loss)
I0625 13:55:28.767706  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.260206 (* 1 = 0.260206 loss)
I0625 13:55:28.767709  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00731644 (* 1 = 0.00731644 loss)
I0625 13:55:28.767712  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013852 (* 1 = 0.013852 loss)
I0625 13:55:28.767717  4216 sgd_solver.cpp:106] Iteration 1440, lr = 0.0002
I0625 13:57:08.893123  4216 solver.cpp:228] Iteration 1460, loss = 0.585805
I0625 13:57:08.893146  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0625 13:57:08.893153  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.415824 (* 1 = 0.415824 loss)
I0625 13:57:08.893157  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.588013 (* 1 = 0.588013 loss)
I0625 13:57:08.893162  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208976 (* 1 = 0.0208976 loss)
I0625 13:57:08.893164  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0747979 (* 1 = 0.0747979 loss)
I0625 13:57:08.893169  4216 sgd_solver.cpp:106] Iteration 1460, lr = 0.0002
I0625 13:58:49.018275  4216 solver.cpp:228] Iteration 1480, loss = 0.573149
I0625 13:58:49.018312  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 13:58:49.018319  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.187624 (* 1 = 0.187624 loss)
I0625 13:58:49.018322  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.356691 (* 1 = 0.356691 loss)
I0625 13:58:49.018326  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170179 (* 1 = 0.0170179 loss)
I0625 13:58:49.018329  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0570468 (* 1 = 0.0570468 loss)
I0625 13:58:49.018333  4216 sgd_solver.cpp:106] Iteration 1480, lr = 0.0002
I0625 14:00:29.266525  4216 solver.cpp:228] Iteration 1500, loss = 0.295933
I0625 14:00:29.266547  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 14:00:29.266554  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0311296 (* 1 = 0.0311296 loss)
I0625 14:00:29.266558  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108061 (* 1 = 0.108061 loss)
I0625 14:00:29.266561  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00799727 (* 1 = 0.00799727 loss)
I0625 14:00:29.266566  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116813 (* 1 = 0.0116813 loss)
I0625 14:00:29.266569  4216 sgd_solver.cpp:106] Iteration 1500, lr = 0.0002
I0625 14:02:09.274166  4216 solver.cpp:228] Iteration 1520, loss = 0.366573
I0625 14:02:09.274204  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 14:02:09.274210  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203942 (* 1 = 0.0203942 loss)
I0625 14:02:09.274214  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0819849 (* 1 = 0.0819849 loss)
I0625 14:02:09.274217  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00924962 (* 1 = 0.00924962 loss)
I0625 14:02:09.274220  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142398 (* 1 = 0.0142398 loss)
I0625 14:02:09.274224  4216 sgd_solver.cpp:106] Iteration 1520, lr = 0.0002
I0625 14:03:49.343966  4216 solver.cpp:228] Iteration 1540, loss = 0.53457
I0625 14:03:49.344000  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 14:03:49.344007  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.047198 (* 1 = 0.047198 loss)
I0625 14:03:49.344012  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0919832 (* 1 = 0.0919832 loss)
I0625 14:03:49.344015  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00934938 (* 1 = 0.00934938 loss)
I0625 14:03:49.344018  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150159 (* 1 = 0.0150159 loss)
I0625 14:03:49.344023  4216 sgd_solver.cpp:106] Iteration 1540, lr = 0.0002
I0625 14:05:29.484187  4216 solver.cpp:228] Iteration 1560, loss = 0.419056
I0625 14:05:29.484210  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 14:05:29.484217  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.260986 (* 1 = 0.260986 loss)
I0625 14:05:29.484221  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.456761 (* 1 = 0.456761 loss)
I0625 14:05:29.484225  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0324057 (* 1 = 0.0324057 loss)
I0625 14:05:29.484228  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390672 (* 1 = 0.0390672 loss)
I0625 14:05:29.484233  4216 sgd_solver.cpp:106] Iteration 1560, lr = 0.0002
I0625 14:07:09.631953  4216 solver.cpp:228] Iteration 1580, loss = 0.485399
I0625 14:07:09.631991  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 14:07:09.631999  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0555366 (* 1 = 0.0555366 loss)
I0625 14:07:09.632004  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.18043 (* 1 = 0.18043 loss)
I0625 14:07:09.632009  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00730636 (* 1 = 0.00730636 loss)
I0625 14:07:09.632014  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155614 (* 1 = 0.0155614 loss)
I0625 14:07:09.632019  4216 sgd_solver.cpp:106] Iteration 1580, lr = 0.0002
speed: 4.975s / iter
I0625 14:08:49.782317  4216 solver.cpp:228] Iteration 1600, loss = 0.153956
I0625 14:08:49.782341  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:08:49.782348  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000266968 (* 1 = 0.000266968 loss)
I0625 14:08:49.782353  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0616323 (* 1 = 0.0616323 loss)
I0625 14:08:49.782356  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241876 (* 1 = 0.0241876 loss)
I0625 14:08:49.782361  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022121 (* 1 = 0.022121 loss)
I0625 14:08:49.782364  4216 sgd_solver.cpp:106] Iteration 1600, lr = 0.0002
I0625 14:10:29.828132  4216 solver.cpp:228] Iteration 1620, loss = 0.396946
I0625 14:10:29.828157  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 14:10:29.828166  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0869247 (* 1 = 0.0869247 loss)
I0625 14:10:29.828169  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.244748 (* 1 = 0.244748 loss)
I0625 14:10:29.828173  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123799 (* 1 = 0.0123799 loss)
I0625 14:10:29.828176  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292721 (* 1 = 0.0292721 loss)
I0625 14:10:29.828181  4216 sgd_solver.cpp:106] Iteration 1620, lr = 0.0002
I0625 14:12:09.660913  4216 solver.cpp:228] Iteration 1640, loss = 0.369085
I0625 14:12:09.660950  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 14:12:09.660959  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359576 (* 1 = 0.0359576 loss)
I0625 14:12:09.660962  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.107185 (* 1 = 0.107185 loss)
I0625 14:12:09.660965  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00735541 (* 1 = 0.00735541 loss)
I0625 14:12:09.660969  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346542 (* 1 = 0.0346542 loss)
I0625 14:12:09.660974  4216 sgd_solver.cpp:106] Iteration 1640, lr = 0.0002
I0625 14:13:49.714362  4216 solver.cpp:228] Iteration 1660, loss = 0.398904
I0625 14:13:49.714386  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:13:49.714395  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000345972 (* 1 = 0.000345972 loss)
I0625 14:13:49.714398  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0491572 (* 1 = 0.0491572 loss)
I0625 14:13:49.714401  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160453 (* 1 = 0.0160453 loss)
I0625 14:13:49.714406  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942985 (* 1 = 0.00942985 loss)
I0625 14:13:49.714411  4216 sgd_solver.cpp:106] Iteration 1660, lr = 0.0002
I0625 14:15:29.524021  4216 solver.cpp:228] Iteration 1680, loss = 0.288554
I0625 14:15:29.524044  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:15:29.524051  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000207696 (* 1 = 0.000207696 loss)
I0625 14:15:29.524055  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0606613 (* 1 = 0.0606613 loss)
I0625 14:15:29.524060  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00886945 (* 1 = 0.00886945 loss)
I0625 14:15:29.524063  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134808 (* 1 = 0.0134808 loss)
I0625 14:15:29.524067  4216 sgd_solver.cpp:106] Iteration 1680, lr = 0.0002
I0625 14:17:09.187376  4216 solver.cpp:228] Iteration 1700, loss = 0.317276
I0625 14:17:09.187410  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:17:09.187417  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000530145 (* 1 = 0.000530145 loss)
I0625 14:17:09.187422  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0515602 (* 1 = 0.0515602 loss)
I0625 14:17:09.187424  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0220444 (* 1 = 0.0220444 loss)
I0625 14:17:09.187428  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119066 (* 1 = 0.0119066 loss)
I0625 14:17:09.187433  4216 sgd_solver.cpp:106] Iteration 1700, lr = 0.0002
I0625 14:18:48.945425  4216 solver.cpp:228] Iteration 1720, loss = 0.272836
I0625 14:18:48.945462  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 14:18:48.945469  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.159721 (* 1 = 0.159721 loss)
I0625 14:18:48.945473  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.261616 (* 1 = 0.261616 loss)
I0625 14:18:48.945477  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112101 (* 1 = 0.0112101 loss)
I0625 14:18:48.945480  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00508523 (* 1 = 0.00508523 loss)
I0625 14:18:48.945484  4216 sgd_solver.cpp:106] Iteration 1720, lr = 0.0002
I0625 14:20:28.429251  4216 solver.cpp:228] Iteration 1740, loss = 0.186645
I0625 14:20:28.429273  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:20:28.429280  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000142871 (* 1 = 0.000142871 loss)
I0625 14:20:28.429286  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.042354 (* 1 = 0.042354 loss)
I0625 14:20:28.429288  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0067859 (* 1 = 0.0067859 loss)
I0625 14:20:28.429292  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154414 (* 1 = 0.0154414 loss)
I0625 14:20:28.429297  4216 sgd_solver.cpp:106] Iteration 1740, lr = 0.0002
I0625 14:22:08.271572  4216 solver.cpp:228] Iteration 1760, loss = 0.435708
I0625 14:22:08.271595  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 14:22:08.271601  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.171043 (* 1 = 0.171043 loss)
I0625 14:22:08.271605  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.279862 (* 1 = 0.279862 loss)
I0625 14:22:08.271610  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00971083 (* 1 = 0.00971083 loss)
I0625 14:22:08.271613  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0399044 (* 1 = 0.0399044 loss)
I0625 14:22:08.271618  4216 sgd_solver.cpp:106] Iteration 1760, lr = 0.0002
I0625 14:23:47.605782  4216 solver.cpp:228] Iteration 1780, loss = 0.407629
I0625 14:23:47.605818  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:23:47.605825  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000284362 (* 1 = 0.000284362 loss)
I0625 14:23:47.605829  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0593087 (* 1 = 0.0593087 loss)
I0625 14:23:47.605832  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126791 (* 1 = 0.0126791 loss)
I0625 14:23:47.605835  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202489 (* 1 = 0.0202489 loss)
I0625 14:23:47.605840  4216 sgd_solver.cpp:106] Iteration 1780, lr = 0.0002
speed: 4.976s / iter
I0625 14:25:27.132709  4216 solver.cpp:228] Iteration 1800, loss = 0.358008
I0625 14:25:27.132745  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:25:27.132752  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000852439 (* 1 = 0.000852439 loss)
I0625 14:25:27.132756  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0408762 (* 1 = 0.0408762 loss)
I0625 14:25:27.132760  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148952 (* 1 = 0.0148952 loss)
I0625 14:25:27.132762  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011381 (* 1 = 0.011381 loss)
I0625 14:25:27.132766  4216 sgd_solver.cpp:106] Iteration 1800, lr = 0.0002
I0625 14:27:06.573637  4216 solver.cpp:228] Iteration 1820, loss = 0.410725
I0625 14:27:06.573673  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 14:27:06.573679  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235827 (* 1 = 0.0235827 loss)
I0625 14:27:06.573683  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0788737 (* 1 = 0.0788737 loss)
I0625 14:27:06.573686  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00716423 (* 1 = 0.00716423 loss)
I0625 14:27:06.573689  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215469 (* 1 = 0.0215469 loss)
I0625 14:27:06.573694  4216 sgd_solver.cpp:106] Iteration 1820, lr = 0.0002
I0625 14:28:45.992801  4216 solver.cpp:228] Iteration 1840, loss = 0.420135
I0625 14:28:45.992838  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 14:28:45.992846  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.241296 (* 1 = 0.241296 loss)
I0625 14:28:45.992848  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.431299 (* 1 = 0.431299 loss)
I0625 14:28:45.992852  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0903477 (* 1 = 0.0903477 loss)
I0625 14:28:45.992857  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0622811 (* 1 = 0.0622811 loss)
I0625 14:28:45.992863  4216 sgd_solver.cpp:106] Iteration 1840, lr = 0.0002
I0625 14:30:25.714061  4216 solver.cpp:228] Iteration 1860, loss = 0.185108
I0625 14:30:25.714098  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 14:30:25.714105  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791691 (* 1 = 0.0791691 loss)
I0625 14:30:25.714109  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.192996 (* 1 = 0.192996 loss)
I0625 14:30:25.714112  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129474 (* 1 = 0.0129474 loss)
I0625 14:30:25.714116  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282076 (* 1 = 0.0282076 loss)
I0625 14:30:25.714121  4216 sgd_solver.cpp:106] Iteration 1860, lr = 0.0002
I0625 14:32:05.241941  4216 solver.cpp:228] Iteration 1880, loss = 0.27095
I0625 14:32:05.241964  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 14:32:05.241971  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541308 (* 1 = 0.0541308 loss)
I0625 14:32:05.241976  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.149609 (* 1 = 0.149609 loss)
I0625 14:32:05.241979  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119936 (* 1 = 0.0119936 loss)
I0625 14:32:05.241982  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107012 (* 1 = 0.0107012 loss)
I0625 14:32:05.241987  4216 sgd_solver.cpp:106] Iteration 1880, lr = 0.0002
I0625 14:33:44.707923  4216 solver.cpp:228] Iteration 1900, loss = 0.415546
I0625 14:33:44.707945  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 14:33:44.707967  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509501 (* 1 = 0.0509501 loss)
I0625 14:33:44.707970  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.240497 (* 1 = 0.240497 loss)
I0625 14:33:44.707973  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153103 (* 1 = 0.0153103 loss)
I0625 14:33:44.707976  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0542767 (* 1 = 0.0542767 loss)
I0625 14:33:44.707981  4216 sgd_solver.cpp:106] Iteration 1900, lr = 0.0002
I0625 14:35:24.198891  4216 solver.cpp:228] Iteration 1920, loss = 0.563502
I0625 14:35:24.198915  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 14:35:24.198922  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.01492 (* 1 = 0.01492 loss)
I0625 14:35:24.198926  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0802369 (* 1 = 0.0802369 loss)
I0625 14:35:24.198930  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104344 (* 1 = 0.0104344 loss)
I0625 14:35:24.198933  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00893717 (* 1 = 0.00893717 loss)
I0625 14:35:24.198938  4216 sgd_solver.cpp:106] Iteration 1920, lr = 0.0002
I0625 14:37:03.668462  4216 solver.cpp:228] Iteration 1940, loss = 0.332285
I0625 14:37:03.668481  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 14:37:03.668488  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518536 (* 1 = 0.0518536 loss)
I0625 14:37:03.668493  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118342 (* 1 = 0.118342 loss)
I0625 14:37:03.668496  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356551 (* 1 = 0.00356551 loss)
I0625 14:37:03.668499  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00948908 (* 1 = 0.00948908 loss)
I0625 14:37:03.668504  4216 sgd_solver.cpp:106] Iteration 1940, lr = 0.0002
I0625 14:38:43.180286  4216 solver.cpp:228] Iteration 1960, loss = 0.277085
I0625 14:38:43.180310  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 14:38:43.180317  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.186934 (* 1 = 0.186934 loss)
I0625 14:38:43.180321  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.360487 (* 1 = 0.360487 loss)
I0625 14:38:43.180325  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141819 (* 1 = 0.0141819 loss)
I0625 14:38:43.180328  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.05232 (* 1 = 0.05232 loss)
I0625 14:38:43.180333  4216 sgd_solver.cpp:106] Iteration 1960, lr = 0.0002
I0625 14:40:22.773763  4216 solver.cpp:228] Iteration 1980, loss = 0.296886
I0625 14:40:22.773799  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:40:22.773807  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000356239 (* 1 = 0.000356239 loss)
I0625 14:40:22.773810  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0512793 (* 1 = 0.0512793 loss)
I0625 14:40:22.773814  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134851 (* 1 = 0.0134851 loss)
I0625 14:40:22.773818  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255469 (* 1 = 0.0255469 loss)
I0625 14:40:22.773821  4216 sgd_solver.cpp:106] Iteration 1980, lr = 0.0002
speed: 4.976s / iter
I0625 14:42:02.186987  4216 solver.cpp:228] Iteration 2000, loss = 0.296454
I0625 14:42:02.187011  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 14:42:02.187018  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0982931 (* 1 = 0.0982931 loss)
I0625 14:42:02.187022  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.249292 (* 1 = 0.249292 loss)
I0625 14:42:02.187026  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0389848 (* 1 = 0.0389848 loss)
I0625 14:42:02.187029  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305498 (* 1 = 0.0305498 loss)
I0625 14:42:02.187033  4216 sgd_solver.cpp:106] Iteration 2000, lr = 0.0002
I0625 14:43:42.015733  4216 solver.cpp:228] Iteration 2020, loss = 0.300086
I0625 14:43:42.015774  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 14:43:42.015781  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.159708 (* 1 = 0.159708 loss)
I0625 14:43:42.015786  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.31193 (* 1 = 0.31193 loss)
I0625 14:43:42.015791  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0475667 (* 1 = 0.0475667 loss)
I0625 14:43:42.015795  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0759443 (* 1 = 0.0759443 loss)
I0625 14:43:42.015800  4216 sgd_solver.cpp:106] Iteration 2020, lr = 0.0002
I0625 14:45:21.860342  4216 solver.cpp:228] Iteration 2040, loss = 0.388422
I0625 14:45:21.860368  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:45:21.860378  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000233961 (* 1 = 0.000233961 loss)
I0625 14:45:21.860383  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0320532 (* 1 = 0.0320532 loss)
I0625 14:45:21.860388  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00427428 (* 1 = 0.00427428 loss)
I0625 14:45:21.860393  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159559 (* 1 = 0.0159559 loss)
I0625 14:45:21.860399  4216 sgd_solver.cpp:106] Iteration 2040, lr = 0.0002
I0625 14:47:01.346052  4216 solver.cpp:228] Iteration 2060, loss = 0.371269
I0625 14:47:01.346073  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 14:47:01.346081  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0127794 (* 1 = 0.0127794 loss)
I0625 14:47:01.346083  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0711412 (* 1 = 0.0711412 loss)
I0625 14:47:01.346087  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115962 (* 1 = 0.0115962 loss)
I0625 14:47:01.346091  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014208 (* 1 = 0.014208 loss)
I0625 14:47:01.346094  4216 sgd_solver.cpp:106] Iteration 2060, lr = 0.0002
I0625 14:48:41.076944  4216 solver.cpp:228] Iteration 2080, loss = 0.347513
I0625 14:48:41.076967  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 14:48:41.076974  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0338088 (* 1 = 0.0338088 loss)
I0625 14:48:41.076978  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0897429 (* 1 = 0.0897429 loss)
I0625 14:48:41.076982  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541554 (* 1 = 0.00541554 loss)
I0625 14:48:41.076985  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128091 (* 1 = 0.0128091 loss)
I0625 14:48:41.076990  4216 sgd_solver.cpp:106] Iteration 2080, lr = 0.0002
I0625 14:50:20.642541  4216 solver.cpp:228] Iteration 2100, loss = 0.294852
I0625 14:50:20.642578  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 14:50:20.642585  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0781925 (* 1 = 0.0781925 loss)
I0625 14:50:20.642590  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129135 (* 1 = 0.129135 loss)
I0625 14:50:20.642593  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00671617 (* 1 = 0.00671617 loss)
I0625 14:50:20.642596  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217367 (* 1 = 0.0217367 loss)
I0625 14:50:20.642601  4216 sgd_solver.cpp:106] Iteration 2100, lr = 0.0002
I0625 14:52:00.357851  4216 solver.cpp:228] Iteration 2120, loss = 0.372271
I0625 14:52:00.357890  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0625 14:52:00.357898  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.417891 (* 1 = 0.417891 loss)
I0625 14:52:00.357903  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.635351 (* 1 = 0.635351 loss)
I0625 14:52:00.357906  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.27585 (* 1 = 0.27585 loss)
I0625 14:52:00.357911  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.409877 (* 1 = 0.409877 loss)
I0625 14:52:00.357916  4216 sgd_solver.cpp:106] Iteration 2120, lr = 0.0002
I0625 14:53:40.705842  4216 solver.cpp:228] Iteration 2140, loss = 0.369842
I0625 14:53:40.705863  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 14:53:40.705884  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000545028 (* 1 = 0.000545028 loss)
I0625 14:53:40.705888  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0492133 (* 1 = 0.0492133 loss)
I0625 14:53:40.705891  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00707064 (* 1 = 0.00707064 loss)
I0625 14:53:40.705894  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164073 (* 1 = 0.0164073 loss)
I0625 14:53:40.705899  4216 sgd_solver.cpp:106] Iteration 2140, lr = 0.0002
I0625 14:55:21.313386  4216 solver.cpp:228] Iteration 2160, loss = 0.247776
I0625 14:55:21.313424  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 14:55:21.313432  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0868175 (* 1 = 0.0868175 loss)
I0625 14:55:21.313436  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.159496 (* 1 = 0.159496 loss)
I0625 14:55:21.313439  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109641 (* 1 = 0.0109641 loss)
I0625 14:55:21.313442  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00888394 (* 1 = 0.00888394 loss)
I0625 14:55:21.313447  4216 sgd_solver.cpp:106] Iteration 2160, lr = 0.0002
I0625 14:57:02.931506  4216 solver.cpp:228] Iteration 2180, loss = 0.419298
I0625 14:57:02.931529  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 14:57:02.931536  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0781154 (* 1 = 0.0781154 loss)
I0625 14:57:02.931540  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.196944 (* 1 = 0.196944 loss)
I0625 14:57:02.931543  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256193 (* 1 = 0.0256193 loss)
I0625 14:57:02.931546  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234828 (* 1 = 0.0234828 loss)
I0625 14:57:02.931551  4216 sgd_solver.cpp:106] Iteration 2180, lr = 0.0002
speed: 4.979s / iter
I0625 14:58:44.189373  4216 solver.cpp:228] Iteration 2200, loss = 0.381975
I0625 14:58:44.189399  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 14:58:44.189405  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0808248 (* 1 = 0.0808248 loss)
I0625 14:58:44.189409  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.235967 (* 1 = 0.235967 loss)
I0625 14:58:44.189411  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226459 (* 1 = 0.0226459 loss)
I0625 14:58:44.189415  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0906745 (* 1 = 0.0906745 loss)
I0625 14:58:44.189419  4216 sgd_solver.cpp:106] Iteration 2200, lr = 0.0002
I0625 15:00:25.820367  4216 solver.cpp:228] Iteration 2220, loss = 0.391378
I0625 15:00:25.820391  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 15:00:25.820397  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.122955 (* 1 = 0.122955 loss)
I0625 15:00:25.820401  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.265414 (* 1 = 0.265414 loss)
I0625 15:00:25.820405  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123757 (* 1 = 0.0123757 loss)
I0625 15:00:25.820408  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0424639 (* 1 = 0.0424639 loss)
I0625 15:00:25.820412  4216 sgd_solver.cpp:106] Iteration 2220, lr = 0.0002
I0625 15:02:10.820261  4216 solver.cpp:228] Iteration 2240, loss = 0.467695
I0625 15:02:10.820288  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0625 15:02:10.820296  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.299358 (* 1 = 0.299358 loss)
I0625 15:02:10.820300  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.50547 (* 1 = 0.50547 loss)
I0625 15:02:10.820303  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030188 (* 1 = 0.030188 loss)
I0625 15:02:10.820307  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13908 (* 1 = 0.13908 loss)
I0625 15:02:10.820313  4216 sgd_solver.cpp:106] Iteration 2240, lr = 0.0002
I0625 15:03:58.043964  4216 solver.cpp:228] Iteration 2260, loss = 0.669951
I0625 15:03:58.043988  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 15:03:58.043995  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321136 (* 1 = 0.0321136 loss)
I0625 15:03:58.043999  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.10344 (* 1 = 0.10344 loss)
I0625 15:03:58.044003  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00857623 (* 1 = 0.00857623 loss)
I0625 15:03:58.044008  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00898902 (* 1 = 0.00898902 loss)
I0625 15:03:58.044011  4216 sgd_solver.cpp:106] Iteration 2260, lr = 0.0002
I0625 15:05:46.383910  4216 solver.cpp:228] Iteration 2280, loss = 0.402116
I0625 15:05:46.383936  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 15:05:46.383944  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.319858 (* 1 = 0.319858 loss)
I0625 15:05:46.383947  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.460178 (* 1 = 0.460178 loss)
I0625 15:05:46.383950  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0598279 (* 1 = 0.0598279 loss)
I0625 15:05:46.383955  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110843 (* 1 = 0.110843 loss)
I0625 15:05:46.383960  4216 sgd_solver.cpp:106] Iteration 2280, lr = 0.0002
I0625 15:07:34.889761  4216 solver.cpp:228] Iteration 2300, loss = 0.373375
I0625 15:07:34.889789  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 15:07:34.889797  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.267143 (* 1 = 0.267143 loss)
I0625 15:07:34.889801  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.491879 (* 1 = 0.491879 loss)
I0625 15:07:34.889804  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133492 (* 1 = 0.0133492 loss)
I0625 15:07:34.889808  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0468565 (* 1 = 0.0468565 loss)
I0625 15:07:34.889813  4216 sgd_solver.cpp:106] Iteration 2300, lr = 0.0002
I0625 15:09:22.465395  4216 solver.cpp:228] Iteration 2320, loss = 0.506661
I0625 15:09:22.465421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 15:09:22.465430  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0632505 (* 1 = 0.0632505 loss)
I0625 15:09:22.465438  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.179774 (* 1 = 0.179774 loss)
I0625 15:09:22.465445  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00783142 (* 1 = 0.00783142 loss)
I0625 15:09:22.465448  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295628 (* 1 = 0.0295628 loss)
I0625 15:09:22.465454  4216 sgd_solver.cpp:106] Iteration 2320, lr = 0.0002
I0625 15:11:10.384114  4216 solver.cpp:228] Iteration 2340, loss = 0.613247
I0625 15:11:10.384142  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 15:11:10.384153  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0880235 (* 1 = 0.0880235 loss)
I0625 15:11:10.384160  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.219214 (* 1 = 0.219214 loss)
I0625 15:11:10.384168  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817461 (* 1 = 0.00817461 loss)
I0625 15:11:10.384176  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020905 (* 1 = 0.020905 loss)
I0625 15:11:10.384184  4216 sgd_solver.cpp:106] Iteration 2340, lr = 0.0002
I0625 15:13:00.294927  4216 solver.cpp:228] Iteration 2360, loss = 0.322727
I0625 15:13:00.294955  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0625 15:13:00.294963  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.248702 (* 1 = 0.248702 loss)
I0625 15:13:00.294967  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.473406 (* 1 = 0.473406 loss)
I0625 15:13:00.294972  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150492 (* 1 = 0.0150492 loss)
I0625 15:13:00.294976  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0876796 (* 1 = 0.0876796 loss)
I0625 15:13:00.294982  4216 sgd_solver.cpp:106] Iteration 2360, lr = 0.0002
I0625 15:14:48.294901  4216 solver.cpp:228] Iteration 2380, loss = 0.180342
I0625 15:14:48.294930  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 15:14:48.294942  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.037485 (* 1 = 0.037485 loss)
I0625 15:14:48.294950  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.218502 (* 1 = 0.218502 loss)
I0625 15:14:48.294957  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205586 (* 1 = 0.0205586 loss)
I0625 15:14:48.294965  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00970604 (* 1 = 0.00970604 loss)
I0625 15:14:48.294975  4216 sgd_solver.cpp:106] Iteration 2380, lr = 0.0002
speed: 5.011s / iter
I0625 15:16:37.007057  4216 solver.cpp:228] Iteration 2400, loss = 0.481441
I0625 15:16:37.007082  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:16:37.007091  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0502614 (* 1 = 0.0502614 loss)
I0625 15:16:37.007094  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.123451 (* 1 = 0.123451 loss)
I0625 15:16:37.007098  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00824667 (* 1 = 0.00824667 loss)
I0625 15:16:37.007102  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150963 (* 1 = 0.0150963 loss)
I0625 15:16:37.007107  4216 sgd_solver.cpp:106] Iteration 2400, lr = 0.0002
I0625 15:18:23.744477  4216 solver.cpp:228] Iteration 2420, loss = 0.305079
I0625 15:18:23.744503  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:18:23.744513  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0461506 (* 1 = 0.0461506 loss)
I0625 15:18:23.744518  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.076271 (* 1 = 0.076271 loss)
I0625 15:18:23.744524  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212156 (* 1 = 0.0212156 loss)
I0625 15:18:23.744529  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125027 (* 1 = 0.0125027 loss)
I0625 15:18:23.744535  4216 sgd_solver.cpp:106] Iteration 2420, lr = 0.0002
I0625 15:20:11.033933  4216 solver.cpp:228] Iteration 2440, loss = 0.313276
I0625 15:20:11.033967  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:20:11.033975  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236888 (* 1 = 0.0236888 loss)
I0625 15:20:11.033979  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0611867 (* 1 = 0.0611867 loss)
I0625 15:20:11.033984  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336469 (* 1 = 0.00336469 loss)
I0625 15:20:11.033988  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154185 (* 1 = 0.0154185 loss)
I0625 15:20:11.033994  4216 sgd_solver.cpp:106] Iteration 2440, lr = 0.0002
I0625 15:21:57.350219  4216 solver.cpp:228] Iteration 2460, loss = 0.381976
I0625 15:21:57.350244  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:21:57.350252  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0118629 (* 1 = 0.0118629 loss)
I0625 15:21:57.350258  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0333262 (* 1 = 0.0333262 loss)
I0625 15:21:57.350263  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674841 (* 1 = 0.00674841 loss)
I0625 15:21:57.350270  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132084 (* 1 = 0.0132084 loss)
I0625 15:21:57.350275  4216 sgd_solver.cpp:106] Iteration 2460, lr = 0.0002
I0625 15:23:44.220258  4216 solver.cpp:228] Iteration 2480, loss = 0.538782
I0625 15:23:44.220289  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:23:44.220297  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207739 (* 1 = 0.0207739 loss)
I0625 15:23:44.220302  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.059653 (* 1 = 0.059653 loss)
I0625 15:23:44.220307  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00500207 (* 1 = 0.00500207 loss)
I0625 15:23:44.220312  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187141 (* 1 = 0.0187141 loss)
I0625 15:23:44.220317  4216 sgd_solver.cpp:106] Iteration 2480, lr = 0.0002
I0625 15:25:30.428978  4216 solver.cpp:228] Iteration 2500, loss = 0.506496
I0625 15:25:30.429002  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.570312
I0625 15:25:30.429010  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.681922 (* 1 = 0.681922 loss)
I0625 15:25:30.429014  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.87241 (* 1 = 0.87241 loss)
I0625 15:25:30.429018  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.130944 (* 1 = 0.130944 loss)
I0625 15:25:30.429023  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.244656 (* 1 = 0.244656 loss)
I0625 15:25:30.429028  4216 sgd_solver.cpp:106] Iteration 2500, lr = 0.0002
I0625 15:27:17.137050  4216 solver.cpp:228] Iteration 2520, loss = 0.143645
I0625 15:27:17.137074  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 15:27:17.137082  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0463742 (* 1 = 0.0463742 loss)
I0625 15:27:17.137085  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.177603 (* 1 = 0.177603 loss)
I0625 15:27:17.137089  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107295 (* 1 = 0.0107295 loss)
I0625 15:27:17.137094  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00347933 (* 1 = 0.00347933 loss)
I0625 15:27:17.137099  4216 sgd_solver.cpp:106] Iteration 2520, lr = 0.0002
I0625 15:29:03.636826  4216 solver.cpp:228] Iteration 2540, loss = 0.445552
I0625 15:29:03.636848  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 15:29:03.636857  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.241252 (* 1 = 0.241252 loss)
I0625 15:29:03.636859  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.303156 (* 1 = 0.303156 loss)
I0625 15:29:03.636863  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185078 (* 1 = 0.0185078 loss)
I0625 15:29:03.636867  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348133 (* 1 = 0.0348133 loss)
I0625 15:29:03.636871  4216 sgd_solver.cpp:106] Iteration 2540, lr = 0.0002
I0625 15:30:50.278327  4216 solver.cpp:228] Iteration 2560, loss = 0.456291
I0625 15:30:50.278352  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0625 15:30:50.278360  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.252127 (* 1 = 0.252127 loss)
I0625 15:30:50.278365  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.506468 (* 1 = 0.506468 loss)
I0625 15:30:50.278369  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015054 (* 1 = 0.015054 loss)
I0625 15:30:50.278373  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101137 (* 1 = 0.101137 loss)
I0625 15:30:50.278378  4216 sgd_solver.cpp:106] Iteration 2560, lr = 0.0002
I0625 15:32:36.551455  4216 solver.cpp:228] Iteration 2580, loss = 0.577018
I0625 15:32:36.551484  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:32:36.551492  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0075296 (* 1 = 0.0075296 loss)
I0625 15:32:36.551496  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0659373 (* 1 = 0.0659373 loss)
I0625 15:32:36.551501  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00599766 (* 1 = 0.00599766 loss)
I0625 15:32:36.551504  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00802572 (* 1 = 0.00802572 loss)
I0625 15:32:36.551509  4216 sgd_solver.cpp:106] Iteration 2580, lr = 0.0002
speed: 5.035s / iter
I0625 15:34:22.579172  4216 solver.cpp:228] Iteration 2600, loss = 0.338886
I0625 15:34:22.579231  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 15:34:22.579246  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0973243 (* 1 = 0.0973243 loss)
I0625 15:34:22.579252  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.239125 (* 1 = 0.239125 loss)
I0625 15:34:22.579257  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817974 (* 1 = 0.00817974 loss)
I0625 15:34:22.579263  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104464 (* 1 = 0.0104464 loss)
I0625 15:34:22.579273  4216 sgd_solver.cpp:106] Iteration 2600, lr = 0.0002
I0625 15:36:09.211396  4216 solver.cpp:228] Iteration 2620, loss = 0.381419
I0625 15:36:09.211421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:36:09.211429  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261988 (* 1 = 0.0261988 loss)
I0625 15:36:09.211433  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0922111 (* 1 = 0.0922111 loss)
I0625 15:36:09.211437  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126194 (* 1 = 0.0126194 loss)
I0625 15:36:09.211441  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135887 (* 1 = 0.0135887 loss)
I0625 15:36:09.211444  4216 sgd_solver.cpp:106] Iteration 2620, lr = 0.0002
I0625 15:37:56.379765  4216 solver.cpp:228] Iteration 2640, loss = 0.176077
I0625 15:37:56.379791  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:37:56.379801  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00390298 (* 1 = 0.00390298 loss)
I0625 15:37:56.379807  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0467771 (* 1 = 0.0467771 loss)
I0625 15:37:56.379812  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259785 (* 1 = 0.00259785 loss)
I0625 15:37:56.379818  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00459151 (* 1 = 0.00459151 loss)
I0625 15:37:56.379824  4216 sgd_solver.cpp:106] Iteration 2640, lr = 0.0002
I0625 15:39:43.433131  4216 solver.cpp:228] Iteration 2660, loss = 0.282924
I0625 15:39:43.433154  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:39:43.433163  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000517527 (* 1 = 0.000517527 loss)
I0625 15:39:43.433169  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0503197 (* 1 = 0.0503197 loss)
I0625 15:39:43.433176  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122959 (* 1 = 0.0122959 loss)
I0625 15:39:43.433181  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144218 (* 1 = 0.0144218 loss)
I0625 15:39:43.433187  4216 sgd_solver.cpp:106] Iteration 2660, lr = 0.0002
I0625 15:41:30.213876  4216 solver.cpp:228] Iteration 2680, loss = 0.507008
I0625 15:41:30.213907  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0625 15:41:30.213914  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.391083 (* 1 = 0.391083 loss)
I0625 15:41:30.213918  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.608029 (* 1 = 0.608029 loss)
I0625 15:41:30.213922  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0484612 (* 1 = 0.0484612 loss)
I0625 15:41:30.213925  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.165668 (* 1 = 0.165668 loss)
I0625 15:41:30.213930  4216 sgd_solver.cpp:106] Iteration 2680, lr = 0.0002
I0625 15:43:18.052008  4216 solver.cpp:228] Iteration 2700, loss = 0.514106
I0625 15:43:18.052037  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:43:18.052044  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00477279 (* 1 = 0.00477279 loss)
I0625 15:43:18.052048  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0603492 (* 1 = 0.0603492 loss)
I0625 15:43:18.052052  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00329632 (* 1 = 0.00329632 loss)
I0625 15:43:18.052055  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00472062 (* 1 = 0.00472062 loss)
I0625 15:43:18.052062  4216 sgd_solver.cpp:106] Iteration 2700, lr = 0.0002
I0625 15:45:05.498383  4216 solver.cpp:228] Iteration 2720, loss = 0.279403
I0625 15:45:05.498407  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:45:05.498414  4216 solver.cpp:244]     Train net output #1: loss_bbox = 6.85503e-05 (* 1 = 6.85503e-05 loss)
I0625 15:45:05.498420  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0273115 (* 1 = 0.0273115 loss)
I0625 15:45:05.498422  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186359 (* 1 = 0.00186359 loss)
I0625 15:45:05.498426  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172685 (* 1 = 0.0172685 loss)
I0625 15:45:05.498430  4216 sgd_solver.cpp:106] Iteration 2720, lr = 0.0002
I0625 15:46:53.049067  4216 solver.cpp:228] Iteration 2740, loss = 0.31056
I0625 15:46:53.049090  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 15:46:53.049098  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627019 (* 1 = 0.0627019 loss)
I0625 15:46:53.049100  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119522 (* 1 = 0.119522 loss)
I0625 15:46:53.049104  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276383 (* 1 = 0.00276383 loss)
I0625 15:46:53.049108  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00893464 (* 1 = 0.00893464 loss)
I0625 15:46:53.049113  4216 sgd_solver.cpp:106] Iteration 2740, lr = 0.0002
I0625 15:48:40.121188  4216 solver.cpp:228] Iteration 2760, loss = 0.293482
I0625 15:48:40.121215  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 15:48:40.121224  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.194167 (* 1 = 0.194167 loss)
I0625 15:48:40.121229  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.34404 (* 1 = 0.34404 loss)
I0625 15:48:40.121234  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00645558 (* 1 = 0.00645558 loss)
I0625 15:48:40.121239  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0799789 (* 1 = 0.0799789 loss)
I0625 15:48:40.121245  4216 sgd_solver.cpp:106] Iteration 2760, lr = 0.0002
I0625 15:50:27.361106  4216 solver.cpp:228] Iteration 2780, loss = 0.240272
I0625 15:50:27.361135  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:50:27.361143  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00235675 (* 1 = 0.00235675 loss)
I0625 15:50:27.361147  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0550017 (* 1 = 0.0550017 loss)
I0625 15:50:27.361151  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073025 (* 1 = 0.0073025 loss)
I0625 15:50:27.361155  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016456 (* 1 = 0.016456 loss)
I0625 15:50:27.361161  4216 sgd_solver.cpp:106] Iteration 2780, lr = 0.0002
speed: 5.059s / iter
I0625 15:52:14.890038  4216 solver.cpp:228] Iteration 2800, loss = 0.284854
I0625 15:52:14.890058  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 15:52:14.890065  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.138763 (* 1 = 0.138763 loss)
I0625 15:52:14.890069  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.369658 (* 1 = 0.369658 loss)
I0625 15:52:14.890072  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193482 (* 1 = 0.0193482 loss)
I0625 15:52:14.890075  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165024 (* 1 = 0.0165024 loss)
I0625 15:52:14.890079  4216 sgd_solver.cpp:106] Iteration 2800, lr = 0.0002
I0625 15:54:02.128422  4216 solver.cpp:228] Iteration 2820, loss = 0.366372
I0625 15:54:02.128448  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 15:54:02.128455  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144118 (* 1 = 0.0144118 loss)
I0625 15:54:02.128459  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0716807 (* 1 = 0.0716807 loss)
I0625 15:54:02.128464  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259122 (* 1 = 0.00259122 loss)
I0625 15:54:02.128468  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00130552 (* 1 = 0.00130552 loss)
I0625 15:54:02.128473  4216 sgd_solver.cpp:106] Iteration 2820, lr = 0.0002
I0625 15:55:48.727176  4216 solver.cpp:228] Iteration 2840, loss = 0.139706
I0625 15:55:48.727203  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 15:55:48.727211  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0921669 (* 1 = 0.0921669 loss)
I0625 15:55:48.727216  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.162308 (* 1 = 0.162308 loss)
I0625 15:55:48.727221  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00826969 (* 1 = 0.00826969 loss)
I0625 15:55:48.727224  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315936 (* 1 = 0.0315936 loss)
I0625 15:55:48.727229  4216 sgd_solver.cpp:106] Iteration 2840, lr = 0.0002
I0625 15:57:36.328871  4216 solver.cpp:228] Iteration 2860, loss = 0.4996
I0625 15:57:36.328897  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 15:57:36.328907  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.199479 (* 1 = 0.199479 loss)
I0625 15:57:36.328913  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.392413 (* 1 = 0.392413 loss)
I0625 15:57:36.328920  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112649 (* 1 = 0.0112649 loss)
I0625 15:57:36.328927  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187241 (* 1 = 0.0187241 loss)
I0625 15:57:36.328933  4216 sgd_solver.cpp:106] Iteration 2860, lr = 0.0002
I0625 15:59:23.360080  4216 solver.cpp:228] Iteration 2880, loss = 0.37853
I0625 15:59:23.360106  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:59:23.360117  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000658449 (* 1 = 0.000658449 loss)
I0625 15:59:23.360124  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0396056 (* 1 = 0.0396056 loss)
I0625 15:59:23.360131  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157705 (* 1 = 0.0157705 loss)
I0625 15:59:23.360136  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213854 (* 1 = 0.0213854 loss)
I0625 15:59:23.360144  4216 sgd_solver.cpp:106] Iteration 2880, lr = 0.0002
I0625 16:01:12.320969  4216 solver.cpp:228] Iteration 2900, loss = 0.559098
I0625 16:01:12.320996  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 16:01:12.321003  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.036169 (* 1 = 0.036169 loss)
I0625 16:01:12.321007  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.180325 (* 1 = 0.180325 loss)
I0625 16:01:12.321010  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0367949 (* 1 = 0.0367949 loss)
I0625 16:01:12.321014  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0671004 (* 1 = 0.0671004 loss)
I0625 16:01:12.321019  4216 sgd_solver.cpp:106] Iteration 2900, lr = 0.0002
I0625 16:03:00.457625  4216 solver.cpp:228] Iteration 2920, loss = 0.567126
I0625 16:03:00.457653  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 16:03:00.457661  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000570327 (* 1 = 0.000570327 loss)
I0625 16:03:00.457666  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0350522 (* 1 = 0.0350522 loss)
I0625 16:03:00.457670  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0046677 (* 1 = 0.0046677 loss)
I0625 16:03:00.457674  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133142 (* 1 = 0.0133142 loss)
I0625 16:03:00.457680  4216 sgd_solver.cpp:106] Iteration 2920, lr = 0.0002
I0625 16:04:48.594802  4216 solver.cpp:228] Iteration 2940, loss = 0.453461
I0625 16:04:48.594828  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 16:04:48.594836  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.194735 (* 1 = 0.194735 loss)
I0625 16:04:48.594841  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.341855 (* 1 = 0.341855 loss)
I0625 16:04:48.594843  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360702 (* 1 = 0.00360702 loss)
I0625 16:04:48.594847  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187402 (* 1 = 0.0187402 loss)
I0625 16:04:48.594852  4216 sgd_solver.cpp:106] Iteration 2940, lr = 0.0002
I0625 16:06:35.872241  4216 solver.cpp:228] Iteration 2960, loss = 0.275622
I0625 16:06:35.872265  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 16:06:35.872272  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473922 (* 1 = 0.0473922 loss)
I0625 16:06:35.872277  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.245221 (* 1 = 0.245221 loss)
I0625 16:06:35.872280  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0095222 (* 1 = 0.0095222 loss)
I0625 16:06:35.872283  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0567605 (* 1 = 0.0567605 loss)
I0625 16:06:35.872288  4216 sgd_solver.cpp:106] Iteration 2960, lr = 0.0002
I0625 16:08:23.888650  4216 solver.cpp:228] Iteration 2980, loss = 0.646582
I0625 16:08:23.888677  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 16:08:23.888684  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.200744 (* 1 = 0.200744 loss)
I0625 16:08:23.888689  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.357774 (* 1 = 0.357774 loss)
I0625 16:08:23.888692  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0243104 (* 1 = 0.0243104 loss)
I0625 16:08:23.888695  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0659461 (* 1 = 0.0659461 loss)
I0625 16:08:23.888700  4216 sgd_solver.cpp:106] Iteration 2980, lr = 0.0002
speed: 5.080s / iter
I0625 16:10:11.292835  4216 solver.cpp:228] Iteration 3000, loss = 0.183893
I0625 16:10:11.292860  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 16:10:11.292868  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.022975 (* 1 = 0.022975 loss)
I0625 16:10:11.292872  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0836191 (* 1 = 0.0836191 loss)
I0625 16:10:11.292876  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0056629 (* 1 = 0.0056629 loss)
I0625 16:10:11.292879  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140975 (* 1 = 0.0140975 loss)
I0625 16:10:11.292884  4216 sgd_solver.cpp:106] Iteration 3000, lr = 0.0002
I0625 16:12:00.045979  4216 solver.cpp:228] Iteration 3020, loss = 0.201325
I0625 16:12:00.046005  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 16:12:00.046015  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0887211 (* 1 = 0.0887211 loss)
I0625 16:12:00.046020  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.18934 (* 1 = 0.18934 loss)
I0625 16:12:00.046025  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053342 (* 1 = 0.0053342 loss)
I0625 16:12:00.046030  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145406 (* 1 = 0.0145406 loss)
I0625 16:12:00.046036  4216 sgd_solver.cpp:106] Iteration 3020, lr = 0.0002
I0625 16:13:46.420835  4216 solver.cpp:228] Iteration 3040, loss = 0.341454
I0625 16:13:46.420859  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 16:13:46.420867  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.15489 (* 1 = 0.15489 loss)
I0625 16:13:46.420871  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.341114 (* 1 = 0.341114 loss)
I0625 16:13:46.420876  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00966071 (* 1 = 0.00966071 loss)
I0625 16:13:46.420881  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298115 (* 1 = 0.0298115 loss)
I0625 16:13:46.420886  4216 sgd_solver.cpp:106] Iteration 3040, lr = 0.0002
I0625 16:15:32.644829  4216 solver.cpp:228] Iteration 3060, loss = 0.392914
I0625 16:15:32.644853  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 16:15:32.644861  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.134684 (* 1 = 0.134684 loss)
I0625 16:15:32.644865  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.222478 (* 1 = 0.222478 loss)
I0625 16:15:32.644870  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118333 (* 1 = 0.0118333 loss)
I0625 16:15:32.644873  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260109 (* 1 = 0.0260109 loss)
I0625 16:15:32.644878  4216 sgd_solver.cpp:106] Iteration 3060, lr = 0.0002
I0625 16:17:20.368463  4216 solver.cpp:228] Iteration 3080, loss = 0.393819
I0625 16:17:20.368489  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 16:17:20.368496  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182652 (* 1 = 0.0182652 loss)
I0625 16:17:20.368500  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0897429 (* 1 = 0.0897429 loss)
I0625 16:17:20.368505  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103576 (* 1 = 0.0103576 loss)
I0625 16:17:20.368508  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00922367 (* 1 = 0.00922367 loss)
I0625 16:17:20.368512  4216 sgd_solver.cpp:106] Iteration 3080, lr = 0.0002
I0625 16:19:08.508108  4216 solver.cpp:228] Iteration 3100, loss = 0.508176
I0625 16:19:08.508136  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0625 16:19:08.508144  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0841113 (* 1 = 0.0841113 loss)
I0625 16:19:08.508148  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.402342 (* 1 = 0.402342 loss)
I0625 16:19:08.508152  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193894 (* 1 = 0.0193894 loss)
I0625 16:19:08.508157  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243958 (* 1 = 0.0243958 loss)
I0625 16:19:08.508162  4216 sgd_solver.cpp:106] Iteration 3100, lr = 0.0002
I0625 16:20:56.354090  4216 solver.cpp:228] Iteration 3120, loss = 0.222551
I0625 16:20:56.354115  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 16:20:56.354122  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0088472 (* 1 = 0.0088472 loss)
I0625 16:20:56.354127  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.101302 (* 1 = 0.101302 loss)
I0625 16:20:56.354131  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00159019 (* 1 = 0.00159019 loss)
I0625 16:20:56.354135  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00924207 (* 1 = 0.00924207 loss)
I0625 16:20:56.354140  4216 sgd_solver.cpp:106] Iteration 3120, lr = 0.0002
I0625 16:22:45.224727  4216 solver.cpp:228] Iteration 3140, loss = 0.194852
I0625 16:22:45.224756  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 16:22:45.224762  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203039 (* 1 = 0.0203039 loss)
I0625 16:22:45.224767  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.101057 (* 1 = 0.101057 loss)
I0625 16:22:45.224771  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102312 (* 1 = 0.0102312 loss)
I0625 16:22:45.224774  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010889 (* 1 = 0.010889 loss)
I0625 16:22:45.224779  4216 sgd_solver.cpp:106] Iteration 3140, lr = 0.0002
I0625 16:24:32.514161  4216 solver.cpp:228] Iteration 3160, loss = 0.45088
I0625 16:24:32.514184  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0625 16:24:32.514191  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.425679 (* 1 = 0.425679 loss)
I0625 16:24:32.514194  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.597697 (* 1 = 0.597697 loss)
I0625 16:24:32.514199  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00769685 (* 1 = 0.00769685 loss)
I0625 16:24:32.514201  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0570743 (* 1 = 0.0570743 loss)
I0625 16:24:32.514206  4216 sgd_solver.cpp:106] Iteration 3160, lr = 0.0002
I0625 16:26:20.433329  4216 solver.cpp:228] Iteration 3180, loss = 0.320614
I0625 16:26:20.433357  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 16:26:20.433368  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485339 (* 1 = 0.0485339 loss)
I0625 16:26:20.433375  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.130942 (* 1 = 0.130942 loss)
I0625 16:26:20.433382  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0062001 (* 1 = 0.0062001 loss)
I0625 16:26:20.433390  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290488 (* 1 = 0.0290488 loss)
I0625 16:26:20.433398  4216 sgd_solver.cpp:106] Iteration 3180, lr = 0.0002
speed: 5.099s / iter
I0625 16:28:07.756566  4216 solver.cpp:228] Iteration 3200, loss = 0.31019
I0625 16:28:07.756600  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 16:28:07.756610  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0644508 (* 1 = 0.0644508 loss)
I0625 16:28:07.756618  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.186595 (* 1 = 0.186595 loss)
I0625 16:28:07.756624  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00791467 (* 1 = 0.00791467 loss)
I0625 16:28:07.756630  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403033 (* 1 = 0.0403033 loss)
I0625 16:28:07.756639  4216 sgd_solver.cpp:106] Iteration 3200, lr = 0.0002
I0625 16:29:52.877079  4216 solver.cpp:228] Iteration 3220, loss = 0.486964
I0625 16:29:52.877102  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0625 16:29:52.877110  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.349692 (* 1 = 0.349692 loss)
I0625 16:29:52.877113  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.714176 (* 1 = 0.714176 loss)
I0625 16:29:52.877117  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0257302 (* 1 = 0.0257302 loss)
I0625 16:29:52.877120  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108209 (* 1 = 0.108209 loss)
I0625 16:29:52.877125  4216 sgd_solver.cpp:106] Iteration 3220, lr = 0.0002
I0625 16:31:40.493260  4216 solver.cpp:228] Iteration 3240, loss = 0.357828
I0625 16:31:40.493288  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 16:31:40.493295  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.231881 (* 1 = 0.231881 loss)
I0625 16:31:40.493299  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.261824 (* 1 = 0.261824 loss)
I0625 16:31:40.493304  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010861 (* 1 = 0.010861 loss)
I0625 16:31:40.493307  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174606 (* 1 = 0.0174606 loss)
I0625 16:31:40.493314  4216 sgd_solver.cpp:106] Iteration 3240, lr = 0.0002
I0625 16:33:27.948119  4216 solver.cpp:228] Iteration 3260, loss = 0.294277
I0625 16:33:27.948143  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 16:33:27.948151  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0136888 (* 1 = 0.0136888 loss)
I0625 16:33:27.948155  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0409483 (* 1 = 0.0409483 loss)
I0625 16:33:27.948158  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216942 (* 1 = 0.00216942 loss)
I0625 16:33:27.948163  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125274 (* 1 = 0.0125274 loss)
I0625 16:33:27.948166  4216 sgd_solver.cpp:106] Iteration 3260, lr = 0.0002
I0625 16:35:14.139398  4216 solver.cpp:228] Iteration 3280, loss = 0.234521
I0625 16:35:14.139430  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 16:35:14.139438  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0642357 (* 1 = 0.0642357 loss)
I0625 16:35:14.139444  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.104965 (* 1 = 0.104965 loss)
I0625 16:35:14.139449  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00801643 (* 1 = 0.00801643 loss)
I0625 16:35:14.139453  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00536189 (* 1 = 0.00536189 loss)
I0625 16:35:14.139459  4216 sgd_solver.cpp:106] Iteration 3280, lr = 0.0002
I0625 16:37:02.312448  4216 solver.cpp:228] Iteration 3300, loss = 0.443437
I0625 16:37:02.312477  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 16:37:02.312485  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0699061 (* 1 = 0.0699061 loss)
I0625 16:37:02.312490  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.131123 (* 1 = 0.131123 loss)
I0625 16:37:02.312494  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279602 (* 1 = 0.0279602 loss)
I0625 16:37:02.312500  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219971 (* 1 = 0.0219971 loss)
I0625 16:37:02.312505  4216 sgd_solver.cpp:106] Iteration 3300, lr = 0.0002
I0625 16:38:50.931879  4216 solver.cpp:228] Iteration 3320, loss = 0.333647
I0625 16:38:50.931905  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 16:38:50.931911  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.160321 (* 1 = 0.160321 loss)
I0625 16:38:50.931915  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.383552 (* 1 = 0.383552 loss)
I0625 16:38:50.931919  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103737 (* 1 = 0.103737 loss)
I0625 16:38:50.931922  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.289961 (* 1 = 0.289961 loss)
I0625 16:38:50.931927  4216 sgd_solver.cpp:106] Iteration 3320, lr = 0.0002
I0625 16:40:37.434764  4216 solver.cpp:228] Iteration 3340, loss = 0.371263
I0625 16:40:37.434788  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 16:40:37.434797  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.102084 (* 1 = 0.102084 loss)
I0625 16:40:37.434800  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108537 (* 1 = 0.108537 loss)
I0625 16:40:37.434804  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00289837 (* 1 = 0.00289837 loss)
I0625 16:40:37.434809  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102771 (* 1 = 0.0102771 loss)
I0625 16:40:37.434814  4216 sgd_solver.cpp:106] Iteration 3340, lr = 0.0002
I0625 16:42:23.916313  4216 solver.cpp:228] Iteration 3360, loss = 0.231035
I0625 16:42:23.916340  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 16:42:23.916348  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198816 (* 1 = 0.0198816 loss)
I0625 16:42:23.916353  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0857801 (* 1 = 0.0857801 loss)
I0625 16:42:23.916357  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00446008 (* 1 = 0.00446008 loss)
I0625 16:42:23.916363  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00612842 (* 1 = 0.00612842 loss)
I0625 16:42:23.916368  4216 sgd_solver.cpp:106] Iteration 3360, lr = 0.0002
I0625 16:44:10.783347  4216 solver.cpp:228] Iteration 3380, loss = 0.33333
I0625 16:44:10.783371  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 16:44:10.783378  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0934515 (* 1 = 0.0934515 loss)
I0625 16:44:10.783381  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121057 (* 1 = 0.121057 loss)
I0625 16:44:10.783385  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023353 (* 1 = 0.0023353 loss)
I0625 16:44:10.783388  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212467 (* 1 = 0.0212467 loss)
I0625 16:44:10.783392  4216 sgd_solver.cpp:106] Iteration 3380, lr = 0.0002
speed: 5.114s / iter
I0625 16:45:58.132143  4216 solver.cpp:228] Iteration 3400, loss = 0.388298
I0625 16:45:58.132174  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 16:45:58.132181  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0951038 (* 1 = 0.0951038 loss)
I0625 16:45:58.132186  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.141412 (* 1 = 0.141412 loss)
I0625 16:45:58.132190  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021243 (* 1 = 0.021243 loss)
I0625 16:45:58.132195  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00166675 (* 1 = 0.00166675 loss)
I0625 16:45:58.132201  4216 sgd_solver.cpp:106] Iteration 3400, lr = 0.0002
I0625 16:47:45.289234  4216 solver.cpp:228] Iteration 3420, loss = 0.323359
I0625 16:47:45.289260  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 16:47:45.289268  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524801 (* 1 = 0.0524801 loss)
I0625 16:47:45.289273  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.157168 (* 1 = 0.157168 loss)
I0625 16:47:45.289275  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151241 (* 1 = 0.0151241 loss)
I0625 16:47:45.289279  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160535 (* 1 = 0.0160535 loss)
I0625 16:47:45.289284  4216 sgd_solver.cpp:106] Iteration 3420, lr = 0.0002
I0625 16:49:32.122853  4216 solver.cpp:228] Iteration 3440, loss = 0.244026
I0625 16:49:32.122881  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 16:49:32.122889  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.042293 (* 1 = 0.042293 loss)
I0625 16:49:32.122892  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.125215 (* 1 = 0.125215 loss)
I0625 16:49:32.122895  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104712 (* 1 = 0.0104712 loss)
I0625 16:49:32.122900  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00574461 (* 1 = 0.00574461 loss)
I0625 16:49:32.122903  4216 sgd_solver.cpp:106] Iteration 3440, lr = 0.0002
I0625 16:51:18.670384  4216 solver.cpp:228] Iteration 3460, loss = 0.267984
I0625 16:51:18.670408  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0625 16:51:18.670418  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0885951 (* 1 = 0.0885951 loss)
I0625 16:51:18.670424  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.314567 (* 1 = 0.314567 loss)
I0625 16:51:18.670430  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0271027 (* 1 = 0.0271027 loss)
I0625 16:51:18.670435  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0749348 (* 1 = 0.0749348 loss)
I0625 16:51:18.670441  4216 sgd_solver.cpp:106] Iteration 3460, lr = 0.0002
I0625 16:53:06.457403  4216 solver.cpp:228] Iteration 3480, loss = 0.257368
I0625 16:53:06.457430  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 16:53:06.457437  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362285 (* 1 = 0.0362285 loss)
I0625 16:53:06.457442  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0567658 (* 1 = 0.0567658 loss)
I0625 16:53:06.457448  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674146 (* 1 = 0.00674146 loss)
I0625 16:53:06.457453  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119055 (* 1 = 0.0119055 loss)
I0625 16:53:06.457459  4216 sgd_solver.cpp:106] Iteration 3480, lr = 0.0002
I0625 16:54:52.589578  4216 solver.cpp:228] Iteration 3500, loss = 0.45576
I0625 16:54:52.589604  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 16:54:52.589613  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292301 (* 1 = 0.0292301 loss)
I0625 16:54:52.589620  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129116 (* 1 = 0.129116 loss)
I0625 16:54:52.589627  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00750046 (* 1 = 0.00750046 loss)
I0625 16:54:52.589632  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302951 (* 1 = 0.0302951 loss)
I0625 16:54:52.589637  4216 sgd_solver.cpp:106] Iteration 3500, lr = 0.0002
I0625 16:56:37.940928  4216 solver.cpp:228] Iteration 3520, loss = 0.2848
I0625 16:56:37.940953  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 16:56:37.940959  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.112466 (* 1 = 0.112466 loss)
I0625 16:56:37.940964  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.304933 (* 1 = 0.304933 loss)
I0625 16:56:37.940968  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021637 (* 1 = 0.021637 loss)
I0625 16:56:37.940970  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037751 (* 1 = 0.037751 loss)
I0625 16:56:37.940975  4216 sgd_solver.cpp:106] Iteration 3520, lr = 0.0002
I0625 16:58:23.313357  4216 solver.cpp:228] Iteration 3540, loss = 0.486899
I0625 16:58:23.313381  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 16:58:23.313388  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0557536 (* 1 = 0.0557536 loss)
I0625 16:58:23.313392  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.162097 (* 1 = 0.162097 loss)
I0625 16:58:23.313395  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123392 (* 1 = 0.0123392 loss)
I0625 16:58:23.313400  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0420517 (* 1 = 0.0420517 loss)
I0625 16:58:23.313405  4216 sgd_solver.cpp:106] Iteration 3540, lr = 0.0002
I0625 17:00:09.362929  4216 solver.cpp:228] Iteration 3560, loss = 0.374474
I0625 17:00:09.362957  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:00:09.362963  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.031601 (* 1 = 0.031601 loss)
I0625 17:00:09.362968  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.127316 (* 1 = 0.127316 loss)
I0625 17:00:09.362972  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123334 (* 1 = 0.0123334 loss)
I0625 17:00:09.362977  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147303 (* 1 = 0.0147303 loss)
I0625 17:00:09.362982  4216 sgd_solver.cpp:106] Iteration 3560, lr = 0.0002
I0625 17:01:56.452139  4216 solver.cpp:228] Iteration 3580, loss = 0.29971
I0625 17:01:56.452179  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 17:01:56.452191  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0826727 (* 1 = 0.0826727 loss)
I0625 17:01:56.452198  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109598 (* 1 = 0.109598 loss)
I0625 17:01:56.452205  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160104 (* 1 = 0.00160104 loss)
I0625 17:01:56.452213  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274093 (* 1 = 0.0274093 loss)
I0625 17:01:56.452219  4216 sgd_solver.cpp:106] Iteration 3580, lr = 0.0002
speed: 5.126s / iter
I0625 17:03:44.110708  4216 solver.cpp:228] Iteration 3600, loss = 0.293557
I0625 17:03:44.110733  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:03:44.110741  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234795 (* 1 = 0.0234795 loss)
I0625 17:03:44.110746  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.148704 (* 1 = 0.148704 loss)
I0625 17:03:44.110749  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157099 (* 1 = 0.0157099 loss)
I0625 17:03:44.110754  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00700929 (* 1 = 0.00700929 loss)
I0625 17:03:44.110759  4216 sgd_solver.cpp:106] Iteration 3600, lr = 0.0002
I0625 17:05:31.678165  4216 solver.cpp:228] Iteration 3620, loss = 0.339298
I0625 17:05:31.678196  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 17:05:31.678203  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.076683 (* 1 = 0.076683 loss)
I0625 17:05:31.678208  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.215699 (* 1 = 0.215699 loss)
I0625 17:05:31.678211  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199686 (* 1 = 0.0199686 loss)
I0625 17:05:31.678215  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438261 (* 1 = 0.0438261 loss)
I0625 17:05:31.678220  4216 sgd_solver.cpp:106] Iteration 3620, lr = 0.0002
I0625 17:07:18.294792  4216 solver.cpp:228] Iteration 3640, loss = 0.382482
I0625 17:07:18.294847  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:07:18.294862  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0644644 (* 1 = 0.0644644 loss)
I0625 17:07:18.294867  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.172094 (* 1 = 0.172094 loss)
I0625 17:07:18.294872  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171877 (* 1 = 0.0171877 loss)
I0625 17:07:18.294875  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196475 (* 1 = 0.0196475 loss)
I0625 17:07:18.294884  4216 sgd_solver.cpp:106] Iteration 3640, lr = 0.0002
I0625 17:09:04.167501  4216 solver.cpp:228] Iteration 3660, loss = 0.24082
I0625 17:09:04.167526  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 17:09:04.167534  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.020615 (* 1 = 0.020615 loss)
I0625 17:09:04.167539  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0880325 (* 1 = 0.0880325 loss)
I0625 17:09:04.167543  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180715 (* 1 = 0.0180715 loss)
I0625 17:09:04.167547  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161961 (* 1 = 0.0161961 loss)
I0625 17:09:04.167552  4216 sgd_solver.cpp:106] Iteration 3660, lr = 0.0002
I0625 17:10:50.428236  4216 solver.cpp:228] Iteration 3680, loss = 0.378585
I0625 17:10:50.428261  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:10:50.428268  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0282886 (* 1 = 0.0282886 loss)
I0625 17:10:50.428273  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0977904 (* 1 = 0.0977904 loss)
I0625 17:10:50.428277  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000735624 (* 1 = 0.000735624 loss)
I0625 17:10:50.428282  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00546415 (* 1 = 0.00546415 loss)
I0625 17:10:50.428287  4216 sgd_solver.cpp:106] Iteration 3680, lr = 0.0002
I0625 17:12:38.062705  4216 solver.cpp:228] Iteration 3700, loss = 0.380757
I0625 17:12:38.062731  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 17:12:38.062738  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.139984 (* 1 = 0.139984 loss)
I0625 17:12:38.062742  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.288163 (* 1 = 0.288163 loss)
I0625 17:12:38.062747  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188926 (* 1 = 0.0188926 loss)
I0625 17:12:38.062749  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160119 (* 1 = 0.0160119 loss)
I0625 17:12:38.062754  4216 sgd_solver.cpp:106] Iteration 3700, lr = 0.0002
I0625 17:14:27.528722  4216 solver.cpp:228] Iteration 3720, loss = 0.296475
I0625 17:14:27.528753  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:14:27.528766  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00028489 (* 1 = 0.00028489 loss)
I0625 17:14:27.528775  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0318358 (* 1 = 0.0318358 loss)
I0625 17:14:27.528784  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126147 (* 1 = 0.0126147 loss)
I0625 17:14:27.528792  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140856 (* 1 = 0.0140856 loss)
I0625 17:14:27.528801  4216 sgd_solver.cpp:106] Iteration 3720, lr = 0.0002
I0625 17:16:14.106360  4216 solver.cpp:228] Iteration 3740, loss = 0.196243
I0625 17:16:14.106386  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 17:16:14.106395  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190762 (* 1 = 0.0190762 loss)
I0625 17:16:14.106400  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0519325 (* 1 = 0.0519325 loss)
I0625 17:16:14.106403  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485309 (* 1 = 0.00485309 loss)
I0625 17:16:14.106407  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116138 (* 1 = 0.0116138 loss)
I0625 17:16:14.106413  4216 sgd_solver.cpp:106] Iteration 3740, lr = 0.0002
I0625 17:18:01.873349  4216 solver.cpp:228] Iteration 3760, loss = 0.232167
I0625 17:18:01.873378  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 17:18:01.873386  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179151 (* 1 = 0.0179151 loss)
I0625 17:18:01.873392  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.11984 (* 1 = 0.11984 loss)
I0625 17:18:01.873396  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199308 (* 1 = 0.0199308 loss)
I0625 17:18:01.873400  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351245 (* 1 = 0.0351245 loss)
I0625 17:18:01.873405  4216 sgd_solver.cpp:106] Iteration 3760, lr = 0.0002
I0625 17:19:48.881687  4216 solver.cpp:228] Iteration 3780, loss = 0.18458
I0625 17:19:48.881712  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 17:19:48.881721  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0100591 (* 1 = 0.0100591 loss)
I0625 17:19:48.881724  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0394058 (* 1 = 0.0394058 loss)
I0625 17:19:48.881729  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119331 (* 1 = 0.0119331 loss)
I0625 17:19:48.881733  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00938001 (* 1 = 0.00938001 loss)
I0625 17:19:48.881738  4216 sgd_solver.cpp:106] Iteration 3780, lr = 0.0002
speed: 5.138s / iter
I0625 17:21:34.874341  4216 solver.cpp:228] Iteration 3800, loss = 0.314778
I0625 17:21:34.874363  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 17:21:34.874370  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.034663 (* 1 = 0.034663 loss)
I0625 17:21:34.874374  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.172776 (* 1 = 0.172776 loss)
I0625 17:21:34.874378  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00374173 (* 1 = 0.00374173 loss)
I0625 17:21:34.874382  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364937 (* 1 = 0.0364937 loss)
I0625 17:21:34.874387  4216 sgd_solver.cpp:106] Iteration 3800, lr = 0.0002
I0625 17:23:20.487646  4216 solver.cpp:228] Iteration 3820, loss = 0.414853
I0625 17:23:20.487673  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:23:20.487681  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0693074 (* 1 = 0.0693074 loss)
I0625 17:23:20.487686  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0650864 (* 1 = 0.0650864 loss)
I0625 17:23:20.487690  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000758321 (* 1 = 0.000758321 loss)
I0625 17:23:20.487694  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00641739 (* 1 = 0.00641739 loss)
I0625 17:23:20.487700  4216 sgd_solver.cpp:106] Iteration 3820, lr = 0.0002
I0625 17:25:06.775856  4216 solver.cpp:228] Iteration 3840, loss = 0.267612
I0625 17:25:06.775880  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 17:25:06.775888  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549781 (* 1 = 0.0549781 loss)
I0625 17:25:06.775892  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.168739 (* 1 = 0.168739 loss)
I0625 17:25:06.775897  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00619244 (* 1 = 0.00619244 loss)
I0625 17:25:06.775900  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272315 (* 1 = 0.0272315 loss)
I0625 17:25:06.775905  4216 sgd_solver.cpp:106] Iteration 3840, lr = 0.0002
I0625 17:26:53.388082  4216 solver.cpp:228] Iteration 3860, loss = 0.475092
I0625 17:26:53.388105  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.53125
I0625 17:26:53.388113  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.786003 (* 1 = 0.786003 loss)
I0625 17:26:53.388116  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.813566 (* 1 = 0.813566 loss)
I0625 17:26:53.388120  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0843977 (* 1 = 0.0843977 loss)
I0625 17:26:53.388124  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.235485 (* 1 = 0.235485 loss)
I0625 17:26:53.388128  4216 sgd_solver.cpp:106] Iteration 3860, lr = 0.0002
I0625 17:28:42.799613  4216 solver.cpp:228] Iteration 3880, loss = 0.28882
I0625 17:28:42.799641  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 17:28:42.799649  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.164395 (* 1 = 0.164395 loss)
I0625 17:28:42.799654  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.353045 (* 1 = 0.353045 loss)
I0625 17:28:42.799657  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0958318 (* 1 = 0.0958318 loss)
I0625 17:28:42.799662  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0561835 (* 1 = 0.0561835 loss)
I0625 17:28:42.799669  4216 sgd_solver.cpp:106] Iteration 3880, lr = 0.0002
I0625 17:30:31.549755  4216 solver.cpp:228] Iteration 3900, loss = 0.354007
I0625 17:30:31.549784  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 17:30:31.549793  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0952121 (* 1 = 0.0952121 loss)
I0625 17:30:31.549798  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.144876 (* 1 = 0.144876 loss)
I0625 17:30:31.549801  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0275816 (* 1 = 0.0275816 loss)
I0625 17:30:31.549806  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037219 (* 1 = 0.037219 loss)
I0625 17:30:31.549813  4216 sgd_solver.cpp:106] Iteration 3900, lr = 0.0002
I0625 17:32:18.334074  4216 solver.cpp:228] Iteration 3920, loss = 0.597533
I0625 17:32:18.334101  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0625 17:32:18.334108  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.255287 (* 1 = 0.255287 loss)
I0625 17:32:18.334115  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.460834 (* 1 = 0.460834 loss)
I0625 17:32:18.334118  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146485 (* 1 = 0.0146485 loss)
I0625 17:32:18.334121  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297627 (* 1 = 0.0297627 loss)
I0625 17:32:18.334127  4216 sgd_solver.cpp:106] Iteration 3920, lr = 0.0002
I0625 17:34:06.282888  4216 solver.cpp:228] Iteration 3940, loss = 0.347731
I0625 17:34:06.282914  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 17:34:06.282923  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.130915 (* 1 = 0.130915 loss)
I0625 17:34:06.282928  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.32295 (* 1 = 0.32295 loss)
I0625 17:34:06.282933  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00482761 (* 1 = 0.00482761 loss)
I0625 17:34:06.282938  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0382157 (* 1 = 0.0382157 loss)
I0625 17:34:06.282944  4216 sgd_solver.cpp:106] Iteration 3940, lr = 0.0002
I0625 17:35:54.043840  4216 solver.cpp:228] Iteration 3960, loss = 0.289143
I0625 17:35:54.043867  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 17:35:54.043874  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120232 (* 1 = 0.120232 loss)
I0625 17:35:54.043879  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.139622 (* 1 = 0.139622 loss)
I0625 17:35:54.043882  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281756 (* 1 = 0.0281756 loss)
I0625 17:35:54.043885  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525154 (* 1 = 0.0525154 loss)
I0625 17:35:54.043890  4216 sgd_solver.cpp:106] Iteration 3960, lr = 0.0002
I0625 17:37:41.362742  4216 solver.cpp:228] Iteration 3980, loss = 0.768604
I0625 17:37:41.362767  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 17:37:41.362774  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.179425 (* 1 = 0.179425 loss)
I0625 17:37:41.362777  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.316571 (* 1 = 0.316571 loss)
I0625 17:37:41.362782  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00771629 (* 1 = 0.00771629 loss)
I0625 17:37:41.362785  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0415578 (* 1 = 0.0415578 loss)
I0625 17:37:41.362790  4216 sgd_solver.cpp:106] Iteration 3980, lr = 0.0002
speed: 5.150s / iter
I0625 17:39:29.596138  4216 solver.cpp:228] Iteration 4000, loss = 0.289395
I0625 17:39:29.596164  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 17:39:29.596171  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.102116 (* 1 = 0.102116 loss)
I0625 17:39:29.596176  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.229514 (* 1 = 0.229514 loss)
I0625 17:39:29.596180  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00946909 (* 1 = 0.00946909 loss)
I0625 17:39:29.596184  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197936 (* 1 = 0.0197936 loss)
I0625 17:39:29.596189  4216 sgd_solver.cpp:106] Iteration 4000, lr = 0.0002
I0625 17:41:16.131891  4216 solver.cpp:228] Iteration 4020, loss = 0.223306
I0625 17:41:16.131919  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 17:41:16.131928  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473607 (* 1 = 0.0473607 loss)
I0625 17:41:16.131935  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0544136 (* 1 = 0.0544136 loss)
I0625 17:41:16.131942  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00421698 (* 1 = 0.00421698 loss)
I0625 17:41:16.131945  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00772453 (* 1 = 0.00772453 loss)
I0625 17:41:16.131950  4216 sgd_solver.cpp:106] Iteration 4020, lr = 0.0002
I0625 17:43:01.434151  4216 solver.cpp:228] Iteration 4040, loss = 0.511567
I0625 17:43:01.434176  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 17:43:01.434185  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258545 (* 1 = 0.0258545 loss)
I0625 17:43:01.434188  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0896598 (* 1 = 0.0896598 loss)
I0625 17:43:01.434192  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00551644 (* 1 = 0.00551644 loss)
I0625 17:43:01.434197  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113365 (* 1 = 0.0113365 loss)
I0625 17:43:01.434202  4216 sgd_solver.cpp:106] Iteration 4040, lr = 0.0002
I0625 17:44:46.697491  4216 solver.cpp:228] Iteration 4060, loss = 0.418824
I0625 17:44:46.697516  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:44:46.697525  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.061165 (* 1 = 0.061165 loss)
I0625 17:44:46.697530  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.14512 (* 1 = 0.14512 loss)
I0625 17:44:46.697533  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00521347 (* 1 = 0.00521347 loss)
I0625 17:44:46.697537  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255773 (* 1 = 0.0255773 loss)
I0625 17:44:46.697542  4216 sgd_solver.cpp:106] Iteration 4060, lr = 0.0002
I0625 17:46:31.889896  4216 solver.cpp:228] Iteration 4080, loss = 0.302892
I0625 17:46:31.889922  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 17:46:31.889931  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195872 (* 1 = 0.0195872 loss)
I0625 17:46:31.889936  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0477942 (* 1 = 0.0477942 loss)
I0625 17:46:31.889941  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000353969 (* 1 = 0.000353969 loss)
I0625 17:46:31.889946  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0090748 (* 1 = 0.0090748 loss)
I0625 17:46:31.889951  4216 sgd_solver.cpp:106] Iteration 4080, lr = 0.0002
I0625 17:48:17.196429  4216 solver.cpp:228] Iteration 4100, loss = 0.391367
I0625 17:48:17.196457  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:48:17.196465  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00111905 (* 1 = 0.00111905 loss)
I0625 17:48:17.196470  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0419611 (* 1 = 0.0419611 loss)
I0625 17:48:17.196475  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00911178 (* 1 = 0.00911178 loss)
I0625 17:48:17.196480  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173586 (* 1 = 0.0173586 loss)
I0625 17:48:17.196485  4216 sgd_solver.cpp:106] Iteration 4100, lr = 0.0002
I0625 17:50:02.487844  4216 solver.cpp:228] Iteration 4120, loss = 0.285895
I0625 17:50:02.487874  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:50:02.487882  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000294324 (* 1 = 0.000294324 loss)
I0625 17:50:02.487887  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0356829 (* 1 = 0.0356829 loss)
I0625 17:50:02.487892  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00633269 (* 1 = 0.00633269 loss)
I0625 17:50:02.487897  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00949376 (* 1 = 0.00949376 loss)
I0625 17:50:02.487902  4216 sgd_solver.cpp:106] Iteration 4120, lr = 0.0002
I0625 17:51:47.794862  4216 solver.cpp:228] Iteration 4140, loss = 0.261546
I0625 17:51:47.794888  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 17:51:47.794896  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329922 (* 1 = 0.0329922 loss)
I0625 17:51:47.794900  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.106981 (* 1 = 0.106981 loss)
I0625 17:51:47.794904  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029064 (* 1 = 0.0029064 loss)
I0625 17:51:47.794909  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00750209 (* 1 = 0.00750209 loss)
I0625 17:51:47.794914  4216 sgd_solver.cpp:106] Iteration 4140, lr = 0.0002
I0625 17:53:33.136270  4216 solver.cpp:228] Iteration 4160, loss = 0.505914
I0625 17:53:33.136297  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 17:53:33.136304  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.231028 (* 1 = 0.231028 loss)
I0625 17:53:33.136309  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.348105 (* 1 = 0.348105 loss)
I0625 17:53:33.136313  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00473219 (* 1 = 0.00473219 loss)
I0625 17:53:33.136317  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0411653 (* 1 = 0.0411653 loss)
I0625 17:53:33.136322  4216 sgd_solver.cpp:106] Iteration 4160, lr = 0.0002
I0625 17:55:18.460034  4216 solver.cpp:228] Iteration 4180, loss = 0.266934
I0625 17:55:18.460062  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:55:18.460068  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.026423 (* 1 = 0.026423 loss)
I0625 17:55:18.460073  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.112506 (* 1 = 0.112506 loss)
I0625 17:55:18.460078  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241538 (* 1 = 0.0241538 loss)
I0625 17:55:18.460081  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0429962 (* 1 = 0.0429962 loss)
I0625 17:55:18.460086  4216 sgd_solver.cpp:106] Iteration 4180, lr = 0.0002
speed: 5.156s / iter
I0625 17:57:03.786645  4216 solver.cpp:228] Iteration 4200, loss = 0.55792
I0625 17:57:03.786671  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 17:57:03.786679  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.199698 (* 1 = 0.199698 loss)
I0625 17:57:03.786684  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.52986 (* 1 = 0.52986 loss)
I0625 17:57:03.786687  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151582 (* 1 = 0.0151582 loss)
I0625 17:57:03.786691  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449909 (* 1 = 0.0449909 loss)
I0625 17:57:03.786696  4216 sgd_solver.cpp:106] Iteration 4200, lr = 0.0002
I0625 17:58:49.101629  4216 solver.cpp:228] Iteration 4220, loss = 0.269482
I0625 17:58:49.101655  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:58:49.101661  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279352 (* 1 = 0.0279352 loss)
I0625 17:58:49.101665  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0957379 (* 1 = 0.0957379 loss)
I0625 17:58:49.101670  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00389812 (* 1 = 0.00389812 loss)
I0625 17:58:49.101672  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0410704 (* 1 = 0.0410704 loss)
I0625 17:58:49.101678  4216 sgd_solver.cpp:106] Iteration 4220, lr = 0.0002
I0625 18:00:34.450295  4216 solver.cpp:228] Iteration 4240, loss = 0.375273
I0625 18:00:34.450320  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 18:00:34.450327  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256596 (* 1 = 0.0256596 loss)
I0625 18:00:34.450331  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0877945 (* 1 = 0.0877945 loss)
I0625 18:00:34.450335  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241428 (* 1 = 0.00241428 loss)
I0625 18:00:34.450340  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0073792 (* 1 = 0.0073792 loss)
I0625 18:00:34.450343  4216 sgd_solver.cpp:106] Iteration 4240, lr = 0.0002
I0625 18:02:19.818351  4216 solver.cpp:228] Iteration 4260, loss = 0.157334
I0625 18:02:19.818374  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 18:02:19.818382  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.261264 (* 1 = 0.261264 loss)
I0625 18:02:19.818384  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.365536 (* 1 = 0.365536 loss)
I0625 18:02:19.818388  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117275 (* 1 = 0.0117275 loss)
I0625 18:02:19.818392  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405299 (* 1 = 0.0405299 loss)
I0625 18:02:19.818397  4216 sgd_solver.cpp:106] Iteration 4260, lr = 0.0002
I0625 18:04:05.173035  4216 solver.cpp:228] Iteration 4280, loss = 0.267268
I0625 18:04:05.173061  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 18:04:05.173069  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181166 (* 1 = 0.0181166 loss)
I0625 18:04:05.173074  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.081885 (* 1 = 0.081885 loss)
I0625 18:04:05.173076  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135692 (* 1 = 0.0135692 loss)
I0625 18:04:05.173081  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106219 (* 1 = 0.0106219 loss)
I0625 18:04:05.173085  4216 sgd_solver.cpp:106] Iteration 4280, lr = 0.0002
I0625 18:05:50.492807  4216 solver.cpp:228] Iteration 4300, loss = 0.391083
I0625 18:05:50.492839  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:05:50.492847  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0500458 (* 1 = 0.0500458 loss)
I0625 18:05:50.492851  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.100181 (* 1 = 0.100181 loss)
I0625 18:05:50.492856  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00243834 (* 1 = 0.00243834 loss)
I0625 18:05:50.492859  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132113 (* 1 = 0.0132113 loss)
I0625 18:05:50.492864  4216 sgd_solver.cpp:106] Iteration 4300, lr = 0.0002
I0625 18:07:35.822471  4216 solver.cpp:228] Iteration 4320, loss = 0.222015
I0625 18:07:35.822497  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 18:07:35.822505  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.054244 (* 1 = 0.054244 loss)
I0625 18:07:35.822510  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.160253 (* 1 = 0.160253 loss)
I0625 18:07:35.822513  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032924 (* 1 = 0.0032924 loss)
I0625 18:07:35.822518  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238126 (* 1 = 0.0238126 loss)
I0625 18:07:35.822523  4216 sgd_solver.cpp:106] Iteration 4320, lr = 0.0002
I0625 18:09:21.051354  4216 solver.cpp:228] Iteration 4340, loss = 0.268612
I0625 18:09:21.051378  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 18:09:21.051384  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.193327 (* 1 = 0.193327 loss)
I0625 18:09:21.051388  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.295545 (* 1 = 0.295545 loss)
I0625 18:09:21.051393  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128109 (* 1 = 0.0128109 loss)
I0625 18:09:21.051395  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282693 (* 1 = 0.0282693 loss)
I0625 18:09:21.051399  4216 sgd_solver.cpp:106] Iteration 4340, lr = 0.0002
I0625 18:11:06.333454  4216 solver.cpp:228] Iteration 4360, loss = 0.306345
I0625 18:11:06.333482  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 18:11:06.333488  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.225943 (* 1 = 0.225943 loss)
I0625 18:11:06.333492  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.347248 (* 1 = 0.347248 loss)
I0625 18:11:06.333497  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00985171 (* 1 = 0.00985171 loss)
I0625 18:11:06.333500  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0537133 (* 1 = 0.0537133 loss)
I0625 18:11:06.333505  4216 sgd_solver.cpp:106] Iteration 4360, lr = 0.0002
I0625 18:12:52.260691  4216 solver.cpp:228] Iteration 4380, loss = 0.42489
I0625 18:12:52.260720  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 18:12:52.260728  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0482076 (* 1 = 0.0482076 loss)
I0625 18:12:52.260733  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.232284 (* 1 = 0.232284 loss)
I0625 18:12:52.260737  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00430392 (* 1 = 0.00430392 loss)
I0625 18:12:52.260741  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297415 (* 1 = 0.0297415 loss)
I0625 18:12:52.260747  4216 sgd_solver.cpp:106] Iteration 4380, lr = 0.0002
speed: 5.161s / iter
I0625 18:14:40.713940  4216 solver.cpp:228] Iteration 4400, loss = 0.221685
I0625 18:14:40.713964  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 18:14:40.713971  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0366354 (* 1 = 0.0366354 loss)
I0625 18:14:40.713975  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0526183 (* 1 = 0.0526183 loss)
I0625 18:14:40.713979  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00170911 (* 1 = 0.00170911 loss)
I0625 18:14:40.713984  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034956 (* 1 = 0.034956 loss)
I0625 18:14:40.713987  4216 sgd_solver.cpp:106] Iteration 4400, lr = 0.0002
I0625 18:16:26.733638  4216 solver.cpp:228] Iteration 4420, loss = 0.424551
I0625 18:16:26.733661  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 18:16:26.733669  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0904366 (* 1 = 0.0904366 loss)
I0625 18:16:26.733674  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.294192 (* 1 = 0.294192 loss)
I0625 18:16:26.733677  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265911 (* 1 = 0.0265911 loss)
I0625 18:16:26.733681  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049993 (* 1 = 0.049993 loss)
I0625 18:16:26.733686  4216 sgd_solver.cpp:106] Iteration 4420, lr = 0.0002
I0625 18:18:11.872769  4216 solver.cpp:228] Iteration 4440, loss = 0.380051
I0625 18:18:11.872797  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:18:11.872807  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323892 (* 1 = 0.0323892 loss)
I0625 18:18:11.872812  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0984707 (* 1 = 0.0984707 loss)
I0625 18:18:11.872815  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016923 (* 1 = 0.016923 loss)
I0625 18:18:11.872822  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023119 (* 1 = 0.023119 loss)
I0625 18:18:11.872828  4216 sgd_solver.cpp:106] Iteration 4440, lr = 0.0002
I0625 18:19:57.061785  4216 solver.cpp:228] Iteration 4460, loss = 0.358153
I0625 18:19:57.061811  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 18:19:57.061820  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0888113 (* 1 = 0.0888113 loss)
I0625 18:19:57.061825  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.167479 (* 1 = 0.167479 loss)
I0625 18:19:57.061828  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181623 (* 1 = 0.00181623 loss)
I0625 18:19:57.061832  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189292 (* 1 = 0.0189292 loss)
I0625 18:19:57.061838  4216 sgd_solver.cpp:106] Iteration 4460, lr = 0.0002
I0625 18:21:42.200899  4216 solver.cpp:228] Iteration 4480, loss = 0.255585
I0625 18:21:42.200932  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 18:21:42.200938  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.129862 (* 1 = 0.129862 loss)
I0625 18:21:42.200943  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.322486 (* 1 = 0.322486 loss)
I0625 18:21:42.200947  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0291304 (* 1 = 0.0291304 loss)
I0625 18:21:42.200950  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0811287 (* 1 = 0.0811287 loss)
I0625 18:21:42.200956  4216 sgd_solver.cpp:106] Iteration 4480, lr = 0.0002
I0625 18:23:27.388846  4216 solver.cpp:228] Iteration 4500, loss = 0.474837
I0625 18:23:27.388871  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 18:23:27.388878  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225774 (* 1 = 0.0225774 loss)
I0625 18:23:27.388882  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0392177 (* 1 = 0.0392177 loss)
I0625 18:23:27.388887  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00666191 (* 1 = 0.00666191 loss)
I0625 18:23:27.388891  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0081843 (* 1 = 0.0081843 loss)
I0625 18:23:27.388895  4216 sgd_solver.cpp:106] Iteration 4500, lr = 0.0002
I0625 18:25:12.447404  4216 solver.cpp:228] Iteration 4520, loss = 0.36236
I0625 18:25:12.447427  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 18:25:12.447435  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00017951 (* 1 = 0.00017951 loss)
I0625 18:25:12.447440  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0437804 (* 1 = 0.0437804 loss)
I0625 18:25:12.447444  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00214211 (* 1 = 0.00214211 loss)
I0625 18:25:12.447448  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00816394 (* 1 = 0.00816394 loss)
I0625 18:25:12.447454  4216 sgd_solver.cpp:106] Iteration 4520, lr = 0.0002
I0625 18:26:57.633977  4216 solver.cpp:228] Iteration 4540, loss = 0.366709
I0625 18:26:57.634002  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 18:26:57.634011  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233234 (* 1 = 0.0233234 loss)
I0625 18:26:57.634014  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.13384 (* 1 = 0.13384 loss)
I0625 18:26:57.634018  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00608854 (* 1 = 0.00608854 loss)
I0625 18:26:57.634021  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132368 (* 1 = 0.0132368 loss)
I0625 18:26:57.634027  4216 sgd_solver.cpp:106] Iteration 4540, lr = 0.0002
I0625 18:28:42.826315  4216 solver.cpp:228] Iteration 4560, loss = 0.358433
I0625 18:28:42.826341  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0625 18:28:42.826349  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.297791 (* 1 = 0.297791 loss)
I0625 18:28:42.826354  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.533202 (* 1 = 0.533202 loss)
I0625 18:28:42.826359  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186462 (* 1 = 0.0186462 loss)
I0625 18:28:42.826361  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0972604 (* 1 = 0.0972604 loss)
I0625 18:28:42.826366  4216 sgd_solver.cpp:106] Iteration 4560, lr = 0.0002
I0625 18:30:27.995379  4216 solver.cpp:228] Iteration 4580, loss = 0.388142
I0625 18:30:27.995406  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 18:30:27.995415  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0343391 (* 1 = 0.0343391 loss)
I0625 18:30:27.995421  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.196155 (* 1 = 0.196155 loss)
I0625 18:30:27.995427  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197564 (* 1 = 0.0197564 loss)
I0625 18:30:27.995432  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00932886 (* 1 = 0.00932886 loss)
I0625 18:30:27.995440  4216 sgd_solver.cpp:106] Iteration 4580, lr = 0.0002
speed: 5.166s / iter
I0625 18:32:13.169816  4216 solver.cpp:228] Iteration 4600, loss = 0.359565
I0625 18:32:13.169842  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 18:32:13.169850  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.204656 (* 1 = 0.204656 loss)
I0625 18:32:13.169854  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.343681 (* 1 = 0.343681 loss)
I0625 18:32:13.169857  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115008 (* 1 = 0.0115008 loss)
I0625 18:32:13.169862  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012243 (* 1 = 0.012243 loss)
I0625 18:32:13.169867  4216 sgd_solver.cpp:106] Iteration 4600, lr = 0.0002
I0625 18:33:58.279180  4216 solver.cpp:228] Iteration 4620, loss = 0.340078
I0625 18:33:58.279206  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 18:33:58.279213  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0695793 (* 1 = 0.0695793 loss)
I0625 18:33:58.279218  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.168759 (* 1 = 0.168759 loss)
I0625 18:33:58.279222  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000872465 (* 1 = 0.000872465 loss)
I0625 18:33:58.279227  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481524 (* 1 = 0.0481524 loss)
I0625 18:33:58.279232  4216 sgd_solver.cpp:106] Iteration 4620, lr = 0.0002
I0625 18:35:43.482806  4216 solver.cpp:228] Iteration 4640, loss = 0.267009
I0625 18:35:43.482831  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:35:43.482838  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690437 (* 1 = 0.0690437 loss)
I0625 18:35:43.482842  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117722 (* 1 = 0.117722 loss)
I0625 18:35:43.482846  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104616 (* 1 = 0.00104616 loss)
I0625 18:35:43.482851  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00937111 (* 1 = 0.00937111 loss)
I0625 18:35:43.482856  4216 sgd_solver.cpp:106] Iteration 4640, lr = 0.0002
I0625 18:37:28.669307  4216 solver.cpp:228] Iteration 4660, loss = 0.367787
I0625 18:37:28.669333  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 18:37:28.669342  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0865146 (* 1 = 0.0865146 loss)
I0625 18:37:28.669345  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.309382 (* 1 = 0.309382 loss)
I0625 18:37:28.669349  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636437 (* 1 = 0.00636437 loss)
I0625 18:37:28.669353  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110027 (* 1 = 0.0110027 loss)
I0625 18:37:28.669358  4216 sgd_solver.cpp:106] Iteration 4660, lr = 0.0002
I0625 18:39:13.790741  4216 solver.cpp:228] Iteration 4680, loss = 0.248338
I0625 18:39:13.790766  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:39:13.790773  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0923909 (* 1 = 0.0923909 loss)
I0625 18:39:13.790777  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.120455 (* 1 = 0.120455 loss)
I0625 18:39:13.790781  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00247413 (* 1 = 0.00247413 loss)
I0625 18:39:13.790784  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139841 (* 1 = 0.0139841 loss)
I0625 18:39:13.790789  4216 sgd_solver.cpp:106] Iteration 4680, lr = 0.0002
I0625 18:40:59.012079  4216 solver.cpp:228] Iteration 4700, loss = 0.436868
I0625 18:40:59.012104  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 18:40:59.012114  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.138211 (* 1 = 0.138211 loss)
I0625 18:40:59.012117  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.210005 (* 1 = 0.210005 loss)
I0625 18:40:59.012121  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00459835 (* 1 = 0.00459835 loss)
I0625 18:40:59.012125  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186476 (* 1 = 0.0186476 loss)
I0625 18:40:59.012130  4216 sgd_solver.cpp:106] Iteration 4700, lr = 0.0002
I0625 18:42:44.201676  4216 solver.cpp:228] Iteration 4720, loss = 0.592385
I0625 18:42:44.201704  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:42:44.201714  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.098323 (* 1 = 0.098323 loss)
I0625 18:42:44.201719  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119823 (* 1 = 0.119823 loss)
I0625 18:42:44.201723  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000546935 (* 1 = 0.000546935 loss)
I0625 18:42:44.201728  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0078001 (* 1 = 0.0078001 loss)
I0625 18:42:44.201733  4216 sgd_solver.cpp:106] Iteration 4720, lr = 0.0002
I0625 18:44:29.421540  4216 solver.cpp:228] Iteration 4740, loss = 0.481787
I0625 18:44:29.421566  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 18:44:29.421576  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634489 (* 1 = 0.0634489 loss)
I0625 18:44:29.421583  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.130654 (* 1 = 0.130654 loss)
I0625 18:44:29.421591  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00138189 (* 1 = 0.00138189 loss)
I0625 18:44:29.421597  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00253298 (* 1 = 0.00253298 loss)
I0625 18:44:29.421604  4216 sgd_solver.cpp:106] Iteration 4740, lr = 0.0002
I0625 18:46:14.564013  4216 solver.cpp:228] Iteration 4760, loss = 0.372779
I0625 18:46:14.564038  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 18:46:14.564044  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.228819 (* 1 = 0.228819 loss)
I0625 18:46:14.564049  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.391056 (* 1 = 0.391056 loss)
I0625 18:46:14.564052  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024175 (* 1 = 0.024175 loss)
I0625 18:46:14.564056  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0818125 (* 1 = 0.0818125 loss)
I0625 18:46:14.564061  4216 sgd_solver.cpp:106] Iteration 4760, lr = 0.0002
I0625 18:47:59.746357  4216 solver.cpp:228] Iteration 4780, loss = 0.487828
I0625 18:47:59.746379  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0625 18:47:59.746387  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.197111 (* 1 = 0.197111 loss)
I0625 18:47:59.746390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.653423 (* 1 = 0.653423 loss)
I0625 18:47:59.746394  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0585246 (* 1 = 0.0585246 loss)
I0625 18:47:59.746397  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.152044 (* 1 = 0.152044 loss)
I0625 18:47:59.746402  4216 sgd_solver.cpp:106] Iteration 4780, lr = 0.0002
speed: 5.170s / iter
I0625 18:49:44.891558  4216 solver.cpp:228] Iteration 4800, loss = 0.239293
I0625 18:49:44.891583  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:49:44.891590  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379528 (* 1 = 0.0379528 loss)
I0625 18:49:44.891594  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0640688 (* 1 = 0.0640688 loss)
I0625 18:49:44.891598  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00295515 (* 1 = 0.00295515 loss)
I0625 18:49:44.891602  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00605706 (* 1 = 0.00605706 loss)
I0625 18:49:44.891607  4216 sgd_solver.cpp:106] Iteration 4800, lr = 0.0002
I0625 18:51:30.089642  4216 solver.cpp:228] Iteration 4820, loss = 0.373016
I0625 18:51:30.089664  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0625 18:51:30.089673  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121 (* 1 = 0.121 loss)
I0625 18:51:30.089679  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.281651 (* 1 = 0.281651 loss)
I0625 18:51:30.089685  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0240856 (* 1 = 0.0240856 loss)
I0625 18:51:30.089690  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0456624 (* 1 = 0.0456624 loss)
I0625 18:51:30.089696  4216 sgd_solver.cpp:106] Iteration 4820, lr = 0.0002
I0625 18:53:15.250262  4216 solver.cpp:228] Iteration 4840, loss = 0.368615
I0625 18:53:15.250288  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 18:53:15.250294  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373867 (* 1 = 0.0373867 loss)
I0625 18:53:15.250298  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.140131 (* 1 = 0.140131 loss)
I0625 18:53:15.250301  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00735162 (* 1 = 0.00735162 loss)
I0625 18:53:15.250305  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00293828 (* 1 = 0.00293828 loss)
I0625 18:53:15.250310  4216 sgd_solver.cpp:106] Iteration 4840, lr = 0.0002
I0625 18:55:00.433061  4216 solver.cpp:228] Iteration 4860, loss = 0.199452
I0625 18:55:00.433084  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 18:55:00.433092  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.042957 (* 1 = 0.042957 loss)
I0625 18:55:00.433097  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.100321 (* 1 = 0.100321 loss)
I0625 18:55:00.433101  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00649462 (* 1 = 0.00649462 loss)
I0625 18:55:00.433105  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137528 (* 1 = 0.0137528 loss)
I0625 18:55:00.433111  4216 sgd_solver.cpp:106] Iteration 4860, lr = 0.0002
I0625 18:56:45.550550  4216 solver.cpp:228] Iteration 4880, loss = 0.306391
I0625 18:56:45.550575  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0625 18:56:45.550582  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.260158 (* 1 = 0.260158 loss)
I0625 18:56:45.550588  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.453751 (* 1 = 0.453751 loss)
I0625 18:56:45.550593  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00942425 (* 1 = 0.00942425 loss)
I0625 18:56:45.550597  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0360235 (* 1 = 0.0360235 loss)
I0625 18:56:45.550603  4216 sgd_solver.cpp:106] Iteration 4880, lr = 0.0002
I0625 18:58:30.554172  4216 solver.cpp:228] Iteration 4900, loss = 0.232008
I0625 18:58:30.554196  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 18:58:30.554203  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0343081 (* 1 = 0.0343081 loss)
I0625 18:58:30.554208  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.165845 (* 1 = 0.165845 loss)
I0625 18:58:30.554211  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275164 (* 1 = 0.00275164 loss)
I0625 18:58:30.554215  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0545502 (* 1 = 0.0545502 loss)
I0625 18:58:30.554219  4216 sgd_solver.cpp:106] Iteration 4900, lr = 0.0002
I0625 19:00:15.725561  4216 solver.cpp:228] Iteration 4920, loss = 0.332628
I0625 19:00:15.725586  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 19:00:15.725594  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0153393 (* 1 = 0.0153393 loss)
I0625 19:00:15.725597  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0561413 (* 1 = 0.0561413 loss)
I0625 19:00:15.725601  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271867 (* 1 = 0.00271867 loss)
I0625 19:00:15.725605  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119 (* 1 = 0.0119 loss)
I0625 19:00:15.725610  4216 sgd_solver.cpp:106] Iteration 4920, lr = 0.0002
I0625 19:02:00.885978  4216 solver.cpp:228] Iteration 4940, loss = 0.18739
I0625 19:02:00.886003  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:02:00.886009  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0489001 (* 1 = 0.0489001 loss)
I0625 19:02:00.886014  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0579732 (* 1 = 0.0579732 loss)
I0625 19:02:00.886018  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000887315 (* 1 = 0.000887315 loss)
I0625 19:02:00.886021  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111489 (* 1 = 0.0111489 loss)
I0625 19:02:00.886026  4216 sgd_solver.cpp:106] Iteration 4940, lr = 0.0002
I0625 19:03:46.115249  4216 solver.cpp:228] Iteration 4960, loss = 0.662752
I0625 19:03:46.115276  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 19:03:46.115284  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104267 (* 1 = 0.104267 loss)
I0625 19:03:46.115289  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.191663 (* 1 = 0.191663 loss)
I0625 19:03:46.115293  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00451748 (* 1 = 0.00451748 loss)
I0625 19:03:46.115298  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137284 (* 1 = 0.0137284 loss)
I0625 19:03:46.115303  4216 sgd_solver.cpp:106] Iteration 4960, lr = 0.0002
I0625 19:05:31.305654  4216 solver.cpp:228] Iteration 4980, loss = 0.332346
I0625 19:05:31.305678  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 19:05:31.305685  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233348 (* 1 = 0.0233348 loss)
I0625 19:05:31.305689  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0618415 (* 1 = 0.0618415 loss)
I0625 19:05:31.305693  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000862367 (* 1 = 0.000862367 loss)
I0625 19:05:31.305697  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00953055 (* 1 = 0.00953055 loss)
I0625 19:05:31.305702  4216 sgd_solver.cpp:106] Iteration 4980, lr = 0.0002
speed: 5.173s / iter
I0625 19:07:11.590191  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_5000.caffemodel
I0625 19:07:17.254401  4216 solver.cpp:228] Iteration 5000, loss = 0.177051
I0625 19:07:17.254428  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:07:17.254436  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272024 (* 1 = 0.0272024 loss)
I0625 19:07:17.254441  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0715918 (* 1 = 0.0715918 loss)
I0625 19:07:17.254444  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000910724 (* 1 = 0.000910724 loss)
I0625 19:07:17.254448  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00972665 (* 1 = 0.00972665 loss)
I0625 19:07:17.254454  4216 sgd_solver.cpp:106] Iteration 5000, lr = 0.0002
I0625 19:09:02.358121  4216 solver.cpp:228] Iteration 5020, loss = 0.427034
I0625 19:09:02.358145  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 19:09:02.358152  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.171429 (* 1 = 0.171429 loss)
I0625 19:09:02.358156  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.216665 (* 1 = 0.216665 loss)
I0625 19:09:02.358160  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116822 (* 1 = 0.0116822 loss)
I0625 19:09:02.358163  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387866 (* 1 = 0.0387866 loss)
I0625 19:09:02.358168  4216 sgd_solver.cpp:106] Iteration 5020, lr = 0.0002
I0625 19:10:47.448901  4216 solver.cpp:228] Iteration 5040, loss = 0.452236
I0625 19:10:47.448925  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0625 19:10:47.448932  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.222018 (* 1 = 0.222018 loss)
I0625 19:10:47.448936  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.5236 (* 1 = 0.5236 loss)
I0625 19:10:47.448940  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162575 (* 1 = 0.0162575 loss)
I0625 19:10:47.448943  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0711527 (* 1 = 0.0711527 loss)
I0625 19:10:47.448948  4216 sgd_solver.cpp:106] Iteration 5040, lr = 0.0002
I0625 19:12:32.572635  4216 solver.cpp:228] Iteration 5060, loss = 0.309734
I0625 19:12:32.572661  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 19:12:32.572669  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.115465 (* 1 = 0.115465 loss)
I0625 19:12:32.572674  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.263407 (* 1 = 0.263407 loss)
I0625 19:12:32.572677  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00310245 (* 1 = 0.00310245 loss)
I0625 19:12:32.572681  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00503489 (* 1 = 0.00503489 loss)
I0625 19:12:32.572686  4216 sgd_solver.cpp:106] Iteration 5060, lr = 0.0002
I0625 19:14:17.697738  4216 solver.cpp:228] Iteration 5080, loss = 0.273353
I0625 19:14:17.697765  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 19:14:17.697774  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000937972 (* 1 = 0.000937972 loss)
I0625 19:14:17.697778  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0452007 (* 1 = 0.0452007 loss)
I0625 19:14:17.697782  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00164211 (* 1 = 0.00164211 loss)
I0625 19:14:17.697787  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01651 (* 1 = 0.01651 loss)
I0625 19:14:17.697793  4216 sgd_solver.cpp:106] Iteration 5080, lr = 0.0002
I0625 19:16:02.806668  4216 solver.cpp:228] Iteration 5100, loss = 0.355418
I0625 19:16:02.806691  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 19:16:02.806700  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.18899 (* 1 = 0.18899 loss)
I0625 19:16:02.806706  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.174011 (* 1 = 0.174011 loss)
I0625 19:16:02.806712  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00878065 (* 1 = 0.00878065 loss)
I0625 19:16:02.806718  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110736 (* 1 = 0.0110736 loss)
I0625 19:16:02.806725  4216 sgd_solver.cpp:106] Iteration 5100, lr = 0.0002
I0625 19:17:47.984907  4216 solver.cpp:228] Iteration 5120, loss = 0.457169
I0625 19:17:47.984935  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 19:17:47.984944  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.288604 (* 1 = 0.288604 loss)
I0625 19:17:47.984951  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.476899 (* 1 = 0.476899 loss)
I0625 19:17:47.984957  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246807 (* 1 = 0.0246807 loss)
I0625 19:17:47.984963  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0628138 (* 1 = 0.0628138 loss)
I0625 19:17:47.984969  4216 sgd_solver.cpp:106] Iteration 5120, lr = 0.0002
I0625 19:19:33.181653  4216 solver.cpp:228] Iteration 5140, loss = 0.354665
I0625 19:19:33.181679  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 19:19:33.181686  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.214801 (* 1 = 0.214801 loss)
I0625 19:19:33.181690  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.226845 (* 1 = 0.226845 loss)
I0625 19:19:33.181695  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00596503 (* 1 = 0.00596503 loss)
I0625 19:19:33.181699  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374135 (* 1 = 0.0374135 loss)
I0625 19:19:33.181704  4216 sgd_solver.cpp:106] Iteration 5140, lr = 0.0002
I0625 19:21:18.349463  4216 solver.cpp:228] Iteration 5160, loss = 0.180772
I0625 19:21:18.349489  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 19:21:18.349496  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0545361 (* 1 = 0.0545361 loss)
I0625 19:21:18.349500  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0755647 (* 1 = 0.0755647 loss)
I0625 19:21:18.349504  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000295077 (* 1 = 0.000295077 loss)
I0625 19:21:18.349508  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143751 (* 1 = 0.0143751 loss)
I0625 19:21:18.349512  4216 sgd_solver.cpp:106] Iteration 5160, lr = 0.0002
I0625 19:23:03.539675  4216 solver.cpp:228] Iteration 5180, loss = 0.176943
I0625 19:23:03.539700  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 19:23:03.539708  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.11196 (* 1 = 0.11196 loss)
I0625 19:23:03.539713  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.113874 (* 1 = 0.113874 loss)
I0625 19:23:03.539717  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000517391 (* 1 = 0.000517391 loss)
I0625 19:23:03.539721  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286456 (* 1 = 0.0286456 loss)
I0625 19:23:03.539726  4216 sgd_solver.cpp:106] Iteration 5180, lr = 0.0002
speed: 5.176s / iter
I0625 19:24:48.736176  4216 solver.cpp:228] Iteration 5200, loss = 0.411918
I0625 19:24:48.736199  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 19:24:48.736207  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475256 (* 1 = 0.0475256 loss)
I0625 19:24:48.736212  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0600744 (* 1 = 0.0600744 loss)
I0625 19:24:48.736215  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00578599 (* 1 = 0.00578599 loss)
I0625 19:24:48.736218  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105664 (* 1 = 0.0105664 loss)
I0625 19:24:48.736223  4216 sgd_solver.cpp:106] Iteration 5200, lr = 0.0002
I0625 19:26:33.920159  4216 solver.cpp:228] Iteration 5220, loss = 0.517989
I0625 19:26:33.920186  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 19:26:33.920192  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613528 (* 1 = 0.0613528 loss)
I0625 19:26:33.920197  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.177156 (* 1 = 0.177156 loss)
I0625 19:26:33.920202  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133932 (* 1 = 0.00133932 loss)
I0625 19:26:33.920205  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0046016 (* 1 = 0.0046016 loss)
I0625 19:26:33.920210  4216 sgd_solver.cpp:106] Iteration 5220, lr = 0.0002
I0625 19:28:19.114796  4216 solver.cpp:228] Iteration 5240, loss = 0.613119
I0625 19:28:19.114823  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0625 19:28:19.114831  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.208104 (* 1 = 0.208104 loss)
I0625 19:28:19.114835  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.410058 (* 1 = 0.410058 loss)
I0625 19:28:19.114840  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0090344 (* 1 = 0.0090344 loss)
I0625 19:28:19.114843  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329901 (* 1 = 0.0329901 loss)
I0625 19:28:19.114848  4216 sgd_solver.cpp:106] Iteration 5240, lr = 0.0002
I0625 19:30:04.485110  4216 solver.cpp:228] Iteration 5260, loss = 0.284169
I0625 19:30:04.485137  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 19:30:04.485147  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241701 (* 1 = 0.0241701 loss)
I0625 19:30:04.485154  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0722336 (* 1 = 0.0722336 loss)
I0625 19:30:04.485160  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00472294 (* 1 = 0.00472294 loss)
I0625 19:30:04.485167  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00629722 (* 1 = 0.00629722 loss)
I0625 19:30:04.485173  4216 sgd_solver.cpp:106] Iteration 5260, lr = 0.0002
I0625 19:31:49.614279  4216 solver.cpp:228] Iteration 5280, loss = 0.443191
I0625 19:31:49.614302  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 19:31:49.614310  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.269628 (* 1 = 0.269628 loss)
I0625 19:31:49.614315  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.503807 (* 1 = 0.503807 loss)
I0625 19:31:49.614317  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0651489 (* 1 = 0.0651489 loss)
I0625 19:31:49.614321  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.06818 (* 1 = 0.06818 loss)
I0625 19:31:49.614326  4216 sgd_solver.cpp:106] Iteration 5280, lr = 0.0002
I0625 19:33:34.810559  4216 solver.cpp:228] Iteration 5300, loss = 0.300573
I0625 19:33:34.810581  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0625 19:33:34.810588  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.238582 (* 1 = 0.238582 loss)
I0625 19:33:34.810592  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.488608 (* 1 = 0.488608 loss)
I0625 19:33:34.810596  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245808 (* 1 = 0.0245808 loss)
I0625 19:33:34.810600  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525514 (* 1 = 0.0525514 loss)
I0625 19:33:34.810605  4216 sgd_solver.cpp:106] Iteration 5300, lr = 0.0002
I0625 19:35:19.968125  4216 solver.cpp:228] Iteration 5320, loss = 0.410782
I0625 19:35:19.968150  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 19:35:19.968158  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.132182 (* 1 = 0.132182 loss)
I0625 19:35:19.968160  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.317608 (* 1 = 0.317608 loss)
I0625 19:35:19.968164  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00478013 (* 1 = 0.00478013 loss)
I0625 19:35:19.968168  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028044 (* 1 = 0.028044 loss)
I0625 19:35:19.968173  4216 sgd_solver.cpp:106] Iteration 5320, lr = 0.0002
I0625 19:37:05.096863  4216 solver.cpp:228] Iteration 5340, loss = 0.277946
I0625 19:37:05.096889  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:37:05.096896  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169871 (* 1 = 0.0169871 loss)
I0625 19:37:05.096900  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.143275 (* 1 = 0.143275 loss)
I0625 19:37:05.096904  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104338 (* 1 = 0.0104338 loss)
I0625 19:37:05.096909  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00394854 (* 1 = 0.00394854 loss)
I0625 19:37:05.096913  4216 sgd_solver.cpp:106] Iteration 5340, lr = 0.0002
I0625 19:38:50.286293  4216 solver.cpp:228] Iteration 5360, loss = 0.420921
I0625 19:38:50.286317  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 19:38:50.286324  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.31865 (* 1 = 0.31865 loss)
I0625 19:38:50.286329  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.441085 (* 1 = 0.441085 loss)
I0625 19:38:50.286332  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0220675 (* 1 = 0.0220675 loss)
I0625 19:38:50.286335  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0536437 (* 1 = 0.0536437 loss)
I0625 19:38:50.286340  4216 sgd_solver.cpp:106] Iteration 5360, lr = 0.0002
I0625 19:40:35.419631  4216 solver.cpp:228] Iteration 5380, loss = 0.225727
I0625 19:40:35.419657  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 19:40:35.419667  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240015 (* 1 = 0.0240015 loss)
I0625 19:40:35.419672  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0985444 (* 1 = 0.0985444 loss)
I0625 19:40:35.419679  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00981339 (* 1 = 0.00981339 loss)
I0625 19:40:35.419685  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00709824 (* 1 = 0.00709824 loss)
I0625 19:40:35.419692  4216 sgd_solver.cpp:106] Iteration 5380, lr = 0.0002
speed: 5.179s / iter
I0625 19:42:20.598848  4216 solver.cpp:228] Iteration 5400, loss = 0.180371
I0625 19:42:20.598882  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 19:42:20.598891  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000343737 (* 1 = 0.000343737 loss)
I0625 19:42:20.598896  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0575679 (* 1 = 0.0575679 loss)
I0625 19:42:20.598898  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173929 (* 1 = 0.0173929 loss)
I0625 19:42:20.598902  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134828 (* 1 = 0.0134828 loss)
I0625 19:42:20.598907  4216 sgd_solver.cpp:106] Iteration 5400, lr = 0.0002
I0625 19:44:05.809197  4216 solver.cpp:228] Iteration 5420, loss = 0.213883
I0625 19:44:05.809221  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 19:44:05.809228  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.105753 (* 1 = 0.105753 loss)
I0625 19:44:05.809232  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.230654 (* 1 = 0.230654 loss)
I0625 19:44:05.809236  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359597 (* 1 = 0.00359597 loss)
I0625 19:44:05.809239  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014112 (* 1 = 0.014112 loss)
I0625 19:44:05.809243  4216 sgd_solver.cpp:106] Iteration 5420, lr = 0.0002
I0625 19:45:51.004818  4216 solver.cpp:228] Iteration 5440, loss = 0.19475
I0625 19:45:51.004843  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 19:45:51.004851  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.148019 (* 1 = 0.148019 loss)
I0625 19:45:51.004855  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.224615 (* 1 = 0.224615 loss)
I0625 19:45:51.004859  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00180484 (* 1 = 0.00180484 loss)
I0625 19:45:51.004863  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134457 (* 1 = 0.0134457 loss)
I0625 19:45:51.004868  4216 sgd_solver.cpp:106] Iteration 5440, lr = 0.0002
I0625 19:47:36.188619  4216 solver.cpp:228] Iteration 5460, loss = 0.506385
I0625 19:47:36.188655  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 19:47:36.188663  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.149039 (* 1 = 0.149039 loss)
I0625 19:47:36.188668  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.342104 (* 1 = 0.342104 loss)
I0625 19:47:36.188671  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134081 (* 1 = 0.0134081 loss)
I0625 19:47:36.188675  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339233 (* 1 = 0.0339233 loss)
I0625 19:47:36.188681  4216 sgd_solver.cpp:106] Iteration 5460, lr = 0.0002
I0625 19:49:21.372558  4216 solver.cpp:228] Iteration 5480, loss = 0.29145
I0625 19:49:21.372584  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 19:49:21.372594  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.014259 (* 1 = 0.014259 loss)
I0625 19:49:21.372601  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.089422 (* 1 = 0.089422 loss)
I0625 19:49:21.372606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000502122 (* 1 = 0.000502122 loss)
I0625 19:49:21.372613  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0354592 (* 1 = 0.0354592 loss)
I0625 19:49:21.372620  4216 sgd_solver.cpp:106] Iteration 5480, lr = 0.0002
I0625 19:51:08.062969  4216 solver.cpp:228] Iteration 5500, loss = 0.40212
I0625 19:51:08.062994  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 19:51:08.063002  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00018705 (* 1 = 0.00018705 loss)
I0625 19:51:08.063006  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.02869 (* 1 = 0.02869 loss)
I0625 19:51:08.063010  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109771 (* 1 = 0.00109771 loss)
I0625 19:51:08.063014  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125522 (* 1 = 0.0125522 loss)
I0625 19:51:08.063019  4216 sgd_solver.cpp:106] Iteration 5500, lr = 0.0002
I0625 19:52:55.226883  4216 solver.cpp:228] Iteration 5520, loss = 0.321974
I0625 19:52:55.226912  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 19:52:55.226919  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.157195 (* 1 = 0.157195 loss)
I0625 19:52:55.226923  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.251433 (* 1 = 0.251433 loss)
I0625 19:52:55.226928  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00185243 (* 1 = 0.00185243 loss)
I0625 19:52:55.226933  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130712 (* 1 = 0.0130712 loss)
I0625 19:52:55.226938  4216 sgd_solver.cpp:106] Iteration 5520, lr = 0.0002
I0625 19:54:41.941078  4216 solver.cpp:228] Iteration 5540, loss = 0.529663
I0625 19:54:41.941104  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 19:54:41.941112  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0722916 (* 1 = 0.0722916 loss)
I0625 19:54:41.941117  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117395 (* 1 = 0.117395 loss)
I0625 19:54:41.941120  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00681031 (* 1 = 0.00681031 loss)
I0625 19:54:41.941125  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445318 (* 1 = 0.0445318 loss)
I0625 19:54:41.941130  4216 sgd_solver.cpp:106] Iteration 5540, lr = 0.0002
I0625 19:56:28.187949  4216 solver.cpp:228] Iteration 5560, loss = 0.379985
I0625 19:56:28.187978  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 19:56:28.187984  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.17073 (* 1 = 0.17073 loss)
I0625 19:56:28.187988  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.22691 (* 1 = 0.22691 loss)
I0625 19:56:28.187993  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00732899 (* 1 = 0.00732899 loss)
I0625 19:56:28.187996  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273682 (* 1 = 0.0273682 loss)
I0625 19:56:28.188001  4216 sgd_solver.cpp:106] Iteration 5560, lr = 0.0002
I0625 19:58:13.853890  4216 solver.cpp:228] Iteration 5580, loss = 0.532916
I0625 19:58:13.853942  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 19:58:13.853952  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729192 (* 1 = 0.0729192 loss)
I0625 19:58:13.853956  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.140774 (* 1 = 0.140774 loss)
I0625 19:58:13.853960  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000212415 (* 1 = 0.000212415 loss)
I0625 19:58:13.853965  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0436569 (* 1 = 0.0436569 loss)
I0625 19:58:13.853973  4216 sgd_solver.cpp:106] Iteration 5580, lr = 0.0002
speed: 5.184s / iter
I0625 20:00:00.022929  4216 solver.cpp:228] Iteration 5600, loss = 0.461168
I0625 20:00:00.022953  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 20:00:00.022960  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.15849 (* 1 = 0.15849 loss)
I0625 20:00:00.022965  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.368869 (* 1 = 0.368869 loss)
I0625 20:00:00.022969  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0236657 (* 1 = 0.0236657 loss)
I0625 20:00:00.022974  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271372 (* 1 = 0.0271372 loss)
I0625 20:00:00.022979  4216 sgd_solver.cpp:106] Iteration 5600, lr = 0.0002
I0625 20:01:46.377234  4216 solver.cpp:228] Iteration 5620, loss = 0.260016
I0625 20:01:46.377259  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:01:46.377267  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392203 (* 1 = 0.0392203 loss)
I0625 20:01:46.377271  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0868259 (* 1 = 0.0868259 loss)
I0625 20:01:46.377275  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00455207 (* 1 = 0.00455207 loss)
I0625 20:01:46.377279  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168942 (* 1 = 0.0168942 loss)
I0625 20:01:46.377285  4216 sgd_solver.cpp:106] Iteration 5620, lr = 0.0002
I0625 20:03:33.279266  4216 solver.cpp:228] Iteration 5640, loss = 0.221212
I0625 20:03:33.279294  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 20:03:33.279301  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000282172 (* 1 = 0.000282172 loss)
I0625 20:03:33.279306  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0482352 (* 1 = 0.0482352 loss)
I0625 20:03:33.279310  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.008743 (* 1 = 0.008743 loss)
I0625 20:03:33.279314  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122657 (* 1 = 0.0122657 loss)
I0625 20:03:33.279319  4216 sgd_solver.cpp:106] Iteration 5640, lr = 0.0002
I0625 20:05:20.764605  4216 solver.cpp:228] Iteration 5660, loss = 0.383629
I0625 20:05:20.764633  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0625 20:05:20.764642  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.277422 (* 1 = 0.277422 loss)
I0625 20:05:20.764645  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.455073 (* 1 = 0.455073 loss)
I0625 20:05:20.764649  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00378405 (* 1 = 0.00378405 loss)
I0625 20:05:20.764652  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0486344 (* 1 = 0.0486344 loss)
I0625 20:05:20.764658  4216 sgd_solver.cpp:106] Iteration 5660, lr = 0.0002
I0625 20:07:08.384109  4216 solver.cpp:228] Iteration 5680, loss = 0.142581
I0625 20:07:08.384136  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:07:08.384145  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0227017 (* 1 = 0.0227017 loss)
I0625 20:07:08.384150  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.071276 (* 1 = 0.071276 loss)
I0625 20:07:08.384153  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000891692 (* 1 = 0.000891692 loss)
I0625 20:07:08.384157  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00450487 (* 1 = 0.00450487 loss)
I0625 20:07:08.384162  4216 sgd_solver.cpp:106] Iteration 5680, lr = 0.0002
I0625 20:08:56.213068  4216 solver.cpp:228] Iteration 5700, loss = 0.314181
I0625 20:08:56.213093  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0625 20:08:56.213100  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.201374 (* 1 = 0.201374 loss)
I0625 20:08:56.213104  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.468026 (* 1 = 0.468026 loss)
I0625 20:08:56.213109  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00531954 (* 1 = 0.00531954 loss)
I0625 20:08:56.213112  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451571 (* 1 = 0.0451571 loss)
I0625 20:08:56.213117  4216 sgd_solver.cpp:106] Iteration 5700, lr = 0.0002
I0625 20:10:43.744973  4216 solver.cpp:228] Iteration 5720, loss = 0.262628
I0625 20:10:43.745002  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:10:43.745010  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571998 (* 1 = 0.0571998 loss)
I0625 20:10:43.745014  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0867469 (* 1 = 0.0867469 loss)
I0625 20:10:43.745018  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000795323 (* 1 = 0.000795323 loss)
I0625 20:10:43.745023  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00679055 (* 1 = 0.00679055 loss)
I0625 20:10:43.745028  4216 sgd_solver.cpp:106] Iteration 5720, lr = 0.0002
I0625 20:12:30.346565  4216 solver.cpp:228] Iteration 5740, loss = 0.654355
I0625 20:12:30.346590  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:12:30.346598  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241411 (* 1 = 0.0241411 loss)
I0625 20:12:30.346603  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0755043 (* 1 = 0.0755043 loss)
I0625 20:12:30.346607  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000932348 (* 1 = 0.000932348 loss)
I0625 20:12:30.346611  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00735637 (* 1 = 0.00735637 loss)
I0625 20:12:30.346616  4216 sgd_solver.cpp:106] Iteration 5740, lr = 0.0002
I0625 20:14:17.620126  4216 solver.cpp:228] Iteration 5760, loss = 0.289222
I0625 20:14:17.620153  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 20:14:17.620162  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000178782 (* 1 = 0.000178782 loss)
I0625 20:14:17.620167  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0391217 (* 1 = 0.0391217 loss)
I0625 20:14:17.620170  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029138 (* 1 = 0.0029138 loss)
I0625 20:14:17.620173  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175278 (* 1 = 0.0175278 loss)
I0625 20:14:17.620179  4216 sgd_solver.cpp:106] Iteration 5760, lr = 0.0002
I0625 20:16:04.460973  4216 solver.cpp:228] Iteration 5780, loss = 0.2298
I0625 20:16:04.460999  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 20:16:04.461005  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236448 (* 1 = 0.0236448 loss)
I0625 20:16:04.461009  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.12753 (* 1 = 0.12753 loss)
I0625 20:16:04.461014  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259434 (* 1 = 0.00259434 loss)
I0625 20:16:04.461017  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104484 (* 1 = 0.0104484 loss)
I0625 20:16:04.461021  4216 sgd_solver.cpp:106] Iteration 5780, lr = 0.0002
speed: 5.190s / iter
I0625 20:17:52.449839  4216 solver.cpp:228] Iteration 5800, loss = 0.55511
I0625 20:17:52.449870  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 20:17:52.449878  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.18194 (* 1 = 0.18194 loss)
I0625 20:17:52.449883  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.211968 (* 1 = 0.211968 loss)
I0625 20:17:52.449890  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00393159 (* 1 = 0.00393159 loss)
I0625 20:17:52.449895  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371712 (* 1 = 0.0371712 loss)
I0625 20:17:52.449901  4216 sgd_solver.cpp:106] Iteration 5800, lr = 0.0002
I0625 20:19:37.915746  4216 solver.cpp:228] Iteration 5820, loss = 0.178889
I0625 20:19:37.915773  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 20:19:37.915781  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.100489 (* 1 = 0.100489 loss)
I0625 20:19:37.915786  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.196728 (* 1 = 0.196728 loss)
I0625 20:19:37.915789  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109603 (* 1 = 0.0109603 loss)
I0625 20:19:37.915793  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189009 (* 1 = 0.0189009 loss)
I0625 20:19:37.915798  4216 sgd_solver.cpp:106] Iteration 5820, lr = 0.0002
I0625 20:21:24.254117  4216 solver.cpp:228] Iteration 5840, loss = 0.301161
I0625 20:21:24.254140  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 20:21:24.254148  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273159 (* 1 = 0.0273159 loss)
I0625 20:21:24.254153  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0447026 (* 1 = 0.0447026 loss)
I0625 20:21:24.254155  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00841922 (* 1 = 0.00841922 loss)
I0625 20:21:24.254159  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111134 (* 1 = 0.0111134 loss)
I0625 20:21:24.254163  4216 sgd_solver.cpp:106] Iteration 5840, lr = 0.0002
I0625 20:23:11.558346  4216 solver.cpp:228] Iteration 5860, loss = 0.273813
I0625 20:23:11.558373  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 20:23:11.558380  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460632 (* 1 = 0.0460632 loss)
I0625 20:23:11.558384  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.144064 (* 1 = 0.144064 loss)
I0625 20:23:11.558388  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124807 (* 1 = 0.0124807 loss)
I0625 20:23:11.558392  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204336 (* 1 = 0.0204336 loss)
I0625 20:23:11.558396  4216 sgd_solver.cpp:106] Iteration 5860, lr = 0.0002
I0625 20:24:58.216645  4216 solver.cpp:228] Iteration 5880, loss = 0.24558
I0625 20:24:58.216670  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 20:24:58.216678  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00804598 (* 1 = 0.00804598 loss)
I0625 20:24:58.216682  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0547841 (* 1 = 0.0547841 loss)
I0625 20:24:58.216686  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216062 (* 1 = 0.00216062 loss)
I0625 20:24:58.216691  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112753 (* 1 = 0.0112753 loss)
I0625 20:24:58.216696  4216 sgd_solver.cpp:106] Iteration 5880, lr = 0.0002
I0625 20:26:44.388748  4216 solver.cpp:228] Iteration 5900, loss = 0.286358
I0625 20:26:44.388774  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 20:26:44.388782  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0395494 (* 1 = 0.0395494 loss)
I0625 20:26:44.388785  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.161544 (* 1 = 0.161544 loss)
I0625 20:26:44.388789  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00203135 (* 1 = 0.00203135 loss)
I0625 20:26:44.388793  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180198 (* 1 = 0.0180198 loss)
I0625 20:26:44.388797  4216 sgd_solver.cpp:106] Iteration 5900, lr = 0.0002
I0625 20:28:31.890698  4216 solver.cpp:228] Iteration 5920, loss = 0.26701
I0625 20:28:31.890723  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 20:28:31.890732  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0619157 (* 1 = 0.0619157 loss)
I0625 20:28:31.890736  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.237596 (* 1 = 0.237596 loss)
I0625 20:28:31.890740  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101886 (* 1 = 0.0101886 loss)
I0625 20:28:31.890744  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0428469 (* 1 = 0.0428469 loss)
I0625 20:28:31.890749  4216 sgd_solver.cpp:106] Iteration 5920, lr = 0.0002
I0625 20:30:17.255506  4216 solver.cpp:228] Iteration 5940, loss = 0.363283
I0625 20:30:17.255533  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:30:17.255542  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.03864 (* 1 = 0.03864 loss)
I0625 20:30:17.255545  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0634568 (* 1 = 0.0634568 loss)
I0625 20:30:17.255549  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000617585 (* 1 = 0.000617585 loss)
I0625 20:30:17.255553  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00834777 (* 1 = 0.00834777 loss)
I0625 20:30:17.255558  4216 sgd_solver.cpp:106] Iteration 5940, lr = 0.0002
I0625 20:32:04.249466  4216 solver.cpp:228] Iteration 5960, loss = 0.299003
I0625 20:32:04.249490  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:32:04.249498  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0726376 (* 1 = 0.0726376 loss)
I0625 20:32:04.249502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121602 (* 1 = 0.121602 loss)
I0625 20:32:04.249506  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000665678 (* 1 = 0.000665678 loss)
I0625 20:32:04.249511  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133094 (* 1 = 0.0133094 loss)
I0625 20:32:04.249516  4216 sgd_solver.cpp:106] Iteration 5960, lr = 0.0002
I0625 20:33:50.937496  4216 solver.cpp:228] Iteration 5980, loss = 0.301622
I0625 20:33:50.937525  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 20:33:50.937532  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0798568 (* 1 = 0.0798568 loss)
I0625 20:33:50.937536  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.168388 (* 1 = 0.168388 loss)
I0625 20:33:50.937541  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600935 (* 1 = 0.00600935 loss)
I0625 20:33:50.937543  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173185 (* 1 = 0.0173185 loss)
I0625 20:33:50.937548  4216 sgd_solver.cpp:106] Iteration 5980, lr = 0.0002
speed: 5.195s / iter
I0625 20:35:39.186714  4216 solver.cpp:228] Iteration 6000, loss = 0.221672
I0625 20:35:39.186741  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:35:39.186750  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0532257 (* 1 = 0.0532257 loss)
I0625 20:35:39.186756  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0976476 (* 1 = 0.0976476 loss)
I0625 20:35:39.186761  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000512072 (* 1 = 0.000512072 loss)
I0625 20:35:39.186766  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00387937 (* 1 = 0.00387937 loss)
I0625 20:35:39.186772  4216 sgd_solver.cpp:106] Iteration 6000, lr = 0.0002
I0625 20:37:27.067979  4216 solver.cpp:228] Iteration 6020, loss = 0.123736
I0625 20:37:27.068006  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:37:27.068015  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0575577 (* 1 = 0.0575577 loss)
I0625 20:37:27.068022  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0576508 (* 1 = 0.0576508 loss)
I0625 20:37:27.068027  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127812 (* 1 = 0.00127812 loss)
I0625 20:37:27.068033  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00658773 (* 1 = 0.00658773 loss)
I0625 20:37:27.068039  4216 sgd_solver.cpp:106] Iteration 6020, lr = 0.0002
I0625 20:39:13.475548  4216 solver.cpp:228] Iteration 6040, loss = 0.468124
I0625 20:39:13.475574  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:39:13.475582  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0563135 (* 1 = 0.0563135 loss)
I0625 20:39:13.475589  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0668224 (* 1 = 0.0668224 loss)
I0625 20:39:13.475594  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0230474 (* 1 = 0.0230474 loss)
I0625 20:39:13.475600  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194206 (* 1 = 0.0194206 loss)
I0625 20:39:13.475607  4216 sgd_solver.cpp:106] Iteration 6040, lr = 0.0002
I0625 20:40:58.652665  4216 solver.cpp:228] Iteration 6060, loss = 0.168906
I0625 20:40:58.652694  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 20:40:58.652704  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708416 (* 1 = 0.0708416 loss)
I0625 20:40:58.652710  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.160594 (* 1 = 0.160594 loss)
I0625 20:40:58.652717  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00534897 (* 1 = 0.00534897 loss)
I0625 20:40:58.652724  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00815367 (* 1 = 0.00815367 loss)
I0625 20:40:58.652729  4216 sgd_solver.cpp:106] Iteration 6060, lr = 0.0002
I0625 20:42:43.862188  4216 solver.cpp:228] Iteration 6080, loss = 0.403846
I0625 20:42:43.862216  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0625 20:42:43.862224  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.379728 (* 1 = 0.379728 loss)
I0625 20:42:43.862231  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.671575 (* 1 = 0.671575 loss)
I0625 20:42:43.862236  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0391911 (* 1 = 0.0391911 loss)
I0625 20:42:43.862239  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.085696 (* 1 = 0.085696 loss)
I0625 20:42:43.862246  4216 sgd_solver.cpp:106] Iteration 6080, lr = 0.0002
I0625 20:44:30.009747  4216 solver.cpp:228] Iteration 6100, loss = 0.32402
I0625 20:44:30.009770  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 20:44:30.009779  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.084597 (* 1 = 0.084597 loss)
I0625 20:44:30.009784  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129721 (* 1 = 0.129721 loss)
I0625 20:44:30.009790  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0045997 (* 1 = 0.0045997 loss)
I0625 20:44:30.009795  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307639 (* 1 = 0.0307639 loss)
I0625 20:44:30.009801  4216 sgd_solver.cpp:106] Iteration 6100, lr = 0.0002
I0625 20:46:15.211637  4216 solver.cpp:228] Iteration 6120, loss = 0.356305
I0625 20:46:15.211661  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:46:15.211669  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215053 (* 1 = 0.0215053 loss)
I0625 20:46:15.211673  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0674348 (* 1 = 0.0674348 loss)
I0625 20:46:15.211678  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000516849 (* 1 = 0.000516849 loss)
I0625 20:46:15.211683  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00608674 (* 1 = 0.00608674 loss)
I0625 20:46:15.211688  4216 sgd_solver.cpp:106] Iteration 6120, lr = 0.0002
I0625 20:48:02.813827  4216 solver.cpp:228] Iteration 6140, loss = 0.385949
I0625 20:48:02.813851  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 20:48:02.813859  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544511 (* 1 = 0.0544511 loss)
I0625 20:48:02.813863  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.123698 (* 1 = 0.123698 loss)
I0625 20:48:02.813868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000695718 (* 1 = 0.000695718 loss)
I0625 20:48:02.813870  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00741957 (* 1 = 0.00741957 loss)
I0625 20:48:02.813875  4216 sgd_solver.cpp:106] Iteration 6140, lr = 0.0002
I0625 20:49:49.793288  4216 solver.cpp:228] Iteration 6160, loss = 0.277401
I0625 20:49:49.793320  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 20:49:49.793331  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.156499 (* 1 = 0.156499 loss)
I0625 20:49:49.793339  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.392709 (* 1 = 0.392709 loss)
I0625 20:49:49.793347  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00558054 (* 1 = 0.00558054 loss)
I0625 20:49:49.793355  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0735634 (* 1 = 0.0735634 loss)
I0625 20:49:49.793364  4216 sgd_solver.cpp:106] Iteration 6160, lr = 0.0002
I0625 20:51:37.887676  4216 solver.cpp:228] Iteration 6180, loss = 0.469262
I0625 20:51:37.887704  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 20:51:37.887712  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.199178 (* 1 = 0.199178 loss)
I0625 20:51:37.887715  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.358545 (* 1 = 0.358545 loss)
I0625 20:51:37.887720  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.037495 (* 1 = 0.037495 loss)
I0625 20:51:37.887725  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0518724 (* 1 = 0.0518724 loss)
I0625 20:51:37.887730  4216 sgd_solver.cpp:106] Iteration 6180, lr = 0.0002
speed: 5.199s / iter
I0625 20:53:24.166990  4216 solver.cpp:228] Iteration 6200, loss = 0.19552
I0625 20:53:24.167016  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:53:24.167026  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0512382 (* 1 = 0.0512382 loss)
I0625 20:53:24.167033  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.088318 (* 1 = 0.088318 loss)
I0625 20:53:24.167040  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000816372 (* 1 = 0.000816372 loss)
I0625 20:53:24.167047  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127805 (* 1 = 0.0127805 loss)
I0625 20:53:24.167057  4216 sgd_solver.cpp:106] Iteration 6200, lr = 0.0002
I0625 20:55:09.968924  4216 solver.cpp:228] Iteration 6220, loss = 0.493439
I0625 20:55:09.968953  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 20:55:09.968961  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437665 (* 1 = 0.0437665 loss)
I0625 20:55:09.968966  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0451085 (* 1 = 0.0451085 loss)
I0625 20:55:09.968971  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000553197 (* 1 = 0.000553197 loss)
I0625 20:55:09.968976  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100225 (* 1 = 0.0100225 loss)
I0625 20:55:09.968981  4216 sgd_solver.cpp:106] Iteration 6220, lr = 0.0002
I0625 20:56:57.101228  4216 solver.cpp:228] Iteration 6240, loss = 0.413537
I0625 20:56:57.101253  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0625 20:56:57.101260  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.402169 (* 1 = 0.402169 loss)
I0625 20:56:57.101264  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.651601 (* 1 = 0.651601 loss)
I0625 20:56:57.101269  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0175127 (* 1 = 0.0175127 loss)
I0625 20:56:57.101272  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113724 (* 1 = 0.113724 loss)
I0625 20:56:57.101277  4216 sgd_solver.cpp:106] Iteration 6240, lr = 0.0002
I0625 20:58:42.336594  4216 solver.cpp:228] Iteration 6260, loss = 0.361463
I0625 20:58:42.336618  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:58:42.336624  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0422567 (* 1 = 0.0422567 loss)
I0625 20:58:42.336628  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.133983 (* 1 = 0.133983 loss)
I0625 20:58:42.336632  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232746 (* 1 = 0.0232746 loss)
I0625 20:58:42.336635  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0074546 (* 1 = 0.0074546 loss)
I0625 20:58:42.336640  4216 sgd_solver.cpp:106] Iteration 6260, lr = 0.0002
I0625 21:00:28.450420  4216 solver.cpp:228] Iteration 6280, loss = 0.469495
I0625 21:00:28.450446  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 21:00:28.450453  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.256604 (* 1 = 0.256604 loss)
I0625 21:00:28.450456  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.358984 (* 1 = 0.358984 loss)
I0625 21:00:28.450460  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.002414 (* 1 = 0.002414 loss)
I0625 21:00:28.450464  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259583 (* 1 = 0.0259583 loss)
I0625 21:00:28.450469  4216 sgd_solver.cpp:106] Iteration 6280, lr = 0.0002
I0625 21:02:17.005987  4216 solver.cpp:228] Iteration 6300, loss = 0.371124
I0625 21:02:17.006014  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 21:02:17.006022  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.027433 (* 1 = 0.027433 loss)
I0625 21:02:17.006029  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.216316 (* 1 = 0.216316 loss)
I0625 21:02:17.006033  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103675 (* 1 = 0.0103675 loss)
I0625 21:02:17.006036  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316518 (* 1 = 0.0316518 loss)
I0625 21:02:17.006042  4216 sgd_solver.cpp:106] Iteration 6300, lr = 0.0002
I0625 21:04:06.480551  4216 solver.cpp:228] Iteration 6320, loss = 0.277489
I0625 21:04:06.480576  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 21:04:06.480582  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.048319 (* 1 = 0.048319 loss)
I0625 21:04:06.480587  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.106734 (* 1 = 0.106734 loss)
I0625 21:04:06.480592  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347142 (* 1 = 0.00347142 loss)
I0625 21:04:06.480595  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939723 (* 1 = 0.00939723 loss)
I0625 21:04:06.480600  4216 sgd_solver.cpp:106] Iteration 6320, lr = 0.0002
I0625 21:05:55.759841  4216 solver.cpp:228] Iteration 6340, loss = 0.26984
I0625 21:05:55.759873  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:05:55.759883  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0903956 (* 1 = 0.0903956 loss)
I0625 21:05:55.759889  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0957001 (* 1 = 0.0957001 loss)
I0625 21:05:55.759896  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600452 (* 1 = 0.00600452 loss)
I0625 21:05:55.759901  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0547683 (* 1 = 0.0547683 loss)
I0625 21:05:55.759907  4216 sgd_solver.cpp:106] Iteration 6340, lr = 0.0002
I0625 21:07:42.452631  4216 solver.cpp:228] Iteration 6360, loss = 0.381062
I0625 21:07:42.452656  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:07:42.452662  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199606 (* 1 = 0.0199606 loss)
I0625 21:07:42.452666  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0385621 (* 1 = 0.0385621 loss)
I0625 21:07:42.452670  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000208425 (* 1 = 0.000208425 loss)
I0625 21:07:42.452674  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00421657 (* 1 = 0.00421657 loss)
I0625 21:07:42.452679  4216 sgd_solver.cpp:106] Iteration 6360, lr = 0.0002
I0625 21:09:31.565259  4216 solver.cpp:228] Iteration 6380, loss = 0.550239
I0625 21:09:31.565282  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0625 21:09:31.565290  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.375372 (* 1 = 0.375372 loss)
I0625 21:09:31.565294  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.477445 (* 1 = 0.477445 loss)
I0625 21:09:31.565297  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0030601 (* 1 = 0.0030601 loss)
I0625 21:09:31.565300  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0520111 (* 1 = 0.0520111 loss)
I0625 21:09:31.565305  4216 sgd_solver.cpp:106] Iteration 6380, lr = 0.0002
speed: 5.205s / iter
I0625 21:11:21.573705  4216 solver.cpp:228] Iteration 6400, loss = 0.283931
I0625 21:11:21.573729  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:11:21.573735  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000185457 (* 1 = 0.000185457 loss)
I0625 21:11:21.573740  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0337793 (* 1 = 0.0337793 loss)
I0625 21:11:21.573743  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109472 (* 1 = 0.0109472 loss)
I0625 21:11:21.573746  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00979013 (* 1 = 0.00979013 loss)
I0625 21:11:21.573750  4216 sgd_solver.cpp:106] Iteration 6400, lr = 0.0002
I0625 21:13:12.391095  4216 solver.cpp:228] Iteration 6420, loss = 0.548838
I0625 21:13:12.391118  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 21:13:12.391125  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.075908 (* 1 = 0.075908 loss)
I0625 21:13:12.391129  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.221442 (* 1 = 0.221442 loss)
I0625 21:13:12.391132  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204228 (* 1 = 0.00204228 loss)
I0625 21:13:12.391136  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186965 (* 1 = 0.0186965 loss)
I0625 21:13:12.391140  4216 sgd_solver.cpp:106] Iteration 6420, lr = 0.0002
I0625 21:15:02.859686  4216 solver.cpp:228] Iteration 6440, loss = 0.220212
I0625 21:15:02.859711  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0625 21:15:02.859719  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.012482 (* 1 = 0.012482 loss)
I0625 21:15:02.859724  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0320781 (* 1 = 0.0320781 loss)
I0625 21:15:02.859727  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000660431 (* 1 = 0.000660431 loss)
I0625 21:15:02.859732  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00413281 (* 1 = 0.00413281 loss)
I0625 21:15:02.859737  4216 sgd_solver.cpp:106] Iteration 6440, lr = 0.0002
I0625 21:16:51.183578  4216 solver.cpp:228] Iteration 6460, loss = 0.445084
I0625 21:16:51.183601  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 21:16:51.183611  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.282914 (* 1 = 0.282914 loss)
I0625 21:16:51.183617  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.450048 (* 1 = 0.450048 loss)
I0625 21:16:51.183622  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135316 (* 1 = 0.0135316 loss)
I0625 21:16:51.183627  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0555189 (* 1 = 0.0555189 loss)
I0625 21:16:51.183634  4216 sgd_solver.cpp:106] Iteration 6460, lr = 0.0002
I0625 21:18:37.934634  4216 solver.cpp:228] Iteration 6480, loss = 0.618116
I0625 21:18:37.934660  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 21:18:37.934670  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121546 (* 1 = 0.121546 loss)
I0625 21:18:37.934677  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.181251 (* 1 = 0.181251 loss)
I0625 21:18:37.934684  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00198023 (* 1 = 0.00198023 loss)
I0625 21:18:37.934690  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448572 (* 1 = 0.0448572 loss)
I0625 21:18:37.934697  4216 sgd_solver.cpp:106] Iteration 6480, lr = 0.0002
I0625 21:20:24.496645  4216 solver.cpp:228] Iteration 6500, loss = 0.337181
I0625 21:20:24.496671  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 21:20:24.496678  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.16903 (* 1 = 0.16903 loss)
I0625 21:20:24.496683  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.517594 (* 1 = 0.517594 loss)
I0625 21:20:24.496687  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133253 (* 1 = 0.0133253 loss)
I0625 21:20:24.496691  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0678134 (* 1 = 0.0678134 loss)
I0625 21:20:24.496696  4216 sgd_solver.cpp:106] Iteration 6500, lr = 0.0002
I0625 21:22:10.289149  4216 solver.cpp:228] Iteration 6520, loss = 0.247368
I0625 21:22:10.289175  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:22:10.289182  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186636 (* 1 = 0.0186636 loss)
I0625 21:22:10.289186  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0570454 (* 1 = 0.0570454 loss)
I0625 21:22:10.289191  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000806828 (* 1 = 0.000806828 loss)
I0625 21:22:10.289193  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150546 (* 1 = 0.0150546 loss)
I0625 21:22:10.289199  4216 sgd_solver.cpp:106] Iteration 6520, lr = 0.0002
I0625 21:23:57.839912  4216 solver.cpp:228] Iteration 6540, loss = 0.456901
I0625 21:23:57.839937  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:23:57.839947  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188616 (* 1 = 0.0188616 loss)
I0625 21:23:57.839954  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.038957 (* 1 = 0.038957 loss)
I0625 21:23:57.839960  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0078868 (* 1 = 0.0078868 loss)
I0625 21:23:57.839967  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137106 (* 1 = 0.0137106 loss)
I0625 21:23:57.839973  4216 sgd_solver.cpp:106] Iteration 6540, lr = 0.0002
I0625 21:25:45.679563  4216 solver.cpp:228] Iteration 6560, loss = 0.503368
I0625 21:25:45.679589  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 21:25:45.679599  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0875216 (* 1 = 0.0875216 loss)
I0625 21:25:45.679605  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.171119 (* 1 = 0.171119 loss)
I0625 21:25:45.679610  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00200347 (* 1 = 0.00200347 loss)
I0625 21:25:45.679616  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248612 (* 1 = 0.0248612 loss)
I0625 21:25:45.679625  4216 sgd_solver.cpp:106] Iteration 6560, lr = 0.0002
I0625 21:27:33.504460  4216 solver.cpp:228] Iteration 6580, loss = 0.298404
I0625 21:27:33.504487  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 21:27:33.504498  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498293 (* 1 = 0.0498293 loss)
I0625 21:27:33.504504  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.26748 (* 1 = 0.26748 loss)
I0625 21:27:33.504510  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234112 (* 1 = 0.0234112 loss)
I0625 21:27:33.504516  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431689 (* 1 = 0.0431689 loss)
I0625 21:27:33.504523  4216 sgd_solver.cpp:106] Iteration 6580, lr = 0.0002
speed: 5.211s / iter
I0625 21:29:22.336908  4216 solver.cpp:228] Iteration 6600, loss = 0.308534
I0625 21:29:22.336933  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:29:22.336941  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189068 (* 1 = 0.0189068 loss)
I0625 21:29:22.336946  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0949134 (* 1 = 0.0949134 loss)
I0625 21:29:22.336949  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318071 (* 1 = 0.00318071 loss)
I0625 21:29:22.336954  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135601 (* 1 = 0.0135601 loss)
I0625 21:29:22.336959  4216 sgd_solver.cpp:106] Iteration 6600, lr = 0.0002
I0625 21:31:11.726030  4216 solver.cpp:228] Iteration 6620, loss = 0.203097
I0625 21:31:11.726061  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:31:11.726070  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0200307 (* 1 = 0.0200307 loss)
I0625 21:31:11.726076  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.044575 (* 1 = 0.044575 loss)
I0625 21:31:11.726080  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00454959 (* 1 = 0.00454959 loss)
I0625 21:31:11.726085  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00460409 (* 1 = 0.00460409 loss)
I0625 21:31:11.726091  4216 sgd_solver.cpp:106] Iteration 6620, lr = 0.0002
I0625 21:33:00.417104  4216 solver.cpp:228] Iteration 6640, loss = 0.546167
I0625 21:33:00.417127  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 21:33:00.417135  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0367018 (* 1 = 0.0367018 loss)
I0625 21:33:00.417140  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.112863 (* 1 = 0.112863 loss)
I0625 21:33:00.417145  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336018 (* 1 = 0.00336018 loss)
I0625 21:33:00.417148  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191986 (* 1 = 0.0191986 loss)
I0625 21:33:00.417153  4216 sgd_solver.cpp:106] Iteration 6640, lr = 0.0002
I0625 21:34:48.246408  4216 solver.cpp:228] Iteration 6660, loss = 0.292887
I0625 21:34:48.246434  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 21:34:48.246444  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393893 (* 1 = 0.0393893 loss)
I0625 21:34:48.246450  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.130982 (* 1 = 0.130982 loss)
I0625 21:34:48.246457  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114911 (* 1 = 0.00114911 loss)
I0625 21:34:48.246464  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0064424 (* 1 = 0.0064424 loss)
I0625 21:34:48.246470  4216 sgd_solver.cpp:106] Iteration 6660, lr = 0.0002
I0625 21:36:35.237931  4216 solver.cpp:228] Iteration 6680, loss = 0.427044
I0625 21:36:35.237960  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 21:36:35.237968  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448708 (* 1 = 0.0448708 loss)
I0625 21:36:35.237972  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.161661 (* 1 = 0.161661 loss)
I0625 21:36:35.237977  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294551 (* 1 = 0.00294551 loss)
I0625 21:36:35.237982  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117042 (* 1 = 0.0117042 loss)
I0625 21:36:35.237987  4216 sgd_solver.cpp:106] Iteration 6680, lr = 0.0002
I0625 21:38:22.008283  4216 solver.cpp:228] Iteration 6700, loss = 0.244253
I0625 21:38:22.008308  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:38:22.008316  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236365 (* 1 = 0.0236365 loss)
I0625 21:38:22.008322  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0661891 (* 1 = 0.0661891 loss)
I0625 21:38:22.008325  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00392119 (* 1 = 0.00392119 loss)
I0625 21:38:22.008329  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234949 (* 1 = 0.0234949 loss)
I0625 21:38:22.008334  4216 sgd_solver.cpp:106] Iteration 6700, lr = 0.0002
I0625 21:40:07.479933  4216 solver.cpp:228] Iteration 6720, loss = 0.210009
I0625 21:40:07.479959  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 21:40:07.479966  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156165 (* 1 = 0.0156165 loss)
I0625 21:40:07.479971  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0658541 (* 1 = 0.0658541 loss)
I0625 21:40:07.479975  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00909468 (* 1 = 0.00909468 loss)
I0625 21:40:07.479979  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00896432 (* 1 = 0.00896432 loss)
I0625 21:40:07.479984  4216 sgd_solver.cpp:106] Iteration 6720, lr = 0.0002
I0625 21:41:52.737637  4216 solver.cpp:228] Iteration 6740, loss = 0.310211
I0625 21:41:52.737661  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:41:52.737668  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000684434 (* 1 = 0.000684434 loss)
I0625 21:41:52.737673  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0343959 (* 1 = 0.0343959 loss)
I0625 21:41:52.737676  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00332079 (* 1 = 0.00332079 loss)
I0625 21:41:52.737679  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146585 (* 1 = 0.0146585 loss)
I0625 21:41:52.737684  4216 sgd_solver.cpp:106] Iteration 6740, lr = 0.0002
I0625 21:43:38.060339  4216 solver.cpp:228] Iteration 6760, loss = 0.172532
I0625 21:43:38.060364  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 21:43:38.060371  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120557 (* 1 = 0.120557 loss)
I0625 21:43:38.060375  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.225091 (* 1 = 0.225091 loss)
I0625 21:43:38.060379  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00313828 (* 1 = 0.00313828 loss)
I0625 21:43:38.060384  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00761335 (* 1 = 0.00761335 loss)
I0625 21:43:38.060389  4216 sgd_solver.cpp:106] Iteration 6760, lr = 0.0002
I0625 21:45:23.373680  4216 solver.cpp:228] Iteration 6780, loss = 0.261147
I0625 21:45:23.373703  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 21:45:23.373711  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708552 (* 1 = 0.0708552 loss)
I0625 21:45:23.373715  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.116528 (* 1 = 0.116528 loss)
I0625 21:45:23.373718  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0273874 (* 1 = 0.0273874 loss)
I0625 21:45:23.373723  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213461 (* 1 = 0.0213461 loss)
I0625 21:45:23.373728  4216 sgd_solver.cpp:106] Iteration 6780, lr = 0.0002
speed: 5.214s / iter
I0625 21:47:08.550472  4216 solver.cpp:228] Iteration 6800, loss = 0.562306
I0625 21:47:08.550498  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0625 21:47:08.550505  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.367878 (* 1 = 0.367878 loss)
I0625 21:47:08.550510  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.622256 (* 1 = 0.622256 loss)
I0625 21:47:08.550514  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0248972 (* 1 = 0.0248972 loss)
I0625 21:47:08.550518  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403749 (* 1 = 0.0403749 loss)
I0625 21:47:08.550523  4216 sgd_solver.cpp:106] Iteration 6800, lr = 0.0002
I0625 21:48:53.833001  4216 solver.cpp:228] Iteration 6820, loss = 0.26794
I0625 21:48:53.833026  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0625 21:48:53.833034  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.381589 (* 1 = 0.381589 loss)
I0625 21:48:53.833039  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.631185 (* 1 = 0.631185 loss)
I0625 21:48:53.833043  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00980816 (* 1 = 0.00980816 loss)
I0625 21:48:53.833047  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109241 (* 1 = 0.109241 loss)
I0625 21:48:53.833051  4216 sgd_solver.cpp:106] Iteration 6820, lr = 0.0002
I0625 21:50:39.078377  4216 solver.cpp:228] Iteration 6840, loss = 0.295596
I0625 21:50:39.078405  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 21:50:39.078413  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.146636 (* 1 = 0.146636 loss)
I0625 21:50:39.078418  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.249504 (* 1 = 0.249504 loss)
I0625 21:50:39.078421  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00429533 (* 1 = 0.00429533 loss)
I0625 21:50:39.078425  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0389244 (* 1 = 0.0389244 loss)
I0625 21:50:39.078430  4216 sgd_solver.cpp:106] Iteration 6840, lr = 0.0002
I0625 21:52:24.408458  4216 solver.cpp:228] Iteration 6860, loss = 0.449685
I0625 21:52:24.408483  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 21:52:24.408490  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.237008 (* 1 = 0.237008 loss)
I0625 21:52:24.408494  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.287475 (* 1 = 0.287475 loss)
I0625 21:52:24.408499  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0069343 (* 1 = 0.0069343 loss)
I0625 21:52:24.408501  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0534025 (* 1 = 0.0534025 loss)
I0625 21:52:24.408506  4216 sgd_solver.cpp:106] Iteration 6860, lr = 0.0002
I0625 21:54:09.650853  4216 solver.cpp:228] Iteration 6880, loss = 0.331391
I0625 21:54:09.650887  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:54:09.650897  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0436972 (* 1 = 0.0436972 loss)
I0625 21:54:09.650907  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0412862 (* 1 = 0.0412862 loss)
I0625 21:54:09.650913  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0007879 (* 1 = 0.0007879 loss)
I0625 21:54:09.650919  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146272 (* 1 = 0.0146272 loss)
I0625 21:54:09.650926  4216 sgd_solver.cpp:106] Iteration 6880, lr = 0.0002
I0625 21:55:54.997786  4216 solver.cpp:228] Iteration 6900, loss = 0.320905
I0625 21:55:54.997812  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:55:54.997818  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000299345 (* 1 = 0.000299345 loss)
I0625 21:55:54.997822  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0407254 (* 1 = 0.0407254 loss)
I0625 21:55:54.997826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00501468 (* 1 = 0.00501468 loss)
I0625 21:55:54.997830  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147281 (* 1 = 0.0147281 loss)
I0625 21:55:54.997834  4216 sgd_solver.cpp:106] Iteration 6900, lr = 0.0002
I0625 21:57:40.306516  4216 solver.cpp:228] Iteration 6920, loss = 0.314526
I0625 21:57:40.306542  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 21:57:40.306552  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533596 (* 1 = 0.0533596 loss)
I0625 21:57:40.306558  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.127045 (* 1 = 0.127045 loss)
I0625 21:57:40.306565  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00731244 (* 1 = 0.00731244 loss)
I0625 21:57:40.306571  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216944 (* 1 = 0.0216944 loss)
I0625 21:57:40.306578  4216 sgd_solver.cpp:106] Iteration 6920, lr = 0.0002
I0625 21:59:25.568464  4216 solver.cpp:228] Iteration 6940, loss = 0.453617
I0625 21:59:25.568495  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 21:59:25.568503  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0565083 (* 1 = 0.0565083 loss)
I0625 21:59:25.568508  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.172935 (* 1 = 0.172935 loss)
I0625 21:59:25.568512  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00601887 (* 1 = 0.00601887 loss)
I0625 21:59:25.568517  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0567399 (* 1 = 0.0567399 loss)
I0625 21:59:25.568522  4216 sgd_solver.cpp:106] Iteration 6940, lr = 0.0002
I0625 22:01:10.779326  4216 solver.cpp:228] Iteration 6960, loss = 0.351258
I0625 22:01:10.779353  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:01:10.779361  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0968536 (* 1 = 0.0968536 loss)
I0625 22:01:10.779366  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.179573 (* 1 = 0.179573 loss)
I0625 22:01:10.779369  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118831 (* 1 = 0.0118831 loss)
I0625 22:01:10.779373  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252463 (* 1 = 0.0252463 loss)
I0625 22:01:10.779378  4216 sgd_solver.cpp:106] Iteration 6960, lr = 0.0002
I0625 22:02:55.944056  4216 solver.cpp:228] Iteration 6980, loss = 0.273749
I0625 22:02:55.944080  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0625 22:02:55.944088  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.235965 (* 1 = 0.235965 loss)
I0625 22:02:55.944092  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.321445 (* 1 = 0.321445 loss)
I0625 22:02:55.944097  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155618 (* 1 = 0.00155618 loss)
I0625 22:02:55.944100  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017592 (* 1 = 0.017592 loss)
I0625 22:02:55.944105  4216 sgd_solver.cpp:106] Iteration 6980, lr = 0.0002
speed: 5.216s / iter
I0625 22:04:41.753487  4216 solver.cpp:228] Iteration 7000, loss = 0.263315
I0625 22:04:41.753515  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 22:04:41.753525  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413696 (* 1 = 0.0413696 loss)
I0625 22:04:41.753531  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0510145 (* 1 = 0.0510145 loss)
I0625 22:04:41.753536  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00310181 (* 1 = 0.00310181 loss)
I0625 22:04:41.753543  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00922144 (* 1 = 0.00922144 loss)
I0625 22:04:41.753551  4216 sgd_solver.cpp:106] Iteration 7000, lr = 0.0002
I0625 22:06:27.832033  4216 solver.cpp:228] Iteration 7020, loss = 0.275388
I0625 22:06:27.832059  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 22:06:27.832067  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362757 (* 1 = 0.0362757 loss)
I0625 22:06:27.832072  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0754359 (* 1 = 0.0754359 loss)
I0625 22:06:27.832077  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000554928 (* 1 = 0.000554928 loss)
I0625 22:06:27.832080  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132016 (* 1 = 0.0132016 loss)
I0625 22:06:27.832087  4216 sgd_solver.cpp:106] Iteration 7020, lr = 0.0002
I0625 22:08:17.384842  4216 solver.cpp:228] Iteration 7040, loss = 0.344746
I0625 22:08:17.384871  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 22:08:17.384883  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0674399 (* 1 = 0.0674399 loss)
I0625 22:08:17.384892  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108071 (* 1 = 0.108071 loss)
I0625 22:08:17.384899  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102051 (* 1 = 0.0102051 loss)
I0625 22:08:17.384907  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019407 (* 1 = 0.019407 loss)
I0625 22:08:17.384914  4216 sgd_solver.cpp:106] Iteration 7040, lr = 0.0002
I0625 22:10:06.368096  4216 solver.cpp:228] Iteration 7060, loss = 0.516739
I0625 22:10:06.368129  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0625 22:10:06.368141  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.105005 (* 1 = 0.105005 loss)
I0625 22:10:06.368151  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.376952 (* 1 = 0.376952 loss)
I0625 22:10:06.368160  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194036 (* 1 = 0.00194036 loss)
I0625 22:10:06.368170  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0755303 (* 1 = 0.0755303 loss)
I0625 22:10:06.368177  4216 sgd_solver.cpp:106] Iteration 7060, lr = 0.0002
I0625 22:11:54.905715  4216 solver.cpp:228] Iteration 7080, loss = 0.343624
I0625 22:11:54.905748  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 22:11:54.905760  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0714099 (* 1 = 0.0714099 loss)
I0625 22:11:54.905766  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.17165 (* 1 = 0.17165 loss)
I0625 22:11:54.905771  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00396892 (* 1 = 0.00396892 loss)
I0625 22:11:54.905776  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0463642 (* 1 = 0.0463642 loss)
I0625 22:11:54.905782  4216 sgd_solver.cpp:106] Iteration 7080, lr = 0.0002
I0625 22:13:43.545665  4216 solver.cpp:228] Iteration 7100, loss = 0.178812
I0625 22:13:43.545692  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 22:13:43.545701  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142784 (* 1 = 0.0142784 loss)
I0625 22:13:43.545706  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0389017 (* 1 = 0.0389017 loss)
I0625 22:13:43.545711  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00863045 (* 1 = 0.00863045 loss)
I0625 22:13:43.545716  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00454099 (* 1 = 0.00454099 loss)
I0625 22:13:43.545722  4216 sgd_solver.cpp:106] Iteration 7100, lr = 0.0002
I0625 22:15:32.137167  4216 solver.cpp:228] Iteration 7120, loss = 0.30557
I0625 22:15:32.137192  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 22:15:32.137198  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0947752 (* 1 = 0.0947752 loss)
I0625 22:15:32.137203  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147123 (* 1 = 0.147123 loss)
I0625 22:15:32.137207  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382891 (* 1 = 0.00382891 loss)
I0625 22:15:32.137210  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00839769 (* 1 = 0.00839769 loss)
I0625 22:15:32.137214  4216 sgd_solver.cpp:106] Iteration 7120, lr = 0.0002
I0625 22:17:20.937319  4216 solver.cpp:228] Iteration 7140, loss = 0.294749
I0625 22:17:20.937342  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:17:20.937350  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0519158 (* 1 = 0.0519158 loss)
I0625 22:17:20.937353  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.144712 (* 1 = 0.144712 loss)
I0625 22:17:20.937357  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189548 (* 1 = 0.0189548 loss)
I0625 22:17:20.937361  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00995139 (* 1 = 0.00995139 loss)
I0625 22:17:20.937366  4216 sgd_solver.cpp:106] Iteration 7140, lr = 0.0002
I0625 22:19:07.815737  4216 solver.cpp:228] Iteration 7160, loss = 0.304467
I0625 22:19:07.815769  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 22:19:07.815783  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.109233 (* 1 = 0.109233 loss)
I0625 22:19:07.815793  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.360535 (* 1 = 0.360535 loss)
I0625 22:19:07.815801  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140659 (* 1 = 0.0140659 loss)
I0625 22:19:07.815809  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336456 (* 1 = 0.0336456 loss)
I0625 22:19:07.815819  4216 sgd_solver.cpp:106] Iteration 7160, lr = 0.0002
I0625 22:20:54.979439  4216 solver.cpp:228] Iteration 7180, loss = 0.325461
I0625 22:20:54.979467  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 22:20:54.979475  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.166074 (* 1 = 0.166074 loss)
I0625 22:20:54.979478  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.263345 (* 1 = 0.263345 loss)
I0625 22:20:54.979481  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0168882 (* 1 = 0.0168882 loss)
I0625 22:20:54.979485  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383683 (* 1 = 0.0383683 loss)
I0625 22:20:54.979490  4216 sgd_solver.cpp:106] Iteration 7180, lr = 0.0002
speed: 5.221s / iter
I0625 22:22:43.660082  4216 solver.cpp:228] Iteration 7200, loss = 0.107028
I0625 22:22:43.660115  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:22:43.660125  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229342 (* 1 = 0.0229342 loss)
I0625 22:22:43.660130  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0793601 (* 1 = 0.0793601 loss)
I0625 22:22:43.660136  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291834 (* 1 = 0.00291834 loss)
I0625 22:22:43.660141  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132741 (* 1 = 0.0132741 loss)
I0625 22:22:43.660147  4216 sgd_solver.cpp:106] Iteration 7200, lr = 0.0002
I0625 22:24:30.320591  4216 solver.cpp:228] Iteration 7220, loss = 0.26781
I0625 22:24:30.320621  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 22:24:30.320629  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.10735 (* 1 = 0.10735 loss)
I0625 22:24:30.320633  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.21094 (* 1 = 0.21094 loss)
I0625 22:24:30.320638  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474989 (* 1 = 0.00474989 loss)
I0625 22:24:30.320642  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010615 (* 1 = 0.010615 loss)
I0625 22:24:30.320648  4216 sgd_solver.cpp:106] Iteration 7220, lr = 0.0002
I0625 22:26:18.333233  4216 solver.cpp:228] Iteration 7240, loss = 0.285461
I0625 22:26:18.333264  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 22:26:18.333272  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.049493 (* 1 = 0.049493 loss)
I0625 22:26:18.333277  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.12018 (* 1 = 0.12018 loss)
I0625 22:26:18.333281  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122769 (* 1 = 0.0122769 loss)
I0625 22:26:18.333286  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178221 (* 1 = 0.0178221 loss)
I0625 22:26:18.333292  4216 sgd_solver.cpp:106] Iteration 7240, lr = 0.0002
I0625 22:28:06.277333  4216 solver.cpp:228] Iteration 7260, loss = 0.192945
I0625 22:28:06.277359  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 22:28:06.277367  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365779 (* 1 = 0.0365779 loss)
I0625 22:28:06.277371  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0535995 (* 1 = 0.0535995 loss)
I0625 22:28:06.277375  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000161478 (* 1 = 0.000161478 loss)
I0625 22:28:06.277380  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0061137 (* 1 = 0.0061137 loss)
I0625 22:28:06.277385  4216 sgd_solver.cpp:106] Iteration 7260, lr = 0.0002
I0625 22:29:54.129344  4216 solver.cpp:228] Iteration 7280, loss = 0.497016
I0625 22:29:54.129375  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 22:29:54.129385  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0427576 (* 1 = 0.0427576 loss)
I0625 22:29:54.129392  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.145944 (* 1 = 0.145944 loss)
I0625 22:29:54.129398  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134843 (* 1 = 0.0134843 loss)
I0625 22:29:54.129405  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0349 (* 1 = 0.0349 loss)
I0625 22:29:54.129412  4216 sgd_solver.cpp:106] Iteration 7280, lr = 0.0002
I0625 22:31:41.746809  4216 solver.cpp:228] Iteration 7300, loss = 0.286941
I0625 22:31:41.746832  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 22:31:41.746840  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.149916 (* 1 = 0.149916 loss)
I0625 22:31:41.746843  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.34081 (* 1 = 0.34081 loss)
I0625 22:31:41.746847  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00885394 (* 1 = 0.00885394 loss)
I0625 22:31:41.746851  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282913 (* 1 = 0.0282913 loss)
I0625 22:31:41.746855  4216 sgd_solver.cpp:106] Iteration 7300, lr = 0.0002
I0625 22:33:28.322142  4216 solver.cpp:228] Iteration 7320, loss = 0.433782
I0625 22:33:28.322171  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 22:33:28.322180  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.138864 (* 1 = 0.138864 loss)
I0625 22:33:28.322185  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.149689 (* 1 = 0.149689 loss)
I0625 22:33:28.322190  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035851 (* 1 = 0.0035851 loss)
I0625 22:33:28.322194  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237538 (* 1 = 0.0237538 loss)
I0625 22:33:28.322201  4216 sgd_solver.cpp:106] Iteration 7320, lr = 0.0002
I0625 22:35:16.922533  4216 solver.cpp:228] Iteration 7340, loss = 0.355763
I0625 22:35:16.922562  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 22:35:16.922570  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229311 (* 1 = 0.0229311 loss)
I0625 22:35:16.922575  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.137905 (* 1 = 0.137905 loss)
I0625 22:35:16.922580  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00682291 (* 1 = 0.00682291 loss)
I0625 22:35:16.922583  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162652 (* 1 = 0.0162652 loss)
I0625 22:35:16.922590  4216 sgd_solver.cpp:106] Iteration 7340, lr = 0.0002
I0625 22:37:02.413331  4216 solver.cpp:228] Iteration 7360, loss = 0.322968
I0625 22:37:02.413357  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:37:02.413364  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220203 (* 1 = 0.0220203 loss)
I0625 22:37:02.413369  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.069273 (* 1 = 0.069273 loss)
I0625 22:37:02.413373  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000477244 (* 1 = 0.000477244 loss)
I0625 22:37:02.413377  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265789 (* 1 = 0.0265789 loss)
I0625 22:37:02.413381  4216 sgd_solver.cpp:106] Iteration 7360, lr = 0.0002
I0625 22:38:48.525362  4216 solver.cpp:228] Iteration 7380, loss = 0.401075
I0625 22:38:48.525388  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:38:48.525394  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0772955 (* 1 = 0.0772955 loss)
I0625 22:38:48.525398  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.225901 (* 1 = 0.225901 loss)
I0625 22:38:48.525401  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00595011 (* 1 = 0.00595011 loss)
I0625 22:38:48.525405  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167286 (* 1 = 0.0167286 loss)
I0625 22:38:48.525410  4216 sgd_solver.cpp:106] Iteration 7380, lr = 0.0002
speed: 5.225s / iter
I0625 22:40:33.841913  4216 solver.cpp:228] Iteration 7400, loss = 0.229657
I0625 22:40:33.841941  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 22:40:33.841949  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0812515 (* 1 = 0.0812515 loss)
I0625 22:40:33.841954  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.190931 (* 1 = 0.190931 loss)
I0625 22:40:33.841958  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0426626 (* 1 = 0.0426626 loss)
I0625 22:40:33.841962  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390694 (* 1 = 0.0390694 loss)
I0625 22:40:33.841969  4216 sgd_solver.cpp:106] Iteration 7400, lr = 0.0002
I0625 22:42:19.137640  4216 solver.cpp:228] Iteration 7420, loss = 0.313852
I0625 22:42:19.137665  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 22:42:19.137673  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.206589 (* 1 = 0.206589 loss)
I0625 22:42:19.137679  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.266264 (* 1 = 0.266264 loss)
I0625 22:42:19.137686  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151917 (* 1 = 0.0151917 loss)
I0625 22:42:19.137691  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0442532 (* 1 = 0.0442532 loss)
I0625 22:42:19.137696  4216 sgd_solver.cpp:106] Iteration 7420, lr = 0.0002
I0625 22:44:04.322461  4216 solver.cpp:228] Iteration 7440, loss = 0.25406
I0625 22:44:04.322487  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:44:04.322494  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305403 (* 1 = 0.0305403 loss)
I0625 22:44:04.322499  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0568346 (* 1 = 0.0568346 loss)
I0625 22:44:04.322504  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00170051 (* 1 = 0.00170051 loss)
I0625 22:44:04.322507  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00406304 (* 1 = 0.00406304 loss)
I0625 22:44:04.322512  4216 sgd_solver.cpp:106] Iteration 7440, lr = 0.0002
I0625 22:45:49.573590  4216 solver.cpp:228] Iteration 7460, loss = 0.300853
I0625 22:45:49.573614  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:45:49.573621  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407527 (* 1 = 0.0407527 loss)
I0625 22:45:49.573626  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0971176 (* 1 = 0.0971176 loss)
I0625 22:45:49.573629  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00182431 (* 1 = 0.00182431 loss)
I0625 22:45:49.573632  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204261 (* 1 = 0.0204261 loss)
I0625 22:45:49.573637  4216 sgd_solver.cpp:106] Iteration 7460, lr = 0.0002
I0625 22:47:34.893643  4216 solver.cpp:228] Iteration 7480, loss = 0.386394
I0625 22:47:34.893676  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 22:47:34.893683  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.199158 (* 1 = 0.199158 loss)
I0625 22:47:34.893687  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.383678 (* 1 = 0.383678 loss)
I0625 22:47:34.893692  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114896 (* 1 = 0.0114896 loss)
I0625 22:47:34.893695  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434018 (* 1 = 0.0434018 loss)
I0625 22:47:34.893702  4216 sgd_solver.cpp:106] Iteration 7480, lr = 0.0002
I0625 22:49:20.202464  4216 solver.cpp:228] Iteration 7500, loss = 0.295141
I0625 22:49:20.202489  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:49:20.202497  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.128759 (* 1 = 0.128759 loss)
I0625 22:49:20.202502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.198528 (* 1 = 0.198528 loss)
I0625 22:49:20.202505  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00352459 (* 1 = 0.00352459 loss)
I0625 22:49:20.202509  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329618 (* 1 = 0.0329618 loss)
I0625 22:49:20.202514  4216 sgd_solver.cpp:106] Iteration 7500, lr = 0.0002
I0625 22:51:05.510628  4216 solver.cpp:228] Iteration 7520, loss = 0.298649
I0625 22:51:05.510653  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 22:51:05.510660  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.173583 (* 1 = 0.173583 loss)
I0625 22:51:05.510663  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.273725 (* 1 = 0.273725 loss)
I0625 22:51:05.510668  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141594 (* 1 = 0.00141594 loss)
I0625 22:51:05.510671  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277097 (* 1 = 0.0277097 loss)
I0625 22:51:05.510676  4216 sgd_solver.cpp:106] Iteration 7520, lr = 0.0002
I0625 22:52:50.922875  4216 solver.cpp:228] Iteration 7540, loss = 0.347023
I0625 22:52:50.922914  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 22:52:50.922921  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0662472 (* 1 = 0.0662472 loss)
I0625 22:52:50.922925  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.19272 (* 1 = 0.19272 loss)
I0625 22:52:50.922930  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00634923 (* 1 = 0.00634923 loss)
I0625 22:52:50.922933  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108016 (* 1 = 0.0108016 loss)
I0625 22:52:50.922938  4216 sgd_solver.cpp:106] Iteration 7540, lr = 0.0002
I0625 22:54:36.396692  4216 solver.cpp:228] Iteration 7560, loss = 0.249703
I0625 22:54:36.396718  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 22:54:36.396724  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363719 (* 1 = 0.0363719 loss)
I0625 22:54:36.396728  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0520939 (* 1 = 0.0520939 loss)
I0625 22:54:36.396733  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000327114 (* 1 = 0.000327114 loss)
I0625 22:54:36.396736  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00308188 (* 1 = 0.00308188 loss)
I0625 22:54:36.396741  4216 sgd_solver.cpp:106] Iteration 7560, lr = 0.0002
I0625 22:56:21.939950  4216 solver.cpp:228] Iteration 7580, loss = 0.321332
I0625 22:56:21.939973  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 22:56:21.939980  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0242527 (* 1 = 0.0242527 loss)
I0625 22:56:21.939985  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0548193 (* 1 = 0.0548193 loss)
I0625 22:56:21.939988  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169318 (* 1 = 0.00169318 loss)
I0625 22:56:21.939992  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206851 (* 1 = 0.0206851 loss)
I0625 22:56:21.939996  4216 sgd_solver.cpp:106] Iteration 7580, lr = 0.0002
speed: 5.226s / iter
I0625 22:58:07.534095  4216 solver.cpp:228] Iteration 7600, loss = 0.35347
I0625 22:58:07.534119  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 22:58:07.534127  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00129351 (* 1 = 0.00129351 loss)
I0625 22:58:07.534132  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0537595 (* 1 = 0.0537595 loss)
I0625 22:58:07.534137  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00826249 (* 1 = 0.00826249 loss)
I0625 22:58:07.534140  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185262 (* 1 = 0.0185262 loss)
I0625 22:58:07.534144  4216 sgd_solver.cpp:106] Iteration 7600, lr = 0.0002
I0625 22:59:53.127583  4216 solver.cpp:228] Iteration 7620, loss = 0.141414
I0625 22:59:53.127607  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 22:59:53.127614  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.034975 (* 1 = 0.034975 loss)
I0625 22:59:53.127619  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0815853 (* 1 = 0.0815853 loss)
I0625 22:59:53.127621  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124765 (* 1 = 0.0124765 loss)
I0625 22:59:53.127625  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00387283 (* 1 = 0.00387283 loss)
I0625 22:59:53.127630  4216 sgd_solver.cpp:106] Iteration 7620, lr = 0.0002
I0625 23:01:38.708956  4216 solver.cpp:228] Iteration 7640, loss = 0.365477
I0625 23:01:38.708983  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 23:01:38.708992  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.213581 (* 1 = 0.213581 loss)
I0625 23:01:38.708995  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.310869 (* 1 = 0.310869 loss)
I0625 23:01:38.708999  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00545247 (* 1 = 0.00545247 loss)
I0625 23:01:38.709003  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269922 (* 1 = 0.0269922 loss)
I0625 23:01:38.709008  4216 sgd_solver.cpp:106] Iteration 7640, lr = 0.0002
I0625 23:03:24.685626  4216 solver.cpp:228] Iteration 7660, loss = 0.207005
I0625 23:03:24.685650  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 23:03:24.685658  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0543573 (* 1 = 0.0543573 loss)
I0625 23:03:24.685663  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.115162 (* 1 = 0.115162 loss)
I0625 23:03:24.685667  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144071 (* 1 = 0.00144071 loss)
I0625 23:03:24.685672  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0079522 (* 1 = 0.0079522 loss)
I0625 23:03:24.685676  4216 sgd_solver.cpp:106] Iteration 7660, lr = 0.0002
I0625 23:05:09.863536  4216 solver.cpp:228] Iteration 7680, loss = 0.140108
I0625 23:05:09.863561  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 23:05:09.863569  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0797705 (* 1 = 0.0797705 loss)
I0625 23:05:09.863574  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.158884 (* 1 = 0.158884 loss)
I0625 23:05:09.863577  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130327 (* 1 = 0.0130327 loss)
I0625 23:05:09.863581  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223126 (* 1 = 0.0223126 loss)
I0625 23:05:09.863587  4216 sgd_solver.cpp:106] Iteration 7680, lr = 0.0002
I0625 23:06:55.449324  4216 solver.cpp:228] Iteration 7700, loss = 0.330261
I0625 23:06:55.449348  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 23:06:55.449355  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.110582 (* 1 = 0.110582 loss)
I0625 23:06:55.449359  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.230269 (* 1 = 0.230269 loss)
I0625 23:06:55.449362  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0049543 (* 1 = 0.0049543 loss)
I0625 23:06:55.449367  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304879 (* 1 = 0.0304879 loss)
I0625 23:06:55.449371  4216 sgd_solver.cpp:106] Iteration 7700, lr = 0.0002
I0625 23:08:40.982952  4216 solver.cpp:228] Iteration 7720, loss = 0.398588
I0625 23:08:40.982985  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:08:40.982996  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00237115 (* 1 = 0.00237115 loss)
I0625 23:08:40.983006  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0542559 (* 1 = 0.0542559 loss)
I0625 23:08:40.983013  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00930159 (* 1 = 0.00930159 loss)
I0625 23:08:40.983021  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00259587 (* 1 = 0.00259587 loss)
I0625 23:08:40.983029  4216 sgd_solver.cpp:106] Iteration 7720, lr = 0.0002
I0625 23:10:26.489418  4216 solver.cpp:228] Iteration 7740, loss = 0.35829
I0625 23:10:26.489444  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 23:10:26.489450  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.16509 (* 1 = 0.16509 loss)
I0625 23:10:26.489454  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.256353 (* 1 = 0.256353 loss)
I0625 23:10:26.489459  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144567 (* 1 = 0.0144567 loss)
I0625 23:10:26.489461  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297376 (* 1 = 0.0297376 loss)
I0625 23:10:26.489466  4216 sgd_solver.cpp:106] Iteration 7740, lr = 0.0002
I0625 23:12:12.046314  4216 solver.cpp:228] Iteration 7760, loss = 0.365201
I0625 23:12:12.046346  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 23:12:12.046357  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.145538 (* 1 = 0.145538 loss)
I0625 23:12:12.046365  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.347913 (* 1 = 0.347913 loss)
I0625 23:12:12.046371  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577624 (* 1 = 0.00577624 loss)
I0625 23:12:12.046380  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201077 (* 1 = 0.0201077 loss)
I0625 23:12:12.046386  4216 sgd_solver.cpp:106] Iteration 7760, lr = 0.0002
I0625 23:13:57.352697  4216 solver.cpp:228] Iteration 7780, loss = 0.286517
I0625 23:13:57.352730  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 23:13:57.352740  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.180542 (* 1 = 0.180542 loss)
I0625 23:13:57.352743  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.353647 (* 1 = 0.353647 loss)
I0625 23:13:57.352748  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00979783 (* 1 = 0.00979783 loss)
I0625 23:13:57.352752  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234967 (* 1 = 0.0234967 loss)
I0625 23:13:57.352761  4216 sgd_solver.cpp:106] Iteration 7780, lr = 0.0002
speed: 5.227s / iter
I0625 23:15:42.669085  4216 solver.cpp:228] Iteration 7800, loss = 0.231741
I0625 23:15:42.669116  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 23:15:42.669126  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.071712 (* 1 = 0.071712 loss)
I0625 23:15:42.669131  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.146607 (* 1 = 0.146607 loss)
I0625 23:15:42.669137  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165821 (* 1 = 0.0165821 loss)
I0625 23:15:42.669142  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152903 (* 1 = 0.0152903 loss)
I0625 23:15:42.669149  4216 sgd_solver.cpp:106] Iteration 7800, lr = 0.0002
I0625 23:17:27.976730  4216 solver.cpp:228] Iteration 7820, loss = 0.373685
I0625 23:17:27.976797  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 23:17:27.976811  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0744227 (* 1 = 0.0744227 loss)
I0625 23:17:27.976819  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.080647 (* 1 = 0.080647 loss)
I0625 23:17:27.976826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000946089 (* 1 = 0.000946089 loss)
I0625 23:17:27.976833  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125298 (* 1 = 0.0125298 loss)
I0625 23:17:27.976848  4216 sgd_solver.cpp:106] Iteration 7820, lr = 0.0002
I0625 23:19:13.167263  4216 solver.cpp:228] Iteration 7840, loss = 0.410065
I0625 23:19:13.167290  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:19:13.167299  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0484443 (* 1 = 0.0484443 loss)
I0625 23:19:13.167302  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.181683 (* 1 = 0.181683 loss)
I0625 23:19:13.167306  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00686342 (* 1 = 0.00686342 loss)
I0625 23:19:13.167310  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0460642 (* 1 = 0.0460642 loss)
I0625 23:19:13.167316  4216 sgd_solver.cpp:106] Iteration 7840, lr = 0.0002
I0625 23:20:58.353827  4216 solver.cpp:228] Iteration 7860, loss = 0.30399
I0625 23:20:58.353852  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 23:20:58.353859  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225568 (* 1 = 0.0225568 loss)
I0625 23:20:58.353863  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.07988 (* 1 = 0.07988 loss)
I0625 23:20:58.353868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000655552 (* 1 = 0.000655552 loss)
I0625 23:20:58.353870  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0022292 (* 1 = 0.0022292 loss)
I0625 23:20:58.353875  4216 sgd_solver.cpp:106] Iteration 7860, lr = 0.0002
I0625 23:22:43.550302  4216 solver.cpp:228] Iteration 7880, loss = 0.173267
I0625 23:22:43.550325  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 23:22:43.550333  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0243464 (* 1 = 0.0243464 loss)
I0625 23:22:43.550338  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0662368 (* 1 = 0.0662368 loss)
I0625 23:22:43.550340  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000196614 (* 1 = 0.000196614 loss)
I0625 23:22:43.550344  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00133067 (* 1 = 0.00133067 loss)
I0625 23:22:43.550349  4216 sgd_solver.cpp:106] Iteration 7880, lr = 0.0002
I0625 23:24:28.780478  4216 solver.cpp:228] Iteration 7900, loss = 0.600435
I0625 23:24:28.780503  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 23:24:28.780509  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326245 (* 1 = 0.0326245 loss)
I0625 23:24:28.780514  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0715894 (* 1 = 0.0715894 loss)
I0625 23:24:28.780517  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00431912 (* 1 = 0.00431912 loss)
I0625 23:24:28.780521  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148861 (* 1 = 0.0148861 loss)
I0625 23:24:28.780525  4216 sgd_solver.cpp:106] Iteration 7900, lr = 0.0002
I0625 23:26:13.980476  4216 solver.cpp:228] Iteration 7920, loss = 0.40482
I0625 23:26:13.980501  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 23:26:13.980509  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.274747 (* 1 = 0.274747 loss)
I0625 23:26:13.980514  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.349744 (* 1 = 0.349744 loss)
I0625 23:26:13.980517  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00295618 (* 1 = 0.00295618 loss)
I0625 23:26:13.980521  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0484838 (* 1 = 0.0484838 loss)
I0625 23:26:13.980526  4216 sgd_solver.cpp:106] Iteration 7920, lr = 0.0002
I0625 23:27:59.218395  4216 solver.cpp:228] Iteration 7940, loss = 0.258137
I0625 23:27:59.218421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 23:27:59.218430  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0667081 (* 1 = 0.0667081 loss)
I0625 23:27:59.218435  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.102128 (* 1 = 0.102128 loss)
I0625 23:27:59.218438  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00418074 (* 1 = 0.00418074 loss)
I0625 23:27:59.218442  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010907 (* 1 = 0.010907 loss)
I0625 23:27:59.218447  4216 sgd_solver.cpp:106] Iteration 7940, lr = 0.0002
I0625 23:29:44.434221  4216 solver.cpp:228] Iteration 7960, loss = 0.350805
I0625 23:29:44.434247  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 23:29:44.434254  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0887969 (* 1 = 0.0887969 loss)
I0625 23:29:44.434259  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0998715 (* 1 = 0.0998715 loss)
I0625 23:29:44.434263  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00859705 (* 1 = 0.00859705 loss)
I0625 23:29:44.434267  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270148 (* 1 = 0.0270148 loss)
I0625 23:29:44.434273  4216 sgd_solver.cpp:106] Iteration 7960, lr = 0.0002
I0625 23:31:29.791410  4216 solver.cpp:228] Iteration 7980, loss = 0.412681
I0625 23:31:29.791435  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 23:31:29.791442  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188347 (* 1 = 0.0188347 loss)
I0625 23:31:29.791447  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0639461 (* 1 = 0.0639461 loss)
I0625 23:31:29.791451  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120332 (* 1 = 0.00120332 loss)
I0625 23:31:29.791455  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198975 (* 1 = 0.0198975 loss)
I0625 23:31:29.791460  4216 sgd_solver.cpp:106] Iteration 7980, lr = 0.0002
speed: 5.228s / iter
I0625 23:33:15.117054  4216 solver.cpp:228] Iteration 8000, loss = 0.243351
I0625 23:33:15.117084  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:33:15.117092  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329722 (* 1 = 0.0329722 loss)
I0625 23:33:15.117097  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.167424 (* 1 = 0.167424 loss)
I0625 23:33:15.117101  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00486302 (* 1 = 0.00486302 loss)
I0625 23:33:15.117105  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0058452 (* 1 = 0.0058452 loss)
I0625 23:33:15.117110  4216 sgd_solver.cpp:106] Iteration 8000, lr = 0.0002
I0625 23:35:00.301023  4216 solver.cpp:228] Iteration 8020, loss = 0.130548
I0625 23:35:00.301051  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 23:35:00.301059  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.058786 (* 1 = 0.058786 loss)
I0625 23:35:00.301064  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.172125 (* 1 = 0.172125 loss)
I0625 23:35:00.301069  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00691129 (* 1 = 0.00691129 loss)
I0625 23:35:00.301072  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011943 (* 1 = 0.011943 loss)
I0625 23:35:00.301079  4216 sgd_solver.cpp:106] Iteration 8020, lr = 0.0002
I0625 23:36:45.505753  4216 solver.cpp:228] Iteration 8040, loss = 0.420439
I0625 23:36:45.505779  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 23:36:45.505785  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.248124 (* 1 = 0.248124 loss)
I0625 23:36:45.505790  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.284705 (* 1 = 0.284705 loss)
I0625 23:36:45.505795  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00146917 (* 1 = 0.00146917 loss)
I0625 23:36:45.505800  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394702 (* 1 = 0.0394702 loss)
I0625 23:36:45.505805  4216 sgd_solver.cpp:106] Iteration 8040, lr = 0.0002
I0625 23:38:30.732008  4216 solver.cpp:228] Iteration 8060, loss = 0.429128
I0625 23:38:30.732033  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:38:30.732039  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0901746 (* 1 = 0.0901746 loss)
I0625 23:38:30.732043  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.166661 (* 1 = 0.166661 loss)
I0625 23:38:30.732048  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000510469 (* 1 = 0.000510469 loss)
I0625 23:38:30.732051  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00400154 (* 1 = 0.00400154 loss)
I0625 23:38:30.732056  4216 sgd_solver.cpp:106] Iteration 8060, lr = 0.0002
I0625 23:40:16.132153  4216 solver.cpp:228] Iteration 8080, loss = 0.393701
I0625 23:40:16.132179  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 23:40:16.132185  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.166552 (* 1 = 0.166552 loss)
I0625 23:40:16.132189  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.347805 (* 1 = 0.347805 loss)
I0625 23:40:16.132192  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102608 (* 1 = 0.0102608 loss)
I0625 23:40:16.132196  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111721 (* 1 = 0.111721 loss)
I0625 23:40:16.132201  4216 sgd_solver.cpp:106] Iteration 8080, lr = 0.0002
I0625 23:42:01.617630  4216 solver.cpp:228] Iteration 8100, loss = 0.368635
I0625 23:42:01.617655  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 23:42:01.617662  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.248367 (* 1 = 0.248367 loss)
I0625 23:42:01.617666  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.354422 (* 1 = 0.354422 loss)
I0625 23:42:01.617671  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00975036 (* 1 = 0.00975036 loss)
I0625 23:42:01.617673  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106862 (* 1 = 0.106862 loss)
I0625 23:42:01.617678  4216 sgd_solver.cpp:106] Iteration 8100, lr = 0.0002
I0625 23:43:47.040333  4216 solver.cpp:228] Iteration 8120, loss = 0.289147
I0625 23:43:47.040360  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 23:43:47.040367  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0721854 (* 1 = 0.0721854 loss)
I0625 23:43:47.040372  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.184906 (* 1 = 0.184906 loss)
I0625 23:43:47.040376  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00310685 (* 1 = 0.00310685 loss)
I0625 23:43:47.040380  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322703 (* 1 = 0.0322703 loss)
I0625 23:43:47.040385  4216 sgd_solver.cpp:106] Iteration 8120, lr = 0.0002
I0625 23:45:32.415340  4216 solver.cpp:228] Iteration 8140, loss = 0.319062
I0625 23:45:32.415372  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 23:45:32.415385  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571252 (* 1 = 0.0571252 loss)
I0625 23:45:32.415395  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0970145 (* 1 = 0.0970145 loss)
I0625 23:45:32.415405  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484447 (* 1 = 0.00484447 loss)
I0625 23:45:32.415413  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166641 (* 1 = 0.0166641 loss)
I0625 23:45:32.415421  4216 sgd_solver.cpp:106] Iteration 8140, lr = 0.0002
I0625 23:47:17.900135  4216 solver.cpp:228] Iteration 8160, loss = 0.212454
I0625 23:47:17.900161  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:47:17.900168  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.108991 (* 1 = 0.108991 loss)
I0625 23:47:17.900173  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.187229 (* 1 = 0.187229 loss)
I0625 23:47:17.900177  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000689543 (* 1 = 0.000689543 loss)
I0625 23:47:17.900182  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225708 (* 1 = 0.0225708 loss)
I0625 23:47:17.900187  4216 sgd_solver.cpp:106] Iteration 8160, lr = 0.0002
I0625 23:49:04.096045  4216 solver.cpp:228] Iteration 8180, loss = 0.199469
I0625 23:49:04.096069  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 23:49:04.096076  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104355 (* 1 = 0.104355 loss)
I0625 23:49:04.096081  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.200873 (* 1 = 0.200873 loss)
I0625 23:49:04.096084  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000782236 (* 1 = 0.000782236 loss)
I0625 23:49:04.096088  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022567 (* 1 = 0.022567 loss)
I0625 23:49:04.096093  4216 sgd_solver.cpp:106] Iteration 8180, lr = 0.0002
speed: 5.229s / iter
I0625 23:50:49.632074  4216 solver.cpp:228] Iteration 8200, loss = 0.251047
I0625 23:50:49.632099  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 23:50:49.632107  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0640393 (* 1 = 0.0640393 loss)
I0625 23:50:49.632110  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.130731 (* 1 = 0.130731 loss)
I0625 23:50:49.632114  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101698 (* 1 = 0.00101698 loss)
I0625 23:50:49.632117  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133904 (* 1 = 0.0133904 loss)
I0625 23:50:49.632122  4216 sgd_solver.cpp:106] Iteration 8200, lr = 0.0002
I0625 23:52:35.205546  4216 solver.cpp:228] Iteration 8220, loss = 0.25956
I0625 23:52:35.205572  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:52:35.205580  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.02572 (* 1 = 0.02572 loss)
I0625 23:52:35.205585  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0653355 (* 1 = 0.0653355 loss)
I0625 23:52:35.205588  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00416819 (* 1 = 0.00416819 loss)
I0625 23:52:35.205592  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277365 (* 1 = 0.0277365 loss)
I0625 23:52:35.205598  4216 sgd_solver.cpp:106] Iteration 8220, lr = 0.0002
I0625 23:54:20.664799  4216 solver.cpp:228] Iteration 8240, loss = 0.563094
I0625 23:54:20.664826  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 23:54:20.664834  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.303939 (* 1 = 0.303939 loss)
I0625 23:54:20.664837  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.489556 (* 1 = 0.489556 loss)
I0625 23:54:20.664841  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00702283 (* 1 = 0.00702283 loss)
I0625 23:54:20.664845  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0518259 (* 1 = 0.0518259 loss)
I0625 23:54:20.664850  4216 sgd_solver.cpp:106] Iteration 8240, lr = 0.0002
I0625 23:56:06.059438  4216 solver.cpp:228] Iteration 8260, loss = 0.1594
I0625 23:56:06.059479  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 23:56:06.059494  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349618 (* 1 = 0.0349618 loss)
I0625 23:56:06.059502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0503903 (* 1 = 0.0503903 loss)
I0625 23:56:06.059510  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000466506 (* 1 = 0.000466506 loss)
I0625 23:56:06.059520  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00669155 (* 1 = 0.00669155 loss)
I0625 23:56:06.059530  4216 sgd_solver.cpp:106] Iteration 8260, lr = 0.0002
I0625 23:57:51.790926  4216 solver.cpp:228] Iteration 8280, loss = 0.260283
I0625 23:57:51.790952  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 23:57:51.790961  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.026023 (* 1 = 0.026023 loss)
I0625 23:57:51.790967  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0327089 (* 1 = 0.0327089 loss)
I0625 23:57:51.790973  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000356725 (* 1 = 0.000356725 loss)
I0625 23:57:51.790978  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100312 (* 1 = 0.0100312 loss)
I0625 23:57:51.790985  4216 sgd_solver.cpp:106] Iteration 8280, lr = 0.0002
I0625 23:59:37.133587  4216 solver.cpp:228] Iteration 8300, loss = 0.357763
I0625 23:59:37.133613  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:59:37.133620  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402949 (* 1 = 0.0402949 loss)
I0625 23:59:37.133625  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119503 (* 1 = 0.119503 loss)
I0625 23:59:37.133630  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542036 (* 1 = 0.00542036 loss)
I0625 23:59:37.133633  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00241977 (* 1 = 0.00241977 loss)
I0625 23:59:37.133638  4216 sgd_solver.cpp:106] Iteration 8300, lr = 0.0002
I0626 00:01:22.957669  4216 solver.cpp:228] Iteration 8320, loss = 0.352609
I0626 00:01:22.957695  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:01:22.957703  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0532679 (* 1 = 0.0532679 loss)
I0626 00:01:22.957707  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119889 (* 1 = 0.119889 loss)
I0626 00:01:22.957712  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104392 (* 1 = 0.00104392 loss)
I0626 00:01:22.957716  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00637712 (* 1 = 0.00637712 loss)
I0626 00:01:22.957721  4216 sgd_solver.cpp:106] Iteration 8320, lr = 0.0002
I0626 00:03:08.288385  4216 solver.cpp:228] Iteration 8340, loss = 0.193467
I0626 00:03:08.288414  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:03:08.288425  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465098 (* 1 = 0.0465098 loss)
I0626 00:03:08.288432  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121107 (* 1 = 0.121107 loss)
I0626 00:03:08.288439  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00663698 (* 1 = 0.00663698 loss)
I0626 00:03:08.288445  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176989 (* 1 = 0.0176989 loss)
I0626 00:03:08.288455  4216 sgd_solver.cpp:106] Iteration 8340, lr = 0.0002
I0626 00:04:53.520843  4216 solver.cpp:228] Iteration 8360, loss = 0.207968
I0626 00:04:53.520869  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 00:04:53.520877  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00845717 (* 1 = 0.00845717 loss)
I0626 00:04:53.520882  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0678882 (* 1 = 0.0678882 loss)
I0626 00:04:53.520886  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00486808 (* 1 = 0.00486808 loss)
I0626 00:04:53.520890  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180065 (* 1 = 0.0180065 loss)
I0626 00:04:53.520895  4216 sgd_solver.cpp:106] Iteration 8360, lr = 0.0002
I0626 00:06:38.688697  4216 solver.cpp:228] Iteration 8380, loss = 0.230337
I0626 00:06:38.688725  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 00:06:38.688732  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.198113 (* 1 = 0.198113 loss)
I0626 00:06:38.688736  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.259276 (* 1 = 0.259276 loss)
I0626 00:06:38.688741  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692944 (* 1 = 0.00692944 loss)
I0626 00:06:38.688745  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0656616 (* 1 = 0.0656616 loss)
I0626 00:06:38.688750  4216 sgd_solver.cpp:106] Iteration 8380, lr = 0.0002
speed: 5.230s / iter
I0626 00:08:23.932332  4216 solver.cpp:228] Iteration 8400, loss = 0.354801
I0626 00:08:23.932358  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:08:23.932366  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455932 (* 1 = 0.0455932 loss)
I0626 00:08:23.932370  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0886992 (* 1 = 0.0886992 loss)
I0626 00:08:23.932374  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000394565 (* 1 = 0.000394565 loss)
I0626 00:08:23.932377  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118711 (* 1 = 0.0118711 loss)
I0626 00:08:23.932382  4216 sgd_solver.cpp:106] Iteration 8400, lr = 0.0002
I0626 00:10:09.049052  4216 solver.cpp:228] Iteration 8420, loss = 0.408549
I0626 00:10:09.049079  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 00:10:09.049089  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0849448 (* 1 = 0.0849448 loss)
I0626 00:10:09.049096  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.193981 (* 1 = 0.193981 loss)
I0626 00:10:09.049103  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00461417 (* 1 = 0.00461417 loss)
I0626 00:10:09.049109  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147851 (* 1 = 0.0147851 loss)
I0626 00:10:09.049118  4216 sgd_solver.cpp:106] Iteration 8420, lr = 0.0002
I0626 00:11:54.246704  4216 solver.cpp:228] Iteration 8440, loss = 0.302393
I0626 00:11:54.246733  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:11:54.246740  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591993 (* 1 = 0.0591993 loss)
I0626 00:11:54.246745  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.169865 (* 1 = 0.169865 loss)
I0626 00:11:54.246750  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00630757 (* 1 = 0.00630757 loss)
I0626 00:11:54.246754  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216573 (* 1 = 0.0216573 loss)
I0626 00:11:54.246759  4216 sgd_solver.cpp:106] Iteration 8440, lr = 0.0002
I0626 00:13:39.432611  4216 solver.cpp:228] Iteration 8460, loss = 0.395283
I0626 00:13:39.432636  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 00:13:39.432643  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.106674 (* 1 = 0.106674 loss)
I0626 00:13:39.432647  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.185919 (* 1 = 0.185919 loss)
I0626 00:13:39.432652  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157429 (* 1 = 0.00157429 loss)
I0626 00:13:39.432657  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0376244 (* 1 = 0.0376244 loss)
I0626 00:13:39.432662  4216 sgd_solver.cpp:106] Iteration 8460, lr = 0.0002
I0626 00:15:24.724179  4216 solver.cpp:228] Iteration 8480, loss = 0.319181
I0626 00:15:24.724205  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 00:15:24.724215  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549378 (* 1 = 0.0549378 loss)
I0626 00:15:24.724221  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.151836 (* 1 = 0.151836 loss)
I0626 00:15:24.724227  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00883724 (* 1 = 0.00883724 loss)
I0626 00:15:24.724234  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00906748 (* 1 = 0.00906748 loss)
I0626 00:15:24.724242  4216 sgd_solver.cpp:106] Iteration 8480, lr = 0.0002
I0626 00:17:10.065698  4216 solver.cpp:228] Iteration 8500, loss = 0.171682
I0626 00:17:10.065724  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:17:10.065732  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167849 (* 1 = 0.0167849 loss)
I0626 00:17:10.065737  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0700829 (* 1 = 0.0700829 loss)
I0626 00:17:10.065740  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0047732 (* 1 = 0.0047732 loss)
I0626 00:17:10.065743  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100236 (* 1 = 0.0100236 loss)
I0626 00:17:10.065748  4216 sgd_solver.cpp:106] Iteration 8500, lr = 0.0002
I0626 00:18:55.281875  4216 solver.cpp:228] Iteration 8520, loss = 0.21284
I0626 00:18:55.281899  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 00:18:55.281906  4216 solver.cpp:244]     Train net output #1: loss_bbox = 8.95242e-05 (* 1 = 8.95242e-05 loss)
I0626 00:18:55.281910  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0334954 (* 1 = 0.0334954 loss)
I0626 00:18:55.281914  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147458 (* 1 = 0.00147458 loss)
I0626 00:18:55.281919  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139138 (* 1 = 0.0139138 loss)
I0626 00:18:55.281922  4216 sgd_solver.cpp:106] Iteration 8520, lr = 0.0002
I0626 00:20:40.527963  4216 solver.cpp:228] Iteration 8540, loss = 0.271019
I0626 00:20:40.527987  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 00:20:40.527994  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262602 (* 1 = 0.0262602 loss)
I0626 00:20:40.527998  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.102246 (* 1 = 0.102246 loss)
I0626 00:20:40.528002  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00454895 (* 1 = 0.00454895 loss)
I0626 00:20:40.528007  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00477401 (* 1 = 0.00477401 loss)
I0626 00:20:40.528010  4216 sgd_solver.cpp:106] Iteration 8540, lr = 0.0002
I0626 00:22:25.821434  4216 solver.cpp:228] Iteration 8560, loss = 0.176533
I0626 00:22:25.821460  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 00:22:25.821466  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0352446 (* 1 = 0.0352446 loss)
I0626 00:22:25.821470  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.143059 (* 1 = 0.143059 loss)
I0626 00:22:25.821473  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133771 (* 1 = 0.0133771 loss)
I0626 00:22:25.821477  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039895 (* 1 = 0.039895 loss)
I0626 00:22:25.821481  4216 sgd_solver.cpp:106] Iteration 8560, lr = 0.0002
I0626 00:24:11.128463  4216 solver.cpp:228] Iteration 8580, loss = 0.392207
I0626 00:24:11.128489  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 00:24:11.128497  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.193067 (* 1 = 0.193067 loss)
I0626 00:24:11.128502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.336115 (* 1 = 0.336115 loss)
I0626 00:24:11.128506  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101934 (* 1 = 0.0101934 loss)
I0626 00:24:11.128509  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227919 (* 1 = 0.0227919 loss)
I0626 00:24:11.128515  4216 sgd_solver.cpp:106] Iteration 8580, lr = 0.0002
speed: 5.231s / iter
I0626 00:25:56.378093  4216 solver.cpp:228] Iteration 8600, loss = 0.597327
I0626 00:25:56.378118  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0626 00:25:56.378125  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.501062 (* 1 = 0.501062 loss)
I0626 00:25:56.378130  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.773219 (* 1 = 0.773219 loss)
I0626 00:25:56.378134  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0586109 (* 1 = 0.0586109 loss)
I0626 00:25:56.378139  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.319731 (* 1 = 0.319731 loss)
I0626 00:25:56.378144  4216 sgd_solver.cpp:106] Iteration 8600, lr = 0.0002
I0626 00:27:41.877632  4216 solver.cpp:228] Iteration 8620, loss = 0.36714
I0626 00:27:41.877658  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 00:27:41.877670  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00045402 (* 1 = 0.00045402 loss)
I0626 00:27:41.877676  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.025085 (* 1 = 0.025085 loss)
I0626 00:27:41.877682  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0030588 (* 1 = 0.0030588 loss)
I0626 00:27:41.877688  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021443 (* 1 = 0.021443 loss)
I0626 00:27:41.877696  4216 sgd_solver.cpp:106] Iteration 8620, lr = 0.0002
I0626 00:29:27.502545  4216 solver.cpp:228] Iteration 8640, loss = 0.236852
I0626 00:29:27.502571  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:29:27.502579  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0584376 (* 1 = 0.0584376 loss)
I0626 00:29:27.502583  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0674783 (* 1 = 0.0674783 loss)
I0626 00:29:27.502588  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00465751 (* 1 = 0.00465751 loss)
I0626 00:29:27.502593  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152378 (* 1 = 0.0152378 loss)
I0626 00:29:27.502598  4216 sgd_solver.cpp:106] Iteration 8640, lr = 0.0002
I0626 00:31:12.963704  4216 solver.cpp:228] Iteration 8660, loss = 0.286566
I0626 00:31:12.963730  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 00:31:12.963738  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0676746 (* 1 = 0.0676746 loss)
I0626 00:31:12.963743  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0568227 (* 1 = 0.0568227 loss)
I0626 00:31:12.963747  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122519 (* 1 = 0.00122519 loss)
I0626 00:31:12.963752  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145302 (* 1 = 0.0145302 loss)
I0626 00:31:12.963757  4216 sgd_solver.cpp:106] Iteration 8660, lr = 0.0002
I0626 00:32:58.647191  4216 solver.cpp:228] Iteration 8680, loss = 0.158642
I0626 00:32:58.647219  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:32:58.647228  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.067642 (* 1 = 0.067642 loss)
I0626 00:32:58.647233  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0701003 (* 1 = 0.0701003 loss)
I0626 00:32:58.647238  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011158 (* 1 = 0.011158 loss)
I0626 00:32:58.647243  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00922129 (* 1 = 0.00922129 loss)
I0626 00:32:58.647248  4216 sgd_solver.cpp:106] Iteration 8680, lr = 0.0002
I0626 00:34:44.233345  4216 solver.cpp:228] Iteration 8700, loss = 0.308563
I0626 00:34:44.233373  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 00:34:44.233381  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113332 (* 1 = 0.0113332 loss)
I0626 00:34:44.233386  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.048208 (* 1 = 0.048208 loss)
I0626 00:34:44.233391  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134248 (* 1 = 0.0134248 loss)
I0626 00:34:44.233394  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00716724 (* 1 = 0.00716724 loss)
I0626 00:34:44.233400  4216 sgd_solver.cpp:106] Iteration 8700, lr = 0.0002
I0626 00:36:29.689553  4216 solver.cpp:228] Iteration 8720, loss = 0.558717
I0626 00:36:29.689579  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 00:36:29.689589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.169338 (* 1 = 0.169338 loss)
I0626 00:36:29.689594  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.479815 (* 1 = 0.479815 loss)
I0626 00:36:29.689599  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113723 (* 1 = 0.0113723 loss)
I0626 00:36:29.689605  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0417381 (* 1 = 0.0417381 loss)
I0626 00:36:29.689612  4216 sgd_solver.cpp:106] Iteration 8720, lr = 0.0002
I0626 00:38:15.183285  4216 solver.cpp:228] Iteration 8740, loss = 0.231517
I0626 00:38:15.183310  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:38:15.183317  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0810774 (* 1 = 0.0810774 loss)
I0626 00:38:15.183321  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0956474 (* 1 = 0.0956474 loss)
I0626 00:38:15.183326  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0087449 (* 1 = 0.0087449 loss)
I0626 00:38:15.183328  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158112 (* 1 = 0.0158112 loss)
I0626 00:38:15.183333  4216 sgd_solver.cpp:106] Iteration 8740, lr = 0.0002
I0626 00:40:00.852980  4216 solver.cpp:228] Iteration 8760, loss = 0.630682
I0626 00:40:00.853008  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0626 00:40:00.853018  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.403465 (* 1 = 0.403465 loss)
I0626 00:40:00.853024  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.626969 (* 1 = 0.626969 loss)
I0626 00:40:00.853027  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0674131 (* 1 = 0.0674131 loss)
I0626 00:40:00.853032  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481207 (* 1 = 0.0481207 loss)
I0626 00:40:00.853039  4216 sgd_solver.cpp:106] Iteration 8760, lr = 0.0002
I0626 00:41:46.438719  4216 solver.cpp:228] Iteration 8780, loss = 0.392949
I0626 00:41:46.438742  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 00:41:46.438750  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.162058 (* 1 = 0.162058 loss)
I0626 00:41:46.438753  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.202396 (* 1 = 0.202396 loss)
I0626 00:41:46.438757  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184874 (* 1 = 0.00184874 loss)
I0626 00:41:46.438761  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395605 (* 1 = 0.0395605 loss)
I0626 00:41:46.438766  4216 sgd_solver.cpp:106] Iteration 8780, lr = 0.0002
speed: 5.232s / iter
I0626 00:43:33.192127  4216 solver.cpp:228] Iteration 8800, loss = 0.447733
I0626 00:43:33.192159  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 00:43:33.192169  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000282099 (* 1 = 0.000282099 loss)
I0626 00:43:33.192175  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.063472 (* 1 = 0.063472 loss)
I0626 00:43:33.192181  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125562 (* 1 = 0.0125562 loss)
I0626 00:43:33.192186  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282509 (* 1 = 0.0282509 loss)
I0626 00:43:33.192193  4216 sgd_solver.cpp:106] Iteration 8800, lr = 0.0002
I0626 00:45:18.437674  4216 solver.cpp:228] Iteration 8820, loss = 0.301696
I0626 00:45:18.437700  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 00:45:18.437706  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.136968 (* 1 = 0.136968 loss)
I0626 00:45:18.437711  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.20614 (* 1 = 0.20614 loss)
I0626 00:45:18.437716  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00438742 (* 1 = 0.00438742 loss)
I0626 00:45:18.437719  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237508 (* 1 = 0.0237508 loss)
I0626 00:45:18.437724  4216 sgd_solver.cpp:106] Iteration 8820, lr = 0.0002
I0626 00:47:03.911317  4216 solver.cpp:228] Iteration 8840, loss = 0.394955
I0626 00:47:03.911343  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0626 00:47:03.911353  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.448454 (* 1 = 0.448454 loss)
I0626 00:47:03.911360  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.610973 (* 1 = 0.610973 loss)
I0626 00:47:03.911365  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107852 (* 1 = 0.0107852 loss)
I0626 00:47:03.911372  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107415 (* 1 = 0.107415 loss)
I0626 00:47:03.911379  4216 sgd_solver.cpp:106] Iteration 8840, lr = 0.0002
I0626 00:48:49.135428  4216 solver.cpp:228] Iteration 8860, loss = 0.192459
I0626 00:48:49.135453  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 00:48:49.135462  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0328043 (* 1 = 0.0328043 loss)
I0626 00:48:49.135465  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.163852 (* 1 = 0.163852 loss)
I0626 00:48:49.135469  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000957339 (* 1 = 0.000957339 loss)
I0626 00:48:49.135474  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00700195 (* 1 = 0.00700195 loss)
I0626 00:48:49.135479  4216 sgd_solver.cpp:106] Iteration 8860, lr = 0.0002
I0626 00:50:34.427147  4216 solver.cpp:228] Iteration 8880, loss = 0.258907
I0626 00:50:34.427171  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 00:50:34.427179  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0583025 (* 1 = 0.0583025 loss)
I0626 00:50:34.427184  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0959813 (* 1 = 0.0959813 loss)
I0626 00:50:34.427188  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00667446 (* 1 = 0.00667446 loss)
I0626 00:50:34.427192  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00865866 (* 1 = 0.00865866 loss)
I0626 00:50:34.427197  4216 sgd_solver.cpp:106] Iteration 8880, lr = 0.0002
I0626 00:52:19.757843  4216 solver.cpp:228] Iteration 8900, loss = 0.267666
I0626 00:52:19.757866  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 00:52:19.757874  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0343164 (* 1 = 0.0343164 loss)
I0626 00:52:19.757879  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0583583 (* 1 = 0.0583583 loss)
I0626 00:52:19.757882  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000394795 (* 1 = 0.000394795 loss)
I0626 00:52:19.757886  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127487 (* 1 = 0.0127487 loss)
I0626 00:52:19.757891  4216 sgd_solver.cpp:106] Iteration 8900, lr = 0.0002
I0626 00:54:04.974503  4216 solver.cpp:228] Iteration 8920, loss = 0.248808
I0626 00:54:04.974525  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 00:54:04.974532  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0330312 (* 1 = 0.0330312 loss)
I0626 00:54:04.974539  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.111948 (* 1 = 0.111948 loss)
I0626 00:54:04.974545  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356561 (* 1 = 0.00356561 loss)
I0626 00:54:04.974548  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153008 (* 1 = 0.0153008 loss)
I0626 00:54:04.974553  4216 sgd_solver.cpp:106] Iteration 8920, lr = 0.0002
I0626 00:55:50.172981  4216 solver.cpp:228] Iteration 8940, loss = 0.131635
I0626 00:55:50.173004  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 00:55:50.173012  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329149 (* 1 = 0.0329149 loss)
I0626 00:55:50.173017  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0533729 (* 1 = 0.0533729 loss)
I0626 00:55:50.173020  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000868881 (* 1 = 0.000868881 loss)
I0626 00:55:50.173023  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117576 (* 1 = 0.0117576 loss)
I0626 00:55:50.173028  4216 sgd_solver.cpp:106] Iteration 8940, lr = 0.0002
I0626 00:57:35.587119  4216 solver.cpp:228] Iteration 8960, loss = 0.232517
I0626 00:57:35.587149  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:57:35.587159  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0491552 (* 1 = 0.0491552 loss)
I0626 00:57:35.587165  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0692331 (* 1 = 0.0692331 loss)
I0626 00:57:35.587172  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127917 (* 1 = 0.0127917 loss)
I0626 00:57:35.587177  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00952683 (* 1 = 0.00952683 loss)
I0626 00:57:35.587186  4216 sgd_solver.cpp:106] Iteration 8960, lr = 0.0002
I0626 00:59:20.785801  4216 solver.cpp:228] Iteration 8980, loss = 0.372483
I0626 00:59:20.785826  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 00:59:20.785833  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0920144 (* 1 = 0.0920144 loss)
I0626 00:59:20.785837  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.354931 (* 1 = 0.354931 loss)
I0626 00:59:20.785841  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00317635 (* 1 = 0.00317635 loss)
I0626 00:59:20.785845  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490988 (* 1 = 0.0490988 loss)
I0626 00:59:20.785850  4216 sgd_solver.cpp:106] Iteration 8980, lr = 0.0002
speed: 5.233s / iter
I0626 01:01:06.002354  4216 solver.cpp:228] Iteration 9000, loss = 0.363825
I0626 01:01:06.002379  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 01:01:06.002387  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334308 (* 1 = 0.0334308 loss)
I0626 01:01:06.002390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.048656 (* 1 = 0.048656 loss)
I0626 01:01:06.002394  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.66638e-05 (* 1 = 9.66638e-05 loss)
I0626 01:01:06.002398  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00244374 (* 1 = 0.00244374 loss)
I0626 01:01:06.002403  4216 sgd_solver.cpp:106] Iteration 9000, lr = 0.0002
I0626 01:02:51.171844  4216 solver.cpp:228] Iteration 9020, loss = 0.443967
I0626 01:02:51.171872  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 01:02:51.171880  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.127568 (* 1 = 0.127568 loss)
I0626 01:02:51.171885  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.228949 (* 1 = 0.228949 loss)
I0626 01:02:51.171888  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161917 (* 1 = 0.0161917 loss)
I0626 01:02:51.171892  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208048 (* 1 = 0.0208048 loss)
I0626 01:02:51.171897  4216 sgd_solver.cpp:106] Iteration 9020, lr = 0.0002
I0626 01:04:36.350662  4216 solver.cpp:228] Iteration 9040, loss = 0.31679
I0626 01:04:36.350688  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:04:36.350697  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266171 (* 1 = 0.0266171 loss)
I0626 01:04:36.350700  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.073142 (* 1 = 0.073142 loss)
I0626 01:04:36.350704  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000269895 (* 1 = 0.000269895 loss)
I0626 01:04:36.350708  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00475279 (* 1 = 0.00475279 loss)
I0626 01:04:36.350714  4216 sgd_solver.cpp:106] Iteration 9040, lr = 0.0002
I0626 01:06:21.788528  4216 solver.cpp:228] Iteration 9060, loss = 0.28786
I0626 01:06:21.788552  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 01:06:21.788559  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0638934 (* 1 = 0.0638934 loss)
I0626 01:06:21.788563  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.311001 (* 1 = 0.311001 loss)
I0626 01:06:21.788568  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0358339 (* 1 = 0.0358339 loss)
I0626 01:06:21.788570  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.260589 (* 1 = 0.260589 loss)
I0626 01:06:21.788575  4216 sgd_solver.cpp:106] Iteration 9060, lr = 0.0002
I0626 01:08:07.038919  4216 solver.cpp:228] Iteration 9080, loss = 0.323749
I0626 01:08:07.038944  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:08:07.038954  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.038324 (* 1 = 0.038324 loss)
I0626 01:08:07.038959  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.100438 (* 1 = 0.100438 loss)
I0626 01:08:07.038965  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189129 (* 1 = 0.00189129 loss)
I0626 01:08:07.038971  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144666 (* 1 = 0.0144666 loss)
I0626 01:08:07.038977  4216 sgd_solver.cpp:106] Iteration 9080, lr = 0.0002
I0626 01:09:52.363492  4216 solver.cpp:228] Iteration 9100, loss = 0.230445
I0626 01:09:52.363515  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 01:09:52.363523  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0998447 (* 1 = 0.0998447 loss)
I0626 01:09:52.363526  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.183717 (* 1 = 0.183717 loss)
I0626 01:09:52.363530  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00287034 (* 1 = 0.00287034 loss)
I0626 01:09:52.363534  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305474 (* 1 = 0.0305474 loss)
I0626 01:09:52.363538  4216 sgd_solver.cpp:106] Iteration 9100, lr = 0.0002
I0626 01:11:37.592365  4216 solver.cpp:228] Iteration 9120, loss = 0.314747
I0626 01:11:37.592392  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 01:11:37.592399  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.251396 (* 1 = 0.251396 loss)
I0626 01:11:37.592403  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.361065 (* 1 = 0.361065 loss)
I0626 01:11:37.592407  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600717 (* 1 = 0.00600717 loss)
I0626 01:11:37.592411  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0354423 (* 1 = 0.0354423 loss)
I0626 01:11:37.592417  4216 sgd_solver.cpp:106] Iteration 9120, lr = 0.0002
I0626 01:13:22.877064  4216 solver.cpp:228] Iteration 9140, loss = 0.421578
I0626 01:13:22.877091  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:13:22.877100  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0871368 (* 1 = 0.0871368 loss)
I0626 01:13:22.877106  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.100988 (* 1 = 0.100988 loss)
I0626 01:13:22.877112  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00111389 (* 1 = 0.00111389 loss)
I0626 01:13:22.877118  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00666879 (* 1 = 0.00666879 loss)
I0626 01:13:22.877126  4216 sgd_solver.cpp:106] Iteration 9140, lr = 0.0002
I0626 01:15:08.152643  4216 solver.cpp:228] Iteration 9160, loss = 0.358009
I0626 01:15:08.152673  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 01:15:08.152683  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816462 (* 1 = 0.0816462 loss)
I0626 01:15:08.152689  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.21036 (* 1 = 0.21036 loss)
I0626 01:15:08.152695  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00366695 (* 1 = 0.00366695 loss)
I0626 01:15:08.152700  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00950908 (* 1 = 0.00950908 loss)
I0626 01:15:08.152707  4216 sgd_solver.cpp:106] Iteration 9160, lr = 0.0002
I0626 01:16:53.433333  4216 solver.cpp:228] Iteration 9180, loss = 0.265204
I0626 01:16:53.433364  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 01:16:53.433374  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0824899 (* 1 = 0.0824899 loss)
I0626 01:16:53.433380  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.156773 (* 1 = 0.156773 loss)
I0626 01:16:53.433387  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245879 (* 1 = 0.00245879 loss)
I0626 01:16:53.433393  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257317 (* 1 = 0.0257317 loss)
I0626 01:16:53.433398  4216 sgd_solver.cpp:106] Iteration 9180, lr = 0.0002
speed: 5.233s / iter
I0626 01:18:39.083575  4216 solver.cpp:228] Iteration 9200, loss = 0.563718
I0626 01:18:39.083603  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0626 01:18:39.083612  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.308517 (* 1 = 0.308517 loss)
I0626 01:18:39.083617  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.445441 (* 1 = 0.445441 loss)
I0626 01:18:39.083622  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356149 (* 1 = 0.00356149 loss)
I0626 01:18:39.083627  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400415 (* 1 = 0.0400415 loss)
I0626 01:18:39.083632  4216 sgd_solver.cpp:106] Iteration 9200, lr = 0.0002
I0626 01:20:24.674335  4216 solver.cpp:228] Iteration 9220, loss = 0.337292
I0626 01:20:24.674365  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 01:20:24.674373  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.153566 (* 1 = 0.153566 loss)
I0626 01:20:24.674378  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.293398 (* 1 = 0.293398 loss)
I0626 01:20:24.674382  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0323288 (* 1 = 0.0323288 loss)
I0626 01:20:24.674386  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0561188 (* 1 = 0.0561188 loss)
I0626 01:20:24.674392  4216 sgd_solver.cpp:106] Iteration 9220, lr = 0.0002
I0626 01:22:10.042038  4216 solver.cpp:228] Iteration 9240, loss = 0.264935
I0626 01:22:10.042062  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:22:10.042070  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466628 (* 1 = 0.0466628 loss)
I0626 01:22:10.042074  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0792712 (* 1 = 0.0792712 loss)
I0626 01:22:10.042078  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00803783 (* 1 = 0.00803783 loss)
I0626 01:22:10.042081  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263023 (* 1 = 0.0263023 loss)
I0626 01:22:10.042086  4216 sgd_solver.cpp:106] Iteration 9240, lr = 0.0002
I0626 01:23:55.597205  4216 solver.cpp:228] Iteration 9260, loss = 0.174059
I0626 01:23:55.597234  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:23:55.597245  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205949 (* 1 = 0.0205949 loss)
I0626 01:23:55.597251  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0755086 (* 1 = 0.0755086 loss)
I0626 01:23:55.597259  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359826 (* 1 = 0.00359826 loss)
I0626 01:23:55.597265  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100538 (* 1 = 0.0100538 loss)
I0626 01:23:55.597275  4216 sgd_solver.cpp:106] Iteration 9260, lr = 0.0002
I0626 01:25:41.005093  4216 solver.cpp:228] Iteration 9280, loss = 0.233127
I0626 01:25:41.005121  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 01:25:41.005131  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0746221 (* 1 = 0.0746221 loss)
I0626 01:25:41.005136  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.182472 (* 1 = 0.182472 loss)
I0626 01:25:41.005141  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00166025 (* 1 = 0.00166025 loss)
I0626 01:25:41.005146  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125853 (* 1 = 0.0125853 loss)
I0626 01:25:41.005151  4216 sgd_solver.cpp:106] Iteration 9280, lr = 0.0002
I0626 01:27:26.501647  4216 solver.cpp:228] Iteration 9300, loss = 0.231625
I0626 01:27:26.501672  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 01:27:26.501679  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0790486 (* 1 = 0.0790486 loss)
I0626 01:27:26.501683  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.177409 (* 1 = 0.177409 loss)
I0626 01:27:26.501687  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000558041 (* 1 = 0.000558041 loss)
I0626 01:27:26.501689  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138815 (* 1 = 0.0138815 loss)
I0626 01:27:26.501694  4216 sgd_solver.cpp:106] Iteration 9300, lr = 0.0002
I0626 01:29:12.100090  4216 solver.cpp:228] Iteration 9320, loss = 0.33158
I0626 01:29:12.100117  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 01:29:12.100126  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144405 (* 1 = 0.0144405 loss)
I0626 01:29:12.100132  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.049173 (* 1 = 0.049173 loss)
I0626 01:29:12.100137  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167854 (* 1 = 0.00167854 loss)
I0626 01:29:12.100142  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00609225 (* 1 = 0.00609225 loss)
I0626 01:29:12.100147  4216 sgd_solver.cpp:106] Iteration 9320, lr = 0.0002
I0626 01:30:57.555078  4216 solver.cpp:228] Iteration 9340, loss = 0.231094
I0626 01:30:57.555105  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:30:57.555112  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236494 (* 1 = 0.0236494 loss)
I0626 01:30:57.555117  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0871582 (* 1 = 0.0871582 loss)
I0626 01:30:57.555121  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591859 (* 1 = 0.00591859 loss)
I0626 01:30:57.555125  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113945 (* 1 = 0.0113945 loss)
I0626 01:30:57.555130  4216 sgd_solver.cpp:106] Iteration 9340, lr = 0.0002
I0626 01:32:42.760057  4216 solver.cpp:228] Iteration 9360, loss = 0.274584
I0626 01:32:42.760082  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0626 01:32:42.760089  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.354047 (* 1 = 0.354047 loss)
I0626 01:32:42.760093  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.670325 (* 1 = 0.670325 loss)
I0626 01:32:42.760097  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012648 (* 1 = 0.012648 loss)
I0626 01:32:42.760102  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0924881 (* 1 = 0.0924881 loss)
I0626 01:32:42.760107  4216 sgd_solver.cpp:106] Iteration 9360, lr = 0.0002
I0626 01:34:28.155067  4216 solver.cpp:228] Iteration 9380, loss = 0.298045
I0626 01:34:28.155099  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0626 01:34:28.155109  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.21409 (* 1 = 0.21409 loss)
I0626 01:34:28.155114  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.416258 (* 1 = 0.416258 loss)
I0626 01:34:28.155120  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00866628 (* 1 = 0.00866628 loss)
I0626 01:34:28.155125  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358553 (* 1 = 0.0358553 loss)
I0626 01:34:28.155133  4216 sgd_solver.cpp:106] Iteration 9380, lr = 0.0002
speed: 5.234s / iter
I0626 01:36:13.621120  4216 solver.cpp:228] Iteration 9400, loss = 0.435875
I0626 01:36:13.621150  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 01:36:13.621160  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0731781 (* 1 = 0.0731781 loss)
I0626 01:36:13.621167  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.113613 (* 1 = 0.113613 loss)
I0626 01:36:13.621172  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000987484 (* 1 = 0.000987484 loss)
I0626 01:36:13.621177  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125189 (* 1 = 0.0125189 loss)
I0626 01:36:13.621184  4216 sgd_solver.cpp:106] Iteration 9400, lr = 0.0002
I0626 01:37:58.896015  4216 solver.cpp:228] Iteration 9420, loss = 0.413973
I0626 01:37:58.896039  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 01:37:58.896046  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0560648 (* 1 = 0.0560648 loss)
I0626 01:37:58.896051  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.120428 (* 1 = 0.120428 loss)
I0626 01:37:58.896055  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276899 (* 1 = 0.00276899 loss)
I0626 01:37:58.896059  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0093143 (* 1 = 0.0093143 loss)
I0626 01:37:58.896064  4216 sgd_solver.cpp:106] Iteration 9420, lr = 0.0002
I0626 01:39:44.096086  4216 solver.cpp:228] Iteration 9440, loss = 0.231171
I0626 01:39:44.096112  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 01:39:44.096119  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142585 (* 1 = 0.0142585 loss)
I0626 01:39:44.096123  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0700926 (* 1 = 0.0700926 loss)
I0626 01:39:44.096127  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00667763 (* 1 = 0.00667763 loss)
I0626 01:39:44.096132  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322228 (* 1 = 0.00322228 loss)
I0626 01:39:44.096137  4216 sgd_solver.cpp:106] Iteration 9440, lr = 0.0002
I0626 01:41:29.339854  4216 solver.cpp:228] Iteration 9460, loss = 0.346742
I0626 01:41:29.339881  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 01:41:29.339890  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.30419 (* 1 = 0.30419 loss)
I0626 01:41:29.339893  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.412164 (* 1 = 0.412164 loss)
I0626 01:41:29.339897  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.165927 (* 1 = 0.165927 loss)
I0626 01:41:29.339900  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116329 (* 1 = 0.116329 loss)
I0626 01:41:29.339906  4216 sgd_solver.cpp:106] Iteration 9460, lr = 0.0002
I0626 01:43:14.552850  4216 solver.cpp:228] Iteration 9480, loss = 0.317215
I0626 01:43:14.552873  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 01:43:14.552882  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0643988 (* 1 = 0.0643988 loss)
I0626 01:43:14.552888  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0748458 (* 1 = 0.0748458 loss)
I0626 01:43:14.552893  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0048714 (* 1 = 0.0048714 loss)
I0626 01:43:14.552899  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00997557 (* 1 = 0.00997557 loss)
I0626 01:43:14.552906  4216 sgd_solver.cpp:106] Iteration 9480, lr = 0.0002
I0626 01:44:59.682057  4216 solver.cpp:228] Iteration 9500, loss = 0.243384
I0626 01:44:59.682082  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 01:44:59.682088  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0446785 (* 1 = 0.0446785 loss)
I0626 01:44:59.682093  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0968183 (* 1 = 0.0968183 loss)
I0626 01:44:59.682096  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0356133 (* 1 = 0.0356133 loss)
I0626 01:44:59.682101  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140245 (* 1 = 0.0140245 loss)
I0626 01:44:59.682104  4216 sgd_solver.cpp:106] Iteration 9500, lr = 0.0002
I0626 01:46:44.907369  4216 solver.cpp:228] Iteration 9520, loss = 0.202729
I0626 01:46:44.907393  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 01:46:44.907400  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.100212 (* 1 = 0.100212 loss)
I0626 01:46:44.907403  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.201904 (* 1 = 0.201904 loss)
I0626 01:46:44.907407  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154388 (* 1 = 0.0154388 loss)
I0626 01:46:44.907411  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189403 (* 1 = 0.0189403 loss)
I0626 01:46:44.907416  4216 sgd_solver.cpp:106] Iteration 9520, lr = 0.0002
I0626 01:48:30.195052  4216 solver.cpp:228] Iteration 9540, loss = 0.257357
I0626 01:48:30.195077  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 01:48:30.195086  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.156967 (* 1 = 0.156967 loss)
I0626 01:48:30.195088  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.237162 (* 1 = 0.237162 loss)
I0626 01:48:30.195092  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028874 (* 1 = 0.0028874 loss)
I0626 01:48:30.195096  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141039 (* 1 = 0.0141039 loss)
I0626 01:48:30.195101  4216 sgd_solver.cpp:106] Iteration 9540, lr = 0.0002
I0626 01:50:15.375391  4216 solver.cpp:228] Iteration 9560, loss = 0.435143
I0626 01:50:15.375416  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 01:50:15.375423  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0555347 (* 1 = 0.0555347 loss)
I0626 01:50:15.375428  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.2058 (* 1 = 0.2058 loss)
I0626 01:50:15.375432  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00552831 (* 1 = 0.00552831 loss)
I0626 01:50:15.375435  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0610084 (* 1 = 0.0610084 loss)
I0626 01:50:15.375439  4216 sgd_solver.cpp:106] Iteration 9560, lr = 0.0002
I0626 01:52:00.612387  4216 solver.cpp:228] Iteration 9580, loss = 0.434801
I0626 01:52:00.612412  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 01:52:00.612421  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.193423 (* 1 = 0.193423 loss)
I0626 01:52:00.612427  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.309312 (* 1 = 0.309312 loss)
I0626 01:52:00.612432  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0400319 (* 1 = 0.0400319 loss)
I0626 01:52:00.612438  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100376 (* 1 = 0.100376 loss)
I0626 01:52:00.612445  4216 sgd_solver.cpp:106] Iteration 9580, lr = 0.0002
speed: 5.235s / iter
I0626 01:53:45.834069  4216 solver.cpp:228] Iteration 9600, loss = 0.183613
I0626 01:53:45.834095  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 01:53:45.834102  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0996725 (* 1 = 0.0996725 loss)
I0626 01:53:45.834106  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.195038 (* 1 = 0.195038 loss)
I0626 01:53:45.834111  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616381 (* 1 = 0.00616381 loss)
I0626 01:53:45.834117  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170753 (* 1 = 0.0170753 loss)
I0626 01:53:45.834125  4216 sgd_solver.cpp:106] Iteration 9600, lr = 0.0002
I0626 01:55:31.198405  4216 solver.cpp:228] Iteration 9620, loss = 0.294305
I0626 01:55:31.198428  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0626 01:55:31.198436  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.238328 (* 1 = 0.238328 loss)
I0626 01:55:31.198439  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.359802 (* 1 = 0.359802 loss)
I0626 01:55:31.198443  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011614 (* 1 = 0.011614 loss)
I0626 01:55:31.198446  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448393 (* 1 = 0.0448393 loss)
I0626 01:55:31.198451  4216 sgd_solver.cpp:106] Iteration 9620, lr = 0.0002
I0626 01:57:16.429080  4216 solver.cpp:228] Iteration 9640, loss = 0.478332
I0626 01:57:16.429102  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 01:57:16.429109  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.109736 (* 1 = 0.109736 loss)
I0626 01:57:16.429113  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.191634 (* 1 = 0.191634 loss)
I0626 01:57:16.429117  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000870027 (* 1 = 0.000870027 loss)
I0626 01:57:16.429121  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324701 (* 1 = 0.0324701 loss)
I0626 01:57:16.429126  4216 sgd_solver.cpp:106] Iteration 9640, lr = 0.0002
I0626 01:59:01.694983  4216 solver.cpp:228] Iteration 9660, loss = 0.162328
I0626 01:59:01.695008  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 01:59:01.695016  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294811 (* 1 = 0.0294811 loss)
I0626 01:59:01.695022  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0937462 (* 1 = 0.0937462 loss)
I0626 01:59:01.695029  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216435 (* 1 = 0.00216435 loss)
I0626 01:59:01.695034  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00762073 (* 1 = 0.00762073 loss)
I0626 01:59:01.695040  4216 sgd_solver.cpp:106] Iteration 9660, lr = 0.0002
I0626 02:00:46.973865  4216 solver.cpp:228] Iteration 9680, loss = 0.226247
I0626 02:00:46.973889  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:00:46.973896  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.022317 (* 1 = 0.022317 loss)
I0626 02:00:46.973901  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0742836 (* 1 = 0.0742836 loss)
I0626 02:00:46.973904  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00389338 (* 1 = 0.00389338 loss)
I0626 02:00:46.973908  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00583335 (* 1 = 0.00583335 loss)
I0626 02:00:46.973913  4216 sgd_solver.cpp:106] Iteration 9680, lr = 0.0002
I0626 02:02:32.262853  4216 solver.cpp:228] Iteration 9700, loss = 0.427264
I0626 02:02:32.262881  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 02:02:32.262889  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.217468 (* 1 = 0.217468 loss)
I0626 02:02:32.262894  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.342991 (* 1 = 0.342991 loss)
I0626 02:02:32.262898  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00672584 (* 1 = 0.00672584 loss)
I0626 02:02:32.262902  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400543 (* 1 = 0.0400543 loss)
I0626 02:02:32.262907  4216 sgd_solver.cpp:106] Iteration 9700, lr = 0.0002
I0626 02:04:17.703995  4216 solver.cpp:228] Iteration 9720, loss = 0.326932
I0626 02:04:17.704021  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:04:17.704030  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00651172 (* 1 = 0.00651172 loss)
I0626 02:04:17.704035  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0702738 (* 1 = 0.0702738 loss)
I0626 02:04:17.704038  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00505088 (* 1 = 0.00505088 loss)
I0626 02:04:17.704042  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00713447 (* 1 = 0.00713447 loss)
I0626 02:04:17.704047  4216 sgd_solver.cpp:106] Iteration 9720, lr = 0.0002
I0626 02:06:03.138782  4216 solver.cpp:228] Iteration 9740, loss = 0.222063
I0626 02:06:03.138808  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 02:06:03.138816  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0553 (* 1 = 0.0553 loss)
I0626 02:06:03.138823  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.162187 (* 1 = 0.162187 loss)
I0626 02:06:03.138828  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119236 (* 1 = 0.00119236 loss)
I0626 02:06:03.138834  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210987 (* 1 = 0.0210987 loss)
I0626 02:06:03.138840  4216 sgd_solver.cpp:106] Iteration 9740, lr = 0.0002
I0626 02:07:48.738251  4216 solver.cpp:228] Iteration 9760, loss = 0.189944
I0626 02:07:48.738297  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 02:07:48.738306  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.059853 (* 1 = 0.059853 loss)
I0626 02:07:48.738312  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0865778 (* 1 = 0.0865778 loss)
I0626 02:07:48.738315  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318642 (* 1 = 0.00318642 loss)
I0626 02:07:48.738319  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353254 (* 1 = 0.0353254 loss)
I0626 02:07:48.738327  4216 sgd_solver.cpp:106] Iteration 9760, lr = 0.0002
I0626 02:09:34.333554  4216 solver.cpp:228] Iteration 9780, loss = 0.168451
I0626 02:09:34.333585  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 02:09:34.333595  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392683 (* 1 = 0.0392683 loss)
I0626 02:09:34.333601  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.11291 (* 1 = 0.11291 loss)
I0626 02:09:34.333606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00668642 (* 1 = 0.00668642 loss)
I0626 02:09:34.333611  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104477 (* 1 = 0.0104477 loss)
I0626 02:09:34.333618  4216 sgd_solver.cpp:106] Iteration 9780, lr = 0.0002
speed: 5.236s / iter
I0626 02:11:19.691644  4216 solver.cpp:228] Iteration 9800, loss = 0.201307
I0626 02:11:19.691669  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:11:19.691678  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627053 (* 1 = 0.0627053 loss)
I0626 02:11:19.691682  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.143573 (* 1 = 0.143573 loss)
I0626 02:11:19.691686  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000185802 (* 1 = 0.000185802 loss)
I0626 02:11:19.691690  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00745282 (* 1 = 0.00745282 loss)
I0626 02:11:19.691695  4216 sgd_solver.cpp:106] Iteration 9800, lr = 0.0002
I0626 02:13:05.303972  4216 solver.cpp:228] Iteration 9820, loss = 0.312894
I0626 02:13:05.304002  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:13:05.304010  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410501 (* 1 = 0.0410501 loss)
I0626 02:13:05.304016  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0727509 (* 1 = 0.0727509 loss)
I0626 02:13:05.304021  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00687943 (* 1 = 0.00687943 loss)
I0626 02:13:05.304025  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187162 (* 1 = 0.0187162 loss)
I0626 02:13:05.304031  4216 sgd_solver.cpp:106] Iteration 9820, lr = 0.0002
I0626 02:14:50.894367  4216 solver.cpp:228] Iteration 9840, loss = 0.2715
I0626 02:14:50.894398  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 02:14:50.894408  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0833409 (* 1 = 0.0833409 loss)
I0626 02:14:50.894414  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117188 (* 1 = 0.117188 loss)
I0626 02:14:50.894419  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00997339 (* 1 = 0.00997339 loss)
I0626 02:14:50.894425  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00411345 (* 1 = 0.00411345 loss)
I0626 02:14:50.894431  4216 sgd_solver.cpp:106] Iteration 9840, lr = 0.0002
I0626 02:16:36.320335  4216 solver.cpp:228] Iteration 9860, loss = 0.244136
I0626 02:16:36.320360  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:16:36.320369  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464154 (* 1 = 0.0464154 loss)
I0626 02:16:36.320372  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0706852 (* 1 = 0.0706852 loss)
I0626 02:16:36.320375  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0460209 (* 1 = 0.0460209 loss)
I0626 02:16:36.320379  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0075644 (* 1 = 0.0075644 loss)
I0626 02:16:36.320384  4216 sgd_solver.cpp:106] Iteration 9860, lr = 0.0002
I0626 02:18:21.952690  4216 solver.cpp:228] Iteration 9880, loss = 0.260822
I0626 02:18:21.952718  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:18:21.952728  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0137976 (* 1 = 0.0137976 loss)
I0626 02:18:21.952733  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0521316 (* 1 = 0.0521316 loss)
I0626 02:18:21.952738  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034873 (* 1 = 0.0034873 loss)
I0626 02:18:21.952742  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00238427 (* 1 = 0.00238427 loss)
I0626 02:18:21.952747  4216 sgd_solver.cpp:106] Iteration 9880, lr = 0.0002
I0626 02:20:07.237995  4216 solver.cpp:228] Iteration 9900, loss = 0.333185
I0626 02:20:07.238021  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 02:20:07.238029  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.249393 (* 1 = 0.249393 loss)
I0626 02:20:07.238034  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.357483 (* 1 = 0.357483 loss)
I0626 02:20:07.238040  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00988944 (* 1 = 0.00988944 loss)
I0626 02:20:07.238045  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0541664 (* 1 = 0.0541664 loss)
I0626 02:20:07.238050  4216 sgd_solver.cpp:106] Iteration 9900, lr = 0.0002
I0626 02:21:52.725903  4216 solver.cpp:228] Iteration 9920, loss = 0.261926
I0626 02:21:52.725930  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:21:52.725939  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308898 (* 1 = 0.0308898 loss)
I0626 02:21:52.725944  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0708319 (* 1 = 0.0708319 loss)
I0626 02:21:52.725950  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00590647 (* 1 = 0.00590647 loss)
I0626 02:21:52.725955  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0537345 (* 1 = 0.0537345 loss)
I0626 02:21:52.725960  4216 sgd_solver.cpp:106] Iteration 9920, lr = 0.0002
I0626 02:23:38.168536  4216 solver.cpp:228] Iteration 9940, loss = 0.348357
I0626 02:23:38.168561  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 02:23:38.168570  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167717 (* 1 = 0.0167717 loss)
I0626 02:23:38.168573  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0552471 (* 1 = 0.0552471 loss)
I0626 02:23:38.168577  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0561825 (* 1 = 0.0561825 loss)
I0626 02:23:38.168581  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.133838 (* 1 = 0.133838 loss)
I0626 02:23:38.168586  4216 sgd_solver.cpp:106] Iteration 9940, lr = 0.0002
I0626 02:25:23.471302  4216 solver.cpp:228] Iteration 9960, loss = 0.424368
I0626 02:25:23.471326  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 02:25:23.471333  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0780864 (* 1 = 0.0780864 loss)
I0626 02:25:23.471338  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.169877 (* 1 = 0.169877 loss)
I0626 02:25:23.471341  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00510519 (* 1 = 0.00510519 loss)
I0626 02:25:23.471345  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00871818 (* 1 = 0.00871818 loss)
I0626 02:25:23.471350  4216 sgd_solver.cpp:106] Iteration 9960, lr = 0.0002
I0626 02:27:08.763195  4216 solver.cpp:228] Iteration 9980, loss = 0.304822
I0626 02:27:08.763221  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:27:08.763227  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197036 (* 1 = 0.0197036 loss)
I0626 02:27:08.763231  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0958986 (* 1 = 0.0958986 loss)
I0626 02:27:08.763236  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000950369 (* 1 = 0.000950369 loss)
I0626 02:27:08.763239  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00346732 (* 1 = 0.00346732 loss)
I0626 02:27:08.763243  4216 sgd_solver.cpp:106] Iteration 9980, lr = 0.0002
speed: 5.236s / iter
I0626 02:28:49.240762  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_10000.caffemodel
I0626 02:28:54.981326  4216 solver.cpp:228] Iteration 10000, loss = 0.279002
I0626 02:28:54.981353  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 02:28:54.981359  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.255336 (* 1 = 0.255336 loss)
I0626 02:28:54.981364  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.280903 (* 1 = 0.280903 loss)
I0626 02:28:54.981366  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00787936 (* 1 = 0.00787936 loss)
I0626 02:28:54.981370  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448945 (* 1 = 0.0448945 loss)
I0626 02:28:54.981375  4216 sgd_solver.cpp:106] Iteration 10000, lr = 0.0002
I0626 02:30:40.192632  4216 solver.cpp:228] Iteration 10020, loss = 0.370215
I0626 02:30:40.192657  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 02:30:40.192665  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.157623 (* 1 = 0.157623 loss)
I0626 02:30:40.192669  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.259833 (* 1 = 0.259833 loss)
I0626 02:30:40.192673  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00568514 (* 1 = 0.00568514 loss)
I0626 02:30:40.192677  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297347 (* 1 = 0.0297347 loss)
I0626 02:30:40.192683  4216 sgd_solver.cpp:106] Iteration 10020, lr = 0.0002
I0626 02:32:25.382747  4216 solver.cpp:228] Iteration 10040, loss = 0.260308
I0626 02:32:25.382772  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 02:32:25.382779  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.165838 (* 1 = 0.165838 loss)
I0626 02:32:25.382784  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.279891 (* 1 = 0.279891 loss)
I0626 02:32:25.382788  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151231 (* 1 = 0.0151231 loss)
I0626 02:32:25.382792  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108506 (* 1 = 0.108506 loss)
I0626 02:32:25.382797  4216 sgd_solver.cpp:106] Iteration 10040, lr = 0.0002
I0626 02:34:10.552641  4216 solver.cpp:228] Iteration 10060, loss = 0.23927
I0626 02:34:10.552669  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 02:34:10.552676  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627534 (* 1 = 0.0627534 loss)
I0626 02:34:10.552680  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.309366 (* 1 = 0.309366 loss)
I0626 02:34:10.552685  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179702 (* 1 = 0.0179702 loss)
I0626 02:34:10.552690  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180663 (* 1 = 0.0180663 loss)
I0626 02:34:10.552695  4216 sgd_solver.cpp:106] Iteration 10060, lr = 0.0002
I0626 02:35:55.836160  4216 solver.cpp:228] Iteration 10080, loss = 0.309557
I0626 02:35:55.836185  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 02:35:55.836192  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0213032 (* 1 = 0.0213032 loss)
I0626 02:35:55.836196  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0805019 (* 1 = 0.0805019 loss)
I0626 02:35:55.836200  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00065489 (* 1 = 0.00065489 loss)
I0626 02:35:55.836203  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00605159 (* 1 = 0.00605159 loss)
I0626 02:35:55.836210  4216 sgd_solver.cpp:106] Iteration 10080, lr = 0.0002
I0626 02:37:40.991324  4216 solver.cpp:228] Iteration 10100, loss = 0.254055
I0626 02:37:40.991351  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 02:37:40.991358  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.061243 (* 1 = 0.061243 loss)
I0626 02:37:40.991364  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.103193 (* 1 = 0.103193 loss)
I0626 02:37:40.991367  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00455344 (* 1 = 0.00455344 loss)
I0626 02:37:40.991371  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0367823 (* 1 = 0.0367823 loss)
I0626 02:37:40.991376  4216 sgd_solver.cpp:106] Iteration 10100, lr = 0.0002
I0626 02:39:26.244995  4216 solver.cpp:228] Iteration 10120, loss = 0.388008
I0626 02:39:26.245020  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 02:39:26.245029  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.101774 (* 1 = 0.101774 loss)
I0626 02:39:26.245034  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.14871 (* 1 = 0.14871 loss)
I0626 02:39:26.245040  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00925586 (* 1 = 0.00925586 loss)
I0626 02:39:26.245046  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00827482 (* 1 = 0.00827482 loss)
I0626 02:39:26.245052  4216 sgd_solver.cpp:106] Iteration 10120, lr = 0.0002
I0626 02:41:11.564013  4216 solver.cpp:228] Iteration 10140, loss = 0.120229
I0626 02:41:11.564040  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 02:41:11.564049  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.03291 (* 1 = 0.03291 loss)
I0626 02:41:11.564052  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0491898 (* 1 = 0.0491898 loss)
I0626 02:41:11.564057  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000530459 (* 1 = 0.000530459 loss)
I0626 02:41:11.564061  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129167 (* 1 = 0.0129167 loss)
I0626 02:41:11.564066  4216 sgd_solver.cpp:106] Iteration 10140, lr = 0.0002
I0626 02:42:56.773156  4216 solver.cpp:228] Iteration 10160, loss = 0.318465
I0626 02:42:56.773180  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:42:56.773187  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00177516 (* 1 = 0.00177516 loss)
I0626 02:42:56.773191  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0234627 (* 1 = 0.0234627 loss)
I0626 02:42:56.773195  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112958 (* 1 = 0.0112958 loss)
I0626 02:42:56.773198  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00766573 (* 1 = 0.00766573 loss)
I0626 02:42:56.773203  4216 sgd_solver.cpp:106] Iteration 10160, lr = 0.0002
I0626 02:44:42.118186  4216 solver.cpp:228] Iteration 10180, loss = 0.437798
I0626 02:44:42.118214  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0626 02:44:42.118223  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.423313 (* 1 = 0.423313 loss)
I0626 02:44:42.118228  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.601696 (* 1 = 0.601696 loss)
I0626 02:44:42.118233  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00599672 (* 1 = 0.00599672 loss)
I0626 02:44:42.118238  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433772 (* 1 = 0.0433772 loss)
I0626 02:44:42.118243  4216 sgd_solver.cpp:106] Iteration 10180, lr = 0.0002
speed: 5.237s / iter
I0626 02:46:27.549126  4216 solver.cpp:228] Iteration 10200, loss = 0.294269
I0626 02:46:27.549151  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:46:27.549160  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0616546 (* 1 = 0.0616546 loss)
I0626 02:46:27.549163  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0848474 (* 1 = 0.0848474 loss)
I0626 02:46:27.549167  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000213293 (* 1 = 0.000213293 loss)
I0626 02:46:27.549171  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00717334 (* 1 = 0.00717334 loss)
I0626 02:46:27.549176  4216 sgd_solver.cpp:106] Iteration 10200, lr = 0.0002
I0626 02:48:12.884928  4216 solver.cpp:228] Iteration 10220, loss = 0.219657
I0626 02:48:12.884956  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 02:48:12.884965  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314406 (* 1 = 0.0314406 loss)
I0626 02:48:12.884970  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0369421 (* 1 = 0.0369421 loss)
I0626 02:48:12.884975  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000203504 (* 1 = 0.000203504 loss)
I0626 02:48:12.884979  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00548446 (* 1 = 0.00548446 loss)
I0626 02:48:12.884985  4216 sgd_solver.cpp:106] Iteration 10220, lr = 0.0002
I0626 02:49:58.163560  4216 solver.cpp:228] Iteration 10240, loss = 0.559496
I0626 02:49:58.163599  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 02:49:58.163609  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259625 (* 1 = 0.0259625 loss)
I0626 02:49:58.163615  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.204557 (* 1 = 0.204557 loss)
I0626 02:49:58.163620  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0284808 (* 1 = 0.0284808 loss)
I0626 02:49:58.163626  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0397867 (* 1 = 0.0397867 loss)
I0626 02:49:58.163635  4216 sgd_solver.cpp:106] Iteration 10240, lr = 0.0002
I0626 02:51:43.531373  4216 solver.cpp:228] Iteration 10260, loss = 0.292402
I0626 02:51:43.531399  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 02:51:43.531406  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104033 (* 1 = 0.104033 loss)
I0626 02:51:43.531410  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.207633 (* 1 = 0.207633 loss)
I0626 02:51:43.531414  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119086 (* 1 = 0.0119086 loss)
I0626 02:51:43.531417  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230456 (* 1 = 0.0230456 loss)
I0626 02:51:43.531422  4216 sgd_solver.cpp:106] Iteration 10260, lr = 0.0002
I0626 02:53:28.853901  4216 solver.cpp:228] Iteration 10280, loss = 0.599594
I0626 02:53:28.853927  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 02:53:28.853935  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.391475 (* 1 = 0.391475 loss)
I0626 02:53:28.853940  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.43212 (* 1 = 0.43212 loss)
I0626 02:53:28.853945  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00337393 (* 1 = 0.00337393 loss)
I0626 02:53:28.853950  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0978393 (* 1 = 0.0978393 loss)
I0626 02:53:28.853955  4216 sgd_solver.cpp:106] Iteration 10280, lr = 0.0002
I0626 02:55:14.252693  4216 solver.cpp:228] Iteration 10300, loss = 0.270144
I0626 02:55:14.252717  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:55:14.252724  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391547 (* 1 = 0.0391547 loss)
I0626 02:55:14.252728  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.102227 (* 1 = 0.102227 loss)
I0626 02:55:14.252732  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023885 (* 1 = 0.0023885 loss)
I0626 02:55:14.252737  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131255 (* 1 = 0.0131255 loss)
I0626 02:55:14.252740  4216 sgd_solver.cpp:106] Iteration 10300, lr = 0.0002
I0626 02:56:59.635937  4216 solver.cpp:228] Iteration 10320, loss = 0.190233
I0626 02:56:59.635964  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 02:56:59.635972  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151844 (* 1 = 0.0151844 loss)
I0626 02:56:59.635975  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0618878 (* 1 = 0.0618878 loss)
I0626 02:56:59.635979  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113774 (* 1 = 0.0113774 loss)
I0626 02:56:59.635982  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119207 (* 1 = 0.0119207 loss)
I0626 02:56:59.635987  4216 sgd_solver.cpp:106] Iteration 10320, lr = 0.0002
I0626 02:58:45.168804  4216 solver.cpp:228] Iteration 10340, loss = 0.440318
I0626 02:58:45.168829  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:58:45.168838  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319562 (* 1 = 0.0319562 loss)
I0626 02:58:45.168841  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0353423 (* 1 = 0.0353423 loss)
I0626 02:58:45.168845  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000729706 (* 1 = 0.000729706 loss)
I0626 02:58:45.168849  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101738 (* 1 = 0.0101738 loss)
I0626 02:58:45.168854  4216 sgd_solver.cpp:106] Iteration 10340, lr = 0.0002
I0626 03:00:30.660760  4216 solver.cpp:228] Iteration 10360, loss = 0.378162
I0626 03:00:30.660794  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:00:30.660804  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151564 (* 1 = 0.0151564 loss)
I0626 03:00:30.660810  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0468301 (* 1 = 0.0468301 loss)
I0626 03:00:30.660815  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300313 (* 1 = 0.00300313 loss)
I0626 03:00:30.660820  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00491548 (* 1 = 0.00491548 loss)
I0626 03:00:30.660827  4216 sgd_solver.cpp:106] Iteration 10360, lr = 0.0002
I0626 03:02:16.292500  4216 solver.cpp:228] Iteration 10380, loss = 0.375514
I0626 03:02:16.292529  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 03:02:16.292537  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225521 (* 1 = 0.0225521 loss)
I0626 03:02:16.292543  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0485734 (* 1 = 0.0485734 loss)
I0626 03:02:16.292548  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000342781 (* 1 = 0.000342781 loss)
I0626 03:02:16.292553  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00374699 (* 1 = 0.00374699 loss)
I0626 03:02:16.292558  4216 sgd_solver.cpp:106] Iteration 10380, lr = 0.0002
speed: 5.237s / iter
I0626 03:04:01.731468  4216 solver.cpp:228] Iteration 10400, loss = 0.291248
I0626 03:04:01.731492  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 03:04:01.731500  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150374 (* 1 = 0.0150374 loss)
I0626 03:04:01.731504  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0319049 (* 1 = 0.0319049 loss)
I0626 03:04:01.731508  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00087509 (* 1 = 0.00087509 loss)
I0626 03:04:01.731511  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00818787 (* 1 = 0.00818787 loss)
I0626 03:04:01.731516  4216 sgd_solver.cpp:106] Iteration 10400, lr = 0.0002
I0626 03:05:47.516561  4216 solver.cpp:228] Iteration 10420, loss = 0.292248
I0626 03:05:47.516584  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:05:47.516592  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00248993 (* 1 = 0.00248993 loss)
I0626 03:05:47.516597  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0309761 (* 1 = 0.0309761 loss)
I0626 03:05:47.516600  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000843181 (* 1 = 0.000843181 loss)
I0626 03:05:47.516603  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000158305 (* 1 = 0.000158305 loss)
I0626 03:05:47.516607  4216 sgd_solver.cpp:106] Iteration 10420, lr = 0.0002
I0626 03:07:32.892040  4216 solver.cpp:228] Iteration 10440, loss = 0.20542
I0626 03:07:32.892067  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 03:07:32.892077  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816143 (* 1 = 0.0816143 loss)
I0626 03:07:32.892086  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.17792 (* 1 = 0.17792 loss)
I0626 03:07:32.892091  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010833 (* 1 = 0.010833 loss)
I0626 03:07:32.892097  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0778941 (* 1 = 0.0778941 loss)
I0626 03:07:32.892104  4216 sgd_solver.cpp:106] Iteration 10440, lr = 0.0002
I0626 03:09:18.302429  4216 solver.cpp:228] Iteration 10460, loss = 0.321199
I0626 03:09:18.302459  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 03:09:18.302471  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000595347 (* 1 = 0.000595347 loss)
I0626 03:09:18.302479  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0406 (* 1 = 0.0406 loss)
I0626 03:09:18.302487  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772356 (* 1 = 0.00772356 loss)
I0626 03:09:18.302495  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210679 (* 1 = 0.0210679 loss)
I0626 03:09:18.302502  4216 sgd_solver.cpp:106] Iteration 10460, lr = 0.0002
I0626 03:11:03.873023  4216 solver.cpp:228] Iteration 10480, loss = 0.352952
I0626 03:11:03.873049  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 03:11:03.873055  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682005 (* 1 = 0.0682005 loss)
I0626 03:11:03.873060  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.126427 (* 1 = 0.126427 loss)
I0626 03:11:03.873064  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000890878 (* 1 = 0.000890878 loss)
I0626 03:11:03.873069  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00933626 (* 1 = 0.00933626 loss)
I0626 03:11:03.873073  4216 sgd_solver.cpp:106] Iteration 10480, lr = 0.0002
I0626 03:12:49.148826  4216 solver.cpp:228] Iteration 10500, loss = 0.407698
I0626 03:12:49.148852  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 03:12:49.148859  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.275825 (* 1 = 0.275825 loss)
I0626 03:12:49.148864  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.38414 (* 1 = 0.38414 loss)
I0626 03:12:49.148867  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00709053 (* 1 = 0.00709053 loss)
I0626 03:12:49.148871  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0435261 (* 1 = 0.0435261 loss)
I0626 03:12:49.148876  4216 sgd_solver.cpp:106] Iteration 10500, lr = 0.0002
I0626 03:14:34.644783  4216 solver.cpp:228] Iteration 10520, loss = 0.208839
I0626 03:14:34.644809  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 03:14:34.644816  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.111265 (* 1 = 0.111265 loss)
I0626 03:14:34.644821  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.179251 (* 1 = 0.179251 loss)
I0626 03:14:34.644825  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116792 (* 1 = 0.00116792 loss)
I0626 03:14:34.644830  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121299 (* 1 = 0.0121299 loss)
I0626 03:14:34.644836  4216 sgd_solver.cpp:106] Iteration 10520, lr = 0.0002
I0626 03:16:19.918088  4216 solver.cpp:228] Iteration 10540, loss = 0.213419
I0626 03:16:19.918118  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 03:16:19.918125  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.108884 (* 1 = 0.108884 loss)
I0626 03:16:19.918129  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.246564 (* 1 = 0.246564 loss)
I0626 03:16:19.918133  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00430565 (* 1 = 0.00430565 loss)
I0626 03:16:19.918136  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207524 (* 1 = 0.0207524 loss)
I0626 03:16:19.918143  4216 sgd_solver.cpp:106] Iteration 10540, lr = 0.0002
I0626 03:18:05.282862  4216 solver.cpp:228] Iteration 10560, loss = 0.304557
I0626 03:18:05.282892  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 03:18:05.282902  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.171689 (* 1 = 0.171689 loss)
I0626 03:18:05.282905  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.271622 (* 1 = 0.271622 loss)
I0626 03:18:05.282908  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000775332 (* 1 = 0.000775332 loss)
I0626 03:18:05.282912  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259095 (* 1 = 0.0259095 loss)
I0626 03:18:05.282917  4216 sgd_solver.cpp:106] Iteration 10560, lr = 0.0002
I0626 03:19:50.745223  4216 solver.cpp:228] Iteration 10580, loss = 0.450909
I0626 03:19:50.745251  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0626 03:19:50.745260  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.231019 (* 1 = 0.231019 loss)
I0626 03:19:50.745265  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.373444 (* 1 = 0.373444 loss)
I0626 03:19:50.745270  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00251623 (* 1 = 0.00251623 loss)
I0626 03:19:50.745275  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379644 (* 1 = 0.0379644 loss)
I0626 03:19:50.745280  4216 sgd_solver.cpp:106] Iteration 10580, lr = 0.0002
speed: 5.238s / iter
I0626 03:21:35.976585  4216 solver.cpp:228] Iteration 10600, loss = 0.2452
I0626 03:21:35.976610  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:21:35.976617  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0022931 (* 1 = 0.0022931 loss)
I0626 03:21:35.976621  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0304835 (* 1 = 0.0304835 loss)
I0626 03:21:35.976625  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00268132 (* 1 = 0.00268132 loss)
I0626 03:21:35.976629  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0426169 (* 1 = 0.0426169 loss)
I0626 03:21:35.976634  4216 sgd_solver.cpp:106] Iteration 10600, lr = 0.0002
I0626 03:23:21.162376  4216 solver.cpp:228] Iteration 10620, loss = 0.132865
I0626 03:23:21.162402  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 03:23:21.162410  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169175 (* 1 = 0.0169175 loss)
I0626 03:23:21.162413  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0378835 (* 1 = 0.0378835 loss)
I0626 03:23:21.162417  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00366113 (* 1 = 0.00366113 loss)
I0626 03:23:21.162421  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00655384 (* 1 = 0.00655384 loss)
I0626 03:23:21.162425  4216 sgd_solver.cpp:106] Iteration 10620, lr = 0.0002
I0626 03:25:06.444811  4216 solver.cpp:228] Iteration 10640, loss = 0.364587
I0626 03:25:06.444835  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 03:25:06.444842  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737932 (* 1 = 0.0737932 loss)
I0626 03:25:06.444846  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.227713 (* 1 = 0.227713 loss)
I0626 03:25:06.444850  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241114 (* 1 = 0.00241114 loss)
I0626 03:25:06.444854  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117115 (* 1 = 0.0117115 loss)
I0626 03:25:06.444859  4216 sgd_solver.cpp:106] Iteration 10640, lr = 0.0002
I0626 03:26:51.653211  4216 solver.cpp:228] Iteration 10660, loss = 0.220854
I0626 03:26:51.653237  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 03:26:51.653246  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.040566 (* 1 = 0.040566 loss)
I0626 03:26:51.653250  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0871 (* 1 = 0.0871 loss)
I0626 03:26:51.653254  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000361566 (* 1 = 0.000361566 loss)
I0626 03:26:51.653259  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146824 (* 1 = 0.0146824 loss)
I0626 03:26:51.653264  4216 sgd_solver.cpp:106] Iteration 10660, lr = 0.0002
I0626 03:28:36.937985  4216 solver.cpp:228] Iteration 10680, loss = 0.291164
I0626 03:28:36.938014  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 03:28:36.938021  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199911 (* 1 = 0.0199911 loss)
I0626 03:28:36.938025  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0554345 (* 1 = 0.0554345 loss)
I0626 03:28:36.938030  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133769 (* 1 = 0.00133769 loss)
I0626 03:28:36.938033  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00297799 (* 1 = 0.00297799 loss)
I0626 03:28:36.938038  4216 sgd_solver.cpp:106] Iteration 10680, lr = 0.0002
I0626 03:30:22.128799  4216 solver.cpp:228] Iteration 10700, loss = 0.225912
I0626 03:30:22.128823  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 03:30:22.128830  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000546737 (* 1 = 0.000546737 loss)
I0626 03:30:22.128834  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.022084 (* 1 = 0.022084 loss)
I0626 03:30:22.128839  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445316 (* 1 = 0.00445316 loss)
I0626 03:30:22.128841  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102991 (* 1 = 0.0102991 loss)
I0626 03:30:22.128846  4216 sgd_solver.cpp:106] Iteration 10700, lr = 0.0002
I0626 03:32:07.409651  4216 solver.cpp:228] Iteration 10720, loss = 0.286898
I0626 03:32:07.409677  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:32:07.409684  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154103 (* 1 = 0.0154103 loss)
I0626 03:32:07.409688  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0370807 (* 1 = 0.0370807 loss)
I0626 03:32:07.409693  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248002 (* 1 = 0.00248002 loss)
I0626 03:32:07.409696  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00643938 (* 1 = 0.00643938 loss)
I0626 03:32:07.409701  4216 sgd_solver.cpp:106] Iteration 10720, lr = 0.0002
I0626 03:33:52.614784  4216 solver.cpp:228] Iteration 10740, loss = 0.303991
I0626 03:33:52.614809  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 03:33:52.614816  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121529 (* 1 = 0.121529 loss)
I0626 03:33:52.614820  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.115246 (* 1 = 0.115246 loss)
I0626 03:33:52.614823  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00262056 (* 1 = 0.00262056 loss)
I0626 03:33:52.614827  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113718 (* 1 = 0.0113718 loss)
I0626 03:33:52.614831  4216 sgd_solver.cpp:106] Iteration 10740, lr = 0.0002
I0626 03:35:37.792259  4216 solver.cpp:228] Iteration 10760, loss = 0.469434
I0626 03:35:37.792284  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 03:35:37.792290  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.131014 (* 1 = 0.131014 loss)
I0626 03:35:37.792294  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.249307 (* 1 = 0.249307 loss)
I0626 03:35:37.792299  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136306 (* 1 = 0.00136306 loss)
I0626 03:35:37.792302  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216383 (* 1 = 0.0216383 loss)
I0626 03:35:37.792306  4216 sgd_solver.cpp:106] Iteration 10760, lr = 0.0002
I0626 03:37:22.968780  4216 solver.cpp:228] Iteration 10780, loss = 0.340597
I0626 03:37:22.968806  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 03:37:22.968814  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390223 (* 1 = 0.0390223 loss)
I0626 03:37:22.968821  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0890169 (* 1 = 0.0890169 loss)
I0626 03:37:22.968827  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00404329 (* 1 = 0.00404329 loss)
I0626 03:37:22.968832  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00914745 (* 1 = 0.00914745 loss)
I0626 03:37:22.968837  4216 sgd_solver.cpp:106] Iteration 10780, lr = 0.0002
speed: 5.239s / iter
I0626 03:39:08.180574  4216 solver.cpp:228] Iteration 10800, loss = 0.295716
I0626 03:39:08.180603  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 03:39:08.180614  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542012 (* 1 = 0.0542012 loss)
I0626 03:39:08.180621  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.158716 (* 1 = 0.158716 loss)
I0626 03:39:08.180629  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191521 (* 1 = 0.00191521 loss)
I0626 03:39:08.180636  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238474 (* 1 = 0.0238474 loss)
I0626 03:39:08.180645  4216 sgd_solver.cpp:106] Iteration 10800, lr = 0.0002
I0626 03:40:53.531216  4216 solver.cpp:228] Iteration 10820, loss = 0.20894
I0626 03:40:53.531241  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 03:40:53.531250  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0242813 (* 1 = 0.0242813 loss)
I0626 03:40:53.531256  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.047651 (* 1 = 0.047651 loss)
I0626 03:40:53.531261  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00525429 (* 1 = 0.00525429 loss)
I0626 03:40:53.531267  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00632503 (* 1 = 0.00632503 loss)
I0626 03:40:53.531273  4216 sgd_solver.cpp:106] Iteration 10820, lr = 0.0002
I0626 03:42:39.052341  4216 solver.cpp:228] Iteration 10840, loss = 0.193499
I0626 03:42:39.052373  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 03:42:39.052383  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521006 (* 1 = 0.0521006 loss)
I0626 03:42:39.052390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.138709 (* 1 = 0.138709 loss)
I0626 03:42:39.052397  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0079 (* 1 = 0.0079 loss)
I0626 03:42:39.052402  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121043 (* 1 = 0.0121043 loss)
I0626 03:42:39.052408  4216 sgd_solver.cpp:106] Iteration 10840, lr = 0.0002
I0626 03:44:24.727835  4216 solver.cpp:228] Iteration 10860, loss = 0.19531
I0626 03:44:24.727861  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0626 03:44:24.727869  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.174346 (* 1 = 0.174346 loss)
I0626 03:44:24.727874  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.444991 (* 1 = 0.444991 loss)
I0626 03:44:24.727877  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02084 (* 1 = 0.02084 loss)
I0626 03:44:24.727881  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.188909 (* 1 = 0.188909 loss)
I0626 03:44:24.727886  4216 sgd_solver.cpp:106] Iteration 10860, lr = 0.0002
I0626 03:46:10.189079  4216 solver.cpp:228] Iteration 10880, loss = 0.184432
I0626 03:46:10.189105  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 03:46:10.189111  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.159701 (* 1 = 0.159701 loss)
I0626 03:46:10.189116  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.293666 (* 1 = 0.293666 loss)
I0626 03:46:10.189119  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213958 (* 1 = 0.0213958 loss)
I0626 03:46:10.189123  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0937872 (* 1 = 0.0937872 loss)
I0626 03:46:10.189128  4216 sgd_solver.cpp:106] Iteration 10880, lr = 0.0002
I0626 03:47:55.703738  4216 solver.cpp:228] Iteration 10900, loss = 0.28485
I0626 03:47:55.703765  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 03:47:55.703775  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737421 (* 1 = 0.0737421 loss)
I0626 03:47:55.703783  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.172769 (* 1 = 0.172769 loss)
I0626 03:47:55.703788  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206587 (* 1 = 0.00206587 loss)
I0626 03:47:55.703794  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129746 (* 1 = 0.0129746 loss)
I0626 03:47:55.703804  4216 sgd_solver.cpp:106] Iteration 10900, lr = 0.0002
I0626 03:49:41.294592  4216 solver.cpp:228] Iteration 10920, loss = 0.157959
I0626 03:49:41.294620  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:49:41.294627  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297694 (* 1 = 0.0297694 loss)
I0626 03:49:41.294634  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0645613 (* 1 = 0.0645613 loss)
I0626 03:49:41.294639  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000177297 (* 1 = 0.000177297 loss)
I0626 03:49:41.294646  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113459 (* 1 = 0.0113459 loss)
I0626 03:49:41.294651  4216 sgd_solver.cpp:106] Iteration 10920, lr = 0.0002
I0626 03:51:26.662536  4216 solver.cpp:228] Iteration 10940, loss = 0.251638
I0626 03:51:26.662562  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 03:51:26.662571  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0920716 (* 1 = 0.0920716 loss)
I0626 03:51:26.662577  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.152346 (* 1 = 0.152346 loss)
I0626 03:51:26.662583  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0233959 (* 1 = 0.0233959 loss)
I0626 03:51:26.662590  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451565 (* 1 = 0.0451565 loss)
I0626 03:51:26.662595  4216 sgd_solver.cpp:106] Iteration 10940, lr = 0.0002
I0626 03:53:12.097671  4216 solver.cpp:228] Iteration 10960, loss = 0.238466
I0626 03:53:12.097698  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 03:53:12.097705  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0357143 (* 1 = 0.0357143 loss)
I0626 03:53:12.097709  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.05205 (* 1 = 0.05205 loss)
I0626 03:53:12.097713  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000811243 (* 1 = 0.000811243 loss)
I0626 03:53:12.097718  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00527469 (* 1 = 0.00527469 loss)
I0626 03:53:12.097721  4216 sgd_solver.cpp:106] Iteration 10960, lr = 0.0002
I0626 03:54:57.365180  4216 solver.cpp:228] Iteration 10980, loss = 0.260149
I0626 03:54:57.365206  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0626 03:54:57.365216  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.303404 (* 1 = 0.303404 loss)
I0626 03:54:57.365221  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.478908 (* 1 = 0.478908 loss)
I0626 03:54:57.365226  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124325 (* 1 = 0.0124325 loss)
I0626 03:54:57.365231  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0493777 (* 1 = 0.0493777 loss)
I0626 03:54:57.365236  4216 sgd_solver.cpp:106] Iteration 10980, lr = 0.0002
speed: 5.239s / iter
I0626 03:56:42.779753  4216 solver.cpp:228] Iteration 11000, loss = 0.254174
I0626 03:56:42.779779  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 03:56:42.779788  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0727256 (* 1 = 0.0727256 loss)
I0626 03:56:42.779794  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.188563 (* 1 = 0.188563 loss)
I0626 03:56:42.779800  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138701 (* 1 = 0.0138701 loss)
I0626 03:56:42.779806  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267775 (* 1 = 0.0267775 loss)
I0626 03:56:42.779812  4216 sgd_solver.cpp:106] Iteration 11000, lr = 0.0002
I0626 03:58:28.372413  4216 solver.cpp:228] Iteration 11020, loss = 0.341197
I0626 03:58:28.372439  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 03:58:28.372447  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.16799 (* 1 = 0.16799 loss)
I0626 03:58:28.372450  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.163961 (* 1 = 0.163961 loss)
I0626 03:58:28.372455  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00741663 (* 1 = 0.00741663 loss)
I0626 03:58:28.372459  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300016 (* 1 = 0.0300016 loss)
I0626 03:58:28.372464  4216 sgd_solver.cpp:106] Iteration 11020, lr = 0.0002
I0626 04:00:13.923869  4216 solver.cpp:228] Iteration 11040, loss = 0.232739
I0626 04:00:13.923894  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:00:13.923902  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0252595 (* 1 = 0.0252595 loss)
I0626 04:00:13.923907  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0382049 (* 1 = 0.0382049 loss)
I0626 04:00:13.923910  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197544 (* 1 = 0.0197544 loss)
I0626 04:00:13.923914  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00291338 (* 1 = 0.00291338 loss)
I0626 04:00:13.923919  4216 sgd_solver.cpp:106] Iteration 11040, lr = 0.0002
I0626 04:01:59.194908  4216 solver.cpp:228] Iteration 11060, loss = 0.14516
I0626 04:01:59.194933  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:01:59.194941  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156374 (* 1 = 0.0156374 loss)
I0626 04:01:59.194945  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0427428 (* 1 = 0.0427428 loss)
I0626 04:01:59.194948  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00488209 (* 1 = 0.00488209 loss)
I0626 04:01:59.194952  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00528832 (* 1 = 0.00528832 loss)
I0626 04:01:59.194957  4216 sgd_solver.cpp:106] Iteration 11060, lr = 0.0002
I0626 04:03:44.469612  4216 solver.cpp:228] Iteration 11080, loss = 0.282869
I0626 04:03:44.469640  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:03:44.469647  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.044406 (* 1 = 0.044406 loss)
I0626 04:03:44.469651  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0658292 (* 1 = 0.0658292 loss)
I0626 04:03:44.469655  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000351712 (* 1 = 0.000351712 loss)
I0626 04:03:44.469660  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00562921 (* 1 = 0.00562921 loss)
I0626 04:03:44.469664  4216 sgd_solver.cpp:106] Iteration 11080, lr = 0.0002
I0626 04:05:29.658393  4216 solver.cpp:228] Iteration 11100, loss = 0.225656
I0626 04:05:29.658418  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 04:05:29.658426  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.234892 (* 1 = 0.234892 loss)
I0626 04:05:29.658429  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.403988 (* 1 = 0.403988 loss)
I0626 04:05:29.658433  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00652889 (* 1 = 0.00652889 loss)
I0626 04:05:29.658437  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199966 (* 1 = 0.0199966 loss)
I0626 04:05:29.658442  4216 sgd_solver.cpp:106] Iteration 11100, lr = 0.0002
I0626 04:07:14.825904  4216 solver.cpp:228] Iteration 11120, loss = 0.2924
I0626 04:07:14.825929  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 04:07:14.825937  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.126166 (* 1 = 0.126166 loss)
I0626 04:07:14.825939  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.310042 (* 1 = 0.310042 loss)
I0626 04:07:14.825943  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215912 (* 1 = 0.00215912 loss)
I0626 04:07:14.825947  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0633425 (* 1 = 0.0633425 loss)
I0626 04:07:14.825953  4216 sgd_solver.cpp:106] Iteration 11120, lr = 0.0002
I0626 04:09:00.191134  4216 solver.cpp:228] Iteration 11140, loss = 0.250968
I0626 04:09:00.191165  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 04:09:00.191174  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.085608 (* 1 = 0.085608 loss)
I0626 04:09:00.191179  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.1764 (* 1 = 0.1764 loss)
I0626 04:09:00.191182  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00401449 (* 1 = 0.00401449 loss)
I0626 04:09:00.191186  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353744 (* 1 = 0.0353744 loss)
I0626 04:09:00.191192  4216 sgd_solver.cpp:106] Iteration 11140, lr = 0.0002
I0626 04:10:45.488745  4216 solver.cpp:228] Iteration 11160, loss = 0.211649
I0626 04:10:45.488771  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 04:10:45.488778  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319404 (* 1 = 0.0319404 loss)
I0626 04:10:45.488783  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0620065 (* 1 = 0.0620065 loss)
I0626 04:10:45.488786  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102837 (* 1 = 0.0102837 loss)
I0626 04:10:45.488790  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0023364 (* 1 = 0.0023364 loss)
I0626 04:10:45.488795  4216 sgd_solver.cpp:106] Iteration 11160, lr = 0.0002
I0626 04:12:30.773211  4216 solver.cpp:228] Iteration 11180, loss = 0.382729
I0626 04:12:30.773237  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 04:12:30.773244  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.12871 (* 1 = 0.12871 loss)
I0626 04:12:30.773247  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.335592 (* 1 = 0.335592 loss)
I0626 04:12:30.773252  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00466957 (* 1 = 0.00466957 loss)
I0626 04:12:30.773255  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0745587 (* 1 = 0.0745587 loss)
I0626 04:12:30.773260  4216 sgd_solver.cpp:106] Iteration 11180, lr = 0.0002
speed: 5.240s / iter
I0626 04:14:15.932379  4216 solver.cpp:228] Iteration 11200, loss = 0.373698
I0626 04:14:15.932401  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 04:14:15.932410  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120433 (* 1 = 0.120433 loss)
I0626 04:14:15.932413  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.212677 (* 1 = 0.212677 loss)
I0626 04:14:15.932416  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542473 (* 1 = 0.00542473 loss)
I0626 04:14:15.932420  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203508 (* 1 = 0.0203508 loss)
I0626 04:14:15.932425  4216 sgd_solver.cpp:106] Iteration 11200, lr = 0.0002
I0626 04:16:01.162304  4216 solver.cpp:228] Iteration 11220, loss = 0.266715
I0626 04:16:01.162328  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 04:16:01.162335  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.171883 (* 1 = 0.171883 loss)
I0626 04:16:01.162339  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.248732 (* 1 = 0.248732 loss)
I0626 04:16:01.162343  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013613 (* 1 = 0.0013613 loss)
I0626 04:16:01.162348  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318447 (* 1 = 0.0318447 loss)
I0626 04:16:01.162353  4216 sgd_solver.cpp:106] Iteration 11220, lr = 0.0002
I0626 04:17:46.407028  4216 solver.cpp:228] Iteration 11240, loss = 0.336664
I0626 04:17:46.407054  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 04:17:46.407063  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.168521 (* 1 = 0.168521 loss)
I0626 04:17:46.407066  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.335561 (* 1 = 0.335561 loss)
I0626 04:17:46.407070  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0309315 (* 1 = 0.0309315 loss)
I0626 04:17:46.407074  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0964192 (* 1 = 0.0964192 loss)
I0626 04:17:46.407080  4216 sgd_solver.cpp:106] Iteration 11240, lr = 0.0002
I0626 04:19:31.764447  4216 solver.cpp:228] Iteration 11260, loss = 0.328173
I0626 04:19:31.764472  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 04:19:31.764479  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.10653 (* 1 = 0.10653 loss)
I0626 04:19:31.764483  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.176564 (* 1 = 0.176564 loss)
I0626 04:19:31.764487  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0083089 (* 1 = 0.0083089 loss)
I0626 04:19:31.764492  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188994 (* 1 = 0.0188994 loss)
I0626 04:19:31.764495  4216 sgd_solver.cpp:106] Iteration 11260, lr = 0.0002
I0626 04:21:17.069036  4216 solver.cpp:228] Iteration 11280, loss = 0.163785
I0626 04:21:17.069062  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:21:17.069070  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316023 (* 1 = 0.0316023 loss)
I0626 04:21:17.069074  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0524028 (* 1 = 0.0524028 loss)
I0626 04:21:17.069078  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000972992 (* 1 = 0.000972992 loss)
I0626 04:21:17.069083  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0056461 (* 1 = 0.0056461 loss)
I0626 04:21:17.069088  4216 sgd_solver.cpp:106] Iteration 11280, lr = 0.0002
I0626 04:23:02.345301  4216 solver.cpp:228] Iteration 11300, loss = 0.224152
I0626 04:23:02.345327  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 04:23:02.345336  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460255 (* 1 = 0.0460255 loss)
I0626 04:23:02.345340  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0840465 (* 1 = 0.0840465 loss)
I0626 04:23:02.345345  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880257 (* 1 = 0.00880257 loss)
I0626 04:23:02.345348  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0074356 (* 1 = 0.0074356 loss)
I0626 04:23:02.345353  4216 sgd_solver.cpp:106] Iteration 11300, lr = 0.0002
I0626 04:24:47.590471  4216 solver.cpp:228] Iteration 11320, loss = 0.230221
I0626 04:24:47.590498  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:24:47.590507  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.037512 (* 1 = 0.037512 loss)
I0626 04:24:47.590512  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0746182 (* 1 = 0.0746182 loss)
I0626 04:24:47.590515  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00428956 (* 1 = 0.00428956 loss)
I0626 04:24:47.590519  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208915 (* 1 = 0.0208915 loss)
I0626 04:24:47.590525  4216 sgd_solver.cpp:106] Iteration 11320, lr = 0.0002
I0626 04:26:32.809262  4216 solver.cpp:228] Iteration 11340, loss = 0.162145
I0626 04:26:32.809289  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:26:32.809298  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0663637 (* 1 = 0.0663637 loss)
I0626 04:26:32.809303  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0612933 (* 1 = 0.0612933 loss)
I0626 04:26:32.809306  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232854 (* 1 = 0.00232854 loss)
I0626 04:26:32.809310  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00580505 (* 1 = 0.00580505 loss)
I0626 04:26:32.809315  4216 sgd_solver.cpp:106] Iteration 11340, lr = 0.0002
I0626 04:28:18.150758  4216 solver.cpp:228] Iteration 11360, loss = 0.267967
I0626 04:28:18.150784  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 04:28:18.150790  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.124565 (* 1 = 0.124565 loss)
I0626 04:28:18.150794  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.202332 (* 1 = 0.202332 loss)
I0626 04:28:18.150797  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.183467 (* 1 = 0.183467 loss)
I0626 04:28:18.150801  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0621064 (* 1 = 0.0621064 loss)
I0626 04:28:18.150805  4216 sgd_solver.cpp:106] Iteration 11360, lr = 0.0002
I0626 04:30:03.520120  4216 solver.cpp:228] Iteration 11380, loss = 0.200227
I0626 04:30:03.520153  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 04:30:03.520161  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827432 (* 1 = 0.0827432 loss)
I0626 04:30:03.520165  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.160045 (* 1 = 0.160045 loss)
I0626 04:30:03.520169  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015438 (* 1 = 0.0015438 loss)
I0626 04:30:03.520172  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278467 (* 1 = 0.0278467 loss)
I0626 04:30:03.520177  4216 sgd_solver.cpp:106] Iteration 11380, lr = 0.0002
speed: 5.240s / iter
I0626 04:31:48.972249  4216 solver.cpp:228] Iteration 11400, loss = 0.20264
I0626 04:31:48.972285  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:31:48.972295  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00725342 (* 1 = 0.00725342 loss)
I0626 04:31:48.972302  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0341587 (* 1 = 0.0341587 loss)
I0626 04:31:48.972308  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000693926 (* 1 = 0.000693926 loss)
I0626 04:31:48.972314  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00902993 (* 1 = 0.00902993 loss)
I0626 04:31:48.972321  4216 sgd_solver.cpp:106] Iteration 11400, lr = 0.0002
I0626 04:33:34.681092  4216 solver.cpp:228] Iteration 11420, loss = 0.286507
I0626 04:33:34.681118  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:33:34.681126  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.056326 (* 1 = 0.056326 loss)
I0626 04:33:34.681131  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0857736 (* 1 = 0.0857736 loss)
I0626 04:33:34.681135  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00287514 (* 1 = 0.00287514 loss)
I0626 04:33:34.681140  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216841 (* 1 = 0.0216841 loss)
I0626 04:33:34.681144  4216 sgd_solver.cpp:106] Iteration 11420, lr = 0.0002
I0626 04:35:20.129707  4216 solver.cpp:228] Iteration 11440, loss = 0.206813
I0626 04:35:20.129736  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 04:35:20.129743  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.098816 (* 1 = 0.098816 loss)
I0626 04:35:20.129748  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.304267 (* 1 = 0.304267 loss)
I0626 04:35:20.129751  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0077104 (* 1 = 0.0077104 loss)
I0626 04:35:20.129755  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364017 (* 1 = 0.0364017 loss)
I0626 04:35:20.129760  4216 sgd_solver.cpp:106] Iteration 11440, lr = 0.0002
I0626 04:37:06.191817  4216 solver.cpp:228] Iteration 11460, loss = 0.247882
I0626 04:37:06.191846  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 04:37:06.191855  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0283433 (* 1 = 0.0283433 loss)
I0626 04:37:06.191861  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0929147 (* 1 = 0.0929147 loss)
I0626 04:37:06.191865  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00752599 (* 1 = 0.00752599 loss)
I0626 04:37:06.191870  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00377746 (* 1 = 0.00377746 loss)
I0626 04:37:06.191876  4216 sgd_solver.cpp:106] Iteration 11460, lr = 0.0002
I0626 04:38:51.552881  4216 solver.cpp:228] Iteration 11480, loss = 0.298069
I0626 04:38:51.552912  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:38:51.552922  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323566 (* 1 = 0.0323566 loss)
I0626 04:38:51.552928  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0514108 (* 1 = 0.0514108 loss)
I0626 04:38:51.552933  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214303 (* 1 = 0.0214303 loss)
I0626 04:38:51.552938  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029588 (* 1 = 0.029588 loss)
I0626 04:38:51.552944  4216 sgd_solver.cpp:106] Iteration 11480, lr = 0.0002
I0626 04:40:37.060626  4216 solver.cpp:228] Iteration 11500, loss = 0.295354
I0626 04:40:37.060653  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:40:37.060660  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.020138 (* 1 = 0.020138 loss)
I0626 04:40:37.060667  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0624514 (* 1 = 0.0624514 loss)
I0626 04:40:37.060673  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116064 (* 1 = 0.0116064 loss)
I0626 04:40:37.060679  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105142 (* 1 = 0.0105142 loss)
I0626 04:40:37.060684  4216 sgd_solver.cpp:106] Iteration 11500, lr = 0.0002
I0626 04:42:22.363786  4216 solver.cpp:228] Iteration 11520, loss = 0.271014
I0626 04:42:22.363811  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 04:42:22.363818  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682122 (* 1 = 0.0682122 loss)
I0626 04:42:22.363822  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.187811 (* 1 = 0.187811 loss)
I0626 04:42:22.363826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00042878 (* 1 = 0.00042878 loss)
I0626 04:42:22.363831  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285932 (* 1 = 0.0285932 loss)
I0626 04:42:22.363834  4216 sgd_solver.cpp:106] Iteration 11520, lr = 0.0002
I0626 04:44:07.909726  4216 solver.cpp:228] Iteration 11540, loss = 0.284893
I0626 04:44:07.909750  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 04:44:07.909757  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.118475 (* 1 = 0.118475 loss)
I0626 04:44:07.909762  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.154575 (* 1 = 0.154575 loss)
I0626 04:44:07.909765  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00793912 (* 1 = 0.00793912 loss)
I0626 04:44:07.909770  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0256202 (* 1 = 0.0256202 loss)
I0626 04:44:07.909773  4216 sgd_solver.cpp:106] Iteration 11540, lr = 0.0002
I0626 04:45:53.371841  4216 solver.cpp:228] Iteration 11560, loss = 0.29605
I0626 04:45:53.371866  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 04:45:53.371873  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121343 (* 1 = 0.121343 loss)
I0626 04:45:53.371877  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.309458 (* 1 = 0.309458 loss)
I0626 04:45:53.371881  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00393553 (* 1 = 0.00393553 loss)
I0626 04:45:53.371884  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0253958 (* 1 = 0.0253958 loss)
I0626 04:45:53.371889  4216 sgd_solver.cpp:106] Iteration 11560, lr = 0.0002
I0626 04:47:38.672441  4216 solver.cpp:228] Iteration 11580, loss = 0.128625
I0626 04:47:38.672466  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 04:47:38.672473  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.106853 (* 1 = 0.106853 loss)
I0626 04:47:38.672477  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.181707 (* 1 = 0.181707 loss)
I0626 04:47:38.672482  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00407148 (* 1 = 0.00407148 loss)
I0626 04:47:38.672485  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156143 (* 1 = 0.0156143 loss)
I0626 04:47:38.672492  4216 sgd_solver.cpp:106] Iteration 11580, lr = 0.0002
speed: 5.241s / iter
I0626 04:49:24.071561  4216 solver.cpp:228] Iteration 11600, loss = 0.179973
I0626 04:49:24.071586  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:49:24.071595  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0361819 (* 1 = 0.0361819 loss)
I0626 04:49:24.071601  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0772778 (* 1 = 0.0772778 loss)
I0626 04:49:24.071607  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.007856 (* 1 = 0.007856 loss)
I0626 04:49:24.071614  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219342 (* 1 = 0.0219342 loss)
I0626 04:49:24.071620  4216 sgd_solver.cpp:106] Iteration 11600, lr = 0.0002
I0626 04:51:09.525914  4216 solver.cpp:228] Iteration 11620, loss = 0.324063
I0626 04:51:09.525941  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 04:51:09.525950  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0401869 (* 1 = 0.0401869 loss)
I0626 04:51:09.525954  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.135712 (* 1 = 0.135712 loss)
I0626 04:51:09.525959  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445703 (* 1 = 0.00445703 loss)
I0626 04:51:09.525962  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114534 (* 1 = 0.0114534 loss)
I0626 04:51:09.525967  4216 sgd_solver.cpp:106] Iteration 11620, lr = 0.0002
I0626 04:52:54.790531  4216 solver.cpp:228] Iteration 11640, loss = 0.295368
I0626 04:52:54.790558  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:52:54.790568  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0246667 (* 1 = 0.0246667 loss)
I0626 04:52:54.790575  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0803525 (* 1 = 0.0803525 loss)
I0626 04:52:54.790580  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00432261 (* 1 = 0.00432261 loss)
I0626 04:52:54.790585  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00337562 (* 1 = 0.00337562 loss)
I0626 04:52:54.790592  4216 sgd_solver.cpp:106] Iteration 11640, lr = 0.0002
I0626 04:54:39.928958  4216 solver.cpp:228] Iteration 11660, loss = 0.22945
I0626 04:54:39.928983  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 04:54:39.928993  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882485 (* 1 = 0.0882485 loss)
I0626 04:54:39.928999  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.112692 (* 1 = 0.112692 loss)
I0626 04:54:39.929004  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00969426 (* 1 = 0.00969426 loss)
I0626 04:54:39.929010  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140675 (* 1 = 0.0140675 loss)
I0626 04:54:39.929016  4216 sgd_solver.cpp:106] Iteration 11660, lr = 0.0002
I0626 04:56:25.154546  4216 solver.cpp:228] Iteration 11680, loss = 0.318745
I0626 04:56:25.154572  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 04:56:25.154580  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.17456 (* 1 = 0.17456 loss)
I0626 04:56:25.154587  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.312005 (* 1 = 0.312005 loss)
I0626 04:56:25.154592  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125511 (* 1 = 0.0125511 loss)
I0626 04:56:25.154599  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293004 (* 1 = 0.0293004 loss)
I0626 04:56:25.154606  4216 sgd_solver.cpp:106] Iteration 11680, lr = 0.0002
I0626 04:58:10.392633  4216 solver.cpp:228] Iteration 11700, loss = 0.2746
I0626 04:58:10.392660  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 04:58:10.392668  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0956804 (* 1 = 0.0956804 loss)
I0626 04:58:10.392673  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.224759 (* 1 = 0.224759 loss)
I0626 04:58:10.392676  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388657 (* 1 = 0.00388657 loss)
I0626 04:58:10.392680  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198669 (* 1 = 0.0198669 loss)
I0626 04:58:10.392686  4216 sgd_solver.cpp:106] Iteration 11700, lr = 0.0002
I0626 04:59:55.583415  4216 solver.cpp:228] Iteration 11720, loss = 0.189142
I0626 04:59:55.583441  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:59:55.583449  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365073 (* 1 = 0.0365073 loss)
I0626 04:59:55.583454  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0431998 (* 1 = 0.0431998 loss)
I0626 04:59:55.583459  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144143 (* 1 = 0.00144143 loss)
I0626 04:59:55.583463  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00994747 (* 1 = 0.00994747 loss)
I0626 04:59:55.583469  4216 sgd_solver.cpp:106] Iteration 11720, lr = 0.0002
I0626 05:01:40.773267  4216 solver.cpp:228] Iteration 11740, loss = 0.154311
I0626 05:01:40.773293  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 05:01:40.773299  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.047715 (* 1 = 0.047715 loss)
I0626 05:01:40.773303  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0502441 (* 1 = 0.0502441 loss)
I0626 05:01:40.773306  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0025684 (* 1 = 0.0025684 loss)
I0626 05:01:40.773310  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165535 (* 1 = 0.0165535 loss)
I0626 05:01:40.773315  4216 sgd_solver.cpp:106] Iteration 11740, lr = 0.0002
I0626 05:03:25.932061  4216 solver.cpp:228] Iteration 11760, loss = 0.335163
I0626 05:03:25.932087  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 05:03:25.932096  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0823817 (* 1 = 0.0823817 loss)
I0626 05:03:25.932099  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0914007 (* 1 = 0.0914007 loss)
I0626 05:03:25.932102  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00393602 (* 1 = 0.00393602 loss)
I0626 05:03:25.932106  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0068398 (* 1 = 0.0068398 loss)
I0626 05:03:25.932111  4216 sgd_solver.cpp:106] Iteration 11760, lr = 0.0002
I0626 05:05:11.068397  4216 solver.cpp:228] Iteration 11780, loss = 0.293129
I0626 05:05:11.068421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:05:11.068429  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00888173 (* 1 = 0.00888173 loss)
I0626 05:05:11.068434  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.030311 (* 1 = 0.030311 loss)
I0626 05:05:11.068437  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000830322 (* 1 = 0.000830322 loss)
I0626 05:05:11.068440  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00868288 (* 1 = 0.00868288 loss)
I0626 05:05:11.068445  4216 sgd_solver.cpp:106] Iteration 11780, lr = 0.0002
speed: 5.241s / iter
I0626 05:06:56.296751  4216 solver.cpp:228] Iteration 11800, loss = 0.290455
I0626 05:06:56.296775  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 05:06:56.296782  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.082069 (* 1 = 0.082069 loss)
I0626 05:06:56.296787  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.202499 (* 1 = 0.202499 loss)
I0626 05:06:56.296790  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211059 (* 1 = 0.0211059 loss)
I0626 05:06:56.296793  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.150113 (* 1 = 0.150113 loss)
I0626 05:06:56.296798  4216 sgd_solver.cpp:106] Iteration 11800, lr = 0.0002
I0626 05:08:41.498720  4216 solver.cpp:228] Iteration 11820, loss = 0.244
I0626 05:08:41.498745  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:08:41.498754  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399891 (* 1 = 0.0399891 loss)
I0626 05:08:41.498757  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0360694 (* 1 = 0.0360694 loss)
I0626 05:08:41.498761  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179737 (* 1 = 0.00179737 loss)
I0626 05:08:41.498765  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00525813 (* 1 = 0.00525813 loss)
I0626 05:08:41.498770  4216 sgd_solver.cpp:106] Iteration 11820, lr = 0.0002
I0626 05:10:26.698299  4216 solver.cpp:228] Iteration 11840, loss = 0.167883
I0626 05:10:26.698325  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 05:10:26.698333  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.149733 (* 1 = 0.149733 loss)
I0626 05:10:26.698338  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.336571 (* 1 = 0.336571 loss)
I0626 05:10:26.698343  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00210237 (* 1 = 0.00210237 loss)
I0626 05:10:26.698346  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0527941 (* 1 = 0.0527941 loss)
I0626 05:10:26.698351  4216 sgd_solver.cpp:106] Iteration 11840, lr = 0.0002
I0626 05:12:11.897487  4216 solver.cpp:228] Iteration 11860, loss = 0.307927
I0626 05:12:11.897513  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 05:12:11.897521  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.134182 (* 1 = 0.134182 loss)
I0626 05:12:11.897526  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.131529 (* 1 = 0.131529 loss)
I0626 05:12:11.897529  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000840917 (* 1 = 0.000840917 loss)
I0626 05:12:11.897533  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220252 (* 1 = 0.0220252 loss)
I0626 05:12:11.897539  4216 sgd_solver.cpp:106] Iteration 11860, lr = 0.0002
I0626 05:13:57.087642  4216 solver.cpp:228] Iteration 11880, loss = 0.353244
I0626 05:13:57.087668  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 05:13:57.087676  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.029059 (* 1 = 0.029059 loss)
I0626 05:13:57.087679  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0596259 (* 1 = 0.0596259 loss)
I0626 05:13:57.087683  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00251184 (* 1 = 0.00251184 loss)
I0626 05:13:57.087687  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00275676 (* 1 = 0.00275676 loss)
I0626 05:13:57.087692  4216 sgd_solver.cpp:106] Iteration 11880, lr = 0.0002
I0626 05:15:42.410333  4216 solver.cpp:228] Iteration 11900, loss = 0.220733
I0626 05:15:42.410362  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0626 05:15:42.410368  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.216835 (* 1 = 0.216835 loss)
I0626 05:15:42.410373  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.404995 (* 1 = 0.404995 loss)
I0626 05:15:42.410377  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249783 (* 1 = 0.00249783 loss)
I0626 05:15:42.410382  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372742 (* 1 = 0.0372742 loss)
I0626 05:15:42.410388  4216 sgd_solver.cpp:106] Iteration 11900, lr = 0.0002
I0626 05:17:27.901103  4216 solver.cpp:228] Iteration 11920, loss = 0.30804
I0626 05:17:27.901130  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:17:27.901139  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0832282 (* 1 = 0.0832282 loss)
I0626 05:17:27.901142  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.126578 (* 1 = 0.126578 loss)
I0626 05:17:27.901146  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195013 (* 1 = 0.0195013 loss)
I0626 05:17:27.901150  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028366 (* 1 = 0.028366 loss)
I0626 05:17:27.901155  4216 sgd_solver.cpp:106] Iteration 11920, lr = 0.0002
I0626 05:19:13.291787  4216 solver.cpp:228] Iteration 11940, loss = 0.451879
I0626 05:19:13.291816  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:19:13.291826  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0427032 (* 1 = 0.0427032 loss)
I0626 05:19:13.291831  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0437153 (* 1 = 0.0437153 loss)
I0626 05:19:13.291836  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141887 (* 1 = 0.00141887 loss)
I0626 05:19:13.291839  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00673037 (* 1 = 0.00673037 loss)
I0626 05:19:13.291846  4216 sgd_solver.cpp:106] Iteration 11940, lr = 0.0002
I0626 05:20:58.754624  4216 solver.cpp:228] Iteration 11960, loss = 0.460129
I0626 05:20:58.754655  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:20:58.754665  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245014 (* 1 = 0.0245014 loss)
I0626 05:20:58.754671  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0589974 (* 1 = 0.0589974 loss)
I0626 05:20:58.754678  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00703756 (* 1 = 0.00703756 loss)
I0626 05:20:58.754683  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00193047 (* 1 = 0.00193047 loss)
I0626 05:20:58.754689  4216 sgd_solver.cpp:106] Iteration 11960, lr = 0.0002
I0626 05:22:44.177677  4216 solver.cpp:228] Iteration 11980, loss = 0.326156
I0626 05:22:44.177707  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 05:22:44.177717  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.146851 (* 1 = 0.146851 loss)
I0626 05:22:44.177723  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.332591 (* 1 = 0.332591 loss)
I0626 05:22:44.177729  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00818624 (* 1 = 0.00818624 loss)
I0626 05:22:44.177734  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169985 (* 1 = 0.0169985 loss)
I0626 05:22:44.177742  4216 sgd_solver.cpp:106] Iteration 11980, lr = 0.0002
speed: 5.241s / iter
I0626 05:24:29.568861  4216 solver.cpp:228] Iteration 12000, loss = 0.136327
I0626 05:24:29.568914  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:24:29.568927  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268175 (* 1 = 0.0268175 loss)
I0626 05:24:29.568933  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.10855 (* 1 = 0.10855 loss)
I0626 05:24:29.568939  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0069609 (* 1 = 0.0069609 loss)
I0626 05:24:29.568946  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165665 (* 1 = 0.0165665 loss)
I0626 05:24:29.568956  4216 sgd_solver.cpp:106] Iteration 12000, lr = 0.0002
I0626 05:26:14.857472  4216 solver.cpp:228] Iteration 12020, loss = 0.266551
I0626 05:26:14.857496  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 05:26:14.857503  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.040209 (* 1 = 0.040209 loss)
I0626 05:26:14.857507  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.153172 (* 1 = 0.153172 loss)
I0626 05:26:14.857511  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00571768 (* 1 = 0.00571768 loss)
I0626 05:26:14.857514  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02677 (* 1 = 0.02677 loss)
I0626 05:26:14.857519  4216 sgd_solver.cpp:106] Iteration 12020, lr = 0.0002
I0626 05:28:00.255314  4216 solver.cpp:228] Iteration 12040, loss = 0.259878
I0626 05:28:00.255339  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 05:28:00.255347  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.103149 (* 1 = 0.103149 loss)
I0626 05:28:00.255350  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0931689 (* 1 = 0.0931689 loss)
I0626 05:28:00.255354  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00182123 (* 1 = 0.00182123 loss)
I0626 05:28:00.255358  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0299619 (* 1 = 0.0299619 loss)
I0626 05:28:00.255362  4216 sgd_solver.cpp:106] Iteration 12040, lr = 0.0002
I0626 05:29:45.724421  4216 solver.cpp:228] Iteration 12060, loss = 0.25415
I0626 05:29:45.724452  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 05:29:45.724462  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.111634 (* 1 = 0.111634 loss)
I0626 05:29:45.724467  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.185143 (* 1 = 0.185143 loss)
I0626 05:29:45.724472  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000383337 (* 1 = 0.000383337 loss)
I0626 05:29:45.724476  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00674969 (* 1 = 0.00674969 loss)
I0626 05:29:45.724483  4216 sgd_solver.cpp:106] Iteration 12060, lr = 0.0002
I0626 05:31:31.145957  4216 solver.cpp:228] Iteration 12080, loss = 0.2539
I0626 05:31:31.145985  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:31:31.145994  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138571 (* 1 = 0.0138571 loss)
I0626 05:31:31.146001  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0272422 (* 1 = 0.0272422 loss)
I0626 05:31:31.146006  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000168055 (* 1 = 0.000168055 loss)
I0626 05:31:31.146011  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00543944 (* 1 = 0.00543944 loss)
I0626 05:31:31.146016  4216 sgd_solver.cpp:106] Iteration 12080, lr = 0.0002
I0626 05:33:16.593633  4216 solver.cpp:228] Iteration 12100, loss = 0.233076
I0626 05:33:16.593660  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:33:16.593668  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356365 (* 1 = 0.0356365 loss)
I0626 05:33:16.593673  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0467703 (* 1 = 0.0467703 loss)
I0626 05:33:16.593677  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000562403 (* 1 = 0.000562403 loss)
I0626 05:33:16.593681  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00559991 (* 1 = 0.00559991 loss)
I0626 05:33:16.593688  4216 sgd_solver.cpp:106] Iteration 12100, lr = 0.0002
I0626 05:35:02.027343  4216 solver.cpp:228] Iteration 12120, loss = 0.137909
I0626 05:35:02.027372  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:35:02.027384  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00154381 (* 1 = 0.00154381 loss)
I0626 05:35:02.027390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.053188 (* 1 = 0.053188 loss)
I0626 05:35:02.027396  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00995748 (* 1 = 0.00995748 loss)
I0626 05:35:02.027403  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193101 (* 1 = 0.0193101 loss)
I0626 05:35:02.027412  4216 sgd_solver.cpp:106] Iteration 12120, lr = 0.0002
I0626 05:36:47.404124  4216 solver.cpp:228] Iteration 12140, loss = 0.302392
I0626 05:36:47.404151  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 05:36:47.404160  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.149968 (* 1 = 0.149968 loss)
I0626 05:36:47.404165  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.240523 (* 1 = 0.240523 loss)
I0626 05:36:47.404170  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00234743 (* 1 = 0.00234743 loss)
I0626 05:36:47.404175  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269804 (* 1 = 0.0269804 loss)
I0626 05:36:47.404181  4216 sgd_solver.cpp:106] Iteration 12140, lr = 0.0002
I0626 05:38:32.671272  4216 solver.cpp:228] Iteration 12160, loss = 0.411983
I0626 05:38:32.671296  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0626 05:38:32.671303  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.331654 (* 1 = 0.331654 loss)
I0626 05:38:32.671308  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.54828 (* 1 = 0.54828 loss)
I0626 05:38:32.671310  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00534704 (* 1 = 0.00534704 loss)
I0626 05:38:32.671314  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0910798 (* 1 = 0.0910798 loss)
I0626 05:38:32.671319  4216 sgd_solver.cpp:106] Iteration 12160, lr = 0.0002
I0626 05:40:17.985370  4216 solver.cpp:228] Iteration 12180, loss = 0.169304
I0626 05:40:17.985396  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 05:40:17.985404  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0419041 (* 1 = 0.0419041 loss)
I0626 05:40:17.985409  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0965886 (* 1 = 0.0965886 loss)
I0626 05:40:17.985414  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00936357 (* 1 = 0.00936357 loss)
I0626 05:40:17.985419  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187409 (* 1 = 0.0187409 loss)
I0626 05:40:17.985424  4216 sgd_solver.cpp:106] Iteration 12180, lr = 0.0002
speed: 5.242s / iter
I0626 05:42:03.172286  4216 solver.cpp:228] Iteration 12200, loss = 0.194928
I0626 05:42:03.172313  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:42:03.172322  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120753 (* 1 = 0.0120753 loss)
I0626 05:42:03.172328  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0662927 (* 1 = 0.0662927 loss)
I0626 05:42:03.172334  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000456104 (* 1 = 0.000456104 loss)
I0626 05:42:03.172341  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0063162 (* 1 = 0.0063162 loss)
I0626 05:42:03.172349  4216 sgd_solver.cpp:106] Iteration 12200, lr = 0.0002
I0626 05:43:48.337184  4216 solver.cpp:228] Iteration 12220, loss = 0.272686
I0626 05:43:48.337213  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:43:48.337222  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0376778 (* 1 = 0.0376778 loss)
I0626 05:43:48.337229  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0936781 (* 1 = 0.0936781 loss)
I0626 05:43:48.337234  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00596205 (* 1 = 0.00596205 loss)
I0626 05:43:48.337239  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264464 (* 1 = 0.0264464 loss)
I0626 05:43:48.337244  4216 sgd_solver.cpp:106] Iteration 12220, lr = 0.0002
I0626 05:45:33.657974  4216 solver.cpp:228] Iteration 12240, loss = 0.165182
I0626 05:45:33.658002  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:45:33.658010  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0230357 (* 1 = 0.0230357 loss)
I0626 05:45:33.658015  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0380629 (* 1 = 0.0380629 loss)
I0626 05:45:33.658018  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000480847 (* 1 = 0.000480847 loss)
I0626 05:45:33.658022  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00290864 (* 1 = 0.00290864 loss)
I0626 05:45:33.658028  4216 sgd_solver.cpp:106] Iteration 12240, lr = 0.0002
I0626 05:47:18.907296  4216 solver.cpp:228] Iteration 12260, loss = 0.274565
I0626 05:47:18.907325  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:47:18.907335  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186112 (* 1 = 0.0186112 loss)
I0626 05:47:18.907341  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0209569 (* 1 = 0.0209569 loss)
I0626 05:47:18.907346  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000474243 (* 1 = 0.000474243 loss)
I0626 05:47:18.907352  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0032919 (* 1 = 0.0032919 loss)
I0626 05:47:18.907358  4216 sgd_solver.cpp:106] Iteration 12260, lr = 0.0002
I0626 05:49:04.190666  4216 solver.cpp:228] Iteration 12280, loss = 0.189181
I0626 05:49:04.190692  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 05:49:04.190701  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.24172 (* 1 = 0.24172 loss)
I0626 05:49:04.190704  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.531355 (* 1 = 0.531355 loss)
I0626 05:49:04.190708  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00609321 (* 1 = 0.00609321 loss)
I0626 05:49:04.190712  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.132541 (* 1 = 0.132541 loss)
I0626 05:49:04.190717  4216 sgd_solver.cpp:106] Iteration 12280, lr = 0.0002
I0626 05:50:49.373802  4216 solver.cpp:228] Iteration 12300, loss = 0.31509
I0626 05:50:49.373983  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:50:49.374034  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739018 (* 1 = 0.0739018 loss)
I0626 05:50:49.374059  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0656079 (* 1 = 0.0656079 loss)
I0626 05:50:49.374083  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000754727 (* 1 = 0.000754727 loss)
I0626 05:50:49.374104  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00499232 (* 1 = 0.00499232 loss)
I0626 05:50:49.374130  4216 sgd_solver.cpp:106] Iteration 12300, lr = 0.0002
I0626 05:52:34.713569  4216 solver.cpp:228] Iteration 12320, loss = 0.257032
I0626 05:52:34.713593  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 05:52:34.713600  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.202125 (* 1 = 0.202125 loss)
I0626 05:52:34.713604  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.376367 (* 1 = 0.376367 loss)
I0626 05:52:34.713608  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377393 (* 1 = 0.00377393 loss)
I0626 05:52:34.713611  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0635583 (* 1 = 0.0635583 loss)
I0626 05:52:34.713616  4216 sgd_solver.cpp:106] Iteration 12320, lr = 0.0002
I0626 05:54:19.908398  4216 solver.cpp:228] Iteration 12340, loss = 0.243801
I0626 05:54:19.908426  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:54:19.908433  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331046 (* 1 = 0.0331046 loss)
I0626 05:54:19.908437  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0697266 (* 1 = 0.0697266 loss)
I0626 05:54:19.908442  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000838619 (* 1 = 0.000838619 loss)
I0626 05:54:19.908445  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00697061 (* 1 = 0.00697061 loss)
I0626 05:54:19.908452  4216 sgd_solver.cpp:106] Iteration 12340, lr = 0.0002
I0626 05:56:05.146812  4216 solver.cpp:228] Iteration 12360, loss = 0.288002
I0626 05:56:05.146836  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 05:56:05.146842  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0568671 (* 1 = 0.0568671 loss)
I0626 05:56:05.146847  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.112474 (* 1 = 0.112474 loss)
I0626 05:56:05.146850  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102769 (* 1 = 0.0102769 loss)
I0626 05:56:05.146853  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016755 (* 1 = 0.016755 loss)
I0626 05:56:05.146862  4216 sgd_solver.cpp:106] Iteration 12360, lr = 0.0002
I0626 05:57:50.434727  4216 solver.cpp:228] Iteration 12380, loss = 0.257675
I0626 05:57:50.434762  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:57:50.434772  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225293 (* 1 = 0.0225293 loss)
I0626 05:57:50.434780  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0465717 (* 1 = 0.0465717 loss)
I0626 05:57:50.434787  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00212863 (* 1 = 0.00212863 loss)
I0626 05:57:50.434794  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107204 (* 1 = 0.0107204 loss)
I0626 05:57:50.434801  4216 sgd_solver.cpp:106] Iteration 12380, lr = 0.0002
speed: 5.242s / iter
I0626 05:59:35.606125  4216 solver.cpp:228] Iteration 12400, loss = 0.176651
I0626 05:59:35.606154  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 05:59:35.606164  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0592976 (* 1 = 0.0592976 loss)
I0626 05:59:35.606170  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0797212 (* 1 = 0.0797212 loss)
I0626 05:59:35.606176  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00111628 (* 1 = 0.00111628 loss)
I0626 05:59:35.606184  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126801 (* 1 = 0.0126801 loss)
I0626 05:59:35.606194  4216 sgd_solver.cpp:106] Iteration 12400, lr = 0.0002
I0626 06:01:20.844135  4216 solver.cpp:228] Iteration 12420, loss = 0.32104
I0626 06:01:20.844159  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 06:01:20.844166  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0798712 (* 1 = 0.0798712 loss)
I0626 06:01:20.844171  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.21481 (* 1 = 0.21481 loss)
I0626 06:01:20.844174  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204619 (* 1 = 0.00204619 loss)
I0626 06:01:20.844177  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00792923 (* 1 = 0.00792923 loss)
I0626 06:01:20.844182  4216 sgd_solver.cpp:106] Iteration 12420, lr = 0.0002
I0626 06:03:06.065732  4216 solver.cpp:228] Iteration 12440, loss = 0.240068
I0626 06:03:06.065757  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:03:06.065763  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0134667 (* 1 = 0.0134667 loss)
I0626 06:03:06.065768  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.136632 (* 1 = 0.136632 loss)
I0626 06:03:06.065771  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157206 (* 1 = 0.00157206 loss)
I0626 06:03:06.065774  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00113718 (* 1 = 0.00113718 loss)
I0626 06:03:06.065780  4216 sgd_solver.cpp:106] Iteration 12440, lr = 0.0002
I0626 06:04:51.377090  4216 solver.cpp:228] Iteration 12460, loss = 0.153985
I0626 06:04:51.377117  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:04:51.377127  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155675 (* 1 = 0.0155675 loss)
I0626 06:04:51.377135  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.056147 (* 1 = 0.056147 loss)
I0626 06:04:51.377140  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000311206 (* 1 = 0.000311206 loss)
I0626 06:04:51.377147  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030785 (* 1 = 0.030785 loss)
I0626 06:04:51.377154  4216 sgd_solver.cpp:106] Iteration 12460, lr = 0.0002
I0626 06:06:36.567574  4216 solver.cpp:228] Iteration 12480, loss = 0.43165
I0626 06:06:36.567600  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 06:06:36.567606  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335462 (* 1 = 0.0335462 loss)
I0626 06:06:36.567611  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0225993 (* 1 = 0.0225993 loss)
I0626 06:06:36.567615  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000837633 (* 1 = 0.000837633 loss)
I0626 06:06:36.567618  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170476 (* 1 = 0.0170476 loss)
I0626 06:06:36.567623  4216 sgd_solver.cpp:106] Iteration 12480, lr = 0.0002
I0626 06:08:21.854955  4216 solver.cpp:228] Iteration 12500, loss = 0.219055
I0626 06:08:21.854981  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:08:21.854991  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0193076 (* 1 = 0.0193076 loss)
I0626 06:08:21.854998  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0249014 (* 1 = 0.0249014 loss)
I0626 06:08:21.855005  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000668342 (* 1 = 0.000668342 loss)
I0626 06:08:21.855011  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00743598 (* 1 = 0.00743598 loss)
I0626 06:08:21.855020  4216 sgd_solver.cpp:106] Iteration 12500, lr = 0.0002
I0626 06:10:07.028228  4216 solver.cpp:228] Iteration 12520, loss = 0.207204
I0626 06:10:07.028254  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:10:07.028260  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0102432 (* 1 = 0.0102432 loss)
I0626 06:10:07.028265  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0294071 (* 1 = 0.0294071 loss)
I0626 06:10:07.028270  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115486 (* 1 = 0.00115486 loss)
I0626 06:10:07.028273  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00740637 (* 1 = 0.00740637 loss)
I0626 06:10:07.028278  4216 sgd_solver.cpp:106] Iteration 12520, lr = 0.0002
I0626 06:11:52.198173  4216 solver.cpp:228] Iteration 12540, loss = 0.134776
I0626 06:11:52.198199  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 06:11:52.198207  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0557542 (* 1 = 0.0557542 loss)
I0626 06:11:52.198212  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117184 (* 1 = 0.117184 loss)
I0626 06:11:52.198216  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00609669 (* 1 = 0.00609669 loss)
I0626 06:11:52.198220  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00566973 (* 1 = 0.00566973 loss)
I0626 06:11:52.198225  4216 sgd_solver.cpp:106] Iteration 12540, lr = 0.0002
I0626 06:13:37.358477  4216 solver.cpp:228] Iteration 12560, loss = 0.315622
I0626 06:13:37.358505  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:13:37.358515  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472939 (* 1 = 0.0472939 loss)
I0626 06:13:37.358521  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0406002 (* 1 = 0.0406002 loss)
I0626 06:13:37.358526  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000371942 (* 1 = 0.000371942 loss)
I0626 06:13:37.358533  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0085074 (* 1 = 0.0085074 loss)
I0626 06:13:37.358539  4216 sgd_solver.cpp:106] Iteration 12560, lr = 0.0002
I0626 06:15:22.563508  4216 solver.cpp:228] Iteration 12580, loss = 0.213866
I0626 06:15:22.563532  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:15:22.563540  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293285 (* 1 = 0.0293285 loss)
I0626 06:15:22.563544  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.056759 (* 1 = 0.056759 loss)
I0626 06:15:22.563547  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010319 (* 1 = 0.0010319 loss)
I0626 06:15:22.563551  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00690283 (* 1 = 0.00690283 loss)
I0626 06:15:22.563556  4216 sgd_solver.cpp:106] Iteration 12580, lr = 0.0002
speed: 5.242s / iter
I0626 06:17:07.764586  4216 solver.cpp:228] Iteration 12600, loss = 0.302979
I0626 06:17:07.764611  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:17:07.764617  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251268 (* 1 = 0.0251268 loss)
I0626 06:17:07.764621  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0841439 (* 1 = 0.0841439 loss)
I0626 06:17:07.764626  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000295647 (* 1 = 0.000295647 loss)
I0626 06:17:07.764628  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00172035 (* 1 = 0.00172035 loss)
I0626 06:17:07.764633  4216 sgd_solver.cpp:106] Iteration 12600, lr = 0.0002
I0626 06:18:52.961587  4216 solver.cpp:228] Iteration 12620, loss = 0.305527
I0626 06:18:52.961611  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 06:18:52.961618  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.151648 (* 1 = 0.151648 loss)
I0626 06:18:52.961623  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.146654 (* 1 = 0.146654 loss)
I0626 06:18:52.961627  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00971131 (* 1 = 0.00971131 loss)
I0626 06:18:52.961632  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336426 (* 1 = 0.0336426 loss)
I0626 06:18:52.961637  4216 sgd_solver.cpp:106] Iteration 12620, lr = 0.0002
I0626 06:20:38.178990  4216 solver.cpp:228] Iteration 12640, loss = 0.264695
I0626 06:20:38.179016  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 06:20:38.179024  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0283126 (* 1 = 0.0283126 loss)
I0626 06:20:38.179028  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0345327 (* 1 = 0.0345327 loss)
I0626 06:20:38.179033  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249531 (* 1 = 0.00249531 loss)
I0626 06:20:38.179036  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00421923 (* 1 = 0.00421923 loss)
I0626 06:20:38.179041  4216 sgd_solver.cpp:106] Iteration 12640, lr = 0.0002
I0626 06:22:23.389098  4216 solver.cpp:228] Iteration 12660, loss = 0.234483
I0626 06:22:23.389125  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:22:23.389133  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293568 (* 1 = 0.0293568 loss)
I0626 06:22:23.389138  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0735602 (* 1 = 0.0735602 loss)
I0626 06:22:23.389142  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000221843 (* 1 = 0.000221843 loss)
I0626 06:22:23.389147  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00449327 (* 1 = 0.00449327 loss)
I0626 06:22:23.389153  4216 sgd_solver.cpp:106] Iteration 12660, lr = 0.0002
I0626 06:24:08.600560  4216 solver.cpp:228] Iteration 12680, loss = 0.140216
I0626 06:24:08.600589  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:24:08.600596  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205551 (* 1 = 0.0205551 loss)
I0626 06:24:08.600600  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0346877 (* 1 = 0.0346877 loss)
I0626 06:24:08.600605  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00334687 (* 1 = 0.00334687 loss)
I0626 06:24:08.600610  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00921188 (* 1 = 0.00921188 loss)
I0626 06:24:08.600615  4216 sgd_solver.cpp:106] Iteration 12680, lr = 0.0002
I0626 06:25:53.850821  4216 solver.cpp:228] Iteration 12700, loss = 0.189668
I0626 06:25:53.850848  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:25:53.850857  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0684053 (* 1 = 0.0684053 loss)
I0626 06:25:53.850864  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0804904 (* 1 = 0.0804904 loss)
I0626 06:25:53.850869  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000376266 (* 1 = 0.000376266 loss)
I0626 06:25:53.850873  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143011 (* 1 = 0.0143011 loss)
I0626 06:25:53.850878  4216 sgd_solver.cpp:106] Iteration 12700, lr = 0.0002
I0626 06:27:38.975798  4216 solver.cpp:228] Iteration 12720, loss = 0.26112
I0626 06:27:38.975824  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:27:38.975832  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.017938 (* 1 = 0.017938 loss)
I0626 06:27:38.975837  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0497439 (* 1 = 0.0497439 loss)
I0626 06:27:38.975841  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160189 (* 1 = 0.00160189 loss)
I0626 06:27:38.975845  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169903 (* 1 = 0.0169903 loss)
I0626 06:27:38.975852  4216 sgd_solver.cpp:106] Iteration 12720, lr = 0.0002
I0626 06:29:24.124892  4216 solver.cpp:228] Iteration 12740, loss = 0.167136
I0626 06:29:24.124919  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 06:29:24.124930  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0616975 (* 1 = 0.0616975 loss)
I0626 06:29:24.124936  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.244638 (* 1 = 0.244638 loss)
I0626 06:29:24.124943  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184042 (* 1 = 0.0184042 loss)
I0626 06:29:24.124948  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439349 (* 1 = 0.0439349 loss)
I0626 06:29:24.124955  4216 sgd_solver.cpp:106] Iteration 12740, lr = 0.0002
I0626 06:31:09.273640  4216 solver.cpp:228] Iteration 12760, loss = 0.22379
I0626 06:31:09.273670  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 06:31:09.273679  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120392 (* 1 = 0.120392 loss)
I0626 06:31:09.273682  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.136601 (* 1 = 0.136601 loss)
I0626 06:31:09.273687  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178229 (* 1 = 0.00178229 loss)
I0626 06:31:09.273691  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144292 (* 1 = 0.0144292 loss)
I0626 06:31:09.273696  4216 sgd_solver.cpp:106] Iteration 12760, lr = 0.0002
I0626 06:32:54.422081  4216 solver.cpp:228] Iteration 12780, loss = 0.337686
I0626 06:32:54.422106  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 06:32:54.422112  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453201 (* 1 = 0.0453201 loss)
I0626 06:32:54.422116  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.105446 (* 1 = 0.105446 loss)
I0626 06:32:54.422121  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00324168 (* 1 = 0.00324168 loss)
I0626 06:32:54.422124  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00714932 (* 1 = 0.00714932 loss)
I0626 06:32:54.422128  4216 sgd_solver.cpp:106] Iteration 12780, lr = 0.0002
speed: 5.243s / iter
I0626 06:34:39.593569  4216 solver.cpp:228] Iteration 12800, loss = 0.162164
I0626 06:34:39.593597  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:34:39.593605  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.024286 (* 1 = 0.024286 loss)
I0626 06:34:39.593608  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0433962 (* 1 = 0.0433962 loss)
I0626 06:34:39.593612  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147673 (* 1 = 0.00147673 loss)
I0626 06:34:39.593616  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00732654 (* 1 = 0.00732654 loss)
I0626 06:34:39.593621  4216 sgd_solver.cpp:106] Iteration 12800, lr = 0.0002
I0626 06:36:24.802948  4216 solver.cpp:228] Iteration 12820, loss = 0.233079
I0626 06:36:24.802973  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 06:36:24.802980  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.156445 (* 1 = 0.156445 loss)
I0626 06:36:24.802984  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.218801 (* 1 = 0.218801 loss)
I0626 06:36:24.802989  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108409 (* 1 = 0.00108409 loss)
I0626 06:36:24.802991  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190334 (* 1 = 0.0190334 loss)
I0626 06:36:24.802997  4216 sgd_solver.cpp:106] Iteration 12820, lr = 0.0002
I0626 06:38:09.986356  4216 solver.cpp:228] Iteration 12840, loss = 0.206475
I0626 06:38:09.986383  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:38:09.986392  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0387823 (* 1 = 0.0387823 loss)
I0626 06:38:09.986395  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0431478 (* 1 = 0.0431478 loss)
I0626 06:38:09.986399  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000916021 (* 1 = 0.000916021 loss)
I0626 06:38:09.986404  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166867 (* 1 = 0.0166867 loss)
I0626 06:38:09.986409  4216 sgd_solver.cpp:106] Iteration 12840, lr = 0.0002
I0626 06:39:55.237643  4216 solver.cpp:228] Iteration 12860, loss = 0.252676
I0626 06:39:55.237668  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 06:39:55.237675  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.154412 (* 1 = 0.154412 loss)
I0626 06:39:55.237679  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.279663 (* 1 = 0.279663 loss)
I0626 06:39:55.237684  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541863 (* 1 = 0.00541863 loss)
I0626 06:39:55.237689  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275738 (* 1 = 0.0275738 loss)
I0626 06:39:55.237694  4216 sgd_solver.cpp:106] Iteration 12860, lr = 0.0002
I0626 06:41:40.440482  4216 solver.cpp:228] Iteration 12880, loss = 0.216596
I0626 06:41:40.440508  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:41:40.440516  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00158619 (* 1 = 0.00158619 loss)
I0626 06:41:40.440521  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0187598 (* 1 = 0.0187598 loss)
I0626 06:41:40.440526  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016711 (* 1 = 0.0016711 loss)
I0626 06:41:40.440529  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0014165 (* 1 = 0.0014165 loss)
I0626 06:41:40.440534  4216 sgd_solver.cpp:106] Iteration 12880, lr = 0.0002
I0626 06:43:25.637909  4216 solver.cpp:228] Iteration 12900, loss = 0.23733
I0626 06:43:25.637935  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:43:25.637943  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0853795 (* 1 = 0.0853795 loss)
I0626 06:43:25.637949  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.082487 (* 1 = 0.082487 loss)
I0626 06:43:25.637955  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000450119 (* 1 = 0.000450119 loss)
I0626 06:43:25.637961  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0070749 (* 1 = 0.0070749 loss)
I0626 06:43:25.637969  4216 sgd_solver.cpp:106] Iteration 12900, lr = 0.0002
I0626 06:45:10.721982  4216 solver.cpp:228] Iteration 12920, loss = 0.354285
I0626 06:45:10.722008  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0626 06:45:10.722017  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.233701 (* 1 = 0.233701 loss)
I0626 06:45:10.722023  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.390443 (* 1 = 0.390443 loss)
I0626 06:45:10.722028  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116766 (* 1 = 0.00116766 loss)
I0626 06:45:10.722033  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0474224 (* 1 = 0.0474224 loss)
I0626 06:45:10.722040  4216 sgd_solver.cpp:106] Iteration 12920, lr = 0.0002
I0626 06:46:55.931170  4216 solver.cpp:228] Iteration 12940, loss = 0.220576
I0626 06:46:55.931195  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:46:55.931202  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.085399 (* 1 = 0.085399 loss)
I0626 06:46:55.931206  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.115436 (* 1 = 0.115436 loss)
I0626 06:46:55.931210  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350827 (* 1 = 0.00350827 loss)
I0626 06:46:55.931213  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264173 (* 1 = 0.0264173 loss)
I0626 06:46:55.931217  4216 sgd_solver.cpp:106] Iteration 12940, lr = 0.0002
I0626 06:48:41.093662  4216 solver.cpp:228] Iteration 12960, loss = 0.340429
I0626 06:48:41.093686  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:48:41.093695  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00931709 (* 1 = 0.00931709 loss)
I0626 06:48:41.093701  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0431825 (* 1 = 0.0431825 loss)
I0626 06:48:41.093708  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108256 (* 1 = 0.00108256 loss)
I0626 06:48:41.093713  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270212 (* 1 = 0.0270212 loss)
I0626 06:48:41.093719  4216 sgd_solver.cpp:106] Iteration 12960, lr = 0.0002
I0626 06:50:26.277122  4216 solver.cpp:228] Iteration 12980, loss = 0.266412
I0626 06:50:26.277146  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:50:26.277153  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0597934 (* 1 = 0.0597934 loss)
I0626 06:50:26.277158  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0829618 (* 1 = 0.0829618 loss)
I0626 06:50:26.277161  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165952 (* 1 = 0.00165952 loss)
I0626 06:50:26.277165  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149709 (* 1 = 0.0149709 loss)
I0626 06:50:26.277170  4216 sgd_solver.cpp:106] Iteration 12980, lr = 0.0002
speed: 5.243s / iter
I0626 06:52:11.472298  4216 solver.cpp:228] Iteration 13000, loss = 0.155586
I0626 06:52:11.472326  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:52:11.472335  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0342974 (* 1 = 0.0342974 loss)
I0626 06:52:11.472342  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0589413 (* 1 = 0.0589413 loss)
I0626 06:52:11.472348  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238292 (* 1 = 0.00238292 loss)
I0626 06:52:11.472357  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198531 (* 1 = 0.0198531 loss)
I0626 06:52:11.472367  4216 sgd_solver.cpp:106] Iteration 13000, lr = 0.0002
I0626 06:53:56.773403  4216 solver.cpp:228] Iteration 13020, loss = 0.194683
I0626 06:53:56.773428  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 06:53:56.773435  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.168279 (* 1 = 0.168279 loss)
I0626 06:53:56.773439  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.195587 (* 1 = 0.195587 loss)
I0626 06:53:56.773443  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136196 (* 1 = 0.00136196 loss)
I0626 06:53:56.773447  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0569662 (* 1 = 0.0569662 loss)
I0626 06:53:56.773452  4216 sgd_solver.cpp:106] Iteration 13020, lr = 0.0002
I0626 06:55:42.081048  4216 solver.cpp:228] Iteration 13040, loss = 0.252688
I0626 06:55:42.081074  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:55:42.081081  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362018 (* 1 = 0.0362018 loss)
I0626 06:55:42.081086  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0603535 (* 1 = 0.0603535 loss)
I0626 06:55:42.081090  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000819847 (* 1 = 0.000819847 loss)
I0626 06:55:42.081095  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00332611 (* 1 = 0.00332611 loss)
I0626 06:55:42.081101  4216 sgd_solver.cpp:106] Iteration 13040, lr = 0.0002
I0626 06:57:27.339555  4216 solver.cpp:228] Iteration 13060, loss = 0.348569
I0626 06:57:27.339581  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 06:57:27.339589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.133918 (* 1 = 0.133918 loss)
I0626 06:57:27.339593  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.10845 (* 1 = 0.10845 loss)
I0626 06:57:27.339597  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000936627 (* 1 = 0.000936627 loss)
I0626 06:57:27.339601  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174721 (* 1 = 0.0174721 loss)
I0626 06:57:27.339606  4216 sgd_solver.cpp:106] Iteration 13060, lr = 0.0002
I0626 06:59:12.756623  4216 solver.cpp:228] Iteration 13080, loss = 0.232365
I0626 06:59:12.756647  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:59:12.756654  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0769084 (* 1 = 0.0769084 loss)
I0626 06:59:12.756659  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.126596 (* 1 = 0.126596 loss)
I0626 06:59:12.756662  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00868005 (* 1 = 0.00868005 loss)
I0626 06:59:12.756666  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379153 (* 1 = 0.0379153 loss)
I0626 06:59:12.756670  4216 sgd_solver.cpp:106] Iteration 13080, lr = 0.0002
I0626 07:00:58.039053  4216 solver.cpp:228] Iteration 13100, loss = 0.272785
I0626 07:00:58.039079  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 07:00:58.039086  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.146283 (* 1 = 0.146283 loss)
I0626 07:00:58.039091  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.197546 (* 1 = 0.197546 loss)
I0626 07:00:58.039095  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00123017 (* 1 = 0.00123017 loss)
I0626 07:00:58.039099  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197973 (* 1 = 0.0197973 loss)
I0626 07:00:58.039105  4216 sgd_solver.cpp:106] Iteration 13100, lr = 0.0002
I0626 07:02:43.380916  4216 solver.cpp:228] Iteration 13120, loss = 0.356426
I0626 07:02:43.380941  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 07:02:43.380949  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.185018 (* 1 = 0.185018 loss)
I0626 07:02:43.380954  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.283874 (* 1 = 0.283874 loss)
I0626 07:02:43.380959  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158346 (* 1 = 0.0158346 loss)
I0626 07:02:43.380962  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.041444 (* 1 = 0.041444 loss)
I0626 07:02:43.380967  4216 sgd_solver.cpp:106] Iteration 13120, lr = 0.0002
I0626 07:04:28.678700  4216 solver.cpp:228] Iteration 13140, loss = 0.270385
I0626 07:04:28.678730  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 07:04:28.678742  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.154888 (* 1 = 0.154888 loss)
I0626 07:04:28.678750  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.278954 (* 1 = 0.278954 loss)
I0626 07:04:28.678758  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648305 (* 1 = 0.00648305 loss)
I0626 07:04:28.678766  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0568654 (* 1 = 0.0568654 loss)
I0626 07:04:28.678776  4216 sgd_solver.cpp:106] Iteration 13140, lr = 0.0002
I0626 07:06:13.984623  4216 solver.cpp:228] Iteration 13160, loss = 0.370667
I0626 07:06:13.984649  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 07:06:13.984658  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.105308 (* 1 = 0.105308 loss)
I0626 07:06:13.984661  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.165428 (* 1 = 0.165428 loss)
I0626 07:06:13.984666  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00323933 (* 1 = 0.00323933 loss)
I0626 07:06:13.984669  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222209 (* 1 = 0.0222209 loss)
I0626 07:06:13.984675  4216 sgd_solver.cpp:106] Iteration 13160, lr = 0.0002
I0626 07:07:59.374917  4216 solver.cpp:228] Iteration 13180, loss = 0.296013
I0626 07:07:59.374941  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 07:07:59.374949  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.159527 (* 1 = 0.159527 loss)
I0626 07:07:59.374953  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.171019 (* 1 = 0.171019 loss)
I0626 07:07:59.374958  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00858786 (* 1 = 0.00858786 loss)
I0626 07:07:59.374961  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663355 (* 1 = 0.0663355 loss)
I0626 07:07:59.374966  4216 sgd_solver.cpp:106] Iteration 13180, lr = 0.0002
speed: 5.243s / iter
I0626 07:09:44.669422  4216 solver.cpp:228] Iteration 13200, loss = 0.276076
I0626 07:09:44.669448  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 07:09:44.669456  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154013 (* 1 = 0.0154013 loss)
I0626 07:09:44.669461  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0436611 (* 1 = 0.0436611 loss)
I0626 07:09:44.669466  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00680052 (* 1 = 0.00680052 loss)
I0626 07:09:44.669469  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00498304 (* 1 = 0.00498304 loss)
I0626 07:09:44.669474  4216 sgd_solver.cpp:106] Iteration 13200, lr = 0.0002
I0626 07:11:30.090997  4216 solver.cpp:228] Iteration 13220, loss = 0.196751
I0626 07:11:30.091023  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 07:11:30.091032  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00198323 (* 1 = 0.00198323 loss)
I0626 07:11:30.091037  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0143835 (* 1 = 0.0143835 loss)
I0626 07:11:30.091040  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00312959 (* 1 = 0.00312959 loss)
I0626 07:11:30.091044  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119527 (* 1 = 0.0119527 loss)
I0626 07:11:30.091049  4216 sgd_solver.cpp:106] Iteration 13220, lr = 0.0002
I0626 07:13:15.319012  4216 solver.cpp:228] Iteration 13240, loss = 0.355527
I0626 07:13:15.319037  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 07:13:15.319044  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540021 (* 1 = 0.0540021 loss)
I0626 07:13:15.319049  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.143881 (* 1 = 0.143881 loss)
I0626 07:13:15.319053  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208077 (* 1 = 0.0208077 loss)
I0626 07:13:15.319057  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400999 (* 1 = 0.0400999 loss)
I0626 07:13:15.319062  4216 sgd_solver.cpp:106] Iteration 13240, lr = 0.0002
I0626 07:15:00.521224  4216 solver.cpp:228] Iteration 13260, loss = 0.175563
I0626 07:15:00.521251  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:15:00.521260  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413374 (* 1 = 0.0413374 loss)
I0626 07:15:00.521266  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.126867 (* 1 = 0.126867 loss)
I0626 07:15:00.521272  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00550739 (* 1 = 0.00550739 loss)
I0626 07:15:00.521277  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105414 (* 1 = 0.0105414 loss)
I0626 07:15:00.521284  4216 sgd_solver.cpp:106] Iteration 13260, lr = 0.0002
I0626 07:16:45.655239  4216 solver.cpp:228] Iteration 13280, loss = 0.124991
I0626 07:16:45.655264  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:16:45.655272  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413857 (* 1 = 0.0413857 loss)
I0626 07:16:45.655275  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0596414 (* 1 = 0.0596414 loss)
I0626 07:16:45.655278  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144939 (* 1 = 0.0144939 loss)
I0626 07:16:45.655282  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00449734 (* 1 = 0.00449734 loss)
I0626 07:16:45.655287  4216 sgd_solver.cpp:106] Iteration 13280, lr = 0.0002
I0626 07:18:30.927875  4216 solver.cpp:228] Iteration 13300, loss = 0.282645
I0626 07:18:30.927901  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:18:30.927911  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0658244 (* 1 = 0.0658244 loss)
I0626 07:18:30.927917  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0817816 (* 1 = 0.0817816 loss)
I0626 07:18:30.927922  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00227521 (* 1 = 0.00227521 loss)
I0626 07:18:30.927927  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233152 (* 1 = 0.0233152 loss)
I0626 07:18:30.927932  4216 sgd_solver.cpp:106] Iteration 13300, lr = 0.0002
I0626 07:20:16.216706  4216 solver.cpp:228] Iteration 13320, loss = 0.425221
I0626 07:20:16.216733  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 07:20:16.216743  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0632538 (* 1 = 0.0632538 loss)
I0626 07:20:16.216750  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.222377 (* 1 = 0.222377 loss)
I0626 07:20:16.216756  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145376 (* 1 = 0.0145376 loss)
I0626 07:20:16.216763  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487473 (* 1 = 0.0487473 loss)
I0626 07:20:16.216770  4216 sgd_solver.cpp:106] Iteration 13320, lr = 0.0002
I0626 07:22:01.379027  4216 solver.cpp:228] Iteration 13340, loss = 0.348694
I0626 07:22:01.379052  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:22:01.379063  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0940122 (* 1 = 0.0940122 loss)
I0626 07:22:01.379070  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.151156 (* 1 = 0.151156 loss)
I0626 07:22:01.379076  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0406049 (* 1 = 0.0406049 loss)
I0626 07:22:01.379083  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362209 (* 1 = 0.0362209 loss)
I0626 07:22:01.379091  4216 sgd_solver.cpp:106] Iteration 13340, lr = 0.0002
I0626 07:23:46.532287  4216 solver.cpp:228] Iteration 13360, loss = 0.342848
I0626 07:23:46.532317  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.617188
I0626 07:23:46.532325  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.569693 (* 1 = 0.569693 loss)
I0626 07:23:46.532330  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.692366 (* 1 = 0.692366 loss)
I0626 07:23:46.532333  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0372004 (* 1 = 0.0372004 loss)
I0626 07:23:46.532337  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.142642 (* 1 = 0.142642 loss)
I0626 07:23:46.532343  4216 sgd_solver.cpp:106] Iteration 13360, lr = 0.0002
I0626 07:25:31.684583  4216 solver.cpp:228] Iteration 13380, loss = 0.263528
I0626 07:25:31.684608  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:25:31.684617  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378526 (* 1 = 0.0378526 loss)
I0626 07:25:31.684622  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0472626 (* 1 = 0.0472626 loss)
I0626 07:25:31.684625  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0047702 (* 1 = 0.0047702 loss)
I0626 07:25:31.684629  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00780975 (* 1 = 0.00780975 loss)
I0626 07:25:31.684634  4216 sgd_solver.cpp:106] Iteration 13380, lr = 0.0002
speed: 5.244s / iter
I0626 07:27:16.893350  4216 solver.cpp:228] Iteration 13400, loss = 0.299871
I0626 07:27:16.893374  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:27:16.893381  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0900733 (* 1 = 0.0900733 loss)
I0626 07:27:16.893385  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0916351 (* 1 = 0.0916351 loss)
I0626 07:27:16.893389  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00258862 (* 1 = 0.00258862 loss)
I0626 07:27:16.893393  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110886 (* 1 = 0.0110886 loss)
I0626 07:27:16.893398  4216 sgd_solver.cpp:106] Iteration 13400, lr = 0.0002
I0626 07:29:02.092562  4216 solver.cpp:228] Iteration 13420, loss = 0.187047
I0626 07:29:02.092587  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:29:02.092594  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254581 (* 1 = 0.0254581 loss)
I0626 07:29:02.092597  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0494584 (* 1 = 0.0494584 loss)
I0626 07:29:02.092602  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286313 (* 1 = 0.00286313 loss)
I0626 07:29:02.092605  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00138802 (* 1 = 0.00138802 loss)
I0626 07:29:02.092610  4216 sgd_solver.cpp:106] Iteration 13420, lr = 0.0002
I0626 07:30:47.304756  4216 solver.cpp:228] Iteration 13440, loss = 0.11903
I0626 07:30:47.304780  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:30:47.304787  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.025289 (* 1 = 0.025289 loss)
I0626 07:30:47.304791  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0535622 (* 1 = 0.0535622 loss)
I0626 07:30:47.304795  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119169 (* 1 = 0.0119169 loss)
I0626 07:30:47.304798  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0807076 (* 1 = 0.0807076 loss)
I0626 07:30:47.304803  4216 sgd_solver.cpp:106] Iteration 13440, lr = 0.0002
I0626 07:32:32.476704  4216 solver.cpp:228] Iteration 13460, loss = 0.29563
I0626 07:32:32.476729  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 07:32:32.476737  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0900714 (* 1 = 0.0900714 loss)
I0626 07:32:32.476740  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.162661 (* 1 = 0.162661 loss)
I0626 07:32:32.476744  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02209 (* 1 = 0.02209 loss)
I0626 07:32:32.476747  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0460649 (* 1 = 0.0460649 loss)
I0626 07:32:32.476752  4216 sgd_solver.cpp:106] Iteration 13460, lr = 0.0002
I0626 07:34:17.650223  4216 solver.cpp:228] Iteration 13480, loss = 0.253087
I0626 07:34:17.650249  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:34:17.650259  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0114761 (* 1 = 0.0114761 loss)
I0626 07:34:17.650265  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.048346 (* 1 = 0.048346 loss)
I0626 07:34:17.650272  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0021029 (* 1 = 0.0021029 loss)
I0626 07:34:17.650279  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00919373 (* 1 = 0.00919373 loss)
I0626 07:34:17.650287  4216 sgd_solver.cpp:106] Iteration 13480, lr = 0.0002
I0626 07:36:02.811317  4216 solver.cpp:228] Iteration 13500, loss = 0.266571
I0626 07:36:02.811344  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:36:02.811352  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.013524 (* 1 = 0.013524 loss)
I0626 07:36:02.811357  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0664278 (* 1 = 0.0664278 loss)
I0626 07:36:02.811360  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000517389 (* 1 = 0.000517389 loss)
I0626 07:36:02.811364  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159523 (* 1 = 0.0159523 loss)
I0626 07:36:02.811369  4216 sgd_solver.cpp:106] Iteration 13500, lr = 0.0002
I0626 07:37:47.931504  4216 solver.cpp:228] Iteration 13520, loss = 0.260221
I0626 07:37:47.931530  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:37:47.931537  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0575666 (* 1 = 0.0575666 loss)
I0626 07:37:47.931542  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0862841 (* 1 = 0.0862841 loss)
I0626 07:37:47.931546  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000551866 (* 1 = 0.000551866 loss)
I0626 07:37:47.931550  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00925677 (* 1 = 0.00925677 loss)
I0626 07:37:47.931555  4216 sgd_solver.cpp:106] Iteration 13520, lr = 0.0002
I0626 07:39:33.089198  4216 solver.cpp:228] Iteration 13540, loss = 0.237554
I0626 07:39:33.089231  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:39:33.089239  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.126633 (* 1 = 0.126633 loss)
I0626 07:39:33.089246  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.100283 (* 1 = 0.100283 loss)
I0626 07:39:33.089251  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191138 (* 1 = 0.00191138 loss)
I0626 07:39:33.089257  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143472 (* 1 = 0.0143472 loss)
I0626 07:39:33.089264  4216 sgd_solver.cpp:106] Iteration 13540, lr = 0.0002
I0626 07:41:18.283736  4216 solver.cpp:228] Iteration 13560, loss = 0.171749
I0626 07:41:18.283761  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:41:18.283768  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232946 (* 1 = 0.0232946 loss)
I0626 07:41:18.283773  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0325105 (* 1 = 0.0325105 loss)
I0626 07:41:18.283777  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000191519 (* 1 = 0.000191519 loss)
I0626 07:41:18.283782  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00367423 (* 1 = 0.00367423 loss)
I0626 07:41:18.283787  4216 sgd_solver.cpp:106] Iteration 13560, lr = 0.0002
I0626 07:43:03.497011  4216 solver.cpp:228] Iteration 13580, loss = 0.246753
I0626 07:43:03.497035  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:43:03.497043  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381494 (* 1 = 0.0381494 loss)
I0626 07:43:03.497048  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0752457 (* 1 = 0.0752457 loss)
I0626 07:43:03.497052  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019473 (* 1 = 0.019473 loss)
I0626 07:43:03.497056  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0463679 (* 1 = 0.0463679 loss)
I0626 07:43:03.497061  4216 sgd_solver.cpp:106] Iteration 13580, lr = 0.0002
speed: 5.244s / iter
I0626 07:44:48.682039  4216 solver.cpp:228] Iteration 13600, loss = 0.20486
I0626 07:44:48.682065  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 07:44:48.682072  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.110277 (* 1 = 0.110277 loss)
I0626 07:44:48.682076  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.201646 (* 1 = 0.201646 loss)
I0626 07:44:48.682080  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314754 (* 1 = 0.00314754 loss)
I0626 07:44:48.682085  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298206 (* 1 = 0.0298206 loss)
I0626 07:44:48.682090  4216 sgd_solver.cpp:106] Iteration 13600, lr = 0.0002
I0626 07:46:33.855077  4216 solver.cpp:228] Iteration 13620, loss = 0.267172
I0626 07:46:33.855103  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 07:46:33.855113  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.231599 (* 1 = 0.231599 loss)
I0626 07:46:33.855118  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.26091 (* 1 = 0.26091 loss)
I0626 07:46:33.855125  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00298883 (* 1 = 0.00298883 loss)
I0626 07:46:33.855131  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364756 (* 1 = 0.0364756 loss)
I0626 07:46:33.855139  4216 sgd_solver.cpp:106] Iteration 13620, lr = 0.0002
I0626 07:48:19.040992  4216 solver.cpp:228] Iteration 13640, loss = 0.18629
I0626 07:48:19.041019  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:48:19.041028  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0288431 (* 1 = 0.0288431 loss)
I0626 07:48:19.041034  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.069231 (* 1 = 0.069231 loss)
I0626 07:48:19.041039  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00900119 (* 1 = 0.00900119 loss)
I0626 07:48:19.041044  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148725 (* 1 = 0.0148725 loss)
I0626 07:48:19.041050  4216 sgd_solver.cpp:106] Iteration 13640, lr = 0.0002
I0626 07:50:04.228153  4216 solver.cpp:228] Iteration 13660, loss = 0.148152
I0626 07:50:04.228176  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 07:50:04.228184  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294297 (* 1 = 0.0294297 loss)
I0626 07:50:04.228188  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0703204 (* 1 = 0.0703204 loss)
I0626 07:50:04.228193  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00040056 (* 1 = 0.00040056 loss)
I0626 07:50:04.228195  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00524519 (* 1 = 0.00524519 loss)
I0626 07:50:04.228200  4216 sgd_solver.cpp:106] Iteration 13660, lr = 0.0002
I0626 07:51:49.429394  4216 solver.cpp:228] Iteration 13680, loss = 0.159653
I0626 07:51:49.429416  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 07:51:49.429425  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437508 (* 1 = 0.0437508 loss)
I0626 07:51:49.429428  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147315 (* 1 = 0.147315 loss)
I0626 07:51:49.429431  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00224741 (* 1 = 0.00224741 loss)
I0626 07:51:49.429435  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205325 (* 1 = 0.0205325 loss)
I0626 07:51:49.429440  4216 sgd_solver.cpp:106] Iteration 13680, lr = 0.0002
I0626 07:53:34.515556  4216 solver.cpp:228] Iteration 13700, loss = 0.21908
I0626 07:53:34.515581  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 07:53:34.515589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.198447 (* 1 = 0.198447 loss)
I0626 07:53:34.515594  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.223034 (* 1 = 0.223034 loss)
I0626 07:53:34.515597  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00548808 (* 1 = 0.00548808 loss)
I0626 07:53:34.515600  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0545378 (* 1 = 0.0545378 loss)
I0626 07:53:34.515605  4216 sgd_solver.cpp:106] Iteration 13700, lr = 0.0002
I0626 07:55:19.647465  4216 solver.cpp:228] Iteration 13720, loss = 0.180993
I0626 07:55:19.647491  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:55:19.647498  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0635546 (* 1 = 0.0635546 loss)
I0626 07:55:19.647502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.115589 (* 1 = 0.115589 loss)
I0626 07:55:19.647506  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179245 (* 1 = 0.00179245 loss)
I0626 07:55:19.647509  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00909185 (* 1 = 0.00909185 loss)
I0626 07:55:19.647514  4216 sgd_solver.cpp:106] Iteration 13720, lr = 0.0002
I0626 07:57:04.822549  4216 solver.cpp:228] Iteration 13740, loss = 0.397594
I0626 07:57:04.822571  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 07:57:04.822578  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000157705 (* 1 = 0.000157705 loss)
I0626 07:57:04.822582  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0560502 (* 1 = 0.0560502 loss)
I0626 07:57:04.822587  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100333 (* 1 = 0.0100333 loss)
I0626 07:57:04.822589  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173167 (* 1 = 0.0173167 loss)
I0626 07:57:04.822594  4216 sgd_solver.cpp:106] Iteration 13740, lr = 0.0002
I0626 07:58:49.941314  4216 solver.cpp:228] Iteration 13760, loss = 0.21568
I0626 07:58:49.941339  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:58:49.941346  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0300003 (* 1 = 0.0300003 loss)
I0626 07:58:49.941350  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0544142 (* 1 = 0.0544142 loss)
I0626 07:58:49.941354  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538971 (* 1 = 0.00538971 loss)
I0626 07:58:49.941357  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00696846 (* 1 = 0.00696846 loss)
I0626 07:58:49.941361  4216 sgd_solver.cpp:106] Iteration 13760, lr = 0.0002
I0626 08:00:35.071617  4216 solver.cpp:228] Iteration 13780, loss = 0.248177
I0626 08:00:35.071642  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 08:00:35.071650  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0723054 (* 1 = 0.0723054 loss)
I0626 08:00:35.071655  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.157912 (* 1 = 0.157912 loss)
I0626 08:00:35.071657  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616972 (* 1 = 0.00616972 loss)
I0626 08:00:35.071661  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155132 (* 1 = 0.0155132 loss)
I0626 08:00:35.071666  4216 sgd_solver.cpp:106] Iteration 13780, lr = 0.0002
speed: 5.244s / iter
I0626 08:02:20.221213  4216 solver.cpp:228] Iteration 13800, loss = 0.26948
I0626 08:02:20.221236  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:02:20.221243  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326415 (* 1 = 0.0326415 loss)
I0626 08:02:20.221248  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0578546 (* 1 = 0.0578546 loss)
I0626 08:02:20.221251  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107366 (* 1 = 0.00107366 loss)
I0626 08:02:20.221256  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0082326 (* 1 = 0.0082326 loss)
I0626 08:02:20.221259  4216 sgd_solver.cpp:106] Iteration 13800, lr = 0.0002
I0626 08:04:05.366466  4216 solver.cpp:228] Iteration 13820, loss = 0.228154
I0626 08:04:05.366493  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:04:05.366502  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.100225 (* 1 = 0.100225 loss)
I0626 08:04:05.366505  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109998 (* 1 = 0.109998 loss)
I0626 08:04:05.366510  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000276304 (* 1 = 0.000276304 loss)
I0626 08:04:05.366514  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00550474 (* 1 = 0.00550474 loss)
I0626 08:04:05.366519  4216 sgd_solver.cpp:106] Iteration 13820, lr = 0.0002
I0626 08:05:50.527931  4216 solver.cpp:228] Iteration 13840, loss = 0.228086
I0626 08:05:50.527961  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:05:50.527969  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485254 (* 1 = 0.0485254 loss)
I0626 08:05:50.527974  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0853837 (* 1 = 0.0853837 loss)
I0626 08:05:50.527979  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190163 (* 1 = 0.0190163 loss)
I0626 08:05:50.527984  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207232 (* 1 = 0.0207232 loss)
I0626 08:05:50.527990  4216 sgd_solver.cpp:106] Iteration 13840, lr = 0.0002
I0626 08:07:35.653976  4216 solver.cpp:228] Iteration 13860, loss = 0.192324
I0626 08:07:35.654003  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:07:35.654011  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00427438 (* 1 = 0.00427438 loss)
I0626 08:07:35.654016  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0258587 (* 1 = 0.0258587 loss)
I0626 08:07:35.654019  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00671789 (* 1 = 0.00671789 loss)
I0626 08:07:35.654024  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0399855 (* 1 = 0.0399855 loss)
I0626 08:07:35.654031  4216 sgd_solver.cpp:106] Iteration 13860, lr = 0.0002
I0626 08:09:20.683877  4216 solver.cpp:228] Iteration 13880, loss = 0.192865
I0626 08:09:20.683902  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 08:09:20.683908  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464582 (* 1 = 0.0464582 loss)
I0626 08:09:20.683912  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.154772 (* 1 = 0.154772 loss)
I0626 08:09:20.683917  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248395 (* 1 = 0.00248395 loss)
I0626 08:09:20.683919  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0376314 (* 1 = 0.0376314 loss)
I0626 08:09:20.683924  4216 sgd_solver.cpp:106] Iteration 13880, lr = 0.0002
I0626 08:11:05.863720  4216 solver.cpp:228] Iteration 13900, loss = 0.259302
I0626 08:11:05.863744  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 08:11:05.863751  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0754059 (* 1 = 0.0754059 loss)
I0626 08:11:05.863755  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.192295 (* 1 = 0.192295 loss)
I0626 08:11:05.863759  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0337731 (* 1 = 0.0337731 loss)
I0626 08:11:05.863762  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374974 (* 1 = 0.0374974 loss)
I0626 08:11:05.863766  4216 sgd_solver.cpp:106] Iteration 13900, lr = 0.0002
I0626 08:12:50.939703  4216 solver.cpp:228] Iteration 13920, loss = 0.247585
I0626 08:12:50.939728  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 08:12:50.939733  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.34859 (* 1 = 0.34859 loss)
I0626 08:12:50.939738  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.393046 (* 1 = 0.393046 loss)
I0626 08:12:50.939741  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165562 (* 1 = 0.0165562 loss)
I0626 08:12:50.939745  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.132794 (* 1 = 0.132794 loss)
I0626 08:12:50.939749  4216 sgd_solver.cpp:106] Iteration 13920, lr = 0.0002
I0626 08:14:36.011577  4216 solver.cpp:228] Iteration 13940, loss = 0.323766
I0626 08:14:36.011601  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:14:36.011610  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0565778 (* 1 = 0.0565778 loss)
I0626 08:14:36.011615  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0998834 (* 1 = 0.0998834 loss)
I0626 08:14:36.011618  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000527681 (* 1 = 0.000527681 loss)
I0626 08:14:36.011622  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174585 (* 1 = 0.0174585 loss)
I0626 08:14:36.011628  4216 sgd_solver.cpp:106] Iteration 13940, lr = 0.0002
I0626 08:16:21.035887  4216 solver.cpp:228] Iteration 13960, loss = 0.346652
I0626 08:16:21.035909  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 08:16:21.035917  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000645149 (* 1 = 0.000645149 loss)
I0626 08:16:21.035920  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.030785 (* 1 = 0.030785 loss)
I0626 08:16:21.035923  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106743 (* 1 = 0.00106743 loss)
I0626 08:16:21.035926  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173888 (* 1 = 0.0173888 loss)
I0626 08:16:21.035930  4216 sgd_solver.cpp:106] Iteration 13960, lr = 0.0002
I0626 08:18:06.174481  4216 solver.cpp:228] Iteration 13980, loss = 0.302658
I0626 08:18:06.174510  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 08:18:06.174516  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.171011 (* 1 = 0.171011 loss)
I0626 08:18:06.174520  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.205198 (* 1 = 0.205198 loss)
I0626 08:18:06.174525  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000553566 (* 1 = 0.000553566 loss)
I0626 08:18:06.174528  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0548042 (* 1 = 0.0548042 loss)
I0626 08:18:06.174533  4216 sgd_solver.cpp:106] Iteration 13980, lr = 0.0002
speed: 5.244s / iter
I0626 08:19:51.190045  4216 solver.cpp:228] Iteration 14000, loss = 0.343367
I0626 08:19:51.190070  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0626 08:19:51.190078  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.577928 (* 1 = 0.577928 loss)
I0626 08:19:51.190081  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.726608 (* 1 = 0.726608 loss)
I0626 08:19:51.190085  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0404131 (* 1 = 0.0404131 loss)
I0626 08:19:51.190088  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185802 (* 1 = 0.185802 loss)
I0626 08:19:51.190093  4216 sgd_solver.cpp:106] Iteration 14000, lr = 0.0002
I0626 08:21:36.157524  4216 solver.cpp:228] Iteration 14020, loss = 0.245109
I0626 08:21:36.157549  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:21:36.157557  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291149 (* 1 = 0.0291149 loss)
I0626 08:21:36.157559  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0671448 (* 1 = 0.0671448 loss)
I0626 08:21:36.157563  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00175432 (* 1 = 0.00175432 loss)
I0626 08:21:36.157567  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251083 (* 1 = 0.0251083 loss)
I0626 08:21:36.157572  4216 sgd_solver.cpp:106] Iteration 14020, lr = 0.0002
I0626 08:23:21.049139  4216 solver.cpp:228] Iteration 14040, loss = 0.278419
I0626 08:23:21.049163  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 08:23:21.049171  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356985 (* 1 = 0.0356985 loss)
I0626 08:23:21.049175  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0717749 (* 1 = 0.0717749 loss)
I0626 08:23:21.049178  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167512 (* 1 = 0.0167512 loss)
I0626 08:23:21.049182  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00814043 (* 1 = 0.00814043 loss)
I0626 08:23:21.049187  4216 sgd_solver.cpp:106] Iteration 14040, lr = 0.0002
I0626 08:25:06.186444  4216 solver.cpp:228] Iteration 14060, loss = 0.209872
I0626 08:25:06.186470  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:25:06.186477  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0422307 (* 1 = 0.0422307 loss)
I0626 08:25:06.186482  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0416154 (* 1 = 0.0416154 loss)
I0626 08:25:06.186486  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000387264 (* 1 = 0.000387264 loss)
I0626 08:25:06.186491  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00980557 (* 1 = 0.00980557 loss)
I0626 08:25:06.186496  4216 sgd_solver.cpp:106] Iteration 14060, lr = 0.0002
I0626 08:26:51.224800  4216 solver.cpp:228] Iteration 14080, loss = 0.427684
I0626 08:26:51.224828  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 08:26:51.224835  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.027135 (* 1 = 0.027135 loss)
I0626 08:26:51.224839  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0290965 (* 1 = 0.0290965 loss)
I0626 08:26:51.224843  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.35844e-05 (* 1 = 9.35844e-05 loss)
I0626 08:26:51.224846  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00271271 (* 1 = 0.00271271 loss)
I0626 08:26:51.224851  4216 sgd_solver.cpp:106] Iteration 14080, lr = 0.0002
I0626 08:28:36.180152  4216 solver.cpp:228] Iteration 14100, loss = 0.166449
I0626 08:28:36.180176  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 08:28:36.180183  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.067774 (* 1 = 0.067774 loss)
I0626 08:28:36.180187  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.174479 (* 1 = 0.174479 loss)
I0626 08:28:36.180191  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.022115 (* 1 = 0.022115 loss)
I0626 08:28:36.180194  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0493264 (* 1 = 0.0493264 loss)
I0626 08:28:36.180199  4216 sgd_solver.cpp:106] Iteration 14100, lr = 0.0002
I0626 08:30:21.242606  4216 solver.cpp:228] Iteration 14120, loss = 0.192115
I0626 08:30:21.242630  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:30:21.242637  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0848942 (* 1 = 0.0848942 loss)
I0626 08:30:21.242640  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.114348 (* 1 = 0.114348 loss)
I0626 08:30:21.242645  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133514 (* 1 = 0.0133514 loss)
I0626 08:30:21.242647  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103521 (* 1 = 0.0103521 loss)
I0626 08:30:21.242651  4216 sgd_solver.cpp:106] Iteration 14120, lr = 0.0002
I0626 08:32:06.205178  4216 solver.cpp:228] Iteration 14140, loss = 0.171251
I0626 08:32:06.205201  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:32:06.205207  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410228 (* 1 = 0.0410228 loss)
I0626 08:32:06.205211  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121295 (* 1 = 0.121295 loss)
I0626 08:32:06.205214  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134867 (* 1 = 0.0134867 loss)
I0626 08:32:06.205217  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237768 (* 1 = 0.0237768 loss)
I0626 08:32:06.205221  4216 sgd_solver.cpp:106] Iteration 14140, lr = 0.0002
I0626 08:33:51.283501  4216 solver.cpp:228] Iteration 14160, loss = 0.352944
I0626 08:33:51.283527  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:33:51.283535  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0653594 (* 1 = 0.0653594 loss)
I0626 08:33:51.283540  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.045045 (* 1 = 0.045045 loss)
I0626 08:33:51.283545  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00243626 (* 1 = 0.00243626 loss)
I0626 08:33:51.283548  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0018012 (* 1 = 0.0018012 loss)
I0626 08:33:51.283553  4216 sgd_solver.cpp:106] Iteration 14160, lr = 0.0002
I0626 08:35:36.369467  4216 solver.cpp:228] Iteration 14180, loss = 0.249428
I0626 08:35:36.369491  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:35:36.369498  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386063 (* 1 = 0.0386063 loss)
I0626 08:35:36.369503  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0727772 (* 1 = 0.0727772 loss)
I0626 08:35:36.369505  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000322808 (* 1 = 0.000322808 loss)
I0626 08:35:36.369509  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103894 (* 1 = 0.0103894 loss)
I0626 08:35:36.369514  4216 sgd_solver.cpp:106] Iteration 14180, lr = 0.0002
speed: 5.244s / iter
I0626 08:37:21.466187  4216 solver.cpp:228] Iteration 14200, loss = 0.597373
I0626 08:37:21.466209  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0626 08:37:21.466217  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.359567 (* 1 = 0.359567 loss)
I0626 08:37:21.466220  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.517098 (* 1 = 0.517098 loss)
I0626 08:37:21.466223  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318166 (* 1 = 0.00318166 loss)
I0626 08:37:21.466228  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0685612 (* 1 = 0.0685612 loss)
I0626 08:37:21.466231  4216 sgd_solver.cpp:106] Iteration 14200, lr = 0.0002
I0626 08:39:06.617141  4216 solver.cpp:228] Iteration 14220, loss = 0.213672
I0626 08:39:06.617166  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 08:39:06.617174  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.231586 (* 1 = 0.231586 loss)
I0626 08:39:06.617179  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.336871 (* 1 = 0.336871 loss)
I0626 08:39:06.617185  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00744655 (* 1 = 0.00744655 loss)
I0626 08:39:06.617192  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374739 (* 1 = 0.0374739 loss)
I0626 08:39:06.617197  4216 sgd_solver.cpp:106] Iteration 14220, lr = 0.0002
I0626 08:40:51.680059  4216 solver.cpp:228] Iteration 14240, loss = 0.201564
I0626 08:40:51.680083  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 08:40:51.680089  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000812523 (* 1 = 0.000812523 loss)
I0626 08:40:51.680094  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00962287 (* 1 = 0.00962287 loss)
I0626 08:40:51.680096  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105676 (* 1 = 0.00105676 loss)
I0626 08:40:51.680100  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134559 (* 1 = 0.0134559 loss)
I0626 08:40:51.680104  4216 sgd_solver.cpp:106] Iteration 14240, lr = 0.0002
I0626 08:42:36.826269  4216 solver.cpp:228] Iteration 14260, loss = 0.173628
I0626 08:42:36.826295  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:42:36.826304  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.114742 (* 1 = 0.114742 loss)
I0626 08:42:36.826308  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.11817 (* 1 = 0.11817 loss)
I0626 08:42:36.826313  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154165 (* 1 = 0.0154165 loss)
I0626 08:42:36.826316  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395759 (* 1 = 0.0395759 loss)
I0626 08:42:36.826321  4216 sgd_solver.cpp:106] Iteration 14260, lr = 0.0002
I0626 08:44:21.818975  4216 solver.cpp:228] Iteration 14280, loss = 0.183173
I0626 08:44:21.819001  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 08:44:21.819011  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0752108 (* 1 = 0.0752108 loss)
I0626 08:44:21.819018  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.157939 (* 1 = 0.157939 loss)
I0626 08:44:21.819025  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00774924 (* 1 = 0.00774924 loss)
I0626 08:44:21.819031  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00365527 (* 1 = 0.00365527 loss)
I0626 08:44:21.819037  4216 sgd_solver.cpp:106] Iteration 14280, lr = 0.0002
I0626 08:46:06.882445  4216 solver.cpp:228] Iteration 14300, loss = 0.297445
I0626 08:46:06.882470  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:46:06.882478  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.060625 (* 1 = 0.060625 loss)
I0626 08:46:06.882483  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.130194 (* 1 = 0.130194 loss)
I0626 08:46:06.882486  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00225421 (* 1 = 0.00225421 loss)
I0626 08:46:06.882490  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00892286 (* 1 = 0.00892286 loss)
I0626 08:46:06.882495  4216 sgd_solver.cpp:106] Iteration 14300, lr = 0.0002
I0626 08:47:51.930971  4216 solver.cpp:228] Iteration 14320, loss = 0.273788
I0626 08:47:51.930995  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 08:47:51.931002  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00129203 (* 1 = 0.00129203 loss)
I0626 08:47:51.931006  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0235849 (* 1 = 0.0235849 loss)
I0626 08:47:51.931010  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388185 (* 1 = 0.00388185 loss)
I0626 08:47:51.931015  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250235 (* 1 = 0.0250235 loss)
I0626 08:47:51.931018  4216 sgd_solver.cpp:106] Iteration 14320, lr = 0.0002
I0626 08:49:37.007369  4216 solver.cpp:228] Iteration 14340, loss = 0.368159
I0626 08:49:37.007395  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 08:49:37.007402  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.261864 (* 1 = 0.261864 loss)
I0626 08:49:37.007406  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.371005 (* 1 = 0.371005 loss)
I0626 08:49:37.007411  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139919 (* 1 = 0.00139919 loss)
I0626 08:49:37.007414  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316292 (* 1 = 0.0316292 loss)
I0626 08:49:37.007419  4216 sgd_solver.cpp:106] Iteration 14340, lr = 0.0002
I0626 08:51:22.043390  4216 solver.cpp:228] Iteration 14360, loss = 0.1901
I0626 08:51:22.043416  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 08:51:22.043424  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0672027 (* 1 = 0.0672027 loss)
I0626 08:51:22.043429  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.14827 (* 1 = 0.14827 loss)
I0626 08:51:22.043433  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00462258 (* 1 = 0.00462258 loss)
I0626 08:51:22.043437  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00983423 (* 1 = 0.00983423 loss)
I0626 08:51:22.043442  4216 sgd_solver.cpp:106] Iteration 14360, lr = 0.0002
I0626 08:53:07.038285  4216 solver.cpp:228] Iteration 14380, loss = 0.223368
I0626 08:53:07.038307  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 08:53:07.038314  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.15399 (* 1 = 0.15399 loss)
I0626 08:53:07.038317  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.234445 (* 1 = 0.234445 loss)
I0626 08:53:07.038321  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00374996 (* 1 = 0.00374996 loss)
I0626 08:53:07.038324  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274267 (* 1 = 0.0274267 loss)
I0626 08:53:07.038328  4216 sgd_solver.cpp:106] Iteration 14380, lr = 0.0002
speed: 5.244s / iter
I0626 08:54:52.118635  4216 solver.cpp:228] Iteration 14400, loss = 0.163122
I0626 08:54:52.118664  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:54:52.118669  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197698 (* 1 = 0.0197698 loss)
I0626 08:54:52.118674  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0578147 (* 1 = 0.0578147 loss)
I0626 08:54:52.118677  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000148342 (* 1 = 0.000148342 loss)
I0626 08:54:52.118680  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00963388 (* 1 = 0.00963388 loss)
I0626 08:54:52.118685  4216 sgd_solver.cpp:106] Iteration 14400, lr = 0.0002
I0626 08:56:37.004447  4216 solver.cpp:228] Iteration 14420, loss = 0.270435
I0626 08:56:37.004468  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:56:37.004475  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353427 (* 1 = 0.0353427 loss)
I0626 08:56:37.004479  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0516757 (* 1 = 0.0516757 loss)
I0626 08:56:37.004483  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110785 (* 1 = 0.00110785 loss)
I0626 08:56:37.004487  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00334329 (* 1 = 0.00334329 loss)
I0626 08:56:37.004490  4216 sgd_solver.cpp:106] Iteration 14420, lr = 0.0002
I0626 08:58:21.883559  4216 solver.cpp:228] Iteration 14440, loss = 0.196546
I0626 08:58:21.883581  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0626 08:58:21.883589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.289885 (* 1 = 0.289885 loss)
I0626 08:58:21.883591  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.452006 (* 1 = 0.452006 loss)
I0626 08:58:21.883595  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00958713 (* 1 = 0.00958713 loss)
I0626 08:58:21.883599  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112078 (* 1 = 0.112078 loss)
I0626 08:58:21.883602  4216 sgd_solver.cpp:106] Iteration 14440, lr = 0.0002
I0626 09:00:06.958302  4216 solver.cpp:228] Iteration 14460, loss = 0.145774
I0626 09:00:06.958328  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:00:06.958334  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248339 (* 1 = 0.0248339 loss)
I0626 09:00:06.958338  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0432988 (* 1 = 0.0432988 loss)
I0626 09:00:06.958343  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026007 (* 1 = 0.0026007 loss)
I0626 09:00:06.958346  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114482 (* 1 = 0.0114482 loss)
I0626 09:00:06.958350  4216 sgd_solver.cpp:106] Iteration 14460, lr = 0.0002
I0626 09:01:53.103109  4216 solver.cpp:228] Iteration 14480, loss = 0.360485
I0626 09:01:53.103133  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0626 09:01:53.103139  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.447266 (* 1 = 0.447266 loss)
I0626 09:01:53.103142  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.619311 (* 1 = 0.619311 loss)
I0626 09:01:53.103145  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147972 (* 1 = 0.0147972 loss)
I0626 09:01:53.103149  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.085806 (* 1 = 0.085806 loss)
I0626 09:01:53.103153  4216 sgd_solver.cpp:106] Iteration 14480, lr = 0.0002
I0626 09:03:41.935534  4216 solver.cpp:228] Iteration 14500, loss = 0.317811
I0626 09:03:41.935560  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:03:41.935570  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264415 (* 1 = 0.0264415 loss)
I0626 09:03:41.935577  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0740691 (* 1 = 0.0740691 loss)
I0626 09:03:41.935583  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000330674 (* 1 = 0.000330674 loss)
I0626 09:03:41.935590  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00484594 (* 1 = 0.00484594 loss)
I0626 09:03:41.935597  4216 sgd_solver.cpp:106] Iteration 14500, lr = 0.0002
I0626 09:05:29.736222  4216 solver.cpp:228] Iteration 14520, loss = 0.145841
I0626 09:05:29.736248  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:05:29.736253  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161391 (* 1 = 0.0161391 loss)
I0626 09:05:29.736258  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0462068 (* 1 = 0.0462068 loss)
I0626 09:05:29.736261  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000137875 (* 1 = 0.000137875 loss)
I0626 09:05:29.736264  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00248769 (* 1 = 0.00248769 loss)
I0626 09:05:29.736268  4216 sgd_solver.cpp:106] Iteration 14520, lr = 0.0002
I0626 09:07:17.119874  4216 solver.cpp:228] Iteration 14540, loss = 0.136763
I0626 09:07:17.119899  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 09:07:17.119905  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0532615 (* 1 = 0.0532615 loss)
I0626 09:07:17.119910  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.145479 (* 1 = 0.145479 loss)
I0626 09:07:17.119913  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0224361 (* 1 = 0.0224361 loss)
I0626 09:07:17.119916  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388615 (* 1 = 0.0388615 loss)
I0626 09:07:17.119921  4216 sgd_solver.cpp:106] Iteration 14540, lr = 0.0002
I0626 09:09:05.813098  4216 solver.cpp:228] Iteration 14560, loss = 0.340931
I0626 09:09:05.813127  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 09:09:05.813133  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.1421 (* 1 = 0.1421 loss)
I0626 09:09:05.813138  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.307628 (* 1 = 0.307628 loss)
I0626 09:09:05.813143  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204142 (* 1 = 0.00204142 loss)
I0626 09:09:05.813146  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019623 (* 1 = 0.019623 loss)
I0626 09:09:05.813151  4216 sgd_solver.cpp:106] Iteration 14560, lr = 0.0002
I0626 09:10:53.241106  4216 solver.cpp:228] Iteration 14580, loss = 0.29459
I0626 09:10:53.241132  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 09:10:53.241139  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.1344 (* 1 = 0.1344 loss)
I0626 09:10:53.241144  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.183725 (* 1 = 0.183725 loss)
I0626 09:10:53.241148  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00367757 (* 1 = 0.00367757 loss)
I0626 09:10:53.241153  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194449 (* 1 = 0.0194449 loss)
I0626 09:10:53.241158  4216 sgd_solver.cpp:106] Iteration 14580, lr = 0.0002
speed: 5.246s / iter
I0626 09:12:40.791885  4216 solver.cpp:228] Iteration 14600, loss = 0.422782
I0626 09:12:40.791911  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 09:12:40.791918  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708096 (* 1 = 0.0708096 loss)
I0626 09:12:40.791923  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.127469 (* 1 = 0.127469 loss)
I0626 09:12:40.791926  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880071 (* 1 = 0.00880071 loss)
I0626 09:12:40.791929  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232528 (* 1 = 0.0232528 loss)
I0626 09:12:40.791934  4216 sgd_solver.cpp:106] Iteration 14600, lr = 0.0002
I0626 09:14:29.247695  4216 solver.cpp:228] Iteration 14620, loss = 0.248671
I0626 09:14:29.247719  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 09:14:29.247725  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.103415 (* 1 = 0.103415 loss)
I0626 09:14:29.247730  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.169388 (* 1 = 0.169388 loss)
I0626 09:14:29.247733  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424574 (* 1 = 0.00424574 loss)
I0626 09:14:29.247736  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016713 (* 1 = 0.016713 loss)
I0626 09:14:29.247741  4216 sgd_solver.cpp:106] Iteration 14620, lr = 0.0002
I0626 09:16:16.606442  4216 solver.cpp:228] Iteration 14640, loss = 0.314769
I0626 09:16:16.606474  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 09:16:16.606483  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0616624 (* 1 = 0.0616624 loss)
I0626 09:16:16.606488  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0198724 (* 1 = 0.0198724 loss)
I0626 09:16:16.606493  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00932115 (* 1 = 0.00932115 loss)
I0626 09:16:16.606498  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00524985 (* 1 = 0.00524985 loss)
I0626 09:16:16.606504  4216 sgd_solver.cpp:106] Iteration 14640, lr = 0.0002
I0626 09:18:04.192106  4216 solver.cpp:228] Iteration 14660, loss = 0.152291
I0626 09:18:04.192136  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 09:18:04.192144  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00183623 (* 1 = 0.00183623 loss)
I0626 09:18:04.192148  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0686699 (* 1 = 0.0686699 loss)
I0626 09:18:04.192152  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00439695 (* 1 = 0.00439695 loss)
I0626 09:18:04.192157  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149714 (* 1 = 0.0149714 loss)
I0626 09:18:04.192163  4216 sgd_solver.cpp:106] Iteration 14660, lr = 0.0002
I0626 09:19:52.719336  4216 solver.cpp:228] Iteration 14680, loss = 0.230618
I0626 09:19:52.719359  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 09:19:52.719367  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0105786 (* 1 = 0.0105786 loss)
I0626 09:19:52.719370  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0169241 (* 1 = 0.0169241 loss)
I0626 09:19:52.719374  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000494132 (* 1 = 0.000494132 loss)
I0626 09:19:52.719378  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00535777 (* 1 = 0.00535777 loss)
I0626 09:19:52.719383  4216 sgd_solver.cpp:106] Iteration 14680, lr = 0.0002
I0626 09:21:39.997015  4216 solver.cpp:228] Iteration 14700, loss = 0.365583
I0626 09:21:39.997040  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0626 09:21:39.997045  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.291426 (* 1 = 0.291426 loss)
I0626 09:21:39.997050  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.532398 (* 1 = 0.532398 loss)
I0626 09:21:39.997053  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187774 (* 1 = 0.0187774 loss)
I0626 09:21:39.997056  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0958335 (* 1 = 0.0958335 loss)
I0626 09:21:39.997061  4216 sgd_solver.cpp:106] Iteration 14700, lr = 0.0002
I0626 09:23:25.723903  4216 solver.cpp:228] Iteration 14720, loss = 0.140486
I0626 09:23:25.723937  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:23:25.723947  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167521 (* 1 = 0.0167521 loss)
I0626 09:23:25.723953  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0646298 (* 1 = 0.0646298 loss)
I0626 09:23:25.723958  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000388124 (* 1 = 0.000388124 loss)
I0626 09:23:25.723964  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00296405 (* 1 = 0.00296405 loss)
I0626 09:23:25.724005  4216 sgd_solver.cpp:106] Iteration 14720, lr = 0.0002
I0626 09:25:13.280241  4216 solver.cpp:228] Iteration 14740, loss = 0.143845
I0626 09:25:13.280270  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:25:13.280278  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264146 (* 1 = 0.0264146 loss)
I0626 09:25:13.280283  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0437052 (* 1 = 0.0437052 loss)
I0626 09:25:13.280287  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122375 (* 1 = 0.00122375 loss)
I0626 09:25:13.280292  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00530009 (* 1 = 0.00530009 loss)
I0626 09:25:13.280298  4216 sgd_solver.cpp:106] Iteration 14740, lr = 0.0002
I0626 09:27:00.244880  4216 solver.cpp:228] Iteration 14760, loss = 0.145483
I0626 09:27:00.244906  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 09:27:00.244915  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121732 (* 1 = 0.121732 loss)
I0626 09:27:00.244920  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.208795 (* 1 = 0.208795 loss)
I0626 09:27:00.244925  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169935 (* 1 = 0.00169935 loss)
I0626 09:27:00.244931  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395825 (* 1 = 0.0395825 loss)
I0626 09:27:00.244956  4216 sgd_solver.cpp:106] Iteration 14760, lr = 0.0002
I0626 09:28:46.129789  4216 solver.cpp:228] Iteration 14780, loss = 0.273475
I0626 09:28:46.129817  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 09:28:46.129824  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.234328 (* 1 = 0.234328 loss)
I0626 09:28:46.129828  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.263235 (* 1 = 0.263235 loss)
I0626 09:28:46.129832  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000885677 (* 1 = 0.000885677 loss)
I0626 09:28:46.129835  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369869 (* 1 = 0.0369869 loss)
I0626 09:28:46.129842  4216 sgd_solver.cpp:106] Iteration 14780, lr = 0.0002
speed: 5.247s / iter
I0626 09:30:32.473858  4216 solver.cpp:228] Iteration 14800, loss = 0.20133
I0626 09:30:32.473886  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 09:30:32.473893  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0968738 (* 1 = 0.0968738 loss)
I0626 09:30:32.473897  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129686 (* 1 = 0.129686 loss)
I0626 09:30:32.473901  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000427267 (* 1 = 0.000427267 loss)
I0626 09:30:32.473906  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0079948 (* 1 = 0.0079948 loss)
I0626 09:30:32.473911  4216 sgd_solver.cpp:106] Iteration 14800, lr = 0.0002
I0626 09:32:19.839562  4216 solver.cpp:228] Iteration 14820, loss = 0.364361
I0626 09:32:19.839591  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:32:19.839601  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291886 (* 1 = 0.0291886 loss)
I0626 09:32:19.839604  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0714313 (* 1 = 0.0714313 loss)
I0626 09:32:19.839608  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000793428 (* 1 = 0.000793428 loss)
I0626 09:32:19.839612  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00564126 (* 1 = 0.00564126 loss)
I0626 09:32:19.839618  4216 sgd_solver.cpp:106] Iteration 14820, lr = 0.0002
I0626 09:34:06.905980  4216 solver.cpp:228] Iteration 14840, loss = 0.264709
I0626 09:34:06.906008  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:34:06.906015  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341779 (* 1 = 0.0341779 loss)
I0626 09:34:06.906021  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0559024 (* 1 = 0.0559024 loss)
I0626 09:34:06.906028  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00672447 (* 1 = 0.00672447 loss)
I0626 09:34:06.906031  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00267778 (* 1 = 0.00267778 loss)
I0626 09:34:06.906036  4216 sgd_solver.cpp:106] Iteration 14840, lr = 0.0002
I0626 09:35:52.059031  4216 solver.cpp:228] Iteration 14860, loss = 0.221146
I0626 09:35:52.059057  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:35:52.059065  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0644043 (* 1 = 0.0644043 loss)
I0626 09:35:52.059069  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0677219 (* 1 = 0.0677219 loss)
I0626 09:35:52.059073  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140733 (* 1 = 0.00140733 loss)
I0626 09:35:52.059077  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180102 (* 1 = 0.0180102 loss)
I0626 09:35:52.059082  4216 sgd_solver.cpp:106] Iteration 14860, lr = 0.0002
I0626 09:37:37.291106  4216 solver.cpp:228] Iteration 14880, loss = 0.469872
I0626 09:37:37.291134  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0626 09:37:37.291141  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.414456 (* 1 = 0.414456 loss)
I0626 09:37:37.291146  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.623402 (* 1 = 0.623402 loss)
I0626 09:37:37.291149  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.034004 (* 1 = 0.034004 loss)
I0626 09:37:37.291153  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.232111 (* 1 = 0.232111 loss)
I0626 09:37:37.291158  4216 sgd_solver.cpp:106] Iteration 14880, lr = 0.0002
I0626 09:39:23.785246  4216 solver.cpp:228] Iteration 14900, loss = 0.224908
I0626 09:39:23.785274  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:39:23.785280  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0489909 (* 1 = 0.0489909 loss)
I0626 09:39:23.785284  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0780138 (* 1 = 0.0780138 loss)
I0626 09:39:23.785289  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00967143 (* 1 = 0.00967143 loss)
I0626 09:39:23.785291  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00628809 (* 1 = 0.00628809 loss)
I0626 09:39:23.785296  4216 sgd_solver.cpp:106] Iteration 14900, lr = 0.0002
I0626 09:41:11.737695  4216 solver.cpp:228] Iteration 14920, loss = 0.174828
I0626 09:41:11.737720  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:41:11.737728  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178106 (* 1 = 0.0178106 loss)
I0626 09:41:11.737733  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0677748 (* 1 = 0.0677748 loss)
I0626 09:41:11.737737  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000674079 (* 1 = 0.000674079 loss)
I0626 09:41:11.737741  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00434251 (* 1 = 0.00434251 loss)
I0626 09:41:11.737746  4216 sgd_solver.cpp:106] Iteration 14920, lr = 0.0002
I0626 09:42:56.997283  4216 solver.cpp:228] Iteration 14940, loss = 0.217623
I0626 09:42:56.997308  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 09:42:56.997313  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0357121 (* 1 = 0.0357121 loss)
I0626 09:42:56.997318  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0754325 (* 1 = 0.0754325 loss)
I0626 09:42:56.997320  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116481 (* 1 = 0.00116481 loss)
I0626 09:42:56.997323  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00946418 (* 1 = 0.00946418 loss)
I0626 09:42:56.997328  4216 sgd_solver.cpp:106] Iteration 14940, lr = 0.0002
I0626 09:44:43.800799  4216 solver.cpp:228] Iteration 14960, loss = 0.210943
I0626 09:44:43.800830  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:44:43.800837  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144262 (* 1 = 0.0144262 loss)
I0626 09:44:43.800843  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0646353 (* 1 = 0.0646353 loss)
I0626 09:44:43.800850  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000473087 (* 1 = 0.000473087 loss)
I0626 09:44:43.800854  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00912032 (* 1 = 0.00912032 loss)
I0626 09:44:43.800861  4216 sgd_solver.cpp:106] Iteration 14960, lr = 0.0002
I0626 09:46:31.139221  4216 solver.cpp:228] Iteration 14980, loss = 0.309378
I0626 09:46:31.139250  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:46:31.139259  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.037231 (* 1 = 0.037231 loss)
I0626 09:46:31.139266  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0771758 (* 1 = 0.0771758 loss)
I0626 09:46:31.139271  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00789871 (* 1 = 0.00789871 loss)
I0626 09:46:31.139276  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00717312 (* 1 = 0.00717312 loss)
I0626 09:46:31.139283  4216 sgd_solver.cpp:106] Iteration 14980, lr = 0.0002
speed: 5.248s / iter
I0626 09:48:14.234259  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_15000.caffemodel
I0626 09:48:19.992266  4216 solver.cpp:228] Iteration 15000, loss = 0.310346
I0626 09:48:19.992293  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 09:48:19.992301  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.170427 (* 1 = 0.170427 loss)
I0626 09:48:19.992306  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.221326 (* 1 = 0.221326 loss)
I0626 09:48:19.992311  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0353616 (* 1 = 0.0353616 loss)
I0626 09:48:19.992313  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0835656 (* 1 = 0.0835656 loss)
I0626 09:48:19.992321  4216 sgd_solver.cpp:106] Iteration 15000, lr = 0.0002
I0626 09:50:08.554833  4216 solver.cpp:228] Iteration 15020, loss = 0.338169
I0626 09:50:08.554863  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:50:08.554870  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486084 (* 1 = 0.0486084 loss)
I0626 09:50:08.554874  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0528087 (* 1 = 0.0528087 loss)
I0626 09:50:08.554878  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00856058 (* 1 = 0.00856058 loss)
I0626 09:50:08.554882  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00200308 (* 1 = 0.00200308 loss)
I0626 09:50:08.554886  4216 sgd_solver.cpp:106] Iteration 15020, lr = 0.0002
I0626 09:51:57.664815  4216 solver.cpp:228] Iteration 15040, loss = 0.13362
I0626 09:51:57.664841  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:51:57.664849  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207808 (* 1 = 0.0207808 loss)
I0626 09:51:57.664854  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0490376 (* 1 = 0.0490376 loss)
I0626 09:51:57.664857  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000504058 (* 1 = 0.000504058 loss)
I0626 09:51:57.664860  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00500199 (* 1 = 0.00500199 loss)
I0626 09:51:57.664865  4216 sgd_solver.cpp:106] Iteration 15040, lr = 0.0002
I0626 09:53:45.227772  4216 solver.cpp:228] Iteration 15060, loss = 0.288366
I0626 09:53:45.227798  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 09:53:45.227807  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.139724 (* 1 = 0.139724 loss)
I0626 09:53:45.227811  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.253216 (* 1 = 0.253216 loss)
I0626 09:53:45.227818  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112857 (* 1 = 0.0112857 loss)
I0626 09:53:45.227823  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214003 (* 1 = 0.0214003 loss)
I0626 09:53:45.227828  4216 sgd_solver.cpp:106] Iteration 15060, lr = 0.0002
I0626 09:55:31.165032  4216 solver.cpp:228] Iteration 15080, loss = 0.165961
I0626 09:55:31.165060  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 09:55:31.165068  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0008813 (* 1 = 0.0008813 loss)
I0626 09:55:31.165073  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0274401 (* 1 = 0.0274401 loss)
I0626 09:55:31.165078  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00448693 (* 1 = 0.00448693 loss)
I0626 09:55:31.165083  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018011 (* 1 = 0.018011 loss)
I0626 09:55:31.165088  4216 sgd_solver.cpp:106] Iteration 15080, lr = 0.0002
I0626 09:57:18.280275  4216 solver.cpp:228] Iteration 15100, loss = 0.212862
I0626 09:57:18.280302  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 09:57:18.280309  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.041505 (* 1 = 0.041505 loss)
I0626 09:57:18.280314  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0889231 (* 1 = 0.0889231 loss)
I0626 09:57:18.280318  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00252202 (* 1 = 0.00252202 loss)
I0626 09:57:18.280323  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00531612 (* 1 = 0.00531612 loss)
I0626 09:57:18.280328  4216 sgd_solver.cpp:106] Iteration 15100, lr = 0.0002
I0626 09:59:03.790227  4216 solver.cpp:228] Iteration 15120, loss = 0.241271
I0626 09:59:03.790249  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 09:59:03.790256  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.052161 (* 1 = 0.052161 loss)
I0626 09:59:03.790261  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119392 (* 1 = 0.119392 loss)
I0626 09:59:03.790264  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000896087 (* 1 = 0.000896087 loss)
I0626 09:59:03.790267  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113043 (* 1 = 0.0113043 loss)
I0626 09:59:03.790272  4216 sgd_solver.cpp:106] Iteration 15120, lr = 0.0002
I0626 10:00:48.981431  4216 solver.cpp:228] Iteration 15140, loss = 0.11418
I0626 10:00:48.981456  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:00:48.981464  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0427751 (* 1 = 0.0427751 loss)
I0626 10:00:48.981468  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.05237 (* 1 = 0.05237 loss)
I0626 10:00:48.981472  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000503172 (* 1 = 0.000503172 loss)
I0626 10:00:48.981477  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00827787 (* 1 = 0.00827787 loss)
I0626 10:00:48.981482  4216 sgd_solver.cpp:106] Iteration 15140, lr = 0.0002
I0626 10:02:34.124399  4216 solver.cpp:228] Iteration 15160, loss = 0.204624
I0626 10:02:34.124423  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 10:02:34.124429  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0730944 (* 1 = 0.0730944 loss)
I0626 10:02:34.124433  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.158456 (* 1 = 0.158456 loss)
I0626 10:02:34.124436  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000463846 (* 1 = 0.000463846 loss)
I0626 10:02:34.124439  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239957 (* 1 = 0.0239957 loss)
I0626 10:02:34.124444  4216 sgd_solver.cpp:106] Iteration 15160, lr = 0.0002
I0626 10:04:19.271198  4216 solver.cpp:228] Iteration 15180, loss = 0.258342
I0626 10:04:19.271225  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 10:04:19.271234  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.214381 (* 1 = 0.214381 loss)
I0626 10:04:19.271239  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.377281 (* 1 = 0.377281 loss)
I0626 10:04:19.271242  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023635 (* 1 = 0.0023635 loss)
I0626 10:04:19.271245  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031952 (* 1 = 0.031952 loss)
I0626 10:04:19.271250  4216 sgd_solver.cpp:106] Iteration 15180, lr = 0.0002
speed: 5.249s / iter
I0626 10:06:05.010768  4216 solver.cpp:228] Iteration 15200, loss = 0.225778
I0626 10:06:05.010799  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:06:05.010808  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0626947 (* 1 = 0.0626947 loss)
I0626 10:06:05.010813  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0719263 (* 1 = 0.0719263 loss)
I0626 10:06:05.010818  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330457 (* 1 = 0.00330457 loss)
I0626 10:06:05.010823  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00286558 (* 1 = 0.00286558 loss)
I0626 10:06:05.010829  4216 sgd_solver.cpp:106] Iteration 15200, lr = 0.0002
I0626 10:07:52.336086  4216 solver.cpp:228] Iteration 15220, loss = 0.157046
I0626 10:07:52.336113  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 10:07:52.336123  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150275 (* 1 = 0.0150275 loss)
I0626 10:07:52.336128  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0269576 (* 1 = 0.0269576 loss)
I0626 10:07:52.336133  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000643774 (* 1 = 0.000643774 loss)
I0626 10:07:52.336138  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178865 (* 1 = 0.0178865 loss)
I0626 10:07:52.336143  4216 sgd_solver.cpp:106] Iteration 15220, lr = 0.0002
I0626 10:09:40.243866  4216 solver.cpp:228] Iteration 15240, loss = 0.424113
I0626 10:09:40.243891  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:09:40.243898  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128396 (* 1 = 0.0128396 loss)
I0626 10:09:40.243902  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0732938 (* 1 = 0.0732938 loss)
I0626 10:09:40.243906  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104392 (* 1 = 0.00104392 loss)
I0626 10:09:40.243909  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00149143 (* 1 = 0.00149143 loss)
I0626 10:09:40.243914  4216 sgd_solver.cpp:106] Iteration 15240, lr = 0.0002
I0626 10:11:27.916177  4216 solver.cpp:228] Iteration 15260, loss = 0.228845
I0626 10:11:27.916200  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:11:27.916208  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236604 (* 1 = 0.0236604 loss)
I0626 10:11:27.916211  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0533659 (* 1 = 0.0533659 loss)
I0626 10:11:27.916215  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00696401 (* 1 = 0.00696401 loss)
I0626 10:11:27.916219  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00390883 (* 1 = 0.00390883 loss)
I0626 10:11:27.916224  4216 sgd_solver.cpp:106] Iteration 15260, lr = 0.0002
I0626 10:13:32.819980  4216 solver.cpp:228] Iteration 15280, loss = 0.145708
I0626 10:13:32.820004  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:13:32.820011  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201151 (* 1 = 0.0201151 loss)
I0626 10:13:32.820015  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0259049 (* 1 = 0.0259049 loss)
I0626 10:13:32.820019  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215887 (* 1 = 0.00215887 loss)
I0626 10:13:32.820024  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144328 (* 1 = 0.0144328 loss)
I0626 10:13:32.820027  4216 sgd_solver.cpp:106] Iteration 15280, lr = 0.0002
I0626 10:15:20.509481  4216 solver.cpp:228] Iteration 15300, loss = 0.288823
I0626 10:15:20.509510  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:15:20.509521  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126476 (* 1 = 0.0126476 loss)
I0626 10:15:20.509526  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0245469 (* 1 = 0.0245469 loss)
I0626 10:15:20.509533  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00146489 (* 1 = 0.00146489 loss)
I0626 10:15:20.509539  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00561759 (* 1 = 0.00561759 loss)
I0626 10:15:20.509549  4216 sgd_solver.cpp:106] Iteration 15300, lr = 0.0002
I0626 10:17:07.881366  4216 solver.cpp:228] Iteration 15320, loss = 0.223271
I0626 10:17:07.881394  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:17:07.881407  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385779 (* 1 = 0.0385779 loss)
I0626 10:17:07.881414  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118577 (* 1 = 0.118577 loss)
I0626 10:17:07.881422  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00386748 (* 1 = 0.00386748 loss)
I0626 10:17:07.881429  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00861146 (* 1 = 0.00861146 loss)
I0626 10:17:07.881438  4216 sgd_solver.cpp:106] Iteration 15320, lr = 0.0002
I0626 10:18:56.701050  4216 solver.cpp:228] Iteration 15340, loss = 0.216906
I0626 10:18:56.701076  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 10:18:56.701084  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.225721 (* 1 = 0.225721 loss)
I0626 10:18:56.701088  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.306831 (* 1 = 0.306831 loss)
I0626 10:18:56.701093  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00188667 (* 1 = 0.00188667 loss)
I0626 10:18:56.701097  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0423669 (* 1 = 0.0423669 loss)
I0626 10:18:56.701102  4216 sgd_solver.cpp:106] Iteration 15340, lr = 0.0002
I0626 10:20:43.560710  4216 solver.cpp:228] Iteration 15360, loss = 0.139208
I0626 10:20:43.560734  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 10:20:43.560741  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203001 (* 1 = 0.0203001 loss)
I0626 10:20:43.560745  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0217564 (* 1 = 0.0217564 loss)
I0626 10:20:43.560750  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.81353e-05 (* 1 = 7.81353e-05 loss)
I0626 10:20:43.560753  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322111 (* 1 = 0.00322111 loss)
I0626 10:20:43.560757  4216 sgd_solver.cpp:106] Iteration 15360, lr = 0.0002
I0626 10:22:28.922358  4216 solver.cpp:228] Iteration 15380, loss = 0.24512
I0626 10:22:28.922385  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 10:22:28.922395  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.112708 (* 1 = 0.112708 loss)
I0626 10:22:28.922402  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.120547 (* 1 = 0.120547 loss)
I0626 10:22:28.922408  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000839122 (* 1 = 0.000839122 loss)
I0626 10:22:28.922415  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165598 (* 1 = 0.0165598 loss)
I0626 10:22:28.922422  4216 sgd_solver.cpp:106] Iteration 15380, lr = 0.0002
speed: 5.252s / iter
I0626 10:24:14.994026  4216 solver.cpp:228] Iteration 15400, loss = 0.30005
I0626 10:24:14.994055  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 10:24:14.994065  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521237 (* 1 = 0.0521237 loss)
I0626 10:24:14.994069  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129742 (* 1 = 0.129742 loss)
I0626 10:24:14.994074  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.67523e-05 (* 1 = 8.67523e-05 loss)
I0626 10:24:14.994081  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00937214 (* 1 = 0.00937214 loss)
I0626 10:24:14.994086  4216 sgd_solver.cpp:106] Iteration 15400, lr = 0.0002
I0626 10:26:00.286460  4216 solver.cpp:228] Iteration 15420, loss = 0.296561
I0626 10:26:00.286485  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 10:26:00.286492  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00486043 (* 1 = 0.00486043 loss)
I0626 10:26:00.286496  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0134525 (* 1 = 0.0134525 loss)
I0626 10:26:00.286500  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00650522 (* 1 = 0.00650522 loss)
I0626 10:26:00.286504  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00434657 (* 1 = 0.00434657 loss)
I0626 10:26:00.286509  4216 sgd_solver.cpp:106] Iteration 15420, lr = 0.0002
I0626 10:27:45.566432  4216 solver.cpp:228] Iteration 15440, loss = 0.275069
I0626 10:27:45.566458  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:27:45.566465  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0456008 (* 1 = 0.0456008 loss)
I0626 10:27:45.566469  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0706697 (* 1 = 0.0706697 loss)
I0626 10:27:45.566473  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00967742 (* 1 = 0.00967742 loss)
I0626 10:27:45.566478  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0071171 (* 1 = 0.0071171 loss)
I0626 10:27:45.566481  4216 sgd_solver.cpp:106] Iteration 15440, lr = 0.0002
I0626 10:29:32.016481  4216 solver.cpp:228] Iteration 15460, loss = 0.302387
I0626 10:29:32.016508  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:29:32.016516  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310291 (* 1 = 0.0310291 loss)
I0626 10:29:32.016521  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.052242 (* 1 = 0.052242 loss)
I0626 10:29:32.016525  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000911168 (* 1 = 0.000911168 loss)
I0626 10:29:32.016530  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139854 (* 1 = 0.0139854 loss)
I0626 10:29:32.016535  4216 sgd_solver.cpp:106] Iteration 15460, lr = 0.0002
I0626 10:31:19.468973  4216 solver.cpp:228] Iteration 15480, loss = 0.267233
I0626 10:31:19.469008  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:31:19.469017  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0280935 (* 1 = 0.0280935 loss)
I0626 10:31:19.469022  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0904008 (* 1 = 0.0904008 loss)
I0626 10:31:19.469025  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109759 (* 1 = 0.0109759 loss)
I0626 10:31:19.469029  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197451 (* 1 = 0.0197451 loss)
I0626 10:31:19.469035  4216 sgd_solver.cpp:106] Iteration 15480, lr = 0.0002
I0626 10:33:06.876809  4216 solver.cpp:228] Iteration 15500, loss = 0.324222
I0626 10:33:06.876845  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:33:06.876855  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0815102 (* 1 = 0.0815102 loss)
I0626 10:33:06.876863  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0927061 (* 1 = 0.0927061 loss)
I0626 10:33:06.876869  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162532 (* 1 = 0.00162532 loss)
I0626 10:33:06.876875  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353227 (* 1 = 0.0353227 loss)
I0626 10:33:06.876883  4216 sgd_solver.cpp:106] Iteration 15500, lr = 0.0002
I0626 10:34:53.830842  4216 solver.cpp:228] Iteration 15520, loss = 0.256066
I0626 10:34:53.830878  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:34:53.830889  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0221537 (* 1 = 0.0221537 loss)
I0626 10:34:53.830896  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0775278 (* 1 = 0.0775278 loss)
I0626 10:34:53.830902  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00580213 (* 1 = 0.00580213 loss)
I0626 10:34:53.830909  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272041 (* 1 = 0.0272041 loss)
I0626 10:34:53.830917  4216 sgd_solver.cpp:106] Iteration 15520, lr = 0.0002
I0626 10:36:40.701787  4216 solver.cpp:228] Iteration 15540, loss = 0.354635
I0626 10:36:40.701822  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 10:36:40.701828  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0988032 (* 1 = 0.0988032 loss)
I0626 10:36:40.701833  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.159279 (* 1 = 0.159279 loss)
I0626 10:36:40.701838  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000528754 (* 1 = 0.000528754 loss)
I0626 10:36:40.701840  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184293 (* 1 = 0.0184293 loss)
I0626 10:36:40.701846  4216 sgd_solver.cpp:106] Iteration 15540, lr = 0.0002
I0626 10:38:27.722295  4216 solver.cpp:228] Iteration 15560, loss = 0.194632
I0626 10:38:27.722378  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 10:38:27.722400  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0507528 (* 1 = 0.0507528 loss)
I0626 10:38:27.722419  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.132978 (* 1 = 0.132978 loss)
I0626 10:38:27.722440  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00695245 (* 1 = 0.00695245 loss)
I0626 10:38:27.722456  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126117 (* 1 = 0.0126117 loss)
I0626 10:38:27.722473  4216 sgd_solver.cpp:106] Iteration 15560, lr = 0.0002
I0626 10:40:15.679698  4216 solver.cpp:228] Iteration 15580, loss = 0.16129
I0626 10:40:15.679731  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:40:15.679739  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168874 (* 1 = 0.0168874 loss)
I0626 10:40:15.679744  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0278845 (* 1 = 0.0278845 loss)
I0626 10:40:15.679749  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000150935 (* 1 = 0.000150935 loss)
I0626 10:40:15.679754  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00273367 (* 1 = 0.00273367 loss)
I0626 10:40:15.679759  4216 sgd_solver.cpp:106] Iteration 15580, lr = 0.0002
speed: 5.253s / iter
I0626 10:42:05.382275  4216 solver.cpp:228] Iteration 15600, loss = 0.250645
I0626 10:42:05.382306  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 10:42:05.382316  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.127449 (* 1 = 0.127449 loss)
I0626 10:42:05.382323  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.152777 (* 1 = 0.152777 loss)
I0626 10:42:05.382329  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015214 (* 1 = 0.0015214 loss)
I0626 10:42:05.382336  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154645 (* 1 = 0.0154645 loss)
I0626 10:42:05.382345  4216 sgd_solver.cpp:106] Iteration 15600, lr = 0.0002
I0626 10:43:52.074992  4216 solver.cpp:228] Iteration 15620, loss = 0.272174
I0626 10:43:52.075017  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 10:43:52.075026  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.258941 (* 1 = 0.258941 loss)
I0626 10:43:52.075029  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.461893 (* 1 = 0.461893 loss)
I0626 10:43:52.075032  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.005122 (* 1 = 0.005122 loss)
I0626 10:43:52.075037  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0608255 (* 1 = 0.0608255 loss)
I0626 10:43:52.075042  4216 sgd_solver.cpp:106] Iteration 15620, lr = 0.0002
I0626 10:45:39.191716  4216 solver.cpp:228] Iteration 15640, loss = 0.304939
I0626 10:45:39.191741  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 10:45:39.191748  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.202148 (* 1 = 0.202148 loss)
I0626 10:45:39.191753  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.270351 (* 1 = 0.270351 loss)
I0626 10:45:39.191756  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00684186 (* 1 = 0.00684186 loss)
I0626 10:45:39.191761  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374885 (* 1 = 0.0374885 loss)
I0626 10:45:39.191764  4216 sgd_solver.cpp:106] Iteration 15640, lr = 0.0002
I0626 10:47:26.224020  4216 solver.cpp:228] Iteration 15660, loss = 0.154969
I0626 10:47:26.224048  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 10:47:26.224056  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.160947 (* 1 = 0.160947 loss)
I0626 10:47:26.224061  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.250619 (* 1 = 0.250619 loss)
I0626 10:47:26.224066  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013285 (* 1 = 0.0013285 loss)
I0626 10:47:26.224069  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0279145 (* 1 = 0.0279145 loss)
I0626 10:47:26.224076  4216 sgd_solver.cpp:106] Iteration 15660, lr = 0.0002
I0626 10:49:13.354688  4216 solver.cpp:228] Iteration 15680, loss = 0.0796279
I0626 10:49:13.354714  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:49:13.354722  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0130857 (* 1 = 0.0130857 loss)
I0626 10:49:13.354725  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0467184 (* 1 = 0.0467184 loss)
I0626 10:49:13.354728  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281181 (* 1 = 0.00281181 loss)
I0626 10:49:13.354732  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00919518 (* 1 = 0.00919518 loss)
I0626 10:49:13.354737  4216 sgd_solver.cpp:106] Iteration 15680, lr = 0.0002
I0626 10:51:00.719673  4216 solver.cpp:228] Iteration 15700, loss = 0.193875
I0626 10:51:00.719745  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:51:00.719764  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0290727 (* 1 = 0.0290727 loss)
I0626 10:51:00.719779  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0826279 (* 1 = 0.0826279 loss)
I0626 10:51:00.719790  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121101 (* 1 = 0.00121101 loss)
I0626 10:51:00.719802  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143623 (* 1 = 0.0143623 loss)
I0626 10:51:00.719815  4216 sgd_solver.cpp:106] Iteration 15700, lr = 0.0002
I0626 10:52:48.113909  4216 solver.cpp:228] Iteration 15720, loss = 0.251469
I0626 10:52:48.113936  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 10:52:48.113945  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000753129 (* 1 = 0.000753129 loss)
I0626 10:52:48.113950  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0293253 (* 1 = 0.0293253 loss)
I0626 10:52:48.113953  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151709 (* 1 = 0.0151709 loss)
I0626 10:52:48.113957  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157019 (* 1 = 0.0157019 loss)
I0626 10:52:48.113962  4216 sgd_solver.cpp:106] Iteration 15720, lr = 0.0002
I0626 10:54:34.068997  4216 solver.cpp:228] Iteration 15740, loss = 0.194085
I0626 10:54:34.069025  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:54:34.069033  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0302943 (* 1 = 0.0302943 loss)
I0626 10:54:34.069038  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0738459 (* 1 = 0.0738459 loss)
I0626 10:54:34.069042  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000628642 (* 1 = 0.000628642 loss)
I0626 10:54:34.069047  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00494195 (* 1 = 0.00494195 loss)
I0626 10:54:34.069053  4216 sgd_solver.cpp:106] Iteration 15740, lr = 0.0002
I0626 10:56:21.439916  4216 solver.cpp:228] Iteration 15760, loss = 0.224455
I0626 10:56:21.439942  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 10:56:21.439950  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.103566 (* 1 = 0.103566 loss)
I0626 10:56:21.439954  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.228323 (* 1 = 0.228323 loss)
I0626 10:56:21.439959  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174367 (* 1 = 0.0174367 loss)
I0626 10:56:21.439962  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0809602 (* 1 = 0.0809602 loss)
I0626 10:56:21.439968  4216 sgd_solver.cpp:106] Iteration 15760, lr = 0.0002
I0626 10:58:08.607671  4216 solver.cpp:228] Iteration 15780, loss = 0.121678
I0626 10:58:08.607697  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:58:08.607703  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0395245 (* 1 = 0.0395245 loss)
I0626 10:58:08.607707  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0438894 (* 1 = 0.0438894 loss)
I0626 10:58:08.607712  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000754344 (* 1 = 0.000754344 loss)
I0626 10:58:08.607715  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00234983 (* 1 = 0.00234983 loss)
I0626 10:58:08.607719  4216 sgd_solver.cpp:106] Iteration 15780, lr = 0.0002
speed: 5.255s / iter
I0626 10:59:56.450105  4216 solver.cpp:228] Iteration 15800, loss = 0.228739
I0626 10:59:56.450134  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 10:59:56.450141  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.379723 (* 1 = 0.379723 loss)
I0626 10:59:56.450146  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.421907 (* 1 = 0.421907 loss)
I0626 10:59:56.450150  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147761 (* 1 = 0.00147761 loss)
I0626 10:59:56.450155  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0882601 (* 1 = 0.0882601 loss)
I0626 10:59:56.450161  4216 sgd_solver.cpp:106] Iteration 15800, lr = 0.0002
I0626 11:01:44.229177  4216 solver.cpp:228] Iteration 15820, loss = 0.315312
I0626 11:01:44.229207  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:01:44.229214  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.184089 (* 1 = 0.184089 loss)
I0626 11:01:44.229219  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147177 (* 1 = 0.147177 loss)
I0626 11:01:44.229223  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00368045 (* 1 = 0.00368045 loss)
I0626 11:01:44.229228  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149814 (* 1 = 0.0149814 loss)
I0626 11:01:44.229233  4216 sgd_solver.cpp:106] Iteration 15820, lr = 0.0002
I0626 11:03:31.719475  4216 solver.cpp:228] Iteration 15840, loss = 0.326696
I0626 11:03:31.719506  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 11:03:31.719516  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.176235 (* 1 = 0.176235 loss)
I0626 11:03:31.719523  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.309448 (* 1 = 0.309448 loss)
I0626 11:03:31.719529  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266543 (* 1 = 0.00266543 loss)
I0626 11:03:31.719537  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.078058 (* 1 = 0.078058 loss)
I0626 11:03:31.719543  4216 sgd_solver.cpp:106] Iteration 15840, lr = 0.0002
I0626 11:05:20.145994  4216 solver.cpp:228] Iteration 15860, loss = 0.10493
I0626 11:05:20.146020  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:05:20.146028  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.018289 (* 1 = 0.018289 loss)
I0626 11:05:20.146031  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0576199 (* 1 = 0.0576199 loss)
I0626 11:05:20.146035  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00451906 (* 1 = 0.00451906 loss)
I0626 11:05:20.146039  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00808731 (* 1 = 0.00808731 loss)
I0626 11:05:20.146044  4216 sgd_solver.cpp:106] Iteration 15860, lr = 0.0002
I0626 11:07:07.556931  4216 solver.cpp:228] Iteration 15880, loss = 0.397202
I0626 11:07:07.556957  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:07:07.556965  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195608 (* 1 = 0.0195608 loss)
I0626 11:07:07.556970  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0372414 (* 1 = 0.0372414 loss)
I0626 11:07:07.556974  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000182643 (* 1 = 0.000182643 loss)
I0626 11:07:07.556978  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00887132 (* 1 = 0.00887132 loss)
I0626 11:07:07.556983  4216 sgd_solver.cpp:106] Iteration 15880, lr = 0.0002
I0626 11:08:54.949059  4216 solver.cpp:228] Iteration 15900, loss = 0.157786
I0626 11:08:54.949090  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:08:54.949098  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247828 (* 1 = 0.0247828 loss)
I0626 11:08:54.949105  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0436773 (* 1 = 0.0436773 loss)
I0626 11:08:54.949110  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00322713 (* 1 = 0.00322713 loss)
I0626 11:08:54.949113  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00250754 (* 1 = 0.00250754 loss)
I0626 11:08:54.949120  4216 sgd_solver.cpp:106] Iteration 15900, lr = 0.0002
I0626 11:10:42.300894  4216 solver.cpp:228] Iteration 15920, loss = 0.231544
I0626 11:10:42.300920  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:10:42.300928  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256404 (* 1 = 0.0256404 loss)
I0626 11:10:42.300933  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0361013 (* 1 = 0.0361013 loss)
I0626 11:10:42.300937  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00983702 (* 1 = 0.00983702 loss)
I0626 11:10:42.300941  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00770639 (* 1 = 0.00770639 loss)
I0626 11:10:42.300946  4216 sgd_solver.cpp:106] Iteration 15920, lr = 0.0002
I0626 11:12:30.433826  4216 solver.cpp:228] Iteration 15940, loss = 0.220144
I0626 11:12:30.433851  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 11:12:30.433858  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.109997 (* 1 = 0.109997 loss)
I0626 11:12:30.433862  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.225117 (* 1 = 0.225117 loss)
I0626 11:12:30.433866  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119018 (* 1 = 0.0119018 loss)
I0626 11:12:30.433869  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0510324 (* 1 = 0.0510324 loss)
I0626 11:12:30.433874  4216 sgd_solver.cpp:106] Iteration 15940, lr = 0.0002
I0626 11:14:17.730710  4216 solver.cpp:228] Iteration 15960, loss = 0.219969
I0626 11:14:17.730737  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:14:17.730746  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0301017 (* 1 = 0.0301017 loss)
I0626 11:14:17.730751  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0842908 (* 1 = 0.0842908 loss)
I0626 11:14:17.730754  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226638 (* 1 = 0.00226638 loss)
I0626 11:14:17.730758  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183755 (* 1 = 0.0183755 loss)
I0626 11:14:17.730763  4216 sgd_solver.cpp:106] Iteration 15960, lr = 0.0002
I0626 11:16:05.600397  4216 solver.cpp:228] Iteration 15980, loss = 0.209782
I0626 11:16:05.600421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:16:05.600428  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385648 (* 1 = 0.0385648 loss)
I0626 11:16:05.600432  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0559376 (* 1 = 0.0559376 loss)
I0626 11:16:05.600436  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017041 (* 1 = 0.0017041 loss)
I0626 11:16:05.600440  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00742274 (* 1 = 0.00742274 loss)
I0626 11:16:05.600445  4216 sgd_solver.cpp:106] Iteration 15980, lr = 0.0002
speed: 5.256s / iter
I0626 11:17:53.020133  4216 solver.cpp:228] Iteration 16000, loss = 0.204305
I0626 11:17:53.020162  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:17:53.020170  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0412617 (* 1 = 0.0412617 loss)
I0626 11:17:53.020175  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.052687 (* 1 = 0.052687 loss)
I0626 11:17:53.020179  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000344201 (* 1 = 0.000344201 loss)
I0626 11:17:53.020184  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0037233 (* 1 = 0.0037233 loss)
I0626 11:17:53.020191  4216 sgd_solver.cpp:106] Iteration 16000, lr = 0.0002
I0626 11:19:39.857626  4216 solver.cpp:228] Iteration 16020, loss = 0.161624
I0626 11:19:39.857652  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 11:19:39.857659  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0891015 (* 1 = 0.0891015 loss)
I0626 11:19:39.857663  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.148214 (* 1 = 0.148214 loss)
I0626 11:19:39.857667  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00608633 (* 1 = 0.00608633 loss)
I0626 11:19:39.857671  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269649 (* 1 = 0.0269649 loss)
I0626 11:19:39.857676  4216 sgd_solver.cpp:106] Iteration 16020, lr = 0.0002
I0626 11:21:27.009542  4216 solver.cpp:228] Iteration 16040, loss = 0.287276
I0626 11:21:27.009567  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 11:21:27.009574  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.135935 (* 1 = 0.135935 loss)
I0626 11:21:27.009580  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.154296 (* 1 = 0.154296 loss)
I0626 11:21:27.009587  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128143 (* 1 = 0.00128143 loss)
I0626 11:21:27.009591  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371197 (* 1 = 0.0371197 loss)
I0626 11:21:27.009596  4216 sgd_solver.cpp:106] Iteration 16040, lr = 0.0002
I0626 11:23:15.057924  4216 solver.cpp:228] Iteration 16060, loss = 0.266584
I0626 11:23:15.057963  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:23:15.057977  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0636455 (* 1 = 0.0636455 loss)
I0626 11:23:15.057986  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0738955 (* 1 = 0.0738955 loss)
I0626 11:23:15.057993  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00366737 (* 1 = 0.00366737 loss)
I0626 11:23:15.058001  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00675002 (* 1 = 0.00675002 loss)
I0626 11:23:15.058008  4216 sgd_solver.cpp:106] Iteration 16060, lr = 0.0002
I0626 11:25:03.486215  4216 solver.cpp:228] Iteration 16080, loss = 0.477529
I0626 11:25:03.486263  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 11:25:03.486277  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.191991 (* 1 = 0.191991 loss)
I0626 11:25:03.486284  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.405734 (* 1 = 0.405734 loss)
I0626 11:25:03.486291  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013066 (* 1 = 0.013066 loss)
I0626 11:25:03.486297  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0648342 (* 1 = 0.0648342 loss)
I0626 11:25:03.486304  4216 sgd_solver.cpp:106] Iteration 16080, lr = 0.0002
I0626 11:26:52.072993  4216 solver.cpp:228] Iteration 16100, loss = 0.162196
I0626 11:26:52.073022  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 11:26:52.073030  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106236 (* 1 = 0.0106236 loss)
I0626 11:26:52.073038  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.075726 (* 1 = 0.075726 loss)
I0626 11:26:52.073045  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00730597 (* 1 = 0.00730597 loss)
I0626 11:26:52.073051  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245905 (* 1 = 0.0245905 loss)
I0626 11:26:52.073058  4216 sgd_solver.cpp:106] Iteration 16100, lr = 0.0002
I0626 11:28:38.043000  4216 solver.cpp:228] Iteration 16120, loss = 0.235572
I0626 11:28:38.043025  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 11:28:38.043031  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.032562 (* 1 = 0.032562 loss)
I0626 11:28:38.043035  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.088523 (* 1 = 0.088523 loss)
I0626 11:28:38.043040  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000237441 (* 1 = 0.000237441 loss)
I0626 11:28:38.043042  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0023338 (* 1 = 0.0023338 loss)
I0626 11:28:38.043047  4216 sgd_solver.cpp:106] Iteration 16120, lr = 0.0002
I0626 11:30:25.224191  4216 solver.cpp:228] Iteration 16140, loss = 0.141712
I0626 11:30:25.224218  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:30:25.224227  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.040198 (* 1 = 0.040198 loss)
I0626 11:30:25.224233  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0607531 (* 1 = 0.0607531 loss)
I0626 11:30:25.224239  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301876 (* 1 = 0.00301876 loss)
I0626 11:30:25.224244  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116253 (* 1 = 0.0116253 loss)
I0626 11:30:25.224251  4216 sgd_solver.cpp:106] Iteration 16140, lr = 0.0002
I0626 11:32:12.637292  4216 solver.cpp:228] Iteration 16160, loss = 0.273316
I0626 11:32:12.637316  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:32:12.637325  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322036 (* 1 = 0.0322036 loss)
I0626 11:32:12.637331  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0447996 (* 1 = 0.0447996 loss)
I0626 11:32:12.637336  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029338 (* 1 = 0.0029338 loss)
I0626 11:32:12.637339  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0017221 (* 1 = 0.0017221 loss)
I0626 11:32:12.637346  4216 sgd_solver.cpp:106] Iteration 16160, lr = 0.0002
I0626 11:33:58.033282  4216 solver.cpp:228] Iteration 16180, loss = 0.216385
I0626 11:33:58.033308  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:33:58.033315  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0271388 (* 1 = 0.0271388 loss)
I0626 11:33:58.033320  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0172697 (* 1 = 0.0172697 loss)
I0626 11:33:58.033324  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00288737 (* 1 = 0.00288737 loss)
I0626 11:33:58.033329  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00310595 (* 1 = 0.00310595 loss)
I0626 11:33:58.033334  4216 sgd_solver.cpp:106] Iteration 16180, lr = 0.0002
speed: 5.257s / iter
I0626 11:35:44.942589  4216 solver.cpp:228] Iteration 16200, loss = 0.169458
I0626 11:35:44.942668  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:35:44.942692  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.107188 (* 1 = 0.107188 loss)
I0626 11:35:44.942708  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.139623 (* 1 = 0.139623 loss)
I0626 11:35:44.942723  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270753 (* 1 = 0.00270753 loss)
I0626 11:35:44.942739  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181715 (* 1 = 0.0181715 loss)
I0626 11:35:44.942754  4216 sgd_solver.cpp:106] Iteration 16200, lr = 0.0002
I0626 11:37:32.047157  4216 solver.cpp:228] Iteration 16220, loss = 0.255805
I0626 11:37:32.047183  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 11:37:32.047190  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.243569 (* 1 = 0.243569 loss)
I0626 11:37:32.047194  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.421234 (* 1 = 0.421234 loss)
I0626 11:37:32.047199  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00535881 (* 1 = 0.00535881 loss)
I0626 11:37:32.047204  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0456285 (* 1 = 0.0456285 loss)
I0626 11:37:32.047209  4216 sgd_solver.cpp:106] Iteration 16220, lr = 0.0002
I0626 11:39:19.377585  4216 solver.cpp:228] Iteration 16240, loss = 0.22062
I0626 11:39:19.377619  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:39:19.377629  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0071166 (* 1 = 0.0071166 loss)
I0626 11:39:19.377635  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0359609 (* 1 = 0.0359609 loss)
I0626 11:39:19.377641  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118502 (* 1 = 0.00118502 loss)
I0626 11:39:19.377648  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178689 (* 1 = 0.0178689 loss)
I0626 11:39:19.377657  4216 sgd_solver.cpp:106] Iteration 16240, lr = 0.0002
I0626 11:41:05.565455  4216 solver.cpp:228] Iteration 16260, loss = 0.227316
I0626 11:41:05.565479  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0626 11:41:05.565487  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.219624 (* 1 = 0.219624 loss)
I0626 11:41:05.565491  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.41842 (* 1 = 0.41842 loss)
I0626 11:41:05.565495  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178018 (* 1 = 0.00178018 loss)
I0626 11:41:05.565500  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352782 (* 1 = 0.0352782 loss)
I0626 11:41:05.565505  4216 sgd_solver.cpp:106] Iteration 16260, lr = 0.0002
I0626 11:42:50.708266  4216 solver.cpp:228] Iteration 16280, loss = 0.111419
I0626 11:42:50.708292  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:42:50.708302  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.019953 (* 1 = 0.019953 loss)
I0626 11:42:50.708308  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0527335 (* 1 = 0.0527335 loss)
I0626 11:42:50.708314  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00786842 (* 1 = 0.00786842 loss)
I0626 11:42:50.708322  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179864 (* 1 = 0.0179864 loss)
I0626 11:42:50.708329  4216 sgd_solver.cpp:106] Iteration 16280, lr = 0.0002
I0626 11:44:38.996536  4216 solver.cpp:228] Iteration 16300, loss = 0.223052
I0626 11:44:38.996567  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:44:38.996577  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176756 (* 1 = 0.0176756 loss)
I0626 11:44:38.996582  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0399806 (* 1 = 0.0399806 loss)
I0626 11:44:38.996588  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00020259 (* 1 = 0.00020259 loss)
I0626 11:44:38.996593  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00883044 (* 1 = 0.00883044 loss)
I0626 11:44:38.996600  4216 sgd_solver.cpp:106] Iteration 16300, lr = 0.0002
I0626 11:46:26.330655  4216 solver.cpp:228] Iteration 16320, loss = 0.250472
I0626 11:46:26.330683  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:46:26.330691  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.033753 (* 1 = 0.033753 loss)
I0626 11:46:26.330695  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.152051 (* 1 = 0.152051 loss)
I0626 11:46:26.330698  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254587 (* 1 = 0.0254587 loss)
I0626 11:46:26.330703  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321492 (* 1 = 0.0321492 loss)
I0626 11:46:26.330708  4216 sgd_solver.cpp:106] Iteration 16320, lr = 0.0002
I0626 11:48:14.963747  4216 solver.cpp:228] Iteration 16340, loss = 0.284572
I0626 11:48:14.963774  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 11:48:14.963781  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0412283 (* 1 = 0.0412283 loss)
I0626 11:48:14.963786  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0926244 (* 1 = 0.0926244 loss)
I0626 11:48:14.963790  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103779 (* 1 = 0.0103779 loss)
I0626 11:48:14.963793  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485997 (* 1 = 0.0485997 loss)
I0626 11:48:14.963798  4216 sgd_solver.cpp:106] Iteration 16340, lr = 0.0002
I0626 11:50:00.624024  4216 solver.cpp:228] Iteration 16360, loss = 0.2952
I0626 11:50:00.624058  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 11:50:00.624070  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486775 (* 1 = 0.0486775 loss)
I0626 11:50:00.624078  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.156688 (* 1 = 0.156688 loss)
I0626 11:50:00.624084  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000809384 (* 1 = 0.000809384 loss)
I0626 11:50:00.624089  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223532 (* 1 = 0.0223532 loss)
I0626 11:50:00.624096  4216 sgd_solver.cpp:106] Iteration 16360, lr = 0.0002
I0626 11:51:48.096271  4216 solver.cpp:228] Iteration 16380, loss = 0.209578
I0626 11:51:48.096295  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:51:48.096302  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363093 (* 1 = 0.0363093 loss)
I0626 11:51:48.096307  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0926781 (* 1 = 0.0926781 loss)
I0626 11:51:48.096310  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167573 (* 1 = 0.0167573 loss)
I0626 11:51:48.096314  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00677821 (* 1 = 0.00677821 loss)
I0626 11:51:48.096319  4216 sgd_solver.cpp:106] Iteration 16380, lr = 0.0002
speed: 5.259s / iter
I0626 11:53:37.582065  4216 solver.cpp:228] Iteration 16400, loss = 0.36523
I0626 11:53:37.582090  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:53:37.582098  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232256 (* 1 = 0.0232256 loss)
I0626 11:53:37.582103  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0477003 (* 1 = 0.0477003 loss)
I0626 11:53:37.582106  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103802 (* 1 = 0.00103802 loss)
I0626 11:53:37.582110  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.006931 (* 1 = 0.006931 loss)
I0626 11:53:37.582115  4216 sgd_solver.cpp:106] Iteration 16400, lr = 0.0002
I0626 11:55:25.078557  4216 solver.cpp:228] Iteration 16420, loss = 0.223222
I0626 11:55:25.078583  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:55:25.078590  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190153 (* 1 = 0.0190153 loss)
I0626 11:55:25.078595  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0252765 (* 1 = 0.0252765 loss)
I0626 11:55:25.078599  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000857107 (* 1 = 0.000857107 loss)
I0626 11:55:25.078603  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00434071 (* 1 = 0.00434071 loss)
I0626 11:55:25.078608  4216 sgd_solver.cpp:106] Iteration 16420, lr = 0.0002
I0626 11:57:12.502249  4216 solver.cpp:228] Iteration 16440, loss = 0.162941
I0626 11:57:12.502276  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 11:57:12.502285  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0996179 (* 1 = 0.0996179 loss)
I0626 11:57:12.502290  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.174594 (* 1 = 0.174594 loss)
I0626 11:57:12.502292  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053941 (* 1 = 0.0053941 loss)
I0626 11:57:12.502297  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012681 (* 1 = 0.012681 loss)
I0626 11:57:12.502302  4216 sgd_solver.cpp:106] Iteration 16440, lr = 0.0002
I0626 11:59:03.192785  4216 solver.cpp:228] Iteration 16460, loss = 0.355715
I0626 11:59:03.192809  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 11:59:03.192817  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.142593 (* 1 = 0.142593 loss)
I0626 11:59:03.192821  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.263754 (* 1 = 0.263754 loss)
I0626 11:59:03.192826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00196254 (* 1 = 0.00196254 loss)
I0626 11:59:03.192829  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0482846 (* 1 = 0.0482846 loss)
I0626 11:59:03.192834  4216 sgd_solver.cpp:106] Iteration 16460, lr = 0.0002
I0626 12:00:48.275382  4216 solver.cpp:228] Iteration 16480, loss = 0.156519
I0626 12:00:48.275406  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:00:48.275414  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.015981 (* 1 = 0.015981 loss)
I0626 12:00:48.275419  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0497855 (* 1 = 0.0497855 loss)
I0626 12:00:48.275424  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00331822 (* 1 = 0.00331822 loss)
I0626 12:00:48.275427  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121083 (* 1 = 0.0121083 loss)
I0626 12:00:48.275432  4216 sgd_solver.cpp:106] Iteration 16480, lr = 0.0002
I0626 12:02:35.778587  4216 solver.cpp:228] Iteration 16500, loss = 0.271734
I0626 12:02:35.778609  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:02:35.778617  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216124 (* 1 = 0.0216124 loss)
I0626 12:02:35.778621  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.026528 (* 1 = 0.026528 loss)
I0626 12:02:35.778625  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184254 (* 1 = 0.00184254 loss)
I0626 12:02:35.778628  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00335486 (* 1 = 0.00335486 loss)
I0626 12:02:35.778632  4216 sgd_solver.cpp:106] Iteration 16500, lr = 0.0002
I0626 12:04:21.391841  4216 solver.cpp:228] Iteration 16520, loss = 0.146819
I0626 12:04:21.391866  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:04:21.391873  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122215 (* 1 = 0.0122215 loss)
I0626 12:04:21.391877  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0227266 (* 1 = 0.0227266 loss)
I0626 12:04:21.391881  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0011135 (* 1 = 0.0011135 loss)
I0626 12:04:21.391885  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0077048 (* 1 = 0.0077048 loss)
I0626 12:04:21.391890  4216 sgd_solver.cpp:106] Iteration 16520, lr = 0.0002
I0626 12:06:06.536097  4216 solver.cpp:228] Iteration 16540, loss = 0.152484
I0626 12:06:06.536119  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 12:06:06.536126  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0421647 (* 1 = 0.0421647 loss)
I0626 12:06:06.536130  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0739416 (* 1 = 0.0739416 loss)
I0626 12:06:06.536134  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010633 (* 1 = 0.0010633 loss)
I0626 12:06:06.536137  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116098 (* 1 = 0.0116098 loss)
I0626 12:06:06.536142  4216 sgd_solver.cpp:106] Iteration 16540, lr = 0.0002
I0626 12:07:51.696879  4216 solver.cpp:228] Iteration 16560, loss = 0.17346
I0626 12:07:51.696902  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 12:07:51.696910  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000561525 (* 1 = 0.000561525 loss)
I0626 12:07:51.696914  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0187507 (* 1 = 0.0187507 loss)
I0626 12:07:51.696918  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000914404 (* 1 = 0.000914404 loss)
I0626 12:07:51.696921  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021218 (* 1 = 0.021218 loss)
I0626 12:07:51.696926  4216 sgd_solver.cpp:106] Iteration 16560, lr = 0.0002
I0626 12:09:36.839769  4216 solver.cpp:228] Iteration 16580, loss = 0.198998
I0626 12:09:36.839792  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 12:09:36.839799  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.123869 (* 1 = 0.123869 loss)
I0626 12:09:36.839803  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.253343 (* 1 = 0.253343 loss)
I0626 12:09:36.839807  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140647 (* 1 = 0.00140647 loss)
I0626 12:09:36.839812  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261466 (* 1 = 0.0261466 loss)
I0626 12:09:36.839815  4216 sgd_solver.cpp:106] Iteration 16580, lr = 0.0002
speed: 5.260s / iter
I0626 12:11:21.951653  4216 solver.cpp:228] Iteration 16600, loss = 0.228482
I0626 12:11:21.951676  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:11:21.951683  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0281053 (* 1 = 0.0281053 loss)
I0626 12:11:21.951687  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0245003 (* 1 = 0.0245003 loss)
I0626 12:11:21.951691  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000691158 (* 1 = 0.000691158 loss)
I0626 12:11:21.951694  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00237338 (* 1 = 0.00237338 loss)
I0626 12:11:21.951699  4216 sgd_solver.cpp:106] Iteration 16600, lr = 0.0002
I0626 12:13:07.128617  4216 solver.cpp:228] Iteration 16620, loss = 0.18427
I0626 12:13:07.128639  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 12:13:07.128646  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.042047 (* 1 = 0.042047 loss)
I0626 12:13:07.128651  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.149262 (* 1 = 0.149262 loss)
I0626 12:13:07.128655  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000238775 (* 1 = 0.000238775 loss)
I0626 12:13:07.128659  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133795 (* 1 = 0.0133795 loss)
I0626 12:13:07.128664  4216 sgd_solver.cpp:106] Iteration 16620, lr = 0.0002
I0626 12:14:52.282294  4216 solver.cpp:228] Iteration 16640, loss = 0.099599
I0626 12:14:52.282317  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:14:52.282325  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233455 (* 1 = 0.0233455 loss)
I0626 12:14:52.282328  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0577618 (* 1 = 0.0577618 loss)
I0626 12:14:52.282331  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000360075 (* 1 = 0.000360075 loss)
I0626 12:14:52.282335  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0047504 (* 1 = 0.0047504 loss)
I0626 12:14:52.282341  4216 sgd_solver.cpp:106] Iteration 16640, lr = 0.0002
I0626 12:16:37.441427  4216 solver.cpp:228] Iteration 16660, loss = 0.189968
I0626 12:16:37.441452  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 12:16:37.441458  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0688623 (* 1 = 0.0688623 loss)
I0626 12:16:37.441462  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.150826 (* 1 = 0.150826 loss)
I0626 12:16:37.441465  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116389 (* 1 = 0.0116389 loss)
I0626 12:16:37.441469  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165864 (* 1 = 0.0165864 loss)
I0626 12:16:37.441474  4216 sgd_solver.cpp:106] Iteration 16660, lr = 0.0002
I0626 12:18:22.546967  4216 solver.cpp:228] Iteration 16680, loss = 0.144389
I0626 12:18:22.546990  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 12:18:22.546998  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0501384 (* 1 = 0.0501384 loss)
I0626 12:18:22.547003  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0744387 (* 1 = 0.0744387 loss)
I0626 12:18:22.547006  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010569 (* 1 = 0.0010569 loss)
I0626 12:18:22.547009  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00876206 (* 1 = 0.00876206 loss)
I0626 12:18:22.547014  4216 sgd_solver.cpp:106] Iteration 16680, lr = 0.0002
I0626 12:20:07.781654  4216 solver.cpp:228] Iteration 16700, loss = 0.222166
I0626 12:20:07.781679  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:20:07.781687  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0452652 (* 1 = 0.0452652 loss)
I0626 12:20:07.781690  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0427211 (* 1 = 0.0427211 loss)
I0626 12:20:07.781695  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0003362 (* 1 = 0.0003362 loss)
I0626 12:20:07.781699  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00832949 (* 1 = 0.00832949 loss)
I0626 12:20:07.781704  4216 sgd_solver.cpp:106] Iteration 16700, lr = 0.0002
I0626 12:21:52.941720  4216 solver.cpp:228] Iteration 16720, loss = 0.216191
I0626 12:21:52.941751  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 12:21:52.941758  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0908423 (* 1 = 0.0908423 loss)
I0626 12:21:52.941762  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.215606 (* 1 = 0.215606 loss)
I0626 12:21:52.941766  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164804 (* 1 = 0.0164804 loss)
I0626 12:21:52.941769  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213335 (* 1 = 0.0213335 loss)
I0626 12:21:52.941774  4216 sgd_solver.cpp:106] Iteration 16720, lr = 0.0002
I0626 12:23:38.054345  4216 solver.cpp:228] Iteration 16740, loss = 0.084416
I0626 12:23:38.054368  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 12:23:38.054376  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268332 (* 1 = 0.0268332 loss)
I0626 12:23:38.054380  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0759502 (* 1 = 0.0759502 loss)
I0626 12:23:38.054384  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000557365 (* 1 = 0.000557365 loss)
I0626 12:23:38.054388  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0023392 (* 1 = 0.0023392 loss)
I0626 12:23:38.054392  4216 sgd_solver.cpp:106] Iteration 16740, lr = 0.0002
I0626 12:25:23.255378  4216 solver.cpp:228] Iteration 16760, loss = 0.124001
I0626 12:25:23.255403  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 12:25:23.255409  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.044654 (* 1 = 0.044654 loss)
I0626 12:25:23.255414  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0983399 (* 1 = 0.0983399 loss)
I0626 12:25:23.255417  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116669 (* 1 = 0.00116669 loss)
I0626 12:25:23.255421  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00358767 (* 1 = 0.00358767 loss)
I0626 12:25:23.255425  4216 sgd_solver.cpp:106] Iteration 16760, lr = 0.0002
I0626 12:27:08.295927  4216 solver.cpp:228] Iteration 16780, loss = 0.196908
I0626 12:27:08.295950  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:27:08.295958  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0302848 (* 1 = 0.0302848 loss)
I0626 12:27:08.295961  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0511489 (* 1 = 0.0511489 loss)
I0626 12:27:08.295965  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000197148 (* 1 = 0.000197148 loss)
I0626 12:27:08.295969  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242778 (* 1 = 0.0242778 loss)
I0626 12:27:08.295974  4216 sgd_solver.cpp:106] Iteration 16780, lr = 0.0002
speed: 5.260s / iter
I0626 12:28:53.428655  4216 solver.cpp:228] Iteration 16800, loss = 0.149819
I0626 12:28:53.428679  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:28:53.428686  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.068545 (* 1 = 0.068545 loss)
I0626 12:28:53.428691  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0589644 (* 1 = 0.0589644 loss)
I0626 12:28:53.428694  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011979 (* 1 = 0.011979 loss)
I0626 12:28:53.428699  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0028467 (* 1 = 0.0028467 loss)
I0626 12:28:53.428704  4216 sgd_solver.cpp:106] Iteration 16800, lr = 0.0002
I0626 12:30:38.560010  4216 solver.cpp:228] Iteration 16820, loss = 0.188476
I0626 12:30:38.560034  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 12:30:38.560040  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0960956 (* 1 = 0.0960956 loss)
I0626 12:30:38.560045  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.18707 (* 1 = 0.18707 loss)
I0626 12:30:38.560048  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0076771 (* 1 = 0.0076771 loss)
I0626 12:30:38.560051  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228093 (* 1 = 0.0228093 loss)
I0626 12:30:38.560056  4216 sgd_solver.cpp:106] Iteration 16820, lr = 0.0002
I0626 12:32:23.734482  4216 solver.cpp:228] Iteration 16840, loss = 0.186411
I0626 12:32:23.734506  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:32:23.734514  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353382 (* 1 = 0.0353382 loss)
I0626 12:32:23.734519  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0232754 (* 1 = 0.0232754 loss)
I0626 12:32:23.734524  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000905485 (* 1 = 0.000905485 loss)
I0626 12:32:23.734526  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0024961 (* 1 = 0.0024961 loss)
I0626 12:32:23.734531  4216 sgd_solver.cpp:106] Iteration 16840, lr = 0.0002
I0626 12:34:08.860209  4216 solver.cpp:228] Iteration 16860, loss = 0.117132
I0626 12:34:08.860234  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:34:08.860240  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162185 (* 1 = 0.0162185 loss)
I0626 12:34:08.860245  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0232374 (* 1 = 0.0232374 loss)
I0626 12:34:08.860249  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000244813 (* 1 = 0.000244813 loss)
I0626 12:34:08.860254  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00300613 (* 1 = 0.00300613 loss)
I0626 12:34:08.860258  4216 sgd_solver.cpp:106] Iteration 16860, lr = 0.0002
I0626 12:35:53.983188  4216 solver.cpp:228] Iteration 16880, loss = 0.254053
I0626 12:35:53.983216  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 12:35:53.983222  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817478 (* 1 = 0.0817478 loss)
I0626 12:35:53.983227  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.18248 (* 1 = 0.18248 loss)
I0626 12:35:53.983230  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0328208 (* 1 = 0.0328208 loss)
I0626 12:35:53.983234  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.137971 (* 1 = 0.137971 loss)
I0626 12:35:53.983239  4216 sgd_solver.cpp:106] Iteration 16880, lr = 0.0002
I0626 12:37:39.102242  4216 solver.cpp:228] Iteration 16900, loss = 0.274
I0626 12:37:39.102267  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 12:37:39.102277  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.112412 (* 1 = 0.112412 loss)
I0626 12:37:39.102283  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.22101 (* 1 = 0.22101 loss)
I0626 12:37:39.102288  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00584031 (* 1 = 0.00584031 loss)
I0626 12:37:39.102293  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0654419 (* 1 = 0.0654419 loss)
I0626 12:37:39.102299  4216 sgd_solver.cpp:106] Iteration 16900, lr = 0.0002
I0626 12:39:24.242853  4216 solver.cpp:228] Iteration 16920, loss = 0.305392
I0626 12:39:24.242887  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 12:39:24.242897  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.129568 (* 1 = 0.129568 loss)
I0626 12:39:24.242902  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.202089 (* 1 = 0.202089 loss)
I0626 12:39:24.242907  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147568 (* 1 = 0.0147568 loss)
I0626 12:39:24.242909  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.048563 (* 1 = 0.048563 loss)
I0626 12:39:24.242914  4216 sgd_solver.cpp:106] Iteration 16920, lr = 0.0002
I0626 12:41:09.406272  4216 solver.cpp:228] Iteration 16940, loss = 0.136828
I0626 12:41:09.406294  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 12:41:09.406304  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.014936 (* 1 = 0.014936 loss)
I0626 12:41:09.406309  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0804914 (* 1 = 0.0804914 loss)
I0626 12:41:09.406316  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000399353 (* 1 = 0.000399353 loss)
I0626 12:41:09.406322  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00912618 (* 1 = 0.00912618 loss)
I0626 12:41:09.406327  4216 sgd_solver.cpp:106] Iteration 16940, lr = 0.0002
I0626 12:42:54.561830  4216 solver.cpp:228] Iteration 16960, loss = 0.283422
I0626 12:42:54.561858  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 12:42:54.561869  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0705597 (* 1 = 0.0705597 loss)
I0626 12:42:54.561878  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.185799 (* 1 = 0.185799 loss)
I0626 12:42:54.561885  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00620102 (* 1 = 0.00620102 loss)
I0626 12:42:54.561893  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211855 (* 1 = 0.0211855 loss)
I0626 12:42:54.561903  4216 sgd_solver.cpp:106] Iteration 16960, lr = 0.0002
I0626 12:44:39.715638  4216 solver.cpp:228] Iteration 16980, loss = 0.221547
I0626 12:44:39.715679  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 12:44:39.715689  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.100394 (* 1 = 0.100394 loss)
I0626 12:44:39.715695  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147692 (* 1 = 0.147692 loss)
I0626 12:44:39.715700  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00166211 (* 1 = 0.00166211 loss)
I0626 12:44:39.715705  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254627 (* 1 = 0.0254627 loss)
I0626 12:44:39.715713  4216 sgd_solver.cpp:106] Iteration 16980, lr = 0.0002
speed: 5.260s / iter
I0626 12:46:24.875378  4216 solver.cpp:228] Iteration 17000, loss = 0.216341
I0626 12:46:24.875402  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 12:46:24.875409  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140694 (* 1 = 0.0140694 loss)
I0626 12:46:24.875413  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0189037 (* 1 = 0.0189037 loss)
I0626 12:46:24.875417  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000118814 (* 1 = 0.000118814 loss)
I0626 12:46:24.875421  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00886129 (* 1 = 0.00886129 loss)
I0626 12:46:24.875424  4216 sgd_solver.cpp:106] Iteration 17000, lr = 0.0002
I0626 12:48:10.011253  4216 solver.cpp:228] Iteration 17020, loss = 0.283442
I0626 12:48:10.011276  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 12:48:10.011282  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.028514 (* 1 = 0.028514 loss)
I0626 12:48:10.011286  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0811156 (* 1 = 0.0811156 loss)
I0626 12:48:10.011291  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157918 (* 1 = 0.00157918 loss)
I0626 12:48:10.011293  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00346922 (* 1 = 0.00346922 loss)
I0626 12:48:10.011298  4216 sgd_solver.cpp:106] Iteration 17020, lr = 0.0002
I0626 12:49:55.139848  4216 solver.cpp:228] Iteration 17040, loss = 0.150024
I0626 12:49:55.139875  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:49:55.139883  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000636075 (* 1 = 0.000636075 loss)
I0626 12:49:55.139889  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0277239 (* 1 = 0.0277239 loss)
I0626 12:49:55.139894  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00780452 (* 1 = 0.00780452 loss)
I0626 12:49:55.139899  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141721 (* 1 = 0.0141721 loss)
I0626 12:49:55.139904  4216 sgd_solver.cpp:106] Iteration 17040, lr = 0.0002
I0626 12:51:40.347141  4216 solver.cpp:228] Iteration 17060, loss = 0.259338
I0626 12:51:40.347163  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 12:51:40.347172  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0586837 (* 1 = 0.0586837 loss)
I0626 12:51:40.347175  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.161076 (* 1 = 0.161076 loss)
I0626 12:51:40.347179  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000361714 (* 1 = 0.000361714 loss)
I0626 12:51:40.347182  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00715134 (* 1 = 0.00715134 loss)
I0626 12:51:40.347187  4216 sgd_solver.cpp:106] Iteration 17060, lr = 0.0002
I0626 12:53:25.511459  4216 solver.cpp:228] Iteration 17080, loss = 0.222645
I0626 12:53:25.511484  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:53:25.511492  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00672891 (* 1 = 0.00672891 loss)
I0626 12:53:25.511497  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0407122 (* 1 = 0.0407122 loss)
I0626 12:53:25.511500  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00444011 (* 1 = 0.00444011 loss)
I0626 12:53:25.511504  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00852876 (* 1 = 0.00852876 loss)
I0626 12:53:25.511509  4216 sgd_solver.cpp:106] Iteration 17080, lr = 0.0002
I0626 12:55:10.621942  4216 solver.cpp:228] Iteration 17100, loss = 0.405061
I0626 12:55:10.621968  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 12:55:10.621975  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0594185 (* 1 = 0.0594185 loss)
I0626 12:55:10.621979  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.133098 (* 1 = 0.133098 loss)
I0626 12:55:10.621984  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00052816 (* 1 = 0.00052816 loss)
I0626 12:55:10.621987  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121352 (* 1 = 0.0121352 loss)
I0626 12:55:10.621992  4216 sgd_solver.cpp:106] Iteration 17100, lr = 0.0002
I0626 12:56:55.793921  4216 solver.cpp:228] Iteration 17120, loss = 0.308821
I0626 12:56:55.793947  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 12:56:55.793954  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0958542 (* 1 = 0.0958542 loss)
I0626 12:56:55.793959  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.250473 (* 1 = 0.250473 loss)
I0626 12:56:55.793963  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00977082 (* 1 = 0.00977082 loss)
I0626 12:56:55.793967  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265874 (* 1 = 0.0265874 loss)
I0626 12:56:55.793973  4216 sgd_solver.cpp:106] Iteration 17120, lr = 0.0002
I0626 12:58:40.942561  4216 solver.cpp:228] Iteration 17140, loss = 0.393723
I0626 12:58:40.942584  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 12:58:40.942593  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0538008 (* 1 = 0.0538008 loss)
I0626 12:58:40.942600  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.136615 (* 1 = 0.136615 loss)
I0626 12:58:40.942605  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000768912 (* 1 = 0.000768912 loss)
I0626 12:58:40.942610  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019568 (* 1 = 0.019568 loss)
I0626 12:58:40.942616  4216 sgd_solver.cpp:106] Iteration 17140, lr = 0.0002
I0626 13:00:26.180897  4216 solver.cpp:228] Iteration 17160, loss = 0.351557
I0626 13:00:26.180922  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:00:26.180928  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.056426 (* 1 = 0.056426 loss)
I0626 13:00:26.180932  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0653797 (* 1 = 0.0653797 loss)
I0626 13:00:26.180936  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000491877 (* 1 = 0.000491877 loss)
I0626 13:00:26.180940  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00437023 (* 1 = 0.00437023 loss)
I0626 13:00:26.180944  4216 sgd_solver.cpp:106] Iteration 17160, lr = 0.0002
I0626 13:02:11.383354  4216 solver.cpp:228] Iteration 17180, loss = 0.216698
I0626 13:02:11.383378  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 13:02:11.383386  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703484 (* 1 = 0.0703484 loss)
I0626 13:02:11.383390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109112 (* 1 = 0.109112 loss)
I0626 13:02:11.383395  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00563294 (* 1 = 0.00563294 loss)
I0626 13:02:11.383399  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105158 (* 1 = 0.0105158 loss)
I0626 13:02:11.383404  4216 sgd_solver.cpp:106] Iteration 17180, lr = 0.0002
speed: 5.259s / iter
I0626 13:03:56.567181  4216 solver.cpp:228] Iteration 17200, loss = 0.148686
I0626 13:03:56.567206  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:03:56.567214  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0654697 (* 1 = 0.0654697 loss)
I0626 13:03:56.567220  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.066879 (* 1 = 0.066879 loss)
I0626 13:03:56.567226  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270236 (* 1 = 0.00270236 loss)
I0626 13:03:56.567232  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00537117 (* 1 = 0.00537117 loss)
I0626 13:03:56.567239  4216 sgd_solver.cpp:106] Iteration 17200, lr = 0.0002
I0626 13:05:41.776572  4216 solver.cpp:228] Iteration 17220, loss = 0.175338
I0626 13:05:41.776597  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 13:05:41.776605  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0950948 (* 1 = 0.0950948 loss)
I0626 13:05:41.776609  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.153161 (* 1 = 0.153161 loss)
I0626 13:05:41.776613  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377668 (* 1 = 0.00377668 loss)
I0626 13:05:41.776618  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107923 (* 1 = 0.0107923 loss)
I0626 13:05:41.776623  4216 sgd_solver.cpp:106] Iteration 17220, lr = 0.0002
I0626 13:07:26.927064  4216 solver.cpp:228] Iteration 17240, loss = 0.0637088
I0626 13:07:26.927089  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:07:26.927096  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251653 (* 1 = 0.0251653 loss)
I0626 13:07:26.927101  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.042468 (* 1 = 0.042468 loss)
I0626 13:07:26.927105  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000653139 (* 1 = 0.000653139 loss)
I0626 13:07:26.927110  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131813 (* 1 = 0.0131813 loss)
I0626 13:07:26.927115  4216 sgd_solver.cpp:106] Iteration 17240, lr = 0.0002
I0626 13:09:11.998811  4216 solver.cpp:228] Iteration 17260, loss = 0.222926
I0626 13:09:11.998836  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 13:09:11.998843  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0522152 (* 1 = 0.0522152 loss)
I0626 13:09:11.998847  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147328 (* 1 = 0.147328 loss)
I0626 13:09:11.998852  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000962324 (* 1 = 0.000962324 loss)
I0626 13:09:11.998855  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126272 (* 1 = 0.0126272 loss)
I0626 13:09:11.998864  4216 sgd_solver.cpp:106] Iteration 17260, lr = 0.0002
I0626 13:10:57.110829  4216 solver.cpp:228] Iteration 17280, loss = 0.408399
I0626 13:10:57.110854  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0626 13:10:57.110867  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.311383 (* 1 = 0.311383 loss)
I0626 13:10:57.110870  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.373559 (* 1 = 0.373559 loss)
I0626 13:10:57.110874  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327622 (* 1 = 0.0327622 loss)
I0626 13:10:57.110878  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124157 (* 1 = 0.124157 loss)
I0626 13:10:57.110885  4216 sgd_solver.cpp:106] Iteration 17280, lr = 0.0002
I0626 13:12:42.216838  4216 solver.cpp:228] Iteration 17300, loss = 0.191922
I0626 13:12:42.216862  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 13:12:42.216871  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486942 (* 1 = 0.0486942 loss)
I0626 13:12:42.216874  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.143008 (* 1 = 0.143008 loss)
I0626 13:12:42.216878  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00629904 (* 1 = 0.00629904 loss)
I0626 13:12:42.216882  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198461 (* 1 = 0.0198461 loss)
I0626 13:12:42.216888  4216 sgd_solver.cpp:106] Iteration 17300, lr = 0.0002
I0626 13:14:27.350245  4216 solver.cpp:228] Iteration 17320, loss = 0.333834
I0626 13:14:27.350267  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 13:14:27.350275  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.12488 (* 1 = 0.12488 loss)
I0626 13:14:27.350278  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.14893 (* 1 = 0.14893 loss)
I0626 13:14:27.350282  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108951 (* 1 = 0.00108951 loss)
I0626 13:14:27.350286  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169134 (* 1 = 0.0169134 loss)
I0626 13:14:27.350291  4216 sgd_solver.cpp:106] Iteration 17320, lr = 0.0002
I0626 13:16:12.492779  4216 solver.cpp:228] Iteration 17340, loss = 0.245823
I0626 13:16:12.492802  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 13:16:12.492810  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.209882 (* 1 = 0.209882 loss)
I0626 13:16:12.492815  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.32108 (* 1 = 0.32108 loss)
I0626 13:16:12.492818  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184248 (* 1 = 0.0184248 loss)
I0626 13:16:12.492822  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683244 (* 1 = 0.0683244 loss)
I0626 13:16:12.492827  4216 sgd_solver.cpp:106] Iteration 17340, lr = 0.0002
I0626 13:17:57.531471  4216 solver.cpp:228] Iteration 17360, loss = 0.227666
I0626 13:17:57.531499  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 13:17:57.531507  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.258692 (* 1 = 0.258692 loss)
I0626 13:17:57.531512  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.287168 (* 1 = 0.287168 loss)
I0626 13:17:57.531515  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305638 (* 1 = 0.00305638 loss)
I0626 13:17:57.531519  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0561717 (* 1 = 0.0561717 loss)
I0626 13:17:57.531525  4216 sgd_solver.cpp:106] Iteration 17360, lr = 0.0002
I0626 13:19:42.663269  4216 solver.cpp:228] Iteration 17380, loss = 0.223635
I0626 13:19:42.663293  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 13:19:42.663301  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795795 (* 1 = 0.0795795 loss)
I0626 13:19:42.663305  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.156441 (* 1 = 0.156441 loss)
I0626 13:19:42.663309  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107437 (* 1 = 0.0107437 loss)
I0626 13:19:42.663313  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144475 (* 1 = 0.0144475 loss)
I0626 13:19:42.663318  4216 sgd_solver.cpp:106] Iteration 17380, lr = 0.0002
speed: 5.259s / iter
I0626 13:21:27.734663  4216 solver.cpp:228] Iteration 17400, loss = 0.32035
I0626 13:21:27.734694  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0626 13:21:27.734707  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.724006 (* 1 = 0.724006 loss)
I0626 13:21:27.734716  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.577845 (* 1 = 0.577845 loss)
I0626 13:21:27.734725  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0370165 (* 1 = 0.0370165 loss)
I0626 13:21:27.734735  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.26821 (* 1 = 0.26821 loss)
I0626 13:21:27.734745  4216 sgd_solver.cpp:106] Iteration 17400, lr = 0.0002
I0626 13:23:12.876632  4216 solver.cpp:228] Iteration 17420, loss = 0.279541
I0626 13:23:12.876658  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 13:23:12.876668  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.068055 (* 1 = 0.068055 loss)
I0626 13:23:12.876674  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.195973 (* 1 = 0.195973 loss)
I0626 13:23:12.876682  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000127428 (* 1 = 0.000127428 loss)
I0626 13:23:12.876688  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117216 (* 1 = 0.0117216 loss)
I0626 13:23:12.876694  4216 sgd_solver.cpp:106] Iteration 17420, lr = 0.0002
I0626 13:24:58.031352  4216 solver.cpp:228] Iteration 17440, loss = 0.203375
I0626 13:24:58.031379  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 13:24:58.031386  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0563918 (* 1 = 0.0563918 loss)
I0626 13:24:58.031390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.137621 (* 1 = 0.137621 loss)
I0626 13:24:58.031394  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000380361 (* 1 = 0.000380361 loss)
I0626 13:24:58.031397  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00235934 (* 1 = 0.00235934 loss)
I0626 13:24:58.031402  4216 sgd_solver.cpp:106] Iteration 17440, lr = 0.0002
I0626 13:26:43.087471  4216 solver.cpp:228] Iteration 17460, loss = 0.156704
I0626 13:26:43.087496  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:26:43.087502  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251235 (* 1 = 0.0251235 loss)
I0626 13:26:43.087507  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0645395 (* 1 = 0.0645395 loss)
I0626 13:26:43.087510  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134203 (* 1 = 0.00134203 loss)
I0626 13:26:43.087513  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023638 (* 1 = 0.023638 loss)
I0626 13:26:43.087518  4216 sgd_solver.cpp:106] Iteration 17460, lr = 0.0002
I0626 13:28:28.284595  4216 solver.cpp:228] Iteration 17480, loss = 0.181089
I0626 13:28:28.284617  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:28:28.284624  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391711 (* 1 = 0.0391711 loss)
I0626 13:28:28.284628  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0965728 (* 1 = 0.0965728 loss)
I0626 13:28:28.284632  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000237587 (* 1 = 0.000237587 loss)
I0626 13:28:28.284636  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113907 (* 1 = 0.0113907 loss)
I0626 13:28:28.284641  4216 sgd_solver.cpp:106] Iteration 17480, lr = 0.0002
I0626 13:30:13.405925  4216 solver.cpp:228] Iteration 17500, loss = 0.216002
I0626 13:30:13.405949  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 13:30:13.405956  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.246281 (* 1 = 0.246281 loss)
I0626 13:30:13.405961  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.245665 (* 1 = 0.245665 loss)
I0626 13:30:13.405966  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000449681 (* 1 = 0.000449681 loss)
I0626 13:30:13.405969  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0392852 (* 1 = 0.0392852 loss)
I0626 13:30:13.405974  4216 sgd_solver.cpp:106] Iteration 17500, lr = 0.0002
I0626 13:31:58.331696  4216 solver.cpp:228] Iteration 17520, loss = 0.46613
I0626 13:31:58.331729  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:31:58.331737  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00651463 (* 1 = 0.00651463 loss)
I0626 13:31:58.331742  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0601628 (* 1 = 0.0601628 loss)
I0626 13:31:58.331745  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956905 (* 1 = 0.00956905 loss)
I0626 13:31:58.331749  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02587 (* 1 = 0.02587 loss)
I0626 13:31:58.331754  4216 sgd_solver.cpp:106] Iteration 17520, lr = 0.0002
I0626 13:33:43.389971  4216 solver.cpp:228] Iteration 17540, loss = 0.206795
I0626 13:33:43.389994  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 13:33:43.390002  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0483249 (* 1 = 0.0483249 loss)
I0626 13:33:43.390007  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0290795 (* 1 = 0.0290795 loss)
I0626 13:33:43.390010  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135404 (* 1 = 0.0135404 loss)
I0626 13:33:43.390014  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123398 (* 1 = 0.0123398 loss)
I0626 13:33:43.390019  4216 sgd_solver.cpp:106] Iteration 17540, lr = 0.0002
I0626 13:35:28.506567  4216 solver.cpp:228] Iteration 17560, loss = 0.260971
I0626 13:35:28.506592  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 13:35:28.506598  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.172531 (* 1 = 0.172531 loss)
I0626 13:35:28.506603  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.261065 (* 1 = 0.261065 loss)
I0626 13:35:28.506606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538286 (* 1 = 0.00538286 loss)
I0626 13:35:28.506609  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353687 (* 1 = 0.0353687 loss)
I0626 13:35:28.506614  4216 sgd_solver.cpp:106] Iteration 17560, lr = 0.0002
I0626 13:37:13.642968  4216 solver.cpp:228] Iteration 17580, loss = 0.176554
I0626 13:37:13.642989  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:37:13.642997  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327398 (* 1 = 0.0327398 loss)
I0626 13:37:13.642999  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0887007 (* 1 = 0.0887007 loss)
I0626 13:37:13.643003  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360597 (* 1 = 0.00360597 loss)
I0626 13:37:13.643007  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023747 (* 1 = 0.023747 loss)
I0626 13:37:13.643010  4216 sgd_solver.cpp:106] Iteration 17580, lr = 0.0002
speed: 5.259s / iter
I0626 13:38:58.796839  4216 solver.cpp:228] Iteration 17600, loss = 0.212956
I0626 13:38:58.796862  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:38:58.796869  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203092 (* 1 = 0.0203092 loss)
I0626 13:38:58.796872  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0703986 (* 1 = 0.0703986 loss)
I0626 13:38:58.796875  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179474 (* 1 = 0.00179474 loss)
I0626 13:38:58.796880  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218493 (* 1 = 0.0218493 loss)
I0626 13:38:58.796883  4216 sgd_solver.cpp:106] Iteration 17600, lr = 0.0002
I0626 13:40:43.951319  4216 solver.cpp:228] Iteration 17620, loss = 0.31231
I0626 13:40:43.951344  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 13:40:43.951351  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0694074 (* 1 = 0.0694074 loss)
I0626 13:40:43.951356  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.103306 (* 1 = 0.103306 loss)
I0626 13:40:43.951360  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00425925 (* 1 = 0.00425925 loss)
I0626 13:40:43.951364  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00814478 (* 1 = 0.00814478 loss)
I0626 13:40:43.951370  4216 sgd_solver.cpp:106] Iteration 17620, lr = 0.0002
I0626 13:42:29.039302  4216 solver.cpp:228] Iteration 17640, loss = 0.152508
I0626 13:42:29.039325  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:42:29.039335  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293345 (* 1 = 0.0293345 loss)
I0626 13:42:29.039341  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0620833 (* 1 = 0.0620833 loss)
I0626 13:42:29.039348  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114946 (* 1 = 0.00114946 loss)
I0626 13:42:29.039355  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00780549 (* 1 = 0.00780549 loss)
I0626 13:42:29.039361  4216 sgd_solver.cpp:106] Iteration 17640, lr = 0.0002
I0626 13:44:14.202527  4216 solver.cpp:228] Iteration 17660, loss = 0.0955084
I0626 13:44:14.202553  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:44:14.202561  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183286 (* 1 = 0.0183286 loss)
I0626 13:44:14.202565  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0322515 (* 1 = 0.0322515 loss)
I0626 13:44:14.202569  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000318213 (* 1 = 0.000318213 loss)
I0626 13:44:14.202574  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00891572 (* 1 = 0.00891572 loss)
I0626 13:44:14.202579  4216 sgd_solver.cpp:106] Iteration 17660, lr = 0.0002
I0626 13:45:59.362522  4216 solver.cpp:228] Iteration 17680, loss = 0.220975
I0626 13:45:59.362545  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 13:45:59.362552  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.109984 (* 1 = 0.109984 loss)
I0626 13:45:59.362557  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.125958 (* 1 = 0.125958 loss)
I0626 13:45:59.362560  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350695 (* 1 = 0.00350695 loss)
I0626 13:45:59.362565  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021086 (* 1 = 0.021086 loss)
I0626 13:45:59.362570  4216 sgd_solver.cpp:106] Iteration 17680, lr = 0.0002
I0626 13:47:44.498018  4216 solver.cpp:228] Iteration 17700, loss = 0.232245
I0626 13:47:44.498040  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 13:47:44.498047  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.17262 (* 1 = 0.17262 loss)
I0626 13:47:44.498051  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.332257 (* 1 = 0.332257 loss)
I0626 13:47:44.498055  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305272 (* 1 = 0.00305272 loss)
I0626 13:47:44.498059  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308319 (* 1 = 0.0308319 loss)
I0626 13:47:44.498064  4216 sgd_solver.cpp:106] Iteration 17700, lr = 0.0002
I0626 13:49:29.691833  4216 solver.cpp:228] Iteration 17720, loss = 0.290817
I0626 13:49:29.691857  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 13:49:29.691864  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0924416 (* 1 = 0.0924416 loss)
I0626 13:49:29.691869  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.191943 (* 1 = 0.191943 loss)
I0626 13:49:29.691874  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000801945 (* 1 = 0.000801945 loss)
I0626 13:49:29.691877  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236584 (* 1 = 0.0236584 loss)
I0626 13:49:29.691882  4216 sgd_solver.cpp:106] Iteration 17720, lr = 0.0002
I0626 13:51:14.799608  4216 solver.cpp:228] Iteration 17740, loss = 0.165965
I0626 13:51:14.799631  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 13:51:14.799640  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0315824 (* 1 = 0.0315824 loss)
I0626 13:51:14.799646  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0389097 (* 1 = 0.0389097 loss)
I0626 13:51:14.799652  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000129415 (* 1 = 0.000129415 loss)
I0626 13:51:14.799659  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146368 (* 1 = 0.0146368 loss)
I0626 13:51:14.799664  4216 sgd_solver.cpp:106] Iteration 17740, lr = 0.0002
I0626 13:52:59.866144  4216 solver.cpp:228] Iteration 17760, loss = 0.126647
I0626 13:52:59.866170  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 13:52:59.866178  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481355 (* 1 = 0.0481355 loss)
I0626 13:52:59.866183  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118612 (* 1 = 0.118612 loss)
I0626 13:52:59.866186  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00319127 (* 1 = 0.00319127 loss)
I0626 13:52:59.866190  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00921268 (* 1 = 0.00921268 loss)
I0626 13:52:59.866195  4216 sgd_solver.cpp:106] Iteration 17760, lr = 0.0002
I0626 13:54:44.958081  4216 solver.cpp:228] Iteration 17780, loss = 0.184803
I0626 13:54:44.958107  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 13:54:44.958115  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.064412 (* 1 = 0.064412 loss)
I0626 13:54:44.958119  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.143574 (* 1 = 0.143574 loss)
I0626 13:54:44.958123  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00890953 (* 1 = 0.00890953 loss)
I0626 13:54:44.958127  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408631 (* 1 = 0.0408631 loss)
I0626 13:54:44.958132  4216 sgd_solver.cpp:106] Iteration 17780, lr = 0.0002
speed: 5.259s / iter
I0626 13:56:30.126657  4216 solver.cpp:228] Iteration 17800, loss = 0.183395
I0626 13:56:30.126688  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 13:56:30.126695  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593983 (* 1 = 0.0593983 loss)
I0626 13:56:30.126700  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129499 (* 1 = 0.129499 loss)
I0626 13:56:30.126704  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120296 (* 1 = 0.00120296 loss)
I0626 13:56:30.126709  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0044121 (* 1 = 0.0044121 loss)
I0626 13:56:30.126714  4216 sgd_solver.cpp:106] Iteration 17800, lr = 0.0002
I0626 13:58:15.283017  4216 solver.cpp:228] Iteration 17820, loss = 0.14342
I0626 13:58:15.283041  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 13:58:15.283049  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0759298 (* 1 = 0.0759298 loss)
I0626 13:58:15.283053  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.127636 (* 1 = 0.127636 loss)
I0626 13:58:15.283058  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229924 (* 1 = 0.00229924 loss)
I0626 13:58:15.283061  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156249 (* 1 = 0.0156249 loss)
I0626 13:58:15.283066  4216 sgd_solver.cpp:106] Iteration 17820, lr = 0.0002
I0626 14:00:00.440939  4216 solver.cpp:228] Iteration 17840, loss = 0.29022
I0626 14:00:00.440963  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:00:00.440973  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0100348 (* 1 = 0.0100348 loss)
I0626 14:00:00.440979  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0395659 (* 1 = 0.0395659 loss)
I0626 14:00:00.440984  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012062 (* 1 = 0.0012062 loss)
I0626 14:00:00.440990  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00635133 (* 1 = 0.00635133 loss)
I0626 14:00:00.440996  4216 sgd_solver.cpp:106] Iteration 17840, lr = 0.0002
I0626 14:01:45.549656  4216 solver.cpp:228] Iteration 17860, loss = 0.177886
I0626 14:01:45.549679  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:01:45.549686  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.121255 (* 1 = 0.121255 loss)
I0626 14:01:45.549690  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0655865 (* 1 = 0.0655865 loss)
I0626 14:01:45.549695  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000329439 (* 1 = 0.000329439 loss)
I0626 14:01:45.549697  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255386 (* 1 = 0.0255386 loss)
I0626 14:01:45.549702  4216 sgd_solver.cpp:106] Iteration 17860, lr = 0.0002
I0626 14:03:30.690268  4216 solver.cpp:228] Iteration 17880, loss = 0.212162
I0626 14:03:30.690291  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:03:30.690299  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264543 (* 1 = 0.0264543 loss)
I0626 14:03:30.690302  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0531577 (* 1 = 0.0531577 loss)
I0626 14:03:30.690306  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00138005 (* 1 = 0.00138005 loss)
I0626 14:03:30.690310  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00806255 (* 1 = 0.00806255 loss)
I0626 14:03:30.690315  4216 sgd_solver.cpp:106] Iteration 17880, lr = 0.0002
I0626 14:05:15.746309  4216 solver.cpp:228] Iteration 17900, loss = 0.234916
I0626 14:05:15.746335  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 14:05:15.746340  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.147698 (* 1 = 0.147698 loss)
I0626 14:05:15.746345  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.219416 (* 1 = 0.219416 loss)
I0626 14:05:15.746348  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00046947 (* 1 = 0.00046947 loss)
I0626 14:05:15.746352  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378349 (* 1 = 0.0378349 loss)
I0626 14:05:15.746356  4216 sgd_solver.cpp:106] Iteration 17900, lr = 0.0002
I0626 14:07:00.900826  4216 solver.cpp:228] Iteration 17920, loss = 0.21592
I0626 14:07:00.900851  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:07:00.900858  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.012434 (* 1 = 0.012434 loss)
I0626 14:07:00.900862  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0140811 (* 1 = 0.0140811 loss)
I0626 14:07:00.900866  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000499637 (* 1 = 0.000499637 loss)
I0626 14:07:00.900871  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00198732 (* 1 = 0.00198732 loss)
I0626 14:07:00.900876  4216 sgd_solver.cpp:106] Iteration 17920, lr = 0.0002
I0626 14:08:46.027317  4216 solver.cpp:228] Iteration 17940, loss = 0.301768
I0626 14:08:46.027340  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 14:08:46.027348  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.128708 (* 1 = 0.128708 loss)
I0626 14:08:46.027351  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.150258 (* 1 = 0.150258 loss)
I0626 14:08:46.027355  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245293 (* 1 = 0.00245293 loss)
I0626 14:08:46.027359  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195538 (* 1 = 0.0195538 loss)
I0626 14:08:46.027364  4216 sgd_solver.cpp:106] Iteration 17940, lr = 0.0002
I0626 14:10:31.163225  4216 solver.cpp:228] Iteration 17960, loss = 0.196533
I0626 14:10:31.163250  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 14:10:31.163259  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.214734 (* 1 = 0.214734 loss)
I0626 14:10:31.163264  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.366088 (* 1 = 0.366088 loss)
I0626 14:10:31.163267  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.004878 (* 1 = 0.004878 loss)
I0626 14:10:31.163271  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342705 (* 1 = 0.0342705 loss)
I0626 14:10:31.163276  4216 sgd_solver.cpp:106] Iteration 17960, lr = 0.0002
I0626 14:12:16.297724  4216 solver.cpp:228] Iteration 17980, loss = 0.287702
I0626 14:12:16.297750  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:12:16.297758  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165915 (* 1 = 0.0165915 loss)
I0626 14:12:16.297765  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0339218 (* 1 = 0.0339218 loss)
I0626 14:12:16.297773  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000200445 (* 1 = 0.000200445 loss)
I0626 14:12:16.297777  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129727 (* 1 = 0.0129727 loss)
I0626 14:12:16.297783  4216 sgd_solver.cpp:106] Iteration 17980, lr = 0.0002
speed: 5.259s / iter
I0626 14:14:01.444615  4216 solver.cpp:228] Iteration 18000, loss = 0.277269
I0626 14:14:01.444640  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:14:01.444648  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0281149 (* 1 = 0.0281149 loss)
I0626 14:14:01.444653  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0532076 (* 1 = 0.0532076 loss)
I0626 14:14:01.444656  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106625 (* 1 = 0.00106625 loss)
I0626 14:14:01.444661  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00546855 (* 1 = 0.00546855 loss)
I0626 14:14:01.444665  4216 sgd_solver.cpp:106] Iteration 18000, lr = 0.0002
I0626 14:15:46.592850  4216 solver.cpp:228] Iteration 18020, loss = 0.168401
I0626 14:15:46.592876  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:15:46.592885  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379383 (* 1 = 0.0379383 loss)
I0626 14:15:46.592890  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0272869 (* 1 = 0.0272869 loss)
I0626 14:15:46.592893  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000883863 (* 1 = 0.000883863 loss)
I0626 14:15:46.592897  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00615109 (* 1 = 0.00615109 loss)
I0626 14:15:46.592903  4216 sgd_solver.cpp:106] Iteration 18020, lr = 0.0002
I0626 14:17:31.736750  4216 solver.cpp:228] Iteration 18040, loss = 0.245375
I0626 14:17:31.736774  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 14:17:31.736781  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.184376 (* 1 = 0.184376 loss)
I0626 14:17:31.736786  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.299625 (* 1 = 0.299625 loss)
I0626 14:17:31.736790  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00514594 (* 1 = 0.00514594 loss)
I0626 14:17:31.736794  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0595242 (* 1 = 0.0595242 loss)
I0626 14:17:31.736799  4216 sgd_solver.cpp:106] Iteration 18040, lr = 0.0002
I0626 14:19:16.826988  4216 solver.cpp:228] Iteration 18060, loss = 0.138097
I0626 14:19:16.827013  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 14:19:16.827020  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.14142 (* 1 = 0.14142 loss)
I0626 14:19:16.827024  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.288672 (* 1 = 0.288672 loss)
I0626 14:19:16.827029  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00391372 (* 1 = 0.00391372 loss)
I0626 14:19:16.827033  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272436 (* 1 = 0.0272436 loss)
I0626 14:19:16.827039  4216 sgd_solver.cpp:106] Iteration 18060, lr = 0.0002
I0626 14:21:01.924563  4216 solver.cpp:228] Iteration 18080, loss = 0.211438
I0626 14:21:01.924588  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:21:01.924595  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245932 (* 1 = 0.0245932 loss)
I0626 14:21:01.924599  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0333566 (* 1 = 0.0333566 loss)
I0626 14:21:01.924603  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000536735 (* 1 = 0.000536735 loss)
I0626 14:21:01.924607  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175137 (* 1 = 0.0175137 loss)
I0626 14:21:01.924613  4216 sgd_solver.cpp:106] Iteration 18080, lr = 0.0002
I0626 14:22:47.059003  4216 solver.cpp:228] Iteration 18100, loss = 0.220657
I0626 14:22:47.059026  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:22:47.059034  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0553518 (* 1 = 0.0553518 loss)
I0626 14:22:47.059039  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.140213 (* 1 = 0.140213 loss)
I0626 14:22:47.059044  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0025896 (* 1 = 0.0025896 loss)
I0626 14:22:47.059049  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161962 (* 1 = 0.0161962 loss)
I0626 14:22:47.059056  4216 sgd_solver.cpp:106] Iteration 18100, lr = 0.0002
I0626 14:24:32.245761  4216 solver.cpp:228] Iteration 18120, loss = 0.256879
I0626 14:24:32.245785  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:24:32.245792  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379737 (* 1 = 0.0379737 loss)
I0626 14:24:32.245796  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0322589 (* 1 = 0.0322589 loss)
I0626 14:24:32.245800  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000729013 (* 1 = 0.000729013 loss)
I0626 14:24:32.245803  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00616991 (* 1 = 0.00616991 loss)
I0626 14:24:32.245808  4216 sgd_solver.cpp:106] Iteration 18120, lr = 0.0002
I0626 14:26:17.370887  4216 solver.cpp:228] Iteration 18140, loss = 0.0684667
I0626 14:26:17.370915  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:26:17.370925  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00177997 (* 1 = 0.00177997 loss)
I0626 14:26:17.370931  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0305753 (* 1 = 0.0305753 loss)
I0626 14:26:17.370937  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00058841 (* 1 = 0.00058841 loss)
I0626 14:26:17.370944  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00863829 (* 1 = 0.00863829 loss)
I0626 14:26:17.370950  4216 sgd_solver.cpp:106] Iteration 18140, lr = 0.0002
I0626 14:28:02.517940  4216 solver.cpp:228] Iteration 18160, loss = 0.140135
I0626 14:28:02.517962  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:28:02.517969  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176367 (* 1 = 0.0176367 loss)
I0626 14:28:02.517972  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0499592 (* 1 = 0.0499592 loss)
I0626 14:28:02.517976  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010437 (* 1 = 0.010437 loss)
I0626 14:28:02.517979  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118693 (* 1 = 0.0118693 loss)
I0626 14:28:02.517984  4216 sgd_solver.cpp:106] Iteration 18160, lr = 0.0002
I0626 14:29:47.654594  4216 solver.cpp:228] Iteration 18180, loss = 0.160989
I0626 14:29:47.654620  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:29:47.654628  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0375433 (* 1 = 0.0375433 loss)
I0626 14:29:47.654633  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0610759 (* 1 = 0.0610759 loss)
I0626 14:29:47.654637  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125004 (* 1 = 0.00125004 loss)
I0626 14:29:47.654641  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00395763 (* 1 = 0.00395763 loss)
I0626 14:29:47.654647  4216 sgd_solver.cpp:106] Iteration 18180, lr = 0.0002
speed: 5.259s / iter
I0626 14:31:32.745949  4216 solver.cpp:228] Iteration 18200, loss = 0.215539
I0626 14:31:32.745971  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 14:31:32.745978  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.14217 (* 1 = 0.14217 loss)
I0626 14:31:32.745983  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.198919 (* 1 = 0.198919 loss)
I0626 14:31:32.745986  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122748 (* 1 = 0.0122748 loss)
I0626 14:31:32.745990  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0731756 (* 1 = 0.0731756 loss)
I0626 14:31:32.745995  4216 sgd_solver.cpp:106] Iteration 18200, lr = 0.0002
I0626 14:33:17.880764  4216 solver.cpp:228] Iteration 18220, loss = 0.143626
I0626 14:33:17.880787  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:33:17.880797  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526785 (* 1 = 0.0526785 loss)
I0626 14:33:17.880805  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.102302 (* 1 = 0.102302 loss)
I0626 14:33:17.880811  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00488648 (* 1 = 0.00488648 loss)
I0626 14:33:17.880818  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138182 (* 1 = 0.0138182 loss)
I0626 14:33:17.880825  4216 sgd_solver.cpp:106] Iteration 18220, lr = 0.0002
I0626 14:35:03.006745  4216 solver.cpp:228] Iteration 18240, loss = 0.203929
I0626 14:35:03.006773  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:35:03.006784  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0370188 (* 1 = 0.0370188 loss)
I0626 14:35:03.006793  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0644877 (* 1 = 0.0644877 loss)
I0626 14:35:03.006799  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000246678 (* 1 = 0.000246678 loss)
I0626 14:35:03.006808  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112864 (* 1 = 0.0112864 loss)
I0626 14:35:03.006819  4216 sgd_solver.cpp:106] Iteration 18240, lr = 0.0002
I0626 14:36:48.140271  4216 solver.cpp:228] Iteration 18260, loss = 0.253622
I0626 14:36:48.140305  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:36:48.140316  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0242401 (* 1 = 0.0242401 loss)
I0626 14:36:48.140322  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0325707 (* 1 = 0.0325707 loss)
I0626 14:36:48.140328  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143509 (* 1 = 0.00143509 loss)
I0626 14:36:48.140336  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00222102 (* 1 = 0.00222102 loss)
I0626 14:36:48.140347  4216 sgd_solver.cpp:106] Iteration 18260, lr = 0.0002
I0626 14:38:33.202030  4216 solver.cpp:228] Iteration 18280, loss = 0.13878
I0626 14:38:33.202054  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:38:33.202061  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605146 (* 1 = 0.0605146 loss)
I0626 14:38:33.202066  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0511528 (* 1 = 0.0511528 loss)
I0626 14:38:33.202069  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00910928 (* 1 = 0.00910928 loss)
I0626 14:38:33.202073  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127073 (* 1 = 0.0127073 loss)
I0626 14:38:33.202078  4216 sgd_solver.cpp:106] Iteration 18280, lr = 0.0002
I0626 14:40:18.317683  4216 solver.cpp:228] Iteration 18300, loss = 0.303137
I0626 14:40:18.317706  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:40:18.317713  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593563 (* 1 = 0.0593563 loss)
I0626 14:40:18.317716  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.122734 (* 1 = 0.122734 loss)
I0626 14:40:18.317720  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00991653 (* 1 = 0.00991653 loss)
I0626 14:40:18.317724  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134324 (* 1 = 0.0134324 loss)
I0626 14:40:18.317729  4216 sgd_solver.cpp:106] Iteration 18300, lr = 0.0002
I0626 14:42:03.461355  4216 solver.cpp:228] Iteration 18320, loss = 0.0881532
I0626 14:42:03.461380  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 14:42:03.461388  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682984 (* 1 = 0.0682984 loss)
I0626 14:42:03.461392  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.187259 (* 1 = 0.187259 loss)
I0626 14:42:03.461396  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000493361 (* 1 = 0.000493361 loss)
I0626 14:42:03.461400  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114292 (* 1 = 0.0114292 loss)
I0626 14:42:03.461405  4216 sgd_solver.cpp:106] Iteration 18320, lr = 0.0002
I0626 14:43:48.606808  4216 solver.cpp:228] Iteration 18340, loss = 0.140627
I0626 14:43:48.606832  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:43:48.606840  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.056179 (* 1 = 0.056179 loss)
I0626 14:43:48.606844  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0746653 (* 1 = 0.0746653 loss)
I0626 14:43:48.606848  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00053253 (* 1 = 0.00053253 loss)
I0626 14:43:48.606851  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00659663 (* 1 = 0.00659663 loss)
I0626 14:43:48.606855  4216 sgd_solver.cpp:106] Iteration 18340, lr = 0.0002
I0626 14:45:33.732647  4216 solver.cpp:228] Iteration 18360, loss = 0.12894
I0626 14:45:33.732672  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 14:45:33.732681  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245081 (* 1 = 0.0245081 loss)
I0626 14:45:33.732688  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0771494 (* 1 = 0.0771494 loss)
I0626 14:45:33.732694  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00188439 (* 1 = 0.00188439 loss)
I0626 14:45:33.732700  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00805711 (* 1 = 0.00805711 loss)
I0626 14:45:33.732708  4216 sgd_solver.cpp:106] Iteration 18360, lr = 0.0002
I0626 14:47:18.792609  4216 solver.cpp:228] Iteration 18380, loss = 0.14862
I0626 14:47:18.792634  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 14:47:18.792642  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0784948 (* 1 = 0.0784948 loss)
I0626 14:47:18.792645  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.221068 (* 1 = 0.221068 loss)
I0626 14:47:18.792649  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119086 (* 1 = 0.00119086 loss)
I0626 14:47:18.792654  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261361 (* 1 = 0.0261361 loss)
I0626 14:47:18.792659  4216 sgd_solver.cpp:106] Iteration 18380, lr = 0.0002
speed: 5.259s / iter
I0626 14:49:03.934026  4216 solver.cpp:228] Iteration 18400, loss = 0.2728
I0626 14:49:03.934049  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 14:49:03.934056  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.072957 (* 1 = 0.072957 loss)
I0626 14:49:03.934060  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.102358 (* 1 = 0.102358 loss)
I0626 14:49:03.934063  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119841 (* 1 = 0.0119841 loss)
I0626 14:49:03.934067  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338599 (* 1 = 0.0338599 loss)
I0626 14:49:03.934072  4216 sgd_solver.cpp:106] Iteration 18400, lr = 0.0002
I0626 14:50:49.020968  4216 solver.cpp:228] Iteration 18420, loss = 0.328916
I0626 14:50:49.020994  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 14:50:49.021005  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.155401 (* 1 = 0.155401 loss)
I0626 14:50:49.021011  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.250025 (* 1 = 0.250025 loss)
I0626 14:50:49.021018  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134816 (* 1 = 0.00134816 loss)
I0626 14:50:49.021024  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0413977 (* 1 = 0.0413977 loss)
I0626 14:50:49.021031  4216 sgd_solver.cpp:106] Iteration 18420, lr = 0.0002
I0626 14:52:34.142050  4216 solver.cpp:228] Iteration 18440, loss = 0.202432
I0626 14:52:34.142074  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 14:52:34.142081  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.209204 (* 1 = 0.209204 loss)
I0626 14:52:34.142086  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.418316 (* 1 = 0.418316 loss)
I0626 14:52:34.142091  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115788 (* 1 = 0.0115788 loss)
I0626 14:52:34.142094  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0623908 (* 1 = 0.0623908 loss)
I0626 14:52:34.142099  4216 sgd_solver.cpp:106] Iteration 18440, lr = 0.0002
I0626 14:54:19.307349  4216 solver.cpp:228] Iteration 18460, loss = 0.186601
I0626 14:54:19.307374  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 14:54:19.307381  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.100517 (* 1 = 0.100517 loss)
I0626 14:54:19.307385  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.135614 (* 1 = 0.135614 loss)
I0626 14:54:19.307390  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000350892 (* 1 = 0.000350892 loss)
I0626 14:54:19.307394  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314809 (* 1 = 0.0314809 loss)
I0626 14:54:19.307400  4216 sgd_solver.cpp:106] Iteration 18460, lr = 0.0002
I0626 14:56:04.413096  4216 solver.cpp:228] Iteration 18480, loss = 0.206204
I0626 14:56:04.413122  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:56:04.413130  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0487802 (* 1 = 0.0487802 loss)
I0626 14:56:04.413134  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0322991 (* 1 = 0.0322991 loss)
I0626 14:56:04.413138  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.10566e-05 (* 1 = 8.10566e-05 loss)
I0626 14:56:04.413142  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137765 (* 1 = 0.0137765 loss)
I0626 14:56:04.413148  4216 sgd_solver.cpp:106] Iteration 18480, lr = 0.0002
I0626 14:57:49.785313  4216 solver.cpp:228] Iteration 18500, loss = 0.280357
I0626 14:57:49.785338  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 14:57:49.785346  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.118569 (* 1 = 0.118569 loss)
I0626 14:57:49.785351  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.221911 (* 1 = 0.221911 loss)
I0626 14:57:49.785354  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778357 (* 1 = 0.00778357 loss)
I0626 14:57:49.785358  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319495 (* 1 = 0.0319495 loss)
I0626 14:57:49.785363  4216 sgd_solver.cpp:106] Iteration 18500, lr = 0.0002
I0626 14:59:35.632666  4216 solver.cpp:228] Iteration 18520, loss = 0.203306
I0626 14:59:35.632690  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:59:35.632697  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.132432 (* 1 = 0.132432 loss)
I0626 14:59:35.632702  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.159158 (* 1 = 0.159158 loss)
I0626 14:59:35.632706  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00586911 (* 1 = 0.00586911 loss)
I0626 14:59:35.632710  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372032 (* 1 = 0.0372032 loss)
I0626 14:59:35.632715  4216 sgd_solver.cpp:106] Iteration 18520, lr = 0.0002
I0626 15:01:21.109606  4216 solver.cpp:228] Iteration 18540, loss = 0.295503
I0626 15:01:21.109630  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:01:21.109638  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460051 (* 1 = 0.0460051 loss)
I0626 15:01:21.109642  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0809003 (* 1 = 0.0809003 loss)
I0626 15:01:21.109647  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000135246 (* 1 = 0.000135246 loss)
I0626 15:01:21.109652  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00877022 (* 1 = 0.00877022 loss)
I0626 15:01:21.109655  4216 sgd_solver.cpp:106] Iteration 18540, lr = 0.0002
I0626 15:03:06.512899  4216 solver.cpp:228] Iteration 18560, loss = 0.179792
I0626 15:03:06.512923  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 15:03:06.512930  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173406 (* 1 = 0.0173406 loss)
I0626 15:03:06.512934  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00535957 (* 1 = 0.00535957 loss)
I0626 15:03:06.512938  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000147715 (* 1 = 0.000147715 loss)
I0626 15:03:06.512943  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00370575 (* 1 = 0.00370575 loss)
I0626 15:03:06.512946  4216 sgd_solver.cpp:106] Iteration 18560, lr = 0.0002
I0626 15:04:52.309712  4216 solver.cpp:228] Iteration 18580, loss = 0.210981
I0626 15:04:52.309741  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 15:04:52.309748  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.117297 (* 1 = 0.117297 loss)
I0626 15:04:52.309752  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.233132 (* 1 = 0.233132 loss)
I0626 15:04:52.309756  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00440667 (* 1 = 0.00440667 loss)
I0626 15:04:52.309759  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219348 (* 1 = 0.0219348 loss)
I0626 15:04:52.309764  4216 sgd_solver.cpp:106] Iteration 18580, lr = 0.0002
speed: 5.259s / iter
I0626 15:06:38.976276  4216 solver.cpp:228] Iteration 18600, loss = 0.175269
I0626 15:06:38.976305  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:06:38.976311  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186129 (* 1 = 0.0186129 loss)
I0626 15:06:38.976315  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.058618 (* 1 = 0.058618 loss)
I0626 15:06:38.976320  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0076649 (* 1 = 0.0076649 loss)
I0626 15:06:38.976323  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00412668 (* 1 = 0.00412668 loss)
I0626 15:06:38.976328  4216 sgd_solver.cpp:106] Iteration 18600, lr = 0.0002
I0626 15:08:24.838570  4216 solver.cpp:228] Iteration 18620, loss = 0.155732
I0626 15:08:24.838598  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 15:08:24.838606  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0522881 (* 1 = 0.0522881 loss)
I0626 15:08:24.838611  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.103663 (* 1 = 0.103663 loss)
I0626 15:08:24.838616  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000541776 (* 1 = 0.000541776 loss)
I0626 15:08:24.838621  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00944706 (* 1 = 0.00944706 loss)
I0626 15:08:24.838626  4216 sgd_solver.cpp:106] Iteration 18620, lr = 0.0002
I0626 15:10:10.566819  4216 solver.cpp:228] Iteration 18640, loss = 0.232449
I0626 15:10:10.566844  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:10:10.566853  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00751337 (* 1 = 0.00751337 loss)
I0626 15:10:10.566856  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0283234 (* 1 = 0.0283234 loss)
I0626 15:10:10.566864  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013418 (* 1 = 0.0013418 loss)
I0626 15:10:10.566869  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00232724 (* 1 = 0.00232724 loss)
I0626 15:10:10.566874  4216 sgd_solver.cpp:106] Iteration 18640, lr = 0.0002
I0626 15:11:56.044610  4216 solver.cpp:228] Iteration 18660, loss = 0.116707
I0626 15:11:56.044634  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:11:56.044641  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0598032 (* 1 = 0.0598032 loss)
I0626 15:11:56.044646  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121363 (* 1 = 0.121363 loss)
I0626 15:11:56.044651  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101072 (* 1 = 0.0101072 loss)
I0626 15:11:56.044653  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0385168 (* 1 = 0.0385168 loss)
I0626 15:11:56.044659  4216 sgd_solver.cpp:106] Iteration 18660, lr = 0.0002
I0626 15:13:41.819484  4216 solver.cpp:228] Iteration 18680, loss = 0.251798
I0626 15:13:41.819507  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 15:13:41.819516  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.174249 (* 1 = 0.174249 loss)
I0626 15:13:41.819522  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.28495 (* 1 = 0.28495 loss)
I0626 15:13:41.819528  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0085075 (* 1 = 0.0085075 loss)
I0626 15:13:41.819535  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368821 (* 1 = 0.0368821 loss)
I0626 15:13:41.819540  4216 sgd_solver.cpp:106] Iteration 18680, lr = 0.0002
I0626 15:15:28.930841  4216 solver.cpp:228] Iteration 18700, loss = 0.0938776
I0626 15:15:28.930871  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:15:28.930881  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293937 (* 1 = 0.0293937 loss)
I0626 15:15:28.930886  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0164012 (* 1 = 0.0164012 loss)
I0626 15:15:28.930891  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202236 (* 1 = 0.00202236 loss)
I0626 15:15:28.930894  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00532059 (* 1 = 0.00532059 loss)
I0626 15:15:28.930899  4216 sgd_solver.cpp:106] Iteration 18700, lr = 0.0002
I0626 15:17:16.903882  4216 solver.cpp:228] Iteration 18720, loss = 0.187547
I0626 15:17:16.903904  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:17:16.903913  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.010365 (* 1 = 0.010365 loss)
I0626 15:17:16.903916  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0449509 (* 1 = 0.0449509 loss)
I0626 15:17:16.903920  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000158979 (* 1 = 0.000158979 loss)
I0626 15:17:16.903924  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00307361 (* 1 = 0.00307361 loss)
I0626 15:17:16.903929  4216 sgd_solver.cpp:106] Iteration 18720, lr = 0.0002
I0626 15:19:04.042546  4216 solver.cpp:228] Iteration 18740, loss = 0.217797
I0626 15:19:04.042569  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 15:19:04.042577  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542632 (* 1 = 0.0542632 loss)
I0626 15:19:04.042582  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.128769 (* 1 = 0.128769 loss)
I0626 15:19:04.042584  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133272 (* 1 = 0.00133272 loss)
I0626 15:19:04.042588  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263719 (* 1 = 0.0263719 loss)
I0626 15:19:04.042593  4216 sgd_solver.cpp:106] Iteration 18740, lr = 0.0002
I0626 15:20:51.634847  4216 solver.cpp:228] Iteration 18760, loss = 0.107139
I0626 15:20:51.634878  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 15:20:51.634886  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0787313 (* 1 = 0.0787313 loss)
I0626 15:20:51.634891  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.106075 (* 1 = 0.106075 loss)
I0626 15:20:51.634894  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00420266 (* 1 = 0.00420266 loss)
I0626 15:20:51.634897  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169624 (* 1 = 0.0169624 loss)
I0626 15:20:51.634903  4216 sgd_solver.cpp:106] Iteration 18760, lr = 0.0002
I0626 15:22:39.277662  4216 solver.cpp:228] Iteration 18780, loss = 0.289167
I0626 15:22:39.277688  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:22:39.277695  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160555 (* 1 = 0.0160555 loss)
I0626 15:22:39.277699  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0204389 (* 1 = 0.0204389 loss)
I0626 15:22:39.277704  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00536101 (* 1 = 0.00536101 loss)
I0626 15:22:39.277706  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00683983 (* 1 = 0.00683983 loss)
I0626 15:22:39.277711  4216 sgd_solver.cpp:106] Iteration 18780, lr = 0.0002
speed: 5.260s / iter
I0626 15:24:26.057200  4216 solver.cpp:228] Iteration 18800, loss = 0.14503
I0626 15:24:26.057224  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:24:26.057231  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.101249 (* 1 = 0.101249 loss)
I0626 15:24:26.057235  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0945335 (* 1 = 0.0945335 loss)
I0626 15:24:26.057240  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205366 (* 1 = 0.00205366 loss)
I0626 15:24:26.057242  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202711 (* 1 = 0.0202711 loss)
I0626 15:24:26.057247  4216 sgd_solver.cpp:106] Iteration 18800, lr = 0.0002
I0626 15:26:13.585950  4216 solver.cpp:228] Iteration 18820, loss = 0.122716
I0626 15:26:13.585978  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 15:26:13.585985  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0239003 (* 1 = 0.0239003 loss)
I0626 15:26:13.585989  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0288218 (* 1 = 0.0288218 loss)
I0626 15:26:13.585994  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000147866 (* 1 = 0.000147866 loss)
I0626 15:26:13.585997  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00866756 (* 1 = 0.00866756 loss)
I0626 15:26:13.586004  4216 sgd_solver.cpp:106] Iteration 18820, lr = 0.0002
I0626 15:28:03.920437  4216 solver.cpp:228] Iteration 18840, loss = 0.373529
I0626 15:28:03.920464  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:28:03.920470  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599267 (* 1 = 0.0599267 loss)
I0626 15:28:03.920475  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0715157 (* 1 = 0.0715157 loss)
I0626 15:28:03.920478  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382177 (* 1 = 0.00382177 loss)
I0626 15:28:03.920481  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.061304 (* 1 = 0.061304 loss)
I0626 15:28:03.920487  4216 sgd_solver.cpp:106] Iteration 18840, lr = 0.0002
I0626 15:29:52.031162  4216 solver.cpp:228] Iteration 18860, loss = 0.238997
I0626 15:29:52.031190  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 15:29:52.031198  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353683 (* 1 = 0.0353683 loss)
I0626 15:29:52.031203  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0792764 (* 1 = 0.0792764 loss)
I0626 15:29:52.031208  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00198766 (* 1 = 0.00198766 loss)
I0626 15:29:52.031211  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00468511 (* 1 = 0.00468511 loss)
I0626 15:29:52.031217  4216 sgd_solver.cpp:106] Iteration 18860, lr = 0.0002
I0626 15:31:51.945165  4216 solver.cpp:228] Iteration 18880, loss = 0.164037
I0626 15:31:51.945194  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:31:51.945201  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459916 (* 1 = 0.0459916 loss)
I0626 15:31:51.945206  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0766149 (* 1 = 0.0766149 loss)
I0626 15:31:51.945210  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000606208 (* 1 = 0.000606208 loss)
I0626 15:31:51.945215  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100624 (* 1 = 0.0100624 loss)
I0626 15:31:51.945221  4216 sgd_solver.cpp:106] Iteration 18880, lr = 0.0002
I0626 15:33:51.010174  4216 solver.cpp:228] Iteration 18900, loss = 0.131966
I0626 15:33:51.010207  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:33:51.010221  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0424656 (* 1 = 0.0424656 loss)
I0626 15:33:51.010227  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0596208 (* 1 = 0.0596208 loss)
I0626 15:33:51.010232  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000525083 (* 1 = 0.000525083 loss)
I0626 15:33:51.010239  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00205293 (* 1 = 0.00205293 loss)
I0626 15:33:51.010246  4216 sgd_solver.cpp:106] Iteration 18900, lr = 0.0002
I0626 15:35:51.888463  4216 solver.cpp:228] Iteration 18920, loss = 0.128893
I0626 15:35:51.888497  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:35:51.888506  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240682 (* 1 = 0.0240682 loss)
I0626 15:35:51.888511  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0312445 (* 1 = 0.0312445 loss)
I0626 15:35:51.888519  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.41322e-05 (* 1 = 9.41322e-05 loss)
I0626 15:35:51.888525  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00741818 (* 1 = 0.00741818 loss)
I0626 15:35:51.888532  4216 sgd_solver.cpp:106] Iteration 18920, lr = 0.0002
I0626 15:37:52.535935  4216 solver.cpp:228] Iteration 18940, loss = 0.114513
I0626 15:37:52.535964  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 15:37:52.535972  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340196 (* 1 = 0.0340196 loss)
I0626 15:37:52.535977  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0650433 (* 1 = 0.0650433 loss)
I0626 15:37:52.535981  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127128 (* 1 = 0.00127128 loss)
I0626 15:37:52.535985  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189451 (* 1 = 0.0189451 loss)
I0626 15:37:52.535991  4216 sgd_solver.cpp:106] Iteration 18940, lr = 0.0002
I0626 15:39:52.380053  4216 solver.cpp:228] Iteration 18960, loss = 0.15477
I0626 15:39:52.380080  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 15:39:52.380090  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325096 (* 1 = 0.0325096 loss)
I0626 15:39:52.380096  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.104424 (* 1 = 0.104424 loss)
I0626 15:39:52.380102  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167474 (* 1 = 0.00167474 loss)
I0626 15:39:52.380108  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201429 (* 1 = 0.0201429 loss)
I0626 15:39:52.380116  4216 sgd_solver.cpp:106] Iteration 18960, lr = 0.0002
I0626 15:41:52.279367  4216 solver.cpp:228] Iteration 18980, loss = 0.264543
I0626 15:41:52.279394  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 15:41:52.279402  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0163046 (* 1 = 0.0163046 loss)
I0626 15:41:52.279407  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00815589 (* 1 = 0.00815589 loss)
I0626 15:41:52.279410  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000317885 (* 1 = 0.000317885 loss)
I0626 15:41:52.279413  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00323495 (* 1 = 0.00323495 loss)
I0626 15:41:52.279419  4216 sgd_solver.cpp:106] Iteration 18980, lr = 0.0002
speed: 5.266s / iter
I0626 15:43:43.292222  4216 solver.cpp:228] Iteration 19000, loss = 0.212319
I0626 15:43:43.292251  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:43:43.292259  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374277 (* 1 = 0.0374277 loss)
I0626 15:43:43.292265  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0224726 (* 1 = 0.0224726 loss)
I0626 15:43:43.292269  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017346 (* 1 = 0.0017346 loss)
I0626 15:43:43.292273  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011549 (* 1 = 0.011549 loss)
I0626 15:43:43.292279  4216 sgd_solver.cpp:106] Iteration 19000, lr = 0.0002
I0626 15:45:38.914762  4216 solver.cpp:228] Iteration 19020, loss = 0.215333
I0626 15:45:38.914789  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:45:38.914798  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188351 (* 1 = 0.0188351 loss)
I0626 15:45:38.914803  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0472113 (* 1 = 0.0472113 loss)
I0626 15:45:38.914809  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000257374 (* 1 = 0.000257374 loss)
I0626 15:45:38.914813  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00760219 (* 1 = 0.00760219 loss)
I0626 15:45:38.914819  4216 sgd_solver.cpp:106] Iteration 19020, lr = 0.0002
I0626 15:47:37.659459  4216 solver.cpp:228] Iteration 19040, loss = 0.287373
I0626 15:47:37.659484  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:47:37.659494  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268498 (* 1 = 0.0268498 loss)
I0626 15:47:37.659500  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0374646 (* 1 = 0.0374646 loss)
I0626 15:47:37.659505  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.128506 (* 1 = 0.128506 loss)
I0626 15:47:37.659512  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356182 (* 1 = 0.0356182 loss)
I0626 15:47:37.659518  4216 sgd_solver.cpp:106] Iteration 19040, lr = 0.0002
I0626 15:49:33.568579  4216 solver.cpp:228] Iteration 19060, loss = 0.254772
I0626 15:49:33.568609  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:49:33.568619  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340003 (* 1 = 0.0340003 loss)
I0626 15:49:33.568624  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.066681 (* 1 = 0.066681 loss)
I0626 15:49:33.568627  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000198486 (* 1 = 0.000198486 loss)
I0626 15:49:33.568631  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00875903 (* 1 = 0.00875903 loss)
I0626 15:49:33.568636  4216 sgd_solver.cpp:106] Iteration 19060, lr = 0.0002
I0626 15:51:30.300592  4216 solver.cpp:228] Iteration 19080, loss = 0.209107
I0626 15:51:30.300618  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 15:51:30.300626  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147455 (* 1 = 0.0147455 loss)
I0626 15:51:30.300631  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.036378 (* 1 = 0.036378 loss)
I0626 15:51:30.300634  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00166264 (* 1 = 0.00166264 loss)
I0626 15:51:30.300637  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00778109 (* 1 = 0.00778109 loss)
I0626 15:51:30.300643  4216 sgd_solver.cpp:106] Iteration 19080, lr = 0.0002
I0626 15:53:28.217427  4216 solver.cpp:228] Iteration 19100, loss = 0.154729
I0626 15:53:28.217456  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:53:28.217465  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0519413 (* 1 = 0.0519413 loss)
I0626 15:53:28.217473  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0700095 (* 1 = 0.0700095 loss)
I0626 15:53:28.217478  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00056735 (* 1 = 0.00056735 loss)
I0626 15:53:28.217483  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194179 (* 1 = 0.0194179 loss)
I0626 15:53:28.217491  4216 sgd_solver.cpp:106] Iteration 19100, lr = 0.0002
I0626 15:55:24.489675  4216 solver.cpp:228] Iteration 19120, loss = 0.198183
I0626 15:55:24.489704  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:55:24.489712  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0313611 (* 1 = 0.0313611 loss)
I0626 15:55:24.489717  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0705301 (* 1 = 0.0705301 loss)
I0626 15:55:24.489722  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158585 (* 1 = 0.00158585 loss)
I0626 15:55:24.489725  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00632865 (* 1 = 0.00632865 loss)
I0626 15:55:24.489730  4216 sgd_solver.cpp:106] Iteration 19120, lr = 0.0002
I0626 15:57:14.097203  4216 solver.cpp:228] Iteration 19140, loss = 0.280092
I0626 15:57:14.097226  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 15:57:14.097234  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0832398 (* 1 = 0.0832398 loss)
I0626 15:57:14.097237  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.134769 (* 1 = 0.134769 loss)
I0626 15:57:14.097240  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00962057 (* 1 = 0.00962057 loss)
I0626 15:57:14.097244  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0320553 (* 1 = 0.0320553 loss)
I0626 15:57:14.097249  4216 sgd_solver.cpp:106] Iteration 19140, lr = 0.0002
I0626 15:59:13.244700  4216 solver.cpp:228] Iteration 19160, loss = 0.169006
I0626 15:59:13.244729  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 15:59:13.244735  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104129 (* 1 = 0.104129 loss)
I0626 15:59:13.244740  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.181946 (* 1 = 0.181946 loss)
I0626 15:59:13.244743  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00994367 (* 1 = 0.00994367 loss)
I0626 15:59:13.244747  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0343693 (* 1 = 0.0343693 loss)
I0626 15:59:13.244752  4216 sgd_solver.cpp:106] Iteration 19160, lr = 0.0002
I0626 16:01:12.746857  4216 solver.cpp:228] Iteration 19180, loss = 0.129388
I0626 16:01:12.746891  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 16:01:12.746901  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468488 (* 1 = 0.0468488 loss)
I0626 16:01:12.746906  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.101141 (* 1 = 0.101141 loss)
I0626 16:01:12.746912  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00210435 (* 1 = 0.00210435 loss)
I0626 16:01:12.746918  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235393 (* 1 = 0.0235393 loss)
I0626 16:01:12.746924  4216 sgd_solver.cpp:106] Iteration 19180, lr = 0.0002
speed: 5.272s / iter
I0626 16:03:10.299151  4216 solver.cpp:228] Iteration 19200, loss = 0.114684
I0626 16:03:10.299177  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 16:03:10.299185  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174287 (* 1 = 0.0174287 loss)
I0626 16:03:10.299188  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0799891 (* 1 = 0.0799891 loss)
I0626 16:03:10.299192  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00290709 (* 1 = 0.00290709 loss)
I0626 16:03:10.299196  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106385 (* 1 = 0.0106385 loss)
I0626 16:03:10.299201  4216 sgd_solver.cpp:106] Iteration 19200, lr = 0.0002
I0626 16:05:05.752316  4216 solver.cpp:228] Iteration 19220, loss = 0.297206
I0626 16:05:05.752344  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 16:05:05.752351  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0704742 (* 1 = 0.0704742 loss)
I0626 16:05:05.752357  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.245705 (* 1 = 0.245705 loss)
I0626 16:05:05.752359  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188376 (* 1 = 0.0188376 loss)
I0626 16:05:05.752363  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153516 (* 1 = 0.153516 loss)
I0626 16:05:05.752368  4216 sgd_solver.cpp:106] Iteration 19220, lr = 0.0002
I0626 16:07:03.785974  4216 solver.cpp:228] Iteration 19240, loss = 0.294246
I0626 16:07:03.786003  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 16:07:03.786012  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0767231 (* 1 = 0.0767231 loss)
I0626 16:07:03.786017  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.158791 (* 1 = 0.158791 loss)
I0626 16:07:03.786021  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00077781 (* 1 = 0.00077781 loss)
I0626 16:07:03.786026  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00789133 (* 1 = 0.00789133 loss)
I0626 16:07:03.786031  4216 sgd_solver.cpp:106] Iteration 19240, lr = 0.0002
I0626 16:09:03.634482  4216 solver.cpp:228] Iteration 19260, loss = 0.149269
I0626 16:09:03.634512  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 16:09:03.634521  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708289 (* 1 = 0.0708289 loss)
I0626 16:09:03.634526  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.128073 (* 1 = 0.128073 loss)
I0626 16:09:03.634531  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00775091 (* 1 = 0.00775091 loss)
I0626 16:09:03.634536  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182016 (* 1 = 0.0182016 loss)
I0626 16:09:03.634542  4216 sgd_solver.cpp:106] Iteration 19260, lr = 0.0002
I0626 16:11:03.786660  4216 solver.cpp:228] Iteration 19280, loss = 0.210221
I0626 16:11:03.786697  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 16:11:03.786708  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0567871 (* 1 = 0.0567871 loss)
I0626 16:11:03.786715  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.123789 (* 1 = 0.123789 loss)
I0626 16:11:03.786721  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00185625 (* 1 = 0.00185625 loss)
I0626 16:11:03.786728  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00773076 (* 1 = 0.00773076 loss)
I0626 16:11:03.786734  4216 sgd_solver.cpp:106] Iteration 19280, lr = 0.0002
I0626 16:13:04.021939  4216 solver.cpp:228] Iteration 19300, loss = 0.186318
I0626 16:13:04.021973  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:13:04.021986  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381658 (* 1 = 0.0381658 loss)
I0626 16:13:04.021993  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0977283 (* 1 = 0.0977283 loss)
I0626 16:13:04.021999  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169942 (* 1 = 0.00169942 loss)
I0626 16:13:04.022006  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00837211 (* 1 = 0.00837211 loss)
I0626 16:13:04.022014  4216 sgd_solver.cpp:106] Iteration 19300, lr = 0.0002
I0626 16:15:04.008266  4216 solver.cpp:228] Iteration 19320, loss = 0.209757
I0626 16:15:04.008298  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 16:15:04.008307  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.202158 (* 1 = 0.202158 loss)
I0626 16:15:04.008314  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.348617 (* 1 = 0.348617 loss)
I0626 16:15:04.008321  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271993 (* 1 = 0.00271993 loss)
I0626 16:15:04.008327  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297704 (* 1 = 0.0297704 loss)
I0626 16:15:04.008334  4216 sgd_solver.cpp:106] Iteration 19320, lr = 0.0002
I0626 16:17:03.567723  4216 solver.cpp:228] Iteration 19340, loss = 0.447327
I0626 16:17:03.567757  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 16:17:03.567765  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.124837 (* 1 = 0.124837 loss)
I0626 16:17:03.567770  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.208774 (* 1 = 0.208774 loss)
I0626 16:17:03.567776  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171178 (* 1 = 0.00171178 loss)
I0626 16:17:03.567780  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126087 (* 1 = 0.0126087 loss)
I0626 16:17:03.567786  4216 sgd_solver.cpp:106] Iteration 19340, lr = 0.0002
I0626 16:19:02.796820  4216 solver.cpp:228] Iteration 19360, loss = 0.245095
I0626 16:19:02.796849  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:19:02.796857  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0999888 (* 1 = 0.0999888 loss)
I0626 16:19:02.796864  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.114318 (* 1 = 0.114318 loss)
I0626 16:19:02.796870  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000552322 (* 1 = 0.000552322 loss)
I0626 16:19:02.796875  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335962 (* 1 = 0.0335962 loss)
I0626 16:19:02.796881  4216 sgd_solver.cpp:106] Iteration 19360, lr = 0.0002
I0626 16:20:58.223446  4216 solver.cpp:228] Iteration 19380, loss = 0.150624
I0626 16:20:58.223471  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 16:20:58.223480  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882853 (* 1 = 0.0882853 loss)
I0626 16:20:58.223486  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129354 (* 1 = 0.129354 loss)
I0626 16:20:58.223492  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000345614 (* 1 = 0.000345614 loss)
I0626 16:20:58.223498  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197596 (* 1 = 0.0197596 loss)
I0626 16:20:58.223505  4216 sgd_solver.cpp:106] Iteration 19380, lr = 0.0002
speed: 5.278s / iter
I0626 16:22:51.557785  4216 solver.cpp:228] Iteration 19400, loss = 0.243167
I0626 16:22:51.557811  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 16:22:51.557817  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.143529 (* 1 = 0.143529 loss)
I0626 16:22:51.557821  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.260145 (* 1 = 0.260145 loss)
I0626 16:22:51.557826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189388 (* 1 = 0.00189388 loss)
I0626 16:22:51.557829  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124116 (* 1 = 0.0124116 loss)
I0626 16:22:51.557834  4216 sgd_solver.cpp:106] Iteration 19400, lr = 0.0002
I0626 16:24:52.182118  4216 solver.cpp:228] Iteration 19420, loss = 0.159351
I0626 16:24:52.182145  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:24:52.182154  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589401 (* 1 = 0.0589401 loss)
I0626 16:24:52.182160  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0684066 (* 1 = 0.0684066 loss)
I0626 16:24:52.182166  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119958 (* 1 = 0.00119958 loss)
I0626 16:24:52.182173  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139665 (* 1 = 0.0139665 loss)
I0626 16:24:52.182193  4216 sgd_solver.cpp:106] Iteration 19420, lr = 0.0002
I0626 16:26:51.157126  4216 solver.cpp:228] Iteration 19440, loss = 0.221482
I0626 16:26:51.157160  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 16:26:51.157171  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0017516 (* 1 = 0.0017516 loss)
I0626 16:26:51.157176  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0156228 (* 1 = 0.0156228 loss)
I0626 16:26:51.157182  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00390516 (* 1 = 0.00390516 loss)
I0626 16:26:51.157187  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175788 (* 1 = 0.0175788 loss)
I0626 16:26:51.157194  4216 sgd_solver.cpp:106] Iteration 19440, lr = 0.0002
I0626 16:28:49.793825  4216 solver.cpp:228] Iteration 19460, loss = 0.179262
I0626 16:28:49.793854  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 16:28:49.793864  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0470603 (* 1 = 0.0470603 loss)
I0626 16:28:49.793867  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.229568 (* 1 = 0.229568 loss)
I0626 16:28:49.793871  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00123003 (* 1 = 0.00123003 loss)
I0626 16:28:49.793874  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00593714 (* 1 = 0.00593714 loss)
I0626 16:28:49.793880  4216 sgd_solver.cpp:106] Iteration 19460, lr = 0.0002
I0626 16:30:36.058039  4216 solver.cpp:228] Iteration 19480, loss = 0.145796
I0626 16:30:36.058064  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 16:30:36.058073  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0111028 (* 1 = 0.0111028 loss)
I0626 16:30:36.058076  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0173119 (* 1 = 0.0173119 loss)
I0626 16:30:36.058080  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000235708 (* 1 = 0.000235708 loss)
I0626 16:30:36.058085  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00492923 (* 1 = 0.00492923 loss)
I0626 16:30:36.058090  4216 sgd_solver.cpp:106] Iteration 19480, lr = 0.0002
I0626 16:32:22.829113  4216 solver.cpp:228] Iteration 19500, loss = 0.270427
I0626 16:32:22.829136  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 16:32:22.829144  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.248712 (* 1 = 0.248712 loss)
I0626 16:32:22.829146  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.315696 (* 1 = 0.315696 loss)
I0626 16:32:22.829150  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028771 (* 1 = 0.0028771 loss)
I0626 16:32:22.829154  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326881 (* 1 = 0.0326881 loss)
I0626 16:32:22.829159  4216 sgd_solver.cpp:106] Iteration 19500, lr = 0.0002
I0626 16:34:14.598713  4216 solver.cpp:228] Iteration 19520, loss = 0.131189
I0626 16:34:14.598757  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:34:14.598765  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178395 (* 1 = 0.0178395 loss)
I0626 16:34:14.598769  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0484731 (* 1 = 0.0484731 loss)
I0626 16:34:14.598773  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000432189 (* 1 = 0.000432189 loss)
I0626 16:34:14.598778  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0071971 (* 1 = 0.0071971 loss)
I0626 16:34:14.598783  4216 sgd_solver.cpp:106] Iteration 19520, lr = 0.0002
I0626 16:36:05.867949  4216 solver.cpp:228] Iteration 19540, loss = 0.134611
I0626 16:36:05.867979  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:36:05.867986  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0516501 (* 1 = 0.0516501 loss)
I0626 16:36:05.867991  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0690383 (* 1 = 0.0690383 loss)
I0626 16:36:05.867995  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00833535 (* 1 = 0.00833535 loss)
I0626 16:36:05.868000  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181911 (* 1 = 0.0181911 loss)
I0626 16:36:05.868005  4216 sgd_solver.cpp:106] Iteration 19540, lr = 0.0002
I0626 16:37:54.557242  4216 solver.cpp:228] Iteration 19560, loss = 0.203109
I0626 16:37:54.557266  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:37:54.557273  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0332996 (* 1 = 0.0332996 loss)
I0626 16:37:54.557278  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0744302 (* 1 = 0.0744302 loss)
I0626 16:37:54.557282  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000490684 (* 1 = 0.000490684 loss)
I0626 16:37:54.557286  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00824629 (* 1 = 0.00824629 loss)
I0626 16:37:54.557291  4216 sgd_solver.cpp:106] Iteration 19560, lr = 0.0002
I0626 16:39:41.369700  4216 solver.cpp:228] Iteration 19580, loss = 0.343741
I0626 16:39:41.369725  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 16:39:41.369735  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.014769 (* 1 = 0.014769 loss)
I0626 16:39:41.369738  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0291066 (* 1 = 0.0291066 loss)
I0626 16:39:41.369743  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000374005 (* 1 = 0.000374005 loss)
I0626 16:39:41.369747  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00626062 (* 1 = 0.00626062 loss)
I0626 16:39:41.369752  4216 sgd_solver.cpp:106] Iteration 19580, lr = 0.0002
speed: 5.281s / iter
I0626 16:41:27.998807  4216 solver.cpp:228] Iteration 19600, loss = 0.185519
I0626 16:41:27.998833  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 16:41:27.998842  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254257 (* 1 = 0.0254257 loss)
I0626 16:41:27.998845  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0645434 (* 1 = 0.0645434 loss)
I0626 16:41:27.998848  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382367 (* 1 = 0.00382367 loss)
I0626 16:41:27.998852  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130732 (* 1 = 0.0130732 loss)
I0626 16:41:27.998857  4216 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I0626 16:43:16.819387  4216 solver.cpp:228] Iteration 19620, loss = 0.20662
I0626 16:43:16.819416  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 16:43:16.819423  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0253718 (* 1 = 0.0253718 loss)
I0626 16:43:16.819428  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0466075 (* 1 = 0.0466075 loss)
I0626 16:43:16.819432  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00131896 (* 1 = 0.00131896 loss)
I0626 16:43:16.819438  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147997 (* 1 = 0.0147997 loss)
I0626 16:43:16.819444  4216 sgd_solver.cpp:106] Iteration 19620, lr = 0.0002
I0626 16:45:11.721648  4216 solver.cpp:228] Iteration 19640, loss = 0.276724
I0626 16:45:11.721686  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 16:45:11.721696  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.132641 (* 1 = 0.132641 loss)
I0626 16:45:11.721704  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.196141 (* 1 = 0.196141 loss)
I0626 16:45:11.721709  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00456227 (* 1 = 0.00456227 loss)
I0626 16:45:11.721715  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0892014 (* 1 = 0.0892014 loss)
I0626 16:45:11.721724  4216 sgd_solver.cpp:106] Iteration 19640, lr = 0.0002
I0626 16:47:02.588109  4216 solver.cpp:228] Iteration 19660, loss = 0.113008
I0626 16:47:02.588140  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:47:02.588147  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0742684 (* 1 = 0.0742684 loss)
I0626 16:47:02.588152  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0920026 (* 1 = 0.0920026 loss)
I0626 16:47:02.588156  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156606 (* 1 = 0.0156606 loss)
I0626 16:47:02.588160  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00603903 (* 1 = 0.00603903 loss)
I0626 16:47:02.588166  4216 sgd_solver.cpp:106] Iteration 19660, lr = 0.0002
I0626 16:48:53.806572  4216 solver.cpp:228] Iteration 19680, loss = 0.192175
I0626 16:48:53.806602  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:48:53.806609  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453441 (* 1 = 0.0453441 loss)
I0626 16:48:53.806614  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.073935 (* 1 = 0.073935 loss)
I0626 16:48:53.806619  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000778566 (* 1 = 0.000778566 loss)
I0626 16:48:53.806623  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00495012 (* 1 = 0.00495012 loss)
I0626 16:48:53.806629  4216 sgd_solver.cpp:106] Iteration 19680, lr = 0.0002
I0626 16:50:43.597393  4216 solver.cpp:228] Iteration 19700, loss = 0.166492
I0626 16:50:43.597421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:50:43.597430  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0425649 (* 1 = 0.0425649 loss)
I0626 16:50:43.597434  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0851843 (* 1 = 0.0851843 loss)
I0626 16:50:43.597438  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0033467 (* 1 = 0.0033467 loss)
I0626 16:50:43.597442  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113118 (* 1 = 0.0113118 loss)
I0626 16:50:43.597448  4216 sgd_solver.cpp:106] Iteration 19700, lr = 0.0002
I0626 16:52:33.373844  4216 solver.cpp:228] Iteration 19720, loss = 0.211252
I0626 16:52:33.373873  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:52:33.373881  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00577889 (* 1 = 0.00577889 loss)
I0626 16:52:33.373886  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0199125 (* 1 = 0.0199125 loss)
I0626 16:52:33.373889  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107168 (* 1 = 0.0107168 loss)
I0626 16:52:33.373893  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155021 (* 1 = 0.0155021 loss)
I0626 16:52:33.373898  4216 sgd_solver.cpp:106] Iteration 19720, lr = 0.0002
I0626 16:54:22.618449  4216 solver.cpp:228] Iteration 19740, loss = 0.126707
I0626 16:54:22.618479  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:54:22.618487  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0118123 (* 1 = 0.0118123 loss)
I0626 16:54:22.618492  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0360675 (* 1 = 0.0360675 loss)
I0626 16:54:22.618497  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000486948 (* 1 = 0.000486948 loss)
I0626 16:54:22.618501  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00346542 (* 1 = 0.00346542 loss)
I0626 16:54:22.618507  4216 sgd_solver.cpp:106] Iteration 19740, lr = 0.0002
I0626 16:56:10.411666  4216 solver.cpp:228] Iteration 19760, loss = 0.105598
I0626 16:56:10.411695  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:56:10.411701  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337134 (* 1 = 0.0337134 loss)
I0626 16:56:10.411705  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0748956 (* 1 = 0.0748956 loss)
I0626 16:56:10.411708  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141025 (* 1 = 0.00141025 loss)
I0626 16:56:10.411712  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114191 (* 1 = 0.0114191 loss)
I0626 16:56:10.411717  4216 sgd_solver.cpp:106] Iteration 19760, lr = 0.0002
I0626 16:57:57.150991  4216 solver.cpp:228] Iteration 19780, loss = 0.106716
I0626 16:57:57.151016  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:57:57.151024  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216807 (* 1 = 0.0216807 loss)
I0626 16:57:57.151028  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0686184 (* 1 = 0.0686184 loss)
I0626 16:57:57.151032  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000905737 (* 1 = 0.000905737 loss)
I0626 16:57:57.151036  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127532 (* 1 = 0.0127532 loss)
I0626 16:57:57.151042  4216 sgd_solver.cpp:106] Iteration 19780, lr = 0.0002
speed: 5.283s / iter
I0626 16:59:44.611389  4216 solver.cpp:228] Iteration 19800, loss = 0.17925
I0626 16:59:44.611413  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 16:59:44.611419  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.175921 (* 1 = 0.175921 loss)
I0626 16:59:44.611424  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.29154 (* 1 = 0.29154 loss)
I0626 16:59:44.611428  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000849217 (* 1 = 0.000849217 loss)
I0626 16:59:44.611433  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0367021 (* 1 = 0.0367021 loss)
I0626 16:59:44.611436  4216 sgd_solver.cpp:106] Iteration 19800, lr = 0.0002
I0626 17:01:33.343061  4216 solver.cpp:228] Iteration 19820, loss = 0.159059
I0626 17:01:33.343086  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 17:01:33.343092  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0986977 (* 1 = 0.0986977 loss)
I0626 17:01:33.343096  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.14403 (* 1 = 0.14403 loss)
I0626 17:01:33.343101  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226207 (* 1 = 0.0226207 loss)
I0626 17:01:33.343104  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204104 (* 1 = 0.0204104 loss)
I0626 17:01:33.343108  4216 sgd_solver.cpp:106] Iteration 19820, lr = 0.0002
I0626 17:03:20.527570  4216 solver.cpp:228] Iteration 19840, loss = 0.171948
I0626 17:03:20.527596  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 17:03:20.527603  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0457603 (* 1 = 0.0457603 loss)
I0626 17:03:20.527607  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0922697 (* 1 = 0.0922697 loss)
I0626 17:03:20.527611  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149686 (* 1 = 0.00149686 loss)
I0626 17:03:20.527614  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111594 (* 1 = 0.0111594 loss)
I0626 17:03:20.527618  4216 sgd_solver.cpp:106] Iteration 19840, lr = 0.0002
I0626 17:05:09.322122  4216 solver.cpp:228] Iteration 19860, loss = 0.214476
I0626 17:05:09.322150  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 17:05:09.322160  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.17318 (* 1 = 0.17318 loss)
I0626 17:05:09.322165  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.285043 (* 1 = 0.285043 loss)
I0626 17:05:09.322170  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00214331 (* 1 = 0.00214331 loss)
I0626 17:05:09.322175  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238218 (* 1 = 0.0238218 loss)
I0626 17:05:09.322181  4216 sgd_solver.cpp:106] Iteration 19860, lr = 0.0002
I0626 17:06:57.646176  4216 solver.cpp:228] Iteration 19880, loss = 0.171276
I0626 17:06:57.646203  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:06:57.646211  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269363 (* 1 = 0.0269363 loss)
I0626 17:06:57.646219  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.070229 (* 1 = 0.070229 loss)
I0626 17:06:57.646224  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000463284 (* 1 = 0.000463284 loss)
I0626 17:06:57.646230  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160791 (* 1 = 0.0160791 loss)
I0626 17:06:57.646237  4216 sgd_solver.cpp:106] Iteration 19880, lr = 0.0002
I0626 17:08:45.505671  4216 solver.cpp:228] Iteration 19900, loss = 0.219982
I0626 17:08:45.505697  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:08:45.505705  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00662312 (* 1 = 0.00662312 loss)
I0626 17:08:45.505710  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0407487 (* 1 = 0.0407487 loss)
I0626 17:08:45.505714  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0022088 (* 1 = 0.0022088 loss)
I0626 17:08:45.505718  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284432 (* 1 = 0.0284432 loss)
I0626 17:08:45.505723  4216 sgd_solver.cpp:106] Iteration 19900, lr = 0.0002
I0626 17:10:32.160873  4216 solver.cpp:228] Iteration 19920, loss = 0.147539
I0626 17:10:32.160898  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:10:32.160907  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0479642 (* 1 = 0.0479642 loss)
I0626 17:10:32.160910  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0465025 (* 1 = 0.0465025 loss)
I0626 17:10:32.160914  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000231884 (* 1 = 0.000231884 loss)
I0626 17:10:32.160919  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019652 (* 1 = 0.019652 loss)
I0626 17:10:32.160924  4216 sgd_solver.cpp:106] Iteration 19920, lr = 0.0002
I0626 17:12:19.708909  4216 solver.cpp:228] Iteration 19940, loss = 0.16733
I0626 17:12:19.708935  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 17:12:19.708945  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0659252 (* 1 = 0.0659252 loss)
I0626 17:12:19.708950  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.139957 (* 1 = 0.139957 loss)
I0626 17:12:19.708953  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000659054 (* 1 = 0.000659054 loss)
I0626 17:12:19.708957  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186415 (* 1 = 0.0186415 loss)
I0626 17:12:19.708963  4216 sgd_solver.cpp:106] Iteration 19940, lr = 0.0002
I0626 17:14:08.024158  4216 solver.cpp:228] Iteration 19960, loss = 0.19786
I0626 17:14:08.024185  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:14:08.024194  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0217711 (* 1 = 0.0217711 loss)
I0626 17:14:08.024199  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0368213 (* 1 = 0.0368213 loss)
I0626 17:14:08.024201  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00570652 (* 1 = 0.00570652 loss)
I0626 17:14:08.024205  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209041 (* 1 = 0.0209041 loss)
I0626 17:14:08.024210  4216 sgd_solver.cpp:106] Iteration 19960, lr = 0.0002
I0626 17:15:55.491281  4216 solver.cpp:228] Iteration 19980, loss = 0.234644
I0626 17:15:55.491304  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 17:15:55.491312  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0586533 (* 1 = 0.0586533 loss)
I0626 17:15:55.491317  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0877135 (* 1 = 0.0877135 loss)
I0626 17:15:55.491320  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000892604 (* 1 = 0.000892604 loss)
I0626 17:15:55.491324  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307981 (* 1 = 0.0307981 loss)
I0626 17:15:55.491329  4216 sgd_solver.cpp:106] Iteration 19980, lr = 0.0002
speed: 5.284s / iter
I0626 17:17:37.000057  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_20000.caffemodel
I0626 17:17:42.856204  4216 solver.cpp:228] Iteration 20000, loss = 0.198257
I0626 17:17:42.856230  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 17:17:42.856236  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0845684 (* 1 = 0.0845684 loss)
I0626 17:17:42.856240  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.199384 (* 1 = 0.199384 loss)
I0626 17:17:42.856245  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134066 (* 1 = 0.0134066 loss)
I0626 17:17:42.856247  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.140091 (* 1 = 0.140091 loss)
I0626 17:17:42.856252  4216 sgd_solver.cpp:106] Iteration 20000, lr = 2e-05
I0626 17:19:29.735282  4216 solver.cpp:228] Iteration 20020, loss = 0.271304
I0626 17:19:29.735309  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:19:29.735317  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0084048 (* 1 = 0.0084048 loss)
I0626 17:19:29.735321  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0145524 (* 1 = 0.0145524 loss)
I0626 17:19:29.735325  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000408684 (* 1 = 0.000408684 loss)
I0626 17:19:29.735329  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00727726 (* 1 = 0.00727726 loss)
I0626 17:19:29.735334  4216 sgd_solver.cpp:106] Iteration 20020, lr = 2e-05
I0626 17:21:15.816715  4216 solver.cpp:228] Iteration 20040, loss = 0.127705
I0626 17:21:15.816737  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:21:15.816746  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331872 (* 1 = 0.0331872 loss)
I0626 17:21:15.816751  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0520431 (* 1 = 0.0520431 loss)
I0626 17:21:15.816754  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000830204 (* 1 = 0.000830204 loss)
I0626 17:21:15.816759  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00953982 (* 1 = 0.00953982 loss)
I0626 17:21:15.816766  4216 sgd_solver.cpp:106] Iteration 20040, lr = 2e-05
I0626 17:23:01.800026  4216 solver.cpp:228] Iteration 20060, loss = 0.283893
I0626 17:23:01.800050  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:23:01.800057  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0208855 (* 1 = 0.0208855 loss)
I0626 17:23:01.800062  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0364328 (* 1 = 0.0364328 loss)
I0626 17:23:01.800066  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00123917 (* 1 = 0.00123917 loss)
I0626 17:23:01.800070  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00189012 (* 1 = 0.00189012 loss)
I0626 17:23:01.800074  4216 sgd_solver.cpp:106] Iteration 20060, lr = 2e-05
I0626 17:24:48.167641  4216 solver.cpp:228] Iteration 20080, loss = 0.123504
I0626 17:24:48.167667  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 17:24:48.167675  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0725447 (* 1 = 0.0725447 loss)
I0626 17:24:48.167680  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.11767 (* 1 = 0.11767 loss)
I0626 17:24:48.167683  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00246065 (* 1 = 0.00246065 loss)
I0626 17:24:48.167687  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378364 (* 1 = 0.0378364 loss)
I0626 17:24:48.167692  4216 sgd_solver.cpp:106] Iteration 20080, lr = 2e-05
I0626 17:26:33.832691  4216 solver.cpp:228] Iteration 20100, loss = 0.129254
I0626 17:26:33.832716  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 17:26:33.832723  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485188 (* 1 = 0.0485188 loss)
I0626 17:26:33.832728  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.153049 (* 1 = 0.153049 loss)
I0626 17:26:33.832732  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377024 (* 1 = 0.00377024 loss)
I0626 17:26:33.832736  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040231 (* 1 = 0.040231 loss)
I0626 17:26:33.832741  4216 sgd_solver.cpp:106] Iteration 20100, lr = 2e-05
I0626 17:28:19.407501  4216 solver.cpp:228] Iteration 20120, loss = 0.195921
I0626 17:28:19.407527  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:28:19.407538  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.028701 (* 1 = 0.028701 loss)
I0626 17:28:19.407544  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0709158 (* 1 = 0.0709158 loss)
I0626 17:28:19.407552  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000239086 (* 1 = 0.000239086 loss)
I0626 17:28:19.407558  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140307 (* 1 = 0.0140307 loss)
I0626 17:28:19.407565  4216 sgd_solver.cpp:106] Iteration 20120, lr = 2e-05
I0626 17:30:05.725459  4216 solver.cpp:228] Iteration 20140, loss = 0.119412
I0626 17:30:05.725493  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 17:30:05.725500  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264181 (* 1 = 0.0264181 loss)
I0626 17:30:05.725505  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0606837 (* 1 = 0.0606837 loss)
I0626 17:30:05.725509  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00896203 (* 1 = 0.00896203 loss)
I0626 17:30:05.725512  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00703342 (* 1 = 0.00703342 loss)
I0626 17:30:05.725518  4216 sgd_solver.cpp:106] Iteration 20140, lr = 2e-05
I0626 17:31:55.059584  4216 solver.cpp:228] Iteration 20160, loss = 0.226367
I0626 17:31:55.059613  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 17:31:55.059620  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.091475 (* 1 = 0.091475 loss)
I0626 17:31:55.059625  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.148341 (* 1 = 0.148341 loss)
I0626 17:31:55.059629  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00472179 (* 1 = 0.00472179 loss)
I0626 17:31:55.059633  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172197 (* 1 = 0.0172197 loss)
I0626 17:31:55.059638  4216 sgd_solver.cpp:106] Iteration 20160, lr = 2e-05
I0626 17:33:45.662420  4216 solver.cpp:228] Iteration 20180, loss = 0.263891
I0626 17:33:45.662448  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 17:33:45.662456  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0701392 (* 1 = 0.0701392 loss)
I0626 17:33:45.662461  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.13574 (* 1 = 0.13574 loss)
I0626 17:33:45.662464  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0025441 (* 1 = 0.0025441 loss)
I0626 17:33:45.662468  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182497 (* 1 = 0.0182497 loss)
I0626 17:33:45.662474  4216 sgd_solver.cpp:106] Iteration 20180, lr = 2e-05
speed: 5.285s / iter
I0626 17:35:36.583061  4216 solver.cpp:228] Iteration 20200, loss = 0.249345
I0626 17:35:36.583086  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 17:35:36.583093  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368301 (* 1 = 0.0368301 loss)
I0626 17:35:36.583097  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.139948 (* 1 = 0.139948 loss)
I0626 17:35:36.583101  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542719 (* 1 = 0.00542719 loss)
I0626 17:35:36.583106  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00911988 (* 1 = 0.00911988 loss)
I0626 17:35:36.583111  4216 sgd_solver.cpp:106] Iteration 20200, lr = 2e-05
I0626 17:37:24.041334  4216 solver.cpp:228] Iteration 20220, loss = 0.0975718
I0626 17:37:24.041357  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 17:37:24.041364  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148657 (* 1 = 0.0148657 loss)
I0626 17:37:24.041368  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00348318 (* 1 = 0.00348318 loss)
I0626 17:37:24.041373  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.2168e-05 (* 1 = 7.2168e-05 loss)
I0626 17:37:24.041376  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00100114 (* 1 = 0.00100114 loss)
I0626 17:37:24.041380  4216 sgd_solver.cpp:106] Iteration 20220, lr = 2e-05
I0626 17:39:10.757797  4216 solver.cpp:228] Iteration 20240, loss = 0.254958
I0626 17:39:10.757824  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 17:39:10.757831  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190478 (* 1 = 0.0190478 loss)
I0626 17:39:10.757835  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0182576 (* 1 = 0.0182576 loss)
I0626 17:39:10.757839  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.005677 (* 1 = 0.005677 loss)
I0626 17:39:10.757843  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00395633 (* 1 = 0.00395633 loss)
I0626 17:39:10.757848  4216 sgd_solver.cpp:106] Iteration 20240, lr = 2e-05
I0626 17:40:58.667330  4216 solver.cpp:228] Iteration 20260, loss = 0.269758
I0626 17:40:58.667354  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0626 17:40:58.667361  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.278262 (* 1 = 0.278262 loss)
I0626 17:40:58.667364  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.333034 (* 1 = 0.333034 loss)
I0626 17:40:58.667367  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152508 (* 1 = 0.0152508 loss)
I0626 17:40:58.667371  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0773781 (* 1 = 0.0773781 loss)
I0626 17:40:58.667376  4216 sgd_solver.cpp:106] Iteration 20260, lr = 2e-05
I0626 17:42:46.884735  4216 solver.cpp:228] Iteration 20280, loss = 0.246411
I0626 17:42:46.884763  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:42:46.884771  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323456 (* 1 = 0.0323456 loss)
I0626 17:42:46.884776  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0248913 (* 1 = 0.0248913 loss)
I0626 17:42:46.884780  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00608648 (* 1 = 0.00608648 loss)
I0626 17:42:46.884784  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125702 (* 1 = 0.0125702 loss)
I0626 17:42:46.884789  4216 sgd_solver.cpp:106] Iteration 20280, lr = 2e-05
I0626 17:44:33.887645  4216 solver.cpp:228] Iteration 20300, loss = 0.144141
I0626 17:44:33.887668  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:44:33.887676  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0375326 (* 1 = 0.0375326 loss)
I0626 17:44:33.887681  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0237838 (* 1 = 0.0237838 loss)
I0626 17:44:33.887684  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237499 (* 1 = 0.00237499 loss)
I0626 17:44:33.887687  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00843616 (* 1 = 0.00843616 loss)
I0626 17:44:33.887692  4216 sgd_solver.cpp:106] Iteration 20300, lr = 2e-05
I0626 17:46:19.077781  4216 solver.cpp:228] Iteration 20320, loss = 0.221565
I0626 17:46:19.077805  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:46:19.077812  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.011742 (* 1 = 0.011742 loss)
I0626 17:46:19.077816  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0219368 (* 1 = 0.0219368 loss)
I0626 17:46:19.077821  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213331 (* 1 = 0.00213331 loss)
I0626 17:46:19.077823  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010191 (* 1 = 0.010191 loss)
I0626 17:46:19.077828  4216 sgd_solver.cpp:106] Iteration 20320, lr = 2e-05
I0626 17:48:04.052913  4216 solver.cpp:228] Iteration 20340, loss = 0.251652
I0626 17:48:04.052937  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 17:48:04.052944  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.11663 (* 1 = 0.11663 loss)
I0626 17:48:04.052948  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.230638 (* 1 = 0.230638 loss)
I0626 17:48:04.052951  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136374 (* 1 = 0.00136374 loss)
I0626 17:48:04.052956  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255502 (* 1 = 0.0255502 loss)
I0626 17:48:04.052960  4216 sgd_solver.cpp:106] Iteration 20340, lr = 2e-05
I0626 17:49:49.190405  4216 solver.cpp:228] Iteration 20360, loss = 0.16183
I0626 17:49:49.190428  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:49:49.190435  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148754 (* 1 = 0.0148754 loss)
I0626 17:49:49.190439  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.030338 (* 1 = 0.030338 loss)
I0626 17:49:49.190443  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000189581 (* 1 = 0.000189581 loss)
I0626 17:49:49.190446  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00423171 (* 1 = 0.00423171 loss)
I0626 17:49:49.190451  4216 sgd_solver.cpp:106] Iteration 20360, lr = 2e-05
I0626 17:51:34.352320  4216 solver.cpp:228] Iteration 20380, loss = 0.106658
I0626 17:51:34.352344  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:51:34.352351  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0416745 (* 1 = 0.0416745 loss)
I0626 17:51:34.352355  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0205303 (* 1 = 0.0205303 loss)
I0626 17:51:34.352360  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00588076 (* 1 = 0.00588076 loss)
I0626 17:51:34.352363  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00117305 (* 1 = 0.00117305 loss)
I0626 17:51:34.352368  4216 sgd_solver.cpp:106] Iteration 20380, lr = 2e-05
speed: 5.286s / iter
I0626 17:53:19.491647  4216 solver.cpp:228] Iteration 20400, loss = 0.190513
I0626 17:53:19.491672  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 17:53:19.491679  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0747552 (* 1 = 0.0747552 loss)
I0626 17:53:19.491683  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.132651 (* 1 = 0.132651 loss)
I0626 17:53:19.491688  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000457805 (* 1 = 0.000457805 loss)
I0626 17:53:19.491693  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192871 (* 1 = 0.0192871 loss)
I0626 17:53:19.491698  4216 sgd_solver.cpp:106] Iteration 20400, lr = 2e-05
I0626 17:55:04.629945  4216 solver.cpp:228] Iteration 20420, loss = 0.109811
I0626 17:55:04.629971  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:55:04.629978  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371735 (* 1 = 0.0371735 loss)
I0626 17:55:04.629982  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0394003 (* 1 = 0.0394003 loss)
I0626 17:55:04.629987  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377519 (* 1 = 0.00377519 loss)
I0626 17:55:04.629992  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117803 (* 1 = 0.0117803 loss)
I0626 17:55:04.629997  4216 sgd_solver.cpp:106] Iteration 20420, lr = 2e-05
I0626 17:56:49.780556  4216 solver.cpp:228] Iteration 20440, loss = 0.126934
I0626 17:56:49.780580  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:56:49.780589  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00426459 (* 1 = 0.00426459 loss)
I0626 17:56:49.780594  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0268805 (* 1 = 0.0268805 loss)
I0626 17:56:49.780599  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00859004 (* 1 = 0.00859004 loss)
I0626 17:56:49.780604  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00232785 (* 1 = 0.00232785 loss)
I0626 17:56:49.780611  4216 sgd_solver.cpp:106] Iteration 20440, lr = 2e-05
I0626 17:58:35.001051  4216 solver.cpp:228] Iteration 20460, loss = 0.269139
I0626 17:58:35.001076  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 17:58:35.001083  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.015432 (* 1 = 0.015432 loss)
I0626 17:58:35.001087  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.013643 (* 1 = 0.013643 loss)
I0626 17:58:35.001091  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.05567e-05 (* 1 = 7.05567e-05 loss)
I0626 17:58:35.001096  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00343956 (* 1 = 0.00343956 loss)
I0626 17:58:35.001101  4216 sgd_solver.cpp:106] Iteration 20460, lr = 2e-05
I0626 18:00:20.134636  4216 solver.cpp:228] Iteration 20480, loss = 0.160699
I0626 18:00:20.134661  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 18:00:20.134668  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882246 (* 1 = 0.0882246 loss)
I0626 18:00:20.134672  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.131902 (* 1 = 0.131902 loss)
I0626 18:00:20.134677  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121932 (* 1 = 0.0121932 loss)
I0626 18:00:20.134680  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227957 (* 1 = 0.0227957 loss)
I0626 18:00:20.134685  4216 sgd_solver.cpp:106] Iteration 20480, lr = 2e-05
I0626 18:02:05.235577  4216 solver.cpp:228] Iteration 20500, loss = 0.201129
I0626 18:02:05.235601  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:02:05.235607  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675419 (* 1 = 0.0675419 loss)
I0626 18:02:05.235611  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.094683 (* 1 = 0.094683 loss)
I0626 18:02:05.235615  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234957 (* 1 = 0.0234957 loss)
I0626 18:02:05.235618  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137821 (* 1 = 0.0137821 loss)
I0626 18:02:05.235622  4216 sgd_solver.cpp:106] Iteration 20500, lr = 2e-05
I0626 18:03:50.390666  4216 solver.cpp:228] Iteration 20520, loss = 0.20959
I0626 18:03:50.390691  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 18:03:50.390697  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322492 (* 1 = 0.0322492 loss)
I0626 18:03:50.390702  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0642526 (* 1 = 0.0642526 loss)
I0626 18:03:50.390705  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114027 (* 1 = 0.00114027 loss)
I0626 18:03:50.390709  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114044 (* 1 = 0.0114044 loss)
I0626 18:03:50.390713  4216 sgd_solver.cpp:106] Iteration 20520, lr = 2e-05
I0626 18:05:35.584867  4216 solver.cpp:228] Iteration 20540, loss = 0.201071
I0626 18:05:35.584892  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:05:35.584899  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171601 (* 1 = 0.0171601 loss)
I0626 18:05:35.584905  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0381254 (* 1 = 0.0381254 loss)
I0626 18:05:35.584911  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00353864 (* 1 = 0.00353864 loss)
I0626 18:05:35.584918  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165628 (* 1 = 0.0165628 loss)
I0626 18:05:35.584928  4216 sgd_solver.cpp:106] Iteration 20540, lr = 2e-05
I0626 18:07:20.716559  4216 solver.cpp:228] Iteration 20560, loss = 0.0901762
I0626 18:07:20.716588  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:07:20.716596  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000356244 (* 1 = 0.000356244 loss)
I0626 18:07:20.716601  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.01753 (* 1 = 0.01753 loss)
I0626 18:07:20.716606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133195 (* 1 = 0.00133195 loss)
I0626 18:07:20.716609  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141042 (* 1 = 0.0141042 loss)
I0626 18:07:20.716615  4216 sgd_solver.cpp:106] Iteration 20560, lr = 2e-05
I0626 18:09:05.851987  4216 solver.cpp:228] Iteration 20580, loss = 0.184832
I0626 18:09:05.852013  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:09:05.852020  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170502 (* 1 = 0.0170502 loss)
I0626 18:09:05.852025  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0508661 (* 1 = 0.0508661 loss)
I0626 18:09:05.852030  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000672521 (* 1 = 0.000672521 loss)
I0626 18:09:05.852033  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179694 (* 1 = 0.0179694 loss)
I0626 18:09:05.852038  4216 sgd_solver.cpp:106] Iteration 20580, lr = 2e-05
speed: 5.285s / iter
I0626 18:10:51.011590  4216 solver.cpp:228] Iteration 20600, loss = 0.211217
I0626 18:10:51.011616  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 18:10:51.011624  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0528827 (* 1 = 0.0528827 loss)
I0626 18:10:51.011628  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.163917 (* 1 = 0.163917 loss)
I0626 18:10:51.011632  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00481102 (* 1 = 0.00481102 loss)
I0626 18:10:51.011636  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241133 (* 1 = 0.0241133 loss)
I0626 18:10:51.011642  4216 sgd_solver.cpp:106] Iteration 20600, lr = 2e-05
I0626 18:12:36.172020  4216 solver.cpp:228] Iteration 20620, loss = 0.211713
I0626 18:12:36.172044  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 18:12:36.172053  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.134232 (* 1 = 0.134232 loss)
I0626 18:12:36.172060  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.173544 (* 1 = 0.173544 loss)
I0626 18:12:36.172065  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134294 (* 1 = 0.00134294 loss)
I0626 18:12:36.172070  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364009 (* 1 = 0.0364009 loss)
I0626 18:12:36.172076  4216 sgd_solver.cpp:106] Iteration 20620, lr = 2e-05
I0626 18:14:21.326460  4216 solver.cpp:228] Iteration 20640, loss = 0.131669
I0626 18:14:21.326483  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:14:21.326489  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.012049 (* 1 = 0.012049 loss)
I0626 18:14:21.326493  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0210685 (* 1 = 0.0210685 loss)
I0626 18:14:21.326498  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000559533 (* 1 = 0.000559533 loss)
I0626 18:14:21.326501  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00375033 (* 1 = 0.00375033 loss)
I0626 18:14:21.326506  4216 sgd_solver.cpp:106] Iteration 20640, lr = 2e-05
I0626 18:16:06.491832  4216 solver.cpp:228] Iteration 20660, loss = 0.232955
I0626 18:16:06.491859  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:16:06.491866  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0227109 (* 1 = 0.0227109 loss)
I0626 18:16:06.491871  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0629748 (* 1 = 0.0629748 loss)
I0626 18:16:06.491875  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216965 (* 1 = 0.00216965 loss)
I0626 18:16:06.491878  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00724294 (* 1 = 0.00724294 loss)
I0626 18:16:06.491884  4216 sgd_solver.cpp:106] Iteration 20660, lr = 2e-05
I0626 18:17:51.646646  4216 solver.cpp:228] Iteration 20680, loss = 0.142465
I0626 18:17:51.646669  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 18:17:51.646677  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.113926 (* 1 = 0.113926 loss)
I0626 18:17:51.646683  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.184521 (* 1 = 0.184521 loss)
I0626 18:17:51.646689  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109615 (* 1 = 0.00109615 loss)
I0626 18:17:51.646693  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151094 (* 1 = 0.0151094 loss)
I0626 18:17:51.646700  4216 sgd_solver.cpp:106] Iteration 20680, lr = 2e-05
I0626 18:19:36.833218  4216 solver.cpp:228] Iteration 20700, loss = 0.15709
I0626 18:19:36.833243  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:19:36.833250  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155782 (* 1 = 0.0155782 loss)
I0626 18:19:36.833256  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.057238 (* 1 = 0.057238 loss)
I0626 18:19:36.833259  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00327037 (* 1 = 0.00327037 loss)
I0626 18:19:36.833263  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00471268 (* 1 = 0.00471268 loss)
I0626 18:19:36.833268  4216 sgd_solver.cpp:106] Iteration 20700, lr = 2e-05
I0626 18:21:21.978489  4216 solver.cpp:228] Iteration 20720, loss = 0.191212
I0626 18:21:21.978514  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:21:21.978523  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.025358 (* 1 = 0.025358 loss)
I0626 18:21:21.978528  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0527436 (* 1 = 0.0527436 loss)
I0626 18:21:21.978531  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130919 (* 1 = 0.00130919 loss)
I0626 18:21:21.978535  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220967 (* 1 = 0.0220967 loss)
I0626 18:21:21.978541  4216 sgd_solver.cpp:106] Iteration 20720, lr = 2e-05
I0626 18:23:07.167114  4216 solver.cpp:228] Iteration 20740, loss = 0.179715
I0626 18:23:07.167142  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:23:07.167150  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339419 (* 1 = 0.0339419 loss)
I0626 18:23:07.167155  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0209545 (* 1 = 0.0209545 loss)
I0626 18:23:07.167158  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000192773 (* 1 = 0.000192773 loss)
I0626 18:23:07.167162  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00534685 (* 1 = 0.00534685 loss)
I0626 18:23:07.167167  4216 sgd_solver.cpp:106] Iteration 20740, lr = 2e-05
I0626 18:24:52.339893  4216 solver.cpp:228] Iteration 20760, loss = 0.177107
I0626 18:24:52.339918  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:24:52.339926  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235923 (* 1 = 0.0235923 loss)
I0626 18:24:52.339931  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0315938 (* 1 = 0.0315938 loss)
I0626 18:24:52.339934  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00222902 (* 1 = 0.00222902 loss)
I0626 18:24:52.339938  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174519 (* 1 = 0.0174519 loss)
I0626 18:24:52.339943  4216 sgd_solver.cpp:106] Iteration 20760, lr = 2e-05
I0626 18:26:37.503491  4216 solver.cpp:228] Iteration 20780, loss = 0.129468
I0626 18:26:37.503516  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:26:37.503523  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148536 (* 1 = 0.0148536 loss)
I0626 18:26:37.503528  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0476258 (* 1 = 0.0476258 loss)
I0626 18:26:37.503532  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445396 (* 1 = 0.00445396 loss)
I0626 18:26:37.503536  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160898 (* 1 = 0.0160898 loss)
I0626 18:26:37.503541  4216 sgd_solver.cpp:106] Iteration 20780, lr = 2e-05
speed: 5.285s / iter
I0626 18:28:22.648432  4216 solver.cpp:228] Iteration 20800, loss = 0.306095
I0626 18:28:22.648458  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 18:28:22.648466  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269393 (* 1 = 0.0269393 loss)
I0626 18:28:22.648473  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.116034 (* 1 = 0.116034 loss)
I0626 18:28:22.648478  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00679513 (* 1 = 0.00679513 loss)
I0626 18:28:22.648485  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178441 (* 1 = 0.0178441 loss)
I0626 18:28:22.648492  4216 sgd_solver.cpp:106] Iteration 20800, lr = 2e-05
I0626 18:30:07.830039  4216 solver.cpp:228] Iteration 20820, loss = 0.198255
I0626 18:30:07.830066  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 18:30:07.830075  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.264377 (* 1 = 0.264377 loss)
I0626 18:30:07.830080  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.286118 (* 1 = 0.286118 loss)
I0626 18:30:07.830086  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00971328 (* 1 = 0.00971328 loss)
I0626 18:30:07.830092  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0773172 (* 1 = 0.0773172 loss)
I0626 18:30:07.830099  4216 sgd_solver.cpp:106] Iteration 20820, lr = 2e-05
I0626 18:31:53.003860  4216 solver.cpp:228] Iteration 20840, loss = 0.0913634
I0626 18:31:53.003896  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 18:31:53.003904  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220466 (* 1 = 0.0220466 loss)
I0626 18:31:53.003908  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00732842 (* 1 = 0.00732842 loss)
I0626 18:31:53.003912  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000207035 (* 1 = 0.000207035 loss)
I0626 18:31:53.003916  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00166398 (* 1 = 0.00166398 loss)
I0626 18:31:53.003921  4216 sgd_solver.cpp:106] Iteration 20840, lr = 2e-05
I0626 18:33:38.088120  4216 solver.cpp:228] Iteration 20860, loss = 0.223164
I0626 18:33:38.088146  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 18:33:38.088156  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0670159 (* 1 = 0.0670159 loss)
I0626 18:33:38.088163  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.14269 (* 1 = 0.14269 loss)
I0626 18:33:38.088169  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00612801 (* 1 = 0.00612801 loss)
I0626 18:33:38.088176  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.123022 (* 1 = 0.123022 loss)
I0626 18:33:38.088182  4216 sgd_solver.cpp:106] Iteration 20860, lr = 2e-05
I0626 18:35:23.253631  4216 solver.cpp:228] Iteration 20880, loss = 0.254536
I0626 18:35:23.253655  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 18:35:23.253664  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.102661 (* 1 = 0.102661 loss)
I0626 18:35:23.253670  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.160929 (* 1 = 0.160929 loss)
I0626 18:35:23.253676  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102227 (* 1 = 0.0102227 loss)
I0626 18:35:23.253682  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330802 (* 1 = 0.0330802 loss)
I0626 18:35:23.253688  4216 sgd_solver.cpp:106] Iteration 20880, lr = 2e-05
I0626 18:37:08.427778  4216 solver.cpp:228] Iteration 20900, loss = 0.204753
I0626 18:37:08.427803  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:37:08.427812  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0338103 (* 1 = 0.0338103 loss)
I0626 18:37:08.427819  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0755502 (* 1 = 0.0755502 loss)
I0626 18:37:08.427825  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144291 (* 1 = 0.00144291 loss)
I0626 18:37:08.427830  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00137573 (* 1 = 0.00137573 loss)
I0626 18:37:08.427839  4216 sgd_solver.cpp:106] Iteration 20900, lr = 2e-05
I0626 18:38:53.588176  4216 solver.cpp:228] Iteration 20920, loss = 0.15671
I0626 18:38:53.588204  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:38:53.588212  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297136 (* 1 = 0.0297136 loss)
I0626 18:38:53.588217  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.069162 (* 1 = 0.069162 loss)
I0626 18:38:53.588222  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000899156 (* 1 = 0.000899156 loss)
I0626 18:38:53.588225  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125286 (* 1 = 0.0125286 loss)
I0626 18:38:53.588230  4216 sgd_solver.cpp:106] Iteration 20920, lr = 2e-05
I0626 18:40:38.744050  4216 solver.cpp:228] Iteration 20940, loss = 0.355558
I0626 18:40:38.744077  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0626 18:40:38.744086  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.320801 (* 1 = 0.320801 loss)
I0626 18:40:38.744091  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.406077 (* 1 = 0.406077 loss)
I0626 18:40:38.744094  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538174 (* 1 = 0.00538174 loss)
I0626 18:40:38.744098  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0723289 (* 1 = 0.0723289 loss)
I0626 18:40:38.744104  4216 sgd_solver.cpp:106] Iteration 20940, lr = 2e-05
I0626 18:42:23.906749  4216 solver.cpp:228] Iteration 20960, loss = 0.152685
I0626 18:42:23.906772  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 18:42:23.906780  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.103807 (* 1 = 0.103807 loss)
I0626 18:42:23.906783  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.22899 (* 1 = 0.22899 loss)
I0626 18:42:23.906787  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0424445 (* 1 = 0.0424445 loss)
I0626 18:42:23.906790  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309757 (* 1 = 0.0309757 loss)
I0626 18:42:23.906795  4216 sgd_solver.cpp:106] Iteration 20960, lr = 2e-05
I0626 18:44:09.054522  4216 solver.cpp:228] Iteration 20980, loss = 0.133377
I0626 18:44:09.054544  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:44:09.054551  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205401 (* 1 = 0.0205401 loss)
I0626 18:44:09.054555  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0498063 (* 1 = 0.0498063 loss)
I0626 18:44:09.054558  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000561139 (* 1 = 0.000561139 loss)
I0626 18:44:09.054563  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136606 (* 1 = 0.0136606 loss)
I0626 18:44:09.054566  4216 sgd_solver.cpp:106] Iteration 20980, lr = 2e-05
speed: 5.285s / iter
I0626 18:45:54.173190  4216 solver.cpp:228] Iteration 21000, loss = 0.0956092
I0626 18:45:54.173214  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:45:54.173223  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240847 (* 1 = 0.0240847 loss)
I0626 18:45:54.173226  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0596524 (* 1 = 0.0596524 loss)
I0626 18:45:54.173230  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000115357 (* 1 = 0.000115357 loss)
I0626 18:45:54.173234  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150769 (* 1 = 0.0150769 loss)
I0626 18:45:54.173240  4216 sgd_solver.cpp:106] Iteration 21000, lr = 2e-05
I0626 18:47:39.353354  4216 solver.cpp:228] Iteration 21020, loss = 0.183981
I0626 18:47:39.353379  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 18:47:39.353384  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0315775 (* 1 = 0.0315775 loss)
I0626 18:47:39.353389  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0508499 (* 1 = 0.0508499 loss)
I0626 18:47:39.353392  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00452561 (* 1 = 0.00452561 loss)
I0626 18:47:39.353396  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00678581 (* 1 = 0.00678581 loss)
I0626 18:47:39.353400  4216 sgd_solver.cpp:106] Iteration 21020, lr = 2e-05
I0626 18:49:24.508551  4216 solver.cpp:228] Iteration 21040, loss = 0.118866
I0626 18:49:24.508579  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 18:49:24.508586  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167124 (* 1 = 0.0167124 loss)
I0626 18:49:24.508591  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00228486 (* 1 = 0.00228486 loss)
I0626 18:49:24.508596  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000386809 (* 1 = 0.000386809 loss)
I0626 18:49:24.508600  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00746749 (* 1 = 0.00746749 loss)
I0626 18:49:24.508606  4216 sgd_solver.cpp:106] Iteration 21040, lr = 2e-05
I0626 18:51:09.659229  4216 solver.cpp:228] Iteration 21060, loss = 0.0807789
I0626 18:51:09.659252  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 18:51:09.659260  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00163845 (* 1 = 0.00163845 loss)
I0626 18:51:09.659263  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00354118 (* 1 = 0.00354118 loss)
I0626 18:51:09.659266  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0041525 (* 1 = 0.0041525 loss)
I0626 18:51:09.659271  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135068 (* 1 = 0.0135068 loss)
I0626 18:51:09.659274  4216 sgd_solver.cpp:106] Iteration 21060, lr = 2e-05
I0626 18:52:54.800644  4216 solver.cpp:228] Iteration 21080, loss = 0.125894
I0626 18:52:54.800668  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 18:52:54.800675  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0370406 (* 1 = 0.0370406 loss)
I0626 18:52:54.800680  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108689 (* 1 = 0.108689 loss)
I0626 18:52:54.800684  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264182 (* 1 = 0.00264182 loss)
I0626 18:52:54.800688  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0054535 (* 1 = 0.0054535 loss)
I0626 18:52:54.800693  4216 sgd_solver.cpp:106] Iteration 21080, lr = 2e-05
I0626 18:54:39.951333  4216 solver.cpp:228] Iteration 21100, loss = 0.137084
I0626 18:54:39.951356  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:54:39.951364  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0282112 (* 1 = 0.0282112 loss)
I0626 18:54:39.951370  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.046252 (* 1 = 0.046252 loss)
I0626 18:54:39.951373  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000813254 (* 1 = 0.000813254 loss)
I0626 18:54:39.951376  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137164 (* 1 = 0.0137164 loss)
I0626 18:54:39.951382  4216 sgd_solver.cpp:106] Iteration 21100, lr = 2e-05
I0626 18:56:25.042939  4216 solver.cpp:228] Iteration 21120, loss = 0.155444
I0626 18:56:25.042963  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 18:56:25.042970  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356991 (* 1 = 0.0356991 loss)
I0626 18:56:25.042974  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.103875 (* 1 = 0.103875 loss)
I0626 18:56:25.042979  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385953 (* 1 = 0.00385953 loss)
I0626 18:56:25.042981  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152182 (* 1 = 0.0152182 loss)
I0626 18:56:25.042986  4216 sgd_solver.cpp:106] Iteration 21120, lr = 2e-05
I0626 18:58:10.213670  4216 solver.cpp:228] Iteration 21140, loss = 0.149823
I0626 18:58:10.213695  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:58:10.213701  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0824936 (* 1 = 0.0824936 loss)
I0626 18:58:10.213704  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.105539 (* 1 = 0.105539 loss)
I0626 18:58:10.213708  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100873 (* 1 = 0.00100873 loss)
I0626 18:58:10.213712  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292375 (* 1 = 0.0292375 loss)
I0626 18:58:10.213716  4216 sgd_solver.cpp:106] Iteration 21140, lr = 2e-05
I0626 18:59:55.338207  4216 solver.cpp:228] Iteration 21160, loss = 0.161335
I0626 18:59:55.338232  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 18:59:55.338239  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.031982 (* 1 = 0.031982 loss)
I0626 18:59:55.338243  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.107523 (* 1 = 0.107523 loss)
I0626 18:59:55.338246  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0009824 (* 1 = 0.0009824 loss)
I0626 18:59:55.338250  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036565 (* 1 = 0.036565 loss)
I0626 18:59:55.338254  4216 sgd_solver.cpp:106] Iteration 21160, lr = 2e-05
I0626 19:01:40.544243  4216 solver.cpp:228] Iteration 21180, loss = 0.129586
I0626 19:01:40.544267  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 19:01:40.544275  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0586402 (* 1 = 0.0586402 loss)
I0626 19:01:40.544279  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.158519 (* 1 = 0.158519 loss)
I0626 19:01:40.544283  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115951 (* 1 = 0.0115951 loss)
I0626 19:01:40.544287  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234227 (* 1 = 0.0234227 loss)
I0626 19:01:40.544292  4216 sgd_solver.cpp:106] Iteration 21180, lr = 2e-05
speed: 5.285s / iter
I0626 19:03:25.689736  4216 solver.cpp:228] Iteration 21200, loss = 0.167839
I0626 19:03:25.689760  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:03:25.689769  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00652109 (* 1 = 0.00652109 loss)
I0626 19:03:25.689774  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0223291 (* 1 = 0.0223291 loss)
I0626 19:03:25.689777  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118807 (* 1 = 0.00118807 loss)
I0626 19:03:25.689781  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00819541 (* 1 = 0.00819541 loss)
I0626 19:03:25.689786  4216 sgd_solver.cpp:106] Iteration 21200, lr = 2e-05
I0626 19:05:10.867025  4216 solver.cpp:228] Iteration 21220, loss = 0.184035
I0626 19:05:10.867049  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:05:10.867055  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.035677 (* 1 = 0.035677 loss)
I0626 19:05:10.867059  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.040345 (* 1 = 0.040345 loss)
I0626 19:05:10.867063  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147806 (* 1 = 0.00147806 loss)
I0626 19:05:10.867067  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00691634 (* 1 = 0.00691634 loss)
I0626 19:05:10.867072  4216 sgd_solver.cpp:106] Iteration 21220, lr = 2e-05
I0626 19:06:55.955685  4216 solver.cpp:228] Iteration 21240, loss = 0.149232
I0626 19:06:55.955708  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:06:55.955715  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.029729 (* 1 = 0.029729 loss)
I0626 19:06:55.955719  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0618742 (* 1 = 0.0618742 loss)
I0626 19:06:55.955724  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221048 (* 1 = 0.00221048 loss)
I0626 19:06:55.955726  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00588264 (* 1 = 0.00588264 loss)
I0626 19:06:55.955731  4216 sgd_solver.cpp:106] Iteration 21240, lr = 2e-05
I0626 19:08:41.109050  4216 solver.cpp:228] Iteration 21260, loss = 0.148683
I0626 19:08:41.109074  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 19:08:41.109081  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0862083 (* 1 = 0.0862083 loss)
I0626 19:08:41.109086  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0792889 (* 1 = 0.0792889 loss)
I0626 19:08:41.109089  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00174655 (* 1 = 0.00174655 loss)
I0626 19:08:41.109092  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236808 (* 1 = 0.0236808 loss)
I0626 19:08:41.109097  4216 sgd_solver.cpp:106] Iteration 21260, lr = 2e-05
I0626 19:10:26.258824  4216 solver.cpp:228] Iteration 21280, loss = 0.111737
I0626 19:10:26.258847  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 19:10:26.258854  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245819 (* 1 = 0.0245819 loss)
I0626 19:10:26.258862  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0721085 (* 1 = 0.0721085 loss)
I0626 19:10:26.258867  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000197419 (* 1 = 0.000197419 loss)
I0626 19:10:26.258869  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0071771 (* 1 = 0.0071771 loss)
I0626 19:10:26.258874  4216 sgd_solver.cpp:106] Iteration 21280, lr = 2e-05
I0626 19:12:11.321681  4216 solver.cpp:228] Iteration 21300, loss = 0.145919
I0626 19:12:11.321708  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:12:11.321715  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176585 (* 1 = 0.0176585 loss)
I0626 19:12:11.321719  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0137307 (* 1 = 0.0137307 loss)
I0626 19:12:11.321723  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000104342 (* 1 = 0.000104342 loss)
I0626 19:12:11.321727  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00079749 (* 1 = 0.00079749 loss)
I0626 19:12:11.321732  4216 sgd_solver.cpp:106] Iteration 21300, lr = 2e-05
I0626 19:13:56.436408  4216 solver.cpp:228] Iteration 21320, loss = 0.147545
I0626 19:13:56.436429  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:13:56.436437  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.084478 (* 1 = 0.084478 loss)
I0626 19:13:56.436441  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.085579 (* 1 = 0.085579 loss)
I0626 19:13:56.436445  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257365 (* 1 = 0.00257365 loss)
I0626 19:13:56.436448  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203057 (* 1 = 0.0203057 loss)
I0626 19:13:56.436453  4216 sgd_solver.cpp:106] Iteration 21320, lr = 2e-05
I0626 19:15:41.513902  4216 solver.cpp:228] Iteration 21340, loss = 0.15978
I0626 19:15:41.513926  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:15:41.513934  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318024 (* 1 = 0.0318024 loss)
I0626 19:15:41.513939  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0456829 (* 1 = 0.0456829 loss)
I0626 19:15:41.513943  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135842 (* 1 = 0.00135842 loss)
I0626 19:15:41.513947  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012785 (* 1 = 0.012785 loss)
I0626 19:15:41.513952  4216 sgd_solver.cpp:106] Iteration 21340, lr = 2e-05
I0626 19:17:26.690246  4216 solver.cpp:228] Iteration 21360, loss = 0.262139
I0626 19:17:26.690270  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 19:17:26.690277  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.373328 (* 1 = 0.373328 loss)
I0626 19:17:26.690282  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.394367 (* 1 = 0.394367 loss)
I0626 19:17:26.690286  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354504 (* 1 = 0.00354504 loss)
I0626 19:17:26.690290  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0997743 (* 1 = 0.0997743 loss)
I0626 19:17:26.690295  4216 sgd_solver.cpp:106] Iteration 21360, lr = 2e-05
I0626 19:19:11.839200  4216 solver.cpp:228] Iteration 21380, loss = 0.247108
I0626 19:19:11.839226  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 19:19:11.839232  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685457 (* 1 = 0.0685457 loss)
I0626 19:19:11.839237  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0907161 (* 1 = 0.0907161 loss)
I0626 19:19:11.839241  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102622 (* 1 = 0.0102622 loss)
I0626 19:19:11.839246  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127349 (* 1 = 0.0127349 loss)
I0626 19:19:11.839251  4216 sgd_solver.cpp:106] Iteration 21380, lr = 2e-05
speed: 5.284s / iter
I0626 19:20:56.945806  4216 solver.cpp:228] Iteration 21400, loss = 0.100243
I0626 19:20:56.945828  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 19:20:56.945835  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170639 (* 1 = 0.0170639 loss)
I0626 19:20:56.945839  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0546409 (* 1 = 0.0546409 loss)
I0626 19:20:56.945843  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000394855 (* 1 = 0.000394855 loss)
I0626 19:20:56.945847  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00622431 (* 1 = 0.00622431 loss)
I0626 19:20:56.945852  4216 sgd_solver.cpp:106] Iteration 21400, lr = 2e-05
I0626 19:22:42.091032  4216 solver.cpp:228] Iteration 21420, loss = 0.16804
I0626 19:22:42.091056  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 19:22:42.091064  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0285994 (* 1 = 0.0285994 loss)
I0626 19:22:42.091068  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0786212 (* 1 = 0.0786212 loss)
I0626 19:22:42.091073  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00365885 (* 1 = 0.00365885 loss)
I0626 19:22:42.091078  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324371 (* 1 = 0.0324371 loss)
I0626 19:22:42.091084  4216 sgd_solver.cpp:106] Iteration 21420, lr = 2e-05
I0626 19:24:27.207949  4216 solver.cpp:228] Iteration 21440, loss = 0.314588
I0626 19:24:27.207973  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 19:24:27.207983  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.293836 (* 1 = 0.293836 loss)
I0626 19:24:27.207988  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.327183 (* 1 = 0.327183 loss)
I0626 19:24:27.207993  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772144 (* 1 = 0.00772144 loss)
I0626 19:24:27.207999  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0846076 (* 1 = 0.0846076 loss)
I0626 19:24:27.208005  4216 sgd_solver.cpp:106] Iteration 21440, lr = 2e-05
I0626 19:26:12.242444  4216 solver.cpp:228] Iteration 21460, loss = 0.145807
I0626 19:26:12.242468  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:26:12.242478  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000495462 (* 1 = 0.000495462 loss)
I0626 19:26:12.242486  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00788236 (* 1 = 0.00788236 loss)
I0626 19:26:12.242491  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0043458 (* 1 = 0.0043458 loss)
I0626 19:26:12.242498  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00664971 (* 1 = 0.00664971 loss)
I0626 19:26:12.242507  4216 sgd_solver.cpp:106] Iteration 21460, lr = 2e-05
I0626 19:27:57.384025  4216 solver.cpp:228] Iteration 21480, loss = 0.095753
I0626 19:27:57.384065  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 19:27:57.384076  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0497118 (* 1 = 0.0497118 loss)
I0626 19:27:57.384083  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0851459 (* 1 = 0.0851459 loss)
I0626 19:27:57.384089  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000984286 (* 1 = 0.000984286 loss)
I0626 19:27:57.384095  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00292325 (* 1 = 0.00292325 loss)
I0626 19:27:57.384104  4216 sgd_solver.cpp:106] Iteration 21480, lr = 2e-05
I0626 19:29:42.490466  4216 solver.cpp:228] Iteration 21500, loss = 0.126844
I0626 19:29:42.490492  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:29:42.490500  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0351702 (* 1 = 0.0351702 loss)
I0626 19:29:42.490504  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.051274 (* 1 = 0.051274 loss)
I0626 19:29:42.490509  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00175427 (* 1 = 0.00175427 loss)
I0626 19:29:42.490512  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000789793 (* 1 = 0.000789793 loss)
I0626 19:29:42.490517  4216 sgd_solver.cpp:106] Iteration 21500, lr = 2e-05
I0626 19:31:27.602705  4216 solver.cpp:228] Iteration 21520, loss = 0.172813
I0626 19:31:27.602730  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:31:27.602736  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0303909 (* 1 = 0.0303909 loss)
I0626 19:31:27.602741  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.01287 (* 1 = 0.01287 loss)
I0626 19:31:27.602746  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00823991 (* 1 = 0.00823991 loss)
I0626 19:31:27.602749  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0054299 (* 1 = 0.0054299 loss)
I0626 19:31:27.602754  4216 sgd_solver.cpp:106] Iteration 21520, lr = 2e-05
I0626 19:33:13.755036  4216 solver.cpp:228] Iteration 21540, loss = 0.108188
I0626 19:33:13.755060  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:33:13.755067  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198714 (* 1 = 0.0198714 loss)
I0626 19:33:13.755071  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0553577 (* 1 = 0.0553577 loss)
I0626 19:33:13.755074  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026715 (* 1 = 0.0026715 loss)
I0626 19:33:13.755079  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00441016 (* 1 = 0.00441016 loss)
I0626 19:33:13.755082  4216 sgd_solver.cpp:106] Iteration 21540, lr = 2e-05
I0626 19:35:01.489356  4216 solver.cpp:228] Iteration 21560, loss = 0.187712
I0626 19:35:01.489382  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:35:01.489389  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000664607 (* 1 = 0.000664607 loss)
I0626 19:35:01.489394  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0302152 (* 1 = 0.0302152 loss)
I0626 19:35:01.489398  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000580074 (* 1 = 0.000580074 loss)
I0626 19:35:01.489401  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165972 (* 1 = 0.0165972 loss)
I0626 19:35:01.489406  4216 sgd_solver.cpp:106] Iteration 21560, lr = 2e-05
I0626 19:36:48.195457  4216 solver.cpp:228] Iteration 21580, loss = 0.283105
I0626 19:36:48.195478  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:36:48.195485  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264476 (* 1 = 0.0264476 loss)
I0626 19:36:48.195488  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0760952 (* 1 = 0.0760952 loss)
I0626 19:36:48.195492  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00117371 (* 1 = 0.00117371 loss)
I0626 19:36:48.195495  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00995164 (* 1 = 0.00995164 loss)
I0626 19:36:48.195499  4216 sgd_solver.cpp:106] Iteration 21580, lr = 2e-05
speed: 5.284s / iter
I0626 19:38:34.153077  4216 solver.cpp:228] Iteration 21600, loss = 0.113555
I0626 19:38:34.153105  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:38:34.153112  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316587 (* 1 = 0.0316587 loss)
I0626 19:38:34.153117  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.025578 (* 1 = 0.025578 loss)
I0626 19:38:34.153121  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00716822 (* 1 = 0.00716822 loss)
I0626 19:38:34.153126  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0085816 (* 1 = 0.0085816 loss)
I0626 19:38:34.153131  4216 sgd_solver.cpp:106] Iteration 21600, lr = 2e-05
I0626 19:40:22.250602  4216 solver.cpp:228] Iteration 21620, loss = 0.122099
I0626 19:40:22.250627  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 19:40:22.250636  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371011 (* 1 = 0.0371011 loss)
I0626 19:40:22.250643  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00749473 (* 1 = 0.00749473 loss)
I0626 19:40:22.250648  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173767 (* 1 = 0.00173767 loss)
I0626 19:40:22.250654  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00914432 (* 1 = 0.00914432 loss)
I0626 19:40:22.250663  4216 sgd_solver.cpp:106] Iteration 21620, lr = 2e-05
I0626 19:42:09.379601  4216 solver.cpp:228] Iteration 21640, loss = 0.187323
I0626 19:42:09.379629  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:42:09.379638  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00865763 (* 1 = 0.00865763 loss)
I0626 19:42:09.379644  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0376215 (* 1 = 0.0376215 loss)
I0626 19:42:09.379648  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00620104 (* 1 = 0.00620104 loss)
I0626 19:42:09.379653  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010068 (* 1 = 0.010068 loss)
I0626 19:42:09.379659  4216 sgd_solver.cpp:106] Iteration 21640, lr = 2e-05
I0626 19:43:56.713740  4216 solver.cpp:228] Iteration 21660, loss = 0.159988
I0626 19:43:56.713764  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:43:56.713771  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385981 (* 1 = 0.0385981 loss)
I0626 19:43:56.713776  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0423011 (* 1 = 0.0423011 loss)
I0626 19:43:56.713780  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0062208 (* 1 = 0.0062208 loss)
I0626 19:43:56.713784  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143667 (* 1 = 0.0143667 loss)
I0626 19:43:56.713788  4216 sgd_solver.cpp:106] Iteration 21660, lr = 2e-05
I0626 19:45:44.210000  4216 solver.cpp:228] Iteration 21680, loss = 0.191071
I0626 19:45:44.210026  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 19:45:44.210036  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455079 (* 1 = 0.0455079 loss)
I0626 19:45:44.210041  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0299403 (* 1 = 0.0299403 loss)
I0626 19:45:44.210045  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144765 (* 1 = 0.00144765 loss)
I0626 19:45:44.210050  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115472 (* 1 = 0.0115472 loss)
I0626 19:45:44.210057  4216 sgd_solver.cpp:106] Iteration 21680, lr = 2e-05
I0626 19:47:30.097770  4216 solver.cpp:228] Iteration 21700, loss = 0.398345
I0626 19:47:30.097793  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:47:30.097800  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496157 (* 1 = 0.0496157 loss)
I0626 19:47:30.097803  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0883814 (* 1 = 0.0883814 loss)
I0626 19:47:30.097806  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107752 (* 1 = 0.00107752 loss)
I0626 19:47:30.097810  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314537 (* 1 = 0.0314537 loss)
I0626 19:47:30.097815  4216 sgd_solver.cpp:106] Iteration 21700, lr = 2e-05
I0626 19:49:17.363332  4216 solver.cpp:228] Iteration 21720, loss = 0.142854
I0626 19:49:17.363356  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 19:49:17.363363  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0376797 (* 1 = 0.0376797 loss)
I0626 19:49:17.363368  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0965308 (* 1 = 0.0965308 loss)
I0626 19:49:17.363371  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132409 (* 1 = 0.00132409 loss)
I0626 19:49:17.363375  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181568 (* 1 = 0.0181568 loss)
I0626 19:49:17.363380  4216 sgd_solver.cpp:106] Iteration 21720, lr = 2e-05
I0626 19:51:03.328836  4216 solver.cpp:228] Iteration 21740, loss = 0.177916
I0626 19:51:03.328866  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 19:51:03.328874  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.116695 (* 1 = 0.116695 loss)
I0626 19:51:03.328879  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.232857 (* 1 = 0.232857 loss)
I0626 19:51:03.328883  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000637559 (* 1 = 0.000637559 loss)
I0626 19:51:03.328887  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.046919 (* 1 = 0.046919 loss)
I0626 19:51:03.328893  4216 sgd_solver.cpp:106] Iteration 21740, lr = 2e-05
I0626 19:52:50.334239  4216 solver.cpp:228] Iteration 21760, loss = 0.294782
I0626 19:52:50.334264  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 19:52:50.334271  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.144853 (* 1 = 0.144853 loss)
I0626 19:52:50.334275  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.292981 (* 1 = 0.292981 loss)
I0626 19:52:50.334280  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354133 (* 1 = 0.00354133 loss)
I0626 19:52:50.334283  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369524 (* 1 = 0.0369524 loss)
I0626 19:52:50.334288  4216 sgd_solver.cpp:106] Iteration 21760, lr = 2e-05
I0626 19:54:36.906994  4216 solver.cpp:228] Iteration 21780, loss = 0.220124
I0626 19:54:36.907018  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:54:36.907025  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0243072 (* 1 = 0.0243072 loss)
I0626 19:54:36.907029  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0523274 (* 1 = 0.0523274 loss)
I0626 19:54:36.907032  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00673789 (* 1 = 0.00673789 loss)
I0626 19:54:36.907037  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191649 (* 1 = 0.0191649 loss)
I0626 19:54:36.907042  4216 sgd_solver.cpp:106] Iteration 21780, lr = 2e-05
speed: 5.285s / iter
I0626 19:56:23.673431  4216 solver.cpp:228] Iteration 21800, loss = 0.136319
I0626 19:56:23.673458  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:56:23.673468  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430563 (* 1 = 0.0430563 loss)
I0626 19:56:23.673475  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0459932 (* 1 = 0.0459932 loss)
I0626 19:56:23.673480  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189715 (* 1 = 0.00189715 loss)
I0626 19:56:23.673488  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105992 (* 1 = 0.0105992 loss)
I0626 19:56:23.673496  4216 sgd_solver.cpp:106] Iteration 21800, lr = 2e-05
I0626 19:58:09.808840  4216 solver.cpp:228] Iteration 21820, loss = 0.0848462
I0626 19:58:09.808866  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 19:58:09.808874  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233716 (* 1 = 0.0233716 loss)
I0626 19:58:09.808878  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0585796 (* 1 = 0.0585796 loss)
I0626 19:58:09.808882  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00387631 (* 1 = 0.00387631 loss)
I0626 19:58:09.808887  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135696 (* 1 = 0.0135696 loss)
I0626 19:58:09.808892  4216 sgd_solver.cpp:106] Iteration 21820, lr = 2e-05
I0626 19:59:57.226346  4216 solver.cpp:228] Iteration 21840, loss = 0.251425
I0626 19:59:57.226373  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:59:57.226382  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278807 (* 1 = 0.0278807 loss)
I0626 19:59:57.226385  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0454621 (* 1 = 0.0454621 loss)
I0626 19:59:57.226390  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000560496 (* 1 = 0.000560496 loss)
I0626 19:59:57.226395  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00536176 (* 1 = 0.00536176 loss)
I0626 19:59:57.226400  4216 sgd_solver.cpp:106] Iteration 21840, lr = 2e-05
I0626 20:01:43.969476  4216 solver.cpp:228] Iteration 21860, loss = 0.256415
I0626 20:01:43.969501  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:01:43.969508  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605458 (* 1 = 0.0605458 loss)
I0626 20:01:43.969512  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0856358 (* 1 = 0.0856358 loss)
I0626 20:01:43.969516  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252392 (* 1 = 0.0252392 loss)
I0626 20:01:43.969519  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136305 (* 1 = 0.0136305 loss)
I0626 20:01:43.969523  4216 sgd_solver.cpp:106] Iteration 21860, lr = 2e-05
I0626 20:03:30.682925  4216 solver.cpp:228] Iteration 21880, loss = 0.169452
I0626 20:03:30.682953  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:03:30.682963  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392082 (* 1 = 0.0392082 loss)
I0626 20:03:30.682970  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0446709 (* 1 = 0.0446709 loss)
I0626 20:03:30.682976  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00461153 (* 1 = 0.00461153 loss)
I0626 20:03:30.682981  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00217039 (* 1 = 0.00217039 loss)
I0626 20:03:30.682988  4216 sgd_solver.cpp:106] Iteration 21880, lr = 2e-05
I0626 20:05:17.552618  4216 solver.cpp:228] Iteration 21900, loss = 0.163368
I0626 20:05:17.552644  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:05:17.552652  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299369 (* 1 = 0.0299369 loss)
I0626 20:05:17.552657  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0415414 (* 1 = 0.0415414 loss)
I0626 20:05:17.552661  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00676875 (* 1 = 0.00676875 loss)
I0626 20:05:17.552665  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109474 (* 1 = 0.0109474 loss)
I0626 20:05:17.552670  4216 sgd_solver.cpp:106] Iteration 21900, lr = 2e-05
I0626 20:07:05.112609  4216 solver.cpp:228] Iteration 21920, loss = 0.112508
I0626 20:07:05.112634  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:07:05.112642  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142359 (* 1 = 0.0142359 loss)
I0626 20:07:05.112645  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0476084 (* 1 = 0.0476084 loss)
I0626 20:07:05.112649  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106413 (* 1 = 0.00106413 loss)
I0626 20:07:05.112653  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00753575 (* 1 = 0.00753575 loss)
I0626 20:07:05.112658  4216 sgd_solver.cpp:106] Iteration 21920, lr = 2e-05
I0626 20:08:50.842248  4216 solver.cpp:228] Iteration 21940, loss = 0.271814
I0626 20:08:50.842275  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 20:08:50.842283  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.177517 (* 1 = 0.177517 loss)
I0626 20:08:50.842286  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.217389 (* 1 = 0.217389 loss)
I0626 20:08:50.842289  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123688 (* 1 = 0.0123688 loss)
I0626 20:08:50.842293  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040122 (* 1 = 0.040122 loss)
I0626 20:08:50.842299  4216 sgd_solver.cpp:106] Iteration 21940, lr = 2e-05
I0626 20:10:37.693104  4216 solver.cpp:228] Iteration 21960, loss = 0.173111
I0626 20:10:37.693131  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:10:37.693140  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0508271 (* 1 = 0.0508271 loss)
I0626 20:10:37.693143  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0477748 (* 1 = 0.0477748 loss)
I0626 20:10:37.693148  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000826037 (* 1 = 0.000826037 loss)
I0626 20:10:37.693151  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160042 (* 1 = 0.0160042 loss)
I0626 20:10:37.693157  4216 sgd_solver.cpp:106] Iteration 21960, lr = 2e-05
I0626 20:12:25.225178  4216 solver.cpp:228] Iteration 21980, loss = 0.169297
I0626 20:12:25.225201  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 20:12:25.225210  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443934 (* 1 = 0.0443934 loss)
I0626 20:12:25.225217  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0853343 (* 1 = 0.0853343 loss)
I0626 20:12:25.225222  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155728 (* 1 = 0.00155728 loss)
I0626 20:12:25.225227  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00889417 (* 1 = 0.00889417 loss)
I0626 20:12:25.225234  4216 sgd_solver.cpp:106] Iteration 21980, lr = 2e-05
speed: 5.285s / iter
I0626 20:14:13.947028  4216 solver.cpp:228] Iteration 22000, loss = 0.194711
I0626 20:14:13.947053  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:14:13.947062  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0610504 (* 1 = 0.0610504 loss)
I0626 20:14:13.947067  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0835517 (* 1 = 0.0835517 loss)
I0626 20:14:13.947070  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194396 (* 1 = 0.00194396 loss)
I0626 20:14:13.947074  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142562 (* 1 = 0.0142562 loss)
I0626 20:14:13.947079  4216 sgd_solver.cpp:106] Iteration 22000, lr = 2e-05
I0626 20:16:01.459867  4216 solver.cpp:228] Iteration 22020, loss = 0.214064
I0626 20:16:01.459892  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 20:16:01.459898  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.108541 (* 1 = 0.108541 loss)
I0626 20:16:01.459903  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.211251 (* 1 = 0.211251 loss)
I0626 20:16:01.459908  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127126 (* 1 = 0.0127126 loss)
I0626 20:16:01.459911  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0472042 (* 1 = 0.0472042 loss)
I0626 20:16:01.459916  4216 sgd_solver.cpp:106] Iteration 22020, lr = 2e-05
I0626 20:17:49.107085  4216 solver.cpp:228] Iteration 22040, loss = 0.144689
I0626 20:17:49.107113  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:17:49.107121  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241937 (* 1 = 0.0241937 loss)
I0626 20:17:49.107126  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0623254 (* 1 = 0.0623254 loss)
I0626 20:17:49.107131  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160177 (* 1 = 0.00160177 loss)
I0626 20:17:49.107136  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116789 (* 1 = 0.0116789 loss)
I0626 20:17:49.107141  4216 sgd_solver.cpp:106] Iteration 22040, lr = 2e-05
I0626 20:19:36.157019  4216 solver.cpp:228] Iteration 22060, loss = 0.149762
I0626 20:19:36.157042  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:19:36.157048  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.043522 (* 1 = 0.043522 loss)
I0626 20:19:36.157053  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0610729 (* 1 = 0.0610729 loss)
I0626 20:19:36.157057  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00656101 (* 1 = 0.00656101 loss)
I0626 20:19:36.157060  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037177 (* 1 = 0.037177 loss)
I0626 20:19:36.157065  4216 sgd_solver.cpp:106] Iteration 22060, lr = 2e-05
I0626 20:21:27.311053  4216 solver.cpp:228] Iteration 22080, loss = 0.221769
I0626 20:21:27.311079  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:21:27.311087  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000486926 (* 1 = 0.000486926 loss)
I0626 20:21:27.311094  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0111616 (* 1 = 0.0111616 loss)
I0626 20:21:27.311100  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017929 (* 1 = 0.0017929 loss)
I0626 20:21:27.311103  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00881447 (* 1 = 0.00881447 loss)
I0626 20:21:27.311108  4216 sgd_solver.cpp:106] Iteration 22080, lr = 2e-05
I0626 20:23:14.465860  4216 solver.cpp:228] Iteration 22100, loss = 0.103309
I0626 20:23:14.465883  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:23:14.465889  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00557125 (* 1 = 0.00557125 loss)
I0626 20:23:14.465893  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0174364 (* 1 = 0.0174364 loss)
I0626 20:23:14.465898  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.16083e-05 (* 1 = 3.16083e-05 loss)
I0626 20:23:14.465901  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00379359 (* 1 = 0.00379359 loss)
I0626 20:23:14.465905  4216 sgd_solver.cpp:106] Iteration 22100, lr = 2e-05
I0626 20:25:01.105178  4216 solver.cpp:228] Iteration 22120, loss = 0.18098
I0626 20:25:01.105204  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:25:01.105214  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138932 (* 1 = 0.0138932 loss)
I0626 20:25:01.105221  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0187842 (* 1 = 0.0187842 loss)
I0626 20:25:01.105226  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173638 (* 1 = 0.00173638 loss)
I0626 20:25:01.105232  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00815709 (* 1 = 0.00815709 loss)
I0626 20:25:01.105242  4216 sgd_solver.cpp:106] Iteration 22120, lr = 2e-05
I0626 20:26:47.768362  4216 solver.cpp:228] Iteration 22140, loss = 0.118704
I0626 20:26:47.768385  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 20:26:47.768393  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291254 (* 1 = 0.0291254 loss)
I0626 20:26:47.768396  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0776206 (* 1 = 0.0776206 loss)
I0626 20:26:47.768400  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164704 (* 1 = 0.0164704 loss)
I0626 20:26:47.768404  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0385922 (* 1 = 0.0385922 loss)
I0626 20:26:47.768409  4216 sgd_solver.cpp:106] Iteration 22140, lr = 2e-05
I0626 20:28:34.017158  4216 solver.cpp:228] Iteration 22160, loss = 0.166025
I0626 20:28:34.017182  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 20:28:34.017190  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.234892 (* 1 = 0.234892 loss)
I0626 20:28:34.017194  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.298831 (* 1 = 0.298831 loss)
I0626 20:28:34.017197  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0287382 (* 1 = 0.0287382 loss)
I0626 20:28:34.017201  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0743016 (* 1 = 0.0743016 loss)
I0626 20:28:34.017206  4216 sgd_solver.cpp:106] Iteration 22160, lr = 2e-05
I0626 20:30:19.645858  4216 solver.cpp:228] Iteration 22180, loss = 0.182801
I0626 20:30:19.645884  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 20:30:19.645891  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0267715 (* 1 = 0.0267715 loss)
I0626 20:30:19.645895  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.112537 (* 1 = 0.112537 loss)
I0626 20:30:19.645900  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0087124 (* 1 = 0.0087124 loss)
I0626 20:30:19.645905  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150723 (* 1 = 0.0150723 loss)
I0626 20:30:19.645910  4216 sgd_solver.cpp:106] Iteration 22180, lr = 2e-05
speed: 5.286s / iter
I0626 20:32:06.945760  4216 solver.cpp:228] Iteration 22200, loss = 0.102421
I0626 20:32:06.945788  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 20:32:06.945797  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0158101 (* 1 = 0.0158101 loss)
I0626 20:32:06.945804  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0715489 (* 1 = 0.0715489 loss)
I0626 20:32:06.945811  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000798633 (* 1 = 0.000798633 loss)
I0626 20:32:06.945816  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00513307 (* 1 = 0.00513307 loss)
I0626 20:32:06.945823  4216 sgd_solver.cpp:106] Iteration 22200, lr = 2e-05
I0626 20:33:53.568899  4216 solver.cpp:228] Iteration 22220, loss = 0.196499
I0626 20:33:53.568924  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 20:33:53.568933  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.139065 (* 1 = 0.139065 loss)
I0626 20:33:53.568936  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.186751 (* 1 = 0.186751 loss)
I0626 20:33:53.568941  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0230655 (* 1 = 0.0230655 loss)
I0626 20:33:53.568944  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387091 (* 1 = 0.0387091 loss)
I0626 20:33:53.568949  4216 sgd_solver.cpp:106] Iteration 22220, lr = 2e-05
I0626 20:35:43.162118  4216 solver.cpp:228] Iteration 22240, loss = 0.391053
I0626 20:35:43.162147  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 20:35:43.162153  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349173 (* 1 = 0.0349173 loss)
I0626 20:35:43.162158  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.185691 (* 1 = 0.185691 loss)
I0626 20:35:43.162163  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211073 (* 1 = 0.0211073 loss)
I0626 20:35:43.162165  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.333539 (* 1 = 0.333539 loss)
I0626 20:35:43.162170  4216 sgd_solver.cpp:106] Iteration 22240, lr = 2e-05
I0626 20:37:34.592527  4216 solver.cpp:228] Iteration 22260, loss = 0.119913
I0626 20:37:34.592555  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 20:37:34.592562  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.131705 (* 1 = 0.131705 loss)
I0626 20:37:34.592566  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.226512 (* 1 = 0.226512 loss)
I0626 20:37:34.592571  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102786 (* 1 = 0.0102786 loss)
I0626 20:37:34.592574  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297797 (* 1 = 0.0297797 loss)
I0626 20:37:34.592581  4216 sgd_solver.cpp:106] Iteration 22260, lr = 2e-05
I0626 20:39:25.659566  4216 solver.cpp:228] Iteration 22280, loss = 0.167454
I0626 20:39:25.659602  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:39:25.659612  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206025 (* 1 = 0.0206025 loss)
I0626 20:39:25.659620  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00897409 (* 1 = 0.00897409 loss)
I0626 20:39:25.659626  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00057045 (* 1 = 0.00057045 loss)
I0626 20:39:25.659631  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00132875 (* 1 = 0.00132875 loss)
I0626 20:39:25.659639  4216 sgd_solver.cpp:106] Iteration 22280, lr = 2e-05
I0626 20:41:17.200165  4216 solver.cpp:228] Iteration 22300, loss = 0.281828
I0626 20:41:17.200192  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:41:17.200199  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368667 (* 1 = 0.0368667 loss)
I0626 20:41:17.200204  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0353207 (* 1 = 0.0353207 loss)
I0626 20:41:17.200208  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00036878 (* 1 = 0.00036878 loss)
I0626 20:41:17.200212  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00938901 (* 1 = 0.00938901 loss)
I0626 20:41:17.200217  4216 sgd_solver.cpp:106] Iteration 22300, lr = 2e-05
I0626 20:43:08.646966  4216 solver.cpp:228] Iteration 22320, loss = 0.201402
I0626 20:43:08.646994  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:43:08.647002  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000276165 (* 1 = 0.000276165 loss)
I0626 20:43:08.647006  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.022952 (* 1 = 0.022952 loss)
I0626 20:43:08.647011  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0059847 (* 1 = 0.0059847 loss)
I0626 20:43:08.647014  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148984 (* 1 = 0.0148984 loss)
I0626 20:43:08.647019  4216 sgd_solver.cpp:106] Iteration 22320, lr = 2e-05
I0626 20:44:59.276764  4216 solver.cpp:228] Iteration 22340, loss = 0.157796
I0626 20:44:59.276792  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:44:59.276798  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0281649 (* 1 = 0.0281649 loss)
I0626 20:44:59.276803  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0447875 (* 1 = 0.0447875 loss)
I0626 20:44:59.276806  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000354911 (* 1 = 0.000354911 loss)
I0626 20:44:59.276810  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00954311 (* 1 = 0.00954311 loss)
I0626 20:44:59.276815  4216 sgd_solver.cpp:106] Iteration 22340, lr = 2e-05
I0626 20:46:46.794132  4216 solver.cpp:228] Iteration 22360, loss = 0.192356
I0626 20:46:46.794160  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:46:46.794168  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122486 (* 1 = 0.0122486 loss)
I0626 20:46:46.794174  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0160975 (* 1 = 0.0160975 loss)
I0626 20:46:46.794178  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00316821 (* 1 = 0.00316821 loss)
I0626 20:46:46.794183  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0018979 (* 1 = 0.0018979 loss)
I0626 20:46:46.794188  4216 sgd_solver.cpp:106] Iteration 22360, lr = 2e-05
I0626 20:48:33.728783  4216 solver.cpp:228] Iteration 22380, loss = 0.16603
I0626 20:48:33.728811  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:48:33.728818  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0304195 (* 1 = 0.0304195 loss)
I0626 20:48:33.728822  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.12776 (* 1 = 0.12776 loss)
I0626 20:48:33.728826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00769764 (* 1 = 0.00769764 loss)
I0626 20:48:33.728830  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297875 (* 1 = 0.0297875 loss)
I0626 20:48:33.728835  4216 sgd_solver.cpp:106] Iteration 22380, lr = 2e-05
speed: 5.288s / iter
I0626 20:50:20.458276  4216 solver.cpp:228] Iteration 22400, loss = 0.158113
I0626 20:50:20.458300  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:50:20.458307  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599102 (* 1 = 0.0599102 loss)
I0626 20:50:20.458312  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0441522 (* 1 = 0.0441522 loss)
I0626 20:50:20.458315  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00038337 (* 1 = 0.00038337 loss)
I0626 20:50:20.458319  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165571 (* 1 = 0.0165571 loss)
I0626 20:50:20.458323  4216 sgd_solver.cpp:106] Iteration 22400, lr = 2e-05
I0626 20:52:06.995613  4216 solver.cpp:228] Iteration 22420, loss = 0.0934185
I0626 20:52:06.995642  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:52:06.995649  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0260512 (* 1 = 0.0260512 loss)
I0626 20:52:06.995654  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0161497 (* 1 = 0.0161497 loss)
I0626 20:52:06.995657  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00952316 (* 1 = 0.00952316 loss)
I0626 20:52:06.995661  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159886 (* 1 = 0.0159886 loss)
I0626 20:52:06.995667  4216 sgd_solver.cpp:106] Iteration 22420, lr = 2e-05
I0626 20:53:53.539402  4216 solver.cpp:228] Iteration 22440, loss = 0.168242
I0626 20:53:53.539435  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 20:53:53.539443  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321157 (* 1 = 0.0321157 loss)
I0626 20:53:53.539448  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.194154 (* 1 = 0.194154 loss)
I0626 20:53:53.539453  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014272 (* 1 = 0.014272 loss)
I0626 20:53:53.539456  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0908591 (* 1 = 0.0908591 loss)
I0626 20:53:53.539463  4216 sgd_solver.cpp:106] Iteration 22440, lr = 2e-05
I0626 20:55:40.710157  4216 solver.cpp:228] Iteration 22460, loss = 0.184654
I0626 20:55:40.710187  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 20:55:40.710196  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.052511 (* 1 = 0.052511 loss)
I0626 20:55:40.710201  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0983081 (* 1 = 0.0983081 loss)
I0626 20:55:40.710204  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00469237 (* 1 = 0.00469237 loss)
I0626 20:55:40.710208  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.032948 (* 1 = 0.032948 loss)
I0626 20:55:40.710214  4216 sgd_solver.cpp:106] Iteration 22460, lr = 2e-05
I0626 20:57:27.797396  4216 solver.cpp:228] Iteration 22480, loss = 0.132446
I0626 20:57:27.797423  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:57:27.797433  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305304 (* 1 = 0.0305304 loss)
I0626 20:57:27.797439  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.069792 (* 1 = 0.069792 loss)
I0626 20:57:27.797446  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000716337 (* 1 = 0.000716337 loss)
I0626 20:57:27.797451  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00378467 (* 1 = 0.00378467 loss)
I0626 20:57:27.797458  4216 sgd_solver.cpp:106] Iteration 22480, lr = 2e-05
I0626 20:59:14.122221  4216 solver.cpp:228] Iteration 22500, loss = 0.271636
I0626 20:59:14.122246  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:59:14.122253  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0139033 (* 1 = 0.0139033 loss)
I0626 20:59:14.122257  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0300903 (* 1 = 0.0300903 loss)
I0626 20:59:14.122262  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000262833 (* 1 = 0.000262833 loss)
I0626 20:59:14.122265  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00260402 (* 1 = 0.00260402 loss)
I0626 20:59:14.122269  4216 sgd_solver.cpp:106] Iteration 22500, lr = 2e-05
I0626 21:01:00.601301  4216 solver.cpp:228] Iteration 22520, loss = 0.328344
I0626 21:01:00.601326  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 21:01:00.601335  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.254978 (* 1 = 0.254978 loss)
I0626 21:01:00.601338  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.342375 (* 1 = 0.342375 loss)
I0626 21:01:00.601342  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00334199 (* 1 = 0.00334199 loss)
I0626 21:01:00.601346  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128562 (* 1 = 0.128562 loss)
I0626 21:01:00.601351  4216 sgd_solver.cpp:106] Iteration 22520, lr = 2e-05
I0626 21:02:47.329542  4216 solver.cpp:228] Iteration 22540, loss = 0.0838494
I0626 21:02:47.329566  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:02:47.329573  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126219 (* 1 = 0.0126219 loss)
I0626 21:02:47.329576  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0365428 (* 1 = 0.0365428 loss)
I0626 21:02:47.329581  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00283551 (* 1 = 0.00283551 loss)
I0626 21:02:47.329583  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133778 (* 1 = 0.0133778 loss)
I0626 21:02:47.329587  4216 sgd_solver.cpp:106] Iteration 22540, lr = 2e-05
I0626 21:04:34.257537  4216 solver.cpp:228] Iteration 22560, loss = 0.196409
I0626 21:04:34.257566  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 21:04:34.257575  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0124398 (* 1 = 0.0124398 loss)
I0626 21:04:34.257580  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0125732 (* 1 = 0.0125732 loss)
I0626 21:04:34.257585  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000223821 (* 1 = 0.000223821 loss)
I0626 21:04:34.257588  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107633 (* 1 = 0.0107633 loss)
I0626 21:04:34.257594  4216 sgd_solver.cpp:106] Iteration 22560, lr = 2e-05
I0626 21:06:21.114122  4216 solver.cpp:228] Iteration 22580, loss = 0.136784
I0626 21:06:21.114148  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:06:21.114156  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142511 (* 1 = 0.0142511 loss)
I0626 21:06:21.114159  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0175888 (* 1 = 0.0175888 loss)
I0626 21:06:21.114162  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0021159 (* 1 = 0.0021159 loss)
I0626 21:06:21.114166  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305584 (* 1 = 0.0305584 loss)
I0626 21:06:21.114171  4216 sgd_solver.cpp:106] Iteration 22580, lr = 2e-05
speed: 5.288s / iter
I0626 21:08:07.085680  4216 solver.cpp:228] Iteration 22600, loss = 0.234336
I0626 21:08:07.085718  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 21:08:07.085731  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.115612 (* 1 = 0.115612 loss)
I0626 21:08:07.085739  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.239012 (* 1 = 0.239012 loss)
I0626 21:08:07.085747  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00255582 (* 1 = 0.00255582 loss)
I0626 21:08:07.085783  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025739 (* 1 = 0.025739 loss)
I0626 21:08:07.085803  4216 sgd_solver.cpp:106] Iteration 22600, lr = 2e-05
I0626 21:09:53.731590  4216 solver.cpp:228] Iteration 22620, loss = 0.135286
I0626 21:09:53.731613  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:09:53.731621  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147501 (* 1 = 0.0147501 loss)
I0626 21:09:53.731626  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0228019 (* 1 = 0.0228019 loss)
I0626 21:09:53.731628  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00246508 (* 1 = 0.00246508 loss)
I0626 21:09:53.731632  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00814813 (* 1 = 0.00814813 loss)
I0626 21:09:53.731637  4216 sgd_solver.cpp:106] Iteration 22620, lr = 2e-05
I0626 21:11:39.757269  4216 solver.cpp:228] Iteration 22640, loss = 0.16113
I0626 21:11:39.757302  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:11:39.757308  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0219217 (* 1 = 0.0219217 loss)
I0626 21:11:39.757314  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0347882 (* 1 = 0.0347882 loss)
I0626 21:11:39.757319  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000279918 (* 1 = 0.000279918 loss)
I0626 21:11:39.757323  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00585492 (* 1 = 0.00585492 loss)
I0626 21:11:39.757329  4216 sgd_solver.cpp:106] Iteration 22640, lr = 2e-05
I0626 21:13:27.286782  4216 solver.cpp:228] Iteration 22660, loss = 0.147599
I0626 21:13:27.286808  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:13:27.286815  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0110617 (* 1 = 0.0110617 loss)
I0626 21:13:27.286819  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0161412 (* 1 = 0.0161412 loss)
I0626 21:13:27.286823  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000920967 (* 1 = 0.000920967 loss)
I0626 21:13:27.286828  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00792158 (* 1 = 0.00792158 loss)
I0626 21:13:27.286833  4216 sgd_solver.cpp:106] Iteration 22660, lr = 2e-05
I0626 21:15:13.483934  4216 solver.cpp:228] Iteration 22680, loss = 0.14
I0626 21:15:13.483961  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:15:13.483969  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122613 (* 1 = 0.0122613 loss)
I0626 21:15:13.483974  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0882346 (* 1 = 0.0882346 loss)
I0626 21:15:13.483978  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00287775 (* 1 = 0.00287775 loss)
I0626 21:15:13.483981  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109025 (* 1 = 0.0109025 loss)
I0626 21:15:13.483988  4216 sgd_solver.cpp:106] Iteration 22680, lr = 2e-05
I0626 21:17:00.521049  4216 solver.cpp:228] Iteration 22700, loss = 0.282444
I0626 21:17:00.521077  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:17:00.521085  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0110357 (* 1 = 0.0110357 loss)
I0626 21:17:00.521090  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0320071 (* 1 = 0.0320071 loss)
I0626 21:17:00.521095  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131967 (* 1 = 0.0131967 loss)
I0626 21:17:00.521098  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485502 (* 1 = 0.0485502 loss)
I0626 21:17:00.521104  4216 sgd_solver.cpp:106] Iteration 22700, lr = 2e-05
I0626 21:18:46.770246  4216 solver.cpp:228] Iteration 22720, loss = 0.211383
I0626 21:18:46.770272  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 21:18:46.770280  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0477314 (* 1 = 0.0477314 loss)
I0626 21:18:46.770284  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.153689 (* 1 = 0.153689 loss)
I0626 21:18:46.770289  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00088689 (* 1 = 0.00088689 loss)
I0626 21:18:46.770293  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154767 (* 1 = 0.0154767 loss)
I0626 21:18:46.770298  4216 sgd_solver.cpp:106] Iteration 22720, lr = 2e-05
I0626 21:20:32.009740  4216 solver.cpp:228] Iteration 22740, loss = 0.164283
I0626 21:20:32.009765  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:20:32.009773  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0104045 (* 1 = 0.0104045 loss)
I0626 21:20:32.009778  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0284371 (* 1 = 0.0284371 loss)
I0626 21:20:32.009780  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351625 (* 1 = 0.00351625 loss)
I0626 21:20:32.009784  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00721976 (* 1 = 0.00721976 loss)
I0626 21:20:32.009789  4216 sgd_solver.cpp:106] Iteration 22740, lr = 2e-05
I0626 21:22:18.818518  4216 solver.cpp:228] Iteration 22760, loss = 0.081655
I0626 21:22:18.818543  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 21:22:18.818550  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.094425 (* 1 = 0.094425 loss)
I0626 21:22:18.818554  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0838413 (* 1 = 0.0838413 loss)
I0626 21:22:18.818558  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000878875 (* 1 = 0.000878875 loss)
I0626 21:22:18.818562  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264656 (* 1 = 0.0264656 loss)
I0626 21:22:18.818565  4216 sgd_solver.cpp:106] Iteration 22760, lr = 2e-05
I0626 21:24:04.450464  4216 solver.cpp:228] Iteration 22780, loss = 0.180536
I0626 21:24:04.450487  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 21:24:04.450495  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685929 (* 1 = 0.0685929 loss)
I0626 21:24:04.450500  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.113661 (* 1 = 0.113661 loss)
I0626 21:24:04.450502  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110637 (* 1 = 0.0110637 loss)
I0626 21:24:04.450506  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375835 (* 1 = 0.0375835 loss)
I0626 21:24:04.450510  4216 sgd_solver.cpp:106] Iteration 22780, lr = 2e-05
speed: 5.288s / iter
I0626 21:25:50.441969  4216 solver.cpp:228] Iteration 22800, loss = 0.122071
I0626 21:25:50.441995  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 21:25:50.442003  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0928042 (* 1 = 0.0928042 loss)
I0626 21:25:50.442008  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108759 (* 1 = 0.108759 loss)
I0626 21:25:50.442013  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000870573 (* 1 = 0.000870573 loss)
I0626 21:25:50.442015  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024528 (* 1 = 0.024528 loss)
I0626 21:25:50.442020  4216 sgd_solver.cpp:106] Iteration 22800, lr = 2e-05
I0626 21:27:36.292150  4216 solver.cpp:228] Iteration 22820, loss = 0.214993
I0626 21:27:36.292174  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 21:27:36.292181  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120686 (* 1 = 0.120686 loss)
I0626 21:27:36.292186  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147179 (* 1 = 0.147179 loss)
I0626 21:27:36.292188  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126031 (* 1 = 0.00126031 loss)
I0626 21:27:36.292192  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0559818 (* 1 = 0.0559818 loss)
I0626 21:27:36.292197  4216 sgd_solver.cpp:106] Iteration 22820, lr = 2e-05
I0626 21:29:22.638177  4216 solver.cpp:228] Iteration 22840, loss = 0.146045
I0626 21:29:22.638203  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 21:29:22.638213  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0134217 (* 1 = 0.0134217 loss)
I0626 21:29:22.638221  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00442133 (* 1 = 0.00442133 loss)
I0626 21:29:22.638226  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00072756 (* 1 = 0.00072756 loss)
I0626 21:29:22.638233  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00895702 (* 1 = 0.00895702 loss)
I0626 21:29:22.638240  4216 sgd_solver.cpp:106] Iteration 22840, lr = 2e-05
I0626 21:31:08.628619  4216 solver.cpp:228] Iteration 22860, loss = 0.173905
I0626 21:31:08.628643  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 21:31:08.628649  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.118313 (* 1 = 0.118313 loss)
I0626 21:31:08.628654  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.13403 (* 1 = 0.13403 loss)
I0626 21:31:08.628657  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577877 (* 1 = 0.00577877 loss)
I0626 21:31:08.628661  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0410408 (* 1 = 0.0410408 loss)
I0626 21:31:08.628665  4216 sgd_solver.cpp:106] Iteration 22860, lr = 2e-05
I0626 21:32:54.658418  4216 solver.cpp:228] Iteration 22880, loss = 0.127704
I0626 21:32:54.658443  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:32:54.658452  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0520312 (* 1 = 0.0520312 loss)
I0626 21:32:54.658457  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0437792 (* 1 = 0.0437792 loss)
I0626 21:32:54.658460  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00499069 (* 1 = 0.00499069 loss)
I0626 21:32:54.658465  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129681 (* 1 = 0.0129681 loss)
I0626 21:32:54.658470  4216 sgd_solver.cpp:106] Iteration 22880, lr = 2e-05
I0626 21:34:40.762614  4216 solver.cpp:228] Iteration 22900, loss = 0.0818642
I0626 21:34:40.762650  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:34:40.762661  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562886 (* 1 = 0.0562886 loss)
I0626 21:34:40.762668  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0468437 (* 1 = 0.0468437 loss)
I0626 21:34:40.762675  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351581 (* 1 = 0.00351581 loss)
I0626 21:34:40.762681  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235518 (* 1 = 0.0235518 loss)
I0626 21:34:40.762688  4216 sgd_solver.cpp:106] Iteration 22900, lr = 2e-05
I0626 21:36:27.074441  4216 solver.cpp:228] Iteration 22920, loss = 0.314883
I0626 21:36:27.074470  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 21:36:27.074478  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.249866 (* 1 = 0.249866 loss)
I0626 21:36:27.074482  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.212063 (* 1 = 0.212063 loss)
I0626 21:36:27.074486  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00324335 (* 1 = 0.00324335 loss)
I0626 21:36:27.074491  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0561498 (* 1 = 0.0561498 loss)
I0626 21:36:27.074496  4216 sgd_solver.cpp:106] Iteration 22920, lr = 2e-05
I0626 21:38:13.057898  4216 solver.cpp:228] Iteration 22940, loss = 0.283192
I0626 21:38:13.057929  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:38:13.057935  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204388 (* 1 = 0.0204388 loss)
I0626 21:38:13.057940  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109256 (* 1 = 0.109256 loss)
I0626 21:38:13.057945  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132854 (* 1 = 0.0132854 loss)
I0626 21:38:13.057947  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119718 (* 1 = 0.0119718 loss)
I0626 21:38:13.057953  4216 sgd_solver.cpp:106] Iteration 22940, lr = 2e-05
I0626 21:39:59.044827  4216 solver.cpp:228] Iteration 22960, loss = 0.133239
I0626 21:39:59.044852  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:39:59.044858  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0602056 (* 1 = 0.0602056 loss)
I0626 21:39:59.044862  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0705855 (* 1 = 0.0705855 loss)
I0626 21:39:59.044867  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000324729 (* 1 = 0.000324729 loss)
I0626 21:39:59.044870  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0096777 (* 1 = 0.0096777 loss)
I0626 21:39:59.044874  4216 sgd_solver.cpp:106] Iteration 22960, lr = 2e-05
I0626 21:41:45.079315  4216 solver.cpp:228] Iteration 22980, loss = 0.30155
I0626 21:41:45.079340  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0626 21:41:45.079349  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.435273 (* 1 = 0.435273 loss)
I0626 21:41:45.079352  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.510202 (* 1 = 0.510202 loss)
I0626 21:41:45.079356  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.044178 (* 1 = 0.044178 loss)
I0626 21:41:45.079360  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.24034 (* 1 = 0.24034 loss)
I0626 21:41:45.079365  4216 sgd_solver.cpp:106] Iteration 22980, lr = 2e-05
speed: 5.289s / iter
I0626 21:43:30.972641  4216 solver.cpp:228] Iteration 23000, loss = 0.113503
I0626 21:43:30.972666  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 21:43:30.972673  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197342 (* 1 = 0.0197342 loss)
I0626 21:43:30.972677  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.023067 (* 1 = 0.023067 loss)
I0626 21:43:30.972681  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00185029 (* 1 = 0.00185029 loss)
I0626 21:43:30.972684  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00460914 (* 1 = 0.00460914 loss)
I0626 21:43:30.972689  4216 sgd_solver.cpp:106] Iteration 23000, lr = 2e-05
I0626 21:45:17.138520  4216 solver.cpp:228] Iteration 23020, loss = 0.178896
I0626 21:45:17.138545  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:45:17.138552  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234057 (* 1 = 0.0234057 loss)
I0626 21:45:17.138558  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0398756 (* 1 = 0.0398756 loss)
I0626 21:45:17.138562  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000161594 (* 1 = 0.000161594 loss)
I0626 21:45:17.138566  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00821425 (* 1 = 0.00821425 loss)
I0626 21:45:17.138571  4216 sgd_solver.cpp:106] Iteration 23020, lr = 2e-05
I0626 21:47:02.928278  4216 solver.cpp:228] Iteration 23040, loss = 0.305413
I0626 21:47:02.928304  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 21:47:02.928311  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529223 (* 1 = 0.0529223 loss)
I0626 21:47:02.928315  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0544369 (* 1 = 0.0544369 loss)
I0626 21:47:02.928319  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118084 (* 1 = 0.00118084 loss)
I0626 21:47:02.928323  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131873 (* 1 = 0.0131873 loss)
I0626 21:47:02.928328  4216 sgd_solver.cpp:106] Iteration 23040, lr = 2e-05
I0626 21:48:49.476490  4216 solver.cpp:228] Iteration 23060, loss = 0.13695
I0626 21:48:49.476513  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 21:48:49.476519  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264811 (* 1 = 0.0264811 loss)
I0626 21:48:49.476523  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117475 (* 1 = 0.117475 loss)
I0626 21:48:49.476526  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102766 (* 1 = 0.0102766 loss)
I0626 21:48:49.476531  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178826 (* 1 = 0.0178826 loss)
I0626 21:48:49.476534  4216 sgd_solver.cpp:106] Iteration 23060, lr = 2e-05
I0626 21:50:34.771831  4216 solver.cpp:228] Iteration 23080, loss = 0.275542
I0626 21:50:34.771854  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 21:50:34.771862  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308977 (* 1 = 0.0308977 loss)
I0626 21:50:34.771865  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0987551 (* 1 = 0.0987551 loss)
I0626 21:50:34.771869  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00530614 (* 1 = 0.00530614 loss)
I0626 21:50:34.771872  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025665 (* 1 = 0.025665 loss)
I0626 21:50:34.771878  4216 sgd_solver.cpp:106] Iteration 23080, lr = 2e-05
I0626 21:52:20.347235  4216 solver.cpp:228] Iteration 23100, loss = 0.15425
I0626 21:52:20.347259  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:52:20.347267  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00115623 (* 1 = 0.00115623 loss)
I0626 21:52:20.347272  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0314489 (* 1 = 0.0314489 loss)
I0626 21:52:20.347276  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103617 (* 1 = 0.00103617 loss)
I0626 21:52:20.347281  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113619 (* 1 = 0.0113619 loss)
I0626 21:52:20.347286  4216 sgd_solver.cpp:106] Iteration 23100, lr = 2e-05
I0626 21:54:05.951624  4216 solver.cpp:228] Iteration 23120, loss = 0.0809334
I0626 21:54:05.951648  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:54:05.951656  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00778358 (* 1 = 0.00778358 loss)
I0626 21:54:05.951660  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0164978 (* 1 = 0.0164978 loss)
I0626 21:54:05.951664  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127085 (* 1 = 0.00127085 loss)
I0626 21:54:05.951668  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.004878 (* 1 = 0.004878 loss)
I0626 21:54:05.951673  4216 sgd_solver.cpp:106] Iteration 23120, lr = 2e-05
I0626 21:55:53.194793  4216 solver.cpp:228] Iteration 23140, loss = 0.16436
I0626 21:55:53.194818  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 21:55:53.194824  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150671 (* 1 = 0.0150671 loss)
I0626 21:55:53.194828  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0637533 (* 1 = 0.0637533 loss)
I0626 21:55:53.194833  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.86646e-05 (* 1 = 4.86646e-05 loss)
I0626 21:55:53.194836  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00391832 (* 1 = 0.00391832 loss)
I0626 21:55:53.194840  4216 sgd_solver.cpp:106] Iteration 23140, lr = 2e-05
I0626 21:57:38.829490  4216 solver.cpp:228] Iteration 23160, loss = 0.134652
I0626 21:57:38.829519  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 21:57:38.829526  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.154157 (* 1 = 0.154157 loss)
I0626 21:57:38.829533  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.132816 (* 1 = 0.132816 loss)
I0626 21:57:38.829540  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00321594 (* 1 = 0.00321594 loss)
I0626 21:57:38.829548  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383884 (* 1 = 0.0383884 loss)
I0626 21:57:38.829563  4216 sgd_solver.cpp:106] Iteration 23160, lr = 2e-05
I0626 21:59:24.680640  4216 solver.cpp:228] Iteration 23180, loss = 0.130543
I0626 21:59:24.680666  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:59:24.680675  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.163786 (* 1 = 0.163786 loss)
I0626 21:59:24.680681  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0483963 (* 1 = 0.0483963 loss)
I0626 21:59:24.680687  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000617107 (* 1 = 0.000617107 loss)
I0626 21:59:24.680693  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321164 (* 1 = 0.0321164 loss)
I0626 21:59:24.680701  4216 sgd_solver.cpp:106] Iteration 23180, lr = 2e-05
speed: 5.289s / iter
I0626 22:01:11.421546  4216 solver.cpp:228] Iteration 23200, loss = 0.127265
I0626 22:01:11.421577  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 22:01:11.421586  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0901069 (* 1 = 0.0901069 loss)
I0626 22:01:11.421589  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.1899 (* 1 = 0.1899 loss)
I0626 22:01:11.421593  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398419 (* 1 = 0.00398419 loss)
I0626 22:01:11.421597  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0462928 (* 1 = 0.0462928 loss)
I0626 22:01:11.421603  4216 sgd_solver.cpp:106] Iteration 23200, lr = 2e-05
I0626 22:02:57.487512  4216 solver.cpp:228] Iteration 23220, loss = 0.295165
I0626 22:02:57.487540  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 22:02:57.487547  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.103676 (* 1 = 0.103676 loss)
I0626 22:02:57.487552  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.182645 (* 1 = 0.182645 loss)
I0626 22:02:57.487556  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120165 (* 1 = 0.0120165 loss)
I0626 22:02:57.487560  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277274 (* 1 = 0.0277274 loss)
I0626 22:02:57.487565  4216 sgd_solver.cpp:106] Iteration 23220, lr = 2e-05
I0626 22:04:43.923856  4216 solver.cpp:228] Iteration 23240, loss = 0.0964858
I0626 22:04:43.923879  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:04:43.923887  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0394061 (* 1 = 0.0394061 loss)
I0626 22:04:43.923892  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.030612 (* 1 = 0.030612 loss)
I0626 22:04:43.923897  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00145804 (* 1 = 0.00145804 loss)
I0626 22:04:43.923899  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00858261 (* 1 = 0.00858261 loss)
I0626 22:04:43.923905  4216 sgd_solver.cpp:106] Iteration 23240, lr = 2e-05
I0626 22:06:30.876037  4216 solver.cpp:228] Iteration 23260, loss = 0.142346
I0626 22:06:30.876063  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:06:30.876071  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574419 (* 1 = 0.0574419 loss)
I0626 22:06:30.876076  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0850546 (* 1 = 0.0850546 loss)
I0626 22:06:30.876080  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00200339 (* 1 = 0.00200339 loss)
I0626 22:06:30.876085  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302555 (* 1 = 0.0302555 loss)
I0626 22:06:30.876088  4216 sgd_solver.cpp:106] Iteration 23260, lr = 2e-05
I0626 22:08:17.987128  4216 solver.cpp:228] Iteration 23280, loss = 0.0806179
I0626 22:08:17.987159  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 22:08:17.987166  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336615 (* 1 = 0.0336615 loss)
I0626 22:08:17.987170  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0611692 (* 1 = 0.0611692 loss)
I0626 22:08:17.987175  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000403597 (* 1 = 0.000403597 loss)
I0626 22:08:17.987179  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00642356 (* 1 = 0.00642356 loss)
I0626 22:08:17.987185  4216 sgd_solver.cpp:106] Iteration 23280, lr = 2e-05
I0626 22:10:04.215672  4216 solver.cpp:228] Iteration 23300, loss = 0.0745671
I0626 22:10:04.215698  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:10:04.215704  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000311285 (* 1 = 0.000311285 loss)
I0626 22:10:04.215708  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00535281 (* 1 = 0.00535281 loss)
I0626 22:10:04.215713  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105588 (* 1 = 0.00105588 loss)
I0626 22:10:04.215716  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00866449 (* 1 = 0.00866449 loss)
I0626 22:10:04.215721  4216 sgd_solver.cpp:106] Iteration 23300, lr = 2e-05
I0626 22:11:49.999163  4216 solver.cpp:228] Iteration 23320, loss = 0.158267
I0626 22:11:49.999188  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 22:11:49.999197  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.112395 (* 1 = 0.112395 loss)
I0626 22:11:49.999200  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.335988 (* 1 = 0.335988 loss)
I0626 22:11:49.999203  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204936 (* 1 = 0.00204936 loss)
I0626 22:11:49.999207  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173246 (* 1 = 0.0173246 loss)
I0626 22:11:49.999212  4216 sgd_solver.cpp:106] Iteration 23320, lr = 2e-05
I0626 22:13:35.912379  4216 solver.cpp:228] Iteration 23340, loss = 0.198277
I0626 22:13:35.912405  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 22:13:35.912412  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.1848 (* 1 = 0.1848 loss)
I0626 22:13:35.912417  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.233087 (* 1 = 0.233087 loss)
I0626 22:13:35.912421  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00502336 (* 1 = 0.00502336 loss)
I0626 22:13:35.912425  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352953 (* 1 = 0.0352953 loss)
I0626 22:13:35.912431  4216 sgd_solver.cpp:106] Iteration 23340, lr = 2e-05
I0626 22:15:22.016798  4216 solver.cpp:228] Iteration 23360, loss = 0.132694
I0626 22:15:22.016821  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:15:22.016829  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000290305 (* 1 = 0.000290305 loss)
I0626 22:15:22.016832  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.040291 (* 1 = 0.040291 loss)
I0626 22:15:22.016836  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0097427 (* 1 = 0.0097427 loss)
I0626 22:15:22.016840  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186303 (* 1 = 0.0186303 loss)
I0626 22:15:22.016844  4216 sgd_solver.cpp:106] Iteration 23360, lr = 2e-05
I0626 22:17:08.544234  4216 solver.cpp:228] Iteration 23380, loss = 0.112791
I0626 22:17:08.544258  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:17:08.544265  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128528 (* 1 = 0.0128528 loss)
I0626 22:17:08.544270  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0177217 (* 1 = 0.0177217 loss)
I0626 22:17:08.544273  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000318572 (* 1 = 0.000318572 loss)
I0626 22:17:08.544277  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00938606 (* 1 = 0.00938606 loss)
I0626 22:17:08.544282  4216 sgd_solver.cpp:106] Iteration 23380, lr = 2e-05
speed: 5.289s / iter
I0626 22:18:54.501222  4216 solver.cpp:228] Iteration 23400, loss = 0.199472
I0626 22:18:54.501246  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:18:54.501255  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176401 (* 1 = 0.0176401 loss)
I0626 22:18:54.501258  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0764211 (* 1 = 0.0764211 loss)
I0626 22:18:54.501261  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245545 (* 1 = 0.0245545 loss)
I0626 22:18:54.501266  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00888264 (* 1 = 0.00888264 loss)
I0626 22:18:54.501271  4216 sgd_solver.cpp:106] Iteration 23400, lr = 2e-05
I0626 22:20:40.908304  4216 solver.cpp:228] Iteration 23420, loss = 0.28378
I0626 22:20:40.908331  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:20:40.908339  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135522 (* 1 = 0.0135522 loss)
I0626 22:20:40.908344  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00766207 (* 1 = 0.00766207 loss)
I0626 22:20:40.908347  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000918126 (* 1 = 0.000918126 loss)
I0626 22:20:40.908351  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00729423 (* 1 = 0.00729423 loss)
I0626 22:20:40.908357  4216 sgd_solver.cpp:106] Iteration 23420, lr = 2e-05
I0626 22:22:27.323518  4216 solver.cpp:228] Iteration 23440, loss = 0.136321
I0626 22:22:27.323544  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 22:22:27.323554  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454931 (* 1 = 0.0454931 loss)
I0626 22:22:27.323559  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0578926 (* 1 = 0.0578926 loss)
I0626 22:22:27.323562  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00539371 (* 1 = 0.00539371 loss)
I0626 22:22:27.323566  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00901066 (* 1 = 0.00901066 loss)
I0626 22:22:27.323572  4216 sgd_solver.cpp:106] Iteration 23440, lr = 2e-05
I0626 22:24:14.136745  4216 solver.cpp:228] Iteration 23460, loss = 0.199271
I0626 22:24:14.136776  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:24:14.136783  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.117121 (* 1 = 0.117121 loss)
I0626 22:24:14.136788  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.15705 (* 1 = 0.15705 loss)
I0626 22:24:14.136791  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.008746 (* 1 = 0.008746 loss)
I0626 22:24:14.136795  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.092097 (* 1 = 0.092097 loss)
I0626 22:24:14.136801  4216 sgd_solver.cpp:106] Iteration 23460, lr = 2e-05
I0626 22:26:01.195719  4216 solver.cpp:228] Iteration 23480, loss = 0.117725
I0626 22:26:01.195744  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:26:01.195750  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0134151 (* 1 = 0.0134151 loss)
I0626 22:26:01.195755  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0564361 (* 1 = 0.0564361 loss)
I0626 22:26:01.195758  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00066987 (* 1 = 0.00066987 loss)
I0626 22:26:01.195762  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00927176 (* 1 = 0.00927176 loss)
I0626 22:26:01.195766  4216 sgd_solver.cpp:106] Iteration 23480, lr = 2e-05
I0626 22:27:48.604583  4216 solver.cpp:228] Iteration 23500, loss = 0.209254
I0626 22:27:48.604610  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 22:27:48.604617  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120917 (* 1 = 0.120917 loss)
I0626 22:27:48.604624  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.175318 (* 1 = 0.175318 loss)
I0626 22:27:48.604627  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000404979 (* 1 = 0.000404979 loss)
I0626 22:27:48.604631  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203011 (* 1 = 0.0203011 loss)
I0626 22:27:48.604637  4216 sgd_solver.cpp:106] Iteration 23500, lr = 2e-05
I0626 22:29:35.333973  4216 solver.cpp:228] Iteration 23520, loss = 0.162906
I0626 22:29:35.334000  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:29:35.334007  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0119917 (* 1 = 0.0119917 loss)
I0626 22:29:35.334012  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.019913 (* 1 = 0.019913 loss)
I0626 22:29:35.334015  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000441497 (* 1 = 0.000441497 loss)
I0626 22:29:35.334019  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00549389 (* 1 = 0.00549389 loss)
I0626 22:29:35.334024  4216 sgd_solver.cpp:106] Iteration 23520, lr = 2e-05
I0626 22:31:21.681620  4216 solver.cpp:228] Iteration 23540, loss = 0.178263
I0626 22:31:21.681644  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 22:31:21.681651  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.101913 (* 1 = 0.101913 loss)
I0626 22:31:21.681655  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.144278 (* 1 = 0.144278 loss)
I0626 22:31:21.681659  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232503 (* 1 = 0.00232503 loss)
I0626 22:31:21.681663  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139168 (* 1 = 0.0139168 loss)
I0626 22:31:21.681668  4216 sgd_solver.cpp:106] Iteration 23540, lr = 2e-05
I0626 22:33:07.844738  4216 solver.cpp:228] Iteration 23560, loss = 0.116128
I0626 22:33:07.844763  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 22:33:07.844772  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0790009 (* 1 = 0.0790009 loss)
I0626 22:33:07.844779  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.100819 (* 1 = 0.100819 loss)
I0626 22:33:07.844784  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165247 (* 1 = 0.00165247 loss)
I0626 22:33:07.844789  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260273 (* 1 = 0.0260273 loss)
I0626 22:33:07.844794  4216 sgd_solver.cpp:106] Iteration 23560, lr = 2e-05
I0626 22:34:54.194413  4216 solver.cpp:228] Iteration 23580, loss = 0.346707
I0626 22:34:54.194438  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:34:54.194447  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.033492 (* 1 = 0.033492 loss)
I0626 22:34:54.194450  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0518821 (* 1 = 0.0518821 loss)
I0626 22:34:54.194455  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000209561 (* 1 = 0.000209561 loss)
I0626 22:34:54.194459  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00305068 (* 1 = 0.00305068 loss)
I0626 22:34:54.194464  4216 sgd_solver.cpp:106] Iteration 23580, lr = 2e-05
speed: 5.289s / iter
I0626 22:36:39.810189  4216 solver.cpp:228] Iteration 23600, loss = 0.154165
I0626 22:36:39.810214  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 22:36:39.810225  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0328171 (* 1 = 0.0328171 loss)
I0626 22:36:39.810230  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0760657 (* 1 = 0.0760657 loss)
I0626 22:36:39.810237  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00419929 (* 1 = 0.00419929 loss)
I0626 22:36:39.810243  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00901962 (* 1 = 0.00901962 loss)
I0626 22:36:39.810250  4216 sgd_solver.cpp:106] Iteration 23600, lr = 2e-05
I0626 22:38:25.036481  4216 solver.cpp:228] Iteration 23620, loss = 0.20284
I0626 22:38:25.036506  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:38:25.036514  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318021 (* 1 = 0.0318021 loss)
I0626 22:38:25.036518  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0203427 (* 1 = 0.0203427 loss)
I0626 22:38:25.036522  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000313572 (* 1 = 0.000313572 loss)
I0626 22:38:25.036526  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00410252 (* 1 = 0.00410252 loss)
I0626 22:38:25.036532  4216 sgd_solver.cpp:106] Iteration 23620, lr = 2e-05
I0626 22:40:10.321944  4216 solver.cpp:228] Iteration 23640, loss = 0.219731
I0626 22:40:10.321972  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:40:10.321980  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00059155 (* 1 = 0.00059155 loss)
I0626 22:40:10.321985  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0215905 (* 1 = 0.0215905 loss)
I0626 22:40:10.321990  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.001482 (* 1 = 0.001482 loss)
I0626 22:40:10.321995  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03145 (* 1 = 0.03145 loss)
I0626 22:40:10.322000  4216 sgd_solver.cpp:106] Iteration 23640, lr = 2e-05
I0626 22:41:55.434556  4216 solver.cpp:228] Iteration 23660, loss = 0.082202
I0626 22:41:55.434583  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 22:41:55.434592  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0418445 (* 1 = 0.0418445 loss)
I0626 22:41:55.434597  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118521 (* 1 = 0.118521 loss)
I0626 22:41:55.434600  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00084665 (* 1 = 0.00084665 loss)
I0626 22:41:55.434604  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00747847 (* 1 = 0.00747847 loss)
I0626 22:41:55.434609  4216 sgd_solver.cpp:106] Iteration 23660, lr = 2e-05
I0626 22:43:40.741119  4216 solver.cpp:228] Iteration 23680, loss = 0.129792
I0626 22:43:40.741145  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 22:43:40.741153  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0764464 (* 1 = 0.0764464 loss)
I0626 22:43:40.741156  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.115463 (* 1 = 0.115463 loss)
I0626 22:43:40.741160  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000212644 (* 1 = 0.000212644 loss)
I0626 22:43:40.741164  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369676 (* 1 = 0.0369676 loss)
I0626 22:43:40.741169  4216 sgd_solver.cpp:106] Iteration 23680, lr = 2e-05
I0626 22:45:25.920740  4216 solver.cpp:228] Iteration 23700, loss = 0.345654
I0626 22:45:25.920764  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:45:25.920771  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0642366 (* 1 = 0.0642366 loss)
I0626 22:45:25.920775  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0406705 (* 1 = 0.0406705 loss)
I0626 22:45:25.920779  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016579 (* 1 = 0.0016579 loss)
I0626 22:45:25.920783  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226566 (* 1 = 0.0226566 loss)
I0626 22:45:25.920789  4216 sgd_solver.cpp:106] Iteration 23700, lr = 2e-05
I0626 22:47:11.074743  4216 solver.cpp:228] Iteration 23720, loss = 0.172533
I0626 22:47:11.074769  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:47:11.074777  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225541 (* 1 = 0.0225541 loss)
I0626 22:47:11.074782  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0622997 (* 1 = 0.0622997 loss)
I0626 22:47:11.074786  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300553 (* 1 = 0.00300553 loss)
I0626 22:47:11.074791  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232109 (* 1 = 0.0232109 loss)
I0626 22:47:11.074796  4216 sgd_solver.cpp:106] Iteration 23720, lr = 2e-05
I0626 22:48:56.353813  4216 solver.cpp:228] Iteration 23740, loss = 0.102922
I0626 22:48:56.353847  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:48:56.353857  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199857 (* 1 = 0.0199857 loss)
I0626 22:48:56.353863  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0268436 (* 1 = 0.0268436 loss)
I0626 22:48:56.353868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013802 (* 1 = 0.0013802 loss)
I0626 22:48:56.353874  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00457339 (* 1 = 0.00457339 loss)
I0626 22:48:56.353880  4216 sgd_solver.cpp:106] Iteration 23740, lr = 2e-05
I0626 22:50:41.666827  4216 solver.cpp:228] Iteration 23760, loss = 0.123083
I0626 22:50:41.666852  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:50:41.666864  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0303551 (* 1 = 0.0303551 loss)
I0626 22:50:41.666869  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0251403 (* 1 = 0.0251403 loss)
I0626 22:50:41.666873  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00669156 (* 1 = 0.00669156 loss)
I0626 22:50:41.666878  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00515524 (* 1 = 0.00515524 loss)
I0626 22:50:41.666882  4216 sgd_solver.cpp:106] Iteration 23760, lr = 2e-05
I0626 22:52:26.881647  4216 solver.cpp:228] Iteration 23780, loss = 0.245526
I0626 22:52:26.881671  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 22:52:26.881678  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.353291 (* 1 = 0.353291 loss)
I0626 22:52:26.881682  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.465075 (* 1 = 0.465075 loss)
I0626 22:52:26.881686  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00942107 (* 1 = 0.00942107 loss)
I0626 22:52:26.881690  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0852657 (* 1 = 0.0852657 loss)
I0626 22:52:26.881695  4216 sgd_solver.cpp:106] Iteration 23780, lr = 2e-05
speed: 5.289s / iter
I0626 22:54:12.099493  4216 solver.cpp:228] Iteration 23800, loss = 0.207942
I0626 22:54:12.099520  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:54:12.099529  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00103064 (* 1 = 0.00103064 loss)
I0626 22:54:12.099534  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00840329 (* 1 = 0.00840329 loss)
I0626 22:54:12.099537  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00736807 (* 1 = 0.00736807 loss)
I0626 22:54:12.099541  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184515 (* 1 = 0.0184515 loss)
I0626 22:54:12.099546  4216 sgd_solver.cpp:106] Iteration 23800, lr = 2e-05
I0626 22:55:57.213027  4216 solver.cpp:228] Iteration 23820, loss = 0.155334
I0626 22:55:57.213053  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:55:57.213063  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0110299 (* 1 = 0.0110299 loss)
I0626 22:55:57.213070  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0578581 (* 1 = 0.0578581 loss)
I0626 22:55:57.213076  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000747299 (* 1 = 0.000747299 loss)
I0626 22:55:57.213083  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111284 (* 1 = 0.0111284 loss)
I0626 22:55:57.213093  4216 sgd_solver.cpp:106] Iteration 23820, lr = 2e-05
I0626 22:57:42.424923  4216 solver.cpp:228] Iteration 23840, loss = 0.209874
I0626 22:57:42.424948  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 22:57:42.424957  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.155427 (* 1 = 0.155427 loss)
I0626 22:57:42.424960  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.128225 (* 1 = 0.128225 loss)
I0626 22:57:42.424964  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00584648 (* 1 = 0.00584648 loss)
I0626 22:57:42.424968  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0386792 (* 1 = 0.0386792 loss)
I0626 22:57:42.424973  4216 sgd_solver.cpp:106] Iteration 23840, lr = 2e-05
I0626 22:59:27.630043  4216 solver.cpp:228] Iteration 23860, loss = 0.0871984
I0626 22:59:27.630067  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:59:27.630075  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156552 (* 1 = 0.0156552 loss)
I0626 22:59:27.630079  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0384551 (* 1 = 0.0384551 loss)
I0626 22:59:27.630084  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000476282 (* 1 = 0.000476282 loss)
I0626 22:59:27.630086  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00784384 (* 1 = 0.00784384 loss)
I0626 22:59:27.630091  4216 sgd_solver.cpp:106] Iteration 23860, lr = 2e-05
I0626 23:01:12.790511  4216 solver.cpp:228] Iteration 23880, loss = 0.0863216
I0626 23:01:12.790535  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 23:01:12.790544  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120245 (* 1 = 0.120245 loss)
I0626 23:01:12.790550  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.140498 (* 1 = 0.140498 loss)
I0626 23:01:12.790556  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000976937 (* 1 = 0.000976937 loss)
I0626 23:01:12.790561  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359626 (* 1 = 0.0359626 loss)
I0626 23:01:12.790568  4216 sgd_solver.cpp:106] Iteration 23880, lr = 2e-05
I0626 23:02:57.945228  4216 solver.cpp:228] Iteration 23900, loss = 0.128856
I0626 23:02:57.945252  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:02:57.945260  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0676518 (* 1 = 0.0676518 loss)
I0626 23:02:57.945263  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0455707 (* 1 = 0.0455707 loss)
I0626 23:02:57.945267  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141714 (* 1 = 0.00141714 loss)
I0626 23:02:57.945271  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251785 (* 1 = 0.0251785 loss)
I0626 23:02:57.945276  4216 sgd_solver.cpp:106] Iteration 23900, lr = 2e-05
I0626 23:04:43.127099  4216 solver.cpp:228] Iteration 23920, loss = 0.0767008
I0626 23:04:43.127127  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:04:43.127135  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222533 (* 1 = 0.0222533 loss)
I0626 23:04:43.127138  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0127881 (* 1 = 0.0127881 loss)
I0626 23:04:43.127142  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000786315 (* 1 = 0.000786315 loss)
I0626 23:04:43.127146  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00441621 (* 1 = 0.00441621 loss)
I0626 23:04:43.127152  4216 sgd_solver.cpp:106] Iteration 23920, lr = 2e-05
I0626 23:06:28.351002  4216 solver.cpp:228] Iteration 23940, loss = 0.222835
I0626 23:06:28.351027  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:06:28.351034  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270319 (* 1 = 0.0270319 loss)
I0626 23:06:28.351039  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.045132 (* 1 = 0.045132 loss)
I0626 23:06:28.351043  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000991929 (* 1 = 0.000991929 loss)
I0626 23:06:28.351047  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013076 (* 1 = 0.013076 loss)
I0626 23:06:28.351052  4216 sgd_solver.cpp:106] Iteration 23940, lr = 2e-05
I0626 23:08:13.651289  4216 solver.cpp:228] Iteration 23960, loss = 0.101413
I0626 23:08:13.651312  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:08:13.651320  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00828194 (* 1 = 0.00828194 loss)
I0626 23:08:13.651324  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0297004 (* 1 = 0.0297004 loss)
I0626 23:08:13.651329  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232178 (* 1 = 0.00232178 loss)
I0626 23:08:13.651331  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173358 (* 1 = 0.0173358 loss)
I0626 23:08:13.651336  4216 sgd_solver.cpp:106] Iteration 23960, lr = 2e-05
I0626 23:09:58.847606  4216 solver.cpp:228] Iteration 23980, loss = 0.0801202
I0626 23:09:58.847631  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 23:09:58.847638  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216672 (* 1 = 0.0216672 loss)
I0626 23:09:58.847643  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0719661 (* 1 = 0.0719661 loss)
I0626 23:09:58.847646  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000219131 (* 1 = 0.000219131 loss)
I0626 23:09:58.847651  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015068 (* 1 = 0.015068 loss)
I0626 23:09:58.847656  4216 sgd_solver.cpp:106] Iteration 23980, lr = 2e-05
speed: 5.289s / iter
I0626 23:11:44.068212  4216 solver.cpp:228] Iteration 24000, loss = 0.156272
I0626 23:11:44.068240  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:11:44.068248  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0446507 (* 1 = 0.0446507 loss)
I0626 23:11:44.068253  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0639132 (* 1 = 0.0639132 loss)
I0626 23:11:44.068256  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217077 (* 1 = 0.00217077 loss)
I0626 23:11:44.068261  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153419 (* 1 = 0.0153419 loss)
I0626 23:11:44.068266  4216 sgd_solver.cpp:106] Iteration 24000, lr = 2e-05
I0626 23:13:29.381386  4216 solver.cpp:228] Iteration 24020, loss = 0.112736
I0626 23:13:29.381409  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:13:29.381417  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000759044 (* 1 = 0.000759044 loss)
I0626 23:13:29.381420  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0286177 (* 1 = 0.0286177 loss)
I0626 23:13:29.381423  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00852046 (* 1 = 0.00852046 loss)
I0626 23:13:29.381428  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123596 (* 1 = 0.0123596 loss)
I0626 23:13:29.381431  4216 sgd_solver.cpp:106] Iteration 24020, lr = 2e-05
I0626 23:15:14.900913  4216 solver.cpp:228] Iteration 24040, loss = 0.118073
I0626 23:15:14.900939  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:15:14.900948  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0796626 (* 1 = 0.0796626 loss)
I0626 23:15:14.900951  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.091422 (* 1 = 0.091422 loss)
I0626 23:15:14.900955  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000163805 (* 1 = 0.000163805 loss)
I0626 23:15:14.900959  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112807 (* 1 = 0.0112807 loss)
I0626 23:15:14.900964  4216 sgd_solver.cpp:106] Iteration 24040, lr = 2e-05
I0626 23:17:00.438796  4216 solver.cpp:228] Iteration 24060, loss = 0.22377
I0626 23:17:00.438822  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:17:00.438829  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323979 (* 1 = 0.0323979 loss)
I0626 23:17:00.438834  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0731674 (* 1 = 0.0731674 loss)
I0626 23:17:00.438838  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000376546 (* 1 = 0.000376546 loss)
I0626 23:17:00.438843  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169788 (* 1 = 0.0169788 loss)
I0626 23:17:00.438848  4216 sgd_solver.cpp:106] Iteration 24060, lr = 2e-05
I0626 23:18:45.765431  4216 solver.cpp:228] Iteration 24080, loss = 0.237931
I0626 23:18:45.765455  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:18:45.765462  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0124466 (* 1 = 0.0124466 loss)
I0626 23:18:45.765466  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0272453 (* 1 = 0.0272453 loss)
I0626 23:18:45.765470  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000155225 (* 1 = 0.000155225 loss)
I0626 23:18:45.765475  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00497004 (* 1 = 0.00497004 loss)
I0626 23:18:45.765478  4216 sgd_solver.cpp:106] Iteration 24080, lr = 2e-05
I0626 23:20:31.373615  4216 solver.cpp:228] Iteration 24100, loss = 0.0851981
I0626 23:20:31.373639  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:20:31.373646  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365412 (* 1 = 0.0365412 loss)
I0626 23:20:31.373649  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0271949 (* 1 = 0.0271949 loss)
I0626 23:20:31.373653  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000689256 (* 1 = 0.000689256 loss)
I0626 23:20:31.373657  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00732259 (* 1 = 0.00732259 loss)
I0626 23:20:31.373662  4216 sgd_solver.cpp:106] Iteration 24100, lr = 2e-05
I0626 23:22:16.624169  4216 solver.cpp:228] Iteration 24120, loss = 0.138098
I0626 23:22:16.624197  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 23:22:16.624205  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.038325 (* 1 = 0.038325 loss)
I0626 23:22:16.624212  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0942153 (* 1 = 0.0942153 loss)
I0626 23:22:16.624217  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142333 (* 1 = 0.0142333 loss)
I0626 23:22:16.624223  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111603 (* 1 = 0.0111603 loss)
I0626 23:22:16.624230  4216 sgd_solver.cpp:106] Iteration 24120, lr = 2e-05
I0626 23:24:02.089931  4216 solver.cpp:228] Iteration 24140, loss = 0.148883
I0626 23:24:02.089958  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:24:02.089967  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251708 (* 1 = 0.0251708 loss)
I0626 23:24:02.089972  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0479354 (* 1 = 0.0479354 loss)
I0626 23:24:02.089977  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112905 (* 1 = 0.0112905 loss)
I0626 23:24:02.089982  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00593715 (* 1 = 0.00593715 loss)
I0626 23:24:02.089987  4216 sgd_solver.cpp:106] Iteration 24140, lr = 2e-05
I0626 23:25:47.424372  4216 solver.cpp:228] Iteration 24160, loss = 0.118725
I0626 23:25:47.424397  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:25:47.424404  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133108 (* 1 = 0.0133108 loss)
I0626 23:25:47.424408  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.046942 (* 1 = 0.046942 loss)
I0626 23:25:47.424412  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0037094 (* 1 = 0.0037094 loss)
I0626 23:25:47.424417  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162292 (* 1 = 0.0162292 loss)
I0626 23:25:47.424422  4216 sgd_solver.cpp:106] Iteration 24160, lr = 2e-05
I0626 23:27:32.746397  4216 solver.cpp:228] Iteration 24180, loss = 0.16436
I0626 23:27:32.746424  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:27:32.746433  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135076 (* 1 = 0.0135076 loss)
I0626 23:27:32.746436  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0256743 (* 1 = 0.0256743 loss)
I0626 23:27:32.746440  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102778 (* 1 = 0.00102778 loss)
I0626 23:27:32.746444  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00755104 (* 1 = 0.00755104 loss)
I0626 23:27:32.746449  4216 sgd_solver.cpp:106] Iteration 24180, lr = 2e-05
speed: 5.289s / iter
I0626 23:29:18.047137  4216 solver.cpp:228] Iteration 24200, loss = 0.120454
I0626 23:29:18.047163  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:29:18.047171  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000422137 (* 1 = 0.000422137 loss)
I0626 23:29:18.047176  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0161869 (* 1 = 0.0161869 loss)
I0626 23:29:18.047180  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000442554 (* 1 = 0.000442554 loss)
I0626 23:29:18.047184  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180172 (* 1 = 0.0180172 loss)
I0626 23:29:18.047189  4216 sgd_solver.cpp:106] Iteration 24200, lr = 2e-05
I0626 23:31:03.590613  4216 solver.cpp:228] Iteration 24220, loss = 0.314856
I0626 23:31:03.590643  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 23:31:03.590651  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.118925 (* 1 = 0.118925 loss)
I0626 23:31:03.590657  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.154647 (* 1 = 0.154647 loss)
I0626 23:31:03.590662  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244916 (* 1 = 0.0244916 loss)
I0626 23:31:03.590667  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0622403 (* 1 = 0.0622403 loss)
I0626 23:31:03.590673  4216 sgd_solver.cpp:106] Iteration 24220, lr = 2e-05
I0626 23:32:51.005313  4216 solver.cpp:228] Iteration 24240, loss = 0.233723
I0626 23:32:51.005337  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:32:51.005344  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00809527 (* 1 = 0.00809527 loss)
I0626 23:32:51.005348  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0144398 (* 1 = 0.0144398 loss)
I0626 23:32:51.005352  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171615 (* 1 = 0.00171615 loss)
I0626 23:32:51.005357  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00482067 (* 1 = 0.00482067 loss)
I0626 23:32:51.005360  4216 sgd_solver.cpp:106] Iteration 24240, lr = 2e-05
I0626 23:34:36.224714  4216 solver.cpp:228] Iteration 24260, loss = 0.210046
I0626 23:34:36.224736  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:34:36.224743  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00939578 (* 1 = 0.00939578 loss)
I0626 23:34:36.224747  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00646006 (* 1 = 0.00646006 loss)
I0626 23:34:36.224751  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00045918 (* 1 = 0.00045918 loss)
I0626 23:34:36.224756  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0049462 (* 1 = 0.0049462 loss)
I0626 23:34:36.224759  4216 sgd_solver.cpp:106] Iteration 24260, lr = 2e-05
I0626 23:36:21.514176  4216 solver.cpp:228] Iteration 24280, loss = 0.158859
I0626 23:36:21.514200  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:36:21.514207  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0559975 (* 1 = 0.0559975 loss)
I0626 23:36:21.514211  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0295522 (* 1 = 0.0295522 loss)
I0626 23:36:21.514215  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.127454 (* 1 = 0.127454 loss)
I0626 23:36:21.514219  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0344746 (* 1 = 0.0344746 loss)
I0626 23:36:21.514223  4216 sgd_solver.cpp:106] Iteration 24280, lr = 2e-05
I0626 23:38:06.723417  4216 solver.cpp:228] Iteration 24300, loss = 0.171427
I0626 23:38:06.723443  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 23:38:06.723449  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0585979 (* 1 = 0.0585979 loss)
I0626 23:38:06.723454  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.178729 (* 1 = 0.178729 loss)
I0626 23:38:06.723457  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00439087 (* 1 = 0.00439087 loss)
I0626 23:38:06.723461  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175078 (* 1 = 0.0175078 loss)
I0626 23:38:06.723465  4216 sgd_solver.cpp:106] Iteration 24300, lr = 2e-05
I0626 23:39:51.871837  4216 solver.cpp:228] Iteration 24320, loss = 0.223832
I0626 23:39:51.871862  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:39:51.871871  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00912937 (* 1 = 0.00912937 loss)
I0626 23:39:51.871878  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0155907 (* 1 = 0.0155907 loss)
I0626 23:39:51.871884  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000171052 (* 1 = 0.000171052 loss)
I0626 23:39:51.871889  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00472559 (* 1 = 0.00472559 loss)
I0626 23:39:51.871896  4216 sgd_solver.cpp:106] Iteration 24320, lr = 2e-05
I0626 23:41:37.156123  4216 solver.cpp:228] Iteration 24340, loss = 0.230251
I0626 23:41:37.156149  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 23:41:37.156157  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0857279 (* 1 = 0.0857279 loss)
I0626 23:41:37.156162  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.164229 (* 1 = 0.164229 loss)
I0626 23:41:37.156165  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00576696 (* 1 = 0.00576696 loss)
I0626 23:41:37.156169  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037113 (* 1 = 0.037113 loss)
I0626 23:41:37.156175  4216 sgd_solver.cpp:106] Iteration 24340, lr = 2e-05
I0626 23:43:22.338346  4216 solver.cpp:228] Iteration 24360, loss = 0.156309
I0626 23:43:22.338372  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 23:43:22.338380  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434498 (* 1 = 0.0434498 loss)
I0626 23:43:22.338384  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.165263 (* 1 = 0.165263 loss)
I0626 23:43:22.338388  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107161 (* 1 = 0.00107161 loss)
I0626 23:43:22.338392  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00901345 (* 1 = 0.00901345 loss)
I0626 23:43:22.338397  4216 sgd_solver.cpp:106] Iteration 24360, lr = 2e-05
I0626 23:45:07.521775  4216 solver.cpp:228] Iteration 24380, loss = 0.123123
I0626 23:45:07.521798  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 23:45:07.521806  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0710681 (* 1 = 0.0710681 loss)
I0626 23:45:07.521811  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.101675 (* 1 = 0.101675 loss)
I0626 23:45:07.521814  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000618289 (* 1 = 0.000618289 loss)
I0626 23:45:07.521817  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203425 (* 1 = 0.0203425 loss)
I0626 23:45:07.521822  4216 sgd_solver.cpp:106] Iteration 24380, lr = 2e-05
speed: 5.288s / iter
I0626 23:46:52.714233  4216 solver.cpp:228] Iteration 24400, loss = 0.161978
I0626 23:46:52.714257  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:46:52.714263  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0217572 (* 1 = 0.0217572 loss)
I0626 23:46:52.714267  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0628794 (* 1 = 0.0628794 loss)
I0626 23:46:52.714272  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000863622 (* 1 = 0.000863622 loss)
I0626 23:46:52.714275  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154817 (* 1 = 0.0154817 loss)
I0626 23:46:52.714280  4216 sgd_solver.cpp:106] Iteration 24400, lr = 2e-05
I0626 23:48:37.899035  4216 solver.cpp:228] Iteration 24420, loss = 0.121479
I0626 23:48:37.899060  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:48:37.899067  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.037638 (* 1 = 0.037638 loss)
I0626 23:48:37.899071  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0360362 (* 1 = 0.0360362 loss)
I0626 23:48:37.899075  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00041708 (* 1 = 0.00041708 loss)
I0626 23:48:37.899080  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126834 (* 1 = 0.0126834 loss)
I0626 23:48:37.899083  4216 sgd_solver.cpp:106] Iteration 24420, lr = 2e-05
I0626 23:50:23.080163  4216 solver.cpp:228] Iteration 24440, loss = 0.121975
I0626 23:50:23.080188  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:50:23.080196  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0939009 (* 1 = 0.0939009 loss)
I0626 23:50:23.080200  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0606829 (* 1 = 0.0606829 loss)
I0626 23:50:23.080204  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103421 (* 1 = 0.00103421 loss)
I0626 23:50:23.080209  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209477 (* 1 = 0.0209477 loss)
I0626 23:50:23.080214  4216 sgd_solver.cpp:106] Iteration 24440, lr = 2e-05
I0626 23:52:08.286206  4216 solver.cpp:228] Iteration 24460, loss = 0.238347
I0626 23:52:08.286232  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:52:08.286240  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241589 (* 1 = 0.0241589 loss)
I0626 23:52:08.286244  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0231851 (* 1 = 0.0231851 loss)
I0626 23:52:08.286248  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000519469 (* 1 = 0.000519469 loss)
I0626 23:52:08.286253  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126718 (* 1 = 0.0126718 loss)
I0626 23:52:08.286258  4216 sgd_solver.cpp:106] Iteration 24460, lr = 2e-05
I0626 23:53:53.506598  4216 solver.cpp:228] Iteration 24480, loss = 0.267221
I0626 23:53:53.506628  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 23:53:53.506635  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.109281 (* 1 = 0.109281 loss)
I0626 23:53:53.506640  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.160301 (* 1 = 0.160301 loss)
I0626 23:53:53.506645  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109466 (* 1 = 0.00109466 loss)
I0626 23:53:53.506649  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276681 (* 1 = 0.0276681 loss)
I0626 23:53:53.506654  4216 sgd_solver.cpp:106] Iteration 24480, lr = 2e-05
I0626 23:55:38.730962  4216 solver.cpp:228] Iteration 24500, loss = 0.260336
I0626 23:55:38.730986  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 23:55:38.730994  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335147 (* 1 = 0.0335147 loss)
I0626 23:55:38.731000  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109563 (* 1 = 0.109563 loss)
I0626 23:55:38.731006  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00634485 (* 1 = 0.00634485 loss)
I0626 23:55:38.731010  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039424 (* 1 = 0.039424 loss)
I0626 23:55:38.731015  4216 sgd_solver.cpp:106] Iteration 24500, lr = 2e-05
I0626 23:57:23.995651  4216 solver.cpp:228] Iteration 24520, loss = 0.133234
I0626 23:57:23.995677  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:57:23.995685  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374357 (* 1 = 0.0374357 loss)
I0626 23:57:23.995690  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0655676 (* 1 = 0.0655676 loss)
I0626 23:57:23.995694  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00487111 (* 1 = 0.00487111 loss)
I0626 23:57:23.995698  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119088 (* 1 = 0.0119088 loss)
I0626 23:57:23.995703  4216 sgd_solver.cpp:106] Iteration 24520, lr = 2e-05
I0626 23:59:09.256659  4216 solver.cpp:228] Iteration 24540, loss = 0.195476
I0626 23:59:09.256685  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:59:09.256695  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00610128 (* 1 = 0.00610128 loss)
I0626 23:59:09.256700  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0119644 (* 1 = 0.0119644 loss)
I0626 23:59:09.256706  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000424183 (* 1 = 0.000424183 loss)
I0626 23:59:09.256711  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00562831 (* 1 = 0.00562831 loss)
I0626 23:59:09.256717  4216 sgd_solver.cpp:106] Iteration 24540, lr = 2e-05
I0627 00:00:54.444078  4216 solver.cpp:228] Iteration 24560, loss = 0.26877
I0627 00:00:54.444123  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 00:00:54.444133  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.15495 (* 1 = 0.15495 loss)
I0627 00:00:54.444139  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.148277 (* 1 = 0.148277 loss)
I0627 00:00:54.444142  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208699 (* 1 = 0.00208699 loss)
I0627 00:00:54.444147  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358876 (* 1 = 0.0358876 loss)
I0627 00:00:54.444155  4216 sgd_solver.cpp:106] Iteration 24560, lr = 2e-05
I0627 00:02:39.968541  4216 solver.cpp:228] Iteration 24580, loss = 0.216222
I0627 00:02:39.968571  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:02:39.968582  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0463773 (* 1 = 0.0463773 loss)
I0627 00:02:39.968590  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0440885 (* 1 = 0.0440885 loss)
I0627 00:02:39.968598  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00608193 (* 1 = 0.00608193 loss)
I0627 00:02:39.968606  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100302 (* 1 = 0.0100302 loss)
I0627 00:02:39.968616  4216 sgd_solver.cpp:106] Iteration 24580, lr = 2e-05
speed: 5.288s / iter
I0627 00:04:25.420563  4216 solver.cpp:228] Iteration 24600, loss = 0.129531
I0627 00:04:25.420589  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:04:25.420598  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262979 (* 1 = 0.0262979 loss)
I0627 00:04:25.420601  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0407787 (* 1 = 0.0407787 loss)
I0627 00:04:25.420606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215708 (* 1 = 0.00215708 loss)
I0627 00:04:25.420610  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00597872 (* 1 = 0.00597872 loss)
I0627 00:04:25.420616  4216 sgd_solver.cpp:106] Iteration 24600, lr = 2e-05
I0627 00:06:10.752974  4216 solver.cpp:228] Iteration 24620, loss = 0.173295
I0627 00:06:10.753000  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:06:10.753008  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.037624 (* 1 = 0.037624 loss)
I0627 00:06:10.753015  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0213652 (* 1 = 0.0213652 loss)
I0627 00:06:10.753021  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.58471e-05 (* 1 = 9.58471e-05 loss)
I0627 00:06:10.753026  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00437472 (* 1 = 0.00437472 loss)
I0627 00:06:10.753032  4216 sgd_solver.cpp:106] Iteration 24620, lr = 2e-05
I0627 00:07:56.164549  4216 solver.cpp:228] Iteration 24640, loss = 0.252364
I0627 00:07:56.164575  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:07:56.164583  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464975 (* 1 = 0.0464975 loss)
I0627 00:07:56.164587  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0327767 (* 1 = 0.0327767 loss)
I0627 00:07:56.164592  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.91783e-05 (* 1 = 2.91783e-05 loss)
I0627 00:07:56.164597  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.009278 (* 1 = 0.009278 loss)
I0627 00:07:56.164602  4216 sgd_solver.cpp:106] Iteration 24640, lr = 2e-05
I0627 00:09:41.511837  4216 solver.cpp:228] Iteration 24660, loss = 0.147506
I0627 00:09:41.511860  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 00:09:41.511868  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298913 (* 1 = 0.0298913 loss)
I0627 00:09:41.511871  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0877038 (* 1 = 0.0877038 loss)
I0627 00:09:41.511875  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218572 (* 1 = 0.00218572 loss)
I0627 00:09:41.511879  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00075781 (* 1 = 0.00075781 loss)
I0627 00:09:41.511883  4216 sgd_solver.cpp:106] Iteration 24660, lr = 2e-05
I0627 00:11:26.966722  4216 solver.cpp:228] Iteration 24680, loss = 0.119013
I0627 00:11:26.966751  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:11:26.966763  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121939 (* 1 = 0.0121939 loss)
I0627 00:11:26.966768  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0304532 (* 1 = 0.0304532 loss)
I0627 00:11:26.966773  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023826 (* 1 = 0.0023826 loss)
I0627 00:11:26.966778  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00244796 (* 1 = 0.00244796 loss)
I0627 00:11:26.966784  4216 sgd_solver.cpp:106] Iteration 24680, lr = 2e-05
I0627 00:13:12.432519  4216 solver.cpp:228] Iteration 24700, loss = 0.189842
I0627 00:13:12.432549  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:13:12.432561  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197137 (* 1 = 0.0197137 loss)
I0627 00:13:12.432569  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0241535 (* 1 = 0.0241535 loss)
I0627 00:13:12.432572  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000966752 (* 1 = 0.000966752 loss)
I0627 00:13:12.432576  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288201 (* 1 = 0.0288201 loss)
I0627 00:13:12.432581  4216 sgd_solver.cpp:106] Iteration 24700, lr = 2e-05
I0627 00:14:57.701853  4216 solver.cpp:228] Iteration 24720, loss = 0.15671
I0627 00:14:57.701880  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:14:57.701890  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0330465 (* 1 = 0.0330465 loss)
I0627 00:14:57.701897  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.025618 (* 1 = 0.025618 loss)
I0627 00:14:57.701903  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000649447 (* 1 = 0.000649447 loss)
I0627 00:14:57.701910  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00597793 (* 1 = 0.00597793 loss)
I0627 00:14:57.701917  4216 sgd_solver.cpp:106] Iteration 24720, lr = 2e-05
I0627 00:16:43.179864  4216 solver.cpp:228] Iteration 24740, loss = 0.197842
I0627 00:16:43.179891  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:16:43.179898  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.024678 (* 1 = 0.024678 loss)
I0627 00:16:43.179905  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0370171 (* 1 = 0.0370171 loss)
I0627 00:16:43.179913  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.79882e-05 (* 1 = 6.79882e-05 loss)
I0627 00:16:43.179917  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00333628 (* 1 = 0.00333628 loss)
I0627 00:16:43.179924  4216 sgd_solver.cpp:106] Iteration 24740, lr = 2e-05
I0627 00:18:28.525701  4216 solver.cpp:228] Iteration 24760, loss = 0.166017
I0627 00:18:28.525727  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 00:18:28.525734  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.079922 (* 1 = 0.079922 loss)
I0627 00:18:28.525739  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0994239 (* 1 = 0.0994239 loss)
I0627 00:18:28.525743  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.33574e-05 (* 1 = 5.33574e-05 loss)
I0627 00:18:28.525748  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00575047 (* 1 = 0.00575047 loss)
I0627 00:18:28.525754  4216 sgd_solver.cpp:106] Iteration 24760, lr = 2e-05
I0627 00:20:14.156194  4216 solver.cpp:228] Iteration 24780, loss = 0.125087
I0627 00:20:14.156220  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 00:20:14.156229  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.045873 (* 1 = 0.045873 loss)
I0627 00:20:14.156234  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0206763 (* 1 = 0.0206763 loss)
I0627 00:20:14.156237  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292091 (* 1 = 0.00292091 loss)
I0627 00:20:14.156241  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146552 (* 1 = 0.0146552 loss)
I0627 00:20:14.156245  4216 sgd_solver.cpp:106] Iteration 24780, lr = 2e-05
speed: 5.288s / iter
I0627 00:21:59.415292  4216 solver.cpp:228] Iteration 24800, loss = 0.178013
I0627 00:21:59.415316  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:21:59.415323  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0115548 (* 1 = 0.0115548 loss)
I0627 00:21:59.415328  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0155111 (* 1 = 0.0155111 loss)
I0627 00:21:59.415331  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105422 (* 1 = 0.00105422 loss)
I0627 00:21:59.415334  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00807033 (* 1 = 0.00807033 loss)
I0627 00:21:59.415339  4216 sgd_solver.cpp:106] Iteration 24800, lr = 2e-05
I0627 00:23:44.689968  4216 solver.cpp:228] Iteration 24820, loss = 0.0632922
I0627 00:23:44.689996  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:23:44.690006  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00476818 (* 1 = 0.00476818 loss)
I0627 00:23:44.690011  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0539983 (* 1 = 0.0539983 loss)
I0627 00:23:44.690016  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00211596 (* 1 = 0.00211596 loss)
I0627 00:23:44.690021  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0019286 (* 1 = 0.0019286 loss)
I0627 00:23:44.690026  4216 sgd_solver.cpp:106] Iteration 24820, lr = 2e-05
I0627 00:25:30.121071  4216 solver.cpp:228] Iteration 24840, loss = 0.145422
I0627 00:25:30.121098  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 00:25:30.121109  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0653903 (* 1 = 0.0653903 loss)
I0627 00:25:30.121114  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0912515 (* 1 = 0.0912515 loss)
I0627 00:25:30.121119  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00269884 (* 1 = 0.00269884 loss)
I0627 00:25:30.121122  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285272 (* 1 = 0.0285272 loss)
I0627 00:25:30.121129  4216 sgd_solver.cpp:106] Iteration 24840, lr = 2e-05
I0627 00:27:15.367173  4216 solver.cpp:228] Iteration 24860, loss = 0.114866
I0627 00:27:15.367197  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 00:27:15.367204  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.012354 (* 1 = 0.012354 loss)
I0627 00:27:15.367209  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00864753 (* 1 = 0.00864753 loss)
I0627 00:27:15.367213  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207841 (* 1 = 0.00207841 loss)
I0627 00:27:15.367216  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00483387 (* 1 = 0.00483387 loss)
I0627 00:27:15.367221  4216 sgd_solver.cpp:106] Iteration 24860, lr = 2e-05
I0627 00:29:00.577196  4216 solver.cpp:228] Iteration 24880, loss = 0.171996
I0627 00:29:00.577229  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 00:29:00.577239  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511552 (* 1 = 0.0511552 loss)
I0627 00:29:00.577247  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.022763 (* 1 = 0.022763 loss)
I0627 00:29:00.577255  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00399173 (* 1 = 0.00399173 loss)
I0627 00:29:00.577261  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238421 (* 1 = 0.0238421 loss)
I0627 00:29:00.577268  4216 sgd_solver.cpp:106] Iteration 24880, lr = 2e-05
I0627 00:30:45.811053  4216 solver.cpp:228] Iteration 24900, loss = 0.109819
I0627 00:30:45.811079  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:30:45.811089  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156011 (* 1 = 0.0156011 loss)
I0627 00:30:45.811092  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0345764 (* 1 = 0.0345764 loss)
I0627 00:30:45.811096  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000408186 (* 1 = 0.000408186 loss)
I0627 00:30:45.811100  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00618609 (* 1 = 0.00618609 loss)
I0627 00:30:45.811106  4216 sgd_solver.cpp:106] Iteration 24900, lr = 2e-05
I0627 00:32:31.013159  4216 solver.cpp:228] Iteration 24920, loss = 0.214318
I0627 00:32:31.013185  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 00:32:31.013193  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0663167 (* 1 = 0.0663167 loss)
I0627 00:32:31.013198  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.17361 (* 1 = 0.17361 loss)
I0627 00:32:31.013201  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119893 (* 1 = 0.0119893 loss)
I0627 00:32:31.013206  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221015 (* 1 = 0.0221015 loss)
I0627 00:32:31.013211  4216 sgd_solver.cpp:106] Iteration 24920, lr = 2e-05
I0627 00:34:16.346046  4216 solver.cpp:228] Iteration 24940, loss = 0.26407
I0627 00:34:16.346071  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:34:16.346077  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0214689 (* 1 = 0.0214689 loss)
I0627 00:34:16.346082  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0661982 (* 1 = 0.0661982 loss)
I0627 00:34:16.346086  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00256845 (* 1 = 0.00256845 loss)
I0627 00:34:16.346089  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00710575 (* 1 = 0.00710575 loss)
I0627 00:34:16.346094  4216 sgd_solver.cpp:106] Iteration 24940, lr = 2e-05
I0627 00:36:01.523656  4216 solver.cpp:228] Iteration 24960, loss = 0.124396
I0627 00:36:01.523684  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:36:01.523692  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0289523 (* 1 = 0.0289523 loss)
I0627 00:36:01.523696  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0377705 (* 1 = 0.0377705 loss)
I0627 00:36:01.523701  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109045 (* 1 = 0.00109045 loss)
I0627 00:36:01.523706  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191181 (* 1 = 0.0191181 loss)
I0627 00:36:01.523711  4216 sgd_solver.cpp:106] Iteration 24960, lr = 2e-05
I0627 00:37:46.747082  4216 solver.cpp:228] Iteration 24980, loss = 0.129426
I0627 00:37:46.747110  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:37:46.747118  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126124 (* 1 = 0.0126124 loss)
I0627 00:37:46.747123  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0374425 (* 1 = 0.0374425 loss)
I0627 00:37:46.747128  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000572734 (* 1 = 0.000572734 loss)
I0627 00:37:46.747131  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00553578 (* 1 = 0.00553578 loss)
I0627 00:37:46.747136  4216 sgd_solver.cpp:106] Iteration 24980, lr = 2e-05
speed: 5.288s / iter
I0627 00:39:27.044735  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_25000.caffemodel
I0627 00:39:32.699947  4216 solver.cpp:228] Iteration 25000, loss = 0.290892
I0627 00:39:32.699975  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:39:32.699985  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0301285 (* 1 = 0.0301285 loss)
I0627 00:39:32.699991  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.021017 (* 1 = 0.021017 loss)
I0627 00:39:32.699998  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000801639 (* 1 = 0.000801639 loss)
I0627 00:39:32.700007  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00139718 (* 1 = 0.00139718 loss)
I0627 00:39:32.700014  4216 sgd_solver.cpp:106] Iteration 25000, lr = 2e-05
I0627 00:41:17.895764  4216 solver.cpp:228] Iteration 25020, loss = 0.0755316
I0627 00:41:17.895788  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:41:17.895795  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.019407 (* 1 = 0.019407 loss)
I0627 00:41:17.895800  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0185172 (* 1 = 0.0185172 loss)
I0627 00:41:17.895803  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00915521 (* 1 = 0.00915521 loss)
I0627 00:41:17.895807  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175429 (* 1 = 0.0175429 loss)
I0627 00:41:17.895812  4216 sgd_solver.cpp:106] Iteration 25020, lr = 2e-05
I0627 00:43:03.097385  4216 solver.cpp:228] Iteration 25040, loss = 0.178177
I0627 00:43:03.097411  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:43:03.097420  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0250635 (* 1 = 0.0250635 loss)
I0627 00:43:03.097427  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0611586 (* 1 = 0.0611586 loss)
I0627 00:43:03.097432  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155346 (* 1 = 0.0155346 loss)
I0627 00:43:03.097437  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0473322 (* 1 = 0.0473322 loss)
I0627 00:43:03.097443  4216 sgd_solver.cpp:106] Iteration 25040, lr = 2e-05
I0627 00:44:48.331462  4216 solver.cpp:228] Iteration 25060, loss = 0.142194
I0627 00:44:48.331487  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 00:44:48.331493  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0546405 (* 1 = 0.0546405 loss)
I0627 00:44:48.331497  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118396 (* 1 = 0.118396 loss)
I0627 00:44:48.331501  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00664679 (* 1 = 0.00664679 loss)
I0627 00:44:48.331506  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108295 (* 1 = 0.0108295 loss)
I0627 00:44:48.331509  4216 sgd_solver.cpp:106] Iteration 25060, lr = 2e-05
I0627 00:46:33.545478  4216 solver.cpp:228] Iteration 25080, loss = 0.177709
I0627 00:46:33.545506  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:46:33.545513  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0552452 (* 1 = 0.0552452 loss)
I0627 00:46:33.545517  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0592933 (* 1 = 0.0592933 loss)
I0627 00:46:33.545521  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124633 (* 1 = 0.0124633 loss)
I0627 00:46:33.545526  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0462137 (* 1 = 0.0462137 loss)
I0627 00:46:33.545531  4216 sgd_solver.cpp:106] Iteration 25080, lr = 2e-05
I0627 00:48:18.741060  4216 solver.cpp:228] Iteration 25100, loss = 0.202142
I0627 00:48:18.741086  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:48:18.741096  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.022785 (* 1 = 0.022785 loss)
I0627 00:48:18.741099  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.050601 (* 1 = 0.050601 loss)
I0627 00:48:18.741103  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122256 (* 1 = 0.00122256 loss)
I0627 00:48:18.741107  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016223 (* 1 = 0.016223 loss)
I0627 00:48:18.741113  4216 sgd_solver.cpp:106] Iteration 25100, lr = 2e-05
I0627 00:50:03.976531  4216 solver.cpp:228] Iteration 25120, loss = 0.159979
I0627 00:50:03.976555  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:50:03.976563  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228756 (* 1 = 0.0228756 loss)
I0627 00:50:03.976568  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0404186 (* 1 = 0.0404186 loss)
I0627 00:50:03.976572  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000432908 (* 1 = 0.000432908 loss)
I0627 00:50:03.976575  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00589781 (* 1 = 0.00589781 loss)
I0627 00:50:03.976581  4216 sgd_solver.cpp:106] Iteration 25120, lr = 2e-05
I0627 00:51:49.584344  4216 solver.cpp:228] Iteration 25140, loss = 0.155157
I0627 00:51:49.584372  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:51:49.584379  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185644 (* 1 = 0.0185644 loss)
I0627 00:51:49.584384  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0586375 (* 1 = 0.0586375 loss)
I0627 00:51:49.584388  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114027 (* 1 = 0.00114027 loss)
I0627 00:51:49.584393  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127345 (* 1 = 0.0127345 loss)
I0627 00:51:49.584398  4216 sgd_solver.cpp:106] Iteration 25140, lr = 2e-05
I0627 00:53:36.117642  4216 solver.cpp:228] Iteration 25160, loss = 0.167804
I0627 00:53:36.117669  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:53:36.117678  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346154 (* 1 = 0.0346154 loss)
I0627 00:53:36.117684  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0753858 (* 1 = 0.0753858 loss)
I0627 00:53:36.117689  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000540787 (* 1 = 0.000540787 loss)
I0627 00:53:36.117696  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00705246 (* 1 = 0.00705246 loss)
I0627 00:53:36.117702  4216 sgd_solver.cpp:106] Iteration 25160, lr = 2e-05
I0627 00:55:21.680094  4216 solver.cpp:228] Iteration 25180, loss = 0.0979547
I0627 00:55:21.680120  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 00:55:21.680130  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0920159 (* 1 = 0.0920159 loss)
I0627 00:55:21.680135  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0932567 (* 1 = 0.0932567 loss)
I0627 00:55:21.680140  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000589496 (* 1 = 0.000589496 loss)
I0627 00:55:21.680145  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261632 (* 1 = 0.0261632 loss)
I0627 00:55:21.680150  4216 sgd_solver.cpp:106] Iteration 25180, lr = 2e-05
speed: 5.288s / iter
I0627 00:57:07.079118  4216 solver.cpp:228] Iteration 25200, loss = 0.355299
I0627 00:57:07.079143  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:57:07.079149  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272418 (* 1 = 0.0272418 loss)
I0627 00:57:07.079154  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0143926 (* 1 = 0.0143926 loss)
I0627 00:57:07.079157  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00246189 (* 1 = 0.00246189 loss)
I0627 00:57:07.079160  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158961 (* 1 = 0.0158961 loss)
I0627 00:57:07.079165  4216 sgd_solver.cpp:106] Iteration 25200, lr = 2e-05
I0627 00:58:52.609542  4216 solver.cpp:228] Iteration 25220, loss = 0.238154
I0627 00:58:52.609568  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 00:58:52.609576  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605224 (* 1 = 0.0605224 loss)
I0627 00:58:52.609580  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0984002 (* 1 = 0.0984002 loss)
I0627 00:58:52.609586  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000613509 (* 1 = 0.000613509 loss)
I0627 00:58:52.609589  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020579 (* 1 = 0.020579 loss)
I0627 00:58:52.609596  4216 sgd_solver.cpp:106] Iteration 25220, lr = 2e-05
I0627 01:00:37.908826  4216 solver.cpp:228] Iteration 25240, loss = 0.222895
I0627 01:00:37.908851  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:00:37.908859  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0954788 (* 1 = 0.0954788 loss)
I0627 01:00:37.908862  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0845478 (* 1 = 0.0845478 loss)
I0627 01:00:37.908865  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000608004 (* 1 = 0.000608004 loss)
I0627 01:00:37.908869  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170728 (* 1 = 0.0170728 loss)
I0627 01:00:37.908874  4216 sgd_solver.cpp:106] Iteration 25240, lr = 2e-05
I0627 01:02:23.377786  4216 solver.cpp:228] Iteration 25260, loss = 0.141529
I0627 01:02:23.377813  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 01:02:23.377823  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233786 (* 1 = 0.0233786 loss)
I0627 01:02:23.377830  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0156717 (* 1 = 0.0156717 loss)
I0627 01:02:23.377837  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636468 (* 1 = 0.00636468 loss)
I0627 01:02:23.377843  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00417032 (* 1 = 0.00417032 loss)
I0627 01:02:23.377852  4216 sgd_solver.cpp:106] Iteration 25260, lr = 2e-05
I0627 01:04:08.970146  4216 solver.cpp:228] Iteration 25280, loss = 0.161317
I0627 01:04:08.970175  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 01:04:08.970182  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0492057 (* 1 = 0.0492057 loss)
I0627 01:04:08.970187  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.199818 (* 1 = 0.199818 loss)
I0627 01:04:08.970191  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01925 (* 1 = 0.01925 loss)
I0627 01:04:08.970196  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0632048 (* 1 = 0.0632048 loss)
I0627 01:04:08.970201  4216 sgd_solver.cpp:106] Iteration 25280, lr = 2e-05
I0627 01:05:54.295588  4216 solver.cpp:228] Iteration 25300, loss = 0.18442
I0627 01:05:54.295612  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:05:54.295621  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.010417 (* 1 = 0.010417 loss)
I0627 01:05:54.295627  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0400334 (* 1 = 0.0400334 loss)
I0627 01:05:54.295634  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00903352 (* 1 = 0.00903352 loss)
I0627 01:05:54.295639  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108568 (* 1 = 0.0108568 loss)
I0627 01:05:54.295645  4216 sgd_solver.cpp:106] Iteration 25300, lr = 2e-05
I0627 01:07:39.746847  4216 solver.cpp:228] Iteration 25320, loss = 0.132151
I0627 01:07:39.746889  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0627 01:07:39.746898  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.143632 (* 1 = 0.143632 loss)
I0627 01:07:39.746903  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.26548 (* 1 = 0.26548 loss)
I0627 01:07:39.746907  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00501012 (* 1 = 0.00501012 loss)
I0627 01:07:39.746912  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227517 (* 1 = 0.0227517 loss)
I0627 01:07:39.746917  4216 sgd_solver.cpp:106] Iteration 25320, lr = 2e-05
I0627 01:09:25.156464  4216 solver.cpp:228] Iteration 25340, loss = 0.238185
I0627 01:09:25.156493  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0627 01:09:25.156502  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.113374 (* 1 = 0.113374 loss)
I0627 01:09:25.156509  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.217647 (* 1 = 0.217647 loss)
I0627 01:09:25.156515  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124159 (* 1 = 0.0124159 loss)
I0627 01:09:25.156522  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0729826 (* 1 = 0.0729826 loss)
I0627 01:09:25.156528  4216 sgd_solver.cpp:106] Iteration 25340, lr = 2e-05
I0627 01:11:10.454452  4216 solver.cpp:228] Iteration 25360, loss = 0.232548
I0627 01:11:10.454476  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0627 01:11:10.454483  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.261279 (* 1 = 0.261279 loss)
I0627 01:11:10.454488  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.439595 (* 1 = 0.439595 loss)
I0627 01:11:10.454490  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00825804 (* 1 = 0.00825804 loss)
I0627 01:11:10.454494  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0661558 (* 1 = 0.0661558 loss)
I0627 01:11:10.454499  4216 sgd_solver.cpp:106] Iteration 25360, lr = 2e-05
I0627 01:12:55.673418  4216 solver.cpp:228] Iteration 25380, loss = 0.0906737
I0627 01:12:55.673444  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 01:12:55.673451  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0117234 (* 1 = 0.0117234 loss)
I0627 01:12:55.673455  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00503883 (* 1 = 0.00503883 loss)
I0627 01:12:55.673460  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194237 (* 1 = 0.00194237 loss)
I0627 01:12:55.673463  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125732 (* 1 = 0.0125732 loss)
I0627 01:12:55.673468  4216 sgd_solver.cpp:106] Iteration 25380, lr = 2e-05
speed: 5.288s / iter
I0627 01:14:40.972885  4216 solver.cpp:228] Iteration 25400, loss = 0.172417
I0627 01:14:40.972908  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:14:40.972915  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397623 (* 1 = 0.0397623 loss)
I0627 01:14:40.972920  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0459347 (* 1 = 0.0459347 loss)
I0627 01:14:40.972923  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000904629 (* 1 = 0.000904629 loss)
I0627 01:14:40.972928  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00530419 (* 1 = 0.00530419 loss)
I0627 01:14:40.972931  4216 sgd_solver.cpp:106] Iteration 25400, lr = 2e-05
I0627 01:16:26.158102  4216 solver.cpp:228] Iteration 25420, loss = 0.0771391
I0627 01:16:26.158128  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:16:26.158134  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297873 (* 1 = 0.0297873 loss)
I0627 01:16:26.158138  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0778195 (* 1 = 0.0778195 loss)
I0627 01:16:26.158143  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000190902 (* 1 = 0.000190902 loss)
I0627 01:16:26.158145  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00716536 (* 1 = 0.00716536 loss)
I0627 01:16:26.158150  4216 sgd_solver.cpp:106] Iteration 25420, lr = 2e-05
I0627 01:18:11.371351  4216 solver.cpp:228] Iteration 25440, loss = 0.199504
I0627 01:18:11.371381  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:18:11.371388  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0699766 (* 1 = 0.0699766 loss)
I0627 01:18:11.371392  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0711368 (* 1 = 0.0711368 loss)
I0627 01:18:11.371397  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00717023 (* 1 = 0.00717023 loss)
I0627 01:18:11.371402  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204264 (* 1 = 0.0204264 loss)
I0627 01:18:11.371407  4216 sgd_solver.cpp:106] Iteration 25440, lr = 2e-05
I0627 01:19:56.552597  4216 solver.cpp:228] Iteration 25460, loss = 0.256135
I0627 01:19:56.552621  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:19:56.552629  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269216 (* 1 = 0.0269216 loss)
I0627 01:19:56.552634  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0217964 (* 1 = 0.0217964 loss)
I0627 01:19:56.552639  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000768695 (* 1 = 0.000768695 loss)
I0627 01:19:56.552642  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135359 (* 1 = 0.0135359 loss)
I0627 01:19:56.552647  4216 sgd_solver.cpp:106] Iteration 25460, lr = 2e-05
I0627 01:21:41.703730  4216 solver.cpp:228] Iteration 25480, loss = 0.176231
I0627 01:21:41.703757  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:21:41.703764  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00277942 (* 1 = 0.00277942 loss)
I0627 01:21:41.703769  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0240637 (* 1 = 0.0240637 loss)
I0627 01:21:41.703773  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301455 (* 1 = 0.00301455 loss)
I0627 01:21:41.703778  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100423 (* 1 = 0.0100423 loss)
I0627 01:21:41.703783  4216 sgd_solver.cpp:106] Iteration 25480, lr = 2e-05
I0627 01:23:26.936031  4216 solver.cpp:228] Iteration 25500, loss = 0.174628
I0627 01:23:26.936058  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:23:26.936066  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0283125 (* 1 = 0.0283125 loss)
I0627 01:23:26.936070  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0643505 (* 1 = 0.0643505 loss)
I0627 01:23:26.936074  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000126094 (* 1 = 0.000126094 loss)
I0627 01:23:26.936079  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178751 (* 1 = 0.0178751 loss)
I0627 01:23:26.936084  4216 sgd_solver.cpp:106] Iteration 25500, lr = 2e-05
I0627 01:25:12.203186  4216 solver.cpp:228] Iteration 25520, loss = 0.171657
I0627 01:25:12.203210  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:25:12.203217  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0180819 (* 1 = 0.0180819 loss)
I0627 01:25:12.203222  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0502335 (* 1 = 0.0502335 loss)
I0627 01:25:12.203224  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173807 (* 1 = 0.00173807 loss)
I0627 01:25:12.203228  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00867618 (* 1 = 0.00867618 loss)
I0627 01:25:12.203233  4216 sgd_solver.cpp:106] Iteration 25520, lr = 2e-05
I0627 01:26:57.395092  4216 solver.cpp:228] Iteration 25540, loss = 0.0857537
I0627 01:26:57.395117  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 01:26:57.395124  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.035487 (* 1 = 0.035487 loss)
I0627 01:26:57.395128  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.011787 (* 1 = 0.011787 loss)
I0627 01:26:57.395133  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000393657 (* 1 = 0.000393657 loss)
I0627 01:26:57.395136  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00667357 (* 1 = 0.00667357 loss)
I0627 01:26:57.395141  4216 sgd_solver.cpp:106] Iteration 25540, lr = 2e-05
I0627 01:28:42.590849  4216 solver.cpp:228] Iteration 25560, loss = 0.162814
I0627 01:28:42.590889  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:28:42.590899  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355721 (* 1 = 0.0355721 loss)
I0627 01:28:42.590906  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0666881 (* 1 = 0.0666881 loss)
I0627 01:28:42.590911  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0021536 (* 1 = 0.0021536 loss)
I0627 01:28:42.590917  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00655307 (* 1 = 0.00655307 loss)
I0627 01:28:42.590924  4216 sgd_solver.cpp:106] Iteration 25560, lr = 2e-05
I0627 01:30:27.803088  4216 solver.cpp:228] Iteration 25580, loss = 0.12565
I0627 01:30:27.803115  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 01:30:27.803123  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0864783 (* 1 = 0.0864783 loss)
I0627 01:30:27.803128  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.108884 (* 1 = 0.108884 loss)
I0627 01:30:27.803131  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000543083 (* 1 = 0.000543083 loss)
I0627 01:30:27.803135  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00542648 (* 1 = 0.00542648 loss)
I0627 01:30:27.803140  4216 sgd_solver.cpp:106] Iteration 25580, lr = 2e-05
speed: 5.287s / iter
I0627 01:32:12.993731  4216 solver.cpp:228] Iteration 25600, loss = 0.147197
I0627 01:32:12.993757  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:32:12.993764  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000885515 (* 1 = 0.000885515 loss)
I0627 01:32:12.993768  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0154161 (* 1 = 0.0154161 loss)
I0627 01:32:12.993773  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029969 (* 1 = 0.0029969 loss)
I0627 01:32:12.993777  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164706 (* 1 = 0.0164706 loss)
I0627 01:32:12.993782  4216 sgd_solver.cpp:106] Iteration 25600, lr = 2e-05
I0627 01:33:58.134099  4216 solver.cpp:228] Iteration 25620, loss = 0.157344
I0627 01:33:58.134141  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 01:33:58.134152  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0714474 (* 1 = 0.0714474 loss)
I0627 01:33:58.134158  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.132082 (* 1 = 0.132082 loss)
I0627 01:33:58.134163  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239703 (* 1 = 0.00239703 loss)
I0627 01:33:58.134168  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244506 (* 1 = 0.0244506 loss)
I0627 01:33:58.134176  4216 sgd_solver.cpp:106] Iteration 25620, lr = 2e-05
I0627 01:35:43.355764  4216 solver.cpp:228] Iteration 25640, loss = 0.0928539
I0627 01:35:43.355790  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:35:43.355798  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0134761 (* 1 = 0.0134761 loss)
I0627 01:35:43.355801  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0391923 (* 1 = 0.0391923 loss)
I0627 01:35:43.355805  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251658 (* 1 = 0.0251658 loss)
I0627 01:35:43.355809  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00754669 (* 1 = 0.00754669 loss)
I0627 01:35:43.355813  4216 sgd_solver.cpp:106] Iteration 25640, lr = 2e-05
I0627 01:37:28.560875  4216 solver.cpp:228] Iteration 25660, loss = 0.197601
I0627 01:37:28.560900  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:37:28.560909  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0491595 (* 1 = 0.0491595 loss)
I0627 01:37:28.560912  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0729249 (* 1 = 0.0729249 loss)
I0627 01:37:28.560916  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403941 (* 1 = 0.00403941 loss)
I0627 01:37:28.560920  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0066084 (* 1 = 0.0066084 loss)
I0627 01:37:28.560925  4216 sgd_solver.cpp:106] Iteration 25660, lr = 2e-05
I0627 01:39:13.724133  4216 solver.cpp:228] Iteration 25680, loss = 0.120833
I0627 01:39:13.724159  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:39:13.724167  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0238059 (* 1 = 0.0238059 loss)
I0627 01:39:13.724172  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.029358 (* 1 = 0.029358 loss)
I0627 01:39:13.724175  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000100024 (* 1 = 0.000100024 loss)
I0627 01:39:13.724180  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00195477 (* 1 = 0.00195477 loss)
I0627 01:39:13.724186  4216 sgd_solver.cpp:106] Iteration 25680, lr = 2e-05
I0627 01:40:58.980576  4216 solver.cpp:228] Iteration 25700, loss = 0.206555
I0627 01:40:58.980602  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:40:58.980609  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270871 (* 1 = 0.0270871 loss)
I0627 01:40:58.980613  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0404642 (* 1 = 0.0404642 loss)
I0627 01:40:58.980618  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169861 (* 1 = 0.00169861 loss)
I0627 01:40:58.980621  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116669 (* 1 = 0.0116669 loss)
I0627 01:40:58.980626  4216 sgd_solver.cpp:106] Iteration 25700, lr = 2e-05
I0627 01:42:44.486593  4216 solver.cpp:228] Iteration 25720, loss = 0.190008
I0627 01:42:44.486618  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:42:44.486625  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000140062 (* 1 = 0.000140062 loss)
I0627 01:42:44.486629  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0187347 (* 1 = 0.0187347 loss)
I0627 01:42:44.486634  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151746 (* 1 = 0.00151746 loss)
I0627 01:42:44.486636  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266187 (* 1 = 0.0266187 loss)
I0627 01:42:44.486641  4216 sgd_solver.cpp:106] Iteration 25720, lr = 2e-05
I0627 01:44:30.009840  4216 solver.cpp:228] Iteration 25740, loss = 0.102475
I0627 01:44:30.009865  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:44:30.009871  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0345309 (* 1 = 0.0345309 loss)
I0627 01:44:30.009876  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0790565 (* 1 = 0.0790565 loss)
I0627 01:44:30.009879  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184929 (* 1 = 0.0184929 loss)
I0627 01:44:30.009882  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011103 (* 1 = 0.011103 loss)
I0627 01:44:30.009887  4216 sgd_solver.cpp:106] Iteration 25740, lr = 2e-05
I0627 01:46:15.424129  4216 solver.cpp:228] Iteration 25760, loss = 0.151907
I0627 01:46:15.424157  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:46:15.424165  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.03395 (* 1 = 0.03395 loss)
I0627 01:46:15.424170  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.115455 (* 1 = 0.115455 loss)
I0627 01:46:15.424173  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000353622 (* 1 = 0.000353622 loss)
I0627 01:46:15.424176  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162768 (* 1 = 0.0162768 loss)
I0627 01:46:15.424181  4216 sgd_solver.cpp:106] Iteration 25760, lr = 2e-05
I0627 01:48:00.779973  4216 solver.cpp:228] Iteration 25780, loss = 0.188187
I0627 01:48:00.779999  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 01:48:00.780006  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.045829 (* 1 = 0.045829 loss)
I0627 01:48:00.780009  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0691302 (* 1 = 0.0691302 loss)
I0627 01:48:00.780014  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239739 (* 1 = 0.00239739 loss)
I0627 01:48:00.780017  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133672 (* 1 = 0.0133672 loss)
I0627 01:48:00.780022  4216 sgd_solver.cpp:106] Iteration 25780, lr = 2e-05
speed: 5.287s / iter
I0627 01:49:46.229398  4216 solver.cpp:228] Iteration 25800, loss = 0.220439
I0627 01:49:46.229421  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0627 01:49:46.229430  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.255326 (* 1 = 0.255326 loss)
I0627 01:49:46.229436  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.344632 (* 1 = 0.344632 loss)
I0627 01:49:46.229442  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00617061 (* 1 = 0.00617061 loss)
I0627 01:49:46.229447  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.064674 (* 1 = 0.064674 loss)
I0627 01:49:46.229454  4216 sgd_solver.cpp:106] Iteration 25800, lr = 2e-05
I0627 01:51:31.657474  4216 solver.cpp:228] Iteration 25820, loss = 0.190091
I0627 01:51:31.657498  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 01:51:31.657505  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.014876 (* 1 = 0.014876 loss)
I0627 01:51:31.657510  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0569544 (* 1 = 0.0569544 loss)
I0627 01:51:31.657513  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000575474 (* 1 = 0.000575474 loss)
I0627 01:51:31.657516  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0077618 (* 1 = 0.0077618 loss)
I0627 01:51:31.657521  4216 sgd_solver.cpp:106] Iteration 25820, lr = 2e-05
I0627 01:53:17.305943  4216 solver.cpp:228] Iteration 25840, loss = 0.19107
I0627 01:53:17.305968  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:53:17.305975  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00326118 (* 1 = 0.00326118 loss)
I0627 01:53:17.305980  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0121794 (* 1 = 0.0121794 loss)
I0627 01:53:17.305984  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000113385 (* 1 = 0.000113385 loss)
I0627 01:53:17.305989  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0026538 (* 1 = 0.0026538 loss)
I0627 01:53:17.305994  4216 sgd_solver.cpp:106] Iteration 25840, lr = 2e-05
I0627 01:55:02.767930  4216 solver.cpp:228] Iteration 25860, loss = 0.133192
I0627 01:55:02.767956  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:55:02.767966  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0026378 (* 1 = 0.0026378 loss)
I0627 01:55:02.767972  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0294907 (* 1 = 0.0294907 loss)
I0627 01:55:02.767978  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00513661 (* 1 = 0.00513661 loss)
I0627 01:55:02.767985  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170538 (* 1 = 0.0170538 loss)
I0627 01:55:02.767994  4216 sgd_solver.cpp:106] Iteration 25860, lr = 2e-05
I0627 01:56:48.260879  4216 solver.cpp:228] Iteration 25880, loss = 0.287187
I0627 01:56:48.260905  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0627 01:56:48.260913  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.48166 (* 1 = 0.48166 loss)
I0627 01:56:48.260918  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.593214 (* 1 = 0.593214 loss)
I0627 01:56:48.260922  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261344 (* 1 = 0.0261344 loss)
I0627 01:56:48.260926  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.260177 (* 1 = 0.260177 loss)
I0627 01:56:48.260931  4216 sgd_solver.cpp:106] Iteration 25880, lr = 2e-05
I0627 01:58:33.724225  4216 solver.cpp:228] Iteration 25900, loss = 0.159587
I0627 01:58:33.724251  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 01:58:33.724257  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320703 (* 1 = 0.0320703 loss)
I0627 01:58:33.724261  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0975397 (* 1 = 0.0975397 loss)
I0627 01:58:33.724265  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445646 (* 1 = 0.00445646 loss)
I0627 01:58:33.724269  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125164 (* 1 = 0.0125164 loss)
I0627 01:58:33.724273  4216 sgd_solver.cpp:106] Iteration 25900, lr = 2e-05
I0627 02:00:18.934092  4216 solver.cpp:228] Iteration 25920, loss = 0.141363
I0627 02:00:18.934116  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:00:18.934123  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104043 (* 1 = 0.104043 loss)
I0627 02:00:18.934128  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.048056 (* 1 = 0.048056 loss)
I0627 02:00:18.934131  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00819863 (* 1 = 0.00819863 loss)
I0627 02:00:18.934134  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219397 (* 1 = 0.0219397 loss)
I0627 02:00:18.934139  4216 sgd_solver.cpp:106] Iteration 25920, lr = 2e-05
I0627 02:02:04.325701  4216 solver.cpp:228] Iteration 25940, loss = 0.117409
I0627 02:02:04.325726  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:02:04.325734  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0303753 (* 1 = 0.0303753 loss)
I0627 02:02:04.325738  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.03993 (* 1 = 0.03993 loss)
I0627 02:02:04.325742  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00381435 (* 1 = 0.00381435 loss)
I0627 02:02:04.325745  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141613 (* 1 = 0.0141613 loss)
I0627 02:02:04.325750  4216 sgd_solver.cpp:106] Iteration 25940, lr = 2e-05
I0627 02:03:49.655071  4216 solver.cpp:228] Iteration 25960, loss = 0.0604284
I0627 02:03:49.655095  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:03:49.655103  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0352191 (* 1 = 0.0352191 loss)
I0627 02:03:49.655107  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0302653 (* 1 = 0.0302653 loss)
I0627 02:03:49.655112  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226797 (* 1 = 0.00226797 loss)
I0627 02:03:49.655114  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108779 (* 1 = 0.0108779 loss)
I0627 02:03:49.655119  4216 sgd_solver.cpp:106] Iteration 25960, lr = 2e-05
I0627 02:05:35.041002  4216 solver.cpp:228] Iteration 25980, loss = 0.241568
I0627 02:05:35.041025  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 02:05:35.041033  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855119 (* 1 = 0.0855119 loss)
I0627 02:05:35.041036  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.124274 (* 1 = 0.124274 loss)
I0627 02:05:35.041040  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00349605 (* 1 = 0.00349605 loss)
I0627 02:05:35.041044  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134103 (* 1 = 0.0134103 loss)
I0627 02:05:35.041049  4216 sgd_solver.cpp:106] Iteration 25980, lr = 2e-05
speed: 5.287s / iter
I0627 02:07:20.241915  4216 solver.cpp:228] Iteration 26000, loss = 0.112583
I0627 02:07:20.241942  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:07:20.241950  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349486 (* 1 = 0.0349486 loss)
I0627 02:07:20.241953  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0642639 (* 1 = 0.0642639 loss)
I0627 02:07:20.241956  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186068 (* 1 = 0.00186068 loss)
I0627 02:07:20.241961  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152879 (* 1 = 0.0152879 loss)
I0627 02:07:20.241966  4216 sgd_solver.cpp:106] Iteration 26000, lr = 2e-05
I0627 02:09:05.411566  4216 solver.cpp:228] Iteration 26020, loss = 0.276903
I0627 02:09:05.411593  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:09:05.411600  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265227 (* 1 = 0.0265227 loss)
I0627 02:09:05.411605  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0135631 (* 1 = 0.0135631 loss)
I0627 02:09:05.411608  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000298883 (* 1 = 0.000298883 loss)
I0627 02:09:05.411612  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00436886 (* 1 = 0.00436886 loss)
I0627 02:09:05.411617  4216 sgd_solver.cpp:106] Iteration 26020, lr = 2e-05
I0627 02:10:50.620443  4216 solver.cpp:228] Iteration 26040, loss = 0.148171
I0627 02:10:50.620470  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:10:50.620477  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00680862 (* 1 = 0.00680862 loss)
I0627 02:10:50.620482  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.012408 (* 1 = 0.012408 loss)
I0627 02:10:50.620486  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241381 (* 1 = 0.00241381 loss)
I0627 02:10:50.620489  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023203 (* 1 = 0.023203 loss)
I0627 02:10:50.620494  4216 sgd_solver.cpp:106] Iteration 26040, lr = 2e-05
I0627 02:12:35.950589  4216 solver.cpp:228] Iteration 26060, loss = 0.135025
I0627 02:12:35.950789  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 02:12:35.950842  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0982712 (* 1 = 0.0982712 loss)
I0627 02:12:35.950875  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.210082 (* 1 = 0.210082 loss)
I0627 02:12:35.950891  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00812866 (* 1 = 0.00812866 loss)
I0627 02:12:35.950906  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374736 (* 1 = 0.0374736 loss)
I0627 02:12:35.950932  4216 sgd_solver.cpp:106] Iteration 26060, lr = 2e-05
I0627 02:14:21.152597  4216 solver.cpp:228] Iteration 26080, loss = 0.234343
I0627 02:14:21.152623  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:14:21.152632  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0342232 (* 1 = 0.0342232 loss)
I0627 02:14:21.152638  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0669223 (* 1 = 0.0669223 loss)
I0627 02:14:21.152644  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000219924 (* 1 = 0.000219924 loss)
I0627 02:14:21.152650  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119647 (* 1 = 0.0119647 loss)
I0627 02:14:21.152658  4216 sgd_solver.cpp:106] Iteration 26080, lr = 2e-05
I0627 02:16:06.353945  4216 solver.cpp:228] Iteration 26100, loss = 0.102355
I0627 02:16:06.353973  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:16:06.353981  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148345 (* 1 = 0.0148345 loss)
I0627 02:16:06.353986  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0185748 (* 1 = 0.0185748 loss)
I0627 02:16:06.353989  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000419448 (* 1 = 0.000419448 loss)
I0627 02:16:06.353993  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00883819 (* 1 = 0.00883819 loss)
I0627 02:16:06.353998  4216 sgd_solver.cpp:106] Iteration 26100, lr = 2e-05
I0627 02:17:51.562269  4216 solver.cpp:228] Iteration 26120, loss = 0.129163
I0627 02:17:51.562295  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:17:51.562304  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0210617 (* 1 = 0.0210617 loss)
I0627 02:17:51.562309  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0529502 (* 1 = 0.0529502 loss)
I0627 02:17:51.562312  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281176 (* 1 = 0.00281176 loss)
I0627 02:17:51.562316  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197114 (* 1 = 0.0197114 loss)
I0627 02:17:51.562321  4216 sgd_solver.cpp:106] Iteration 26120, lr = 2e-05
I0627 02:19:36.810490  4216 solver.cpp:228] Iteration 26140, loss = 0.115016
I0627 02:19:36.810519  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 02:19:36.810528  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259041 (* 1 = 0.0259041 loss)
I0627 02:19:36.810531  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117213 (* 1 = 0.117213 loss)
I0627 02:19:36.810536  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0048608 (* 1 = 0.0048608 loss)
I0627 02:19:36.810540  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0484841 (* 1 = 0.0484841 loss)
I0627 02:19:36.810545  4216 sgd_solver.cpp:106] Iteration 26140, lr = 2e-05
I0627 02:21:22.021782  4216 solver.cpp:228] Iteration 26160, loss = 0.307822
I0627 02:21:22.021808  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0627 02:21:22.021816  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.633723 (* 1 = 0.633723 loss)
I0627 02:21:22.021821  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.572187 (* 1 = 0.572187 loss)
I0627 02:21:22.021826  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0487709 (* 1 = 0.0487709 loss)
I0627 02:21:22.021829  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.247361 (* 1 = 0.247361 loss)
I0627 02:21:22.021834  4216 sgd_solver.cpp:106] Iteration 26160, lr = 2e-05
I0627 02:23:07.444314  4216 solver.cpp:228] Iteration 26180, loss = 0.118982
I0627 02:23:07.444344  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:23:07.444358  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.034056 (* 1 = 0.034056 loss)
I0627 02:23:07.444367  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0339476 (* 1 = 0.0339476 loss)
I0627 02:23:07.444376  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000948305 (* 1 = 0.000948305 loss)
I0627 02:23:07.444386  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00649491 (* 1 = 0.00649491 loss)
I0627 02:23:07.444396  4216 sgd_solver.cpp:106] Iteration 26180, lr = 2e-05
speed: 5.287s / iter
I0627 02:24:52.746253  4216 solver.cpp:228] Iteration 26200, loss = 0.202757
I0627 02:24:52.746279  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:24:52.746289  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0111288 (* 1 = 0.0111288 loss)
I0627 02:24:52.746295  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0177196 (* 1 = 0.0177196 loss)
I0627 02:24:52.746302  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000475135 (* 1 = 0.000475135 loss)
I0627 02:24:52.746309  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100647 (* 1 = 0.0100647 loss)
I0627 02:24:52.746316  4216 sgd_solver.cpp:106] Iteration 26200, lr = 2e-05
I0627 02:26:38.561280  4216 solver.cpp:228] Iteration 26220, loss = 0.141718
I0627 02:26:38.561306  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:26:38.561314  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0180006 (* 1 = 0.0180006 loss)
I0627 02:26:38.561319  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0237362 (* 1 = 0.0237362 loss)
I0627 02:26:38.561323  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 1.75607e-05 (* 1 = 1.75607e-05 loss)
I0627 02:26:38.561329  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00693929 (* 1 = 0.00693929 loss)
I0627 02:26:38.561334  4216 sgd_solver.cpp:106] Iteration 26220, lr = 2e-05
I0627 02:28:24.035874  4216 solver.cpp:228] Iteration 26240, loss = 0.224451
I0627 02:28:24.035900  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:28:24.035907  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00692185 (* 1 = 0.00692185 loss)
I0627 02:28:24.035912  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.015093 (* 1 = 0.015093 loss)
I0627 02:28:24.035917  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000950088 (* 1 = 0.000950088 loss)
I0627 02:28:24.035921  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0072193 (* 1 = 0.0072193 loss)
I0627 02:28:24.035926  4216 sgd_solver.cpp:106] Iteration 26240, lr = 2e-05
I0627 02:30:09.438822  4216 solver.cpp:228] Iteration 26260, loss = 0.187672
I0627 02:30:09.438848  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 02:30:09.438863  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.107826 (* 1 = 0.107826 loss)
I0627 02:30:09.438871  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.112907 (* 1 = 0.112907 loss)
I0627 02:30:09.438877  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00495772 (* 1 = 0.00495772 loss)
I0627 02:30:09.438884  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00492686 (* 1 = 0.00492686 loss)
I0627 02:30:09.438890  4216 sgd_solver.cpp:106] Iteration 26260, lr = 2e-05
I0627 02:31:55.010134  4216 solver.cpp:228] Iteration 26280, loss = 0.104985
I0627 02:31:55.010161  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:31:55.010171  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0123052 (* 1 = 0.0123052 loss)
I0627 02:31:55.010179  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0360966 (* 1 = 0.0360966 loss)
I0627 02:31:55.010185  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000172239 (* 1 = 0.000172239 loss)
I0627 02:31:55.010191  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0058636 (* 1 = 0.0058636 loss)
I0627 02:31:55.010198  4216 sgd_solver.cpp:106] Iteration 26280, lr = 2e-05
I0627 02:33:40.681726  4216 solver.cpp:228] Iteration 26300, loss = 0.103113
I0627 02:33:40.681754  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:33:40.681766  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000321451 (* 1 = 0.000321451 loss)
I0627 02:33:40.681774  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0127611 (* 1 = 0.0127611 loss)
I0627 02:33:40.681782  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107062 (* 1 = 0.00107062 loss)
I0627 02:33:40.681790  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234312 (* 1 = 0.0234312 loss)
I0627 02:33:40.681798  4216 sgd_solver.cpp:106] Iteration 26300, lr = 2e-05
I0627 02:35:25.980382  4216 solver.cpp:228] Iteration 26320, loss = 0.145482
I0627 02:35:25.980412  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:35:25.980422  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441841 (* 1 = 0.0441841 loss)
I0627 02:35:25.980427  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0885164 (* 1 = 0.0885164 loss)
I0627 02:35:25.980433  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000411616 (* 1 = 0.000411616 loss)
I0627 02:35:25.980438  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154373 (* 1 = 0.0154373 loss)
I0627 02:35:25.980445  4216 sgd_solver.cpp:106] Iteration 26320, lr = 2e-05
I0627 02:37:11.491303  4216 solver.cpp:228] Iteration 26340, loss = 0.195637
I0627 02:37:11.491329  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:37:11.491338  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476914 (* 1 = 0.0476914 loss)
I0627 02:37:11.491341  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0839716 (* 1 = 0.0839716 loss)
I0627 02:37:11.491346  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00479141 (* 1 = 0.00479141 loss)
I0627 02:37:11.491350  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01178 (* 1 = 0.01178 loss)
I0627 02:37:11.491355  4216 sgd_solver.cpp:106] Iteration 26340, lr = 2e-05
I0627 02:38:56.804802  4216 solver.cpp:228] Iteration 26360, loss = 0.120834
I0627 02:38:56.804829  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:38:56.804836  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384795 (* 1 = 0.0384795 loss)
I0627 02:38:56.804841  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0658381 (* 1 = 0.0658381 loss)
I0627 02:38:56.804844  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000357837 (* 1 = 0.000357837 loss)
I0627 02:38:56.804848  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00522182 (* 1 = 0.00522182 loss)
I0627 02:38:56.804852  4216 sgd_solver.cpp:106] Iteration 26360, lr = 2e-05
I0627 02:40:42.306887  4216 solver.cpp:228] Iteration 26380, loss = 0.144884
I0627 02:40:42.306915  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:40:42.306921  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262316 (* 1 = 0.0262316 loss)
I0627 02:40:42.306926  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0291289 (* 1 = 0.0291289 loss)
I0627 02:40:42.306931  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363606 (* 1 = 0.00363606 loss)
I0627 02:40:42.306933  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186246 (* 1 = 0.0186246 loss)
I0627 02:40:42.306938  4216 sgd_solver.cpp:106] Iteration 26380, lr = 2e-05
speed: 5.287s / iter
I0627 02:42:27.652951  4216 solver.cpp:228] Iteration 26400, loss = 0.102478
I0627 02:42:27.652976  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:42:27.652984  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.015817 (* 1 = 0.015817 loss)
I0627 02:42:27.652988  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0595548 (* 1 = 0.0595548 loss)
I0627 02:42:27.652992  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00707731 (* 1 = 0.00707731 loss)
I0627 02:42:27.652997  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00443381 (* 1 = 0.00443381 loss)
I0627 02:42:27.653002  4216 sgd_solver.cpp:106] Iteration 26400, lr = 2e-05
I0627 02:44:13.020301  4216 solver.cpp:228] Iteration 26420, loss = 0.27441
I0627 02:44:13.020328  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 02:44:13.020335  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0860208 (* 1 = 0.0860208 loss)
I0627 02:44:13.020340  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.180151 (* 1 = 0.180151 loss)
I0627 02:44:13.020344  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270329 (* 1 = 0.00270329 loss)
I0627 02:44:13.020349  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202581 (* 1 = 0.0202581 loss)
I0627 02:44:13.020354  4216 sgd_solver.cpp:106] Iteration 26420, lr = 2e-05
I0627 02:45:58.476210  4216 solver.cpp:228] Iteration 26440, loss = 0.174825
I0627 02:45:58.476236  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 02:45:58.476246  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.198881 (* 1 = 0.198881 loss)
I0627 02:45:58.476254  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.19585 (* 1 = 0.19585 loss)
I0627 02:45:58.476260  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135171 (* 1 = 0.00135171 loss)
I0627 02:45:58.476267  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419935 (* 1 = 0.0419935 loss)
I0627 02:45:58.476275  4216 sgd_solver.cpp:106] Iteration 26440, lr = 2e-05
I0627 02:47:43.877986  4216 solver.cpp:228] Iteration 26460, loss = 0.198318
I0627 02:47:43.878010  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:47:43.878020  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00140942 (* 1 = 0.00140942 loss)
I0627 02:47:43.878023  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0158824 (* 1 = 0.0158824 loss)
I0627 02:47:43.878028  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000506992 (* 1 = 0.000506992 loss)
I0627 02:47:43.878032  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204383 (* 1 = 0.0204383 loss)
I0627 02:47:43.878037  4216 sgd_solver.cpp:106] Iteration 26460, lr = 2e-05
I0627 02:49:29.166820  4216 solver.cpp:228] Iteration 26480, loss = 0.23353
I0627 02:49:29.166846  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:49:29.166853  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138096 (* 1 = 0.0138096 loss)
I0627 02:49:29.166860  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0299171 (* 1 = 0.0299171 loss)
I0627 02:49:29.166865  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000655417 (* 1 = 0.000655417 loss)
I0627 02:49:29.166869  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00450481 (* 1 = 0.00450481 loss)
I0627 02:49:29.166875  4216 sgd_solver.cpp:106] Iteration 26480, lr = 2e-05
I0627 02:51:14.487962  4216 solver.cpp:228] Iteration 26500, loss = 0.151894
I0627 02:51:14.487987  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:51:14.487995  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.050259 (* 1 = 0.050259 loss)
I0627 02:51:14.488001  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0574591 (* 1 = 0.0574591 loss)
I0627 02:51:14.488008  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116729 (* 1 = 0.00116729 loss)
I0627 02:51:14.488013  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105914 (* 1 = 0.0105914 loss)
I0627 02:51:14.488023  4216 sgd_solver.cpp:106] Iteration 26500, lr = 2e-05
I0627 02:52:59.757670  4216 solver.cpp:228] Iteration 26520, loss = 0.148009
I0627 02:52:59.757699  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:52:59.757707  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0184573 (* 1 = 0.0184573 loss)
I0627 02:52:59.757712  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0803971 (* 1 = 0.0803971 loss)
I0627 02:52:59.757716  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772487 (* 1 = 0.00772487 loss)
I0627 02:52:59.757721  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226244 (* 1 = 0.0226244 loss)
I0627 02:52:59.757727  4216 sgd_solver.cpp:106] Iteration 26520, lr = 2e-05
I0627 02:54:44.953204  4216 solver.cpp:228] Iteration 26540, loss = 0.140434
I0627 02:54:44.953227  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:54:44.953234  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0114216 (* 1 = 0.0114216 loss)
I0627 02:54:44.953238  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0399384 (* 1 = 0.0399384 loss)
I0627 02:54:44.953243  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00031324 (* 1 = 0.00031324 loss)
I0627 02:54:44.953245  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00318125 (* 1 = 0.00318125 loss)
I0627 02:54:44.953250  4216 sgd_solver.cpp:106] Iteration 26540, lr = 2e-05
I0627 02:56:30.173295  4216 solver.cpp:228] Iteration 26560, loss = 0.185324
I0627 02:56:30.173319  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0627 02:56:30.173327  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.248162 (* 1 = 0.248162 loss)
I0627 02:56:30.173331  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.368856 (* 1 = 0.368856 loss)
I0627 02:56:30.173336  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00634775 (* 1 = 0.00634775 loss)
I0627 02:56:30.173341  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0673916 (* 1 = 0.0673916 loss)
I0627 02:56:30.173346  4216 sgd_solver.cpp:106] Iteration 26560, lr = 2e-05
I0627 02:58:15.362651  4216 solver.cpp:228] Iteration 26580, loss = 0.118455
I0627 02:58:15.362679  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:58:15.362686  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523164 (* 1 = 0.0523164 loss)
I0627 02:58:15.362690  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.052351 (* 1 = 0.052351 loss)
I0627 02:58:15.362694  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000107699 (* 1 = 0.000107699 loss)
I0627 02:58:15.362699  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130065 (* 1 = 0.0130065 loss)
I0627 02:58:15.362704  4216 sgd_solver.cpp:106] Iteration 26580, lr = 2e-05
speed: 5.287s / iter
I0627 03:00:00.570233  4216 solver.cpp:228] Iteration 26600, loss = 0.119344
I0627 03:00:00.570261  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 03:00:00.570269  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0585961 (* 1 = 0.0585961 loss)
I0627 03:00:00.570274  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0888896 (* 1 = 0.0888896 loss)
I0627 03:00:00.570278  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00603171 (* 1 = 0.00603171 loss)
I0627 03:00:00.570282  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241399 (* 1 = 0.0241399 loss)
I0627 03:00:00.570287  4216 sgd_solver.cpp:106] Iteration 26600, lr = 2e-05
I0627 03:01:45.785696  4216 solver.cpp:228] Iteration 26620, loss = 0.135206
I0627 03:01:45.785720  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:01:45.785727  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262776 (* 1 = 0.0262776 loss)
I0627 03:01:45.785732  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0514444 (* 1 = 0.0514444 loss)
I0627 03:01:45.785735  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294666 (* 1 = 0.0294666 loss)
I0627 03:01:45.785738  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103463 (* 1 = 0.103463 loss)
I0627 03:01:45.785743  4216 sgd_solver.cpp:106] Iteration 26620, lr = 2e-05
I0627 03:03:31.107655  4216 solver.cpp:228] Iteration 26640, loss = 0.200176
I0627 03:03:31.107681  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 03:03:31.107689  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0617216 (* 1 = 0.0617216 loss)
I0627 03:03:31.107694  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121047 (* 1 = 0.121047 loss)
I0627 03:03:31.107698  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179988 (* 1 = 0.0179988 loss)
I0627 03:03:31.107702  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.11605 (* 1 = 0.11605 loss)
I0627 03:03:31.107707  4216 sgd_solver.cpp:106] Iteration 26640, lr = 2e-05
I0627 03:05:16.363549  4216 solver.cpp:228] Iteration 26660, loss = 0.117496
I0627 03:05:16.363574  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:05:16.363581  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00149039 (* 1 = 0.00149039 loss)
I0627 03:05:16.363585  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00348637 (* 1 = 0.00348637 loss)
I0627 03:05:16.363590  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294698 (* 1 = 0.00294698 loss)
I0627 03:05:16.363592  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211953 (* 1 = 0.0211953 loss)
I0627 03:05:16.363597  4216 sgd_solver.cpp:106] Iteration 26660, lr = 2e-05
I0627 03:07:01.544926  4216 solver.cpp:228] Iteration 26680, loss = 0.150707
I0627 03:07:01.544951  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:07:01.544960  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204247 (* 1 = 0.0204247 loss)
I0627 03:07:01.544963  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.052532 (* 1 = 0.052532 loss)
I0627 03:07:01.544967  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165525 (* 1 = 0.00165525 loss)
I0627 03:07:01.544971  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00174308 (* 1 = 0.00174308 loss)
I0627 03:07:01.544977  4216 sgd_solver.cpp:106] Iteration 26680, lr = 2e-05
I0627 03:08:46.842548  4216 solver.cpp:228] Iteration 26700, loss = 0.227695
I0627 03:08:46.842571  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 03:08:46.842578  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441038 (* 1 = 0.0441038 loss)
I0627 03:08:46.842584  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.102697 (* 1 = 0.102697 loss)
I0627 03:08:46.842591  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00739165 (* 1 = 0.00739165 loss)
I0627 03:08:46.842594  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280245 (* 1 = 0.0280245 loss)
I0627 03:08:46.842599  4216 sgd_solver.cpp:106] Iteration 26700, lr = 2e-05
I0627 03:10:32.052721  4216 solver.cpp:228] Iteration 26720, loss = 0.162699
I0627 03:10:32.052745  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:10:32.052752  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434896 (* 1 = 0.0434896 loss)
I0627 03:10:32.052757  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0533188 (* 1 = 0.0533188 loss)
I0627 03:10:32.052760  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00432112 (* 1 = 0.00432112 loss)
I0627 03:10:32.052763  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00958883 (* 1 = 0.00958883 loss)
I0627 03:10:32.052768  4216 sgd_solver.cpp:106] Iteration 26720, lr = 2e-05
I0627 03:12:17.336375  4216 solver.cpp:228] Iteration 26740, loss = 0.168454
I0627 03:12:17.336402  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:12:17.336410  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0356189 (* 1 = 0.0356189 loss)
I0627 03:12:17.336416  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0647111 (* 1 = 0.0647111 loss)
I0627 03:12:17.336421  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271365 (* 1 = 0.00271365 loss)
I0627 03:12:17.336426  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00975572 (* 1 = 0.00975572 loss)
I0627 03:12:17.336431  4216 sgd_solver.cpp:106] Iteration 26740, lr = 2e-05
I0627 03:14:02.599406  4216 solver.cpp:228] Iteration 26760, loss = 0.202265
I0627 03:14:02.599434  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:14:02.599444  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.029476 (* 1 = 0.029476 loss)
I0627 03:14:02.599452  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0746956 (* 1 = 0.0746956 loss)
I0627 03:14:02.599457  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000858362 (* 1 = 0.000858362 loss)
I0627 03:14:02.599463  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00945366 (* 1 = 0.00945366 loss)
I0627 03:14:02.599470  4216 sgd_solver.cpp:106] Iteration 26760, lr = 2e-05
I0627 03:15:47.772204  4216 solver.cpp:228] Iteration 26780, loss = 0.0987035
I0627 03:15:47.772228  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 03:15:47.772235  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.067898 (* 1 = 0.067898 loss)
I0627 03:15:47.772239  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.098095 (* 1 = 0.098095 loss)
I0627 03:15:47.772243  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00323933 (* 1 = 0.00323933 loss)
I0627 03:15:47.772246  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00996314 (* 1 = 0.00996314 loss)
I0627 03:15:47.772251  4216 sgd_solver.cpp:106] Iteration 26780, lr = 2e-05
speed: 5.286s / iter
I0627 03:17:33.183099  4216 solver.cpp:228] Iteration 26800, loss = 0.155198
I0627 03:17:33.183125  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 03:17:33.183132  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.10138 (* 1 = 0.10138 loss)
I0627 03:17:33.183136  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.202092 (* 1 = 0.202092 loss)
I0627 03:17:33.183140  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150825 (* 1 = 0.0150825 loss)
I0627 03:17:33.183143  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495568 (* 1 = 0.0495568 loss)
I0627 03:17:33.183147  4216 sgd_solver.cpp:106] Iteration 26800, lr = 2e-05
I0627 03:19:18.617743  4216 solver.cpp:228] Iteration 26820, loss = 0.11334
I0627 03:19:18.617770  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:19:18.617780  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0578923 (* 1 = 0.0578923 loss)
I0627 03:19:18.617787  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0747746 (* 1 = 0.0747746 loss)
I0627 03:19:18.617794  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111639 (* 1 = 0.0111639 loss)
I0627 03:19:18.617799  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368079 (* 1 = 0.0368079 loss)
I0627 03:19:18.617808  4216 sgd_solver.cpp:106] Iteration 26820, lr = 2e-05
I0627 03:21:04.206599  4216 solver.cpp:228] Iteration 26840, loss = 0.221992
I0627 03:21:04.206624  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:21:04.206631  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222375 (* 1 = 0.0222375 loss)
I0627 03:21:04.206636  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0184343 (* 1 = 0.0184343 loss)
I0627 03:21:04.206640  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108514 (* 1 = 0.00108514 loss)
I0627 03:21:04.206645  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130602 (* 1 = 0.0130602 loss)
I0627 03:21:04.206650  4216 sgd_solver.cpp:106] Iteration 26840, lr = 2e-05
I0627 03:22:49.850229  4216 solver.cpp:228] Iteration 26860, loss = 0.232484
I0627 03:22:49.850255  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:22:49.850261  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0285406 (* 1 = 0.0285406 loss)
I0627 03:22:49.850266  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.039206 (* 1 = 0.039206 loss)
I0627 03:22:49.850270  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000118314 (* 1 = 0.000118314 loss)
I0627 03:22:49.850275  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00866641 (* 1 = 0.00866641 loss)
I0627 03:22:49.850280  4216 sgd_solver.cpp:106] Iteration 26860, lr = 2e-05
I0627 03:24:37.604743  4216 solver.cpp:228] Iteration 26880, loss = 0.227415
I0627 03:24:37.604771  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:24:37.604781  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185714 (* 1 = 0.0185714 loss)
I0627 03:24:37.604787  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0152214 (* 1 = 0.0152214 loss)
I0627 03:24:37.604794  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000306601 (* 1 = 0.000306601 loss)
I0627 03:24:37.604800  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00354444 (* 1 = 0.00354444 loss)
I0627 03:24:37.604807  4216 sgd_solver.cpp:106] Iteration 26880, lr = 2e-05
I0627 03:26:23.051497  4216 solver.cpp:228] Iteration 26900, loss = 0.185431
I0627 03:26:23.051525  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 03:26:23.051533  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.128284 (* 1 = 0.128284 loss)
I0627 03:26:23.051538  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.215635 (* 1 = 0.215635 loss)
I0627 03:26:23.051543  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112804 (* 1 = 0.0112804 loss)
I0627 03:26:23.051548  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0661344 (* 1 = 0.0661344 loss)
I0627 03:26:23.051554  4216 sgd_solver.cpp:106] Iteration 26900, lr = 2e-05
I0627 03:28:08.488477  4216 solver.cpp:228] Iteration 26920, loss = 0.157489
I0627 03:28:08.488507  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:28:08.488515  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0105095 (* 1 = 0.0105095 loss)
I0627 03:28:08.488521  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.015402 (* 1 = 0.015402 loss)
I0627 03:28:08.488526  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00059308 (* 1 = 0.00059308 loss)
I0627 03:28:08.488531  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00465289 (* 1 = 0.00465289 loss)
I0627 03:28:08.488536  4216 sgd_solver.cpp:106] Iteration 26920, lr = 2e-05
I0627 03:29:53.956076  4216 solver.cpp:228] Iteration 26940, loss = 0.180455
I0627 03:29:53.956100  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 03:29:53.956107  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.112446 (* 1 = 0.112446 loss)
I0627 03:29:53.956111  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.19786 (* 1 = 0.19786 loss)
I0627 03:29:53.956115  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388064 (* 1 = 0.00388064 loss)
I0627 03:29:53.956120  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0750185 (* 1 = 0.0750185 loss)
I0627 03:29:53.956123  4216 sgd_solver.cpp:106] Iteration 26940, lr = 2e-05
I0627 03:31:39.594172  4216 solver.cpp:228] Iteration 26960, loss = 0.29158
I0627 03:31:39.594200  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:31:39.594208  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000743923 (* 1 = 0.000743923 loss)
I0627 03:31:39.594215  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0312708 (* 1 = 0.0312708 loss)
I0627 03:31:39.594223  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120187 (* 1 = 0.00120187 loss)
I0627 03:31:39.594228  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145065 (* 1 = 0.0145065 loss)
I0627 03:31:39.594233  4216 sgd_solver.cpp:106] Iteration 26960, lr = 2e-05
I0627 03:33:25.109933  4216 solver.cpp:228] Iteration 26980, loss = 0.127301
I0627 03:33:25.109977  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:33:25.109987  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0200082 (* 1 = 0.0200082 loss)
I0627 03:33:25.109992  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0162579 (* 1 = 0.0162579 loss)
I0627 03:33:25.109995  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019839 (* 1 = 0.0019839 loss)
I0627 03:33:25.109999  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0045029 (* 1 = 0.0045029 loss)
I0627 03:33:25.110007  4216 sgd_solver.cpp:106] Iteration 26980, lr = 2e-05
speed: 5.286s / iter
I0627 03:35:10.392278  4216 solver.cpp:228] Iteration 27000, loss = 0.152015
I0627 03:35:10.392304  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:35:10.392313  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266695 (* 1 = 0.0266695 loss)
I0627 03:35:10.392319  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0212235 (* 1 = 0.0212235 loss)
I0627 03:35:10.392325  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016831 (* 1 = 0.0016831 loss)
I0627 03:35:10.392331  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378018 (* 1 = 0.0378018 loss)
I0627 03:35:10.392338  4216 sgd_solver.cpp:106] Iteration 27000, lr = 2e-05
I0627 03:36:55.597369  4216 solver.cpp:228] Iteration 27020, loss = 0.349376
I0627 03:36:55.597396  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0627 03:36:55.597404  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.303187 (* 1 = 0.303187 loss)
I0627 03:36:55.597409  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.340353 (* 1 = 0.340353 loss)
I0627 03:36:55.597414  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013569 (* 1 = 0.0013569 loss)
I0627 03:36:55.597417  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0766995 (* 1 = 0.0766995 loss)
I0627 03:36:55.597424  4216 sgd_solver.cpp:106] Iteration 27020, lr = 2e-05
I0627 03:38:40.918018  4216 solver.cpp:228] Iteration 27040, loss = 0.178017
I0627 03:38:40.918045  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:38:40.918051  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142774 (* 1 = 0.0142774 loss)
I0627 03:38:40.918056  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.02401 (* 1 = 0.02401 loss)
I0627 03:38:40.918059  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00635336 (* 1 = 0.00635336 loss)
I0627 03:38:40.918062  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00319094 (* 1 = 0.00319094 loss)
I0627 03:38:40.918068  4216 sgd_solver.cpp:106] Iteration 27040, lr = 2e-05
I0627 03:40:26.146208  4216 solver.cpp:228] Iteration 27060, loss = 0.145423
I0627 03:40:26.146232  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:40:26.146241  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0572105 (* 1 = 0.0572105 loss)
I0627 03:40:26.146247  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0735453 (* 1 = 0.0735453 loss)
I0627 03:40:26.146252  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00033501 (* 1 = 0.00033501 loss)
I0627 03:40:26.146257  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171082 (* 1 = 0.0171082 loss)
I0627 03:40:26.146265  4216 sgd_solver.cpp:106] Iteration 27060, lr = 2e-05
I0627 03:42:11.398133  4216 solver.cpp:228] Iteration 27080, loss = 0.2548
I0627 03:42:11.398159  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0627 03:42:11.398167  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.148345 (* 1 = 0.148345 loss)
I0627 03:42:11.398175  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.185957 (* 1 = 0.185957 loss)
I0627 03:42:11.398180  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120234 (* 1 = 0.0120234 loss)
I0627 03:42:11.398185  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0721501 (* 1 = 0.0721501 loss)
I0627 03:42:11.398190  4216 sgd_solver.cpp:106] Iteration 27080, lr = 2e-05
I0627 03:43:56.607097  4216 solver.cpp:228] Iteration 27100, loss = 0.19343
I0627 03:43:56.607125  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0627 03:43:56.607133  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.297258 (* 1 = 0.297258 loss)
I0627 03:43:56.607137  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.405363 (* 1 = 0.405363 loss)
I0627 03:43:56.607141  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181051 (* 1 = 0.0181051 loss)
I0627 03:43:56.607146  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107054 (* 1 = 0.107054 loss)
I0627 03:43:56.607151  4216 sgd_solver.cpp:106] Iteration 27100, lr = 2e-05
I0627 03:45:41.893296  4216 solver.cpp:228] Iteration 27120, loss = 0.0996569
I0627 03:45:41.893328  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:45:41.893338  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349222 (* 1 = 0.0349222 loss)
I0627 03:45:41.893344  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0379113 (* 1 = 0.0379113 loss)
I0627 03:45:41.893349  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330109 (* 1 = 0.00330109 loss)
I0627 03:45:41.893354  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00960312 (* 1 = 0.00960312 loss)
I0627 03:45:41.893362  4216 sgd_solver.cpp:106] Iteration 27120, lr = 2e-05
I0627 03:47:27.241123  4216 solver.cpp:228] Iteration 27140, loss = 0.147665
I0627 03:47:27.241152  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:47:27.241161  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169179 (* 1 = 0.0169179 loss)
I0627 03:47:27.241166  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.04456 (* 1 = 0.04456 loss)
I0627 03:47:27.241170  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0021668 (* 1 = 0.0021668 loss)
I0627 03:47:27.241175  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0363731 (* 1 = 0.0363731 loss)
I0627 03:47:27.241181  4216 sgd_solver.cpp:106] Iteration 27140, lr = 2e-05
I0627 03:49:12.576732  4216 solver.cpp:228] Iteration 27160, loss = 0.0880648
I0627 03:49:12.576762  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:49:12.576772  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00796086 (* 1 = 0.00796086 loss)
I0627 03:49:12.576778  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0120557 (* 1 = 0.0120557 loss)
I0627 03:49:12.576784  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.98398e-05 (* 1 = 5.98398e-05 loss)
I0627 03:49:12.576791  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000286764 (* 1 = 0.000286764 loss)
I0627 03:49:12.576797  4216 sgd_solver.cpp:106] Iteration 27160, lr = 2e-05
I0627 03:50:57.959745  4216 solver.cpp:228] Iteration 27180, loss = 0.105827
I0627 03:50:57.959770  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:50:57.959777  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188677 (* 1 = 0.0188677 loss)
I0627 03:50:57.959784  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0741819 (* 1 = 0.0741819 loss)
I0627 03:50:57.959790  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000673698 (* 1 = 0.000673698 loss)
I0627 03:50:57.959794  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339711 (* 1 = 0.0339711 loss)
I0627 03:50:57.959798  4216 sgd_solver.cpp:106] Iteration 27180, lr = 2e-05
speed: 5.286s / iter
I0627 03:52:43.257278  4216 solver.cpp:228] Iteration 27200, loss = 0.162571
I0627 03:52:43.257303  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:52:43.257311  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0112513 (* 1 = 0.0112513 loss)
I0627 03:52:43.257316  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00502332 (* 1 = 0.00502332 loss)
I0627 03:52:43.257320  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000300888 (* 1 = 0.000300888 loss)
I0627 03:52:43.257324  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00420513 (* 1 = 0.00420513 loss)
I0627 03:52:43.257329  4216 sgd_solver.cpp:106] Iteration 27200, lr = 2e-05
I0627 03:54:28.480689  4216 solver.cpp:228] Iteration 27220, loss = 0.13462
I0627 03:54:28.480715  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:54:28.480726  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.048524 (* 1 = 0.048524 loss)
I0627 03:54:28.480731  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0323923 (* 1 = 0.0323923 loss)
I0627 03:54:28.480736  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000835469 (* 1 = 0.000835469 loss)
I0627 03:54:28.480742  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00748501 (* 1 = 0.00748501 loss)
I0627 03:54:28.480748  4216 sgd_solver.cpp:106] Iteration 27220, lr = 2e-05
I0627 03:56:13.777562  4216 solver.cpp:228] Iteration 27240, loss = 0.176931
I0627 03:56:13.777590  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:56:13.777597  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.024355 (* 1 = 0.024355 loss)
I0627 03:56:13.777601  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0484481 (* 1 = 0.0484481 loss)
I0627 03:56:13.777606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000478068 (* 1 = 0.000478068 loss)
I0627 03:56:13.777611  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117142 (* 1 = 0.0117142 loss)
I0627 03:56:13.777616  4216 sgd_solver.cpp:106] Iteration 27240, lr = 2e-05
I0627 03:58:00.298521  4216 solver.cpp:228] Iteration 27260, loss = 0.101251
I0627 03:58:00.298547  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:58:00.298557  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0551372 (* 1 = 0.0551372 loss)
I0627 03:58:00.298564  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0825963 (* 1 = 0.0825963 loss)
I0627 03:58:00.298570  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00222924 (* 1 = 0.00222924 loss)
I0627 03:58:00.298578  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.009951 (* 1 = 0.009951 loss)
I0627 03:58:00.298588  4216 sgd_solver.cpp:106] Iteration 27260, lr = 2e-05
I0627 03:59:45.616777  4216 solver.cpp:228] Iteration 27280, loss = 0.0819611
I0627 03:59:45.616803  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 03:59:45.616811  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0652384 (* 1 = 0.0652384 loss)
I0627 03:59:45.616814  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.138032 (* 1 = 0.138032 loss)
I0627 03:59:45.616818  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228274 (* 1 = 0.0228274 loss)
I0627 03:59:45.616822  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0484397 (* 1 = 0.0484397 loss)
I0627 03:59:45.616827  4216 sgd_solver.cpp:106] Iteration 27280, lr = 2e-05
I0627 04:01:30.809253  4216 solver.cpp:228] Iteration 27300, loss = 0.171961
I0627 04:01:30.809278  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 04:01:30.809285  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339413 (* 1 = 0.0339413 loss)
I0627 04:01:30.809289  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0770399 (* 1 = 0.0770399 loss)
I0627 04:01:30.809293  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00293381 (* 1 = 0.00293381 loss)
I0627 04:01:30.809296  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160049 (* 1 = 0.0160049 loss)
I0627 04:01:30.809303  4216 sgd_solver.cpp:106] Iteration 27300, lr = 2e-05
I0627 04:03:16.878319  4216 solver.cpp:228] Iteration 27320, loss = 0.151634
I0627 04:03:16.878345  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:03:16.878351  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00569183 (* 1 = 0.00569183 loss)
I0627 04:03:16.878356  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0103785 (* 1 = 0.0103785 loss)
I0627 04:03:16.878360  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00180747 (* 1 = 0.00180747 loss)
I0627 04:03:16.878365  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00557388 (* 1 = 0.00557388 loss)
I0627 04:03:16.878370  4216 sgd_solver.cpp:106] Iteration 27320, lr = 2e-05
I0627 04:05:02.391522  4216 solver.cpp:228] Iteration 27340, loss = 0.213888
I0627 04:05:02.391547  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0627 04:05:02.391554  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.214979 (* 1 = 0.214979 loss)
I0627 04:05:02.391558  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.281551 (* 1 = 0.281551 loss)
I0627 04:05:02.391562  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016157 (* 1 = 0.0016157 loss)
I0627 04:05:02.391566  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405297 (* 1 = 0.0405297 loss)
I0627 04:05:02.391571  4216 sgd_solver.cpp:106] Iteration 27340, lr = 2e-05
I0627 04:06:47.728081  4216 solver.cpp:228] Iteration 27360, loss = 0.071715
I0627 04:06:47.728107  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 04:06:47.728116  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273183 (* 1 = 0.0273183 loss)
I0627 04:06:47.728119  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0530549 (* 1 = 0.0530549 loss)
I0627 04:06:47.728123  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264884 (* 1 = 0.00264884 loss)
I0627 04:06:47.728128  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00635565 (* 1 = 0.00635565 loss)
I0627 04:06:47.728133  4216 sgd_solver.cpp:106] Iteration 27360, lr = 2e-05
I0627 04:08:33.155145  4216 solver.cpp:228] Iteration 27380, loss = 0.226599
I0627 04:08:33.155174  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 04:08:33.155182  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107974 (* 1 = 0.0107974 loss)
I0627 04:08:33.155187  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0396159 (* 1 = 0.0396159 loss)
I0627 04:08:33.155192  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.65528e-05 (* 1 = 3.65528e-05 loss)
I0627 04:08:33.155196  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00611257 (* 1 = 0.00611257 loss)
I0627 04:08:33.155202  4216 sgd_solver.cpp:106] Iteration 27380, lr = 2e-05
speed: 5.286s / iter
I0627 04:10:18.666561  4216 solver.cpp:228] Iteration 27400, loss = 0.197333
I0627 04:10:18.666592  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 04:10:18.666600  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355694 (* 1 = 0.0355694 loss)
I0627 04:10:18.666606  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0850072 (* 1 = 0.0850072 loss)
I0627 04:10:18.666610  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182574 (* 1 = 0.0182574 loss)
I0627 04:10:18.666615  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103962 (* 1 = 0.0103962 loss)
I0627 04:10:18.666620  4216 sgd_solver.cpp:106] Iteration 27400, lr = 2e-05
I0627 04:12:04.139384  4216 solver.cpp:228] Iteration 27420, loss = 0.182974
I0627 04:12:04.139415  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 04:12:04.139422  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0836936 (* 1 = 0.0836936 loss)
I0627 04:12:04.139426  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.104 (* 1 = 0.104 loss)
I0627 04:12:04.139430  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154213 (* 1 = 0.00154213 loss)
I0627 04:12:04.139434  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162975 (* 1 = 0.0162975 loss)
I0627 04:12:04.139441  4216 sgd_solver.cpp:106] Iteration 27420, lr = 2e-05
I0627 04:13:49.691305  4216 solver.cpp:228] Iteration 27440, loss = 0.173144
I0627 04:13:49.691334  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 04:13:49.691344  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.117592 (* 1 = 0.117592 loss)
I0627 04:13:49.691349  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.156872 (* 1 = 0.156872 loss)
I0627 04:13:49.691352  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00212691 (* 1 = 0.00212691 loss)
I0627 04:13:49.691357  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122257 (* 1 = 0.0122257 loss)
I0627 04:13:49.691364  4216 sgd_solver.cpp:106] Iteration 27440, lr = 2e-05
I0627 04:15:35.162495  4216 solver.cpp:228] Iteration 27460, loss = 0.179256
I0627 04:15:35.162523  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:15:35.162530  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0438436 (* 1 = 0.0438436 loss)
I0627 04:15:35.162535  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0603682 (* 1 = 0.0603682 loss)
I0627 04:15:35.162539  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00080202 (* 1 = 0.00080202 loss)
I0627 04:15:35.162542  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00597941 (* 1 = 0.00597941 loss)
I0627 04:15:35.162549  4216 sgd_solver.cpp:106] Iteration 27460, lr = 2e-05
I0627 04:17:20.686661  4216 solver.cpp:228] Iteration 27480, loss = 0.139212
I0627 04:17:20.686684  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0627 04:17:20.686691  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.12253 (* 1 = 0.12253 loss)
I0627 04:17:20.686695  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.261583 (* 1 = 0.261583 loss)
I0627 04:17:20.686699  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152093 (* 1 = 0.0152093 loss)
I0627 04:17:20.686702  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0891802 (* 1 = 0.0891802 loss)
I0627 04:17:20.686707  4216 sgd_solver.cpp:106] Iteration 27480, lr = 2e-05
I0627 04:19:06.249634  4216 solver.cpp:228] Iteration 27500, loss = 0.171077
I0627 04:19:06.249660  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:19:06.249667  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329277 (* 1 = 0.0329277 loss)
I0627 04:19:06.249671  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0760908 (* 1 = 0.0760908 loss)
I0627 04:19:06.249676  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351512 (* 1 = 0.00351512 loss)
I0627 04:19:06.249680  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361232 (* 1 = 0.0361232 loss)
I0627 04:19:06.249686  4216 sgd_solver.cpp:106] Iteration 27500, lr = 2e-05
I0627 04:20:51.711333  4216 solver.cpp:228] Iteration 27520, loss = 0.0831576
I0627 04:20:51.711359  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:20:51.711369  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00156541 (* 1 = 0.00156541 loss)
I0627 04:20:51.711376  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00751396 (* 1 = 0.00751396 loss)
I0627 04:20:51.711382  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0259882 (* 1 = 0.0259882 loss)
I0627 04:20:51.711390  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00984117 (* 1 = 0.00984117 loss)
I0627 04:20:51.711396  4216 sgd_solver.cpp:106] Iteration 27520, lr = 2e-05
I0627 04:22:37.179071  4216 solver.cpp:228] Iteration 27540, loss = 0.170137
I0627 04:22:37.179097  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 04:22:37.179105  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453352 (* 1 = 0.0453352 loss)
I0627 04:22:37.179109  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0968241 (* 1 = 0.0968241 loss)
I0627 04:22:37.179113  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00634843 (* 1 = 0.00634843 loss)
I0627 04:22:37.179117  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0360498 (* 1 = 0.0360498 loss)
I0627 04:22:37.179122  4216 sgd_solver.cpp:106] Iteration 27540, lr = 2e-05
I0627 04:24:22.750782  4216 solver.cpp:228] Iteration 27560, loss = 0.162933
I0627 04:24:22.750808  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:24:22.750816  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00135463 (* 1 = 0.00135463 loss)
I0627 04:24:22.750821  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0117121 (* 1 = 0.0117121 loss)
I0627 04:24:22.750825  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0331339 (* 1 = 0.0331339 loss)
I0627 04:24:22.750829  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110861 (* 1 = 0.0110861 loss)
I0627 04:24:22.750833  4216 sgd_solver.cpp:106] Iteration 27560, lr = 2e-05
I0627 04:26:07.905443  4216 solver.cpp:228] Iteration 27580, loss = 0.0953091
I0627 04:26:07.905469  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:26:07.905477  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225847 (* 1 = 0.0225847 loss)
I0627 04:26:07.905481  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0116348 (* 1 = 0.0116348 loss)
I0627 04:26:07.905485  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015151 (* 1 = 0.0015151 loss)
I0627 04:26:07.905489  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00448946 (* 1 = 0.00448946 loss)
I0627 04:26:07.905494  4216 sgd_solver.cpp:106] Iteration 27580, lr = 2e-05
speed: 5.286s / iter
I0627 04:27:53.346935  4216 solver.cpp:228] Iteration 27600, loss = 0.139781
I0627 04:27:53.346968  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:27:53.346977  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00896804 (* 1 = 0.00896804 loss)
I0627 04:27:53.346982  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0177809 (* 1 = 0.0177809 loss)
I0627 04:27:53.346985  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000429701 (* 1 = 0.000429701 loss)
I0627 04:27:53.346990  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00258929 (* 1 = 0.00258929 loss)
I0627 04:27:53.346997  4216 sgd_solver.cpp:106] Iteration 27600, lr = 2e-05
I0627 04:29:38.564412  4216 solver.cpp:228] Iteration 27620, loss = 0.256182
I0627 04:29:38.564440  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 04:29:38.564446  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523071 (* 1 = 0.0523071 loss)
I0627 04:29:38.564450  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.131624 (* 1 = 0.131624 loss)
I0627 04:29:38.564455  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000982621 (* 1 = 0.000982621 loss)
I0627 04:29:38.564458  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00948357 (* 1 = 0.00948357 loss)
I0627 04:29:38.564463  4216 sgd_solver.cpp:106] Iteration 27620, lr = 2e-05
I0627 04:31:23.831825  4216 solver.cpp:228] Iteration 27640, loss = 0.0914344
I0627 04:31:23.831852  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:31:23.831859  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0123866 (* 1 = 0.0123866 loss)
I0627 04:31:23.831864  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0633966 (* 1 = 0.0633966 loss)
I0627 04:31:23.831868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000298178 (* 1 = 0.000298178 loss)
I0627 04:31:23.831872  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00202947 (* 1 = 0.00202947 loss)
I0627 04:31:23.831877  4216 sgd_solver.cpp:106] Iteration 27640, lr = 2e-05
I0627 04:33:09.908828  4216 solver.cpp:228] Iteration 27660, loss = 0.104983
I0627 04:33:09.908854  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:33:09.908862  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0136801 (* 1 = 0.0136801 loss)
I0627 04:33:09.908867  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0081103 (* 1 = 0.0081103 loss)
I0627 04:33:09.908871  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000946974 (* 1 = 0.000946974 loss)
I0627 04:33:09.908875  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00332341 (* 1 = 0.00332341 loss)
I0627 04:33:09.908880  4216 sgd_solver.cpp:106] Iteration 27660, lr = 2e-05
I0627 04:34:55.233340  4216 solver.cpp:228] Iteration 27680, loss = 0.225902
I0627 04:34:55.233366  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:34:55.233373  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159257 (* 1 = 0.0159257 loss)
I0627 04:34:55.233377  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0204919 (* 1 = 0.0204919 loss)
I0627 04:34:55.233381  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00814859 (* 1 = 0.00814859 loss)
I0627 04:34:55.233386  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00681699 (* 1 = 0.00681699 loss)
I0627 04:34:55.233391  4216 sgd_solver.cpp:106] Iteration 27680, lr = 2e-05
I0627 04:36:40.412267  4216 solver.cpp:228] Iteration 27700, loss = 0.106512
I0627 04:36:40.412292  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 04:36:40.412300  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291537 (* 1 = 0.0291537 loss)
I0627 04:36:40.412304  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0750218 (* 1 = 0.0750218 loss)
I0627 04:36:40.412308  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215081 (* 1 = 0.00215081 loss)
I0627 04:36:40.412312  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00766797 (* 1 = 0.00766797 loss)
I0627 04:36:40.412317  4216 sgd_solver.cpp:106] Iteration 27700, lr = 2e-05
I0627 04:38:25.844185  4216 solver.cpp:228] Iteration 27720, loss = 0.145552
I0627 04:38:25.844211  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 04:38:25.844219  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523112 (* 1 = 0.0523112 loss)
I0627 04:38:25.844224  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.127834 (* 1 = 0.127834 loss)
I0627 04:38:25.844228  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00055743 (* 1 = 0.00055743 loss)
I0627 04:38:25.844233  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353324 (* 1 = 0.0353324 loss)
I0627 04:38:25.844238  4216 sgd_solver.cpp:106] Iteration 27720, lr = 2e-05
I0627 04:40:11.072492  4216 solver.cpp:228] Iteration 27740, loss = 0.207619
I0627 04:40:11.072523  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:40:11.072531  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.059103 (* 1 = 0.059103 loss)
I0627 04:40:11.072535  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.062033 (* 1 = 0.062033 loss)
I0627 04:40:11.072540  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113974 (* 1 = 0.00113974 loss)
I0627 04:40:11.072542  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274345 (* 1 = 0.0274345 loss)
I0627 04:40:11.072548  4216 sgd_solver.cpp:106] Iteration 27740, lr = 2e-05
I0627 04:41:56.322638  4216 solver.cpp:228] Iteration 27760, loss = 0.217945
I0627 04:41:56.322662  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:41:56.322669  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0352373 (* 1 = 0.0352373 loss)
I0627 04:41:56.322674  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0395637 (* 1 = 0.0395637 loss)
I0627 04:41:56.322677  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00787682 (* 1 = 0.00787682 loss)
I0627 04:41:56.322681  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151976 (* 1 = 0.0151976 loss)
I0627 04:41:56.322685  4216 sgd_solver.cpp:106] Iteration 27760, lr = 2e-05
I0627 04:43:41.512770  4216 solver.cpp:228] Iteration 27780, loss = 0.241347
I0627 04:43:41.512794  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 04:43:41.512802  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00913219 (* 1 = 0.00913219 loss)
I0627 04:43:41.512806  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.051017 (* 1 = 0.051017 loss)
I0627 04:43:41.512810  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000334172 (* 1 = 0.000334172 loss)
I0627 04:43:41.512814  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00354824 (* 1 = 0.00354824 loss)
I0627 04:43:41.512818  4216 sgd_solver.cpp:106] Iteration 27780, lr = 2e-05
speed: 5.286s / iter
I0627 04:45:26.744808  4216 solver.cpp:228] Iteration 27800, loss = 0.215311
I0627 04:45:26.744833  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0627 04:45:26.744841  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.275875 (* 1 = 0.275875 loss)
I0627 04:45:26.744846  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.411179 (* 1 = 0.411179 loss)
I0627 04:45:26.744850  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255348 (* 1 = 0.0255348 loss)
I0627 04:45:26.744853  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118544 (* 1 = 0.118544 loss)
I0627 04:45:26.744858  4216 sgd_solver.cpp:106] Iteration 27800, lr = 2e-05
I0627 04:47:12.030942  4216 solver.cpp:228] Iteration 27820, loss = 0.115516
I0627 04:47:12.030969  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 04:47:12.030977  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0366055 (* 1 = 0.0366055 loss)
I0627 04:47:12.030982  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.105605 (* 1 = 0.105605 loss)
I0627 04:47:12.030987  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000867599 (* 1 = 0.000867599 loss)
I0627 04:47:12.030992  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128094 (* 1 = 0.0128094 loss)
I0627 04:47:12.030997  4216 sgd_solver.cpp:106] Iteration 27820, lr = 2e-05
I0627 04:48:57.276041  4216 solver.cpp:228] Iteration 27840, loss = 0.228784
I0627 04:48:57.276068  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:48:57.276077  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0239423 (* 1 = 0.0239423 loss)
I0627 04:48:57.276080  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0226682 (* 1 = 0.0226682 loss)
I0627 04:48:57.276084  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120217 (* 1 = 0.0120217 loss)
I0627 04:48:57.276088  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00557156 (* 1 = 0.00557156 loss)
I0627 04:48:57.276094  4216 sgd_solver.cpp:106] Iteration 27840, lr = 2e-05
I0627 04:50:42.464241  4216 solver.cpp:228] Iteration 27860, loss = 0.10458
I0627 04:50:42.464268  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 04:50:42.464277  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613349 (* 1 = 0.0613349 loss)
I0627 04:50:42.464282  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.11028 (* 1 = 0.11028 loss)
I0627 04:50:42.464285  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000185786 (* 1 = 0.000185786 loss)
I0627 04:50:42.464289  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00681741 (* 1 = 0.00681741 loss)
I0627 04:50:42.464294  4216 sgd_solver.cpp:106] Iteration 27860, lr = 2e-05
I0627 04:52:27.763392  4216 solver.cpp:228] Iteration 27880, loss = 0.108236
I0627 04:52:27.763417  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 04:52:27.763425  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.028854 (* 1 = 0.028854 loss)
I0627 04:52:27.763429  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0700841 (* 1 = 0.0700841 loss)
I0627 04:52:27.763434  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00153176 (* 1 = 0.00153176 loss)
I0627 04:52:27.763438  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00401277 (* 1 = 0.00401277 loss)
I0627 04:52:27.763443  4216 sgd_solver.cpp:106] Iteration 27880, lr = 2e-05
I0627 04:54:13.317932  4216 solver.cpp:228] Iteration 27900, loss = 0.0832502
I0627 04:54:13.317956  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:54:13.317963  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339468 (* 1 = 0.0339468 loss)
I0627 04:54:13.317967  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0170379 (* 1 = 0.0170379 loss)
I0627 04:54:13.317971  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133982 (* 1 = 0.00133982 loss)
I0627 04:54:13.317975  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00214372 (* 1 = 0.00214372 loss)
I0627 04:54:13.317979  4216 sgd_solver.cpp:106] Iteration 27900, lr = 2e-05
I0627 04:55:58.943541  4216 solver.cpp:228] Iteration 27920, loss = 0.139229
I0627 04:55:58.943565  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 04:55:58.943572  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0598206 (* 1 = 0.0598206 loss)
I0627 04:55:58.943576  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.116521 (* 1 = 0.116521 loss)
I0627 04:55:58.943580  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0024769 (* 1 = 0.0024769 loss)
I0627 04:55:58.943584  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305519 (* 1 = 0.0305519 loss)
I0627 04:55:58.943588  4216 sgd_solver.cpp:106] Iteration 27920, lr = 2e-05
I0627 04:57:44.487226  4216 solver.cpp:228] Iteration 27940, loss = 0.15434
I0627 04:57:44.487255  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:57:44.487264  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168708 (* 1 = 0.0168708 loss)
I0627 04:57:44.487270  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0260861 (* 1 = 0.0260861 loss)
I0627 04:57:44.487274  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000148825 (* 1 = 0.000148825 loss)
I0627 04:57:44.487279  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00325072 (* 1 = 0.00325072 loss)
I0627 04:57:44.487285  4216 sgd_solver.cpp:106] Iteration 27940, lr = 2e-05
I0627 04:59:29.847728  4216 solver.cpp:228] Iteration 27960, loss = 0.116038
I0627 04:59:29.847753  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0627 04:59:29.847759  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.102546 (* 1 = 0.102546 loss)
I0627 04:59:29.847764  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.197071 (* 1 = 0.197071 loss)
I0627 04:59:29.847769  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138431 (* 1 = 0.0138431 loss)
I0627 04:59:29.847772  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153111 (* 1 = 0.0153111 loss)
I0627 04:59:29.847777  4216 sgd_solver.cpp:106] Iteration 27960, lr = 2e-05
I0627 05:01:15.403264  4216 solver.cpp:228] Iteration 27980, loss = 0.143778
I0627 05:01:15.403288  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:01:15.403295  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.105538 (* 1 = 0.105538 loss)
I0627 05:01:15.403301  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.03662 (* 1 = 0.03662 loss)
I0627 05:01:15.403304  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315729 (* 1 = 0.00315729 loss)
I0627 05:01:15.403308  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218083 (* 1 = 0.0218083 loss)
I0627 05:01:15.403313  4216 sgd_solver.cpp:106] Iteration 27980, lr = 2e-05
speed: 5.286s / iter
I0627 05:03:01.464082  4216 solver.cpp:228] Iteration 28000, loss = 0.346222
I0627 05:03:01.464108  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:03:01.464116  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0100547 (* 1 = 0.0100547 loss)
I0627 05:03:01.464120  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0252959 (* 1 = 0.0252959 loss)
I0627 05:03:01.464124  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0099001 (* 1 = 0.0099001 loss)
I0627 05:03:01.464129  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017242 (* 1 = 0.017242 loss)
I0627 05:03:01.464134  4216 sgd_solver.cpp:106] Iteration 28000, lr = 2e-05
I0627 05:04:47.162936  4216 solver.cpp:228] Iteration 28020, loss = 0.20145
I0627 05:04:47.162966  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:04:47.162973  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00360993 (* 1 = 0.00360993 loss)
I0627 05:04:47.162979  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0151968 (* 1 = 0.0151968 loss)
I0627 05:04:47.162983  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351557 (* 1 = 0.00351557 loss)
I0627 05:04:47.162988  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0041952 (* 1 = 0.0041952 loss)
I0627 05:04:47.162994  4216 sgd_solver.cpp:106] Iteration 28020, lr = 2e-05
I0627 05:06:32.699681  4216 solver.cpp:228] Iteration 28040, loss = 0.0735515
I0627 05:06:32.699707  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:06:32.699714  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00994364 (* 1 = 0.00994364 loss)
I0627 05:06:32.699719  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0222969 (* 1 = 0.0222969 loss)
I0627 05:06:32.699723  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0002137 (* 1 = 0.0002137 loss)
I0627 05:06:32.699728  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114105 (* 1 = 0.0114105 loss)
I0627 05:06:32.699733  4216 sgd_solver.cpp:106] Iteration 28040, lr = 2e-05
I0627 05:08:18.081935  4216 solver.cpp:228] Iteration 28060, loss = 0.132298
I0627 05:08:18.081961  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:08:18.081969  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205673 (* 1 = 0.0205673 loss)
I0627 05:08:18.081974  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0203728 (* 1 = 0.0203728 loss)
I0627 05:08:18.081979  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000667806 (* 1 = 0.000667806 loss)
I0627 05:08:18.081984  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00608166 (* 1 = 0.00608166 loss)
I0627 05:08:18.081990  4216 sgd_solver.cpp:106] Iteration 28060, lr = 2e-05
I0627 05:10:03.511775  4216 solver.cpp:228] Iteration 28080, loss = 0.202179
I0627 05:10:03.511804  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:10:03.511812  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188553 (* 1 = 0.0188553 loss)
I0627 05:10:03.511816  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0168084 (* 1 = 0.0168084 loss)
I0627 05:10:03.511819  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129086 (* 1 = 0.0129086 loss)
I0627 05:10:03.511823  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193152 (* 1 = 0.0193152 loss)
I0627 05:10:03.511828  4216 sgd_solver.cpp:106] Iteration 28080, lr = 2e-05
I0627 05:11:48.955965  4216 solver.cpp:228] Iteration 28100, loss = 0.110645
I0627 05:11:48.955992  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:11:48.956002  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198156 (* 1 = 0.0198156 loss)
I0627 05:11:48.956009  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0181267 (* 1 = 0.0181267 loss)
I0627 05:11:48.956015  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000275008 (* 1 = 0.000275008 loss)
I0627 05:11:48.956022  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00354189 (* 1 = 0.00354189 loss)
I0627 05:11:48.956030  4216 sgd_solver.cpp:106] Iteration 28100, lr = 2e-05
I0627 05:13:34.367060  4216 solver.cpp:228] Iteration 28120, loss = 0.104508
I0627 05:13:34.367086  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 05:13:34.367096  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00795292 (* 1 = 0.00795292 loss)
I0627 05:13:34.367105  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0508647 (* 1 = 0.0508647 loss)
I0627 05:13:34.367110  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000358843 (* 1 = 0.000358843 loss)
I0627 05:13:34.367116  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512259 (* 1 = 0.00512259 loss)
I0627 05:13:34.367125  4216 sgd_solver.cpp:106] Iteration 28120, lr = 2e-05
I0627 05:15:19.711637  4216 solver.cpp:228] Iteration 28140, loss = 0.136857
I0627 05:15:19.711661  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:15:19.711670  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0503704 (* 1 = 0.0503704 loss)
I0627 05:15:19.711675  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118802 (* 1 = 0.118802 loss)
I0627 05:15:19.711680  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00521163 (* 1 = 0.00521163 loss)
I0627 05:15:19.711684  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307895 (* 1 = 0.0307895 loss)
I0627 05:15:19.711690  4216 sgd_solver.cpp:106] Iteration 28140, lr = 2e-05
I0627 05:17:05.194830  4216 solver.cpp:228] Iteration 28160, loss = 0.135574
I0627 05:17:05.194855  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:17:05.194866  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739664 (* 1 = 0.0739664 loss)
I0627 05:17:05.194871  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.133439 (* 1 = 0.133439 loss)
I0627 05:17:05.194875  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00655832 (* 1 = 0.00655832 loss)
I0627 05:17:05.194880  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0366873 (* 1 = 0.0366873 loss)
I0627 05:17:05.194885  4216 sgd_solver.cpp:106] Iteration 28160, lr = 2e-05
I0627 05:18:50.500043  4216 solver.cpp:228] Iteration 28180, loss = 0.168358
I0627 05:18:50.500068  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:18:50.500075  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00703665 (* 1 = 0.00703665 loss)
I0627 05:18:50.500079  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0450805 (* 1 = 0.0450805 loss)
I0627 05:18:50.500083  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360589 (* 1 = 0.00360589 loss)
I0627 05:18:50.500087  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00737236 (* 1 = 0.00737236 loss)
I0627 05:18:50.500092  4216 sgd_solver.cpp:106] Iteration 28180, lr = 2e-05
speed: 5.286s / iter
I0627 05:20:35.838518  4216 solver.cpp:228] Iteration 28200, loss = 0.171929
I0627 05:20:35.838543  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:20:35.838551  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170085 (* 1 = 0.0170085 loss)
I0627 05:20:35.838555  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0371584 (* 1 = 0.0371584 loss)
I0627 05:20:35.838559  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00912034 (* 1 = 0.00912034 loss)
I0627 05:20:35.838564  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00119338 (* 1 = 0.00119338 loss)
I0627 05:20:35.838569  4216 sgd_solver.cpp:106] Iteration 28200, lr = 2e-05
I0627 05:22:21.162421  4216 solver.cpp:228] Iteration 28220, loss = 0.161864
I0627 05:22:21.162447  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0627 05:22:21.162456  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.236606 (* 1 = 0.236606 loss)
I0627 05:22:21.162459  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.238832 (* 1 = 0.238832 loss)
I0627 05:22:21.162464  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147949 (* 1 = 0.0147949 loss)
I0627 05:22:21.162468  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419475 (* 1 = 0.0419475 loss)
I0627 05:22:21.162473  4216 sgd_solver.cpp:106] Iteration 28220, lr = 2e-05
I0627 05:24:06.395576  4216 solver.cpp:228] Iteration 28240, loss = 0.298286
I0627 05:24:06.395601  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:24:06.395608  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128421 (* 1 = 0.0128421 loss)
I0627 05:24:06.395613  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0205236 (* 1 = 0.0205236 loss)
I0627 05:24:06.395617  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184998 (* 1 = 0.00184998 loss)
I0627 05:24:06.395622  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00802092 (* 1 = 0.00802092 loss)
I0627 05:24:06.395627  4216 sgd_solver.cpp:106] Iteration 28240, lr = 2e-05
I0627 05:25:51.707326  4216 solver.cpp:228] Iteration 28260, loss = 0.18007
I0627 05:25:51.707355  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:25:51.707365  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00507322 (* 1 = 0.00507322 loss)
I0627 05:25:51.707370  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0222196 (* 1 = 0.0222196 loss)
I0627 05:25:51.707375  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00219404 (* 1 = 0.00219404 loss)
I0627 05:25:51.707378  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00695788 (* 1 = 0.00695788 loss)
I0627 05:25:51.707384  4216 sgd_solver.cpp:106] Iteration 28260, lr = 2e-05
I0627 05:27:37.233541  4216 solver.cpp:228] Iteration 28280, loss = 0.140046
I0627 05:27:37.233568  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:27:37.233575  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318933 (* 1 = 0.0318933 loss)
I0627 05:27:37.233579  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0877516 (* 1 = 0.0877516 loss)
I0627 05:27:37.233583  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000750993 (* 1 = 0.000750993 loss)
I0627 05:27:37.233587  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143934 (* 1 = 0.0143934 loss)
I0627 05:27:37.233592  4216 sgd_solver.cpp:106] Iteration 28280, lr = 2e-05
I0627 05:29:22.604406  4216 solver.cpp:228] Iteration 28300, loss = 0.210771
I0627 05:29:22.604434  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 05:29:22.604440  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.141167 (* 1 = 0.141167 loss)
I0627 05:29:22.604444  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.193678 (* 1 = 0.193678 loss)
I0627 05:29:22.604449  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00777651 (* 1 = 0.00777651 loss)
I0627 05:29:22.604451  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024965 (* 1 = 0.024965 loss)
I0627 05:29:22.604456  4216 sgd_solver.cpp:106] Iteration 28300, lr = 2e-05
I0627 05:31:07.848724  4216 solver.cpp:228] Iteration 28320, loss = 0.307512
I0627 05:31:07.848749  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:31:07.848757  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.054647 (* 1 = 0.054647 loss)
I0627 05:31:07.848762  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0315841 (* 1 = 0.0315841 loss)
I0627 05:31:07.848765  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000595534 (* 1 = 0.000595534 loss)
I0627 05:31:07.848768  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00905164 (* 1 = 0.00905164 loss)
I0627 05:31:07.848773  4216 sgd_solver.cpp:106] Iteration 28320, lr = 2e-05
I0627 05:32:53.083078  4216 solver.cpp:228] Iteration 28340, loss = 0.227686
I0627 05:32:53.083107  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:32:53.083117  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00919983 (* 1 = 0.00919983 loss)
I0627 05:32:53.083124  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00445595 (* 1 = 0.00445595 loss)
I0627 05:32:53.083132  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115625 (* 1 = 0.0115625 loss)
I0627 05:32:53.083137  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00632305 (* 1 = 0.00632305 loss)
I0627 05:32:53.083145  4216 sgd_solver.cpp:106] Iteration 28340, lr = 2e-05
I0627 05:34:38.498457  4216 solver.cpp:228] Iteration 28360, loss = 0.195188
I0627 05:34:38.498484  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 05:34:38.498494  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.056552 (* 1 = 0.056552 loss)
I0627 05:34:38.498502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0767754 (* 1 = 0.0767754 loss)
I0627 05:34:38.498508  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000337108 (* 1 = 0.000337108 loss)
I0627 05:34:38.498515  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00680978 (* 1 = 0.00680978 loss)
I0627 05:34:38.498522  4216 sgd_solver.cpp:106] Iteration 28360, lr = 2e-05
I0627 05:36:26.829974  4216 solver.cpp:228] Iteration 28380, loss = 0.163756
I0627 05:36:26.829998  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 05:36:26.830006  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147643 (* 1 = 0.0147643 loss)
I0627 05:36:26.830010  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.057428 (* 1 = 0.057428 loss)
I0627 05:36:26.830013  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0500585 (* 1 = 0.0500585 loss)
I0627 05:36:26.830018  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125496 (* 1 = 0.125496 loss)
I0627 05:36:26.830021  4216 sgd_solver.cpp:106] Iteration 28380, lr = 2e-05
speed: 5.286s / iter
I0627 05:38:12.063714  4216 solver.cpp:228] Iteration 28400, loss = 0.143576
I0627 05:38:12.063740  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:38:12.063747  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0617593 (* 1 = 0.0617593 loss)
I0627 05:38:12.063751  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.114876 (* 1 = 0.114876 loss)
I0627 05:38:12.063755  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00427289 (* 1 = 0.00427289 loss)
I0627 05:38:12.063758  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177555 (* 1 = 0.0177555 loss)
I0627 05:38:12.063763  4216 sgd_solver.cpp:106] Iteration 28400, lr = 2e-05
I0627 05:39:57.353173  4216 solver.cpp:228] Iteration 28420, loss = 0.163504
I0627 05:39:57.353197  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 05:39:57.353206  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649238 (* 1 = 0.0649238 loss)
I0627 05:39:57.353210  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0758259 (* 1 = 0.0758259 loss)
I0627 05:39:57.353215  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167813 (* 1 = 0.00167813 loss)
I0627 05:39:57.353219  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940524 (* 1 = 0.00940524 loss)
I0627 05:39:57.353224  4216 sgd_solver.cpp:106] Iteration 28420, lr = 2e-05
I0627 05:41:42.936336  4216 solver.cpp:228] Iteration 28440, loss = 0.261206
I0627 05:41:42.936367  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 05:41:42.936378  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.151014 (* 1 = 0.151014 loss)
I0627 05:41:42.936383  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.1567 (* 1 = 0.1567 loss)
I0627 05:41:42.936388  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00443515 (* 1 = 0.00443515 loss)
I0627 05:41:42.936394  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132918 (* 1 = 0.0132918 loss)
I0627 05:41:42.936400  4216 sgd_solver.cpp:106] Iteration 28440, lr = 2e-05
I0627 05:43:28.996951  4216 solver.cpp:228] Iteration 28460, loss = 0.144688
I0627 05:43:28.996982  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 05:43:28.996989  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817231 (* 1 = 0.0817231 loss)
I0627 05:43:28.996994  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.134055 (* 1 = 0.134055 loss)
I0627 05:43:28.996999  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000396902 (* 1 = 0.000396902 loss)
I0627 05:43:28.997002  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250709 (* 1 = 0.0250709 loss)
I0627 05:43:28.997009  4216 sgd_solver.cpp:106] Iteration 28460, lr = 2e-05
I0627 05:45:14.548044  4216 solver.cpp:228] Iteration 28480, loss = 0.26401
I0627 05:45:14.548071  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0627 05:45:14.548079  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.477761 (* 1 = 0.477761 loss)
I0627 05:45:14.548082  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.532304 (* 1 = 0.532304 loss)
I0627 05:45:14.548086  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0471669 (* 1 = 0.0471669 loss)
I0627 05:45:14.548089  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153894 (* 1 = 0.153894 loss)
I0627 05:45:14.548095  4216 sgd_solver.cpp:106] Iteration 28480, lr = 2e-05
I0627 05:46:59.980965  4216 solver.cpp:228] Iteration 28500, loss = 0.150367
I0627 05:46:59.980993  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 05:46:59.981003  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0570589 (* 1 = 0.0570589 loss)
I0627 05:46:59.981007  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.133315 (* 1 = 0.133315 loss)
I0627 05:46:59.981011  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385574 (* 1 = 0.00385574 loss)
I0627 05:46:59.981016  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238047 (* 1 = 0.0238047 loss)
I0627 05:46:59.981022  4216 sgd_solver.cpp:106] Iteration 28500, lr = 2e-05
I0627 05:48:45.467831  4216 solver.cpp:228] Iteration 28520, loss = 0.112068
I0627 05:48:45.467854  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:48:45.467861  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.026874 (* 1 = 0.026874 loss)
I0627 05:48:45.467866  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.021255 (* 1 = 0.021255 loss)
I0627 05:48:45.467869  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100579 (* 1 = 0.00100579 loss)
I0627 05:48:45.467873  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.038363 (* 1 = 0.038363 loss)
I0627 05:48:45.467878  4216 sgd_solver.cpp:106] Iteration 28520, lr = 2e-05
I0627 05:50:31.170666  4216 solver.cpp:228] Iteration 28540, loss = 0.0837157
I0627 05:50:31.170693  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:50:31.170703  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0145185 (* 1 = 0.0145185 loss)
I0627 05:50:31.170708  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0241124 (* 1 = 0.0241124 loss)
I0627 05:50:31.170713  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000255924 (* 1 = 0.000255924 loss)
I0627 05:50:31.170718  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00613877 (* 1 = 0.00613877 loss)
I0627 05:50:31.170723  4216 sgd_solver.cpp:106] Iteration 28540, lr = 2e-05
I0627 05:52:16.722286  4216 solver.cpp:228] Iteration 28560, loss = 0.295734
I0627 05:52:16.722318  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 05:52:16.722331  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.106639 (* 1 = 0.106639 loss)
I0627 05:52:16.722339  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.121581 (* 1 = 0.121581 loss)
I0627 05:52:16.722347  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109112 (* 1 = 0.00109112 loss)
I0627 05:52:16.722357  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307377 (* 1 = 0.0307377 loss)
I0627 05:52:16.722367  4216 sgd_solver.cpp:106] Iteration 28560, lr = 2e-05
I0627 05:54:02.251700  4216 solver.cpp:228] Iteration 28580, loss = 0.136775
I0627 05:54:02.251727  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:54:02.251737  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00942487 (* 1 = 0.00942487 loss)
I0627 05:54:02.251744  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0133192 (* 1 = 0.0133192 loss)
I0627 05:54:02.251749  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00565499 (* 1 = 0.00565499 loss)
I0627 05:54:02.251754  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00711624 (* 1 = 0.00711624 loss)
I0627 05:54:02.251760  4216 sgd_solver.cpp:106] Iteration 28580, lr = 2e-05
speed: 5.286s / iter
I0627 05:55:48.117964  4216 solver.cpp:228] Iteration 28600, loss = 0.182074
I0627 05:55:48.117991  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:55:48.118000  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107689 (* 1 = 0.0107689 loss)
I0627 05:55:48.118006  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.028232 (* 1 = 0.028232 loss)
I0627 05:55:48.118011  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000410262 (* 1 = 0.000410262 loss)
I0627 05:55:48.118016  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00289767 (* 1 = 0.00289767 loss)
I0627 05:55:48.118021  4216 sgd_solver.cpp:106] Iteration 28600, lr = 2e-05
I0627 05:57:33.605885  4216 solver.cpp:228] Iteration 28620, loss = 0.213169
I0627 05:57:33.605912  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:57:33.605921  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.013619 (* 1 = 0.013619 loss)
I0627 05:57:33.605927  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00704221 (* 1 = 0.00704221 loss)
I0627 05:57:33.605933  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000456462 (* 1 = 0.000456462 loss)
I0627 05:57:33.605939  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00192565 (* 1 = 0.00192565 loss)
I0627 05:57:33.605948  4216 sgd_solver.cpp:106] Iteration 28620, lr = 2e-05
I0627 05:59:19.094058  4216 solver.cpp:228] Iteration 28640, loss = 0.180854
I0627 05:59:19.094082  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 05:59:19.094090  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0538129 (* 1 = 0.0538129 loss)
I0627 05:59:19.094094  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.12741 (* 1 = 0.12741 loss)
I0627 05:59:19.094099  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0094066 (* 1 = 0.0094066 loss)
I0627 05:59:19.094102  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0807162 (* 1 = 0.0807162 loss)
I0627 05:59:19.094107  4216 sgd_solver.cpp:106] Iteration 28640, lr = 2e-05
I0627 06:01:04.423835  4216 solver.cpp:228] Iteration 28660, loss = 0.110485
I0627 06:01:04.423859  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:01:04.423867  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00899663 (* 1 = 0.00899663 loss)
I0627 06:01:04.423871  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0521616 (* 1 = 0.0521616 loss)
I0627 06:01:04.423876  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232923 (* 1 = 0.00232923 loss)
I0627 06:01:04.423878  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0029415 (* 1 = 0.0029415 loss)
I0627 06:01:04.423883  4216 sgd_solver.cpp:106] Iteration 28660, lr = 2e-05
I0627 06:02:49.647121  4216 solver.cpp:228] Iteration 28680, loss = 0.165361
I0627 06:02:49.647145  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 06:02:49.647153  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.146809 (* 1 = 0.146809 loss)
I0627 06:02:49.647157  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.197884 (* 1 = 0.197884 loss)
I0627 06:02:49.647161  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00663472 (* 1 = 0.00663472 loss)
I0627 06:02:49.647164  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368335 (* 1 = 0.0368335 loss)
I0627 06:02:49.647169  4216 sgd_solver.cpp:106] Iteration 28680, lr = 2e-05
I0627 06:04:34.806383  4216 solver.cpp:228] Iteration 28700, loss = 0.11413
I0627 06:04:34.806407  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 06:04:34.806417  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284824 (* 1 = 0.0284824 loss)
I0627 06:04:34.806424  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0712408 (* 1 = 0.0712408 loss)
I0627 06:04:34.806430  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000176906 (* 1 = 0.000176906 loss)
I0627 06:04:34.806437  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00860585 (* 1 = 0.00860585 loss)
I0627 06:04:34.806443  4216 sgd_solver.cpp:106] Iteration 28700, lr = 2e-05
I0627 06:06:19.958115  4216 solver.cpp:228] Iteration 28720, loss = 0.139948
I0627 06:06:19.958145  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:06:19.958154  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179957 (* 1 = 0.0179957 loss)
I0627 06:06:19.958158  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0643745 (* 1 = 0.0643745 loss)
I0627 06:06:19.958163  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000434467 (* 1 = 0.000434467 loss)
I0627 06:06:19.958168  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00937052 (* 1 = 0.00937052 loss)
I0627 06:06:19.958173  4216 sgd_solver.cpp:106] Iteration 28720, lr = 2e-05
I0627 06:08:05.126904  4216 solver.cpp:228] Iteration 28740, loss = 0.101637
I0627 06:08:05.126929  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:08:05.126936  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00130778 (* 1 = 0.00130778 loss)
I0627 06:08:05.126941  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.016358 (* 1 = 0.016358 loss)
I0627 06:08:05.126945  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000513224 (* 1 = 0.000513224 loss)
I0627 06:08:05.126950  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00832896 (* 1 = 0.00832896 loss)
I0627 06:08:05.126956  4216 sgd_solver.cpp:106] Iteration 28740, lr = 2e-05
I0627 06:09:50.318477  4216 solver.cpp:228] Iteration 28760, loss = 0.221676
I0627 06:09:50.318502  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 06:09:50.318511  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.090051 (* 1 = 0.090051 loss)
I0627 06:09:50.318516  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.18891 (* 1 = 0.18891 loss)
I0627 06:09:50.318519  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000410932 (* 1 = 0.000410932 loss)
I0627 06:09:50.318523  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331035 (* 1 = 0.0331035 loss)
I0627 06:09:50.318528  4216 sgd_solver.cpp:106] Iteration 28760, lr = 2e-05
I0627 06:11:35.508517  4216 solver.cpp:228] Iteration 28780, loss = 0.246645
I0627 06:11:35.508540  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 06:11:35.508548  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.142825 (* 1 = 0.142825 loss)
I0627 06:11:35.508551  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.197817 (* 1 = 0.197817 loss)
I0627 06:11:35.508555  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00112318 (* 1 = 0.00112318 loss)
I0627 06:11:35.508559  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298897 (* 1 = 0.0298897 loss)
I0627 06:11:35.508563  4216 sgd_solver.cpp:106] Iteration 28780, lr = 2e-05
speed: 5.286s / iter
I0627 06:13:20.680025  4216 solver.cpp:228] Iteration 28800, loss = 0.140856
I0627 06:13:20.680052  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 06:13:20.680058  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613848 (* 1 = 0.0613848 loss)
I0627 06:13:20.680063  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.154157 (* 1 = 0.154157 loss)
I0627 06:13:20.680066  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00517478 (* 1 = 0.00517478 loss)
I0627 06:13:20.680069  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182954 (* 1 = 0.0182954 loss)
I0627 06:13:20.680074  4216 sgd_solver.cpp:106] Iteration 28800, lr = 2e-05
I0627 06:15:05.841104  4216 solver.cpp:228] Iteration 28820, loss = 0.179336
I0627 06:15:05.841135  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:15:05.841145  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0342615 (* 1 = 0.0342615 loss)
I0627 06:15:05.841148  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0464272 (* 1 = 0.0464272 loss)
I0627 06:15:05.841152  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122614 (* 1 = 0.00122614 loss)
I0627 06:15:05.841156  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00715784 (* 1 = 0.00715784 loss)
I0627 06:15:05.841161  4216 sgd_solver.cpp:106] Iteration 28820, lr = 2e-05
I0627 06:16:50.981633  4216 solver.cpp:228] Iteration 28840, loss = 0.177162
I0627 06:16:50.981657  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 06:16:50.981664  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0866917 (* 1 = 0.0866917 loss)
I0627 06:16:50.981668  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.11974 (* 1 = 0.11974 loss)
I0627 06:16:50.981673  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0415315 (* 1 = 0.0415315 loss)
I0627 06:16:50.981675  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0860711 (* 1 = 0.0860711 loss)
I0627 06:16:50.981680  4216 sgd_solver.cpp:106] Iteration 28840, lr = 2e-05
I0627 06:18:36.168951  4216 solver.cpp:228] Iteration 28860, loss = 0.224785
I0627 06:18:36.168980  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0627 06:18:36.168990  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.196199 (* 1 = 0.196199 loss)
I0627 06:18:36.168995  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.252737 (* 1 = 0.252737 loss)
I0627 06:18:36.169001  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145429 (* 1 = 0.0145429 loss)
I0627 06:18:36.169006  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0719395 (* 1 = 0.0719395 loss)
I0627 06:18:36.169013  4216 sgd_solver.cpp:106] Iteration 28860, lr = 2e-05
I0627 06:20:21.329149  4216 solver.cpp:228] Iteration 28880, loss = 0.168082
I0627 06:20:21.329176  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:20:21.329185  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0302305 (* 1 = 0.0302305 loss)
I0627 06:20:21.329190  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.046979 (* 1 = 0.046979 loss)
I0627 06:20:21.329193  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00748205 (* 1 = 0.00748205 loss)
I0627 06:20:21.329197  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683126 (* 1 = 0.0683126 loss)
I0627 06:20:21.329202  4216 sgd_solver.cpp:106] Iteration 28880, lr = 2e-05
I0627 06:22:06.515059  4216 solver.cpp:228] Iteration 28900, loss = 0.15195
I0627 06:22:06.515090  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 06:22:06.515102  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.118121 (* 1 = 0.118121 loss)
I0627 06:22:06.515110  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.177251 (* 1 = 0.177251 loss)
I0627 06:22:06.515116  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000648494 (* 1 = 0.000648494 loss)
I0627 06:22:06.515123  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408846 (* 1 = 0.0408846 loss)
I0627 06:22:06.515131  4216 sgd_solver.cpp:106] Iteration 28900, lr = 2e-05
I0627 06:23:51.674407  4216 solver.cpp:228] Iteration 28920, loss = 0.17056
I0627 06:23:51.674444  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:23:51.674454  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169516 (* 1 = 0.0169516 loss)
I0627 06:23:51.674461  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0810657 (* 1 = 0.0810657 loss)
I0627 06:23:51.674465  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0207638 (* 1 = 0.0207638 loss)
I0627 06:23:51.674469  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0754713 (* 1 = 0.0754713 loss)
I0627 06:23:51.674477  4216 sgd_solver.cpp:106] Iteration 28920, lr = 2e-05
I0627 06:25:36.836545  4216 solver.cpp:228] Iteration 28940, loss = 0.240629
I0627 06:25:36.836570  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 06:25:36.836577  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.101079 (* 1 = 0.101079 loss)
I0627 06:25:36.836582  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.150595 (* 1 = 0.150595 loss)
I0627 06:25:36.836586  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108837 (* 1 = 0.00108837 loss)
I0627 06:25:36.836591  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0407717 (* 1 = 0.0407717 loss)
I0627 06:25:36.836596  4216 sgd_solver.cpp:106] Iteration 28940, lr = 2e-05
I0627 06:27:22.009444  4216 solver.cpp:228] Iteration 28960, loss = 0.274469
I0627 06:27:22.009470  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 06:27:22.009477  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363677 (* 1 = 0.0363677 loss)
I0627 06:27:22.009482  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0758312 (* 1 = 0.0758312 loss)
I0627 06:27:22.009486  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351424 (* 1 = 0.00351424 loss)
I0627 06:27:22.009490  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102771 (* 1 = 0.0102771 loss)
I0627 06:27:22.009496  4216 sgd_solver.cpp:106] Iteration 28960, lr = 2e-05
I0627 06:29:07.169096  4216 solver.cpp:228] Iteration 28980, loss = 0.21147
I0627 06:29:07.169124  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0627 06:29:07.169137  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.292426 (* 1 = 0.292426 loss)
I0627 06:29:07.169142  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.365022 (* 1 = 0.365022 loss)
I0627 06:29:07.169148  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0058847 (* 1 = 0.0058847 loss)
I0627 06:29:07.169155  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0708551 (* 1 = 0.0708551 loss)
I0627 06:29:07.169162  4216 sgd_solver.cpp:106] Iteration 28980, lr = 2e-05
speed: 5.285s / iter
I0627 06:30:52.354490  4216 solver.cpp:228] Iteration 29000, loss = 0.18118
I0627 06:30:52.354513  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:30:52.354521  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106636 (* 1 = 0.0106636 loss)
I0627 06:30:52.354524  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0109599 (* 1 = 0.0109599 loss)
I0627 06:30:52.354528  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000926422 (* 1 = 0.000926422 loss)
I0627 06:30:52.354532  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00413122 (* 1 = 0.00413122 loss)
I0627 06:30:52.354537  4216 sgd_solver.cpp:106] Iteration 29000, lr = 2e-05
I0627 06:32:37.516345  4216 solver.cpp:228] Iteration 29020, loss = 0.242661
I0627 06:32:37.516371  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:32:37.516376  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0620472 (* 1 = 0.0620472 loss)
I0627 06:32:37.516381  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.078388 (* 1 = 0.078388 loss)
I0627 06:32:37.516384  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000857079 (* 1 = 0.000857079 loss)
I0627 06:32:37.516388  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154622 (* 1 = 0.0154622 loss)
I0627 06:32:37.516392  4216 sgd_solver.cpp:106] Iteration 29020, lr = 2e-05
I0627 06:34:22.658885  4216 solver.cpp:228] Iteration 29040, loss = 0.145502
I0627 06:34:22.658910  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:34:22.658921  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0146811 (* 1 = 0.0146811 loss)
I0627 06:34:22.658926  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0485745 (* 1 = 0.0485745 loss)
I0627 06:34:22.658932  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000358672 (* 1 = 0.000358672 loss)
I0627 06:34:22.658938  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00479708 (* 1 = 0.00479708 loss)
I0627 06:34:22.658946  4216 sgd_solver.cpp:106] Iteration 29040, lr = 2e-05
I0627 06:36:07.855113  4216 solver.cpp:228] Iteration 29060, loss = 0.196018
I0627 06:36:07.855139  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:36:07.855146  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0253452 (* 1 = 0.0253452 loss)
I0627 06:36:07.855152  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0250693 (* 1 = 0.0250693 loss)
I0627 06:36:07.855156  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00554269 (* 1 = 0.00554269 loss)
I0627 06:36:07.855161  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022735 (* 1 = 0.022735 loss)
I0627 06:36:07.855167  4216 sgd_solver.cpp:106] Iteration 29060, lr = 2e-05
I0627 06:37:52.990178  4216 solver.cpp:228] Iteration 29080, loss = 0.182359
I0627 06:37:52.990219  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0627 06:37:52.990227  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.144313 (* 1 = 0.144313 loss)
I0627 06:37:52.990232  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.287988 (* 1 = 0.287988 loss)
I0627 06:37:52.990236  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00402266 (* 1 = 0.00402266 loss)
I0627 06:37:52.990240  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.04454 (* 1 = 0.04454 loss)
I0627 06:37:52.990249  4216 sgd_solver.cpp:106] Iteration 29080, lr = 2e-05
I0627 06:39:38.140089  4216 solver.cpp:228] Iteration 29100, loss = 0.14161
I0627 06:39:38.140115  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 06:39:38.140122  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0907509 (* 1 = 0.0907509 loss)
I0627 06:39:38.140126  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.243045 (* 1 = 0.243045 loss)
I0627 06:39:38.140131  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00409504 (* 1 = 0.00409504 loss)
I0627 06:39:38.140135  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280557 (* 1 = 0.0280557 loss)
I0627 06:39:38.140139  4216 sgd_solver.cpp:106] Iteration 29100, lr = 2e-05
I0627 06:41:23.456902  4216 solver.cpp:228] Iteration 29120, loss = 0.178872
I0627 06:41:23.456925  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:41:23.456933  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0223378 (* 1 = 0.0223378 loss)
I0627 06:41:23.456936  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0351868 (* 1 = 0.0351868 loss)
I0627 06:41:23.456940  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00429345 (* 1 = 0.00429345 loss)
I0627 06:41:23.456943  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00780584 (* 1 = 0.00780584 loss)
I0627 06:41:23.456948  4216 sgd_solver.cpp:106] Iteration 29120, lr = 2e-05
I0627 06:43:08.621358  4216 solver.cpp:228] Iteration 29140, loss = 0.115244
I0627 06:43:08.621383  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:43:08.621392  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.049058 (* 1 = 0.049058 loss)
I0627 06:43:08.621395  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.052559 (* 1 = 0.052559 loss)
I0627 06:43:08.621398  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235657 (* 1 = 0.00235657 loss)
I0627 06:43:08.621402  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134539 (* 1 = 0.0134539 loss)
I0627 06:43:08.621407  4216 sgd_solver.cpp:106] Iteration 29140, lr = 2e-05
I0627 06:44:53.790307  4216 solver.cpp:228] Iteration 29160, loss = 0.123413
I0627 06:44:53.790333  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 06:44:53.790339  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.165848 (* 1 = 0.165848 loss)
I0627 06:44:53.790344  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.214256 (* 1 = 0.214256 loss)
I0627 06:44:53.790349  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00319544 (* 1 = 0.00319544 loss)
I0627 06:44:53.790354  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286331 (* 1 = 0.0286331 loss)
I0627 06:44:53.790359  4216 sgd_solver.cpp:106] Iteration 29160, lr = 2e-05
I0627 06:46:39.000217  4216 solver.cpp:228] Iteration 29180, loss = 0.171733
I0627 06:46:39.000241  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 06:46:39.000248  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473828 (* 1 = 0.0473828 loss)
I0627 06:46:39.000252  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119968 (* 1 = 0.119968 loss)
I0627 06:46:39.000257  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245074 (* 1 = 0.0245074 loss)
I0627 06:46:39.000259  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010821 (* 1 = 0.010821 loss)
I0627 06:46:39.000264  4216 sgd_solver.cpp:106] Iteration 29180, lr = 2e-05
speed: 5.285s / iter
I0627 06:48:24.190531  4216 solver.cpp:228] Iteration 29200, loss = 0.12795
I0627 06:48:24.190569  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 06:48:24.190578  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165902 (* 1 = 0.0165902 loss)
I0627 06:48:24.190583  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0535936 (* 1 = 0.0535936 loss)
I0627 06:48:24.190587  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213357 (* 1 = 0.00213357 loss)
I0627 06:48:24.190593  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00528674 (* 1 = 0.00528674 loss)
I0627 06:48:24.190598  4216 sgd_solver.cpp:106] Iteration 29200, lr = 2e-05
I0627 06:50:09.354629  4216 solver.cpp:228] Iteration 29220, loss = 0.113852
I0627 06:50:09.354651  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:50:09.354658  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000512762 (* 1 = 0.000512762 loss)
I0627 06:50:09.354662  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0147044 (* 1 = 0.0147044 loss)
I0627 06:50:09.354666  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000532581 (* 1 = 0.000532581 loss)
I0627 06:50:09.354671  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00555717 (* 1 = 0.00555717 loss)
I0627 06:50:09.354676  4216 sgd_solver.cpp:106] Iteration 29220, lr = 2e-05
I0627 06:51:54.531716  4216 solver.cpp:228] Iteration 29240, loss = 0.167717
I0627 06:51:54.531741  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0627 06:51:54.531749  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.246112 (* 1 = 0.246112 loss)
I0627 06:51:54.531752  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.255021 (* 1 = 0.255021 loss)
I0627 06:51:54.531756  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292095 (* 1 = 0.00292095 loss)
I0627 06:51:54.531760  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383501 (* 1 = 0.0383501 loss)
I0627 06:51:54.531764  4216 sgd_solver.cpp:106] Iteration 29240, lr = 2e-05
I0627 06:53:39.719702  4216 solver.cpp:228] Iteration 29260, loss = 0.195959
I0627 06:53:39.719727  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 06:53:39.719734  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.020174 (* 1 = 0.020174 loss)
I0627 06:53:39.719738  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.155733 (* 1 = 0.155733 loss)
I0627 06:53:39.719743  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190316 (* 1 = 0.0190316 loss)
I0627 06:53:39.719745  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044909 (* 1 = 0.044909 loss)
I0627 06:53:39.719750  4216 sgd_solver.cpp:106] Iteration 29260, lr = 2e-05
I0627 06:55:24.756850  4216 solver.cpp:228] Iteration 29280, loss = 0.14406
I0627 06:55:24.756873  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:55:24.756880  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.01497 (* 1 = 0.01497 loss)
I0627 06:55:24.756884  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00818078 (* 1 = 0.00818078 loss)
I0627 06:55:24.756888  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294829 (* 1 = 0.00294829 loss)
I0627 06:55:24.756892  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00169386 (* 1 = 0.00169386 loss)
I0627 06:55:24.756897  4216 sgd_solver.cpp:106] Iteration 29280, lr = 2e-05
I0627 06:57:09.939353  4216 solver.cpp:228] Iteration 29300, loss = 0.159723
I0627 06:57:09.939378  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 06:57:09.939386  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.152886 (* 1 = 0.152886 loss)
I0627 06:57:09.939389  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.236935 (* 1 = 0.236935 loss)
I0627 06:57:09.939393  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136428 (* 1 = 0.00136428 loss)
I0627 06:57:09.939397  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0294726 (* 1 = 0.0294726 loss)
I0627 06:57:09.939401  4216 sgd_solver.cpp:106] Iteration 29300, lr = 2e-05
I0627 06:58:55.075089  4216 solver.cpp:228] Iteration 29320, loss = 0.155077
I0627 06:58:55.075114  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:58:55.075120  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0874443 (* 1 = 0.0874443 loss)
I0627 06:58:55.075125  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0660088 (* 1 = 0.0660088 loss)
I0627 06:58:55.075129  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00865653 (* 1 = 0.00865653 loss)
I0627 06:58:55.075132  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0428904 (* 1 = 0.0428904 loss)
I0627 06:58:55.075136  4216 sgd_solver.cpp:106] Iteration 29320, lr = 2e-05
I0627 07:00:40.255548  4216 solver.cpp:228] Iteration 29340, loss = 0.129124
I0627 07:00:40.255573  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 07:00:40.255580  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.120114 (* 1 = 0.120114 loss)
I0627 07:00:40.255584  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.163902 (* 1 = 0.163902 loss)
I0627 07:00:40.255589  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00298002 (* 1 = 0.00298002 loss)
I0627 07:00:40.255594  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307561 (* 1 = 0.0307561 loss)
I0627 07:00:40.255597  4216 sgd_solver.cpp:106] Iteration 29340, lr = 2e-05
I0627 07:02:25.346141  4216 solver.cpp:228] Iteration 29360, loss = 0.155629
I0627 07:02:25.346166  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 07:02:25.346173  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0683867 (* 1 = 0.0683867 loss)
I0627 07:02:25.346175  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.132988 (* 1 = 0.132988 loss)
I0627 07:02:25.346179  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00180968 (* 1 = 0.00180968 loss)
I0627 07:02:25.346182  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218816 (* 1 = 0.0218816 loss)
I0627 07:02:25.346187  4216 sgd_solver.cpp:106] Iteration 29360, lr = 2e-05
I0627 07:04:10.529776  4216 solver.cpp:228] Iteration 29380, loss = 0.150038
I0627 07:04:10.529801  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:04:10.529810  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0398535 (* 1 = 0.0398535 loss)
I0627 07:04:10.529815  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0411154 (* 1 = 0.0411154 loss)
I0627 07:04:10.529820  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00313262 (* 1 = 0.00313262 loss)
I0627 07:04:10.529825  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106972 (* 1 = 0.0106972 loss)
I0627 07:04:10.529832  4216 sgd_solver.cpp:106] Iteration 29380, lr = 2e-05
speed: 5.285s / iter
I0627 07:05:55.699134  4216 solver.cpp:228] Iteration 29400, loss = 0.126448
I0627 07:05:55.699162  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 07:05:55.699172  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536755 (* 1 = 0.0536755 loss)
I0627 07:05:55.699179  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.136847 (* 1 = 0.136847 loss)
I0627 07:05:55.699187  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00525075 (* 1 = 0.00525075 loss)
I0627 07:05:55.699195  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290721 (* 1 = 0.0290721 loss)
I0627 07:05:55.699203  4216 sgd_solver.cpp:106] Iteration 29400, lr = 2e-05
I0627 07:07:40.875838  4216 solver.cpp:228] Iteration 29420, loss = 0.299639
I0627 07:07:40.875864  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:07:40.875874  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593167 (* 1 = 0.0593167 loss)
I0627 07:07:40.875880  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0394238 (* 1 = 0.0394238 loss)
I0627 07:07:40.875885  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132666 (* 1 = 0.00132666 loss)
I0627 07:07:40.875891  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01308 (* 1 = 0.01308 loss)
I0627 07:07:40.875898  4216 sgd_solver.cpp:106] Iteration 29420, lr = 2e-05
I0627 07:09:26.038363  4216 solver.cpp:228] Iteration 29440, loss = 0.160098
I0627 07:09:26.038388  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:09:26.038394  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0143892 (* 1 = 0.0143892 loss)
I0627 07:09:26.038398  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0357969 (* 1 = 0.0357969 loss)
I0627 07:09:26.038403  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00015819 (* 1 = 0.00015819 loss)
I0627 07:09:26.038405  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00222933 (* 1 = 0.00222933 loss)
I0627 07:09:26.038410  4216 sgd_solver.cpp:106] Iteration 29440, lr = 2e-05
I0627 07:11:11.231535  4216 solver.cpp:228] Iteration 29460, loss = 0.127164
I0627 07:11:11.231560  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:11:11.231568  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248101 (* 1 = 0.0248101 loss)
I0627 07:11:11.231573  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0191535 (* 1 = 0.0191535 loss)
I0627 07:11:11.231577  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.94429e-05 (* 1 = 6.94429e-05 loss)
I0627 07:11:11.231581  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940384 (* 1 = 0.00940384 loss)
I0627 07:11:11.231586  4216 sgd_solver.cpp:106] Iteration 29460, lr = 2e-05
I0627 07:12:56.359417  4216 solver.cpp:228] Iteration 29480, loss = 0.126187
I0627 07:12:56.359442  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:12:56.359449  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00216869 (* 1 = 0.00216869 loss)
I0627 07:12:56.359454  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0152296 (* 1 = 0.0152296 loss)
I0627 07:12:56.359457  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0222902 (* 1 = 0.0222902 loss)
I0627 07:12:56.359462  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00818488 (* 1 = 0.00818488 loss)
I0627 07:12:56.359465  4216 sgd_solver.cpp:106] Iteration 29480, lr = 2e-05
I0627 07:14:41.560227  4216 solver.cpp:228] Iteration 29500, loss = 0.240214
I0627 07:14:41.560250  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 07:14:41.560258  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.070908 (* 1 = 0.070908 loss)
I0627 07:14:41.560262  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0934144 (* 1 = 0.0934144 loss)
I0627 07:14:41.560266  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000372265 (* 1 = 0.000372265 loss)
I0627 07:14:41.560271  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156571 (* 1 = 0.0156571 loss)
I0627 07:14:41.560274  4216 sgd_solver.cpp:106] Iteration 29500, lr = 2e-05
I0627 07:16:26.738304  4216 solver.cpp:228] Iteration 29520, loss = 0.109725
I0627 07:16:26.738330  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 07:16:26.738337  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.126939 (* 1 = 0.126939 loss)
I0627 07:16:26.738343  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.147738 (* 1 = 0.147738 loss)
I0627 07:16:26.738346  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169346 (* 1 = 0.00169346 loss)
I0627 07:16:26.738350  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305052 (* 1 = 0.0305052 loss)
I0627 07:16:26.738355  4216 sgd_solver.cpp:106] Iteration 29520, lr = 2e-05
I0627 07:18:11.929829  4216 solver.cpp:228] Iteration 29540, loss = 0.0753617
I0627 07:18:11.929853  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:18:11.929862  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144498 (* 1 = 0.0144498 loss)
I0627 07:18:11.929868  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0558978 (* 1 = 0.0558978 loss)
I0627 07:18:11.929874  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000112047 (* 1 = 0.000112047 loss)
I0627 07:18:11.929880  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0015051 (* 1 = 0.0015051 loss)
I0627 07:18:11.929886  4216 sgd_solver.cpp:106] Iteration 29540, lr = 2e-05
I0627 07:19:57.085777  4216 solver.cpp:228] Iteration 29560, loss = 0.258798
I0627 07:19:57.085801  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 07:19:57.085809  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0752372 (* 1 = 0.0752372 loss)
I0627 07:19:57.085814  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.107128 (* 1 = 0.107128 loss)
I0627 07:19:57.085819  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00579722 (* 1 = 0.00579722 loss)
I0627 07:19:57.085824  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318047 (* 1 = 0.0318047 loss)
I0627 07:19:57.085829  4216 sgd_solver.cpp:106] Iteration 29560, lr = 2e-05
I0627 07:21:42.249246  4216 solver.cpp:228] Iteration 29580, loss = 0.163751
I0627 07:21:42.249272  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:21:42.249279  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.012496 (* 1 = 0.012496 loss)
I0627 07:21:42.249284  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.016965 (* 1 = 0.016965 loss)
I0627 07:21:42.249289  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00392918 (* 1 = 0.00392918 loss)
I0627 07:21:42.249294  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00444679 (* 1 = 0.00444679 loss)
I0627 07:21:42.249299  4216 sgd_solver.cpp:106] Iteration 29580, lr = 2e-05
speed: 5.285s / iter
I0627 07:23:27.369714  4216 solver.cpp:228] Iteration 29600, loss = 0.167198
I0627 07:23:27.369745  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:23:27.369756  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467441 (* 1 = 0.0467441 loss)
I0627 07:23:27.369763  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0821958 (* 1 = 0.0821958 loss)
I0627 07:23:27.369771  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000967717 (* 1 = 0.000967717 loss)
I0627 07:23:27.369777  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315117 (* 1 = 0.0315117 loss)
I0627 07:23:27.369786  4216 sgd_solver.cpp:106] Iteration 29600, lr = 2e-05
I0627 07:25:12.555825  4216 solver.cpp:228] Iteration 29620, loss = 0.101675
I0627 07:25:12.555851  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 07:25:12.555860  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0317299 (* 1 = 0.0317299 loss)
I0627 07:25:12.555865  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.122977 (* 1 = 0.122977 loss)
I0627 07:25:12.555868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171894 (* 1 = 0.00171894 loss)
I0627 07:25:12.555872  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104994 (* 1 = 0.0104994 loss)
I0627 07:25:12.555878  4216 sgd_solver.cpp:106] Iteration 29620, lr = 2e-05
I0627 07:26:57.743338  4216 solver.cpp:228] Iteration 29640, loss = 0.138049
I0627 07:26:57.743365  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:26:57.743372  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379784 (* 1 = 0.0379784 loss)
I0627 07:26:57.743377  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00866971 (* 1 = 0.00866971 loss)
I0627 07:26:57.743381  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00170992 (* 1 = 0.00170992 loss)
I0627 07:26:57.743386  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00687815 (* 1 = 0.00687815 loss)
I0627 07:26:57.743391  4216 sgd_solver.cpp:106] Iteration 29640, lr = 2e-05
I0627 07:28:42.931223  4216 solver.cpp:228] Iteration 29660, loss = 0.122468
I0627 07:28:42.931247  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:28:42.931254  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0311483 (* 1 = 0.0311483 loss)
I0627 07:28:42.931258  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0476861 (* 1 = 0.0476861 loss)
I0627 07:28:42.931262  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282466 (* 1 = 0.00282466 loss)
I0627 07:28:42.931265  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00918 (* 1 = 0.00918 loss)
I0627 07:28:42.931270  4216 sgd_solver.cpp:106] Iteration 29660, lr = 2e-05
I0627 07:30:28.090699  4216 solver.cpp:228] Iteration 29680, loss = 0.210965
I0627 07:30:28.090724  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 07:30:28.090732  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201103 (* 1 = 0.0201103 loss)
I0627 07:30:28.090736  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0780079 (* 1 = 0.0780079 loss)
I0627 07:30:28.090740  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00174022 (* 1 = 0.00174022 loss)
I0627 07:30:28.090744  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00860437 (* 1 = 0.00860437 loss)
I0627 07:30:28.090749  4216 sgd_solver.cpp:106] Iteration 29680, lr = 2e-05
I0627 07:32:13.204186  4216 solver.cpp:228] Iteration 29700, loss = 0.0650714
I0627 07:32:13.204210  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:32:13.204218  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270432 (* 1 = 0.0270432 loss)
I0627 07:32:13.204222  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0372651 (* 1 = 0.0372651 loss)
I0627 07:32:13.204226  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00124649 (* 1 = 0.00124649 loss)
I0627 07:32:13.204231  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939968 (* 1 = 0.00939968 loss)
I0627 07:32:13.204236  4216 sgd_solver.cpp:106] Iteration 29700, lr = 2e-05
I0627 07:33:58.393200  4216 solver.cpp:228] Iteration 29720, loss = 0.213439
I0627 07:33:58.393226  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 07:33:58.393234  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0746059 (* 1 = 0.0746059 loss)
I0627 07:33:58.393239  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.111888 (* 1 = 0.111888 loss)
I0627 07:33:58.393244  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000470245 (* 1 = 0.000470245 loss)
I0627 07:33:58.393247  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145346 (* 1 = 0.0145346 loss)
I0627 07:33:58.393252  4216 sgd_solver.cpp:106] Iteration 29720, lr = 2e-05
I0627 07:35:43.587280  4216 solver.cpp:228] Iteration 29740, loss = 0.148908
I0627 07:35:43.587308  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:35:43.587316  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.043018 (* 1 = 0.043018 loss)
I0627 07:35:43.587321  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0893413 (* 1 = 0.0893413 loss)
I0627 07:35:43.587326  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00406452 (* 1 = 0.00406452 loss)
I0627 07:35:43.587329  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224665 (* 1 = 0.0224665 loss)
I0627 07:35:43.587335  4216 sgd_solver.cpp:106] Iteration 29740, lr = 2e-05
I0627 07:37:28.794284  4216 solver.cpp:228] Iteration 29760, loss = 0.124851
I0627 07:37:28.794313  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:37:28.794322  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148197 (* 1 = 0.0148197 loss)
I0627 07:37:28.794325  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0380489 (* 1 = 0.0380489 loss)
I0627 07:37:28.794329  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336249 (* 1 = 0.00336249 loss)
I0627 07:37:28.794332  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230929 (* 1 = 0.0230929 loss)
I0627 07:37:28.794337  4216 sgd_solver.cpp:106] Iteration 29760, lr = 2e-05
I0627 07:39:13.976512  4216 solver.cpp:228] Iteration 29780, loss = 0.369244
I0627 07:39:13.976537  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:39:13.976544  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00124136 (* 1 = 0.00124136 loss)
I0627 07:39:13.976549  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0236375 (* 1 = 0.0236375 loss)
I0627 07:39:13.976552  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388266 (* 1 = 0.00388266 loss)
I0627 07:39:13.976557  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184737 (* 1 = 0.0184737 loss)
I0627 07:39:13.976560  4216 sgd_solver.cpp:106] Iteration 29780, lr = 2e-05
speed: 5.285s / iter
I0627 07:40:59.150166  4216 solver.cpp:228] Iteration 29800, loss = 0.23266
I0627 07:40:59.150192  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 07:40:59.150198  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.110534 (* 1 = 0.110534 loss)
I0627 07:40:59.150202  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.216764 (* 1 = 0.216764 loss)
I0627 07:40:59.150207  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00814944 (* 1 = 0.00814944 loss)
I0627 07:40:59.150210  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235987 (* 1 = 0.0235987 loss)
I0627 07:40:59.150214  4216 sgd_solver.cpp:106] Iteration 29800, lr = 2e-05
I0627 07:42:44.301571  4216 solver.cpp:228] Iteration 29820, loss = 0.147275
I0627 07:42:44.301596  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:42:44.301604  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151954 (* 1 = 0.0151954 loss)
I0627 07:42:44.301609  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00641178 (* 1 = 0.00641178 loss)
I0627 07:42:44.301612  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108235 (* 1 = 0.00108235 loss)
I0627 07:42:44.301616  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00472488 (* 1 = 0.00472488 loss)
I0627 07:42:44.301621  4216 sgd_solver.cpp:106] Iteration 29820, lr = 2e-05
I0627 07:44:29.468601  4216 solver.cpp:228] Iteration 29840, loss = 0.107056
I0627 07:44:29.468626  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:44:29.468632  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.035773 (* 1 = 0.035773 loss)
I0627 07:44:29.468636  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0322342 (* 1 = 0.0322342 loss)
I0627 07:44:29.468639  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.92686e-05 (* 1 = 5.92686e-05 loss)
I0627 07:44:29.468642  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00688494 (* 1 = 0.00688494 loss)
I0627 07:44:29.468647  4216 sgd_solver.cpp:106] Iteration 29840, lr = 2e-05
I0627 07:46:14.647720  4216 solver.cpp:228] Iteration 29860, loss = 0.146731
I0627 07:46:14.647747  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:46:14.647755  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0209578 (* 1 = 0.0209578 loss)
I0627 07:46:14.647759  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.013959 (* 1 = 0.013959 loss)
I0627 07:46:14.647763  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.4676e-05 (* 1 = 5.4676e-05 loss)
I0627 07:46:14.647768  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00274097 (* 1 = 0.00274097 loss)
I0627 07:46:14.647773  4216 sgd_solver.cpp:106] Iteration 29860, lr = 2e-05
I0627 07:47:59.802505  4216 solver.cpp:228] Iteration 29880, loss = 0.259253
I0627 07:47:59.802531  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0627 07:47:59.802537  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.207945 (* 1 = 0.207945 loss)
I0627 07:47:59.802541  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.332989 (* 1 = 0.332989 loss)
I0627 07:47:59.802546  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0518156 (* 1 = 0.0518156 loss)
I0627 07:47:59.802548  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118435 (* 1 = 0.118435 loss)
I0627 07:47:59.802553  4216 sgd_solver.cpp:106] Iteration 29880, lr = 2e-05
I0627 07:49:44.886466  4216 solver.cpp:228] Iteration 29900, loss = 0.261731
I0627 07:49:44.886492  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 07:49:44.886498  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.089271 (* 1 = 0.089271 loss)
I0627 07:49:44.886502  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.1633 (* 1 = 0.1633 loss)
I0627 07:49:44.886507  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00357433 (* 1 = 0.00357433 loss)
I0627 07:49:44.886509  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0410745 (* 1 = 0.0410745 loss)
I0627 07:49:44.886514  4216 sgd_solver.cpp:106] Iteration 29900, lr = 2e-05
I0627 07:51:30.088148  4216 solver.cpp:228] Iteration 29920, loss = 0.340555
I0627 07:51:30.088176  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0627 07:51:30.088183  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.633847 (* 1 = 0.633847 loss)
I0627 07:51:30.088187  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.553386 (* 1 = 0.553386 loss)
I0627 07:51:30.088191  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0403801 (* 1 = 0.0403801 loss)
I0627 07:51:30.088196  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.245527 (* 1 = 0.245527 loss)
I0627 07:51:30.088201  4216 sgd_solver.cpp:106] Iteration 29920, lr = 2e-05
I0627 07:53:15.269917  4216 solver.cpp:228] Iteration 29940, loss = 0.158486
I0627 07:53:15.269943  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 07:53:15.269951  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.104446 (* 1 = 0.104446 loss)
I0627 07:53:15.269955  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.169975 (* 1 = 0.169975 loss)
I0627 07:53:15.269959  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139805 (* 1 = 0.0139805 loss)
I0627 07:53:15.269963  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03023 (* 1 = 0.03023 loss)
I0627 07:53:15.269968  4216 sgd_solver.cpp:106] Iteration 29940, lr = 2e-05
I0627 07:55:00.408217  4216 solver.cpp:228] Iteration 29960, loss = 0.227606
I0627 07:55:00.408260  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:55:00.408269  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0907575 (* 1 = 0.0907575 loss)
I0627 07:55:00.408274  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0554858 (* 1 = 0.0554858 loss)
I0627 07:55:00.408278  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360188 (* 1 = 0.00360188 loss)
I0627 07:55:00.408282  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207523 (* 1 = 0.0207523 loss)
I0627 07:55:00.408289  4216 sgd_solver.cpp:106] Iteration 29960, lr = 2e-05
I0627 07:56:45.581001  4216 solver.cpp:228] Iteration 29980, loss = 0.122944
I0627 07:56:45.581035  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 07:56:45.581043  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.116641 (* 1 = 0.116641 loss)
I0627 07:56:45.581048  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.166909 (* 1 = 0.166909 loss)
I0627 07:56:45.581051  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017324 (* 1 = 0.0017324 loss)
I0627 07:56:45.581055  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277356 (* 1 = 0.0277356 loss)
I0627 07:56:45.581063  4216 sgd_solver.cpp:106] Iteration 29980, lr = 2e-05
speed: 5.285s / iter
I0627 07:58:25.829102  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_30000.caffemodel
I0627 07:58:31.545739  4216 solver.cpp:228] Iteration 30000, loss = 0.159761
I0627 07:58:31.545768  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 07:58:31.545778  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.128757 (* 1 = 0.128757 loss)
I0627 07:58:31.545783  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.144934 (* 1 = 0.144934 loss)
I0627 07:58:31.545789  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00922058 (* 1 = 0.00922058 loss)
I0627 07:58:31.545795  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305611 (* 1 = 0.0305611 loss)
I0627 07:58:31.545804  4216 sgd_solver.cpp:106] Iteration 30000, lr = 2e-05
I0627 08:00:16.707862  4216 solver.cpp:228] Iteration 30020, loss = 0.121363
I0627 08:00:16.707886  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 08:00:16.707893  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.069859 (* 1 = 0.069859 loss)
I0627 08:00:16.707897  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.151662 (* 1 = 0.151662 loss)
I0627 08:00:16.707901  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00117427 (* 1 = 0.00117427 loss)
I0627 08:00:16.707906  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0392094 (* 1 = 0.0392094 loss)
I0627 08:00:16.707909  4216 sgd_solver.cpp:106] Iteration 30020, lr = 2e-05
I0627 08:02:01.863483  4216 solver.cpp:228] Iteration 30040, loss = 0.201696
I0627 08:02:01.863508  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 08:02:01.863515  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574167 (* 1 = 0.0574167 loss)
I0627 08:02:01.863519  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.111535 (* 1 = 0.111535 loss)
I0627 08:02:01.863523  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266748 (* 1 = 0.00266748 loss)
I0627 08:02:01.863528  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306391 (* 1 = 0.0306391 loss)
I0627 08:02:01.863531  4216 sgd_solver.cpp:106] Iteration 30040, lr = 2e-05
I0627 08:03:47.024279  4216 solver.cpp:228] Iteration 30060, loss = 0.153253
I0627 08:03:47.024307  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:03:47.024318  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207797 (* 1 = 0.0207797 loss)
I0627 08:03:47.024325  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.037036 (* 1 = 0.037036 loss)
I0627 08:03:47.024332  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010188 (* 1 = 0.0010188 loss)
I0627 08:03:47.024338  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00839554 (* 1 = 0.00839554 loss)
I0627 08:03:47.024346  4216 sgd_solver.cpp:106] Iteration 30060, lr = 2e-05
I0627 08:05:32.250941  4216 solver.cpp:228] Iteration 30080, loss = 0.315317
I0627 08:05:32.250967  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 08:05:32.250974  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0971159 (* 1 = 0.0971159 loss)
I0627 08:05:32.250978  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.107079 (* 1 = 0.107079 loss)
I0627 08:05:32.250982  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00581962 (* 1 = 0.00581962 loss)
I0627 08:05:32.250985  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140832 (* 1 = 0.0140832 loss)
I0627 08:05:32.250990  4216 sgd_solver.cpp:106] Iteration 30080, lr = 2e-05
I0627 08:07:17.451676  4216 solver.cpp:228] Iteration 30100, loss = 0.157243
I0627 08:07:17.451704  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 08:07:17.451711  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0246175 (* 1 = 0.0246175 loss)
I0627 08:07:17.451719  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0885768 (* 1 = 0.0885768 loss)
I0627 08:07:17.451723  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000652554 (* 1 = 0.000652554 loss)
I0627 08:07:17.451730  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.043792 (* 1 = 0.043792 loss)
I0627 08:07:17.451735  4216 sgd_solver.cpp:106] Iteration 30100, lr = 2e-05
I0627 08:09:02.630820  4216 solver.cpp:228] Iteration 30120, loss = 0.209563
I0627 08:09:02.630844  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 08:09:02.630852  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0838842 (* 1 = 0.0838842 loss)
I0627 08:09:02.630857  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.200261 (* 1 = 0.200261 loss)
I0627 08:09:02.630868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0373487 (* 1 = 0.0373487 loss)
I0627 08:09:02.630875  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301435 (* 1 = 0.0301435 loss)
I0627 08:09:02.630883  4216 sgd_solver.cpp:106] Iteration 30120, lr = 2e-05
I0627 08:10:47.841511  4216 solver.cpp:228] Iteration 30140, loss = 0.162416
I0627 08:10:47.841537  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 08:10:47.841544  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324486 (* 1 = 0.0324486 loss)
I0627 08:10:47.841549  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.011795 (* 1 = 0.011795 loss)
I0627 08:10:47.841553  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000520285 (* 1 = 0.000520285 loss)
I0627 08:10:47.841557  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0066717 (* 1 = 0.0066717 loss)
I0627 08:10:47.841562  4216 sgd_solver.cpp:106] Iteration 30140, lr = 2e-05
I0627 08:12:33.019675  4216 solver.cpp:228] Iteration 30160, loss = 0.148932
I0627 08:12:33.019701  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:12:33.019708  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185585 (* 1 = 0.0185585 loss)
I0627 08:12:33.019712  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0319076 (* 1 = 0.0319076 loss)
I0627 08:12:33.019717  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000177426 (* 1 = 0.000177426 loss)
I0627 08:12:33.019721  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00724452 (* 1 = 0.00724452 loss)
I0627 08:12:33.019726  4216 sgd_solver.cpp:106] Iteration 30160, lr = 2e-05
I0627 08:14:18.255188  4216 solver.cpp:228] Iteration 30180, loss = 0.128097
I0627 08:14:18.255221  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:14:18.255231  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222079 (* 1 = 0.0222079 loss)
I0627 08:14:18.255239  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0418089 (* 1 = 0.0418089 loss)
I0627 08:14:18.255244  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144721 (* 1 = 0.00144721 loss)
I0627 08:14:18.255251  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000505288 (* 1 = 0.000505288 loss)
I0627 08:14:18.255259  4216 sgd_solver.cpp:106] Iteration 30180, lr = 2e-05
speed: 5.284s / iter
I0627 08:16:03.445650  4216 solver.cpp:228] Iteration 30200, loss = 0.149014
I0627 08:16:03.445675  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:16:03.445683  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254281 (* 1 = 0.0254281 loss)
I0627 08:16:03.445688  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0402098 (* 1 = 0.0402098 loss)
I0627 08:16:03.445693  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.81096e-05 (* 1 = 9.81096e-05 loss)
I0627 08:16:03.445696  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00214212 (* 1 = 0.00214212 loss)
I0627 08:16:03.445701  4216 sgd_solver.cpp:106] Iteration 30200, lr = 2e-05
I0627 08:17:48.644313  4216 solver.cpp:228] Iteration 30220, loss = 0.165537
I0627 08:17:48.644340  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 08:17:48.644348  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518742 (* 1 = 0.0518742 loss)
I0627 08:17:48.644354  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.111122 (* 1 = 0.111122 loss)
I0627 08:17:48.644358  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00309759 (* 1 = 0.00309759 loss)
I0627 08:17:48.644362  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142002 (* 1 = 0.0142002 loss)
I0627 08:17:48.644367  4216 sgd_solver.cpp:106] Iteration 30220, lr = 2e-05
I0627 08:19:33.718116  4216 solver.cpp:228] Iteration 30240, loss = 0.121709
I0627 08:19:33.718142  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:19:33.718150  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341163 (* 1 = 0.0341163 loss)
I0627 08:19:33.718154  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0918235 (* 1 = 0.0918235 loss)
I0627 08:19:33.718158  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000528023 (* 1 = 0.000528023 loss)
I0627 08:19:33.718163  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00958853 (* 1 = 0.00958853 loss)
I0627 08:19:33.718168  4216 sgd_solver.cpp:106] Iteration 30240, lr = 2e-05
I0627 08:21:18.932822  4216 solver.cpp:228] Iteration 30260, loss = 0.214959
I0627 08:21:18.932848  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 08:21:18.932855  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0629225 (* 1 = 0.0629225 loss)
I0627 08:21:18.932859  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.186436 (* 1 = 0.186436 loss)
I0627 08:21:18.932862  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218612 (* 1 = 0.0218612 loss)
I0627 08:21:18.932866  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124738 (* 1 = 0.124738 loss)
I0627 08:21:18.932870  4216 sgd_solver.cpp:106] Iteration 30260, lr = 2e-05
I0627 08:23:04.091683  4216 solver.cpp:228] Iteration 30280, loss = 0.0975316
I0627 08:23:04.091707  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 08:23:04.091715  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0408707 (* 1 = 0.0408707 loss)
I0627 08:23:04.091719  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109892 (* 1 = 0.109892 loss)
I0627 08:23:04.091723  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205737 (* 1 = 0.00205737 loss)
I0627 08:23:04.091727  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104436 (* 1 = 0.0104436 loss)
I0627 08:23:04.091732  4216 sgd_solver.cpp:106] Iteration 30280, lr = 2e-05
I0627 08:24:49.262239  4216 solver.cpp:228] Iteration 30300, loss = 0.14543
I0627 08:24:49.262265  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:24:49.262274  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183604 (* 1 = 0.0183604 loss)
I0627 08:24:49.262281  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0182221 (* 1 = 0.0182221 loss)
I0627 08:24:49.262287  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000805618 (* 1 = 0.000805618 loss)
I0627 08:24:49.262292  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00647877 (* 1 = 0.00647877 loss)
I0627 08:24:49.262300  4216 sgd_solver.cpp:106] Iteration 30300, lr = 2e-05
I0627 08:26:34.420505  4216 solver.cpp:228] Iteration 30320, loss = 0.179922
I0627 08:26:34.420527  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0627 08:26:34.420534  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.259446 (* 1 = 0.259446 loss)
I0627 08:26:34.420538  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.409703 (* 1 = 0.409703 loss)
I0627 08:26:34.420542  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129369 (* 1 = 0.0129369 loss)
I0627 08:26:34.420545  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0982704 (* 1 = 0.0982704 loss)
I0627 08:26:34.420550  4216 sgd_solver.cpp:106] Iteration 30320, lr = 2e-05
I0627 08:28:19.585330  4216 solver.cpp:228] Iteration 30340, loss = 0.117968
I0627 08:28:19.585357  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:28:19.585366  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284902 (* 1 = 0.0284902 loss)
I0627 08:28:19.585371  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0203851 (* 1 = 0.0203851 loss)
I0627 08:28:19.585376  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000357217 (* 1 = 0.000357217 loss)
I0627 08:28:19.585379  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00696355 (* 1 = 0.00696355 loss)
I0627 08:28:19.585384  4216 sgd_solver.cpp:106] Iteration 30340, lr = 2e-05
I0627 08:30:04.727622  4216 solver.cpp:228] Iteration 30360, loss = 0.0938055
I0627 08:30:04.727645  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 08:30:04.727653  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472769 (* 1 = 0.0472769 loss)
I0627 08:30:04.727656  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.107016 (* 1 = 0.107016 loss)
I0627 08:30:04.727660  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000484139 (* 1 = 0.000484139 loss)
I0627 08:30:04.727663  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112981 (* 1 = 0.0112981 loss)
I0627 08:30:04.727669  4216 sgd_solver.cpp:106] Iteration 30360, lr = 2e-05
I0627 08:31:49.896689  4216 solver.cpp:228] Iteration 30380, loss = 0.178594
I0627 08:31:49.896713  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:31:49.896719  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0131416 (* 1 = 0.0131416 loss)
I0627 08:31:49.896724  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0356141 (* 1 = 0.0356141 loss)
I0627 08:31:49.896728  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00712249 (* 1 = 0.00712249 loss)
I0627 08:31:49.896733  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228147 (* 1 = 0.0228147 loss)
I0627 08:31:49.896739  4216 sgd_solver.cpp:106] Iteration 30380, lr = 2e-05
speed: 5.284s / iter
I0627 08:33:35.091990  4216 solver.cpp:228] Iteration 30400, loss = 0.161909
I0627 08:33:35.092015  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0627 08:33:35.092023  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.142283 (* 1 = 0.142283 loss)
I0627 08:33:35.092027  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.246516 (* 1 = 0.246516 loss)
I0627 08:33:35.092031  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162769 (* 1 = 0.0162769 loss)
I0627 08:33:35.092036  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223975 (* 1 = 0.0223975 loss)
I0627 08:33:35.092041  4216 sgd_solver.cpp:106] Iteration 30400, lr = 2e-05
I0627 08:35:20.270103  4216 solver.cpp:228] Iteration 30420, loss = 0.12187
I0627 08:35:20.270129  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 08:35:20.270138  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251513 (* 1 = 0.0251513 loss)
I0627 08:35:20.270141  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0667351 (* 1 = 0.0667351 loss)
I0627 08:35:20.270145  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000576195 (* 1 = 0.000576195 loss)
I0627 08:35:20.270150  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00320054 (* 1 = 0.00320054 loss)
I0627 08:35:20.270154  4216 sgd_solver.cpp:106] Iteration 30420, lr = 2e-05
I0627 08:37:05.447238  4216 solver.cpp:228] Iteration 30440, loss = 0.122826
I0627 08:37:05.447263  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 08:37:05.447269  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0993858 (* 1 = 0.0993858 loss)
I0627 08:37:05.447273  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.117977 (* 1 = 0.117977 loss)
I0627 08:37:05.447278  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000620078 (* 1 = 0.000620078 loss)
I0627 08:37:05.447281  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014832 (* 1 = 0.014832 loss)
I0627 08:37:05.447286  4216 sgd_solver.cpp:106] Iteration 30440, lr = 2e-05
I0627 08:38:50.592545  4216 solver.cpp:228] Iteration 30460, loss = 0.119529
I0627 08:38:50.592568  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:38:50.592576  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371981 (* 1 = 0.0371981 loss)
I0627 08:38:50.592581  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0253218 (* 1 = 0.0253218 loss)
I0627 08:38:50.592583  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00210882 (* 1 = 0.00210882 loss)
I0627 08:38:50.592587  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146637 (* 1 = 0.0146637 loss)
I0627 08:38:50.592593  4216 sgd_solver.cpp:106] Iteration 30460, lr = 2e-05
I0627 08:40:35.780503  4216 solver.cpp:228] Iteration 30480, loss = 0.147009
I0627 08:40:35.780529  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:40:35.780535  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244901 (* 1 = 0.0244901 loss)
I0627 08:40:35.780539  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0323265 (* 1 = 0.0323265 loss)
I0627 08:40:35.780544  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00741883 (* 1 = 0.00741883 loss)
I0627 08:40:35.780546  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193203 (* 1 = 0.0193203 loss)
I0627 08:40:35.780551  4216 sgd_solver.cpp:106] Iteration 30480, lr = 2e-05
I0627 08:42:20.950825  4216 solver.cpp:228] Iteration 30500, loss = 0.0828682
I0627 08:42:20.950850  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:42:20.950856  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0424758 (* 1 = 0.0424758 loss)
I0627 08:42:20.950865  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0393124 (* 1 = 0.0393124 loss)
I0627 08:42:20.950868  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141128 (* 1 = 0.00141128 loss)
I0627 08:42:20.950871  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111194 (* 1 = 0.0111194 loss)
I0627 08:42:20.950876  4216 sgd_solver.cpp:106] Iteration 30500, lr = 2e-05
I0627 08:44:07.871233  4216 solver.cpp:228] Iteration 30520, loss = 0.245772
I0627 08:44:07.871258  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:44:07.871268  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0735313 (* 1 = 0.0735313 loss)
I0627 08:44:07.871271  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0450688 (* 1 = 0.0450688 loss)
I0627 08:44:07.871276  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000948993 (* 1 = 0.000948993 loss)
I0627 08:44:07.871279  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167103 (* 1 = 0.0167103 loss)
I0627 08:44:07.871285  4216 sgd_solver.cpp:106] Iteration 30520, lr = 2e-05
I0627 08:45:55.341974  4216 solver.cpp:228] Iteration 30540, loss = 0.305953
I0627 08:45:55.341998  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:45:55.342006  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113607 (* 1 = 0.0113607 loss)
I0627 08:45:55.342011  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0195466 (* 1 = 0.0195466 loss)
I0627 08:45:55.342015  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000190658 (* 1 = 0.000190658 loss)
I0627 08:45:55.342020  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00226513 (* 1 = 0.00226513 loss)
I0627 08:45:55.342025  4216 sgd_solver.cpp:106] Iteration 30540, lr = 2e-05
I0627 08:47:42.539854  4216 solver.cpp:228] Iteration 30560, loss = 0.134514
I0627 08:47:42.539878  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:47:42.539885  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207351 (* 1 = 0.0207351 loss)
I0627 08:47:42.539889  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0364516 (* 1 = 0.0364516 loss)
I0627 08:47:42.539893  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00811677 (* 1 = 0.00811677 loss)
I0627 08:47:42.539896  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013438 (* 1 = 0.013438 loss)
I0627 08:47:42.539901  4216 sgd_solver.cpp:106] Iteration 30560, lr = 2e-05
I0627 08:49:28.605443  4216 solver.cpp:228] Iteration 30580, loss = 0.177014
I0627 08:49:28.605470  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:49:28.605479  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157117 (* 1 = 0.0157117 loss)
I0627 08:49:28.605484  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0756364 (* 1 = 0.0756364 loss)
I0627 08:49:28.605487  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115045 (* 1 = 0.00115045 loss)
I0627 08:49:28.605491  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214956 (* 1 = 0.0214956 loss)
I0627 08:49:28.605496  4216 sgd_solver.cpp:106] Iteration 30580, lr = 2e-05
speed: 5.284s / iter
I0627 08:51:14.561161  4216 solver.cpp:228] Iteration 30600, loss = 0.3596
I0627 08:51:14.561187  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 08:51:14.561194  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807288 (* 1 = 0.0807288 loss)
I0627 08:51:14.561198  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.158667 (* 1 = 0.158667 loss)
I0627 08:51:14.561203  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103022 (* 1 = 0.00103022 loss)
I0627 08:51:14.561208  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390112 (* 1 = 0.0390112 loss)
I0627 08:51:14.561213  4216 sgd_solver.cpp:106] Iteration 30600, lr = 2e-05
I0627 08:53:00.791743  4216 solver.cpp:228] Iteration 30620, loss = 0.140276
I0627 08:53:00.791770  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:53:00.791777  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154983 (* 1 = 0.0154983 loss)
I0627 08:53:00.791782  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0518826 (* 1 = 0.0518826 loss)
I0627 08:53:00.791786  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0280399 (* 1 = 0.0280399 loss)
I0627 08:53:00.791790  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124215 (* 1 = 0.124215 loss)
I0627 08:53:00.791795  4216 sgd_solver.cpp:106] Iteration 30620, lr = 2e-05
I0627 08:54:46.987359  4216 solver.cpp:228] Iteration 30640, loss = 0.153273
I0627 08:54:46.987385  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:54:46.987396  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353843 (* 1 = 0.0353843 loss)
I0627 08:54:46.987402  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0340547 (* 1 = 0.0340547 loss)
I0627 08:54:46.987408  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00187977 (* 1 = 0.00187977 loss)
I0627 08:54:46.987416  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106571 (* 1 = 0.0106571 loss)
I0627 08:54:46.987422  4216 sgd_solver.cpp:106] Iteration 30640, lr = 2e-05
I0627 08:56:33.325332  4216 solver.cpp:228] Iteration 30660, loss = 0.209923
I0627 08:56:33.325356  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:56:33.325362  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000512345 (* 1 = 0.000512345 loss)
I0627 08:56:33.325366  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0116794 (* 1 = 0.0116794 loss)
I0627 08:56:33.325371  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00486175 (* 1 = 0.00486175 loss)
I0627 08:56:33.325374  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00760041 (* 1 = 0.00760041 loss)
I0627 08:56:33.325378  4216 sgd_solver.cpp:106] Iteration 30660, lr = 2e-05
I0627 08:58:19.903295  4216 solver.cpp:228] Iteration 30680, loss = 0.153648
I0627 08:58:19.903321  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:58:19.903331  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0219245 (* 1 = 0.0219245 loss)
I0627 08:58:19.903337  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0561081 (* 1 = 0.0561081 loss)
I0627 08:58:19.903343  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000882101 (* 1 = 0.000882101 loss)
I0627 08:58:19.903349  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336775 (* 1 = 0.0336775 loss)
I0627 08:58:19.903357  4216 sgd_solver.cpp:106] Iteration 30680, lr = 2e-05
I0627 09:00:06.323319  4216 solver.cpp:228] Iteration 30700, loss = 0.314248
I0627 09:00:06.323343  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 09:00:06.323350  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.270412 (* 1 = 0.270412 loss)
I0627 09:00:06.323354  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.197247 (* 1 = 0.197247 loss)
I0627 09:00:06.323359  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00747575 (* 1 = 0.00747575 loss)
I0627 09:00:06.323361  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445977 (* 1 = 0.0445977 loss)
I0627 09:00:06.323366  4216 sgd_solver.cpp:106] Iteration 30700, lr = 2e-05
I0627 09:01:52.848420  4216 solver.cpp:228] Iteration 30720, loss = 0.112506
I0627 09:01:52.848448  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 09:01:52.848457  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.08954 (* 1 = 0.08954 loss)
I0627 09:01:52.848464  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0838942 (* 1 = 0.0838942 loss)
I0627 09:01:52.848471  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00729975 (* 1 = 0.00729975 loss)
I0627 09:01:52.848479  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223141 (* 1 = 0.0223141 loss)
I0627 09:01:52.848485  4216 sgd_solver.cpp:106] Iteration 30720, lr = 2e-05
I0627 09:03:39.385285  4216 solver.cpp:228] Iteration 30740, loss = 0.186636
I0627 09:03:39.385313  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:03:39.385321  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459312 (* 1 = 0.0459312 loss)
I0627 09:03:39.385325  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0766129 (* 1 = 0.0766129 loss)
I0627 09:03:39.385329  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354247 (* 1 = 0.00354247 loss)
I0627 09:03:39.385334  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0256302 (* 1 = 0.0256302 loss)
I0627 09:03:39.385339  4216 sgd_solver.cpp:106] Iteration 30740, lr = 2e-05
I0627 09:05:25.838419  4216 solver.cpp:228] Iteration 30760, loss = 0.151483
I0627 09:05:25.838444  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:05:25.838451  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166162 (* 1 = 0.0166162 loss)
I0627 09:05:25.838456  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0402354 (* 1 = 0.0402354 loss)
I0627 09:05:25.838459  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015324 (* 1 = 0.015324 loss)
I0627 09:05:25.838464  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172176 (* 1 = 0.0172176 loss)
I0627 09:05:25.838469  4216 sgd_solver.cpp:106] Iteration 30760, lr = 2e-05
I0627 09:07:12.277667  4216 solver.cpp:228] Iteration 30780, loss = 0.11667
I0627 09:07:12.277693  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 09:07:12.277699  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.114798 (* 1 = 0.114798 loss)
I0627 09:07:12.277704  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.146566 (* 1 = 0.146566 loss)
I0627 09:07:12.277707  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122358 (* 1 = 0.00122358 loss)
I0627 09:07:12.277711  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.050921 (* 1 = 0.050921 loss)
I0627 09:07:12.277717  4216 sgd_solver.cpp:106] Iteration 30780, lr = 2e-05
speed: 5.284s / iter
I0627 09:08:58.569775  4216 solver.cpp:228] Iteration 30800, loss = 0.10997
I0627 09:08:58.569799  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:08:58.569806  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142701 (* 1 = 0.0142701 loss)
I0627 09:08:58.569810  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0412695 (* 1 = 0.0412695 loss)
I0627 09:08:58.569814  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000207537 (* 1 = 0.000207537 loss)
I0627 09:08:58.569818  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00298031 (* 1 = 0.00298031 loss)
I0627 09:08:58.569823  4216 sgd_solver.cpp:106] Iteration 30800, lr = 2e-05
I0627 09:10:44.223428  4216 solver.cpp:228] Iteration 30820, loss = 0.157684
I0627 09:10:44.223451  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:10:44.223459  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182739 (* 1 = 0.0182739 loss)
I0627 09:10:44.223462  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0523817 (* 1 = 0.0523817 loss)
I0627 09:10:44.223466  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186137 (* 1 = 0.00186137 loss)
I0627 09:10:44.223470  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00349444 (* 1 = 0.00349444 loss)
I0627 09:10:44.223474  4216 sgd_solver.cpp:106] Iteration 30820, lr = 2e-05
I0627 09:12:30.667914  4216 solver.cpp:228] Iteration 30840, loss = 0.140969
I0627 09:12:30.667938  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:12:30.667945  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122979 (* 1 = 0.0122979 loss)
I0627 09:12:30.667949  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0158048 (* 1 = 0.0158048 loss)
I0627 09:12:30.667953  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213713 (* 1 = 0.00213713 loss)
I0627 09:12:30.667958  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0081573 (* 1 = 0.0081573 loss)
I0627 09:12:30.667961  4216 sgd_solver.cpp:106] Iteration 30840, lr = 2e-05
I0627 09:14:17.584944  4216 solver.cpp:228] Iteration 30860, loss = 0.15909
I0627 09:14:17.584975  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0627 09:14:17.584983  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0923458 (* 1 = 0.0923458 loss)
I0627 09:14:17.584991  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.305828 (* 1 = 0.305828 loss)
I0627 09:14:17.584997  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00835415 (* 1 = 0.00835415 loss)
I0627 09:14:17.585005  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273164 (* 1 = 0.0273164 loss)
I0627 09:14:17.585014  4216 sgd_solver.cpp:106] Iteration 30860, lr = 2e-05
I0627 09:16:04.320765  4216 solver.cpp:228] Iteration 30880, loss = 0.249175
I0627 09:16:04.320791  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:16:04.320801  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308746 (* 1 = 0.0308746 loss)
I0627 09:16:04.320808  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0172802 (* 1 = 0.0172802 loss)
I0627 09:16:04.320814  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000137198 (* 1 = 0.000137198 loss)
I0627 09:16:04.320821  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00199305 (* 1 = 0.00199305 loss)
I0627 09:16:04.320827  4216 sgd_solver.cpp:106] Iteration 30880, lr = 2e-05
I0627 09:17:51.238751  4216 solver.cpp:228] Iteration 30900, loss = 0.199778
I0627 09:17:51.238785  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 09:17:51.238795  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0480614 (* 1 = 0.0480614 loss)
I0627 09:17:51.238801  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.135679 (* 1 = 0.135679 loss)
I0627 09:17:51.238807  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00366387 (* 1 = 0.00366387 loss)
I0627 09:17:51.238812  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141442 (* 1 = 0.0141442 loss)
I0627 09:17:51.238819  4216 sgd_solver.cpp:106] Iteration 30900, lr = 2e-05
I0627 09:19:38.129580  4216 solver.cpp:228] Iteration 30920, loss = 0.20005
I0627 09:19:38.129606  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:19:38.129613  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.031672 (* 1 = 0.031672 loss)
I0627 09:19:38.129617  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0340868 (* 1 = 0.0340868 loss)
I0627 09:19:38.129621  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0051492 (* 1 = 0.0051492 loss)
I0627 09:19:38.129626  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00924018 (* 1 = 0.00924018 loss)
I0627 09:19:38.129631  4216 sgd_solver.cpp:106] Iteration 30920, lr = 2e-05
I0627 09:21:23.262723  4216 solver.cpp:228] Iteration 30940, loss = 0.179401
I0627 09:21:23.262749  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:21:23.262758  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161152 (* 1 = 0.0161152 loss)
I0627 09:21:23.262763  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0295503 (* 1 = 0.0295503 loss)
I0627 09:21:23.262768  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00987782 (* 1 = 0.00987782 loss)
I0627 09:21:23.262771  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00537374 (* 1 = 0.00537374 loss)
I0627 09:21:23.262775  4216 sgd_solver.cpp:106] Iteration 30940, lr = 2e-05
I0627 09:23:08.438242  4216 solver.cpp:228] Iteration 30960, loss = 0.230123
I0627 09:23:08.438267  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:23:08.438275  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381493 (* 1 = 0.0381493 loss)
I0627 09:23:08.438279  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0579092 (* 1 = 0.0579092 loss)
I0627 09:23:08.438284  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000141246 (* 1 = 0.000141246 loss)
I0627 09:23:08.438288  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00629612 (* 1 = 0.00629612 loss)
I0627 09:23:08.438293  4216 sgd_solver.cpp:106] Iteration 30960, lr = 2e-05
I0627 09:24:55.963094  4216 solver.cpp:228] Iteration 30980, loss = 0.182998
I0627 09:24:55.963120  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 09:24:55.963129  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476971 (* 1 = 0.0476971 loss)
I0627 09:24:55.963133  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.15722 (* 1 = 0.15722 loss)
I0627 09:24:55.963137  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108286 (* 1 = 0.00108286 loss)
I0627 09:24:55.963142  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250072 (* 1 = 0.0250072 loss)
I0627 09:24:55.963148  4216 sgd_solver.cpp:106] Iteration 30980, lr = 2e-05
speed: 5.285s / iter
I0627 09:26:42.473892  4216 solver.cpp:228] Iteration 31000, loss = 0.164374
I0627 09:26:42.473917  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 09:26:42.473923  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625115 (* 1 = 0.0625115 loss)
I0627 09:26:42.473927  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0867372 (* 1 = 0.0867372 loss)
I0627 09:26:42.473932  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00067228 (* 1 = 0.00067228 loss)
I0627 09:26:42.473935  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0069887 (* 1 = 0.0069887 loss)
I0627 09:26:42.473939  4216 sgd_solver.cpp:106] Iteration 31000, lr = 2e-05
I0627 09:28:28.440894  4216 solver.cpp:228] Iteration 31020, loss = 0.305122
I0627 09:28:28.440918  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 09:28:28.440925  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236303 (* 1 = 0.0236303 loss)
I0627 09:28:28.440929  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0970874 (* 1 = 0.0970874 loss)
I0627 09:28:28.440933  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176019 (* 1 = 0.0176019 loss)
I0627 09:28:28.440937  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0829968 (* 1 = 0.0829968 loss)
I0627 09:28:28.440942  4216 sgd_solver.cpp:106] Iteration 31020, lr = 2e-05
I0627 09:30:14.806149  4216 solver.cpp:228] Iteration 31040, loss = 0.314902
I0627 09:30:14.806177  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0627 09:30:14.806185  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.346141 (* 1 = 0.346141 loss)
I0627 09:30:14.806190  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.514706 (* 1 = 0.514706 loss)
I0627 09:30:14.806193  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021197 (* 1 = 0.021197 loss)
I0627 09:30:14.806197  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0913738 (* 1 = 0.0913738 loss)
I0627 09:30:14.806203  4216 sgd_solver.cpp:106] Iteration 31040, lr = 2e-05
I0627 09:32:01.316499  4216 solver.cpp:228] Iteration 31060, loss = 0.0537065
I0627 09:32:01.316525  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:32:01.316534  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.000549756 (* 1 = 0.000549756 loss)
I0627 09:32:01.316539  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0142306 (* 1 = 0.0142306 loss)
I0627 09:32:01.316542  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00129858 (* 1 = 0.00129858 loss)
I0627 09:32:01.316546  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140883 (* 1 = 0.0140883 loss)
I0627 09:32:01.316552  4216 sgd_solver.cpp:106] Iteration 31060, lr = 2e-05
I0627 09:33:47.905128  4216 solver.cpp:228] Iteration 31080, loss = 0.179083
I0627 09:33:47.905153  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:33:47.905160  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0089129 (* 1 = 0.0089129 loss)
I0627 09:33:47.905165  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0346661 (* 1 = 0.0346661 loss)
I0627 09:33:47.905169  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226231 (* 1 = 0.00226231 loss)
I0627 09:33:47.905172  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00244521 (* 1 = 0.00244521 loss)
I0627 09:33:47.905176  4216 sgd_solver.cpp:106] Iteration 31080, lr = 2e-05
I0627 09:35:35.357367  4216 solver.cpp:228] Iteration 31100, loss = 0.105674
I0627 09:35:35.357393  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 09:35:35.357399  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359358 (* 1 = 0.0359358 loss)
I0627 09:35:35.357404  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0681027 (* 1 = 0.0681027 loss)
I0627 09:35:35.357409  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359739 (* 1 = 0.00359739 loss)
I0627 09:35:35.357412  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263972 (* 1 = 0.0263972 loss)
I0627 09:35:35.357417  4216 sgd_solver.cpp:106] Iteration 31100, lr = 2e-05
I0627 09:37:22.710199  4216 solver.cpp:228] Iteration 31120, loss = 0.126756
I0627 09:37:22.710227  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 09:37:22.710233  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0713758 (* 1 = 0.0713758 loss)
I0627 09:37:22.710237  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109741 (* 1 = 0.109741 loss)
I0627 09:37:22.710242  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000502022 (* 1 = 0.000502022 loss)
I0627 09:37:22.710244  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318322 (* 1 = 0.0318322 loss)
I0627 09:37:22.710250  4216 sgd_solver.cpp:106] Iteration 31120, lr = 2e-05
I0627 09:39:11.288465  4216 solver.cpp:228] Iteration 31140, loss = 0.127184
I0627 09:39:11.288493  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:39:11.288504  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.036703 (* 1 = 0.036703 loss)
I0627 09:39:11.288511  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0352424 (* 1 = 0.0352424 loss)
I0627 09:39:11.288517  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265599 (* 1 = 0.00265599 loss)
I0627 09:39:11.288524  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126767 (* 1 = 0.0126767 loss)
I0627 09:39:11.288534  4216 sgd_solver.cpp:106] Iteration 31140, lr = 2e-05
I0627 09:40:59.118450  4216 solver.cpp:228] Iteration 31160, loss = 0.111176
I0627 09:40:59.118482  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:40:59.118494  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222428 (* 1 = 0.0222428 loss)
I0627 09:40:59.118500  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0439909 (* 1 = 0.0439909 loss)
I0627 09:40:59.118508  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102255 (* 1 = 0.00102255 loss)
I0627 09:40:59.118532  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335527 (* 1 = 0.0335527 loss)
I0627 09:40:59.118548  4216 sgd_solver.cpp:106] Iteration 31160, lr = 2e-05
I0627 09:42:45.363983  4216 solver.cpp:228] Iteration 31180, loss = 0.335007
I0627 09:42:45.364012  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0627 09:42:45.364018  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.316646 (* 1 = 0.316646 loss)
I0627 09:42:45.364023  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.390746 (* 1 = 0.390746 loss)
I0627 09:42:45.364028  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00723669 (* 1 = 0.00723669 loss)
I0627 09:42:45.364032  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0705726 (* 1 = 0.0705726 loss)
I0627 09:42:45.364037  4216 sgd_solver.cpp:106] Iteration 31180, lr = 2e-05
speed: 5.285s / iter
I0627 09:44:31.973551  4216 solver.cpp:228] Iteration 31200, loss = 0.118707
I0627 09:44:31.973578  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 09:44:31.973587  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206523 (* 1 = 0.0206523 loss)
I0627 09:44:31.973590  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0193871 (* 1 = 0.0193871 loss)
I0627 09:44:31.973595  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000839378 (* 1 = 0.000839378 loss)
I0627 09:44:31.973599  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00671915 (* 1 = 0.00671915 loss)
I0627 09:44:31.973604  4216 sgd_solver.cpp:106] Iteration 31200, lr = 2e-05
I0627 09:46:19.493034  4216 solver.cpp:228] Iteration 31220, loss = 0.188529
I0627 09:46:19.493057  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 09:46:19.493064  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.184686 (* 1 = 0.184686 loss)
I0627 09:46:19.493068  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.142986 (* 1 = 0.142986 loss)
I0627 09:46:19.493072  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0332646 (* 1 = 0.0332646 loss)
I0627 09:46:19.493075  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0752914 (* 1 = 0.0752914 loss)
I0627 09:46:19.493080  4216 sgd_solver.cpp:106] Iteration 31220, lr = 2e-05
I0627 09:48:05.542523  4216 solver.cpp:228] Iteration 31240, loss = 0.15558
I0627 09:48:05.542548  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:48:05.542557  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442313 (* 1 = 0.0442313 loss)
I0627 09:48:05.542560  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0324533 (* 1 = 0.0324533 loss)
I0627 09:48:05.542564  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168681 (* 1 = 0.00168681 loss)
I0627 09:48:05.542567  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198384 (* 1 = 0.0198384 loss)
I0627 09:48:05.542572  4216 sgd_solver.cpp:106] Iteration 31240, lr = 2e-05
I0627 09:49:50.900180  4216 solver.cpp:228] Iteration 31260, loss = 0.232072
I0627 09:49:50.900204  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 09:49:50.900213  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0669919 (* 1 = 0.0669919 loss)
I0627 09:49:50.900218  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0516175 (* 1 = 0.0516175 loss)
I0627 09:49:50.900221  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102279 (* 1 = 0.0102279 loss)
I0627 09:49:50.900225  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00845175 (* 1 = 0.00845175 loss)
I0627 09:49:50.900230  4216 sgd_solver.cpp:106] Iteration 31260, lr = 2e-05
I0627 09:51:37.009706  4216 solver.cpp:228] Iteration 31280, loss = 0.132287
I0627 09:51:37.009729  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:51:37.009737  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294971 (* 1 = 0.0294971 loss)
I0627 09:51:37.009740  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0557407 (* 1 = 0.0557407 loss)
I0627 09:51:37.009744  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00174485 (* 1 = 0.00174485 loss)
I0627 09:51:37.009748  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00709997 (* 1 = 0.00709997 loss)
I0627 09:51:37.009752  4216 sgd_solver.cpp:106] Iteration 31280, lr = 2e-05
I0627 09:53:23.764698  4216 solver.cpp:228] Iteration 31300, loss = 0.166288
I0627 09:53:23.764724  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 09:53:23.764731  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381602 (* 1 = 0.0381602 loss)
I0627 09:53:23.764736  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.162658 (* 1 = 0.162658 loss)
I0627 09:53:23.764740  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000881411 (* 1 = 0.000881411 loss)
I0627 09:53:23.764744  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00879028 (* 1 = 0.00879028 loss)
I0627 09:53:23.764750  4216 sgd_solver.cpp:106] Iteration 31300, lr = 2e-05
I0627 09:55:10.777904  4216 solver.cpp:228] Iteration 31320, loss = 0.148556
I0627 09:55:10.777927  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 09:55:10.777935  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0615316 (* 1 = 0.0615316 loss)
I0627 09:55:10.777938  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.129003 (* 1 = 0.129003 loss)
I0627 09:55:10.777942  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00492689 (* 1 = 0.00492689 loss)
I0627 09:55:10.777945  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0847798 (* 1 = 0.0847798 loss)
I0627 09:55:10.777951  4216 sgd_solver.cpp:106] Iteration 31320, lr = 2e-05
I0627 09:56:57.665271  4216 solver.cpp:228] Iteration 31340, loss = 0.184074
I0627 09:56:57.665297  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:56:57.665305  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154031 (* 1 = 0.0154031 loss)
I0627 09:56:57.665310  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.028081 (* 1 = 0.028081 loss)
I0627 09:56:57.665314  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000444542 (* 1 = 0.000444542 loss)
I0627 09:56:57.665318  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00624277 (* 1 = 0.00624277 loss)
I0627 09:56:57.665323  4216 sgd_solver.cpp:106] Iteration 31340, lr = 2e-05
I0627 09:58:45.362120  4216 solver.cpp:228] Iteration 31360, loss = 0.192625
I0627 09:58:45.362145  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 09:58:45.362154  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0581197 (* 1 = 0.0581197 loss)
I0627 09:58:45.362157  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0941845 (* 1 = 0.0941845 loss)
I0627 09:58:45.362161  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00539356 (* 1 = 0.00539356 loss)
I0627 09:58:45.362165  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243533 (* 1 = 0.0243533 loss)
I0627 09:58:45.362170  4216 sgd_solver.cpp:106] Iteration 31360, lr = 2e-05
I0627 10:00:32.908089  4216 solver.cpp:228] Iteration 31380, loss = 0.12455
I0627 10:00:32.908113  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 10:00:32.908120  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0398302 (* 1 = 0.0398302 loss)
I0627 10:00:32.908124  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.118831 (* 1 = 0.118831 loss)
I0627 10:00:32.908128  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000795811 (* 1 = 0.000795811 loss)
I0627 10:00:32.908133  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010315 (* 1 = 0.010315 loss)
I0627 10:00:32.908138  4216 sgd_solver.cpp:106] Iteration 31380, lr = 2e-05
speed: 5.285s / iter
I0627 10:02:19.908512  4216 solver.cpp:228] Iteration 31400, loss = 0.122284
I0627 10:02:19.908535  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:02:19.908543  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168366 (* 1 = 0.0168366 loss)
I0627 10:02:19.908547  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0478615 (* 1 = 0.0478615 loss)
I0627 10:02:19.908551  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134456 (* 1 = 0.00134456 loss)
I0627 10:02:19.908555  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127819 (* 1 = 0.0127819 loss)
I0627 10:02:19.908560  4216 sgd_solver.cpp:106] Iteration 31400, lr = 2e-05
I0627 10:04:07.364393  4216 solver.cpp:228] Iteration 31420, loss = 0.182672
I0627 10:04:07.364418  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 10:04:07.364424  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156942 (* 1 = 0.0156942 loss)
I0627 10:04:07.364428  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.068418 (* 1 = 0.068418 loss)
I0627 10:04:07.364432  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180661 (* 1 = 0.0180661 loss)
I0627 10:04:07.364436  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00716031 (* 1 = 0.00716031 loss)
I0627 10:04:07.364440  4216 sgd_solver.cpp:106] Iteration 31420, lr = 2e-05
I0627 10:05:53.585805  4216 solver.cpp:228] Iteration 31440, loss = 0.258452
I0627 10:05:53.585832  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 10:05:53.585840  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0865222 (* 1 = 0.0865222 loss)
I0627 10:05:53.585844  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.172722 (* 1 = 0.172722 loss)
I0627 10:05:53.585849  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0317943 (* 1 = 0.0317943 loss)
I0627 10:05:53.585851  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430447 (* 1 = 0.0430447 loss)
I0627 10:05:53.585857  4216 sgd_solver.cpp:106] Iteration 31440, lr = 2e-05
I0627 10:07:40.193688  4216 solver.cpp:228] Iteration 31460, loss = 0.154957
I0627 10:07:40.193719  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0627 10:07:40.193727  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0527029 (* 1 = 0.0527029 loss)
I0627 10:07:40.193732  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.200358 (* 1 = 0.200358 loss)
I0627 10:07:40.193737  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00153855 (* 1 = 0.00153855 loss)
I0627 10:07:40.193742  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192835 (* 1 = 0.0192835 loss)
I0627 10:07:40.193747  4216 sgd_solver.cpp:106] Iteration 31460, lr = 2e-05
I0627 10:09:27.584558  4216 solver.cpp:228] Iteration 31480, loss = 0.159823
I0627 10:09:27.584584  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:09:27.584594  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220613 (* 1 = 0.0220613 loss)
I0627 10:09:27.584600  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0284897 (* 1 = 0.0284897 loss)
I0627 10:09:27.584606  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111911 (* 1 = 0.0111911 loss)
I0627 10:09:27.584611  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00385903 (* 1 = 0.00385903 loss)
I0627 10:09:27.584621  4216 sgd_solver.cpp:106] Iteration 31480, lr = 2e-05
I0627 10:11:13.765200  4216 solver.cpp:228] Iteration 31500, loss = 0.214435
I0627 10:11:13.765223  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 10:11:13.765230  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614011 (* 1 = 0.0614011 loss)
I0627 10:11:13.765234  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.104429 (* 1 = 0.104429 loss)
I0627 10:11:13.765239  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110832 (* 1 = 0.00110832 loss)
I0627 10:11:13.765242  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438558 (* 1 = 0.0438558 loss)
I0627 10:11:13.765247  4216 sgd_solver.cpp:106] Iteration 31500, lr = 2e-05
I0627 10:12:59.927559  4216 solver.cpp:228] Iteration 31520, loss = 0.155858
I0627 10:12:59.927582  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 10:12:59.927588  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0941045 (* 1 = 0.0941045 loss)
I0627 10:12:59.927592  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.124983 (* 1 = 0.124983 loss)
I0627 10:12:59.927597  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.03223 (* 1 = 0.03223 loss)
I0627 10:12:59.927599  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0635126 (* 1 = 0.0635126 loss)
I0627 10:12:59.927604  4216 sgd_solver.cpp:106] Iteration 31520, lr = 2e-05
I0627 10:14:46.641302  4216 solver.cpp:228] Iteration 31540, loss = 0.150332
I0627 10:14:46.641330  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:14:46.641340  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00850745 (* 1 = 0.00850745 loss)
I0627 10:14:46.641346  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0257028 (* 1 = 0.0257028 loss)
I0627 10:14:46.641352  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189414 (* 1 = 0.00189414 loss)
I0627 10:14:46.641360  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00199317 (* 1 = 0.00199317 loss)
I0627 10:14:46.641368  4216 sgd_solver.cpp:106] Iteration 31540, lr = 2e-05
I0627 10:16:32.772011  4216 solver.cpp:228] Iteration 31560, loss = 0.10306
I0627 10:16:32.772032  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 10:16:32.772039  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0257385 (* 1 = 0.0257385 loss)
I0627 10:16:32.772043  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0535744 (* 1 = 0.0535744 loss)
I0627 10:16:32.772047  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00124722 (* 1 = 0.00124722 loss)
I0627 10:16:32.772052  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0056292 (* 1 = 0.0056292 loss)
I0627 10:16:32.772055  4216 sgd_solver.cpp:106] Iteration 31560, lr = 2e-05
I0627 10:18:18.972327  4216 solver.cpp:228] Iteration 31580, loss = 0.204941
I0627 10:18:18.972354  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 10:18:18.972362  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0560784 (* 1 = 0.0560784 loss)
I0627 10:18:18.972367  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.119457 (* 1 = 0.119457 loss)
I0627 10:18:18.972370  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000364922 (* 1 = 0.000364922 loss)
I0627 10:18:18.972373  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00864395 (* 1 = 0.00864395 loss)
I0627 10:18:18.972379  4216 sgd_solver.cpp:106] Iteration 31580, lr = 2e-05
speed: 5.286s / iter
I0627 10:20:05.940400  4216 solver.cpp:228] Iteration 31600, loss = 0.161289
I0627 10:20:05.940425  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:20:05.940433  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138642 (* 1 = 0.0138642 loss)
I0627 10:20:05.940438  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0159854 (* 1 = 0.0159854 loss)
I0627 10:20:05.940443  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000778107 (* 1 = 0.000778107 loss)
I0627 10:20:05.940446  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00340021 (* 1 = 0.00340021 loss)
I0627 10:20:05.940451  4216 sgd_solver.cpp:106] Iteration 31600, lr = 2e-05
I0627 10:21:52.197255  4216 solver.cpp:228] Iteration 31620, loss = 0.259923
I0627 10:21:52.197278  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0627 10:21:52.197284  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.335725 (* 1 = 0.335725 loss)
I0627 10:21:52.197288  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.589977 (* 1 = 0.589977 loss)
I0627 10:21:52.197291  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136163 (* 1 = 0.0136163 loss)
I0627 10:21:52.197295  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.088032 (* 1 = 0.088032 loss)
I0627 10:21:52.197300  4216 sgd_solver.cpp:106] Iteration 31620, lr = 2e-05
I0627 10:23:37.757936  4216 solver.cpp:228] Iteration 31640, loss = 0.114402
I0627 10:23:37.757966  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:23:37.757973  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178424 (* 1 = 0.0178424 loss)
I0627 10:23:37.757978  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0144065 (* 1 = 0.0144065 loss)
I0627 10:23:37.757982  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.73234e-05 (* 1 = 9.73234e-05 loss)
I0627 10:23:37.757987  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128674 (* 1 = 0.0128674 loss)
I0627 10:23:37.757992  4216 sgd_solver.cpp:106] Iteration 31640, lr = 2e-05
I0627 10:25:24.508901  4216 solver.cpp:228] Iteration 31660, loss = 0.0812333
I0627 10:25:24.508929  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:25:24.508936  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174761 (* 1 = 0.0174761 loss)
I0627 10:25:24.508940  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0295921 (* 1 = 0.0295921 loss)
I0627 10:25:24.508945  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000241556 (* 1 = 0.000241556 loss)
I0627 10:25:24.508949  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00519163 (* 1 = 0.00519163 loss)
I0627 10:25:24.508955  4216 sgd_solver.cpp:106] Iteration 31660, lr = 2e-05
I0627 10:27:10.442353  4216 solver.cpp:228] Iteration 31680, loss = 0.205238
I0627 10:27:10.442379  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 10:27:10.442386  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319768 (* 1 = 0.0319768 loss)
I0627 10:27:10.442390  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0701734 (* 1 = 0.0701734 loss)
I0627 10:27:10.442394  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000137188 (* 1 = 0.000137188 loss)
I0627 10:27:10.442399  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108474 (* 1 = 0.0108474 loss)
I0627 10:27:10.442404  4216 sgd_solver.cpp:106] Iteration 31680, lr = 2e-05
I0627 10:28:57.204795  4216 solver.cpp:228] Iteration 31700, loss = 0.169922
I0627 10:28:57.204819  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0627 10:28:57.204826  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.355445 (* 1 = 0.355445 loss)
I0627 10:28:57.204830  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.364543 (* 1 = 0.364543 loss)
I0627 10:28:57.204834  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314483 (* 1 = 0.00314483 loss)
I0627 10:28:57.204838  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681584 (* 1 = 0.0681584 loss)
I0627 10:28:57.204843  4216 sgd_solver.cpp:106] Iteration 31700, lr = 2e-05
I0627 10:30:44.122683  4216 solver.cpp:228] Iteration 31720, loss = 0.139842
I0627 10:30:44.122707  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:30:44.122715  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251505 (* 1 = 0.0251505 loss)
I0627 10:30:44.122720  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0421565 (* 1 = 0.0421565 loss)
I0627 10:30:44.122725  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000200605 (* 1 = 0.000200605 loss)
I0627 10:30:44.122727  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00842717 (* 1 = 0.00842717 loss)
I0627 10:30:44.122732  4216 sgd_solver.cpp:106] Iteration 31720, lr = 2e-05
I0627 10:32:30.941102  4216 solver.cpp:228] Iteration 31740, loss = 0.123407
I0627 10:32:30.941128  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:32:30.941135  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198038 (* 1 = 0.0198038 loss)
I0627 10:32:30.941139  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0222925 (* 1 = 0.0222925 loss)
I0627 10:32:30.941143  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305205 (* 1 = 0.00305205 loss)
I0627 10:32:30.941146  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00914349 (* 1 = 0.00914349 loss)
I0627 10:32:30.941151  4216 sgd_solver.cpp:106] Iteration 31740, lr = 2e-05
I0627 10:34:17.429641  4216 solver.cpp:228] Iteration 31760, loss = 0.139758
I0627 10:34:17.429669  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 10:34:17.429677  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739953 (* 1 = 0.0739953 loss)
I0627 10:34:17.429682  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.179971 (* 1 = 0.179971 loss)
I0627 10:34:17.429687  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114783 (* 1 = 0.0114783 loss)
I0627 10:34:17.429692  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177465 (* 1 = 0.0177465 loss)
I0627 10:34:17.429698  4216 sgd_solver.cpp:106] Iteration 31760, lr = 2e-05
I0627 10:36:03.557073  4216 solver.cpp:228] Iteration 31780, loss = 0.165385
I0627 10:36:03.557099  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 10:36:03.557106  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0598583 (* 1 = 0.0598583 loss)
I0627 10:36:03.557111  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.138255 (* 1 = 0.138255 loss)
I0627 10:36:03.557114  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010933 (* 1 = 0.010933 loss)
I0627 10:36:03.557118  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146809 (* 1 = 0.0146809 loss)
I0627 10:36:03.557123  4216 sgd_solver.cpp:106] Iteration 31780, lr = 2e-05
speed: 5.286s / iter
I0627 10:37:50.098078  4216 solver.cpp:228] Iteration 31800, loss = 0.192094
I0627 10:37:50.098105  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 10:37:50.098115  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00912647 (* 1 = 0.00912647 loss)
I0627 10:37:50.098124  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0643217 (* 1 = 0.0643217 loss)
I0627 10:37:50.098129  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218858 (* 1 = 0.00218858 loss)
I0627 10:37:50.098137  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.151494 (* 1 = 0.151494 loss)
I0627 10:37:50.098147  4216 sgd_solver.cpp:106] Iteration 31800, lr = 2e-05
I0627 10:39:37.101104  4216 solver.cpp:228] Iteration 31820, loss = 0.179735
I0627 10:39:37.101126  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 10:39:37.101135  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0818166 (* 1 = 0.0818166 loss)
I0627 10:39:37.101138  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.109101 (* 1 = 0.109101 loss)
I0627 10:39:37.101142  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000760864 (* 1 = 0.000760864 loss)
I0627 10:39:37.101145  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239579 (* 1 = 0.0239579 loss)
I0627 10:39:37.101150  4216 sgd_solver.cpp:106] Iteration 31820, lr = 2e-05
I0627 10:41:24.530622  4216 solver.cpp:228] Iteration 31840, loss = 0.114066
I0627 10:41:24.530647  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:41:24.530652  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0158696 (* 1 = 0.0158696 loss)
I0627 10:41:24.530656  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.020584 (* 1 = 0.020584 loss)
I0627 10:41:24.530660  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.40171e-05 (* 1 = 6.40171e-05 loss)
I0627 10:41:24.530664  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00197106 (* 1 = 0.00197106 loss)
I0627 10:41:24.530669  4216 sgd_solver.cpp:106] Iteration 31840, lr = 2e-05
I0627 10:43:11.593883  4216 solver.cpp:228] Iteration 31860, loss = 0.081657
I0627 10:43:11.593909  4216 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:43:11.593916  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.00863484 (* 1 = 0.00863484 loss)
I0627 10:43:11.593921  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.00359513 (* 1 = 0.00359513 loss)
I0627 10:43:11.593925  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.67368e-05 (* 1 = 9.67368e-05 loss)
I0627 10:43:11.593928  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00384631 (* 1 = 0.00384631 loss)
I0627 10:43:11.593933  4216 sgd_solver.cpp:106] Iteration 31860, lr = 2e-05
I0627 10:44:58.759660  4216 solver.cpp:228] Iteration 31880, loss = 0.14188
I0627 10:44:58.759683  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 10:44:58.759690  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0414536 (* 1 = 0.0414536 loss)
I0627 10:44:58.759696  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.101292 (* 1 = 0.101292 loss)
I0627 10:44:58.759698  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00826403 (* 1 = 0.00826403 loss)
I0627 10:44:58.759702  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0343466 (* 1 = 0.0343466 loss)
I0627 10:44:58.759707  4216 sgd_solver.cpp:106] Iteration 31880, lr = 2e-05
I0627 10:46:47.883131  4216 solver.cpp:228] Iteration 31900, loss = 0.203496
I0627 10:46:47.883154  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 10:46:47.883162  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.125177 (* 1 = 0.125177 loss)
I0627 10:46:47.883167  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.204688 (* 1 = 0.204688 loss)
I0627 10:46:47.883172  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111566 (* 1 = 0.0111566 loss)
I0627 10:46:47.883175  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163985 (* 1 = 0.0163985 loss)
I0627 10:46:47.883179  4216 sgd_solver.cpp:106] Iteration 31900, lr = 2e-05
I0627 10:48:34.291167  4216 solver.cpp:228] Iteration 31920, loss = 0.117798
I0627 10:48:34.291198  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:48:34.291205  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0141537 (* 1 = 0.0141537 loss)
I0627 10:48:34.291209  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0215473 (* 1 = 0.0215473 loss)
I0627 10:48:34.291213  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000136347 (* 1 = 0.000136347 loss)
I0627 10:48:34.291218  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322893 (* 1 = 0.00322893 loss)
I0627 10:48:34.291223  4216 sgd_solver.cpp:106] Iteration 31920, lr = 2e-05
I0627 10:50:22.347620  4216 solver.cpp:228] Iteration 31940, loss = 0.185915
I0627 10:50:22.347643  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:50:22.347652  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229386 (* 1 = 0.0229386 loss)
I0627 10:50:22.347658  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0246284 (* 1 = 0.0246284 loss)
I0627 10:50:22.347664  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000568213 (* 1 = 0.000568213 loss)
I0627 10:50:22.347669  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00281557 (* 1 = 0.00281557 loss)
I0627 10:50:22.347676  4216 sgd_solver.cpp:106] Iteration 31940, lr = 2e-05
I0627 10:52:09.143606  4216 solver.cpp:228] Iteration 31960, loss = 0.0716619
I0627 10:52:09.143630  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:52:09.143637  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308274 (* 1 = 0.0308274 loss)
I0627 10:52:09.143641  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0259421 (* 1 = 0.0259421 loss)
I0627 10:52:09.143646  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000412521 (* 1 = 0.000412521 loss)
I0627 10:52:09.143649  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00611023 (* 1 = 0.00611023 loss)
I0627 10:52:09.143653  4216 sgd_solver.cpp:106] Iteration 31960, lr = 2e-05
I0627 10:53:55.987139  4216 solver.cpp:228] Iteration 31980, loss = 0.117591
I0627 10:53:55.987164  4216 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:53:55.987171  4216 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440864 (* 1 = 0.0440864 loss)
I0627 10:53:55.987176  4216 solver.cpp:244]     Train net output #2: loss_cls = 0.0565317 (* 1 = 0.0565317 loss)
I0627 10:53:55.987180  4216 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125394 (* 1 = 0.0125394 loss)
I0627 10:53:55.987185  4216 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01443 (* 1 = 0.01443 loss)
I0627 10:53:55.987190  4216 sgd_solver.cpp:106] Iteration 31980, lr = 2e-05
speed: 5.286s / iter
I0627 10:55:37.181599  4216 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_32000.caffemodel
done solving

real	2819m37.143s
user	2336m23.236s
sys	505m55.972s
+ set +x
+ ./tools/test_net.py --gpu 0 --def experiments/6_25_head/test_agnostic.prototxt --net /home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_32000.caffemodel --imdb voc_0712_test --cfg experiments/6_25_head/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='/home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_32000.caffemodel', cfg_file='experiments/6_25_head/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=0, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/6_25_head/test_agnostic.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py_R_FCN_6_25/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '6_25_head/model',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py_R_FCN_6_25/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py_R_FCN_6_25',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SOFT_NMS': 0,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0627 10:55:38.901388 25648 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0627 10:55:38.901410 25648 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0627 10:55:38.901412 25648 _caffe.cpp:125] Net('experiments/6_25_head/test_agnostic.prototxt', 1, weights='/home/user/Disk1.8T/py_R_FCN_6_25/experiments/6_25_head/model/resnet50_rfcn_ohem_iter_32000.caffemodel')
I0627 10:55:38.915333 25648 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/6_25_head/test_agnostic.prototxt
I0627 10:55:38.915555 25648 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0627 10:55:38.915560 25648 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0627 10:55:38.916836 25648 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "r
I0627 10:55:38.918855 25648 layer_factory.hpp:77] Creating layer input
I0627 10:55:38.918895 25648 net.cpp:100] Creating Layer input
I0627 10:55:38.918902 25648 net.cpp:418] input -> data
I0627 10:55:38.918939 25648 net.cpp:418] input -> im_info
I0627 10:55:38.941023 25648 net.cpp:150] Setting up input
I0627 10:55:38.941054 25648 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0627 10:55:38.941059 25648 net.cpp:157] Top shape: 1 3 (3)
I0627 10:55:38.941061 25648 net.cpp:165] Memory required for data: 602124
I0627 10:55:38.941081 25648 layer_factory.hpp:77] Creating layer conv1
I0627 10:55:38.941131 25648 net.cpp:100] Creating Layer conv1
I0627 10:55:38.941143 25648 net.cpp:444] conv1 <- data
I0627 10:55:38.941165 25648 net.cpp:418] conv1 -> conv1
I0627 10:55:39.269372 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 225816
I0627 10:55:39.269594 25648 net.cpp:150] Setting up conv1
I0627 10:55:39.269615 25648 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:55:39.269618 25648 net.cpp:165] Memory required for data: 3813388
I0627 10:55:39.269670 25648 layer_factory.hpp:77] Creating layer bn_conv1
I0627 10:55:39.269701 25648 net.cpp:100] Creating Layer bn_conv1
I0627 10:55:39.269711 25648 net.cpp:444] bn_conv1 <- conv1
I0627 10:55:39.269726 25648 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0627 10:55:39.269907 25648 net.cpp:150] Setting up bn_conv1
I0627 10:55:39.269913 25648 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:55:39.269917 25648 net.cpp:165] Memory required for data: 7024652
I0627 10:55:39.269943 25648 layer_factory.hpp:77] Creating layer scale_conv1
I0627 10:55:39.269960 25648 net.cpp:100] Creating Layer scale_conv1
I0627 10:55:39.269965 25648 net.cpp:444] scale_conv1 <- conv1
I0627 10:55:39.269976 25648 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0627 10:55:39.270025 25648 layer_factory.hpp:77] Creating layer scale_conv1
I0627 10:55:39.270174 25648 net.cpp:150] Setting up scale_conv1
I0627 10:55:39.270181 25648 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:55:39.270184 25648 net.cpp:165] Memory required for data: 10235916
I0627 10:55:39.270193 25648 layer_factory.hpp:77] Creating layer conv1_relu
I0627 10:55:39.270207 25648 net.cpp:100] Creating Layer conv1_relu
I0627 10:55:39.270213 25648 net.cpp:444] conv1_relu <- conv1
I0627 10:55:39.270225 25648 net.cpp:405] conv1_relu -> conv1 (in-place)
I0627 10:55:39.270370 25648 net.cpp:150] Setting up conv1_relu
I0627 10:55:39.270377 25648 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:55:39.270380 25648 net.cpp:165] Memory required for data: 13447180
I0627 10:55:39.270385 25648 layer_factory.hpp:77] Creating layer pool1
I0627 10:55:39.270401 25648 net.cpp:100] Creating Layer pool1
I0627 10:55:39.270406 25648 net.cpp:444] pool1 <- conv1
I0627 10:55:39.270423 25648 net.cpp:418] pool1 -> pool1
I0627 10:55:39.270473 25648 net.cpp:150] Setting up pool1
I0627 10:55:39.270483 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.270486 25648 net.cpp:165] Memory required for data: 14249996
I0627 10:55:39.270490 25648 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0627 10:55:39.270503 25648 net.cpp:100] Creating Layer pool1_pool1_0_split
I0627 10:55:39.270509 25648 net.cpp:444] pool1_pool1_0_split <- pool1
I0627 10:55:39.270524 25648 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0627 10:55:39.270543 25648 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0627 10:55:39.270582 25648 net.cpp:150] Setting up pool1_pool1_0_split
I0627 10:55:39.270592 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.270598 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.270601 25648 net.cpp:165] Memory required for data: 15855628
I0627 10:55:39.270606 25648 layer_factory.hpp:77] Creating layer res2a_branch1
I0627 10:55:39.270623 25648 net.cpp:100] Creating Layer res2a_branch1
I0627 10:55:39.270628 25648 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0627 10:55:39.270643 25648 net.cpp:418] res2a_branch1 -> res2a_branch1
I0627 10:55:39.271445 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.271463 25648 net.cpp:150] Setting up res2a_branch1
I0627 10:55:39.271472 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.271476 25648 net.cpp:165] Memory required for data: 19066892
I0627 10:55:39.271488 25648 layer_factory.hpp:77] Creating layer bn2a_branch1
I0627 10:55:39.271507 25648 net.cpp:100] Creating Layer bn2a_branch1
I0627 10:55:39.271512 25648 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0627 10:55:39.271526 25648 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0627 10:55:39.272251 25648 net.cpp:150] Setting up bn2a_branch1
I0627 10:55:39.272260 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.272262 25648 net.cpp:165] Memory required for data: 22278156
I0627 10:55:39.272291 25648 layer_factory.hpp:77] Creating layer scale2a_branch1
I0627 10:55:39.272306 25648 net.cpp:100] Creating Layer scale2a_branch1
I0627 10:55:39.272312 25648 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0627 10:55:39.272325 25648 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0627 10:55:39.272372 25648 layer_factory.hpp:77] Creating layer scale2a_branch1
I0627 10:55:39.272492 25648 net.cpp:150] Setting up scale2a_branch1
I0627 10:55:39.272501 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.272503 25648 net.cpp:165] Memory required for data: 25489420
I0627 10:55:39.272516 25648 layer_factory.hpp:77] Creating layer res2a_branch2a
I0627 10:55:39.272532 25648 net.cpp:100] Creating Layer res2a_branch2a
I0627 10:55:39.272541 25648 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0627 10:55:39.272557 25648 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0627 10:55:39.273344 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.273361 25648 net.cpp:150] Setting up res2a_branch2a
I0627 10:55:39.273371 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.273375 25648 net.cpp:165] Memory required for data: 26292236
I0627 10:55:39.273386 25648 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0627 10:55:39.273402 25648 net.cpp:100] Creating Layer bn2a_branch2a
I0627 10:55:39.273409 25648 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0627 10:55:39.273427 25648 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0627 10:55:39.273584 25648 net.cpp:150] Setting up bn2a_branch2a
I0627 10:55:39.273591 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.273596 25648 net.cpp:165] Memory required for data: 27095052
I0627 10:55:39.273623 25648 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0627 10:55:39.273638 25648 net.cpp:100] Creating Layer scale2a_branch2a
I0627 10:55:39.273643 25648 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0627 10:55:39.273655 25648 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0627 10:55:39.273701 25648 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0627 10:55:39.273820 25648 net.cpp:150] Setting up scale2a_branch2a
I0627 10:55:39.273828 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.273831 25648 net.cpp:165] Memory required for data: 27897868
I0627 10:55:39.273842 25648 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0627 10:55:39.273854 25648 net.cpp:100] Creating Layer res2a_branch2a_relu
I0627 10:55:39.273861 25648 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0627 10:55:39.273874 25648 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0627 10:55:39.274019 25648 net.cpp:150] Setting up res2a_branch2a_relu
I0627 10:55:39.274026 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.274030 25648 net.cpp:165] Memory required for data: 28700684
I0627 10:55:39.274037 25648 layer_factory.hpp:77] Creating layer res2a_branch2b
I0627 10:55:39.274055 25648 net.cpp:100] Creating Layer res2a_branch2b
I0627 10:55:39.274061 25648 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0627 10:55:39.274078 25648 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0627 10:55:39.275496 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0627 10:55:39.275712 25648 net.cpp:150] Setting up res2a_branch2b
I0627 10:55:39.275727 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.275730 25648 net.cpp:165] Memory required for data: 29503500
I0627 10:55:39.275744 25648 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0627 10:55:39.275761 25648 net.cpp:100] Creating Layer bn2a_branch2b
I0627 10:55:39.275768 25648 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0627 10:55:39.275786 25648 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0627 10:55:39.275964 25648 net.cpp:150] Setting up bn2a_branch2b
I0627 10:55:39.275970 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.275974 25648 net.cpp:165] Memory required for data: 30306316
I0627 10:55:39.275993 25648 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0627 10:55:39.276015 25648 net.cpp:100] Creating Layer scale2a_branch2b
I0627 10:55:39.276022 25648 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0627 10:55:39.276038 25648 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0627 10:55:39.276090 25648 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0627 10:55:39.276222 25648 net.cpp:150] Setting up scale2a_branch2b
I0627 10:55:39.276230 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.276234 25648 net.cpp:165] Memory required for data: 31109132
I0627 10:55:39.276247 25648 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0627 10:55:39.276260 25648 net.cpp:100] Creating Layer res2a_branch2b_relu
I0627 10:55:39.276266 25648 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0627 10:55:39.276281 25648 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0627 10:55:39.276639 25648 net.cpp:150] Setting up res2a_branch2b_relu
I0627 10:55:39.276649 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.276652 25648 net.cpp:165] Memory required for data: 31911948
I0627 10:55:39.276656 25648 layer_factory.hpp:77] Creating layer res2a_branch2c
I0627 10:55:39.276674 25648 net.cpp:100] Creating Layer res2a_branch2c
I0627 10:55:39.276679 25648 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0627 10:55:39.276695 25648 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0627 10:55:39.277547 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.277564 25648 net.cpp:150] Setting up res2a_branch2c
I0627 10:55:39.277572 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.277575 25648 net.cpp:165] Memory required for data: 35123212
I0627 10:55:39.277586 25648 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0627 10:55:39.277602 25648 net.cpp:100] Creating Layer bn2a_branch2c
I0627 10:55:39.277608 25648 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0627 10:55:39.277623 25648 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0627 10:55:39.277791 25648 net.cpp:150] Setting up bn2a_branch2c
I0627 10:55:39.277797 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.277799 25648 net.cpp:165] Memory required for data: 38334476
I0627 10:55:39.277815 25648 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0627 10:55:39.277829 25648 net.cpp:100] Creating Layer scale2a_branch2c
I0627 10:55:39.277835 25648 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0627 10:55:39.277846 25648 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0627 10:55:39.277894 25648 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0627 10:55:39.278015 25648 net.cpp:150] Setting up scale2a_branch2c
I0627 10:55:39.278023 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.278025 25648 net.cpp:165] Memory required for data: 41545740
I0627 10:55:39.278035 25648 layer_factory.hpp:77] Creating layer res2a
I0627 10:55:39.278048 25648 net.cpp:100] Creating Layer res2a
I0627 10:55:39.278053 25648 net.cpp:444] res2a <- res2a_branch1
I0627 10:55:39.278061 25648 net.cpp:444] res2a <- res2a_branch2c
I0627 10:55:39.278069 25648 net.cpp:418] res2a -> res2a
I0627 10:55:39.278103 25648 net.cpp:150] Setting up res2a
I0627 10:55:39.278111 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.278115 25648 net.cpp:165] Memory required for data: 44757004
I0627 10:55:39.278118 25648 layer_factory.hpp:77] Creating layer res2a_relu
I0627 10:55:39.278127 25648 net.cpp:100] Creating Layer res2a_relu
I0627 10:55:39.278131 25648 net.cpp:444] res2a_relu <- res2a
I0627 10:55:39.278143 25648 net.cpp:405] res2a_relu -> res2a (in-place)
I0627 10:55:39.278291 25648 net.cpp:150] Setting up res2a_relu
I0627 10:55:39.278298 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.278301 25648 net.cpp:165] Memory required for data: 47968268
I0627 10:55:39.278303 25648 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0627 10:55:39.278313 25648 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0627 10:55:39.278318 25648 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0627 10:55:39.278331 25648 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0627 10:55:39.278345 25648 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0627 10:55:39.278384 25648 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0627 10:55:39.278393 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.278398 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.278399 25648 net.cpp:165] Memory required for data: 54390796
I0627 10:55:39.278403 25648 layer_factory.hpp:77] Creating layer res2b_branch2a
I0627 10:55:39.278415 25648 net.cpp:100] Creating Layer res2b_branch2a
I0627 10:55:39.278420 25648 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0627 10:55:39.278434 25648 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0627 10:55:39.279275 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.279291 25648 net.cpp:150] Setting up res2b_branch2a
I0627 10:55:39.279299 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.279302 25648 net.cpp:165] Memory required for data: 55193612
I0627 10:55:39.279312 25648 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0627 10:55:39.279327 25648 net.cpp:100] Creating Layer bn2b_branch2a
I0627 10:55:39.279333 25648 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0627 10:55:39.279348 25648 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0627 10:55:39.279517 25648 net.cpp:150] Setting up bn2b_branch2a
I0627 10:55:39.279525 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.279526 25648 net.cpp:165] Memory required for data: 55996428
I0627 10:55:39.279553 25648 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0627 10:55:39.279569 25648 net.cpp:100] Creating Layer scale2b_branch2a
I0627 10:55:39.279574 25648 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0627 10:55:39.279587 25648 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0627 10:55:39.279634 25648 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0627 10:55:39.279762 25648 net.cpp:150] Setting up scale2b_branch2a
I0627 10:55:39.279769 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.279772 25648 net.cpp:165] Memory required for data: 56799244
I0627 10:55:39.279781 25648 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0627 10:55:39.279791 25648 net.cpp:100] Creating Layer res2b_branch2a_relu
I0627 10:55:39.279796 25648 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0627 10:55:39.279806 25648 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0627 10:55:39.279954 25648 net.cpp:150] Setting up res2b_branch2a_relu
I0627 10:55:39.279963 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.279964 25648 net.cpp:165] Memory required for data: 57602060
I0627 10:55:39.279968 25648 layer_factory.hpp:77] Creating layer res2b_branch2b
I0627 10:55:39.279981 25648 net.cpp:100] Creating Layer res2b_branch2b
I0627 10:55:39.279987 25648 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0627 10:55:39.280001 25648 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0627 10:55:39.280913 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0627 10:55:39.280930 25648 net.cpp:150] Setting up res2b_branch2b
I0627 10:55:39.280937 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.280941 25648 net.cpp:165] Memory required for data: 58404876
I0627 10:55:39.280951 25648 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0627 10:55:39.280967 25648 net.cpp:100] Creating Layer bn2b_branch2b
I0627 10:55:39.280974 25648 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0627 10:55:39.280988 25648 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0627 10:55:39.281165 25648 net.cpp:150] Setting up bn2b_branch2b
I0627 10:55:39.281172 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.281174 25648 net.cpp:165] Memory required for data: 59207692
I0627 10:55:39.281190 25648 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0627 10:55:39.281203 25648 net.cpp:100] Creating Layer scale2b_branch2b
I0627 10:55:39.281208 25648 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0627 10:55:39.281219 25648 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0627 10:55:39.281268 25648 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0627 10:55:39.281400 25648 net.cpp:150] Setting up scale2b_branch2b
I0627 10:55:39.281407 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.281409 25648 net.cpp:165] Memory required for data: 60010508
I0627 10:55:39.281420 25648 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0627 10:55:39.281430 25648 net.cpp:100] Creating Layer res2b_branch2b_relu
I0627 10:55:39.281433 25648 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0627 10:55:39.281446 25648 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0627 10:55:39.281827 25648 net.cpp:150] Setting up res2b_branch2b_relu
I0627 10:55:39.281836 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.281839 25648 net.cpp:165] Memory required for data: 60813324
I0627 10:55:39.281843 25648 layer_factory.hpp:77] Creating layer res2b_branch2c
I0627 10:55:39.281869 25648 net.cpp:100] Creating Layer res2b_branch2c
I0627 10:55:39.281879 25648 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0627 10:55:39.281898 25648 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0627 10:55:39.282886 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.282912 25648 net.cpp:150] Setting up res2b_branch2c
I0627 10:55:39.282924 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.282929 25648 net.cpp:165] Memory required for data: 64024588
I0627 10:55:39.282948 25648 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0627 10:55:39.282970 25648 net.cpp:100] Creating Layer bn2b_branch2c
I0627 10:55:39.282981 25648 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0627 10:55:39.283005 25648 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0627 10:55:39.283210 25648 net.cpp:150] Setting up bn2b_branch2c
I0627 10:55:39.283219 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.283223 25648 net.cpp:165] Memory required for data: 67235852
I0627 10:55:39.283244 25648 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0627 10:55:39.283263 25648 net.cpp:100] Creating Layer scale2b_branch2c
I0627 10:55:39.283270 25648 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0627 10:55:39.283288 25648 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0627 10:55:39.283345 25648 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0627 10:55:39.283501 25648 net.cpp:150] Setting up scale2b_branch2c
I0627 10:55:39.283510 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.283514 25648 net.cpp:165] Memory required for data: 70447116
I0627 10:55:39.283529 25648 layer_factory.hpp:77] Creating layer res2b
I0627 10:55:39.283545 25648 net.cpp:100] Creating Layer res2b
I0627 10:55:39.283551 25648 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0627 10:55:39.283565 25648 net.cpp:444] res2b <- res2b_branch2c
I0627 10:55:39.283581 25648 net.cpp:418] res2b -> res2b
I0627 10:55:39.283632 25648 net.cpp:150] Setting up res2b
I0627 10:55:39.283643 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.283648 25648 net.cpp:165] Memory required for data: 73658380
I0627 10:55:39.283653 25648 layer_factory.hpp:77] Creating layer res2b_relu
I0627 10:55:39.283668 25648 net.cpp:100] Creating Layer res2b_relu
I0627 10:55:39.283674 25648 net.cpp:444] res2b_relu <- res2b
I0627 10:55:39.283689 25648 net.cpp:405] res2b_relu -> res2b (in-place)
I0627 10:55:39.283870 25648 net.cpp:150] Setting up res2b_relu
I0627 10:55:39.283879 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.283884 25648 net.cpp:165] Memory required for data: 76869644
I0627 10:55:39.283890 25648 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0627 10:55:39.283905 25648 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0627 10:55:39.283911 25648 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0627 10:55:39.283928 25648 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0627 10:55:39.283947 25648 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0627 10:55:39.283996 25648 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0627 10:55:39.284006 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.284013 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.284018 25648 net.cpp:165] Memory required for data: 83292172
I0627 10:55:39.284024 25648 layer_factory.hpp:77] Creating layer res2c_branch2a
I0627 10:55:39.284044 25648 net.cpp:100] Creating Layer res2c_branch2a
I0627 10:55:39.284050 25648 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0627 10:55:39.284070 25648 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0627 10:55:39.285034 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.285056 25648 net.cpp:150] Setting up res2c_branch2a
I0627 10:55:39.285068 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.285073 25648 net.cpp:165] Memory required for data: 84094988
I0627 10:55:39.285087 25648 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0627 10:55:39.285107 25648 net.cpp:100] Creating Layer bn2c_branch2a
I0627 10:55:39.285115 25648 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0627 10:55:39.285135 25648 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0627 10:55:39.285323 25648 net.cpp:150] Setting up bn2c_branch2a
I0627 10:55:39.285331 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.285336 25648 net.cpp:165] Memory required for data: 84897804
I0627 10:55:39.285354 25648 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0627 10:55:39.285372 25648 net.cpp:100] Creating Layer scale2c_branch2a
I0627 10:55:39.285379 25648 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0627 10:55:39.285396 25648 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0627 10:55:39.285454 25648 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0627 10:55:39.285596 25648 net.cpp:150] Setting up scale2c_branch2a
I0627 10:55:39.285604 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.285609 25648 net.cpp:165] Memory required for data: 85700620
I0627 10:55:39.285622 25648 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0627 10:55:39.285636 25648 net.cpp:100] Creating Layer res2c_branch2a_relu
I0627 10:55:39.285643 25648 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0627 10:55:39.285660 25648 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0627 10:55:39.285815 25648 net.cpp:150] Setting up res2c_branch2a_relu
I0627 10:55:39.285825 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.285827 25648 net.cpp:165] Memory required for data: 86503436
I0627 10:55:39.285833 25648 layer_factory.hpp:77] Creating layer res2c_branch2b
I0627 10:55:39.285852 25648 net.cpp:100] Creating Layer res2c_branch2b
I0627 10:55:39.285861 25648 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0627 10:55:39.285881 25648 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0627 10:55:39.286824 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0627 10:55:39.287061 25648 net.cpp:150] Setting up res2c_branch2b
I0627 10:55:39.287077 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.287082 25648 net.cpp:165] Memory required for data: 87306252
I0627 10:55:39.287097 25648 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0627 10:55:39.287117 25648 net.cpp:100] Creating Layer bn2c_branch2b
I0627 10:55:39.287125 25648 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0627 10:55:39.287145 25648 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0627 10:55:39.287338 25648 net.cpp:150] Setting up bn2c_branch2b
I0627 10:55:39.287345 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.287348 25648 net.cpp:165] Memory required for data: 88109068
I0627 10:55:39.287369 25648 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0627 10:55:39.287385 25648 net.cpp:100] Creating Layer scale2c_branch2b
I0627 10:55:39.287392 25648 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0627 10:55:39.287410 25648 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0627 10:55:39.287467 25648 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0627 10:55:39.287606 25648 net.cpp:150] Setting up scale2c_branch2b
I0627 10:55:39.287616 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.287618 25648 net.cpp:165] Memory required for data: 88911884
I0627 10:55:39.287632 25648 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0627 10:55:39.287647 25648 net.cpp:100] Creating Layer res2c_branch2b_relu
I0627 10:55:39.287654 25648 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0627 10:55:39.287669 25648 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0627 10:55:39.287832 25648 net.cpp:150] Setting up res2c_branch2b_relu
I0627 10:55:39.287839 25648 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:55:39.287843 25648 net.cpp:165] Memory required for data: 89714700
I0627 10:55:39.287848 25648 layer_factory.hpp:77] Creating layer res2c_branch2c
I0627 10:55:39.287868 25648 net.cpp:100] Creating Layer res2c_branch2c
I0627 10:55:39.287876 25648 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0627 10:55:39.287894 25648 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0627 10:55:39.288770 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:55:39.288792 25648 net.cpp:150] Setting up res2c_branch2c
I0627 10:55:39.288803 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.288807 25648 net.cpp:165] Memory required for data: 92925964
I0627 10:55:39.288820 25648 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0627 10:55:39.288836 25648 net.cpp:100] Creating Layer bn2c_branch2c
I0627 10:55:39.288844 25648 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0627 10:55:39.288863 25648 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0627 10:55:39.289041 25648 net.cpp:150] Setting up bn2c_branch2c
I0627 10:55:39.289048 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.289052 25648 net.cpp:165] Memory required for data: 96137228
I0627 10:55:39.289090 25648 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0627 10:55:39.289108 25648 net.cpp:100] Creating Layer scale2c_branch2c
I0627 10:55:39.289115 25648 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0627 10:55:39.289132 25648 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0627 10:55:39.289187 25648 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0627 10:55:39.289322 25648 net.cpp:150] Setting up scale2c_branch2c
I0627 10:55:39.289330 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.289335 25648 net.cpp:165] Memory required for data: 99348492
I0627 10:55:39.289348 25648 layer_factory.hpp:77] Creating layer res2c
I0627 10:55:39.289362 25648 net.cpp:100] Creating Layer res2c
I0627 10:55:39.289369 25648 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0627 10:55:39.289382 25648 net.cpp:444] res2c <- res2c_branch2c
I0627 10:55:39.289396 25648 net.cpp:418] res2c -> res2c
I0627 10:55:39.289433 25648 net.cpp:150] Setting up res2c
I0627 10:55:39.289443 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.289448 25648 net.cpp:165] Memory required for data: 102559756
I0627 10:55:39.289453 25648 layer_factory.hpp:77] Creating layer res2c_relu
I0627 10:55:39.289464 25648 net.cpp:100] Creating Layer res2c_relu
I0627 10:55:39.289470 25648 net.cpp:444] res2c_relu <- res2c
I0627 10:55:39.289486 25648 net.cpp:405] res2c_relu -> res2c (in-place)
I0627 10:55:39.289854 25648 net.cpp:150] Setting up res2c_relu
I0627 10:55:39.289865 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.289870 25648 net.cpp:165] Memory required for data: 105771020
I0627 10:55:39.289877 25648 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0627 10:55:39.289891 25648 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0627 10:55:39.289898 25648 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0627 10:55:39.289917 25648 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0627 10:55:39.289937 25648 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0627 10:55:39.289986 25648 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0627 10:55:39.289996 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.290004 25648 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:55:39.290009 25648 net.cpp:165] Memory required for data: 112193548
I0627 10:55:39.290014 25648 layer_factory.hpp:77] Creating layer res3a_branch1
I0627 10:55:39.290032 25648 net.cpp:100] Creating Layer res3a_branch1
I0627 10:55:39.290040 25648 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0627 10:55:39.290057 25648 net.cpp:418] res3a_branch1 -> res3a_branch1
I0627 10:55:39.291693 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0627 10:55:39.291919 25648 net.cpp:150] Setting up res3a_branch1
I0627 10:55:39.291932 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.291937 25648 net.cpp:165] Memory required for data: 113799180
I0627 10:55:39.291952 25648 layer_factory.hpp:77] Creating layer bn3a_branch1
I0627 10:55:39.291971 25648 net.cpp:100] Creating Layer bn3a_branch1
I0627 10:55:39.291980 25648 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0627 10:55:39.291997 25648 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0627 10:55:39.292752 25648 net.cpp:150] Setting up bn3a_branch1
I0627 10:55:39.292763 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.292767 25648 net.cpp:165] Memory required for data: 115404812
I0627 10:55:39.292788 25648 layer_factory.hpp:77] Creating layer scale3a_branch1
I0627 10:55:39.292809 25648 net.cpp:100] Creating Layer scale3a_branch1
I0627 10:55:39.292815 25648 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0627 10:55:39.292832 25648 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0627 10:55:39.292896 25648 layer_factory.hpp:77] Creating layer scale3a_branch1
I0627 10:55:39.293025 25648 net.cpp:150] Setting up scale3a_branch1
I0627 10:55:39.293033 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.293036 25648 net.cpp:165] Memory required for data: 117010444
I0627 10:55:39.293051 25648 layer_factory.hpp:77] Creating layer res3a_branch2a
I0627 10:55:39.293071 25648 net.cpp:100] Creating Layer res3a_branch2a
I0627 10:55:39.293079 25648 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0627 10:55:39.293098 25648 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0627 10:55:39.294041 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0627 10:55:39.294064 25648 net.cpp:150] Setting up res3a_branch2a
I0627 10:55:39.294075 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.294080 25648 net.cpp:165] Memory required for data: 117411852
I0627 10:55:39.294093 25648 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0627 10:55:39.294111 25648 net.cpp:100] Creating Layer bn3a_branch2a
I0627 10:55:39.294119 25648 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0627 10:55:39.294138 25648 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0627 10:55:39.294315 25648 net.cpp:150] Setting up bn3a_branch2a
I0627 10:55:39.294323 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.294327 25648 net.cpp:165] Memory required for data: 117813260
I0627 10:55:39.294347 25648 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0627 10:55:39.294363 25648 net.cpp:100] Creating Layer scale3a_branch2a
I0627 10:55:39.294370 25648 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0627 10:55:39.294386 25648 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0627 10:55:39.294440 25648 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0627 10:55:39.294570 25648 net.cpp:150] Setting up scale3a_branch2a
I0627 10:55:39.294579 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.294582 25648 net.cpp:165] Memory required for data: 118214668
I0627 10:55:39.294595 25648 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0627 10:55:39.294610 25648 net.cpp:100] Creating Layer res3a_branch2a_relu
I0627 10:55:39.294617 25648 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0627 10:55:39.294633 25648 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0627 10:55:39.295039 25648 net.cpp:150] Setting up res3a_branch2a_relu
I0627 10:55:39.295049 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.295053 25648 net.cpp:165] Memory required for data: 118616076
I0627 10:55:39.295059 25648 layer_factory.hpp:77] Creating layer res3a_branch2b
I0627 10:55:39.295080 25648 net.cpp:100] Creating Layer res3a_branch2b
I0627 10:55:39.295089 25648 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0627 10:55:39.295109 25648 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0627 10:55:39.296222 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:55:39.296450 25648 net.cpp:150] Setting up res3a_branch2b
I0627 10:55:39.296464 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.296469 25648 net.cpp:165] Memory required for data: 119017484
I0627 10:55:39.296485 25648 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0627 10:55:39.296504 25648 net.cpp:100] Creating Layer bn3a_branch2b
I0627 10:55:39.296512 25648 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0627 10:55:39.296531 25648 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0627 10:55:39.296713 25648 net.cpp:150] Setting up bn3a_branch2b
I0627 10:55:39.296721 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.296725 25648 net.cpp:165] Memory required for data: 119418892
I0627 10:55:39.296744 25648 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0627 10:55:39.296763 25648 net.cpp:100] Creating Layer scale3a_branch2b
I0627 10:55:39.296771 25648 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0627 10:55:39.296787 25648 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0627 10:55:39.296844 25648 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0627 10:55:39.296973 25648 net.cpp:150] Setting up scale3a_branch2b
I0627 10:55:39.296983 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.296985 25648 net.cpp:165] Memory required for data: 119820300
I0627 10:55:39.296999 25648 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0627 10:55:39.297013 25648 net.cpp:100] Creating Layer res3a_branch2b_relu
I0627 10:55:39.297021 25648 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0627 10:55:39.297036 25648 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0627 10:55:39.297199 25648 net.cpp:150] Setting up res3a_branch2b_relu
I0627 10:55:39.297206 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.297209 25648 net.cpp:165] Memory required for data: 120221708
I0627 10:55:39.297215 25648 layer_factory.hpp:77] Creating layer res3a_branch2c
I0627 10:55:39.297236 25648 net.cpp:100] Creating Layer res3a_branch2c
I0627 10:55:39.297245 25648 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0627 10:55:39.297262 25648 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0627 10:55:39.298245 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.298264 25648 net.cpp:150] Setting up res3a_branch2c
I0627 10:55:39.298275 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.298280 25648 net.cpp:165] Memory required for data: 121827340
I0627 10:55:39.298293 25648 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0627 10:55:39.298321 25648 net.cpp:100] Creating Layer bn3a_branch2c
I0627 10:55:39.298329 25648 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0627 10:55:39.298347 25648 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0627 10:55:39.298528 25648 net.cpp:150] Setting up bn3a_branch2c
I0627 10:55:39.298537 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.298539 25648 net.cpp:165] Memory required for data: 123432972
I0627 10:55:39.298560 25648 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0627 10:55:39.298578 25648 net.cpp:100] Creating Layer scale3a_branch2c
I0627 10:55:39.298585 25648 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0627 10:55:39.298602 25648 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0627 10:55:39.298660 25648 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0627 10:55:39.298807 25648 net.cpp:150] Setting up scale3a_branch2c
I0627 10:55:39.298816 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.298820 25648 net.cpp:165] Memory required for data: 125038604
I0627 10:55:39.298835 25648 layer_factory.hpp:77] Creating layer res3a
I0627 10:55:39.298851 25648 net.cpp:100] Creating Layer res3a
I0627 10:55:39.298862 25648 net.cpp:444] res3a <- res3a_branch1
I0627 10:55:39.298877 25648 net.cpp:444] res3a <- res3a_branch2c
I0627 10:55:39.298888 25648 net.cpp:418] res3a -> res3a
I0627 10:55:39.298930 25648 net.cpp:150] Setting up res3a
I0627 10:55:39.298941 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.298945 25648 net.cpp:165] Memory required for data: 126644236
I0627 10:55:39.298951 25648 layer_factory.hpp:77] Creating layer res3a_relu
I0627 10:55:39.298964 25648 net.cpp:100] Creating Layer res3a_relu
I0627 10:55:39.298970 25648 net.cpp:444] res3a_relu <- res3a
I0627 10:55:39.298985 25648 net.cpp:405] res3a_relu -> res3a (in-place)
I0627 10:55:39.299381 25648 net.cpp:150] Setting up res3a_relu
I0627 10:55:39.299392 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.299396 25648 net.cpp:165] Memory required for data: 128249868
I0627 10:55:39.299402 25648 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0627 10:55:39.299419 25648 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0627 10:55:39.299427 25648 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0627 10:55:39.299444 25648 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0627 10:55:39.299466 25648 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0627 10:55:39.299517 25648 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0627 10:55:39.299527 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.299535 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.299538 25648 net.cpp:165] Memory required for data: 131461132
I0627 10:55:39.299545 25648 layer_factory.hpp:77] Creating layer res3b_branch2a
I0627 10:55:39.299566 25648 net.cpp:100] Creating Layer res3b_branch2a
I0627 10:55:39.299574 25648 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0627 10:55:39.299594 25648 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0627 10:55:39.300575 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.300591 25648 net.cpp:150] Setting up res3b_branch2a
I0627 10:55:39.300601 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.300603 25648 net.cpp:165] Memory required for data: 131862540
I0627 10:55:39.300614 25648 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0627 10:55:39.300631 25648 net.cpp:100] Creating Layer bn3b_branch2a
I0627 10:55:39.300637 25648 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0627 10:55:39.300649 25648 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0627 10:55:39.300824 25648 net.cpp:150] Setting up bn3b_branch2a
I0627 10:55:39.300832 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.300834 25648 net.cpp:165] Memory required for data: 132263948
I0627 10:55:39.300850 25648 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0627 10:55:39.300863 25648 net.cpp:100] Creating Layer scale3b_branch2a
I0627 10:55:39.300868 25648 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0627 10:55:39.300880 25648 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0627 10:55:39.300931 25648 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0627 10:55:39.301055 25648 net.cpp:150] Setting up scale3b_branch2a
I0627 10:55:39.301062 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.301064 25648 net.cpp:165] Memory required for data: 132665356
I0627 10:55:39.301074 25648 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0627 10:55:39.301086 25648 net.cpp:100] Creating Layer res3b_branch2a_relu
I0627 10:55:39.301091 25648 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0627 10:55:39.301102 25648 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0627 10:55:39.301256 25648 net.cpp:150] Setting up res3b_branch2a_relu
I0627 10:55:39.301264 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.301266 25648 net.cpp:165] Memory required for data: 133066764
I0627 10:55:39.301270 25648 layer_factory.hpp:77] Creating layer res3b_branch2b
I0627 10:55:39.301285 25648 net.cpp:100] Creating Layer res3b_branch2b
I0627 10:55:39.301291 25648 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0627 10:55:39.301306 25648 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0627 10:55:39.302395 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:55:39.302616 25648 net.cpp:150] Setting up res3b_branch2b
I0627 10:55:39.302629 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.302634 25648 net.cpp:165] Memory required for data: 133468172
I0627 10:55:39.302644 25648 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0627 10:55:39.302659 25648 net.cpp:100] Creating Layer bn3b_branch2b
I0627 10:55:39.302666 25648 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0627 10:55:39.302680 25648 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0627 10:55:39.302856 25648 net.cpp:150] Setting up bn3b_branch2b
I0627 10:55:39.302870 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.302871 25648 net.cpp:165] Memory required for data: 133869580
I0627 10:55:39.302887 25648 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0627 10:55:39.302901 25648 net.cpp:100] Creating Layer scale3b_branch2b
I0627 10:55:39.302906 25648 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0627 10:55:39.302918 25648 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0627 10:55:39.302969 25648 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0627 10:55:39.303093 25648 net.cpp:150] Setting up scale3b_branch2b
I0627 10:55:39.303100 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.303103 25648 net.cpp:165] Memory required for data: 134270988
I0627 10:55:39.303114 25648 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0627 10:55:39.303124 25648 net.cpp:100] Creating Layer res3b_branch2b_relu
I0627 10:55:39.303129 25648 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0627 10:55:39.303141 25648 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0627 10:55:39.303297 25648 net.cpp:150] Setting up res3b_branch2b_relu
I0627 10:55:39.303303 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.303306 25648 net.cpp:165] Memory required for data: 134672396
I0627 10:55:39.303310 25648 layer_factory.hpp:77] Creating layer res3b_branch2c
I0627 10:55:39.303325 25648 net.cpp:100] Creating Layer res3b_branch2c
I0627 10:55:39.303331 25648 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0627 10:55:39.303347 25648 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0627 10:55:39.304296 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.304311 25648 net.cpp:150] Setting up res3b_branch2c
I0627 10:55:39.304318 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.304320 25648 net.cpp:165] Memory required for data: 136278028
I0627 10:55:39.304332 25648 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0627 10:55:39.304347 25648 net.cpp:100] Creating Layer bn3b_branch2c
I0627 10:55:39.304352 25648 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0627 10:55:39.304366 25648 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0627 10:55:39.304543 25648 net.cpp:150] Setting up bn3b_branch2c
I0627 10:55:39.304549 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.304551 25648 net.cpp:165] Memory required for data: 137883660
I0627 10:55:39.304567 25648 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0627 10:55:39.304580 25648 net.cpp:100] Creating Layer scale3b_branch2c
I0627 10:55:39.304585 25648 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0627 10:55:39.304597 25648 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0627 10:55:39.304647 25648 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0627 10:55:39.304770 25648 net.cpp:150] Setting up scale3b_branch2c
I0627 10:55:39.304778 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.304781 25648 net.cpp:165] Memory required for data: 139489292
I0627 10:55:39.304791 25648 layer_factory.hpp:77] Creating layer res3b
I0627 10:55:39.304802 25648 net.cpp:100] Creating Layer res3b
I0627 10:55:39.304808 25648 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0627 10:55:39.304817 25648 net.cpp:444] res3b <- res3b_branch2c
I0627 10:55:39.304826 25648 net.cpp:418] res3b -> res3b
I0627 10:55:39.304860 25648 net.cpp:150] Setting up res3b
I0627 10:55:39.304868 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.304872 25648 net.cpp:165] Memory required for data: 141094924
I0627 10:55:39.304875 25648 layer_factory.hpp:77] Creating layer res3b_relu
I0627 10:55:39.304885 25648 net.cpp:100] Creating Layer res3b_relu
I0627 10:55:39.304890 25648 net.cpp:444] res3b_relu <- res3b
I0627 10:55:39.304901 25648 net.cpp:405] res3b_relu -> res3b (in-place)
I0627 10:55:39.305270 25648 net.cpp:150] Setting up res3b_relu
I0627 10:55:39.305279 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.305282 25648 net.cpp:165] Memory required for data: 142700556
I0627 10:55:39.305287 25648 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0627 10:55:39.305299 25648 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0627 10:55:39.305305 25648 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0627 10:55:39.305320 25648 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0627 10:55:39.305335 25648 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0627 10:55:39.305378 25648 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0627 10:55:39.305387 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.305392 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.305394 25648 net.cpp:165] Memory required for data: 145911820
I0627 10:55:39.305398 25648 layer_factory.hpp:77] Creating layer res3c_branch2a
I0627 10:55:39.305413 25648 net.cpp:100] Creating Layer res3c_branch2a
I0627 10:55:39.305418 25648 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0627 10:55:39.305433 25648 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0627 10:55:39.306375 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.306391 25648 net.cpp:150] Setting up res3c_branch2a
I0627 10:55:39.306398 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.306401 25648 net.cpp:165] Memory required for data: 146313228
I0627 10:55:39.306412 25648 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0627 10:55:39.306427 25648 net.cpp:100] Creating Layer bn3c_branch2a
I0627 10:55:39.306433 25648 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0627 10:55:39.306447 25648 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0627 10:55:39.306623 25648 net.cpp:150] Setting up bn3c_branch2a
I0627 10:55:39.306629 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.306632 25648 net.cpp:165] Memory required for data: 146714636
I0627 10:55:39.306648 25648 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0627 10:55:39.306663 25648 net.cpp:100] Creating Layer scale3c_branch2a
I0627 10:55:39.306668 25648 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0627 10:55:39.306679 25648 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0627 10:55:39.306731 25648 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0627 10:55:39.306856 25648 net.cpp:150] Setting up scale3c_branch2a
I0627 10:55:39.306874 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.306875 25648 net.cpp:165] Memory required for data: 147116044
I0627 10:55:39.306886 25648 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0627 10:55:39.306896 25648 net.cpp:100] Creating Layer res3c_branch2a_relu
I0627 10:55:39.306901 25648 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0627 10:55:39.306913 25648 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0627 10:55:39.307066 25648 net.cpp:150] Setting up res3c_branch2a_relu
I0627 10:55:39.307073 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.307075 25648 net.cpp:165] Memory required for data: 147517452
I0627 10:55:39.307080 25648 layer_factory.hpp:77] Creating layer res3c_branch2b
I0627 10:55:39.307096 25648 net.cpp:100] Creating Layer res3c_branch2b
I0627 10:55:39.307101 25648 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0627 10:55:39.307116 25648 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0627 10:55:39.308784 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:55:39.309005 25648 net.cpp:150] Setting up res3c_branch2b
I0627 10:55:39.309020 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.309022 25648 net.cpp:165] Memory required for data: 147918860
I0627 10:55:39.309034 25648 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0627 10:55:39.309047 25648 net.cpp:100] Creating Layer bn3c_branch2b
I0627 10:55:39.309056 25648 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0627 10:55:39.309068 25648 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0627 10:55:39.309257 25648 net.cpp:150] Setting up bn3c_branch2b
I0627 10:55:39.309262 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.309265 25648 net.cpp:165] Memory required for data: 148320268
I0627 10:55:39.309280 25648 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0627 10:55:39.309293 25648 net.cpp:100] Creating Layer scale3c_branch2b
I0627 10:55:39.309299 25648 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0627 10:55:39.309310 25648 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0627 10:55:39.309361 25648 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0627 10:55:39.309489 25648 net.cpp:150] Setting up scale3c_branch2b
I0627 10:55:39.309495 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.309499 25648 net.cpp:165] Memory required for data: 148721676
I0627 10:55:39.309509 25648 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0627 10:55:39.309520 25648 net.cpp:100] Creating Layer res3c_branch2b_relu
I0627 10:55:39.309525 25648 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0627 10:55:39.309537 25648 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0627 10:55:39.309693 25648 net.cpp:150] Setting up res3c_branch2b_relu
I0627 10:55:39.309700 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.309703 25648 net.cpp:165] Memory required for data: 149123084
I0627 10:55:39.309707 25648 layer_factory.hpp:77] Creating layer res3c_branch2c
I0627 10:55:39.309723 25648 net.cpp:100] Creating Layer res3c_branch2c
I0627 10:55:39.309728 25648 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0627 10:55:39.309743 25648 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0627 10:55:39.310709 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.310724 25648 net.cpp:150] Setting up res3c_branch2c
I0627 10:55:39.310731 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.310734 25648 net.cpp:165] Memory required for data: 150728716
I0627 10:55:39.310745 25648 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0627 10:55:39.310760 25648 net.cpp:100] Creating Layer bn3c_branch2c
I0627 10:55:39.310766 25648 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0627 10:55:39.310781 25648 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0627 10:55:39.310969 25648 net.cpp:150] Setting up bn3c_branch2c
I0627 10:55:39.310976 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.310978 25648 net.cpp:165] Memory required for data: 152334348
I0627 10:55:39.310994 25648 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0627 10:55:39.311008 25648 net.cpp:100] Creating Layer scale3c_branch2c
I0627 10:55:39.311014 25648 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0627 10:55:39.311025 25648 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0627 10:55:39.311076 25648 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0627 10:55:39.311203 25648 net.cpp:150] Setting up scale3c_branch2c
I0627 10:55:39.311210 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.311213 25648 net.cpp:165] Memory required for data: 153939980
I0627 10:55:39.311223 25648 layer_factory.hpp:77] Creating layer res3c
I0627 10:55:39.311233 25648 net.cpp:100] Creating Layer res3c
I0627 10:55:39.311239 25648 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0627 10:55:39.311249 25648 net.cpp:444] res3c <- res3c_branch2c
I0627 10:55:39.311257 25648 net.cpp:418] res3c -> res3c
I0627 10:55:39.311292 25648 net.cpp:150] Setting up res3c
I0627 10:55:39.311300 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.311303 25648 net.cpp:165] Memory required for data: 155545612
I0627 10:55:39.311307 25648 layer_factory.hpp:77] Creating layer res3c_relu
I0627 10:55:39.311316 25648 net.cpp:100] Creating Layer res3c_relu
I0627 10:55:39.311321 25648 net.cpp:444] res3c_relu <- res3c
I0627 10:55:39.311331 25648 net.cpp:405] res3c_relu -> res3c (in-place)
I0627 10:55:39.311486 25648 net.cpp:150] Setting up res3c_relu
I0627 10:55:39.311492 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.311496 25648 net.cpp:165] Memory required for data: 157151244
I0627 10:55:39.311499 25648 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0627 10:55:39.311509 25648 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0627 10:55:39.311514 25648 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0627 10:55:39.311527 25648 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0627 10:55:39.311542 25648 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0627 10:55:39.311584 25648 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0627 10:55:39.311594 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.311597 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.311599 25648 net.cpp:165] Memory required for data: 160362508
I0627 10:55:39.311604 25648 layer_factory.hpp:77] Creating layer res3d_branch2a
I0627 10:55:39.311616 25648 net.cpp:100] Creating Layer res3d_branch2a
I0627 10:55:39.311621 25648 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0627 10:55:39.311635 25648 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0627 10:55:39.313158 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.313174 25648 net.cpp:150] Setting up res3d_branch2a
I0627 10:55:39.313182 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.313185 25648 net.cpp:165] Memory required for data: 160763916
I0627 10:55:39.313196 25648 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0627 10:55:39.313210 25648 net.cpp:100] Creating Layer bn3d_branch2a
I0627 10:55:39.313216 25648 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0627 10:55:39.313231 25648 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0627 10:55:39.313416 25648 net.cpp:150] Setting up bn3d_branch2a
I0627 10:55:39.313423 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.313426 25648 net.cpp:165] Memory required for data: 161165324
I0627 10:55:39.313477 25648 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0627 10:55:39.313493 25648 net.cpp:100] Creating Layer scale3d_branch2a
I0627 10:55:39.313498 25648 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0627 10:55:39.313511 25648 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0627 10:55:39.313571 25648 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0627 10:55:39.313702 25648 net.cpp:150] Setting up scale3d_branch2a
I0627 10:55:39.313710 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.313712 25648 net.cpp:165] Memory required for data: 161566732
I0627 10:55:39.313724 25648 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0627 10:55:39.313733 25648 net.cpp:100] Creating Layer res3d_branch2a_relu
I0627 10:55:39.313740 25648 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0627 10:55:39.313750 25648 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0627 10:55:39.314126 25648 net.cpp:150] Setting up res3d_branch2a_relu
I0627 10:55:39.314136 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.314137 25648 net.cpp:165] Memory required for data: 161968140
I0627 10:55:39.314142 25648 layer_factory.hpp:77] Creating layer res3d_branch2b
I0627 10:55:39.314160 25648 net.cpp:100] Creating Layer res3d_branch2b
I0627 10:55:39.314167 25648 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0627 10:55:39.314182 25648 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0627 10:55:39.315268 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:55:39.315487 25648 net.cpp:150] Setting up res3d_branch2b
I0627 10:55:39.315498 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.315501 25648 net.cpp:165] Memory required for data: 162369548
I0627 10:55:39.315513 25648 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0627 10:55:39.315528 25648 net.cpp:100] Creating Layer bn3d_branch2b
I0627 10:55:39.315536 25648 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0627 10:55:39.315549 25648 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0627 10:55:39.315735 25648 net.cpp:150] Setting up bn3d_branch2b
I0627 10:55:39.315742 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.315745 25648 net.cpp:165] Memory required for data: 162770956
I0627 10:55:39.315760 25648 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0627 10:55:39.315774 25648 net.cpp:100] Creating Layer scale3d_branch2b
I0627 10:55:39.315780 25648 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0627 10:55:39.315793 25648 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0627 10:55:39.315845 25648 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0627 10:55:39.315971 25648 net.cpp:150] Setting up scale3d_branch2b
I0627 10:55:39.315979 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.315982 25648 net.cpp:165] Memory required for data: 163172364
I0627 10:55:39.315992 25648 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0627 10:55:39.316004 25648 net.cpp:100] Creating Layer res3d_branch2b_relu
I0627 10:55:39.316009 25648 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0627 10:55:39.316021 25648 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0627 10:55:39.316176 25648 net.cpp:150] Setting up res3d_branch2b_relu
I0627 10:55:39.316184 25648 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:55:39.316186 25648 net.cpp:165] Memory required for data: 163573772
I0627 10:55:39.316190 25648 layer_factory.hpp:77] Creating layer res3d_branch2c
I0627 10:55:39.316205 25648 net.cpp:100] Creating Layer res3d_branch2c
I0627 10:55:39.316210 25648 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0627 10:55:39.316224 25648 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0627 10:55:39.317181 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:55:39.317198 25648 net.cpp:150] Setting up res3d_branch2c
I0627 10:55:39.317206 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.317209 25648 net.cpp:165] Memory required for data: 165179404
I0627 10:55:39.317219 25648 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0627 10:55:39.317234 25648 net.cpp:100] Creating Layer bn3d_branch2c
I0627 10:55:39.317240 25648 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0627 10:55:39.317253 25648 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0627 10:55:39.317435 25648 net.cpp:150] Setting up bn3d_branch2c
I0627 10:55:39.317441 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.317445 25648 net.cpp:165] Memory required for data: 166785036
I0627 10:55:39.317459 25648 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0627 10:55:39.317472 25648 net.cpp:100] Creating Layer scale3d_branch2c
I0627 10:55:39.317477 25648 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0627 10:55:39.317489 25648 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0627 10:55:39.317541 25648 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0627 10:55:39.317668 25648 net.cpp:150] Setting up scale3d_branch2c
I0627 10:55:39.317677 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.317678 25648 net.cpp:165] Memory required for data: 168390668
I0627 10:55:39.317688 25648 layer_factory.hpp:77] Creating layer res3d
I0627 10:55:39.317698 25648 net.cpp:100] Creating Layer res3d
I0627 10:55:39.317704 25648 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0627 10:55:39.317714 25648 net.cpp:444] res3d <- res3d_branch2c
I0627 10:55:39.317724 25648 net.cpp:418] res3d -> res3d
I0627 10:55:39.317759 25648 net.cpp:150] Setting up res3d
I0627 10:55:39.317766 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.317770 25648 net.cpp:165] Memory required for data: 169996300
I0627 10:55:39.317773 25648 layer_factory.hpp:77] Creating layer res3d_relu
I0627 10:55:39.317781 25648 net.cpp:100] Creating Layer res3d_relu
I0627 10:55:39.317786 25648 net.cpp:444] res3d_relu <- res3d
I0627 10:55:39.317797 25648 net.cpp:405] res3d_relu -> res3d (in-place)
I0627 10:55:39.317950 25648 net.cpp:150] Setting up res3d_relu
I0627 10:55:39.317956 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.317960 25648 net.cpp:165] Memory required for data: 171601932
I0627 10:55:39.317963 25648 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0627 10:55:39.317972 25648 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0627 10:55:39.317977 25648 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0627 10:55:39.317989 25648 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0627 10:55:39.318004 25648 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0627 10:55:39.318048 25648 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0627 10:55:39.318056 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.318060 25648 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:55:39.318063 25648 net.cpp:165] Memory required for data: 174813196
I0627 10:55:39.318066 25648 layer_factory.hpp:77] Creating layer res4a_branch1
I0627 10:55:39.318079 25648 net.cpp:100] Creating Layer res4a_branch1
I0627 10:55:39.318085 25648 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0627 10:55:39.318100 25648 net.cpp:418] res4a_branch1 -> res4a_branch1
I0627 10:55:39.320365 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7416
I0627 10:55:39.320394 25648 net.cpp:150] Setting up res4a_branch1
I0627 10:55:39.320406 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.320410 25648 net.cpp:165] Memory required for data: 175616012
I0627 10:55:39.320425 25648 layer_factory.hpp:77] Creating layer bn4a_branch1
I0627 10:55:39.320447 25648 net.cpp:100] Creating Layer bn4a_branch1
I0627 10:55:39.320456 25648 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0627 10:55:39.320471 25648 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0627 10:55:39.320664 25648 net.cpp:150] Setting up bn4a_branch1
I0627 10:55:39.320672 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.320674 25648 net.cpp:165] Memory required for data: 176418828
I0627 10:55:39.320690 25648 layer_factory.hpp:77] Creating layer scale4a_branch1
I0627 10:55:39.320703 25648 net.cpp:100] Creating Layer scale4a_branch1
I0627 10:55:39.320708 25648 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0627 10:55:39.320720 25648 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0627 10:55:39.320770 25648 layer_factory.hpp:77] Creating layer scale4a_branch1
I0627 10:55:39.320897 25648 net.cpp:150] Setting up scale4a_branch1
I0627 10:55:39.320905 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.320909 25648 net.cpp:165] Memory required for data: 177221644
I0627 10:55:39.320919 25648 layer_factory.hpp:77] Creating layer res4a_branch2a
I0627 10:55:39.320935 25648 net.cpp:100] Creating Layer res4a_branch2a
I0627 10:55:39.320941 25648 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0627 10:55:39.320955 25648 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0627 10:55:39.322019 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7032
I0627 10:55:39.322041 25648 net.cpp:150] Setting up res4a_branch2a
I0627 10:55:39.322048 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.322051 25648 net.cpp:165] Memory required for data: 177422348
I0627 10:55:39.322062 25648 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0627 10:55:39.322075 25648 net.cpp:100] Creating Layer bn4a_branch2a
I0627 10:55:39.322082 25648 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0627 10:55:39.322095 25648 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0627 10:55:39.322278 25648 net.cpp:150] Setting up bn4a_branch2a
I0627 10:55:39.322284 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.322286 25648 net.cpp:165] Memory required for data: 177623052
I0627 10:55:39.322302 25648 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0627 10:55:39.322315 25648 net.cpp:100] Creating Layer scale4a_branch2a
I0627 10:55:39.322320 25648 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0627 10:55:39.322331 25648 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0627 10:55:39.322382 25648 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0627 10:55:39.322506 25648 net.cpp:150] Setting up scale4a_branch2a
I0627 10:55:39.322513 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.322516 25648 net.cpp:165] Memory required for data: 177823756
I0627 10:55:39.322526 25648 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0627 10:55:39.322537 25648 net.cpp:100] Creating Layer res4a_branch2a_relu
I0627 10:55:39.322543 25648 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0627 10:55:39.322553 25648 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0627 10:55:39.322932 25648 net.cpp:150] Setting up res4a_branch2a_relu
I0627 10:55:39.322942 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.322944 25648 net.cpp:165] Memory required for data: 178024460
I0627 10:55:39.322949 25648 layer_factory.hpp:77] Creating layer res4a_branch2b
I0627 10:55:39.322966 25648 net.cpp:100] Creating Layer res4a_branch2b
I0627 10:55:39.322973 25648 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0627 10:55:39.322989 25648 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0627 10:55:39.325413 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:55:39.325639 25648 net.cpp:150] Setting up res4a_branch2b
I0627 10:55:39.325651 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.325654 25648 net.cpp:165] Memory required for data: 178225164
I0627 10:55:39.325667 25648 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0627 10:55:39.325683 25648 net.cpp:100] Creating Layer bn4a_branch2b
I0627 10:55:39.325690 25648 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0627 10:55:39.325704 25648 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0627 10:55:39.325894 25648 net.cpp:150] Setting up bn4a_branch2b
I0627 10:55:39.325901 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.325902 25648 net.cpp:165] Memory required for data: 178425868
I0627 10:55:39.325918 25648 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0627 10:55:39.325932 25648 net.cpp:100] Creating Layer scale4a_branch2b
I0627 10:55:39.325937 25648 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0627 10:55:39.325948 25648 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0627 10:55:39.326000 25648 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0627 10:55:39.326128 25648 net.cpp:150] Setting up scale4a_branch2b
I0627 10:55:39.326134 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.326138 25648 net.cpp:165] Memory required for data: 178626572
I0627 10:55:39.326148 25648 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0627 10:55:39.326158 25648 net.cpp:100] Creating Layer res4a_branch2b_relu
I0627 10:55:39.326164 25648 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0627 10:55:39.326175 25648 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0627 10:55:39.326351 25648 net.cpp:150] Setting up res4a_branch2b_relu
I0627 10:55:39.326359 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.326361 25648 net.cpp:165] Memory required for data: 178827276
I0627 10:55:39.326365 25648 layer_factory.hpp:77] Creating layer res4a_branch2c
I0627 10:55:39.326380 25648 net.cpp:100] Creating Layer res4a_branch2c
I0627 10:55:39.326386 25648 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0627 10:55:39.326401 25648 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0627 10:55:39.328299 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.328322 25648 net.cpp:150] Setting up res4a_branch2c
I0627 10:55:39.328332 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.328336 25648 net.cpp:165] Memory required for data: 179630092
I0627 10:55:39.328346 25648 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0627 10:55:39.328363 25648 net.cpp:100] Creating Layer bn4a_branch2c
I0627 10:55:39.328371 25648 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0627 10:55:39.328385 25648 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0627 10:55:39.328578 25648 net.cpp:150] Setting up bn4a_branch2c
I0627 10:55:39.328584 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.328588 25648 net.cpp:165] Memory required for data: 180432908
I0627 10:55:39.328603 25648 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0627 10:55:39.328618 25648 net.cpp:100] Creating Layer scale4a_branch2c
I0627 10:55:39.328624 25648 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0627 10:55:39.328635 25648 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0627 10:55:39.328685 25648 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0627 10:55:39.328820 25648 net.cpp:150] Setting up scale4a_branch2c
I0627 10:55:39.328828 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.328830 25648 net.cpp:165] Memory required for data: 181235724
I0627 10:55:39.328840 25648 layer_factory.hpp:77] Creating layer res4a
I0627 10:55:39.328852 25648 net.cpp:100] Creating Layer res4a
I0627 10:55:39.328858 25648 net.cpp:444] res4a <- res4a_branch1
I0627 10:55:39.328867 25648 net.cpp:444] res4a <- res4a_branch2c
I0627 10:55:39.328876 25648 net.cpp:418] res4a -> res4a
I0627 10:55:39.328912 25648 net.cpp:150] Setting up res4a
I0627 10:55:39.328920 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.328923 25648 net.cpp:165] Memory required for data: 182038540
I0627 10:55:39.328927 25648 layer_factory.hpp:77] Creating layer res4a_relu
I0627 10:55:39.328935 25648 net.cpp:100] Creating Layer res4a_relu
I0627 10:55:39.328940 25648 net.cpp:444] res4a_relu <- res4a
I0627 10:55:39.328951 25648 net.cpp:405] res4a_relu -> res4a (in-place)
I0627 10:55:39.329324 25648 net.cpp:150] Setting up res4a_relu
I0627 10:55:39.329334 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.329337 25648 net.cpp:165] Memory required for data: 182841356
I0627 10:55:39.329341 25648 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0627 10:55:39.329352 25648 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0627 10:55:39.329358 25648 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0627 10:55:39.329373 25648 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0627 10:55:39.329390 25648 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0627 10:55:39.329437 25648 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0627 10:55:39.329444 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.329448 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.329450 25648 net.cpp:165] Memory required for data: 184446988
I0627 10:55:39.329454 25648 layer_factory.hpp:77] Creating layer res4b_branch2a
I0627 10:55:39.329486 25648 net.cpp:100] Creating Layer res4b_branch2a
I0627 10:55:39.329493 25648 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0627 10:55:39.329507 25648 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0627 10:55:39.330802 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.330826 25648 net.cpp:150] Setting up res4b_branch2a
I0627 10:55:39.330833 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.330835 25648 net.cpp:165] Memory required for data: 184647692
I0627 10:55:39.330848 25648 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0627 10:55:39.330870 25648 net.cpp:100] Creating Layer bn4b_branch2a
I0627 10:55:39.330890 25648 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0627 10:55:39.330904 25648 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0627 10:55:39.331099 25648 net.cpp:150] Setting up bn4b_branch2a
I0627 10:55:39.331105 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.331109 25648 net.cpp:165] Memory required for data: 184848396
I0627 10:55:39.331125 25648 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0627 10:55:39.331138 25648 net.cpp:100] Creating Layer scale4b_branch2a
I0627 10:55:39.331145 25648 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0627 10:55:39.331156 25648 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0627 10:55:39.331209 25648 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0627 10:55:39.331338 25648 net.cpp:150] Setting up scale4b_branch2a
I0627 10:55:39.331346 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.331348 25648 net.cpp:165] Memory required for data: 185049100
I0627 10:55:39.331358 25648 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0627 10:55:39.331369 25648 net.cpp:100] Creating Layer res4b_branch2a_relu
I0627 10:55:39.331374 25648 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0627 10:55:39.331387 25648 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0627 10:55:39.331785 25648 net.cpp:150] Setting up res4b_branch2a_relu
I0627 10:55:39.331794 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.331797 25648 net.cpp:165] Memory required for data: 185249804
I0627 10:55:39.331802 25648 layer_factory.hpp:77] Creating layer res4b_branch2b
I0627 10:55:39.331820 25648 net.cpp:100] Creating Layer res4b_branch2b
I0627 10:55:39.331826 25648 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0627 10:55:39.331845 25648 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0627 10:55:39.334480 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:55:39.334734 25648 net.cpp:150] Setting up res4b_branch2b
I0627 10:55:39.334750 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.334753 25648 net.cpp:165] Memory required for data: 185450508
I0627 10:55:39.334774 25648 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0627 10:55:39.334800 25648 net.cpp:100] Creating Layer bn4b_branch2b
I0627 10:55:39.334810 25648 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0627 10:55:39.334828 25648 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0627 10:55:39.335039 25648 net.cpp:150] Setting up bn4b_branch2b
I0627 10:55:39.335047 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.335049 25648 net.cpp:165] Memory required for data: 185651212
I0627 10:55:39.335065 25648 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0627 10:55:39.335080 25648 net.cpp:100] Creating Layer scale4b_branch2b
I0627 10:55:39.335086 25648 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0627 10:55:39.335098 25648 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0627 10:55:39.335152 25648 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0627 10:55:39.335283 25648 net.cpp:150] Setting up scale4b_branch2b
I0627 10:55:39.335290 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.335294 25648 net.cpp:165] Memory required for data: 185851916
I0627 10:55:39.335304 25648 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0627 10:55:39.335314 25648 net.cpp:100] Creating Layer res4b_branch2b_relu
I0627 10:55:39.335319 25648 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0627 10:55:39.335330 25648 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0627 10:55:39.335494 25648 net.cpp:150] Setting up res4b_branch2b_relu
I0627 10:55:39.335500 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.335503 25648 net.cpp:165] Memory required for data: 186052620
I0627 10:55:39.335507 25648 layer_factory.hpp:77] Creating layer res4b_branch2c
I0627 10:55:39.335525 25648 net.cpp:100] Creating Layer res4b_branch2c
I0627 10:55:39.335530 25648 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0627 10:55:39.335544 25648 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0627 10:55:39.337452 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.337477 25648 net.cpp:150] Setting up res4b_branch2c
I0627 10:55:39.337486 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.337489 25648 net.cpp:165] Memory required for data: 186855436
I0627 10:55:39.337501 25648 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0627 10:55:39.337517 25648 net.cpp:100] Creating Layer bn4b_branch2c
I0627 10:55:39.337523 25648 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0627 10:55:39.337536 25648 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0627 10:55:39.337733 25648 net.cpp:150] Setting up bn4b_branch2c
I0627 10:55:39.337739 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.337743 25648 net.cpp:165] Memory required for data: 187658252
I0627 10:55:39.337759 25648 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0627 10:55:39.337771 25648 net.cpp:100] Creating Layer scale4b_branch2c
I0627 10:55:39.337776 25648 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0627 10:55:39.337788 25648 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0627 10:55:39.337838 25648 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0627 10:55:39.337975 25648 net.cpp:150] Setting up scale4b_branch2c
I0627 10:55:39.337982 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.337985 25648 net.cpp:165] Memory required for data: 188461068
I0627 10:55:39.337996 25648 layer_factory.hpp:77] Creating layer res4b
I0627 10:55:39.338007 25648 net.cpp:100] Creating Layer res4b
I0627 10:55:39.338012 25648 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0627 10:55:39.338022 25648 net.cpp:444] res4b <- res4b_branch2c
I0627 10:55:39.338032 25648 net.cpp:418] res4b -> res4b
I0627 10:55:39.338069 25648 net.cpp:150] Setting up res4b
I0627 10:55:39.338078 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.338080 25648 net.cpp:165] Memory required for data: 189263884
I0627 10:55:39.338084 25648 layer_factory.hpp:77] Creating layer res4b_relu
I0627 10:55:39.338093 25648 net.cpp:100] Creating Layer res4b_relu
I0627 10:55:39.338099 25648 net.cpp:444] res4b_relu <- res4b
I0627 10:55:39.338109 25648 net.cpp:405] res4b_relu -> res4b (in-place)
I0627 10:55:39.338263 25648 net.cpp:150] Setting up res4b_relu
I0627 10:55:39.338270 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.338274 25648 net.cpp:165] Memory required for data: 190066700
I0627 10:55:39.338277 25648 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0627 10:55:39.338287 25648 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0627 10:55:39.338292 25648 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0627 10:55:39.338305 25648 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0627 10:55:39.338320 25648 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0627 10:55:39.338366 25648 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0627 10:55:39.338373 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.338377 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.338380 25648 net.cpp:165] Memory required for data: 191672332
I0627 10:55:39.338384 25648 layer_factory.hpp:77] Creating layer res4c_branch2a
I0627 10:55:39.338398 25648 net.cpp:100] Creating Layer res4c_branch2a
I0627 10:55:39.338404 25648 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0627 10:55:39.338419 25648 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0627 10:55:39.339713 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.339735 25648 net.cpp:150] Setting up res4c_branch2a
I0627 10:55:39.339743 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.339746 25648 net.cpp:165] Memory required for data: 191873036
I0627 10:55:39.339756 25648 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0627 10:55:39.339771 25648 net.cpp:100] Creating Layer bn4c_branch2a
I0627 10:55:39.339778 25648 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0627 10:55:39.339792 25648 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0627 10:55:39.339985 25648 net.cpp:150] Setting up bn4c_branch2a
I0627 10:55:39.339993 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.339994 25648 net.cpp:165] Memory required for data: 192073740
I0627 10:55:39.340011 25648 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0627 10:55:39.340023 25648 net.cpp:100] Creating Layer scale4c_branch2a
I0627 10:55:39.340029 25648 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0627 10:55:39.340041 25648 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0627 10:55:39.340095 25648 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0627 10:55:39.340225 25648 net.cpp:150] Setting up scale4c_branch2a
I0627 10:55:39.340232 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.340235 25648 net.cpp:165] Memory required for data: 192274444
I0627 10:55:39.340246 25648 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0627 10:55:39.340255 25648 net.cpp:100] Creating Layer res4c_branch2a_relu
I0627 10:55:39.340261 25648 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0627 10:55:39.340272 25648 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0627 10:55:39.340426 25648 net.cpp:150] Setting up res4c_branch2a_relu
I0627 10:55:39.340433 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.340436 25648 net.cpp:165] Memory required for data: 192475148
I0627 10:55:39.340440 25648 layer_factory.hpp:77] Creating layer res4c_branch2b
I0627 10:55:39.340456 25648 net.cpp:100] Creating Layer res4c_branch2b
I0627 10:55:39.340462 25648 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0627 10:55:39.340477 25648 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0627 10:55:39.342969 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:55:39.343214 25648 net.cpp:150] Setting up res4c_branch2b
I0627 10:55:39.343228 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.343232 25648 net.cpp:165] Memory required for data: 192675852
I0627 10:55:39.343245 25648 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0627 10:55:39.343261 25648 net.cpp:100] Creating Layer bn4c_branch2b
I0627 10:55:39.343268 25648 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0627 10:55:39.343283 25648 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0627 10:55:39.343485 25648 net.cpp:150] Setting up bn4c_branch2b
I0627 10:55:39.343492 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.343495 25648 net.cpp:165] Memory required for data: 192876556
I0627 10:55:39.343511 25648 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0627 10:55:39.343525 25648 net.cpp:100] Creating Layer scale4c_branch2b
I0627 10:55:39.343530 25648 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0627 10:55:39.343544 25648 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0627 10:55:39.343597 25648 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0627 10:55:39.343729 25648 net.cpp:150] Setting up scale4c_branch2b
I0627 10:55:39.343736 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.343739 25648 net.cpp:165] Memory required for data: 193077260
I0627 10:55:39.343750 25648 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0627 10:55:39.343760 25648 net.cpp:100] Creating Layer res4c_branch2b_relu
I0627 10:55:39.343765 25648 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0627 10:55:39.343776 25648 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0627 10:55:39.344166 25648 net.cpp:150] Setting up res4c_branch2b_relu
I0627 10:55:39.344175 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.344178 25648 net.cpp:165] Memory required for data: 193277964
I0627 10:55:39.344183 25648 layer_factory.hpp:77] Creating layer res4c_branch2c
I0627 10:55:39.344202 25648 net.cpp:100] Creating Layer res4c_branch2c
I0627 10:55:39.344208 25648 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0627 10:55:39.344224 25648 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0627 10:55:39.346138 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.346164 25648 net.cpp:150] Setting up res4c_branch2c
I0627 10:55:39.346174 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.346177 25648 net.cpp:165] Memory required for data: 194080780
I0627 10:55:39.346189 25648 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0627 10:55:39.346205 25648 net.cpp:100] Creating Layer bn4c_branch2c
I0627 10:55:39.346212 25648 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0627 10:55:39.346226 25648 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0627 10:55:39.346424 25648 net.cpp:150] Setting up bn4c_branch2c
I0627 10:55:39.346431 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.346433 25648 net.cpp:165] Memory required for data: 194883596
I0627 10:55:39.346449 25648 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0627 10:55:39.346463 25648 net.cpp:100] Creating Layer scale4c_branch2c
I0627 10:55:39.346468 25648 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0627 10:55:39.346479 25648 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0627 10:55:39.346532 25648 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0627 10:55:39.346670 25648 net.cpp:150] Setting up scale4c_branch2c
I0627 10:55:39.346678 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.346681 25648 net.cpp:165] Memory required for data: 195686412
I0627 10:55:39.346691 25648 layer_factory.hpp:77] Creating layer res4c
I0627 10:55:39.346704 25648 net.cpp:100] Creating Layer res4c
I0627 10:55:39.346709 25648 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0627 10:55:39.346719 25648 net.cpp:444] res4c <- res4c_branch2c
I0627 10:55:39.346729 25648 net.cpp:418] res4c -> res4c
I0627 10:55:39.346765 25648 net.cpp:150] Setting up res4c
I0627 10:55:39.346773 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.346776 25648 net.cpp:165] Memory required for data: 196489228
I0627 10:55:39.346781 25648 layer_factory.hpp:77] Creating layer res4c_relu
I0627 10:55:39.346789 25648 net.cpp:100] Creating Layer res4c_relu
I0627 10:55:39.346794 25648 net.cpp:444] res4c_relu <- res4c
I0627 10:55:39.346806 25648 net.cpp:405] res4c_relu -> res4c (in-place)
I0627 10:55:39.346966 25648 net.cpp:150] Setting up res4c_relu
I0627 10:55:39.346974 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.346976 25648 net.cpp:165] Memory required for data: 197292044
I0627 10:55:39.346981 25648 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0627 10:55:39.346992 25648 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0627 10:55:39.346997 25648 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0627 10:55:39.347009 25648 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0627 10:55:39.347023 25648 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0627 10:55:39.347069 25648 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0627 10:55:39.347077 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.347081 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.347084 25648 net.cpp:165] Memory required for data: 198897676
I0627 10:55:39.347088 25648 layer_factory.hpp:77] Creating layer res4d_branch2a
I0627 10:55:39.347102 25648 net.cpp:100] Creating Layer res4d_branch2a
I0627 10:55:39.347108 25648 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0627 10:55:39.347123 25648 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0627 10:55:39.348426 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.348448 25648 net.cpp:150] Setting up res4d_branch2a
I0627 10:55:39.348456 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.348460 25648 net.cpp:165] Memory required for data: 199098380
I0627 10:55:39.348470 25648 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0627 10:55:39.348485 25648 net.cpp:100] Creating Layer bn4d_branch2a
I0627 10:55:39.348491 25648 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0627 10:55:39.348505 25648 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0627 10:55:39.348700 25648 net.cpp:150] Setting up bn4d_branch2a
I0627 10:55:39.348706 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.348708 25648 net.cpp:165] Memory required for data: 199299084
I0627 10:55:39.348726 25648 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0627 10:55:39.348737 25648 net.cpp:100] Creating Layer scale4d_branch2a
I0627 10:55:39.348743 25648 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0627 10:55:39.348754 25648 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0627 10:55:39.348809 25648 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0627 10:55:39.348937 25648 net.cpp:150] Setting up scale4d_branch2a
I0627 10:55:39.348944 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.348948 25648 net.cpp:165] Memory required for data: 199499788
I0627 10:55:39.348958 25648 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0627 10:55:39.348969 25648 net.cpp:100] Creating Layer res4d_branch2a_relu
I0627 10:55:39.348975 25648 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0627 10:55:39.348985 25648 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0627 10:55:39.349140 25648 net.cpp:150] Setting up res4d_branch2a_relu
I0627 10:55:39.349148 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.349151 25648 net.cpp:165] Memory required for data: 199700492
I0627 10:55:39.349155 25648 layer_factory.hpp:77] Creating layer res4d_branch2b
I0627 10:55:39.349169 25648 net.cpp:100] Creating Layer res4d_branch2b
I0627 10:55:39.349175 25648 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0627 10:55:39.349190 25648 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0627 10:55:39.351660 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:55:39.351900 25648 net.cpp:150] Setting up res4d_branch2b
I0627 10:55:39.351915 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.351918 25648 net.cpp:165] Memory required for data: 199901196
I0627 10:55:39.351933 25648 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0627 10:55:39.351951 25648 net.cpp:100] Creating Layer bn4d_branch2b
I0627 10:55:39.351958 25648 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0627 10:55:39.351971 25648 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0627 10:55:39.352175 25648 net.cpp:150] Setting up bn4d_branch2b
I0627 10:55:39.352182 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.352185 25648 net.cpp:165] Memory required for data: 200101900
I0627 10:55:39.352200 25648 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0627 10:55:39.352214 25648 net.cpp:100] Creating Layer scale4d_branch2b
I0627 10:55:39.352221 25648 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0627 10:55:39.352231 25648 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0627 10:55:39.352285 25648 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0627 10:55:39.352417 25648 net.cpp:150] Setting up scale4d_branch2b
I0627 10:55:39.352424 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.352427 25648 net.cpp:165] Memory required for data: 200302604
I0627 10:55:39.352437 25648 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0627 10:55:39.352447 25648 net.cpp:100] Creating Layer res4d_branch2b_relu
I0627 10:55:39.352453 25648 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0627 10:55:39.352465 25648 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0627 10:55:39.352859 25648 net.cpp:150] Setting up res4d_branch2b_relu
I0627 10:55:39.352867 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.352870 25648 net.cpp:165] Memory required for data: 200503308
I0627 10:55:39.352875 25648 layer_factory.hpp:77] Creating layer res4d_branch2c
I0627 10:55:39.352892 25648 net.cpp:100] Creating Layer res4d_branch2c
I0627 10:55:39.352898 25648 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0627 10:55:39.352916 25648 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0627 10:55:39.354851 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.354882 25648 net.cpp:150] Setting up res4d_branch2c
I0627 10:55:39.354890 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.354892 25648 net.cpp:165] Memory required for data: 201306124
I0627 10:55:39.354905 25648 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0627 10:55:39.354923 25648 net.cpp:100] Creating Layer bn4d_branch2c
I0627 10:55:39.354929 25648 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0627 10:55:39.354945 25648 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0627 10:55:39.355147 25648 net.cpp:150] Setting up bn4d_branch2c
I0627 10:55:39.355154 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.355156 25648 net.cpp:165] Memory required for data: 202108940
I0627 10:55:39.355173 25648 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0627 10:55:39.355188 25648 net.cpp:100] Creating Layer scale4d_branch2c
I0627 10:55:39.355193 25648 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0627 10:55:39.355206 25648 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0627 10:55:39.355259 25648 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0627 10:55:39.355399 25648 net.cpp:150] Setting up scale4d_branch2c
I0627 10:55:39.355406 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.355409 25648 net.cpp:165] Memory required for data: 202911756
I0627 10:55:39.355419 25648 layer_factory.hpp:77] Creating layer res4d
I0627 10:55:39.355432 25648 net.cpp:100] Creating Layer res4d
I0627 10:55:39.355437 25648 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0627 10:55:39.355448 25648 net.cpp:444] res4d <- res4d_branch2c
I0627 10:55:39.355458 25648 net.cpp:418] res4d -> res4d
I0627 10:55:39.355494 25648 net.cpp:150] Setting up res4d
I0627 10:55:39.355501 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.355504 25648 net.cpp:165] Memory required for data: 203714572
I0627 10:55:39.355509 25648 layer_factory.hpp:77] Creating layer res4d_relu
I0627 10:55:39.355520 25648 net.cpp:100] Creating Layer res4d_relu
I0627 10:55:39.355523 25648 net.cpp:444] res4d_relu <- res4d
I0627 10:55:39.355535 25648 net.cpp:405] res4d_relu -> res4d (in-place)
I0627 10:55:39.355690 25648 net.cpp:150] Setting up res4d_relu
I0627 10:55:39.355696 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.355698 25648 net.cpp:165] Memory required for data: 204517388
I0627 10:55:39.355702 25648 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0627 10:55:39.355713 25648 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0627 10:55:39.355718 25648 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0627 10:55:39.355732 25648 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0627 10:55:39.355746 25648 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0627 10:55:39.355793 25648 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0627 10:55:39.355801 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.355806 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.355808 25648 net.cpp:165] Memory required for data: 206123020
I0627 10:55:39.355811 25648 layer_factory.hpp:77] Creating layer res4e_branch2a
I0627 10:55:39.355825 25648 net.cpp:100] Creating Layer res4e_branch2a
I0627 10:55:39.355831 25648 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0627 10:55:39.355846 25648 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0627 10:55:39.357167 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.357188 25648 net.cpp:150] Setting up res4e_branch2a
I0627 10:55:39.357197 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.357198 25648 net.cpp:165] Memory required for data: 206323724
I0627 10:55:39.357209 25648 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0627 10:55:39.357223 25648 net.cpp:100] Creating Layer bn4e_branch2a
I0627 10:55:39.357230 25648 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0627 10:55:39.357244 25648 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0627 10:55:39.357444 25648 net.cpp:150] Setting up bn4e_branch2a
I0627 10:55:39.357450 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.357452 25648 net.cpp:165] Memory required for data: 206524428
I0627 10:55:39.357468 25648 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0627 10:55:39.357481 25648 net.cpp:100] Creating Layer scale4e_branch2a
I0627 10:55:39.357487 25648 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0627 10:55:39.357499 25648 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0627 10:55:39.357553 25648 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0627 10:55:39.357686 25648 net.cpp:150] Setting up scale4e_branch2a
I0627 10:55:39.357693 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.357695 25648 net.cpp:165] Memory required for data: 206725132
I0627 10:55:39.357707 25648 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0627 10:55:39.357717 25648 net.cpp:100] Creating Layer res4e_branch2a_relu
I0627 10:55:39.357722 25648 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0627 10:55:39.357734 25648 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0627 10:55:39.357890 25648 net.cpp:150] Setting up res4e_branch2a_relu
I0627 10:55:39.357897 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.357900 25648 net.cpp:165] Memory required for data: 206925836
I0627 10:55:39.357904 25648 layer_factory.hpp:77] Creating layer res4e_branch2b
I0627 10:55:39.357919 25648 net.cpp:100] Creating Layer res4e_branch2b
I0627 10:55:39.357925 25648 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0627 10:55:39.357939 25648 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0627 10:55:39.360429 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:55:39.360672 25648 net.cpp:150] Setting up res4e_branch2b
I0627 10:55:39.360685 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.360688 25648 net.cpp:165] Memory required for data: 207126540
I0627 10:55:39.360702 25648 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0627 10:55:39.360719 25648 net.cpp:100] Creating Layer bn4e_branch2b
I0627 10:55:39.360725 25648 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0627 10:55:39.360741 25648 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0627 10:55:39.360949 25648 net.cpp:150] Setting up bn4e_branch2b
I0627 10:55:39.360956 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.360958 25648 net.cpp:165] Memory required for data: 207327244
I0627 10:55:39.360975 25648 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0627 10:55:39.360988 25648 net.cpp:100] Creating Layer scale4e_branch2b
I0627 10:55:39.360994 25648 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0627 10:55:39.361006 25648 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0627 10:55:39.361058 25648 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0627 10:55:39.361194 25648 net.cpp:150] Setting up scale4e_branch2b
I0627 10:55:39.361202 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.361204 25648 net.cpp:165] Memory required for data: 207527948
I0627 10:55:39.361215 25648 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0627 10:55:39.361227 25648 net.cpp:100] Creating Layer res4e_branch2b_relu
I0627 10:55:39.361232 25648 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0627 10:55:39.361243 25648 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0627 10:55:39.361631 25648 net.cpp:150] Setting up res4e_branch2b_relu
I0627 10:55:39.361640 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.361644 25648 net.cpp:165] Memory required for data: 207728652
I0627 10:55:39.361649 25648 layer_factory.hpp:77] Creating layer res4e_branch2c
I0627 10:55:39.361665 25648 net.cpp:100] Creating Layer res4e_branch2c
I0627 10:55:39.361671 25648 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0627 10:55:39.361687 25648 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0627 10:55:39.363641 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.363668 25648 net.cpp:150] Setting up res4e_branch2c
I0627 10:55:39.363677 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.363680 25648 net.cpp:165] Memory required for data: 208531468
I0627 10:55:39.363692 25648 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0627 10:55:39.363708 25648 net.cpp:100] Creating Layer bn4e_branch2c
I0627 10:55:39.363714 25648 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0627 10:55:39.363729 25648 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0627 10:55:39.363940 25648 net.cpp:150] Setting up bn4e_branch2c
I0627 10:55:39.363946 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.363948 25648 net.cpp:165] Memory required for data: 209334284
I0627 10:55:39.363965 25648 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0627 10:55:39.363978 25648 net.cpp:100] Creating Layer scale4e_branch2c
I0627 10:55:39.363983 25648 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0627 10:55:39.363996 25648 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0627 10:55:39.364049 25648 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0627 10:55:39.364194 25648 net.cpp:150] Setting up scale4e_branch2c
I0627 10:55:39.364202 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.364204 25648 net.cpp:165] Memory required for data: 210137100
I0627 10:55:39.364215 25648 layer_factory.hpp:77] Creating layer res4e
I0627 10:55:39.364225 25648 net.cpp:100] Creating Layer res4e
I0627 10:55:39.364231 25648 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0627 10:55:39.364240 25648 net.cpp:444] res4e <- res4e_branch2c
I0627 10:55:39.364251 25648 net.cpp:418] res4e -> res4e
I0627 10:55:39.364289 25648 net.cpp:150] Setting up res4e
I0627 10:55:39.364296 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.364300 25648 net.cpp:165] Memory required for data: 210939916
I0627 10:55:39.364303 25648 layer_factory.hpp:77] Creating layer res4e_relu
I0627 10:55:39.364312 25648 net.cpp:100] Creating Layer res4e_relu
I0627 10:55:39.364317 25648 net.cpp:444] res4e_relu <- res4e
I0627 10:55:39.364328 25648 net.cpp:405] res4e_relu -> res4e (in-place)
I0627 10:55:39.364490 25648 net.cpp:150] Setting up res4e_relu
I0627 10:55:39.364496 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.364500 25648 net.cpp:165] Memory required for data: 211742732
I0627 10:55:39.364503 25648 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0627 10:55:39.364513 25648 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0627 10:55:39.364518 25648 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0627 10:55:39.364531 25648 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0627 10:55:39.364547 25648 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0627 10:55:39.364596 25648 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0627 10:55:39.364604 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.364609 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.364611 25648 net.cpp:165] Memory required for data: 213348364
I0627 10:55:39.364615 25648 layer_factory.hpp:77] Creating layer res4f_branch2a
I0627 10:55:39.364629 25648 net.cpp:100] Creating Layer res4f_branch2a
I0627 10:55:39.364637 25648 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0627 10:55:39.364656 25648 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0627 10:55:39.366446 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.366482 25648 net.cpp:150] Setting up res4f_branch2a
I0627 10:55:39.366495 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.366499 25648 net.cpp:165] Memory required for data: 213549068
I0627 10:55:39.366518 25648 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0627 10:55:39.366544 25648 net.cpp:100] Creating Layer bn4f_branch2a
I0627 10:55:39.366554 25648 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0627 10:55:39.366575 25648 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0627 10:55:39.366796 25648 net.cpp:150] Setting up bn4f_branch2a
I0627 10:55:39.366804 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.366808 25648 net.cpp:165] Memory required for data: 213749772
I0627 10:55:39.366828 25648 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0627 10:55:39.366847 25648 net.cpp:100] Creating Layer scale4f_branch2a
I0627 10:55:39.366853 25648 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0627 10:55:39.366879 25648 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0627 10:55:39.366950 25648 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0627 10:55:39.367094 25648 net.cpp:150] Setting up scale4f_branch2a
I0627 10:55:39.367102 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.367106 25648 net.cpp:165] Memory required for data: 213950476
I0627 10:55:39.367120 25648 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0627 10:55:39.367133 25648 net.cpp:100] Creating Layer res4f_branch2a_relu
I0627 10:55:39.367141 25648 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0627 10:55:39.367157 25648 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0627 10:55:39.367326 25648 net.cpp:150] Setting up res4f_branch2a_relu
I0627 10:55:39.367334 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.367337 25648 net.cpp:165] Memory required for data: 214151180
I0627 10:55:39.367343 25648 layer_factory.hpp:77] Creating layer res4f_branch2b
I0627 10:55:39.367365 25648 net.cpp:100] Creating Layer res4f_branch2b
I0627 10:55:39.367372 25648 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0627 10:55:39.367393 25648 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0627 10:55:39.369951 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:55:39.370203 25648 net.cpp:150] Setting up res4f_branch2b
I0627 10:55:39.370218 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.370223 25648 net.cpp:165] Memory required for data: 214351884
I0627 10:55:39.370239 25648 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0627 10:55:39.370257 25648 net.cpp:100] Creating Layer bn4f_branch2b
I0627 10:55:39.370265 25648 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0627 10:55:39.370285 25648 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0627 10:55:39.370503 25648 net.cpp:150] Setting up bn4f_branch2b
I0627 10:55:39.370512 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.370515 25648 net.cpp:165] Memory required for data: 214552588
I0627 10:55:39.370535 25648 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0627 10:55:39.370553 25648 net.cpp:100] Creating Layer scale4f_branch2b
I0627 10:55:39.370559 25648 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0627 10:55:39.370576 25648 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0627 10:55:39.370636 25648 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0627 10:55:39.370781 25648 net.cpp:150] Setting up scale4f_branch2b
I0627 10:55:39.370790 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.370793 25648 net.cpp:165] Memory required for data: 214753292
I0627 10:55:39.370807 25648 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0627 10:55:39.370820 25648 net.cpp:100] Creating Layer res4f_branch2b_relu
I0627 10:55:39.370827 25648 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0627 10:55:39.370844 25648 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0627 10:55:39.371024 25648 net.cpp:150] Setting up res4f_branch2b_relu
I0627 10:55:39.371033 25648 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:55:39.371037 25648 net.cpp:165] Memory required for data: 214953996
I0627 10:55:39.371043 25648 layer_factory.hpp:77] Creating layer res4f_branch2c
I0627 10:55:39.371063 25648 net.cpp:100] Creating Layer res4f_branch2c
I0627 10:55:39.371071 25648 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0627 10:55:39.371093 25648 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0627 10:55:39.373035 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.373066 25648 net.cpp:150] Setting up res4f_branch2c
I0627 10:55:39.373078 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.373081 25648 net.cpp:165] Memory required for data: 215756812
I0627 10:55:39.373095 25648 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0627 10:55:39.373111 25648 net.cpp:100] Creating Layer bn4f_branch2c
I0627 10:55:39.373118 25648 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0627 10:55:39.373132 25648 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0627 10:55:39.373344 25648 net.cpp:150] Setting up bn4f_branch2c
I0627 10:55:39.373351 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.373353 25648 net.cpp:165] Memory required for data: 216559628
I0627 10:55:39.373405 25648 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0627 10:55:39.373420 25648 net.cpp:100] Creating Layer scale4f_branch2c
I0627 10:55:39.373426 25648 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0627 10:55:39.373437 25648 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0627 10:55:39.373493 25648 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0627 10:55:39.373638 25648 net.cpp:150] Setting up scale4f_branch2c
I0627 10:55:39.373646 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.373649 25648 net.cpp:165] Memory required for data: 217362444
I0627 10:55:39.373659 25648 layer_factory.hpp:77] Creating layer res4f
I0627 10:55:39.373672 25648 net.cpp:100] Creating Layer res4f
I0627 10:55:39.373678 25648 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0627 10:55:39.373687 25648 net.cpp:444] res4f <- res4f_branch2c
I0627 10:55:39.373697 25648 net.cpp:418] res4f -> res4f
I0627 10:55:39.373735 25648 net.cpp:150] Setting up res4f
I0627 10:55:39.373744 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.373746 25648 net.cpp:165] Memory required for data: 218165260
I0627 10:55:39.373750 25648 layer_factory.hpp:77] Creating layer res4f_relu
I0627 10:55:39.373759 25648 net.cpp:100] Creating Layer res4f_relu
I0627 10:55:39.373764 25648 net.cpp:444] res4f_relu <- res4f
I0627 10:55:39.373775 25648 net.cpp:405] res4f_relu -> res4f (in-place)
I0627 10:55:39.374188 25648 net.cpp:150] Setting up res4f_relu
I0627 10:55:39.374197 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.374200 25648 net.cpp:165] Memory required for data: 218968076
I0627 10:55:39.374205 25648 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0627 10:55:39.374219 25648 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0627 10:55:39.374224 25648 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0627 10:55:39.374239 25648 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0627 10:55:39.374255 25648 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0627 10:55:39.374267 25648 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0627 10:55:39.374330 25648 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0627 10:55:39.374339 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.374343 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.374346 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:39.374348 25648 net.cpp:165] Memory required for data: 221376524
I0627 10:55:39.374352 25648 layer_factory.hpp:77] Creating layer res5a_branch1
I0627 10:55:39.374366 25648 net.cpp:100] Creating Layer res5a_branch1
I0627 10:55:39.374372 25648 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0627 10:55:39.374387 25648 net.cpp:418] res5a_branch1 -> res5a_branch1
I0627 10:55:39.380528 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 8568
I0627 10:55:39.380563 25648 net.cpp:150] Setting up res5a_branch1
I0627 10:55:39.380580 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.380584 25648 net.cpp:165] Memory required for data: 222982156
I0627 10:55:39.380605 25648 layer_factory.hpp:77] Creating layer bn5a_branch1
I0627 10:55:39.380632 25648 net.cpp:100] Creating Layer bn5a_branch1
I0627 10:55:39.380643 25648 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0627 10:55:39.380662 25648 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0627 10:55:39.380899 25648 net.cpp:150] Setting up bn5a_branch1
I0627 10:55:39.380906 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.380908 25648 net.cpp:165] Memory required for data: 224587788
I0627 10:55:39.380925 25648 layer_factory.hpp:77] Creating layer scale5a_branch1
I0627 10:55:39.380940 25648 net.cpp:100] Creating Layer scale5a_branch1
I0627 10:55:39.380945 25648 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0627 10:55:39.380957 25648 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0627 10:55:39.381013 25648 layer_factory.hpp:77] Creating layer scale5a_branch1
I0627 10:55:39.381161 25648 net.cpp:150] Setting up scale5a_branch1
I0627 10:55:39.381170 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.381171 25648 net.cpp:165] Memory required for data: 226193420
I0627 10:55:39.381182 25648 layer_factory.hpp:77] Creating layer res5a_branch2a
I0627 10:55:39.381199 25648 net.cpp:100] Creating Layer res5a_branch2a
I0627 10:55:39.381206 25648 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0627 10:55:39.381222 25648 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0627 10:55:39.384043 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.384075 25648 net.cpp:150] Setting up res5a_branch2a
I0627 10:55:39.384088 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.384091 25648 net.cpp:165] Memory required for data: 226594828
I0627 10:55:39.384107 25648 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0627 10:55:39.384130 25648 net.cpp:100] Creating Layer bn5a_branch2a
I0627 10:55:39.384138 25648 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0627 10:55:39.384156 25648 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0627 10:55:39.384380 25648 net.cpp:150] Setting up bn5a_branch2a
I0627 10:55:39.384387 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.384389 25648 net.cpp:165] Memory required for data: 226996236
I0627 10:55:39.384405 25648 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0627 10:55:39.384421 25648 net.cpp:100] Creating Layer scale5a_branch2a
I0627 10:55:39.384426 25648 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0627 10:55:39.384438 25648 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0627 10:55:39.384493 25648 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0627 10:55:39.384640 25648 net.cpp:150] Setting up scale5a_branch2a
I0627 10:55:39.384647 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.384650 25648 net.cpp:165] Memory required for data: 227397644
I0627 10:55:39.384660 25648 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0627 10:55:39.384671 25648 net.cpp:100] Creating Layer res5a_branch2a_relu
I0627 10:55:39.384677 25648 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0627 10:55:39.384688 25648 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0627 10:55:39.384850 25648 net.cpp:150] Setting up res5a_branch2a_relu
I0627 10:55:39.384856 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.384860 25648 net.cpp:165] Memory required for data: 227799052
I0627 10:55:39.384863 25648 layer_factory.hpp:77] Creating layer res5a_branch2b
I0627 10:55:39.384879 25648 net.cpp:100] Creating Layer res5a_branch2b
I0627 10:55:39.384884 25648 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0627 10:55:39.384901 25648 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0627 10:55:39.390875 25648 net.cpp:150] Setting up res5a_branch2b
I0627 10:55:39.390915 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.390918 25648 net.cpp:165] Memory required for data: 228200460
I0627 10:55:39.390941 25648 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0627 10:55:39.390972 25648 net.cpp:100] Creating Layer bn5a_branch2b
I0627 10:55:39.390983 25648 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0627 10:55:39.391001 25648 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0627 10:55:39.391242 25648 net.cpp:150] Setting up bn5a_branch2b
I0627 10:55:39.391249 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.391252 25648 net.cpp:165] Memory required for data: 228601868
I0627 10:55:39.391268 25648 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0627 10:55:39.391284 25648 net.cpp:100] Creating Layer scale5a_branch2b
I0627 10:55:39.391289 25648 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0627 10:55:39.391301 25648 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0627 10:55:39.391356 25648 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0627 10:55:39.391504 25648 net.cpp:150] Setting up scale5a_branch2b
I0627 10:55:39.391511 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.391515 25648 net.cpp:165] Memory required for data: 229003276
I0627 10:55:39.391525 25648 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0627 10:55:39.391535 25648 net.cpp:100] Creating Layer res5a_branch2b_relu
I0627 10:55:39.391541 25648 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0627 10:55:39.391552 25648 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0627 10:55:39.391757 25648 net.cpp:150] Setting up res5a_branch2b_relu
I0627 10:55:39.391763 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.391765 25648 net.cpp:165] Memory required for data: 229404684
I0627 10:55:39.391770 25648 layer_factory.hpp:77] Creating layer res5a_branch2c
I0627 10:55:39.391788 25648 net.cpp:100] Creating Layer res5a_branch2c
I0627 10:55:39.391793 25648 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0627 10:55:39.391809 25648 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0627 10:55:39.395525 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0627 10:55:39.395555 25648 net.cpp:150] Setting up res5a_branch2c
I0627 10:55:39.395568 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.395571 25648 net.cpp:165] Memory required for data: 231010316
I0627 10:55:39.395588 25648 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0627 10:55:39.395612 25648 net.cpp:100] Creating Layer bn5a_branch2c
I0627 10:55:39.395620 25648 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0627 10:55:39.395637 25648 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0627 10:55:39.395864 25648 net.cpp:150] Setting up bn5a_branch2c
I0627 10:55:39.395870 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.395872 25648 net.cpp:165] Memory required for data: 232615948
I0627 10:55:39.395889 25648 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0627 10:55:39.395905 25648 net.cpp:100] Creating Layer scale5a_branch2c
I0627 10:55:39.395910 25648 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0627 10:55:39.395921 25648 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0627 10:55:39.395978 25648 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0627 10:55:39.396128 25648 net.cpp:150] Setting up scale5a_branch2c
I0627 10:55:39.396136 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.396138 25648 net.cpp:165] Memory required for data: 234221580
I0627 10:55:39.396148 25648 layer_factory.hpp:77] Creating layer res5a
I0627 10:55:39.396159 25648 net.cpp:100] Creating Layer res5a
I0627 10:55:39.396165 25648 net.cpp:444] res5a <- res5a_branch1
I0627 10:55:39.396174 25648 net.cpp:444] res5a <- res5a_branch2c
I0627 10:55:39.396184 25648 net.cpp:418] res5a -> res5a
I0627 10:55:39.396220 25648 net.cpp:150] Setting up res5a
I0627 10:55:39.396229 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.396231 25648 net.cpp:165] Memory required for data: 235827212
I0627 10:55:39.396235 25648 layer_factory.hpp:77] Creating layer res5a_relu
I0627 10:55:39.396245 25648 net.cpp:100] Creating Layer res5a_relu
I0627 10:55:39.396251 25648 net.cpp:444] res5a_relu <- res5a
I0627 10:55:39.396261 25648 net.cpp:405] res5a_relu -> res5a (in-place)
I0627 10:55:39.396700 25648 net.cpp:150] Setting up res5a_relu
I0627 10:55:39.396709 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.396713 25648 net.cpp:165] Memory required for data: 237432844
I0627 10:55:39.396716 25648 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0627 10:55:39.396728 25648 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0627 10:55:39.396733 25648 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0627 10:55:39.396749 25648 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0627 10:55:39.396765 25648 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0627 10:55:39.396816 25648 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0627 10:55:39.396826 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.396829 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.396831 25648 net.cpp:165] Memory required for data: 240644108
I0627 10:55:39.396834 25648 layer_factory.hpp:77] Creating layer res5b_branch2a
I0627 10:55:39.396850 25648 net.cpp:100] Creating Layer res5b_branch2a
I0627 10:55:39.396857 25648 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0627 10:55:39.396869 25648 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0627 10:55:39.400818 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.400854 25648 net.cpp:150] Setting up res5b_branch2a
I0627 10:55:39.400871 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.400874 25648 net.cpp:165] Memory required for data: 241045516
I0627 10:55:39.400897 25648 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0627 10:55:39.400925 25648 net.cpp:100] Creating Layer bn5b_branch2a
I0627 10:55:39.400936 25648 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0627 10:55:39.400956 25648 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0627 10:55:39.401188 25648 net.cpp:150] Setting up bn5b_branch2a
I0627 10:55:39.401196 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.401198 25648 net.cpp:165] Memory required for data: 241446924
I0627 10:55:39.401216 25648 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0627 10:55:39.401230 25648 net.cpp:100] Creating Layer scale5b_branch2a
I0627 10:55:39.401235 25648 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0627 10:55:39.401248 25648 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0627 10:55:39.401304 25648 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0627 10:55:39.401453 25648 net.cpp:150] Setting up scale5b_branch2a
I0627 10:55:39.401459 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.401463 25648 net.cpp:165] Memory required for data: 241848332
I0627 10:55:39.401473 25648 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0627 10:55:39.401484 25648 net.cpp:100] Creating Layer res5b_branch2a_relu
I0627 10:55:39.401490 25648 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0627 10:55:39.401501 25648 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0627 10:55:39.401664 25648 net.cpp:150] Setting up res5b_branch2a_relu
I0627 10:55:39.401671 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.401674 25648 net.cpp:165] Memory required for data: 242249740
I0627 10:55:39.401679 25648 layer_factory.hpp:77] Creating layer res5b_branch2b
I0627 10:55:39.401695 25648 net.cpp:100] Creating Layer res5b_branch2b
I0627 10:55:39.401700 25648 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0627 10:55:39.401715 25648 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0627 10:55:39.407732 25648 net.cpp:150] Setting up res5b_branch2b
I0627 10:55:39.407761 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.407764 25648 net.cpp:165] Memory required for data: 242651148
I0627 10:55:39.407788 25648 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0627 10:55:39.407819 25648 net.cpp:100] Creating Layer bn5b_branch2b
I0627 10:55:39.407829 25648 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0627 10:55:39.407850 25648 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0627 10:55:39.408090 25648 net.cpp:150] Setting up bn5b_branch2b
I0627 10:55:39.408097 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.408099 25648 net.cpp:165] Memory required for data: 243052556
I0627 10:55:39.408115 25648 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0627 10:55:39.408130 25648 net.cpp:100] Creating Layer scale5b_branch2b
I0627 10:55:39.408136 25648 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0627 10:55:39.408149 25648 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0627 10:55:39.408203 25648 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0627 10:55:39.408354 25648 net.cpp:150] Setting up scale5b_branch2b
I0627 10:55:39.408361 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.408365 25648 net.cpp:165] Memory required for data: 243453964
I0627 10:55:39.408375 25648 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0627 10:55:39.408385 25648 net.cpp:100] Creating Layer res5b_branch2b_relu
I0627 10:55:39.408390 25648 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0627 10:55:39.408401 25648 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0627 10:55:39.408612 25648 net.cpp:150] Setting up res5b_branch2b_relu
I0627 10:55:39.408618 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.408620 25648 net.cpp:165] Memory required for data: 243855372
I0627 10:55:39.408624 25648 layer_factory.hpp:77] Creating layer res5b_branch2c
I0627 10:55:39.408641 25648 net.cpp:100] Creating Layer res5b_branch2c
I0627 10:55:39.408648 25648 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0627 10:55:39.408663 25648 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0627 10:55:39.412384 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0627 10:55:39.412415 25648 net.cpp:150] Setting up res5b_branch2c
I0627 10:55:39.412425 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.412428 25648 net.cpp:165] Memory required for data: 245461004
I0627 10:55:39.412444 25648 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0627 10:55:39.412467 25648 net.cpp:100] Creating Layer bn5b_branch2c
I0627 10:55:39.412475 25648 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0627 10:55:39.412493 25648 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0627 10:55:39.412732 25648 net.cpp:150] Setting up bn5b_branch2c
I0627 10:55:39.412739 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.412741 25648 net.cpp:165] Memory required for data: 247066636
I0627 10:55:39.412758 25648 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0627 10:55:39.412772 25648 net.cpp:100] Creating Layer scale5b_branch2c
I0627 10:55:39.412778 25648 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0627 10:55:39.412789 25648 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0627 10:55:39.412847 25648 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0627 10:55:39.412998 25648 net.cpp:150] Setting up scale5b_branch2c
I0627 10:55:39.413005 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.413008 25648 net.cpp:165] Memory required for data: 248672268
I0627 10:55:39.413019 25648 layer_factory.hpp:77] Creating layer res5b
I0627 10:55:39.413030 25648 net.cpp:100] Creating Layer res5b
I0627 10:55:39.413035 25648 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0627 10:55:39.413045 25648 net.cpp:444] res5b <- res5b_branch2c
I0627 10:55:39.413054 25648 net.cpp:418] res5b -> res5b
I0627 10:55:39.413092 25648 net.cpp:150] Setting up res5b
I0627 10:55:39.413100 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.413103 25648 net.cpp:165] Memory required for data: 250277900
I0627 10:55:39.413107 25648 layer_factory.hpp:77] Creating layer res5b_relu
I0627 10:55:39.413117 25648 net.cpp:100] Creating Layer res5b_relu
I0627 10:55:39.413122 25648 net.cpp:444] res5b_relu <- res5b
I0627 10:55:39.413133 25648 net.cpp:405] res5b_relu -> res5b (in-place)
I0627 10:55:39.413571 25648 net.cpp:150] Setting up res5b_relu
I0627 10:55:39.413581 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.413585 25648 net.cpp:165] Memory required for data: 251883532
I0627 10:55:39.413589 25648 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0627 10:55:39.413601 25648 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0627 10:55:39.413606 25648 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0627 10:55:39.413619 25648 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0627 10:55:39.413636 25648 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0627 10:55:39.413688 25648 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0627 10:55:39.413697 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.413700 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.413702 25648 net.cpp:165] Memory required for data: 255094796
I0627 10:55:39.413707 25648 layer_factory.hpp:77] Creating layer res5c_branch2a
I0627 10:55:39.413723 25648 net.cpp:100] Creating Layer res5c_branch2a
I0627 10:55:39.413729 25648 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0627 10:55:39.413743 25648 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0627 10:55:39.417395 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:39.417426 25648 net.cpp:150] Setting up res5c_branch2a
I0627 10:55:39.417438 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.417441 25648 net.cpp:165] Memory required for data: 255496204
I0627 10:55:39.417459 25648 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0627 10:55:39.417482 25648 net.cpp:100] Creating Layer bn5c_branch2a
I0627 10:55:39.417490 25648 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0627 10:55:39.417507 25648 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0627 10:55:39.417737 25648 net.cpp:150] Setting up bn5c_branch2a
I0627 10:55:39.417744 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.417747 25648 net.cpp:165] Memory required for data: 255897612
I0627 10:55:39.417763 25648 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0627 10:55:39.417779 25648 net.cpp:100] Creating Layer scale5c_branch2a
I0627 10:55:39.417784 25648 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0627 10:55:39.417796 25648 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0627 10:55:39.417852 25648 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0627 10:55:39.418001 25648 net.cpp:150] Setting up scale5c_branch2a
I0627 10:55:39.418009 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.418011 25648 net.cpp:165] Memory required for data: 256299020
I0627 10:55:39.418021 25648 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0627 10:55:39.418032 25648 net.cpp:100] Creating Layer res5c_branch2a_relu
I0627 10:55:39.418037 25648 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0627 10:55:39.418048 25648 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0627 10:55:39.418210 25648 net.cpp:150] Setting up res5c_branch2a_relu
I0627 10:55:39.418217 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.418220 25648 net.cpp:165] Memory required for data: 256700428
I0627 10:55:39.418224 25648 layer_factory.hpp:77] Creating layer res5c_branch2b
I0627 10:55:39.418241 25648 net.cpp:100] Creating Layer res5c_branch2b
I0627 10:55:39.418246 25648 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0627 10:55:39.418262 25648 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0627 10:55:39.424255 25648 net.cpp:150] Setting up res5c_branch2b
I0627 10:55:39.424288 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.424290 25648 net.cpp:165] Memory required for data: 257101836
I0627 10:55:39.424314 25648 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0627 10:55:39.424345 25648 net.cpp:100] Creating Layer bn5c_branch2b
I0627 10:55:39.424355 25648 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0627 10:55:39.424374 25648 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0627 10:55:39.424618 25648 net.cpp:150] Setting up bn5c_branch2b
I0627 10:55:39.424625 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.424628 25648 net.cpp:165] Memory required for data: 257503244
I0627 10:55:39.424645 25648 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0627 10:55:39.424660 25648 net.cpp:100] Creating Layer scale5c_branch2b
I0627 10:55:39.424665 25648 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0627 10:55:39.424677 25648 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0627 10:55:39.424734 25648 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0627 10:55:39.424885 25648 net.cpp:150] Setting up scale5c_branch2b
I0627 10:55:39.424892 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.424895 25648 net.cpp:165] Memory required for data: 257904652
I0627 10:55:39.424906 25648 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0627 10:55:39.424916 25648 net.cpp:100] Creating Layer res5c_branch2b_relu
I0627 10:55:39.424921 25648 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0627 10:55:39.424933 25648 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0627 10:55:39.425143 25648 net.cpp:150] Setting up res5c_branch2b_relu
I0627 10:55:39.425151 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:39.425154 25648 net.cpp:165] Memory required for data: 258306060
I0627 10:55:39.425158 25648 layer_factory.hpp:77] Creating layer res5c_branch2c
I0627 10:55:39.425175 25648 net.cpp:100] Creating Layer res5c_branch2c
I0627 10:55:39.425181 25648 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0627 10:55:39.425196 25648 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0627 10:55:39.428956 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0627 10:55:39.428989 25648 net.cpp:150] Setting up res5c_branch2c
I0627 10:55:39.429003 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.429005 25648 net.cpp:165] Memory required for data: 259911692
I0627 10:55:39.429023 25648 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0627 10:55:39.429046 25648 net.cpp:100] Creating Layer bn5c_branch2c
I0627 10:55:39.429056 25648 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0627 10:55:39.429074 25648 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0627 10:55:39.429309 25648 net.cpp:150] Setting up bn5c_branch2c
I0627 10:55:39.429316 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.429318 25648 net.cpp:165] Memory required for data: 261517324
I0627 10:55:39.429334 25648 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0627 10:55:39.429350 25648 net.cpp:100] Creating Layer scale5c_branch2c
I0627 10:55:39.429356 25648 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0627 10:55:39.429369 25648 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0627 10:55:39.429428 25648 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0627 10:55:39.429584 25648 net.cpp:150] Setting up scale5c_branch2c
I0627 10:55:39.429591 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.429594 25648 net.cpp:165] Memory required for data: 263122956
I0627 10:55:39.429603 25648 layer_factory.hpp:77] Creating layer res5c
I0627 10:55:39.429615 25648 net.cpp:100] Creating Layer res5c
I0627 10:55:39.429621 25648 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0627 10:55:39.429632 25648 net.cpp:444] res5c <- res5c_branch2c
I0627 10:55:39.429641 25648 net.cpp:418] res5c -> res5c
I0627 10:55:39.429682 25648 net.cpp:150] Setting up res5c
I0627 10:55:39.429690 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.429693 25648 net.cpp:165] Memory required for data: 264728588
I0627 10:55:39.429697 25648 layer_factory.hpp:77] Creating layer res5c_relu
I0627 10:55:39.429706 25648 net.cpp:100] Creating Layer res5c_relu
I0627 10:55:39.429711 25648 net.cpp:444] res5c_relu <- res5c
I0627 10:55:39.429723 25648 net.cpp:405] res5c_relu -> res5c (in-place)
I0627 10:55:39.429886 25648 net.cpp:150] Setting up res5c_relu
I0627 10:55:39.429893 25648 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:55:39.429895 25648 net.cpp:165] Memory required for data: 266334220
I0627 10:55:39.429899 25648 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0627 10:55:39.429919 25648 net.cpp:100] Creating Layer rpn_conv/3x3
I0627 10:55:39.429926 25648 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0627 10:55:39.429941 25648 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0627 10:55:40.015446 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0627 10:55:40.015743 25648 net.cpp:150] Setting up rpn_conv/3x3
I0627 10:55:40.015760 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:40.015763 25648 net.cpp:165] Memory required for data: 266735628
I0627 10:55:40.015787 25648 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0627 10:55:40.015810 25648 net.cpp:100] Creating Layer rpn_relu/3x3
I0627 10:55:40.015820 25648 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0627 10:55:40.015837 25648 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0627 10:55:40.016268 25648 net.cpp:150] Setting up rpn_relu/3x3
I0627 10:55:40.016278 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:40.016280 25648 net.cpp:165] Memory required for data: 267137036
I0627 10:55:40.016284 25648 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0627 10:55:40.016297 25648 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0627 10:55:40.016302 25648 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0627 10:55:40.016319 25648 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0627 10:55:40.016337 25648 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0627 10:55:40.016399 25648 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0627 10:55:40.016407 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:40.016412 25648 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:55:40.016413 25648 net.cpp:165] Memory required for data: 267939852
I0627 10:55:40.016417 25648 layer_factory.hpp:77] Creating layer rpn_cls_score
I0627 10:55:40.016438 25648 net.cpp:100] Creating Layer rpn_cls_score
I0627 10:55:40.016444 25648 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0627 10:55:40.016463 25648 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0627 10:55:40.018898 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:40.018924 25648 net.cpp:150] Setting up rpn_cls_score
I0627 10:55:40.018931 25648 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0627 10:55:40.018934 25648 net.cpp:165] Memory required for data: 267957100
I0627 10:55:40.018949 25648 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0627 10:55:40.018971 25648 net.cpp:100] Creating Layer rpn_bbox_pred
I0627 10:55:40.018978 25648 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0627 10:55:40.018996 25648 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0627 10:55:40.022800 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:40.022827 25648 net.cpp:150] Setting up rpn_bbox_pred
I0627 10:55:40.022836 25648 net.cpp:157] Top shape: 1 44 14 14 (8624)
I0627 10:55:40.022841 25648 net.cpp:165] Memory required for data: 267991596
I0627 10:55:40.022855 25648 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0627 10:55:40.022876 25648 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0627 10:55:40.022882 25648 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score
I0627 10:55:40.022897 25648 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0627 10:55:40.022945 25648 net.cpp:150] Setting up rpn_cls_score_reshape
I0627 10:55:40.022955 25648 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0627 10:55:40.022959 25648 net.cpp:165] Memory required for data: 268008844
I0627 10:55:40.022964 25648 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0627 10:55:40.022976 25648 net.cpp:100] Creating Layer rpn_cls_prob
I0627 10:55:40.022982 25648 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape
I0627 10:55:40.022996 25648 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0627 10:55:40.023264 25648 net.cpp:150] Setting up rpn_cls_prob
I0627 10:55:40.023275 25648 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0627 10:55:40.023278 25648 net.cpp:165] Memory required for data: 268026092
I0627 10:55:40.023283 25648 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0627 10:55:40.023296 25648 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0627 10:55:40.023303 25648 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0627 10:55:40.023320 25648 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0627 10:55:40.023361 25648 net.cpp:150] Setting up rpn_cls_prob_reshape
I0627 10:55:40.023371 25648 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0627 10:55:40.023375 25648 net.cpp:165] Memory required for data: 268043340
I0627 10:55:40.023380 25648 layer_factory.hpp:77] Creating layer proposal
I0627 10:55:40.023707 25648 net.cpp:100] Creating Layer proposal
I0627 10:55:40.023717 25648 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0627 10:55:40.023730 25648 net.cpp:444] proposal <- rpn_bbox_pred
I0627 10:55:40.023737 25648 net.cpp:444] proposal <- im_info
I0627 10:55:40.023747 25648 net.cpp:418] proposal -> rois
I0627 10:55:40.025002 25648 net.cpp:150] Setting up proposal
I0627 10:55:40.025014 25648 net.cpp:157] Top shape: 1 5 (5)
I0627 10:55:40.025017 25648 net.cpp:165] Memory required for data: 268043360
I0627 10:55:40.025022 25648 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0627 10:55:40.025032 25648 net.cpp:100] Creating Layer rois_proposal_0_split
I0627 10:55:40.025038 25648 net.cpp:444] rois_proposal_0_split <- rois
I0627 10:55:40.025053 25648 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_0
I0627 10:55:40.025068 25648 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_1
I0627 10:55:40.025116 25648 net.cpp:150] Setting up rois_proposal_0_split
I0627 10:55:40.025125 25648 net.cpp:157] Top shape: 1 5 (5)
I0627 10:55:40.025128 25648 net.cpp:157] Top shape: 1 5 (5)
I0627 10:55:40.025130 25648 net.cpp:165] Memory required for data: 268043400
I0627 10:55:40.025133 25648 layer_factory.hpp:77] Creating layer conv_new_1
I0627 10:55:40.025152 25648 net.cpp:100] Creating Layer conv_new_1
I0627 10:55:40.025159 25648 net.cpp:444] conv_new_1 <- res5c
I0627 10:55:40.025179 25648 net.cpp:418] conv_new_1 -> conv_new_1
I0627 10:55:40.285748 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:40.285781 25648 net.cpp:150] Setting up conv_new_1
I0627 10:55:40.285797 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:40.285801 25648 net.cpp:165] Memory required for data: 268846216
I0627 10:55:40.285826 25648 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0627 10:55:40.285851 25648 net.cpp:100] Creating Layer conv_new_1_relu
I0627 10:55:40.285859 25648 net.cpp:444] conv_new_1_relu <- conv_new_1
I0627 10:55:40.285876 25648 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0627 10:55:40.286048 25648 net.cpp:150] Setting up conv_new_1_relu
I0627 10:55:40.286056 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:40.286058 25648 net.cpp:165] Memory required for data: 269649032
I0627 10:55:40.286063 25648 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0627 10:55:40.286072 25648 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0627 10:55:40.286077 25648 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0627 10:55:40.286090 25648 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0627 10:55:40.286106 25648 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0627 10:55:40.286165 25648 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0627 10:55:40.286173 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:40.286178 25648 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:55:40.286180 25648 net.cpp:165] Memory required for data: 271254664
I0627 10:55:40.286185 25648 layer_factory.hpp:77] Creating layer rfcn_cls
I0627 10:55:40.286208 25648 net.cpp:100] Creating Layer rfcn_cls
I0627 10:55:40.286216 25648 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0627 10:55:40.286231 25648 net.cpp:418] rfcn_cls -> rfcn_cls
I0627 10:55:40.299885 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:40.299917 25648 net.cpp:150] Setting up rfcn_cls
I0627 10:55:40.299931 25648 net.cpp:157] Top shape: 1 98 14 14 (19208)
I0627 10:55:40.299933 25648 net.cpp:165] Memory required for data: 271331496
I0627 10:55:40.299952 25648 layer_factory.hpp:77] Creating layer rfcn_bbox
I0627 10:55:40.300010 25648 net.cpp:100] Creating Layer rfcn_bbox
I0627 10:55:40.300021 25648 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0627 10:55:40.300042 25648 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0627 10:55:40.351351 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:55:40.351384 25648 net.cpp:150] Setting up rfcn_bbox
I0627 10:55:40.351399 25648 net.cpp:157] Top shape: 1 392 14 14 (76832)
I0627 10:55:40.351402 25648 net.cpp:165] Memory required for data: 271638824
I0627 10:55:40.351424 25648 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0627 10:55:40.351450 25648 net.cpp:100] Creating Layer psroipooled_cls_rois
I0627 10:55:40.351459 25648 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0627 10:55:40.351475 25648 net.cpp:444] psroipooled_cls_rois <- rois_proposal_0_split_0
I0627 10:55:40.351488 25648 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0627 10:55:40.351510 25648 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0627 10:55:40.351573 25648 net.cpp:150] Setting up psroipooled_cls_rois
I0627 10:55:40.351583 25648 net.cpp:157] Top shape: 1 2 7 7 (98)
I0627 10:55:40.351584 25648 net.cpp:165] Memory required for data: 271639216
I0627 10:55:40.351588 25648 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0627 10:55:40.351601 25648 net.cpp:100] Creating Layer ave_cls_score_rois
I0627 10:55:40.351606 25648 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0627 10:55:40.351621 25648 net.cpp:418] ave_cls_score_rois -> cls_score
I0627 10:55:40.352098 25648 net.cpp:150] Setting up ave_cls_score_rois
I0627 10:55:40.352110 25648 net.cpp:157] Top shape: 1 2 1 1 (2)
I0627 10:55:40.352113 25648 net.cpp:165] Memory required for data: 271639224
I0627 10:55:40.352118 25648 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0627 10:55:40.352134 25648 net.cpp:100] Creating Layer psroipooled_loc_rois
I0627 10:55:40.352141 25648 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0627 10:55:40.352152 25648 net.cpp:444] psroipooled_loc_rois <- rois_proposal_0_split_1
I0627 10:55:40.352162 25648 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0627 10:55:40.352176 25648 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0627 10:55:40.352226 25648 net.cpp:150] Setting up psroipooled_loc_rois
I0627 10:55:40.352236 25648 net.cpp:157] Top shape: 1 8 7 7 (392)
I0627 10:55:40.352239 25648 net.cpp:165] Memory required for data: 271640792
I0627 10:55:40.352244 25648 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0627 10:55:40.352258 25648 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0627 10:55:40.352265 25648 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0627 10:55:40.352282 25648 net.cpp:418] ave_bbox_pred_rois -> bbox_pred_pre
I0627 10:55:40.352471 25648 net.cpp:150] Setting up ave_bbox_pred_rois
I0627 10:55:40.352483 25648 net.cpp:157] Top shape: 1 8 1 1 (8)
I0627 10:55:40.352486 25648 net.cpp:165] Memory required for data: 271640824
I0627 10:55:40.352491 25648 layer_factory.hpp:77] Creating layer cls_prob
I0627 10:55:40.352504 25648 net.cpp:100] Creating Layer cls_prob
I0627 10:55:40.352509 25648 net.cpp:444] cls_prob <- cls_score
I0627 10:55:40.352525 25648 net.cpp:418] cls_prob -> cls_prob_pre
I0627 10:55:40.352768 25648 net.cpp:150] Setting up cls_prob
I0627 10:55:40.352779 25648 net.cpp:157] Top shape: 1 2 1 1 (2)
I0627 10:55:40.352783 25648 net.cpp:165] Memory required for data: 271640832
I0627 10:55:40.352788 25648 layer_factory.hpp:77] Creating layer cls_prob_reshape
I0627 10:55:40.352804 25648 net.cpp:100] Creating Layer cls_prob_reshape
I0627 10:55:40.352810 25648 net.cpp:444] cls_prob_reshape <- cls_prob_pre
I0627 10:55:40.352825 25648 net.cpp:418] cls_prob_reshape -> cls_prob
I0627 10:55:40.352865 25648 net.cpp:150] Setting up cls_prob_reshape
I0627 10:55:40.352874 25648 net.cpp:157] Top shape: 1 2 (2)
I0627 10:55:40.352876 25648 net.cpp:165] Memory required for data: 271640840
I0627 10:55:40.352880 25648 layer_factory.hpp:77] Creating layer bbox_pred_reshape
I0627 10:55:40.352890 25648 net.cpp:100] Creating Layer bbox_pred_reshape
I0627 10:55:40.352895 25648 net.cpp:444] bbox_pred_reshape <- bbox_pred_pre
I0627 10:55:40.352910 25648 net.cpp:418] bbox_pred_reshape -> bbox_pred
I0627 10:55:40.352946 25648 net.cpp:150] Setting up bbox_pred_reshape
I0627 10:55:40.352953 25648 net.cpp:157] Top shape: 1 8 (8)
I0627 10:55:40.352957 25648 net.cpp:165] Memory required for data: 271640872
I0627 10:55:40.352962 25648 net.cpp:228] bbox_pred_reshape does not need backward computation.
I0627 10:55:40.352965 25648 net.cpp:228] cls_prob_reshape does not need backward computation.
I0627 10:55:40.352969 25648 net.cpp:228] cls_prob does not need backward computation.
I0627 10:55:40.352973 25648 net.cpp:228] ave_bbox_pred_rois does not need backward computation.
I0627 10:55:40.352975 25648 net.cpp:228] psroipooled_loc_rois does not need backward computation.
I0627 10:55:40.352980 25648 net.cpp:228] ave_cls_score_rois does not need backward computation.
I0627 10:55:40.352983 25648 net.cpp:228] psroipooled_cls_rois does not need backward computation.
I0627 10:55:40.352990 25648 net.cpp:228] rfcn_bbox does not need backward computation.
I0627 10:55:40.352998 25648 net.cpp:228] rfcn_cls does not need backward computation.
I0627 10:55:40.353003 25648 net.cpp:228] conv_new_1_conv_new_1_relu_0_split does not need backward computation.
I0627 10:55:40.353010 25648 net.cpp:228] conv_new_1_relu does not need backward computation.
I0627 10:55:40.353016 25648 net.cpp:228] conv_new_1 does not need backward computation.
I0627 10:55:40.353024 25648 net.cpp:228] rois_proposal_0_split does not need backward computation.
I0627 10:55:40.353029 25648 net.cpp:228] proposal does not need backward computation.
I0627 10:55:40.353036 25648 net.cpp:228] rpn_cls_prob_reshape does not need backward computation.
I0627 10:55:40.353042 25648 net.cpp:228] rpn_cls_prob does not need backward computation.
I0627 10:55:40.353049 25648 net.cpp:228] rpn_cls_score_reshape does not need backward computation.
I0627 10:55:40.353054 25648 net.cpp:228] rpn_bbox_pred does not need backward computation.
I0627 10:55:40.353060 25648 net.cpp:228] rpn_cls_score does not need backward computation.
I0627 10:55:40.353065 25648 net.cpp:228] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0627 10:55:40.353071 25648 net.cpp:228] rpn_relu/3x3 does not need backward computation.
I0627 10:55:40.353076 25648 net.cpp:228] rpn_conv/3x3 does not need backward computation.
I0627 10:55:40.353082 25648 net.cpp:228] res5c_relu does not need backward computation.
I0627 10:55:40.353088 25648 net.cpp:228] res5c does not need backward computation.
I0627 10:55:40.353096 25648 net.cpp:228] scale5c_branch2c does not need backward computation.
I0627 10:55:40.353101 25648 net.cpp:228] bn5c_branch2c does not need backward computation.
I0627 10:55:40.353106 25648 net.cpp:228] res5c_branch2c does not need backward computation.
I0627 10:55:40.353111 25648 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I0627 10:55:40.353116 25648 net.cpp:228] scale5c_branch2b does not need backward computation.
I0627 10:55:40.353121 25648 net.cpp:228] bn5c_branch2b does not need backward computation.
I0627 10:55:40.353127 25648 net.cpp:228] res5c_branch2b does not need backward computation.
I0627 10:55:40.353133 25648 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I0627 10:55:40.353138 25648 net.cpp:228] scale5c_branch2a does not need backward computation.
I0627 10:55:40.353143 25648 net.cpp:228] bn5c_branch2a does not need backward computation.
I0627 10:55:40.353148 25648 net.cpp:228] res5c_branch2a does not need backward computation.
I0627 10:55:40.353155 25648 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I0627 10:55:40.353161 25648 net.cpp:228] res5b_relu does not need backward computation.
I0627 10:55:40.353168 25648 net.cpp:228] res5b does not need backward computation.
I0627 10:55:40.353175 25648 net.cpp:228] scale5b_branch2c does not need backward computation.
I0627 10:55:40.353180 25648 net.cpp:228] bn5b_branch2c does not need backward computation.
I0627 10:55:40.353185 25648 net.cpp:228] res5b_branch2c does not need backward computation.
I0627 10:55:40.353191 25648 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I0627 10:55:40.353196 25648 net.cpp:228] scale5b_branch2b does not need backward computation.
I0627 10:55:40.353201 25648 net.cpp:228] bn5b_branch2b does not need backward computation.
I0627 10:55:40.353207 25648 net.cpp:228] res5b_branch2b does not need backward computation.
I0627 10:55:40.353214 25648 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I0627 10:55:40.353219 25648 net.cpp:228] scale5b_branch2a does not need backward computation.
I0627 10:55:40.353224 25648 net.cpp:228] bn5b_branch2a does not need backward computation.
I0627 10:55:40.353229 25648 net.cpp:228] res5b_branch2a does not need backward computation.
I0627 10:55:40.353235 25648 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I0627 10:55:40.353240 25648 net.cpp:228] res5a_relu does not need backward computation.
I0627 10:55:40.353246 25648 net.cpp:228] res5a does not need backward computation.
I0627 10:55:40.353253 25648 net.cpp:228] scale5a_branch2c does not need backward computation.
I0627 10:55:40.353258 25648 net.cpp:228] bn5a_branch2c does not need backward computation.
I0627 10:55:40.353265 25648 net.cpp:228] res5a_branch2c does not need backward computation.
I0627 10:55:40.353269 25648 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I0627 10:55:40.353276 25648 net.cpp:228] scale5a_branch2b does not need backward computation.
I0627 10:55:40.353281 25648 net.cpp:228] bn5a_branch2b does not need backward computation.
I0627 10:55:40.353286 25648 net.cpp:228] res5a_branch2b does not need backward computation.
I0627 10:55:40.353291 25648 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I0627 10:55:40.353296 25648 net.cpp:228] scale5a_branch2a does not need backward computation.
I0627 10:55:40.353302 25648 net.cpp:228] bn5a_branch2a does not need backward computation.
I0627 10:55:40.353307 25648 net.cpp:228] res5a_branch2a does not need backward computation.
I0627 10:55:40.353313 25648 net.cpp:228] scale5a_branch1 does not need backward computation.
I0627 10:55:40.353318 25648 net.cpp:228] bn5a_branch1 does not need backward computation.
I0627 10:55:40.353323 25648 net.cpp:228] res5a_branch1 does not need backward computation.
I0627 10:55:40.353330 25648 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I0627 10:55:40.353337 25648 net.cpp:228] res4f_relu does not need backward computation.
I0627 10:55:40.353341 25648 net.cpp:228] res4f does not need backward computation.
I0627 10:55:40.353348 25648 net.cpp:228] scale4f_branch2c does not need backward computation.
I0627 10:55:40.353353 25648 net.cpp:228] bn4f_branch2c does not need backward computation.
I0627 10:55:40.353358 25648 net.cpp:228] res4f_branch2c does not need backward computation.
I0627 10:55:40.353360 25648 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I0627 10:55:40.353363 25648 net.cpp:228] scale4f_branch2b does not need backward computation.
I0627 10:55:40.353366 25648 net.cpp:228] bn4f_branch2b does not need backward computation.
I0627 10:55:40.353371 25648 net.cpp:228] res4f_branch2b does not need backward computation.
I0627 10:55:40.353377 25648 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I0627 10:55:40.353384 25648 net.cpp:228] scale4f_branch2a does not need backward computation.
I0627 10:55:40.353389 25648 net.cpp:228] bn4f_branch2a does not need backward computation.
I0627 10:55:40.353394 25648 net.cpp:228] res4f_branch2a does not need backward computation.
I0627 10:55:40.353401 25648 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I0627 10:55:40.353406 25648 net.cpp:228] res4e_relu does not need backward computation.
I0627 10:55:40.353411 25648 net.cpp:228] res4e does not need backward computation.
I0627 10:55:40.353418 25648 net.cpp:228] scale4e_branch2c does not need backward computation.
I0627 10:55:40.353423 25648 net.cpp:228] bn4e_branch2c does not need backward computation.
I0627 10:55:40.353430 25648 net.cpp:228] res4e_branch2c does not need backward computation.
I0627 10:55:40.353435 25648 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I0627 10:55:40.353440 25648 net.cpp:228] scale4e_branch2b does not need backward computation.
I0627 10:55:40.353446 25648 net.cpp:228] bn4e_branch2b does not need backward computation.
I0627 10:55:40.353451 25648 net.cpp:228] res4e_branch2b does not need backward computation.
I0627 10:55:40.353456 25648 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I0627 10:55:40.353462 25648 net.cpp:228] scale4e_branch2a does not need backward computation.
I0627 10:55:40.353467 25648 net.cpp:228] bn4e_branch2a does not need backward computation.
I0627 10:55:40.353472 25648 net.cpp:228] res4e_branch2a does not need backward computation.
I0627 10:55:40.353480 25648 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I0627 10:55:40.353487 25648 net.cpp:228] res4d_relu does not need backward computation.
I0627 10:55:40.353492 25648 net.cpp:228] res4d does not need backward computation.
I0627 10:55:40.353498 25648 net.cpp:228] scale4d_branch2c does not need backward computation.
I0627 10:55:40.353503 25648 net.cpp:228] bn4d_branch2c does not need backward computation.
I0627 10:55:40.353508 25648 net.cpp:228] res4d_branch2c does not need backward computation.
I0627 10:55:40.353514 25648 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I0627 10:55:40.353519 25648 net.cpp:228] scale4d_branch2b does not need backward computation.
I0627 10:55:40.353524 25648 net.cpp:228] bn4d_branch2b does not need backward computation.
I0627 10:55:40.353530 25648 net.cpp:228] res4d_branch2b does not need backward computation.
I0627 10:55:40.353535 25648 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I0627 10:55:40.353541 25648 net.cpp:228] scale4d_branch2a does not need backward computation.
I0627 10:55:40.353546 25648 net.cpp:228] bn4d_branch2a does not need backward computation.
I0627 10:55:40.353551 25648 net.cpp:228] res4d_branch2a does not need backward computation.
I0627 10:55:40.353559 25648 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I0627 10:55:40.353564 25648 net.cpp:228] res4c_relu does not need backward computation.
I0627 10:55:40.353569 25648 net.cpp:228] res4c does not need backward computation.
I0627 10:55:40.353576 25648 net.cpp:228] scale4c_branch2c does not need backward computation.
I0627 10:55:40.353581 25648 net.cpp:228] bn4c_branch2c does not need backward computation.
I0627 10:55:40.353586 25648 net.cpp:228] res4c_branch2c does not need backward computation.
I0627 10:55:40.353592 25648 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I0627 10:55:40.353597 25648 net.cpp:228] scale4c_branch2b does not need backward computation.
I0627 10:55:40.353602 25648 net.cpp:228] bn4c_branch2b does not need backward computation.
I0627 10:55:40.353607 25648 net.cpp:228] res4c_branch2b does not need backward computation.
I0627 10:55:40.353613 25648 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I0627 10:55:40.353618 25648 net.cpp:228] scale4c_branch2a does not need backward computation.
I0627 10:55:40.353624 25648 net.cpp:228] bn4c_branch2a does not need backward computation.
I0627 10:55:40.353629 25648 net.cpp:228] res4c_branch2a does not need backward computation.
I0627 10:55:40.353636 25648 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I0627 10:55:40.353641 25648 net.cpp:228] res4b_relu does not need backward computation.
I0627 10:55:40.353646 25648 net.cpp:228] res4b does not need backward computation.
I0627 10:55:40.353653 25648 net.cpp:228] scale4b_branch2c does not need backward computation.
I0627 10:55:40.353657 25648 net.cpp:228] bn4b_branch2c does not need backward computation.
I0627 10:55:40.353663 25648 net.cpp:228] res4b_branch2c does not need backward computation.
I0627 10:55:40.353669 25648 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I0627 10:55:40.353674 25648 net.cpp:228] scale4b_branch2b does not need backward computation.
I0627 10:55:40.353679 25648 net.cpp:228] bn4b_branch2b does not need backward computation.
I0627 10:55:40.353685 25648 net.cpp:228] res4b_branch2b does not need backward computation.
I0627 10:55:40.353690 25648 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I0627 10:55:40.353695 25648 net.cpp:228] scale4b_branch2a does not need backward computation.
I0627 10:55:40.353701 25648 net.cpp:228] bn4b_branch2a does not need backward computation.
I0627 10:55:40.353706 25648 net.cpp:228] res4b_branch2a does not need backward computation.
I0627 10:55:40.353713 25648 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I0627 10:55:40.353720 25648 net.cpp:228] res4a_relu does not need backward computation.
I0627 10:55:40.353725 25648 net.cpp:228] res4a does not need backward computation.
I0627 10:55:40.353734 25648 net.cpp:228] scale4a_branch2c does not need backward computation.
I0627 10:55:40.353739 25648 net.cpp:228] bn4a_branch2c does not need backward computation.
I0627 10:55:40.353744 25648 net.cpp:228] res4a_branch2c does not need backward computation.
I0627 10:55:40.353749 25648 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I0627 10:55:40.353754 25648 net.cpp:228] scale4a_branch2b does not need backward computation.
I0627 10:55:40.353760 25648 net.cpp:228] bn4a_branch2b does not need backward computation.
I0627 10:55:40.353765 25648 net.cpp:228] res4a_branch2b does not need backward computation.
I0627 10:55:40.353771 25648 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I0627 10:55:40.353776 25648 net.cpp:228] scale4a_branch2a does not need backward computation.
I0627 10:55:40.353782 25648 net.cpp:228] bn4a_branch2a does not need backward computation.
I0627 10:55:40.353787 25648 net.cpp:228] res4a_branch2a does not need backward computation.
I0627 10:55:40.353793 25648 net.cpp:228] scale4a_branch1 does not need backward computation.
I0627 10:55:40.353799 25648 net.cpp:228] bn4a_branch1 does not need backward computation.
I0627 10:55:40.353804 25648 net.cpp:228] res4a_branch1 does not need backward computation.
I0627 10:55:40.353811 25648 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I0627 10:55:40.353817 25648 net.cpp:228] res3d_relu does not need backward computation.
I0627 10:55:40.353822 25648 net.cpp:228] res3d does not need backward computation.
I0627 10:55:40.353830 25648 net.cpp:228] scale3d_branch2c does not need backward computation.
I0627 10:55:40.353835 25648 net.cpp:228] bn3d_branch2c does not need backward computation.
I0627 10:55:40.353840 25648 net.cpp:228] res3d_branch2c does not need backward computation.
I0627 10:55:40.353847 25648 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I0627 10:55:40.353852 25648 net.cpp:228] scale3d_branch2b does not need backward computation.
I0627 10:55:40.353857 25648 net.cpp:228] bn3d_branch2b does not need backward computation.
I0627 10:55:40.353863 25648 net.cpp:228] res3d_branch2b does not need backward computation.
I0627 10:55:40.353869 25648 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I0627 10:55:40.353874 25648 net.cpp:228] scale3d_branch2a does not need backward computation.
I0627 10:55:40.353879 25648 net.cpp:228] bn3d_branch2a does not need backward computation.
I0627 10:55:40.353885 25648 net.cpp:228] res3d_branch2a does not need backward computation.
I0627 10:55:40.353893 25648 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I0627 10:55:40.353898 25648 net.cpp:228] res3c_relu does not need backward computation.
I0627 10:55:40.353902 25648 net.cpp:228] res3c does not need backward computation.
I0627 10:55:40.353909 25648 net.cpp:228] scale3c_branch2c does not need backward computation.
I0627 10:55:40.353914 25648 net.cpp:228] bn3c_branch2c does not need backward computation.
I0627 10:55:40.353919 25648 net.cpp:228] res3c_branch2c does not need backward computation.
I0627 10:55:40.353925 25648 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I0627 10:55:40.353930 25648 net.cpp:228] scale3c_branch2b does not need backward computation.
I0627 10:55:40.353936 25648 net.cpp:228] bn3c_branch2b does not need backward computation.
I0627 10:55:40.353941 25648 net.cpp:228] res3c_branch2b does not need backward computation.
I0627 10:55:40.353947 25648 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I0627 10:55:40.353952 25648 net.cpp:228] scale3c_branch2a does not need backward computation.
I0627 10:55:40.353958 25648 net.cpp:228] bn3c_branch2a does not need backward computation.
I0627 10:55:40.353963 25648 net.cpp:228] res3c_branch2a does not need backward computation.
I0627 10:55:40.353971 25648 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I0627 10:55:40.353976 25648 net.cpp:228] res3b_relu does not need backward computation.
I0627 10:55:40.353981 25648 net.cpp:228] res3b does not need backward computation.
I0627 10:55:40.353989 25648 net.cpp:228] scale3b_branch2c does not need backward computation.
I0627 10:55:40.353994 25648 net.cpp:228] bn3b_branch2c does not need backward computation.
I0627 10:55:40.353999 25648 net.cpp:228] res3b_branch2c does not need backward computation.
I0627 10:55:40.354007 25648 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I0627 10:55:40.354012 25648 net.cpp:228] scale3b_branch2b does not need backward computation.
I0627 10:55:40.354017 25648 net.cpp:228] bn3b_branch2b does not need backward computation.
I0627 10:55:40.354022 25648 net.cpp:228] res3b_branch2b does not need backward computation.
I0627 10:55:40.354028 25648 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I0627 10:55:40.354033 25648 net.cpp:228] scale3b_branch2a does not need backward computation.
I0627 10:55:40.354039 25648 net.cpp:228] bn3b_branch2a does not need backward computation.
I0627 10:55:40.354044 25648 net.cpp:228] res3b_branch2a does not need backward computation.
I0627 10:55:40.354053 25648 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I0627 10:55:40.354058 25648 net.cpp:228] res3a_relu does not need backward computation.
I0627 10:55:40.354063 25648 net.cpp:228] res3a does not need backward computation.
I0627 10:55:40.354070 25648 net.cpp:228] scale3a_branch2c does not need backward computation.
I0627 10:55:40.354075 25648 net.cpp:228] bn3a_branch2c does not need backward computation.
I0627 10:55:40.354081 25648 net.cpp:228] res3a_branch2c does not need backward computation.
I0627 10:55:40.354087 25648 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I0627 10:55:40.354092 25648 net.cpp:228] scale3a_branch2b does not need backward computation.
I0627 10:55:40.354099 25648 net.cpp:228] bn3a_branch2b does not need backward computation.
I0627 10:55:40.354104 25648 net.cpp:228] res3a_branch2b does not need backward computation.
I0627 10:55:40.354110 25648 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I0627 10:55:40.354115 25648 net.cpp:228] scale3a_branch2a does not need backward computation.
I0627 10:55:40.354120 25648 net.cpp:228] bn3a_branch2a does not need backward computation.
I0627 10:55:40.354125 25648 net.cpp:228] res3a_branch2a does not need backward computation.
I0627 10:55:40.354131 25648 net.cpp:228] scale3a_branch1 does not need backward computation.
I0627 10:55:40.354137 25648 net.cpp:228] bn3a_branch1 does not need backward computation.
I0627 10:55:40.354142 25648 net.cpp:228] res3a_branch1 does not need backward computation.
I0627 10:55:40.354149 25648 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0627 10:55:40.354156 25648 net.cpp:228] res2c_relu does not need backward computation.
I0627 10:55:40.354161 25648 net.cpp:228] res2c does not need backward computation.
I0627 10:55:40.354167 25648 net.cpp:228] scale2c_branch2c does not need backward computation.
I0627 10:55:40.354172 25648 net.cpp:228] bn2c_branch2c does not need backward computation.
I0627 10:55:40.354178 25648 net.cpp:228] res2c_branch2c does not need backward computation.
I0627 10:55:40.354183 25648 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0627 10:55:40.354189 25648 net.cpp:228] scale2c_branch2b does not need backward computation.
I0627 10:55:40.354194 25648 net.cpp:228] bn2c_branch2b does not need backward computation.
I0627 10:55:40.354199 25648 net.cpp:228] res2c_branch2b does not need backward computation.
I0627 10:55:40.354205 25648 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0627 10:55:40.354210 25648 net.cpp:228] scale2c_branch2a does not need backward computation.
I0627 10:55:40.354216 25648 net.cpp:228] bn2c_branch2a does not need backward computation.
I0627 10:55:40.354221 25648 net.cpp:228] res2c_branch2a does not need backward computation.
I0627 10:55:40.354228 25648 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0627 10:55:40.354234 25648 net.cpp:228] res2b_relu does not need backward computation.
I0627 10:55:40.354239 25648 net.cpp:228] res2b does not need backward computation.
I0627 10:55:40.354248 25648 net.cpp:228] scale2b_branch2c does not need backward computation.
I0627 10:55:40.354251 25648 net.cpp:228] bn2b_branch2c does not need backward computation.
I0627 10:55:40.354257 25648 net.cpp:228] res2b_branch2c does not need backward computation.
I0627 10:55:40.354264 25648 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0627 10:55:40.354269 25648 net.cpp:228] scale2b_branch2b does not need backward computation.
I0627 10:55:40.354274 25648 net.cpp:228] bn2b_branch2b does not need backward computation.
I0627 10:55:40.354279 25648 net.cpp:228] res2b_branch2b does not need backward computation.
I0627 10:55:40.354285 25648 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0627 10:55:40.354290 25648 net.cpp:228] scale2b_branch2a does not need backward computation.
I0627 10:55:40.354296 25648 net.cpp:228] bn2b_branch2a does not need backward computation.
I0627 10:55:40.354301 25648 net.cpp:228] res2b_branch2a does not need backward computation.
I0627 10:55:40.354310 25648 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0627 10:55:40.354315 25648 net.cpp:228] res2a_relu does not need backward computation.
I0627 10:55:40.354320 25648 net.cpp:228] res2a does not need backward computation.
I0627 10:55:40.354327 25648 net.cpp:228] scale2a_branch2c does not need backward computation.
I0627 10:55:40.354332 25648 net.cpp:228] bn2a_branch2c does not need backward computation.
I0627 10:55:40.354338 25648 net.cpp:228] res2a_branch2c does not need backward computation.
I0627 10:55:40.354344 25648 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0627 10:55:40.354349 25648 net.cpp:228] scale2a_branch2b does not need backward computation.
I0627 10:55:40.354355 25648 net.cpp:228] bn2a_branch2b does not need backward computation.
I0627 10:55:40.354360 25648 net.cpp:228] res2a_branch2b does not need backward computation.
I0627 10:55:40.354367 25648 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0627 10:55:40.354372 25648 net.cpp:228] scale2a_branch2a does not need backward computation.
I0627 10:55:40.354377 25648 net.cpp:228] bn2a_branch2a does not need backward computation.
I0627 10:55:40.354382 25648 net.cpp:228] res2a_branch2a does not need backward computation.
I0627 10:55:40.354388 25648 net.cpp:228] scale2a_branch1 does not need backward computation.
I0627 10:55:40.354394 25648 net.cpp:228] bn2a_branch1 does not need backward computation.
I0627 10:55:40.354399 25648 net.cpp:228] res2a_branch1 does not need backward computation.
I0627 10:55:40.354406 25648 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0627 10:55:40.354411 25648 net.cpp:228] pool1 does not need backward computation.
I0627 10:55:40.354418 25648 net.cpp:228] conv1_relu does not need backward computation.
I0627 10:55:40.354423 25648 net.cpp:228] scale_conv1 does not need backward computation.
I0627 10:55:40.354429 25648 net.cpp:228] bn_conv1 does not need backward computation.
I0627 10:55:40.354434 25648 net.cpp:228] conv1 does not need backward computation.
I0627 10:55:40.354440 25648 net.cpp:228] input does not need backward computation.
I0627 10:55:40.354444 25648 net.cpp:270] This network produces output bbox_pred
I0627 10:55:40.354452 25648 net.cpp:270] This network produces output cls_prob
I0627 10:55:40.354759 25648 net.cpp:283] Network initialization done.
I0627 10:55:40.464581 25648 net.cpp:771] Ignoring source layer input-data
I0627 10:55:40.464601 25648 net.cpp:771] Ignoring source layer data_input-data_0_split
I0627 10:55:40.464606 25648 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I0627 10:55:40.464610 25648 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I0627 10:55:40.464612 25648 net.cpp:774] Copying source layer conv1
I0627 10:55:40.464717 25648 net.cpp:774] Copying source layer bn_conv1
I0627 10:55:40.464727 25648 net.cpp:774] Copying source layer scale_conv1
I0627 10:55:40.464732 25648 net.cpp:774] Copying source layer conv1_relu
I0627 10:55:40.464735 25648 net.cpp:774] Copying source layer pool1
I0627 10:55:40.464737 25648 net.cpp:774] Copying source layer pool1_pool1_0_split
I0627 10:55:40.464740 25648 net.cpp:774] Copying source layer res2a_branch1
I0627 10:55:40.464880 25648 net.cpp:774] Copying source layer bn2a_branch1
I0627 10:55:40.464893 25648 net.cpp:774] Copying source layer scale2a_branch1
I0627 10:55:40.464902 25648 net.cpp:774] Copying source layer res2a_branch2a
I0627 10:55:40.464942 25648 net.cpp:774] Copying source layer bn2a_branch2a
I0627 10:55:40.464951 25648 net.cpp:774] Copying source layer scale2a_branch2a
I0627 10:55:40.464956 25648 net.cpp:774] Copying source layer res2a_branch2a_relu
I0627 10:55:40.464958 25648 net.cpp:774] Copying source layer res2a_branch2b
I0627 10:55:40.465270 25648 net.cpp:774] Copying source layer bn2a_branch2b
I0627 10:55:40.465278 25648 net.cpp:774] Copying source layer scale2a_branch2b
I0627 10:55:40.465286 25648 net.cpp:774] Copying source layer res2a_branch2b_relu
I0627 10:55:40.465287 25648 net.cpp:774] Copying source layer res2a_branch2c
I0627 10:55:40.465430 25648 net.cpp:774] Copying source layer bn2a_branch2c
I0627 10:55:40.465440 25648 net.cpp:774] Copying source layer scale2a_branch2c
I0627 10:55:40.465451 25648 net.cpp:774] Copying source layer res2a
I0627 10:55:40.465452 25648 net.cpp:774] Copying source layer res2a_relu
I0627 10:55:40.465454 25648 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0627 10:55:40.465457 25648 net.cpp:774] Copying source layer res2b_branch2a
I0627 10:55:40.465601 25648 net.cpp:774] Copying source layer bn2b_branch2a
I0627 10:55:40.465610 25648 net.cpp:774] Copying source layer scale2b_branch2a
I0627 10:55:40.465615 25648 net.cpp:774] Copying source layer res2b_branch2a_relu
I0627 10:55:40.465617 25648 net.cpp:774] Copying source layer res2b_branch2b
I0627 10:55:40.465929 25648 net.cpp:774] Copying source layer bn2b_branch2b
I0627 10:55:40.465937 25648 net.cpp:774] Copying source layer scale2b_branch2b
I0627 10:55:40.465943 25648 net.cpp:774] Copying source layer res2b_branch2b_relu
I0627 10:55:40.465945 25648 net.cpp:774] Copying source layer res2b_branch2c
I0627 10:55:40.466089 25648 net.cpp:774] Copying source layer bn2b_branch2c
I0627 10:55:40.466099 25648 net.cpp:774] Copying source layer scale2b_branch2c
I0627 10:55:40.466109 25648 net.cpp:774] Copying source layer res2b
I0627 10:55:40.466110 25648 net.cpp:774] Copying source layer res2b_relu
I0627 10:55:40.466114 25648 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0627 10:55:40.466117 25648 net.cpp:774] Copying source layer res2c_branch2a
I0627 10:55:40.466260 25648 net.cpp:774] Copying source layer bn2c_branch2a
I0627 10:55:40.466271 25648 net.cpp:774] Copying source layer scale2c_branch2a
I0627 10:55:40.466279 25648 net.cpp:774] Copying source layer res2c_branch2a_relu
I0627 10:55:40.466282 25648 net.cpp:774] Copying source layer res2c_branch2b
I0627 10:55:40.466595 25648 net.cpp:774] Copying source layer bn2c_branch2b
I0627 10:55:40.466603 25648 net.cpp:774] Copying source layer scale2c_branch2b
I0627 10:55:40.466610 25648 net.cpp:774] Copying source layer res2c_branch2b_relu
I0627 10:55:40.466614 25648 net.cpp:774] Copying source layer res2c_branch2c
I0627 10:55:40.466753 25648 net.cpp:774] Copying source layer bn2c_branch2c
I0627 10:55:40.466763 25648 net.cpp:774] Copying source layer scale2c_branch2c
I0627 10:55:40.466773 25648 net.cpp:774] Copying source layer res2c
I0627 10:55:40.466775 25648 net.cpp:774] Copying source layer res2c_relu
I0627 10:55:40.466778 25648 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0627 10:55:40.466781 25648 net.cpp:774] Copying source layer res3a_branch1
I0627 10:55:40.467873 25648 net.cpp:774] Copying source layer bn3a_branch1
I0627 10:55:40.467890 25648 net.cpp:774] Copying source layer scale3a_branch1
I0627 10:55:40.467905 25648 net.cpp:774] Copying source layer res3a_branch2a
I0627 10:55:40.468180 25648 net.cpp:774] Copying source layer bn3a_branch2a
I0627 10:55:40.468190 25648 net.cpp:774] Copying source layer scale3a_branch2a
I0627 10:55:40.468199 25648 net.cpp:774] Copying source layer res3a_branch2a_relu
I0627 10:55:40.468200 25648 net.cpp:774] Copying source layer res3a_branch2b
I0627 10:55:40.469424 25648 net.cpp:774] Copying source layer bn3a_branch2b
I0627 10:55:40.469434 25648 net.cpp:774] Copying source layer scale3a_branch2b
I0627 10:55:40.469441 25648 net.cpp:774] Copying source layer res3a_branch2b_relu
I0627 10:55:40.469444 25648 net.cpp:774] Copying source layer res3a_branch2c
I0627 10:55:40.469990 25648 net.cpp:774] Copying source layer bn3a_branch2c
I0627 10:55:40.470007 25648 net.cpp:774] Copying source layer scale3a_branch2c
I0627 10:55:40.470022 25648 net.cpp:774] Copying source layer res3a
I0627 10:55:40.470026 25648 net.cpp:774] Copying source layer res3a_relu
I0627 10:55:40.470027 25648 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0627 10:55:40.470031 25648 net.cpp:774] Copying source layer res3b_branch2a
I0627 10:55:40.470577 25648 net.cpp:774] Copying source layer bn3b_branch2a
I0627 10:55:40.470588 25648 net.cpp:774] Copying source layer scale3b_branch2a
I0627 10:55:40.470595 25648 net.cpp:774] Copying source layer res3b_branch2a_relu
I0627 10:55:40.470599 25648 net.cpp:774] Copying source layer res3b_branch2b
I0627 10:55:40.471825 25648 net.cpp:774] Copying source layer bn3b_branch2b
I0627 10:55:40.471835 25648 net.cpp:774] Copying source layer scale3b_branch2b
I0627 10:55:40.471843 25648 net.cpp:774] Copying source layer res3b_branch2b_relu
I0627 10:55:40.471846 25648 net.cpp:774] Copying source layer res3b_branch2c
I0627 10:55:40.472393 25648 net.cpp:774] Copying source layer bn3b_branch2c
I0627 10:55:40.472409 25648 net.cpp:774] Copying source layer scale3b_branch2c
I0627 10:55:40.472424 25648 net.cpp:774] Copying source layer res3b
I0627 10:55:40.472427 25648 net.cpp:774] Copying source layer res3b_relu
I0627 10:55:40.472430 25648 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0627 10:55:40.472434 25648 net.cpp:774] Copying source layer res3c_branch2a
I0627 10:55:40.472980 25648 net.cpp:774] Copying source layer bn3c_branch2a
I0627 10:55:40.472990 25648 net.cpp:774] Copying source layer scale3c_branch2a
I0627 10:55:40.472998 25648 net.cpp:774] Copying source layer res3c_branch2a_relu
I0627 10:55:40.473002 25648 net.cpp:774] Copying source layer res3c_branch2b
I0627 10:55:40.474225 25648 net.cpp:774] Copying source layer bn3c_branch2b
I0627 10:55:40.474236 25648 net.cpp:774] Copying source layer scale3c_branch2b
I0627 10:55:40.474244 25648 net.cpp:774] Copying source layer res3c_branch2b_relu
I0627 10:55:40.474247 25648 net.cpp:774] Copying source layer res3c_branch2c
I0627 10:55:40.474795 25648 net.cpp:774] Copying source layer bn3c_branch2c
I0627 10:55:40.474812 25648 net.cpp:774] Copying source layer scale3c_branch2c
I0627 10:55:40.474826 25648 net.cpp:774] Copying source layer res3c
I0627 10:55:40.474829 25648 net.cpp:774] Copying source layer res3c_relu
I0627 10:55:40.474833 25648 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0627 10:55:40.474836 25648 net.cpp:774] Copying source layer res3d_branch2a
I0627 10:55:40.475387 25648 net.cpp:774] Copying source layer bn3d_branch2a
I0627 10:55:40.475397 25648 net.cpp:774] Copying source layer scale3d_branch2a
I0627 10:55:40.475406 25648 net.cpp:774] Copying source layer res3d_branch2a_relu
I0627 10:55:40.475410 25648 net.cpp:774] Copying source layer res3d_branch2b
I0627 10:55:40.476634 25648 net.cpp:774] Copying source layer bn3d_branch2b
I0627 10:55:40.476645 25648 net.cpp:774] Copying source layer scale3d_branch2b
I0627 10:55:40.476653 25648 net.cpp:774] Copying source layer res3d_branch2b_relu
I0627 10:55:40.476657 25648 net.cpp:774] Copying source layer res3d_branch2c
I0627 10:55:40.477205 25648 net.cpp:774] Copying source layer bn3d_branch2c
I0627 10:55:40.477221 25648 net.cpp:774] Copying source layer scale3d_branch2c
I0627 10:55:40.477236 25648 net.cpp:774] Copying source layer res3d
I0627 10:55:40.477239 25648 net.cpp:774] Copying source layer res3d_relu
I0627 10:55:40.477243 25648 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0627 10:55:40.477246 25648 net.cpp:774] Copying source layer res4a_branch1
I0627 10:55:40.481623 25648 net.cpp:774] Copying source layer bn4a_branch1
I0627 10:55:40.481657 25648 net.cpp:774] Copying source layer scale4a_branch1
I0627 10:55:40.481680 25648 net.cpp:774] Copying source layer res4a_branch2a
I0627 10:55:40.482769 25648 net.cpp:774] Copying source layer bn4a_branch2a
I0627 10:55:40.482784 25648 net.cpp:774] Copying source layer scale4a_branch2a
I0627 10:55:40.482796 25648 net.cpp:774] Copying source layer res4a_branch2a_relu
I0627 10:55:40.482800 25648 net.cpp:774] Copying source layer res4a_branch2b
I0627 10:55:40.487685 25648 net.cpp:774] Copying source layer bn4a_branch2b
I0627 10:55:40.487701 25648 net.cpp:774] Copying source layer scale4a_branch2b
I0627 10:55:40.487712 25648 net.cpp:774] Copying source layer res4a_branch2b_relu
I0627 10:55:40.487716 25648 net.cpp:774] Copying source layer res4a_branch2c
I0627 10:55:40.489889 25648 net.cpp:774] Copying source layer bn4a_branch2c
I0627 10:55:40.489915 25648 net.cpp:774] Copying source layer scale4a_branch2c
I0627 10:55:40.489940 25648 net.cpp:774] Copying source layer res4a
I0627 10:55:40.489945 25648 net.cpp:774] Copying source layer res4a_relu
I0627 10:55:40.489950 25648 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0627 10:55:40.489954 25648 net.cpp:774] Copying source layer res4b_branch2a
I0627 10:55:40.492131 25648 net.cpp:774] Copying source layer bn4b_branch2a
I0627 10:55:40.492146 25648 net.cpp:774] Copying source layer scale4b_branch2a
I0627 10:55:40.492158 25648 net.cpp:774] Copying source layer res4b_branch2a_relu
I0627 10:55:40.492162 25648 net.cpp:774] Copying source layer res4b_branch2b
I0627 10:55:40.497072 25648 net.cpp:774] Copying source layer bn4b_branch2b
I0627 10:55:40.497092 25648 net.cpp:774] Copying source layer scale4b_branch2b
I0627 10:55:40.497104 25648 net.cpp:774] Copying source layer res4b_branch2b_relu
I0627 10:55:40.497108 25648 net.cpp:774] Copying source layer res4b_branch2c
I0627 10:55:40.499284 25648 net.cpp:774] Copying source layer bn4b_branch2c
I0627 10:55:40.499312 25648 net.cpp:774] Copying source layer scale4b_branch2c
I0627 10:55:40.499336 25648 net.cpp:774] Copying source layer res4b
I0627 10:55:40.499341 25648 net.cpp:774] Copying source layer res4b_relu
I0627 10:55:40.499346 25648 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0627 10:55:40.499349 25648 net.cpp:774] Copying source layer res4c_branch2a
I0627 10:55:40.501521 25648 net.cpp:774] Copying source layer bn4c_branch2a
I0627 10:55:40.501535 25648 net.cpp:774] Copying source layer scale4c_branch2a
I0627 10:55:40.501549 25648 net.cpp:774] Copying source layer res4c_branch2a_relu
I0627 10:55:40.501552 25648 net.cpp:774] Copying source layer res4c_branch2b
I0627 10:55:40.506435 25648 net.cpp:774] Copying source layer bn4c_branch2b
I0627 10:55:40.506451 25648 net.cpp:774] Copying source layer scale4c_branch2b
I0627 10:55:40.506464 25648 net.cpp:774] Copying source layer res4c_branch2b_relu
I0627 10:55:40.506469 25648 net.cpp:774] Copying source layer res4c_branch2c
I0627 10:55:40.508642 25648 net.cpp:774] Copying source layer bn4c_branch2c
I0627 10:55:40.508669 25648 net.cpp:774] Copying source layer scale4c_branch2c
I0627 10:55:40.508695 25648 net.cpp:774] Copying source layer res4c
I0627 10:55:40.508699 25648 net.cpp:774] Copying source layer res4c_relu
I0627 10:55:40.508705 25648 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0627 10:55:40.508709 25648 net.cpp:774] Copying source layer res4d_branch2a
I0627 10:55:40.510885 25648 net.cpp:774] Copying source layer bn4d_branch2a
I0627 10:55:40.510898 25648 net.cpp:774] Copying source layer scale4d_branch2a
I0627 10:55:40.510911 25648 net.cpp:774] Copying source layer res4d_branch2a_relu
I0627 10:55:40.510916 25648 net.cpp:774] Copying source layer res4d_branch2b
I0627 10:55:40.515802 25648 net.cpp:774] Copying source layer bn4d_branch2b
I0627 10:55:40.515818 25648 net.cpp:774] Copying source layer scale4d_branch2b
I0627 10:55:40.515831 25648 net.cpp:774] Copying source layer res4d_branch2b_relu
I0627 10:55:40.515836 25648 net.cpp:774] Copying source layer res4d_branch2c
I0627 10:55:40.518014 25648 net.cpp:774] Copying source layer bn4d_branch2c
I0627 10:55:40.518041 25648 net.cpp:774] Copying source layer scale4d_branch2c
I0627 10:55:40.518064 25648 net.cpp:774] Copying source layer res4d
I0627 10:55:40.518069 25648 net.cpp:774] Copying source layer res4d_relu
I0627 10:55:40.518075 25648 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0627 10:55:40.518079 25648 net.cpp:774] Copying source layer res4e_branch2a
I0627 10:55:40.520254 25648 net.cpp:774] Copying source layer bn4e_branch2a
I0627 10:55:40.520269 25648 net.cpp:774] Copying source layer scale4e_branch2a
I0627 10:55:40.520282 25648 net.cpp:774] Copying source layer res4e_branch2a_relu
I0627 10:55:40.520287 25648 net.cpp:774] Copying source layer res4e_branch2b
I0627 10:55:40.525183 25648 net.cpp:774] Copying source layer bn4e_branch2b
I0627 10:55:40.525202 25648 net.cpp:774] Copying source layer scale4e_branch2b
I0627 10:55:40.525216 25648 net.cpp:774] Copying source layer res4e_branch2b_relu
I0627 10:55:40.525223 25648 net.cpp:774] Copying source layer res4e_branch2c
I0627 10:55:40.527410 25648 net.cpp:774] Copying source layer bn4e_branch2c
I0627 10:55:40.527441 25648 net.cpp:774] Copying source layer scale4e_branch2c
I0627 10:55:40.527467 25648 net.cpp:774] Copying source layer res4e
I0627 10:55:40.527472 25648 net.cpp:774] Copying source layer res4e_relu
I0627 10:55:40.527477 25648 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0627 10:55:40.527482 25648 net.cpp:774] Copying source layer res4f_branch2a
I0627 10:55:40.529655 25648 net.cpp:774] Copying source layer bn4f_branch2a
I0627 10:55:40.529670 25648 net.cpp:774] Copying source layer scale4f_branch2a
I0627 10:55:40.529682 25648 net.cpp:774] Copying source layer res4f_branch2a_relu
I0627 10:55:40.529687 25648 net.cpp:774] Copying source layer res4f_branch2b
I0627 10:55:40.534570 25648 net.cpp:774] Copying source layer bn4f_branch2b
I0627 10:55:40.534587 25648 net.cpp:774] Copying source layer scale4f_branch2b
I0627 10:55:40.534600 25648 net.cpp:774] Copying source layer res4f_branch2b_relu
I0627 10:55:40.534605 25648 net.cpp:774] Copying source layer res4f_branch2c
I0627 10:55:40.536782 25648 net.cpp:774] Copying source layer bn4f_branch2c
I0627 10:55:40.536809 25648 net.cpp:774] Copying source layer scale4f_branch2c
I0627 10:55:40.536834 25648 net.cpp:774] Copying source layer res4f
I0627 10:55:40.536839 25648 net.cpp:774] Copying source layer res4f_relu
I0627 10:55:40.536845 25648 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0627 10:55:40.536850 25648 net.cpp:774] Copying source layer res5a_branch1
I0627 10:55:40.554250 25648 net.cpp:774] Copying source layer bn5a_branch1
I0627 10:55:40.554296 25648 net.cpp:774] Copying source layer scale5a_branch1
I0627 10:55:40.554338 25648 net.cpp:774] Copying source layer res5a_branch2a
I0627 10:55:40.558709 25648 net.cpp:774] Copying source layer bn5a_branch2a
I0627 10:55:40.558742 25648 net.cpp:774] Copying source layer scale5a_branch2a
I0627 10:55:40.558759 25648 net.cpp:774] Copying source layer res5a_branch2a_relu
I0627 10:55:40.558765 25648 net.cpp:774] Copying source layer res5a_branch2b
I0627 10:55:40.578375 25648 net.cpp:774] Copying source layer bn5a_branch2b
I0627 10:55:40.578399 25648 net.cpp:774] Copying source layer scale5a_branch2b
I0627 10:55:40.578418 25648 net.cpp:774] Copying source layer res5a_branch2b_relu
I0627 10:55:40.578423 25648 net.cpp:774] Copying source layer res5a_branch2c
I0627 10:55:40.589033 25648 net.cpp:774] Copying source layer bn5a_branch2c
I0627 10:55:40.589121 25648 net.cpp:774] Copying source layer scale5a_branch2c
I0627 10:55:40.589184 25648 net.cpp:774] Copying source layer res5a
I0627 10:55:40.589192 25648 net.cpp:774] Copying source layer res5a_relu
I0627 10:55:40.589198 25648 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0627 10:55:40.589205 25648 net.cpp:774] Copying source layer res5b_branch2a
I0627 10:55:40.597910 25648 net.cpp:774] Copying source layer bn5b_branch2a
I0627 10:55:40.597935 25648 net.cpp:774] Copying source layer scale5b_branch2a
I0627 10:55:40.597954 25648 net.cpp:774] Copying source layer res5b_branch2a_relu
I0627 10:55:40.597961 25648 net.cpp:774] Copying source layer res5b_branch2b
I0627 10:55:40.617564 25648 net.cpp:774] Copying source layer bn5b_branch2b
I0627 10:55:40.617588 25648 net.cpp:774] Copying source layer scale5b_branch2b
I0627 10:55:40.617607 25648 net.cpp:774] Copying source layer res5b_branch2b_relu
I0627 10:55:40.617614 25648 net.cpp:774] Copying source layer res5b_branch2c
I0627 10:55:40.626339 25648 net.cpp:774] Copying source layer bn5b_branch2c
I0627 10:55:40.626400 25648 net.cpp:774] Copying source layer scale5b_branch2c
I0627 10:55:40.626442 25648 net.cpp:774] Copying source layer res5b
I0627 10:55:40.626448 25648 net.cpp:774] Copying source layer res5b_relu
I0627 10:55:40.626456 25648 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0627 10:55:40.626461 25648 net.cpp:774] Copying source layer res5c_branch2a
I0627 10:55:40.635171 25648 net.cpp:774] Copying source layer bn5c_branch2a
I0627 10:55:40.635195 25648 net.cpp:774] Copying source layer scale5c_branch2a
I0627 10:55:40.635215 25648 net.cpp:774] Copying source layer res5c_branch2a_relu
I0627 10:55:40.635221 25648 net.cpp:774] Copying source layer res5c_branch2b
I0627 10:55:40.654848 25648 net.cpp:774] Copying source layer bn5c_branch2b
I0627 10:55:40.654901 25648 net.cpp:774] Copying source layer scale5c_branch2b
I0627 10:55:40.654922 25648 net.cpp:774] Copying source layer res5c_branch2b_relu
I0627 10:55:40.654927 25648 net.cpp:774] Copying source layer res5c_branch2c
I0627 10:55:40.663640 25648 net.cpp:774] Copying source layer bn5c_branch2c
I0627 10:55:40.663694 25648 net.cpp:774] Copying source layer scale5c_branch2c
I0627 10:55:40.663738 25648 net.cpp:774] Copying source layer res5c
I0627 10:55:40.663743 25648 net.cpp:774] Copying source layer res5c_relu
I0627 10:55:40.663748 25648 net.cpp:774] Copying source layer rpn_conv/3x3
I0627 10:55:40.703132 25648 net.cpp:774] Copying source layer rpn_relu/3x3
I0627 10:55:40.703151 25648 net.cpp:774] Copying source layer rpn/output_rpn_relu/3x3_0_split
I0627 10:55:40.703157 25648 net.cpp:774] Copying source layer rpn_cls_score
I0627 10:55:40.703259 25648 net.cpp:771] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0627 10:55:40.703265 25648 net.cpp:774] Copying source layer rpn_bbox_pred
I0627 10:55:40.703460 25648 net.cpp:771] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0627 10:55:40.703466 25648 net.cpp:774] Copying source layer rpn_cls_score_reshape
I0627 10:55:40.703471 25648 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0627 10:55:40.703476 25648 net.cpp:771] Ignoring source layer rpn-data
I0627 10:55:40.703481 25648 net.cpp:771] Ignoring source layer rpn_loss_cls
I0627 10:55:40.703487 25648 net.cpp:771] Ignoring source layer rpn_loss_bbox
I0627 10:55:40.703491 25648 net.cpp:774] Copying source layer rpn_cls_prob
I0627 10:55:40.703496 25648 net.cpp:774] Copying source layer rpn_cls_prob_reshape
I0627 10:55:40.703501 25648 net.cpp:774] Copying source layer proposal
I0627 10:55:40.703507 25648 net.cpp:771] Ignoring source layer roi-data
I0627 10:55:40.703513 25648 net.cpp:771] Ignoring source layer rois_roi-data_0_split
I0627 10:55:40.703518 25648 net.cpp:771] Ignoring source layer labels_roi-data_1_split
I0627 10:55:40.703523 25648 net.cpp:771] Ignoring source layer bbox_targets_roi-data_2_split
I0627 10:55:40.703528 25648 net.cpp:771] Ignoring source layer bbox_inside_weights_roi-data_3_split
I0627 10:55:40.703533 25648 net.cpp:774] Copying source layer conv_new_1
I0627 10:55:40.721002 25648 net.cpp:774] Copying source layer conv_new_1_relu
I0627 10:55:40.721016 25648 net.cpp:774] Copying source layer conv_new_1_conv_new_1_relu_0_split
I0627 10:55:40.721022 25648 net.cpp:774] Copying source layer rfcn_cls
I0627 10:55:40.721860 25648 net.cpp:774] Copying source layer rfcn_bbox
I0627 10:55:40.725193 25648 net.cpp:774] Copying source layer psroipooled_cls_rois
I0627 10:55:40.725201 25648 net.cpp:774] Copying source layer ave_cls_score_rois
I0627 10:55:40.725206 25648 net.cpp:771] Ignoring source layer cls_score_ave_cls_score_rois_0_split
I0627 10:55:40.725211 25648 net.cpp:774] Copying source layer psroipooled_loc_rois
I0627 10:55:40.725216 25648 net.cpp:774] Copying source layer ave_bbox_pred_rois
I0627 10:55:40.725220 25648 net.cpp:771] Ignoring source layer bbox_pred_ave_bbox_pred_rois_0_split
I0627 10:55:40.725234 25648 net.cpp:771] Ignoring source layer per_roi_loss_cls
I0627 10:55:40.725237 25648 net.cpp:771] Ignoring source layer per_roi_loss_bbox
I0627 10:55:40.725244 25648 net.cpp:771] Ignoring source layer per_roi_loss
I0627 10:55:40.725248 25648 net.cpp:771] Ignoring source layer annotator_detector
I0627 10:55:40.725255 25648 net.cpp:771] Ignoring source layer labels_ohem_annotator_detector_0_split
I0627 10:55:40.725260 25648 net.cpp:771] Ignoring source layer silence
I0627 10:55:40.725267 25648 net.cpp:771] Ignoring source layer loss
I0627 10:55:40.725272 25648 net.cpp:771] Ignoring source layer accuarcy
I0627 10:55:40.725281 25648 net.cpp:771] Ignoring source layer loss_bbox
I0627 10:55:40.952117 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5529624
I0627 10:55:40.966874 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:40.989260 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:41.002954 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:41.011220 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:41.028157 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:41.037539 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:41.054517 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:55:41.062782 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0627 10:55:41.077006 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0627 10:55:41.084687 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.089076 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.097967 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.102988 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.112772 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.117316 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.126179 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:55:41.130532 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:55:41.138972 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:55:41.144426 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.147507 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.153887 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.156975 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.163094 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.166532 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.172991 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.176383 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.182605 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.185715 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.191874 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.195017 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:55:41.204759 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.223843 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:55:41.231189 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.253376 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:55:41.259729 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.281939 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:55:41.303321 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.303612 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.318835 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.324189 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:55:41.324908 25648 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
im_detect: 1/4024 0.395s 0.000s
im_detect: 2/4024 0.344s 0.000s
im_detect: 3/4024 0.327s 0.000s
im_detect: 4/4024 0.319s 0.000s
im_detect: 5/4024 0.314s 0.000s
im_detect: 6/4024 0.310s 0.000s
im_detect: 7/4024 0.307s 0.000s
im_detect: 8/4024 0.306s 0.000s
im_detect: 9/4024 0.304s 0.000s
im_detect: 10/4024 0.302s 0.000s
im_detect: 11/4024 0.301s 0.000s
im_detect: 12/4024 0.301s 0.000s
im_detect: 13/4024 0.299s 0.000s
im_detect: 14/4024 0.299s 0.000s
im_detect: 15/4024 0.299s 0.000s
im_detect: 16/4024 0.298s 0.000s
im_detect: 17/4024 0.298s 0.000s
im_detect: 18/4024 0.297s 0.000s
im_detect: 19/4024 0.297s 0.000s
im_detect: 20/4024 0.297s 0.000s
im_detect: 21/4024 0.297s 0.000s
im_detect: 22/4024 0.297s 0.000s
im_detect: 23/4024 0.296s 0.000s
im_detect: 24/4024 0.296s 0.000s
im_detect: 25/4024 0.296s 0.000s
im_detect: 26/4024 0.296s 0.000s
im_detect: 27/4024 0.296s 0.000s
im_detect: 28/4024 0.296s 0.000s
im_detect: 29/4024 0.296s 0.000s
im_detect: 30/4024 0.296s 0.000s
im_detect: 31/4024 0.296s 0.000s
im_detect: 32/4024 0.295s 0.000s
im_detect: 33/4024 0.295s 0.000s
im_detect: 34/4024 0.295s 0.000s
im_detect: 35/4024 0.295s 0.000s
im_detect: 36/4024 0.295s 0.000s
im_detect: 37/4024 0.295s 0.000s
im_detect: 38/4024 0.295s 0.000s
im_detect: 39/4024 0.295s 0.000s
im_detect: 40/4024 0.295s 0.000s
im_detect: 41/4024 0.295s 0.000s
im_detect: 42/4024 0.294s 0.000s
im_detect: 43/4024 0.294s 0.000s
im_detect: 44/4024 0.294s 0.000s
im_detect: 45/4024 0.294s 0.000s
im_detect: 46/4024 0.294s 0.000s
im_detect: 47/4024 0.294s 0.000s
im_detect: 48/4024 0.294s 0.000s
im_detect: 49/4024 0.294s 0.000s
im_detect: 50/4024 0.294s 0.000s
im_detect: 51/4024 0.294s 0.000s
im_detect: 52/4024 0.294s 0.000s
im_detect: 53/4024 0.294s 0.000s
im_detect: 54/4024 0.294s 0.000s
im_detect: 55/4024 0.294s 0.000s
im_detect: 56/4024 0.294s 0.000s
im_detect: 57/4024 0.294s 0.000s
im_detect: 58/4024 0.294s 0.000s
im_detect: 59/4024 0.294s 0.000s
im_detect: 60/4024 0.295s 0.000s
im_detect: 61/4024 0.295s 0.000s
im_detect: 62/4024 0.295s 0.000s
im_detect: 63/4024 0.295s 0.000s
im_detect: 64/4024 0.295s 0.000s
im_detect: 65/4024 0.295s 0.000s
im_detect: 66/4024 0.295s 0.000s
im_detect: 67/4024 0.295s 0.000s
im_detect: 68/4024 0.295s 0.000s
im_detect: 69/4024 0.295s 0.000s
im_detect: 70/4024 0.295s 0.000s
im_detect: 71/4024 0.295s 0.000s
im_detect: 72/4024 0.295s 0.000s
im_detect: 73/4024 0.295s 0.000s
im_detect: 74/4024 0.294s 0.000s
im_detect: 75/4024 0.294s 0.000s
im_detect: 76/4024 0.294s 0.000s
im_detect: 77/4024 0.294s 0.000s
im_detect: 78/4024 0.294s 0.000s
im_detect: 79/4024 0.294s 0.000s
im_detect: 80/4024 0.294s 0.000s
im_detect: 81/4024 0.294s 0.000s
im_detect: 82/4024 0.294s 0.000s
im_detect: 83/4024 0.294s 0.000s
im_detect: 84/4024 0.294s 0.000s
im_detect: 85/4024 0.294s 0.000s
im_detect: 86/4024 0.294s 0.000s
im_detect: 87/4024 0.294s 0.000s
im_detect: 88/4024 0.294s 0.000s
im_detect: 89/4024 0.294s 0.000s
im_detect: 90/4024 0.294s 0.000s
im_detect: 91/4024 0.294s 0.000s
im_detect: 92/4024 0.294s 0.000s
im_detect: 93/4024 0.294s 0.000s
im_detect: 94/4024 0.294s 0.000s
im_detect: 95/4024 0.294s 0.000s
im_detect: 96/4024 0.294s 0.000s
im_detect: 97/4024 0.294s 0.000s
im_detect: 98/4024 0.294s 0.000s
im_detect: 99/4024 0.294s 0.000s
im_detect: 100/4024 0.294s 0.000s
im_detect: 101/4024 0.294s 0.000s
im_detect: 102/4024 0.294s 0.000s
im_detect: 103/4024 0.294s 0.000s
im_detect: 104/4024 0.294s 0.000s
im_detect: 105/4024 0.294s 0.000s
im_detect: 106/4024 0.294s 0.000s
im_detect: 107/4024 0.294s 0.000s
im_detect: 108/4024 0.294s 0.000s
im_detect: 109/4024 0.294s 0.000s
im_detect: 110/4024 0.294s 0.000s
im_detect: 111/4024 0.294s 0.000s
im_detect: 112/4024 0.294s 0.000s
im_detect: 113/4024 0.294s 0.000s
im_detect: 114/4024 0.294s 0.000s
im_detect: 115/4024 0.294s 0.000s
im_detect: 116/4024 0.294s 0.000s
im_detect: 117/4024 0.294s 0.000s
im_detect: 118/4024 0.294s 0.000s
im_detect: 119/4024 0.294s 0.000s
im_detect: 120/4024 0.294s 0.000s
im_detect: 121/4024 0.294s 0.000s
im_detect: 122/4024 0.294s 0.000s
im_detect: 123/4024 0.294s 0.000s
im_detect: 124/4024 0.294s 0.000s
im_detect: 125/4024 0.294s 0.000s
im_detect: 126/4024 0.294s 0.000s
im_detect: 127/4024 0.294s 0.000s
im_detect: 128/4024 0.294s 0.000s
im_detect: 129/4024 0.294s 0.000s
im_detect: 130/4024 0.294s 0.000s
im_detect: 131/4024 0.294s 0.000s
im_detect: 132/4024 0.294s 0.000s
im_detect: 133/4024 0.294s 0.000s
im_detect: 134/4024 0.294s 0.000s
im_detect: 135/4024 0.294s 0.000s
im_detect: 136/4024 0.294s 0.000s
im_detect: 137/4024 0.294s 0.000s
im_detect: 138/4024 0.294s 0.000s
im_detect: 139/4024 0.294s 0.000s
im_detect: 140/4024 0.294s 0.000s
im_detect: 141/4024 0.294s 0.000s
im_detect: 142/4024 0.294s 0.000s
im_detect: 143/4024 0.294s 0.000s
im_detect: 144/4024 0.294s 0.000s
im_detect: 145/4024 0.294s 0.000s
im_detect: 146/4024 0.294s 0.000s
im_detect: 147/4024 0.294s 0.000s
im_detect: 148/4024 0.294s 0.000s
im_detect: 149/4024 0.294s 0.000s
im_detect: 150/4024 0.293s 0.000s
im_detect: 151/4024 0.293s 0.000s
im_detect: 152/4024 0.293s 0.000s
im_detect: 153/4024 0.293s 0.000s
im_detect: 154/4024 0.293s 0.000s
im_detect: 155/4024 0.293s 0.000s
im_detect: 156/4024 0.293s 0.000s
im_detect: 157/4024 0.293s 0.000s
im_detect: 158/4024 0.293s 0.000s
im_detect: 159/4024 0.293s 0.000s
im_detect: 160/4024 0.293s 0.000s
im_detect: 161/4024 0.293s 0.000s
im_detect: 162/4024 0.293s 0.000s
im_detect: 163/4024 0.293s 0.000s
im_detect: 164/4024 0.293s 0.000s
im_detect: 165/4024 0.293s 0.000s
im_detect: 166/4024 0.293s 0.000s
im_detect: 167/4024 0.293s 0.000s
im_detect: 168/4024 0.293s 0.000s
im_detect: 169/4024 0.293s 0.000s
im_detect: 170/4024 0.293s 0.000s
im_detect: 171/4024 0.293s 0.000s
im_detect: 172/4024 0.293s 0.000s
im_detect: 173/4024 0.293s 0.000s
im_detect: 174/4024 0.293s 0.000s
im_detect: 175/4024 0.293s 0.000s
im_detect: 176/4024 0.293s 0.000s
im_detect: 177/4024 0.293s 0.000s
im_detect: 178/4024 0.293s 0.000s
im_detect: 179/4024 0.293s 0.000s
im_detect: 180/4024 0.293s 0.000s
im_detect: 181/4024 0.293s 0.000s
im_detect: 182/4024 0.293s 0.000s
im_detect: 183/4024 0.293s 0.000s
im_detect: 184/4024 0.293s 0.000s
im_detect: 185/4024 0.293s 0.000s
im_detect: 186/4024 0.293s 0.000s
im_detect: 187/4024 0.293s 0.000s
im_detect: 188/4024 0.293s 0.000s
im_detect: 189/4024 0.293s 0.000s
im_detect: 190/4024 0.293s 0.000s
im_detect: 191/4024 0.293s 0.000s
im_detect: 192/4024 0.293s 0.000s
im_detect: 193/4024 0.293s 0.000s
im_detect: 194/4024 0.293s 0.000s
im_detect: 195/4024 0.293s 0.000s
im_detect: 196/4024 0.293s 0.000s
im_detect: 197/4024 0.293s 0.000s
im_detect: 198/4024 0.293s 0.000s
im_detect: 199/4024 0.293s 0.000s
im_detect: 200/4024 0.293s 0.000s
im_detect: 201/4024 0.293s 0.000s
im_detect: 202/4024 0.293s 0.000s
im_detect: 203/4024 0.293s 0.000s
im_detect: 204/4024 0.293s 0.000s
im_detect: 205/4024 0.293s 0.000s
im_detect: 206/4024 0.293s 0.000s
im_detect: 207/4024 0.293s 0.000s
im_detect: 208/4024 0.293s 0.000s
im_detect: 209/4024 0.293s 0.000s
im_detect: 210/4024 0.293s 0.000s
im_detect: 211/4024 0.293s 0.000s
im_detect: 212/4024 0.293s 0.000s
im_detect: 213/4024 0.293s 0.000s
im_detect: 214/4024 0.293s 0.000s
im_detect: 215/4024 0.293s 0.000s
im_detect: 216/4024 0.293s 0.000s
im_detect: 217/4024 0.293s 0.000s
im_detect: 218/4024 0.293s 0.000s
im_detect: 219/4024 0.293s 0.000s
im_detect: 220/4024 0.293s 0.000s
im_detect: 221/4024 0.293s 0.000s
im_detect: 222/4024 0.293s 0.000s
im_detect: 223/4024 0.293s 0.000s
im_detect: 224/4024 0.293s 0.000s
im_detect: 225/4024 0.293s 0.000s
im_detect: 226/4024 0.293s 0.000s
im_detect: 227/4024 0.293s 0.000s
im_detect: 228/4024 0.293s 0.000s
im_detect: 229/4024 0.293s 0.000s
im_detect: 230/4024 0.293s 0.000s
im_detect: 231/4024 0.293s 0.000s
im_detect: 232/4024 0.293s 0.000s
im_detect: 233/4024 0.293s 0.000s
im_detect: 234/4024 0.293s 0.000s
im_detect: 235/4024 0.293s 0.000s
im_detect: 236/4024 0.293s 0.000s
im_detect: 237/4024 0.293s 0.000s
im_detect: 238/4024 0.293s 0.000s
im_detect: 239/4024 0.293s 0.000s
im_detect: 240/4024 0.293s 0.000s
im_detect: 241/4024 0.293s 0.000s
im_detect: 242/4024 0.293s 0.000s
im_detect: 243/4024 0.293s 0.000s
im_detect: 244/4024 0.293s 0.000s
im_detect: 245/4024 0.293s 0.000s
im_detect: 246/4024 0.293s 0.000s
im_detect: 247/4024 0.293s 0.000s
im_detect: 248/4024 0.293s 0.000s
im_detect: 249/4024 0.293s 0.000s
im_detect: 250/4024 0.293s 0.000s
im_detect: 251/4024 0.293s 0.000s
im_detect: 252/4024 0.293s 0.000s
im_detect: 253/4024 0.293s 0.000s
im_detect: 254/4024 0.293s 0.000s
im_detect: 255/4024 0.293s 0.000s
im_detect: 256/4024 0.293s 0.000s
im_detect: 257/4024 0.293s 0.000s
im_detect: 258/4024 0.293s 0.000s
im_detect: 259/4024 0.293s 0.000s
im_detect: 260/4024 0.293s 0.000s
im_detect: 261/4024 0.293s 0.000s
im_detect: 262/4024 0.293s 0.000s
im_detect: 263/4024 0.293s 0.000s
im_detect: 264/4024 0.293s 0.000s
im_detect: 265/4024 0.293s 0.000s
im_detect: 266/4024 0.293s 0.000s
im_detect: 267/4024 0.293s 0.000s
im_detect: 268/4024 0.293s 0.000s
im_detect: 269/4024 0.293s 0.000s
im_detect: 270/4024 0.293s 0.000s
im_detect: 271/4024 0.293s 0.000s
im_detect: 272/4024 0.293s 0.000s
im_detect: 273/4024 0.293s 0.000s
im_detect: 274/4024 0.293s 0.000s
im_detect: 275/4024 0.293s 0.000s
im_detect: 276/4024 0.293s 0.000s
im_detect: 277/4024 0.293s 0.000s
im_detect: 278/4024 0.293s 0.000s
im_detect: 279/4024 0.293s 0.000s
im_detect: 280/4024 0.293s 0.000s
im_detect: 281/4024 0.293s 0.000s
im_detect: 282/4024 0.293s 0.000s
im_detect: 283/4024 0.293s 0.000s
im_detect: 284/4024 0.293s 0.000s
im_detect: 285/4024 0.293s 0.000s
im_detect: 286/4024 0.293s 0.000s
im_detect: 287/4024 0.293s 0.000s
im_detect: 288/4024 0.293s 0.000s
im_detect: 289/4024 0.293s 0.000s
im_detect: 290/4024 0.293s 0.000s
im_detect: 291/4024 0.293s 0.000s
im_detect: 292/4024 0.293s 0.000s
im_detect: 293/4024 0.293s 0.000s
im_detect: 294/4024 0.293s 0.000s
im_detect: 295/4024 0.293s 0.000s
im_detect: 296/4024 0.293s 0.000s
im_detect: 297/4024 0.293s 0.000s
im_detect: 298/4024 0.293s 0.000s
im_detect: 299/4024 0.293s 0.000s
im_detect: 300/4024 0.293s 0.000s
im_detect: 301/4024 0.293s 0.000s
im_detect: 302/4024 0.293s 0.000s
im_detect: 303/4024 0.293s 0.000s
im_detect: 304/4024 0.293s 0.000s
im_detect: 305/4024 0.293s 0.000s
im_detect: 306/4024 0.293s 0.000s
im_detect: 307/4024 0.293s 0.000s
im_detect: 308/4024 0.293s 0.000s
im_detect: 309/4024 0.293s 0.000s
im_detect: 310/4024 0.293s 0.000s
im_detect: 311/4024 0.293s 0.000s
im_detect: 312/4024 0.293s 0.000s
im_detect: 313/4024 0.293s 0.000s
im_detect: 314/4024 0.293s 0.000s
im_detect: 315/4024 0.293s 0.000s
im_detect: 316/4024 0.293s 0.000s
im_detect: 317/4024 0.293s 0.000s
im_detect: 318/4024 0.293s 0.000s
im_detect: 319/4024 0.293s 0.000s
im_detect: 320/4024 0.293s 0.000s
im_detect: 321/4024 0.293s 0.000s
im_detect: 322/4024 0.293s 0.000s
im_detect: 323/4024 0.293s 0.000s
im_detect: 324/4024 0.293s 0.000s
im_detect: 325/4024 0.293s 0.000s
im_detect: 326/4024 0.293s 0.000s
im_detect: 327/4024 0.293s 0.000s
im_detect: 328/4024 0.293s 0.000s
im_detect: 329/4024 0.293s 0.000s
im_detect: 330/4024 0.293s 0.000s
im_detect: 331/4024 0.293s 0.000s
im_detect: 332/4024 0.293s 0.000s
im_detect: 333/4024 0.293s 0.000s
im_detect: 334/4024 0.293s 0.000s
im_detect: 335/4024 0.293s 0.000s
im_detect: 336/4024 0.293s 0.000s
im_detect: 337/4024 0.293s 0.000s
im_detect: 338/4024 0.293s 0.000s
im_detect: 339/4024 0.293s 0.000s
im_detect: 340/4024 0.293s 0.000s
im_detect: 341/4024 0.293s 0.000s
im_detect: 342/4024 0.293s 0.000s
im_detect: 343/4024 0.293s 0.000s
im_detect: 344/4024 0.293s 0.000s
im_detect: 345/4024 0.293s 0.000s
im_detect: 346/4024 0.293s 0.000s
im_detect: 347/4024 0.293s 0.000s
im_detect: 348/4024 0.293s 0.000s
im_detect: 349/4024 0.293s 0.000s
im_detect: 350/4024 0.293s 0.000s
im_detect: 351/4024 0.293s 0.000s
im_detect: 352/4024 0.293s 0.000s
im_detect: 353/4024 0.293s 0.000s
im_detect: 354/4024 0.293s 0.000s
im_detect: 355/4024 0.293s 0.000s
im_detect: 356/4024 0.293s 0.000s
im_detect: 357/4024 0.293s 0.000s
im_detect: 358/4024 0.293s 0.000s
im_detect: 359/4024 0.293s 0.000s
im_detect: 360/4024 0.293s 0.000s
im_detect: 361/4024 0.293s 0.000s
im_detect: 362/4024 0.293s 0.000s
im_detect: 363/4024 0.293s 0.000s
im_detect: 364/4024 0.293s 0.000s
im_detect: 365/4024 0.293s 0.000s
im_detect: 366/4024 0.293s 0.000s
im_detect: 367/4024 0.293s 0.000s
im_detect: 368/4024 0.293s 0.000s
im_detect: 369/4024 0.293s 0.000s
im_detect: 370/4024 0.293s 0.000s
im_detect: 371/4024 0.293s 0.000s
im_detect: 372/4024 0.293s 0.000s
im_detect: 373/4024 0.293s 0.000s
im_detect: 374/4024 0.293s 0.000s
im_detect: 375/4024 0.293s 0.000s
im_detect: 376/4024 0.293s 0.000s
im_detect: 377/4024 0.293s 0.000s
im_detect: 378/4024 0.293s 0.000s
im_detect: 379/4024 0.293s 0.000s
im_detect: 380/4024 0.293s 0.000s
im_detect: 381/4024 0.293s 0.000s
im_detect: 382/4024 0.293s 0.000s
im_detect: 383/4024 0.293s 0.000s
im_detect: 384/4024 0.293s 0.000s
im_detect: 385/4024 0.293s 0.000s
im_detect: 386/4024 0.293s 0.000s
im_detect: 387/4024 0.293s 0.000s
im_detect: 388/4024 0.293s 0.000s
im_detect: 389/4024 0.293s 0.000s
im_detect: 390/4024 0.293s 0.000s
im_detect: 391/4024 0.293s 0.000s
im_detect: 392/4024 0.293s 0.000s
im_detect: 393/4024 0.293s 0.000s
im_detect: 394/4024 0.293s 0.000s
im_detect: 395/4024 0.293s 0.000s
im_detect: 396/4024 0.293s 0.000s
im_detect: 397/4024 0.293s 0.000s
im_detect: 398/4024 0.293s 0.000s
im_detect: 399/4024 0.293s 0.000s
im_detect: 400/4024 0.293s 0.000s
im_detect: 401/4024 0.293s 0.000s
im_detect: 402/4024 0.293s 0.000s
im_detect: 403/4024 0.293s 0.000s
im_detect: 404/4024 0.293s 0.000s
im_detect: 405/4024 0.293s 0.000s
im_detect: 406/4024 0.293s 0.000s
im_detect: 407/4024 0.293s 0.000s
im_detect: 408/4024 0.293s 0.000s
im_detect: 409/4024 0.293s 0.000s
im_detect: 410/4024 0.293s 0.000s
im_detect: 411/4024 0.293s 0.000s
im_detect: 412/4024 0.293s 0.000s
im_detect: 413/4024 0.293s 0.000s
im_detect: 414/4024 0.293s 0.000s
im_detect: 415/4024 0.293s 0.000s
im_detect: 416/4024 0.293s 0.000s
im_detect: 417/4024 0.293s 0.000s
im_detect: 418/4024 0.293s 0.000s
im_detect: 419/4024 0.293s 0.000s
im_detect: 420/4024 0.293s 0.000s
im_detect: 421/4024 0.293s 0.000s
im_detect: 422/4024 0.293s 0.000s
im_detect: 423/4024 0.293s 0.000s
im_detect: 424/4024 0.293s 0.000s
im_detect: 425/4024 0.293s 0.000s
im_detect: 426/4024 0.293s 0.000s
im_detect: 427/4024 0.293s 0.000s
im_detect: 428/4024 0.293s 0.000s
im_detect: 429/4024 0.293s 0.000s
im_detect: 430/4024 0.293s 0.000s
im_detect: 431/4024 0.293s 0.000s
im_detect: 432/4024 0.293s 0.000s
im_detect: 433/4024 0.293s 0.000s
im_detect: 434/4024 0.293s 0.000s
im_detect: 435/4024 0.293s 0.000s
im_detect: 436/4024 0.293s 0.000s
im_detect: 437/4024 0.293s 0.000s
im_detect: 438/4024 0.293s 0.000s
im_detect: 439/4024 0.293s 0.000s
im_detect: 440/4024 0.293s 0.000s
im_detect: 441/4024 0.293s 0.000s
im_detect: 442/4024 0.293s 0.000s
im_detect: 443/4024 0.293s 0.000s
im_detect: 444/4024 0.293s 0.000s
im_detect: 445/4024 0.293s 0.000s
im_detect: 446/4024 0.293s 0.000s
im_detect: 447/4024 0.293s 0.000s
im_detect: 448/4024 0.293s 0.000s
im_detect: 449/4024 0.293s 0.000s
im_detect: 450/4024 0.293s 0.000s
im_detect: 451/4024 0.293s 0.000s
im_detect: 452/4024 0.293s 0.000s
im_detect: 453/4024 0.293s 0.000s
im_detect: 454/4024 0.293s 0.000s
im_detect: 455/4024 0.293s 0.000s
im_detect: 456/4024 0.293s 0.000s
im_detect: 457/4024 0.293s 0.000s
im_detect: 458/4024 0.293s 0.000s
im_detect: 459/4024 0.293s 0.000s
im_detect: 460/4024 0.293s 0.000s
im_detect: 461/4024 0.293s 0.000s
im_detect: 462/4024 0.293s 0.000s
im_detect: 463/4024 0.293s 0.000s
im_detect: 464/4024 0.293s 0.000s
im_detect: 465/4024 0.293s 0.000s
im_detect: 466/4024 0.293s 0.000s
im_detect: 467/4024 0.293s 0.000s
im_detect: 468/4024 0.293s 0.000s
im_detect: 469/4024 0.293s 0.000s
im_detect: 470/4024 0.293s 0.000s
im_detect: 471/4024 0.293s 0.000s
im_detect: 472/4024 0.293s 0.000s
im_detect: 473/4024 0.293s 0.000s
im_detect: 474/4024 0.293s 0.000s
im_detect: 475/4024 0.293s 0.000s
im_detect: 476/4024 0.293s 0.000s
im_detect: 477/4024 0.293s 0.000s
im_detect: 478/4024 0.293s 0.000s
im_detect: 479/4024 0.293s 0.000s
im_detect: 480/4024 0.293s 0.000s
im_detect: 481/4024 0.293s 0.000s
im_detect: 482/4024 0.293s 0.000s
im_detect: 483/4024 0.293s 0.000s
im_detect: 484/4024 0.293s 0.000s
im_detect: 485/4024 0.293s 0.000s
im_detect: 486/4024 0.293s 0.000s
im_detect: 487/4024 0.293s 0.000s
im_detect: 488/4024 0.293s 0.000s
im_detect: 489/4024 0.293s 0.000s
im_detect: 490/4024 0.293s 0.000s
im_detect: 491/4024 0.293s 0.000s
im_detect: 492/4024 0.293s 0.000s
im_detect: 493/4024 0.293s 0.000s
im_detect: 494/4024 0.293s 0.000s
im_detect: 495/4024 0.293s 0.000s
im_detect: 496/4024 0.293s 0.000s
im_detect: 497/4024 0.293s 0.000s
im_detect: 498/4024 0.293s 0.000s
im_detect: 499/4024 0.293s 0.000s
im_detect: 500/4024 0.293s 0.000s
im_detect: 501/4024 0.293s 0.000s
im_detect: 502/4024 0.293s 0.000s
im_detect: 503/4024 0.293s 0.000s
im_detect: 504/4024 0.293s 0.000s
im_detect: 505/4024 0.293s 0.000s
im_detect: 506/4024 0.293s 0.000s
im_detect: 507/4024 0.293s 0.000s
im_detect: 508/4024 0.293s 0.000s
im_detect: 509/4024 0.293s 0.000s
im_detect: 510/4024 0.293s 0.000s
im_detect: 511/4024 0.293s 0.000s
im_detect: 512/4024 0.293s 0.000s
im_detect: 513/4024 0.293s 0.000s
im_detect: 514/4024 0.293s 0.000s
im_detect: 515/4024 0.293s 0.000s
im_detect: 516/4024 0.293s 0.000s
im_detect: 517/4024 0.293s 0.000s
im_detect: 518/4024 0.293s 0.000s
im_detect: 519/4024 0.293s 0.000s
im_detect: 520/4024 0.293s 0.000s
im_detect: 521/4024 0.293s 0.000s
im_detect: 522/4024 0.293s 0.000s
im_detect: 523/4024 0.293s 0.000s
im_detect: 524/4024 0.293s 0.000s
im_detect: 525/4024 0.293s 0.000s
im_detect: 526/4024 0.293s 0.000s
im_detect: 527/4024 0.293s 0.000s
im_detect: 528/4024 0.293s 0.000s
im_detect: 529/4024 0.293s 0.000s
im_detect: 530/4024 0.293s 0.000s
im_detect: 531/4024 0.293s 0.000s
im_detect: 532/4024 0.293s 0.000s
im_detect: 533/4024 0.293s 0.000s
im_detect: 534/4024 0.293s 0.000s
im_detect: 535/4024 0.293s 0.000s
im_detect: 536/4024 0.293s 0.000s
im_detect: 537/4024 0.293s 0.000s
im_detect: 538/4024 0.293s 0.000s
im_detect: 539/4024 0.293s 0.000s
im_detect: 540/4024 0.293s 0.000s
im_detect: 541/4024 0.293s 0.000s
im_detect: 542/4024 0.293s 0.000s
im_detect: 543/4024 0.293s 0.000s
im_detect: 544/4024 0.293s 0.000s
im_detect: 545/4024 0.293s 0.000s
im_detect: 546/4024 0.293s 0.000s
im_detect: 547/4024 0.293s 0.000s
im_detect: 548/4024 0.293s 0.000s
im_detect: 549/4024 0.293s 0.000s
im_detect: 550/4024 0.293s 0.000s
im_detect: 551/4024 0.293s 0.000s
im_detect: 552/4024 0.293s 0.000s
im_detect: 553/4024 0.293s 0.000s
im_detect: 554/4024 0.293s 0.000s
im_detect: 555/4024 0.293s 0.000s
im_detect: 556/4024 0.293s 0.000s
im_detect: 557/4024 0.293s 0.000s
im_detect: 558/4024 0.293s 0.000s
im_detect: 559/4024 0.293s 0.000s
im_detect: 560/4024 0.293s 0.000s
im_detect: 561/4024 0.293s 0.000s
im_detect: 562/4024 0.293s 0.000s
im_detect: 563/4024 0.293s 0.000s
im_detect: 564/4024 0.293s 0.000s
im_detect: 565/4024 0.293s 0.000s
im_detect: 566/4024 0.293s 0.000s
im_detect: 567/4024 0.293s 0.000s
im_detect: 568/4024 0.293s 0.000s
im_detect: 569/4024 0.293s 0.000s
im_detect: 570/4024 0.293s 0.000s
im_detect: 571/4024 0.293s 0.000s
im_detect: 572/4024 0.293s 0.000s
im_detect: 573/4024 0.293s 0.000s
im_detect: 574/4024 0.293s 0.000s
im_detect: 575/4024 0.293s 0.000s
im_detect: 576/4024 0.293s 0.000s
im_detect: 577/4024 0.293s 0.000s
im_detect: 578/4024 0.293s 0.000s
im_detect: 579/4024 0.293s 0.000s
im_detect: 580/4024 0.293s 0.000s
im_detect: 581/4024 0.293s 0.000s
im_detect: 582/4024 0.293s 0.000s
im_detect: 583/4024 0.293s 0.000s
im_detect: 584/4024 0.293s 0.000s
im_detect: 585/4024 0.293s 0.000s
im_detect: 586/4024 0.293s 0.000s
im_detect: 587/4024 0.293s 0.000s
im_detect: 588/4024 0.293s 0.000s
im_detect: 589/4024 0.293s 0.000s
im_detect: 590/4024 0.293s 0.000s
im_detect: 591/4024 0.293s 0.000s
im_detect: 592/4024 0.293s 0.000s
im_detect: 593/4024 0.293s 0.000s
im_detect: 594/4024 0.293s 0.000s
im_detect: 595/4024 0.293s 0.000s
im_detect: 596/4024 0.293s 0.000s
im_detect: 597/4024 0.293s 0.000s
im_detect: 598/4024 0.293s 0.000s
im_detect: 599/4024 0.293s 0.000s
im_detect: 600/4024 0.293s 0.000s
im_detect: 601/4024 0.293s 0.000s
im_detect: 602/4024 0.293s 0.000s
im_detect: 603/4024 0.293s 0.000s
im_detect: 604/4024 0.293s 0.000s
im_detect: 605/4024 0.293s 0.000s
im_detect: 606/4024 0.293s 0.000s
im_detect: 607/4024 0.293s 0.000s
im_detect: 608/4024 0.293s 0.000s
im_detect: 609/4024 0.293s 0.000s
im_detect: 610/4024 0.293s 0.000s
im_detect: 611/4024 0.293s 0.000s
im_detect: 612/4024 0.293s 0.000s
im_detect: 613/4024 0.293s 0.000s
im_detect: 614/4024 0.293s 0.000s
im_detect: 615/4024 0.293s 0.000s
im_detect: 616/4024 0.293s 0.000s
im_detect: 617/4024 0.293s 0.000s
im_detect: 618/4024 0.293s 0.000s
im_detect: 619/4024 0.293s 0.000s
im_detect: 620/4024 0.293s 0.000s
im_detect: 621/4024 0.293s 0.000s
im_detect: 622/4024 0.293s 0.000s
im_detect: 623/4024 0.293s 0.000s
im_detect: 624/4024 0.293s 0.000s
im_detect: 625/4024 0.293s 0.000s
im_detect: 626/4024 0.293s 0.000s
im_detect: 627/4024 0.293s 0.000s
im_detect: 628/4024 0.293s 0.000s
im_detect: 629/4024 0.293s 0.000s
im_detect: 630/4024 0.293s 0.000s
im_detect: 631/4024 0.293s 0.000s
im_detect: 632/4024 0.293s 0.000s
im_detect: 633/4024 0.293s 0.000s
im_detect: 634/4024 0.293s 0.000s
im_detect: 635/4024 0.293s 0.000s
im_detect: 636/4024 0.293s 0.000s
im_detect: 637/4024 0.293s 0.000s
im_detect: 638/4024 0.293s 0.000s
im_detect: 639/4024 0.293s 0.000s
im_detect: 640/4024 0.293s 0.000s
im_detect: 641/4024 0.293s 0.000s
im_detect: 642/4024 0.293s 0.000s
im_detect: 643/4024 0.293s 0.000s
im_detect: 644/4024 0.293s 0.000s
im_detect: 645/4024 0.293s 0.000s
im_detect: 646/4024 0.293s 0.000s
im_detect: 647/4024 0.293s 0.000s
im_detect: 648/4024 0.293s 0.000s
im_detect: 649/4024 0.293s 0.000s
im_detect: 650/4024 0.293s 0.000s
im_detect: 651/4024 0.293s 0.000s
im_detect: 652/4024 0.293s 0.000s
im_detect: 653/4024 0.293s 0.000s
im_detect: 654/4024 0.293s 0.000s
im_detect: 655/4024 0.293s 0.000s
im_detect: 656/4024 0.293s 0.000s
im_detect: 657/4024 0.293s 0.000s
im_detect: 658/4024 0.293s 0.000s
im_detect: 659/4024 0.293s 0.000s
im_detect: 660/4024 0.293s 0.000s
im_detect: 661/4024 0.293s 0.000s
im_detect: 662/4024 0.293s 0.000s
im_detect: 663/4024 0.293s 0.000s
im_detect: 664/4024 0.293s 0.000s
im_detect: 665/4024 0.293s 0.000s
im_detect: 666/4024 0.293s 0.000s
im_detect: 667/4024 0.293s 0.000s
im_detect: 668/4024 0.293s 0.000s
im_detect: 669/4024 0.293s 0.000s
im_detect: 670/4024 0.293s 0.000s
im_detect: 671/4024 0.293s 0.000s
im_detect: 672/4024 0.293s 0.000s
im_detect: 673/4024 0.293s 0.000s
im_detect: 674/4024 0.293s 0.000s
im_detect: 675/4024 0.293s 0.000s
im_detect: 676/4024 0.293s 0.000s
im_detect: 677/4024 0.293s 0.000s
im_detect: 678/4024 0.293s 0.000s
im_detect: 679/4024 0.293s 0.000s
im_detect: 680/4024 0.293s 0.000s
im_detect: 681/4024 0.293s 0.000s
im_detect: 682/4024 0.293s 0.000s
im_detect: 683/4024 0.293s 0.000s
im_detect: 684/4024 0.293s 0.000s
im_detect: 685/4024 0.293s 0.000s
im_detect: 686/4024 0.293s 0.000s
im_detect: 687/4024 0.293s 0.000s
im_detect: 688/4024 0.293s 0.000s
im_detect: 689/4024 0.293s 0.000s
im_detect: 690/4024 0.293s 0.000s
im_detect: 691/4024 0.293s 0.000s
im_detect: 692/4024 0.293s 0.000s
im_detect: 693/4024 0.293s 0.000s
im_detect: 694/4024 0.293s 0.000s
im_detect: 695/4024 0.293s 0.000s
im_detect: 696/4024 0.293s 0.000s
im_detect: 697/4024 0.293s 0.000s
im_detect: 698/4024 0.293s 0.000s
im_detect: 699/4024 0.293s 0.000s
im_detect: 700/4024 0.293s 0.000s
im_detect: 701/4024 0.293s 0.000s
im_detect: 702/4024 0.293s 0.000s
im_detect: 703/4024 0.293s 0.000s
im_detect: 704/4024 0.293s 0.000s
im_detect: 705/4024 0.293s 0.000s
im_detect: 706/4024 0.293s 0.000s
im_detect: 707/4024 0.293s 0.000s
im_detect: 708/4024 0.293s 0.000s
im_detect: 709/4024 0.293s 0.000s
im_detect: 710/4024 0.293s 0.000s
im_detect: 711/4024 0.293s 0.000s
im_detect: 712/4024 0.293s 0.000s
im_detect: 713/4024 0.293s 0.000s
im_detect: 714/4024 0.293s 0.000s
im_detect: 715/4024 0.293s 0.000s
im_detect: 716/4024 0.293s 0.000s
im_detect: 717/4024 0.293s 0.000s
im_detect: 718/4024 0.293s 0.000s
im_detect: 719/4024 0.293s 0.000s
im_detect: 720/4024 0.293s 0.000s
im_detect: 721/4024 0.293s 0.000s
im_detect: 722/4024 0.293s 0.000s
im_detect: 723/4024 0.293s 0.000s
im_detect: 724/4024 0.293s 0.000s
im_detect: 725/4024 0.293s 0.000s
im_detect: 726/4024 0.293s 0.000s
im_detect: 727/4024 0.293s 0.000s
im_detect: 728/4024 0.293s 0.000s
im_detect: 729/4024 0.293s 0.000s
im_detect: 730/4024 0.293s 0.000s
im_detect: 731/4024 0.293s 0.000s
im_detect: 732/4024 0.293s 0.000s
im_detect: 733/4024 0.293s 0.000s
im_detect: 734/4024 0.293s 0.000s
im_detect: 735/4024 0.293s 0.000s
im_detect: 736/4024 0.293s 0.000s
im_detect: 737/4024 0.293s 0.000s
im_detect: 738/4024 0.293s 0.000s
im_detect: 739/4024 0.293s 0.000s
im_detect: 740/4024 0.293s 0.000s
im_detect: 741/4024 0.293s 0.000s
im_detect: 742/4024 0.293s 0.000s
im_detect: 743/4024 0.293s 0.000s
im_detect: 744/4024 0.293s 0.000s
im_detect: 745/4024 0.293s 0.000s
im_detect: 746/4024 0.293s 0.000s
im_detect: 747/4024 0.293s 0.000s
im_detect: 748/4024 0.293s 0.000s
im_detect: 749/4024 0.293s 0.000s
im_detect: 750/4024 0.293s 0.000s
im_detect: 751/4024 0.293s 0.000s
im_detect: 752/4024 0.293s 0.000s
im_detect: 753/4024 0.293s 0.000s
im_detect: 754/4024 0.293s 0.000s
im_detect: 755/4024 0.293s 0.000s
im_detect: 756/4024 0.293s 0.000s
im_detect: 757/4024 0.293s 0.000s
im_detect: 758/4024 0.293s 0.000s
im_detect: 759/4024 0.293s 0.000s
im_detect: 760/4024 0.293s 0.000s
im_detect: 761/4024 0.293s 0.000s
im_detect: 762/4024 0.293s 0.000s
im_detect: 763/4024 0.293s 0.000s
im_detect: 764/4024 0.293s 0.000s
im_detect: 765/4024 0.293s 0.000s
im_detect: 766/4024 0.293s 0.000s
im_detect: 767/4024 0.293s 0.000s
im_detect: 768/4024 0.293s 0.000s
im_detect: 769/4024 0.293s 0.000s
im_detect: 770/4024 0.293s 0.000s
im_detect: 771/4024 0.293s 0.000s
im_detect: 772/4024 0.293s 0.000s
im_detect: 773/4024 0.293s 0.000s
im_detect: 774/4024 0.293s 0.000s
im_detect: 775/4024 0.293s 0.000s
im_detect: 776/4024 0.293s 0.000s
im_detect: 777/4024 0.293s 0.000s
im_detect: 778/4024 0.293s 0.000s
im_detect: 779/4024 0.293s 0.000s
im_detect: 780/4024 0.293s 0.000s
im_detect: 781/4024 0.293s 0.000s
im_detect: 782/4024 0.293s 0.000s
im_detect: 783/4024 0.293s 0.000s
im_detect: 784/4024 0.293s 0.000s
im_detect: 785/4024 0.293s 0.000s
im_detect: 786/4024 0.293s 0.000s
im_detect: 787/4024 0.293s 0.000s
im_detect: 788/4024 0.293s 0.000s
im_detect: 789/4024 0.293s 0.000s
im_detect: 790/4024 0.293s 0.000s
im_detect: 791/4024 0.293s 0.000s
im_detect: 792/4024 0.293s 0.000s
im_detect: 793/4024 0.293s 0.000s
im_detect: 794/4024 0.293s 0.000s
im_detect: 795/4024 0.293s 0.000s
im_detect: 796/4024 0.293s 0.000s
im_detect: 797/4024 0.293s 0.000s
im_detect: 798/4024 0.293s 0.000s
im_detect: 799/4024 0.293s 0.000s
im_detect: 800/4024 0.293s 0.000s
im_detect: 801/4024 0.293s 0.000s
im_detect: 802/4024 0.293s 0.000s
im_detect: 803/4024 0.293s 0.000s
im_detect: 804/4024 0.293s 0.000s
im_detect: 805/4024 0.293s 0.000s
im_detect: 806/4024 0.293s 0.000s
im_detect: 807/4024 0.293s 0.000s
im_detect: 808/4024 0.293s 0.000s
im_detect: 809/4024 0.293s 0.000s
im_detect: 810/4024 0.293s 0.000s
im_detect: 811/4024 0.293s 0.000s
im_detect: 812/4024 0.293s 0.000s
im_detect: 813/4024 0.293s 0.000s
im_detect: 814/4024 0.293s 0.000s
im_detect: 815/4024 0.293s 0.000s
im_detect: 816/4024 0.293s 0.000s
im_detect: 817/4024 0.293s 0.000s
im_detect: 818/4024 0.293s 0.000s
im_detect: 819/4024 0.293s 0.000s
im_detect: 820/4024 0.293s 0.000s
im_detect: 821/4024 0.293s 0.000s
im_detect: 822/4024 0.293s 0.000s
im_detect: 823/4024 0.293s 0.000s
im_detect: 824/4024 0.293s 0.000s
im_detect: 825/4024 0.293s 0.000s
im_detect: 826/4024 0.293s 0.000s
im_detect: 827/4024 0.293s 0.000s
im_detect: 828/4024 0.293s 0.000s
im_detect: 829/4024 0.293s 0.000s
im_detect: 830/4024 0.293s 0.000s
im_detect: 831/4024 0.293s 0.000s
im_detect: 832/4024 0.293s 0.000s
im_detect: 833/4024 0.293s 0.000s
im_detect: 834/4024 0.293s 0.000s
im_detect: 835/4024 0.293s 0.000s
im_detect: 836/4024 0.293s 0.000s
im_detect: 837/4024 0.293s 0.000s
im_detect: 838/4024 0.293s 0.000s
im_detect: 839/4024 0.293s 0.000s
im_detect: 840/4024 0.293s 0.000s
im_detect: 841/4024 0.293s 0.000s
im_detect: 842/4024 0.293s 0.000s
im_detect: 843/4024 0.293s 0.000s
im_detect: 844/4024 0.293s 0.000s
im_detect: 845/4024 0.293s 0.000s
im_detect: 846/4024 0.293s 0.000s
im_detect: 847/4024 0.293s 0.000s
im_detect: 848/4024 0.293s 0.000s
im_detect: 849/4024 0.293s 0.000s
im_detect: 850/4024 0.293s 0.000s
im_detect: 851/4024 0.293s 0.000s
im_detect: 852/4024 0.293s 0.000s
im_detect: 853/4024 0.293s 0.000s
im_detect: 854/4024 0.293s 0.000s
im_detect: 855/4024 0.293s 0.000s
im_detect: 856/4024 0.293s 0.000s
im_detect: 857/4024 0.293s 0.000s
im_detect: 858/4024 0.293s 0.000s
im_detect: 859/4024 0.293s 0.000s
im_detect: 860/4024 0.293s 0.000s
im_detect: 861/4024 0.293s 0.000s
im_detect: 862/4024 0.293s 0.000s
im_detect: 863/4024 0.293s 0.000s
im_detect: 864/4024 0.293s 0.000s
im_detect: 865/4024 0.293s 0.000s
im_detect: 866/4024 0.293s 0.000s
im_detect: 867/4024 0.293s 0.000s
im_detect: 868/4024 0.293s 0.000s
im_detect: 869/4024 0.293s 0.000s
im_detect: 870/4024 0.293s 0.000s
im_detect: 871/4024 0.293s 0.000s
im_detect: 872/4024 0.293s 0.000s
im_detect: 873/4024 0.293s 0.000s
im_detect: 874/4024 0.293s 0.000s
im_detect: 875/4024 0.293s 0.000s
im_detect: 876/4024 0.293s 0.000s
im_detect: 877/4024 0.293s 0.000s
im_detect: 878/4024 0.293s 0.000s
im_detect: 879/4024 0.293s 0.000s
im_detect: 880/4024 0.293s 0.000s
im_detect: 881/4024 0.293s 0.000s
im_detect: 882/4024 0.293s 0.000s
im_detect: 883/4024 0.293s 0.000s
im_detect: 884/4024 0.293s 0.000s
im_detect: 885/4024 0.293s 0.000s
im_detect: 886/4024 0.293s 0.000s
im_detect: 887/4024 0.293s 0.000s
im_detect: 888/4024 0.293s 0.000s
im_detect: 889/4024 0.293s 0.000s
im_detect: 890/4024 0.293s 0.000s
im_detect: 891/4024 0.293s 0.000s
im_detect: 892/4024 0.293s 0.000s
im_detect: 893/4024 0.293s 0.000s
im_detect: 894/4024 0.293s 0.000s
im_detect: 895/4024 0.293s 0.000s
im_detect: 896/4024 0.293s 0.000s
im_detect: 897/4024 0.293s 0.000s
im_detect: 898/4024 0.293s 0.000s
im_detect: 899/4024 0.293s 0.000s
im_detect: 900/4024 0.293s 0.000s
im_detect: 901/4024 0.293s 0.000s
im_detect: 902/4024 0.293s 0.000s
im_detect: 903/4024 0.293s 0.000s
im_detect: 904/4024 0.293s 0.000s
im_detect: 905/4024 0.293s 0.000s
im_detect: 906/4024 0.293s 0.000s
im_detect: 907/4024 0.293s 0.000s
im_detect: 908/4024 0.293s 0.000s
im_detect: 909/4024 0.293s 0.000s
im_detect: 910/4024 0.293s 0.000s
im_detect: 911/4024 0.293s 0.000s
im_detect: 912/4024 0.293s 0.000s
im_detect: 913/4024 0.293s 0.000s
im_detect: 914/4024 0.293s 0.000s
im_detect: 915/4024 0.293s 0.000s
im_detect: 916/4024 0.293s 0.000s
im_detect: 917/4024 0.293s 0.000s
im_detect: 918/4024 0.293s 0.000s
im_detect: 919/4024 0.293s 0.000s
im_detect: 920/4024 0.293s 0.000s
im_detect: 921/4024 0.293s 0.000s
im_detect: 922/4024 0.293s 0.000s
im_detect: 923/4024 0.293s 0.000s
im_detect: 924/4024 0.293s 0.000s
im_detect: 925/4024 0.293s 0.000s
im_detect: 926/4024 0.293s 0.000s
im_detect: 927/4024 0.293s 0.000s
im_detect: 928/4024 0.293s 0.000s
im_detect: 929/4024 0.293s 0.000s
im_detect: 930/4024 0.293s 0.000s
im_detect: 931/4024 0.293s 0.000s
im_detect: 932/4024 0.293s 0.000s
im_detect: 933/4024 0.293s 0.000s
im_detect: 934/4024 0.293s 0.000s
im_detect: 935/4024 0.293s 0.000s
im_detect: 936/4024 0.293s 0.000s
im_detect: 937/4024 0.293s 0.000s
im_detect: 938/4024 0.293s 0.000s
im_detect: 939/4024 0.293s 0.000s
im_detect: 940/4024 0.293s 0.000s
im_detect: 941/4024 0.293s 0.000s
im_detect: 942/4024 0.293s 0.000s
im_detect: 943/4024 0.293s 0.000s
im_detect: 944/4024 0.293s 0.000s
im_detect: 945/4024 0.293s 0.000s
im_detect: 946/4024 0.293s 0.000s
im_detect: 947/4024 0.293s 0.000s
im_detect: 948/4024 0.293s 0.000s
im_detect: 949/4024 0.293s 0.000s
im_detect: 950/4024 0.293s 0.000s
im_detect: 951/4024 0.293s 0.000s
im_detect: 952/4024 0.293s 0.000s
im_detect: 953/4024 0.293s 0.000s
im_detect: 954/4024 0.293s 0.000s
im_detect: 955/4024 0.293s 0.000s
im_detect: 956/4024 0.293s 0.000s
im_detect: 957/4024 0.293s 0.000s
im_detect: 958/4024 0.293s 0.000s
im_detect: 959/4024 0.293s 0.000s
im_detect: 960/4024 0.293s 0.000s
im_detect: 961/4024 0.293s 0.000s
im_detect: 962/4024 0.293s 0.000s
im_detect: 963/4024 0.293s 0.000s
im_detect: 964/4024 0.293s 0.000s
im_detect: 965/4024 0.293s 0.000s
im_detect: 966/4024 0.293s 0.000s
im_detect: 967/4024 0.293s 0.000s
im_detect: 968/4024 0.293s 0.000s
im_detect: 969/4024 0.293s 0.000s
im_detect: 970/4024 0.293s 0.000s
im_detect: 971/4024 0.293s 0.000s
im_detect: 972/4024 0.293s 0.000s
im_detect: 973/4024 0.293s 0.000s
im_detect: 974/4024 0.293s 0.000s
im_detect: 975/4024 0.293s 0.000s
im_detect: 976/4024 0.293s 0.000s
im_detect: 977/4024 0.293s 0.000s
im_detect: 978/4024 0.293s 0.000s
im_detect: 979/4024 0.293s 0.000s
im_detect: 980/4024 0.293s 0.000s
im_detect: 981/4024 0.293s 0.000s
im_detect: 982/4024 0.293s 0.000s
im_detect: 983/4024 0.293s 0.000s
im_detect: 984/4024 0.293s 0.000s
im_detect: 985/4024 0.293s 0.000s
im_detect: 986/4024 0.293s 0.000s
im_detect: 987/4024 0.293s 0.000s
im_detect: 988/4024 0.293s 0.000s
im_detect: 989/4024 0.293s 0.000s
im_detect: 990/4024 0.293s 0.000s
im_detect: 991/4024 0.293s 0.000s
im_detect: 992/4024 0.293s 0.000s
im_detect: 993/4024 0.293s 0.000s
im_detect: 994/4024 0.293s 0.000s
im_detect: 995/4024 0.293s 0.000s
im_detect: 996/4024 0.293s 0.000s
im_detect: 997/4024 0.293s 0.000s
im_detect: 998/4024 0.293s 0.000s
im_detect: 999/4024 0.293s 0.000s
im_detect: 1000/4024 0.293s 0.000s
im_detect: 1001/4024 0.293s 0.000s
im_detect: 1002/4024 0.293s 0.000s
im_detect: 1003/4024 0.294s 0.000s
im_detect: 1004/4024 0.294s 0.000s
im_detect: 1005/4024 0.293s 0.000s
im_detect: 1006/4024 0.293s 0.000s
im_detect: 1007/4024 0.293s 0.000s
im_detect: 1008/4024 0.293s 0.000s
im_detect: 1009/4024 0.293s 0.000s
im_detect: 1010/4024 0.294s 0.000s
im_detect: 1011/4024 0.294s 0.000s
im_detect: 1012/4024 0.294s 0.000s
im_detect: 1013/4024 0.294s 0.000s
im_detect: 1014/4024 0.294s 0.000s
im_detect: 1015/4024 0.294s 0.000s
im_detect: 1016/4024 0.294s 0.000s
im_detect: 1017/4024 0.294s 0.000s
im_detect: 1018/4024 0.294s 0.000s
im_detect: 1019/4024 0.294s 0.000s
im_detect: 1020/4024 0.294s 0.000s
im_detect: 1021/4024 0.294s 0.000s
im_detect: 1022/4024 0.294s 0.000s
im_detect: 1023/4024 0.294s 0.000s
im_detect: 1024/4024 0.294s 0.000s
im_detect: 1025/4024 0.294s 0.000s
im_detect: 1026/4024 0.294s 0.000s
im_detect: 1027/4024 0.294s 0.000s
im_detect: 1028/4024 0.294s 0.000s
im_detect: 1029/4024 0.294s 0.000s
im_detect: 1030/4024 0.294s 0.000s
im_detect: 1031/4024 0.294s 0.000s
im_detect: 1032/4024 0.294s 0.000s
im_detect: 1033/4024 0.294s 0.000s
im_detect: 1034/4024 0.294s 0.000s
im_detect: 1035/4024 0.294s 0.000s
im_detect: 1036/4024 0.294s 0.000s
im_detect: 1037/4024 0.294s 0.000s
im_detect: 1038/4024 0.294s 0.000s
im_detect: 1039/4024 0.294s 0.000s
im_detect: 1040/4024 0.294s 0.000s
im_detect: 1041/4024 0.294s 0.000s
im_detect: 1042/4024 0.294s 0.000s
im_detect: 1043/4024 0.294s 0.000s
im_detect: 1044/4024 0.294s 0.000s
im_detect: 1045/4024 0.294s 0.000s
im_detect: 1046/4024 0.294s 0.000s
im_detect: 1047/4024 0.294s 0.000s
im_detect: 1048/4024 0.294s 0.000s
im_detect: 1049/4024 0.294s 0.000s
im_detect: 1050/4024 0.294s 0.000s
im_detect: 1051/4024 0.294s 0.000s
im_detect: 1052/4024 0.294s 0.000s
im_detect: 1053/4024 0.294s 0.000s
im_detect: 1054/4024 0.294s 0.000s
im_detect: 1055/4024 0.294s 0.000s
im_detect: 1056/4024 0.294s 0.000s
im_detect: 1057/4024 0.294s 0.000s
im_detect: 1058/4024 0.294s 0.000s
im_detect: 1059/4024 0.294s 0.000s
im_detect: 1060/4024 0.294s 0.000s
im_detect: 1061/4024 0.294s 0.000s
im_detect: 1062/4024 0.294s 0.000s
im_detect: 1063/4024 0.294s 0.000s
im_detect: 1064/4024 0.294s 0.000s
im_detect: 1065/4024 0.294s 0.000s
im_detect: 1066/4024 0.294s 0.000s
im_detect: 1067/4024 0.294s 0.000s
im_detect: 1068/4024 0.294s 0.000s
im_detect: 1069/4024 0.294s 0.000s
im_detect: 1070/4024 0.294s 0.000s
im_detect: 1071/4024 0.294s 0.000s
im_detect: 1072/4024 0.294s 0.000s
im_detect: 1073/4024 0.294s 0.000s
im_detect: 1074/4024 0.294s 0.000s
im_detect: 1075/4024 0.294s 0.000s
im_detect: 1076/4024 0.294s 0.000s
im_detect: 1077/4024 0.294s 0.000s
im_detect: 1078/4024 0.294s 0.000s
im_detect: 1079/4024 0.294s 0.000s
im_detect: 1080/4024 0.294s 0.000s
im_detect: 1081/4024 0.294s 0.000s
im_detect: 1082/4024 0.294s 0.000s
im_detect: 1083/4024 0.294s 0.000s
im_detect: 1084/4024 0.294s 0.000s
im_detect: 1085/4024 0.294s 0.000s
im_detect: 1086/4024 0.294s 0.000s
im_detect: 1087/4024 0.294s 0.000s
im_detect: 1088/4024 0.294s 0.000s
im_detect: 1089/4024 0.294s 0.000s
im_detect: 1090/4024 0.294s 0.000s
im_detect: 1091/4024 0.294s 0.000s
im_detect: 1092/4024 0.294s 0.000s
im_detect: 1093/4024 0.294s 0.000s
im_detect: 1094/4024 0.294s 0.000s
im_detect: 1095/4024 0.294s 0.000s
im_detect: 1096/4024 0.294s 0.000s
im_detect: 1097/4024 0.294s 0.000s
im_detect: 1098/4024 0.294s 0.000s
im_detect: 1099/4024 0.294s 0.000s
im_detect: 1100/4024 0.294s 0.000s
im_detect: 1101/4024 0.294s 0.000s
im_detect: 1102/4024 0.294s 0.000s
im_detect: 1103/4024 0.294s 0.000s
im_detect: 1104/4024 0.294s 0.000s
im_detect: 1105/4024 0.294s 0.000s
im_detect: 1106/4024 0.294s 0.000s
im_detect: 1107/4024 0.294s 0.000s
im_detect: 1108/4024 0.294s 0.000s
im_detect: 1109/4024 0.294s 0.000s
im_detect: 1110/4024 0.294s 0.000s
im_detect: 1111/4024 0.294s 0.000s
im_detect: 1112/4024 0.294s 0.000s
im_detect: 1113/4024 0.294s 0.000s
im_detect: 1114/4024 0.294s 0.000s
im_detect: 1115/4024 0.294s 0.000s
im_detect: 1116/4024 0.294s 0.000s
im_detect: 1117/4024 0.294s 0.000s
im_detect: 1118/4024 0.294s 0.000s
im_detect: 1119/4024 0.294s 0.000s
im_detect: 1120/4024 0.294s 0.000s
im_detect: 1121/4024 0.294s 0.000s
im_detect: 1122/4024 0.294s 0.000s
im_detect: 1123/4024 0.294s 0.000s
im_detect: 1124/4024 0.294s 0.000s
im_detect: 1125/4024 0.294s 0.000s
im_detect: 1126/4024 0.294s 0.000s
im_detect: 1127/4024 0.294s 0.000s
im_detect: 1128/4024 0.294s 0.000s
im_detect: 1129/4024 0.294s 0.000s
im_detect: 1130/4024 0.294s 0.000s
im_detect: 1131/4024 0.294s 0.000s
im_detect: 1132/4024 0.294s 0.000s
im_detect: 1133/4024 0.294s 0.000s
im_detect: 1134/4024 0.294s 0.000s
im_detect: 1135/4024 0.294s 0.000s
im_detect: 1136/4024 0.294s 0.000s
im_detect: 1137/4024 0.294s 0.000s
im_detect: 1138/4024 0.294s 0.000s
im_detect: 1139/4024 0.294s 0.000s
im_detect: 1140/4024 0.294s 0.000s
im_detect: 1141/4024 0.294s 0.000s
im_detect: 1142/4024 0.294s 0.000s
im_detect: 1143/4024 0.294s 0.000s
im_detect: 1144/4024 0.294s 0.000s
im_detect: 1145/4024 0.294s 0.000s
im_detect: 1146/4024 0.294s 0.000s
im_detect: 1147/4024 0.294s 0.000s
im_detect: 1148/4024 0.294s 0.000s
im_detect: 1149/4024 0.294s 0.000s
im_detect: 1150/4024 0.294s 0.000s
im_detect: 1151/4024 0.294s 0.000s
im_detect: 1152/4024 0.294s 0.000s
im_detect: 1153/4024 0.294s 0.000s
im_detect: 1154/4024 0.294s 0.000s
im_detect: 1155/4024 0.294s 0.000s
im_detect: 1156/4024 0.294s 0.000s
im_detect: 1157/4024 0.294s 0.000s
im_detect: 1158/4024 0.294s 0.000s
im_detect: 1159/4024 0.294s 0.000s
im_detect: 1160/4024 0.294s 0.000s
im_detect: 1161/4024 0.294s 0.000s
im_detect: 1162/4024 0.294s 0.000s
im_detect: 1163/4024 0.294s 0.000s
im_detect: 1164/4024 0.294s 0.000s
im_detect: 1165/4024 0.294s 0.000s
im_detect: 1166/4024 0.294s 0.000s
im_detect: 1167/4024 0.294s 0.000s
im_detect: 1168/4024 0.294s 0.000s
im_detect: 1169/4024 0.294s 0.000s
im_detect: 1170/4024 0.294s 0.000s
im_detect: 1171/4024 0.294s 0.000s
im_detect: 1172/4024 0.294s 0.000s
im_detect: 1173/4024 0.294s 0.000s
im_detect: 1174/4024 0.294s 0.000s
im_detect: 1175/4024 0.294s 0.000s
im_detect: 1176/4024 0.294s 0.000s
im_detect: 1177/4024 0.294s 0.000s
im_detect: 1178/4024 0.294s 0.000s
im_detect: 1179/4024 0.294s 0.000s
im_detect: 1180/4024 0.294s 0.000s
im_detect: 1181/4024 0.294s 0.000s
im_detect: 1182/4024 0.294s 0.000s
im_detect: 1183/4024 0.294s 0.000s
im_detect: 1184/4024 0.294s 0.000s
im_detect: 1185/4024 0.294s 0.000s
im_detect: 1186/4024 0.294s 0.000s
im_detect: 1187/4024 0.294s 0.000s
im_detect: 1188/4024 0.294s 0.000s
im_detect: 1189/4024 0.294s 0.000s
im_detect: 1190/4024 0.294s 0.000s
im_detect: 1191/4024 0.294s 0.000s
im_detect: 1192/4024 0.294s 0.000s
im_detect: 1193/4024 0.294s 0.000s
im_detect: 1194/4024 0.294s 0.000s
im_detect: 1195/4024 0.294s 0.000s
im_detect: 1196/4024 0.294s 0.000s
im_detect: 1197/4024 0.294s 0.000s
im_detect: 1198/4024 0.294s 0.000s
im_detect: 1199/4024 0.294s 0.000s
im_detect: 1200/4024 0.294s 0.000s
im_detect: 1201/4024 0.294s 0.000s
im_detect: 1202/4024 0.294s 0.000s
im_detect: 1203/4024 0.294s 0.000s
im_detect: 1204/4024 0.294s 0.000s
im_detect: 1205/4024 0.294s 0.000s
im_detect: 1206/4024 0.294s 0.000s
im_detect: 1207/4024 0.294s 0.000s
im_detect: 1208/4024 0.294s 0.000s
im_detect: 1209/4024 0.294s 0.000s
im_detect: 1210/4024 0.294s 0.000s
im_detect: 1211/4024 0.294s 0.000s
im_detect: 1212/4024 0.294s 0.000s
im_detect: 1213/4024 0.294s 0.000s
im_detect: 1214/4024 0.294s 0.000s
im_detect: 1215/4024 0.294s 0.000s
im_detect: 1216/4024 0.294s 0.000s
im_detect: 1217/4024 0.294s 0.000s
im_detect: 1218/4024 0.294s 0.000s
im_detect: 1219/4024 0.294s 0.000s
im_detect: 1220/4024 0.294s 0.000s
im_detect: 1221/4024 0.294s 0.000s
im_detect: 1222/4024 0.294s 0.000s
im_detect: 1223/4024 0.294s 0.000s
im_detect: 1224/4024 0.294s 0.000s
im_detect: 1225/4024 0.294s 0.000s
im_detect: 1226/4024 0.294s 0.000s
im_detect: 1227/4024 0.294s 0.000s
im_detect: 1228/4024 0.294s 0.000s
im_detect: 1229/4024 0.294s 0.000s
im_detect: 1230/4024 0.294s 0.000s
im_detect: 1231/4024 0.294s 0.000s
im_detect: 1232/4024 0.294s 0.000s
im_detect: 1233/4024 0.294s 0.000s
im_detect: 1234/4024 0.294s 0.000s
im_detect: 1235/4024 0.294s 0.000s
im_detect: 1236/4024 0.294s 0.000s
im_detect: 1237/4024 0.294s 0.000s
im_detect: 1238/4024 0.294s 0.000s
im_detect: 1239/4024 0.294s 0.000s
im_detect: 1240/4024 0.294s 0.000s
im_detect: 1241/4024 0.294s 0.000s
im_detect: 1242/4024 0.294s 0.000s
im_detect: 1243/4024 0.294s 0.000s
im_detect: 1244/4024 0.294s 0.000s
im_detect: 1245/4024 0.294s 0.000s
im_detect: 1246/4024 0.294s 0.000s
im_detect: 1247/4024 0.294s 0.000s
im_detect: 1248/4024 0.294s 0.000s
im_detect: 1249/4024 0.294s 0.000s
im_detect: 1250/4024 0.294s 0.000s
im_detect: 1251/4024 0.294s 0.000s
im_detect: 1252/4024 0.294s 0.000s
im_detect: 1253/4024 0.294s 0.000s
im_detect: 1254/4024 0.294s 0.000s
im_detect: 1255/4024 0.294s 0.000s
im_detect: 1256/4024 0.294s 0.000s
im_detect: 1257/4024 0.294s 0.000s
im_detect: 1258/4024 0.294s 0.000s
im_detect: 1259/4024 0.294s 0.000s
im_detect: 1260/4024 0.294s 0.000s
im_detect: 1261/4024 0.294s 0.000s
im_detect: 1262/4024 0.294s 0.000s
im_detect: 1263/4024 0.294s 0.000s
im_detect: 1264/4024 0.294s 0.000s
im_detect: 1265/4024 0.294s 0.000s
im_detect: 1266/4024 0.294s 0.000s
im_detect: 1267/4024 0.294s 0.000s
im_detect: 1268/4024 0.294s 0.000s
im_detect: 1269/4024 0.294s 0.000s
im_detect: 1270/4024 0.294s 0.000s
im_detect: 1271/4024 0.294s 0.000s
im_detect: 1272/4024 0.294s 0.000s
im_detect: 1273/4024 0.294s 0.000s
im_detect: 1274/4024 0.294s 0.000s
im_detect: 1275/4024 0.294s 0.000s
im_detect: 1276/4024 0.294s 0.000s
im_detect: 1277/4024 0.294s 0.000s
im_detect: 1278/4024 0.294s 0.000s
im_detect: 1279/4024 0.294s 0.000s
im_detect: 1280/4024 0.294s 0.000s
im_detect: 1281/4024 0.294s 0.000s
im_detect: 1282/4024 0.294s 0.000s
im_detect: 1283/4024 0.294s 0.000s
im_detect: 1284/4024 0.294s 0.000s
im_detect: 1285/4024 0.294s 0.000s
im_detect: 1286/4024 0.294s 0.000s
im_detect: 1287/4024 0.294s 0.000s
im_detect: 1288/4024 0.294s 0.000s
im_detect: 1289/4024 0.294s 0.000s
im_detect: 1290/4024 0.294s 0.000s
im_detect: 1291/4024 0.294s 0.000s
im_detect: 1292/4024 0.294s 0.000s
im_detect: 1293/4024 0.294s 0.000s
im_detect: 1294/4024 0.294s 0.000s
im_detect: 1295/4024 0.294s 0.000s
im_detect: 1296/4024 0.294s 0.000s
im_detect: 1297/4024 0.294s 0.000s
im_detect: 1298/4024 0.294s 0.000s
im_detect: 1299/4024 0.294s 0.000s
im_detect: 1300/4024 0.294s 0.000s
im_detect: 1301/4024 0.294s 0.000s
im_detect: 1302/4024 0.294s 0.000s
im_detect: 1303/4024 0.294s 0.000s
im_detect: 1304/4024 0.294s 0.000s
im_detect: 1305/4024 0.294s 0.000s
im_detect: 1306/4024 0.294s 0.000s
im_detect: 1307/4024 0.294s 0.000s
im_detect: 1308/4024 0.294s 0.000s
im_detect: 1309/4024 0.294s 0.000s
im_detect: 1310/4024 0.294s 0.000s
im_detect: 1311/4024 0.294s 0.000s
im_detect: 1312/4024 0.294s 0.000s
im_detect: 1313/4024 0.294s 0.000s
im_detect: 1314/4024 0.294s 0.000s
im_detect: 1315/4024 0.294s 0.000s
im_detect: 1316/4024 0.294s 0.000s
im_detect: 1317/4024 0.294s 0.000s
im_detect: 1318/4024 0.294s 0.000s
im_detect: 1319/4024 0.294s 0.000s
im_detect: 1320/4024 0.294s 0.000s
im_detect: 1321/4024 0.294s 0.000s
im_detect: 1322/4024 0.294s 0.000s
im_detect: 1323/4024 0.294s 0.000s
im_detect: 1324/4024 0.294s 0.000s
im_detect: 1325/4024 0.294s 0.000s
im_detect: 1326/4024 0.294s 0.000s
im_detect: 1327/4024 0.294s 0.000s
im_detect: 1328/4024 0.294s 0.000s
im_detect: 1329/4024 0.294s 0.000s
im_detect: 1330/4024 0.294s 0.000s
im_detect: 1331/4024 0.294s 0.000s
im_detect: 1332/4024 0.294s 0.000s
im_detect: 1333/4024 0.294s 0.000s
im_detect: 1334/4024 0.294s 0.000s
im_detect: 1335/4024 0.294s 0.000s
im_detect: 1336/4024 0.294s 0.000s
im_detect: 1337/4024 0.294s 0.000s
im_detect: 1338/4024 0.294s 0.000s
im_detect: 1339/4024 0.294s 0.000s
im_detect: 1340/4024 0.294s 0.000s
im_detect: 1341/4024 0.294s 0.000s
im_detect: 1342/4024 0.294s 0.000s
im_detect: 1343/4024 0.294s 0.000s
im_detect: 1344/4024 0.294s 0.000s
im_detect: 1345/4024 0.294s 0.000s
im_detect: 1346/4024 0.294s 0.000s
im_detect: 1347/4024 0.294s 0.000s
im_detect: 1348/4024 0.294s 0.000s
im_detect: 1349/4024 0.294s 0.000s
im_detect: 1350/4024 0.294s 0.000s
im_detect: 1351/4024 0.294s 0.000s
im_detect: 1352/4024 0.294s 0.000s
im_detect: 1353/4024 0.294s 0.000s
im_detect: 1354/4024 0.294s 0.000s
im_detect: 1355/4024 0.294s 0.000s
im_detect: 1356/4024 0.294s 0.000s
im_detect: 1357/4024 0.294s 0.000s
im_detect: 1358/4024 0.294s 0.000s
im_detect: 1359/4024 0.294s 0.000s
im_detect: 1360/4024 0.294s 0.000s
im_detect: 1361/4024 0.294s 0.000s
im_detect: 1362/4024 0.294s 0.000s
im_detect: 1363/4024 0.294s 0.000s
im_detect: 1364/4024 0.294s 0.000s
im_detect: 1365/4024 0.294s 0.000s
im_detect: 1366/4024 0.294s 0.000s
im_detect: 1367/4024 0.294s 0.000s
im_detect: 1368/4024 0.294s 0.000s
im_detect: 1369/4024 0.294s 0.000s
im_detect: 1370/4024 0.294s 0.000s
im_detect: 1371/4024 0.294s 0.000s
im_detect: 1372/4024 0.294s 0.000s
im_detect: 1373/4024 0.294s 0.000s
im_detect: 1374/4024 0.294s 0.000s
im_detect: 1375/4024 0.294s 0.000s
im_detect: 1376/4024 0.294s 0.000s
im_detect: 1377/4024 0.294s 0.000s
im_detect: 1378/4024 0.294s 0.000s
im_detect: 1379/4024 0.294s 0.000s
im_detect: 1380/4024 0.294s 0.000s
im_detect: 1381/4024 0.294s 0.000s
im_detect: 1382/4024 0.294s 0.000s
im_detect: 1383/4024 0.294s 0.000s
im_detect: 1384/4024 0.294s 0.000s
im_detect: 1385/4024 0.294s 0.000s
im_detect: 1386/4024 0.294s 0.000s
im_detect: 1387/4024 0.294s 0.000s
im_detect: 1388/4024 0.294s 0.000s
im_detect: 1389/4024 0.294s 0.000s
im_detect: 1390/4024 0.294s 0.000s
im_detect: 1391/4024 0.294s 0.000s
im_detect: 1392/4024 0.294s 0.000s
im_detect: 1393/4024 0.294s 0.000s
im_detect: 1394/4024 0.294s 0.000s
im_detect: 1395/4024 0.294s 0.000s
im_detect: 1396/4024 0.294s 0.000s
im_detect: 1397/4024 0.294s 0.000s
im_detect: 1398/4024 0.294s 0.000s
im_detect: 1399/4024 0.294s 0.000s
im_detect: 1400/4024 0.294s 0.000s
im_detect: 1401/4024 0.294s 0.000s
im_detect: 1402/4024 0.294s 0.000s
im_detect: 1403/4024 0.294s 0.000s
im_detect: 1404/4024 0.294s 0.000s
im_detect: 1405/4024 0.294s 0.000s
im_detect: 1406/4024 0.294s 0.000s
im_detect: 1407/4024 0.294s 0.000s
im_detect: 1408/4024 0.294s 0.000s
im_detect: 1409/4024 0.294s 0.000s
im_detect: 1410/4024 0.294s 0.000s
im_detect: 1411/4024 0.294s 0.000s
im_detect: 1412/4024 0.294s 0.000s
im_detect: 1413/4024 0.294s 0.000s
im_detect: 1414/4024 0.294s 0.000s
im_detect: 1415/4024 0.294s 0.000s
im_detect: 1416/4024 0.294s 0.000s
im_detect: 1417/4024 0.294s 0.000s
im_detect: 1418/4024 0.294s 0.000s
im_detect: 1419/4024 0.294s 0.000s
im_detect: 1420/4024 0.294s 0.000s
im_detect: 1421/4024 0.294s 0.000s
im_detect: 1422/4024 0.294s 0.000s
im_detect: 1423/4024 0.294s 0.000s
im_detect: 1424/4024 0.294s 0.000s
im_detect: 1425/4024 0.294s 0.000s
im_detect: 1426/4024 0.294s 0.000s
im_detect: 1427/4024 0.294s 0.000s
im_detect: 1428/4024 0.294s 0.000s
im_detect: 1429/4024 0.294s 0.000s
im_detect: 1430/4024 0.294s 0.000s
im_detect: 1431/4024 0.294s 0.000s
im_detect: 1432/4024 0.294s 0.000s
im_detect: 1433/4024 0.294s 0.000s
im_detect: 1434/4024 0.294s 0.000s
im_detect: 1435/4024 0.294s 0.000s
im_detect: 1436/4024 0.294s 0.000s
im_detect: 1437/4024 0.294s 0.000s
im_detect: 1438/4024 0.294s 0.000s
im_detect: 1439/4024 0.294s 0.000s
im_detect: 1440/4024 0.294s 0.000s
im_detect: 1441/4024 0.294s 0.000s
im_detect: 1442/4024 0.294s 0.000s
im_detect: 1443/4024 0.294s 0.000s
im_detect: 1444/4024 0.294s 0.000s
im_detect: 1445/4024 0.294s 0.000s
im_detect: 1446/4024 0.294s 0.000s
im_detect: 1447/4024 0.294s 0.000s
im_detect: 1448/4024 0.294s 0.000s
im_detect: 1449/4024 0.294s 0.000s
im_detect: 1450/4024 0.294s 0.000s
im_detect: 1451/4024 0.294s 0.000s
im_detect: 1452/4024 0.294s 0.000s
im_detect: 1453/4024 0.294s 0.000s
im_detect: 1454/4024 0.294s 0.000s
im_detect: 1455/4024 0.294s 0.000s
im_detect: 1456/4024 0.294s 0.000s
im_detect: 1457/4024 0.294s 0.000s
im_detect: 1458/4024 0.294s 0.000s
im_detect: 1459/4024 0.294s 0.000s
im_detect: 1460/4024 0.294s 0.000s
im_detect: 1461/4024 0.294s 0.000s
im_detect: 1462/4024 0.294s 0.000s
im_detect: 1463/4024 0.294s 0.000s
im_detect: 1464/4024 0.294s 0.000s
im_detect: 1465/4024 0.294s 0.000s
im_detect: 1466/4024 0.294s 0.000s
im_detect: 1467/4024 0.294s 0.000s
im_detect: 1468/4024 0.294s 0.000s
im_detect: 1469/4024 0.294s 0.000s
im_detect: 1470/4024 0.294s 0.000s
im_detect: 1471/4024 0.294s 0.000s
im_detect: 1472/4024 0.294s 0.000s
im_detect: 1473/4024 0.294s 0.000s
im_detect: 1474/4024 0.294s 0.000s
im_detect: 1475/4024 0.294s 0.000s
im_detect: 1476/4024 0.294s 0.000s
im_detect: 1477/4024 0.294s 0.000s
im_detect: 1478/4024 0.294s 0.000s
im_detect: 1479/4024 0.294s 0.000s
im_detect: 1480/4024 0.294s 0.000s
im_detect: 1481/4024 0.294s 0.000s
im_detect: 1482/4024 0.294s 0.000s
im_detect: 1483/4024 0.294s 0.000s
im_detect: 1484/4024 0.294s 0.000s
im_detect: 1485/4024 0.294s 0.000s
im_detect: 1486/4024 0.294s 0.000s
im_detect: 1487/4024 0.294s 0.000s
im_detect: 1488/4024 0.294s 0.000s
im_detect: 1489/4024 0.294s 0.000s
im_detect: 1490/4024 0.294s 0.000s
im_detect: 1491/4024 0.294s 0.000s
im_detect: 1492/4024 0.294s 0.000s
im_detect: 1493/4024 0.294s 0.000s
im_detect: 1494/4024 0.294s 0.000s
im_detect: 1495/4024 0.294s 0.000s
im_detect: 1496/4024 0.294s 0.000s
im_detect: 1497/4024 0.294s 0.000s
im_detect: 1498/4024 0.294s 0.000s
im_detect: 1499/4024 0.294s 0.000s
im_detect: 1500/4024 0.294s 0.000s
im_detect: 1501/4024 0.294s 0.000s
im_detect: 1502/4024 0.294s 0.000s
im_detect: 1503/4024 0.294s 0.000s
im_detect: 1504/4024 0.294s 0.000s
im_detect: 1505/4024 0.294s 0.000s
im_detect: 1506/4024 0.294s 0.000s
im_detect: 1507/4024 0.294s 0.000s
im_detect: 1508/4024 0.294s 0.000s
im_detect: 1509/4024 0.294s 0.000s
im_detect: 1510/4024 0.294s 0.000s
im_detect: 1511/4024 0.294s 0.000s
im_detect: 1512/4024 0.294s 0.000s
im_detect: 1513/4024 0.294s 0.000s
im_detect: 1514/4024 0.294s 0.000s
im_detect: 1515/4024 0.294s 0.000s
im_detect: 1516/4024 0.294s 0.000s
im_detect: 1517/4024 0.294s 0.000s
im_detect: 1518/4024 0.294s 0.000s
im_detect: 1519/4024 0.294s 0.000s
im_detect: 1520/4024 0.294s 0.000s
im_detect: 1521/4024 0.294s 0.000s
im_detect: 1522/4024 0.294s 0.000s
im_detect: 1523/4024 0.294s 0.000s
im_detect: 1524/4024 0.294s 0.000s
im_detect: 1525/4024 0.294s 0.000s
im_detect: 1526/4024 0.294s 0.000s
im_detect: 1527/4024 0.294s 0.000s
im_detect: 1528/4024 0.294s 0.000s
im_detect: 1529/4024 0.294s 0.000s
im_detect: 1530/4024 0.294s 0.000s
im_detect: 1531/4024 0.294s 0.000s
im_detect: 1532/4024 0.294s 0.000s
im_detect: 1533/4024 0.294s 0.000s
im_detect: 1534/4024 0.294s 0.000s
im_detect: 1535/4024 0.294s 0.000s
im_detect: 1536/4024 0.294s 0.000s
im_detect: 1537/4024 0.294s 0.000s
im_detect: 1538/4024 0.294s 0.000s
im_detect: 1539/4024 0.294s 0.000s
im_detect: 1540/4024 0.294s 0.000s
im_detect: 1541/4024 0.294s 0.000s
im_detect: 1542/4024 0.294s 0.000s
im_detect: 1543/4024 0.294s 0.000s
im_detect: 1544/4024 0.294s 0.000s
im_detect: 1545/4024 0.294s 0.000s
im_detect: 1546/4024 0.294s 0.000s
im_detect: 1547/4024 0.294s 0.000s
im_detect: 1548/4024 0.294s 0.000s
im_detect: 1549/4024 0.294s 0.000s
im_detect: 1550/4024 0.294s 0.000s
im_detect: 1551/4024 0.294s 0.000s
im_detect: 1552/4024 0.294s 0.000s
im_detect: 1553/4024 0.294s 0.000s
im_detect: 1554/4024 0.294s 0.000s
im_detect: 1555/4024 0.294s 0.000s
im_detect: 1556/4024 0.294s 0.000s
im_detect: 1557/4024 0.294s 0.000s
im_detect: 1558/4024 0.294s 0.000s
im_detect: 1559/4024 0.294s 0.000s
im_detect: 1560/4024 0.294s 0.000s
im_detect: 1561/4024 0.294s 0.000s
im_detect: 1562/4024 0.294s 0.000s
im_detect: 1563/4024 0.294s 0.000s
im_detect: 1564/4024 0.294s 0.000s
im_detect: 1565/4024 0.294s 0.000s
im_detect: 1566/4024 0.294s 0.000s
im_detect: 1567/4024 0.294s 0.000s
im_detect: 1568/4024 0.294s 0.000s
im_detect: 1569/4024 0.294s 0.000s
im_detect: 1570/4024 0.294s 0.000s
im_detect: 1571/4024 0.294s 0.000s
im_detect: 1572/4024 0.294s 0.000s
im_detect: 1573/4024 0.294s 0.000s
im_detect: 1574/4024 0.294s 0.000s
im_detect: 1575/4024 0.294s 0.000s
im_detect: 1576/4024 0.294s 0.000s
im_detect: 1577/4024 0.294s 0.000s
im_detect: 1578/4024 0.294s 0.000s
im_detect: 1579/4024 0.294s 0.000s
im_detect: 1580/4024 0.294s 0.000s
im_detect: 1581/4024 0.294s 0.000s
im_detect: 1582/4024 0.294s 0.000s
im_detect: 1583/4024 0.294s 0.000s
im_detect: 1584/4024 0.294s 0.000s
im_detect: 1585/4024 0.294s 0.000s
im_detect: 1586/4024 0.294s 0.000s
im_detect: 1587/4024 0.294s 0.000s
im_detect: 1588/4024 0.294s 0.000s
im_detect: 1589/4024 0.294s 0.000s
im_detect: 1590/4024 0.294s 0.000s
im_detect: 1591/4024 0.294s 0.000s
im_detect: 1592/4024 0.294s 0.000s
im_detect: 1593/4024 0.294s 0.000s
im_detect: 1594/4024 0.294s 0.000s
im_detect: 1595/4024 0.294s 0.000s
im_detect: 1596/4024 0.294s 0.000s
im_detect: 1597/4024 0.294s 0.000s
im_detect: 1598/4024 0.294s 0.000s
im_detect: 1599/4024 0.294s 0.000s
im_detect: 1600/4024 0.294s 0.000s
im_detect: 1601/4024 0.294s 0.000s
im_detect: 1602/4024 0.294s 0.000s
im_detect: 1603/4024 0.294s 0.000s
im_detect: 1604/4024 0.294s 0.000s
im_detect: 1605/4024 0.294s 0.000s
im_detect: 1606/4024 0.294s 0.000s
im_detect: 1607/4024 0.294s 0.000s
im_detect: 1608/4024 0.294s 0.000s
im_detect: 1609/4024 0.294s 0.000s
im_detect: 1610/4024 0.294s 0.000s
im_detect: 1611/4024 0.294s 0.000s
im_detect: 1612/4024 0.294s 0.000s
im_detect: 1613/4024 0.294s 0.000s
im_detect: 1614/4024 0.294s 0.000s
im_detect: 1615/4024 0.294s 0.000s
im_detect: 1616/4024 0.294s 0.000s
im_detect: 1617/4024 0.294s 0.000s
im_detect: 1618/4024 0.294s 0.000s
im_detect: 1619/4024 0.294s 0.000s
im_detect: 1620/4024 0.294s 0.000s
im_detect: 1621/4024 0.294s 0.000s
im_detect: 1622/4024 0.294s 0.000s
im_detect: 1623/4024 0.294s 0.000s
im_detect: 1624/4024 0.294s 0.000s
im_detect: 1625/4024 0.294s 0.000s
im_detect: 1626/4024 0.294s 0.000s
im_detect: 1627/4024 0.294s 0.000s
im_detect: 1628/4024 0.294s 0.000s
im_detect: 1629/4024 0.294s 0.000s
im_detect: 1630/4024 0.294s 0.000s
im_detect: 1631/4024 0.294s 0.000s
im_detect: 1632/4024 0.294s 0.000s
im_detect: 1633/4024 0.294s 0.000s
im_detect: 1634/4024 0.294s 0.000s
im_detect: 1635/4024 0.294s 0.000s
im_detect: 1636/4024 0.294s 0.000s
im_detect: 1637/4024 0.294s 0.000s
im_detect: 1638/4024 0.294s 0.000s
im_detect: 1639/4024 0.294s 0.000s
im_detect: 1640/4024 0.294s 0.000s
im_detect: 1641/4024 0.294s 0.000s
im_detect: 1642/4024 0.294s 0.000s
im_detect: 1643/4024 0.294s 0.000s
im_detect: 1644/4024 0.294s 0.000s
im_detect: 1645/4024 0.294s 0.000s
im_detect: 1646/4024 0.294s 0.000s
im_detect: 1647/4024 0.294s 0.000s
im_detect: 1648/4024 0.294s 0.000s
im_detect: 1649/4024 0.294s 0.000s
im_detect: 1650/4024 0.294s 0.000s
im_detect: 1651/4024 0.294s 0.000s
im_detect: 1652/4024 0.294s 0.000s
im_detect: 1653/4024 0.294s 0.000s
im_detect: 1654/4024 0.294s 0.000s
im_detect: 1655/4024 0.294s 0.000s
im_detect: 1656/4024 0.294s 0.000s
im_detect: 1657/4024 0.294s 0.000s
im_detect: 1658/4024 0.294s 0.000s
im_detect: 1659/4024 0.294s 0.000s
im_detect: 1660/4024 0.294s 0.000s
im_detect: 1661/4024 0.294s 0.000s
im_detect: 1662/4024 0.294s 0.000s
im_detect: 1663/4024 0.294s 0.000s
im_detect: 1664/4024 0.294s 0.000s
im_detect: 1665/4024 0.294s 0.000s
im_detect: 1666/4024 0.294s 0.000s
im_detect: 1667/4024 0.294s 0.000s
im_detect: 1668/4024 0.294s 0.000s
im_detect: 1669/4024 0.294s 0.000s
im_detect: 1670/4024 0.294s 0.000s
im_detect: 1671/4024 0.294s 0.000s
im_detect: 1672/4024 0.294s 0.000s
im_detect: 1673/4024 0.294s 0.000s
im_detect: 1674/4024 0.294s 0.000s
im_detect: 1675/4024 0.294s 0.000s
im_detect: 1676/4024 0.294s 0.000s
im_detect: 1677/4024 0.294s 0.000s
im_detect: 1678/4024 0.294s 0.000s
im_detect: 1679/4024 0.294s 0.000s
im_detect: 1680/4024 0.294s 0.000s
im_detect: 1681/4024 0.294s 0.000s
im_detect: 1682/4024 0.294s 0.000s
im_detect: 1683/4024 0.294s 0.000s
im_detect: 1684/4024 0.294s 0.000s
im_detect: 1685/4024 0.294s 0.000s
im_detect: 1686/4024 0.294s 0.000s
im_detect: 1687/4024 0.294s 0.000s
im_detect: 1688/4024 0.294s 0.000s
im_detect: 1689/4024 0.294s 0.000s
im_detect: 1690/4024 0.294s 0.000s
im_detect: 1691/4024 0.294s 0.000s
im_detect: 1692/4024 0.294s 0.000s
im_detect: 1693/4024 0.294s 0.000s
im_detect: 1694/4024 0.294s 0.000s
im_detect: 1695/4024 0.294s 0.000s
im_detect: 1696/4024 0.294s 0.000s
im_detect: 1697/4024 0.294s 0.000s
im_detect: 1698/4024 0.294s 0.000s
im_detect: 1699/4024 0.294s 0.000s
im_detect: 1700/4024 0.294s 0.000s
im_detect: 1701/4024 0.294s 0.000s
im_detect: 1702/4024 0.294s 0.000s
im_detect: 1703/4024 0.294s 0.000s
im_detect: 1704/4024 0.294s 0.000s
im_detect: 1705/4024 0.294s 0.000s
im_detect: 1706/4024 0.294s 0.000s
im_detect: 1707/4024 0.294s 0.000s
im_detect: 1708/4024 0.294s 0.000s
im_detect: 1709/4024 0.294s 0.000s
im_detect: 1710/4024 0.294s 0.000s
im_detect: 1711/4024 0.294s 0.000s
im_detect: 1712/4024 0.294s 0.000s
im_detect: 1713/4024 0.294s 0.000s
im_detect: 1714/4024 0.294s 0.000s
im_detect: 1715/4024 0.294s 0.000s
im_detect: 1716/4024 0.294s 0.000s
im_detect: 1717/4024 0.294s 0.000s
im_detect: 1718/4024 0.294s 0.000s
im_detect: 1719/4024 0.294s 0.000s
im_detect: 1720/4024 0.293s 0.000s
im_detect: 1721/4024 0.293s 0.000s
im_detect: 1722/4024 0.293s 0.000s
im_detect: 1723/4024 0.293s 0.000s
im_detect: 1724/4024 0.293s 0.000s
im_detect: 1725/4024 0.293s 0.000s
im_detect: 1726/4024 0.293s 0.000s
im_detect: 1727/4024 0.293s 0.000s
im_detect: 1728/4024 0.293s 0.000s
im_detect: 1729/4024 0.293s 0.000s
im_detect: 1730/4024 0.293s 0.000s
im_detect: 1731/4024 0.293s 0.000s
im_detect: 1732/4024 0.293s 0.000s
im_detect: 1733/4024 0.293s 0.000s
im_detect: 1734/4024 0.293s 0.000s
im_detect: 1735/4024 0.293s 0.000s
im_detect: 1736/4024 0.293s 0.000s
im_detect: 1737/4024 0.293s 0.000s
im_detect: 1738/4024 0.293s 0.000s
im_detect: 1739/4024 0.293s 0.000s
im_detect: 1740/4024 0.293s 0.000s
im_detect: 1741/4024 0.293s 0.000s
im_detect: 1742/4024 0.293s 0.000s
im_detect: 1743/4024 0.293s 0.000s
im_detect: 1744/4024 0.293s 0.000s
im_detect: 1745/4024 0.293s 0.000s
im_detect: 1746/4024 0.293s 0.000s
im_detect: 1747/4024 0.293s 0.000s
im_detect: 1748/4024 0.293s 0.000s
im_detect: 1749/4024 0.293s 0.000s
im_detect: 1750/4024 0.293s 0.000s
im_detect: 1751/4024 0.293s 0.000s
im_detect: 1752/4024 0.293s 0.000s
im_detect: 1753/4024 0.293s 0.000s
im_detect: 1754/4024 0.293s 0.000s
im_detect: 1755/4024 0.293s 0.000s
im_detect: 1756/4024 0.293s 0.000s
im_detect: 1757/4024 0.293s 0.000s
im_detect: 1758/4024 0.293s 0.000s
im_detect: 1759/4024 0.293s 0.000s
im_detect: 1760/4024 0.293s 0.000s
im_detect: 1761/4024 0.293s 0.000s
im_detect: 1762/4024 0.293s 0.000s
im_detect: 1763/4024 0.293s 0.000s
im_detect: 1764/4024 0.293s 0.000s
im_detect: 1765/4024 0.293s 0.000s
im_detect: 1766/4024 0.293s 0.000s
im_detect: 1767/4024 0.293s 0.000s
im_detect: 1768/4024 0.293s 0.000s
im_detect: 1769/4024 0.293s 0.000s
im_detect: 1770/4024 0.293s 0.000s
im_detect: 1771/4024 0.293s 0.000s
im_detect: 1772/4024 0.293s 0.000s
im_detect: 1773/4024 0.293s 0.000s
im_detect: 1774/4024 0.293s 0.000s
im_detect: 1775/4024 0.293s 0.000s
im_detect: 1776/4024 0.293s 0.000s
im_detect: 1777/4024 0.293s 0.000s
im_detect: 1778/4024 0.293s 0.000s
im_detect: 1779/4024 0.293s 0.000s
im_detect: 1780/4024 0.293s 0.000s
im_detect: 1781/4024 0.293s 0.000s
im_detect: 1782/4024 0.293s 0.000s
im_detect: 1783/4024 0.293s 0.000s
im_detect: 1784/4024 0.293s 0.000s
im_detect: 1785/4024 0.293s 0.000s
im_detect: 1786/4024 0.293s 0.000s
im_detect: 1787/4024 0.293s 0.000s
im_detect: 1788/4024 0.293s 0.000s
im_detect: 1789/4024 0.293s 0.000s
im_detect: 1790/4024 0.293s 0.000s
im_detect: 1791/4024 0.293s 0.000s
im_detect: 1792/4024 0.293s 0.000s
im_detect: 1793/4024 0.293s 0.000s
im_detect: 1794/4024 0.293s 0.000s
im_detect: 1795/4024 0.293s 0.000s
im_detect: 1796/4024 0.293s 0.000s
im_detect: 1797/4024 0.293s 0.000s
im_detect: 1798/4024 0.293s 0.000s
im_detect: 1799/4024 0.293s 0.000s
im_detect: 1800/4024 0.293s 0.000s
im_detect: 1801/4024 0.293s 0.000s
im_detect: 1802/4024 0.293s 0.000s
im_detect: 1803/4024 0.293s 0.000s
im_detect: 1804/4024 0.293s 0.000s
im_detect: 1805/4024 0.293s 0.000s
im_detect: 1806/4024 0.293s 0.000s
im_detect: 1807/4024 0.293s 0.000s
im_detect: 1808/4024 0.293s 0.000s
im_detect: 1809/4024 0.293s 0.000s
im_detect: 1810/4024 0.293s 0.000s
im_detect: 1811/4024 0.293s 0.000s
im_detect: 1812/4024 0.293s 0.000s
im_detect: 1813/4024 0.293s 0.000s
im_detect: 1814/4024 0.293s 0.000s
im_detect: 1815/4024 0.293s 0.000s
im_detect: 1816/4024 0.293s 0.000s
im_detect: 1817/4024 0.293s 0.000s
im_detect: 1818/4024 0.293s 0.000s
im_detect: 1819/4024 0.293s 0.000s
im_detect: 1820/4024 0.293s 0.000s
im_detect: 1821/4024 0.293s 0.000s
im_detect: 1822/4024 0.293s 0.000s
im_detect: 1823/4024 0.293s 0.000s
im_detect: 1824/4024 0.293s 0.000s
im_detect: 1825/4024 0.293s 0.000s
im_detect: 1826/4024 0.293s 0.000s
im_detect: 1827/4024 0.293s 0.000s
im_detect: 1828/4024 0.293s 0.000s
im_detect: 1829/4024 0.293s 0.000s
im_detect: 1830/4024 0.293s 0.000s
im_detect: 1831/4024 0.293s 0.000s
im_detect: 1832/4024 0.293s 0.000s
im_detect: 1833/4024 0.293s 0.000s
im_detect: 1834/4024 0.293s 0.000s
im_detect: 1835/4024 0.293s 0.000s
im_detect: 1836/4024 0.293s 0.000s
im_detect: 1837/4024 0.293s 0.000s
im_detect: 1838/4024 0.293s 0.000s
im_detect: 1839/4024 0.293s 0.000s
im_detect: 1840/4024 0.293s 0.000s
im_detect: 1841/4024 0.293s 0.000s
im_detect: 1842/4024 0.293s 0.000s
im_detect: 1843/4024 0.293s 0.000s
im_detect: 1844/4024 0.293s 0.000s
im_detect: 1845/4024 0.293s 0.000s
im_detect: 1846/4024 0.293s 0.000s
im_detect: 1847/4024 0.293s 0.000s
im_detect: 1848/4024 0.293s 0.000s
im_detect: 1849/4024 0.293s 0.000s
im_detect: 1850/4024 0.293s 0.000s
im_detect: 1851/4024 0.293s 0.000s
im_detect: 1852/4024 0.293s 0.000s
im_detect: 1853/4024 0.293s 0.000s
im_detect: 1854/4024 0.293s 0.000s
im_detect: 1855/4024 0.293s 0.000s
im_detect: 1856/4024 0.293s 0.000s
im_detect: 1857/4024 0.293s 0.000s
im_detect: 1858/4024 0.293s 0.000s
im_detect: 1859/4024 0.293s 0.000s
im_detect: 1860/4024 0.293s 0.000s
im_detect: 1861/4024 0.293s 0.000s
im_detect: 1862/4024 0.293s 0.000s
im_detect: 1863/4024 0.293s 0.000s
im_detect: 1864/4024 0.293s 0.000s
im_detect: 1865/4024 0.293s 0.000s
im_detect: 1866/4024 0.293s 0.000s
im_detect: 1867/4024 0.293s 0.000s
im_detect: 1868/4024 0.293s 0.000s
im_detect: 1869/4024 0.293s 0.000s
im_detect: 1870/4024 0.293s 0.000s
im_detect: 1871/4024 0.293s 0.000s
im_detect: 1872/4024 0.293s 0.000s
im_detect: 1873/4024 0.293s 0.000s
im_detect: 1874/4024 0.293s 0.000s
im_detect: 1875/4024 0.293s 0.000s
im_detect: 1876/4024 0.293s 0.000s
im_detect: 1877/4024 0.293s 0.000s
im_detect: 1878/4024 0.293s 0.000s
im_detect: 1879/4024 0.293s 0.000s
im_detect: 1880/4024 0.293s 0.000s
im_detect: 1881/4024 0.293s 0.000s
im_detect: 1882/4024 0.293s 0.000s
im_detect: 1883/4024 0.293s 0.000s
im_detect: 1884/4024 0.293s 0.000s
im_detect: 1885/4024 0.293s 0.000s
im_detect: 1886/4024 0.293s 0.000s
im_detect: 1887/4024 0.293s 0.000s
im_detect: 1888/4024 0.293s 0.000s
im_detect: 1889/4024 0.293s 0.000s
im_detect: 1890/4024 0.293s 0.000s
im_detect: 1891/4024 0.293s 0.000s
im_detect: 1892/4024 0.293s 0.000s
im_detect: 1893/4024 0.293s 0.000s
im_detect: 1894/4024 0.293s 0.000s
im_detect: 1895/4024 0.293s 0.000s
im_detect: 1896/4024 0.293s 0.000s
im_detect: 1897/4024 0.293s 0.000s
im_detect: 1898/4024 0.293s 0.000s
im_detect: 1899/4024 0.293s 0.000s
im_detect: 1900/4024 0.293s 0.000s
im_detect: 1901/4024 0.293s 0.000s
im_detect: 1902/4024 0.293s 0.000s
im_detect: 1903/4024 0.293s 0.000s
im_detect: 1904/4024 0.293s 0.000s
im_detect: 1905/4024 0.293s 0.000s
im_detect: 1906/4024 0.293s 0.000s
im_detect: 1907/4024 0.293s 0.000s
im_detect: 1908/4024 0.293s 0.000s
im_detect: 1909/4024 0.293s 0.000s
im_detect: 1910/4024 0.293s 0.000s
im_detect: 1911/4024 0.293s 0.000s
im_detect: 1912/4024 0.293s 0.000s
im_detect: 1913/4024 0.293s 0.000s
im_detect: 1914/4024 0.293s 0.000s
im_detect: 1915/4024 0.293s 0.000s
im_detect: 1916/4024 0.293s 0.000s
im_detect: 1917/4024 0.293s 0.000s
im_detect: 1918/4024 0.293s 0.000s
im_detect: 1919/4024 0.293s 0.000s
im_detect: 1920/4024 0.293s 0.000s
im_detect: 1921/4024 0.293s 0.000s
im_detect: 1922/4024 0.293s 0.000s
im_detect: 1923/4024 0.293s 0.000s
im_detect: 1924/4024 0.293s 0.000s
im_detect: 1925/4024 0.293s 0.000s
im_detect: 1926/4024 0.293s 0.000s
im_detect: 1927/4024 0.293s 0.000s
im_detect: 1928/4024 0.293s 0.000s
im_detect: 1929/4024 0.293s 0.000s
im_detect: 1930/4024 0.293s 0.000s
im_detect: 1931/4024 0.293s 0.000s
im_detect: 1932/4024 0.293s 0.000s
im_detect: 1933/4024 0.293s 0.000s
im_detect: 1934/4024 0.293s 0.000s
im_detect: 1935/4024 0.293s 0.000s
im_detect: 1936/4024 0.293s 0.000s
im_detect: 1937/4024 0.293s 0.000s
im_detect: 1938/4024 0.293s 0.000s
im_detect: 1939/4024 0.293s 0.000s
im_detect: 1940/4024 0.293s 0.000s
im_detect: 1941/4024 0.293s 0.000s
im_detect: 1942/4024 0.293s 0.000s
im_detect: 1943/4024 0.293s 0.000s
im_detect: 1944/4024 0.293s 0.000s
im_detect: 1945/4024 0.293s 0.000s
im_detect: 1946/4024 0.293s 0.000s
im_detect: 1947/4024 0.293s 0.000s
im_detect: 1948/4024 0.293s 0.000s
im_detect: 1949/4024 0.293s 0.000s
im_detect: 1950/4024 0.293s 0.000s
im_detect: 1951/4024 0.293s 0.000s
im_detect: 1952/4024 0.293s 0.000s
im_detect: 1953/4024 0.293s 0.000s
im_detect: 1954/4024 0.293s 0.000s
im_detect: 1955/4024 0.293s 0.000s
im_detect: 1956/4024 0.293s 0.000s
im_detect: 1957/4024 0.293s 0.000s
im_detect: 1958/4024 0.293s 0.000s
im_detect: 1959/4024 0.293s 0.000s
im_detect: 1960/4024 0.293s 0.000s
im_detect: 1961/4024 0.293s 0.000s
im_detect: 1962/4024 0.293s 0.000s
im_detect: 1963/4024 0.293s 0.000s
im_detect: 1964/4024 0.293s 0.000s
im_detect: 1965/4024 0.293s 0.000s
im_detect: 1966/4024 0.293s 0.000s
im_detect: 1967/4024 0.293s 0.000s
im_detect: 1968/4024 0.293s 0.000s
im_detect: 1969/4024 0.293s 0.000s
im_detect: 1970/4024 0.293s 0.000s
im_detect: 1971/4024 0.293s 0.000s
im_detect: 1972/4024 0.293s 0.000s
im_detect: 1973/4024 0.293s 0.000s
im_detect: 1974/4024 0.293s 0.000s
im_detect: 1975/4024 0.293s 0.000s
im_detect: 1976/4024 0.293s 0.000s
im_detect: 1977/4024 0.293s 0.000s
im_detect: 1978/4024 0.293s 0.000s
im_detect: 1979/4024 0.293s 0.000s
im_detect: 1980/4024 0.293s 0.000s
im_detect: 1981/4024 0.293s 0.000s
im_detect: 1982/4024 0.293s 0.000s
im_detect: 1983/4024 0.293s 0.000s
im_detect: 1984/4024 0.293s 0.000s
im_detect: 1985/4024 0.293s 0.000s
im_detect: 1986/4024 0.293s 0.000s
im_detect: 1987/4024 0.293s 0.000s
im_detect: 1988/4024 0.293s 0.000s
im_detect: 1989/4024 0.293s 0.000s
im_detect: 1990/4024 0.293s 0.000s
im_detect: 1991/4024 0.293s 0.000s
im_detect: 1992/4024 0.293s 0.000s
im_detect: 1993/4024 0.293s 0.000s
im_detect: 1994/4024 0.293s 0.000s
im_detect: 1995/4024 0.293s 0.000s
im_detect: 1996/4024 0.293s 0.000s
im_detect: 1997/4024 0.293s 0.000s
im_detect: 1998/4024 0.293s 0.000s
im_detect: 1999/4024 0.293s 0.000s
im_detect: 2000/4024 0.293s 0.000s
im_detect: 2001/4024 0.293s 0.000s
im_detect: 2002/4024 0.293s 0.000s
im_detect: 2003/4024 0.293s 0.000s
im_detect: 2004/4024 0.293s 0.000s
im_detect: 2005/4024 0.293s 0.000s
im_detect: 2006/4024 0.293s 0.000s
im_detect: 2007/4024 0.293s 0.000s
im_detect: 2008/4024 0.293s 0.000s
im_detect: 2009/4024 0.293s 0.000s
im_detect: 2010/4024 0.293s 0.000s
im_detect: 2011/4024 0.293s 0.000s
im_detect: 2012/4024 0.293s 0.000s
im_detect: 2013/4024 0.293s 0.000s
im_detect: 2014/4024 0.293s 0.000s
im_detect: 2015/4024 0.293s 0.000s
im_detect: 2016/4024 0.293s 0.000s
im_detect: 2017/4024 0.293s 0.000s
im_detect: 2018/4024 0.293s 0.000s
im_detect: 2019/4024 0.293s 0.000s
im_detect: 2020/4024 0.293s 0.000s
im_detect: 2021/4024 0.293s 0.000s
im_detect: 2022/4024 0.293s 0.000s
im_detect: 2023/4024 0.293s 0.000s
im_detect: 2024/4024 0.293s 0.000s
im_detect: 2025/4024 0.293s 0.000s
im_detect: 2026/4024 0.293s 0.000s
im_detect: 2027/4024 0.293s 0.000s
im_detect: 2028/4024 0.293s 0.000s
im_detect: 2029/4024 0.293s 0.000s
im_detect: 2030/4024 0.293s 0.000s
im_detect: 2031/4024 0.293s 0.000s
im_detect: 2032/4024 0.293s 0.000s
im_detect: 2033/4024 0.293s 0.000s
im_detect: 2034/4024 0.293s 0.000s
im_detect: 2035/4024 0.293s 0.000s
im_detect: 2036/4024 0.293s 0.000s
im_detect: 2037/4024 0.293s 0.000s
im_detect: 2038/4024 0.293s 0.000s
im_detect: 2039/4024 0.293s 0.000s
im_detect: 2040/4024 0.293s 0.000s
im_detect: 2041/4024 0.293s 0.000s
im_detect: 2042/4024 0.293s 0.000s
im_detect: 2043/4024 0.293s 0.000s
im_detect: 2044/4024 0.293s 0.000s
im_detect: 2045/4024 0.293s 0.000s
im_detect: 2046/4024 0.293s 0.000s
im_detect: 2047/4024 0.293s 0.000s
im_detect: 2048/4024 0.293s 0.000s
im_detect: 2049/4024 0.293s 0.000s
im_detect: 2050/4024 0.293s 0.000s
im_detect: 2051/4024 0.293s 0.000s
im_detect: 2052/4024 0.293s 0.000s
im_detect: 2053/4024 0.293s 0.000s
im_detect: 2054/4024 0.293s 0.000s
im_detect: 2055/4024 0.293s 0.000s
im_detect: 2056/4024 0.293s 0.000s
im_detect: 2057/4024 0.293s 0.000s
im_detect: 2058/4024 0.293s 0.000s
im_detect: 2059/4024 0.293s 0.000s
im_detect: 2060/4024 0.293s 0.000s
im_detect: 2061/4024 0.293s 0.000s
im_detect: 2062/4024 0.293s 0.000s
im_detect: 2063/4024 0.293s 0.000s
im_detect: 2064/4024 0.293s 0.000s
im_detect: 2065/4024 0.293s 0.000s
im_detect: 2066/4024 0.293s 0.000s
im_detect: 2067/4024 0.293s 0.000s
im_detect: 2068/4024 0.293s 0.000s
im_detect: 2069/4024 0.293s 0.000s
im_detect: 2070/4024 0.293s 0.000s
im_detect: 2071/4024 0.293s 0.000s
im_detect: 2072/4024 0.293s 0.000s
im_detect: 2073/4024 0.293s 0.000s
im_detect: 2074/4024 0.293s 0.000s
im_detect: 2075/4024 0.293s 0.000s
im_detect: 2076/4024 0.293s 0.000s
im_detect: 2077/4024 0.293s 0.000s
im_detect: 2078/4024 0.293s 0.000s
im_detect: 2079/4024 0.293s 0.000s
im_detect: 2080/4024 0.293s 0.000s
im_detect: 2081/4024 0.293s 0.000s
im_detect: 2082/4024 0.293s 0.000s
im_detect: 2083/4024 0.293s 0.000s
im_detect: 2084/4024 0.293s 0.000s
im_detect: 2085/4024 0.293s 0.000s
im_detect: 2086/4024 0.293s 0.000s
im_detect: 2087/4024 0.293s 0.000s
im_detect: 2088/4024 0.293s 0.000s
im_detect: 2089/4024 0.293s 0.000s
im_detect: 2090/4024 0.293s 0.000s
im_detect: 2091/4024 0.293s 0.000s
im_detect: 2092/4024 0.293s 0.000s
im_detect: 2093/4024 0.293s 0.000s
im_detect: 2094/4024 0.293s 0.000s
im_detect: 2095/4024 0.293s 0.000s
im_detect: 2096/4024 0.293s 0.000s
im_detect: 2097/4024 0.293s 0.000s
im_detect: 2098/4024 0.293s 0.000s
im_detect: 2099/4024 0.293s 0.000s
im_detect: 2100/4024 0.293s 0.000s
im_detect: 2101/4024 0.293s 0.000s
im_detect: 2102/4024 0.293s 0.000s
im_detect: 2103/4024 0.293s 0.000s
im_detect: 2104/4024 0.293s 0.000s
im_detect: 2105/4024 0.293s 0.000s
im_detect: 2106/4024 0.293s 0.000s
im_detect: 2107/4024 0.293s 0.000s
im_detect: 2108/4024 0.293s 0.000s
im_detect: 2109/4024 0.293s 0.000s
im_detect: 2110/4024 0.293s 0.000s
im_detect: 2111/4024 0.293s 0.000s
im_detect: 2112/4024 0.293s 0.000s
im_detect: 2113/4024 0.293s 0.000s
im_detect: 2114/4024 0.293s 0.000s
im_detect: 2115/4024 0.293s 0.000s
im_detect: 2116/4024 0.293s 0.000s
im_detect: 2117/4024 0.293s 0.000s
im_detect: 2118/4024 0.293s 0.000s
im_detect: 2119/4024 0.293s 0.000s
im_detect: 2120/4024 0.293s 0.000s
im_detect: 2121/4024 0.293s 0.000s
im_detect: 2122/4024 0.293s 0.000s
im_detect: 2123/4024 0.293s 0.000s
im_detect: 2124/4024 0.293s 0.000s
im_detect: 2125/4024 0.293s 0.000s
im_detect: 2126/4024 0.293s 0.000s
im_detect: 2127/4024 0.293s 0.000s
im_detect: 2128/4024 0.293s 0.000s
im_detect: 2129/4024 0.293s 0.000s
im_detect: 2130/4024 0.293s 0.000s
im_detect: 2131/4024 0.293s 0.000s
im_detect: 2132/4024 0.293s 0.000s
im_detect: 2133/4024 0.293s 0.000s
im_detect: 2134/4024 0.293s 0.000s
im_detect: 2135/4024 0.293s 0.000s
im_detect: 2136/4024 0.293s 0.000s
im_detect: 2137/4024 0.293s 0.000s
im_detect: 2138/4024 0.293s 0.000s
im_detect: 2139/4024 0.293s 0.000s
im_detect: 2140/4024 0.293s 0.000s
im_detect: 2141/4024 0.293s 0.000s
im_detect: 2142/4024 0.293s 0.000s
im_detect: 2143/4024 0.293s 0.000s
im_detect: 2144/4024 0.293s 0.000s
im_detect: 2145/4024 0.293s 0.000s
im_detect: 2146/4024 0.293s 0.000s
im_detect: 2147/4024 0.293s 0.000s
im_detect: 2148/4024 0.293s 0.000s
im_detect: 2149/4024 0.293s 0.000s
im_detect: 2150/4024 0.293s 0.000s
im_detect: 2151/4024 0.293s 0.000s
im_detect: 2152/4024 0.293s 0.000s
im_detect: 2153/4024 0.293s 0.000s
im_detect: 2154/4024 0.293s 0.000s
im_detect: 2155/4024 0.293s 0.000s
im_detect: 2156/4024 0.293s 0.000s
im_detect: 2157/4024 0.293s 0.000s
im_detect: 2158/4024 0.293s 0.000s
im_detect: 2159/4024 0.293s 0.000s
im_detect: 2160/4024 0.293s 0.000s
im_detect: 2161/4024 0.293s 0.000s
im_detect: 2162/4024 0.293s 0.000s
im_detect: 2163/4024 0.293s 0.000s
im_detect: 2164/4024 0.293s 0.000s
im_detect: 2165/4024 0.293s 0.000s
im_detect: 2166/4024 0.293s 0.000s
im_detect: 2167/4024 0.293s 0.000s
im_detect: 2168/4024 0.293s 0.000s
im_detect: 2169/4024 0.293s 0.000s
im_detect: 2170/4024 0.293s 0.000s
im_detect: 2171/4024 0.293s 0.000s
im_detect: 2172/4024 0.293s 0.000s
im_detect: 2173/4024 0.293s 0.000s
im_detect: 2174/4024 0.293s 0.000s
im_detect: 2175/4024 0.293s 0.000s
im_detect: 2176/4024 0.293s 0.000s
im_detect: 2177/4024 0.293s 0.000s
im_detect: 2178/4024 0.293s 0.000s
im_detect: 2179/4024 0.293s 0.000s
im_detect: 2180/4024 0.293s 0.000s
im_detect: 2181/4024 0.293s 0.000s
im_detect: 2182/4024 0.293s 0.000s
im_detect: 2183/4024 0.293s 0.000s
im_detect: 2184/4024 0.293s 0.000s
im_detect: 2185/4024 0.293s 0.000s
im_detect: 2186/4024 0.293s 0.000s
im_detect: 2187/4024 0.293s 0.000s
im_detect: 2188/4024 0.293s 0.000s
im_detect: 2189/4024 0.293s 0.000s
im_detect: 2190/4024 0.293s 0.000s
im_detect: 2191/4024 0.293s 0.000s
im_detect: 2192/4024 0.293s 0.000s
im_detect: 2193/4024 0.293s 0.000s
im_detect: 2194/4024 0.293s 0.000s
im_detect: 2195/4024 0.293s 0.000s
im_detect: 2196/4024 0.293s 0.000s
im_detect: 2197/4024 0.293s 0.000s
im_detect: 2198/4024 0.293s 0.000s
im_detect: 2199/4024 0.293s 0.000s
im_detect: 2200/4024 0.293s 0.000s
im_detect: 2201/4024 0.293s 0.000s
im_detect: 2202/4024 0.293s 0.000s
im_detect: 2203/4024 0.293s 0.000s
im_detect: 2204/4024 0.293s 0.000s
im_detect: 2205/4024 0.293s 0.000s
im_detect: 2206/4024 0.293s 0.000s
im_detect: 2207/4024 0.293s 0.000s
im_detect: 2208/4024 0.293s 0.000s
im_detect: 2209/4024 0.293s 0.000s
im_detect: 2210/4024 0.293s 0.000s
im_detect: 2211/4024 0.293s 0.000s
im_detect: 2212/4024 0.293s 0.000s
im_detect: 2213/4024 0.293s 0.000s
im_detect: 2214/4024 0.293s 0.000s
im_detect: 2215/4024 0.293s 0.000s
im_detect: 2216/4024 0.293s 0.000s
im_detect: 2217/4024 0.293s 0.000s
im_detect: 2218/4024 0.293s 0.000s
im_detect: 2219/4024 0.293s 0.000s
im_detect: 2220/4024 0.293s 0.000s
im_detect: 2221/4024 0.293s 0.000s
im_detect: 2222/4024 0.293s 0.000s
im_detect: 2223/4024 0.293s 0.000s
im_detect: 2224/4024 0.293s 0.000s
im_detect: 2225/4024 0.293s 0.000s
im_detect: 2226/4024 0.293s 0.000s
im_detect: 2227/4024 0.293s 0.000s
im_detect: 2228/4024 0.293s 0.000s
im_detect: 2229/4024 0.293s 0.000s
im_detect: 2230/4024 0.293s 0.000s
im_detect: 2231/4024 0.293s 0.000s
im_detect: 2232/4024 0.293s 0.000s
im_detect: 2233/4024 0.293s 0.000s
im_detect: 2234/4024 0.293s 0.000s
im_detect: 2235/4024 0.293s 0.000s
im_detect: 2236/4024 0.293s 0.000s
im_detect: 2237/4024 0.293s 0.000s
im_detect: 2238/4024 0.293s 0.000s
im_detect: 2239/4024 0.293s 0.000s
im_detect: 2240/4024 0.293s 0.000s
im_detect: 2241/4024 0.293s 0.000s
im_detect: 2242/4024 0.293s 0.000s
im_detect: 2243/4024 0.293s 0.000s
im_detect: 2244/4024 0.293s 0.000s
im_detect: 2245/4024 0.293s 0.000s
im_detect: 2246/4024 0.293s 0.000s
im_detect: 2247/4024 0.293s 0.000s
im_detect: 2248/4024 0.293s 0.000s
im_detect: 2249/4024 0.293s 0.000s
im_detect: 2250/4024 0.293s 0.000s
im_detect: 2251/4024 0.293s 0.000s
im_detect: 2252/4024 0.293s 0.000s
im_detect: 2253/4024 0.293s 0.000s
im_detect: 2254/4024 0.293s 0.000s
im_detect: 2255/4024 0.293s 0.000s
im_detect: 2256/4024 0.293s 0.000s
im_detect: 2257/4024 0.293s 0.000s
im_detect: 2258/4024 0.293s 0.000s
im_detect: 2259/4024 0.293s 0.000s
im_detect: 2260/4024 0.293s 0.000s
im_detect: 2261/4024 0.293s 0.000s
im_detect: 2262/4024 0.293s 0.000s
im_detect: 2263/4024 0.293s 0.000s
im_detect: 2264/4024 0.293s 0.000s
im_detect: 2265/4024 0.293s 0.000s
im_detect: 2266/4024 0.293s 0.000s
im_detect: 2267/4024 0.293s 0.000s
im_detect: 2268/4024 0.293s 0.000s
im_detect: 2269/4024 0.293s 0.000s
im_detect: 2270/4024 0.293s 0.000s
im_detect: 2271/4024 0.293s 0.000s
im_detect: 2272/4024 0.293s 0.000s
im_detect: 2273/4024 0.293s 0.000s
im_detect: 2274/4024 0.293s 0.000s
im_detect: 2275/4024 0.293s 0.000s
im_detect: 2276/4024 0.293s 0.000s
im_detect: 2277/4024 0.293s 0.000s
im_detect: 2278/4024 0.293s 0.000s
im_detect: 2279/4024 0.293s 0.000s
im_detect: 2280/4024 0.293s 0.000s
im_detect: 2281/4024 0.293s 0.000s
im_detect: 2282/4024 0.293s 0.000s
im_detect: 2283/4024 0.293s 0.000s
im_detect: 2284/4024 0.293s 0.000s
im_detect: 2285/4024 0.293s 0.000s
im_detect: 2286/4024 0.293s 0.000s
im_detect: 2287/4024 0.293s 0.000s
im_detect: 2288/4024 0.293s 0.000s
im_detect: 2289/4024 0.293s 0.000s
im_detect: 2290/4024 0.293s 0.000s
im_detect: 2291/4024 0.293s 0.000s
im_detect: 2292/4024 0.293s 0.000s
im_detect: 2293/4024 0.293s 0.000s
im_detect: 2294/4024 0.293s 0.000s
im_detect: 2295/4024 0.293s 0.000s
im_detect: 2296/4024 0.293s 0.000s
im_detect: 2297/4024 0.293s 0.000s
im_detect: 2298/4024 0.293s 0.000s
im_detect: 2299/4024 0.293s 0.000s
im_detect: 2300/4024 0.293s 0.000s
im_detect: 2301/4024 0.293s 0.000s
im_detect: 2302/4024 0.293s 0.000s
im_detect: 2303/4024 0.293s 0.000s
im_detect: 2304/4024 0.293s 0.000s
im_detect: 2305/4024 0.293s 0.000s
im_detect: 2306/4024 0.293s 0.000s
im_detect: 2307/4024 0.293s 0.000s
im_detect: 2308/4024 0.293s 0.000s
im_detect: 2309/4024 0.293s 0.000s
im_detect: 2310/4024 0.293s 0.000s
im_detect: 2311/4024 0.293s 0.000s
im_detect: 2312/4024 0.293s 0.000s
im_detect: 2313/4024 0.293s 0.000s
im_detect: 2314/4024 0.293s 0.000s
im_detect: 2315/4024 0.293s 0.000s
im_detect: 2316/4024 0.293s 0.000s
im_detect: 2317/4024 0.293s 0.000s
im_detect: 2318/4024 0.293s 0.000s
im_detect: 2319/4024 0.293s 0.000s
im_detect: 2320/4024 0.293s 0.000s
im_detect: 2321/4024 0.293s 0.000s
im_detect: 2322/4024 0.293s 0.000s
im_detect: 2323/4024 0.293s 0.000s
im_detect: 2324/4024 0.293s 0.000s
im_detect: 2325/4024 0.293s 0.000s
im_detect: 2326/4024 0.293s 0.000s
im_detect: 2327/4024 0.293s 0.000s
im_detect: 2328/4024 0.293s 0.000s
im_detect: 2329/4024 0.293s 0.000s
im_detect: 2330/4024 0.293s 0.000s
im_detect: 2331/4024 0.293s 0.000s
im_detect: 2332/4024 0.293s 0.000s
im_detect: 2333/4024 0.293s 0.000s
im_detect: 2334/4024 0.293s 0.000s
im_detect: 2335/4024 0.293s 0.000s
im_detect: 2336/4024 0.293s 0.000s
im_detect: 2337/4024 0.293s 0.000s
im_detect: 2338/4024 0.293s 0.000s
im_detect: 2339/4024 0.293s 0.000s
im_detect: 2340/4024 0.293s 0.000s
im_detect: 2341/4024 0.293s 0.000s
im_detect: 2342/4024 0.293s 0.000s
im_detect: 2343/4024 0.293s 0.000s
im_detect: 2344/4024 0.292s 0.000s
im_detect: 2345/4024 0.292s 0.000s
im_detect: 2346/4024 0.292s 0.000s
im_detect: 2347/4024 0.292s 0.000s
im_detect: 2348/4024 0.292s 0.000s
im_detect: 2349/4024 0.292s 0.000s
im_detect: 2350/4024 0.292s 0.000s
im_detect: 2351/4024 0.292s 0.000s
im_detect: 2352/4024 0.292s 0.000s
im_detect: 2353/4024 0.292s 0.000s
im_detect: 2354/4024 0.292s 0.000s
im_detect: 2355/4024 0.292s 0.000s
im_detect: 2356/4024 0.292s 0.000s
im_detect: 2357/4024 0.292s 0.000s
im_detect: 2358/4024 0.292s 0.000s
im_detect: 2359/4024 0.292s 0.000s
im_detect: 2360/4024 0.292s 0.000s
im_detect: 2361/4024 0.292s 0.000s
im_detect: 2362/4024 0.292s 0.000s
im_detect: 2363/4024 0.292s 0.000s
im_detect: 2364/4024 0.292s 0.000s
im_detect: 2365/4024 0.292s 0.000s
im_detect: 2366/4024 0.292s 0.000s
im_detect: 2367/4024 0.292s 0.000s
im_detect: 2368/4024 0.292s 0.000s
im_detect: 2369/4024 0.292s 0.000s
im_detect: 2370/4024 0.292s 0.000s
im_detect: 2371/4024 0.292s 0.000s
im_detect: 2372/4024 0.292s 0.000s
im_detect: 2373/4024 0.292s 0.000s
im_detect: 2374/4024 0.292s 0.000s
im_detect: 2375/4024 0.292s 0.000s
im_detect: 2376/4024 0.292s 0.000s
im_detect: 2377/4024 0.292s 0.000s
im_detect: 2378/4024 0.292s 0.000s
im_detect: 2379/4024 0.292s 0.000s
im_detect: 2380/4024 0.292s 0.000s
im_detect: 2381/4024 0.292s 0.000s
im_detect: 2382/4024 0.292s 0.000s
im_detect: 2383/4024 0.292s 0.000s
im_detect: 2384/4024 0.292s 0.000s
im_detect: 2385/4024 0.292s 0.000s
im_detect: 2386/4024 0.292s 0.000s
im_detect: 2387/4024 0.292s 0.000s
im_detect: 2388/4024 0.292s 0.000s
im_detect: 2389/4024 0.292s 0.000s
im_detect: 2390/4024 0.292s 0.000s
im_detect: 2391/4024 0.292s 0.000s
im_detect: 2392/4024 0.292s 0.000s
im_detect: 2393/4024 0.292s 0.000s
im_detect: 2394/4024 0.292s 0.000s
im_detect: 2395/4024 0.292s 0.000s
im_detect: 2396/4024 0.292s 0.000s
im_detect: 2397/4024 0.292s 0.000s
im_detect: 2398/4024 0.292s 0.000s
im_detect: 2399/4024 0.292s 0.000s
im_detect: 2400/4024 0.292s 0.000s
im_detect: 2401/4024 0.292s 0.000s
im_detect: 2402/4024 0.292s 0.000s
im_detect: 2403/4024 0.292s 0.000s
im_detect: 2404/4024 0.292s 0.000s
im_detect: 2405/4024 0.292s 0.000s
im_detect: 2406/4024 0.292s 0.000s
im_detect: 2407/4024 0.292s 0.000s
im_detect: 2408/4024 0.292s 0.000s
im_detect: 2409/4024 0.292s 0.000s
im_detect: 2410/4024 0.292s 0.000s
im_detect: 2411/4024 0.292s 0.000s
im_detect: 2412/4024 0.292s 0.000s
im_detect: 2413/4024 0.292s 0.000s
im_detect: 2414/4024 0.292s 0.000s
im_detect: 2415/4024 0.292s 0.000s
im_detect: 2416/4024 0.292s 0.000s
im_detect: 2417/4024 0.292s 0.000s
im_detect: 2418/4024 0.292s 0.000s
im_detect: 2419/4024 0.292s 0.000s
im_detect: 2420/4024 0.292s 0.000s
im_detect: 2421/4024 0.292s 0.000s
im_detect: 2422/4024 0.292s 0.000s
im_detect: 2423/4024 0.292s 0.000s
im_detect: 2424/4024 0.292s 0.000s
im_detect: 2425/4024 0.292s 0.000s
im_detect: 2426/4024 0.292s 0.000s
im_detect: 2427/4024 0.292s 0.000s
im_detect: 2428/4024 0.292s 0.000s
im_detect: 2429/4024 0.292s 0.000s
im_detect: 2430/4024 0.292s 0.000s
im_detect: 2431/4024 0.292s 0.000s
im_detect: 2432/4024 0.292s 0.000s
im_detect: 2433/4024 0.292s 0.000s
im_detect: 2434/4024 0.292s 0.000s
im_detect: 2435/4024 0.292s 0.000s
im_detect: 2436/4024 0.292s 0.000s
im_detect: 2437/4024 0.292s 0.000s
im_detect: 2438/4024 0.292s 0.000s
im_detect: 2439/4024 0.292s 0.000s
im_detect: 2440/4024 0.292s 0.000s
im_detect: 2441/4024 0.292s 0.000s
im_detect: 2442/4024 0.292s 0.000s
im_detect: 2443/4024 0.292s 0.000s
im_detect: 2444/4024 0.292s 0.000s
im_detect: 2445/4024 0.292s 0.000s
im_detect: 2446/4024 0.292s 0.000s
im_detect: 2447/4024 0.292s 0.000s
im_detect: 2448/4024 0.292s 0.000s
im_detect: 2449/4024 0.292s 0.000s
im_detect: 2450/4024 0.292s 0.000s
im_detect: 2451/4024 0.292s 0.000s
im_detect: 2452/4024 0.292s 0.000s
im_detect: 2453/4024 0.292s 0.000s
im_detect: 2454/4024 0.292s 0.000s
im_detect: 2455/4024 0.292s 0.000s
im_detect: 2456/4024 0.292s 0.000s
im_detect: 2457/4024 0.292s 0.000s
im_detect: 2458/4024 0.292s 0.000s
im_detect: 2459/4024 0.292s 0.000s
im_detect: 2460/4024 0.292s 0.000s
im_detect: 2461/4024 0.292s 0.000s
im_detect: 2462/4024 0.292s 0.000s
im_detect: 2463/4024 0.292s 0.000s
im_detect: 2464/4024 0.292s 0.000s
im_detect: 2465/4024 0.292s 0.000s
im_detect: 2466/4024 0.292s 0.000s
im_detect: 2467/4024 0.292s 0.000s
im_detect: 2468/4024 0.292s 0.000s
im_detect: 2469/4024 0.292s 0.000s
im_detect: 2470/4024 0.292s 0.000s
im_detect: 2471/4024 0.292s 0.000s
im_detect: 2472/4024 0.292s 0.000s
im_detect: 2473/4024 0.292s 0.000s
im_detect: 2474/4024 0.292s 0.000s
im_detect: 2475/4024 0.292s 0.000s
im_detect: 2476/4024 0.292s 0.000s
im_detect: 2477/4024 0.292s 0.000s
im_detect: 2478/4024 0.292s 0.000s
im_detect: 2479/4024 0.292s 0.000s
im_detect: 2480/4024 0.292s 0.000s
im_detect: 2481/4024 0.292s 0.000s
im_detect: 2482/4024 0.292s 0.000s
im_detect: 2483/4024 0.292s 0.000s
im_detect: 2484/4024 0.292s 0.000s
im_detect: 2485/4024 0.292s 0.000s
im_detect: 2486/4024 0.292s 0.000s
im_detect: 2487/4024 0.292s 0.000s
im_detect: 2488/4024 0.292s 0.000s
im_detect: 2489/4024 0.292s 0.000s
im_detect: 2490/4024 0.292s 0.000s
im_detect: 2491/4024 0.292s 0.000s
im_detect: 2492/4024 0.292s 0.000s
im_detect: 2493/4024 0.292s 0.000s
im_detect: 2494/4024 0.292s 0.000s
im_detect: 2495/4024 0.292s 0.000s
im_detect: 2496/4024 0.292s 0.000s
im_detect: 2497/4024 0.292s 0.000s
im_detect: 2498/4024 0.292s 0.000s
im_detect: 2499/4024 0.292s 0.000s
im_detect: 2500/4024 0.292s 0.000s
im_detect: 2501/4024 0.292s 0.000s
im_detect: 2502/4024 0.292s 0.000s
im_detect: 2503/4024 0.292s 0.000s
im_detect: 2504/4024 0.292s 0.000s
im_detect: 2505/4024 0.292s 0.000s
im_detect: 2506/4024 0.292s 0.000s
im_detect: 2507/4024 0.292s 0.000s
im_detect: 2508/4024 0.292s 0.000s
im_detect: 2509/4024 0.292s 0.000s
im_detect: 2510/4024 0.292s 0.000s
im_detect: 2511/4024 0.292s 0.000s
im_detect: 2512/4024 0.292s 0.000s
im_detect: 2513/4024 0.292s 0.000s
im_detect: 2514/4024 0.292s 0.000s
im_detect: 2515/4024 0.292s 0.000s
im_detect: 2516/4024 0.292s 0.000s
im_detect: 2517/4024 0.292s 0.000s
im_detect: 2518/4024 0.292s 0.000s
im_detect: 2519/4024 0.292s 0.000s
im_detect: 2520/4024 0.292s 0.000s
im_detect: 2521/4024 0.292s 0.000s
im_detect: 2522/4024 0.292s 0.000s
im_detect: 2523/4024 0.292s 0.000s
im_detect: 2524/4024 0.292s 0.000s
im_detect: 2525/4024 0.292s 0.000s
im_detect: 2526/4024 0.292s 0.000s
im_detect: 2527/4024 0.292s 0.000s
im_detect: 2528/4024 0.292s 0.000s
im_detect: 2529/4024 0.292s 0.000s
im_detect: 2530/4024 0.292s 0.000s
im_detect: 2531/4024 0.292s 0.000s
im_detect: 2532/4024 0.292s 0.000s
im_detect: 2533/4024 0.292s 0.000s
im_detect: 2534/4024 0.292s 0.000s
im_detect: 2535/4024 0.292s 0.000s
im_detect: 2536/4024 0.292s 0.000s
im_detect: 2537/4024 0.292s 0.000s
im_detect: 2538/4024 0.292s 0.000s
im_detect: 2539/4024 0.292s 0.000s
im_detect: 2540/4024 0.292s 0.000s
im_detect: 2541/4024 0.292s 0.000s
im_detect: 2542/4024 0.292s 0.000s
im_detect: 2543/4024 0.292s 0.000s
im_detect: 2544/4024 0.292s 0.000s
im_detect: 2545/4024 0.292s 0.000s
im_detect: 2546/4024 0.292s 0.000s
im_detect: 2547/4024 0.292s 0.000s
im_detect: 2548/4024 0.292s 0.000s
im_detect: 2549/4024 0.292s 0.000s
im_detect: 2550/4024 0.292s 0.000s
im_detect: 2551/4024 0.292s 0.000s
im_detect: 2552/4024 0.292s 0.000s
im_detect: 2553/4024 0.292s 0.000s
im_detect: 2554/4024 0.292s 0.000s
im_detect: 2555/4024 0.292s 0.000s
im_detect: 2556/4024 0.292s 0.000s
im_detect: 2557/4024 0.292s 0.000s
im_detect: 2558/4024 0.292s 0.000s
im_detect: 2559/4024 0.292s 0.000s
im_detect: 2560/4024 0.292s 0.000s
im_detect: 2561/4024 0.292s 0.000s
im_detect: 2562/4024 0.292s 0.000s
im_detect: 2563/4024 0.292s 0.000s
im_detect: 2564/4024 0.292s 0.000s
im_detect: 2565/4024 0.292s 0.000s
im_detect: 2566/4024 0.292s 0.000s
im_detect: 2567/4024 0.292s 0.000s
im_detect: 2568/4024 0.292s 0.000s
im_detect: 2569/4024 0.292s 0.000s
im_detect: 2570/4024 0.292s 0.000s
im_detect: 2571/4024 0.292s 0.000s
im_detect: 2572/4024 0.292s 0.000s
im_detect: 2573/4024 0.292s 0.000s
im_detect: 2574/4024 0.292s 0.000s
im_detect: 2575/4024 0.292s 0.000s
im_detect: 2576/4024 0.292s 0.000s
im_detect: 2577/4024 0.292s 0.000s
im_detect: 2578/4024 0.292s 0.000s
im_detect: 2579/4024 0.292s 0.000s
im_detect: 2580/4024 0.292s 0.000s
im_detect: 2581/4024 0.292s 0.000s
im_detect: 2582/4024 0.292s 0.000s
im_detect: 2583/4024 0.292s 0.000s
im_detect: 2584/4024 0.292s 0.000s
im_detect: 2585/4024 0.292s 0.000s
im_detect: 2586/4024 0.292s 0.000s
im_detect: 2587/4024 0.292s 0.000s
im_detect: 2588/4024 0.292s 0.000s
im_detect: 2589/4024 0.292s 0.000s
im_detect: 2590/4024 0.292s 0.000s
im_detect: 2591/4024 0.292s 0.000s
im_detect: 2592/4024 0.292s 0.000s
im_detect: 2593/4024 0.292s 0.000s
im_detect: 2594/4024 0.292s 0.000s
im_detect: 2595/4024 0.292s 0.000s
im_detect: 2596/4024 0.292s 0.000s
im_detect: 2597/4024 0.292s 0.000s
im_detect: 2598/4024 0.292s 0.000s
im_detect: 2599/4024 0.292s 0.000s
im_detect: 2600/4024 0.292s 0.000s
im_detect: 2601/4024 0.292s 0.000s
im_detect: 2602/4024 0.292s 0.000s
im_detect: 2603/4024 0.292s 0.000s
im_detect: 2604/4024 0.292s 0.000s
im_detect: 2605/4024 0.292s 0.000s
im_detect: 2606/4024 0.292s 0.000s
im_detect: 2607/4024 0.292s 0.000s
im_detect: 2608/4024 0.292s 0.000s
im_detect: 2609/4024 0.292s 0.000s
im_detect: 2610/4024 0.292s 0.000s
im_detect: 2611/4024 0.292s 0.000s
im_detect: 2612/4024 0.292s 0.000s
im_detect: 2613/4024 0.292s 0.000s
im_detect: 2614/4024 0.292s 0.000s
im_detect: 2615/4024 0.292s 0.000s
im_detect: 2616/4024 0.292s 0.000s
im_detect: 2617/4024 0.292s 0.000s
im_detect: 2618/4024 0.292s 0.000s
im_detect: 2619/4024 0.292s 0.000s
im_detect: 2620/4024 0.292s 0.000s
im_detect: 2621/4024 0.292s 0.000s
im_detect: 2622/4024 0.292s 0.000s
im_detect: 2623/4024 0.292s 0.000s
im_detect: 2624/4024 0.292s 0.000s
im_detect: 2625/4024 0.292s 0.000s
im_detect: 2626/4024 0.292s 0.000s
im_detect: 2627/4024 0.292s 0.000s
im_detect: 2628/4024 0.292s 0.000s
im_detect: 2629/4024 0.292s 0.000s
im_detect: 2630/4024 0.292s 0.000s
im_detect: 2631/4024 0.292s 0.000s
im_detect: 2632/4024 0.292s 0.000s
im_detect: 2633/4024 0.292s 0.000s
im_detect: 2634/4024 0.292s 0.000s
im_detect: 2635/4024 0.292s 0.000s
im_detect: 2636/4024 0.292s 0.000s
im_detect: 2637/4024 0.292s 0.000s
im_detect: 2638/4024 0.292s 0.000s
im_detect: 2639/4024 0.292s 0.000s
im_detect: 2640/4024 0.292s 0.000s
im_detect: 2641/4024 0.292s 0.000s
im_detect: 2642/4024 0.292s 0.000s
im_detect: 2643/4024 0.292s 0.000s
im_detect: 2644/4024 0.292s 0.000s
im_detect: 2645/4024 0.292s 0.000s
im_detect: 2646/4024 0.292s 0.000s
im_detect: 2647/4024 0.292s 0.000s
im_detect: 2648/4024 0.292s 0.000s
im_detect: 2649/4024 0.292s 0.000s
im_detect: 2650/4024 0.292s 0.000s
im_detect: 2651/4024 0.292s 0.000s
im_detect: 2652/4024 0.292s 0.000s
im_detect: 2653/4024 0.292s 0.000s
im_detect: 2654/4024 0.292s 0.000s
im_detect: 2655/4024 0.292s 0.000s
im_detect: 2656/4024 0.292s 0.000s
im_detect: 2657/4024 0.292s 0.000s
im_detect: 2658/4024 0.292s 0.000s
im_detect: 2659/4024 0.292s 0.000s
im_detect: 2660/4024 0.292s 0.000s
im_detect: 2661/4024 0.292s 0.000s
im_detect: 2662/4024 0.292s 0.000s
im_detect: 2663/4024 0.292s 0.000s
im_detect: 2664/4024 0.292s 0.000s
im_detect: 2665/4024 0.292s 0.000s
im_detect: 2666/4024 0.292s 0.000s
im_detect: 2667/4024 0.292s 0.000s
im_detect: 2668/4024 0.292s 0.000s
im_detect: 2669/4024 0.292s 0.000s
im_detect: 2670/4024 0.292s 0.000s
im_detect: 2671/4024 0.292s 0.000s
im_detect: 2672/4024 0.292s 0.000s
im_detect: 2673/4024 0.292s 0.000s
im_detect: 2674/4024 0.292s 0.000s
im_detect: 2675/4024 0.292s 0.000s
im_detect: 2676/4024 0.292s 0.000s
im_detect: 2677/4024 0.292s 0.000s
im_detect: 2678/4024 0.292s 0.000s
im_detect: 2679/4024 0.292s 0.000s
im_detect: 2680/4024 0.292s 0.000s
im_detect: 2681/4024 0.292s 0.000s
im_detect: 2682/4024 0.292s 0.000s
im_detect: 2683/4024 0.292s 0.000s
im_detect: 2684/4024 0.292s 0.000s
im_detect: 2685/4024 0.292s 0.000s
im_detect: 2686/4024 0.292s 0.000s
im_detect: 2687/4024 0.292s 0.000s
im_detect: 2688/4024 0.292s 0.000s
im_detect: 2689/4024 0.292s 0.000s
im_detect: 2690/4024 0.292s 0.000s
im_detect: 2691/4024 0.292s 0.000s
im_detect: 2692/4024 0.292s 0.000s
im_detect: 2693/4024 0.292s 0.000s
im_detect: 2694/4024 0.292s 0.000s
im_detect: 2695/4024 0.292s 0.000s
im_detect: 2696/4024 0.292s 0.000s
im_detect: 2697/4024 0.292s 0.000s
im_detect: 2698/4024 0.292s 0.000s
im_detect: 2699/4024 0.292s 0.000s
im_detect: 2700/4024 0.292s 0.000s
im_detect: 2701/4024 0.292s 0.000s
im_detect: 2702/4024 0.292s 0.000s
im_detect: 2703/4024 0.292s 0.000s
im_detect: 2704/4024 0.292s 0.000s
im_detect: 2705/4024 0.292s 0.000s
im_detect: 2706/4024 0.292s 0.000s
im_detect: 2707/4024 0.292s 0.000s
im_detect: 2708/4024 0.292s 0.000s
im_detect: 2709/4024 0.292s 0.000s
im_detect: 2710/4024 0.292s 0.000s
im_detect: 2711/4024 0.292s 0.000s
im_detect: 2712/4024 0.292s 0.000s
im_detect: 2713/4024 0.292s 0.000s
im_detect: 2714/4024 0.292s 0.000s
im_detect: 2715/4024 0.292s 0.000s
im_detect: 2716/4024 0.292s 0.000s
im_detect: 2717/4024 0.292s 0.000s
im_detect: 2718/4024 0.292s 0.000s
im_detect: 2719/4024 0.292s 0.000s
im_detect: 2720/4024 0.292s 0.000s
im_detect: 2721/4024 0.292s 0.000s
im_detect: 2722/4024 0.292s 0.000s
im_detect: 2723/4024 0.292s 0.000s
im_detect: 2724/4024 0.292s 0.000s
im_detect: 2725/4024 0.292s 0.000s
im_detect: 2726/4024 0.292s 0.000s
im_detect: 2727/4024 0.292s 0.000s
im_detect: 2728/4024 0.292s 0.000s
im_detect: 2729/4024 0.292s 0.000s
im_detect: 2730/4024 0.292s 0.000s
im_detect: 2731/4024 0.292s 0.000s
im_detect: 2732/4024 0.292s 0.000s
im_detect: 2733/4024 0.292s 0.000s
im_detect: 2734/4024 0.292s 0.000s
im_detect: 2735/4024 0.292s 0.000s
im_detect: 2736/4024 0.292s 0.000s
im_detect: 2737/4024 0.292s 0.000s
im_detect: 2738/4024 0.292s 0.000s
im_detect: 2739/4024 0.292s 0.000s
im_detect: 2740/4024 0.292s 0.000s
im_detect: 2741/4024 0.292s 0.000s
im_detect: 2742/4024 0.292s 0.000s
im_detect: 2743/4024 0.292s 0.000s
im_detect: 2744/4024 0.292s 0.000s
im_detect: 2745/4024 0.292s 0.000s
im_detect: 2746/4024 0.292s 0.000s
im_detect: 2747/4024 0.292s 0.000s
im_detect: 2748/4024 0.292s 0.000s
im_detect: 2749/4024 0.292s 0.000s
im_detect: 2750/4024 0.292s 0.000s
im_detect: 2751/4024 0.292s 0.000s
im_detect: 2752/4024 0.292s 0.000s
im_detect: 2753/4024 0.292s 0.000s
im_detect: 2754/4024 0.292s 0.000s
im_detect: 2755/4024 0.292s 0.000s
im_detect: 2756/4024 0.292s 0.000s
im_detect: 2757/4024 0.292s 0.000s
im_detect: 2758/4024 0.292s 0.000s
im_detect: 2759/4024 0.292s 0.000s
im_detect: 2760/4024 0.292s 0.000s
im_detect: 2761/4024 0.292s 0.000s
im_detect: 2762/4024 0.292s 0.000s
im_detect: 2763/4024 0.292s 0.000s
im_detect: 2764/4024 0.292s 0.000s
im_detect: 2765/4024 0.292s 0.000s
im_detect: 2766/4024 0.292s 0.000s
im_detect: 2767/4024 0.292s 0.000s
im_detect: 2768/4024 0.292s 0.000s
im_detect: 2769/4024 0.292s 0.000s
im_detect: 2770/4024 0.292s 0.000s
im_detect: 2771/4024 0.292s 0.000s
im_detect: 2772/4024 0.292s 0.000s
im_detect: 2773/4024 0.292s 0.000s
im_detect: 2774/4024 0.292s 0.000s
im_detect: 2775/4024 0.292s 0.000s
im_detect: 2776/4024 0.292s 0.000s
im_detect: 2777/4024 0.292s 0.000s
im_detect: 2778/4024 0.292s 0.000s
im_detect: 2779/4024 0.292s 0.000s
im_detect: 2780/4024 0.292s 0.000s
im_detect: 2781/4024 0.292s 0.000s
im_detect: 2782/4024 0.292s 0.000s
im_detect: 2783/4024 0.292s 0.000s
im_detect: 2784/4024 0.292s 0.000s
im_detect: 2785/4024 0.292s 0.000s
im_detect: 2786/4024 0.292s 0.000s
im_detect: 2787/4024 0.292s 0.000s
im_detect: 2788/4024 0.292s 0.000s
im_detect: 2789/4024 0.292s 0.000s
im_detect: 2790/4024 0.292s 0.000s
im_detect: 2791/4024 0.292s 0.000s
im_detect: 2792/4024 0.292s 0.000s
im_detect: 2793/4024 0.292s 0.000s
im_detect: 2794/4024 0.292s 0.000s
im_detect: 2795/4024 0.292s 0.000s
im_detect: 2796/4024 0.292s 0.000s
im_detect: 2797/4024 0.292s 0.000s
im_detect: 2798/4024 0.292s 0.000s
im_detect: 2799/4024 0.292s 0.000s
im_detect: 2800/4024 0.292s 0.000s
im_detect: 2801/4024 0.292s 0.000s
im_detect: 2802/4024 0.292s 0.000s
im_detect: 2803/4024 0.292s 0.000s
im_detect: 2804/4024 0.292s 0.000s
im_detect: 2805/4024 0.292s 0.000s
im_detect: 2806/4024 0.292s 0.000s
im_detect: 2807/4024 0.292s 0.000s
im_detect: 2808/4024 0.292s 0.000s
im_detect: 2809/4024 0.292s 0.000s
im_detect: 2810/4024 0.292s 0.000s
im_detect: 2811/4024 0.292s 0.000s
im_detect: 2812/4024 0.292s 0.000s
im_detect: 2813/4024 0.292s 0.000s
im_detect: 2814/4024 0.292s 0.000s
im_detect: 2815/4024 0.292s 0.000s
im_detect: 2816/4024 0.292s 0.000s
im_detect: 2817/4024 0.292s 0.000s
im_detect: 2818/4024 0.292s 0.000s
im_detect: 2819/4024 0.292s 0.000s
im_detect: 2820/4024 0.292s 0.000s
im_detect: 2821/4024 0.292s 0.000s
im_detect: 2822/4024 0.292s 0.000s
im_detect: 2823/4024 0.292s 0.000s
im_detect: 2824/4024 0.292s 0.000s
im_detect: 2825/4024 0.292s 0.000s
im_detect: 2826/4024 0.292s 0.000s
im_detect: 2827/4024 0.292s 0.000s
im_detect: 2828/4024 0.292s 0.000s
im_detect: 2829/4024 0.292s 0.000s
im_detect: 2830/4024 0.292s 0.000s
im_detect: 2831/4024 0.292s 0.000s
im_detect: 2832/4024 0.292s 0.000s
im_detect: 2833/4024 0.292s 0.000s
im_detect: 2834/4024 0.292s 0.000s
im_detect: 2835/4024 0.292s 0.000s
im_detect: 2836/4024 0.292s 0.000s
im_detect: 2837/4024 0.292s 0.000s
im_detect: 2838/4024 0.292s 0.000s
im_detect: 2839/4024 0.292s 0.000s
im_detect: 2840/4024 0.292s 0.000s
im_detect: 2841/4024 0.292s 0.000s
im_detect: 2842/4024 0.292s 0.000s
im_detect: 2843/4024 0.292s 0.000s
im_detect: 2844/4024 0.292s 0.000s
im_detect: 2845/4024 0.292s 0.000s
im_detect: 2846/4024 0.292s 0.000s
im_detect: 2847/4024 0.292s 0.000s
im_detect: 2848/4024 0.292s 0.000s
im_detect: 2849/4024 0.292s 0.000s
im_detect: 2850/4024 0.292s 0.000s
im_detect: 2851/4024 0.292s 0.000s
im_detect: 2852/4024 0.292s 0.000s
im_detect: 2853/4024 0.292s 0.000s
im_detect: 2854/4024 0.292s 0.000s
im_detect: 2855/4024 0.292s 0.000s
im_detect: 2856/4024 0.292s 0.000s
im_detect: 2857/4024 0.292s 0.000s
im_detect: 2858/4024 0.292s 0.000s
im_detect: 2859/4024 0.292s 0.000s
im_detect: 2860/4024 0.292s 0.000s
im_detect: 2861/4024 0.292s 0.000s
im_detect: 2862/4024 0.292s 0.000s
im_detect: 2863/4024 0.292s 0.000s
im_detect: 2864/4024 0.292s 0.000s
im_detect: 2865/4024 0.292s 0.000s
im_detect: 2866/4024 0.292s 0.000s
im_detect: 2867/4024 0.292s 0.000s
im_detect: 2868/4024 0.292s 0.000s
im_detect: 2869/4024 0.292s 0.000s
im_detect: 2870/4024 0.292s 0.000s
im_detect: 2871/4024 0.292s 0.000s
im_detect: 2872/4024 0.292s 0.000s
im_detect: 2873/4024 0.292s 0.000s
im_detect: 2874/4024 0.292s 0.000s
im_detect: 2875/4024 0.292s 0.000s
im_detect: 2876/4024 0.292s 0.000s
im_detect: 2877/4024 0.292s 0.000s
im_detect: 2878/4024 0.292s 0.000s
im_detect: 2879/4024 0.292s 0.000s
im_detect: 2880/4024 0.292s 0.000s
im_detect: 2881/4024 0.292s 0.000s
im_detect: 2882/4024 0.292s 0.000s
im_detect: 2883/4024 0.292s 0.000s
im_detect: 2884/4024 0.292s 0.000s
im_detect: 2885/4024 0.292s 0.000s
im_detect: 2886/4024 0.292s 0.000s
im_detect: 2887/4024 0.292s 0.000s
im_detect: 2888/4024 0.292s 0.000s
im_detect: 2889/4024 0.292s 0.000s
im_detect: 2890/4024 0.292s 0.000s
im_detect: 2891/4024 0.292s 0.000s
im_detect: 2892/4024 0.292s 0.000s
im_detect: 2893/4024 0.292s 0.000s
im_detect: 2894/4024 0.292s 0.000s
im_detect: 2895/4024 0.292s 0.000s
im_detect: 2896/4024 0.292s 0.000s
im_detect: 2897/4024 0.292s 0.000s
im_detect: 2898/4024 0.291s 0.000s
im_detect: 2899/4024 0.291s 0.000s
im_detect: 2900/4024 0.291s 0.000s
im_detect: 2901/4024 0.291s 0.000s
im_detect: 2902/4024 0.291s 0.000s
im_detect: 2903/4024 0.291s 0.000s
im_detect: 2904/4024 0.291s 0.000s
im_detect: 2905/4024 0.291s 0.000s
im_detect: 2906/4024 0.291s 0.000s
im_detect: 2907/4024 0.291s 0.000s
im_detect: 2908/4024 0.291s 0.000s
im_detect: 2909/4024 0.291s 0.000s
im_detect: 2910/4024 0.291s 0.000s
im_detect: 2911/4024 0.291s 0.000s
im_detect: 2912/4024 0.291s 0.000s
im_detect: 2913/4024 0.291s 0.000s
im_detect: 2914/4024 0.291s 0.000s
im_detect: 2915/4024 0.291s 0.000s
im_detect: 2916/4024 0.291s 0.000s
im_detect: 2917/4024 0.291s 0.000s
im_detect: 2918/4024 0.291s 0.000s
im_detect: 2919/4024 0.291s 0.000s
im_detect: 2920/4024 0.291s 0.000s
im_detect: 2921/4024 0.291s 0.000s
im_detect: 2922/4024 0.291s 0.000s
im_detect: 2923/4024 0.291s 0.000s
im_detect: 2924/4024 0.291s 0.000s
im_detect: 2925/4024 0.291s 0.000s
im_detect: 2926/4024 0.291s 0.000s
im_detect: 2927/4024 0.291s 0.000s
im_detect: 2928/4024 0.291s 0.000s
im_detect: 2929/4024 0.291s 0.000s
im_detect: 2930/4024 0.291s 0.000s
im_detect: 2931/4024 0.291s 0.000s
im_detect: 2932/4024 0.291s 0.000s
im_detect: 2933/4024 0.291s 0.000s
im_detect: 2934/4024 0.291s 0.000s
im_detect: 2935/4024 0.291s 0.000s
im_detect: 2936/4024 0.291s 0.000s
im_detect: 2937/4024 0.291s 0.000s
im_detect: 2938/4024 0.291s 0.000s
im_detect: 2939/4024 0.291s 0.000s
im_detect: 2940/4024 0.291s 0.000s
im_detect: 2941/4024 0.291s 0.000s
im_detect: 2942/4024 0.291s 0.000s
im_detect: 2943/4024 0.291s 0.000s
im_detect: 2944/4024 0.291s 0.000s
im_detect: 2945/4024 0.291s 0.000s
im_detect: 2946/4024 0.291s 0.000s
im_detect: 2947/4024 0.291s 0.000s
im_detect: 2948/4024 0.291s 0.000s
im_detect: 2949/4024 0.291s 0.000s
im_detect: 2950/4024 0.291s 0.000s
im_detect: 2951/4024 0.291s 0.000s
im_detect: 2952/4024 0.291s 0.000s
im_detect: 2953/4024 0.291s 0.000s
im_detect: 2954/4024 0.291s 0.000s
im_detect: 2955/4024 0.291s 0.000s
im_detect: 2956/4024 0.291s 0.000s
im_detect: 2957/4024 0.291s 0.000s
im_detect: 2958/4024 0.291s 0.000s
im_detect: 2959/4024 0.291s 0.000s
im_detect: 2960/4024 0.291s 0.000s
im_detect: 2961/4024 0.291s 0.000s
im_detect: 2962/4024 0.291s 0.000s
im_detect: 2963/4024 0.291s 0.000s
im_detect: 2964/4024 0.291s 0.000s
im_detect: 2965/4024 0.291s 0.000s
im_detect: 2966/4024 0.291s 0.000s
im_detect: 2967/4024 0.291s 0.000s
im_detect: 2968/4024 0.291s 0.000s
im_detect: 2969/4024 0.291s 0.000s
im_detect: 2970/4024 0.291s 0.000s
im_detect: 2971/4024 0.291s 0.000s
im_detect: 2972/4024 0.291s 0.000s
im_detect: 2973/4024 0.291s 0.000s
im_detect: 2974/4024 0.291s 0.000s
im_detect: 2975/4024 0.291s 0.000s
im_detect: 2976/4024 0.291s 0.000s
im_detect: 2977/4024 0.291s 0.000s
im_detect: 2978/4024 0.291s 0.000s
im_detect: 2979/4024 0.291s 0.000s
im_detect: 2980/4024 0.291s 0.000s
im_detect: 2981/4024 0.291s 0.000s
im_detect: 2982/4024 0.291s 0.000s
im_detect: 2983/4024 0.291s 0.000s
im_detect: 2984/4024 0.291s 0.000s
im_detect: 2985/4024 0.291s 0.000s
im_detect: 2986/4024 0.291s 0.000s
im_detect: 2987/4024 0.291s 0.000s
im_detect: 2988/4024 0.291s 0.000s
im_detect: 2989/4024 0.291s 0.000s
im_detect: 2990/4024 0.291s 0.000s
im_detect: 2991/4024 0.291s 0.000s
im_detect: 2992/4024 0.291s 0.000s
im_detect: 2993/4024 0.291s 0.000s
im_detect: 2994/4024 0.291s 0.000s
im_detect: 2995/4024 0.291s 0.000s
im_detect: 2996/4024 0.291s 0.000s
im_detect: 2997/4024 0.291s 0.000s
im_detect: 2998/4024 0.291s 0.000s
im_detect: 2999/4024 0.291s 0.000s
im_detect: 3000/4024 0.291s 0.000s
im_detect: 3001/4024 0.291s 0.000s
im_detect: 3002/4024 0.291s 0.000s
im_detect: 3003/4024 0.291s 0.000s
im_detect: 3004/4024 0.291s 0.000s
im_detect: 3005/4024 0.291s 0.000s
im_detect: 3006/4024 0.291s 0.000s
im_detect: 3007/4024 0.291s 0.000s
im_detect: 3008/4024 0.291s 0.000s
im_detect: 3009/4024 0.291s 0.000s
im_detect: 3010/4024 0.291s 0.000s
im_detect: 3011/4024 0.291s 0.000s
im_detect: 3012/4024 0.291s 0.000s
im_detect: 3013/4024 0.291s 0.000s
im_detect: 3014/4024 0.291s 0.000s
im_detect: 3015/4024 0.291s 0.000s
im_detect: 3016/4024 0.291s 0.000s
im_detect: 3017/4024 0.291s 0.000s
im_detect: 3018/4024 0.291s 0.000s
im_detect: 3019/4024 0.291s 0.000s
im_detect: 3020/4024 0.291s 0.000s
im_detect: 3021/4024 0.291s 0.000s
im_detect: 3022/4024 0.291s 0.000s
im_detect: 3023/4024 0.291s 0.000s
im_detect: 3024/4024 0.291s 0.000s
im_detect: 3025/4024 0.291s 0.000s
im_detect: 3026/4024 0.291s 0.000s
im_detect: 3027/4024 0.291s 0.000s
im_detect: 3028/4024 0.291s 0.000s
im_detect: 3029/4024 0.291s 0.000s
im_detect: 3030/4024 0.291s 0.000s
im_detect: 3031/4024 0.291s 0.000s
im_detect: 3032/4024 0.291s 0.000s
im_detect: 3033/4024 0.291s 0.000s
im_detect: 3034/4024 0.291s 0.000s
im_detect: 3035/4024 0.291s 0.000s
im_detect: 3036/4024 0.291s 0.000s
im_detect: 3037/4024 0.291s 0.000s
im_detect: 3038/4024 0.291s 0.000s
im_detect: 3039/4024 0.291s 0.000s
im_detect: 3040/4024 0.291s 0.000s
im_detect: 3041/4024 0.291s 0.000s
im_detect: 3042/4024 0.291s 0.000s
im_detect: 3043/4024 0.291s 0.000s
im_detect: 3044/4024 0.291s 0.000s
im_detect: 3045/4024 0.291s 0.000s
im_detect: 3046/4024 0.291s 0.000s
im_detect: 3047/4024 0.291s 0.000s
im_detect: 3048/4024 0.291s 0.000s
im_detect: 3049/4024 0.291s 0.000s
im_detect: 3050/4024 0.291s 0.000s
im_detect: 3051/4024 0.291s 0.000s
im_detect: 3052/4024 0.291s 0.000s
im_detect: 3053/4024 0.291s 0.000s
im_detect: 3054/4024 0.291s 0.000s
im_detect: 3055/4024 0.291s 0.000s
im_detect: 3056/4024 0.291s 0.000s
im_detect: 3057/4024 0.291s 0.000s
im_detect: 3058/4024 0.291s 0.000s
im_detect: 3059/4024 0.291s 0.000s
im_detect: 3060/4024 0.291s 0.000s
im_detect: 3061/4024 0.291s 0.000s
im_detect: 3062/4024 0.291s 0.000s
im_detect: 3063/4024 0.291s 0.000s
im_detect: 3064/4024 0.291s 0.000s
im_detect: 3065/4024 0.291s 0.000s
im_detect: 3066/4024 0.291s 0.000s
im_detect: 3067/4024 0.291s 0.000s
im_detect: 3068/4024 0.291s 0.000s
im_detect: 3069/4024 0.291s 0.000s
im_detect: 3070/4024 0.291s 0.000s
im_detect: 3071/4024 0.291s 0.000s
im_detect: 3072/4024 0.291s 0.000s
im_detect: 3073/4024 0.291s 0.000s
im_detect: 3074/4024 0.291s 0.000s
im_detect: 3075/4024 0.291s 0.000s
im_detect: 3076/4024 0.291s 0.000s
im_detect: 3077/4024 0.291s 0.000s
im_detect: 3078/4024 0.291s 0.000s
im_detect: 3079/4024 0.291s 0.000s
im_detect: 3080/4024 0.291s 0.000s
im_detect: 3081/4024 0.291s 0.000s
im_detect: 3082/4024 0.291s 0.000s
im_detect: 3083/4024 0.291s 0.000s
im_detect: 3084/4024 0.291s 0.000s
im_detect: 3085/4024 0.291s 0.000s
im_detect: 3086/4024 0.291s 0.000s
im_detect: 3087/4024 0.291s 0.000s
im_detect: 3088/4024 0.291s 0.000s
im_detect: 3089/4024 0.291s 0.000s
im_detect: 3090/4024 0.291s 0.000s
im_detect: 3091/4024 0.291s 0.000s
im_detect: 3092/4024 0.291s 0.000s
im_detect: 3093/4024 0.291s 0.000s
im_detect: 3094/4024 0.291s 0.000s
im_detect: 3095/4024 0.291s 0.000s
im_detect: 3096/4024 0.291s 0.000s
im_detect: 3097/4024 0.291s 0.000s
im_detect: 3098/4024 0.291s 0.000s
im_detect: 3099/4024 0.291s 0.000s
im_detect: 3100/4024 0.291s 0.000s
im_detect: 3101/4024 0.291s 0.000s
im_detect: 3102/4024 0.291s 0.000s
im_detect: 3103/4024 0.291s 0.000s
im_detect: 3104/4024 0.291s 0.000s
im_detect: 3105/4024 0.291s 0.000s
im_detect: 3106/4024 0.291s 0.000s
im_detect: 3107/4024 0.291s 0.000s
im_detect: 3108/4024 0.291s 0.000s
im_detect: 3109/4024 0.291s 0.000s
im_detect: 3110/4024 0.291s 0.000s
im_detect: 3111/4024 0.291s 0.000s
im_detect: 3112/4024 0.291s 0.000s
im_detect: 3113/4024 0.291s 0.000s
im_detect: 3114/4024 0.291s 0.000s
im_detect: 3115/4024 0.291s 0.000s
im_detect: 3116/4024 0.291s 0.000s
im_detect: 3117/4024 0.291s 0.000s
im_detect: 3118/4024 0.291s 0.000s
im_detect: 3119/4024 0.291s 0.000s
im_detect: 3120/4024 0.291s 0.000s
im_detect: 3121/4024 0.291s 0.000s
im_detect: 3122/4024 0.291s 0.000s
im_detect: 3123/4024 0.291s 0.000s
im_detect: 3124/4024 0.291s 0.000s
im_detect: 3125/4024 0.291s 0.000s
im_detect: 3126/4024 0.291s 0.000s
im_detect: 3127/4024 0.291s 0.000s
im_detect: 3128/4024 0.291s 0.000s
im_detect: 3129/4024 0.291s 0.000s
im_detect: 3130/4024 0.291s 0.000s
im_detect: 3131/4024 0.291s 0.000s
im_detect: 3132/4024 0.291s 0.000s
im_detect: 3133/4024 0.291s 0.000s
im_detect: 3134/4024 0.291s 0.000s
im_detect: 3135/4024 0.291s 0.000s
im_detect: 3136/4024 0.291s 0.000s
im_detect: 3137/4024 0.291s 0.000s
im_detect: 3138/4024 0.291s 0.000s
im_detect: 3139/4024 0.291s 0.000s
im_detect: 3140/4024 0.291s 0.000s
im_detect: 3141/4024 0.291s 0.000s
im_detect: 3142/4024 0.291s 0.000s
im_detect: 3143/4024 0.291s 0.000s
im_detect: 3144/4024 0.291s 0.000s
im_detect: 3145/4024 0.291s 0.000s
im_detect: 3146/4024 0.291s 0.000s
im_detect: 3147/4024 0.291s 0.000s
im_detect: 3148/4024 0.291s 0.000s
im_detect: 3149/4024 0.291s 0.000s
im_detect: 3150/4024 0.291s 0.000s
im_detect: 3151/4024 0.291s 0.000s
im_detect: 3152/4024 0.291s 0.000s
im_detect: 3153/4024 0.291s 0.000s
im_detect: 3154/4024 0.291s 0.000s
im_detect: 3155/4024 0.291s 0.000s
im_detect: 3156/4024 0.291s 0.000s
im_detect: 3157/4024 0.291s 0.000s
im_detect: 3158/4024 0.291s 0.000s
im_detect: 3159/4024 0.291s 0.000s
im_detect: 3160/4024 0.291s 0.000s
im_detect: 3161/4024 0.291s 0.000s
im_detect: 3162/4024 0.291s 0.000s
im_detect: 3163/4024 0.291s 0.000s
im_detect: 3164/4024 0.291s 0.000s
im_detect: 3165/4024 0.291s 0.000s
im_detect: 3166/4024 0.291s 0.000s
im_detect: 3167/4024 0.291s 0.000s
im_detect: 3168/4024 0.291s 0.000s
im_detect: 3169/4024 0.291s 0.000s
im_detect: 3170/4024 0.291s 0.000s
im_detect: 3171/4024 0.291s 0.000s
im_detect: 3172/4024 0.291s 0.000s
im_detect: 3173/4024 0.291s 0.000s
im_detect: 3174/4024 0.291s 0.000s
im_detect: 3175/4024 0.291s 0.000s
im_detect: 3176/4024 0.291s 0.000s
im_detect: 3177/4024 0.291s 0.000s
im_detect: 3178/4024 0.291s 0.000s
im_detect: 3179/4024 0.291s 0.000s
im_detect: 3180/4024 0.291s 0.000s
im_detect: 3181/4024 0.291s 0.000s
im_detect: 3182/4024 0.291s 0.000s
im_detect: 3183/4024 0.291s 0.000s
im_detect: 3184/4024 0.291s 0.000s
im_detect: 3185/4024 0.291s 0.000s
im_detect: 3186/4024 0.291s 0.000s
im_detect: 3187/4024 0.291s 0.000s
im_detect: 3188/4024 0.291s 0.000s
im_detect: 3189/4024 0.291s 0.000s
im_detect: 3190/4024 0.291s 0.000s
im_detect: 3191/4024 0.291s 0.000s
im_detect: 3192/4024 0.291s 0.000s
im_detect: 3193/4024 0.291s 0.000s
im_detect: 3194/4024 0.291s 0.000s
im_detect: 3195/4024 0.291s 0.000s
im_detect: 3196/4024 0.291s 0.000s
im_detect: 3197/4024 0.291s 0.000s
im_detect: 3198/4024 0.291s 0.000s
im_detect: 3199/4024 0.291s 0.000s
im_detect: 3200/4024 0.291s 0.000s
im_detect: 3201/4024 0.291s 0.000s
im_detect: 3202/4024 0.291s 0.000s
im_detect: 3203/4024 0.291s 0.000s
im_detect: 3204/4024 0.291s 0.000s
im_detect: 3205/4024 0.291s 0.000s
im_detect: 3206/4024 0.291s 0.000s
im_detect: 3207/4024 0.291s 0.000s
im_detect: 3208/4024 0.291s 0.000s
im_detect: 3209/4024 0.291s 0.000s
im_detect: 3210/4024 0.291s 0.000s
im_detect: 3211/4024 0.291s 0.000s
im_detect: 3212/4024 0.291s 0.000s
im_detect: 3213/4024 0.291s 0.000s
im_detect: 3214/4024 0.291s 0.000s
im_detect: 3215/4024 0.291s 0.000s
im_detect: 3216/4024 0.291s 0.000s
im_detect: 3217/4024 0.291s 0.000s
im_detect: 3218/4024 0.291s 0.000s
im_detect: 3219/4024 0.291s 0.000s
im_detect: 3220/4024 0.291s 0.000s
im_detect: 3221/4024 0.291s 0.000s
im_detect: 3222/4024 0.291s 0.000s
im_detect: 3223/4024 0.291s 0.000s
im_detect: 3224/4024 0.291s 0.000s
im_detect: 3225/4024 0.291s 0.000s
im_detect: 3226/4024 0.291s 0.000s
im_detect: 3227/4024 0.291s 0.000s
im_detect: 3228/4024 0.291s 0.000s
im_detect: 3229/4024 0.291s 0.000s
im_detect: 3230/4024 0.291s 0.000s
im_detect: 3231/4024 0.291s 0.000s
im_detect: 3232/4024 0.291s 0.000s
im_detect: 3233/4024 0.291s 0.000s
im_detect: 3234/4024 0.291s 0.000s
im_detect: 3235/4024 0.291s 0.000s
im_detect: 3236/4024 0.291s 0.000s
im_detect: 3237/4024 0.291s 0.000s
im_detect: 3238/4024 0.291s 0.000s
im_detect: 3239/4024 0.291s 0.000s
im_detect: 3240/4024 0.291s 0.000s
im_detect: 3241/4024 0.291s 0.000s
im_detect: 3242/4024 0.291s 0.000s
im_detect: 3243/4024 0.291s 0.000s
im_detect: 3244/4024 0.291s 0.000s
im_detect: 3245/4024 0.291s 0.000s
im_detect: 3246/4024 0.291s 0.000s
im_detect: 3247/4024 0.291s 0.000s
im_detect: 3248/4024 0.291s 0.000s
im_detect: 3249/4024 0.291s 0.000s
im_detect: 3250/4024 0.291s 0.000s
im_detect: 3251/4024 0.291s 0.000s
im_detect: 3252/4024 0.291s 0.000s
im_detect: 3253/4024 0.291s 0.000s
im_detect: 3254/4024 0.291s 0.000s
im_detect: 3255/4024 0.291s 0.000s
im_detect: 3256/4024 0.291s 0.000s
im_detect: 3257/4024 0.291s 0.000s
im_detect: 3258/4024 0.291s 0.000s
im_detect: 3259/4024 0.291s 0.000s
im_detect: 3260/4024 0.291s 0.000s
im_detect: 3261/4024 0.291s 0.000s
im_detect: 3262/4024 0.291s 0.000s
im_detect: 3263/4024 0.291s 0.000s
im_detect: 3264/4024 0.291s 0.000s
im_detect: 3265/4024 0.291s 0.000s
im_detect: 3266/4024 0.291s 0.000s
im_detect: 3267/4024 0.291s 0.000s
im_detect: 3268/4024 0.291s 0.000s
im_detect: 3269/4024 0.291s 0.000s
im_detect: 3270/4024 0.291s 0.000s
im_detect: 3271/4024 0.291s 0.000s
im_detect: 3272/4024 0.291s 0.000s
im_detect: 3273/4024 0.291s 0.000s
im_detect: 3274/4024 0.291s 0.000s
im_detect: 3275/4024 0.291s 0.000s
im_detect: 3276/4024 0.291s 0.000s
im_detect: 3277/4024 0.291s 0.000s
im_detect: 3278/4024 0.291s 0.000s
im_detect: 3279/4024 0.291s 0.000s
im_detect: 3280/4024 0.291s 0.000s
im_detect: 3281/4024 0.291s 0.000s
im_detect: 3282/4024 0.291s 0.000s
im_detect: 3283/4024 0.291s 0.000s
im_detect: 3284/4024 0.291s 0.000s
im_detect: 3285/4024 0.291s 0.000s
im_detect: 3286/4024 0.291s 0.000s
im_detect: 3287/4024 0.291s 0.000s
im_detect: 3288/4024 0.291s 0.000s
im_detect: 3289/4024 0.291s 0.000s
im_detect: 3290/4024 0.291s 0.000s
im_detect: 3291/4024 0.291s 0.000s
im_detect: 3292/4024 0.291s 0.000s
im_detect: 3293/4024 0.290s 0.000s
im_detect: 3294/4024 0.290s 0.000s
im_detect: 3295/4024 0.290s 0.000s
im_detect: 3296/4024 0.290s 0.000s
im_detect: 3297/4024 0.290s 0.000s
im_detect: 3298/4024 0.290s 0.000s
im_detect: 3299/4024 0.290s 0.000s
im_detect: 3300/4024 0.290s 0.000s
im_detect: 3301/4024 0.290s 0.000s
im_detect: 3302/4024 0.290s 0.000s
im_detect: 3303/4024 0.290s 0.000s
im_detect: 3304/4024 0.290s 0.000s
im_detect: 3305/4024 0.290s 0.000s
im_detect: 3306/4024 0.290s 0.000s
im_detect: 3307/4024 0.290s 0.000s
im_detect: 3308/4024 0.290s 0.000s
im_detect: 3309/4024 0.290s 0.000s
im_detect: 3310/4024 0.290s 0.000s
im_detect: 3311/4024 0.290s 0.000s
im_detect: 3312/4024 0.290s 0.000s
im_detect: 3313/4024 0.290s 0.000s
im_detect: 3314/4024 0.290s 0.000s
im_detect: 3315/4024 0.290s 0.000s
im_detect: 3316/4024 0.290s 0.000s
im_detect: 3317/4024 0.290s 0.000s
im_detect: 3318/4024 0.290s 0.000s
im_detect: 3319/4024 0.290s 0.000s
im_detect: 3320/4024 0.290s 0.000s
im_detect: 3321/4024 0.290s 0.000s
im_detect: 3322/4024 0.290s 0.000s
im_detect: 3323/4024 0.290s 0.000s
im_detect: 3324/4024 0.290s 0.000s
im_detect: 3325/4024 0.290s 0.000s
im_detect: 3326/4024 0.290s 0.000s
im_detect: 3327/4024 0.290s 0.000s
im_detect: 3328/4024 0.290s 0.000s
im_detect: 3329/4024 0.290s 0.000s
im_detect: 3330/4024 0.290s 0.000s
im_detect: 3331/4024 0.290s 0.000s
im_detect: 3332/4024 0.290s 0.000s
im_detect: 3333/4024 0.290s 0.000s
im_detect: 3334/4024 0.290s 0.000s
im_detect: 3335/4024 0.290s 0.000s
im_detect: 3336/4024 0.290s 0.000s
im_detect: 3337/4024 0.290s 0.000s
im_detect: 3338/4024 0.290s 0.000s
im_detect: 3339/4024 0.290s 0.000s
im_detect: 3340/4024 0.290s 0.000s
im_detect: 3341/4024 0.290s 0.000s
im_detect: 3342/4024 0.290s 0.000s
im_detect: 3343/4024 0.290s 0.000s
im_detect: 3344/4024 0.290s 0.000s
im_detect: 3345/4024 0.290s 0.000s
im_detect: 3346/4024 0.290s 0.000s
im_detect: 3347/4024 0.290s 0.000s
im_detect: 3348/4024 0.290s 0.000s
im_detect: 3349/4024 0.290s 0.000s
im_detect: 3350/4024 0.290s 0.000s
im_detect: 3351/4024 0.290s 0.000s
im_detect: 3352/4024 0.290s 0.000s
im_detect: 3353/4024 0.290s 0.000s
im_detect: 3354/4024 0.290s 0.000s
im_detect: 3355/4024 0.290s 0.000s
im_detect: 3356/4024 0.290s 0.000s
im_detect: 3357/4024 0.290s 0.000s
im_detect: 3358/4024 0.290s 0.000s
im_detect: 3359/4024 0.290s 0.000s
im_detect: 3360/4024 0.290s 0.000s
im_detect: 3361/4024 0.290s 0.000s
im_detect: 3362/4024 0.290s 0.000s
im_detect: 3363/4024 0.290s 0.000s
im_detect: 3364/4024 0.290s 0.000s
im_detect: 3365/4024 0.290s 0.000s
im_detect: 3366/4024 0.290s 0.000s
im_detect: 3367/4024 0.290s 0.000s
im_detect: 3368/4024 0.290s 0.000s
im_detect: 3369/4024 0.290s 0.000s
im_detect: 3370/4024 0.290s 0.000s
im_detect: 3371/4024 0.290s 0.000s
im_detect: 3372/4024 0.290s 0.000s
im_detect: 3373/4024 0.290s 0.000s
im_detect: 3374/4024 0.290s 0.000s
im_detect: 3375/4024 0.290s 0.000s
im_detect: 3376/4024 0.290s 0.000s
im_detect: 3377/4024 0.290s 0.000s
im_detect: 3378/4024 0.290s 0.000s
im_detect: 3379/4024 0.290s 0.000s
im_detect: 3380/4024 0.290s 0.000s
im_detect: 3381/4024 0.290s 0.000s
im_detect: 3382/4024 0.290s 0.000s
im_detect: 3383/4024 0.290s 0.000s
im_detect: 3384/4024 0.290s 0.000s
im_detect: 3385/4024 0.290s 0.000s
im_detect: 3386/4024 0.290s 0.000s
im_detect: 3387/4024 0.290s 0.000s
im_detect: 3388/4024 0.290s 0.000s
im_detect: 3389/4024 0.290s 0.000s
im_detect: 3390/4024 0.290s 0.000s
im_detect: 3391/4024 0.290s 0.000s
im_detect: 3392/4024 0.290s 0.000s
im_detect: 3393/4024 0.290s 0.000s
im_detect: 3394/4024 0.290s 0.000s
im_detect: 3395/4024 0.290s 0.000s
im_detect: 3396/4024 0.290s 0.000s
im_detect: 3397/4024 0.290s 0.000s
im_detect: 3398/4024 0.290s 0.000s
im_detect: 3399/4024 0.290s 0.000s
im_detect: 3400/4024 0.290s 0.000s
im_detect: 3401/4024 0.290s 0.000s
im_detect: 3402/4024 0.290s 0.000s
im_detect: 3403/4024 0.290s 0.000s
im_detect: 3404/4024 0.290s 0.000s
im_detect: 3405/4024 0.290s 0.000s
im_detect: 3406/4024 0.290s 0.000s
im_detect: 3407/4024 0.290s 0.000s
im_detect: 3408/4024 0.290s 0.000s
im_detect: 3409/4024 0.290s 0.000s
im_detect: 3410/4024 0.290s 0.000s
im_detect: 3411/4024 0.290s 0.000s
im_detect: 3412/4024 0.290s 0.000s
im_detect: 3413/4024 0.290s 0.000s
im_detect: 3414/4024 0.290s 0.000s
im_detect: 3415/4024 0.290s 0.000s
im_detect: 3416/4024 0.290s 0.000s
im_detect: 3417/4024 0.290s 0.000s
im_detect: 3418/4024 0.290s 0.000s
im_detect: 3419/4024 0.290s 0.000s
im_detect: 3420/4024 0.290s 0.000s
im_detect: 3421/4024 0.290s 0.000s
im_detect: 3422/4024 0.290s 0.000s
im_detect: 3423/4024 0.290s 0.000s
im_detect: 3424/4024 0.290s 0.000s
im_detect: 3425/4024 0.290s 0.000s
im_detect: 3426/4024 0.290s 0.000s
im_detect: 3427/4024 0.290s 0.000s
im_detect: 3428/4024 0.290s 0.000s
im_detect: 3429/4024 0.290s 0.000s
im_detect: 3430/4024 0.290s 0.000s
im_detect: 3431/4024 0.290s 0.000s
im_detect: 3432/4024 0.290s 0.000s
im_detect: 3433/4024 0.290s 0.000s
im_detect: 3434/4024 0.290s 0.000s
im_detect: 3435/4024 0.290s 0.000s
im_detect: 3436/4024 0.290s 0.000s
im_detect: 3437/4024 0.290s 0.000s
im_detect: 3438/4024 0.290s 0.000s
im_detect: 3439/4024 0.290s 0.000s
im_detect: 3440/4024 0.290s 0.000s
im_detect: 3441/4024 0.290s 0.000s
im_detect: 3442/4024 0.290s 0.000s
im_detect: 3443/4024 0.290s 0.000s
im_detect: 3444/4024 0.290s 0.000s
im_detect: 3445/4024 0.290s 0.000s
im_detect: 3446/4024 0.290s 0.000s
im_detect: 3447/4024 0.290s 0.000s
im_detect: 3448/4024 0.290s 0.000s
im_detect: 3449/4024 0.290s 0.000s
im_detect: 3450/4024 0.290s 0.000s
im_detect: 3451/4024 0.290s 0.000s
im_detect: 3452/4024 0.290s 0.000s
im_detect: 3453/4024 0.290s 0.000s
im_detect: 3454/4024 0.290s 0.000s
im_detect: 3455/4024 0.290s 0.000s
im_detect: 3456/4024 0.290s 0.000s
im_detect: 3457/4024 0.290s 0.000s
im_detect: 3458/4024 0.290s 0.000s
im_detect: 3459/4024 0.290s 0.000s
im_detect: 3460/4024 0.290s 0.000s
im_detect: 3461/4024 0.290s 0.000s
im_detect: 3462/4024 0.290s 0.000s
im_detect: 3463/4024 0.290s 0.000s
im_detect: 3464/4024 0.290s 0.000s
im_detect: 3465/4024 0.290s 0.000s
im_detect: 3466/4024 0.290s 0.000s
im_detect: 3467/4024 0.290s 0.000s
im_detect: 3468/4024 0.290s 0.000s
im_detect: 3469/4024 0.290s 0.000s
im_detect: 3470/4024 0.290s 0.000s
im_detect: 3471/4024 0.290s 0.000s
im_detect: 3472/4024 0.290s 0.000s
im_detect: 3473/4024 0.290s 0.000s
im_detect: 3474/4024 0.290s 0.000s
im_detect: 3475/4024 0.290s 0.000s
im_detect: 3476/4024 0.290s 0.000s
im_detect: 3477/4024 0.290s 0.000s
im_detect: 3478/4024 0.290s 0.000s
im_detect: 3479/4024 0.290s 0.000s
im_detect: 3480/4024 0.290s 0.000s
im_detect: 3481/4024 0.290s 0.000s
im_detect: 3482/4024 0.290s 0.000s
im_detect: 3483/4024 0.290s 0.000s
im_detect: 3484/4024 0.290s 0.000s
im_detect: 3485/4024 0.290s 0.000s
im_detect: 3486/4024 0.290s 0.000s
im_detect: 3487/4024 0.290s 0.000s
im_detect: 3488/4024 0.290s 0.000s
im_detect: 3489/4024 0.290s 0.000s
im_detect: 3490/4024 0.290s 0.000s
im_detect: 3491/4024 0.290s 0.000s
im_detect: 3492/4024 0.290s 0.000s
im_detect: 3493/4024 0.290s 0.000s
im_detect: 3494/4024 0.290s 0.000s
im_detect: 3495/4024 0.290s 0.000s
im_detect: 3496/4024 0.290s 0.000s
im_detect: 3497/4024 0.290s 0.000s
im_detect: 3498/4024 0.290s 0.000s
im_detect: 3499/4024 0.290s 0.000s
im_detect: 3500/4024 0.290s 0.000s
im_detect: 3501/4024 0.290s 0.000s
im_detect: 3502/4024 0.290s 0.000s
im_detect: 3503/4024 0.290s 0.000s
im_detect: 3504/4024 0.290s 0.000s
im_detect: 3505/4024 0.290s 0.000s
im_detect: 3506/4024 0.290s 0.000s
im_detect: 3507/4024 0.290s 0.000s
im_detect: 3508/4024 0.290s 0.000s
im_detect: 3509/4024 0.290s 0.000s
im_detect: 3510/4024 0.290s 0.000s
im_detect: 3511/4024 0.290s 0.000s
im_detect: 3512/4024 0.290s 0.000s
im_detect: 3513/4024 0.290s 0.000s
im_detect: 3514/4024 0.290s 0.000s
im_detect: 3515/4024 0.290s 0.000s
im_detect: 3516/4024 0.290s 0.000s
im_detect: 3517/4024 0.290s 0.000s
im_detect: 3518/4024 0.290s 0.000s
im_detect: 3519/4024 0.290s 0.000s
im_detect: 3520/4024 0.290s 0.000s
im_detect: 3521/4024 0.290s 0.000s
im_detect: 3522/4024 0.290s 0.000s
im_detect: 3523/4024 0.290s 0.000s
im_detect: 3524/4024 0.290s 0.000s
im_detect: 3525/4024 0.290s 0.000s
im_detect: 3526/4024 0.290s 0.000s
im_detect: 3527/4024 0.290s 0.000s
im_detect: 3528/4024 0.290s 0.000s
im_detect: 3529/4024 0.290s 0.000s
im_detect: 3530/4024 0.290s 0.000s
im_detect: 3531/4024 0.290s 0.000s
im_detect: 3532/4024 0.290s 0.000s
im_detect: 3533/4024 0.290s 0.000s
im_detect: 3534/4024 0.290s 0.000s
im_detect: 3535/4024 0.290s 0.000s
im_detect: 3536/4024 0.290s 0.000s
im_detect: 3537/4024 0.290s 0.000s
im_detect: 3538/4024 0.290s 0.000s
im_detect: 3539/4024 0.290s 0.000s
im_detect: 3540/4024 0.290s 0.000s
im_detect: 3541/4024 0.290s 0.000s
im_detect: 3542/4024 0.290s 0.000s
im_detect: 3543/4024 0.290s 0.000s
im_detect: 3544/4024 0.290s 0.000s
im_detect: 3545/4024 0.290s 0.000s
im_detect: 3546/4024 0.290s 0.000s
im_detect: 3547/4024 0.290s 0.000s
im_detect: 3548/4024 0.290s 0.000s
im_detect: 3549/4024 0.290s 0.000s
im_detect: 3550/4024 0.290s 0.000s
im_detect: 3551/4024 0.290s 0.000s
im_detect: 3552/4024 0.290s 0.000s
im_detect: 3553/4024 0.290s 0.000s
im_detect: 3554/4024 0.290s 0.000s
im_detect: 3555/4024 0.290s 0.000s
im_detect: 3556/4024 0.290s 0.000s
im_detect: 3557/4024 0.290s 0.000s
im_detect: 3558/4024 0.290s 0.000s
im_detect: 3559/4024 0.290s 0.000s
im_detect: 3560/4024 0.290s 0.000s
im_detect: 3561/4024 0.290s 0.000s
im_detect: 3562/4024 0.290s 0.000s
im_detect: 3563/4024 0.290s 0.000s
im_detect: 3564/4024 0.290s 0.000s
im_detect: 3565/4024 0.290s 0.000s
im_detect: 3566/4024 0.290s 0.000s
im_detect: 3567/4024 0.290s 0.000s
im_detect: 3568/4024 0.290s 0.000s
im_detect: 3569/4024 0.290s 0.000s
im_detect: 3570/4024 0.290s 0.000s
im_detect: 3571/4024 0.290s 0.000s
im_detect: 3572/4024 0.290s 0.000s
im_detect: 3573/4024 0.290s 0.000s
im_detect: 3574/4024 0.290s 0.000s
im_detect: 3575/4024 0.290s 0.000s
im_detect: 3576/4024 0.290s 0.000s
im_detect: 3577/4024 0.290s 0.000s
im_detect: 3578/4024 0.290s 0.000s
im_detect: 3579/4024 0.290s 0.000s
im_detect: 3580/4024 0.290s 0.000s
im_detect: 3581/4024 0.290s 0.000s
im_detect: 3582/4024 0.290s 0.000s
im_detect: 3583/4024 0.290s 0.000s
im_detect: 3584/4024 0.290s 0.000s
im_detect: 3585/4024 0.290s 0.000s
im_detect: 3586/4024 0.290s 0.000s
im_detect: 3587/4024 0.290s 0.000s
im_detect: 3588/4024 0.290s 0.000s
im_detect: 3589/4024 0.290s 0.000s
im_detect: 3590/4024 0.290s 0.000s
im_detect: 3591/4024 0.290s 0.000s
im_detect: 3592/4024 0.290s 0.000s
im_detect: 3593/4024 0.290s 0.000s
im_detect: 3594/4024 0.290s 0.000s
im_detect: 3595/4024 0.290s 0.000s
im_detect: 3596/4024 0.290s 0.000s
im_detect: 3597/4024 0.290s 0.000s
im_detect: 3598/4024 0.290s 0.000s
im_detect: 3599/4024 0.290s 0.000s
im_detect: 3600/4024 0.290s 0.000s
im_detect: 3601/4024 0.290s 0.000s
im_detect: 3602/4024 0.290s 0.000s
im_detect: 3603/4024 0.290s 0.000s
im_detect: 3604/4024 0.290s 0.000s
im_detect: 3605/4024 0.290s 0.000s
im_detect: 3606/4024 0.290s 0.000s
im_detect: 3607/4024 0.290s 0.000s
im_detect: 3608/4024 0.290s 0.000s
im_detect: 3609/4024 0.290s 0.000s
im_detect: 3610/4024 0.290s 0.000s
im_detect: 3611/4024 0.290s 0.000s
im_detect: 3612/4024 0.290s 0.000s
im_detect: 3613/4024 0.290s 0.000s
im_detect: 3614/4024 0.290s 0.000s
im_detect: 3615/4024 0.290s 0.000s
im_detect: 3616/4024 0.290s 0.000s
im_detect: 3617/4024 0.290s 0.000s
im_detect: 3618/4024 0.290s 0.000s
im_detect: 3619/4024 0.290s 0.000s
im_detect: 3620/4024 0.290s 0.000s
im_detect: 3621/4024 0.290s 0.000s
im_detect: 3622/4024 0.290s 0.000s
im_detect: 3623/4024 0.290s 0.000s
im_detect: 3624/4024 0.290s 0.000s
im_detect: 3625/4024 0.290s 0.000s
im_detect: 3626/4024 0.290s 0.000s
im_detect: 3627/4024 0.290s 0.000s
im_detect: 3628/4024 0.290s 0.000s
im_detect: 3629/4024 0.290s 0.000s
im_detect: 3630/4024 0.290s 0.000s
im_detect: 3631/4024 0.290s 0.000s
im_detect: 3632/4024 0.290s 0.000s
im_detect: 3633/4024 0.290s 0.000s
im_detect: 3634/4024 0.290s 0.000s
im_detect: 3635/4024 0.290s 0.000s
im_detect: 3636/4024 0.290s 0.000s
im_detect: 3637/4024 0.290s 0.000s
im_detect: 3638/4024 0.290s 0.000s
im_detect: 3639/4024 0.290s 0.000s
im_detect: 3640/4024 0.290s 0.000s
im_detect: 3641/4024 0.290s 0.000s
im_detect: 3642/4024 0.290s 0.000s
im_detect: 3643/4024 0.290s 0.000s
im_detect: 3644/4024 0.290s 0.000s
im_detect: 3645/4024 0.290s 0.000s
im_detect: 3646/4024 0.290s 0.000s
im_detect: 3647/4024 0.290s 0.000s
im_detect: 3648/4024 0.290s 0.000s
im_detect: 3649/4024 0.290s 0.000s
im_detect: 3650/4024 0.290s 0.000s
im_detect: 3651/4024 0.290s 0.000s
im_detect: 3652/4024 0.290s 0.000s
im_detect: 3653/4024 0.290s 0.000s
im_detect: 3654/4024 0.290s 0.000s
im_detect: 3655/4024 0.290s 0.000s
im_detect: 3656/4024 0.290s 0.000s
im_detect: 3657/4024 0.290s 0.000s
im_detect: 3658/4024 0.290s 0.000s
im_detect: 3659/4024 0.290s 0.000s
im_detect: 3660/4024 0.290s 0.000s
im_detect: 3661/4024 0.290s 0.000s
im_detect: 3662/4024 0.290s 0.000s
im_detect: 3663/4024 0.290s 0.000s
im_detect: 3664/4024 0.290s 0.000s
im_detect: 3665/4024 0.290s 0.000s
im_detect: 3666/4024 0.290s 0.000s
im_detect: 3667/4024 0.290s 0.000s
im_detect: 3668/4024 0.290s 0.000s
im_detect: 3669/4024 0.290s 0.000s
im_detect: 3670/4024 0.290s 0.000s
im_detect: 3671/4024 0.290s 0.000s
im_detect: 3672/4024 0.290s 0.000s
im_detect: 3673/4024 0.290s 0.000s
im_detect: 3674/4024 0.290s 0.000s
im_detect: 3675/4024 0.290s 0.000s
im_detect: 3676/4024 0.290s 0.000s
im_detect: 3677/4024 0.290s 0.000s
im_detect: 3678/4024 0.290s 0.000s
im_detect: 3679/4024 0.290s 0.000s
im_detect: 3680/4024 0.290s 0.000s
im_detect: 3681/4024 0.290s 0.000s
im_detect: 3682/4024 0.290s 0.000s
im_detect: 3683/4024 0.290s 0.000s
im_detect: 3684/4024 0.290s 0.000s
im_detect: 3685/4024 0.290s 0.000s
im_detect: 3686/4024 0.290s 0.000s
im_detect: 3687/4024 0.290s 0.000s
im_detect: 3688/4024 0.290s 0.000s
im_detect: 3689/4024 0.290s 0.000s
im_detect: 3690/4024 0.290s 0.000s
im_detect: 3691/4024 0.290s 0.000s
im_detect: 3692/4024 0.290s 0.000s
im_detect: 3693/4024 0.290s 0.000s
im_detect: 3694/4024 0.290s 0.000s
im_detect: 3695/4024 0.290s 0.000s
im_detect: 3696/4024 0.290s 0.000s
im_detect: 3697/4024 0.290s 0.000s
im_detect: 3698/4024 0.290s 0.000s
im_detect: 3699/4024 0.290s 0.000s
im_detect: 3700/4024 0.290s 0.000s
im_detect: 3701/4024 0.290s 0.000s
im_detect: 3702/4024 0.290s 0.000s
im_detect: 3703/4024 0.290s 0.000s
im_detect: 3704/4024 0.290s 0.000s
im_detect: 3705/4024 0.290s 0.000s
im_detect: 3706/4024 0.290s 0.000s
im_detect: 3707/4024 0.290s 0.000s
im_detect: 3708/4024 0.290s 0.000s
im_detect: 3709/4024 0.290s 0.000s
im_detect: 3710/4024 0.290s 0.000s
im_detect: 3711/4024 0.290s 0.000s
im_detect: 3712/4024 0.290s 0.000s
im_detect: 3713/4024 0.290s 0.000s
im_detect: 3714/4024 0.290s 0.000s
im_detect: 3715/4024 0.290s 0.000s
im_detect: 3716/4024 0.290s 0.000s
im_detect: 3717/4024 0.290s 0.000s
im_detect: 3718/4024 0.290s 0.000s
im_detect: 3719/4024 0.290s 0.000s
im_detect: 3720/4024 0.290s 0.000s
im_detect: 3721/4024 0.290s 0.000s
im_detect: 3722/4024 0.290s 0.000s
im_detect: 3723/4024 0.290s 0.000s
im_detect: 3724/4024 0.290s 0.000s
im_detect: 3725/4024 0.290s 0.000s
im_detect: 3726/4024 0.290s 0.000s
im_detect: 3727/4024 0.290s 0.000s
im_detect: 3728/4024 0.290s 0.000s
im_detect: 3729/4024 0.290s 0.000s
im_detect: 3730/4024 0.290s 0.000s
im_detect: 3731/4024 0.290s 0.000s
im_detect: 3732/4024 0.290s 0.000s
im_detect: 3733/4024 0.290s 0.000s
im_detect: 3734/4024 0.290s 0.000s
im_detect: 3735/4024 0.290s 0.000s
im_detect: 3736/4024 0.290s 0.000s
im_detect: 3737/4024 0.290s 0.000s
im_detect: 3738/4024 0.290s 0.000s
im_detect: 3739/4024 0.290s 0.000s
im_detect: 3740/4024 0.290s 0.000s
im_detect: 3741/4024 0.290s 0.000s
im_detect: 3742/4024 0.290s 0.000s
im_detect: 3743/4024 0.289s 0.000s
im_detect: 3744/4024 0.289s 0.000s
im_detect: 3745/4024 0.289s 0.000s
im_detect: 3746/4024 0.289s 0.000s
im_detect: 3747/4024 0.289s 0.000s
im_detect: 3748/4024 0.289s 0.000s
im_detect: 3749/4024 0.289s 0.000s
im_detect: 3750/4024 0.289s 0.000s
im_detect: 3751/4024 0.289s 0.000s
im_detect: 3752/4024 0.289s 0.000s
im_detect: 3753/4024 0.289s 0.000s
im_detect: 3754/4024 0.289s 0.000s
im_detect: 3755/4024 0.289s 0.000s
im_detect: 3756/4024 0.289s 0.000s
im_detect: 3757/4024 0.289s 0.000s
im_detect: 3758/4024 0.289s 0.000s
im_detect: 3759/4024 0.289s 0.000s
im_detect: 3760/4024 0.289s 0.000s
im_detect: 3761/4024 0.289s 0.000s
im_detect: 3762/4024 0.289s 0.000s
im_detect: 3763/4024 0.289s 0.000s
im_detect: 3764/4024 0.289s 0.000s
im_detect: 3765/4024 0.289s 0.000s
im_detect: 3766/4024 0.289s 0.000s
im_detect: 3767/4024 0.289s 0.000s
im_detect: 3768/4024 0.289s 0.000s
im_detect: 3769/4024 0.289s 0.000s
im_detect: 3770/4024 0.289s 0.000s
im_detect: 3771/4024 0.289s 0.000s
im_detect: 3772/4024 0.289s 0.000s
im_detect: 3773/4024 0.289s 0.000s
im_detect: 3774/4024 0.289s 0.000s
im_detect: 3775/4024 0.289s 0.000s
im_detect: 3776/4024 0.289s 0.000s
im_detect: 3777/4024 0.289s 0.000s
im_detect: 3778/4024 0.289s 0.000s
im_detect: 3779/4024 0.289s 0.000s
im_detect: 3780/4024 0.289s 0.000s
im_detect: 3781/4024 0.289s 0.000s
im_detect: 3782/4024 0.289s 0.000s
im_detect: 3783/4024 0.289s 0.000s
im_detect: 3784/4024 0.289s 0.000s
im_detect: 3785/4024 0.289s 0.000s
im_detect: 3786/4024 0.289s 0.000s
im_detect: 3787/4024 0.289s 0.000s
im_detect: 3788/4024 0.289s 0.000s
im_detect: 3789/4024 0.289s 0.000s
im_detect: 3790/4024 0.289s 0.000s
im_detect: 3791/4024 0.289s 0.000s
im_detect: 3792/4024 0.289s 0.000s
im_detect: 3793/4024 0.289s 0.000s
im_detect: 3794/4024 0.289s 0.000s
im_detect: 3795/4024 0.289s 0.000s
im_detect: 3796/4024 0.289s 0.000s
im_detect: 3797/4024 0.289s 0.000s
im_detect: 3798/4024 0.289s 0.000s
im_detect: 3799/4024 0.289s 0.000s
im_detect: 3800/4024 0.289s 0.000s
im_detect: 3801/4024 0.289s 0.000s
im_detect: 3802/4024 0.289s 0.000s
im_detect: 3803/4024 0.289s 0.000s
im_detect: 3804/4024 0.289s 0.000s
im_detect: 3805/4024 0.289s 0.000s
im_detect: 3806/4024 0.289s 0.000s
im_detect: 3807/4024 0.289s 0.000s
im_detect: 3808/4024 0.289s 0.000s
im_detect: 3809/4024 0.289s 0.000s
im_detect: 3810/4024 0.289s 0.000s
im_detect: 3811/4024 0.289s 0.000s
im_detect: 3812/4024 0.289s 0.000s
im_detect: 3813/4024 0.289s 0.000s
im_detect: 3814/4024 0.289s 0.000s
im_detect: 3815/4024 0.289s 0.000s
im_detect: 3816/4024 0.289s 0.000s
im_detect: 3817/4024 0.289s 0.000s
im_detect: 3818/4024 0.289s 0.000s
im_detect: 3819/4024 0.289s 0.000s
im_detect: 3820/4024 0.289s 0.000s
im_detect: 3821/4024 0.289s 0.000s
im_detect: 3822/4024 0.289s 0.000s
im_detect: 3823/4024 0.289s 0.000s
im_detect: 3824/4024 0.289s 0.000s
im_detect: 3825/4024 0.289s 0.000s
im_detect: 3826/4024 0.289s 0.000s
im_detect: 3827/4024 0.289s 0.000s
im_detect: 3828/4024 0.289s 0.000s
im_detect: 3829/4024 0.289s 0.000s
im_detect: 3830/4024 0.289s 0.000s
im_detect: 3831/4024 0.289s 0.000s
im_detect: 3832/4024 0.289s 0.000s
im_detect: 3833/4024 0.289s 0.000s
im_detect: 3834/4024 0.289s 0.000s
im_detect: 3835/4024 0.289s 0.000s
im_detect: 3836/4024 0.289s 0.000s
im_detect: 3837/4024 0.289s 0.000s
im_detect: 3838/4024 0.289s 0.000s
im_detect: 3839/4024 0.289s 0.000s
im_detect: 3840/4024 0.289s 0.000s
im_detect: 3841/4024 0.289s 0.000s
im_detect: 3842/4024 0.289s 0.000s
im_detect: 3843/4024 0.289s 0.000s
im_detect: 3844/4024 0.289s 0.000s
im_detect: 3845/4024 0.289s 0.000s
im_detect: 3846/4024 0.289s 0.000s
im_detect: 3847/4024 0.289s 0.000s
im_detect: 3848/4024 0.289s 0.000s
im_detect: 3849/4024 0.289s 0.000s
im_detect: 3850/4024 0.289s 0.000s
im_detect: 3851/4024 0.289s 0.000s
im_detect: 3852/4024 0.289s 0.000s
im_detect: 3853/4024 0.289s 0.000s
im_detect: 3854/4024 0.289s 0.000s
im_detect: 3855/4024 0.289s 0.000s
im_detect: 3856/4024 0.289s 0.000s
im_detect: 3857/4024 0.289s 0.000s
im_detect: 3858/4024 0.289s 0.000s
im_detect: 3859/4024 0.289s 0.000s
im_detect: 3860/4024 0.289s 0.000s
im_detect: 3861/4024 0.289s 0.000s
im_detect: 3862/4024 0.289s 0.000s
im_detect: 3863/4024 0.289s 0.000s
im_detect: 3864/4024 0.289s 0.000s
im_detect: 3865/4024 0.289s 0.000s
im_detect: 3866/4024 0.289s 0.000s
im_detect: 3867/4024 0.289s 0.000s
im_detect: 3868/4024 0.289s 0.000s
im_detect: 3869/4024 0.289s 0.000s
im_detect: 3870/4024 0.289s 0.000s
im_detect: 3871/4024 0.289s 0.000s
im_detect: 3872/4024 0.289s 0.000s
im_detect: 3873/4024 0.289s 0.000s
im_detect: 3874/4024 0.289s 0.000s
im_detect: 3875/4024 0.289s 0.000s
im_detect: 3876/4024 0.289s 0.000s
im_detect: 3877/4024 0.289s 0.000s
im_detect: 3878/4024 0.289s 0.000s
im_detect: 3879/4024 0.289s 0.000s
im_detect: 3880/4024 0.289s 0.000s
im_detect: 3881/4024 0.289s 0.000s
im_detect: 3882/4024 0.289s 0.000s
im_detect: 3883/4024 0.289s 0.000s
im_detect: 3884/4024 0.289s 0.000s
im_detect: 3885/4024 0.289s 0.000s
im_detect: 3886/4024 0.289s 0.000s
im_detect: 3887/4024 0.289s 0.000s
im_detect: 3888/4024 0.289s 0.000s
im_detect: 3889/4024 0.289s 0.000s
im_detect: 3890/4024 0.289s 0.000s
im_detect: 3891/4024 0.289s 0.000s
im_detect: 3892/4024 0.289s 0.000s
im_detect: 3893/4024 0.289s 0.000s
im_detect: 3894/4024 0.289s 0.000s
im_detect: 3895/4024 0.289s 0.000s
im_detect: 3896/4024 0.289s 0.000s
im_detect: 3897/4024 0.289s 0.000s
im_detect: 3898/4024 0.289s 0.000s
im_detect: 3899/4024 0.289s 0.000s
im_detect: 3900/4024 0.289s 0.000s
im_detect: 3901/4024 0.289s 0.000s
im_detect: 3902/4024 0.289s 0.000s
im_detect: 3903/4024 0.289s 0.000s
im_detect: 3904/4024 0.289s 0.000s
im_detect: 3905/4024 0.289s 0.000s
im_detect: 3906/4024 0.289s 0.000s
im_detect: 3907/4024 0.289s 0.000s
im_detect: 3908/4024 0.289s 0.000s
im_detect: 3909/4024 0.289s 0.000s
im_detect: 3910/4024 0.289s 0.000s
im_detect: 3911/4024 0.289s 0.000s
im_detect: 3912/4024 0.289s 0.000s
im_detect: 3913/4024 0.289s 0.000s
im_detect: 3914/4024 0.289s 0.000s
im_detect: 3915/4024 0.289s 0.000s
im_detect: 3916/4024 0.289s 0.000s
im_detect: 3917/4024 0.289s 0.000s
im_detect: 3918/4024 0.289s 0.000s
im_detect: 3919/4024 0.289s 0.000s
im_detect: 3920/4024 0.289s 0.000s
im_detect: 3921/4024 0.289s 0.000s
im_detect: 3922/4024 0.289s 0.000s
im_detect: 3923/4024 0.289s 0.000s
im_detect: 3924/4024 0.289s 0.000s
im_detect: 3925/4024 0.289s 0.000s
im_detect: 3926/4024 0.289s 0.000s
im_detect: 3927/4024 0.289s 0.000s
im_detect: 3928/4024 0.289s 0.000s
im_detect: 3929/4024 0.289s 0.000s
im_detect: 3930/4024 0.289s 0.000s
im_detect: 3931/4024 0.289s 0.000s
im_detect: 3932/4024 0.289s 0.000s
im_detect: 3933/4024 0.289s 0.000s
im_detect: 3934/4024 0.289s 0.000s
im_detect: 3935/4024 0.289s 0.000s
im_detect: 3936/4024 0.289s 0.000s
im_detect: 3937/4024 0.289s 0.000s
im_detect: 3938/4024 0.289s 0.000s
im_detect: 3939/4024 0.289s 0.000s
im_detect: 3940/4024 0.289s 0.000s
im_detect: 3941/4024 0.289s 0.000s
im_detect: 3942/4024 0.289s 0.000s
im_detect: 3943/4024 0.289s 0.000s
im_detect: 3944/4024 0.289s 0.000s
im_detect: 3945/4024 0.289s 0.000s
im_detect: 3946/4024 0.289s 0.000s
im_detect: 3947/4024 0.289s 0.000s
im_detect: 3948/4024 0.289s 0.000s
im_detect: 3949/4024 0.289s 0.000s
im_detect: 3950/4024 0.289s 0.000s
im_detect: 3951/4024 0.289s 0.000s
im_detect: 3952/4024 0.289s 0.000s
im_detect: 3953/4024 0.289s 0.000s
im_detect: 3954/4024 0.289s 0.000s
im_detect: 3955/4024 0.289s 0.000s
im_detect: 3956/4024 0.289s 0.000s
im_detect: 3957/4024 0.289s 0.000s
im_detect: 3958/4024 0.289s 0.000s
im_detect: 3959/4024 0.289s 0.000s
im_detect: 3960/4024 0.289s 0.000s
im_detect: 3961/4024 0.289s 0.000s
im_detect: 3962/4024 0.289s 0.000s
im_detect: 3963/4024 0.289s 0.000s
im_detect: 3964/4024 0.289s 0.000s
im_detect: 3965/4024 0.289s 0.000s
im_detect: 3966/4024 0.289s 0.000s
im_detect: 3967/4024 0.289s 0.000s
im_detect: 3968/4024 0.289s 0.000s
im_detect: 3969/4024 0.289s 0.000s
im_detect: 3970/4024 0.289s 0.000s
im_detect: 3971/4024 0.289s 0.000s
im_detect: 3972/4024 0.289s 0.000s
im_detect: 3973/4024 0.289s 0.000s
im_detect: 3974/4024 0.289s 0.000s
im_detect: 3975/4024 0.289s 0.000s
im_detect: 3976/4024 0.289s 0.000s
im_detect: 3977/4024 0.289s 0.000s
im_detect: 3978/4024 0.289s 0.000s
im_detect: 3979/4024 0.289s 0.000s
im_detect: 3980/4024 0.289s 0.000s
im_detect: 3981/4024 0.289s 0.000s
im_detect: 3982/4024 0.289s 0.000s
im_detect: 3983/4024 0.289s 0.000s
im_detect: 3984/4024 0.289s 0.000s
im_detect: 3985/4024 0.289s 0.000s
im_detect: 3986/4024 0.289s 0.000s
im_detect: 3987/4024 0.289s 0.000s
im_detect: 3988/4024 0.289s 0.000s
im_detect: 3989/4024 0.289s 0.000s
im_detect: 3990/4024 0.289s 0.000s
im_detect: 3991/4024 0.289s 0.000s
im_detect: 3992/4024 0.289s 0.000s
im_detect: 3993/4024 0.289s 0.000s
im_detect: 3994/4024 0.289s 0.000s
im_detect: 3995/4024 0.289s 0.000s
im_detect: 3996/4024 0.289s 0.000s
im_detect: 3997/4024 0.289s 0.000s
im_detect: 3998/4024 0.289s 0.000s
im_detect: 3999/4024 0.289s 0.000s
im_detect: 4000/4024 0.289s 0.000s
im_detect: 4001/4024 0.289s 0.000s
im_detect: 4002/4024 0.289s 0.000s
im_detect: 4003/4024 0.289s 0.000s
im_detect: 4004/4024 0.289s 0.000s
im_detect: 4005/4024 0.289s 0.000s
im_detect: 4006/4024 0.289s 0.000s
im_detect: 4007/4024 0.289s 0.000s
im_detect: 4008/4024 0.289s 0.000s
im_detect: 4009/4024 0.289s 0.000s
im_detect: 4010/4024 0.289s 0.000s
im_detect: 4011/4024 0.289s 0.000s
im_detect: 4012/4024 0.289s 0.000s
im_detect: 4013/4024 0.289s 0.000s
im_detect: 4014/4024 0.289s 0.000s
im_detect: 4015/4024 0.289s 0.000s
im_detect: 4016/4024 0.289s 0.000s
im_detect: 4017/4024 0.289s 0.000s
im_detect: 4018/4024 0.289s 0.000s
im_detect: 4019/4024 0.289s 0.000s
im_detect: 4020/4024 0.289s 0.000s
im_detect: 4021/4024 0.289s 0.000s
im_detect: 4022/4024 0.289s 0.000s
im_detect: 4023/4024 0.289s 0.000s
im_detect: 4024/4024 0.289s 0.000s
Evaluating detections
Writing head VOC results file
VOC07 metric? Yes
Traceback (most recent call last):
  File "./tools/test_net.py", line 95, in <module>
    test_net(net, imdb, max_per_image=args.max_per_image, vis=args.vis)
  File "/home/user/Disk1.8T/py_R_FCN_6_25/tools/../lib/fast_rcnn/test.py", line 318, in test_net
    imdb.evaluate_detections(all_boxes, output_dir)
  File "/home/user/Disk1.8T/py_R_FCN_6_25/tools/../lib/datasets/pascal_voc.py", line 330, in evaluate_detections
    self._do_python_eval(output_dir)
  File "/home/user/Disk1.8T/py_R_FCN_6_25/tools/../lib/datasets/pascal_voc.py", line 293, in _do_python_eval
    use_07_metric=use_07_metric)
  File "/home/user/Disk1.8T/py_R_FCN_6_25/tools/../lib/datasets/voc_eval.py", line 110, in voc_eval
    recs[imagename] = parse_rec(annopath.format(imagename))
  File "/home/user/Disk1.8T/py_R_FCN_6_25/tools/../lib/datasets/voc_eval.py", line 14, in parse_rec
    tree = ET.parse(filename)
  File "/usr/lib/python2.7/xml/etree/ElementTree.py", line 1182, in parse
    tree.parse(source, parser)
  File "/usr/lib/python2.7/xml/etree/ElementTree.py", line 647, in parse
    source = open(source, "rb")
IOError: [Errno 2] No such file or directory: '/home/user/Disk1.8T/py_R_FCN_6_25/data/VOCdevkit0712/VOC0712/Annotations/set08_V003_I00689.xml'
