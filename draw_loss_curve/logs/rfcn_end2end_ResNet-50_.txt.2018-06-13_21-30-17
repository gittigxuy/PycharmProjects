+ echo Logging output to experiments/6_13_original_head_upper_body_handle/logs/rfcn_end2end_ResNet-50_.txt.2018-06-13_21-30-17
Logging output to experiments/6_13_original_head_upper_body_handle/logs/rfcn_end2end_ResNet-50_.txt.2018-06-13_21-30-17
+ ./tools/train_net.py --gpu 1 --solver experiments/6_13_original_head_upper_body_handle/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_0712_trainval --iters 32000 --cfg experiments/6_13_original_head_upper_body_handle/rfcn_end2end_ohem.yml
Called with args:
Namespace(cfg_file='experiments/6_13_original_head_upper_body_handle/rfcn_end2end_ohem.yml', gpu_id=1, imdb_name='voc_0712_trainval', max_iters=32000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='experiments/6_13_original_head_upper_body_handle/solver_ohem.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '6_13_original_head_upper_body_handle/model',
 'GPU_ID': 1,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SOFT_NMS': 1,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_0712_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_0712_trainval gt roidb loaded from /home/user/Disk1.8T/py-R-FCN/data/cache/voc_0712_trainval_gt_roidb.pkl
done
Preparing training data...
done
8500 roidb entries
Output will be saved to `/home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model`
Filtered 5544 roidb entries: 8500 -> 2956
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0613 21:30:20.039809 15760 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/train_agnostic_ohem.prototxt"
base_lr: 0.0002
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "resnet50_rfcn_ohem"
iter_size: 8
I0613 21:30:20.039845 15760 solver.cpp:81] Creating training net from train_net file: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/train_agnostic_ohem.prototxt
I0613 21:30:20.042881 15760 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 4"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "res4c_
I0613 21:30:20.044819 15760 layer_factory.hpp:77] Creating layer input-data
I0613 21:30:20.054332 15760 net.cpp:100] Creating Layer input-data
I0613 21:30:20.054353 15760 net.cpp:418] input-data -> data
I0613 21:30:20.054394 15760 net.cpp:418] input-data -> im_info
I0613 21:30:20.054409 15760 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0613 21:30:20.074715 15760 net.cpp:150] Setting up input-data
I0613 21:30:20.074741 15760 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0613 21:30:20.074746 15760 net.cpp:157] Top shape: 1 3 (3)
I0613 21:30:20.074749 15760 net.cpp:157] Top shape: 1 4 (4)
I0613 21:30:20.074751 15760 net.cpp:165] Memory required for data: 14745628
I0613 21:30:20.074766 15760 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0613 21:30:20.074796 15760 net.cpp:100] Creating Layer data_input-data_0_split
I0613 21:30:20.074807 15760 net.cpp:444] data_input-data_0_split <- data
I0613 21:30:20.074823 15760 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I0613 21:30:20.074843 15760 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I0613 21:30:20.074895 15760 net.cpp:150] Setting up data_input-data_0_split
I0613 21:30:20.074903 15760 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0613 21:30:20.074908 15760 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0613 21:30:20.074909 15760 net.cpp:165] Memory required for data: 44236828
I0613 21:30:20.074913 15760 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0613 21:30:20.074923 15760 net.cpp:100] Creating Layer im_info_input-data_1_split
I0613 21:30:20.074928 15760 net.cpp:444] im_info_input-data_1_split <- im_info
I0613 21:30:20.074937 15760 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0613 21:30:20.074950 15760 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0613 21:30:20.074988 15760 net.cpp:150] Setting up im_info_input-data_1_split
I0613 21:30:20.074995 15760 net.cpp:157] Top shape: 1 3 (3)
I0613 21:30:20.075000 15760 net.cpp:157] Top shape: 1 3 (3)
I0613 21:30:20.075001 15760 net.cpp:165] Memory required for data: 44236852
I0613 21:30:20.075004 15760 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0613 21:30:20.075012 15760 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I0613 21:30:20.075016 15760 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I0613 21:30:20.075027 15760 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0613 21:30:20.075038 15760 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0613 21:30:20.075079 15760 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0613 21:30:20.075086 15760 net.cpp:157] Top shape: 1 4 (4)
I0613 21:30:20.075090 15760 net.cpp:157] Top shape: 1 4 (4)
I0613 21:30:20.075093 15760 net.cpp:165] Memory required for data: 44236884
I0613 21:30:20.075096 15760 layer_factory.hpp:77] Creating layer conv1
I0613 21:30:20.075116 15760 net.cpp:100] Creating Layer conv1
I0613 21:30:20.075122 15760 net.cpp:444] conv1 <- data_input-data_0_split_0
I0613 21:30:20.075135 15760 net.cpp:418] conv1 -> conv1
I0613 21:30:20.383437 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5529624
I0613 21:30:20.383697 15760 net.cpp:150] Setting up conv1
I0613 21:30:20.383715 15760 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0613 21:30:20.383719 15760 net.cpp:165] Memory required for data: 122880084
I0613 21:30:20.383771 15760 layer_factory.hpp:77] Creating layer bn_conv1
I0613 21:30:20.383800 15760 net.cpp:100] Creating Layer bn_conv1
I0613 21:30:20.383808 15760 net.cpp:444] bn_conv1 <- conv1
I0613 21:30:20.383822 15760 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0613 21:30:20.385169 15760 net.cpp:150] Setting up bn_conv1
I0613 21:30:20.385180 15760 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0613 21:30:20.385184 15760 net.cpp:165] Memory required for data: 201523284
I0613 21:30:20.385216 15760 layer_factory.hpp:77] Creating layer scale_conv1
I0613 21:30:20.385236 15760 net.cpp:100] Creating Layer scale_conv1
I0613 21:30:20.385241 15760 net.cpp:444] scale_conv1 <- conv1
I0613 21:30:20.385252 15760 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0613 21:30:20.385313 15760 layer_factory.hpp:77] Creating layer scale_conv1
I0613 21:30:20.388972 15760 net.cpp:150] Setting up scale_conv1
I0613 21:30:20.388994 15760 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0613 21:30:20.388998 15760 net.cpp:165] Memory required for data: 280166484
I0613 21:30:20.389026 15760 layer_factory.hpp:77] Creating layer conv1_relu
I0613 21:30:20.389057 15760 net.cpp:100] Creating Layer conv1_relu
I0613 21:30:20.389067 15760 net.cpp:444] conv1_relu <- conv1
I0613 21:30:20.389094 15760 net.cpp:405] conv1_relu -> conv1 (in-place)
I0613 21:30:20.389297 15760 net.cpp:150] Setting up conv1_relu
I0613 21:30:20.389305 15760 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0613 21:30:20.389307 15760 net.cpp:165] Memory required for data: 358809684
I0613 21:30:20.389312 15760 layer_factory.hpp:77] Creating layer pool1
I0613 21:30:20.389335 15760 net.cpp:100] Creating Layer pool1
I0613 21:30:20.389341 15760 net.cpp:444] pool1 <- conv1
I0613 21:30:20.389355 15760 net.cpp:418] pool1 -> pool1
I0613 21:30:20.389430 15760 net.cpp:150] Setting up pool1
I0613 21:30:20.389441 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.389443 15760 net.cpp:165] Memory required for data: 378470484
I0613 21:30:20.389447 15760 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0613 21:30:20.389456 15760 net.cpp:100] Creating Layer pool1_pool1_0_split
I0613 21:30:20.389461 15760 net.cpp:444] pool1_pool1_0_split <- pool1
I0613 21:30:20.389469 15760 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0613 21:30:20.389482 15760 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0613 21:30:20.389530 15760 net.cpp:150] Setting up pool1_pool1_0_split
I0613 21:30:20.389538 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.389540 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.389542 15760 net.cpp:165] Memory required for data: 417792084
I0613 21:30:20.389546 15760 layer_factory.hpp:77] Creating layer res2a_branch1
I0613 21:30:20.389562 15760 net.cpp:100] Creating Layer res2a_branch1
I0613 21:30:20.389567 15760 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0613 21:30:20.389580 15760 net.cpp:418] res2a_branch1 -> res2a_branch1
I0613 21:30:20.390604 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.390902 15760 net.cpp:150] Setting up res2a_branch1
I0613 21:30:20.390914 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.390916 15760 net.cpp:165] Memory required for data: 496435284
I0613 21:30:20.390930 15760 layer_factory.hpp:77] Creating layer bn2a_branch1
I0613 21:30:20.390946 15760 net.cpp:100] Creating Layer bn2a_branch1
I0613 21:30:20.390952 15760 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0613 21:30:20.390964 15760 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0613 21:30:20.391305 15760 net.cpp:150] Setting up bn2a_branch1
I0613 21:30:20.391312 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.391314 15760 net.cpp:165] Memory required for data: 575078484
I0613 21:30:20.391341 15760 layer_factory.hpp:77] Creating layer scale2a_branch1
I0613 21:30:20.391356 15760 net.cpp:100] Creating Layer scale2a_branch1
I0613 21:30:20.391362 15760 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0613 21:30:20.391373 15760 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0613 21:30:20.391433 15760 layer_factory.hpp:77] Creating layer scale2a_branch1
I0613 21:30:20.391793 15760 net.cpp:150] Setting up scale2a_branch1
I0613 21:30:20.391799 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.391803 15760 net.cpp:165] Memory required for data: 653721684
I0613 21:30:20.391811 15760 layer_factory.hpp:77] Creating layer res2a_branch2a
I0613 21:30:20.391826 15760 net.cpp:100] Creating Layer res2a_branch2a
I0613 21:30:20.391832 15760 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0613 21:30:20.391846 15760 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0613 21:30:20.393532 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.393790 15760 net.cpp:150] Setting up res2a_branch2a
I0613 21:30:20.393805 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.393807 15760 net.cpp:165] Memory required for data: 673382484
I0613 21:30:20.393821 15760 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0613 21:30:20.393838 15760 net.cpp:100] Creating Layer bn2a_branch2a
I0613 21:30:20.393844 15760 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0613 21:30:20.393857 15760 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0613 21:30:20.394207 15760 net.cpp:150] Setting up bn2a_branch2a
I0613 21:30:20.394214 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.394217 15760 net.cpp:165] Memory required for data: 693043284
I0613 21:30:20.394243 15760 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0613 21:30:20.394259 15760 net.cpp:100] Creating Layer scale2a_branch2a
I0613 21:30:20.394265 15760 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0613 21:30:20.394275 15760 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0613 21:30:20.394335 15760 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0613 21:30:20.394703 15760 net.cpp:150] Setting up scale2a_branch2a
I0613 21:30:20.394711 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.394714 15760 net.cpp:165] Memory required for data: 712704084
I0613 21:30:20.394723 15760 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0613 21:30:20.394740 15760 net.cpp:100] Creating Layer res2a_branch2a_relu
I0613 21:30:20.394745 15760 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0613 21:30:20.394758 15760 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0613 21:30:20.394914 15760 net.cpp:150] Setting up res2a_branch2a_relu
I0613 21:30:20.394922 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.394924 15760 net.cpp:165] Memory required for data: 732364884
I0613 21:30:20.394928 15760 layer_factory.hpp:77] Creating layer res2a_branch2b
I0613 21:30:20.394944 15760 net.cpp:100] Creating Layer res2a_branch2b
I0613 21:30:20.394949 15760 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0613 21:30:20.394963 15760 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0613 21:30:20.396733 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0613 21:30:20.397071 15760 net.cpp:150] Setting up res2a_branch2b
I0613 21:30:20.397089 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.397092 15760 net.cpp:165] Memory required for data: 752025684
I0613 21:30:20.397111 15760 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0613 21:30:20.397135 15760 net.cpp:100] Creating Layer bn2a_branch2b
I0613 21:30:20.397145 15760 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0613 21:30:20.397161 15760 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0613 21:30:20.397527 15760 net.cpp:150] Setting up bn2a_branch2b
I0613 21:30:20.397534 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.397536 15760 net.cpp:165] Memory required for data: 771686484
I0613 21:30:20.397552 15760 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0613 21:30:20.397567 15760 net.cpp:100] Creating Layer scale2a_branch2b
I0613 21:30:20.397573 15760 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0613 21:30:20.397585 15760 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0613 21:30:20.397646 15760 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0613 21:30:20.398811 15760 net.cpp:150] Setting up scale2a_branch2b
I0613 21:30:20.398823 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.398825 15760 net.cpp:165] Memory required for data: 791347284
I0613 21:30:20.398839 15760 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0613 21:30:20.398854 15760 net.cpp:100] Creating Layer res2a_branch2b_relu
I0613 21:30:20.398859 15760 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0613 21:30:20.398870 15760 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0613 21:30:20.399329 15760 net.cpp:150] Setting up res2a_branch2b_relu
I0613 21:30:20.399338 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.399340 15760 net.cpp:165] Memory required for data: 811008084
I0613 21:30:20.399345 15760 layer_factory.hpp:77] Creating layer res2a_branch2c
I0613 21:30:20.399365 15760 net.cpp:100] Creating Layer res2a_branch2c
I0613 21:30:20.399371 15760 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0613 21:30:20.399386 15760 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0613 21:30:20.400370 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.400692 15760 net.cpp:150] Setting up res2a_branch2c
I0613 21:30:20.400708 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.400712 15760 net.cpp:165] Memory required for data: 889651284
I0613 21:30:20.400724 15760 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0613 21:30:20.400740 15760 net.cpp:100] Creating Layer bn2a_branch2c
I0613 21:30:20.400746 15760 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0613 21:30:20.400759 15760 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0613 21:30:20.401136 15760 net.cpp:150] Setting up bn2a_branch2c
I0613 21:30:20.401144 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.401145 15760 net.cpp:165] Memory required for data: 968294484
I0613 21:30:20.401161 15760 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0613 21:30:20.401176 15760 net.cpp:100] Creating Layer scale2a_branch2c
I0613 21:30:20.401182 15760 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0613 21:30:20.401193 15760 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0613 21:30:20.401253 15760 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0613 21:30:20.401614 15760 net.cpp:150] Setting up scale2a_branch2c
I0613 21:30:20.401621 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.401625 15760 net.cpp:165] Memory required for data: 1046937684
I0613 21:30:20.401634 15760 layer_factory.hpp:77] Creating layer res2a
I0613 21:30:20.401645 15760 net.cpp:100] Creating Layer res2a
I0613 21:30:20.401650 15760 net.cpp:444] res2a <- res2a_branch1
I0613 21:30:20.401659 15760 net.cpp:444] res2a <- res2a_branch2c
I0613 21:30:20.401667 15760 net.cpp:418] res2a -> res2a
I0613 21:30:20.401706 15760 net.cpp:150] Setting up res2a
I0613 21:30:20.401715 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.401717 15760 net.cpp:165] Memory required for data: 1125580884
I0613 21:30:20.401721 15760 layer_factory.hpp:77] Creating layer res2a_relu
I0613 21:30:20.401728 15760 net.cpp:100] Creating Layer res2a_relu
I0613 21:30:20.401733 15760 net.cpp:444] res2a_relu <- res2a
I0613 21:30:20.401743 15760 net.cpp:405] res2a_relu -> res2a (in-place)
I0613 21:30:20.401896 15760 net.cpp:150] Setting up res2a_relu
I0613 21:30:20.401903 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.401906 15760 net.cpp:165] Memory required for data: 1204224084
I0613 21:30:20.401909 15760 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0613 21:30:20.401918 15760 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0613 21:30:20.401923 15760 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0613 21:30:20.401935 15760 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0613 21:30:20.401948 15760 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0613 21:30:20.402000 15760 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0613 21:30:20.402009 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.402012 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.402014 15760 net.cpp:165] Memory required for data: 1361510484
I0613 21:30:20.402019 15760 layer_factory.hpp:77] Creating layer res2b_branch2a
I0613 21:30:20.402034 15760 net.cpp:100] Creating Layer res2b_branch2a
I0613 21:30:20.402038 15760 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0613 21:30:20.402051 15760 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0613 21:30:20.402999 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.403256 15760 net.cpp:150] Setting up res2b_branch2a
I0613 21:30:20.403266 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.403270 15760 net.cpp:165] Memory required for data: 1381171284
I0613 21:30:20.403280 15760 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0613 21:30:20.403293 15760 net.cpp:100] Creating Layer bn2b_branch2a
I0613 21:30:20.403300 15760 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0613 21:30:20.403311 15760 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0613 21:30:20.403663 15760 net.cpp:150] Setting up bn2b_branch2a
I0613 21:30:20.403671 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.403672 15760 net.cpp:165] Memory required for data: 1400832084
I0613 21:30:20.403700 15760 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0613 21:30:20.403713 15760 net.cpp:100] Creating Layer scale2b_branch2a
I0613 21:30:20.403718 15760 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0613 21:30:20.403729 15760 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0613 21:30:20.403790 15760 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0613 21:30:20.404901 15760 net.cpp:150] Setting up scale2b_branch2a
I0613 21:30:20.404911 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.404913 15760 net.cpp:165] Memory required for data: 1420492884
I0613 21:30:20.404928 15760 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0613 21:30:20.404948 15760 net.cpp:100] Creating Layer res2b_branch2a_relu
I0613 21:30:20.404973 15760 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0613 21:30:20.404987 15760 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0613 21:30:20.405165 15760 net.cpp:150] Setting up res2b_branch2a_relu
I0613 21:30:20.405172 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.405174 15760 net.cpp:165] Memory required for data: 1440153684
I0613 21:30:20.405179 15760 layer_factory.hpp:77] Creating layer res2b_branch2b
I0613 21:30:20.405195 15760 net.cpp:100] Creating Layer res2b_branch2b
I0613 21:30:20.405200 15760 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0613 21:30:20.405213 15760 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0613 21:30:20.406222 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0613 21:30:20.406239 15760 net.cpp:150] Setting up res2b_branch2b
I0613 21:30:20.406246 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.406249 15760 net.cpp:165] Memory required for data: 1459814484
I0613 21:30:20.406257 15760 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0613 21:30:20.406280 15760 net.cpp:100] Creating Layer bn2b_branch2b
I0613 21:30:20.406286 15760 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0613 21:30:20.406298 15760 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0613 21:30:20.406651 15760 net.cpp:150] Setting up bn2b_branch2b
I0613 21:30:20.406657 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.406659 15760 net.cpp:165] Memory required for data: 1479475284
I0613 21:30:20.406674 15760 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0613 21:30:20.406687 15760 net.cpp:100] Creating Layer scale2b_branch2b
I0613 21:30:20.406692 15760 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0613 21:30:20.406704 15760 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0613 21:30:20.406764 15760 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0613 21:30:20.407133 15760 net.cpp:150] Setting up scale2b_branch2b
I0613 21:30:20.407140 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.407143 15760 net.cpp:165] Memory required for data: 1499136084
I0613 21:30:20.407152 15760 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0613 21:30:20.407163 15760 net.cpp:100] Creating Layer res2b_branch2b_relu
I0613 21:30:20.407168 15760 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0613 21:30:20.407178 15760 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0613 21:30:20.407578 15760 net.cpp:150] Setting up res2b_branch2b_relu
I0613 21:30:20.407588 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.407590 15760 net.cpp:165] Memory required for data: 1518796884
I0613 21:30:20.407594 15760 layer_factory.hpp:77] Creating layer res2b_branch2c
I0613 21:30:20.407608 15760 net.cpp:100] Creating Layer res2b_branch2c
I0613 21:30:20.407614 15760 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0613 21:30:20.407629 15760 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0613 21:30:20.408555 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.408808 15760 net.cpp:150] Setting up res2b_branch2c
I0613 21:30:20.408819 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.408823 15760 net.cpp:165] Memory required for data: 1597440084
I0613 21:30:20.408833 15760 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0613 21:30:20.408846 15760 net.cpp:100] Creating Layer bn2b_branch2c
I0613 21:30:20.408852 15760 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0613 21:30:20.408864 15760 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0613 21:30:20.409217 15760 net.cpp:150] Setting up bn2b_branch2c
I0613 21:30:20.409224 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.409226 15760 net.cpp:165] Memory required for data: 1676083284
I0613 21:30:20.409241 15760 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0613 21:30:20.409255 15760 net.cpp:100] Creating Layer scale2b_branch2c
I0613 21:30:20.409258 15760 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0613 21:30:20.409268 15760 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0613 21:30:20.409327 15760 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0613 21:30:20.410440 15760 net.cpp:150] Setting up scale2b_branch2c
I0613 21:30:20.410454 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.410457 15760 net.cpp:165] Memory required for data: 1754726484
I0613 21:30:20.410475 15760 layer_factory.hpp:77] Creating layer res2b
I0613 21:30:20.410493 15760 net.cpp:100] Creating Layer res2b
I0613 21:30:20.410501 15760 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0613 21:30:20.410513 15760 net.cpp:444] res2b <- res2b_branch2c
I0613 21:30:20.410522 15760 net.cpp:418] res2b -> res2b
I0613 21:30:20.410590 15760 net.cpp:150] Setting up res2b
I0613 21:30:20.410603 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.410606 15760 net.cpp:165] Memory required for data: 1833369684
I0613 21:30:20.410614 15760 layer_factory.hpp:77] Creating layer res2b_relu
I0613 21:30:20.410629 15760 net.cpp:100] Creating Layer res2b_relu
I0613 21:30:20.410636 15760 net.cpp:444] res2b_relu <- res2b
I0613 21:30:20.410650 15760 net.cpp:405] res2b_relu -> res2b (in-place)
I0613 21:30:20.410851 15760 net.cpp:150] Setting up res2b_relu
I0613 21:30:20.410858 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.410859 15760 net.cpp:165] Memory required for data: 1912012884
I0613 21:30:20.410864 15760 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0613 21:30:20.410874 15760 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0613 21:30:20.410879 15760 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0613 21:30:20.410892 15760 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0613 21:30:20.410907 15760 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0613 21:30:20.410966 15760 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0613 21:30:20.410974 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.410979 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.410981 15760 net.cpp:165] Memory required for data: 2069299284
I0613 21:30:20.410984 15760 layer_factory.hpp:77] Creating layer res2c_branch2a
I0613 21:30:20.411000 15760 net.cpp:100] Creating Layer res2c_branch2a
I0613 21:30:20.411005 15760 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0613 21:30:20.411018 15760 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0613 21:30:20.412042 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.412317 15760 net.cpp:150] Setting up res2c_branch2a
I0613 21:30:20.412328 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.412331 15760 net.cpp:165] Memory required for data: 2088960084
I0613 21:30:20.412343 15760 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0613 21:30:20.412358 15760 net.cpp:100] Creating Layer bn2c_branch2a
I0613 21:30:20.412364 15760 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0613 21:30:20.412375 15760 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0613 21:30:20.412750 15760 net.cpp:150] Setting up bn2c_branch2a
I0613 21:30:20.412757 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.412760 15760 net.cpp:165] Memory required for data: 2108620884
I0613 21:30:20.412775 15760 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0613 21:30:20.412789 15760 net.cpp:100] Creating Layer scale2c_branch2a
I0613 21:30:20.412794 15760 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0613 21:30:20.412806 15760 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0613 21:30:20.412866 15760 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0613 21:30:20.413252 15760 net.cpp:150] Setting up scale2c_branch2a
I0613 21:30:20.413261 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.413264 15760 net.cpp:165] Memory required for data: 2128281684
I0613 21:30:20.413274 15760 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0613 21:30:20.413285 15760 net.cpp:100] Creating Layer res2c_branch2a_relu
I0613 21:30:20.413290 15760 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0613 21:30:20.413298 15760 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0613 21:30:20.413460 15760 net.cpp:150] Setting up res2c_branch2a_relu
I0613 21:30:20.413466 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.413468 15760 net.cpp:165] Memory required for data: 2147942484
I0613 21:30:20.413471 15760 layer_factory.hpp:77] Creating layer res2c_branch2b
I0613 21:30:20.413487 15760 net.cpp:100] Creating Layer res2c_branch2b
I0613 21:30:20.413491 15760 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0613 21:30:20.413504 15760 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0613 21:30:20.414558 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0613 21:30:20.414824 15760 net.cpp:150] Setting up res2c_branch2b
I0613 21:30:20.414837 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.414840 15760 net.cpp:165] Memory required for data: 2167603284
I0613 21:30:20.414851 15760 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0613 21:30:20.414865 15760 net.cpp:100] Creating Layer bn2c_branch2b
I0613 21:30:20.414872 15760 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0613 21:30:20.414883 15760 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0613 21:30:20.415244 15760 net.cpp:150] Setting up bn2c_branch2b
I0613 21:30:20.415251 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.415253 15760 net.cpp:165] Memory required for data: 2187264084
I0613 21:30:20.415268 15760 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0613 21:30:20.415282 15760 net.cpp:100] Creating Layer scale2c_branch2b
I0613 21:30:20.415287 15760 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0613 21:30:20.415298 15760 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0613 21:30:20.415357 15760 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0613 21:30:20.416452 15760 net.cpp:150] Setting up scale2c_branch2b
I0613 21:30:20.416461 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.416463 15760 net.cpp:165] Memory required for data: 2206924884
I0613 21:30:20.416476 15760 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0613 21:30:20.416487 15760 net.cpp:100] Creating Layer res2c_branch2b_relu
I0613 21:30:20.416492 15760 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0613 21:30:20.416505 15760 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0613 21:30:20.416671 15760 net.cpp:150] Setting up res2c_branch2b_relu
I0613 21:30:20.416677 15760 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0613 21:30:20.416679 15760 net.cpp:165] Memory required for data: 2226585684
I0613 21:30:20.416683 15760 layer_factory.hpp:77] Creating layer res2c_branch2c
I0613 21:30:20.416700 15760 net.cpp:100] Creating Layer res2c_branch2c
I0613 21:30:20.416705 15760 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0613 21:30:20.416718 15760 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0613 21:30:20.417735 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0613 21:30:20.417997 15760 net.cpp:150] Setting up res2c_branch2c
I0613 21:30:20.418009 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.418012 15760 net.cpp:165] Memory required for data: 2305228884
I0613 21:30:20.418022 15760 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0613 21:30:20.418035 15760 net.cpp:100] Creating Layer bn2c_branch2c
I0613 21:30:20.418040 15760 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0613 21:30:20.418052 15760 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0613 21:30:20.418402 15760 net.cpp:150] Setting up bn2c_branch2c
I0613 21:30:20.418408 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.418411 15760 net.cpp:165] Memory required for data: 2383872084
I0613 21:30:20.418444 15760 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0613 21:30:20.418459 15760 net.cpp:100] Creating Layer scale2c_branch2c
I0613 21:30:20.418464 15760 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0613 21:30:20.418474 15760 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0613 21:30:20.418534 15760 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0613 21:30:20.418895 15760 net.cpp:150] Setting up scale2c_branch2c
I0613 21:30:20.418902 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.418905 15760 net.cpp:165] Memory required for data: 2462515284
I0613 21:30:20.418915 15760 layer_factory.hpp:77] Creating layer res2c
I0613 21:30:20.418926 15760 net.cpp:100] Creating Layer res2c
I0613 21:30:20.418931 15760 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0613 21:30:20.418941 15760 net.cpp:444] res2c <- res2c_branch2c
I0613 21:30:20.418949 15760 net.cpp:418] res2c -> res2c
I0613 21:30:20.418989 15760 net.cpp:150] Setting up res2c
I0613 21:30:20.418997 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.418999 15760 net.cpp:165] Memory required for data: 2541158484
I0613 21:30:20.419003 15760 layer_factory.hpp:77] Creating layer res2c_relu
I0613 21:30:20.419011 15760 net.cpp:100] Creating Layer res2c_relu
I0613 21:30:20.419016 15760 net.cpp:444] res2c_relu <- res2c
I0613 21:30:20.419028 15760 net.cpp:405] res2c_relu -> res2c (in-place)
I0613 21:30:20.419435 15760 net.cpp:150] Setting up res2c_relu
I0613 21:30:20.419445 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.419450 15760 net.cpp:165] Memory required for data: 2619801684
I0613 21:30:20.419456 15760 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0613 21:30:20.419468 15760 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0613 21:30:20.419492 15760 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0613 21:30:20.419508 15760 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0613 21:30:20.419528 15760 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0613 21:30:20.419595 15760 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0613 21:30:20.419605 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.419610 15760 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0613 21:30:20.419615 15760 net.cpp:165] Memory required for data: 2777088084
I0613 21:30:20.419620 15760 layer_factory.hpp:77] Creating layer res3a_branch1
I0613 21:30:20.419637 15760 net.cpp:100] Creating Layer res3a_branch1
I0613 21:30:20.419644 15760 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0613 21:30:20.419661 15760 net.cpp:418] res3a_branch1 -> res3a_branch1
I0613 21:30:20.420825 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0613 21:30:20.420847 15760 net.cpp:150] Setting up res3a_branch1
I0613 21:30:20.420857 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.420861 15760 net.cpp:165] Memory required for data: 2816409684
I0613 21:30:20.420876 15760 layer_factory.hpp:77] Creating layer bn3a_branch1
I0613 21:30:20.420893 15760 net.cpp:100] Creating Layer bn3a_branch1
I0613 21:30:20.420900 15760 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0613 21:30:20.420917 15760 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0613 21:30:20.421967 15760 net.cpp:150] Setting up bn3a_branch1
I0613 21:30:20.421977 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.421982 15760 net.cpp:165] Memory required for data: 2855731284
I0613 21:30:20.422003 15760 layer_factory.hpp:77] Creating layer scale3a_branch1
I0613 21:30:20.422024 15760 net.cpp:100] Creating Layer scale3a_branch1
I0613 21:30:20.422030 15760 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0613 21:30:20.422046 15760 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0613 21:30:20.422111 15760 layer_factory.hpp:77] Creating layer scale3a_branch1
I0613 21:30:20.422328 15760 net.cpp:150] Setting up scale3a_branch1
I0613 21:30:20.422338 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.422340 15760 net.cpp:165] Memory required for data: 2895052884
I0613 21:30:20.422353 15760 layer_factory.hpp:77] Creating layer res3a_branch2a
I0613 21:30:20.422371 15760 net.cpp:100] Creating Layer res3a_branch2a
I0613 21:30:20.422379 15760 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0613 21:30:20.422396 15760 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0613 21:30:20.423429 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0613 21:30:20.423450 15760 net.cpp:150] Setting up res3a_branch2a
I0613 21:30:20.423460 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.423463 15760 net.cpp:165] Memory required for data: 2904883284
I0613 21:30:20.423476 15760 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0613 21:30:20.423492 15760 net.cpp:100] Creating Layer bn3a_branch2a
I0613 21:30:20.423499 15760 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0613 21:30:20.423516 15760 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0613 21:30:20.423790 15760 net.cpp:150] Setting up bn3a_branch2a
I0613 21:30:20.423799 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.423801 15760 net.cpp:165] Memory required for data: 2914713684
I0613 21:30:20.423820 15760 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0613 21:30:20.423835 15760 net.cpp:100] Creating Layer scale3a_branch2a
I0613 21:30:20.423841 15760 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0613 21:30:20.423856 15760 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0613 21:30:20.423921 15760 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0613 21:30:20.424130 15760 net.cpp:150] Setting up scale3a_branch2a
I0613 21:30:20.424139 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.424141 15760 net.cpp:165] Memory required for data: 2924544084
I0613 21:30:20.424154 15760 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0613 21:30:20.424167 15760 net.cpp:100] Creating Layer res3a_branch2a_relu
I0613 21:30:20.424173 15760 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0613 21:30:20.424188 15760 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0613 21:30:20.424336 15760 net.cpp:150] Setting up res3a_branch2a_relu
I0613 21:30:20.424345 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.424348 15760 net.cpp:165] Memory required for data: 2934374484
I0613 21:30:20.424353 15760 layer_factory.hpp:77] Creating layer res3a_branch2b
I0613 21:30:20.424371 15760 net.cpp:100] Creating Layer res3a_branch2b
I0613 21:30:20.424377 15760 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0613 21:30:20.424396 15760 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0613 21:30:20.426355 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0613 21:30:20.426631 15760 net.cpp:150] Setting up res3a_branch2b
I0613 21:30:20.426646 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.426651 15760 net.cpp:165] Memory required for data: 2944204884
I0613 21:30:20.426666 15760 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0613 21:30:20.426687 15760 net.cpp:100] Creating Layer bn3a_branch2b
I0613 21:30:20.426694 15760 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0613 21:30:20.426712 15760 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0613 21:30:20.426998 15760 net.cpp:150] Setting up bn3a_branch2b
I0613 21:30:20.427007 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.427011 15760 net.cpp:165] Memory required for data: 2954035284
I0613 21:30:20.427029 15760 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0613 21:30:20.427055 15760 net.cpp:100] Creating Layer scale3a_branch2b
I0613 21:30:20.427062 15760 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0613 21:30:20.427078 15760 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0613 21:30:20.427146 15760 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0613 21:30:20.427357 15760 net.cpp:150] Setting up scale3a_branch2b
I0613 21:30:20.427366 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.427369 15760 net.cpp:165] Memory required for data: 2963865684
I0613 21:30:20.427384 15760 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0613 21:30:20.427398 15760 net.cpp:100] Creating Layer res3a_branch2b_relu
I0613 21:30:20.427404 15760 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0613 21:30:20.427418 15760 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0613 21:30:20.427570 15760 net.cpp:150] Setting up res3a_branch2b_relu
I0613 21:30:20.427578 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.427582 15760 net.cpp:165] Memory required for data: 2973696084
I0613 21:30:20.427587 15760 layer_factory.hpp:77] Creating layer res3a_branch2c
I0613 21:30:20.427606 15760 net.cpp:100] Creating Layer res3a_branch2c
I0613 21:30:20.427613 15760 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0613 21:30:20.427628 15760 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0613 21:30:20.428683 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.428699 15760 net.cpp:150] Setting up res3a_branch2c
I0613 21:30:20.428709 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.428712 15760 net.cpp:165] Memory required for data: 3013017684
I0613 21:30:20.428725 15760 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0613 21:30:20.428741 15760 net.cpp:100] Creating Layer bn3a_branch2c
I0613 21:30:20.428748 15760 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0613 21:30:20.428766 15760 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0613 21:30:20.429060 15760 net.cpp:150] Setting up bn3a_branch2c
I0613 21:30:20.429069 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.429072 15760 net.cpp:165] Memory required for data: 3052339284
I0613 21:30:20.429090 15760 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0613 21:30:20.429105 15760 net.cpp:100] Creating Layer scale3a_branch2c
I0613 21:30:20.429112 15760 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0613 21:30:20.429128 15760 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0613 21:30:20.429189 15760 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0613 21:30:20.429406 15760 net.cpp:150] Setting up scale3a_branch2c
I0613 21:30:20.429414 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.429417 15760 net.cpp:165] Memory required for data: 3091660884
I0613 21:30:20.429430 15760 layer_factory.hpp:77] Creating layer res3a
I0613 21:30:20.429443 15760 net.cpp:100] Creating Layer res3a
I0613 21:30:20.429450 15760 net.cpp:444] res3a <- res3a_branch1
I0613 21:30:20.429462 15760 net.cpp:444] res3a <- res3a_branch2c
I0613 21:30:20.429476 15760 net.cpp:418] res3a -> res3a
I0613 21:30:20.429518 15760 net.cpp:150] Setting up res3a
I0613 21:30:20.429527 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.429533 15760 net.cpp:165] Memory required for data: 3130982484
I0613 21:30:20.429538 15760 layer_factory.hpp:77] Creating layer res3a_relu
I0613 21:30:20.429550 15760 net.cpp:100] Creating Layer res3a_relu
I0613 21:30:20.429556 15760 net.cpp:444] res3a_relu <- res3a
I0613 21:30:20.429570 15760 net.cpp:405] res3a_relu -> res3a (in-place)
I0613 21:30:20.429986 15760 net.cpp:150] Setting up res3a_relu
I0613 21:30:20.429996 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.430001 15760 net.cpp:165] Memory required for data: 3170304084
I0613 21:30:20.430006 15760 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0613 21:30:20.430019 15760 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0613 21:30:20.430027 15760 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0613 21:30:20.430042 15760 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0613 21:30:20.430060 15760 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0613 21:30:20.430124 15760 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0613 21:30:20.430132 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.430138 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.430143 15760 net.cpp:165] Memory required for data: 3248947284
I0613 21:30:20.430148 15760 layer_factory.hpp:77] Creating layer res3b_branch2a
I0613 21:30:20.430166 15760 net.cpp:100] Creating Layer res3b_branch2a
I0613 21:30:20.430171 15760 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0613 21:30:20.430188 15760 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0613 21:30:20.431267 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.431288 15760 net.cpp:150] Setting up res3b_branch2a
I0613 21:30:20.431298 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.431303 15760 net.cpp:165] Memory required for data: 3258777684
I0613 21:30:20.431315 15760 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0613 21:30:20.431332 15760 net.cpp:100] Creating Layer bn3b_branch2a
I0613 21:30:20.431339 15760 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0613 21:30:20.431363 15760 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0613 21:30:20.431650 15760 net.cpp:150] Setting up bn3b_branch2a
I0613 21:30:20.431658 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.431661 15760 net.cpp:165] Memory required for data: 3268608084
I0613 21:30:20.431680 15760 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0613 21:30:20.431697 15760 net.cpp:100] Creating Layer scale3b_branch2a
I0613 21:30:20.431704 15760 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0613 21:30:20.431720 15760 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0613 21:30:20.431787 15760 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0613 21:30:20.432778 15760 net.cpp:150] Setting up scale3b_branch2a
I0613 21:30:20.432788 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.432792 15760 net.cpp:165] Memory required for data: 3278438484
I0613 21:30:20.432808 15760 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0613 21:30:20.432822 15760 net.cpp:100] Creating Layer res3b_branch2a_relu
I0613 21:30:20.432831 15760 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0613 21:30:20.432844 15760 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0613 21:30:20.433029 15760 net.cpp:150] Setting up res3b_branch2a_relu
I0613 21:30:20.433038 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.433042 15760 net.cpp:165] Memory required for data: 3288268884
I0613 21:30:20.433048 15760 layer_factory.hpp:77] Creating layer res3b_branch2b
I0613 21:30:20.433068 15760 net.cpp:100] Creating Layer res3b_branch2b
I0613 21:30:20.433074 15760 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0613 21:30:20.433090 15760 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0613 21:30:20.434589 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0613 21:30:20.434864 15760 net.cpp:150] Setting up res3b_branch2b
I0613 21:30:20.434880 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.434885 15760 net.cpp:165] Memory required for data: 3298099284
I0613 21:30:20.434898 15760 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0613 21:30:20.434916 15760 net.cpp:100] Creating Layer bn3b_branch2b
I0613 21:30:20.434923 15760 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0613 21:30:20.434942 15760 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0613 21:30:20.435233 15760 net.cpp:150] Setting up bn3b_branch2b
I0613 21:30:20.435241 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.435245 15760 net.cpp:165] Memory required for data: 3307929684
I0613 21:30:20.435264 15760 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0613 21:30:20.435281 15760 net.cpp:100] Creating Layer scale3b_branch2b
I0613 21:30:20.435288 15760 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0613 21:30:20.435303 15760 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0613 21:30:20.435371 15760 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0613 21:30:20.435582 15760 net.cpp:150] Setting up scale3b_branch2b
I0613 21:30:20.435590 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.435595 15760 net.cpp:165] Memory required for data: 3317760084
I0613 21:30:20.435607 15760 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0613 21:30:20.435619 15760 net.cpp:100] Creating Layer res3b_branch2b_relu
I0613 21:30:20.435626 15760 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0613 21:30:20.435639 15760 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0613 21:30:20.435798 15760 net.cpp:150] Setting up res3b_branch2b_relu
I0613 21:30:20.435807 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.435811 15760 net.cpp:165] Memory required for data: 3327590484
I0613 21:30:20.435817 15760 layer_factory.hpp:77] Creating layer res3b_branch2c
I0613 21:30:20.435834 15760 net.cpp:100] Creating Layer res3b_branch2c
I0613 21:30:20.435842 15760 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0613 21:30:20.435859 15760 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0613 21:30:20.436921 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.436952 15760 net.cpp:150] Setting up res3b_branch2c
I0613 21:30:20.436962 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.436966 15760 net.cpp:165] Memory required for data: 3366912084
I0613 21:30:20.436980 15760 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0613 21:30:20.436995 15760 net.cpp:100] Creating Layer bn3b_branch2c
I0613 21:30:20.437003 15760 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0613 21:30:20.437018 15760 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0613 21:30:20.437305 15760 net.cpp:150] Setting up bn3b_branch2c
I0613 21:30:20.437314 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.437317 15760 net.cpp:165] Memory required for data: 3406233684
I0613 21:30:20.437335 15760 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0613 21:30:20.437350 15760 net.cpp:100] Creating Layer scale3b_branch2c
I0613 21:30:20.437357 15760 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0613 21:30:20.437372 15760 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0613 21:30:20.437434 15760 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0613 21:30:20.437652 15760 net.cpp:150] Setting up scale3b_branch2c
I0613 21:30:20.437660 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.437664 15760 net.cpp:165] Memory required for data: 3445555284
I0613 21:30:20.437676 15760 layer_factory.hpp:77] Creating layer res3b
I0613 21:30:20.437690 15760 net.cpp:100] Creating Layer res3b
I0613 21:30:20.437696 15760 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0613 21:30:20.437708 15760 net.cpp:444] res3b <- res3b_branch2c
I0613 21:30:20.437721 15760 net.cpp:418] res3b -> res3b
I0613 21:30:20.437764 15760 net.cpp:150] Setting up res3b
I0613 21:30:20.437774 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.437778 15760 net.cpp:165] Memory required for data: 3484876884
I0613 21:30:20.437783 15760 layer_factory.hpp:77] Creating layer res3b_relu
I0613 21:30:20.437795 15760 net.cpp:100] Creating Layer res3b_relu
I0613 21:30:20.437801 15760 net.cpp:444] res3b_relu <- res3b
I0613 21:30:20.437814 15760 net.cpp:405] res3b_relu -> res3b (in-place)
I0613 21:30:20.438223 15760 net.cpp:150] Setting up res3b_relu
I0613 21:30:20.438233 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.438236 15760 net.cpp:165] Memory required for data: 3524198484
I0613 21:30:20.438242 15760 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0613 21:30:20.438256 15760 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0613 21:30:20.438263 15760 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0613 21:30:20.438279 15760 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0613 21:30:20.438297 15760 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0613 21:30:20.438360 15760 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0613 21:30:20.438369 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.438376 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.438380 15760 net.cpp:165] Memory required for data: 3602841684
I0613 21:30:20.438385 15760 layer_factory.hpp:77] Creating layer res3c_branch2a
I0613 21:30:20.438402 15760 net.cpp:100] Creating Layer res3c_branch2a
I0613 21:30:20.438410 15760 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0613 21:30:20.438426 15760 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0613 21:30:20.439467 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.439488 15760 net.cpp:150] Setting up res3c_branch2a
I0613 21:30:20.439497 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.439502 15760 net.cpp:165] Memory required for data: 3612672084
I0613 21:30:20.439513 15760 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0613 21:30:20.439529 15760 net.cpp:100] Creating Layer bn3c_branch2a
I0613 21:30:20.439537 15760 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0613 21:30:20.439553 15760 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0613 21:30:20.439836 15760 net.cpp:150] Setting up bn3c_branch2a
I0613 21:30:20.439844 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.439847 15760 net.cpp:165] Memory required for data: 3622502484
I0613 21:30:20.439865 15760 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0613 21:30:20.439882 15760 net.cpp:100] Creating Layer scale3c_branch2a
I0613 21:30:20.439888 15760 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0613 21:30:20.439903 15760 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0613 21:30:20.439967 15760 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0613 21:30:20.440176 15760 net.cpp:150] Setting up scale3c_branch2a
I0613 21:30:20.440184 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.440187 15760 net.cpp:165] Memory required for data: 3632332884
I0613 21:30:20.440201 15760 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0613 21:30:20.440212 15760 net.cpp:100] Creating Layer res3c_branch2a_relu
I0613 21:30:20.440218 15760 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0613 21:30:20.440233 15760 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0613 21:30:20.440382 15760 net.cpp:150] Setting up res3c_branch2a_relu
I0613 21:30:20.440388 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.440392 15760 net.cpp:165] Memory required for data: 3642163284
I0613 21:30:20.440398 15760 layer_factory.hpp:77] Creating layer res3c_branch2b
I0613 21:30:20.440414 15760 net.cpp:100] Creating Layer res3c_branch2b
I0613 21:30:20.440421 15760 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0613 21:30:20.440438 15760 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0613 21:30:20.441642 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0613 21:30:20.441920 15760 net.cpp:150] Setting up res3c_branch2b
I0613 21:30:20.441933 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.441938 15760 net.cpp:165] Memory required for data: 3651993684
I0613 21:30:20.441952 15760 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0613 21:30:20.441969 15760 net.cpp:100] Creating Layer bn3c_branch2b
I0613 21:30:20.441977 15760 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0613 21:30:20.441994 15760 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0613 21:30:20.442286 15760 net.cpp:150] Setting up bn3c_branch2b
I0613 21:30:20.442293 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.442297 15760 net.cpp:165] Memory required for data: 3661824084
I0613 21:30:20.442315 15760 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0613 21:30:20.442330 15760 net.cpp:100] Creating Layer scale3c_branch2b
I0613 21:30:20.442337 15760 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0613 21:30:20.442353 15760 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0613 21:30:20.442420 15760 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0613 21:30:20.442632 15760 net.cpp:150] Setting up scale3c_branch2b
I0613 21:30:20.442641 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.442643 15760 net.cpp:165] Memory required for data: 3671654484
I0613 21:30:20.442656 15760 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0613 21:30:20.442669 15760 net.cpp:100] Creating Layer res3c_branch2b_relu
I0613 21:30:20.442675 15760 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0613 21:30:20.442689 15760 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0613 21:30:20.442847 15760 net.cpp:150] Setting up res3c_branch2b_relu
I0613 21:30:20.442855 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.442858 15760 net.cpp:165] Memory required for data: 3681484884
I0613 21:30:20.442864 15760 layer_factory.hpp:77] Creating layer res3c_branch2c
I0613 21:30:20.442883 15760 net.cpp:100] Creating Layer res3c_branch2c
I0613 21:30:20.442889 15760 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0613 21:30:20.442906 15760 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0613 21:30:20.443989 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.444005 15760 net.cpp:150] Setting up res3c_branch2c
I0613 21:30:20.444015 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.444020 15760 net.cpp:165] Memory required for data: 3720806484
I0613 21:30:20.444032 15760 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0613 21:30:20.444051 15760 net.cpp:100] Creating Layer bn3c_branch2c
I0613 21:30:20.444058 15760 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0613 21:30:20.444074 15760 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0613 21:30:20.444368 15760 net.cpp:150] Setting up bn3c_branch2c
I0613 21:30:20.444376 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.444380 15760 net.cpp:165] Memory required for data: 3760128084
I0613 21:30:20.444399 15760 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0613 21:30:20.444416 15760 net.cpp:100] Creating Layer scale3c_branch2c
I0613 21:30:20.444423 15760 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0613 21:30:20.444439 15760 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0613 21:30:20.444504 15760 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0613 21:30:20.444725 15760 net.cpp:150] Setting up scale3c_branch2c
I0613 21:30:20.444733 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.444736 15760 net.cpp:165] Memory required for data: 3799449684
I0613 21:30:20.444749 15760 layer_factory.hpp:77] Creating layer res3c
I0613 21:30:20.444762 15760 net.cpp:100] Creating Layer res3c
I0613 21:30:20.444770 15760 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0613 21:30:20.444782 15760 net.cpp:444] res3c <- res3c_branch2c
I0613 21:30:20.444793 15760 net.cpp:418] res3c -> res3c
I0613 21:30:20.444839 15760 net.cpp:150] Setting up res3c
I0613 21:30:20.444849 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.444852 15760 net.cpp:165] Memory required for data: 3838771284
I0613 21:30:20.444859 15760 layer_factory.hpp:77] Creating layer res3c_relu
I0613 21:30:20.444870 15760 net.cpp:100] Creating Layer res3c_relu
I0613 21:30:20.444876 15760 net.cpp:444] res3c_relu <- res3c
I0613 21:30:20.444890 15760 net.cpp:405] res3c_relu -> res3c (in-place)
I0613 21:30:20.445047 15760 net.cpp:150] Setting up res3c_relu
I0613 21:30:20.445055 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.445058 15760 net.cpp:165] Memory required for data: 3878092884
I0613 21:30:20.445065 15760 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0613 21:30:20.445077 15760 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0613 21:30:20.445083 15760 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0613 21:30:20.445099 15760 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0613 21:30:20.445116 15760 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0613 21:30:20.445178 15760 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0613 21:30:20.445188 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.445194 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.445197 15760 net.cpp:165] Memory required for data: 3956736084
I0613 21:30:20.445204 15760 layer_factory.hpp:77] Creating layer res3d_branch2a
I0613 21:30:20.445220 15760 net.cpp:100] Creating Layer res3d_branch2a
I0613 21:30:20.445227 15760 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0613 21:30:20.445245 15760 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0613 21:30:20.447088 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.447110 15760 net.cpp:150] Setting up res3d_branch2a
I0613 21:30:20.447119 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.447124 15760 net.cpp:165] Memory required for data: 3966566484
I0613 21:30:20.447136 15760 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0613 21:30:20.447154 15760 net.cpp:100] Creating Layer bn3d_branch2a
I0613 21:30:20.447162 15760 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0613 21:30:20.447180 15760 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0613 21:30:20.447469 15760 net.cpp:150] Setting up bn3d_branch2a
I0613 21:30:20.447477 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.447480 15760 net.cpp:165] Memory required for data: 3976396884
I0613 21:30:20.447525 15760 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0613 21:30:20.447543 15760 net.cpp:100] Creating Layer scale3d_branch2a
I0613 21:30:20.447551 15760 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0613 21:30:20.447564 15760 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0613 21:30:20.447635 15760 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0613 21:30:20.447851 15760 net.cpp:150] Setting up scale3d_branch2a
I0613 21:30:20.447860 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.447862 15760 net.cpp:165] Memory required for data: 3986227284
I0613 21:30:20.447876 15760 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0613 21:30:20.447888 15760 net.cpp:100] Creating Layer res3d_branch2a_relu
I0613 21:30:20.447896 15760 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0613 21:30:20.447911 15760 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0613 21:30:20.448379 15760 net.cpp:150] Setting up res3d_branch2a_relu
I0613 21:30:20.448388 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.448391 15760 net.cpp:165] Memory required for data: 3996057684
I0613 21:30:20.448397 15760 layer_factory.hpp:77] Creating layer res3d_branch2b
I0613 21:30:20.448418 15760 net.cpp:100] Creating Layer res3d_branch2b
I0613 21:30:20.448426 15760 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0613 21:30:20.448444 15760 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0613 21:30:20.450464 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0613 21:30:20.450738 15760 net.cpp:150] Setting up res3d_branch2b
I0613 21:30:20.450754 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.450758 15760 net.cpp:165] Memory required for data: 4005888084
I0613 21:30:20.450774 15760 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0613 21:30:20.450796 15760 net.cpp:100] Creating Layer bn3d_branch2b
I0613 21:30:20.450804 15760 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0613 21:30:20.450821 15760 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0613 21:30:20.451124 15760 net.cpp:150] Setting up bn3d_branch2b
I0613 21:30:20.451133 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.451135 15760 net.cpp:165] Memory required for data: 4015718484
I0613 21:30:20.451154 15760 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0613 21:30:20.451174 15760 net.cpp:100] Creating Layer scale3d_branch2b
I0613 21:30:20.451180 15760 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0613 21:30:20.451195 15760 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0613 21:30:20.451269 15760 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0613 21:30:20.451490 15760 net.cpp:150] Setting up scale3d_branch2b
I0613 21:30:20.451499 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.451503 15760 net.cpp:165] Memory required for data: 4025548884
I0613 21:30:20.451515 15760 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0613 21:30:20.451529 15760 net.cpp:100] Creating Layer res3d_branch2b_relu
I0613 21:30:20.451534 15760 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0613 21:30:20.451550 15760 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0613 21:30:20.451723 15760 net.cpp:150] Setting up res3d_branch2b_relu
I0613 21:30:20.451731 15760 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0613 21:30:20.451735 15760 net.cpp:165] Memory required for data: 4035379284
I0613 21:30:20.451740 15760 layer_factory.hpp:77] Creating layer res3d_branch2c
I0613 21:30:20.451761 15760 net.cpp:100] Creating Layer res3d_branch2c
I0613 21:30:20.451767 15760 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0613 21:30:20.451786 15760 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0613 21:30:20.452927 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0613 21:30:20.452950 15760 net.cpp:150] Setting up res3d_branch2c
I0613 21:30:20.452962 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.452965 15760 net.cpp:165] Memory required for data: 4074700884
I0613 21:30:20.452980 15760 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0613 21:30:20.452997 15760 net.cpp:100] Creating Layer bn3d_branch2c
I0613 21:30:20.453004 15760 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0613 21:30:20.453021 15760 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0613 21:30:20.453317 15760 net.cpp:150] Setting up bn3d_branch2c
I0613 21:30:20.453325 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.453328 15760 net.cpp:165] Memory required for data: 4114022484
I0613 21:30:20.453346 15760 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0613 21:30:20.453363 15760 net.cpp:100] Creating Layer scale3d_branch2c
I0613 21:30:20.453371 15760 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0613 21:30:20.453385 15760 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0613 21:30:20.453449 15760 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0613 21:30:20.453670 15760 net.cpp:150] Setting up scale3d_branch2c
I0613 21:30:20.453677 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.453680 15760 net.cpp:165] Memory required for data: 4153344084
I0613 21:30:20.453693 15760 layer_factory.hpp:77] Creating layer res3d
I0613 21:30:20.453706 15760 net.cpp:100] Creating Layer res3d
I0613 21:30:20.453713 15760 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0613 21:30:20.453725 15760 net.cpp:444] res3d <- res3d_branch2c
I0613 21:30:20.453737 15760 net.cpp:418] res3d -> res3d
I0613 21:30:20.453783 15760 net.cpp:150] Setting up res3d
I0613 21:30:20.453793 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.453796 15760 net.cpp:165] Memory required for data: 4192665684
I0613 21:30:20.453802 15760 layer_factory.hpp:77] Creating layer res3d_relu
I0613 21:30:20.453814 15760 net.cpp:100] Creating Layer res3d_relu
I0613 21:30:20.453820 15760 net.cpp:444] res3d_relu <- res3d
I0613 21:30:20.453835 15760 net.cpp:405] res3d_relu -> res3d (in-place)
I0613 21:30:20.453987 15760 net.cpp:150] Setting up res3d_relu
I0613 21:30:20.453995 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.453999 15760 net.cpp:165] Memory required for data: 4231987284
I0613 21:30:20.454005 15760 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0613 21:30:20.454016 15760 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0613 21:30:20.454023 15760 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0613 21:30:20.454037 15760 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0613 21:30:20.454056 15760 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0613 21:30:20.454118 15760 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0613 21:30:20.454128 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.454133 15760 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0613 21:30:20.454138 15760 net.cpp:165] Memory required for data: 4310630484
I0613 21:30:20.454143 15760 layer_factory.hpp:77] Creating layer res4a_branch1
I0613 21:30:20.454160 15760 net.cpp:100] Creating Layer res4a_branch1
I0613 21:30:20.454167 15760 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0613 21:30:20.454183 15760 net.cpp:418] res4a_branch1 -> res4a_branch1
I0613 21:30:20.456661 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0613 21:30:20.456934 15760 net.cpp:150] Setting up res4a_branch1
I0613 21:30:20.456953 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.456957 15760 net.cpp:165] Memory required for data: 4330291284
I0613 21:30:20.456972 15760 layer_factory.hpp:77] Creating layer bn4a_branch1
I0613 21:30:20.456992 15760 net.cpp:100] Creating Layer bn4a_branch1
I0613 21:30:20.457000 15760 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0613 21:30:20.457020 15760 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0613 21:30:20.457306 15760 net.cpp:150] Setting up bn4a_branch1
I0613 21:30:20.457314 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.457317 15760 net.cpp:165] Memory required for data: 4349952084
I0613 21:30:20.457336 15760 layer_factory.hpp:77] Creating layer scale4a_branch1
I0613 21:30:20.457352 15760 net.cpp:100] Creating Layer scale4a_branch1
I0613 21:30:20.457358 15760 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0613 21:30:20.457375 15760 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0613 21:30:20.457440 15760 layer_factory.hpp:77] Creating layer scale4a_branch1
I0613 21:30:20.457641 15760 net.cpp:150] Setting up scale4a_branch1
I0613 21:30:20.457649 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.457653 15760 net.cpp:165] Memory required for data: 4369612884
I0613 21:30:20.457665 15760 layer_factory.hpp:77] Creating layer res4a_branch2a
I0613 21:30:20.457684 15760 net.cpp:100] Creating Layer res4a_branch2a
I0613 21:30:20.457691 15760 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0613 21:30:20.457707 15760 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0613 21:30:20.458876 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0613 21:30:20.458900 15760 net.cpp:150] Setting up res4a_branch2a
I0613 21:30:20.458909 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.458914 15760 net.cpp:165] Memory required for data: 4374528084
I0613 21:30:20.458927 15760 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0613 21:30:20.458943 15760 net.cpp:100] Creating Layer bn4a_branch2a
I0613 21:30:20.458950 15760 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0613 21:30:20.458968 15760 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0613 21:30:20.459251 15760 net.cpp:150] Setting up bn4a_branch2a
I0613 21:30:20.459259 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.459262 15760 net.cpp:165] Memory required for data: 4379443284
I0613 21:30:20.459280 15760 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0613 21:30:20.459295 15760 net.cpp:100] Creating Layer scale4a_branch2a
I0613 21:30:20.459301 15760 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0613 21:30:20.459317 15760 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0613 21:30:20.459385 15760 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0613 21:30:20.459576 15760 net.cpp:150] Setting up scale4a_branch2a
I0613 21:30:20.459584 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.459587 15760 net.cpp:165] Memory required for data: 4384358484
I0613 21:30:20.459600 15760 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0613 21:30:20.459614 15760 net.cpp:100] Creating Layer res4a_branch2a_relu
I0613 21:30:20.459619 15760 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0613 21:30:20.459635 15760 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0613 21:30:20.460089 15760 net.cpp:150] Setting up res4a_branch2a_relu
I0613 21:30:20.460100 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.460103 15760 net.cpp:165] Memory required for data: 4389273684
I0613 21:30:20.460109 15760 layer_factory.hpp:77] Creating layer res4a_branch2b
I0613 21:30:20.460137 15760 net.cpp:100] Creating Layer res4a_branch2b
I0613 21:30:20.460145 15760 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0613 21:30:20.460165 15760 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0613 21:30:20.464349 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0613 21:30:20.464646 15760 net.cpp:150] Setting up res4a_branch2b
I0613 21:30:20.464664 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.464668 15760 net.cpp:165] Memory required for data: 4394188884
I0613 21:30:20.464687 15760 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0613 21:30:20.464715 15760 net.cpp:100] Creating Layer bn4a_branch2b
I0613 21:30:20.464725 15760 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0613 21:30:20.464745 15760 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0613 21:30:20.465078 15760 net.cpp:150] Setting up bn4a_branch2b
I0613 21:30:20.465087 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.465091 15760 net.cpp:165] Memory required for data: 4399104084
I0613 21:30:20.465111 15760 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0613 21:30:20.465131 15760 net.cpp:100] Creating Layer scale4a_branch2b
I0613 21:30:20.465137 15760 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0613 21:30:20.465152 15760 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0613 21:30:20.465225 15760 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0613 21:30:20.465422 15760 net.cpp:150] Setting up scale4a_branch2b
I0613 21:30:20.465431 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.465435 15760 net.cpp:165] Memory required for data: 4404019284
I0613 21:30:20.465448 15760 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0613 21:30:20.465462 15760 net.cpp:100] Creating Layer res4a_branch2b_relu
I0613 21:30:20.465469 15760 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0613 21:30:20.465483 15760 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0613 21:30:20.465648 15760 net.cpp:150] Setting up res4a_branch2b_relu
I0613 21:30:20.465657 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.465661 15760 net.cpp:165] Memory required for data: 4408934484
I0613 21:30:20.465667 15760 layer_factory.hpp:77] Creating layer res4a_branch2c
I0613 21:30:20.465685 15760 net.cpp:100] Creating Layer res4a_branch2c
I0613 21:30:20.465692 15760 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0613 21:30:20.465709 15760 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0613 21:30:20.467897 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.467923 15760 net.cpp:150] Setting up res4a_branch2c
I0613 21:30:20.467936 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.467939 15760 net.cpp:165] Memory required for data: 4428595284
I0613 21:30:20.467954 15760 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0613 21:30:20.467977 15760 net.cpp:100] Creating Layer bn4a_branch2c
I0613 21:30:20.467984 15760 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0613 21:30:20.468003 15760 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0613 21:30:20.468308 15760 net.cpp:150] Setting up bn4a_branch2c
I0613 21:30:20.468317 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.468320 15760 net.cpp:165] Memory required for data: 4448256084
I0613 21:30:20.468340 15760 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0613 21:30:20.468356 15760 net.cpp:100] Creating Layer scale4a_branch2c
I0613 21:30:20.468364 15760 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0613 21:30:20.468379 15760 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0613 21:30:20.468446 15760 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0613 21:30:20.468649 15760 net.cpp:150] Setting up scale4a_branch2c
I0613 21:30:20.468657 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.468662 15760 net.cpp:165] Memory required for data: 4467916884
I0613 21:30:20.468673 15760 layer_factory.hpp:77] Creating layer res4a
I0613 21:30:20.468701 15760 net.cpp:100] Creating Layer res4a
I0613 21:30:20.468709 15760 net.cpp:444] res4a <- res4a_branch1
I0613 21:30:20.468721 15760 net.cpp:444] res4a <- res4a_branch2c
I0613 21:30:20.468734 15760 net.cpp:418] res4a -> res4a
I0613 21:30:20.468780 15760 net.cpp:150] Setting up res4a
I0613 21:30:20.468791 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.468794 15760 net.cpp:165] Memory required for data: 4487577684
I0613 21:30:20.468802 15760 layer_factory.hpp:77] Creating layer res4a_relu
I0613 21:30:20.468814 15760 net.cpp:100] Creating Layer res4a_relu
I0613 21:30:20.468821 15760 net.cpp:444] res4a_relu <- res4a
I0613 21:30:20.468833 15760 net.cpp:405] res4a_relu -> res4a (in-place)
I0613 21:30:20.468998 15760 net.cpp:150] Setting up res4a_relu
I0613 21:30:20.469007 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.469010 15760 net.cpp:165] Memory required for data: 4507238484
I0613 21:30:20.469017 15760 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0613 21:30:20.469029 15760 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0613 21:30:20.469035 15760 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0613 21:30:20.469050 15760 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0613 21:30:20.469067 15760 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0613 21:30:20.469131 15760 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0613 21:30:20.469142 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.469148 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.469152 15760 net.cpp:165] Memory required for data: 4546560084
I0613 21:30:20.469157 15760 layer_factory.hpp:77] Creating layer res4b_branch2a
I0613 21:30:20.469175 15760 net.cpp:100] Creating Layer res4b_branch2a
I0613 21:30:20.469182 15760 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0613 21:30:20.469198 15760 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0613 21:30:20.470607 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.470631 15760 net.cpp:150] Setting up res4b_branch2a
I0613 21:30:20.470643 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.470645 15760 net.cpp:165] Memory required for data: 4551475284
I0613 21:30:20.470659 15760 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0613 21:30:20.470675 15760 net.cpp:100] Creating Layer bn4b_branch2a
I0613 21:30:20.470682 15760 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0613 21:30:20.470700 15760 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0613 21:30:20.470985 15760 net.cpp:150] Setting up bn4b_branch2a
I0613 21:30:20.470994 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.470999 15760 net.cpp:165] Memory required for data: 4556390484
I0613 21:30:20.471016 15760 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0613 21:30:20.471031 15760 net.cpp:100] Creating Layer scale4b_branch2a
I0613 21:30:20.471037 15760 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0613 21:30:20.471053 15760 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0613 21:30:20.471124 15760 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0613 21:30:20.471321 15760 net.cpp:150] Setting up scale4b_branch2a
I0613 21:30:20.471329 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.471333 15760 net.cpp:165] Memory required for data: 4561305684
I0613 21:30:20.471345 15760 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0613 21:30:20.471357 15760 net.cpp:100] Creating Layer res4b_branch2a_relu
I0613 21:30:20.471364 15760 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0613 21:30:20.471377 15760 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0613 21:30:20.471818 15760 net.cpp:150] Setting up res4b_branch2a_relu
I0613 21:30:20.471828 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.471832 15760 net.cpp:165] Memory required for data: 4566220884
I0613 21:30:20.471838 15760 layer_factory.hpp:77] Creating layer res4b_branch2b
I0613 21:30:20.471856 15760 net.cpp:100] Creating Layer res4b_branch2b
I0613 21:30:20.471863 15760 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0613 21:30:20.471882 15760 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0613 21:30:20.474602 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0613 21:30:20.474900 15760 net.cpp:150] Setting up res4b_branch2b
I0613 21:30:20.474915 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.474920 15760 net.cpp:165] Memory required for data: 4571136084
I0613 21:30:20.474936 15760 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0613 21:30:20.474957 15760 net.cpp:100] Creating Layer bn4b_branch2b
I0613 21:30:20.474967 15760 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0613 21:30:20.474985 15760 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0613 21:30:20.475288 15760 net.cpp:150] Setting up bn4b_branch2b
I0613 21:30:20.475296 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.475299 15760 net.cpp:165] Memory required for data: 4576051284
I0613 21:30:20.475319 15760 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0613 21:30:20.475337 15760 net.cpp:100] Creating Layer scale4b_branch2b
I0613 21:30:20.475344 15760 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0613 21:30:20.475358 15760 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0613 21:30:20.475430 15760 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0613 21:30:20.475630 15760 net.cpp:150] Setting up scale4b_branch2b
I0613 21:30:20.475638 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.475641 15760 net.cpp:165] Memory required for data: 4580966484
I0613 21:30:20.475654 15760 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0613 21:30:20.475667 15760 net.cpp:100] Creating Layer res4b_branch2b_relu
I0613 21:30:20.475673 15760 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0613 21:30:20.475688 15760 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0613 21:30:20.475852 15760 net.cpp:150] Setting up res4b_branch2b_relu
I0613 21:30:20.475859 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.475863 15760 net.cpp:165] Memory required for data: 4585881684
I0613 21:30:20.475869 15760 layer_factory.hpp:77] Creating layer res4b_branch2c
I0613 21:30:20.475888 15760 net.cpp:100] Creating Layer res4b_branch2c
I0613 21:30:20.475894 15760 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0613 21:30:20.475911 15760 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0613 21:30:20.478091 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.478121 15760 net.cpp:150] Setting up res4b_branch2c
I0613 21:30:20.478132 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.478135 15760 net.cpp:165] Memory required for data: 4605542484
I0613 21:30:20.478150 15760 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0613 21:30:20.478170 15760 net.cpp:100] Creating Layer bn4b_branch2c
I0613 21:30:20.478179 15760 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0613 21:30:20.478195 15760 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0613 21:30:20.478502 15760 net.cpp:150] Setting up bn4b_branch2c
I0613 21:30:20.478509 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.478513 15760 net.cpp:165] Memory required for data: 4625203284
I0613 21:30:20.478533 15760 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0613 21:30:20.478550 15760 net.cpp:100] Creating Layer scale4b_branch2c
I0613 21:30:20.478557 15760 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0613 21:30:20.478571 15760 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0613 21:30:20.478641 15760 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0613 21:30:20.478847 15760 net.cpp:150] Setting up scale4b_branch2c
I0613 21:30:20.478855 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.478859 15760 net.cpp:165] Memory required for data: 4644864084
I0613 21:30:20.478873 15760 layer_factory.hpp:77] Creating layer res4b
I0613 21:30:20.478886 15760 net.cpp:100] Creating Layer res4b
I0613 21:30:20.478893 15760 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0613 21:30:20.478905 15760 net.cpp:444] res4b <- res4b_branch2c
I0613 21:30:20.478917 15760 net.cpp:418] res4b -> res4b
I0613 21:30:20.478965 15760 net.cpp:150] Setting up res4b
I0613 21:30:20.478974 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.478978 15760 net.cpp:165] Memory required for data: 4664524884
I0613 21:30:20.478984 15760 layer_factory.hpp:77] Creating layer res4b_relu
I0613 21:30:20.478997 15760 net.cpp:100] Creating Layer res4b_relu
I0613 21:30:20.479003 15760 net.cpp:444] res4b_relu <- res4b
I0613 21:30:20.479017 15760 net.cpp:405] res4b_relu -> res4b (in-place)
I0613 21:30:20.479176 15760 net.cpp:150] Setting up res4b_relu
I0613 21:30:20.479183 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.479187 15760 net.cpp:165] Memory required for data: 4684185684
I0613 21:30:20.479192 15760 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0613 21:30:20.479204 15760 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0613 21:30:20.479212 15760 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0613 21:30:20.479228 15760 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0613 21:30:20.479244 15760 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0613 21:30:20.479308 15760 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0613 21:30:20.479318 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.479324 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.479328 15760 net.cpp:165] Memory required for data: 4723507284
I0613 21:30:20.479334 15760 layer_factory.hpp:77] Creating layer res4c_branch2a
I0613 21:30:20.479352 15760 net.cpp:100] Creating Layer res4c_branch2a
I0613 21:30:20.479358 15760 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0613 21:30:20.479375 15760 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0613 21:30:20.480917 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.480959 15760 net.cpp:150] Setting up res4c_branch2a
I0613 21:30:20.480975 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.480979 15760 net.cpp:165] Memory required for data: 4728422484
I0613 21:30:20.480999 15760 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0613 21:30:20.481024 15760 net.cpp:100] Creating Layer bn4c_branch2a
I0613 21:30:20.481034 15760 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0613 21:30:20.481053 15760 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0613 21:30:20.481359 15760 net.cpp:150] Setting up bn4c_branch2a
I0613 21:30:20.481366 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.481370 15760 net.cpp:165] Memory required for data: 4733337684
I0613 21:30:20.481389 15760 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0613 21:30:20.481405 15760 net.cpp:100] Creating Layer scale4c_branch2a
I0613 21:30:20.481412 15760 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0613 21:30:20.481427 15760 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0613 21:30:20.481501 15760 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0613 21:30:20.481703 15760 net.cpp:150] Setting up scale4c_branch2a
I0613 21:30:20.481711 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.481714 15760 net.cpp:165] Memory required for data: 4738252884
I0613 21:30:20.481727 15760 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0613 21:30:20.481740 15760 net.cpp:100] Creating Layer res4c_branch2a_relu
I0613 21:30:20.481746 15760 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0613 21:30:20.481761 15760 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0613 21:30:20.481921 15760 net.cpp:150] Setting up res4c_branch2a_relu
I0613 21:30:20.481930 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.481932 15760 net.cpp:165] Memory required for data: 4743168084
I0613 21:30:20.481938 15760 layer_factory.hpp:77] Creating layer res4c_branch2b
I0613 21:30:20.481957 15760 net.cpp:100] Creating Layer res4c_branch2b
I0613 21:30:20.481964 15760 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0613 21:30:20.481983 15760 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0613 21:30:20.485302 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0613 21:30:20.485599 15760 net.cpp:150] Setting up res4c_branch2b
I0613 21:30:20.485618 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.485622 15760 net.cpp:165] Memory required for data: 4748083284
I0613 21:30:20.485644 15760 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0613 21:30:20.485671 15760 net.cpp:100] Creating Layer bn4c_branch2b
I0613 21:30:20.485683 15760 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0613 21:30:20.485704 15760 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0613 21:30:20.486030 15760 net.cpp:150] Setting up bn4c_branch2b
I0613 21:30:20.486039 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.486042 15760 net.cpp:165] Memory required for data: 4752998484
I0613 21:30:20.486063 15760 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0613 21:30:20.486081 15760 net.cpp:100] Creating Layer scale4c_branch2b
I0613 21:30:20.486088 15760 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0613 21:30:20.486104 15760 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0613 21:30:20.486177 15760 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0613 21:30:20.486380 15760 net.cpp:150] Setting up scale4c_branch2b
I0613 21:30:20.486388 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.486392 15760 net.cpp:165] Memory required for data: 4757913684
I0613 21:30:20.486404 15760 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0613 21:30:20.486418 15760 net.cpp:100] Creating Layer res4c_branch2b_relu
I0613 21:30:20.486423 15760 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0613 21:30:20.486439 15760 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0613 21:30:20.486871 15760 net.cpp:150] Setting up res4c_branch2b_relu
I0613 21:30:20.486881 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.486884 15760 net.cpp:165] Memory required for data: 4762828884
I0613 21:30:20.486891 15760 layer_factory.hpp:77] Creating layer res4c_branch2c
I0613 21:30:20.486912 15760 net.cpp:100] Creating Layer res4c_branch2c
I0613 21:30:20.486918 15760 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0613 21:30:20.486937 15760 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0613 21:30:20.489100 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.489128 15760 net.cpp:150] Setting up res4c_branch2c
I0613 21:30:20.489140 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.489145 15760 net.cpp:165] Memory required for data: 4782489684
I0613 21:30:20.489158 15760 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0613 21:30:20.489177 15760 net.cpp:100] Creating Layer bn4c_branch2c
I0613 21:30:20.489186 15760 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0613 21:30:20.489203 15760 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0613 21:30:20.489512 15760 net.cpp:150] Setting up bn4c_branch2c
I0613 21:30:20.489521 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.489523 15760 net.cpp:165] Memory required for data: 4802150484
I0613 21:30:20.489542 15760 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0613 21:30:20.489559 15760 net.cpp:100] Creating Layer scale4c_branch2c
I0613 21:30:20.489567 15760 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0613 21:30:20.489580 15760 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0613 21:30:20.489648 15760 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0613 21:30:20.489856 15760 net.cpp:150] Setting up scale4c_branch2c
I0613 21:30:20.489864 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.489868 15760 net.cpp:165] Memory required for data: 4821811284
I0613 21:30:20.489881 15760 layer_factory.hpp:77] Creating layer res4c
I0613 21:30:20.489895 15760 net.cpp:100] Creating Layer res4c
I0613 21:30:20.489902 15760 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0613 21:30:20.489915 15760 net.cpp:444] res4c <- res4c_branch2c
I0613 21:30:20.489928 15760 net.cpp:418] res4c -> res4c
I0613 21:30:20.489975 15760 net.cpp:150] Setting up res4c
I0613 21:30:20.489984 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.489989 15760 net.cpp:165] Memory required for data: 4841472084
I0613 21:30:20.489995 15760 layer_factory.hpp:77] Creating layer res4c_relu
I0613 21:30:20.490006 15760 net.cpp:100] Creating Layer res4c_relu
I0613 21:30:20.490012 15760 net.cpp:444] res4c_relu <- res4c
I0613 21:30:20.490025 15760 net.cpp:405] res4c_relu -> res4c (in-place)
I0613 21:30:20.490183 15760 net.cpp:150] Setting up res4c_relu
I0613 21:30:20.490191 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.490195 15760 net.cpp:165] Memory required for data: 4861132884
I0613 21:30:20.490200 15760 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0613 21:30:20.490211 15760 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0613 21:30:20.490218 15760 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0613 21:30:20.490234 15760 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0613 21:30:20.490252 15760 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0613 21:30:20.490317 15760 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0613 21:30:20.490327 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.490334 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.490337 15760 net.cpp:165] Memory required for data: 4900454484
I0613 21:30:20.490342 15760 layer_factory.hpp:77] Creating layer res4d_branch2a
I0613 21:30:20.490360 15760 net.cpp:100] Creating Layer res4d_branch2a
I0613 21:30:20.490367 15760 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0613 21:30:20.490384 15760 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0613 21:30:20.491776 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.491801 15760 net.cpp:150] Setting up res4d_branch2a
I0613 21:30:20.491811 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.491814 15760 net.cpp:165] Memory required for data: 4905369684
I0613 21:30:20.491827 15760 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0613 21:30:20.491842 15760 net.cpp:100] Creating Layer bn4d_branch2a
I0613 21:30:20.491849 15760 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0613 21:30:20.491866 15760 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0613 21:30:20.492179 15760 net.cpp:150] Setting up bn4d_branch2a
I0613 21:30:20.492187 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.492190 15760 net.cpp:165] Memory required for data: 4910284884
I0613 21:30:20.492209 15760 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0613 21:30:20.492226 15760 net.cpp:100] Creating Layer scale4d_branch2a
I0613 21:30:20.492233 15760 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0613 21:30:20.492249 15760 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0613 21:30:20.492321 15760 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0613 21:30:20.492524 15760 net.cpp:150] Setting up scale4d_branch2a
I0613 21:30:20.492533 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.492537 15760 net.cpp:165] Memory required for data: 4915200084
I0613 21:30:20.492549 15760 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0613 21:30:20.492561 15760 net.cpp:100] Creating Layer res4d_branch2a_relu
I0613 21:30:20.492568 15760 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0613 21:30:20.492583 15760 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0613 21:30:20.492740 15760 net.cpp:150] Setting up res4d_branch2a_relu
I0613 21:30:20.492748 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.492751 15760 net.cpp:165] Memory required for data: 4920115284
I0613 21:30:20.492758 15760 layer_factory.hpp:77] Creating layer res4d_branch2b
I0613 21:30:20.492775 15760 net.cpp:100] Creating Layer res4d_branch2b
I0613 21:30:20.492782 15760 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0613 21:30:20.492800 15760 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0613 21:30:20.495538 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0613 21:30:20.495848 15760 net.cpp:150] Setting up res4d_branch2b
I0613 21:30:20.495867 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.495870 15760 net.cpp:165] Memory required for data: 4925030484
I0613 21:30:20.495892 15760 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0613 21:30:20.495916 15760 net.cpp:100] Creating Layer bn4d_branch2b
I0613 21:30:20.495928 15760 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0613 21:30:20.495946 15760 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0613 21:30:20.496266 15760 net.cpp:150] Setting up bn4d_branch2b
I0613 21:30:20.496274 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.496279 15760 net.cpp:165] Memory required for data: 4929945684
I0613 21:30:20.496299 15760 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0613 21:30:20.496316 15760 net.cpp:100] Creating Layer scale4d_branch2b
I0613 21:30:20.496323 15760 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0613 21:30:20.496338 15760 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0613 21:30:20.496412 15760 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0613 21:30:20.496623 15760 net.cpp:150] Setting up scale4d_branch2b
I0613 21:30:20.496631 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.496634 15760 net.cpp:165] Memory required for data: 4934860884
I0613 21:30:20.496647 15760 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0613 21:30:20.496661 15760 net.cpp:100] Creating Layer res4d_branch2b_relu
I0613 21:30:20.496668 15760 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0613 21:30:20.496681 15760 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0613 21:30:20.497138 15760 net.cpp:150] Setting up res4d_branch2b_relu
I0613 21:30:20.497148 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.497151 15760 net.cpp:165] Memory required for data: 4939776084
I0613 21:30:20.497157 15760 layer_factory.hpp:77] Creating layer res4d_branch2c
I0613 21:30:20.497179 15760 net.cpp:100] Creating Layer res4d_branch2c
I0613 21:30:20.497186 15760 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0613 21:30:20.497205 15760 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0613 21:30:20.499686 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.499718 15760 net.cpp:150] Setting up res4d_branch2c
I0613 21:30:20.499733 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.499737 15760 net.cpp:165] Memory required for data: 4959436884
I0613 21:30:20.499755 15760 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0613 21:30:20.499781 15760 net.cpp:100] Creating Layer bn4d_branch2c
I0613 21:30:20.499792 15760 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0613 21:30:20.499814 15760 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0613 21:30:20.500134 15760 net.cpp:150] Setting up bn4d_branch2c
I0613 21:30:20.500142 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.500146 15760 net.cpp:165] Memory required for data: 4979097684
I0613 21:30:20.500165 15760 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0613 21:30:20.500185 15760 net.cpp:100] Creating Layer scale4d_branch2c
I0613 21:30:20.500191 15760 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0613 21:30:20.500207 15760 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0613 21:30:20.500282 15760 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0613 21:30:20.500502 15760 net.cpp:150] Setting up scale4d_branch2c
I0613 21:30:20.500511 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.500514 15760 net.cpp:165] Memory required for data: 4998758484
I0613 21:30:20.500527 15760 layer_factory.hpp:77] Creating layer res4d
I0613 21:30:20.500540 15760 net.cpp:100] Creating Layer res4d
I0613 21:30:20.500548 15760 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0613 21:30:20.500560 15760 net.cpp:444] res4d <- res4d_branch2c
I0613 21:30:20.500572 15760 net.cpp:418] res4d -> res4d
I0613 21:30:20.500622 15760 net.cpp:150] Setting up res4d
I0613 21:30:20.500633 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.500636 15760 net.cpp:165] Memory required for data: 5018419284
I0613 21:30:20.500643 15760 layer_factory.hpp:77] Creating layer res4d_relu
I0613 21:30:20.500653 15760 net.cpp:100] Creating Layer res4d_relu
I0613 21:30:20.500659 15760 net.cpp:444] res4d_relu <- res4d
I0613 21:30:20.500674 15760 net.cpp:405] res4d_relu -> res4d (in-place)
I0613 21:30:20.500843 15760 net.cpp:150] Setting up res4d_relu
I0613 21:30:20.500850 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.500854 15760 net.cpp:165] Memory required for data: 5038080084
I0613 21:30:20.500859 15760 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0613 21:30:20.500871 15760 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0613 21:30:20.500877 15760 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0613 21:30:20.500893 15760 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0613 21:30:20.500911 15760 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0613 21:30:20.501006 15760 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0613 21:30:20.501016 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.501024 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.501027 15760 net.cpp:165] Memory required for data: 5077401684
I0613 21:30:20.501032 15760 layer_factory.hpp:77] Creating layer res4e_branch2a
I0613 21:30:20.501051 15760 net.cpp:100] Creating Layer res4e_branch2a
I0613 21:30:20.501058 15760 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0613 21:30:20.501076 15760 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0613 21:30:20.502589 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.502616 15760 net.cpp:150] Setting up res4e_branch2a
I0613 21:30:20.502627 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.502631 15760 net.cpp:165] Memory required for data: 5082316884
I0613 21:30:20.502645 15760 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0613 21:30:20.502661 15760 net.cpp:100] Creating Layer bn4e_branch2a
I0613 21:30:20.502668 15760 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0613 21:30:20.502686 15760 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0613 21:30:20.502996 15760 net.cpp:150] Setting up bn4e_branch2a
I0613 21:30:20.503005 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.503007 15760 net.cpp:165] Memory required for data: 5087232084
I0613 21:30:20.503027 15760 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0613 21:30:20.503044 15760 net.cpp:100] Creating Layer scale4e_branch2a
I0613 21:30:20.503052 15760 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0613 21:30:20.503067 15760 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0613 21:30:20.503140 15760 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0613 21:30:20.503346 15760 net.cpp:150] Setting up scale4e_branch2a
I0613 21:30:20.503355 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.503357 15760 net.cpp:165] Memory required for data: 5092147284
I0613 21:30:20.503371 15760 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0613 21:30:20.503383 15760 net.cpp:100] Creating Layer res4e_branch2a_relu
I0613 21:30:20.503389 15760 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0613 21:30:20.503406 15760 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0613 21:30:20.503561 15760 net.cpp:150] Setting up res4e_branch2a_relu
I0613 21:30:20.503568 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.503572 15760 net.cpp:165] Memory required for data: 5097062484
I0613 21:30:20.503577 15760 layer_factory.hpp:77] Creating layer res4e_branch2b
I0613 21:30:20.503597 15760 net.cpp:100] Creating Layer res4e_branch2b
I0613 21:30:20.503603 15760 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0613 21:30:20.503620 15760 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0613 21:30:20.506366 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0613 21:30:20.506665 15760 net.cpp:150] Setting up res4e_branch2b
I0613 21:30:20.506680 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.506683 15760 net.cpp:165] Memory required for data: 5101977684
I0613 21:30:20.506700 15760 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0613 21:30:20.506722 15760 net.cpp:100] Creating Layer bn4e_branch2b
I0613 21:30:20.506731 15760 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0613 21:30:20.506750 15760 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0613 21:30:20.507064 15760 net.cpp:150] Setting up bn4e_branch2b
I0613 21:30:20.507073 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.507076 15760 net.cpp:165] Memory required for data: 5106892884
I0613 21:30:20.507097 15760 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0613 21:30:20.507113 15760 net.cpp:100] Creating Layer scale4e_branch2b
I0613 21:30:20.507120 15760 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0613 21:30:20.507135 15760 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0613 21:30:20.507210 15760 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0613 21:30:20.507418 15760 net.cpp:150] Setting up scale4e_branch2b
I0613 21:30:20.507427 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.507431 15760 net.cpp:165] Memory required for data: 5111808084
I0613 21:30:20.507443 15760 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0613 21:30:20.507457 15760 net.cpp:100] Creating Layer res4e_branch2b_relu
I0613 21:30:20.507464 15760 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0613 21:30:20.507478 15760 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0613 21:30:20.507913 15760 net.cpp:150] Setting up res4e_branch2b_relu
I0613 21:30:20.507922 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.507926 15760 net.cpp:165] Memory required for data: 5116723284
I0613 21:30:20.507932 15760 layer_factory.hpp:77] Creating layer res4e_branch2c
I0613 21:30:20.507951 15760 net.cpp:100] Creating Layer res4e_branch2c
I0613 21:30:20.507959 15760 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0613 21:30:20.507978 15760 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0613 21:30:20.510179 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.510208 15760 net.cpp:150] Setting up res4e_branch2c
I0613 21:30:20.510221 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.510224 15760 net.cpp:165] Memory required for data: 5136384084
I0613 21:30:20.510239 15760 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0613 21:30:20.510262 15760 net.cpp:100] Creating Layer bn4e_branch2c
I0613 21:30:20.510270 15760 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0613 21:30:20.510289 15760 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0613 21:30:20.510612 15760 net.cpp:150] Setting up bn4e_branch2c
I0613 21:30:20.510620 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.510625 15760 net.cpp:165] Memory required for data: 5156044884
I0613 21:30:20.510644 15760 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0613 21:30:20.510660 15760 net.cpp:100] Creating Layer scale4e_branch2c
I0613 21:30:20.510666 15760 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0613 21:30:20.510682 15760 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0613 21:30:20.510753 15760 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0613 21:30:20.510969 15760 net.cpp:150] Setting up scale4e_branch2c
I0613 21:30:20.510977 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.510980 15760 net.cpp:165] Memory required for data: 5175705684
I0613 21:30:20.510993 15760 layer_factory.hpp:77] Creating layer res4e
I0613 21:30:20.511006 15760 net.cpp:100] Creating Layer res4e
I0613 21:30:20.511013 15760 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0613 21:30:20.511025 15760 net.cpp:444] res4e <- res4e_branch2c
I0613 21:30:20.511037 15760 net.cpp:418] res4e -> res4e
I0613 21:30:20.511086 15760 net.cpp:150] Setting up res4e
I0613 21:30:20.511096 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.511101 15760 net.cpp:165] Memory required for data: 5195366484
I0613 21:30:20.511106 15760 layer_factory.hpp:77] Creating layer res4e_relu
I0613 21:30:20.511118 15760 net.cpp:100] Creating Layer res4e_relu
I0613 21:30:20.511124 15760 net.cpp:444] res4e_relu <- res4e
I0613 21:30:20.511138 15760 net.cpp:405] res4e_relu -> res4e (in-place)
I0613 21:30:20.511296 15760 net.cpp:150] Setting up res4e_relu
I0613 21:30:20.511304 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.511307 15760 net.cpp:165] Memory required for data: 5215027284
I0613 21:30:20.511312 15760 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0613 21:30:20.511325 15760 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0613 21:30:20.511332 15760 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0613 21:30:20.511348 15760 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0613 21:30:20.511364 15760 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0613 21:30:20.511432 15760 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0613 21:30:20.511441 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.511448 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.511452 15760 net.cpp:165] Memory required for data: 5254348884
I0613 21:30:20.511457 15760 layer_factory.hpp:77] Creating layer res4f_branch2a
I0613 21:30:20.511476 15760 net.cpp:100] Creating Layer res4f_branch2a
I0613 21:30:20.511482 15760 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0613 21:30:20.511499 15760 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0613 21:30:20.513105 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.513142 15760 net.cpp:150] Setting up res4f_branch2a
I0613 21:30:20.513159 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.513162 15760 net.cpp:165] Memory required for data: 5259264084
I0613 21:30:20.513185 15760 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0613 21:30:20.513214 15760 net.cpp:100] Creating Layer bn4f_branch2a
I0613 21:30:20.513226 15760 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0613 21:30:20.513247 15760 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0613 21:30:20.513577 15760 net.cpp:150] Setting up bn4f_branch2a
I0613 21:30:20.513586 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.513589 15760 net.cpp:165] Memory required for data: 5264179284
I0613 21:30:20.513608 15760 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0613 21:30:20.513628 15760 net.cpp:100] Creating Layer scale4f_branch2a
I0613 21:30:20.513634 15760 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0613 21:30:20.513649 15760 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0613 21:30:20.513725 15760 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0613 21:30:20.513936 15760 net.cpp:150] Setting up scale4f_branch2a
I0613 21:30:20.513944 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.513947 15760 net.cpp:165] Memory required for data: 5269094484
I0613 21:30:20.513960 15760 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0613 21:30:20.513973 15760 net.cpp:100] Creating Layer res4f_branch2a_relu
I0613 21:30:20.513980 15760 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0613 21:30:20.513995 15760 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0613 21:30:20.514163 15760 net.cpp:150] Setting up res4f_branch2a_relu
I0613 21:30:20.514170 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.514173 15760 net.cpp:165] Memory required for data: 5274009684
I0613 21:30:20.514178 15760 layer_factory.hpp:77] Creating layer res4f_branch2b
I0613 21:30:20.514199 15760 net.cpp:100] Creating Layer res4f_branch2b
I0613 21:30:20.514205 15760 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0613 21:30:20.514223 15760 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0613 21:30:20.517066 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0613 21:30:20.517408 15760 net.cpp:150] Setting up res4f_branch2b
I0613 21:30:20.517431 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.517434 15760 net.cpp:165] Memory required for data: 5278924884
I0613 21:30:20.517457 15760 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0613 21:30:20.517488 15760 net.cpp:100] Creating Layer bn4f_branch2b
I0613 21:30:20.517499 15760 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0613 21:30:20.517522 15760 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0613 21:30:20.517863 15760 net.cpp:150] Setting up bn4f_branch2b
I0613 21:30:20.517870 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.517875 15760 net.cpp:165] Memory required for data: 5283840084
I0613 21:30:20.517896 15760 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0613 21:30:20.517915 15760 net.cpp:100] Creating Layer scale4f_branch2b
I0613 21:30:20.517922 15760 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0613 21:30:20.517937 15760 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0613 21:30:20.518013 15760 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0613 21:30:20.518229 15760 net.cpp:150] Setting up scale4f_branch2b
I0613 21:30:20.518239 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.518244 15760 net.cpp:165] Memory required for data: 5288755284
I0613 21:30:20.518256 15760 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0613 21:30:20.518268 15760 net.cpp:100] Creating Layer res4f_branch2b_relu
I0613 21:30:20.518275 15760 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0613 21:30:20.518290 15760 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0613 21:30:20.518462 15760 net.cpp:150] Setting up res4f_branch2b_relu
I0613 21:30:20.518471 15760 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0613 21:30:20.518476 15760 net.cpp:165] Memory required for data: 5293670484
I0613 21:30:20.518482 15760 layer_factory.hpp:77] Creating layer res4f_branch2c
I0613 21:30:20.518501 15760 net.cpp:100] Creating Layer res4f_branch2c
I0613 21:30:20.518507 15760 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0613 21:30:20.518525 15760 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0613 21:30:20.523643 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.523679 15760 net.cpp:150] Setting up res4f_branch2c
I0613 21:30:20.523705 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.523708 15760 net.cpp:165] Memory required for data: 5313331284
I0613 21:30:20.523727 15760 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0613 21:30:20.523752 15760 net.cpp:100] Creating Layer bn4f_branch2c
I0613 21:30:20.523764 15760 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0613 21:30:20.523784 15760 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0613 21:30:20.524122 15760 net.cpp:150] Setting up bn4f_branch2c
I0613 21:30:20.524130 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.524134 15760 net.cpp:165] Memory required for data: 5332992084
I0613 21:30:20.524200 15760 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0613 21:30:20.524220 15760 net.cpp:100] Creating Layer scale4f_branch2c
I0613 21:30:20.524227 15760 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0613 21:30:20.524242 15760 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0613 21:30:20.524317 15760 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0613 21:30:20.524540 15760 net.cpp:150] Setting up scale4f_branch2c
I0613 21:30:20.524549 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.524554 15760 net.cpp:165] Memory required for data: 5352652884
I0613 21:30:20.524566 15760 layer_factory.hpp:77] Creating layer res4f
I0613 21:30:20.524580 15760 net.cpp:100] Creating Layer res4f
I0613 21:30:20.524587 15760 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0613 21:30:20.524600 15760 net.cpp:444] res4f <- res4f_branch2c
I0613 21:30:20.524612 15760 net.cpp:418] res4f -> res4f
I0613 21:30:20.524663 15760 net.cpp:150] Setting up res4f
I0613 21:30:20.524674 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.524678 15760 net.cpp:165] Memory required for data: 5372313684
I0613 21:30:20.524683 15760 layer_factory.hpp:77] Creating layer res4f_relu
I0613 21:30:20.524695 15760 net.cpp:100] Creating Layer res4f_relu
I0613 21:30:20.524703 15760 net.cpp:444] res4f_relu <- res4f
I0613 21:30:20.524716 15760 net.cpp:405] res4f_relu -> res4f (in-place)
I0613 21:30:20.525270 15760 net.cpp:150] Setting up res4f_relu
I0613 21:30:20.525281 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.525285 15760 net.cpp:165] Memory required for data: 5391974484
I0613 21:30:20.525290 15760 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0613 21:30:20.525306 15760 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0613 21:30:20.525315 15760 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0613 21:30:20.525331 15760 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0613 21:30:20.525351 15760 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0613 21:30:20.525365 15760 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0613 21:30:20.525460 15760 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0613 21:30:20.525470 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.525476 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.525482 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:20.525485 15760 net.cpp:165] Memory required for data: 5450956884
I0613 21:30:20.525491 15760 layer_factory.hpp:77] Creating layer res5a_branch1
I0613 21:30:20.525511 15760 net.cpp:100] Creating Layer res5a_branch1
I0613 21:30:20.525517 15760 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0613 21:30:20.525535 15760 net.cpp:418] res5a_branch1 -> res5a_branch1
I0613 21:30:20.531718 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0613 21:30:20.531757 15760 net.cpp:150] Setting up res5a_branch1
I0613 21:30:20.531776 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.531780 15760 net.cpp:165] Memory required for data: 5490278484
I0613 21:30:20.531805 15760 layer_factory.hpp:77] Creating layer bn5a_branch1
I0613 21:30:20.531836 15760 net.cpp:100] Creating Layer bn5a_branch1
I0613 21:30:20.531849 15760 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0613 21:30:20.531872 15760 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0613 21:30:20.532217 15760 net.cpp:150] Setting up bn5a_branch1
I0613 21:30:20.532225 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.532228 15760 net.cpp:165] Memory required for data: 5529600084
I0613 21:30:20.532248 15760 layer_factory.hpp:77] Creating layer scale5a_branch1
I0613 21:30:20.532268 15760 net.cpp:100] Creating Layer scale5a_branch1
I0613 21:30:20.532274 15760 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0613 21:30:20.532289 15760 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0613 21:30:20.532368 15760 layer_factory.hpp:77] Creating layer scale5a_branch1
I0613 21:30:20.532610 15760 net.cpp:150] Setting up scale5a_branch1
I0613 21:30:20.532619 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.532622 15760 net.cpp:165] Memory required for data: 5568921684
I0613 21:30:20.532635 15760 layer_factory.hpp:77] Creating layer res5a_branch2a
I0613 21:30:20.532656 15760 net.cpp:100] Creating Layer res5a_branch2a
I0613 21:30:20.532665 15760 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0613 21:30:20.532681 15760 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0613 21:30:20.535393 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.535423 15760 net.cpp:150] Setting up res5a_branch2a
I0613 21:30:20.535435 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.535439 15760 net.cpp:165] Memory required for data: 5578752084
I0613 21:30:20.535454 15760 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0613 21:30:20.535473 15760 net.cpp:100] Creating Layer bn5a_branch2a
I0613 21:30:20.535481 15760 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0613 21:30:20.535498 15760 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0613 21:30:20.535826 15760 net.cpp:150] Setting up bn5a_branch2a
I0613 21:30:20.535835 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.535837 15760 net.cpp:165] Memory required for data: 5588582484
I0613 21:30:20.535856 15760 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0613 21:30:20.535873 15760 net.cpp:100] Creating Layer scale5a_branch2a
I0613 21:30:20.535881 15760 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0613 21:30:20.535895 15760 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0613 21:30:20.535969 15760 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0613 21:30:20.536187 15760 net.cpp:150] Setting up scale5a_branch2a
I0613 21:30:20.536196 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.536200 15760 net.cpp:165] Memory required for data: 5598412884
I0613 21:30:20.536212 15760 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0613 21:30:20.536226 15760 net.cpp:100] Creating Layer res5a_branch2a_relu
I0613 21:30:20.536232 15760 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0613 21:30:20.536247 15760 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0613 21:30:20.536407 15760 net.cpp:150] Setting up res5a_branch2a_relu
I0613 21:30:20.536415 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.536419 15760 net.cpp:165] Memory required for data: 5608243284
I0613 21:30:20.536424 15760 layer_factory.hpp:77] Creating layer res5a_branch2b
I0613 21:30:20.536442 15760 net.cpp:100] Creating Layer res5a_branch2b
I0613 21:30:20.536449 15760 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0613 21:30:20.536468 15760 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0613 21:30:20.542372 15760 net.cpp:150] Setting up res5a_branch2b
I0613 21:30:20.542405 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.542409 15760 net.cpp:165] Memory required for data: 5618073684
I0613 21:30:20.542436 15760 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0613 21:30:20.542471 15760 net.cpp:100] Creating Layer bn5a_branch2b
I0613 21:30:20.542484 15760 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0613 21:30:20.542508 15760 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0613 21:30:20.542876 15760 net.cpp:150] Setting up bn5a_branch2b
I0613 21:30:20.542887 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.542891 15760 net.cpp:165] Memory required for data: 5627904084
I0613 21:30:20.542912 15760 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0613 21:30:20.542932 15760 net.cpp:100] Creating Layer scale5a_branch2b
I0613 21:30:20.542938 15760 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0613 21:30:20.542954 15760 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0613 21:30:20.543030 15760 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0613 21:30:20.543251 15760 net.cpp:150] Setting up scale5a_branch2b
I0613 21:30:20.543260 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.543263 15760 net.cpp:165] Memory required for data: 5637734484
I0613 21:30:20.543275 15760 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0613 21:30:20.543288 15760 net.cpp:100] Creating Layer res5a_branch2b_relu
I0613 21:30:20.543295 15760 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0613 21:30:20.543309 15760 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0613 21:30:20.543520 15760 net.cpp:150] Setting up res5a_branch2b_relu
I0613 21:30:20.543529 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.543532 15760 net.cpp:165] Memory required for data: 5647564884
I0613 21:30:20.543537 15760 layer_factory.hpp:77] Creating layer res5a_branch2c
I0613 21:30:20.543556 15760 net.cpp:100] Creating Layer res5a_branch2c
I0613 21:30:20.543565 15760 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0613 21:30:20.543582 15760 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0613 21:30:20.547650 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0613 21:30:20.547691 15760 net.cpp:150] Setting up res5a_branch2c
I0613 21:30:20.547708 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.547711 15760 net.cpp:165] Memory required for data: 5686886484
I0613 21:30:20.547736 15760 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0613 21:30:20.547766 15760 net.cpp:100] Creating Layer bn5a_branch2c
I0613 21:30:20.547780 15760 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0613 21:30:20.547804 15760 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0613 21:30:20.548167 15760 net.cpp:150] Setting up bn5a_branch2c
I0613 21:30:20.548177 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.548180 15760 net.cpp:165] Memory required for data: 5726208084
I0613 21:30:20.548202 15760 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0613 21:30:20.548219 15760 net.cpp:100] Creating Layer scale5a_branch2c
I0613 21:30:20.548226 15760 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0613 21:30:20.548243 15760 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0613 21:30:20.548321 15760 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0613 21:30:20.548552 15760 net.cpp:150] Setting up scale5a_branch2c
I0613 21:30:20.548560 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.548564 15760 net.cpp:165] Memory required for data: 5765529684
I0613 21:30:20.548578 15760 layer_factory.hpp:77] Creating layer res5a
I0613 21:30:20.548590 15760 net.cpp:100] Creating Layer res5a
I0613 21:30:20.548597 15760 net.cpp:444] res5a <- res5a_branch1
I0613 21:30:20.548610 15760 net.cpp:444] res5a <- res5a_branch2c
I0613 21:30:20.548622 15760 net.cpp:418] res5a -> res5a
I0613 21:30:20.548673 15760 net.cpp:150] Setting up res5a
I0613 21:30:20.548683 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.548688 15760 net.cpp:165] Memory required for data: 5804851284
I0613 21:30:20.548693 15760 layer_factory.hpp:77] Creating layer res5a_relu
I0613 21:30:20.548707 15760 net.cpp:100] Creating Layer res5a_relu
I0613 21:30:20.548713 15760 net.cpp:444] res5a_relu <- res5a
I0613 21:30:20.548727 15760 net.cpp:405] res5a_relu -> res5a (in-place)
I0613 21:30:20.549243 15760 net.cpp:150] Setting up res5a_relu
I0613 21:30:20.549253 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.549257 15760 net.cpp:165] Memory required for data: 5844172884
I0613 21:30:20.549263 15760 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0613 21:30:20.549278 15760 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0613 21:30:20.549284 15760 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0613 21:30:20.549301 15760 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0613 21:30:20.549320 15760 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0613 21:30:20.549391 15760 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0613 21:30:20.549401 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.549407 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.549412 15760 net.cpp:165] Memory required for data: 5922816084
I0613 21:30:20.549417 15760 layer_factory.hpp:77] Creating layer res5b_branch2a
I0613 21:30:20.549437 15760 net.cpp:100] Creating Layer res5b_branch2a
I0613 21:30:20.549443 15760 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0613 21:30:20.549460 15760 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0613 21:30:20.553426 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.553459 15760 net.cpp:150] Setting up res5b_branch2a
I0613 21:30:20.553477 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.553480 15760 net.cpp:165] Memory required for data: 5932646484
I0613 21:30:20.553503 15760 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0613 21:30:20.553535 15760 net.cpp:100] Creating Layer bn5b_branch2a
I0613 21:30:20.553548 15760 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0613 21:30:20.553572 15760 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0613 21:30:20.553920 15760 net.cpp:150] Setting up bn5b_branch2a
I0613 21:30:20.553930 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.553934 15760 net.cpp:165] Memory required for data: 5942476884
I0613 21:30:20.553953 15760 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0613 21:30:20.553970 15760 net.cpp:100] Creating Layer scale5b_branch2a
I0613 21:30:20.553977 15760 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0613 21:30:20.553992 15760 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0613 21:30:20.554066 15760 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0613 21:30:20.554293 15760 net.cpp:150] Setting up scale5b_branch2a
I0613 21:30:20.554301 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.554304 15760 net.cpp:165] Memory required for data: 5952307284
I0613 21:30:20.554319 15760 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0613 21:30:20.554332 15760 net.cpp:100] Creating Layer res5b_branch2a_relu
I0613 21:30:20.554339 15760 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0613 21:30:20.554352 15760 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0613 21:30:20.554519 15760 net.cpp:150] Setting up res5b_branch2a_relu
I0613 21:30:20.554528 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.554531 15760 net.cpp:165] Memory required for data: 5962137684
I0613 21:30:20.554538 15760 layer_factory.hpp:77] Creating layer res5b_branch2b
I0613 21:30:20.554556 15760 net.cpp:100] Creating Layer res5b_branch2b
I0613 21:30:20.554564 15760 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0613 21:30:20.554580 15760 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0613 21:30:20.560493 15760 net.cpp:150] Setting up res5b_branch2b
I0613 21:30:20.560525 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.560529 15760 net.cpp:165] Memory required for data: 5971968084
I0613 21:30:20.560554 15760 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0613 21:30:20.560588 15760 net.cpp:100] Creating Layer bn5b_branch2b
I0613 21:30:20.560603 15760 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0613 21:30:20.560626 15760 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0613 21:30:20.561002 15760 net.cpp:150] Setting up bn5b_branch2b
I0613 21:30:20.561010 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.561014 15760 net.cpp:165] Memory required for data: 5981798484
I0613 21:30:20.561034 15760 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0613 21:30:20.561053 15760 net.cpp:100] Creating Layer scale5b_branch2b
I0613 21:30:20.561060 15760 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0613 21:30:20.561075 15760 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0613 21:30:20.561152 15760 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0613 21:30:20.561379 15760 net.cpp:150] Setting up scale5b_branch2b
I0613 21:30:20.561388 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.561391 15760 net.cpp:165] Memory required for data: 5991628884
I0613 21:30:20.561405 15760 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0613 21:30:20.561417 15760 net.cpp:100] Creating Layer res5b_branch2b_relu
I0613 21:30:20.561424 15760 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0613 21:30:20.561439 15760 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0613 21:30:20.561645 15760 net.cpp:150] Setting up res5b_branch2b_relu
I0613 21:30:20.561655 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.561657 15760 net.cpp:165] Memory required for data: 6001459284
I0613 21:30:20.561664 15760 layer_factory.hpp:77] Creating layer res5b_branch2c
I0613 21:30:20.561683 15760 net.cpp:100] Creating Layer res5b_branch2c
I0613 21:30:20.561691 15760 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0613 21:30:20.561707 15760 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0613 21:30:20.565656 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0613 21:30:20.565695 15760 net.cpp:150] Setting up res5b_branch2c
I0613 21:30:20.565711 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.565714 15760 net.cpp:165] Memory required for data: 6040780884
I0613 21:30:20.565737 15760 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0613 21:30:20.565768 15760 net.cpp:100] Creating Layer bn5b_branch2c
I0613 21:30:20.565779 15760 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0613 21:30:20.565800 15760 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0613 21:30:20.566154 15760 net.cpp:150] Setting up bn5b_branch2c
I0613 21:30:20.566162 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.566166 15760 net.cpp:165] Memory required for data: 6080102484
I0613 21:30:20.566185 15760 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0613 21:30:20.566205 15760 net.cpp:100] Creating Layer scale5b_branch2c
I0613 21:30:20.566212 15760 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0613 21:30:20.566228 15760 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0613 21:30:20.566303 15760 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0613 21:30:20.566534 15760 net.cpp:150] Setting up scale5b_branch2c
I0613 21:30:20.566541 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.566545 15760 net.cpp:165] Memory required for data: 6119424084
I0613 21:30:20.566557 15760 layer_factory.hpp:77] Creating layer res5b
I0613 21:30:20.566571 15760 net.cpp:100] Creating Layer res5b
I0613 21:30:20.566578 15760 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0613 21:30:20.566591 15760 net.cpp:444] res5b <- res5b_branch2c
I0613 21:30:20.566603 15760 net.cpp:418] res5b -> res5b
I0613 21:30:20.566653 15760 net.cpp:150] Setting up res5b
I0613 21:30:20.566663 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.566666 15760 net.cpp:165] Memory required for data: 6158745684
I0613 21:30:20.566671 15760 layer_factory.hpp:77] Creating layer res5b_relu
I0613 21:30:20.566685 15760 net.cpp:100] Creating Layer res5b_relu
I0613 21:30:20.566691 15760 net.cpp:444] res5b_relu <- res5b
I0613 21:30:20.566706 15760 net.cpp:405] res5b_relu -> res5b (in-place)
I0613 21:30:20.567204 15760 net.cpp:150] Setting up res5b_relu
I0613 21:30:20.567214 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.567217 15760 net.cpp:165] Memory required for data: 6198067284
I0613 21:30:20.567224 15760 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0613 21:30:20.567236 15760 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0613 21:30:20.567243 15760 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0613 21:30:20.567260 15760 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0613 21:30:20.567278 15760 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0613 21:30:20.567349 15760 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0613 21:30:20.567359 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.567365 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.567369 15760 net.cpp:165] Memory required for data: 6276710484
I0613 21:30:20.567374 15760 layer_factory.hpp:77] Creating layer res5c_branch2a
I0613 21:30:20.567394 15760 net.cpp:100] Creating Layer res5c_branch2a
I0613 21:30:20.567400 15760 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0613 21:30:20.567417 15760 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0613 21:30:20.571470 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:20.571503 15760 net.cpp:150] Setting up res5c_branch2a
I0613 21:30:20.571519 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.571523 15760 net.cpp:165] Memory required for data: 6286540884
I0613 21:30:20.571543 15760 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0613 21:30:20.571571 15760 net.cpp:100] Creating Layer bn5c_branch2a
I0613 21:30:20.571583 15760 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0613 21:30:20.571604 15760 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0613 21:30:20.571952 15760 net.cpp:150] Setting up bn5c_branch2a
I0613 21:30:20.571960 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.571964 15760 net.cpp:165] Memory required for data: 6296371284
I0613 21:30:20.571983 15760 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0613 21:30:20.572000 15760 net.cpp:100] Creating Layer scale5c_branch2a
I0613 21:30:20.572008 15760 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0613 21:30:20.572023 15760 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0613 21:30:20.572098 15760 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0613 21:30:20.572324 15760 net.cpp:150] Setting up scale5c_branch2a
I0613 21:30:20.572331 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.572335 15760 net.cpp:165] Memory required for data: 6306201684
I0613 21:30:20.572350 15760 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0613 21:30:20.572362 15760 net.cpp:100] Creating Layer res5c_branch2a_relu
I0613 21:30:20.572371 15760 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0613 21:30:20.572386 15760 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0613 21:30:20.572548 15760 net.cpp:150] Setting up res5c_branch2a_relu
I0613 21:30:20.572556 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.572559 15760 net.cpp:165] Memory required for data: 6316032084
I0613 21:30:20.572566 15760 layer_factory.hpp:77] Creating layer res5c_branch2b
I0613 21:30:20.572584 15760 net.cpp:100] Creating Layer res5c_branch2b
I0613 21:30:20.572592 15760 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0613 21:30:20.572609 15760 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0613 21:30:20.578508 15760 net.cpp:150] Setting up res5c_branch2b
I0613 21:30:20.578541 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.578544 15760 net.cpp:165] Memory required for data: 6325862484
I0613 21:30:20.578572 15760 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0613 21:30:20.578606 15760 net.cpp:100] Creating Layer bn5c_branch2b
I0613 21:30:20.578619 15760 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0613 21:30:20.578642 15760 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0613 21:30:20.578999 15760 net.cpp:150] Setting up bn5c_branch2b
I0613 21:30:20.579007 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.579010 15760 net.cpp:165] Memory required for data: 6335692884
I0613 21:30:20.579030 15760 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0613 21:30:20.579048 15760 net.cpp:100] Creating Layer scale5c_branch2b
I0613 21:30:20.579056 15760 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0613 21:30:20.579072 15760 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0613 21:30:20.579149 15760 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0613 21:30:20.579376 15760 net.cpp:150] Setting up scale5c_branch2b
I0613 21:30:20.579385 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.579388 15760 net.cpp:165] Memory required for data: 6345523284
I0613 21:30:20.579401 15760 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0613 21:30:20.579414 15760 net.cpp:100] Creating Layer res5c_branch2b_relu
I0613 21:30:20.579421 15760 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0613 21:30:20.579434 15760 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0613 21:30:20.579640 15760 net.cpp:150] Setting up res5c_branch2b_relu
I0613 21:30:20.579649 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:20.579653 15760 net.cpp:165] Memory required for data: 6355353684
I0613 21:30:20.579659 15760 layer_factory.hpp:77] Creating layer res5c_branch2c
I0613 21:30:20.579679 15760 net.cpp:100] Creating Layer res5c_branch2c
I0613 21:30:20.579686 15760 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0613 21:30:20.579702 15760 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0613 21:30:20.583804 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0613 21:30:20.583842 15760 net.cpp:150] Setting up res5c_branch2c
I0613 21:30:20.583861 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.583865 15760 net.cpp:165] Memory required for data: 6394675284
I0613 21:30:20.583890 15760 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0613 21:30:20.583921 15760 net.cpp:100] Creating Layer bn5c_branch2c
I0613 21:30:20.583933 15760 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0613 21:30:20.583958 15760 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0613 21:30:20.584319 15760 net.cpp:150] Setting up bn5c_branch2c
I0613 21:30:20.584328 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.584331 15760 net.cpp:165] Memory required for data: 6433996884
I0613 21:30:20.584352 15760 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0613 21:30:20.584369 15760 net.cpp:100] Creating Layer scale5c_branch2c
I0613 21:30:20.584376 15760 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0613 21:30:20.584393 15760 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0613 21:30:20.584471 15760 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0613 21:30:20.585541 15760 net.cpp:150] Setting up scale5c_branch2c
I0613 21:30:20.585553 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.585556 15760 net.cpp:165] Memory required for data: 6473318484
I0613 21:30:20.585572 15760 layer_factory.hpp:77] Creating layer res5c
I0613 21:30:20.585588 15760 net.cpp:100] Creating Layer res5c
I0613 21:30:20.585597 15760 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0613 21:30:20.585610 15760 net.cpp:444] res5c <- res5c_branch2c
I0613 21:30:20.585623 15760 net.cpp:418] res5c -> res5c
I0613 21:30:20.585680 15760 net.cpp:150] Setting up res5c
I0613 21:30:20.585691 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.585695 15760 net.cpp:165] Memory required for data: 6512640084
I0613 21:30:20.585700 15760 layer_factory.hpp:77] Creating layer res5c_relu
I0613 21:30:20.585712 15760 net.cpp:100] Creating Layer res5c_relu
I0613 21:30:20.585718 15760 net.cpp:444] res5c_relu <- res5c
I0613 21:30:20.585734 15760 net.cpp:405] res5c_relu -> res5c (in-place)
I0613 21:30:20.585922 15760 net.cpp:150] Setting up res5c_relu
I0613 21:30:20.585930 15760 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0613 21:30:20.585933 15760 net.cpp:165] Memory required for data: 6551961684
I0613 21:30:20.585940 15760 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0613 21:30:20.585964 15760 net.cpp:100] Creating Layer rpn_conv/3x3
I0613 21:30:20.585971 15760 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0613 21:30:20.585990 15760 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0613 21:30:21.116565 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:21.116605 15760 net.cpp:150] Setting up rpn_conv/3x3
I0613 21:30:21.116626 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:21.116638 15760 net.cpp:165] Memory required for data: 6561792084
I0613 21:30:21.116667 15760 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0613 21:30:21.116696 15760 net.cpp:100] Creating Layer rpn_relu/3x3
I0613 21:30:21.116708 15760 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0613 21:30:21.116731 15760 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0613 21:30:21.117282 15760 net.cpp:150] Setting up rpn_relu/3x3
I0613 21:30:21.117295 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:21.117298 15760 net.cpp:165] Memory required for data: 6571622484
I0613 21:30:21.117305 15760 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0613 21:30:21.117319 15760 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0613 21:30:21.117326 15760 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0613 21:30:21.117346 15760 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0613 21:30:21.117367 15760 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0613 21:30:21.117455 15760 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0613 21:30:21.117465 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:21.117472 15760 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0613 21:30:21.117477 15760 net.cpp:165] Memory required for data: 6591283284
I0613 21:30:21.117481 15760 layer_factory.hpp:77] Creating layer rpn_cls_score
I0613 21:30:21.117503 15760 net.cpp:100] Creating Layer rpn_cls_score
I0613 21:30:21.117508 15760 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0613 21:30:21.117523 15760 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0613 21:30:21.122839 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:21.122877 15760 net.cpp:150] Setting up rpn_cls_score
I0613 21:30:21.122895 15760 net.cpp:157] Top shape: 1 66 60 80 (316800)
I0613 21:30:21.122900 15760 net.cpp:165] Memory required for data: 6592550484
I0613 21:30:21.122926 15760 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0613 21:30:21.122956 15760 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0613 21:30:21.122967 15760 net.cpp:444] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0613 21:30:21.122992 15760 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0613 21:30:21.123019 15760 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0613 21:30:21.123122 15760 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0613 21:30:21.123136 15760 net.cpp:157] Top shape: 1 66 60 80 (316800)
I0613 21:30:21.123142 15760 net.cpp:157] Top shape: 1 66 60 80 (316800)
I0613 21:30:21.123144 15760 net.cpp:165] Memory required for data: 6595084884
I0613 21:30:21.123150 15760 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0613 21:30:21.123179 15760 net.cpp:100] Creating Layer rpn_bbox_pred
I0613 21:30:21.123185 15760 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0613 21:30:21.123201 15760 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0613 21:30:21.132757 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:21.133165 15760 net.cpp:150] Setting up rpn_bbox_pred
I0613 21:30:21.133188 15760 net.cpp:157] Top shape: 1 132 60 80 (633600)
I0613 21:30:21.133193 15760 net.cpp:165] Memory required for data: 6597619284
I0613 21:30:21.133221 15760 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0613 21:30:21.133249 15760 net.cpp:100] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0613 21:30:21.133262 15760 net.cpp:444] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0613 21:30:21.133287 15760 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0613 21:30:21.133312 15760 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0613 21:30:21.133399 15760 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0613 21:30:21.133410 15760 net.cpp:157] Top shape: 1 132 60 80 (633600)
I0613 21:30:21.133417 15760 net.cpp:157] Top shape: 1 132 60 80 (633600)
I0613 21:30:21.133420 15760 net.cpp:165] Memory required for data: 6602688084
I0613 21:30:21.133426 15760 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0613 21:30:21.133443 15760 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0613 21:30:21.133450 15760 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0613 21:30:21.133466 15760 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0613 21:30:21.133520 15760 net.cpp:150] Setting up rpn_cls_score_reshape
I0613 21:30:21.133530 15760 net.cpp:157] Top shape: 1 2 1980 80 (316800)
I0613 21:30:21.133534 15760 net.cpp:165] Memory required for data: 6603955284
I0613 21:30:21.133538 15760 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0613 21:30:21.133550 15760 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0613 21:30:21.133558 15760 net.cpp:444] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0613 21:30:21.133571 15760 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0613 21:30:21.133589 15760 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0613 21:30:21.133657 15760 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0613 21:30:21.133666 15760 net.cpp:157] Top shape: 1 2 1980 80 (316800)
I0613 21:30:21.133672 15760 net.cpp:157] Top shape: 1 2 1980 80 (316800)
I0613 21:30:21.133677 15760 net.cpp:165] Memory required for data: 6606489684
I0613 21:30:21.133682 15760 layer_factory.hpp:77] Creating layer rpn-data
I0613 21:30:21.134011 15760 net.cpp:100] Creating Layer rpn-data
I0613 21:30:21.134022 15760 net.cpp:444] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0613 21:30:21.134039 15760 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I0613 21:30:21.134049 15760 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I0613 21:30:21.134057 15760 net.cpp:444] rpn-data <- data_input-data_0_split_1
I0613 21:30:21.134070 15760 net.cpp:418] rpn-data -> rpn_labels
I0613 21:30:21.134089 15760 net.cpp:418] rpn-data -> rpn_bbox_targets
I0613 21:30:21.134107 15760 net.cpp:418] rpn-data -> rpn_bbox_inside_weights
I0613 21:30:21.134124 15760 net.cpp:418] rpn-data -> rpn_bbox_outside_weights
I0613 21:30:21.135637 15760 net.cpp:150] Setting up rpn-data
I0613 21:30:21.135656 15760 net.cpp:157] Top shape: 1 1 1980 80 (158400)
I0613 21:30:21.135663 15760 net.cpp:157] Top shape: 1 132 60 80 (633600)
I0613 21:30:21.135669 15760 net.cpp:157] Top shape: 1 132 60 80 (633600)
I0613 21:30:21.135675 15760 net.cpp:157] Top shape: 1 132 60 80 (633600)
I0613 21:30:21.135679 15760 net.cpp:165] Memory required for data: 6614726484
I0613 21:30:21.135690 15760 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0613 21:30:21.135713 15760 net.cpp:100] Creating Layer rpn_loss_cls
I0613 21:30:21.135723 15760 net.cpp:444] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0613 21:30:21.135740 15760 net.cpp:444] rpn_loss_cls <- rpn_labels
I0613 21:30:21.135753 15760 net.cpp:418] rpn_loss_cls -> rpn_cls_loss
I0613 21:30:21.135793 15760 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0613 21:30:21.137504 15760 net.cpp:150] Setting up rpn_loss_cls
I0613 21:30:21.137528 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.137532 15760 net.cpp:160]     with loss weight 1
I0613 21:30:21.137542 15760 net.cpp:165] Memory required for data: 6614726488
I0613 21:30:21.137555 15760 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0613 21:30:21.137609 15760 net.cpp:100] Creating Layer rpn_loss_bbox
I0613 21:30:21.137622 15760 net.cpp:444] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0613 21:30:21.137645 15760 net.cpp:444] rpn_loss_bbox <- rpn_bbox_targets
I0613 21:30:21.137653 15760 net.cpp:444] rpn_loss_bbox <- rpn_bbox_inside_weights
I0613 21:30:21.137661 15760 net.cpp:444] rpn_loss_bbox <- rpn_bbox_outside_weights
I0613 21:30:21.137675 15760 net.cpp:418] rpn_loss_bbox -> rpn_loss_bbox
I0613 21:30:21.146929 15760 net.cpp:150] Setting up rpn_loss_bbox
I0613 21:30:21.146955 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.146957 15760 net.cpp:160]     with loss weight 1
I0613 21:30:21.146966 15760 net.cpp:165] Memory required for data: 6614726492
I0613 21:30:21.146989 15760 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0613 21:30:21.147022 15760 net.cpp:100] Creating Layer rpn_cls_prob
I0613 21:30:21.147035 15760 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0613 21:30:21.147063 15760 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0613 21:30:21.147455 15760 net.cpp:150] Setting up rpn_cls_prob
I0613 21:30:21.147467 15760 net.cpp:157] Top shape: 1 2 1980 80 (316800)
I0613 21:30:21.147471 15760 net.cpp:165] Memory required for data: 6615993692
I0613 21:30:21.147477 15760 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0613 21:30:21.147495 15760 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0613 21:30:21.147502 15760 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0613 21:30:21.147519 15760 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0613 21:30:21.147574 15760 net.cpp:150] Setting up rpn_cls_prob_reshape
I0613 21:30:21.147583 15760 net.cpp:157] Top shape: 1 66 60 80 (316800)
I0613 21:30:21.147588 15760 net.cpp:165] Memory required for data: 6617260892
I0613 21:30:21.147593 15760 layer_factory.hpp:77] Creating layer proposal
I0613 21:30:21.148233 15760 net.cpp:100] Creating Layer proposal
I0613 21:30:21.148247 15760 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0613 21:30:21.148262 15760 net.cpp:444] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0613 21:30:21.148272 15760 net.cpp:444] proposal <- im_info_input-data_1_split_1
I0613 21:30:21.148285 15760 net.cpp:418] proposal -> rpn_rois
I0613 21:30:21.150254 15760 net.cpp:150] Setting up proposal
I0613 21:30:21.150277 15760 net.cpp:157] Top shape: 1 5 (5)
I0613 21:30:21.150280 15760 net.cpp:165] Memory required for data: 6617260912
I0613 21:30:21.150292 15760 layer_factory.hpp:77] Creating layer roi-data
I0613 21:30:21.150460 15760 net.cpp:100] Creating Layer roi-data
I0613 21:30:21.150475 15760 net.cpp:444] roi-data <- rpn_rois
I0613 21:30:21.150493 15760 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I0613 21:30:21.150506 15760 net.cpp:418] roi-data -> rois
I0613 21:30:21.150526 15760 net.cpp:418] roi-data -> labels
I0613 21:30:21.150538 15760 net.cpp:418] roi-data -> bbox_targets
I0613 21:30:21.150549 15760 net.cpp:418] roi-data -> bbox_inside_weights
I0613 21:30:21.150559 15760 net.cpp:418] roi-data -> bbox_outside_weights
I0613 21:30:21.151000 15760 net.cpp:150] Setting up roi-data
I0613 21:30:21.151013 15760 net.cpp:157] Top shape: 1 5 1 1 (5)
I0613 21:30:21.151021 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.151026 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151032 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151037 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151041 15760 net.cpp:165] Memory required for data: 6617261032
I0613 21:30:21.151048 15760 layer_factory.hpp:77] Creating layer rois_roi-data_0_split
I0613 21:30:21.151062 15760 net.cpp:100] Creating Layer rois_roi-data_0_split
I0613 21:30:21.151069 15760 net.cpp:444] rois_roi-data_0_split <- rois
I0613 21:30:21.151085 15760 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_0
I0613 21:30:21.151104 15760 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_1
I0613 21:30:21.151119 15760 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_2
I0613 21:30:21.151208 15760 net.cpp:150] Setting up rois_roi-data_0_split
I0613 21:30:21.151217 15760 net.cpp:157] Top shape: 1 5 1 1 (5)
I0613 21:30:21.151224 15760 net.cpp:157] Top shape: 1 5 1 1 (5)
I0613 21:30:21.151229 15760 net.cpp:157] Top shape: 1 5 1 1 (5)
I0613 21:30:21.151233 15760 net.cpp:165] Memory required for data: 6617261092
I0613 21:30:21.151238 15760 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0613 21:30:21.151249 15760 net.cpp:100] Creating Layer labels_roi-data_1_split
I0613 21:30:21.151257 15760 net.cpp:444] labels_roi-data_1_split <- labels
I0613 21:30:21.151270 15760 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0613 21:30:21.151288 15760 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0613 21:30:21.151351 15760 net.cpp:150] Setting up labels_roi-data_1_split
I0613 21:30:21.151360 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.151366 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.151371 15760 net.cpp:165] Memory required for data: 6617261100
I0613 21:30:21.151376 15760 layer_factory.hpp:77] Creating layer bbox_targets_roi-data_2_split
I0613 21:30:21.151386 15760 net.cpp:100] Creating Layer bbox_targets_roi-data_2_split
I0613 21:30:21.151392 15760 net.cpp:444] bbox_targets_roi-data_2_split <- bbox_targets
I0613 21:30:21.151407 15760 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_0
I0613 21:30:21.151423 15760 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_1
I0613 21:30:21.151485 15760 net.cpp:150] Setting up bbox_targets_roi-data_2_split
I0613 21:30:21.151494 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151500 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151504 15760 net.cpp:165] Memory required for data: 6617261164
I0613 21:30:21.151510 15760 layer_factory.hpp:77] Creating layer bbox_inside_weights_roi-data_3_split
I0613 21:30:21.151520 15760 net.cpp:100] Creating Layer bbox_inside_weights_roi-data_3_split
I0613 21:30:21.151526 15760 net.cpp:444] bbox_inside_weights_roi-data_3_split <- bbox_inside_weights
I0613 21:30:21.151541 15760 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_0
I0613 21:30:21.151558 15760 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_1
I0613 21:30:21.151623 15760 net.cpp:150] Setting up bbox_inside_weights_roi-data_3_split
I0613 21:30:21.151630 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151636 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.151639 15760 net.cpp:165] Memory required for data: 6617261228
I0613 21:30:21.151644 15760 layer_factory.hpp:77] Creating layer conv_new_1
I0613 21:30:21.151669 15760 net.cpp:100] Creating Layer conv_new_1
I0613 21:30:21.151677 15760 net.cpp:444] conv_new_1 <- res5c
I0613 21:30:21.151695 15760 net.cpp:418] conv_new_1 -> conv_new_1
I0613 21:30:21.374326 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:21.374358 15760 net.cpp:150] Setting up conv_new_1
I0613 21:30:21.374373 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:21.374377 15760 net.cpp:165] Memory required for data: 6636922028
I0613 21:30:21.374399 15760 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0613 21:30:21.374420 15760 net.cpp:100] Creating Layer conv_new_1_relu
I0613 21:30:21.374433 15760 net.cpp:444] conv_new_1_relu <- conv_new_1
I0613 21:30:21.374450 15760 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0613 21:30:21.374927 15760 net.cpp:150] Setting up conv_new_1_relu
I0613 21:30:21.374936 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:21.374940 15760 net.cpp:165] Memory required for data: 6656582828
I0613 21:30:21.374946 15760 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0613 21:30:21.374958 15760 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0613 21:30:21.374965 15760 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0613 21:30:21.374981 15760 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0613 21:30:21.375000 15760 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0613 21:30:21.375069 15760 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0613 21:30:21.375078 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:21.375085 15760 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0613 21:30:21.375088 15760 net.cpp:165] Memory required for data: 6695904428
I0613 21:30:21.375093 15760 layer_factory.hpp:77] Creating layer rfcn_cls
I0613 21:30:21.375115 15760 net.cpp:100] Creating Layer rfcn_cls
I0613 21:30:21.375121 15760 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0613 21:30:21.375139 15760 net.cpp:418] rfcn_cls -> rfcn_cls
I0613 21:30:21.396827 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:21.396860 15760 net.cpp:150] Setting up rfcn_cls
I0613 21:30:21.396903 15760 net.cpp:157] Top shape: 1 196 60 80 (940800)
I0613 21:30:21.396908 15760 net.cpp:165] Memory required for data: 6699667628
I0613 21:30:21.396932 15760 layer_factory.hpp:77] Creating layer rfcn_bbox
I0613 21:30:21.396975 15760 net.cpp:100] Creating Layer rfcn_bbox
I0613 21:30:21.396987 15760 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0613 21:30:21.397011 15760 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0613 21:30:21.439985 15760 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0613 21:30:21.440019 15760 net.cpp:150] Setting up rfcn_bbox
I0613 21:30:21.440034 15760 net.cpp:157] Top shape: 1 392 60 80 (1881600)
I0613 21:30:21.440038 15760 net.cpp:165] Memory required for data: 6707194028
I0613 21:30:21.440059 15760 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0613 21:30:21.440085 15760 net.cpp:100] Creating Layer psroipooled_cls_rois
I0613 21:30:21.440096 15760 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0613 21:30:21.440114 15760 net.cpp:444] psroipooled_cls_rois <- rois_roi-data_0_split_0
I0613 21:30:21.440126 15760 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0613 21:30:21.440147 15760 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0613 21:30:21.440215 15760 net.cpp:150] Setting up psroipooled_cls_rois
I0613 21:30:21.440224 15760 net.cpp:157] Top shape: 1 4 7 7 (196)
I0613 21:30:21.440227 15760 net.cpp:165] Memory required for data: 6707194812
I0613 21:30:21.440232 15760 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0613 21:30:21.440248 15760 net.cpp:100] Creating Layer ave_cls_score_rois
I0613 21:30:21.440253 15760 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0613 21:30:21.440268 15760 net.cpp:418] ave_cls_score_rois -> cls_score
I0613 21:30:21.440451 15760 net.cpp:150] Setting up ave_cls_score_rois
I0613 21:30:21.440461 15760 net.cpp:157] Top shape: 1 4 1 1 (4)
I0613 21:30:21.440464 15760 net.cpp:165] Memory required for data: 6707194828
I0613 21:30:21.440469 15760 layer_factory.hpp:77] Creating layer cls_score_ave_cls_score_rois_0_split
I0613 21:30:21.440482 15760 net.cpp:100] Creating Layer cls_score_ave_cls_score_rois_0_split
I0613 21:30:21.440490 15760 net.cpp:444] cls_score_ave_cls_score_rois_0_split <- cls_score
I0613 21:30:21.440503 15760 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_0
I0613 21:30:21.440520 15760 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_1
I0613 21:30:21.440533 15760 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_2
I0613 21:30:21.440615 15760 net.cpp:150] Setting up cls_score_ave_cls_score_rois_0_split
I0613 21:30:21.440624 15760 net.cpp:157] Top shape: 1 4 1 1 (4)
I0613 21:30:21.440629 15760 net.cpp:157] Top shape: 1 4 1 1 (4)
I0613 21:30:21.440635 15760 net.cpp:157] Top shape: 1 4 1 1 (4)
I0613 21:30:21.440639 15760 net.cpp:165] Memory required for data: 6707194876
I0613 21:30:21.440644 15760 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0613 21:30:21.440656 15760 net.cpp:100] Creating Layer psroipooled_loc_rois
I0613 21:30:21.440663 15760 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0613 21:30:21.440675 15760 net.cpp:444] psroipooled_loc_rois <- rois_roi-data_0_split_1
I0613 21:30:21.440686 15760 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0613 21:30:21.440701 15760 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0613 21:30:21.440760 15760 net.cpp:150] Setting up psroipooled_loc_rois
I0613 21:30:21.440768 15760 net.cpp:157] Top shape: 1 8 7 7 (392)
I0613 21:30:21.440773 15760 net.cpp:165] Memory required for data: 6707196444
I0613 21:30:21.440778 15760 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0613 21:30:21.440789 15760 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0613 21:30:21.440795 15760 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0613 21:30:21.440809 15760 net.cpp:418] ave_bbox_pred_rois -> bbox_pred
I0613 21:30:21.440991 15760 net.cpp:150] Setting up ave_bbox_pred_rois
I0613 21:30:21.441004 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.441007 15760 net.cpp:165] Memory required for data: 6707196476
I0613 21:30:21.441012 15760 layer_factory.hpp:77] Creating layer bbox_pred_ave_bbox_pred_rois_0_split
I0613 21:30:21.441023 15760 net.cpp:100] Creating Layer bbox_pred_ave_bbox_pred_rois_0_split
I0613 21:30:21.441030 15760 net.cpp:444] bbox_pred_ave_bbox_pred_rois_0_split <- bbox_pred
I0613 21:30:21.441045 15760 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_0
I0613 21:30:21.441057 15760 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_1
I0613 21:30:21.441115 15760 net.cpp:150] Setting up bbox_pred_ave_bbox_pred_rois_0_split
I0613 21:30:21.441123 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.441124 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.441126 15760 net.cpp:165] Memory required for data: 6707196540
I0613 21:30:21.441129 15760 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0613 21:30:21.441138 15760 net.cpp:100] Creating Layer per_roi_loss_cls
I0613 21:30:21.441143 15760 net.cpp:444] per_roi_loss_cls <- cls_score_ave_cls_score_rois_0_split_0
I0613 21:30:21.441150 15760 net.cpp:444] per_roi_loss_cls <- labels_roi-data_1_split_0
I0613 21:30:21.441159 15760 net.cpp:418] per_roi_loss_cls -> temp_loss_cls
I0613 21:30:21.441170 15760 net.cpp:418] per_roi_loss_cls -> temp_prob_cls
I0613 21:30:21.441179 15760 net.cpp:418] per_roi_loss_cls -> per_roi_loss_cls
I0613 21:30:21.441190 15760 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0613 21:30:21.441824 15760 net.cpp:150] Setting up per_roi_loss_cls
I0613 21:30:21.441833 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.441836 15760 net.cpp:157] Top shape: 1 4 1 1 (4)
I0613 21:30:21.441838 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.441840 15760 net.cpp:165] Memory required for data: 6707196564
I0613 21:30:21.441844 15760 layer_factory.hpp:77] Creating layer per_roi_loss_bbox
I0613 21:30:21.441854 15760 net.cpp:100] Creating Layer per_roi_loss_bbox
I0613 21:30:21.441859 15760 net.cpp:444] per_roi_loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_0
I0613 21:30:21.441869 15760 net.cpp:444] per_roi_loss_bbox <- bbox_targets_roi-data_2_split_0
I0613 21:30:21.441874 15760 net.cpp:444] per_roi_loss_bbox <- bbox_inside_weights_roi-data_3_split_0
I0613 21:30:21.441882 15760 net.cpp:418] per_roi_loss_bbox -> temp_loss_bbox
I0613 21:30:21.441895 15760 net.cpp:418] per_roi_loss_bbox -> per_roi_loss_bbox
I0613 21:30:21.441977 15760 net.cpp:150] Setting up per_roi_loss_bbox
I0613 21:30:21.441982 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.441985 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.441987 15760 net.cpp:165] Memory required for data: 6707196572
I0613 21:30:21.441990 15760 layer_factory.hpp:77] Creating layer per_roi_loss
I0613 21:30:21.441999 15760 net.cpp:100] Creating Layer per_roi_loss
I0613 21:30:21.442003 15760 net.cpp:444] per_roi_loss <- per_roi_loss_cls
I0613 21:30:21.442010 15760 net.cpp:444] per_roi_loss <- per_roi_loss_bbox
I0613 21:30:21.442018 15760 net.cpp:418] per_roi_loss -> per_roi_loss
I0613 21:30:21.442056 15760 net.cpp:150] Setting up per_roi_loss
I0613 21:30:21.442061 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.442064 15760 net.cpp:165] Memory required for data: 6707196576
I0613 21:30:21.442066 15760 layer_factory.hpp:77] Creating layer annotator_detector
I0613 21:30:21.442077 15760 net.cpp:100] Creating Layer annotator_detector
I0613 21:30:21.442081 15760 net.cpp:444] annotator_detector <- rois_roi-data_0_split_2
I0613 21:30:21.442090 15760 net.cpp:444] annotator_detector <- per_roi_loss
I0613 21:30:21.442095 15760 net.cpp:444] annotator_detector <- labels_roi-data_1_split_1
I0613 21:30:21.442098 15760 net.cpp:444] annotator_detector <- bbox_inside_weights_roi-data_3_split_1
I0613 21:30:21.442104 15760 net.cpp:418] annotator_detector -> labels_ohem
I0613 21:30:21.442116 15760 net.cpp:418] annotator_detector -> bbox_loss_weights_ohem
I0613 21:30:21.442174 15760 net.cpp:150] Setting up annotator_detector
I0613 21:30:21.442180 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.442183 15760 net.cpp:157] Top shape: 1 8 1 1 (8)
I0613 21:30:21.442184 15760 net.cpp:165] Memory required for data: 6707196612
I0613 21:30:21.442188 15760 layer_factory.hpp:77] Creating layer labels_ohem_annotator_detector_0_split
I0613 21:30:21.442195 15760 net.cpp:100] Creating Layer labels_ohem_annotator_detector_0_split
I0613 21:30:21.442198 15760 net.cpp:444] labels_ohem_annotator_detector_0_split <- labels_ohem
I0613 21:30:21.442207 15760 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_0
I0613 21:30:21.442219 15760 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_1
I0613 21:30:21.442270 15760 net.cpp:150] Setting up labels_ohem_annotator_detector_0_split
I0613 21:30:21.442276 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.442278 15760 net.cpp:157] Top shape: 1 1 1 1 (1)
I0613 21:30:21.442279 15760 net.cpp:165] Memory required for data: 6707196620
I0613 21:30:21.442282 15760 layer_factory.hpp:77] Creating layer silence
I0613 21:30:21.442289 15760 net.cpp:100] Creating Layer silence
I0613 21:30:21.442293 15760 net.cpp:444] silence <- bbox_outside_weights
I0613 21:30:21.442301 15760 net.cpp:444] silence <- temp_loss_cls
I0613 21:30:21.442306 15760 net.cpp:444] silence <- temp_prob_cls
I0613 21:30:21.442311 15760 net.cpp:444] silence <- temp_loss_bbox
I0613 21:30:21.442314 15760 net.cpp:150] Setting up silence
I0613 21:30:21.442315 15760 net.cpp:165] Memory required for data: 6707196620
I0613 21:30:21.442317 15760 layer_factory.hpp:77] Creating layer loss
I0613 21:30:21.442327 15760 net.cpp:100] Creating Layer loss
I0613 21:30:21.442330 15760 net.cpp:444] loss <- cls_score_ave_cls_score_rois_0_split_1
I0613 21:30:21.442337 15760 net.cpp:444] loss <- labels_ohem_annotator_detector_0_split_0
I0613 21:30:21.442343 15760 net.cpp:418] loss -> loss_cls
I0613 21:30:21.442355 15760 layer_factory.hpp:77] Creating layer loss
I0613 21:30:21.442632 15760 net.cpp:150] Setting up loss
I0613 21:30:21.442641 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.442642 15760 net.cpp:160]     with loss weight 1
I0613 21:30:21.442646 15760 net.cpp:165] Memory required for data: 6707196624
I0613 21:30:21.442649 15760 layer_factory.hpp:77] Creating layer accuarcy
I0613 21:30:21.442659 15760 net.cpp:100] Creating Layer accuarcy
I0613 21:30:21.442663 15760 net.cpp:444] accuarcy <- cls_score_ave_cls_score_rois_0_split_2
I0613 21:30:21.442672 15760 net.cpp:444] accuarcy <- labels_ohem_annotator_detector_0_split_1
I0613 21:30:21.442678 15760 net.cpp:418] accuarcy -> accuarcy
I0613 21:30:21.442693 15760 net.cpp:150] Setting up accuarcy
I0613 21:30:21.442699 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.442700 15760 net.cpp:165] Memory required for data: 6707196628
I0613 21:30:21.442703 15760 layer_factory.hpp:77] Creating layer loss_bbox
I0613 21:30:21.442711 15760 net.cpp:100] Creating Layer loss_bbox
I0613 21:30:21.442715 15760 net.cpp:444] loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_1
I0613 21:30:21.442723 15760 net.cpp:444] loss_bbox <- bbox_targets_roi-data_2_split_1
I0613 21:30:21.442728 15760 net.cpp:444] loss_bbox <- bbox_loss_weights_ohem
I0613 21:30:21.442735 15760 net.cpp:418] loss_bbox -> loss_bbox
I0613 21:30:21.442818 15760 net.cpp:150] Setting up loss_bbox
I0613 21:30:21.442824 15760 net.cpp:157] Top shape: (1)
I0613 21:30:21.442826 15760 net.cpp:160]     with loss weight 1
I0613 21:30:21.442828 15760 net.cpp:165] Memory required for data: 6707196632
I0613 21:30:21.442832 15760 net.cpp:226] loss_bbox needs backward computation.
I0613 21:30:21.442837 15760 net.cpp:228] accuarcy does not need backward computation.
I0613 21:30:21.442840 15760 net.cpp:226] loss needs backward computation.
I0613 21:30:21.442843 15760 net.cpp:228] silence does not need backward computation.
I0613 21:30:21.442848 15760 net.cpp:228] labels_ohem_annotator_detector_0_split does not need backward computation.
I0613 21:30:21.442852 15760 net.cpp:228] annotator_detector does not need backward computation.
I0613 21:30:21.442858 15760 net.cpp:228] per_roi_loss does not need backward computation.
I0613 21:30:21.442863 15760 net.cpp:228] per_roi_loss_bbox does not need backward computation.
I0613 21:30:21.442870 15760 net.cpp:228] per_roi_loss_cls does not need backward computation.
I0613 21:30:21.442874 15760 net.cpp:226] bbox_pred_ave_bbox_pred_rois_0_split needs backward computation.
I0613 21:30:21.442878 15760 net.cpp:226] ave_bbox_pred_rois needs backward computation.
I0613 21:30:21.442880 15760 net.cpp:226] psroipooled_loc_rois needs backward computation.
I0613 21:30:21.442884 15760 net.cpp:226] cls_score_ave_cls_score_rois_0_split needs backward computation.
I0613 21:30:21.442886 15760 net.cpp:226] ave_cls_score_rois needs backward computation.
I0613 21:30:21.442889 15760 net.cpp:226] psroipooled_cls_rois needs backward computation.
I0613 21:30:21.442893 15760 net.cpp:226] rfcn_bbox needs backward computation.
I0613 21:30:21.442895 15760 net.cpp:226] rfcn_cls needs backward computation.
I0613 21:30:21.442898 15760 net.cpp:226] conv_new_1_conv_new_1_relu_0_split needs backward computation.
I0613 21:30:21.442900 15760 net.cpp:226] conv_new_1_relu needs backward computation.
I0613 21:30:21.442903 15760 net.cpp:226] conv_new_1 needs backward computation.
I0613 21:30:21.442906 15760 net.cpp:228] bbox_inside_weights_roi-data_3_split does not need backward computation.
I0613 21:30:21.442910 15760 net.cpp:228] bbox_targets_roi-data_2_split does not need backward computation.
I0613 21:30:21.442914 15760 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0613 21:30:21.442919 15760 net.cpp:226] rois_roi-data_0_split needs backward computation.
I0613 21:30:21.442921 15760 net.cpp:226] roi-data needs backward computation.
I0613 21:30:21.442925 15760 net.cpp:226] proposal needs backward computation.
I0613 21:30:21.442930 15760 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0613 21:30:21.442934 15760 net.cpp:226] rpn_cls_prob needs backward computation.
I0613 21:30:21.442936 15760 net.cpp:226] rpn_loss_bbox needs backward computation.
I0613 21:30:21.442941 15760 net.cpp:226] rpn_loss_cls needs backward computation.
I0613 21:30:21.442945 15760 net.cpp:226] rpn-data needs backward computation.
I0613 21:30:21.442952 15760 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0613 21:30:21.442955 15760 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0613 21:30:21.442958 15760 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0613 21:30:21.442961 15760 net.cpp:226] rpn_bbox_pred needs backward computation.
I0613 21:30:21.442965 15760 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0613 21:30:21.442967 15760 net.cpp:226] rpn_cls_score needs backward computation.
I0613 21:30:21.442970 15760 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0613 21:30:21.442972 15760 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0613 21:30:21.442975 15760 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0613 21:30:21.442978 15760 net.cpp:226] res5c_relu needs backward computation.
I0613 21:30:21.442981 15760 net.cpp:226] res5c needs backward computation.
I0613 21:30:21.442986 15760 net.cpp:226] scale5c_branch2c needs backward computation.
I0613 21:30:21.442987 15760 net.cpp:226] bn5c_branch2c needs backward computation.
I0613 21:30:21.442991 15760 net.cpp:226] res5c_branch2c needs backward computation.
I0613 21:30:21.442993 15760 net.cpp:226] res5c_branch2b_relu needs backward computation.
I0613 21:30:21.442996 15760 net.cpp:226] scale5c_branch2b needs backward computation.
I0613 21:30:21.442998 15760 net.cpp:226] bn5c_branch2b needs backward computation.
I0613 21:30:21.443001 15760 net.cpp:226] res5c_branch2b needs backward computation.
I0613 21:30:21.443003 15760 net.cpp:226] res5c_branch2a_relu needs backward computation.
I0613 21:30:21.443006 15760 net.cpp:226] scale5c_branch2a needs backward computation.
I0613 21:30:21.443008 15760 net.cpp:226] bn5c_branch2a needs backward computation.
I0613 21:30:21.443011 15760 net.cpp:226] res5c_branch2a needs backward computation.
I0613 21:30:21.443013 15760 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I0613 21:30:21.443017 15760 net.cpp:226] res5b_relu needs backward computation.
I0613 21:30:21.443018 15760 net.cpp:226] res5b needs backward computation.
I0613 21:30:21.443022 15760 net.cpp:226] scale5b_branch2c needs backward computation.
I0613 21:30:21.443024 15760 net.cpp:226] bn5b_branch2c needs backward computation.
I0613 21:30:21.443027 15760 net.cpp:226] res5b_branch2c needs backward computation.
I0613 21:30:21.443029 15760 net.cpp:226] res5b_branch2b_relu needs backward computation.
I0613 21:30:21.443032 15760 net.cpp:226] scale5b_branch2b needs backward computation.
I0613 21:30:21.443035 15760 net.cpp:226] bn5b_branch2b needs backward computation.
I0613 21:30:21.443037 15760 net.cpp:226] res5b_branch2b needs backward computation.
I0613 21:30:21.443040 15760 net.cpp:226] res5b_branch2a_relu needs backward computation.
I0613 21:30:21.443043 15760 net.cpp:226] scale5b_branch2a needs backward computation.
I0613 21:30:21.443045 15760 net.cpp:226] bn5b_branch2a needs backward computation.
I0613 21:30:21.443048 15760 net.cpp:226] res5b_branch2a needs backward computation.
I0613 21:30:21.443051 15760 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I0613 21:30:21.443054 15760 net.cpp:226] res5a_relu needs backward computation.
I0613 21:30:21.443056 15760 net.cpp:226] res5a needs backward computation.
I0613 21:30:21.443060 15760 net.cpp:226] scale5a_branch2c needs backward computation.
I0613 21:30:21.443063 15760 net.cpp:226] bn5a_branch2c needs backward computation.
I0613 21:30:21.443065 15760 net.cpp:226] res5a_branch2c needs backward computation.
I0613 21:30:21.443068 15760 net.cpp:226] res5a_branch2b_relu needs backward computation.
I0613 21:30:21.443071 15760 net.cpp:226] scale5a_branch2b needs backward computation.
I0613 21:30:21.443073 15760 net.cpp:226] bn5a_branch2b needs backward computation.
I0613 21:30:21.443076 15760 net.cpp:226] res5a_branch2b needs backward computation.
I0613 21:30:21.443079 15760 net.cpp:226] res5a_branch2a_relu needs backward computation.
I0613 21:30:21.443081 15760 net.cpp:226] scale5a_branch2a needs backward computation.
I0613 21:30:21.443084 15760 net.cpp:226] bn5a_branch2a needs backward computation.
I0613 21:30:21.443087 15760 net.cpp:226] res5a_branch2a needs backward computation.
I0613 21:30:21.443089 15760 net.cpp:226] scale5a_branch1 needs backward computation.
I0613 21:30:21.443092 15760 net.cpp:226] bn5a_branch1 needs backward computation.
I0613 21:30:21.443094 15760 net.cpp:226] res5a_branch1 needs backward computation.
I0613 21:30:21.443099 15760 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I0613 21:30:21.443100 15760 net.cpp:226] res4f_relu needs backward computation.
I0613 21:30:21.443104 15760 net.cpp:226] res4f needs backward computation.
I0613 21:30:21.443107 15760 net.cpp:226] scale4f_branch2c needs backward computation.
I0613 21:30:21.443110 15760 net.cpp:226] bn4f_branch2c needs backward computation.
I0613 21:30:21.443114 15760 net.cpp:226] res4f_branch2c needs backward computation.
I0613 21:30:21.443115 15760 net.cpp:226] res4f_branch2b_relu needs backward computation.
I0613 21:30:21.443119 15760 net.cpp:226] scale4f_branch2b needs backward computation.
I0613 21:30:21.443120 15760 net.cpp:226] bn4f_branch2b needs backward computation.
I0613 21:30:21.443123 15760 net.cpp:226] res4f_branch2b needs backward computation.
I0613 21:30:21.443126 15760 net.cpp:226] res4f_branch2a_relu needs backward computation.
I0613 21:30:21.443128 15760 net.cpp:226] scale4f_branch2a needs backward computation.
I0613 21:30:21.443131 15760 net.cpp:226] bn4f_branch2a needs backward computation.
I0613 21:30:21.443133 15760 net.cpp:226] res4f_branch2a needs backward computation.
I0613 21:30:21.443136 15760 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I0613 21:30:21.443140 15760 net.cpp:226] res4e_relu needs backward computation.
I0613 21:30:21.443141 15760 net.cpp:226] res4e needs backward computation.
I0613 21:30:21.443145 15760 net.cpp:226] scale4e_branch2c needs backward computation.
I0613 21:30:21.443148 15760 net.cpp:226] bn4e_branch2c needs backward computation.
I0613 21:30:21.443150 15760 net.cpp:226] res4e_branch2c needs backward computation.
I0613 21:30:21.443153 15760 net.cpp:226] res4e_branch2b_relu needs backward computation.
I0613 21:30:21.443156 15760 net.cpp:226] scale4e_branch2b needs backward computation.
I0613 21:30:21.443158 15760 net.cpp:226] bn4e_branch2b needs backward computation.
I0613 21:30:21.443161 15760 net.cpp:226] res4e_branch2b needs backward computation.
I0613 21:30:21.443163 15760 net.cpp:226] res4e_branch2a_relu needs backward computation.
I0613 21:30:21.443166 15760 net.cpp:226] scale4e_branch2a needs backward computation.
I0613 21:30:21.443168 15760 net.cpp:226] bn4e_branch2a needs backward computation.
I0613 21:30:21.443171 15760 net.cpp:226] res4e_branch2a needs backward computation.
I0613 21:30:21.443174 15760 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I0613 21:30:21.443177 15760 net.cpp:226] res4d_relu needs backward computation.
I0613 21:30:21.443179 15760 net.cpp:226] res4d needs backward computation.
I0613 21:30:21.443183 15760 net.cpp:226] scale4d_branch2c needs backward computation.
I0613 21:30:21.443186 15760 net.cpp:226] bn4d_branch2c needs backward computation.
I0613 21:30:21.443188 15760 net.cpp:226] res4d_branch2c needs backward computation.
I0613 21:30:21.443192 15760 net.cpp:226] res4d_branch2b_relu needs backward computation.
I0613 21:30:21.443194 15760 net.cpp:226] scale4d_branch2b needs backward computation.
I0613 21:30:21.443197 15760 net.cpp:226] bn4d_branch2b needs backward computation.
I0613 21:30:21.443199 15760 net.cpp:226] res4d_branch2b needs backward computation.
I0613 21:30:21.443202 15760 net.cpp:226] res4d_branch2a_relu needs backward computation.
I0613 21:30:21.443205 15760 net.cpp:226] scale4d_branch2a needs backward computation.
I0613 21:30:21.443208 15760 net.cpp:226] bn4d_branch2a needs backward computation.
I0613 21:30:21.443210 15760 net.cpp:226] res4d_branch2a needs backward computation.
I0613 21:30:21.443213 15760 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I0613 21:30:21.443217 15760 net.cpp:226] res4c_relu needs backward computation.
I0613 21:30:21.443219 15760 net.cpp:226] res4c needs backward computation.
I0613 21:30:21.443222 15760 net.cpp:226] scale4c_branch2c needs backward computation.
I0613 21:30:21.443225 15760 net.cpp:226] bn4c_branch2c needs backward computation.
I0613 21:30:21.443228 15760 net.cpp:226] res4c_branch2c needs backward computation.
I0613 21:30:21.443230 15760 net.cpp:226] res4c_branch2b_relu needs backward computation.
I0613 21:30:21.443233 15760 net.cpp:226] scale4c_branch2b needs backward computation.
I0613 21:30:21.443236 15760 net.cpp:226] bn4c_branch2b needs backward computation.
I0613 21:30:21.443238 15760 net.cpp:226] res4c_branch2b needs backward computation.
I0613 21:30:21.443241 15760 net.cpp:226] res4c_branch2a_relu needs backward computation.
I0613 21:30:21.443244 15760 net.cpp:226] scale4c_branch2a needs backward computation.
I0613 21:30:21.443246 15760 net.cpp:226] bn4c_branch2a needs backward computation.
I0613 21:30:21.443249 15760 net.cpp:226] res4c_branch2a needs backward computation.
I0613 21:30:21.443253 15760 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I0613 21:30:21.443255 15760 net.cpp:226] res4b_relu needs backward computation.
I0613 21:30:21.443258 15760 net.cpp:226] res4b needs backward computation.
I0613 21:30:21.443261 15760 net.cpp:226] scale4b_branch2c needs backward computation.
I0613 21:30:21.443264 15760 net.cpp:226] bn4b_branch2c needs backward computation.
I0613 21:30:21.443267 15760 net.cpp:226] res4b_branch2c needs backward computation.
I0613 21:30:21.443270 15760 net.cpp:226] res4b_branch2b_relu needs backward computation.
I0613 21:30:21.443272 15760 net.cpp:226] scale4b_branch2b needs backward computation.
I0613 21:30:21.443275 15760 net.cpp:226] bn4b_branch2b needs backward computation.
I0613 21:30:21.443279 15760 net.cpp:226] res4b_branch2b needs backward computation.
I0613 21:30:21.443281 15760 net.cpp:226] res4b_branch2a_relu needs backward computation.
I0613 21:30:21.443284 15760 net.cpp:226] scale4b_branch2a needs backward computation.
I0613 21:30:21.443286 15760 net.cpp:226] bn4b_branch2a needs backward computation.
I0613 21:30:21.443289 15760 net.cpp:226] res4b_branch2a needs backward computation.
I0613 21:30:21.443291 15760 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I0613 21:30:21.443295 15760 net.cpp:226] res4a_relu needs backward computation.
I0613 21:30:21.443297 15760 net.cpp:226] res4a needs backward computation.
I0613 21:30:21.443300 15760 net.cpp:226] scale4a_branch2c needs backward computation.
I0613 21:30:21.443303 15760 net.cpp:226] bn4a_branch2c needs backward computation.
I0613 21:30:21.443305 15760 net.cpp:226] res4a_branch2c needs backward computation.
I0613 21:30:21.443308 15760 net.cpp:226] res4a_branch2b_relu needs backward computation.
I0613 21:30:21.443311 15760 net.cpp:226] scale4a_branch2b needs backward computation.
I0613 21:30:21.443313 15760 net.cpp:226] bn4a_branch2b needs backward computation.
I0613 21:30:21.443316 15760 net.cpp:226] res4a_branch2b needs backward computation.
I0613 21:30:21.443320 15760 net.cpp:226] res4a_branch2a_relu needs backward computation.
I0613 21:30:21.443321 15760 net.cpp:226] scale4a_branch2a needs backward computation.
I0613 21:30:21.443325 15760 net.cpp:226] bn4a_branch2a needs backward computation.
I0613 21:30:21.443327 15760 net.cpp:226] res4a_branch2a needs backward computation.
I0613 21:30:21.443331 15760 net.cpp:226] scale4a_branch1 needs backward computation.
I0613 21:30:21.443332 15760 net.cpp:226] bn4a_branch1 needs backward computation.
I0613 21:30:21.443336 15760 net.cpp:226] res4a_branch1 needs backward computation.
I0613 21:30:21.443338 15760 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I0613 21:30:21.443341 15760 net.cpp:226] res3d_relu needs backward computation.
I0613 21:30:21.443344 15760 net.cpp:226] res3d needs backward computation.
I0613 21:30:21.443348 15760 net.cpp:226] scale3d_branch2c needs backward computation.
I0613 21:30:21.443351 15760 net.cpp:226] bn3d_branch2c needs backward computation.
I0613 21:30:21.443354 15760 net.cpp:226] res3d_branch2c needs backward computation.
I0613 21:30:21.443357 15760 net.cpp:226] res3d_branch2b_relu needs backward computation.
I0613 21:30:21.443359 15760 net.cpp:226] scale3d_branch2b needs backward computation.
I0613 21:30:21.443362 15760 net.cpp:226] bn3d_branch2b needs backward computation.
I0613 21:30:21.443365 15760 net.cpp:226] res3d_branch2b needs backward computation.
I0613 21:30:21.443368 15760 net.cpp:226] res3d_branch2a_relu needs backward computation.
I0613 21:30:21.443372 15760 net.cpp:226] scale3d_branch2a needs backward computation.
I0613 21:30:21.443373 15760 net.cpp:226] bn3d_branch2a needs backward computation.
I0613 21:30:21.443377 15760 net.cpp:226] res3d_branch2a needs backward computation.
I0613 21:30:21.443379 15760 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I0613 21:30:21.443382 15760 net.cpp:226] res3c_relu needs backward computation.
I0613 21:30:21.443384 15760 net.cpp:226] res3c needs backward computation.
I0613 21:30:21.443388 15760 net.cpp:226] scale3c_branch2c needs backward computation.
I0613 21:30:21.443392 15760 net.cpp:226] bn3c_branch2c needs backward computation.
I0613 21:30:21.443393 15760 net.cpp:226] res3c_branch2c needs backward computation.
I0613 21:30:21.443397 15760 net.cpp:226] res3c_branch2b_relu needs backward computation.
I0613 21:30:21.443399 15760 net.cpp:226] scale3c_branch2b needs backward computation.
I0613 21:30:21.443403 15760 net.cpp:226] bn3c_branch2b needs backward computation.
I0613 21:30:21.443404 15760 net.cpp:226] res3c_branch2b needs backward computation.
I0613 21:30:21.443408 15760 net.cpp:226] res3c_branch2a_relu needs backward computation.
I0613 21:30:21.443410 15760 net.cpp:226] scale3c_branch2a needs backward computation.
I0613 21:30:21.443413 15760 net.cpp:226] bn3c_branch2a needs backward computation.
I0613 21:30:21.443415 15760 net.cpp:226] res3c_branch2a needs backward computation.
I0613 21:30:21.443418 15760 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I0613 21:30:21.443423 15760 net.cpp:226] res3b_relu needs backward computation.
I0613 21:30:21.443424 15760 net.cpp:226] res3b needs backward computation.
I0613 21:30:21.443428 15760 net.cpp:226] scale3b_branch2c needs backward computation.
I0613 21:30:21.443431 15760 net.cpp:226] bn3b_branch2c needs backward computation.
I0613 21:30:21.443434 15760 net.cpp:226] res3b_branch2c needs backward computation.
I0613 21:30:21.443437 15760 net.cpp:226] res3b_branch2b_relu needs backward computation.
I0613 21:30:21.443439 15760 net.cpp:226] scale3b_branch2b needs backward computation.
I0613 21:30:21.443442 15760 net.cpp:226] bn3b_branch2b needs backward computation.
I0613 21:30:21.443444 15760 net.cpp:226] res3b_branch2b needs backward computation.
I0613 21:30:21.443447 15760 net.cpp:226] res3b_branch2a_relu needs backward computation.
I0613 21:30:21.443450 15760 net.cpp:226] scale3b_branch2a needs backward computation.
I0613 21:30:21.443452 15760 net.cpp:226] bn3b_branch2a needs backward computation.
I0613 21:30:21.443455 15760 net.cpp:226] res3b_branch2a needs backward computation.
I0613 21:30:21.443459 15760 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I0613 21:30:21.443461 15760 net.cpp:226] res3a_relu needs backward computation.
I0613 21:30:21.443464 15760 net.cpp:226] res3a needs backward computation.
I0613 21:30:21.443467 15760 net.cpp:226] scale3a_branch2c needs backward computation.
I0613 21:30:21.443470 15760 net.cpp:226] bn3a_branch2c needs backward computation.
I0613 21:30:21.443473 15760 net.cpp:226] res3a_branch2c needs backward computation.
I0613 21:30:21.443475 15760 net.cpp:226] res3a_branch2b_relu needs backward computation.
I0613 21:30:21.443480 15760 net.cpp:226] scale3a_branch2b needs backward computation.
I0613 21:30:21.443481 15760 net.cpp:226] bn3a_branch2b needs backward computation.
I0613 21:30:21.443485 15760 net.cpp:226] res3a_branch2b needs backward computation.
I0613 21:30:21.443486 15760 net.cpp:226] res3a_branch2a_relu needs backward computation.
I0613 21:30:21.443490 15760 net.cpp:226] scale3a_branch2a needs backward computation.
I0613 21:30:21.443492 15760 net.cpp:226] bn3a_branch2a needs backward computation.
I0613 21:30:21.443495 15760 net.cpp:226] res3a_branch2a needs backward computation.
I0613 21:30:21.443498 15760 net.cpp:226] scale3a_branch1 needs backward computation.
I0613 21:30:21.443501 15760 net.cpp:226] bn3a_branch1 needs backward computation.
I0613 21:30:21.443503 15760 net.cpp:226] res3a_branch1 needs backward computation.
I0613 21:30:21.443508 15760 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0613 21:30:21.443511 15760 net.cpp:228] res2c_relu does not need backward computation.
I0613 21:30:21.443514 15760 net.cpp:228] res2c does not need backward computation.
I0613 21:30:21.443523 15760 net.cpp:228] scale2c_branch2c does not need backward computation.
I0613 21:30:21.443528 15760 net.cpp:228] bn2c_branch2c does not need backward computation.
I0613 21:30:21.443532 15760 net.cpp:228] res2c_branch2c does not need backward computation.
I0613 21:30:21.443537 15760 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0613 21:30:21.443542 15760 net.cpp:228] scale2c_branch2b does not need backward computation.
I0613 21:30:21.443547 15760 net.cpp:228] bn2c_branch2b does not need backward computation.
I0613 21:30:21.443552 15760 net.cpp:228] res2c_branch2b does not need backward computation.
I0613 21:30:21.443557 15760 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0613 21:30:21.443563 15760 net.cpp:228] scale2c_branch2a does not need backward computation.
I0613 21:30:21.443568 15760 net.cpp:228] bn2c_branch2a does not need backward computation.
I0613 21:30:21.443572 15760 net.cpp:228] res2c_branch2a does not need backward computation.
I0613 21:30:21.443580 15760 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0613 21:30:21.443585 15760 net.cpp:228] res2b_relu does not need backward computation.
I0613 21:30:21.443590 15760 net.cpp:228] res2b does not need backward computation.
I0613 21:30:21.443598 15760 net.cpp:228] scale2b_branch2c does not need backward computation.
I0613 21:30:21.443603 15760 net.cpp:228] bn2b_branch2c does not need backward computation.
I0613 21:30:21.443608 15760 net.cpp:228] res2b_branch2c does not need backward computation.
I0613 21:30:21.443612 15760 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0613 21:30:21.443617 15760 net.cpp:228] scale2b_branch2b does not need backward computation.
I0613 21:30:21.443622 15760 net.cpp:228] bn2b_branch2b does not need backward computation.
I0613 21:30:21.443627 15760 net.cpp:228] res2b_branch2b does not need backward computation.
I0613 21:30:21.443634 15760 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0613 21:30:21.443637 15760 net.cpp:228] scale2b_branch2a does not need backward computation.
I0613 21:30:21.443642 15760 net.cpp:228] bn2b_branch2a does not need backward computation.
I0613 21:30:21.443646 15760 net.cpp:228] res2b_branch2a does not need backward computation.
I0613 21:30:21.443653 15760 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0613 21:30:21.443660 15760 net.cpp:228] res2a_relu does not need backward computation.
I0613 21:30:21.443665 15760 net.cpp:228] res2a does not need backward computation.
I0613 21:30:21.443671 15760 net.cpp:228] scale2a_branch2c does not need backward computation.
I0613 21:30:21.443677 15760 net.cpp:228] bn2a_branch2c does not need backward computation.
I0613 21:30:21.443681 15760 net.cpp:228] res2a_branch2c does not need backward computation.
I0613 21:30:21.443687 15760 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0613 21:30:21.443692 15760 net.cpp:228] scale2a_branch2b does not need backward computation.
I0613 21:30:21.443697 15760 net.cpp:228] bn2a_branch2b does not need backward computation.
I0613 21:30:21.443701 15760 net.cpp:228] res2a_branch2b does not need backward computation.
I0613 21:30:21.443707 15760 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0613 21:30:21.443712 15760 net.cpp:228] scale2a_branch2a does not need backward computation.
I0613 21:30:21.443717 15760 net.cpp:228] bn2a_branch2a does not need backward computation.
I0613 21:30:21.443725 15760 net.cpp:228] res2a_branch2a does not need backward computation.
I0613 21:30:21.443732 15760 net.cpp:228] scale2a_branch1 does not need backward computation.
I0613 21:30:21.443734 15760 net.cpp:228] bn2a_branch1 does not need backward computation.
I0613 21:30:21.443737 15760 net.cpp:228] res2a_branch1 does not need backward computation.
I0613 21:30:21.443742 15760 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0613 21:30:21.443747 15760 net.cpp:228] pool1 does not need backward computation.
I0613 21:30:21.443749 15760 net.cpp:228] conv1_relu does not need backward computation.
I0613 21:30:21.443753 15760 net.cpp:228] scale_conv1 does not need backward computation.
I0613 21:30:21.443755 15760 net.cpp:228] bn_conv1 does not need backward computation.
I0613 21:30:21.443758 15760 net.cpp:228] conv1 does not need backward computation.
I0613 21:30:21.443763 15760 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0613 21:30:21.443768 15760 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0613 21:30:21.443773 15760 net.cpp:228] data_input-data_0_split does not need backward computation.
I0613 21:30:21.443778 15760 net.cpp:228] input-data does not need backward computation.
I0613 21:30:21.443780 15760 net.cpp:270] This network produces output accuarcy
I0613 21:30:21.443785 15760 net.cpp:270] This network produces output loss_bbox
I0613 21:30:21.443789 15760 net.cpp:270] This network produces output loss_cls
I0613 21:30:21.443792 15760 net.cpp:270] This network produces output rpn_cls_loss
I0613 21:30:21.443795 15760 net.cpp:270] This network produces output rpn_loss_bbox
I0613 21:30:21.444100 15760 net.cpp:283] Network initialization done.
I0613 21:30:21.444615 15760 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I0613 21:30:21.540060 15760 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I0613 21:30:21.540082 15760 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0613 21:30:21.540086 15760 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0613 21:30:21.540092 15760 net.cpp:774] Copying source layer conv1
I0613 21:30:21.540205 15760 net.cpp:774] Copying source layer bn_conv1
I0613 21:30:21.540216 15760 net.cpp:774] Copying source layer scale_conv1
I0613 21:30:21.540225 15760 net.cpp:774] Copying source layer conv1_relu
I0613 21:30:21.540241 15760 net.cpp:774] Copying source layer pool1
I0613 21:30:21.540244 15760 net.cpp:774] Copying source layer pool1_pool1_0_split
I0613 21:30:21.540248 15760 net.cpp:774] Copying source layer res2a_branch1
I0613 21:30:21.540369 15760 net.cpp:774] Copying source layer bn2a_branch1
I0613 21:30:21.540383 15760 net.cpp:774] Copying source layer scale2a_branch1
I0613 21:30:21.540395 15760 net.cpp:774] Copying source layer res2a_branch2a
I0613 21:30:21.540431 15760 net.cpp:774] Copying source layer bn2a_branch2a
I0613 21:30:21.540439 15760 net.cpp:774] Copying source layer scale2a_branch2a
I0613 21:30:21.540447 15760 net.cpp:774] Copying source layer res2a_branch2a_relu
I0613 21:30:21.540451 15760 net.cpp:774] Copying source layer res2a_branch2b
I0613 21:30:21.540706 15760 net.cpp:774] Copying source layer bn2a_branch2b
I0613 21:30:21.540716 15760 net.cpp:774] Copying source layer scale2a_branch2b
I0613 21:30:21.540724 15760 net.cpp:774] Copying source layer res2a_branch2b_relu
I0613 21:30:21.540727 15760 net.cpp:774] Copying source layer res2a_branch2c
I0613 21:30:21.540844 15760 net.cpp:774] Copying source layer bn2a_branch2c
I0613 21:30:21.540855 15760 net.cpp:774] Copying source layer scale2a_branch2c
I0613 21:30:21.540865 15760 net.cpp:774] Copying source layer res2a
I0613 21:30:21.540869 15760 net.cpp:774] Copying source layer res2a_relu
I0613 21:30:21.540872 15760 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0613 21:30:21.540876 15760 net.cpp:774] Copying source layer res2b_branch2a
I0613 21:30:21.541004 15760 net.cpp:774] Copying source layer bn2b_branch2a
I0613 21:30:21.541015 15760 net.cpp:774] Copying source layer scale2b_branch2a
I0613 21:30:21.541023 15760 net.cpp:774] Copying source layer res2b_branch2a_relu
I0613 21:30:21.541028 15760 net.cpp:774] Copying source layer res2b_branch2b
I0613 21:30:21.541282 15760 net.cpp:774] Copying source layer bn2b_branch2b
I0613 21:30:21.541292 15760 net.cpp:774] Copying source layer scale2b_branch2b
I0613 21:30:21.541301 15760 net.cpp:774] Copying source layer res2b_branch2b_relu
I0613 21:30:21.541303 15760 net.cpp:774] Copying source layer res2b_branch2c
I0613 21:30:21.541420 15760 net.cpp:774] Copying source layer bn2b_branch2c
I0613 21:30:21.541434 15760 net.cpp:774] Copying source layer scale2b_branch2c
I0613 21:30:21.541445 15760 net.cpp:774] Copying source layer res2b
I0613 21:30:21.541447 15760 net.cpp:774] Copying source layer res2b_relu
I0613 21:30:21.541451 15760 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0613 21:30:21.541455 15760 net.cpp:774] Copying source layer res2c_branch2a
I0613 21:30:21.541574 15760 net.cpp:774] Copying source layer bn2c_branch2a
I0613 21:30:21.541582 15760 net.cpp:774] Copying source layer scale2c_branch2a
I0613 21:30:21.541591 15760 net.cpp:774] Copying source layer res2c_branch2a_relu
I0613 21:30:21.541595 15760 net.cpp:774] Copying source layer res2c_branch2b
I0613 21:30:21.541851 15760 net.cpp:774] Copying source layer bn2c_branch2b
I0613 21:30:21.541862 15760 net.cpp:774] Copying source layer scale2c_branch2b
I0613 21:30:21.541869 15760 net.cpp:774] Copying source layer res2c_branch2b_relu
I0613 21:30:21.541873 15760 net.cpp:774] Copying source layer res2c_branch2c
I0613 21:30:21.541991 15760 net.cpp:774] Copying source layer bn2c_branch2c
I0613 21:30:21.542004 15760 net.cpp:774] Copying source layer scale2c_branch2c
I0613 21:30:21.542016 15760 net.cpp:774] Copying source layer res2c
I0613 21:30:21.542019 15760 net.cpp:774] Copying source layer res2c_relu
I0613 21:30:21.542023 15760 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0613 21:30:21.542027 15760 net.cpp:774] Copying source layer res3a_branch1
I0613 21:30:21.542920 15760 net.cpp:774] Copying source layer bn3a_branch1
I0613 21:30:21.542937 15760 net.cpp:774] Copying source layer scale3a_branch1
I0613 21:30:21.542951 15760 net.cpp:774] Copying source layer res3a_branch2a
I0613 21:30:21.543180 15760 net.cpp:774] Copying source layer bn3a_branch2a
I0613 21:30:21.543191 15760 net.cpp:774] Copying source layer scale3a_branch2a
I0613 21:30:21.543201 15760 net.cpp:774] Copying source layer res3a_branch2a_relu
I0613 21:30:21.543205 15760 net.cpp:774] Copying source layer res3a_branch2b
I0613 21:30:21.544209 15760 net.cpp:774] Copying source layer bn3a_branch2b
I0613 21:30:21.544221 15760 net.cpp:774] Copying source layer scale3a_branch2b
I0613 21:30:21.544231 15760 net.cpp:774] Copying source layer res3a_branch2b_relu
I0613 21:30:21.544235 15760 net.cpp:774] Copying source layer res3a_branch2c
I0613 21:30:21.544687 15760 net.cpp:774] Copying source layer bn3a_branch2c
I0613 21:30:21.544703 15760 net.cpp:774] Copying source layer scale3a_branch2c
I0613 21:30:21.544718 15760 net.cpp:774] Copying source layer res3a
I0613 21:30:21.544723 15760 net.cpp:774] Copying source layer res3a_relu
I0613 21:30:21.544734 15760 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0613 21:30:21.544739 15760 net.cpp:774] Copying source layer res3b_branch2a
I0613 21:30:21.545217 15760 net.cpp:774] Copying source layer bn3b_branch2a
I0613 21:30:21.545229 15760 net.cpp:774] Copying source layer scale3b_branch2a
I0613 21:30:21.545238 15760 net.cpp:774] Copying source layer res3b_branch2a_relu
I0613 21:30:21.545239 15760 net.cpp:774] Copying source layer res3b_branch2b
I0613 21:30:21.546247 15760 net.cpp:774] Copying source layer bn3b_branch2b
I0613 21:30:21.546257 15760 net.cpp:774] Copying source layer scale3b_branch2b
I0613 21:30:21.546263 15760 net.cpp:774] Copying source layer res3b_branch2b_relu
I0613 21:30:21.546267 15760 net.cpp:774] Copying source layer res3b_branch2c
I0613 21:30:21.546716 15760 net.cpp:774] Copying source layer bn3b_branch2c
I0613 21:30:21.546736 15760 net.cpp:774] Copying source layer scale3b_branch2c
I0613 21:30:21.546751 15760 net.cpp:774] Copying source layer res3b
I0613 21:30:21.546756 15760 net.cpp:774] Copying source layer res3b_relu
I0613 21:30:21.546761 15760 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0613 21:30:21.546766 15760 net.cpp:774] Copying source layer res3c_branch2a
I0613 21:30:21.547219 15760 net.cpp:774] Copying source layer bn3c_branch2a
I0613 21:30:21.547231 15760 net.cpp:774] Copying source layer scale3c_branch2a
I0613 21:30:21.547241 15760 net.cpp:774] Copying source layer res3c_branch2a_relu
I0613 21:30:21.547245 15760 net.cpp:774] Copying source layer res3c_branch2b
I0613 21:30:21.548251 15760 net.cpp:774] Copying source layer bn3c_branch2b
I0613 21:30:21.548264 15760 net.cpp:774] Copying source layer scale3c_branch2b
I0613 21:30:21.548274 15760 net.cpp:774] Copying source layer res3c_branch2b_relu
I0613 21:30:21.548279 15760 net.cpp:774] Copying source layer res3c_branch2c
I0613 21:30:21.548729 15760 net.cpp:774] Copying source layer bn3c_branch2c
I0613 21:30:21.548746 15760 net.cpp:774] Copying source layer scale3c_branch2c
I0613 21:30:21.548761 15760 net.cpp:774] Copying source layer res3c
I0613 21:30:21.548765 15760 net.cpp:774] Copying source layer res3c_relu
I0613 21:30:21.548771 15760 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0613 21:30:21.548776 15760 net.cpp:774] Copying source layer res3d_branch2a
I0613 21:30:21.549239 15760 net.cpp:774] Copying source layer bn3d_branch2a
I0613 21:30:21.549252 15760 net.cpp:774] Copying source layer scale3d_branch2a
I0613 21:30:21.549263 15760 net.cpp:774] Copying source layer res3d_branch2a_relu
I0613 21:30:21.549268 15760 net.cpp:774] Copying source layer res3d_branch2b
I0613 21:30:21.550274 15760 net.cpp:774] Copying source layer bn3d_branch2b
I0613 21:30:21.550287 15760 net.cpp:774] Copying source layer scale3d_branch2b
I0613 21:30:21.550297 15760 net.cpp:774] Copying source layer res3d_branch2b_relu
I0613 21:30:21.550302 15760 net.cpp:774] Copying source layer res3d_branch2c
I0613 21:30:21.550752 15760 net.cpp:774] Copying source layer bn3d_branch2c
I0613 21:30:21.550770 15760 net.cpp:774] Copying source layer scale3d_branch2c
I0613 21:30:21.550786 15760 net.cpp:774] Copying source layer res3d
I0613 21:30:21.550791 15760 net.cpp:774] Copying source layer res3d_relu
I0613 21:30:21.550796 15760 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0613 21:30:21.550801 15760 net.cpp:774] Copying source layer res4a_branch1
I0613 21:30:21.554428 15760 net.cpp:774] Copying source layer bn4a_branch1
I0613 21:30:21.554469 15760 net.cpp:774] Copying source layer scale4a_branch1
I0613 21:30:21.554494 15760 net.cpp:774] Copying source layer res4a_branch2a
I0613 21:30:21.555389 15760 net.cpp:774] Copying source layer bn4a_branch2a
I0613 21:30:21.555409 15760 net.cpp:774] Copying source layer scale4a_branch2a
I0613 21:30:21.555423 15760 net.cpp:774] Copying source layer res4a_branch2a_relu
I0613 21:30:21.555428 15760 net.cpp:774] Copying source layer res4a_branch2b
I0613 21:30:21.559448 15760 net.cpp:774] Copying source layer bn4a_branch2b
I0613 21:30:21.559476 15760 net.cpp:774] Copying source layer scale4a_branch2b
I0613 21:30:21.559494 15760 net.cpp:774] Copying source layer res4a_branch2b_relu
I0613 21:30:21.559500 15760 net.cpp:774] Copying source layer res4a_branch2c
I0613 21:30:21.561302 15760 net.cpp:774] Copying source layer bn4a_branch2c
I0613 21:30:21.561331 15760 net.cpp:774] Copying source layer scale4a_branch2c
I0613 21:30:21.561357 15760 net.cpp:774] Copying source layer res4a
I0613 21:30:21.561363 15760 net.cpp:774] Copying source layer res4a_relu
I0613 21:30:21.561369 15760 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0613 21:30:21.561378 15760 net.cpp:774] Copying source layer res4b_branch2a
I0613 21:30:21.563170 15760 net.cpp:774] Copying source layer bn4b_branch2a
I0613 21:30:21.563185 15760 net.cpp:774] Copying source layer scale4b_branch2a
I0613 21:30:21.563201 15760 net.cpp:774] Copying source layer res4b_branch2a_relu
I0613 21:30:21.563207 15760 net.cpp:774] Copying source layer res4b_branch2b
I0613 21:30:21.567509 15760 net.cpp:774] Copying source layer bn4b_branch2b
I0613 21:30:21.567544 15760 net.cpp:774] Copying source layer scale4b_branch2b
I0613 21:30:21.567561 15760 net.cpp:774] Copying source layer res4b_branch2b_relu
I0613 21:30:21.567569 15760 net.cpp:774] Copying source layer res4b_branch2c
I0613 21:30:21.569382 15760 net.cpp:774] Copying source layer bn4b_branch2c
I0613 21:30:21.569418 15760 net.cpp:774] Copying source layer scale4b_branch2c
I0613 21:30:21.569443 15760 net.cpp:774] Copying source layer res4b
I0613 21:30:21.569448 15760 net.cpp:774] Copying source layer res4b_relu
I0613 21:30:21.569453 15760 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0613 21:30:21.569459 15760 net.cpp:774] Copying source layer res4c_branch2a
I0613 21:30:21.571243 15760 net.cpp:774] Copying source layer bn4c_branch2a
I0613 21:30:21.571265 15760 net.cpp:774] Copying source layer scale4c_branch2a
I0613 21:30:21.571288 15760 net.cpp:774] Copying source layer res4c_branch2a_relu
I0613 21:30:21.571295 15760 net.cpp:774] Copying source layer res4c_branch2b
I0613 21:30:21.575306 15760 net.cpp:774] Copying source layer bn4c_branch2b
I0613 21:30:21.575332 15760 net.cpp:774] Copying source layer scale4c_branch2b
I0613 21:30:21.575350 15760 net.cpp:774] Copying source layer res4c_branch2b_relu
I0613 21:30:21.575366 15760 net.cpp:774] Copying source layer res4c_branch2c
I0613 21:30:21.577160 15760 net.cpp:774] Copying source layer bn4c_branch2c
I0613 21:30:21.577196 15760 net.cpp:774] Copying source layer scale4c_branch2c
I0613 21:30:21.577220 15760 net.cpp:774] Copying source layer res4c
I0613 21:30:21.577226 15760 net.cpp:774] Copying source layer res4c_relu
I0613 21:30:21.577234 15760 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0613 21:30:21.577239 15760 net.cpp:774] Copying source layer res4d_branch2a
I0613 21:30:21.579022 15760 net.cpp:774] Copying source layer bn4d_branch2a
I0613 21:30:21.579042 15760 net.cpp:774] Copying source layer scale4d_branch2a
I0613 21:30:21.579058 15760 net.cpp:774] Copying source layer res4d_branch2a_relu
I0613 21:30:21.579064 15760 net.cpp:774] Copying source layer res4d_branch2b
I0613 21:30:21.583067 15760 net.cpp:774] Copying source layer bn4d_branch2b
I0613 21:30:21.583089 15760 net.cpp:774] Copying source layer scale4d_branch2b
I0613 21:30:21.583103 15760 net.cpp:774] Copying source layer res4d_branch2b_relu
I0613 21:30:21.583111 15760 net.cpp:774] Copying source layer res4d_branch2c
I0613 21:30:21.584910 15760 net.cpp:774] Copying source layer bn4d_branch2c
I0613 21:30:21.584951 15760 net.cpp:774] Copying source layer scale4d_branch2c
I0613 21:30:21.584978 15760 net.cpp:774] Copying source layer res4d
I0613 21:30:21.584985 15760 net.cpp:774] Copying source layer res4d_relu
I0613 21:30:21.584991 15760 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0613 21:30:21.584997 15760 net.cpp:774] Copying source layer res4e_branch2a
I0613 21:30:21.586793 15760 net.cpp:774] Copying source layer bn4e_branch2a
I0613 21:30:21.586813 15760 net.cpp:774] Copying source layer scale4e_branch2a
I0613 21:30:21.586824 15760 net.cpp:774] Copying source layer res4e_branch2a_relu
I0613 21:30:21.586828 15760 net.cpp:774] Copying source layer res4e_branch2b
I0613 21:30:21.590847 15760 net.cpp:774] Copying source layer bn4e_branch2b
I0613 21:30:21.590876 15760 net.cpp:774] Copying source layer scale4e_branch2b
I0613 21:30:21.590889 15760 net.cpp:774] Copying source layer res4e_branch2b_relu
I0613 21:30:21.590893 15760 net.cpp:774] Copying source layer res4e_branch2c
I0613 21:30:21.592682 15760 net.cpp:774] Copying source layer bn4e_branch2c
I0613 21:30:21.592710 15760 net.cpp:774] Copying source layer scale4e_branch2c
I0613 21:30:21.592733 15760 net.cpp:774] Copying source layer res4e
I0613 21:30:21.592739 15760 net.cpp:774] Copying source layer res4e_relu
I0613 21:30:21.592747 15760 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0613 21:30:21.592756 15760 net.cpp:774] Copying source layer res4f_branch2a
I0613 21:30:21.594552 15760 net.cpp:774] Copying source layer bn4f_branch2a
I0613 21:30:21.594570 15760 net.cpp:774] Copying source layer scale4f_branch2a
I0613 21:30:21.594583 15760 net.cpp:774] Copying source layer res4f_branch2a_relu
I0613 21:30:21.594586 15760 net.cpp:774] Copying source layer res4f_branch2b
I0613 21:30:21.598597 15760 net.cpp:774] Copying source layer bn4f_branch2b
I0613 21:30:21.598624 15760 net.cpp:774] Copying source layer scale4f_branch2b
I0613 21:30:21.598641 15760 net.cpp:774] Copying source layer res4f_branch2b_relu
I0613 21:30:21.598647 15760 net.cpp:774] Copying source layer res4f_branch2c
I0613 21:30:21.600798 15760 net.cpp:774] Copying source layer bn4f_branch2c
I0613 21:30:21.600838 15760 net.cpp:774] Copying source layer scale4f_branch2c
I0613 21:30:21.600859 15760 net.cpp:774] Copying source layer res4f
I0613 21:30:21.600864 15760 net.cpp:774] Copying source layer res4f_relu
I0613 21:30:21.600872 15760 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0613 21:30:21.600875 15760 net.cpp:774] Copying source layer res5a_branch1
I0613 21:30:21.615172 15760 net.cpp:774] Copying source layer bn5a_branch1
I0613 21:30:21.615229 15760 net.cpp:774] Copying source layer scale5a_branch1
I0613 21:30:21.615275 15760 net.cpp:774] Copying source layer res5a_branch2a
I0613 21:30:21.618839 15760 net.cpp:774] Copying source layer bn5a_branch2a
I0613 21:30:21.618863 15760 net.cpp:774] Copying source layer scale5a_branch2a
I0613 21:30:21.618880 15760 net.cpp:774] Copying source layer res5a_branch2a_relu
I0613 21:30:21.618887 15760 net.cpp:774] Copying source layer res5a_branch2b
I0613 21:30:21.635280 15760 net.cpp:774] Copying source layer bn5a_branch2b
I0613 21:30:21.635330 15760 net.cpp:774] Copying source layer scale5a_branch2b
I0613 21:30:21.635352 15760 net.cpp:774] Copying source layer res5a_branch2b_relu
I0613 21:30:21.635360 15760 net.cpp:774] Copying source layer res5a_branch2c
I0613 21:30:21.642524 15760 net.cpp:774] Copying source layer bn5a_branch2c
I0613 21:30:21.642583 15760 net.cpp:774] Copying source layer scale5a_branch2c
I0613 21:30:21.642627 15760 net.cpp:774] Copying source layer res5a
I0613 21:30:21.642633 15760 net.cpp:774] Copying source layer res5a_relu
I0613 21:30:21.642640 15760 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0613 21:30:21.642648 15760 net.cpp:774] Copying source layer res5b_branch2a
I0613 21:30:21.649799 15760 net.cpp:774] Copying source layer bn5b_branch2a
I0613 21:30:21.649837 15760 net.cpp:774] Copying source layer scale5b_branch2a
I0613 21:30:21.649886 15760 net.cpp:774] Copying source layer res5b_branch2a_relu
I0613 21:30:21.649902 15760 net.cpp:774] Copying source layer res5b_branch2b
I0613 21:30:21.666067 15760 net.cpp:774] Copying source layer bn5b_branch2b
I0613 21:30:21.666121 15760 net.cpp:774] Copying source layer scale5b_branch2b
I0613 21:30:21.666147 15760 net.cpp:774] Copying source layer res5b_branch2b_relu
I0613 21:30:21.666155 15760 net.cpp:774] Copying source layer res5b_branch2c
I0613 21:30:21.673558 15760 net.cpp:774] Copying source layer bn5b_branch2c
I0613 21:30:21.673632 15760 net.cpp:774] Copying source layer scale5b_branch2c
I0613 21:30:21.673676 15760 net.cpp:774] Copying source layer res5b
I0613 21:30:21.673686 15760 net.cpp:774] Copying source layer res5b_relu
I0613 21:30:21.673692 15760 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0613 21:30:21.673697 15760 net.cpp:774] Copying source layer res5c_branch2a
I0613 21:30:21.680836 15760 net.cpp:774] Copying source layer bn5c_branch2a
I0613 21:30:21.680873 15760 net.cpp:774] Copying source layer scale5c_branch2a
I0613 21:30:21.680891 15760 net.cpp:774] Copying source layer res5c_branch2a_relu
I0613 21:30:21.680899 15760 net.cpp:774] Copying source layer res5c_branch2b
I0613 21:30:21.697008 15760 net.cpp:774] Copying source layer bn5c_branch2b
I0613 21:30:21.697049 15760 net.cpp:774] Copying source layer scale5c_branch2b
I0613 21:30:21.697068 15760 net.cpp:774] Copying source layer res5c_branch2b_relu
I0613 21:30:21.697077 15760 net.cpp:774] Copying source layer res5c_branch2c
I0613 21:30:21.704499 15760 net.cpp:774] Copying source layer bn5c_branch2c
I0613 21:30:21.704576 15760 net.cpp:774] Copying source layer scale5c_branch2c
I0613 21:30:21.704622 15760 net.cpp:774] Copying source layer res5c
I0613 21:30:21.704628 15760 net.cpp:774] Copying source layer res5c_relu
I0613 21:30:21.704633 15760 net.cpp:771] Ignoring source layer pool5
I0613 21:30:21.704639 15760 net.cpp:771] Ignoring source layer fc1000
I0613 21:30:21.704646 15760 net.cpp:771] Ignoring source layer prob
Solving...
I0613 21:30:26.769536 15760 solver.cpp:228] Iteration 0, loss = 2.1553
I0613 21:30:26.769563 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.0546875
I0613 21:30:26.769572 15760 solver.cpp:244]     Train net output #1: loss_bbox = 5.09399e-05 (* 1 = 5.09399e-05 loss)
I0613 21:30:26.769575 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.38809 (* 1 = 1.38809 loss)
I0613 21:30:26.769579 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.700708 (* 1 = 0.700708 loss)
I0613 21:30:26.769583 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157429 (* 1 = 0.157429 loss)
I0613 21:30:26.769588 15760 sgd_solver.cpp:106] Iteration 0, lr = 0.0002
I0613 21:32:12.910467 15760 solver.cpp:228] Iteration 20, loss = 2.11235
I0613 21:32:12.910493 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0613 21:32:12.910503 15760 solver.cpp:244]     Train net output #1: loss_bbox = 3.67703e-05 (* 1 = 3.67703e-05 loss)
I0613 21:32:12.910508 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.36653 (* 1 = 1.36653 loss)
I0613 21:32:12.910513 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.660469 (* 1 = 0.660469 loss)
I0613 21:32:12.910519 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261052 (* 1 = 0.0261052 loss)
I0613 21:32:12.910526 15760 sgd_solver.cpp:106] Iteration 20, lr = 0.0002
I0613 21:33:59.895032 15760 solver.cpp:228] Iteration 40, loss = 2.02865
I0613 21:33:59.895056 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0613 21:33:59.895063 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.12962e-05 (* 1 = 1.12962e-05 loss)
I0613 21:33:59.895067 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.32932 (* 1 = 1.32932 loss)
I0613 21:33:59.895071 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.588451 (* 1 = 0.588451 loss)
I0613 21:33:59.895073 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0906628 (* 1 = 0.0906628 loss)
I0613 21:33:59.895078 15760 sgd_solver.cpp:106] Iteration 40, lr = 0.0002
I0613 21:35:47.434224 15760 solver.cpp:228] Iteration 60, loss = 1.89523
I0613 21:35:47.434254 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0613 21:35:47.434264 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000124977 (* 1 = 0.000124977 loss)
I0613 21:35:47.434273 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.27639 (* 1 = 1.27639 loss)
I0613 21:35:47.434278 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.514912 (* 1 = 0.514912 loss)
I0613 21:35:47.434284 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.186246 (* 1 = 0.186246 loss)
I0613 21:35:47.434293 15760 sgd_solver.cpp:106] Iteration 60, lr = 0.0002
I0613 21:37:34.776257 15760 solver.cpp:228] Iteration 80, loss = 1.61962
I0613 21:37:34.776288 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0613 21:37:34.776298 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000105569 (* 1 = 0.000105569 loss)
I0613 21:37:34.776302 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.14386 (* 1 = 1.14386 loss)
I0613 21:37:34.776307 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.409974 (* 1 = 0.409974 loss)
I0613 21:37:34.776312 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.070464 (* 1 = 0.070464 loss)
I0613 21:37:34.776319 15760 sgd_solver.cpp:106] Iteration 80, lr = 0.0002
I0613 21:39:22.366835 15760 solver.cpp:228] Iteration 100, loss = 1.35604
I0613 21:39:22.366863 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 21:39:22.366871 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000141462 (* 1 = 0.000141462 loss)
I0613 21:39:22.366878 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.824737 (* 1 = 0.824737 loss)
I0613 21:39:22.366883 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.318261 (* 1 = 0.318261 loss)
I0613 21:39:22.366888 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124986 (* 1 = 0.124986 loss)
I0613 21:39:22.366896 15760 sgd_solver.cpp:106] Iteration 100, lr = 0.0002
I0613 21:41:09.411640 15760 solver.cpp:228] Iteration 120, loss = 0.436072
I0613 21:41:09.411664 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 21:41:09.411672 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000464799 (* 1 = 0.000464799 loss)
I0613 21:41:09.411676 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.111035 (* 1 = 0.111035 loss)
I0613 21:41:09.411680 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.18184 (* 1 = 0.18184 loss)
I0613 21:41:09.411684 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037775 (* 1 = 0.037775 loss)
I0613 21:41:09.411689 15760 sgd_solver.cpp:106] Iteration 120, lr = 0.0002
I0613 21:42:56.453276 15760 solver.cpp:228] Iteration 140, loss = 0.489144
I0613 21:42:56.453305 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 21:42:56.453315 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000801567 (* 1 = 0.000801567 loss)
I0613 21:42:56.453320 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.258228 (* 1 = 0.258228 loss)
I0613 21:42:56.453325 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.191772 (* 1 = 0.191772 loss)
I0613 21:42:56.453330 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110379 (* 1 = 0.110379 loss)
I0613 21:42:56.453336 15760 sgd_solver.cpp:106] Iteration 140, lr = 0.0002
I0613 21:44:43.618758 15760 solver.cpp:228] Iteration 160, loss = 0.580597
I0613 21:44:43.618788 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 21:44:43.618795 15760 solver.cpp:244]     Train net output #1: loss_bbox = 9.65106e-05 (* 1 = 9.65106e-05 loss)
I0613 21:44:43.618800 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0742893 (* 1 = 0.0742893 loss)
I0613 21:44:43.618804 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0904472 (* 1 = 0.0904472 loss)
I0613 21:44:43.618808 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277502 (* 1 = 0.0277502 loss)
I0613 21:44:43.618813 15760 sgd_solver.cpp:106] Iteration 160, lr = 0.0002
I0613 21:46:31.112748 15760 solver.cpp:228] Iteration 180, loss = 0.338266
I0613 21:46:31.112774 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 21:46:31.112782 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000278189 (* 1 = 0.000278189 loss)
I0613 21:46:31.112787 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.152795 (* 1 = 0.152795 loss)
I0613 21:46:31.112792 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.173263 (* 1 = 0.173263 loss)
I0613 21:46:31.112797 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106405 (* 1 = 0.106405 loss)
I0613 21:46:31.112804 15760 sgd_solver.cpp:106] Iteration 180, lr = 0.0002
speed: 5.357s / iter
I0613 21:48:18.135493 15760 solver.cpp:228] Iteration 200, loss = 0.310156
I0613 21:48:18.135526 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 21:48:18.135535 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000633971 (* 1 = 0.000633971 loss)
I0613 21:48:18.135540 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.169452 (* 1 = 0.169452 loss)
I0613 21:48:18.135545 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.129103 (* 1 = 0.129103 loss)
I0613 21:48:18.135548 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.181872 (* 1 = 0.181872 loss)
I0613 21:48:18.135556 15760 sgd_solver.cpp:106] Iteration 200, lr = 0.0002
I0613 21:50:05.367775 15760 solver.cpp:228] Iteration 220, loss = 0.535399
I0613 21:50:05.367807 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0613 21:50:05.367818 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00274641 (* 1 = 0.00274641 loss)
I0613 21:50:05.367825 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.700829 (* 1 = 0.700829 loss)
I0613 21:50:05.367831 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.401268 (* 1 = 0.401268 loss)
I0613 21:50:05.367837 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.443385 (* 1 = 0.443385 loss)
I0613 21:50:05.367846 15760 sgd_solver.cpp:106] Iteration 220, lr = 0.0002
I0613 21:51:52.548970 15760 solver.cpp:228] Iteration 240, loss = 0.361285
I0613 21:51:52.548998 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 21:51:52.549006 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00086411 (* 1 = 0.00086411 loss)
I0613 21:51:52.549010 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.184433 (* 1 = 0.184433 loss)
I0613 21:51:52.549015 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.128642 (* 1 = 0.128642 loss)
I0613 21:51:52.549019 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0935905 (* 1 = 0.0935905 loss)
I0613 21:51:52.549026 15760 sgd_solver.cpp:106] Iteration 240, lr = 0.0002
I0613 21:53:40.004755 15760 solver.cpp:228] Iteration 260, loss = 0.511442
I0613 21:53:40.004781 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0613 21:53:40.004788 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334624 (* 1 = 0.0334624 loss)
I0613 21:53:40.004792 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.322347 (* 1 = 0.322347 loss)
I0613 21:53:40.004796 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0910415 (* 1 = 0.0910415 loss)
I0613 21:53:40.004799 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.131123 (* 1 = 0.131123 loss)
I0613 21:53:40.004804 15760 sgd_solver.cpp:106] Iteration 260, lr = 0.0002
I0613 21:55:27.260546 15760 solver.cpp:228] Iteration 280, loss = 0.959603
I0613 21:55:27.260573 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 21:55:27.260581 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000212277 (* 1 = 0.000212277 loss)
I0613 21:55:27.260586 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.191937 (* 1 = 0.191937 loss)
I0613 21:55:27.260588 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0626673 (* 1 = 0.0626673 loss)
I0613 21:55:27.260592 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325502 (* 1 = 0.0325502 loss)
I0613 21:55:27.260597 15760 sgd_solver.cpp:106] Iteration 280, lr = 0.0002
I0613 21:57:13.728497 15760 solver.cpp:228] Iteration 300, loss = 1.27924
I0613 21:57:13.728518 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.476562
I0613 21:57:13.728525 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.545738 (* 1 = 0.545738 loss)
I0613 21:57:13.728529 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.61433 (* 1 = 1.61433 loss)
I0613 21:57:13.728533 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.822872 (* 1 = 0.822872 loss)
I0613 21:57:13.728536 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.841726 (* 1 = 0.841726 loss)
I0613 21:57:13.728541 15760 sgd_solver.cpp:106] Iteration 300, lr = 0.0002
I0613 21:59:00.475595 15760 solver.cpp:228] Iteration 320, loss = 0.439175
I0613 21:59:00.475623 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0613 21:59:00.475630 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.120426 (* 1 = 0.120426 loss)
I0613 21:59:00.475636 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.402116 (* 1 = 0.402116 loss)
I0613 21:59:00.475639 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0756679 (* 1 = 0.0756679 loss)
I0613 21:59:00.475642 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0447443 (* 1 = 0.0447443 loss)
I0613 21:59:00.475647 15760 sgd_solver.cpp:106] Iteration 320, lr = 0.0002
I0613 22:00:47.121886 15760 solver.cpp:228] Iteration 340, loss = 0.743725
I0613 22:00:47.121909 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 22:00:47.121917 15760 solver.cpp:244]     Train net output #1: loss_bbox = 8.75627e-05 (* 1 = 8.75627e-05 loss)
I0613 22:00:47.121920 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.17351 (* 1 = 0.17351 loss)
I0613 22:00:47.121924 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0674075 (* 1 = 0.0674075 loss)
I0613 22:00:47.121927 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039558 (* 1 = 0.039558 loss)
I0613 22:00:47.121932 15760 sgd_solver.cpp:106] Iteration 340, lr = 0.0002
I0613 22:02:33.811497 15760 solver.cpp:228] Iteration 360, loss = 0.868192
I0613 22:02:33.811523 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0613 22:02:33.811532 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000421119 (* 1 = 0.000421119 loss)
I0613 22:02:33.811535 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.327574 (* 1 = 0.327574 loss)
I0613 22:02:33.811539 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0751715 (* 1 = 0.0751715 loss)
I0613 22:02:33.811543 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0688513 (* 1 = 0.0688513 loss)
I0613 22:02:33.811548 15760 sgd_solver.cpp:106] Iteration 360, lr = 0.0002
I0613 22:04:21.247012 15760 solver.cpp:228] Iteration 380, loss = 1.11198
I0613 22:04:21.247040 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0613 22:04:21.247048 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.021379 (* 1 = 0.021379 loss)
I0613 22:04:21.247054 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.281079 (* 1 = 0.281079 loss)
I0613 22:04:21.247058 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0554331 (* 1 = 0.0554331 loss)
I0613 22:04:21.247063 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0412735 (* 1 = 0.0412735 loss)
I0613 22:04:21.247068 15760 sgd_solver.cpp:106] Iteration 380, lr = 0.0002
speed: 5.355s / iter
I0613 22:06:08.648494 15760 solver.cpp:228] Iteration 400, loss = 0.511406
I0613 22:06:08.648519 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 22:06:08.648527 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000323653 (* 1 = 0.000323653 loss)
I0613 22:06:08.648531 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.267318 (* 1 = 0.267318 loss)
I0613 22:06:08.648535 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0784332 (* 1 = 0.0784332 loss)
I0613 22:06:08.648540 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379589 (* 1 = 0.0379589 loss)
I0613 22:06:08.648545 15760 sgd_solver.cpp:106] Iteration 400, lr = 0.0002
I0613 22:07:56.103863 15760 solver.cpp:228] Iteration 420, loss = 0.944201
I0613 22:07:56.103888 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0613 22:07:56.103896 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.565502 (* 1 = 0.565502 loss)
I0613 22:07:56.103900 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.08711 (* 1 = 1.08711 loss)
I0613 22:07:56.103904 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0772482 (* 1 = 0.0772482 loss)
I0613 22:07:56.103909 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0765099 (* 1 = 0.0765099 loss)
I0613 22:07:56.103914 15760 sgd_solver.cpp:106] Iteration 420, lr = 0.0002
I0613 22:09:42.827482 15760 solver.cpp:228] Iteration 440, loss = 1.21945
I0613 22:09:42.827507 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.585938
I0613 22:09:42.827515 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.398136 (* 1 = 0.398136 loss)
I0613 22:09:42.827519 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.35924 (* 1 = 1.35924 loss)
I0613 22:09:42.827523 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.189236 (* 1 = 0.189236 loss)
I0613 22:09:42.827527 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.343678 (* 1 = 0.343678 loss)
I0613 22:09:42.827533 15760 sgd_solver.cpp:106] Iteration 440, lr = 0.0002
I0613 22:11:29.849864 15760 solver.cpp:228] Iteration 460, loss = 1.10444
I0613 22:11:29.849890 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 22:11:29.849897 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00108918 (* 1 = 0.00108918 loss)
I0613 22:11:29.849902 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.187644 (* 1 = 0.187644 loss)
I0613 22:11:29.849906 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0413475 (* 1 = 0.0413475 loss)
I0613 22:11:29.849910 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325469 (* 1 = 0.0325469 loss)
I0613 22:11:29.849916 15760 sgd_solver.cpp:106] Iteration 460, lr = 0.0002
I0613 22:13:17.162253 15760 solver.cpp:228] Iteration 480, loss = 1.11369
I0613 22:13:17.162278 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 22:13:17.162286 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0808256 (* 1 = 0.0808256 loss)
I0613 22:13:17.162289 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.363333 (* 1 = 0.363333 loss)
I0613 22:13:17.162292 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0606891 (* 1 = 0.0606891 loss)
I0613 22:13:17.162297 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0664968 (* 1 = 0.0664968 loss)
I0613 22:13:17.162300 15760 sgd_solver.cpp:106] Iteration 480, lr = 0.0002
I0613 22:15:04.420413 15760 solver.cpp:228] Iteration 500, loss = 1.46443
I0613 22:15:04.420444 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.5
I0613 22:15:04.420452 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.443103 (* 1 = 0.443103 loss)
I0613 22:15:04.420457 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.68116 (* 1 = 1.68116 loss)
I0613 22:15:04.420461 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.700924 (* 1 = 0.700924 loss)
I0613 22:15:04.420466 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.791715 (* 1 = 0.791715 loss)
I0613 22:15:04.420472 15760 sgd_solver.cpp:106] Iteration 500, lr = 0.0002
I0613 22:16:51.566507 15760 solver.cpp:228] Iteration 520, loss = 0.934733
I0613 22:16:51.566532 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0613 22:16:51.566540 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.311652 (* 1 = 0.311652 loss)
I0613 22:16:51.566545 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.707745 (* 1 = 0.707745 loss)
I0613 22:16:51.566547 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.285644 (* 1 = 0.285644 loss)
I0613 22:16:51.566551 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.266176 (* 1 = 0.266176 loss)
I0613 22:16:51.566556 15760 sgd_solver.cpp:106] Iteration 520, lr = 0.0002
I0613 22:18:38.728229 15760 solver.cpp:228] Iteration 540, loss = 1.27798
I0613 22:18:38.728261 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0613 22:18:38.728271 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194244 (* 1 = 0.194244 loss)
I0613 22:18:38.728276 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.323496 (* 1 = 0.323496 loss)
I0613 22:18:38.728281 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0290483 (* 1 = 0.0290483 loss)
I0613 22:18:38.728287 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200831 (* 1 = 0.0200831 loss)
I0613 22:18:38.728293 15760 sgd_solver.cpp:106] Iteration 540, lr = 0.0002
I0613 22:20:25.847653 15760 solver.cpp:228] Iteration 560, loss = 1.52756
I0613 22:20:25.847681 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.601562
I0613 22:20:25.847687 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.455077 (* 1 = 0.455077 loss)
I0613 22:20:25.847692 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.14616 (* 1 = 1.14616 loss)
I0613 22:20:25.847695 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.179994 (* 1 = 0.179994 loss)
I0613 22:20:25.847698 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.270007 (* 1 = 0.270007 loss)
I0613 22:20:25.847703 15760 sgd_solver.cpp:106] Iteration 560, lr = 0.0002
I0613 22:22:12.856160 15760 solver.cpp:228] Iteration 580, loss = 1.18796
I0613 22:22:12.856186 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 22:22:12.856195 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000635529 (* 1 = 0.000635529 loss)
I0613 22:22:12.856199 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.144932 (* 1 = 0.144932 loss)
I0613 22:22:12.856204 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0433812 (* 1 = 0.0433812 loss)
I0613 22:22:12.856207 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332397 (* 1 = 0.0332397 loss)
I0613 22:22:12.856215 15760 sgd_solver.cpp:106] Iteration 580, lr = 0.0002
speed: 5.354s / iter
I0613 22:23:59.251418 15760 solver.cpp:228] Iteration 600, loss = 0.942961
I0613 22:23:59.251461 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0613 22:23:59.251469 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.246817 (* 1 = 0.246817 loss)
I0613 22:23:59.251474 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.541437 (* 1 = 0.541437 loss)
I0613 22:23:59.251477 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0328431 (* 1 = 0.0328431 loss)
I0613 22:23:59.251482 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314106 (* 1 = 0.0314106 loss)
I0613 22:23:59.251490 15760 sgd_solver.cpp:106] Iteration 600, lr = 0.0002
I0613 22:25:45.865918 15760 solver.cpp:228] Iteration 620, loss = 1.22227
I0613 22:25:45.865943 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.492188
I0613 22:25:45.865950 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.848187 (* 1 = 0.848187 loss)
I0613 22:25:45.865955 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.01741 (* 1 = 1.01741 loss)
I0613 22:25:45.865959 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0599835 (* 1 = 0.0599835 loss)
I0613 22:25:45.865962 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120225 (* 1 = 0.120225 loss)
I0613 22:25:45.865967 15760 sgd_solver.cpp:106] Iteration 620, lr = 0.0002
I0613 22:27:32.948305 15760 solver.cpp:228] Iteration 640, loss = 1.17646
I0613 22:27:32.948335 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0613 22:27:32.948344 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.269727 (* 1 = 0.269727 loss)
I0613 22:27:32.948349 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.83178 (* 1 = 0.83178 loss)
I0613 22:27:32.948354 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.126151 (* 1 = 0.126151 loss)
I0613 22:27:32.948359 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.285407 (* 1 = 0.285407 loss)
I0613 22:27:32.948364 15760 sgd_solver.cpp:106] Iteration 640, lr = 0.0002
I0613 22:29:19.468600 15760 solver.cpp:228] Iteration 660, loss = 1.29773
I0613 22:29:19.468626 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0613 22:29:19.468632 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.315299 (* 1 = 0.315299 loss)
I0613 22:29:19.468636 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.57471 (* 1 = 0.57471 loss)
I0613 22:29:19.468639 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0603614 (* 1 = 0.0603614 loss)
I0613 22:29:19.468643 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0856505 (* 1 = 0.0856505 loss)
I0613 22:29:19.468647 15760 sgd_solver.cpp:106] Iteration 660, lr = 0.0002
I0613 22:31:05.815711 15760 solver.cpp:228] Iteration 680, loss = 0.813004
I0613 22:31:05.815734 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0613 22:31:05.815742 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.151327 (* 1 = 0.151327 loss)
I0613 22:31:05.815747 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.290794 (* 1 = 0.290794 loss)
I0613 22:31:05.815750 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0243917 (* 1 = 0.0243917 loss)
I0613 22:31:05.815755 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0428344 (* 1 = 0.0428344 loss)
I0613 22:31:05.815760 15760 sgd_solver.cpp:106] Iteration 680, lr = 0.0002
I0613 22:32:52.144742 15760 solver.cpp:228] Iteration 700, loss = 1.04861
I0613 22:32:52.144770 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.609375
I0613 22:32:52.144778 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.822162 (* 1 = 0.822162 loss)
I0613 22:32:52.144783 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.90494 (* 1 = 0.90494 loss)
I0613 22:32:52.144788 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211887 (* 1 = 0.0211887 loss)
I0613 22:32:52.144790 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0781118 (* 1 = 0.0781118 loss)
I0613 22:32:52.144798 15760 sgd_solver.cpp:106] Iteration 700, lr = 0.0002
I0613 22:34:38.443281 15760 solver.cpp:228] Iteration 720, loss = 1.11706
I0613 22:34:38.443306 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0613 22:34:38.443313 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.382876 (* 1 = 0.382876 loss)
I0613 22:34:38.443317 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.599749 (* 1 = 0.599749 loss)
I0613 22:34:38.443321 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0523103 (* 1 = 0.0523103 loss)
I0613 22:34:38.443325 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.122199 (* 1 = 0.122199 loss)
I0613 22:34:38.443330 15760 sgd_solver.cpp:106] Iteration 720, lr = 0.0002
I0613 22:36:25.146176 15760 solver.cpp:228] Iteration 740, loss = 1.50362
I0613 22:36:25.146199 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.3125
I0613 22:36:25.146206 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.581041 (* 1 = 0.581041 loss)
I0613 22:36:25.146210 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.52716 (* 1 = 1.52716 loss)
I0613 22:36:25.146214 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.527099 (* 1 = 0.527099 loss)
I0613 22:36:25.146217 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.860534 (* 1 = 0.860534 loss)
I0613 22:36:25.146221 15760 sgd_solver.cpp:106] Iteration 740, lr = 0.0002
I0613 22:38:11.426007 15760 solver.cpp:228] Iteration 760, loss = 1.41415
I0613 22:38:11.426030 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0613 22:38:11.426040 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.479471 (* 1 = 0.479471 loss)
I0613 22:38:11.426045 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.938872 (* 1 = 0.938872 loss)
I0613 22:38:11.426051 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.268509 (* 1 = 0.268509 loss)
I0613 22:38:11.426056 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.48096 (* 1 = 0.48096 loss)
I0613 22:38:11.426062 15760 sgd_solver.cpp:106] Iteration 760, lr = 0.0002
I0613 22:39:57.816534 15760 solver.cpp:228] Iteration 780, loss = 1.12964
I0613 22:39:57.816560 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0613 22:39:57.816566 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.271056 (* 1 = 0.271056 loss)
I0613 22:39:57.816571 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.364426 (* 1 = 0.364426 loss)
I0613 22:39:57.816576 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212238 (* 1 = 0.0212238 loss)
I0613 22:39:57.816578 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244828 (* 1 = 0.0244828 loss)
I0613 22:39:57.816584 15760 sgd_solver.cpp:106] Iteration 780, lr = 0.0002
speed: 5.347s / iter
I0613 22:41:44.345218 15760 solver.cpp:228] Iteration 800, loss = 0.828515
I0613 22:41:44.345242 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0613 22:41:44.345249 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435046 (* 1 = 0.0435046 loss)
I0613 22:41:44.345253 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.291264 (* 1 = 0.291264 loss)
I0613 22:41:44.345257 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0466666 (* 1 = 0.0466666 loss)
I0613 22:41:44.345260 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274981 (* 1 = 0.0274981 loss)
I0613 22:41:44.345265 15760 sgd_solver.cpp:106] Iteration 800, lr = 0.0002
I0613 22:43:30.576721 15760 solver.cpp:228] Iteration 820, loss = 1.21952
I0613 22:43:30.576747 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0613 22:43:30.576756 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.275762 (* 1 = 0.275762 loss)
I0613 22:43:30.576759 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.599731 (* 1 = 0.599731 loss)
I0613 22:43:30.576763 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.241597 (* 1 = 0.241597 loss)
I0613 22:43:30.576767 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.631891 (* 1 = 0.631891 loss)
I0613 22:43:30.576772 15760 sgd_solver.cpp:106] Iteration 820, lr = 0.0002
I0613 22:45:16.979621 15760 solver.cpp:228] Iteration 840, loss = 1.07618
I0613 22:45:16.979647 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0613 22:45:16.979655 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262907 (* 1 = 0.0262907 loss)
I0613 22:45:16.979660 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.151346 (* 1 = 0.151346 loss)
I0613 22:45:16.979663 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245875 (* 1 = 0.0245875 loss)
I0613 22:45:16.979666 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284694 (* 1 = 0.0284694 loss)
I0613 22:45:16.979672 15760 sgd_solver.cpp:106] Iteration 840, lr = 0.0002
I0613 22:47:03.420295 15760 solver.cpp:228] Iteration 860, loss = 1.02974
I0613 22:47:03.420320 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0613 22:47:03.420330 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292026 (* 1 = 0.0292026 loss)
I0613 22:47:03.420333 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.199076 (* 1 = 0.199076 loss)
I0613 22:47:03.420337 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0445993 (* 1 = 0.0445993 loss)
I0613 22:47:03.420341 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0720448 (* 1 = 0.0720448 loss)
I0613 22:47:03.420346 15760 sgd_solver.cpp:106] Iteration 860, lr = 0.0002
I0613 22:48:50.891183 15760 solver.cpp:228] Iteration 880, loss = 1.0995
I0613 22:48:50.891206 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0613 22:48:50.891213 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459062 (* 1 = 0.0459062 loss)
I0613 22:48:50.891217 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.383851 (* 1 = 0.383851 loss)
I0613 22:48:50.891221 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0817069 (* 1 = 0.0817069 loss)
I0613 22:48:50.891224 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.247348 (* 1 = 0.247348 loss)
I0613 22:48:50.891228 15760 sgd_solver.cpp:106] Iteration 880, lr = 0.0002
I0613 22:50:38.197113 15760 solver.cpp:228] Iteration 900, loss = 1.22994
I0613 22:50:38.197139 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0613 22:50:38.197147 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.432894 (* 1 = 0.432894 loss)
I0613 22:50:38.197151 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.590138 (* 1 = 0.590138 loss)
I0613 22:50:38.197155 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265157 (* 1 = 0.0265157 loss)
I0613 22:50:38.197158 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335305 (* 1 = 0.0335305 loss)
I0613 22:50:38.197163 15760 sgd_solver.cpp:106] Iteration 900, lr = 0.0002
I0613 22:52:25.364439 15760 solver.cpp:228] Iteration 920, loss = 1.05757
I0613 22:52:25.364461 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0613 22:52:25.364470 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.526374 (* 1 = 0.526374 loss)
I0613 22:52:25.364472 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.719484 (* 1 = 0.719484 loss)
I0613 22:52:25.364476 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0416817 (* 1 = 0.0416817 loss)
I0613 22:52:25.364480 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0960216 (* 1 = 0.0960216 loss)
I0613 22:52:25.364485 15760 sgd_solver.cpp:106] Iteration 920, lr = 0.0002
I0613 22:54:13.026857 15760 solver.cpp:228] Iteration 940, loss = 1.36152
I0613 22:54:13.026883 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 22:54:13.026892 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628537 (* 1 = 0.0628537 loss)
I0613 22:54:13.026896 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.380942 (* 1 = 0.380942 loss)
I0613 22:54:13.026901 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0573815 (* 1 = 0.0573815 loss)
I0613 22:54:13.026904 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.069442 (* 1 = 0.069442 loss)
I0613 22:54:13.026909 15760 sgd_solver.cpp:106] Iteration 940, lr = 0.0002
I0613 22:56:00.445178 15760 solver.cpp:228] Iteration 960, loss = 0.742793
I0613 22:56:00.445202 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 22:56:00.445210 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00367121 (* 1 = 0.00367121 loss)
I0613 22:56:00.445214 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.125624 (* 1 = 0.125624 loss)
I0613 22:56:00.445219 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0675397 (* 1 = 0.0675397 loss)
I0613 22:56:00.445222 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0477607 (* 1 = 0.0477607 loss)
I0613 22:56:00.445227 15760 sgd_solver.cpp:106] Iteration 960, lr = 0.0002
I0613 22:57:47.527207 15760 solver.cpp:228] Iteration 980, loss = 1.09812
I0613 22:57:47.527237 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0613 22:57:47.527247 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.486882 (* 1 = 0.486882 loss)
I0613 22:57:47.527253 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.750993 (* 1 = 0.750993 loss)
I0613 22:57:47.527258 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0273184 (* 1 = 0.0273184 loss)
I0613 22:57:47.527263 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0538157 (* 1 = 0.0538157 loss)
I0613 22:57:47.527269 15760 sgd_solver.cpp:106] Iteration 980, lr = 0.0002
speed: 5.348s / iter
I0613 22:59:34.976519 15760 solver.cpp:228] Iteration 1000, loss = 1.33228
I0613 22:59:34.976546 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0613 22:59:34.976553 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.44992 (* 1 = 0.44992 loss)
I0613 22:59:34.976557 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.742049 (* 1 = 0.742049 loss)
I0613 22:59:34.976562 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0735675 (* 1 = 0.0735675 loss)
I0613 22:59:34.976565 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129881 (* 1 = 0.129881 loss)
I0613 22:59:34.976570 15760 sgd_solver.cpp:106] Iteration 1000, lr = 0.0002
I0613 23:01:21.765522 15760 solver.cpp:228] Iteration 1020, loss = 1.13756
I0613 23:01:21.765547 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.53125
I0613 23:01:21.765553 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.47678 (* 1 = 0.47678 loss)
I0613 23:01:21.765558 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.799789 (* 1 = 0.799789 loss)
I0613 23:01:21.765560 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0787332 (* 1 = 0.0787332 loss)
I0613 23:01:21.765564 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.183682 (* 1 = 0.183682 loss)
I0613 23:01:21.765568 15760 sgd_solver.cpp:106] Iteration 1020, lr = 0.0002
I0613 23:03:08.459761 15760 solver.cpp:228] Iteration 1040, loss = 1.29071
I0613 23:03:08.459789 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0613 23:03:08.459798 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.235051 (* 1 = 0.235051 loss)
I0613 23:03:08.459803 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.500926 (* 1 = 0.500926 loss)
I0613 23:03:08.459810 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0555194 (* 1 = 0.0555194 loss)
I0613 23:03:08.459815 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109124 (* 1 = 0.109124 loss)
I0613 23:03:08.459820 15760 sgd_solver.cpp:106] Iteration 1040, lr = 0.0002
I0613 23:04:55.061744 15760 solver.cpp:228] Iteration 1060, loss = 1.05115
I0613 23:04:55.061767 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.273438
I0613 23:04:55.061775 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.28074 (* 1 = 1.28074 loss)
I0613 23:04:55.061779 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.21322 (* 1 = 1.21322 loss)
I0613 23:04:55.061784 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0585234 (* 1 = 0.0585234 loss)
I0613 23:04:55.061787 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.190747 (* 1 = 0.190747 loss)
I0613 23:04:55.061792 15760 sgd_solver.cpp:106] Iteration 1060, lr = 0.0002
I0613 23:06:42.074630 15760 solver.cpp:228] Iteration 1080, loss = 1.17814
I0613 23:06:42.074654 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0613 23:06:42.074662 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.63981 (* 1 = 0.63981 loss)
I0613 23:06:42.074666 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.732357 (* 1 = 0.732357 loss)
I0613 23:06:42.074671 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0361695 (* 1 = 0.0361695 loss)
I0613 23:06:42.074673 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.123267 (* 1 = 0.123267 loss)
I0613 23:06:42.074679 15760 sgd_solver.cpp:106] Iteration 1080, lr = 0.0002
I0613 23:08:28.734447 15760 solver.cpp:228] Iteration 1100, loss = 0.947321
I0613 23:08:28.734475 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0613 23:08:28.734483 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.245693 (* 1 = 0.245693 loss)
I0613 23:08:28.734488 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.501362 (* 1 = 0.501362 loss)
I0613 23:08:28.734491 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0509447 (* 1 = 0.0509447 loss)
I0613 23:08:28.734495 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0943639 (* 1 = 0.0943639 loss)
I0613 23:08:28.734501 15760 sgd_solver.cpp:106] Iteration 1100, lr = 0.0002
I0613 23:10:15.052467 15760 solver.cpp:228] Iteration 1120, loss = 0.900466
I0613 23:10:15.052491 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0613 23:10:15.052498 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.175701 (* 1 = 0.175701 loss)
I0613 23:10:15.052502 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.426425 (* 1 = 0.426425 loss)
I0613 23:10:15.052505 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0598256 (* 1 = 0.0598256 loss)
I0613 23:10:15.052510 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.084133 (* 1 = 0.084133 loss)
I0613 23:10:15.052515 15760 sgd_solver.cpp:106] Iteration 1120, lr = 0.0002
I0613 23:12:01.258731 15760 solver.cpp:228] Iteration 1140, loss = 0.804403
I0613 23:12:01.258756 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0613 23:12:01.258765 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.328714 (* 1 = 0.328714 loss)
I0613 23:12:01.258772 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.645028 (* 1 = 0.645028 loss)
I0613 23:12:01.258775 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.229281 (* 1 = 0.229281 loss)
I0613 23:12:01.258780 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 1.06696 (* 1 = 1.06696 loss)
I0613 23:12:01.258785 15760 sgd_solver.cpp:106] Iteration 1140, lr = 0.0002
I0613 23:13:47.536597 15760 solver.cpp:228] Iteration 1160, loss = 0.947152
I0613 23:13:47.536623 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0613 23:13:47.536631 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.216944 (* 1 = 0.216944 loss)
I0613 23:13:47.536638 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.409384 (* 1 = 0.409384 loss)
I0613 23:13:47.536644 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219905 (* 1 = 0.0219905 loss)
I0613 23:13:47.536648 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316403 (* 1 = 0.0316403 loss)
I0613 23:13:47.536653 15760 sgd_solver.cpp:106] Iteration 1160, lr = 0.0002
I0613 23:15:33.835911 15760 solver.cpp:228] Iteration 1180, loss = 1.06676
I0613 23:15:33.835937 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.476562
I0613 23:15:33.835947 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.635294 (* 1 = 0.635294 loss)
I0613 23:15:33.835954 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.927764 (* 1 = 0.927764 loss)
I0613 23:15:33.835960 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142012 (* 1 = 0.0142012 loss)
I0613 23:15:33.835966 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103714 (* 1 = 0.103714 loss)
I0613 23:15:33.835973 15760 sgd_solver.cpp:106] Iteration 1180, lr = 0.0002
speed: 5.345s / iter
I0613 23:17:20.392521 15760 solver.cpp:228] Iteration 1200, loss = 1.34123
I0613 23:17:20.392546 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.476562
I0613 23:17:20.392554 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.842357 (* 1 = 0.842357 loss)
I0613 23:17:20.392557 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.950422 (* 1 = 0.950422 loss)
I0613 23:17:20.392560 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0488074 (* 1 = 0.0488074 loss)
I0613 23:17:20.392565 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.180595 (* 1 = 0.180595 loss)
I0613 23:17:20.392568 15760 sgd_solver.cpp:106] Iteration 1200, lr = 0.0002
I0613 23:19:06.572190 15760 solver.cpp:228] Iteration 1220, loss = 1.14554
I0613 23:19:06.572214 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0613 23:19:06.572221 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.423715 (* 1 = 0.423715 loss)
I0613 23:19:06.572224 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.577693 (* 1 = 0.577693 loss)
I0613 23:19:06.572228 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00620808 (* 1 = 0.00620808 loss)
I0613 23:19:06.572232 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681304 (* 1 = 0.0681304 loss)
I0613 23:19:06.572237 15760 sgd_solver.cpp:106] Iteration 1220, lr = 0.0002
I0613 23:20:52.864116 15760 solver.cpp:228] Iteration 1240, loss = 0.959342
I0613 23:20:52.864140 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0613 23:20:52.864148 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.199566 (* 1 = 0.199566 loss)
I0613 23:20:52.864152 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.349123 (* 1 = 0.349123 loss)
I0613 23:20:52.864156 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00852164 (* 1 = 0.00852164 loss)
I0613 23:20:52.864161 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027339 (* 1 = 0.027339 loss)
I0613 23:20:52.864166 15760 sgd_solver.cpp:106] Iteration 1240, lr = 0.0002
I0613 23:22:39.395120 15760 solver.cpp:228] Iteration 1260, loss = 1.59508
I0613 23:22:39.395225 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0613 23:22:39.395244 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.404283 (* 1 = 0.404283 loss)
I0613 23:22:39.395251 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.595261 (* 1 = 0.595261 loss)
I0613 23:22:39.395257 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039831 (* 1 = 0.039831 loss)
I0613 23:22:39.395263 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309341 (* 1 = 0.0309341 loss)
I0613 23:22:39.395277 15760 sgd_solver.cpp:106] Iteration 1260, lr = 0.0002
I0613 23:24:25.554666 15760 solver.cpp:228] Iteration 1280, loss = 0.986501
I0613 23:24:25.554695 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0613 23:24:25.554702 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.356683 (* 1 = 0.356683 loss)
I0613 23:24:25.554706 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.676542 (* 1 = 0.676542 loss)
I0613 23:24:25.554710 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0487031 (* 1 = 0.0487031 loss)
I0613 23:24:25.554714 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100359 (* 1 = 0.100359 loss)
I0613 23:24:25.554720 15760 sgd_solver.cpp:106] Iteration 1280, lr = 0.0002
I0613 23:26:11.854730 15760 solver.cpp:228] Iteration 1300, loss = 1.35807
I0613 23:26:11.854755 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0613 23:26:11.854763 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.38809 (* 1 = 0.38809 loss)
I0613 23:26:11.854768 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.53081 (* 1 = 0.53081 loss)
I0613 23:26:11.854771 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199674 (* 1 = 0.0199674 loss)
I0613 23:26:11.854775 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414751 (* 1 = 0.0414751 loss)
I0613 23:26:11.854780 15760 sgd_solver.cpp:106] Iteration 1300, lr = 0.0002
I0613 23:27:58.640619 15760 solver.cpp:228] Iteration 1320, loss = 1.09574
I0613 23:27:58.640645 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0613 23:27:58.640652 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.354173 (* 1 = 0.354173 loss)
I0613 23:27:58.640656 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.601527 (* 1 = 0.601527 loss)
I0613 23:27:58.640661 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206414 (* 1 = 0.0206414 loss)
I0613 23:27:58.640664 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0557632 (* 1 = 0.0557632 loss)
I0613 23:27:58.640669 15760 sgd_solver.cpp:106] Iteration 1320, lr = 0.0002
I0613 23:29:44.980154 15760 solver.cpp:228] Iteration 1340, loss = 1.15047
I0613 23:29:44.980178 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0613 23:29:44.980185 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308718 (* 1 = 0.0308718 loss)
I0613 23:29:44.980190 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.1579 (* 1 = 0.1579 loss)
I0613 23:29:44.980192 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215344 (* 1 = 0.0215344 loss)
I0613 23:29:44.980195 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0657948 (* 1 = 0.0657948 loss)
I0613 23:29:44.980201 15760 sgd_solver.cpp:106] Iteration 1340, lr = 0.0002
I0613 23:31:31.804908 15760 solver.cpp:228] Iteration 1360, loss = 1.07954
I0613 23:31:31.804932 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0613 23:31:31.804942 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.516736 (* 1 = 0.516736 loss)
I0613 23:31:31.804946 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.730656 (* 1 = 0.730656 loss)
I0613 23:31:31.804950 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.5143 (* 1 = 0.5143 loss)
I0613 23:31:31.804953 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.855845 (* 1 = 0.855845 loss)
I0613 23:31:31.804958 15760 sgd_solver.cpp:106] Iteration 1360, lr = 0.0002
I0613 23:33:18.417933 15760 solver.cpp:228] Iteration 1380, loss = 0.963639
I0613 23:33:18.417959 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.570312
I0613 23:33:18.417966 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.473641 (* 1 = 0.473641 loss)
I0613 23:33:18.417970 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.770445 (* 1 = 0.770445 loss)
I0613 23:33:18.417974 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0895487 (* 1 = 0.0895487 loss)
I0613 23:33:18.417979 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.198361 (* 1 = 0.198361 loss)
I0613 23:33:18.417984 15760 sgd_solver.cpp:106] Iteration 1380, lr = 0.0002
speed: 5.342s / iter
I0613 23:35:05.112510 15760 solver.cpp:228] Iteration 1400, loss = 1.03191
I0613 23:35:05.112537 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0613 23:35:05.112547 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.427311 (* 1 = 0.427311 loss)
I0613 23:35:05.112555 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.635144 (* 1 = 0.635144 loss)
I0613 23:35:05.112561 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0310651 (* 1 = 0.0310651 loss)
I0613 23:35:05.112570 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0769666 (* 1 = 0.0769666 loss)
I0613 23:35:05.112578 15760 sgd_solver.cpp:106] Iteration 1400, lr = 0.0002
I0613 23:36:52.221309 15760 solver.cpp:228] Iteration 1420, loss = 1.40983
I0613 23:36:52.221336 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0613 23:36:52.221346 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.403463 (* 1 = 0.403463 loss)
I0613 23:36:52.221352 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.660165 (* 1 = 0.660165 loss)
I0613 23:36:52.221359 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.074586 (* 1 = 0.074586 loss)
I0613 23:36:52.221365 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.374722 (* 1 = 0.374722 loss)
I0613 23:36:52.221372 15760 sgd_solver.cpp:106] Iteration 1420, lr = 0.0002
I0613 23:38:39.316440 15760 solver.cpp:228] Iteration 1440, loss = 0.804117
I0613 23:38:39.316468 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0613 23:38:39.316476 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.291673 (* 1 = 0.291673 loss)
I0613 23:38:39.316483 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.295213 (* 1 = 0.295213 loss)
I0613 23:38:39.316489 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120661 (* 1 = 0.0120661 loss)
I0613 23:38:39.316495 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0299838 (* 1 = 0.0299838 loss)
I0613 23:38:39.316504 15760 sgd_solver.cpp:106] Iteration 1440, lr = 0.0002
I0613 23:40:26.255388 15760 solver.cpp:228] Iteration 1460, loss = 1.20462
I0613 23:40:26.255415 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0613 23:40:26.255422 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.114182 (* 1 = 0.114182 loss)
I0613 23:40:26.255426 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.294203 (* 1 = 0.294203 loss)
I0613 23:40:26.255429 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164785 (* 1 = 0.0164785 loss)
I0613 23:40:26.255434 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225515 (* 1 = 0.0225515 loss)
I0613 23:40:26.255439 15760 sgd_solver.cpp:106] Iteration 1460, lr = 0.0002
I0613 23:42:13.304553 15760 solver.cpp:228] Iteration 1480, loss = 1.1872
I0613 23:42:13.304577 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0613 23:42:13.304585 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.389897 (* 1 = 0.389897 loss)
I0613 23:42:13.304589 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.686066 (* 1 = 0.686066 loss)
I0613 23:42:13.304594 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0332548 (* 1 = 0.0332548 loss)
I0613 23:42:13.304597 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0762353 (* 1 = 0.0762353 loss)
I0613 23:42:13.304602 15760 sgd_solver.cpp:106] Iteration 1480, lr = 0.0002
I0613 23:44:00.037379 15760 solver.cpp:228] Iteration 1500, loss = 1.33643
I0613 23:44:00.037400 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0613 23:44:00.037407 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.714032 (* 1 = 0.714032 loss)
I0613 23:44:00.037411 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.735647 (* 1 = 0.735647 loss)
I0613 23:44:00.037415 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0510652 (* 1 = 0.0510652 loss)
I0613 23:44:00.037418 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0909337 (* 1 = 0.0909337 loss)
I0613 23:44:00.037423 15760 sgd_solver.cpp:106] Iteration 1500, lr = 0.0002
I0613 23:45:46.626492 15760 solver.cpp:228] Iteration 1520, loss = 0.893927
I0613 23:45:46.626519 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0613 23:45:46.626528 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.226914 (* 1 = 0.226914 loss)
I0613 23:45:46.626533 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.504101 (* 1 = 0.504101 loss)
I0613 23:45:46.626536 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135682 (* 1 = 0.0135682 loss)
I0613 23:45:46.626539 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195703 (* 1 = 0.0195703 loss)
I0613 23:45:46.626545 15760 sgd_solver.cpp:106] Iteration 1520, lr = 0.0002
I0613 23:47:33.908545 15760 solver.cpp:228] Iteration 1540, loss = 1.25538
I0613 23:47:33.908566 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.601562
I0613 23:47:33.908573 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.480212 (* 1 = 0.480212 loss)
I0613 23:47:33.908576 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.83668 (* 1 = 0.83668 loss)
I0613 23:47:33.908581 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.046169 (* 1 = 0.046169 loss)
I0613 23:47:33.908584 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134747 (* 1 = 0.134747 loss)
I0613 23:47:33.908589 15760 sgd_solver.cpp:106] Iteration 1540, lr = 0.0002
I0613 23:49:20.554615 15760 solver.cpp:228] Iteration 1560, loss = 0.847779
I0613 23:49:20.554638 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0613 23:49:20.554648 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00268037 (* 1 = 0.00268037 loss)
I0613 23:49:20.554654 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113435 (* 1 = 0.113435 loss)
I0613 23:49:20.554659 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.029739 (* 1 = 0.029739 loss)
I0613 23:49:20.554666 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206832 (* 1 = 0.0206832 loss)
I0613 23:49:20.554672 15760 sgd_solver.cpp:106] Iteration 1560, lr = 0.0002
I0613 23:51:07.060488 15760 solver.cpp:228] Iteration 1580, loss = 0.757035
I0613 23:51:07.060513 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0613 23:51:07.060521 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.353588 (* 1 = 0.353588 loss)
I0613 23:51:07.060525 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.479078 (* 1 = 0.479078 loss)
I0613 23:51:07.060529 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807661 (* 1 = 0.00807661 loss)
I0613 23:51:07.060534 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306498 (* 1 = 0.0306498 loss)
I0613 23:51:07.060539 15760 sgd_solver.cpp:106] Iteration 1580, lr = 0.0002
speed: 5.342s / iter
I0613 23:52:53.203550 15760 solver.cpp:228] Iteration 1600, loss = 0.916642
I0613 23:52:53.203573 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0613 23:52:53.203579 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.592267 (* 1 = 0.592267 loss)
I0613 23:52:53.203583 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.757186 (* 1 = 0.757186 loss)
I0613 23:52:53.203586 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0334441 (* 1 = 0.0334441 loss)
I0613 23:52:53.203590 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0954051 (* 1 = 0.0954051 loss)
I0613 23:52:53.203594 15760 sgd_solver.cpp:106] Iteration 1600, lr = 0.0002
I0613 23:54:39.657647 15760 solver.cpp:228] Iteration 1620, loss = 1.19102
I0613 23:54:39.657677 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0613 23:54:39.657685 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0406554 (* 1 = 0.0406554 loss)
I0613 23:54:39.657688 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.265739 (* 1 = 0.265739 loss)
I0613 23:54:39.657692 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130076 (* 1 = 0.0130076 loss)
I0613 23:54:39.657696 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0350617 (* 1 = 0.0350617 loss)
I0613 23:54:39.657701 15760 sgd_solver.cpp:106] Iteration 1620, lr = 0.0002
I0613 23:56:25.919957 15760 solver.cpp:228] Iteration 1640, loss = 0.804646
I0613 23:56:25.919983 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0613 23:56:25.919991 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.100085 (* 1 = 0.100085 loss)
I0613 23:56:25.919996 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.32957 (* 1 = 0.32957 loss)
I0613 23:56:25.920001 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149883 (* 1 = 0.0149883 loss)
I0613 23:56:25.920003 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189585 (* 1 = 0.0189585 loss)
I0613 23:56:25.920009 15760 sgd_solver.cpp:106] Iteration 1640, lr = 0.0002
I0613 23:58:12.169800 15760 solver.cpp:228] Iteration 1660, loss = 0.735843
I0613 23:58:12.169826 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0613 23:58:12.169832 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.271357 (* 1 = 0.271357 loss)
I0613 23:58:12.169837 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.478626 (* 1 = 0.478626 loss)
I0613 23:58:12.169842 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226724 (* 1 = 0.0226724 loss)
I0613 23:58:12.169844 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036259 (* 1 = 0.036259 loss)
I0613 23:58:12.169850 15760 sgd_solver.cpp:106] Iteration 1660, lr = 0.0002
I0613 23:59:58.764220 15760 solver.cpp:228] Iteration 1680, loss = 1.48222
I0613 23:59:58.764243 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.273438
I0613 23:59:58.764250 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.29028 (* 1 = 1.29028 loss)
I0613 23:59:58.764253 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.14078 (* 1 = 1.14078 loss)
I0613 23:59:58.764257 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0719833 (* 1 = 0.0719833 loss)
I0613 23:59:58.764261 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.299331 (* 1 = 0.299331 loss)
I0613 23:59:58.764266 15760 sgd_solver.cpp:106] Iteration 1680, lr = 0.0002
I0614 00:01:45.215483 15760 solver.cpp:228] Iteration 1700, loss = 1.48728
I0614 00:01:45.215531 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.375
I0614 00:01:45.215540 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.626587 (* 1 = 0.626587 loss)
I0614 00:01:45.215544 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.914065 (* 1 = 0.914065 loss)
I0614 00:01:45.215549 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0264524 (* 1 = 0.0264524 loss)
I0614 00:01:45.215554 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0686916 (* 1 = 0.0686916 loss)
I0614 00:01:45.215564 15760 sgd_solver.cpp:106] Iteration 1700, lr = 0.0002
I0614 00:03:31.566383 15760 solver.cpp:228] Iteration 1720, loss = 0.849535
I0614 00:03:31.566411 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 00:03:31.566418 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.254007 (* 1 = 0.254007 loss)
I0614 00:03:31.566422 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.399489 (* 1 = 0.399489 loss)
I0614 00:03:31.566427 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186816 (* 1 = 0.0186816 loss)
I0614 00:03:31.566431 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0560106 (* 1 = 0.0560106 loss)
I0614 00:03:31.566437 15760 sgd_solver.cpp:106] Iteration 1720, lr = 0.0002
I0614 00:05:17.904654 15760 solver.cpp:228] Iteration 1740, loss = 1.10856
I0614 00:05:17.904677 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0614 00:05:17.904685 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.865837 (* 1 = 0.865837 loss)
I0614 00:05:17.904688 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.796778 (* 1 = 0.796778 loss)
I0614 00:05:17.904692 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245136 (* 1 = 0.0245136 loss)
I0614 00:05:17.904695 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102694 (* 1 = 0.102694 loss)
I0614 00:05:17.904700 15760 sgd_solver.cpp:106] Iteration 1740, lr = 0.0002
I0614 00:07:04.160219 15760 solver.cpp:228] Iteration 1760, loss = 1.29986
I0614 00:07:04.160243 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.625
I0614 00:07:04.160250 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.877053 (* 1 = 0.877053 loss)
I0614 00:07:04.160254 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.89986 (* 1 = 0.89986 loss)
I0614 00:07:04.160259 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0511358 (* 1 = 0.0511358 loss)
I0614 00:07:04.160261 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.216911 (* 1 = 0.216911 loss)
I0614 00:07:04.160265 15760 sgd_solver.cpp:106] Iteration 1760, lr = 0.0002
I0614 00:08:50.643479 15760 solver.cpp:228] Iteration 1780, loss = 0.751796
I0614 00:08:50.643505 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 00:08:50.643515 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.249844 (* 1 = 0.249844 loss)
I0614 00:08:50.643522 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.613041 (* 1 = 0.613041 loss)
I0614 00:08:50.643527 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00311675 (* 1 = 0.00311675 loss)
I0614 00:08:50.643534 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029524 (* 1 = 0.029524 loss)
I0614 00:08:50.643541 15760 sgd_solver.cpp:106] Iteration 1780, lr = 0.0002
speed: 5.339s / iter
I0614 00:10:36.924492 15760 solver.cpp:228] Iteration 1800, loss = 0.820315
I0614 00:10:36.924518 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.46875
I0614 00:10:36.924525 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.04292 (* 1 = 1.04292 loss)
I0614 00:10:36.924530 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.84733 (* 1 = 0.84733 loss)
I0614 00:10:36.924535 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0473808 (* 1 = 0.0473808 loss)
I0614 00:10:36.924537 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.192148 (* 1 = 0.192148 loss)
I0614 00:10:36.924543 15760 sgd_solver.cpp:106] Iteration 1800, lr = 0.0002
I0614 00:12:23.341946 15760 solver.cpp:228] Iteration 1820, loss = 1.2377
I0614 00:12:23.341969 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 00:12:23.341976 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0971705 (* 1 = 0.0971705 loss)
I0614 00:12:23.341980 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.362316 (* 1 = 0.362316 loss)
I0614 00:12:23.341984 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256792 (* 1 = 0.0256792 loss)
I0614 00:12:23.341987 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273871 (* 1 = 0.0273871 loss)
I0614 00:12:23.341992 15760 sgd_solver.cpp:106] Iteration 1820, lr = 0.0002
I0614 00:14:09.634481 15760 solver.cpp:228] Iteration 1840, loss = 0.927082
I0614 00:14:09.634507 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 00:14:09.634515 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.523863 (* 1 = 0.523863 loss)
I0614 00:14:09.634519 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.42898 (* 1 = 0.42898 loss)
I0614 00:14:09.634523 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218421 (* 1 = 0.0218421 loss)
I0614 00:14:09.634527 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026421 (* 1 = 0.026421 loss)
I0614 00:14:09.634532 15760 sgd_solver.cpp:106] Iteration 1840, lr = 0.0002
I0614 00:15:56.198750 15760 solver.cpp:228] Iteration 1860, loss = 1.73546
I0614 00:15:56.198772 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0614 00:15:56.198781 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.491285 (* 1 = 0.491285 loss)
I0614 00:15:56.198783 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.908907 (* 1 = 0.908907 loss)
I0614 00:15:56.198787 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.680268 (* 1 = 0.680268 loss)
I0614 00:15:56.198791 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.841394 (* 1 = 0.841394 loss)
I0614 00:15:56.198796 15760 sgd_solver.cpp:106] Iteration 1860, lr = 0.0002
I0614 00:17:43.334729 15760 solver.cpp:228] Iteration 1880, loss = 1.18139
I0614 00:17:43.334753 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 00:17:43.334764 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139524 (* 1 = 0.139524 loss)
I0614 00:17:43.334769 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.378719 (* 1 = 0.378719 loss)
I0614 00:17:43.334775 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165875 (* 1 = 0.0165875 loss)
I0614 00:17:43.334780 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159792 (* 1 = 0.0159792 loss)
I0614 00:17:43.334789 15760 sgd_solver.cpp:106] Iteration 1880, lr = 0.0002
I0614 00:19:30.267556 15760 solver.cpp:228] Iteration 1900, loss = 1.09159
I0614 00:19:30.267585 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 00:19:30.267594 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.468896 (* 1 = 0.468896 loss)
I0614 00:19:30.267599 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.717368 (* 1 = 0.717368 loss)
I0614 00:19:30.267602 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00421872 (* 1 = 0.00421872 loss)
I0614 00:19:30.267606 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0350394 (* 1 = 0.0350394 loss)
I0614 00:19:30.267613 15760 sgd_solver.cpp:106] Iteration 1900, lr = 0.0002
I0614 00:21:17.083664 15760 solver.cpp:228] Iteration 1920, loss = 1.05179
I0614 00:21:17.083689 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.414062
I0614 00:21:17.083698 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.07364 (* 1 = 1.07364 loss)
I0614 00:21:17.083701 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.92343 (* 1 = 0.92343 loss)
I0614 00:21:17.083706 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247293 (* 1 = 0.0247293 loss)
I0614 00:21:17.083710 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117188 (* 1 = 0.117188 loss)
I0614 00:21:17.083716 15760 sgd_solver.cpp:106] Iteration 1920, lr = 0.0002
I0614 00:23:04.508249 15760 solver.cpp:228] Iteration 1940, loss = 1.42989
I0614 00:23:04.508275 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 00:23:04.508285 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937886 (* 1 = 0.0937886 loss)
I0614 00:23:04.508291 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.271628 (* 1 = 0.271628 loss)
I0614 00:23:04.508297 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226721 (* 1 = 0.0226721 loss)
I0614 00:23:04.508303 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0253074 (* 1 = 0.0253074 loss)
I0614 00:23:04.508311 15760 sgd_solver.cpp:106] Iteration 1940, lr = 0.0002
I0614 00:24:51.143332 15760 solver.cpp:228] Iteration 1960, loss = 1.90517
I0614 00:24:51.143357 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0614 00:24:51.143368 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.597783 (* 1 = 0.597783 loss)
I0614 00:24:51.143373 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.870797 (* 1 = 0.870797 loss)
I0614 00:24:51.143379 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0835312 (* 1 = 0.0835312 loss)
I0614 00:24:51.143386 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.363285 (* 1 = 0.363285 loss)
I0614 00:24:51.143395 15760 sgd_solver.cpp:106] Iteration 1960, lr = 0.0002
I0614 00:26:38.417150 15760 solver.cpp:228] Iteration 1980, loss = 0.833915
I0614 00:26:38.417176 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 00:26:38.417184 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.150491 (* 1 = 0.150491 loss)
I0614 00:26:38.417188 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.305658 (* 1 = 0.305658 loss)
I0614 00:26:38.417192 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188588 (* 1 = 0.0188588 loss)
I0614 00:26:38.417196 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192109 (* 1 = 0.0192109 loss)
I0614 00:26:38.417201 15760 sgd_solver.cpp:106] Iteration 1980, lr = 0.0002
speed: 5.339s / iter
I0614 00:28:25.690239 15760 solver.cpp:228] Iteration 2000, loss = 0.778502
I0614 00:28:25.690268 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.445312
I0614 00:28:25.690275 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.551628 (* 1 = 0.551628 loss)
I0614 00:28:25.690280 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.26988 (* 1 = 1.26988 loss)
I0614 00:28:25.690285 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.119083 (* 1 = 0.119083 loss)
I0614 00:28:25.690289 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.396623 (* 1 = 0.396623 loss)
I0614 00:28:25.690295 15760 sgd_solver.cpp:106] Iteration 2000, lr = 0.0002
I0614 00:30:12.853418 15760 solver.cpp:228] Iteration 2020, loss = 1.4179
I0614 00:30:12.853446 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.5
I0614 00:30:12.853454 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.34855 (* 1 = 1.34855 loss)
I0614 00:30:12.853459 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.935338 (* 1 = 0.935338 loss)
I0614 00:30:12.853464 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0902756 (* 1 = 0.0902756 loss)
I0614 00:30:12.853469 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.478726 (* 1 = 0.478726 loss)
I0614 00:30:12.853476 15760 sgd_solver.cpp:106] Iteration 2020, lr = 0.0002
I0614 00:31:59.777653 15760 solver.cpp:228] Iteration 2040, loss = 0.813408
I0614 00:31:59.777678 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.46875
I0614 00:31:59.777684 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.722785 (* 1 = 0.722785 loss)
I0614 00:31:59.777688 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.830146 (* 1 = 0.830146 loss)
I0614 00:31:59.777691 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252569 (* 1 = 0.0252569 loss)
I0614 00:31:59.777695 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.129383 (* 1 = 0.129383 loss)
I0614 00:31:59.777700 15760 sgd_solver.cpp:106] Iteration 2040, lr = 0.0002
I0614 00:33:46.776801 15760 solver.cpp:228] Iteration 2060, loss = 0.818284
I0614 00:33:46.776830 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 00:33:46.776841 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.133512 (* 1 = 0.133512 loss)
I0614 00:33:46.776849 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.363155 (* 1 = 0.363155 loss)
I0614 00:33:46.776856 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0269094 (* 1 = 0.0269094 loss)
I0614 00:33:46.776863 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0885372 (* 1 = 0.0885372 loss)
I0614 00:33:46.776873 15760 sgd_solver.cpp:106] Iteration 2060, lr = 0.0002
I0614 00:35:33.084913 15760 solver.cpp:228] Iteration 2080, loss = 1.17823
I0614 00:35:33.084938 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 00:35:33.084949 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00379012 (* 1 = 0.00379012 loss)
I0614 00:35:33.084952 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128443 (* 1 = 0.128443 loss)
I0614 00:35:33.084955 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167733 (* 1 = 0.0167733 loss)
I0614 00:35:33.084959 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345646 (* 1 = 0.0345646 loss)
I0614 00:35:33.084964 15760 sgd_solver.cpp:106] Iteration 2080, lr = 0.0002
I0614 00:37:19.446214 15760 solver.cpp:228] Iteration 2100, loss = 1.10903
I0614 00:37:19.446240 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 00:37:19.446249 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.220276 (* 1 = 0.220276 loss)
I0614 00:37:19.446254 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.649893 (* 1 = 0.649893 loss)
I0614 00:37:19.446257 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0288863 (* 1 = 0.0288863 loss)
I0614 00:37:19.446261 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045782 (* 1 = 0.045782 loss)
I0614 00:37:19.446266 15760 sgd_solver.cpp:106] Iteration 2100, lr = 0.0002
I0614 00:39:05.945427 15760 solver.cpp:228] Iteration 2120, loss = 0.934856
I0614 00:39:05.945453 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 00:39:05.945461 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.256805 (* 1 = 0.256805 loss)
I0614 00:39:05.945466 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.452688 (* 1 = 0.452688 loss)
I0614 00:39:05.945469 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.112636 (* 1 = 0.112636 loss)
I0614 00:39:05.945473 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105283 (* 1 = 0.105283 loss)
I0614 00:39:05.945478 15760 sgd_solver.cpp:106] Iteration 2120, lr = 0.0002
I0614 00:40:52.557870 15760 solver.cpp:228] Iteration 2140, loss = 0.812741
I0614 00:40:52.557896 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 00:40:52.557906 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0985248 (* 1 = 0.0985248 loss)
I0614 00:40:52.557912 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.268087 (* 1 = 0.268087 loss)
I0614 00:40:52.557919 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00582655 (* 1 = 0.00582655 loss)
I0614 00:40:52.557926 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159669 (* 1 = 0.0159669 loss)
I0614 00:40:52.557934 15760 sgd_solver.cpp:106] Iteration 2140, lr = 0.0002
I0614 00:42:39.065449 15760 solver.cpp:228] Iteration 2160, loss = 0.812623
I0614 00:42:39.065474 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.515625
I0614 00:42:39.065480 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.635072 (* 1 = 0.635072 loss)
I0614 00:42:39.065485 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.764915 (* 1 = 0.764915 loss)
I0614 00:42:39.065488 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100002 (* 1 = 0.0100002 loss)
I0614 00:42:39.065492 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0854279 (* 1 = 0.0854279 loss)
I0614 00:42:39.065498 15760 sgd_solver.cpp:106] Iteration 2160, lr = 0.0002
I0614 00:44:25.257530 15760 solver.cpp:228] Iteration 2180, loss = 1.09308
I0614 00:44:25.257556 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 00:44:25.257565 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.19679 (* 1 = 0.19679 loss)
I0614 00:44:25.257570 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28752 (* 1 = 0.28752 loss)
I0614 00:44:25.257573 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485085 (* 1 = 0.00485085 loss)
I0614 00:44:25.257577 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0498492 (* 1 = 0.0498492 loss)
I0614 00:44:25.257582 15760 sgd_solver.cpp:106] Iteration 2180, lr = 0.0002
speed: 5.339s / iter
I0614 00:46:11.522640 15760 solver.cpp:228] Iteration 2200, loss = 1.12835
I0614 00:46:11.522665 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.617188
I0614 00:46:11.522671 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.597488 (* 1 = 0.597488 loss)
I0614 00:46:11.522675 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.947858 (* 1 = 0.947858 loss)
I0614 00:46:11.522678 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147297 (* 1 = 0.0147297 loss)
I0614 00:46:11.522681 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1307 (* 1 = 0.1307 loss)
I0614 00:46:11.522686 15760 sgd_solver.cpp:106] Iteration 2200, lr = 0.0002
I0614 00:47:57.933434 15760 solver.cpp:228] Iteration 2220, loss = 1.1778
I0614 00:47:57.933457 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 00:47:57.933465 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.121033 (* 1 = 0.121033 loss)
I0614 00:47:57.933468 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.158927 (* 1 = 0.158927 loss)
I0614 00:47:57.933472 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00750276 (* 1 = 0.00750276 loss)
I0614 00:47:57.933475 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026802 (* 1 = 0.026802 loss)
I0614 00:47:57.933480 15760 sgd_solver.cpp:106] Iteration 2220, lr = 0.0002
I0614 00:49:44.293784 15760 solver.cpp:228] Iteration 2240, loss = 0.995822
I0614 00:49:44.293810 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 00:49:44.293818 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0692126 (* 1 = 0.0692126 loss)
I0614 00:49:44.293823 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.166306 (* 1 = 0.166306 loss)
I0614 00:49:44.293826 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0308481 (* 1 = 0.0308481 loss)
I0614 00:49:44.293829 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0804546 (* 1 = 0.0804546 loss)
I0614 00:49:44.293834 15760 sgd_solver.cpp:106] Iteration 2240, lr = 0.0002
I0614 00:51:31.000134 15760 solver.cpp:228] Iteration 2260, loss = 0.883457
I0614 00:51:31.000159 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 00:51:31.000166 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.142617 (* 1 = 0.142617 loss)
I0614 00:51:31.000170 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.449727 (* 1 = 0.449727 loss)
I0614 00:51:31.000174 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195958 (* 1 = 0.0195958 loss)
I0614 00:51:31.000177 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0454955 (* 1 = 0.0454955 loss)
I0614 00:51:31.000182 15760 sgd_solver.cpp:106] Iteration 2260, lr = 0.0002
I0614 00:53:17.493676 15760 solver.cpp:228] Iteration 2280, loss = 0.725958
I0614 00:53:17.493702 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 00:53:17.493710 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.307574 (* 1 = 0.307574 loss)
I0614 00:53:17.493715 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.36477 (* 1 = 0.36477 loss)
I0614 00:53:17.493718 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104838 (* 1 = 0.0104838 loss)
I0614 00:53:17.493722 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218588 (* 1 = 0.0218588 loss)
I0614 00:53:17.493727 15760 sgd_solver.cpp:106] Iteration 2280, lr = 0.0002
I0614 00:55:03.663313 15760 solver.cpp:228] Iteration 2300, loss = 0.937012
I0614 00:55:03.663339 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 00:55:03.663347 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226749 (* 1 = 0.0226749 loss)
I0614 00:55:03.663350 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.123294 (* 1 = 0.123294 loss)
I0614 00:55:03.663354 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00887601 (* 1 = 0.00887601 loss)
I0614 00:55:03.663358 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0614611 (* 1 = 0.0614611 loss)
I0614 00:55:03.663362 15760 sgd_solver.cpp:106] Iteration 2300, lr = 0.0002
I0614 00:56:49.911711 15760 solver.cpp:228] Iteration 2320, loss = 0.808705
I0614 00:56:49.911736 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 00:56:49.911742 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.126414 (* 1 = 0.126414 loss)
I0614 00:56:49.911746 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.318962 (* 1 = 0.318962 loss)
I0614 00:56:49.911749 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364953 (* 1 = 0.0364953 loss)
I0614 00:56:49.911753 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0726372 (* 1 = 0.0726372 loss)
I0614 00:56:49.911757 15760 sgd_solver.cpp:106] Iteration 2320, lr = 0.0002
I0614 00:58:36.349246 15760 solver.cpp:228] Iteration 2340, loss = 0.891471
I0614 00:58:36.349270 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0614 00:58:36.349278 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.518329 (* 1 = 0.518329 loss)
I0614 00:58:36.349282 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.766311 (* 1 = 0.766311 loss)
I0614 00:58:36.349287 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134755 (* 1 = 0.0134755 loss)
I0614 00:58:36.349290 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0765237 (* 1 = 0.0765237 loss)
I0614 00:58:36.349295 15760 sgd_solver.cpp:106] Iteration 2340, lr = 0.0002
I0614 01:00:23.342665 15760 solver.cpp:228] Iteration 2360, loss = 1.20394
I0614 01:00:23.342694 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.601562
I0614 01:00:23.342703 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.776418 (* 1 = 0.776418 loss)
I0614 01:00:23.342710 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.807894 (* 1 = 0.807894 loss)
I0614 01:00:23.342715 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0517354 (* 1 = 0.0517354 loss)
I0614 01:00:23.342722 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.154065 (* 1 = 0.154065 loss)
I0614 01:00:23.342728 15760 sgd_solver.cpp:106] Iteration 2360, lr = 0.0002
I0614 01:02:10.460454 15760 solver.cpp:228] Iteration 2380, loss = 1.359
I0614 01:02:10.460477 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0614 01:02:10.460485 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.639883 (* 1 = 0.639883 loss)
I0614 01:02:10.460489 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.66144 (* 1 = 0.66144 loss)
I0614 01:02:10.460492 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01388 (* 1 = 0.01388 loss)
I0614 01:02:10.460495 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414441 (* 1 = 0.0414441 loss)
I0614 01:02:10.460501 15760 sgd_solver.cpp:106] Iteration 2380, lr = 0.0002
speed: 5.338s / iter
I0614 01:03:57.543238 15760 solver.cpp:228] Iteration 2400, loss = 0.714006
I0614 01:03:57.543270 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 01:03:57.543279 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0031215 (* 1 = 0.0031215 loss)
I0614 01:03:57.543284 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.189678 (* 1 = 0.189678 loss)
I0614 01:03:57.543288 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228867 (* 1 = 0.0228867 loss)
I0614 01:03:57.543293 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258423 (* 1 = 0.0258423 loss)
I0614 01:03:57.543299 15760 sgd_solver.cpp:106] Iteration 2400, lr = 0.0002
I0614 01:05:44.364156 15760 solver.cpp:228] Iteration 2420, loss = 0.768954
I0614 01:05:44.364181 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 01:05:44.364189 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.35123 (* 1 = 0.35123 loss)
I0614 01:05:44.364193 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.423868 (* 1 = 0.423868 loss)
I0614 01:05:44.364198 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160982 (* 1 = 0.0160982 loss)
I0614 01:05:44.364202 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315437 (* 1 = 0.0315437 loss)
I0614 01:05:44.364207 15760 sgd_solver.cpp:106] Iteration 2420, lr = 0.0002
I0614 01:07:31.386180 15760 solver.cpp:228] Iteration 2440, loss = 0.806151
I0614 01:07:31.386206 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.398438
I0614 01:07:31.386214 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.815545 (* 1 = 0.815545 loss)
I0614 01:07:31.386219 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.94985 (* 1 = 0.94985 loss)
I0614 01:07:31.386224 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600344 (* 1 = 0.00600344 loss)
I0614 01:07:31.386227 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.169415 (* 1 = 0.169415 loss)
I0614 01:07:31.386232 15760 sgd_solver.cpp:106] Iteration 2440, lr = 0.0002
I0614 01:09:18.344171 15760 solver.cpp:228] Iteration 2460, loss = 1.47222
I0614 01:09:18.344193 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0614 01:09:18.344200 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.698639 (* 1 = 0.698639 loss)
I0614 01:09:18.344204 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.67779 (* 1 = 0.67779 loss)
I0614 01:09:18.344208 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0436347 (* 1 = 0.0436347 loss)
I0614 01:09:18.344211 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0717575 (* 1 = 0.0717575 loss)
I0614 01:09:18.344216 15760 sgd_solver.cpp:106] Iteration 2460, lr = 0.0002
I0614 01:11:05.090272 15760 solver.cpp:228] Iteration 2480, loss = 1.35746
I0614 01:11:05.090299 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0614 01:11:05.090308 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.589442 (* 1 = 0.589442 loss)
I0614 01:11:05.090313 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.836431 (* 1 = 0.836431 loss)
I0614 01:11:05.090317 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0833537 (* 1 = 0.0833537 loss)
I0614 01:11:05.090322 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.368716 (* 1 = 0.368716 loss)
I0614 01:11:05.090328 15760 sgd_solver.cpp:106] Iteration 2480, lr = 0.0002
I0614 01:12:51.605701 15760 solver.cpp:228] Iteration 2500, loss = 0.756431
I0614 01:12:51.605726 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 01:12:51.605734 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0436722 (* 1 = 0.0436722 loss)
I0614 01:12:51.605739 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.248444 (* 1 = 0.248444 loss)
I0614 01:12:51.605742 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279865 (* 1 = 0.0279865 loss)
I0614 01:12:51.605746 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0618211 (* 1 = 0.0618211 loss)
I0614 01:12:51.605751 15760 sgd_solver.cpp:106] Iteration 2500, lr = 0.0002
I0614 01:14:39.224548 15760 solver.cpp:228] Iteration 2520, loss = 1.24146
I0614 01:14:39.224572 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.507812
I0614 01:14:39.224581 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.22101 (* 1 = 1.22101 loss)
I0614 01:14:39.224584 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.937984 (* 1 = 0.937984 loss)
I0614 01:14:39.224588 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.164491 (* 1 = 0.164491 loss)
I0614 01:14:39.224592 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.67096 (* 1 = 0.67096 loss)
I0614 01:14:39.224597 15760 sgd_solver.cpp:106] Iteration 2520, lr = 0.0002
I0614 01:16:26.105919 15760 solver.cpp:228] Iteration 2540, loss = 1.11538
I0614 01:16:26.105942 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 01:16:26.105948 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.555916 (* 1 = 0.555916 loss)
I0614 01:16:26.105952 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.661219 (* 1 = 0.661219 loss)
I0614 01:16:26.105957 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100203 (* 1 = 0.0100203 loss)
I0614 01:16:26.105959 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0533308 (* 1 = 0.0533308 loss)
I0614 01:16:26.105963 15760 sgd_solver.cpp:106] Iteration 2540, lr = 0.0002
I0614 01:18:13.152110 15760 solver.cpp:228] Iteration 2560, loss = 1.2514
I0614 01:18:13.152134 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 01:18:13.152142 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.220691 (* 1 = 0.220691 loss)
I0614 01:18:13.152144 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.318462 (* 1 = 0.318462 loss)
I0614 01:18:13.152148 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00469235 (* 1 = 0.00469235 loss)
I0614 01:18:13.152153 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332165 (* 1 = 0.0332165 loss)
I0614 01:18:13.152158 15760 sgd_solver.cpp:106] Iteration 2560, lr = 0.0002
I0614 01:19:59.913120 15760 solver.cpp:228] Iteration 2580, loss = 1.15725
I0614 01:19:59.913143 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 01:19:59.913151 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.216038 (* 1 = 0.216038 loss)
I0614 01:19:59.913154 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.283051 (* 1 = 0.283051 loss)
I0614 01:19:59.913157 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0036634 (* 1 = 0.0036634 loss)
I0614 01:19:59.913161 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269088 (* 1 = 0.0269088 loss)
I0614 01:19:59.913166 15760 sgd_solver.cpp:106] Iteration 2580, lr = 0.0002
speed: 5.338s / iter
I0614 01:21:46.302340 15760 solver.cpp:228] Iteration 2600, loss = 1.15134
I0614 01:21:46.302366 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 01:21:46.302372 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.185672 (* 1 = 0.185672 loss)
I0614 01:21:46.302376 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.331053 (* 1 = 0.331053 loss)
I0614 01:21:46.302381 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474649 (* 1 = 0.00474649 loss)
I0614 01:21:46.302383 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159983 (* 1 = 0.0159983 loss)
I0614 01:21:46.302388 15760 sgd_solver.cpp:106] Iteration 2600, lr = 0.0002
I0614 01:23:32.634136 15760 solver.cpp:228] Iteration 2620, loss = 0.97945
I0614 01:23:32.634162 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 01:23:32.634171 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117872 (* 1 = 0.117872 loss)
I0614 01:23:32.634174 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.197432 (* 1 = 0.197432 loss)
I0614 01:23:32.634178 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0063123 (* 1 = 0.0063123 loss)
I0614 01:23:32.634182 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146674 (* 1 = 0.0146674 loss)
I0614 01:23:32.634187 15760 sgd_solver.cpp:106] Iteration 2620, lr = 0.0002
I0614 01:25:18.933612 15760 solver.cpp:228] Iteration 2640, loss = 0.712282
I0614 01:25:18.933637 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 01:25:18.933645 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.358761 (* 1 = 0.358761 loss)
I0614 01:25:18.933650 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.664471 (* 1 = 0.664471 loss)
I0614 01:25:18.933653 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00589917 (* 1 = 0.00589917 loss)
I0614 01:25:18.933658 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0552365 (* 1 = 0.0552365 loss)
I0614 01:25:18.933662 15760 sgd_solver.cpp:106] Iteration 2640, lr = 0.0002
I0614 01:27:05.415937 15760 solver.cpp:228] Iteration 2660, loss = 1.33996
I0614 01:27:05.415961 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 01:27:05.415968 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.172041 (* 1 = 0.172041 loss)
I0614 01:27:05.415971 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.235559 (* 1 = 0.235559 loss)
I0614 01:27:05.415976 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00240846 (* 1 = 0.00240846 loss)
I0614 01:27:05.415979 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261432 (* 1 = 0.0261432 loss)
I0614 01:27:05.415984 15760 sgd_solver.cpp:106] Iteration 2660, lr = 0.0002
I0614 01:28:51.632294 15760 solver.cpp:228] Iteration 2680, loss = 0.824729
I0614 01:28:51.632318 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 01:28:51.632324 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.14128 (* 1 = 0.14128 loss)
I0614 01:28:51.632328 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.382394 (* 1 = 0.382394 loss)
I0614 01:28:51.632331 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162065 (* 1 = 0.0162065 loss)
I0614 01:28:51.632335 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302558 (* 1 = 0.0302558 loss)
I0614 01:28:51.632340 15760 sgd_solver.cpp:106] Iteration 2680, lr = 0.0002
I0614 01:30:37.837208 15760 solver.cpp:228] Iteration 2700, loss = 0.655324
I0614 01:30:37.837234 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 01:30:37.837242 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.103005 (* 1 = 0.103005 loss)
I0614 01:30:37.837246 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.231691 (* 1 = 0.231691 loss)
I0614 01:30:37.837250 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164476 (* 1 = 0.0164476 loss)
I0614 01:30:37.837254 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167757 (* 1 = 0.0167757 loss)
I0614 01:30:37.837258 15760 sgd_solver.cpp:106] Iteration 2700, lr = 0.0002
I0614 01:32:24.085214 15760 solver.cpp:228] Iteration 2720, loss = 1.69413
I0614 01:32:24.085242 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.484375
I0614 01:32:24.085250 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.747221 (* 1 = 0.747221 loss)
I0614 01:32:24.085258 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.90489 (* 1 = 0.90489 loss)
I0614 01:32:24.085263 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0944974 (* 1 = 0.0944974 loss)
I0614 01:32:24.085270 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.335743 (* 1 = 0.335743 loss)
I0614 01:32:24.085278 15760 sgd_solver.cpp:106] Iteration 2720, lr = 0.0002
I0614 01:34:10.509595 15760 solver.cpp:228] Iteration 2740, loss = 0.851855
I0614 01:34:10.509619 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 01:34:10.509627 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.137968 (* 1 = 0.137968 loss)
I0614 01:34:10.509631 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.261479 (* 1 = 0.261479 loss)
I0614 01:34:10.509635 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382935 (* 1 = 0.00382935 loss)
I0614 01:34:10.509639 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372539 (* 1 = 0.0372539 loss)
I0614 01:34:10.509644 15760 sgd_solver.cpp:106] Iteration 2740, lr = 0.0002
I0614 01:35:57.016633 15760 solver.cpp:228] Iteration 2760, loss = 1.19267
I0614 01:35:57.016657 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.460938
I0614 01:35:57.016664 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.59544 (* 1 = 1.59544 loss)
I0614 01:35:57.016667 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.06219 (* 1 = 1.06219 loss)
I0614 01:35:57.016671 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276736 (* 1 = 0.0276736 loss)
I0614 01:35:57.016674 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164209 (* 1 = 0.164209 loss)
I0614 01:35:57.016680 15760 sgd_solver.cpp:106] Iteration 2760, lr = 0.0002
I0614 01:37:43.412180 15760 solver.cpp:228] Iteration 2780, loss = 0.776419
I0614 01:37:43.412207 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 01:37:43.412217 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.166232 (* 1 = 0.166232 loss)
I0614 01:37:43.412223 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28136 (* 1 = 0.28136 loss)
I0614 01:37:43.412230 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00638302 (* 1 = 0.00638302 loss)
I0614 01:37:43.412236 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272731 (* 1 = 0.0272731 loss)
I0614 01:37:43.412245 15760 sgd_solver.cpp:106] Iteration 2780, lr = 0.0002
speed: 5.337s / iter
I0614 01:39:29.717135 15760 solver.cpp:228] Iteration 2800, loss = 0.995957
I0614 01:39:29.717159 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 01:39:29.717165 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.142682 (* 1 = 0.142682 loss)
I0614 01:39:29.717169 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.336353 (* 1 = 0.336353 loss)
I0614 01:39:29.717172 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.064233 (* 1 = 0.064233 loss)
I0614 01:39:29.717175 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.126803 (* 1 = 0.126803 loss)
I0614 01:39:29.717180 15760 sgd_solver.cpp:106] Iteration 2800, lr = 0.0002
I0614 01:41:16.023589 15760 solver.cpp:228] Iteration 2820, loss = 1.0557
I0614 01:41:16.023613 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.5
I0614 01:41:16.023622 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.85551 (* 1 = 0.85551 loss)
I0614 01:41:16.023624 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.921852 (* 1 = 0.921852 loss)
I0614 01:41:16.023628 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.157398 (* 1 = 0.157398 loss)
I0614 01:41:16.023632 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.905522 (* 1 = 0.905522 loss)
I0614 01:41:16.023636 15760 sgd_solver.cpp:106] Iteration 2820, lr = 0.0002
I0614 01:43:02.298060 15760 solver.cpp:228] Iteration 2840, loss = 0.476162
I0614 01:43:02.298086 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 01:43:02.298094 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00136788 (* 1 = 0.00136788 loss)
I0614 01:43:02.298099 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.185124 (* 1 = 0.185124 loss)
I0614 01:43:02.298104 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265167 (* 1 = 0.0265167 loss)
I0614 01:43:02.298107 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267969 (* 1 = 0.0267969 loss)
I0614 01:43:02.298112 15760 sgd_solver.cpp:106] Iteration 2840, lr = 0.0002
I0614 01:44:49.046974 15760 solver.cpp:228] Iteration 2860, loss = 0.942736
I0614 01:44:49.047004 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.539062
I0614 01:44:49.047013 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.668182 (* 1 = 0.668182 loss)
I0614 01:44:49.047019 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.796962 (* 1 = 0.796962 loss)
I0614 01:44:49.047024 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0349088 (* 1 = 0.0349088 loss)
I0614 01:44:49.047030 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.194148 (* 1 = 0.194148 loss)
I0614 01:44:49.047036 15760 sgd_solver.cpp:106] Iteration 2860, lr = 0.0002
I0614 01:46:35.846282 15760 solver.cpp:228] Iteration 2880, loss = 1.3516
I0614 01:46:35.846312 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.40625
I0614 01:46:35.846323 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.22665 (* 1 = 1.22665 loss)
I0614 01:46:35.846328 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.03006 (* 1 = 1.03006 loss)
I0614 01:46:35.846333 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.220438 (* 1 = 0.220438 loss)
I0614 01:46:35.846338 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.696643 (* 1 = 0.696643 loss)
I0614 01:46:35.846344 15760 sgd_solver.cpp:106] Iteration 2880, lr = 0.0002
I0614 01:48:22.584549 15760 solver.cpp:228] Iteration 2900, loss = 1.13152
I0614 01:48:22.584576 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.515625
I0614 01:48:22.584583 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.05232 (* 1 = 1.05232 loss)
I0614 01:48:22.584589 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.8859 (* 1 = 0.8859 loss)
I0614 01:48:22.584592 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00431775 (* 1 = 0.00431775 loss)
I0614 01:48:22.584596 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0888629 (* 1 = 0.0888629 loss)
I0614 01:48:22.584602 15760 sgd_solver.cpp:106] Iteration 2900, lr = 0.0002
I0614 01:50:09.735805 15760 solver.cpp:228] Iteration 2920, loss = 0.804498
I0614 01:50:09.735827 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 01:50:09.735834 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0659688 (* 1 = 0.0659688 loss)
I0614 01:50:09.735838 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.361186 (* 1 = 0.361186 loss)
I0614 01:50:09.735841 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00660268 (* 1 = 0.00660268 loss)
I0614 01:50:09.735846 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204477 (* 1 = 0.0204477 loss)
I0614 01:50:09.735849 15760 sgd_solver.cpp:106] Iteration 2920, lr = 0.0002
I0614 01:51:56.373236 15760 solver.cpp:228] Iteration 2940, loss = 0.924923
I0614 01:51:56.373260 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 01:51:56.373266 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.400269 (* 1 = 0.400269 loss)
I0614 01:51:56.373270 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.587438 (* 1 = 0.587438 loss)
I0614 01:51:56.373273 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.214189 (* 1 = 0.214189 loss)
I0614 01:51:56.373276 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.474643 (* 1 = 0.474643 loss)
I0614 01:51:56.373281 15760 sgd_solver.cpp:106] Iteration 2940, lr = 0.0002
I0614 01:53:43.639544 15760 solver.cpp:228] Iteration 2960, loss = 0.733738
I0614 01:53:43.639571 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.53125
I0614 01:53:43.639580 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.06131 (* 1 = 1.06131 loss)
I0614 01:53:43.639585 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.954499 (* 1 = 0.954499 loss)
I0614 01:53:43.639591 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0941777 (* 1 = 0.0941777 loss)
I0614 01:53:43.639596 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.882661 (* 1 = 0.882661 loss)
I0614 01:53:43.639601 15760 sgd_solver.cpp:106] Iteration 2960, lr = 0.0002
I0614 01:55:30.922578 15760 solver.cpp:228] Iteration 2980, loss = 0.732036
I0614 01:55:30.922605 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 01:55:30.922616 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215084 (* 1 = 0.0215084 loss)
I0614 01:55:30.922621 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0822024 (* 1 = 0.0822024 loss)
I0614 01:55:30.922624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126746 (* 1 = 0.0126746 loss)
I0614 01:55:30.922628 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491223 (* 1 = 0.0491223 loss)
I0614 01:55:30.922634 15760 sgd_solver.cpp:106] Iteration 2980, lr = 0.0002
speed: 5.337s / iter
I0614 01:57:18.254115 15760 solver.cpp:228] Iteration 3000, loss = 0.850899
I0614 01:57:18.254140 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.4375
I0614 01:57:18.254148 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.78516 (* 1 = 0.78516 loss)
I0614 01:57:18.254153 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.857996 (* 1 = 0.857996 loss)
I0614 01:57:18.254156 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0441526 (* 1 = 0.0441526 loss)
I0614 01:57:18.254160 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.104635 (* 1 = 0.104635 loss)
I0614 01:57:18.254165 15760 sgd_solver.cpp:106] Iteration 3000, lr = 0.0002
I0614 01:59:05.198333 15760 solver.cpp:228] Iteration 3020, loss = 1.49775
I0614 01:59:05.198359 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 01:59:05.198365 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.78578 (* 1 = 0.78578 loss)
I0614 01:59:05.198370 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.611221 (* 1 = 0.611221 loss)
I0614 01:59:05.198374 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00997789 (* 1 = 0.00997789 loss)
I0614 01:59:05.198379 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0620242 (* 1 = 0.0620242 loss)
I0614 01:59:05.198384 15760 sgd_solver.cpp:106] Iteration 3020, lr = 0.0002
I0614 02:00:51.786588 15760 solver.cpp:228] Iteration 3040, loss = 0.653337
I0614 02:00:51.786617 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 02:00:51.786625 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.309095 (* 1 = 0.309095 loss)
I0614 02:00:51.786629 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.515415 (* 1 = 0.515415 loss)
I0614 02:00:51.786633 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00550462 (* 1 = 0.00550462 loss)
I0614 02:00:51.786638 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452337 (* 1 = 0.0452337 loss)
I0614 02:00:51.786643 15760 sgd_solver.cpp:106] Iteration 3040, lr = 0.0002
I0614 02:02:38.437564 15760 solver.cpp:228] Iteration 3060, loss = 1.18168
I0614 02:02:38.437590 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 02:02:38.437600 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.155807 (* 1 = 0.155807 loss)
I0614 02:02:38.437607 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.23909 (* 1 = 0.23909 loss)
I0614 02:02:38.437613 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206373 (* 1 = 0.00206373 loss)
I0614 02:02:38.437619 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152183 (* 1 = 0.0152183 loss)
I0614 02:02:38.437628 15760 sgd_solver.cpp:106] Iteration 3060, lr = 0.0002
I0614 02:04:25.157402 15760 solver.cpp:228] Iteration 3080, loss = 0.907912
I0614 02:04:25.157429 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.421875
I0614 02:04:25.157439 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.518638 (* 1 = 0.518638 loss)
I0614 02:04:25.157445 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.03679 (* 1 = 1.03679 loss)
I0614 02:04:25.157450 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241196 (* 1 = 0.0241196 loss)
I0614 02:04:25.157455 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.122703 (* 1 = 0.122703 loss)
I0614 02:04:25.157462 15760 sgd_solver.cpp:106] Iteration 3080, lr = 0.0002
I0614 02:06:11.919383 15760 solver.cpp:228] Iteration 3100, loss = 1.0325
I0614 02:06:11.919406 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 02:06:11.919414 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.325164 (* 1 = 0.325164 loss)
I0614 02:06:11.919418 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.545614 (* 1 = 0.545614 loss)
I0614 02:06:11.919423 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180791 (* 1 = 0.0180791 loss)
I0614 02:06:11.919427 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0956486 (* 1 = 0.0956486 loss)
I0614 02:06:11.919432 15760 sgd_solver.cpp:106] Iteration 3100, lr = 0.0002
I0614 02:07:58.257995 15760 solver.cpp:228] Iteration 3120, loss = 1.27369
I0614 02:07:58.258021 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 02:07:58.258028 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.243048 (* 1 = 0.243048 loss)
I0614 02:07:58.258033 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.556027 (* 1 = 0.556027 loss)
I0614 02:07:58.258036 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182586 (* 1 = 0.0182586 loss)
I0614 02:07:58.258040 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0415623 (* 1 = 0.0415623 loss)
I0614 02:07:58.258045 15760 sgd_solver.cpp:106] Iteration 3120, lr = 0.0002
I0614 02:09:44.883442 15760 solver.cpp:228] Iteration 3140, loss = 0.863371
I0614 02:09:44.883467 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0614 02:09:44.883476 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.722264 (* 1 = 0.722264 loss)
I0614 02:09:44.883479 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.649861 (* 1 = 0.649861 loss)
I0614 02:09:44.883483 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0168052 (* 1 = 0.0168052 loss)
I0614 02:09:44.883486 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0547575 (* 1 = 0.0547575 loss)
I0614 02:09:44.883491 15760 sgd_solver.cpp:106] Iteration 3140, lr = 0.0002
I0614 02:11:31.275523 15760 solver.cpp:228] Iteration 3160, loss = 1.15223
I0614 02:11:31.275547 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 02:11:31.275553 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101027 (* 1 = 0.101027 loss)
I0614 02:11:31.275557 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.164886 (* 1 = 0.164886 loss)
I0614 02:11:31.275562 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00744755 (* 1 = 0.00744755 loss)
I0614 02:11:31.275564 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304727 (* 1 = 0.0304727 loss)
I0614 02:11:31.275569 15760 sgd_solver.cpp:106] Iteration 3160, lr = 0.0002
I0614 02:13:17.648092 15760 solver.cpp:228] Iteration 3180, loss = 1.0744
I0614 02:13:17.648115 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 02:13:17.648123 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0992179 (* 1 = 0.0992179 loss)
I0614 02:13:17.648126 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.190017 (* 1 = 0.190017 loss)
I0614 02:13:17.648130 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00981337 (* 1 = 0.00981337 loss)
I0614 02:13:17.648134 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0504038 (* 1 = 0.0504038 loss)
I0614 02:13:17.648138 15760 sgd_solver.cpp:106] Iteration 3180, lr = 0.0002
speed: 5.337s / iter
I0614 02:15:04.022955 15760 solver.cpp:228] Iteration 3200, loss = 0.691561
I0614 02:15:04.022980 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 02:15:04.022989 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.147949 (* 1 = 0.147949 loss)
I0614 02:15:04.022992 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.328172 (* 1 = 0.328172 loss)
I0614 02:15:04.022996 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0045745 (* 1 = 0.0045745 loss)
I0614 02:15:04.023000 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119677 (* 1 = 0.0119677 loss)
I0614 02:15:04.023005 15760 sgd_solver.cpp:106] Iteration 3200, lr = 0.0002
I0614 02:16:50.557766 15760 solver.cpp:228] Iteration 3220, loss = 0.838905
I0614 02:16:50.557790 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 02:16:50.557796 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.360787 (* 1 = 0.360787 loss)
I0614 02:16:50.557801 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.597698 (* 1 = 0.597698 loss)
I0614 02:16:50.557804 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00374706 (* 1 = 0.00374706 loss)
I0614 02:16:50.557807 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0480567 (* 1 = 0.0480567 loss)
I0614 02:16:50.557812 15760 sgd_solver.cpp:106] Iteration 3220, lr = 0.0002
I0614 02:18:36.966058 15760 solver.cpp:228] Iteration 3240, loss = 1.49632
I0614 02:18:36.966083 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 02:18:36.966090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.162643 (* 1 = 0.162643 loss)
I0614 02:18:36.966094 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.261861 (* 1 = 0.261861 loss)
I0614 02:18:36.966099 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265942 (* 1 = 0.0265942 loss)
I0614 02:18:36.966102 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158711 (* 1 = 0.0158711 loss)
I0614 02:18:36.966107 15760 sgd_solver.cpp:106] Iteration 3240, lr = 0.0002
I0614 02:20:23.447604 15760 solver.cpp:228] Iteration 3260, loss = 0.841437
I0614 02:20:23.447636 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 02:20:23.447648 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0067743 (* 1 = 0.0067743 loss)
I0614 02:20:23.447654 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161624 (* 1 = 0.161624 loss)
I0614 02:20:23.447661 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0669556 (* 1 = 0.0669556 loss)
I0614 02:20:23.447667 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439473 (* 1 = 0.0439473 loss)
I0614 02:20:23.447674 15760 sgd_solver.cpp:106] Iteration 3260, lr = 0.0002
I0614 02:22:09.905100 15760 solver.cpp:228] Iteration 3280, loss = 1.19208
I0614 02:22:09.905125 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 02:22:09.905133 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15412 (* 1 = 0.15412 loss)
I0614 02:22:09.905138 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.390458 (* 1 = 0.390458 loss)
I0614 02:22:09.905143 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00495286 (* 1 = 0.00495286 loss)
I0614 02:22:09.905146 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172084 (* 1 = 0.0172084 loss)
I0614 02:22:09.905151 15760 sgd_solver.cpp:106] Iteration 3280, lr = 0.0002
I0614 02:23:56.228636 15760 solver.cpp:228] Iteration 3300, loss = 0.82576
I0614 02:23:56.228660 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 02:23:56.228667 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232629 (* 1 = 0.0232629 loss)
I0614 02:23:56.228672 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.190844 (* 1 = 0.190844 loss)
I0614 02:23:56.228674 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144656 (* 1 = 0.0144656 loss)
I0614 02:23:56.228678 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255238 (* 1 = 0.0255238 loss)
I0614 02:23:56.228682 15760 sgd_solver.cpp:106] Iteration 3300, lr = 0.0002
I0614 02:25:42.490444 15760 solver.cpp:228] Iteration 3320, loss = 1.1082
I0614 02:25:42.490468 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 02:25:42.490475 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139617 (* 1 = 0.139617 loss)
I0614 02:25:42.490479 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.275707 (* 1 = 0.275707 loss)
I0614 02:25:42.490483 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0040474 (* 1 = 0.0040474 loss)
I0614 02:25:42.490486 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036181 (* 1 = 0.036181 loss)
I0614 02:25:42.490490 15760 sgd_solver.cpp:106] Iteration 3320, lr = 0.0002
I0614 02:27:29.111300 15760 solver.cpp:228] Iteration 3340, loss = 0.894209
I0614 02:27:29.111326 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.5625
I0614 02:27:29.111335 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.549563 (* 1 = 0.549563 loss)
I0614 02:27:29.111338 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.963274 (* 1 = 0.963274 loss)
I0614 02:27:29.111342 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.101431 (* 1 = 0.101431 loss)
I0614 02:27:29.111346 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.219748 (* 1 = 0.219748 loss)
I0614 02:27:29.111351 15760 sgd_solver.cpp:106] Iteration 3340, lr = 0.0002
I0614 02:29:15.743192 15760 solver.cpp:228] Iteration 3360, loss = 1.3558
I0614 02:29:15.743217 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0614 02:29:15.743224 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.282889 (* 1 = 0.282889 loss)
I0614 02:29:15.743228 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.670487 (* 1 = 0.670487 loss)
I0614 02:29:15.743232 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0424223 (* 1 = 0.0424223 loss)
I0614 02:29:15.743237 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.165213 (* 1 = 0.165213 loss)
I0614 02:29:15.743242 15760 sgd_solver.cpp:106] Iteration 3360, lr = 0.0002
I0614 02:31:02.774489 15760 solver.cpp:228] Iteration 3380, loss = 1.53689
I0614 02:31:02.774515 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 02:31:02.774523 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.138017 (* 1 = 0.138017 loss)
I0614 02:31:02.774528 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.280274 (* 1 = 0.280274 loss)
I0614 02:31:02.774533 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023078 (* 1 = 0.023078 loss)
I0614 02:31:02.774535 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0637056 (* 1 = 0.0637056 loss)
I0614 02:31:02.774540 15760 sgd_solver.cpp:106] Iteration 3380, lr = 0.0002
speed: 5.336s / iter
I0614 02:32:49.165072 15760 solver.cpp:228] Iteration 3400, loss = 0.788267
I0614 02:32:49.165098 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 02:32:49.165107 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.299282 (* 1 = 0.299282 loss)
I0614 02:32:49.165110 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.364106 (* 1 = 0.364106 loss)
I0614 02:32:49.165114 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314391 (* 1 = 0.00314391 loss)
I0614 02:32:49.165119 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0469284 (* 1 = 0.0469284 loss)
I0614 02:32:49.165125 15760 sgd_solver.cpp:106] Iteration 3400, lr = 0.0002
I0614 02:34:36.098835 15760 solver.cpp:228] Iteration 3420, loss = 0.939163
I0614 02:34:36.098861 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 02:34:36.098871 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.13695 (* 1 = 0.13695 loss)
I0614 02:34:36.098877 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.282127 (* 1 = 0.282127 loss)
I0614 02:34:36.098884 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0038627 (* 1 = 0.0038627 loss)
I0614 02:34:36.098891 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151517 (* 1 = 0.0151517 loss)
I0614 02:34:36.098898 15760 sgd_solver.cpp:106] Iteration 3420, lr = 0.0002
I0614 02:36:22.776554 15760 solver.cpp:228] Iteration 3440, loss = 0.91797
I0614 02:36:22.776582 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 02:36:22.776588 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.276373 (* 1 = 0.276373 loss)
I0614 02:36:22.776592 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.429445 (* 1 = 0.429445 loss)
I0614 02:36:22.776595 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0328301 (* 1 = 0.0328301 loss)
I0614 02:36:22.776598 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.131591 (* 1 = 0.131591 loss)
I0614 02:36:22.776603 15760 sgd_solver.cpp:106] Iteration 3440, lr = 0.0002
I0614 02:38:09.923202 15760 solver.cpp:228] Iteration 3460, loss = 1.1308
I0614 02:38:09.923228 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0614 02:38:09.923235 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.352061 (* 1 = 0.352061 loss)
I0614 02:38:09.923238 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.688834 (* 1 = 0.688834 loss)
I0614 02:38:09.923243 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181128 (* 1 = 0.0181128 loss)
I0614 02:38:09.923245 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12088 (* 1 = 0.12088 loss)
I0614 02:38:09.923251 15760 sgd_solver.cpp:106] Iteration 3460, lr = 0.0002
I0614 02:39:56.276063 15760 solver.cpp:228] Iteration 3480, loss = 0.852122
I0614 02:39:56.276088 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 02:39:56.276095 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.405154 (* 1 = 0.405154 loss)
I0614 02:39:56.276100 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.537502 (* 1 = 0.537502 loss)
I0614 02:39:56.276104 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110455 (* 1 = 0.0110455 loss)
I0614 02:39:56.276108 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395597 (* 1 = 0.0395597 loss)
I0614 02:39:56.276113 15760 sgd_solver.cpp:106] Iteration 3480, lr = 0.0002
I0614 02:41:42.902891 15760 solver.cpp:228] Iteration 3500, loss = 0.698087
I0614 02:41:42.902915 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 02:41:42.902925 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0825871 (* 1 = 0.0825871 loss)
I0614 02:41:42.902930 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.268142 (* 1 = 0.268142 loss)
I0614 02:41:42.902936 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00490644 (* 1 = 0.00490644 loss)
I0614 02:41:42.902941 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0710214 (* 1 = 0.0710214 loss)
I0614 02:41:42.902950 15760 sgd_solver.cpp:106] Iteration 3500, lr = 0.0002
I0614 02:43:30.322846 15760 solver.cpp:228] Iteration 3520, loss = 0.842836
I0614 02:43:30.322871 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 02:43:30.322878 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0252051 (* 1 = 0.0252051 loss)
I0614 02:43:30.322881 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.17578 (* 1 = 0.17578 loss)
I0614 02:43:30.322885 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00777128 (* 1 = 0.00777128 loss)
I0614 02:43:30.322890 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236891 (* 1 = 0.0236891 loss)
I0614 02:43:30.322894 15760 sgd_solver.cpp:106] Iteration 3520, lr = 0.0002
I0614 02:45:17.392299 15760 solver.cpp:228] Iteration 3540, loss = 1.31056
I0614 02:45:17.392324 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.585938
I0614 02:45:17.392333 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.648264 (* 1 = 0.648264 loss)
I0614 02:45:17.392336 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.791775 (* 1 = 0.791775 loss)
I0614 02:45:17.392339 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0229987 (* 1 = 0.0229987 loss)
I0614 02:45:17.392343 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.145828 (* 1 = 0.145828 loss)
I0614 02:45:17.392349 15760 sgd_solver.cpp:106] Iteration 3540, lr = 0.0002
I0614 02:47:04.684183 15760 solver.cpp:228] Iteration 3560, loss = 1.1709
I0614 02:47:04.684208 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.617188
I0614 02:47:04.684218 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.71105 (* 1 = 1.71105 loss)
I0614 02:47:04.684226 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.80224 (* 1 = 0.80224 loss)
I0614 02:47:04.684231 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0382207 (* 1 = 0.0382207 loss)
I0614 02:47:04.684237 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.339396 (* 1 = 0.339396 loss)
I0614 02:47:04.684244 15760 sgd_solver.cpp:106] Iteration 3560, lr = 0.0002
I0614 02:48:51.450366 15760 solver.cpp:228] Iteration 3580, loss = 0.82658
I0614 02:48:51.450392 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 02:48:51.450399 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.468001 (* 1 = 0.468001 loss)
I0614 02:48:51.450403 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.727065 (* 1 = 0.727065 loss)
I0614 02:48:51.450408 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0724024 (* 1 = 0.0724024 loss)
I0614 02:48:51.450412 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.470126 (* 1 = 0.470126 loss)
I0614 02:48:51.450417 15760 sgd_solver.cpp:106] Iteration 3580, lr = 0.0002
speed: 5.336s / iter
I0614 02:50:37.923450 15760 solver.cpp:228] Iteration 3600, loss = 1.04269
I0614 02:50:37.923475 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 02:50:37.923482 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.103807 (* 1 = 0.103807 loss)
I0614 02:50:37.923486 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.301184 (* 1 = 0.301184 loss)
I0614 02:50:37.923491 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000881261 (* 1 = 0.000881261 loss)
I0614 02:50:37.923493 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139807 (* 1 = 0.0139807 loss)
I0614 02:50:37.923498 15760 sgd_solver.cpp:106] Iteration 3600, lr = 0.0002
I0614 02:52:24.446053 15760 solver.cpp:228] Iteration 3620, loss = 0.78886
I0614 02:52:24.446076 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 02:52:24.446084 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.149207 (* 1 = 0.149207 loss)
I0614 02:52:24.446089 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.331077 (* 1 = 0.331077 loss)
I0614 02:52:24.446094 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105081 (* 1 = 0.0105081 loss)
I0614 02:52:24.446096 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315733 (* 1 = 0.0315733 loss)
I0614 02:52:24.446102 15760 sgd_solver.cpp:106] Iteration 3620, lr = 0.0002
I0614 02:54:10.908051 15760 solver.cpp:228] Iteration 3640, loss = 1.11083
I0614 02:54:10.908077 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 02:54:10.908083 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.216547 (* 1 = 0.216547 loss)
I0614 02:54:10.908087 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.329196 (* 1 = 0.329196 loss)
I0614 02:54:10.908090 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140277 (* 1 = 0.0140277 loss)
I0614 02:54:10.908094 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0657298 (* 1 = 0.0657298 loss)
I0614 02:54:10.908099 15760 sgd_solver.cpp:106] Iteration 3640, lr = 0.0002
I0614 02:55:57.158105 15760 solver.cpp:228] Iteration 3660, loss = 0.623089
I0614 02:55:57.158130 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 02:55:57.158138 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.185046 (* 1 = 0.185046 loss)
I0614 02:55:57.158141 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.301588 (* 1 = 0.301588 loss)
I0614 02:55:57.158146 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00705568 (* 1 = 0.00705568 loss)
I0614 02:55:57.158150 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00638318 (* 1 = 0.00638318 loss)
I0614 02:55:57.158155 15760 sgd_solver.cpp:106] Iteration 3660, lr = 0.0002
I0614 02:57:43.421397 15760 solver.cpp:228] Iteration 3680, loss = 0.677656
I0614 02:57:43.421423 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 02:57:43.421430 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.471325 (* 1 = 0.471325 loss)
I0614 02:57:43.421434 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.493205 (* 1 = 0.493205 loss)
I0614 02:57:43.421438 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00675411 (* 1 = 0.00675411 loss)
I0614 02:57:43.421442 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433979 (* 1 = 0.0433979 loss)
I0614 02:57:43.421447 15760 sgd_solver.cpp:106] Iteration 3680, lr = 0.0002
I0614 02:59:29.753240 15760 solver.cpp:228] Iteration 3700, loss = 0.918359
I0614 02:59:29.753264 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0614 02:59:29.753273 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.605176 (* 1 = 0.605176 loss)
I0614 02:59:29.753276 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.853254 (* 1 = 0.853254 loss)
I0614 02:59:29.753279 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.10084 (* 1 = 0.10084 loss)
I0614 02:59:29.753283 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.39995 (* 1 = 0.39995 loss)
I0614 02:59:29.753288 15760 sgd_solver.cpp:106] Iteration 3700, lr = 0.0002
I0614 03:01:16.110137 15760 solver.cpp:228] Iteration 3720, loss = 0.834456
I0614 03:01:16.110160 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0614 03:01:16.110167 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.439021 (* 1 = 0.439021 loss)
I0614 03:01:16.110172 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.651651 (* 1 = 0.651651 loss)
I0614 03:01:16.110174 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0481726 (* 1 = 0.0481726 loss)
I0614 03:01:16.110178 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0598734 (* 1 = 0.0598734 loss)
I0614 03:01:16.110183 15760 sgd_solver.cpp:106] Iteration 3720, lr = 0.0002
I0614 03:03:02.292830 15760 solver.cpp:228] Iteration 3740, loss = 0.978351
I0614 03:03:02.292855 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 03:03:02.292865 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.299183 (* 1 = 0.299183 loss)
I0614 03:03:02.292871 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.368059 (* 1 = 0.368059 loss)
I0614 03:03:02.292877 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00467728 (* 1 = 0.00467728 loss)
I0614 03:03:02.292884 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180628 (* 1 = 0.0180628 loss)
I0614 03:03:02.292892 15760 sgd_solver.cpp:106] Iteration 3740, lr = 0.0002
I0614 03:04:48.720362 15760 solver.cpp:228] Iteration 3760, loss = 0.893016
I0614 03:04:48.720386 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 03:04:48.720394 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.364401 (* 1 = 0.364401 loss)
I0614 03:04:48.720398 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.44969 (* 1 = 0.44969 loss)
I0614 03:04:48.720402 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00555877 (* 1 = 0.00555877 loss)
I0614 03:04:48.720407 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421156 (* 1 = 0.0421156 loss)
I0614 03:04:48.720412 15760 sgd_solver.cpp:106] Iteration 3760, lr = 0.0002
I0614 03:06:35.052003 15760 solver.cpp:228] Iteration 3780, loss = 1.33284
I0614 03:06:35.052026 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 03:06:35.052033 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.185413 (* 1 = 0.185413 loss)
I0614 03:06:35.052039 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.433427 (* 1 = 0.433427 loss)
I0614 03:06:35.052044 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128461 (* 1 = 0.00128461 loss)
I0614 03:06:35.052048 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135809 (* 1 = 0.0135809 loss)
I0614 03:06:35.052054 15760 sgd_solver.cpp:106] Iteration 3780, lr = 0.0002
speed: 5.335s / iter
I0614 03:08:21.291823 15760 solver.cpp:228] Iteration 3800, loss = 1.03882
I0614 03:08:21.291846 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 03:08:21.291854 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.165547 (* 1 = 0.165547 loss)
I0614 03:08:21.291858 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.32039 (* 1 = 0.32039 loss)
I0614 03:08:21.291862 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00247981 (* 1 = 0.00247981 loss)
I0614 03:08:21.291865 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171677 (* 1 = 0.0171677 loss)
I0614 03:08:21.291870 15760 sgd_solver.cpp:106] Iteration 3800, lr = 0.0002
I0614 03:10:07.788123 15760 solver.cpp:228] Iteration 3820, loss = 0.693461
I0614 03:10:07.788148 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 03:10:07.788156 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.135027 (* 1 = 0.135027 loss)
I0614 03:10:07.788161 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.169748 (* 1 = 0.169748 loss)
I0614 03:10:07.788164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178486 (* 1 = 0.00178486 loss)
I0614 03:10:07.788168 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283605 (* 1 = 0.0283605 loss)
I0614 03:10:07.788173 15760 sgd_solver.cpp:106] Iteration 3820, lr = 0.0002
I0614 03:11:54.021661 15760 solver.cpp:228] Iteration 3840, loss = 0.502003
I0614 03:11:54.021688 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 03:11:54.021697 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.14497 (* 1 = 0.14497 loss)
I0614 03:11:54.021703 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.354462 (* 1 = 0.354462 loss)
I0614 03:11:54.021708 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111724 (* 1 = 0.0111724 loss)
I0614 03:11:54.021714 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600056 (* 1 = 0.0600056 loss)
I0614 03:11:54.021723 15760 sgd_solver.cpp:106] Iteration 3840, lr = 0.0002
I0614 03:13:40.342237 15760 solver.cpp:228] Iteration 3860, loss = 1.43061
I0614 03:13:40.342259 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 03:13:40.342267 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.297982 (* 1 = 0.297982 loss)
I0614 03:13:40.342272 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.395758 (* 1 = 0.395758 loss)
I0614 03:13:40.342275 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143222 (* 1 = 0.00143222 loss)
I0614 03:13:40.342278 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044888 (* 1 = 0.044888 loss)
I0614 03:13:40.342283 15760 sgd_solver.cpp:106] Iteration 3860, lr = 0.0002
I0614 03:15:27.710332 15760 solver.cpp:228] Iteration 3880, loss = 1.43535
I0614 03:15:27.710359 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 03:15:27.710367 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15028 (* 1 = 0.15028 loss)
I0614 03:15:27.710373 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.248694 (* 1 = 0.248694 loss)
I0614 03:15:27.710377 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000683213 (* 1 = 0.000683213 loss)
I0614 03:15:27.710382 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017329 (* 1 = 0.017329 loss)
I0614 03:15:27.710387 15760 sgd_solver.cpp:106] Iteration 3880, lr = 0.0002
I0614 03:17:14.870818 15760 solver.cpp:228] Iteration 3900, loss = 0.929634
I0614 03:17:14.870844 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 03:17:14.870851 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.153061 (* 1 = 0.153061 loss)
I0614 03:17:14.870856 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.225831 (* 1 = 0.225831 loss)
I0614 03:17:14.870859 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0568481 (* 1 = 0.0568481 loss)
I0614 03:17:14.870863 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249298 (* 1 = 0.0249298 loss)
I0614 03:17:14.870868 15760 sgd_solver.cpp:106] Iteration 3900, lr = 0.0002
I0614 03:19:02.062686 15760 solver.cpp:228] Iteration 3920, loss = 1.19178
I0614 03:19:02.062713 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0614 03:19:02.062721 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.515532 (* 1 = 0.515532 loss)
I0614 03:19:02.062726 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.575515 (* 1 = 0.575515 loss)
I0614 03:19:02.062729 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0503122 (* 1 = 0.0503122 loss)
I0614 03:19:02.062733 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.285012 (* 1 = 0.285012 loss)
I0614 03:19:02.062739 15760 sgd_solver.cpp:106] Iteration 3920, lr = 0.0002
I0614 03:20:49.250164 15760 solver.cpp:228] Iteration 3940, loss = 0.694122
I0614 03:20:49.250190 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 03:20:49.250198 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.141612 (* 1 = 0.141612 loss)
I0614 03:20:49.250203 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.182632 (* 1 = 0.182632 loss)
I0614 03:20:49.250207 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00400435 (* 1 = 0.00400435 loss)
I0614 03:20:49.250212 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431208 (* 1 = 0.0431208 loss)
I0614 03:20:49.250217 15760 sgd_solver.cpp:106] Iteration 3940, lr = 0.0002
I0614 03:22:35.983166 15760 solver.cpp:228] Iteration 3960, loss = 1.21136
I0614 03:22:35.983191 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.554688
I0614 03:22:35.983198 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.992227 (* 1 = 0.992227 loss)
I0614 03:22:35.983203 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.853271 (* 1 = 0.853271 loss)
I0614 03:22:35.983207 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0043746 (* 1 = 0.0043746 loss)
I0614 03:22:35.983211 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0938661 (* 1 = 0.0938661 loss)
I0614 03:22:35.983217 15760 sgd_solver.cpp:106] Iteration 3960, lr = 0.0002
I0614 03:24:22.905457 15760 solver.cpp:228] Iteration 3980, loss = 1.05922
I0614 03:24:22.905486 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 03:24:22.905496 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.616117 (* 1 = 0.616117 loss)
I0614 03:24:22.905501 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.634578 (* 1 = 0.634578 loss)
I0614 03:24:22.905508 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0415659 (* 1 = 0.0415659 loss)
I0614 03:24:22.905513 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.215216 (* 1 = 0.215216 loss)
I0614 03:24:22.905519 15760 sgd_solver.cpp:106] Iteration 3980, lr = 0.0002
speed: 5.336s / iter
I0614 03:26:10.630136 15760 solver.cpp:228] Iteration 4000, loss = 1.07794
I0614 03:26:10.630163 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.46875
I0614 03:26:10.630172 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.50208 (* 1 = 1.50208 loss)
I0614 03:26:10.630177 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.21918 (* 1 = 1.21918 loss)
I0614 03:26:10.630180 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.112928 (* 1 = 0.112928 loss)
I0614 03:26:10.630185 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.795198 (* 1 = 0.795198 loss)
I0614 03:26:10.630190 15760 sgd_solver.cpp:106] Iteration 4000, lr = 0.0002
I0614 03:27:57.300911 15760 solver.cpp:228] Iteration 4020, loss = 1.11972
I0614 03:27:57.300937 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 03:27:57.300949 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.62474 (* 1 = 0.62474 loss)
I0614 03:27:57.300953 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.5138 (* 1 = 0.5138 loss)
I0614 03:27:57.300957 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171776 (* 1 = 0.0171776 loss)
I0614 03:27:57.300961 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100349 (* 1 = 0.100349 loss)
I0614 03:27:57.300967 15760 sgd_solver.cpp:106] Iteration 4020, lr = 0.0002
I0614 03:29:44.239145 15760 solver.cpp:228] Iteration 4040, loss = 1.13934
I0614 03:29:44.239167 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 03:29:44.239173 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.208466 (* 1 = 0.208466 loss)
I0614 03:29:44.239177 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.417575 (* 1 = 0.417575 loss)
I0614 03:29:44.239181 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244941 (* 1 = 0.0244941 loss)
I0614 03:29:44.239186 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0549158 (* 1 = 0.0549158 loss)
I0614 03:29:44.239190 15760 sgd_solver.cpp:106] Iteration 4040, lr = 0.0002
I0614 03:31:30.689141 15760 solver.cpp:228] Iteration 4060, loss = 1.01685
I0614 03:31:30.689164 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.390625
I0614 03:31:30.689172 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.19228 (* 1 = 1.19228 loss)
I0614 03:31:30.689177 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.23742 (* 1 = 1.23742 loss)
I0614 03:31:30.689182 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.101834 (* 1 = 0.101834 loss)
I0614 03:31:30.689185 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.75862 (* 1 = 0.75862 loss)
I0614 03:31:30.689189 15760 sgd_solver.cpp:106] Iteration 4060, lr = 0.0002
I0614 03:33:17.223742 15760 solver.cpp:228] Iteration 4080, loss = 0.958767
I0614 03:33:17.223764 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 03:33:17.223772 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.000328346 (* 1 = 0.000328346 loss)
I0614 03:33:17.223775 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0855557 (* 1 = 0.0855557 loss)
I0614 03:33:17.223778 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234662 (* 1 = 0.0234662 loss)
I0614 03:33:17.223783 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0508438 (* 1 = 0.0508438 loss)
I0614 03:33:17.223788 15760 sgd_solver.cpp:106] Iteration 4080, lr = 0.0002
I0614 03:35:03.456295 15760 solver.cpp:228] Iteration 4100, loss = 0.495639
I0614 03:35:03.456321 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 03:35:03.456328 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.188798 (* 1 = 0.188798 loss)
I0614 03:35:03.456332 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.225824 (* 1 = 0.225824 loss)
I0614 03:35:03.456336 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000836658 (* 1 = 0.000836658 loss)
I0614 03:35:03.456341 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016726 (* 1 = 0.016726 loss)
I0614 03:35:03.456346 15760 sgd_solver.cpp:106] Iteration 4100, lr = 0.0002
I0614 03:36:49.769083 15760 solver.cpp:228] Iteration 4120, loss = 0.637917
I0614 03:36:49.769107 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0614 03:36:49.769114 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.4134 (* 1 = 0.4134 loss)
I0614 03:36:49.769119 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.537745 (* 1 = 0.537745 loss)
I0614 03:36:49.769124 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245899 (* 1 = 0.0245899 loss)
I0614 03:36:49.769126 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127654 (* 1 = 0.127654 loss)
I0614 03:36:49.769131 15760 sgd_solver.cpp:106] Iteration 4120, lr = 0.0002
I0614 03:38:36.140050 15760 solver.cpp:228] Iteration 4140, loss = 0.598876
I0614 03:38:36.140071 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 03:38:36.140079 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.186046 (* 1 = 0.186046 loss)
I0614 03:38:36.140082 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.305238 (* 1 = 0.305238 loss)
I0614 03:38:36.140086 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0295836 (* 1 = 0.0295836 loss)
I0614 03:38:36.140089 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0427634 (* 1 = 0.0427634 loss)
I0614 03:38:36.140094 15760 sgd_solver.cpp:106] Iteration 4140, lr = 0.0002
I0614 03:40:22.636129 15760 solver.cpp:228] Iteration 4160, loss = 0.969427
I0614 03:40:22.636153 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 03:40:22.636162 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.161965 (* 1 = 0.161965 loss)
I0614 03:40:22.636165 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.210937 (* 1 = 0.210937 loss)
I0614 03:40:22.636168 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00854428 (* 1 = 0.00854428 loss)
I0614 03:40:22.636173 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185187 (* 1 = 0.0185187 loss)
I0614 03:40:22.636178 15760 sgd_solver.cpp:106] Iteration 4160, lr = 0.0002
I0614 03:42:08.932623 15760 solver.cpp:228] Iteration 4180, loss = 0.772914
I0614 03:42:08.932649 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 03:42:08.932658 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.123705 (* 1 = 0.123705 loss)
I0614 03:42:08.932665 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.23495 (* 1 = 0.23495 loss)
I0614 03:42:08.932672 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127661 (* 1 = 0.00127661 loss)
I0614 03:42:08.932679 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134007 (* 1 = 0.0134007 loss)
I0614 03:42:08.932688 15760 sgd_solver.cpp:106] Iteration 4180, lr = 0.0002
speed: 5.335s / iter
I0614 03:43:55.376132 15760 solver.cpp:228] Iteration 4200, loss = 0.869866
I0614 03:43:55.376158 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 03:43:55.376165 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.159978 (* 1 = 0.159978 loss)
I0614 03:43:55.376168 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.428037 (* 1 = 0.428037 loss)
I0614 03:43:55.376173 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00418312 (* 1 = 0.00418312 loss)
I0614 03:43:55.376176 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139219 (* 1 = 0.0139219 loss)
I0614 03:43:55.376180 15760 sgd_solver.cpp:106] Iteration 4200, lr = 0.0002
I0614 03:45:41.728876 15760 solver.cpp:228] Iteration 4220, loss = 0.771825
I0614 03:45:41.728901 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 03:45:41.728907 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0935207 (* 1 = 0.0935207 loss)
I0614 03:45:41.728911 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.140243 (* 1 = 0.140243 loss)
I0614 03:45:41.728915 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019592 (* 1 = 0.0019592 loss)
I0614 03:45:41.728919 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198954 (* 1 = 0.0198954 loss)
I0614 03:45:41.728924 15760 sgd_solver.cpp:106] Iteration 4220, lr = 0.0002
I0614 03:47:28.024436 15760 solver.cpp:228] Iteration 4240, loss = 0.756814
I0614 03:47:28.024464 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 03:47:28.024473 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.311759 (* 1 = 0.311759 loss)
I0614 03:47:28.024480 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.529051 (* 1 = 0.529051 loss)
I0614 03:47:28.024487 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.037903 (* 1 = 0.037903 loss)
I0614 03:47:28.024493 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101306 (* 1 = 0.101306 loss)
I0614 03:47:28.024502 15760 sgd_solver.cpp:106] Iteration 4240, lr = 0.0002
I0614 03:49:14.429522 15760 solver.cpp:228] Iteration 4260, loss = 0.846915
I0614 03:49:14.429548 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 03:49:14.429555 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.19288 (* 1 = 0.19288 loss)
I0614 03:49:14.429559 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.347705 (* 1 = 0.347705 loss)
I0614 03:49:14.429563 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250265 (* 1 = 0.00250265 loss)
I0614 03:49:14.429567 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0456245 (* 1 = 0.0456245 loss)
I0614 03:49:14.429574 15760 sgd_solver.cpp:106] Iteration 4260, lr = 0.0002
I0614 03:51:00.845186 15760 solver.cpp:228] Iteration 4280, loss = 0.94993
I0614 03:51:00.845211 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 03:51:00.845217 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.095453 (* 1 = 0.095453 loss)
I0614 03:51:00.845221 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.247403 (* 1 = 0.247403 loss)
I0614 03:51:00.845224 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142858 (* 1 = 0.0142858 loss)
I0614 03:51:00.845228 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159727 (* 1 = 0.0159727 loss)
I0614 03:51:00.845232 15760 sgd_solver.cpp:106] Iteration 4280, lr = 0.0002
I0614 03:52:47.202124 15760 solver.cpp:228] Iteration 4300, loss = 0.946905
I0614 03:52:47.202148 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0614 03:52:47.202155 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.361569 (* 1 = 0.361569 loss)
I0614 03:52:47.202159 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.522012 (* 1 = 0.522012 loss)
I0614 03:52:47.202163 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115892 (* 1 = 0.0115892 loss)
I0614 03:52:47.202167 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262376 (* 1 = 0.0262376 loss)
I0614 03:52:47.202172 15760 sgd_solver.cpp:106] Iteration 4300, lr = 0.0002
I0614 03:54:33.478111 15760 solver.cpp:228] Iteration 4320, loss = 0.796882
I0614 03:54:33.478135 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 03:54:33.478143 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.244935 (* 1 = 0.244935 loss)
I0614 03:54:33.478147 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.291179 (* 1 = 0.291179 loss)
I0614 03:54:33.478152 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019232 (* 1 = 0.019232 loss)
I0614 03:54:33.478155 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0647032 (* 1 = 0.0647032 loss)
I0614 03:54:33.478160 15760 sgd_solver.cpp:106] Iteration 4320, lr = 0.0002
I0614 03:56:19.902783 15760 solver.cpp:228] Iteration 4340, loss = 0.621637
I0614 03:56:19.902812 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 03:56:19.902820 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.228339 (* 1 = 0.228339 loss)
I0614 03:56:19.902824 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.294946 (* 1 = 0.294946 loss)
I0614 03:56:19.902827 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00843778 (* 1 = 0.00843778 loss)
I0614 03:56:19.902832 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00882364 (* 1 = 0.00882364 loss)
I0614 03:56:19.902838 15760 sgd_solver.cpp:106] Iteration 4340, lr = 0.0002
I0614 03:58:06.534065 15760 solver.cpp:228] Iteration 4360, loss = 0.836007
I0614 03:58:06.534088 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 03:58:06.534096 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0522702 (* 1 = 0.0522702 loss)
I0614 03:58:06.534099 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.153796 (* 1 = 0.153796 loss)
I0614 03:58:06.534103 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232971 (* 1 = 0.00232971 loss)
I0614 03:58:06.534106 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207261 (* 1 = 0.0207261 loss)
I0614 03:58:06.534111 15760 sgd_solver.cpp:106] Iteration 4360, lr = 0.0002
I0614 03:59:53.305502 15760 solver.cpp:228] Iteration 4380, loss = 1.032
I0614 03:59:53.305526 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.554688
I0614 03:59:53.305534 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.536263 (* 1 = 0.536263 loss)
I0614 03:59:53.305538 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.80279 (* 1 = 0.80279 loss)
I0614 03:59:53.305542 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170136 (* 1 = 0.0170136 loss)
I0614 03:59:53.305546 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340584 (* 1 = 0.0340584 loss)
I0614 03:59:53.305552 15760 sgd_solver.cpp:106] Iteration 4380, lr = 0.0002
speed: 5.335s / iter
I0614 04:01:40.350348 15760 solver.cpp:228] Iteration 4400, loss = 0.832095
I0614 04:01:40.350375 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 04:01:40.350384 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.631621 (* 1 = 0.631621 loss)
I0614 04:01:40.350389 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.501599 (* 1 = 0.501599 loss)
I0614 04:01:40.350394 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197939 (* 1 = 0.0197939 loss)
I0614 04:01:40.350399 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.199897 (* 1 = 0.199897 loss)
I0614 04:01:40.350404 15760 sgd_solver.cpp:106] Iteration 4400, lr = 0.0002
I0614 04:03:27.507962 15760 solver.cpp:228] Iteration 4420, loss = 0.732467
I0614 04:03:27.507988 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 04:03:27.507995 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.386938 (* 1 = 0.386938 loss)
I0614 04:03:27.507999 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.481123 (* 1 = 0.481123 loss)
I0614 04:03:27.508002 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00574117 (* 1 = 0.00574117 loss)
I0614 04:03:27.508007 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0510022 (* 1 = 0.0510022 loss)
I0614 04:03:27.508011 15760 sgd_solver.cpp:106] Iteration 4420, lr = 0.0002
I0614 04:05:13.937368 15760 solver.cpp:228] Iteration 4440, loss = 0.720532
I0614 04:05:13.937394 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0614 04:05:13.937402 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.154856 (* 1 = 0.154856 loss)
I0614 04:05:13.937407 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.733867 (* 1 = 0.733867 loss)
I0614 04:05:13.937410 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0330715 (* 1 = 0.0330715 loss)
I0614 04:05:13.937414 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0627984 (* 1 = 0.0627984 loss)
I0614 04:05:13.937418 15760 sgd_solver.cpp:106] Iteration 4440, lr = 0.0002
I0614 04:07:00.585875 15760 solver.cpp:228] Iteration 4460, loss = 0.815202
I0614 04:07:00.585901 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 04:07:00.585911 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.721546 (* 1 = 0.721546 loss)
I0614 04:07:00.585918 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.760785 (* 1 = 0.760785 loss)
I0614 04:07:00.585924 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00853007 (* 1 = 0.00853007 loss)
I0614 04:07:00.585932 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0979751 (* 1 = 0.0979751 loss)
I0614 04:07:00.585940 15760 sgd_solver.cpp:106] Iteration 4460, lr = 0.0002
I0614 04:08:47.335288 15760 solver.cpp:228] Iteration 4480, loss = 1.09715
I0614 04:08:47.335312 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 04:08:47.335320 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.337522 (* 1 = 0.337522 loss)
I0614 04:08:47.335325 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.441854 (* 1 = 0.441854 loss)
I0614 04:08:47.335328 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00520042 (* 1 = 0.00520042 loss)
I0614 04:08:47.335331 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0475314 (* 1 = 0.0475314 loss)
I0614 04:08:47.335336 15760 sgd_solver.cpp:106] Iteration 4480, lr = 0.0002
I0614 04:10:34.662569 15760 solver.cpp:228] Iteration 4500, loss = 0.76183
I0614 04:10:34.662592 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 04:10:34.662600 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168984 (* 1 = 0.0168984 loss)
I0614 04:10:34.662605 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128476 (* 1 = 0.128476 loss)
I0614 04:10:34.662608 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294938 (* 1 = 0.0294938 loss)
I0614 04:10:34.662612 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356655 (* 1 = 0.0356655 loss)
I0614 04:10:34.662617 15760 sgd_solver.cpp:106] Iteration 4500, lr = 0.0002
I0614 04:12:21.521085 15760 solver.cpp:228] Iteration 4520, loss = 0.78277
I0614 04:12:21.521111 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 04:12:21.521119 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.228112 (* 1 = 0.228112 loss)
I0614 04:12:21.521124 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.313124 (* 1 = 0.313124 loss)
I0614 04:12:21.521129 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147176 (* 1 = 0.0147176 loss)
I0614 04:12:21.521134 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273734 (* 1 = 0.0273734 loss)
I0614 04:12:21.521140 15760 sgd_solver.cpp:106] Iteration 4520, lr = 0.0002
I0614 04:14:08.581619 15760 solver.cpp:228] Iteration 4540, loss = 1.01592
I0614 04:14:08.581653 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.617188
I0614 04:14:08.581663 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.720485 (* 1 = 0.720485 loss)
I0614 04:14:08.581670 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.759542 (* 1 = 0.759542 loss)
I0614 04:14:08.581677 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351155 (* 1 = 0.00351155 loss)
I0614 04:14:08.581682 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0800112 (* 1 = 0.0800112 loss)
I0614 04:14:08.581689 15760 sgd_solver.cpp:106] Iteration 4540, lr = 0.0002
I0614 04:15:55.195083 15760 solver.cpp:228] Iteration 4560, loss = 0.941339
I0614 04:15:55.195106 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0614 04:15:55.195112 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.520827 (* 1 = 0.520827 loss)
I0614 04:15:55.195116 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.600279 (* 1 = 0.600279 loss)
I0614 04:15:55.195121 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0432772 (* 1 = 0.0432772 loss)
I0614 04:15:55.195123 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.172478 (* 1 = 0.172478 loss)
I0614 04:15:55.195128 15760 sgd_solver.cpp:106] Iteration 4560, lr = 0.0002
I0614 04:17:42.232576 15760 solver.cpp:228] Iteration 4580, loss = 1.14259
I0614 04:17:42.232604 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0614 04:17:42.232611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.420349 (* 1 = 0.420349 loss)
I0614 04:17:42.232615 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.71107 (* 1 = 0.71107 loss)
I0614 04:17:42.232620 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00389988 (* 1 = 0.00389988 loss)
I0614 04:17:42.232625 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346249 (* 1 = 0.0346249 loss)
I0614 04:17:42.232630 15760 sgd_solver.cpp:106] Iteration 4580, lr = 0.0002
speed: 5.335s / iter
I0614 04:19:28.705775 15760 solver.cpp:228] Iteration 4600, loss = 0.591473
I0614 04:19:28.705801 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.53125
I0614 04:19:28.705808 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.869687 (* 1 = 0.869687 loss)
I0614 04:19:28.705812 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.888402 (* 1 = 0.888402 loss)
I0614 04:19:28.705816 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171383 (* 1 = 0.0171383 loss)
I0614 04:19:28.705821 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.135154 (* 1 = 0.135154 loss)
I0614 04:19:28.705826 15760 sgd_solver.cpp:106] Iteration 4600, lr = 0.0002
I0614 04:21:14.957599 15760 solver.cpp:228] Iteration 4620, loss = 0.646264
I0614 04:21:14.957623 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 04:21:14.957631 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0230523 (* 1 = 0.0230523 loss)
I0614 04:21:14.957635 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.222198 (* 1 = 0.222198 loss)
I0614 04:21:14.957639 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0243631 (* 1 = 0.0243631 loss)
I0614 04:21:14.957643 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222851 (* 1 = 0.0222851 loss)
I0614 04:21:14.957646 15760 sgd_solver.cpp:106] Iteration 4620, lr = 0.0002
I0614 04:23:01.316123 15760 solver.cpp:228] Iteration 4640, loss = 1.00226
I0614 04:23:01.316148 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 04:23:01.316156 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.250832 (* 1 = 0.250832 loss)
I0614 04:23:01.316160 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.676392 (* 1 = 0.676392 loss)
I0614 04:23:01.316164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00803624 (* 1 = 0.00803624 loss)
I0614 04:23:01.316169 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040423 (* 1 = 0.040423 loss)
I0614 04:23:01.316174 15760 sgd_solver.cpp:106] Iteration 4640, lr = 0.0002
I0614 04:24:47.797935 15760 solver.cpp:228] Iteration 4660, loss = 1.1095
I0614 04:24:47.797961 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.554688
I0614 04:24:47.797969 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.849014 (* 1 = 0.849014 loss)
I0614 04:24:47.797973 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.922431 (* 1 = 0.922431 loss)
I0614 04:24:47.797977 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014024 (* 1 = 0.014024 loss)
I0614 04:24:47.797981 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.181148 (* 1 = 0.181148 loss)
I0614 04:24:47.797986 15760 sgd_solver.cpp:106] Iteration 4660, lr = 0.0002
I0614 04:26:34.162190 15760 solver.cpp:228] Iteration 4680, loss = 0.765743
I0614 04:26:34.162214 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 04:26:34.162221 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.395676 (* 1 = 0.395676 loss)
I0614 04:26:34.162225 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.682092 (* 1 = 0.682092 loss)
I0614 04:26:34.162230 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00635151 (* 1 = 0.00635151 loss)
I0614 04:26:34.162233 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0540836 (* 1 = 0.0540836 loss)
I0614 04:26:34.162237 15760 sgd_solver.cpp:106] Iteration 4680, lr = 0.0002
I0614 04:28:20.669090 15760 solver.cpp:228] Iteration 4700, loss = 0.967948
I0614 04:28:20.669113 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.4375
I0614 04:28:20.669122 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.5606 (* 1 = 1.5606 loss)
I0614 04:28:20.669128 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.28208 (* 1 = 1.28208 loss)
I0614 04:28:20.669133 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.13301 (* 1 = 0.13301 loss)
I0614 04:28:20.669139 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.696295 (* 1 = 0.696295 loss)
I0614 04:28:20.669145 15760 sgd_solver.cpp:106] Iteration 4700, lr = 0.0002
I0614 04:30:07.079615 15760 solver.cpp:228] Iteration 4720, loss = 0.729074
I0614 04:30:07.079640 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 04:30:07.079648 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325146 (* 1 = 0.0325146 loss)
I0614 04:30:07.079653 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.16692 (* 1 = 0.16692 loss)
I0614 04:30:07.079656 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221379 (* 1 = 0.0221379 loss)
I0614 04:30:07.079660 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288089 (* 1 = 0.0288089 loss)
I0614 04:30:07.079665 15760 sgd_solver.cpp:106] Iteration 4720, lr = 0.0002
I0614 04:31:53.542820 15760 solver.cpp:228] Iteration 4740, loss = 0.725902
I0614 04:31:53.542845 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0614 04:31:53.542852 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.912629 (* 1 = 0.912629 loss)
I0614 04:31:53.542856 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.770126 (* 1 = 0.770126 loss)
I0614 04:31:53.542861 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028753 (* 1 = 0.0028753 loss)
I0614 04:31:53.542865 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.092293 (* 1 = 0.092293 loss)
I0614 04:31:53.542870 15760 sgd_solver.cpp:106] Iteration 4740, lr = 0.0002
I0614 04:33:39.883582 15760 solver.cpp:228] Iteration 4760, loss = 0.663913
I0614 04:33:39.883608 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 04:33:39.883616 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.254663 (* 1 = 0.254663 loss)
I0614 04:33:39.883620 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.284038 (* 1 = 0.284038 loss)
I0614 04:33:39.883625 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151895 (* 1 = 0.0151895 loss)
I0614 04:33:39.883627 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566355 (* 1 = 0.0566355 loss)
I0614 04:33:39.883632 15760 sgd_solver.cpp:106] Iteration 4760, lr = 0.0002
I0614 04:35:26.281399 15760 solver.cpp:228] Iteration 4780, loss = 0.714871
I0614 04:35:26.281428 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 04:35:26.281437 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.127622 (* 1 = 0.127622 loss)
I0614 04:35:26.281443 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.190901 (* 1 = 0.190901 loss)
I0614 04:35:26.281450 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151551 (* 1 = 0.0151551 loss)
I0614 04:35:26.281455 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185314 (* 1 = 0.0185314 loss)
I0614 04:35:26.281463 15760 sgd_solver.cpp:106] Iteration 4780, lr = 0.0002
speed: 5.335s / iter
I0614 04:37:12.532053 15760 solver.cpp:228] Iteration 4800, loss = 0.831829
I0614 04:37:12.532078 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0614 04:37:12.532085 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.479993 (* 1 = 0.479993 loss)
I0614 04:37:12.532089 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.892287 (* 1 = 0.892287 loss)
I0614 04:37:12.532093 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247939 (* 1 = 0.0247939 loss)
I0614 04:37:12.532096 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120136 (* 1 = 0.120136 loss)
I0614 04:37:12.532101 15760 sgd_solver.cpp:106] Iteration 4800, lr = 0.0002
I0614 04:38:58.853973 15760 solver.cpp:228] Iteration 4820, loss = 0.68445
I0614 04:38:58.853998 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 04:38:58.854005 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.224846 (* 1 = 0.224846 loss)
I0614 04:38:58.854009 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.201172 (* 1 = 0.201172 loss)
I0614 04:38:58.854013 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648181 (* 1 = 0.00648181 loss)
I0614 04:38:58.854017 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233994 (* 1 = 0.0233994 loss)
I0614 04:38:58.854022 15760 sgd_solver.cpp:106] Iteration 4820, lr = 0.0002
I0614 04:40:45.524268 15760 solver.cpp:228] Iteration 4840, loss = 1.06978
I0614 04:40:45.524292 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 04:40:45.524302 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.165836 (* 1 = 0.165836 loss)
I0614 04:40:45.524307 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.284577 (* 1 = 0.284577 loss)
I0614 04:40:45.524313 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000406629 (* 1 = 0.000406629 loss)
I0614 04:40:45.524318 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00866376 (* 1 = 0.00866376 loss)
I0614 04:40:45.524324 15760 sgd_solver.cpp:106] Iteration 4840, lr = 0.0002
I0614 04:42:31.730233 15760 solver.cpp:228] Iteration 4860, loss = 0.97049
I0614 04:42:31.730257 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 04:42:31.730265 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.19789 (* 1 = 0.19789 loss)
I0614 04:42:31.730269 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.255386 (* 1 = 0.255386 loss)
I0614 04:42:31.730273 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100109 (* 1 = 0.0100109 loss)
I0614 04:42:31.730278 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0703427 (* 1 = 0.0703427 loss)
I0614 04:42:31.730283 15760 sgd_solver.cpp:106] Iteration 4860, lr = 0.0002
I0614 04:44:18.750979 15760 solver.cpp:228] Iteration 4880, loss = 0.770475
I0614 04:44:18.751003 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 04:44:18.751013 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.20082 (* 1 = 0.20082 loss)
I0614 04:44:18.751019 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.229105 (* 1 = 0.229105 loss)
I0614 04:44:18.751024 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111878 (* 1 = 0.0111878 loss)
I0614 04:44:18.751029 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.032285 (* 1 = 0.032285 loss)
I0614 04:44:18.751035 15760 sgd_solver.cpp:106] Iteration 4880, lr = 0.0002
I0614 04:46:06.126688 15760 solver.cpp:228] Iteration 4900, loss = 0.685758
I0614 04:46:06.126713 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 04:46:06.126719 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.233035 (* 1 = 0.233035 loss)
I0614 04:46:06.126724 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.224433 (* 1 = 0.224433 loss)
I0614 04:46:06.126726 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636763 (* 1 = 0.00636763 loss)
I0614 04:46:06.126730 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240916 (* 1 = 0.0240916 loss)
I0614 04:46:06.126735 15760 sgd_solver.cpp:106] Iteration 4900, lr = 0.0002
I0614 04:47:53.189127 15760 solver.cpp:228] Iteration 4920, loss = 0.986794
I0614 04:47:53.189157 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 04:47:53.189165 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.200444 (* 1 = 0.200444 loss)
I0614 04:47:53.189170 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.3695 (* 1 = 0.3695 loss)
I0614 04:47:53.189175 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193791 (* 1 = 0.00193791 loss)
I0614 04:47:53.189180 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267659 (* 1 = 0.0267659 loss)
I0614 04:47:53.189185 15760 sgd_solver.cpp:106] Iteration 4920, lr = 0.0002
I0614 04:49:40.091255 15760 solver.cpp:228] Iteration 4940, loss = 0.774907
I0614 04:49:40.091281 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 04:49:40.091289 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.216398 (* 1 = 0.216398 loss)
I0614 04:49:40.091293 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.370546 (* 1 = 0.370546 loss)
I0614 04:49:40.091297 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00172924 (* 1 = 0.00172924 loss)
I0614 04:49:40.091301 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368066 (* 1 = 0.0368066 loss)
I0614 04:49:40.091307 15760 sgd_solver.cpp:106] Iteration 4940, lr = 0.0002
I0614 04:51:27.046157 15760 solver.cpp:228] Iteration 4960, loss = 1.02372
I0614 04:51:27.046181 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 04:51:27.046188 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0506462 (* 1 = 0.0506462 loss)
I0614 04:51:27.046192 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.220184 (* 1 = 0.220184 loss)
I0614 04:51:27.046196 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00726026 (* 1 = 0.00726026 loss)
I0614 04:51:27.046200 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324187 (* 1 = 0.0324187 loss)
I0614 04:51:27.046205 15760 sgd_solver.cpp:106] Iteration 4960, lr = 0.0002
I0614 04:53:13.713665 15760 solver.cpp:228] Iteration 4980, loss = 1.24596
I0614 04:53:13.713688 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0614 04:53:13.713696 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.674938 (* 1 = 0.674938 loss)
I0614 04:53:13.713701 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.679065 (* 1 = 0.679065 loss)
I0614 04:53:13.713703 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00618881 (* 1 = 0.00618881 loss)
I0614 04:53:13.713707 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113827 (* 1 = 0.113827 loss)
I0614 04:53:13.713712 15760 sgd_solver.cpp:106] Iteration 4980, lr = 0.0002
speed: 5.335s / iter
I0614 04:54:55.489513 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_5000.caffemodel
I0614 04:55:01.205955 15760 solver.cpp:228] Iteration 5000, loss = 0.800723
I0614 04:55:01.205981 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 04:55:01.205988 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.137932 (* 1 = 0.137932 loss)
I0614 04:55:01.205993 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.261814 (* 1 = 0.261814 loss)
I0614 04:55:01.205996 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082231 (* 1 = 0.0082231 loss)
I0614 04:55:01.206001 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217903 (* 1 = 0.0217903 loss)
I0614 04:55:01.206005 15760 sgd_solver.cpp:106] Iteration 5000, lr = 0.0002
I0614 04:56:48.149298 15760 solver.cpp:228] Iteration 5020, loss = 0.762377
I0614 04:56:48.149327 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.53125
I0614 04:56:48.149336 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.527852 (* 1 = 0.527852 loss)
I0614 04:56:48.149343 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.899164 (* 1 = 0.899164 loss)
I0614 04:56:48.149348 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0585572 (* 1 = 0.0585572 loss)
I0614 04:56:48.149354 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.369006 (* 1 = 0.369006 loss)
I0614 04:56:48.149360 15760 sgd_solver.cpp:106] Iteration 5020, lr = 0.0002
I0614 04:58:34.665845 15760 solver.cpp:228] Iteration 5040, loss = 1.07993
I0614 04:58:34.665868 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 04:58:34.665875 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.770205 (* 1 = 0.770205 loss)
I0614 04:58:34.665879 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.588995 (* 1 = 0.588995 loss)
I0614 04:58:34.665884 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103444 (* 1 = 0.0103444 loss)
I0614 04:58:34.665886 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0723299 (* 1 = 0.0723299 loss)
I0614 04:58:34.665891 15760 sgd_solver.cpp:106] Iteration 5040, lr = 0.0002
I0614 05:00:21.485116 15760 solver.cpp:228] Iteration 5060, loss = 0.9781
I0614 05:00:21.485141 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 05:00:21.485148 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.295155 (* 1 = 0.295155 loss)
I0614 05:00:21.485152 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.407902 (* 1 = 0.407902 loss)
I0614 05:00:21.485157 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00665519 (* 1 = 0.00665519 loss)
I0614 05:00:21.485160 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0687045 (* 1 = 0.0687045 loss)
I0614 05:00:21.485164 15760 sgd_solver.cpp:106] Iteration 5060, lr = 0.0002
I0614 05:02:08.796191 15760 solver.cpp:228] Iteration 5080, loss = 1.01425
I0614 05:02:08.796221 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 05:02:08.796236 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.19362 (* 1 = 0.19362 loss)
I0614 05:02:08.796244 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.355639 (* 1 = 0.355639 loss)
I0614 05:02:08.796252 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171384 (* 1 = 0.0171384 loss)
I0614 05:02:08.796265 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184904 (* 1 = 0.0184904 loss)
I0614 05:02:08.796277 15760 sgd_solver.cpp:106] Iteration 5080, lr = 0.0002
I0614 05:03:55.213691 15760 solver.cpp:228] Iteration 5100, loss = 0.951662
I0614 05:03:55.213716 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 05:03:55.213722 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.512069 (* 1 = 0.512069 loss)
I0614 05:03:55.213726 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.512527 (* 1 = 0.512527 loss)
I0614 05:03:55.213730 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0380986 (* 1 = 0.0380986 loss)
I0614 05:03:55.213733 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.334045 (* 1 = 0.334045 loss)
I0614 05:03:55.213738 15760 sgd_solver.cpp:106] Iteration 5100, lr = 0.0002
I0614 05:05:41.725353 15760 solver.cpp:228] Iteration 5120, loss = 0.896578
I0614 05:05:41.725378 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 05:05:41.725384 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.167404 (* 1 = 0.167404 loss)
I0614 05:05:41.725389 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.346888 (* 1 = 0.346888 loss)
I0614 05:05:41.725392 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108986 (* 1 = 0.00108986 loss)
I0614 05:05:41.725395 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110508 (* 1 = 0.0110508 loss)
I0614 05:05:41.725400 15760 sgd_solver.cpp:106] Iteration 5120, lr = 0.0002
I0614 05:07:28.352654 15760 solver.cpp:228] Iteration 5140, loss = 0.804936
I0614 05:07:28.352680 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 05:07:28.352689 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.188237 (* 1 = 0.188237 loss)
I0614 05:07:28.352692 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309287 (* 1 = 0.309287 loss)
I0614 05:07:28.352696 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142154 (* 1 = 0.0142154 loss)
I0614 05:07:28.352700 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0549876 (* 1 = 0.0549876 loss)
I0614 05:07:28.352705 15760 sgd_solver.cpp:106] Iteration 5140, lr = 0.0002
I0614 05:09:14.689103 15760 solver.cpp:228] Iteration 5160, loss = 0.708855
I0614 05:09:14.689129 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 05:09:14.689137 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.214747 (* 1 = 0.214747 loss)
I0614 05:09:14.689141 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.244005 (* 1 = 0.244005 loss)
I0614 05:09:14.689146 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350921 (* 1 = 0.00350921 loss)
I0614 05:09:14.689149 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184487 (* 1 = 0.0184487 loss)
I0614 05:09:14.689155 15760 sgd_solver.cpp:106] Iteration 5160, lr = 0.0002
I0614 05:11:00.764631 15760 solver.cpp:228] Iteration 5180, loss = 0.716679
I0614 05:11:00.764654 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 05:11:00.764662 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.376605 (* 1 = 0.376605 loss)
I0614 05:11:00.764665 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.509067 (* 1 = 0.509067 loss)
I0614 05:11:00.764668 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0330446 (* 1 = 0.0330446 loss)
I0614 05:11:00.764672 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.22523 (* 1 = 0.22523 loss)
I0614 05:11:00.764677 15760 sgd_solver.cpp:106] Iteration 5180, lr = 0.0002
speed: 5.335s / iter
I0614 05:12:47.125780 15760 solver.cpp:228] Iteration 5200, loss = 1.00617
I0614 05:12:47.125804 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 05:12:47.125813 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.181694 (* 1 = 0.181694 loss)
I0614 05:12:47.125815 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.283165 (* 1 = 0.283165 loss)
I0614 05:12:47.125819 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00371671 (* 1 = 0.00371671 loss)
I0614 05:12:47.125823 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353129 (* 1 = 0.0353129 loss)
I0614 05:12:47.125828 15760 sgd_solver.cpp:106] Iteration 5200, lr = 0.0002
I0614 05:14:33.422502 15760 solver.cpp:228] Iteration 5220, loss = 0.803222
I0614 05:14:33.422528 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 05:14:33.422535 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.287054 (* 1 = 0.287054 loss)
I0614 05:14:33.422539 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309789 (* 1 = 0.309789 loss)
I0614 05:14:33.422544 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234109 (* 1 = 0.0234109 loss)
I0614 05:14:33.422547 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034551 (* 1 = 0.034551 loss)
I0614 05:14:33.422552 15760 sgd_solver.cpp:106] Iteration 5220, lr = 0.0002
I0614 05:16:19.879128 15760 solver.cpp:228] Iteration 5240, loss = 1.0586
I0614 05:16:19.879158 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0614 05:16:19.879165 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.418722 (* 1 = 0.418722 loss)
I0614 05:16:19.879169 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.876696 (* 1 = 0.876696 loss)
I0614 05:16:19.879173 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133053 (* 1 = 0.0133053 loss)
I0614 05:16:19.879176 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.062552 (* 1 = 0.062552 loss)
I0614 05:16:19.879181 15760 sgd_solver.cpp:106] Iteration 5240, lr = 0.0002
I0614 05:18:06.281327 15760 solver.cpp:228] Iteration 5260, loss = 0.770531
I0614 05:18:06.281350 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 05:18:06.281358 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.062966 (* 1 = 0.062966 loss)
I0614 05:18:06.281361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.295916 (* 1 = 0.295916 loss)
I0614 05:18:06.281365 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0441317 (* 1 = 0.0441317 loss)
I0614 05:18:06.281368 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0839505 (* 1 = 0.0839505 loss)
I0614 05:18:06.281373 15760 sgd_solver.cpp:106] Iteration 5260, lr = 0.0002
I0614 05:19:52.492336 15760 solver.cpp:228] Iteration 5280, loss = 0.85546
I0614 05:19:52.492362 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.539062
I0614 05:19:52.492372 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.544675 (* 1 = 0.544675 loss)
I0614 05:19:52.492378 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.804461 (* 1 = 0.804461 loss)
I0614 05:19:52.492385 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0420015 (* 1 = 0.0420015 loss)
I0614 05:19:52.492391 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.255729 (* 1 = 0.255729 loss)
I0614 05:19:52.492398 15760 sgd_solver.cpp:106] Iteration 5280, lr = 0.0002
I0614 05:21:39.043256 15760 solver.cpp:228] Iteration 5300, loss = 0.82883
I0614 05:21:39.043284 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 05:21:39.043292 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.257197 (* 1 = 0.257197 loss)
I0614 05:21:39.043298 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.361951 (* 1 = 0.361951 loss)
I0614 05:21:39.043303 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247678 (* 1 = 0.0247678 loss)
I0614 05:21:39.043309 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0593423 (* 1 = 0.0593423 loss)
I0614 05:21:39.043316 15760 sgd_solver.cpp:106] Iteration 5300, lr = 0.0002
I0614 05:23:25.396859 15760 solver.cpp:228] Iteration 5320, loss = 0.957649
I0614 05:23:25.396881 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 05:23:25.396888 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.227353 (* 1 = 0.227353 loss)
I0614 05:23:25.396893 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.207927 (* 1 = 0.207927 loss)
I0614 05:23:25.396895 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229275 (* 1 = 0.00229275 loss)
I0614 05:23:25.396899 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323117 (* 1 = 0.0323117 loss)
I0614 05:23:25.396904 15760 sgd_solver.cpp:106] Iteration 5320, lr = 0.0002
I0614 05:25:11.631592 15760 solver.cpp:228] Iteration 5340, loss = 1.15278
I0614 05:25:11.631616 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.507812
I0614 05:25:11.631623 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.790122 (* 1 = 0.790122 loss)
I0614 05:25:11.631628 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.841031 (* 1 = 0.841031 loss)
I0614 05:25:11.631631 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231943 (* 1 = 0.0231943 loss)
I0614 05:25:11.631634 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.200247 (* 1 = 0.200247 loss)
I0614 05:25:11.631639 15760 sgd_solver.cpp:106] Iteration 5340, lr = 0.0002
I0614 05:26:58.179684 15760 solver.cpp:228] Iteration 5360, loss = 0.918142
I0614 05:26:58.179710 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.601562
I0614 05:26:58.179718 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.587169 (* 1 = 0.587169 loss)
I0614 05:26:58.179723 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.828999 (* 1 = 0.828999 loss)
I0614 05:26:58.179728 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184675 (* 1 = 0.0184675 loss)
I0614 05:26:58.179730 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134885 (* 1 = 0.134885 loss)
I0614 05:26:58.179735 15760 sgd_solver.cpp:106] Iteration 5360, lr = 0.0002
I0614 05:28:44.954150 15760 solver.cpp:228] Iteration 5380, loss = 0.662302
I0614 05:28:44.954176 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 05:28:44.954183 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.449385 (* 1 = 0.449385 loss)
I0614 05:28:44.954187 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.543221 (* 1 = 0.543221 loss)
I0614 05:28:44.954191 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115697 (* 1 = 0.0115697 loss)
I0614 05:28:44.954195 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101202 (* 1 = 0.101202 loss)
I0614 05:28:44.954200 15760 sgd_solver.cpp:106] Iteration 5380, lr = 0.0002
speed: 5.334s / iter
I0614 05:30:32.397644 15760 solver.cpp:228] Iteration 5400, loss = 0.866748
I0614 05:30:32.397668 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 05:30:32.397677 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.195213 (* 1 = 0.195213 loss)
I0614 05:30:32.397683 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.317003 (* 1 = 0.317003 loss)
I0614 05:30:32.397688 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123107 (* 1 = 0.0123107 loss)
I0614 05:30:32.397694 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359145 (* 1 = 0.0359145 loss)
I0614 05:30:32.397701 15760 sgd_solver.cpp:106] Iteration 5400, lr = 0.0002
I0614 05:32:18.966305 15760 solver.cpp:228] Iteration 5420, loss = 0.475865
I0614 05:32:18.966328 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 05:32:18.966336 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.145406 (* 1 = 0.145406 loss)
I0614 05:32:18.966339 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.199046 (* 1 = 0.199046 loss)
I0614 05:32:18.966342 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182455 (* 1 = 0.0182455 loss)
I0614 05:32:18.966346 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00823544 (* 1 = 0.00823544 loss)
I0614 05:32:18.966351 15760 sgd_solver.cpp:106] Iteration 5420, lr = 0.0002
I0614 05:34:06.165948 15760 solver.cpp:228] Iteration 5440, loss = 0.589318
I0614 05:34:06.165973 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 05:34:06.165980 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.21605 (* 1 = 0.21605 loss)
I0614 05:34:06.165984 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.433034 (* 1 = 0.433034 loss)
I0614 05:34:06.165988 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338925 (* 1 = 0.00338925 loss)
I0614 05:34:06.165992 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10512 (* 1 = 0.10512 loss)
I0614 05:34:06.165997 15760 sgd_solver.cpp:106] Iteration 5440, lr = 0.0002
I0614 05:35:53.064483 15760 solver.cpp:228] Iteration 5460, loss = 0.514662
I0614 05:35:53.064510 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 05:35:53.064517 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.16519 (* 1 = 0.16519 loss)
I0614 05:35:53.064522 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.269768 (* 1 = 0.269768 loss)
I0614 05:35:53.064527 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00554673 (* 1 = 0.00554673 loss)
I0614 05:35:53.064530 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00629598 (* 1 = 0.00629598 loss)
I0614 05:35:53.064535 15760 sgd_solver.cpp:106] Iteration 5460, lr = 0.0002
I0614 05:37:39.901100 15760 solver.cpp:228] Iteration 5480, loss = 0.89127
I0614 05:37:39.901129 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.539062
I0614 05:37:39.901139 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.11537 (* 1 = 1.11537 loss)
I0614 05:37:39.901144 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.947998 (* 1 = 0.947998 loss)
I0614 05:37:39.901149 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0550525 (* 1 = 0.0550525 loss)
I0614 05:37:39.901154 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.69996 (* 1 = 0.69996 loss)
I0614 05:37:39.901160 15760 sgd_solver.cpp:106] Iteration 5480, lr = 0.0002
I0614 05:39:26.930919 15760 solver.cpp:228] Iteration 5500, loss = 0.963028
I0614 05:39:26.930948 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 05:39:26.930955 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0860789 (* 1 = 0.0860789 loss)
I0614 05:39:26.930961 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.39888 (* 1 = 0.39888 loss)
I0614 05:39:26.930965 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107823 (* 1 = 0.0107823 loss)
I0614 05:39:26.930969 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0357971 (* 1 = 0.0357971 loss)
I0614 05:39:26.930975 15760 sgd_solver.cpp:106] Iteration 5500, lr = 0.0002
I0614 05:41:13.767791 15760 solver.cpp:228] Iteration 5520, loss = 0.775971
I0614 05:41:13.767817 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 05:41:13.767825 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.329931 (* 1 = 0.329931 loss)
I0614 05:41:13.767829 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.446285 (* 1 = 0.446285 loss)
I0614 05:41:13.767833 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154496 (* 1 = 0.0154496 loss)
I0614 05:41:13.767838 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339118 (* 1 = 0.0339118 loss)
I0614 05:41:13.767843 15760 sgd_solver.cpp:106] Iteration 5520, lr = 0.0002
I0614 05:43:00.827942 15760 solver.cpp:228] Iteration 5540, loss = 0.754777
I0614 05:43:00.827967 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 05:43:00.827975 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.163004 (* 1 = 0.163004 loss)
I0614 05:43:00.827978 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.422045 (* 1 = 0.422045 loss)
I0614 05:43:00.827982 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135806 (* 1 = 0.0135806 loss)
I0614 05:43:00.827986 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208984 (* 1 = 0.0208984 loss)
I0614 05:43:00.827991 15760 sgd_solver.cpp:106] Iteration 5540, lr = 0.0002
I0614 05:44:47.605700 15760 solver.cpp:228] Iteration 5560, loss = 0.954751
I0614 05:44:47.605722 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 05:44:47.605731 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.195666 (* 1 = 0.195666 loss)
I0614 05:44:47.605733 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.25207 (* 1 = 0.25207 loss)
I0614 05:44:47.605737 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000519447 (* 1 = 0.000519447 loss)
I0614 05:44:47.605741 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129078 (* 1 = 0.0129078 loss)
I0614 05:44:47.605746 15760 sgd_solver.cpp:106] Iteration 5560, lr = 0.0002
I0614 05:46:34.174363 15760 solver.cpp:228] Iteration 5580, loss = 0.501383
I0614 05:46:34.174386 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 05:46:34.174393 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.138193 (* 1 = 0.138193 loss)
I0614 05:46:34.174397 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.177252 (* 1 = 0.177252 loss)
I0614 05:46:34.174401 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121285 (* 1 = 0.00121285 loss)
I0614 05:46:34.174404 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00879184 (* 1 = 0.00879184 loss)
I0614 05:46:34.174409 15760 sgd_solver.cpp:106] Iteration 5580, lr = 0.0002
speed: 5.334s / iter
I0614 05:48:20.641727 15760 solver.cpp:228] Iteration 5600, loss = 0.818302
I0614 05:48:20.641752 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 05:48:20.641759 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.130887 (* 1 = 0.130887 loss)
I0614 05:48:20.641763 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.456659 (* 1 = 0.456659 loss)
I0614 05:48:20.641768 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241728 (* 1 = 0.00241728 loss)
I0614 05:48:20.641772 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00691243 (* 1 = 0.00691243 loss)
I0614 05:48:20.641777 15760 sgd_solver.cpp:106] Iteration 5600, lr = 0.0002
I0614 05:50:06.841446 15760 solver.cpp:228] Iteration 5620, loss = 0.71115
I0614 05:50:06.841470 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 05:50:06.841477 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.277203 (* 1 = 0.277203 loss)
I0614 05:50:06.841481 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309219 (* 1 = 0.309219 loss)
I0614 05:50:06.841485 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0307245 (* 1 = 0.0307245 loss)
I0614 05:50:06.841488 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0580933 (* 1 = 0.0580933 loss)
I0614 05:50:06.841493 15760 sgd_solver.cpp:106] Iteration 5620, lr = 0.0002
I0614 05:51:53.547245 15760 solver.cpp:228] Iteration 5640, loss = 0.793385
I0614 05:51:53.547267 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 05:51:53.547276 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0275272 (* 1 = 0.0275272 loss)
I0614 05:51:53.547282 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.138231 (* 1 = 0.138231 loss)
I0614 05:51:53.547287 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205225 (* 1 = 0.0205225 loss)
I0614 05:51:53.547292 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451702 (* 1 = 0.0451702 loss)
I0614 05:51:53.547298 15760 sgd_solver.cpp:106] Iteration 5640, lr = 0.0002
I0614 05:53:39.990082 15760 solver.cpp:228] Iteration 5660, loss = 0.989164
I0614 05:53:39.990110 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 05:53:39.990118 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.145994 (* 1 = 0.145994 loss)
I0614 05:53:39.990121 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.187946 (* 1 = 0.187946 loss)
I0614 05:53:39.990125 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00258776 (* 1 = 0.00258776 loss)
I0614 05:53:39.990128 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246916 (* 1 = 0.0246916 loss)
I0614 05:53:39.990134 15760 sgd_solver.cpp:106] Iteration 5660, lr = 0.0002
I0614 05:55:26.659668 15760 solver.cpp:228] Iteration 5680, loss = 0.920804
I0614 05:55:26.659693 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 05:55:26.659700 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.365506 (* 1 = 0.365506 loss)
I0614 05:55:26.659705 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.54107 (* 1 = 0.54107 loss)
I0614 05:55:26.659709 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181142 (* 1 = 0.0181142 loss)
I0614 05:55:26.659713 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0589048 (* 1 = 0.0589048 loss)
I0614 05:55:26.659718 15760 sgd_solver.cpp:106] Iteration 5680, lr = 0.0002
I0614 05:57:13.258024 15760 solver.cpp:228] Iteration 5700, loss = 0.683442
I0614 05:57:13.258054 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 05:57:13.258060 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.266053 (* 1 = 0.266053 loss)
I0614 05:57:13.258064 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.439702 (* 1 = 0.439702 loss)
I0614 05:57:13.258069 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00735599 (* 1 = 0.00735599 loss)
I0614 05:57:13.258072 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0772705 (* 1 = 0.0772705 loss)
I0614 05:57:13.258077 15760 sgd_solver.cpp:106] Iteration 5700, lr = 0.0002
I0614 05:58:59.533313 15760 solver.cpp:228] Iteration 5720, loss = 0.723999
I0614 05:58:59.533339 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 05:58:59.533349 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.465236 (* 1 = 0.465236 loss)
I0614 05:58:59.533356 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.451515 (* 1 = 0.451515 loss)
I0614 05:58:59.533362 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00978162 (* 1 = 0.00978162 loss)
I0614 05:58:59.533368 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0550024 (* 1 = 0.0550024 loss)
I0614 05:58:59.533376 15760 sgd_solver.cpp:106] Iteration 5720, lr = 0.0002
I0614 06:00:46.299763 15760 solver.cpp:228] Iteration 5740, loss = 0.811693
I0614 06:00:46.299787 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 06:00:46.299795 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.181131 (* 1 = 0.181131 loss)
I0614 06:00:46.299800 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.209878 (* 1 = 0.209878 loss)
I0614 06:00:46.299804 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00500725 (* 1 = 0.00500725 loss)
I0614 06:00:46.299808 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251194 (* 1 = 0.0251194 loss)
I0614 06:00:46.299813 15760 sgd_solver.cpp:106] Iteration 5740, lr = 0.0002
I0614 06:02:32.499488 15760 solver.cpp:228] Iteration 5760, loss = 0.880979
I0614 06:02:32.499512 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 06:02:32.499519 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.133821 (* 1 = 0.133821 loss)
I0614 06:02:32.499523 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.183776 (* 1 = 0.183776 loss)
I0614 06:02:32.499528 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00289535 (* 1 = 0.00289535 loss)
I0614 06:02:32.499531 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316452 (* 1 = 0.0316452 loss)
I0614 06:02:32.499538 15760 sgd_solver.cpp:106] Iteration 5760, lr = 0.0002
I0614 06:04:19.136242 15760 solver.cpp:228] Iteration 5780, loss = 0.784656
I0614 06:04:19.136266 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 06:04:19.136273 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.473834 (* 1 = 0.473834 loss)
I0614 06:04:19.136277 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.435318 (* 1 = 0.435318 loss)
I0614 06:04:19.136281 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00812685 (* 1 = 0.00812685 loss)
I0614 06:04:19.136286 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369451 (* 1 = 0.0369451 loss)
I0614 06:04:19.136291 15760 sgd_solver.cpp:106] Iteration 5780, lr = 0.0002
speed: 5.334s / iter
I0614 06:06:05.455191 15760 solver.cpp:228] Iteration 5800, loss = 0.844331
I0614 06:06:05.455215 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 06:06:05.455222 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.042762 (* 1 = 0.042762 loss)
I0614 06:06:05.455226 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.194975 (* 1 = 0.194975 loss)
I0614 06:06:05.455230 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146635 (* 1 = 0.0146635 loss)
I0614 06:06:05.455235 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254813 (* 1 = 0.0254813 loss)
I0614 06:06:05.455240 15760 sgd_solver.cpp:106] Iteration 5800, lr = 0.0002
I0614 06:07:51.730916 15760 solver.cpp:228] Iteration 5820, loss = 0.724108
I0614 06:07:51.730940 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 06:07:51.730947 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.138045 (* 1 = 0.138045 loss)
I0614 06:07:51.730952 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.211288 (* 1 = 0.211288 loss)
I0614 06:07:51.730955 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00368568 (* 1 = 0.00368568 loss)
I0614 06:07:51.730958 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380908 (* 1 = 0.0380908 loss)
I0614 06:07:51.730964 15760 sgd_solver.cpp:106] Iteration 5820, lr = 0.0002
I0614 06:09:38.181083 15760 solver.cpp:228] Iteration 5840, loss = 0.897039
I0614 06:09:38.181111 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 06:09:38.181119 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.555493 (* 1 = 0.555493 loss)
I0614 06:09:38.181123 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.665196 (* 1 = 0.665196 loss)
I0614 06:09:38.181128 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00505307 (* 1 = 0.00505307 loss)
I0614 06:09:38.181131 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109578 (* 1 = 0.109578 loss)
I0614 06:09:38.181136 15760 sgd_solver.cpp:106] Iteration 5840, lr = 0.0002
I0614 06:11:24.459650 15760 solver.cpp:228] Iteration 5860, loss = 0.816298
I0614 06:11:24.459674 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 06:11:24.459681 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.186705 (* 1 = 0.186705 loss)
I0614 06:11:24.459686 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206975 (* 1 = 0.206975 loss)
I0614 06:11:24.459691 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00486044 (* 1 = 0.00486044 loss)
I0614 06:11:24.459694 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291562 (* 1 = 0.0291562 loss)
I0614 06:11:24.459699 15760 sgd_solver.cpp:106] Iteration 5860, lr = 0.0002
I0614 06:13:11.591240 15760 solver.cpp:228] Iteration 5880, loss = 0.621126
I0614 06:13:11.591270 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0614 06:13:11.591280 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.549533 (* 1 = 0.549533 loss)
I0614 06:13:11.591285 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.610426 (* 1 = 0.610426 loss)
I0614 06:13:11.591291 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00426846 (* 1 = 0.00426846 loss)
I0614 06:13:11.591296 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127743 (* 1 = 0.127743 loss)
I0614 06:13:11.591303 15760 sgd_solver.cpp:106] Iteration 5880, lr = 0.0002
I0614 06:14:58.421828 15760 solver.cpp:228] Iteration 5900, loss = 0.689364
I0614 06:14:58.421851 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 06:14:58.421859 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.323423 (* 1 = 0.323423 loss)
I0614 06:14:58.421864 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.611546 (* 1 = 0.611546 loss)
I0614 06:14:58.421867 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014718 (* 1 = 0.014718 loss)
I0614 06:14:58.421871 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0817744 (* 1 = 0.0817744 loss)
I0614 06:14:58.421876 15760 sgd_solver.cpp:106] Iteration 5900, lr = 0.0002
I0614 06:16:45.632637 15760 solver.cpp:228] Iteration 5920, loss = 0.749494
I0614 06:16:45.632663 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 06:16:45.632670 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.475173 (* 1 = 0.475173 loss)
I0614 06:16:45.632675 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.43276 (* 1 = 0.43276 loss)
I0614 06:16:45.632679 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00901121 (* 1 = 0.00901121 loss)
I0614 06:16:45.632683 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0702788 (* 1 = 0.0702788 loss)
I0614 06:16:45.632688 15760 sgd_solver.cpp:106] Iteration 5920, lr = 0.0002
I0614 06:18:32.904386 15760 solver.cpp:228] Iteration 5940, loss = 0.898068
I0614 06:18:32.904417 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 06:18:32.904426 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.320024 (* 1 = 0.320024 loss)
I0614 06:18:32.904431 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.491639 (* 1 = 0.491639 loss)
I0614 06:18:32.904436 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190077 (* 1 = 0.0190077 loss)
I0614 06:18:32.904441 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176007 (* 1 = 0.0176007 loss)
I0614 06:18:32.904448 15760 sgd_solver.cpp:106] Iteration 5940, lr = 0.0002
I0614 06:20:19.935022 15760 solver.cpp:228] Iteration 5960, loss = 0.786356
I0614 06:20:19.935050 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 06:20:19.935060 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.539136 (* 1 = 0.539136 loss)
I0614 06:20:19.935063 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.640251 (* 1 = 0.640251 loss)
I0614 06:20:19.935068 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123297 (* 1 = 0.0123297 loss)
I0614 06:20:19.935072 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418846 (* 1 = 0.0418846 loss)
I0614 06:20:19.935078 15760 sgd_solver.cpp:106] Iteration 5960, lr = 0.0002
I0614 06:22:06.639446 15760 solver.cpp:228] Iteration 5980, loss = 0.723911
I0614 06:22:06.639473 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 06:22:06.639480 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.467236 (* 1 = 0.467236 loss)
I0614 06:22:06.639487 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.380591 (* 1 = 0.380591 loss)
I0614 06:22:06.639495 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00280348 (* 1 = 0.00280348 loss)
I0614 06:22:06.639499 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034629 (* 1 = 0.034629 loss)
I0614 06:22:06.639505 15760 sgd_solver.cpp:106] Iteration 5980, lr = 0.0002
speed: 5.334s / iter
I0614 06:23:54.049829 15760 solver.cpp:228] Iteration 6000, loss = 1.01934
I0614 06:23:54.049855 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 06:23:54.049863 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.513484 (* 1 = 0.513484 loss)
I0614 06:23:54.049867 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.748938 (* 1 = 0.748938 loss)
I0614 06:23:54.049871 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0295029 (* 1 = 0.0295029 loss)
I0614 06:23:54.049875 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.442097 (* 1 = 0.442097 loss)
I0614 06:23:54.049880 15760 sgd_solver.cpp:106] Iteration 6000, lr = 0.0002
I0614 06:25:40.699353 15760 solver.cpp:228] Iteration 6020, loss = 1.11307
I0614 06:25:40.699378 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 06:25:40.699386 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.346104 (* 1 = 0.346104 loss)
I0614 06:25:40.699390 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.520191 (* 1 = 0.520191 loss)
I0614 06:25:40.699394 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00914414 (* 1 = 0.00914414 loss)
I0614 06:25:40.699398 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300132 (* 1 = 0.0300132 loss)
I0614 06:25:40.699404 15760 sgd_solver.cpp:106] Iteration 6020, lr = 0.0002
I0614 06:27:27.192142 15760 solver.cpp:228] Iteration 6040, loss = 0.742693
I0614 06:27:27.192167 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 06:27:27.192174 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.076881 (* 1 = 0.076881 loss)
I0614 06:27:27.192178 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.25782 (* 1 = 0.25782 loss)
I0614 06:27:27.192183 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199748 (* 1 = 0.0199748 loss)
I0614 06:27:27.192185 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232552 (* 1 = 0.0232552 loss)
I0614 06:27:27.192191 15760 sgd_solver.cpp:106] Iteration 6040, lr = 0.0002
I0614 06:29:13.804199 15760 solver.cpp:228] Iteration 6060, loss = 1.1174
I0614 06:29:13.804224 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 06:29:13.804230 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0964557 (* 1 = 0.0964557 loss)
I0614 06:29:13.804234 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.179562 (* 1 = 0.179562 loss)
I0614 06:29:13.804239 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692785 (* 1 = 0.00692785 loss)
I0614 06:29:13.804241 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262623 (* 1 = 0.0262623 loss)
I0614 06:29:13.804246 15760 sgd_solver.cpp:106] Iteration 6060, lr = 0.0002
I0614 06:31:00.289916 15760 solver.cpp:228] Iteration 6080, loss = 0.869995
I0614 06:31:00.289938 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 06:31:00.289945 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.297777 (* 1 = 0.297777 loss)
I0614 06:31:00.289949 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.380569 (* 1 = 0.380569 loss)
I0614 06:31:00.289952 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293663 (* 1 = 0.0293663 loss)
I0614 06:31:00.289957 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.075325 (* 1 = 0.075325 loss)
I0614 06:31:00.289961 15760 sgd_solver.cpp:106] Iteration 6080, lr = 0.0002
I0614 06:32:46.758836 15760 solver.cpp:228] Iteration 6100, loss = 0.712203
I0614 06:32:46.758860 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 06:32:46.758867 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0317707 (* 1 = 0.0317707 loss)
I0614 06:32:46.758872 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.152415 (* 1 = 0.152415 loss)
I0614 06:32:46.758874 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176601 (* 1 = 0.0176601 loss)
I0614 06:32:46.758878 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296455 (* 1 = 0.0296455 loss)
I0614 06:32:46.758882 15760 sgd_solver.cpp:106] Iteration 6100, lr = 0.0002
I0614 06:34:33.241894 15760 solver.cpp:228] Iteration 6120, loss = 0.647331
I0614 06:34:33.241919 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 06:34:33.241926 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.668876 (* 1 = 0.668876 loss)
I0614 06:34:33.241930 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.672779 (* 1 = 0.672779 loss)
I0614 06:34:33.241935 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113966 (* 1 = 0.0113966 loss)
I0614 06:34:33.241938 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.122306 (* 1 = 0.122306 loss)
I0614 06:34:33.241943 15760 sgd_solver.cpp:106] Iteration 6120, lr = 0.0002
I0614 06:36:19.618400 15760 solver.cpp:228] Iteration 6140, loss = 0.687209
I0614 06:36:19.618423 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 06:36:19.618430 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12363 (* 1 = 0.12363 loss)
I0614 06:36:19.618434 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.170915 (* 1 = 0.170915 loss)
I0614 06:36:19.618438 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273901 (* 1 = 0.00273901 loss)
I0614 06:36:19.618441 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134385 (* 1 = 0.0134385 loss)
I0614 06:36:19.618446 15760 sgd_solver.cpp:106] Iteration 6140, lr = 0.0002
I0614 06:38:05.782240 15760 solver.cpp:228] Iteration 6160, loss = 0.609844
I0614 06:38:05.782268 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 06:38:05.782275 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.171526 (* 1 = 0.171526 loss)
I0614 06:38:05.782280 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.219378 (* 1 = 0.219378 loss)
I0614 06:38:05.782285 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00607489 (* 1 = 0.00607489 loss)
I0614 06:38:05.782290 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023507 (* 1 = 0.023507 loss)
I0614 06:38:05.782295 15760 sgd_solver.cpp:106] Iteration 6160, lr = 0.0002
I0614 06:39:52.251742 15760 solver.cpp:228] Iteration 6180, loss = 1.17384
I0614 06:39:52.251768 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0614 06:39:52.251775 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.850293 (* 1 = 0.850293 loss)
I0614 06:39:52.251780 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.672532 (* 1 = 0.672532 loss)
I0614 06:39:52.251783 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0054063 (* 1 = 0.0054063 loss)
I0614 06:39:52.251787 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101991 (* 1 = 0.101991 loss)
I0614 06:39:52.251792 15760 sgd_solver.cpp:106] Iteration 6180, lr = 0.0002
speed: 5.334s / iter
I0614 06:41:38.466578 15760 solver.cpp:228] Iteration 6200, loss = 0.60139
I0614 06:41:38.466603 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 06:41:38.466611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.693661 (* 1 = 0.693661 loss)
I0614 06:41:38.466616 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.541128 (* 1 = 0.541128 loss)
I0614 06:41:38.466619 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0922763 (* 1 = 0.0922763 loss)
I0614 06:41:38.466624 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.367536 (* 1 = 0.367536 loss)
I0614 06:41:38.466629 15760 sgd_solver.cpp:106] Iteration 6200, lr = 0.0002
I0614 06:43:24.798025 15760 solver.cpp:228] Iteration 6220, loss = 0.453785
I0614 06:43:24.798050 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 06:43:24.798056 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.137834 (* 1 = 0.137834 loss)
I0614 06:43:24.798061 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.261044 (* 1 = 0.261044 loss)
I0614 06:43:24.798064 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00576792 (* 1 = 0.00576792 loss)
I0614 06:43:24.798069 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0926179 (* 1 = 0.0926179 loss)
I0614 06:43:24.798072 15760 sgd_solver.cpp:106] Iteration 6220, lr = 0.0002
I0614 06:45:11.222508 15760 solver.cpp:228] Iteration 6240, loss = 0.747167
I0614 06:45:11.222530 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.609375
I0614 06:45:11.222537 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.732706 (* 1 = 0.732706 loss)
I0614 06:45:11.222540 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.908715 (* 1 = 0.908715 loss)
I0614 06:45:11.222544 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0791305 (* 1 = 0.0791305 loss)
I0614 06:45:11.222548 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.235124 (* 1 = 0.235124 loss)
I0614 06:45:11.222553 15760 sgd_solver.cpp:106] Iteration 6240, lr = 0.0002
I0614 06:46:57.421115 15760 solver.cpp:228] Iteration 6260, loss = 0.547215
I0614 06:46:57.421141 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 06:46:57.421149 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.219896 (* 1 = 0.219896 loss)
I0614 06:46:57.421152 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.222634 (* 1 = 0.222634 loss)
I0614 06:46:57.421155 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228723 (* 1 = 0.00228723 loss)
I0614 06:46:57.421159 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222988 (* 1 = 0.0222988 loss)
I0614 06:46:57.421164 15760 sgd_solver.cpp:106] Iteration 6260, lr = 0.0002
I0614 06:48:44.017802 15760 solver.cpp:228] Iteration 6280, loss = 0.986621
I0614 06:48:44.017827 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 06:48:44.017833 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113686 (* 1 = 0.113686 loss)
I0614 06:48:44.017838 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.262458 (* 1 = 0.262458 loss)
I0614 06:48:44.017840 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0051451 (* 1 = 0.0051451 loss)
I0614 06:48:44.017844 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184306 (* 1 = 0.0184306 loss)
I0614 06:48:44.017849 15760 sgd_solver.cpp:106] Iteration 6280, lr = 0.0002
I0614 06:50:30.221072 15760 solver.cpp:228] Iteration 6300, loss = 0.828306
I0614 06:50:30.221097 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0614 06:50:30.221104 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.549178 (* 1 = 0.549178 loss)
I0614 06:50:30.221109 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.594478 (* 1 = 0.594478 loss)
I0614 06:50:30.221112 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102013 (* 1 = 0.0102013 loss)
I0614 06:50:30.221117 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0679927 (* 1 = 0.0679927 loss)
I0614 06:50:30.221122 15760 sgd_solver.cpp:106] Iteration 6300, lr = 0.0002
I0614 06:52:16.541703 15760 solver.cpp:228] Iteration 6320, loss = 0.471363
I0614 06:52:16.541730 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 06:52:16.541738 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.130442 (* 1 = 0.130442 loss)
I0614 06:52:16.541741 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.238848 (* 1 = 0.238848 loss)
I0614 06:52:16.541746 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153433 (* 1 = 0.0153433 loss)
I0614 06:52:16.541750 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390665 (* 1 = 0.0390665 loss)
I0614 06:52:16.541755 15760 sgd_solver.cpp:106] Iteration 6320, lr = 0.0002
I0614 06:54:02.711423 15760 solver.cpp:228] Iteration 6340, loss = 0.68188
I0614 06:54:02.711448 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 06:54:02.711454 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.425526 (* 1 = 0.425526 loss)
I0614 06:54:02.711458 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.440245 (* 1 = 0.440245 loss)
I0614 06:54:02.711462 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00540865 (* 1 = 0.00540865 loss)
I0614 06:54:02.711467 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.038342 (* 1 = 0.038342 loss)
I0614 06:54:02.711470 15760 sgd_solver.cpp:106] Iteration 6340, lr = 0.0002
I0614 06:55:49.069151 15760 solver.cpp:228] Iteration 6360, loss = 0.810196
I0614 06:55:49.069176 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 06:55:49.069185 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.223754 (* 1 = 0.223754 loss)
I0614 06:55:49.069188 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.371316 (* 1 = 0.371316 loss)
I0614 06:55:49.069192 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00664947 (* 1 = 0.00664947 loss)
I0614 06:55:49.069196 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0559055 (* 1 = 0.0559055 loss)
I0614 06:55:49.069202 15760 sgd_solver.cpp:106] Iteration 6360, lr = 0.0002
I0614 06:57:35.347132 15760 solver.cpp:228] Iteration 6380, loss = 0.821433
I0614 06:57:35.347158 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0614 06:57:35.347167 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.291708 (* 1 = 0.291708 loss)
I0614 06:57:35.347172 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.626522 (* 1 = 0.626522 loss)
I0614 06:57:35.347174 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179882 (* 1 = 0.0179882 loss)
I0614 06:57:35.347178 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.351477 (* 1 = 0.351477 loss)
I0614 06:57:35.347184 15760 sgd_solver.cpp:106] Iteration 6380, lr = 0.0002
speed: 5.334s / iter
I0614 06:59:22.072810 15760 solver.cpp:228] Iteration 6400, loss = 0.398297
I0614 06:59:22.072836 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 06:59:22.072844 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.184565 (* 1 = 0.184565 loss)
I0614 06:59:22.072849 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.246872 (* 1 = 0.246872 loss)
I0614 06:59:22.072852 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00192195 (* 1 = 0.00192195 loss)
I0614 06:59:22.072856 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443718 (* 1 = 0.0443718 loss)
I0614 06:59:22.072861 15760 sgd_solver.cpp:106] Iteration 6400, lr = 0.0002
I0614 07:01:08.376394 15760 solver.cpp:228] Iteration 6420, loss = 0.730774
I0614 07:01:08.376417 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 07:01:08.376425 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.362579 (* 1 = 0.362579 loss)
I0614 07:01:08.376427 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.463369 (* 1 = 0.463369 loss)
I0614 07:01:08.376431 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00906916 (* 1 = 0.00906916 loss)
I0614 07:01:08.376435 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.069999 (* 1 = 0.069999 loss)
I0614 07:01:08.376440 15760 sgd_solver.cpp:106] Iteration 6420, lr = 0.0002
I0614 07:02:54.862001 15760 solver.cpp:228] Iteration 6440, loss = 0.831231
I0614 07:02:54.862025 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 07:02:54.862031 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.441658 (* 1 = 0.441658 loss)
I0614 07:02:54.862035 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.863053 (* 1 = 0.863053 loss)
I0614 07:02:54.862038 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00659034 (* 1 = 0.00659034 loss)
I0614 07:02:54.862041 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103152 (* 1 = 0.103152 loss)
I0614 07:02:54.862046 15760 sgd_solver.cpp:106] Iteration 6440, lr = 0.0002
I0614 07:04:41.215793 15760 solver.cpp:228] Iteration 6460, loss = 0.75135
I0614 07:04:41.215818 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 07:04:41.215826 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.490147 (* 1 = 0.490147 loss)
I0614 07:04:41.215829 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.489031 (* 1 = 0.489031 loss)
I0614 07:04:41.215834 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103989 (* 1 = 0.0103989 loss)
I0614 07:04:41.215837 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0576791 (* 1 = 0.0576791 loss)
I0614 07:04:41.215842 15760 sgd_solver.cpp:106] Iteration 6460, lr = 0.0002
I0614 07:06:27.807168 15760 solver.cpp:228] Iteration 6480, loss = 0.780509
I0614 07:06:27.807194 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 07:06:27.807202 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.392591 (* 1 = 0.392591 loss)
I0614 07:06:27.807206 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.393093 (* 1 = 0.393093 loss)
I0614 07:06:27.807211 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0071515 (* 1 = 0.0071515 loss)
I0614 07:06:27.807214 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0608414 (* 1 = 0.0608414 loss)
I0614 07:06:27.807219 15760 sgd_solver.cpp:106] Iteration 6480, lr = 0.0002
I0614 07:08:14.251399 15760 solver.cpp:228] Iteration 6500, loss = 0.965454
I0614 07:08:14.251425 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 07:08:14.251431 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.35659 (* 1 = 0.35659 loss)
I0614 07:08:14.251435 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.483569 (* 1 = 0.483569 loss)
I0614 07:08:14.251440 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766734 (* 1 = 0.00766734 loss)
I0614 07:08:14.251442 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033637 (* 1 = 0.033637 loss)
I0614 07:08:14.251447 15760 sgd_solver.cpp:106] Iteration 6500, lr = 0.0002
I0614 07:10:00.571295 15760 solver.cpp:228] Iteration 6520, loss = 0.84477
I0614 07:10:00.571321 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 07:10:00.571331 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.440724 (* 1 = 0.440724 loss)
I0614 07:10:00.571336 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.521003 (* 1 = 0.521003 loss)
I0614 07:10:00.571341 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244619 (* 1 = 0.0244619 loss)
I0614 07:10:00.571346 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.390895 (* 1 = 0.390895 loss)
I0614 07:10:00.571353 15760 sgd_solver.cpp:106] Iteration 6520, lr = 0.0002
I0614 07:11:47.009523 15760 solver.cpp:228] Iteration 6540, loss = 0.634634
I0614 07:11:47.009551 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 07:11:47.009559 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108432 (* 1 = 0.108432 loss)
I0614 07:11:47.009567 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.204441 (* 1 = 0.204441 loss)
I0614 07:11:47.009572 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00464307 (* 1 = 0.00464307 loss)
I0614 07:11:47.009578 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364319 (* 1 = 0.0364319 loss)
I0614 07:11:47.009588 15760 sgd_solver.cpp:106] Iteration 6540, lr = 0.0002
I0614 07:13:33.408900 15760 solver.cpp:228] Iteration 6560, loss = 0.727609
I0614 07:13:33.408926 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 07:13:33.408933 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.62685 (* 1 = 0.62685 loss)
I0614 07:13:33.408936 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.679695 (* 1 = 0.679695 loss)
I0614 07:13:33.408963 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011765 (* 1 = 0.011765 loss)
I0614 07:13:33.408967 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125597 (* 1 = 0.125597 loss)
I0614 07:13:33.408972 15760 sgd_solver.cpp:106] Iteration 6560, lr = 0.0002
I0614 07:15:19.906260 15760 solver.cpp:228] Iteration 6580, loss = 0.349444
I0614 07:15:19.906285 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 07:15:19.906291 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.092502 (* 1 = 0.092502 loss)
I0614 07:15:19.906296 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.133948 (* 1 = 0.133948 loss)
I0614 07:15:19.906299 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053517 (* 1 = 0.0053517 loss)
I0614 07:15:19.906302 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266168 (* 1 = 0.0266168 loss)
I0614 07:15:19.906307 15760 sgd_solver.cpp:106] Iteration 6580, lr = 0.0002
speed: 5.333s / iter
I0614 07:17:06.060358 15760 solver.cpp:228] Iteration 6600, loss = 0.528874
I0614 07:17:06.060384 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 07:17:06.060394 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.209581 (* 1 = 0.209581 loss)
I0614 07:17:06.060400 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.218883 (* 1 = 0.218883 loss)
I0614 07:17:06.060407 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00537247 (* 1 = 0.00537247 loss)
I0614 07:17:06.060415 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192561 (* 1 = 0.0192561 loss)
I0614 07:17:06.060423 15760 sgd_solver.cpp:106] Iteration 6600, lr = 0.0002
I0614 07:18:52.586882 15760 solver.cpp:228] Iteration 6620, loss = 0.597587
I0614 07:18:52.586912 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 07:18:52.586920 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0569593 (* 1 = 0.0569593 loss)
I0614 07:18:52.586925 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.163161 (* 1 = 0.163161 loss)
I0614 07:18:52.586928 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00295144 (* 1 = 0.00295144 loss)
I0614 07:18:52.586932 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237631 (* 1 = 0.0237631 loss)
I0614 07:18:52.586937 15760 sgd_solver.cpp:106] Iteration 6620, lr = 0.0002
I0614 07:20:38.945662 15760 solver.cpp:228] Iteration 6640, loss = 0.812762
I0614 07:20:38.945686 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 07:20:38.945693 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.149075 (* 1 = 0.149075 loss)
I0614 07:20:38.945698 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.331004 (* 1 = 0.331004 loss)
I0614 07:20:38.945701 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00145394 (* 1 = 0.00145394 loss)
I0614 07:20:38.945704 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181604 (* 1 = 0.0181604 loss)
I0614 07:20:38.945709 15760 sgd_solver.cpp:106] Iteration 6640, lr = 0.0002
I0614 07:22:25.307730 15760 solver.cpp:228] Iteration 6660, loss = 0.636771
I0614 07:22:25.307756 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0614 07:22:25.307763 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.553407 (* 1 = 0.553407 loss)
I0614 07:22:25.307767 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.584667 (* 1 = 0.584667 loss)
I0614 07:22:25.307771 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186287 (* 1 = 0.0186287 loss)
I0614 07:22:25.307775 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117497 (* 1 = 0.117497 loss)
I0614 07:22:25.307780 15760 sgd_solver.cpp:106] Iteration 6660, lr = 0.0002
I0614 07:24:11.757714 15760 solver.cpp:228] Iteration 6680, loss = 0.759396
I0614 07:24:11.757740 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 07:24:11.757746 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.287868 (* 1 = 0.287868 loss)
I0614 07:24:11.757750 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.32029 (* 1 = 0.32029 loss)
I0614 07:24:11.757753 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00161826 (* 1 = 0.00161826 loss)
I0614 07:24:11.757757 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.068754 (* 1 = 0.068754 loss)
I0614 07:24:11.757762 15760 sgd_solver.cpp:106] Iteration 6680, lr = 0.0002
I0614 07:25:58.142314 15760 solver.cpp:228] Iteration 6700, loss = 0.891298
I0614 07:25:58.142338 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 07:25:58.142344 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.131674 (* 1 = 0.131674 loss)
I0614 07:25:58.142349 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.215304 (* 1 = 0.215304 loss)
I0614 07:25:58.142352 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00898315 (* 1 = 0.00898315 loss)
I0614 07:25:58.142356 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193401 (* 1 = 0.0193401 loss)
I0614 07:25:58.142362 15760 sgd_solver.cpp:106] Iteration 6700, lr = 0.0002
I0614 07:27:44.610950 15760 solver.cpp:228] Iteration 6720, loss = 0.872326
I0614 07:27:44.610975 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0614 07:27:44.610982 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.381432 (* 1 = 0.381432 loss)
I0614 07:27:44.610986 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.57396 (* 1 = 0.57396 loss)
I0614 07:27:44.610991 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00470967 (* 1 = 0.00470967 loss)
I0614 07:27:44.610994 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0764442 (* 1 = 0.0764442 loss)
I0614 07:27:44.610999 15760 sgd_solver.cpp:106] Iteration 6720, lr = 0.0002
I0614 07:29:30.961040 15760 solver.cpp:228] Iteration 6740, loss = 0.91538
I0614 07:29:30.961066 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 07:29:30.961074 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.192547 (* 1 = 0.192547 loss)
I0614 07:29:30.961078 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.26605 (* 1 = 0.26605 loss)
I0614 07:29:30.961081 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178643 (* 1 = 0.0178643 loss)
I0614 07:29:30.961084 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0493266 (* 1 = 0.0493266 loss)
I0614 07:29:30.961089 15760 sgd_solver.cpp:106] Iteration 6740, lr = 0.0002
I0614 07:31:17.240692 15760 solver.cpp:228] Iteration 6760, loss = 0.930132
I0614 07:31:17.240716 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 07:31:17.240725 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.133009 (* 1 = 0.133009 loss)
I0614 07:31:17.240731 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.27469 (* 1 = 0.27469 loss)
I0614 07:31:17.240736 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00818527 (* 1 = 0.00818527 loss)
I0614 07:31:17.240742 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196895 (* 1 = 0.0196895 loss)
I0614 07:31:17.240748 15760 sgd_solver.cpp:106] Iteration 6760, lr = 0.0002
I0614 07:33:03.479555 15760 solver.cpp:228] Iteration 6780, loss = 1.21435
I0614 07:33:03.479581 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 07:33:03.479588 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.373654 (* 1 = 0.373654 loss)
I0614 07:33:03.479593 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.343271 (* 1 = 0.343271 loss)
I0614 07:33:03.479598 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110547 (* 1 = 0.00110547 loss)
I0614 07:33:03.479600 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0415484 (* 1 = 0.0415484 loss)
I0614 07:33:03.479606 15760 sgd_solver.cpp:106] Iteration 6780, lr = 0.0002
speed: 5.333s / iter
I0614 07:34:49.763101 15760 solver.cpp:228] Iteration 6800, loss = 1.12943
I0614 07:34:49.763124 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 07:34:49.763134 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.733168 (* 1 = 0.733168 loss)
I0614 07:34:49.763139 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.656726 (* 1 = 0.656726 loss)
I0614 07:34:49.763145 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359183 (* 1 = 0.00359183 loss)
I0614 07:34:49.763151 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.126133 (* 1 = 0.126133 loss)
I0614 07:34:49.763157 15760 sgd_solver.cpp:106] Iteration 6800, lr = 0.0002
I0614 07:36:36.059830 15760 solver.cpp:228] Iteration 6820, loss = 0.672168
I0614 07:36:36.059854 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 07:36:36.059859 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.222998 (* 1 = 0.222998 loss)
I0614 07:36:36.059864 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.428278 (* 1 = 0.428278 loss)
I0614 07:36:36.059867 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018526 (* 1 = 0.018526 loss)
I0614 07:36:36.059870 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.486966 (* 1 = 0.486966 loss)
I0614 07:36:36.059875 15760 sgd_solver.cpp:106] Iteration 6820, lr = 0.0002
I0614 07:38:22.508844 15760 solver.cpp:228] Iteration 6840, loss = 1.05517
I0614 07:38:22.508869 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 07:38:22.508877 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.134154 (* 1 = 0.134154 loss)
I0614 07:38:22.508882 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.252524 (* 1 = 0.252524 loss)
I0614 07:38:22.508885 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253928 (* 1 = 0.00253928 loss)
I0614 07:38:22.508889 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166821 (* 1 = 0.0166821 loss)
I0614 07:38:22.508894 15760 sgd_solver.cpp:106] Iteration 6840, lr = 0.0002
I0614 07:40:08.994848 15760 solver.cpp:228] Iteration 6860, loss = 0.961266
I0614 07:40:08.994874 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.28125
I0614 07:40:08.994884 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.492483 (* 1 = 0.492483 loss)
I0614 07:40:08.994891 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.32242 (* 1 = 1.32242 loss)
I0614 07:40:08.994897 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189262 (* 1 = 0.0189262 loss)
I0614 07:40:08.994904 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148603 (* 1 = 0.148603 loss)
I0614 07:40:08.994910 15760 sgd_solver.cpp:106] Iteration 6860, lr = 0.0002
I0614 07:41:55.200592 15760 solver.cpp:228] Iteration 6880, loss = 0.715927
I0614 07:41:55.200615 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 07:41:55.200621 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.317646 (* 1 = 0.317646 loss)
I0614 07:41:55.200625 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.660436 (* 1 = 0.660436 loss)
I0614 07:41:55.200629 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144193 (* 1 = 0.0144193 loss)
I0614 07:41:55.200633 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0931327 (* 1 = 0.0931327 loss)
I0614 07:41:55.200637 15760 sgd_solver.cpp:106] Iteration 6880, lr = 0.0002
I0614 07:43:41.564064 15760 solver.cpp:228] Iteration 6900, loss = 0.560865
I0614 07:43:41.564090 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 07:43:41.564096 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.197021 (* 1 = 0.197021 loss)
I0614 07:43:41.564100 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.22233 (* 1 = 0.22233 loss)
I0614 07:43:41.564105 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00201192 (* 1 = 0.00201192 loss)
I0614 07:43:41.564108 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126606 (* 1 = 0.0126606 loss)
I0614 07:43:41.564113 15760 sgd_solver.cpp:106] Iteration 6900, lr = 0.0002
I0614 07:45:27.844274 15760 solver.cpp:228] Iteration 6920, loss = 0.885242
I0614 07:45:27.844298 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 07:45:27.844306 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.150114 (* 1 = 0.150114 loss)
I0614 07:45:27.844310 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.244698 (* 1 = 0.244698 loss)
I0614 07:45:27.844314 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181661 (* 1 = 0.00181661 loss)
I0614 07:45:27.844318 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207106 (* 1 = 0.0207106 loss)
I0614 07:45:27.844323 15760 sgd_solver.cpp:106] Iteration 6920, lr = 0.0002
I0614 07:47:14.431654 15760 solver.cpp:228] Iteration 6940, loss = 0.84698
I0614 07:47:14.431684 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 07:47:14.431694 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.632911 (* 1 = 0.632911 loss)
I0614 07:47:14.431699 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.446309 (* 1 = 0.446309 loss)
I0614 07:47:14.431704 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112555 (* 1 = 0.0112555 loss)
I0614 07:47:14.431710 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.209645 (* 1 = 0.209645 loss)
I0614 07:47:14.431715 15760 sgd_solver.cpp:106] Iteration 6940, lr = 0.0002
I0614 07:49:00.767607 15760 solver.cpp:228] Iteration 6960, loss = 0.859305
I0614 07:49:00.767633 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 07:49:00.767642 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.168356 (* 1 = 0.168356 loss)
I0614 07:49:00.767645 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309246 (* 1 = 0.309246 loss)
I0614 07:49:00.767649 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131833 (* 1 = 0.0131833 loss)
I0614 07:49:00.767653 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00515131 (* 1 = 0.00515131 loss)
I0614 07:49:00.767658 15760 sgd_solver.cpp:106] Iteration 6960, lr = 0.0002
I0614 07:50:46.983888 15760 solver.cpp:228] Iteration 6980, loss = 0.699936
I0614 07:50:46.983912 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 07:50:46.983918 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.122893 (* 1 = 0.122893 loss)
I0614 07:50:46.983922 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.207811 (* 1 = 0.207811 loss)
I0614 07:50:46.983927 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291077 (* 1 = 0.00291077 loss)
I0614 07:50:46.983930 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100013 (* 1 = 0.0100013 loss)
I0614 07:50:46.983934 15760 sgd_solver.cpp:106] Iteration 6980, lr = 0.0002
speed: 5.332s / iter
I0614 07:52:33.466507 15760 solver.cpp:228] Iteration 7000, loss = 0.998013
I0614 07:52:33.466531 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 07:52:33.466540 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.116248 (* 1 = 0.116248 loss)
I0614 07:52:33.466547 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148285 (* 1 = 0.148285 loss)
I0614 07:52:33.466552 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.002616 (* 1 = 0.002616 loss)
I0614 07:52:33.466557 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186579 (* 1 = 0.0186579 loss)
I0614 07:52:33.466563 15760 sgd_solver.cpp:106] Iteration 7000, lr = 0.0002
I0614 07:54:19.791767 15760 solver.cpp:228] Iteration 7020, loss = 0.905362
I0614 07:54:19.791793 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 07:54:19.791800 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.213826 (* 1 = 0.213826 loss)
I0614 07:54:19.791805 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.224644 (* 1 = 0.224644 loss)
I0614 07:54:19.791810 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140129 (* 1 = 0.0140129 loss)
I0614 07:54:19.791812 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0503624 (* 1 = 0.0503624 loss)
I0614 07:54:19.791817 15760 sgd_solver.cpp:106] Iteration 7020, lr = 0.0002
I0614 07:56:06.193593 15760 solver.cpp:228] Iteration 7040, loss = 0.653181
I0614 07:56:06.193619 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 07:56:06.193627 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.395577 (* 1 = 0.395577 loss)
I0614 07:56:06.193631 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.5876 (* 1 = 0.5876 loss)
I0614 07:56:06.193635 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.112778 (* 1 = 0.112778 loss)
I0614 07:56:06.193639 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.198329 (* 1 = 0.198329 loss)
I0614 07:56:06.193644 15760 sgd_solver.cpp:106] Iteration 7040, lr = 0.0002
I0614 07:57:52.770352 15760 solver.cpp:228] Iteration 7060, loss = 0.733308
I0614 07:57:52.770377 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0614 07:57:52.770385 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.336161 (* 1 = 0.336161 loss)
I0614 07:57:52.770390 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.476559 (* 1 = 0.476559 loss)
I0614 07:57:52.770395 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.043484 (* 1 = 0.043484 loss)
I0614 07:57:52.770398 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191715 (* 1 = 0.191715 loss)
I0614 07:57:52.770403 15760 sgd_solver.cpp:106] Iteration 7060, lr = 0.0002
I0614 07:59:39.076573 15760 solver.cpp:228] Iteration 7080, loss = 1.07565
I0614 07:59:39.076594 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.453125
I0614 07:59:39.076602 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.10065 (* 1 = 1.10065 loss)
I0614 07:59:39.076606 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.98723 (* 1 = 0.98723 loss)
I0614 07:59:39.076609 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.125872 (* 1 = 0.125872 loss)
I0614 07:59:39.076612 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.683401 (* 1 = 0.683401 loss)
I0614 07:59:39.076617 15760 sgd_solver.cpp:106] Iteration 7080, lr = 0.0002
I0614 08:01:25.394927 15760 solver.cpp:228] Iteration 7100, loss = 0.765165
I0614 08:01:25.394950 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 08:01:25.394958 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15433 (* 1 = 0.15433 loss)
I0614 08:01:25.394961 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.260495 (* 1 = 0.260495 loss)
I0614 08:01:25.394964 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00728108 (* 1 = 0.00728108 loss)
I0614 08:01:25.394968 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418374 (* 1 = 0.0418374 loss)
I0614 08:01:25.394973 15760 sgd_solver.cpp:106] Iteration 7100, lr = 0.0002
I0614 08:03:11.972542 15760 solver.cpp:228] Iteration 7120, loss = 0.807736
I0614 08:03:11.972566 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 08:03:11.972574 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113081 (* 1 = 0.113081 loss)
I0614 08:03:11.972579 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.144194 (* 1 = 0.144194 loss)
I0614 08:03:11.972584 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00302682 (* 1 = 0.00302682 loss)
I0614 08:03:11.972586 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247952 (* 1 = 0.0247952 loss)
I0614 08:03:11.972591 15760 sgd_solver.cpp:106] Iteration 7120, lr = 0.0002
I0614 08:04:58.254660 15760 solver.cpp:228] Iteration 7140, loss = 0.62645
I0614 08:04:58.254684 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 08:04:58.254690 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00210134 (* 1 = 0.00210134 loss)
I0614 08:04:58.254694 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.16189 (* 1 = 0.16189 loss)
I0614 08:04:58.254698 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0659128 (* 1 = 0.0659128 loss)
I0614 08:04:58.254701 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0389457 (* 1 = 0.0389457 loss)
I0614 08:04:58.254706 15760 sgd_solver.cpp:106] Iteration 7140, lr = 0.0002
I0614 08:06:44.541121 15760 solver.cpp:228] Iteration 7160, loss = 0.642
I0614 08:06:44.541146 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 08:06:44.541155 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.217059 (* 1 = 0.217059 loss)
I0614 08:06:44.541159 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.429815 (* 1 = 0.429815 loss)
I0614 08:06:44.541163 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00199831 (* 1 = 0.00199831 loss)
I0614 08:06:44.541167 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0588256 (* 1 = 0.0588256 loss)
I0614 08:06:44.541172 15760 sgd_solver.cpp:106] Iteration 7160, lr = 0.0002
I0614 08:08:30.931859 15760 solver.cpp:228] Iteration 7180, loss = 0.885293
I0614 08:08:30.931885 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 08:08:30.931893 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.196872 (* 1 = 0.196872 loss)
I0614 08:08:30.931897 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.323829 (* 1 = 0.323829 loss)
I0614 08:08:30.931901 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108182 (* 1 = 0.0108182 loss)
I0614 08:08:30.931905 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.188492 (* 1 = 0.188492 loss)
I0614 08:08:30.931910 15760 sgd_solver.cpp:106] Iteration 7180, lr = 0.0002
speed: 5.332s / iter
I0614 08:10:17.100050 15760 solver.cpp:228] Iteration 7200, loss = 0.776167
I0614 08:10:17.100073 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 08:10:17.100080 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.10873 (* 1 = 0.10873 loss)
I0614 08:10:17.100085 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234968 (* 1 = 0.234968 loss)
I0614 08:10:17.100088 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320816 (* 1 = 0.00320816 loss)
I0614 08:10:17.100092 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211311 (* 1 = 0.0211311 loss)
I0614 08:10:17.100096 15760 sgd_solver.cpp:106] Iteration 7200, lr = 0.0002
I0614 08:12:03.647578 15760 solver.cpp:228] Iteration 7220, loss = 0.898968
I0614 08:12:03.647604 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 08:12:03.647613 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.286129 (* 1 = 0.286129 loss)
I0614 08:12:03.647616 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.461539 (* 1 = 0.461539 loss)
I0614 08:12:03.647620 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00825519 (* 1 = 0.00825519 loss)
I0614 08:12:03.647624 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0355017 (* 1 = 0.0355017 loss)
I0614 08:12:03.647629 15760 sgd_solver.cpp:106] Iteration 7220, lr = 0.0002
I0614 08:13:50.068651 15760 solver.cpp:228] Iteration 7240, loss = 0.556354
I0614 08:13:50.068675 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0614 08:13:50.068683 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.251328 (* 1 = 0.251328 loss)
I0614 08:13:50.068687 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.440796 (* 1 = 0.440796 loss)
I0614 08:13:50.068691 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00530455 (* 1 = 0.00530455 loss)
I0614 08:13:50.068696 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.059547 (* 1 = 0.059547 loss)
I0614 08:13:50.068701 15760 sgd_solver.cpp:106] Iteration 7240, lr = 0.0002
I0614 08:15:36.544881 15760 solver.cpp:228] Iteration 7260, loss = 0.800794
I0614 08:15:36.544905 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0614 08:15:36.544912 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.690632 (* 1 = 0.690632 loss)
I0614 08:15:36.544916 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.690266 (* 1 = 0.690266 loss)
I0614 08:15:36.544919 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0976783 (* 1 = 0.0976783 loss)
I0614 08:15:36.544922 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.491742 (* 1 = 0.491742 loss)
I0614 08:15:36.544927 15760 sgd_solver.cpp:106] Iteration 7260, lr = 0.0002
I0614 08:17:22.806299 15760 solver.cpp:228] Iteration 7280, loss = 0.633519
I0614 08:17:22.806324 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 08:17:22.806332 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.150345 (* 1 = 0.150345 loss)
I0614 08:17:22.806336 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.36379 (* 1 = 0.36379 loss)
I0614 08:17:22.806340 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00770511 (* 1 = 0.00770511 loss)
I0614 08:17:22.806344 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338422 (* 1 = 0.0338422 loss)
I0614 08:17:22.806349 15760 sgd_solver.cpp:106] Iteration 7280, lr = 0.0002
I0614 08:19:09.076318 15760 solver.cpp:228] Iteration 7300, loss = 0.509458
I0614 08:19:09.076342 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 08:19:09.076350 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0755462 (* 1 = 0.0755462 loss)
I0614 08:19:09.076354 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.194096 (* 1 = 0.194096 loss)
I0614 08:19:09.076357 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00383482 (* 1 = 0.00383482 loss)
I0614 08:19:09.076361 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210358 (* 1 = 0.0210358 loss)
I0614 08:19:09.076366 15760 sgd_solver.cpp:106] Iteration 7300, lr = 0.0002
I0614 08:20:55.483475 15760 solver.cpp:228] Iteration 7320, loss = 0.628009
I0614 08:20:55.483500 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 08:20:55.483506 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0117348 (* 1 = 0.0117348 loss)
I0614 08:20:55.483510 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0970216 (* 1 = 0.0970216 loss)
I0614 08:20:55.483513 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103216 (* 1 = 0.0103216 loss)
I0614 08:20:55.483516 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237165 (* 1 = 0.0237165 loss)
I0614 08:20:55.483522 15760 sgd_solver.cpp:106] Iteration 7320, lr = 0.0002
I0614 08:22:42.005844 15760 solver.cpp:228] Iteration 7340, loss = 0.627238
I0614 08:22:42.005870 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 08:22:42.005878 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0889173 (* 1 = 0.0889173 loss)
I0614 08:22:42.005883 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.145866 (* 1 = 0.145866 loss)
I0614 08:22:42.005887 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0360322 (* 1 = 0.0360322 loss)
I0614 08:22:42.005892 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114186 (* 1 = 0.0114186 loss)
I0614 08:22:42.005897 15760 sgd_solver.cpp:106] Iteration 7340, lr = 0.0002
I0614 08:24:28.383733 15760 solver.cpp:228] Iteration 7360, loss = 0.722975
I0614 08:24:28.383759 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0614 08:24:28.383764 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.350246 (* 1 = 0.350246 loss)
I0614 08:24:28.383769 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.528132 (* 1 = 0.528132 loss)
I0614 08:24:28.383772 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01851 (* 1 = 0.01851 loss)
I0614 08:24:28.383775 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191624 (* 1 = 0.191624 loss)
I0614 08:24:28.383780 15760 sgd_solver.cpp:106] Iteration 7360, lr = 0.0002
I0614 08:26:14.546016 15760 solver.cpp:228] Iteration 7380, loss = 0.761281
I0614 08:26:14.546039 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 08:26:14.546048 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0560843 (* 1 = 0.0560843 loss)
I0614 08:26:14.546054 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130879 (* 1 = 0.130879 loss)
I0614 08:26:14.546059 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000573941 (* 1 = 0.000573941 loss)
I0614 08:26:14.546066 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169483 (* 1 = 0.0169483 loss)
I0614 08:26:14.546072 15760 sgd_solver.cpp:106] Iteration 7380, lr = 0.0002
speed: 5.332s / iter
I0614 08:28:00.747030 15760 solver.cpp:228] Iteration 7400, loss = 0.720635
I0614 08:28:00.747054 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0614 08:28:00.747062 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.364722 (* 1 = 0.364722 loss)
I0614 08:28:00.747066 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.510468 (* 1 = 0.510468 loss)
I0614 08:28:00.747071 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301362 (* 1 = 0.00301362 loss)
I0614 08:28:00.747074 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0564836 (* 1 = 0.0564836 loss)
I0614 08:28:00.747081 15760 sgd_solver.cpp:106] Iteration 7400, lr = 0.0002
I0614 08:29:47.192204 15760 solver.cpp:228] Iteration 7420, loss = 0.786042
I0614 08:29:47.192232 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 08:29:47.192239 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.132513 (* 1 = 0.132513 loss)
I0614 08:29:47.192245 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.187234 (* 1 = 0.187234 loss)
I0614 08:29:47.192248 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000756656 (* 1 = 0.000756656 loss)
I0614 08:29:47.192252 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202574 (* 1 = 0.0202574 loss)
I0614 08:29:47.192258 15760 sgd_solver.cpp:106] Iteration 7420, lr = 0.0002
I0614 08:31:33.630446 15760 solver.cpp:228] Iteration 7440, loss = 1.01059
I0614 08:31:33.630472 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 08:31:33.630481 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.381207 (* 1 = 0.381207 loss)
I0614 08:31:33.630487 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.412224 (* 1 = 0.412224 loss)
I0614 08:31:33.630492 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00605669 (* 1 = 0.00605669 loss)
I0614 08:31:33.630498 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.073128 (* 1 = 0.073128 loss)
I0614 08:31:33.630506 15760 sgd_solver.cpp:106] Iteration 7440, lr = 0.0002
I0614 08:33:20.174075 15760 solver.cpp:228] Iteration 7460, loss = 0.723674
I0614 08:33:20.174101 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 08:33:20.174109 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.237986 (* 1 = 0.237986 loss)
I0614 08:33:20.174113 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.294415 (* 1 = 0.294415 loss)
I0614 08:33:20.174118 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134338 (* 1 = 0.0134338 loss)
I0614 08:33:20.174121 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121459 (* 1 = 0.121459 loss)
I0614 08:33:20.174126 15760 sgd_solver.cpp:106] Iteration 7460, lr = 0.0002
I0614 08:35:06.557909 15760 solver.cpp:228] Iteration 7480, loss = 0.77878
I0614 08:35:06.557934 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 08:35:06.557941 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.409694 (* 1 = 0.409694 loss)
I0614 08:35:06.557945 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.528388 (* 1 = 0.528388 loss)
I0614 08:35:06.557948 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164939 (* 1 = 0.0164939 loss)
I0614 08:35:06.557951 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0951377 (* 1 = 0.0951377 loss)
I0614 08:35:06.557956 15760 sgd_solver.cpp:106] Iteration 7480, lr = 0.0002
I0614 08:36:52.867941 15760 solver.cpp:228] Iteration 7500, loss = 0.884279
I0614 08:36:52.867969 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 08:36:52.867975 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.252975 (* 1 = 0.252975 loss)
I0614 08:36:52.867980 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.435423 (* 1 = 0.435423 loss)
I0614 08:36:52.867983 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00734427 (* 1 = 0.00734427 loss)
I0614 08:36:52.867987 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102069 (* 1 = 0.102069 loss)
I0614 08:36:52.867993 15760 sgd_solver.cpp:106] Iteration 7500, lr = 0.0002
I0614 08:38:39.467557 15760 solver.cpp:228] Iteration 7520, loss = 0.521917
I0614 08:38:39.467581 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 08:38:39.467588 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.140722 (* 1 = 0.140722 loss)
I0614 08:38:39.467592 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.263766 (* 1 = 0.263766 loss)
I0614 08:38:39.467597 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00912038 (* 1 = 0.00912038 loss)
I0614 08:38:39.467599 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0417642 (* 1 = 0.0417642 loss)
I0614 08:38:39.467603 15760 sgd_solver.cpp:106] Iteration 7520, lr = 0.0002
I0614 08:40:25.789196 15760 solver.cpp:228] Iteration 7540, loss = 0.801266
I0614 08:40:25.789225 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 08:40:25.789233 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.281926 (* 1 = 0.281926 loss)
I0614 08:40:25.789237 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321291 (* 1 = 0.321291 loss)
I0614 08:40:25.789242 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018873 (* 1 = 0.018873 loss)
I0614 08:40:25.789245 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0775933 (* 1 = 0.0775933 loss)
I0614 08:40:25.789252 15760 sgd_solver.cpp:106] Iteration 7540, lr = 0.0002
I0614 08:42:12.268864 15760 solver.cpp:228] Iteration 7560, loss = 0.694678
I0614 08:42:12.268892 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 08:42:12.268903 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.116066 (* 1 = 0.116066 loss)
I0614 08:42:12.268908 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.133562 (* 1 = 0.133562 loss)
I0614 08:42:12.268914 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00420762 (* 1 = 0.00420762 loss)
I0614 08:42:12.268920 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135364 (* 1 = 0.0135364 loss)
I0614 08:42:12.268929 15760 sgd_solver.cpp:106] Iteration 7560, lr = 0.0002
I0614 08:43:58.659682 15760 solver.cpp:228] Iteration 7580, loss = 0.889554
I0614 08:43:58.659706 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0614 08:43:58.659713 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.420645 (* 1 = 0.420645 loss)
I0614 08:43:58.659718 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.662199 (* 1 = 0.662199 loss)
I0614 08:43:58.659721 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00901195 (* 1 = 0.00901195 loss)
I0614 08:43:58.659724 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0466845 (* 1 = 0.0466845 loss)
I0614 08:43:58.659729 15760 sgd_solver.cpp:106] Iteration 7580, lr = 0.0002
speed: 5.331s / iter
I0614 08:45:45.224798 15760 solver.cpp:228] Iteration 7600, loss = 0.842762
I0614 08:45:45.224823 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 08:45:45.224830 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.641727 (* 1 = 0.641727 loss)
I0614 08:45:45.224834 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.579826 (* 1 = 0.579826 loss)
I0614 08:45:45.224839 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364796 (* 1 = 0.0364796 loss)
I0614 08:45:45.224843 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.217863 (* 1 = 0.217863 loss)
I0614 08:45:45.224848 15760 sgd_solver.cpp:106] Iteration 7600, lr = 0.0002
I0614 08:47:31.571436 15760 solver.cpp:228] Iteration 7620, loss = 1.04539
I0614 08:47:31.571466 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 08:47:31.571477 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146684 (* 1 = 0.146684 loss)
I0614 08:47:31.571483 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.184759 (* 1 = 0.184759 loss)
I0614 08:47:31.571491 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00529635 (* 1 = 0.00529635 loss)
I0614 08:47:31.571499 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026157 (* 1 = 0.026157 loss)
I0614 08:47:31.571507 15760 sgd_solver.cpp:106] Iteration 7620, lr = 0.0002
I0614 08:49:17.828860 15760 solver.cpp:228] Iteration 7640, loss = 0.73339
I0614 08:49:17.828882 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 08:49:17.828889 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.172337 (* 1 = 0.172337 loss)
I0614 08:49:17.828893 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.200122 (* 1 = 0.200122 loss)
I0614 08:49:17.828897 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100858 (* 1 = 0.00100858 loss)
I0614 08:49:17.828900 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0429035 (* 1 = 0.0429035 loss)
I0614 08:49:17.828905 15760 sgd_solver.cpp:106] Iteration 7640, lr = 0.0002
I0614 08:51:04.051867 15760 solver.cpp:228] Iteration 7660, loss = 0.67388
I0614 08:51:04.051892 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 08:51:04.051898 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.201798 (* 1 = 0.201798 loss)
I0614 08:51:04.051903 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.257796 (* 1 = 0.257796 loss)
I0614 08:51:04.051906 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186965 (* 1 = 0.00186965 loss)
I0614 08:51:04.051910 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016118 (* 1 = 0.016118 loss)
I0614 08:51:04.051914 15760 sgd_solver.cpp:106] Iteration 7660, lr = 0.0002
I0614 08:52:50.463906 15760 solver.cpp:228] Iteration 7680, loss = 0.495813
I0614 08:52:50.463932 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 08:52:50.463939 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0260059 (* 1 = 0.0260059 loss)
I0614 08:52:50.463943 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0949964 (* 1 = 0.0949964 loss)
I0614 08:52:50.463948 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149037 (* 1 = 0.0149037 loss)
I0614 08:52:50.463951 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310962 (* 1 = 0.0310962 loss)
I0614 08:52:50.463956 15760 sgd_solver.cpp:106] Iteration 7680, lr = 0.0002
I0614 08:54:36.767580 15760 solver.cpp:228] Iteration 7700, loss = 0.540393
I0614 08:54:36.767604 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 08:54:36.767611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.36689 (* 1 = 0.36689 loss)
I0614 08:54:36.767616 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.387737 (* 1 = 0.387737 loss)
I0614 08:54:36.767619 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00319639 (* 1 = 0.00319639 loss)
I0614 08:54:36.767624 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183731 (* 1 = 0.0183731 loss)
I0614 08:54:36.767628 15760 sgd_solver.cpp:106] Iteration 7700, lr = 0.0002
I0614 08:56:23.255949 15760 solver.cpp:228] Iteration 7720, loss = 1.04941
I0614 08:56:23.255973 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 08:56:23.255980 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117515 (* 1 = 0.117515 loss)
I0614 08:56:23.255985 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.214638 (* 1 = 0.214638 loss)
I0614 08:56:23.255988 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412496 (* 1 = 0.00412496 loss)
I0614 08:56:23.255991 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0862266 (* 1 = 0.0862266 loss)
I0614 08:56:23.255995 15760 sgd_solver.cpp:106] Iteration 7720, lr = 0.0002
I0614 08:58:09.504318 15760 solver.cpp:228] Iteration 7740, loss = 1.04533
I0614 08:58:09.504343 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.625
I0614 08:58:09.504351 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.936767 (* 1 = 0.936767 loss)
I0614 08:58:09.504357 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.605561 (* 1 = 0.605561 loss)
I0614 08:58:09.504362 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158083 (* 1 = 0.0158083 loss)
I0614 08:58:09.504369 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.169306 (* 1 = 0.169306 loss)
I0614 08:58:09.504374 15760 sgd_solver.cpp:106] Iteration 7740, lr = 0.0002
I0614 08:59:56.019107 15760 solver.cpp:228] Iteration 7760, loss = 0.578836
I0614 08:59:56.019132 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 08:59:56.019142 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.124136 (* 1 = 0.124136 loss)
I0614 08:59:56.019148 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.110854 (* 1 = 0.110854 loss)
I0614 08:59:56.019155 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00514002 (* 1 = 0.00514002 loss)
I0614 08:59:56.019161 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143253 (* 1 = 0.0143253 loss)
I0614 08:59:56.019167 15760 sgd_solver.cpp:106] Iteration 7760, lr = 0.0002
I0614 09:01:42.376273 15760 solver.cpp:228] Iteration 7780, loss = 1.1423
I0614 09:01:42.376297 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.3125
I0614 09:01:42.376305 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.547268 (* 1 = 0.547268 loss)
I0614 09:01:42.376308 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.31006 (* 1 = 1.31006 loss)
I0614 09:01:42.376312 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115063 (* 1 = 0.0115063 loss)
I0614 09:01:42.376315 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.150976 (* 1 = 0.150976 loss)
I0614 09:01:42.376320 15760 sgd_solver.cpp:106] Iteration 7780, lr = 0.0002
speed: 5.331s / iter
I0614 09:03:28.714537 15760 solver.cpp:228] Iteration 7800, loss = 0.704109
I0614 09:03:28.714562 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0614 09:03:28.714571 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.463732 (* 1 = 0.463732 loss)
I0614 09:03:28.714577 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.694634 (* 1 = 0.694634 loss)
I0614 09:03:28.714582 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014293 (* 1 = 0.014293 loss)
I0614 09:03:28.714591 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0737256 (* 1 = 0.0737256 loss)
I0614 09:03:28.714598 15760 sgd_solver.cpp:106] Iteration 7800, lr = 0.0002
I0614 09:05:14.941067 15760 solver.cpp:228] Iteration 7820, loss = 0.960029
I0614 09:05:14.941098 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 09:05:14.941108 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.256565 (* 1 = 0.256565 loss)
I0614 09:05:14.941115 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.319667 (* 1 = 0.319667 loss)
I0614 09:05:14.941121 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00462814 (* 1 = 0.00462814 loss)
I0614 09:05:14.941128 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252704 (* 1 = 0.0252704 loss)
I0614 09:05:14.941136 15760 sgd_solver.cpp:106] Iteration 7820, lr = 0.0002
I0614 09:07:01.448611 15760 solver.cpp:228] Iteration 7840, loss = 1.08108
I0614 09:07:01.448637 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0614 09:07:01.448647 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.22796 (* 1 = 1.22796 loss)
I0614 09:07:01.448653 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.809225 (* 1 = 0.809225 loss)
I0614 09:07:01.448659 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0386195 (* 1 = 0.0386195 loss)
I0614 09:07:01.448665 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.303743 (* 1 = 0.303743 loss)
I0614 09:07:01.448675 15760 sgd_solver.cpp:106] Iteration 7840, lr = 0.0002
I0614 09:08:48.202608 15760 solver.cpp:228] Iteration 7860, loss = 0.740198
I0614 09:08:48.202633 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 09:08:48.202641 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.135387 (* 1 = 0.135387 loss)
I0614 09:08:48.202646 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.235883 (* 1 = 0.235883 loss)
I0614 09:08:48.202649 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206658 (* 1 = 0.00206658 loss)
I0614 09:08:48.202653 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120242 (* 1 = 0.0120242 loss)
I0614 09:08:48.202658 15760 sgd_solver.cpp:106] Iteration 7860, lr = 0.0002
I0614 09:10:34.497375 15760 solver.cpp:228] Iteration 7880, loss = 0.785337
I0614 09:10:34.497403 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 09:10:34.497412 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.217481 (* 1 = 0.217481 loss)
I0614 09:10:34.497418 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.320315 (* 1 = 0.320315 loss)
I0614 09:10:34.497424 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00632164 (* 1 = 0.00632164 loss)
I0614 09:10:34.497429 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330566 (* 1 = 0.0330566 loss)
I0614 09:10:34.497438 15760 sgd_solver.cpp:106] Iteration 7880, lr = 0.0002
I0614 09:12:21.059614 15760 solver.cpp:228] Iteration 7900, loss = 0.889038
I0614 09:12:21.059638 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 09:12:21.059644 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.211716 (* 1 = 0.211716 loss)
I0614 09:12:21.059649 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.256677 (* 1 = 0.256677 loss)
I0614 09:12:21.059653 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398196 (* 1 = 0.00398196 loss)
I0614 09:12:21.059656 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325811 (* 1 = 0.0325811 loss)
I0614 09:12:21.059661 15760 sgd_solver.cpp:106] Iteration 7900, lr = 0.0002
I0614 09:14:07.582583 15760 solver.cpp:228] Iteration 7920, loss = 0.602703
I0614 09:14:07.582607 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 09:14:07.582614 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.16366 (* 1 = 0.16366 loss)
I0614 09:14:07.582618 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.149887 (* 1 = 0.149887 loss)
I0614 09:14:07.582623 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125443 (* 1 = 0.00125443 loss)
I0614 09:14:07.582625 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00568743 (* 1 = 0.00568743 loss)
I0614 09:14:07.582630 15760 sgd_solver.cpp:106] Iteration 7920, lr = 0.0002
I0614 09:15:54.125039 15760 solver.cpp:228] Iteration 7940, loss = 0.657078
I0614 09:15:54.125064 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 09:15:54.125072 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.13405 (* 1 = 0.13405 loss)
I0614 09:15:54.125075 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161268 (* 1 = 0.161268 loss)
I0614 09:15:54.125079 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000590281 (* 1 = 0.000590281 loss)
I0614 09:15:54.125083 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227435 (* 1 = 0.0227435 loss)
I0614 09:15:54.125088 15760 sgd_solver.cpp:106] Iteration 7940, lr = 0.0002
I0614 09:17:40.708151 15760 solver.cpp:228] Iteration 7960, loss = 0.489935
I0614 09:17:40.708178 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 09:17:40.708185 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112784 (* 1 = 0.112784 loss)
I0614 09:17:40.708189 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.196444 (* 1 = 0.196444 loss)
I0614 09:17:40.708194 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00564065 (* 1 = 0.00564065 loss)
I0614 09:17:40.708197 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217509 (* 1 = 0.0217509 loss)
I0614 09:17:40.708204 15760 sgd_solver.cpp:106] Iteration 7960, lr = 0.0002
I0614 09:19:27.147306 15760 solver.cpp:228] Iteration 7980, loss = 0.671872
I0614 09:19:27.147333 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 09:19:27.147341 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.527179 (* 1 = 0.527179 loss)
I0614 09:19:27.147346 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.534029 (* 1 = 0.534029 loss)
I0614 09:19:27.147349 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206875 (* 1 = 0.0206875 loss)
I0614 09:19:27.147353 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.141342 (* 1 = 0.141342 loss)
I0614 09:19:27.147358 15760 sgd_solver.cpp:106] Iteration 7980, lr = 0.0002
speed: 5.331s / iter
I0614 09:21:13.772689 15760 solver.cpp:228] Iteration 8000, loss = 0.782117
I0614 09:21:13.772714 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 09:21:13.772722 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.324663 (* 1 = 0.324663 loss)
I0614 09:21:13.772725 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.455938 (* 1 = 0.455938 loss)
I0614 09:21:13.772730 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0769519 (* 1 = 0.0769519 loss)
I0614 09:21:13.772733 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.504531 (* 1 = 0.504531 loss)
I0614 09:21:13.772738 15760 sgd_solver.cpp:106] Iteration 8000, lr = 0.0002
I0614 09:23:00.063907 15760 solver.cpp:228] Iteration 8020, loss = 0.809518
I0614 09:23:00.063933 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 09:23:00.063941 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.253131 (* 1 = 0.253131 loss)
I0614 09:23:00.063944 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.337622 (* 1 = 0.337622 loss)
I0614 09:23:00.063947 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0014228 (* 1 = 0.0014228 loss)
I0614 09:23:00.063951 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218434 (* 1 = 0.0218434 loss)
I0614 09:23:00.063956 15760 sgd_solver.cpp:106] Iteration 8020, lr = 0.0002
I0614 09:24:46.322711 15760 solver.cpp:228] Iteration 8040, loss = 0.40623
I0614 09:24:46.322736 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 09:24:46.322746 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.196717 (* 1 = 0.196717 loss)
I0614 09:24:46.322751 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.265463 (* 1 = 0.265463 loss)
I0614 09:24:46.322757 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100287 (* 1 = 0.00100287 loss)
I0614 09:24:46.322762 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318858 (* 1 = 0.0318858 loss)
I0614 09:24:46.322770 15760 sgd_solver.cpp:106] Iteration 8040, lr = 0.0002
I0614 09:26:32.719583 15760 solver.cpp:228] Iteration 8060, loss = 1.21962
I0614 09:26:32.719609 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 09:26:32.719616 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.299316 (* 1 = 0.299316 loss)
I0614 09:26:32.719620 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.450386 (* 1 = 0.450386 loss)
I0614 09:26:32.719624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0556999 (* 1 = 0.0556999 loss)
I0614 09:26:32.719629 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0717371 (* 1 = 0.0717371 loss)
I0614 09:26:32.719632 15760 sgd_solver.cpp:106] Iteration 8060, lr = 0.0002
I0614 09:28:19.220444 15760 solver.cpp:228] Iteration 8080, loss = 0.47083
I0614 09:28:19.220468 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 09:28:19.220474 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.14066 (* 1 = 0.14066 loss)
I0614 09:28:19.220479 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.302565 (* 1 = 0.302565 loss)
I0614 09:28:19.220482 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0274215 (* 1 = 0.0274215 loss)
I0614 09:28:19.220485 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512664 (* 1 = 0.0512664 loss)
I0614 09:28:19.220490 15760 sgd_solver.cpp:106] Iteration 8080, lr = 0.0002
I0614 09:30:05.395546 15760 solver.cpp:228] Iteration 8100, loss = 0.62414
I0614 09:30:05.395578 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 09:30:05.395589 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822694 (* 1 = 0.0822694 loss)
I0614 09:30:05.395593 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.14687 (* 1 = 0.14687 loss)
I0614 09:30:05.395597 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.007226 (* 1 = 0.007226 loss)
I0614 09:30:05.395601 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387369 (* 1 = 0.0387369 loss)
I0614 09:30:05.395606 15760 sgd_solver.cpp:106] Iteration 8100, lr = 0.0002
I0614 09:31:51.606863 15760 solver.cpp:228] Iteration 8120, loss = 0.755341
I0614 09:31:51.606890 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 09:31:51.606900 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.154448 (* 1 = 0.154448 loss)
I0614 09:31:51.606907 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.300697 (* 1 = 0.300697 loss)
I0614 09:31:51.606914 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591567 (* 1 = 0.00591567 loss)
I0614 09:31:51.606920 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195021 (* 1 = 0.0195021 loss)
I0614 09:31:51.606930 15760 sgd_solver.cpp:106] Iteration 8120, lr = 0.0002
I0614 09:33:38.091867 15760 solver.cpp:228] Iteration 8140, loss = 0.568963
I0614 09:33:38.091893 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 09:33:38.091900 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.207319 (* 1 = 0.207319 loss)
I0614 09:33:38.091905 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.443163 (* 1 = 0.443163 loss)
I0614 09:33:38.091909 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938634 (* 1 = 0.00938634 loss)
I0614 09:33:38.091912 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.380825 (* 1 = 0.380825 loss)
I0614 09:33:38.091917 15760 sgd_solver.cpp:106] Iteration 8140, lr = 0.0002
I0614 09:35:24.682190 15760 solver.cpp:228] Iteration 8160, loss = 0.458285
I0614 09:35:24.682221 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 09:35:24.682231 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542451 (* 1 = 0.0542451 loss)
I0614 09:35:24.682236 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119298 (* 1 = 0.119298 loss)
I0614 09:35:24.682242 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00623968 (* 1 = 0.00623968 loss)
I0614 09:35:24.682247 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169246 (* 1 = 0.0169246 loss)
I0614 09:35:24.682253 15760 sgd_solver.cpp:106] Iteration 8160, lr = 0.0002
I0614 09:37:11.381533 15760 solver.cpp:228] Iteration 8180, loss = 0.825291
I0614 09:37:11.381559 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 09:37:11.381567 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12483 (* 1 = 0.12483 loss)
I0614 09:37:11.381572 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.232624 (* 1 = 0.232624 loss)
I0614 09:37:11.381575 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00197538 (* 1 = 0.00197538 loss)
I0614 09:37:11.381579 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158152 (* 1 = 0.0158152 loss)
I0614 09:37:11.381584 15760 sgd_solver.cpp:106] Iteration 8180, lr = 0.0002
speed: 5.331s / iter
I0614 09:38:57.898202 15760 solver.cpp:228] Iteration 8200, loss = 0.621336
I0614 09:38:57.898228 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 09:38:57.898236 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.122521 (* 1 = 0.122521 loss)
I0614 09:38:57.898241 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.250467 (* 1 = 0.250467 loss)
I0614 09:38:57.898244 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000529496 (* 1 = 0.000529496 loss)
I0614 09:38:57.898247 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104514 (* 1 = 0.0104514 loss)
I0614 09:38:57.898253 15760 sgd_solver.cpp:106] Iteration 8200, lr = 0.0002
I0614 09:40:44.269549 15760 solver.cpp:228] Iteration 8220, loss = 0.518721
I0614 09:40:44.269575 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 09:40:44.269583 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.266384 (* 1 = 0.266384 loss)
I0614 09:40:44.269587 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.298299 (* 1 = 0.298299 loss)
I0614 09:40:44.269593 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00210345 (* 1 = 0.00210345 loss)
I0614 09:40:44.269596 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0617941 (* 1 = 0.0617941 loss)
I0614 09:40:44.269601 15760 sgd_solver.cpp:106] Iteration 8220, lr = 0.0002
I0614 09:42:30.691715 15760 solver.cpp:228] Iteration 8240, loss = 0.562048
I0614 09:42:30.691740 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 09:42:30.691746 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.174189 (* 1 = 0.174189 loss)
I0614 09:42:30.691751 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.151085 (* 1 = 0.151085 loss)
I0614 09:42:30.691756 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000617751 (* 1 = 0.000617751 loss)
I0614 09:42:30.691759 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025025 (* 1 = 0.025025 loss)
I0614 09:42:30.691766 15760 sgd_solver.cpp:106] Iteration 8240, lr = 0.0002
I0614 09:44:17.274569 15760 solver.cpp:228] Iteration 8260, loss = 0.685715
I0614 09:44:17.274598 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 09:44:17.274608 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.283308 (* 1 = 0.283308 loss)
I0614 09:44:17.274615 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321647 (* 1 = 0.321647 loss)
I0614 09:44:17.274621 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00813401 (* 1 = 0.00813401 loss)
I0614 09:44:17.274626 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241222 (* 1 = 0.0241222 loss)
I0614 09:44:17.274632 15760 sgd_solver.cpp:106] Iteration 8260, lr = 0.0002
I0614 09:46:03.670533 15760 solver.cpp:228] Iteration 8280, loss = 1.00776
I0614 09:46:03.670557 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 09:46:03.670565 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.130277 (* 1 = 0.130277 loss)
I0614 09:46:03.670568 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.200954 (* 1 = 0.200954 loss)
I0614 09:46:03.670572 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376233 (* 1 = 0.00376233 loss)
I0614 09:46:03.670575 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246075 (* 1 = 0.0246075 loss)
I0614 09:46:03.670581 15760 sgd_solver.cpp:106] Iteration 8280, lr = 0.0002
I0614 09:47:49.898340 15760 solver.cpp:228] Iteration 8300, loss = 0.504754
I0614 09:47:49.898368 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0614 09:47:49.898378 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129104 (* 1 = 0.129104 loss)
I0614 09:47:49.898386 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.593487 (* 1 = 0.593487 loss)
I0614 09:47:49.898392 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00701114 (* 1 = 0.00701114 loss)
I0614 09:47:49.898399 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209903 (* 1 = 0.0209903 loss)
I0614 09:47:49.898408 15760 sgd_solver.cpp:106] Iteration 8300, lr = 0.0002
I0614 09:49:36.305835 15760 solver.cpp:228] Iteration 8320, loss = 0.72569
I0614 09:49:36.305860 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 09:49:36.305866 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.482825 (* 1 = 0.482825 loss)
I0614 09:49:36.305871 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.541237 (* 1 = 0.541237 loss)
I0614 09:49:36.305876 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00142836 (* 1 = 0.00142836 loss)
I0614 09:49:36.305878 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106328 (* 1 = 0.106328 loss)
I0614 09:49:36.305883 15760 sgd_solver.cpp:106] Iteration 8320, lr = 0.0002
I0614 09:51:22.784456 15760 solver.cpp:228] Iteration 8340, loss = 0.525668
I0614 09:51:22.784478 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 09:51:22.784485 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.313126 (* 1 = 0.313126 loss)
I0614 09:51:22.784489 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.337109 (* 1 = 0.337109 loss)
I0614 09:51:22.784492 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00655045 (* 1 = 0.00655045 loss)
I0614 09:51:22.784497 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342932 (* 1 = 0.0342932 loss)
I0614 09:51:22.784500 15760 sgd_solver.cpp:106] Iteration 8340, lr = 0.0002
I0614 09:53:09.543756 15760 solver.cpp:228] Iteration 8360, loss = 0.719119
I0614 09:53:09.543779 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 09:53:09.543787 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129002 (* 1 = 0.129002 loss)
I0614 09:53:09.543790 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.188274 (* 1 = 0.188274 loss)
I0614 09:53:09.543794 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0018925 (* 1 = 0.0018925 loss)
I0614 09:53:09.543797 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00710888 (* 1 = 0.00710888 loss)
I0614 09:53:09.543802 15760 sgd_solver.cpp:106] Iteration 8360, lr = 0.0002
I0614 09:54:56.344290 15760 solver.cpp:228] Iteration 8380, loss = 0.634785
I0614 09:54:56.344312 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 09:54:56.344319 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0570558 (* 1 = 0.0570558 loss)
I0614 09:54:56.344323 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.236294 (* 1 = 0.236294 loss)
I0614 09:54:56.344327 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00919105 (* 1 = 0.00919105 loss)
I0614 09:54:56.344331 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0644581 (* 1 = 0.0644581 loss)
I0614 09:54:56.344336 15760 sgd_solver.cpp:106] Iteration 8380, lr = 0.0002
speed: 5.330s / iter
I0614 09:56:43.136128 15760 solver.cpp:228] Iteration 8400, loss = 0.694524
I0614 09:56:43.136150 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 09:56:43.136157 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.128215 (* 1 = 0.128215 loss)
I0614 09:56:43.136160 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.144659 (* 1 = 0.144659 loss)
I0614 09:56:43.136164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000474324 (* 1 = 0.000474324 loss)
I0614 09:56:43.136168 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243006 (* 1 = 0.0243006 loss)
I0614 09:56:43.136173 15760 sgd_solver.cpp:106] Iteration 8400, lr = 0.0002
I0614 09:58:30.241458 15760 solver.cpp:228] Iteration 8420, loss = 1.00894
I0614 09:58:30.241485 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0614 09:58:30.241492 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.06135 (* 1 = 1.06135 loss)
I0614 09:58:30.241497 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.801199 (* 1 = 0.801199 loss)
I0614 09:58:30.241500 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266601 (* 1 = 0.0266601 loss)
I0614 09:58:30.241504 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.281449 (* 1 = 0.281449 loss)
I0614 09:58:30.241509 15760 sgd_solver.cpp:106] Iteration 8420, lr = 0.0002
I0614 10:00:17.329274 15760 solver.cpp:228] Iteration 8440, loss = 0.708165
I0614 10:00:17.329299 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.40625
I0614 10:00:17.329308 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.649085 (* 1 = 0.649085 loss)
I0614 10:00:17.329311 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.18037 (* 1 = 1.18037 loss)
I0614 10:00:17.329315 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294692 (* 1 = 0.0294692 loss)
I0614 10:00:17.329319 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.316233 (* 1 = 0.316233 loss)
I0614 10:00:17.329324 15760 sgd_solver.cpp:106] Iteration 8440, lr = 0.0002
I0614 10:02:04.112550 15760 solver.cpp:228] Iteration 8460, loss = 0.668548
I0614 10:02:04.112576 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 10:02:04.112582 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.160986 (* 1 = 0.160986 loss)
I0614 10:02:04.112586 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.17358 (* 1 = 0.17358 loss)
I0614 10:02:04.112591 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00397047 (* 1 = 0.00397047 loss)
I0614 10:02:04.112593 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0377035 (* 1 = 0.0377035 loss)
I0614 10:02:04.112598 15760 sgd_solver.cpp:106] Iteration 8460, lr = 0.0002
I0614 10:03:50.576450 15760 solver.cpp:228] Iteration 8480, loss = 0.797971
I0614 10:03:50.576478 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 10:03:50.576486 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.154989 (* 1 = 0.154989 loss)
I0614 10:03:50.576490 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.13778 (* 1 = 0.13778 loss)
I0614 10:03:50.576495 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127681 (* 1 = 0.0127681 loss)
I0614 10:03:50.576498 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152426 (* 1 = 0.0152426 loss)
I0614 10:03:50.576504 15760 sgd_solver.cpp:106] Iteration 8480, lr = 0.0002
I0614 10:05:37.376330 15760 solver.cpp:228] Iteration 8500, loss = 0.803004
I0614 10:05:37.376355 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 10:05:37.376363 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.339503 (* 1 = 0.339503 loss)
I0614 10:05:37.376366 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.383692 (* 1 = 0.383692 loss)
I0614 10:05:37.376370 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00410024 (* 1 = 0.00410024 loss)
I0614 10:05:37.376374 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0505123 (* 1 = 0.0505123 loss)
I0614 10:05:37.376380 15760 sgd_solver.cpp:106] Iteration 8500, lr = 0.0002
I0614 10:07:23.981287 15760 solver.cpp:228] Iteration 8520, loss = 0.801544
I0614 10:07:23.981310 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0614 10:07:23.981318 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.461285 (* 1 = 0.461285 loss)
I0614 10:07:23.981321 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.745691 (* 1 = 0.745691 loss)
I0614 10:07:23.981325 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155279 (* 1 = 0.00155279 loss)
I0614 10:07:23.981329 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.068353 (* 1 = 0.068353 loss)
I0614 10:07:23.981334 15760 sgd_solver.cpp:106] Iteration 8520, lr = 0.0002
I0614 10:09:11.086766 15760 solver.cpp:228] Iteration 8540, loss = 0.92834
I0614 10:09:11.086796 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 10:09:11.086803 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.160689 (* 1 = 0.160689 loss)
I0614 10:09:11.086808 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.18118 (* 1 = 0.18118 loss)
I0614 10:09:11.086812 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000243215 (* 1 = 0.000243215 loss)
I0614 10:09:11.086817 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250589 (* 1 = 0.0250589 loss)
I0614 10:09:11.086822 15760 sgd_solver.cpp:106] Iteration 8540, lr = 0.0002
I0614 10:10:57.556742 15760 solver.cpp:228] Iteration 8560, loss = 0.437743
I0614 10:10:57.556766 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 10:10:57.556773 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.321422 (* 1 = 0.321422 loss)
I0614 10:10:57.556777 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321305 (* 1 = 0.321305 loss)
I0614 10:10:57.556782 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000648082 (* 1 = 0.000648082 loss)
I0614 10:10:57.556784 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430072 (* 1 = 0.0430072 loss)
I0614 10:10:57.556789 15760 sgd_solver.cpp:106] Iteration 8560, lr = 0.0002
I0614 10:12:44.306697 15760 solver.cpp:228] Iteration 8580, loss = 0.480997
I0614 10:12:44.306727 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 10:12:44.306735 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.181849 (* 1 = 0.181849 loss)
I0614 10:12:44.306740 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.243377 (* 1 = 0.243377 loss)
I0614 10:12:44.306743 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202189 (* 1 = 0.0202189 loss)
I0614 10:12:44.306747 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0536527 (* 1 = 0.0536527 loss)
I0614 10:12:44.306753 15760 sgd_solver.cpp:106] Iteration 8580, lr = 0.0002
speed: 5.331s / iter
I0614 10:14:30.828173 15760 solver.cpp:228] Iteration 8600, loss = 0.892789
I0614 10:14:30.828198 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 10:14:30.828205 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.366564 (* 1 = 0.366564 loss)
I0614 10:14:30.828208 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.446908 (* 1 = 0.446908 loss)
I0614 10:14:30.828212 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0798092 (* 1 = 0.0798092 loss)
I0614 10:14:30.828215 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.291726 (* 1 = 0.291726 loss)
I0614 10:14:30.828220 15760 sgd_solver.cpp:106] Iteration 8600, lr = 0.0002
I0614 10:16:17.027946 15760 solver.cpp:228] Iteration 8620, loss = 0.669492
I0614 10:16:17.027971 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 10:16:17.027981 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.242906 (* 1 = 0.242906 loss)
I0614 10:16:17.027987 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.441142 (* 1 = 0.441142 loss)
I0614 10:16:17.027992 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164241 (* 1 = 0.0164241 loss)
I0614 10:16:17.027997 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.092633 (* 1 = 0.092633 loss)
I0614 10:16:17.028004 15760 sgd_solver.cpp:106] Iteration 8620, lr = 0.0002
I0614 10:18:03.248700 15760 solver.cpp:228] Iteration 8640, loss = 0.700977
I0614 10:18:03.248724 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 10:18:03.248733 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.10787 (* 1 = 0.10787 loss)
I0614 10:18:03.248736 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.13648 (* 1 = 0.13648 loss)
I0614 10:18:03.248740 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00662079 (* 1 = 0.00662079 loss)
I0614 10:18:03.248744 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414423 (* 1 = 0.0414423 loss)
I0614 10:18:03.248749 15760 sgd_solver.cpp:106] Iteration 8640, lr = 0.0002
I0614 10:19:49.656517 15760 solver.cpp:228] Iteration 8660, loss = 0.607275
I0614 10:19:49.656541 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.492188
I0614 10:19:49.656549 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.498394 (* 1 = 0.498394 loss)
I0614 10:19:49.656553 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.793709 (* 1 = 0.793709 loss)
I0614 10:19:49.656558 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00867712 (* 1 = 0.00867712 loss)
I0614 10:19:49.656561 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.192686 (* 1 = 0.192686 loss)
I0614 10:19:49.656565 15760 sgd_solver.cpp:106] Iteration 8660, lr = 0.0002
I0614 10:21:36.047752 15760 solver.cpp:228] Iteration 8680, loss = 0.70539
I0614 10:21:36.047776 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 10:21:36.047783 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.46638 (* 1 = 0.46638 loss)
I0614 10:21:36.047787 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.462286 (* 1 = 0.462286 loss)
I0614 10:21:36.047791 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113116 (* 1 = 0.00113116 loss)
I0614 10:21:36.047794 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0806933 (* 1 = 0.0806933 loss)
I0614 10:21:36.047801 15760 sgd_solver.cpp:106] Iteration 8680, lr = 0.0002
I0614 10:23:22.472151 15760 solver.cpp:228] Iteration 8700, loss = 0.720891
I0614 10:23:22.472178 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.5625
I0614 10:23:22.472188 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.86274 (* 1 = 0.86274 loss)
I0614 10:23:22.472195 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.692284 (* 1 = 0.692284 loss)
I0614 10:23:22.472201 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0461551 (* 1 = 0.0461551 loss)
I0614 10:23:22.472208 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.696799 (* 1 = 0.696799 loss)
I0614 10:23:22.472216 15760 sgd_solver.cpp:106] Iteration 8700, lr = 0.0002
I0614 10:25:08.947168 15760 solver.cpp:228] Iteration 8720, loss = 0.673742
I0614 10:25:08.947192 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 10:25:08.947201 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386103 (* 1 = 0.0386103 loss)
I0614 10:25:08.947204 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128643 (* 1 = 0.128643 loss)
I0614 10:25:08.947208 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00811457 (* 1 = 0.00811457 loss)
I0614 10:25:08.947212 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214756 (* 1 = 0.0214756 loss)
I0614 10:25:08.947217 15760 sgd_solver.cpp:106] Iteration 8720, lr = 0.0002
I0614 10:26:55.305065 15760 solver.cpp:228] Iteration 8740, loss = 0.595412
I0614 10:26:55.305095 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 10:26:55.305102 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.227942 (* 1 = 0.227942 loss)
I0614 10:26:55.305106 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.365543 (* 1 = 0.365543 loss)
I0614 10:26:55.305109 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014634 (* 1 = 0.014634 loss)
I0614 10:26:55.305114 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.188612 (* 1 = 0.188612 loss)
I0614 10:26:55.305119 15760 sgd_solver.cpp:106] Iteration 8740, lr = 0.0002
I0614 10:28:41.776471 15760 solver.cpp:228] Iteration 8760, loss = 0.741984
I0614 10:28:41.776494 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 10:28:41.776501 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.104949 (* 1 = 0.104949 loss)
I0614 10:28:41.776505 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.165901 (* 1 = 0.165901 loss)
I0614 10:28:41.776510 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228751 (* 1 = 0.00228751 loss)
I0614 10:28:41.776512 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011415 (* 1 = 0.011415 loss)
I0614 10:28:41.776517 15760 sgd_solver.cpp:106] Iteration 8760, lr = 0.0002
I0614 10:30:28.280256 15760 solver.cpp:228] Iteration 8780, loss = 0.863327
I0614 10:30:28.280282 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 10:30:28.280288 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.435168 (* 1 = 0.435168 loss)
I0614 10:30:28.280293 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.6901 (* 1 = 0.6901 loss)
I0614 10:30:28.280297 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0643077 (* 1 = 0.0643077 loss)
I0614 10:30:28.280302 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.492783 (* 1 = 0.492783 loss)
I0614 10:30:28.280306 15760 sgd_solver.cpp:106] Iteration 8780, lr = 0.0002
speed: 5.330s / iter
I0614 10:32:14.532014 15760 solver.cpp:228] Iteration 8800, loss = 0.524979
I0614 10:32:14.532037 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 10:32:14.532044 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.191558 (* 1 = 0.191558 loss)
I0614 10:32:14.532048 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.360559 (* 1 = 0.360559 loss)
I0614 10:32:14.532052 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00876236 (* 1 = 0.00876236 loss)
I0614 10:32:14.532055 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226731 (* 1 = 0.0226731 loss)
I0614 10:32:14.532060 15760 sgd_solver.cpp:106] Iteration 8800, lr = 0.0002
I0614 10:34:00.960597 15760 solver.cpp:228] Iteration 8820, loss = 0.616185
I0614 10:34:00.960620 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 10:34:00.960629 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.81025 (* 1 = 0.81025 loss)
I0614 10:34:00.960635 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.517254 (* 1 = 0.517254 loss)
I0614 10:34:00.960640 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131054 (* 1 = 0.0131054 loss)
I0614 10:34:00.960646 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116845 (* 1 = 0.116845 loss)
I0614 10:34:00.960652 15760 sgd_solver.cpp:106] Iteration 8820, lr = 0.0002
I0614 10:35:47.135813 15760 solver.cpp:228] Iteration 8840, loss = 0.833332
I0614 10:35:47.135838 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.609375
I0614 10:35:47.135846 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.508044 (* 1 = 0.508044 loss)
I0614 10:35:47.135850 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.958549 (* 1 = 0.958549 loss)
I0614 10:35:47.135854 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00987178 (* 1 = 0.00987178 loss)
I0614 10:35:47.135859 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1798 (* 1 = 0.1798 loss)
I0614 10:35:47.135864 15760 sgd_solver.cpp:106] Iteration 8840, lr = 0.0002
I0614 10:37:33.795935 15760 solver.cpp:228] Iteration 8860, loss = 0.57854
I0614 10:37:33.795961 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 10:37:33.795969 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.267276 (* 1 = 0.267276 loss)
I0614 10:37:33.795974 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.306194 (* 1 = 0.306194 loss)
I0614 10:37:33.795977 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00164236 (* 1 = 0.00164236 loss)
I0614 10:37:33.795981 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.050211 (* 1 = 0.050211 loss)
I0614 10:37:33.795986 15760 sgd_solver.cpp:106] Iteration 8860, lr = 0.0002
I0614 10:39:20.329964 15760 solver.cpp:228] Iteration 8880, loss = 0.632246
I0614 10:39:20.329988 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 10:39:20.329995 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12246 (* 1 = 0.12246 loss)
I0614 10:39:20.329999 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20478 (* 1 = 0.20478 loss)
I0614 10:39:20.330003 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000493414 (* 1 = 0.000493414 loss)
I0614 10:39:20.330006 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246558 (* 1 = 0.0246558 loss)
I0614 10:39:20.330011 15760 sgd_solver.cpp:106] Iteration 8880, lr = 0.0002
I0614 10:41:07.124315 15760 solver.cpp:228] Iteration 8900, loss = 0.822356
I0614 10:41:07.124343 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 10:41:07.124356 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.036586 (* 1 = 0.036586 loss)
I0614 10:41:07.124362 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.175903 (* 1 = 0.175903 loss)
I0614 10:41:07.124369 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179499 (* 1 = 0.0179499 loss)
I0614 10:41:07.124377 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239573 (* 1 = 0.0239573 loss)
I0614 10:41:07.124387 15760 sgd_solver.cpp:106] Iteration 8900, lr = 0.0002
I0614 10:42:53.719207 15760 solver.cpp:228] Iteration 8920, loss = 0.758496
I0614 10:42:53.719233 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 10:42:53.719240 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.236423 (* 1 = 0.236423 loss)
I0614 10:42:53.719245 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.436352 (* 1 = 0.436352 loss)
I0614 10:42:53.719249 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184718 (* 1 = 0.0184718 loss)
I0614 10:42:53.719252 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.11304 (* 1 = 0.11304 loss)
I0614 10:42:53.719259 15760 sgd_solver.cpp:106] Iteration 8920, lr = 0.0002
I0614 10:44:40.679481 15760 solver.cpp:228] Iteration 8940, loss = 0.49835
I0614 10:44:40.679504 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 10:44:40.679510 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.368232 (* 1 = 0.368232 loss)
I0614 10:44:40.679514 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.354227 (* 1 = 0.354227 loss)
I0614 10:44:40.679518 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017898 (* 1 = 0.0017898 loss)
I0614 10:44:40.679522 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0496582 (* 1 = 0.0496582 loss)
I0614 10:44:40.679527 15760 sgd_solver.cpp:106] Iteration 8940, lr = 0.0002
I0614 10:46:27.376219 15760 solver.cpp:228] Iteration 8960, loss = 0.880835
I0614 10:46:27.376245 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 10:46:27.376252 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.184354 (* 1 = 0.184354 loss)
I0614 10:46:27.376258 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.169309 (* 1 = 0.169309 loss)
I0614 10:46:27.376266 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00312404 (* 1 = 0.00312404 loss)
I0614 10:46:27.376271 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0691791 (* 1 = 0.0691791 loss)
I0614 10:46:27.376276 15760 sgd_solver.cpp:106] Iteration 8960, lr = 0.0002
I0614 10:48:13.788929 15760 solver.cpp:228] Iteration 8980, loss = 0.55244
I0614 10:48:13.788966 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 10:48:13.788975 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.27818 (* 1 = 0.27818 loss)
I0614 10:48:13.788980 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.254762 (* 1 = 0.254762 loss)
I0614 10:48:13.788983 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00367746 (* 1 = 0.00367746 loss)
I0614 10:48:13.788990 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013333 (* 1 = 0.013333 loss)
I0614 10:48:13.788995 15760 sgd_solver.cpp:106] Iteration 8980, lr = 0.0002
speed: 5.330s / iter
I0614 10:50:00.060669 15760 solver.cpp:228] Iteration 9000, loss = 0.592133
I0614 10:50:00.060693 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 10:50:00.060700 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0860103 (* 1 = 0.0860103 loss)
I0614 10:50:00.060703 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.1756 (* 1 = 0.1756 loss)
I0614 10:50:00.060708 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00476388 (* 1 = 0.00476388 loss)
I0614 10:50:00.060710 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187813 (* 1 = 0.0187813 loss)
I0614 10:50:00.060715 15760 sgd_solver.cpp:106] Iteration 9000, lr = 0.0002
I0614 10:51:46.255141 15760 solver.cpp:228] Iteration 9020, loss = 0.701658
I0614 10:51:46.255163 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 10:51:46.255170 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.563197 (* 1 = 0.563197 loss)
I0614 10:51:46.255174 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.486002 (* 1 = 0.486002 loss)
I0614 10:51:46.255177 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616861 (* 1 = 0.00616861 loss)
I0614 10:51:46.255180 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106093 (* 1 = 0.106093 loss)
I0614 10:51:46.255185 15760 sgd_solver.cpp:106] Iteration 9020, lr = 0.0002
I0614 10:53:32.827394 15760 solver.cpp:228] Iteration 9040, loss = 0.599058
I0614 10:53:32.827417 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 10:53:32.827425 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890313 (* 1 = 0.0890313 loss)
I0614 10:53:32.827428 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120364 (* 1 = 0.120364 loss)
I0614 10:53:32.827432 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00467318 (* 1 = 0.00467318 loss)
I0614 10:53:32.827436 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315627 (* 1 = 0.0315627 loss)
I0614 10:53:32.827440 15760 sgd_solver.cpp:106] Iteration 9040, lr = 0.0002
I0614 10:55:19.175942 15760 solver.cpp:228] Iteration 9060, loss = 0.766381
I0614 10:55:19.175966 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 10:55:19.175972 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453316 (* 1 = 0.0453316 loss)
I0614 10:55:19.175976 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0843817 (* 1 = 0.0843817 loss)
I0614 10:55:19.175979 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0398896 (* 1 = 0.0398896 loss)
I0614 10:55:19.175983 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362505 (* 1 = 0.0362505 loss)
I0614 10:55:19.175987 15760 sgd_solver.cpp:106] Iteration 9060, lr = 0.0002
I0614 10:57:05.542500 15760 solver.cpp:228] Iteration 9080, loss = 0.636344
I0614 10:57:05.542526 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 10:57:05.542533 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.213952 (* 1 = 0.213952 loss)
I0614 10:57:05.542537 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.312169 (* 1 = 0.312169 loss)
I0614 10:57:05.542541 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183841 (* 1 = 0.00183841 loss)
I0614 10:57:05.542546 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327792 (* 1 = 0.0327792 loss)
I0614 10:57:05.542551 15760 sgd_solver.cpp:106] Iteration 9080, lr = 0.0002
I0614 10:58:51.984757 15760 solver.cpp:228] Iteration 9100, loss = 0.781573
I0614 10:58:51.984781 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 10:58:51.984788 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.44731 (* 1 = 0.44731 loss)
I0614 10:58:51.984792 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.38839 (* 1 = 0.38839 loss)
I0614 10:58:51.984797 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00373275 (* 1 = 0.00373275 loss)
I0614 10:58:51.984800 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0785272 (* 1 = 0.0785272 loss)
I0614 10:58:51.984804 15760 sgd_solver.cpp:106] Iteration 9100, lr = 0.0002
I0614 11:00:38.369279 15760 solver.cpp:228] Iteration 9120, loss = 0.989611
I0614 11:00:38.369304 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 11:00:38.369312 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.115744 (* 1 = 0.115744 loss)
I0614 11:00:38.369315 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.12868 (* 1 = 0.12868 loss)
I0614 11:00:38.369319 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015262 (* 1 = 0.0015262 loss)
I0614 11:00:38.369323 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221549 (* 1 = 0.0221549 loss)
I0614 11:00:38.369328 15760 sgd_solver.cpp:106] Iteration 9120, lr = 0.0002
I0614 11:02:24.770045 15760 solver.cpp:228] Iteration 9140, loss = 0.559753
I0614 11:02:24.770071 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 11:02:24.770079 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0048032 (* 1 = 0.0048032 loss)
I0614 11:02:24.770083 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0809519 (* 1 = 0.0809519 loss)
I0614 11:02:24.770087 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0856556 (* 1 = 0.0856556 loss)
I0614 11:02:24.770092 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280153 (* 1 = 0.0280153 loss)
I0614 11:02:24.770097 15760 sgd_solver.cpp:106] Iteration 9140, lr = 0.0002
I0614 11:04:11.170433 15760 solver.cpp:228] Iteration 9160, loss = 0.706171
I0614 11:04:11.170459 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 11:04:11.170466 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0858306 (* 1 = 0.0858306 loss)
I0614 11:04:11.170470 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.156913 (* 1 = 0.156913 loss)
I0614 11:04:11.170475 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0070848 (* 1 = 0.0070848 loss)
I0614 11:04:11.170478 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268504 (* 1 = 0.0268504 loss)
I0614 11:04:11.170483 15760 sgd_solver.cpp:106] Iteration 9160, lr = 0.0002
I0614 11:05:57.485462 15760 solver.cpp:228] Iteration 9180, loss = 0.564166
I0614 11:05:57.485486 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 11:05:57.485491 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.042787 (* 1 = 0.042787 loss)
I0614 11:05:57.485496 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.146169 (* 1 = 0.146169 loss)
I0614 11:05:57.485499 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177176 (* 1 = 0.0177176 loss)
I0614 11:05:57.485502 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0508783 (* 1 = 0.0508783 loss)
I0614 11:05:57.485507 15760 sgd_solver.cpp:106] Iteration 9180, lr = 0.0002
speed: 5.330s / iter
I0614 11:07:43.859740 15760 solver.cpp:228] Iteration 9200, loss = 0.790872
I0614 11:07:43.859764 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 11:07:43.859771 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.369889 (* 1 = 0.369889 loss)
I0614 11:07:43.859774 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.399854 (* 1 = 0.399854 loss)
I0614 11:07:43.859778 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053301 (* 1 = 0.0053301 loss)
I0614 11:07:43.859781 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106583 (* 1 = 0.106583 loss)
I0614 11:07:43.859786 15760 sgd_solver.cpp:106] Iteration 9200, lr = 0.0002
I0614 11:09:30.137454 15760 solver.cpp:228] Iteration 9220, loss = 0.584508
I0614 11:09:30.137478 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 11:09:30.137485 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.126111 (* 1 = 0.126111 loss)
I0614 11:09:30.137490 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.175591 (* 1 = 0.175591 loss)
I0614 11:09:30.137493 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0049505 (* 1 = 0.0049505 loss)
I0614 11:09:30.137497 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250354 (* 1 = 0.0250354 loss)
I0614 11:09:30.137503 15760 sgd_solver.cpp:106] Iteration 9220, lr = 0.0002
I0614 11:11:16.645803 15760 solver.cpp:228] Iteration 9240, loss = 0.690474
I0614 11:11:16.645826 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.609375
I0614 11:11:16.645833 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.618876 (* 1 = 0.618876 loss)
I0614 11:11:16.645838 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.81911 (* 1 = 0.81911 loss)
I0614 11:11:16.645841 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129278 (* 1 = 0.0129278 loss)
I0614 11:11:16.645844 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.397203 (* 1 = 0.397203 loss)
I0614 11:11:16.645849 15760 sgd_solver.cpp:106] Iteration 9240, lr = 0.0002
I0614 11:13:03.122745 15760 solver.cpp:228] Iteration 9260, loss = 0.527777
I0614 11:13:03.122768 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 11:13:03.122777 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0666488 (* 1 = 0.0666488 loss)
I0614 11:13:03.122783 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.203518 (* 1 = 0.203518 loss)
I0614 11:13:03.122789 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00961146 (* 1 = 0.00961146 loss)
I0614 11:13:03.122794 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145655 (* 1 = 0.0145655 loss)
I0614 11:13:03.122800 15760 sgd_solver.cpp:106] Iteration 9260, lr = 0.0002
I0614 11:14:49.435254 15760 solver.cpp:228] Iteration 9280, loss = 0.426399
I0614 11:14:49.435277 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 11:14:49.435284 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.116363 (* 1 = 0.116363 loss)
I0614 11:14:49.435287 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.24786 (* 1 = 0.24786 loss)
I0614 11:14:49.435292 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262718 (* 1 = 0.0262718 loss)
I0614 11:14:49.435294 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0810733 (* 1 = 0.0810733 loss)
I0614 11:14:49.435299 15760 sgd_solver.cpp:106] Iteration 9280, lr = 0.0002
I0614 11:16:35.884002 15760 solver.cpp:228] Iteration 9300, loss = 0.476054
I0614 11:16:35.884025 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 11:16:35.884032 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.255111 (* 1 = 0.255111 loss)
I0614 11:16:35.884037 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.394751 (* 1 = 0.394751 loss)
I0614 11:16:35.884039 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00374024 (* 1 = 0.00374024 loss)
I0614 11:16:35.884043 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380814 (* 1 = 0.0380814 loss)
I0614 11:16:35.884048 15760 sgd_solver.cpp:106] Iteration 9300, lr = 0.0002
I0614 11:18:22.223191 15760 solver.cpp:228] Iteration 9320, loss = 0.587923
I0614 11:18:22.223213 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 11:18:22.223222 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.154229 (* 1 = 0.154229 loss)
I0614 11:18:22.223225 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159656 (* 1 = 0.159656 loss)
I0614 11:18:22.223229 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00493955 (* 1 = 0.00493955 loss)
I0614 11:18:22.223233 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149897 (* 1 = 0.0149897 loss)
I0614 11:18:22.223238 15760 sgd_solver.cpp:106] Iteration 9320, lr = 0.0002
I0614 11:20:08.512017 15760 solver.cpp:228] Iteration 9340, loss = 0.656087
I0614 11:20:08.512043 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 11:20:08.512050 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.638229 (* 1 = 0.638229 loss)
I0614 11:20:08.512055 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.585351 (* 1 = 0.585351 loss)
I0614 11:20:08.512059 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102308 (* 1 = 0.0102308 loss)
I0614 11:20:08.512063 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.204928 (* 1 = 0.204928 loss)
I0614 11:20:08.512068 15760 sgd_solver.cpp:106] Iteration 9340, lr = 0.0002
I0614 11:21:55.254062 15760 solver.cpp:228] Iteration 9360, loss = 1.07184
I0614 11:21:55.254086 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0614 11:21:55.254093 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.695417 (* 1 = 0.695417 loss)
I0614 11:21:55.254097 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.551889 (* 1 = 0.551889 loss)
I0614 11:21:55.254101 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114003 (* 1 = 0.0114003 loss)
I0614 11:21:55.254104 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112713 (* 1 = 0.112713 loss)
I0614 11:21:55.254109 15760 sgd_solver.cpp:106] Iteration 9360, lr = 0.0002
I0614 11:23:41.496932 15760 solver.cpp:228] Iteration 9380, loss = 0.604461
I0614 11:23:41.496960 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 11:23:41.496968 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0959226 (* 1 = 0.0959226 loss)
I0614 11:23:41.496973 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161327 (* 1 = 0.161327 loss)
I0614 11:23:41.496976 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0332297 (* 1 = 0.0332297 loss)
I0614 11:23:41.496980 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0620062 (* 1 = 0.0620062 loss)
I0614 11:23:41.496985 15760 sgd_solver.cpp:106] Iteration 9380, lr = 0.0002
speed: 5.330s / iter
I0614 11:25:27.928953 15760 solver.cpp:228] Iteration 9400, loss = 0.552459
I0614 11:25:27.928977 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 11:25:27.928985 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109719 (* 1 = 0.109719 loss)
I0614 11:25:27.928989 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.132612 (* 1 = 0.132612 loss)
I0614 11:25:27.928994 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106729 (* 1 = 0.00106729 loss)
I0614 11:25:27.928998 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00362467 (* 1 = 0.00362467 loss)
I0614 11:25:27.929003 15760 sgd_solver.cpp:106] Iteration 9400, lr = 0.0002
I0614 11:27:14.331815 15760 solver.cpp:228] Iteration 9420, loss = 0.723216
I0614 11:27:14.331836 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0614 11:27:14.331843 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.659763 (* 1 = 0.659763 loss)
I0614 11:27:14.331847 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.658646 (* 1 = 0.658646 loss)
I0614 11:27:14.331851 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017875 (* 1 = 0.017875 loss)
I0614 11:27:14.331854 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117696 (* 1 = 0.117696 loss)
I0614 11:27:14.331858 15760 sgd_solver.cpp:106] Iteration 9420, lr = 0.0002
I0614 11:29:00.433749 15760 solver.cpp:228] Iteration 9440, loss = 0.963086
I0614 11:29:00.433773 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 11:29:00.433780 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.180358 (* 1 = 0.180358 loss)
I0614 11:29:00.433784 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.412695 (* 1 = 0.412695 loss)
I0614 11:29:00.433787 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263191 (* 1 = 0.0263191 loss)
I0614 11:29:00.433790 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0741601 (* 1 = 0.0741601 loss)
I0614 11:29:00.433795 15760 sgd_solver.cpp:106] Iteration 9440, lr = 0.0002
I0614 11:30:47.263782 15760 solver.cpp:228] Iteration 9460, loss = 0.588833
I0614 11:30:47.263810 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 11:30:47.263818 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.26263 (* 1 = 0.26263 loss)
I0614 11:30:47.263823 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.263674 (* 1 = 0.263674 loss)
I0614 11:30:47.263826 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00243036 (* 1 = 0.00243036 loss)
I0614 11:30:47.263829 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345648 (* 1 = 0.0345648 loss)
I0614 11:30:47.263834 15760 sgd_solver.cpp:106] Iteration 9460, lr = 0.0002
I0614 11:32:33.348487 15760 solver.cpp:228] Iteration 9480, loss = 0.873677
I0614 11:32:33.348513 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 11:32:33.348521 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.123521 (* 1 = 0.123521 loss)
I0614 11:32:33.348526 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.19229 (* 1 = 0.19229 loss)
I0614 11:32:33.348531 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00096141 (* 1 = 0.00096141 loss)
I0614 11:32:33.348533 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242814 (* 1 = 0.0242814 loss)
I0614 11:32:33.348538 15760 sgd_solver.cpp:106] Iteration 9480, lr = 0.0002
I0614 11:34:20.081750 15760 solver.cpp:228] Iteration 9500, loss = 0.606298
I0614 11:34:20.081774 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 11:34:20.081780 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.354152 (* 1 = 0.354152 loss)
I0614 11:34:20.081784 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.420675 (* 1 = 0.420675 loss)
I0614 11:34:20.081789 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0058488 (* 1 = 0.0058488 loss)
I0614 11:34:20.081792 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0807858 (* 1 = 0.0807858 loss)
I0614 11:34:20.081796 15760 sgd_solver.cpp:106] Iteration 9500, lr = 0.0002
I0614 11:36:06.381214 15760 solver.cpp:228] Iteration 9520, loss = 1.10501
I0614 11:36:06.381239 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.554688
I0614 11:36:06.381249 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.03237 (* 1 = 1.03237 loss)
I0614 11:36:06.381255 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.854633 (* 1 = 0.854633 loss)
I0614 11:36:06.381263 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674568 (* 1 = 0.00674568 loss)
I0614 11:36:06.381268 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148483 (* 1 = 0.148483 loss)
I0614 11:36:06.381276 15760 sgd_solver.cpp:106] Iteration 9520, lr = 0.0002
I0614 11:37:53.329632 15760 solver.cpp:228] Iteration 9540, loss = 0.830535
I0614 11:37:53.329663 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 11:37:53.329670 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.138131 (* 1 = 0.138131 loss)
I0614 11:37:53.329675 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.270379 (* 1 = 0.270379 loss)
I0614 11:37:53.329680 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000266717 (* 1 = 0.000266717 loss)
I0614 11:37:53.329685 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015082 (* 1 = 0.015082 loss)
I0614 11:37:53.329691 15760 sgd_solver.cpp:106] Iteration 9540, lr = 0.0002
I0614 11:39:40.164494 15760 solver.cpp:228] Iteration 9560, loss = 0.704481
I0614 11:39:40.164520 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 11:39:40.164530 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.276588 (* 1 = 0.276588 loss)
I0614 11:39:40.164535 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.330396 (* 1 = 0.330396 loss)
I0614 11:39:40.164541 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00677097 (* 1 = 0.00677097 loss)
I0614 11:39:40.164547 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292929 (* 1 = 0.0292929 loss)
I0614 11:39:40.164553 15760 sgd_solver.cpp:106] Iteration 9560, lr = 0.0002
I0614 11:41:26.930583 15760 solver.cpp:228] Iteration 9580, loss = 0.891241
I0614 11:41:26.930609 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0614 11:41:26.930616 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.729339 (* 1 = 0.729339 loss)
I0614 11:41:26.930620 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.702764 (* 1 = 0.702764 loss)
I0614 11:41:26.930624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0807384 (* 1 = 0.0807384 loss)
I0614 11:41:26.930627 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.171519 (* 1 = 0.171519 loss)
I0614 11:41:26.930631 15760 sgd_solver.cpp:106] Iteration 9580, lr = 0.0002
speed: 5.330s / iter
I0614 11:43:13.553542 15760 solver.cpp:228] Iteration 9600, loss = 0.715402
I0614 11:43:13.553566 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 11:43:13.553573 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.368947 (* 1 = 0.368947 loss)
I0614 11:43:13.553577 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.372373 (* 1 = 0.372373 loss)
I0614 11:43:13.553581 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144038 (* 1 = 0.0144038 loss)
I0614 11:43:13.553584 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.254197 (* 1 = 0.254197 loss)
I0614 11:43:13.553591 15760 sgd_solver.cpp:106] Iteration 9600, lr = 0.0002
I0614 11:45:00.667601 15760 solver.cpp:228] Iteration 9620, loss = 0.666578
I0614 11:45:00.667625 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 11:45:00.667631 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.144728 (* 1 = 0.144728 loss)
I0614 11:45:00.667635 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.245402 (* 1 = 0.245402 loss)
I0614 11:45:00.667639 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000843898 (* 1 = 0.000843898 loss)
I0614 11:45:00.667642 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03234 (* 1 = 0.03234 loss)
I0614 11:45:00.667647 15760 sgd_solver.cpp:106] Iteration 9620, lr = 0.0002
I0614 11:46:47.201514 15760 solver.cpp:228] Iteration 9640, loss = 0.766467
I0614 11:46:47.201555 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 11:46:47.201567 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.125499 (* 1 = 0.125499 loss)
I0614 11:46:47.201575 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.151225 (* 1 = 0.151225 loss)
I0614 11:46:47.201581 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00835025 (* 1 = 0.00835025 loss)
I0614 11:46:47.201587 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193702 (* 1 = 0.0193702 loss)
I0614 11:46:47.201596 15760 sgd_solver.cpp:106] Iteration 9640, lr = 0.0002
I0614 11:48:34.180536 15760 solver.cpp:228] Iteration 9660, loss = 0.66865
I0614 11:48:34.180560 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 11:48:34.180568 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0414184 (* 1 = 0.0414184 loss)
I0614 11:48:34.180572 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0912284 (* 1 = 0.0912284 loss)
I0614 11:48:34.180575 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149173 (* 1 = 0.00149173 loss)
I0614 11:48:34.180579 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237393 (* 1 = 0.0237393 loss)
I0614 11:48:34.180584 15760 sgd_solver.cpp:106] Iteration 9660, lr = 0.0002
I0614 11:50:20.662410 15760 solver.cpp:228] Iteration 9680, loss = 0.675299
I0614 11:50:20.662434 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 11:50:20.662441 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.10568 (* 1 = 0.10568 loss)
I0614 11:50:20.662446 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195133 (* 1 = 0.195133 loss)
I0614 11:50:20.662449 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00452423 (* 1 = 0.00452423 loss)
I0614 11:50:20.662452 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162614 (* 1 = 0.0162614 loss)
I0614 11:50:20.662458 15760 sgd_solver.cpp:106] Iteration 9680, lr = 0.0002
I0614 11:52:07.218564 15760 solver.cpp:228] Iteration 9700, loss = 0.76804
I0614 11:52:07.218591 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0614 11:52:07.218598 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.74113 (* 1 = 0.74113 loss)
I0614 11:52:07.218602 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.714119 (* 1 = 0.714119 loss)
I0614 11:52:07.218606 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.106553 (* 1 = 0.106553 loss)
I0614 11:52:07.218611 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.647678 (* 1 = 0.647678 loss)
I0614 11:52:07.218616 15760 sgd_solver.cpp:106] Iteration 9700, lr = 0.0002
I0614 11:53:53.629251 15760 solver.cpp:228] Iteration 9720, loss = 0.604471
I0614 11:53:53.629276 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 11:53:53.629284 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.14655 (* 1 = 0.14655 loss)
I0614 11:53:53.629289 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.108982 (* 1 = 0.108982 loss)
I0614 11:53:53.629293 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178011 (* 1 = 0.00178011 loss)
I0614 11:53:53.629297 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197296 (* 1 = 0.0197296 loss)
I0614 11:53:53.629302 15760 sgd_solver.cpp:106] Iteration 9720, lr = 0.0002
I0614 11:55:40.178185 15760 solver.cpp:228] Iteration 9740, loss = 0.70985
I0614 11:55:40.178210 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.625
I0614 11:55:40.178217 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.587864 (* 1 = 0.587864 loss)
I0614 11:55:40.178221 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.765726 (* 1 = 0.765726 loss)
I0614 11:55:40.178225 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.10066 (* 1 = 0.10066 loss)
I0614 11:55:40.178228 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.378128 (* 1 = 0.378128 loss)
I0614 11:55:40.178232 15760 sgd_solver.cpp:106] Iteration 9740, lr = 0.0002
I0614 11:57:26.494586 15760 solver.cpp:228] Iteration 9760, loss = 0.422129
I0614 11:57:26.494611 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 11:57:26.494621 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.191276 (* 1 = 0.191276 loss)
I0614 11:57:26.494627 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.237235 (* 1 = 0.237235 loss)
I0614 11:57:26.494634 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00355725 (* 1 = 0.00355725 loss)
I0614 11:57:26.494642 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293262 (* 1 = 0.0293262 loss)
I0614 11:57:26.494648 15760 sgd_solver.cpp:106] Iteration 9760, lr = 0.0002
I0614 11:59:13.179951 15760 solver.cpp:228] Iteration 9780, loss = 0.742829
I0614 11:59:13.179975 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0614 11:59:13.179982 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.449097 (* 1 = 0.449097 loss)
I0614 11:59:13.179986 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.545483 (* 1 = 0.545483 loss)
I0614 11:59:13.179989 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713127 (* 1 = 0.00713127 loss)
I0614 11:59:13.179992 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0700792 (* 1 = 0.0700792 loss)
I0614 11:59:13.179997 15760 sgd_solver.cpp:106] Iteration 9780, lr = 0.0002
speed: 5.330s / iter
I0614 12:00:59.379930 15760 solver.cpp:228] Iteration 9800, loss = 0.663954
I0614 12:00:59.379956 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 12:00:59.379963 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11583 (* 1 = 0.11583 loss)
I0614 12:00:59.379967 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.170831 (* 1 = 0.170831 loss)
I0614 12:00:59.379971 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00663036 (* 1 = 0.00663036 loss)
I0614 12:00:59.379974 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0483835 (* 1 = 0.0483835 loss)
I0614 12:00:59.379979 15760 sgd_solver.cpp:106] Iteration 9800, lr = 0.0002
I0614 12:02:45.628267 15760 solver.cpp:228] Iteration 9820, loss = 0.523635
I0614 12:02:45.628293 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 12:02:45.628299 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.172936 (* 1 = 0.172936 loss)
I0614 12:02:45.628304 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.150841 (* 1 = 0.150841 loss)
I0614 12:02:45.628309 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00054833 (* 1 = 0.00054833 loss)
I0614 12:02:45.628311 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371581 (* 1 = 0.0371581 loss)
I0614 12:02:45.628316 15760 sgd_solver.cpp:106] Iteration 9820, lr = 0.0002
I0614 12:04:32.030820 15760 solver.cpp:228] Iteration 9840, loss = 0.803177
I0614 12:04:32.030844 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 12:04:32.030853 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.565567 (* 1 = 0.565567 loss)
I0614 12:04:32.030855 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.567094 (* 1 = 0.567094 loss)
I0614 12:04:32.030859 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0648986 (* 1 = 0.0648986 loss)
I0614 12:04:32.030863 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191176 (* 1 = 0.191176 loss)
I0614 12:04:32.030867 15760 sgd_solver.cpp:106] Iteration 9840, lr = 0.0002
I0614 12:06:18.306478 15760 solver.cpp:228] Iteration 9860, loss = 0.944264
I0614 12:06:18.306502 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.492188
I0614 12:06:18.306509 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.454317 (* 1 = 0.454317 loss)
I0614 12:06:18.306512 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.814087 (* 1 = 0.814087 loss)
I0614 12:06:18.306516 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177106 (* 1 = 0.0177106 loss)
I0614 12:06:18.306519 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.144001 (* 1 = 0.144001 loss)
I0614 12:06:18.306524 15760 sgd_solver.cpp:106] Iteration 9860, lr = 0.0002
I0614 12:08:05.181440 15760 solver.cpp:228] Iteration 9880, loss = 0.750474
I0614 12:08:05.181465 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 12:08:05.181473 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.293524 (* 1 = 0.293524 loss)
I0614 12:08:05.181478 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.340133 (* 1 = 0.340133 loss)
I0614 12:08:05.181481 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00450197 (* 1 = 0.00450197 loss)
I0614 12:08:05.181485 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273013 (* 1 = 0.0273013 loss)
I0614 12:08:05.181491 15760 sgd_solver.cpp:106] Iteration 9880, lr = 0.0002
I0614 12:09:51.827455 15760 solver.cpp:228] Iteration 9900, loss = 0.651995
I0614 12:09:51.827481 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 12:09:51.827489 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11571 (* 1 = 0.11571 loss)
I0614 12:09:51.827493 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167835 (* 1 = 0.167835 loss)
I0614 12:09:51.827497 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192012 (* 1 = 0.0192012 loss)
I0614 12:09:51.827502 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199744 (* 1 = 0.0199744 loss)
I0614 12:09:51.827507 15760 sgd_solver.cpp:106] Iteration 9900, lr = 0.0002
I0614 12:11:38.770357 15760 solver.cpp:228] Iteration 9920, loss = 0.666442
I0614 12:11:38.770382 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 12:11:38.770390 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.185404 (* 1 = 0.185404 loss)
I0614 12:11:38.770393 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.244659 (* 1 = 0.244659 loss)
I0614 12:11:38.770397 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00685447 (* 1 = 0.00685447 loss)
I0614 12:11:38.770402 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162701 (* 1 = 0.0162701 loss)
I0614 12:11:38.770407 15760 sgd_solver.cpp:106] Iteration 9920, lr = 0.0002
I0614 12:13:25.147754 15760 solver.cpp:228] Iteration 9940, loss = 0.537408
I0614 12:13:25.147778 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 12:13:25.147786 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.28507 (* 1 = 0.28507 loss)
I0614 12:13:25.147790 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.290904 (* 1 = 0.290904 loss)
I0614 12:13:25.147794 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00816188 (* 1 = 0.00816188 loss)
I0614 12:13:25.147799 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0603585 (* 1 = 0.0603585 loss)
I0614 12:13:25.147804 15760 sgd_solver.cpp:106] Iteration 9940, lr = 0.0002
I0614 12:15:11.942152 15760 solver.cpp:228] Iteration 9960, loss = 0.646626
I0614 12:15:11.942175 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 12:15:11.942183 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.163703 (* 1 = 0.163703 loss)
I0614 12:15:11.942189 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.343054 (* 1 = 0.343054 loss)
I0614 12:15:11.942195 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00182945 (* 1 = 0.00182945 loss)
I0614 12:15:11.942201 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0294166 (* 1 = 0.0294166 loss)
I0614 12:15:11.942209 15760 sgd_solver.cpp:106] Iteration 9960, lr = 0.0002
I0614 12:16:58.308107 15760 solver.cpp:228] Iteration 9980, loss = 0.763714
I0614 12:16:58.308131 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 12:16:58.308138 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0798824 (* 1 = 0.0798824 loss)
I0614 12:16:58.308142 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0935545 (* 1 = 0.0935545 loss)
I0614 12:16:58.308146 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291524 (* 1 = 0.00291524 loss)
I0614 12:16:58.308149 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103481 (* 1 = 0.0103481 loss)
I0614 12:16:58.308153 15760 sgd_solver.cpp:106] Iteration 9980, lr = 0.0002
speed: 5.330s / iter
I0614 12:18:39.877753 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_10000.caffemodel
I0614 12:18:45.663286 15760 solver.cpp:228] Iteration 10000, loss = 0.559585
I0614 12:18:45.663311 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 12:18:45.663317 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0895963 (* 1 = 0.0895963 loss)
I0614 12:18:45.663321 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0988934 (* 1 = 0.0988934 loss)
I0614 12:18:45.663324 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00462501 (* 1 = 0.00462501 loss)
I0614 12:18:45.663328 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028133 (* 1 = 0.028133 loss)
I0614 12:18:45.663332 15760 sgd_solver.cpp:106] Iteration 10000, lr = 0.0002
I0614 12:20:31.897493 15760 solver.cpp:228] Iteration 10020, loss = 0.6762
I0614 12:20:31.897518 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 12:20:31.897526 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.368977 (* 1 = 0.368977 loss)
I0614 12:20:31.897529 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.356047 (* 1 = 0.356047 loss)
I0614 12:20:31.897534 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00849555 (* 1 = 0.00849555 loss)
I0614 12:20:31.897538 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0596523 (* 1 = 0.0596523 loss)
I0614 12:20:31.897543 15760 sgd_solver.cpp:106] Iteration 10020, lr = 0.0002
I0614 12:22:18.423900 15760 solver.cpp:228] Iteration 10040, loss = 0.738571
I0614 12:22:18.423928 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 12:22:18.423936 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113895 (* 1 = 0.113895 loss)
I0614 12:22:18.423941 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0861868 (* 1 = 0.0861868 loss)
I0614 12:22:18.423946 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266642 (* 1 = 0.00266642 loss)
I0614 12:22:18.423950 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00758706 (* 1 = 0.00758706 loss)
I0614 12:22:18.423957 15760 sgd_solver.cpp:106] Iteration 10040, lr = 0.0002
I0614 12:24:04.645427 15760 solver.cpp:228] Iteration 10060, loss = 0.97102
I0614 12:24:04.645459 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 12:24:04.645468 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.120585 (* 1 = 0.120585 loss)
I0614 12:24:04.645473 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.193274 (* 1 = 0.193274 loss)
I0614 12:24:04.645478 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000469691 (* 1 = 0.000469691 loss)
I0614 12:24:04.645480 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00264401 (* 1 = 0.00264401 loss)
I0614 12:24:04.645486 15760 sgd_solver.cpp:106] Iteration 10060, lr = 0.0002
I0614 12:25:51.104782 15760 solver.cpp:228] Iteration 10080, loss = 0.695385
I0614 12:25:51.104807 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 12:25:51.104815 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112915 (* 1 = 0.112915 loss)
I0614 12:25:51.104820 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.194805 (* 1 = 0.194805 loss)
I0614 12:25:51.104823 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125083 (* 1 = 0.00125083 loss)
I0614 12:25:51.104827 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261277 (* 1 = 0.0261277 loss)
I0614 12:25:51.104832 15760 sgd_solver.cpp:106] Iteration 10080, lr = 0.0002
I0614 12:27:37.638756 15760 solver.cpp:228] Iteration 10100, loss = 0.907558
I0614 12:27:37.638779 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.515625
I0614 12:27:37.638787 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.1107 (* 1 = 1.1107 loss)
I0614 12:27:37.638793 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.837641 (* 1 = 0.837641 loss)
I0614 12:27:37.638799 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188682 (* 1 = 0.0188682 loss)
I0614 12:27:37.638805 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.234249 (* 1 = 0.234249 loss)
I0614 12:27:37.638811 15760 sgd_solver.cpp:106] Iteration 10100, lr = 0.0002
I0614 12:29:23.996817 15760 solver.cpp:228] Iteration 10120, loss = 0.931228
I0614 12:29:23.996841 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 12:29:23.996850 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.309052 (* 1 = 0.309052 loss)
I0614 12:29:23.996853 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.274109 (* 1 = 0.274109 loss)
I0614 12:29:23.996857 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102352 (* 1 = 0.0102352 loss)
I0614 12:29:23.996861 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0474293 (* 1 = 0.0474293 loss)
I0614 12:29:23.996866 15760 sgd_solver.cpp:106] Iteration 10120, lr = 0.0002
I0614 12:31:10.426364 15760 solver.cpp:228] Iteration 10140, loss = 0.619344
I0614 12:31:10.426390 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 12:31:10.426398 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.160417 (* 1 = 0.160417 loss)
I0614 12:31:10.426403 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.151483 (* 1 = 0.151483 loss)
I0614 12:31:10.426406 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000547856 (* 1 = 0.000547856 loss)
I0614 12:31:10.426410 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370402 (* 1 = 0.0370402 loss)
I0614 12:31:10.426415 15760 sgd_solver.cpp:106] Iteration 10140, lr = 0.0002
I0614 12:32:56.743728 15760 solver.cpp:228] Iteration 10160, loss = 0.655939
I0614 12:32:56.743753 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 12:32:56.743760 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.375873 (* 1 = 0.375873 loss)
I0614 12:32:56.743764 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.480829 (* 1 = 0.480829 loss)
I0614 12:32:56.743767 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00986019 (* 1 = 0.00986019 loss)
I0614 12:32:56.743772 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115554 (* 1 = 0.115554 loss)
I0614 12:32:56.743777 15760 sgd_solver.cpp:106] Iteration 10160, lr = 0.0002
I0614 12:34:43.172950 15760 solver.cpp:228] Iteration 10180, loss = 0.575578
I0614 12:34:43.172979 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 12:34:43.172986 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.200414 (* 1 = 0.200414 loss)
I0614 12:34:43.172989 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.338146 (* 1 = 0.338146 loss)
I0614 12:34:43.172993 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0018515 (* 1 = 0.0018515 loss)
I0614 12:34:43.172996 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0700907 (* 1 = 0.0700907 loss)
I0614 12:34:43.173002 15760 sgd_solver.cpp:106] Iteration 10180, lr = 0.0002
speed: 5.330s / iter
I0614 12:36:29.635174 15760 solver.cpp:228] Iteration 10200, loss = 0.518424
I0614 12:36:29.635200 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 12:36:29.635207 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117332 (* 1 = 0.117332 loss)
I0614 12:36:29.635211 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.214308 (* 1 = 0.214308 loss)
I0614 12:36:29.635215 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0086737 (* 1 = 0.0086737 loss)
I0614 12:36:29.635219 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0423619 (* 1 = 0.0423619 loss)
I0614 12:36:29.635224 15760 sgd_solver.cpp:106] Iteration 10200, lr = 0.0002
I0614 12:38:16.013701 15760 solver.cpp:228] Iteration 10220, loss = 0.532049
I0614 12:38:16.013726 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 12:38:16.013734 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0629556 (* 1 = 0.0629556 loss)
I0614 12:38:16.013738 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.26351 (* 1 = 0.26351 loss)
I0614 12:38:16.013742 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00381982 (* 1 = 0.00381982 loss)
I0614 12:38:16.013746 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491302 (* 1 = 0.0491302 loss)
I0614 12:38:16.013752 15760 sgd_solver.cpp:106] Iteration 10220, lr = 0.0002
I0614 12:40:02.576721 15760 solver.cpp:228] Iteration 10240, loss = 0.845474
I0614 12:40:02.576745 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 12:40:02.576751 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.159039 (* 1 = 0.159039 loss)
I0614 12:40:02.576756 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234551 (* 1 = 0.234551 loss)
I0614 12:40:02.576759 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114015 (* 1 = 0.00114015 loss)
I0614 12:40:02.576762 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514161 (* 1 = 0.0514161 loss)
I0614 12:40:02.576767 15760 sgd_solver.cpp:106] Iteration 10240, lr = 0.0002
I0614 12:41:48.891198 15760 solver.cpp:228] Iteration 10260, loss = 0.56889
I0614 12:41:48.891223 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 12:41:48.891230 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.046198 (* 1 = 0.046198 loss)
I0614 12:41:48.891234 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.187509 (* 1 = 0.187509 loss)
I0614 12:41:48.891238 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00427233 (* 1 = 0.00427233 loss)
I0614 12:41:48.891242 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0382083 (* 1 = 0.0382083 loss)
I0614 12:41:48.891247 15760 sgd_solver.cpp:106] Iteration 10260, lr = 0.0002
I0614 12:43:35.403388 15760 solver.cpp:228] Iteration 10280, loss = 0.611051
I0614 12:43:35.403419 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 12:43:35.403426 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.125626 (* 1 = 0.125626 loss)
I0614 12:43:35.403431 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119106 (* 1 = 0.119106 loss)
I0614 12:43:35.403435 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154071 (* 1 = 0.00154071 loss)
I0614 12:43:35.403439 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134315 (* 1 = 0.0134315 loss)
I0614 12:43:35.403445 15760 sgd_solver.cpp:106] Iteration 10280, lr = 0.0002
I0614 12:45:21.707589 15760 solver.cpp:228] Iteration 10300, loss = 0.681994
I0614 12:45:21.707613 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 12:45:21.707620 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.726035 (* 1 = 0.726035 loss)
I0614 12:45:21.707624 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.783666 (* 1 = 0.783666 loss)
I0614 12:45:21.707628 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00689404 (* 1 = 0.00689404 loss)
I0614 12:45:21.707631 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0937158 (* 1 = 0.0937158 loss)
I0614 12:45:21.707636 15760 sgd_solver.cpp:106] Iteration 10300, lr = 0.0002
I0614 12:47:08.087087 15760 solver.cpp:228] Iteration 10320, loss = 0.462293
I0614 12:47:08.087110 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 12:47:08.087117 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.37147 (* 1 = 0.37147 loss)
I0614 12:47:08.087121 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.1395 (* 1 = 0.1395 loss)
I0614 12:47:08.087126 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00269992 (* 1 = 0.00269992 loss)
I0614 12:47:08.087128 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0713634 (* 1 = 0.0713634 loss)
I0614 12:47:08.087133 15760 sgd_solver.cpp:106] Iteration 10320, lr = 0.0002
I0614 12:48:54.284369 15760 solver.cpp:228] Iteration 10340, loss = 0.352462
I0614 12:48:54.284395 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 12:48:54.284404 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347369 (* 1 = 0.0347369 loss)
I0614 12:48:54.284407 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.131261 (* 1 = 0.131261 loss)
I0614 12:48:54.284411 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242912 (* 1 = 0.0242912 loss)
I0614 12:48:54.284415 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333703 (* 1 = 0.0333703 loss)
I0614 12:48:54.284420 15760 sgd_solver.cpp:106] Iteration 10340, lr = 0.0002
I0614 12:50:40.749683 15760 solver.cpp:228] Iteration 10360, loss = 0.845987
I0614 12:50:40.749709 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.4375
I0614 12:50:40.749717 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.23466 (* 1 = 1.23466 loss)
I0614 12:50:40.749722 15760 solver.cpp:244]     Train net output #2: loss_cls = 1.10635 (* 1 = 1.10635 loss)
I0614 12:50:40.749724 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0702408 (* 1 = 0.0702408 loss)
I0614 12:50:40.749729 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.669524 (* 1 = 0.669524 loss)
I0614 12:50:40.749735 15760 sgd_solver.cpp:106] Iteration 10360, lr = 0.0002
I0614 12:52:26.969655 15760 solver.cpp:228] Iteration 10380, loss = 0.346828
I0614 12:52:26.969681 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 12:52:26.969689 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.110789 (* 1 = 0.110789 loss)
I0614 12:52:26.969696 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.142262 (* 1 = 0.142262 loss)
I0614 12:52:26.969702 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100431 (* 1 = 0.0100431 loss)
I0614 12:52:26.969707 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161708 (* 1 = 0.0161708 loss)
I0614 12:52:26.969715 15760 sgd_solver.cpp:106] Iteration 10380, lr = 0.0002
speed: 5.329s / iter
I0614 12:54:13.167129 15760 solver.cpp:228] Iteration 10400, loss = 0.369801
I0614 12:54:13.167155 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 12:54:13.167163 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.138702 (* 1 = 0.138702 loss)
I0614 12:54:13.167168 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0682008 (* 1 = 0.0682008 loss)
I0614 12:54:13.167172 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118514 (* 1 = 0.00118514 loss)
I0614 12:54:13.167176 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178005 (* 1 = 0.0178005 loss)
I0614 12:54:13.167181 15760 sgd_solver.cpp:106] Iteration 10400, lr = 0.0002
I0614 12:55:59.614797 15760 solver.cpp:228] Iteration 10420, loss = 0.395259
I0614 12:55:59.614820 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 12:55:59.614827 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540367 (* 1 = 0.0540367 loss)
I0614 12:55:59.614831 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.274688 (* 1 = 0.274688 loss)
I0614 12:55:59.614835 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00864851 (* 1 = 0.00864851 loss)
I0614 12:55:59.614838 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439525 (* 1 = 0.0439525 loss)
I0614 12:55:59.614843 15760 sgd_solver.cpp:106] Iteration 10420, lr = 0.0002
I0614 12:57:45.761535 15760 solver.cpp:228] Iteration 10440, loss = 0.461804
I0614 12:57:45.761560 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 12:57:45.761569 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.123376 (* 1 = 0.123376 loss)
I0614 12:57:45.761572 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.184155 (* 1 = 0.184155 loss)
I0614 12:57:45.761576 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000244962 (* 1 = 0.000244962 loss)
I0614 12:57:45.761580 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138201 (* 1 = 0.0138201 loss)
I0614 12:57:45.761585 15760 sgd_solver.cpp:106] Iteration 10440, lr = 0.0002
I0614 12:59:32.184825 15760 solver.cpp:228] Iteration 10460, loss = 0.624244
I0614 12:59:32.184850 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 12:59:32.184859 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.133253 (* 1 = 0.133253 loss)
I0614 12:59:32.184862 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134197 (* 1 = 0.134197 loss)
I0614 12:59:32.184866 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239588 (* 1 = 0.00239588 loss)
I0614 12:59:32.184870 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419353 (* 1 = 0.0419353 loss)
I0614 12:59:32.184875 15760 sgd_solver.cpp:106] Iteration 10460, lr = 0.0002
I0614 13:01:18.497025 15760 solver.cpp:228] Iteration 10480, loss = 0.941555
I0614 13:01:18.497050 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 13:01:18.497056 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.338349 (* 1 = 0.338349 loss)
I0614 13:01:18.497061 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.429636 (* 1 = 0.429636 loss)
I0614 13:01:18.497064 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000680247 (* 1 = 0.000680247 loss)
I0614 13:01:18.497067 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.067608 (* 1 = 0.067608 loss)
I0614 13:01:18.497072 15760 sgd_solver.cpp:106] Iteration 10480, lr = 0.0002
I0614 13:03:04.824195 15760 solver.cpp:228] Iteration 10500, loss = 0.951437
I0614 13:03:04.824221 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 13:03:04.824230 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.29245 (* 1 = 0.29245 loss)
I0614 13:03:04.824236 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.294987 (* 1 = 0.294987 loss)
I0614 13:03:04.824242 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000478999 (* 1 = 0.000478999 loss)
I0614 13:03:04.824249 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201709 (* 1 = 0.0201709 loss)
I0614 13:03:04.824256 15760 sgd_solver.cpp:106] Iteration 10500, lr = 0.0002
I0614 13:04:51.440639 15760 solver.cpp:228] Iteration 10520, loss = 0.626958
I0614 13:04:51.440665 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 13:04:51.440675 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.155695 (* 1 = 0.155695 loss)
I0614 13:04:51.440680 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.127656 (* 1 = 0.127656 loss)
I0614 13:04:51.440686 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00478758 (* 1 = 0.00478758 loss)
I0614 13:04:51.440693 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405906 (* 1 = 0.0405906 loss)
I0614 13:04:51.440702 15760 sgd_solver.cpp:106] Iteration 10520, lr = 0.0002
I0614 13:06:37.821732 15760 solver.cpp:228] Iteration 10540, loss = 0.722434
I0614 13:06:37.821758 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 13:06:37.821768 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0955004 (* 1 = 0.0955004 loss)
I0614 13:06:37.821774 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.22896 (* 1 = 0.22896 loss)
I0614 13:06:37.821779 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000611814 (* 1 = 0.000611814 loss)
I0614 13:06:37.821785 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00851058 (* 1 = 0.00851058 loss)
I0614 13:06:37.821791 15760 sgd_solver.cpp:106] Iteration 10540, lr = 0.0002
I0614 13:08:24.258224 15760 solver.cpp:228] Iteration 10560, loss = 0.700552
I0614 13:08:24.258249 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 13:08:24.258255 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.339376 (* 1 = 0.339376 loss)
I0614 13:08:24.258260 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321089 (* 1 = 0.321089 loss)
I0614 13:08:24.258263 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127523 (* 1 = 0.0127523 loss)
I0614 13:08:24.258266 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157777 (* 1 = 0.157777 loss)
I0614 13:08:24.258271 15760 sgd_solver.cpp:106] Iteration 10560, lr = 0.0002
I0614 13:10:10.510602 15760 solver.cpp:228] Iteration 10580, loss = 0.67481
I0614 13:10:10.510628 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 13:10:10.510637 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.350785 (* 1 = 0.350785 loss)
I0614 13:10:10.510640 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.452693 (* 1 = 0.452693 loss)
I0614 13:10:10.510644 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263011 (* 1 = 0.0263011 loss)
I0614 13:10:10.510648 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108811 (* 1 = 0.108811 loss)
I0614 13:10:10.510653 15760 sgd_solver.cpp:106] Iteration 10580, lr = 0.0002
speed: 5.329s / iter
I0614 13:11:57.004767 15760 solver.cpp:228] Iteration 10600, loss = 0.758769
I0614 13:11:57.004792 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 13:11:57.004799 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.275999 (* 1 = 0.275999 loss)
I0614 13:11:57.004803 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.293735 (* 1 = 0.293735 loss)
I0614 13:11:57.004807 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121646 (* 1 = 0.00121646 loss)
I0614 13:11:57.004812 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228819 (* 1 = 0.0228819 loss)
I0614 13:11:57.004817 15760 sgd_solver.cpp:106] Iteration 10600, lr = 0.0002
I0614 13:13:43.490839 15760 solver.cpp:228] Iteration 10620, loss = 0.488326
I0614 13:13:43.490864 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 13:13:43.490872 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0426958 (* 1 = 0.0426958 loss)
I0614 13:13:43.490878 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.168798 (* 1 = 0.168798 loss)
I0614 13:13:43.490885 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120776 (* 1 = 0.00120776 loss)
I0614 13:13:43.490890 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276263 (* 1 = 0.0276263 loss)
I0614 13:13:43.490896 15760 sgd_solver.cpp:106] Iteration 10620, lr = 0.0002
I0614 13:15:29.884105 15760 solver.cpp:228] Iteration 10640, loss = 0.58346
I0614 13:15:29.884131 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 13:15:29.884140 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0740119 (* 1 = 0.0740119 loss)
I0614 13:15:29.884146 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116206 (* 1 = 0.116206 loss)
I0614 13:15:29.884152 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000367063 (* 1 = 0.000367063 loss)
I0614 13:15:29.884157 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123016 (* 1 = 0.0123016 loss)
I0614 13:15:29.884163 15760 sgd_solver.cpp:106] Iteration 10640, lr = 0.0002
I0614 13:17:16.226905 15760 solver.cpp:228] Iteration 10660, loss = 0.694998
I0614 13:17:16.226930 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 13:17:16.226938 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0721063 (* 1 = 0.0721063 loss)
I0614 13:17:16.226943 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117788 (* 1 = 0.117788 loss)
I0614 13:17:16.226948 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000707004 (* 1 = 0.000707004 loss)
I0614 13:17:16.226950 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148627 (* 1 = 0.0148627 loss)
I0614 13:17:16.226955 15760 sgd_solver.cpp:106] Iteration 10660, lr = 0.0002
I0614 13:19:02.770310 15760 solver.cpp:228] Iteration 10680, loss = 0.863304
I0614 13:19:02.770334 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0614 13:19:02.770341 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.211701 (* 1 = 0.211701 loss)
I0614 13:19:02.770345 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.641517 (* 1 = 0.641517 loss)
I0614 13:19:02.770349 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0950353 (* 1 = 0.0950353 loss)
I0614 13:19:02.770352 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.181412 (* 1 = 0.181412 loss)
I0614 13:19:02.770357 15760 sgd_solver.cpp:106] Iteration 10680, lr = 0.0002
I0614 13:20:48.971819 15760 solver.cpp:228] Iteration 10700, loss = 0.644885
I0614 13:20:48.971843 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 13:20:48.971850 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.107225 (* 1 = 0.107225 loss)
I0614 13:20:48.971854 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116203 (* 1 = 0.116203 loss)
I0614 13:20:48.971858 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000524558 (* 1 = 0.000524558 loss)
I0614 13:20:48.971860 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166603 (* 1 = 0.0166603 loss)
I0614 13:20:48.971866 15760 sgd_solver.cpp:106] Iteration 10700, lr = 0.0002
I0614 13:22:35.485884 15760 solver.cpp:228] Iteration 10720, loss = 0.398098
I0614 13:22:35.485908 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 13:22:35.485916 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113391 (* 1 = 0.113391 loss)
I0614 13:22:35.485921 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.156536 (* 1 = 0.156536 loss)
I0614 13:22:35.485925 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00055125 (* 1 = 0.00055125 loss)
I0614 13:22:35.485929 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140553 (* 1 = 0.0140553 loss)
I0614 13:22:35.485934 15760 sgd_solver.cpp:106] Iteration 10720, lr = 0.0002
I0614 13:24:21.851725 15760 solver.cpp:228] Iteration 10740, loss = 0.560887
I0614 13:24:21.851753 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 13:24:21.851763 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.188711 (* 1 = 0.188711 loss)
I0614 13:24:21.851769 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.29303 (* 1 = 0.29303 loss)
I0614 13:24:21.851775 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000688231 (* 1 = 0.000688231 loss)
I0614 13:24:21.851783 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191163 (* 1 = 0.0191163 loss)
I0614 13:24:21.851788 15760 sgd_solver.cpp:106] Iteration 10740, lr = 0.0002
I0614 13:26:08.246935 15760 solver.cpp:228] Iteration 10760, loss = 0.603419
I0614 13:26:08.246960 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 13:26:08.246968 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.232156 (* 1 = 0.232156 loss)
I0614 13:26:08.246970 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.244906 (* 1 = 0.244906 loss)
I0614 13:26:08.246974 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184324 (* 1 = 0.00184324 loss)
I0614 13:26:08.246978 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683576 (* 1 = 0.0683576 loss)
I0614 13:26:08.246984 15760 sgd_solver.cpp:106] Iteration 10760, lr = 0.0002
I0614 13:27:54.614761 15760 solver.cpp:228] Iteration 10780, loss = 0.694012
I0614 13:27:54.614784 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 13:27:54.614791 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0763831 (* 1 = 0.0763831 loss)
I0614 13:27:54.614797 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0884823 (* 1 = 0.0884823 loss)
I0614 13:27:54.614804 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000305225 (* 1 = 0.000305225 loss)
I0614 13:27:54.614807 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286116 (* 1 = 0.0286116 loss)
I0614 13:27:54.614816 15760 sgd_solver.cpp:106] Iteration 10780, lr = 0.0002
speed: 5.329s / iter
I0614 13:29:41.156893 15760 solver.cpp:228] Iteration 10800, loss = 0.612983
I0614 13:29:41.156919 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 13:29:41.156925 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.373835 (* 1 = 0.373835 loss)
I0614 13:29:41.156929 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.302803 (* 1 = 0.302803 loss)
I0614 13:29:41.156934 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00331102 (* 1 = 0.00331102 loss)
I0614 13:29:41.156937 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0406947 (* 1 = 0.0406947 loss)
I0614 13:29:41.156947 15760 sgd_solver.cpp:106] Iteration 10800, lr = 0.0002
I0614 13:31:27.580046 15760 solver.cpp:228] Iteration 10820, loss = 0.506473
I0614 13:31:27.580070 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 13:31:27.580076 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445811 (* 1 = 0.0445811 loss)
I0614 13:31:27.580080 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0634326 (* 1 = 0.0634326 loss)
I0614 13:31:27.580083 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265045 (* 1 = 0.00265045 loss)
I0614 13:31:27.580087 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123961 (* 1 = 0.0123961 loss)
I0614 13:31:27.580091 15760 sgd_solver.cpp:106] Iteration 10820, lr = 0.0002
I0614 13:33:13.712983 15760 solver.cpp:228] Iteration 10840, loss = 0.637352
I0614 13:33:13.713008 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 13:33:13.713016 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0730629 (* 1 = 0.0730629 loss)
I0614 13:33:13.713019 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117927 (* 1 = 0.117927 loss)
I0614 13:33:13.713023 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202818 (* 1 = 0.00202818 loss)
I0614 13:33:13.713027 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135471 (* 1 = 0.0135471 loss)
I0614 13:33:13.713032 15760 sgd_solver.cpp:106] Iteration 10840, lr = 0.0002
I0614 13:35:00.273660 15760 solver.cpp:228] Iteration 10860, loss = 0.54426
I0614 13:35:00.273684 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 13:35:00.273691 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117875 (* 1 = 0.117875 loss)
I0614 13:35:00.273694 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.124312 (* 1 = 0.124312 loss)
I0614 13:35:00.273699 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000346054 (* 1 = 0.000346054 loss)
I0614 13:35:00.273701 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149992 (* 1 = 0.0149992 loss)
I0614 13:35:00.273706 15760 sgd_solver.cpp:106] Iteration 10860, lr = 0.0002
I0614 13:36:46.588920 15760 solver.cpp:228] Iteration 10880, loss = 0.929244
I0614 13:36:46.588946 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 13:36:46.588953 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.277509 (* 1 = 0.277509 loss)
I0614 13:36:46.588958 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.383157 (* 1 = 0.383157 loss)
I0614 13:36:46.588961 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00967145 (* 1 = 0.00967145 loss)
I0614 13:36:46.588964 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288698 (* 1 = 0.0288698 loss)
I0614 13:36:46.588969 15760 sgd_solver.cpp:106] Iteration 10880, lr = 0.0002
I0614 13:38:33.163931 15760 solver.cpp:228] Iteration 10900, loss = 0.520202
I0614 13:38:33.163954 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 13:38:33.163961 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.382794 (* 1 = 0.382794 loss)
I0614 13:38:33.163965 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.449943 (* 1 = 0.449943 loss)
I0614 13:38:33.163969 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956956 (* 1 = 0.00956956 loss)
I0614 13:38:33.163972 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0851324 (* 1 = 0.0851324 loss)
I0614 13:38:33.163977 15760 sgd_solver.cpp:106] Iteration 10900, lr = 0.0002
I0614 13:40:19.487118 15760 solver.cpp:228] Iteration 10920, loss = 0.480172
I0614 13:40:19.487144 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 13:40:19.487151 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.102288 (* 1 = 0.102288 loss)
I0614 13:40:19.487155 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.144842 (* 1 = 0.144842 loss)
I0614 13:40:19.487159 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132424 (* 1 = 0.00132424 loss)
I0614 13:40:19.487164 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103114 (* 1 = 0.0103114 loss)
I0614 13:40:19.487169 15760 sgd_solver.cpp:106] Iteration 10920, lr = 0.0002
I0614 13:42:06.159521 15760 solver.cpp:228] Iteration 10940, loss = 0.684939
I0614 13:42:06.159545 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 13:42:06.159552 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15178 (* 1 = 0.15178 loss)
I0614 13:42:06.159556 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.140906 (* 1 = 0.140906 loss)
I0614 13:42:06.159560 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010101 (* 1 = 0.0010101 loss)
I0614 13:42:06.159564 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00603972 (* 1 = 0.00603972 loss)
I0614 13:42:06.159569 15760 sgd_solver.cpp:106] Iteration 10940, lr = 0.0002
I0614 13:43:53.052742 15760 solver.cpp:228] Iteration 10960, loss = 1.1072
I0614 13:43:53.052767 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 13:43:53.052773 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.403045 (* 1 = 0.403045 loss)
I0614 13:43:53.052778 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.502024 (* 1 = 0.502024 loss)
I0614 13:43:53.052781 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0769499 (* 1 = 0.0769499 loss)
I0614 13:43:53.052784 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.413867 (* 1 = 0.413867 loss)
I0614 13:43:53.052788 15760 sgd_solver.cpp:106] Iteration 10960, lr = 0.0002
I0614 13:45:39.470095 15760 solver.cpp:228] Iteration 10980, loss = 0.734385
I0614 13:45:39.470119 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 13:45:39.470129 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.140093 (* 1 = 0.140093 loss)
I0614 13:45:39.470134 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.093688 (* 1 = 0.093688 loss)
I0614 13:45:39.470139 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105001 (* 1 = 0.0105001 loss)
I0614 13:45:39.470145 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00681637 (* 1 = 0.00681637 loss)
I0614 13:45:39.470151 15760 sgd_solver.cpp:106] Iteration 10980, lr = 0.0002
speed: 5.329s / iter
I0614 13:47:25.854866 15760 solver.cpp:228] Iteration 11000, loss = 0.52375
I0614 13:47:25.854890 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0614 13:47:25.854898 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.609075 (* 1 = 0.609075 loss)
I0614 13:47:25.854902 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.596607 (* 1 = 0.596607 loss)
I0614 13:47:25.854907 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00461488 (* 1 = 0.00461488 loss)
I0614 13:47:25.854910 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103488 (* 1 = 0.103488 loss)
I0614 13:47:25.854915 15760 sgd_solver.cpp:106] Iteration 11000, lr = 0.0002
I0614 13:49:12.195292 15760 solver.cpp:228] Iteration 11020, loss = 0.742104
I0614 13:49:12.195315 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 13:49:12.195323 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.174655 (* 1 = 0.174655 loss)
I0614 13:49:12.195327 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.528851 (* 1 = 0.528851 loss)
I0614 13:49:12.195331 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0726746 (* 1 = 0.0726746 loss)
I0614 13:49:12.195334 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.136062 (* 1 = 0.136062 loss)
I0614 13:49:12.195339 15760 sgd_solver.cpp:106] Iteration 11020, lr = 0.0002
I0614 13:50:58.671284 15760 solver.cpp:228] Iteration 11040, loss = 0.557483
I0614 13:50:58.671310 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 13:50:58.671319 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0900249 (* 1 = 0.0900249 loss)
I0614 13:50:58.671322 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0652441 (* 1 = 0.0652441 loss)
I0614 13:50:58.671327 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000964326 (* 1 = 0.000964326 loss)
I0614 13:50:58.671330 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132437 (* 1 = 0.0132437 loss)
I0614 13:50:58.671336 15760 sgd_solver.cpp:106] Iteration 11040, lr = 0.0002
I0614 13:52:45.143921 15760 solver.cpp:228] Iteration 11060, loss = 0.707189
I0614 13:52:45.143946 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 13:52:45.143954 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.329649 (* 1 = 0.329649 loss)
I0614 13:52:45.143959 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.37783 (* 1 = 0.37783 loss)
I0614 13:52:45.143962 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185148 (* 1 = 0.0185148 loss)
I0614 13:52:45.143965 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0541881 (* 1 = 0.0541881 loss)
I0614 13:52:45.143971 15760 sgd_solver.cpp:106] Iteration 11060, lr = 0.0002
I0614 13:54:31.486479 15760 solver.cpp:228] Iteration 11080, loss = 0.599813
I0614 13:54:31.486505 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 13:54:31.486511 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.147171 (* 1 = 0.147171 loss)
I0614 13:54:31.486516 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.201109 (* 1 = 0.201109 loss)
I0614 13:54:31.486519 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019622 (* 1 = 0.0019622 loss)
I0614 13:54:31.486523 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0644936 (* 1 = 0.0644936 loss)
I0614 13:54:31.486528 15760 sgd_solver.cpp:106] Iteration 11080, lr = 0.0002
I0614 13:56:17.881402 15760 solver.cpp:228] Iteration 11100, loss = 0.886479
I0614 13:56:17.881435 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 13:56:17.881445 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.125058 (* 1 = 0.125058 loss)
I0614 13:56:17.881451 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159415 (* 1 = 0.159415 loss)
I0614 13:56:17.881458 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000608941 (* 1 = 0.000608941 loss)
I0614 13:56:17.881464 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00616256 (* 1 = 0.00616256 loss)
I0614 13:56:17.881471 15760 sgd_solver.cpp:106] Iteration 11100, lr = 0.0002
I0614 13:58:04.473697 15760 solver.cpp:228] Iteration 11120, loss = 0.698711
I0614 13:58:04.473722 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 13:58:04.473731 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.1139 (* 1 = 0.1139 loss)
I0614 13:58:04.473734 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20841 (* 1 = 0.20841 loss)
I0614 13:58:04.473739 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00175923 (* 1 = 0.00175923 loss)
I0614 13:58:04.473743 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247953 (* 1 = 0.0247953 loss)
I0614 13:58:04.473747 15760 sgd_solver.cpp:106] Iteration 11120, lr = 0.0002
I0614 13:59:50.864470 15760 solver.cpp:228] Iteration 11140, loss = 0.874323
I0614 13:59:50.864495 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 13:59:50.864503 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.228126 (* 1 = 0.228126 loss)
I0614 13:59:50.864507 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.347528 (* 1 = 0.347528 loss)
I0614 13:59:50.864511 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120234 (* 1 = 0.0120234 loss)
I0614 13:59:50.864516 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.17554 (* 1 = 0.17554 loss)
I0614 13:59:50.864521 15760 sgd_solver.cpp:106] Iteration 11140, lr = 0.0002
I0614 14:01:37.400491 15760 solver.cpp:228] Iteration 11160, loss = 0.703743
I0614 14:01:37.400514 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 14:01:37.400521 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109949 (* 1 = 0.109949 loss)
I0614 14:01:37.400524 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.17907 (* 1 = 0.17907 loss)
I0614 14:01:37.400528 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249346 (* 1 = 0.00249346 loss)
I0614 14:01:37.400532 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175746 (* 1 = 0.0175746 loss)
I0614 14:01:37.400537 15760 sgd_solver.cpp:106] Iteration 11160, lr = 0.0002
I0614 14:03:23.821939 15760 solver.cpp:228] Iteration 11180, loss = 0.427764
I0614 14:03:23.821964 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 14:03:23.821971 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.199123 (* 1 = 0.199123 loss)
I0614 14:03:23.821975 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.173425 (* 1 = 0.173425 loss)
I0614 14:03:23.821979 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135537 (* 1 = 0.00135537 loss)
I0614 14:03:23.821982 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126132 (* 1 = 0.0126132 loss)
I0614 14:03:23.821987 15760 sgd_solver.cpp:106] Iteration 11180, lr = 0.0002
speed: 5.329s / iter
I0614 14:05:10.295974 15760 solver.cpp:228] Iteration 11200, loss = 0.417514
I0614 14:05:10.295998 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 14:05:10.296005 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111431 (* 1 = 0.111431 loss)
I0614 14:05:10.296010 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.12074 (* 1 = 0.12074 loss)
I0614 14:05:10.296015 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171418 (* 1 = 0.0171418 loss)
I0614 14:05:10.296017 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00889949 (* 1 = 0.00889949 loss)
I0614 14:05:10.296023 15760 sgd_solver.cpp:106] Iteration 11200, lr = 0.0002
I0614 14:06:56.607962 15760 solver.cpp:228] Iteration 11220, loss = 0.718924
I0614 14:06:56.607985 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 14:06:56.607992 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.123239 (* 1 = 0.123239 loss)
I0614 14:06:56.607995 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.188377 (* 1 = 0.188377 loss)
I0614 14:06:56.608000 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102865 (* 1 = 0.00102865 loss)
I0614 14:06:56.608003 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225796 (* 1 = 0.0225796 loss)
I0614 14:06:56.608008 15760 sgd_solver.cpp:106] Iteration 11220, lr = 0.0002
I0614 14:08:43.097980 15760 solver.cpp:228] Iteration 11240, loss = 0.461809
I0614 14:08:43.098006 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 14:08:43.098012 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12141 (* 1 = 0.12141 loss)
I0614 14:08:43.098016 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.138191 (* 1 = 0.138191 loss)
I0614 14:08:43.098019 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00989413 (* 1 = 0.00989413 loss)
I0614 14:08:43.098023 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196894 (* 1 = 0.0196894 loss)
I0614 14:08:43.098028 15760 sgd_solver.cpp:106] Iteration 11240, lr = 0.0002
I0614 14:10:29.338951 15760 solver.cpp:228] Iteration 11260, loss = 0.337095
I0614 14:10:29.338976 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 14:10:29.338984 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432286 (* 1 = 0.0432286 loss)
I0614 14:10:29.338989 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0953731 (* 1 = 0.0953731 loss)
I0614 14:10:29.338992 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412639 (* 1 = 0.00412639 loss)
I0614 14:10:29.338996 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296477 (* 1 = 0.0296477 loss)
I0614 14:10:29.339002 15760 sgd_solver.cpp:106] Iteration 11260, lr = 0.0002
I0614 14:12:15.662257 15760 solver.cpp:228] Iteration 11280, loss = 0.507799
I0614 14:12:15.662283 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 14:12:15.662291 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0999218 (* 1 = 0.0999218 loss)
I0614 14:12:15.662295 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.139058 (* 1 = 0.139058 loss)
I0614 14:12:15.662299 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00847628 (* 1 = 0.00847628 loss)
I0614 14:12:15.662302 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258636 (* 1 = 0.0258636 loss)
I0614 14:12:15.662307 15760 sgd_solver.cpp:106] Iteration 11280, lr = 0.0002
I0614 14:14:01.929056 15760 solver.cpp:228] Iteration 11300, loss = 0.626055
I0614 14:14:01.929081 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 14:14:01.929090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.025711 (* 1 = 0.025711 loss)
I0614 14:14:01.929095 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.094656 (* 1 = 0.094656 loss)
I0614 14:14:01.929101 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196439 (* 1 = 0.0196439 loss)
I0614 14:14:01.929106 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314999 (* 1 = 0.0314999 loss)
I0614 14:14:01.929113 15760 sgd_solver.cpp:106] Iteration 11300, lr = 0.0002
I0614 14:15:48.192206 15760 solver.cpp:228] Iteration 11320, loss = 0.479359
I0614 14:15:48.192231 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 14:15:48.192239 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11896 (* 1 = 0.11896 loss)
I0614 14:15:48.192242 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0977865 (* 1 = 0.0977865 loss)
I0614 14:15:48.192246 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880471 (* 1 = 0.00880471 loss)
I0614 14:15:48.192250 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132865 (* 1 = 0.0132865 loss)
I0614 14:15:48.192255 15760 sgd_solver.cpp:106] Iteration 11320, lr = 0.0002
I0614 14:17:34.699259 15760 solver.cpp:228] Iteration 11340, loss = 1.07215
I0614 14:17:34.699282 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 14:17:34.699290 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.577907 (* 1 = 0.577907 loss)
I0614 14:17:34.699293 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.506985 (* 1 = 0.506985 loss)
I0614 14:17:34.699298 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00517126 (* 1 = 0.00517126 loss)
I0614 14:17:34.699302 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0697616 (* 1 = 0.0697616 loss)
I0614 14:17:34.699307 15760 sgd_solver.cpp:106] Iteration 11340, lr = 0.0002
I0614 14:19:21.019286 15760 solver.cpp:228] Iteration 11360, loss = 0.699234
I0614 14:19:21.019313 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 14:19:21.019323 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0940118 (* 1 = 0.0940118 loss)
I0614 14:19:21.019330 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.105783 (* 1 = 0.105783 loss)
I0614 14:19:21.019336 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00384313 (* 1 = 0.00384313 loss)
I0614 14:19:21.019343 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177935 (* 1 = 0.0177935 loss)
I0614 14:19:21.019351 15760 sgd_solver.cpp:106] Iteration 11360, lr = 0.0002
I0614 14:21:07.228754 15760 solver.cpp:228] Iteration 11380, loss = 0.793407
I0614 14:21:07.228776 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 14:21:07.228783 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.103538 (* 1 = 0.103538 loss)
I0614 14:21:07.228787 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120198 (* 1 = 0.120198 loss)
I0614 14:21:07.228791 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0042706 (* 1 = 0.0042706 loss)
I0614 14:21:07.228794 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202996 (* 1 = 0.0202996 loss)
I0614 14:21:07.228799 15760 sgd_solver.cpp:106] Iteration 11380, lr = 0.0002
speed: 5.329s / iter
I0614 14:22:53.634856 15760 solver.cpp:228] Iteration 11400, loss = 0.719154
I0614 14:22:53.634881 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 14:22:53.634891 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.119585 (* 1 = 0.119585 loss)
I0614 14:22:53.634897 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.153302 (* 1 = 0.153302 loss)
I0614 14:22:53.634904 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000730928 (* 1 = 0.000730928 loss)
I0614 14:22:53.634912 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174567 (* 1 = 0.0174567 loss)
I0614 14:22:53.634918 15760 sgd_solver.cpp:106] Iteration 11400, lr = 0.0002
I0614 14:24:40.158414 15760 solver.cpp:228] Iteration 11420, loss = 0.574382
I0614 14:24:40.158440 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 14:24:40.158449 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.242075 (* 1 = 0.242075 loss)
I0614 14:24:40.158454 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.260179 (* 1 = 0.260179 loss)
I0614 14:24:40.158458 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235881 (* 1 = 0.00235881 loss)
I0614 14:24:40.158463 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138763 (* 1 = 0.0138763 loss)
I0614 14:24:40.158468 15760 sgd_solver.cpp:106] Iteration 11420, lr = 0.0002
I0614 14:26:26.742668 15760 solver.cpp:228] Iteration 11440, loss = 0.422212
I0614 14:26:26.742691 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 14:26:26.742698 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0722585 (* 1 = 0.0722585 loss)
I0614 14:26:26.742702 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.124771 (* 1 = 0.124771 loss)
I0614 14:26:26.742707 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207008 (* 1 = 0.00207008 loss)
I0614 14:26:26.742709 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238715 (* 1 = 0.0238715 loss)
I0614 14:26:26.742713 15760 sgd_solver.cpp:106] Iteration 11440, lr = 0.0002
I0614 14:28:13.003213 15760 solver.cpp:228] Iteration 11460, loss = 0.278975
I0614 14:28:13.003237 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 14:28:13.003243 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0218645 (* 1 = 0.0218645 loss)
I0614 14:28:13.003247 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0957871 (* 1 = 0.0957871 loss)
I0614 14:28:13.003252 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0236576 (* 1 = 0.0236576 loss)
I0614 14:28:13.003255 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0410724 (* 1 = 0.0410724 loss)
I0614 14:28:13.003259 15760 sgd_solver.cpp:106] Iteration 11460, lr = 0.0002
I0614 14:29:59.387019 15760 solver.cpp:228] Iteration 11480, loss = 0.785635
I0614 14:29:59.387045 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0614 14:29:59.387053 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.376889 (* 1 = 0.376889 loss)
I0614 14:29:59.387058 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.517893 (* 1 = 0.517893 loss)
I0614 14:29:59.387061 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00461008 (* 1 = 0.00461008 loss)
I0614 14:29:59.387065 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106422 (* 1 = 0.106422 loss)
I0614 14:29:59.387070 15760 sgd_solver.cpp:106] Iteration 11480, lr = 0.0002
I0614 14:31:45.952822 15760 solver.cpp:228] Iteration 11500, loss = 0.678432
I0614 14:31:45.952847 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.617188
I0614 14:31:45.952853 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.440248 (* 1 = 0.440248 loss)
I0614 14:31:45.952857 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.780161 (* 1 = 0.780161 loss)
I0614 14:31:45.952862 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187965 (* 1 = 0.0187965 loss)
I0614 14:31:45.952867 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148507 (* 1 = 0.148507 loss)
I0614 14:31:45.952873 15760 sgd_solver.cpp:106] Iteration 11500, lr = 0.0002
I0614 14:33:32.389045 15760 solver.cpp:228] Iteration 11520, loss = 0.574665
I0614 14:33:32.389067 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 14:33:32.389075 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.327344 (* 1 = 0.327344 loss)
I0614 14:33:32.389078 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.300486 (* 1 = 0.300486 loss)
I0614 14:33:32.389081 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102146 (* 1 = 0.00102146 loss)
I0614 14:33:32.389086 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403784 (* 1 = 0.0403784 loss)
I0614 14:33:32.389089 15760 sgd_solver.cpp:106] Iteration 11520, lr = 0.0002
I0614 14:35:18.668314 15760 solver.cpp:228] Iteration 11540, loss = 0.623486
I0614 14:35:18.668340 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 14:35:18.668350 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.566248 (* 1 = 0.566248 loss)
I0614 14:35:18.668356 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.490467 (* 1 = 0.490467 loss)
I0614 14:35:18.668364 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301128 (* 1 = 0.00301128 loss)
I0614 14:35:18.668370 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0510805 (* 1 = 0.0510805 loss)
I0614 14:35:18.668378 15760 sgd_solver.cpp:106] Iteration 11540, lr = 0.0002
I0614 14:37:04.953480 15760 solver.cpp:228] Iteration 11560, loss = 0.449116
I0614 14:37:04.953505 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 14:37:04.953513 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206334 (* 1 = 0.0206334 loss)
I0614 14:37:04.953517 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117475 (* 1 = 0.117475 loss)
I0614 14:37:04.953521 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167439 (* 1 = 0.0167439 loss)
I0614 14:37:04.953524 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329221 (* 1 = 0.0329221 loss)
I0614 14:37:04.953531 15760 sgd_solver.cpp:106] Iteration 11560, lr = 0.0002
I0614 14:38:51.524749 15760 solver.cpp:228] Iteration 11580, loss = 0.706993
I0614 14:38:51.524775 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 14:38:51.524781 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.259582 (* 1 = 0.259582 loss)
I0614 14:38:51.524785 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.31193 (* 1 = 0.31193 loss)
I0614 14:38:51.524788 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000752527 (* 1 = 0.000752527 loss)
I0614 14:38:51.524792 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273019 (* 1 = 0.0273019 loss)
I0614 14:38:51.524797 15760 sgd_solver.cpp:106] Iteration 11580, lr = 0.0002
speed: 5.328s / iter
I0614 14:40:37.845582 15760 solver.cpp:228] Iteration 11600, loss = 0.803027
I0614 14:40:37.845605 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 14:40:37.845613 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541473 (* 1 = 0.0541473 loss)
I0614 14:40:37.845618 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119035 (* 1 = 0.119035 loss)
I0614 14:40:37.845620 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117435 (* 1 = 0.0117435 loss)
I0614 14:40:37.845623 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163958 (* 1 = 0.0163958 loss)
I0614 14:40:37.845628 15760 sgd_solver.cpp:106] Iteration 11600, lr = 0.0002
I0614 14:42:24.257475 15760 solver.cpp:228] Iteration 11620, loss = 0.343853
I0614 14:42:24.257501 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 14:42:24.257508 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.231034 (* 1 = 0.231034 loss)
I0614 14:42:24.257513 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321769 (* 1 = 0.321769 loss)
I0614 14:42:24.257516 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102208 (* 1 = 0.0102208 loss)
I0614 14:42:24.257520 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268356 (* 1 = 0.0268356 loss)
I0614 14:42:24.257525 15760 sgd_solver.cpp:106] Iteration 11620, lr = 0.0002
I0614 14:44:10.624791 15760 solver.cpp:228] Iteration 11640, loss = 0.636594
I0614 14:44:10.624814 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 14:44:10.624821 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.163624 (* 1 = 0.163624 loss)
I0614 14:44:10.624825 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171516 (* 1 = 0.171516 loss)
I0614 14:44:10.624828 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000147715 (* 1 = 0.000147715 loss)
I0614 14:44:10.624832 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194323 (* 1 = 0.0194323 loss)
I0614 14:44:10.624837 15760 sgd_solver.cpp:106] Iteration 11640, lr = 0.0002
I0614 14:45:56.910949 15760 solver.cpp:228] Iteration 11660, loss = 0.489367
I0614 14:45:56.910974 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 14:45:56.910980 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743031 (* 1 = 0.0743031 loss)
I0614 14:45:56.910986 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.240548 (* 1 = 0.240548 loss)
I0614 14:45:56.910991 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132166 (* 1 = 0.0132166 loss)
I0614 14:45:56.910996 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0635272 (* 1 = 0.0635272 loss)
I0614 14:45:56.911001 15760 sgd_solver.cpp:106] Iteration 11660, lr = 0.0002
I0614 14:47:43.393453 15760 solver.cpp:228] Iteration 11680, loss = 0.655562
I0614 14:47:43.393479 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 14:47:43.393486 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.326756 (* 1 = 0.326756 loss)
I0614 14:47:43.393491 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.410764 (* 1 = 0.410764 loss)
I0614 14:47:43.393496 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108735 (* 1 = 0.00108735 loss)
I0614 14:47:43.393499 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0594366 (* 1 = 0.0594366 loss)
I0614 14:47:43.393504 15760 sgd_solver.cpp:106] Iteration 11680, lr = 0.0002
I0614 14:49:29.838433 15760 solver.cpp:228] Iteration 11700, loss = 0.543146
I0614 14:49:29.838457 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 14:49:29.838465 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.192315 (* 1 = 0.192315 loss)
I0614 14:49:29.838469 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.144899 (* 1 = 0.144899 loss)
I0614 14:49:29.838474 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636154 (* 1 = 0.00636154 loss)
I0614 14:49:29.838476 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0559661 (* 1 = 0.0559661 loss)
I0614 14:49:29.838482 15760 sgd_solver.cpp:106] Iteration 11700, lr = 0.0002
I0614 14:51:16.196414 15760 solver.cpp:228] Iteration 11720, loss = 0.561359
I0614 14:51:16.196439 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 14:51:16.196446 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.332211 (* 1 = 0.332211 loss)
I0614 14:51:16.196452 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.307856 (* 1 = 0.307856 loss)
I0614 14:51:16.196458 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190025 (* 1 = 0.0190025 loss)
I0614 14:51:16.196463 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0798967 (* 1 = 0.0798967 loss)
I0614 14:51:16.196470 15760 sgd_solver.cpp:106] Iteration 11720, lr = 0.0002
I0614 14:53:02.457912 15760 solver.cpp:228] Iteration 11740, loss = 0.459599
I0614 14:53:02.457937 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 14:53:02.457944 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.214285 (* 1 = 0.214285 loss)
I0614 14:53:02.457948 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.336662 (* 1 = 0.336662 loss)
I0614 14:53:02.457953 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104321 (* 1 = 0.00104321 loss)
I0614 14:53:02.457957 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248781 (* 1 = 0.0248781 loss)
I0614 14:53:02.457962 15760 sgd_solver.cpp:106] Iteration 11740, lr = 0.0002
I0614 14:54:48.875160 15760 solver.cpp:228] Iteration 11760, loss = 0.322577
I0614 14:54:48.875190 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 14:54:48.875200 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.192698 (* 1 = 0.192698 loss)
I0614 14:54:48.875206 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.285027 (* 1 = 0.285027 loss)
I0614 14:54:48.875211 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0056059 (* 1 = 0.0056059 loss)
I0614 14:54:48.875218 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.056879 (* 1 = 0.056879 loss)
I0614 14:54:48.875224 15760 sgd_solver.cpp:106] Iteration 11760, lr = 0.0002
I0614 14:56:35.276123 15760 solver.cpp:228] Iteration 11780, loss = 0.621275
I0614 14:56:35.276147 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 14:56:35.276155 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.758978 (* 1 = 0.758978 loss)
I0614 14:56:35.276160 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.610802 (* 1 = 0.610802 loss)
I0614 14:56:35.276165 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00570488 (* 1 = 0.00570488 loss)
I0614 14:56:35.276167 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112616 (* 1 = 0.112616 loss)
I0614 14:56:35.276172 15760 sgd_solver.cpp:106] Iteration 11780, lr = 0.0002
speed: 5.328s / iter
I0614 14:58:21.848703 15760 solver.cpp:228] Iteration 11800, loss = 0.553064
I0614 14:58:21.848728 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0614 14:58:21.848736 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.305327 (* 1 = 0.305327 loss)
I0614 14:58:21.848739 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.551434 (* 1 = 0.551434 loss)
I0614 14:58:21.848742 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234051 (* 1 = 0.0234051 loss)
I0614 14:58:21.848747 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.538301 (* 1 = 0.538301 loss)
I0614 14:58:21.848750 15760 sgd_solver.cpp:106] Iteration 11800, lr = 0.0002
I0614 15:00:08.346683 15760 solver.cpp:228] Iteration 11820, loss = 0.585116
I0614 15:00:08.346707 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0614 15:00:08.346715 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.572917 (* 1 = 0.572917 loss)
I0614 15:00:08.346719 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.618456 (* 1 = 0.618456 loss)
I0614 15:00:08.346724 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019921 (* 1 = 0.019921 loss)
I0614 15:00:08.346726 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164879 (* 1 = 0.164879 loss)
I0614 15:00:08.346732 15760 sgd_solver.cpp:106] Iteration 11820, lr = 0.0002
I0614 15:01:54.900856 15760 solver.cpp:228] Iteration 11840, loss = 0.718978
I0614 15:01:54.900880 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 15:01:54.900887 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.121507 (* 1 = 0.121507 loss)
I0614 15:01:54.900892 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.2418 (* 1 = 0.2418 loss)
I0614 15:01:54.900897 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000754617 (* 1 = 0.000754617 loss)
I0614 15:01:54.900900 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940949 (* 1 = 0.00940949 loss)
I0614 15:01:54.900905 15760 sgd_solver.cpp:106] Iteration 11840, lr = 0.0002
I0614 15:03:41.279182 15760 solver.cpp:228] Iteration 11860, loss = 1.00097
I0614 15:03:41.279206 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 15:03:41.279212 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.554202 (* 1 = 0.554202 loss)
I0614 15:03:41.279217 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.515455 (* 1 = 0.515455 loss)
I0614 15:03:41.279219 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016846 (* 1 = 0.016846 loss)
I0614 15:03:41.279223 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.088398 (* 1 = 0.088398 loss)
I0614 15:03:41.279228 15760 sgd_solver.cpp:106] Iteration 11860, lr = 0.0002
I0614 15:05:27.574342 15760 solver.cpp:228] Iteration 11880, loss = 0.751908
I0614 15:05:27.574368 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 15:05:27.574375 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.258457 (* 1 = 0.258457 loss)
I0614 15:05:27.574379 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.274464 (* 1 = 0.274464 loss)
I0614 15:05:27.574384 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00501811 (* 1 = 0.00501811 loss)
I0614 15:05:27.574388 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0648272 (* 1 = 0.0648272 loss)
I0614 15:05:27.574393 15760 sgd_solver.cpp:106] Iteration 11880, lr = 0.0002
I0614 15:07:13.810614 15760 solver.cpp:228] Iteration 11900, loss = 0.579008
I0614 15:07:13.810639 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 15:07:13.810647 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0896753 (* 1 = 0.0896753 loss)
I0614 15:07:13.810652 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116253 (* 1 = 0.116253 loss)
I0614 15:07:13.810657 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00323187 (* 1 = 0.00323187 loss)
I0614 15:07:13.810659 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100513 (* 1 = 0.0100513 loss)
I0614 15:07:13.810664 15760 sgd_solver.cpp:106] Iteration 11900, lr = 0.0002
I0614 15:09:00.333169 15760 solver.cpp:228] Iteration 11920, loss = 0.550514
I0614 15:09:00.333195 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 15:09:00.333202 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.143804 (* 1 = 0.143804 loss)
I0614 15:09:00.333206 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.137845 (* 1 = 0.137845 loss)
I0614 15:09:00.333210 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205759 (* 1 = 0.00205759 loss)
I0614 15:09:00.333214 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134421 (* 1 = 0.0134421 loss)
I0614 15:09:00.333220 15760 sgd_solver.cpp:106] Iteration 11920, lr = 0.0002
I0614 15:10:47.085933 15760 solver.cpp:228] Iteration 11940, loss = 0.494231
I0614 15:10:47.085960 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 15:10:47.085968 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.257241 (* 1 = 0.257241 loss)
I0614 15:10:47.085971 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.293159 (* 1 = 0.293159 loss)
I0614 15:10:47.085975 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0368709 (* 1 = 0.0368709 loss)
I0614 15:10:47.085978 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.221537 (* 1 = 0.221537 loss)
I0614 15:10:47.085984 15760 sgd_solver.cpp:106] Iteration 11940, lr = 0.0002
I0614 15:12:33.796994 15760 solver.cpp:228] Iteration 11960, loss = 0.759154
I0614 15:12:33.797019 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.625
I0614 15:12:33.797025 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.04498 (* 1 = 1.04498 loss)
I0614 15:12:33.797029 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.829989 (* 1 = 0.829989 loss)
I0614 15:12:33.797034 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00606868 (* 1 = 0.00606868 loss)
I0614 15:12:33.797036 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.220363 (* 1 = 0.220363 loss)
I0614 15:12:33.797041 15760 sgd_solver.cpp:106] Iteration 11960, lr = 0.0002
I0614 15:14:20.898766 15760 solver.cpp:228] Iteration 11980, loss = 0.396897
I0614 15:14:20.898788 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 15:14:20.898797 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.2135 (* 1 = 0.2135 loss)
I0614 15:14:20.898802 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.257942 (* 1 = 0.257942 loss)
I0614 15:14:20.898808 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165131 (* 1 = 0.0165131 loss)
I0614 15:14:20.898813 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036116 (* 1 = 0.036116 loss)
I0614 15:14:20.898819 15760 sgd_solver.cpp:106] Iteration 11980, lr = 0.0002
speed: 5.328s / iter
I0614 15:16:07.242954 15760 solver.cpp:228] Iteration 12000, loss = 0.508603
I0614 15:16:07.242980 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 15:16:07.242987 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.176908 (* 1 = 0.176908 loss)
I0614 15:16:07.242991 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.300928 (* 1 = 0.300928 loss)
I0614 15:16:07.242995 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00638292 (* 1 = 0.00638292 loss)
I0614 15:16:07.243000 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0456081 (* 1 = 0.0456081 loss)
I0614 15:16:07.243005 15760 sgd_solver.cpp:106] Iteration 12000, lr = 0.0002
I0614 15:17:53.920202 15760 solver.cpp:228] Iteration 12020, loss = 0.475096
I0614 15:17:53.920224 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 15:17:53.920233 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.061464 (* 1 = 0.061464 loss)
I0614 15:17:53.920236 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.154619 (* 1 = 0.154619 loss)
I0614 15:17:53.920240 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00526258 (* 1 = 0.00526258 loss)
I0614 15:17:53.920244 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00894441 (* 1 = 0.00894441 loss)
I0614 15:17:53.920249 15760 sgd_solver.cpp:106] Iteration 12020, lr = 0.0002
I0614 15:19:40.758198 15760 solver.cpp:228] Iteration 12040, loss = 0.510639
I0614 15:19:40.758224 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 15:19:40.758229 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.107131 (* 1 = 0.107131 loss)
I0614 15:19:40.758234 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.096748 (* 1 = 0.096748 loss)
I0614 15:19:40.758237 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016705 (* 1 = 0.0016705 loss)
I0614 15:19:40.758240 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438509 (* 1 = 0.0438509 loss)
I0614 15:19:40.758245 15760 sgd_solver.cpp:106] Iteration 12040, lr = 0.0002
I0614 15:21:27.284013 15760 solver.cpp:228] Iteration 12060, loss = 0.507231
I0614 15:21:27.284039 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 15:21:27.284049 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0865259 (* 1 = 0.0865259 loss)
I0614 15:21:27.284056 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.11463 (* 1 = 0.11463 loss)
I0614 15:21:27.284062 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000504558 (* 1 = 0.000504558 loss)
I0614 15:21:27.284070 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181588 (* 1 = 0.0181588 loss)
I0614 15:21:27.284076 15760 sgd_solver.cpp:106] Iteration 12060, lr = 0.0002
I0614 15:23:13.771729 15760 solver.cpp:228] Iteration 12080, loss = 0.478225
I0614 15:23:13.771752 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 15:23:13.771759 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.136617 (* 1 = 0.136617 loss)
I0614 15:23:13.771764 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.132666 (* 1 = 0.132666 loss)
I0614 15:23:13.771767 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00937214 (* 1 = 0.00937214 loss)
I0614 15:23:13.771771 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0636887 (* 1 = 0.0636887 loss)
I0614 15:23:13.771775 15760 sgd_solver.cpp:106] Iteration 12080, lr = 0.0002
I0614 15:25:00.311281 15760 solver.cpp:228] Iteration 12100, loss = 0.495987
I0614 15:25:00.311305 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 15:25:00.311313 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.541069 (* 1 = 0.541069 loss)
I0614 15:25:00.311317 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.537739 (* 1 = 0.537739 loss)
I0614 15:25:00.311321 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248053 (* 1 = 0.00248053 loss)
I0614 15:25:00.311326 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0654963 (* 1 = 0.0654963 loss)
I0614 15:25:00.311331 15760 sgd_solver.cpp:106] Iteration 12100, lr = 0.0002
I0614 15:26:46.831147 15760 solver.cpp:228] Iteration 12120, loss = 0.547021
I0614 15:26:46.831173 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 15:26:46.831181 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129482 (* 1 = 0.129482 loss)
I0614 15:26:46.831184 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.14097 (* 1 = 0.14097 loss)
I0614 15:26:46.831188 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766756 (* 1 = 0.00766756 loss)
I0614 15:26:46.831192 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395779 (* 1 = 0.0395779 loss)
I0614 15:26:46.831197 15760 sgd_solver.cpp:106] Iteration 12120, lr = 0.0002
I0614 15:28:33.111927 15760 solver.cpp:228] Iteration 12140, loss = 0.429281
I0614 15:28:33.111950 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0614 15:28:33.111958 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.459971 (* 1 = 0.459971 loss)
I0614 15:28:33.111961 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.469148 (* 1 = 0.469148 loss)
I0614 15:28:33.111965 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772762 (* 1 = 0.00772762 loss)
I0614 15:28:33.111968 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0901213 (* 1 = 0.0901213 loss)
I0614 15:28:33.111974 15760 sgd_solver.cpp:106] Iteration 12140, lr = 0.0002
I0614 15:30:19.976999 15760 solver.cpp:228] Iteration 12160, loss = 0.434899
I0614 15:30:19.977026 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 15:30:19.977035 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.277215 (* 1 = 0.277215 loss)
I0614 15:30:19.977039 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.24622 (* 1 = 0.24622 loss)
I0614 15:30:19.977044 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00515208 (* 1 = 0.00515208 loss)
I0614 15:30:19.977048 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231348 (* 1 = 0.0231348 loss)
I0614 15:30:19.977054 15760 sgd_solver.cpp:106] Iteration 12160, lr = 0.0002
I0614 15:32:06.588760 15760 solver.cpp:228] Iteration 12180, loss = 0.347639
I0614 15:32:06.588783 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 15:32:06.588791 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.227269 (* 1 = 0.227269 loss)
I0614 15:32:06.588795 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.305996 (* 1 = 0.305996 loss)
I0614 15:32:06.588798 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000413542 (* 1 = 0.000413542 loss)
I0614 15:32:06.588802 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0545037 (* 1 = 0.0545037 loss)
I0614 15:32:06.588807 15760 sgd_solver.cpp:106] Iteration 12180, lr = 0.0002
speed: 5.328s / iter
I0614 15:33:52.758407 15760 solver.cpp:228] Iteration 12200, loss = 0.786727
I0614 15:33:52.758433 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 15:33:52.758441 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.321468 (* 1 = 0.321468 loss)
I0614 15:33:52.758445 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28878 (* 1 = 0.28878 loss)
I0614 15:33:52.758450 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0069134 (* 1 = 0.0069134 loss)
I0614 15:33:52.758453 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0622372 (* 1 = 0.0622372 loss)
I0614 15:33:52.758458 15760 sgd_solver.cpp:106] Iteration 12200, lr = 0.0002
I0614 15:35:39.309213 15760 solver.cpp:228] Iteration 12220, loss = 0.39515
I0614 15:35:39.309239 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 15:35:39.309247 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0860501 (* 1 = 0.0860501 loss)
I0614 15:35:39.309252 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116966 (* 1 = 0.116966 loss)
I0614 15:35:39.309257 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016388 (* 1 = 0.0016388 loss)
I0614 15:35:39.309260 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134921 (* 1 = 0.0134921 loss)
I0614 15:35:39.309265 15760 sgd_solver.cpp:106] Iteration 12220, lr = 0.0002
I0614 15:37:25.655299 15760 solver.cpp:228] Iteration 12240, loss = 0.665578
I0614 15:37:25.655323 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 15:37:25.655329 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.357631 (* 1 = 0.357631 loss)
I0614 15:37:25.655333 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.41175 (* 1 = 0.41175 loss)
I0614 15:37:25.655338 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195574 (* 1 = 0.0195574 loss)
I0614 15:37:25.655340 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0957396 (* 1 = 0.0957396 loss)
I0614 15:37:25.655345 15760 sgd_solver.cpp:106] Iteration 12240, lr = 0.0002
I0614 15:39:11.903558 15760 solver.cpp:228] Iteration 12260, loss = 0.412641
I0614 15:39:11.903581 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 15:39:11.903589 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.105668 (* 1 = 0.105668 loss)
I0614 15:39:11.903594 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117123 (* 1 = 0.117123 loss)
I0614 15:39:11.903596 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213075 (* 1 = 0.00213075 loss)
I0614 15:39:11.903600 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250482 (* 1 = 0.0250482 loss)
I0614 15:39:11.903604 15760 sgd_solver.cpp:106] Iteration 12260, lr = 0.0002
I0614 15:40:58.363389 15760 solver.cpp:228] Iteration 12280, loss = 0.587385
I0614 15:40:58.363416 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0614 15:40:58.363425 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0819274 (* 1 = 0.0819274 loss)
I0614 15:40:58.363428 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0384492 (* 1 = 0.0384492 loss)
I0614 15:40:58.363432 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000948709 (* 1 = 0.000948709 loss)
I0614 15:40:58.363436 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139539 (* 1 = 0.0139539 loss)
I0614 15:40:58.363441 15760 sgd_solver.cpp:106] Iteration 12280, lr = 0.0002
I0614 15:42:44.702088 15760 solver.cpp:228] Iteration 12300, loss = 0.35189
I0614 15:42:44.702114 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 15:42:44.702121 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0871329 (* 1 = 0.0871329 loss)
I0614 15:42:44.702126 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0683422 (* 1 = 0.0683422 loss)
I0614 15:42:44.702131 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276609 (* 1 = 0.00276609 loss)
I0614 15:42:44.702133 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232312 (* 1 = 0.0232312 loss)
I0614 15:42:44.702139 15760 sgd_solver.cpp:106] Iteration 12300, lr = 0.0002
I0614 15:44:31.119918 15760 solver.cpp:228] Iteration 12320, loss = 0.645611
I0614 15:44:31.119945 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 15:44:31.119952 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.120005 (* 1 = 0.120005 loss)
I0614 15:44:31.119958 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.231214 (* 1 = 0.231214 loss)
I0614 15:44:31.119963 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00487574 (* 1 = 0.00487574 loss)
I0614 15:44:31.119969 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266034 (* 1 = 0.0266034 loss)
I0614 15:44:31.119976 15760 sgd_solver.cpp:106] Iteration 12320, lr = 0.0002
I0614 15:46:17.411059 15760 solver.cpp:228] Iteration 12340, loss = 0.764326
I0614 15:46:17.411087 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 15:46:17.411094 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0852719 (* 1 = 0.0852719 loss)
I0614 15:46:17.411098 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.179011 (* 1 = 0.179011 loss)
I0614 15:46:17.411103 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000384028 (* 1 = 0.000384028 loss)
I0614 15:46:17.411106 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117185 (* 1 = 0.0117185 loss)
I0614 15:46:17.411111 15760 sgd_solver.cpp:106] Iteration 12340, lr = 0.0002
I0614 15:48:04.004618 15760 solver.cpp:228] Iteration 12360, loss = 0.548979
I0614 15:48:04.004644 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 15:48:04.004652 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.228087 (* 1 = 0.228087 loss)
I0614 15:48:04.004657 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.373002 (* 1 = 0.373002 loss)
I0614 15:48:04.004660 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0272536 (* 1 = 0.0272536 loss)
I0614 15:48:04.004664 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.123647 (* 1 = 0.123647 loss)
I0614 15:48:04.004670 15760 sgd_solver.cpp:106] Iteration 12360, lr = 0.0002
I0614 15:49:50.341531 15760 solver.cpp:228] Iteration 12380, loss = 0.68676
I0614 15:49:50.341557 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 15:49:50.341563 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.266917 (* 1 = 0.266917 loss)
I0614 15:49:50.341567 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.2508 (* 1 = 0.2508 loss)
I0614 15:49:50.341572 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000483127 (* 1 = 0.000483127 loss)
I0614 15:49:50.341574 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0612425 (* 1 = 0.0612425 loss)
I0614 15:49:50.341579 15760 sgd_solver.cpp:106] Iteration 12380, lr = 0.0002
speed: 5.328s / iter
I0614 15:51:36.560665 15760 solver.cpp:228] Iteration 12400, loss = 0.45308
I0614 15:51:36.560693 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 15:51:36.560701 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0727993 (* 1 = 0.0727993 loss)
I0614 15:51:36.560706 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.121901 (* 1 = 0.121901 loss)
I0614 15:51:36.560712 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265394 (* 1 = 0.00265394 loss)
I0614 15:51:36.560720 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154657 (* 1 = 0.0154657 loss)
I0614 15:51:36.560729 15760 sgd_solver.cpp:106] Iteration 12400, lr = 0.0002
I0614 15:53:22.870826 15760 solver.cpp:228] Iteration 12420, loss = 0.678331
I0614 15:53:22.870851 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 15:53:22.870859 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.159891 (* 1 = 0.159891 loss)
I0614 15:53:22.870863 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.131218 (* 1 = 0.131218 loss)
I0614 15:53:22.870867 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105654 (* 1 = 0.00105654 loss)
I0614 15:53:22.870872 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288164 (* 1 = 0.0288164 loss)
I0614 15:53:22.870877 15760 sgd_solver.cpp:106] Iteration 12420, lr = 0.0002
I0614 15:55:10.006780 15760 solver.cpp:228] Iteration 12440, loss = 0.698232
I0614 15:55:10.006806 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 15:55:10.006814 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.281219 (* 1 = 0.281219 loss)
I0614 15:55:10.006819 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.311532 (* 1 = 0.311532 loss)
I0614 15:55:10.006824 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000535966 (* 1 = 0.000535966 loss)
I0614 15:55:10.006827 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488605 (* 1 = 0.0488605 loss)
I0614 15:55:10.006832 15760 sgd_solver.cpp:106] Iteration 12440, lr = 0.0002
I0614 15:56:57.177716 15760 solver.cpp:228] Iteration 12460, loss = 0.36574
I0614 15:56:57.177742 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 15:56:57.177748 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.209201 (* 1 = 0.209201 loss)
I0614 15:56:57.177752 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.229809 (* 1 = 0.229809 loss)
I0614 15:56:57.177757 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000666633 (* 1 = 0.000666633 loss)
I0614 15:56:57.177760 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0822584 (* 1 = 0.0822584 loss)
I0614 15:56:57.177765 15760 sgd_solver.cpp:106] Iteration 12460, lr = 0.0002
I0614 15:58:43.938355 15760 solver.cpp:228] Iteration 12480, loss = 0.345242
I0614 15:58:43.938380 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 15:58:43.938387 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.182846 (* 1 = 0.182846 loss)
I0614 15:58:43.938390 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.265331 (* 1 = 0.265331 loss)
I0614 15:58:43.938395 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178865 (* 1 = 0.00178865 loss)
I0614 15:58:43.938398 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245297 (* 1 = 0.0245297 loss)
I0614 15:58:43.938402 15760 sgd_solver.cpp:106] Iteration 12480, lr = 0.0002
I0614 16:00:30.146728 15760 solver.cpp:228] Iteration 12500, loss = 0.632335
I0614 16:00:30.146770 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 16:00:30.146780 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.439184 (* 1 = 0.439184 loss)
I0614 16:00:30.146783 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.480428 (* 1 = 0.480428 loss)
I0614 16:00:30.146787 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026098 (* 1 = 0.026098 loss)
I0614 16:00:30.146791 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.255299 (* 1 = 0.255299 loss)
I0614 16:00:30.146800 15760 sgd_solver.cpp:106] Iteration 12500, lr = 0.0002
I0614 16:02:16.995049 15760 solver.cpp:228] Iteration 12520, loss = 0.349244
I0614 16:02:16.995074 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 16:02:16.995082 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00255555 (* 1 = 0.00255555 loss)
I0614 16:02:16.995086 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0794265 (* 1 = 0.0794265 loss)
I0614 16:02:16.995090 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0459398 (* 1 = 0.0459398 loss)
I0614 16:02:16.995095 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512384 (* 1 = 0.0512384 loss)
I0614 16:02:16.995100 15760 sgd_solver.cpp:106] Iteration 12520, lr = 0.0002
I0614 16:04:03.445432 15760 solver.cpp:228] Iteration 12540, loss = 0.604444
I0614 16:04:03.445457 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 16:04:03.445466 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.181617 (* 1 = 0.181617 loss)
I0614 16:04:03.445469 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.219569 (* 1 = 0.219569 loss)
I0614 16:04:03.445473 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000931632 (* 1 = 0.000931632 loss)
I0614 16:04:03.445477 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263541 (* 1 = 0.0263541 loss)
I0614 16:04:03.445482 15760 sgd_solver.cpp:106] Iteration 12540, lr = 0.0002
I0614 16:05:49.987602 15760 solver.cpp:228] Iteration 12560, loss = 0.563842
I0614 16:05:49.987632 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 16:05:49.987639 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0802816 (* 1 = 0.0802816 loss)
I0614 16:05:49.987644 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0910286 (* 1 = 0.0910286 loss)
I0614 16:05:49.987648 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035881 (* 1 = 0.0035881 loss)
I0614 16:05:49.987653 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239823 (* 1 = 0.0239823 loss)
I0614 16:05:49.987658 15760 sgd_solver.cpp:106] Iteration 12560, lr = 0.0002
I0614 16:07:36.412890 15760 solver.cpp:228] Iteration 12580, loss = 0.699992
I0614 16:07:36.412915 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 16:07:36.412922 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0906558 (* 1 = 0.0906558 loss)
I0614 16:07:36.412926 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0995458 (* 1 = 0.0995458 loss)
I0614 16:07:36.412930 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000333144 (* 1 = 0.000333144 loss)
I0614 16:07:36.412932 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133103 (* 1 = 0.0133103 loss)
I0614 16:07:36.412941 15760 sgd_solver.cpp:106] Iteration 12580, lr = 0.0002
speed: 5.328s / iter
I0614 16:09:23.714565 15760 solver.cpp:228] Iteration 12600, loss = 0.670399
I0614 16:09:23.714593 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 16:09:23.714602 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0686644 (* 1 = 0.0686644 loss)
I0614 16:09:23.714608 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0969564 (* 1 = 0.0969564 loss)
I0614 16:09:23.714614 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000903507 (* 1 = 0.000903507 loss)
I0614 16:09:23.714619 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176808 (* 1 = 0.0176808 loss)
I0614 16:09:23.714624 15760 sgd_solver.cpp:106] Iteration 12600, lr = 0.0002
I0614 16:11:10.275773 15760 solver.cpp:228] Iteration 12620, loss = 0.475104
I0614 16:11:10.275810 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 16:11:10.275817 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.207227 (* 1 = 0.207227 loss)
I0614 16:11:10.275821 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234479 (* 1 = 0.234479 loss)
I0614 16:11:10.275826 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118471 (* 1 = 0.00118471 loss)
I0614 16:11:10.275830 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206576 (* 1 = 0.0206576 loss)
I0614 16:11:10.275836 15760 sgd_solver.cpp:106] Iteration 12620, lr = 0.0002
I0614 16:12:56.547777 15760 solver.cpp:228] Iteration 12640, loss = 0.787238
I0614 16:12:56.547802 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 16:12:56.547809 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536552 (* 1 = 0.0536552 loss)
I0614 16:12:56.547813 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.10193 (* 1 = 0.10193 loss)
I0614 16:12:56.547816 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235678 (* 1 = 0.00235678 loss)
I0614 16:12:56.547821 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333063 (* 1 = 0.0333063 loss)
I0614 16:12:56.547825 15760 sgd_solver.cpp:106] Iteration 12640, lr = 0.0002
I0614 16:14:42.981739 15760 solver.cpp:228] Iteration 12660, loss = 0.401668
I0614 16:14:42.981765 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 16:14:42.981772 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.236678 (* 1 = 0.236678 loss)
I0614 16:14:42.981776 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.278806 (* 1 = 0.278806 loss)
I0614 16:14:42.981781 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00797318 (* 1 = 0.00797318 loss)
I0614 16:14:42.981784 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0944713 (* 1 = 0.0944713 loss)
I0614 16:14:42.981789 15760 sgd_solver.cpp:106] Iteration 12660, lr = 0.0002
I0614 16:16:29.374649 15760 solver.cpp:228] Iteration 12680, loss = 0.435503
I0614 16:16:29.374673 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 16:16:29.374680 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.217679 (* 1 = 0.217679 loss)
I0614 16:16:29.374685 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.303991 (* 1 = 0.303991 loss)
I0614 16:16:29.374688 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000867803 (* 1 = 0.000867803 loss)
I0614 16:16:29.374692 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145218 (* 1 = 0.0145218 loss)
I0614 16:16:29.374698 15760 sgd_solver.cpp:106] Iteration 12680, lr = 0.0002
I0614 16:18:15.918787 15760 solver.cpp:228] Iteration 12700, loss = 0.415254
I0614 16:18:15.918810 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 16:18:15.918817 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0788155 (* 1 = 0.0788155 loss)
I0614 16:18:15.918821 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0819779 (* 1 = 0.0819779 loss)
I0614 16:18:15.918825 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216939 (* 1 = 0.00216939 loss)
I0614 16:18:15.918828 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103145 (* 1 = 0.0103145 loss)
I0614 16:18:15.918833 15760 sgd_solver.cpp:106] Iteration 12700, lr = 0.0002
I0614 16:20:02.333320 15760 solver.cpp:228] Iteration 12720, loss = 0.681176
I0614 16:20:02.333343 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 16:20:02.333350 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.307857 (* 1 = 0.307857 loss)
I0614 16:20:02.333354 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.292319 (* 1 = 0.292319 loss)
I0614 16:20:02.333359 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.001025 (* 1 = 0.001025 loss)
I0614 16:20:02.333361 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222545 (* 1 = 0.0222545 loss)
I0614 16:20:02.333366 15760 sgd_solver.cpp:106] Iteration 12720, lr = 0.0002
I0614 16:21:48.879379 15760 solver.cpp:228] Iteration 12740, loss = 0.989823
I0614 16:21:48.879408 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 16:21:48.879420 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.236137 (* 1 = 0.236137 loss)
I0614 16:21:48.879426 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.473825 (* 1 = 0.473825 loss)
I0614 16:21:48.879432 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134059 (* 1 = 0.0134059 loss)
I0614 16:21:48.879438 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0710111 (* 1 = 0.0710111 loss)
I0614 16:21:48.879446 15760 sgd_solver.cpp:106] Iteration 12740, lr = 0.0002
I0614 16:23:35.265163 15760 solver.cpp:228] Iteration 12760, loss = 0.509097
I0614 16:23:35.265188 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 16:23:35.265195 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0884314 (* 1 = 0.0884314 loss)
I0614 16:23:35.265199 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.105446 (* 1 = 0.105446 loss)
I0614 16:23:35.265203 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00420833 (* 1 = 0.00420833 loss)
I0614 16:23:35.265206 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110243 (* 1 = 0.0110243 loss)
I0614 16:23:35.265211 15760 sgd_solver.cpp:106] Iteration 12760, lr = 0.0002
I0614 16:25:21.885869 15760 solver.cpp:228] Iteration 12780, loss = 0.383618
I0614 16:25:21.885896 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 16:25:21.885905 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.175278 (* 1 = 0.175278 loss)
I0614 16:25:21.885912 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.18398 (* 1 = 0.18398 loss)
I0614 16:25:21.885918 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157235 (* 1 = 0.00157235 loss)
I0614 16:25:21.885924 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030387 (* 1 = 0.030387 loss)
I0614 16:25:21.885931 15760 sgd_solver.cpp:106] Iteration 12780, lr = 0.0002
speed: 5.328s / iter
I0614 16:27:08.296058 15760 solver.cpp:228] Iteration 12800, loss = 0.69375
I0614 16:27:08.296084 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 16:27:08.296094 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.485432 (* 1 = 0.485432 loss)
I0614 16:27:08.296100 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.489217 (* 1 = 0.489217 loss)
I0614 16:27:08.296106 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00715772 (* 1 = 0.00715772 loss)
I0614 16:27:08.296113 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370644 (* 1 = 0.0370644 loss)
I0614 16:27:08.296123 15760 sgd_solver.cpp:106] Iteration 12800, lr = 0.0002
I0614 16:28:54.930238 15760 solver.cpp:228] Iteration 12820, loss = 0.497741
I0614 16:28:54.930264 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 16:28:54.930272 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.152863 (* 1 = 0.152863 loss)
I0614 16:28:54.930276 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.197708 (* 1 = 0.197708 loss)
I0614 16:28:54.930280 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103271 (* 1 = 0.0103271 loss)
I0614 16:28:54.930284 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034402 (* 1 = 0.034402 loss)
I0614 16:28:54.930290 15760 sgd_solver.cpp:106] Iteration 12820, lr = 0.0002
I0614 16:30:41.464462 15760 solver.cpp:228] Iteration 12840, loss = 0.858623
I0614 16:30:41.464504 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0614 16:30:41.464511 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.596594 (* 1 = 0.596594 loss)
I0614 16:30:41.464516 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.574813 (* 1 = 0.574813 loss)
I0614 16:30:41.464519 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165003 (* 1 = 0.0165003 loss)
I0614 16:30:41.464524 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.275975 (* 1 = 0.275975 loss)
I0614 16:30:41.464529 15760 sgd_solver.cpp:106] Iteration 12840, lr = 0.0002
I0614 16:32:28.073123 15760 solver.cpp:228] Iteration 12860, loss = 0.471369
I0614 16:32:28.073148 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 16:32:28.073156 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.136633 (* 1 = 0.136633 loss)
I0614 16:32:28.073160 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112537 (* 1 = 0.112537 loss)
I0614 16:32:28.073164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0297964 (* 1 = 0.0297964 loss)
I0614 16:32:28.073168 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122905 (* 1 = 0.0122905 loss)
I0614 16:32:28.073173 15760 sgd_solver.cpp:106] Iteration 12860, lr = 0.0002
I0614 16:34:14.378824 15760 solver.cpp:228] Iteration 12880, loss = 0.538663
I0614 16:34:14.378851 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 16:34:14.378859 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.183177 (* 1 = 0.183177 loss)
I0614 16:34:14.378864 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.263372 (* 1 = 0.263372 loss)
I0614 16:34:14.378867 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282132 (* 1 = 0.00282132 loss)
I0614 16:34:14.378871 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0343223 (* 1 = 0.0343223 loss)
I0614 16:34:14.378875 15760 sgd_solver.cpp:106] Iteration 12880, lr = 0.0002
I0614 16:36:01.159468 15760 solver.cpp:228] Iteration 12900, loss = 0.998304
I0614 16:36:01.159492 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 16:36:01.159500 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.504871 (* 1 = 0.504871 loss)
I0614 16:36:01.159504 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.469383 (* 1 = 0.469383 loss)
I0614 16:36:01.159508 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360174 (* 1 = 0.00360174 loss)
I0614 16:36:01.159512 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0777044 (* 1 = 0.0777044 loss)
I0614 16:36:01.159518 15760 sgd_solver.cpp:106] Iteration 12900, lr = 0.0002
I0614 16:37:48.173347 15760 solver.cpp:228] Iteration 12920, loss = 0.601976
I0614 16:37:48.173369 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 16:37:48.173377 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614774 (* 1 = 0.0614774 loss)
I0614 16:37:48.173380 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0725078 (* 1 = 0.0725078 loss)
I0614 16:37:48.173384 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000461864 (* 1 = 0.000461864 loss)
I0614 16:37:48.173388 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169604 (* 1 = 0.0169604 loss)
I0614 16:37:48.173391 15760 sgd_solver.cpp:106] Iteration 12920, lr = 0.0002
I0614 16:39:35.103077 15760 solver.cpp:228] Iteration 12940, loss = 0.576968
I0614 16:39:35.103101 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 16:39:35.103107 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.232442 (* 1 = 0.232442 loss)
I0614 16:39:35.103111 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.141898 (* 1 = 0.141898 loss)
I0614 16:39:35.103116 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00402515 (* 1 = 0.00402515 loss)
I0614 16:39:35.103119 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388041 (* 1 = 0.0388041 loss)
I0614 16:39:35.103124 15760 sgd_solver.cpp:106] Iteration 12940, lr = 0.0002
I0614 16:41:22.031458 15760 solver.cpp:228] Iteration 12960, loss = 0.490774
I0614 16:41:22.031481 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 16:41:22.031491 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.17753 (* 1 = 0.17753 loss)
I0614 16:41:22.031497 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171413 (* 1 = 0.171413 loss)
I0614 16:41:22.031502 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000464735 (* 1 = 0.000464735 loss)
I0614 16:41:22.031508 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102486 (* 1 = 0.0102486 loss)
I0614 16:41:22.031515 15760 sgd_solver.cpp:106] Iteration 12960, lr = 0.0002
I0614 16:43:08.611966 15760 solver.cpp:228] Iteration 12980, loss = 0.456481
I0614 16:43:08.611990 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 16:43:08.611997 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.2476 (* 1 = 0.2476 loss)
I0614 16:43:08.612001 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.267208 (* 1 = 0.267208 loss)
I0614 16:43:08.612005 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257339 (* 1 = 0.00257339 loss)
I0614 16:43:08.612009 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293671 (* 1 = 0.0293671 loss)
I0614 16:43:08.612015 15760 sgd_solver.cpp:106] Iteration 12980, lr = 0.0002
speed: 5.328s / iter
I0614 16:44:56.066673 15760 solver.cpp:228] Iteration 13000, loss = 0.402658
I0614 16:44:56.066695 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 16:44:56.066704 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113754 (* 1 = 0.113754 loss)
I0614 16:44:56.066707 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.138074 (* 1 = 0.138074 loss)
I0614 16:44:56.066710 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00796174 (* 1 = 0.00796174 loss)
I0614 16:44:56.066715 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261408 (* 1 = 0.0261408 loss)
I0614 16:44:56.066720 15760 sgd_solver.cpp:106] Iteration 13000, lr = 0.0002
I0614 16:46:43.126108 15760 solver.cpp:228] Iteration 13020, loss = 0.49217
I0614 16:46:43.126135 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 16:46:43.126144 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.107024 (* 1 = 0.107024 loss)
I0614 16:46:43.126150 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0991963 (* 1 = 0.0991963 loss)
I0614 16:46:43.126157 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119168 (* 1 = 0.0119168 loss)
I0614 16:46:43.126161 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0674869 (* 1 = 0.0674869 loss)
I0614 16:46:43.126168 15760 sgd_solver.cpp:106] Iteration 13020, lr = 0.0002
I0614 16:48:30.408437 15760 solver.cpp:228] Iteration 13040, loss = 0.334686
I0614 16:48:30.408465 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 16:48:30.408473 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117854 (* 1 = 0.117854 loss)
I0614 16:48:30.408478 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.133909 (* 1 = 0.133909 loss)
I0614 16:48:30.408483 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128071 (* 1 = 0.00128071 loss)
I0614 16:48:30.408490 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200027 (* 1 = 0.0200027 loss)
I0614 16:48:30.408498 15760 sgd_solver.cpp:106] Iteration 13040, lr = 0.0002
I0614 16:50:17.927402 15760 solver.cpp:228] Iteration 13060, loss = 0.51197
I0614 16:50:17.927425 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 16:50:17.927433 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.430019 (* 1 = 0.430019 loss)
I0614 16:50:17.927436 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.461519 (* 1 = 0.461519 loss)
I0614 16:50:17.927439 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385616 (* 1 = 0.00385616 loss)
I0614 16:50:17.927443 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0344139 (* 1 = 0.0344139 loss)
I0614 16:50:17.927448 15760 sgd_solver.cpp:106] Iteration 13060, lr = 0.0002
I0614 16:52:04.505198 15760 solver.cpp:228] Iteration 13080, loss = 0.760269
I0614 16:52:04.505224 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0614 16:52:04.505233 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.777315 (* 1 = 0.777315 loss)
I0614 16:52:04.505239 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.806811 (* 1 = 0.806811 loss)
I0614 16:52:04.505242 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0207238 (* 1 = 0.0207238 loss)
I0614 16:52:04.505247 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.526734 (* 1 = 0.526734 loss)
I0614 16:52:04.505254 15760 sgd_solver.cpp:106] Iteration 13080, lr = 0.0002
I0614 16:53:51.345950 15760 solver.cpp:228] Iteration 13100, loss = 0.534796
I0614 16:53:51.345975 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 16:53:51.345983 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.299674 (* 1 = 0.299674 loss)
I0614 16:53:51.345986 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.313433 (* 1 = 0.313433 loss)
I0614 16:53:51.345991 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300451 (* 1 = 0.00300451 loss)
I0614 16:53:51.345994 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0583751 (* 1 = 0.0583751 loss)
I0614 16:53:51.345999 15760 sgd_solver.cpp:106] Iteration 13100, lr = 0.0002
I0614 16:55:37.792165 15760 solver.cpp:228] Iteration 13120, loss = 0.327057
I0614 16:55:37.792189 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 16:55:37.792196 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.200639 (* 1 = 0.200639 loss)
I0614 16:55:37.792201 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.168364 (* 1 = 0.168364 loss)
I0614 16:55:37.792203 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206057 (* 1 = 0.00206057 loss)
I0614 16:55:37.792207 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372322 (* 1 = 0.0372322 loss)
I0614 16:55:37.792212 15760 sgd_solver.cpp:106] Iteration 13120, lr = 0.0002
I0614 16:57:24.156872 15760 solver.cpp:228] Iteration 13140, loss = 0.944603
I0614 16:57:24.156895 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0614 16:57:24.156903 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.743655 (* 1 = 0.743655 loss)
I0614 16:57:24.156906 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.636693 (* 1 = 0.636693 loss)
I0614 16:57:24.156909 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0091571 (* 1 = 0.0091571 loss)
I0614 16:57:24.156913 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.207369 (* 1 = 0.207369 loss)
I0614 16:57:24.156921 15760 sgd_solver.cpp:106] Iteration 13140, lr = 0.0002
I0614 16:59:10.718052 15760 solver.cpp:228] Iteration 13160, loss = 0.878446
I0614 16:59:10.718077 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 16:59:10.718083 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194428 (* 1 = 0.194428 loss)
I0614 16:59:10.718087 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.288472 (* 1 = 0.288472 loss)
I0614 16:59:10.718091 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053653 (* 1 = 0.0053653 loss)
I0614 16:59:10.718094 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111243 (* 1 = 0.111243 loss)
I0614 16:59:10.718099 15760 sgd_solver.cpp:106] Iteration 13160, lr = 0.0002
I0614 17:00:56.978786 15760 solver.cpp:228] Iteration 13180, loss = 1.02611
I0614 17:00:56.978811 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 17:00:56.978821 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0805493 (* 1 = 0.0805493 loss)
I0614 17:00:56.978827 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0930657 (* 1 = 0.0930657 loss)
I0614 17:00:56.978834 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126626 (* 1 = 0.00126626 loss)
I0614 17:00:56.978842 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0086456 (* 1 = 0.0086456 loss)
I0614 17:00:56.978849 15760 sgd_solver.cpp:106] Iteration 13180, lr = 0.0002
speed: 5.328s / iter
I0614 17:02:43.380295 15760 solver.cpp:228] Iteration 13200, loss = 0.524162
I0614 17:02:43.380324 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0614 17:02:43.380332 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.187488 (* 1 = 0.187488 loss)
I0614 17:02:43.380336 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.743908 (* 1 = 0.743908 loss)
I0614 17:02:43.380340 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199339 (* 1 = 0.0199339 loss)
I0614 17:02:43.380344 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317721 (* 1 = 0.0317721 loss)
I0614 17:02:43.380350 15760 sgd_solver.cpp:106] Iteration 13200, lr = 0.0002
I0614 17:04:29.741644 15760 solver.cpp:228] Iteration 13220, loss = 0.480247
I0614 17:04:29.741669 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 17:04:29.741677 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.170591 (* 1 = 0.170591 loss)
I0614 17:04:29.741679 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.133532 (* 1 = 0.133532 loss)
I0614 17:04:29.741683 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385716 (* 1 = 0.00385716 loss)
I0614 17:04:29.741688 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159799 (* 1 = 0.0159799 loss)
I0614 17:04:29.741693 15760 sgd_solver.cpp:106] Iteration 13220, lr = 0.0002
I0614 17:06:15.881863 15760 solver.cpp:228] Iteration 13240, loss = 0.590968
I0614 17:06:15.881884 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 17:06:15.881891 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.342107 (* 1 = 0.342107 loss)
I0614 17:06:15.881896 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.478874 (* 1 = 0.478874 loss)
I0614 17:06:15.881898 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126164 (* 1 = 0.0126164 loss)
I0614 17:06:15.881901 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.137461 (* 1 = 0.137461 loss)
I0614 17:06:15.881906 15760 sgd_solver.cpp:106] Iteration 13240, lr = 0.0002
I0614 17:08:02.210853 15760 solver.cpp:228] Iteration 13260, loss = 0.512445
I0614 17:08:02.210880 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0614 17:08:02.210889 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.45059 (* 1 = 0.45059 loss)
I0614 17:08:02.210896 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.616159 (* 1 = 0.616159 loss)
I0614 17:08:02.210902 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00518759 (* 1 = 0.00518759 loss)
I0614 17:08:02.210908 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103033 (* 1 = 0.103033 loss)
I0614 17:08:02.210916 15760 sgd_solver.cpp:106] Iteration 13260, lr = 0.0002
I0614 17:09:48.455029 15760 solver.cpp:228] Iteration 13280, loss = 0.539569
I0614 17:09:48.455054 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 17:09:48.455061 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231722 (* 1 = 0.0231722 loss)
I0614 17:09:48.455066 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0917088 (* 1 = 0.0917088 loss)
I0614 17:09:48.455070 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161483 (* 1 = 0.0161483 loss)
I0614 17:09:48.455073 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264931 (* 1 = 0.0264931 loss)
I0614 17:09:48.455078 15760 sgd_solver.cpp:106] Iteration 13280, lr = 0.0002
I0614 17:11:34.773767 15760 solver.cpp:228] Iteration 13300, loss = 0.536021
I0614 17:11:34.773792 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 17:11:34.773799 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.247858 (* 1 = 0.247858 loss)
I0614 17:11:34.773802 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.209193 (* 1 = 0.209193 loss)
I0614 17:11:34.773807 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00790749 (* 1 = 0.00790749 loss)
I0614 17:11:34.773809 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168615 (* 1 = 0.0168615 loss)
I0614 17:11:34.773814 15760 sgd_solver.cpp:106] Iteration 13300, lr = 0.0002
I0614 17:13:21.395025 15760 solver.cpp:228] Iteration 13320, loss = 0.426631
I0614 17:13:21.395050 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 17:13:21.395056 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.244844 (* 1 = 0.244844 loss)
I0614 17:13:21.395061 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.333311 (* 1 = 0.333311 loss)
I0614 17:13:21.395063 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226298 (* 1 = 0.0226298 loss)
I0614 17:13:21.395067 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.212376 (* 1 = 0.212376 loss)
I0614 17:13:21.395071 15760 sgd_solver.cpp:106] Iteration 13320, lr = 0.0002
I0614 17:15:07.564131 15760 solver.cpp:228] Iteration 13340, loss = 0.303862
I0614 17:15:07.564160 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 17:15:07.564167 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.151367 (* 1 = 0.151367 loss)
I0614 17:15:07.564172 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.204003 (* 1 = 0.204003 loss)
I0614 17:15:07.564175 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00367156 (* 1 = 0.00367156 loss)
I0614 17:15:07.564179 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175392 (* 1 = 0.0175392 loss)
I0614 17:15:07.564184 15760 sgd_solver.cpp:106] Iteration 13340, lr = 0.0002
I0614 17:16:54.302867 15760 solver.cpp:228] Iteration 13360, loss = 0.554284
I0614 17:16:54.302891 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 17:16:54.302897 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827186 (* 1 = 0.0827186 loss)
I0614 17:16:54.302901 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119358 (* 1 = 0.119358 loss)
I0614 17:16:54.302906 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000692351 (* 1 = 0.000692351 loss)
I0614 17:16:54.302908 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127044 (* 1 = 0.0127044 loss)
I0614 17:16:54.302913 15760 sgd_solver.cpp:106] Iteration 13360, lr = 0.0002
I0614 17:18:40.690234 15760 solver.cpp:228] Iteration 13380, loss = 0.442568
I0614 17:18:40.690256 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0614 17:18:40.690264 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0813721 (* 1 = 0.0813721 loss)
I0614 17:18:40.690268 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0559008 (* 1 = 0.0559008 loss)
I0614 17:18:40.690271 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130243 (* 1 = 0.00130243 loss)
I0614 17:18:40.690275 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00740699 (* 1 = 0.00740699 loss)
I0614 17:18:40.690279 15760 sgd_solver.cpp:106] Iteration 13380, lr = 0.0002
speed: 5.328s / iter
I0614 17:20:27.099544 15760 solver.cpp:228] Iteration 13400, loss = 0.64476
I0614 17:20:27.099570 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 17:20:27.099576 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0963895 (* 1 = 0.0963895 loss)
I0614 17:20:27.099581 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0859016 (* 1 = 0.0859016 loss)
I0614 17:20:27.099586 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010004 (* 1 = 0.010004 loss)
I0614 17:20:27.099589 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375299 (* 1 = 0.0375299 loss)
I0614 17:20:27.099594 15760 sgd_solver.cpp:106] Iteration 13400, lr = 0.0002
I0614 17:22:14.101953 15760 solver.cpp:228] Iteration 13420, loss = 0.474407
I0614 17:22:14.101977 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 17:22:14.101984 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.510874 (* 1 = 0.510874 loss)
I0614 17:22:14.101987 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.431706 (* 1 = 0.431706 loss)
I0614 17:22:14.101991 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109884 (* 1 = 0.00109884 loss)
I0614 17:22:14.101995 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0603443 (* 1 = 0.0603443 loss)
I0614 17:22:14.102000 15760 sgd_solver.cpp:106] Iteration 13420, lr = 0.0002
I0614 17:24:01.544963 15760 solver.cpp:228] Iteration 13440, loss = 0.456598
I0614 17:24:01.544986 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 17:24:01.544992 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139922 (* 1 = 0.139922 loss)
I0614 17:24:01.544996 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.247669 (* 1 = 0.247669 loss)
I0614 17:24:01.545001 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00316397 (* 1 = 0.00316397 loss)
I0614 17:24:01.545003 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.054691 (* 1 = 0.054691 loss)
I0614 17:24:01.545008 15760 sgd_solver.cpp:106] Iteration 13440, lr = 0.0002
I0614 17:25:48.363607 15760 solver.cpp:228] Iteration 13460, loss = 0.595318
I0614 17:25:48.363632 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 17:25:48.363641 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112461 (* 1 = 0.112461 loss)
I0614 17:25:48.363644 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134382 (* 1 = 0.134382 loss)
I0614 17:25:48.363648 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737616 (* 1 = 0.00737616 loss)
I0614 17:25:48.363652 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154722 (* 1 = 0.0154722 loss)
I0614 17:25:48.363657 15760 sgd_solver.cpp:106] Iteration 13460, lr = 0.0002
I0614 17:27:35.468323 15760 solver.cpp:228] Iteration 13480, loss = 0.788379
I0614 17:27:35.468348 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 17:27:35.468356 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.261998 (* 1 = 0.261998 loss)
I0614 17:27:35.468360 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.2559 (* 1 = 0.2559 loss)
I0614 17:27:35.468364 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00664743 (* 1 = 0.00664743 loss)
I0614 17:27:35.468367 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0904141 (* 1 = 0.0904141 loss)
I0614 17:27:35.468372 15760 sgd_solver.cpp:106] Iteration 13480, lr = 0.0002
I0614 17:29:22.146353 15760 solver.cpp:228] Iteration 13500, loss = 0.399712
I0614 17:29:22.146381 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 17:29:22.146391 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.35514 (* 1 = 0.35514 loss)
I0614 17:29:22.146396 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321895 (* 1 = 0.321895 loss)
I0614 17:29:22.146402 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00453125 (* 1 = 0.00453125 loss)
I0614 17:29:22.146409 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658053 (* 1 = 0.0658053 loss)
I0614 17:29:22.146414 15760 sgd_solver.cpp:106] Iteration 13500, lr = 0.0002
I0614 17:31:08.916563 15760 solver.cpp:228] Iteration 13520, loss = 0.591385
I0614 17:31:08.916590 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 17:31:08.916599 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.276126 (* 1 = 0.276126 loss)
I0614 17:31:08.916604 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.478034 (* 1 = 0.478034 loss)
I0614 17:31:08.916609 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0336988 (* 1 = 0.0336988 loss)
I0614 17:31:08.916613 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.476549 (* 1 = 0.476549 loss)
I0614 17:31:08.916618 15760 sgd_solver.cpp:106] Iteration 13520, lr = 0.0002
I0614 17:32:55.698225 15760 solver.cpp:228] Iteration 13540, loss = 0.458412
I0614 17:32:55.698252 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 17:32:55.698262 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.233436 (* 1 = 0.233436 loss)
I0614 17:32:55.698267 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.257637 (* 1 = 0.257637 loss)
I0614 17:32:55.698273 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00397396 (* 1 = 0.00397396 loss)
I0614 17:32:55.698278 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0502488 (* 1 = 0.0502488 loss)
I0614 17:32:55.698284 15760 sgd_solver.cpp:106] Iteration 13540, lr = 0.0002
I0614 17:34:42.560389 15760 solver.cpp:228] Iteration 13560, loss = 0.592344
I0614 17:34:42.560417 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 17:34:42.560428 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0632238 (* 1 = 0.0632238 loss)
I0614 17:34:42.560436 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0972723 (* 1 = 0.0972723 loss)
I0614 17:34:42.560444 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000275902 (* 1 = 0.000275902 loss)
I0614 17:34:42.560452 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142477 (* 1 = 0.0142477 loss)
I0614 17:34:42.560461 15760 sgd_solver.cpp:106] Iteration 13560, lr = 0.0002
I0614 17:36:29.093756 15760 solver.cpp:228] Iteration 13580, loss = 0.696996
I0614 17:36:29.093780 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 17:36:29.093786 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.107951 (* 1 = 0.107951 loss)
I0614 17:36:29.093791 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.123093 (* 1 = 0.123093 loss)
I0614 17:36:29.093794 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122928 (* 1 = 0.00122928 loss)
I0614 17:36:29.093798 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185831 (* 1 = 0.0185831 loss)
I0614 17:36:29.093802 15760 sgd_solver.cpp:106] Iteration 13580, lr = 0.0002
speed: 5.328s / iter
I0614 17:38:15.468065 15760 solver.cpp:228] Iteration 13600, loss = 0.631124
I0614 17:38:15.468091 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 17:38:15.468098 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0879453 (* 1 = 0.0879453 loss)
I0614 17:38:15.468102 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134263 (* 1 = 0.134263 loss)
I0614 17:38:15.468106 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00112976 (* 1 = 0.00112976 loss)
I0614 17:38:15.468111 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214943 (* 1 = 0.0214943 loss)
I0614 17:38:15.468116 15760 sgd_solver.cpp:106] Iteration 13600, lr = 0.0002
I0614 17:40:01.815275 15760 solver.cpp:228] Iteration 13620, loss = 0.464744
I0614 17:40:01.815300 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0614 17:40:01.815309 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0966187 (* 1 = 0.0966187 loss)
I0614 17:40:01.815312 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0645583 (* 1 = 0.0645583 loss)
I0614 17:40:01.815316 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286125 (* 1 = 0.00286125 loss)
I0614 17:40:01.815320 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136917 (* 1 = 0.0136917 loss)
I0614 17:40:01.815325 15760 sgd_solver.cpp:106] Iteration 13620, lr = 0.0002
I0614 17:41:48.229259 15760 solver.cpp:228] Iteration 13640, loss = 0.330434
I0614 17:41:48.229286 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0614 17:41:48.229293 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.468909 (* 1 = 0.468909 loss)
I0614 17:41:48.229298 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.559764 (* 1 = 0.559764 loss)
I0614 17:41:48.229301 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000984817 (* 1 = 0.000984817 loss)
I0614 17:41:48.229305 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0534333 (* 1 = 0.0534333 loss)
I0614 17:41:48.229310 15760 sgd_solver.cpp:106] Iteration 13640, lr = 0.0002
I0614 17:43:35.000177 15760 solver.cpp:228] Iteration 13660, loss = 0.966098
I0614 17:43:35.000202 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 17:43:35.000210 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.268333 (* 1 = 0.268333 loss)
I0614 17:43:35.000216 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.364617 (* 1 = 0.364617 loss)
I0614 17:43:35.000222 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00824144 (* 1 = 0.00824144 loss)
I0614 17:43:35.000226 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0661697 (* 1 = 0.0661697 loss)
I0614 17:43:35.000233 15760 sgd_solver.cpp:106] Iteration 13660, lr = 0.0002
I0614 17:45:21.231032 15760 solver.cpp:228] Iteration 13680, loss = 0.380226
I0614 17:45:21.231058 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 17:45:21.231065 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329726 (* 1 = 0.0329726 loss)
I0614 17:45:21.231070 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128673 (* 1 = 0.128673 loss)
I0614 17:45:21.231073 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00751453 (* 1 = 0.00751453 loss)
I0614 17:45:21.231077 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0583078 (* 1 = 0.0583078 loss)
I0614 17:45:21.231082 15760 sgd_solver.cpp:106] Iteration 13680, lr = 0.0002
I0614 17:47:07.770323 15760 solver.cpp:228] Iteration 13700, loss = 0.602877
I0614 17:47:07.770349 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 17:47:07.770356 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.187544 (* 1 = 0.187544 loss)
I0614 17:47:07.770361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.228344 (* 1 = 0.228344 loss)
I0614 17:47:07.770365 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271995 (* 1 = 0.00271995 loss)
I0614 17:47:07.770370 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0413288 (* 1 = 0.0413288 loss)
I0614 17:47:07.770375 15760 sgd_solver.cpp:106] Iteration 13700, lr = 0.0002
I0614 17:48:54.091547 15760 solver.cpp:228] Iteration 13720, loss = 0.547262
I0614 17:48:54.091572 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 17:48:54.091583 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.219406 (* 1 = 0.219406 loss)
I0614 17:48:54.091588 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.232161 (* 1 = 0.232161 loss)
I0614 17:48:54.091595 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00368201 (* 1 = 0.00368201 loss)
I0614 17:48:54.091601 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317077 (* 1 = 0.0317077 loss)
I0614 17:48:54.091609 15760 sgd_solver.cpp:106] Iteration 13720, lr = 0.0002
I0614 17:50:40.385213 15760 solver.cpp:228] Iteration 13740, loss = 0.349704
I0614 17:50:40.385238 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 17:50:40.385246 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0934915 (* 1 = 0.0934915 loss)
I0614 17:50:40.385249 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.188079 (* 1 = 0.188079 loss)
I0614 17:50:40.385253 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00644962 (* 1 = 0.00644962 loss)
I0614 17:50:40.385257 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295687 (* 1 = 0.0295687 loss)
I0614 17:50:40.385262 15760 sgd_solver.cpp:106] Iteration 13740, lr = 0.0002
I0614 17:52:26.719481 15760 solver.cpp:228] Iteration 13760, loss = 0.828901
I0614 17:52:26.719506 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 17:52:26.719512 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0967877 (* 1 = 0.0967877 loss)
I0614 17:52:26.719516 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0654793 (* 1 = 0.0654793 loss)
I0614 17:52:26.719519 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146714 (* 1 = 0.0146714 loss)
I0614 17:52:26.719523 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243819 (* 1 = 0.0243819 loss)
I0614 17:52:26.719527 15760 sgd_solver.cpp:106] Iteration 13760, lr = 0.0002
I0614 17:54:13.263676 15760 solver.cpp:228] Iteration 13780, loss = 0.492931
I0614 17:54:13.263700 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 17:54:13.263707 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.290226 (* 1 = 0.290226 loss)
I0614 17:54:13.263711 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28943 (* 1 = 0.28943 loss)
I0614 17:54:13.263715 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143503 (* 1 = 0.00143503 loss)
I0614 17:54:13.263718 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0397202 (* 1 = 0.0397202 loss)
I0614 17:54:13.263723 15760 sgd_solver.cpp:106] Iteration 13780, lr = 0.0002
speed: 5.328s / iter
I0614 17:55:59.479811 15760 solver.cpp:228] Iteration 13800, loss = 0.439055
I0614 17:55:59.479836 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 17:55:59.479845 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.198059 (* 1 = 0.198059 loss)
I0614 17:55:59.479849 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.26291 (* 1 = 0.26291 loss)
I0614 17:55:59.479852 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132151 (* 1 = 0.0132151 loss)
I0614 17:55:59.479856 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.146758 (* 1 = 0.146758 loss)
I0614 17:55:59.479861 15760 sgd_solver.cpp:106] Iteration 13800, lr = 0.0002
I0614 17:57:46.063169 15760 solver.cpp:228] Iteration 13820, loss = 0.533912
I0614 17:57:46.063196 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 17:57:46.063205 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685876 (* 1 = 0.0685876 loss)
I0614 17:57:46.063208 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.114188 (* 1 = 0.114188 loss)
I0614 17:57:46.063212 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000424967 (* 1 = 0.000424967 loss)
I0614 17:57:46.063216 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00746131 (* 1 = 0.00746131 loss)
I0614 17:57:46.063221 15760 sgd_solver.cpp:106] Iteration 13820, lr = 0.0002
I0614 17:59:32.336756 15760 solver.cpp:228] Iteration 13840, loss = 0.58386
I0614 17:59:32.336782 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 17:59:32.336791 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.263275 (* 1 = 0.263275 loss)
I0614 17:59:32.336796 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.339368 (* 1 = 0.339368 loss)
I0614 17:59:32.336802 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202177 (* 1 = 0.0202177 loss)
I0614 17:59:32.336807 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.300161 (* 1 = 0.300161 loss)
I0614 17:59:32.336812 15760 sgd_solver.cpp:106] Iteration 13840, lr = 0.0002
I0614 18:01:18.744354 15760 solver.cpp:228] Iteration 13860, loss = 0.313152
I0614 18:01:18.744385 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 18:01:18.744393 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.327249 (* 1 = 0.327249 loss)
I0614 18:01:18.744400 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.342309 (* 1 = 0.342309 loss)
I0614 18:01:18.744405 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00312339 (* 1 = 0.00312339 loss)
I0614 18:01:18.744411 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0427716 (* 1 = 0.0427716 loss)
I0614 18:01:18.744418 15760 sgd_solver.cpp:106] Iteration 13860, lr = 0.0002
I0614 18:03:05.271749 15760 solver.cpp:228] Iteration 13880, loss = 0.506026
I0614 18:03:05.271780 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 18:03:05.271791 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.228817 (* 1 = 0.228817 loss)
I0614 18:03:05.271798 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.1537 (* 1 = 0.1537 loss)
I0614 18:03:05.271806 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135968 (* 1 = 0.0135968 loss)
I0614 18:03:05.271812 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0569789 (* 1 = 0.0569789 loss)
I0614 18:03:05.271818 15760 sgd_solver.cpp:106] Iteration 13880, lr = 0.0002
I0614 18:04:51.993062 15760 solver.cpp:228] Iteration 13900, loss = 0.616554
I0614 18:04:51.993084 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 18:04:51.993091 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.233922 (* 1 = 0.233922 loss)
I0614 18:04:51.993094 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.262585 (* 1 = 0.262585 loss)
I0614 18:04:51.993098 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00543372 (* 1 = 0.00543372 loss)
I0614 18:04:51.993103 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325433 (* 1 = 0.0325433 loss)
I0614 18:04:51.993106 15760 sgd_solver.cpp:106] Iteration 13900, lr = 0.0002
I0614 18:06:38.862329 15760 solver.cpp:228] Iteration 13920, loss = 0.33
I0614 18:06:38.862352 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 18:06:38.862360 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595765 (* 1 = 0.0595765 loss)
I0614 18:06:38.862363 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0725305 (* 1 = 0.0725305 loss)
I0614 18:06:38.862366 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00489072 (* 1 = 0.00489072 loss)
I0614 18:06:38.862370 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171618 (* 1 = 0.0171618 loss)
I0614 18:06:38.862375 15760 sgd_solver.cpp:106] Iteration 13920, lr = 0.0002
I0614 18:08:25.746960 15760 solver.cpp:228] Iteration 13940, loss = 0.734448
I0614 18:08:25.746985 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 18:08:25.746992 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.459648 (* 1 = 0.459648 loss)
I0614 18:08:25.746996 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.508423 (* 1 = 0.508423 loss)
I0614 18:08:25.746999 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538535 (* 1 = 0.00538535 loss)
I0614 18:08:25.747004 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0995911 (* 1 = 0.0995911 loss)
I0614 18:08:25.747009 15760 sgd_solver.cpp:106] Iteration 13940, lr = 0.0002
I0614 18:10:12.656651 15760 solver.cpp:228] Iteration 13960, loss = 0.364828
I0614 18:10:12.656678 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 18:10:12.656688 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.120922 (* 1 = 0.120922 loss)
I0614 18:10:12.656695 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.14472 (* 1 = 0.14472 loss)
I0614 18:10:12.656702 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130725 (* 1 = 0.0130725 loss)
I0614 18:10:12.656708 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199572 (* 1 = 0.0199572 loss)
I0614 18:10:12.656714 15760 sgd_solver.cpp:106] Iteration 13960, lr = 0.0002
I0614 18:11:59.255049 15760 solver.cpp:228] Iteration 13980, loss = 0.731184
I0614 18:11:59.255074 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 18:11:59.255080 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.281739 (* 1 = 0.281739 loss)
I0614 18:11:59.255084 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.320785 (* 1 = 0.320785 loss)
I0614 18:11:59.255089 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00295901 (* 1 = 0.00295901 loss)
I0614 18:11:59.255091 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0756771 (* 1 = 0.0756771 loss)
I0614 18:11:59.255096 15760 sgd_solver.cpp:106] Iteration 13980, lr = 0.0002
speed: 5.328s / iter
I0614 18:13:45.963587 15760 solver.cpp:228] Iteration 14000, loss = 0.668193
I0614 18:13:45.963613 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 18:13:45.963623 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.174969 (* 1 = 0.174969 loss)
I0614 18:13:45.963627 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.190679 (* 1 = 0.190679 loss)
I0614 18:13:45.963634 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00164058 (* 1 = 0.00164058 loss)
I0614 18:13:45.963639 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418051 (* 1 = 0.0418051 loss)
I0614 18:13:45.963645 15760 sgd_solver.cpp:106] Iteration 14000, lr = 0.0002
I0614 18:15:32.958400 15760 solver.cpp:228] Iteration 14020, loss = 0.581371
I0614 18:15:32.958431 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 18:15:32.958441 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.18591 (* 1 = 0.18591 loss)
I0614 18:15:32.958447 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.193256 (* 1 = 0.193256 loss)
I0614 18:15:32.958453 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281775 (* 1 = 0.00281775 loss)
I0614 18:15:32.958458 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232084 (* 1 = 0.0232084 loss)
I0614 18:15:32.958464 15760 sgd_solver.cpp:106] Iteration 14020, lr = 0.0002
I0614 18:17:19.558821 15760 solver.cpp:228] Iteration 14040, loss = 0.569572
I0614 18:17:19.558845 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 18:17:19.558853 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.203765 (* 1 = 0.203765 loss)
I0614 18:17:19.558857 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.211847 (* 1 = 0.211847 loss)
I0614 18:17:19.558861 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186474 (* 1 = 0.0186474 loss)
I0614 18:17:19.558866 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0570313 (* 1 = 0.0570313 loss)
I0614 18:17:19.558871 15760 sgd_solver.cpp:106] Iteration 14040, lr = 0.0002
I0614 18:19:06.005404 15760 solver.cpp:228] Iteration 14060, loss = 0.750372
I0614 18:19:06.005429 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 18:19:06.005437 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.187409 (* 1 = 0.187409 loss)
I0614 18:19:06.005445 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112088 (* 1 = 0.112088 loss)
I0614 18:19:06.005450 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320243 (* 1 = 0.00320243 loss)
I0614 18:19:06.005456 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512794 (* 1 = 0.0512794 loss)
I0614 18:19:06.005462 15760 sgd_solver.cpp:106] Iteration 14060, lr = 0.0002
I0614 18:20:52.753676 15760 solver.cpp:228] Iteration 14080, loss = 0.810969
I0614 18:20:52.753701 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 18:20:52.753708 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.56607 (* 1 = 0.56607 loss)
I0614 18:20:52.753711 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.348609 (* 1 = 0.348609 loss)
I0614 18:20:52.753715 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00188514 (* 1 = 0.00188514 loss)
I0614 18:20:52.753720 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0990219 (* 1 = 0.0990219 loss)
I0614 18:20:52.753723 15760 sgd_solver.cpp:106] Iteration 14080, lr = 0.0002
I0614 18:22:39.073285 15760 solver.cpp:228] Iteration 14100, loss = 0.621275
I0614 18:22:39.073313 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 18:22:39.073320 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.300817 (* 1 = 0.300817 loss)
I0614 18:22:39.073324 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.25568 (* 1 = 0.25568 loss)
I0614 18:22:39.073328 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000870707 (* 1 = 0.000870707 loss)
I0614 18:22:39.073331 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221884 (* 1 = 0.0221884 loss)
I0614 18:22:39.073338 15760 sgd_solver.cpp:106] Iteration 14100, lr = 0.0002
I0614 18:24:25.422291 15760 solver.cpp:228] Iteration 14120, loss = 0.567931
I0614 18:24:25.422317 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 18:24:25.422323 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.299916 (* 1 = 0.299916 loss)
I0614 18:24:25.422327 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.25569 (* 1 = 0.25569 loss)
I0614 18:24:25.422333 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173064 (* 1 = 0.00173064 loss)
I0614 18:24:25.422336 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013458 (* 1 = 0.013458 loss)
I0614 18:24:25.422343 15760 sgd_solver.cpp:106] Iteration 14120, lr = 0.0002
I0614 18:26:11.798015 15760 solver.cpp:228] Iteration 14140, loss = 0.696404
I0614 18:26:11.798041 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 18:26:11.798049 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.106577 (* 1 = 0.106577 loss)
I0614 18:26:11.798053 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.181346 (* 1 = 0.181346 loss)
I0614 18:26:11.798058 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130339 (* 1 = 0.00130339 loss)
I0614 18:26:11.798061 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161027 (* 1 = 0.0161027 loss)
I0614 18:26:11.798068 15760 sgd_solver.cpp:106] Iteration 14140, lr = 0.0002
I0614 18:27:58.011299 15760 solver.cpp:228] Iteration 14160, loss = 0.534466
I0614 18:27:58.011324 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0614 18:27:58.011332 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.617286 (* 1 = 0.617286 loss)
I0614 18:27:58.011335 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.594014 (* 1 = 0.594014 loss)
I0614 18:27:58.011339 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0311594 (* 1 = 0.0311594 loss)
I0614 18:27:58.011343 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.276344 (* 1 = 0.276344 loss)
I0614 18:27:58.011348 15760 sgd_solver.cpp:106] Iteration 14160, lr = 0.0002
I0614 18:29:44.432662 15760 solver.cpp:228] Iteration 14180, loss = 0.655802
I0614 18:29:44.432687 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 18:29:44.432693 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0970971 (* 1 = 0.0970971 loss)
I0614 18:29:44.432698 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0952472 (* 1 = 0.0952472 loss)
I0614 18:29:44.432701 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000248273 (* 1 = 0.000248273 loss)
I0614 18:29:44.432704 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00818945 (* 1 = 0.00818945 loss)
I0614 18:29:44.432709 15760 sgd_solver.cpp:106] Iteration 14180, lr = 0.0002
speed: 5.328s / iter
I0614 18:31:30.878319 15760 solver.cpp:228] Iteration 14200, loss = 0.469486
I0614 18:31:30.878345 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 18:31:30.878353 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0942445 (* 1 = 0.0942445 loss)
I0614 18:31:30.878357 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.132486 (* 1 = 0.132486 loss)
I0614 18:31:30.878361 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205495 (* 1 = 0.00205495 loss)
I0614 18:31:30.878365 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160554 (* 1 = 0.0160554 loss)
I0614 18:31:30.878371 15760 sgd_solver.cpp:106] Iteration 14200, lr = 0.0002
I0614 18:33:17.277614 15760 solver.cpp:228] Iteration 14220, loss = 0.642889
I0614 18:33:17.277642 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 18:33:17.277649 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.141551 (* 1 = 0.141551 loss)
I0614 18:33:17.277653 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113442 (* 1 = 0.113442 loss)
I0614 18:33:17.277657 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00949629 (* 1 = 0.00949629 loss)
I0614 18:33:17.277662 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0694136 (* 1 = 0.0694136 loss)
I0614 18:33:17.277667 15760 sgd_solver.cpp:106] Iteration 14220, lr = 0.0002
I0614 18:35:03.605890 15760 solver.cpp:228] Iteration 14240, loss = 0.311855
I0614 18:35:03.605913 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 18:35:03.605921 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.304618 (* 1 = 0.304618 loss)
I0614 18:35:03.605924 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.286753 (* 1 = 0.286753 loss)
I0614 18:35:03.605927 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155978 (* 1 = 0.00155978 loss)
I0614 18:35:03.605931 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0412617 (* 1 = 0.0412617 loss)
I0614 18:35:03.605937 15760 sgd_solver.cpp:106] Iteration 14240, lr = 0.0002
I0614 18:36:50.204499 15760 solver.cpp:228] Iteration 14260, loss = 0.487353
I0614 18:36:50.204522 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 18:36:50.204530 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0962231 (* 1 = 0.0962231 loss)
I0614 18:36:50.204533 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0759883 (* 1 = 0.0759883 loss)
I0614 18:36:50.204537 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167031 (* 1 = 0.00167031 loss)
I0614 18:36:50.204540 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138305 (* 1 = 0.0138305 loss)
I0614 18:36:50.204545 15760 sgd_solver.cpp:106] Iteration 14260, lr = 0.0002
I0614 18:38:36.663722 15760 solver.cpp:228] Iteration 14280, loss = 0.60863
I0614 18:38:36.663748 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 18:38:36.663756 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.153267 (* 1 = 0.153267 loss)
I0614 18:38:36.663763 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.178157 (* 1 = 0.178157 loss)
I0614 18:38:36.663767 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00549689 (* 1 = 0.00549689 loss)
I0614 18:38:36.663774 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110118 (* 1 = 0.0110118 loss)
I0614 18:38:36.663779 15760 sgd_solver.cpp:106] Iteration 14280, lr = 0.0002
I0614 18:40:23.118942 15760 solver.cpp:228] Iteration 14300, loss = 0.793492
I0614 18:40:23.118966 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0614 18:40:23.118973 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.57122 (* 1 = 0.57122 loss)
I0614 18:40:23.118978 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.545446 (* 1 = 0.545446 loss)
I0614 18:40:23.118981 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511225 (* 1 = 0.00511225 loss)
I0614 18:40:23.118985 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.187184 (* 1 = 0.187184 loss)
I0614 18:40:23.118990 15760 sgd_solver.cpp:106] Iteration 14300, lr = 0.0002
I0614 18:42:09.498620 15760 solver.cpp:228] Iteration 14320, loss = 0.514429
I0614 18:42:09.498646 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 18:42:09.498652 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.226757 (* 1 = 0.226757 loss)
I0614 18:42:09.498656 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.237449 (* 1 = 0.237449 loss)
I0614 18:42:09.498659 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412095 (* 1 = 0.00412095 loss)
I0614 18:42:09.498663 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0826108 (* 1 = 0.0826108 loss)
I0614 18:42:09.498669 15760 sgd_solver.cpp:106] Iteration 14320, lr = 0.0002
I0614 18:43:55.931291 15760 solver.cpp:228] Iteration 14340, loss = 0.690696
I0614 18:43:55.931314 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0614 18:43:55.931321 15760 solver.cpp:244]     Train net output #1: loss_bbox = 1.14908 (* 1 = 1.14908 loss)
I0614 18:43:55.931325 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.886198 (* 1 = 0.886198 loss)
I0614 18:43:55.931329 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0558369 (* 1 = 0.0558369 loss)
I0614 18:43:55.931332 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.633855 (* 1 = 0.633855 loss)
I0614 18:43:55.931336 15760 sgd_solver.cpp:106] Iteration 14340, lr = 0.0002
I0614 18:45:42.354871 15760 solver.cpp:228] Iteration 14360, loss = 0.714008
I0614 18:45:42.354897 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 18:45:42.354904 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.220488 (* 1 = 0.220488 loss)
I0614 18:45:42.354908 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.222568 (* 1 = 0.222568 loss)
I0614 18:45:42.354913 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00279289 (* 1 = 0.00279289 loss)
I0614 18:45:42.354917 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226468 (* 1 = 0.0226468 loss)
I0614 18:45:42.354921 15760 sgd_solver.cpp:106] Iteration 14360, lr = 0.0002
I0614 18:47:28.626293 15760 solver.cpp:228] Iteration 14380, loss = 0.637443
I0614 18:47:28.626317 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0614 18:47:28.626324 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.563639 (* 1 = 0.563639 loss)
I0614 18:47:28.626328 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.689076 (* 1 = 0.689076 loss)
I0614 18:47:28.626332 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127537 (* 1 = 0.0127537 loss)
I0614 18:47:28.626336 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.289983 (* 1 = 0.289983 loss)
I0614 18:47:28.626343 15760 sgd_solver.cpp:106] Iteration 14380, lr = 0.0002
speed: 5.328s / iter
I0614 18:49:15.129612 15760 solver.cpp:228] Iteration 14400, loss = 0.700495
I0614 18:49:15.129634 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 18:49:15.129642 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146377 (* 1 = 0.146377 loss)
I0614 18:49:15.129645 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117944 (* 1 = 0.117944 loss)
I0614 18:49:15.129649 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00030397 (* 1 = 0.00030397 loss)
I0614 18:49:15.129652 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338628 (* 1 = 0.0338628 loss)
I0614 18:49:15.129657 15760 sgd_solver.cpp:106] Iteration 14400, lr = 0.0002
I0614 18:51:02.161015 15760 solver.cpp:228] Iteration 14420, loss = 0.394747
I0614 18:51:02.161041 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 18:51:02.161051 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.225935 (* 1 = 0.225935 loss)
I0614 18:51:02.161056 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.176606 (* 1 = 0.176606 loss)
I0614 18:51:02.161061 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000274968 (* 1 = 0.000274968 loss)
I0614 18:51:02.161064 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335023 (* 1 = 0.0335023 loss)
I0614 18:51:02.161072 15760 sgd_solver.cpp:106] Iteration 14420, lr = 0.0002
I0614 18:52:49.027523 15760 solver.cpp:228] Iteration 14440, loss = 0.351805
I0614 18:52:49.027547 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 18:52:49.027554 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.174717 (* 1 = 0.174717 loss)
I0614 18:52:49.027559 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206226 (* 1 = 0.206226 loss)
I0614 18:52:49.027564 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000456498 (* 1 = 0.000456498 loss)
I0614 18:52:49.027567 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278052 (* 1 = 0.0278052 loss)
I0614 18:52:49.027572 15760 sgd_solver.cpp:106] Iteration 14440, lr = 0.0002
I0614 18:54:36.087287 15760 solver.cpp:228] Iteration 14460, loss = 0.566743
I0614 18:54:36.087311 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 18:54:36.087318 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.345979 (* 1 = 0.345979 loss)
I0614 18:54:36.087322 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.400267 (* 1 = 0.400267 loss)
I0614 18:54:36.087326 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212531 (* 1 = 0.0212531 loss)
I0614 18:54:36.087329 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113816 (* 1 = 0.113816 loss)
I0614 18:54:36.087334 15760 sgd_solver.cpp:106] Iteration 14460, lr = 0.0002
I0614 18:56:23.151150 15760 solver.cpp:228] Iteration 14480, loss = 0.465836
I0614 18:56:23.151176 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 18:56:23.151185 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.161177 (* 1 = 0.161177 loss)
I0614 18:56:23.151190 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.218965 (* 1 = 0.218965 loss)
I0614 18:56:23.151195 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00335424 (* 1 = 0.00335424 loss)
I0614 18:56:23.151198 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0625959 (* 1 = 0.0625959 loss)
I0614 18:56:23.151204 15760 sgd_solver.cpp:106] Iteration 14480, lr = 0.0002
I0614 18:58:09.934640 15760 solver.cpp:228] Iteration 14500, loss = 0.687473
I0614 18:58:09.934664 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 18:58:09.934672 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.105656 (* 1 = 0.105656 loss)
I0614 18:58:09.934676 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167378 (* 1 = 0.167378 loss)
I0614 18:58:09.934680 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000492243 (* 1 = 0.000492243 loss)
I0614 18:58:09.934684 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00529568 (* 1 = 0.00529568 loss)
I0614 18:58:09.934689 15760 sgd_solver.cpp:106] Iteration 14500, lr = 0.0002
I0614 18:59:56.660271 15760 solver.cpp:228] Iteration 14520, loss = 0.534546
I0614 18:59:56.660295 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 18:59:56.660301 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.264752 (* 1 = 0.264752 loss)
I0614 18:59:56.660305 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.244343 (* 1 = 0.244343 loss)
I0614 18:59:56.660308 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0834005 (* 1 = 0.0834005 loss)
I0614 18:59:56.660312 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.45743 (* 1 = 0.45743 loss)
I0614 18:59:56.660316 15760 sgd_solver.cpp:106] Iteration 14520, lr = 0.0002
I0614 19:01:43.518486 15760 solver.cpp:228] Iteration 14540, loss = 0.732817
I0614 19:01:43.518517 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 19:01:43.518527 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.176998 (* 1 = 0.176998 loss)
I0614 19:01:43.518532 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.146315 (* 1 = 0.146315 loss)
I0614 19:01:43.518538 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00349948 (* 1 = 0.00349948 loss)
I0614 19:01:43.518544 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326962 (* 1 = 0.0326962 loss)
I0614 19:01:43.518551 15760 sgd_solver.cpp:106] Iteration 14540, lr = 0.0002
I0614 19:03:30.228675 15760 solver.cpp:228] Iteration 14560, loss = 0.461126
I0614 19:03:30.228700 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 19:03:30.228708 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.559536 (* 1 = 0.559536 loss)
I0614 19:03:30.228713 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.50291 (* 1 = 0.50291 loss)
I0614 19:03:30.228716 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137756 (* 1 = 0.0137756 loss)
I0614 19:03:30.228719 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168638 (* 1 = 0.168638 loss)
I0614 19:03:30.228725 15760 sgd_solver.cpp:106] Iteration 14560, lr = 0.0002
I0614 19:05:16.697127 15760 solver.cpp:228] Iteration 14580, loss = 0.34108
I0614 19:05:16.697149 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 19:05:16.697156 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.31612 (* 1 = 0.31612 loss)
I0614 19:05:16.697160 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.331947 (* 1 = 0.331947 loss)
I0614 19:05:16.697165 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0250191 (* 1 = 0.0250191 loss)
I0614 19:05:16.697167 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.126868 (* 1 = 0.126868 loss)
I0614 19:05:16.697172 15760 sgd_solver.cpp:106] Iteration 14580, lr = 0.0002
speed: 5.328s / iter
I0614 19:07:03.870884 15760 solver.cpp:228] Iteration 14600, loss = 0.278792
I0614 19:07:03.870914 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 19:07:03.870924 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.103848 (* 1 = 0.103848 loss)
I0614 19:07:03.870930 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0584002 (* 1 = 0.0584002 loss)
I0614 19:07:03.870935 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112902 (* 1 = 0.0112902 loss)
I0614 19:07:03.870940 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00652989 (* 1 = 0.00652989 loss)
I0614 19:07:03.870947 15760 sgd_solver.cpp:106] Iteration 14600, lr = 0.0002
I0614 19:08:50.391095 15760 solver.cpp:228] Iteration 14620, loss = 0.637718
I0614 19:08:50.391120 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 19:08:50.391129 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.231133 (* 1 = 0.231133 loss)
I0614 19:08:50.391132 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.321788 (* 1 = 0.321788 loss)
I0614 19:08:50.391136 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213079 (* 1 = 0.00213079 loss)
I0614 19:08:50.391140 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021974 (* 1 = 0.021974 loss)
I0614 19:08:50.391145 15760 sgd_solver.cpp:106] Iteration 14620, lr = 0.0002
I0614 19:10:36.794730 15760 solver.cpp:228] Iteration 14640, loss = 0.549589
I0614 19:10:36.794756 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 19:10:36.794764 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.346692 (* 1 = 0.346692 loss)
I0614 19:10:36.794770 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.286979 (* 1 = 0.286979 loss)
I0614 19:10:36.794773 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053355 (* 1 = 0.0053355 loss)
I0614 19:10:36.794777 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.186689 (* 1 = 0.186689 loss)
I0614 19:10:36.794783 15760 sgd_solver.cpp:106] Iteration 14640, lr = 0.0002
I0614 19:12:23.637605 15760 solver.cpp:228] Iteration 14660, loss = 0.537083
I0614 19:12:23.637630 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 19:12:23.637639 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.230434 (* 1 = 0.230434 loss)
I0614 19:12:23.637643 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.293871 (* 1 = 0.293871 loss)
I0614 19:12:23.637647 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388766 (* 1 = 0.00388766 loss)
I0614 19:12:23.637652 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0576995 (* 1 = 0.0576995 loss)
I0614 19:12:23.637657 15760 sgd_solver.cpp:106] Iteration 14660, lr = 0.0002
I0614 19:14:10.037891 15760 solver.cpp:228] Iteration 14680, loss = 0.611148
I0614 19:14:10.037915 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 19:14:10.037922 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.158072 (* 1 = 0.158072 loss)
I0614 19:14:10.037926 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.267493 (* 1 = 0.267493 loss)
I0614 19:14:10.037930 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00575808 (* 1 = 0.00575808 loss)
I0614 19:14:10.037935 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0764045 (* 1 = 0.0764045 loss)
I0614 19:14:10.037940 15760 sgd_solver.cpp:106] Iteration 14680, lr = 0.0002
I0614 19:15:56.378660 15760 solver.cpp:228] Iteration 14700, loss = 0.707919
I0614 19:15:56.378685 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 19:15:56.378692 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.350031 (* 1 = 0.350031 loss)
I0614 19:15:56.378696 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.358457 (* 1 = 0.358457 loss)
I0614 19:15:56.378700 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000436242 (* 1 = 0.000436242 loss)
I0614 19:15:56.378705 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368863 (* 1 = 0.0368863 loss)
I0614 19:15:56.378710 15760 sgd_solver.cpp:106] Iteration 14700, lr = 0.0002
I0614 19:17:42.828703 15760 solver.cpp:228] Iteration 14720, loss = 0.365481
I0614 19:17:42.828729 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 19:17:42.828737 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0290032 (* 1 = 0.0290032 loss)
I0614 19:17:42.828742 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0859489 (* 1 = 0.0859489 loss)
I0614 19:17:42.828745 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0172131 (* 1 = 0.0172131 loss)
I0614 19:17:42.828749 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247186 (* 1 = 0.0247186 loss)
I0614 19:17:42.828754 15760 sgd_solver.cpp:106] Iteration 14720, lr = 0.0002
I0614 19:19:29.416072 15760 solver.cpp:228] Iteration 14740, loss = 0.751895
I0614 19:19:29.416095 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 19:19:29.416102 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.167827 (* 1 = 0.167827 loss)
I0614 19:19:29.416106 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.358349 (* 1 = 0.358349 loss)
I0614 19:19:29.416110 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00726349 (* 1 = 0.00726349 loss)
I0614 19:19:29.416113 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.381047 (* 1 = 0.381047 loss)
I0614 19:19:29.416117 15760 sgd_solver.cpp:106] Iteration 14740, lr = 0.0002
I0614 19:21:15.735152 15760 solver.cpp:228] Iteration 14760, loss = 0.598756
I0614 19:21:15.735178 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 19:21:15.735186 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.682387 (* 1 = 0.682387 loss)
I0614 19:21:15.735190 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.535257 (* 1 = 0.535257 loss)
I0614 19:21:15.735194 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019213 (* 1 = 0.019213 loss)
I0614 19:21:15.735198 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.198802 (* 1 = 0.198802 loss)
I0614 19:21:15.735204 15760 sgd_solver.cpp:106] Iteration 14760, lr = 0.0002
I0614 19:23:02.025406 15760 solver.cpp:228] Iteration 14780, loss = 0.570602
I0614 19:23:02.025439 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 19:23:02.025450 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101801 (* 1 = 0.101801 loss)
I0614 19:23:02.025457 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.111886 (* 1 = 0.111886 loss)
I0614 19:23:02.025465 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00860439 (* 1 = 0.00860439 loss)
I0614 19:23:02.025471 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216013 (* 1 = 0.0216013 loss)
I0614 19:23:02.025478 15760 sgd_solver.cpp:106] Iteration 14780, lr = 0.0002
speed: 5.328s / iter
I0614 19:24:48.250190 15760 solver.cpp:228] Iteration 14800, loss = 0.562507
I0614 19:24:48.250216 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 19:24:48.250222 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.275403 (* 1 = 0.275403 loss)
I0614 19:24:48.250226 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28943 (* 1 = 0.28943 loss)
I0614 19:24:48.250229 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00200461 (* 1 = 0.00200461 loss)
I0614 19:24:48.250233 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222214 (* 1 = 0.0222214 loss)
I0614 19:24:48.250238 15760 sgd_solver.cpp:106] Iteration 14800, lr = 0.0002
I0614 19:26:34.880084 15760 solver.cpp:228] Iteration 14820, loss = 0.442046
I0614 19:26:34.880110 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 19:26:34.880117 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.321565 (* 1 = 0.321565 loss)
I0614 19:26:34.880121 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.257397 (* 1 = 0.257397 loss)
I0614 19:26:34.880125 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260334 (* 1 = 0.00260334 loss)
I0614 19:26:34.880129 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0548048 (* 1 = 0.0548048 loss)
I0614 19:26:34.880134 15760 sgd_solver.cpp:106] Iteration 14820, lr = 0.0002
I0614 19:28:21.560446 15760 solver.cpp:228] Iteration 14840, loss = 0.497504
I0614 19:28:21.560475 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 19:28:21.560485 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.124239 (* 1 = 0.124239 loss)
I0614 19:28:21.560492 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.142961 (* 1 = 0.142961 loss)
I0614 19:28:21.560499 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00368488 (* 1 = 0.00368488 loss)
I0614 19:28:21.560506 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112728 (* 1 = 0.0112728 loss)
I0614 19:28:21.560515 15760 sgd_solver.cpp:106] Iteration 14840, lr = 0.0002
I0614 19:30:08.160974 15760 solver.cpp:228] Iteration 14860, loss = 0.470882
I0614 19:30:08.161005 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 19:30:08.161015 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0809592 (* 1 = 0.0809592 loss)
I0614 19:30:08.161020 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.203268 (* 1 = 0.203268 loss)
I0614 19:30:08.161026 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000196692 (* 1 = 0.000196692 loss)
I0614 19:30:08.161032 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106022 (* 1 = 0.0106022 loss)
I0614 19:30:08.161039 15760 sgd_solver.cpp:106] Iteration 14860, lr = 0.0002
I0614 19:31:55.601583 15760 solver.cpp:228] Iteration 14880, loss = 0.936446
I0614 19:31:55.601625 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 19:31:55.601642 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.361144 (* 1 = 0.361144 loss)
I0614 19:31:55.601652 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.26313 (* 1 = 0.26313 loss)
I0614 19:31:55.601662 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00969257 (* 1 = 0.00969257 loss)
I0614 19:31:55.601670 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0602885 (* 1 = 0.0602885 loss)
I0614 19:31:55.601681 15760 sgd_solver.cpp:106] Iteration 14880, lr = 0.0002
I0614 19:33:43.325769 15760 solver.cpp:228] Iteration 14900, loss = 0.362974
I0614 19:33:43.325794 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 19:33:43.325803 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0582025 (* 1 = 0.0582025 loss)
I0614 19:33:43.325808 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0866972 (* 1 = 0.0866972 loss)
I0614 19:33:43.325811 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000506294 (* 1 = 0.000506294 loss)
I0614 19:33:43.325814 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268911 (* 1 = 0.0268911 loss)
I0614 19:33:43.325819 15760 sgd_solver.cpp:106] Iteration 14900, lr = 0.0002
I0614 19:35:30.042043 15760 solver.cpp:228] Iteration 14920, loss = 0.452179
I0614 19:35:30.042068 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 19:35:30.042074 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542466 (* 1 = 0.0542466 loss)
I0614 19:35:30.042078 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0834582 (* 1 = 0.0834582 loss)
I0614 19:35:30.042083 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00578046 (* 1 = 0.00578046 loss)
I0614 19:35:30.042085 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118826 (* 1 = 0.0118826 loss)
I0614 19:35:30.042090 15760 sgd_solver.cpp:106] Iteration 14920, lr = 0.0002
I0614 19:37:17.138984 15760 solver.cpp:228] Iteration 14940, loss = 0.484866
I0614 19:37:17.139024 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 19:37:17.139032 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.481175 (* 1 = 0.481175 loss)
I0614 19:37:17.139036 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.360428 (* 1 = 0.360428 loss)
I0614 19:37:17.139040 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273582 (* 1 = 0.00273582 loss)
I0614 19:37:17.139045 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0489439 (* 1 = 0.0489439 loss)
I0614 19:37:17.139051 15760 sgd_solver.cpp:106] Iteration 14940, lr = 0.0002
I0614 19:39:04.541193 15760 solver.cpp:228] Iteration 14960, loss = 0.495027
I0614 19:39:04.541219 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 19:39:04.541229 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.163837 (* 1 = 0.163837 loss)
I0614 19:39:04.541234 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.157734 (* 1 = 0.157734 loss)
I0614 19:39:04.541239 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00018919 (* 1 = 0.00018919 loss)
I0614 19:39:04.541245 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179903 (* 1 = 0.0179903 loss)
I0614 19:39:04.541254 15760 sgd_solver.cpp:106] Iteration 14960, lr = 0.0002
I0614 19:40:50.805522 15760 solver.cpp:228] Iteration 14980, loss = 0.56931
I0614 19:40:50.805546 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 19:40:50.805552 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.438712 (* 1 = 0.438712 loss)
I0614 19:40:50.805555 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.505025 (* 1 = 0.505025 loss)
I0614 19:40:50.805559 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0227825 (* 1 = 0.0227825 loss)
I0614 19:40:50.805563 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.362127 (* 1 = 0.362127 loss)
I0614 19:40:50.805568 15760 sgd_solver.cpp:106] Iteration 14980, lr = 0.0002
speed: 5.329s / iter
I0614 19:42:32.617770 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_15000.caffemodel
I0614 19:42:38.408032 15760 solver.cpp:228] Iteration 15000, loss = 0.271175
I0614 19:42:38.408074 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 19:42:38.408083 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.182353 (* 1 = 0.182353 loss)
I0614 19:42:38.408088 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.204806 (* 1 = 0.204806 loss)
I0614 19:42:38.408092 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0046805 (* 1 = 0.0046805 loss)
I0614 19:42:38.408095 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0589554 (* 1 = 0.0589554 loss)
I0614 19:42:38.408102 15760 sgd_solver.cpp:106] Iteration 15000, lr = 0.0002
I0614 19:44:25.744413 15760 solver.cpp:228] Iteration 15020, loss = 0.737909
I0614 19:44:25.744436 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 19:44:25.744443 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.16169 (* 1 = 0.16169 loss)
I0614 19:44:25.744447 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.188988 (* 1 = 0.188988 loss)
I0614 19:44:25.744451 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00939888 (* 1 = 0.00939888 loss)
I0614 19:44:25.744454 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0283233 (* 1 = 0.0283233 loss)
I0614 19:44:25.744458 15760 sgd_solver.cpp:106] Iteration 15020, lr = 0.0002
I0614 19:46:12.844733 15760 solver.cpp:228] Iteration 15040, loss = 0.494573
I0614 19:46:12.844760 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 19:46:12.844769 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.526707 (* 1 = 0.526707 loss)
I0614 19:46:12.844774 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.361033 (* 1 = 0.361033 loss)
I0614 19:46:12.844779 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00677298 (* 1 = 0.00677298 loss)
I0614 19:46:12.844784 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103293 (* 1 = 0.103293 loss)
I0614 19:46:12.844789 15760 sgd_solver.cpp:106] Iteration 15040, lr = 0.0002
I0614 19:47:59.655026 15760 solver.cpp:228] Iteration 15060, loss = 0.64263
I0614 19:47:59.655052 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0614 19:47:59.655063 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.721514 (* 1 = 0.721514 loss)
I0614 19:47:59.655071 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.532129 (* 1 = 0.532129 loss)
I0614 19:47:59.655076 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00771531 (* 1 = 0.00771531 loss)
I0614 19:47:59.655082 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109375 (* 1 = 0.109375 loss)
I0614 19:47:59.655091 15760 sgd_solver.cpp:106] Iteration 15060, lr = 0.0002
I0614 19:49:46.437322 15760 solver.cpp:228] Iteration 15080, loss = 0.779905
I0614 19:49:46.437348 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0614 19:49:46.437355 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.634212 (* 1 = 0.634212 loss)
I0614 19:49:46.437361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.494233 (* 1 = 0.494233 loss)
I0614 19:49:46.437364 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00190362 (* 1 = 0.00190362 loss)
I0614 19:49:46.437368 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0951563 (* 1 = 0.0951563 loss)
I0614 19:49:46.437373 15760 sgd_solver.cpp:106] Iteration 15080, lr = 0.0002
I0614 19:51:33.214886 15760 solver.cpp:228] Iteration 15100, loss = 0.515471
I0614 19:51:33.214911 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 19:51:33.214920 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882523 (* 1 = 0.0882523 loss)
I0614 19:51:33.214926 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130347 (* 1 = 0.130347 loss)
I0614 19:51:33.214931 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00170295 (* 1 = 0.00170295 loss)
I0614 19:51:33.214937 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00853327 (* 1 = 0.00853327 loss)
I0614 19:51:33.214943 15760 sgd_solver.cpp:106] Iteration 15100, lr = 0.0002
I0614 19:53:19.968605 15760 solver.cpp:228] Iteration 15120, loss = 0.320543
I0614 19:53:19.968636 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 19:53:19.968647 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0903652 (* 1 = 0.0903652 loss)
I0614 19:53:19.968653 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0766149 (* 1 = 0.0766149 loss)
I0614 19:53:19.968659 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.89903e-05 (* 1 = 9.89903e-05 loss)
I0614 19:53:19.968667 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138112 (* 1 = 0.0138112 loss)
I0614 19:53:19.968673 15760 sgd_solver.cpp:106] Iteration 15120, lr = 0.0002
I0614 19:55:06.455055 15760 solver.cpp:228] Iteration 15140, loss = 0.752382
I0614 19:55:06.455080 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 19:55:06.455087 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.276319 (* 1 = 0.276319 loss)
I0614 19:55:06.455091 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.289318 (* 1 = 0.289318 loss)
I0614 19:55:06.455094 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167566 (* 1 = 0.00167566 loss)
I0614 19:55:06.455098 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0459467 (* 1 = 0.0459467 loss)
I0614 19:55:06.455102 15760 sgd_solver.cpp:106] Iteration 15140, lr = 0.0002
I0614 19:56:53.105474 15760 solver.cpp:228] Iteration 15160, loss = 0.597565
I0614 19:56:53.105512 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 19:56:53.105520 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.169891 (* 1 = 0.169891 loss)
I0614 19:56:53.105525 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.190827 (* 1 = 0.190827 loss)
I0614 19:56:53.105530 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00506634 (* 1 = 0.00506634 loss)
I0614 19:56:53.105532 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317989 (* 1 = 0.0317989 loss)
I0614 19:56:53.105540 15760 sgd_solver.cpp:106] Iteration 15160, lr = 0.0002
I0614 19:58:39.880437 15760 solver.cpp:228] Iteration 15180, loss = 0.343842
I0614 19:58:39.880462 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 19:58:39.880470 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.209681 (* 1 = 0.209681 loss)
I0614 19:58:39.880473 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.233701 (* 1 = 0.233701 loss)
I0614 19:58:39.880478 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168112 (* 1 = 0.00168112 loss)
I0614 19:58:39.880482 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286894 (* 1 = 0.0286894 loss)
I0614 19:58:39.880487 15760 sgd_solver.cpp:106] Iteration 15180, lr = 0.0002
speed: 5.329s / iter
I0614 20:00:26.595957 15760 solver.cpp:228] Iteration 15200, loss = 0.320742
I0614 20:00:26.595981 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 20:00:26.595989 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113424 (* 1 = 0.113424 loss)
I0614 20:00:26.595993 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109079 (* 1 = 0.109079 loss)
I0614 20:00:26.595998 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0095979 (* 1 = 0.0095979 loss)
I0614 20:00:26.596001 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00671321 (* 1 = 0.00671321 loss)
I0614 20:00:26.596006 15760 sgd_solver.cpp:106] Iteration 15200, lr = 0.0002
I0614 20:02:12.927043 15760 solver.cpp:228] Iteration 15220, loss = 0.378902
I0614 20:02:12.927069 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 20:02:12.927078 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0771553 (* 1 = 0.0771553 loss)
I0614 20:02:12.927083 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0933948 (* 1 = 0.0933948 loss)
I0614 20:02:12.927086 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0027674 (* 1 = 0.0027674 loss)
I0614 20:02:12.927089 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292318 (* 1 = 0.0292318 loss)
I0614 20:02:12.927095 15760 sgd_solver.cpp:106] Iteration 15220, lr = 0.0002
I0614 20:03:59.244928 15760 solver.cpp:228] Iteration 15240, loss = 0.335006
I0614 20:03:59.244958 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 20:03:59.244967 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194839 (* 1 = 0.194839 loss)
I0614 20:03:59.244973 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171859 (* 1 = 0.171859 loss)
I0614 20:03:59.244979 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000515161 (* 1 = 0.000515161 loss)
I0614 20:03:59.244985 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022619 (* 1 = 0.022619 loss)
I0614 20:03:59.244992 15760 sgd_solver.cpp:106] Iteration 15240, lr = 0.0002
I0614 20:05:45.751945 15760 solver.cpp:228] Iteration 15260, loss = 0.446915
I0614 20:05:45.751969 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 20:05:45.751976 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.266078 (* 1 = 0.266078 loss)
I0614 20:05:45.751979 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.271258 (* 1 = 0.271258 loss)
I0614 20:05:45.751983 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000875315 (* 1 = 0.000875315 loss)
I0614 20:05:45.751986 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025655 (* 1 = 0.025655 loss)
I0614 20:05:45.751991 15760 sgd_solver.cpp:106] Iteration 15260, lr = 0.0002
I0614 20:07:31.996986 15760 solver.cpp:228] Iteration 15280, loss = 0.626123
I0614 20:07:31.997009 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 20:07:31.997016 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.447788 (* 1 = 0.447788 loss)
I0614 20:07:31.997020 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.418503 (* 1 = 0.418503 loss)
I0614 20:07:31.997023 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213622 (* 1 = 0.0213622 loss)
I0614 20:07:31.997027 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148042 (* 1 = 0.148042 loss)
I0614 20:07:31.997032 15760 sgd_solver.cpp:106] Iteration 15280, lr = 0.0002
I0614 20:09:18.367251 15760 solver.cpp:228] Iteration 15300, loss = 0.532536
I0614 20:09:18.367275 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 20:09:18.367283 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.562058 (* 1 = 0.562058 loss)
I0614 20:09:18.367287 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.388008 (* 1 = 0.388008 loss)
I0614 20:09:18.367291 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192138 (* 1 = 0.0192138 loss)
I0614 20:09:18.367295 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.190826 (* 1 = 0.190826 loss)
I0614 20:09:18.367300 15760 sgd_solver.cpp:106] Iteration 15300, lr = 0.0002
I0614 20:11:04.809805 15760 solver.cpp:228] Iteration 15320, loss = 0.843005
I0614 20:11:04.809830 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 20:11:04.809837 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.355006 (* 1 = 0.355006 loss)
I0614 20:11:04.809842 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.327118 (* 1 = 0.327118 loss)
I0614 20:11:04.809846 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00323133 (* 1 = 0.00323133 loss)
I0614 20:11:04.809850 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106593 (* 1 = 0.106593 loss)
I0614 20:11:04.809855 15760 sgd_solver.cpp:106] Iteration 15320, lr = 0.0002
I0614 20:12:51.457197 15760 solver.cpp:228] Iteration 15340, loss = 0.271988
I0614 20:12:51.457221 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 20:12:51.457228 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.227137 (* 1 = 0.227137 loss)
I0614 20:12:51.457232 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195558 (* 1 = 0.195558 loss)
I0614 20:12:51.457237 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249355 (* 1 = 0.00249355 loss)
I0614 20:12:51.457239 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030171 (* 1 = 0.030171 loss)
I0614 20:12:51.457245 15760 sgd_solver.cpp:106] Iteration 15340, lr = 0.0002
I0614 20:14:37.940563 15760 solver.cpp:228] Iteration 15360, loss = 0.546842
I0614 20:14:37.940587 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 20:14:37.940593 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0856389 (* 1 = 0.0856389 loss)
I0614 20:14:37.940598 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.187995 (* 1 = 0.187995 loss)
I0614 20:14:37.940600 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00568102 (* 1 = 0.00568102 loss)
I0614 20:14:37.940604 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.06327 (* 1 = 0.06327 loss)
I0614 20:14:37.940608 15760 sgd_solver.cpp:106] Iteration 15360, lr = 0.0002
I0614 20:16:24.960594 15760 solver.cpp:228] Iteration 15380, loss = 0.784647
I0614 20:16:24.960618 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0614 20:16:24.960624 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.371716 (* 1 = 0.371716 loss)
I0614 20:16:24.960628 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.514642 (* 1 = 0.514642 loss)
I0614 20:16:24.960633 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0243615 (* 1 = 0.0243615 loss)
I0614 20:16:24.960635 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.251426 (* 1 = 0.251426 loss)
I0614 20:16:24.960640 15760 sgd_solver.cpp:106] Iteration 15380, lr = 0.0002
speed: 5.329s / iter
I0614 20:18:11.436215 15760 solver.cpp:228] Iteration 15400, loss = 0.414984
I0614 20:18:11.436239 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 20:18:11.436246 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.104423 (* 1 = 0.104423 loss)
I0614 20:18:11.436250 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.13482 (* 1 = 0.13482 loss)
I0614 20:18:11.436254 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376103 (* 1 = 0.00376103 loss)
I0614 20:18:11.436259 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.047753 (* 1 = 0.047753 loss)
I0614 20:18:11.436264 15760 sgd_solver.cpp:106] Iteration 15400, lr = 0.0002
I0614 20:19:59.346750 15760 solver.cpp:228] Iteration 15420, loss = 0.419093
I0614 20:19:59.346773 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 20:19:59.346781 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0972613 (* 1 = 0.0972613 loss)
I0614 20:19:59.346786 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.156032 (* 1 = 0.156032 loss)
I0614 20:19:59.346789 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0237864 (* 1 = 0.0237864 loss)
I0614 20:19:59.346793 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340112 (* 1 = 0.0340112 loss)
I0614 20:19:59.346798 15760 sgd_solver.cpp:106] Iteration 15420, lr = 0.0002
I0614 20:21:46.336549 15760 solver.cpp:228] Iteration 15440, loss = 0.458097
I0614 20:21:46.336575 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 20:21:46.336585 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.165122 (* 1 = 0.165122 loss)
I0614 20:21:46.336591 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0866381 (* 1 = 0.0866381 loss)
I0614 20:21:46.336596 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0059642 (* 1 = 0.0059642 loss)
I0614 20:21:46.336601 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174306 (* 1 = 0.0174306 loss)
I0614 20:21:46.336611 15760 sgd_solver.cpp:106] Iteration 15440, lr = 0.0002
I0614 20:23:34.057281 15760 solver.cpp:228] Iteration 15460, loss = 0.4112
I0614 20:23:34.057307 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 20:23:34.057315 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0806319 (* 1 = 0.0806319 loss)
I0614 20:23:34.057322 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.17417 (* 1 = 0.17417 loss)
I0614 20:23:34.057325 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000609474 (* 1 = 0.000609474 loss)
I0614 20:23:34.057330 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227967 (* 1 = 0.0227967 loss)
I0614 20:23:34.057337 15760 sgd_solver.cpp:106] Iteration 15460, lr = 0.0002
I0614 20:25:21.144320 15760 solver.cpp:228] Iteration 15480, loss = 0.406747
I0614 20:25:21.144341 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 20:25:21.144349 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0753582 (* 1 = 0.0753582 loss)
I0614 20:25:21.144353 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.108764 (* 1 = 0.108764 loss)
I0614 20:25:21.144356 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000859648 (* 1 = 0.000859648 loss)
I0614 20:25:21.144361 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209531 (* 1 = 0.0209531 loss)
I0614 20:25:21.144366 15760 sgd_solver.cpp:106] Iteration 15480, lr = 0.0002
I0614 20:27:08.706455 15760 solver.cpp:228] Iteration 15500, loss = 0.337363
I0614 20:27:08.706481 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 20:27:08.706488 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.215295 (* 1 = 0.215295 loss)
I0614 20:27:08.706492 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.173023 (* 1 = 0.173023 loss)
I0614 20:27:08.706497 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00163207 (* 1 = 0.00163207 loss)
I0614 20:27:08.706501 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151992 (* 1 = 0.0151992 loss)
I0614 20:27:08.706506 15760 sgd_solver.cpp:106] Iteration 15500, lr = 0.0002
I0614 20:28:55.560905 15760 solver.cpp:228] Iteration 15520, loss = 0.373762
I0614 20:28:55.560932 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 20:28:55.560947 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.120365 (* 1 = 0.120365 loss)
I0614 20:28:55.560956 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.499616 (* 1 = 0.499616 loss)
I0614 20:28:55.560964 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157432 (* 1 = 0.00157432 loss)
I0614 20:28:55.560972 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164763 (* 1 = 0.0164763 loss)
I0614 20:28:55.560981 15760 sgd_solver.cpp:106] Iteration 15520, lr = 0.0002
I0614 20:30:43.054764 15760 solver.cpp:228] Iteration 15540, loss = 0.577476
I0614 20:30:43.054792 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 20:30:43.054800 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0823351 (* 1 = 0.0823351 loss)
I0614 20:30:43.054805 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0843969 (* 1 = 0.0843969 loss)
I0614 20:30:43.054808 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0033196 (* 1 = 0.0033196 loss)
I0614 20:30:43.054813 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181625 (* 1 = 0.0181625 loss)
I0614 20:30:43.054819 15760 sgd_solver.cpp:106] Iteration 15540, lr = 0.0002
I0614 20:32:29.459254 15760 solver.cpp:228] Iteration 15560, loss = 0.649403
I0614 20:32:29.459278 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 20:32:29.459286 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.294737 (* 1 = 0.294737 loss)
I0614 20:32:29.459290 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.31383 (* 1 = 0.31383 loss)
I0614 20:32:29.459295 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0727862 (* 1 = 0.0727862 loss)
I0614 20:32:29.459298 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.21071 (* 1 = 0.21071 loss)
I0614 20:32:29.459303 15760 sgd_solver.cpp:106] Iteration 15560, lr = 0.0002
I0614 20:34:16.944545 15760 solver.cpp:228] Iteration 15580, loss = 0.621404
I0614 20:34:16.944571 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 20:34:16.944578 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.197455 (* 1 = 0.197455 loss)
I0614 20:34:16.944583 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.218507 (* 1 = 0.218507 loss)
I0614 20:34:16.944588 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00792728 (* 1 = 0.00792728 loss)
I0614 20:34:16.944593 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0582526 (* 1 = 0.0582526 loss)
I0614 20:34:16.944599 15760 sgd_solver.cpp:106] Iteration 15580, lr = 0.0002
speed: 5.329s / iter
I0614 20:36:04.143635 15760 solver.cpp:228] Iteration 15600, loss = 0.59076
I0614 20:36:04.143659 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0614 20:36:04.143667 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.775359 (* 1 = 0.775359 loss)
I0614 20:36:04.143671 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.664849 (* 1 = 0.664849 loss)
I0614 20:36:04.143676 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122642 (* 1 = 0.0122642 loss)
I0614 20:36:04.143678 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.19673 (* 1 = 0.19673 loss)
I0614 20:36:04.143683 15760 sgd_solver.cpp:106] Iteration 15600, lr = 0.0002
I0614 20:37:51.292656 15760 solver.cpp:228] Iteration 15620, loss = 0.458497
I0614 20:37:51.292685 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 20:37:51.292695 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.197623 (* 1 = 0.197623 loss)
I0614 20:37:51.292698 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.248679 (* 1 = 0.248679 loss)
I0614 20:37:51.292703 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00214649 (* 1 = 0.00214649 loss)
I0614 20:37:51.292708 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226775 (* 1 = 0.0226775 loss)
I0614 20:37:51.292714 15760 sgd_solver.cpp:106] Iteration 15620, lr = 0.0002
I0614 20:39:38.076628 15760 solver.cpp:228] Iteration 15640, loss = 0.970215
I0614 20:39:38.076661 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0614 20:39:38.076673 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.83585 (* 1 = 0.83585 loss)
I0614 20:39:38.076683 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.707571 (* 1 = 0.707571 loss)
I0614 20:39:38.076689 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0415246 (* 1 = 0.0415246 loss)
I0614 20:39:38.076694 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.553559 (* 1 = 0.553559 loss)
I0614 20:39:38.076704 15760 sgd_solver.cpp:106] Iteration 15640, lr = 0.0002
I0614 20:41:24.937817 15760 solver.cpp:228] Iteration 15660, loss = 0.665065
I0614 20:41:24.937841 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 20:41:24.937849 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.306314 (* 1 = 0.306314 loss)
I0614 20:41:24.937852 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.313949 (* 1 = 0.313949 loss)
I0614 20:41:24.937856 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000522092 (* 1 = 0.000522092 loss)
I0614 20:41:24.937860 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03406 (* 1 = 0.03406 loss)
I0614 20:41:24.937865 15760 sgd_solver.cpp:106] Iteration 15660, lr = 0.0002
I0614 20:43:11.411839 15760 solver.cpp:228] Iteration 15680, loss = 0.411982
I0614 20:43:11.411864 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0614 20:43:11.411872 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.291678 (* 1 = 0.291678 loss)
I0614 20:43:11.411876 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.473486 (* 1 = 0.473486 loss)
I0614 20:43:11.411881 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226203 (* 1 = 0.0226203 loss)
I0614 20:43:11.411885 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0986313 (* 1 = 0.0986313 loss)
I0614 20:43:11.411891 15760 sgd_solver.cpp:106] Iteration 15680, lr = 0.0002
I0614 20:44:58.010262 15760 solver.cpp:228] Iteration 15700, loss = 0.385775
I0614 20:44:58.010319 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 20:44:58.010335 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.170682 (* 1 = 0.170682 loss)
I0614 20:44:58.010342 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120799 (* 1 = 0.120799 loss)
I0614 20:44:58.010349 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144807 (* 1 = 0.0144807 loss)
I0614 20:44:58.010354 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.052287 (* 1 = 0.052287 loss)
I0614 20:44:58.010366 15760 sgd_solver.cpp:106] Iteration 15700, lr = 0.0002
I0614 20:46:44.684656 15760 solver.cpp:228] Iteration 15720, loss = 0.544235
I0614 20:46:44.684684 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0614 20:46:44.684692 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.620301 (* 1 = 0.620301 loss)
I0614 20:46:44.684698 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.562402 (* 1 = 0.562402 loss)
I0614 20:46:44.684705 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016479 (* 1 = 0.016479 loss)
I0614 20:46:44.684710 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.16612 (* 1 = 0.16612 loss)
I0614 20:46:44.684717 15760 sgd_solver.cpp:106] Iteration 15720, lr = 0.0002
I0614 20:48:31.498992 15760 solver.cpp:228] Iteration 15740, loss = 0.600883
I0614 20:48:31.499017 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 20:48:31.499024 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.181392 (* 1 = 0.181392 loss)
I0614 20:48:31.499028 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.255975 (* 1 = 0.255975 loss)
I0614 20:48:31.499032 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382311 (* 1 = 0.00382311 loss)
I0614 20:48:31.499035 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288651 (* 1 = 0.0288651 loss)
I0614 20:48:31.499040 15760 sgd_solver.cpp:106] Iteration 15740, lr = 0.0002
I0614 20:50:17.832536 15760 solver.cpp:228] Iteration 15760, loss = 0.332394
I0614 20:50:17.832566 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 20:50:17.832574 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816338 (* 1 = 0.0816338 loss)
I0614 20:50:17.832579 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0576073 (* 1 = 0.0576073 loss)
I0614 20:50:17.832584 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538312 (* 1 = 0.00538312 loss)
I0614 20:50:17.832590 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224237 (* 1 = 0.0224237 loss)
I0614 20:50:17.832597 15760 sgd_solver.cpp:106] Iteration 15760, lr = 0.0002
I0614 20:52:04.526468 15760 solver.cpp:228] Iteration 15780, loss = 0.432972
I0614 20:52:04.526494 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 20:52:04.526501 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108413 (* 1 = 0.108413 loss)
I0614 20:52:04.526506 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0923066 (* 1 = 0.0923066 loss)
I0614 20:52:04.526510 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000505136 (* 1 = 0.000505136 loss)
I0614 20:52:04.526515 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142693 (* 1 = 0.0142693 loss)
I0614 20:52:04.526520 15760 sgd_solver.cpp:106] Iteration 15780, lr = 0.0002
speed: 5.329s / iter
I0614 20:53:51.161094 15760 solver.cpp:228] Iteration 15800, loss = 0.538367
I0614 20:53:51.161120 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 20:53:51.161128 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.153328 (* 1 = 0.153328 loss)
I0614 20:53:51.161132 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161323 (* 1 = 0.161323 loss)
I0614 20:53:51.161136 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125413 (* 1 = 0.00125413 loss)
I0614 20:53:51.161140 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418459 (* 1 = 0.0418459 loss)
I0614 20:53:51.161145 15760 sgd_solver.cpp:106] Iteration 15800, lr = 0.0002
I0614 20:55:37.959564 15760 solver.cpp:228] Iteration 15820, loss = 0.44459
I0614 20:55:37.959589 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 20:55:37.959595 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.261985 (* 1 = 0.261985 loss)
I0614 20:55:37.959600 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.32756 (* 1 = 0.32756 loss)
I0614 20:55:37.959604 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0278564 (* 1 = 0.0278564 loss)
I0614 20:55:37.959609 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.461985 (* 1 = 0.461985 loss)
I0614 20:55:37.959612 15760 sgd_solver.cpp:106] Iteration 15820, lr = 0.0002
I0614 20:57:24.636448 15760 solver.cpp:228] Iteration 15840, loss = 0.624679
I0614 20:57:24.636473 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 20:57:24.636481 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.267757 (* 1 = 0.267757 loss)
I0614 20:57:24.636484 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.265255 (* 1 = 0.265255 loss)
I0614 20:57:24.636488 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000756334 (* 1 = 0.000756334 loss)
I0614 20:57:24.636492 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303461 (* 1 = 0.0303461 loss)
I0614 20:57:24.636497 15760 sgd_solver.cpp:106] Iteration 15840, lr = 0.0002
I0614 20:59:11.301415 15760 solver.cpp:228] Iteration 15860, loss = 0.409128
I0614 20:59:11.301440 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 20:59:11.301445 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.133129 (* 1 = 0.133129 loss)
I0614 20:59:11.301450 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.162625 (* 1 = 0.162625 loss)
I0614 20:59:11.301453 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00392739 (* 1 = 0.00392739 loss)
I0614 20:59:11.301456 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00683715 (* 1 = 0.00683715 loss)
I0614 20:59:11.301461 15760 sgd_solver.cpp:106] Iteration 15860, lr = 0.0002
I0614 21:00:58.508610 15760 solver.cpp:228] Iteration 15880, loss = 0.414289
I0614 21:00:58.508632 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 21:00:58.508639 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.39873 (* 1 = 0.39873 loss)
I0614 21:00:58.508643 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.322496 (* 1 = 0.322496 loss)
I0614 21:00:58.508647 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154946 (* 1 = 0.00154946 loss)
I0614 21:00:58.508651 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0901591 (* 1 = 0.0901591 loss)
I0614 21:00:58.508656 15760 sgd_solver.cpp:106] Iteration 15880, lr = 0.0002
I0614 21:02:45.479509 15760 solver.cpp:228] Iteration 15900, loss = 0.492743
I0614 21:02:45.479537 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 21:02:45.479544 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.301358 (* 1 = 0.301358 loss)
I0614 21:02:45.479549 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.346314 (* 1 = 0.346314 loss)
I0614 21:02:45.479554 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00960251 (* 1 = 0.00960251 loss)
I0614 21:02:45.479559 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.25251 (* 1 = 0.25251 loss)
I0614 21:02:45.479565 15760 sgd_solver.cpp:106] Iteration 15900, lr = 0.0002
I0614 21:04:32.733441 15760 solver.cpp:228] Iteration 15920, loss = 0.387195
I0614 21:04:32.733466 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 21:04:32.733474 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.201458 (* 1 = 0.201458 loss)
I0614 21:04:32.733479 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.249147 (* 1 = 0.249147 loss)
I0614 21:04:32.733482 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100673 (* 1 = 0.00100673 loss)
I0614 21:04:32.733486 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379927 (* 1 = 0.0379927 loss)
I0614 21:04:32.733492 15760 sgd_solver.cpp:106] Iteration 15920, lr = 0.0002
I0614 21:06:20.228263 15760 solver.cpp:228] Iteration 15940, loss = 0.239258
I0614 21:06:20.228288 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 21:06:20.228297 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.072151 (* 1 = 0.072151 loss)
I0614 21:06:20.228302 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0633011 (* 1 = 0.0633011 loss)
I0614 21:06:20.228307 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135918 (* 1 = 0.00135918 loss)
I0614 21:06:20.228310 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177191 (* 1 = 0.0177191 loss)
I0614 21:06:20.228317 15760 sgd_solver.cpp:106] Iteration 15940, lr = 0.0002
I0614 21:08:07.947337 15760 solver.cpp:228] Iteration 15960, loss = 0.523596
I0614 21:08:07.947363 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0614 21:08:07.947371 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.654608 (* 1 = 0.654608 loss)
I0614 21:08:07.947376 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.539657 (* 1 = 0.539657 loss)
I0614 21:08:07.947379 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165105 (* 1 = 0.00165105 loss)
I0614 21:08:07.947383 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115917 (* 1 = 0.115917 loss)
I0614 21:08:07.947387 15760 sgd_solver.cpp:106] Iteration 15960, lr = 0.0002
I0614 21:09:54.888669 15760 solver.cpp:228] Iteration 15980, loss = 0.672412
I0614 21:09:54.888694 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 21:09:54.888700 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.143604 (* 1 = 0.143604 loss)
I0614 21:09:54.888705 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.25472 (* 1 = 0.25472 loss)
I0614 21:09:54.888708 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000691781 (* 1 = 0.000691781 loss)
I0614 21:09:54.888711 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318711 (* 1 = 0.0318711 loss)
I0614 21:09:54.888716 15760 sgd_solver.cpp:106] Iteration 15980, lr = 0.0002
speed: 5.330s / iter
I0614 21:11:42.276597 15760 solver.cpp:228] Iteration 16000, loss = 0.413469
I0614 21:11:42.276620 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0614 21:11:42.276628 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.381627 (* 1 = 0.381627 loss)
I0614 21:11:42.276631 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.477079 (* 1 = 0.477079 loss)
I0614 21:11:42.276635 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0269947 (* 1 = 0.0269947 loss)
I0614 21:11:42.276639 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149318 (* 1 = 0.149318 loss)
I0614 21:11:42.276643 15760 sgd_solver.cpp:106] Iteration 16000, lr = 0.0002
I0614 21:13:29.330144 15760 solver.cpp:228] Iteration 16020, loss = 0.459952
I0614 21:13:29.330168 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 21:13:29.330178 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.102299 (* 1 = 0.102299 loss)
I0614 21:13:29.330183 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.154475 (* 1 = 0.154475 loss)
I0614 21:13:29.330188 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000715716 (* 1 = 0.000715716 loss)
I0614 21:13:29.330194 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00781507 (* 1 = 0.00781507 loss)
I0614 21:13:29.330201 15760 sgd_solver.cpp:106] Iteration 16020, lr = 0.0002
I0614 21:15:16.248976 15760 solver.cpp:228] Iteration 16040, loss = 0.386011
I0614 21:15:16.249011 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 21:15:16.249020 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0732655 (* 1 = 0.0732655 loss)
I0614 21:15:16.249027 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0740309 (* 1 = 0.0740309 loss)
I0614 21:15:16.249032 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181166 (* 1 = 0.00181166 loss)
I0614 21:15:16.249037 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0071996 (* 1 = 0.0071996 loss)
I0614 21:15:16.249043 15760 sgd_solver.cpp:106] Iteration 16040, lr = 0.0002
I0614 21:17:03.169116 15760 solver.cpp:228] Iteration 16060, loss = 0.283429
I0614 21:17:03.169137 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 21:17:03.169144 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0408407 (* 1 = 0.0408407 loss)
I0614 21:17:03.169148 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0719144 (* 1 = 0.0719144 loss)
I0614 21:17:03.169152 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000352829 (* 1 = 0.000352829 loss)
I0614 21:17:03.169155 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125369 (* 1 = 0.0125369 loss)
I0614 21:17:03.169160 15760 sgd_solver.cpp:106] Iteration 16060, lr = 0.0002
I0614 21:18:50.237852 15760 solver.cpp:228] Iteration 16080, loss = 0.541163
I0614 21:18:50.237875 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 21:18:50.237882 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.422409 (* 1 = 0.422409 loss)
I0614 21:18:50.237887 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.435535 (* 1 = 0.435535 loss)
I0614 21:18:50.237890 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0259114 (* 1 = 0.0259114 loss)
I0614 21:18:50.237895 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.145475 (* 1 = 0.145475 loss)
I0614 21:18:50.237900 15760 sgd_solver.cpp:106] Iteration 16080, lr = 0.0002
I0614 21:20:37.815717 15760 solver.cpp:228] Iteration 16100, loss = 0.425826
I0614 21:20:37.815743 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 21:20:37.815752 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912953 (* 1 = 0.0912953 loss)
I0614 21:20:37.815757 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0656871 (* 1 = 0.0656871 loss)
I0614 21:20:37.815763 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00111807 (* 1 = 0.00111807 loss)
I0614 21:20:37.815768 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129599 (* 1 = 0.0129599 loss)
I0614 21:20:37.815778 15760 sgd_solver.cpp:106] Iteration 16100, lr = 0.0002
I0614 21:22:24.929936 15760 solver.cpp:228] Iteration 16120, loss = 0.52459
I0614 21:22:24.929963 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 21:22:24.929971 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194082 (* 1 = 0.194082 loss)
I0614 21:22:24.929976 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.215038 (* 1 = 0.215038 loss)
I0614 21:22:24.929981 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00797261 (* 1 = 0.00797261 loss)
I0614 21:22:24.929986 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0588459 (* 1 = 0.0588459 loss)
I0614 21:22:24.929992 15760 sgd_solver.cpp:106] Iteration 16120, lr = 0.0002
I0614 21:24:11.320088 15760 solver.cpp:228] Iteration 16140, loss = 0.420784
I0614 21:24:11.320113 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 21:24:11.320122 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0501463 (* 1 = 0.0501463 loss)
I0614 21:24:11.320125 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0926721 (* 1 = 0.0926721 loss)
I0614 21:24:11.320129 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000554193 (* 1 = 0.000554193 loss)
I0614 21:24:11.320133 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00757615 (* 1 = 0.00757615 loss)
I0614 21:24:11.320138 15760 sgd_solver.cpp:106] Iteration 16140, lr = 0.0002
I0614 21:25:58.041406 15760 solver.cpp:228] Iteration 16160, loss = 0.611062
I0614 21:25:58.041430 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0614 21:25:58.041438 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.676602 (* 1 = 0.676602 loss)
I0614 21:25:58.041441 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.432752 (* 1 = 0.432752 loss)
I0614 21:25:58.041445 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00552436 (* 1 = 0.00552436 loss)
I0614 21:25:58.041450 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.161641 (* 1 = 0.161641 loss)
I0614 21:25:58.041453 15760 sgd_solver.cpp:106] Iteration 16160, lr = 0.0002
I0614 21:27:44.626680 15760 solver.cpp:228] Iteration 16180, loss = 0.540221
I0614 21:27:44.626706 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 21:27:44.626713 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0755947 (* 1 = 0.0755947 loss)
I0614 21:27:44.626718 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.068333 (* 1 = 0.068333 loss)
I0614 21:27:44.626721 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282543 (* 1 = 0.00282543 loss)
I0614 21:27:44.626725 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.060728 (* 1 = 0.060728 loss)
I0614 21:27:44.626730 15760 sgd_solver.cpp:106] Iteration 16180, lr = 0.0002
speed: 5.330s / iter
I0614 21:29:30.951767 15760 solver.cpp:228] Iteration 16200, loss = 0.505629
I0614 21:29:30.951791 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 21:29:30.951797 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101695 (* 1 = 0.101695 loss)
I0614 21:29:30.951802 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0752105 (* 1 = 0.0752105 loss)
I0614 21:29:30.951805 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000651903 (* 1 = 0.000651903 loss)
I0614 21:29:30.951809 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942061 (* 1 = 0.00942061 loss)
I0614 21:29:30.951814 15760 sgd_solver.cpp:106] Iteration 16200, lr = 0.0002
I0614 21:31:17.524087 15760 solver.cpp:228] Iteration 16220, loss = 0.588449
I0614 21:31:17.524112 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 21:31:17.524119 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.275351 (* 1 = 0.275351 loss)
I0614 21:31:17.524123 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.304536 (* 1 = 0.304536 loss)
I0614 21:31:17.524127 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00443463 (* 1 = 0.00443463 loss)
I0614 21:31:17.524132 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128986 (* 1 = 0.128986 loss)
I0614 21:31:17.524137 15760 sgd_solver.cpp:106] Iteration 16220, lr = 0.0002
I0614 21:33:03.736438 15760 solver.cpp:228] Iteration 16240, loss = 0.418237
I0614 21:33:03.736465 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 21:33:03.736475 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15602 (* 1 = 0.15602 loss)
I0614 21:33:03.736481 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.194431 (* 1 = 0.194431 loss)
I0614 21:33:03.736487 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00699536 (* 1 = 0.00699536 loss)
I0614 21:33:03.736495 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254961 (* 1 = 0.0254961 loss)
I0614 21:33:03.736503 15760 sgd_solver.cpp:106] Iteration 16240, lr = 0.0002
I0614 21:34:50.498869 15760 solver.cpp:228] Iteration 16260, loss = 0.830078
I0614 21:34:50.498895 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 21:34:50.498903 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.17941 (* 1 = 0.17941 loss)
I0614 21:34:50.498908 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.205847 (* 1 = 0.205847 loss)
I0614 21:34:50.498911 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150497 (* 1 = 0.0150497 loss)
I0614 21:34:50.498915 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0287645 (* 1 = 0.0287645 loss)
I0614 21:34:50.498920 15760 sgd_solver.cpp:106] Iteration 16260, lr = 0.0002
I0614 21:36:37.307015 15760 solver.cpp:228] Iteration 16280, loss = 0.585407
I0614 21:36:37.307041 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 21:36:37.307049 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.34921 (* 1 = 0.34921 loss)
I0614 21:36:37.307052 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.284517 (* 1 = 0.284517 loss)
I0614 21:36:37.307056 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116835 (* 1 = 0.0116835 loss)
I0614 21:36:37.307060 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0866255 (* 1 = 0.0866255 loss)
I0614 21:36:37.307065 15760 sgd_solver.cpp:106] Iteration 16280, lr = 0.0002
I0614 21:38:24.057461 15760 solver.cpp:228] Iteration 16300, loss = 0.527473
I0614 21:38:24.057483 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 21:38:24.057489 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.380403 (* 1 = 0.380403 loss)
I0614 21:38:24.057493 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.366109 (* 1 = 0.366109 loss)
I0614 21:38:24.057497 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000498187 (* 1 = 0.000498187 loss)
I0614 21:38:24.057500 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0584153 (* 1 = 0.0584153 loss)
I0614 21:38:24.057505 15760 sgd_solver.cpp:106] Iteration 16300, lr = 0.0002
I0614 21:40:10.428059 15760 solver.cpp:228] Iteration 16320, loss = 0.476629
I0614 21:40:10.428086 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 21:40:10.428092 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0666562 (* 1 = 0.0666562 loss)
I0614 21:40:10.428097 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120854 (* 1 = 0.120854 loss)
I0614 21:40:10.428102 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101307 (* 1 = 0.00101307 loss)
I0614 21:40:10.428105 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218033 (* 1 = 0.0218033 loss)
I0614 21:40:10.428112 15760 sgd_solver.cpp:106] Iteration 16320, lr = 0.0002
I0614 21:41:57.312731 15760 solver.cpp:228] Iteration 16340, loss = 0.415238
I0614 21:41:57.312757 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 21:41:57.312767 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.244428 (* 1 = 0.244428 loss)
I0614 21:41:57.312773 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.273443 (* 1 = 0.273443 loss)
I0614 21:41:57.312779 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00052479 (* 1 = 0.00052479 loss)
I0614 21:41:57.312786 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284568 (* 1 = 0.0284568 loss)
I0614 21:41:57.312794 15760 sgd_solver.cpp:106] Iteration 16340, lr = 0.0002
I0614 21:43:44.177692 15760 solver.cpp:228] Iteration 16360, loss = 0.471751
I0614 21:43:44.177716 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 21:43:44.177722 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628591 (* 1 = 0.0628591 loss)
I0614 21:43:44.177726 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0677564 (* 1 = 0.0677564 loss)
I0614 21:43:44.177731 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217592 (* 1 = 0.00217592 loss)
I0614 21:43:44.177733 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291913 (* 1 = 0.0291913 loss)
I0614 21:43:44.177738 15760 sgd_solver.cpp:106] Iteration 16360, lr = 0.0002
I0614 21:45:31.577728 15760 solver.cpp:228] Iteration 16380, loss = 0.618813
I0614 21:45:31.577752 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0614 21:45:31.577759 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.586901 (* 1 = 0.586901 loss)
I0614 21:45:31.577764 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.431341 (* 1 = 0.431341 loss)
I0614 21:45:31.577769 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143548 (* 1 = 0.00143548 loss)
I0614 21:45:31.577771 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113241 (* 1 = 0.113241 loss)
I0614 21:45:31.577776 15760 sgd_solver.cpp:106] Iteration 16380, lr = 0.0002
speed: 5.330s / iter
I0614 21:47:18.473675 15760 solver.cpp:228] Iteration 16400, loss = 0.619744
I0614 21:47:18.473701 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 21:47:18.473709 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0917757 (* 1 = 0.0917757 loss)
I0614 21:47:18.473714 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0862423 (* 1 = 0.0862423 loss)
I0614 21:47:18.473719 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00441937 (* 1 = 0.00441937 loss)
I0614 21:47:18.473723 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141648 (* 1 = 0.0141648 loss)
I0614 21:47:18.473729 15760 sgd_solver.cpp:106] Iteration 16400, lr = 0.0002
I0614 21:49:06.366928 15760 solver.cpp:228] Iteration 16420, loss = 0.661224
I0614 21:49:06.366952 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0614 21:49:06.366961 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0645675 (* 1 = 0.0645675 loss)
I0614 21:49:06.366964 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0565027 (* 1 = 0.0565027 loss)
I0614 21:49:06.366968 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157365 (* 1 = 0.00157365 loss)
I0614 21:49:06.366972 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010854 (* 1 = 0.010854 loss)
I0614 21:49:06.366977 15760 sgd_solver.cpp:106] Iteration 16420, lr = 0.0002
I0614 21:50:53.636266 15760 solver.cpp:228] Iteration 16440, loss = 0.261772
I0614 21:50:53.636294 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 21:50:53.636303 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.223617 (* 1 = 0.223617 loss)
I0614 21:50:53.636308 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.349828 (* 1 = 0.349828 loss)
I0614 21:50:53.636313 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000733852 (* 1 = 0.000733852 loss)
I0614 21:50:53.636318 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278491 (* 1 = 0.0278491 loss)
I0614 21:50:53.636324 15760 sgd_solver.cpp:106] Iteration 16440, lr = 0.0002
I0614 21:52:41.488342 15760 solver.cpp:228] Iteration 16460, loss = 0.671725
I0614 21:52:41.488366 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0614 21:52:41.488374 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.692234 (* 1 = 0.692234 loss)
I0614 21:52:41.488379 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.667709 (* 1 = 0.667709 loss)
I0614 21:52:41.488384 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00303162 (* 1 = 0.00303162 loss)
I0614 21:52:41.488389 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0899685 (* 1 = 0.0899685 loss)
I0614 21:52:41.488394 15760 sgd_solver.cpp:106] Iteration 16460, lr = 0.0002
I0614 21:54:28.810915 15760 solver.cpp:228] Iteration 16480, loss = 0.451047
I0614 21:54:28.810941 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 21:54:28.810950 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113866 (* 1 = 0.113866 loss)
I0614 21:54:28.810953 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.149868 (* 1 = 0.149868 loss)
I0614 21:54:28.810957 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616701 (* 1 = 0.00616701 loss)
I0614 21:54:28.810961 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408325 (* 1 = 0.0408325 loss)
I0614 21:54:28.810966 15760 sgd_solver.cpp:106] Iteration 16480, lr = 0.0002
I0614 21:56:15.957288 15760 solver.cpp:228] Iteration 16500, loss = 0.3288
I0614 21:56:15.957314 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0614 21:56:15.957324 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0580257 (* 1 = 0.0580257 loss)
I0614 21:56:15.957330 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0310876 (* 1 = 0.0310876 loss)
I0614 21:56:15.957336 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0072169 (* 1 = 0.0072169 loss)
I0614 21:56:15.957342 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239053 (* 1 = 0.0239053 loss)
I0614 21:56:15.957350 15760 sgd_solver.cpp:106] Iteration 16500, lr = 0.0002
I0614 21:58:02.619856 15760 solver.cpp:228] Iteration 16520, loss = 0.511238
I0614 21:58:02.619884 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 21:58:02.619894 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0777757 (* 1 = 0.0777757 loss)
I0614 21:58:02.619900 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167656 (* 1 = 0.167656 loss)
I0614 21:58:02.619905 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000901138 (* 1 = 0.000901138 loss)
I0614 21:58:02.619910 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217769 (* 1 = 0.0217769 loss)
I0614 21:58:02.619917 15760 sgd_solver.cpp:106] Iteration 16520, lr = 0.0002
I0614 21:59:49.914541 15760 solver.cpp:228] Iteration 16540, loss = 0.422656
I0614 21:59:49.914566 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 21:59:49.914572 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129832 (* 1 = 0.129832 loss)
I0614 21:59:49.914577 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.110274 (* 1 = 0.110274 loss)
I0614 21:59:49.914582 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168257 (* 1 = 0.00168257 loss)
I0614 21:59:49.914584 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221021 (* 1 = 0.0221021 loss)
I0614 21:59:49.914589 15760 sgd_solver.cpp:106] Iteration 16540, lr = 0.0002
I0614 22:01:37.153478 15760 solver.cpp:228] Iteration 16560, loss = 0.424906
I0614 22:01:37.153503 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 22:01:37.153512 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.251003 (* 1 = 0.251003 loss)
I0614 22:01:37.153515 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.346795 (* 1 = 0.346795 loss)
I0614 22:01:37.153519 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124074 (* 1 = 0.0124074 loss)
I0614 22:01:37.153523 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0910693 (* 1 = 0.0910693 loss)
I0614 22:01:37.153529 15760 sgd_solver.cpp:106] Iteration 16560, lr = 0.0002
I0614 22:03:24.137074 15760 solver.cpp:228] Iteration 16580, loss = 0.481321
I0614 22:03:24.137095 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 22:03:24.137104 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.145981 (* 1 = 0.145981 loss)
I0614 22:03:24.137106 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.153577 (* 1 = 0.153577 loss)
I0614 22:03:24.137110 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0024321 (* 1 = 0.0024321 loss)
I0614 22:03:24.137114 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232768 (* 1 = 0.0232768 loss)
I0614 22:03:24.137118 15760 sgd_solver.cpp:106] Iteration 16580, lr = 0.0002
speed: 5.330s / iter
I0614 22:05:11.027473 15760 solver.cpp:228] Iteration 16600, loss = 0.275792
I0614 22:05:11.027498 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 22:05:11.027505 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.119533 (* 1 = 0.119533 loss)
I0614 22:05:11.027510 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0906579 (* 1 = 0.0906579 loss)
I0614 22:05:11.027514 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000768594 (* 1 = 0.000768594 loss)
I0614 22:05:11.027518 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00717921 (* 1 = 0.00717921 loss)
I0614 22:05:11.027523 15760 sgd_solver.cpp:106] Iteration 16600, lr = 0.0002
I0614 22:06:57.382506 15760 solver.cpp:228] Iteration 16620, loss = 0.853902
I0614 22:06:57.382530 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 22:06:57.382537 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.264854 (* 1 = 0.264854 loss)
I0614 22:06:57.382542 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309946 (* 1 = 0.309946 loss)
I0614 22:06:57.382546 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127999 (* 1 = 0.0127999 loss)
I0614 22:06:57.382550 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270146 (* 1 = 0.0270146 loss)
I0614 22:06:57.382555 15760 sgd_solver.cpp:106] Iteration 16620, lr = 0.0002
I0614 22:08:43.858949 15760 solver.cpp:228] Iteration 16640, loss = 0.452295
I0614 22:08:43.858973 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0614 22:08:43.858980 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0653386 (* 1 = 0.0653386 loss)
I0614 22:08:43.858984 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0571231 (* 1 = 0.0571231 loss)
I0614 22:08:43.858989 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000425777 (* 1 = 0.000425777 loss)
I0614 22:08:43.858991 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101125 (* 1 = 0.0101125 loss)
I0614 22:08:43.858996 15760 sgd_solver.cpp:106] Iteration 16640, lr = 0.0002
I0614 22:10:30.598136 15760 solver.cpp:228] Iteration 16660, loss = 0.676605
I0614 22:10:30.598163 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 22:10:30.598171 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.246266 (* 1 = 0.246266 loss)
I0614 22:10:30.598176 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234306 (* 1 = 0.234306 loss)
I0614 22:10:30.598181 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766783 (* 1 = 0.00766783 loss)
I0614 22:10:30.598186 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039768 (* 1 = 0.039768 loss)
I0614 22:10:30.598192 15760 sgd_solver.cpp:106] Iteration 16660, lr = 0.0002
I0614 22:12:17.121814 15760 solver.cpp:228] Iteration 16680, loss = 0.512456
I0614 22:12:17.121837 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 22:12:17.121845 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0819972 (* 1 = 0.0819972 loss)
I0614 22:12:17.121848 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.181491 (* 1 = 0.181491 loss)
I0614 22:12:17.121851 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0572607 (* 1 = 0.0572607 loss)
I0614 22:12:17.121855 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.050973 (* 1 = 0.050973 loss)
I0614 22:12:17.121860 15760 sgd_solver.cpp:106] Iteration 16680, lr = 0.0002
I0614 22:14:04.071218 15760 solver.cpp:228] Iteration 16700, loss = 0.571274
I0614 22:14:04.071244 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0614 22:14:04.071251 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.145474 (* 1 = 0.145474 loss)
I0614 22:14:04.071255 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.209484 (* 1 = 0.209484 loss)
I0614 22:14:04.071259 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108108 (* 1 = 0.00108108 loss)
I0614 22:14:04.071264 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433452 (* 1 = 0.0433452 loss)
I0614 22:14:04.071269 15760 sgd_solver.cpp:106] Iteration 16700, lr = 0.0002
I0614 22:15:50.962451 15760 solver.cpp:228] Iteration 16720, loss = 0.443863
I0614 22:15:50.962476 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 22:15:50.962483 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.25602 (* 1 = 0.25602 loss)
I0614 22:15:50.962487 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.199683 (* 1 = 0.199683 loss)
I0614 22:15:50.962491 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155497 (* 1 = 0.00155497 loss)
I0614 22:15:50.962496 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400364 (* 1 = 0.0400364 loss)
I0614 22:15:50.962502 15760 sgd_solver.cpp:106] Iteration 16720, lr = 0.0002
I0614 22:17:37.847515 15760 solver.cpp:228] Iteration 16740, loss = 0.457358
I0614 22:17:37.847543 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 22:17:37.847553 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.161352 (* 1 = 0.161352 loss)
I0614 22:17:37.847558 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0978865 (* 1 = 0.0978865 loss)
I0614 22:17:37.847563 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00278627 (* 1 = 0.00278627 loss)
I0614 22:17:37.847566 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0429929 (* 1 = 0.0429929 loss)
I0614 22:17:37.847573 15760 sgd_solver.cpp:106] Iteration 16740, lr = 0.0002
I0614 22:19:24.590776 15760 solver.cpp:228] Iteration 16760, loss = 0.417024
I0614 22:19:24.590806 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 22:19:24.590814 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.207022 (* 1 = 0.207022 loss)
I0614 22:19:24.590819 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.189473 (* 1 = 0.189473 loss)
I0614 22:19:24.590823 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265096 (* 1 = 0.00265096 loss)
I0614 22:19:24.590827 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049086 (* 1 = 0.049086 loss)
I0614 22:19:24.590834 15760 sgd_solver.cpp:106] Iteration 16760, lr = 0.0002
I0614 22:21:11.835922 15760 solver.cpp:228] Iteration 16780, loss = 0.783268
I0614 22:21:11.835949 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 22:21:11.835959 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.240887 (* 1 = 0.240887 loss)
I0614 22:21:11.835964 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.18228 (* 1 = 0.18228 loss)
I0614 22:21:11.835970 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00492335 (* 1 = 0.00492335 loss)
I0614 22:21:11.835975 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0929207 (* 1 = 0.0929207 loss)
I0614 22:21:11.835981 15760 sgd_solver.cpp:106] Iteration 16780, lr = 0.0002
speed: 5.330s / iter
I0614 22:22:59.257752 15760 solver.cpp:228] Iteration 16800, loss = 0.441772
I0614 22:22:59.257781 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 22:22:59.257791 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112324 (* 1 = 0.112324 loss)
I0614 22:22:59.257797 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0856632 (* 1 = 0.0856632 loss)
I0614 22:22:59.257802 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000183559 (* 1 = 0.000183559 loss)
I0614 22:22:59.257807 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00599129 (* 1 = 0.00599129 loss)
I0614 22:22:59.257813 15760 sgd_solver.cpp:106] Iteration 16800, lr = 0.0002
I0614 22:24:46.083123 15760 solver.cpp:228] Iteration 16820, loss = 0.620705
I0614 22:24:46.083149 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0614 22:24:46.083156 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.763126 (* 1 = 0.763126 loss)
I0614 22:24:46.083160 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.635043 (* 1 = 0.635043 loss)
I0614 22:24:46.083164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0450413 (* 1 = 0.0450413 loss)
I0614 22:24:46.083168 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.593357 (* 1 = 0.593357 loss)
I0614 22:24:46.083173 15760 sgd_solver.cpp:106] Iteration 16820, lr = 0.0002
I0614 22:26:32.510071 15760 solver.cpp:228] Iteration 16840, loss = 0.696703
I0614 22:26:32.510097 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 22:26:32.510103 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.170007 (* 1 = 0.170007 loss)
I0614 22:26:32.510107 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.170787 (* 1 = 0.170787 loss)
I0614 22:26:32.510113 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00668657 (* 1 = 0.00668657 loss)
I0614 22:26:32.510115 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0471771 (* 1 = 0.0471771 loss)
I0614 22:26:32.510120 15760 sgd_solver.cpp:106] Iteration 16840, lr = 0.0002
I0614 22:28:19.556699 15760 solver.cpp:228] Iteration 16860, loss = 0.596478
I0614 22:28:19.556723 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 22:28:19.556731 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526359 (* 1 = 0.0526359 loss)
I0614 22:28:19.556735 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0628477 (* 1 = 0.0628477 loss)
I0614 22:28:19.556740 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017004 (* 1 = 0.017004 loss)
I0614 22:28:19.556742 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149345 (* 1 = 0.0149345 loss)
I0614 22:28:19.556747 15760 sgd_solver.cpp:106] Iteration 16860, lr = 0.0002
I0614 22:30:07.118016 15760 solver.cpp:228] Iteration 16880, loss = 0.403517
I0614 22:30:07.118042 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 22:30:07.118049 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111083 (* 1 = 0.111083 loss)
I0614 22:30:07.118053 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.169084 (* 1 = 0.169084 loss)
I0614 22:30:07.118057 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00434784 (* 1 = 0.00434784 loss)
I0614 22:30:07.118060 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0917973 (* 1 = 0.0917973 loss)
I0614 22:30:07.118065 15760 sgd_solver.cpp:106] Iteration 16880, lr = 0.0002
I0614 22:31:54.129824 15760 solver.cpp:228] Iteration 16900, loss = 0.570196
I0614 22:31:54.129855 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0614 22:31:54.129865 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.230388 (* 1 = 0.230388 loss)
I0614 22:31:54.129871 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.384484 (* 1 = 0.384484 loss)
I0614 22:31:54.129876 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158827 (* 1 = 0.0158827 loss)
I0614 22:31:54.129880 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.225876 (* 1 = 0.225876 loss)
I0614 22:31:54.129887 15760 sgd_solver.cpp:106] Iteration 16900, lr = 0.0002
I0614 22:33:41.137497 15760 solver.cpp:228] Iteration 16920, loss = 0.440196
I0614 22:33:41.137522 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 22:33:41.137531 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.110042 (* 1 = 0.110042 loss)
I0614 22:33:41.137537 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.10662 (* 1 = 0.10662 loss)
I0614 22:33:41.137542 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016325 (* 1 = 0.0016325 loss)
I0614 22:33:41.137545 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237664 (* 1 = 0.0237664 loss)
I0614 22:33:41.137552 15760 sgd_solver.cpp:106] Iteration 16920, lr = 0.0002
I0614 22:35:28.726922 15760 solver.cpp:228] Iteration 16940, loss = 0.395216
I0614 22:35:28.726948 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0614 22:35:28.726956 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.486267 (* 1 = 0.486267 loss)
I0614 22:35:28.726961 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.416129 (* 1 = 0.416129 loss)
I0614 22:35:28.726966 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178936 (* 1 = 0.00178936 loss)
I0614 22:35:28.726971 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0701582 (* 1 = 0.0701582 loss)
I0614 22:35:28.726977 15760 sgd_solver.cpp:106] Iteration 16940, lr = 0.0002
I0614 22:37:15.810751 15760 solver.cpp:228] Iteration 16960, loss = 0.825241
I0614 22:37:15.810780 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 22:37:15.810787 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.10208 (* 1 = 0.10208 loss)
I0614 22:37:15.810792 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0981289 (* 1 = 0.0981289 loss)
I0614 22:37:15.810796 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000278608 (* 1 = 0.000278608 loss)
I0614 22:37:15.810801 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00827455 (* 1 = 0.00827455 loss)
I0614 22:37:15.810807 15760 sgd_solver.cpp:106] Iteration 16960, lr = 0.0002
I0614 22:39:03.664712 15760 solver.cpp:228] Iteration 16980, loss = 0.489716
I0614 22:39:03.664741 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0614 22:39:03.664750 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.257042 (* 1 = 0.257042 loss)
I0614 22:39:03.664755 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.636904 (* 1 = 0.636904 loss)
I0614 22:39:03.664760 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00163516 (* 1 = 0.00163516 loss)
I0614 22:39:03.664764 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304051 (* 1 = 0.0304051 loss)
I0614 22:39:03.664772 15760 sgd_solver.cpp:106] Iteration 16980, lr = 0.0002
speed: 5.331s / iter
I0614 22:40:50.234542 15760 solver.cpp:228] Iteration 17000, loss = 0.486418
I0614 22:40:50.234566 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 22:40:50.234573 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.153358 (* 1 = 0.153358 loss)
I0614 22:40:50.234577 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134238 (* 1 = 0.134238 loss)
I0614 22:40:50.234581 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202971 (* 1 = 0.00202971 loss)
I0614 22:40:50.234585 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336444 (* 1 = 0.0336444 loss)
I0614 22:40:50.234588 15760 sgd_solver.cpp:106] Iteration 17000, lr = 0.0002
I0614 22:42:37.623296 15760 solver.cpp:228] Iteration 17020, loss = 0.63298
I0614 22:42:37.623319 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 22:42:37.623327 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.134997 (* 1 = 0.134997 loss)
I0614 22:42:37.623332 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0979864 (* 1 = 0.0979864 loss)
I0614 22:42:37.623335 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350574 (* 1 = 0.00350574 loss)
I0614 22:42:37.623339 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296613 (* 1 = 0.0296613 loss)
I0614 22:42:37.623344 15760 sgd_solver.cpp:106] Iteration 17020, lr = 0.0002
I0614 22:44:24.714082 15760 solver.cpp:228] Iteration 17040, loss = 0.383066
I0614 22:44:24.714107 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 22:44:24.714113 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0958633 (* 1 = 0.0958633 loss)
I0614 22:44:24.714118 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0715464 (* 1 = 0.0715464 loss)
I0614 22:44:24.714120 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000245606 (* 1 = 0.000245606 loss)
I0614 22:44:24.714124 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108044 (* 1 = 0.0108044 loss)
I0614 22:44:24.714129 15760 sgd_solver.cpp:106] Iteration 17040, lr = 0.0002
I0614 22:46:11.500461 15760 solver.cpp:228] Iteration 17060, loss = 0.391955
I0614 22:46:11.500483 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 22:46:11.500490 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0622251 (* 1 = 0.0622251 loss)
I0614 22:46:11.500494 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0902401 (* 1 = 0.0902401 loss)
I0614 22:46:11.500499 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000314224 (* 1 = 0.000314224 loss)
I0614 22:46:11.500501 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00873854 (* 1 = 0.00873854 loss)
I0614 22:46:11.500507 15760 sgd_solver.cpp:106] Iteration 17060, lr = 0.0002
I0614 22:47:57.985085 15760 solver.cpp:228] Iteration 17080, loss = 0.688735
I0614 22:47:57.985108 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 22:47:57.985116 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843831 (* 1 = 0.0843831 loss)
I0614 22:47:57.985121 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0451629 (* 1 = 0.0451629 loss)
I0614 22:47:57.985123 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000399975 (* 1 = 0.000399975 loss)
I0614 22:47:57.985127 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164488 (* 1 = 0.0164488 loss)
I0614 22:47:57.985131 15760 sgd_solver.cpp:106] Iteration 17080, lr = 0.0002
I0614 22:49:44.175346 15760 solver.cpp:228] Iteration 17100, loss = 0.286628
I0614 22:49:44.175371 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 22:49:44.175379 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.135806 (* 1 = 0.135806 loss)
I0614 22:49:44.175384 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.15474 (* 1 = 0.15474 loss)
I0614 22:49:44.175387 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00246781 (* 1 = 0.00246781 loss)
I0614 22:49:44.175391 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316004 (* 1 = 0.0316004 loss)
I0614 22:49:44.175396 15760 sgd_solver.cpp:106] Iteration 17100, lr = 0.0002
I0614 22:51:30.685708 15760 solver.cpp:228] Iteration 17120, loss = 0.636502
I0614 22:51:30.685730 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0614 22:51:30.685737 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.165536 (* 1 = 0.165536 loss)
I0614 22:51:30.685741 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.346851 (* 1 = 0.346851 loss)
I0614 22:51:30.685745 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.138711 (* 1 = 0.138711 loss)
I0614 22:51:30.685747 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.196708 (* 1 = 0.196708 loss)
I0614 22:51:30.685751 15760 sgd_solver.cpp:106] Iteration 17120, lr = 0.0002
I0614 22:53:17.137681 15760 solver.cpp:228] Iteration 17140, loss = 0.634679
I0614 22:53:17.137706 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 22:53:17.137715 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.482148 (* 1 = 0.482148 loss)
I0614 22:53:17.137719 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.393483 (* 1 = 0.393483 loss)
I0614 22:53:17.137723 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00190476 (* 1 = 0.00190476 loss)
I0614 22:53:17.137727 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658012 (* 1 = 0.0658012 loss)
I0614 22:53:17.137732 15760 sgd_solver.cpp:106] Iteration 17140, lr = 0.0002
I0614 22:55:03.532058 15760 solver.cpp:228] Iteration 17160, loss = 0.454689
I0614 22:55:03.532083 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 22:55:03.532090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.154326 (* 1 = 0.154326 loss)
I0614 22:55:03.532094 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.168061 (* 1 = 0.168061 loss)
I0614 22:55:03.532099 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000537622 (* 1 = 0.000537622 loss)
I0614 22:55:03.532102 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292532 (* 1 = 0.0292532 loss)
I0614 22:55:03.532109 15760 sgd_solver.cpp:106] Iteration 17160, lr = 0.0002
I0614 22:56:50.121245 15760 solver.cpp:228] Iteration 17180, loss = 0.669473
I0614 22:56:50.121268 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 22:56:50.121275 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.125951 (* 1 = 0.125951 loss)
I0614 22:56:50.121279 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171532 (* 1 = 0.171532 loss)
I0614 22:56:50.121282 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00243537 (* 1 = 0.00243537 loss)
I0614 22:56:50.121286 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0256583 (* 1 = 0.0256583 loss)
I0614 22:56:50.121291 15760 sgd_solver.cpp:106] Iteration 17180, lr = 0.0002
speed: 5.331s / iter
I0614 22:58:36.577431 15760 solver.cpp:228] Iteration 17200, loss = 0.900887
I0614 22:58:36.577456 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0614 22:58:36.577464 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.730993 (* 1 = 0.730993 loss)
I0614 22:58:36.577468 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.566191 (* 1 = 0.566191 loss)
I0614 22:58:36.577472 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737736 (* 1 = 0.00737736 loss)
I0614 22:58:36.577476 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157878 (* 1 = 0.157878 loss)
I0614 22:58:36.577481 15760 sgd_solver.cpp:106] Iteration 17200, lr = 0.0002
I0614 23:00:22.890014 15760 solver.cpp:228] Iteration 17220, loss = 0.532063
I0614 23:00:22.890038 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0614 23:00:22.890046 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0802763 (* 1 = 0.0802763 loss)
I0614 23:00:22.890050 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0602858 (* 1 = 0.0602858 loss)
I0614 23:00:22.890054 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241193 (* 1 = 0.00241193 loss)
I0614 23:00:22.890058 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108682 (* 1 = 0.0108682 loss)
I0614 23:00:22.890064 15760 sgd_solver.cpp:106] Iteration 17220, lr = 0.0002
I0614 23:02:09.369150 15760 solver.cpp:228] Iteration 17240, loss = 0.439749
I0614 23:02:09.369174 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 23:02:09.369180 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.213169 (* 1 = 0.213169 loss)
I0614 23:02:09.369184 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.207376 (* 1 = 0.207376 loss)
I0614 23:02:09.369189 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000280191 (* 1 = 0.000280191 loss)
I0614 23:02:09.369192 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219178 (* 1 = 0.0219178 loss)
I0614 23:02:09.369196 15760 sgd_solver.cpp:106] Iteration 17240, lr = 0.0002
I0614 23:03:55.857882 15760 solver.cpp:228] Iteration 17260, loss = 0.298584
I0614 23:03:55.857906 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 23:03:55.857913 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.119141 (* 1 = 0.119141 loss)
I0614 23:03:55.857916 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148904 (* 1 = 0.148904 loss)
I0614 23:03:55.857920 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012583 (* 1 = 0.012583 loss)
I0614 23:03:55.857923 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337733 (* 1 = 0.0337733 loss)
I0614 23:03:55.857928 15760 sgd_solver.cpp:106] Iteration 17260, lr = 0.0002
I0614 23:05:42.341039 15760 solver.cpp:228] Iteration 17280, loss = 0.412805
I0614 23:05:42.341065 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 23:05:42.341073 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.20787 (* 1 = 0.20787 loss)
I0614 23:05:42.341076 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.220337 (* 1 = 0.220337 loss)
I0614 23:05:42.341080 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00090488 (* 1 = 0.00090488 loss)
I0614 23:05:42.341084 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228649 (* 1 = 0.0228649 loss)
I0614 23:05:42.341089 15760 sgd_solver.cpp:106] Iteration 17280, lr = 0.0002
I0614 23:07:28.955040 15760 solver.cpp:228] Iteration 17300, loss = 0.521831
I0614 23:07:28.955063 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 23:07:28.955070 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.090641 (* 1 = 0.090641 loss)
I0614 23:07:28.955075 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.082947 (* 1 = 0.082947 loss)
I0614 23:07:28.955077 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000417328 (* 1 = 0.000417328 loss)
I0614 23:07:28.955080 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188079 (* 1 = 0.0188079 loss)
I0614 23:07:28.955085 15760 sgd_solver.cpp:106] Iteration 17300, lr = 0.0002
I0614 23:09:15.221499 15760 solver.cpp:228] Iteration 17320, loss = 0.41362
I0614 23:09:15.221523 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 23:09:15.221529 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.347868 (* 1 = 0.347868 loss)
I0614 23:09:15.221534 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.382807 (* 1 = 0.382807 loss)
I0614 23:09:15.221536 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347087 (* 1 = 0.00347087 loss)
I0614 23:09:15.221540 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109636 (* 1 = 0.109636 loss)
I0614 23:09:15.221544 15760 sgd_solver.cpp:106] Iteration 17320, lr = 0.0002
I0614 23:11:02.147480 15760 solver.cpp:228] Iteration 17340, loss = 0.437905
I0614 23:11:02.147505 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0614 23:11:02.147512 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.145802 (* 1 = 0.145802 loss)
I0614 23:11:02.147516 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.210864 (* 1 = 0.210864 loss)
I0614 23:11:02.147521 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019601 (* 1 = 0.0019601 loss)
I0614 23:11:02.147524 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0763543 (* 1 = 0.0763543 loss)
I0614 23:11:02.147531 15760 sgd_solver.cpp:106] Iteration 17340, lr = 0.0002
I0614 23:12:49.527038 15760 solver.cpp:228] Iteration 17360, loss = 0.455438
I0614 23:12:49.527063 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0614 23:12:49.527071 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0652771 (* 1 = 0.0652771 loss)
I0614 23:12:49.527076 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.165083 (* 1 = 0.165083 loss)
I0614 23:12:49.527079 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00749899 (* 1 = 0.00749899 loss)
I0614 23:12:49.527083 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00866122 (* 1 = 0.00866122 loss)
I0614 23:12:49.527088 15760 sgd_solver.cpp:106] Iteration 17360, lr = 0.0002
I0614 23:14:36.651706 15760 solver.cpp:228] Iteration 17380, loss = 0.529869
I0614 23:14:36.651732 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 23:14:36.651743 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.334759 (* 1 = 0.334759 loss)
I0614 23:14:36.651751 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.274172 (* 1 = 0.274172 loss)
I0614 23:14:36.651757 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00373437 (* 1 = 0.00373437 loss)
I0614 23:14:36.651762 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.176019 (* 1 = 0.176019 loss)
I0614 23:14:36.651770 15760 sgd_solver.cpp:106] Iteration 17380, lr = 0.0002
speed: 5.331s / iter
I0614 23:16:23.783437 15760 solver.cpp:228] Iteration 17400, loss = 0.390408
I0614 23:16:23.783462 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 23:16:23.783468 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0892835 (* 1 = 0.0892835 loss)
I0614 23:16:23.783473 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0623451 (* 1 = 0.0623451 loss)
I0614 23:16:23.783478 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248701 (* 1 = 0.00248701 loss)
I0614 23:16:23.783480 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135049 (* 1 = 0.0135049 loss)
I0614 23:16:23.783485 15760 sgd_solver.cpp:106] Iteration 17400, lr = 0.0002
I0614 23:18:10.931720 15760 solver.cpp:228] Iteration 17420, loss = 0.443425
I0614 23:18:10.931746 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 23:18:10.931756 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0488215 (* 1 = 0.0488215 loss)
I0614 23:18:10.931763 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.118439 (* 1 = 0.118439 loss)
I0614 23:18:10.931769 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398489 (* 1 = 0.00398489 loss)
I0614 23:18:10.931777 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0588372 (* 1 = 0.0588372 loss)
I0614 23:18:10.931783 15760 sgd_solver.cpp:106] Iteration 17420, lr = 0.0002
I0614 23:19:58.593202 15760 solver.cpp:228] Iteration 17440, loss = 0.635986
I0614 23:19:58.593231 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0614 23:19:58.593240 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.645182 (* 1 = 0.645182 loss)
I0614 23:19:58.593245 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.416611 (* 1 = 0.416611 loss)
I0614 23:19:58.593250 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354898 (* 1 = 0.00354898 loss)
I0614 23:19:58.593255 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12692 (* 1 = 0.12692 loss)
I0614 23:19:58.593261 15760 sgd_solver.cpp:106] Iteration 17440, lr = 0.0002
I0614 23:21:45.563963 15760 solver.cpp:228] Iteration 17460, loss = 0.412088
I0614 23:21:45.563992 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 23:21:45.564002 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0944021 (* 1 = 0.0944021 loss)
I0614 23:21:45.564007 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.180937 (* 1 = 0.180937 loss)
I0614 23:21:45.564013 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0369854 (* 1 = 0.0369854 loss)
I0614 23:21:45.564016 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0700646 (* 1 = 0.0700646 loss)
I0614 23:21:45.564023 15760 sgd_solver.cpp:106] Iteration 17460, lr = 0.0002
I0614 23:23:32.208963 15760 solver.cpp:228] Iteration 17480, loss = 0.465343
I0614 23:23:32.208992 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 23:23:32.209003 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.118213 (* 1 = 0.118213 loss)
I0614 23:23:32.209012 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.135538 (* 1 = 0.135538 loss)
I0614 23:23:32.209018 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108579 (* 1 = 0.00108579 loss)
I0614 23:23:32.209026 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234086 (* 1 = 0.0234086 loss)
I0614 23:23:32.209034 15760 sgd_solver.cpp:106] Iteration 17480, lr = 0.0002
I0614 23:25:18.869415 15760 solver.cpp:228] Iteration 17500, loss = 0.604716
I0614 23:25:18.869438 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 23:25:18.869444 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566591 (* 1 = 0.0566591 loss)
I0614 23:25:18.869448 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0334775 (* 1 = 0.0334775 loss)
I0614 23:25:18.869451 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0313313 (* 1 = 0.0313313 loss)
I0614 23:25:18.869455 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176378 (* 1 = 0.0176378 loss)
I0614 23:25:18.869460 15760 sgd_solver.cpp:106] Iteration 17500, lr = 0.0002
I0614 23:27:06.184280 15760 solver.cpp:228] Iteration 17520, loss = 0.391092
I0614 23:27:06.184303 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 23:27:06.184310 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.160476 (* 1 = 0.160476 loss)
I0614 23:27:06.184314 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159481 (* 1 = 0.159481 loss)
I0614 23:27:06.184317 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000412084 (* 1 = 0.000412084 loss)
I0614 23:27:06.184321 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00977817 (* 1 = 0.00977817 loss)
I0614 23:27:06.184325 15760 sgd_solver.cpp:106] Iteration 17520, lr = 0.0002
I0614 23:28:52.904824 15760 solver.cpp:228] Iteration 17540, loss = 0.533592
I0614 23:28:52.904850 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0614 23:28:52.904857 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.133232 (* 1 = 0.133232 loss)
I0614 23:28:52.904861 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.221129 (* 1 = 0.221129 loss)
I0614 23:28:52.904866 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00525106 (* 1 = 0.00525106 loss)
I0614 23:28:52.904870 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0584128 (* 1 = 0.0584128 loss)
I0614 23:28:52.904875 15760 sgd_solver.cpp:106] Iteration 17540, lr = 0.0002
I0614 23:30:39.727188 15760 solver.cpp:228] Iteration 17560, loss = 0.485171
I0614 23:30:39.727212 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0614 23:30:39.727219 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.37038 (* 1 = 0.37038 loss)
I0614 23:30:39.727223 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.411243 (* 1 = 0.411243 loss)
I0614 23:30:39.727226 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0436703 (* 1 = 0.0436703 loss)
I0614 23:30:39.727229 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.21329 (* 1 = 0.21329 loss)
I0614 23:30:39.727234 15760 sgd_solver.cpp:106] Iteration 17560, lr = 0.0002
I0614 23:32:26.143110 15760 solver.cpp:228] Iteration 17580, loss = 0.292633
I0614 23:32:26.143132 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 23:32:26.143139 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.282064 (* 1 = 0.282064 loss)
I0614 23:32:26.143143 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.323629 (* 1 = 0.323629 loss)
I0614 23:32:26.143148 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00760918 (* 1 = 0.00760918 loss)
I0614 23:32:26.143152 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.085966 (* 1 = 0.085966 loss)
I0614 23:32:26.143157 15760 sgd_solver.cpp:106] Iteration 17580, lr = 0.0002
speed: 5.331s / iter
I0614 23:34:12.522087 15760 solver.cpp:228] Iteration 17600, loss = 0.493838
I0614 23:34:12.522114 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0614 23:34:12.522123 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590711 (* 1 = 0.0590711 loss)
I0614 23:34:12.522130 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0584791 (* 1 = 0.0584791 loss)
I0614 23:34:12.522136 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00117382 (* 1 = 0.00117382 loss)
I0614 23:34:12.522143 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184841 (* 1 = 0.0184841 loss)
I0614 23:34:12.522150 15760 sgd_solver.cpp:106] Iteration 17600, lr = 0.0002
I0614 23:35:58.922485 15760 solver.cpp:228] Iteration 17620, loss = 0.358505
I0614 23:35:58.922510 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0614 23:35:58.922519 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.300111 (* 1 = 0.300111 loss)
I0614 23:35:58.922525 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.338756 (* 1 = 0.338756 loss)
I0614 23:35:58.922530 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00240463 (* 1 = 0.00240463 loss)
I0614 23:35:58.922536 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0501202 (* 1 = 0.0501202 loss)
I0614 23:35:58.922543 15760 sgd_solver.cpp:106] Iteration 17620, lr = 0.0002
I0614 23:37:45.324554 15760 solver.cpp:228] Iteration 17640, loss = 0.384439
I0614 23:37:45.324579 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 23:37:45.324585 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.161904 (* 1 = 0.161904 loss)
I0614 23:37:45.324589 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0684913 (* 1 = 0.0684913 loss)
I0614 23:37:45.324592 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000294116 (* 1 = 0.000294116 loss)
I0614 23:37:45.324596 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0279021 (* 1 = 0.0279021 loss)
I0614 23:37:45.324600 15760 sgd_solver.cpp:106] Iteration 17640, lr = 0.0002
I0614 23:39:31.931702 15760 solver.cpp:228] Iteration 17660, loss = 0.498308
I0614 23:39:31.931738 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0614 23:39:31.931747 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.163681 (* 1 = 0.163681 loss)
I0614 23:39:31.931753 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.143495 (* 1 = 0.143495 loss)
I0614 23:39:31.931761 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000442407 (* 1 = 0.000442407 loss)
I0614 23:39:31.931766 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380071 (* 1 = 0.0380071 loss)
I0614 23:39:31.931772 15760 sgd_solver.cpp:106] Iteration 17660, lr = 0.0002
I0614 23:41:18.419786 15760 solver.cpp:228] Iteration 17680, loss = 0.470674
I0614 23:41:18.419811 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 23:41:18.419817 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.135042 (* 1 = 0.135042 loss)
I0614 23:41:18.419821 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.220532 (* 1 = 0.220532 loss)
I0614 23:41:18.419824 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00618036 (* 1 = 0.00618036 loss)
I0614 23:41:18.419828 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00775849 (* 1 = 0.00775849 loss)
I0614 23:41:18.419833 15760 sgd_solver.cpp:106] Iteration 17680, lr = 0.0002
I0614 23:43:04.865980 15760 solver.cpp:228] Iteration 17700, loss = 0.470182
I0614 23:43:04.866005 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 23:43:04.866014 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108365 (* 1 = 0.108365 loss)
I0614 23:43:04.866017 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112996 (* 1 = 0.112996 loss)
I0614 23:43:04.866021 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000166804 (* 1 = 0.000166804 loss)
I0614 23:43:04.866024 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148648 (* 1 = 0.0148648 loss)
I0614 23:43:04.866030 15760 sgd_solver.cpp:106] Iteration 17700, lr = 0.0002
I0614 23:44:51.330132 15760 solver.cpp:228] Iteration 17720, loss = 0.348571
I0614 23:44:51.330157 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0614 23:44:51.330163 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.121807 (* 1 = 0.121807 loss)
I0614 23:44:51.330168 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.182604 (* 1 = 0.182604 loss)
I0614 23:44:51.330171 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00318506 (* 1 = 0.00318506 loss)
I0614 23:44:51.330174 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351419 (* 1 = 0.0351419 loss)
I0614 23:44:51.330179 15760 sgd_solver.cpp:106] Iteration 17720, lr = 0.0002
I0614 23:46:38.207206 15760 solver.cpp:228] Iteration 17740, loss = 0.364989
I0614 23:46:38.207231 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0614 23:46:38.207238 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523196 (* 1 = 0.0523196 loss)
I0614 23:46:38.207242 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0775259 (* 1 = 0.0775259 loss)
I0614 23:46:38.207247 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130382 (* 1 = 0.00130382 loss)
I0614 23:46:38.207250 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225688 (* 1 = 0.0225688 loss)
I0614 23:46:38.207255 15760 sgd_solver.cpp:106] Iteration 17740, lr = 0.0002
I0614 23:48:24.454732 15760 solver.cpp:228] Iteration 17760, loss = 0.324644
I0614 23:48:24.454756 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0614 23:48:24.454763 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.187409 (* 1 = 0.187409 loss)
I0614 23:48:24.454767 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.263948 (* 1 = 0.263948 loss)
I0614 23:48:24.454771 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264292 (* 1 = 0.00264292 loss)
I0614 23:48:24.454774 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249717 (* 1 = 0.0249717 loss)
I0614 23:48:24.454778 15760 sgd_solver.cpp:106] Iteration 17760, lr = 0.0002
I0614 23:50:10.776062 15760 solver.cpp:228] Iteration 17780, loss = 0.284338
I0614 23:50:10.776088 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0614 23:50:10.776096 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101308 (* 1 = 0.101308 loss)
I0614 23:50:10.776100 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116332 (* 1 = 0.116332 loss)
I0614 23:50:10.776104 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.28308e-05 (* 1 = 6.28308e-05 loss)
I0614 23:50:10.776108 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126931 (* 1 = 0.0126931 loss)
I0614 23:50:10.776113 15760 sgd_solver.cpp:106] Iteration 17780, lr = 0.0002
speed: 5.331s / iter
I0614 23:51:57.219573 15760 solver.cpp:228] Iteration 17800, loss = 0.436144
I0614 23:51:57.219601 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0614 23:51:57.219611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0981393 (* 1 = 0.0981393 loss)
I0614 23:51:57.219619 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.151018 (* 1 = 0.151018 loss)
I0614 23:51:57.219624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00499069 (* 1 = 0.00499069 loss)
I0614 23:51:57.219630 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405285 (* 1 = 0.0405285 loss)
I0614 23:51:57.219637 15760 sgd_solver.cpp:106] Iteration 17800, lr = 0.0002
I0614 23:53:43.938714 15760 solver.cpp:228] Iteration 17820, loss = 0.530836
I0614 23:53:43.938740 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0614 23:53:43.938746 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.590694 (* 1 = 0.590694 loss)
I0614 23:53:43.938750 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.390017 (* 1 = 0.390017 loss)
I0614 23:53:43.938755 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023036 (* 1 = 0.0023036 loss)
I0614 23:53:43.938760 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125477 (* 1 = 0.125477 loss)
I0614 23:53:43.938766 15760 sgd_solver.cpp:106] Iteration 17820, lr = 0.0002
I0614 23:55:30.762847 15760 solver.cpp:228] Iteration 17840, loss = 0.351045
I0614 23:55:30.762876 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0614 23:55:30.762887 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.116365 (* 1 = 0.116365 loss)
I0614 23:55:30.762892 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.181332 (* 1 = 0.181332 loss)
I0614 23:55:30.762897 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000413111 (* 1 = 0.000413111 loss)
I0614 23:55:30.762902 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00300908 (* 1 = 0.00300908 loss)
I0614 23:55:30.762908 15760 sgd_solver.cpp:106] Iteration 17840, lr = 0.0002
I0614 23:57:17.987642 15760 solver.cpp:228] Iteration 17860, loss = 0.416846
I0614 23:57:17.987665 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0614 23:57:17.987671 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.114879 (* 1 = 0.114879 loss)
I0614 23:57:17.987675 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167825 (* 1 = 0.167825 loss)
I0614 23:57:17.987679 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162944 (* 1 = 0.00162944 loss)
I0614 23:57:17.987682 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112196 (* 1 = 0.0112196 loss)
I0614 23:57:17.987687 15760 sgd_solver.cpp:106] Iteration 17860, lr = 0.0002
I0614 23:59:05.080420 15760 solver.cpp:228] Iteration 17880, loss = 0.609565
I0614 23:59:05.080446 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0614 23:59:05.080457 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.298596 (* 1 = 0.298596 loss)
I0614 23:59:05.080464 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.274168 (* 1 = 0.274168 loss)
I0614 23:59:05.080471 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017604 (* 1 = 0.017604 loss)
I0614 23:59:05.080476 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.135819 (* 1 = 0.135819 loss)
I0614 23:59:05.080485 15760 sgd_solver.cpp:106] Iteration 17880, lr = 0.0002
I0615 00:00:52.165144 15760 solver.cpp:228] Iteration 17900, loss = 0.596156
I0615 00:00:52.165171 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 00:00:52.165180 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.115674 (* 1 = 0.115674 loss)
I0615 00:00:52.165186 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148179 (* 1 = 0.148179 loss)
I0615 00:00:52.165192 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108161 (* 1 = 0.00108161 loss)
I0615 00:00:52.165199 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0539653 (* 1 = 0.0539653 loss)
I0615 00:00:52.165205 15760 sgd_solver.cpp:106] Iteration 17900, lr = 0.0002
I0615 00:02:39.259804 15760 solver.cpp:228] Iteration 17920, loss = 0.344595
I0615 00:02:39.259826 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 00:02:39.259833 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.179944 (* 1 = 0.179944 loss)
I0615 00:02:39.259837 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.23154 (* 1 = 0.23154 loss)
I0615 00:02:39.259841 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00293087 (* 1 = 0.00293087 loss)
I0615 00:02:39.259845 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227565 (* 1 = 0.0227565 loss)
I0615 00:02:39.259850 15760 sgd_solver.cpp:106] Iteration 17920, lr = 0.0002
I0615 00:04:26.677204 15760 solver.cpp:228] Iteration 17940, loss = 0.848894
I0615 00:04:26.677232 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0615 00:04:26.677242 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.638934 (* 1 = 0.638934 loss)
I0615 00:04:26.677249 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.728083 (* 1 = 0.728083 loss)
I0615 00:04:26.677255 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0324501 (* 1 = 0.0324501 loss)
I0615 00:04:26.677263 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.323521 (* 1 = 0.323521 loss)
I0615 00:04:26.677269 15760 sgd_solver.cpp:106] Iteration 17940, lr = 0.0002
I0615 00:06:13.335139 15760 solver.cpp:228] Iteration 17960, loss = 0.42691
I0615 00:06:13.335163 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 00:06:13.335171 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.10393 (* 1 = 0.10393 loss)
I0615 00:06:13.335176 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.157191 (* 1 = 0.157191 loss)
I0615 00:06:13.335180 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143693 (* 1 = 0.00143693 loss)
I0615 00:06:13.335184 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0651203 (* 1 = 0.0651203 loss)
I0615 00:06:13.335189 15760 sgd_solver.cpp:106] Iteration 17960, lr = 0.0002
I0615 00:08:00.528409 15760 solver.cpp:228] Iteration 17980, loss = 0.354477
I0615 00:08:00.528436 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 00:08:00.528445 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0777927 (* 1 = 0.0777927 loss)
I0615 00:08:00.528450 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0627303 (* 1 = 0.0627303 loss)
I0615 00:08:00.528455 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000984626 (* 1 = 0.000984626 loss)
I0615 00:08:00.528460 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204463 (* 1 = 0.0204463 loss)
I0615 00:08:00.528465 15760 sgd_solver.cpp:106] Iteration 17980, lr = 0.0002
speed: 5.331s / iter
I0615 00:09:47.618593 15760 solver.cpp:228] Iteration 18000, loss = 0.694408
I0615 00:09:47.618618 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 00:09:47.618625 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.41884 (* 1 = 0.41884 loss)
I0615 00:09:47.618629 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.361645 (* 1 = 0.361645 loss)
I0615 00:09:47.618633 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112629 (* 1 = 0.0112629 loss)
I0615 00:09:47.618636 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.169208 (* 1 = 0.169208 loss)
I0615 00:09:47.618641 15760 sgd_solver.cpp:106] Iteration 18000, lr = 0.0002
I0615 00:11:35.275010 15760 solver.cpp:228] Iteration 18020, loss = 0.514504
I0615 00:11:35.275043 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 00:11:35.275056 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.191339 (* 1 = 0.191339 loss)
I0615 00:11:35.275065 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.197482 (* 1 = 0.197482 loss)
I0615 00:11:35.275074 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000945986 (* 1 = 0.000945986 loss)
I0615 00:11:35.275082 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221876 (* 1 = 0.0221876 loss)
I0615 00:11:35.275091 15760 sgd_solver.cpp:106] Iteration 18020, lr = 0.0002
I0615 00:13:22.134065 15760 solver.cpp:228] Iteration 18040, loss = 0.488982
I0615 00:13:22.134088 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 00:13:22.134095 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129259 (* 1 = 0.129259 loss)
I0615 00:13:22.134100 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.149033 (* 1 = 0.149033 loss)
I0615 00:13:22.134104 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000580581 (* 1 = 0.000580581 loss)
I0615 00:13:22.134109 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195621 (* 1 = 0.0195621 loss)
I0615 00:13:22.134114 15760 sgd_solver.cpp:106] Iteration 18040, lr = 0.0002
I0615 00:15:09.046226 15760 solver.cpp:228] Iteration 18060, loss = 0.363438
I0615 00:15:09.046250 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 00:15:09.046259 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0790941 (* 1 = 0.0790941 loss)
I0615 00:15:09.046265 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.080575 (* 1 = 0.080575 loss)
I0615 00:15:09.046272 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000559011 (* 1 = 0.000559011 loss)
I0615 00:15:09.046277 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013117 (* 1 = 0.013117 loss)
I0615 00:15:09.046283 15760 sgd_solver.cpp:106] Iteration 18060, lr = 0.0002
I0615 00:16:55.303192 15760 solver.cpp:228] Iteration 18080, loss = 0.464044
I0615 00:16:55.303216 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0615 00:16:55.303222 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.610882 (* 1 = 0.610882 loss)
I0615 00:16:55.303226 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.465372 (* 1 = 0.465372 loss)
I0615 00:16:55.303231 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778288 (* 1 = 0.00778288 loss)
I0615 00:16:55.303233 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128077 (* 1 = 0.128077 loss)
I0615 00:16:55.303238 15760 sgd_solver.cpp:106] Iteration 18080, lr = 0.0002
I0615 00:18:41.696213 15760 solver.cpp:228] Iteration 18100, loss = 0.692152
I0615 00:18:41.696239 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 00:18:41.696247 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231822 (* 1 = 0.0231822 loss)
I0615 00:18:41.696251 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0352231 (* 1 = 0.0352231 loss)
I0615 00:18:41.696255 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577686 (* 1 = 0.00577686 loss)
I0615 00:18:41.696259 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274811 (* 1 = 0.0274811 loss)
I0615 00:18:41.696265 15760 sgd_solver.cpp:106] Iteration 18100, lr = 0.0002
I0615 00:20:28.025338 15760 solver.cpp:228] Iteration 18120, loss = 0.518797
I0615 00:20:28.025367 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 00:20:28.025377 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.13159 (* 1 = 0.13159 loss)
I0615 00:20:28.025380 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.162832 (* 1 = 0.162832 loss)
I0615 00:20:28.025385 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000729626 (* 1 = 0.000729626 loss)
I0615 00:20:28.025389 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00683609 (* 1 = 0.00683609 loss)
I0615 00:20:28.025395 15760 sgd_solver.cpp:106] Iteration 18120, lr = 0.0002
I0615 00:22:14.683589 15760 solver.cpp:228] Iteration 18140, loss = 0.565884
I0615 00:22:14.683616 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 00:22:14.683624 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.127915 (* 1 = 0.127915 loss)
I0615 00:22:14.683629 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0683788 (* 1 = 0.0683788 loss)
I0615 00:22:14.683632 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000810659 (* 1 = 0.000810659 loss)
I0615 00:22:14.683636 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026984 (* 1 = 0.026984 loss)
I0615 00:22:14.683640 15760 sgd_solver.cpp:106] Iteration 18140, lr = 0.0002
I0615 00:24:01.099997 15760 solver.cpp:228] Iteration 18160, loss = 0.826895
I0615 00:24:01.100020 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0615 00:24:01.100028 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.589231 (* 1 = 0.589231 loss)
I0615 00:24:01.100031 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.462075 (* 1 = 0.462075 loss)
I0615 00:24:01.100034 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034259 (* 1 = 0.0034259 loss)
I0615 00:24:01.100039 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.135597 (* 1 = 0.135597 loss)
I0615 00:24:01.100042 15760 sgd_solver.cpp:106] Iteration 18160, lr = 0.0002
I0615 00:25:47.256889 15760 solver.cpp:228] Iteration 18180, loss = 0.565881
I0615 00:25:47.256913 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 00:25:47.256920 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0408735 (* 1 = 0.0408735 loss)
I0615 00:25:47.256924 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.060041 (* 1 = 0.060041 loss)
I0615 00:25:47.256928 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00199527 (* 1 = 0.00199527 loss)
I0615 00:25:47.256932 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197711 (* 1 = 0.0197711 loss)
I0615 00:25:47.256937 15760 sgd_solver.cpp:106] Iteration 18180, lr = 0.0002
speed: 5.331s / iter
I0615 00:27:33.692404 15760 solver.cpp:228] Iteration 18200, loss = 0.495618
I0615 00:27:33.692430 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 00:27:33.692436 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0804565 (* 1 = 0.0804565 loss)
I0615 00:27:33.692441 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0919508 (* 1 = 0.0919508 loss)
I0615 00:27:33.692445 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00596618 (* 1 = 0.00596618 loss)
I0615 00:27:33.692450 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121656 (* 1 = 0.0121656 loss)
I0615 00:27:33.692454 15760 sgd_solver.cpp:106] Iteration 18200, lr = 0.0002
I0615 00:29:20.065042 15760 solver.cpp:228] Iteration 18220, loss = 0.639669
I0615 00:29:20.065066 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 00:29:20.065074 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.323725 (* 1 = 0.323725 loss)
I0615 00:29:20.065078 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.262104 (* 1 = 0.262104 loss)
I0615 00:29:20.065083 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214062 (* 1 = 0.0214062 loss)
I0615 00:29:20.065088 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121619 (* 1 = 0.121619 loss)
I0615 00:29:20.065093 15760 sgd_solver.cpp:106] Iteration 18220, lr = 0.0002
I0615 00:31:06.434274 15760 solver.cpp:228] Iteration 18240, loss = 0.402208
I0615 00:31:06.434299 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 00:31:06.434305 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0538549 (* 1 = 0.0538549 loss)
I0615 00:31:06.434309 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0874335 (* 1 = 0.0874335 loss)
I0615 00:31:06.434314 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000979885 (* 1 = 0.000979885 loss)
I0615 00:31:06.434317 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290004 (* 1 = 0.0290004 loss)
I0615 00:31:06.434322 15760 sgd_solver.cpp:106] Iteration 18240, lr = 0.0002
I0615 00:32:52.743733 15760 solver.cpp:228] Iteration 18260, loss = 0.373892
I0615 00:32:52.743757 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 00:32:52.743763 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.119561 (* 1 = 0.119561 loss)
I0615 00:32:52.743767 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.179625 (* 1 = 0.179625 loss)
I0615 00:32:52.743770 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168507 (* 1 = 0.00168507 loss)
I0615 00:32:52.743774 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014862 (* 1 = 0.014862 loss)
I0615 00:32:52.743779 15760 sgd_solver.cpp:106] Iteration 18260, lr = 0.0002
I0615 00:34:39.178978 15760 solver.cpp:228] Iteration 18280, loss = 0.437661
I0615 00:34:39.179004 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 00:34:39.179014 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.207792 (* 1 = 0.207792 loss)
I0615 00:34:39.179021 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.277048 (* 1 = 0.277048 loss)
I0615 00:34:39.179028 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0054617 (* 1 = 0.0054617 loss)
I0615 00:34:39.179033 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0502421 (* 1 = 0.0502421 loss)
I0615 00:34:39.179040 15760 sgd_solver.cpp:106] Iteration 18280, lr = 0.0002
I0615 00:36:25.890164 15760 solver.cpp:228] Iteration 18300, loss = 0.628605
I0615 00:36:25.890190 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 00:36:25.890200 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.221135 (* 1 = 0.221135 loss)
I0615 00:36:25.890206 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.232475 (* 1 = 0.232475 loss)
I0615 00:36:25.890213 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00658582 (* 1 = 0.00658582 loss)
I0615 00:36:25.890219 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.209994 (* 1 = 0.209994 loss)
I0615 00:36:25.890228 15760 sgd_solver.cpp:106] Iteration 18300, lr = 0.0002
I0615 00:38:12.459559 15760 solver.cpp:228] Iteration 18320, loss = 0.537966
I0615 00:38:12.459583 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 00:38:12.459591 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.275331 (* 1 = 0.275331 loss)
I0615 00:38:12.459595 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.305182 (* 1 = 0.305182 loss)
I0615 00:38:12.459599 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154289 (* 1 = 0.00154289 loss)
I0615 00:38:12.459602 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284824 (* 1 = 0.0284824 loss)
I0615 00:38:12.459609 15760 sgd_solver.cpp:106] Iteration 18320, lr = 0.0002
I0615 00:39:58.763996 15760 solver.cpp:228] Iteration 18340, loss = 0.503134
I0615 00:39:58.764024 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 00:39:58.764032 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0934232 (* 1 = 0.0934232 loss)
I0615 00:39:58.764040 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.062427 (* 1 = 0.062427 loss)
I0615 00:39:58.764046 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000981568 (* 1 = 0.000981568 loss)
I0615 00:39:58.764052 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124028 (* 1 = 0.0124028 loss)
I0615 00:39:58.764061 15760 sgd_solver.cpp:106] Iteration 18340, lr = 0.0002
I0615 00:41:45.592912 15760 solver.cpp:228] Iteration 18360, loss = 0.360475
I0615 00:41:45.592937 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 00:41:45.592949 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0409941 (* 1 = 0.0409941 loss)
I0615 00:41:45.592953 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0499118 (* 1 = 0.0499118 loss)
I0615 00:41:45.592957 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275796 (* 1 = 0.00275796 loss)
I0615 00:41:45.592962 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166109 (* 1 = 0.0166109 loss)
I0615 00:41:45.592967 15760 sgd_solver.cpp:106] Iteration 18360, lr = 0.0002
I0615 00:43:32.071234 15760 solver.cpp:228] Iteration 18380, loss = 0.413449
I0615 00:43:32.071260 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 00:43:32.071267 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.173852 (* 1 = 0.173852 loss)
I0615 00:43:32.071271 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.144352 (* 1 = 0.144352 loss)
I0615 00:43:32.071275 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139387 (* 1 = 0.00139387 loss)
I0615 00:43:32.071280 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149714 (* 1 = 0.0149714 loss)
I0615 00:43:32.071285 15760 sgd_solver.cpp:106] Iteration 18380, lr = 0.0002
speed: 5.331s / iter
I0615 00:45:19.014139 15760 solver.cpp:228] Iteration 18400, loss = 0.404219
I0615 00:45:19.014160 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 00:45:19.014168 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0558385 (* 1 = 0.0558385 loss)
I0615 00:45:19.014171 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0713637 (* 1 = 0.0713637 loss)
I0615 00:45:19.014175 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000487871 (* 1 = 0.000487871 loss)
I0615 00:45:19.014178 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00417682 (* 1 = 0.00417682 loss)
I0615 00:45:19.014183 15760 sgd_solver.cpp:106] Iteration 18400, lr = 0.0002
I0615 00:47:06.391129 15760 solver.cpp:228] Iteration 18420, loss = 0.403015
I0615 00:47:06.391153 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 00:47:06.391160 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.258493 (* 1 = 0.258493 loss)
I0615 00:47:06.391165 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.289756 (* 1 = 0.289756 loss)
I0615 00:47:06.391170 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000817009 (* 1 = 0.000817009 loss)
I0615 00:47:06.391173 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0556699 (* 1 = 0.0556699 loss)
I0615 00:47:06.391177 15760 sgd_solver.cpp:106] Iteration 18420, lr = 0.0002
I0615 00:48:53.040390 15760 solver.cpp:228] Iteration 18440, loss = 0.699332
I0615 00:48:53.040416 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0615 00:48:53.040422 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.737916 (* 1 = 0.737916 loss)
I0615 00:48:53.040426 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.553068 (* 1 = 0.553068 loss)
I0615 00:48:53.040429 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152318 (* 1 = 0.0152318 loss)
I0615 00:48:53.040433 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.58674 (* 1 = 0.58674 loss)
I0615 00:48:53.040438 15760 sgd_solver.cpp:106] Iteration 18440, lr = 0.0002
I0615 00:50:40.505376 15760 solver.cpp:228] Iteration 18460, loss = 0.484854
I0615 00:50:40.505399 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 00:50:40.505406 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.255033 (* 1 = 0.255033 loss)
I0615 00:50:40.505410 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206066 (* 1 = 0.206066 loss)
I0615 00:50:40.505414 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00293934 (* 1 = 0.00293934 loss)
I0615 00:50:40.505419 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0516804 (* 1 = 0.0516804 loss)
I0615 00:50:40.505424 15760 sgd_solver.cpp:106] Iteration 18460, lr = 0.0002
I0615 00:52:27.542737 15760 solver.cpp:228] Iteration 18480, loss = 0.504515
I0615 00:52:27.542767 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0615 00:52:27.542776 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.671458 (* 1 = 0.671458 loss)
I0615 00:52:27.542783 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.529743 (* 1 = 0.529743 loss)
I0615 00:52:27.542788 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115438 (* 1 = 0.0115438 loss)
I0615 00:52:27.542793 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1833 (* 1 = 0.1833 loss)
I0615 00:52:27.542798 15760 sgd_solver.cpp:106] Iteration 18480, lr = 0.0002
I0615 00:54:13.936822 15760 solver.cpp:228] Iteration 18500, loss = 0.388195
I0615 00:54:13.936846 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 00:54:13.936852 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113284 (* 1 = 0.113284 loss)
I0615 00:54:13.936856 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0883792 (* 1 = 0.0883792 loss)
I0615 00:54:13.936861 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00297314 (* 1 = 0.00297314 loss)
I0615 00:54:13.936863 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00797832 (* 1 = 0.00797832 loss)
I0615 00:54:13.936867 15760 sgd_solver.cpp:106] Iteration 18500, lr = 0.0002
I0615 00:56:00.709343 15760 solver.cpp:228] Iteration 18520, loss = 0.385771
I0615 00:56:00.709367 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 00:56:00.709374 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0611937 (* 1 = 0.0611937 loss)
I0615 00:56:00.709378 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.13349 (* 1 = 0.13349 loss)
I0615 00:56:00.709383 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141794 (* 1 = 0.00141794 loss)
I0615 00:56:00.709385 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013044 (* 1 = 0.013044 loss)
I0615 00:56:00.709390 15760 sgd_solver.cpp:106] Iteration 18520, lr = 0.0002
I0615 00:57:47.340016 15760 solver.cpp:228] Iteration 18540, loss = 0.45518
I0615 00:57:47.340039 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 00:57:47.340046 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.138223 (* 1 = 0.138223 loss)
I0615 00:57:47.340050 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.141648 (* 1 = 0.141648 loss)
I0615 00:57:47.340054 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000296025 (* 1 = 0.000296025 loss)
I0615 00:57:47.340057 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231232 (* 1 = 0.0231232 loss)
I0615 00:57:47.340062 15760 sgd_solver.cpp:106] Iteration 18540, lr = 0.0002
I0615 00:59:33.673861 15760 solver.cpp:228] Iteration 18560, loss = 0.505259
I0615 00:59:33.673888 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0615 00:59:33.673895 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.491084 (* 1 = 0.491084 loss)
I0615 00:59:33.673899 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.480587 (* 1 = 0.480587 loss)
I0615 00:59:33.673903 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140555 (* 1 = 0.0140555 loss)
I0615 00:59:33.673907 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.144951 (* 1 = 0.144951 loss)
I0615 00:59:33.673913 15760 sgd_solver.cpp:106] Iteration 18560, lr = 0.0002
I0615 01:01:20.220448 15760 solver.cpp:228] Iteration 18580, loss = 0.359144
I0615 01:01:20.220471 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 01:01:20.220479 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0644368 (* 1 = 0.0644368 loss)
I0615 01:01:20.220484 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0755395 (* 1 = 0.0755395 loss)
I0615 01:01:20.220489 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236409 (* 1 = 0.00236409 loss)
I0615 01:01:20.220491 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00702318 (* 1 = 0.00702318 loss)
I0615 01:01:20.220497 15760 sgd_solver.cpp:106] Iteration 18580, lr = 0.0002
speed: 5.331s / iter
I0615 01:03:06.637976 15760 solver.cpp:228] Iteration 18600, loss = 0.926533
I0615 01:03:06.638000 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 01:03:06.638007 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.241877 (* 1 = 0.241877 loss)
I0615 01:03:06.638010 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.263582 (* 1 = 0.263582 loss)
I0615 01:03:06.638015 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0033293 (* 1 = 0.0033293 loss)
I0615 01:03:06.638018 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.147053 (* 1 = 0.147053 loss)
I0615 01:03:06.638022 15760 sgd_solver.cpp:106] Iteration 18600, lr = 0.0002
I0615 01:04:52.979238 15760 solver.cpp:228] Iteration 18620, loss = 0.378271
I0615 01:04:52.979261 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 01:04:52.979269 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0987906 (* 1 = 0.0987906 loss)
I0615 01:04:52.979272 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0832235 (* 1 = 0.0832235 loss)
I0615 01:04:52.979276 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101263 (* 1 = 0.00101263 loss)
I0615 01:04:52.979280 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129405 (* 1 = 0.0129405 loss)
I0615 01:04:52.979285 15760 sgd_solver.cpp:106] Iteration 18620, lr = 0.0002
I0615 01:06:39.337735 15760 solver.cpp:228] Iteration 18640, loss = 0.561144
I0615 01:06:39.337761 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 01:06:39.337769 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.088337 (* 1 = 0.088337 loss)
I0615 01:06:39.337774 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.108945 (* 1 = 0.108945 loss)
I0615 01:06:39.337779 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00394884 (* 1 = 0.00394884 loss)
I0615 01:06:39.337781 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012648 (* 1 = 0.012648 loss)
I0615 01:06:39.337787 15760 sgd_solver.cpp:106] Iteration 18640, lr = 0.0002
I0615 01:08:25.799047 15760 solver.cpp:228] Iteration 18660, loss = 0.276097
I0615 01:08:25.799073 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 01:08:25.799080 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.1951 (* 1 = 0.1951 loss)
I0615 01:08:25.799085 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.24412 (* 1 = 0.24412 loss)
I0615 01:08:25.799089 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000523369 (* 1 = 0.000523369 loss)
I0615 01:08:25.799093 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224196 (* 1 = 0.0224196 loss)
I0615 01:08:25.799098 15760 sgd_solver.cpp:106] Iteration 18660, lr = 0.0002
I0615 01:10:12.075099 15760 solver.cpp:228] Iteration 18680, loss = 0.553274
I0615 01:10:12.075124 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0615 01:10:12.075130 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.483638 (* 1 = 0.483638 loss)
I0615 01:10:12.075134 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.473701 (* 1 = 0.473701 loss)
I0615 01:10:12.075139 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00721008 (* 1 = 0.00721008 loss)
I0615 01:10:12.075142 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.177637 (* 1 = 0.177637 loss)
I0615 01:10:12.075146 15760 sgd_solver.cpp:106] Iteration 18680, lr = 0.0002
I0615 01:11:58.253769 15760 solver.cpp:228] Iteration 18700, loss = 0.547647
I0615 01:11:58.253793 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 01:11:58.253800 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.207521 (* 1 = 0.207521 loss)
I0615 01:11:58.253804 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109841 (* 1 = 0.109841 loss)
I0615 01:11:58.253808 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00673973 (* 1 = 0.00673973 loss)
I0615 01:11:58.253811 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206268 (* 1 = 0.0206268 loss)
I0615 01:11:58.253816 15760 sgd_solver.cpp:106] Iteration 18700, lr = 0.0002
I0615 01:13:44.610637 15760 solver.cpp:228] Iteration 18720, loss = 0.333301
I0615 01:13:44.610663 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 01:13:44.610671 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.167629 (* 1 = 0.167629 loss)
I0615 01:13:44.610675 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167208 (* 1 = 0.167208 loss)
I0615 01:13:44.610679 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130381 (* 1 = 0.00130381 loss)
I0615 01:13:44.610683 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199035 (* 1 = 0.0199035 loss)
I0615 01:13:44.610688 15760 sgd_solver.cpp:106] Iteration 18720, lr = 0.0002
I0615 01:15:31.072062 15760 solver.cpp:228] Iteration 18740, loss = 0.375588
I0615 01:15:31.072091 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 01:15:31.072098 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0763476 (* 1 = 0.0763476 loss)
I0615 01:15:31.072103 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0550134 (* 1 = 0.0550134 loss)
I0615 01:15:31.072108 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00313129 (* 1 = 0.00313129 loss)
I0615 01:15:31.072110 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122602 (* 1 = 0.0122602 loss)
I0615 01:15:31.072115 15760 sgd_solver.cpp:106] Iteration 18740, lr = 0.0002
I0615 01:17:17.662554 15760 solver.cpp:228] Iteration 18760, loss = 0.596661
I0615 01:17:17.662580 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 01:17:17.662587 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0916452 (* 1 = 0.0916452 loss)
I0615 01:17:17.662592 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.106566 (* 1 = 0.106566 loss)
I0615 01:17:17.662596 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000834141 (* 1 = 0.000834141 loss)
I0615 01:17:17.662602 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00812793 (* 1 = 0.00812793 loss)
I0615 01:17:17.662611 15760 sgd_solver.cpp:106] Iteration 18760, lr = 0.0002
I0615 01:19:04.123438 15760 solver.cpp:228] Iteration 18780, loss = 0.405133
I0615 01:19:04.123462 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0615 01:19:04.123469 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.413002 (* 1 = 0.413002 loss)
I0615 01:19:04.123472 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.401235 (* 1 = 0.401235 loss)
I0615 01:19:04.123476 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00379639 (* 1 = 0.00379639 loss)
I0615 01:19:04.123479 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.181502 (* 1 = 0.181502 loss)
I0615 01:19:04.123484 15760 sgd_solver.cpp:106] Iteration 18780, lr = 0.0002
speed: 5.331s / iter
I0615 01:20:50.418464 15760 solver.cpp:228] Iteration 18800, loss = 0.498714
I0615 01:20:50.418489 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0615 01:20:50.418496 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.633625 (* 1 = 0.633625 loss)
I0615 01:20:50.418500 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.486833 (* 1 = 0.486833 loss)
I0615 01:20:50.418503 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00987302 (* 1 = 0.00987302 loss)
I0615 01:20:50.418507 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.121642 (* 1 = 0.121642 loss)
I0615 01:20:50.418512 15760 sgd_solver.cpp:106] Iteration 18800, lr = 0.0002
I0615 01:22:36.796649 15760 solver.cpp:228] Iteration 18820, loss = 0.318844
I0615 01:22:36.796672 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 01:22:36.796679 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605419 (* 1 = 0.0605419 loss)
I0615 01:22:36.796684 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0573161 (* 1 = 0.0573161 loss)
I0615 01:22:36.796687 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281104 (* 1 = 0.00281104 loss)
I0615 01:22:36.796690 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197962 (* 1 = 0.0197962 loss)
I0615 01:22:36.796695 15760 sgd_solver.cpp:106] Iteration 18820, lr = 0.0002
I0615 01:24:24.085486 15760 solver.cpp:228] Iteration 18840, loss = 0.433344
I0615 01:24:24.085518 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 01:24:24.085527 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109423 (* 1 = 0.109423 loss)
I0615 01:24:24.085532 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.147344 (* 1 = 0.147344 loss)
I0615 01:24:24.085538 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.99033e-05 (* 1 = 8.99033e-05 loss)
I0615 01:24:24.085542 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116964 (* 1 = 0.0116964 loss)
I0615 01:24:24.085549 15760 sgd_solver.cpp:106] Iteration 18840, lr = 0.0002
I0615 01:26:10.561211 15760 solver.cpp:228] Iteration 18860, loss = 0.702076
I0615 01:26:10.561236 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 01:26:10.561244 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.157759 (* 1 = 0.157759 loss)
I0615 01:26:10.561250 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.163203 (* 1 = 0.163203 loss)
I0615 01:26:10.561255 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000455681 (* 1 = 0.000455681 loss)
I0615 01:26:10.561261 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172478 (* 1 = 0.0172478 loss)
I0615 01:26:10.561269 15760 sgd_solver.cpp:106] Iteration 18860, lr = 0.0002
I0615 01:27:57.062814 15760 solver.cpp:228] Iteration 18880, loss = 0.631347
I0615 01:27:57.062836 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 01:27:57.062844 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0996407 (* 1 = 0.0996407 loss)
I0615 01:27:57.062847 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.104542 (* 1 = 0.104542 loss)
I0615 01:27:57.062851 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000519717 (* 1 = 0.000519717 loss)
I0615 01:27:57.062855 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0097339 (* 1 = 0.0097339 loss)
I0615 01:27:57.062860 15760 sgd_solver.cpp:106] Iteration 18880, lr = 0.0002
I0615 01:29:43.940572 15760 solver.cpp:228] Iteration 18900, loss = 0.867433
I0615 01:29:43.940596 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 01:29:43.940603 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.271077 (* 1 = 0.271077 loss)
I0615 01:29:43.940608 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.320786 (* 1 = 0.320786 loss)
I0615 01:29:43.940611 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0345579 (* 1 = 0.0345579 loss)
I0615 01:29:43.940614 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.480677 (* 1 = 0.480677 loss)
I0615 01:29:43.940618 15760 sgd_solver.cpp:106] Iteration 18900, lr = 0.0002
I0615 01:31:31.001616 15760 solver.cpp:228] Iteration 18920, loss = 0.448754
I0615 01:31:31.001642 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 01:31:31.001652 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0956371 (* 1 = 0.0956371 loss)
I0615 01:31:31.001659 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.118589 (* 1 = 0.118589 loss)
I0615 01:31:31.001665 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000131752 (* 1 = 0.000131752 loss)
I0615 01:31:31.001672 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00941731 (* 1 = 0.00941731 loss)
I0615 01:31:31.001682 15760 sgd_solver.cpp:106] Iteration 18920, lr = 0.0002
I0615 01:33:18.221989 15760 solver.cpp:228] Iteration 18940, loss = 0.376068
I0615 01:33:18.222017 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 01:33:18.222023 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.238795 (* 1 = 0.238795 loss)
I0615 01:33:18.222028 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.197584 (* 1 = 0.197584 loss)
I0615 01:33:18.222031 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110617 (* 1 = 0.00110617 loss)
I0615 01:33:18.222036 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192407 (* 1 = 0.0192407 loss)
I0615 01:33:18.222041 15760 sgd_solver.cpp:106] Iteration 18940, lr = 0.0002
I0615 01:35:05.163852 15760 solver.cpp:228] Iteration 18960, loss = 0.441661
I0615 01:35:05.163877 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 01:35:05.163884 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0992371 (* 1 = 0.0992371 loss)
I0615 01:35:05.163888 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.212217 (* 1 = 0.212217 loss)
I0615 01:35:05.163892 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00387666 (* 1 = 0.00387666 loss)
I0615 01:35:05.163895 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0615934 (* 1 = 0.0615934 loss)
I0615 01:35:05.163900 15760 sgd_solver.cpp:106] Iteration 18960, lr = 0.0002
I0615 01:36:52.458804 15760 solver.cpp:228] Iteration 18980, loss = 0.364567
I0615 01:36:52.458828 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 01:36:52.458837 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.13179 (* 1 = 0.13179 loss)
I0615 01:36:52.458844 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0894052 (* 1 = 0.0894052 loss)
I0615 01:36:52.458850 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.33019e-05 (* 1 = 6.33019e-05 loss)
I0615 01:36:52.458855 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00463465 (* 1 = 0.00463465 loss)
I0615 01:36:52.458864 15760 sgd_solver.cpp:106] Iteration 18980, lr = 0.0002
speed: 5.331s / iter
I0615 01:38:38.891925 15760 solver.cpp:228] Iteration 19000, loss = 0.36976
I0615 01:38:38.891950 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 01:38:38.891957 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.200397 (* 1 = 0.200397 loss)
I0615 01:38:38.891964 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148189 (* 1 = 0.148189 loss)
I0615 01:38:38.891971 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00420316 (* 1 = 0.00420316 loss)
I0615 01:38:38.891976 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159175 (* 1 = 0.0159175 loss)
I0615 01:38:38.891983 15760 sgd_solver.cpp:106] Iteration 19000, lr = 0.0002
I0615 01:40:25.526674 15760 solver.cpp:228] Iteration 19020, loss = 0.435545
I0615 01:40:25.526700 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 01:40:25.526707 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0638203 (* 1 = 0.0638203 loss)
I0615 01:40:25.526711 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0451922 (* 1 = 0.0451922 loss)
I0615 01:40:25.526715 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000250944 (* 1 = 0.000250944 loss)
I0615 01:40:25.526720 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145529 (* 1 = 0.0145529 loss)
I0615 01:40:25.526724 15760 sgd_solver.cpp:106] Iteration 19020, lr = 0.0002
I0615 01:42:12.268129 15760 solver.cpp:228] Iteration 19040, loss = 0.439487
I0615 01:42:12.268152 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 01:42:12.268160 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.164596 (* 1 = 0.164596 loss)
I0615 01:42:12.268164 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.14375 (* 1 = 0.14375 loss)
I0615 01:42:12.268168 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205625 (* 1 = 0.00205625 loss)
I0615 01:42:12.268172 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0861227 (* 1 = 0.0861227 loss)
I0615 01:42:12.268177 15760 sgd_solver.cpp:106] Iteration 19040, lr = 0.0002
I0615 01:43:58.788765 15760 solver.cpp:228] Iteration 19060, loss = 0.552115
I0615 01:43:58.788789 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 01:43:58.788795 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707629 (* 1 = 0.0707629 loss)
I0615 01:43:58.788800 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109271 (* 1 = 0.109271 loss)
I0615 01:43:58.788803 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000311079 (* 1 = 0.000311079 loss)
I0615 01:43:58.788807 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263813 (* 1 = 0.0263813 loss)
I0615 01:43:58.788811 15760 sgd_solver.cpp:106] Iteration 19060, lr = 0.0002
I0615 01:45:45.239822 15760 solver.cpp:228] Iteration 19080, loss = 0.353615
I0615 01:45:45.239847 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 01:45:45.239856 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0910962 (* 1 = 0.0910962 loss)
I0615 01:45:45.239861 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.146406 (* 1 = 0.146406 loss)
I0615 01:45:45.239864 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142596 (* 1 = 0.0142596 loss)
I0615 01:45:45.239867 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414285 (* 1 = 0.0414285 loss)
I0615 01:45:45.239872 15760 sgd_solver.cpp:106] Iteration 19080, lr = 0.0002
I0615 01:47:31.830844 15760 solver.cpp:228] Iteration 19100, loss = 0.610493
I0615 01:47:31.830870 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 01:47:31.830878 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.182007 (* 1 = 0.182007 loss)
I0615 01:47:31.830883 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.183052 (* 1 = 0.183052 loss)
I0615 01:47:31.830885 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000443906 (* 1 = 0.000443906 loss)
I0615 01:47:31.830890 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0404016 (* 1 = 0.0404016 loss)
I0615 01:47:31.830894 15760 sgd_solver.cpp:106] Iteration 19100, lr = 0.0002
I0615 01:49:18.045094 15760 solver.cpp:228] Iteration 19120, loss = 0.461388
I0615 01:49:18.045117 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 01:49:18.045125 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0624318 (* 1 = 0.0624318 loss)
I0615 01:49:18.045128 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.07238 (* 1 = 0.07238 loss)
I0615 01:49:18.045132 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00167901 (* 1 = 0.00167901 loss)
I0615 01:49:18.045135 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223869 (* 1 = 0.0223869 loss)
I0615 01:49:18.045140 15760 sgd_solver.cpp:106] Iteration 19120, lr = 0.0002
I0615 01:51:04.367619 15760 solver.cpp:228] Iteration 19140, loss = 0.414075
I0615 01:51:04.367641 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0615 01:51:04.367648 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.533493 (* 1 = 0.533493 loss)
I0615 01:51:04.367652 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.344877 (* 1 = 0.344877 loss)
I0615 01:51:04.367656 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00177336 (* 1 = 0.00177336 loss)
I0615 01:51:04.367660 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0685863 (* 1 = 0.0685863 loss)
I0615 01:51:04.367664 15760 sgd_solver.cpp:106] Iteration 19140, lr = 0.0002
I0615 01:52:50.630347 15760 solver.cpp:228] Iteration 19160, loss = 0.527902
I0615 01:52:50.630373 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0615 01:52:50.630383 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.455412 (* 1 = 0.455412 loss)
I0615 01:52:50.630389 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.450018 (* 1 = 0.450018 loss)
I0615 01:52:50.630396 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00792254 (* 1 = 0.00792254 loss)
I0615 01:52:50.630403 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0951525 (* 1 = 0.0951525 loss)
I0615 01:52:50.630409 15760 sgd_solver.cpp:106] Iteration 19160, lr = 0.0002
I0615 01:54:37.015669 15760 solver.cpp:228] Iteration 19180, loss = 0.583037
I0615 01:54:37.015692 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 01:54:37.015699 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415984 (* 1 = 0.0415984 loss)
I0615 01:54:37.015703 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0767283 (* 1 = 0.0767283 loss)
I0615 01:54:37.015707 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141843 (* 1 = 0.00141843 loss)
I0615 01:54:37.015710 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158561 (* 1 = 0.0158561 loss)
I0615 01:54:37.015715 15760 sgd_solver.cpp:106] Iteration 19180, lr = 0.0002
speed: 5.331s / iter
I0615 01:56:23.490011 15760 solver.cpp:228] Iteration 19200, loss = 0.316545
I0615 01:56:23.490036 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 01:56:23.490042 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0974764 (* 1 = 0.0974764 loss)
I0615 01:56:23.490046 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.160445 (* 1 = 0.160445 loss)
I0615 01:56:23.490049 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114442 (* 1 = 0.00114442 loss)
I0615 01:56:23.490053 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00927087 (* 1 = 0.00927087 loss)
I0615 01:56:23.490058 15760 sgd_solver.cpp:106] Iteration 19200, lr = 0.0002
I0615 01:58:09.852846 15760 solver.cpp:228] Iteration 19220, loss = 0.461552
I0615 01:58:09.852879 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 01:58:09.852890 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.178582 (* 1 = 0.178582 loss)
I0615 01:58:09.852896 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.239703 (* 1 = 0.239703 loss)
I0615 01:58:09.852902 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000362924 (* 1 = 0.000362924 loss)
I0615 01:58:09.852910 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0406558 (* 1 = 0.0406558 loss)
I0615 01:58:09.852917 15760 sgd_solver.cpp:106] Iteration 19220, lr = 0.0002
I0615 01:59:56.299062 15760 solver.cpp:228] Iteration 19240, loss = 0.384549
I0615 01:59:56.299085 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 01:59:56.299093 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0805581 (* 1 = 0.0805581 loss)
I0615 01:59:56.299098 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119672 (* 1 = 0.119672 loss)
I0615 01:59:56.299101 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00251187 (* 1 = 0.00251187 loss)
I0615 01:59:56.299105 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011025 (* 1 = 0.011025 loss)
I0615 01:59:56.299111 15760 sgd_solver.cpp:106] Iteration 19240, lr = 0.0002
I0615 02:01:42.535353 15760 solver.cpp:228] Iteration 19260, loss = 0.428603
I0615 02:01:42.535375 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0615 02:01:42.535382 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.347262 (* 1 = 0.347262 loss)
I0615 02:01:42.535385 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.497146 (* 1 = 0.497146 loss)
I0615 02:01:42.535389 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026459 (* 1 = 0.026459 loss)
I0615 02:01:42.535392 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.140632 (* 1 = 0.140632 loss)
I0615 02:01:42.535398 15760 sgd_solver.cpp:106] Iteration 19260, lr = 0.0002
I0615 02:03:28.841198 15760 solver.cpp:228] Iteration 19280, loss = 0.323699
I0615 02:03:28.841222 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 02:03:28.841228 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.333462 (* 1 = 0.333462 loss)
I0615 02:03:28.841233 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.229242 (* 1 = 0.229242 loss)
I0615 02:03:28.841236 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00459775 (* 1 = 0.00459775 loss)
I0615 02:03:28.841239 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488439 (* 1 = 0.0488439 loss)
I0615 02:03:28.841244 15760 sgd_solver.cpp:106] Iteration 19280, lr = 0.0002
I0615 02:05:15.040467 15760 solver.cpp:228] Iteration 19300, loss = 0.389676
I0615 02:05:15.040493 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 02:05:15.040499 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.254064 (* 1 = 0.254064 loss)
I0615 02:05:15.040504 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.173508 (* 1 = 0.173508 loss)
I0615 02:05:15.040508 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0077306 (* 1 = 0.0077306 loss)
I0615 02:05:15.040513 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330644 (* 1 = 0.0330644 loss)
I0615 02:05:15.040518 15760 sgd_solver.cpp:106] Iteration 19300, lr = 0.0002
I0615 02:07:01.529943 15760 solver.cpp:228] Iteration 19320, loss = 0.332942
I0615 02:07:01.529966 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 02:07:01.529973 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748922 (* 1 = 0.0748922 loss)
I0615 02:07:01.529976 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0991373 (* 1 = 0.0991373 loss)
I0615 02:07:01.529980 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157587 (* 1 = 0.00157587 loss)
I0615 02:07:01.529983 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00667848 (* 1 = 0.00667848 loss)
I0615 02:07:01.529989 15760 sgd_solver.cpp:106] Iteration 19320, lr = 0.0002
I0615 02:08:48.407490 15760 solver.cpp:228] Iteration 19340, loss = 0.837848
I0615 02:08:48.407515 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0615 02:08:48.407521 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.645704 (* 1 = 0.645704 loss)
I0615 02:08:48.407526 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.641691 (* 1 = 0.641691 loss)
I0615 02:08:48.407529 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0449636 (* 1 = 0.0449636 loss)
I0615 02:08:48.407533 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.576481 (* 1 = 0.576481 loss)
I0615 02:08:48.407538 15760 sgd_solver.cpp:106] Iteration 19340, lr = 0.0002
I0615 02:10:34.877992 15760 solver.cpp:228] Iteration 19360, loss = 0.332611
I0615 02:10:34.878020 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 02:10:34.878028 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882482 (* 1 = 0.0882482 loss)
I0615 02:10:34.878033 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0817269 (* 1 = 0.0817269 loss)
I0615 02:10:34.878038 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0030821 (* 1 = 0.0030821 loss)
I0615 02:10:34.878042 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133361 (* 1 = 0.0133361 loss)
I0615 02:10:34.878048 15760 sgd_solver.cpp:106] Iteration 19360, lr = 0.0002
I0615 02:12:22.236362 15760 solver.cpp:228] Iteration 19380, loss = 0.646008
I0615 02:12:22.236387 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0615 02:12:22.236394 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.730249 (* 1 = 0.730249 loss)
I0615 02:12:22.236398 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.631307 (* 1 = 0.631307 loss)
I0615 02:12:22.236402 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201173 (* 1 = 0.0201173 loss)
I0615 02:12:22.236407 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.330401 (* 1 = 0.330401 loss)
I0615 02:12:22.236412 15760 sgd_solver.cpp:106] Iteration 19380, lr = 0.0002
speed: 5.331s / iter
I0615 02:14:09.316959 15760 solver.cpp:228] Iteration 19400, loss = 0.568754
I0615 02:14:09.316987 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 02:14:09.316995 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.618046 (* 1 = 0.618046 loss)
I0615 02:14:09.316999 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.467734 (* 1 = 0.467734 loss)
I0615 02:14:09.317003 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330523 (* 1 = 0.00330523 loss)
I0615 02:14:09.317008 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.095933 (* 1 = 0.095933 loss)
I0615 02:14:09.317013 15760 sgd_solver.cpp:106] Iteration 19400, lr = 0.0002
I0615 02:15:55.794347 15760 solver.cpp:228] Iteration 19420, loss = 0.412831
I0615 02:15:55.794369 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 02:15:55.794376 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576556 (* 1 = 0.0576556 loss)
I0615 02:15:55.794380 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0628514 (* 1 = 0.0628514 loss)
I0615 02:15:55.794384 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131657 (* 1 = 0.0131657 loss)
I0615 02:15:55.794387 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490521 (* 1 = 0.0490521 loss)
I0615 02:15:55.794392 15760 sgd_solver.cpp:106] Iteration 19420, lr = 0.0002
I0615 02:17:42.626467 15760 solver.cpp:228] Iteration 19440, loss = 0.493239
I0615 02:17:42.626492 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 02:17:42.626500 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.055394 (* 1 = 0.055394 loss)
I0615 02:17:42.626504 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.125969 (* 1 = 0.125969 loss)
I0615 02:17:42.626508 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181609 (* 1 = 0.00181609 loss)
I0615 02:17:42.626513 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290124 (* 1 = 0.0290124 loss)
I0615 02:17:42.626516 15760 sgd_solver.cpp:106] Iteration 19440, lr = 0.0002
I0615 02:19:29.053370 15760 solver.cpp:228] Iteration 19460, loss = 0.286984
I0615 02:19:29.053396 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 02:19:29.053403 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15859 (* 1 = 0.15859 loss)
I0615 02:19:29.053408 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130787 (* 1 = 0.130787 loss)
I0615 02:19:29.053412 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000476681 (* 1 = 0.000476681 loss)
I0615 02:19:29.053416 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362482 (* 1 = 0.0362482 loss)
I0615 02:19:29.053422 15760 sgd_solver.cpp:106] Iteration 19460, lr = 0.0002
I0615 02:21:15.451128 15760 solver.cpp:228] Iteration 19480, loss = 0.337573
I0615 02:21:15.451150 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 02:21:15.451158 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0457775 (* 1 = 0.0457775 loss)
I0615 02:21:15.451161 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0543995 (* 1 = 0.0543995 loss)
I0615 02:21:15.451165 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.028821 (* 1 = 0.028821 loss)
I0615 02:21:15.451169 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018538 (* 1 = 0.018538 loss)
I0615 02:21:15.451174 15760 sgd_solver.cpp:106] Iteration 19480, lr = 0.0002
I0615 02:23:02.021561 15760 solver.cpp:228] Iteration 19500, loss = 0.519022
I0615 02:23:02.021584 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 02:23:02.021590 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15613 (* 1 = 0.15613 loss)
I0615 02:23:02.021595 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.124761 (* 1 = 0.124761 loss)
I0615 02:23:02.021597 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000233165 (* 1 = 0.000233165 loss)
I0615 02:23:02.021601 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049993 (* 1 = 0.049993 loss)
I0615 02:23:02.021605 15760 sgd_solver.cpp:106] Iteration 19500, lr = 0.0002
I0615 02:24:48.777956 15760 solver.cpp:228] Iteration 19520, loss = 0.557611
I0615 02:24:48.777986 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.554688
I0615 02:24:48.777994 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.77383 (* 1 = 0.77383 loss)
I0615 02:24:48.777999 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.797285 (* 1 = 0.797285 loss)
I0615 02:24:48.778004 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0343068 (* 1 = 0.0343068 loss)
I0615 02:24:48.778008 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.389826 (* 1 = 0.389826 loss)
I0615 02:24:48.778014 15760 sgd_solver.cpp:106] Iteration 19520, lr = 0.0002
I0615 02:26:35.790083 15760 solver.cpp:228] Iteration 19540, loss = 0.293773
I0615 02:26:35.790105 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 02:26:35.790112 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0416994 (* 1 = 0.0416994 loss)
I0615 02:26:35.790117 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.047454 (* 1 = 0.047454 loss)
I0615 02:26:35.790120 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029839 (* 1 = 0.0029839 loss)
I0615 02:26:35.790123 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269545 (* 1 = 0.0269545 loss)
I0615 02:26:35.790128 15760 sgd_solver.cpp:106] Iteration 19540, lr = 0.0002
I0615 02:28:22.328896 15760 solver.cpp:228] Iteration 19560, loss = 0.36362
I0615 02:28:22.328922 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 02:28:22.328930 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0921305 (* 1 = 0.0921305 loss)
I0615 02:28:22.328934 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0662181 (* 1 = 0.0662181 loss)
I0615 02:28:22.328943 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000214577 (* 1 = 0.000214577 loss)
I0615 02:28:22.328948 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144603 (* 1 = 0.0144603 loss)
I0615 02:28:22.328953 15760 sgd_solver.cpp:106] Iteration 19560, lr = 0.0002
I0615 02:30:08.796218 15760 solver.cpp:228] Iteration 19580, loss = 0.50986
I0615 02:30:08.796244 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 02:30:08.796254 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.250053 (* 1 = 0.250053 loss)
I0615 02:30:08.796260 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206543 (* 1 = 0.206543 loss)
I0615 02:30:08.796267 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237637 (* 1 = 0.00237637 loss)
I0615 02:30:08.796273 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0519996 (* 1 = 0.0519996 loss)
I0615 02:30:08.796280 15760 sgd_solver.cpp:106] Iteration 19580, lr = 0.0002
speed: 5.331s / iter
I0615 02:31:55.296684 15760 solver.cpp:228] Iteration 19600, loss = 0.454975
I0615 02:31:55.296706 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 02:31:55.296713 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0747498 (* 1 = 0.0747498 loss)
I0615 02:31:55.296717 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0603708 (* 1 = 0.0603708 loss)
I0615 02:31:55.296721 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000123324 (* 1 = 0.000123324 loss)
I0615 02:31:55.296725 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013473 (* 1 = 0.013473 loss)
I0615 02:31:55.296730 15760 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I0615 02:33:41.724537 15760 solver.cpp:228] Iteration 19620, loss = 0.366558
I0615 02:33:41.724562 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 02:33:41.724570 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.16364 (* 1 = 0.16364 loss)
I0615 02:33:41.724573 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.181213 (* 1 = 0.181213 loss)
I0615 02:33:41.724576 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00488584 (* 1 = 0.00488584 loss)
I0615 02:33:41.724581 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351783 (* 1 = 0.0351783 loss)
I0615 02:33:41.724586 15760 sgd_solver.cpp:106] Iteration 19620, lr = 0.0002
I0615 02:35:28.021054 15760 solver.cpp:228] Iteration 19640, loss = 0.422946
I0615 02:35:28.021080 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0615 02:35:28.021088 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.481478 (* 1 = 0.481478 loss)
I0615 02:35:28.021092 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.455473 (* 1 = 0.455473 loss)
I0615 02:35:28.021096 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121898 (* 1 = 0.00121898 loss)
I0615 02:35:28.021101 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.084151 (* 1 = 0.084151 loss)
I0615 02:35:28.021106 15760 sgd_solver.cpp:106] Iteration 19640, lr = 0.0002
I0615 02:37:14.372648 15760 solver.cpp:228] Iteration 19660, loss = 0.378059
I0615 02:37:14.372680 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 02:37:14.372689 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112385 (* 1 = 0.112385 loss)
I0615 02:37:14.372694 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.101775 (* 1 = 0.101775 loss)
I0615 02:37:14.372697 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.006194 (* 1 = 0.006194 loss)
I0615 02:37:14.372700 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133687 (* 1 = 0.0133687 loss)
I0615 02:37:14.372706 15760 sgd_solver.cpp:106] Iteration 19660, lr = 0.0002
I0615 02:39:00.514917 15760 solver.cpp:228] Iteration 19680, loss = 0.310972
I0615 02:39:00.514942 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 02:39:00.514950 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.155458 (* 1 = 0.155458 loss)
I0615 02:39:00.514952 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.162859 (* 1 = 0.162859 loss)
I0615 02:39:00.514956 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000148072 (* 1 = 0.000148072 loss)
I0615 02:39:00.514959 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0531969 (* 1 = 0.0531969 loss)
I0615 02:39:00.514964 15760 sgd_solver.cpp:106] Iteration 19680, lr = 0.0002
I0615 02:40:46.842056 15760 solver.cpp:228] Iteration 19700, loss = 0.464542
I0615 02:40:46.842080 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 02:40:46.842089 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0483804 (* 1 = 0.0483804 loss)
I0615 02:40:46.842097 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0545852 (* 1 = 0.0545852 loss)
I0615 02:40:46.842103 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000457058 (* 1 = 0.000457058 loss)
I0615 02:40:46.842108 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00695024 (* 1 = 0.00695024 loss)
I0615 02:40:46.842115 15760 sgd_solver.cpp:106] Iteration 19700, lr = 0.0002
I0615 02:42:33.401913 15760 solver.cpp:228] Iteration 19720, loss = 0.603816
I0615 02:42:33.401937 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 02:42:33.401944 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0477601 (* 1 = 0.0477601 loss)
I0615 02:42:33.401948 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0931256 (* 1 = 0.0931256 loss)
I0615 02:42:33.401953 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000501263 (* 1 = 0.000501263 loss)
I0615 02:42:33.401957 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139414 (* 1 = 0.0139414 loss)
I0615 02:42:33.401962 15760 sgd_solver.cpp:106] Iteration 19720, lr = 0.0002
I0615 02:44:19.674875 15760 solver.cpp:228] Iteration 19740, loss = 0.448004
I0615 02:44:19.674899 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 02:44:19.674907 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.116525 (* 1 = 0.116525 loss)
I0615 02:44:19.674913 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.135243 (* 1 = 0.135243 loss)
I0615 02:44:19.674918 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000605015 (* 1 = 0.000605015 loss)
I0615 02:44:19.674924 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194539 (* 1 = 0.0194539 loss)
I0615 02:44:19.674931 15760 sgd_solver.cpp:106] Iteration 19740, lr = 0.0002
I0615 02:46:05.929540 15760 solver.cpp:228] Iteration 19760, loss = 0.421225
I0615 02:46:05.929565 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 02:46:05.929572 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.131086 (* 1 = 0.131086 loss)
I0615 02:46:05.929577 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113459 (* 1 = 0.113459 loss)
I0615 02:46:05.929584 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00889991 (* 1 = 0.00889991 loss)
I0615 02:46:05.929587 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658276 (* 1 = 0.0658276 loss)
I0615 02:46:05.929592 15760 sgd_solver.cpp:106] Iteration 19760, lr = 0.0002
I0615 02:47:52.242286 15760 solver.cpp:228] Iteration 19780, loss = 0.31623
I0615 02:47:52.242311 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 02:47:52.242319 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.18053 (* 1 = 0.18053 loss)
I0615 02:47:52.242323 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.173395 (* 1 = 0.173395 loss)
I0615 02:47:52.242327 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000290266 (* 1 = 0.000290266 loss)
I0615 02:47:52.242331 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249478 (* 1 = 0.0249478 loss)
I0615 02:47:52.242336 15760 sgd_solver.cpp:106] Iteration 19780, lr = 0.0002
speed: 5.331s / iter
I0615 02:49:38.517302 15760 solver.cpp:228] Iteration 19800, loss = 0.381961
I0615 02:49:38.517328 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 02:49:38.517338 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.102092 (* 1 = 0.102092 loss)
I0615 02:49:38.517344 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0666912 (* 1 = 0.0666912 loss)
I0615 02:49:38.517351 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00220993 (* 1 = 0.00220993 loss)
I0615 02:49:38.517359 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00974814 (* 1 = 0.00974814 loss)
I0615 02:49:38.517367 15760 sgd_solver.cpp:106] Iteration 19800, lr = 0.0002
I0615 02:51:24.873641 15760 solver.cpp:228] Iteration 19820, loss = 0.514653
I0615 02:51:24.873670 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0615 02:51:24.873679 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.43478 (* 1 = 0.43478 loss)
I0615 02:51:24.873685 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.40489 (* 1 = 0.40489 loss)
I0615 02:51:24.873690 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032953 (* 1 = 0.0032953 loss)
I0615 02:51:24.873697 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0968444 (* 1 = 0.0968444 loss)
I0615 02:51:24.873703 15760 sgd_solver.cpp:106] Iteration 19820, lr = 0.0002
I0615 02:53:11.825177 15760 solver.cpp:228] Iteration 19840, loss = 0.445349
I0615 02:53:11.825203 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 02:53:11.825213 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455195 (* 1 = 0.0455195 loss)
I0615 02:53:11.825219 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117022 (* 1 = 0.117022 loss)
I0615 02:53:11.825224 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00716661 (* 1 = 0.00716661 loss)
I0615 02:53:11.825230 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172501 (* 1 = 0.0172501 loss)
I0615 02:53:11.825238 15760 sgd_solver.cpp:106] Iteration 19840, lr = 0.0002
I0615 02:54:58.899947 15760 solver.cpp:228] Iteration 19860, loss = 0.366912
I0615 02:54:58.899976 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 02:54:58.899986 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.193602 (* 1 = 0.193602 loss)
I0615 02:54:58.899993 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.208699 (* 1 = 0.208699 loss)
I0615 02:54:58.900001 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00251204 (* 1 = 0.00251204 loss)
I0615 02:54:58.900007 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143194 (* 1 = 0.0143194 loss)
I0615 02:54:58.900015 15760 sgd_solver.cpp:106] Iteration 19860, lr = 0.0002
I0615 02:56:46.094892 15760 solver.cpp:228] Iteration 19880, loss = 0.311392
I0615 02:56:46.094918 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 02:56:46.094926 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.386692 (* 1 = 0.386692 loss)
I0615 02:56:46.094931 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.330334 (* 1 = 0.330334 loss)
I0615 02:56:46.094936 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245487 (* 1 = 0.00245487 loss)
I0615 02:56:46.094941 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0717397 (* 1 = 0.0717397 loss)
I0615 02:56:46.094946 15760 sgd_solver.cpp:106] Iteration 19880, lr = 0.0002
I0615 02:58:33.062978 15760 solver.cpp:228] Iteration 19900, loss = 0.378737
I0615 02:58:33.063002 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 02:58:33.063010 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540036 (* 1 = 0.0540036 loss)
I0615 02:58:33.063014 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.151218 (* 1 = 0.151218 loss)
I0615 02:58:33.063019 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000599758 (* 1 = 0.000599758 loss)
I0615 02:58:33.063022 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00594796 (* 1 = 0.00594796 loss)
I0615 02:58:33.063027 15760 sgd_solver.cpp:106] Iteration 19900, lr = 0.0002
I0615 03:00:20.323608 15760 solver.cpp:228] Iteration 19920, loss = 0.397324
I0615 03:00:20.323634 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 03:00:20.323642 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.184272 (* 1 = 0.184272 loss)
I0615 03:00:20.323645 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.173302 (* 1 = 0.173302 loss)
I0615 03:00:20.323649 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00230264 (* 1 = 0.00230264 loss)
I0615 03:00:20.323652 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624162 (* 1 = 0.0624162 loss)
I0615 03:00:20.323658 15760 sgd_solver.cpp:106] Iteration 19920, lr = 0.0002
I0615 03:02:07.416792 15760 solver.cpp:228] Iteration 19940, loss = 0.590189
I0615 03:02:07.416823 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 03:02:07.416831 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.375985 (* 1 = 0.375985 loss)
I0615 03:02:07.416834 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.288189 (* 1 = 0.288189 loss)
I0615 03:02:07.416838 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000835974 (* 1 = 0.000835974 loss)
I0615 03:02:07.416841 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0576458 (* 1 = 0.0576458 loss)
I0615 03:02:07.416846 15760 sgd_solver.cpp:106] Iteration 19940, lr = 0.0002
I0615 03:03:54.636055 15760 solver.cpp:228] Iteration 19960, loss = 0.527027
I0615 03:03:54.636081 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 03:03:54.636088 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.150759 (* 1 = 0.150759 loss)
I0615 03:03:54.636092 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.268579 (* 1 = 0.268579 loss)
I0615 03:03:54.636097 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000826354 (* 1 = 0.000826354 loss)
I0615 03:03:54.636101 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01383 (* 1 = 0.01383 loss)
I0615 03:03:54.636106 15760 sgd_solver.cpp:106] Iteration 19960, lr = 0.0002
I0615 03:05:41.196521 15760 solver.cpp:228] Iteration 19980, loss = 0.493323
I0615 03:05:41.196544 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 03:05:41.196552 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.193111 (* 1 = 0.193111 loss)
I0615 03:05:41.196555 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.186069 (* 1 = 0.186069 loss)
I0615 03:05:41.196559 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113019 (* 1 = 0.00113019 loss)
I0615 03:05:41.196563 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199652 (* 1 = 0.0199652 loss)
I0615 03:05:41.196568 15760 sgd_solver.cpp:106] Iteration 19980, lr = 0.0002
speed: 5.331s / iter
I0615 03:07:22.742307 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_20000.caffemodel
I0615 03:07:28.502547 15760 solver.cpp:228] Iteration 20000, loss = 0.26483
I0615 03:07:28.502573 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 03:07:28.502579 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112632 (* 1 = 0.112632 loss)
I0615 03:07:28.502583 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.100547 (* 1 = 0.100547 loss)
I0615 03:07:28.502588 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759606 (* 1 = 0.00759606 loss)
I0615 03:07:28.502591 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.114113 (* 1 = 0.114113 loss)
I0615 03:07:28.502596 15760 sgd_solver.cpp:106] Iteration 20000, lr = 0.0002
I0615 03:09:15.091794 15760 solver.cpp:228] Iteration 20020, loss = 0.490574
I0615 03:09:15.091817 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 03:09:15.091825 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0736828 (* 1 = 0.0736828 loss)
I0615 03:09:15.091828 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.125333 (* 1 = 0.125333 loss)
I0615 03:09:15.091832 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000128221 (* 1 = 0.000128221 loss)
I0615 03:09:15.091835 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016749 (* 1 = 0.016749 loss)
I0615 03:09:15.091840 15760 sgd_solver.cpp:106] Iteration 20020, lr = 0.0002
I0615 03:11:01.778365 15760 solver.cpp:228] Iteration 20040, loss = 0.284138
I0615 03:11:01.778389 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 03:11:01.778396 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410313 (* 1 = 0.0410313 loss)
I0615 03:11:01.778400 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0783853 (* 1 = 0.0783853 loss)
I0615 03:11:01.778404 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282647 (* 1 = 0.00282647 loss)
I0615 03:11:01.778407 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115514 (* 1 = 0.0115514 loss)
I0615 03:11:01.778412 15760 sgd_solver.cpp:106] Iteration 20040, lr = 0.0002
I0615 03:12:48.532989 15760 solver.cpp:228] Iteration 20060, loss = 0.542051
I0615 03:12:48.533013 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0615 03:12:48.533021 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.918578 (* 1 = 0.918578 loss)
I0615 03:12:48.533025 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.595139 (* 1 = 0.595139 loss)
I0615 03:12:48.533030 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00735099 (* 1 = 0.00735099 loss)
I0615 03:12:48.533033 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.19742 (* 1 = 0.19742 loss)
I0615 03:12:48.533038 15760 sgd_solver.cpp:106] Iteration 20060, lr = 0.0002
I0615 03:14:35.182734 15760 solver.cpp:228] Iteration 20080, loss = 0.380543
I0615 03:14:35.182757 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 03:14:35.182765 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.123188 (* 1 = 0.123188 loss)
I0615 03:14:35.182768 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.245911 (* 1 = 0.245911 loss)
I0615 03:14:35.182771 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00855685 (* 1 = 0.00855685 loss)
I0615 03:14:35.182775 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.211256 (* 1 = 0.211256 loss)
I0615 03:14:35.182780 15760 sgd_solver.cpp:106] Iteration 20080, lr = 0.0002
I0615 03:16:21.980355 15760 solver.cpp:228] Iteration 20100, loss = 0.325233
I0615 03:16:21.980377 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 03:16:21.980384 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139043 (* 1 = 0.139043 loss)
I0615 03:16:21.980387 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.139724 (* 1 = 0.139724 loss)
I0615 03:16:21.980391 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00256756 (* 1 = 0.00256756 loss)
I0615 03:16:21.980394 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221024 (* 1 = 0.0221024 loss)
I0615 03:16:21.980399 15760 sgd_solver.cpp:106] Iteration 20100, lr = 0.0002
I0615 03:18:08.139987 15760 solver.cpp:228] Iteration 20120, loss = 0.343473
I0615 03:18:08.140010 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 03:18:08.140017 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682437 (* 1 = 0.0682437 loss)
I0615 03:18:08.140022 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130431 (* 1 = 0.130431 loss)
I0615 03:18:08.140025 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000695348 (* 1 = 0.000695348 loss)
I0615 03:18:08.140028 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332361 (* 1 = 0.0332361 loss)
I0615 03:18:08.140033 15760 sgd_solver.cpp:106] Iteration 20120, lr = 0.0002
I0615 03:19:54.623051 15760 solver.cpp:228] Iteration 20140, loss = 0.551709
I0615 03:19:54.623075 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 03:19:54.623082 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.236496 (* 1 = 0.236496 loss)
I0615 03:19:54.623086 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.155648 (* 1 = 0.155648 loss)
I0615 03:19:54.623091 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000553045 (* 1 = 0.000553045 loss)
I0615 03:19:54.623095 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176557 (* 1 = 0.0176557 loss)
I0615 03:19:54.623100 15760 sgd_solver.cpp:106] Iteration 20140, lr = 0.0002
I0615 03:21:41.048199 15760 solver.cpp:228] Iteration 20160, loss = 0.454234
I0615 03:21:41.048223 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 03:21:41.048233 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0892768 (* 1 = 0.0892768 loss)
I0615 03:21:41.048238 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.131775 (* 1 = 0.131775 loss)
I0615 03:21:41.048244 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000623683 (* 1 = 0.000623683 loss)
I0615 03:21:41.048250 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0074172 (* 1 = 0.0074172 loss)
I0615 03:21:41.048259 15760 sgd_solver.cpp:106] Iteration 20160, lr = 0.0002
I0615 03:23:27.428829 15760 solver.cpp:228] Iteration 20180, loss = 0.233579
I0615 03:23:27.428853 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 03:23:27.428860 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0858857 (* 1 = 0.0858857 loss)
I0615 03:23:27.428864 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.107362 (* 1 = 0.107362 loss)
I0615 03:23:27.428867 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00509726 (* 1 = 0.00509726 loss)
I0615 03:23:27.428871 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156581 (* 1 = 0.0156581 loss)
I0615 03:23:27.428876 15760 sgd_solver.cpp:106] Iteration 20180, lr = 0.0002
speed: 5.331s / iter
I0615 03:25:13.878324 15760 solver.cpp:228] Iteration 20200, loss = 0.297522
I0615 03:25:13.878350 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 03:25:13.878357 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101162 (* 1 = 0.101162 loss)
I0615 03:25:13.878361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0880542 (* 1 = 0.0880542 loss)
I0615 03:25:13.878365 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012879 (* 1 = 0.0012879 loss)
I0615 03:25:13.878370 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128856 (* 1 = 0.0128856 loss)
I0615 03:25:13.878373 15760 sgd_solver.cpp:106] Iteration 20200, lr = 0.0002
I0615 03:27:00.083454 15760 solver.cpp:228] Iteration 20220, loss = 0.377193
I0615 03:27:00.083482 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 03:27:00.083489 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0772915 (* 1 = 0.0772915 loss)
I0615 03:27:00.083494 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.110628 (* 1 = 0.110628 loss)
I0615 03:27:00.083498 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000208527 (* 1 = 0.000208527 loss)
I0615 03:27:00.083503 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010768 (* 1 = 0.010768 loss)
I0615 03:27:00.083508 15760 sgd_solver.cpp:106] Iteration 20220, lr = 0.0002
I0615 03:28:46.317807 15760 solver.cpp:228] Iteration 20240, loss = 0.340481
I0615 03:28:46.317831 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 03:28:46.317838 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0916141 (* 1 = 0.0916141 loss)
I0615 03:28:46.317842 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.13836 (* 1 = 0.13836 loss)
I0615 03:28:46.317845 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154396 (* 1 = 0.0154396 loss)
I0615 03:28:46.317849 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272723 (* 1 = 0.0272723 loss)
I0615 03:28:46.317853 15760 sgd_solver.cpp:106] Iteration 20240, lr = 0.0002
I0615 03:30:32.506253 15760 solver.cpp:228] Iteration 20260, loss = 0.536476
I0615 03:30:32.506275 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 03:30:32.506283 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.141215 (* 1 = 0.141215 loss)
I0615 03:30:32.506285 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206027 (* 1 = 0.206027 loss)
I0615 03:30:32.506289 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000672076 (* 1 = 0.000672076 loss)
I0615 03:30:32.506292 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390713 (* 1 = 0.0390713 loss)
I0615 03:30:32.506297 15760 sgd_solver.cpp:106] Iteration 20260, lr = 0.0002
I0615 03:32:18.985772 15760 solver.cpp:228] Iteration 20280, loss = 0.499882
I0615 03:32:18.985800 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 03:32:18.985807 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0477573 (* 1 = 0.0477573 loss)
I0615 03:32:18.985812 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0676466 (* 1 = 0.0676466 loss)
I0615 03:32:18.985816 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000814298 (* 1 = 0.000814298 loss)
I0615 03:32:18.985819 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134855 (* 1 = 0.0134855 loss)
I0615 03:32:18.985826 15760 sgd_solver.cpp:106] Iteration 20280, lr = 0.0002
I0615 03:34:05.271031 15760 solver.cpp:228] Iteration 20300, loss = 0.39999
I0615 03:34:05.271057 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 03:34:05.271065 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.051086 (* 1 = 0.051086 loss)
I0615 03:34:05.271070 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.070361 (* 1 = 0.070361 loss)
I0615 03:34:05.271073 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000703649 (* 1 = 0.000703649 loss)
I0615 03:34:05.271077 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149631 (* 1 = 0.0149631 loss)
I0615 03:34:05.271082 15760 sgd_solver.cpp:106] Iteration 20300, lr = 0.0002
I0615 03:35:51.841037 15760 solver.cpp:228] Iteration 20320, loss = 0.611798
I0615 03:35:51.841060 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0615 03:35:51.841068 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.508807 (* 1 = 0.508807 loss)
I0615 03:35:51.841070 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.40286 (* 1 = 0.40286 loss)
I0615 03:35:51.841074 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00470884 (* 1 = 0.00470884 loss)
I0615 03:35:51.841078 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134683 (* 1 = 0.134683 loss)
I0615 03:35:51.841084 15760 sgd_solver.cpp:106] Iteration 20320, lr = 0.0002
I0615 03:37:39.006711 15760 solver.cpp:228] Iteration 20340, loss = 0.462276
I0615 03:37:39.006737 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 03:37:39.006749 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129942 (* 1 = 0.129942 loss)
I0615 03:37:39.006757 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.201334 (* 1 = 0.201334 loss)
I0615 03:37:39.006764 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00695585 (* 1 = 0.00695585 loss)
I0615 03:37:39.006772 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0660497 (* 1 = 0.0660497 loss)
I0615 03:37:39.006783 15760 sgd_solver.cpp:106] Iteration 20340, lr = 0.0002
I0615 03:39:25.746042 15760 solver.cpp:228] Iteration 20360, loss = 0.471041
I0615 03:39:25.746068 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 03:39:25.746074 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.172081 (* 1 = 0.172081 loss)
I0615 03:39:25.746079 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.169475 (* 1 = 0.169475 loss)
I0615 03:39:25.746083 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221382 (* 1 = 0.0221382 loss)
I0615 03:39:25.746086 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0473389 (* 1 = 0.0473389 loss)
I0615 03:39:25.746091 15760 sgd_solver.cpp:106] Iteration 20360, lr = 0.0002
I0615 03:41:12.808413 15760 solver.cpp:228] Iteration 20380, loss = 0.541827
I0615 03:41:12.808437 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 03:41:12.808444 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.305982 (* 1 = 0.305982 loss)
I0615 03:41:12.808447 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.37262 (* 1 = 0.37262 loss)
I0615 03:41:12.808452 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191005 (* 1 = 0.0191005 loss)
I0615 03:41:12.808455 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.15076 (* 1 = 0.15076 loss)
I0615 03:41:12.808459 15760 sgd_solver.cpp:106] Iteration 20380, lr = 0.0002
speed: 5.331s / iter
I0615 03:43:00.073870 15760 solver.cpp:228] Iteration 20400, loss = 0.479393
I0615 03:43:00.073894 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 03:43:00.073901 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.061511 (* 1 = 0.061511 loss)
I0615 03:43:00.073905 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0685342 (* 1 = 0.0685342 loss)
I0615 03:43:00.073909 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000143592 (* 1 = 0.000143592 loss)
I0615 03:43:00.073912 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183419 (* 1 = 0.0183419 loss)
I0615 03:43:00.073917 15760 sgd_solver.cpp:106] Iteration 20400, lr = 0.0002
I0615 03:44:46.758785 15760 solver.cpp:228] Iteration 20420, loss = 0.339196
I0615 03:44:46.758813 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 03:44:46.758821 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0983312 (* 1 = 0.0983312 loss)
I0615 03:44:46.758826 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.147284 (* 1 = 0.147284 loss)
I0615 03:44:46.758831 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273747 (* 1 = 0.00273747 loss)
I0615 03:44:46.758836 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012676 (* 1 = 0.012676 loss)
I0615 03:44:46.758841 15760 sgd_solver.cpp:106] Iteration 20420, lr = 0.0002
I0615 03:46:33.592869 15760 solver.cpp:228] Iteration 20440, loss = 0.356044
I0615 03:46:33.592893 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 03:46:33.592900 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.357708 (* 1 = 0.357708 loss)
I0615 03:46:33.592903 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.328904 (* 1 = 0.328904 loss)
I0615 03:46:33.592907 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00324478 (* 1 = 0.00324478 loss)
I0615 03:46:33.592911 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0664934 (* 1 = 0.0664934 loss)
I0615 03:46:33.592914 15760 sgd_solver.cpp:106] Iteration 20440, lr = 0.0002
I0615 03:48:20.196619 15760 solver.cpp:228] Iteration 20460, loss = 0.343618
I0615 03:48:20.196641 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 03:48:20.196648 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.107945 (* 1 = 0.107945 loss)
I0615 03:48:20.196652 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.152386 (* 1 = 0.152386 loss)
I0615 03:48:20.196656 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00012793 (* 1 = 0.00012793 loss)
I0615 03:48:20.196660 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0058958 (* 1 = 0.0058958 loss)
I0615 03:48:20.196665 15760 sgd_solver.cpp:106] Iteration 20460, lr = 0.0002
I0615 03:50:06.479996 15760 solver.cpp:228] Iteration 20480, loss = 0.447045
I0615 03:50:06.480021 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 03:50:06.480027 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0886793 (* 1 = 0.0886793 loss)
I0615 03:50:06.480031 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0978534 (* 1 = 0.0978534 loss)
I0615 03:50:06.480036 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000498347 (* 1 = 0.000498347 loss)
I0615 03:50:06.480039 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00649534 (* 1 = 0.00649534 loss)
I0615 03:50:06.480043 15760 sgd_solver.cpp:106] Iteration 20480, lr = 0.0002
I0615 03:51:53.797197 15760 solver.cpp:228] Iteration 20500, loss = 0.391162
I0615 03:51:53.797222 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 03:51:53.797230 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.217768 (* 1 = 0.217768 loss)
I0615 03:51:53.797233 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.213984 (* 1 = 0.213984 loss)
I0615 03:51:53.797236 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000403612 (* 1 = 0.000403612 loss)
I0615 03:51:53.797240 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0381982 (* 1 = 0.0381982 loss)
I0615 03:51:53.797245 15760 sgd_solver.cpp:106] Iteration 20500, lr = 0.0002
I0615 03:53:40.312151 15760 solver.cpp:228] Iteration 20520, loss = 0.401611
I0615 03:53:40.312177 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 03:53:40.312186 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.333209 (* 1 = 0.333209 loss)
I0615 03:53:40.312189 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.310094 (* 1 = 0.310094 loss)
I0615 03:53:40.312193 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000991539 (* 1 = 0.000991539 loss)
I0615 03:53:40.312197 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.060403 (* 1 = 0.060403 loss)
I0615 03:53:40.312202 15760 sgd_solver.cpp:106] Iteration 20520, lr = 0.0002
I0615 03:55:27.241803 15760 solver.cpp:228] Iteration 20540, loss = 0.624619
I0615 03:55:27.241829 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0615 03:55:27.241837 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.413585 (* 1 = 0.413585 loss)
I0615 03:55:27.241844 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.441583 (* 1 = 0.441583 loss)
I0615 03:55:27.241850 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01273 (* 1 = 0.01273 loss)
I0615 03:55:27.241854 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.14089 (* 1 = 0.14089 loss)
I0615 03:55:27.241861 15760 sgd_solver.cpp:106] Iteration 20540, lr = 0.0002
I0615 03:57:13.593989 15760 solver.cpp:228] Iteration 20560, loss = 0.515597
I0615 03:57:13.594017 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 03:57:13.594027 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.282808 (* 1 = 0.282808 loss)
I0615 03:57:13.594033 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.30425 (* 1 = 0.30425 loss)
I0615 03:57:13.594038 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542455 (* 1 = 0.00542455 loss)
I0615 03:57:13.594044 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.238936 (* 1 = 0.238936 loss)
I0615 03:57:13.594051 15760 sgd_solver.cpp:106] Iteration 20560, lr = 0.0002
I0615 03:58:59.972187 15760 solver.cpp:228] Iteration 20580, loss = 0.40929
I0615 03:58:59.972209 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 03:58:59.972216 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0753705 (* 1 = 0.0753705 loss)
I0615 03:58:59.972220 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0178839 (* 1 = 0.0178839 loss)
I0615 03:58:59.972223 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000294229 (* 1 = 0.000294229 loss)
I0615 03:58:59.972227 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00731474 (* 1 = 0.00731474 loss)
I0615 03:58:59.972232 15760 sgd_solver.cpp:106] Iteration 20580, lr = 0.0002
speed: 5.331s / iter
I0615 04:00:46.518666 15760 solver.cpp:228] Iteration 20600, loss = 0.495618
I0615 04:00:46.518692 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 04:00:46.518699 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.034668 (* 1 = 0.034668 loss)
I0615 04:00:46.518704 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0477177 (* 1 = 0.0477177 loss)
I0615 04:00:46.518708 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00916123 (* 1 = 0.00916123 loss)
I0615 04:00:46.518712 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196894 (* 1 = 0.0196894 loss)
I0615 04:00:46.518716 15760 sgd_solver.cpp:106] Iteration 20600, lr = 0.0002
I0615 04:02:32.881557 15760 solver.cpp:228] Iteration 20620, loss = 0.554685
I0615 04:02:32.881579 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 04:02:32.881587 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385631 (* 1 = 0.0385631 loss)
I0615 04:02:32.881590 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0478174 (* 1 = 0.0478174 loss)
I0615 04:02:32.881594 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0002259 (* 1 = 0.0002259 loss)
I0615 04:02:32.881597 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013537 (* 1 = 0.013537 loss)
I0615 04:02:32.881603 15760 sgd_solver.cpp:106] Iteration 20620, lr = 0.0002
I0615 04:04:19.286949 15760 solver.cpp:228] Iteration 20640, loss = 0.669052
I0615 04:04:19.286974 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 04:04:19.286981 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.291712 (* 1 = 0.291712 loss)
I0615 04:04:19.286985 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.312569 (* 1 = 0.312569 loss)
I0615 04:04:19.286989 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148354 (* 1 = 0.0148354 loss)
I0615 04:04:19.286993 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.223624 (* 1 = 0.223624 loss)
I0615 04:04:19.286998 15760 sgd_solver.cpp:106] Iteration 20640, lr = 0.0002
I0615 04:06:05.701068 15760 solver.cpp:228] Iteration 20660, loss = 0.544779
I0615 04:06:05.701092 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 04:06:05.701100 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.22761 (* 1 = 0.22761 loss)
I0615 04:06:05.701104 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.181721 (* 1 = 0.181721 loss)
I0615 04:06:05.701108 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221934 (* 1 = 0.00221934 loss)
I0615 04:06:05.701112 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.053049 (* 1 = 0.053049 loss)
I0615 04:06:05.701117 15760 sgd_solver.cpp:106] Iteration 20660, lr = 0.0002
I0615 04:07:52.484697 15760 solver.cpp:228] Iteration 20680, loss = 0.578236
I0615 04:07:52.484722 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 04:07:52.484730 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.197241 (* 1 = 0.197241 loss)
I0615 04:07:52.484733 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.103801 (* 1 = 0.103801 loss)
I0615 04:07:52.484737 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144916 (* 1 = 0.0144916 loss)
I0615 04:07:52.484741 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0709805 (* 1 = 0.0709805 loss)
I0615 04:07:52.484747 15760 sgd_solver.cpp:106] Iteration 20680, lr = 0.0002
I0615 04:09:39.135187 15760 solver.cpp:228] Iteration 20700, loss = 0.571673
I0615 04:09:39.135213 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 04:09:39.135221 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0457837 (* 1 = 0.0457837 loss)
I0615 04:09:39.135224 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0588531 (* 1 = 0.0588531 loss)
I0615 04:09:39.135229 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108355 (* 1 = 0.00108355 loss)
I0615 04:09:39.135233 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163871 (* 1 = 0.0163871 loss)
I0615 04:09:39.135238 15760 sgd_solver.cpp:106] Iteration 20700, lr = 0.0002
I0615 04:11:25.312322 15760 solver.cpp:228] Iteration 20720, loss = 0.494732
I0615 04:11:25.312350 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 04:11:25.312357 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.471185 (* 1 = 0.471185 loss)
I0615 04:11:25.312361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28645 (* 1 = 0.28645 loss)
I0615 04:11:25.312366 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119564 (* 1 = 0.00119564 loss)
I0615 04:11:25.312371 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566455 (* 1 = 0.0566455 loss)
I0615 04:11:25.312376 15760 sgd_solver.cpp:106] Iteration 20720, lr = 0.0002
I0615 04:13:11.549640 15760 solver.cpp:228] Iteration 20740, loss = 0.365989
I0615 04:13:11.549662 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 04:13:11.549669 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.175517 (* 1 = 0.175517 loss)
I0615 04:13:11.549674 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.184079 (* 1 = 0.184079 loss)
I0615 04:13:11.549677 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0285595 (* 1 = 0.0285595 loss)
I0615 04:13:11.549680 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101086 (* 1 = 0.101086 loss)
I0615 04:13:11.549685 15760 sgd_solver.cpp:106] Iteration 20740, lr = 0.0002
I0615 04:14:57.982015 15760 solver.cpp:228] Iteration 20760, loss = 0.59436
I0615 04:14:57.982039 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0615 04:14:57.982045 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.590642 (* 1 = 0.590642 loss)
I0615 04:14:57.982049 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.581399 (* 1 = 0.581399 loss)
I0615 04:14:57.982053 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0577312 (* 1 = 0.0577312 loss)
I0615 04:14:57.982056 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.266557 (* 1 = 0.266557 loss)
I0615 04:14:57.982061 15760 sgd_solver.cpp:106] Iteration 20760, lr = 0.0002
I0615 04:16:44.451212 15760 solver.cpp:228] Iteration 20780, loss = 0.444965
I0615 04:16:44.451238 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 04:16:44.451246 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0728115 (* 1 = 0.0728115 loss)
I0615 04:16:44.451249 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.100923 (* 1 = 0.100923 loss)
I0615 04:16:44.451254 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000229534 (* 1 = 0.000229534 loss)
I0615 04:16:44.451257 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284903 (* 1 = 0.0284903 loss)
I0615 04:16:44.451262 15760 sgd_solver.cpp:106] Iteration 20780, lr = 0.0002
speed: 5.331s / iter
I0615 04:18:30.986307 15760 solver.cpp:228] Iteration 20800, loss = 0.306597
I0615 04:18:30.986331 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 04:18:30.986338 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117604 (* 1 = 0.117604 loss)
I0615 04:18:30.986343 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0515786 (* 1 = 0.0515786 loss)
I0615 04:18:30.986347 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000120664 (* 1 = 0.000120664 loss)
I0615 04:18:30.986351 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166819 (* 1 = 0.0166819 loss)
I0615 04:18:30.986356 15760 sgd_solver.cpp:106] Iteration 20800, lr = 0.0002
I0615 04:20:17.704782 15760 solver.cpp:228] Iteration 20820, loss = 0.481549
I0615 04:20:17.704807 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 04:20:17.704815 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587202 (* 1 = 0.0587202 loss)
I0615 04:20:17.704819 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0790523 (* 1 = 0.0790523 loss)
I0615 04:20:17.704823 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00182174 (* 1 = 0.00182174 loss)
I0615 04:20:17.704828 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0080173 (* 1 = 0.0080173 loss)
I0615 04:20:17.704833 15760 sgd_solver.cpp:106] Iteration 20820, lr = 0.0002
I0615 04:22:04.691998 15760 solver.cpp:228] Iteration 20840, loss = 0.305724
I0615 04:22:04.692028 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 04:22:04.692041 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.104229 (* 1 = 0.104229 loss)
I0615 04:22:04.692051 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159731 (* 1 = 0.159731 loss)
I0615 04:22:04.692059 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000148613 (* 1 = 0.000148613 loss)
I0615 04:22:04.692068 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184948 (* 1 = 0.0184948 loss)
I0615 04:22:04.692076 15760 sgd_solver.cpp:106] Iteration 20840, lr = 0.0002
I0615 04:23:51.581166 15760 solver.cpp:228] Iteration 20860, loss = 0.414588
I0615 04:23:51.581190 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 04:23:51.581197 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.307492 (* 1 = 0.307492 loss)
I0615 04:23:51.581200 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.241778 (* 1 = 0.241778 loss)
I0615 04:23:51.581204 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000419684 (* 1 = 0.000419684 loss)
I0615 04:23:51.581208 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239298 (* 1 = 0.0239298 loss)
I0615 04:23:51.581213 15760 sgd_solver.cpp:106] Iteration 20860, lr = 0.0002
I0615 04:25:38.797056 15760 solver.cpp:228] Iteration 20880, loss = 0.315629
I0615 04:25:38.797086 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 04:25:38.797096 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139854 (* 1 = 0.139854 loss)
I0615 04:25:38.797101 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134631 (* 1 = 0.134631 loss)
I0615 04:25:38.797106 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00227144 (* 1 = 0.00227144 loss)
I0615 04:25:38.797112 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00978459 (* 1 = 0.00978459 loss)
I0615 04:25:38.797118 15760 sgd_solver.cpp:106] Iteration 20880, lr = 0.0002
I0615 04:27:26.515653 15760 solver.cpp:228] Iteration 20900, loss = 0.604273
I0615 04:27:26.515682 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 04:27:26.515696 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.567225 (* 1 = 0.567225 loss)
I0615 04:27:26.515702 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.35435 (* 1 = 0.35435 loss)
I0615 04:27:26.515710 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00896833 (* 1 = 0.00896833 loss)
I0615 04:27:26.515717 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0985163 (* 1 = 0.0985163 loss)
I0615 04:27:26.515727 15760 sgd_solver.cpp:106] Iteration 20900, lr = 0.0002
I0615 04:29:13.486377 15760 solver.cpp:228] Iteration 20920, loss = 0.51757
I0615 04:29:13.486402 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 04:29:13.486408 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.107112 (* 1 = 0.107112 loss)
I0615 04:29:13.486413 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171596 (* 1 = 0.171596 loss)
I0615 04:29:13.486418 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713205 (* 1 = 0.00713205 loss)
I0615 04:29:13.486420 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033194 (* 1 = 0.033194 loss)
I0615 04:29:13.486426 15760 sgd_solver.cpp:106] Iteration 20920, lr = 0.0002
I0615 04:31:00.028525 15760 solver.cpp:228] Iteration 20940, loss = 0.540307
I0615 04:31:00.028558 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 04:31:00.028571 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.378789 (* 1 = 0.378789 loss)
I0615 04:31:00.028580 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.222945 (* 1 = 0.222945 loss)
I0615 04:31:00.028590 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276653 (* 1 = 0.00276653 loss)
I0615 04:31:00.028599 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430303 (* 1 = 0.0430303 loss)
I0615 04:31:00.028607 15760 sgd_solver.cpp:106] Iteration 20940, lr = 0.0002
I0615 04:32:46.837085 15760 solver.cpp:228] Iteration 20960, loss = 0.321412
I0615 04:32:46.837110 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 04:32:46.837118 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266619 (* 1 = 0.0266619 loss)
I0615 04:32:46.837122 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0808959 (* 1 = 0.0808959 loss)
I0615 04:32:46.837126 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124707 (* 1 = 0.0124707 loss)
I0615 04:32:46.837129 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378401 (* 1 = 0.0378401 loss)
I0615 04:32:46.837136 15760 sgd_solver.cpp:106] Iteration 20960, lr = 0.0002
I0615 04:34:33.328374 15760 solver.cpp:228] Iteration 20980, loss = 0.373392
I0615 04:34:33.328402 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 04:34:33.328413 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.349377 (* 1 = 0.349377 loss)
I0615 04:34:33.328418 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.192427 (* 1 = 0.192427 loss)
I0615 04:34:33.328425 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131178 (* 1 = 0.0131178 loss)
I0615 04:34:33.328431 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127608 (* 1 = 0.127608 loss)
I0615 04:34:33.328440 15760 sgd_solver.cpp:106] Iteration 20980, lr = 0.0002
speed: 5.331s / iter
I0615 04:36:20.040287 15760 solver.cpp:228] Iteration 21000, loss = 0.469619
I0615 04:36:20.040318 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 04:36:20.040324 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.614567 (* 1 = 0.614567 loss)
I0615 04:36:20.040329 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.32464 (* 1 = 0.32464 loss)
I0615 04:36:20.040333 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00328715 (* 1 = 0.00328715 loss)
I0615 04:36:20.040336 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116999 (* 1 = 0.116999 loss)
I0615 04:36:20.040341 15760 sgd_solver.cpp:106] Iteration 21000, lr = 0.0002
I0615 04:38:07.034303 15760 solver.cpp:228] Iteration 21020, loss = 0.486594
I0615 04:38:07.034328 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 04:38:07.034335 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0680864 (* 1 = 0.0680864 loss)
I0615 04:38:07.034339 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.082554 (* 1 = 0.082554 loss)
I0615 04:38:07.034343 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00049872 (* 1 = 0.00049872 loss)
I0615 04:38:07.034348 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00575737 (* 1 = 0.00575737 loss)
I0615 04:38:07.034353 15760 sgd_solver.cpp:106] Iteration 21020, lr = 0.0002
I0615 04:39:53.176000 15760 solver.cpp:228] Iteration 21040, loss = 0.255856
I0615 04:39:53.176028 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 04:39:53.176035 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.217809 (* 1 = 0.217809 loss)
I0615 04:39:53.176040 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.158753 (* 1 = 0.158753 loss)
I0615 04:39:53.176044 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00888046 (* 1 = 0.00888046 loss)
I0615 04:39:53.176048 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149964 (* 1 = 0.149964 loss)
I0615 04:39:53.176054 15760 sgd_solver.cpp:106] Iteration 21040, lr = 0.0002
I0615 04:41:39.718185 15760 solver.cpp:228] Iteration 21060, loss = 0.409138
I0615 04:41:39.718211 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0615 04:41:39.718219 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.271567 (* 1 = 0.271567 loss)
I0615 04:41:39.718222 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.362183 (* 1 = 0.362183 loss)
I0615 04:41:39.718226 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100582 (* 1 = 0.00100582 loss)
I0615 04:41:39.718230 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390192 (* 1 = 0.0390192 loss)
I0615 04:41:39.718235 15760 sgd_solver.cpp:106] Iteration 21060, lr = 0.0002
I0615 04:43:26.085463 15760 solver.cpp:228] Iteration 21080, loss = 0.38707
I0615 04:43:26.085484 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0615 04:43:26.085492 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.445175 (* 1 = 0.445175 loss)
I0615 04:43:26.085499 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.436331 (* 1 = 0.436331 loss)
I0615 04:43:26.085503 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000210264 (* 1 = 0.000210264 loss)
I0615 04:43:26.085507 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0579604 (* 1 = 0.0579604 loss)
I0615 04:43:26.085513 15760 sgd_solver.cpp:106] Iteration 21080, lr = 0.0002
I0615 04:45:12.328663 15760 solver.cpp:228] Iteration 21100, loss = 0.3923
I0615 04:45:12.328687 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 04:45:12.328694 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.00322069 (* 1 = 0.00322069 loss)
I0615 04:45:12.328698 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0087397 (* 1 = 0.0087397 loss)
I0615 04:45:12.328702 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0768106 (* 1 = 0.0768106 loss)
I0615 04:45:12.328706 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0365888 (* 1 = 0.0365888 loss)
I0615 04:45:12.328711 15760 sgd_solver.cpp:106] Iteration 21100, lr = 0.0002
I0615 04:46:58.519678 15760 solver.cpp:228] Iteration 21120, loss = 0.507429
I0615 04:46:58.519711 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 04:46:58.519719 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.057569 (* 1 = 0.057569 loss)
I0615 04:46:58.519724 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0584163 (* 1 = 0.0584163 loss)
I0615 04:46:58.519728 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271184 (* 1 = 0.00271184 loss)
I0615 04:46:58.519732 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289283 (* 1 = 0.0289283 loss)
I0615 04:46:58.519737 15760 sgd_solver.cpp:106] Iteration 21120, lr = 0.0002
I0615 04:48:44.822485 15760 solver.cpp:228] Iteration 21140, loss = 0.46026
I0615 04:48:44.822511 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 04:48:44.822520 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.077438 (* 1 = 0.077438 loss)
I0615 04:48:44.822525 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120397 (* 1 = 0.120397 loss)
I0615 04:48:44.822528 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000480021 (* 1 = 0.000480021 loss)
I0615 04:48:44.822532 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168764 (* 1 = 0.0168764 loss)
I0615 04:48:44.822538 15760 sgd_solver.cpp:106] Iteration 21140, lr = 0.0002
I0615 04:50:31.194025 15760 solver.cpp:228] Iteration 21160, loss = 0.20294
I0615 04:50:31.194048 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 04:50:31.194056 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0487289 (* 1 = 0.0487289 loss)
I0615 04:50:31.194059 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0514985 (* 1 = 0.0514985 loss)
I0615 04:50:31.194063 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00631136 (* 1 = 0.00631136 loss)
I0615 04:50:31.194067 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00496457 (* 1 = 0.00496457 loss)
I0615 04:50:31.194072 15760 sgd_solver.cpp:106] Iteration 21160, lr = 0.0002
I0615 04:52:17.766436 15760 solver.cpp:228] Iteration 21180, loss = 0.42137
I0615 04:52:17.766461 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 04:52:17.766469 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0520341 (* 1 = 0.0520341 loss)
I0615 04:52:17.766474 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0244463 (* 1 = 0.0244463 loss)
I0615 04:52:17.766479 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189954 (* 1 = 0.00189954 loss)
I0615 04:52:17.766481 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402068 (* 1 = 0.0402068 loss)
I0615 04:52:17.766487 15760 sgd_solver.cpp:106] Iteration 21180, lr = 0.0002
speed: 5.331s / iter
I0615 04:54:04.464773 15760 solver.cpp:228] Iteration 21200, loss = 0.509108
I0615 04:54:04.464797 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 04:54:04.464803 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0837488 (* 1 = 0.0837488 loss)
I0615 04:54:04.464807 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113667 (* 1 = 0.113667 loss)
I0615 04:54:04.464812 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184097 (* 1 = 0.00184097 loss)
I0615 04:54:04.464814 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00410337 (* 1 = 0.00410337 loss)
I0615 04:54:04.464819 15760 sgd_solver.cpp:106] Iteration 21200, lr = 0.0002
I0615 04:55:50.843817 15760 solver.cpp:228] Iteration 21220, loss = 0.373019
I0615 04:55:50.843843 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 04:55:50.843853 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108199 (* 1 = 0.108199 loss)
I0615 04:55:50.843860 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0903952 (* 1 = 0.0903952 loss)
I0615 04:55:50.843866 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00606661 (* 1 = 0.00606661 loss)
I0615 04:55:50.843873 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225232 (* 1 = 0.0225232 loss)
I0615 04:55:50.843880 15760 sgd_solver.cpp:106] Iteration 21220, lr = 0.0002
I0615 04:57:37.397205 15760 solver.cpp:228] Iteration 21240, loss = 0.318884
I0615 04:57:37.397228 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 04:57:37.397235 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.2293 (* 1 = 0.2293 loss)
I0615 04:57:37.397239 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.218716 (* 1 = 0.218716 loss)
I0615 04:57:37.397243 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00874995 (* 1 = 0.00874995 loss)
I0615 04:57:37.397246 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259076 (* 1 = 0.0259076 loss)
I0615 04:57:37.397251 15760 sgd_solver.cpp:106] Iteration 21240, lr = 0.0002
I0615 04:59:23.690515 15760 solver.cpp:228] Iteration 21260, loss = 0.321579
I0615 04:59:23.690537 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 04:59:23.690547 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109834 (* 1 = 0.109834 loss)
I0615 04:59:23.690553 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0673571 (* 1 = 0.0673571 loss)
I0615 04:59:23.690558 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00404642 (* 1 = 0.00404642 loss)
I0615 04:59:23.690564 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106114 (* 1 = 0.0106114 loss)
I0615 04:59:23.690570 15760 sgd_solver.cpp:106] Iteration 21260, lr = 0.0002
I0615 05:01:10.211024 15760 solver.cpp:228] Iteration 21280, loss = 0.442144
I0615 05:01:10.211050 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0615 05:01:10.211058 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.365477 (* 1 = 0.365477 loss)
I0615 05:01:10.211066 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.499394 (* 1 = 0.499394 loss)
I0615 05:01:10.211071 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129551 (* 1 = 0.0129551 loss)
I0615 05:01:10.211078 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.138071 (* 1 = 0.138071 loss)
I0615 05:01:10.211086 15760 sgd_solver.cpp:106] Iteration 21280, lr = 0.0002
I0615 05:02:56.555732 15760 solver.cpp:228] Iteration 21300, loss = 0.544245
I0615 05:02:56.555758 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0615 05:02:56.555766 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.216763 (* 1 = 0.216763 loss)
I0615 05:02:56.555770 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.582762 (* 1 = 0.582762 loss)
I0615 05:02:56.555773 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119237 (* 1 = 0.0119237 loss)
I0615 05:02:56.555778 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.468721 (* 1 = 0.468721 loss)
I0615 05:02:56.555783 15760 sgd_solver.cpp:106] Iteration 21300, lr = 0.0002
I0615 05:04:43.195348 15760 solver.cpp:228] Iteration 21320, loss = 0.49744
I0615 05:04:43.195372 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 05:04:43.195380 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.135998 (* 1 = 0.135998 loss)
I0615 05:04:43.195385 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.211481 (* 1 = 0.211481 loss)
I0615 05:04:43.195389 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000244043 (* 1 = 0.000244043 loss)
I0615 05:04:43.195394 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024327 (* 1 = 0.024327 loss)
I0615 05:04:43.195399 15760 sgd_solver.cpp:106] Iteration 21320, lr = 0.0002
I0615 05:06:30.224890 15760 solver.cpp:228] Iteration 21340, loss = 0.422449
I0615 05:06:30.224915 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 05:06:30.224925 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.225395 (* 1 = 0.225395 loss)
I0615 05:06:30.224931 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20203 (* 1 = 0.20203 loss)
I0615 05:06:30.224936 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00479447 (* 1 = 0.00479447 loss)
I0615 05:06:30.224947 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0776491 (* 1 = 0.0776491 loss)
I0615 05:06:30.224954 15760 sgd_solver.cpp:106] Iteration 21340, lr = 0.0002
I0615 05:08:17.270897 15760 solver.cpp:228] Iteration 21360, loss = 0.453531
I0615 05:08:17.270921 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 05:08:17.270928 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.110323 (* 1 = 0.110323 loss)
I0615 05:08:17.270932 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167323 (* 1 = 0.167323 loss)
I0615 05:08:17.270936 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012997 (* 1 = 0.012997 loss)
I0615 05:08:17.270938 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449824 (* 1 = 0.0449824 loss)
I0615 05:08:17.270943 15760 sgd_solver.cpp:106] Iteration 21360, lr = 0.0002
I0615 05:10:04.064222 15760 solver.cpp:228] Iteration 21380, loss = 0.396372
I0615 05:10:04.064249 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 05:10:04.064260 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0531079 (* 1 = 0.0531079 loss)
I0615 05:10:04.064266 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0507129 (* 1 = 0.0507129 loss)
I0615 05:10:04.064273 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000466003 (* 1 = 0.000466003 loss)
I0615 05:10:04.064280 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100587 (* 1 = 0.0100587 loss)
I0615 05:10:04.064286 15760 sgd_solver.cpp:106] Iteration 21380, lr = 0.0002
speed: 5.331s / iter
I0615 05:11:51.011729 15760 solver.cpp:228] Iteration 21400, loss = 0.339188
I0615 05:11:51.011755 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 05:11:51.011764 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108498 (* 1 = 0.108498 loss)
I0615 05:11:51.011767 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0930066 (* 1 = 0.0930066 loss)
I0615 05:11:51.011771 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000343313 (* 1 = 0.000343313 loss)
I0615 05:11:51.011775 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232925 (* 1 = 0.0232925 loss)
I0615 05:11:51.011780 15760 sgd_solver.cpp:106] Iteration 21400, lr = 0.0002
I0615 05:13:37.856739 15760 solver.cpp:228] Iteration 21420, loss = 0.542131
I0615 05:13:37.856766 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 05:13:37.856775 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.099215 (* 1 = 0.099215 loss)
I0615 05:13:37.856781 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0757817 (* 1 = 0.0757817 loss)
I0615 05:13:37.856787 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000420018 (* 1 = 0.000420018 loss)
I0615 05:13:37.856792 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123578 (* 1 = 0.0123578 loss)
I0615 05:13:37.856798 15760 sgd_solver.cpp:106] Iteration 21420, lr = 0.0002
I0615 05:15:25.289113 15760 solver.cpp:228] Iteration 21440, loss = 0.33249
I0615 05:15:25.289144 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 05:15:25.289153 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0910575 (* 1 = 0.0910575 loss)
I0615 05:15:25.289158 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.092463 (* 1 = 0.092463 loss)
I0615 05:15:25.289165 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000363324 (* 1 = 0.000363324 loss)
I0615 05:15:25.289170 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111974 (* 1 = 0.0111974 loss)
I0615 05:15:25.289175 15760 sgd_solver.cpp:106] Iteration 21440, lr = 0.0002
I0615 05:17:12.379017 15760 solver.cpp:228] Iteration 21460, loss = 0.378655
I0615 05:17:12.379040 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 05:17:12.379048 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0657467 (* 1 = 0.0657467 loss)
I0615 05:17:12.379051 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.079403 (* 1 = 0.079403 loss)
I0615 05:17:12.379055 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231359 (* 1 = 0.00231359 loss)
I0615 05:17:12.379058 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00454508 (* 1 = 0.00454508 loss)
I0615 05:17:12.379063 15760 sgd_solver.cpp:106] Iteration 21460, lr = 0.0002
I0615 05:18:58.794229 15760 solver.cpp:228] Iteration 21480, loss = 0.468592
I0615 05:18:58.794255 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 05:18:58.794265 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.15835 (* 1 = 0.15835 loss)
I0615 05:18:58.794272 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.219525 (* 1 = 0.219525 loss)
I0615 05:18:58.794278 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00335389 (* 1 = 0.00335389 loss)
I0615 05:18:58.794284 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.131867 (* 1 = 0.131867 loss)
I0615 05:18:58.794291 15760 sgd_solver.cpp:106] Iteration 21480, lr = 0.0002
I0615 05:20:45.236361 15760 solver.cpp:228] Iteration 21500, loss = 0.307877
I0615 05:20:45.236390 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 05:20:45.236398 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.177262 (* 1 = 0.177262 loss)
I0615 05:20:45.236402 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.253374 (* 1 = 0.253374 loss)
I0615 05:20:45.236407 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00664574 (* 1 = 0.00664574 loss)
I0615 05:20:45.236413 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199435 (* 1 = 0.0199435 loss)
I0615 05:20:45.236418 15760 sgd_solver.cpp:106] Iteration 21500, lr = 0.0002
I0615 05:22:31.684072 15760 solver.cpp:228] Iteration 21520, loss = 0.471534
I0615 05:22:31.684096 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 05:22:31.684104 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.18817 (* 1 = 0.18817 loss)
I0615 05:22:31.684108 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.226917 (* 1 = 0.226917 loss)
I0615 05:22:31.684113 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000455584 (* 1 = 0.000455584 loss)
I0615 05:22:31.684116 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258948 (* 1 = 0.0258948 loss)
I0615 05:22:31.684121 15760 sgd_solver.cpp:106] Iteration 21520, lr = 0.0002
I0615 05:24:18.108583 15760 solver.cpp:228] Iteration 21540, loss = 0.640029
I0615 05:24:18.108608 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 05:24:18.108615 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.114421 (* 1 = 0.114421 loss)
I0615 05:24:18.108620 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.108382 (* 1 = 0.108382 loss)
I0615 05:24:18.108624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00473511 (* 1 = 0.00473511 loss)
I0615 05:24:18.108628 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165954 (* 1 = 0.0165954 loss)
I0615 05:24:18.108633 15760 sgd_solver.cpp:106] Iteration 21540, lr = 0.0002
I0615 05:26:04.288228 15760 solver.cpp:228] Iteration 21560, loss = 0.41515
I0615 05:26:04.288276 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 05:26:04.288285 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595726 (* 1 = 0.0595726 loss)
I0615 05:26:04.288290 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0734296 (* 1 = 0.0734296 loss)
I0615 05:26:04.288295 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000268837 (* 1 = 0.000268837 loss)
I0615 05:26:04.288298 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131593 (* 1 = 0.0131593 loss)
I0615 05:26:04.288306 15760 sgd_solver.cpp:106] Iteration 21560, lr = 0.0002
I0615 05:27:50.599524 15760 solver.cpp:228] Iteration 21580, loss = 0.292242
I0615 05:27:50.599546 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 05:27:50.599553 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0691673 (* 1 = 0.0691673 loss)
I0615 05:27:50.599557 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0408416 (* 1 = 0.0408416 loss)
I0615 05:27:50.599561 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217882 (* 1 = 0.00217882 loss)
I0615 05:27:50.599565 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308165 (* 1 = 0.0308165 loss)
I0615 05:27:50.599570 15760 sgd_solver.cpp:106] Iteration 21580, lr = 0.0002
speed: 5.331s / iter
I0615 05:29:36.765488 15760 solver.cpp:228] Iteration 21600, loss = 0.31621
I0615 05:29:36.765513 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 05:29:36.765522 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0901017 (* 1 = 0.0901017 loss)
I0615 05:29:36.765525 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.168899 (* 1 = 0.168899 loss)
I0615 05:29:36.765529 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.45365e-05 (* 1 = 5.45365e-05 loss)
I0615 05:29:36.765533 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127057 (* 1 = 0.0127057 loss)
I0615 05:29:36.765537 15760 sgd_solver.cpp:106] Iteration 21600, lr = 0.0002
I0615 05:31:23.034011 15760 solver.cpp:228] Iteration 21620, loss = 0.394383
I0615 05:31:23.034035 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 05:31:23.034045 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0808284 (* 1 = 0.0808284 loss)
I0615 05:31:23.034052 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0589165 (* 1 = 0.0589165 loss)
I0615 05:31:23.034057 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000259951 (* 1 = 0.000259951 loss)
I0615 05:31:23.034063 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102826 (* 1 = 0.0102826 loss)
I0615 05:31:23.034072 15760 sgd_solver.cpp:106] Iteration 21620, lr = 0.0002
I0615 05:33:09.603562 15760 solver.cpp:228] Iteration 21640, loss = 0.42531
I0615 05:33:09.603586 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 05:33:09.603593 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.134009 (* 1 = 0.134009 loss)
I0615 05:33:09.603597 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.158811 (* 1 = 0.158811 loss)
I0615 05:33:09.603602 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000121655 (* 1 = 0.000121655 loss)
I0615 05:33:09.603606 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00596753 (* 1 = 0.00596753 loss)
I0615 05:33:09.603611 15760 sgd_solver.cpp:106] Iteration 21640, lr = 0.0002
I0615 05:34:56.117285 15760 solver.cpp:228] Iteration 21660, loss = 0.288815
I0615 05:34:56.117308 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 05:34:56.117318 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0471318 (* 1 = 0.0471318 loss)
I0615 05:34:56.117323 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0271641 (* 1 = 0.0271641 loss)
I0615 05:34:56.117329 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000539725 (* 1 = 0.000539725 loss)
I0615 05:34:56.117336 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0098692 (* 1 = 0.0098692 loss)
I0615 05:34:56.117341 15760 sgd_solver.cpp:106] Iteration 21660, lr = 0.0002
I0615 05:36:42.381611 15760 solver.cpp:228] Iteration 21680, loss = 0.36496
I0615 05:36:42.381633 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 05:36:42.381641 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0650181 (* 1 = 0.0650181 loss)
I0615 05:36:42.381645 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0491317 (* 1 = 0.0491317 loss)
I0615 05:36:42.381649 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000143286 (* 1 = 0.000143286 loss)
I0615 05:36:42.381652 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00979255 (* 1 = 0.00979255 loss)
I0615 05:36:42.381657 15760 sgd_solver.cpp:106] Iteration 21680, lr = 0.0002
I0615 05:38:28.801031 15760 solver.cpp:228] Iteration 21700, loss = 0.502611
I0615 05:38:28.801056 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 05:38:28.801064 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0721147 (* 1 = 0.0721147 loss)
I0615 05:38:28.801069 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0872087 (* 1 = 0.0872087 loss)
I0615 05:38:28.801072 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178493 (* 1 = 0.00178493 loss)
I0615 05:38:28.801076 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00830554 (* 1 = 0.00830554 loss)
I0615 05:38:28.801082 15760 sgd_solver.cpp:106] Iteration 21700, lr = 0.0002
I0615 05:40:15.250108 15760 solver.cpp:228] Iteration 21720, loss = 0.204156
I0615 05:40:15.250131 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 05:40:15.250138 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112579 (* 1 = 0.112579 loss)
I0615 05:40:15.250142 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112407 (* 1 = 0.112407 loss)
I0615 05:40:15.250146 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000518527 (* 1 = 0.000518527 loss)
I0615 05:40:15.250149 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00514686 (* 1 = 0.00514686 loss)
I0615 05:40:15.250154 15760 sgd_solver.cpp:106] Iteration 21720, lr = 0.0002
I0615 05:42:01.687794 15760 solver.cpp:228] Iteration 21740, loss = 0.498159
I0615 05:42:01.687820 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 05:42:01.687829 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.21247 (* 1 = 0.21247 loss)
I0615 05:42:01.687835 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.224974 (* 1 = 0.224974 loss)
I0615 05:42:01.687840 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0022264 (* 1 = 0.0022264 loss)
I0615 05:42:01.687846 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0654114 (* 1 = 0.0654114 loss)
I0615 05:42:01.687855 15760 sgd_solver.cpp:106] Iteration 21740, lr = 0.0002
I0615 05:43:48.179330 15760 solver.cpp:228] Iteration 21760, loss = 0.274933
I0615 05:43:48.179353 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 05:43:48.179361 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0770356 (* 1 = 0.0770356 loss)
I0615 05:43:48.179365 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.127806 (* 1 = 0.127806 loss)
I0615 05:43:48.179369 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000579354 (* 1 = 0.000579354 loss)
I0615 05:43:48.179373 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00960149 (* 1 = 0.00960149 loss)
I0615 05:43:48.179378 15760 sgd_solver.cpp:106] Iteration 21760, lr = 0.0002
I0615 05:45:34.654947 15760 solver.cpp:228] Iteration 21780, loss = 0.412218
I0615 05:45:34.654973 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 05:45:34.654981 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.284073 (* 1 = 0.284073 loss)
I0615 05:45:34.654985 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.211956 (* 1 = 0.211956 loss)
I0615 05:45:34.654989 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136925 (* 1 = 0.00136925 loss)
I0615 05:45:34.654994 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337011 (* 1 = 0.0337011 loss)
I0615 05:45:34.654999 15760 sgd_solver.cpp:106] Iteration 21780, lr = 0.0002
speed: 5.331s / iter
I0615 05:47:21.065717 15760 solver.cpp:228] Iteration 21800, loss = 0.200871
I0615 05:47:21.065742 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 05:47:21.065747 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.100981 (* 1 = 0.100981 loss)
I0615 05:47:21.065752 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0671076 (* 1 = 0.0671076 loss)
I0615 05:47:21.065755 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000893136 (* 1 = 0.000893136 loss)
I0615 05:47:21.065759 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232552 (* 1 = 0.0232552 loss)
I0615 05:47:21.065763 15760 sgd_solver.cpp:106] Iteration 21800, lr = 0.0002
I0615 05:49:07.856708 15760 solver.cpp:228] Iteration 21820, loss = 0.282661
I0615 05:49:07.856731 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 05:49:07.856739 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.210323 (* 1 = 0.210323 loss)
I0615 05:49:07.856742 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.147809 (* 1 = 0.147809 loss)
I0615 05:49:07.856745 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00915514 (* 1 = 0.00915514 loss)
I0615 05:49:07.856750 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152365 (* 1 = 0.0152365 loss)
I0615 05:49:07.856755 15760 sgd_solver.cpp:106] Iteration 21820, lr = 0.0002
I0615 05:50:54.578868 15760 solver.cpp:228] Iteration 21840, loss = 0.289226
I0615 05:50:54.578891 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 05:50:54.578900 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.105664 (* 1 = 0.105664 loss)
I0615 05:50:54.578907 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.114599 (* 1 = 0.114599 loss)
I0615 05:50:54.578912 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205613 (* 1 = 0.00205613 loss)
I0615 05:50:54.578917 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102442 (* 1 = 0.0102442 loss)
I0615 05:50:54.578924 15760 sgd_solver.cpp:106] Iteration 21840, lr = 0.0002
I0615 05:52:41.670174 15760 solver.cpp:228] Iteration 21860, loss = 0.337258
I0615 05:52:41.670203 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 05:52:41.670214 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0773294 (* 1 = 0.0773294 loss)
I0615 05:52:41.670223 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.172002 (* 1 = 0.172002 loss)
I0615 05:52:41.670231 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000222436 (* 1 = 0.000222436 loss)
I0615 05:52:41.670239 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00881302 (* 1 = 0.00881302 loss)
I0615 05:52:41.670248 15760 sgd_solver.cpp:106] Iteration 21860, lr = 0.0002
I0615 05:54:29.220002 15760 solver.cpp:228] Iteration 21880, loss = 0.674811
I0615 05:54:29.220032 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 05:54:29.220041 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.293871 (* 1 = 0.293871 loss)
I0615 05:54:29.220047 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.249707 (* 1 = 0.249707 loss)
I0615 05:54:29.220053 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126562 (* 1 = 0.00126562 loss)
I0615 05:54:29.220059 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403896 (* 1 = 0.0403896 loss)
I0615 05:54:29.220065 15760 sgd_solver.cpp:106] Iteration 21880, lr = 0.0002
I0615 05:56:16.361762 15760 solver.cpp:228] Iteration 21900, loss = 0.337298
I0615 05:56:16.361786 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 05:56:16.361793 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.463484 (* 1 = 0.463484 loss)
I0615 05:56:16.361796 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.386102 (* 1 = 0.386102 loss)
I0615 05:56:16.361800 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132674 (* 1 = 0.00132674 loss)
I0615 05:56:16.361804 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100872 (* 1 = 0.100872 loss)
I0615 05:56:16.361809 15760 sgd_solver.cpp:106] Iteration 21900, lr = 0.0002
I0615 05:58:03.452992 15760 solver.cpp:228] Iteration 21920, loss = 0.393313
I0615 05:58:03.453018 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 05:58:03.453027 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.07373 (* 1 = 0.07373 loss)
I0615 05:58:03.453030 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0402859 (* 1 = 0.0402859 loss)
I0615 05:58:03.453035 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000238662 (* 1 = 0.000238662 loss)
I0615 05:58:03.453038 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203308 (* 1 = 0.0203308 loss)
I0615 05:58:03.453044 15760 sgd_solver.cpp:106] Iteration 21920, lr = 0.0002
I0615 05:59:50.511201 15760 solver.cpp:228] Iteration 21940, loss = 0.466768
I0615 05:59:50.511226 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 05:59:50.511232 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.128654 (* 1 = 0.128654 loss)
I0615 05:59:50.511237 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167612 (* 1 = 0.167612 loss)
I0615 05:59:50.511240 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140242 (* 1 = 0.00140242 loss)
I0615 05:59:50.511245 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186558 (* 1 = 0.0186558 loss)
I0615 05:59:50.511248 15760 sgd_solver.cpp:106] Iteration 21940, lr = 0.0002
I0615 06:01:36.636184 15760 solver.cpp:228] Iteration 21960, loss = 0.417754
I0615 06:01:36.636209 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 06:01:36.636216 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.165241 (* 1 = 0.165241 loss)
I0615 06:01:36.636220 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.140108 (* 1 = 0.140108 loss)
I0615 06:01:36.636224 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207762 (* 1 = 0.00207762 loss)
I0615 06:01:36.636229 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0500315 (* 1 = 0.0500315 loss)
I0615 06:01:36.636234 15760 sgd_solver.cpp:106] Iteration 21960, lr = 0.0002
I0615 06:03:23.080318 15760 solver.cpp:228] Iteration 21980, loss = 0.531725
I0615 06:03:23.080348 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 06:03:23.080356 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.278597 (* 1 = 0.278597 loss)
I0615 06:03:23.080361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.242103 (* 1 = 0.242103 loss)
I0615 06:03:23.080366 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00145601 (* 1 = 0.00145601 loss)
I0615 06:03:23.080370 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158018 (* 1 = 0.0158018 loss)
I0615 06:03:23.080376 15760 sgd_solver.cpp:106] Iteration 21980, lr = 0.0002
speed: 5.331s / iter
I0615 06:05:09.684672 15760 solver.cpp:228] Iteration 22000, loss = 0.4527
I0615 06:05:09.684695 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 06:05:09.684702 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.081347 (* 1 = 0.081347 loss)
I0615 06:05:09.684706 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.123837 (* 1 = 0.123837 loss)
I0615 06:05:09.684710 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238389 (* 1 = 0.00238389 loss)
I0615 06:05:09.684713 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0671568 (* 1 = 0.0671568 loss)
I0615 06:05:09.684718 15760 sgd_solver.cpp:106] Iteration 22000, lr = 0.0002
I0615 06:06:56.278748 15760 solver.cpp:228] Iteration 22020, loss = 0.457321
I0615 06:06:56.278774 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 06:06:56.278782 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.150465 (* 1 = 0.150465 loss)
I0615 06:06:56.278786 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.121499 (* 1 = 0.121499 loss)
I0615 06:06:56.278791 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151099 (* 1 = 0.00151099 loss)
I0615 06:06:56.278795 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181449 (* 1 = 0.0181449 loss)
I0615 06:06:56.278800 15760 sgd_solver.cpp:106] Iteration 22020, lr = 0.0002
I0615 06:08:42.666993 15760 solver.cpp:228] Iteration 22040, loss = 0.528434
I0615 06:08:42.667017 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0615 06:08:42.667023 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.387686 (* 1 = 0.387686 loss)
I0615 06:08:42.667027 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.407746 (* 1 = 0.407746 loss)
I0615 06:08:42.667032 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00862277 (* 1 = 0.00862277 loss)
I0615 06:08:42.667034 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.155295 (* 1 = 0.155295 loss)
I0615 06:08:42.667039 15760 sgd_solver.cpp:106] Iteration 22040, lr = 0.0002
I0615 06:10:29.214928 15760 solver.cpp:228] Iteration 22060, loss = 0.412227
I0615 06:10:29.214954 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0615 06:10:29.214962 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.198063 (* 1 = 0.198063 loss)
I0615 06:10:29.214967 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.372644 (* 1 = 0.372644 loss)
I0615 06:10:29.214970 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0050014 (* 1 = 0.0050014 loss)
I0615 06:10:29.214974 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.251698 (* 1 = 0.251698 loss)
I0615 06:10:29.214979 15760 sgd_solver.cpp:106] Iteration 22060, lr = 0.0002
I0615 06:12:15.546461 15760 solver.cpp:228] Iteration 22080, loss = 0.434048
I0615 06:12:15.546486 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 06:12:15.546494 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0725353 (* 1 = 0.0725353 loss)
I0615 06:12:15.546499 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.105691 (* 1 = 0.105691 loss)
I0615 06:12:15.546502 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000729262 (* 1 = 0.000729262 loss)
I0615 06:12:15.546505 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245603 (* 1 = 0.0245603 loss)
I0615 06:12:15.546511 15760 sgd_solver.cpp:106] Iteration 22080, lr = 0.0002
I0615 06:14:01.979879 15760 solver.cpp:228] Iteration 22100, loss = 0.385163
I0615 06:14:01.979905 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 06:14:01.979912 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0619535 (* 1 = 0.0619535 loss)
I0615 06:14:01.979917 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.143637 (* 1 = 0.143637 loss)
I0615 06:14:01.979919 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.04944 (* 1 = 0.04944 loss)
I0615 06:14:01.979923 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563593 (* 1 = 0.0563593 loss)
I0615 06:14:01.979928 15760 sgd_solver.cpp:106] Iteration 22100, lr = 0.0002
I0615 06:15:48.502264 15760 solver.cpp:228] Iteration 22120, loss = 0.341284
I0615 06:15:48.502288 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 06:15:48.502295 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.116965 (* 1 = 0.116965 loss)
I0615 06:15:48.502300 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0631228 (* 1 = 0.0631228 loss)
I0615 06:15:48.502303 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00438791 (* 1 = 0.00438791 loss)
I0615 06:15:48.502307 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110838 (* 1 = 0.0110838 loss)
I0615 06:15:48.502312 15760 sgd_solver.cpp:106] Iteration 22120, lr = 0.0002
I0615 06:17:34.821602 15760 solver.cpp:228] Iteration 22140, loss = 0.330174
I0615 06:17:34.821627 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 06:17:34.821635 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.106049 (* 1 = 0.106049 loss)
I0615 06:17:34.821640 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0867724 (* 1 = 0.0867724 loss)
I0615 06:17:34.821643 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00274812 (* 1 = 0.00274812 loss)
I0615 06:17:34.821647 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364711 (* 1 = 0.0364711 loss)
I0615 06:17:34.821652 15760 sgd_solver.cpp:106] Iteration 22140, lr = 0.0002
I0615 06:19:21.224699 15760 solver.cpp:228] Iteration 22160, loss = 0.439373
I0615 06:19:21.224722 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 06:19:21.224730 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.208275 (* 1 = 0.208275 loss)
I0615 06:19:21.224733 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.289266 (* 1 = 0.289266 loss)
I0615 06:19:21.224736 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019729 (* 1 = 0.0019729 loss)
I0615 06:19:21.224740 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0494672 (* 1 = 0.0494672 loss)
I0615 06:19:21.224745 15760 sgd_solver.cpp:106] Iteration 22160, lr = 0.0002
I0615 06:21:07.669816 15760 solver.cpp:228] Iteration 22180, loss = 0.573447
I0615 06:21:07.669840 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 06:21:07.669849 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.461115 (* 1 = 0.461115 loss)
I0615 06:21:07.669855 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.276173 (* 1 = 0.276173 loss)
I0615 06:21:07.669862 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778404 (* 1 = 0.00778404 loss)
I0615 06:21:07.669867 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.136828 (* 1 = 0.136828 loss)
I0615 06:21:07.669872 15760 sgd_solver.cpp:106] Iteration 22180, lr = 0.0002
speed: 5.331s / iter
I0615 06:22:54.074379 15760 solver.cpp:228] Iteration 22200, loss = 0.391333
I0615 06:22:54.074404 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 06:22:54.074412 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0963662 (* 1 = 0.0963662 loss)
I0615 06:22:54.074416 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161453 (* 1 = 0.161453 loss)
I0615 06:22:54.074420 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102896 (* 1 = 0.00102896 loss)
I0615 06:22:54.074424 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252882 (* 1 = 0.0252882 loss)
I0615 06:22:54.074429 15760 sgd_solver.cpp:106] Iteration 22200, lr = 0.0002
I0615 06:24:40.405645 15760 solver.cpp:228] Iteration 22220, loss = 0.395697
I0615 06:24:40.405675 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 06:24:40.405685 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.205679 (* 1 = 0.205679 loss)
I0615 06:24:40.405692 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.196224 (* 1 = 0.196224 loss)
I0615 06:24:40.405700 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168833 (* 1 = 0.00168833 loss)
I0615 06:24:40.405707 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0355798 (* 1 = 0.0355798 loss)
I0615 06:24:40.405714 15760 sgd_solver.cpp:106] Iteration 22220, lr = 0.0002
I0615 06:26:26.640643 15760 solver.cpp:228] Iteration 22240, loss = 0.450114
I0615 06:26:26.640666 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 06:26:26.640673 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.340114 (* 1 = 0.340114 loss)
I0615 06:26:26.640677 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.256462 (* 1 = 0.256462 loss)
I0615 06:26:26.640681 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000713564 (* 1 = 0.000713564 loss)
I0615 06:26:26.640684 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020436 (* 1 = 0.020436 loss)
I0615 06:26:26.640688 15760 sgd_solver.cpp:106] Iteration 22240, lr = 0.0002
I0615 06:28:12.998759 15760 solver.cpp:228] Iteration 22260, loss = 0.367021
I0615 06:28:12.998783 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 06:28:12.998790 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.260936 (* 1 = 0.260936 loss)
I0615 06:28:12.998795 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.326304 (* 1 = 0.326304 loss)
I0615 06:28:12.998798 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000631369 (* 1 = 0.000631369 loss)
I0615 06:28:12.998801 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00619592 (* 1 = 0.00619592 loss)
I0615 06:28:12.998806 15760 sgd_solver.cpp:106] Iteration 22260, lr = 0.0002
I0615 06:29:59.155766 15760 solver.cpp:228] Iteration 22280, loss = 0.269101
I0615 06:29:59.155791 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 06:29:59.155798 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816734 (* 1 = 0.0816734 loss)
I0615 06:29:59.155802 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0437156 (* 1 = 0.0437156 loss)
I0615 06:29:59.155807 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000132733 (* 1 = 0.000132733 loss)
I0615 06:29:59.155810 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00327269 (* 1 = 0.00327269 loss)
I0615 06:29:59.155815 15760 sgd_solver.cpp:106] Iteration 22280, lr = 0.0002
I0615 06:31:45.580808 15760 solver.cpp:228] Iteration 22300, loss = 0.495428
I0615 06:31:45.580830 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 06:31:45.580837 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.104336 (* 1 = 0.104336 loss)
I0615 06:31:45.580840 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.15487 (* 1 = 0.15487 loss)
I0615 06:31:45.580844 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000355911 (* 1 = 0.000355911 loss)
I0615 06:31:45.580848 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105832 (* 1 = 0.0105832 loss)
I0615 06:31:45.580852 15760 sgd_solver.cpp:106] Iteration 22300, lr = 0.0002
I0615 06:33:32.146354 15760 solver.cpp:228] Iteration 22320, loss = 0.572714
I0615 06:33:32.146378 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 06:33:32.146385 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0965585 (* 1 = 0.0965585 loss)
I0615 06:33:32.146390 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0663381 (* 1 = 0.0663381 loss)
I0615 06:33:32.146394 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228984 (* 1 = 0.00228984 loss)
I0615 06:33:32.146399 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103894 (* 1 = 0.0103894 loss)
I0615 06:33:32.146404 15760 sgd_solver.cpp:106] Iteration 22320, lr = 0.0002
I0615 06:35:18.909303 15760 solver.cpp:228] Iteration 22340, loss = 0.304429
I0615 06:35:18.909328 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 06:35:18.909337 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513877 (* 1 = 0.0513877 loss)
I0615 06:35:18.909340 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.079066 (* 1 = 0.079066 loss)
I0615 06:35:18.909344 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136558 (* 1 = 0.00136558 loss)
I0615 06:35:18.909348 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00560061 (* 1 = 0.00560061 loss)
I0615 06:35:18.909354 15760 sgd_solver.cpp:106] Iteration 22340, lr = 0.0002
I0615 06:37:05.781929 15760 solver.cpp:228] Iteration 22360, loss = 0.494545
I0615 06:37:05.781955 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 06:37:05.781962 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139621 (* 1 = 0.139621 loss)
I0615 06:37:05.781967 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.173184 (* 1 = 0.173184 loss)
I0615 06:37:05.781971 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000502756 (* 1 = 0.000502756 loss)
I0615 06:37:05.781975 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314641 (* 1 = 0.0314641 loss)
I0615 06:37:05.781980 15760 sgd_solver.cpp:106] Iteration 22360, lr = 0.0002
I0615 06:38:52.605434 15760 solver.cpp:228] Iteration 22380, loss = 0.370249
I0615 06:38:52.605460 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 06:38:52.605468 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194886 (* 1 = 0.194886 loss)
I0615 06:38:52.605471 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234794 (* 1 = 0.234794 loss)
I0615 06:38:52.605475 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0477316 (* 1 = 0.0477316 loss)
I0615 06:38:52.605479 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.287249 (* 1 = 0.287249 loss)
I0615 06:38:52.605485 15760 sgd_solver.cpp:106] Iteration 22380, lr = 0.0002
speed: 5.331s / iter
I0615 06:40:39.537895 15760 solver.cpp:228] Iteration 22400, loss = 0.533353
I0615 06:40:39.537921 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 06:40:39.537931 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.211193 (* 1 = 0.211193 loss)
I0615 06:40:39.537937 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.249054 (* 1 = 0.249054 loss)
I0615 06:40:39.537945 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000305868 (* 1 = 0.000305868 loss)
I0615 06:40:39.537950 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166574 (* 1 = 0.0166574 loss)
I0615 06:40:39.537958 15760 sgd_solver.cpp:106] Iteration 22400, lr = 0.0002
I0615 06:42:26.687839 15760 solver.cpp:228] Iteration 22420, loss = 0.462473
I0615 06:42:26.687871 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 06:42:26.687881 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.127583 (* 1 = 0.127583 loss)
I0615 06:42:26.687888 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159188 (* 1 = 0.159188 loss)
I0615 06:42:26.687894 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00272936 (* 1 = 0.00272936 loss)
I0615 06:42:26.687901 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.04151 (* 1 = 0.04151 loss)
I0615 06:42:26.687907 15760 sgd_solver.cpp:106] Iteration 22420, lr = 0.0002
I0615 06:44:13.701151 15760 solver.cpp:228] Iteration 22440, loss = 0.505335
I0615 06:44:13.701190 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 06:44:13.701200 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.100857 (* 1 = 0.100857 loss)
I0615 06:44:13.701205 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.107722 (* 1 = 0.107722 loss)
I0615 06:44:13.701210 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000754393 (* 1 = 0.000754393 loss)
I0615 06:44:13.701215 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00868098 (* 1 = 0.00868098 loss)
I0615 06:44:13.701223 15760 sgd_solver.cpp:106] Iteration 22440, lr = 0.0002
I0615 06:46:00.269059 15760 solver.cpp:228] Iteration 22460, loss = 0.434793
I0615 06:46:00.269083 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 06:46:00.269090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.204746 (* 1 = 0.204746 loss)
I0615 06:46:00.269094 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195318 (* 1 = 0.195318 loss)
I0615 06:46:00.269098 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00211634 (* 1 = 0.00211634 loss)
I0615 06:46:00.269101 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0320453 (* 1 = 0.0320453 loss)
I0615 06:46:00.269106 15760 sgd_solver.cpp:106] Iteration 22460, lr = 0.0002
I0615 06:47:46.710173 15760 solver.cpp:228] Iteration 22480, loss = 0.38199
I0615 06:47:46.710196 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 06:47:46.710204 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0978666 (* 1 = 0.0978666 loss)
I0615 06:47:46.710207 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0997591 (* 1 = 0.0997591 loss)
I0615 06:47:46.710211 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000161087 (* 1 = 0.000161087 loss)
I0615 06:47:46.710214 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128283 (* 1 = 0.0128283 loss)
I0615 06:47:46.710219 15760 sgd_solver.cpp:106] Iteration 22480, lr = 0.0002
I0615 06:49:33.355543 15760 solver.cpp:228] Iteration 22500, loss = 0.299742
I0615 06:49:33.355569 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 06:49:33.355579 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.140839 (* 1 = 0.140839 loss)
I0615 06:49:33.355587 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.267453 (* 1 = 0.267453 loss)
I0615 06:49:33.355592 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00699474 (* 1 = 0.00699474 loss)
I0615 06:49:33.355598 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108763 (* 1 = 0.108763 loss)
I0615 06:49:33.355605 15760 sgd_solver.cpp:106] Iteration 22500, lr = 0.0002
I0615 06:51:20.025331 15760 solver.cpp:228] Iteration 22520, loss = 0.247304
I0615 06:51:20.025363 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 06:51:20.025372 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.095472 (* 1 = 0.095472 loss)
I0615 06:51:20.025378 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0622439 (* 1 = 0.0622439 loss)
I0615 06:51:20.025384 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00754588 (* 1 = 0.00754588 loss)
I0615 06:51:20.025389 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185632 (* 1 = 0.0185632 loss)
I0615 06:51:20.025395 15760 sgd_solver.cpp:106] Iteration 22520, lr = 0.0002
I0615 06:53:06.574005 15760 solver.cpp:228] Iteration 22540, loss = 0.262346
I0615 06:53:06.574033 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 06:53:06.574041 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0601893 (* 1 = 0.0601893 loss)
I0615 06:53:06.574045 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0441448 (* 1 = 0.0441448 loss)
I0615 06:53:06.574049 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00323565 (* 1 = 0.00323565 loss)
I0615 06:53:06.574054 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198136 (* 1 = 0.0198136 loss)
I0615 06:53:06.574059 15760 sgd_solver.cpp:106] Iteration 22540, lr = 0.0002
I0615 06:54:52.968076 15760 solver.cpp:228] Iteration 22560, loss = 0.711998
I0615 06:54:52.968106 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 06:54:52.968116 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.218748 (* 1 = 0.218748 loss)
I0615 06:54:52.968119 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.264471 (* 1 = 0.264471 loss)
I0615 06:54:52.968123 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00632208 (* 1 = 0.00632208 loss)
I0615 06:54:52.968127 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0689457 (* 1 = 0.0689457 loss)
I0615 06:54:52.968134 15760 sgd_solver.cpp:106] Iteration 22560, lr = 0.0002
I0615 06:56:39.199609 15760 solver.cpp:228] Iteration 22580, loss = 0.416232
I0615 06:56:39.199633 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 06:56:39.199640 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.154084 (* 1 = 0.154084 loss)
I0615 06:56:39.199645 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.221184 (* 1 = 0.221184 loss)
I0615 06:56:39.199648 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103162 (* 1 = 0.0103162 loss)
I0615 06:56:39.199651 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103965 (* 1 = 0.103965 loss)
I0615 06:56:39.199656 15760 sgd_solver.cpp:106] Iteration 22580, lr = 0.0002
speed: 5.331s / iter
I0615 06:58:25.575830 15760 solver.cpp:228] Iteration 22600, loss = 0.326066
I0615 06:58:25.575855 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 06:58:25.575861 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11326 (* 1 = 0.11326 loss)
I0615 06:58:25.575865 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0916588 (* 1 = 0.0916588 loss)
I0615 06:58:25.575870 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00637657 (* 1 = 0.00637657 loss)
I0615 06:58:25.575873 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00666036 (* 1 = 0.00666036 loss)
I0615 06:58:25.575877 15760 sgd_solver.cpp:106] Iteration 22600, lr = 0.0002
I0615 07:00:11.932421 15760 solver.cpp:228] Iteration 22620, loss = 0.316817
I0615 07:00:11.932447 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 07:00:11.932456 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.152807 (* 1 = 0.152807 loss)
I0615 07:00:11.932459 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.165639 (* 1 = 0.165639 loss)
I0615 07:00:11.932463 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591336 (* 1 = 0.00591336 loss)
I0615 07:00:11.932467 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216931 (* 1 = 0.0216931 loss)
I0615 07:00:11.932472 15760 sgd_solver.cpp:106] Iteration 22620, lr = 0.0002
I0615 07:01:58.362812 15760 solver.cpp:228] Iteration 22640, loss = 0.319037
I0615 07:01:58.362838 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 07:01:58.362845 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111846 (* 1 = 0.111846 loss)
I0615 07:01:58.362849 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.110851 (* 1 = 0.110851 loss)
I0615 07:01:58.362854 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301916 (* 1 = 0.00301916 loss)
I0615 07:01:58.362857 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0474441 (* 1 = 0.0474441 loss)
I0615 07:01:58.362862 15760 sgd_solver.cpp:106] Iteration 22640, lr = 0.0002
I0615 07:03:44.986241 15760 solver.cpp:228] Iteration 22660, loss = 0.439367
I0615 07:03:44.986265 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 07:03:44.986274 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.21795 (* 1 = 0.21795 loss)
I0615 07:03:44.986281 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.27858 (* 1 = 0.27858 loss)
I0615 07:03:44.986286 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00830732 (* 1 = 0.00830732 loss)
I0615 07:03:44.986292 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169406 (* 1 = 0.0169406 loss)
I0615 07:03:44.986299 15760 sgd_solver.cpp:106] Iteration 22660, lr = 0.0002
I0615 07:05:31.402971 15760 solver.cpp:228] Iteration 22680, loss = 0.302603
I0615 07:05:31.402994 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 07:05:31.403002 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.235664 (* 1 = 0.235664 loss)
I0615 07:05:31.403007 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.250768 (* 1 = 0.250768 loss)
I0615 07:05:31.403012 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347209 (* 1 = 0.00347209 loss)
I0615 07:05:31.403014 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.154297 (* 1 = 0.154297 loss)
I0615 07:05:31.403020 15760 sgd_solver.cpp:106] Iteration 22680, lr = 0.0002
I0615 07:07:18.067653 15760 solver.cpp:228] Iteration 22700, loss = 0.285073
I0615 07:07:18.067682 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 07:07:18.067690 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0714448 (* 1 = 0.0714448 loss)
I0615 07:07:18.067695 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0923636 (* 1 = 0.0923636 loss)
I0615 07:07:18.067700 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00335728 (* 1 = 0.00335728 loss)
I0615 07:07:18.067705 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307141 (* 1 = 0.0307141 loss)
I0615 07:07:18.067711 15760 sgd_solver.cpp:106] Iteration 22700, lr = 0.0002
I0615 07:09:04.599041 15760 solver.cpp:228] Iteration 22720, loss = 0.210534
I0615 07:09:04.599066 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 07:09:04.599074 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0633916 (* 1 = 0.0633916 loss)
I0615 07:09:04.599078 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0513507 (* 1 = 0.0513507 loss)
I0615 07:09:04.599082 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000136935 (* 1 = 0.000136935 loss)
I0615 07:09:04.599086 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0099776 (* 1 = 0.0099776 loss)
I0615 07:09:04.599092 15760 sgd_solver.cpp:106] Iteration 22720, lr = 0.0002
I0615 07:10:51.047605 15760 solver.cpp:228] Iteration 22740, loss = 0.549646
I0615 07:10:51.047631 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0615 07:10:51.047637 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.649414 (* 1 = 0.649414 loss)
I0615 07:10:51.047641 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.532973 (* 1 = 0.532973 loss)
I0615 07:10:51.047646 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00877595 (* 1 = 0.00877595 loss)
I0615 07:10:51.047649 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.165137 (* 1 = 0.165137 loss)
I0615 07:10:51.047654 15760 sgd_solver.cpp:106] Iteration 22740, lr = 0.0002
I0615 07:12:37.402580 15760 solver.cpp:228] Iteration 22760, loss = 0.362388
I0615 07:12:37.402603 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 07:12:37.402611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442653 (* 1 = 0.0442653 loss)
I0615 07:12:37.402616 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0595069 (* 1 = 0.0595069 loss)
I0615 07:12:37.402619 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000409264 (* 1 = 0.000409264 loss)
I0615 07:12:37.402622 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236911 (* 1 = 0.0236911 loss)
I0615 07:12:37.402627 15760 sgd_solver.cpp:106] Iteration 22760, lr = 0.0002
I0615 07:14:23.835675 15760 solver.cpp:228] Iteration 22780, loss = 0.369382
I0615 07:14:23.835700 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 07:14:23.835707 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448383 (* 1 = 0.0448383 loss)
I0615 07:14:23.835711 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0196825 (* 1 = 0.0196825 loss)
I0615 07:14:23.835716 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424181 (* 1 = 0.00424181 loss)
I0615 07:14:23.835721 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152387 (* 1 = 0.0152387 loss)
I0615 07:14:23.835726 15760 sgd_solver.cpp:106] Iteration 22780, lr = 0.0002
speed: 5.331s / iter
I0615 07:16:10.424479 15760 solver.cpp:228] Iteration 22800, loss = 0.487178
I0615 07:16:10.424504 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 07:16:10.424510 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111601 (* 1 = 0.111601 loss)
I0615 07:16:10.424515 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0996397 (* 1 = 0.0996397 loss)
I0615 07:16:10.424518 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128252 (* 1 = 0.00128252 loss)
I0615 07:16:10.424521 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00929285 (* 1 = 0.00929285 loss)
I0615 07:16:10.424526 15760 sgd_solver.cpp:106] Iteration 22800, lr = 0.0002
I0615 07:17:57.719405 15760 solver.cpp:228] Iteration 22820, loss = 0.463674
I0615 07:17:57.719429 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 07:17:57.719437 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.184693 (* 1 = 0.184693 loss)
I0615 07:17:57.719441 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.185893 (* 1 = 0.185893 loss)
I0615 07:17:57.719445 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000257841 (* 1 = 0.000257841 loss)
I0615 07:17:57.719449 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170964 (* 1 = 0.0170964 loss)
I0615 07:17:57.719455 15760 sgd_solver.cpp:106] Iteration 22820, lr = 0.0002
I0615 07:19:44.141180 15760 solver.cpp:228] Iteration 22840, loss = 0.528383
I0615 07:19:44.141204 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 07:19:44.141211 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0767841 (* 1 = 0.0767841 loss)
I0615 07:19:44.141216 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0754158 (* 1 = 0.0754158 loss)
I0615 07:19:44.141221 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000141157 (* 1 = 0.000141157 loss)
I0615 07:19:44.141224 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107362 (* 1 = 0.0107362 loss)
I0615 07:19:44.141229 15760 sgd_solver.cpp:106] Iteration 22840, lr = 0.0002
I0615 07:21:30.721386 15760 solver.cpp:228] Iteration 22860, loss = 0.399563
I0615 07:21:30.721410 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 07:21:30.721416 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0456332 (* 1 = 0.0456332 loss)
I0615 07:21:30.721420 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0401162 (* 1 = 0.0401162 loss)
I0615 07:21:30.721423 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100865 (* 1 = 0.0100865 loss)
I0615 07:21:30.721426 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181248 (* 1 = 0.0181248 loss)
I0615 07:21:30.721431 15760 sgd_solver.cpp:106] Iteration 22860, lr = 0.0002
I0615 07:23:18.035324 15760 solver.cpp:228] Iteration 22880, loss = 0.423808
I0615 07:23:18.035348 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 07:23:18.035356 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609837 (* 1 = 0.0609837 loss)
I0615 07:23:18.035359 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.107583 (* 1 = 0.107583 loss)
I0615 07:23:18.035363 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000232059 (* 1 = 0.000232059 loss)
I0615 07:23:18.035367 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335166 (* 1 = 0.0335166 loss)
I0615 07:23:18.035372 15760 sgd_solver.cpp:106] Iteration 22880, lr = 0.0002
I0615 07:25:04.983196 15760 solver.cpp:228] Iteration 22900, loss = 0.403447
I0615 07:25:04.983223 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 07:25:04.983232 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.095793 (* 1 = 0.095793 loss)
I0615 07:25:04.983235 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.125722 (* 1 = 0.125722 loss)
I0615 07:25:04.983239 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000247751 (* 1 = 0.000247751 loss)
I0615 07:25:04.983243 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199196 (* 1 = 0.0199196 loss)
I0615 07:25:04.983248 15760 sgd_solver.cpp:106] Iteration 22900, lr = 0.0002
I0615 07:26:52.283860 15760 solver.cpp:228] Iteration 22920, loss = 0.261072
I0615 07:26:52.283885 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 07:26:52.283892 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0882988 (* 1 = 0.0882988 loss)
I0615 07:26:52.283896 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109086 (* 1 = 0.109086 loss)
I0615 07:26:52.283900 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00124015 (* 1 = 0.00124015 loss)
I0615 07:26:52.283905 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158257 (* 1 = 0.0158257 loss)
I0615 07:26:52.283910 15760 sgd_solver.cpp:106] Iteration 22920, lr = 0.0002
I0615 07:28:39.271669 15760 solver.cpp:228] Iteration 22940, loss = 0.285529
I0615 07:28:39.271697 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 07:28:39.271704 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.136145 (* 1 = 0.136145 loss)
I0615 07:28:39.271708 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.11244 (* 1 = 0.11244 loss)
I0615 07:28:39.271713 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00047874 (* 1 = 0.00047874 loss)
I0615 07:28:39.271716 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127333 (* 1 = 0.0127333 loss)
I0615 07:28:39.271723 15760 sgd_solver.cpp:106] Iteration 22940, lr = 0.0002
I0615 07:30:26.111356 15760 solver.cpp:228] Iteration 22960, loss = 0.354113
I0615 07:30:26.111383 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 07:30:26.111393 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.204107 (* 1 = 0.204107 loss)
I0615 07:30:26.111398 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.239137 (* 1 = 0.239137 loss)
I0615 07:30:26.111402 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000228928 (* 1 = 0.000228928 loss)
I0615 07:30:26.111407 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122641 (* 1 = 0.0122641 loss)
I0615 07:30:26.111413 15760 sgd_solver.cpp:106] Iteration 22960, lr = 0.0002
I0615 07:32:12.961560 15760 solver.cpp:228] Iteration 22980, loss = 0.303325
I0615 07:32:12.961586 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 07:32:12.961594 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.110494 (* 1 = 0.110494 loss)
I0615 07:32:12.961601 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.118992 (* 1 = 0.118992 loss)
I0615 07:32:12.961608 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000863961 (* 1 = 0.000863961 loss)
I0615 07:32:12.961612 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00684222 (* 1 = 0.00684222 loss)
I0615 07:32:12.961619 15760 sgd_solver.cpp:106] Iteration 22980, lr = 0.0002
speed: 5.331s / iter
I0615 07:33:59.713448 15760 solver.cpp:228] Iteration 23000, loss = 0.269384
I0615 07:33:59.713471 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 07:33:59.713480 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561559 (* 1 = 0.0561559 loss)
I0615 07:33:59.713486 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0870461 (* 1 = 0.0870461 loss)
I0615 07:33:59.713492 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000846223 (* 1 = 0.000846223 loss)
I0615 07:33:59.713497 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00907305 (* 1 = 0.00907305 loss)
I0615 07:33:59.713503 15760 sgd_solver.cpp:106] Iteration 23000, lr = 0.0002
I0615 07:35:46.421038 15760 solver.cpp:228] Iteration 23020, loss = 0.249089
I0615 07:35:46.421062 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 07:35:46.421069 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0907909 (* 1 = 0.0907909 loss)
I0615 07:35:46.421073 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.098625 (* 1 = 0.098625 loss)
I0615 07:35:46.421077 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143017 (* 1 = 0.00143017 loss)
I0615 07:35:46.421080 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0051424 (* 1 = 0.0051424 loss)
I0615 07:35:46.421085 15760 sgd_solver.cpp:106] Iteration 23020, lr = 0.0002
I0615 07:37:32.587112 15760 solver.cpp:228] Iteration 23040, loss = 0.46823
I0615 07:37:32.587136 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 07:37:32.587143 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0971659 (* 1 = 0.0971659 loss)
I0615 07:37:32.587146 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.177252 (* 1 = 0.177252 loss)
I0615 07:37:32.587150 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351435 (* 1 = 0.00351435 loss)
I0615 07:37:32.587153 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00666084 (* 1 = 0.00666084 loss)
I0615 07:37:32.587158 15760 sgd_solver.cpp:106] Iteration 23040, lr = 0.0002
I0615 07:39:18.972754 15760 solver.cpp:228] Iteration 23060, loss = 0.363604
I0615 07:39:18.972779 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 07:39:18.972786 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194357 (* 1 = 0.194357 loss)
I0615 07:39:18.972791 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.146382 (* 1 = 0.146382 loss)
I0615 07:39:18.972795 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197238 (* 1 = 0.0197238 loss)
I0615 07:39:18.972798 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.081238 (* 1 = 0.081238 loss)
I0615 07:39:18.972803 15760 sgd_solver.cpp:106] Iteration 23060, lr = 0.0002
I0615 07:41:05.458833 15760 solver.cpp:228] Iteration 23080, loss = 0.449164
I0615 07:41:05.458858 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 07:41:05.458864 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0831754 (* 1 = 0.0831754 loss)
I0615 07:41:05.458868 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128087 (* 1 = 0.128087 loss)
I0615 07:41:05.458873 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00197754 (* 1 = 0.00197754 loss)
I0615 07:41:05.458875 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228857 (* 1 = 0.0228857 loss)
I0615 07:41:05.458880 15760 sgd_solver.cpp:106] Iteration 23080, lr = 0.0002
I0615 07:42:51.998893 15760 solver.cpp:228] Iteration 23100, loss = 0.461773
I0615 07:42:51.998916 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 07:42:51.998922 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0814347 (* 1 = 0.0814347 loss)
I0615 07:42:51.998926 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0735849 (* 1 = 0.0735849 loss)
I0615 07:42:51.998930 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00060259 (* 1 = 0.00060259 loss)
I0615 07:42:51.998934 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00713261 (* 1 = 0.00713261 loss)
I0615 07:42:51.998939 15760 sgd_solver.cpp:106] Iteration 23100, lr = 0.0002
I0615 07:44:38.228113 15760 solver.cpp:228] Iteration 23120, loss = 0.47274
I0615 07:44:38.228140 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 07:44:38.228152 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0691798 (* 1 = 0.0691798 loss)
I0615 07:44:38.228157 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0951574 (* 1 = 0.0951574 loss)
I0615 07:44:38.228164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147347 (* 1 = 0.00147347 loss)
I0615 07:44:38.228170 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128507 (* 1 = 0.0128507 loss)
I0615 07:44:38.228178 15760 sgd_solver.cpp:106] Iteration 23120, lr = 0.0002
I0615 07:46:24.703480 15760 solver.cpp:228] Iteration 23140, loss = 0.370184
I0615 07:46:24.703506 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 07:46:24.703516 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0983481 (* 1 = 0.0983481 loss)
I0615 07:46:24.703524 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0687745 (* 1 = 0.0687745 loss)
I0615 07:46:24.703531 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000182529 (* 1 = 0.000182529 loss)
I0615 07:46:24.703536 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230291 (* 1 = 0.0230291 loss)
I0615 07:46:24.703543 15760 sgd_solver.cpp:106] Iteration 23140, lr = 0.0002
I0615 07:48:10.986249 15760 solver.cpp:228] Iteration 23160, loss = 0.280992
I0615 07:48:10.986274 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 07:48:10.986280 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0706087 (* 1 = 0.0706087 loss)
I0615 07:48:10.986284 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0506868 (* 1 = 0.0506868 loss)
I0615 07:48:10.986289 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.80714e-05 (* 1 = 9.80714e-05 loss)
I0615 07:48:10.986291 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154575 (* 1 = 0.0154575 loss)
I0615 07:48:10.986296 15760 sgd_solver.cpp:106] Iteration 23160, lr = 0.0002
I0615 07:49:57.294193 15760 solver.cpp:228] Iteration 23180, loss = 0.471028
I0615 07:49:57.294219 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 07:49:57.294226 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.179527 (* 1 = 0.179527 loss)
I0615 07:49:57.294230 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.164367 (* 1 = 0.164367 loss)
I0615 07:49:57.294234 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000940415 (* 1 = 0.000940415 loss)
I0615 07:49:57.294239 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227319 (* 1 = 0.0227319 loss)
I0615 07:49:57.294243 15760 sgd_solver.cpp:106] Iteration 23180, lr = 0.0002
speed: 5.331s / iter
I0615 07:51:43.748872 15760 solver.cpp:228] Iteration 23200, loss = 0.425342
I0615 07:51:43.748901 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 07:51:43.748910 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605748 (* 1 = 0.0605748 loss)
I0615 07:51:43.748914 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0612395 (* 1 = 0.0612395 loss)
I0615 07:51:43.748919 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315322 (* 1 = 0.00315322 loss)
I0615 07:51:43.748922 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192027 (* 1 = 0.0192027 loss)
I0615 07:51:43.748929 15760 sgd_solver.cpp:106] Iteration 23200, lr = 0.0002
I0615 07:53:30.356449 15760 solver.cpp:228] Iteration 23220, loss = 0.386856
I0615 07:53:30.356477 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 07:53:30.356484 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.131824 (* 1 = 0.131824 loss)
I0615 07:53:30.356488 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.114458 (* 1 = 0.114458 loss)
I0615 07:53:30.356492 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000408955 (* 1 = 0.000408955 loss)
I0615 07:53:30.356495 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379023 (* 1 = 0.0379023 loss)
I0615 07:53:30.356500 15760 sgd_solver.cpp:106] Iteration 23220, lr = 0.0002
I0615 07:55:16.624029 15760 solver.cpp:228] Iteration 23240, loss = 0.414494
I0615 07:55:16.624053 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 07:55:16.624060 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.474169 (* 1 = 0.474169 loss)
I0615 07:55:16.624066 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.290013 (* 1 = 0.290013 loss)
I0615 07:55:16.624073 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140515 (* 1 = 0.00140515 loss)
I0615 07:55:16.624076 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.140222 (* 1 = 0.140222 loss)
I0615 07:55:16.624083 15760 sgd_solver.cpp:106] Iteration 23240, lr = 0.0002
I0615 07:57:03.164448 15760 solver.cpp:228] Iteration 23260, loss = 0.514464
I0615 07:57:03.164474 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 07:57:03.164482 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0724861 (* 1 = 0.0724861 loss)
I0615 07:57:03.164487 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0835075 (* 1 = 0.0835075 loss)
I0615 07:57:03.164491 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101968 (* 1 = 0.00101968 loss)
I0615 07:57:03.164495 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228063 (* 1 = 0.0228063 loss)
I0615 07:57:03.164501 15760 sgd_solver.cpp:106] Iteration 23260, lr = 0.0002
I0615 07:58:49.422158 15760 solver.cpp:228] Iteration 23280, loss = 0.4177
I0615 07:58:49.422184 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 07:58:49.422194 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0990138 (* 1 = 0.0990138 loss)
I0615 07:58:49.422201 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.123431 (* 1 = 0.123431 loss)
I0615 07:58:49.422209 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000673052 (* 1 = 0.000673052 loss)
I0615 07:58:49.422214 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00793668 (* 1 = 0.00793668 loss)
I0615 07:58:49.422224 15760 sgd_solver.cpp:106] Iteration 23280, lr = 0.0002
I0615 08:00:36.230880 15760 solver.cpp:228] Iteration 23300, loss = 0.472857
I0615 08:00:36.230904 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 08:00:36.230912 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.26312 (* 1 = 0.26312 loss)
I0615 08:00:36.230916 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.19318 (* 1 = 0.19318 loss)
I0615 08:00:36.230921 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000176672 (* 1 = 0.000176672 loss)
I0615 08:00:36.230924 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136244 (* 1 = 0.0136244 loss)
I0615 08:00:36.230929 15760 sgd_solver.cpp:106] Iteration 23300, lr = 0.0002
I0615 08:02:23.260284 15760 solver.cpp:228] Iteration 23320, loss = 0.357575
I0615 08:02:23.260308 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 08:02:23.260314 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0684251 (* 1 = 0.0684251 loss)
I0615 08:02:23.260318 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0557688 (* 1 = 0.0557688 loss)
I0615 08:02:23.260321 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0272362 (* 1 = 0.0272362 loss)
I0615 08:02:23.260325 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228401 (* 1 = 0.0228401 loss)
I0615 08:02:23.260329 15760 sgd_solver.cpp:106] Iteration 23320, lr = 0.0002
I0615 08:04:10.167750 15760 solver.cpp:228] Iteration 23340, loss = 0.487809
I0615 08:04:10.167775 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 08:04:10.167783 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111855 (* 1 = 0.111855 loss)
I0615 08:04:10.167788 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119989 (* 1 = 0.119989 loss)
I0615 08:04:10.167791 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000430773 (* 1 = 0.000430773 loss)
I0615 08:04:10.167795 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167865 (* 1 = 0.0167865 loss)
I0615 08:04:10.167800 15760 sgd_solver.cpp:106] Iteration 23340, lr = 0.0002
I0615 08:05:57.091060 15760 solver.cpp:228] Iteration 23360, loss = 0.458884
I0615 08:05:57.091084 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 08:05:57.091094 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.123754 (* 1 = 0.123754 loss)
I0615 08:05:57.091099 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159071 (* 1 = 0.159071 loss)
I0615 08:05:57.091104 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000212061 (* 1 = 0.000212061 loss)
I0615 08:05:57.091110 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270399 (* 1 = 0.0270399 loss)
I0615 08:05:57.091120 15760 sgd_solver.cpp:106] Iteration 23360, lr = 0.0002
I0615 08:07:43.711930 15760 solver.cpp:228] Iteration 23380, loss = 0.216301
I0615 08:07:43.711954 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 08:07:43.711961 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0704066 (* 1 = 0.0704066 loss)
I0615 08:07:43.711966 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0639931 (* 1 = 0.0639931 loss)
I0615 08:07:43.711969 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00278236 (* 1 = 0.00278236 loss)
I0615 08:07:43.711972 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010919 (* 1 = 0.010919 loss)
I0615 08:07:43.711977 15760 sgd_solver.cpp:106] Iteration 23380, lr = 0.0002
speed: 5.331s / iter
I0615 08:09:30.397660 15760 solver.cpp:228] Iteration 23400, loss = 0.597267
I0615 08:09:30.397684 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 08:09:30.397693 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.437672 (* 1 = 0.437672 loss)
I0615 08:09:30.397699 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.250837 (* 1 = 0.250837 loss)
I0615 08:09:30.397706 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00436719 (* 1 = 0.00436719 loss)
I0615 08:09:30.397711 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0568049 (* 1 = 0.0568049 loss)
I0615 08:09:30.397718 15760 sgd_solver.cpp:106] Iteration 23400, lr = 0.0002
I0615 08:11:16.982511 15760 solver.cpp:228] Iteration 23420, loss = 0.287905
I0615 08:11:16.982539 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 08:11:16.982549 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.162023 (* 1 = 0.162023 loss)
I0615 08:11:16.982556 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.169994 (* 1 = 0.169994 loss)
I0615 08:11:16.982561 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0935855 (* 1 = 0.0935855 loss)
I0615 08:11:16.982568 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.278904 (* 1 = 0.278904 loss)
I0615 08:11:16.982575 15760 sgd_solver.cpp:106] Iteration 23420, lr = 0.0002
I0615 08:13:03.620883 15760 solver.cpp:228] Iteration 23440, loss = 0.377588
I0615 08:13:03.620909 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0615 08:13:03.620918 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.550969 (* 1 = 0.550969 loss)
I0615 08:13:03.620921 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.549444 (* 1 = 0.549444 loss)
I0615 08:13:03.620924 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0321836 (* 1 = 0.0321836 loss)
I0615 08:13:03.620929 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.281654 (* 1 = 0.281654 loss)
I0615 08:13:03.620934 15760 sgd_solver.cpp:106] Iteration 23440, lr = 0.0002
I0615 08:14:50.030774 15760 solver.cpp:228] Iteration 23460, loss = 0.442771
I0615 08:14:50.030802 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 08:14:50.030809 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.114974 (* 1 = 0.114974 loss)
I0615 08:14:50.030814 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148386 (* 1 = 0.148386 loss)
I0615 08:14:50.030818 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000391878 (* 1 = 0.000391878 loss)
I0615 08:14:50.030822 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00958774 (* 1 = 0.00958774 loss)
I0615 08:14:50.030827 15760 sgd_solver.cpp:106] Iteration 23460, lr = 0.0002
I0615 08:16:37.011500 15760 solver.cpp:228] Iteration 23480, loss = 0.35396
I0615 08:16:37.011524 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 08:16:37.011530 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0881156 (* 1 = 0.0881156 loss)
I0615 08:16:37.011534 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.145352 (* 1 = 0.145352 loss)
I0615 08:16:37.011538 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00784751 (* 1 = 0.00784751 loss)
I0615 08:16:37.011541 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114154 (* 1 = 0.0114154 loss)
I0615 08:16:37.011546 15760 sgd_solver.cpp:106] Iteration 23480, lr = 0.0002
I0615 08:18:23.387290 15760 solver.cpp:228] Iteration 23500, loss = 0.521694
I0615 08:18:23.387317 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 08:18:23.387326 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0674055 (* 1 = 0.0674055 loss)
I0615 08:18:23.387329 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0503675 (* 1 = 0.0503675 loss)
I0615 08:18:23.387333 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000665927 (* 1 = 0.000665927 loss)
I0615 08:18:23.387337 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570178 (* 1 = 0.00570178 loss)
I0615 08:18:23.387342 15760 sgd_solver.cpp:106] Iteration 23500, lr = 0.0002
I0615 08:20:10.004866 15760 solver.cpp:228] Iteration 23520, loss = 0.358667
I0615 08:20:10.004889 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 08:20:10.004896 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.222952 (* 1 = 0.222952 loss)
I0615 08:20:10.004900 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.166594 (* 1 = 0.166594 loss)
I0615 08:20:10.004904 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000899943 (* 1 = 0.000899943 loss)
I0615 08:20:10.004907 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289204 (* 1 = 0.0289204 loss)
I0615 08:20:10.004911 15760 sgd_solver.cpp:106] Iteration 23520, lr = 0.0002
I0615 08:21:56.398078 15760 solver.cpp:228] Iteration 23540, loss = 0.359738
I0615 08:21:56.398102 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 08:21:56.398109 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.363447 (* 1 = 0.363447 loss)
I0615 08:21:56.398114 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.334588 (* 1 = 0.334588 loss)
I0615 08:21:56.398118 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00890756 (* 1 = 0.00890756 loss)
I0615 08:21:56.398123 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0605161 (* 1 = 0.0605161 loss)
I0615 08:21:56.398128 15760 sgd_solver.cpp:106] Iteration 23540, lr = 0.0002
I0615 08:23:42.995185 15760 solver.cpp:228] Iteration 23560, loss = 0.38166
I0615 08:23:42.995211 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 08:23:42.995221 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0348257 (* 1 = 0.0348257 loss)
I0615 08:23:42.995229 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0403924 (* 1 = 0.0403924 loss)
I0615 08:23:42.995234 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137293 (* 1 = 0.00137293 loss)
I0615 08:23:42.995241 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0077749 (* 1 = 0.0077749 loss)
I0615 08:23:42.995249 15760 sgd_solver.cpp:106] Iteration 23560, lr = 0.0002
I0615 08:25:29.419601 15760 solver.cpp:228] Iteration 23580, loss = 0.233383
I0615 08:25:29.419626 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 08:25:29.419633 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.171796 (* 1 = 0.171796 loss)
I0615 08:25:29.419637 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.238523 (* 1 = 0.238523 loss)
I0615 08:25:29.419641 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00730145 (* 1 = 0.00730145 loss)
I0615 08:25:29.419646 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0712806 (* 1 = 0.0712806 loss)
I0615 08:25:29.419651 15760 sgd_solver.cpp:106] Iteration 23580, lr = 0.0002
speed: 5.331s / iter
I0615 08:27:15.769906 15760 solver.cpp:228] Iteration 23600, loss = 0.393929
I0615 08:27:15.769930 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 08:27:15.769938 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.40859 (* 1 = 0.40859 loss)
I0615 08:27:15.769944 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.403525 (* 1 = 0.403525 loss)
I0615 08:27:15.769950 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00795799 (* 1 = 0.00795799 loss)
I0615 08:27:15.769956 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.165809 (* 1 = 0.165809 loss)
I0615 08:27:15.769963 15760 sgd_solver.cpp:106] Iteration 23600, lr = 0.0002
I0615 08:29:02.094058 15760 solver.cpp:228] Iteration 23620, loss = 0.408393
I0615 08:29:02.094081 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 08:29:02.094090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.201374 (* 1 = 0.201374 loss)
I0615 08:29:02.094096 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.279685 (* 1 = 0.279685 loss)
I0615 08:29:02.094103 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010316 (* 1 = 0.010316 loss)
I0615 08:29:02.094106 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.162039 (* 1 = 0.162039 loss)
I0615 08:29:02.094112 15760 sgd_solver.cpp:106] Iteration 23620, lr = 0.0002
I0615 08:30:48.238188 15760 solver.cpp:228] Iteration 23640, loss = 0.440551
I0615 08:30:48.238212 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 08:30:48.238219 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0813516 (* 1 = 0.0813516 loss)
I0615 08:30:48.238224 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0673894 (* 1 = 0.0673894 loss)
I0615 08:30:48.238226 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0362634 (* 1 = 0.0362634 loss)
I0615 08:30:48.238230 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273493 (* 1 = 0.0273493 loss)
I0615 08:30:48.238234 15760 sgd_solver.cpp:106] Iteration 23640, lr = 0.0002
I0615 08:32:35.048825 15760 solver.cpp:228] Iteration 23660, loss = 0.393564
I0615 08:32:35.048849 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 08:32:35.048857 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108243 (* 1 = 0.108243 loss)
I0615 08:32:35.048861 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148977 (* 1 = 0.148977 loss)
I0615 08:32:35.048864 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012298 (* 1 = 0.0012298 loss)
I0615 08:32:35.048868 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00840788 (* 1 = 0.00840788 loss)
I0615 08:32:35.048873 15760 sgd_solver.cpp:106] Iteration 23660, lr = 0.0002
I0615 08:34:21.445605 15760 solver.cpp:228] Iteration 23680, loss = 0.36159
I0615 08:34:21.445631 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 08:34:21.445641 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0483942 (* 1 = 0.0483942 loss)
I0615 08:34:21.445647 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0525321 (* 1 = 0.0525321 loss)
I0615 08:34:21.445653 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000212148 (* 1 = 0.000212148 loss)
I0615 08:34:21.445660 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106654 (* 1 = 0.0106654 loss)
I0615 08:34:21.445669 15760 sgd_solver.cpp:106] Iteration 23680, lr = 0.0002
I0615 08:36:07.844975 15760 solver.cpp:228] Iteration 23700, loss = 0.240841
I0615 08:36:07.845001 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 08:36:07.845011 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0812104 (* 1 = 0.0812104 loss)
I0615 08:36:07.845017 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0952658 (* 1 = 0.0952658 loss)
I0615 08:36:07.845024 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00612786 (* 1 = 0.00612786 loss)
I0615 08:36:07.845031 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372616 (* 1 = 0.0372616 loss)
I0615 08:36:07.845037 15760 sgd_solver.cpp:106] Iteration 23700, lr = 0.0002
I0615 08:37:54.473201 15760 solver.cpp:228] Iteration 23720, loss = 0.471987
I0615 08:37:54.473233 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0615 08:37:54.473242 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.350008 (* 1 = 0.350008 loss)
I0615 08:37:54.473246 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.383189 (* 1 = 0.383189 loss)
I0615 08:37:54.473250 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000685469 (* 1 = 0.000685469 loss)
I0615 08:37:54.473254 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0916269 (* 1 = 0.0916269 loss)
I0615 08:37:54.473260 15760 sgd_solver.cpp:106] Iteration 23720, lr = 0.0002
I0615 08:39:40.791097 15760 solver.cpp:228] Iteration 23740, loss = 0.352975
I0615 08:39:40.791123 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 08:39:40.791132 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.272527 (* 1 = 0.272527 loss)
I0615 08:39:40.791138 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.284071 (* 1 = 0.284071 loss)
I0615 08:39:40.791144 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259708 (* 1 = 0.00259708 loss)
I0615 08:39:40.791149 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330656 (* 1 = 0.0330656 loss)
I0615 08:39:40.791155 15760 sgd_solver.cpp:106] Iteration 23740, lr = 0.0002
I0615 08:41:27.191769 15760 solver.cpp:228] Iteration 23760, loss = 0.422068
I0615 08:41:27.191793 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 08:41:27.191799 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12966 (* 1 = 0.12966 loss)
I0615 08:41:27.191803 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.135949 (* 1 = 0.135949 loss)
I0615 08:41:27.191807 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000235825 (* 1 = 0.000235825 loss)
I0615 08:41:27.191812 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00373826 (* 1 = 0.00373826 loss)
I0615 08:41:27.191815 15760 sgd_solver.cpp:106] Iteration 23760, lr = 0.0002
I0615 08:43:13.474706 15760 solver.cpp:228] Iteration 23780, loss = 0.23222
I0615 08:43:13.474731 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 08:43:13.474740 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.191136 (* 1 = 0.191136 loss)
I0615 08:43:13.474743 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.186768 (* 1 = 0.186768 loss)
I0615 08:43:13.474748 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474892 (* 1 = 0.00474892 loss)
I0615 08:43:13.474751 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0385537 (* 1 = 0.0385537 loss)
I0615 08:43:13.474756 15760 sgd_solver.cpp:106] Iteration 23780, lr = 0.0002
speed: 5.331s / iter
I0615 08:44:59.818037 15760 solver.cpp:228] Iteration 23800, loss = 0.249933
I0615 08:44:59.818061 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 08:44:59.818068 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0987799 (* 1 = 0.0987799 loss)
I0615 08:44:59.818073 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0969599 (* 1 = 0.0969599 loss)
I0615 08:44:59.818078 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165342 (* 1 = 0.00165342 loss)
I0615 08:44:59.818081 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00380734 (* 1 = 0.00380734 loss)
I0615 08:44:59.818086 15760 sgd_solver.cpp:106] Iteration 23800, lr = 0.0002
I0615 08:46:46.386889 15760 solver.cpp:228] Iteration 23820, loss = 0.373183
I0615 08:46:46.386916 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 08:46:46.386926 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.115567 (* 1 = 0.115567 loss)
I0615 08:46:46.386934 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.140544 (* 1 = 0.140544 loss)
I0615 08:46:46.386940 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00803061 (* 1 = 0.00803061 loss)
I0615 08:46:46.386945 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0634268 (* 1 = 0.0634268 loss)
I0615 08:46:46.386953 15760 sgd_solver.cpp:106] Iteration 23820, lr = 0.0002
I0615 08:48:33.165727 15760 solver.cpp:228] Iteration 23840, loss = 0.626772
I0615 08:48:33.165752 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 08:48:33.165760 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101563 (* 1 = 0.101563 loss)
I0615 08:48:33.165765 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.21954 (* 1 = 0.21954 loss)
I0615 08:48:33.165768 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135608 (* 1 = 0.0135608 loss)
I0615 08:48:33.165772 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.175176 (* 1 = 0.175176 loss)
I0615 08:48:33.165776 15760 sgd_solver.cpp:106] Iteration 23840, lr = 0.0002
I0615 08:50:19.894306 15760 solver.cpp:228] Iteration 23860, loss = 0.337924
I0615 08:50:19.894331 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 08:50:19.894340 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0766424 (* 1 = 0.0766424 loss)
I0615 08:50:19.894343 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.088141 (* 1 = 0.088141 loss)
I0615 08:50:19.894347 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000126018 (* 1 = 0.000126018 loss)
I0615 08:50:19.894351 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00837775 (* 1 = 0.00837775 loss)
I0615 08:50:19.894356 15760 sgd_solver.cpp:106] Iteration 23860, lr = 0.0002
I0615 08:52:06.495524 15760 solver.cpp:228] Iteration 23880, loss = 0.292724
I0615 08:52:06.495554 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 08:52:06.495565 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.101784 (* 1 = 0.101784 loss)
I0615 08:52:06.495571 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.104605 (* 1 = 0.104605 loss)
I0615 08:52:06.495579 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000744599 (* 1 = 0.000744599 loss)
I0615 08:52:06.495585 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192334 (* 1 = 0.0192334 loss)
I0615 08:52:06.495592 15760 sgd_solver.cpp:106] Iteration 23880, lr = 0.0002
I0615 08:53:53.402848 15760 solver.cpp:228] Iteration 23900, loss = 0.319709
I0615 08:53:53.402874 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 08:53:53.402882 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.254706 (* 1 = 0.254706 loss)
I0615 08:53:53.402886 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.216352 (* 1 = 0.216352 loss)
I0615 08:53:53.402890 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219433 (* 1 = 0.0219433 loss)
I0615 08:53:53.402894 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153976 (* 1 = 0.153976 loss)
I0615 08:53:53.402900 15760 sgd_solver.cpp:106] Iteration 23900, lr = 0.0002
I0615 08:55:40.236706 15760 solver.cpp:228] Iteration 23920, loss = 0.375624
I0615 08:55:40.236728 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 08:55:40.236734 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.073975 (* 1 = 0.073975 loss)
I0615 08:55:40.236738 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113081 (* 1 = 0.113081 loss)
I0615 08:55:40.236742 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000623974 (* 1 = 0.000623974 loss)
I0615 08:55:40.236747 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307567 (* 1 = 0.0307567 loss)
I0615 08:55:40.236750 15760 sgd_solver.cpp:106] Iteration 23920, lr = 0.0002
I0615 08:57:26.611806 15760 solver.cpp:228] Iteration 23940, loss = 0.320588
I0615 08:57:26.611830 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 08:57:26.611837 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.223367 (* 1 = 0.223367 loss)
I0615 08:57:26.611840 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161265 (* 1 = 0.161265 loss)
I0615 08:57:26.611845 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000318867 (* 1 = 0.000318867 loss)
I0615 08:57:26.611848 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018442 (* 1 = 0.018442 loss)
I0615 08:57:26.611852 15760 sgd_solver.cpp:106] Iteration 23940, lr = 0.0002
I0615 08:59:12.946650 15760 solver.cpp:228] Iteration 23960, loss = 0.255395
I0615 08:59:12.946674 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 08:59:12.946682 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0700493 (* 1 = 0.0700493 loss)
I0615 08:59:12.946686 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0904913 (* 1 = 0.0904913 loss)
I0615 08:59:12.946689 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00242812 (* 1 = 0.00242812 loss)
I0615 08:59:12.946693 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015684 (* 1 = 0.015684 loss)
I0615 08:59:12.946698 15760 sgd_solver.cpp:106] Iteration 23960, lr = 0.0002
I0615 09:00:59.744321 15760 solver.cpp:228] Iteration 23980, loss = 0.509328
I0615 09:00:59.744346 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 09:00:59.744354 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0658984 (* 1 = 0.0658984 loss)
I0615 09:00:59.744357 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.139437 (* 1 = 0.139437 loss)
I0615 09:00:59.744361 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000185345 (* 1 = 0.000185345 loss)
I0615 09:00:59.744365 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00763205 (* 1 = 0.00763205 loss)
I0615 09:00:59.744369 15760 sgd_solver.cpp:106] Iteration 23980, lr = 0.0002
speed: 5.331s / iter
I0615 09:02:46.511831 15760 solver.cpp:228] Iteration 24000, loss = 0.33574
I0615 09:02:46.511854 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 09:02:46.511862 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.239513 (* 1 = 0.239513 loss)
I0615 09:02:46.511868 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.306865 (* 1 = 0.306865 loss)
I0615 09:02:46.511871 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052264 (* 1 = 0.0052264 loss)
I0615 09:02:46.511878 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02744 (* 1 = 0.02744 loss)
I0615 09:02:46.511884 15760 sgd_solver.cpp:106] Iteration 24000, lr = 0.0002
I0615 09:04:32.867409 15760 solver.cpp:228] Iteration 24020, loss = 0.353628
I0615 09:04:32.867434 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 09:04:32.867442 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.119407 (* 1 = 0.119407 loss)
I0615 09:04:32.867446 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116263 (* 1 = 0.116263 loss)
I0615 09:04:32.867450 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000460398 (* 1 = 0.000460398 loss)
I0615 09:04:32.867455 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00504801 (* 1 = 0.00504801 loss)
I0615 09:04:32.867460 15760 sgd_solver.cpp:106] Iteration 24020, lr = 0.0002
I0615 09:06:19.359385 15760 solver.cpp:228] Iteration 24040, loss = 0.338908
I0615 09:06:19.359407 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 09:06:19.359416 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0243367 (* 1 = 0.0243367 loss)
I0615 09:06:19.359418 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0515138 (* 1 = 0.0515138 loss)
I0615 09:06:19.359422 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00523512 (* 1 = 0.00523512 loss)
I0615 09:06:19.359426 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315056 (* 1 = 0.0315056 loss)
I0615 09:06:19.359431 15760 sgd_solver.cpp:106] Iteration 24040, lr = 0.0002
I0615 09:08:05.726078 15760 solver.cpp:228] Iteration 24060, loss = 0.395798
I0615 09:08:05.726104 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 09:08:05.726111 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.20674 (* 1 = 0.20674 loss)
I0615 09:08:05.726115 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195542 (* 1 = 0.195542 loss)
I0615 09:08:05.726119 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00177416 (* 1 = 0.00177416 loss)
I0615 09:08:05.726122 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224043 (* 1 = 0.0224043 loss)
I0615 09:08:05.726127 15760 sgd_solver.cpp:106] Iteration 24060, lr = 0.0002
I0615 09:09:51.989543 15760 solver.cpp:228] Iteration 24080, loss = 0.385928
I0615 09:09:51.989569 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 09:09:51.989578 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.460938 (* 1 = 0.460938 loss)
I0615 09:09:51.989581 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.358521 (* 1 = 0.358521 loss)
I0615 09:09:51.989586 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538782 (* 1 = 0.00538782 loss)
I0615 09:09:51.989589 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0796531 (* 1 = 0.0796531 loss)
I0615 09:09:51.989595 15760 sgd_solver.cpp:106] Iteration 24080, lr = 0.0002
I0615 09:11:38.226039 15760 solver.cpp:228] Iteration 24100, loss = 0.219633
I0615 09:11:38.226063 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 09:11:38.226069 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.28055 (* 1 = 0.28055 loss)
I0615 09:11:38.226073 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.215178 (* 1 = 0.215178 loss)
I0615 09:11:38.226078 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00501719 (* 1 = 0.00501719 loss)
I0615 09:11:38.226080 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332392 (* 1 = 0.0332392 loss)
I0615 09:11:38.226085 15760 sgd_solver.cpp:106] Iteration 24100, lr = 0.0002
I0615 09:13:24.585999 15760 solver.cpp:228] Iteration 24120, loss = 0.342131
I0615 09:13:24.586024 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 09:13:24.586031 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0942565 (* 1 = 0.0942565 loss)
I0615 09:13:24.586035 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120057 (* 1 = 0.120057 loss)
I0615 09:13:24.586038 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273902 (* 1 = 0.00273902 loss)
I0615 09:13:24.586042 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185736 (* 1 = 0.0185736 loss)
I0615 09:13:24.586046 15760 sgd_solver.cpp:106] Iteration 24120, lr = 0.0002
I0615 09:15:10.986905 15760 solver.cpp:228] Iteration 24140, loss = 0.33218
I0615 09:15:10.986930 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 09:15:10.986938 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468196 (* 1 = 0.0468196 loss)
I0615 09:15:10.986943 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0495453 (* 1 = 0.0495453 loss)
I0615 09:15:10.986946 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0046355 (* 1 = 0.0046355 loss)
I0615 09:15:10.986949 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228472 (* 1 = 0.0228472 loss)
I0615 09:15:10.986954 15760 sgd_solver.cpp:106] Iteration 24140, lr = 0.0002
I0615 09:16:57.472656 15760 solver.cpp:228] Iteration 24160, loss = 0.384517
I0615 09:16:57.472682 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 09:16:57.472688 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0636013 (* 1 = 0.0636013 loss)
I0615 09:16:57.472693 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.096107 (* 1 = 0.096107 loss)
I0615 09:16:57.472697 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000639873 (* 1 = 0.000639873 loss)
I0615 09:16:57.472700 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152729 (* 1 = 0.0152729 loss)
I0615 09:16:57.472705 15760 sgd_solver.cpp:106] Iteration 24160, lr = 0.0002
I0615 09:18:43.909384 15760 solver.cpp:228] Iteration 24180, loss = 0.517484
I0615 09:18:43.909410 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 09:18:43.909420 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.546268 (* 1 = 0.546268 loss)
I0615 09:18:43.909426 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.317308 (* 1 = 0.317308 loss)
I0615 09:18:43.909433 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360417 (* 1 = 0.00360417 loss)
I0615 09:18:43.909440 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.136491 (* 1 = 0.136491 loss)
I0615 09:18:43.909446 15760 sgd_solver.cpp:106] Iteration 24180, lr = 0.0002
speed: 5.331s / iter
I0615 09:20:30.576624 15760 solver.cpp:228] Iteration 24200, loss = 0.320701
I0615 09:20:30.576649 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 09:20:30.576656 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.153025 (* 1 = 0.153025 loss)
I0615 09:20:30.576660 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.16332 (* 1 = 0.16332 loss)
I0615 09:20:30.576664 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00277979 (* 1 = 0.00277979 loss)
I0615 09:20:30.576668 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288739 (* 1 = 0.0288739 loss)
I0615 09:20:30.576673 15760 sgd_solver.cpp:106] Iteration 24200, lr = 0.0002
I0615 09:22:16.900182 15760 solver.cpp:228] Iteration 24220, loss = 0.401528
I0615 09:22:16.900204 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 09:22:16.900212 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.176017 (* 1 = 0.176017 loss)
I0615 09:22:16.900215 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116021 (* 1 = 0.116021 loss)
I0615 09:22:16.900219 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0022129 (* 1 = 0.0022129 loss)
I0615 09:22:16.900223 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0436559 (* 1 = 0.0436559 loss)
I0615 09:22:16.900228 15760 sgd_solver.cpp:106] Iteration 24220, lr = 0.0002
I0615 09:24:03.232519 15760 solver.cpp:228] Iteration 24240, loss = 0.645537
I0615 09:24:03.232545 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 09:24:03.232553 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.210651 (* 1 = 0.210651 loss)
I0615 09:24:03.232558 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.211662 (* 1 = 0.211662 loss)
I0615 09:24:03.232561 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0024333 (* 1 = 0.0024333 loss)
I0615 09:24:03.232565 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490615 (* 1 = 0.0490615 loss)
I0615 09:24:03.232571 15760 sgd_solver.cpp:106] Iteration 24240, lr = 0.0002
I0615 09:25:49.832903 15760 solver.cpp:228] Iteration 24260, loss = 0.522946
I0615 09:25:49.832926 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 09:25:49.832933 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.073576 (* 1 = 0.073576 loss)
I0615 09:25:49.832942 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0508534 (* 1 = 0.0508534 loss)
I0615 09:25:49.832947 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0051863 (* 1 = 0.0051863 loss)
I0615 09:25:49.832950 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194871 (* 1 = 0.0194871 loss)
I0615 09:25:49.832957 15760 sgd_solver.cpp:106] Iteration 24260, lr = 0.0002
I0615 09:27:36.169536 15760 solver.cpp:228] Iteration 24280, loss = 0.502511
I0615 09:27:36.169559 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 09:27:36.169566 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0671756 (* 1 = 0.0671756 loss)
I0615 09:27:36.169572 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.127685 (* 1 = 0.127685 loss)
I0615 09:27:36.169579 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314842 (* 1 = 0.00314842 loss)
I0615 09:27:36.169581 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141318 (* 1 = 0.0141318 loss)
I0615 09:27:36.169587 15760 sgd_solver.cpp:106] Iteration 24280, lr = 0.0002
I0615 09:29:22.601671 15760 solver.cpp:228] Iteration 24300, loss = 0.239117
I0615 09:29:22.601696 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 09:29:22.601703 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0696609 (* 1 = 0.0696609 loss)
I0615 09:29:22.601707 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113152 (* 1 = 0.113152 loss)
I0615 09:29:22.601711 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259547 (* 1 = 0.00259547 loss)
I0615 09:29:22.601716 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00521031 (* 1 = 0.00521031 loss)
I0615 09:29:22.601721 15760 sgd_solver.cpp:106] Iteration 24300, lr = 0.0002
I0615 09:31:09.217689 15760 solver.cpp:228] Iteration 24320, loss = 0.268217
I0615 09:31:09.217713 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 09:31:09.217720 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.145293 (* 1 = 0.145293 loss)
I0615 09:31:09.217725 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.191009 (* 1 = 0.191009 loss)
I0615 09:31:09.217730 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0298911 (* 1 = 0.0298911 loss)
I0615 09:31:09.217732 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0701483 (* 1 = 0.0701483 loss)
I0615 09:31:09.217738 15760 sgd_solver.cpp:106] Iteration 24320, lr = 0.0002
I0615 09:32:55.793062 15760 solver.cpp:228] Iteration 24340, loss = 0.261854
I0615 09:32:55.793088 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 09:32:55.793097 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.276832 (* 1 = 0.276832 loss)
I0615 09:32:55.793103 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.189687 (* 1 = 0.189687 loss)
I0615 09:32:55.793110 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000217296 (* 1 = 0.000217296 loss)
I0615 09:32:55.793117 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0328376 (* 1 = 0.0328376 loss)
I0615 09:32:55.793123 15760 sgd_solver.cpp:106] Iteration 24340, lr = 0.0002
I0615 09:34:42.813302 15760 solver.cpp:228] Iteration 24360, loss = 0.301311
I0615 09:34:42.813326 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 09:34:42.813334 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0770537 (* 1 = 0.0770537 loss)
I0615 09:34:42.813338 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0780294 (* 1 = 0.0780294 loss)
I0615 09:34:42.813343 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000103558 (* 1 = 0.000103558 loss)
I0615 09:34:42.813346 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00732341 (* 1 = 0.00732341 loss)
I0615 09:34:42.813351 15760 sgd_solver.cpp:106] Iteration 24360, lr = 0.0002
I0615 09:36:29.443958 15760 solver.cpp:228] Iteration 24380, loss = 0.639978
I0615 09:36:29.443981 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 09:36:29.443989 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0626358 (* 1 = 0.0626358 loss)
I0615 09:36:29.443992 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0791982 (* 1 = 0.0791982 loss)
I0615 09:36:29.443996 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000525821 (* 1 = 0.000525821 loss)
I0615 09:36:29.444000 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171282 (* 1 = 0.0171282 loss)
I0615 09:36:29.444005 15760 sgd_solver.cpp:106] Iteration 24380, lr = 0.0002
speed: 5.331s / iter
I0615 09:38:16.395516 15760 solver.cpp:228] Iteration 24400, loss = 0.649025
I0615 09:38:16.395541 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 09:38:16.395550 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0811763 (* 1 = 0.0811763 loss)
I0615 09:38:16.395553 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0565554 (* 1 = 0.0565554 loss)
I0615 09:38:16.395557 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00622582 (* 1 = 0.00622582 loss)
I0615 09:38:16.395561 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030752 (* 1 = 0.030752 loss)
I0615 09:38:16.395566 15760 sgd_solver.cpp:106] Iteration 24400, lr = 0.0002
I0615 09:40:02.714046 15760 solver.cpp:228] Iteration 24420, loss = 0.47214
I0615 09:40:02.714071 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0615 09:40:02.714079 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.51392 (* 1 = 0.51392 loss)
I0615 09:40:02.714083 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.428306 (* 1 = 0.428306 loss)
I0615 09:40:02.714088 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330373 (* 1 = 0.00330373 loss)
I0615 09:40:02.714092 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.094083 (* 1 = 0.094083 loss)
I0615 09:40:02.714097 15760 sgd_solver.cpp:106] Iteration 24420, lr = 0.0002
I0615 09:41:49.106709 15760 solver.cpp:228] Iteration 24440, loss = 0.470459
I0615 09:41:49.106735 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 09:41:49.106742 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0734842 (* 1 = 0.0734842 loss)
I0615 09:41:49.106746 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0614163 (* 1 = 0.0614163 loss)
I0615 09:41:49.106750 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213876 (* 1 = 0.00213876 loss)
I0615 09:41:49.106753 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184086 (* 1 = 0.0184086 loss)
I0615 09:41:49.106760 15760 sgd_solver.cpp:106] Iteration 24440, lr = 0.0002
I0615 09:43:35.986956 15760 solver.cpp:228] Iteration 24460, loss = 0.437355
I0615 09:43:35.986985 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 09:43:35.986994 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.341893 (* 1 = 0.341893 loss)
I0615 09:43:35.986999 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.230866 (* 1 = 0.230866 loss)
I0615 09:43:35.987004 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137581 (* 1 = 0.00137581 loss)
I0615 09:43:35.987009 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0662537 (* 1 = 0.0662537 loss)
I0615 09:43:35.987015 15760 sgd_solver.cpp:106] Iteration 24460, lr = 0.0002
I0615 09:45:22.779578 15760 solver.cpp:228] Iteration 24480, loss = 0.511391
I0615 09:45:22.779600 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 09:45:22.779608 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.190629 (* 1 = 0.190629 loss)
I0615 09:45:22.779611 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.21802 (* 1 = 0.21802 loss)
I0615 09:45:22.779615 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00274586 (* 1 = 0.00274586 loss)
I0615 09:45:22.779618 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307265 (* 1 = 0.0307265 loss)
I0615 09:45:22.779623 15760 sgd_solver.cpp:106] Iteration 24480, lr = 0.0002
I0615 09:47:09.317256 15760 solver.cpp:228] Iteration 24500, loss = 0.27091
I0615 09:47:09.317281 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 09:47:09.317291 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322107 (* 1 = 0.0322107 loss)
I0615 09:47:09.317296 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0594784 (* 1 = 0.0594784 loss)
I0615 09:47:09.317301 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236425 (* 1 = 0.00236425 loss)
I0615 09:47:09.317307 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121392 (* 1 = 0.0121392 loss)
I0615 09:47:09.317313 15760 sgd_solver.cpp:106] Iteration 24500, lr = 0.0002
I0615 09:48:55.543252 15760 solver.cpp:228] Iteration 24520, loss = 0.549632
I0615 09:48:55.543277 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 09:48:55.543287 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0762855 (* 1 = 0.0762855 loss)
I0615 09:48:55.543292 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0716289 (* 1 = 0.0716289 loss)
I0615 09:48:55.543298 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00339077 (* 1 = 0.00339077 loss)
I0615 09:48:55.543303 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200025 (* 1 = 0.0200025 loss)
I0615 09:48:55.543309 15760 sgd_solver.cpp:106] Iteration 24520, lr = 0.0002
I0615 09:50:41.903259 15760 solver.cpp:228] Iteration 24540, loss = 0.436608
I0615 09:50:41.903285 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 09:50:41.903295 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0800178 (* 1 = 0.0800178 loss)
I0615 09:50:41.903301 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128878 (* 1 = 0.128878 loss)
I0615 09:50:41.903307 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0398494 (* 1 = 0.0398494 loss)
I0615 09:50:41.903313 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.047041 (* 1 = 0.047041 loss)
I0615 09:50:41.903321 15760 sgd_solver.cpp:106] Iteration 24540, lr = 0.0002
I0615 09:52:28.207881 15760 solver.cpp:228] Iteration 24560, loss = 0.523618
I0615 09:52:28.207904 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 09:52:28.207911 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855831 (* 1 = 0.0855831 loss)
I0615 09:52:28.207916 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0988508 (* 1 = 0.0988508 loss)
I0615 09:52:28.207918 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000579478 (* 1 = 0.000579478 loss)
I0615 09:52:28.207922 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00581498 (* 1 = 0.00581498 loss)
I0615 09:52:28.207926 15760 sgd_solver.cpp:106] Iteration 24560, lr = 0.0002
I0615 09:54:14.727321 15760 solver.cpp:228] Iteration 24580, loss = 0.713043
I0615 09:54:14.727346 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 09:54:14.727354 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.356852 (* 1 = 0.356852 loss)
I0615 09:54:14.727357 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309836 (* 1 = 0.309836 loss)
I0615 09:54:14.727360 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121702 (* 1 = 0.00121702 loss)
I0615 09:54:14.727365 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431036 (* 1 = 0.0431036 loss)
I0615 09:54:14.727370 15760 sgd_solver.cpp:106] Iteration 24580, lr = 0.0002
speed: 5.331s / iter
I0615 09:56:01.025879 15760 solver.cpp:228] Iteration 24600, loss = 0.70918
I0615 09:56:01.025905 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 09:56:01.025913 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278217 (* 1 = 0.0278217 loss)
I0615 09:56:01.025918 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0642549 (* 1 = 0.0642549 loss)
I0615 09:56:01.025921 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0209803 (* 1 = 0.0209803 loss)
I0615 09:56:01.025925 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036945 (* 1 = 0.036945 loss)
I0615 09:56:01.025931 15760 sgd_solver.cpp:106] Iteration 24600, lr = 0.0002
I0615 09:57:47.394264 15760 solver.cpp:228] Iteration 24620, loss = 0.406389
I0615 09:57:47.394289 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 09:57:47.394297 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.131148 (* 1 = 0.131148 loss)
I0615 09:57:47.394301 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.219548 (* 1 = 0.219548 loss)
I0615 09:57:47.394305 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.116387 (* 1 = 0.116387 loss)
I0615 09:57:47.394309 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.25925 (* 1 = 0.25925 loss)
I0615 09:57:47.394315 15760 sgd_solver.cpp:106] Iteration 24620, lr = 0.0002
I0615 09:59:33.639734 15760 solver.cpp:228] Iteration 24640, loss = 0.390095
I0615 09:59:33.639758 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 09:59:33.639765 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576751 (* 1 = 0.0576751 loss)
I0615 09:59:33.639770 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0283139 (* 1 = 0.0283139 loss)
I0615 09:59:33.639773 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139648 (* 1 = 0.00139648 loss)
I0615 09:59:33.639776 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00976734 (* 1 = 0.00976734 loss)
I0615 09:59:33.639781 15760 sgd_solver.cpp:106] Iteration 24640, lr = 0.0002
I0615 10:01:19.997326 15760 solver.cpp:228] Iteration 24660, loss = 0.319969
I0615 10:01:19.997350 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 10:01:19.997356 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0596997 (* 1 = 0.0596997 loss)
I0615 10:01:19.997360 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0188341 (* 1 = 0.0188341 loss)
I0615 10:01:19.997364 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000472284 (* 1 = 0.000472284 loss)
I0615 10:01:19.997368 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00402933 (* 1 = 0.00402933 loss)
I0615 10:01:19.997372 15760 sgd_solver.cpp:106] Iteration 24660, lr = 0.0002
I0615 10:03:06.107587 15760 solver.cpp:228] Iteration 24680, loss = 0.292447
I0615 10:03:06.107614 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 10:03:06.107621 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0611251 (* 1 = 0.0611251 loss)
I0615 10:03:06.107626 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.085046 (* 1 = 0.085046 loss)
I0615 10:03:06.107630 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276652 (* 1 = 0.00276652 loss)
I0615 10:03:06.107635 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206522 (* 1 = 0.0206522 loss)
I0615 10:03:06.107638 15760 sgd_solver.cpp:106] Iteration 24680, lr = 0.0002
I0615 10:04:52.566319 15760 solver.cpp:228] Iteration 24700, loss = 0.419208
I0615 10:04:52.566344 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 10:04:52.566354 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0775587 (* 1 = 0.0775587 loss)
I0615 10:04:52.566361 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.058657 (* 1 = 0.058657 loss)
I0615 10:04:52.566367 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120045 (* 1 = 0.00120045 loss)
I0615 10:04:52.566375 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00601302 (* 1 = 0.00601302 loss)
I0615 10:04:52.566381 15760 sgd_solver.cpp:106] Iteration 24700, lr = 0.0002
I0615 10:06:39.046066 15760 solver.cpp:228] Iteration 24720, loss = 0.429717
I0615 10:06:39.046090 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 10:06:39.046097 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.218048 (* 1 = 0.218048 loss)
I0615 10:06:39.046102 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.210796 (* 1 = 0.210796 loss)
I0615 10:06:39.046105 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0373939 (* 1 = 0.0373939 loss)
I0615 10:06:39.046109 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100884 (* 1 = 0.100884 loss)
I0615 10:06:39.046118 15760 sgd_solver.cpp:106] Iteration 24720, lr = 0.0002
I0615 10:08:25.507694 15760 solver.cpp:228] Iteration 24740, loss = 0.513146
I0615 10:08:25.507719 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 10:08:25.507727 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.166028 (* 1 = 0.166028 loss)
I0615 10:08:25.507731 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.175549 (* 1 = 0.175549 loss)
I0615 10:08:25.507735 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000289026 (* 1 = 0.000289026 loss)
I0615 10:08:25.507740 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128545 (* 1 = 0.0128545 loss)
I0615 10:08:25.507745 15760 sgd_solver.cpp:106] Iteration 24740, lr = 0.0002
I0615 10:10:11.714144 15760 solver.cpp:228] Iteration 24760, loss = 0.462553
I0615 10:10:11.714169 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 10:10:11.714176 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0532332 (* 1 = 0.0532332 loss)
I0615 10:10:11.714181 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0682885 (* 1 = 0.0682885 loss)
I0615 10:10:11.714184 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131762 (* 1 = 0.0131762 loss)
I0615 10:10:11.714188 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0587866 (* 1 = 0.0587866 loss)
I0615 10:10:11.714193 15760 sgd_solver.cpp:106] Iteration 24760, lr = 0.0002
I0615 10:11:57.996589 15760 solver.cpp:228] Iteration 24780, loss = 0.310956
I0615 10:11:57.996614 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 10:11:57.996621 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.149845 (* 1 = 0.149845 loss)
I0615 10:11:57.996625 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.158562 (* 1 = 0.158562 loss)
I0615 10:11:57.996629 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000843292 (* 1 = 0.000843292 loss)
I0615 10:11:57.996632 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387232 (* 1 = 0.0387232 loss)
I0615 10:11:57.996636 15760 sgd_solver.cpp:106] Iteration 24780, lr = 0.0002
speed: 5.330s / iter
I0615 10:13:44.547602 15760 solver.cpp:228] Iteration 24800, loss = 0.502476
I0615 10:13:44.547626 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0615 10:13:44.547632 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.704041 (* 1 = 0.704041 loss)
I0615 10:13:44.547636 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.740863 (* 1 = 0.740863 loss)
I0615 10:13:44.547639 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.11882 (* 1 = 0.11882 loss)
I0615 10:13:44.547643 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.370323 (* 1 = 0.370323 loss)
I0615 10:13:44.547647 15760 sgd_solver.cpp:106] Iteration 24800, lr = 0.0002
I0615 10:15:31.037505 15760 solver.cpp:228] Iteration 24820, loss = 0.436823
I0615 10:15:31.037533 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 10:15:31.037540 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.124915 (* 1 = 0.124915 loss)
I0615 10:15:31.037544 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.064861 (* 1 = 0.064861 loss)
I0615 10:15:31.037549 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000209513 (* 1 = 0.000209513 loss)
I0615 10:15:31.037552 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00646105 (* 1 = 0.00646105 loss)
I0615 10:15:31.037557 15760 sgd_solver.cpp:106] Iteration 24820, lr = 0.0002
I0615 10:17:17.373303 15760 solver.cpp:228] Iteration 24840, loss = 0.508075
I0615 10:17:17.373327 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 10:17:17.373334 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.329846 (* 1 = 0.329846 loss)
I0615 10:17:17.373339 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.34709 (* 1 = 0.34709 loss)
I0615 10:17:17.373342 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115368 (* 1 = 0.0115368 loss)
I0615 10:17:17.373347 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.249092 (* 1 = 0.249092 loss)
I0615 10:17:17.373351 15760 sgd_solver.cpp:106] Iteration 24840, lr = 0.0002
I0615 10:19:04.118824 15760 solver.cpp:228] Iteration 24860, loss = 0.726568
I0615 10:19:04.118849 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0615 10:19:04.118854 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.67876 (* 1 = 0.67876 loss)
I0615 10:19:04.118858 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.492978 (* 1 = 0.492978 loss)
I0615 10:19:04.118862 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100842 (* 1 = 0.0100842 loss)
I0615 10:19:04.118865 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.416106 (* 1 = 0.416106 loss)
I0615 10:19:04.118870 15760 sgd_solver.cpp:106] Iteration 24860, lr = 0.0002
I0615 10:20:51.023303 15760 solver.cpp:228] Iteration 24880, loss = 0.280454
I0615 10:20:51.023329 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 10:20:51.023336 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795787 (* 1 = 0.0795787 loss)
I0615 10:20:51.023340 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0596007 (* 1 = 0.0596007 loss)
I0615 10:20:51.023345 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00452428 (* 1 = 0.00452428 loss)
I0615 10:20:51.023349 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127947 (* 1 = 0.0127947 loss)
I0615 10:20:51.023353 15760 sgd_solver.cpp:106] Iteration 24880, lr = 0.0002
I0615 10:22:38.374727 15760 solver.cpp:228] Iteration 24900, loss = 0.391699
I0615 10:22:38.374753 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 10:22:38.374763 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0844454 (* 1 = 0.0844454 loss)
I0615 10:22:38.374770 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0597973 (* 1 = 0.0597973 loss)
I0615 10:22:38.374776 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00612403 (* 1 = 0.00612403 loss)
I0615 10:22:38.374783 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217288 (* 1 = 0.0217288 loss)
I0615 10:22:38.374791 15760 sgd_solver.cpp:106] Iteration 24900, lr = 0.0002
I0615 10:24:24.621279 15760 solver.cpp:228] Iteration 24920, loss = 0.396533
I0615 10:24:24.621304 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 10:24:24.621310 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.365363 (* 1 = 0.365363 loss)
I0615 10:24:24.621315 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.266555 (* 1 = 0.266555 loss)
I0615 10:24:24.621318 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169706 (* 1 = 0.00169706 loss)
I0615 10:24:24.621322 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110793 (* 1 = 0.110793 loss)
I0615 10:24:24.621327 15760 sgd_solver.cpp:106] Iteration 24920, lr = 0.0002
I0615 10:26:11.001631 15760 solver.cpp:228] Iteration 24940, loss = 0.231531
I0615 10:26:11.001658 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 10:26:11.001667 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.122205 (* 1 = 0.122205 loss)
I0615 10:26:11.001670 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.090237 (* 1 = 0.090237 loss)
I0615 10:26:11.001674 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000187867 (* 1 = 0.000187867 loss)
I0615 10:26:11.001678 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00620421 (* 1 = 0.00620421 loss)
I0615 10:26:11.001683 15760 sgd_solver.cpp:106] Iteration 24940, lr = 0.0002
I0615 10:27:58.100648 15760 solver.cpp:228] Iteration 24960, loss = 1.07151
I0615 10:27:58.100672 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 10:27:58.100679 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.185509 (* 1 = 0.185509 loss)
I0615 10:27:58.100683 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.277619 (* 1 = 0.277619 loss)
I0615 10:27:58.100687 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000255956 (* 1 = 0.000255956 loss)
I0615 10:27:58.100690 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361758 (* 1 = 0.0361758 loss)
I0615 10:27:58.100695 15760 sgd_solver.cpp:106] Iteration 24960, lr = 0.0002
I0615 10:29:44.948305 15760 solver.cpp:228] Iteration 24980, loss = 0.418217
I0615 10:29:44.948330 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 10:29:44.948338 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146606 (* 1 = 0.146606 loss)
I0615 10:29:44.948341 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.131401 (* 1 = 0.131401 loss)
I0615 10:29:44.948345 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00905763 (* 1 = 0.00905763 loss)
I0615 10:29:44.948349 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332193 (* 1 = 0.0332193 loss)
I0615 10:29:44.948354 15760 sgd_solver.cpp:106] Iteration 24980, lr = 0.0002
speed: 5.330s / iter
I0615 10:31:26.476002 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_25000.caffemodel
I0615 10:31:32.270220 15760 solver.cpp:228] Iteration 25000, loss = 0.428127
I0615 10:31:32.270246 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 10:31:32.270256 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817644 (* 1 = 0.0817644 loss)
I0615 10:31:32.270262 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0990582 (* 1 = 0.0990582 loss)
I0615 10:31:32.270267 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382189 (* 1 = 0.00382189 loss)
I0615 10:31:32.270272 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278846 (* 1 = 0.0278846 loss)
I0615 10:31:32.270290 15760 sgd_solver.cpp:106] Iteration 25000, lr = 0.0002
I0615 10:33:18.508371 15760 solver.cpp:228] Iteration 25020, loss = 0.231909
I0615 10:33:18.508395 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 10:33:18.508404 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748911 (* 1 = 0.0748911 loss)
I0615 10:33:18.508407 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.071599 (* 1 = 0.071599 loss)
I0615 10:33:18.508411 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00916512 (* 1 = 0.00916512 loss)
I0615 10:33:18.508414 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231722 (* 1 = 0.0231722 loss)
I0615 10:33:18.508419 15760 sgd_solver.cpp:106] Iteration 25020, lr = 0.0002
I0615 10:35:04.871531 15760 solver.cpp:228] Iteration 25040, loss = 0.270429
I0615 10:35:04.871554 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 10:35:04.871562 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.156558 (* 1 = 0.156558 loss)
I0615 10:35:04.871567 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.232464 (* 1 = 0.232464 loss)
I0615 10:35:04.871570 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023531 (* 1 = 0.023531 loss)
I0615 10:35:04.871574 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0946248 (* 1 = 0.0946248 loss)
I0615 10:35:04.871579 15760 sgd_solver.cpp:106] Iteration 25040, lr = 0.0002
I0615 10:36:51.174221 15760 solver.cpp:228] Iteration 25060, loss = 0.403122
I0615 10:36:51.174245 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 10:36:51.174254 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194912 (* 1 = 0.194912 loss)
I0615 10:36:51.174260 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.213116 (* 1 = 0.213116 loss)
I0615 10:36:51.174265 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00299932 (* 1 = 0.00299932 loss)
I0615 10:36:51.174271 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0552237 (* 1 = 0.0552237 loss)
I0615 10:36:51.174278 15760 sgd_solver.cpp:106] Iteration 25060, lr = 0.0002
I0615 10:38:37.355510 15760 solver.cpp:228] Iteration 25080, loss = 0.337506
I0615 10:38:37.355535 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 10:38:37.355545 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.050303 (* 1 = 0.050303 loss)
I0615 10:38:37.355551 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0931745 (* 1 = 0.0931745 loss)
I0615 10:38:37.355556 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000735962 (* 1 = 0.000735962 loss)
I0615 10:38:37.355561 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106298 (* 1 = 0.0106298 loss)
I0615 10:38:37.355567 15760 sgd_solver.cpp:106] Iteration 25080, lr = 0.0002
I0615 10:40:23.825366 15760 solver.cpp:228] Iteration 25100, loss = 0.248259
I0615 10:40:23.825392 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 10:40:23.825400 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719398 (* 1 = 0.0719398 loss)
I0615 10:40:23.825404 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.14343 (* 1 = 0.14343 loss)
I0615 10:40:23.825408 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000148873 (* 1 = 0.000148873 loss)
I0615 10:40:23.825412 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127717 (* 1 = 0.0127717 loss)
I0615 10:40:23.825417 15760 sgd_solver.cpp:106] Iteration 25100, lr = 0.0002
I0615 10:42:10.148066 15760 solver.cpp:228] Iteration 25120, loss = 0.512807
I0615 10:42:10.148090 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 10:42:10.148098 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912269 (* 1 = 0.0912269 loss)
I0615 10:42:10.148103 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.121737 (* 1 = 0.121737 loss)
I0615 10:42:10.148108 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00145251 (* 1 = 0.00145251 loss)
I0615 10:42:10.148111 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00846507 (* 1 = 0.00846507 loss)
I0615 10:42:10.148116 15760 sgd_solver.cpp:106] Iteration 25120, lr = 0.0002
I0615 10:43:56.612711 15760 solver.cpp:228] Iteration 25140, loss = 0.481509
I0615 10:43:56.612735 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 10:43:56.612741 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433582 (* 1 = 0.0433582 loss)
I0615 10:43:56.612746 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0901618 (* 1 = 0.0901618 loss)
I0615 10:43:56.612748 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00930185 (* 1 = 0.00930185 loss)
I0615 10:43:56.612752 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198463 (* 1 = 0.0198463 loss)
I0615 10:43:56.612757 15760 sgd_solver.cpp:106] Iteration 25140, lr = 0.0002
I0615 10:45:43.252115 15760 solver.cpp:228] Iteration 25160, loss = 0.391162
I0615 10:45:43.252140 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 10:45:43.252147 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.247684 (* 1 = 0.247684 loss)
I0615 10:45:43.252151 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.23652 (* 1 = 0.23652 loss)
I0615 10:45:43.252154 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110612 (* 1 = 0.00110612 loss)
I0615 10:45:43.252158 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491526 (* 1 = 0.0491526 loss)
I0615 10:45:43.252162 15760 sgd_solver.cpp:106] Iteration 25160, lr = 0.0002
I0615 10:47:29.617956 15760 solver.cpp:228] Iteration 25180, loss = 0.452032
I0615 10:47:29.617980 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0615 10:47:29.617986 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.315448 (* 1 = 0.315448 loss)
I0615 10:47:29.617990 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.438673 (* 1 = 0.438673 loss)
I0615 10:47:29.617995 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0014833 (* 1 = 0.0014833 loss)
I0615 10:47:29.617998 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226444 (* 1 = 0.0226444 loss)
I0615 10:47:29.618002 15760 sgd_solver.cpp:106] Iteration 25180, lr = 0.0002
speed: 5.330s / iter
I0615 10:49:15.953266 15760 solver.cpp:228] Iteration 25200, loss = 0.557094
I0615 10:49:15.953290 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 10:49:15.953297 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.322678 (* 1 = 0.322678 loss)
I0615 10:49:15.953302 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.270694 (* 1 = 0.270694 loss)
I0615 10:49:15.953306 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000830066 (* 1 = 0.000830066 loss)
I0615 10:49:15.953310 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0579055 (* 1 = 0.0579055 loss)
I0615 10:49:15.953315 15760 sgd_solver.cpp:106] Iteration 25200, lr = 0.0002
I0615 10:51:02.352144 15760 solver.cpp:228] Iteration 25220, loss = 0.392302
I0615 10:51:02.352169 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 10:51:02.352177 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.190164 (* 1 = 0.190164 loss)
I0615 10:51:02.352181 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.237957 (* 1 = 0.237957 loss)
I0615 10:51:02.352185 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0222154 (* 1 = 0.0222154 loss)
I0615 10:51:02.352190 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0816614 (* 1 = 0.0816614 loss)
I0615 10:51:02.352195 15760 sgd_solver.cpp:106] Iteration 25220, lr = 0.0002
I0615 10:52:48.938164 15760 solver.cpp:228] Iteration 25240, loss = 0.31331
I0615 10:52:48.938187 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 10:52:48.938194 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.536959 (* 1 = 0.536959 loss)
I0615 10:52:48.938199 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.356685 (* 1 = 0.356685 loss)
I0615 10:52:48.938201 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102078 (* 1 = 0.0102078 loss)
I0615 10:52:48.938205 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12498 (* 1 = 0.12498 loss)
I0615 10:52:48.938210 15760 sgd_solver.cpp:106] Iteration 25240, lr = 0.0002
I0615 10:54:35.384327 15760 solver.cpp:228] Iteration 25260, loss = 0.412997
I0615 10:54:35.384353 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 10:54:35.384361 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0620368 (* 1 = 0.0620368 loss)
I0615 10:54:35.384366 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0367067 (* 1 = 0.0367067 loss)
I0615 10:54:35.384369 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132497 (* 1 = 0.00132497 loss)
I0615 10:54:35.384373 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192583 (* 1 = 0.0192583 loss)
I0615 10:54:35.384379 15760 sgd_solver.cpp:106] Iteration 25260, lr = 0.0002
I0615 10:56:21.655781 15760 solver.cpp:228] Iteration 25280, loss = 0.446994
I0615 10:56:21.655805 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 10:56:21.655812 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707567 (* 1 = 0.0707567 loss)
I0615 10:56:21.655817 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.10748 (* 1 = 0.10748 loss)
I0615 10:56:21.655822 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204273 (* 1 = 0.00204273 loss)
I0615 10:56:21.655825 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00860806 (* 1 = 0.00860806 loss)
I0615 10:56:21.655829 15760 sgd_solver.cpp:106] Iteration 25280, lr = 0.0002
I0615 10:58:07.985945 15760 solver.cpp:228] Iteration 25300, loss = 0.669086
I0615 10:58:07.985970 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 10:58:07.985976 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.148312 (* 1 = 0.148312 loss)
I0615 10:58:07.985980 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0937285 (* 1 = 0.0937285 loss)
I0615 10:58:07.985985 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000116641 (* 1 = 0.000116641 loss)
I0615 10:58:07.985987 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175804 (* 1 = 0.0175804 loss)
I0615 10:58:07.985992 15760 sgd_solver.cpp:106] Iteration 25300, lr = 0.0002
I0615 10:59:54.688424 15760 solver.cpp:228] Iteration 25320, loss = 0.543629
I0615 10:59:54.688450 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 10:59:54.688457 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.415853 (* 1 = 0.415853 loss)
I0615 10:59:54.688462 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.293168 (* 1 = 0.293168 loss)
I0615 10:59:54.688465 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00720482 (* 1 = 0.00720482 loss)
I0615 10:59:54.688469 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0831179 (* 1 = 0.0831179 loss)
I0615 10:59:54.688474 15760 sgd_solver.cpp:106] Iteration 25320, lr = 0.0002
I0615 11:01:41.346182 15760 solver.cpp:228] Iteration 25340, loss = 0.195503
I0615 11:01:41.346401 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 11:01:41.346453 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498856 (* 1 = 0.0498856 loss)
I0615 11:01:41.346474 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.04857 (* 1 = 0.04857 loss)
I0615 11:01:41.346490 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000259791 (* 1 = 0.000259791 loss)
I0615 11:01:41.346503 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00803545 (* 1 = 0.00803545 loss)
I0615 11:01:41.346525 15760 sgd_solver.cpp:106] Iteration 25340, lr = 0.0002
I0615 11:03:27.621816 15760 solver.cpp:228] Iteration 25360, loss = 0.729282
I0615 11:03:27.621840 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 11:03:27.621848 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.10096 (* 1 = 0.10096 loss)
I0615 11:03:27.621852 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.255562 (* 1 = 0.255562 loss)
I0615 11:03:27.621857 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236439 (* 1 = 0.00236439 loss)
I0615 11:03:27.621860 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0635503 (* 1 = 0.0635503 loss)
I0615 11:03:27.621865 15760 sgd_solver.cpp:106] Iteration 25360, lr = 0.0002
I0615 11:05:14.111264 15760 solver.cpp:228] Iteration 25380, loss = 0.776371
I0615 11:05:14.111289 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 11:05:14.111295 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0696556 (* 1 = 0.0696556 loss)
I0615 11:05:14.111299 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0898491 (* 1 = 0.0898491 loss)
I0615 11:05:14.111304 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000128169 (* 1 = 0.000128169 loss)
I0615 11:05:14.111306 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035079 (* 1 = 0.035079 loss)
I0615 11:05:14.111311 15760 sgd_solver.cpp:106] Iteration 25380, lr = 0.0002
speed: 5.330s / iter
I0615 11:07:00.592998 15760 solver.cpp:228] Iteration 25400, loss = 0.473463
I0615 11:07:00.593024 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 11:07:00.593031 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0769819 (* 1 = 0.0769819 loss)
I0615 11:07:00.593035 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0761472 (* 1 = 0.0761472 loss)
I0615 11:07:00.593039 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00489112 (* 1 = 0.00489112 loss)
I0615 11:07:00.593044 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00707284 (* 1 = 0.00707284 loss)
I0615 11:07:00.593049 15760 sgd_solver.cpp:106] Iteration 25400, lr = 0.0002
I0615 11:08:47.065218 15760 solver.cpp:228] Iteration 25420, loss = 0.589584
I0615 11:08:47.065244 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0615 11:08:47.065253 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.602666 (* 1 = 0.602666 loss)
I0615 11:08:47.065256 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.399247 (* 1 = 0.399247 loss)
I0615 11:08:47.065260 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265035 (* 1 = 0.00265035 loss)
I0615 11:08:47.065264 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0834921 (* 1 = 0.0834921 loss)
I0615 11:08:47.065270 15760 sgd_solver.cpp:106] Iteration 25420, lr = 0.0002
I0615 11:10:33.700835 15760 solver.cpp:228] Iteration 25440, loss = 0.326068
I0615 11:10:33.700860 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 11:10:33.700868 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.19246 (* 1 = 0.19246 loss)
I0615 11:10:33.700872 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.114888 (* 1 = 0.114888 loss)
I0615 11:10:33.700877 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000492911 (* 1 = 0.000492911 loss)
I0615 11:10:33.700881 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172147 (* 1 = 0.0172147 loss)
I0615 11:10:33.700886 15760 sgd_solver.cpp:106] Iteration 25440, lr = 0.0002
I0615 11:12:20.599102 15760 solver.cpp:228] Iteration 25460, loss = 0.35785
I0615 11:12:20.599129 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 11:12:20.599136 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11015 (* 1 = 0.11015 loss)
I0615 11:12:20.599140 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.103243 (* 1 = 0.103243 loss)
I0615 11:12:20.599145 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000335363 (* 1 = 0.000335363 loss)
I0615 11:12:20.599149 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00961421 (* 1 = 0.00961421 loss)
I0615 11:12:20.599154 15760 sgd_solver.cpp:106] Iteration 25460, lr = 0.0002
I0615 11:14:07.087764 15760 solver.cpp:228] Iteration 25480, loss = 0.505062
I0615 11:14:07.087791 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 11:14:07.087798 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.178123 (* 1 = 0.178123 loss)
I0615 11:14:07.087802 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.170656 (* 1 = 0.170656 loss)
I0615 11:14:07.087805 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000508858 (* 1 = 0.000508858 loss)
I0615 11:14:07.087810 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0396933 (* 1 = 0.0396933 loss)
I0615 11:14:07.087815 15760 sgd_solver.cpp:106] Iteration 25480, lr = 0.0002
I0615 11:15:53.638695 15760 solver.cpp:228] Iteration 25500, loss = 0.328797
I0615 11:15:53.638721 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 11:15:53.638730 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.300998 (* 1 = 0.300998 loss)
I0615 11:15:53.638733 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.193576 (* 1 = 0.193576 loss)
I0615 11:15:53.638737 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000521059 (* 1 = 0.000521059 loss)
I0615 11:15:53.638741 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246171 (* 1 = 0.0246171 loss)
I0615 11:15:53.638746 15760 sgd_solver.cpp:106] Iteration 25500, lr = 0.0002
I0615 11:17:40.042284 15760 solver.cpp:228] Iteration 25520, loss = 0.443093
I0615 11:17:40.042307 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 11:17:40.042315 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111285 (* 1 = 0.111285 loss)
I0615 11:17:40.042320 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.215187 (* 1 = 0.215187 loss)
I0615 11:17:40.042322 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00196906 (* 1 = 0.00196906 loss)
I0615 11:17:40.042325 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.184866 (* 1 = 0.184866 loss)
I0615 11:17:40.042331 15760 sgd_solver.cpp:106] Iteration 25520, lr = 0.0002
I0615 11:19:26.597508 15760 solver.cpp:228] Iteration 25540, loss = 0.251799
I0615 11:19:26.597533 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 11:19:26.597542 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.223473 (* 1 = 0.223473 loss)
I0615 11:19:26.597546 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.277981 (* 1 = 0.277981 loss)
I0615 11:19:26.597550 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0372913 (* 1 = 0.0372913 loss)
I0615 11:19:26.597554 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0392575 (* 1 = 0.0392575 loss)
I0615 11:19:26.597558 15760 sgd_solver.cpp:106] Iteration 25540, lr = 0.0002
I0615 11:21:13.074090 15760 solver.cpp:228] Iteration 25560, loss = 0.549751
I0615 11:21:13.074115 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0615 11:21:13.074123 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.691508 (* 1 = 0.691508 loss)
I0615 11:21:13.074128 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.615106 (* 1 = 0.615106 loss)
I0615 11:21:13.074133 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111848 (* 1 = 0.0111848 loss)
I0615 11:21:13.074139 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.299622 (* 1 = 0.299622 loss)
I0615 11:21:13.074146 15760 sgd_solver.cpp:106] Iteration 25560, lr = 0.0002
I0615 11:22:59.227067 15760 solver.cpp:228] Iteration 25580, loss = 0.44641
I0615 11:22:59.227093 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 11:22:59.227102 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391629 (* 1 = 0.0391629 loss)
I0615 11:22:59.227104 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0754029 (* 1 = 0.0754029 loss)
I0615 11:22:59.227108 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149303 (* 1 = 0.00149303 loss)
I0615 11:22:59.227111 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161571 (* 1 = 0.0161571 loss)
I0615 11:22:59.227116 15760 sgd_solver.cpp:106] Iteration 25580, lr = 0.0002
speed: 5.330s / iter
I0615 11:24:45.852737 15760 solver.cpp:228] Iteration 25600, loss = 0.461056
I0615 11:24:45.852761 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 11:24:45.852769 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.199255 (* 1 = 0.199255 loss)
I0615 11:24:45.852774 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.157323 (* 1 = 0.157323 loss)
I0615 11:24:45.852778 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00224155 (* 1 = 0.00224155 loss)
I0615 11:24:45.852782 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0474401 (* 1 = 0.0474401 loss)
I0615 11:24:45.852787 15760 sgd_solver.cpp:106] Iteration 25600, lr = 0.0002
I0615 11:26:32.168840 15760 solver.cpp:228] Iteration 25620, loss = 0.372847
I0615 11:26:32.168867 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 11:26:32.168876 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.382924 (* 1 = 0.382924 loss)
I0615 11:26:32.168882 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.306185 (* 1 = 0.306185 loss)
I0615 11:26:32.168889 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026091 (* 1 = 0.026091 loss)
I0615 11:26:32.168896 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10848 (* 1 = 0.10848 loss)
I0615 11:26:32.168903 15760 sgd_solver.cpp:106] Iteration 25620, lr = 0.0002
I0615 11:28:18.454149 15760 solver.cpp:228] Iteration 25640, loss = 0.429392
I0615 11:28:18.454172 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 11:28:18.454180 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109554 (* 1 = 0.109554 loss)
I0615 11:28:18.454183 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.150568 (* 1 = 0.150568 loss)
I0615 11:28:18.454187 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000592472 (* 1 = 0.000592472 loss)
I0615 11:28:18.454190 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190118 (* 1 = 0.0190118 loss)
I0615 11:28:18.454195 15760 sgd_solver.cpp:106] Iteration 25640, lr = 0.0002
I0615 11:30:04.705793 15760 solver.cpp:228] Iteration 25660, loss = 0.282173
I0615 11:30:04.705819 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 11:30:04.705828 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.197529 (* 1 = 0.197529 loss)
I0615 11:30:04.705835 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.223432 (* 1 = 0.223432 loss)
I0615 11:30:04.705842 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082488 (* 1 = 0.0082488 loss)
I0615 11:30:04.705847 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402162 (* 1 = 0.0402162 loss)
I0615 11:30:04.705855 15760 sgd_solver.cpp:106] Iteration 25660, lr = 0.0002
I0615 11:31:51.165436 15760 solver.cpp:228] Iteration 25680, loss = 0.314671
I0615 11:31:51.165462 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 11:31:51.165469 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.258063 (* 1 = 0.258063 loss)
I0615 11:31:51.165473 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.203805 (* 1 = 0.203805 loss)
I0615 11:31:51.165477 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00447263 (* 1 = 0.00447263 loss)
I0615 11:31:51.165482 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364168 (* 1 = 0.0364168 loss)
I0615 11:31:51.165486 15760 sgd_solver.cpp:106] Iteration 25680, lr = 0.0002
I0615 11:33:37.355293 15760 solver.cpp:228] Iteration 25700, loss = 0.300162
I0615 11:33:37.355317 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 11:33:37.355324 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0954422 (* 1 = 0.0954422 loss)
I0615 11:33:37.355329 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0669711 (* 1 = 0.0669711 loss)
I0615 11:33:37.355332 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.56726e-05 (* 1 = 5.56726e-05 loss)
I0615 11:33:37.355335 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108025 (* 1 = 0.0108025 loss)
I0615 11:33:37.355341 15760 sgd_solver.cpp:106] Iteration 25700, lr = 0.0002
I0615 11:35:23.698702 15760 solver.cpp:228] Iteration 25720, loss = 0.228478
I0615 11:35:23.698725 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 11:35:23.698731 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.114352 (* 1 = 0.114352 loss)
I0615 11:35:23.698735 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0739789 (* 1 = 0.0739789 loss)
I0615 11:35:23.698740 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294768 (* 1 = 0.00294768 loss)
I0615 11:35:23.698743 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194637 (* 1 = 0.0194637 loss)
I0615 11:35:23.698748 15760 sgd_solver.cpp:106] Iteration 25720, lr = 0.0002
I0615 11:37:09.991298 15760 solver.cpp:228] Iteration 25740, loss = 0.555511
I0615 11:37:09.991323 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 11:37:09.991331 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0744591 (* 1 = 0.0744591 loss)
I0615 11:37:09.991335 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.10948 (* 1 = 0.10948 loss)
I0615 11:37:09.991339 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000116642 (* 1 = 0.000116642 loss)
I0615 11:37:09.991343 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00632023 (* 1 = 0.00632023 loss)
I0615 11:37:09.991348 15760 sgd_solver.cpp:106] Iteration 25740, lr = 0.0002
I0615 11:38:56.387919 15760 solver.cpp:228] Iteration 25760, loss = 0.425934
I0615 11:38:56.387944 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 11:38:56.387951 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.344669 (* 1 = 0.344669 loss)
I0615 11:38:56.387956 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.1909 (* 1 = 0.1909 loss)
I0615 11:38:56.387960 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385858 (* 1 = 0.00385858 loss)
I0615 11:38:56.387964 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.110813 (* 1 = 0.110813 loss)
I0615 11:38:56.387969 15760 sgd_solver.cpp:106] Iteration 25760, lr = 0.0002
I0615 11:40:42.759479 15760 solver.cpp:228] Iteration 25780, loss = 0.346053
I0615 11:40:42.759502 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 11:40:42.759510 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.166504 (* 1 = 0.166504 loss)
I0615 11:40:42.759513 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.182889 (* 1 = 0.182889 loss)
I0615 11:40:42.759517 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000536331 (* 1 = 0.000536331 loss)
I0615 11:40:42.759521 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199644 (* 1 = 0.0199644 loss)
I0615 11:40:42.759526 15760 sgd_solver.cpp:106] Iteration 25780, lr = 0.0002
speed: 5.330s / iter
I0615 11:42:29.300060 15760 solver.cpp:228] Iteration 25800, loss = 0.361141
I0615 11:42:29.300084 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 11:42:29.300091 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.127321 (* 1 = 0.127321 loss)
I0615 11:42:29.300094 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.175581 (* 1 = 0.175581 loss)
I0615 11:42:29.300098 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306767 (* 1 = 0.0306767 loss)
I0615 11:42:29.300102 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100955 (* 1 = 0.100955 loss)
I0615 11:42:29.300107 15760 sgd_solver.cpp:106] Iteration 25800, lr = 0.0002
I0615 11:44:16.116375 15760 solver.cpp:228] Iteration 25820, loss = 0.409235
I0615 11:44:16.116399 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 11:44:16.116406 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614894 (* 1 = 0.0614894 loss)
I0615 11:44:16.116410 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.103222 (* 1 = 0.103222 loss)
I0615 11:44:16.116415 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00683264 (* 1 = 0.00683264 loss)
I0615 11:44:16.116418 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128638 (* 1 = 0.0128638 loss)
I0615 11:44:16.116423 15760 sgd_solver.cpp:106] Iteration 25820, lr = 0.0002
I0615 11:46:03.281457 15760 solver.cpp:228] Iteration 25840, loss = 0.516233
I0615 11:46:03.281488 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 11:46:03.281497 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.228403 (* 1 = 0.228403 loss)
I0615 11:46:03.281503 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.28716 (* 1 = 0.28716 loss)
I0615 11:46:03.281509 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000971402 (* 1 = 0.000971402 loss)
I0615 11:46:03.281514 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167334 (* 1 = 0.0167334 loss)
I0615 11:46:03.281520 15760 sgd_solver.cpp:106] Iteration 25840, lr = 0.0002
I0615 11:47:49.794153 15760 solver.cpp:228] Iteration 25860, loss = 0.352129
I0615 11:47:49.794178 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 11:47:49.794185 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11949 (* 1 = 0.11949 loss)
I0615 11:47:49.794188 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.123411 (* 1 = 0.123411 loss)
I0615 11:47:49.794193 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000306043 (* 1 = 0.000306043 loss)
I0615 11:47:49.794195 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109089 (* 1 = 0.0109089 loss)
I0615 11:47:49.794200 15760 sgd_solver.cpp:106] Iteration 25860, lr = 0.0002
I0615 11:49:36.534631 15760 solver.cpp:228] Iteration 25880, loss = 0.481083
I0615 11:49:36.534657 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 11:49:36.534665 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.240936 (* 1 = 0.240936 loss)
I0615 11:49:36.534669 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206245 (* 1 = 0.206245 loss)
I0615 11:49:36.534673 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186629 (* 1 = 0.00186629 loss)
I0615 11:49:36.534677 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388434 (* 1 = 0.0388434 loss)
I0615 11:49:36.534682 15760 sgd_solver.cpp:106] Iteration 25880, lr = 0.0002
I0615 11:51:23.097198 15760 solver.cpp:228] Iteration 25900, loss = 0.529226
I0615 11:51:23.097229 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0615 11:51:23.097239 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.703211 (* 1 = 0.703211 loss)
I0615 11:51:23.097244 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.742855 (* 1 = 0.742855 loss)
I0615 11:51:23.097249 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261724 (* 1 = 0.0261724 loss)
I0615 11:51:23.097254 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.397497 (* 1 = 0.397497 loss)
I0615 11:51:23.097260 15760 sgd_solver.cpp:106] Iteration 25900, lr = 0.0002
I0615 11:53:09.671504 15760 solver.cpp:228] Iteration 25920, loss = 0.296536
I0615 11:53:09.671528 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 11:53:09.671535 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.283972 (* 1 = 0.283972 loss)
I0615 11:53:09.671538 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.180206 (* 1 = 0.180206 loss)
I0615 11:53:09.671542 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00481546 (* 1 = 0.00481546 loss)
I0615 11:53:09.671546 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0706148 (* 1 = 0.0706148 loss)
I0615 11:53:09.671550 15760 sgd_solver.cpp:106] Iteration 25920, lr = 0.0002
I0615 11:54:55.876453 15760 solver.cpp:228] Iteration 25940, loss = 0.548558
I0615 11:54:55.876476 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 11:54:55.876482 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.533517 (* 1 = 0.533517 loss)
I0615 11:54:55.876487 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.343095 (* 1 = 0.343095 loss)
I0615 11:54:55.876490 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00893647 (* 1 = 0.00893647 loss)
I0615 11:54:55.876493 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.158831 (* 1 = 0.158831 loss)
I0615 11:54:55.876497 15760 sgd_solver.cpp:106] Iteration 25940, lr = 0.0002
I0615 11:56:42.301923 15760 solver.cpp:228] Iteration 25960, loss = 0.428278
I0615 11:56:42.301949 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 11:56:42.301956 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.130368 (* 1 = 0.130368 loss)
I0615 11:56:42.301964 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0985699 (* 1 = 0.0985699 loss)
I0615 11:56:42.301970 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147188 (* 1 = 0.00147188 loss)
I0615 11:56:42.301975 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00855742 (* 1 = 0.00855742 loss)
I0615 11:56:42.301980 15760 sgd_solver.cpp:106] Iteration 25960, lr = 0.0002
I0615 11:58:28.538573 15760 solver.cpp:228] Iteration 25980, loss = 0.222244
I0615 11:58:28.538599 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 11:58:28.538606 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.153077 (* 1 = 0.153077 loss)
I0615 11:58:28.538611 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0993922 (* 1 = 0.0993922 loss)
I0615 11:58:28.538615 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000828447 (* 1 = 0.000828447 loss)
I0615 11:58:28.538619 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0287044 (* 1 = 0.0287044 loss)
I0615 11:58:28.538624 15760 sgd_solver.cpp:106] Iteration 25980, lr = 0.0002
speed: 5.330s / iter
I0615 12:00:15.160830 15760 solver.cpp:228] Iteration 26000, loss = 0.411842
I0615 12:00:15.160853 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 12:00:15.160861 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0569562 (* 1 = 0.0569562 loss)
I0615 12:00:15.160866 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0281389 (* 1 = 0.0281389 loss)
I0615 12:00:15.160869 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00566101 (* 1 = 0.00566101 loss)
I0615 12:00:15.160873 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00311633 (* 1 = 0.00311633 loss)
I0615 12:00:15.160878 15760 sgd_solver.cpp:106] Iteration 26000, lr = 0.0002
I0615 12:02:01.320626 15760 solver.cpp:228] Iteration 26020, loss = 0.358974
I0615 12:02:01.320652 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 12:02:01.320659 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.128539 (* 1 = 0.128539 loss)
I0615 12:02:01.320663 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.150132 (* 1 = 0.150132 loss)
I0615 12:02:01.320668 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00434684 (* 1 = 0.00434684 loss)
I0615 12:02:01.320672 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0273494 (* 1 = 0.0273494 loss)
I0615 12:02:01.320677 15760 sgd_solver.cpp:106] Iteration 26020, lr = 0.0002
I0615 12:03:47.807556 15760 solver.cpp:228] Iteration 26040, loss = 0.215302
I0615 12:03:47.807581 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 12:03:47.807588 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146841 (* 1 = 0.146841 loss)
I0615 12:03:47.807592 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171485 (* 1 = 0.171485 loss)
I0615 12:03:47.807595 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147425 (* 1 = 0.00147425 loss)
I0615 12:03:47.807600 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0548418 (* 1 = 0.0548418 loss)
I0615 12:03:47.807605 15760 sgd_solver.cpp:106] Iteration 26040, lr = 0.0002
I0615 12:05:34.282248 15760 solver.cpp:228] Iteration 26060, loss = 0.401327
I0615 12:05:34.282274 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 12:05:34.282280 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.185283 (* 1 = 0.185283 loss)
I0615 12:05:34.282284 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206815 (* 1 = 0.206815 loss)
I0615 12:05:34.282287 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359654 (* 1 = 0.00359654 loss)
I0615 12:05:34.282290 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185225 (* 1 = 0.0185225 loss)
I0615 12:05:34.282295 15760 sgd_solver.cpp:106] Iteration 26060, lr = 0.0002
I0615 12:07:20.758239 15760 solver.cpp:228] Iteration 26080, loss = 0.371391
I0615 12:07:20.758263 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 12:07:20.758271 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.252178 (* 1 = 0.252178 loss)
I0615 12:07:20.758277 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.219556 (* 1 = 0.219556 loss)
I0615 12:07:20.758285 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00346209 (* 1 = 0.00346209 loss)
I0615 12:07:20.758289 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681646 (* 1 = 0.0681646 loss)
I0615 12:07:20.758294 15760 sgd_solver.cpp:106] Iteration 26080, lr = 0.0002
I0615 12:09:07.339022 15760 solver.cpp:228] Iteration 26100, loss = 0.497966
I0615 12:09:07.339046 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 12:09:07.339054 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.347109 (* 1 = 0.347109 loss)
I0615 12:09:07.339057 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.224623 (* 1 = 0.224623 loss)
I0615 12:09:07.339061 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135237 (* 1 = 0.00135237 loss)
I0615 12:09:07.339066 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0625972 (* 1 = 0.0625972 loss)
I0615 12:09:07.339069 15760 sgd_solver.cpp:106] Iteration 26100, lr = 0.0002
I0615 12:10:53.889628 15760 solver.cpp:228] Iteration 26120, loss = 0.367925
I0615 12:10:53.889653 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 12:10:53.889662 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0731933 (* 1 = 0.0731933 loss)
I0615 12:10:53.889667 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0683985 (* 1 = 0.0683985 loss)
I0615 12:10:53.889669 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000428177 (* 1 = 0.000428177 loss)
I0615 12:10:53.889673 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332063 (* 1 = 0.0332063 loss)
I0615 12:10:53.889678 15760 sgd_solver.cpp:106] Iteration 26120, lr = 0.0002
I0615 12:12:40.302287 15760 solver.cpp:228] Iteration 26140, loss = 0.414562
I0615 12:12:40.302310 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 12:12:40.302319 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399231 (* 1 = 0.0399231 loss)
I0615 12:12:40.302322 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0437589 (* 1 = 0.0437589 loss)
I0615 12:12:40.302325 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000792275 (* 1 = 0.000792275 loss)
I0615 12:12:40.302328 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134071 (* 1 = 0.0134071 loss)
I0615 12:12:40.302333 15760 sgd_solver.cpp:106] Iteration 26140, lr = 0.0002
I0615 12:14:26.653430 15760 solver.cpp:228] Iteration 26160, loss = 0.369308
I0615 12:14:26.653455 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 12:14:26.653461 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0774673 (* 1 = 0.0774673 loss)
I0615 12:14:26.653465 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.141103 (* 1 = 0.141103 loss)
I0615 12:14:26.653470 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120988 (* 1 = 0.00120988 loss)
I0615 12:14:26.653472 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0406177 (* 1 = 0.0406177 loss)
I0615 12:14:26.653477 15760 sgd_solver.cpp:106] Iteration 26160, lr = 0.0002
I0615 12:16:13.051093 15760 solver.cpp:228] Iteration 26180, loss = 0.574099
I0615 12:16:13.051120 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 12:16:13.051126 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.221992 (* 1 = 0.221992 loss)
I0615 12:16:13.051131 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.17561 (* 1 = 0.17561 loss)
I0615 12:16:13.051136 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00036246 (* 1 = 0.00036246 loss)
I0615 12:16:13.051139 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0480711 (* 1 = 0.0480711 loss)
I0615 12:16:13.051143 15760 sgd_solver.cpp:106] Iteration 26180, lr = 0.0002
speed: 5.330s / iter
I0615 12:17:59.173581 15760 solver.cpp:228] Iteration 26200, loss = 0.290146
I0615 12:17:59.173610 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 12:17:59.173619 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.100968 (* 1 = 0.100968 loss)
I0615 12:17:59.173622 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0921152 (* 1 = 0.0921152 loss)
I0615 12:17:59.173625 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00343517 (* 1 = 0.00343517 loss)
I0615 12:17:59.173629 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149554 (* 1 = 0.0149554 loss)
I0615 12:17:59.173635 15760 sgd_solver.cpp:106] Iteration 26200, lr = 0.0002
I0615 12:19:45.615932 15760 solver.cpp:228] Iteration 26220, loss = 0.55598
I0615 12:19:45.615957 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 12:19:45.615963 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.296019 (* 1 = 0.296019 loss)
I0615 12:19:45.615967 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.298232 (* 1 = 0.298232 loss)
I0615 12:19:45.615972 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257162 (* 1 = 0.00257162 loss)
I0615 12:19:45.615974 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.054881 (* 1 = 0.054881 loss)
I0615 12:19:45.615979 15760 sgd_solver.cpp:106] Iteration 26220, lr = 0.0002
I0615 12:21:31.876119 15760 solver.cpp:228] Iteration 26240, loss = 0.29088
I0615 12:21:31.876143 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 12:21:31.876150 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.1432 (* 1 = 0.1432 loss)
I0615 12:21:31.876155 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.219005 (* 1 = 0.219005 loss)
I0615 12:21:31.876159 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00997603 (* 1 = 0.00997603 loss)
I0615 12:21:31.876163 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.252971 (* 1 = 0.252971 loss)
I0615 12:21:31.876168 15760 sgd_solver.cpp:106] Iteration 26240, lr = 0.0002
I0615 12:23:18.165606 15760 solver.cpp:228] Iteration 26260, loss = 0.356205
I0615 12:23:18.165632 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 12:23:18.165639 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0771335 (* 1 = 0.0771335 loss)
I0615 12:23:18.165643 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.108768 (* 1 = 0.108768 loss)
I0615 12:23:18.165647 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155676 (* 1 = 0.00155676 loss)
I0615 12:23:18.165652 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100642 (* 1 = 0.0100642 loss)
I0615 12:23:18.165657 15760 sgd_solver.cpp:106] Iteration 26260, lr = 0.0002
I0615 12:25:04.484246 15760 solver.cpp:228] Iteration 26280, loss = 0.499307
I0615 12:25:04.484269 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0615 12:25:04.484275 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.591362 (* 1 = 0.591362 loss)
I0615 12:25:04.484279 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.582999 (* 1 = 0.582999 loss)
I0615 12:25:04.484283 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.082057 (* 1 = 0.082057 loss)
I0615 12:25:04.484287 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.406297 (* 1 = 0.406297 loss)
I0615 12:25:04.484290 15760 sgd_solver.cpp:106] Iteration 26280, lr = 0.0002
I0615 12:26:50.925595 15760 solver.cpp:228] Iteration 26300, loss = 0.272858
I0615 12:26:50.925616 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 12:26:50.925623 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146682 (* 1 = 0.146682 loss)
I0615 12:26:50.925627 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112854 (* 1 = 0.112854 loss)
I0615 12:26:50.925631 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296257 (* 1 = 0.00296257 loss)
I0615 12:26:50.925634 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221914 (* 1 = 0.0221914 loss)
I0615 12:26:50.925639 15760 sgd_solver.cpp:106] Iteration 26300, lr = 0.0002
I0615 12:28:37.891984 15760 solver.cpp:228] Iteration 26320, loss = 0.497218
I0615 12:28:37.892010 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 12:28:37.892019 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.130062 (* 1 = 0.130062 loss)
I0615 12:28:37.892024 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.174225 (* 1 = 0.174225 loss)
I0615 12:28:37.892026 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143804 (* 1 = 0.0143804 loss)
I0615 12:28:37.892030 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112366 (* 1 = 0.112366 loss)
I0615 12:28:37.892035 15760 sgd_solver.cpp:106] Iteration 26320, lr = 0.0002
I0615 12:30:24.406543 15760 solver.cpp:228] Iteration 26340, loss = 0.454493
I0615 12:30:24.406570 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 12:30:24.406577 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.250261 (* 1 = 0.250261 loss)
I0615 12:30:24.406581 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.230835 (* 1 = 0.230835 loss)
I0615 12:30:24.406586 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155005 (* 1 = 0.00155005 loss)
I0615 12:30:24.406590 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333257 (* 1 = 0.0333257 loss)
I0615 12:30:24.406594 15760 sgd_solver.cpp:106] Iteration 26340, lr = 0.0002
I0615 12:32:10.940240 15760 solver.cpp:228] Iteration 26360, loss = 0.336481
I0615 12:32:10.940270 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 12:32:10.940280 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0997109 (* 1 = 0.0997109 loss)
I0615 12:32:10.940286 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0489071 (* 1 = 0.0489071 loss)
I0615 12:32:10.940292 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000570442 (* 1 = 0.000570442 loss)
I0615 12:32:10.940299 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170332 (* 1 = 0.0170332 loss)
I0615 12:32:10.940306 15760 sgd_solver.cpp:106] Iteration 26360, lr = 0.0002
I0615 12:33:57.758774 15760 solver.cpp:228] Iteration 26380, loss = 0.494562
I0615 12:33:57.758797 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 12:33:57.758805 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0783197 (* 1 = 0.0783197 loss)
I0615 12:33:57.758808 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.093224 (* 1 = 0.093224 loss)
I0615 12:33:57.758812 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.7035e-05 (* 1 = 5.7035e-05 loss)
I0615 12:33:57.758816 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00363735 (* 1 = 0.00363735 loss)
I0615 12:33:57.758821 15760 sgd_solver.cpp:106] Iteration 26380, lr = 0.0002
speed: 5.330s / iter
I0615 12:35:44.258594 15760 solver.cpp:228] Iteration 26400, loss = 0.286102
I0615 12:35:44.258616 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 12:35:44.258623 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791884 (* 1 = 0.0791884 loss)
I0615 12:35:44.258627 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0894566 (* 1 = 0.0894566 loss)
I0615 12:35:44.258631 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000297511 (* 1 = 0.000297511 loss)
I0615 12:35:44.258635 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150896 (* 1 = 0.0150896 loss)
I0615 12:35:44.258639 15760 sgd_solver.cpp:106] Iteration 26400, lr = 0.0002
I0615 12:37:30.578150 15760 solver.cpp:228] Iteration 26420, loss = 0.345948
I0615 12:37:30.578173 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 12:37:30.578181 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0653561 (* 1 = 0.0653561 loss)
I0615 12:37:30.578186 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.100611 (* 1 = 0.100611 loss)
I0615 12:37:30.578191 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000779598 (* 1 = 0.000779598 loss)
I0615 12:37:30.578194 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109757 (* 1 = 0.0109757 loss)
I0615 12:37:30.578198 15760 sgd_solver.cpp:106] Iteration 26420, lr = 0.0002
I0615 12:39:17.148460 15760 solver.cpp:228] Iteration 26440, loss = 0.356042
I0615 12:39:17.148485 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 12:39:17.148492 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.150721 (* 1 = 0.150721 loss)
I0615 12:39:17.148496 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.115069 (* 1 = 0.115069 loss)
I0615 12:39:17.148499 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119784 (* 1 = 0.00119784 loss)
I0615 12:39:17.148504 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238193 (* 1 = 0.0238193 loss)
I0615 12:39:17.148509 15760 sgd_solver.cpp:106] Iteration 26440, lr = 0.0002
I0615 12:41:03.963398 15760 solver.cpp:228] Iteration 26460, loss = 0.307146
I0615 12:41:03.963423 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 12:41:03.963431 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.180596 (* 1 = 0.180596 loss)
I0615 12:41:03.963435 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.158206 (* 1 = 0.158206 loss)
I0615 12:41:03.963439 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00370633 (* 1 = 0.00370633 loss)
I0615 12:41:03.963443 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.064136 (* 1 = 0.064136 loss)
I0615 12:41:03.963449 15760 sgd_solver.cpp:106] Iteration 26460, lr = 0.0002
I0615 12:42:50.199546 15760 solver.cpp:228] Iteration 26480, loss = 0.383244
I0615 12:42:50.199578 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 12:42:50.199585 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117225 (* 1 = 0.117225 loss)
I0615 12:42:50.199589 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.270985 (* 1 = 0.270985 loss)
I0615 12:42:50.199594 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0670868 (* 1 = 0.0670868 loss)
I0615 12:42:50.199596 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12974 (* 1 = 0.12974 loss)
I0615 12:42:50.199602 15760 sgd_solver.cpp:106] Iteration 26480, lr = 0.0002
I0615 12:44:36.859432 15760 solver.cpp:228] Iteration 26500, loss = 0.602732
I0615 12:44:36.859454 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 12:44:36.859462 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.256285 (* 1 = 0.256285 loss)
I0615 12:44:36.859464 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.257243 (* 1 = 0.257243 loss)
I0615 12:44:36.859468 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616784 (* 1 = 0.00616784 loss)
I0615 12:44:36.859472 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109908 (* 1 = 0.109908 loss)
I0615 12:44:36.859477 15760 sgd_solver.cpp:106] Iteration 26500, lr = 0.0002
I0615 12:46:23.326758 15760 solver.cpp:228] Iteration 26520, loss = 0.515668
I0615 12:46:23.326786 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 12:46:23.326793 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0681043 (* 1 = 0.0681043 loss)
I0615 12:46:23.326797 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0679763 (* 1 = 0.0679763 loss)
I0615 12:46:23.326802 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00111851 (* 1 = 0.00111851 loss)
I0615 12:46:23.326805 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134055 (* 1 = 0.0134055 loss)
I0615 12:46:23.326810 15760 sgd_solver.cpp:106] Iteration 26520, lr = 0.0002
I0615 12:48:09.807631 15760 solver.cpp:228] Iteration 26540, loss = 0.245443
I0615 12:48:09.807653 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 12:48:09.807660 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.16785 (* 1 = 0.16785 loss)
I0615 12:48:09.807664 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234238 (* 1 = 0.234238 loss)
I0615 12:48:09.807668 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000930143 (* 1 = 0.000930143 loss)
I0615 12:48:09.807672 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353871 (* 1 = 0.0353871 loss)
I0615 12:48:09.807677 15760 sgd_solver.cpp:106] Iteration 26540, lr = 0.0002
I0615 12:49:56.284617 15760 solver.cpp:228] Iteration 26560, loss = 0.458781
I0615 12:49:56.284641 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 12:49:56.284651 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.329418 (* 1 = 0.329418 loss)
I0615 12:49:56.284657 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.286172 (* 1 = 0.286172 loss)
I0615 12:49:56.284662 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0283027 (* 1 = 0.0283027 loss)
I0615 12:49:56.284667 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.137479 (* 1 = 0.137479 loss)
I0615 12:49:56.284672 15760 sgd_solver.cpp:106] Iteration 26560, lr = 0.0002
I0615 12:51:42.495779 15760 solver.cpp:228] Iteration 26580, loss = 0.270017
I0615 12:51:42.495805 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 12:51:42.495813 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.11436 (* 1 = 0.11436 loss)
I0615 12:51:42.495817 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.102802 (* 1 = 0.102802 loss)
I0615 12:51:42.495822 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0043164 (* 1 = 0.0043164 loss)
I0615 12:51:42.495826 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211446 (* 1 = 0.0211446 loss)
I0615 12:51:42.495831 15760 sgd_solver.cpp:106] Iteration 26580, lr = 0.0002
speed: 5.330s / iter
I0615 12:53:28.933238 15760 solver.cpp:228] Iteration 26600, loss = 0.453036
I0615 12:53:28.933260 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 12:53:28.933266 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609421 (* 1 = 0.0609421 loss)
I0615 12:53:28.933270 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.059843 (* 1 = 0.059843 loss)
I0615 12:53:28.933274 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00867933 (* 1 = 0.00867933 loss)
I0615 12:53:28.933277 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022964 (* 1 = 0.022964 loss)
I0615 12:53:28.933282 15760 sgd_solver.cpp:106] Iteration 26600, lr = 0.0002
I0615 12:55:15.259536 15760 solver.cpp:228] Iteration 26620, loss = 0.361996
I0615 12:55:15.259562 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 12:55:15.259569 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.103583 (* 1 = 0.103583 loss)
I0615 12:55:15.259573 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0750205 (* 1 = 0.0750205 loss)
I0615 12:55:15.259577 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000761644 (* 1 = 0.000761644 loss)
I0615 12:55:15.259580 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358951 (* 1 = 0.0358951 loss)
I0615 12:55:15.259585 15760 sgd_solver.cpp:106] Iteration 26620, lr = 0.0002
I0615 12:57:01.835371 15760 solver.cpp:228] Iteration 26640, loss = 0.617003
I0615 12:57:01.835397 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 12:57:01.835405 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.175839 (* 1 = 0.175839 loss)
I0615 12:57:01.835409 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.113325 (* 1 = 0.113325 loss)
I0615 12:57:01.835413 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000552315 (* 1 = 0.000552315 loss)
I0615 12:57:01.835417 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232025 (* 1 = 0.0232025 loss)
I0615 12:57:01.835422 15760 sgd_solver.cpp:106] Iteration 26640, lr = 0.0002
I0615 12:58:48.108080 15760 solver.cpp:228] Iteration 26660, loss = 0.347768
I0615 12:58:48.108105 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 12:58:48.108114 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410082 (* 1 = 0.0410082 loss)
I0615 12:58:48.108117 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0377268 (* 1 = 0.0377268 loss)
I0615 12:58:48.108121 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000117071 (* 1 = 0.000117071 loss)
I0615 12:58:48.108125 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122351 (* 1 = 0.0122351 loss)
I0615 12:58:48.108131 15760 sgd_solver.cpp:106] Iteration 26660, lr = 0.0002
I0615 13:00:34.691808 15760 solver.cpp:228] Iteration 26680, loss = 0.429465
I0615 13:00:34.691831 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 13:00:34.691838 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.511745 (* 1 = 0.511745 loss)
I0615 13:00:34.691843 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.252555 (* 1 = 0.252555 loss)
I0615 13:00:34.691845 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117842 (* 1 = 0.0117842 loss)
I0615 13:00:34.691849 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.135338 (* 1 = 0.135338 loss)
I0615 13:00:34.691854 15760 sgd_solver.cpp:106] Iteration 26680, lr = 0.0002
I0615 13:02:20.998239 15760 solver.cpp:228] Iteration 26700, loss = 0.415556
I0615 13:02:20.998263 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 13:02:20.998270 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.166595 (* 1 = 0.166595 loss)
I0615 13:02:20.998275 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0852532 (* 1 = 0.0852532 loss)
I0615 13:02:20.998277 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00279871 (* 1 = 0.00279871 loss)
I0615 13:02:20.998281 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114643 (* 1 = 0.0114643 loss)
I0615 13:02:20.998286 15760 sgd_solver.cpp:106] Iteration 26700, lr = 0.0002
I0615 13:04:07.200299 15760 solver.cpp:228] Iteration 26720, loss = 0.328903
I0615 13:04:07.200330 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 13:04:07.200340 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.177222 (* 1 = 0.177222 loss)
I0615 13:04:07.200347 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.155848 (* 1 = 0.155848 loss)
I0615 13:04:07.200356 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000938356 (* 1 = 0.000938356 loss)
I0615 13:04:07.200363 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163106 (* 1 = 0.0163106 loss)
I0615 13:04:07.200389 15760 sgd_solver.cpp:106] Iteration 26720, lr = 0.0002
I0615 13:05:53.531296 15760 solver.cpp:228] Iteration 26740, loss = 0.211464
I0615 13:05:53.531321 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 13:05:53.531327 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.174757 (* 1 = 0.174757 loss)
I0615 13:05:53.531332 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.170269 (* 1 = 0.170269 loss)
I0615 13:05:53.531335 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140797 (* 1 = 0.00140797 loss)
I0615 13:05:53.531338 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170625 (* 1 = 0.0170625 loss)
I0615 13:05:53.531343 15760 sgd_solver.cpp:106] Iteration 26740, lr = 0.0002
I0615 13:07:39.749970 15760 solver.cpp:228] Iteration 26760, loss = 0.302614
I0615 13:07:39.749994 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 13:07:39.750001 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.104712 (* 1 = 0.104712 loss)
I0615 13:07:39.750005 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.104593 (* 1 = 0.104593 loss)
I0615 13:07:39.750008 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00637412 (* 1 = 0.00637412 loss)
I0615 13:07:39.750012 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00365707 (* 1 = 0.00365707 loss)
I0615 13:07:39.750016 15760 sgd_solver.cpp:106] Iteration 26760, lr = 0.0002
I0615 13:09:26.299991 15760 solver.cpp:228] Iteration 26780, loss = 0.245889
I0615 13:09:26.300016 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 13:09:26.300024 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0868041 (* 1 = 0.0868041 loss)
I0615 13:09:26.300029 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.089228 (* 1 = 0.089228 loss)
I0615 13:09:26.300032 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000881119 (* 1 = 0.000881119 loss)
I0615 13:09:26.300036 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141238 (* 1 = 0.0141238 loss)
I0615 13:09:26.300041 15760 sgd_solver.cpp:106] Iteration 26780, lr = 0.0002
speed: 5.330s / iter
I0615 13:11:12.744087 15760 solver.cpp:228] Iteration 26800, loss = 0.617921
I0615 13:11:12.744109 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0615 13:11:12.744117 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.523015 (* 1 = 0.523015 loss)
I0615 13:11:12.744122 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.62085 (* 1 = 0.62085 loss)
I0615 13:11:12.744124 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0488765 (* 1 = 0.0488765 loss)
I0615 13:11:12.744127 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.415158 (* 1 = 0.415158 loss)
I0615 13:11:12.744132 15760 sgd_solver.cpp:106] Iteration 26800, lr = 0.0002
I0615 13:12:59.214939 15760 solver.cpp:228] Iteration 26820, loss = 0.393402
I0615 13:12:59.214963 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 13:12:59.214970 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0664727 (* 1 = 0.0664727 loss)
I0615 13:12:59.214974 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0809994 (* 1 = 0.0809994 loss)
I0615 13:12:59.214977 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234809 (* 1 = 0.0234809 loss)
I0615 13:12:59.214980 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168905 (* 1 = 0.0168905 loss)
I0615 13:12:59.214985 15760 sgd_solver.cpp:106] Iteration 26820, lr = 0.0002
I0615 13:14:46.266172 15760 solver.cpp:228] Iteration 26840, loss = 0.286266
I0615 13:14:46.266196 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 13:14:46.266203 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.206494 (* 1 = 0.206494 loss)
I0615 13:14:46.266207 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.25324 (* 1 = 0.25324 loss)
I0615 13:14:46.266211 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158317 (* 1 = 0.0158317 loss)
I0615 13:14:46.266214 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.306519 (* 1 = 0.306519 loss)
I0615 13:14:46.266218 15760 sgd_solver.cpp:106] Iteration 26840, lr = 0.0002
I0615 13:16:33.495057 15760 solver.cpp:228] Iteration 26860, loss = 0.464647
I0615 13:16:33.495084 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 13:16:33.495090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0760135 (* 1 = 0.0760135 loss)
I0615 13:16:33.495095 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.145263 (* 1 = 0.145263 loss)
I0615 13:16:33.495100 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150682 (* 1 = 0.00150682 loss)
I0615 13:16:33.495102 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207684 (* 1 = 0.0207684 loss)
I0615 13:16:33.495108 15760 sgd_solver.cpp:106] Iteration 26860, lr = 0.0002
I0615 13:18:20.643293 15760 solver.cpp:228] Iteration 26880, loss = 0.364332
I0615 13:18:20.643323 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 13:18:20.643332 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.235737 (* 1 = 0.235737 loss)
I0615 13:18:20.643337 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.193302 (* 1 = 0.193302 loss)
I0615 13:18:20.643340 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00342047 (* 1 = 0.00342047 loss)
I0615 13:18:20.643344 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0398421 (* 1 = 0.0398421 loss)
I0615 13:18:20.643350 15760 sgd_solver.cpp:106] Iteration 26880, lr = 0.0002
I0615 13:20:07.462678 15760 solver.cpp:228] Iteration 26900, loss = 0.369181
I0615 13:20:07.462703 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 13:20:07.462710 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.171692 (* 1 = 0.171692 loss)
I0615 13:20:07.462713 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130801 (* 1 = 0.130801 loss)
I0615 13:20:07.462718 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255805 (* 1 = 0.0255805 loss)
I0615 13:20:07.462721 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.269776 (* 1 = 0.269776 loss)
I0615 13:20:07.462725 15760 sgd_solver.cpp:106] Iteration 26900, lr = 0.0002
I0615 13:21:53.886723 15760 solver.cpp:228] Iteration 26920, loss = 0.304005
I0615 13:21:53.886744 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 13:21:53.886751 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.187831 (* 1 = 0.187831 loss)
I0615 13:21:53.886755 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.218596 (* 1 = 0.218596 loss)
I0615 13:21:53.886759 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00639934 (* 1 = 0.00639934 loss)
I0615 13:21:53.886762 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128816 (* 1 = 0.128816 loss)
I0615 13:21:53.886767 15760 sgd_solver.cpp:106] Iteration 26920, lr = 0.0002
I0615 13:23:40.516420 15760 solver.cpp:228] Iteration 26940, loss = 0.305873
I0615 13:23:40.516443 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 13:23:40.516450 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0966322 (* 1 = 0.0966322 loss)
I0615 13:23:40.516454 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0654384 (* 1 = 0.0654384 loss)
I0615 13:23:40.516458 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000290086 (* 1 = 0.000290086 loss)
I0615 13:23:40.516461 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235314 (* 1 = 0.0235314 loss)
I0615 13:23:40.516466 15760 sgd_solver.cpp:106] Iteration 26940, lr = 0.0002
I0615 13:25:27.220048 15760 solver.cpp:228] Iteration 26960, loss = 0.469487
I0615 13:25:27.220072 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 13:25:27.220082 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.173963 (* 1 = 0.173963 loss)
I0615 13:25:27.220086 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.127146 (* 1 = 0.127146 loss)
I0615 13:25:27.220093 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133996 (* 1 = 0.00133996 loss)
I0615 13:25:27.220098 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0334505 (* 1 = 0.0334505 loss)
I0615 13:25:27.220104 15760 sgd_solver.cpp:106] Iteration 26960, lr = 0.0002
I0615 13:27:13.805454 15760 solver.cpp:228] Iteration 26980, loss = 0.425328
I0615 13:27:13.805479 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 13:27:13.805487 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.111515 (* 1 = 0.111515 loss)
I0615 13:27:13.805493 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.146608 (* 1 = 0.146608 loss)
I0615 13:27:13.805500 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143339 (* 1 = 0.0143339 loss)
I0615 13:27:13.805507 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197559 (* 1 = 0.0197559 loss)
I0615 13:27:13.805516 15760 sgd_solver.cpp:106] Iteration 26980, lr = 0.0002
speed: 5.330s / iter
I0615 13:29:00.323226 15760 solver.cpp:228] Iteration 27000, loss = 0.290751
I0615 13:29:00.323251 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 13:29:00.323259 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.188635 (* 1 = 0.188635 loss)
I0615 13:29:00.323263 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.187632 (* 1 = 0.187632 loss)
I0615 13:29:00.323267 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010536 (* 1 = 0.0010536 loss)
I0615 13:29:00.323271 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0516945 (* 1 = 0.0516945 loss)
I0615 13:29:00.323276 15760 sgd_solver.cpp:106] Iteration 27000, lr = 0.0002
I0615 13:30:46.625475 15760 solver.cpp:228] Iteration 27020, loss = 0.311536
I0615 13:30:46.625500 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 13:30:46.625509 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0907827 (* 1 = 0.0907827 loss)
I0615 13:30:46.625515 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.08042 (* 1 = 0.08042 loss)
I0615 13:30:46.625521 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034881 (* 1 = 0.0034881 loss)
I0615 13:30:46.625526 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121658 (* 1 = 0.0121658 loss)
I0615 13:30:46.625532 15760 sgd_solver.cpp:106] Iteration 27020, lr = 0.0002
I0615 13:32:33.099915 15760 solver.cpp:228] Iteration 27040, loss = 0.552592
I0615 13:32:33.099938 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 13:32:33.099946 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.139316 (* 1 = 0.139316 loss)
I0615 13:32:33.099949 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109996 (* 1 = 0.109996 loss)
I0615 13:32:33.099953 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000814759 (* 1 = 0.000814759 loss)
I0615 13:32:33.099957 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110471 (* 1 = 0.0110471 loss)
I0615 13:32:33.099962 15760 sgd_solver.cpp:106] Iteration 27040, lr = 0.0002
I0615 13:34:19.765933 15760 solver.cpp:228] Iteration 27060, loss = 0.408161
I0615 13:34:19.765959 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 13:34:19.765966 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.157794 (* 1 = 0.157794 loss)
I0615 13:34:19.765970 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195869 (* 1 = 0.195869 loss)
I0615 13:34:19.765974 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00464223 (* 1 = 0.00464223 loss)
I0615 13:34:19.765977 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240877 (* 1 = 0.0240877 loss)
I0615 13:34:19.765982 15760 sgd_solver.cpp:106] Iteration 27060, lr = 0.0002
I0615 13:36:06.141132 15760 solver.cpp:228] Iteration 27080, loss = 0.204461
I0615 13:36:06.141155 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 13:36:06.141161 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0688699 (* 1 = 0.0688699 loss)
I0615 13:36:06.141166 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.10616 (* 1 = 0.10616 loss)
I0615 13:36:06.141170 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.88143e-05 (* 1 = 6.88143e-05 loss)
I0615 13:36:06.141173 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00988841 (* 1 = 0.00988841 loss)
I0615 13:36:06.141178 15760 sgd_solver.cpp:106] Iteration 27080, lr = 0.0002
I0615 13:37:52.484133 15760 solver.cpp:228] Iteration 27100, loss = 0.377602
I0615 13:37:52.484158 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 13:37:52.484165 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0630141 (* 1 = 0.0630141 loss)
I0615 13:37:52.484169 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0659617 (* 1 = 0.0659617 loss)
I0615 13:37:52.484174 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000196598 (* 1 = 0.000196598 loss)
I0615 13:37:52.484177 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00578844 (* 1 = 0.00578844 loss)
I0615 13:37:52.484182 15760 sgd_solver.cpp:106] Iteration 27100, lr = 0.0002
I0615 13:39:38.986054 15760 solver.cpp:228] Iteration 27120, loss = 0.373836
I0615 13:39:38.986078 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 13:39:38.986085 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614907 (* 1 = 0.0614907 loss)
I0615 13:39:38.986089 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.105223 (* 1 = 0.105223 loss)
I0615 13:39:38.986093 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134881 (* 1 = 0.00134881 loss)
I0615 13:39:38.986096 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03009 (* 1 = 0.03009 loss)
I0615 13:39:38.986101 15760 sgd_solver.cpp:106] Iteration 27120, lr = 0.0002
I0615 13:41:25.209851 15760 solver.cpp:228] Iteration 27140, loss = 0.152897
I0615 13:41:25.209875 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 13:41:25.209883 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0942213 (* 1 = 0.0942213 loss)
I0615 13:41:25.209887 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0631732 (* 1 = 0.0631732 loss)
I0615 13:41:25.209892 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000830481 (* 1 = 0.000830481 loss)
I0615 13:41:25.209894 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186515 (* 1 = 0.0186515 loss)
I0615 13:41:25.209899 15760 sgd_solver.cpp:106] Iteration 27140, lr = 0.0002
I0615 13:43:11.718011 15760 solver.cpp:228] Iteration 27160, loss = 0.286572
I0615 13:43:11.718035 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 13:43:11.718044 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.199642 (* 1 = 0.199642 loss)
I0615 13:43:11.718047 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.275211 (* 1 = 0.275211 loss)
I0615 13:43:11.718051 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00321834 (* 1 = 0.00321834 loss)
I0615 13:43:11.718055 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100414 (* 1 = 0.100414 loss)
I0615 13:43:11.718060 15760 sgd_solver.cpp:106] Iteration 27160, lr = 0.0002
I0615 13:44:58.076495 15760 solver.cpp:228] Iteration 27180, loss = 0.298651
I0615 13:44:58.076521 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 13:44:58.076529 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322496 (* 1 = 0.0322496 loss)
I0615 13:44:58.076534 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0436626 (* 1 = 0.0436626 loss)
I0615 13:44:58.076537 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00200987 (* 1 = 0.00200987 loss)
I0615 13:44:58.076541 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144944 (* 1 = 0.0144944 loss)
I0615 13:44:58.076546 15760 sgd_solver.cpp:106] Iteration 27180, lr = 0.0002
speed: 5.330s / iter
I0615 13:46:44.321883 15760 solver.cpp:228] Iteration 27200, loss = 0.343864
I0615 13:46:44.321909 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 13:46:44.321916 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0914195 (* 1 = 0.0914195 loss)
I0615 13:46:44.321919 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0677476 (* 1 = 0.0677476 loss)
I0615 13:46:44.321923 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000777263 (* 1 = 0.000777263 loss)
I0615 13:46:44.321926 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00739387 (* 1 = 0.00739387 loss)
I0615 13:46:44.321931 15760 sgd_solver.cpp:106] Iteration 27200, lr = 0.0002
I0615 13:48:30.728070 15760 solver.cpp:228] Iteration 27220, loss = 0.599605
I0615 13:48:30.728096 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 13:48:30.728104 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.284026 (* 1 = 0.284026 loss)
I0615 13:48:30.728111 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.209248 (* 1 = 0.209248 loss)
I0615 13:48:30.728116 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0079839 (* 1 = 0.0079839 loss)
I0615 13:48:30.728121 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.151599 (* 1 = 0.151599 loss)
I0615 13:48:30.728128 15760 sgd_solver.cpp:106] Iteration 27220, lr = 0.0002
I0615 13:50:17.142388 15760 solver.cpp:228] Iteration 27240, loss = 0.418881
I0615 13:50:17.142411 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 13:50:17.142418 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109904 (* 1 = 0.109904 loss)
I0615 13:50:17.142423 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0985085 (* 1 = 0.0985085 loss)
I0615 13:50:17.142427 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233788 (* 1 = 0.00233788 loss)
I0615 13:50:17.142431 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.008469 (* 1 = 0.008469 loss)
I0615 13:50:17.142436 15760 sgd_solver.cpp:106] Iteration 27240, lr = 0.0002
I0615 13:52:03.537086 15760 solver.cpp:228] Iteration 27260, loss = 0.417877
I0615 13:52:03.537112 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 13:52:03.537119 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235119 (* 1 = 0.0235119 loss)
I0615 13:52:03.537125 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0471523 (* 1 = 0.0471523 loss)
I0615 13:52:03.537132 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000107607 (* 1 = 0.000107607 loss)
I0615 13:52:03.537135 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161671 (* 1 = 0.0161671 loss)
I0615 13:52:03.537142 15760 sgd_solver.cpp:106] Iteration 27260, lr = 0.0002
I0615 13:53:49.813910 15760 solver.cpp:228] Iteration 27280, loss = 0.492605
I0615 13:53:49.813935 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 13:53:49.813941 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529061 (* 1 = 0.0529061 loss)
I0615 13:53:49.813946 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0629572 (* 1 = 0.0629572 loss)
I0615 13:53:49.813949 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000317655 (* 1 = 0.000317655 loss)
I0615 13:53:49.813952 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224098 (* 1 = 0.0224098 loss)
I0615 13:53:49.813957 15760 sgd_solver.cpp:106] Iteration 27280, lr = 0.0002
I0615 13:55:36.513983 15760 solver.cpp:228] Iteration 27300, loss = 0.414292
I0615 13:55:36.514012 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 13:55:36.514019 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.25685 (* 1 = 0.25685 loss)
I0615 13:55:36.514024 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.197368 (* 1 = 0.197368 loss)
I0615 13:55:36.514027 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012861 (* 1 = 0.0012861 loss)
I0615 13:55:36.514030 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0381058 (* 1 = 0.0381058 loss)
I0615 13:55:36.514036 15760 sgd_solver.cpp:106] Iteration 27300, lr = 0.0002
I0615 13:57:23.316295 15760 solver.cpp:228] Iteration 27320, loss = 0.322197
I0615 13:57:23.316319 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 13:57:23.316329 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0893751 (* 1 = 0.0893751 loss)
I0615 13:57:23.316334 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0407453 (* 1 = 0.0407453 loss)
I0615 13:57:23.316340 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000516837 (* 1 = 0.000516837 loss)
I0615 13:57:23.316346 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179851 (* 1 = 0.0179851 loss)
I0615 13:57:23.316354 15760 sgd_solver.cpp:106] Iteration 27320, lr = 0.0002
I0615 13:59:09.987278 15760 solver.cpp:228] Iteration 27340, loss = 0.379601
I0615 13:59:09.987309 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0615 13:59:09.987318 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.233501 (* 1 = 0.233501 loss)
I0615 13:59:09.987323 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.303987 (* 1 = 0.303987 loss)
I0615 13:59:09.987329 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179018 (* 1 = 0.00179018 loss)
I0615 13:59:09.987335 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452008 (* 1 = 0.0452008 loss)
I0615 13:59:09.987341 15760 sgd_solver.cpp:106] Iteration 27340, lr = 0.0002
I0615 14:00:56.808354 15760 solver.cpp:228] Iteration 27360, loss = 0.451078
I0615 14:00:56.808380 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 14:00:56.808388 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.125458 (* 1 = 0.125458 loss)
I0615 14:00:56.808393 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0739031 (* 1 = 0.0739031 loss)
I0615 14:00:56.808396 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.26911e-05 (* 1 = 4.26911e-05 loss)
I0615 14:00:56.808400 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243247 (* 1 = 0.0243247 loss)
I0615 14:00:56.808405 15760 sgd_solver.cpp:106] Iteration 27360, lr = 0.0002
I0615 14:02:43.586257 15760 solver.cpp:228] Iteration 27380, loss = 0.509029
I0615 14:02:43.586282 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 14:02:43.586292 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.246091 (* 1 = 0.246091 loss)
I0615 14:02:43.586295 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.186985 (* 1 = 0.186985 loss)
I0615 14:02:43.586299 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052566 (* 1 = 0.0052566 loss)
I0615 14:02:43.586302 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0578764 (* 1 = 0.0578764 loss)
I0615 14:02:43.586308 15760 sgd_solver.cpp:106] Iteration 27380, lr = 0.0002
speed: 5.330s / iter
I0615 14:04:30.308187 15760 solver.cpp:228] Iteration 27400, loss = 0.276688
I0615 14:04:30.308215 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 14:04:30.308225 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.059352 (* 1 = 0.059352 loss)
I0615 14:04:30.308233 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.126509 (* 1 = 0.126509 loss)
I0615 14:04:30.308239 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282339 (* 1 = 0.00282339 loss)
I0615 14:04:30.308248 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00928682 (* 1 = 0.00928682 loss)
I0615 14:04:30.308256 15760 sgd_solver.cpp:106] Iteration 27400, lr = 0.0002
I0615 14:06:16.640381 15760 solver.cpp:228] Iteration 27420, loss = 0.318609
I0615 14:06:16.640410 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 14:06:16.640419 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109238 (* 1 = 0.109238 loss)
I0615 14:06:16.640425 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.142535 (* 1 = 0.142535 loss)
I0615 14:06:16.640430 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00345518 (* 1 = 0.00345518 loss)
I0615 14:06:16.640436 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0645037 (* 1 = 0.0645037 loss)
I0615 14:06:16.640442 15760 sgd_solver.cpp:106] Iteration 27420, lr = 0.0002
I0615 14:08:03.261878 15760 solver.cpp:228] Iteration 27440, loss = 0.499233
I0615 14:08:03.261903 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 14:08:03.261909 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.581408 (* 1 = 0.581408 loss)
I0615 14:08:03.261914 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.358458 (* 1 = 0.358458 loss)
I0615 14:08:03.261916 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159783 (* 1 = 0.0159783 loss)
I0615 14:08:03.261920 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.156339 (* 1 = 0.156339 loss)
I0615 14:08:03.261924 15760 sgd_solver.cpp:106] Iteration 27440, lr = 0.0002
I0615 14:09:49.880100 15760 solver.cpp:228] Iteration 27460, loss = 0.391671
I0615 14:09:49.880125 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 14:09:49.880131 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0804428 (* 1 = 0.0804428 loss)
I0615 14:09:49.880136 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0923422 (* 1 = 0.0923422 loss)
I0615 14:09:49.880139 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000231149 (* 1 = 0.000231149 loss)
I0615 14:09:49.880142 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150135 (* 1 = 0.0150135 loss)
I0615 14:09:49.880147 15760 sgd_solver.cpp:106] Iteration 27460, lr = 0.0002
I0615 14:11:36.427590 15760 solver.cpp:228] Iteration 27480, loss = 0.412883
I0615 14:11:36.427614 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 14:11:36.427620 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.127433 (* 1 = 0.127433 loss)
I0615 14:11:36.427625 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134832 (* 1 = 0.134832 loss)
I0615 14:11:36.427628 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101988 (* 1 = 0.00101988 loss)
I0615 14:11:36.427633 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0669996 (* 1 = 0.0669996 loss)
I0615 14:11:36.427636 15760 sgd_solver.cpp:106] Iteration 27480, lr = 0.0002
I0615 14:13:23.140142 15760 solver.cpp:228] Iteration 27500, loss = 0.317548
I0615 14:13:23.140164 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 14:13:23.140172 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.190219 (* 1 = 0.190219 loss)
I0615 14:13:23.140175 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.226825 (* 1 = 0.226825 loss)
I0615 14:13:23.140178 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126498 (* 1 = 0.0126498 loss)
I0615 14:13:23.140182 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.144464 (* 1 = 0.144464 loss)
I0615 14:13:23.140187 15760 sgd_solver.cpp:106] Iteration 27500, lr = 0.0002
I0615 14:15:09.845726 15760 solver.cpp:228] Iteration 27520, loss = 0.654418
I0615 14:15:09.845752 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 14:15:09.845758 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0734494 (* 1 = 0.0734494 loss)
I0615 14:15:09.845762 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0780098 (* 1 = 0.0780098 loss)
I0615 14:15:09.845765 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00076967 (* 1 = 0.00076967 loss)
I0615 14:15:09.845769 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0051824 (* 1 = 0.0051824 loss)
I0615 14:15:09.845774 15760 sgd_solver.cpp:106] Iteration 27520, lr = 0.0002
I0615 14:16:56.501579 15760 solver.cpp:228] Iteration 27540, loss = 0.290183
I0615 14:16:56.501603 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 14:16:56.501611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0845978 (* 1 = 0.0845978 loss)
I0615 14:16:56.501616 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0569912 (* 1 = 0.0569912 loss)
I0615 14:16:56.501619 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000179048 (* 1 = 0.000179048 loss)
I0615 14:16:56.501623 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284771 (* 1 = 0.0284771 loss)
I0615 14:16:56.501628 15760 sgd_solver.cpp:106] Iteration 27540, lr = 0.0002
I0615 14:18:42.905560 15760 solver.cpp:228] Iteration 27560, loss = 0.478203
I0615 14:18:42.905583 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 14:18:42.905591 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0631623 (* 1 = 0.0631623 loss)
I0615 14:18:42.905594 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0541481 (* 1 = 0.0541481 loss)
I0615 14:18:42.905598 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00188458 (* 1 = 0.00188458 loss)
I0615 14:18:42.905601 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00941627 (* 1 = 0.00941627 loss)
I0615 14:18:42.905606 15760 sgd_solver.cpp:106] Iteration 27560, lr = 0.0002
I0615 14:20:29.253705 15760 solver.cpp:228] Iteration 27580, loss = 0.334417
I0615 14:20:29.253731 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 14:20:29.253741 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.14181 (* 1 = 0.14181 loss)
I0615 14:20:29.253746 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.162172 (* 1 = 0.162172 loss)
I0615 14:20:29.253753 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0002921 (* 1 = 0.0002921 loss)
I0615 14:20:29.253759 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0340643 (* 1 = 0.0340643 loss)
I0615 14:20:29.253767 15760 sgd_solver.cpp:106] Iteration 27580, lr = 0.0002
speed: 5.330s / iter
I0615 14:22:15.790583 15760 solver.cpp:228] Iteration 27600, loss = 0.458374
I0615 14:22:15.790608 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 14:22:15.790616 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.067187 (* 1 = 0.067187 loss)
I0615 14:22:15.790621 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0672389 (* 1 = 0.0672389 loss)
I0615 14:22:15.790624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00175372 (* 1 = 0.00175372 loss)
I0615 14:22:15.790628 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143469 (* 1 = 0.0143469 loss)
I0615 14:22:15.790632 15760 sgd_solver.cpp:106] Iteration 27600, lr = 0.0002
I0615 14:24:02.375464 15760 solver.cpp:228] Iteration 27620, loss = 0.51113
I0615 14:24:02.375488 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 14:24:02.375494 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.178208 (* 1 = 0.178208 loss)
I0615 14:24:02.375499 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.172339 (* 1 = 0.172339 loss)
I0615 14:24:02.375501 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134228 (* 1 = 0.00134228 loss)
I0615 14:24:02.375505 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153737 (* 1 = 0.0153737 loss)
I0615 14:24:02.375510 15760 sgd_solver.cpp:106] Iteration 27620, lr = 0.0002
I0615 14:25:48.752602 15760 solver.cpp:228] Iteration 27640, loss = 0.395532
I0615 14:25:48.752626 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 14:25:48.752634 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494743 (* 1 = 0.0494743 loss)
I0615 14:25:48.752637 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.056227 (* 1 = 0.056227 loss)
I0615 14:25:48.752641 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135604 (* 1 = 0.00135604 loss)
I0615 14:25:48.752645 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152141 (* 1 = 0.0152141 loss)
I0615 14:25:48.752648 15760 sgd_solver.cpp:106] Iteration 27640, lr = 0.0002
I0615 14:27:35.299821 15760 solver.cpp:228] Iteration 27660, loss = 0.366389
I0615 14:27:35.299845 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 14:27:35.299852 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.237043 (* 1 = 0.237043 loss)
I0615 14:27:35.299856 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.316962 (* 1 = 0.316962 loss)
I0615 14:27:35.299860 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160228 (* 1 = 0.0160228 loss)
I0615 14:27:35.299865 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0785845 (* 1 = 0.0785845 loss)
I0615 14:27:35.299870 15760 sgd_solver.cpp:106] Iteration 27660, lr = 0.0002
I0615 14:29:21.895875 15760 solver.cpp:228] Iteration 27680, loss = 0.589679
I0615 14:29:21.895901 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0615 14:29:21.895908 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.358667 (* 1 = 0.358667 loss)
I0615 14:29:21.895912 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.456876 (* 1 = 0.456876 loss)
I0615 14:29:21.895916 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956545 (* 1 = 0.00956545 loss)
I0615 14:29:21.895920 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.238899 (* 1 = 0.238899 loss)
I0615 14:29:21.895925 15760 sgd_solver.cpp:106] Iteration 27680, lr = 0.0002
I0615 14:31:08.090138 15760 solver.cpp:228] Iteration 27700, loss = 0.273488
I0615 14:31:08.090183 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 14:31:08.090196 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.086265 (* 1 = 0.086265 loss)
I0615 14:31:08.090204 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.149652 (* 1 = 0.149652 loss)
I0615 14:31:08.090209 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000877489 (* 1 = 0.000877489 loss)
I0615 14:31:08.090215 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116005 (* 1 = 0.0116005 loss)
I0615 14:31:08.090225 15760 sgd_solver.cpp:106] Iteration 27700, lr = 0.0002
I0615 14:32:54.499886 15760 solver.cpp:228] Iteration 27720, loss = 0.286217
I0615 14:32:54.499907 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 14:32:54.499914 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0271282 (* 1 = 0.0271282 loss)
I0615 14:32:54.499918 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0497187 (* 1 = 0.0497187 loss)
I0615 14:32:54.499922 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131001 (* 1 = 0.0131001 loss)
I0615 14:32:54.499925 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207497 (* 1 = 0.0207497 loss)
I0615 14:32:54.499929 15760 sgd_solver.cpp:106] Iteration 27720, lr = 0.0002
I0615 14:34:40.786739 15760 solver.cpp:228] Iteration 27740, loss = 0.477452
I0615 14:34:40.786761 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 14:34:40.786768 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.243866 (* 1 = 0.243866 loss)
I0615 14:34:40.786772 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.23616 (* 1 = 0.23616 loss)
I0615 14:34:40.786777 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110319 (* 1 = 0.00110319 loss)
I0615 14:34:40.786779 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0350075 (* 1 = 0.0350075 loss)
I0615 14:34:40.786783 15760 sgd_solver.cpp:106] Iteration 27740, lr = 0.0002
I0615 14:36:27.162914 15760 solver.cpp:228] Iteration 27760, loss = 0.296492
I0615 14:36:27.162940 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 14:36:27.162946 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.207349 (* 1 = 0.207349 loss)
I0615 14:36:27.162951 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109579 (* 1 = 0.109579 loss)
I0615 14:36:27.162955 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000748326 (* 1 = 0.000748326 loss)
I0615 14:36:27.162959 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0593524 (* 1 = 0.0593524 loss)
I0615 14:36:27.162964 15760 sgd_solver.cpp:106] Iteration 27760, lr = 0.0002
I0615 14:38:13.603252 15760 solver.cpp:228] Iteration 27780, loss = 0.24406
I0615 14:38:13.603277 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 14:38:13.603286 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.169942 (* 1 = 0.169942 loss)
I0615 14:38:13.603291 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.167242 (* 1 = 0.167242 loss)
I0615 14:38:13.603296 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00595429 (* 1 = 0.00595429 loss)
I0615 14:38:13.603301 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.13144 (* 1 = 0.13144 loss)
I0615 14:38:13.603307 15760 sgd_solver.cpp:106] Iteration 27780, lr = 0.0002
speed: 5.330s / iter
I0615 14:40:00.346076 15760 solver.cpp:228] Iteration 27800, loss = 0.375334
I0615 14:40:00.346102 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 14:40:00.346110 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378111 (* 1 = 0.0378111 loss)
I0615 14:40:00.346114 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0401326 (* 1 = 0.0401326 loss)
I0615 14:40:00.346118 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000252355 (* 1 = 0.000252355 loss)
I0615 14:40:00.346122 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00916233 (* 1 = 0.00916233 loss)
I0615 14:40:00.346128 15760 sgd_solver.cpp:106] Iteration 27800, lr = 0.0002
I0615 14:41:47.937427 15760 solver.cpp:228] Iteration 27820, loss = 0.470869
I0615 14:41:47.937449 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 14:41:47.937456 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0696906 (* 1 = 0.0696906 loss)
I0615 14:41:47.937459 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.106647 (* 1 = 0.106647 loss)
I0615 14:41:47.937463 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000934146 (* 1 = 0.000934146 loss)
I0615 14:41:47.937467 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209007 (* 1 = 0.0209007 loss)
I0615 14:41:47.937471 15760 sgd_solver.cpp:106] Iteration 27820, lr = 0.0002
I0615 14:43:34.780546 15760 solver.cpp:228] Iteration 27840, loss = 0.37085
I0615 14:43:34.780570 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 14:43:34.780577 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0493833 (* 1 = 0.0493833 loss)
I0615 14:43:34.780581 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0626716 (* 1 = 0.0626716 loss)
I0615 14:43:34.780586 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105236 (* 1 = 0.0105236 loss)
I0615 14:43:34.780589 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00596279 (* 1 = 0.00596279 loss)
I0615 14:43:34.780594 15760 sgd_solver.cpp:106] Iteration 27840, lr = 0.0002
I0615 14:45:22.310168 15760 solver.cpp:228] Iteration 27860, loss = 0.363111
I0615 14:45:22.310194 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 14:45:22.310201 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.105056 (* 1 = 0.105056 loss)
I0615 14:45:22.310205 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.109163 (* 1 = 0.109163 loss)
I0615 14:45:22.310209 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000291236 (* 1 = 0.000291236 loss)
I0615 14:45:22.310212 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00721524 (* 1 = 0.00721524 loss)
I0615 14:45:22.310219 15760 sgd_solver.cpp:106] Iteration 27860, lr = 0.0002
I0615 14:47:09.354557 15760 solver.cpp:228] Iteration 27880, loss = 0.433977
I0615 14:47:09.354601 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 14:47:09.354611 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.112069 (* 1 = 0.112069 loss)
I0615 14:47:09.354619 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.106719 (* 1 = 0.106719 loss)
I0615 14:47:09.354624 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136468 (* 1 = 0.00136468 loss)
I0615 14:47:09.354629 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00597258 (* 1 = 0.00597258 loss)
I0615 14:47:09.354637 15760 sgd_solver.cpp:106] Iteration 27880, lr = 0.0002
I0615 14:48:56.631439 15760 solver.cpp:228] Iteration 27900, loss = 0.292275
I0615 14:48:56.631464 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 14:48:56.631472 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0669271 (* 1 = 0.0669271 loss)
I0615 14:48:56.631476 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0804457 (* 1 = 0.0804457 loss)
I0615 14:48:56.631480 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102209 (* 1 = 0.00102209 loss)
I0615 14:48:56.631484 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118439 (* 1 = 0.0118439 loss)
I0615 14:48:56.631489 15760 sgd_solver.cpp:106] Iteration 27900, lr = 0.0002
I0615 14:50:43.649698 15760 solver.cpp:228] Iteration 27920, loss = 0.386197
I0615 14:50:43.649722 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 14:50:43.649729 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.173056 (* 1 = 0.173056 loss)
I0615 14:50:43.649734 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.198402 (* 1 = 0.198402 loss)
I0615 14:50:43.649737 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160885 (* 1 = 0.00160885 loss)
I0615 14:50:43.649741 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0366303 (* 1 = 0.0366303 loss)
I0615 14:50:43.649747 15760 sgd_solver.cpp:106] Iteration 27920, lr = 0.0002
I0615 14:52:30.936803 15760 solver.cpp:228] Iteration 27940, loss = 0.29979
I0615 14:52:30.936826 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 14:52:30.936834 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.129182 (* 1 = 0.129182 loss)
I0615 14:52:30.936838 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.148037 (* 1 = 0.148037 loss)
I0615 14:52:30.936842 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000624101 (* 1 = 0.000624101 loss)
I0615 14:52:30.936846 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226525 (* 1 = 0.0226525 loss)
I0615 14:52:30.936851 15760 sgd_solver.cpp:106] Iteration 27940, lr = 0.0002
I0615 14:54:17.935117 15760 solver.cpp:228] Iteration 27960, loss = 0.572693
I0615 14:54:17.935142 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 14:54:17.935150 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117802 (* 1 = 0.117802 loss)
I0615 14:54:17.935154 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.115037 (* 1 = 0.115037 loss)
I0615 14:54:17.935159 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000448613 (* 1 = 0.000448613 loss)
I0615 14:54:17.935163 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100625 (* 1 = 0.0100625 loss)
I0615 14:54:17.935169 15760 sgd_solver.cpp:106] Iteration 27960, lr = 0.0002
I0615 14:56:04.381336 15760 solver.cpp:228] Iteration 27980, loss = 0.367733
I0615 14:56:04.381361 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 14:56:04.381369 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.137699 (* 1 = 0.137699 loss)
I0615 14:56:04.381373 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.103733 (* 1 = 0.103733 loss)
I0615 14:56:04.381377 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000686839 (* 1 = 0.000686839 loss)
I0615 14:56:04.381381 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229006 (* 1 = 0.0229006 loss)
I0615 14:56:04.381386 15760 sgd_solver.cpp:106] Iteration 27980, lr = 0.0002
speed: 5.330s / iter
I0615 14:57:51.087123 15760 solver.cpp:228] Iteration 28000, loss = 0.422754
I0615 14:57:51.087149 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0615 14:57:51.087157 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.451946 (* 1 = 0.451946 loss)
I0615 14:57:51.087162 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.41283 (* 1 = 0.41283 loss)
I0615 14:57:51.087165 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000818957 (* 1 = 0.000818957 loss)
I0615 14:57:51.087169 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372022 (* 1 = 0.0372022 loss)
I0615 14:57:51.087174 15760 sgd_solver.cpp:106] Iteration 28000, lr = 0.0002
I0615 14:59:37.350427 15760 solver.cpp:228] Iteration 28020, loss = 0.350302
I0615 14:59:37.350453 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0615 14:59:37.350461 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.619849 (* 1 = 0.619849 loss)
I0615 14:59:37.350466 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.572277 (* 1 = 0.572277 loss)
I0615 14:59:37.350469 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122017 (* 1 = 0.0122017 loss)
I0615 14:59:37.350473 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.246875 (* 1 = 0.246875 loss)
I0615 14:59:37.350478 15760 sgd_solver.cpp:106] Iteration 28020, lr = 0.0002
I0615 15:01:24.019266 15760 solver.cpp:228] Iteration 28040, loss = 0.255506
I0615 15:01:24.019290 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 15:01:24.019299 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566619 (* 1 = 0.0566619 loss)
I0615 15:01:24.019304 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112382 (* 1 = 0.112382 loss)
I0615 15:01:24.019306 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276268 (* 1 = 0.0276268 loss)
I0615 15:01:24.019310 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0591155 (* 1 = 0.0591155 loss)
I0615 15:01:24.019315 15760 sgd_solver.cpp:106] Iteration 28040, lr = 0.0002
I0615 15:03:10.283296 15760 solver.cpp:228] Iteration 28060, loss = 0.277904
I0615 15:03:10.283325 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 15:03:10.283334 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.21071 (* 1 = 0.21071 loss)
I0615 15:03:10.283337 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.21867 (* 1 = 0.21867 loss)
I0615 15:03:10.283341 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00826212 (* 1 = 0.00826212 loss)
I0615 15:03:10.283345 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0602606 (* 1 = 0.0602606 loss)
I0615 15:03:10.283350 15760 sgd_solver.cpp:106] Iteration 28060, lr = 0.0002
I0615 15:04:56.708575 15760 solver.cpp:228] Iteration 28080, loss = 0.44838
I0615 15:04:56.708600 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 15:04:56.708606 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685709 (* 1 = 0.0685709 loss)
I0615 15:04:56.708609 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0613785 (* 1 = 0.0613785 loss)
I0615 15:04:56.708613 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000453353 (* 1 = 0.000453353 loss)
I0615 15:04:56.708617 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00710171 (* 1 = 0.00710171 loss)
I0615 15:04:56.708621 15760 sgd_solver.cpp:106] Iteration 28080, lr = 0.0002
I0615 15:06:42.871857 15760 solver.cpp:228] Iteration 28100, loss = 0.36488
I0615 15:06:42.871882 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 15:06:42.871889 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0989696 (* 1 = 0.0989696 loss)
I0615 15:06:42.871893 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.138473 (* 1 = 0.138473 loss)
I0615 15:06:42.871897 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00364315 (* 1 = 0.00364315 loss)
I0615 15:06:42.871901 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148844 (* 1 = 0.0148844 loss)
I0615 15:06:42.871906 15760 sgd_solver.cpp:106] Iteration 28100, lr = 0.0002
I0615 15:08:29.368314 15760 solver.cpp:228] Iteration 28120, loss = 0.303052
I0615 15:08:29.368338 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 15:08:29.368345 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.166116 (* 1 = 0.166116 loss)
I0615 15:08:29.368350 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.104745 (* 1 = 0.104745 loss)
I0615 15:08:29.368355 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000201986 (* 1 = 0.000201986 loss)
I0615 15:08:29.368358 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257187 (* 1 = 0.0257187 loss)
I0615 15:08:29.368363 15760 sgd_solver.cpp:106] Iteration 28120, lr = 0.0002
I0615 15:10:15.809998 15760 solver.cpp:228] Iteration 28140, loss = 0.35741
I0615 15:10:15.810020 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 15:10:15.810027 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0832032 (* 1 = 0.0832032 loss)
I0615 15:10:15.810031 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0913994 (* 1 = 0.0913994 loss)
I0615 15:10:15.810035 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000443256 (* 1 = 0.000443256 loss)
I0615 15:10:15.810039 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00544893 (* 1 = 0.00544893 loss)
I0615 15:10:15.810043 15760 sgd_solver.cpp:106] Iteration 28140, lr = 0.0002
I0615 15:12:02.231112 15760 solver.cpp:228] Iteration 28160, loss = 0.442816
I0615 15:12:02.231137 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 15:12:02.231143 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.126066 (* 1 = 0.126066 loss)
I0615 15:12:02.231148 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.128253 (* 1 = 0.128253 loss)
I0615 15:12:02.231150 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.26203e-05 (* 1 = 5.26203e-05 loss)
I0615 15:12:02.231154 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00677076 (* 1 = 0.00677076 loss)
I0615 15:12:02.231159 15760 sgd_solver.cpp:106] Iteration 28160, lr = 0.0002
I0615 15:13:48.483148 15760 solver.cpp:228] Iteration 28180, loss = 0.336066
I0615 15:13:48.483173 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 15:13:48.483181 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0607011 (* 1 = 0.0607011 loss)
I0615 15:13:48.483186 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0281346 (* 1 = 0.0281346 loss)
I0615 15:13:48.483191 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.84011e-05 (* 1 = 2.84011e-05 loss)
I0615 15:13:48.483194 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00875688 (* 1 = 0.00875688 loss)
I0615 15:13:48.483199 15760 sgd_solver.cpp:106] Iteration 28180, lr = 0.0002
speed: 5.330s / iter
I0615 15:15:34.699745 15760 solver.cpp:228] Iteration 28200, loss = 0.23843
I0615 15:15:34.699769 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 15:15:34.699777 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0643239 (* 1 = 0.0643239 loss)
I0615 15:15:34.699781 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0575345 (* 1 = 0.0575345 loss)
I0615 15:15:34.699785 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.23059e-05 (* 1 = 9.23059e-05 loss)
I0615 15:15:34.699790 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108798 (* 1 = 0.0108798 loss)
I0615 15:15:34.699795 15760 sgd_solver.cpp:106] Iteration 28200, lr = 0.0002
I0615 15:17:21.087661 15760 solver.cpp:228] Iteration 28220, loss = 0.392998
I0615 15:17:21.087685 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 15:17:21.087692 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.219825 (* 1 = 0.219825 loss)
I0615 15:17:21.087695 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.238534 (* 1 = 0.238534 loss)
I0615 15:17:21.087699 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00500421 (* 1 = 0.00500421 loss)
I0615 15:17:21.087702 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036587 (* 1 = 0.036587 loss)
I0615 15:17:21.087707 15760 sgd_solver.cpp:106] Iteration 28220, lr = 0.0002
I0615 15:19:07.450948 15760 solver.cpp:228] Iteration 28240, loss = 0.32869
I0615 15:19:07.450974 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 15:19:07.450981 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.124839 (* 1 = 0.124839 loss)
I0615 15:19:07.450985 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0887214 (* 1 = 0.0887214 loss)
I0615 15:19:07.450989 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110462 (* 1 = 0.00110462 loss)
I0615 15:19:07.450994 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241714 (* 1 = 0.0241714 loss)
I0615 15:19:07.450999 15760 sgd_solver.cpp:106] Iteration 28240, lr = 0.0002
I0615 15:20:54.083405 15760 solver.cpp:228] Iteration 28260, loss = 0.391411
I0615 15:20:54.083431 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 15:20:54.083437 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.066668 (* 1 = 0.066668 loss)
I0615 15:20:54.083441 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0869166 (* 1 = 0.0869166 loss)
I0615 15:20:54.083444 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000699965 (* 1 = 0.000699965 loss)
I0615 15:20:54.083448 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129272 (* 1 = 0.0129272 loss)
I0615 15:20:54.083452 15760 sgd_solver.cpp:106] Iteration 28260, lr = 0.0002
I0615 15:22:40.360110 15760 solver.cpp:228] Iteration 28280, loss = 0.40952
I0615 15:22:40.360136 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 15:22:40.360142 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0790552 (* 1 = 0.0790552 loss)
I0615 15:22:40.360147 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.11785 (* 1 = 0.11785 loss)
I0615 15:22:40.360152 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135625 (* 1 = 0.00135625 loss)
I0615 15:22:40.360155 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126983 (* 1 = 0.0126983 loss)
I0615 15:22:40.360160 15760 sgd_solver.cpp:106] Iteration 28280, lr = 0.0002
I0615 15:24:27.039883 15760 solver.cpp:228] Iteration 28300, loss = 0.572529
I0615 15:24:27.039909 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 15:24:27.039917 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481964 (* 1 = 0.0481964 loss)
I0615 15:24:27.039921 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0812919 (* 1 = 0.0812919 loss)
I0615 15:24:27.039924 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157056 (* 1 = 0.0157056 loss)
I0615 15:24:27.039927 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0350962 (* 1 = 0.0350962 loss)
I0615 15:24:27.039932 15760 sgd_solver.cpp:106] Iteration 28300, lr = 0.0002
I0615 15:26:13.832024 15760 solver.cpp:228] Iteration 28320, loss = 0.466991
I0615 15:26:13.832048 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 15:26:13.832056 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.178275 (* 1 = 0.178275 loss)
I0615 15:26:13.832060 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.235629 (* 1 = 0.235629 loss)
I0615 15:26:13.832063 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112048 (* 1 = 0.0112048 loss)
I0615 15:26:13.832067 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295989 (* 1 = 0.0295989 loss)
I0615 15:26:13.832073 15760 sgd_solver.cpp:106] Iteration 28320, lr = 0.0002
I0615 15:28:00.708151 15760 solver.cpp:228] Iteration 28340, loss = 0.442519
I0615 15:28:00.708176 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 15:28:00.708184 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.456624 (* 1 = 0.456624 loss)
I0615 15:28:00.708186 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.364856 (* 1 = 0.364856 loss)
I0615 15:28:00.708190 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00838195 (* 1 = 0.00838195 loss)
I0615 15:28:00.708194 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.124015 (* 1 = 0.124015 loss)
I0615 15:28:00.708199 15760 sgd_solver.cpp:106] Iteration 28340, lr = 0.0002
I0615 15:29:47.625128 15760 solver.cpp:228] Iteration 28360, loss = 0.406095
I0615 15:29:47.625154 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 15:29:47.625160 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.283485 (* 1 = 0.283485 loss)
I0615 15:29:47.625164 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195662 (* 1 = 0.195662 loss)
I0615 15:29:47.625167 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00042227 (* 1 = 0.00042227 loss)
I0615 15:29:47.625171 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443981 (* 1 = 0.0443981 loss)
I0615 15:29:47.625175 15760 sgd_solver.cpp:106] Iteration 28360, lr = 0.0002
I0615 15:31:34.899225 15760 solver.cpp:228] Iteration 28380, loss = 0.438098
I0615 15:31:34.899252 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 15:31:34.899260 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0436446 (* 1 = 0.0436446 loss)
I0615 15:31:34.899266 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0610598 (* 1 = 0.0610598 loss)
I0615 15:31:34.899271 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169405 (* 1 = 0.00169405 loss)
I0615 15:31:34.899276 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166925 (* 1 = 0.0166925 loss)
I0615 15:31:34.899281 15760 sgd_solver.cpp:106] Iteration 28380, lr = 0.0002
speed: 5.330s / iter
I0615 15:33:21.650377 15760 solver.cpp:228] Iteration 28400, loss = 0.410665
I0615 15:33:21.650403 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 15:33:21.650411 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146318 (* 1 = 0.146318 loss)
I0615 15:33:21.650416 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.18681 (* 1 = 0.18681 loss)
I0615 15:33:21.650420 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164491 (* 1 = 0.0164491 loss)
I0615 15:33:21.650425 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0721932 (* 1 = 0.0721932 loss)
I0615 15:33:21.650430 15760 sgd_solver.cpp:106] Iteration 28400, lr = 0.0002
I0615 15:35:08.346197 15760 solver.cpp:228] Iteration 28420, loss = 0.599504
I0615 15:35:08.346222 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 15:35:08.346230 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529073 (* 1 = 0.0529073 loss)
I0615 15:35:08.346236 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0945721 (* 1 = 0.0945721 loss)
I0615 15:35:08.346241 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113459 (* 1 = 0.00113459 loss)
I0615 15:35:08.346246 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252985 (* 1 = 0.0252985 loss)
I0615 15:35:08.346251 15760 sgd_solver.cpp:106] Iteration 28420, lr = 0.0002
I0615 15:36:55.675137 15760 solver.cpp:228] Iteration 28440, loss = 0.540735
I0615 15:36:55.675161 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 15:36:55.675169 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0876493 (* 1 = 0.0876493 loss)
I0615 15:36:55.675173 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.110049 (* 1 = 0.110049 loss)
I0615 15:36:55.675177 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.69939e-05 (* 1 = 7.69939e-05 loss)
I0615 15:36:55.675181 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00412874 (* 1 = 0.00412874 loss)
I0615 15:36:55.675187 15760 sgd_solver.cpp:106] Iteration 28440, lr = 0.0002
I0615 15:38:42.885980 15760 solver.cpp:228] Iteration 28460, loss = 0.382826
I0615 15:38:42.886005 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 15:38:42.886013 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0837111 (* 1 = 0.0837111 loss)
I0615 15:38:42.886018 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0752332 (* 1 = 0.0752332 loss)
I0615 15:38:42.886021 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000612779 (* 1 = 0.000612779 loss)
I0615 15:38:42.886025 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103775 (* 1 = 0.0103775 loss)
I0615 15:38:42.886030 15760 sgd_solver.cpp:106] Iteration 28460, lr = 0.0002
I0615 15:40:30.364241 15760 solver.cpp:228] Iteration 28480, loss = 0.564795
I0615 15:40:30.364269 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 15:40:30.364276 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.294195 (* 1 = 0.294195 loss)
I0615 15:40:30.364280 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.231641 (* 1 = 0.231641 loss)
I0615 15:40:30.364284 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00325066 (* 1 = 0.00325066 loss)
I0615 15:40:30.364287 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0386672 (* 1 = 0.0386672 loss)
I0615 15:40:30.364292 15760 sgd_solver.cpp:106] Iteration 28480, lr = 0.0002
I0615 15:42:17.264338 15760 solver.cpp:228] Iteration 28500, loss = 0.315612
I0615 15:42:17.264365 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 15:42:17.264374 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.258312 (* 1 = 0.258312 loss)
I0615 15:42:17.264379 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.178835 (* 1 = 0.178835 loss)
I0615 15:42:17.264382 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158922 (* 1 = 0.00158922 loss)
I0615 15:42:17.264386 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331543 (* 1 = 0.0331543 loss)
I0615 15:42:17.264394 15760 sgd_solver.cpp:106] Iteration 28500, lr = 0.0002
I0615 15:44:03.923422 15760 solver.cpp:228] Iteration 28520, loss = 0.460757
I0615 15:44:03.923445 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 15:44:03.923452 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.288153 (* 1 = 0.288153 loss)
I0615 15:44:03.923456 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.225043 (* 1 = 0.225043 loss)
I0615 15:44:03.923460 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217926 (* 1 = 0.00217926 loss)
I0615 15:44:03.923463 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0666504 (* 1 = 0.0666504 loss)
I0615 15:44:03.923468 15760 sgd_solver.cpp:106] Iteration 28520, lr = 0.0002
I0615 15:45:50.219445 15760 solver.cpp:228] Iteration 28540, loss = 0.539238
I0615 15:45:50.219470 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 15:45:50.219477 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.307001 (* 1 = 0.307001 loss)
I0615 15:45:50.219481 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.268123 (* 1 = 0.268123 loss)
I0615 15:45:50.219485 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173839 (* 1 = 0.0173839 loss)
I0615 15:45:50.219489 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.423479 (* 1 = 0.423479 loss)
I0615 15:45:50.219494 15760 sgd_solver.cpp:106] Iteration 28540, lr = 0.0002
I0615 15:47:36.576896 15760 solver.cpp:228] Iteration 28560, loss = 0.377063
I0615 15:47:36.576922 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 15:47:36.576932 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.1149 (* 1 = 0.1149 loss)
I0615 15:47:36.576942 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0567389 (* 1 = 0.0567389 loss)
I0615 15:47:36.576951 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000429642 (* 1 = 0.000429642 loss)
I0615 15:47:36.576956 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106295 (* 1 = 0.0106295 loss)
I0615 15:47:36.576963 15760 sgd_solver.cpp:106] Iteration 28560, lr = 0.0002
I0615 15:49:23.098827 15760 solver.cpp:228] Iteration 28580, loss = 0.665517
I0615 15:49:23.098856 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 15:49:23.098865 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.319084 (* 1 = 0.319084 loss)
I0615 15:49:23.098867 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.400278 (* 1 = 0.400278 loss)
I0615 15:49:23.098871 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052921 (* 1 = 0.0052921 loss)
I0615 15:49:23.098875 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.065319 (* 1 = 0.065319 loss)
I0615 15:49:23.098879 15760 sgd_solver.cpp:106] Iteration 28580, lr = 0.0002
speed: 5.330s / iter
I0615 15:51:09.579459 15760 solver.cpp:228] Iteration 28600, loss = 0.337458
I0615 15:51:09.579483 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 15:51:09.579489 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0697845 (* 1 = 0.0697845 loss)
I0615 15:51:09.579493 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0439033 (* 1 = 0.0439033 loss)
I0615 15:51:09.579496 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000279291 (* 1 = 0.000279291 loss)
I0615 15:51:09.579500 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208727 (* 1 = 0.0208727 loss)
I0615 15:51:09.579504 15760 sgd_solver.cpp:106] Iteration 28600, lr = 0.0002
I0615 15:52:55.774888 15760 solver.cpp:228] Iteration 28620, loss = 0.38382
I0615 15:52:55.774910 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 15:52:55.774916 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0693194 (* 1 = 0.0693194 loss)
I0615 15:52:55.774920 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0505273 (* 1 = 0.0505273 loss)
I0615 15:52:55.774924 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000722897 (* 1 = 0.000722897 loss)
I0615 15:52:55.774927 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123198 (* 1 = 0.0123198 loss)
I0615 15:52:55.774932 15760 sgd_solver.cpp:106] Iteration 28620, lr = 0.0002
I0615 15:54:42.695937 15760 solver.cpp:228] Iteration 28640, loss = 0.802168
I0615 15:54:42.695962 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 15:54:42.695968 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.628848 (* 1 = 0.628848 loss)
I0615 15:54:42.695972 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.311232 (* 1 = 0.311232 loss)
I0615 15:54:42.695976 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00258936 (* 1 = 0.00258936 loss)
I0615 15:54:42.695979 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.17617 (* 1 = 0.17617 loss)
I0615 15:54:42.695984 15760 sgd_solver.cpp:106] Iteration 28640, lr = 0.0002
I0615 15:56:29.144611 15760 solver.cpp:228] Iteration 28660, loss = 0.298833
I0615 15:56:29.144634 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 15:56:29.144641 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.199825 (* 1 = 0.199825 loss)
I0615 15:56:29.144645 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.206744 (* 1 = 0.206744 loss)
I0615 15:56:29.144649 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0011971 (* 1 = 0.0011971 loss)
I0615 15:56:29.144651 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0470501 (* 1 = 0.0470501 loss)
I0615 15:56:29.144657 15760 sgd_solver.cpp:106] Iteration 28660, lr = 0.0002
I0615 15:58:15.495882 15760 solver.cpp:228] Iteration 28680, loss = 0.549876
I0615 15:58:15.495911 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 15:58:15.495918 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.186314 (* 1 = 0.186314 loss)
I0615 15:58:15.495923 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.165664 (* 1 = 0.165664 loss)
I0615 15:58:15.495928 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016008 (* 1 = 0.0016008 loss)
I0615 15:58:15.495930 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251554 (* 1 = 0.0251554 loss)
I0615 15:58:15.495936 15760 sgd_solver.cpp:106] Iteration 28680, lr = 0.0002
I0615 16:00:02.002148 15760 solver.cpp:228] Iteration 28700, loss = 0.308069
I0615 16:00:02.002172 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 16:00:02.002180 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.148562 (* 1 = 0.148562 loss)
I0615 16:00:02.002184 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130991 (* 1 = 0.130991 loss)
I0615 16:00:02.002188 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260028 (* 1 = 0.00260028 loss)
I0615 16:00:02.002192 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0407957 (* 1 = 0.0407957 loss)
I0615 16:00:02.002197 15760 sgd_solver.cpp:106] Iteration 28700, lr = 0.0002
I0615 16:01:48.436894 15760 solver.cpp:228] Iteration 28720, loss = 0.319044
I0615 16:01:48.436918 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 16:01:48.436924 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0872306 (* 1 = 0.0872306 loss)
I0615 16:01:48.436928 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0842483 (* 1 = 0.0842483 loss)
I0615 16:01:48.436931 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000339096 (* 1 = 0.000339096 loss)
I0615 16:01:48.436935 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130746 (* 1 = 0.0130746 loss)
I0615 16:01:48.436944 15760 sgd_solver.cpp:106] Iteration 28720, lr = 0.0002
I0615 16:03:35.312849 15760 solver.cpp:228] Iteration 28740, loss = 0.439181
I0615 16:03:35.312873 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 16:03:35.312881 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12281 (* 1 = 0.12281 loss)
I0615 16:03:35.312885 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.161587 (* 1 = 0.161587 loss)
I0615 16:03:35.312888 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162154 (* 1 = 0.0162154 loss)
I0615 16:03:35.312891 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.226506 (* 1 = 0.226506 loss)
I0615 16:03:35.312896 15760 sgd_solver.cpp:106] Iteration 28740, lr = 0.0002
I0615 16:05:21.701223 15760 solver.cpp:228] Iteration 28760, loss = 0.431015
I0615 16:05:21.701249 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 16:05:21.701256 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.175596 (* 1 = 0.175596 loss)
I0615 16:05:21.701261 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.185623 (* 1 = 0.185623 loss)
I0615 16:05:21.701265 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00788523 (* 1 = 0.00788523 loss)
I0615 16:05:21.701268 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128352 (* 1 = 0.128352 loss)
I0615 16:05:21.701273 15760 sgd_solver.cpp:106] Iteration 28760, lr = 0.0002
I0615 16:07:08.537886 15760 solver.cpp:228] Iteration 28780, loss = 0.316354
I0615 16:07:08.537912 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 16:07:08.537919 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.362607 (* 1 = 0.362607 loss)
I0615 16:07:08.537923 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.323486 (* 1 = 0.323486 loss)
I0615 16:07:08.537927 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00340515 (* 1 = 0.00340515 loss)
I0615 16:07:08.537931 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0607349 (* 1 = 0.0607349 loss)
I0615 16:07:08.537937 15760 sgd_solver.cpp:106] Iteration 28780, lr = 0.0002
speed: 5.330s / iter
I0615 16:08:55.034428 15760 solver.cpp:228] Iteration 28800, loss = 0.498919
I0615 16:08:55.034456 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 16:08:55.034463 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.383438 (* 1 = 0.383438 loss)
I0615 16:08:55.034467 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.294154 (* 1 = 0.294154 loss)
I0615 16:08:55.034471 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000263673 (* 1 = 0.000263673 loss)
I0615 16:08:55.034476 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0409979 (* 1 = 0.0409979 loss)
I0615 16:08:55.034482 15760 sgd_solver.cpp:106] Iteration 28800, lr = 0.0002
I0615 16:10:41.477082 15760 solver.cpp:228] Iteration 28820, loss = 0.41221
I0615 16:10:41.477107 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 16:10:41.477114 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0572449 (* 1 = 0.0572449 loss)
I0615 16:10:41.477118 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0620608 (* 1 = 0.0620608 loss)
I0615 16:10:41.477123 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00054401 (* 1 = 0.00054401 loss)
I0615 16:10:41.477126 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00242034 (* 1 = 0.00242034 loss)
I0615 16:10:41.477133 15760 sgd_solver.cpp:106] Iteration 28820, lr = 0.0002
I0615 16:12:28.121393 15760 solver.cpp:228] Iteration 28840, loss = 0.309781
I0615 16:12:28.121418 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 16:12:28.121425 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541327 (* 1 = 0.0541327 loss)
I0615 16:12:28.121429 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0308625 (* 1 = 0.0308625 loss)
I0615 16:12:28.121433 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013694 (* 1 = 0.013694 loss)
I0615 16:12:28.121438 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219017 (* 1 = 0.0219017 loss)
I0615 16:12:28.121441 15760 sgd_solver.cpp:106] Iteration 28840, lr = 0.0002
I0615 16:14:15.387054 15760 solver.cpp:228] Iteration 28860, loss = 0.502801
I0615 16:14:15.387080 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 16:14:15.387090 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.391296 (* 1 = 0.391296 loss)
I0615 16:14:15.387096 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.358082 (* 1 = 0.358082 loss)
I0615 16:14:15.387102 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00357753 (* 1 = 0.00357753 loss)
I0615 16:14:15.387109 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0862511 (* 1 = 0.0862511 loss)
I0615 16:14:15.387117 15760 sgd_solver.cpp:106] Iteration 28860, lr = 0.0002
I0615 16:16:02.855816 15760 solver.cpp:228] Iteration 28880, loss = 0.36823
I0615 16:16:02.855840 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 16:16:02.855847 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0960535 (* 1 = 0.0960535 loss)
I0615 16:16:02.855851 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.216231 (* 1 = 0.216231 loss)
I0615 16:16:02.855854 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244151 (* 1 = 0.0244151 loss)
I0615 16:16:02.855859 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.281177 (* 1 = 0.281177 loss)
I0615 16:16:02.855862 15760 sgd_solver.cpp:106] Iteration 28880, lr = 0.0002
I0615 16:17:50.347162 15760 solver.cpp:228] Iteration 28900, loss = 0.2987
I0615 16:17:50.347187 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 16:17:50.347194 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.204574 (* 1 = 0.204574 loss)
I0615 16:17:50.347198 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.372626 (* 1 = 0.372626 loss)
I0615 16:17:50.347203 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00528838 (* 1 = 0.00528838 loss)
I0615 16:17:50.347206 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.294543 (* 1 = 0.294543 loss)
I0615 16:17:50.347211 15760 sgd_solver.cpp:106] Iteration 28900, lr = 0.0002
I0615 16:19:37.190831 15760 solver.cpp:228] Iteration 28920, loss = 0.240092
I0615 16:19:37.190857 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 16:19:37.190865 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.305121 (* 1 = 0.305121 loss)
I0615 16:19:37.190870 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.153218 (* 1 = 0.153218 loss)
I0615 16:19:37.190873 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00172014 (* 1 = 0.00172014 loss)
I0615 16:19:37.190877 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0506097 (* 1 = 0.0506097 loss)
I0615 16:19:37.190882 15760 sgd_solver.cpp:106] Iteration 28920, lr = 0.0002
I0615 16:21:24.048025 15760 solver.cpp:228] Iteration 28940, loss = 0.392895
I0615 16:21:24.048051 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 16:21:24.048059 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0401701 (* 1 = 0.0401701 loss)
I0615 16:21:24.048063 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.023393 (* 1 = 0.023393 loss)
I0615 16:21:24.048068 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00400887 (* 1 = 0.00400887 loss)
I0615 16:21:24.048071 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00479544 (* 1 = 0.00479544 loss)
I0615 16:21:24.048076 15760 sgd_solver.cpp:106] Iteration 28940, lr = 0.0002
I0615 16:23:11.432756 15760 solver.cpp:228] Iteration 28960, loss = 0.29378
I0615 16:23:11.432780 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 16:23:11.432787 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.224536 (* 1 = 0.224536 loss)
I0615 16:23:11.432791 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.179058 (* 1 = 0.179058 loss)
I0615 16:23:11.432796 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216399 (* 1 = 0.00216399 loss)
I0615 16:23:11.432798 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0605535 (* 1 = 0.0605535 loss)
I0615 16:23:11.432803 15760 sgd_solver.cpp:106] Iteration 28960, lr = 0.0002
I0615 16:24:58.270792 15760 solver.cpp:228] Iteration 28980, loss = 0.484014
I0615 16:24:58.270815 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 16:24:58.270823 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.173532 (* 1 = 0.173532 loss)
I0615 16:24:58.270826 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.210653 (* 1 = 0.210653 loss)
I0615 16:24:58.270829 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00832446 (* 1 = 0.00832446 loss)
I0615 16:24:58.270833 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0707551 (* 1 = 0.0707551 loss)
I0615 16:24:58.270838 15760 sgd_solver.cpp:106] Iteration 28980, lr = 0.0002
speed: 5.330s / iter
I0615 16:26:44.820817 15760 solver.cpp:228] Iteration 29000, loss = 0.503762
I0615 16:26:44.820842 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 16:26:44.820848 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.39314 (* 1 = 0.39314 loss)
I0615 16:26:44.820852 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.309775 (* 1 = 0.309775 loss)
I0615 16:26:44.820855 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00401332 (* 1 = 0.00401332 loss)
I0615 16:26:44.820859 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0750549 (* 1 = 0.0750549 loss)
I0615 16:26:44.820863 15760 sgd_solver.cpp:106] Iteration 29000, lr = 0.0002
I0615 16:28:31.546427 15760 solver.cpp:228] Iteration 29020, loss = 0.297312
I0615 16:28:31.546452 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 16:28:31.546459 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109597 (* 1 = 0.109597 loss)
I0615 16:28:31.546463 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.099941 (* 1 = 0.099941 loss)
I0615 16:28:31.546468 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102024 (* 1 = 0.00102024 loss)
I0615 16:28:31.546471 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200236 (* 1 = 0.0200236 loss)
I0615 16:28:31.546476 15760 sgd_solver.cpp:106] Iteration 29020, lr = 0.0002
I0615 16:30:17.836182 15760 solver.cpp:228] Iteration 29040, loss = 0.335376
I0615 16:30:17.836207 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 16:30:17.836215 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0406729 (* 1 = 0.0406729 loss)
I0615 16:30:17.836220 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0475326 (* 1 = 0.0475326 loss)
I0615 16:30:17.836223 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00177835 (* 1 = 0.00177835 loss)
I0615 16:30:17.836228 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182296 (* 1 = 0.0182296 loss)
I0615 16:30:17.836233 15760 sgd_solver.cpp:106] Iteration 29040, lr = 0.0002
I0615 16:32:04.286412 15760 solver.cpp:228] Iteration 29060, loss = 0.508245
I0615 16:32:04.286437 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 16:32:04.286442 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.169161 (* 1 = 0.169161 loss)
I0615 16:32:04.286447 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.162355 (* 1 = 0.162355 loss)
I0615 16:32:04.286450 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000247259 (* 1 = 0.000247259 loss)
I0615 16:32:04.286453 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309994 (* 1 = 0.0309994 loss)
I0615 16:32:04.286458 15760 sgd_solver.cpp:106] Iteration 29060, lr = 0.0002
I0615 16:33:50.618598 15760 solver.cpp:228] Iteration 29080, loss = 0.211185
I0615 16:33:50.618621 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 16:33:50.618628 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739363 (* 1 = 0.0739363 loss)
I0615 16:33:50.618633 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0215342 (* 1 = 0.0215342 loss)
I0615 16:33:50.618636 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00621841 (* 1 = 0.00621841 loss)
I0615 16:33:50.618639 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108529 (* 1 = 0.0108529 loss)
I0615 16:33:50.618643 15760 sgd_solver.cpp:106] Iteration 29080, lr = 0.0002
I0615 16:35:36.982908 15760 solver.cpp:228] Iteration 29100, loss = 0.410533
I0615 16:35:36.982933 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 16:35:36.982939 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.190085 (* 1 = 0.190085 loss)
I0615 16:35:36.982945 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.228886 (* 1 = 0.228886 loss)
I0615 16:35:36.982952 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00109384 (* 1 = 0.00109384 loss)
I0615 16:35:36.982956 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105263 (* 1 = 0.105263 loss)
I0615 16:35:36.982962 15760 sgd_solver.cpp:106] Iteration 29100, lr = 0.0002
I0615 16:37:23.397807 15760 solver.cpp:228] Iteration 29120, loss = 0.364905
I0615 16:37:23.397831 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 16:37:23.397840 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0626788 (* 1 = 0.0626788 loss)
I0615 16:37:23.397843 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.166034 (* 1 = 0.166034 loss)
I0615 16:37:23.397846 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000244268 (* 1 = 0.000244268 loss)
I0615 16:37:23.397850 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131165 (* 1 = 0.0131165 loss)
I0615 16:37:23.397855 15760 sgd_solver.cpp:106] Iteration 29120, lr = 0.0002
I0615 16:39:09.692575 15760 solver.cpp:228] Iteration 29140, loss = 0.38751
I0615 16:39:09.692598 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 16:39:09.692608 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.110339 (* 1 = 0.110339 loss)
I0615 16:39:09.692615 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0517314 (* 1 = 0.0517314 loss)
I0615 16:39:09.692620 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000165315 (* 1 = 0.000165315 loss)
I0615 16:39:09.692625 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169407 (* 1 = 0.0169407 loss)
I0615 16:39:09.692632 15760 sgd_solver.cpp:106] Iteration 29140, lr = 0.0002
I0615 16:40:56.062382 15760 solver.cpp:228] Iteration 29160, loss = 0.433956
I0615 16:40:56.062408 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 16:40:56.062417 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.165677 (* 1 = 0.165677 loss)
I0615 16:40:56.062422 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.265828 (* 1 = 0.265828 loss)
I0615 16:40:56.062427 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026694 (* 1 = 0.0026694 loss)
I0615 16:40:56.062430 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.220775 (* 1 = 0.220775 loss)
I0615 16:40:56.062436 15760 sgd_solver.cpp:106] Iteration 29160, lr = 0.0002
I0615 16:42:42.396086 15760 solver.cpp:228] Iteration 29180, loss = 0.367398
I0615 16:42:42.396109 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 16:42:42.396116 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465597 (* 1 = 0.0465597 loss)
I0615 16:42:42.396121 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0388016 (* 1 = 0.0388016 loss)
I0615 16:42:42.396124 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0011083 (* 1 = 0.0011083 loss)
I0615 16:42:42.396127 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100846 (* 1 = 0.0100846 loss)
I0615 16:42:42.396131 15760 sgd_solver.cpp:106] Iteration 29180, lr = 0.0002
speed: 5.330s / iter
I0615 16:44:28.777734 15760 solver.cpp:228] Iteration 29200, loss = 0.208586
I0615 16:44:28.777758 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 16:44:28.777766 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0774239 (* 1 = 0.0774239 loss)
I0615 16:44:28.777770 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0554949 (* 1 = 0.0554949 loss)
I0615 16:44:28.777775 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.67939e-05 (* 1 = 4.67939e-05 loss)
I0615 16:44:28.777778 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00963105 (* 1 = 0.00963105 loss)
I0615 16:44:28.777783 15760 sgd_solver.cpp:106] Iteration 29200, lr = 0.0002
I0615 16:46:15.479185 15760 solver.cpp:228] Iteration 29220, loss = 0.39583
I0615 16:46:15.479210 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 16:46:15.479218 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.172103 (* 1 = 0.172103 loss)
I0615 16:46:15.479220 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.134944 (* 1 = 0.134944 loss)
I0615 16:46:15.479224 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000340268 (* 1 = 0.000340268 loss)
I0615 16:46:15.479228 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120834 (* 1 = 0.0120834 loss)
I0615 16:46:15.479233 15760 sgd_solver.cpp:106] Iteration 29220, lr = 0.0002
I0615 16:48:01.945920 15760 solver.cpp:228] Iteration 29240, loss = 0.466145
I0615 16:48:01.945945 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 16:48:01.945951 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0593964 (* 1 = 0.0593964 loss)
I0615 16:48:01.945956 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0456754 (* 1 = 0.0456754 loss)
I0615 16:48:01.945960 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00142615 (* 1 = 0.00142615 loss)
I0615 16:48:01.945964 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00680021 (* 1 = 0.00680021 loss)
I0615 16:48:01.945968 15760 sgd_solver.cpp:106] Iteration 29240, lr = 0.0002
I0615 16:49:48.508561 15760 solver.cpp:228] Iteration 29260, loss = 0.456958
I0615 16:49:48.508584 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 16:49:48.508591 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.205069 (* 1 = 0.205069 loss)
I0615 16:49:48.508595 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.177846 (* 1 = 0.177846 loss)
I0615 16:49:48.508599 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210212 (* 1 = 0.0210212 loss)
I0615 16:49:48.508604 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0644801 (* 1 = 0.0644801 loss)
I0615 16:49:48.508608 15760 sgd_solver.cpp:106] Iteration 29260, lr = 0.0002
I0615 16:51:34.970867 15760 solver.cpp:228] Iteration 29280, loss = 0.521249
I0615 16:51:34.970892 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 16:51:34.970899 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0720951 (* 1 = 0.0720951 loss)
I0615 16:51:34.970904 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0783639 (* 1 = 0.0783639 loss)
I0615 16:51:34.970907 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000352193 (* 1 = 0.000352193 loss)
I0615 16:51:34.970912 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00617391 (* 1 = 0.00617391 loss)
I0615 16:51:34.970917 15760 sgd_solver.cpp:106] Iteration 29280, lr = 0.0002
I0615 16:53:22.182265 15760 solver.cpp:228] Iteration 29300, loss = 0.299095
I0615 16:53:22.182291 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0615 16:53:22.182301 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.324438 (* 1 = 0.324438 loss)
I0615 16:53:22.182307 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.258233 (* 1 = 0.258233 loss)
I0615 16:53:22.182313 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173957 (* 1 = 0.00173957 loss)
I0615 16:53:22.182319 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0464745 (* 1 = 0.0464745 loss)
I0615 16:53:22.182327 15760 sgd_solver.cpp:106] Iteration 29300, lr = 0.0002
I0615 16:55:09.055099 15760 solver.cpp:228] Iteration 29320, loss = 0.565917
I0615 16:55:09.055124 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0615 16:55:09.055133 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.504689 (* 1 = 0.504689 loss)
I0615 16:55:09.055140 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.644637 (* 1 = 0.644637 loss)
I0615 16:55:09.055145 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0972975 (* 1 = 0.0972975 loss)
I0615 16:55:09.055150 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.362857 (* 1 = 0.362857 loss)
I0615 16:55:09.055157 15760 sgd_solver.cpp:106] Iteration 29320, lr = 0.0002
I0615 16:56:56.083571 15760 solver.cpp:228] Iteration 29340, loss = 0.231263
I0615 16:56:56.083597 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 16:56:56.083604 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.103579 (* 1 = 0.103579 loss)
I0615 16:56:56.083608 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0645596 (* 1 = 0.0645596 loss)
I0615 16:56:56.083612 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101513 (* 1 = 0.00101513 loss)
I0615 16:56:56.083616 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241355 (* 1 = 0.0241355 loss)
I0615 16:56:56.083621 15760 sgd_solver.cpp:106] Iteration 29340, lr = 0.0002
I0615 16:58:42.964860 15760 solver.cpp:228] Iteration 29360, loss = 0.34694
I0615 16:58:42.964885 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 16:58:42.964893 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737886 (* 1 = 0.0737886 loss)
I0615 16:58:42.964897 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.11763 (* 1 = 0.11763 loss)
I0615 16:58:42.964901 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.40645e-05 (* 1 = 8.40645e-05 loss)
I0615 16:58:42.964905 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101337 (* 1 = 0.0101337 loss)
I0615 16:58:42.964910 15760 sgd_solver.cpp:106] Iteration 29360, lr = 0.0002
I0615 17:00:30.506093 15760 solver.cpp:228] Iteration 29380, loss = 0.248903
I0615 17:00:30.506121 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 17:00:30.506131 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.113495 (* 1 = 0.113495 loss)
I0615 17:00:30.506136 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.12892 (* 1 = 0.12892 loss)
I0615 17:00:30.506141 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122346 (* 1 = 0.00122346 loss)
I0615 17:00:30.506145 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267526 (* 1 = 0.0267526 loss)
I0615 17:00:30.506152 15760 sgd_solver.cpp:106] Iteration 29380, lr = 0.0002
speed: 5.330s / iter
I0615 17:02:17.247012 15760 solver.cpp:228] Iteration 29400, loss = 0.296524
I0615 17:02:17.247035 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 17:02:17.247043 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0874883 (* 1 = 0.0874883 loss)
I0615 17:02:17.247047 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.112612 (* 1 = 0.112612 loss)
I0615 17:02:17.247051 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000107233 (* 1 = 0.000107233 loss)
I0615 17:02:17.247054 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00661325 (* 1 = 0.00661325 loss)
I0615 17:02:17.247058 15760 sgd_solver.cpp:106] Iteration 29400, lr = 0.0002
I0615 17:04:03.777962 15760 solver.cpp:228] Iteration 29420, loss = 0.299794
I0615 17:04:03.777987 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 17:04:03.777995 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0616269 (* 1 = 0.0616269 loss)
I0615 17:04:03.777999 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0582238 (* 1 = 0.0582238 loss)
I0615 17:04:03.778003 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000276374 (* 1 = 0.000276374 loss)
I0615 17:04:03.778007 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00456304 (* 1 = 0.00456304 loss)
I0615 17:04:03.778012 15760 sgd_solver.cpp:106] Iteration 29420, lr = 0.0002
I0615 17:05:50.965312 15760 solver.cpp:228] Iteration 29440, loss = 0.422076
I0615 17:05:50.965339 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 17:05:50.965346 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.16636 (* 1 = 0.16636 loss)
I0615 17:05:50.965351 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.130702 (* 1 = 0.130702 loss)
I0615 17:05:50.965355 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338837 (* 1 = 0.00338837 loss)
I0615 17:05:50.965359 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0801064 (* 1 = 0.0801064 loss)
I0615 17:05:50.965364 15760 sgd_solver.cpp:106] Iteration 29440, lr = 0.0002
I0615 17:07:37.892758 15760 solver.cpp:228] Iteration 29460, loss = 0.506298
I0615 17:07:37.892787 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 17:07:37.892794 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0429512 (* 1 = 0.0429512 loss)
I0615 17:07:37.892798 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.036457 (* 1 = 0.036457 loss)
I0615 17:07:37.892802 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120811 (* 1 = 0.00120811 loss)
I0615 17:07:37.892807 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113658 (* 1 = 0.0113658 loss)
I0615 17:07:37.892812 15760 sgd_solver.cpp:106] Iteration 29460, lr = 0.0002
I0615 17:09:24.890343 15760 solver.cpp:228] Iteration 29480, loss = 0.367851
I0615 17:09:24.890367 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 17:09:24.890374 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.124831 (* 1 = 0.124831 loss)
I0615 17:09:24.890378 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.198885 (* 1 = 0.198885 loss)
I0615 17:09:24.890383 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245983 (* 1 = 0.00245983 loss)
I0615 17:09:24.890385 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0693183 (* 1 = 0.0693183 loss)
I0615 17:09:24.890389 15760 sgd_solver.cpp:106] Iteration 29480, lr = 0.0002
I0615 17:11:11.189882 15760 solver.cpp:228] Iteration 29500, loss = 0.256253
I0615 17:11:11.189908 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 17:11:11.189914 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.174078 (* 1 = 0.174078 loss)
I0615 17:11:11.189918 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.159072 (* 1 = 0.159072 loss)
I0615 17:11:11.189923 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000157812 (* 1 = 0.000157812 loss)
I0615 17:11:11.189926 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269539 (* 1 = 0.0269539 loss)
I0615 17:11:11.189931 15760 sgd_solver.cpp:106] Iteration 29500, lr = 0.0002
I0615 17:12:57.612653 15760 solver.cpp:228] Iteration 29520, loss = 0.40893
I0615 17:12:57.612677 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 17:12:57.612684 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0490652 (* 1 = 0.0490652 loss)
I0615 17:12:57.612687 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.076888 (* 1 = 0.076888 loss)
I0615 17:12:57.612691 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.87609e-05 (* 1 = 7.87609e-05 loss)
I0615 17:12:57.612694 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114605 (* 1 = 0.0114605 loss)
I0615 17:12:57.612699 15760 sgd_solver.cpp:106] Iteration 29520, lr = 0.0002
I0615 17:14:44.183416 15760 solver.cpp:228] Iteration 29540, loss = 0.303758
I0615 17:14:44.183447 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 17:14:44.183457 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.377364 (* 1 = 0.377364 loss)
I0615 17:14:44.183462 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.335659 (* 1 = 0.335659 loss)
I0615 17:14:44.183467 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130894 (* 1 = 0.0130894 loss)
I0615 17:14:44.183472 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12566 (* 1 = 0.12566 loss)
I0615 17:14:44.183480 15760 sgd_solver.cpp:106] Iteration 29540, lr = 0.0002
I0615 17:16:30.423115 15760 solver.cpp:228] Iteration 29560, loss = 0.246851
I0615 17:16:30.423138 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 17:16:30.423146 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0581951 (* 1 = 0.0581951 loss)
I0615 17:16:30.423149 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0448751 (* 1 = 0.0448751 loss)
I0615 17:16:30.423153 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00524458 (* 1 = 0.00524458 loss)
I0615 17:16:30.423156 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379348 (* 1 = 0.0379348 loss)
I0615 17:16:30.423161 15760 sgd_solver.cpp:106] Iteration 29560, lr = 0.0002
I0615 17:18:16.786480 15760 solver.cpp:228] Iteration 29580, loss = 0.297382
I0615 17:18:16.786509 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 17:18:16.786515 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0934715 (* 1 = 0.0934715 loss)
I0615 17:18:16.786520 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0849413 (* 1 = 0.0849413 loss)
I0615 17:18:16.786523 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00041031 (* 1 = 0.00041031 loss)
I0615 17:18:16.786526 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342944 (* 1 = 0.0342944 loss)
I0615 17:18:16.786532 15760 sgd_solver.cpp:106] Iteration 29580, lr = 0.0002
speed: 5.330s / iter
I0615 17:20:03.321483 15760 solver.cpp:228] Iteration 29600, loss = 0.468166
I0615 17:20:03.321511 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 17:20:03.321517 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0275216 (* 1 = 0.0275216 loss)
I0615 17:20:03.321522 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0208042 (* 1 = 0.0208042 loss)
I0615 17:20:03.321527 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118482 (* 1 = 0.00118482 loss)
I0615 17:20:03.321530 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264608 (* 1 = 0.0264608 loss)
I0615 17:20:03.321535 15760 sgd_solver.cpp:106] Iteration 29600, lr = 0.0002
I0615 17:21:49.669539 15760 solver.cpp:228] Iteration 29620, loss = 0.444807
I0615 17:21:49.669561 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 17:21:49.669569 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0676602 (* 1 = 0.0676602 loss)
I0615 17:21:49.669572 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0488657 (* 1 = 0.0488657 loss)
I0615 17:21:49.669575 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150573 (* 1 = 0.00150573 loss)
I0615 17:21:49.669579 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00453996 (* 1 = 0.00453996 loss)
I0615 17:21:49.669584 15760 sgd_solver.cpp:106] Iteration 29620, lr = 0.0002
I0615 17:23:35.948998 15760 solver.cpp:228] Iteration 29640, loss = 0.405985
I0615 17:23:35.949023 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 17:23:35.949029 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.084252 (* 1 = 0.084252 loss)
I0615 17:23:35.949033 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0434347 (* 1 = 0.0434347 loss)
I0615 17:23:35.949038 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000133011 (* 1 = 0.000133011 loss)
I0615 17:23:35.949040 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00790044 (* 1 = 0.00790044 loss)
I0615 17:23:35.949045 15760 sgd_solver.cpp:106] Iteration 29640, lr = 0.0002
I0615 17:25:22.466078 15760 solver.cpp:228] Iteration 29660, loss = 0.446231
I0615 17:25:22.466102 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 17:25:22.466109 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.108184 (* 1 = 0.108184 loss)
I0615 17:25:22.466114 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0879922 (* 1 = 0.0879922 loss)
I0615 17:25:22.466118 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000173985 (* 1 = 0.000173985 loss)
I0615 17:25:22.466122 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00782347 (* 1 = 0.00782347 loss)
I0615 17:25:22.466127 15760 sgd_solver.cpp:106] Iteration 29660, lr = 0.0002
I0615 17:27:08.866212 15760 solver.cpp:228] Iteration 29680, loss = 0.254965
I0615 17:27:08.866238 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 17:27:08.866246 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0709972 (* 1 = 0.0709972 loss)
I0615 17:27:08.866250 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0590266 (* 1 = 0.0590266 loss)
I0615 17:27:08.866255 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000337151 (* 1 = 0.000337151 loss)
I0615 17:27:08.866258 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00495487 (* 1 = 0.00495487 loss)
I0615 17:27:08.866263 15760 sgd_solver.cpp:106] Iteration 29680, lr = 0.0002
I0615 17:28:55.118820 15760 solver.cpp:228] Iteration 29700, loss = 0.452886
I0615 17:28:55.118844 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0615 17:28:55.118854 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.566202 (* 1 = 0.566202 loss)
I0615 17:28:55.118860 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.393807 (* 1 = 0.393807 loss)
I0615 17:28:55.118865 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366819 (* 1 = 0.0366819 loss)
I0615 17:28:55.118870 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.508905 (* 1 = 0.508905 loss)
I0615 17:28:55.118875 15760 sgd_solver.cpp:106] Iteration 29700, lr = 0.0002
I0615 17:30:41.530267 15760 solver.cpp:228] Iteration 29720, loss = 0.507323
I0615 17:30:41.530288 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 17:30:41.530295 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719166 (* 1 = 0.0719166 loss)
I0615 17:30:41.530303 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0693146 (* 1 = 0.0693146 loss)
I0615 17:30:41.530309 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.28324e-05 (* 1 = 6.28324e-05 loss)
I0615 17:30:41.530313 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102545 (* 1 = 0.0102545 loss)
I0615 17:30:41.530319 15760 sgd_solver.cpp:106] Iteration 29720, lr = 0.0002
I0615 17:32:27.812404 15760 solver.cpp:228] Iteration 29740, loss = 0.374614
I0615 17:32:27.812431 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 17:32:27.812439 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.149378 (* 1 = 0.149378 loss)
I0615 17:32:27.812443 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.13057 (* 1 = 0.13057 loss)
I0615 17:32:27.812448 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000553697 (* 1 = 0.000553697 loss)
I0615 17:32:27.812451 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01475 (* 1 = 0.01475 loss)
I0615 17:32:27.812458 15760 sgd_solver.cpp:106] Iteration 29740, lr = 0.0002
I0615 17:34:14.184818 15760 solver.cpp:228] Iteration 29760, loss = 0.26598
I0615 17:34:14.184841 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 17:34:14.184849 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0747681 (* 1 = 0.0747681 loss)
I0615 17:34:14.184851 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0740714 (* 1 = 0.0740714 loss)
I0615 17:34:14.184855 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00161145 (* 1 = 0.00161145 loss)
I0615 17:34:14.184859 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200251 (* 1 = 0.0200251 loss)
I0615 17:34:14.184864 15760 sgd_solver.cpp:106] Iteration 29760, lr = 0.0002
I0615 17:36:00.754668 15760 solver.cpp:228] Iteration 29780, loss = 0.46102
I0615 17:36:00.754694 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 17:36:00.754704 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.31682 (* 1 = 0.31682 loss)
I0615 17:36:00.754710 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.224081 (* 1 = 0.224081 loss)
I0615 17:36:00.754716 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577128 (* 1 = 0.00577128 loss)
I0615 17:36:00.754724 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.122187 (* 1 = 0.122187 loss)
I0615 17:36:00.754730 15760 sgd_solver.cpp:106] Iteration 29780, lr = 0.0002
speed: 5.330s / iter
I0615 17:37:48.143863 15760 solver.cpp:228] Iteration 29800, loss = 0.451036
I0615 17:37:48.143888 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 17:37:48.143898 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.190097 (* 1 = 0.190097 loss)
I0615 17:37:48.143905 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.263436 (* 1 = 0.263436 loss)
I0615 17:37:48.143911 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000236919 (* 1 = 0.000236919 loss)
I0615 17:37:48.143919 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0384737 (* 1 = 0.0384737 loss)
I0615 17:37:48.143929 15760 sgd_solver.cpp:106] Iteration 29800, lr = 0.0002
I0615 17:39:34.642690 15760 solver.cpp:228] Iteration 29820, loss = 0.22094
I0615 17:39:34.642717 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 17:39:34.642727 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.280282 (* 1 = 0.280282 loss)
I0615 17:39:34.642735 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.184102 (* 1 = 0.184102 loss)
I0615 17:39:34.642740 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000677543 (* 1 = 0.000677543 loss)
I0615 17:39:34.642747 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0399394 (* 1 = 0.0399394 loss)
I0615 17:39:34.642753 15760 sgd_solver.cpp:106] Iteration 29820, lr = 0.0002
I0615 17:41:22.091182 15760 solver.cpp:228] Iteration 29840, loss = 0.54857
I0615 17:41:22.091207 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 17:41:22.091213 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.522656 (* 1 = 0.522656 loss)
I0615 17:41:22.091217 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.358628 (* 1 = 0.358628 loss)
I0615 17:41:22.091222 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183252 (* 1 = 0.00183252 loss)
I0615 17:41:22.091225 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0921582 (* 1 = 0.0921582 loss)
I0615 17:41:22.091230 15760 sgd_solver.cpp:106] Iteration 29840, lr = 0.0002
I0615 17:43:08.439802 15760 solver.cpp:228] Iteration 29860, loss = 0.334532
I0615 17:43:08.439828 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 17:43:08.439836 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.234608 (* 1 = 0.234608 loss)
I0615 17:43:08.439841 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.252215 (* 1 = 0.252215 loss)
I0615 17:43:08.439844 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265078 (* 1 = 0.00265078 loss)
I0615 17:43:08.439848 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297369 (* 1 = 0.0297369 loss)
I0615 17:43:08.439854 15760 sgd_solver.cpp:106] Iteration 29860, lr = 0.0002
I0615 17:44:55.487291 15760 solver.cpp:228] Iteration 29880, loss = 0.229112
I0615 17:44:55.487316 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 17:44:55.487323 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0987227 (* 1 = 0.0987227 loss)
I0615 17:44:55.487329 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.139082 (* 1 = 0.139082 loss)
I0615 17:44:55.487332 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00222637 (* 1 = 0.00222637 loss)
I0615 17:44:55.487336 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244042 (* 1 = 0.0244042 loss)
I0615 17:44:55.487341 15760 sgd_solver.cpp:106] Iteration 29880, lr = 0.0002
I0615 17:46:42.473603 15760 solver.cpp:228] Iteration 29900, loss = 0.566524
I0615 17:46:42.473625 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 17:46:42.473632 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.156235 (* 1 = 0.156235 loss)
I0615 17:46:42.473635 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.204002 (* 1 = 0.204002 loss)
I0615 17:46:42.473639 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000185015 (* 1 = 0.000185015 loss)
I0615 17:46:42.473644 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215913 (* 1 = 0.0215913 loss)
I0615 17:46:42.473649 15760 sgd_solver.cpp:106] Iteration 29900, lr = 0.0002
I0615 17:48:28.880559 15760 solver.cpp:228] Iteration 29920, loss = 0.265134
I0615 17:48:28.880589 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 17:48:28.880597 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816938 (* 1 = 0.0816938 loss)
I0615 17:48:28.880604 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.107765 (* 1 = 0.107765 loss)
I0615 17:48:28.880609 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000661111 (* 1 = 0.000661111 loss)
I0615 17:48:28.880614 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0317855 (* 1 = 0.0317855 loss)
I0615 17:48:28.880620 15760 sgd_solver.cpp:106] Iteration 29920, lr = 0.0002
I0615 17:50:15.995208 15760 solver.cpp:228] Iteration 29940, loss = 0.381045
I0615 17:50:15.995234 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 17:50:15.995241 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0493134 (* 1 = 0.0493134 loss)
I0615 17:50:15.995245 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.116018 (* 1 = 0.116018 loss)
I0615 17:50:15.995249 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00736015 (* 1 = 0.00736015 loss)
I0615 17:50:15.995254 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028041 (* 1 = 0.028041 loss)
I0615 17:50:15.995259 15760 sgd_solver.cpp:106] Iteration 29940, lr = 0.0002
I0615 17:52:02.575181 15760 solver.cpp:228] Iteration 29960, loss = 0.331206
I0615 17:52:02.575206 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 17:52:02.575212 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.306479 (* 1 = 0.306479 loss)
I0615 17:52:02.575217 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.271219 (* 1 = 0.271219 loss)
I0615 17:52:02.575220 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000358081 (* 1 = 0.000358081 loss)
I0615 17:52:02.575224 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044891 (* 1 = 0.044891 loss)
I0615 17:52:02.575229 15760 sgd_solver.cpp:106] Iteration 29960, lr = 0.0002
I0615 17:53:49.262049 15760 solver.cpp:228] Iteration 29980, loss = 0.32608
I0615 17:53:49.262074 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 17:53:49.262081 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702535 (* 1 = 0.0702535 loss)
I0615 17:53:49.262086 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0956636 (* 1 = 0.0956636 loss)
I0615 17:53:49.262090 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000774497 (* 1 = 0.000774497 loss)
I0615 17:53:49.262094 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119048 (* 1 = 0.0119048 loss)
I0615 17:53:49.262099 15760 sgd_solver.cpp:106] Iteration 29980, lr = 0.0002
speed: 5.330s / iter
I0615 17:55:31.099957 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_30000.caffemodel
I0615 17:55:36.809018 15760 solver.cpp:228] Iteration 30000, loss = 0.274196
I0615 17:55:36.809043 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 17:55:36.809051 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.114857 (* 1 = 0.114857 loss)
I0615 17:55:36.809056 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0870051 (* 1 = 0.0870051 loss)
I0615 17:55:36.809060 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00348921 (* 1 = 0.00348921 loss)
I0615 17:55:36.809067 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00953712 (* 1 = 0.00953712 loss)
I0615 17:55:36.809072 15760 sgd_solver.cpp:106] Iteration 30000, lr = 0.0002
I0615 17:57:23.171330 15760 solver.cpp:228] Iteration 30020, loss = 0.399199
I0615 17:57:23.171357 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 17:57:23.171367 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.264362 (* 1 = 0.264362 loss)
I0615 17:57:23.171373 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.209227 (* 1 = 0.209227 loss)
I0615 17:57:23.171380 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000391799 (* 1 = 0.000391799 loss)
I0615 17:57:23.171386 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.038217 (* 1 = 0.038217 loss)
I0615 17:57:23.171393 15760 sgd_solver.cpp:106] Iteration 30020, lr = 0.0002
I0615 17:59:09.506765 15760 solver.cpp:228] Iteration 30040, loss = 0.207471
I0615 17:59:09.506791 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 17:59:09.506799 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0622095 (* 1 = 0.0622095 loss)
I0615 17:59:09.506803 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0745068 (* 1 = 0.0745068 loss)
I0615 17:59:09.506806 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000172051 (* 1 = 0.000172051 loss)
I0615 17:59:09.506810 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248799 (* 1 = 0.0248799 loss)
I0615 17:59:09.506815 15760 sgd_solver.cpp:106] Iteration 30040, lr = 0.0002
I0615 18:00:55.736377 15760 solver.cpp:228] Iteration 30060, loss = 0.24411
I0615 18:00:55.736402 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 18:00:55.736412 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0560947 (* 1 = 0.0560947 loss)
I0615 18:00:55.736418 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.023919 (* 1 = 0.023919 loss)
I0615 18:00:55.736423 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000861907 (* 1 = 0.000861907 loss)
I0615 18:00:55.736428 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00599266 (* 1 = 0.00599266 loss)
I0615 18:00:55.736434 15760 sgd_solver.cpp:106] Iteration 30060, lr = 0.0002
I0615 18:02:42.224066 15760 solver.cpp:228] Iteration 30080, loss = 0.616345
I0615 18:02:42.224087 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 18:02:42.224094 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.299046 (* 1 = 0.299046 loss)
I0615 18:02:42.224098 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20362 (* 1 = 0.20362 loss)
I0615 18:02:42.224102 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0059019 (* 1 = 0.0059019 loss)
I0615 18:02:42.224105 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.099808 (* 1 = 0.099808 loss)
I0615 18:02:42.224110 15760 sgd_solver.cpp:106] Iteration 30080, lr = 0.0002
I0615 18:04:28.647020 15760 solver.cpp:228] Iteration 30100, loss = 0.318996
I0615 18:04:28.647044 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 18:04:28.647052 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0525862 (* 1 = 0.0525862 loss)
I0615 18:04:28.647055 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0649095 (* 1 = 0.0649095 loss)
I0615 18:04:28.647059 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179241 (* 1 = 0.0179241 loss)
I0615 18:04:28.647063 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220982 (* 1 = 0.0220982 loss)
I0615 18:04:28.647068 15760 sgd_solver.cpp:106] Iteration 30100, lr = 0.0002
I0615 18:06:14.967495 15760 solver.cpp:228] Iteration 30120, loss = 0.297588
I0615 18:06:14.967521 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 18:06:14.967530 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0570355 (* 1 = 0.0570355 loss)
I0615 18:06:14.967533 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.122528 (* 1 = 0.122528 loss)
I0615 18:06:14.967537 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000264609 (* 1 = 0.000264609 loss)
I0615 18:06:14.967541 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128501 (* 1 = 0.0128501 loss)
I0615 18:06:14.967546 15760 sgd_solver.cpp:106] Iteration 30120, lr = 0.0002
I0615 18:08:01.756244 15760 solver.cpp:228] Iteration 30140, loss = 0.7352
I0615 18:08:01.756273 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 18:08:01.756280 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0762258 (* 1 = 0.0762258 loss)
I0615 18:08:01.756284 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0567536 (* 1 = 0.0567536 loss)
I0615 18:08:01.756289 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115083 (* 1 = 0.00115083 loss)
I0615 18:08:01.756291 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109217 (* 1 = 0.0109217 loss)
I0615 18:08:01.756297 15760 sgd_solver.cpp:106] Iteration 30140, lr = 0.0002
I0615 18:09:48.301486 15760 solver.cpp:228] Iteration 30160, loss = 0.430418
I0615 18:09:48.301511 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 18:09:48.301518 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0913223 (* 1 = 0.0913223 loss)
I0615 18:09:48.301522 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0929752 (* 1 = 0.0929752 loss)
I0615 18:09:48.301527 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00386482 (* 1 = 0.00386482 loss)
I0615 18:09:48.301530 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211999 (* 1 = 0.0211999 loss)
I0615 18:09:48.301535 15760 sgd_solver.cpp:106] Iteration 30160, lr = 0.0002
I0615 18:11:34.744685 15760 solver.cpp:228] Iteration 30180, loss = 0.445353
I0615 18:11:34.744707 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 18:11:34.744714 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.204301 (* 1 = 0.204301 loss)
I0615 18:11:34.744719 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.29932 (* 1 = 0.29932 loss)
I0615 18:11:34.744722 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674107 (* 1 = 0.00674107 loss)
I0615 18:11:34.744726 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.360226 (* 1 = 0.360226 loss)
I0615 18:11:34.744731 15760 sgd_solver.cpp:106] Iteration 30180, lr = 0.0002
speed: 5.330s / iter
I0615 18:13:21.067919 15760 solver.cpp:228] Iteration 30200, loss = 0.517243
I0615 18:13:21.067945 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0615 18:13:21.067950 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.569427 (* 1 = 0.569427 loss)
I0615 18:13:21.067955 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.481754 (* 1 = 0.481754 loss)
I0615 18:13:21.067957 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00658038 (* 1 = 0.00658038 loss)
I0615 18:13:21.067961 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.372765 (* 1 = 0.372765 loss)
I0615 18:13:21.067966 15760 sgd_solver.cpp:106] Iteration 30200, lr = 0.0002
I0615 18:15:07.322767 15760 solver.cpp:228] Iteration 30220, loss = 0.312896
I0615 18:15:07.322789 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0615 18:15:07.322796 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.283287 (* 1 = 0.283287 loss)
I0615 18:15:07.322800 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.274919 (* 1 = 0.274919 loss)
I0615 18:15:07.322804 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00525517 (* 1 = 0.00525517 loss)
I0615 18:15:07.322808 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0633213 (* 1 = 0.0633213 loss)
I0615 18:15:07.322811 15760 sgd_solver.cpp:106] Iteration 30220, lr = 0.0002
I0615 18:16:53.837765 15760 solver.cpp:228] Iteration 30240, loss = 0.313386
I0615 18:16:53.837788 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 18:16:53.837795 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0424343 (* 1 = 0.0424343 loss)
I0615 18:16:53.837800 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0507492 (* 1 = 0.0507492 loss)
I0615 18:16:53.837803 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000184874 (* 1 = 0.000184874 loss)
I0615 18:16:53.837806 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131607 (* 1 = 0.0131607 loss)
I0615 18:16:53.837810 15760 sgd_solver.cpp:106] Iteration 30240, lr = 0.0002
I0615 18:18:40.056578 15760 solver.cpp:228] Iteration 30260, loss = 0.255587
I0615 18:18:40.056604 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 18:18:40.056613 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.070278 (* 1 = 0.070278 loss)
I0615 18:18:40.056620 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0611603 (* 1 = 0.0611603 loss)
I0615 18:18:40.056627 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.84716e-05 (* 1 = 8.84716e-05 loss)
I0615 18:18:40.056630 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214655 (* 1 = 0.0214655 loss)
I0615 18:18:40.056638 15760 sgd_solver.cpp:106] Iteration 30260, lr = 0.0002
I0615 18:20:26.719121 15760 solver.cpp:228] Iteration 30280, loss = 0.268533
I0615 18:20:26.719148 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 18:20:26.719157 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.22329 (* 1 = 0.22329 loss)
I0615 18:20:26.719166 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.339493 (* 1 = 0.339493 loss)
I0615 18:20:26.719172 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000788176 (* 1 = 0.000788176 loss)
I0615 18:20:26.719177 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0582014 (* 1 = 0.0582014 loss)
I0615 18:20:26.719184 15760 sgd_solver.cpp:106] Iteration 30280, lr = 0.0002
I0615 18:22:13.396119 15760 solver.cpp:228] Iteration 30300, loss = 0.473377
I0615 18:22:13.396143 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 18:22:13.396152 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.328969 (* 1 = 0.328969 loss)
I0615 18:22:13.396158 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.195982 (* 1 = 0.195982 loss)
I0615 18:22:13.396164 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0066906 (* 1 = 0.0066906 loss)
I0615 18:22:13.396169 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0638077 (* 1 = 0.0638077 loss)
I0615 18:22:13.396175 15760 sgd_solver.cpp:106] Iteration 30300, lr = 0.0002
I0615 18:24:00.081270 15760 solver.cpp:228] Iteration 30320, loss = 0.499651
I0615 18:24:00.081295 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 18:24:00.081301 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0422446 (* 1 = 0.0422446 loss)
I0615 18:24:00.081306 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.051461 (* 1 = 0.051461 loss)
I0615 18:24:00.081310 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226965 (* 1 = 0.00226965 loss)
I0615 18:24:00.081315 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234285 (* 1 = 0.0234285 loss)
I0615 18:24:00.081320 15760 sgd_solver.cpp:106] Iteration 30320, lr = 0.0002
I0615 18:25:47.060822 15760 solver.cpp:228] Iteration 30340, loss = 0.183289
I0615 18:25:47.060849 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 18:25:47.060858 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.083359 (* 1 = 0.083359 loss)
I0615 18:25:47.060863 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0811418 (* 1 = 0.0811418 loss)
I0615 18:25:47.060868 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000283386 (* 1 = 0.000283386 loss)
I0615 18:25:47.060871 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00671567 (* 1 = 0.00671567 loss)
I0615 18:25:47.060878 15760 sgd_solver.cpp:106] Iteration 30340, lr = 0.0002
I0615 18:27:34.311450 15760 solver.cpp:228] Iteration 30360, loss = 0.246383
I0615 18:27:34.311476 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 18:27:34.311488 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839849 (* 1 = 0.0839849 loss)
I0615 18:27:34.311496 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.138602 (* 1 = 0.138602 loss)
I0615 18:27:34.311504 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00726438 (* 1 = 0.00726438 loss)
I0615 18:27:34.311511 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200157 (* 1 = 0.0200157 loss)
I0615 18:27:34.311522 15760 sgd_solver.cpp:106] Iteration 30360, lr = 0.0002
I0615 18:29:20.994158 15760 solver.cpp:228] Iteration 30380, loss = 0.411186
I0615 18:29:20.994184 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 18:29:20.994194 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807469 (* 1 = 0.0807469 loss)
I0615 18:29:20.994199 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0363002 (* 1 = 0.0363002 loss)
I0615 18:29:20.994204 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000117804 (* 1 = 0.000117804 loss)
I0615 18:29:20.994208 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00554703 (* 1 = 0.00554703 loss)
I0615 18:29:20.994213 15760 sgd_solver.cpp:106] Iteration 30380, lr = 0.0002
speed: 5.330s / iter
I0615 18:31:08.108384 15760 solver.cpp:228] Iteration 30400, loss = 0.419319
I0615 18:31:08.108410 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 18:31:08.108418 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0517854 (* 1 = 0.0517854 loss)
I0615 18:31:08.108422 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0467546 (* 1 = 0.0467546 loss)
I0615 18:31:08.108427 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508018 (* 1 = 0.00508018 loss)
I0615 18:31:08.108430 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184104 (* 1 = 0.0184104 loss)
I0615 18:31:08.108435 15760 sgd_solver.cpp:106] Iteration 30400, lr = 0.0002
I0615 18:32:55.252648 15760 solver.cpp:228] Iteration 30420, loss = 0.289463
I0615 18:32:55.252677 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 18:32:55.252686 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.336646 (* 1 = 0.336646 loss)
I0615 18:32:55.252691 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.229704 (* 1 = 0.229704 loss)
I0615 18:32:55.252696 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00197468 (* 1 = 0.00197468 loss)
I0615 18:32:55.252699 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.088388 (* 1 = 0.088388 loss)
I0615 18:32:55.252705 15760 sgd_solver.cpp:106] Iteration 30420, lr = 0.0002
I0615 18:34:42.143308 15760 solver.cpp:228] Iteration 30440, loss = 0.385159
I0615 18:34:42.143333 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 18:34:42.143342 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.163938 (* 1 = 0.163938 loss)
I0615 18:34:42.143345 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.228627 (* 1 = 0.228627 loss)
I0615 18:34:42.143349 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000676819 (* 1 = 0.000676819 loss)
I0615 18:34:42.143353 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015963 (* 1 = 0.015963 loss)
I0615 18:34:42.143358 15760 sgd_solver.cpp:106] Iteration 30440, lr = 0.0002
I0615 18:36:28.461483 15760 solver.cpp:228] Iteration 30460, loss = 0.462809
I0615 18:36:28.461510 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 18:36:28.461519 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.171035 (* 1 = 0.171035 loss)
I0615 18:36:28.461526 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.118919 (* 1 = 0.118919 loss)
I0615 18:36:28.461532 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0050554 (* 1 = 0.0050554 loss)
I0615 18:36:28.461539 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00814615 (* 1 = 0.00814615 loss)
I0615 18:36:28.461545 15760 sgd_solver.cpp:106] Iteration 30460, lr = 0.0002
I0615 18:38:14.683944 15760 solver.cpp:228] Iteration 30480, loss = 0.265962
I0615 18:38:14.683969 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 18:38:14.683975 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0569825 (* 1 = 0.0569825 loss)
I0615 18:38:14.683979 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0180381 (* 1 = 0.0180381 loss)
I0615 18:38:14.683984 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00941588 (* 1 = 0.00941588 loss)
I0615 18:38:14.683986 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00990931 (* 1 = 0.00990931 loss)
I0615 18:38:14.683991 15760 sgd_solver.cpp:106] Iteration 30480, lr = 0.0002
I0615 18:40:01.904779 15760 solver.cpp:228] Iteration 30500, loss = 0.410982
I0615 18:40:01.904803 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 18:40:01.904808 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.104647 (* 1 = 0.104647 loss)
I0615 18:40:01.904812 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0914929 (* 1 = 0.0914929 loss)
I0615 18:40:01.904816 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000292232 (* 1 = 0.000292232 loss)
I0615 18:40:01.904820 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00656439 (* 1 = 0.00656439 loss)
I0615 18:40:01.904824 15760 sgd_solver.cpp:106] Iteration 30500, lr = 0.0002
I0615 18:41:48.708155 15760 solver.cpp:228] Iteration 30520, loss = 0.394662
I0615 18:41:48.708181 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 18:41:48.708189 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.202461 (* 1 = 0.202461 loss)
I0615 18:41:48.708194 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.203444 (* 1 = 0.203444 loss)
I0615 18:41:48.708197 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151171 (* 1 = 0.00151171 loss)
I0615 18:41:48.708201 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375114 (* 1 = 0.0375114 loss)
I0615 18:41:48.708206 15760 sgd_solver.cpp:106] Iteration 30520, lr = 0.0002
I0615 18:43:35.063364 15760 solver.cpp:228] Iteration 30540, loss = 0.244522
I0615 18:43:35.063393 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 18:43:35.063403 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.157255 (* 1 = 0.157255 loss)
I0615 18:43:35.063410 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.145966 (* 1 = 0.145966 loss)
I0615 18:43:35.063414 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00067185 (* 1 = 0.00067185 loss)
I0615 18:43:35.063419 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239306 (* 1 = 0.0239306 loss)
I0615 18:43:35.063426 15760 sgd_solver.cpp:106] Iteration 30540, lr = 0.0002
I0615 18:45:21.700587 15760 solver.cpp:228] Iteration 30560, loss = 0.50746
I0615 18:45:21.700609 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 18:45:21.700616 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.117853 (* 1 = 0.117853 loss)
I0615 18:45:21.700620 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0995588 (* 1 = 0.0995588 loss)
I0615 18:45:21.700623 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000683313 (* 1 = 0.000683313 loss)
I0615 18:45:21.700628 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356762 (* 1 = 0.0356762 loss)
I0615 18:45:21.700633 15760 sgd_solver.cpp:106] Iteration 30560, lr = 0.0002
I0615 18:47:08.091480 15760 solver.cpp:228] Iteration 30580, loss = 0.503881
I0615 18:47:08.091502 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 18:47:08.091508 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0762045 (* 1 = 0.0762045 loss)
I0615 18:47:08.091513 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.106245 (* 1 = 0.106245 loss)
I0615 18:47:08.091517 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000546091 (* 1 = 0.000546091 loss)
I0615 18:47:08.091521 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020343 (* 1 = 0.020343 loss)
I0615 18:47:08.091524 15760 sgd_solver.cpp:106] Iteration 30580, lr = 0.0002
speed: 5.330s / iter
I0615 18:48:54.471956 15760 solver.cpp:228] Iteration 30600, loss = 0.295193
I0615 18:48:54.471979 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 18:48:54.471988 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0764369 (* 1 = 0.0764369 loss)
I0615 18:48:54.471992 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0613049 (* 1 = 0.0613049 loss)
I0615 18:48:54.471997 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000567758 (* 1 = 0.000567758 loss)
I0615 18:48:54.472000 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00426073 (* 1 = 0.00426073 loss)
I0615 18:48:54.472004 15760 sgd_solver.cpp:106] Iteration 30600, lr = 0.0002
I0615 18:50:40.879093 15760 solver.cpp:228] Iteration 30620, loss = 0.541697
I0615 18:50:40.879118 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 18:50:40.879125 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.149896 (* 1 = 0.149896 loss)
I0615 18:50:40.879130 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.190713 (* 1 = 0.190713 loss)
I0615 18:50:40.879134 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000389257 (* 1 = 0.000389257 loss)
I0615 18:50:40.879138 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0626619 (* 1 = 0.0626619 loss)
I0615 18:50:40.879142 15760 sgd_solver.cpp:106] Iteration 30620, lr = 0.0002
I0615 18:52:27.393980 15760 solver.cpp:228] Iteration 30640, loss = 0.189275
I0615 18:52:27.394004 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 18:52:27.394011 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0514751 (* 1 = 0.0514751 loss)
I0615 18:52:27.394016 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.115172 (* 1 = 0.115172 loss)
I0615 18:52:27.394019 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183807 (* 1 = 0.00183807 loss)
I0615 18:52:27.394022 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163772 (* 1 = 0.0163772 loss)
I0615 18:52:27.394027 15760 sgd_solver.cpp:106] Iteration 30640, lr = 0.0002
I0615 18:54:13.772716 15760 solver.cpp:228] Iteration 30660, loss = 0.581296
I0615 18:54:13.772742 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 18:54:13.772750 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.666701 (* 1 = 0.666701 loss)
I0615 18:54:13.772758 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.282249 (* 1 = 0.282249 loss)
I0615 18:54:13.772763 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00505831 (* 1 = 0.00505831 loss)
I0615 18:54:13.772770 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.148986 (* 1 = 0.148986 loss)
I0615 18:54:13.772779 15760 sgd_solver.cpp:106] Iteration 30660, lr = 0.0002
I0615 18:56:00.092309 15760 solver.cpp:228] Iteration 30680, loss = 0.519431
I0615 18:56:00.092335 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 18:56:00.092341 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.33112 (* 1 = 0.33112 loss)
I0615 18:56:00.092345 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20892 (* 1 = 0.20892 loss)
I0615 18:56:00.092348 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00438237 (* 1 = 0.00438237 loss)
I0615 18:56:00.092352 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0952663 (* 1 = 0.0952663 loss)
I0615 18:56:00.092357 15760 sgd_solver.cpp:106] Iteration 30680, lr = 0.0002
I0615 18:57:46.630408 15760 solver.cpp:228] Iteration 30700, loss = 0.458278
I0615 18:57:46.630431 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 18:57:46.630439 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.391283 (* 1 = 0.391283 loss)
I0615 18:57:46.630444 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.196686 (* 1 = 0.196686 loss)
I0615 18:57:46.630447 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181869 (* 1 = 0.00181869 loss)
I0615 18:57:46.630451 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106159 (* 1 = 0.106159 loss)
I0615 18:57:46.630455 15760 sgd_solver.cpp:106] Iteration 30700, lr = 0.0002
I0615 18:59:32.982378 15760 solver.cpp:228] Iteration 30720, loss = 0.239511
I0615 18:59:32.982401 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 18:59:32.982411 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.177619 (* 1 = 0.177619 loss)
I0615 18:59:32.982419 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.152274 (* 1 = 0.152274 loss)
I0615 18:59:32.982424 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600287 (* 1 = 0.00600287 loss)
I0615 18:59:32.982430 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110854 (* 1 = 0.0110854 loss)
I0615 18:59:32.982437 15760 sgd_solver.cpp:106] Iteration 30720, lr = 0.0002
I0615 19:01:19.414130 15760 solver.cpp:228] Iteration 30740, loss = 0.572718
I0615 19:01:19.414153 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 19:01:19.414160 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.294635 (* 1 = 0.294635 loss)
I0615 19:01:19.414165 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.210886 (* 1 = 0.210886 loss)
I0615 19:01:19.414167 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193154 (* 1 = 0.00193154 loss)
I0615 19:01:19.414171 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.067342 (* 1 = 0.067342 loss)
I0615 19:01:19.414176 15760 sgd_solver.cpp:106] Iteration 30740, lr = 0.0002
I0615 19:03:05.743077 15760 solver.cpp:228] Iteration 30760, loss = 0.318265
I0615 19:03:05.743100 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 19:03:05.743108 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228909 (* 1 = 0.0228909 loss)
I0615 19:03:05.743111 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0448322 (* 1 = 0.0448322 loss)
I0615 19:03:05.743115 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000436676 (* 1 = 0.000436676 loss)
I0615 19:03:05.743119 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178742 (* 1 = 0.0178742 loss)
I0615 19:03:05.743124 15760 sgd_solver.cpp:106] Iteration 30760, lr = 0.0002
I0615 19:04:52.554256 15760 solver.cpp:228] Iteration 30780, loss = 0.326345
I0615 19:04:52.554280 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 19:04:52.554286 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.256961 (* 1 = 0.256961 loss)
I0615 19:04:52.554291 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.12417 (* 1 = 0.12417 loss)
I0615 19:04:52.554294 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000746306 (* 1 = 0.000746306 loss)
I0615 19:04:52.554297 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0560983 (* 1 = 0.0560983 loss)
I0615 19:04:52.554301 15760 sgd_solver.cpp:106] Iteration 30780, lr = 0.0002
speed: 5.330s / iter
I0615 19:06:39.041864 15760 solver.cpp:228] Iteration 30800, loss = 0.251888
I0615 19:06:39.041896 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0615 19:06:39.041904 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0815291 (* 1 = 0.0815291 loss)
I0615 19:06:39.041908 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0550323 (* 1 = 0.0550323 loss)
I0615 19:06:39.041913 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121271 (* 1 = 0.0121271 loss)
I0615 19:06:39.041916 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00621646 (* 1 = 0.00621646 loss)
I0615 19:06:39.041923 15760 sgd_solver.cpp:106] Iteration 30800, lr = 0.0002
I0615 19:08:26.154014 15760 solver.cpp:228] Iteration 30820, loss = 0.294262
I0615 19:08:26.154040 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 19:08:26.154047 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.132529 (* 1 = 0.132529 loss)
I0615 19:08:26.154050 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.177115 (* 1 = 0.177115 loss)
I0615 19:08:26.154054 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00187662 (* 1 = 0.00187662 loss)
I0615 19:08:26.154058 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388791 (* 1 = 0.0388791 loss)
I0615 19:08:26.154063 15760 sgd_solver.cpp:106] Iteration 30820, lr = 0.0002
I0615 19:10:13.002025 15760 solver.cpp:228] Iteration 30840, loss = 0.383869
I0615 19:10:13.002053 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 19:10:13.002063 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0877434 (* 1 = 0.0877434 loss)
I0615 19:10:13.002068 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.150805 (* 1 = 0.150805 loss)
I0615 19:10:13.002073 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00214059 (* 1 = 0.00214059 loss)
I0615 19:10:13.002076 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190423 (* 1 = 0.0190423 loss)
I0615 19:10:13.002082 15760 sgd_solver.cpp:106] Iteration 30840, lr = 0.0002
I0615 19:11:59.689834 15760 solver.cpp:228] Iteration 30860, loss = 0.291853
I0615 19:11:59.689862 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 19:11:59.689869 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.173624 (* 1 = 0.173624 loss)
I0615 19:11:59.689874 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171592 (* 1 = 0.171592 loss)
I0615 19:11:59.689882 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000183511 (* 1 = 0.000183511 loss)
I0615 19:11:59.689887 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297091 (* 1 = 0.0297091 loss)
I0615 19:11:59.689891 15760 sgd_solver.cpp:106] Iteration 30860, lr = 0.0002
I0615 19:13:46.208891 15760 solver.cpp:228] Iteration 30880, loss = 0.396374
I0615 19:13:46.208915 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 19:13:46.208923 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.087773 (* 1 = 0.087773 loss)
I0615 19:13:46.208928 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0712267 (* 1 = 0.0712267 loss)
I0615 19:13:46.208932 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000722353 (* 1 = 0.000722353 loss)
I0615 19:13:46.208936 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00526252 (* 1 = 0.00526252 loss)
I0615 19:13:46.208946 15760 sgd_solver.cpp:106] Iteration 30880, lr = 0.0002
I0615 19:15:33.262372 15760 solver.cpp:228] Iteration 30900, loss = 0.439675
I0615 19:15:33.262398 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0615 19:15:33.262408 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.668589 (* 1 = 0.668589 loss)
I0615 19:15:33.262413 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.490528 (* 1 = 0.490528 loss)
I0615 19:15:33.262418 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00762008 (* 1 = 0.00762008 loss)
I0615 19:15:33.262424 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.442968 (* 1 = 0.442968 loss)
I0615 19:15:33.262431 15760 sgd_solver.cpp:106] Iteration 30900, lr = 0.0002
I0615 19:17:19.907349 15760 solver.cpp:228] Iteration 30920, loss = 0.318682
I0615 19:17:19.907371 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0615 19:17:19.907378 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.279567 (* 1 = 0.279567 loss)
I0615 19:17:19.907382 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.250799 (* 1 = 0.250799 loss)
I0615 19:17:19.907387 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000471463 (* 1 = 0.000471463 loss)
I0615 19:17:19.907389 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289221 (* 1 = 0.0289221 loss)
I0615 19:17:19.907394 15760 sgd_solver.cpp:106] Iteration 30920, lr = 0.0002
I0615 19:19:06.889441 15760 solver.cpp:228] Iteration 30940, loss = 0.25658
I0615 19:19:06.889466 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0615 19:19:06.889473 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.160656 (* 1 = 0.160656 loss)
I0615 19:19:06.889479 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.172265 (* 1 = 0.172265 loss)
I0615 19:19:06.889485 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00876185 (* 1 = 0.00876185 loss)
I0615 19:19:06.889490 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431298 (* 1 = 0.0431298 loss)
I0615 19:19:06.889497 15760 sgd_solver.cpp:106] Iteration 30940, lr = 0.0002
I0615 19:20:53.577250 15760 solver.cpp:228] Iteration 30960, loss = 0.713332
I0615 19:20:53.577276 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 19:20:53.577284 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.493863 (* 1 = 0.493863 loss)
I0615 19:20:53.577288 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.354894 (* 1 = 0.354894 loss)
I0615 19:20:53.577292 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205189 (* 1 = 0.00205189 loss)
I0615 19:20:53.577296 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185714 (* 1 = 0.185714 loss)
I0615 19:20:53.577302 15760 sgd_solver.cpp:106] Iteration 30960, lr = 0.0002
I0615 19:22:40.373589 15760 solver.cpp:228] Iteration 30980, loss = 0.438362
I0615 19:22:40.373613 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 19:22:40.373621 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.167892 (* 1 = 0.167892 loss)
I0615 19:22:40.373625 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.201721 (* 1 = 0.201721 loss)
I0615 19:22:40.373630 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00111383 (* 1 = 0.00111383 loss)
I0615 19:22:40.373633 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174441 (* 1 = 0.0174441 loss)
I0615 19:22:40.373638 15760 sgd_solver.cpp:106] Iteration 30980, lr = 0.0002
speed: 5.330s / iter
I0615 19:24:26.580375 15760 solver.cpp:228] Iteration 31000, loss = 0.248402
I0615 19:24:26.580401 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 19:24:26.580410 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.124815 (* 1 = 0.124815 loss)
I0615 19:24:26.580413 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0468874 (* 1 = 0.0468874 loss)
I0615 19:24:26.580418 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110006 (* 1 = 0.00110006 loss)
I0615 19:24:26.580421 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239273 (* 1 = 0.0239273 loss)
I0615 19:24:26.580426 15760 sgd_solver.cpp:106] Iteration 31000, lr = 0.0002
I0615 19:26:12.963148 15760 solver.cpp:228] Iteration 31020, loss = 0.432532
I0615 19:26:12.963172 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 19:26:12.963181 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.267018 (* 1 = 0.267018 loss)
I0615 19:26:12.963186 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.228832 (* 1 = 0.228832 loss)
I0615 19:26:12.963192 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000167663 (* 1 = 0.000167663 loss)
I0615 19:26:12.963198 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0586314 (* 1 = 0.0586314 loss)
I0615 19:26:12.963204 15760 sgd_solver.cpp:106] Iteration 31020, lr = 0.0002
I0615 19:27:59.323710 15760 solver.cpp:228] Iteration 31040, loss = 0.519311
I0615 19:27:59.323735 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 19:27:59.323742 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.390653 (* 1 = 0.390653 loss)
I0615 19:27:59.323746 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.242441 (* 1 = 0.242441 loss)
I0615 19:27:59.323751 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301623 (* 1 = 0.00301623 loss)
I0615 19:27:59.323755 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101704 (* 1 = 0.101704 loss)
I0615 19:27:59.323760 15760 sgd_solver.cpp:106] Iteration 31040, lr = 0.0002
I0615 19:29:45.914332 15760 solver.cpp:228] Iteration 31060, loss = 0.534565
I0615 19:29:45.914358 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 19:29:45.914366 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.156771 (* 1 = 0.156771 loss)
I0615 19:29:45.914371 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.117689 (* 1 = 0.117689 loss)
I0615 19:29:45.914374 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0006027 (* 1 = 0.0006027 loss)
I0615 19:29:45.914378 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361098 (* 1 = 0.0361098 loss)
I0615 19:29:45.914383 15760 sgd_solver.cpp:106] Iteration 31060, lr = 0.0002
I0615 19:31:32.258877 15760 solver.cpp:228] Iteration 31080, loss = 0.567243
I0615 19:31:32.258898 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0615 19:31:32.258905 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.470974 (* 1 = 0.470974 loss)
I0615 19:31:32.258909 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.380138 (* 1 = 0.380138 loss)
I0615 19:31:32.258913 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00152986 (* 1 = 0.00152986 loss)
I0615 19:31:32.258916 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0536002 (* 1 = 0.0536002 loss)
I0615 19:31:32.258921 15760 sgd_solver.cpp:106] Iteration 31080, lr = 0.0002
I0615 19:33:18.626248 15760 solver.cpp:228] Iteration 31100, loss = 0.264536
I0615 19:33:18.626271 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 19:33:18.626281 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795979 (* 1 = 0.0795979 loss)
I0615 19:33:18.626286 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0370921 (* 1 = 0.0370921 loss)
I0615 19:33:18.626292 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00605306 (* 1 = 0.00605306 loss)
I0615 19:33:18.626297 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00445178 (* 1 = 0.00445178 loss)
I0615 19:33:18.626304 15760 sgd_solver.cpp:106] Iteration 31100, lr = 0.0002
I0615 19:35:05.132320 15760 solver.cpp:228] Iteration 31120, loss = 0.347795
I0615 19:35:05.132344 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 19:35:05.132350 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.205801 (* 1 = 0.205801 loss)
I0615 19:35:05.132354 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.172197 (* 1 = 0.172197 loss)
I0615 19:35:05.132357 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000235015 (* 1 = 0.000235015 loss)
I0615 19:35:05.132361 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232257 (* 1 = 0.0232257 loss)
I0615 19:35:05.132366 15760 sgd_solver.cpp:106] Iteration 31120, lr = 0.0002
I0615 19:36:51.575526 15760 solver.cpp:228] Iteration 31140, loss = 0.341087
I0615 19:36:51.575552 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 19:36:51.575562 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0901633 (* 1 = 0.0901633 loss)
I0615 19:36:51.575568 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0686498 (* 1 = 0.0686498 loss)
I0615 19:36:51.575574 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137961 (* 1 = 0.00137961 loss)
I0615 19:36:51.575582 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00874066 (* 1 = 0.00874066 loss)
I0615 19:36:51.575589 15760 sgd_solver.cpp:106] Iteration 31140, lr = 0.0002
I0615 19:38:37.861045 15760 solver.cpp:228] Iteration 31160, loss = 0.414309
I0615 19:38:37.861073 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 19:38:37.861079 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.451179 (* 1 = 0.451179 loss)
I0615 19:38:37.861083 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20991 (* 1 = 0.20991 loss)
I0615 19:38:37.861088 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179578 (* 1 = 0.00179578 loss)
I0615 19:38:37.861091 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0743235 (* 1 = 0.0743235 loss)
I0615 19:38:37.861097 15760 sgd_solver.cpp:106] Iteration 31160, lr = 0.0002
I0615 19:40:24.284700 15760 solver.cpp:228] Iteration 31180, loss = 0.328355
I0615 19:40:24.284724 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 19:40:24.284730 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481899 (* 1 = 0.0481899 loss)
I0615 19:40:24.284734 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0636883 (* 1 = 0.0636883 loss)
I0615 19:40:24.284739 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000172165 (* 1 = 0.000172165 loss)
I0615 19:40:24.284741 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271396 (* 1 = 0.0271396 loss)
I0615 19:40:24.284746 15760 sgd_solver.cpp:106] Iteration 31180, lr = 0.0002
speed: 5.330s / iter
I0615 19:42:10.578248 15760 solver.cpp:228] Iteration 31200, loss = 0.29467
I0615 19:42:10.578270 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 19:42:10.578277 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0676914 (* 1 = 0.0676914 loss)
I0615 19:42:10.578281 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.10651 (* 1 = 0.10651 loss)
I0615 19:42:10.578285 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000621579 (* 1 = 0.000621579 loss)
I0615 19:42:10.578289 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016436 (* 1 = 0.016436 loss)
I0615 19:42:10.578294 15760 sgd_solver.cpp:106] Iteration 31200, lr = 0.0002
I0615 19:43:57.069068 15760 solver.cpp:228] Iteration 31220, loss = 0.302969
I0615 19:43:57.069097 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 19:43:57.069103 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0878302 (* 1 = 0.0878302 loss)
I0615 19:43:57.069108 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.119236 (* 1 = 0.119236 loss)
I0615 19:43:57.069113 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591626 (* 1 = 0.00591626 loss)
I0615 19:43:57.069116 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0427679 (* 1 = 0.0427679 loss)
I0615 19:43:57.069121 15760 sgd_solver.cpp:106] Iteration 31220, lr = 0.0002
I0615 19:45:43.479261 15760 solver.cpp:228] Iteration 31240, loss = 0.2803
I0615 19:45:43.479286 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 19:45:43.479295 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363846 (* 1 = 0.0363846 loss)
I0615 19:45:43.479300 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0348658 (* 1 = 0.0348658 loss)
I0615 19:45:43.479302 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000723662 (* 1 = 0.000723662 loss)
I0615 19:45:43.479306 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119739 (* 1 = 0.0119739 loss)
I0615 19:45:43.479311 15760 sgd_solver.cpp:106] Iteration 31240, lr = 0.0002
I0615 19:47:29.955816 15760 solver.cpp:228] Iteration 31260, loss = 0.333582
I0615 19:47:29.955844 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 19:47:29.955854 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0794439 (* 1 = 0.0794439 loss)
I0615 19:47:29.955860 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0815891 (* 1 = 0.0815891 loss)
I0615 19:47:29.955865 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000858739 (* 1 = 0.000858739 loss)
I0615 19:47:29.955870 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0437595 (* 1 = 0.0437595 loss)
I0615 19:47:29.955876 15760 sgd_solver.cpp:106] Iteration 31260, lr = 0.0002
I0615 19:49:16.959975 15760 solver.cpp:228] Iteration 31280, loss = 0.330015
I0615 19:49:16.960000 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 19:49:16.960007 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.037474 (* 1 = 0.037474 loss)
I0615 19:49:16.960011 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0314752 (* 1 = 0.0314752 loss)
I0615 19:49:16.960016 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00551055 (* 1 = 0.00551055 loss)
I0615 19:49:16.960019 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133812 (* 1 = 0.0133812 loss)
I0615 19:49:16.960024 15760 sgd_solver.cpp:106] Iteration 31280, lr = 0.0002
I0615 19:51:03.723950 15760 solver.cpp:228] Iteration 31300, loss = 0.362504
I0615 19:51:03.723973 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 19:51:03.723983 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.157099 (* 1 = 0.157099 loss)
I0615 19:51:03.723987 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.121966 (* 1 = 0.121966 loss)
I0615 19:51:03.723994 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000401777 (* 1 = 0.000401777 loss)
I0615 19:51:03.723999 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134495 (* 1 = 0.0134495 loss)
I0615 19:51:03.724006 15760 sgd_solver.cpp:106] Iteration 31300, lr = 0.0002
I0615 19:52:51.002461 15760 solver.cpp:228] Iteration 31320, loss = 0.336649
I0615 19:52:51.002488 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 19:52:51.002496 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.161568 (* 1 = 0.161568 loss)
I0615 19:52:51.002501 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.180996 (* 1 = 0.180996 loss)
I0615 19:52:51.002506 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221076 (* 1 = 0.00221076 loss)
I0615 19:52:51.002511 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030094 (* 1 = 0.030094 loss)
I0615 19:52:51.002517 15760 sgd_solver.cpp:106] Iteration 31320, lr = 0.0002
I0615 19:54:38.013090 15760 solver.cpp:228] Iteration 31340, loss = 0.22303
I0615 19:54:38.013116 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 19:54:38.013125 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.118445 (* 1 = 0.118445 loss)
I0615 19:54:38.013133 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.126671 (* 1 = 0.126671 loss)
I0615 19:54:38.013139 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00327205 (* 1 = 0.00327205 loss)
I0615 19:54:38.013144 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353038 (* 1 = 0.0353038 loss)
I0615 19:54:38.013151 15760 sgd_solver.cpp:106] Iteration 31340, lr = 0.0002
I0615 19:56:24.652802 15760 solver.cpp:228] Iteration 31360, loss = 0.323763
I0615 19:56:24.652830 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 19:56:24.652840 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.175798 (* 1 = 0.175798 loss)
I0615 19:56:24.652845 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.111835 (* 1 = 0.111835 loss)
I0615 19:56:24.652851 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00820983 (* 1 = 0.00820983 loss)
I0615 19:56:24.652856 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.04822 (* 1 = 0.04822 loss)
I0615 19:56:24.652863 15760 sgd_solver.cpp:106] Iteration 31360, lr = 0.0002
I0615 19:58:11.647157 15760 solver.cpp:228] Iteration 31380, loss = 0.407633
I0615 19:58:11.647181 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 19:58:11.647188 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.181393 (* 1 = 0.181393 loss)
I0615 19:58:11.647192 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.20523 (* 1 = 0.20523 loss)
I0615 19:58:11.647197 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000313998 (* 1 = 0.000313998 loss)
I0615 19:58:11.647202 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136934 (* 1 = 0.0136934 loss)
I0615 19:58:11.647205 15760 sgd_solver.cpp:106] Iteration 31380, lr = 0.0002
speed: 5.330s / iter
I0615 19:59:59.123922 15760 solver.cpp:228] Iteration 31400, loss = 0.404192
I0615 19:59:59.123951 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 19:59:59.123963 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719576 (* 1 = 0.0719576 loss)
I0615 19:59:59.123971 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0795656 (* 1 = 0.0795656 loss)
I0615 19:59:59.123980 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000683703 (* 1 = 0.000683703 loss)
I0615 19:59:59.123989 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135897 (* 1 = 0.0135897 loss)
I0615 19:59:59.123998 15760 sgd_solver.cpp:106] Iteration 31400, lr = 0.0002
I0615 20:01:45.989298 15760 solver.cpp:228] Iteration 31420, loss = 0.276187
I0615 20:01:45.989320 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 20:01:45.989327 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682453 (* 1 = 0.0682453 loss)
I0615 20:01:45.989331 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0782588 (* 1 = 0.0782588 loss)
I0615 20:01:45.989334 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115858 (* 1 = 0.00115858 loss)
I0615 20:01:45.989338 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157263 (* 1 = 0.0157263 loss)
I0615 20:01:45.989343 15760 sgd_solver.cpp:106] Iteration 31420, lr = 0.0002
I0615 20:03:32.654605 15760 solver.cpp:228] Iteration 31440, loss = 0.303089
I0615 20:03:32.654629 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 20:03:32.654636 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.109731 (* 1 = 0.109731 loss)
I0615 20:03:32.654640 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.120403 (* 1 = 0.120403 loss)
I0615 20:03:32.654644 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00017048 (* 1 = 0.00017048 loss)
I0615 20:03:32.654647 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185998 (* 1 = 0.0185998 loss)
I0615 20:03:32.654654 15760 sgd_solver.cpp:106] Iteration 31440, lr = 0.0002
I0615 20:05:19.485673 15760 solver.cpp:228] Iteration 31460, loss = 0.400604
I0615 20:05:19.485697 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 20:05:19.485703 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.141957 (* 1 = 0.141957 loss)
I0615 20:05:19.485707 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.125219 (* 1 = 0.125219 loss)
I0615 20:05:19.485711 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00065304 (* 1 = 0.00065304 loss)
I0615 20:05:19.485714 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239365 (* 1 = 0.0239365 loss)
I0615 20:05:19.485719 15760 sgd_solver.cpp:106] Iteration 31460, lr = 0.0002
I0615 20:07:05.933939 15760 solver.cpp:228] Iteration 31480, loss = 0.21925
I0615 20:07:05.933962 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 20:07:05.933972 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.134695 (* 1 = 0.134695 loss)
I0615 20:07:05.933979 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.216481 (* 1 = 0.216481 loss)
I0615 20:07:05.933984 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000182028 (* 1 = 0.000182028 loss)
I0615 20:07:05.933990 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156892 (* 1 = 0.0156892 loss)
I0615 20:07:05.933995 15760 sgd_solver.cpp:106] Iteration 31480, lr = 0.0002
I0615 20:08:52.132084 15760 solver.cpp:228] Iteration 31500, loss = 0.332748
I0615 20:08:52.132107 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0615 20:08:52.132114 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.322612 (* 1 = 0.322612 loss)
I0615 20:08:52.132118 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234036 (* 1 = 0.234036 loss)
I0615 20:08:52.132122 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000622835 (* 1 = 0.000622835 loss)
I0615 20:08:52.132125 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0533835 (* 1 = 0.0533835 loss)
I0615 20:08:52.132130 15760 sgd_solver.cpp:106] Iteration 31500, lr = 0.0002
I0615 20:10:38.348716 15760 solver.cpp:228] Iteration 31520, loss = 0.194966
I0615 20:10:38.348745 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0615 20:10:38.348752 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0854419 (* 1 = 0.0854419 loss)
I0615 20:10:38.348757 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.124405 (* 1 = 0.124405 loss)
I0615 20:10:38.348762 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000883492 (* 1 = 0.000883492 loss)
I0615 20:10:38.348765 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00718847 (* 1 = 0.00718847 loss)
I0615 20:10:38.348772 15760 sgd_solver.cpp:106] Iteration 31520, lr = 0.0002
I0615 20:12:24.988984 15760 solver.cpp:228] Iteration 31540, loss = 0.276242
I0615 20:12:24.989018 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 20:12:24.989027 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.061271 (* 1 = 0.061271 loss)
I0615 20:12:24.989032 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0547827 (* 1 = 0.0547827 loss)
I0615 20:12:24.989034 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.85739e-05 (* 1 = 9.85739e-05 loss)
I0615 20:12:24.989039 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00908554 (* 1 = 0.00908554 loss)
I0615 20:12:24.989045 15760 sgd_solver.cpp:106] Iteration 31540, lr = 0.0002
I0615 20:14:11.340458 15760 solver.cpp:228] Iteration 31560, loss = 0.409337
I0615 20:14:11.340484 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 20:14:11.340492 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.146729 (* 1 = 0.146729 loss)
I0615 20:14:11.340497 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.296813 (* 1 = 0.296813 loss)
I0615 20:14:11.340502 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000581933 (* 1 = 0.000581933 loss)
I0615 20:14:11.340504 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230164 (* 1 = 0.0230164 loss)
I0615 20:14:11.340509 15760 sgd_solver.cpp:106] Iteration 31560, lr = 0.0002
I0615 20:15:57.670902 15760 solver.cpp:228] Iteration 31580, loss = 0.287218
I0615 20:15:57.670925 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 20:15:57.670931 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.333922 (* 1 = 0.333922 loss)
I0615 20:15:57.670935 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.230715 (* 1 = 0.230715 loss)
I0615 20:15:57.670939 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00306359 (* 1 = 0.00306359 loss)
I0615 20:15:57.670943 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0596439 (* 1 = 0.0596439 loss)
I0615 20:15:57.670948 15760 sgd_solver.cpp:106] Iteration 31580, lr = 0.0002
speed: 5.330s / iter
I0615 20:17:43.988162 15760 solver.cpp:228] Iteration 31600, loss = 0.18691
I0615 20:17:43.988185 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 20:17:43.988193 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.122963 (* 1 = 0.122963 loss)
I0615 20:17:43.988196 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.154864 (* 1 = 0.154864 loss)
I0615 20:17:43.988201 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104765 (* 1 = 0.00104765 loss)
I0615 20:17:43.988204 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277703 (* 1 = 0.0277703 loss)
I0615 20:17:43.988209 15760 sgd_solver.cpp:106] Iteration 31600, lr = 0.0002
I0615 20:19:30.265355 15760 solver.cpp:228] Iteration 31620, loss = 0.252497
I0615 20:19:30.265383 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 20:19:30.265390 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.194517 (* 1 = 0.194517 loss)
I0615 20:19:30.265394 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.176811 (* 1 = 0.176811 loss)
I0615 20:19:30.265398 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0314434 (* 1 = 0.0314434 loss)
I0615 20:19:30.265403 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0557027 (* 1 = 0.0557027 loss)
I0615 20:19:30.265408 15760 sgd_solver.cpp:106] Iteration 31620, lr = 0.0002
I0615 20:21:16.871374 15760 solver.cpp:228] Iteration 31640, loss = 0.399329
I0615 20:21:16.871399 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 20:21:16.871407 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.187104 (* 1 = 0.187104 loss)
I0615 20:21:16.871412 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.171723 (* 1 = 0.171723 loss)
I0615 20:21:16.871415 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.25519e-05 (* 1 = 8.25519e-05 loss)
I0615 20:21:16.871419 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0409436 (* 1 = 0.0409436 loss)
I0615 20:21:16.871424 15760 sgd_solver.cpp:106] Iteration 31640, lr = 0.0002
I0615 20:23:03.330657 15760 solver.cpp:228] Iteration 31660, loss = 0.397961
I0615 20:23:03.330684 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0615 20:23:03.330691 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.373506 (* 1 = 0.373506 loss)
I0615 20:23:03.330695 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.249858 (* 1 = 0.249858 loss)
I0615 20:23:03.330699 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00987392 (* 1 = 0.00987392 loss)
I0615 20:23:03.330703 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0582639 (* 1 = 0.0582639 loss)
I0615 20:23:03.330708 15760 sgd_solver.cpp:106] Iteration 31660, lr = 0.0002
I0615 20:24:49.899737 15760 solver.cpp:228] Iteration 31680, loss = 0.446877
I0615 20:24:49.899762 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0615 20:24:49.899770 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.197196 (* 1 = 0.197196 loss)
I0615 20:24:49.899775 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.149206 (* 1 = 0.149206 loss)
I0615 20:24:49.899778 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00904004 (* 1 = 0.00904004 loss)
I0615 20:24:49.899782 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0545305 (* 1 = 0.0545305 loss)
I0615 20:24:49.899787 15760 sgd_solver.cpp:106] Iteration 31680, lr = 0.0002
I0615 20:26:36.307989 15760 solver.cpp:228] Iteration 31700, loss = 0.286491
I0615 20:26:36.308014 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 20:26:36.308022 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472015 (* 1 = 0.0472015 loss)
I0615 20:26:36.308025 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0709931 (* 1 = 0.0709931 loss)
I0615 20:26:36.308029 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00498032 (* 1 = 0.00498032 loss)
I0615 20:26:36.308033 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268672 (* 1 = 0.0268672 loss)
I0615 20:26:36.308038 15760 sgd_solver.cpp:106] Iteration 31700, lr = 0.0002
I0615 20:28:22.629149 15760 solver.cpp:228] Iteration 31720, loss = 0.403678
I0615 20:28:22.629173 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 20:28:22.629181 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.115784 (* 1 = 0.115784 loss)
I0615 20:28:22.629187 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0822934 (* 1 = 0.0822934 loss)
I0615 20:28:22.629194 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000303059 (* 1 = 0.000303059 loss)
I0615 20:28:22.629199 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136549 (* 1 = 0.0136549 loss)
I0615 20:28:22.629205 15760 sgd_solver.cpp:106] Iteration 31720, lr = 0.0002
I0615 20:30:09.363638 15760 solver.cpp:228] Iteration 31740, loss = 0.652084
I0615 20:30:09.363663 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 20:30:09.363673 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399371 (* 1 = 0.0399371 loss)
I0615 20:30:09.363680 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0317007 (* 1 = 0.0317007 loss)
I0615 20:30:09.363687 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00203104 (* 1 = 0.00203104 loss)
I0615 20:30:09.363692 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0068233 (* 1 = 0.0068233 loss)
I0615 20:30:09.363701 15760 sgd_solver.cpp:106] Iteration 31740, lr = 0.0002
I0615 20:31:55.679616 15760 solver.cpp:228] Iteration 31760, loss = 0.308304
I0615 20:31:55.679641 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0615 20:31:55.679647 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0771836 (* 1 = 0.0771836 loss)
I0615 20:31:55.679651 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.108114 (* 1 = 0.108114 loss)
I0615 20:31:55.679654 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.46357e-05 (* 1 = 8.46357e-05 loss)
I0615 20:31:55.679658 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00498135 (* 1 = 0.00498135 loss)
I0615 20:31:55.679663 15760 sgd_solver.cpp:106] Iteration 31760, lr = 0.0002
I0615 20:33:42.433516 15760 solver.cpp:228] Iteration 31780, loss = 0.335893
I0615 20:33:42.433545 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0615 20:33:42.433555 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.230792 (* 1 = 0.230792 loss)
I0615 20:33:42.433562 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.312635 (* 1 = 0.312635 loss)
I0615 20:33:42.433567 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128787 (* 1 = 0.00128787 loss)
I0615 20:33:42.433571 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0459512 (* 1 = 0.0459512 loss)
I0615 20:33:42.433578 15760 sgd_solver.cpp:106] Iteration 31780, lr = 0.0002
speed: 5.330s / iter
I0615 20:35:29.466931 15760 solver.cpp:228] Iteration 31800, loss = 0.437832
I0615 20:35:29.466956 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0615 20:35:29.466965 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.140869 (* 1 = 0.140869 loss)
I0615 20:35:29.466974 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.083707 (* 1 = 0.083707 loss)
I0615 20:35:29.466980 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00201105 (* 1 = 0.00201105 loss)
I0615 20:35:29.466989 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00899187 (* 1 = 0.00899187 loss)
I0615 20:35:29.466997 15760 sgd_solver.cpp:106] Iteration 31800, lr = 0.0002
I0615 20:37:16.397457 15760 solver.cpp:228] Iteration 31820, loss = 0.298441
I0615 20:37:16.397491 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 20:37:16.397498 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702818 (* 1 = 0.0702818 loss)
I0615 20:37:16.397503 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0664809 (* 1 = 0.0664809 loss)
I0615 20:37:16.397507 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000542889 (* 1 = 0.000542889 loss)
I0615 20:37:16.397511 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158806 (* 1 = 0.0158806 loss)
I0615 20:37:16.397516 15760 sgd_solver.cpp:106] Iteration 31820, lr = 0.0002
I0615 20:39:03.588898 15760 solver.cpp:228] Iteration 31840, loss = 0.453369
I0615 20:39:03.588924 15760 solver.cpp:244]     Train net output #0: accuarcy = 1
I0615 20:39:03.588932 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496062 (* 1 = 0.0496062 loss)
I0615 20:39:03.588934 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0352521 (* 1 = 0.0352521 loss)
I0615 20:39:03.588963 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143631 (* 1 = 0.00143631 loss)
I0615 20:39:03.588968 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00465463 (* 1 = 0.00465463 loss)
I0615 20:39:03.588973 15760 sgd_solver.cpp:106] Iteration 31840, lr = 0.0002
I0615 20:40:50.389611 15760 solver.cpp:228] Iteration 31860, loss = 0.333402
I0615 20:40:50.389636 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0615 20:40:50.389645 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533122 (* 1 = 0.0533122 loss)
I0615 20:40:50.389652 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0420855 (* 1 = 0.0420855 loss)
I0615 20:40:50.389657 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.0287e-05 (* 1 = 7.0287e-05 loss)
I0615 20:40:50.389664 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0097217 (* 1 = 0.0097217 loss)
I0615 20:40:50.389672 15760 sgd_solver.cpp:106] Iteration 31860, lr = 0.0002
I0615 20:42:37.199584 15760 solver.cpp:228] Iteration 31880, loss = 0.234732
I0615 20:42:37.199606 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0615 20:42:37.199614 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.157186 (* 1 = 0.157186 loss)
I0615 20:42:37.199617 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.162785 (* 1 = 0.162785 loss)
I0615 20:42:37.199620 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000509412 (* 1 = 0.000509412 loss)
I0615 20:42:37.199625 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0440518 (* 1 = 0.0440518 loss)
I0615 20:42:37.199628 15760 sgd_solver.cpp:106] Iteration 31880, lr = 0.0002
I0615 20:44:24.068073 15760 solver.cpp:228] Iteration 31900, loss = 0.320564
I0615 20:44:24.068096 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0615 20:44:24.068104 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0555925 (* 1 = 0.0555925 loss)
I0615 20:44:24.068107 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.101271 (* 1 = 0.101271 loss)
I0615 20:44:24.068111 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000797173 (* 1 = 0.000797173 loss)
I0615 20:44:24.068114 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290529 (* 1 = 0.0290529 loss)
I0615 20:44:24.068120 15760 sgd_solver.cpp:106] Iteration 31900, lr = 0.0002
I0615 20:46:10.981230 15760 solver.cpp:228] Iteration 31920, loss = 0.353863
I0615 20:46:10.981256 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0615 20:46:10.981264 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.12693 (* 1 = 0.12693 loss)
I0615 20:46:10.981268 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.133795 (* 1 = 0.133795 loss)
I0615 20:46:10.981272 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00142105 (* 1 = 0.00142105 loss)
I0615 20:46:10.981276 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449558 (* 1 = 0.0449558 loss)
I0615 20:46:10.981281 15760 sgd_solver.cpp:106] Iteration 31920, lr = 0.0002
I0615 20:47:57.828199 15760 solver.cpp:228] Iteration 31940, loss = 0.465629
I0615 20:47:57.828225 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0615 20:47:57.828233 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.35899 (* 1 = 0.35899 loss)
I0615 20:47:57.828236 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.312645 (* 1 = 0.312645 loss)
I0615 20:47:57.828240 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000936575 (* 1 = 0.000936575 loss)
I0615 20:47:57.828243 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0360659 (* 1 = 0.0360659 loss)
I0615 20:47:57.828249 15760 sgd_solver.cpp:106] Iteration 31940, lr = 0.0002
I0615 20:49:44.275959 15760 solver.cpp:228] Iteration 31960, loss = 0.382423
I0615 20:49:44.275984 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0615 20:49:44.275990 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.217231 (* 1 = 0.217231 loss)
I0615 20:49:44.275995 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.234022 (* 1 = 0.234022 loss)
I0615 20:49:44.276000 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00263475 (* 1 = 0.00263475 loss)
I0615 20:49:44.276003 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311658 (* 1 = 0.0311658 loss)
I0615 20:49:44.276007 15760 sgd_solver.cpp:106] Iteration 31960, lr = 0.0002
I0615 20:51:31.399890 15760 solver.cpp:228] Iteration 31980, loss = 0.335257
I0615 20:51:31.399915 15760 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0615 20:51:31.399924 15760 solver.cpp:244]     Train net output #1: loss_bbox = 0.0894502 (* 1 = 0.0894502 loss)
I0615 20:51:31.399927 15760 solver.cpp:244]     Train net output #2: loss_cls = 0.0618633 (* 1 = 0.0618633 loss)
I0615 20:51:31.399931 15760 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000345752 (* 1 = 0.000345752 loss)
I0615 20:51:31.399935 15760 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00447345 (* 1 = 0.00447345 loss)
I0615 20:51:31.399940 15760 sgd_solver.cpp:106] Iteration 31980, lr = 0.0002
speed: 5.330s / iter
I0615 20:53:12.976594 15760 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_32000.caffemodel
done solving

real	2842m56.539s
user	2393m50.840s
sys	471m19.640s
+ set +x
+ ./tools/test_net.py --gpu 1 --def experiments/6_13_original_head_upper_body_handle/test_agnostic.prototxt --net /home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_32000.caffemodel --imdb voc_0712_test --cfg experiments/6_13_original_head_upper_body_handle/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='/home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_32000.caffemodel', cfg_file='experiments/6_13_original_head_upper_body_handle/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=1, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/6_13_original_head_upper_body_handle/test_agnostic.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '6_13_original_head_upper_body_handle/model',
 'GPU_ID': 1,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SOFT_NMS': 0,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0615 20:53:15.257867 23191 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0615 20:53:15.257891 23191 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0615 20:53:15.257894 23191 _caffe.cpp:125] Net('experiments/6_13_original_head_upper_body_handle/test_agnostic.prototxt', 1, weights='/home/user/Disk1.8T/py-R-FCN/experiments/6_13_original_head_upper_body_handle/model/resnet50_rfcn_ohem_iter_32000.caffemodel')
I0615 20:53:15.259915 23191 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/6_13_original_head_upper_body_handle/test_agnostic.prototxt
I0615 20:53:15.260125 23191 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0615 20:53:15.260130 23191 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0615 20:53:15.261452 23191 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "r
I0615 20:53:15.263314 23191 layer_factory.hpp:77] Creating layer input
I0615 20:53:15.263342 23191 net.cpp:100] Creating Layer input
I0615 20:53:15.263350 23191 net.cpp:418] input -> data
I0615 20:53:15.263384 23191 net.cpp:418] input -> im_info
I0615 20:53:15.285635 23191 net.cpp:150] Setting up input
I0615 20:53:15.285665 23191 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0615 20:53:15.285671 23191 net.cpp:157] Top shape: 1 3 (3)
I0615 20:53:15.285673 23191 net.cpp:165] Memory required for data: 602124
I0615 20:53:15.285692 23191 layer_factory.hpp:77] Creating layer conv1
I0615 20:53:15.285738 23191 net.cpp:100] Creating Layer conv1
I0615 20:53:15.285749 23191 net.cpp:444] conv1 <- data
I0615 20:53:15.285770 23191 net.cpp:418] conv1 -> conv1
I0615 20:53:15.621104 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 225816
I0615 20:53:15.621412 23191 net.cpp:150] Setting up conv1
I0615 20:53:15.621434 23191 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0615 20:53:15.621438 23191 net.cpp:165] Memory required for data: 3813388
I0615 20:53:15.621490 23191 layer_factory.hpp:77] Creating layer bn_conv1
I0615 20:53:15.621523 23191 net.cpp:100] Creating Layer bn_conv1
I0615 20:53:15.621534 23191 net.cpp:444] bn_conv1 <- conv1
I0615 20:53:15.621551 23191 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0615 20:53:15.621820 23191 net.cpp:150] Setting up bn_conv1
I0615 20:53:15.621827 23191 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0615 20:53:15.621830 23191 net.cpp:165] Memory required for data: 7024652
I0615 20:53:15.621857 23191 layer_factory.hpp:77] Creating layer scale_conv1
I0615 20:53:15.621873 23191 net.cpp:100] Creating Layer scale_conv1
I0615 20:53:15.621879 23191 net.cpp:444] scale_conv1 <- conv1
I0615 20:53:15.621891 23191 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0615 20:53:15.621953 23191 layer_factory.hpp:77] Creating layer scale_conv1
I0615 20:53:15.622148 23191 net.cpp:150] Setting up scale_conv1
I0615 20:53:15.622156 23191 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0615 20:53:15.622159 23191 net.cpp:165] Memory required for data: 10235916
I0615 20:53:15.622169 23191 layer_factory.hpp:77] Creating layer conv1_relu
I0615 20:53:15.622184 23191 net.cpp:100] Creating Layer conv1_relu
I0615 20:53:15.622189 23191 net.cpp:444] conv1_relu <- conv1
I0615 20:53:15.622200 23191 net.cpp:405] conv1_relu -> conv1 (in-place)
I0615 20:53:15.622354 23191 net.cpp:150] Setting up conv1_relu
I0615 20:53:15.622362 23191 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0615 20:53:15.622365 23191 net.cpp:165] Memory required for data: 13447180
I0615 20:53:15.622370 23191 layer_factory.hpp:77] Creating layer pool1
I0615 20:53:15.622383 23191 net.cpp:100] Creating Layer pool1
I0615 20:53:15.622390 23191 net.cpp:444] pool1 <- conv1
I0615 20:53:15.622402 23191 net.cpp:418] pool1 -> pool1
I0615 20:53:15.622463 23191 net.cpp:150] Setting up pool1
I0615 20:53:15.622472 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.622474 23191 net.cpp:165] Memory required for data: 14249996
I0615 20:53:15.622478 23191 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0615 20:53:15.622488 23191 net.cpp:100] Creating Layer pool1_pool1_0_split
I0615 20:53:15.622493 23191 net.cpp:444] pool1_pool1_0_split <- pool1
I0615 20:53:15.622504 23191 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0615 20:53:15.622522 23191 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0615 20:53:15.622571 23191 net.cpp:150] Setting up pool1_pool1_0_split
I0615 20:53:15.622581 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.622584 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.622587 23191 net.cpp:165] Memory required for data: 15855628
I0615 20:53:15.622591 23191 layer_factory.hpp:77] Creating layer res2a_branch1
I0615 20:53:15.622606 23191 net.cpp:100] Creating Layer res2a_branch1
I0615 20:53:15.622612 23191 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0615 20:53:15.622625 23191 net.cpp:418] res2a_branch1 -> res2a_branch1
I0615 20:53:15.623631 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.623647 23191 net.cpp:150] Setting up res2a_branch1
I0615 20:53:15.623656 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.623657 23191 net.cpp:165] Memory required for data: 19066892
I0615 20:53:15.623668 23191 layer_factory.hpp:77] Creating layer bn2a_branch1
I0615 20:53:15.623687 23191 net.cpp:100] Creating Layer bn2a_branch1
I0615 20:53:15.623695 23191 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0615 20:53:15.623709 23191 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0615 20:53:15.624740 23191 net.cpp:150] Setting up bn2a_branch1
I0615 20:53:15.624750 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.624752 23191 net.cpp:165] Memory required for data: 22278156
I0615 20:53:15.624783 23191 layer_factory.hpp:77] Creating layer scale2a_branch1
I0615 20:53:15.624799 23191 net.cpp:100] Creating Layer scale2a_branch1
I0615 20:53:15.624804 23191 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0615 20:53:15.624819 23191 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0615 20:53:15.624884 23191 layer_factory.hpp:77] Creating layer scale2a_branch1
I0615 20:53:15.625092 23191 net.cpp:150] Setting up scale2a_branch1
I0615 20:53:15.625100 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.625103 23191 net.cpp:165] Memory required for data: 25489420
I0615 20:53:15.625115 23191 layer_factory.hpp:77] Creating layer res2a_branch2a
I0615 20:53:15.625131 23191 net.cpp:100] Creating Layer res2a_branch2a
I0615 20:53:15.625138 23191 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0615 20:53:15.625151 23191 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0615 20:53:15.626142 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.626160 23191 net.cpp:150] Setting up res2a_branch2a
I0615 20:53:15.626168 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.626169 23191 net.cpp:165] Memory required for data: 26292236
I0615 20:53:15.626179 23191 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0615 20:53:15.626194 23191 net.cpp:100] Creating Layer bn2a_branch2a
I0615 20:53:15.626200 23191 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0615 20:53:15.626214 23191 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0615 20:53:15.626477 23191 net.cpp:150] Setting up bn2a_branch2a
I0615 20:53:15.626485 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.626488 23191 net.cpp:165] Memory required for data: 27095052
I0615 20:53:15.626513 23191 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0615 20:53:15.626528 23191 net.cpp:100] Creating Layer scale2a_branch2a
I0615 20:53:15.626534 23191 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0615 20:53:15.626546 23191 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0615 20:53:15.626608 23191 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0615 20:53:15.626788 23191 net.cpp:150] Setting up scale2a_branch2a
I0615 20:53:15.626796 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.626799 23191 net.cpp:165] Memory required for data: 27897868
I0615 20:53:15.626809 23191 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0615 20:53:15.626821 23191 net.cpp:100] Creating Layer res2a_branch2a_relu
I0615 20:53:15.626826 23191 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0615 20:53:15.626837 23191 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0615 20:53:15.626991 23191 net.cpp:150] Setting up res2a_branch2a_relu
I0615 20:53:15.626998 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.627002 23191 net.cpp:165] Memory required for data: 28700684
I0615 20:53:15.627005 23191 layer_factory.hpp:77] Creating layer res2a_branch2b
I0615 20:53:15.627019 23191 net.cpp:100] Creating Layer res2a_branch2b
I0615 20:53:15.627025 23191 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0615 20:53:15.627040 23191 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0615 20:53:15.628831 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0615 20:53:15.629144 23191 net.cpp:150] Setting up res2a_branch2b
I0615 20:53:15.629158 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.629161 23191 net.cpp:165] Memory required for data: 29503500
I0615 20:53:15.629173 23191 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0615 20:53:15.629194 23191 net.cpp:100] Creating Layer bn2a_branch2b
I0615 20:53:15.629204 23191 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0615 20:53:15.629223 23191 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0615 20:53:15.629525 23191 net.cpp:150] Setting up bn2a_branch2b
I0615 20:53:15.629534 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.629539 23191 net.cpp:165] Memory required for data: 30306316
I0615 20:53:15.629559 23191 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0615 20:53:15.629582 23191 net.cpp:100] Creating Layer scale2a_branch2b
I0615 20:53:15.629590 23191 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0615 20:53:15.629607 23191 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0615 20:53:15.629679 23191 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0615 20:53:15.629870 23191 net.cpp:150] Setting up scale2a_branch2b
I0615 20:53:15.629878 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.629882 23191 net.cpp:165] Memory required for data: 31109132
I0615 20:53:15.629897 23191 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0615 20:53:15.629912 23191 net.cpp:100] Creating Layer res2a_branch2b_relu
I0615 20:53:15.629920 23191 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0615 20:53:15.629935 23191 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0615 20:53:15.630363 23191 net.cpp:150] Setting up res2a_branch2b_relu
I0615 20:53:15.630374 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.630378 23191 net.cpp:165] Memory required for data: 31911948
I0615 20:53:15.630384 23191 layer_factory.hpp:77] Creating layer res2a_branch2c
I0615 20:53:15.630404 23191 net.cpp:100] Creating Layer res2a_branch2c
I0615 20:53:15.630412 23191 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0615 20:53:15.630432 23191 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0615 20:53:15.631439 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.631459 23191 net.cpp:150] Setting up res2a_branch2c
I0615 20:53:15.631471 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.631475 23191 net.cpp:165] Memory required for data: 35123212
I0615 20:53:15.631489 23191 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0615 20:53:15.631505 23191 net.cpp:100] Creating Layer bn2a_branch2c
I0615 20:53:15.631512 23191 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0615 20:53:15.631531 23191 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0615 20:53:15.631796 23191 net.cpp:150] Setting up bn2a_branch2c
I0615 20:53:15.631804 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.631808 23191 net.cpp:165] Memory required for data: 38334476
I0615 20:53:15.631829 23191 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0615 20:53:15.631846 23191 net.cpp:100] Creating Layer scale2a_branch2c
I0615 20:53:15.631853 23191 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0615 20:53:15.631871 23191 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0615 20:53:15.631939 23191 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0615 20:53:15.632120 23191 net.cpp:150] Setting up scale2a_branch2c
I0615 20:53:15.632129 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.632133 23191 net.cpp:165] Memory required for data: 41545740
I0615 20:53:15.632148 23191 layer_factory.hpp:77] Creating layer res2a
I0615 20:53:15.632163 23191 net.cpp:100] Creating Layer res2a
I0615 20:53:15.632170 23191 net.cpp:444] res2a <- res2a_branch1
I0615 20:53:15.632184 23191 net.cpp:444] res2a <- res2a_branch2c
I0615 20:53:15.632196 23191 net.cpp:418] res2a -> res2a
I0615 20:53:15.632242 23191 net.cpp:150] Setting up res2a
I0615 20:53:15.632252 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.632257 23191 net.cpp:165] Memory required for data: 44757004
I0615 20:53:15.632262 23191 layer_factory.hpp:77] Creating layer res2a_relu
I0615 20:53:15.632275 23191 net.cpp:100] Creating Layer res2a_relu
I0615 20:53:15.632283 23191 net.cpp:444] res2a_relu <- res2a
I0615 20:53:15.632298 23191 net.cpp:405] res2a_relu -> res2a (in-place)
I0615 20:53:15.632483 23191 net.cpp:150] Setting up res2a_relu
I0615 20:53:15.632493 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.632496 23191 net.cpp:165] Memory required for data: 47968268
I0615 20:53:15.632503 23191 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0615 20:53:15.632519 23191 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0615 20:53:15.632526 23191 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0615 20:53:15.632544 23191 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0615 20:53:15.632563 23191 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0615 20:53:15.632627 23191 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0615 20:53:15.632637 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.632644 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.632648 23191 net.cpp:165] Memory required for data: 54390796
I0615 20:53:15.632654 23191 layer_factory.hpp:77] Creating layer res2b_branch2a
I0615 20:53:15.632673 23191 net.cpp:100] Creating Layer res2b_branch2a
I0615 20:53:15.632680 23191 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0615 20:53:15.632699 23191 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0615 20:53:15.633759 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.633780 23191 net.cpp:150] Setting up res2b_branch2a
I0615 20:53:15.633790 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.633795 23191 net.cpp:165] Memory required for data: 55193612
I0615 20:53:15.633808 23191 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0615 20:53:15.633826 23191 net.cpp:100] Creating Layer bn2b_branch2a
I0615 20:53:15.633834 23191 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0615 20:53:15.633852 23191 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0615 20:53:15.634130 23191 net.cpp:150] Setting up bn2b_branch2a
I0615 20:53:15.634138 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.634142 23191 net.cpp:165] Memory required for data: 55996428
I0615 20:53:15.634178 23191 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0615 20:53:15.634197 23191 net.cpp:100] Creating Layer scale2b_branch2a
I0615 20:53:15.634204 23191 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0615 20:53:15.634222 23191 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0615 20:53:15.634294 23191 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0615 20:53:15.634485 23191 net.cpp:150] Setting up scale2b_branch2a
I0615 20:53:15.634495 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.634497 23191 net.cpp:165] Memory required for data: 56799244
I0615 20:53:15.634513 23191 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0615 20:53:15.634526 23191 net.cpp:100] Creating Layer res2b_branch2a_relu
I0615 20:53:15.634533 23191 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0615 20:53:15.634549 23191 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0615 20:53:15.634713 23191 net.cpp:150] Setting up res2b_branch2a_relu
I0615 20:53:15.634722 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.634727 23191 net.cpp:165] Memory required for data: 57602060
I0615 20:53:15.634732 23191 layer_factory.hpp:77] Creating layer res2b_branch2b
I0615 20:53:15.634759 23191 net.cpp:100] Creating Layer res2b_branch2b
I0615 20:53:15.634768 23191 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0615 20:53:15.634788 23191 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0615 20:53:15.635875 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0615 20:53:15.635895 23191 net.cpp:150] Setting up res2b_branch2b
I0615 20:53:15.635906 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.635910 23191 net.cpp:165] Memory required for data: 58404876
I0615 20:53:15.635924 23191 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0615 20:53:15.635941 23191 net.cpp:100] Creating Layer bn2b_branch2b
I0615 20:53:15.635948 23191 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0615 20:53:15.635967 23191 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0615 20:53:15.636245 23191 net.cpp:150] Setting up bn2b_branch2b
I0615 20:53:15.636253 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.636258 23191 net.cpp:165] Memory required for data: 59207692
I0615 20:53:15.636279 23191 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0615 20:53:15.636296 23191 net.cpp:100] Creating Layer scale2b_branch2b
I0615 20:53:15.636302 23191 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0615 20:53:15.636320 23191 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0615 20:53:15.636390 23191 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0615 20:53:15.636582 23191 net.cpp:150] Setting up scale2b_branch2b
I0615 20:53:15.636590 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.636595 23191 net.cpp:165] Memory required for data: 60010508
I0615 20:53:15.636608 23191 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0615 20:53:15.636622 23191 net.cpp:100] Creating Layer res2b_branch2b_relu
I0615 20:53:15.636629 23191 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0615 20:53:15.636644 23191 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0615 20:53:15.637115 23191 net.cpp:150] Setting up res2b_branch2b_relu
I0615 20:53:15.637126 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.637130 23191 net.cpp:165] Memory required for data: 60813324
I0615 20:53:15.637137 23191 layer_factory.hpp:77] Creating layer res2b_branch2c
I0615 20:53:15.637167 23191 net.cpp:100] Creating Layer res2b_branch2c
I0615 20:53:15.637176 23191 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0615 20:53:15.637194 23191 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0615 20:53:15.638211 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.638231 23191 net.cpp:150] Setting up res2b_branch2c
I0615 20:53:15.638240 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.638244 23191 net.cpp:165] Memory required for data: 64024588
I0615 20:53:15.638258 23191 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0615 20:53:15.638276 23191 net.cpp:100] Creating Layer bn2b_branch2c
I0615 20:53:15.638284 23191 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0615 20:53:15.638301 23191 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0615 20:53:15.638567 23191 net.cpp:150] Setting up bn2b_branch2c
I0615 20:53:15.638577 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.638581 23191 net.cpp:165] Memory required for data: 67235852
I0615 20:53:15.638602 23191 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0615 20:53:15.638618 23191 net.cpp:100] Creating Layer scale2b_branch2c
I0615 20:53:15.638625 23191 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0615 20:53:15.638643 23191 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0615 20:53:15.638712 23191 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0615 20:53:15.638893 23191 net.cpp:150] Setting up scale2b_branch2c
I0615 20:53:15.638902 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.638906 23191 net.cpp:165] Memory required for data: 70447116
I0615 20:53:15.638919 23191 layer_factory.hpp:77] Creating layer res2b
I0615 20:53:15.638933 23191 net.cpp:100] Creating Layer res2b
I0615 20:53:15.638942 23191 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0615 20:53:15.638954 23191 net.cpp:444] res2b <- res2b_branch2c
I0615 20:53:15.638967 23191 net.cpp:418] res2b -> res2b
I0615 20:53:15.639019 23191 net.cpp:150] Setting up res2b
I0615 20:53:15.639029 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.639034 23191 net.cpp:165] Memory required for data: 73658380
I0615 20:53:15.639039 23191 layer_factory.hpp:77] Creating layer res2b_relu
I0615 20:53:15.639053 23191 net.cpp:100] Creating Layer res2b_relu
I0615 20:53:15.639060 23191 net.cpp:444] res2b_relu <- res2b
I0615 20:53:15.639075 23191 net.cpp:405] res2b_relu -> res2b (in-place)
I0615 20:53:15.639237 23191 net.cpp:150] Setting up res2b_relu
I0615 20:53:15.639246 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.639250 23191 net.cpp:165] Memory required for data: 76869644
I0615 20:53:15.639256 23191 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0615 20:53:15.639268 23191 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0615 20:53:15.639276 23191 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0615 20:53:15.639292 23191 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0615 20:53:15.639312 23191 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0615 20:53:15.639372 23191 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0615 20:53:15.639384 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.639390 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.639394 23191 net.cpp:165] Memory required for data: 83292172
I0615 20:53:15.639400 23191 layer_factory.hpp:77] Creating layer res2c_branch2a
I0615 20:53:15.639418 23191 net.cpp:100] Creating Layer res2c_branch2a
I0615 20:53:15.639425 23191 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0615 20:53:15.639444 23191 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0615 20:53:15.640455 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.640475 23191 net.cpp:150] Setting up res2c_branch2a
I0615 20:53:15.640485 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.640488 23191 net.cpp:165] Memory required for data: 84094988
I0615 20:53:15.640501 23191 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0615 20:53:15.640521 23191 net.cpp:100] Creating Layer bn2c_branch2a
I0615 20:53:15.640527 23191 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0615 20:53:15.640545 23191 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0615 20:53:15.640823 23191 net.cpp:150] Setting up bn2c_branch2a
I0615 20:53:15.640831 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.640836 23191 net.cpp:165] Memory required for data: 84897804
I0615 20:53:15.640856 23191 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0615 20:53:15.640872 23191 net.cpp:100] Creating Layer scale2c_branch2a
I0615 20:53:15.640879 23191 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0615 20:53:15.640897 23191 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0615 20:53:15.640982 23191 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0615 20:53:15.641185 23191 net.cpp:150] Setting up scale2c_branch2a
I0615 20:53:15.641194 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.641197 23191 net.cpp:165] Memory required for data: 85700620
I0615 20:53:15.641212 23191 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0615 20:53:15.641225 23191 net.cpp:100] Creating Layer res2c_branch2a_relu
I0615 20:53:15.641232 23191 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0615 20:53:15.641249 23191 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0615 20:53:15.641412 23191 net.cpp:150] Setting up res2c_branch2a_relu
I0615 20:53:15.641420 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.641424 23191 net.cpp:165] Memory required for data: 86503436
I0615 20:53:15.641430 23191 layer_factory.hpp:77] Creating layer res2c_branch2b
I0615 20:53:15.641449 23191 net.cpp:100] Creating Layer res2c_branch2b
I0615 20:53:15.641458 23191 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0615 20:53:15.641476 23191 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0615 20:53:15.642540 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0615 20:53:15.642817 23191 net.cpp:150] Setting up res2c_branch2b
I0615 20:53:15.642830 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.642835 23191 net.cpp:165] Memory required for data: 87306252
I0615 20:53:15.642849 23191 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0615 20:53:15.642868 23191 net.cpp:100] Creating Layer bn2c_branch2b
I0615 20:53:15.642876 23191 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0615 20:53:15.642894 23191 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0615 20:53:15.643180 23191 net.cpp:150] Setting up bn2c_branch2b
I0615 20:53:15.643188 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.643191 23191 net.cpp:165] Memory required for data: 88109068
I0615 20:53:15.643211 23191 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0615 20:53:15.643229 23191 net.cpp:100] Creating Layer scale2c_branch2b
I0615 20:53:15.643236 23191 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0615 20:53:15.643252 23191 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0615 20:53:15.643323 23191 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0615 20:53:15.643519 23191 net.cpp:150] Setting up scale2c_branch2b
I0615 20:53:15.643528 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.643532 23191 net.cpp:165] Memory required for data: 88911884
I0615 20:53:15.643546 23191 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0615 20:53:15.643560 23191 net.cpp:100] Creating Layer res2c_branch2b_relu
I0615 20:53:15.643568 23191 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0615 20:53:15.643582 23191 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0615 20:53:15.643746 23191 net.cpp:150] Setting up res2c_branch2b_relu
I0615 20:53:15.643754 23191 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0615 20:53:15.643759 23191 net.cpp:165] Memory required for data: 89714700
I0615 20:53:15.643764 23191 layer_factory.hpp:77] Creating layer res2c_branch2c
I0615 20:53:15.643784 23191 net.cpp:100] Creating Layer res2c_branch2c
I0615 20:53:15.643790 23191 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0615 20:53:15.643810 23191 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0615 20:53:15.644826 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0615 20:53:15.644847 23191 net.cpp:150] Setting up res2c_branch2c
I0615 20:53:15.644857 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.644861 23191 net.cpp:165] Memory required for data: 92925964
I0615 20:53:15.644875 23191 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0615 20:53:15.644892 23191 net.cpp:100] Creating Layer bn2c_branch2c
I0615 20:53:15.644901 23191 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0615 20:53:15.644918 23191 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0615 20:53:15.645208 23191 net.cpp:150] Setting up bn2c_branch2c
I0615 20:53:15.645217 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.645221 23191 net.cpp:165] Memory required for data: 96137228
I0615 20:53:15.645261 23191 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0615 20:53:15.645279 23191 net.cpp:100] Creating Layer scale2c_branch2c
I0615 20:53:15.645287 23191 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0615 20:53:15.645304 23191 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0615 20:53:15.645375 23191 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0615 20:53:15.645555 23191 net.cpp:150] Setting up scale2c_branch2c
I0615 20:53:15.645565 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.645568 23191 net.cpp:165] Memory required for data: 99348492
I0615 20:53:15.645582 23191 layer_factory.hpp:77] Creating layer res2c
I0615 20:53:15.645596 23191 net.cpp:100] Creating Layer res2c
I0615 20:53:15.645604 23191 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0615 20:53:15.645617 23191 net.cpp:444] res2c <- res2c_branch2c
I0615 20:53:15.645632 23191 net.cpp:418] res2c -> res2c
I0615 20:53:15.645676 23191 net.cpp:150] Setting up res2c
I0615 20:53:15.645687 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.645691 23191 net.cpp:165] Memory required for data: 102559756
I0615 20:53:15.645697 23191 layer_factory.hpp:77] Creating layer res2c_relu
I0615 20:53:15.645709 23191 net.cpp:100] Creating Layer res2c_relu
I0615 20:53:15.645715 23191 net.cpp:444] res2c_relu <- res2c
I0615 20:53:15.645733 23191 net.cpp:405] res2c_relu -> res2c (in-place)
I0615 20:53:15.646162 23191 net.cpp:150] Setting up res2c_relu
I0615 20:53:15.646173 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.646176 23191 net.cpp:165] Memory required for data: 105771020
I0615 20:53:15.646183 23191 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0615 20:53:15.646198 23191 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0615 20:53:15.646204 23191 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0615 20:53:15.646221 23191 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0615 20:53:15.646242 23191 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0615 20:53:15.646307 23191 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0615 20:53:15.646318 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.646325 23191 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0615 20:53:15.646329 23191 net.cpp:165] Memory required for data: 112193548
I0615 20:53:15.646335 23191 layer_factory.hpp:77] Creating layer res3a_branch1
I0615 20:53:15.646353 23191 net.cpp:100] Creating Layer res3a_branch1
I0615 20:53:15.646361 23191 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0615 20:53:15.646379 23191 net.cpp:418] res3a_branch1 -> res3a_branch1
I0615 20:53:15.648380 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0615 20:53:15.648667 23191 net.cpp:150] Setting up res3a_branch1
I0615 20:53:15.648682 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.648689 23191 net.cpp:165] Memory required for data: 113799180
I0615 20:53:15.648706 23191 layer_factory.hpp:77] Creating layer bn3a_branch1
I0615 20:53:15.648732 23191 net.cpp:100] Creating Layer bn3a_branch1
I0615 20:53:15.648743 23191 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0615 20:53:15.648764 23191 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0615 20:53:15.649881 23191 net.cpp:150] Setting up bn3a_branch1
I0615 20:53:15.649894 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.649896 23191 net.cpp:165] Memory required for data: 115404812
I0615 20:53:15.649921 23191 layer_factory.hpp:77] Creating layer scale3a_branch1
I0615 20:53:15.649940 23191 net.cpp:100] Creating Layer scale3a_branch1
I0615 20:53:15.649948 23191 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0615 20:53:15.649962 23191 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0615 20:53:15.650041 23191 layer_factory.hpp:77] Creating layer scale3a_branch1
I0615 20:53:15.650216 23191 net.cpp:150] Setting up scale3a_branch1
I0615 20:53:15.650224 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.650226 23191 net.cpp:165] Memory required for data: 117010444
I0615 20:53:15.650238 23191 layer_factory.hpp:77] Creating layer res3a_branch2a
I0615 20:53:15.650255 23191 net.cpp:100] Creating Layer res3a_branch2a
I0615 20:53:15.650261 23191 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0615 20:53:15.650275 23191 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0615 20:53:15.651428 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0615 20:53:15.651453 23191 net.cpp:150] Setting up res3a_branch2a
I0615 20:53:15.651460 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.651463 23191 net.cpp:165] Memory required for data: 117411852
I0615 20:53:15.651474 23191 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0615 20:53:15.651489 23191 net.cpp:100] Creating Layer bn3a_branch2a
I0615 20:53:15.651495 23191 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0615 20:53:15.651510 23191 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0615 20:53:15.651779 23191 net.cpp:150] Setting up bn3a_branch2a
I0615 20:53:15.651787 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.651788 23191 net.cpp:165] Memory required for data: 117813260
I0615 20:53:15.651805 23191 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0615 20:53:15.651818 23191 net.cpp:100] Creating Layer scale3a_branch2a
I0615 20:53:15.651824 23191 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0615 20:53:15.651836 23191 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0615 20:53:15.651901 23191 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0615 20:53:15.652074 23191 net.cpp:150] Setting up scale3a_branch2a
I0615 20:53:15.652082 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.652084 23191 net.cpp:165] Memory required for data: 118214668
I0615 20:53:15.652096 23191 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0615 20:53:15.652107 23191 net.cpp:100] Creating Layer res3a_branch2a_relu
I0615 20:53:15.652112 23191 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0615 20:53:15.652122 23191 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0615 20:53:15.652588 23191 net.cpp:150] Setting up res3a_branch2a_relu
I0615 20:53:15.652597 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.652601 23191 net.cpp:165] Memory required for data: 118616076
I0615 20:53:15.652606 23191 layer_factory.hpp:77] Creating layer res3a_branch2b
I0615 20:53:15.652623 23191 net.cpp:100] Creating Layer res3a_branch2b
I0615 20:53:15.652631 23191 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0615 20:53:15.652647 23191 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0615 20:53:15.653961 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0615 20:53:15.654243 23191 net.cpp:150] Setting up res3a_branch2b
I0615 20:53:15.654256 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.654259 23191 net.cpp:165] Memory required for data: 119017484
I0615 20:53:15.654271 23191 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0615 20:53:15.654286 23191 net.cpp:100] Creating Layer bn3a_branch2b
I0615 20:53:15.654292 23191 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0615 20:53:15.654306 23191 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0615 20:53:15.654582 23191 net.cpp:150] Setting up bn3a_branch2b
I0615 20:53:15.654587 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.654592 23191 net.cpp:165] Memory required for data: 119418892
I0615 20:53:15.654608 23191 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0615 20:53:15.654621 23191 net.cpp:100] Creating Layer scale3a_branch2b
I0615 20:53:15.654626 23191 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0615 20:53:15.654639 23191 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0615 20:53:15.654703 23191 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0615 20:53:15.654876 23191 net.cpp:150] Setting up scale3a_branch2b
I0615 20:53:15.654883 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.654886 23191 net.cpp:165] Memory required for data: 119820300
I0615 20:53:15.654897 23191 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0615 20:53:15.654909 23191 net.cpp:100] Creating Layer res3a_branch2b_relu
I0615 20:53:15.654914 23191 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0615 20:53:15.654925 23191 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0615 20:53:15.655084 23191 net.cpp:150] Setting up res3a_branch2b_relu
I0615 20:53:15.655092 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.655094 23191 net.cpp:165] Memory required for data: 120221708
I0615 20:53:15.655098 23191 layer_factory.hpp:77] Creating layer res3a_branch2c
I0615 20:53:15.655114 23191 net.cpp:100] Creating Layer res3a_branch2c
I0615 20:53:15.655120 23191 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0615 20:53:15.655134 23191 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0615 20:53:15.656247 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.656263 23191 net.cpp:150] Setting up res3a_branch2c
I0615 20:53:15.656271 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.656275 23191 net.cpp:165] Memory required for data: 121827340
I0615 20:53:15.656286 23191 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0615 20:53:15.656311 23191 net.cpp:100] Creating Layer bn3a_branch2c
I0615 20:53:15.656317 23191 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0615 20:53:15.656332 23191 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0615 20:53:15.656605 23191 net.cpp:150] Setting up bn3a_branch2c
I0615 20:53:15.656612 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.656615 23191 net.cpp:165] Memory required for data: 123432972
I0615 20:53:15.656631 23191 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0615 20:53:15.656646 23191 net.cpp:100] Creating Layer scale3a_branch2c
I0615 20:53:15.656651 23191 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0615 20:53:15.656664 23191 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0615 20:53:15.656730 23191 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0615 20:53:15.656904 23191 net.cpp:150] Setting up scale3a_branch2c
I0615 20:53:15.656913 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.656914 23191 net.cpp:165] Memory required for data: 125038604
I0615 20:53:15.656925 23191 layer_factory.hpp:77] Creating layer res3a
I0615 20:53:15.656936 23191 net.cpp:100] Creating Layer res3a
I0615 20:53:15.656951 23191 net.cpp:444] res3a <- res3a_branch1
I0615 20:53:15.656963 23191 net.cpp:444] res3a <- res3a_branch2c
I0615 20:53:15.656977 23191 net.cpp:418] res3a -> res3a
I0615 20:53:15.657025 23191 net.cpp:150] Setting up res3a
I0615 20:53:15.657033 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.657037 23191 net.cpp:165] Memory required for data: 126644236
I0615 20:53:15.657040 23191 layer_factory.hpp:77] Creating layer res3a_relu
I0615 20:53:15.657050 23191 net.cpp:100] Creating Layer res3a_relu
I0615 20:53:15.657055 23191 net.cpp:444] res3a_relu <- res3a
I0615 20:53:15.657066 23191 net.cpp:405] res3a_relu -> res3a (in-place)
I0615 20:53:15.657505 23191 net.cpp:150] Setting up res3a_relu
I0615 20:53:15.657516 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.657519 23191 net.cpp:165] Memory required for data: 128249868
I0615 20:53:15.657524 23191 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0615 20:53:15.657536 23191 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0615 20:53:15.657541 23191 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0615 20:53:15.657557 23191 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0615 20:53:15.657572 23191 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0615 20:53:15.657634 23191 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0615 20:53:15.657642 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.657647 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.657650 23191 net.cpp:165] Memory required for data: 131461132
I0615 20:53:15.657655 23191 layer_factory.hpp:77] Creating layer res3b_branch2a
I0615 20:53:15.657668 23191 net.cpp:100] Creating Layer res3b_branch2a
I0615 20:53:15.657675 23191 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0615 20:53:15.657687 23191 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0615 20:53:15.659377 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.659394 23191 net.cpp:150] Setting up res3b_branch2a
I0615 20:53:15.659402 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.659406 23191 net.cpp:165] Memory required for data: 131862540
I0615 20:53:15.659416 23191 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0615 20:53:15.659432 23191 net.cpp:100] Creating Layer bn3b_branch2a
I0615 20:53:15.659438 23191 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0615 20:53:15.659453 23191 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0615 20:53:15.659720 23191 net.cpp:150] Setting up bn3b_branch2a
I0615 20:53:15.659727 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.659730 23191 net.cpp:165] Memory required for data: 132263948
I0615 20:53:15.659746 23191 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0615 20:53:15.659760 23191 net.cpp:100] Creating Layer scale3b_branch2a
I0615 20:53:15.659766 23191 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0615 20:53:15.659778 23191 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0615 20:53:15.659842 23191 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0615 20:53:15.660015 23191 net.cpp:150] Setting up scale3b_branch2a
I0615 20:53:15.660023 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.660027 23191 net.cpp:165] Memory required for data: 132665356
I0615 20:53:15.660037 23191 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0615 20:53:15.660048 23191 net.cpp:100] Creating Layer res3b_branch2a_relu
I0615 20:53:15.660053 23191 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0615 20:53:15.660064 23191 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0615 20:53:15.660224 23191 net.cpp:150] Setting up res3b_branch2a_relu
I0615 20:53:15.660231 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.660234 23191 net.cpp:165] Memory required for data: 133066764
I0615 20:53:15.660239 23191 layer_factory.hpp:77] Creating layer res3b_branch2b
I0615 20:53:15.660254 23191 net.cpp:100] Creating Layer res3b_branch2b
I0615 20:53:15.660260 23191 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0615 20:53:15.660274 23191 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0615 20:53:15.661579 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0615 20:53:15.661865 23191 net.cpp:150] Setting up res3b_branch2b
I0615 20:53:15.661876 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.661880 23191 net.cpp:165] Memory required for data: 133468172
I0615 20:53:15.661891 23191 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0615 20:53:15.661904 23191 net.cpp:100] Creating Layer bn3b_branch2b
I0615 20:53:15.661911 23191 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0615 20:53:15.661926 23191 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0615 20:53:15.662204 23191 net.cpp:150] Setting up bn3b_branch2b
I0615 20:53:15.662210 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.662212 23191 net.cpp:165] Memory required for data: 133869580
I0615 20:53:15.662228 23191 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0615 20:53:15.662241 23191 net.cpp:100] Creating Layer scale3b_branch2b
I0615 20:53:15.662247 23191 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0615 20:53:15.662259 23191 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0615 20:53:15.662325 23191 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0615 20:53:15.662505 23191 net.cpp:150] Setting up scale3b_branch2b
I0615 20:53:15.662513 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.662515 23191 net.cpp:165] Memory required for data: 134270988
I0615 20:53:15.662526 23191 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0615 20:53:15.662536 23191 net.cpp:100] Creating Layer res3b_branch2b_relu
I0615 20:53:15.662542 23191 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0615 20:53:15.662554 23191 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0615 20:53:15.662717 23191 net.cpp:150] Setting up res3b_branch2b_relu
I0615 20:53:15.662725 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.662729 23191 net.cpp:165] Memory required for data: 134672396
I0615 20:53:15.662732 23191 layer_factory.hpp:77] Creating layer res3b_branch2c
I0615 20:53:15.662747 23191 net.cpp:100] Creating Layer res3b_branch2c
I0615 20:53:15.662753 23191 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0615 20:53:15.662770 23191 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0615 20:53:15.663893 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.663908 23191 net.cpp:150] Setting up res3b_branch2c
I0615 20:53:15.663916 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.663919 23191 net.cpp:165] Memory required for data: 136278028
I0615 20:53:15.663930 23191 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0615 20:53:15.663944 23191 net.cpp:100] Creating Layer bn3b_branch2c
I0615 20:53:15.663952 23191 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0615 20:53:15.663965 23191 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0615 20:53:15.664245 23191 net.cpp:150] Setting up bn3b_branch2c
I0615 20:53:15.664252 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.664255 23191 net.cpp:165] Memory required for data: 137883660
I0615 20:53:15.664271 23191 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0615 20:53:15.664284 23191 net.cpp:100] Creating Layer scale3b_branch2c
I0615 20:53:15.664289 23191 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0615 20:53:15.664302 23191 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0615 20:53:15.664371 23191 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0615 20:53:15.664547 23191 net.cpp:150] Setting up scale3b_branch2c
I0615 20:53:15.664554 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.664557 23191 net.cpp:165] Memory required for data: 139489292
I0615 20:53:15.664568 23191 layer_factory.hpp:77] Creating layer res3b
I0615 20:53:15.664579 23191 net.cpp:100] Creating Layer res3b
I0615 20:53:15.664584 23191 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0615 20:53:15.664594 23191 net.cpp:444] res3b <- res3b_branch2c
I0615 20:53:15.664604 23191 net.cpp:418] res3b -> res3b
I0615 20:53:15.664645 23191 net.cpp:150] Setting up res3b
I0615 20:53:15.664654 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.664656 23191 net.cpp:165] Memory required for data: 141094924
I0615 20:53:15.664660 23191 layer_factory.hpp:77] Creating layer res3b_relu
I0615 20:53:15.664669 23191 net.cpp:100] Creating Layer res3b_relu
I0615 20:53:15.664674 23191 net.cpp:444] res3b_relu <- res3b
I0615 20:53:15.664685 23191 net.cpp:405] res3b_relu -> res3b (in-place)
I0615 20:53:15.665138 23191 net.cpp:150] Setting up res3b_relu
I0615 20:53:15.665148 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.665151 23191 net.cpp:165] Memory required for data: 142700556
I0615 20:53:15.665156 23191 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0615 20:53:15.665168 23191 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0615 20:53:15.665174 23191 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0615 20:53:15.665189 23191 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0615 20:53:15.665204 23191 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0615 20:53:15.665266 23191 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0615 20:53:15.665274 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.665278 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.665282 23191 net.cpp:165] Memory required for data: 145911820
I0615 20:53:15.665285 23191 layer_factory.hpp:77] Creating layer res3c_branch2a
I0615 20:53:15.665300 23191 net.cpp:100] Creating Layer res3c_branch2a
I0615 20:53:15.665307 23191 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0615 20:53:15.665323 23191 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0615 20:53:15.666442 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.666458 23191 net.cpp:150] Setting up res3c_branch2a
I0615 20:53:15.666466 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.666471 23191 net.cpp:165] Memory required for data: 146313228
I0615 20:53:15.666481 23191 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0615 20:53:15.666494 23191 net.cpp:100] Creating Layer bn3c_branch2a
I0615 20:53:15.666501 23191 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0615 20:53:15.666515 23191 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0615 20:53:15.666790 23191 net.cpp:150] Setting up bn3c_branch2a
I0615 20:53:15.666796 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.666798 23191 net.cpp:165] Memory required for data: 146714636
I0615 20:53:15.666815 23191 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0615 20:53:15.666829 23191 net.cpp:100] Creating Layer scale3c_branch2a
I0615 20:53:15.666834 23191 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0615 20:53:15.666847 23191 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0615 20:53:15.666913 23191 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0615 20:53:15.667088 23191 net.cpp:150] Setting up scale3c_branch2a
I0615 20:53:15.667095 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.667098 23191 net.cpp:165] Memory required for data: 147116044
I0615 20:53:15.667109 23191 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0615 20:53:15.667121 23191 net.cpp:100] Creating Layer res3c_branch2a_relu
I0615 20:53:15.667127 23191 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0615 20:53:15.667137 23191 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0615 20:53:15.667300 23191 net.cpp:150] Setting up res3c_branch2a_relu
I0615 20:53:15.667307 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.667310 23191 net.cpp:165] Memory required for data: 147517452
I0615 20:53:15.667315 23191 layer_factory.hpp:77] Creating layer res3c_branch2b
I0615 20:53:15.667330 23191 net.cpp:100] Creating Layer res3c_branch2b
I0615 20:53:15.667336 23191 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0615 20:53:15.667351 23191 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0615 20:53:15.669454 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0615 20:53:15.669742 23191 net.cpp:150] Setting up res3c_branch2b
I0615 20:53:15.669754 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.669757 23191 net.cpp:165] Memory required for data: 147918860
I0615 20:53:15.669770 23191 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0615 20:53:15.669786 23191 net.cpp:100] Creating Layer bn3c_branch2b
I0615 20:53:15.669793 23191 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0615 20:53:15.669807 23191 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0615 20:53:15.670099 23191 net.cpp:150] Setting up bn3c_branch2b
I0615 20:53:15.670107 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.670109 23191 net.cpp:165] Memory required for data: 148320268
I0615 20:53:15.670126 23191 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0615 20:53:15.670140 23191 net.cpp:100] Creating Layer scale3c_branch2b
I0615 20:53:15.670146 23191 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0615 20:53:15.670159 23191 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0615 20:53:15.670225 23191 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0615 20:53:15.670403 23191 net.cpp:150] Setting up scale3c_branch2b
I0615 20:53:15.670411 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.670413 23191 net.cpp:165] Memory required for data: 148721676
I0615 20:53:15.670423 23191 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0615 20:53:15.670433 23191 net.cpp:100] Creating Layer res3c_branch2b_relu
I0615 20:53:15.670439 23191 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0615 20:53:15.670450 23191 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0615 20:53:15.670615 23191 net.cpp:150] Setting up res3c_branch2b_relu
I0615 20:53:15.670622 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.670625 23191 net.cpp:165] Memory required for data: 149123084
I0615 20:53:15.670630 23191 layer_factory.hpp:77] Creating layer res3c_branch2c
I0615 20:53:15.670645 23191 net.cpp:100] Creating Layer res3c_branch2c
I0615 20:53:15.670651 23191 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0615 20:53:15.670666 23191 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0615 20:53:15.671813 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.671829 23191 net.cpp:150] Setting up res3c_branch2c
I0615 20:53:15.671838 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.671840 23191 net.cpp:165] Memory required for data: 150728716
I0615 20:53:15.671850 23191 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0615 20:53:15.671865 23191 net.cpp:100] Creating Layer bn3c_branch2c
I0615 20:53:15.671871 23191 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0615 20:53:15.671886 23191 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0615 20:53:15.672168 23191 net.cpp:150] Setting up bn3c_branch2c
I0615 20:53:15.672174 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.672176 23191 net.cpp:165] Memory required for data: 152334348
I0615 20:53:15.672192 23191 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0615 20:53:15.672206 23191 net.cpp:100] Creating Layer scale3c_branch2c
I0615 20:53:15.672212 23191 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0615 20:53:15.672224 23191 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0615 20:53:15.672293 23191 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0615 20:53:15.672469 23191 net.cpp:150] Setting up scale3c_branch2c
I0615 20:53:15.672477 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.672479 23191 net.cpp:165] Memory required for data: 153939980
I0615 20:53:15.672490 23191 layer_factory.hpp:77] Creating layer res3c
I0615 20:53:15.672502 23191 net.cpp:100] Creating Layer res3c
I0615 20:53:15.672508 23191 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0615 20:53:15.672518 23191 net.cpp:444] res3c <- res3c_branch2c
I0615 20:53:15.672528 23191 net.cpp:418] res3c -> res3c
I0615 20:53:15.672570 23191 net.cpp:150] Setting up res3c
I0615 20:53:15.672578 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.672581 23191 net.cpp:165] Memory required for data: 155545612
I0615 20:53:15.672585 23191 layer_factory.hpp:77] Creating layer res3c_relu
I0615 20:53:15.672595 23191 net.cpp:100] Creating Layer res3c_relu
I0615 20:53:15.672600 23191 net.cpp:444] res3c_relu <- res3c
I0615 20:53:15.672611 23191 net.cpp:405] res3c_relu -> res3c (in-place)
I0615 20:53:15.672772 23191 net.cpp:150] Setting up res3c_relu
I0615 20:53:15.672780 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.672782 23191 net.cpp:165] Memory required for data: 157151244
I0615 20:53:15.672786 23191 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0615 20:53:15.672798 23191 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0615 20:53:15.672803 23191 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0615 20:53:15.672816 23191 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0615 20:53:15.672830 23191 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0615 20:53:15.672889 23191 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0615 20:53:15.672899 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.672904 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.672906 23191 net.cpp:165] Memory required for data: 160362508
I0615 20:53:15.672909 23191 layer_factory.hpp:77] Creating layer res3d_branch2a
I0615 20:53:15.672924 23191 net.cpp:100] Creating Layer res3d_branch2a
I0615 20:53:15.672930 23191 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0615 20:53:15.672950 23191 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0615 20:53:15.674892 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.674908 23191 net.cpp:150] Setting up res3d_branch2a
I0615 20:53:15.674917 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.674921 23191 net.cpp:165] Memory required for data: 160763916
I0615 20:53:15.674932 23191 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0615 20:53:15.674947 23191 net.cpp:100] Creating Layer bn3d_branch2a
I0615 20:53:15.674954 23191 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0615 20:53:15.674968 23191 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0615 20:53:15.675251 23191 net.cpp:150] Setting up bn3d_branch2a
I0615 20:53:15.675258 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.675261 23191 net.cpp:165] Memory required for data: 161165324
I0615 20:53:15.675304 23191 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0615 20:53:15.675319 23191 net.cpp:100] Creating Layer scale3d_branch2a
I0615 20:53:15.675325 23191 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0615 20:53:15.675338 23191 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0615 20:53:15.675405 23191 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0615 20:53:15.675582 23191 net.cpp:150] Setting up scale3d_branch2a
I0615 20:53:15.675590 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.675593 23191 net.cpp:165] Memory required for data: 161566732
I0615 20:53:15.675603 23191 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0615 20:53:15.675614 23191 net.cpp:100] Creating Layer res3d_branch2a_relu
I0615 20:53:15.675619 23191 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0615 20:53:15.675631 23191 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0615 20:53:15.676074 23191 net.cpp:150] Setting up res3d_branch2a_relu
I0615 20:53:15.676084 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.676087 23191 net.cpp:165] Memory required for data: 161968140
I0615 20:53:15.676091 23191 layer_factory.hpp:77] Creating layer res3d_branch2b
I0615 20:53:15.676108 23191 net.cpp:100] Creating Layer res3d_branch2b
I0615 20:53:15.676115 23191 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0615 20:53:15.676131 23191 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0615 20:53:15.677445 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0615 20:53:15.677731 23191 net.cpp:150] Setting up res3d_branch2b
I0615 20:53:15.677742 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.677745 23191 net.cpp:165] Memory required for data: 162369548
I0615 20:53:15.677757 23191 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0615 20:53:15.677772 23191 net.cpp:100] Creating Layer bn3d_branch2b
I0615 20:53:15.677778 23191 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0615 20:53:15.677793 23191 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0615 20:53:15.678081 23191 net.cpp:150] Setting up bn3d_branch2b
I0615 20:53:15.678087 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.678091 23191 net.cpp:165] Memory required for data: 162770956
I0615 20:53:15.678107 23191 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0615 20:53:15.678120 23191 net.cpp:100] Creating Layer scale3d_branch2b
I0615 20:53:15.678126 23191 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0615 20:53:15.678138 23191 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0615 20:53:15.678205 23191 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0615 20:53:15.678382 23191 net.cpp:150] Setting up scale3d_branch2b
I0615 20:53:15.678390 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.678392 23191 net.cpp:165] Memory required for data: 163172364
I0615 20:53:15.678402 23191 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0615 20:53:15.678412 23191 net.cpp:100] Creating Layer res3d_branch2b_relu
I0615 20:53:15.678417 23191 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0615 20:53:15.678428 23191 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0615 20:53:15.678599 23191 net.cpp:150] Setting up res3d_branch2b_relu
I0615 20:53:15.678606 23191 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0615 20:53:15.678608 23191 net.cpp:165] Memory required for data: 163573772
I0615 20:53:15.678613 23191 layer_factory.hpp:77] Creating layer res3d_branch2c
I0615 20:53:15.678627 23191 net.cpp:100] Creating Layer res3d_branch2c
I0615 20:53:15.678633 23191 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0615 20:53:15.678647 23191 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0615 20:53:15.679793 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0615 20:53:15.679810 23191 net.cpp:150] Setting up res3d_branch2c
I0615 20:53:15.679817 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.679821 23191 net.cpp:165] Memory required for data: 165179404
I0615 20:53:15.679831 23191 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0615 20:53:15.679847 23191 net.cpp:100] Creating Layer bn3d_branch2c
I0615 20:53:15.679852 23191 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0615 20:53:15.679865 23191 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0615 20:53:15.680146 23191 net.cpp:150] Setting up bn3d_branch2c
I0615 20:53:15.680153 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.680156 23191 net.cpp:165] Memory required for data: 166785036
I0615 20:53:15.680171 23191 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0615 20:53:15.680184 23191 net.cpp:100] Creating Layer scale3d_branch2c
I0615 20:53:15.680191 23191 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0615 20:53:15.680203 23191 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0615 20:53:15.680272 23191 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0615 20:53:15.680451 23191 net.cpp:150] Setting up scale3d_branch2c
I0615 20:53:15.680459 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.680461 23191 net.cpp:165] Memory required for data: 168390668
I0615 20:53:15.680472 23191 layer_factory.hpp:77] Creating layer res3d
I0615 20:53:15.680483 23191 net.cpp:100] Creating Layer res3d
I0615 20:53:15.680490 23191 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0615 20:53:15.680500 23191 net.cpp:444] res3d <- res3d_branch2c
I0615 20:53:15.680510 23191 net.cpp:418] res3d -> res3d
I0615 20:53:15.680552 23191 net.cpp:150] Setting up res3d
I0615 20:53:15.680559 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.680562 23191 net.cpp:165] Memory required for data: 169996300
I0615 20:53:15.680567 23191 layer_factory.hpp:77] Creating layer res3d_relu
I0615 20:53:15.680577 23191 net.cpp:100] Creating Layer res3d_relu
I0615 20:53:15.680583 23191 net.cpp:444] res3d_relu <- res3d
I0615 20:53:15.680593 23191 net.cpp:405] res3d_relu -> res3d (in-place)
I0615 20:53:15.680757 23191 net.cpp:150] Setting up res3d_relu
I0615 20:53:15.680768 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.680771 23191 net.cpp:165] Memory required for data: 171601932
I0615 20:53:15.680778 23191 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0615 20:53:15.680791 23191 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0615 20:53:15.680799 23191 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0615 20:53:15.680816 23191 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0615 20:53:15.680835 23191 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0615 20:53:15.680912 23191 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0615 20:53:15.680923 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.680929 23191 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0615 20:53:15.680933 23191 net.cpp:165] Memory required for data: 174813196
I0615 20:53:15.680943 23191 layer_factory.hpp:77] Creating layer res4a_branch1
I0615 20:53:15.680963 23191 net.cpp:100] Creating Layer res4a_branch1
I0615 20:53:15.680969 23191 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0615 20:53:15.680989 23191 net.cpp:418] res4a_branch1 -> res4a_branch1
I0615 20:53:15.683818 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7416
I0615 20:53:15.683848 23191 net.cpp:150] Setting up res4a_branch1
I0615 20:53:15.683861 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.683864 23191 net.cpp:165] Memory required for data: 175616012
I0615 20:53:15.683881 23191 layer_factory.hpp:77] Creating layer bn4a_branch1
I0615 20:53:15.683902 23191 net.cpp:100] Creating Layer bn4a_branch1
I0615 20:53:15.683910 23191 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0615 20:53:15.683926 23191 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0615 20:53:15.684237 23191 net.cpp:150] Setting up bn4a_branch1
I0615 20:53:15.684245 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.684247 23191 net.cpp:165] Memory required for data: 176418828
I0615 20:53:15.684263 23191 layer_factory.hpp:77] Creating layer scale4a_branch1
I0615 20:53:15.684279 23191 net.cpp:100] Creating Layer scale4a_branch1
I0615 20:53:15.684285 23191 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0615 20:53:15.684298 23191 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0615 20:53:15.684360 23191 layer_factory.hpp:77] Creating layer scale4a_branch1
I0615 20:53:15.684547 23191 net.cpp:150] Setting up scale4a_branch1
I0615 20:53:15.684556 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.684557 23191 net.cpp:165] Memory required for data: 177221644
I0615 20:53:15.684567 23191 layer_factory.hpp:77] Creating layer res4a_branch2a
I0615 20:53:15.684584 23191 net.cpp:100] Creating Layer res4a_branch2a
I0615 20:53:15.684592 23191 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0615 20:53:15.684604 23191 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0615 20:53:15.685936 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7032
I0615 20:53:15.685961 23191 net.cpp:150] Setting up res4a_branch2a
I0615 20:53:15.685969 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.685972 23191 net.cpp:165] Memory required for data: 177422348
I0615 20:53:15.685983 23191 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0615 20:53:15.685999 23191 net.cpp:100] Creating Layer bn4a_branch2a
I0615 20:53:15.686007 23191 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0615 20:53:15.686022 23191 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0615 20:53:15.686307 23191 net.cpp:150] Setting up bn4a_branch2a
I0615 20:53:15.686316 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.686318 23191 net.cpp:165] Memory required for data: 177623052
I0615 20:53:15.686336 23191 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0615 20:53:15.686352 23191 net.cpp:100] Creating Layer scale4a_branch2a
I0615 20:53:15.686357 23191 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0615 20:53:15.686369 23191 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0615 20:53:15.686439 23191 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0615 20:53:15.686619 23191 net.cpp:150] Setting up scale4a_branch2a
I0615 20:53:15.686626 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.686630 23191 net.cpp:165] Memory required for data: 177823756
I0615 20:53:15.686640 23191 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0615 20:53:15.686652 23191 net.cpp:100] Creating Layer res4a_branch2a_relu
I0615 20:53:15.686657 23191 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0615 20:53:15.686668 23191 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0615 20:53:15.687147 23191 net.cpp:150] Setting up res4a_branch2a_relu
I0615 20:53:15.687158 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.687161 23191 net.cpp:165] Memory required for data: 178024460
I0615 20:53:15.687166 23191 layer_factory.hpp:77] Creating layer res4a_branch2b
I0615 20:53:15.687183 23191 net.cpp:100] Creating Layer res4a_branch2b
I0615 20:53:15.687189 23191 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0615 20:53:15.687204 23191 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0615 20:53:15.690196 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0615 20:53:15.690495 23191 net.cpp:150] Setting up res4a_branch2b
I0615 20:53:15.690510 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.690513 23191 net.cpp:165] Memory required for data: 178225164
I0615 20:53:15.690529 23191 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0615 20:53:15.690548 23191 net.cpp:100] Creating Layer bn4a_branch2b
I0615 20:53:15.690557 23191 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0615 20:53:15.690572 23191 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0615 20:53:15.690872 23191 net.cpp:150] Setting up bn4a_branch2b
I0615 20:53:15.690881 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.690882 23191 net.cpp:165] Memory required for data: 178425868
I0615 20:53:15.690898 23191 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0615 20:53:15.690913 23191 net.cpp:100] Creating Layer scale4a_branch2b
I0615 20:53:15.690920 23191 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0615 20:53:15.690932 23191 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0615 20:53:15.691001 23191 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0615 20:53:15.691182 23191 net.cpp:150] Setting up scale4a_branch2b
I0615 20:53:15.691190 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.691191 23191 net.cpp:165] Memory required for data: 178626572
I0615 20:53:15.691202 23191 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0615 20:53:15.691212 23191 net.cpp:100] Creating Layer res4a_branch2b_relu
I0615 20:53:15.691217 23191 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0615 20:53:15.691229 23191 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0615 20:53:15.691397 23191 net.cpp:150] Setting up res4a_branch2b_relu
I0615 20:53:15.691406 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.691408 23191 net.cpp:165] Memory required for data: 178827276
I0615 20:53:15.691412 23191 layer_factory.hpp:77] Creating layer res4a_branch2c
I0615 20:53:15.691429 23191 net.cpp:100] Creating Layer res4a_branch2c
I0615 20:53:15.691435 23191 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0615 20:53:15.691450 23191 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0615 20:53:15.693763 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.693789 23191 net.cpp:150] Setting up res4a_branch2c
I0615 20:53:15.693796 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.693799 23191 net.cpp:165] Memory required for data: 179630092
I0615 20:53:15.693809 23191 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0615 20:53:15.693825 23191 net.cpp:100] Creating Layer bn4a_branch2c
I0615 20:53:15.693832 23191 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0615 20:53:15.693845 23191 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0615 20:53:15.694147 23191 net.cpp:150] Setting up bn4a_branch2c
I0615 20:53:15.694154 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.694157 23191 net.cpp:165] Memory required for data: 180432908
I0615 20:53:15.694173 23191 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0615 20:53:15.694188 23191 net.cpp:100] Creating Layer scale4a_branch2c
I0615 20:53:15.694193 23191 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0615 20:53:15.694205 23191 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0615 20:53:15.694269 23191 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0615 20:53:15.694458 23191 net.cpp:150] Setting up scale4a_branch2c
I0615 20:53:15.694465 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.694468 23191 net.cpp:165] Memory required for data: 181235724
I0615 20:53:15.694479 23191 layer_factory.hpp:77] Creating layer res4a
I0615 20:53:15.694490 23191 net.cpp:100] Creating Layer res4a
I0615 20:53:15.694495 23191 net.cpp:444] res4a <- res4a_branch1
I0615 20:53:15.694505 23191 net.cpp:444] res4a <- res4a_branch2c
I0615 20:53:15.694515 23191 net.cpp:418] res4a -> res4a
I0615 20:53:15.694559 23191 net.cpp:150] Setting up res4a
I0615 20:53:15.694567 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.694571 23191 net.cpp:165] Memory required for data: 182038540
I0615 20:53:15.694574 23191 layer_factory.hpp:77] Creating layer res4a_relu
I0615 20:53:15.694586 23191 net.cpp:100] Creating Layer res4a_relu
I0615 20:53:15.694591 23191 net.cpp:444] res4a_relu <- res4a
I0615 20:53:15.694602 23191 net.cpp:405] res4a_relu -> res4a (in-place)
I0615 20:53:15.695039 23191 net.cpp:150] Setting up res4a_relu
I0615 20:53:15.695047 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.695050 23191 net.cpp:165] Memory required for data: 182841356
I0615 20:53:15.695055 23191 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0615 20:53:15.695066 23191 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0615 20:53:15.695072 23191 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0615 20:53:15.695087 23191 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0615 20:53:15.695103 23191 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0615 20:53:15.695169 23191 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0615 20:53:15.695178 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.695181 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.695184 23191 net.cpp:165] Memory required for data: 184446988
I0615 20:53:15.695188 23191 layer_factory.hpp:77] Creating layer res4b_branch2a
I0615 20:53:15.695219 23191 net.cpp:100] Creating Layer res4b_branch2a
I0615 20:53:15.695225 23191 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0615 20:53:15.695240 23191 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0615 20:53:15.696699 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.696722 23191 net.cpp:150] Setting up res4b_branch2a
I0615 20:53:15.696729 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.696732 23191 net.cpp:165] Memory required for data: 184647692
I0615 20:53:15.696745 23191 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0615 20:53:15.696760 23191 net.cpp:100] Creating Layer bn4b_branch2a
I0615 20:53:15.696768 23191 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0615 20:53:15.696781 23191 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0615 20:53:15.697108 23191 net.cpp:150] Setting up bn4b_branch2a
I0615 20:53:15.697115 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.697118 23191 net.cpp:165] Memory required for data: 184848396
I0615 20:53:15.697134 23191 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0615 20:53:15.697147 23191 net.cpp:100] Creating Layer scale4b_branch2a
I0615 20:53:15.697154 23191 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0615 20:53:15.697165 23191 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0615 20:53:15.697234 23191 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0615 20:53:15.697414 23191 net.cpp:150] Setting up scale4b_branch2a
I0615 20:53:15.697422 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.697424 23191 net.cpp:165] Memory required for data: 185049100
I0615 20:53:15.697435 23191 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0615 20:53:15.697445 23191 net.cpp:100] Creating Layer res4b_branch2a_relu
I0615 20:53:15.697451 23191 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0615 20:53:15.697463 23191 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0615 20:53:15.697903 23191 net.cpp:150] Setting up res4b_branch2a_relu
I0615 20:53:15.697912 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.697916 23191 net.cpp:165] Memory required for data: 185249804
I0615 20:53:15.697921 23191 layer_factory.hpp:77] Creating layer res4b_branch2b
I0615 20:53:15.697937 23191 net.cpp:100] Creating Layer res4b_branch2b
I0615 20:53:15.697944 23191 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0615 20:53:15.697960 23191 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0615 20:53:15.700816 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0615 20:53:15.701170 23191 net.cpp:150] Setting up res4b_branch2b
I0615 20:53:15.701185 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.701189 23191 net.cpp:165] Memory required for data: 185450508
I0615 20:53:15.701205 23191 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0615 20:53:15.701225 23191 net.cpp:100] Creating Layer bn4b_branch2b
I0615 20:53:15.701232 23191 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0615 20:53:15.701247 23191 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0615 20:53:15.701555 23191 net.cpp:150] Setting up bn4b_branch2b
I0615 20:53:15.701563 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.701566 23191 net.cpp:165] Memory required for data: 185651212
I0615 20:53:15.701582 23191 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0615 20:53:15.701598 23191 net.cpp:100] Creating Layer scale4b_branch2b
I0615 20:53:15.701604 23191 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0615 20:53:15.701617 23191 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0615 20:53:15.701686 23191 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0615 20:53:15.701874 23191 net.cpp:150] Setting up scale4b_branch2b
I0615 20:53:15.701884 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.701886 23191 net.cpp:165] Memory required for data: 185851916
I0615 20:53:15.701897 23191 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0615 20:53:15.701908 23191 net.cpp:100] Creating Layer res4b_branch2b_relu
I0615 20:53:15.701915 23191 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0615 20:53:15.701926 23191 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0615 20:53:15.702097 23191 net.cpp:150] Setting up res4b_branch2b_relu
I0615 20:53:15.702105 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.702108 23191 net.cpp:165] Memory required for data: 186052620
I0615 20:53:15.702112 23191 layer_factory.hpp:77] Creating layer res4b_branch2c
I0615 20:53:15.702129 23191 net.cpp:100] Creating Layer res4b_branch2c
I0615 20:53:15.702136 23191 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0615 20:53:15.702152 23191 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0615 20:53:15.704442 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.704468 23191 net.cpp:150] Setting up res4b_branch2c
I0615 20:53:15.704478 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.704480 23191 net.cpp:165] Memory required for data: 186855436
I0615 20:53:15.704491 23191 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0615 20:53:15.704506 23191 net.cpp:100] Creating Layer bn4b_branch2c
I0615 20:53:15.704514 23191 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0615 20:53:15.704527 23191 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0615 20:53:15.704833 23191 net.cpp:150] Setting up bn4b_branch2c
I0615 20:53:15.704839 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.704843 23191 net.cpp:165] Memory required for data: 187658252
I0615 20:53:15.704859 23191 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0615 20:53:15.704874 23191 net.cpp:100] Creating Layer scale4b_branch2c
I0615 20:53:15.704879 23191 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0615 20:53:15.704891 23191 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0615 20:53:15.704969 23191 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0615 20:53:15.705183 23191 net.cpp:150] Setting up scale4b_branch2c
I0615 20:53:15.705190 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.705193 23191 net.cpp:165] Memory required for data: 188461068
I0615 20:53:15.705205 23191 layer_factory.hpp:77] Creating layer res4b
I0615 20:53:15.705217 23191 net.cpp:100] Creating Layer res4b
I0615 20:53:15.705224 23191 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0615 20:53:15.705233 23191 net.cpp:444] res4b <- res4b_branch2c
I0615 20:53:15.705242 23191 net.cpp:418] res4b -> res4b
I0615 20:53:15.705288 23191 net.cpp:150] Setting up res4b
I0615 20:53:15.705296 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.705299 23191 net.cpp:165] Memory required for data: 189263884
I0615 20:53:15.705303 23191 layer_factory.hpp:77] Creating layer res4b_relu
I0615 20:53:15.705312 23191 net.cpp:100] Creating Layer res4b_relu
I0615 20:53:15.705317 23191 net.cpp:444] res4b_relu <- res4b
I0615 20:53:15.705328 23191 net.cpp:405] res4b_relu -> res4b (in-place)
I0615 20:53:15.705492 23191 net.cpp:150] Setting up res4b_relu
I0615 20:53:15.705498 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.705502 23191 net.cpp:165] Memory required for data: 190066700
I0615 20:53:15.705505 23191 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0615 20:53:15.705515 23191 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0615 20:53:15.705520 23191 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0615 20:53:15.705534 23191 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0615 20:53:15.705549 23191 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0615 20:53:15.705612 23191 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0615 20:53:15.705621 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.705626 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.705627 23191 net.cpp:165] Memory required for data: 191672332
I0615 20:53:15.705631 23191 layer_factory.hpp:77] Creating layer res4c_branch2a
I0615 20:53:15.705646 23191 net.cpp:100] Creating Layer res4c_branch2a
I0615 20:53:15.705651 23191 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0615 20:53:15.705665 23191 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0615 20:53:15.707149 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.707170 23191 net.cpp:150] Setting up res4c_branch2a
I0615 20:53:15.707178 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.707181 23191 net.cpp:165] Memory required for data: 191873036
I0615 20:53:15.707192 23191 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0615 20:53:15.707207 23191 net.cpp:100] Creating Layer bn4c_branch2a
I0615 20:53:15.707213 23191 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0615 20:53:15.707226 23191 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0615 20:53:15.707523 23191 net.cpp:150] Setting up bn4c_branch2a
I0615 20:53:15.707530 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.707533 23191 net.cpp:165] Memory required for data: 192073740
I0615 20:53:15.707548 23191 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0615 20:53:15.707562 23191 net.cpp:100] Creating Layer scale4c_branch2a
I0615 20:53:15.707567 23191 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0615 20:53:15.707579 23191 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0615 20:53:15.707648 23191 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0615 20:53:15.707831 23191 net.cpp:150] Setting up scale4c_branch2a
I0615 20:53:15.707839 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.707842 23191 net.cpp:165] Memory required for data: 192274444
I0615 20:53:15.707852 23191 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0615 20:53:15.707864 23191 net.cpp:100] Creating Layer res4c_branch2a_relu
I0615 20:53:15.707868 23191 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0615 20:53:15.707880 23191 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0615 20:53:15.708040 23191 net.cpp:150] Setting up res4c_branch2a_relu
I0615 20:53:15.708047 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.708050 23191 net.cpp:165] Memory required for data: 192475148
I0615 20:53:15.708055 23191 layer_factory.hpp:77] Creating layer res4c_branch2b
I0615 20:53:15.708070 23191 net.cpp:100] Creating Layer res4c_branch2b
I0615 20:53:15.708076 23191 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0615 20:53:15.708091 23191 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0615 20:53:15.711009 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0615 20:53:15.711313 23191 net.cpp:150] Setting up res4c_branch2b
I0615 20:53:15.711330 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.711333 23191 net.cpp:165] Memory required for data: 192675852
I0615 20:53:15.711347 23191 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0615 20:53:15.711364 23191 net.cpp:100] Creating Layer bn4c_branch2b
I0615 20:53:15.711374 23191 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0615 20:53:15.711387 23191 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0615 20:53:15.711696 23191 net.cpp:150] Setting up bn4c_branch2b
I0615 20:53:15.711704 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.711707 23191 net.cpp:165] Memory required for data: 192876556
I0615 20:53:15.711724 23191 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0615 20:53:15.711738 23191 net.cpp:100] Creating Layer scale4c_branch2b
I0615 20:53:15.711745 23191 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0615 20:53:15.711757 23191 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0615 20:53:15.711829 23191 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0615 20:53:15.712014 23191 net.cpp:150] Setting up scale4c_branch2b
I0615 20:53:15.712023 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.712025 23191 net.cpp:165] Memory required for data: 193077260
I0615 20:53:15.712036 23191 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0615 20:53:15.712046 23191 net.cpp:100] Creating Layer res4c_branch2b_relu
I0615 20:53:15.712054 23191 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0615 20:53:15.712065 23191 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0615 20:53:15.712529 23191 net.cpp:150] Setting up res4c_branch2b_relu
I0615 20:53:15.712539 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.712543 23191 net.cpp:165] Memory required for data: 193277964
I0615 20:53:15.712550 23191 layer_factory.hpp:77] Creating layer res4c_branch2c
I0615 20:53:15.712572 23191 net.cpp:100] Creating Layer res4c_branch2c
I0615 20:53:15.712580 23191 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0615 20:53:15.712599 23191 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0615 20:53:15.714964 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.714998 23191 net.cpp:150] Setting up res4c_branch2c
I0615 20:53:15.715009 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.715013 23191 net.cpp:165] Memory required for data: 194080780
I0615 20:53:15.715029 23191 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0615 20:53:15.715050 23191 net.cpp:100] Creating Layer bn4c_branch2c
I0615 20:53:15.715059 23191 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0615 20:53:15.715076 23191 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0615 20:53:15.715399 23191 net.cpp:150] Setting up bn4c_branch2c
I0615 20:53:15.715407 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.715410 23191 net.cpp:165] Memory required for data: 194883596
I0615 20:53:15.715430 23191 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0615 20:53:15.715450 23191 net.cpp:100] Creating Layer scale4c_branch2c
I0615 20:53:15.715457 23191 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0615 20:53:15.715473 23191 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0615 20:53:15.715548 23191 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0615 20:53:15.715754 23191 net.cpp:150] Setting up scale4c_branch2c
I0615 20:53:15.715762 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.715766 23191 net.cpp:165] Memory required for data: 195686412
I0615 20:53:15.715780 23191 layer_factory.hpp:77] Creating layer res4c
I0615 20:53:15.715796 23191 net.cpp:100] Creating Layer res4c
I0615 20:53:15.715803 23191 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0615 20:53:15.715817 23191 net.cpp:444] res4c <- res4c_branch2c
I0615 20:53:15.715831 23191 net.cpp:418] res4c -> res4c
I0615 20:53:15.715881 23191 net.cpp:150] Setting up res4c
I0615 20:53:15.715891 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.715895 23191 net.cpp:165] Memory required for data: 196489228
I0615 20:53:15.715901 23191 layer_factory.hpp:77] Creating layer res4c_relu
I0615 20:53:15.715916 23191 net.cpp:100] Creating Layer res4c_relu
I0615 20:53:15.715924 23191 net.cpp:444] res4c_relu <- res4c
I0615 20:53:15.715937 23191 net.cpp:405] res4c_relu -> res4c (in-place)
I0615 20:53:15.716106 23191 net.cpp:150] Setting up res4c_relu
I0615 20:53:15.716114 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.716118 23191 net.cpp:165] Memory required for data: 197292044
I0615 20:53:15.716125 23191 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0615 20:53:15.716140 23191 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0615 20:53:15.716146 23191 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0615 20:53:15.716163 23191 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0615 20:53:15.716182 23191 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0615 20:53:15.716253 23191 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0615 20:53:15.716262 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.716269 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.716274 23191 net.cpp:165] Memory required for data: 198897676
I0615 20:53:15.716280 23191 layer_factory.hpp:77] Creating layer res4d_branch2a
I0615 20:53:15.716301 23191 net.cpp:100] Creating Layer res4d_branch2a
I0615 20:53:15.716310 23191 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0615 20:53:15.716328 23191 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0615 20:53:15.717938 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.717968 23191 net.cpp:150] Setting up res4d_branch2a
I0615 20:53:15.717978 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.717983 23191 net.cpp:165] Memory required for data: 199098380
I0615 20:53:15.717998 23191 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0615 20:53:15.718016 23191 net.cpp:100] Creating Layer bn4d_branch2a
I0615 20:53:15.718024 23191 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0615 20:53:15.718044 23191 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0615 20:53:15.718358 23191 net.cpp:150] Setting up bn4d_branch2a
I0615 20:53:15.718367 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.718371 23191 net.cpp:165] Memory required for data: 199299084
I0615 20:53:15.718391 23191 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0615 20:53:15.718408 23191 net.cpp:100] Creating Layer scale4d_branch2a
I0615 20:53:15.718416 23191 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0615 20:53:15.718433 23191 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0615 20:53:15.718510 23191 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0615 20:53:15.718708 23191 net.cpp:150] Setting up scale4d_branch2a
I0615 20:53:15.718717 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.718720 23191 net.cpp:165] Memory required for data: 199499788
I0615 20:53:15.718734 23191 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0615 20:53:15.718749 23191 net.cpp:100] Creating Layer res4d_branch2a_relu
I0615 20:53:15.718755 23191 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0615 20:53:15.718772 23191 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0615 20:53:15.718943 23191 net.cpp:150] Setting up res4d_branch2a_relu
I0615 20:53:15.718952 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.718956 23191 net.cpp:165] Memory required for data: 199700492
I0615 20:53:15.718962 23191 layer_factory.hpp:77] Creating layer res4d_branch2b
I0615 20:53:15.718982 23191 net.cpp:100] Creating Layer res4d_branch2b
I0615 20:53:15.718991 23191 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0615 20:53:15.719010 23191 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0615 20:53:15.722323 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0615 20:53:15.722664 23191 net.cpp:150] Setting up res4d_branch2b
I0615 20:53:15.722684 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.722689 23191 net.cpp:165] Memory required for data: 199901196
I0615 20:53:15.722712 23191 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0615 20:53:15.722741 23191 net.cpp:100] Creating Layer bn4d_branch2b
I0615 20:53:15.722754 23191 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0615 20:53:15.722776 23191 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0615 20:53:15.723109 23191 net.cpp:150] Setting up bn4d_branch2b
I0615 20:53:15.723117 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.723120 23191 net.cpp:165] Memory required for data: 200101900
I0615 20:53:15.723141 23191 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0615 20:53:15.723160 23191 net.cpp:100] Creating Layer scale4d_branch2b
I0615 20:53:15.723167 23191 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0615 20:53:15.723186 23191 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0615 20:53:15.723266 23191 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0615 20:53:15.723469 23191 net.cpp:150] Setting up scale4d_branch2b
I0615 20:53:15.723477 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.723481 23191 net.cpp:165] Memory required for data: 200302604
I0615 20:53:15.723495 23191 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0615 20:53:15.723510 23191 net.cpp:100] Creating Layer res4d_branch2b_relu
I0615 20:53:15.723517 23191 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0615 20:53:15.723534 23191 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0615 20:53:15.724002 23191 net.cpp:150] Setting up res4d_branch2b_relu
I0615 20:53:15.724012 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.724016 23191 net.cpp:165] Memory required for data: 200503308
I0615 20:53:15.724023 23191 layer_factory.hpp:77] Creating layer res4d_branch2c
I0615 20:53:15.724046 23191 net.cpp:100] Creating Layer res4d_branch2c
I0615 20:53:15.724054 23191 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0615 20:53:15.724073 23191 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0615 20:53:15.726433 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.726464 23191 net.cpp:150] Setting up res4d_branch2c
I0615 20:53:15.726475 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.726480 23191 net.cpp:165] Memory required for data: 201306124
I0615 20:53:15.726495 23191 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0615 20:53:15.726514 23191 net.cpp:100] Creating Layer bn4d_branch2c
I0615 20:53:15.726523 23191 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0615 20:53:15.726541 23191 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0615 20:53:15.726868 23191 net.cpp:150] Setting up bn4d_branch2c
I0615 20:53:15.726877 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.726881 23191 net.cpp:165] Memory required for data: 202108940
I0615 20:53:15.726902 23191 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0615 20:53:15.726919 23191 net.cpp:100] Creating Layer scale4d_branch2c
I0615 20:53:15.726927 23191 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0615 20:53:15.726943 23191 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0615 20:53:15.727017 23191 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0615 20:53:15.727224 23191 net.cpp:150] Setting up scale4d_branch2c
I0615 20:53:15.727233 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.727237 23191 net.cpp:165] Memory required for data: 202911756
I0615 20:53:15.727252 23191 layer_factory.hpp:77] Creating layer res4d
I0615 20:53:15.727267 23191 net.cpp:100] Creating Layer res4d
I0615 20:53:15.727274 23191 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0615 20:53:15.727288 23191 net.cpp:444] res4d <- res4d_branch2c
I0615 20:53:15.727301 23191 net.cpp:418] res4d -> res4d
I0615 20:53:15.727351 23191 net.cpp:150] Setting up res4d
I0615 20:53:15.727362 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.727366 23191 net.cpp:165] Memory required for data: 203714572
I0615 20:53:15.727372 23191 layer_factory.hpp:77] Creating layer res4d_relu
I0615 20:53:15.727386 23191 net.cpp:100] Creating Layer res4d_relu
I0615 20:53:15.727393 23191 net.cpp:444] res4d_relu <- res4d
I0615 20:53:15.727409 23191 net.cpp:405] res4d_relu -> res4d (in-place)
I0615 20:53:15.727578 23191 net.cpp:150] Setting up res4d_relu
I0615 20:53:15.727587 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.727591 23191 net.cpp:165] Memory required for data: 204517388
I0615 20:53:15.727597 23191 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0615 20:53:15.727612 23191 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0615 20:53:15.727617 23191 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0615 20:53:15.727635 23191 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0615 20:53:15.727655 23191 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0615 20:53:15.727725 23191 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0615 20:53:15.727736 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.727743 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.727747 23191 net.cpp:165] Memory required for data: 206123020
I0615 20:53:15.727752 23191 layer_factory.hpp:77] Creating layer res4e_branch2a
I0615 20:53:15.727771 23191 net.cpp:100] Creating Layer res4e_branch2a
I0615 20:53:15.727779 23191 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0615 20:53:15.727798 23191 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0615 20:53:15.729328 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.729357 23191 net.cpp:150] Setting up res4e_branch2a
I0615 20:53:15.729367 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.729372 23191 net.cpp:165] Memory required for data: 206323724
I0615 20:53:15.729385 23191 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0615 20:53:15.729403 23191 net.cpp:100] Creating Layer bn4e_branch2a
I0615 20:53:15.729411 23191 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0615 20:53:15.729430 23191 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0615 20:53:15.729773 23191 net.cpp:150] Setting up bn4e_branch2a
I0615 20:53:15.729781 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.729785 23191 net.cpp:165] Memory required for data: 206524428
I0615 20:53:15.729806 23191 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0615 20:53:15.729823 23191 net.cpp:100] Creating Layer scale4e_branch2a
I0615 20:53:15.729831 23191 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0615 20:53:15.729849 23191 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0615 20:53:15.729926 23191 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0615 20:53:15.730128 23191 net.cpp:150] Setting up scale4e_branch2a
I0615 20:53:15.730136 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.730140 23191 net.cpp:165] Memory required for data: 206725132
I0615 20:53:15.730154 23191 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0615 20:53:15.730167 23191 net.cpp:100] Creating Layer res4e_branch2a_relu
I0615 20:53:15.730175 23191 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0615 20:53:15.730191 23191 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0615 20:53:15.730360 23191 net.cpp:150] Setting up res4e_branch2a_relu
I0615 20:53:15.730368 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.730372 23191 net.cpp:165] Memory required for data: 206925836
I0615 20:53:15.730378 23191 layer_factory.hpp:77] Creating layer res4e_branch2b
I0615 20:53:15.730397 23191 net.cpp:100] Creating Layer res4e_branch2b
I0615 20:53:15.730404 23191 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0615 20:53:15.730424 23191 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0615 20:53:15.733392 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0615 20:53:15.733709 23191 net.cpp:150] Setting up res4e_branch2b
I0615 20:53:15.733726 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.733731 23191 net.cpp:165] Memory required for data: 207126540
I0615 20:53:15.733748 23191 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0615 20:53:15.733772 23191 net.cpp:100] Creating Layer bn4e_branch2b
I0615 20:53:15.733780 23191 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0615 20:53:15.733799 23191 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0615 20:53:15.734127 23191 net.cpp:150] Setting up bn4e_branch2b
I0615 20:53:15.734136 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.734139 23191 net.cpp:165] Memory required for data: 207327244
I0615 20:53:15.734159 23191 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0615 20:53:15.734179 23191 net.cpp:100] Creating Layer scale4e_branch2b
I0615 20:53:15.734186 23191 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0615 20:53:15.734202 23191 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0615 20:53:15.734282 23191 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0615 20:53:15.734484 23191 net.cpp:150] Setting up scale4e_branch2b
I0615 20:53:15.734493 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.734498 23191 net.cpp:165] Memory required for data: 207527948
I0615 20:53:15.734513 23191 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0615 20:53:15.734527 23191 net.cpp:100] Creating Layer res4e_branch2b_relu
I0615 20:53:15.734534 23191 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0615 20:53:15.734550 23191 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0615 20:53:15.735015 23191 net.cpp:150] Setting up res4e_branch2b_relu
I0615 20:53:15.735026 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.735030 23191 net.cpp:165] Memory required for data: 207728652
I0615 20:53:15.735038 23191 layer_factory.hpp:77] Creating layer res4e_branch2c
I0615 20:53:15.735057 23191 net.cpp:100] Creating Layer res4e_branch2c
I0615 20:53:15.735066 23191 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0615 20:53:15.735086 23191 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0615 20:53:15.737452 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.737484 23191 net.cpp:150] Setting up res4e_branch2c
I0615 20:53:15.737496 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.737501 23191 net.cpp:165] Memory required for data: 208531468
I0615 20:53:15.737516 23191 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0615 20:53:15.737536 23191 net.cpp:100] Creating Layer bn4e_branch2c
I0615 20:53:15.737545 23191 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0615 20:53:15.737565 23191 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0615 20:53:15.737897 23191 net.cpp:150] Setting up bn4e_branch2c
I0615 20:53:15.737906 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.737910 23191 net.cpp:165] Memory required for data: 209334284
I0615 20:53:15.737931 23191 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0615 20:53:15.737948 23191 net.cpp:100] Creating Layer scale4e_branch2c
I0615 20:53:15.737957 23191 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0615 20:53:15.737974 23191 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0615 20:53:15.738047 23191 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0615 20:53:15.738260 23191 net.cpp:150] Setting up scale4e_branch2c
I0615 20:53:15.738268 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.738272 23191 net.cpp:165] Memory required for data: 210137100
I0615 20:53:15.738287 23191 layer_factory.hpp:77] Creating layer res4e
I0615 20:53:15.738302 23191 net.cpp:100] Creating Layer res4e
I0615 20:53:15.738310 23191 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0615 20:53:15.738324 23191 net.cpp:444] res4e <- res4e_branch2c
I0615 20:53:15.738337 23191 net.cpp:418] res4e -> res4e
I0615 20:53:15.738390 23191 net.cpp:150] Setting up res4e
I0615 20:53:15.738401 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.738406 23191 net.cpp:165] Memory required for data: 210939916
I0615 20:53:15.738412 23191 layer_factory.hpp:77] Creating layer res4e_relu
I0615 20:53:15.738425 23191 net.cpp:100] Creating Layer res4e_relu
I0615 20:53:15.738431 23191 net.cpp:444] res4e_relu <- res4e
I0615 20:53:15.738447 23191 net.cpp:405] res4e_relu -> res4e (in-place)
I0615 20:53:15.738622 23191 net.cpp:150] Setting up res4e_relu
I0615 20:53:15.738631 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.738636 23191 net.cpp:165] Memory required for data: 211742732
I0615 20:53:15.738641 23191 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0615 20:53:15.738656 23191 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0615 20:53:15.738662 23191 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0615 20:53:15.738680 23191 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0615 20:53:15.738700 23191 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0615 20:53:15.738771 23191 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0615 20:53:15.738782 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.738790 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.738793 23191 net.cpp:165] Memory required for data: 213348364
I0615 20:53:15.738800 23191 layer_factory.hpp:77] Creating layer res4f_branch2a
I0615 20:53:15.738817 23191 net.cpp:100] Creating Layer res4f_branch2a
I0615 20:53:15.738824 23191 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0615 20:53:15.738844 23191 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0615 20:53:15.740372 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.740399 23191 net.cpp:150] Setting up res4f_branch2a
I0615 20:53:15.740409 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.740414 23191 net.cpp:165] Memory required for data: 213549068
I0615 20:53:15.740427 23191 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0615 20:53:15.740445 23191 net.cpp:100] Creating Layer bn4f_branch2a
I0615 20:53:15.740453 23191 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0615 20:53:15.740471 23191 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0615 20:53:15.740793 23191 net.cpp:150] Setting up bn4f_branch2a
I0615 20:53:15.740802 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.740805 23191 net.cpp:165] Memory required for data: 213749772
I0615 20:53:15.740828 23191 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0615 20:53:15.740844 23191 net.cpp:100] Creating Layer scale4f_branch2a
I0615 20:53:15.740850 23191 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0615 20:53:15.740869 23191 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0615 20:53:15.740952 23191 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0615 20:53:15.741168 23191 net.cpp:150] Setting up scale4f_branch2a
I0615 20:53:15.741176 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.741180 23191 net.cpp:165] Memory required for data: 213950476
I0615 20:53:15.741196 23191 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0615 20:53:15.741209 23191 net.cpp:100] Creating Layer res4f_branch2a_relu
I0615 20:53:15.741217 23191 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0615 20:53:15.741233 23191 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0615 20:53:15.741403 23191 net.cpp:150] Setting up res4f_branch2a_relu
I0615 20:53:15.741411 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.741415 23191 net.cpp:165] Memory required for data: 214151180
I0615 20:53:15.741421 23191 layer_factory.hpp:77] Creating layer res4f_branch2b
I0615 20:53:15.741441 23191 net.cpp:100] Creating Layer res4f_branch2b
I0615 20:53:15.741448 23191 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0615 20:53:15.741469 23191 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0615 20:53:15.744387 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0615 20:53:15.744707 23191 net.cpp:150] Setting up res4f_branch2b
I0615 20:53:15.744721 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.744726 23191 net.cpp:165] Memory required for data: 214351884
I0615 20:53:15.744742 23191 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0615 20:53:15.744763 23191 net.cpp:100] Creating Layer bn4f_branch2b
I0615 20:53:15.744771 23191 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0615 20:53:15.744789 23191 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0615 20:53:15.745158 23191 net.cpp:150] Setting up bn4f_branch2b
I0615 20:53:15.745167 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.745172 23191 net.cpp:165] Memory required for data: 214552588
I0615 20:53:15.745191 23191 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0615 20:53:15.745210 23191 net.cpp:100] Creating Layer scale4f_branch2b
I0615 20:53:15.745218 23191 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0615 20:53:15.745234 23191 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0615 20:53:15.745316 23191 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0615 20:53:15.745519 23191 net.cpp:150] Setting up scale4f_branch2b
I0615 20:53:15.745528 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.745532 23191 net.cpp:165] Memory required for data: 214753292
I0615 20:53:15.745546 23191 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0615 20:53:15.745559 23191 net.cpp:100] Creating Layer res4f_branch2b_relu
I0615 20:53:15.745568 23191 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0615 20:53:15.745584 23191 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0615 20:53:15.745759 23191 net.cpp:150] Setting up res4f_branch2b_relu
I0615 20:53:15.745767 23191 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0615 20:53:15.745771 23191 net.cpp:165] Memory required for data: 214953996
I0615 20:53:15.745779 23191 layer_factory.hpp:77] Creating layer res4f_branch2c
I0615 20:53:15.745797 23191 net.cpp:100] Creating Layer res4f_branch2c
I0615 20:53:15.745805 23191 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0615 20:53:15.745824 23191 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0615 20:53:15.748155 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.748188 23191 net.cpp:150] Setting up res4f_branch2c
I0615 20:53:15.748198 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.748203 23191 net.cpp:165] Memory required for data: 215756812
I0615 20:53:15.748216 23191 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0615 20:53:15.748235 23191 net.cpp:100] Creating Layer bn4f_branch2c
I0615 20:53:15.748244 23191 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0615 20:53:15.748262 23191 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0615 20:53:15.748600 23191 net.cpp:150] Setting up bn4f_branch2c
I0615 20:53:15.748610 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.748613 23191 net.cpp:165] Memory required for data: 216559628
I0615 20:53:15.748672 23191 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0615 20:53:15.748690 23191 net.cpp:100] Creating Layer scale4f_branch2c
I0615 20:53:15.748698 23191 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0615 20:53:15.748714 23191 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0615 20:53:15.748791 23191 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0615 20:53:15.749045 23191 net.cpp:150] Setting up scale4f_branch2c
I0615 20:53:15.749055 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.749059 23191 net.cpp:165] Memory required for data: 217362444
I0615 20:53:15.749074 23191 layer_factory.hpp:77] Creating layer res4f
I0615 20:53:15.749089 23191 net.cpp:100] Creating Layer res4f
I0615 20:53:15.749097 23191 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0615 20:53:15.749111 23191 net.cpp:444] res4f <- res4f_branch2c
I0615 20:53:15.749125 23191 net.cpp:418] res4f -> res4f
I0615 20:53:15.749178 23191 net.cpp:150] Setting up res4f
I0615 20:53:15.749188 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.749193 23191 net.cpp:165] Memory required for data: 218165260
I0615 20:53:15.749199 23191 layer_factory.hpp:77] Creating layer res4f_relu
I0615 20:53:15.749212 23191 net.cpp:100] Creating Layer res4f_relu
I0615 20:53:15.749218 23191 net.cpp:444] res4f_relu <- res4f
I0615 20:53:15.749234 23191 net.cpp:405] res4f_relu -> res4f (in-place)
I0615 20:53:15.749718 23191 net.cpp:150] Setting up res4f_relu
I0615 20:53:15.749728 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.749732 23191 net.cpp:165] Memory required for data: 218968076
I0615 20:53:15.749739 23191 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0615 20:53:15.749755 23191 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0615 20:53:15.749763 23191 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0615 20:53:15.749781 23191 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0615 20:53:15.749800 23191 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0615 20:53:15.749819 23191 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0615 20:53:15.749917 23191 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0615 20:53:15.749928 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.749935 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.749943 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:15.749946 23191 net.cpp:165] Memory required for data: 221376524
I0615 20:53:15.749953 23191 layer_factory.hpp:77] Creating layer res5a_branch1
I0615 20:53:15.749972 23191 net.cpp:100] Creating Layer res5a_branch1
I0615 20:53:15.749980 23191 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0615 20:53:15.750000 23191 net.cpp:418] res5a_branch1 -> res5a_branch1
I0615 20:53:15.756712 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 8568
I0615 20:53:15.756753 23191 net.cpp:150] Setting up res5a_branch1
I0615 20:53:15.756770 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.756774 23191 net.cpp:165] Memory required for data: 222982156
I0615 20:53:15.756798 23191 layer_factory.hpp:77] Creating layer bn5a_branch1
I0615 20:53:15.756831 23191 net.cpp:100] Creating Layer bn5a_branch1
I0615 20:53:15.756844 23191 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0615 20:53:15.756867 23191 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0615 20:53:15.757283 23191 net.cpp:150] Setting up bn5a_branch1
I0615 20:53:15.757293 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.757297 23191 net.cpp:165] Memory required for data: 224587788
I0615 20:53:15.757319 23191 layer_factory.hpp:77] Creating layer scale5a_branch1
I0615 20:53:15.757340 23191 net.cpp:100] Creating Layer scale5a_branch1
I0615 20:53:15.757349 23191 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0615 20:53:15.757366 23191 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0615 20:53:15.757448 23191 layer_factory.hpp:77] Creating layer scale5a_branch1
I0615 20:53:15.757666 23191 net.cpp:150] Setting up scale5a_branch1
I0615 20:53:15.757675 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.757679 23191 net.cpp:165] Memory required for data: 226193420
I0615 20:53:15.757694 23191 layer_factory.hpp:77] Creating layer res5a_branch2a
I0615 20:53:15.757715 23191 net.cpp:100] Creating Layer res5a_branch2a
I0615 20:53:15.757724 23191 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0615 20:53:15.757742 23191 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0615 20:53:15.760866 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.760898 23191 net.cpp:150] Setting up res5a_branch2a
I0615 20:53:15.760910 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.760915 23191 net.cpp:165] Memory required for data: 226594828
I0615 20:53:15.760931 23191 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0615 20:53:15.760977 23191 net.cpp:100] Creating Layer bn5a_branch2a
I0615 20:53:15.760987 23191 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0615 20:53:15.761008 23191 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0615 20:53:15.761350 23191 net.cpp:150] Setting up bn5a_branch2a
I0615 20:53:15.761359 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.761363 23191 net.cpp:165] Memory required for data: 226996236
I0615 20:53:15.761385 23191 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0615 20:53:15.761404 23191 net.cpp:100] Creating Layer scale5a_branch2a
I0615 20:53:15.761412 23191 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0615 20:53:15.761430 23191 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0615 20:53:15.761505 23191 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0615 20:53:15.761719 23191 net.cpp:150] Setting up scale5a_branch2a
I0615 20:53:15.761729 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.761732 23191 net.cpp:165] Memory required for data: 227397644
I0615 20:53:15.761749 23191 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0615 20:53:15.761764 23191 net.cpp:100] Creating Layer res5a_branch2a_relu
I0615 20:53:15.761771 23191 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0615 20:53:15.761787 23191 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0615 20:53:15.761961 23191 net.cpp:150] Setting up res5a_branch2a_relu
I0615 20:53:15.761970 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.761975 23191 net.cpp:165] Memory required for data: 227799052
I0615 20:53:15.761981 23191 layer_factory.hpp:77] Creating layer res5a_branch2b
I0615 20:53:15.762001 23191 net.cpp:100] Creating Layer res5a_branch2b
I0615 20:53:15.762008 23191 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0615 20:53:15.762028 23191 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0615 20:53:15.768460 23191 net.cpp:150] Setting up res5a_branch2b
I0615 20:53:15.768492 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.768496 23191 net.cpp:165] Memory required for data: 228200460
I0615 20:53:15.768522 23191 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0615 20:53:15.768556 23191 net.cpp:100] Creating Layer bn5a_branch2b
I0615 20:53:15.768570 23191 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0615 20:53:15.768592 23191 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0615 20:53:15.768976 23191 net.cpp:150] Setting up bn5a_branch2b
I0615 20:53:15.768987 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.768990 23191 net.cpp:165] Memory required for data: 228601868
I0615 20:53:15.769016 23191 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0615 20:53:15.769034 23191 net.cpp:100] Creating Layer scale5a_branch2b
I0615 20:53:15.769042 23191 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0615 20:53:15.769060 23191 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0615 20:53:15.769146 23191 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0615 20:53:15.769362 23191 net.cpp:150] Setting up scale5a_branch2b
I0615 20:53:15.769371 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.769376 23191 net.cpp:165] Memory required for data: 229003276
I0615 20:53:15.769390 23191 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0615 20:53:15.769404 23191 net.cpp:100] Creating Layer res5a_branch2b_relu
I0615 20:53:15.769412 23191 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0615 20:53:15.769428 23191 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0615 20:53:15.769640 23191 net.cpp:150] Setting up res5a_branch2b_relu
I0615 20:53:15.769649 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.769652 23191 net.cpp:165] Memory required for data: 229404684
I0615 20:53:15.769659 23191 layer_factory.hpp:77] Creating layer res5a_branch2c
I0615 20:53:15.769681 23191 net.cpp:100] Creating Layer res5a_branch2c
I0615 20:53:15.769688 23191 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0615 20:53:15.769708 23191 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0615 20:53:15.773900 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0615 20:53:15.773941 23191 net.cpp:150] Setting up res5a_branch2c
I0615 20:53:15.773957 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.773960 23191 net.cpp:165] Memory required for data: 231010316
I0615 20:53:15.773983 23191 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0615 20:53:15.774011 23191 net.cpp:100] Creating Layer bn5a_branch2c
I0615 20:53:15.774022 23191 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0615 20:53:15.774044 23191 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0615 20:53:15.774397 23191 net.cpp:150] Setting up bn5a_branch2c
I0615 20:53:15.774406 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.774410 23191 net.cpp:165] Memory required for data: 232615948
I0615 20:53:15.774431 23191 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0615 20:53:15.774451 23191 net.cpp:100] Creating Layer scale5a_branch2c
I0615 20:53:15.774458 23191 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0615 20:53:15.774474 23191 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0615 20:53:15.774555 23191 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0615 20:53:15.774776 23191 net.cpp:150] Setting up scale5a_branch2c
I0615 20:53:15.774786 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.774790 23191 net.cpp:165] Memory required for data: 234221580
I0615 20:53:15.774806 23191 layer_factory.hpp:77] Creating layer res5a
I0615 20:53:15.774821 23191 net.cpp:100] Creating Layer res5a
I0615 20:53:15.774827 23191 net.cpp:444] res5a <- res5a_branch1
I0615 20:53:15.774842 23191 net.cpp:444] res5a <- res5a_branch2c
I0615 20:53:15.774853 23191 net.cpp:418] res5a -> res5a
I0615 20:53:15.774909 23191 net.cpp:150] Setting up res5a
I0615 20:53:15.774919 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.774924 23191 net.cpp:165] Memory required for data: 235827212
I0615 20:53:15.774929 23191 layer_factory.hpp:77] Creating layer res5a_relu
I0615 20:53:15.774941 23191 net.cpp:100] Creating Layer res5a_relu
I0615 20:53:15.774948 23191 net.cpp:444] res5a_relu <- res5a
I0615 20:53:15.774963 23191 net.cpp:405] res5a_relu -> res5a (in-place)
I0615 20:53:15.775476 23191 net.cpp:150] Setting up res5a_relu
I0615 20:53:15.775488 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.775492 23191 net.cpp:165] Memory required for data: 237432844
I0615 20:53:15.775501 23191 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0615 20:53:15.775516 23191 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0615 20:53:15.775523 23191 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0615 20:53:15.775542 23191 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0615 20:53:15.775563 23191 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0615 20:53:15.775638 23191 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0615 20:53:15.775650 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.775656 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.775660 23191 net.cpp:165] Memory required for data: 240644108
I0615 20:53:15.775666 23191 layer_factory.hpp:77] Creating layer res5b_branch2a
I0615 20:53:15.775687 23191 net.cpp:100] Creating Layer res5b_branch2a
I0615 20:53:15.775696 23191 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0615 20:53:15.775714 23191 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0615 20:53:15.779785 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.779824 23191 net.cpp:150] Setting up res5b_branch2a
I0615 20:53:15.779840 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.779844 23191 net.cpp:165] Memory required for data: 241045516
I0615 20:53:15.779865 23191 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0615 20:53:15.779891 23191 net.cpp:100] Creating Layer bn5b_branch2a
I0615 20:53:15.779902 23191 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0615 20:53:15.779923 23191 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0615 20:53:15.780277 23191 net.cpp:150] Setting up bn5b_branch2a
I0615 20:53:15.780287 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.780290 23191 net.cpp:165] Memory required for data: 241446924
I0615 20:53:15.780310 23191 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0615 20:53:15.780328 23191 net.cpp:100] Creating Layer scale5b_branch2a
I0615 20:53:15.780338 23191 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0615 20:53:15.780354 23191 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0615 20:53:15.780433 23191 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0615 20:53:15.780652 23191 net.cpp:150] Setting up scale5b_branch2a
I0615 20:53:15.780661 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.780664 23191 net.cpp:165] Memory required for data: 241848332
I0615 20:53:15.780679 23191 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0615 20:53:15.780694 23191 net.cpp:100] Creating Layer res5b_branch2a_relu
I0615 20:53:15.780701 23191 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0615 20:53:15.780719 23191 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0615 20:53:15.780894 23191 net.cpp:150] Setting up res5b_branch2a_relu
I0615 20:53:15.780902 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.780906 23191 net.cpp:165] Memory required for data: 242249740
I0615 20:53:15.780912 23191 layer_factory.hpp:77] Creating layer res5b_branch2b
I0615 20:53:15.780933 23191 net.cpp:100] Creating Layer res5b_branch2b
I0615 20:53:15.780953 23191 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0615 20:53:15.780977 23191 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0615 20:53:15.787382 23191 net.cpp:150] Setting up res5b_branch2b
I0615 20:53:15.787415 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.787418 23191 net.cpp:165] Memory required for data: 242651148
I0615 20:53:15.787443 23191 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0615 20:53:15.787479 23191 net.cpp:100] Creating Layer bn5b_branch2b
I0615 20:53:15.787492 23191 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0615 20:53:15.787516 23191 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0615 20:53:15.787878 23191 net.cpp:150] Setting up bn5b_branch2b
I0615 20:53:15.787887 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.787890 23191 net.cpp:165] Memory required for data: 243052556
I0615 20:53:15.787912 23191 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0615 20:53:15.787933 23191 net.cpp:100] Creating Layer scale5b_branch2b
I0615 20:53:15.787941 23191 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0615 20:53:15.787957 23191 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0615 20:53:15.788038 23191 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0615 20:53:15.788264 23191 net.cpp:150] Setting up scale5b_branch2b
I0615 20:53:15.788275 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.788278 23191 net.cpp:165] Memory required for data: 243453964
I0615 20:53:15.788292 23191 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0615 20:53:15.788307 23191 net.cpp:100] Creating Layer res5b_branch2b_relu
I0615 20:53:15.788316 23191 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0615 20:53:15.788331 23191 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0615 20:53:15.788545 23191 net.cpp:150] Setting up res5b_branch2b_relu
I0615 20:53:15.788555 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.788560 23191 net.cpp:165] Memory required for data: 243855372
I0615 20:53:15.788568 23191 layer_factory.hpp:77] Creating layer res5b_branch2c
I0615 20:53:15.788588 23191 net.cpp:100] Creating Layer res5b_branch2c
I0615 20:53:15.788595 23191 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0615 20:53:15.788614 23191 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0615 20:53:15.792982 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0615 20:53:15.793030 23191 net.cpp:150] Setting up res5b_branch2c
I0615 20:53:15.793047 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.793051 23191 net.cpp:165] Memory required for data: 245461004
I0615 20:53:15.793076 23191 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0615 20:53:15.793113 23191 net.cpp:100] Creating Layer bn5b_branch2c
I0615 20:53:15.793128 23191 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0615 20:53:15.793154 23191 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0615 20:53:15.793521 23191 net.cpp:150] Setting up bn5b_branch2c
I0615 20:53:15.793529 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.793534 23191 net.cpp:165] Memory required for data: 247066636
I0615 20:53:15.793556 23191 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0615 20:53:15.793576 23191 net.cpp:100] Creating Layer scale5b_branch2c
I0615 20:53:15.793584 23191 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0615 20:53:15.793602 23191 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0615 20:53:15.793684 23191 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0615 20:53:15.793911 23191 net.cpp:150] Setting up scale5b_branch2c
I0615 20:53:15.793920 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.793925 23191 net.cpp:165] Memory required for data: 248672268
I0615 20:53:15.793938 23191 layer_factory.hpp:77] Creating layer res5b
I0615 20:53:15.793954 23191 net.cpp:100] Creating Layer res5b
I0615 20:53:15.793962 23191 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0615 20:53:15.793977 23191 net.cpp:444] res5b <- res5b_branch2c
I0615 20:53:15.793990 23191 net.cpp:418] res5b -> res5b
I0615 20:53:15.794045 23191 net.cpp:150] Setting up res5b
I0615 20:53:15.794056 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.794061 23191 net.cpp:165] Memory required for data: 250277900
I0615 20:53:15.794066 23191 layer_factory.hpp:77] Creating layer res5b_relu
I0615 20:53:15.794080 23191 net.cpp:100] Creating Layer res5b_relu
I0615 20:53:15.794086 23191 net.cpp:444] res5b_relu <- res5b
I0615 20:53:15.794103 23191 net.cpp:405] res5b_relu -> res5b (in-place)
I0615 20:53:15.794636 23191 net.cpp:150] Setting up res5b_relu
I0615 20:53:15.794646 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.794651 23191 net.cpp:165] Memory required for data: 251883532
I0615 20:53:15.794657 23191 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0615 20:53:15.794672 23191 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0615 20:53:15.794679 23191 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0615 20:53:15.794698 23191 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0615 20:53:15.794718 23191 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0615 20:53:15.794798 23191 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0615 20:53:15.794808 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.794816 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.794821 23191 net.cpp:165] Memory required for data: 255094796
I0615 20:53:15.794826 23191 layer_factory.hpp:77] Creating layer res5c_branch2a
I0615 20:53:15.794847 23191 net.cpp:100] Creating Layer res5c_branch2a
I0615 20:53:15.794854 23191 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0615 20:53:15.794873 23191 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0615 20:53:15.798974 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:15.799012 23191 net.cpp:150] Setting up res5c_branch2a
I0615 20:53:15.799027 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.799031 23191 net.cpp:165] Memory required for data: 255496204
I0615 20:53:15.799052 23191 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0615 20:53:15.799080 23191 net.cpp:100] Creating Layer bn5c_branch2a
I0615 20:53:15.799091 23191 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0615 20:53:15.799114 23191 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0615 20:53:15.799473 23191 net.cpp:150] Setting up bn5c_branch2a
I0615 20:53:15.799480 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.799484 23191 net.cpp:165] Memory required for data: 255897612
I0615 20:53:15.799506 23191 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0615 20:53:15.799525 23191 net.cpp:100] Creating Layer scale5c_branch2a
I0615 20:53:15.799533 23191 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0615 20:53:15.799551 23191 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0615 20:53:15.799628 23191 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0615 20:53:15.799851 23191 net.cpp:150] Setting up scale5c_branch2a
I0615 20:53:15.799861 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.799865 23191 net.cpp:165] Memory required for data: 256299020
I0615 20:53:15.799880 23191 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0615 20:53:15.799896 23191 net.cpp:100] Creating Layer res5c_branch2a_relu
I0615 20:53:15.799902 23191 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0615 20:53:15.799918 23191 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0615 20:53:15.800094 23191 net.cpp:150] Setting up res5c_branch2a_relu
I0615 20:53:15.800106 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.800109 23191 net.cpp:165] Memory required for data: 256700428
I0615 20:53:15.800117 23191 layer_factory.hpp:77] Creating layer res5c_branch2b
I0615 20:53:15.800135 23191 net.cpp:100] Creating Layer res5c_branch2b
I0615 20:53:15.800143 23191 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0615 20:53:15.800168 23191 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0615 20:53:15.806658 23191 net.cpp:150] Setting up res5c_branch2b
I0615 20:53:15.806690 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.806694 23191 net.cpp:165] Memory required for data: 257101836
I0615 20:53:15.806721 23191 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0615 20:53:15.806756 23191 net.cpp:100] Creating Layer bn5c_branch2b
I0615 20:53:15.806771 23191 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0615 20:53:15.806797 23191 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0615 20:53:15.807165 23191 net.cpp:150] Setting up bn5c_branch2b
I0615 20:53:15.807173 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.807178 23191 net.cpp:165] Memory required for data: 257503244
I0615 20:53:15.807198 23191 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0615 20:53:15.807217 23191 net.cpp:100] Creating Layer scale5c_branch2b
I0615 20:53:15.807225 23191 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0615 20:53:15.807242 23191 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0615 20:53:15.807323 23191 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0615 20:53:15.807548 23191 net.cpp:150] Setting up scale5c_branch2b
I0615 20:53:15.807556 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.807560 23191 net.cpp:165] Memory required for data: 257904652
I0615 20:53:15.807575 23191 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0615 20:53:15.807590 23191 net.cpp:100] Creating Layer res5c_branch2b_relu
I0615 20:53:15.807597 23191 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0615 20:53:15.807612 23191 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0615 20:53:15.807832 23191 net.cpp:150] Setting up res5c_branch2b_relu
I0615 20:53:15.807842 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:15.807844 23191 net.cpp:165] Memory required for data: 258306060
I0615 20:53:15.807852 23191 layer_factory.hpp:77] Creating layer res5c_branch2c
I0615 20:53:15.807873 23191 net.cpp:100] Creating Layer res5c_branch2c
I0615 20:53:15.807880 23191 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0615 20:53:15.807899 23191 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0615 20:53:15.812144 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0615 20:53:15.812183 23191 net.cpp:150] Setting up res5c_branch2c
I0615 20:53:15.812197 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.812201 23191 net.cpp:165] Memory required for data: 259911692
I0615 20:53:15.812223 23191 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0615 20:53:15.812250 23191 net.cpp:100] Creating Layer bn5c_branch2c
I0615 20:53:15.812263 23191 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0615 20:53:15.812283 23191 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0615 20:53:15.812651 23191 net.cpp:150] Setting up bn5c_branch2c
I0615 20:53:15.812660 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.812664 23191 net.cpp:165] Memory required for data: 261517324
I0615 20:53:15.812685 23191 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0615 20:53:15.812703 23191 net.cpp:100] Creating Layer scale5c_branch2c
I0615 20:53:15.812711 23191 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0615 20:53:15.812729 23191 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0615 20:53:15.812811 23191 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0615 20:53:15.813081 23191 net.cpp:150] Setting up scale5c_branch2c
I0615 20:53:15.813091 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.813096 23191 net.cpp:165] Memory required for data: 263122956
I0615 20:53:15.813109 23191 layer_factory.hpp:77] Creating layer res5c
I0615 20:53:15.813124 23191 net.cpp:100] Creating Layer res5c
I0615 20:53:15.813133 23191 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0615 20:53:15.813146 23191 net.cpp:444] res5c <- res5c_branch2c
I0615 20:53:15.813161 23191 net.cpp:418] res5c -> res5c
I0615 20:53:15.813215 23191 net.cpp:150] Setting up res5c
I0615 20:53:15.813226 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.813231 23191 net.cpp:165] Memory required for data: 264728588
I0615 20:53:15.813237 23191 layer_factory.hpp:77] Creating layer res5c_relu
I0615 20:53:15.813251 23191 net.cpp:100] Creating Layer res5c_relu
I0615 20:53:15.813259 23191 net.cpp:444] res5c_relu <- res5c
I0615 20:53:15.813274 23191 net.cpp:405] res5c_relu -> res5c (in-place)
I0615 20:53:15.813449 23191 net.cpp:150] Setting up res5c_relu
I0615 20:53:15.813458 23191 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0615 20:53:15.813462 23191 net.cpp:165] Memory required for data: 266334220
I0615 20:53:15.813467 23191 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0615 20:53:15.813491 23191 net.cpp:100] Creating Layer rpn_conv/3x3
I0615 20:53:15.813500 23191 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0615 20:53:15.813520 23191 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0615 20:53:16.401185 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0615 20:53:16.401558 23191 net.cpp:150] Setting up rpn_conv/3x3
I0615 20:53:16.401579 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:16.401583 23191 net.cpp:165] Memory required for data: 266735628
I0615 20:53:16.401608 23191 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0615 20:53:16.401635 23191 net.cpp:100] Creating Layer rpn_relu/3x3
I0615 20:53:16.401648 23191 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0615 20:53:16.401669 23191 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0615 20:53:16.402165 23191 net.cpp:150] Setting up rpn_relu/3x3
I0615 20:53:16.402176 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:16.402181 23191 net.cpp:165] Memory required for data: 267137036
I0615 20:53:16.402187 23191 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0615 20:53:16.402202 23191 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0615 20:53:16.402209 23191 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0615 20:53:16.402230 23191 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0615 20:53:16.402251 23191 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0615 20:53:16.402341 23191 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0615 20:53:16.402351 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:16.402359 23191 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0615 20:53:16.402362 23191 net.cpp:165] Memory required for data: 267939852
I0615 20:53:16.402369 23191 layer_factory.hpp:77] Creating layer rpn_cls_score
I0615 20:53:16.402393 23191 net.cpp:100] Creating Layer rpn_cls_score
I0615 20:53:16.402401 23191 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0615 20:53:16.402423 23191 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0615 20:53:16.407912 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:16.407943 23191 net.cpp:150] Setting up rpn_cls_score
I0615 20:53:16.407954 23191 net.cpp:157] Top shape: 1 66 14 14 (12936)
I0615 20:53:16.407958 23191 net.cpp:165] Memory required for data: 267991596
I0615 20:53:16.407975 23191 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0615 20:53:16.407999 23191 net.cpp:100] Creating Layer rpn_bbox_pred
I0615 20:53:16.408007 23191 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0615 20:53:16.408028 23191 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0615 20:53:16.417901 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:16.417943 23191 net.cpp:150] Setting up rpn_bbox_pred
I0615 20:53:16.417958 23191 net.cpp:157] Top shape: 1 132 14 14 (25872)
I0615 20:53:16.417961 23191 net.cpp:165] Memory required for data: 268095084
I0615 20:53:16.417985 23191 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0615 20:53:16.418014 23191 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0615 20:53:16.418025 23191 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score
I0615 20:53:16.418051 23191 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0615 20:53:16.418123 23191 net.cpp:150] Setting up rpn_cls_score_reshape
I0615 20:53:16.418134 23191 net.cpp:157] Top shape: 1 2 462 14 (12936)
I0615 20:53:16.418139 23191 net.cpp:165] Memory required for data: 268146828
I0615 20:53:16.418145 23191 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0615 20:53:16.418159 23191 net.cpp:100] Creating Layer rpn_cls_prob
I0615 20:53:16.418167 23191 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape
I0615 20:53:16.418184 23191 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0615 20:53:16.418467 23191 net.cpp:150] Setting up rpn_cls_prob
I0615 20:53:16.418478 23191 net.cpp:157] Top shape: 1 2 462 14 (12936)
I0615 20:53:16.418483 23191 net.cpp:165] Memory required for data: 268198572
I0615 20:53:16.418489 23191 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0615 20:53:16.418504 23191 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0615 20:53:16.418511 23191 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0615 20:53:16.418529 23191 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0615 20:53:16.418587 23191 net.cpp:150] Setting up rpn_cls_prob_reshape
I0615 20:53:16.418597 23191 net.cpp:157] Top shape: 1 66 14 14 (12936)
I0615 20:53:16.418601 23191 net.cpp:165] Memory required for data: 268250316
I0615 20:53:16.418607 23191 layer_factory.hpp:77] Creating layer proposal
I0615 20:53:16.418931 23191 net.cpp:100] Creating Layer proposal
I0615 20:53:16.418942 23191 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0615 20:53:16.418957 23191 net.cpp:444] proposal <- rpn_bbox_pred
I0615 20:53:16.418968 23191 net.cpp:444] proposal <- im_info
I0615 20:53:16.418983 23191 net.cpp:418] proposal -> rois
I0615 20:53:16.420289 23191 net.cpp:150] Setting up proposal
I0615 20:53:16.420302 23191 net.cpp:157] Top shape: 1 5 (5)
I0615 20:53:16.420308 23191 net.cpp:165] Memory required for data: 268250336
I0615 20:53:16.420315 23191 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0615 20:53:16.420331 23191 net.cpp:100] Creating Layer rois_proposal_0_split
I0615 20:53:16.420338 23191 net.cpp:444] rois_proposal_0_split <- rois
I0615 20:53:16.420356 23191 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_0
I0615 20:53:16.420377 23191 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_1
I0615 20:53:16.420454 23191 net.cpp:150] Setting up rois_proposal_0_split
I0615 20:53:16.420464 23191 net.cpp:157] Top shape: 1 5 (5)
I0615 20:53:16.420471 23191 net.cpp:157] Top shape: 1 5 (5)
I0615 20:53:16.420475 23191 net.cpp:165] Memory required for data: 268250376
I0615 20:53:16.420481 23191 layer_factory.hpp:77] Creating layer conv_new_1
I0615 20:53:16.420506 23191 net.cpp:100] Creating Layer conv_new_1
I0615 20:53:16.420513 23191 net.cpp:444] conv_new_1 <- res5c
I0615 20:53:16.420533 23191 net.cpp:418] conv_new_1 -> conv_new_1
I0615 20:53:16.682829 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:16.682870 23191 net.cpp:150] Setting up conv_new_1
I0615 20:53:16.682888 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:16.682893 23191 net.cpp:165] Memory required for data: 269053192
I0615 20:53:16.682916 23191 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0615 20:53:16.682942 23191 net.cpp:100] Creating Layer conv_new_1_relu
I0615 20:53:16.682955 23191 net.cpp:444] conv_new_1_relu <- conv_new_1
I0615 20:53:16.682976 23191 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0615 20:53:16.683153 23191 net.cpp:150] Setting up conv_new_1_relu
I0615 20:53:16.683162 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:16.683166 23191 net.cpp:165] Memory required for data: 269856008
I0615 20:53:16.683174 23191 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0615 20:53:16.683187 23191 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0615 20:53:16.683194 23191 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0615 20:53:16.683212 23191 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0615 20:53:16.683234 23191 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0615 20:53:16.683323 23191 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0615 20:53:16.683334 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:16.683341 23191 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0615 20:53:16.683343 23191 net.cpp:165] Memory required for data: 271461640
I0615 20:53:16.683349 23191 layer_factory.hpp:77] Creating layer rfcn_cls
I0615 20:53:16.683373 23191 net.cpp:100] Creating Layer rfcn_cls
I0615 20:53:16.683382 23191 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0615 20:53:16.683403 23191 net.cpp:418] rfcn_cls -> rfcn_cls
I0615 20:53:16.711340 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:16.711390 23191 net.cpp:150] Setting up rfcn_cls
I0615 20:53:16.711426 23191 net.cpp:157] Top shape: 1 196 14 14 (38416)
I0615 20:53:16.711431 23191 net.cpp:165] Memory required for data: 271615304
I0615 20:53:16.711460 23191 layer_factory.hpp:77] Creating layer rfcn_bbox
I0615 20:53:16.711536 23191 net.cpp:100] Creating Layer rfcn_bbox
I0615 20:53:16.711552 23191 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0615 20:53:16.711582 23191 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0615 20:53:16.763794 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0615 20:53:16.763834 23191 net.cpp:150] Setting up rfcn_bbox
I0615 20:53:16.763851 23191 net.cpp:157] Top shape: 1 392 14 14 (76832)
I0615 20:53:16.763855 23191 net.cpp:165] Memory required for data: 271922632
I0615 20:53:16.763883 23191 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0615 20:53:16.763912 23191 net.cpp:100] Creating Layer psroipooled_cls_rois
I0615 20:53:16.763926 23191 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0615 20:53:16.763943 23191 net.cpp:444] psroipooled_cls_rois <- rois_proposal_0_split_0
I0615 20:53:16.763962 23191 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0615 20:53:16.763985 23191 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0615 20:53:16.764073 23191 net.cpp:150] Setting up psroipooled_cls_rois
I0615 20:53:16.764083 23191 net.cpp:157] Top shape: 1 4 7 7 (196)
I0615 20:53:16.764087 23191 net.cpp:165] Memory required for data: 271923416
I0615 20:53:16.764093 23191 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0615 20:53:16.764111 23191 net.cpp:100] Creating Layer ave_cls_score_rois
I0615 20:53:16.764119 23191 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0615 20:53:16.764138 23191 net.cpp:418] ave_cls_score_rois -> cls_score
I0615 20:53:16.765280 23191 net.cpp:150] Setting up ave_cls_score_rois
I0615 20:53:16.765295 23191 net.cpp:157] Top shape: 1 4 1 1 (4)
I0615 20:53:16.765300 23191 net.cpp:165] Memory required for data: 271923432
I0615 20:53:16.765306 23191 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0615 20:53:16.765321 23191 net.cpp:100] Creating Layer psroipooled_loc_rois
I0615 20:53:16.765329 23191 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0615 20:53:16.765344 23191 net.cpp:444] psroipooled_loc_rois <- rois_proposal_0_split_1
I0615 20:53:16.765360 23191 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0615 20:53:16.765379 23191 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0615 20:53:16.765451 23191 net.cpp:150] Setting up psroipooled_loc_rois
I0615 20:53:16.765462 23191 net.cpp:157] Top shape: 1 8 7 7 (392)
I0615 20:53:16.765466 23191 net.cpp:165] Memory required for data: 271925000
I0615 20:53:16.765471 23191 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0615 20:53:16.765486 23191 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0615 20:53:16.765493 23191 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0615 20:53:16.765511 23191 net.cpp:418] ave_bbox_pred_rois -> bbox_pred_pre
I0615 20:53:16.765718 23191 net.cpp:150] Setting up ave_bbox_pred_rois
I0615 20:53:16.765729 23191 net.cpp:157] Top shape: 1 8 1 1 (8)
I0615 20:53:16.765734 23191 net.cpp:165] Memory required for data: 271925032
I0615 20:53:16.765740 23191 layer_factory.hpp:77] Creating layer cls_prob
I0615 20:53:16.765754 23191 net.cpp:100] Creating Layer cls_prob
I0615 20:53:16.765761 23191 net.cpp:444] cls_prob <- cls_score
I0615 20:53:16.765781 23191 net.cpp:418] cls_prob -> cls_prob_pre
I0615 20:53:16.766058 23191 net.cpp:150] Setting up cls_prob
I0615 20:53:16.766070 23191 net.cpp:157] Top shape: 1 4 1 1 (4)
I0615 20:53:16.766074 23191 net.cpp:165] Memory required for data: 271925048
I0615 20:53:16.766082 23191 layer_factory.hpp:77] Creating layer cls_prob_reshape
I0615 20:53:16.766099 23191 net.cpp:100] Creating Layer cls_prob_reshape
I0615 20:53:16.766106 23191 net.cpp:444] cls_prob_reshape <- cls_prob_pre
I0615 20:53:16.766124 23191 net.cpp:418] cls_prob_reshape -> cls_prob
I0615 20:53:16.766180 23191 net.cpp:150] Setting up cls_prob_reshape
I0615 20:53:16.766191 23191 net.cpp:157] Top shape: 1 4 (4)
I0615 20:53:16.766194 23191 net.cpp:165] Memory required for data: 271925064
I0615 20:53:16.766201 23191 layer_factory.hpp:77] Creating layer bbox_pred_reshape
I0615 20:53:16.766213 23191 net.cpp:100] Creating Layer bbox_pred_reshape
I0615 20:53:16.766221 23191 net.cpp:444] bbox_pred_reshape <- bbox_pred_pre
I0615 20:53:16.766238 23191 net.cpp:418] bbox_pred_reshape -> bbox_pred
I0615 20:53:16.766295 23191 net.cpp:150] Setting up bbox_pred_reshape
I0615 20:53:16.766305 23191 net.cpp:157] Top shape: 1 8 (8)
I0615 20:53:16.766309 23191 net.cpp:165] Memory required for data: 271925096
I0615 20:53:16.766316 23191 net.cpp:228] bbox_pred_reshape does not need backward computation.
I0615 20:53:16.766322 23191 net.cpp:228] cls_prob_reshape does not need backward computation.
I0615 20:53:16.766330 23191 net.cpp:228] cls_prob does not need backward computation.
I0615 20:53:16.766335 23191 net.cpp:228] ave_bbox_pred_rois does not need backward computation.
I0615 20:53:16.766341 23191 net.cpp:228] psroipooled_loc_rois does not need backward computation.
I0615 20:53:16.766348 23191 net.cpp:228] ave_cls_score_rois does not need backward computation.
I0615 20:53:16.766355 23191 net.cpp:228] psroipooled_cls_rois does not need backward computation.
I0615 20:53:16.766361 23191 net.cpp:228] rfcn_bbox does not need backward computation.
I0615 20:53:16.766368 23191 net.cpp:228] rfcn_cls does not need backward computation.
I0615 20:53:16.766376 23191 net.cpp:228] conv_new_1_conv_new_1_relu_0_split does not need backward computation.
I0615 20:53:16.766381 23191 net.cpp:228] conv_new_1_relu does not need backward computation.
I0615 20:53:16.766387 23191 net.cpp:228] conv_new_1 does not need backward computation.
I0615 20:53:16.766394 23191 net.cpp:228] rois_proposal_0_split does not need backward computation.
I0615 20:53:16.766400 23191 net.cpp:228] proposal does not need backward computation.
I0615 20:53:16.766410 23191 net.cpp:228] rpn_cls_prob_reshape does not need backward computation.
I0615 20:53:16.766417 23191 net.cpp:228] rpn_cls_prob does not need backward computation.
I0615 20:53:16.766422 23191 net.cpp:228] rpn_cls_score_reshape does not need backward computation.
I0615 20:53:16.766429 23191 net.cpp:228] rpn_bbox_pred does not need backward computation.
I0615 20:53:16.766436 23191 net.cpp:228] rpn_cls_score does not need backward computation.
I0615 20:53:16.766443 23191 net.cpp:228] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0615 20:53:16.766449 23191 net.cpp:228] rpn_relu/3x3 does not need backward computation.
I0615 20:53:16.766455 23191 net.cpp:228] rpn_conv/3x3 does not need backward computation.
I0615 20:53:16.766463 23191 net.cpp:228] res5c_relu does not need backward computation.
I0615 20:53:16.766468 23191 net.cpp:228] res5c does not need backward computation.
I0615 20:53:16.766475 23191 net.cpp:228] scale5c_branch2c does not need backward computation.
I0615 20:53:16.766481 23191 net.cpp:228] bn5c_branch2c does not need backward computation.
I0615 20:53:16.766486 23191 net.cpp:228] res5c_branch2c does not need backward computation.
I0615 20:53:16.766494 23191 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I0615 20:53:16.766499 23191 net.cpp:228] scale5c_branch2b does not need backward computation.
I0615 20:53:16.766505 23191 net.cpp:228] bn5c_branch2b does not need backward computation.
I0615 20:53:16.766511 23191 net.cpp:228] res5c_branch2b does not need backward computation.
I0615 20:53:16.766517 23191 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I0615 20:53:16.766521 23191 net.cpp:228] scale5c_branch2a does not need backward computation.
I0615 20:53:16.766527 23191 net.cpp:228] bn5c_branch2a does not need backward computation.
I0615 20:53:16.766533 23191 net.cpp:228] res5c_branch2a does not need backward computation.
I0615 20:53:16.766541 23191 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I0615 20:53:16.766546 23191 net.cpp:228] res5b_relu does not need backward computation.
I0615 20:53:16.766552 23191 net.cpp:228] res5b does not need backward computation.
I0615 20:53:16.766561 23191 net.cpp:228] scale5b_branch2c does not need backward computation.
I0615 20:53:16.766566 23191 net.cpp:228] bn5b_branch2c does not need backward computation.
I0615 20:53:16.766571 23191 net.cpp:228] res5b_branch2c does not need backward computation.
I0615 20:53:16.766577 23191 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I0615 20:53:16.766584 23191 net.cpp:228] scale5b_branch2b does not need backward computation.
I0615 20:53:16.766589 23191 net.cpp:228] bn5b_branch2b does not need backward computation.
I0615 20:53:16.766595 23191 net.cpp:228] res5b_branch2b does not need backward computation.
I0615 20:53:16.766602 23191 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I0615 20:53:16.766608 23191 net.cpp:228] scale5b_branch2a does not need backward computation.
I0615 20:53:16.766613 23191 net.cpp:228] bn5b_branch2a does not need backward computation.
I0615 20:53:16.766619 23191 net.cpp:228] res5b_branch2a does not need backward computation.
I0615 20:53:16.766626 23191 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I0615 20:53:16.766633 23191 net.cpp:228] res5a_relu does not need backward computation.
I0615 20:53:16.766638 23191 net.cpp:228] res5a does not need backward computation.
I0615 20:53:16.766646 23191 net.cpp:228] scale5a_branch2c does not need backward computation.
I0615 20:53:16.766651 23191 net.cpp:228] bn5a_branch2c does not need backward computation.
I0615 20:53:16.766657 23191 net.cpp:228] res5a_branch2c does not need backward computation.
I0615 20:53:16.766664 23191 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I0615 20:53:16.766669 23191 net.cpp:228] scale5a_branch2b does not need backward computation.
I0615 20:53:16.766675 23191 net.cpp:228] bn5a_branch2b does not need backward computation.
I0615 20:53:16.766681 23191 net.cpp:228] res5a_branch2b does not need backward computation.
I0615 20:53:16.766695 23191 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I0615 20:53:16.766700 23191 net.cpp:228] scale5a_branch2a does not need backward computation.
I0615 20:53:16.766706 23191 net.cpp:228] bn5a_branch2a does not need backward computation.
I0615 20:53:16.766712 23191 net.cpp:228] res5a_branch2a does not need backward computation.
I0615 20:53:16.766719 23191 net.cpp:228] scale5a_branch1 does not need backward computation.
I0615 20:53:16.766724 23191 net.cpp:228] bn5a_branch1 does not need backward computation.
I0615 20:53:16.766731 23191 net.cpp:228] res5a_branch1 does not need backward computation.
I0615 20:53:16.766739 23191 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I0615 20:53:16.766746 23191 net.cpp:228] res4f_relu does not need backward computation.
I0615 20:53:16.766752 23191 net.cpp:228] res4f does not need backward computation.
I0615 20:53:16.766759 23191 net.cpp:228] scale4f_branch2c does not need backward computation.
I0615 20:53:16.766764 23191 net.cpp:228] bn4f_branch2c does not need backward computation.
I0615 20:53:16.766770 23191 net.cpp:228] res4f_branch2c does not need backward computation.
I0615 20:53:16.766777 23191 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I0615 20:53:16.766782 23191 net.cpp:228] scale4f_branch2b does not need backward computation.
I0615 20:53:16.766788 23191 net.cpp:228] bn4f_branch2b does not need backward computation.
I0615 20:53:16.766793 23191 net.cpp:228] res4f_branch2b does not need backward computation.
I0615 20:53:16.766799 23191 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I0615 20:53:16.766805 23191 net.cpp:228] scale4f_branch2a does not need backward computation.
I0615 20:53:16.766811 23191 net.cpp:228] bn4f_branch2a does not need backward computation.
I0615 20:53:16.766816 23191 net.cpp:228] res4f_branch2a does not need backward computation.
I0615 20:53:16.766824 23191 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I0615 20:53:16.766830 23191 net.cpp:228] res4e_relu does not need backward computation.
I0615 20:53:16.766836 23191 net.cpp:228] res4e does not need backward computation.
I0615 20:53:16.766844 23191 net.cpp:228] scale4e_branch2c does not need backward computation.
I0615 20:53:16.766850 23191 net.cpp:228] bn4e_branch2c does not need backward computation.
I0615 20:53:16.766856 23191 net.cpp:228] res4e_branch2c does not need backward computation.
I0615 20:53:16.766863 23191 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I0615 20:53:16.766870 23191 net.cpp:228] scale4e_branch2b does not need backward computation.
I0615 20:53:16.766875 23191 net.cpp:228] bn4e_branch2b does not need backward computation.
I0615 20:53:16.766880 23191 net.cpp:228] res4e_branch2b does not need backward computation.
I0615 20:53:16.766886 23191 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I0615 20:53:16.766892 23191 net.cpp:228] scale4e_branch2a does not need backward computation.
I0615 20:53:16.766897 23191 net.cpp:228] bn4e_branch2a does not need backward computation.
I0615 20:53:16.766903 23191 net.cpp:228] res4e_branch2a does not need backward computation.
I0615 20:53:16.766911 23191 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I0615 20:53:16.766918 23191 net.cpp:228] res4d_relu does not need backward computation.
I0615 20:53:16.766924 23191 net.cpp:228] res4d does not need backward computation.
I0615 20:53:16.766932 23191 net.cpp:228] scale4d_branch2c does not need backward computation.
I0615 20:53:16.766937 23191 net.cpp:228] bn4d_branch2c does not need backward computation.
I0615 20:53:16.766943 23191 net.cpp:228] res4d_branch2c does not need backward computation.
I0615 20:53:16.766949 23191 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I0615 20:53:16.766955 23191 net.cpp:228] scale4d_branch2b does not need backward computation.
I0615 20:53:16.766961 23191 net.cpp:228] bn4d_branch2b does not need backward computation.
I0615 20:53:16.766968 23191 net.cpp:228] res4d_branch2b does not need backward computation.
I0615 20:53:16.766974 23191 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I0615 20:53:16.766980 23191 net.cpp:228] scale4d_branch2a does not need backward computation.
I0615 20:53:16.766986 23191 net.cpp:228] bn4d_branch2a does not need backward computation.
I0615 20:53:16.766991 23191 net.cpp:228] res4d_branch2a does not need backward computation.
I0615 20:53:16.766999 23191 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I0615 20:53:16.767005 23191 net.cpp:228] res4c_relu does not need backward computation.
I0615 20:53:16.767012 23191 net.cpp:228] res4c does not need backward computation.
I0615 20:53:16.767019 23191 net.cpp:228] scale4c_branch2c does not need backward computation.
I0615 20:53:16.767025 23191 net.cpp:228] bn4c_branch2c does not need backward computation.
I0615 20:53:16.767030 23191 net.cpp:228] res4c_branch2c does not need backward computation.
I0615 20:53:16.767037 23191 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I0615 20:53:16.767043 23191 net.cpp:228] scale4c_branch2b does not need backward computation.
I0615 20:53:16.767050 23191 net.cpp:228] bn4c_branch2b does not need backward computation.
I0615 20:53:16.767055 23191 net.cpp:228] res4c_branch2b does not need backward computation.
I0615 20:53:16.767061 23191 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I0615 20:53:16.767067 23191 net.cpp:228] scale4c_branch2a does not need backward computation.
I0615 20:53:16.767072 23191 net.cpp:228] bn4c_branch2a does not need backward computation.
I0615 20:53:16.767078 23191 net.cpp:228] res4c_branch2a does not need backward computation.
I0615 20:53:16.767086 23191 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I0615 20:53:16.767092 23191 net.cpp:228] res4b_relu does not need backward computation.
I0615 20:53:16.767098 23191 net.cpp:228] res4b does not need backward computation.
I0615 20:53:16.767107 23191 net.cpp:228] scale4b_branch2c does not need backward computation.
I0615 20:53:16.767112 23191 net.cpp:228] bn4b_branch2c does not need backward computation.
I0615 20:53:16.767117 23191 net.cpp:228] res4b_branch2c does not need backward computation.
I0615 20:53:16.767124 23191 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I0615 20:53:16.767129 23191 net.cpp:228] scale4b_branch2b does not need backward computation.
I0615 20:53:16.767135 23191 net.cpp:228] bn4b_branch2b does not need backward computation.
I0615 20:53:16.767141 23191 net.cpp:228] res4b_branch2b does not need backward computation.
I0615 20:53:16.767148 23191 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I0615 20:53:16.767154 23191 net.cpp:228] scale4b_branch2a does not need backward computation.
I0615 20:53:16.767160 23191 net.cpp:228] bn4b_branch2a does not need backward computation.
I0615 20:53:16.767165 23191 net.cpp:228] res4b_branch2a does not need backward computation.
I0615 20:53:16.767174 23191 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I0615 20:53:16.767179 23191 net.cpp:228] res4a_relu does not need backward computation.
I0615 20:53:16.767185 23191 net.cpp:228] res4a does not need backward computation.
I0615 20:53:16.767194 23191 net.cpp:228] scale4a_branch2c does not need backward computation.
I0615 20:53:16.767199 23191 net.cpp:228] bn4a_branch2c does not need backward computation.
I0615 20:53:16.767204 23191 net.cpp:228] res4a_branch2c does not need backward computation.
I0615 20:53:16.767211 23191 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I0615 20:53:16.767217 23191 net.cpp:228] scale4a_branch2b does not need backward computation.
I0615 20:53:16.767222 23191 net.cpp:228] bn4a_branch2b does not need backward computation.
I0615 20:53:16.767228 23191 net.cpp:228] res4a_branch2b does not need backward computation.
I0615 20:53:16.767235 23191 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I0615 20:53:16.767241 23191 net.cpp:228] scale4a_branch2a does not need backward computation.
I0615 20:53:16.767247 23191 net.cpp:228] bn4a_branch2a does not need backward computation.
I0615 20:53:16.767253 23191 net.cpp:228] res4a_branch2a does not need backward computation.
I0615 20:53:16.767261 23191 net.cpp:228] scale4a_branch1 does not need backward computation.
I0615 20:53:16.767266 23191 net.cpp:228] bn4a_branch1 does not need backward computation.
I0615 20:53:16.767272 23191 net.cpp:228] res4a_branch1 does not need backward computation.
I0615 20:53:16.767280 23191 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I0615 20:53:16.767287 23191 net.cpp:228] res3d_relu does not need backward computation.
I0615 20:53:16.767292 23191 net.cpp:228] res3d does not need backward computation.
I0615 20:53:16.767302 23191 net.cpp:228] scale3d_branch2c does not need backward computation.
I0615 20:53:16.767307 23191 net.cpp:228] bn3d_branch2c does not need backward computation.
I0615 20:53:16.767313 23191 net.cpp:228] res3d_branch2c does not need backward computation.
I0615 20:53:16.767319 23191 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I0615 20:53:16.767325 23191 net.cpp:228] scale3d_branch2b does not need backward computation.
I0615 20:53:16.767331 23191 net.cpp:228] bn3d_branch2b does not need backward computation.
I0615 20:53:16.767338 23191 net.cpp:228] res3d_branch2b does not need backward computation.
I0615 20:53:16.767343 23191 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I0615 20:53:16.767349 23191 net.cpp:228] scale3d_branch2a does not need backward computation.
I0615 20:53:16.767355 23191 net.cpp:228] bn3d_branch2a does not need backward computation.
I0615 20:53:16.767361 23191 net.cpp:228] res3d_branch2a does not need backward computation.
I0615 20:53:16.767369 23191 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I0615 20:53:16.767375 23191 net.cpp:228] res3c_relu does not need backward computation.
I0615 20:53:16.767381 23191 net.cpp:228] res3c does not need backward computation.
I0615 20:53:16.767390 23191 net.cpp:228] scale3c_branch2c does not need backward computation.
I0615 20:53:16.767395 23191 net.cpp:228] bn3c_branch2c does not need backward computation.
I0615 20:53:16.767400 23191 net.cpp:228] res3c_branch2c does not need backward computation.
I0615 20:53:16.767406 23191 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I0615 20:53:16.767412 23191 net.cpp:228] scale3c_branch2b does not need backward computation.
I0615 20:53:16.767418 23191 net.cpp:228] bn3c_branch2b does not need backward computation.
I0615 20:53:16.767424 23191 net.cpp:228] res3c_branch2b does not need backward computation.
I0615 20:53:16.767431 23191 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I0615 20:53:16.767438 23191 net.cpp:228] scale3c_branch2a does not need backward computation.
I0615 20:53:16.767444 23191 net.cpp:228] bn3c_branch2a does not need backward computation.
I0615 20:53:16.767449 23191 net.cpp:228] res3c_branch2a does not need backward computation.
I0615 20:53:16.767457 23191 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I0615 20:53:16.767464 23191 net.cpp:228] res3b_relu does not need backward computation.
I0615 20:53:16.767469 23191 net.cpp:228] res3b does not need backward computation.
I0615 20:53:16.767478 23191 net.cpp:228] scale3b_branch2c does not need backward computation.
I0615 20:53:16.767483 23191 net.cpp:228] bn3b_branch2c does not need backward computation.
I0615 20:53:16.767490 23191 net.cpp:228] res3b_branch2c does not need backward computation.
I0615 20:53:16.767498 23191 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I0615 20:53:16.767503 23191 net.cpp:228] scale3b_branch2b does not need backward computation.
I0615 20:53:16.767508 23191 net.cpp:228] bn3b_branch2b does not need backward computation.
I0615 20:53:16.767515 23191 net.cpp:228] res3b_branch2b does not need backward computation.
I0615 20:53:16.767522 23191 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I0615 20:53:16.767527 23191 net.cpp:228] scale3b_branch2a does not need backward computation.
I0615 20:53:16.767534 23191 net.cpp:228] bn3b_branch2a does not need backward computation.
I0615 20:53:16.767539 23191 net.cpp:228] res3b_branch2a does not need backward computation.
I0615 20:53:16.767547 23191 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I0615 20:53:16.767554 23191 net.cpp:228] res3a_relu does not need backward computation.
I0615 20:53:16.767560 23191 net.cpp:228] res3a does not need backward computation.
I0615 20:53:16.767568 23191 net.cpp:228] scale3a_branch2c does not need backward computation.
I0615 20:53:16.767573 23191 net.cpp:228] bn3a_branch2c does not need backward computation.
I0615 20:53:16.767580 23191 net.cpp:228] res3a_branch2c does not need backward computation.
I0615 20:53:16.767586 23191 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I0615 20:53:16.767592 23191 net.cpp:228] scale3a_branch2b does not need backward computation.
I0615 20:53:16.767598 23191 net.cpp:228] bn3a_branch2b does not need backward computation.
I0615 20:53:16.767603 23191 net.cpp:228] res3a_branch2b does not need backward computation.
I0615 20:53:16.767613 23191 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I0615 20:53:16.767619 23191 net.cpp:228] scale3a_branch2a does not need backward computation.
I0615 20:53:16.767626 23191 net.cpp:228] bn3a_branch2a does not need backward computation.
I0615 20:53:16.767630 23191 net.cpp:228] res3a_branch2a does not need backward computation.
I0615 20:53:16.767637 23191 net.cpp:228] scale3a_branch1 does not need backward computation.
I0615 20:53:16.767644 23191 net.cpp:228] bn3a_branch1 does not need backward computation.
I0615 20:53:16.767650 23191 net.cpp:228] res3a_branch1 does not need backward computation.
I0615 20:53:16.767658 23191 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0615 20:53:16.767664 23191 net.cpp:228] res2c_relu does not need backward computation.
I0615 20:53:16.767670 23191 net.cpp:228] res2c does not need backward computation.
I0615 20:53:16.767679 23191 net.cpp:228] scale2c_branch2c does not need backward computation.
I0615 20:53:16.767684 23191 net.cpp:228] bn2c_branch2c does not need backward computation.
I0615 20:53:16.767690 23191 net.cpp:228] res2c_branch2c does not need backward computation.
I0615 20:53:16.767698 23191 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0615 20:53:16.767702 23191 net.cpp:228] scale2c_branch2b does not need backward computation.
I0615 20:53:16.767709 23191 net.cpp:228] bn2c_branch2b does not need backward computation.
I0615 20:53:16.767714 23191 net.cpp:228] res2c_branch2b does not need backward computation.
I0615 20:53:16.767721 23191 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0615 20:53:16.767727 23191 net.cpp:228] scale2c_branch2a does not need backward computation.
I0615 20:53:16.767733 23191 net.cpp:228] bn2c_branch2a does not need backward computation.
I0615 20:53:16.767740 23191 net.cpp:228] res2c_branch2a does not need backward computation.
I0615 20:53:16.767747 23191 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0615 20:53:16.767753 23191 net.cpp:228] res2b_relu does not need backward computation.
I0615 20:53:16.767760 23191 net.cpp:228] res2b does not need backward computation.
I0615 20:53:16.767767 23191 net.cpp:228] scale2b_branch2c does not need backward computation.
I0615 20:53:16.767773 23191 net.cpp:228] bn2b_branch2c does not need backward computation.
I0615 20:53:16.767778 23191 net.cpp:228] res2b_branch2c does not need backward computation.
I0615 20:53:16.767786 23191 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0615 20:53:16.767791 23191 net.cpp:228] scale2b_branch2b does not need backward computation.
I0615 20:53:16.767797 23191 net.cpp:228] bn2b_branch2b does not need backward computation.
I0615 20:53:16.767803 23191 net.cpp:228] res2b_branch2b does not need backward computation.
I0615 20:53:16.767809 23191 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0615 20:53:16.767815 23191 net.cpp:228] scale2b_branch2a does not need backward computation.
I0615 20:53:16.767822 23191 net.cpp:228] bn2b_branch2a does not need backward computation.
I0615 20:53:16.767827 23191 net.cpp:228] res2b_branch2a does not need backward computation.
I0615 20:53:16.767834 23191 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0615 20:53:16.767841 23191 net.cpp:228] res2a_relu does not need backward computation.
I0615 20:53:16.767848 23191 net.cpp:228] res2a does not need backward computation.
I0615 20:53:16.767855 23191 net.cpp:228] scale2a_branch2c does not need backward computation.
I0615 20:53:16.767860 23191 net.cpp:228] bn2a_branch2c does not need backward computation.
I0615 20:53:16.767866 23191 net.cpp:228] res2a_branch2c does not need backward computation.
I0615 20:53:16.767874 23191 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0615 20:53:16.767879 23191 net.cpp:228] scale2a_branch2b does not need backward computation.
I0615 20:53:16.767884 23191 net.cpp:228] bn2a_branch2b does not need backward computation.
I0615 20:53:16.767890 23191 net.cpp:228] res2a_branch2b does not need backward computation.
I0615 20:53:16.767897 23191 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0615 20:53:16.767904 23191 net.cpp:228] scale2a_branch2a does not need backward computation.
I0615 20:53:16.767909 23191 net.cpp:228] bn2a_branch2a does not need backward computation.
I0615 20:53:16.767915 23191 net.cpp:228] res2a_branch2a does not need backward computation.
I0615 20:53:16.767922 23191 net.cpp:228] scale2a_branch1 does not need backward computation.
I0615 20:53:16.767927 23191 net.cpp:228] bn2a_branch1 does not need backward computation.
I0615 20:53:16.767933 23191 net.cpp:228] res2a_branch1 does not need backward computation.
I0615 20:53:16.767941 23191 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0615 20:53:16.767948 23191 net.cpp:228] pool1 does not need backward computation.
I0615 20:53:16.767954 23191 net.cpp:228] conv1_relu does not need backward computation.
I0615 20:53:16.767961 23191 net.cpp:228] scale_conv1 does not need backward computation.
I0615 20:53:16.767966 23191 net.cpp:228] bn_conv1 does not need backward computation.
I0615 20:53:16.767972 23191 net.cpp:228] conv1 does not need backward computation.
I0615 20:53:16.767979 23191 net.cpp:228] input does not need backward computation.
I0615 20:53:16.767983 23191 net.cpp:270] This network produces output bbox_pred
I0615 20:53:16.767992 23191 net.cpp:270] This network produces output cls_prob
I0615 20:53:16.768302 23191 net.cpp:283] Network initialization done.
I0615 20:53:16.878417 23191 net.cpp:771] Ignoring source layer input-data
I0615 20:53:16.878438 23191 net.cpp:771] Ignoring source layer data_input-data_0_split
I0615 20:53:16.878445 23191 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I0615 20:53:16.878453 23191 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I0615 20:53:16.878455 23191 net.cpp:774] Copying source layer conv1
I0615 20:53:16.878557 23191 net.cpp:774] Copying source layer bn_conv1
I0615 20:53:16.878569 23191 net.cpp:774] Copying source layer scale_conv1
I0615 20:53:16.878581 23191 net.cpp:774] Copying source layer conv1_relu
I0615 20:53:16.878584 23191 net.cpp:774] Copying source layer pool1
I0615 20:53:16.878587 23191 net.cpp:774] Copying source layer pool1_pool1_0_split
I0615 20:53:16.878592 23191 net.cpp:774] Copying source layer res2a_branch1
I0615 20:53:16.878736 23191 net.cpp:774] Copying source layer bn2a_branch1
I0615 20:53:16.878752 23191 net.cpp:774] Copying source layer scale2a_branch1
I0615 20:53:16.878765 23191 net.cpp:774] Copying source layer res2a_branch2a
I0615 20:53:16.878808 23191 net.cpp:774] Copying source layer bn2a_branch2a
I0615 20:53:16.878819 23191 net.cpp:774] Copying source layer scale2a_branch2a
I0615 20:53:16.878829 23191 net.cpp:774] Copying source layer res2a_branch2a_relu
I0615 20:53:16.878832 23191 net.cpp:774] Copying source layer res2a_branch2b
I0615 20:53:16.879148 23191 net.cpp:774] Copying source layer bn2a_branch2b
I0615 20:53:16.879160 23191 net.cpp:774] Copying source layer scale2a_branch2b
I0615 20:53:16.879169 23191 net.cpp:774] Copying source layer res2a_branch2b_relu
I0615 20:53:16.879173 23191 net.cpp:774] Copying source layer res2a_branch2c
I0615 20:53:16.879317 23191 net.cpp:774] Copying source layer bn2a_branch2c
I0615 20:53:16.879331 23191 net.cpp:774] Copying source layer scale2a_branch2c
I0615 20:53:16.879344 23191 net.cpp:774] Copying source layer res2a
I0615 20:53:16.879348 23191 net.cpp:774] Copying source layer res2a_relu
I0615 20:53:16.879354 23191 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0615 20:53:16.879359 23191 net.cpp:774] Copying source layer res2b_branch2a
I0615 20:53:16.879500 23191 net.cpp:774] Copying source layer bn2b_branch2a
I0615 20:53:16.879513 23191 net.cpp:774] Copying source layer scale2b_branch2a
I0615 20:53:16.879523 23191 net.cpp:774] Copying source layer res2b_branch2a_relu
I0615 20:53:16.879528 23191 net.cpp:774] Copying source layer res2b_branch2b
I0615 20:53:16.879839 23191 net.cpp:774] Copying source layer bn2b_branch2b
I0615 20:53:16.879851 23191 net.cpp:774] Copying source layer scale2b_branch2b
I0615 20:53:16.879861 23191 net.cpp:774] Copying source layer res2b_branch2b_relu
I0615 20:53:16.879866 23191 net.cpp:774] Copying source layer res2b_branch2c
I0615 20:53:16.880012 23191 net.cpp:774] Copying source layer bn2b_branch2c
I0615 20:53:16.880028 23191 net.cpp:774] Copying source layer scale2b_branch2c
I0615 20:53:16.880041 23191 net.cpp:774] Copying source layer res2b
I0615 20:53:16.880046 23191 net.cpp:774] Copying source layer res2b_relu
I0615 20:53:16.880051 23191 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0615 20:53:16.880056 23191 net.cpp:774] Copying source layer res2c_branch2a
I0615 20:53:16.880204 23191 net.cpp:774] Copying source layer bn2c_branch2a
I0615 20:53:16.880218 23191 net.cpp:774] Copying source layer scale2c_branch2a
I0615 20:53:16.880228 23191 net.cpp:774] Copying source layer res2c_branch2a_relu
I0615 20:53:16.880234 23191 net.cpp:774] Copying source layer res2c_branch2b
I0615 20:53:16.880547 23191 net.cpp:774] Copying source layer bn2c_branch2b
I0615 20:53:16.880559 23191 net.cpp:774] Copying source layer scale2c_branch2b
I0615 20:53:16.880569 23191 net.cpp:774] Copying source layer res2c_branch2b_relu
I0615 20:53:16.880573 23191 net.cpp:774] Copying source layer res2c_branch2c
I0615 20:53:16.880722 23191 net.cpp:774] Copying source layer bn2c_branch2c
I0615 20:53:16.880739 23191 net.cpp:774] Copying source layer scale2c_branch2c
I0615 20:53:16.880753 23191 net.cpp:774] Copying source layer res2c
I0615 20:53:16.880758 23191 net.cpp:774] Copying source layer res2c_relu
I0615 20:53:16.880762 23191 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0615 20:53:16.880767 23191 net.cpp:774] Copying source layer res3a_branch1
I0615 20:53:16.881912 23191 net.cpp:774] Copying source layer bn3a_branch1
I0615 20:53:16.881934 23191 net.cpp:774] Copying source layer scale3a_branch1
I0615 20:53:16.881953 23191 net.cpp:774] Copying source layer res3a_branch2a
I0615 20:53:16.882234 23191 net.cpp:774] Copying source layer bn3a_branch2a
I0615 20:53:16.882249 23191 net.cpp:774] Copying source layer scale3a_branch2a
I0615 20:53:16.882261 23191 net.cpp:774] Copying source layer res3a_branch2a_relu
I0615 20:53:16.882266 23191 net.cpp:774] Copying source layer res3a_branch2b
I0615 20:53:16.883493 23191 net.cpp:774] Copying source layer bn3a_branch2b
I0615 20:53:16.883507 23191 net.cpp:774] Copying source layer scale3a_branch2b
I0615 20:53:16.883519 23191 net.cpp:774] Copying source layer res3a_branch2b_relu
I0615 20:53:16.883524 23191 net.cpp:774] Copying source layer res3a_branch2c
I0615 20:53:16.884074 23191 net.cpp:774] Copying source layer bn3a_branch2c
I0615 20:53:16.884094 23191 net.cpp:774] Copying source layer scale3a_branch2c
I0615 20:53:16.884114 23191 net.cpp:774] Copying source layer res3a
I0615 20:53:16.884119 23191 net.cpp:774] Copying source layer res3a_relu
I0615 20:53:16.884125 23191 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0615 20:53:16.884130 23191 net.cpp:774] Copying source layer res3b_branch2a
I0615 20:53:16.884682 23191 net.cpp:774] Copying source layer bn3b_branch2a
I0615 20:53:16.884696 23191 net.cpp:774] Copying source layer scale3b_branch2a
I0615 20:53:16.884708 23191 net.cpp:774] Copying source layer res3b_branch2a_relu
I0615 20:53:16.884713 23191 net.cpp:774] Copying source layer res3b_branch2b
I0615 20:53:16.885973 23191 net.cpp:774] Copying source layer bn3b_branch2b
I0615 20:53:16.885990 23191 net.cpp:774] Copying source layer scale3b_branch2b
I0615 20:53:16.886003 23191 net.cpp:774] Copying source layer res3b_branch2b_relu
I0615 20:53:16.886009 23191 net.cpp:774] Copying source layer res3b_branch2c
I0615 20:53:16.886560 23191 net.cpp:774] Copying source layer bn3b_branch2c
I0615 20:53:16.886581 23191 net.cpp:774] Copying source layer scale3b_branch2c
I0615 20:53:16.886600 23191 net.cpp:774] Copying source layer res3b
I0615 20:53:16.886605 23191 net.cpp:774] Copying source layer res3b_relu
I0615 20:53:16.886610 23191 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0615 20:53:16.886616 23191 net.cpp:774] Copying source layer res3c_branch2a
I0615 20:53:16.887167 23191 net.cpp:774] Copying source layer bn3c_branch2a
I0615 20:53:16.887183 23191 net.cpp:774] Copying source layer scale3c_branch2a
I0615 20:53:16.887195 23191 net.cpp:774] Copying source layer res3c_branch2a_relu
I0615 20:53:16.887202 23191 net.cpp:774] Copying source layer res3c_branch2b
I0615 20:53:16.888430 23191 net.cpp:774] Copying source layer bn3c_branch2b
I0615 20:53:16.888444 23191 net.cpp:774] Copying source layer scale3c_branch2b
I0615 20:53:16.888456 23191 net.cpp:774] Copying source layer res3c_branch2b_relu
I0615 20:53:16.888463 23191 net.cpp:774] Copying source layer res3c_branch2c
I0615 20:53:16.889040 23191 net.cpp:774] Copying source layer bn3c_branch2c
I0615 20:53:16.889065 23191 net.cpp:774] Copying source layer scale3c_branch2c
I0615 20:53:16.889083 23191 net.cpp:774] Copying source layer res3c
I0615 20:53:16.889088 23191 net.cpp:774] Copying source layer res3c_relu
I0615 20:53:16.889094 23191 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0615 20:53:16.889101 23191 net.cpp:774] Copying source layer res3d_branch2a
I0615 20:53:16.889653 23191 net.cpp:774] Copying source layer bn3d_branch2a
I0615 20:53:16.889668 23191 net.cpp:774] Copying source layer scale3d_branch2a
I0615 20:53:16.889683 23191 net.cpp:774] Copying source layer res3d_branch2a_relu
I0615 20:53:16.889688 23191 net.cpp:774] Copying source layer res3d_branch2b
I0615 20:53:16.890921 23191 net.cpp:774] Copying source layer bn3d_branch2b
I0615 20:53:16.890938 23191 net.cpp:774] Copying source layer scale3d_branch2b
I0615 20:53:16.890951 23191 net.cpp:774] Copying source layer res3d_branch2b_relu
I0615 20:53:16.890957 23191 net.cpp:774] Copying source layer res3d_branch2c
I0615 20:53:16.891508 23191 net.cpp:774] Copying source layer bn3d_branch2c
I0615 20:53:16.891530 23191 net.cpp:774] Copying source layer scale3d_branch2c
I0615 20:53:16.891552 23191 net.cpp:774] Copying source layer res3d
I0615 20:53:16.891558 23191 net.cpp:774] Copying source layer res3d_relu
I0615 20:53:16.891564 23191 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0615 20:53:16.891571 23191 net.cpp:774] Copying source layer res4a_branch1
I0615 20:53:16.895967 23191 net.cpp:774] Copying source layer bn4a_branch1
I0615 20:53:16.896001 23191 net.cpp:774] Copying source layer scale4a_branch1
I0615 20:53:16.896030 23191 net.cpp:774] Copying source layer res4a_branch2a
I0615 20:53:16.897150 23191 net.cpp:774] Copying source layer bn4a_branch2a
I0615 20:53:16.897171 23191 net.cpp:774] Copying source layer scale4a_branch2a
I0615 20:53:16.897186 23191 net.cpp:774] Copying source layer res4a_branch2a_relu
I0615 20:53:16.897192 23191 net.cpp:774] Copying source layer res4a_branch2b
I0615 20:53:16.902102 23191 net.cpp:774] Copying source layer bn4a_branch2b
I0615 20:53:16.902124 23191 net.cpp:774] Copying source layer scale4a_branch2b
I0615 20:53:16.902139 23191 net.cpp:774] Copying source layer res4a_branch2b_relu
I0615 20:53:16.902146 23191 net.cpp:774] Copying source layer res4a_branch2c
I0615 20:53:16.904323 23191 net.cpp:774] Copying source layer bn4a_branch2c
I0615 20:53:16.904353 23191 net.cpp:774] Copying source layer scale4a_branch2c
I0615 20:53:16.904382 23191 net.cpp:774] Copying source layer res4a
I0615 20:53:16.904388 23191 net.cpp:774] Copying source layer res4a_relu
I0615 20:53:16.904397 23191 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0615 20:53:16.904402 23191 net.cpp:774] Copying source layer res4b_branch2a
I0615 20:53:16.906602 23191 net.cpp:774] Copying source layer bn4b_branch2a
I0615 20:53:16.906623 23191 net.cpp:774] Copying source layer scale4b_branch2a
I0615 20:53:16.906639 23191 net.cpp:774] Copying source layer res4b_branch2a_relu
I0615 20:53:16.906646 23191 net.cpp:774] Copying source layer res4b_branch2b
I0615 20:53:16.911554 23191 net.cpp:774] Copying source layer bn4b_branch2b
I0615 20:53:16.911577 23191 net.cpp:774] Copying source layer scale4b_branch2b
I0615 20:53:16.911593 23191 net.cpp:774] Copying source layer res4b_branch2b_relu
I0615 20:53:16.911600 23191 net.cpp:774] Copying source layer res4b_branch2c
I0615 20:53:16.913797 23191 net.cpp:774] Copying source layer bn4b_branch2c
I0615 20:53:16.913831 23191 net.cpp:774] Copying source layer scale4b_branch2c
I0615 20:53:16.913859 23191 net.cpp:774] Copying source layer res4b
I0615 20:53:16.913866 23191 net.cpp:774] Copying source layer res4b_relu
I0615 20:53:16.913874 23191 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0615 20:53:16.913882 23191 net.cpp:774] Copying source layer res4c_branch2a
I0615 20:53:16.916061 23191 net.cpp:774] Copying source layer bn4c_branch2a
I0615 20:53:16.916081 23191 net.cpp:774] Copying source layer scale4c_branch2a
I0615 20:53:16.916097 23191 net.cpp:774] Copying source layer res4c_branch2a_relu
I0615 20:53:16.916105 23191 net.cpp:774] Copying source layer res4c_branch2b
I0615 20:53:16.921027 23191 net.cpp:774] Copying source layer bn4c_branch2b
I0615 20:53:16.921049 23191 net.cpp:774] Copying source layer scale4c_branch2b
I0615 20:53:16.921066 23191 net.cpp:774] Copying source layer res4c_branch2b_relu
I0615 20:53:16.921073 23191 net.cpp:774] Copying source layer res4c_branch2c
I0615 20:53:16.923249 23191 net.cpp:774] Copying source layer bn4c_branch2c
I0615 20:53:16.923281 23191 net.cpp:774] Copying source layer scale4c_branch2c
I0615 20:53:16.923310 23191 net.cpp:774] Copying source layer res4c
I0615 20:53:16.923316 23191 net.cpp:774] Copying source layer res4c_relu
I0615 20:53:16.923324 23191 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0615 20:53:16.923331 23191 net.cpp:774] Copying source layer res4d_branch2a
I0615 20:53:16.925546 23191 net.cpp:774] Copying source layer bn4d_branch2a
I0615 20:53:16.925568 23191 net.cpp:774] Copying source layer scale4d_branch2a
I0615 20:53:16.925585 23191 net.cpp:774] Copying source layer res4d_branch2a_relu
I0615 20:53:16.925592 23191 net.cpp:774] Copying source layer res4d_branch2b
I0615 20:53:16.930579 23191 net.cpp:774] Copying source layer bn4d_branch2b
I0615 20:53:16.930600 23191 net.cpp:774] Copying source layer scale4d_branch2b
I0615 20:53:16.930616 23191 net.cpp:774] Copying source layer res4d_branch2b_relu
I0615 20:53:16.930624 23191 net.cpp:774] Copying source layer res4d_branch2c
I0615 20:53:16.932806 23191 net.cpp:774] Copying source layer bn4d_branch2c
I0615 20:53:16.932837 23191 net.cpp:774] Copying source layer scale4d_branch2c
I0615 20:53:16.932866 23191 net.cpp:774] Copying source layer res4d
I0615 20:53:16.932873 23191 net.cpp:774] Copying source layer res4d_relu
I0615 20:53:16.932883 23191 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0615 20:53:16.932890 23191 net.cpp:774] Copying source layer res4e_branch2a
I0615 20:53:16.935086 23191 net.cpp:774] Copying source layer bn4e_branch2a
I0615 20:53:16.935106 23191 net.cpp:774] Copying source layer scale4e_branch2a
I0615 20:53:16.935123 23191 net.cpp:774] Copying source layer res4e_branch2a_relu
I0615 20:53:16.935132 23191 net.cpp:774] Copying source layer res4e_branch2b
I0615 20:53:16.940039 23191 net.cpp:774] Copying source layer bn4e_branch2b
I0615 20:53:16.940062 23191 net.cpp:774] Copying source layer scale4e_branch2b
I0615 20:53:16.940079 23191 net.cpp:774] Copying source layer res4e_branch2b_relu
I0615 20:53:16.940088 23191 net.cpp:774] Copying source layer res4e_branch2c
I0615 20:53:16.942284 23191 net.cpp:774] Copying source layer bn4e_branch2c
I0615 20:53:16.942318 23191 net.cpp:774] Copying source layer scale4e_branch2c
I0615 20:53:16.942348 23191 net.cpp:774] Copying source layer res4e
I0615 20:53:16.942355 23191 net.cpp:774] Copying source layer res4e_relu
I0615 20:53:16.942364 23191 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0615 20:53:16.942373 23191 net.cpp:774] Copying source layer res4f_branch2a
I0615 20:53:16.944550 23191 net.cpp:774] Copying source layer bn4f_branch2a
I0615 20:53:16.944569 23191 net.cpp:774] Copying source layer scale4f_branch2a
I0615 20:53:16.944586 23191 net.cpp:774] Copying source layer res4f_branch2a_relu
I0615 20:53:16.944594 23191 net.cpp:774] Copying source layer res4f_branch2b
I0615 20:53:16.949527 23191 net.cpp:774] Copying source layer bn4f_branch2b
I0615 20:53:16.949550 23191 net.cpp:774] Copying source layer scale4f_branch2b
I0615 20:53:16.949568 23191 net.cpp:774] Copying source layer res4f_branch2b_relu
I0615 20:53:16.949576 23191 net.cpp:774] Copying source layer res4f_branch2c
I0615 20:53:16.951755 23191 net.cpp:774] Copying source layer bn4f_branch2c
I0615 20:53:16.951786 23191 net.cpp:774] Copying source layer scale4f_branch2c
I0615 20:53:16.951815 23191 net.cpp:774] Copying source layer res4f
I0615 20:53:16.951823 23191 net.cpp:774] Copying source layer res4f_relu
I0615 20:53:16.951833 23191 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0615 20:53:16.951841 23191 net.cpp:774] Copying source layer res5a_branch1
I0615 20:53:16.969342 23191 net.cpp:774] Copying source layer bn5a_branch1
I0615 20:53:16.969393 23191 net.cpp:774] Copying source layer scale5a_branch1
I0615 20:53:16.969441 23191 net.cpp:774] Copying source layer res5a_branch2a
I0615 20:53:16.973819 23191 net.cpp:774] Copying source layer bn5a_branch2a
I0615 20:53:16.973851 23191 net.cpp:774] Copying source layer scale5a_branch2a
I0615 20:53:16.973875 23191 net.cpp:774] Copying source layer res5a_branch2a_relu
I0615 20:53:16.973883 23191 net.cpp:774] Copying source layer res5a_branch2b
I0615 20:53:16.993582 23191 net.cpp:774] Copying source layer bn5a_branch2b
I0615 20:53:16.993614 23191 net.cpp:774] Copying source layer scale5a_branch2b
I0615 20:53:16.993638 23191 net.cpp:774] Copying source layer res5a_branch2b_relu
I0615 20:53:16.993646 23191 net.cpp:774] Copying source layer res5a_branch2c
I0615 20:53:17.002390 23191 net.cpp:774] Copying source layer bn5a_branch2c
I0615 20:53:17.002444 23191 net.cpp:774] Copying source layer scale5a_branch2c
I0615 20:53:17.002490 23191 net.cpp:774] Copying source layer res5a
I0615 20:53:17.002498 23191 net.cpp:774] Copying source layer res5a_relu
I0615 20:53:17.002508 23191 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0615 20:53:17.002517 23191 net.cpp:774] Copying source layer res5b_branch2a
I0615 20:53:17.011265 23191 net.cpp:774] Copying source layer bn5b_branch2a
I0615 20:53:17.011301 23191 net.cpp:774] Copying source layer scale5b_branch2a
I0615 20:53:17.011324 23191 net.cpp:774] Copying source layer res5b_branch2a_relu
I0615 20:53:17.011333 23191 net.cpp:774] Copying source layer res5b_branch2b
I0615 20:53:17.031162 23191 net.cpp:774] Copying source layer bn5b_branch2b
I0615 20:53:17.031206 23191 net.cpp:774] Copying source layer scale5b_branch2b
I0615 20:53:17.031230 23191 net.cpp:774] Copying source layer res5b_branch2b_relu
I0615 20:53:17.031239 23191 net.cpp:774] Copying source layer res5b_branch2c
I0615 20:53:17.039988 23191 net.cpp:774] Copying source layer bn5b_branch2c
I0615 20:53:17.040055 23191 net.cpp:774] Copying source layer scale5b_branch2c
I0615 20:53:17.040102 23191 net.cpp:774] Copying source layer res5b
I0615 20:53:17.040110 23191 net.cpp:774] Copying source layer res5b_relu
I0615 20:53:17.040122 23191 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0615 20:53:17.040130 23191 net.cpp:774] Copying source layer res5c_branch2a
I0615 20:53:17.048879 23191 net.cpp:774] Copying source layer bn5c_branch2a
I0615 20:53:17.048908 23191 net.cpp:774] Copying source layer scale5c_branch2a
I0615 20:53:17.048933 23191 net.cpp:774] Copying source layer res5c_branch2a_relu
I0615 20:53:17.048944 23191 net.cpp:774] Copying source layer res5c_branch2b
I0615 20:53:17.068624 23191 net.cpp:774] Copying source layer bn5c_branch2b
I0615 20:53:17.068655 23191 net.cpp:774] Copying source layer scale5c_branch2b
I0615 20:53:17.068678 23191 net.cpp:774] Copying source layer res5c_branch2b_relu
I0615 20:53:17.068688 23191 net.cpp:774] Copying source layer res5c_branch2c
I0615 20:53:17.077452 23191 net.cpp:774] Copying source layer bn5c_branch2c
I0615 20:53:17.077514 23191 net.cpp:774] Copying source layer scale5c_branch2c
I0615 20:53:17.077563 23191 net.cpp:774] Copying source layer res5c
I0615 20:53:17.077570 23191 net.cpp:774] Copying source layer res5c_relu
I0615 20:53:17.077579 23191 net.cpp:774] Copying source layer rpn_conv/3x3
I0615 20:53:17.116950 23191 net.cpp:774] Copying source layer rpn_relu/3x3
I0615 20:53:17.116971 23191 net.cpp:774] Copying source layer rpn/output_rpn_relu/3x3_0_split
I0615 20:53:17.116981 23191 net.cpp:774] Copying source layer rpn_cls_score
I0615 20:53:17.117276 23191 net.cpp:771] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0615 20:53:17.117285 23191 net.cpp:774] Copying source layer rpn_bbox_pred
I0615 20:53:17.117861 23191 net.cpp:771] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0615 20:53:17.117871 23191 net.cpp:774] Copying source layer rpn_cls_score_reshape
I0615 20:53:17.117879 23191 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0615 20:53:17.117887 23191 net.cpp:771] Ignoring source layer rpn-data
I0615 20:53:17.117895 23191 net.cpp:771] Ignoring source layer rpn_loss_cls
I0615 20:53:17.117905 23191 net.cpp:771] Ignoring source layer rpn_loss_bbox
I0615 20:53:17.117913 23191 net.cpp:774] Copying source layer rpn_cls_prob
I0615 20:53:17.117923 23191 net.cpp:774] Copying source layer rpn_cls_prob_reshape
I0615 20:53:17.117931 23191 net.cpp:774] Copying source layer proposal
I0615 20:53:17.117939 23191 net.cpp:771] Ignoring source layer roi-data
I0615 20:53:17.117947 23191 net.cpp:771] Ignoring source layer rois_roi-data_0_split
I0615 20:53:17.117955 23191 net.cpp:771] Ignoring source layer labels_roi-data_1_split
I0615 20:53:17.117964 23191 net.cpp:771] Ignoring source layer bbox_targets_roi-data_2_split
I0615 20:53:17.117971 23191 net.cpp:771] Ignoring source layer bbox_inside_weights_roi-data_3_split
I0615 20:53:17.117980 23191 net.cpp:774] Copying source layer conv_new_1
I0615 20:53:17.135514 23191 net.cpp:774] Copying source layer conv_new_1_relu
I0615 20:53:17.135529 23191 net.cpp:774] Copying source layer conv_new_1_conv_new_1_relu_0_split
I0615 20:53:17.135536 23191 net.cpp:774] Copying source layer rfcn_cls
I0615 20:53:17.137238 23191 net.cpp:774] Copying source layer rfcn_bbox
I0615 20:53:17.140583 23191 net.cpp:774] Copying source layer psroipooled_cls_rois
I0615 20:53:17.140594 23191 net.cpp:774] Copying source layer ave_cls_score_rois
I0615 20:53:17.140602 23191 net.cpp:771] Ignoring source layer cls_score_ave_cls_score_rois_0_split
I0615 20:53:17.140610 23191 net.cpp:774] Copying source layer psroipooled_loc_rois
I0615 20:53:17.140619 23191 net.cpp:774] Copying source layer ave_bbox_pred_rois
I0615 20:53:17.140627 23191 net.cpp:771] Ignoring source layer bbox_pred_ave_bbox_pred_rois_0_split
I0615 20:53:17.140643 23191 net.cpp:771] Ignoring source layer per_roi_loss_cls
I0615 20:53:17.140651 23191 net.cpp:771] Ignoring source layer per_roi_loss_bbox
I0615 20:53:17.140660 23191 net.cpp:771] Ignoring source layer per_roi_loss
I0615 20:53:17.140668 23191 net.cpp:771] Ignoring source layer annotator_detector
I0615 20:53:17.140676 23191 net.cpp:771] Ignoring source layer labels_ohem_annotator_detector_0_split
I0615 20:53:17.140683 23191 net.cpp:771] Ignoring source layer silence
I0615 20:53:17.140691 23191 net.cpp:771] Ignoring source layer loss
I0615 20:53:17.140700 23191 net.cpp:771] Ignoring source layer accuarcy
I0615 20:53:17.140708 23191 net.cpp:771] Ignoring source layer loss_bbox
I0615 20:53:17.428681 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5529624
I0615 20:53:17.444011 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.465397 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.479290 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.488543 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.506368 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.514607 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.532183 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0615 20:53:17.541657 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0615 20:53:17.554671 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0615 20:53:17.562592 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.567868 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.577075 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.582520 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.595156 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.599550 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.608512 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0615 20:53:17.612864 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0615 20:53:17.620307 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0615 20:53:17.627079 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.630342 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.637100 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.640347 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.646584 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.650030 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.656360 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.659984 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.666221 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.669484 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.675719 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.678966 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0615 20:53:17.688195 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.706275 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0615 20:53:17.712851 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.733170 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0615 20:53:17.739570 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.762434 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0615 20:53:17.783105 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.783506 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.818696 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.823930 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0615 20:53:17.824970 23191 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
im_detect: 1/4024 0.421s 0.001s
im_detect: 2/4024 0.355s 0.001s
im_detect: 3/4024 0.333s 0.001s
im_detect: 4/4024 0.322s 0.001s
im_detect: 5/4024 0.315s 0.001s
im_detect: 6/4024 0.310s 0.001s
im_detect: 7/4024 0.307s 0.001s
im_detect: 8/4024 0.304s 0.001s
im_detect: 9/4024 0.302s 0.001s
im_detect: 10/4024 0.301s 0.001s
im_detect: 11/4024 0.300s 0.001s
im_detect: 12/4024 0.299s 0.001s
im_detect: 13/4024 0.298s 0.001s
im_detect: 14/4024 0.297s 0.001s
im_detect: 15/4024 0.296s 0.001s
im_detect: 16/4024 0.296s 0.001s
im_detect: 17/4024 0.295s 0.001s
im_detect: 18/4024 0.295s 0.001s
im_detect: 19/4024 0.294s 0.001s
im_detect: 20/4024 0.294s 0.001s
im_detect: 21/4024 0.294s 0.001s
im_detect: 22/4024 0.294s 0.001s
im_detect: 23/4024 0.293s 0.001s
im_detect: 24/4024 0.293s 0.001s
im_detect: 25/4024 0.293s 0.001s
im_detect: 26/4024 0.293s 0.001s
im_detect: 27/4024 0.293s 0.001s
im_detect: 28/4024 0.293s 0.001s
im_detect: 29/4024 0.293s 0.001s
im_detect: 30/4024 0.293s 0.001s
im_detect: 31/4024 0.292s 0.001s
im_detect: 32/4024 0.292s 0.001s
im_detect: 33/4024 0.292s 0.001s
im_detect: 34/4024 0.292s 0.001s
im_detect: 35/4024 0.292s 0.001s
im_detect: 36/4024 0.292s 0.001s
im_detect: 37/4024 0.291s 0.001s
im_detect: 38/4024 0.291s 0.001s
im_detect: 39/4024 0.291s 0.001s
im_detect: 40/4024 0.291s 0.001s
im_detect: 41/4024 0.291s 0.001s
im_detect: 42/4024 0.291s 0.001s
im_detect: 43/4024 0.291s 0.001s
im_detect: 44/4024 0.291s 0.001s
im_detect: 45/4024 0.291s 0.001s
im_detect: 46/4024 0.290s 0.001s
im_detect: 47/4024 0.290s 0.001s
im_detect: 48/4024 0.290s 0.001s
im_detect: 49/4024 0.290s 0.001s
im_detect: 50/4024 0.290s 0.001s
im_detect: 51/4024 0.290s 0.001s
im_detect: 52/4024 0.290s 0.001s
im_detect: 53/4024 0.290s 0.001s
im_detect: 54/4024 0.290s 0.001s
im_detect: 55/4024 0.290s 0.001s
im_detect: 56/4024 0.290s 0.001s
im_detect: 57/4024 0.290s 0.001s
im_detect: 58/4024 0.290s 0.001s
im_detect: 59/4024 0.290s 0.001s
im_detect: 60/4024 0.290s 0.001s
im_detect: 61/4024 0.290s 0.001s
im_detect: 62/4024 0.290s 0.001s
im_detect: 63/4024 0.290s 0.001s
im_detect: 64/4024 0.290s 0.001s
im_detect: 65/4024 0.290s 0.001s
im_detect: 66/4024 0.290s 0.001s
im_detect: 67/4024 0.290s 0.001s
im_detect: 68/4024 0.290s 0.001s
im_detect: 69/4024 0.289s 0.001s
im_detect: 70/4024 0.289s 0.001s
im_detect: 71/4024 0.289s 0.001s
im_detect: 72/4024 0.289s 0.001s
im_detect: 73/4024 0.289s 0.001s
im_detect: 74/4024 0.289s 0.001s
im_detect: 75/4024 0.289s 0.001s
im_detect: 76/4024 0.289s 0.001s
im_detect: 77/4024 0.289s 0.001s
im_detect: 78/4024 0.289s 0.001s
im_detect: 79/4024 0.289s 0.001s
im_detect: 80/4024 0.289s 0.001s
im_detect: 81/4024 0.289s 0.001s
im_detect: 82/4024 0.289s 0.001s
im_detect: 83/4024 0.289s 0.001s
im_detect: 84/4024 0.289s 0.001s
im_detect: 85/4024 0.289s 0.001s
im_detect: 86/4024 0.289s 0.001s
im_detect: 87/4024 0.289s 0.001s
im_detect: 88/4024 0.289s 0.001s
im_detect: 89/4024 0.289s 0.001s
im_detect: 90/4024 0.289s 0.001s
im_detect: 91/4024 0.289s 0.001s
im_detect: 92/4024 0.289s 0.001s
im_detect: 93/4024 0.289s 0.001s
im_detect: 94/4024 0.289s 0.001s
im_detect: 95/4024 0.289s 0.001s
im_detect: 96/4024 0.289s 0.001s
im_detect: 97/4024 0.289s 0.001s
im_detect: 98/4024 0.289s 0.001s
im_detect: 99/4024 0.289s 0.001s
im_detect: 100/4024 0.289s 0.001s
im_detect: 101/4024 0.289s 0.001s
im_detect: 102/4024 0.289s 0.001s
im_detect: 103/4024 0.289s 0.001s
im_detect: 104/4024 0.289s 0.001s
im_detect: 105/4024 0.289s 0.001s
im_detect: 106/4024 0.289s 0.001s
im_detect: 107/4024 0.289s 0.001s
im_detect: 108/4024 0.289s 0.001s
im_detect: 109/4024 0.289s 0.001s
im_detect: 110/4024 0.289s 0.001s
im_detect: 111/4024 0.289s 0.001s
im_detect: 112/4024 0.289s 0.001s
im_detect: 113/4024 0.289s 0.001s
im_detect: 114/4024 0.289s 0.001s
im_detect: 115/4024 0.289s 0.001s
im_detect: 116/4024 0.289s 0.001s
im_detect: 117/4024 0.289s 0.001s
im_detect: 118/4024 0.289s 0.001s
im_detect: 119/4024 0.289s 0.001s
im_detect: 120/4024 0.289s 0.001s
im_detect: 121/4024 0.289s 0.001s
im_detect: 122/4024 0.289s 0.001s
im_detect: 123/4024 0.289s 0.001s
im_detect: 124/4024 0.289s 0.001s
im_detect: 125/4024 0.289s 0.001s
im_detect: 126/4024 0.289s 0.001s
im_detect: 127/4024 0.289s 0.001s
im_detect: 128/4024 0.289s 0.001s
im_detect: 129/4024 0.289s 0.001s
im_detect: 130/4024 0.289s 0.001s
im_detect: 131/4024 0.289s 0.001s
im_detect: 132/4024 0.289s 0.001s
im_detect: 133/4024 0.289s 0.001s
im_detect: 134/4024 0.289s 0.001s
im_detect: 135/4024 0.289s 0.001s
im_detect: 136/4024 0.289s 0.001s
im_detect: 137/4024 0.289s 0.001s
im_detect: 138/4024 0.289s 0.001s
im_detect: 139/4024 0.289s 0.001s
im_detect: 140/4024 0.289s 0.001s
im_detect: 141/4024 0.289s 0.001s
im_detect: 142/4024 0.289s 0.001s
im_detect: 143/4024 0.289s 0.001s
im_detect: 144/4024 0.289s 0.001s
im_detect: 145/4024 0.288s 0.001s
im_detect: 146/4024 0.288s 0.001s
im_detect: 147/4024 0.288s 0.001s
im_detect: 148/4024 0.288s 0.001s
im_detect: 149/4024 0.288s 0.001s
im_detect: 150/4024 0.288s 0.001s
im_detect: 151/4024 0.288s 0.001s
im_detect: 152/4024 0.288s 0.001s
im_detect: 153/4024 0.288s 0.001s
im_detect: 154/4024 0.288s 0.001s
im_detect: 155/4024 0.288s 0.001s
im_detect: 156/4024 0.288s 0.001s
im_detect: 157/4024 0.288s 0.001s
im_detect: 158/4024 0.288s 0.001s
im_detect: 159/4024 0.288s 0.001s
im_detect: 160/4024 0.288s 0.001s
im_detect: 161/4024 0.288s 0.001s
im_detect: 162/4024 0.288s 0.001s
im_detect: 163/4024 0.288s 0.001s
im_detect: 164/4024 0.288s 0.001s
im_detect: 165/4024 0.288s 0.001s
im_detect: 166/4024 0.288s 0.001s
im_detect: 167/4024 0.288s 0.001s
im_detect: 168/4024 0.288s 0.001s
im_detect: 169/4024 0.288s 0.001s
im_detect: 170/4024 0.288s 0.001s
im_detect: 171/4024 0.288s 0.001s
im_detect: 172/4024 0.288s 0.001s
im_detect: 173/4024 0.288s 0.001s
im_detect: 174/4024 0.288s 0.001s
im_detect: 175/4024 0.288s 0.001s
im_detect: 176/4024 0.288s 0.001s
im_detect: 177/4024 0.288s 0.001s
im_detect: 178/4024 0.288s 0.001s
im_detect: 179/4024 0.288s 0.001s
im_detect: 180/4024 0.288s 0.001s
im_detect: 181/4024 0.288s 0.001s
im_detect: 182/4024 0.288s 0.001s
im_detect: 183/4024 0.288s 0.001s
im_detect: 184/4024 0.288s 0.001s
im_detect: 185/4024 0.288s 0.001s
im_detect: 186/4024 0.288s 0.001s
im_detect: 187/4024 0.288s 0.001s
im_detect: 188/4024 0.288s 0.001s
im_detect: 189/4024 0.288s 0.001s
im_detect: 190/4024 0.288s 0.001s
im_detect: 191/4024 0.288s 0.001s
im_detect: 192/4024 0.288s 0.001s
im_detect: 193/4024 0.288s 0.001s
im_detect: 194/4024 0.288s 0.001s
im_detect: 195/4024 0.288s 0.001s
im_detect: 196/4024 0.288s 0.001s
im_detect: 197/4024 0.288s 0.001s
im_detect: 198/4024 0.288s 0.001s
im_detect: 199/4024 0.288s 0.001s
im_detect: 200/4024 0.288s 0.001s
im_detect: 201/4024 0.288s 0.001s
im_detect: 202/4024 0.288s 0.001s
im_detect: 203/4024 0.288s 0.001s
im_detect: 204/4024 0.288s 0.001s
im_detect: 205/4024 0.288s 0.001s
im_detect: 206/4024 0.288s 0.001s
im_detect: 207/4024 0.288s 0.001s
im_detect: 208/4024 0.288s 0.001s
im_detect: 209/4024 0.288s 0.001s
im_detect: 210/4024 0.288s 0.001s
im_detect: 211/4024 0.288s 0.001s
im_detect: 212/4024 0.288s 0.001s
im_detect: 213/4024 0.288s 0.001s
im_detect: 214/4024 0.288s 0.001s
im_detect: 215/4024 0.288s 0.001s
im_detect: 216/4024 0.288s 0.001s
im_detect: 217/4024 0.288s 0.001s
im_detect: 218/4024 0.288s 0.001s
im_detect: 219/4024 0.288s 0.001s
im_detect: 220/4024 0.288s 0.001s
im_detect: 221/4024 0.288s 0.001s
im_detect: 222/4024 0.288s 0.001s
im_detect: 223/4024 0.288s 0.001s
im_detect: 224/4024 0.288s 0.001s
im_detect: 225/4024 0.288s 0.001s
im_detect: 226/4024 0.288s 0.001s
im_detect: 227/4024 0.288s 0.001s
im_detect: 228/4024 0.288s 0.001s
im_detect: 229/4024 0.288s 0.001s
im_detect: 230/4024 0.288s 0.001s
im_detect: 231/4024 0.288s 0.001s
im_detect: 232/4024 0.288s 0.001s
im_detect: 233/4024 0.288s 0.001s
im_detect: 234/4024 0.288s 0.001s
im_detect: 235/4024 0.288s 0.001s
im_detect: 236/4024 0.288s 0.001s
im_detect: 237/4024 0.288s 0.001s
im_detect: 238/4024 0.288s 0.001s
im_detect: 239/4024 0.288s 0.001s
im_detect: 240/4024 0.288s 0.001s
im_detect: 241/4024 0.288s 0.001s
im_detect: 242/4024 0.288s 0.001s
im_detect: 243/4024 0.288s 0.001s
im_detect: 244/4024 0.288s 0.001s
im_detect: 245/4024 0.288s 0.001s
im_detect: 246/4024 0.288s 0.001s
im_detect: 247/4024 0.288s 0.001s
im_detect: 248/4024 0.288s 0.001s
im_detect: 249/4024 0.288s 0.001s
im_detect: 250/4024 0.288s 0.001s
im_detect: 251/4024 0.288s 0.001s
im_detect: 252/4024 0.288s 0.001s
im_detect: 253/4024 0.288s 0.001s
im_detect: 254/4024 0.288s 0.001s
im_detect: 255/4024 0.288s 0.001s
im_detect: 256/4024 0.288s 0.001s
im_detect: 257/4024 0.288s 0.001s
im_detect: 258/4024 0.288s 0.001s
im_detect: 259/4024 0.288s 0.001s
im_detect: 260/4024 0.288s 0.001s
im_detect: 261/4024 0.288s 0.001s
im_detect: 262/4024 0.288s 0.001s
im_detect: 263/4024 0.288s 0.001s
im_detect: 264/4024 0.288s 0.001s
im_detect: 265/4024 0.288s 0.001s
im_detect: 266/4024 0.288s 0.001s
im_detect: 267/4024 0.288s 0.001s
im_detect: 268/4024 0.288s 0.001s
im_detect: 269/4024 0.288s 0.001s
im_detect: 270/4024 0.288s 0.001s
im_detect: 271/4024 0.288s 0.001s
im_detect: 272/4024 0.288s 0.001s
im_detect: 273/4024 0.288s 0.001s
im_detect: 274/4024 0.288s 0.001s
im_detect: 275/4024 0.288s 0.001s
im_detect: 276/4024 0.288s 0.001s
im_detect: 277/4024 0.288s 0.001s
im_detect: 278/4024 0.288s 0.001s
im_detect: 279/4024 0.288s 0.001s
im_detect: 280/4024 0.288s 0.001s
im_detect: 281/4024 0.288s 0.001s
im_detect: 282/4024 0.288s 0.001s
im_detect: 283/4024 0.288s 0.001s
im_detect: 284/4024 0.288s 0.001s
im_detect: 285/4024 0.288s 0.001s
im_detect: 286/4024 0.288s 0.001s
im_detect: 287/4024 0.288s 0.001s
im_detect: 288/4024 0.288s 0.001s
im_detect: 289/4024 0.288s 0.001s
im_detect: 290/4024 0.288s 0.001s
im_detect: 291/4024 0.288s 0.001s
im_detect: 292/4024 0.288s 0.001s
im_detect: 293/4024 0.288s 0.001s
im_detect: 294/4024 0.288s 0.001s
im_detect: 295/4024 0.288s 0.001s
im_detect: 296/4024 0.288s 0.001s
im_detect: 297/4024 0.288s 0.001s
im_detect: 298/4024 0.288s 0.001s
im_detect: 299/4024 0.288s 0.001s
im_detect: 300/4024 0.288s 0.001s
im_detect: 301/4024 0.288s 0.001s
im_detect: 302/4024 0.288s 0.001s
im_detect: 303/4024 0.288s 0.001s
im_detect: 304/4024 0.288s 0.001s
im_detect: 305/4024 0.288s 0.001s
im_detect: 306/4024 0.288s 0.001s
im_detect: 307/4024 0.288s 0.001s
im_detect: 308/4024 0.288s 0.001s
im_detect: 309/4024 0.288s 0.001s
im_detect: 310/4024 0.288s 0.001s
im_detect: 311/4024 0.288s 0.001s
im_detect: 312/4024 0.288s 0.001s
im_detect: 313/4024 0.288s 0.001s
im_detect: 314/4024 0.288s 0.001s
im_detect: 315/4024 0.288s 0.001s
im_detect: 316/4024 0.288s 0.001s
im_detect: 317/4024 0.288s 0.001s
im_detect: 318/4024 0.288s 0.001s
im_detect: 319/4024 0.288s 0.001s
im_detect: 320/4024 0.288s 0.001s
im_detect: 321/4024 0.288s 0.001s
im_detect: 322/4024 0.288s 0.001s
im_detect: 323/4024 0.288s 0.001s
im_detect: 324/4024 0.288s 0.001s
im_detect: 325/4024 0.288s 0.001s
im_detect: 326/4024 0.288s 0.001s
im_detect: 327/4024 0.288s 0.001s
im_detect: 328/4024 0.288s 0.001s
im_detect: 329/4024 0.288s 0.001s
im_detect: 330/4024 0.288s 0.001s
im_detect: 331/4024 0.288s 0.001s
im_detect: 332/4024 0.288s 0.001s
im_detect: 333/4024 0.288s 0.001s
im_detect: 334/4024 0.288s 0.001s
im_detect: 335/4024 0.288s 0.001s
im_detect: 336/4024 0.288s 0.001s
im_detect: 337/4024 0.288s 0.001s
im_detect: 338/4024 0.288s 0.001s
im_detect: 339/4024 0.288s 0.001s
im_detect: 340/4024 0.288s 0.001s
im_detect: 341/4024 0.288s 0.001s
im_detect: 342/4024 0.288s 0.001s
im_detect: 343/4024 0.288s 0.001s
im_detect: 344/4024 0.288s 0.001s
im_detect: 345/4024 0.288s 0.001s
im_detect: 346/4024 0.288s 0.001s
im_detect: 347/4024 0.288s 0.001s
im_detect: 348/4024 0.288s 0.001s
im_detect: 349/4024 0.288s 0.001s
im_detect: 350/4024 0.288s 0.001s
im_detect: 351/4024 0.288s 0.001s
im_detect: 352/4024 0.288s 0.001s
im_detect: 353/4024 0.288s 0.001s
im_detect: 354/4024 0.288s 0.001s
im_detect: 355/4024 0.288s 0.001s
im_detect: 356/4024 0.288s 0.001s
im_detect: 357/4024 0.288s 0.001s
im_detect: 358/4024 0.288s 0.001s
im_detect: 359/4024 0.288s 0.001s
im_detect: 360/4024 0.288s 0.001s
im_detect: 361/4024 0.288s 0.001s
im_detect: 362/4024 0.288s 0.001s
im_detect: 363/4024 0.288s 0.001s
im_detect: 364/4024 0.288s 0.001s
im_detect: 365/4024 0.288s 0.001s
im_detect: 366/4024 0.288s 0.001s
im_detect: 367/4024 0.288s 0.001s
im_detect: 368/4024 0.288s 0.001s
im_detect: 369/4024 0.288s 0.001s
im_detect: 370/4024 0.288s 0.001s
im_detect: 371/4024 0.288s 0.001s
im_detect: 372/4024 0.288s 0.001s
im_detect: 373/4024 0.288s 0.001s
im_detect: 374/4024 0.288s 0.001s
im_detect: 375/4024 0.288s 0.001s
im_detect: 376/4024 0.288s 0.001s
im_detect: 377/4024 0.288s 0.001s
im_detect: 378/4024 0.288s 0.001s
im_detect: 379/4024 0.288s 0.001s
im_detect: 380/4024 0.288s 0.001s
im_detect: 381/4024 0.288s 0.001s
im_detect: 382/4024 0.288s 0.001s
im_detect: 383/4024 0.288s 0.001s
im_detect: 384/4024 0.288s 0.001s
im_detect: 385/4024 0.288s 0.001s
im_detect: 386/4024 0.288s 0.001s
im_detect: 387/4024 0.288s 0.001s
im_detect: 388/4024 0.288s 0.001s
im_detect: 389/4024 0.288s 0.001s
im_detect: 390/4024 0.288s 0.001s
im_detect: 391/4024 0.288s 0.001s
im_detect: 392/4024 0.288s 0.001s
im_detect: 393/4024 0.288s 0.001s
im_detect: 394/4024 0.288s 0.001s
im_detect: 395/4024 0.288s 0.001s
im_detect: 396/4024 0.288s 0.001s
im_detect: 397/4024 0.288s 0.001s
im_detect: 398/4024 0.288s 0.001s
im_detect: 399/4024 0.288s 0.001s
im_detect: 400/4024 0.288s 0.001s
im_detect: 401/4024 0.288s 0.001s
im_detect: 402/4024 0.288s 0.001s
im_detect: 403/4024 0.288s 0.001s
im_detect: 404/4024 0.288s 0.001s
im_detect: 405/4024 0.288s 0.001s
im_detect: 406/4024 0.288s 0.001s
im_detect: 407/4024 0.288s 0.001s
im_detect: 408/4024 0.288s 0.001s
im_detect: 409/4024 0.288s 0.001s
im_detect: 410/4024 0.288s 0.001s
im_detect: 411/4024 0.288s 0.001s
im_detect: 412/4024 0.288s 0.001s
im_detect: 413/4024 0.288s 0.001s
im_detect: 414/4024 0.288s 0.001s
im_detect: 415/4024 0.288s 0.001s
im_detect: 416/4024 0.288s 0.001s
im_detect: 417/4024 0.288s 0.001s
im_detect: 418/4024 0.288s 0.001s
im_detect: 419/4024 0.288s 0.001s
im_detect: 420/4024 0.288s 0.001s
im_detect: 421/4024 0.288s 0.001s
im_detect: 422/4024 0.288s 0.001s
im_detect: 423/4024 0.288s 0.001s
im_detect: 424/4024 0.288s 0.001s
im_detect: 425/4024 0.288s 0.001s
im_detect: 426/4024 0.288s 0.001s
im_detect: 427/4024 0.288s 0.001s
im_detect: 428/4024 0.288s 0.001s
im_detect: 429/4024 0.288s 0.001s
im_detect: 430/4024 0.288s 0.001s
im_detect: 431/4024 0.288s 0.001s
im_detect: 432/4024 0.288s 0.001s
im_detect: 433/4024 0.288s 0.001s
im_detect: 434/4024 0.288s 0.001s
im_detect: 435/4024 0.288s 0.001s
im_detect: 436/4024 0.288s 0.001s
im_detect: 437/4024 0.288s 0.001s
im_detect: 438/4024 0.288s 0.001s
im_detect: 439/4024 0.288s 0.001s
im_detect: 440/4024 0.288s 0.001s
im_detect: 441/4024 0.288s 0.001s
im_detect: 442/4024 0.288s 0.001s
im_detect: 443/4024 0.288s 0.001s
im_detect: 444/4024 0.288s 0.001s
im_detect: 445/4024 0.288s 0.001s
im_detect: 446/4024 0.288s 0.001s
im_detect: 447/4024 0.288s 0.001s
im_detect: 448/4024 0.288s 0.001s
im_detect: 449/4024 0.288s 0.001s
im_detect: 450/4024 0.288s 0.001s
im_detect: 451/4024 0.288s 0.001s
im_detect: 452/4024 0.288s 0.001s
im_detect: 453/4024 0.288s 0.001s
im_detect: 454/4024 0.288s 0.001s
im_detect: 455/4024 0.288s 0.001s
im_detect: 456/4024 0.288s 0.001s
im_detect: 457/4024 0.288s 0.001s
im_detect: 458/4024 0.288s 0.001s
im_detect: 459/4024 0.288s 0.001s
im_detect: 460/4024 0.288s 0.001s
im_detect: 461/4024 0.288s 0.001s
im_detect: 462/4024 0.288s 0.001s
im_detect: 463/4024 0.288s 0.001s
im_detect: 464/4024 0.288s 0.001s
im_detect: 465/4024 0.288s 0.001s
im_detect: 466/4024 0.288s 0.001s
im_detect: 467/4024 0.288s 0.001s
im_detect: 468/4024 0.288s 0.001s
im_detect: 469/4024 0.288s 0.001s
im_detect: 470/4024 0.288s 0.001s
im_detect: 471/4024 0.288s 0.001s
im_detect: 472/4024 0.288s 0.001s
im_detect: 473/4024 0.288s 0.001s
im_detect: 474/4024 0.288s 0.001s
im_detect: 475/4024 0.288s 0.001s
im_detect: 476/4024 0.288s 0.001s
im_detect: 477/4024 0.288s 0.001s
im_detect: 478/4024 0.288s 0.001s
im_detect: 479/4024 0.288s 0.001s
im_detect: 480/4024 0.288s 0.001s
im_detect: 481/4024 0.288s 0.001s
im_detect: 482/4024 0.288s 0.001s
im_detect: 483/4024 0.288s 0.001s
im_detect: 484/4024 0.288s 0.001s
im_detect: 485/4024 0.288s 0.001s
im_detect: 486/4024 0.288s 0.001s
im_detect: 487/4024 0.288s 0.001s
im_detect: 488/4024 0.288s 0.001s
im_detect: 489/4024 0.288s 0.001s
im_detect: 490/4024 0.288s 0.001s
im_detect: 491/4024 0.288s 0.001s
im_detect: 492/4024 0.288s 0.001s
im_detect: 493/4024 0.288s 0.001s
im_detect: 494/4024 0.288s 0.001s
im_detect: 495/4024 0.288s 0.001s
im_detect: 496/4024 0.288s 0.001s
im_detect: 497/4024 0.288s 0.001s
im_detect: 498/4024 0.288s 0.001s
im_detect: 499/4024 0.288s 0.001s
im_detect: 500/4024 0.288s 0.001s
im_detect: 501/4024 0.288s 0.001s
im_detect: 502/4024 0.288s 0.001s
im_detect: 503/4024 0.288s 0.001s
im_detect: 504/4024 0.288s 0.001s
im_detect: 505/4024 0.288s 0.001s
im_detect: 506/4024 0.288s 0.001s
im_detect: 507/4024 0.288s 0.001s
im_detect: 508/4024 0.288s 0.001s
im_detect: 509/4024 0.288s 0.001s
im_detect: 510/4024 0.288s 0.001s
im_detect: 511/4024 0.288s 0.001s
im_detect: 512/4024 0.288s 0.001s
im_detect: 513/4024 0.288s 0.001s
im_detect: 514/4024 0.288s 0.001s
im_detect: 515/4024 0.288s 0.001s
im_detect: 516/4024 0.288s 0.001s
im_detect: 517/4024 0.288s 0.001s
im_detect: 518/4024 0.288s 0.001s
im_detect: 519/4024 0.288s 0.001s
im_detect: 520/4024 0.288s 0.001s
im_detect: 521/4024 0.288s 0.001s
im_detect: 522/4024 0.288s 0.001s
im_detect: 523/4024 0.288s 0.001s
im_detect: 524/4024 0.288s 0.001s
im_detect: 525/4024 0.288s 0.001s
im_detect: 526/4024 0.288s 0.001s
im_detect: 527/4024 0.288s 0.001s
im_detect: 528/4024 0.288s 0.001s
im_detect: 529/4024 0.288s 0.001s
im_detect: 530/4024 0.288s 0.001s
im_detect: 531/4024 0.288s 0.001s
im_detect: 532/4024 0.288s 0.001s
im_detect: 533/4024 0.288s 0.001s
im_detect: 534/4024 0.288s 0.001s
im_detect: 535/4024 0.288s 0.001s
im_detect: 536/4024 0.288s 0.001s
im_detect: 537/4024 0.288s 0.001s
im_detect: 538/4024 0.288s 0.001s
im_detect: 539/4024 0.288s 0.001s
im_detect: 540/4024 0.288s 0.001s
im_detect: 541/4024 0.288s 0.001s
im_detect: 542/4024 0.288s 0.001s
im_detect: 543/4024 0.288s 0.001s
im_detect: 544/4024 0.288s 0.001s
im_detect: 545/4024 0.288s 0.001s
im_detect: 546/4024 0.288s 0.001s
im_detect: 547/4024 0.288s 0.001s
im_detect: 548/4024 0.288s 0.001s
im_detect: 549/4024 0.288s 0.001s
im_detect: 550/4024 0.288s 0.001s
im_detect: 551/4024 0.288s 0.001s
im_detect: 552/4024 0.288s 0.001s
im_detect: 553/4024 0.288s 0.001s
im_detect: 554/4024 0.288s 0.001s
im_detect: 555/4024 0.288s 0.001s
im_detect: 556/4024 0.288s 0.001s
im_detect: 557/4024 0.288s 0.001s
im_detect: 558/4024 0.288s 0.001s
im_detect: 559/4024 0.288s 0.001s
im_detect: 560/4024 0.288s 0.001s
im_detect: 561/4024 0.288s 0.001s
im_detect: 562/4024 0.288s 0.001s
im_detect: 563/4024 0.288s 0.001s
im_detect: 564/4024 0.288s 0.001s
im_detect: 565/4024 0.288s 0.001s
im_detect: 566/4024 0.288s 0.001s
im_detect: 567/4024 0.288s 0.001s
im_detect: 568/4024 0.288s 0.001s
im_detect: 569/4024 0.288s 0.001s
im_detect: 570/4024 0.288s 0.001s
im_detect: 571/4024 0.288s 0.001s
im_detect: 572/4024 0.288s 0.001s
im_detect: 573/4024 0.288s 0.001s
im_detect: 574/4024 0.288s 0.001s
im_detect: 575/4024 0.288s 0.001s
im_detect: 576/4024 0.288s 0.001s
im_detect: 577/4024 0.288s 0.001s
im_detect: 578/4024 0.288s 0.001s
im_detect: 579/4024 0.288s 0.001s
im_detect: 580/4024 0.288s 0.001s
im_detect: 581/4024 0.288s 0.001s
im_detect: 582/4024 0.288s 0.001s
im_detect: 583/4024 0.288s 0.001s
im_detect: 584/4024 0.288s 0.001s
im_detect: 585/4024 0.288s 0.001s
im_detect: 586/4024 0.288s 0.001s
im_detect: 587/4024 0.288s 0.001s
im_detect: 588/4024 0.288s 0.001s
im_detect: 589/4024 0.288s 0.001s
im_detect: 590/4024 0.288s 0.001s
im_detect: 591/4024 0.288s 0.001s
im_detect: 592/4024 0.288s 0.001s
im_detect: 593/4024 0.288s 0.001s
im_detect: 594/4024 0.288s 0.001s
im_detect: 595/4024 0.288s 0.001s
im_detect: 596/4024 0.288s 0.001s
im_detect: 597/4024 0.288s 0.001s
im_detect: 598/4024 0.288s 0.001s
im_detect: 599/4024 0.288s 0.001s
im_detect: 600/4024 0.288s 0.001s
im_detect: 601/4024 0.288s 0.001s
im_detect: 602/4024 0.288s 0.001s
im_detect: 603/4024 0.288s 0.001s
im_detect: 604/4024 0.288s 0.001s
im_detect: 605/4024 0.288s 0.001s
im_detect: 606/4024 0.288s 0.001s
im_detect: 607/4024 0.288s 0.001s
im_detect: 608/4024 0.288s 0.001s
im_detect: 609/4024 0.288s 0.001s
im_detect: 610/4024 0.288s 0.001s
im_detect: 611/4024 0.288s 0.001s
im_detect: 612/4024 0.288s 0.001s
im_detect: 613/4024 0.288s 0.001s
im_detect: 614/4024 0.288s 0.001s
im_detect: 615/4024 0.288s 0.001s
im_detect: 616/4024 0.288s 0.001s
im_detect: 617/4024 0.288s 0.001s
im_detect: 618/4024 0.288s 0.001s
im_detect: 619/4024 0.288s 0.001s
im_detect: 620/4024 0.288s 0.001s
im_detect: 621/4024 0.288s 0.001s
im_detect: 622/4024 0.288s 0.001s
im_detect: 623/4024 0.288s 0.001s
im_detect: 624/4024 0.288s 0.001s
im_detect: 625/4024 0.288s 0.001s
im_detect: 626/4024 0.288s 0.001s
im_detect: 627/4024 0.288s 0.001s
im_detect: 628/4024 0.288s 0.001s
im_detect: 629/4024 0.288s 0.001s
im_detect: 630/4024 0.288s 0.001s
im_detect: 631/4024 0.288s 0.001s
im_detect: 632/4024 0.288s 0.001s
im_detect: 633/4024 0.288s 0.001s
im_detect: 634/4024 0.288s 0.001s
im_detect: 635/4024 0.288s 0.001s
im_detect: 636/4024 0.288s 0.001s
im_detect: 637/4024 0.288s 0.001s
im_detect: 638/4024 0.288s 0.001s
im_detect: 639/4024 0.288s 0.001s
im_detect: 640/4024 0.288s 0.001s
im_detect: 641/4024 0.288s 0.001s
im_detect: 642/4024 0.288s 0.001s
im_detect: 643/4024 0.288s 0.001s
im_detect: 644/4024 0.288s 0.001s
im_detect: 645/4024 0.288s 0.001s
im_detect: 646/4024 0.288s 0.001s
im_detect: 647/4024 0.288s 0.001s
im_detect: 648/4024 0.288s 0.001s
im_detect: 649/4024 0.288s 0.001s
im_detect: 650/4024 0.288s 0.001s
im_detect: 651/4024 0.288s 0.001s
im_detect: 652/4024 0.288s 0.001s
im_detect: 653/4024 0.288s 0.001s
im_detect: 654/4024 0.288s 0.001s
im_detect: 655/4024 0.288s 0.001s
im_detect: 656/4024 0.288s 0.001s
im_detect: 657/4024 0.288s 0.001s
im_detect: 658/4024 0.288s 0.001s
im_detect: 659/4024 0.288s 0.001s
im_detect: 660/4024 0.288s 0.001s
im_detect: 661/4024 0.288s 0.001s
im_detect: 662/4024 0.288s 0.001s
im_detect: 663/4024 0.288s 0.001s
im_detect: 664/4024 0.288s 0.001s
im_detect: 665/4024 0.288s 0.001s
im_detect: 666/4024 0.288s 0.001s
im_detect: 667/4024 0.288s 0.001s
im_detect: 668/4024 0.288s 0.001s
im_detect: 669/4024 0.288s 0.001s
im_detect: 670/4024 0.288s 0.001s
im_detect: 671/4024 0.288s 0.001s
im_detect: 672/4024 0.288s 0.001s
im_detect: 673/4024 0.288s 0.001s
im_detect: 674/4024 0.288s 0.001s
im_detect: 675/4024 0.288s 0.001s
im_detect: 676/4024 0.288s 0.001s
im_detect: 677/4024 0.288s 0.001s
im_detect: 678/4024 0.288s 0.001s
im_detect: 679/4024 0.288s 0.001s
im_detect: 680/4024 0.288s 0.001s
im_detect: 681/4024 0.288s 0.001s
im_detect: 682/4024 0.288s 0.001s
im_detect: 683/4024 0.288s 0.001s
im_detect: 684/4024 0.288s 0.001s
im_detect: 685/4024 0.288s 0.001s
im_detect: 686/4024 0.288s 0.001s
im_detect: 687/4024 0.288s 0.001s
im_detect: 688/4024 0.288s 0.001s
im_detect: 689/4024 0.288s 0.001s
im_detect: 690/4024 0.288s 0.001s
im_detect: 691/4024 0.288s 0.001s
im_detect: 692/4024 0.288s 0.001s
im_detect: 693/4024 0.288s 0.001s
im_detect: 694/4024 0.288s 0.001s
im_detect: 695/4024 0.288s 0.001s
im_detect: 696/4024 0.288s 0.001s
im_detect: 697/4024 0.288s 0.001s
im_detect: 698/4024 0.288s 0.001s
im_detect: 699/4024 0.288s 0.001s
im_detect: 700/4024 0.288s 0.001s
im_detect: 701/4024 0.288s 0.001s
im_detect: 702/4024 0.288s 0.001s
im_detect: 703/4024 0.288s 0.001s
im_detect: 704/4024 0.288s 0.001s
im_detect: 705/4024 0.288s 0.001s
im_detect: 706/4024 0.288s 0.001s
im_detect: 707/4024 0.288s 0.001s
im_detect: 708/4024 0.288s 0.001s
im_detect: 709/4024 0.288s 0.001s
im_detect: 710/4024 0.288s 0.001s
im_detect: 711/4024 0.288s 0.001s
im_detect: 712/4024 0.288s 0.001s
im_detect: 713/4024 0.288s 0.001s
im_detect: 714/4024 0.288s 0.001s
im_detect: 715/4024 0.288s 0.001s
im_detect: 716/4024 0.288s 0.001s
im_detect: 717/4024 0.288s 0.001s
im_detect: 718/4024 0.288s 0.001s
im_detect: 719/4024 0.288s 0.001s
im_detect: 720/4024 0.288s 0.001s
im_detect: 721/4024 0.288s 0.001s
im_detect: 722/4024 0.288s 0.001s
im_detect: 723/4024 0.288s 0.001s
im_detect: 724/4024 0.288s 0.001s
im_detect: 725/4024 0.288s 0.001s
im_detect: 726/4024 0.288s 0.001s
im_detect: 727/4024 0.288s 0.001s
im_detect: 728/4024 0.288s 0.001s
im_detect: 729/4024 0.288s 0.001s
im_detect: 730/4024 0.288s 0.001s
im_detect: 731/4024 0.288s 0.001s
im_detect: 732/4024 0.288s 0.001s
im_detect: 733/4024 0.288s 0.001s
im_detect: 734/4024 0.288s 0.001s
im_detect: 735/4024 0.288s 0.001s
im_detect: 736/4024 0.288s 0.001s
im_detect: 737/4024 0.288s 0.001s
im_detect: 738/4024 0.288s 0.001s
im_detect: 739/4024 0.288s 0.001s
im_detect: 740/4024 0.288s 0.001s
im_detect: 741/4024 0.288s 0.001s
im_detect: 742/4024 0.288s 0.001s
im_detect: 743/4024 0.288s 0.001s
im_detect: 744/4024 0.288s 0.001s
im_detect: 745/4024 0.288s 0.001s
im_detect: 746/4024 0.288s 0.001s
im_detect: 747/4024 0.288s 0.001s
im_detect: 748/4024 0.288s 0.001s
im_detect: 749/4024 0.288s 0.001s
im_detect: 750/4024 0.288s 0.001s
im_detect: 751/4024 0.288s 0.001s
im_detect: 752/4024 0.288s 0.001s
im_detect: 753/4024 0.288s 0.001s
im_detect: 754/4024 0.288s 0.001s
im_detect: 755/4024 0.288s 0.001s
im_detect: 756/4024 0.288s 0.001s
im_detect: 757/4024 0.288s 0.001s
im_detect: 758/4024 0.288s 0.001s
im_detect: 759/4024 0.288s 0.001s
im_detect: 760/4024 0.288s 0.001s
im_detect: 761/4024 0.288s 0.001s
im_detect: 762/4024 0.288s 0.001s
im_detect: 763/4024 0.288s 0.001s
im_detect: 764/4024 0.288s 0.001s
im_detect: 765/4024 0.288s 0.001s
im_detect: 766/4024 0.288s 0.001s
im_detect: 767/4024 0.288s 0.001s
im_detect: 768/4024 0.288s 0.001s
im_detect: 769/4024 0.288s 0.001s
im_detect: 770/4024 0.288s 0.001s
im_detect: 771/4024 0.288s 0.001s
im_detect: 772/4024 0.288s 0.001s
im_detect: 773/4024 0.288s 0.001s
im_detect: 774/4024 0.288s 0.001s
im_detect: 775/4024 0.288s 0.001s
im_detect: 776/4024 0.288s 0.001s
im_detect: 777/4024 0.288s 0.001s
im_detect: 778/4024 0.288s 0.001s
im_detect: 779/4024 0.288s 0.001s
im_detect: 780/4024 0.288s 0.001s
im_detect: 781/4024 0.288s 0.001s
im_detect: 782/4024 0.288s 0.001s
im_detect: 783/4024 0.288s 0.001s
im_detect: 784/4024 0.288s 0.001s
im_detect: 785/4024 0.288s 0.001s
im_detect: 786/4024 0.288s 0.001s
im_detect: 787/4024 0.288s 0.001s
im_detect: 788/4024 0.288s 0.001s
im_detect: 789/4024 0.288s 0.001s
im_detect: 790/4024 0.288s 0.001s
im_detect: 791/4024 0.288s 0.001s
im_detect: 792/4024 0.288s 0.001s
im_detect: 793/4024 0.288s 0.001s
im_detect: 794/4024 0.288s 0.001s
im_detect: 795/4024 0.288s 0.001s
im_detect: 796/4024 0.288s 0.001s
im_detect: 797/4024 0.288s 0.001s
im_detect: 798/4024 0.288s 0.001s
im_detect: 799/4024 0.288s 0.001s
im_detect: 800/4024 0.288s 0.001s
im_detect: 801/4024 0.288s 0.001s
im_detect: 802/4024 0.288s 0.001s
im_detect: 803/4024 0.288s 0.001s
im_detect: 804/4024 0.288s 0.001s
im_detect: 805/4024 0.288s 0.001s
im_detect: 806/4024 0.288s 0.001s
im_detect: 807/4024 0.288s 0.001s
im_detect: 808/4024 0.288s 0.001s
im_detect: 809/4024 0.288s 0.001s
im_detect: 810/4024 0.288s 0.001s
im_detect: 811/4024 0.288s 0.001s
im_detect: 812/4024 0.288s 0.001s
im_detect: 813/4024 0.288s 0.001s
im_detect: 814/4024 0.288s 0.001s
im_detect: 815/4024 0.288s 0.001s
im_detect: 816/4024 0.288s 0.001s
im_detect: 817/4024 0.288s 0.001s
im_detect: 818/4024 0.288s 0.001s
im_detect: 819/4024 0.288s 0.001s
im_detect: 820/4024 0.288s 0.001s
im_detect: 821/4024 0.288s 0.001s
im_detect: 822/4024 0.288s 0.001s
im_detect: 823/4024 0.288s 0.001s
im_detect: 824/4024 0.288s 0.001s
im_detect: 825/4024 0.288s 0.001s
im_detect: 826/4024 0.288s 0.001s
im_detect: 827/4024 0.288s 0.001s
im_detect: 828/4024 0.288s 0.001s
im_detect: 829/4024 0.288s 0.001s
im_detect: 830/4024 0.288s 0.001s
im_detect: 831/4024 0.288s 0.001s
im_detect: 832/4024 0.288s 0.001s
im_detect: 833/4024 0.288s 0.001s
im_detect: 834/4024 0.288s 0.001s
im_detect: 835/4024 0.288s 0.001s
im_detect: 836/4024 0.288s 0.001s
im_detect: 837/4024 0.288s 0.001s
im_detect: 838/4024 0.288s 0.001s
im_detect: 839/4024 0.288s 0.001s
im_detect: 840/4024 0.288s 0.001s
im_detect: 841/4024 0.288s 0.001s
im_detect: 842/4024 0.288s 0.001s
im_detect: 843/4024 0.288s 0.001s
im_detect: 844/4024 0.288s 0.001s
im_detect: 845/4024 0.288s 0.001s
im_detect: 846/4024 0.288s 0.001s
im_detect: 847/4024 0.288s 0.001s
im_detect: 848/4024 0.288s 0.001s
im_detect: 849/4024 0.288s 0.001s
im_detect: 850/4024 0.288s 0.001s
im_detect: 851/4024 0.288s 0.001s
im_detect: 852/4024 0.288s 0.001s
im_detect: 853/4024 0.288s 0.001s
im_detect: 854/4024 0.288s 0.001s
im_detect: 855/4024 0.288s 0.001s
im_detect: 856/4024 0.288s 0.001s
im_detect: 857/4024 0.288s 0.001s
im_detect: 858/4024 0.288s 0.001s
im_detect: 859/4024 0.288s 0.001s
im_detect: 860/4024 0.288s 0.001s
im_detect: 861/4024 0.288s 0.001s
im_detect: 862/4024 0.288s 0.001s
im_detect: 863/4024 0.288s 0.001s
im_detect: 864/4024 0.288s 0.001s
im_detect: 865/4024 0.288s 0.001s
im_detect: 866/4024 0.288s 0.001s
im_detect: 867/4024 0.288s 0.001s
im_detect: 868/4024 0.288s 0.001s
im_detect: 869/4024 0.288s 0.001s
im_detect: 870/4024 0.288s 0.001s
im_detect: 871/4024 0.288s 0.001s
im_detect: 872/4024 0.288s 0.001s
im_detect: 873/4024 0.288s 0.001s
im_detect: 874/4024 0.288s 0.001s
im_detect: 875/4024 0.288s 0.001s
im_detect: 876/4024 0.288s 0.001s
im_detect: 877/4024 0.288s 0.001s
im_detect: 878/4024 0.288s 0.001s
im_detect: 879/4024 0.288s 0.001s
im_detect: 880/4024 0.288s 0.001s
im_detect: 881/4024 0.288s 0.001s
im_detect: 882/4024 0.288s 0.001s
im_detect: 883/4024 0.288s 0.001s
im_detect: 884/4024 0.288s 0.001s
im_detect: 885/4024 0.288s 0.001s
im_detect: 886/4024 0.288s 0.001s
im_detect: 887/4024 0.288s 0.001s
im_detect: 888/4024 0.288s 0.001s
im_detect: 889/4024 0.288s 0.001s
im_detect: 890/4024 0.288s 0.001s
im_detect: 891/4024 0.288s 0.001s
im_detect: 892/4024 0.288s 0.001s
im_detect: 893/4024 0.288s 0.001s
im_detect: 894/4024 0.288s 0.001s
im_detect: 895/4024 0.288s 0.001s
im_detect: 896/4024 0.288s 0.001s
im_detect: 897/4024 0.288s 0.001s
im_detect: 898/4024 0.288s 0.001s
im_detect: 899/4024 0.288s 0.001s
im_detect: 900/4024 0.288s 0.001s
im_detect: 901/4024 0.288s 0.001s
im_detect: 902/4024 0.288s 0.001s
im_detect: 903/4024 0.288s 0.001s
im_detect: 904/4024 0.288s 0.001s
im_detect: 905/4024 0.288s 0.001s
im_detect: 906/4024 0.288s 0.001s
im_detect: 907/4024 0.288s 0.001s
im_detect: 908/4024 0.288s 0.001s
im_detect: 909/4024 0.288s 0.001s
im_detect: 910/4024 0.288s 0.001s
im_detect: 911/4024 0.288s 0.001s
im_detect: 912/4024 0.288s 0.001s
im_detect: 913/4024 0.288s 0.001s
im_detect: 914/4024 0.288s 0.001s
im_detect: 915/4024 0.288s 0.001s
im_detect: 916/4024 0.288s 0.001s
im_detect: 917/4024 0.288s 0.001s
im_detect: 918/4024 0.288s 0.001s
im_detect: 919/4024 0.288s 0.001s
im_detect: 920/4024 0.288s 0.001s
im_detect: 921/4024 0.288s 0.001s
im_detect: 922/4024 0.288s 0.001s
im_detect: 923/4024 0.288s 0.001s
im_detect: 924/4024 0.288s 0.001s
im_detect: 925/4024 0.288s 0.001s
im_detect: 926/4024 0.288s 0.001s
im_detect: 927/4024 0.288s 0.001s
im_detect: 928/4024 0.288s 0.001s
im_detect: 929/4024 0.288s 0.001s
im_detect: 930/4024 0.288s 0.001s
im_detect: 931/4024 0.288s 0.001s
im_detect: 932/4024 0.288s 0.001s
im_detect: 933/4024 0.288s 0.001s
im_detect: 934/4024 0.288s 0.001s
im_detect: 935/4024 0.288s 0.001s
im_detect: 936/4024 0.288s 0.001s
im_detect: 937/4024 0.288s 0.001s
im_detect: 938/4024 0.288s 0.001s
im_detect: 939/4024 0.288s 0.001s
im_detect: 940/4024 0.288s 0.001s
im_detect: 941/4024 0.288s 0.001s
im_detect: 942/4024 0.288s 0.001s
im_detect: 943/4024 0.288s 0.001s
im_detect: 944/4024 0.288s 0.001s
im_detect: 945/4024 0.288s 0.001s
im_detect: 946/4024 0.288s 0.001s
im_detect: 947/4024 0.288s 0.001s
im_detect: 948/4024 0.288s 0.001s
im_detect: 949/4024 0.288s 0.001s
im_detect: 950/4024 0.288s 0.001s
im_detect: 951/4024 0.288s 0.001s
im_detect: 952/4024 0.288s 0.001s
im_detect: 953/4024 0.288s 0.001s
im_detect: 954/4024 0.288s 0.001s
im_detect: 955/4024 0.288s 0.001s
im_detect: 956/4024 0.288s 0.001s
im_detect: 957/4024 0.288s 0.001s
im_detect: 958/4024 0.288s 0.001s
im_detect: 959/4024 0.288s 0.001s
im_detect: 960/4024 0.288s 0.001s
im_detect: 961/4024 0.288s 0.001s
im_detect: 962/4024 0.288s 0.001s
im_detect: 963/4024 0.288s 0.001s
im_detect: 964/4024 0.288s 0.001s
im_detect: 965/4024 0.288s 0.001s
im_detect: 966/4024 0.288s 0.001s
im_detect: 967/4024 0.288s 0.001s
im_detect: 968/4024 0.288s 0.001s
im_detect: 969/4024 0.288s 0.001s
im_detect: 970/4024 0.288s 0.001s
im_detect: 971/4024 0.288s 0.001s
im_detect: 972/4024 0.288s 0.001s
im_detect: 973/4024 0.288s 0.001s
im_detect: 974/4024 0.288s 0.001s
im_detect: 975/4024 0.288s 0.001s
im_detect: 976/4024 0.288s 0.001s
im_detect: 977/4024 0.288s 0.001s
im_detect: 978/4024 0.288s 0.001s
im_detect: 979/4024 0.288s 0.001s
im_detect: 980/4024 0.288s 0.001s
im_detect: 981/4024 0.288s 0.001s
im_detect: 982/4024 0.288s 0.001s
im_detect: 983/4024 0.288s 0.001s
im_detect: 984/4024 0.288s 0.001s
im_detect: 985/4024 0.288s 0.001s
im_detect: 986/4024 0.288s 0.001s
im_detect: 987/4024 0.288s 0.001s
im_detect: 988/4024 0.288s 0.001s
im_detect: 989/4024 0.288s 0.001s
im_detect: 990/4024 0.288s 0.001s
im_detect: 991/4024 0.288s 0.001s
im_detect: 992/4024 0.288s 0.001s
im_detect: 993/4024 0.288s 0.001s
im_detect: 994/4024 0.288s 0.001s
im_detect: 995/4024 0.288s 0.001s
im_detect: 996/4024 0.288s 0.001s
im_detect: 997/4024 0.288s 0.001s
im_detect: 998/4024 0.288s 0.001s
im_detect: 999/4024 0.288s 0.001s
im_detect: 1000/4024 0.288s 0.001s
im_detect: 1001/4024 0.288s 0.001s
im_detect: 1002/4024 0.288s 0.001s
im_detect: 1003/4024 0.288s 0.001s
im_detect: 1004/4024 0.288s 0.001s
im_detect: 1005/4024 0.288s 0.001s
im_detect: 1006/4024 0.288s 0.001s
im_detect: 1007/4024 0.288s 0.001s
im_detect: 1008/4024 0.288s 0.001s
im_detect: 1009/4024 0.288s 0.001s
im_detect: 1010/4024 0.288s 0.001s
im_detect: 1011/4024 0.288s 0.001s
im_detect: 1012/4024 0.288s 0.001s
im_detect: 1013/4024 0.288s 0.001s
im_detect: 1014/4024 0.288s 0.001s
im_detect: 1015/4024 0.288s 0.001s
im_detect: 1016/4024 0.288s 0.001s
im_detect: 1017/4024 0.288s 0.001s
im_detect: 1018/4024 0.288s 0.001s
im_detect: 1019/4024 0.288s 0.001s
im_detect: 1020/4024 0.288s 0.001s
im_detect: 1021/4024 0.288s 0.001s
im_detect: 1022/4024 0.288s 0.001s
im_detect: 1023/4024 0.288s 0.001s
im_detect: 1024/4024 0.288s 0.001s
im_detect: 1025/4024 0.288s 0.001s
im_detect: 1026/4024 0.288s 0.001s
im_detect: 1027/4024 0.288s 0.001s
im_detect: 1028/4024 0.288s 0.001s
im_detect: 1029/4024 0.288s 0.001s
im_detect: 1030/4024 0.288s 0.001s
im_detect: 1031/4024 0.288s 0.001s
im_detect: 1032/4024 0.288s 0.001s
im_detect: 1033/4024 0.288s 0.001s
im_detect: 1034/4024 0.288s 0.001s
im_detect: 1035/4024 0.288s 0.001s
im_detect: 1036/4024 0.288s 0.001s
im_detect: 1037/4024 0.288s 0.001s
im_detect: 1038/4024 0.288s 0.001s
im_detect: 1039/4024 0.288s 0.001s
im_detect: 1040/4024 0.288s 0.001s
im_detect: 1041/4024 0.288s 0.001s
im_detect: 1042/4024 0.288s 0.001s
im_detect: 1043/4024 0.288s 0.001s
im_detect: 1044/4024 0.288s 0.001s
im_detect: 1045/4024 0.288s 0.001s
im_detect: 1046/4024 0.288s 0.001s
im_detect: 1047/4024 0.288s 0.001s
im_detect: 1048/4024 0.288s 0.001s
im_detect: 1049/4024 0.288s 0.001s
im_detect: 1050/4024 0.288s 0.001s
im_detect: 1051/4024 0.288s 0.001s
im_detect: 1052/4024 0.288s 0.001s
im_detect: 1053/4024 0.288s 0.001s
im_detect: 1054/4024 0.288s 0.001s
im_detect: 1055/4024 0.288s 0.001s
im_detect: 1056/4024 0.288s 0.001s
im_detect: 1057/4024 0.288s 0.001s
im_detect: 1058/4024 0.288s 0.001s
im_detect: 1059/4024 0.288s 0.001s
im_detect: 1060/4024 0.288s 0.001s
im_detect: 1061/4024 0.288s 0.001s
im_detect: 1062/4024 0.288s 0.001s
im_detect: 1063/4024 0.288s 0.001s
im_detect: 1064/4024 0.288s 0.001s
im_detect: 1065/4024 0.288s 0.001s
im_detect: 1066/4024 0.288s 0.001s
im_detect: 1067/4024 0.288s 0.001s
im_detect: 1068/4024 0.288s 0.001s
im_detect: 1069/4024 0.288s 0.001s
im_detect: 1070/4024 0.288s 0.001s
im_detect: 1071/4024 0.288s 0.001s
im_detect: 1072/4024 0.288s 0.001s
im_detect: 1073/4024 0.288s 0.001s
im_detect: 1074/4024 0.288s 0.001s
im_detect: 1075/4024 0.288s 0.001s
im_detect: 1076/4024 0.288s 0.001s
im_detect: 1077/4024 0.288s 0.001s
im_detect: 1078/4024 0.288s 0.001s
im_detect: 1079/4024 0.288s 0.001s
im_detect: 1080/4024 0.288s 0.001s
im_detect: 1081/4024 0.288s 0.001s
im_detect: 1082/4024 0.288s 0.001s
im_detect: 1083/4024 0.288s 0.001s
im_detect: 1084/4024 0.288s 0.001s
im_detect: 1085/4024 0.288s 0.001s
im_detect: 1086/4024 0.288s 0.001s
im_detect: 1087/4024 0.288s 0.001s
im_detect: 1088/4024 0.288s 0.001s
im_detect: 1089/4024 0.288s 0.001s
im_detect: 1090/4024 0.288s 0.001s
im_detect: 1091/4024 0.288s 0.001s
im_detect: 1092/4024 0.288s 0.001s
im_detect: 1093/4024 0.288s 0.001s
im_detect: 1094/4024 0.288s 0.001s
im_detect: 1095/4024 0.288s 0.001s
im_detect: 1096/4024 0.288s 0.001s
im_detect: 1097/4024 0.288s 0.001s
im_detect: 1098/4024 0.288s 0.001s
im_detect: 1099/4024 0.288s 0.001s
im_detect: 1100/4024 0.288s 0.001s
im_detect: 1101/4024 0.288s 0.001s
im_detect: 1102/4024 0.288s 0.001s
im_detect: 1103/4024 0.288s 0.001s
im_detect: 1104/4024 0.288s 0.001s
im_detect: 1105/4024 0.288s 0.001s
im_detect: 1106/4024 0.288s 0.001s
im_detect: 1107/4024 0.288s 0.001s
im_detect: 1108/4024 0.288s 0.001s
im_detect: 1109/4024 0.288s 0.001s
im_detect: 1110/4024 0.288s 0.001s
im_detect: 1111/4024 0.288s 0.001s
im_detect: 1112/4024 0.288s 0.001s
im_detect: 1113/4024 0.288s 0.001s
im_detect: 1114/4024 0.288s 0.001s
im_detect: 1115/4024 0.288s 0.001s
im_detect: 1116/4024 0.288s 0.001s
im_detect: 1117/4024 0.288s 0.001s
im_detect: 1118/4024 0.288s 0.001s
im_detect: 1119/4024 0.288s 0.001s
im_detect: 1120/4024 0.288s 0.001s
im_detect: 1121/4024 0.288s 0.001s
im_detect: 1122/4024 0.288s 0.001s
im_detect: 1123/4024 0.288s 0.001s
im_detect: 1124/4024 0.288s 0.001s
im_detect: 1125/4024 0.288s 0.001s
im_detect: 1126/4024 0.288s 0.001s
im_detect: 1127/4024 0.288s 0.001s
im_detect: 1128/4024 0.288s 0.001s
im_detect: 1129/4024 0.288s 0.001s
im_detect: 1130/4024 0.288s 0.001s
im_detect: 1131/4024 0.288s 0.001s
im_detect: 1132/4024 0.288s 0.001s
im_detect: 1133/4024 0.288s 0.001s
im_detect: 1134/4024 0.288s 0.001s
im_detect: 1135/4024 0.288s 0.001s
im_detect: 1136/4024 0.288s 0.001s
im_detect: 1137/4024 0.288s 0.001s
im_detect: 1138/4024 0.288s 0.001s
im_detect: 1139/4024 0.288s 0.001s
im_detect: 1140/4024 0.288s 0.001s
im_detect: 1141/4024 0.288s 0.001s
im_detect: 1142/4024 0.288s 0.001s
im_detect: 1143/4024 0.288s 0.001s
im_detect: 1144/4024 0.288s 0.001s
im_detect: 1145/4024 0.288s 0.001s
im_detect: 1146/4024 0.288s 0.001s
im_detect: 1147/4024 0.288s 0.001s
im_detect: 1148/4024 0.288s 0.001s
im_detect: 1149/4024 0.288s 0.001s
im_detect: 1150/4024 0.288s 0.001s
im_detect: 1151/4024 0.288s 0.001s
im_detect: 1152/4024 0.288s 0.001s
im_detect: 1153/4024 0.288s 0.001s
im_detect: 1154/4024 0.288s 0.001s
im_detect: 1155/4024 0.288s 0.001s
im_detect: 1156/4024 0.288s 0.001s
im_detect: 1157/4024 0.288s 0.001s
im_detect: 1158/4024 0.288s 0.001s
im_detect: 1159/4024 0.288s 0.001s
im_detect: 1160/4024 0.288s 0.001s
im_detect: 1161/4024 0.288s 0.001s
im_detect: 1162/4024 0.288s 0.001s
im_detect: 1163/4024 0.288s 0.001s
im_detect: 1164/4024 0.288s 0.001s
im_detect: 1165/4024 0.288s 0.001s
im_detect: 1166/4024 0.288s 0.001s
im_detect: 1167/4024 0.288s 0.001s
im_detect: 1168/4024 0.288s 0.001s
im_detect: 1169/4024 0.288s 0.001s
im_detect: 1170/4024 0.288s 0.001s
im_detect: 1171/4024 0.288s 0.001s
im_detect: 1172/4024 0.288s 0.001s
im_detect: 1173/4024 0.288s 0.001s
im_detect: 1174/4024 0.288s 0.001s
im_detect: 1175/4024 0.288s 0.001s
im_detect: 1176/4024 0.288s 0.001s
im_detect: 1177/4024 0.288s 0.001s
im_detect: 1178/4024 0.288s 0.001s
im_detect: 1179/4024 0.288s 0.001s
im_detect: 1180/4024 0.288s 0.001s
im_detect: 1181/4024 0.288s 0.001s
im_detect: 1182/4024 0.288s 0.001s
im_detect: 1183/4024 0.288s 0.001s
im_detect: 1184/4024 0.288s 0.001s
im_detect: 1185/4024 0.288s 0.001s
im_detect: 1186/4024 0.288s 0.001s
im_detect: 1187/4024 0.288s 0.001s
im_detect: 1188/4024 0.288s 0.001s
im_detect: 1189/4024 0.288s 0.001s
im_detect: 1190/4024 0.288s 0.001s
im_detect: 1191/4024 0.288s 0.001s
im_detect: 1192/4024 0.288s 0.001s
im_detect: 1193/4024 0.288s 0.001s
im_detect: 1194/4024 0.288s 0.001s
im_detect: 1195/4024 0.288s 0.001s
im_detect: 1196/4024 0.288s 0.001s
im_detect: 1197/4024 0.288s 0.001s
im_detect: 1198/4024 0.288s 0.001s
im_detect: 1199/4024 0.288s 0.001s
im_detect: 1200/4024 0.288s 0.001s
im_detect: 1201/4024 0.288s 0.001s
im_detect: 1202/4024 0.288s 0.001s
im_detect: 1203/4024 0.288s 0.001s
im_detect: 1204/4024 0.288s 0.001s
im_detect: 1205/4024 0.288s 0.001s
im_detect: 1206/4024 0.288s 0.001s
im_detect: 1207/4024 0.288s 0.001s
im_detect: 1208/4024 0.288s 0.001s
im_detect: 1209/4024 0.288s 0.001s
im_detect: 1210/4024 0.288s 0.001s
im_detect: 1211/4024 0.288s 0.001s
im_detect: 1212/4024 0.288s 0.001s
im_detect: 1213/4024 0.288s 0.001s
im_detect: 1214/4024 0.288s 0.001s
im_detect: 1215/4024 0.288s 0.001s
im_detect: 1216/4024 0.288s 0.001s
im_detect: 1217/4024 0.288s 0.001s
im_detect: 1218/4024 0.288s 0.001s
im_detect: 1219/4024 0.288s 0.001s
im_detect: 1220/4024 0.288s 0.001s
im_detect: 1221/4024 0.288s 0.001s
im_detect: 1222/4024 0.288s 0.001s
im_detect: 1223/4024 0.288s 0.001s
im_detect: 1224/4024 0.288s 0.001s
im_detect: 1225/4024 0.288s 0.001s
im_detect: 1226/4024 0.288s 0.001s
im_detect: 1227/4024 0.288s 0.001s
im_detect: 1228/4024 0.288s 0.001s
im_detect: 1229/4024 0.288s 0.001s
im_detect: 1230/4024 0.288s 0.001s
im_detect: 1231/4024 0.288s 0.001s
im_detect: 1232/4024 0.288s 0.001s
im_detect: 1233/4024 0.288s 0.001s
im_detect: 1234/4024 0.288s 0.001s
im_detect: 1235/4024 0.288s 0.001s
im_detect: 1236/4024 0.288s 0.001s
im_detect: 1237/4024 0.288s 0.001s
im_detect: 1238/4024 0.288s 0.001s
im_detect: 1239/4024 0.288s 0.001s
im_detect: 1240/4024 0.288s 0.001s
im_detect: 1241/4024 0.288s 0.001s
im_detect: 1242/4024 0.288s 0.001s
im_detect: 1243/4024 0.288s 0.001s
im_detect: 1244/4024 0.288s 0.001s
im_detect: 1245/4024 0.288s 0.001s
im_detect: 1246/4024 0.288s 0.001s
im_detect: 1247/4024 0.288s 0.001s
im_detect: 1248/4024 0.288s 0.001s
im_detect: 1249/4024 0.288s 0.001s
im_detect: 1250/4024 0.288s 0.001s
im_detect: 1251/4024 0.288s 0.001s
im_detect: 1252/4024 0.288s 0.001s
im_detect: 1253/4024 0.288s 0.001s
im_detect: 1254/4024 0.288s 0.001s
im_detect: 1255/4024 0.288s 0.001s
im_detect: 1256/4024 0.288s 0.001s
im_detect: 1257/4024 0.288s 0.001s
im_detect: 1258/4024 0.288s 0.001s
im_detect: 1259/4024 0.288s 0.001s
im_detect: 1260/4024 0.288s 0.001s
im_detect: 1261/4024 0.288s 0.001s
im_detect: 1262/4024 0.288s 0.001s
im_detect: 1263/4024 0.288s 0.001s
im_detect: 1264/4024 0.288s 0.001s
im_detect: 1265/4024 0.288s 0.001s
im_detect: 1266/4024 0.288s 0.001s
im_detect: 1267/4024 0.288s 0.001s
im_detect: 1268/4024 0.288s 0.001s
im_detect: 1269/4024 0.288s 0.001s
im_detect: 1270/4024 0.288s 0.001s
im_detect: 1271/4024 0.288s 0.001s
im_detect: 1272/4024 0.288s 0.001s
im_detect: 1273/4024 0.288s 0.001s
im_detect: 1274/4024 0.288s 0.001s
im_detect: 1275/4024 0.288s 0.001s
im_detect: 1276/4024 0.288s 0.001s
im_detect: 1277/4024 0.288s 0.001s
im_detect: 1278/4024 0.288s 0.001s
im_detect: 1279/4024 0.288s 0.001s
im_detect: 1280/4024 0.288s 0.001s
im_detect: 1281/4024 0.288s 0.001s
im_detect: 1282/4024 0.288s 0.001s
im_detect: 1283/4024 0.288s 0.001s
im_detect: 1284/4024 0.288s 0.001s
im_detect: 1285/4024 0.288s 0.001s
im_detect: 1286/4024 0.288s 0.001s
im_detect: 1287/4024 0.288s 0.001s
im_detect: 1288/4024 0.288s 0.001s
im_detect: 1289/4024 0.288s 0.001s
im_detect: 1290/4024 0.288s 0.001s
im_detect: 1291/4024 0.288s 0.001s
im_detect: 1292/4024 0.288s 0.001s
im_detect: 1293/4024 0.288s 0.001s
im_detect: 1294/4024 0.288s 0.001s
im_detect: 1295/4024 0.288s 0.001s
im_detect: 1296/4024 0.288s 0.001s
im_detect: 1297/4024 0.288s 0.001s
im_detect: 1298/4024 0.288s 0.001s
im_detect: 1299/4024 0.288s 0.001s
im_detect: 1300/4024 0.288s 0.001s
im_detect: 1301/4024 0.288s 0.001s
im_detect: 1302/4024 0.288s 0.001s
im_detect: 1303/4024 0.288s 0.001s
im_detect: 1304/4024 0.288s 0.001s
im_detect: 1305/4024 0.288s 0.001s
im_detect: 1306/4024 0.288s 0.001s
im_detect: 1307/4024 0.288s 0.001s
im_detect: 1308/4024 0.288s 0.001s
im_detect: 1309/4024 0.288s 0.001s
im_detect: 1310/4024 0.288s 0.001s
im_detect: 1311/4024 0.288s 0.001s
im_detect: 1312/4024 0.288s 0.001s
im_detect: 1313/4024 0.288s 0.001s
im_detect: 1314/4024 0.288s 0.001s
im_detect: 1315/4024 0.288s 0.001s
im_detect: 1316/4024 0.288s 0.001s
im_detect: 1317/4024 0.288s 0.001s
im_detect: 1318/4024 0.288s 0.001s
im_detect: 1319/4024 0.288s 0.001s
im_detect: 1320/4024 0.288s 0.001s
im_detect: 1321/4024 0.288s 0.001s
im_detect: 1322/4024 0.288s 0.001s
im_detect: 1323/4024 0.288s 0.001s
im_detect: 1324/4024 0.288s 0.001s
im_detect: 1325/4024 0.288s 0.001s
im_detect: 1326/4024 0.288s 0.001s
im_detect: 1327/4024 0.288s 0.001s
im_detect: 1328/4024 0.288s 0.001s
im_detect: 1329/4024 0.288s 0.001s
im_detect: 1330/4024 0.288s 0.001s
im_detect: 1331/4024 0.288s 0.001s
im_detect: 1332/4024 0.288s 0.001s
im_detect: 1333/4024 0.288s 0.001s
im_detect: 1334/4024 0.288s 0.001s
im_detect: 1335/4024 0.288s 0.001s
im_detect: 1336/4024 0.288s 0.001s
im_detect: 1337/4024 0.288s 0.001s
im_detect: 1338/4024 0.288s 0.001s
im_detect: 1339/4024 0.288s 0.001s
im_detect: 1340/4024 0.288s 0.001s
im_detect: 1341/4024 0.288s 0.001s
im_detect: 1342/4024 0.288s 0.001s
im_detect: 1343/4024 0.288s 0.001s
im_detect: 1344/4024 0.288s 0.001s
im_detect: 1345/4024 0.288s 0.001s
im_detect: 1346/4024 0.288s 0.001s
im_detect: 1347/4024 0.288s 0.001s
im_detect: 1348/4024 0.288s 0.001s
im_detect: 1349/4024 0.288s 0.001s
im_detect: 1350/4024 0.288s 0.001s
im_detect: 1351/4024 0.288s 0.001s
im_detect: 1352/4024 0.288s 0.001s
im_detect: 1353/4024 0.288s 0.001s
im_detect: 1354/4024 0.288s 0.001s
im_detect: 1355/4024 0.288s 0.001s
im_detect: 1356/4024 0.288s 0.001s
im_detect: 1357/4024 0.288s 0.001s
im_detect: 1358/4024 0.288s 0.001s
im_detect: 1359/4024 0.288s 0.001s
im_detect: 1360/4024 0.288s 0.001s
im_detect: 1361/4024 0.288s 0.001s
im_detect: 1362/4024 0.288s 0.001s
im_detect: 1363/4024 0.288s 0.001s
im_detect: 1364/4024 0.288s 0.001s
im_detect: 1365/4024 0.288s 0.001s
im_detect: 1366/4024 0.288s 0.001s
im_detect: 1367/4024 0.288s 0.001s
im_detect: 1368/4024 0.288s 0.001s
im_detect: 1369/4024 0.288s 0.001s
im_detect: 1370/4024 0.288s 0.001s
im_detect: 1371/4024 0.288s 0.001s
im_detect: 1372/4024 0.288s 0.001s
im_detect: 1373/4024 0.288s 0.001s
im_detect: 1374/4024 0.288s 0.001s
im_detect: 1375/4024 0.288s 0.001s
im_detect: 1376/4024 0.288s 0.001s
im_detect: 1377/4024 0.288s 0.001s
im_detect: 1378/4024 0.288s 0.001s
im_detect: 1379/4024 0.288s 0.001s
im_detect: 1380/4024 0.288s 0.001s
im_detect: 1381/4024 0.288s 0.001s
im_detect: 1382/4024 0.288s 0.001s
im_detect: 1383/4024 0.288s 0.001s
im_detect: 1384/4024 0.288s 0.001s
im_detect: 1385/4024 0.288s 0.001s
im_detect: 1386/4024 0.288s 0.001s
im_detect: 1387/4024 0.288s 0.001s
im_detect: 1388/4024 0.288s 0.001s
im_detect: 1389/4024 0.288s 0.001s
im_detect: 1390/4024 0.288s 0.001s
im_detect: 1391/4024 0.288s 0.001s
im_detect: 1392/4024 0.288s 0.001s
im_detect: 1393/4024 0.288s 0.001s
im_detect: 1394/4024 0.288s 0.001s
im_detect: 1395/4024 0.288s 0.001s
im_detect: 1396/4024 0.288s 0.001s
im_detect: 1397/4024 0.288s 0.001s
im_detect: 1398/4024 0.288s 0.001s
im_detect: 1399/4024 0.288s 0.001s
im_detect: 1400/4024 0.288s 0.001s
im_detect: 1401/4024 0.288s 0.001s
im_detect: 1402/4024 0.288s 0.001s
im_detect: 1403/4024 0.288s 0.001s
im_detect: 1404/4024 0.288s 0.001s
im_detect: 1405/4024 0.288s 0.001s
im_detect: 1406/4024 0.288s 0.001s
im_detect: 1407/4024 0.288s 0.001s
im_detect: 1408/4024 0.288s 0.001s
im_detect: 1409/4024 0.288s 0.001s
im_detect: 1410/4024 0.288s 0.001s
im_detect: 1411/4024 0.288s 0.001s
im_detect: 1412/4024 0.288s 0.001s
im_detect: 1413/4024 0.288s 0.001s
im_detect: 1414/4024 0.288s 0.001s
im_detect: 1415/4024 0.288s 0.001s
im_detect: 1416/4024 0.288s 0.001s
im_detect: 1417/4024 0.288s 0.001s
im_detect: 1418/4024 0.288s 0.001s
im_detect: 1419/4024 0.288s 0.001s
im_detect: 1420/4024 0.288s 0.001s
im_detect: 1421/4024 0.288s 0.001s
im_detect: 1422/4024 0.288s 0.001s
im_detect: 1423/4024 0.288s 0.001s
im_detect: 1424/4024 0.288s 0.001s
im_detect: 1425/4024 0.288s 0.001s
im_detect: 1426/4024 0.288s 0.001s
im_detect: 1427/4024 0.288s 0.001s
im_detect: 1428/4024 0.288s 0.001s
im_detect: 1429/4024 0.288s 0.001s
im_detect: 1430/4024 0.288s 0.001s
im_detect: 1431/4024 0.288s 0.001s
im_detect: 1432/4024 0.288s 0.001s
im_detect: 1433/4024 0.288s 0.001s
im_detect: 1434/4024 0.288s 0.001s
im_detect: 1435/4024 0.288s 0.001s
im_detect: 1436/4024 0.288s 0.001s
im_detect: 1437/4024 0.288s 0.001s
im_detect: 1438/4024 0.288s 0.001s
im_detect: 1439/4024 0.288s 0.001s
im_detect: 1440/4024 0.288s 0.001s
im_detect: 1441/4024 0.288s 0.001s
im_detect: 1442/4024 0.288s 0.001s
im_detect: 1443/4024 0.288s 0.001s
im_detect: 1444/4024 0.288s 0.001s
im_detect: 1445/4024 0.288s 0.001s
im_detect: 1446/4024 0.288s 0.001s
im_detect: 1447/4024 0.288s 0.001s
im_detect: 1448/4024 0.288s 0.001s
im_detect: 1449/4024 0.288s 0.001s
im_detect: 1450/4024 0.288s 0.001s
im_detect: 1451/4024 0.288s 0.001s
im_detect: 1452/4024 0.288s 0.001s
im_detect: 1453/4024 0.288s 0.001s
im_detect: 1454/4024 0.288s 0.001s
im_detect: 1455/4024 0.288s 0.001s
im_detect: 1456/4024 0.288s 0.001s
im_detect: 1457/4024 0.288s 0.001s
im_detect: 1458/4024 0.288s 0.001s
im_detect: 1459/4024 0.288s 0.001s
im_detect: 1460/4024 0.288s 0.001s
im_detect: 1461/4024 0.288s 0.001s
im_detect: 1462/4024 0.288s 0.001s
im_detect: 1463/4024 0.288s 0.001s
im_detect: 1464/4024 0.288s 0.001s
im_detect: 1465/4024 0.288s 0.001s
im_detect: 1466/4024 0.288s 0.001s
im_detect: 1467/4024 0.288s 0.001s
im_detect: 1468/4024 0.288s 0.001s
im_detect: 1469/4024 0.288s 0.001s
im_detect: 1470/4024 0.288s 0.001s
im_detect: 1471/4024 0.288s 0.001s
im_detect: 1472/4024 0.288s 0.001s
im_detect: 1473/4024 0.288s 0.001s
im_detect: 1474/4024 0.288s 0.001s
im_detect: 1475/4024 0.288s 0.001s
im_detect: 1476/4024 0.288s 0.001s
im_detect: 1477/4024 0.288s 0.001s
im_detect: 1478/4024 0.288s 0.001s
im_detect: 1479/4024 0.288s 0.001s
im_detect: 1480/4024 0.288s 0.001s
im_detect: 1481/4024 0.288s 0.001s
im_detect: 1482/4024 0.288s 0.001s
im_detect: 1483/4024 0.288s 0.001s
im_detect: 1484/4024 0.288s 0.001s
im_detect: 1485/4024 0.288s 0.001s
im_detect: 1486/4024 0.288s 0.001s
im_detect: 1487/4024 0.288s 0.001s
im_detect: 1488/4024 0.288s 0.001s
im_detect: 1489/4024 0.288s 0.001s
im_detect: 1490/4024 0.288s 0.001s
im_detect: 1491/4024 0.288s 0.001s
im_detect: 1492/4024 0.288s 0.001s
im_detect: 1493/4024 0.288s 0.001s
im_detect: 1494/4024 0.288s 0.001s
im_detect: 1495/4024 0.288s 0.001s
im_detect: 1496/4024 0.288s 0.001s
im_detect: 1497/4024 0.288s 0.001s
im_detect: 1498/4024 0.288s 0.001s
im_detect: 1499/4024 0.288s 0.001s
im_detect: 1500/4024 0.288s 0.001s
im_detect: 1501/4024 0.288s 0.001s
im_detect: 1502/4024 0.288s 0.001s
im_detect: 1503/4024 0.288s 0.001s
im_detect: 1504/4024 0.288s 0.001s
im_detect: 1505/4024 0.288s 0.001s
im_detect: 1506/4024 0.288s 0.001s
im_detect: 1507/4024 0.288s 0.001s
im_detect: 1508/4024 0.288s 0.001s
im_detect: 1509/4024 0.288s 0.001s
im_detect: 1510/4024 0.288s 0.001s
im_detect: 1511/4024 0.288s 0.001s
im_detect: 1512/4024 0.288s 0.001s
im_detect: 1513/4024 0.288s 0.001s
im_detect: 1514/4024 0.288s 0.001s
im_detect: 1515/4024 0.288s 0.001s
im_detect: 1516/4024 0.288s 0.001s
im_detect: 1517/4024 0.288s 0.001s
im_detect: 1518/4024 0.288s 0.001s
im_detect: 1519/4024 0.288s 0.001s
im_detect: 1520/4024 0.288s 0.001s
im_detect: 1521/4024 0.288s 0.001s
im_detect: 1522/4024 0.288s 0.001s
im_detect: 1523/4024 0.288s 0.001s
im_detect: 1524/4024 0.288s 0.001s
im_detect: 1525/4024 0.288s 0.001s
im_detect: 1526/4024 0.288s 0.001s
im_detect: 1527/4024 0.288s 0.001s
im_detect: 1528/4024 0.288s 0.001s
im_detect: 1529/4024 0.288s 0.001s
im_detect: 1530/4024 0.288s 0.001s
im_detect: 1531/4024 0.288s 0.001s
im_detect: 1532/4024 0.288s 0.001s
im_detect: 1533/4024 0.288s 0.001s
im_detect: 1534/4024 0.288s 0.001s
im_detect: 1535/4024 0.288s 0.001s
im_detect: 1536/4024 0.288s 0.001s
im_detect: 1537/4024 0.288s 0.001s
im_detect: 1538/4024 0.288s 0.001s
im_detect: 1539/4024 0.288s 0.001s
im_detect: 1540/4024 0.288s 0.001s
im_detect: 1541/4024 0.288s 0.001s
im_detect: 1542/4024 0.288s 0.001s
im_detect: 1543/4024 0.288s 0.001s
im_detect: 1544/4024 0.288s 0.001s
im_detect: 1545/4024 0.288s 0.001s
im_detect: 1546/4024 0.288s 0.001s
im_detect: 1547/4024 0.288s 0.001s
im_detect: 1548/4024 0.288s 0.001s
im_detect: 1549/4024 0.288s 0.001s
im_detect: 1550/4024 0.288s 0.001s
im_detect: 1551/4024 0.288s 0.001s
im_detect: 1552/4024 0.288s 0.001s
im_detect: 1553/4024 0.288s 0.001s
im_detect: 1554/4024 0.288s 0.001s
im_detect: 1555/4024 0.288s 0.001s
im_detect: 1556/4024 0.288s 0.001s
im_detect: 1557/4024 0.288s 0.001s
im_detect: 1558/4024 0.288s 0.001s
im_detect: 1559/4024 0.288s 0.001s
im_detect: 1560/4024 0.288s 0.001s
im_detect: 1561/4024 0.288s 0.001s
im_detect: 1562/4024 0.288s 0.001s
im_detect: 1563/4024 0.288s 0.001s
im_detect: 1564/4024 0.288s 0.001s
im_detect: 1565/4024 0.288s 0.001s
im_detect: 1566/4024 0.288s 0.001s
im_detect: 1567/4024 0.288s 0.001s
im_detect: 1568/4024 0.288s 0.001s
im_detect: 1569/4024 0.288s 0.001s
im_detect: 1570/4024 0.288s 0.001s
im_detect: 1571/4024 0.288s 0.001s
im_detect: 1572/4024 0.288s 0.001s
im_detect: 1573/4024 0.288s 0.001s
im_detect: 1574/4024 0.288s 0.001s
im_detect: 1575/4024 0.288s 0.001s
im_detect: 1576/4024 0.288s 0.001s
im_detect: 1577/4024 0.288s 0.001s
im_detect: 1578/4024 0.288s 0.001s
im_detect: 1579/4024 0.288s 0.001s
im_detect: 1580/4024 0.288s 0.001s
im_detect: 1581/4024 0.288s 0.001s
im_detect: 1582/4024 0.288s 0.001s
im_detect: 1583/4024 0.288s 0.001s
im_detect: 1584/4024 0.288s 0.001s
im_detect: 1585/4024 0.288s 0.001s
im_detect: 1586/4024 0.288s 0.001s
im_detect: 1587/4024 0.288s 0.001s
im_detect: 1588/4024 0.288s 0.001s
im_detect: 1589/4024 0.288s 0.001s
im_detect: 1590/4024 0.288s 0.001s
im_detect: 1591/4024 0.288s 0.001s
im_detect: 1592/4024 0.288s 0.001s
im_detect: 1593/4024 0.288s 0.001s
im_detect: 1594/4024 0.288s 0.001s
im_detect: 1595/4024 0.288s 0.001s
im_detect: 1596/4024 0.288s 0.001s
im_detect: 1597/4024 0.288s 0.001s
im_detect: 1598/4024 0.288s 0.001s
im_detect: 1599/4024 0.288s 0.001s
im_detect: 1600/4024 0.288s 0.001s
im_detect: 1601/4024 0.288s 0.001s
im_detect: 1602/4024 0.288s 0.001s
im_detect: 1603/4024 0.288s 0.001s
im_detect: 1604/4024 0.288s 0.001s
im_detect: 1605/4024 0.288s 0.001s
im_detect: 1606/4024 0.288s 0.001s
im_detect: 1607/4024 0.288s 0.001s
im_detect: 1608/4024 0.288s 0.001s
im_detect: 1609/4024 0.288s 0.001s
im_detect: 1610/4024 0.288s 0.001s
im_detect: 1611/4024 0.288s 0.001s
im_detect: 1612/4024 0.288s 0.001s
im_detect: 1613/4024 0.288s 0.001s
im_detect: 1614/4024 0.288s 0.001s
im_detect: 1615/4024 0.288s 0.001s
im_detect: 1616/4024 0.288s 0.001s
im_detect: 1617/4024 0.288s 0.001s
im_detect: 1618/4024 0.288s 0.001s
im_detect: 1619/4024 0.288s 0.001s
im_detect: 1620/4024 0.288s 0.001s
im_detect: 1621/4024 0.288s 0.001s
im_detect: 1622/4024 0.288s 0.001s
im_detect: 1623/4024 0.288s 0.001s
im_detect: 1624/4024 0.288s 0.001s
im_detect: 1625/4024 0.288s 0.001s
im_detect: 1626/4024 0.288s 0.001s
im_detect: 1627/4024 0.288s 0.001s
im_detect: 1628/4024 0.288s 0.001s
im_detect: 1629/4024 0.288s 0.001s
im_detect: 1630/4024 0.288s 0.001s
im_detect: 1631/4024 0.288s 0.001s
im_detect: 1632/4024 0.288s 0.001s
im_detect: 1633/4024 0.288s 0.001s
im_detect: 1634/4024 0.288s 0.001s
im_detect: 1635/4024 0.288s 0.001s
im_detect: 1636/4024 0.288s 0.001s
im_detect: 1637/4024 0.288s 0.001s
im_detect: 1638/4024 0.288s 0.001s
im_detect: 1639/4024 0.288s 0.001s
im_detect: 1640/4024 0.288s 0.001s
im_detect: 1641/4024 0.288s 0.001s
im_detect: 1642/4024 0.288s 0.001s
im_detect: 1643/4024 0.288s 0.001s
im_detect: 1644/4024 0.288s 0.001s
im_detect: 1645/4024 0.288s 0.001s
im_detect: 1646/4024 0.288s 0.001s
im_detect: 1647/4024 0.288s 0.001s
im_detect: 1648/4024 0.288s 0.001s
im_detect: 1649/4024 0.288s 0.001s
im_detect: 1650/4024 0.288s 0.001s
im_detect: 1651/4024 0.288s 0.001s
im_detect: 1652/4024 0.288s 0.001s
im_detect: 1653/4024 0.288s 0.001s
im_detect: 1654/4024 0.288s 0.001s
im_detect: 1655/4024 0.288s 0.001s
im_detect: 1656/4024 0.288s 0.001s
im_detect: 1657/4024 0.288s 0.001s
im_detect: 1658/4024 0.288s 0.001s
im_detect: 1659/4024 0.288s 0.001s
im_detect: 1660/4024 0.288s 0.001s
im_detect: 1661/4024 0.288s 0.001s
im_detect: 1662/4024 0.288s 0.001s
im_detect: 1663/4024 0.288s 0.001s
im_detect: 1664/4024 0.288s 0.001s
im_detect: 1665/4024 0.288s 0.001s
im_detect: 1666/4024 0.288s 0.001s
im_detect: 1667/4024 0.288s 0.001s
im_detect: 1668/4024 0.288s 0.001s
im_detect: 1669/4024 0.288s 0.001s
im_detect: 1670/4024 0.288s 0.001s
im_detect: 1671/4024 0.288s 0.001s
im_detect: 1672/4024 0.288s 0.001s
im_detect: 1673/4024 0.288s 0.001s
im_detect: 1674/4024 0.288s 0.001s
im_detect: 1675/4024 0.288s 0.001s
im_detect: 1676/4024 0.288s 0.001s
im_detect: 1677/4024 0.288s 0.001s
im_detect: 1678/4024 0.288s 0.001s
im_detect: 1679/4024 0.288s 0.001s
im_detect: 1680/4024 0.288s 0.001s
im_detect: 1681/4024 0.288s 0.001s
im_detect: 1682/4024 0.288s 0.001s
im_detect: 1683/4024 0.288s 0.001s
im_detect: 1684/4024 0.288s 0.001s
im_detect: 1685/4024 0.288s 0.001s
im_detect: 1686/4024 0.288s 0.001s
im_detect: 1687/4024 0.288s 0.001s
im_detect: 1688/4024 0.288s 0.001s
im_detect: 1689/4024 0.288s 0.001s
im_detect: 1690/4024 0.288s 0.001s
im_detect: 1691/4024 0.288s 0.001s
im_detect: 1692/4024 0.288s 0.001s
im_detect: 1693/4024 0.288s 0.001s
im_detect: 1694/4024 0.288s 0.001s
im_detect: 1695/4024 0.288s 0.001s
im_detect: 1696/4024 0.288s 0.001s
im_detect: 1697/4024 0.288s 0.001s
im_detect: 1698/4024 0.288s 0.001s
im_detect: 1699/4024 0.288s 0.001s
im_detect: 1700/4024 0.288s 0.001s
im_detect: 1701/4024 0.288s 0.001s
im_detect: 1702/4024 0.288s 0.001s
im_detect: 1703/4024 0.288s 0.001s
im_detect: 1704/4024 0.288s 0.001s
im_detect: 1705/4024 0.288s 0.001s
im_detect: 1706/4024 0.288s 0.001s
im_detect: 1707/4024 0.288s 0.001s
im_detect: 1708/4024 0.288s 0.001s
im_detect: 1709/4024 0.288s 0.001s
im_detect: 1710/4024 0.288s 0.001s
im_detect: 1711/4024 0.288s 0.001s
im_detect: 1712/4024 0.288s 0.001s
im_detect: 1713/4024 0.288s 0.001s
im_detect: 1714/4024 0.288s 0.001s
im_detect: 1715/4024 0.288s 0.001s
im_detect: 1716/4024 0.288s 0.001s
im_detect: 1717/4024 0.288s 0.001s
im_detect: 1718/4024 0.288s 0.001s
im_detect: 1719/4024 0.288s 0.001s
im_detect: 1720/4024 0.288s 0.001s
im_detect: 1721/4024 0.288s 0.001s
im_detect: 1722/4024 0.288s 0.001s
im_detect: 1723/4024 0.288s 0.001s
im_detect: 1724/4024 0.288s 0.001s
im_detect: 1725/4024 0.288s 0.001s
im_detect: 1726/4024 0.288s 0.001s
im_detect: 1727/4024 0.288s 0.001s
im_detect: 1728/4024 0.288s 0.001s
im_detect: 1729/4024 0.288s 0.001s
im_detect: 1730/4024 0.288s 0.001s
im_detect: 1731/4024 0.288s 0.001s
im_detect: 1732/4024 0.288s 0.001s
im_detect: 1733/4024 0.288s 0.001s
im_detect: 1734/4024 0.288s 0.001s
im_detect: 1735/4024 0.288s 0.001s
im_detect: 1736/4024 0.288s 0.001s
im_detect: 1737/4024 0.288s 0.001s
im_detect: 1738/4024 0.288s 0.001s
im_detect: 1739/4024 0.288s 0.001s
im_detect: 1740/4024 0.288s 0.001s
im_detect: 1741/4024 0.288s 0.001s
im_detect: 1742/4024 0.288s 0.001s
im_detect: 1743/4024 0.288s 0.001s
im_detect: 1744/4024 0.288s 0.001s
im_detect: 1745/4024 0.288s 0.001s
im_detect: 1746/4024 0.288s 0.001s
im_detect: 1747/4024 0.288s 0.001s
im_detect: 1748/4024 0.288s 0.001s
im_detect: 1749/4024 0.288s 0.001s
im_detect: 1750/4024 0.288s 0.001s
im_detect: 1751/4024 0.288s 0.001s
im_detect: 1752/4024 0.288s 0.001s
im_detect: 1753/4024 0.288s 0.001s
im_detect: 1754/4024 0.288s 0.001s
im_detect: 1755/4024 0.288s 0.001s
im_detect: 1756/4024 0.288s 0.001s
im_detect: 1757/4024 0.288s 0.001s
im_detect: 1758/4024 0.288s 0.001s
im_detect: 1759/4024 0.288s 0.001s
im_detect: 1760/4024 0.288s 0.001s
im_detect: 1761/4024 0.288s 0.001s
im_detect: 1762/4024 0.288s 0.001s
im_detect: 1763/4024 0.288s 0.001s
im_detect: 1764/4024 0.288s 0.001s
im_detect: 1765/4024 0.288s 0.001s
im_detect: 1766/4024 0.288s 0.001s
im_detect: 1767/4024 0.288s 0.001s
im_detect: 1768/4024 0.288s 0.001s
im_detect: 1769/4024 0.288s 0.001s
im_detect: 1770/4024 0.288s 0.001s
im_detect: 1771/4024 0.288s 0.001s
im_detect: 1772/4024 0.288s 0.001s
im_detect: 1773/4024 0.288s 0.001s
im_detect: 1774/4024 0.288s 0.001s
im_detect: 1775/4024 0.288s 0.001s
im_detect: 1776/4024 0.288s 0.001s
im_detect: 1777/4024 0.288s 0.001s
im_detect: 1778/4024 0.288s 0.001s
im_detect: 1779/4024 0.288s 0.001s
im_detect: 1780/4024 0.288s 0.001s
im_detect: 1781/4024 0.288s 0.001s
im_detect: 1782/4024 0.288s 0.001s
im_detect: 1783/4024 0.288s 0.001s
im_detect: 1784/4024 0.288s 0.001s
im_detect: 1785/4024 0.288s 0.001s
im_detect: 1786/4024 0.288s 0.001s
im_detect: 1787/4024 0.288s 0.001s
im_detect: 1788/4024 0.288s 0.001s
im_detect: 1789/4024 0.288s 0.001s
im_detect: 1790/4024 0.288s 0.001s
im_detect: 1791/4024 0.288s 0.001s
im_detect: 1792/4024 0.288s 0.001s
im_detect: 1793/4024 0.288s 0.001s
im_detect: 1794/4024 0.288s 0.001s
im_detect: 1795/4024 0.288s 0.001s
im_detect: 1796/4024 0.288s 0.001s
im_detect: 1797/4024 0.288s 0.001s
im_detect: 1798/4024 0.288s 0.001s
im_detect: 1799/4024 0.288s 0.001s
im_detect: 1800/4024 0.288s 0.001s
im_detect: 1801/4024 0.288s 0.001s
im_detect: 1802/4024 0.288s 0.001s
im_detect: 1803/4024 0.288s 0.001s
im_detect: 1804/4024 0.288s 0.001s
im_detect: 1805/4024 0.288s 0.001s
im_detect: 1806/4024 0.288s 0.001s
im_detect: 1807/4024 0.288s 0.001s
im_detect: 1808/4024 0.288s 0.001s
im_detect: 1809/4024 0.288s 0.001s
im_detect: 1810/4024 0.288s 0.001s
im_detect: 1811/4024 0.288s 0.001s
im_detect: 1812/4024 0.288s 0.001s
im_detect: 1813/4024 0.288s 0.001s
im_detect: 1814/4024 0.288s 0.001s
im_detect: 1815/4024 0.288s 0.001s
im_detect: 1816/4024 0.288s 0.001s
im_detect: 1817/4024 0.288s 0.001s
im_detect: 1818/4024 0.288s 0.001s
im_detect: 1819/4024 0.288s 0.001s
im_detect: 1820/4024 0.288s 0.001s
im_detect: 1821/4024 0.288s 0.001s
im_detect: 1822/4024 0.288s 0.001s
im_detect: 1823/4024 0.288s 0.001s
im_detect: 1824/4024 0.288s 0.001s
im_detect: 1825/4024 0.288s 0.001s
im_detect: 1826/4024 0.288s 0.001s
im_detect: 1827/4024 0.288s 0.001s
im_detect: 1828/4024 0.288s 0.001s
im_detect: 1829/4024 0.288s 0.001s
im_detect: 1830/4024 0.288s 0.001s
im_detect: 1831/4024 0.288s 0.001s
im_detect: 1832/4024 0.288s 0.001s
im_detect: 1833/4024 0.288s 0.001s
im_detect: 1834/4024 0.288s 0.001s
im_detect: 1835/4024 0.288s 0.001s
im_detect: 1836/4024 0.288s 0.001s
im_detect: 1837/4024 0.288s 0.001s
im_detect: 1838/4024 0.288s 0.001s
im_detect: 1839/4024 0.288s 0.001s
im_detect: 1840/4024 0.288s 0.001s
im_detect: 1841/4024 0.288s 0.001s
im_detect: 1842/4024 0.288s 0.001s
im_detect: 1843/4024 0.288s 0.001s
im_detect: 1844/4024 0.288s 0.001s
im_detect: 1845/4024 0.288s 0.001s
im_detect: 1846/4024 0.288s 0.001s
im_detect: 1847/4024 0.288s 0.001s
im_detect: 1848/4024 0.288s 0.001s
im_detect: 1849/4024 0.288s 0.001s
im_detect: 1850/4024 0.288s 0.001s
im_detect: 1851/4024 0.288s 0.001s
im_detect: 1852/4024 0.288s 0.001s
im_detect: 1853/4024 0.288s 0.001s
im_detect: 1854/4024 0.288s 0.001s
im_detect: 1855/4024 0.288s 0.001s
im_detect: 1856/4024 0.288s 0.001s
im_detect: 1857/4024 0.288s 0.001s
im_detect: 1858/4024 0.288s 0.001s
im_detect: 1859/4024 0.288s 0.001s
im_detect: 1860/4024 0.288s 0.001s
im_detect: 1861/4024 0.288s 0.001s
im_detect: 1862/4024 0.288s 0.001s
im_detect: 1863/4024 0.288s 0.001s
im_detect: 1864/4024 0.288s 0.001s
im_detect: 1865/4024 0.288s 0.001s
im_detect: 1866/4024 0.288s 0.001s
im_detect: 1867/4024 0.288s 0.001s
im_detect: 1868/4024 0.288s 0.001s
im_detect: 1869/4024 0.288s 0.001s
im_detect: 1870/4024 0.288s 0.001s
im_detect: 1871/4024 0.288s 0.001s
im_detect: 1872/4024 0.288s 0.001s
im_detect: 1873/4024 0.288s 0.001s
im_detect: 1874/4024 0.288s 0.001s
im_detect: 1875/4024 0.288s 0.001s
im_detect: 1876/4024 0.288s 0.001s
im_detect: 1877/4024 0.288s 0.001s
im_detect: 1878/4024 0.288s 0.001s
im_detect: 1879/4024 0.288s 0.001s
im_detect: 1880/4024 0.288s 0.001s
im_detect: 1881/4024 0.288s 0.001s
im_detect: 1882/4024 0.288s 0.001s
im_detect: 1883/4024 0.288s 0.001s
im_detect: 1884/4024 0.288s 0.001s
im_detect: 1885/4024 0.288s 0.001s
im_detect: 1886/4024 0.288s 0.001s
im_detect: 1887/4024 0.288s 0.001s
im_detect: 1888/4024 0.288s 0.001s
im_detect: 1889/4024 0.288s 0.001s
im_detect: 1890/4024 0.288s 0.001s
im_detect: 1891/4024 0.288s 0.001s
im_detect: 1892/4024 0.288s 0.001s
im_detect: 1893/4024 0.288s 0.001s
im_detect: 1894/4024 0.288s 0.001s
im_detect: 1895/4024 0.288s 0.001s
im_detect: 1896/4024 0.288s 0.001s
im_detect: 1897/4024 0.288s 0.001s
im_detect: 1898/4024 0.288s 0.001s
im_detect: 1899/4024 0.288s 0.001s
im_detect: 1900/4024 0.288s 0.001s
im_detect: 1901/4024 0.288s 0.001s
im_detect: 1902/4024 0.288s 0.001s
im_detect: 1903/4024 0.288s 0.001s
im_detect: 1904/4024 0.288s 0.001s
im_detect: 1905/4024 0.288s 0.001s
im_detect: 1906/4024 0.288s 0.001s
im_detect: 1907/4024 0.288s 0.001s
im_detect: 1908/4024 0.288s 0.001s
im_detect: 1909/4024 0.288s 0.001s
im_detect: 1910/4024 0.288s 0.001s
im_detect: 1911/4024 0.288s 0.001s
im_detect: 1912/4024 0.288s 0.001s
im_detect: 1913/4024 0.288s 0.001s
im_detect: 1914/4024 0.288s 0.001s
im_detect: 1915/4024 0.288s 0.001s
im_detect: 1916/4024 0.288s 0.001s
im_detect: 1917/4024 0.288s 0.001s
im_detect: 1918/4024 0.288s 0.001s
im_detect: 1919/4024 0.288s 0.001s
im_detect: 1920/4024 0.288s 0.001s
im_detect: 1921/4024 0.288s 0.001s
im_detect: 1922/4024 0.288s 0.001s
im_detect: 1923/4024 0.288s 0.001s
im_detect: 1924/4024 0.288s 0.001s
im_detect: 1925/4024 0.288s 0.001s
im_detect: 1926/4024 0.288s 0.001s
im_detect: 1927/4024 0.288s 0.001s
im_detect: 1928/4024 0.288s 0.001s
im_detect: 1929/4024 0.288s 0.001s
im_detect: 1930/4024 0.288s 0.001s
im_detect: 1931/4024 0.288s 0.001s
im_detect: 1932/4024 0.288s 0.001s
im_detect: 1933/4024 0.288s 0.001s
im_detect: 1934/4024 0.288s 0.001s
im_detect: 1935/4024 0.288s 0.001s
im_detect: 1936/4024 0.288s 0.001s
im_detect: 1937/4024 0.288s 0.001s
im_detect: 1938/4024 0.288s 0.001s
im_detect: 1939/4024 0.288s 0.001s
im_detect: 1940/4024 0.288s 0.001s
im_detect: 1941/4024 0.288s 0.001s
im_detect: 1942/4024 0.288s 0.001s
im_detect: 1943/4024 0.288s 0.001s
im_detect: 1944/4024 0.288s 0.001s
im_detect: 1945/4024 0.288s 0.001s
im_detect: 1946/4024 0.288s 0.001s
im_detect: 1947/4024 0.288s 0.001s
im_detect: 1948/4024 0.288s 0.001s
im_detect: 1949/4024 0.288s 0.001s
im_detect: 1950/4024 0.288s 0.001s
im_detect: 1951/4024 0.288s 0.001s
im_detect: 1952/4024 0.288s 0.001s
im_detect: 1953/4024 0.288s 0.001s
im_detect: 1954/4024 0.288s 0.001s
im_detect: 1955/4024 0.288s 0.001s
im_detect: 1956/4024 0.288s 0.001s
im_detect: 1957/4024 0.288s 0.001s
im_detect: 1958/4024 0.288s 0.001s
im_detect: 1959/4024 0.288s 0.001s
im_detect: 1960/4024 0.288s 0.001s
im_detect: 1961/4024 0.288s 0.001s
im_detect: 1962/4024 0.288s 0.001s
im_detect: 1963/4024 0.288s 0.001s
im_detect: 1964/4024 0.288s 0.001s
im_detect: 1965/4024 0.288s 0.001s
im_detect: 1966/4024 0.288s 0.001s
im_detect: 1967/4024 0.288s 0.001s
im_detect: 1968/4024 0.288s 0.001s
im_detect: 1969/4024 0.288s 0.001s
im_detect: 1970/4024 0.288s 0.001s
im_detect: 1971/4024 0.288s 0.001s
im_detect: 1972/4024 0.288s 0.001s
im_detect: 1973/4024 0.288s 0.001s
im_detect: 1974/4024 0.288s 0.001s
im_detect: 1975/4024 0.288s 0.001s
im_detect: 1976/4024 0.288s 0.001s
im_detect: 1977/4024 0.288s 0.001s
im_detect: 1978/4024 0.288s 0.001s
im_detect: 1979/4024 0.288s 0.001s
im_detect: 1980/4024 0.288s 0.001s
im_detect: 1981/4024 0.288s 0.001s
im_detect: 1982/4024 0.288s 0.001s
im_detect: 1983/4024 0.288s 0.001s
im_detect: 1984/4024 0.288s 0.001s
im_detect: 1985/4024 0.288s 0.001s
im_detect: 1986/4024 0.288s 0.001s
im_detect: 1987/4024 0.288s 0.001s
im_detect: 1988/4024 0.288s 0.001s
im_detect: 1989/4024 0.288s 0.001s
im_detect: 1990/4024 0.288s 0.001s
im_detect: 1991/4024 0.288s 0.001s
im_detect: 1992/4024 0.288s 0.001s
im_detect: 1993/4024 0.288s 0.001s
im_detect: 1994/4024 0.288s 0.001s
im_detect: 1995/4024 0.288s 0.001s
im_detect: 1996/4024 0.288s 0.001s
im_detect: 1997/4024 0.288s 0.001s
im_detect: 1998/4024 0.288s 0.001s
im_detect: 1999/4024 0.288s 0.001s
im_detect: 2000/4024 0.288s 0.001s
im_detect: 2001/4024 0.288s 0.001s
im_detect: 2002/4024 0.288s 0.001s
im_detect: 2003/4024 0.288s 0.001s
im_detect: 2004/4024 0.288s 0.001s
im_detect: 2005/4024 0.288s 0.001s
im_detect: 2006/4024 0.288s 0.001s
im_detect: 2007/4024 0.288s 0.001s
im_detect: 2008/4024 0.288s 0.001s
im_detect: 2009/4024 0.288s 0.001s
im_detect: 2010/4024 0.288s 0.001s
im_detect: 2011/4024 0.288s 0.001s
im_detect: 2012/4024 0.288s 0.001s
im_detect: 2013/4024 0.288s 0.001s
im_detect: 2014/4024 0.288s 0.001s
im_detect: 2015/4024 0.288s 0.001s
im_detect: 2016/4024 0.288s 0.001s
im_detect: 2017/4024 0.288s 0.001s
im_detect: 2018/4024 0.288s 0.001s
im_detect: 2019/4024 0.288s 0.001s
im_detect: 2020/4024 0.288s 0.001s
im_detect: 2021/4024 0.288s 0.001s
im_detect: 2022/4024 0.288s 0.001s
im_detect: 2023/4024 0.288s 0.001s
im_detect: 2024/4024 0.288s 0.001s
im_detect: 2025/4024 0.288s 0.001s
im_detect: 2026/4024 0.288s 0.001s
im_detect: 2027/4024 0.288s 0.001s
im_detect: 2028/4024 0.288s 0.001s
im_detect: 2029/4024 0.288s 0.001s
im_detect: 2030/4024 0.288s 0.001s
im_detect: 2031/4024 0.288s 0.001s
im_detect: 2032/4024 0.288s 0.001s
im_detect: 2033/4024 0.288s 0.001s
im_detect: 2034/4024 0.288s 0.001s
im_detect: 2035/4024 0.288s 0.001s
im_detect: 2036/4024 0.288s 0.001s
im_detect: 2037/4024 0.288s 0.001s
im_detect: 2038/4024 0.288s 0.001s
im_detect: 2039/4024 0.288s 0.001s
im_detect: 2040/4024 0.288s 0.001s
im_detect: 2041/4024 0.288s 0.001s
im_detect: 2042/4024 0.288s 0.001s
im_detect: 2043/4024 0.288s 0.001s
im_detect: 2044/4024 0.288s 0.001s
im_detect: 2045/4024 0.288s 0.001s
im_detect: 2046/4024 0.288s 0.001s
im_detect: 2047/4024 0.288s 0.001s
im_detect: 2048/4024 0.288s 0.001s
im_detect: 2049/4024 0.288s 0.001s
im_detect: 2050/4024 0.288s 0.001s
im_detect: 2051/4024 0.288s 0.001s
im_detect: 2052/4024 0.288s 0.001s
im_detect: 2053/4024 0.288s 0.001s
im_detect: 2054/4024 0.288s 0.001s
im_detect: 2055/4024 0.288s 0.001s
im_detect: 2056/4024 0.288s 0.001s
im_detect: 2057/4024 0.288s 0.001s
im_detect: 2058/4024 0.288s 0.001s
im_detect: 2059/4024 0.288s 0.001s
im_detect: 2060/4024 0.288s 0.001s
im_detect: 2061/4024 0.288s 0.001s
im_detect: 2062/4024 0.288s 0.001s
im_detect: 2063/4024 0.288s 0.001s
im_detect: 2064/4024 0.288s 0.001s
im_detect: 2065/4024 0.288s 0.001s
im_detect: 2066/4024 0.288s 0.001s
im_detect: 2067/4024 0.288s 0.001s
im_detect: 2068/4024 0.288s 0.001s
im_detect: 2069/4024 0.288s 0.001s
im_detect: 2070/4024 0.288s 0.001s
im_detect: 2071/4024 0.288s 0.001s
im_detect: 2072/4024 0.288s 0.001s
im_detect: 2073/4024 0.288s 0.001s
im_detect: 2074/4024 0.288s 0.001s
im_detect: 2075/4024 0.288s 0.001s
im_detect: 2076/4024 0.288s 0.001s
im_detect: 2077/4024 0.288s 0.001s
im_detect: 2078/4024 0.288s 0.001s
im_detect: 2079/4024 0.288s 0.001s
im_detect: 2080/4024 0.288s 0.001s
im_detect: 2081/4024 0.288s 0.001s
im_detect: 2082/4024 0.288s 0.001s
im_detect: 2083/4024 0.288s 0.001s
im_detect: 2084/4024 0.288s 0.001s
im_detect: 2085/4024 0.288s 0.001s
im_detect: 2086/4024 0.288s 0.001s
im_detect: 2087/4024 0.288s 0.001s
im_detect: 2088/4024 0.288s 0.001s
im_detect: 2089/4024 0.288s 0.001s
im_detect: 2090/4024 0.288s 0.001s
im_detect: 2091/4024 0.288s 0.001s
im_detect: 2092/4024 0.288s 0.001s
im_detect: 2093/4024 0.288s 0.001s
im_detect: 2094/4024 0.288s 0.001s
im_detect: 2095/4024 0.288s 0.001s
im_detect: 2096/4024 0.288s 0.001s
im_detect: 2097/4024 0.288s 0.001s
im_detect: 2098/4024 0.288s 0.001s
im_detect: 2099/4024 0.288s 0.001s
im_detect: 2100/4024 0.288s 0.001s
im_detect: 2101/4024 0.288s 0.001s
im_detect: 2102/4024 0.288s 0.001s
im_detect: 2103/4024 0.288s 0.001s
im_detect: 2104/4024 0.288s 0.001s
im_detect: 2105/4024 0.288s 0.001s
im_detect: 2106/4024 0.288s 0.001s
im_detect: 2107/4024 0.288s 0.001s
im_detect: 2108/4024 0.288s 0.001s
im_detect: 2109/4024 0.288s 0.001s
im_detect: 2110/4024 0.288s 0.001s
im_detect: 2111/4024 0.288s 0.001s
im_detect: 2112/4024 0.288s 0.001s
im_detect: 2113/4024 0.288s 0.001s
im_detect: 2114/4024 0.288s 0.001s
im_detect: 2115/4024 0.288s 0.001s
im_detect: 2116/4024 0.288s 0.001s
im_detect: 2117/4024 0.288s 0.001s
im_detect: 2118/4024 0.288s 0.001s
im_detect: 2119/4024 0.288s 0.001s
im_detect: 2120/4024 0.288s 0.001s
im_detect: 2121/4024 0.288s 0.001s
im_detect: 2122/4024 0.288s 0.001s
im_detect: 2123/4024 0.288s 0.001s
im_detect: 2124/4024 0.288s 0.001s
im_detect: 2125/4024 0.288s 0.001s
im_detect: 2126/4024 0.288s 0.001s
im_detect: 2127/4024 0.288s 0.001s
im_detect: 2128/4024 0.288s 0.001s
im_detect: 2129/4024 0.288s 0.001s
im_detect: 2130/4024 0.288s 0.001s
im_detect: 2131/4024 0.288s 0.001s
im_detect: 2132/4024 0.288s 0.001s
im_detect: 2133/4024 0.288s 0.001s
im_detect: 2134/4024 0.288s 0.001s
im_detect: 2135/4024 0.288s 0.001s
im_detect: 2136/4024 0.288s 0.001s
im_detect: 2137/4024 0.288s 0.001s
im_detect: 2138/4024 0.288s 0.001s
im_detect: 2139/4024 0.288s 0.001s
im_detect: 2140/4024 0.288s 0.001s
im_detect: 2141/4024 0.288s 0.001s
im_detect: 2142/4024 0.288s 0.001s
im_detect: 2143/4024 0.288s 0.001s
im_detect: 2144/4024 0.288s 0.001s
im_detect: 2145/4024 0.288s 0.001s
im_detect: 2146/4024 0.288s 0.001s
im_detect: 2147/4024 0.288s 0.001s
im_detect: 2148/4024 0.288s 0.001s
im_detect: 2149/4024 0.288s 0.001s
im_detect: 2150/4024 0.288s 0.001s
im_detect: 2151/4024 0.288s 0.001s
im_detect: 2152/4024 0.288s 0.001s
im_detect: 2153/4024 0.288s 0.001s
im_detect: 2154/4024 0.288s 0.001s
im_detect: 2155/4024 0.288s 0.001s
im_detect: 2156/4024 0.288s 0.001s
im_detect: 2157/4024 0.288s 0.001s
im_detect: 2158/4024 0.288s 0.001s
im_detect: 2159/4024 0.288s 0.001s
im_detect: 2160/4024 0.288s 0.001s
im_detect: 2161/4024 0.288s 0.001s
im_detect: 2162/4024 0.288s 0.001s
im_detect: 2163/4024 0.288s 0.001s
im_detect: 2164/4024 0.288s 0.001s
im_detect: 2165/4024 0.288s 0.001s
im_detect: 2166/4024 0.288s 0.001s
im_detect: 2167/4024 0.288s 0.001s
im_detect: 2168/4024 0.288s 0.001s
im_detect: 2169/4024 0.288s 0.001s
im_detect: 2170/4024 0.288s 0.001s
im_detect: 2171/4024 0.288s 0.001s
im_detect: 2172/4024 0.288s 0.001s
im_detect: 2173/4024 0.288s 0.001s
im_detect: 2174/4024 0.288s 0.001s
im_detect: 2175/4024 0.288s 0.001s
im_detect: 2176/4024 0.288s 0.001s
im_detect: 2177/4024 0.288s 0.001s
im_detect: 2178/4024 0.288s 0.001s
im_detect: 2179/4024 0.288s 0.001s
im_detect: 2180/4024 0.288s 0.001s
im_detect: 2181/4024 0.288s 0.001s
im_detect: 2182/4024 0.288s 0.001s
im_detect: 2183/4024 0.288s 0.001s
im_detect: 2184/4024 0.288s 0.001s
im_detect: 2185/4024 0.288s 0.001s
im_detect: 2186/4024 0.288s 0.001s
im_detect: 2187/4024 0.288s 0.001s
im_detect: 2188/4024 0.288s 0.001s
im_detect: 2189/4024 0.288s 0.001s
im_detect: 2190/4024 0.288s 0.001s
im_detect: 2191/4024 0.288s 0.001s
im_detect: 2192/4024 0.288s 0.001s
im_detect: 2193/4024 0.288s 0.001s
im_detect: 2194/4024 0.288s 0.001s
im_detect: 2195/4024 0.288s 0.001s
im_detect: 2196/4024 0.288s 0.001s
im_detect: 2197/4024 0.288s 0.001s
im_detect: 2198/4024 0.288s 0.001s
im_detect: 2199/4024 0.288s 0.001s
im_detect: 2200/4024 0.288s 0.001s
im_detect: 2201/4024 0.288s 0.001s
im_detect: 2202/4024 0.288s 0.001s
im_detect: 2203/4024 0.288s 0.001s
im_detect: 2204/4024 0.288s 0.001s
im_detect: 2205/4024 0.288s 0.001s
im_detect: 2206/4024 0.288s 0.001s
im_detect: 2207/4024 0.288s 0.001s
im_detect: 2208/4024 0.288s 0.001s
im_detect: 2209/4024 0.288s 0.001s
im_detect: 2210/4024 0.288s 0.001s
im_detect: 2211/4024 0.288s 0.001s
im_detect: 2212/4024 0.288s 0.001s
im_detect: 2213/4024 0.288s 0.001s
im_detect: 2214/4024 0.288s 0.001s
im_detect: 2215/4024 0.288s 0.001s
im_detect: 2216/4024 0.288s 0.001s
im_detect: 2217/4024 0.288s 0.001s
im_detect: 2218/4024 0.288s 0.001s
im_detect: 2219/4024 0.288s 0.001s
im_detect: 2220/4024 0.288s 0.001s
im_detect: 2221/4024 0.288s 0.001s
im_detect: 2222/4024 0.288s 0.001s
im_detect: 2223/4024 0.288s 0.001s
im_detect: 2224/4024 0.288s 0.001s
im_detect: 2225/4024 0.288s 0.001s
im_detect: 2226/4024 0.288s 0.001s
im_detect: 2227/4024 0.288s 0.001s
im_detect: 2228/4024 0.288s 0.001s
im_detect: 2229/4024 0.288s 0.001s
im_detect: 2230/4024 0.288s 0.001s
im_detect: 2231/4024 0.288s 0.001s
im_detect: 2232/4024 0.288s 0.001s
im_detect: 2233/4024 0.288s 0.001s
im_detect: 2234/4024 0.288s 0.001s
im_detect: 2235/4024 0.288s 0.001s
im_detect: 2236/4024 0.288s 0.001s
im_detect: 2237/4024 0.288s 0.001s
im_detect: 2238/4024 0.288s 0.001s
im_detect: 2239/4024 0.288s 0.001s
im_detect: 2240/4024 0.288s 0.001s
im_detect: 2241/4024 0.288s 0.001s
im_detect: 2242/4024 0.288s 0.001s
im_detect: 2243/4024 0.288s 0.001s
im_detect: 2244/4024 0.288s 0.001s
im_detect: 2245/4024 0.288s 0.001s
im_detect: 2246/4024 0.288s 0.001s
im_detect: 2247/4024 0.288s 0.001s
im_detect: 2248/4024 0.288s 0.001s
im_detect: 2249/4024 0.288s 0.001s
im_detect: 2250/4024 0.288s 0.001s
im_detect: 2251/4024 0.288s 0.001s
im_detect: 2252/4024 0.288s 0.001s
im_detect: 2253/4024 0.288s 0.001s
im_detect: 2254/4024 0.288s 0.001s
im_detect: 2255/4024 0.288s 0.001s
im_detect: 2256/4024 0.288s 0.001s
im_detect: 2257/4024 0.288s 0.001s
im_detect: 2258/4024 0.288s 0.001s
im_detect: 2259/4024 0.288s 0.001s
im_detect: 2260/4024 0.288s 0.001s
im_detect: 2261/4024 0.288s 0.001s
im_detect: 2262/4024 0.288s 0.001s
im_detect: 2263/4024 0.288s 0.001s
im_detect: 2264/4024 0.288s 0.001s
im_detect: 2265/4024 0.288s 0.001s
im_detect: 2266/4024 0.288s 0.001s
im_detect: 2267/4024 0.288s 0.001s
im_detect: 2268/4024 0.288s 0.001s
im_detect: 2269/4024 0.288s 0.001s
im_detect: 2270/4024 0.288s 0.001s
im_detect: 2271/4024 0.288s 0.001s
im_detect: 2272/4024 0.288s 0.001s
im_detect: 2273/4024 0.288s 0.001s
im_detect: 2274/4024 0.288s 0.001s
im_detect: 2275/4024 0.288s 0.001s
im_detect: 2276/4024 0.288s 0.001s
im_detect: 2277/4024 0.288s 0.001s
im_detect: 2278/4024 0.288s 0.001s
im_detect: 2279/4024 0.288s 0.001s
im_detect: 2280/4024 0.288s 0.001s
im_detect: 2281/4024 0.288s 0.001s
im_detect: 2282/4024 0.288s 0.001s
im_detect: 2283/4024 0.288s 0.001s
im_detect: 2284/4024 0.288s 0.001s
im_detect: 2285/4024 0.288s 0.001s
im_detect: 2286/4024 0.288s 0.001s
im_detect: 2287/4024 0.288s 0.001s
im_detect: 2288/4024 0.288s 0.001s
im_detect: 2289/4024 0.288s 0.001s
im_detect: 2290/4024 0.288s 0.001s
im_detect: 2291/4024 0.288s 0.001s
im_detect: 2292/4024 0.288s 0.001s
im_detect: 2293/4024 0.288s 0.001s
im_detect: 2294/4024 0.288s 0.001s
im_detect: 2295/4024 0.288s 0.001s
im_detect: 2296/4024 0.288s 0.001s
im_detect: 2297/4024 0.288s 0.001s
im_detect: 2298/4024 0.288s 0.001s
im_detect: 2299/4024 0.288s 0.001s
im_detect: 2300/4024 0.288s 0.001s
im_detect: 2301/4024 0.288s 0.001s
im_detect: 2302/4024 0.288s 0.001s
im_detect: 2303/4024 0.288s 0.001s
im_detect: 2304/4024 0.288s 0.001s
im_detect: 2305/4024 0.288s 0.001s
im_detect: 2306/4024 0.288s 0.001s
im_detect: 2307/4024 0.288s 0.001s
im_detect: 2308/4024 0.288s 0.001s
im_detect: 2309/4024 0.288s 0.001s
im_detect: 2310/4024 0.288s 0.001s
im_detect: 2311/4024 0.288s 0.001s
im_detect: 2312/4024 0.288s 0.001s
im_detect: 2313/4024 0.288s 0.001s
im_detect: 2314/4024 0.288s 0.001s
im_detect: 2315/4024 0.288s 0.001s
im_detect: 2316/4024 0.288s 0.001s
im_detect: 2317/4024 0.288s 0.001s
im_detect: 2318/4024 0.288s 0.001s
im_detect: 2319/4024 0.288s 0.001s
im_detect: 2320/4024 0.288s 0.001s
im_detect: 2321/4024 0.288s 0.001s
im_detect: 2322/4024 0.288s 0.001s
im_detect: 2323/4024 0.288s 0.001s
im_detect: 2324/4024 0.288s 0.001s
im_detect: 2325/4024 0.288s 0.001s
im_detect: 2326/4024 0.288s 0.001s
im_detect: 2327/4024 0.288s 0.001s
im_detect: 2328/4024 0.288s 0.001s
im_detect: 2329/4024 0.288s 0.001s
im_detect: 2330/4024 0.288s 0.001s
im_detect: 2331/4024 0.288s 0.001s
im_detect: 2332/4024 0.288s 0.001s
im_detect: 2333/4024 0.288s 0.001s
im_detect: 2334/4024 0.288s 0.001s
im_detect: 2335/4024 0.288s 0.001s
im_detect: 2336/4024 0.288s 0.001s
im_detect: 2337/4024 0.288s 0.001s
im_detect: 2338/4024 0.288s 0.001s
im_detect: 2339/4024 0.288s 0.001s
im_detect: 2340/4024 0.288s 0.001s
im_detect: 2341/4024 0.288s 0.001s
im_detect: 2342/4024 0.288s 0.001s
im_detect: 2343/4024 0.288s 0.001s
im_detect: 2344/4024 0.288s 0.001s
im_detect: 2345/4024 0.288s 0.001s
im_detect: 2346/4024 0.288s 0.001s
im_detect: 2347/4024 0.288s 0.001s
im_detect: 2348/4024 0.288s 0.001s
im_detect: 2349/4024 0.288s 0.001s
im_detect: 2350/4024 0.288s 0.001s
im_detect: 2351/4024 0.288s 0.001s
im_detect: 2352/4024 0.288s 0.001s
im_detect: 2353/4024 0.288s 0.001s
im_detect: 2354/4024 0.288s 0.001s
im_detect: 2355/4024 0.288s 0.001s
im_detect: 2356/4024 0.288s 0.001s
im_detect: 2357/4024 0.288s 0.001s
im_detect: 2358/4024 0.288s 0.001s
im_detect: 2359/4024 0.288s 0.001s
im_detect: 2360/4024 0.288s 0.001s
im_detect: 2361/4024 0.288s 0.001s
im_detect: 2362/4024 0.288s 0.001s
im_detect: 2363/4024 0.288s 0.001s
im_detect: 2364/4024 0.288s 0.001s
im_detect: 2365/4024 0.288s 0.001s
im_detect: 2366/4024 0.288s 0.001s
im_detect: 2367/4024 0.288s 0.001s
im_detect: 2368/4024 0.288s 0.001s
im_detect: 2369/4024 0.288s 0.001s
im_detect: 2370/4024 0.288s 0.001s
im_detect: 2371/4024 0.288s 0.001s
im_detect: 2372/4024 0.288s 0.001s
im_detect: 2373/4024 0.288s 0.001s
im_detect: 2374/4024 0.288s 0.001s
im_detect: 2375/4024 0.288s 0.001s
im_detect: 2376/4024 0.288s 0.001s
im_detect: 2377/4024 0.288s 0.001s
im_detect: 2378/4024 0.288s 0.001s
im_detect: 2379/4024 0.288s 0.001s
im_detect: 2380/4024 0.288s 0.001s
im_detect: 2381/4024 0.288s 0.001s
im_detect: 2382/4024 0.288s 0.001s
im_detect: 2383/4024 0.288s 0.001s
im_detect: 2384/4024 0.288s 0.001s
im_detect: 2385/4024 0.288s 0.001s
im_detect: 2386/4024 0.288s 0.001s
im_detect: 2387/4024 0.288s 0.001s
im_detect: 2388/4024 0.288s 0.001s
im_detect: 2389/4024 0.288s 0.001s
im_detect: 2390/4024 0.288s 0.001s
im_detect: 2391/4024 0.288s 0.001s
im_detect: 2392/4024 0.288s 0.001s
im_detect: 2393/4024 0.288s 0.001s
im_detect: 2394/4024 0.288s 0.001s
im_detect: 2395/4024 0.288s 0.001s
im_detect: 2396/4024 0.288s 0.001s
im_detect: 2397/4024 0.288s 0.001s
im_detect: 2398/4024 0.288s 0.001s
im_detect: 2399/4024 0.288s 0.001s
im_detect: 2400/4024 0.288s 0.001s
im_detect: 2401/4024 0.288s 0.001s
im_detect: 2402/4024 0.288s 0.001s
im_detect: 2403/4024 0.288s 0.001s
im_detect: 2404/4024 0.288s 0.001s
im_detect: 2405/4024 0.288s 0.001s
im_detect: 2406/4024 0.288s 0.001s
im_detect: 2407/4024 0.288s 0.001s
im_detect: 2408/4024 0.288s 0.001s
im_detect: 2409/4024 0.288s 0.001s
im_detect: 2410/4024 0.288s 0.001s
im_detect: 2411/4024 0.288s 0.001s
im_detect: 2412/4024 0.288s 0.001s
im_detect: 2413/4024 0.288s 0.001s
im_detect: 2414/4024 0.288s 0.001s
im_detect: 2415/4024 0.288s 0.001s
im_detect: 2416/4024 0.288s 0.001s
im_detect: 2417/4024 0.288s 0.001s
im_detect: 2418/4024 0.288s 0.001s
im_detect: 2419/4024 0.288s 0.001s
im_detect: 2420/4024 0.288s 0.001s
im_detect: 2421/4024 0.288s 0.001s
im_detect: 2422/4024 0.288s 0.001s
im_detect: 2423/4024 0.288s 0.001s
im_detect: 2424/4024 0.288s 0.001s
im_detect: 2425/4024 0.288s 0.001s
im_detect: 2426/4024 0.288s 0.001s
im_detect: 2427/4024 0.288s 0.001s
im_detect: 2428/4024 0.288s 0.001s
im_detect: 2429/4024 0.288s 0.001s
im_detect: 2430/4024 0.288s 0.001s
im_detect: 2431/4024 0.288s 0.001s
im_detect: 2432/4024 0.288s 0.001s
im_detect: 2433/4024 0.288s 0.001s
im_detect: 2434/4024 0.288s 0.001s
im_detect: 2435/4024 0.288s 0.001s
im_detect: 2436/4024 0.288s 0.001s
im_detect: 2437/4024 0.288s 0.001s
im_detect: 2438/4024 0.288s 0.001s
im_detect: 2439/4024 0.288s 0.001s
im_detect: 2440/4024 0.288s 0.001s
im_detect: 2441/4024 0.288s 0.001s
im_detect: 2442/4024 0.288s 0.001s
im_detect: 2443/4024 0.288s 0.001s
im_detect: 2444/4024 0.288s 0.001s
im_detect: 2445/4024 0.288s 0.001s
im_detect: 2446/4024 0.288s 0.001s
im_detect: 2447/4024 0.288s 0.001s
im_detect: 2448/4024 0.288s 0.001s
im_detect: 2449/4024 0.288s 0.001s
im_detect: 2450/4024 0.288s 0.001s
im_detect: 2451/4024 0.288s 0.001s
im_detect: 2452/4024 0.288s 0.001s
im_detect: 2453/4024 0.288s 0.001s
im_detect: 2454/4024 0.288s 0.001s
im_detect: 2455/4024 0.288s 0.001s
im_detect: 2456/4024 0.288s 0.001s
im_detect: 2457/4024 0.288s 0.001s
im_detect: 2458/4024 0.288s 0.001s
im_detect: 2459/4024 0.288s 0.001s
im_detect: 2460/4024 0.288s 0.001s
im_detect: 2461/4024 0.288s 0.001s
im_detect: 2462/4024 0.288s 0.001s
im_detect: 2463/4024 0.288s 0.001s
im_detect: 2464/4024 0.288s 0.001s
im_detect: 2465/4024 0.288s 0.001s
im_detect: 2466/4024 0.288s 0.001s
im_detect: 2467/4024 0.288s 0.001s
im_detect: 2468/4024 0.288s 0.001s
im_detect: 2469/4024 0.288s 0.001s
im_detect: 2470/4024 0.288s 0.001s
im_detect: 2471/4024 0.288s 0.001s
im_detect: 2472/4024 0.288s 0.001s
im_detect: 2473/4024 0.288s 0.001s
im_detect: 2474/4024 0.288s 0.001s
im_detect: 2475/4024 0.288s 0.001s
im_detect: 2476/4024 0.288s 0.001s
im_detect: 2477/4024 0.288s 0.001s
im_detect: 2478/4024 0.288s 0.001s
im_detect: 2479/4024 0.288s 0.001s
im_detect: 2480/4024 0.288s 0.001s
im_detect: 2481/4024 0.288s 0.001s
im_detect: 2482/4024 0.288s 0.001s
im_detect: 2483/4024 0.288s 0.001s
im_detect: 2484/4024 0.288s 0.001s
im_detect: 2485/4024 0.288s 0.001s
im_detect: 2486/4024 0.288s 0.001s
im_detect: 2487/4024 0.288s 0.001s
im_detect: 2488/4024 0.288s 0.001s
im_detect: 2489/4024 0.288s 0.001s
im_detect: 2490/4024 0.288s 0.001s
im_detect: 2491/4024 0.288s 0.001s
im_detect: 2492/4024 0.288s 0.001s
im_detect: 2493/4024 0.288s 0.001s
im_detect: 2494/4024 0.288s 0.001s
im_detect: 2495/4024 0.288s 0.001s
im_detect: 2496/4024 0.288s 0.001s
im_detect: 2497/4024 0.288s 0.001s
im_detect: 2498/4024 0.288s 0.001s
im_detect: 2499/4024 0.288s 0.001s
im_detect: 2500/4024 0.288s 0.001s
im_detect: 2501/4024 0.288s 0.001s
im_detect: 2502/4024 0.288s 0.001s
im_detect: 2503/4024 0.288s 0.001s
im_detect: 2504/4024 0.288s 0.001s
im_detect: 2505/4024 0.288s 0.001s
im_detect: 2506/4024 0.288s 0.001s
im_detect: 2507/4024 0.288s 0.001s
im_detect: 2508/4024 0.288s 0.001s
im_detect: 2509/4024 0.288s 0.001s
im_detect: 2510/4024 0.288s 0.001s
im_detect: 2511/4024 0.288s 0.001s
im_detect: 2512/4024 0.288s 0.001s
im_detect: 2513/4024 0.288s 0.001s
im_detect: 2514/4024 0.288s 0.001s
im_detect: 2515/4024 0.288s 0.001s
im_detect: 2516/4024 0.288s 0.001s
im_detect: 2517/4024 0.288s 0.001s
im_detect: 2518/4024 0.288s 0.001s
im_detect: 2519/4024 0.288s 0.001s
im_detect: 2520/4024 0.288s 0.001s
im_detect: 2521/4024 0.288s 0.001s
im_detect: 2522/4024 0.288s 0.001s
im_detect: 2523/4024 0.288s 0.001s
im_detect: 2524/4024 0.288s 0.001s
im_detect: 2525/4024 0.288s 0.001s
im_detect: 2526/4024 0.288s 0.001s
im_detect: 2527/4024 0.288s 0.001s
im_detect: 2528/4024 0.288s 0.001s
im_detect: 2529/4024 0.288s 0.001s
im_detect: 2530/4024 0.288s 0.001s
im_detect: 2531/4024 0.288s 0.001s
im_detect: 2532/4024 0.288s 0.001s
im_detect: 2533/4024 0.288s 0.001s
im_detect: 2534/4024 0.288s 0.001s
im_detect: 2535/4024 0.288s 0.001s
im_detect: 2536/4024 0.288s 0.001s
im_detect: 2537/4024 0.288s 0.001s
im_detect: 2538/4024 0.288s 0.001s
im_detect: 2539/4024 0.288s 0.001s
im_detect: 2540/4024 0.288s 0.001s
im_detect: 2541/4024 0.288s 0.001s
im_detect: 2542/4024 0.288s 0.001s
im_detect: 2543/4024 0.288s 0.001s
im_detect: 2544/4024 0.288s 0.001s
im_detect: 2545/4024 0.288s 0.001s
im_detect: 2546/4024 0.288s 0.001s
im_detect: 2547/4024 0.288s 0.001s
im_detect: 2548/4024 0.288s 0.001s
im_detect: 2549/4024 0.288s 0.001s
im_detect: 2550/4024 0.288s 0.001s
im_detect: 2551/4024 0.288s 0.001s
im_detect: 2552/4024 0.288s 0.001s
im_detect: 2553/4024 0.288s 0.001s
im_detect: 2554/4024 0.288s 0.001s
im_detect: 2555/4024 0.288s 0.001s
im_detect: 2556/4024 0.288s 0.001s
im_detect: 2557/4024 0.288s 0.001s
im_detect: 2558/4024 0.288s 0.001s
im_detect: 2559/4024 0.288s 0.001s
im_detect: 2560/4024 0.288s 0.001s
im_detect: 2561/4024 0.288s 0.001s
im_detect: 2562/4024 0.288s 0.001s
im_detect: 2563/4024 0.288s 0.001s
im_detect: 2564/4024 0.288s 0.001s
im_detect: 2565/4024 0.288s 0.001s
im_detect: 2566/4024 0.288s 0.001s
im_detect: 2567/4024 0.288s 0.001s
im_detect: 2568/4024 0.288s 0.001s
im_detect: 2569/4024 0.288s 0.001s
im_detect: 2570/4024 0.288s 0.001s
im_detect: 2571/4024 0.288s 0.001s
im_detect: 2572/4024 0.288s 0.001s
im_detect: 2573/4024 0.288s 0.001s
im_detect: 2574/4024 0.288s 0.001s
im_detect: 2575/4024 0.288s 0.001s
im_detect: 2576/4024 0.288s 0.001s
im_detect: 2577/4024 0.288s 0.001s
im_detect: 2578/4024 0.288s 0.001s
im_detect: 2579/4024 0.288s 0.001s
im_detect: 2580/4024 0.288s 0.001s
im_detect: 2581/4024 0.288s 0.001s
im_detect: 2582/4024 0.288s 0.001s
im_detect: 2583/4024 0.288s 0.001s
im_detect: 2584/4024 0.288s 0.001s
im_detect: 2585/4024 0.288s 0.001s
im_detect: 2586/4024 0.288s 0.001s
im_detect: 2587/4024 0.288s 0.001s
im_detect: 2588/4024 0.288s 0.001s
im_detect: 2589/4024 0.288s 0.001s
im_detect: 2590/4024 0.288s 0.001s
im_detect: 2591/4024 0.288s 0.001s
im_detect: 2592/4024 0.288s 0.001s
im_detect: 2593/4024 0.288s 0.001s
im_detect: 2594/4024 0.288s 0.001s
im_detect: 2595/4024 0.288s 0.001s
im_detect: 2596/4024 0.288s 0.001s
im_detect: 2597/4024 0.288s 0.001s
im_detect: 2598/4024 0.288s 0.001s
im_detect: 2599/4024 0.288s 0.001s
im_detect: 2600/4024 0.288s 0.001s
im_detect: 2601/4024 0.288s 0.001s
im_detect: 2602/4024 0.288s 0.001s
im_detect: 2603/4024 0.288s 0.001s
im_detect: 2604/4024 0.288s 0.001s
im_detect: 2605/4024 0.288s 0.001s
im_detect: 2606/4024 0.288s 0.001s
im_detect: 2607/4024 0.288s 0.001s
im_detect: 2608/4024 0.288s 0.001s
im_detect: 2609/4024 0.288s 0.001s
im_detect: 2610/4024 0.288s 0.001s
im_detect: 2611/4024 0.288s 0.001s
im_detect: 2612/4024 0.288s 0.001s
im_detect: 2613/4024 0.288s 0.001s
im_detect: 2614/4024 0.288s 0.001s
im_detect: 2615/4024 0.288s 0.001s
im_detect: 2616/4024 0.288s 0.001s
im_detect: 2617/4024 0.288s 0.001s
im_detect: 2618/4024 0.288s 0.001s
im_detect: 2619/4024 0.288s 0.001s
im_detect: 2620/4024 0.288s 0.001s
im_detect: 2621/4024 0.288s 0.001s
im_detect: 2622/4024 0.288s 0.001s
im_detect: 2623/4024 0.288s 0.001s
im_detect: 2624/4024 0.288s 0.001s
im_detect: 2625/4024 0.288s 0.001s
im_detect: 2626/4024 0.288s 0.001s
im_detect: 2627/4024 0.288s 0.001s
im_detect: 2628/4024 0.288s 0.001s
im_detect: 2629/4024 0.288s 0.001s
im_detect: 2630/4024 0.288s 0.001s
im_detect: 2631/4024 0.288s 0.001s
im_detect: 2632/4024 0.288s 0.001s
im_detect: 2633/4024 0.288s 0.001s
im_detect: 2634/4024 0.288s 0.001s
im_detect: 2635/4024 0.288s 0.001s
im_detect: 2636/4024 0.288s 0.001s
im_detect: 2637/4024 0.288s 0.001s
im_detect: 2638/4024 0.288s 0.001s
im_detect: 2639/4024 0.288s 0.001s
im_detect: 2640/4024 0.288s 0.001s
im_detect: 2641/4024 0.288s 0.001s
im_detect: 2642/4024 0.288s 0.001s
im_detect: 2643/4024 0.288s 0.001s
im_detect: 2644/4024 0.288s 0.001s
im_detect: 2645/4024 0.288s 0.001s
im_detect: 2646/4024 0.288s 0.001s
im_detect: 2647/4024 0.288s 0.001s
im_detect: 2648/4024 0.288s 0.001s
im_detect: 2649/4024 0.288s 0.001s
im_detect: 2650/4024 0.288s 0.001s
im_detect: 2651/4024 0.288s 0.001s
im_detect: 2652/4024 0.288s 0.001s
im_detect: 2653/4024 0.288s 0.001s
im_detect: 2654/4024 0.288s 0.001s
im_detect: 2655/4024 0.288s 0.001s
im_detect: 2656/4024 0.288s 0.001s
im_detect: 2657/4024 0.288s 0.001s
im_detect: 2658/4024 0.288s 0.001s
im_detect: 2659/4024 0.288s 0.001s
im_detect: 2660/4024 0.288s 0.001s
im_detect: 2661/4024 0.288s 0.001s
im_detect: 2662/4024 0.288s 0.001s
im_detect: 2663/4024 0.288s 0.001s
im_detect: 2664/4024 0.288s 0.001s
im_detect: 2665/4024 0.288s 0.001s
im_detect: 2666/4024 0.288s 0.001s
im_detect: 2667/4024 0.288s 0.001s
im_detect: 2668/4024 0.288s 0.001s
im_detect: 2669/4024 0.288s 0.001s
im_detect: 2670/4024 0.288s 0.001s
im_detect: 2671/4024 0.288s 0.001s
im_detect: 2672/4024 0.288s 0.001s
im_detect: 2673/4024 0.288s 0.001s
im_detect: 2674/4024 0.288s 0.001s
im_detect: 2675/4024 0.288s 0.001s
im_detect: 2676/4024 0.288s 0.001s
im_detect: 2677/4024 0.288s 0.001s
im_detect: 2678/4024 0.288s 0.001s
im_detect: 2679/4024 0.288s 0.001s
im_detect: 2680/4024 0.288s 0.001s
im_detect: 2681/4024 0.288s 0.001s
im_detect: 2682/4024 0.288s 0.001s
im_detect: 2683/4024 0.288s 0.001s
im_detect: 2684/4024 0.288s 0.001s
im_detect: 2685/4024 0.288s 0.001s
im_detect: 2686/4024 0.288s 0.001s
im_detect: 2687/4024 0.288s 0.001s
im_detect: 2688/4024 0.288s 0.001s
im_detect: 2689/4024 0.288s 0.001s
im_detect: 2690/4024 0.288s 0.001s
im_detect: 2691/4024 0.288s 0.001s
im_detect: 2692/4024 0.288s 0.001s
im_detect: 2693/4024 0.288s 0.001s
im_detect: 2694/4024 0.288s 0.001s
im_detect: 2695/4024 0.288s 0.001s
im_detect: 2696/4024 0.288s 0.001s
im_detect: 2697/4024 0.288s 0.001s
im_detect: 2698/4024 0.288s 0.001s
im_detect: 2699/4024 0.288s 0.001s
im_detect: 2700/4024 0.288s 0.001s
im_detect: 2701/4024 0.288s 0.001s
im_detect: 2702/4024 0.288s 0.001s
im_detect: 2703/4024 0.288s 0.001s
im_detect: 2704/4024 0.288s 0.001s
im_detect: 2705/4024 0.288s 0.001s
im_detect: 2706/4024 0.288s 0.001s
im_detect: 2707/4024 0.288s 0.001s
im_detect: 2708/4024 0.288s 0.001s
im_detect: 2709/4024 0.288s 0.001s
im_detect: 2710/4024 0.288s 0.001s
im_detect: 2711/4024 0.288s 0.001s
im_detect: 2712/4024 0.288s 0.001s
im_detect: 2713/4024 0.288s 0.001s
im_detect: 2714/4024 0.288s 0.001s
im_detect: 2715/4024 0.288s 0.001s
im_detect: 2716/4024 0.288s 0.001s
im_detect: 2717/4024 0.288s 0.001s
im_detect: 2718/4024 0.288s 0.001s
im_detect: 2719/4024 0.288s 0.001s
im_detect: 2720/4024 0.288s 0.001s
im_detect: 2721/4024 0.288s 0.001s
im_detect: 2722/4024 0.288s 0.001s
im_detect: 2723/4024 0.288s 0.001s
im_detect: 2724/4024 0.288s 0.001s
im_detect: 2725/4024 0.288s 0.001s
im_detect: 2726/4024 0.288s 0.001s
im_detect: 2727/4024 0.288s 0.001s
im_detect: 2728/4024 0.288s 0.001s
im_detect: 2729/4024 0.288s 0.001s
im_detect: 2730/4024 0.288s 0.001s
im_detect: 2731/4024 0.288s 0.001s
im_detect: 2732/4024 0.288s 0.001s
im_detect: 2733/4024 0.288s 0.001s
im_detect: 2734/4024 0.288s 0.001s
im_detect: 2735/4024 0.288s 0.001s
im_detect: 2736/4024 0.288s 0.001s
im_detect: 2737/4024 0.288s 0.001s
im_detect: 2738/4024 0.288s 0.001s
im_detect: 2739/4024 0.288s 0.001s
im_detect: 2740/4024 0.288s 0.001s
im_detect: 2741/4024 0.288s 0.001s
im_detect: 2742/4024 0.288s 0.001s
im_detect: 2743/4024 0.288s 0.001s
im_detect: 2744/4024 0.288s 0.001s
im_detect: 2745/4024 0.288s 0.001s
im_detect: 2746/4024 0.288s 0.001s
im_detect: 2747/4024 0.288s 0.001s
im_detect: 2748/4024 0.288s 0.001s
im_detect: 2749/4024 0.288s 0.001s
im_detect: 2750/4024 0.288s 0.001s
im_detect: 2751/4024 0.288s 0.001s
im_detect: 2752/4024 0.288s 0.001s
im_detect: 2753/4024 0.288s 0.001s
im_detect: 2754/4024 0.288s 0.001s
im_detect: 2755/4024 0.288s 0.001s
im_detect: 2756/4024 0.288s 0.001s
im_detect: 2757/4024 0.288s 0.001s
im_detect: 2758/4024 0.288s 0.001s
im_detect: 2759/4024 0.288s 0.001s
im_detect: 2760/4024 0.288s 0.001s
im_detect: 2761/4024 0.288s 0.001s
im_detect: 2762/4024 0.288s 0.001s
im_detect: 2763/4024 0.288s 0.001s
im_detect: 2764/4024 0.288s 0.001s
im_detect: 2765/4024 0.288s 0.001s
im_detect: 2766/4024 0.288s 0.001s
im_detect: 2767/4024 0.288s 0.001s
im_detect: 2768/4024 0.288s 0.001s
im_detect: 2769/4024 0.288s 0.001s
im_detect: 2770/4024 0.288s 0.001s
im_detect: 2771/4024 0.288s 0.001s
im_detect: 2772/4024 0.288s 0.001s
im_detect: 2773/4024 0.288s 0.001s
im_detect: 2774/4024 0.288s 0.001s
im_detect: 2775/4024 0.288s 0.001s
im_detect: 2776/4024 0.288s 0.001s
im_detect: 2777/4024 0.288s 0.001s
im_detect: 2778/4024 0.288s 0.001s
im_detect: 2779/4024 0.288s 0.001s
im_detect: 2780/4024 0.288s 0.001s
im_detect: 2781/4024 0.288s 0.001s
im_detect: 2782/4024 0.288s 0.001s
im_detect: 2783/4024 0.288s 0.001s
im_detect: 2784/4024 0.288s 0.001s
im_detect: 2785/4024 0.288s 0.001s
im_detect: 2786/4024 0.288s 0.001s
im_detect: 2787/4024 0.288s 0.001s
im_detect: 2788/4024 0.288s 0.001s
im_detect: 2789/4024 0.288s 0.001s
im_detect: 2790/4024 0.288s 0.001s
im_detect: 2791/4024 0.288s 0.001s
im_detect: 2792/4024 0.288s 0.001s
im_detect: 2793/4024 0.288s 0.001s
im_detect: 2794/4024 0.288s 0.001s
im_detect: 2795/4024 0.288s 0.001s
im_detect: 2796/4024 0.288s 0.001s
im_detect: 2797/4024 0.288s 0.001s
im_detect: 2798/4024 0.288s 0.001s
im_detect: 2799/4024 0.288s 0.001s
im_detect: 2800/4024 0.288s 0.001s
im_detect: 2801/4024 0.288s 0.001s
im_detect: 2802/4024 0.288s 0.001s
im_detect: 2803/4024 0.288s 0.001s
im_detect: 2804/4024 0.288s 0.001s
im_detect: 2805/4024 0.288s 0.001s
im_detect: 2806/4024 0.288s 0.001s
im_detect: 2807/4024 0.288s 0.001s
im_detect: 2808/4024 0.288s 0.001s
im_detect: 2809/4024 0.288s 0.001s
im_detect: 2810/4024 0.288s 0.001s
im_detect: 2811/4024 0.288s 0.001s
im_detect: 2812/4024 0.288s 0.001s
im_detect: 2813/4024 0.288s 0.001s
im_detect: 2814/4024 0.288s 0.001s
im_detect: 2815/4024 0.288s 0.001s
im_detect: 2816/4024 0.288s 0.001s
im_detect: 2817/4024 0.288s 0.001s
im_detect: 2818/4024 0.288s 0.001s
im_detect: 2819/4024 0.288s 0.001s
im_detect: 2820/4024 0.288s 0.001s
im_detect: 2821/4024 0.288s 0.001s
im_detect: 2822/4024 0.288s 0.001s
im_detect: 2823/4024 0.288s 0.001s
im_detect: 2824/4024 0.288s 0.001s
im_detect: 2825/4024 0.288s 0.001s
im_detect: 2826/4024 0.288s 0.001s
im_detect: 2827/4024 0.288s 0.001s
im_detect: 2828/4024 0.288s 0.001s
im_detect: 2829/4024 0.288s 0.001s
im_detect: 2830/4024 0.288s 0.001s
im_detect: 2831/4024 0.288s 0.001s
im_detect: 2832/4024 0.288s 0.001s
im_detect: 2833/4024 0.288s 0.001s
im_detect: 2834/4024 0.288s 0.001s
im_detect: 2835/4024 0.288s 0.001s
im_detect: 2836/4024 0.288s 0.001s
im_detect: 2837/4024 0.288s 0.001s
im_detect: 2838/4024 0.288s 0.001s
im_detect: 2839/4024 0.288s 0.001s
im_detect: 2840/4024 0.288s 0.001s
im_detect: 2841/4024 0.288s 0.001s
im_detect: 2842/4024 0.288s 0.001s
im_detect: 2843/4024 0.288s 0.001s
im_detect: 2844/4024 0.288s 0.001s
im_detect: 2845/4024 0.288s 0.001s
im_detect: 2846/4024 0.288s 0.001s
im_detect: 2847/4024 0.288s 0.001s
im_detect: 2848/4024 0.288s 0.001s
im_detect: 2849/4024 0.288s 0.001s
im_detect: 2850/4024 0.288s 0.001s
im_detect: 2851/4024 0.288s 0.001s
im_detect: 2852/4024 0.288s 0.001s
im_detect: 2853/4024 0.288s 0.001s
im_detect: 2854/4024 0.288s 0.001s
im_detect: 2855/4024 0.288s 0.001s
im_detect: 2856/4024 0.288s 0.001s
im_detect: 2857/4024 0.288s 0.001s
im_detect: 2858/4024 0.288s 0.001s
im_detect: 2859/4024 0.288s 0.001s
im_detect: 2860/4024 0.288s 0.001s
im_detect: 2861/4024 0.288s 0.001s
im_detect: 2862/4024 0.288s 0.001s
im_detect: 2863/4024 0.288s 0.001s
im_detect: 2864/4024 0.288s 0.001s
im_detect: 2865/4024 0.288s 0.001s
im_detect: 2866/4024 0.288s 0.001s
im_detect: 2867/4024 0.288s 0.001s
im_detect: 2868/4024 0.288s 0.001s
im_detect: 2869/4024 0.288s 0.001s
im_detect: 2870/4024 0.288s 0.001s
im_detect: 2871/4024 0.288s 0.001s
im_detect: 2872/4024 0.288s 0.001s
im_detect: 2873/4024 0.288s 0.001s
im_detect: 2874/4024 0.288s 0.001s
im_detect: 2875/4024 0.288s 0.001s
im_detect: 2876/4024 0.288s 0.001s
im_detect: 2877/4024 0.288s 0.001s
im_detect: 2878/4024 0.288s 0.001s
im_detect: 2879/4024 0.288s 0.001s
im_detect: 2880/4024 0.288s 0.001s
im_detect: 2881/4024 0.288s 0.001s
im_detect: 2882/4024 0.288s 0.001s
im_detect: 2883/4024 0.288s 0.001s
im_detect: 2884/4024 0.288s 0.001s
im_detect: 2885/4024 0.288s 0.001s
im_detect: 2886/4024 0.288s 0.001s
im_detect: 2887/4024 0.288s 0.001s
im_detect: 2888/4024 0.288s 0.001s
im_detect: 2889/4024 0.288s 0.001s
im_detect: 2890/4024 0.288s 0.001s
im_detect: 2891/4024 0.288s 0.001s
im_detect: 2892/4024 0.288s 0.001s
im_detect: 2893/4024 0.288s 0.001s
im_detect: 2894/4024 0.288s 0.001s
im_detect: 2895/4024 0.288s 0.001s
im_detect: 2896/4024 0.288s 0.001s
im_detect: 2897/4024 0.288s 0.001s
im_detect: 2898/4024 0.288s 0.001s
im_detect: 2899/4024 0.288s 0.001s
im_detect: 2900/4024 0.288s 0.001s
im_detect: 2901/4024 0.288s 0.001s
im_detect: 2902/4024 0.288s 0.001s
im_detect: 2903/4024 0.288s 0.001s
im_detect: 2904/4024 0.288s 0.001s
im_detect: 2905/4024 0.288s 0.001s
im_detect: 2906/4024 0.288s 0.001s
im_detect: 2907/4024 0.288s 0.001s
im_detect: 2908/4024 0.288s 0.001s
im_detect: 2909/4024 0.288s 0.001s
im_detect: 2910/4024 0.288s 0.001s
im_detect: 2911/4024 0.288s 0.001s
im_detect: 2912/4024 0.288s 0.001s
im_detect: 2913/4024 0.288s 0.001s
im_detect: 2914/4024 0.288s 0.001s
im_detect: 2915/4024 0.288s 0.001s
im_detect: 2916/4024 0.288s 0.001s
im_detect: 2917/4024 0.288s 0.001s
im_detect: 2918/4024 0.288s 0.001s
im_detect: 2919/4024 0.288s 0.001s
im_detect: 2920/4024 0.288s 0.001s
im_detect: 2921/4024 0.288s 0.001s
im_detect: 2922/4024 0.288s 0.001s
im_detect: 2923/4024 0.288s 0.001s
im_detect: 2924/4024 0.288s 0.001s
im_detect: 2925/4024 0.288s 0.001s
im_detect: 2926/4024 0.288s 0.001s
im_detect: 2927/4024 0.288s 0.001s
im_detect: 2928/4024 0.288s 0.001s
im_detect: 2929/4024 0.288s 0.001s
im_detect: 2930/4024 0.288s 0.001s
im_detect: 2931/4024 0.288s 0.001s
im_detect: 2932/4024 0.288s 0.001s
im_detect: 2933/4024 0.288s 0.001s
im_detect: 2934/4024 0.288s 0.001s
im_detect: 2935/4024 0.288s 0.001s
im_detect: 2936/4024 0.288s 0.001s
im_detect: 2937/4024 0.288s 0.001s
im_detect: 2938/4024 0.288s 0.001s
im_detect: 2939/4024 0.288s 0.001s
im_detect: 2940/4024 0.288s 0.001s
im_detect: 2941/4024 0.288s 0.001s
im_detect: 2942/4024 0.288s 0.001s
im_detect: 2943/4024 0.288s 0.001s
im_detect: 2944/4024 0.288s 0.001s
im_detect: 2945/4024 0.288s 0.001s
im_detect: 2946/4024 0.288s 0.001s
im_detect: 2947/4024 0.288s 0.001s
im_detect: 2948/4024 0.288s 0.001s
im_detect: 2949/4024 0.288s 0.001s
im_detect: 2950/4024 0.288s 0.001s
im_detect: 2951/4024 0.288s 0.001s
im_detect: 2952/4024 0.288s 0.001s
im_detect: 2953/4024 0.288s 0.001s
im_detect: 2954/4024 0.288s 0.001s
im_detect: 2955/4024 0.288s 0.001s
im_detect: 2956/4024 0.288s 0.001s
im_detect: 2957/4024 0.288s 0.001s
im_detect: 2958/4024 0.288s 0.001s
im_detect: 2959/4024 0.288s 0.001s
im_detect: 2960/4024 0.288s 0.001s
im_detect: 2961/4024 0.288s 0.001s
im_detect: 2962/4024 0.288s 0.001s
im_detect: 2963/4024 0.288s 0.001s
im_detect: 2964/4024 0.288s 0.001s
im_detect: 2965/4024 0.288s 0.001s
im_detect: 2966/4024 0.288s 0.001s
im_detect: 2967/4024 0.288s 0.001s
im_detect: 2968/4024 0.288s 0.001s
im_detect: 2969/4024 0.288s 0.001s
im_detect: 2970/4024 0.288s 0.001s
im_detect: 2971/4024 0.288s 0.001s
im_detect: 2972/4024 0.288s 0.001s
im_detect: 2973/4024 0.288s 0.001s
im_detect: 2974/4024 0.288s 0.001s
im_detect: 2975/4024 0.288s 0.001s
im_detect: 2976/4024 0.288s 0.001s
im_detect: 2977/4024 0.288s 0.001s
im_detect: 2978/4024 0.288s 0.001s
im_detect: 2979/4024 0.288s 0.001s
im_detect: 2980/4024 0.288s 0.001s
im_detect: 2981/4024 0.288s 0.001s
im_detect: 2982/4024 0.288s 0.001s
im_detect: 2983/4024 0.288s 0.001s
im_detect: 2984/4024 0.288s 0.001s
im_detect: 2985/4024 0.288s 0.001s
im_detect: 2986/4024 0.288s 0.001s
im_detect: 2987/4024 0.288s 0.001s
im_detect: 2988/4024 0.288s 0.001s
im_detect: 2989/4024 0.288s 0.001s
im_detect: 2990/4024 0.288s 0.001s
im_detect: 2991/4024 0.288s 0.001s
im_detect: 2992/4024 0.288s 0.001s
im_detect: 2993/4024 0.288s 0.001s
im_detect: 2994/4024 0.288s 0.001s
im_detect: 2995/4024 0.288s 0.001s
im_detect: 2996/4024 0.288s 0.001s
im_detect: 2997/4024 0.288s 0.001s
im_detect: 2998/4024 0.288s 0.001s
im_detect: 2999/4024 0.288s 0.001s
im_detect: 3000/4024 0.288s 0.001s
im_detect: 3001/4024 0.288s 0.001s
im_detect: 3002/4024 0.288s 0.001s
im_detect: 3003/4024 0.288s 0.001s
im_detect: 3004/4024 0.288s 0.001s
im_detect: 3005/4024 0.288s 0.001s
im_detect: 3006/4024 0.288s 0.001s
im_detect: 3007/4024 0.288s 0.001s
im_detect: 3008/4024 0.288s 0.001s
im_detect: 3009/4024 0.288s 0.001s
im_detect: 3010/4024 0.288s 0.001s
im_detect: 3011/4024 0.288s 0.001s
im_detect: 3012/4024 0.288s 0.001s
im_detect: 3013/4024 0.288s 0.001s
im_detect: 3014/4024 0.288s 0.001s
im_detect: 3015/4024 0.288s 0.001s
im_detect: 3016/4024 0.288s 0.001s
im_detect: 3017/4024 0.288s 0.001s
im_detect: 3018/4024 0.288s 0.001s
im_detect: 3019/4024 0.288s 0.001s
im_detect: 3020/4024 0.288s 0.001s
im_detect: 3021/4024 0.288s 0.001s
im_detect: 3022/4024 0.288s 0.001s
im_detect: 3023/4024 0.288s 0.001s
im_detect: 3024/4024 0.288s 0.001s
im_detect: 3025/4024 0.288s 0.001s
im_detect: 3026/4024 0.288s 0.001s
im_detect: 3027/4024 0.288s 0.001s
im_detect: 3028/4024 0.288s 0.001s
im_detect: 3029/4024 0.288s 0.001s
im_detect: 3030/4024 0.288s 0.001s
im_detect: 3031/4024 0.288s 0.001s
im_detect: 3032/4024 0.288s 0.001s
im_detect: 3033/4024 0.288s 0.001s
im_detect: 3034/4024 0.288s 0.001s
im_detect: 3035/4024 0.288s 0.001s
im_detect: 3036/4024 0.288s 0.001s
im_detect: 3037/4024 0.288s 0.001s
im_detect: 3038/4024 0.288s 0.001s
im_detect: 3039/4024 0.288s 0.001s
im_detect: 3040/4024 0.288s 0.001s
im_detect: 3041/4024 0.288s 0.001s
im_detect: 3042/4024 0.288s 0.001s
im_detect: 3043/4024 0.288s 0.001s
im_detect: 3044/4024 0.288s 0.001s
im_detect: 3045/4024 0.288s 0.001s
im_detect: 3046/4024 0.288s 0.001s
im_detect: 3047/4024 0.288s 0.001s
im_detect: 3048/4024 0.288s 0.001s
im_detect: 3049/4024 0.288s 0.001s
im_detect: 3050/4024 0.288s 0.001s
im_detect: 3051/4024 0.288s 0.001s
im_detect: 3052/4024 0.288s 0.001s
im_detect: 3053/4024 0.288s 0.001s
im_detect: 3054/4024 0.288s 0.001s
im_detect: 3055/4024 0.288s 0.001s
im_detect: 3056/4024 0.288s 0.001s
im_detect: 3057/4024 0.288s 0.001s
im_detect: 3058/4024 0.288s 0.001s
im_detect: 3059/4024 0.288s 0.001s
im_detect: 3060/4024 0.288s 0.001s
im_detect: 3061/4024 0.288s 0.001s
im_detect: 3062/4024 0.288s 0.001s
im_detect: 3063/4024 0.288s 0.001s
im_detect: 3064/4024 0.288s 0.001s
im_detect: 3065/4024 0.288s 0.001s
im_detect: 3066/4024 0.288s 0.001s
im_detect: 3067/4024 0.288s 0.001s
im_detect: 3068/4024 0.288s 0.001s
im_detect: 3069/4024 0.288s 0.001s
im_detect: 3070/4024 0.288s 0.001s
im_detect: 3071/4024 0.288s 0.001s
im_detect: 3072/4024 0.288s 0.001s
im_detect: 3073/4024 0.288s 0.001s
im_detect: 3074/4024 0.288s 0.001s
im_detect: 3075/4024 0.288s 0.001s
im_detect: 3076/4024 0.288s 0.001s
im_detect: 3077/4024 0.288s 0.001s
im_detect: 3078/4024 0.288s 0.001s
im_detect: 3079/4024 0.288s 0.001s
im_detect: 3080/4024 0.288s 0.001s
im_detect: 3081/4024 0.288s 0.001s
im_detect: 3082/4024 0.288s 0.001s
im_detect: 3083/4024 0.288s 0.001s
im_detect: 3084/4024 0.288s 0.001s
im_detect: 3085/4024 0.288s 0.001s
im_detect: 3086/4024 0.288s 0.001s
im_detect: 3087/4024 0.288s 0.001s
im_detect: 3088/4024 0.288s 0.001s
im_detect: 3089/4024 0.288s 0.001s
im_detect: 3090/4024 0.288s 0.001s
im_detect: 3091/4024 0.288s 0.001s
im_detect: 3092/4024 0.288s 0.001s
im_detect: 3093/4024 0.288s 0.001s
im_detect: 3094/4024 0.288s 0.001s
im_detect: 3095/4024 0.288s 0.001s
im_detect: 3096/4024 0.288s 0.001s
im_detect: 3097/4024 0.288s 0.001s
im_detect: 3098/4024 0.288s 0.001s
im_detect: 3099/4024 0.288s 0.001s
im_detect: 3100/4024 0.288s 0.001s
im_detect: 3101/4024 0.288s 0.001s
im_detect: 3102/4024 0.288s 0.001s
im_detect: 3103/4024 0.288s 0.001s
im_detect: 3104/4024 0.288s 0.001s
im_detect: 3105/4024 0.288s 0.001s
im_detect: 3106/4024 0.288s 0.001s
im_detect: 3107/4024 0.288s 0.001s
im_detect: 3108/4024 0.288s 0.001s
im_detect: 3109/4024 0.288s 0.001s
im_detect: 3110/4024 0.288s 0.001s
im_detect: 3111/4024 0.288s 0.001s
im_detect: 3112/4024 0.288s 0.001s
im_detect: 3113/4024 0.288s 0.001s
im_detect: 3114/4024 0.288s 0.001s
im_detect: 3115/4024 0.288s 0.001s
im_detect: 3116/4024 0.288s 0.001s
im_detect: 3117/4024 0.288s 0.001s
im_detect: 3118/4024 0.288s 0.001s
im_detect: 3119/4024 0.288s 0.001s
im_detect: 3120/4024 0.288s 0.001s
im_detect: 3121/4024 0.288s 0.001s
im_detect: 3122/4024 0.288s 0.001s
im_detect: 3123/4024 0.288s 0.001s
im_detect: 3124/4024 0.288s 0.001s
im_detect: 3125/4024 0.288s 0.001s
im_detect: 3126/4024 0.288s 0.001s
im_detect: 3127/4024 0.288s 0.001s
im_detect: 3128/4024 0.288s 0.001s
im_detect: 3129/4024 0.288s 0.001s
im_detect: 3130/4024 0.288s 0.001s
im_detect: 3131/4024 0.288s 0.001s
im_detect: 3132/4024 0.288s 0.001s
im_detect: 3133/4024 0.288s 0.001s
im_detect: 3134/4024 0.288s 0.001s
im_detect: 3135/4024 0.288s 0.001s
im_detect: 3136/4024 0.288s 0.001s
im_detect: 3137/4024 0.288s 0.001s
im_detect: 3138/4024 0.288s 0.001s
im_detect: 3139/4024 0.288s 0.001s
im_detect: 3140/4024 0.288s 0.001s
im_detect: 3141/4024 0.288s 0.001s
im_detect: 3142/4024 0.288s 0.001s
im_detect: 3143/4024 0.288s 0.001s
im_detect: 3144/4024 0.288s 0.001s
im_detect: 3145/4024 0.288s 0.001s
im_detect: 3146/4024 0.288s 0.001s
im_detect: 3147/4024 0.288s 0.001s
im_detect: 3148/4024 0.288s 0.001s
im_detect: 3149/4024 0.288s 0.001s
im_detect: 3150/4024 0.288s 0.001s
im_detect: 3151/4024 0.288s 0.001s
im_detect: 3152/4024 0.288s 0.001s
im_detect: 3153/4024 0.288s 0.001s
im_detect: 3154/4024 0.288s 0.001s
im_detect: 3155/4024 0.288s 0.001s
im_detect: 3156/4024 0.288s 0.001s
im_detect: 3157/4024 0.288s 0.001s
im_detect: 3158/4024 0.288s 0.001s
im_detect: 3159/4024 0.288s 0.001s
im_detect: 3160/4024 0.288s 0.001s
im_detect: 3161/4024 0.288s 0.001s
im_detect: 3162/4024 0.288s 0.001s
im_detect: 3163/4024 0.288s 0.001s
im_detect: 3164/4024 0.288s 0.001s
im_detect: 3165/4024 0.288s 0.001s
im_detect: 3166/4024 0.288s 0.001s
im_detect: 3167/4024 0.288s 0.001s
im_detect: 3168/4024 0.288s 0.001s
im_detect: 3169/4024 0.288s 0.001s
im_detect: 3170/4024 0.288s 0.001s
im_detect: 3171/4024 0.288s 0.001s
im_detect: 3172/4024 0.288s 0.001s
im_detect: 3173/4024 0.288s 0.001s
im_detect: 3174/4024 0.288s 0.001s
im_detect: 3175/4024 0.288s 0.001s
im_detect: 3176/4024 0.288s 0.001s
im_detect: 3177/4024 0.288s 0.001s
im_detect: 3178/4024 0.288s 0.001s
im_detect: 3179/4024 0.288s 0.001s
im_detect: 3180/4024 0.288s 0.001s
im_detect: 3181/4024 0.288s 0.001s
im_detect: 3182/4024 0.288s 0.001s
im_detect: 3183/4024 0.288s 0.001s
im_detect: 3184/4024 0.288s 0.001s
im_detect: 3185/4024 0.288s 0.001s
im_detect: 3186/4024 0.288s 0.001s
im_detect: 3187/4024 0.288s 0.001s
im_detect: 3188/4024 0.288s 0.001s
im_detect: 3189/4024 0.288s 0.001s
im_detect: 3190/4024 0.288s 0.001s
im_detect: 3191/4024 0.288s 0.001s
im_detect: 3192/4024 0.288s 0.001s
im_detect: 3193/4024 0.288s 0.001s
im_detect: 3194/4024 0.288s 0.001s
im_detect: 3195/4024 0.288s 0.001s
im_detect: 3196/4024 0.288s 0.001s
im_detect: 3197/4024 0.288s 0.001s
im_detect: 3198/4024 0.288s 0.001s
im_detect: 3199/4024 0.288s 0.001s
im_detect: 3200/4024 0.288s 0.001s
im_detect: 3201/4024 0.288s 0.001s
im_detect: 3202/4024 0.288s 0.001s
im_detect: 3203/4024 0.288s 0.001s
im_detect: 3204/4024 0.288s 0.001s
im_detect: 3205/4024 0.288s 0.001s
im_detect: 3206/4024 0.288s 0.001s
im_detect: 3207/4024 0.288s 0.001s
im_detect: 3208/4024 0.288s 0.001s
im_detect: 3209/4024 0.288s 0.001s
im_detect: 3210/4024 0.288s 0.001s
im_detect: 3211/4024 0.288s 0.001s
im_detect: 3212/4024 0.288s 0.001s
im_detect: 3213/4024 0.288s 0.001s
im_detect: 3214/4024 0.288s 0.001s
im_detect: 3215/4024 0.288s 0.001s
im_detect: 3216/4024 0.288s 0.001s
im_detect: 3217/4024 0.288s 0.001s
im_detect: 3218/4024 0.288s 0.001s
im_detect: 3219/4024 0.288s 0.001s
im_detect: 3220/4024 0.288s 0.001s
im_detect: 3221/4024 0.288s 0.001s
im_detect: 3222/4024 0.288s 0.001s
im_detect: 3223/4024 0.288s 0.001s
im_detect: 3224/4024 0.288s 0.001s
im_detect: 3225/4024 0.288s 0.001s
im_detect: 3226/4024 0.288s 0.001s
im_detect: 3227/4024 0.288s 0.001s
im_detect: 3228/4024 0.288s 0.001s
im_detect: 3229/4024 0.288s 0.001s
im_detect: 3230/4024 0.288s 0.001s
im_detect: 3231/4024 0.288s 0.001s
im_detect: 3232/4024 0.288s 0.001s
im_detect: 3233/4024 0.288s 0.001s
im_detect: 3234/4024 0.288s 0.001s
im_detect: 3235/4024 0.288s 0.001s
im_detect: 3236/4024 0.288s 0.001s
im_detect: 3237/4024 0.288s 0.001s
im_detect: 3238/4024 0.288s 0.001s
im_detect: 3239/4024 0.288s 0.001s
im_detect: 3240/4024 0.288s 0.001s
im_detect: 3241/4024 0.288s 0.001s
im_detect: 3242/4024 0.288s 0.001s
im_detect: 3243/4024 0.288s 0.001s
im_detect: 3244/4024 0.288s 0.001s
im_detect: 3245/4024 0.288s 0.001s
im_detect: 3246/4024 0.288s 0.001s
im_detect: 3247/4024 0.288s 0.001s
im_detect: 3248/4024 0.288s 0.001s
im_detect: 3249/4024 0.288s 0.001s
im_detect: 3250/4024 0.288s 0.001s
im_detect: 3251/4024 0.288s 0.001s
im_detect: 3252/4024 0.288s 0.001s
im_detect: 3253/4024 0.288s 0.001s
im_detect: 3254/4024 0.288s 0.001s
im_detect: 3255/4024 0.288s 0.001s
im_detect: 3256/4024 0.288s 0.001s
im_detect: 3257/4024 0.288s 0.001s
im_detect: 3258/4024 0.288s 0.001s
im_detect: 3259/4024 0.288s 0.001s
im_detect: 3260/4024 0.288s 0.001s
im_detect: 3261/4024 0.288s 0.001s
im_detect: 3262/4024 0.288s 0.001s
im_detect: 3263/4024 0.288s 0.001s
im_detect: 3264/4024 0.288s 0.001s
im_detect: 3265/4024 0.288s 0.001s
im_detect: 3266/4024 0.288s 0.001s
im_detect: 3267/4024 0.288s 0.001s
im_detect: 3268/4024 0.288s 0.001s
im_detect: 3269/4024 0.288s 0.001s
im_detect: 3270/4024 0.288s 0.001s
im_detect: 3271/4024 0.288s 0.001s
im_detect: 3272/4024 0.288s 0.001s
im_detect: 3273/4024 0.288s 0.001s
im_detect: 3274/4024 0.288s 0.001s
im_detect: 3275/4024 0.288s 0.001s
im_detect: 3276/4024 0.288s 0.001s
im_detect: 3277/4024 0.288s 0.001s
im_detect: 3278/4024 0.288s 0.001s
im_detect: 3279/4024 0.288s 0.001s
im_detect: 3280/4024 0.288s 0.001s
im_detect: 3281/4024 0.288s 0.001s
im_detect: 3282/4024 0.288s 0.001s
im_detect: 3283/4024 0.288s 0.001s
im_detect: 3284/4024 0.288s 0.001s
im_detect: 3285/4024 0.288s 0.001s
im_detect: 3286/4024 0.288s 0.001s
im_detect: 3287/4024 0.288s 0.001s
im_detect: 3288/4024 0.288s 0.001s
im_detect: 3289/4024 0.288s 0.001s
im_detect: 3290/4024 0.288s 0.001s
im_detect: 3291/4024 0.288s 0.001s
im_detect: 3292/4024 0.288s 0.001s
im_detect: 3293/4024 0.288s 0.001s
im_detect: 3294/4024 0.288s 0.001s
im_detect: 3295/4024 0.288s 0.001s
im_detect: 3296/4024 0.288s 0.001s
im_detect: 3297/4024 0.288s 0.001s
im_detect: 3298/4024 0.288s 0.001s
im_detect: 3299/4024 0.288s 0.001s
im_detect: 3300/4024 0.288s 0.001s
im_detect: 3301/4024 0.288s 0.001s
im_detect: 3302/4024 0.288s 0.001s
im_detect: 3303/4024 0.288s 0.001s
im_detect: 3304/4024 0.288s 0.001s
im_detect: 3305/4024 0.288s 0.001s
im_detect: 3306/4024 0.288s 0.001s
im_detect: 3307/4024 0.288s 0.001s
im_detect: 3308/4024 0.288s 0.001s
im_detect: 3309/4024 0.288s 0.001s
im_detect: 3310/4024 0.288s 0.001s
im_detect: 3311/4024 0.288s 0.001s
im_detect: 3312/4024 0.288s 0.001s
im_detect: 3313/4024 0.288s 0.001s
im_detect: 3314/4024 0.288s 0.001s
im_detect: 3315/4024 0.288s 0.001s
im_detect: 3316/4024 0.288s 0.001s
im_detect: 3317/4024 0.288s 0.001s
im_detect: 3318/4024 0.288s 0.001s
im_detect: 3319/4024 0.288s 0.001s
im_detect: 3320/4024 0.288s 0.001s
im_detect: 3321/4024 0.288s 0.001s
im_detect: 3322/4024 0.288s 0.001s
im_detect: 3323/4024 0.288s 0.001s
im_detect: 3324/4024 0.288s 0.001s
im_detect: 3325/4024 0.288s 0.001s
im_detect: 3326/4024 0.288s 0.001s
im_detect: 3327/4024 0.288s 0.001s
im_detect: 3328/4024 0.288s 0.001s
im_detect: 3329/4024 0.288s 0.001s
im_detect: 3330/4024 0.288s 0.001s
im_detect: 3331/4024 0.288s 0.001s
im_detect: 3332/4024 0.288s 0.001s
im_detect: 3333/4024 0.288s 0.001s
im_detect: 3334/4024 0.288s 0.001s
im_detect: 3335/4024 0.288s 0.001s
im_detect: 3336/4024 0.288s 0.001s
im_detect: 3337/4024 0.288s 0.001s
im_detect: 3338/4024 0.288s 0.001s
im_detect: 3339/4024 0.288s 0.001s
im_detect: 3340/4024 0.288s 0.001s
im_detect: 3341/4024 0.288s 0.001s
im_detect: 3342/4024 0.288s 0.001s
im_detect: 3343/4024 0.288s 0.001s
im_detect: 3344/4024 0.288s 0.001s
im_detect: 3345/4024 0.288s 0.001s
im_detect: 3346/4024 0.288s 0.001s
im_detect: 3347/4024 0.288s 0.001s
im_detect: 3348/4024 0.288s 0.001s
im_detect: 3349/4024 0.288s 0.001s
im_detect: 3350/4024 0.288s 0.001s
im_detect: 3351/4024 0.288s 0.001s
im_detect: 3352/4024 0.288s 0.001s
im_detect: 3353/4024 0.288s 0.001s
im_detect: 3354/4024 0.288s 0.001s
im_detect: 3355/4024 0.288s 0.001s
im_detect: 3356/4024 0.288s 0.001s
im_detect: 3357/4024 0.288s 0.001s
im_detect: 3358/4024 0.288s 0.001s
im_detect: 3359/4024 0.288s 0.001s
im_detect: 3360/4024 0.288s 0.001s
im_detect: 3361/4024 0.288s 0.001s
im_detect: 3362/4024 0.288s 0.001s
im_detect: 3363/4024 0.288s 0.001s
im_detect: 3364/4024 0.288s 0.001s
im_detect: 3365/4024 0.288s 0.001s
im_detect: 3366/4024 0.288s 0.001s
im_detect: 3367/4024 0.288s 0.001s
im_detect: 3368/4024 0.288s 0.001s
im_detect: 3369/4024 0.288s 0.001s
im_detect: 3370/4024 0.288s 0.001s
im_detect: 3371/4024 0.288s 0.001s
im_detect: 3372/4024 0.288s 0.001s
im_detect: 3373/4024 0.288s 0.001s
im_detect: 3374/4024 0.288s 0.001s
im_detect: 3375/4024 0.288s 0.001s
im_detect: 3376/4024 0.288s 0.001s
im_detect: 3377/4024 0.288s 0.001s
im_detect: 3378/4024 0.288s 0.001s
im_detect: 3379/4024 0.288s 0.001s
im_detect: 3380/4024 0.288s 0.001s
im_detect: 3381/4024 0.288s 0.001s
im_detect: 3382/4024 0.288s 0.001s
im_detect: 3383/4024 0.288s 0.001s
im_detect: 3384/4024 0.288s 0.001s
im_detect: 3385/4024 0.288s 0.001s
im_detect: 3386/4024 0.288s 0.001s
im_detect: 3387/4024 0.288s 0.001s
im_detect: 3388/4024 0.288s 0.001s
im_detect: 3389/4024 0.288s 0.001s
im_detect: 3390/4024 0.288s 0.001s
im_detect: 3391/4024 0.288s 0.001s
im_detect: 3392/4024 0.288s 0.001s
im_detect: 3393/4024 0.288s 0.001s
im_detect: 3394/4024 0.288s 0.001s
im_detect: 3395/4024 0.288s 0.001s
im_detect: 3396/4024 0.288s 0.001s
im_detect: 3397/4024 0.288s 0.001s
im_detect: 3398/4024 0.288s 0.001s
im_detect: 3399/4024 0.288s 0.001s
im_detect: 3400/4024 0.288s 0.001s
im_detect: 3401/4024 0.288s 0.001s
im_detect: 3402/4024 0.288s 0.001s
im_detect: 3403/4024 0.288s 0.001s
im_detect: 3404/4024 0.288s 0.001s
im_detect: 3405/4024 0.288s 0.001s
im_detect: 3406/4024 0.288s 0.001s
im_detect: 3407/4024 0.288s 0.001s
im_detect: 3408/4024 0.288s 0.001s
im_detect: 3409/4024 0.288s 0.001s
im_detect: 3410/4024 0.288s 0.001s
im_detect: 3411/4024 0.288s 0.001s
im_detect: 3412/4024 0.288s 0.001s
im_detect: 3413/4024 0.288s 0.001s
im_detect: 3414/4024 0.288s 0.001s
im_detect: 3415/4024 0.288s 0.001s
im_detect: 3416/4024 0.288s 0.001s
im_detect: 3417/4024 0.288s 0.001s
im_detect: 3418/4024 0.288s 0.001s
im_detect: 3419/4024 0.288s 0.001s
im_detect: 3420/4024 0.288s 0.001s
im_detect: 3421/4024 0.288s 0.001s
im_detect: 3422/4024 0.288s 0.001s
im_detect: 3423/4024 0.288s 0.001s
im_detect: 3424/4024 0.288s 0.001s
im_detect: 3425/4024 0.288s 0.001s
im_detect: 3426/4024 0.288s 0.001s
im_detect: 3427/4024 0.288s 0.001s
im_detect: 3428/4024 0.288s 0.001s
im_detect: 3429/4024 0.288s 0.001s
im_detect: 3430/4024 0.288s 0.001s
im_detect: 3431/4024 0.288s 0.001s
im_detect: 3432/4024 0.288s 0.001s
im_detect: 3433/4024 0.288s 0.001s
im_detect: 3434/4024 0.288s 0.001s
im_detect: 3435/4024 0.288s 0.001s
im_detect: 3436/4024 0.288s 0.001s
im_detect: 3437/4024 0.288s 0.001s
im_detect: 3438/4024 0.288s 0.001s
im_detect: 3439/4024 0.288s 0.001s
im_detect: 3440/4024 0.288s 0.001s
im_detect: 3441/4024 0.288s 0.001s
im_detect: 3442/4024 0.288s 0.001s
im_detect: 3443/4024 0.288s 0.001s
im_detect: 3444/4024 0.288s 0.001s
im_detect: 3445/4024 0.288s 0.001s
im_detect: 3446/4024 0.288s 0.001s
im_detect: 3447/4024 0.288s 0.001s
im_detect: 3448/4024 0.288s 0.001s
im_detect: 3449/4024 0.288s 0.001s
im_detect: 3450/4024 0.288s 0.001s
im_detect: 3451/4024 0.288s 0.001s
im_detect: 3452/4024 0.288s 0.001s
im_detect: 3453/4024 0.288s 0.001s
im_detect: 3454/4024 0.288s 0.001s
im_detect: 3455/4024 0.288s 0.001s
im_detect: 3456/4024 0.288s 0.001s
im_detect: 3457/4024 0.288s 0.001s
im_detect: 3458/4024 0.288s 0.001s
im_detect: 3459/4024 0.288s 0.001s
im_detect: 3460/4024 0.288s 0.001s
im_detect: 3461/4024 0.288s 0.001s
im_detect: 3462/4024 0.288s 0.001s
im_detect: 3463/4024 0.288s 0.001s
im_detect: 3464/4024 0.288s 0.001s
im_detect: 3465/4024 0.288s 0.001s
im_detect: 3466/4024 0.288s 0.001s
im_detect: 3467/4024 0.288s 0.001s
im_detect: 3468/4024 0.288s 0.001s
im_detect: 3469/4024 0.288s 0.001s
im_detect: 3470/4024 0.288s 0.001s
im_detect: 3471/4024 0.288s 0.001s
im_detect: 3472/4024 0.288s 0.001s
im_detect: 3473/4024 0.288s 0.001s
im_detect: 3474/4024 0.288s 0.001s
im_detect: 3475/4024 0.288s 0.001s
im_detect: 3476/4024 0.288s 0.001s
im_detect: 3477/4024 0.288s 0.001s
im_detect: 3478/4024 0.288s 0.001s
im_detect: 3479/4024 0.288s 0.001s
im_detect: 3480/4024 0.288s 0.001s
im_detect: 3481/4024 0.288s 0.001s
im_detect: 3482/4024 0.288s 0.001s
im_detect: 3483/4024 0.288s 0.001s
im_detect: 3484/4024 0.288s 0.001s
im_detect: 3485/4024 0.288s 0.001s
im_detect: 3486/4024 0.288s 0.001s
im_detect: 3487/4024 0.288s 0.001s
im_detect: 3488/4024 0.288s 0.001s
im_detect: 3489/4024 0.288s 0.001s
im_detect: 3490/4024 0.288s 0.001s
im_detect: 3491/4024 0.288s 0.001s
im_detect: 3492/4024 0.288s 0.001s
im_detect: 3493/4024 0.288s 0.001s
im_detect: 3494/4024 0.288s 0.001s
im_detect: 3495/4024 0.288s 0.001s
im_detect: 3496/4024 0.288s 0.001s
im_detect: 3497/4024 0.288s 0.001s
im_detect: 3498/4024 0.288s 0.001s
im_detect: 3499/4024 0.288s 0.001s
im_detect: 3500/4024 0.288s 0.001s
im_detect: 3501/4024 0.288s 0.001s
im_detect: 3502/4024 0.288s 0.001s
im_detect: 3503/4024 0.288s 0.001s
im_detect: 3504/4024 0.288s 0.001s
im_detect: 3505/4024 0.288s 0.001s
im_detect: 3506/4024 0.288s 0.001s
im_detect: 3507/4024 0.288s 0.001s
im_detect: 3508/4024 0.288s 0.001s
im_detect: 3509/4024 0.288s 0.001s
im_detect: 3510/4024 0.288s 0.001s
im_detect: 3511/4024 0.288s 0.001s
im_detect: 3512/4024 0.288s 0.001s
im_detect: 3513/4024 0.288s 0.001s
im_detect: 3514/4024 0.288s 0.001s
im_detect: 3515/4024 0.288s 0.001s
im_detect: 3516/4024 0.288s 0.001s
im_detect: 3517/4024 0.288s 0.001s
im_detect: 3518/4024 0.288s 0.001s
im_detect: 3519/4024 0.288s 0.001s
im_detect: 3520/4024 0.288s 0.001s
im_detect: 3521/4024 0.288s 0.001s
im_detect: 3522/4024 0.288s 0.001s
im_detect: 3523/4024 0.288s 0.001s
im_detect: 3524/4024 0.288s 0.001s
im_detect: 3525/4024 0.288s 0.001s
im_detect: 3526/4024 0.288s 0.001s
im_detect: 3527/4024 0.288s 0.001s
im_detect: 3528/4024 0.288s 0.001s
im_detect: 3529/4024 0.288s 0.001s
im_detect: 3530/4024 0.288s 0.001s
im_detect: 3531/4024 0.288s 0.001s
im_detect: 3532/4024 0.288s 0.001s
im_detect: 3533/4024 0.288s 0.001s
im_detect: 3534/4024 0.288s 0.001s
im_detect: 3535/4024 0.288s 0.001s
im_detect: 3536/4024 0.288s 0.001s
im_detect: 3537/4024 0.288s 0.001s
im_detect: 3538/4024 0.288s 0.001s
im_detect: 3539/4024 0.288s 0.001s
im_detect: 3540/4024 0.288s 0.001s
im_detect: 3541/4024 0.288s 0.001s
im_detect: 3542/4024 0.288s 0.001s
im_detect: 3543/4024 0.288s 0.001s
im_detect: 3544/4024 0.288s 0.001s
im_detect: 3545/4024 0.288s 0.001s
im_detect: 3546/4024 0.288s 0.001s
im_detect: 3547/4024 0.288s 0.001s
im_detect: 3548/4024 0.288s 0.001s
im_detect: 3549/4024 0.288s 0.001s
im_detect: 3550/4024 0.288s 0.001s
im_detect: 3551/4024 0.288s 0.001s
im_detect: 3552/4024 0.288s 0.001s
im_detect: 3553/4024 0.288s 0.001s
im_detect: 3554/4024 0.288s 0.001s
im_detect: 3555/4024 0.288s 0.001s
im_detect: 3556/4024 0.288s 0.001s
im_detect: 3557/4024 0.288s 0.001s
im_detect: 3558/4024 0.288s 0.001s
im_detect: 3559/4024 0.288s 0.001s
im_detect: 3560/4024 0.288s 0.001s
im_detect: 3561/4024 0.288s 0.001s
im_detect: 3562/4024 0.288s 0.001s
im_detect: 3563/4024 0.288s 0.001s
im_detect: 3564/4024 0.288s 0.001s
im_detect: 3565/4024 0.288s 0.001s
im_detect: 3566/4024 0.288s 0.001s
im_detect: 3567/4024 0.288s 0.001s
im_detect: 3568/4024 0.288s 0.001s
im_detect: 3569/4024 0.288s 0.001s
im_detect: 3570/4024 0.288s 0.001s
im_detect: 3571/4024 0.288s 0.001s
im_detect: 3572/4024 0.288s 0.001s
im_detect: 3573/4024 0.288s 0.001s
im_detect: 3574/4024 0.288s 0.001s
im_detect: 3575/4024 0.288s 0.001s
im_detect: 3576/4024 0.288s 0.001s
im_detect: 3577/4024 0.288s 0.001s
im_detect: 3578/4024 0.288s 0.001s
im_detect: 3579/4024 0.288s 0.001s
im_detect: 3580/4024 0.288s 0.001s
im_detect: 3581/4024 0.288s 0.001s
im_detect: 3582/4024 0.288s 0.001s
im_detect: 3583/4024 0.288s 0.001s
im_detect: 3584/4024 0.288s 0.001s
im_detect: 3585/4024 0.288s 0.001s
im_detect: 3586/4024 0.288s 0.001s
im_detect: 3587/4024 0.288s 0.001s
im_detect: 3588/4024 0.288s 0.001s
im_detect: 3589/4024 0.288s 0.001s
im_detect: 3590/4024 0.288s 0.001s
im_detect: 3591/4024 0.288s 0.001s
im_detect: 3592/4024 0.288s 0.001s
im_detect: 3593/4024 0.288s 0.001s
im_detect: 3594/4024 0.288s 0.001s
im_detect: 3595/4024 0.288s 0.001s
im_detect: 3596/4024 0.288s 0.001s
im_detect: 3597/4024 0.288s 0.001s
im_detect: 3598/4024 0.288s 0.001s
im_detect: 3599/4024 0.288s 0.001s
im_detect: 3600/4024 0.288s 0.001s
im_detect: 3601/4024 0.288s 0.001s
im_detect: 3602/4024 0.288s 0.001s
im_detect: 3603/4024 0.288s 0.001s
im_detect: 3604/4024 0.288s 0.001s
im_detect: 3605/4024 0.288s 0.001s
im_detect: 3606/4024 0.288s 0.001s
im_detect: 3607/4024 0.288s 0.001s
im_detect: 3608/4024 0.288s 0.001s
im_detect: 3609/4024 0.288s 0.001s
im_detect: 3610/4024 0.288s 0.001s
im_detect: 3611/4024 0.288s 0.001s
im_detect: 3612/4024 0.288s 0.001s
im_detect: 3613/4024 0.288s 0.001s
im_detect: 3614/4024 0.288s 0.001s
im_detect: 3615/4024 0.288s 0.001s
im_detect: 3616/4024 0.288s 0.001s
im_detect: 3617/4024 0.288s 0.001s
im_detect: 3618/4024 0.288s 0.001s
im_detect: 3619/4024 0.288s 0.001s
im_detect: 3620/4024 0.288s 0.001s
im_detect: 3621/4024 0.288s 0.001s
im_detect: 3622/4024 0.288s 0.001s
im_detect: 3623/4024 0.288s 0.001s
im_detect: 3624/4024 0.288s 0.001s
im_detect: 3625/4024 0.288s 0.001s
im_detect: 3626/4024 0.288s 0.001s
im_detect: 3627/4024 0.288s 0.001s
im_detect: 3628/4024 0.288s 0.001s
im_detect: 3629/4024 0.288s 0.001s
im_detect: 3630/4024 0.288s 0.001s
im_detect: 3631/4024 0.288s 0.001s
im_detect: 3632/4024 0.288s 0.001s
im_detect: 3633/4024 0.288s 0.001s
im_detect: 3634/4024 0.288s 0.001s
im_detect: 3635/4024 0.288s 0.001s
im_detect: 3636/4024 0.288s 0.001s
im_detect: 3637/4024 0.288s 0.001s
im_detect: 3638/4024 0.288s 0.001s
im_detect: 3639/4024 0.288s 0.001s
im_detect: 3640/4024 0.288s 0.001s
im_detect: 3641/4024 0.288s 0.001s
im_detect: 3642/4024 0.288s 0.001s
im_detect: 3643/4024 0.288s 0.001s
im_detect: 3644/4024 0.288s 0.001s
im_detect: 3645/4024 0.288s 0.001s
im_detect: 3646/4024 0.288s 0.001s
im_detect: 3647/4024 0.288s 0.001s
im_detect: 3648/4024 0.288s 0.001s
im_detect: 3649/4024 0.288s 0.001s
im_detect: 3650/4024 0.288s 0.001s
im_detect: 3651/4024 0.288s 0.001s
im_detect: 3652/4024 0.288s 0.001s
im_detect: 3653/4024 0.288s 0.001s
im_detect: 3654/4024 0.288s 0.001s
im_detect: 3655/4024 0.288s 0.001s
im_detect: 3656/4024 0.288s 0.001s
im_detect: 3657/4024 0.288s 0.001s
im_detect: 3658/4024 0.288s 0.001s
im_detect: 3659/4024 0.288s 0.001s
im_detect: 3660/4024 0.288s 0.001s
im_detect: 3661/4024 0.288s 0.001s
im_detect: 3662/4024 0.288s 0.001s
im_detect: 3663/4024 0.288s 0.001s
im_detect: 3664/4024 0.288s 0.001s
im_detect: 3665/4024 0.288s 0.001s
im_detect: 3666/4024 0.288s 0.001s
im_detect: 3667/4024 0.288s 0.001s
im_detect: 3668/4024 0.288s 0.001s
im_detect: 3669/4024 0.288s 0.001s
im_detect: 3670/4024 0.288s 0.001s
im_detect: 3671/4024 0.288s 0.001s
im_detect: 3672/4024 0.288s 0.001s
im_detect: 3673/4024 0.288s 0.001s
im_detect: 3674/4024 0.288s 0.001s
im_detect: 3675/4024 0.288s 0.001s
im_detect: 3676/4024 0.288s 0.001s
im_detect: 3677/4024 0.288s 0.001s
im_detect: 3678/4024 0.288s 0.001s
im_detect: 3679/4024 0.288s 0.001s
im_detect: 3680/4024 0.288s 0.001s
im_detect: 3681/4024 0.288s 0.001s
im_detect: 3682/4024 0.288s 0.001s
im_detect: 3683/4024 0.288s 0.001s
im_detect: 3684/4024 0.288s 0.001s
im_detect: 3685/4024 0.288s 0.001s
im_detect: 3686/4024 0.288s 0.001s
im_detect: 3687/4024 0.288s 0.001s
im_detect: 3688/4024 0.288s 0.001s
im_detect: 3689/4024 0.288s 0.001s
im_detect: 3690/4024 0.288s 0.001s
im_detect: 3691/4024 0.288s 0.001s
im_detect: 3692/4024 0.288s 0.001s
im_detect: 3693/4024 0.288s 0.001s
im_detect: 3694/4024 0.288s 0.001s
im_detect: 3695/4024 0.288s 0.001s
im_detect: 3696/4024 0.288s 0.001s
im_detect: 3697/4024 0.288s 0.001s
im_detect: 3698/4024 0.288s 0.001s
im_detect: 3699/4024 0.288s 0.001s
im_detect: 3700/4024 0.288s 0.001s
im_detect: 3701/4024 0.288s 0.001s
im_detect: 3702/4024 0.288s 0.001s
im_detect: 3703/4024 0.288s 0.001s
im_detect: 3704/4024 0.288s 0.001s
im_detect: 3705/4024 0.288s 0.001s
im_detect: 3706/4024 0.288s 0.001s
im_detect: 3707/4024 0.288s 0.001s
im_detect: 3708/4024 0.288s 0.001s
im_detect: 3709/4024 0.288s 0.001s
im_detect: 3710/4024 0.288s 0.001s
im_detect: 3711/4024 0.288s 0.001s
im_detect: 3712/4024 0.288s 0.001s
im_detect: 3713/4024 0.288s 0.001s
im_detect: 3714/4024 0.288s 0.001s
im_detect: 3715/4024 0.288s 0.001s
im_detect: 3716/4024 0.288s 0.001s
im_detect: 3717/4024 0.288s 0.001s
im_detect: 3718/4024 0.288s 0.001s
im_detect: 3719/4024 0.288s 0.001s
im_detect: 3720/4024 0.288s 0.001s
im_detect: 3721/4024 0.288s 0.001s
im_detect: 3722/4024 0.288s 0.001s
im_detect: 3723/4024 0.288s 0.001s
im_detect: 3724/4024 0.288s 0.001s
im_detect: 3725/4024 0.288s 0.001s
im_detect: 3726/4024 0.288s 0.001s
im_detect: 3727/4024 0.288s 0.001s
im_detect: 3728/4024 0.288s 0.001s
im_detect: 3729/4024 0.288s 0.001s
im_detect: 3730/4024 0.288s 0.001s
im_detect: 3731/4024 0.288s 0.001s
im_detect: 3732/4024 0.288s 0.001s
im_detect: 3733/4024 0.288s 0.001s
im_detect: 3734/4024 0.288s 0.001s
im_detect: 3735/4024 0.288s 0.001s
im_detect: 3736/4024 0.288s 0.001s
im_detect: 3737/4024 0.288s 0.001s
im_detect: 3738/4024 0.288s 0.001s
im_detect: 3739/4024 0.288s 0.001s
im_detect: 3740/4024 0.288s 0.001s
im_detect: 3741/4024 0.288s 0.001s
im_detect: 3742/4024 0.288s 0.001s
im_detect: 3743/4024 0.288s 0.001s
im_detect: 3744/4024 0.288s 0.001s
im_detect: 3745/4024 0.288s 0.001s
im_detect: 3746/4024 0.288s 0.001s
im_detect: 3747/4024 0.288s 0.001s
im_detect: 3748/4024 0.288s 0.001s
im_detect: 3749/4024 0.288s 0.001s
im_detect: 3750/4024 0.288s 0.001s
im_detect: 3751/4024 0.288s 0.001s
im_detect: 3752/4024 0.288s 0.001s
im_detect: 3753/4024 0.288s 0.001s
im_detect: 3754/4024 0.288s 0.001s
im_detect: 3755/4024 0.288s 0.001s
im_detect: 3756/4024 0.288s 0.001s
im_detect: 3757/4024 0.288s 0.001s
im_detect: 3758/4024 0.288s 0.001s
im_detect: 3759/4024 0.288s 0.001s
im_detect: 3760/4024 0.288s 0.001s
im_detect: 3761/4024 0.288s 0.001s
im_detect: 3762/4024 0.288s 0.001s
im_detect: 3763/4024 0.288s 0.001s
im_detect: 3764/4024 0.288s 0.001s
im_detect: 3765/4024 0.288s 0.001s
im_detect: 3766/4024 0.288s 0.001s
im_detect: 3767/4024 0.288s 0.001s
im_detect: 3768/4024 0.288s 0.001s
im_detect: 3769/4024 0.288s 0.001s
im_detect: 3770/4024 0.288s 0.001s
im_detect: 3771/4024 0.288s 0.001s
im_detect: 3772/4024 0.288s 0.001s
im_detect: 3773/4024 0.288s 0.001s
im_detect: 3774/4024 0.288s 0.001s
im_detect: 3775/4024 0.288s 0.001s
im_detect: 3776/4024 0.288s 0.001s
im_detect: 3777/4024 0.288s 0.001s
im_detect: 3778/4024 0.288s 0.001s
im_detect: 3779/4024 0.288s 0.001s
im_detect: 3780/4024 0.288s 0.001s
im_detect: 3781/4024 0.288s 0.001s
im_detect: 3782/4024 0.288s 0.001s
im_detect: 3783/4024 0.288s 0.001s
im_detect: 3784/4024 0.288s 0.001s
im_detect: 3785/4024 0.288s 0.001s
im_detect: 3786/4024 0.288s 0.001s
im_detect: 3787/4024 0.288s 0.001s
im_detect: 3788/4024 0.288s 0.001s
im_detect: 3789/4024 0.288s 0.001s
im_detect: 3790/4024 0.288s 0.001s
im_detect: 3791/4024 0.288s 0.001s
im_detect: 3792/4024 0.288s 0.001s
im_detect: 3793/4024 0.288s 0.001s
im_detect: 3794/4024 0.288s 0.001s
im_detect: 3795/4024 0.288s 0.001s
im_detect: 3796/4024 0.288s 0.001s
im_detect: 3797/4024 0.288s 0.001s
im_detect: 3798/4024 0.288s 0.001s
im_detect: 3799/4024 0.288s 0.001s
im_detect: 3800/4024 0.288s 0.001s
im_detect: 3801/4024 0.288s 0.001s
im_detect: 3802/4024 0.288s 0.001s
im_detect: 3803/4024 0.288s 0.001s
im_detect: 3804/4024 0.288s 0.001s
im_detect: 3805/4024 0.288s 0.001s
im_detect: 3806/4024 0.288s 0.001s
im_detect: 3807/4024 0.288s 0.001s
im_detect: 3808/4024 0.288s 0.001s
im_detect: 3809/4024 0.288s 0.001s
im_detect: 3810/4024 0.288s 0.001s
im_detect: 3811/4024 0.288s 0.001s
im_detect: 3812/4024 0.288s 0.001s
im_detect: 3813/4024 0.288s 0.001s
im_detect: 3814/4024 0.288s 0.001s
im_detect: 3815/4024 0.288s 0.001s
im_detect: 3816/4024 0.288s 0.001s
im_detect: 3817/4024 0.288s 0.001s
im_detect: 3818/4024 0.288s 0.001s
im_detect: 3819/4024 0.288s 0.001s
im_detect: 3820/4024 0.288s 0.001s
im_detect: 3821/4024 0.288s 0.001s
im_detect: 3822/4024 0.288s 0.001s
im_detect: 3823/4024 0.288s 0.001s
im_detect: 3824/4024 0.288s 0.001s
im_detect: 3825/4024 0.288s 0.001s
im_detect: 3826/4024 0.288s 0.001s
im_detect: 3827/4024 0.288s 0.001s
im_detect: 3828/4024 0.288s 0.001s
im_detect: 3829/4024 0.288s 0.001s
im_detect: 3830/4024 0.288s 0.001s
im_detect: 3831/4024 0.288s 0.001s
im_detect: 3832/4024 0.288s 0.001s
im_detect: 3833/4024 0.288s 0.001s
im_detect: 3834/4024 0.288s 0.001s
im_detect: 3835/4024 0.288s 0.001s
im_detect: 3836/4024 0.288s 0.001s
im_detect: 3837/4024 0.288s 0.001s
im_detect: 3838/4024 0.288s 0.001s
im_detect: 3839/4024 0.288s 0.001s
im_detect: 3840/4024 0.288s 0.001s
im_detect: 3841/4024 0.288s 0.001s
im_detect: 3842/4024 0.288s 0.001s
im_detect: 3843/4024 0.288s 0.001s
im_detect: 3844/4024 0.288s 0.001s
im_detect: 3845/4024 0.288s 0.001s
im_detect: 3846/4024 0.288s 0.001s
im_detect: 3847/4024 0.288s 0.001s
im_detect: 3848/4024 0.288s 0.001s
im_detect: 3849/4024 0.288s 0.001s
im_detect: 3850/4024 0.288s 0.001s
im_detect: 3851/4024 0.288s 0.001s
im_detect: 3852/4024 0.288s 0.001s
im_detect: 3853/4024 0.288s 0.001s
im_detect: 3854/4024 0.288s 0.001s
im_detect: 3855/4024 0.288s 0.001s
im_detect: 3856/4024 0.288s 0.001s
im_detect: 3857/4024 0.288s 0.001s
im_detect: 3858/4024 0.288s 0.001s
im_detect: 3859/4024 0.288s 0.001s
im_detect: 3860/4024 0.288s 0.001s
im_detect: 3861/4024 0.288s 0.001s
im_detect: 3862/4024 0.288s 0.001s
im_detect: 3863/4024 0.288s 0.001s
im_detect: 3864/4024 0.288s 0.001s
im_detect: 3865/4024 0.288s 0.001s
im_detect: 3866/4024 0.288s 0.001s
im_detect: 3867/4024 0.288s 0.001s
im_detect: 3868/4024 0.288s 0.001s
im_detect: 3869/4024 0.288s 0.001s
im_detect: 3870/4024 0.288s 0.001s
im_detect: 3871/4024 0.288s 0.001s
im_detect: 3872/4024 0.288s 0.001s
im_detect: 3873/4024 0.288s 0.001s
im_detect: 3874/4024 0.288s 0.001s
im_detect: 3875/4024 0.288s 0.001s
im_detect: 3876/4024 0.288s 0.001s
im_detect: 3877/4024 0.288s 0.001s
im_detect: 3878/4024 0.288s 0.001s
im_detect: 3879/4024 0.288s 0.001s
im_detect: 3880/4024 0.288s 0.001s
im_detect: 3881/4024 0.288s 0.001s
im_detect: 3882/4024 0.288s 0.001s
im_detect: 3883/4024 0.288s 0.001s
im_detect: 3884/4024 0.288s 0.001s
im_detect: 3885/4024 0.288s 0.001s
im_detect: 3886/4024 0.288s 0.001s
im_detect: 3887/4024 0.288s 0.001s
im_detect: 3888/4024 0.288s 0.001s
im_detect: 3889/4024 0.288s 0.001s
im_detect: 3890/4024 0.288s 0.001s
im_detect: 3891/4024 0.288s 0.001s
im_detect: 3892/4024 0.288s 0.001s
im_detect: 3893/4024 0.288s 0.001s
im_detect: 3894/4024 0.288s 0.001s
im_detect: 3895/4024 0.288s 0.001s
im_detect: 3896/4024 0.288s 0.001s
im_detect: 3897/4024 0.288s 0.001s
im_detect: 3898/4024 0.288s 0.001s
im_detect: 3899/4024 0.288s 0.001s
im_detect: 3900/4024 0.288s 0.001s
im_detect: 3901/4024 0.288s 0.001s
im_detect: 3902/4024 0.288s 0.001s
im_detect: 3903/4024 0.288s 0.001s
im_detect: 3904/4024 0.288s 0.001s
im_detect: 3905/4024 0.288s 0.001s
im_detect: 3906/4024 0.288s 0.001s
im_detect: 3907/4024 0.288s 0.001s
im_detect: 3908/4024 0.288s 0.001s
im_detect: 3909/4024 0.288s 0.001s
im_detect: 3910/4024 0.288s 0.001s
im_detect: 3911/4024 0.288s 0.001s
im_detect: 3912/4024 0.288s 0.001s
im_detect: 3913/4024 0.288s 0.001s
im_detect: 3914/4024 0.288s 0.001s
im_detect: 3915/4024 0.288s 0.001s
im_detect: 3916/4024 0.288s 0.001s
im_detect: 3917/4024 0.288s 0.001s
im_detect: 3918/4024 0.288s 0.001s
im_detect: 3919/4024 0.288s 0.001s
im_detect: 3920/4024 0.288s 0.001s
im_detect: 3921/4024 0.288s 0.001s
im_detect: 3922/4024 0.288s 0.001s
im_detect: 3923/4024 0.288s 0.001s
im_detect: 3924/4024 0.288s 0.001s
im_detect: 3925/4024 0.288s 0.001s
im_detect: 3926/4024 0.288s 0.001s
im_detect: 3927/4024 0.288s 0.001s
im_detect: 3928/4024 0.288s 0.001s
im_detect: 3929/4024 0.288s 0.001s
im_detect: 3930/4024 0.288s 0.001s
im_detect: 3931/4024 0.288s 0.001s
im_detect: 3932/4024 0.288s 0.001s
im_detect: 3933/4024 0.288s 0.001s
im_detect: 3934/4024 0.288s 0.001s
im_detect: 3935/4024 0.288s 0.001s
im_detect: 3936/4024 0.288s 0.001s
im_detect: 3937/4024 0.288s 0.001s
im_detect: 3938/4024 0.288s 0.001s
im_detect: 3939/4024 0.288s 0.001s
im_detect: 3940/4024 0.288s 0.001s
im_detect: 3941/4024 0.288s 0.001s
im_detect: 3942/4024 0.288s 0.001s
im_detect: 3943/4024 0.288s 0.001s
im_detect: 3944/4024 0.288s 0.001s
im_detect: 3945/4024 0.288s 0.001s
im_detect: 3946/4024 0.288s 0.001s
im_detect: 3947/4024 0.288s 0.001s
im_detect: 3948/4024 0.288s 0.001s
im_detect: 3949/4024 0.288s 0.001s
im_detect: 3950/4024 0.288s 0.001s
im_detect: 3951/4024 0.288s 0.001s
im_detect: 3952/4024 0.288s 0.001s
im_detect: 3953/4024 0.288s 0.001s
im_detect: 3954/4024 0.288s 0.001s
im_detect: 3955/4024 0.288s 0.001s
im_detect: 3956/4024 0.288s 0.001s
im_detect: 3957/4024 0.288s 0.001s
im_detect: 3958/4024 0.288s 0.001s
im_detect: 3959/4024 0.288s 0.001s
im_detect: 3960/4024 0.288s 0.001s
im_detect: 3961/4024 0.288s 0.001s
im_detect: 3962/4024 0.288s 0.001s
im_detect: 3963/4024 0.288s 0.001s
im_detect: 3964/4024 0.288s 0.001s
im_detect: 3965/4024 0.288s 0.001s
im_detect: 3966/4024 0.288s 0.001s
im_detect: 3967/4024 0.288s 0.001s
im_detect: 3968/4024 0.288s 0.001s
im_detect: 3969/4024 0.288s 0.001s
im_detect: 3970/4024 0.288s 0.001s
im_detect: 3971/4024 0.288s 0.001s
im_detect: 3972/4024 0.288s 0.001s
im_detect: 3973/4024 0.288s 0.001s
im_detect: 3974/4024 0.288s 0.001s
im_detect: 3975/4024 0.288s 0.001s
im_detect: 3976/4024 0.288s 0.001s
im_detect: 3977/4024 0.288s 0.001s
im_detect: 3978/4024 0.288s 0.001s
im_detect: 3979/4024 0.288s 0.001s
im_detect: 3980/4024 0.288s 0.001s
im_detect: 3981/4024 0.288s 0.001s
im_detect: 3982/4024 0.288s 0.001s
im_detect: 3983/4024 0.288s 0.001s
im_detect: 3984/4024 0.288s 0.001s
im_detect: 3985/4024 0.288s 0.001s
im_detect: 3986/4024 0.288s 0.001s
im_detect: 3987/4024 0.288s 0.001s
im_detect: 3988/4024 0.288s 0.001s
im_detect: 3989/4024 0.288s 0.001s
im_detect: 3990/4024 0.288s 0.001s
im_detect: 3991/4024 0.288s 0.001s
im_detect: 3992/4024 0.288s 0.001s
im_detect: 3993/4024 0.288s 0.001s
im_detect: 3994/4024 0.288s 0.001s
im_detect: 3995/4024 0.288s 0.001s
im_detect: 3996/4024 0.288s 0.001s
im_detect: 3997/4024 0.288s 0.001s
im_detect: 3998/4024 0.288s 0.001s
im_detect: 3999/4024 0.288s 0.001s
im_detect: 4000/4024 0.288s 0.001s
im_detect: 4001/4024 0.288s 0.001s
im_detect: 4002/4024 0.288s 0.001s
im_detect: 4003/4024 0.288s 0.001s
im_detect: 4004/4024 0.288s 0.001s
im_detect: 4005/4024 0.288s 0.001s
im_detect: 4006/4024 0.288s 0.001s
im_detect: 4007/4024 0.288s 0.001s
im_detect: 4008/4024 0.288s 0.001s
im_detect: 4009/4024 0.288s 0.001s
im_detect: 4010/4024 0.288s 0.001s
im_detect: 4011/4024 0.288s 0.001s
im_detect: 4012/4024 0.288s 0.001s
im_detect: 4013/4024 0.288s 0.001s
im_detect: 4014/4024 0.288s 0.001s
im_detect: 4015/4024 0.288s 0.001s
im_detect: 4016/4024 0.288s 0.001s
im_detect: 4017/4024 0.288s 0.001s
im_detect: 4018/4024 0.288s 0.001s
im_detect: 4019/4024 0.288s 0.001s
im_detect: 4020/4024 0.288s 0.001s
im_detect: 4021/4024 0.288s 0.001s
im_detect: 4022/4024 0.288s 0.001s
im_detect: 4023/4024 0.288s 0.001s
im_detect: 4024/4024 0.288s 0.001s
Evaluating detections
Writing person VOC results file
Writing upper VOC results file
Writing head VOC results file
VOC07 metric? Yes
Traceback (most recent call last):
  File "./tools/test_net.py", line 95, in <module>
    test_net(net, imdb, max_per_image=args.max_per_image, vis=args.vis)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/fast_rcnn/test.py", line 308, in test_net
    imdb.evaluate_detections(all_boxes, output_dir)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/pascal_voc.py", line 326, in evaluate_detections
    self._do_python_eval(output_dir)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/pascal_voc.py", line 289, in _do_python_eval
    use_07_metric=use_07_metric)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/voc_eval.py", line 110, in voc_eval
    recs[imagename] = parse_rec(annopath.format(imagename))
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/voc_eval.py", line 14, in parse_rec
    tree = ET.parse(filename)
  File "/usr/lib/python2.7/xml/etree/ElementTree.py", line 1182, in parse
    tree.parse(source, parser)
  File "/usr/lib/python2.7/xml/etree/ElementTree.py", line 647, in parse
    source = open(source, "rb")
IOError: [Errno 2] No such file or directory: '/home/user/Disk1.8T/py-R-FCN/data/VOCdevkit0712/VOC0712/Annotations/set08_V003_I00689.xml'
