 + echo Logging output to experiments/6_25_upper/logs/rfcn_end2end_ResNet-50_.txt.2018-06-25_14-59-40
Logging output to experiments/6_25_upper/logs/rfcn_end2end_ResNet-50_.txt.2018-06-25_14-59-40
+ ./tools/train_net.py --gpu 1 --solver experiments/6_25_upper/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_0712_trainval --iters 32000 --cfg experiments/6_25_upper/rfcn_end2end_ohem.yml
Called with args:
Namespace(cfg_file='experiments/6_25_upper/rfcn_end2end_ohem.yml', gpu_id=1, imdb_name='voc_0712_trainval', max_iters=32000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='experiments/6_25_upper/solver_ohem.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '6_25_upper/model',
 'GPU_ID': 1,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SOFT_NMS': 1,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_0712_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_0712_trainval gt roidb loaded from /home/user/Disk1.8T/py-R-FCN/data/cache/voc_0712_trainval_gt_roidb.pkl
done
Preparing training data...
done
8500 roidb entries
Output will be saved to `/home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model`
Filtered 5544 roidb entries: 8500 -> 2956
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 14:59:42.550412  6673 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/train_agnostic_ohem.prototxt"
base_lr: 0.0002
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "resnet50_rfcn_ohem"
iter_size: 8
I0625 14:59:42.550451  6673 solver.cpp:81] Creating training net from train_net file: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/train_agnostic_ohem.prototxt
I0625 14:59:42.552716  6673 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "res4c_
I0625 14:59:42.554385  6673 layer_factory.hpp:77] Creating layer input-data
I0625 14:59:42.562796  6673 net.cpp:100] Creating Layer input-data
I0625 14:59:42.562816  6673 net.cpp:418] input-data -> data
I0625 14:59:42.562855  6673 net.cpp:418] input-data -> im_info
I0625 14:59:42.562875  6673 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0625 14:59:42.582489  6673 net.cpp:150] Setting up input-data
I0625 14:59:42.582511  6673 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0625 14:59:42.582516  6673 net.cpp:157] Top shape: 1 3 (3)
I0625 14:59:42.582520  6673 net.cpp:157] Top shape: 1 4 (4)
I0625 14:59:42.582521  6673 net.cpp:165] Memory required for data: 14745628
I0625 14:59:42.582538  6673 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 14:59:42.582566  6673 net.cpp:100] Creating Layer data_input-data_0_split
I0625 14:59:42.582576  6673 net.cpp:444] data_input-data_0_split <- data
I0625 14:59:42.582592  6673 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I0625 14:59:42.582610  6673 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I0625 14:59:42.582653  6673 net.cpp:150] Setting up data_input-data_0_split
I0625 14:59:42.582660  6673 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0625 14:59:42.582664  6673 net.cpp:157] Top shape: 1 3 960 1280 (3686400)
I0625 14:59:42.582667  6673 net.cpp:165] Memory required for data: 44236828
I0625 14:59:42.582669  6673 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 14:59:42.582679  6673 net.cpp:100] Creating Layer im_info_input-data_1_split
I0625 14:59:42.582684  6673 net.cpp:444] im_info_input-data_1_split <- im_info
I0625 14:59:42.582693  6673 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 14:59:42.582703  6673 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 14:59:42.582737  6673 net.cpp:150] Setting up im_info_input-data_1_split
I0625 14:59:42.582743  6673 net.cpp:157] Top shape: 1 3 (3)
I0625 14:59:42.582747  6673 net.cpp:157] Top shape: 1 3 (3)
I0625 14:59:42.582748  6673 net.cpp:165] Memory required for data: 44236852
I0625 14:59:42.582751  6673 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 14:59:42.582757  6673 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I0625 14:59:42.582762  6673 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I0625 14:59:42.582770  6673 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 14:59:42.582782  6673 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 14:59:42.582818  6673 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 14:59:42.582824  6673 net.cpp:157] Top shape: 1 4 (4)
I0625 14:59:42.582828  6673 net.cpp:157] Top shape: 1 4 (4)
I0625 14:59:42.582830  6673 net.cpp:165] Memory required for data: 44236884
I0625 14:59:42.582834  6673 layer_factory.hpp:77] Creating layer conv1
I0625 14:59:42.582852  6673 net.cpp:100] Creating Layer conv1
I0625 14:59:42.582862  6673 net.cpp:444] conv1 <- data_input-data_0_split_0
I0625 14:59:42.582877  6673 net.cpp:418] conv1 -> conv1
I0625 14:59:42.884764  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5529624
I0625 14:59:42.885010  6673 net.cpp:150] Setting up conv1
I0625 14:59:42.885026  6673 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 14:59:42.885028  6673 net.cpp:165] Memory required for data: 122880084
I0625 14:59:42.885078  6673 layer_factory.hpp:77] Creating layer bn_conv1
I0625 14:59:42.885104  6673 net.cpp:100] Creating Layer bn_conv1
I0625 14:59:42.885113  6673 net.cpp:444] bn_conv1 <- conv1
I0625 14:59:42.885124  6673 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0625 14:59:42.886378  6673 net.cpp:150] Setting up bn_conv1
I0625 14:59:42.886385  6673 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 14:59:42.886387  6673 net.cpp:165] Memory required for data: 201523284
I0625 14:59:42.886415  6673 layer_factory.hpp:77] Creating layer scale_conv1
I0625 14:59:42.886428  6673 net.cpp:100] Creating Layer scale_conv1
I0625 14:59:42.886435  6673 net.cpp:444] scale_conv1 <- conv1
I0625 14:59:42.886443  6673 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0625 14:59:42.886500  6673 layer_factory.hpp:77] Creating layer scale_conv1
I0625 14:59:42.888754  6673 net.cpp:150] Setting up scale_conv1
I0625 14:59:42.888765  6673 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 14:59:42.888767  6673 net.cpp:165] Memory required for data: 280166484
I0625 14:59:42.888782  6673 layer_factory.hpp:77] Creating layer conv1_relu
I0625 14:59:42.888797  6673 net.cpp:100] Creating Layer conv1_relu
I0625 14:59:42.888803  6673 net.cpp:444] conv1_relu <- conv1
I0625 14:59:42.888816  6673 net.cpp:405] conv1_relu -> conv1 (in-place)
I0625 14:59:42.888978  6673 net.cpp:150] Setting up conv1_relu
I0625 14:59:42.888983  6673 net.cpp:157] Top shape: 1 64 480 640 (19660800)
I0625 14:59:42.888986  6673 net.cpp:165] Memory required for data: 358809684
I0625 14:59:42.888989  6673 layer_factory.hpp:77] Creating layer pool1
I0625 14:59:42.889006  6673 net.cpp:100] Creating Layer pool1
I0625 14:59:42.889010  6673 net.cpp:444] pool1 <- conv1
I0625 14:59:42.889022  6673 net.cpp:418] pool1 -> pool1
I0625 14:59:42.889080  6673 net.cpp:150] Setting up pool1
I0625 14:59:42.889087  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.889089  6673 net.cpp:165] Memory required for data: 378470484
I0625 14:59:42.889092  6673 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0625 14:59:42.889101  6673 net.cpp:100] Creating Layer pool1_pool1_0_split
I0625 14:59:42.889103  6673 net.cpp:444] pool1_pool1_0_split <- pool1
I0625 14:59:42.889112  6673 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0625 14:59:42.889122  6673 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0625 14:59:42.889163  6673 net.cpp:150] Setting up pool1_pool1_0_split
I0625 14:59:42.889168  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.889170  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.889173  6673 net.cpp:165] Memory required for data: 417792084
I0625 14:59:42.889175  6673 layer_factory.hpp:77] Creating layer res2a_branch1
I0625 14:59:42.889189  6673 net.cpp:100] Creating Layer res2a_branch1
I0625 14:59:42.889192  6673 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0625 14:59:42.889204  6673 net.cpp:418] res2a_branch1 -> res2a_branch1
I0625 14:59:42.890048  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.890288  6673 net.cpp:150] Setting up res2a_branch1
I0625 14:59:42.890297  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.890300  6673 net.cpp:165] Memory required for data: 496435284
I0625 14:59:42.890308  6673 layer_factory.hpp:77] Creating layer bn2a_branch1
I0625 14:59:42.890321  6673 net.cpp:100] Creating Layer bn2a_branch1
I0625 14:59:42.890324  6673 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0625 14:59:42.890336  6673 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0625 14:59:42.890633  6673 net.cpp:150] Setting up bn2a_branch1
I0625 14:59:42.890638  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.890640  6673 net.cpp:165] Memory required for data: 575078484
I0625 14:59:42.890662  6673 layer_factory.hpp:77] Creating layer scale2a_branch1
I0625 14:59:42.890674  6673 net.cpp:100] Creating Layer scale2a_branch1
I0625 14:59:42.890679  6673 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0625 14:59:42.890688  6673 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0625 14:59:42.890738  6673 layer_factory.hpp:77] Creating layer scale2a_branch1
I0625 14:59:42.891136  6673 net.cpp:150] Setting up scale2a_branch1
I0625 14:59:42.891146  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.891149  6673 net.cpp:165] Memory required for data: 653721684
I0625 14:59:42.891161  6673 layer_factory.hpp:77] Creating layer res2a_branch2a
I0625 14:59:42.891176  6673 net.cpp:100] Creating Layer res2a_branch2a
I0625 14:59:42.891185  6673 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0625 14:59:42.891199  6673 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0625 14:59:42.892999  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.893235  6673 net.cpp:150] Setting up res2a_branch2a
I0625 14:59:42.893245  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.893247  6673 net.cpp:165] Memory required for data: 673382484
I0625 14:59:42.893257  6673 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0625 14:59:42.893268  6673 net.cpp:100] Creating Layer bn2a_branch2a
I0625 14:59:42.893273  6673 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0625 14:59:42.893283  6673 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0625 14:59:42.893592  6673 net.cpp:150] Setting up bn2a_branch2a
I0625 14:59:42.893597  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.893599  6673 net.cpp:165] Memory required for data: 693043284
I0625 14:59:42.893620  6673 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0625 14:59:42.893632  6673 net.cpp:100] Creating Layer scale2a_branch2a
I0625 14:59:42.893637  6673 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0625 14:59:42.893646  6673 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0625 14:59:42.893697  6673 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0625 14:59:42.894026  6673 net.cpp:150] Setting up scale2a_branch2a
I0625 14:59:42.894032  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.894034  6673 net.cpp:165] Memory required for data: 712704084
I0625 14:59:42.894043  6673 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0625 14:59:42.894058  6673 net.cpp:100] Creating Layer res2a_branch2a_relu
I0625 14:59:42.894063  6673 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0625 14:59:42.894073  6673 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0625 14:59:42.894196  6673 net.cpp:150] Setting up res2a_branch2a_relu
I0625 14:59:42.894201  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.894203  6673 net.cpp:165] Memory required for data: 732364884
I0625 14:59:42.894207  6673 layer_factory.hpp:77] Creating layer res2a_branch2b
I0625 14:59:42.894218  6673 net.cpp:100] Creating Layer res2a_branch2b
I0625 14:59:42.894223  6673 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0625 14:59:42.894235  6673 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0625 14:59:42.895761  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0625 14:59:42.895998  6673 net.cpp:150] Setting up res2a_branch2b
I0625 14:59:42.896008  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.896010  6673 net.cpp:165] Memory required for data: 752025684
I0625 14:59:42.896023  6673 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0625 14:59:42.896035  6673 net.cpp:100] Creating Layer bn2a_branch2b
I0625 14:59:42.896040  6673 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0625 14:59:42.896051  6673 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0625 14:59:42.896375  6673 net.cpp:150] Setting up bn2a_branch2b
I0625 14:59:42.896383  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.896384  6673 net.cpp:165] Memory required for data: 771686484
I0625 14:59:42.896397  6673 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0625 14:59:42.896412  6673 net.cpp:100] Creating Layer scale2a_branch2b
I0625 14:59:42.896417  6673 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0625 14:59:42.896426  6673 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0625 14:59:42.896494  6673 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0625 14:59:42.897503  6673 net.cpp:150] Setting up scale2a_branch2b
I0625 14:59:42.897511  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.897516  6673 net.cpp:165] Memory required for data: 791347284
I0625 14:59:42.897529  6673 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0625 14:59:42.897543  6673 net.cpp:100] Creating Layer res2a_branch2b_relu
I0625 14:59:42.897549  6673 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0625 14:59:42.897562  6673 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0625 14:59:42.897970  6673 net.cpp:150] Setting up res2a_branch2b_relu
I0625 14:59:42.897979  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.897982  6673 net.cpp:165] Memory required for data: 811008084
I0625 14:59:42.897989  6673 layer_factory.hpp:77] Creating layer res2a_branch2c
I0625 14:59:42.898008  6673 net.cpp:100] Creating Layer res2a_branch2c
I0625 14:59:42.898015  6673 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0625 14:59:42.898030  6673 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0625 14:59:42.898912  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.899160  6673 net.cpp:150] Setting up res2a_branch2c
I0625 14:59:42.899174  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.899178  6673 net.cpp:165] Memory required for data: 889651284
I0625 14:59:42.899191  6673 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0625 14:59:42.899207  6673 net.cpp:100] Creating Layer bn2a_branch2c
I0625 14:59:42.899214  6673 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0625 14:59:42.899227  6673 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0625 14:59:42.899534  6673 net.cpp:150] Setting up bn2a_branch2c
I0625 14:59:42.899541  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.899544  6673 net.cpp:165] Memory required for data: 968294484
I0625 14:59:42.899561  6673 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0625 14:59:42.899576  6673 net.cpp:100] Creating Layer scale2a_branch2c
I0625 14:59:42.899582  6673 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0625 14:59:42.899595  6673 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0625 14:59:42.899652  6673 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0625 14:59:42.899999  6673 net.cpp:150] Setting up scale2a_branch2c
I0625 14:59:42.900007  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.900010  6673 net.cpp:165] Memory required for data: 1046937684
I0625 14:59:42.900023  6673 layer_factory.hpp:77] Creating layer res2a
I0625 14:59:42.900035  6673 net.cpp:100] Creating Layer res2a
I0625 14:59:42.900041  6673 net.cpp:444] res2a <- res2a_branch1
I0625 14:59:42.900053  6673 net.cpp:444] res2a <- res2a_branch2c
I0625 14:59:42.900063  6673 net.cpp:418] res2a -> res2a
I0625 14:59:42.900100  6673 net.cpp:150] Setting up res2a
I0625 14:59:42.900108  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.900111  6673 net.cpp:165] Memory required for data: 1125580884
I0625 14:59:42.900116  6673 layer_factory.hpp:77] Creating layer res2a_relu
I0625 14:59:42.900127  6673 net.cpp:100] Creating Layer res2a_relu
I0625 14:59:42.900132  6673 net.cpp:444] res2a_relu <- res2a
I0625 14:59:42.900144  6673 net.cpp:405] res2a_relu -> res2a (in-place)
I0625 14:59:42.900276  6673 net.cpp:150] Setting up res2a_relu
I0625 14:59:42.900285  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.900286  6673 net.cpp:165] Memory required for data: 1204224084
I0625 14:59:42.900291  6673 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0625 14:59:42.900303  6673 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0625 14:59:42.900308  6673 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0625 14:59:42.900322  6673 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0625 14:59:42.900337  6673 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0625 14:59:42.900385  6673 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0625 14:59:42.900394  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.900399  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.900403  6673 net.cpp:165] Memory required for data: 1361510484
I0625 14:59:42.900408  6673 layer_factory.hpp:77] Creating layer res2b_branch2a
I0625 14:59:42.900423  6673 net.cpp:100] Creating Layer res2b_branch2a
I0625 14:59:42.900427  6673 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0625 14:59:42.900441  6673 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0625 14:59:42.901266  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.901504  6673 net.cpp:150] Setting up res2b_branch2a
I0625 14:59:42.901513  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.901517  6673 net.cpp:165] Memory required for data: 1381171284
I0625 14:59:42.901530  6673 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0625 14:59:42.901543  6673 net.cpp:100] Creating Layer bn2b_branch2a
I0625 14:59:42.901549  6673 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0625 14:59:42.901564  6673 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0625 14:59:42.901885  6673 net.cpp:150] Setting up bn2b_branch2a
I0625 14:59:42.901891  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.901895  6673 net.cpp:165] Memory required for data: 1400832084
I0625 14:59:42.901921  6673 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0625 14:59:42.901937  6673 net.cpp:100] Creating Layer scale2b_branch2a
I0625 14:59:42.901942  6673 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0625 14:59:42.901955  6673 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0625 14:59:42.902012  6673 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0625 14:59:42.903029  6673 net.cpp:150] Setting up scale2b_branch2a
I0625 14:59:42.903039  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.903043  6673 net.cpp:165] Memory required for data: 1420492884
I0625 14:59:42.903056  6673 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0625 14:59:42.903069  6673 net.cpp:100] Creating Layer res2b_branch2a_relu
I0625 14:59:42.903075  6673 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0625 14:59:42.903089  6673 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0625 14:59:42.903229  6673 net.cpp:150] Setting up res2b_branch2a_relu
I0625 14:59:42.903236  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.903239  6673 net.cpp:165] Memory required for data: 1440153684
I0625 14:59:42.903244  6673 layer_factory.hpp:77] Creating layer res2b_branch2b
I0625 14:59:42.903259  6673 net.cpp:100] Creating Layer res2b_branch2b
I0625 14:59:42.903265  6673 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0625 14:59:42.903281  6673 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0625 14:59:42.904148  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0625 14:59:42.904163  6673 net.cpp:150] Setting up res2b_branch2b
I0625 14:59:42.904172  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.904176  6673 net.cpp:165] Memory required for data: 1459814484
I0625 14:59:42.904188  6673 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0625 14:59:42.904208  6673 net.cpp:100] Creating Layer bn2b_branch2b
I0625 14:59:42.904214  6673 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0625 14:59:42.904229  6673 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0625 14:59:42.904547  6673 net.cpp:150] Setting up bn2b_branch2b
I0625 14:59:42.904554  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.904557  6673 net.cpp:165] Memory required for data: 1479475284
I0625 14:59:42.904574  6673 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0625 14:59:42.904588  6673 net.cpp:100] Creating Layer scale2b_branch2b
I0625 14:59:42.904594  6673 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0625 14:59:42.904608  6673 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0625 14:59:42.904664  6673 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0625 14:59:42.904999  6673 net.cpp:150] Setting up scale2b_branch2b
I0625 14:59:42.905005  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.905009  6673 net.cpp:165] Memory required for data: 1499136084
I0625 14:59:42.905021  6673 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0625 14:59:42.905032  6673 net.cpp:100] Creating Layer res2b_branch2b_relu
I0625 14:59:42.905038  6673 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0625 14:59:42.905050  6673 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0625 14:59:42.905407  6673 net.cpp:150] Setting up res2b_branch2b_relu
I0625 14:59:42.905416  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.905418  6673 net.cpp:165] Memory required for data: 1518796884
I0625 14:59:42.905424  6673 layer_factory.hpp:77] Creating layer res2b_branch2c
I0625 14:59:42.905441  6673 net.cpp:100] Creating Layer res2b_branch2c
I0625 14:59:42.905447  6673 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0625 14:59:42.905462  6673 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0625 14:59:42.906289  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.906528  6673 net.cpp:150] Setting up res2b_branch2c
I0625 14:59:42.906538  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.906543  6673 net.cpp:165] Memory required for data: 1597440084
I0625 14:59:42.906554  6673 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0625 14:59:42.906569  6673 net.cpp:100] Creating Layer bn2b_branch2c
I0625 14:59:42.906574  6673 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0625 14:59:42.906587  6673 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0625 14:59:42.906904  6673 net.cpp:150] Setting up bn2b_branch2c
I0625 14:59:42.906913  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.906915  6673 net.cpp:165] Memory required for data: 1676083284
I0625 14:59:42.906932  6673 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0625 14:59:42.906945  6673 net.cpp:100] Creating Layer scale2b_branch2c
I0625 14:59:42.906952  6673 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0625 14:59:42.906965  6673 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0625 14:59:42.907021  6673 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0625 14:59:42.908041  6673 net.cpp:150] Setting up scale2b_branch2c
I0625 14:59:42.908051  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.908053  6673 net.cpp:165] Memory required for data: 1754726484
I0625 14:59:42.908067  6673 layer_factory.hpp:77] Creating layer res2b
I0625 14:59:42.908080  6673 net.cpp:100] Creating Layer res2b
I0625 14:59:42.908087  6673 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0625 14:59:42.908098  6673 net.cpp:444] res2b <- res2b_branch2c
I0625 14:59:42.908109  6673 net.cpp:418] res2b -> res2b
I0625 14:59:42.908155  6673 net.cpp:150] Setting up res2b
I0625 14:59:42.908164  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.908167  6673 net.cpp:165] Memory required for data: 1833369684
I0625 14:59:42.908172  6673 layer_factory.hpp:77] Creating layer res2b_relu
I0625 14:59:42.908182  6673 net.cpp:100] Creating Layer res2b_relu
I0625 14:59:42.908190  6673 net.cpp:444] res2b_relu <- res2b
I0625 14:59:42.908202  6673 net.cpp:405] res2b_relu -> res2b (in-place)
I0625 14:59:42.908341  6673 net.cpp:150] Setting up res2b_relu
I0625 14:59:42.908349  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.908351  6673 net.cpp:165] Memory required for data: 1912012884
I0625 14:59:42.908356  6673 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0625 14:59:42.908367  6673 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0625 14:59:42.908372  6673 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0625 14:59:42.908386  6673 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0625 14:59:42.908401  6673 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0625 14:59:42.908454  6673 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0625 14:59:42.908463  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.908468  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.908471  6673 net.cpp:165] Memory required for data: 2069299284
I0625 14:59:42.908475  6673 layer_factory.hpp:77] Creating layer res2c_branch2a
I0625 14:59:42.908490  6673 net.cpp:100] Creating Layer res2c_branch2a
I0625 14:59:42.908496  6673 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0625 14:59:42.908510  6673 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0625 14:59:42.909364  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.909602  6673 net.cpp:150] Setting up res2c_branch2a
I0625 14:59:42.909613  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.909617  6673 net.cpp:165] Memory required for data: 2088960084
I0625 14:59:42.909629  6673 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0625 14:59:42.909643  6673 net.cpp:100] Creating Layer bn2c_branch2a
I0625 14:59:42.909649  6673 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0625 14:59:42.909663  6673 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0625 14:59:42.909988  6673 net.cpp:150] Setting up bn2c_branch2a
I0625 14:59:42.909996  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.909998  6673 net.cpp:165] Memory required for data: 2108620884
I0625 14:59:42.910015  6673 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0625 14:59:42.910028  6673 net.cpp:100] Creating Layer scale2c_branch2a
I0625 14:59:42.910034  6673 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0625 14:59:42.910048  6673 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0625 14:59:42.910105  6673 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0625 14:59:42.910441  6673 net.cpp:150] Setting up scale2c_branch2a
I0625 14:59:42.910449  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.910452  6673 net.cpp:165] Memory required for data: 2128281684
I0625 14:59:42.910465  6673 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0625 14:59:42.910475  6673 net.cpp:100] Creating Layer res2c_branch2a_relu
I0625 14:59:42.910481  6673 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0625 14:59:42.910493  6673 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0625 14:59:42.910624  6673 net.cpp:150] Setting up res2c_branch2a_relu
I0625 14:59:42.910631  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.910634  6673 net.cpp:165] Memory required for data: 2147942484
I0625 14:59:42.910639  6673 layer_factory.hpp:77] Creating layer res2c_branch2b
I0625 14:59:42.910655  6673 net.cpp:100] Creating Layer res2c_branch2b
I0625 14:59:42.910660  6673 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0625 14:59:42.910676  6673 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0625 14:59:42.912169  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0625 14:59:42.912420  6673 net.cpp:150] Setting up res2c_branch2b
I0625 14:59:42.912431  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.912436  6673 net.cpp:165] Memory required for data: 2167603284
I0625 14:59:42.912451  6673 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0625 14:59:42.912467  6673 net.cpp:100] Creating Layer bn2c_branch2b
I0625 14:59:42.912473  6673 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0625 14:59:42.912490  6673 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0625 14:59:42.912818  6673 net.cpp:150] Setting up bn2c_branch2b
I0625 14:59:42.912825  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.912828  6673 net.cpp:165] Memory required for data: 2187264084
I0625 14:59:42.912845  6673 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0625 14:59:42.912859  6673 net.cpp:100] Creating Layer scale2c_branch2b
I0625 14:59:42.912866  6673 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0625 14:59:42.912878  6673 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0625 14:59:42.912936  6673 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0625 14:59:42.913962  6673 net.cpp:150] Setting up scale2c_branch2b
I0625 14:59:42.913971  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.913975  6673 net.cpp:165] Memory required for data: 2206924884
I0625 14:59:42.913987  6673 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0625 14:59:42.914000  6673 net.cpp:100] Creating Layer res2c_branch2b_relu
I0625 14:59:42.914007  6673 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0625 14:59:42.914021  6673 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0625 14:59:42.914168  6673 net.cpp:150] Setting up res2c_branch2b_relu
I0625 14:59:42.914176  6673 net.cpp:157] Top shape: 1 64 240 320 (4915200)
I0625 14:59:42.914180  6673 net.cpp:165] Memory required for data: 2226585684
I0625 14:59:42.914185  6673 layer_factory.hpp:77] Creating layer res2c_branch2c
I0625 14:59:42.914202  6673 net.cpp:100] Creating Layer res2c_branch2c
I0625 14:59:42.914208  6673 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0625 14:59:42.914223  6673 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0625 14:59:42.915182  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0625 14:59:42.915493  6673 net.cpp:150] Setting up res2c_branch2c
I0625 14:59:42.915506  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.915510  6673 net.cpp:165] Memory required for data: 2305228884
I0625 14:59:42.915524  6673 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0625 14:59:42.915541  6673 net.cpp:100] Creating Layer bn2c_branch2c
I0625 14:59:42.915549  6673 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0625 14:59:42.915563  6673 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0625 14:59:42.915894  6673 net.cpp:150] Setting up bn2c_branch2c
I0625 14:59:42.915901  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.915904  6673 net.cpp:165] Memory required for data: 2383872084
I0625 14:59:42.915937  6673 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0625 14:59:42.915956  6673 net.cpp:100] Creating Layer scale2c_branch2c
I0625 14:59:42.915961  6673 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0625 14:59:42.915976  6673 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0625 14:59:42.916036  6673 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0625 14:59:42.916374  6673 net.cpp:150] Setting up scale2c_branch2c
I0625 14:59:42.916381  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.916384  6673 net.cpp:165] Memory required for data: 2462515284
I0625 14:59:42.916396  6673 layer_factory.hpp:77] Creating layer res2c
I0625 14:59:42.916409  6673 net.cpp:100] Creating Layer res2c
I0625 14:59:42.916415  6673 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0625 14:59:42.916427  6673 net.cpp:444] res2c <- res2c_branch2c
I0625 14:59:42.916438  6673 net.cpp:418] res2c -> res2c
I0625 14:59:42.916478  6673 net.cpp:150] Setting up res2c
I0625 14:59:42.916487  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.916491  6673 net.cpp:165] Memory required for data: 2541158484
I0625 14:59:42.916496  6673 layer_factory.hpp:77] Creating layer res2c_relu
I0625 14:59:42.916507  6673 net.cpp:100] Creating Layer res2c_relu
I0625 14:59:42.916513  6673 net.cpp:444] res2c_relu <- res2c
I0625 14:59:42.916527  6673 net.cpp:405] res2c_relu -> res2c (in-place)
I0625 14:59:42.916900  6673 net.cpp:150] Setting up res2c_relu
I0625 14:59:42.916908  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.916911  6673 net.cpp:165] Memory required for data: 2619801684
I0625 14:59:42.916916  6673 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0625 14:59:42.916929  6673 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0625 14:59:42.916934  6673 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0625 14:59:42.916949  6673 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0625 14:59:42.916966  6673 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0625 14:59:42.917021  6673 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0625 14:59:42.917031  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.917035  6673 net.cpp:157] Top shape: 1 256 240 320 (19660800)
I0625 14:59:42.917039  6673 net.cpp:165] Memory required for data: 2777088084
I0625 14:59:42.917043  6673 layer_factory.hpp:77] Creating layer res3a_branch1
I0625 14:59:42.917060  6673 net.cpp:100] Creating Layer res3a_branch1
I0625 14:59:42.917066  6673 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0625 14:59:42.917083  6673 net.cpp:418] res3a_branch1 -> res3a_branch1
I0625 14:59:42.918108  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0625 14:59:42.918126  6673 net.cpp:150] Setting up res3a_branch1
I0625 14:59:42.918136  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.918139  6673 net.cpp:165] Memory required for data: 2816409684
I0625 14:59:42.918151  6673 layer_factory.hpp:77] Creating layer bn3a_branch1
I0625 14:59:42.918166  6673 net.cpp:100] Creating Layer bn3a_branch1
I0625 14:59:42.918174  6673 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0625 14:59:42.918187  6673 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0625 14:59:42.919150  6673 net.cpp:150] Setting up bn3a_branch1
I0625 14:59:42.919160  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.919163  6673 net.cpp:165] Memory required for data: 2855731284
I0625 14:59:42.919181  6673 layer_factory.hpp:77] Creating layer scale3a_branch1
I0625 14:59:42.919198  6673 net.cpp:100] Creating Layer scale3a_branch1
I0625 14:59:42.919203  6673 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0625 14:59:42.919219  6673 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0625 14:59:42.919275  6673 layer_factory.hpp:77] Creating layer scale3a_branch1
I0625 14:59:42.919471  6673 net.cpp:150] Setting up scale3a_branch1
I0625 14:59:42.919478  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.919481  6673 net.cpp:165] Memory required for data: 2895052884
I0625 14:59:42.919493  6673 layer_factory.hpp:77] Creating layer res3a_branch2a
I0625 14:59:42.919509  6673 net.cpp:100] Creating Layer res3a_branch2a
I0625 14:59:42.919517  6673 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0625 14:59:42.919531  6673 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0625 14:59:42.920447  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0625 14:59:42.920465  6673 net.cpp:150] Setting up res3a_branch2a
I0625 14:59:42.920473  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.920477  6673 net.cpp:165] Memory required for data: 2904883284
I0625 14:59:42.920488  6673 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0625 14:59:42.920503  6673 net.cpp:100] Creating Layer bn3a_branch2a
I0625 14:59:42.920509  6673 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0625 14:59:42.920524  6673 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0625 14:59:42.920773  6673 net.cpp:150] Setting up bn3a_branch2a
I0625 14:59:42.920780  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.920783  6673 net.cpp:165] Memory required for data: 2914713684
I0625 14:59:42.920801  6673 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0625 14:59:42.920816  6673 net.cpp:100] Creating Layer scale3a_branch2a
I0625 14:59:42.920823  6673 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0625 14:59:42.920837  6673 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0625 14:59:42.920895  6673 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0625 14:59:42.921084  6673 net.cpp:150] Setting up scale3a_branch2a
I0625 14:59:42.921092  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.921094  6673 net.cpp:165] Memory required for data: 2924544084
I0625 14:59:42.921106  6673 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0625 14:59:42.921118  6673 net.cpp:100] Creating Layer res3a_branch2a_relu
I0625 14:59:42.921123  6673 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0625 14:59:42.921138  6673 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0625 14:59:42.921269  6673 net.cpp:150] Setting up res3a_branch2a_relu
I0625 14:59:42.921277  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.921279  6673 net.cpp:165] Memory required for data: 2934374484
I0625 14:59:42.921284  6673 layer_factory.hpp:77] Creating layer res3a_branch2b
I0625 14:59:42.921300  6673 net.cpp:100] Creating Layer res3a_branch2b
I0625 14:59:42.921308  6673 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0625 14:59:42.921324  6673 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0625 14:59:42.923089  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 14:59:42.923337  6673 net.cpp:150] Setting up res3a_branch2b
I0625 14:59:42.923349  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.923354  6673 net.cpp:165] Memory required for data: 2944204884
I0625 14:59:42.923367  6673 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0625 14:59:42.923382  6673 net.cpp:100] Creating Layer bn3a_branch2b
I0625 14:59:42.923388  6673 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0625 14:59:42.923405  6673 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0625 14:59:42.923660  6673 net.cpp:150] Setting up bn3a_branch2b
I0625 14:59:42.923667  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.923669  6673 net.cpp:165] Memory required for data: 2954035284
I0625 14:59:42.923687  6673 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0625 14:59:42.923712  6673 net.cpp:100] Creating Layer scale3a_branch2b
I0625 14:59:42.923717  6673 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0625 14:59:42.923732  6673 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0625 14:59:42.923791  6673 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0625 14:59:42.923981  6673 net.cpp:150] Setting up scale3a_branch2b
I0625 14:59:42.923988  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.923991  6673 net.cpp:165] Memory required for data: 2963865684
I0625 14:59:42.924005  6673 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0625 14:59:42.924016  6673 net.cpp:100] Creating Layer res3a_branch2b_relu
I0625 14:59:42.924022  6673 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0625 14:59:42.924034  6673 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0625 14:59:42.924170  6673 net.cpp:150] Setting up res3a_branch2b_relu
I0625 14:59:42.924177  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.924180  6673 net.cpp:165] Memory required for data: 2973696084
I0625 14:59:42.924185  6673 layer_factory.hpp:77] Creating layer res3a_branch2c
I0625 14:59:42.924201  6673 net.cpp:100] Creating Layer res3a_branch2c
I0625 14:59:42.924207  6673 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0625 14:59:42.924223  6673 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0625 14:59:42.925177  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.925192  6673 net.cpp:150] Setting up res3a_branch2c
I0625 14:59:42.925200  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.925204  6673 net.cpp:165] Memory required for data: 3013017684
I0625 14:59:42.925215  6673 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0625 14:59:42.925230  6673 net.cpp:100] Creating Layer bn3a_branch2c
I0625 14:59:42.925237  6673 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0625 14:59:42.925252  6673 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0625 14:59:42.925508  6673 net.cpp:150] Setting up bn3a_branch2c
I0625 14:59:42.925513  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.925516  6673 net.cpp:165] Memory required for data: 3052339284
I0625 14:59:42.925534  6673 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0625 14:59:42.925547  6673 net.cpp:100] Creating Layer scale3a_branch2c
I0625 14:59:42.925554  6673 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0625 14:59:42.925567  6673 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0625 14:59:42.925622  6673 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0625 14:59:42.925824  6673 net.cpp:150] Setting up scale3a_branch2c
I0625 14:59:42.925832  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.925835  6673 net.cpp:165] Memory required for data: 3091660884
I0625 14:59:42.925848  6673 layer_factory.hpp:77] Creating layer res3a
I0625 14:59:42.925859  6673 net.cpp:100] Creating Layer res3a
I0625 14:59:42.925865  6673 net.cpp:444] res3a <- res3a_branch1
I0625 14:59:42.925878  6673 net.cpp:444] res3a <- res3a_branch2c
I0625 14:59:42.925887  6673 net.cpp:418] res3a -> res3a
I0625 14:59:42.925927  6673 net.cpp:150] Setting up res3a
I0625 14:59:42.925936  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.925940  6673 net.cpp:165] Memory required for data: 3130982484
I0625 14:59:42.925945  6673 layer_factory.hpp:77] Creating layer res3a_relu
I0625 14:59:42.925954  6673 net.cpp:100] Creating Layer res3a_relu
I0625 14:59:42.925961  6673 net.cpp:444] res3a_relu <- res3a
I0625 14:59:42.925972  6673 net.cpp:405] res3a_relu -> res3a (in-place)
I0625 14:59:42.926347  6673 net.cpp:150] Setting up res3a_relu
I0625 14:59:42.926354  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.926357  6673 net.cpp:165] Memory required for data: 3170304084
I0625 14:59:42.926363  6673 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0625 14:59:42.926374  6673 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0625 14:59:42.926380  6673 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0625 14:59:42.926395  6673 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0625 14:59:42.926412  6673 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0625 14:59:42.926467  6673 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0625 14:59:42.926476  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.926482  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.926486  6673 net.cpp:165] Memory required for data: 3248947284
I0625 14:59:42.926491  6673 layer_factory.hpp:77] Creating layer res3b_branch2a
I0625 14:59:42.926506  6673 net.cpp:100] Creating Layer res3b_branch2a
I0625 14:59:42.926512  6673 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0625 14:59:42.926527  6673 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0625 14:59:42.927480  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.927501  6673 net.cpp:150] Setting up res3b_branch2a
I0625 14:59:42.927510  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.927513  6673 net.cpp:165] Memory required for data: 3258777684
I0625 14:59:42.927525  6673 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0625 14:59:42.927538  6673 net.cpp:100] Creating Layer bn3b_branch2a
I0625 14:59:42.927546  6673 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0625 14:59:42.927559  6673 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0625 14:59:42.927814  6673 net.cpp:150] Setting up bn3b_branch2a
I0625 14:59:42.927820  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.927824  6673 net.cpp:165] Memory required for data: 3268608084
I0625 14:59:42.927839  6673 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0625 14:59:42.927855  6673 net.cpp:100] Creating Layer scale3b_branch2a
I0625 14:59:42.927860  6673 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0625 14:59:42.927875  6673 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0625 14:59:42.927934  6673 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0625 14:59:42.928818  6673 net.cpp:150] Setting up scale3b_branch2a
I0625 14:59:42.928827  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.928830  6673 net.cpp:165] Memory required for data: 3278438484
I0625 14:59:42.928843  6673 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0625 14:59:42.928855  6673 net.cpp:100] Creating Layer res3b_branch2a_relu
I0625 14:59:42.928861  6673 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0625 14:59:42.928876  6673 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0625 14:59:42.929021  6673 net.cpp:150] Setting up res3b_branch2a_relu
I0625 14:59:42.929028  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.929031  6673 net.cpp:165] Memory required for data: 3288268884
I0625 14:59:42.929036  6673 layer_factory.hpp:77] Creating layer res3b_branch2b
I0625 14:59:42.929052  6673 net.cpp:100] Creating Layer res3b_branch2b
I0625 14:59:42.929059  6673 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0625 14:59:42.929075  6673 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0625 14:59:42.930385  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 14:59:42.930632  6673 net.cpp:150] Setting up res3b_branch2b
I0625 14:59:42.930644  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.930647  6673 net.cpp:165] Memory required for data: 3298099284
I0625 14:59:42.930660  6673 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0625 14:59:42.930673  6673 net.cpp:100] Creating Layer bn3b_branch2b
I0625 14:59:42.930680  6673 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0625 14:59:42.930693  6673 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0625 14:59:42.930979  6673 net.cpp:150] Setting up bn3b_branch2b
I0625 14:59:42.930989  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.930991  6673 net.cpp:165] Memory required for data: 3307929684
I0625 14:59:42.931010  6673 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0625 14:59:42.931026  6673 net.cpp:100] Creating Layer scale3b_branch2b
I0625 14:59:42.931033  6673 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0625 14:59:42.931048  6673 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0625 14:59:42.931123  6673 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0625 14:59:42.931370  6673 net.cpp:150] Setting up scale3b_branch2b
I0625 14:59:42.931377  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.931380  6673 net.cpp:165] Memory required for data: 3317760084
I0625 14:59:42.931392  6673 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0625 14:59:42.931403  6673 net.cpp:100] Creating Layer res3b_branch2b_relu
I0625 14:59:42.931409  6673 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0625 14:59:42.931421  6673 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0625 14:59:42.931603  6673 net.cpp:150] Setting up res3b_branch2b_relu
I0625 14:59:42.931612  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.931615  6673 net.cpp:165] Memory required for data: 3327590484
I0625 14:59:42.931620  6673 layer_factory.hpp:77] Creating layer res3b_branch2c
I0625 14:59:42.931637  6673 net.cpp:100] Creating Layer res3b_branch2c
I0625 14:59:42.931643  6673 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0625 14:59:42.931658  6673 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0625 14:59:42.932732  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.932745  6673 net.cpp:150] Setting up res3b_branch2c
I0625 14:59:42.932751  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.932754  6673 net.cpp:165] Memory required for data: 3366912084
I0625 14:59:42.932762  6673 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0625 14:59:42.932775  6673 net.cpp:100] Creating Layer bn3b_branch2c
I0625 14:59:42.932780  6673 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0625 14:59:42.932791  6673 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0625 14:59:42.933048  6673 net.cpp:150] Setting up bn3b_branch2c
I0625 14:59:42.933053  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.933055  6673 net.cpp:165] Memory required for data: 3406233684
I0625 14:59:42.933068  6673 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0625 14:59:42.933079  6673 net.cpp:100] Creating Layer scale3b_branch2c
I0625 14:59:42.933084  6673 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0625 14:59:42.933094  6673 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0625 14:59:42.933146  6673 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0625 14:59:42.933337  6673 net.cpp:150] Setting up scale3b_branch2c
I0625 14:59:42.933343  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.933346  6673 net.cpp:165] Memory required for data: 3445555284
I0625 14:59:42.933354  6673 layer_factory.hpp:77] Creating layer res3b
I0625 14:59:42.933363  6673 net.cpp:100] Creating Layer res3b
I0625 14:59:42.933368  6673 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0625 14:59:42.933377  6673 net.cpp:444] res3b <- res3b_branch2c
I0625 14:59:42.933383  6673 net.cpp:418] res3b -> res3b
I0625 14:59:42.933419  6673 net.cpp:150] Setting up res3b
I0625 14:59:42.933426  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.933429  6673 net.cpp:165] Memory required for data: 3484876884
I0625 14:59:42.933431  6673 layer_factory.hpp:77] Creating layer res3b_relu
I0625 14:59:42.933439  6673 net.cpp:100] Creating Layer res3b_relu
I0625 14:59:42.933442  6673 net.cpp:444] res3b_relu <- res3b
I0625 14:59:42.933451  6673 net.cpp:405] res3b_relu -> res3b (in-place)
I0625 14:59:42.933818  6673 net.cpp:150] Setting up res3b_relu
I0625 14:59:42.933827  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.933830  6673 net.cpp:165] Memory required for data: 3524198484
I0625 14:59:42.933833  6673 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0625 14:59:42.933842  6673 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0625 14:59:42.933847  6673 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0625 14:59:42.933859  6673 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0625 14:59:42.933872  6673 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0625 14:59:42.933924  6673 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0625 14:59:42.933931  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.933934  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.933936  6673 net.cpp:165] Memory required for data: 3602841684
I0625 14:59:42.933939  6673 layer_factory.hpp:77] Creating layer res3c_branch2a
I0625 14:59:42.933951  6673 net.cpp:100] Creating Layer res3c_branch2a
I0625 14:59:42.933956  6673 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0625 14:59:42.933967  6673 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0625 14:59:42.934912  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.934931  6673 net.cpp:150] Setting up res3c_branch2a
I0625 14:59:42.934937  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.934939  6673 net.cpp:165] Memory required for data: 3612672084
I0625 14:59:42.934947  6673 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0625 14:59:42.934960  6673 net.cpp:100] Creating Layer bn3c_branch2a
I0625 14:59:42.934965  6673 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0625 14:59:42.934976  6673 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0625 14:59:42.935228  6673 net.cpp:150] Setting up bn3c_branch2a
I0625 14:59:42.935235  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.935236  6673 net.cpp:165] Memory required for data: 3622502484
I0625 14:59:42.935250  6673 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0625 14:59:42.935261  6673 net.cpp:100] Creating Layer scale3c_branch2a
I0625 14:59:42.935266  6673 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0625 14:59:42.935276  6673 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0625 14:59:42.935331  6673 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0625 14:59:42.935516  6673 net.cpp:150] Setting up scale3c_branch2a
I0625 14:59:42.935523  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.935525  6673 net.cpp:165] Memory required for data: 3632332884
I0625 14:59:42.935534  6673 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0625 14:59:42.935544  6673 net.cpp:100] Creating Layer res3c_branch2a_relu
I0625 14:59:42.935547  6673 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0625 14:59:42.935556  6673 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0625 14:59:42.935685  6673 net.cpp:150] Setting up res3c_branch2a_relu
I0625 14:59:42.935691  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.935693  6673 net.cpp:165] Memory required for data: 3642163284
I0625 14:59:42.935698  6673 layer_factory.hpp:77] Creating layer res3c_branch2b
I0625 14:59:42.935709  6673 net.cpp:100] Creating Layer res3c_branch2b
I0625 14:59:42.935714  6673 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0625 14:59:42.935726  6673 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0625 14:59:42.936777  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 14:59:42.937022  6673 net.cpp:150] Setting up res3c_branch2b
I0625 14:59:42.937031  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.937034  6673 net.cpp:165] Memory required for data: 3651993684
I0625 14:59:42.937043  6673 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0625 14:59:42.937055  6673 net.cpp:100] Creating Layer bn3c_branch2b
I0625 14:59:42.937060  6673 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0625 14:59:42.937072  6673 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0625 14:59:42.937330  6673 net.cpp:150] Setting up bn3c_branch2b
I0625 14:59:42.937336  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.937338  6673 net.cpp:165] Memory required for data: 3661824084
I0625 14:59:42.937351  6673 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0625 14:59:42.937362  6673 net.cpp:100] Creating Layer scale3c_branch2b
I0625 14:59:42.937367  6673 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0625 14:59:42.937377  6673 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0625 14:59:42.937433  6673 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0625 14:59:42.937618  6673 net.cpp:150] Setting up scale3c_branch2b
I0625 14:59:42.937624  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.937626  6673 net.cpp:165] Memory required for data: 3671654484
I0625 14:59:42.937634  6673 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0625 14:59:42.937642  6673 net.cpp:100] Creating Layer res3c_branch2b_relu
I0625 14:59:42.937647  6673 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0625 14:59:42.937656  6673 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0625 14:59:42.937795  6673 net.cpp:150] Setting up res3c_branch2b_relu
I0625 14:59:42.937803  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.937804  6673 net.cpp:165] Memory required for data: 3681484884
I0625 14:59:42.937808  6673 layer_factory.hpp:77] Creating layer res3c_branch2c
I0625 14:59:42.937819  6673 net.cpp:100] Creating Layer res3c_branch2c
I0625 14:59:42.937824  6673 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0625 14:59:42.937837  6673 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0625 14:59:42.938794  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.938807  6673 net.cpp:150] Setting up res3c_branch2c
I0625 14:59:42.938813  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.938817  6673 net.cpp:165] Memory required for data: 3720806484
I0625 14:59:42.938824  6673 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0625 14:59:42.938836  6673 net.cpp:100] Creating Layer bn3c_branch2c
I0625 14:59:42.938841  6673 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0625 14:59:42.938853  6673 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0625 14:59:42.939131  6673 net.cpp:150] Setting up bn3c_branch2c
I0625 14:59:42.939137  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.939139  6673 net.cpp:165] Memory required for data: 3760128084
I0625 14:59:42.939153  6673 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0625 14:59:42.939163  6673 net.cpp:100] Creating Layer scale3c_branch2c
I0625 14:59:42.939168  6673 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0625 14:59:42.939179  6673 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0625 14:59:42.939230  6673 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0625 14:59:42.939422  6673 net.cpp:150] Setting up scale3c_branch2c
I0625 14:59:42.939429  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.939431  6673 net.cpp:165] Memory required for data: 3799449684
I0625 14:59:42.939440  6673 layer_factory.hpp:77] Creating layer res3c
I0625 14:59:42.939448  6673 net.cpp:100] Creating Layer res3c
I0625 14:59:42.939453  6673 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0625 14:59:42.939460  6673 net.cpp:444] res3c <- res3c_branch2c
I0625 14:59:42.939468  6673 net.cpp:418] res3c -> res3c
I0625 14:59:42.939503  6673 net.cpp:150] Setting up res3c
I0625 14:59:42.939510  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.939512  6673 net.cpp:165] Memory required for data: 3838771284
I0625 14:59:42.939515  6673 layer_factory.hpp:77] Creating layer res3c_relu
I0625 14:59:42.939522  6673 net.cpp:100] Creating Layer res3c_relu
I0625 14:59:42.939527  6673 net.cpp:444] res3c_relu <- res3c
I0625 14:59:42.939534  6673 net.cpp:405] res3c_relu -> res3c (in-place)
I0625 14:59:42.939666  6673 net.cpp:150] Setting up res3c_relu
I0625 14:59:42.939671  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.939674  6673 net.cpp:165] Memory required for data: 3878092884
I0625 14:59:42.939677  6673 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0625 14:59:42.939685  6673 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0625 14:59:42.939689  6673 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0625 14:59:42.939699  6673 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0625 14:59:42.939710  6673 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0625 14:59:42.939760  6673 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0625 14:59:42.939769  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.939771  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.939774  6673 net.cpp:165] Memory required for data: 3956736084
I0625 14:59:42.939776  6673 layer_factory.hpp:77] Creating layer res3d_branch2a
I0625 14:59:42.939787  6673 net.cpp:100] Creating Layer res3d_branch2a
I0625 14:59:42.939792  6673 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0625 14:59:42.939803  6673 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0625 14:59:42.941437  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.941454  6673 net.cpp:150] Setting up res3d_branch2a
I0625 14:59:42.941460  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.941463  6673 net.cpp:165] Memory required for data: 3966566484
I0625 14:59:42.941473  6673 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0625 14:59:42.941483  6673 net.cpp:100] Creating Layer bn3d_branch2a
I0625 14:59:42.941488  6673 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0625 14:59:42.941500  6673 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0625 14:59:42.941761  6673 net.cpp:150] Setting up bn3d_branch2a
I0625 14:59:42.941766  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.941769  6673 net.cpp:165] Memory required for data: 3976396884
I0625 14:59:42.941802  6673 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0625 14:59:42.941817  6673 net.cpp:100] Creating Layer scale3d_branch2a
I0625 14:59:42.941820  6673 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0625 14:59:42.941830  6673 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0625 14:59:42.941889  6673 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0625 14:59:42.942076  6673 net.cpp:150] Setting up scale3d_branch2a
I0625 14:59:42.942082  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.942085  6673 net.cpp:165] Memory required for data: 3986227284
I0625 14:59:42.942093  6673 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0625 14:59:42.942104  6673 net.cpp:100] Creating Layer res3d_branch2a_relu
I0625 14:59:42.942108  6673 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0625 14:59:42.942117  6673 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0625 14:59:42.942487  6673 net.cpp:150] Setting up res3d_branch2a_relu
I0625 14:59:42.942495  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.942498  6673 net.cpp:165] Memory required for data: 3996057684
I0625 14:59:42.942502  6673 layer_factory.hpp:77] Creating layer res3d_branch2b
I0625 14:59:42.942515  6673 net.cpp:100] Creating Layer res3d_branch2b
I0625 14:59:42.942520  6673 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0625 14:59:42.942533  6673 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0625 14:59:42.944298  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0625 14:59:42.944547  6673 net.cpp:150] Setting up res3d_branch2b
I0625 14:59:42.944556  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.944558  6673 net.cpp:165] Memory required for data: 4005888084
I0625 14:59:42.944569  6673 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0625 14:59:42.944582  6673 net.cpp:100] Creating Layer bn3d_branch2b
I0625 14:59:42.944589  6673 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0625 14:59:42.944600  6673 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0625 14:59:42.944864  6673 net.cpp:150] Setting up bn3d_branch2b
I0625 14:59:42.944870  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.944872  6673 net.cpp:165] Memory required for data: 4015718484
I0625 14:59:42.944885  6673 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0625 14:59:42.944897  6673 net.cpp:100] Creating Layer scale3d_branch2b
I0625 14:59:42.944902  6673 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0625 14:59:42.944912  6673 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0625 14:59:42.944969  6673 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0625 14:59:42.945158  6673 net.cpp:150] Setting up scale3d_branch2b
I0625 14:59:42.945163  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.945166  6673 net.cpp:165] Memory required for data: 4025548884
I0625 14:59:42.945174  6673 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0625 14:59:42.945184  6673 net.cpp:100] Creating Layer res3d_branch2b_relu
I0625 14:59:42.945188  6673 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0625 14:59:42.945199  6673 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0625 14:59:42.945335  6673 net.cpp:150] Setting up res3d_branch2b_relu
I0625 14:59:42.945341  6673 net.cpp:157] Top shape: 1 128 120 160 (2457600)
I0625 14:59:42.945343  6673 net.cpp:165] Memory required for data: 4035379284
I0625 14:59:42.945348  6673 layer_factory.hpp:77] Creating layer res3d_branch2c
I0625 14:59:42.945360  6673 net.cpp:100] Creating Layer res3d_branch2c
I0625 14:59:42.945365  6673 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0625 14:59:42.945376  6673 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0625 14:59:42.946386  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0625 14:59:42.946400  6673 net.cpp:150] Setting up res3d_branch2c
I0625 14:59:42.946408  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.946409  6673 net.cpp:165] Memory required for data: 4074700884
I0625 14:59:42.946419  6673 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0625 14:59:42.946431  6673 net.cpp:100] Creating Layer bn3d_branch2c
I0625 14:59:42.946437  6673 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0625 14:59:42.946449  6673 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0625 14:59:42.946715  6673 net.cpp:150] Setting up bn3d_branch2c
I0625 14:59:42.946722  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.946723  6673 net.cpp:165] Memory required for data: 4114022484
I0625 14:59:42.946736  6673 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0625 14:59:42.946749  6673 net.cpp:100] Creating Layer scale3d_branch2c
I0625 14:59:42.946754  6673 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0625 14:59:42.946763  6673 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0625 14:59:42.946816  6673 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0625 14:59:42.947024  6673 net.cpp:150] Setting up scale3d_branch2c
I0625 14:59:42.947031  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.947033  6673 net.cpp:165] Memory required for data: 4153344084
I0625 14:59:42.947041  6673 layer_factory.hpp:77] Creating layer res3d
I0625 14:59:42.947052  6673 net.cpp:100] Creating Layer res3d
I0625 14:59:42.947055  6673 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0625 14:59:42.947064  6673 net.cpp:444] res3d <- res3d_branch2c
I0625 14:59:42.947072  6673 net.cpp:418] res3d -> res3d
I0625 14:59:42.947108  6673 net.cpp:150] Setting up res3d
I0625 14:59:42.947115  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.947118  6673 net.cpp:165] Memory required for data: 4192665684
I0625 14:59:42.947120  6673 layer_factory.hpp:77] Creating layer res3d_relu
I0625 14:59:42.947129  6673 net.cpp:100] Creating Layer res3d_relu
I0625 14:59:42.947134  6673 net.cpp:444] res3d_relu <- res3d
I0625 14:59:42.947142  6673 net.cpp:405] res3d_relu -> res3d (in-place)
I0625 14:59:42.947274  6673 net.cpp:150] Setting up res3d_relu
I0625 14:59:42.947280  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.947283  6673 net.cpp:165] Memory required for data: 4231987284
I0625 14:59:42.947285  6673 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0625 14:59:42.947294  6673 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0625 14:59:42.947299  6673 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0625 14:59:42.947309  6673 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0625 14:59:42.947321  6673 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0625 14:59:42.947373  6673 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0625 14:59:42.947381  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.947384  6673 net.cpp:157] Top shape: 1 512 120 160 (9830400)
I0625 14:59:42.947386  6673 net.cpp:165] Memory required for data: 4310630484
I0625 14:59:42.947389  6673 layer_factory.hpp:77] Creating layer res4a_branch1
I0625 14:59:42.947402  6673 net.cpp:100] Creating Layer res4a_branch1
I0625 14:59:42.947407  6673 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0625 14:59:42.947417  6673 net.cpp:418] res4a_branch1 -> res4a_branch1
I0625 14:59:42.949774  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 14:59:42.950057  6673 net.cpp:150] Setting up res4a_branch1
I0625 14:59:42.950071  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.950073  6673 net.cpp:165] Memory required for data: 4330291284
I0625 14:59:42.950090  6673 layer_factory.hpp:77] Creating layer bn4a_branch1
I0625 14:59:42.950111  6673 net.cpp:100] Creating Layer bn4a_branch1
I0625 14:59:42.950119  6673 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0625 14:59:42.950134  6673 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0625 14:59:42.950397  6673 net.cpp:150] Setting up bn4a_branch1
I0625 14:59:42.950403  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.950405  6673 net.cpp:165] Memory required for data: 4349952084
I0625 14:59:42.950419  6673 layer_factory.hpp:77] Creating layer scale4a_branch1
I0625 14:59:42.950433  6673 net.cpp:100] Creating Layer scale4a_branch1
I0625 14:59:42.950438  6673 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0625 14:59:42.950448  6673 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0625 14:59:42.950502  6673 layer_factory.hpp:77] Creating layer scale4a_branch1
I0625 14:59:42.950680  6673 net.cpp:150] Setting up scale4a_branch1
I0625 14:59:42.950686  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.950690  6673 net.cpp:165] Memory required for data: 4369612884
I0625 14:59:42.950697  6673 layer_factory.hpp:77] Creating layer res4a_branch2a
I0625 14:59:42.950712  6673 net.cpp:100] Creating Layer res4a_branch2a
I0625 14:59:42.950717  6673 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0625 14:59:42.950728  6673 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0625 14:59:42.952432  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 14:59:42.952450  6673 net.cpp:150] Setting up res4a_branch2a
I0625 14:59:42.952456  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.952458  6673 net.cpp:165] Memory required for data: 4374528084
I0625 14:59:42.952467  6673 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0625 14:59:42.952478  6673 net.cpp:100] Creating Layer bn4a_branch2a
I0625 14:59:42.952483  6673 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0625 14:59:42.952495  6673 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0625 14:59:42.952744  6673 net.cpp:150] Setting up bn4a_branch2a
I0625 14:59:42.952749  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.952751  6673 net.cpp:165] Memory required for data: 4379443284
I0625 14:59:42.952764  6673 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0625 14:59:42.952775  6673 net.cpp:100] Creating Layer scale4a_branch2a
I0625 14:59:42.952780  6673 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0625 14:59:42.952788  6673 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0625 14:59:42.952844  6673 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0625 14:59:42.953011  6673 net.cpp:150] Setting up scale4a_branch2a
I0625 14:59:42.953017  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.953019  6673 net.cpp:165] Memory required for data: 4384358484
I0625 14:59:42.953028  6673 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0625 14:59:42.953037  6673 net.cpp:100] Creating Layer res4a_branch2a_relu
I0625 14:59:42.953042  6673 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0625 14:59:42.953050  6673 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0625 14:59:42.953438  6673 net.cpp:150] Setting up res4a_branch2a_relu
I0625 14:59:42.953445  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.953447  6673 net.cpp:165] Memory required for data: 4389273684
I0625 14:59:42.953451  6673 layer_factory.hpp:77] Creating layer res4a_branch2b
I0625 14:59:42.953465  6673 net.cpp:100] Creating Layer res4a_branch2b
I0625 14:59:42.953470  6673 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0625 14:59:42.953485  6673 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0625 14:59:42.955943  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 14:59:42.956202  6673 net.cpp:150] Setting up res4a_branch2b
I0625 14:59:42.956214  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.956216  6673 net.cpp:165] Memory required for data: 4394188884
I0625 14:59:42.956229  6673 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0625 14:59:42.956244  6673 net.cpp:100] Creating Layer bn4a_branch2b
I0625 14:59:42.956251  6673 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0625 14:59:42.956264  6673 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0625 14:59:42.956527  6673 net.cpp:150] Setting up bn4a_branch2b
I0625 14:59:42.956533  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.956535  6673 net.cpp:165] Memory required for data: 4399104084
I0625 14:59:42.956547  6673 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0625 14:59:42.956560  6673 net.cpp:100] Creating Layer scale4a_branch2b
I0625 14:59:42.956564  6673 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0625 14:59:42.956573  6673 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0625 14:59:42.956634  6673 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0625 14:59:42.956804  6673 net.cpp:150] Setting up scale4a_branch2b
I0625 14:59:42.956809  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.956811  6673 net.cpp:165] Memory required for data: 4404019284
I0625 14:59:42.956820  6673 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0625 14:59:42.956830  6673 net.cpp:100] Creating Layer res4a_branch2b_relu
I0625 14:59:42.956833  6673 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0625 14:59:42.956841  6673 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0625 14:59:42.956982  6673 net.cpp:150] Setting up res4a_branch2b_relu
I0625 14:59:42.956989  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.956990  6673 net.cpp:165] Memory required for data: 4408934484
I0625 14:59:42.956993  6673 layer_factory.hpp:77] Creating layer res4a_branch2c
I0625 14:59:42.957006  6673 net.cpp:100] Creating Layer res4a_branch2c
I0625 14:59:42.957010  6673 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0625 14:59:42.957021  6673 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0625 14:59:42.958961  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.958979  6673 net.cpp:150] Setting up res4a_branch2c
I0625 14:59:42.958986  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.958988  6673 net.cpp:165] Memory required for data: 4428595284
I0625 14:59:42.958997  6673 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0625 14:59:42.959010  6673 net.cpp:100] Creating Layer bn4a_branch2c
I0625 14:59:42.959017  6673 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0625 14:59:42.959028  6673 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0625 14:59:42.959288  6673 net.cpp:150] Setting up bn4a_branch2c
I0625 14:59:42.959295  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.959296  6673 net.cpp:165] Memory required for data: 4448256084
I0625 14:59:42.959309  6673 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0625 14:59:42.959321  6673 net.cpp:100] Creating Layer scale4a_branch2c
I0625 14:59:42.959324  6673 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0625 14:59:42.959334  6673 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0625 14:59:42.959388  6673 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0625 14:59:42.959563  6673 net.cpp:150] Setting up scale4a_branch2c
I0625 14:59:42.959569  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.959571  6673 net.cpp:165] Memory required for data: 4467916884
I0625 14:59:42.959579  6673 layer_factory.hpp:77] Creating layer res4a
I0625 14:59:42.959602  6673 net.cpp:100] Creating Layer res4a
I0625 14:59:42.959607  6673 net.cpp:444] res4a <- res4a_branch1
I0625 14:59:42.959615  6673 net.cpp:444] res4a <- res4a_branch2c
I0625 14:59:42.959621  6673 net.cpp:418] res4a -> res4a
I0625 14:59:42.959658  6673 net.cpp:150] Setting up res4a
I0625 14:59:42.959666  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.959667  6673 net.cpp:165] Memory required for data: 4487577684
I0625 14:59:42.959672  6673 layer_factory.hpp:77] Creating layer res4a_relu
I0625 14:59:42.959679  6673 net.cpp:100] Creating Layer res4a_relu
I0625 14:59:42.959684  6673 net.cpp:444] res4a_relu <- res4a
I0625 14:59:42.959692  6673 net.cpp:405] res4a_relu -> res4a (in-place)
I0625 14:59:42.959826  6673 net.cpp:150] Setting up res4a_relu
I0625 14:59:42.959833  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.959836  6673 net.cpp:165] Memory required for data: 4507238484
I0625 14:59:42.959839  6673 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0625 14:59:42.959847  6673 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0625 14:59:42.959852  6673 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0625 14:59:42.959861  6673 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0625 14:59:42.959874  6673 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0625 14:59:42.959928  6673 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0625 14:59:42.959935  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.959939  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.959940  6673 net.cpp:165] Memory required for data: 4546560084
I0625 14:59:42.959944  6673 layer_factory.hpp:77] Creating layer res4b_branch2a
I0625 14:59:42.959955  6673 net.cpp:100] Creating Layer res4b_branch2a
I0625 14:59:42.959959  6673 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0625 14:59:42.959971  6673 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0625 14:59:42.961208  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.961230  6673 net.cpp:150] Setting up res4b_branch2a
I0625 14:59:42.961237  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.961241  6673 net.cpp:165] Memory required for data: 4551475284
I0625 14:59:42.961248  6673 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0625 14:59:42.961261  6673 net.cpp:100] Creating Layer bn4b_branch2a
I0625 14:59:42.961266  6673 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0625 14:59:42.961278  6673 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0625 14:59:42.961530  6673 net.cpp:150] Setting up bn4b_branch2a
I0625 14:59:42.961536  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.961539  6673 net.cpp:165] Memory required for data: 4556390484
I0625 14:59:42.961551  6673 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0625 14:59:42.961562  6673 net.cpp:100] Creating Layer scale4b_branch2a
I0625 14:59:42.961567  6673 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0625 14:59:42.961576  6673 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0625 14:59:42.961634  6673 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0625 14:59:42.961807  6673 net.cpp:150] Setting up scale4b_branch2a
I0625 14:59:42.961812  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.961814  6673 net.cpp:165] Memory required for data: 4561305684
I0625 14:59:42.961823  6673 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0625 14:59:42.961832  6673 net.cpp:100] Creating Layer res4b_branch2a_relu
I0625 14:59:42.961836  6673 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0625 14:59:42.961845  6673 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0625 14:59:42.962227  6673 net.cpp:150] Setting up res4b_branch2a_relu
I0625 14:59:42.962234  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.962237  6673 net.cpp:165] Memory required for data: 4566220884
I0625 14:59:42.962240  6673 layer_factory.hpp:77] Creating layer res4b_branch2b
I0625 14:59:42.962255  6673 net.cpp:100] Creating Layer res4b_branch2b
I0625 14:59:42.962260  6673 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0625 14:59:42.962272  6673 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0625 14:59:42.964733  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 14:59:42.964998  6673 net.cpp:150] Setting up res4b_branch2b
I0625 14:59:42.965008  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.965010  6673 net.cpp:165] Memory required for data: 4571136084
I0625 14:59:42.965023  6673 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0625 14:59:42.965039  6673 net.cpp:100] Creating Layer bn4b_branch2b
I0625 14:59:42.965045  6673 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0625 14:59:42.965059  6673 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0625 14:59:42.965327  6673 net.cpp:150] Setting up bn4b_branch2b
I0625 14:59:42.965332  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.965334  6673 net.cpp:165] Memory required for data: 4576051284
I0625 14:59:42.965348  6673 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0625 14:59:42.965359  6673 net.cpp:100] Creating Layer scale4b_branch2b
I0625 14:59:42.965364  6673 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0625 14:59:42.965373  6673 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0625 14:59:42.965431  6673 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0625 14:59:42.965605  6673 net.cpp:150] Setting up scale4b_branch2b
I0625 14:59:42.965611  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.965613  6673 net.cpp:165] Memory required for data: 4580966484
I0625 14:59:42.965622  6673 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0625 14:59:42.965631  6673 net.cpp:100] Creating Layer res4b_branch2b_relu
I0625 14:59:42.965634  6673 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0625 14:59:42.965643  6673 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0625 14:59:42.965783  6673 net.cpp:150] Setting up res4b_branch2b_relu
I0625 14:59:42.965790  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.965793  6673 net.cpp:165] Memory required for data: 4585881684
I0625 14:59:42.965796  6673 layer_factory.hpp:77] Creating layer res4b_branch2c
I0625 14:59:42.965809  6673 net.cpp:100] Creating Layer res4b_branch2c
I0625 14:59:42.965813  6673 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0625 14:59:42.965826  6673 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0625 14:59:42.967838  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.967861  6673 net.cpp:150] Setting up res4b_branch2c
I0625 14:59:42.967870  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.967872  6673 net.cpp:165] Memory required for data: 4605542484
I0625 14:59:42.967883  6673 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0625 14:59:42.967895  6673 net.cpp:100] Creating Layer bn4b_branch2c
I0625 14:59:42.967901  6673 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0625 14:59:42.967914  6673 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0625 14:59:42.968186  6673 net.cpp:150] Setting up bn4b_branch2c
I0625 14:59:42.968192  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.968194  6673 net.cpp:165] Memory required for data: 4625203284
I0625 14:59:42.968207  6673 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0625 14:59:42.968220  6673 net.cpp:100] Creating Layer scale4b_branch2c
I0625 14:59:42.968225  6673 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0625 14:59:42.968235  6673 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0625 14:59:42.968288  6673 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0625 14:59:42.968468  6673 net.cpp:150] Setting up scale4b_branch2c
I0625 14:59:42.968474  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.968477  6673 net.cpp:165] Memory required for data: 4644864084
I0625 14:59:42.968487  6673 layer_factory.hpp:77] Creating layer res4b
I0625 14:59:42.968497  6673 net.cpp:100] Creating Layer res4b
I0625 14:59:42.968502  6673 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0625 14:59:42.968510  6673 net.cpp:444] res4b <- res4b_branch2c
I0625 14:59:42.968518  6673 net.cpp:418] res4b -> res4b
I0625 14:59:42.968555  6673 net.cpp:150] Setting up res4b
I0625 14:59:42.968562  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.968564  6673 net.cpp:165] Memory required for data: 4664524884
I0625 14:59:42.968567  6673 layer_factory.hpp:77] Creating layer res4b_relu
I0625 14:59:42.968575  6673 net.cpp:100] Creating Layer res4b_relu
I0625 14:59:42.968580  6673 net.cpp:444] res4b_relu <- res4b
I0625 14:59:42.968588  6673 net.cpp:405] res4b_relu -> res4b (in-place)
I0625 14:59:42.968724  6673 net.cpp:150] Setting up res4b_relu
I0625 14:59:42.968729  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.968731  6673 net.cpp:165] Memory required for data: 4684185684
I0625 14:59:42.968735  6673 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0625 14:59:42.968744  6673 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0625 14:59:42.968749  6673 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0625 14:59:42.968757  6673 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0625 14:59:42.968768  6673 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0625 14:59:42.968822  6673 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0625 14:59:42.968828  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.968832  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.968833  6673 net.cpp:165] Memory required for data: 4723507284
I0625 14:59:42.968837  6673 layer_factory.hpp:77] Creating layer res4c_branch2a
I0625 14:59:42.968847  6673 net.cpp:100] Creating Layer res4c_branch2a
I0625 14:59:42.968852  6673 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0625 14:59:42.968863  6673 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0625 14:59:42.970113  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.970132  6673 net.cpp:150] Setting up res4c_branch2a
I0625 14:59:42.970139  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.970141  6673 net.cpp:165] Memory required for data: 4728422484
I0625 14:59:42.970150  6673 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0625 14:59:42.970162  6673 net.cpp:100] Creating Layer bn4c_branch2a
I0625 14:59:42.970167  6673 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0625 14:59:42.970178  6673 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0625 14:59:42.970438  6673 net.cpp:150] Setting up bn4c_branch2a
I0625 14:59:42.970443  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.970445  6673 net.cpp:165] Memory required for data: 4733337684
I0625 14:59:42.970458  6673 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0625 14:59:42.970470  6673 net.cpp:100] Creating Layer scale4c_branch2a
I0625 14:59:42.970474  6673 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0625 14:59:42.970484  6673 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0625 14:59:42.970542  6673 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0625 14:59:42.970715  6673 net.cpp:150] Setting up scale4c_branch2a
I0625 14:59:42.970721  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.970722  6673 net.cpp:165] Memory required for data: 4738252884
I0625 14:59:42.970731  6673 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0625 14:59:42.970739  6673 net.cpp:100] Creating Layer res4c_branch2a_relu
I0625 14:59:42.970744  6673 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0625 14:59:42.970758  6673 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0625 14:59:42.970898  6673 net.cpp:150] Setting up res4c_branch2a_relu
I0625 14:59:42.970904  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.970906  6673 net.cpp:165] Memory required for data: 4743168084
I0625 14:59:42.970911  6673 layer_factory.hpp:77] Creating layer res4c_branch2b
I0625 14:59:42.970922  6673 net.cpp:100] Creating Layer res4c_branch2b
I0625 14:59:42.970928  6673 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0625 14:59:42.970940  6673 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0625 14:59:42.973623  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 14:59:42.973883  6673 net.cpp:150] Setting up res4c_branch2b
I0625 14:59:42.973894  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.973896  6673 net.cpp:165] Memory required for data: 4748083284
I0625 14:59:42.973907  6673 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0625 14:59:42.973923  6673 net.cpp:100] Creating Layer bn4c_branch2b
I0625 14:59:42.973929  6673 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0625 14:59:42.973943  6673 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0625 14:59:42.974215  6673 net.cpp:150] Setting up bn4c_branch2b
I0625 14:59:42.974220  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.974221  6673 net.cpp:165] Memory required for data: 4752998484
I0625 14:59:42.974234  6673 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0625 14:59:42.974247  6673 net.cpp:100] Creating Layer scale4c_branch2b
I0625 14:59:42.974252  6673 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0625 14:59:42.974261  6673 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0625 14:59:42.974320  6673 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0625 14:59:42.974498  6673 net.cpp:150] Setting up scale4c_branch2b
I0625 14:59:42.974504  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.974506  6673 net.cpp:165] Memory required for data: 4757913684
I0625 14:59:42.974515  6673 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0625 14:59:42.974524  6673 net.cpp:100] Creating Layer res4c_branch2b_relu
I0625 14:59:42.974529  6673 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0625 14:59:42.974537  6673 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0625 14:59:42.974927  6673 net.cpp:150] Setting up res4c_branch2b_relu
I0625 14:59:42.974936  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.974937  6673 net.cpp:165] Memory required for data: 4762828884
I0625 14:59:42.974941  6673 layer_factory.hpp:77] Creating layer res4c_branch2c
I0625 14:59:42.974956  6673 net.cpp:100] Creating Layer res4c_branch2c
I0625 14:59:42.974961  6673 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0625 14:59:42.974974  6673 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0625 14:59:42.976941  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.976963  6673 net.cpp:150] Setting up res4c_branch2c
I0625 14:59:42.976970  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.976972  6673 net.cpp:165] Memory required for data: 4782489684
I0625 14:59:42.976982  6673 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0625 14:59:42.976994  6673 net.cpp:100] Creating Layer bn4c_branch2c
I0625 14:59:42.976999  6673 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0625 14:59:42.977011  6673 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0625 14:59:42.977283  6673 net.cpp:150] Setting up bn4c_branch2c
I0625 14:59:42.977289  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.977291  6673 net.cpp:165] Memory required for data: 4802150484
I0625 14:59:42.977304  6673 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0625 14:59:42.977315  6673 net.cpp:100] Creating Layer scale4c_branch2c
I0625 14:59:42.977319  6673 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0625 14:59:42.977329  6673 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0625 14:59:42.977385  6673 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0625 14:59:42.977566  6673 net.cpp:150] Setting up scale4c_branch2c
I0625 14:59:42.977572  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.977576  6673 net.cpp:165] Memory required for data: 4821811284
I0625 14:59:42.977583  6673 layer_factory.hpp:77] Creating layer res4c
I0625 14:59:42.977592  6673 net.cpp:100] Creating Layer res4c
I0625 14:59:42.977597  6673 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0625 14:59:42.977607  6673 net.cpp:444] res4c <- res4c_branch2c
I0625 14:59:42.977613  6673 net.cpp:418] res4c -> res4c
I0625 14:59:42.977651  6673 net.cpp:150] Setting up res4c
I0625 14:59:42.977658  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.977660  6673 net.cpp:165] Memory required for data: 4841472084
I0625 14:59:42.977664  6673 layer_factory.hpp:77] Creating layer res4c_relu
I0625 14:59:42.977671  6673 net.cpp:100] Creating Layer res4c_relu
I0625 14:59:42.977675  6673 net.cpp:444] res4c_relu <- res4c
I0625 14:59:42.977684  6673 net.cpp:405] res4c_relu -> res4c (in-place)
I0625 14:59:42.977820  6673 net.cpp:150] Setting up res4c_relu
I0625 14:59:42.977826  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.977828  6673 net.cpp:165] Memory required for data: 4861132884
I0625 14:59:42.977831  6673 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0625 14:59:42.977839  6673 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0625 14:59:42.977844  6673 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0625 14:59:42.977854  6673 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0625 14:59:42.977866  6673 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0625 14:59:42.977919  6673 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0625 14:59:42.977926  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.977931  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.977931  6673 net.cpp:165] Memory required for data: 4900454484
I0625 14:59:42.977934  6673 layer_factory.hpp:77] Creating layer res4d_branch2a
I0625 14:59:42.977946  6673 net.cpp:100] Creating Layer res4d_branch2a
I0625 14:59:42.977952  6673 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0625 14:59:42.977963  6673 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0625 14:59:42.979229  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.979255  6673 net.cpp:150] Setting up res4d_branch2a
I0625 14:59:42.979264  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.979266  6673 net.cpp:165] Memory required for data: 4905369684
I0625 14:59:42.979276  6673 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0625 14:59:42.979290  6673 net.cpp:100] Creating Layer bn4d_branch2a
I0625 14:59:42.979295  6673 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0625 14:59:42.979307  6673 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0625 14:59:42.979578  6673 net.cpp:150] Setting up bn4d_branch2a
I0625 14:59:42.979583  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.979585  6673 net.cpp:165] Memory required for data: 4910284884
I0625 14:59:42.979599  6673 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0625 14:59:42.979612  6673 net.cpp:100] Creating Layer scale4d_branch2a
I0625 14:59:42.979619  6673 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0625 14:59:42.979626  6673 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0625 14:59:42.979687  6673 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0625 14:59:42.979867  6673 net.cpp:150] Setting up scale4d_branch2a
I0625 14:59:42.979874  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.979876  6673 net.cpp:165] Memory required for data: 4915200084
I0625 14:59:42.979884  6673 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0625 14:59:42.979893  6673 net.cpp:100] Creating Layer res4d_branch2a_relu
I0625 14:59:42.979898  6673 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0625 14:59:42.979907  6673 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0625 14:59:42.980047  6673 net.cpp:150] Setting up res4d_branch2a_relu
I0625 14:59:42.980053  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.980056  6673 net.cpp:165] Memory required for data: 4920115284
I0625 14:59:42.980059  6673 layer_factory.hpp:77] Creating layer res4d_branch2b
I0625 14:59:42.980072  6673 net.cpp:100] Creating Layer res4d_branch2b
I0625 14:59:42.980077  6673 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0625 14:59:42.980090  6673 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0625 14:59:42.982614  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 14:59:42.982894  6673 net.cpp:150] Setting up res4d_branch2b
I0625 14:59:42.982913  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.982915  6673 net.cpp:165] Memory required for data: 4925030484
I0625 14:59:42.982929  6673 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0625 14:59:42.982949  6673 net.cpp:100] Creating Layer bn4d_branch2b
I0625 14:59:42.982955  6673 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0625 14:59:42.982970  6673 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0625 14:59:42.983256  6673 net.cpp:150] Setting up bn4d_branch2b
I0625 14:59:42.983263  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.983263  6673 net.cpp:165] Memory required for data: 4929945684
I0625 14:59:42.983278  6673 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0625 14:59:42.983290  6673 net.cpp:100] Creating Layer scale4d_branch2b
I0625 14:59:42.983295  6673 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0625 14:59:42.983305  6673 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0625 14:59:42.983366  6673 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0625 14:59:42.983551  6673 net.cpp:150] Setting up scale4d_branch2b
I0625 14:59:42.983556  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.983557  6673 net.cpp:165] Memory required for data: 4934860884
I0625 14:59:42.983566  6673 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0625 14:59:42.983575  6673 net.cpp:100] Creating Layer res4d_branch2b_relu
I0625 14:59:42.983580  6673 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0625 14:59:42.983588  6673 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0625 14:59:42.984053  6673 net.cpp:150] Setting up res4d_branch2b_relu
I0625 14:59:42.984061  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.984063  6673 net.cpp:165] Memory required for data: 4939776084
I0625 14:59:42.984067  6673 layer_factory.hpp:77] Creating layer res4d_branch2c
I0625 14:59:42.984084  6673 net.cpp:100] Creating Layer res4d_branch2c
I0625 14:59:42.984091  6673 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0625 14:59:42.984104  6673 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0625 14:59:42.986160  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.986184  6673 net.cpp:150] Setting up res4d_branch2c
I0625 14:59:42.986192  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.986194  6673 net.cpp:165] Memory required for data: 4959436884
I0625 14:59:42.986204  6673 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0625 14:59:42.986218  6673 net.cpp:100] Creating Layer bn4d_branch2c
I0625 14:59:42.986224  6673 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0625 14:59:42.986237  6673 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0625 14:59:42.986515  6673 net.cpp:150] Setting up bn4d_branch2c
I0625 14:59:42.986521  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.986523  6673 net.cpp:165] Memory required for data: 4979097684
I0625 14:59:42.986536  6673 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0625 14:59:42.986547  6673 net.cpp:100] Creating Layer scale4d_branch2c
I0625 14:59:42.986552  6673 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0625 14:59:42.986562  6673 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0625 14:59:42.986619  6673 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0625 14:59:42.986802  6673 net.cpp:150] Setting up scale4d_branch2c
I0625 14:59:42.986809  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.986811  6673 net.cpp:165] Memory required for data: 4998758484
I0625 14:59:42.986819  6673 layer_factory.hpp:77] Creating layer res4d
I0625 14:59:42.986829  6673 net.cpp:100] Creating Layer res4d
I0625 14:59:42.986834  6673 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0625 14:59:42.986842  6673 net.cpp:444] res4d <- res4d_branch2c
I0625 14:59:42.986850  6673 net.cpp:418] res4d -> res4d
I0625 14:59:42.986917  6673 net.cpp:150] Setting up res4d
I0625 14:59:42.986924  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.986927  6673 net.cpp:165] Memory required for data: 5018419284
I0625 14:59:42.986929  6673 layer_factory.hpp:77] Creating layer res4d_relu
I0625 14:59:42.986937  6673 net.cpp:100] Creating Layer res4d_relu
I0625 14:59:42.986941  6673 net.cpp:444] res4d_relu <- res4d
I0625 14:59:42.986953  6673 net.cpp:405] res4d_relu -> res4d (in-place)
I0625 14:59:42.987089  6673 net.cpp:150] Setting up res4d_relu
I0625 14:59:42.987095  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.987097  6673 net.cpp:165] Memory required for data: 5038080084
I0625 14:59:42.987102  6673 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0625 14:59:42.987109  6673 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0625 14:59:42.987114  6673 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0625 14:59:42.987124  6673 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0625 14:59:42.987138  6673 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0625 14:59:42.987191  6673 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0625 14:59:42.987198  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.987201  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.987203  6673 net.cpp:165] Memory required for data: 5077401684
I0625 14:59:42.987206  6673 layer_factory.hpp:77] Creating layer res4e_branch2a
I0625 14:59:42.987218  6673 net.cpp:100] Creating Layer res4e_branch2a
I0625 14:59:42.987223  6673 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0625 14:59:42.987236  6673 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0625 14:59:42.988502  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.988523  6673 net.cpp:150] Setting up res4e_branch2a
I0625 14:59:42.988529  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.988531  6673 net.cpp:165] Memory required for data: 5082316884
I0625 14:59:42.988540  6673 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0625 14:59:42.988553  6673 net.cpp:100] Creating Layer bn4e_branch2a
I0625 14:59:42.988557  6673 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0625 14:59:42.988569  6673 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0625 14:59:42.988840  6673 net.cpp:150] Setting up bn4e_branch2a
I0625 14:59:42.988845  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.988848  6673 net.cpp:165] Memory required for data: 5087232084
I0625 14:59:42.988862  6673 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0625 14:59:42.988873  6673 net.cpp:100] Creating Layer scale4e_branch2a
I0625 14:59:42.988878  6673 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0625 14:59:42.988888  6673 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0625 14:59:42.988947  6673 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0625 14:59:42.989125  6673 net.cpp:150] Setting up scale4e_branch2a
I0625 14:59:42.989131  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.989133  6673 net.cpp:165] Memory required for data: 5092147284
I0625 14:59:42.989142  6673 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0625 14:59:42.989151  6673 net.cpp:100] Creating Layer res4e_branch2a_relu
I0625 14:59:42.989156  6673 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0625 14:59:42.989166  6673 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0625 14:59:42.989302  6673 net.cpp:150] Setting up res4e_branch2a_relu
I0625 14:59:42.989308  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.989311  6673 net.cpp:165] Memory required for data: 5097062484
I0625 14:59:42.989315  6673 layer_factory.hpp:77] Creating layer res4e_branch2b
I0625 14:59:42.989326  6673 net.cpp:100] Creating Layer res4e_branch2b
I0625 14:59:42.989331  6673 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0625 14:59:42.989343  6673 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0625 14:59:42.991801  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 14:59:42.992703  6673 net.cpp:150] Setting up res4e_branch2b
I0625 14:59:42.992715  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.992717  6673 net.cpp:165] Memory required for data: 5101977684
I0625 14:59:42.992730  6673 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0625 14:59:42.992746  6673 net.cpp:100] Creating Layer bn4e_branch2b
I0625 14:59:42.992751  6673 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0625 14:59:42.992764  6673 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0625 14:59:42.993053  6673 net.cpp:150] Setting up bn4e_branch2b
I0625 14:59:42.993062  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.993063  6673 net.cpp:165] Memory required for data: 5106892884
I0625 14:59:42.993077  6673 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0625 14:59:42.993088  6673 net.cpp:100] Creating Layer scale4e_branch2b
I0625 14:59:42.993093  6673 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0625 14:59:42.993103  6673 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0625 14:59:42.993165  6673 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0625 14:59:42.993345  6673 net.cpp:150] Setting up scale4e_branch2b
I0625 14:59:42.993351  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.993352  6673 net.cpp:165] Memory required for data: 5111808084
I0625 14:59:42.993361  6673 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0625 14:59:42.993369  6673 net.cpp:100] Creating Layer res4e_branch2b_relu
I0625 14:59:42.993373  6673 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0625 14:59:42.993382  6673 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0625 14:59:42.993778  6673 net.cpp:150] Setting up res4e_branch2b_relu
I0625 14:59:42.993788  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.993789  6673 net.cpp:165] Memory required for data: 5116723284
I0625 14:59:42.993793  6673 layer_factory.hpp:77] Creating layer res4e_branch2c
I0625 14:59:42.993808  6673 net.cpp:100] Creating Layer res4e_branch2c
I0625 14:59:42.993813  6673 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0625 14:59:42.993825  6673 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0625 14:59:42.995856  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.995878  6673 net.cpp:150] Setting up res4e_branch2c
I0625 14:59:42.995887  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.995888  6673 net.cpp:165] Memory required for data: 5136384084
I0625 14:59:42.995898  6673 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0625 14:59:42.995911  6673 net.cpp:100] Creating Layer bn4e_branch2c
I0625 14:59:42.995918  6673 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0625 14:59:42.995929  6673 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0625 14:59:42.996209  6673 net.cpp:150] Setting up bn4e_branch2c
I0625 14:59:42.996215  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.996217  6673 net.cpp:165] Memory required for data: 5156044884
I0625 14:59:42.996230  6673 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0625 14:59:42.996242  6673 net.cpp:100] Creating Layer scale4e_branch2c
I0625 14:59:42.996246  6673 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0625 14:59:42.996256  6673 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0625 14:59:42.996314  6673 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0625 14:59:42.996502  6673 net.cpp:150] Setting up scale4e_branch2c
I0625 14:59:42.996508  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.996510  6673 net.cpp:165] Memory required for data: 5175705684
I0625 14:59:42.996520  6673 layer_factory.hpp:77] Creating layer res4e
I0625 14:59:42.996528  6673 net.cpp:100] Creating Layer res4e
I0625 14:59:42.996533  6673 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0625 14:59:42.996541  6673 net.cpp:444] res4e <- res4e_branch2c
I0625 14:59:42.996549  6673 net.cpp:418] res4e -> res4e
I0625 14:59:42.996588  6673 net.cpp:150] Setting up res4e
I0625 14:59:42.996594  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.996598  6673 net.cpp:165] Memory required for data: 5195366484
I0625 14:59:42.996600  6673 layer_factory.hpp:77] Creating layer res4e_relu
I0625 14:59:42.996608  6673 net.cpp:100] Creating Layer res4e_relu
I0625 14:59:42.996611  6673 net.cpp:444] res4e_relu <- res4e
I0625 14:59:42.996621  6673 net.cpp:405] res4e_relu -> res4e (in-place)
I0625 14:59:42.996758  6673 net.cpp:150] Setting up res4e_relu
I0625 14:59:42.996764  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.996767  6673 net.cpp:165] Memory required for data: 5215027284
I0625 14:59:42.996769  6673 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0625 14:59:42.996778  6673 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0625 14:59:42.996783  6673 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0625 14:59:42.996793  6673 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0625 14:59:42.996805  6673 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0625 14:59:42.996860  6673 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0625 14:59:42.996866  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.996870  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:42.996871  6673 net.cpp:165] Memory required for data: 5254348884
I0625 14:59:42.996875  6673 layer_factory.hpp:77] Creating layer res4f_branch2a
I0625 14:59:42.996886  6673 net.cpp:100] Creating Layer res4f_branch2a
I0625 14:59:42.996891  6673 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0625 14:59:42.996902  6673 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0625 14:59:42.998159  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:42.998179  6673 net.cpp:150] Setting up res4f_branch2a
I0625 14:59:42.998186  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.998188  6673 net.cpp:165] Memory required for data: 5259264084
I0625 14:59:42.998198  6673 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0625 14:59:42.998209  6673 net.cpp:100] Creating Layer bn4f_branch2a
I0625 14:59:42.998214  6673 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0625 14:59:42.998225  6673 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0625 14:59:42.998497  6673 net.cpp:150] Setting up bn4f_branch2a
I0625 14:59:42.998502  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.998504  6673 net.cpp:165] Memory required for data: 5264179284
I0625 14:59:42.998517  6673 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0625 14:59:42.998528  6673 net.cpp:100] Creating Layer scale4f_branch2a
I0625 14:59:42.998533  6673 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0625 14:59:42.998543  6673 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0625 14:59:42.998601  6673 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0625 14:59:42.998781  6673 net.cpp:150] Setting up scale4f_branch2a
I0625 14:59:42.998788  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.998790  6673 net.cpp:165] Memory required for data: 5269094484
I0625 14:59:42.998798  6673 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0625 14:59:42.998807  6673 net.cpp:100] Creating Layer res4f_branch2a_relu
I0625 14:59:42.998811  6673 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0625 14:59:42.998821  6673 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0625 14:59:42.998962  6673 net.cpp:150] Setting up res4f_branch2a_relu
I0625 14:59:42.998970  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:42.998971  6673 net.cpp:165] Memory required for data: 5274009684
I0625 14:59:42.998975  6673 layer_factory.hpp:77] Creating layer res4f_branch2b
I0625 14:59:42.998986  6673 net.cpp:100] Creating Layer res4f_branch2b
I0625 14:59:42.998991  6673 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0625 14:59:42.999004  6673 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0625 14:59:43.001497  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0625 14:59:43.001768  6673 net.cpp:150] Setting up res4f_branch2b
I0625 14:59:43.001780  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:43.001783  6673 net.cpp:165] Memory required for data: 5278924884
I0625 14:59:43.001796  6673 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0625 14:59:43.001813  6673 net.cpp:100] Creating Layer bn4f_branch2b
I0625 14:59:43.001819  6673 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0625 14:59:43.001833  6673 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0625 14:59:43.002120  6673 net.cpp:150] Setting up bn4f_branch2b
I0625 14:59:43.002125  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:43.002128  6673 net.cpp:165] Memory required for data: 5283840084
I0625 14:59:43.002141  6673 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0625 14:59:43.002152  6673 net.cpp:100] Creating Layer scale4f_branch2b
I0625 14:59:43.002157  6673 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0625 14:59:43.002167  6673 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0625 14:59:43.002229  6673 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0625 14:59:43.002413  6673 net.cpp:150] Setting up scale4f_branch2b
I0625 14:59:43.002418  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:43.002421  6673 net.cpp:165] Memory required for data: 5288755284
I0625 14:59:43.002430  6673 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0625 14:59:43.002439  6673 net.cpp:100] Creating Layer res4f_branch2b_relu
I0625 14:59:43.002444  6673 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0625 14:59:43.002454  6673 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0625 14:59:43.002600  6673 net.cpp:150] Setting up res4f_branch2b_relu
I0625 14:59:43.002606  6673 net.cpp:157] Top shape: 1 256 60 80 (1228800)
I0625 14:59:43.002609  6673 net.cpp:165] Memory required for data: 5293670484
I0625 14:59:43.002611  6673 layer_factory.hpp:77] Creating layer res4f_branch2c
I0625 14:59:43.002625  6673 net.cpp:100] Creating Layer res4f_branch2c
I0625 14:59:43.002630  6673 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0625 14:59:43.002642  6673 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0625 14:59:43.004629  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.004654  6673 net.cpp:150] Setting up res4f_branch2c
I0625 14:59:43.004662  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.004664  6673 net.cpp:165] Memory required for data: 5313331284
I0625 14:59:43.004673  6673 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0625 14:59:43.004685  6673 net.cpp:100] Creating Layer bn4f_branch2c
I0625 14:59:43.004691  6673 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0625 14:59:43.004703  6673 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0625 14:59:43.004987  6673 net.cpp:150] Setting up bn4f_branch2c
I0625 14:59:43.004993  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.004995  6673 net.cpp:165] Memory required for data: 5332992084
I0625 14:59:43.005038  6673 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0625 14:59:43.005051  6673 net.cpp:100] Creating Layer scale4f_branch2c
I0625 14:59:43.005056  6673 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0625 14:59:43.005066  6673 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0625 14:59:43.005123  6673 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0625 14:59:43.005313  6673 net.cpp:150] Setting up scale4f_branch2c
I0625 14:59:43.005319  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.005321  6673 net.cpp:165] Memory required for data: 5352652884
I0625 14:59:43.005329  6673 layer_factory.hpp:77] Creating layer res4f
I0625 14:59:43.005338  6673 net.cpp:100] Creating Layer res4f
I0625 14:59:43.005343  6673 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0625 14:59:43.005352  6673 net.cpp:444] res4f <- res4f_branch2c
I0625 14:59:43.005359  6673 net.cpp:418] res4f -> res4f
I0625 14:59:43.005398  6673 net.cpp:150] Setting up res4f
I0625 14:59:43.005404  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.005406  6673 net.cpp:165] Memory required for data: 5372313684
I0625 14:59:43.005409  6673 layer_factory.hpp:77] Creating layer res4f_relu
I0625 14:59:43.005417  6673 net.cpp:100] Creating Layer res4f_relu
I0625 14:59:43.005421  6673 net.cpp:444] res4f_relu <- res4f
I0625 14:59:43.005429  6673 net.cpp:405] res4f_relu -> res4f (in-place)
I0625 14:59:43.005831  6673 net.cpp:150] Setting up res4f_relu
I0625 14:59:43.005838  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.005841  6673 net.cpp:165] Memory required for data: 5391974484
I0625 14:59:43.005846  6673 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0625 14:59:43.005854  6673 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0625 14:59:43.005859  6673 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0625 14:59:43.005872  6673 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0625 14:59:43.005884  6673 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0625 14:59:43.005893  6673 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0625 14:59:43.005970  6673 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0625 14:59:43.005976  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.005980  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.005982  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.005985  6673 net.cpp:165] Memory required for data: 5450956884
I0625 14:59:43.005987  6673 layer_factory.hpp:77] Creating layer res5a_branch1
I0625 14:59:43.006000  6673 net.cpp:100] Creating Layer res5a_branch1
I0625 14:59:43.006005  6673 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0625 14:59:43.006016  6673 net.cpp:418] res5a_branch1 -> res5a_branch1
I0625 14:59:43.011703  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 14:59:43.011739  6673 net.cpp:150] Setting up res5a_branch1
I0625 14:59:43.011754  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.011756  6673 net.cpp:165] Memory required for data: 5490278484
I0625 14:59:43.011776  6673 layer_factory.hpp:77] Creating layer bn5a_branch1
I0625 14:59:43.011802  6673 net.cpp:100] Creating Layer bn5a_branch1
I0625 14:59:43.011812  6673 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0625 14:59:43.011829  6673 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0625 14:59:43.012133  6673 net.cpp:150] Setting up bn5a_branch1
I0625 14:59:43.012140  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.012142  6673 net.cpp:165] Memory required for data: 5529600084
I0625 14:59:43.012156  6673 layer_factory.hpp:77] Creating layer scale5a_branch1
I0625 14:59:43.012169  6673 net.cpp:100] Creating Layer scale5a_branch1
I0625 14:59:43.012173  6673 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0625 14:59:43.012184  6673 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0625 14:59:43.012246  6673 layer_factory.hpp:77] Creating layer scale5a_branch1
I0625 14:59:43.012440  6673 net.cpp:150] Setting up scale5a_branch1
I0625 14:59:43.012447  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.012449  6673 net.cpp:165] Memory required for data: 5568921684
I0625 14:59:43.012459  6673 layer_factory.hpp:77] Creating layer res5a_branch2a
I0625 14:59:43.012472  6673 net.cpp:100] Creating Layer res5a_branch2a
I0625 14:59:43.012478  6673 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0625 14:59:43.012490  6673 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0625 14:59:43.017879  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.017910  6673 net.cpp:150] Setting up res5a_branch2a
I0625 14:59:43.017925  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.017926  6673 net.cpp:165] Memory required for data: 5578752084
I0625 14:59:43.017946  6673 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0625 14:59:43.017971  6673 net.cpp:100] Creating Layer bn5a_branch2a
I0625 14:59:43.017979  6673 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0625 14:59:43.017997  6673 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0625 14:59:43.018301  6673 net.cpp:150] Setting up bn5a_branch2a
I0625 14:59:43.018307  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.018308  6673 net.cpp:165] Memory required for data: 5588582484
I0625 14:59:43.018322  6673 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0625 14:59:43.018337  6673 net.cpp:100] Creating Layer scale5a_branch2a
I0625 14:59:43.018342  6673 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0625 14:59:43.018352  6673 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0625 14:59:43.018412  6673 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0625 14:59:43.018610  6673 net.cpp:150] Setting up scale5a_branch2a
I0625 14:59:43.018615  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.018617  6673 net.cpp:165] Memory required for data: 5598412884
I0625 14:59:43.018625  6673 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0625 14:59:43.018636  6673 net.cpp:100] Creating Layer res5a_branch2a_relu
I0625 14:59:43.018640  6673 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0625 14:59:43.018649  6673 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0625 14:59:43.018800  6673 net.cpp:150] Setting up res5a_branch2a_relu
I0625 14:59:43.018805  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.018808  6673 net.cpp:165] Memory required for data: 5608243284
I0625 14:59:43.018811  6673 layer_factory.hpp:77] Creating layer res5a_branch2b
I0625 14:59:43.018826  6673 net.cpp:100] Creating Layer res5a_branch2b
I0625 14:59:43.018833  6673 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0625 14:59:43.018848  6673 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0625 14:59:43.024381  6673 net.cpp:150] Setting up res5a_branch2b
I0625 14:59:43.024415  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.024417  6673 net.cpp:165] Memory required for data: 5618073684
I0625 14:59:43.024439  6673 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0625 14:59:43.024471  6673 net.cpp:100] Creating Layer bn5a_branch2b
I0625 14:59:43.024482  6673 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0625 14:59:43.024498  6673 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0625 14:59:43.024811  6673 net.cpp:150] Setting up bn5a_branch2b
I0625 14:59:43.024816  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.024818  6673 net.cpp:165] Memory required for data: 5627904084
I0625 14:59:43.024832  6673 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0625 14:59:43.024845  6673 net.cpp:100] Creating Layer scale5a_branch2b
I0625 14:59:43.024850  6673 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0625 14:59:43.024860  6673 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0625 14:59:43.024922  6673 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0625 14:59:43.025115  6673 net.cpp:150] Setting up scale5a_branch2b
I0625 14:59:43.025121  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.025123  6673 net.cpp:165] Memory required for data: 5637734484
I0625 14:59:43.025131  6673 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0625 14:59:43.025141  6673 net.cpp:100] Creating Layer res5a_branch2b_relu
I0625 14:59:43.025146  6673 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0625 14:59:43.025156  6673 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0625 14:59:43.025354  6673 net.cpp:150] Setting up res5a_branch2b_relu
I0625 14:59:43.025360  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.025363  6673 net.cpp:165] Memory required for data: 5647564884
I0625 14:59:43.025367  6673 layer_factory.hpp:77] Creating layer res5a_branch2c
I0625 14:59:43.025382  6673 net.cpp:100] Creating Layer res5a_branch2c
I0625 14:59:43.025387  6673 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0625 14:59:43.025398  6673 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0625 14:59:43.028923  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 14:59:43.028955  6673 net.cpp:150] Setting up res5a_branch2c
I0625 14:59:43.028966  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.028969  6673 net.cpp:165] Memory required for data: 5686886484
I0625 14:59:43.028983  6673 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0625 14:59:43.029006  6673 net.cpp:100] Creating Layer bn5a_branch2c
I0625 14:59:43.029013  6673 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0625 14:59:43.029028  6673 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0625 14:59:43.029332  6673 net.cpp:150] Setting up bn5a_branch2c
I0625 14:59:43.029338  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.029340  6673 net.cpp:165] Memory required for data: 5726208084
I0625 14:59:43.029353  6673 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0625 14:59:43.029366  6673 net.cpp:100] Creating Layer scale5a_branch2c
I0625 14:59:43.029371  6673 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0625 14:59:43.029381  6673 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0625 14:59:43.029443  6673 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0625 14:59:43.029640  6673 net.cpp:150] Setting up scale5a_branch2c
I0625 14:59:43.029647  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.029649  6673 net.cpp:165] Memory required for data: 5765529684
I0625 14:59:43.029657  6673 layer_factory.hpp:77] Creating layer res5a
I0625 14:59:43.029667  6673 net.cpp:100] Creating Layer res5a
I0625 14:59:43.029672  6673 net.cpp:444] res5a <- res5a_branch1
I0625 14:59:43.029680  6673 net.cpp:444] res5a <- res5a_branch2c
I0625 14:59:43.029690  6673 net.cpp:418] res5a -> res5a
I0625 14:59:43.029736  6673 net.cpp:150] Setting up res5a
I0625 14:59:43.029743  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.029747  6673 net.cpp:165] Memory required for data: 5804851284
I0625 14:59:43.029752  6673 layer_factory.hpp:77] Creating layer res5a_relu
I0625 14:59:43.029762  6673 net.cpp:100] Creating Layer res5a_relu
I0625 14:59:43.029768  6673 net.cpp:444] res5a_relu <- res5a
I0625 14:59:43.029779  6673 net.cpp:405] res5a_relu -> res5a (in-place)
I0625 14:59:43.030213  6673 net.cpp:150] Setting up res5a_relu
I0625 14:59:43.030223  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.030227  6673 net.cpp:165] Memory required for data: 5844172884
I0625 14:59:43.030232  6673 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0625 14:59:43.030244  6673 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0625 14:59:43.030251  6673 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0625 14:59:43.030266  6673 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0625 14:59:43.030282  6673 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0625 14:59:43.030345  6673 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0625 14:59:43.030354  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.030360  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.030364  6673 net.cpp:165] Memory required for data: 5922816084
I0625 14:59:43.030369  6673 layer_factory.hpp:77] Creating layer res5b_branch2a
I0625 14:59:43.030385  6673 net.cpp:100] Creating Layer res5b_branch2a
I0625 14:59:43.030392  6673 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0625 14:59:43.030408  6673 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0625 14:59:43.033836  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.033867  6673 net.cpp:150] Setting up res5b_branch2a
I0625 14:59:43.033880  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.033884  6673 net.cpp:165] Memory required for data: 5932646484
I0625 14:59:43.033900  6673 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0625 14:59:43.033922  6673 net.cpp:100] Creating Layer bn5b_branch2a
I0625 14:59:43.033932  6673 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0625 14:59:43.033949  6673 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0625 14:59:43.034260  6673 net.cpp:150] Setting up bn5b_branch2a
I0625 14:59:43.034266  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.034270  6673 net.cpp:165] Memory required for data: 5942476884
I0625 14:59:43.034288  6673 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0625 14:59:43.034303  6673 net.cpp:100] Creating Layer scale5b_branch2a
I0625 14:59:43.034309  6673 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0625 14:59:43.034324  6673 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0625 14:59:43.034390  6673 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0625 14:59:43.034590  6673 net.cpp:150] Setting up scale5b_branch2a
I0625 14:59:43.034597  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.034600  6673 net.cpp:165] Memory required for data: 5952307284
I0625 14:59:43.034612  6673 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0625 14:59:43.034624  6673 net.cpp:100] Creating Layer res5b_branch2a_relu
I0625 14:59:43.034631  6673 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0625 14:59:43.034643  6673 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0625 14:59:43.034791  6673 net.cpp:150] Setting up res5b_branch2a_relu
I0625 14:59:43.034798  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.034801  6673 net.cpp:165] Memory required for data: 5962137684
I0625 14:59:43.034806  6673 layer_factory.hpp:77] Creating layer res5b_branch2b
I0625 14:59:43.034824  6673 net.cpp:100] Creating Layer res5b_branch2b
I0625 14:59:43.034831  6673 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0625 14:59:43.034847  6673 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0625 14:59:43.040266  6673 net.cpp:150] Setting up res5b_branch2b
I0625 14:59:43.040297  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.040300  6673 net.cpp:165] Memory required for data: 5971968084
I0625 14:59:43.040324  6673 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0625 14:59:43.040360  6673 net.cpp:100] Creating Layer bn5b_branch2b
I0625 14:59:43.040372  6673 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0625 14:59:43.040393  6673 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0625 14:59:43.040715  6673 net.cpp:150] Setting up bn5b_branch2b
I0625 14:59:43.040722  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.040726  6673 net.cpp:165] Memory required for data: 5981798484
I0625 14:59:43.040742  6673 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0625 14:59:43.040760  6673 net.cpp:100] Creating Layer scale5b_branch2b
I0625 14:59:43.040766  6673 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0625 14:59:43.040781  6673 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0625 14:59:43.040848  6673 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0625 14:59:43.041049  6673 net.cpp:150] Setting up scale5b_branch2b
I0625 14:59:43.041057  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.041060  6673 net.cpp:165] Memory required for data: 5991628884
I0625 14:59:43.041072  6673 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0625 14:59:43.041083  6673 net.cpp:100] Creating Layer res5b_branch2b_relu
I0625 14:59:43.041090  6673 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0625 14:59:43.041102  6673 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0625 14:59:43.041294  6673 net.cpp:150] Setting up res5b_branch2b_relu
I0625 14:59:43.041302  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.041306  6673 net.cpp:165] Memory required for data: 6001459284
I0625 14:59:43.041311  6673 layer_factory.hpp:77] Creating layer res5b_branch2c
I0625 14:59:43.041329  6673 net.cpp:100] Creating Layer res5b_branch2c
I0625 14:59:43.041335  6673 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0625 14:59:43.041350  6673 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0625 14:59:43.044898  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 14:59:43.044931  6673 net.cpp:150] Setting up res5b_branch2c
I0625 14:59:43.044945  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.044947  6673 net.cpp:165] Memory required for data: 6040780884
I0625 14:59:43.044965  6673 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0625 14:59:43.044986  6673 net.cpp:100] Creating Layer bn5b_branch2c
I0625 14:59:43.044996  6673 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0625 14:59:43.045014  6673 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0625 14:59:43.045331  6673 net.cpp:150] Setting up bn5b_branch2c
I0625 14:59:43.045338  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.045341  6673 net.cpp:165] Memory required for data: 6080102484
I0625 14:59:43.045358  6673 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0625 14:59:43.045374  6673 net.cpp:100] Creating Layer scale5b_branch2c
I0625 14:59:43.045380  6673 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0625 14:59:43.045395  6673 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0625 14:59:43.045464  6673 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0625 14:59:43.045671  6673 net.cpp:150] Setting up scale5b_branch2c
I0625 14:59:43.045678  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.045681  6673 net.cpp:165] Memory required for data: 6119424084
I0625 14:59:43.045693  6673 layer_factory.hpp:77] Creating layer res5b
I0625 14:59:43.045707  6673 net.cpp:100] Creating Layer res5b
I0625 14:59:43.045714  6673 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0625 14:59:43.045725  6673 net.cpp:444] res5b <- res5b_branch2c
I0625 14:59:43.045737  6673 net.cpp:418] res5b -> res5b
I0625 14:59:43.045783  6673 net.cpp:150] Setting up res5b
I0625 14:59:43.045790  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.045794  6673 net.cpp:165] Memory required for data: 6158745684
I0625 14:59:43.045799  6673 layer_factory.hpp:77] Creating layer res5b_relu
I0625 14:59:43.045809  6673 net.cpp:100] Creating Layer res5b_relu
I0625 14:59:43.045815  6673 net.cpp:444] res5b_relu <- res5b
I0625 14:59:43.045828  6673 net.cpp:405] res5b_relu -> res5b (in-place)
I0625 14:59:43.046264  6673 net.cpp:150] Setting up res5b_relu
I0625 14:59:43.046273  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.046277  6673 net.cpp:165] Memory required for data: 6198067284
I0625 14:59:43.046281  6673 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0625 14:59:43.046294  6673 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0625 14:59:43.046300  6673 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0625 14:59:43.046315  6673 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0625 14:59:43.046332  6673 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0625 14:59:43.046396  6673 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0625 14:59:43.046404  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.046411  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.046413  6673 net.cpp:165] Memory required for data: 6276710484
I0625 14:59:43.046418  6673 layer_factory.hpp:77] Creating layer res5c_branch2a
I0625 14:59:43.046435  6673 net.cpp:100] Creating Layer res5c_branch2a
I0625 14:59:43.046442  6673 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0625 14:59:43.046456  6673 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0625 14:59:43.050302  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.050335  6673 net.cpp:150] Setting up res5c_branch2a
I0625 14:59:43.050350  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.050354  6673 net.cpp:165] Memory required for data: 6286540884
I0625 14:59:43.050375  6673 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0625 14:59:43.050405  6673 net.cpp:100] Creating Layer bn5c_branch2a
I0625 14:59:43.050415  6673 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0625 14:59:43.050436  6673 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0625 14:59:43.050745  6673 net.cpp:150] Setting up bn5c_branch2a
I0625 14:59:43.050752  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.050755  6673 net.cpp:165] Memory required for data: 6296371284
I0625 14:59:43.050772  6673 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0625 14:59:43.050789  6673 net.cpp:100] Creating Layer scale5c_branch2a
I0625 14:59:43.050796  6673 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0625 14:59:43.050810  6673 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0625 14:59:43.050885  6673 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0625 14:59:43.051090  6673 net.cpp:150] Setting up scale5c_branch2a
I0625 14:59:43.051098  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.051101  6673 net.cpp:165] Memory required for data: 6306201684
I0625 14:59:43.051113  6673 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0625 14:59:43.051126  6673 net.cpp:100] Creating Layer res5c_branch2a_relu
I0625 14:59:43.051132  6673 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0625 14:59:43.051146  6673 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0625 14:59:43.051291  6673 net.cpp:150] Setting up res5c_branch2a_relu
I0625 14:59:43.051298  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.051302  6673 net.cpp:165] Memory required for data: 6316032084
I0625 14:59:43.051307  6673 layer_factory.hpp:77] Creating layer res5c_branch2b
I0625 14:59:43.051326  6673 net.cpp:100] Creating Layer res5c_branch2b
I0625 14:59:43.051332  6673 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0625 14:59:43.051348  6673 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0625 14:59:43.057620  6673 net.cpp:150] Setting up res5c_branch2b
I0625 14:59:43.057651  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.057653  6673 net.cpp:165] Memory required for data: 6325862484
I0625 14:59:43.057677  6673 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0625 14:59:43.057713  6673 net.cpp:100] Creating Layer bn5c_branch2b
I0625 14:59:43.057724  6673 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0625 14:59:43.057745  6673 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0625 14:59:43.058073  6673 net.cpp:150] Setting up bn5c_branch2b
I0625 14:59:43.058080  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.058084  6673 net.cpp:165] Memory required for data: 6335692884
I0625 14:59:43.058100  6673 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0625 14:59:43.058116  6673 net.cpp:100] Creating Layer scale5c_branch2b
I0625 14:59:43.058122  6673 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0625 14:59:43.058136  6673 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0625 14:59:43.058207  6673 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0625 14:59:43.058414  6673 net.cpp:150] Setting up scale5c_branch2b
I0625 14:59:43.058423  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.058424  6673 net.cpp:165] Memory required for data: 6345523284
I0625 14:59:43.058437  6673 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0625 14:59:43.058449  6673 net.cpp:100] Creating Layer res5c_branch2b_relu
I0625 14:59:43.058455  6673 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0625 14:59:43.058468  6673 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0625 14:59:43.058660  6673 net.cpp:150] Setting up res5c_branch2b_relu
I0625 14:59:43.058666  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.058670  6673 net.cpp:165] Memory required for data: 6355353684
I0625 14:59:43.058674  6673 layer_factory.hpp:77] Creating layer res5c_branch2c
I0625 14:59:43.058693  6673 net.cpp:100] Creating Layer res5c_branch2c
I0625 14:59:43.058699  6673 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0625 14:59:43.058717  6673 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0625 14:59:43.062258  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0625 14:59:43.062292  6673 net.cpp:150] Setting up res5c_branch2c
I0625 14:59:43.062306  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.062309  6673 net.cpp:165] Memory required for data: 6394675284
I0625 14:59:43.062326  6673 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0625 14:59:43.062350  6673 net.cpp:100] Creating Layer bn5c_branch2c
I0625 14:59:43.062358  6673 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0625 14:59:43.062376  6673 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0625 14:59:43.062695  6673 net.cpp:150] Setting up bn5c_branch2c
I0625 14:59:43.062702  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.062705  6673 net.cpp:165] Memory required for data: 6433996884
I0625 14:59:43.062723  6673 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0625 14:59:43.062741  6673 net.cpp:100] Creating Layer scale5c_branch2c
I0625 14:59:43.062747  6673 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0625 14:59:43.062762  6673 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0625 14:59:43.062834  6673 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0625 14:59:43.063802  6673 net.cpp:150] Setting up scale5c_branch2c
I0625 14:59:43.063812  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.063815  6673 net.cpp:165] Memory required for data: 6473318484
I0625 14:59:43.063829  6673 layer_factory.hpp:77] Creating layer res5c
I0625 14:59:43.063843  6673 net.cpp:100] Creating Layer res5c
I0625 14:59:43.063850  6673 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0625 14:59:43.063863  6673 net.cpp:444] res5c <- res5c_branch2c
I0625 14:59:43.063876  6673 net.cpp:418] res5c -> res5c
I0625 14:59:43.063925  6673 net.cpp:150] Setting up res5c
I0625 14:59:43.063935  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.063938  6673 net.cpp:165] Memory required for data: 6512640084
I0625 14:59:43.063943  6673 layer_factory.hpp:77] Creating layer res5c_relu
I0625 14:59:43.063956  6673 net.cpp:100] Creating Layer res5c_relu
I0625 14:59:43.063962  6673 net.cpp:444] res5c_relu <- res5c
I0625 14:59:43.063974  6673 net.cpp:405] res5c_relu -> res5c (in-place)
I0625 14:59:43.064142  6673 net.cpp:150] Setting up res5c_relu
I0625 14:59:43.064149  6673 net.cpp:157] Top shape: 1 2048 60 80 (9830400)
I0625 14:59:43.064152  6673 net.cpp:165] Memory required for data: 6551961684
I0625 14:59:43.064157  6673 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 14:59:43.064179  6673 net.cpp:100] Creating Layer rpn_conv/3x3
I0625 14:59:43.064187  6673 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0625 14:59:43.064203  6673 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0625 14:59:43.556277  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.556311  6673 net.cpp:150] Setting up rpn_conv/3x3
I0625 14:59:43.556327  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.556330  6673 net.cpp:165] Memory required for data: 6561792084
I0625 14:59:43.556354  6673 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 14:59:43.556376  6673 net.cpp:100] Creating Layer rpn_relu/3x3
I0625 14:59:43.556387  6673 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0625 14:59:43.556407  6673 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0625 14:59:43.556841  6673 net.cpp:150] Setting up rpn_relu/3x3
I0625 14:59:43.556850  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.556854  6673 net.cpp:165] Memory required for data: 6571622484
I0625 14:59:43.556859  6673 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 14:59:43.556872  6673 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 14:59:43.556879  6673 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 14:59:43.556895  6673 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 14:59:43.556912  6673 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 14:59:43.556980  6673 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 14:59:43.556989  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.556995  6673 net.cpp:157] Top shape: 1 512 60 80 (2457600)
I0625 14:59:43.556998  6673 net.cpp:165] Memory required for data: 6591283284
I0625 14:59:43.557003  6673 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 14:59:43.557025  6673 net.cpp:100] Creating Layer rpn_cls_score
I0625 14:59:43.557032  6673 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 14:59:43.557049  6673 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0625 14:59:43.559257  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.559283  6673 net.cpp:150] Setting up rpn_cls_score
I0625 14:59:43.559290  6673 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 14:59:43.559293  6673 net.cpp:165] Memory required for data: 6591705684
I0625 14:59:43.559309  6673 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 14:59:43.559321  6673 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 14:59:43.559327  6673 net.cpp:444] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 14:59:43.559342  6673 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 14:59:43.559360  6673 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 14:59:43.559424  6673 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 14:59:43.559432  6673 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 14:59:43.559438  6673 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 14:59:43.559442  6673 net.cpp:165] Memory required for data: 6592550484
I0625 14:59:43.559446  6673 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 14:59:43.559465  6673 net.cpp:100] Creating Layer rpn_bbox_pred
I0625 14:59:43.559473  6673 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 14:59:43.559489  6673 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0625 14:59:43.562855  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.563138  6673 net.cpp:150] Setting up rpn_bbox_pred
I0625 14:59:43.563149  6673 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 14:59:43.563153  6673 net.cpp:165] Memory required for data: 6593395284
I0625 14:59:43.563168  6673 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 14:59:43.563179  6673 net.cpp:100] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 14:59:43.563185  6673 net.cpp:444] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 14:59:43.563199  6673 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 14:59:43.563216  6673 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 14:59:43.563279  6673 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 14:59:43.563287  6673 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 14:59:43.563293  6673 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 14:59:43.563297  6673 net.cpp:165] Memory required for data: 6595084884
I0625 14:59:43.563302  6673 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 14:59:43.563315  6673 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0625 14:59:43.563321  6673 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 14:59:43.563336  6673 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 14:59:43.563381  6673 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 14:59:43.563390  6673 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 14:59:43.563393  6673 net.cpp:165] Memory required for data: 6595507284
I0625 14:59:43.563398  6673 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 14:59:43.563408  6673 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 14:59:43.563414  6673 net.cpp:444] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 14:59:43.563427  6673 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 14:59:43.563443  6673 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 14:59:43.563503  6673 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 14:59:43.563511  6673 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 14:59:43.563518  6673 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 14:59:43.563521  6673 net.cpp:165] Memory required for data: 6596352084
I0625 14:59:43.563525  6673 layer_factory.hpp:77] Creating layer rpn-data
I0625 14:59:43.563836  6673 net.cpp:100] Creating Layer rpn-data
I0625 14:59:43.563845  6673 net.cpp:444] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 14:59:43.563860  6673 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I0625 14:59:43.563868  6673 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I0625 14:59:43.563876  6673 net.cpp:444] rpn-data <- data_input-data_0_split_1
I0625 14:59:43.563889  6673 net.cpp:418] rpn-data -> rpn_labels
I0625 14:59:43.563905  6673 net.cpp:418] rpn-data -> rpn_bbox_targets
I0625 14:59:43.563923  6673 net.cpp:418] rpn-data -> rpn_bbox_inside_weights
I0625 14:59:43.563938  6673 net.cpp:418] rpn-data -> rpn_bbox_outside_weights
I0625 14:59:43.564460  6673 net.cpp:150] Setting up rpn-data
I0625 14:59:43.564471  6673 net.cpp:157] Top shape: 1 1 660 80 (52800)
I0625 14:59:43.564477  6673 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 14:59:43.564482  6673 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 14:59:43.564487  6673 net.cpp:157] Top shape: 1 44 60 80 (211200)
I0625 14:59:43.564491  6673 net.cpp:165] Memory required for data: 6599097684
I0625 14:59:43.564496  6673 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 14:59:43.564512  6673 net.cpp:100] Creating Layer rpn_loss_cls
I0625 14:59:43.564519  6673 net.cpp:444] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 14:59:43.564532  6673 net.cpp:444] rpn_loss_cls <- rpn_labels
I0625 14:59:43.564543  6673 net.cpp:418] rpn_loss_cls -> rpn_cls_loss
I0625 14:59:43.564576  6673 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 14:59:43.565012  6673 net.cpp:150] Setting up rpn_loss_cls
I0625 14:59:43.565023  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.565027  6673 net.cpp:160]     with loss weight 1
I0625 14:59:43.565037  6673 net.cpp:165] Memory required for data: 6599097688
I0625 14:59:43.565042  6673 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 14:59:43.565076  6673 net.cpp:100] Creating Layer rpn_loss_bbox
I0625 14:59:43.565083  6673 net.cpp:444] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 14:59:43.565096  6673 net.cpp:444] rpn_loss_bbox <- rpn_bbox_targets
I0625 14:59:43.565105  6673 net.cpp:444] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 14:59:43.565114  6673 net.cpp:444] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 14:59:43.565124  6673 net.cpp:418] rpn_loss_bbox -> rpn_loss_bbox
I0625 14:59:43.567662  6673 net.cpp:150] Setting up rpn_loss_bbox
I0625 14:59:43.567670  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.567673  6673 net.cpp:160]     with loss weight 1
I0625 14:59:43.567678  6673 net.cpp:165] Memory required for data: 6599097692
I0625 14:59:43.567687  6673 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 14:59:43.567698  6673 net.cpp:100] Creating Layer rpn_cls_prob
I0625 14:59:43.567704  6673 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 14:59:43.567718  6673 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0625 14:59:43.567970  6673 net.cpp:150] Setting up rpn_cls_prob
I0625 14:59:43.567979  6673 net.cpp:157] Top shape: 1 2 660 80 (105600)
I0625 14:59:43.567982  6673 net.cpp:165] Memory required for data: 6599520092
I0625 14:59:43.567987  6673 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 14:59:43.568004  6673 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0625 14:59:43.568011  6673 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 14:59:43.568027  6673 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 14:59:43.568076  6673 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 14:59:43.568085  6673 net.cpp:157] Top shape: 1 22 60 80 (105600)
I0625 14:59:43.568090  6673 net.cpp:165] Memory required for data: 6599942492
I0625 14:59:43.568094  6673 layer_factory.hpp:77] Creating layer proposal
I0625 14:59:43.568573  6673 net.cpp:100] Creating Layer proposal
I0625 14:59:43.568581  6673 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0625 14:59:43.568591  6673 net.cpp:444] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 14:59:43.568598  6673 net.cpp:444] proposal <- im_info_input-data_1_split_1
I0625 14:59:43.568605  6673 net.cpp:418] proposal -> rpn_rois
I0625 14:59:43.570044  6673 net.cpp:150] Setting up proposal
I0625 14:59:43.570057  6673 net.cpp:157] Top shape: 1 5 (5)
I0625 14:59:43.570060  6673 net.cpp:165] Memory required for data: 6599942512
I0625 14:59:43.570066  6673 layer_factory.hpp:77] Creating layer roi-data
I0625 14:59:43.570197  6673 net.cpp:100] Creating Layer roi-data
I0625 14:59:43.570207  6673 net.cpp:444] roi-data <- rpn_rois
I0625 14:59:43.570219  6673 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I0625 14:59:43.570228  6673 net.cpp:418] roi-data -> rois
I0625 14:59:43.570245  6673 net.cpp:418] roi-data -> labels
I0625 14:59:43.570261  6673 net.cpp:418] roi-data -> bbox_targets
I0625 14:59:43.570271  6673 net.cpp:418] roi-data -> bbox_inside_weights
I0625 14:59:43.570279  6673 net.cpp:418] roi-data -> bbox_outside_weights
I0625 14:59:43.570641  6673 net.cpp:150] Setting up roi-data
I0625 14:59:43.570652  6673 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 14:59:43.570655  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.570657  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.570659  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.570662  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.570663  6673 net.cpp:165] Memory required for data: 6599942632
I0625 14:59:43.570667  6673 layer_factory.hpp:77] Creating layer rois_roi-data_0_split
I0625 14:59:43.570678  6673 net.cpp:100] Creating Layer rois_roi-data_0_split
I0625 14:59:43.570685  6673 net.cpp:444] rois_roi-data_0_split <- rois
I0625 14:59:43.570699  6673 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_0
I0625 14:59:43.570714  6673 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_1
I0625 14:59:43.570726  6673 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_2
I0625 14:59:43.570802  6673 net.cpp:150] Setting up rois_roi-data_0_split
I0625 14:59:43.570809  6673 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 14:59:43.570814  6673 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 14:59:43.570818  6673 net.cpp:157] Top shape: 1 5 1 1 (5)
I0625 14:59:43.570822  6673 net.cpp:165] Memory required for data: 6599942692
I0625 14:59:43.570827  6673 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0625 14:59:43.570835  6673 net.cpp:100] Creating Layer labels_roi-data_1_split
I0625 14:59:43.570839  6673 net.cpp:444] labels_roi-data_1_split <- labels
I0625 14:59:43.570849  6673 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0625 14:59:43.570865  6673 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0625 14:59:43.570924  6673 net.cpp:150] Setting up labels_roi-data_1_split
I0625 14:59:43.570931  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.570935  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.570936  6673 net.cpp:165] Memory required for data: 6599942700
I0625 14:59:43.570940  6673 layer_factory.hpp:77] Creating layer bbox_targets_roi-data_2_split
I0625 14:59:43.570947  6673 net.cpp:100] Creating Layer bbox_targets_roi-data_2_split
I0625 14:59:43.570952  6673 net.cpp:444] bbox_targets_roi-data_2_split <- bbox_targets
I0625 14:59:43.570964  6673 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_0
I0625 14:59:43.570977  6673 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_1
I0625 14:59:43.571030  6673 net.cpp:150] Setting up bbox_targets_roi-data_2_split
I0625 14:59:43.571038  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.571043  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.571045  6673 net.cpp:165] Memory required for data: 6599942764
I0625 14:59:43.571049  6673 layer_factory.hpp:77] Creating layer bbox_inside_weights_roi-data_3_split
I0625 14:59:43.571056  6673 net.cpp:100] Creating Layer bbox_inside_weights_roi-data_3_split
I0625 14:59:43.571061  6673 net.cpp:444] bbox_inside_weights_roi-data_3_split <- bbox_inside_weights
I0625 14:59:43.571072  6673 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_0
I0625 14:59:43.571086  6673 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_1
I0625 14:59:43.571142  6673 net.cpp:150] Setting up bbox_inside_weights_roi-data_3_split
I0625 14:59:43.571149  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.571153  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.571156  6673 net.cpp:165] Memory required for data: 6599942828
I0625 14:59:43.571161  6673 layer_factory.hpp:77] Creating layer conv_new_1
I0625 14:59:43.571182  6673 net.cpp:100] Creating Layer conv_new_1
I0625 14:59:43.571187  6673 net.cpp:444] conv_new_1 <- res5c
I0625 14:59:43.571199  6673 net.cpp:418] conv_new_1 -> conv_new_1
I0625 14:59:43.791151  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.791180  6673 net.cpp:150] Setting up conv_new_1
I0625 14:59:43.791193  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.791195  6673 net.cpp:165] Memory required for data: 6619603628
I0625 14:59:43.791214  6673 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0625 14:59:43.791237  6673 net.cpp:100] Creating Layer conv_new_1_relu
I0625 14:59:43.791249  6673 net.cpp:444] conv_new_1_relu <- conv_new_1
I0625 14:59:43.791270  6673 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0625 14:59:43.791730  6673 net.cpp:150] Setting up conv_new_1_relu
I0625 14:59:43.791739  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.791743  6673 net.cpp:165] Memory required for data: 6639264428
I0625 14:59:43.791748  6673 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0625 14:59:43.791761  6673 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0625 14:59:43.791769  6673 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0625 14:59:43.791785  6673 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0625 14:59:43.791803  6673 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0625 14:59:43.791872  6673 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0625 14:59:43.791882  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.791887  6673 net.cpp:157] Top shape: 1 1024 60 80 (4915200)
I0625 14:59:43.791891  6673 net.cpp:165] Memory required for data: 6678586028
I0625 14:59:43.791895  6673 layer_factory.hpp:77] Creating layer rfcn_cls
I0625 14:59:43.791918  6673 net.cpp:100] Creating Layer rfcn_cls
I0625 14:59:43.791923  6673 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0625 14:59:43.791942  6673 net.cpp:418] rfcn_cls -> rfcn_cls
I0625 14:59:43.804425  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.804457  6673 net.cpp:150] Setting up rfcn_cls
I0625 14:59:43.804473  6673 net.cpp:157] Top shape: 1 98 60 80 (470400)
I0625 14:59:43.804476  6673 net.cpp:165] Memory required for data: 6680467628
I0625 14:59:43.804497  6673 layer_factory.hpp:77] Creating layer rfcn_bbox
I0625 14:59:43.804529  6673 net.cpp:100] Creating Layer rfcn_bbox
I0625 14:59:43.804540  6673 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0625 14:59:43.804563  6673 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0625 14:59:43.848060  6673 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0625 14:59:43.848094  6673 net.cpp:150] Setting up rfcn_bbox
I0625 14:59:43.848111  6673 net.cpp:157] Top shape: 1 392 60 80 (1881600)
I0625 14:59:43.848114  6673 net.cpp:165] Memory required for data: 6687994028
I0625 14:59:43.848135  6673 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0625 14:59:43.848161  6673 net.cpp:100] Creating Layer psroipooled_cls_rois
I0625 14:59:43.848173  6673 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0625 14:59:43.848191  6673 net.cpp:444] psroipooled_cls_rois <- rois_roi-data_0_split_0
I0625 14:59:43.848207  6673 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0625 14:59:43.848229  6673 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0625 14:59:43.848299  6673 net.cpp:150] Setting up psroipooled_cls_rois
I0625 14:59:43.848307  6673 net.cpp:157] Top shape: 1 2 7 7 (98)
I0625 14:59:43.848311  6673 net.cpp:165] Memory required for data: 6687994420
I0625 14:59:43.848316  6673 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0625 14:59:43.848330  6673 net.cpp:100] Creating Layer ave_cls_score_rois
I0625 14:59:43.848336  6673 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0625 14:59:43.848352  6673 net.cpp:418] ave_cls_score_rois -> cls_score
I0625 14:59:43.848533  6673 net.cpp:150] Setting up ave_cls_score_rois
I0625 14:59:43.848543  6673 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 14:59:43.848546  6673 net.cpp:165] Memory required for data: 6687994428
I0625 14:59:43.848551  6673 layer_factory.hpp:77] Creating layer cls_score_ave_cls_score_rois_0_split
I0625 14:59:43.848562  6673 net.cpp:100] Creating Layer cls_score_ave_cls_score_rois_0_split
I0625 14:59:43.848568  6673 net.cpp:444] cls_score_ave_cls_score_rois_0_split <- cls_score
I0625 14:59:43.848583  6673 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_0
I0625 14:59:43.848599  6673 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_1
I0625 14:59:43.848613  6673 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_2
I0625 14:59:43.848695  6673 net.cpp:150] Setting up cls_score_ave_cls_score_rois_0_split
I0625 14:59:43.848702  6673 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 14:59:43.848707  6673 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 14:59:43.848712  6673 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 14:59:43.848716  6673 net.cpp:165] Memory required for data: 6687994452
I0625 14:59:43.848721  6673 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0625 14:59:43.848731  6673 net.cpp:100] Creating Layer psroipooled_loc_rois
I0625 14:59:43.848737  6673 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0625 14:59:43.848750  6673 net.cpp:444] psroipooled_loc_rois <- rois_roi-data_0_split_1
I0625 14:59:43.848762  6673 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0625 14:59:43.848776  6673 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0625 14:59:43.848832  6673 net.cpp:150] Setting up psroipooled_loc_rois
I0625 14:59:43.848840  6673 net.cpp:157] Top shape: 1 8 7 7 (392)
I0625 14:59:43.848845  6673 net.cpp:165] Memory required for data: 6687996020
I0625 14:59:43.848850  6673 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0625 14:59:43.848861  6673 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0625 14:59:43.848867  6673 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0625 14:59:43.848881  6673 net.cpp:418] ave_bbox_pred_rois -> bbox_pred
I0625 14:59:43.849051  6673 net.cpp:150] Setting up ave_bbox_pred_rois
I0625 14:59:43.849061  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.849066  6673 net.cpp:165] Memory required for data: 6687996052
I0625 14:59:43.849071  6673 layer_factory.hpp:77] Creating layer bbox_pred_ave_bbox_pred_rois_0_split
I0625 14:59:43.849082  6673 net.cpp:100] Creating Layer bbox_pred_ave_bbox_pred_rois_0_split
I0625 14:59:43.849088  6673 net.cpp:444] bbox_pred_ave_bbox_pred_rois_0_split <- bbox_pred
I0625 14:59:43.849102  6673 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_0
I0625 14:59:43.849117  6673 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_1
I0625 14:59:43.849179  6673 net.cpp:150] Setting up bbox_pred_ave_bbox_pred_rois_0_split
I0625 14:59:43.849186  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.849192  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.849195  6673 net.cpp:165] Memory required for data: 6687996116
I0625 14:59:43.849200  6673 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0625 14:59:43.849213  6673 net.cpp:100] Creating Layer per_roi_loss_cls
I0625 14:59:43.849220  6673 net.cpp:444] per_roi_loss_cls <- cls_score_ave_cls_score_rois_0_split_0
I0625 14:59:43.849231  6673 net.cpp:444] per_roi_loss_cls <- labels_roi-data_1_split_0
I0625 14:59:43.849243  6673 net.cpp:418] per_roi_loss_cls -> temp_loss_cls
I0625 14:59:43.849259  6673 net.cpp:418] per_roi_loss_cls -> temp_prob_cls
I0625 14:59:43.849273  6673 net.cpp:418] per_roi_loss_cls -> per_roi_loss_cls
I0625 14:59:43.849287  6673 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0625 14:59:43.849900  6673 net.cpp:150] Setting up per_roi_loss_cls
I0625 14:59:43.849912  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.849918  6673 net.cpp:157] Top shape: 1 2 1 1 (2)
I0625 14:59:43.849925  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.849926  6673 net.cpp:165] Memory required for data: 6687996132
I0625 14:59:43.849932  6673 layer_factory.hpp:77] Creating layer per_roi_loss_bbox
I0625 14:59:43.849946  6673 net.cpp:100] Creating Layer per_roi_loss_bbox
I0625 14:59:43.849951  6673 net.cpp:444] per_roi_loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_0
I0625 14:59:43.849964  6673 net.cpp:444] per_roi_loss_bbox <- bbox_targets_roi-data_2_split_0
I0625 14:59:43.849973  6673 net.cpp:444] per_roi_loss_bbox <- bbox_inside_weights_roi-data_3_split_0
I0625 14:59:43.849985  6673 net.cpp:418] per_roi_loss_bbox -> temp_loss_bbox
I0625 14:59:43.850003  6673 net.cpp:418] per_roi_loss_bbox -> per_roi_loss_bbox
I0625 14:59:43.850092  6673 net.cpp:150] Setting up per_roi_loss_bbox
I0625 14:59:43.850101  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.850106  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.850111  6673 net.cpp:165] Memory required for data: 6687996140
I0625 14:59:43.850116  6673 layer_factory.hpp:77] Creating layer per_roi_loss
I0625 14:59:43.850127  6673 net.cpp:100] Creating Layer per_roi_loss
I0625 14:59:43.850133  6673 net.cpp:444] per_roi_loss <- per_roi_loss_cls
I0625 14:59:43.850145  6673 net.cpp:444] per_roi_loss <- per_roi_loss_bbox
I0625 14:59:43.850157  6673 net.cpp:418] per_roi_loss -> per_roi_loss
I0625 14:59:43.850200  6673 net.cpp:150] Setting up per_roi_loss
I0625 14:59:43.850208  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.850211  6673 net.cpp:165] Memory required for data: 6687996144
I0625 14:59:43.850217  6673 layer_factory.hpp:77] Creating layer annotator_detector
I0625 14:59:43.850229  6673 net.cpp:100] Creating Layer annotator_detector
I0625 14:59:43.850236  6673 net.cpp:444] annotator_detector <- rois_roi-data_0_split_2
I0625 14:59:43.850247  6673 net.cpp:444] annotator_detector <- per_roi_loss
I0625 14:59:43.850255  6673 net.cpp:444] annotator_detector <- labels_roi-data_1_split_1
I0625 14:59:43.850263  6673 net.cpp:444] annotator_detector <- bbox_inside_weights_roi-data_3_split_1
I0625 14:59:43.850275  6673 net.cpp:418] annotator_detector -> labels_ohem
I0625 14:59:43.850291  6673 net.cpp:418] annotator_detector -> bbox_loss_weights_ohem
I0625 14:59:43.850355  6673 net.cpp:150] Setting up annotator_detector
I0625 14:59:43.850364  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.850369  6673 net.cpp:157] Top shape: 1 8 1 1 (8)
I0625 14:59:43.850373  6673 net.cpp:165] Memory required for data: 6687996180
I0625 14:59:43.850378  6673 layer_factory.hpp:77] Creating layer labels_ohem_annotator_detector_0_split
I0625 14:59:43.850387  6673 net.cpp:100] Creating Layer labels_ohem_annotator_detector_0_split
I0625 14:59:43.850394  6673 net.cpp:444] labels_ohem_annotator_detector_0_split <- labels_ohem
I0625 14:59:43.850407  6673 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_0
I0625 14:59:43.850423  6673 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_1
I0625 14:59:43.850479  6673 net.cpp:150] Setting up labels_ohem_annotator_detector_0_split
I0625 14:59:43.850487  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.850493  6673 net.cpp:157] Top shape: 1 1 1 1 (1)
I0625 14:59:43.850497  6673 net.cpp:165] Memory required for data: 6687996188
I0625 14:59:43.850500  6673 layer_factory.hpp:77] Creating layer silence
I0625 14:59:43.850512  6673 net.cpp:100] Creating Layer silence
I0625 14:59:43.850517  6673 net.cpp:444] silence <- bbox_outside_weights
I0625 14:59:43.850529  6673 net.cpp:444] silence <- temp_loss_cls
I0625 14:59:43.850536  6673 net.cpp:444] silence <- temp_prob_cls
I0625 14:59:43.850544  6673 net.cpp:444] silence <- temp_loss_bbox
I0625 14:59:43.850551  6673 net.cpp:150] Setting up silence
I0625 14:59:43.850554  6673 net.cpp:165] Memory required for data: 6687996188
I0625 14:59:43.850558  6673 layer_factory.hpp:77] Creating layer loss
I0625 14:59:43.850569  6673 net.cpp:100] Creating Layer loss
I0625 14:59:43.850574  6673 net.cpp:444] loss <- cls_score_ave_cls_score_rois_0_split_1
I0625 14:59:43.850585  6673 net.cpp:444] loss <- labels_ohem_annotator_detector_0_split_0
I0625 14:59:43.850597  6673 net.cpp:418] loss -> loss_cls
I0625 14:59:43.850615  6673 layer_factory.hpp:77] Creating layer loss
I0625 14:59:43.850901  6673 net.cpp:150] Setting up loss
I0625 14:59:43.850911  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.850914  6673 net.cpp:160]     with loss weight 1
I0625 14:59:43.850920  6673 net.cpp:165] Memory required for data: 6687996192
I0625 14:59:43.850925  6673 layer_factory.hpp:77] Creating layer accuarcy
I0625 14:59:43.850939  6673 net.cpp:100] Creating Layer accuarcy
I0625 14:59:43.850945  6673 net.cpp:444] accuarcy <- cls_score_ave_cls_score_rois_0_split_2
I0625 14:59:43.850958  6673 net.cpp:444] accuarcy <- labels_ohem_annotator_detector_0_split_1
I0625 14:59:43.850970  6673 net.cpp:418] accuarcy -> accuarcy
I0625 14:59:43.850988  6673 net.cpp:150] Setting up accuarcy
I0625 14:59:43.850996  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.850999  6673 net.cpp:165] Memory required for data: 6687996196
I0625 14:59:43.851003  6673 layer_factory.hpp:77] Creating layer loss_bbox
I0625 14:59:43.851018  6673 net.cpp:100] Creating Layer loss_bbox
I0625 14:59:43.851024  6673 net.cpp:444] loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_1
I0625 14:59:43.851035  6673 net.cpp:444] loss_bbox <- bbox_targets_roi-data_2_split_1
I0625 14:59:43.851043  6673 net.cpp:444] loss_bbox <- bbox_loss_weights_ohem
I0625 14:59:43.851054  6673 net.cpp:418] loss_bbox -> loss_bbox
I0625 14:59:43.851145  6673 net.cpp:150] Setting up loss_bbox
I0625 14:59:43.851153  6673 net.cpp:157] Top shape: (1)
I0625 14:59:43.851156  6673 net.cpp:160]     with loss weight 1
I0625 14:59:43.851161  6673 net.cpp:165] Memory required for data: 6687996200
I0625 14:59:43.851166  6673 net.cpp:226] loss_bbox needs backward computation.
I0625 14:59:43.851176  6673 net.cpp:228] accuarcy does not need backward computation.
I0625 14:59:43.851179  6673 net.cpp:226] loss needs backward computation.
I0625 14:59:43.851186  6673 net.cpp:228] silence does not need backward computation.
I0625 14:59:43.851194  6673 net.cpp:228] labels_ohem_annotator_detector_0_split does not need backward computation.
I0625 14:59:43.851199  6673 net.cpp:228] annotator_detector does not need backward computation.
I0625 14:59:43.851210  6673 net.cpp:228] per_roi_loss does not need backward computation.
I0625 14:59:43.851218  6673 net.cpp:228] per_roi_loss_bbox does not need backward computation.
I0625 14:59:43.851228  6673 net.cpp:228] per_roi_loss_cls does not need backward computation.
I0625 14:59:43.851238  6673 net.cpp:226] bbox_pred_ave_bbox_pred_rois_0_split needs backward computation.
I0625 14:59:43.851243  6673 net.cpp:226] ave_bbox_pred_rois needs backward computation.
I0625 14:59:43.851246  6673 net.cpp:226] psroipooled_loc_rois needs backward computation.
I0625 14:59:43.851253  6673 net.cpp:226] cls_score_ave_cls_score_rois_0_split needs backward computation.
I0625 14:59:43.851258  6673 net.cpp:226] ave_cls_score_rois needs backward computation.
I0625 14:59:43.851263  6673 net.cpp:226] psroipooled_cls_rois needs backward computation.
I0625 14:59:43.851270  6673 net.cpp:226] rfcn_bbox needs backward computation.
I0625 14:59:43.851275  6673 net.cpp:226] rfcn_cls needs backward computation.
I0625 14:59:43.851281  6673 net.cpp:226] conv_new_1_conv_new_1_relu_0_split needs backward computation.
I0625 14:59:43.851286  6673 net.cpp:226] conv_new_1_relu needs backward computation.
I0625 14:59:43.851291  6673 net.cpp:226] conv_new_1 needs backward computation.
I0625 14:59:43.851297  6673 net.cpp:228] bbox_inside_weights_roi-data_3_split does not need backward computation.
I0625 14:59:43.851303  6673 net.cpp:228] bbox_targets_roi-data_2_split does not need backward computation.
I0625 14:59:43.851310  6673 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0625 14:59:43.851316  6673 net.cpp:226] rois_roi-data_0_split needs backward computation.
I0625 14:59:43.851322  6673 net.cpp:226] roi-data needs backward computation.
I0625 14:59:43.851330  6673 net.cpp:226] proposal needs backward computation.
I0625 14:59:43.851339  6673 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 14:59:43.851344  6673 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 14:59:43.851349  6673 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 14:59:43.851357  6673 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 14:59:43.851364  6673 net.cpp:226] rpn-data needs backward computation.
I0625 14:59:43.851375  6673 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 14:59:43.851380  6673 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 14:59:43.851387  6673 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 14:59:43.851392  6673 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 14:59:43.851397  6673 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 14:59:43.851402  6673 net.cpp:226] rpn_cls_score needs backward computation.
I0625 14:59:43.851408  6673 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 14:59:43.851414  6673 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 14:59:43.851419  6673 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 14:59:43.851424  6673 net.cpp:226] res5c_relu needs backward computation.
I0625 14:59:43.851429  6673 net.cpp:226] res5c needs backward computation.
I0625 14:59:43.851436  6673 net.cpp:226] scale5c_branch2c needs backward computation.
I0625 14:59:43.851440  6673 net.cpp:226] bn5c_branch2c needs backward computation.
I0625 14:59:43.851444  6673 net.cpp:226] res5c_branch2c needs backward computation.
I0625 14:59:43.851449  6673 net.cpp:226] res5c_branch2b_relu needs backward computation.
I0625 14:59:43.851454  6673 net.cpp:226] scale5c_branch2b needs backward computation.
I0625 14:59:43.851459  6673 net.cpp:226] bn5c_branch2b needs backward computation.
I0625 14:59:43.851464  6673 net.cpp:226] res5c_branch2b needs backward computation.
I0625 14:59:43.851469  6673 net.cpp:226] res5c_branch2a_relu needs backward computation.
I0625 14:59:43.851475  6673 net.cpp:226] scale5c_branch2a needs backward computation.
I0625 14:59:43.851478  6673 net.cpp:226] bn5c_branch2a needs backward computation.
I0625 14:59:43.851483  6673 net.cpp:226] res5c_branch2a needs backward computation.
I0625 14:59:43.851490  6673 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I0625 14:59:43.851495  6673 net.cpp:226] res5b_relu needs backward computation.
I0625 14:59:43.851500  6673 net.cpp:226] res5b needs backward computation.
I0625 14:59:43.851506  6673 net.cpp:226] scale5b_branch2c needs backward computation.
I0625 14:59:43.851511  6673 net.cpp:226] bn5b_branch2c needs backward computation.
I0625 14:59:43.851516  6673 net.cpp:226] res5b_branch2c needs backward computation.
I0625 14:59:43.851521  6673 net.cpp:226] res5b_branch2b_relu needs backward computation.
I0625 14:59:43.851526  6673 net.cpp:226] scale5b_branch2b needs backward computation.
I0625 14:59:43.851531  6673 net.cpp:226] bn5b_branch2b needs backward computation.
I0625 14:59:43.851536  6673 net.cpp:226] res5b_branch2b needs backward computation.
I0625 14:59:43.851541  6673 net.cpp:226] res5b_branch2a_relu needs backward computation.
I0625 14:59:43.851546  6673 net.cpp:226] scale5b_branch2a needs backward computation.
I0625 14:59:43.851550  6673 net.cpp:226] bn5b_branch2a needs backward computation.
I0625 14:59:43.851555  6673 net.cpp:226] res5b_branch2a needs backward computation.
I0625 14:59:43.851560  6673 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I0625 14:59:43.851567  6673 net.cpp:226] res5a_relu needs backward computation.
I0625 14:59:43.851572  6673 net.cpp:226] res5a needs backward computation.
I0625 14:59:43.851578  6673 net.cpp:226] scale5a_branch2c needs backward computation.
I0625 14:59:43.851583  6673 net.cpp:226] bn5a_branch2c needs backward computation.
I0625 14:59:43.851588  6673 net.cpp:226] res5a_branch2c needs backward computation.
I0625 14:59:43.851593  6673 net.cpp:226] res5a_branch2b_relu needs backward computation.
I0625 14:59:43.851598  6673 net.cpp:226] scale5a_branch2b needs backward computation.
I0625 14:59:43.851603  6673 net.cpp:226] bn5a_branch2b needs backward computation.
I0625 14:59:43.851608  6673 net.cpp:226] res5a_branch2b needs backward computation.
I0625 14:59:43.851613  6673 net.cpp:226] res5a_branch2a_relu needs backward computation.
I0625 14:59:43.851619  6673 net.cpp:226] scale5a_branch2a needs backward computation.
I0625 14:59:43.851622  6673 net.cpp:226] bn5a_branch2a needs backward computation.
I0625 14:59:43.851627  6673 net.cpp:226] res5a_branch2a needs backward computation.
I0625 14:59:43.851634  6673 net.cpp:226] scale5a_branch1 needs backward computation.
I0625 14:59:43.851639  6673 net.cpp:226] bn5a_branch1 needs backward computation.
I0625 14:59:43.851644  6673 net.cpp:226] res5a_branch1 needs backward computation.
I0625 14:59:43.851649  6673 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I0625 14:59:43.851655  6673 net.cpp:226] res4f_relu needs backward computation.
I0625 14:59:43.851660  6673 net.cpp:226] res4f needs backward computation.
I0625 14:59:43.851665  6673 net.cpp:226] scale4f_branch2c needs backward computation.
I0625 14:59:43.851670  6673 net.cpp:226] bn4f_branch2c needs backward computation.
I0625 14:59:43.851675  6673 net.cpp:226] res4f_branch2c needs backward computation.
I0625 14:59:43.851680  6673 net.cpp:226] res4f_branch2b_relu needs backward computation.
I0625 14:59:43.851685  6673 net.cpp:226] scale4f_branch2b needs backward computation.
I0625 14:59:43.851689  6673 net.cpp:226] bn4f_branch2b needs backward computation.
I0625 14:59:43.851693  6673 net.cpp:226] res4f_branch2b needs backward computation.
I0625 14:59:43.851698  6673 net.cpp:226] res4f_branch2a_relu needs backward computation.
I0625 14:59:43.851703  6673 net.cpp:226] scale4f_branch2a needs backward computation.
I0625 14:59:43.851707  6673 net.cpp:226] bn4f_branch2a needs backward computation.
I0625 14:59:43.851712  6673 net.cpp:226] res4f_branch2a needs backward computation.
I0625 14:59:43.851717  6673 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I0625 14:59:43.851722  6673 net.cpp:226] res4e_relu needs backward computation.
I0625 14:59:43.851727  6673 net.cpp:226] res4e needs backward computation.
I0625 14:59:43.851734  6673 net.cpp:226] scale4e_branch2c needs backward computation.
I0625 14:59:43.851739  6673 net.cpp:226] bn4e_branch2c needs backward computation.
I0625 14:59:43.851743  6673 net.cpp:226] res4e_branch2c needs backward computation.
I0625 14:59:43.851748  6673 net.cpp:226] res4e_branch2b_relu needs backward computation.
I0625 14:59:43.851753  6673 net.cpp:226] scale4e_branch2b needs backward computation.
I0625 14:59:43.851758  6673 net.cpp:226] bn4e_branch2b needs backward computation.
I0625 14:59:43.851763  6673 net.cpp:226] res4e_branch2b needs backward computation.
I0625 14:59:43.851768  6673 net.cpp:226] res4e_branch2a_relu needs backward computation.
I0625 14:59:43.851773  6673 net.cpp:226] scale4e_branch2a needs backward computation.
I0625 14:59:43.851778  6673 net.cpp:226] bn4e_branch2a needs backward computation.
I0625 14:59:43.851783  6673 net.cpp:226] res4e_branch2a needs backward computation.
I0625 14:59:43.851788  6673 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I0625 14:59:43.851794  6673 net.cpp:226] res4d_relu needs backward computation.
I0625 14:59:43.851799  6673 net.cpp:226] res4d needs backward computation.
I0625 14:59:43.851805  6673 net.cpp:226] scale4d_branch2c needs backward computation.
I0625 14:59:43.851809  6673 net.cpp:226] bn4d_branch2c needs backward computation.
I0625 14:59:43.851815  6673 net.cpp:226] res4d_branch2c needs backward computation.
I0625 14:59:43.851820  6673 net.cpp:226] res4d_branch2b_relu needs backward computation.
I0625 14:59:43.851825  6673 net.cpp:226] scale4d_branch2b needs backward computation.
I0625 14:59:43.851830  6673 net.cpp:226] bn4d_branch2b needs backward computation.
I0625 14:59:43.851835  6673 net.cpp:226] res4d_branch2b needs backward computation.
I0625 14:59:43.851840  6673 net.cpp:226] res4d_branch2a_relu needs backward computation.
I0625 14:59:43.851845  6673 net.cpp:226] scale4d_branch2a needs backward computation.
I0625 14:59:43.851850  6673 net.cpp:226] bn4d_branch2a needs backward computation.
I0625 14:59:43.851855  6673 net.cpp:226] res4d_branch2a needs backward computation.
I0625 14:59:43.851861  6673 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I0625 14:59:43.851866  6673 net.cpp:226] res4c_relu needs backward computation.
I0625 14:59:43.851871  6673 net.cpp:226] res4c needs backward computation.
I0625 14:59:43.851878  6673 net.cpp:226] scale4c_branch2c needs backward computation.
I0625 14:59:43.851883  6673 net.cpp:226] bn4c_branch2c needs backward computation.
I0625 14:59:43.851887  6673 net.cpp:226] res4c_branch2c needs backward computation.
I0625 14:59:43.851893  6673 net.cpp:226] res4c_branch2b_relu needs backward computation.
I0625 14:59:43.851898  6673 net.cpp:226] scale4c_branch2b needs backward computation.
I0625 14:59:43.851903  6673 net.cpp:226] bn4c_branch2b needs backward computation.
I0625 14:59:43.851908  6673 net.cpp:226] res4c_branch2b needs backward computation.
I0625 14:59:43.851913  6673 net.cpp:226] res4c_branch2a_relu needs backward computation.
I0625 14:59:43.851918  6673 net.cpp:226] scale4c_branch2a needs backward computation.
I0625 14:59:43.851923  6673 net.cpp:226] bn4c_branch2a needs backward computation.
I0625 14:59:43.851928  6673 net.cpp:226] res4c_branch2a needs backward computation.
I0625 14:59:43.851933  6673 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I0625 14:59:43.851939  6673 net.cpp:226] res4b_relu needs backward computation.
I0625 14:59:43.851944  6673 net.cpp:226] res4b needs backward computation.
I0625 14:59:43.851950  6673 net.cpp:226] scale4b_branch2c needs backward computation.
I0625 14:59:43.851954  6673 net.cpp:226] bn4b_branch2c needs backward computation.
I0625 14:59:43.851959  6673 net.cpp:226] res4b_branch2c needs backward computation.
I0625 14:59:43.851964  6673 net.cpp:226] res4b_branch2b_relu needs backward computation.
I0625 14:59:43.851969  6673 net.cpp:226] scale4b_branch2b needs backward computation.
I0625 14:59:43.851975  6673 net.cpp:226] bn4b_branch2b needs backward computation.
I0625 14:59:43.851980  6673 net.cpp:226] res4b_branch2b needs backward computation.
I0625 14:59:43.851985  6673 net.cpp:226] res4b_branch2a_relu needs backward computation.
I0625 14:59:43.851990  6673 net.cpp:226] scale4b_branch2a needs backward computation.
I0625 14:59:43.851995  6673 net.cpp:226] bn4b_branch2a needs backward computation.
I0625 14:59:43.852000  6673 net.cpp:226] res4b_branch2a needs backward computation.
I0625 14:59:43.852005  6673 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I0625 14:59:43.852007  6673 net.cpp:226] res4a_relu needs backward computation.
I0625 14:59:43.852010  6673 net.cpp:226] res4a needs backward computation.
I0625 14:59:43.852015  6673 net.cpp:226] scale4a_branch2c needs backward computation.
I0625 14:59:43.852017  6673 net.cpp:226] bn4a_branch2c needs backward computation.
I0625 14:59:43.852020  6673 net.cpp:226] res4a_branch2c needs backward computation.
I0625 14:59:43.852022  6673 net.cpp:226] res4a_branch2b_relu needs backward computation.
I0625 14:59:43.852025  6673 net.cpp:226] scale4a_branch2b needs backward computation.
I0625 14:59:43.852027  6673 net.cpp:226] bn4a_branch2b needs backward computation.
I0625 14:59:43.852030  6673 net.cpp:226] res4a_branch2b needs backward computation.
I0625 14:59:43.852032  6673 net.cpp:226] res4a_branch2a_relu needs backward computation.
I0625 14:59:43.852035  6673 net.cpp:226] scale4a_branch2a needs backward computation.
I0625 14:59:43.852038  6673 net.cpp:226] bn4a_branch2a needs backward computation.
I0625 14:59:43.852041  6673 net.cpp:226] res4a_branch2a needs backward computation.
I0625 14:59:43.852043  6673 net.cpp:226] scale4a_branch1 needs backward computation.
I0625 14:59:43.852046  6673 net.cpp:226] bn4a_branch1 needs backward computation.
I0625 14:59:43.852049  6673 net.cpp:226] res4a_branch1 needs backward computation.
I0625 14:59:43.852052  6673 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I0625 14:59:43.852056  6673 net.cpp:226] res3d_relu needs backward computation.
I0625 14:59:43.852058  6673 net.cpp:226] res3d needs backward computation.
I0625 14:59:43.852061  6673 net.cpp:226] scale3d_branch2c needs backward computation.
I0625 14:59:43.852064  6673 net.cpp:226] bn3d_branch2c needs backward computation.
I0625 14:59:43.852067  6673 net.cpp:226] res3d_branch2c needs backward computation.
I0625 14:59:43.852071  6673 net.cpp:226] res3d_branch2b_relu needs backward computation.
I0625 14:59:43.852072  6673 net.cpp:226] scale3d_branch2b needs backward computation.
I0625 14:59:43.852075  6673 net.cpp:226] bn3d_branch2b needs backward computation.
I0625 14:59:43.852077  6673 net.cpp:226] res3d_branch2b needs backward computation.
I0625 14:59:43.852080  6673 net.cpp:226] res3d_branch2a_relu needs backward computation.
I0625 14:59:43.852083  6673 net.cpp:226] scale3d_branch2a needs backward computation.
I0625 14:59:43.852087  6673 net.cpp:226] bn3d_branch2a needs backward computation.
I0625 14:59:43.852088  6673 net.cpp:226] res3d_branch2a needs backward computation.
I0625 14:59:43.852092  6673 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I0625 14:59:43.852094  6673 net.cpp:226] res3c_relu needs backward computation.
I0625 14:59:43.852097  6673 net.cpp:226] res3c needs backward computation.
I0625 14:59:43.852100  6673 net.cpp:226] scale3c_branch2c needs backward computation.
I0625 14:59:43.852103  6673 net.cpp:226] bn3c_branch2c needs backward computation.
I0625 14:59:43.852107  6673 net.cpp:226] res3c_branch2c needs backward computation.
I0625 14:59:43.852109  6673 net.cpp:226] res3c_branch2b_relu needs backward computation.
I0625 14:59:43.852113  6673 net.cpp:226] scale3c_branch2b needs backward computation.
I0625 14:59:43.852114  6673 net.cpp:226] bn3c_branch2b needs backward computation.
I0625 14:59:43.852118  6673 net.cpp:226] res3c_branch2b needs backward computation.
I0625 14:59:43.852119  6673 net.cpp:226] res3c_branch2a_relu needs backward computation.
I0625 14:59:43.852123  6673 net.cpp:226] scale3c_branch2a needs backward computation.
I0625 14:59:43.852125  6673 net.cpp:226] bn3c_branch2a needs backward computation.
I0625 14:59:43.852128  6673 net.cpp:226] res3c_branch2a needs backward computation.
I0625 14:59:43.852130  6673 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I0625 14:59:43.852133  6673 net.cpp:226] res3b_relu needs backward computation.
I0625 14:59:43.852136  6673 net.cpp:226] res3b needs backward computation.
I0625 14:59:43.852140  6673 net.cpp:226] scale3b_branch2c needs backward computation.
I0625 14:59:43.852143  6673 net.cpp:226] bn3b_branch2c needs backward computation.
I0625 14:59:43.852145  6673 net.cpp:226] res3b_branch2c needs backward computation.
I0625 14:59:43.852149  6673 net.cpp:226] res3b_branch2b_relu needs backward computation.
I0625 14:59:43.852151  6673 net.cpp:226] scale3b_branch2b needs backward computation.
I0625 14:59:43.852154  6673 net.cpp:226] bn3b_branch2b needs backward computation.
I0625 14:59:43.852156  6673 net.cpp:226] res3b_branch2b needs backward computation.
I0625 14:59:43.852159  6673 net.cpp:226] res3b_branch2a_relu needs backward computation.
I0625 14:59:43.852162  6673 net.cpp:226] scale3b_branch2a needs backward computation.
I0625 14:59:43.852164  6673 net.cpp:226] bn3b_branch2a needs backward computation.
I0625 14:59:43.852167  6673 net.cpp:226] res3b_branch2a needs backward computation.
I0625 14:59:43.852170  6673 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I0625 14:59:43.852174  6673 net.cpp:226] res3a_relu needs backward computation.
I0625 14:59:43.852176  6673 net.cpp:226] res3a needs backward computation.
I0625 14:59:43.852180  6673 net.cpp:226] scale3a_branch2c needs backward computation.
I0625 14:59:43.852182  6673 net.cpp:226] bn3a_branch2c needs backward computation.
I0625 14:59:43.852185  6673 net.cpp:226] res3a_branch2c needs backward computation.
I0625 14:59:43.852188  6673 net.cpp:226] res3a_branch2b_relu needs backward computation.
I0625 14:59:43.852190  6673 net.cpp:226] scale3a_branch2b needs backward computation.
I0625 14:59:43.852193  6673 net.cpp:226] bn3a_branch2b needs backward computation.
I0625 14:59:43.852196  6673 net.cpp:226] res3a_branch2b needs backward computation.
I0625 14:59:43.852198  6673 net.cpp:226] res3a_branch2a_relu needs backward computation.
I0625 14:59:43.852201  6673 net.cpp:226] scale3a_branch2a needs backward computation.
I0625 14:59:43.852205  6673 net.cpp:226] bn3a_branch2a needs backward computation.
I0625 14:59:43.852207  6673 net.cpp:226] res3a_branch2a needs backward computation.
I0625 14:59:43.852210  6673 net.cpp:226] scale3a_branch1 needs backward computation.
I0625 14:59:43.852213  6673 net.cpp:226] bn3a_branch1 needs backward computation.
I0625 14:59:43.852216  6673 net.cpp:226] res3a_branch1 needs backward computation.
I0625 14:59:43.852221  6673 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0625 14:59:43.852224  6673 net.cpp:228] res2c_relu does not need backward computation.
I0625 14:59:43.852227  6673 net.cpp:228] res2c does not need backward computation.
I0625 14:59:43.852232  6673 net.cpp:228] scale2c_branch2c does not need backward computation.
I0625 14:59:43.852236  6673 net.cpp:228] bn2c_branch2c does not need backward computation.
I0625 14:59:43.852238  6673 net.cpp:228] res2c_branch2c does not need backward computation.
I0625 14:59:43.852241  6673 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0625 14:59:43.852244  6673 net.cpp:228] scale2c_branch2b does not need backward computation.
I0625 14:59:43.852247  6673 net.cpp:228] bn2c_branch2b does not need backward computation.
I0625 14:59:43.852250  6673 net.cpp:228] res2c_branch2b does not need backward computation.
I0625 14:59:43.852253  6673 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0625 14:59:43.852257  6673 net.cpp:228] scale2c_branch2a does not need backward computation.
I0625 14:59:43.852259  6673 net.cpp:228] bn2c_branch2a does not need backward computation.
I0625 14:59:43.852262  6673 net.cpp:228] res2c_branch2a does not need backward computation.
I0625 14:59:43.852267  6673 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0625 14:59:43.852272  6673 net.cpp:228] res2b_relu does not need backward computation.
I0625 14:59:43.852274  6673 net.cpp:228] res2b does not need backward computation.
I0625 14:59:43.852278  6673 net.cpp:228] scale2b_branch2c does not need backward computation.
I0625 14:59:43.852282  6673 net.cpp:228] bn2b_branch2c does not need backward computation.
I0625 14:59:43.852285  6673 net.cpp:228] res2b_branch2c does not need backward computation.
I0625 14:59:43.852288  6673 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0625 14:59:43.852291  6673 net.cpp:228] scale2b_branch2b does not need backward computation.
I0625 14:59:43.852294  6673 net.cpp:228] bn2b_branch2b does not need backward computation.
I0625 14:59:43.852298  6673 net.cpp:228] res2b_branch2b does not need backward computation.
I0625 14:59:43.852300  6673 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0625 14:59:43.852303  6673 net.cpp:228] scale2b_branch2a does not need backward computation.
I0625 14:59:43.852306  6673 net.cpp:228] bn2b_branch2a does not need backward computation.
I0625 14:59:43.852309  6673 net.cpp:228] res2b_branch2a does not need backward computation.
I0625 14:59:43.852313  6673 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0625 14:59:43.852318  6673 net.cpp:228] res2a_relu does not need backward computation.
I0625 14:59:43.852320  6673 net.cpp:228] res2a does not need backward computation.
I0625 14:59:43.852325  6673 net.cpp:228] scale2a_branch2c does not need backward computation.
I0625 14:59:43.852329  6673 net.cpp:228] bn2a_branch2c does not need backward computation.
I0625 14:59:43.852331  6673 net.cpp:228] res2a_branch2c does not need backward computation.
I0625 14:59:43.852334  6673 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0625 14:59:43.852339  6673 net.cpp:228] scale2a_branch2b does not need backward computation.
I0625 14:59:43.852341  6673 net.cpp:228] bn2a_branch2b does not need backward computation.
I0625 14:59:43.852344  6673 net.cpp:228] res2a_branch2b does not need backward computation.
I0625 14:59:43.852347  6673 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0625 14:59:43.852350  6673 net.cpp:228] scale2a_branch2a does not need backward computation.
I0625 14:59:43.852354  6673 net.cpp:228] bn2a_branch2a does not need backward computation.
I0625 14:59:43.852356  6673 net.cpp:228] res2a_branch2a does not need backward computation.
I0625 14:59:43.852360  6673 net.cpp:228] scale2a_branch1 does not need backward computation.
I0625 14:59:43.852365  6673 net.cpp:228] bn2a_branch1 does not need backward computation.
I0625 14:59:43.852367  6673 net.cpp:228] res2a_branch1 does not need backward computation.
I0625 14:59:43.852371  6673 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0625 14:59:43.852375  6673 net.cpp:228] pool1 does not need backward computation.
I0625 14:59:43.852378  6673 net.cpp:228] conv1_relu does not need backward computation.
I0625 14:59:43.852381  6673 net.cpp:228] scale_conv1 does not need backward computation.
I0625 14:59:43.852385  6673 net.cpp:228] bn_conv1 does not need backward computation.
I0625 14:59:43.852386  6673 net.cpp:228] conv1 does not need backward computation.
I0625 14:59:43.852391  6673 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 14:59:43.852396  6673 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 14:59:43.852401  6673 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 14:59:43.852406  6673 net.cpp:228] input-data does not need backward computation.
I0625 14:59:43.852407  6673 net.cpp:270] This network produces output accuarcy
I0625 14:59:43.852412  6673 net.cpp:270] This network produces output loss_bbox
I0625 14:59:43.852416  6673 net.cpp:270] This network produces output loss_cls
I0625 14:59:43.852419  6673 net.cpp:270] This network produces output rpn_cls_loss
I0625 14:59:43.852422  6673 net.cpp:270] This network produces output rpn_loss_bbox
I0625 14:59:43.852759  6673 net.cpp:283] Network initialization done.
I0625 14:59:43.853193  6673 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I0625 14:59:43.952818  6673 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I0625 14:59:43.952839  6673 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0625 14:59:43.952841  6673 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0625 14:59:43.952847  6673 net.cpp:774] Copying source layer conv1
I0625 14:59:43.952935  6673 net.cpp:774] Copying source layer bn_conv1
I0625 14:59:43.952946  6673 net.cpp:774] Copying source layer scale_conv1
I0625 14:59:43.952955  6673 net.cpp:774] Copying source layer conv1_relu
I0625 14:59:43.952958  6673 net.cpp:774] Copying source layer pool1
I0625 14:59:43.952961  6673 net.cpp:774] Copying source layer pool1_pool1_0_split
I0625 14:59:43.952965  6673 net.cpp:774] Copying source layer res2a_branch1
I0625 14:59:43.953081  6673 net.cpp:774] Copying source layer bn2a_branch1
I0625 14:59:43.953094  6673 net.cpp:774] Copying source layer scale2a_branch1
I0625 14:59:43.953106  6673 net.cpp:774] Copying source layer res2a_branch2a
I0625 14:59:43.953141  6673 net.cpp:774] Copying source layer bn2a_branch2a
I0625 14:59:43.953150  6673 net.cpp:774] Copying source layer scale2a_branch2a
I0625 14:59:43.953158  6673 net.cpp:774] Copying source layer res2a_branch2a_relu
I0625 14:59:43.953161  6673 net.cpp:774] Copying source layer res2a_branch2b
I0625 14:59:43.953419  6673 net.cpp:774] Copying source layer bn2a_branch2b
I0625 14:59:43.953429  6673 net.cpp:774] Copying source layer scale2a_branch2b
I0625 14:59:43.953438  6673 net.cpp:774] Copying source layer res2a_branch2b_relu
I0625 14:59:43.953441  6673 net.cpp:774] Copying source layer res2a_branch2c
I0625 14:59:43.953558  6673 net.cpp:774] Copying source layer bn2a_branch2c
I0625 14:59:43.953570  6673 net.cpp:774] Copying source layer scale2a_branch2c
I0625 14:59:43.953582  6673 net.cpp:774] Copying source layer res2a
I0625 14:59:43.953584  6673 net.cpp:774] Copying source layer res2a_relu
I0625 14:59:43.953588  6673 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0625 14:59:43.953593  6673 net.cpp:774] Copying source layer res2b_branch2a
I0625 14:59:43.953709  6673 net.cpp:774] Copying source layer bn2b_branch2a
I0625 14:59:43.953719  6673 net.cpp:774] Copying source layer scale2b_branch2a
I0625 14:59:43.953727  6673 net.cpp:774] Copying source layer res2b_branch2a_relu
I0625 14:59:43.953732  6673 net.cpp:774] Copying source layer res2b_branch2b
I0625 14:59:43.953986  6673 net.cpp:774] Copying source layer bn2b_branch2b
I0625 14:59:43.953996  6673 net.cpp:774] Copying source layer scale2b_branch2b
I0625 14:59:43.954005  6673 net.cpp:774] Copying source layer res2b_branch2b_relu
I0625 14:59:43.954008  6673 net.cpp:774] Copying source layer res2b_branch2c
I0625 14:59:43.954126  6673 net.cpp:774] Copying source layer bn2b_branch2c
I0625 14:59:43.954139  6673 net.cpp:774] Copying source layer scale2b_branch2c
I0625 14:59:43.954150  6673 net.cpp:774] Copying source layer res2b
I0625 14:59:43.954154  6673 net.cpp:774] Copying source layer res2b_relu
I0625 14:59:43.954157  6673 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0625 14:59:43.954161  6673 net.cpp:774] Copying source layer res2c_branch2a
I0625 14:59:43.954278  6673 net.cpp:774] Copying source layer bn2c_branch2a
I0625 14:59:43.954288  6673 net.cpp:774] Copying source layer scale2c_branch2a
I0625 14:59:43.954296  6673 net.cpp:774] Copying source layer res2c_branch2a_relu
I0625 14:59:43.954301  6673 net.cpp:774] Copying source layer res2c_branch2b
I0625 14:59:43.954557  6673 net.cpp:774] Copying source layer bn2c_branch2b
I0625 14:59:43.954568  6673 net.cpp:774] Copying source layer scale2c_branch2b
I0625 14:59:43.954576  6673 net.cpp:774] Copying source layer res2c_branch2b_relu
I0625 14:59:43.954581  6673 net.cpp:774] Copying source layer res2c_branch2c
I0625 14:59:43.954699  6673 net.cpp:774] Copying source layer bn2c_branch2c
I0625 14:59:43.954711  6673 net.cpp:774] Copying source layer scale2c_branch2c
I0625 14:59:43.954723  6673 net.cpp:774] Copying source layer res2c
I0625 14:59:43.954727  6673 net.cpp:774] Copying source layer res2c_relu
I0625 14:59:43.954731  6673 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0625 14:59:43.954736  6673 net.cpp:774] Copying source layer res3a_branch1
I0625 14:59:43.955633  6673 net.cpp:774] Copying source layer bn3a_branch1
I0625 14:59:43.955651  6673 net.cpp:774] Copying source layer scale3a_branch1
I0625 14:59:43.955667  6673 net.cpp:774] Copying source layer res3a_branch2a
I0625 14:59:43.955896  6673 net.cpp:774] Copying source layer bn3a_branch2a
I0625 14:59:43.955909  6673 net.cpp:774] Copying source layer scale3a_branch2a
I0625 14:59:43.955919  6673 net.cpp:774] Copying source layer res3a_branch2a_relu
I0625 14:59:43.955922  6673 net.cpp:774] Copying source layer res3a_branch2b
I0625 14:59:43.957250  6673 net.cpp:774] Copying source layer bn3a_branch2b
I0625 14:59:43.957267  6673 net.cpp:774] Copying source layer scale3a_branch2b
I0625 14:59:43.957278  6673 net.cpp:774] Copying source layer res3a_branch2b_relu
I0625 14:59:43.957281  6673 net.cpp:774] Copying source layer res3a_branch2c
I0625 14:59:43.957965  6673 net.cpp:774] Copying source layer bn3a_branch2c
I0625 14:59:43.957985  6673 net.cpp:774] Copying source layer scale3a_branch2c
I0625 14:59:43.958001  6673 net.cpp:774] Copying source layer res3a
I0625 14:59:43.958005  6673 net.cpp:774] Copying source layer res3a_relu
I0625 14:59:43.958009  6673 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0625 14:59:43.958012  6673 net.cpp:774] Copying source layer res3b_branch2a
I0625 14:59:43.958626  6673 net.cpp:774] Copying source layer bn3b_branch2a
I0625 14:59:43.958638  6673 net.cpp:774] Copying source layer scale3b_branch2a
I0625 14:59:43.958649  6673 net.cpp:774] Copying source layer res3b_branch2a_relu
I0625 14:59:43.958652  6673 net.cpp:774] Copying source layer res3b_branch2b
I0625 14:59:43.959976  6673 net.cpp:774] Copying source layer bn3b_branch2b
I0625 14:59:43.959992  6673 net.cpp:774] Copying source layer scale3b_branch2b
I0625 14:59:43.960002  6673 net.cpp:774] Copying source layer res3b_branch2b_relu
I0625 14:59:43.960005  6673 net.cpp:774] Copying source layer res3b_branch2c
I0625 14:59:43.960538  6673 net.cpp:774] Copying source layer bn3b_branch2c
I0625 14:59:43.960556  6673 net.cpp:774] Copying source layer scale3b_branch2c
I0625 14:59:43.960568  6673 net.cpp:774] Copying source layer res3b
I0625 14:59:43.960570  6673 net.cpp:774] Copying source layer res3b_relu
I0625 14:59:43.960573  6673 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0625 14:59:43.960577  6673 net.cpp:774] Copying source layer res3c_branch2a
I0625 14:59:43.961024  6673 net.cpp:774] Copying source layer bn3c_branch2a
I0625 14:59:43.961032  6673 net.cpp:774] Copying source layer scale3c_branch2a
I0625 14:59:43.961040  6673 net.cpp:774] Copying source layer res3c_branch2a_relu
I0625 14:59:43.961042  6673 net.cpp:774] Copying source layer res3c_branch2b
I0625 14:59:43.962044  6673 net.cpp:774] Copying source layer bn3c_branch2b
I0625 14:59:43.962052  6673 net.cpp:774] Copying source layer scale3c_branch2b
I0625 14:59:43.962059  6673 net.cpp:774] Copying source layer res3c_branch2b_relu
I0625 14:59:43.962062  6673 net.cpp:774] Copying source layer res3c_branch2c
I0625 14:59:43.962510  6673 net.cpp:774] Copying source layer bn3c_branch2c
I0625 14:59:43.962523  6673 net.cpp:774] Copying source layer scale3c_branch2c
I0625 14:59:43.962535  6673 net.cpp:774] Copying source layer res3c
I0625 14:59:43.962538  6673 net.cpp:774] Copying source layer res3c_relu
I0625 14:59:43.962541  6673 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0625 14:59:43.962544  6673 net.cpp:774] Copying source layer res3d_branch2a
I0625 14:59:43.962996  6673 net.cpp:774] Copying source layer bn3d_branch2a
I0625 14:59:43.963004  6673 net.cpp:774] Copying source layer scale3d_branch2a
I0625 14:59:43.963011  6673 net.cpp:774] Copying source layer res3d_branch2a_relu
I0625 14:59:43.963014  6673 net.cpp:774] Copying source layer res3d_branch2b
I0625 14:59:43.964015  6673 net.cpp:774] Copying source layer bn3d_branch2b
I0625 14:59:43.964030  6673 net.cpp:774] Copying source layer scale3d_branch2b
I0625 14:59:43.964042  6673 net.cpp:774] Copying source layer res3d_branch2b_relu
I0625 14:59:43.964049  6673 net.cpp:774] Copying source layer res3d_branch2c
I0625 14:59:43.964504  6673 net.cpp:774] Copying source layer bn3d_branch2c
I0625 14:59:43.964524  6673 net.cpp:774] Copying source layer scale3d_branch2c
I0625 14:59:43.964540  6673 net.cpp:774] Copying source layer res3d
I0625 14:59:43.964545  6673 net.cpp:774] Copying source layer res3d_relu
I0625 14:59:43.964550  6673 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0625 14:59:43.964556  6673 net.cpp:774] Copying source layer res4a_branch1
I0625 14:59:43.968152  6673 net.cpp:774] Copying source layer bn4a_branch1
I0625 14:59:43.968197  6673 net.cpp:774] Copying source layer scale4a_branch1
I0625 14:59:43.968220  6673 net.cpp:774] Copying source layer res4a_branch2a
I0625 14:59:43.969117  6673 net.cpp:774] Copying source layer bn4a_branch2a
I0625 14:59:43.969136  6673 net.cpp:774] Copying source layer scale4a_branch2a
I0625 14:59:43.969151  6673 net.cpp:774] Copying source layer res4a_branch2a_relu
I0625 14:59:43.969156  6673 net.cpp:774] Copying source layer res4a_branch2b
I0625 14:59:43.973165  6673 net.cpp:774] Copying source layer bn4a_branch2b
I0625 14:59:43.973192  6673 net.cpp:774] Copying source layer scale4a_branch2b
I0625 14:59:43.973206  6673 net.cpp:774] Copying source layer res4a_branch2b_relu
I0625 14:59:43.973212  6673 net.cpp:774] Copying source layer res4a_branch2c
I0625 14:59:43.975008  6673 net.cpp:774] Copying source layer bn4a_branch2c
I0625 14:59:43.975036  6673 net.cpp:774] Copying source layer scale4a_branch2c
I0625 14:59:43.975059  6673 net.cpp:774] Copying source layer res4a
I0625 14:59:43.975064  6673 net.cpp:774] Copying source layer res4a_relu
I0625 14:59:43.975071  6673 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0625 14:59:43.975076  6673 net.cpp:774] Copying source layer res4b_branch2a
I0625 14:59:43.977322  6673 net.cpp:774] Copying source layer bn4b_branch2a
I0625 14:59:43.977347  6673 net.cpp:774] Copying source layer scale4b_branch2a
I0625 14:59:43.977363  6673 net.cpp:774] Copying source layer res4b_branch2a_relu
I0625 14:59:43.977368  6673 net.cpp:774] Copying source layer res4b_branch2b
I0625 14:59:43.981469  6673 net.cpp:774] Copying source layer bn4b_branch2b
I0625 14:59:43.981501  6673 net.cpp:774] Copying source layer scale4b_branch2b
I0625 14:59:43.981513  6673 net.cpp:774] Copying source layer res4b_branch2b_relu
I0625 14:59:43.981516  6673 net.cpp:774] Copying source layer res4b_branch2c
I0625 14:59:43.983330  6673 net.cpp:774] Copying source layer bn4b_branch2c
I0625 14:59:43.983358  6673 net.cpp:774] Copying source layer scale4b_branch2c
I0625 14:59:43.983377  6673 net.cpp:774] Copying source layer res4b
I0625 14:59:43.983381  6673 net.cpp:774] Copying source layer res4b_relu
I0625 14:59:43.983386  6673 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0625 14:59:43.983391  6673 net.cpp:774] Copying source layer res4c_branch2a
I0625 14:59:43.985168  6673 net.cpp:774] Copying source layer bn4c_branch2a
I0625 14:59:43.985183  6673 net.cpp:774] Copying source layer scale4c_branch2a
I0625 14:59:43.985194  6673 net.cpp:774] Copying source layer res4c_branch2a_relu
I0625 14:59:43.985198  6673 net.cpp:774] Copying source layer res4c_branch2b
I0625 14:59:43.989195  6673 net.cpp:774] Copying source layer bn4c_branch2b
I0625 14:59:43.989212  6673 net.cpp:774] Copying source layer scale4c_branch2b
I0625 14:59:43.989223  6673 net.cpp:774] Copying source layer res4c_branch2b_relu
I0625 14:59:43.989228  6673 net.cpp:774] Copying source layer res4c_branch2c
I0625 14:59:43.991022  6673 net.cpp:774] Copying source layer bn4c_branch2c
I0625 14:59:43.991046  6673 net.cpp:774] Copying source layer scale4c_branch2c
I0625 14:59:43.991065  6673 net.cpp:774] Copying source layer res4c
I0625 14:59:43.991070  6673 net.cpp:774] Copying source layer res4c_relu
I0625 14:59:43.991075  6673 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0625 14:59:43.991078  6673 net.cpp:774] Copying source layer res4d_branch2a
I0625 14:59:43.992856  6673 net.cpp:774] Copying source layer bn4d_branch2a
I0625 14:59:43.992867  6673 net.cpp:774] Copying source layer scale4d_branch2a
I0625 14:59:43.992879  6673 net.cpp:774] Copying source layer res4d_branch2a_relu
I0625 14:59:43.992883  6673 net.cpp:774] Copying source layer res4d_branch2b
I0625 14:59:43.997292  6673 net.cpp:774] Copying source layer bn4d_branch2b
I0625 14:59:43.997310  6673 net.cpp:774] Copying source layer scale4d_branch2b
I0625 14:59:43.997323  6673 net.cpp:774] Copying source layer res4d_branch2b_relu
I0625 14:59:43.997325  6673 net.cpp:774] Copying source layer res4d_branch2c
I0625 14:59:43.999106  6673 net.cpp:774] Copying source layer bn4d_branch2c
I0625 14:59:43.999130  6673 net.cpp:774] Copying source layer scale4d_branch2c
I0625 14:59:43.999150  6673 net.cpp:774] Copying source layer res4d
I0625 14:59:43.999155  6673 net.cpp:774] Copying source layer res4d_relu
I0625 14:59:43.999159  6673 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0625 14:59:43.999162  6673 net.cpp:774] Copying source layer res4e_branch2a
I0625 14:59:44.000941  6673 net.cpp:774] Copying source layer bn4e_branch2a
I0625 14:59:44.000954  6673 net.cpp:774] Copying source layer scale4e_branch2a
I0625 14:59:44.000965  6673 net.cpp:774] Copying source layer res4e_branch2a_relu
I0625 14:59:44.000969  6673 net.cpp:774] Copying source layer res4e_branch2b
I0625 14:59:44.004964  6673 net.cpp:774] Copying source layer bn4e_branch2b
I0625 14:59:44.004979  6673 net.cpp:774] Copying source layer scale4e_branch2b
I0625 14:59:44.004990  6673 net.cpp:774] Copying source layer res4e_branch2b_relu
I0625 14:59:44.004994  6673 net.cpp:774] Copying source layer res4e_branch2c
I0625 14:59:44.006772  6673 net.cpp:774] Copying source layer bn4e_branch2c
I0625 14:59:44.006795  6673 net.cpp:774] Copying source layer scale4e_branch2c
I0625 14:59:44.006815  6673 net.cpp:774] Copying source layer res4e
I0625 14:59:44.006820  6673 net.cpp:774] Copying source layer res4e_relu
I0625 14:59:44.006826  6673 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0625 14:59:44.006831  6673 net.cpp:774] Copying source layer res4f_branch2a
I0625 14:59:44.008611  6673 net.cpp:774] Copying source layer bn4f_branch2a
I0625 14:59:44.008623  6673 net.cpp:774] Copying source layer scale4f_branch2a
I0625 14:59:44.008635  6673 net.cpp:774] Copying source layer res4f_branch2a_relu
I0625 14:59:44.008638  6673 net.cpp:774] Copying source layer res4f_branch2b
I0625 14:59:44.013272  6673 net.cpp:774] Copying source layer bn4f_branch2b
I0625 14:59:44.013308  6673 net.cpp:774] Copying source layer scale4f_branch2b
I0625 14:59:44.013322  6673 net.cpp:774] Copying source layer res4f_branch2b_relu
I0625 14:59:44.013329  6673 net.cpp:774] Copying source layer res4f_branch2c
I0625 14:59:44.015638  6673 net.cpp:774] Copying source layer bn4f_branch2c
I0625 14:59:44.015677  6673 net.cpp:774] Copying source layer scale4f_branch2c
I0625 14:59:44.015705  6673 net.cpp:774] Copying source layer res4f
I0625 14:59:44.015712  6673 net.cpp:774] Copying source layer res4f_relu
I0625 14:59:44.015718  6673 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0625 14:59:44.015724  6673 net.cpp:774] Copying source layer res5a_branch1
I0625 14:59:44.030932  6673 net.cpp:774] Copying source layer bn5a_branch1
I0625 14:59:44.030985  6673 net.cpp:774] Copying source layer scale5a_branch1
I0625 14:59:44.031019  6673 net.cpp:774] Copying source layer res5a_branch2a
I0625 14:59:44.034570  6673 net.cpp:774] Copying source layer bn5a_branch2a
I0625 14:59:44.034591  6673 net.cpp:774] Copying source layer scale5a_branch2a
I0625 14:59:44.034607  6673 net.cpp:774] Copying source layer res5a_branch2a_relu
I0625 14:59:44.034611  6673 net.cpp:774] Copying source layer res5a_branch2b
I0625 14:59:44.051609  6673 net.cpp:774] Copying source layer bn5a_branch2b
I0625 14:59:44.051648  6673 net.cpp:774] Copying source layer scale5a_branch2b
I0625 14:59:44.051664  6673 net.cpp:774] Copying source layer res5a_branch2b_relu
I0625 14:59:44.051669  6673 net.cpp:774] Copying source layer res5a_branch2c
I0625 14:59:44.059362  6673 net.cpp:774] Copying source layer bn5a_branch2c
I0625 14:59:44.059408  6673 net.cpp:774] Copying source layer scale5a_branch2c
I0625 14:59:44.059442  6673 net.cpp:774] Copying source layer res5a
I0625 14:59:44.059448  6673 net.cpp:774] Copying source layer res5a_relu
I0625 14:59:44.059453  6673 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0625 14:59:44.059458  6673 net.cpp:774] Copying source layer res5b_branch2a
I0625 14:59:44.066555  6673 net.cpp:774] Copying source layer bn5b_branch2a
I0625 14:59:44.066574  6673 net.cpp:774] Copying source layer scale5b_branch2a
I0625 14:59:44.066588  6673 net.cpp:774] Copying source layer res5b_branch2a_relu
I0625 14:59:44.066593  6673 net.cpp:774] Copying source layer res5b_branch2b
I0625 14:59:44.083000  6673 net.cpp:774] Copying source layer bn5b_branch2b
I0625 14:59:44.083034  6673 net.cpp:774] Copying source layer scale5b_branch2b
I0625 14:59:44.083050  6673 net.cpp:774] Copying source layer res5b_branch2b_relu
I0625 14:59:44.083055  6673 net.cpp:774] Copying source layer res5b_branch2c
I0625 14:59:44.090154  6673 net.cpp:774] Copying source layer bn5b_branch2c
I0625 14:59:44.090195  6673 net.cpp:774] Copying source layer scale5b_branch2c
I0625 14:59:44.090229  6673 net.cpp:774] Copying source layer res5b
I0625 14:59:44.090235  6673 net.cpp:774] Copying source layer res5b_relu
I0625 14:59:44.090240  6673 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0625 14:59:44.090245  6673 net.cpp:774] Copying source layer res5c_branch2a
I0625 14:59:44.097766  6673 net.cpp:774] Copying source layer bn5c_branch2a
I0625 14:59:44.097787  6673 net.cpp:774] Copying source layer scale5c_branch2a
I0625 14:59:44.097803  6673 net.cpp:774] Copying source layer res5c_branch2a_relu
I0625 14:59:44.097808  6673 net.cpp:774] Copying source layer res5c_branch2b
I0625 14:59:44.113796  6673 net.cpp:774] Copying source layer bn5c_branch2b
I0625 14:59:44.113822  6673 net.cpp:774] Copying source layer scale5c_branch2b
I0625 14:59:44.113838  6673 net.cpp:774] Copying source layer res5c_branch2b_relu
I0625 14:59:44.113842  6673 net.cpp:774] Copying source layer res5c_branch2c
I0625 14:59:44.121377  6673 net.cpp:774] Copying source layer bn5c_branch2c
I0625 14:59:44.121421  6673 net.cpp:774] Copying source layer scale5c_branch2c
I0625 14:59:44.121456  6673 net.cpp:774] Copying source layer res5c
I0625 14:59:44.121461  6673 net.cpp:774] Copying source layer res5c_relu
I0625 14:59:44.121466  6673 net.cpp:771] Ignoring source layer pool5
I0625 14:59:44.121470  6673 net.cpp:771] Ignoring source layer fc1000
I0625 14:59:44.121474  6673 net.cpp:771] Ignoring source layer prob
Solving...
I0625 14:59:48.704017  6673 solver.cpp:228] Iteration 0, loss = 1.39213
I0625 14:59:48.704046  6673 solver.cpp:244]     Train net output #0: accuarcy = 0
I0625 14:59:48.704056  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310116 (* 1 = 0.0310116 loss)
I0625 14:59:48.704061  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.703661 (* 1 = 0.703661 loss)
I0625 14:59:48.704066  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.667991 (* 1 = 0.667991 loss)
I0625 14:59:48.704071  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0528728 (* 1 = 0.0528728 loss)
I0625 14:59:48.704077  6673 sgd_solver.cpp:106] Iteration 0, lr = 0.0002
I0625 15:01:25.411437  6673 solver.cpp:228] Iteration 20, loss = 1.2205
I0625 15:01:25.411461  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 15:01:25.411470  6673 solver.cpp:244]     Train net output #1: loss_bbox = 2.29349e-05 (* 1 = 2.29349e-05 loss)
I0625 15:01:25.411476  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.680743 (* 1 = 0.680743 loss)
I0625 15:01:25.411480  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.499885 (* 1 = 0.499885 loss)
I0625 15:01:25.411485  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00362442 (* 1 = 0.00362442 loss)
I0625 15:01:25.411491  6673 sgd_solver.cpp:106] Iteration 20, lr = 0.0002
I0625 15:03:02.942445  6673 solver.cpp:228] Iteration 40, loss = 1.00816
I0625 15:03:02.942476  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:03:02.942487  6673 solver.cpp:244]     Train net output #1: loss_bbox = 1.14216e-05 (* 1 = 1.14216e-05 loss)
I0625 15:03:02.942492  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.649566 (* 1 = 0.649566 loss)
I0625 15:03:02.942497  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.337124 (* 1 = 0.337124 loss)
I0625 15:03:02.942502  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326914 (* 1 = 0.0326914 loss)
I0625 15:03:02.942507  6673 sgd_solver.cpp:106] Iteration 40, lr = 0.0002
I0625 15:04:40.276180  6673 solver.cpp:228] Iteration 60, loss = 0.835605
I0625 15:04:40.276204  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 15:04:40.276211  6673 solver.cpp:244]     Train net output #1: loss_bbox = 6.84999e-05 (* 1 = 6.84999e-05 loss)
I0625 15:04:40.276216  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.606489 (* 1 = 0.606489 loss)
I0625 15:04:40.276218  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.208617 (* 1 = 0.208617 loss)
I0625 15:04:40.276222  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0655024 (* 1 = 0.0655024 loss)
I0625 15:04:40.276226  6673 sgd_solver.cpp:106] Iteration 60, lr = 0.0002
I0625 15:06:17.556679  6673 solver.cpp:228] Iteration 80, loss = 0.664816
I0625 15:06:17.556702  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:06:17.556710  6673 solver.cpp:244]     Train net output #1: loss_bbox = 2.76597e-05 (* 1 = 2.76597e-05 loss)
I0625 15:06:17.556715  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.529318 (* 1 = 0.529318 loss)
I0625 15:06:17.556717  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103197 (* 1 = 0.103197 loss)
I0625 15:06:17.556720  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197887 (* 1 = 0.0197887 loss)
I0625 15:06:17.556725  6673 sgd_solver.cpp:106] Iteration 80, lr = 0.0002
I0625 15:07:55.022671  6673 solver.cpp:228] Iteration 100, loss = 0.621436
I0625 15:07:55.022697  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:07:55.022704  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000105745 (* 1 = 0.000105745 loss)
I0625 15:07:55.022708  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.421003 (* 1 = 0.421003 loss)
I0625 15:07:55.022711  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0923757 (* 1 = 0.0923757 loss)
I0625 15:07:55.022714  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400444 (* 1 = 0.0400444 loss)
I0625 15:07:55.022719  6673 sgd_solver.cpp:106] Iteration 100, lr = 0.0002
I0625 15:09:32.798338  6673 solver.cpp:228] Iteration 120, loss = 0.30835
I0625 15:09:32.798362  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:09:32.798369  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00010363 (* 1 = 0.00010363 loss)
I0625 15:09:32.798375  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.213341 (* 1 = 0.213341 loss)
I0625 15:09:32.798382  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.046068 (* 1 = 0.046068 loss)
I0625 15:09:32.798385  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00890747 (* 1 = 0.00890747 loss)
I0625 15:09:32.798390  6673 sgd_solver.cpp:106] Iteration 120, lr = 0.0002
I0625 15:11:10.806627  6673 solver.cpp:228] Iteration 140, loss = 0.205162
I0625 15:11:10.806653  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:11:10.806660  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000616317 (* 1 = 0.000616317 loss)
I0625 15:11:10.806664  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.128048 (* 1 = 0.128048 loss)
I0625 15:11:10.806668  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0681905 (* 1 = 0.0681905 loss)
I0625 15:11:10.806673  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0524183 (* 1 = 0.0524183 loss)
I0625 15:11:10.806676  6673 sgd_solver.cpp:106] Iteration 140, lr = 0.0002
I0625 15:12:48.884901  6673 solver.cpp:228] Iteration 160, loss = 0.321077
I0625 15:12:48.884927  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:12:48.884933  6673 solver.cpp:244]     Train net output #1: loss_bbox = 6.87922e-05 (* 1 = 6.87922e-05 loss)
I0625 15:12:48.884938  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0465089 (* 1 = 0.0465089 loss)
I0625 15:12:48.884940  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0302005 (* 1 = 0.0302005 loss)
I0625 15:12:48.884943  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106265 (* 1 = 0.0106265 loss)
I0625 15:12:48.884948  6673 sgd_solver.cpp:106] Iteration 160, lr = 0.0002
I0625 15:14:26.958626  6673 solver.cpp:228] Iteration 180, loss = 0.148833
I0625 15:14:26.958652  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:14:26.958658  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000182213 (* 1 = 0.000182213 loss)
I0625 15:14:26.958662  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0935235 (* 1 = 0.0935235 loss)
I0625 15:14:26.958667  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.066179 (* 1 = 0.066179 loss)
I0625 15:14:26.958669  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321109 (* 1 = 0.0321109 loss)
I0625 15:14:26.958673  6673 sgd_solver.cpp:106] Iteration 180, lr = 0.0002
speed: 4.883s / iter
I0625 15:16:05.247016  6673 solver.cpp:228] Iteration 200, loss = 0.137073
I0625 15:16:05.247041  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:16:05.247048  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000210069 (* 1 = 0.000210069 loss)
I0625 15:16:05.247056  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0709766 (* 1 = 0.0709766 loss)
I0625 15:16:05.247061  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0550336 (* 1 = 0.0550336 loss)
I0625 15:16:05.247067  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0592556 (* 1 = 0.0592556 loss)
I0625 15:16:05.247076  6673 sgd_solver.cpp:106] Iteration 200, lr = 0.0002
I0625 15:17:43.304570  6673 solver.cpp:228] Iteration 220, loss = 0.248716
I0625 15:17:43.304594  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 15:17:43.304601  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000396639 (* 1 = 0.000396639 loss)
I0625 15:17:43.304605  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.269108 (* 1 = 0.269108 loss)
I0625 15:17:43.304610  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.189339 (* 1 = 0.189339 loss)
I0625 15:17:43.304612  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.135323 (* 1 = 0.135323 loss)
I0625 15:17:43.304617  6673 sgd_solver.cpp:106] Iteration 220, lr = 0.0002
I0625 15:19:21.366313  6673 solver.cpp:228] Iteration 240, loss = 0.168983
I0625 15:19:21.366344  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:19:21.366355  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000126413 (* 1 = 0.000126413 loss)
I0625 15:19:21.366361  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0658857 (* 1 = 0.0658857 loss)
I0625 15:19:21.366366  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0582201 (* 1 = 0.0582201 loss)
I0625 15:19:21.366371  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265297 (* 1 = 0.0265297 loss)
I0625 15:19:21.366379  6673 sgd_solver.cpp:106] Iteration 240, lr = 0.0002
I0625 15:20:59.458992  6673 solver.cpp:228] Iteration 260, loss = 0.190679
I0625 15:20:59.459033  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:20:59.459043  6673 solver.cpp:244]     Train net output #1: loss_bbox = 4.04109e-05 (* 1 = 4.04109e-05 loss)
I0625 15:20:59.459046  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0935508 (* 1 = 0.0935508 loss)
I0625 15:20:59.459050  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0472359 (* 1 = 0.0472359 loss)
I0625 15:20:59.459053  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387648 (* 1 = 0.0387648 loss)
I0625 15:20:59.459059  6673 sgd_solver.cpp:106] Iteration 260, lr = 0.0002
I0625 15:22:37.488795  6673 solver.cpp:228] Iteration 280, loss = 0.566682
I0625 15:22:37.488823  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:22:37.488831  6673 solver.cpp:244]     Train net output #1: loss_bbox = 5.59594e-06 (* 1 = 5.59594e-06 loss)
I0625 15:22:37.488835  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0527444 (* 1 = 0.0527444 loss)
I0625 15:22:37.488839  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268997 (* 1 = 0.0268997 loss)
I0625 15:22:37.488842  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142095 (* 1 = 0.0142095 loss)
I0625 15:22:37.488848  6673 sgd_solver.cpp:106] Iteration 280, lr = 0.0002
I0625 15:24:15.492259  6673 solver.cpp:228] Iteration 300, loss = 0.574792
I0625 15:24:15.492287  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0625 15:24:15.492295  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.364228 (* 1 = 0.364228 loss)
I0625 15:24:15.492300  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.734556 (* 1 = 0.734556 loss)
I0625 15:24:15.492303  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.680851 (* 1 = 0.680851 loss)
I0625 15:24:15.492307  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.359983 (* 1 = 0.359983 loss)
I0625 15:24:15.492313  6673 sgd_solver.cpp:106] Iteration 300, lr = 0.0002
I0625 15:25:53.625542  6673 solver.cpp:228] Iteration 320, loss = 0.171153
I0625 15:25:53.625567  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 15:25:53.625576  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0612263 (* 1 = 0.0612263 loss)
I0625 15:25:53.625582  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.179242 (* 1 = 0.179242 loss)
I0625 15:25:53.625587  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0354884 (* 1 = 0.0354884 loss)
I0625 15:25:53.625592  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175752 (* 1 = 0.0175752 loss)
I0625 15:25:53.625599  6673 sgd_solver.cpp:106] Iteration 320, lr = 0.0002
I0625 15:27:31.628923  6673 solver.cpp:228] Iteration 340, loss = 0.304771
I0625 15:27:31.628947  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:27:31.628954  6673 solver.cpp:244]     Train net output #1: loss_bbox = 2.30157e-05 (* 1 = 2.30157e-05 loss)
I0625 15:27:31.628958  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0478046 (* 1 = 0.0478046 loss)
I0625 15:27:31.628962  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0284244 (* 1 = 0.0284244 loss)
I0625 15:27:31.628965  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163503 (* 1 = 0.0163503 loss)
I0625 15:27:31.628969  6673 sgd_solver.cpp:106] Iteration 340, lr = 0.0002
I0625 15:29:09.597472  6673 solver.cpp:228] Iteration 360, loss = 0.310853
I0625 15:29:09.597501  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 15:29:09.597507  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00625065 (* 1 = 0.00625065 loss)
I0625 15:29:09.597512  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.139448 (* 1 = 0.139448 loss)
I0625 15:29:09.597517  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0585241 (* 1 = 0.0585241 loss)
I0625 15:29:09.597519  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681998 (* 1 = 0.0681998 loss)
I0625 15:29:09.597524  6673 sgd_solver.cpp:106] Iteration 360, lr = 0.0002
I0625 15:30:47.596881  6673 solver.cpp:228] Iteration 380, loss = 0.285844
I0625 15:30:47.596906  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:30:47.596915  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157727 (* 1 = 0.0157727 loss)
I0625 15:30:47.596918  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0790167 (* 1 = 0.0790167 loss)
I0625 15:30:47.596921  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204686 (* 1 = 0.0204686 loss)
I0625 15:30:47.596925  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012899 (* 1 = 0.012899 loss)
I0625 15:30:47.596930  6673 sgd_solver.cpp:106] Iteration 380, lr = 0.0002
speed: 4.892s / iter
I0625 15:32:25.570883  6673 solver.cpp:228] Iteration 400, loss = 0.425064
I0625 15:32:25.570909  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 15:32:25.570916  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.112041 (* 1 = 0.112041 loss)
I0625 15:32:25.570920  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.278224 (* 1 = 0.278224 loss)
I0625 15:32:25.570924  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0326474 (* 1 = 0.0326474 loss)
I0625 15:32:25.570926  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02111 (* 1 = 0.02111 loss)
I0625 15:32:25.570930  6673 sgd_solver.cpp:106] Iteration 400, lr = 0.0002
I0625 15:34:03.574996  6673 solver.cpp:228] Iteration 420, loss = 0.382276
I0625 15:34:03.575021  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 15:34:03.575028  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.194062 (* 1 = 0.194062 loss)
I0625 15:34:03.575033  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.449101 (* 1 = 0.449101 loss)
I0625 15:34:03.575037  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.150841 (* 1 = 0.150841 loss)
I0625 15:34:03.575040  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0980722 (* 1 = 0.0980722 loss)
I0625 15:34:03.575045  6673 sgd_solver.cpp:106] Iteration 420, lr = 0.0002
I0625 15:35:41.584043  6673 solver.cpp:228] Iteration 440, loss = 0.269764
I0625 15:35:41.584072  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 15:35:41.584082  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.110229 (* 1 = 0.110229 loss)
I0625 15:35:41.584089  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.215131 (* 1 = 0.215131 loss)
I0625 15:35:41.584095  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0442803 (* 1 = 0.0442803 loss)
I0625 15:35:41.584101  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379847 (* 1 = 0.0379847 loss)
I0625 15:35:41.584108  6673 sgd_solver.cpp:106] Iteration 440, lr = 0.0002
I0625 15:37:19.673439  6673 solver.cpp:228] Iteration 460, loss = 0.575213
I0625 15:37:19.673463  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 15:37:19.673470  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0482512 (* 1 = 0.0482512 loss)
I0625 15:37:19.673475  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.205788 (* 1 = 0.205788 loss)
I0625 15:37:19.673477  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0933591 (* 1 = 0.0933591 loss)
I0625 15:37:19.673481  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.137356 (* 1 = 0.137356 loss)
I0625 15:37:19.673486  6673 sgd_solver.cpp:106] Iteration 460, lr = 0.0002
I0625 15:38:57.725416  6673 solver.cpp:228] Iteration 480, loss = 0.565882
I0625 15:38:57.725442  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 15:38:57.725450  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000903642 (* 1 = 0.000903642 loss)
I0625 15:38:57.725453  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.353871 (* 1 = 0.353871 loss)
I0625 15:38:57.725456  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.179091 (* 1 = 0.179091 loss)
I0625 15:38:57.725461  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.185614 (* 1 = 0.185614 loss)
I0625 15:38:57.725466  6673 sgd_solver.cpp:106] Iteration 480, lr = 0.0002
I0625 15:40:35.709466  6673 solver.cpp:228] Iteration 500, loss = 0.340961
I0625 15:40:35.709493  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 15:40:35.709501  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0404608 (* 1 = 0.0404608 loss)
I0625 15:40:35.709504  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.166229 (* 1 = 0.166229 loss)
I0625 15:40:35.709507  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293248 (* 1 = 0.0293248 loss)
I0625 15:40:35.709511  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115859 (* 1 = 0.0115859 loss)
I0625 15:40:35.709517  6673 sgd_solver.cpp:106] Iteration 500, lr = 0.0002
I0625 15:42:13.726014  6673 solver.cpp:228] Iteration 520, loss = 0.747559
I0625 15:42:13.726042  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 15:42:13.726049  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.244733 (* 1 = 0.244733 loss)
I0625 15:42:13.726053  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.558329 (* 1 = 0.558329 loss)
I0625 15:42:13.726058  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.509074 (* 1 = 0.509074 loss)
I0625 15:42:13.726061  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.409937 (* 1 = 0.409937 loss)
I0625 15:42:13.726066  6673 sgd_solver.cpp:106] Iteration 520, lr = 0.0002
I0625 15:43:51.794250  6673 solver.cpp:228] Iteration 540, loss = 0.225671
I0625 15:43:51.794278  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:43:51.794286  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000119439 (* 1 = 0.000119439 loss)
I0625 15:43:51.794291  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0814514 (* 1 = 0.0814514 loss)
I0625 15:43:51.794296  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026735 (* 1 = 0.026735 loss)
I0625 15:43:51.794299  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108907 (* 1 = 0.0108907 loss)
I0625 15:43:51.794304  6673 sgd_solver.cpp:106] Iteration 540, lr = 0.0002
I0625 15:45:29.846233  6673 solver.cpp:228] Iteration 560, loss = 0.419716
I0625 15:45:29.846262  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 15:45:29.846273  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.13104 (* 1 = 0.13104 loss)
I0625 15:45:29.846279  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.292769 (* 1 = 0.292769 loss)
I0625 15:45:29.846285  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0455211 (* 1 = 0.0455211 loss)
I0625 15:45:29.846290  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0555003 (* 1 = 0.0555003 loss)
I0625 15:45:29.846297  6673 sgd_solver.cpp:106] Iteration 560, lr = 0.0002
I0625 15:47:07.805289  6673 solver.cpp:228] Iteration 580, loss = 0.34771
I0625 15:47:07.805315  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 15:47:07.805325  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.173805 (* 1 = 0.173805 loss)
I0625 15:47:07.805332  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.378325 (* 1 = 0.378325 loss)
I0625 15:47:07.805338  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.056737 (* 1 = 0.056737 loss)
I0625 15:47:07.805344  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0604599 (* 1 = 0.0604599 loss)
I0625 15:47:07.805351  6673 sgd_solver.cpp:106] Iteration 580, lr = 0.0002
speed: 4.895s / iter
I0625 15:48:45.867789  6673 solver.cpp:228] Iteration 600, loss = 0.393324
I0625 15:48:45.867815  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 15:48:45.867821  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0792409 (* 1 = 0.0792409 loss)
I0625 15:48:45.867826  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.194546 (* 1 = 0.194546 loss)
I0625 15:48:45.867832  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281981 (* 1 = 0.0281981 loss)
I0625 15:48:45.867837  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145579 (* 1 = 0.0145579 loss)
I0625 15:48:45.867841  6673 sgd_solver.cpp:106] Iteration 600, lr = 0.0002
I0625 15:50:23.875193  6673 solver.cpp:228] Iteration 620, loss = 0.605481
I0625 15:50:23.875216  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 15:50:23.875223  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.27886 (* 1 = 0.27886 loss)
I0625 15:50:23.875227  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.54757 (* 1 = 0.54757 loss)
I0625 15:50:23.875231  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.164581 (* 1 = 0.164581 loss)
I0625 15:50:23.875234  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109713 (* 1 = 0.109713 loss)
I0625 15:50:23.875239  6673 sgd_solver.cpp:106] Iteration 620, lr = 0.0002
I0625 15:52:01.893999  6673 solver.cpp:228] Iteration 640, loss = 0.556302
I0625 15:52:01.894032  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 15:52:01.894044  6673 solver.cpp:244]     Train net output #1: loss_bbox = 3.11962e-05 (* 1 = 3.11962e-05 loss)
I0625 15:52:01.894053  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0771831 (* 1 = 0.0771831 loss)
I0625 15:52:01.894060  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.022604 (* 1 = 0.022604 loss)
I0625 15:52:01.894068  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132946 (* 1 = 0.0132946 loss)
I0625 15:52:01.894076  6673 sgd_solver.cpp:106] Iteration 640, lr = 0.0002
I0625 15:53:39.998674  6673 solver.cpp:228] Iteration 660, loss = 0.667285
I0625 15:53:39.998699  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 15:53:39.998706  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.179429 (* 1 = 0.179429 loss)
I0625 15:53:39.998710  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.258485 (* 1 = 0.258485 loss)
I0625 15:53:39.998714  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026102 (* 1 = 0.026102 loss)
I0625 15:53:39.998718  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160684 (* 1 = 0.0160684 loss)
I0625 15:53:39.998723  6673 sgd_solver.cpp:106] Iteration 660, lr = 0.0002
I0625 15:55:18.055141  6673 solver.cpp:228] Iteration 680, loss = 0.425888
I0625 15:55:18.055166  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 15:55:18.055173  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0076856 (* 1 = 0.0076856 loss)
I0625 15:55:18.055177  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0979583 (* 1 = 0.0979583 loss)
I0625 15:55:18.055181  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256464 (* 1 = 0.0256464 loss)
I0625 15:55:18.055184  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145001 (* 1 = 0.0145001 loss)
I0625 15:55:18.055189  6673 sgd_solver.cpp:106] Iteration 680, lr = 0.0002
I0625 15:56:56.104203  6673 solver.cpp:228] Iteration 700, loss = 0.489391
I0625 15:56:56.104229  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 15:56:56.104240  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172609 (* 1 = 0.0172609 loss)
I0625 15:56:56.104246  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.163801 (* 1 = 0.163801 loss)
I0625 15:56:56.104252  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0370206 (* 1 = 0.0370206 loss)
I0625 15:56:56.104259  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0620055 (* 1 = 0.0620055 loss)
I0625 15:56:56.104265  6673 sgd_solver.cpp:106] Iteration 700, lr = 0.0002
I0625 15:58:34.055644  6673 solver.cpp:228] Iteration 720, loss = 0.304247
I0625 15:58:34.055670  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 15:58:34.055677  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.19215 (* 1 = 0.19215 loss)
I0625 15:58:34.055681  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.31508 (* 1 = 0.31508 loss)
I0625 15:58:34.055685  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206978 (* 1 = 0.0206978 loss)
I0625 15:58:34.055689  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135182 (* 1 = 0.0135182 loss)
I0625 15:58:34.055694  6673 sgd_solver.cpp:106] Iteration 720, lr = 0.0002
I0625 16:00:12.082303  6673 solver.cpp:228] Iteration 740, loss = 0.411282
I0625 16:00:12.082329  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0625 16:00:12.082339  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.167119 (* 1 = 0.167119 loss)
I0625 16:00:12.082345  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.380874 (* 1 = 0.380874 loss)
I0625 16:00:12.082350  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0634133 (* 1 = 0.0634133 loss)
I0625 16:00:12.082356  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.056308 (* 1 = 0.056308 loss)
I0625 16:00:12.082363  6673 sgd_solver.cpp:106] Iteration 740, lr = 0.0002
I0625 16:01:50.079211  6673 solver.cpp:228] Iteration 760, loss = 0.66827
I0625 16:01:50.079236  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0625 16:01:50.079244  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.326583 (* 1 = 0.326583 loss)
I0625 16:01:50.079248  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.51517 (* 1 = 0.51517 loss)
I0625 16:01:50.079253  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0798434 (* 1 = 0.0798434 loss)
I0625 16:01:50.079257  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0809405 (* 1 = 0.0809405 loss)
I0625 16:01:50.079262  6673 sgd_solver.cpp:106] Iteration 760, lr = 0.0002
I0625 16:03:28.086189  6673 solver.cpp:228] Iteration 780, loss = 0.345286
I0625 16:03:28.086213  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 16:03:28.086220  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274822 (* 1 = 0.0274822 loss)
I0625 16:03:28.086225  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138361 (* 1 = 0.138361 loss)
I0625 16:03:28.086228  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143907 (* 1 = 0.0143907 loss)
I0625 16:03:28.086231  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0089998 (* 1 = 0.0089998 loss)
I0625 16:03:28.086236  6673 sgd_solver.cpp:106] Iteration 780, lr = 0.0002
speed: 4.897s / iter
I0625 16:05:06.058135  6673 solver.cpp:228] Iteration 800, loss = 0.376043
I0625 16:05:06.058161  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 16:05:06.058168  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0001017 (* 1 = 0.0001017 loss)
I0625 16:05:06.058173  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0543979 (* 1 = 0.0543979 loss)
I0625 16:05:06.058176  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205552 (* 1 = 0.0205552 loss)
I0625 16:05:06.058181  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0093098 (* 1 = 0.0093098 loss)
I0625 16:05:06.058185  6673 sgd_solver.cpp:106] Iteration 800, lr = 0.0002
I0625 16:06:44.138963  6673 solver.cpp:228] Iteration 820, loss = 0.283338
I0625 16:06:44.138988  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 16:06:44.138995  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0693104 (* 1 = 0.0693104 loss)
I0625 16:06:44.138999  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.237078 (* 1 = 0.237078 loss)
I0625 16:06:44.139003  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0477623 (* 1 = 0.0477623 loss)
I0625 16:06:44.139006  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0532332 (* 1 = 0.0532332 loss)
I0625 16:06:44.139010  6673 sgd_solver.cpp:106] Iteration 820, lr = 0.0002
I0625 16:08:22.267941  6673 solver.cpp:228] Iteration 840, loss = 0.635804
I0625 16:08:22.267969  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 16:08:22.267979  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0654828 (* 1 = 0.0654828 loss)
I0625 16:08:22.267984  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.145283 (* 1 = 0.145283 loss)
I0625 16:08:22.267990  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109765 (* 1 = 0.0109765 loss)
I0625 16:08:22.267995  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106391 (* 1 = 0.0106391 loss)
I0625 16:08:22.268003  6673 sgd_solver.cpp:106] Iteration 840, lr = 0.0002
I0625 16:10:00.261441  6673 solver.cpp:228] Iteration 860, loss = 0.759438
I0625 16:10:00.261464  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 16:10:00.261471  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.171228 (* 1 = 0.171228 loss)
I0625 16:10:00.261476  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.405109 (* 1 = 0.405109 loss)
I0625 16:10:00.261478  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0490225 (* 1 = 0.0490225 loss)
I0625 16:10:00.261482  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0501293 (* 1 = 0.0501293 loss)
I0625 16:10:00.261487  6673 sgd_solver.cpp:106] Iteration 860, lr = 0.0002
I0625 16:11:38.441303  6673 solver.cpp:228] Iteration 880, loss = 0.429429
I0625 16:11:38.441336  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 16:11:38.441349  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151036 (* 1 = 0.0151036 loss)
I0625 16:11:38.441356  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0953613 (* 1 = 0.0953613 loss)
I0625 16:11:38.441364  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149383 (* 1 = 0.0149383 loss)
I0625 16:11:38.441370  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104128 (* 1 = 0.0104128 loss)
I0625 16:11:38.441378  6673 sgd_solver.cpp:106] Iteration 880, lr = 0.0002
I0625 16:13:16.553023  6673 solver.cpp:228] Iteration 900, loss = 0.696468
I0625 16:13:16.553047  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0625 16:13:16.553056  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.494587 (* 1 = 0.494587 loss)
I0625 16:13:16.553059  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.820593 (* 1 = 0.820593 loss)
I0625 16:13:16.553063  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.386855 (* 1 = 0.386855 loss)
I0625 16:13:16.553067  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.343781 (* 1 = 0.343781 loss)
I0625 16:13:16.553071  6673 sgd_solver.cpp:106] Iteration 900, lr = 0.0002
I0625 16:14:54.491696  6673 solver.cpp:228] Iteration 920, loss = 0.427801
I0625 16:14:54.491720  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0625 16:14:54.491727  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.25163 (* 1 = 0.25163 loss)
I0625 16:14:54.491731  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.430036 (* 1 = 0.430036 loss)
I0625 16:14:54.491735  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0333441 (* 1 = 0.0333441 loss)
I0625 16:14:54.491739  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0432365 (* 1 = 0.0432365 loss)
I0625 16:14:54.491742  6673 sgd_solver.cpp:106] Iteration 920, lr = 0.0002
I0625 16:16:32.474259  6673 solver.cpp:228] Iteration 940, loss = 0.481293
I0625 16:16:32.474284  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 16:16:32.474292  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.146114 (* 1 = 0.146114 loss)
I0625 16:16:32.474295  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.293363 (* 1 = 0.293363 loss)
I0625 16:16:32.474299  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183709 (* 1 = 0.0183709 loss)
I0625 16:16:32.474303  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00836366 (* 1 = 0.00836366 loss)
I0625 16:16:32.474308  6673 sgd_solver.cpp:106] Iteration 940, lr = 0.0002
I0625 16:18:10.579835  6673 solver.cpp:228] Iteration 960, loss = 0.505197
I0625 16:18:10.579864  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0625 16:18:10.579872  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.316212 (* 1 = 0.316212 loss)
I0625 16:18:10.579877  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.507172 (* 1 = 0.507172 loss)
I0625 16:18:10.579881  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.041681 (* 1 = 0.041681 loss)
I0625 16:18:10.579885  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364364 (* 1 = 0.0364364 loss)
I0625 16:18:10.579890  6673 sgd_solver.cpp:106] Iteration 960, lr = 0.0002
I0625 16:19:48.583453  6673 solver.cpp:228] Iteration 980, loss = 0.608409
I0625 16:19:48.583483  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 16:19:48.583492  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.162176 (* 1 = 0.162176 loss)
I0625 16:19:48.583497  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.345013 (* 1 = 0.345013 loss)
I0625 16:19:48.583500  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0309962 (* 1 = 0.0309962 loss)
I0625 16:19:48.583505  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296897 (* 1 = 0.0296897 loss)
I0625 16:19:48.583511  6673 sgd_solver.cpp:106] Iteration 980, lr = 0.0002
speed: 4.898s / iter
I0625 16:21:26.601191  6673 solver.cpp:228] Iteration 1000, loss = 0.376047
I0625 16:21:26.601231  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 16:21:26.601239  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0686808 (* 1 = 0.0686808 loss)
I0625 16:21:26.601243  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.26908 (* 1 = 0.26908 loss)
I0625 16:21:26.601248  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103982 (* 1 = 0.103982 loss)
I0625 16:21:26.601251  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0771397 (* 1 = 0.0771397 loss)
I0625 16:21:26.601258  6673 sgd_solver.cpp:106] Iteration 1000, lr = 0.0002
I0625 16:23:04.700959  6673 solver.cpp:228] Iteration 1020, loss = 0.608766
I0625 16:23:04.700984  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 16:23:04.700990  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.210849 (* 1 = 0.210849 loss)
I0625 16:23:04.700994  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.523127 (* 1 = 0.523127 loss)
I0625 16:23:04.700997  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0294083 (* 1 = 0.0294083 loss)
I0625 16:23:04.701001  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0423385 (* 1 = 0.0423385 loss)
I0625 16:23:04.701005  6673 sgd_solver.cpp:106] Iteration 1020, lr = 0.0002
I0625 16:24:42.648871  6673 solver.cpp:228] Iteration 1040, loss = 0.653006
I0625 16:24:42.648900  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 16:24:42.648910  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.383016 (* 1 = 0.383016 loss)
I0625 16:24:42.648914  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.523387 (* 1 = 0.523387 loss)
I0625 16:24:42.648918  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0414474 (* 1 = 0.0414474 loss)
I0625 16:24:42.648924  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359654 (* 1 = 0.0359654 loss)
I0625 16:24:42.648931  6673 sgd_solver.cpp:106] Iteration 1040, lr = 0.0002
I0625 16:26:20.614619  6673 solver.cpp:228] Iteration 1060, loss = 0.567772
I0625 16:26:20.614645  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 16:26:20.614653  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000441441 (* 1 = 0.000441441 loss)
I0625 16:26:20.614660  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0685781 (* 1 = 0.0685781 loss)
I0625 16:26:20.614663  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019863 (* 1 = 0.019863 loss)
I0625 16:26:20.614668  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236427 (* 1 = 0.0236427 loss)
I0625 16:26:20.614673  6673 sgd_solver.cpp:106] Iteration 1060, lr = 0.0002
I0625 16:27:58.603479  6673 solver.cpp:228] Iteration 1080, loss = 0.34848
I0625 16:27:58.603508  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 16:27:58.603518  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827831 (* 1 = 0.0827831 loss)
I0625 16:27:58.603523  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.220998 (* 1 = 0.220998 loss)
I0625 16:27:58.603526  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255354 (* 1 = 0.0255354 loss)
I0625 16:27:58.603531  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0389676 (* 1 = 0.0389676 loss)
I0625 16:27:58.603536  6673 sgd_solver.cpp:106] Iteration 1080, lr = 0.0002
I0625 16:29:36.560199  6673 solver.cpp:228] Iteration 1100, loss = 0.452797
I0625 16:29:36.560223  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 16:29:36.560230  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0444399 (* 1 = 0.0444399 loss)
I0625 16:29:36.560235  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.189469 (* 1 = 0.189469 loss)
I0625 16:29:36.560238  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135372 (* 1 = 0.0135372 loss)
I0625 16:29:36.560241  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00817927 (* 1 = 0.00817927 loss)
I0625 16:29:36.560246  6673 sgd_solver.cpp:106] Iteration 1100, lr = 0.0002
I0625 16:31:14.507756  6673 solver.cpp:228] Iteration 1120, loss = 0.661675
I0625 16:31:14.507781  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 16:31:14.507788  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0307213 (* 1 = 0.0307213 loss)
I0625 16:31:14.507791  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0664517 (* 1 = 0.0664517 loss)
I0625 16:31:14.507796  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186032 (* 1 = 0.0186032 loss)
I0625 16:31:14.507798  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158624 (* 1 = 0.0158624 loss)
I0625 16:31:14.507802  6673 sgd_solver.cpp:106] Iteration 1120, lr = 0.0002
I0625 16:32:52.468302  6673 solver.cpp:228] Iteration 1140, loss = 0.552625
I0625 16:32:52.468329  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 16:32:52.468338  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.362867 (* 1 = 0.362867 loss)
I0625 16:32:52.468346  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.623768 (* 1 = 0.623768 loss)
I0625 16:32:52.468353  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0298675 (* 1 = 0.0298675 loss)
I0625 16:32:52.468358  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490432 (* 1 = 0.0490432 loss)
I0625 16:32:52.468364  6673 sgd_solver.cpp:106] Iteration 1140, lr = 0.0002
I0625 16:34:30.458883  6673 solver.cpp:228] Iteration 1160, loss = 0.287482
I0625 16:34:30.458909  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 16:34:30.458917  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.175305 (* 1 = 0.175305 loss)
I0625 16:34:30.458922  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.340604 (* 1 = 0.340604 loss)
I0625 16:34:30.458927  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195618 (* 1 = 0.0195618 loss)
I0625 16:34:30.458931  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311637 (* 1 = 0.0311637 loss)
I0625 16:34:30.458937  6673 sgd_solver.cpp:106] Iteration 1160, lr = 0.0002
I0625 16:36:08.431078  6673 solver.cpp:228] Iteration 1180, loss = 0.482918
I0625 16:36:08.431102  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 16:36:08.431108  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.115212 (* 1 = 0.115212 loss)
I0625 16:36:08.431113  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.239205 (* 1 = 0.239205 loss)
I0625 16:36:08.431115  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125425 (* 1 = 0.0125425 loss)
I0625 16:36:08.431119  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00751312 (* 1 = 0.00751312 loss)
I0625 16:36:08.431123  6673 sgd_solver.cpp:106] Iteration 1180, lr = 0.0002
speed: 4.898s / iter
I0625 16:37:46.424269  6673 solver.cpp:228] Iteration 1200, loss = 0.37679
I0625 16:37:46.424302  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 16:37:46.424314  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0149291 (* 1 = 0.0149291 loss)
I0625 16:37:46.424321  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.096337 (* 1 = 0.096337 loss)
I0625 16:37:46.424327  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0235942 (* 1 = 0.0235942 loss)
I0625 16:37:46.424334  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153747 (* 1 = 0.0153747 loss)
I0625 16:37:46.424342  6673 sgd_solver.cpp:106] Iteration 1200, lr = 0.0002
I0625 16:39:24.366786  6673 solver.cpp:228] Iteration 1220, loss = 0.616885
I0625 16:39:24.366813  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 16:39:24.366822  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0858172 (* 1 = 0.0858172 loss)
I0625 16:39:24.366825  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.242955 (* 1 = 0.242955 loss)
I0625 16:39:24.366828  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0555437 (* 1 = 0.0555437 loss)
I0625 16:39:24.366832  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418201 (* 1 = 0.0418201 loss)
I0625 16:39:24.366837  6673 sgd_solver.cpp:106] Iteration 1220, lr = 0.0002
I0625 16:41:02.267709  6673 solver.cpp:228] Iteration 1240, loss = 0.626855
I0625 16:41:02.267731  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 16:41:02.267737  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.187597 (* 1 = 0.187597 loss)
I0625 16:41:02.267742  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.424388 (* 1 = 0.424388 loss)
I0625 16:41:02.267747  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.176515 (* 1 = 0.176515 loss)
I0625 16:41:02.267751  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.17598 (* 1 = 0.17598 loss)
I0625 16:41:02.267756  6673 sgd_solver.cpp:106] Iteration 1240, lr = 0.0002
I0625 16:42:40.239189  6673 solver.cpp:228] Iteration 1260, loss = 0.386196
I0625 16:42:40.239217  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 16:42:40.239224  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00108927 (* 1 = 0.00108927 loss)
I0625 16:42:40.239229  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0495152 (* 1 = 0.0495152 loss)
I0625 16:42:40.239233  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159534 (* 1 = 0.0159534 loss)
I0625 16:42:40.239236  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106228 (* 1 = 0.0106228 loss)
I0625 16:42:40.239241  6673 sgd_solver.cpp:106] Iteration 1260, lr = 0.0002
I0625 16:44:18.259413  6673 solver.cpp:228] Iteration 1280, loss = 0.32133
I0625 16:44:18.259443  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 16:44:18.259455  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261279 (* 1 = 0.0261279 loss)
I0625 16:44:18.259464  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0830775 (* 1 = 0.0830775 loss)
I0625 16:44:18.259470  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142931 (* 1 = 0.0142931 loss)
I0625 16:44:18.259477  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152114 (* 1 = 0.0152114 loss)
I0625 16:44:18.259485  6673 sgd_solver.cpp:106] Iteration 1280, lr = 0.0002
I0625 16:45:56.295753  6673 solver.cpp:228] Iteration 1300, loss = 0.541461
I0625 16:45:56.295778  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.546875
I0625 16:45:56.295786  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.580608 (* 1 = 0.580608 loss)
I0625 16:45:56.295790  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.863755 (* 1 = 0.863755 loss)
I0625 16:45:56.295794  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0492412 (* 1 = 0.0492412 loss)
I0625 16:45:56.295799  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107381 (* 1 = 0.107381 loss)
I0625 16:45:56.295804  6673 sgd_solver.cpp:106] Iteration 1300, lr = 0.0002
I0625 16:47:34.308866  6673 solver.cpp:228] Iteration 1320, loss = 0.848026
I0625 16:47:34.308892  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 16:47:34.308899  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.238218 (* 1 = 0.238218 loss)
I0625 16:47:34.308903  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.375563 (* 1 = 0.375563 loss)
I0625 16:47:34.308907  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0510909 (* 1 = 0.0510909 loss)
I0625 16:47:34.308912  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368745 (* 1 = 0.0368745 loss)
I0625 16:47:34.308917  6673 sgd_solver.cpp:106] Iteration 1320, lr = 0.0002
I0625 16:49:12.266229  6673 solver.cpp:228] Iteration 1340, loss = 0.354602
I0625 16:49:12.266253  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 16:49:12.266260  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0345015 (* 1 = 0.0345015 loss)
I0625 16:49:12.266263  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.126515 (* 1 = 0.126515 loss)
I0625 16:49:12.266268  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0325043 (* 1 = 0.0325043 loss)
I0625 16:49:12.266270  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319961 (* 1 = 0.0319961 loss)
I0625 16:49:12.266274  6673 sgd_solver.cpp:106] Iteration 1340, lr = 0.0002
I0625 16:50:50.206766  6673 solver.cpp:228] Iteration 1360, loss = 0.429588
I0625 16:50:50.206792  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 16:50:50.206799  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.130258 (* 1 = 0.130258 loss)
I0625 16:50:50.206804  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.228686 (* 1 = 0.228686 loss)
I0625 16:50:50.206809  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00722583 (* 1 = 0.00722583 loss)
I0625 16:50:50.206812  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00705033 (* 1 = 0.00705033 loss)
I0625 16:50:50.206816  6673 sgd_solver.cpp:106] Iteration 1360, lr = 0.0002
I0625 16:52:28.203650  6673 solver.cpp:228] Iteration 1380, loss = 0.407751
I0625 16:52:28.203681  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 16:52:28.203691  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0857181 (* 1 = 0.0857181 loss)
I0625 16:52:28.203696  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.261376 (* 1 = 0.261376 loss)
I0625 16:52:28.203701  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0315378 (* 1 = 0.0315378 loss)
I0625 16:52:28.203704  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0739409 (* 1 = 0.0739409 loss)
I0625 16:52:28.203711  6673 sgd_solver.cpp:106] Iteration 1380, lr = 0.0002
speed: 4.898s / iter
I0625 16:54:06.197088  6673 solver.cpp:228] Iteration 1400, loss = 0.51268
I0625 16:54:06.197110  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 16:54:06.197118  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.100474 (* 1 = 0.100474 loss)
I0625 16:54:06.197120  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.168545 (* 1 = 0.168545 loss)
I0625 16:54:06.197124  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152745 (* 1 = 0.0152745 loss)
I0625 16:54:06.197127  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352179 (* 1 = 0.0352179 loss)
I0625 16:54:06.197131  6673 sgd_solver.cpp:106] Iteration 1400, lr = 0.0002
I0625 16:55:44.189154  6673 solver.cpp:228] Iteration 1420, loss = 0.477485
I0625 16:55:44.189179  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 16:55:44.189188  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.277452 (* 1 = 0.277452 loss)
I0625 16:55:44.189191  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.464647 (* 1 = 0.464647 loss)
I0625 16:55:44.189195  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0299179 (* 1 = 0.0299179 loss)
I0625 16:55:44.189199  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332606 (* 1 = 0.0332606 loss)
I0625 16:55:44.189204  6673 sgd_solver.cpp:106] Iteration 1420, lr = 0.0002
I0625 16:57:22.140759  6673 solver.cpp:228] Iteration 1440, loss = 0.585467
I0625 16:57:22.140784  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 16:57:22.140791  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.111184 (* 1 = 0.111184 loss)
I0625 16:57:22.140795  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.270309 (* 1 = 0.270309 loss)
I0625 16:57:22.140799  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.028883 (* 1 = 0.028883 loss)
I0625 16:57:22.140801  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326095 (* 1 = 0.0326095 loss)
I0625 16:57:22.140806  6673 sgd_solver.cpp:106] Iteration 1440, lr = 0.0002
I0625 16:59:00.111254  6673 solver.cpp:228] Iteration 1460, loss = 0.6075
I0625 16:59:00.111281  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 16:59:00.111289  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.190492 (* 1 = 0.190492 loss)
I0625 16:59:00.111294  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.443897 (* 1 = 0.443897 loss)
I0625 16:59:00.111297  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030092 (* 1 = 0.030092 loss)
I0625 16:59:00.111300  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0436589 (* 1 = 0.0436589 loss)
I0625 16:59:00.111305  6673 sgd_solver.cpp:106] Iteration 1460, lr = 0.0002
I0625 17:00:38.151473  6673 solver.cpp:228] Iteration 1480, loss = 0.317744
I0625 17:00:38.151510  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:00:38.151520  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.039834 (* 1 = 0.039834 loss)
I0625 17:00:38.151526  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.115013 (* 1 = 0.115013 loss)
I0625 17:00:38.151533  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00867102 (* 1 = 0.00867102 loss)
I0625 17:00:38.151538  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121636 (* 1 = 0.0121636 loss)
I0625 17:00:38.151548  6673 sgd_solver.cpp:106] Iteration 1480, lr = 0.0002
I0625 17:02:16.221271  6673 solver.cpp:228] Iteration 1500, loss = 0.484214
I0625 17:02:16.221302  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:02:16.221308  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0786373 (* 1 = 0.0786373 loss)
I0625 17:02:16.221312  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.108435 (* 1 = 0.108435 loss)
I0625 17:02:16.221315  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00684449 (* 1 = 0.00684449 loss)
I0625 17:02:16.221319  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00854617 (* 1 = 0.00854617 loss)
I0625 17:02:16.221323  6673 sgd_solver.cpp:106] Iteration 1500, lr = 0.0002
I0625 17:03:54.326877  6673 solver.cpp:228] Iteration 1520, loss = 0.445286
I0625 17:03:54.326920  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 17:03:54.326933  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0845048 (* 1 = 0.0845048 loss)
I0625 17:03:54.326939  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.437965 (* 1 = 0.437965 loss)
I0625 17:03:54.326944  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0229351 (* 1 = 0.0229351 loss)
I0625 17:03:54.326951  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0493303 (* 1 = 0.0493303 loss)
I0625 17:03:54.326958  6673 sgd_solver.cpp:106] Iteration 1520, lr = 0.0002
I0625 17:05:32.321612  6673 solver.cpp:228] Iteration 1540, loss = 0.357719
I0625 17:05:32.321645  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 17:05:32.321651  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0158245 (* 1 = 0.0158245 loss)
I0625 17:05:32.321656  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0673872 (* 1 = 0.0673872 loss)
I0625 17:05:32.321660  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120662 (* 1 = 0.0120662 loss)
I0625 17:05:32.321662  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011748 (* 1 = 0.011748 loss)
I0625 17:05:32.321667  6673 sgd_solver.cpp:106] Iteration 1540, lr = 0.0002
I0625 17:07:10.310957  6673 solver.cpp:228] Iteration 1560, loss = 0.312891
I0625 17:07:10.310995  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 17:07:10.311005  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434719 (* 1 = 0.0434719 loss)
I0625 17:07:10.311010  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.14323 (* 1 = 0.14323 loss)
I0625 17:07:10.311015  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508659 (* 1 = 0.00508659 loss)
I0625 17:07:10.311020  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00796782 (* 1 = 0.00796782 loss)
I0625 17:07:10.311025  6673 sgd_solver.cpp:106] Iteration 1560, lr = 0.0002
I0625 17:08:48.343628  6673 solver.cpp:228] Iteration 1580, loss = 0.385299
I0625 17:08:48.343653  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 17:08:48.343662  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0978575 (* 1 = 0.0978575 loss)
I0625 17:08:48.343665  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.146747 (* 1 = 0.146747 loss)
I0625 17:08:48.343669  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00530453 (* 1 = 0.00530453 loss)
I0625 17:08:48.343673  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00271616 (* 1 = 0.00271616 loss)
I0625 17:08:48.343678  6673 sgd_solver.cpp:106] Iteration 1580, lr = 0.0002
speed: 4.898s / iter
I0625 17:10:26.309551  6673 solver.cpp:228] Iteration 1600, loss = 0.30531
I0625 17:10:26.309576  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 17:10:26.309584  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.066019 (* 1 = 0.066019 loss)
I0625 17:10:26.309589  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.180063 (* 1 = 0.180063 loss)
I0625 17:10:26.309592  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132154 (* 1 = 0.0132154 loss)
I0625 17:10:26.309597  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0080997 (* 1 = 0.0080997 loss)
I0625 17:10:26.309602  6673 sgd_solver.cpp:106] Iteration 1600, lr = 0.0002
I0625 17:12:04.260512  6673 solver.cpp:228] Iteration 1620, loss = 0.532421
I0625 17:12:04.260540  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 17:12:04.260550  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.297807 (* 1 = 0.297807 loss)
I0625 17:12:04.260555  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.49424 (* 1 = 0.49424 loss)
I0625 17:12:04.260560  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0447688 (* 1 = 0.0447688 loss)
I0625 17:12:04.260565  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0396737 (* 1 = 0.0396737 loss)
I0625 17:12:04.260571  6673 sgd_solver.cpp:106] Iteration 1620, lr = 0.0002
I0625 17:13:42.294234  6673 solver.cpp:228] Iteration 1640, loss = 0.19077
I0625 17:13:42.294262  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 17:13:42.294270  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.126296 (* 1 = 0.126296 loss)
I0625 17:13:42.294275  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.310454 (* 1 = 0.310454 loss)
I0625 17:13:42.294278  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026096 (* 1 = 0.026096 loss)
I0625 17:13:42.294282  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175957 (* 1 = 0.0175957 loss)
I0625 17:13:42.294287  6673 sgd_solver.cpp:106] Iteration 1640, lr = 0.0002
I0625 17:15:20.442011  6673 solver.cpp:228] Iteration 1660, loss = 0.412387
I0625 17:15:20.442034  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 17:15:20.442041  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0497944 (* 1 = 0.0497944 loss)
I0625 17:15:20.442045  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.118104 (* 1 = 0.118104 loss)
I0625 17:15:20.442049  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00879634 (* 1 = 0.00879634 loss)
I0625 17:15:20.442052  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00914214 (* 1 = 0.00914214 loss)
I0625 17:15:20.442056  6673 sgd_solver.cpp:106] Iteration 1660, lr = 0.0002
I0625 17:16:58.438302  6673 solver.cpp:228] Iteration 1680, loss = 0.581409
I0625 17:16:58.438326  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:16:58.438335  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542133 (* 1 = 0.0542133 loss)
I0625 17:16:58.438339  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.160524 (* 1 = 0.160524 loss)
I0625 17:16:58.438344  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292904 (* 1 = 0.00292904 loss)
I0625 17:16:58.438347  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00608756 (* 1 = 0.00608756 loss)
I0625 17:16:58.438352  6673 sgd_solver.cpp:106] Iteration 1680, lr = 0.0002
I0625 17:18:36.531112  6673 solver.cpp:228] Iteration 1700, loss = 0.404784
I0625 17:18:36.531138  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0625 17:18:36.531146  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.284497 (* 1 = 0.284497 loss)
I0625 17:18:36.531150  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.4633 (* 1 = 0.4633 loss)
I0625 17:18:36.531154  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.119499 (* 1 = 0.119499 loss)
I0625 17:18:36.531157  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168597 (* 1 = 0.168597 loss)
I0625 17:18:36.531162  6673 sgd_solver.cpp:106] Iteration 1700, lr = 0.0002
I0625 17:20:14.525830  6673 solver.cpp:228] Iteration 1720, loss = 0.353482
I0625 17:20:14.525853  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:20:14.525861  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00129036 (* 1 = 0.00129036 loss)
I0625 17:20:14.525864  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0662246 (* 1 = 0.0662246 loss)
I0625 17:20:14.525868  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00937344 (* 1 = 0.00937344 loss)
I0625 17:20:14.525871  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148389 (* 1 = 0.0148389 loss)
I0625 17:20:14.525876  6673 sgd_solver.cpp:106] Iteration 1720, lr = 0.0002
I0625 17:21:52.495151  6673 solver.cpp:228] Iteration 1740, loss = 0.336045
I0625 17:21:52.495178  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 17:21:52.495185  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613258 (* 1 = 0.0613258 loss)
I0625 17:21:52.495189  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.282055 (* 1 = 0.282055 loss)
I0625 17:21:52.495193  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0890673 (* 1 = 0.0890673 loss)
I0625 17:21:52.495196  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.096303 (* 1 = 0.096303 loss)
I0625 17:21:52.495201  6673 sgd_solver.cpp:106] Iteration 1740, lr = 0.0002
I0625 17:23:30.454934  6673 solver.cpp:228] Iteration 1760, loss = 0.312169
I0625 17:23:30.454960  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 17:23:30.454967  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.14293 (* 1 = 0.14293 loss)
I0625 17:23:30.454972  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.354243 (* 1 = 0.354243 loss)
I0625 17:23:30.454975  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124101 (* 1 = 0.0124101 loss)
I0625 17:23:30.454978  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243794 (* 1 = 0.0243794 loss)
I0625 17:23:30.454983  6673 sgd_solver.cpp:106] Iteration 1760, lr = 0.0002
I0625 17:25:08.450547  6673 solver.cpp:228] Iteration 1780, loss = 0.345268
I0625 17:25:08.450575  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:25:08.450582  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.117956 (* 1 = 0.117956 loss)
I0625 17:25:08.450587  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.16969 (* 1 = 0.16969 loss)
I0625 17:25:08.450592  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0066868 (* 1 = 0.0066868 loss)
I0625 17:25:08.450595  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136984 (* 1 = 0.0136984 loss)
I0625 17:25:08.450600  6673 sgd_solver.cpp:106] Iteration 1780, lr = 0.0002
speed: 4.899s / iter
I0625 17:26:46.429397  6673 solver.cpp:228] Iteration 1800, loss = 0.277213
I0625 17:26:46.429421  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:26:46.429430  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0677318 (* 1 = 0.0677318 loss)
I0625 17:26:46.429433  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.170381 (* 1 = 0.170381 loss)
I0625 17:26:46.429437  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00625707 (* 1 = 0.00625707 loss)
I0625 17:26:46.429440  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211661 (* 1 = 0.0211661 loss)
I0625 17:26:46.429446  6673 sgd_solver.cpp:106] Iteration 1800, lr = 0.0002
I0625 17:28:24.445798  6673 solver.cpp:228] Iteration 1820, loss = 0.310123
I0625 17:28:24.445825  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 17:28:24.445834  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.174671 (* 1 = 0.174671 loss)
I0625 17:28:24.445840  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.356435 (* 1 = 0.356435 loss)
I0625 17:28:24.445845  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215403 (* 1 = 0.0215403 loss)
I0625 17:28:24.445850  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0547676 (* 1 = 0.0547676 loss)
I0625 17:28:24.445857  6673 sgd_solver.cpp:106] Iteration 1820, lr = 0.0002
I0625 17:30:02.432459  6673 solver.cpp:228] Iteration 1840, loss = 0.407522
I0625 17:30:02.432483  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 17:30:02.432492  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0679918 (* 1 = 0.0679918 loss)
I0625 17:30:02.432497  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.164729 (* 1 = 0.164729 loss)
I0625 17:30:02.432500  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0924565 (* 1 = 0.0924565 loss)
I0625 17:30:02.432503  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.074944 (* 1 = 0.074944 loss)
I0625 17:30:02.432509  6673 sgd_solver.cpp:106] Iteration 1840, lr = 0.0002
I0625 17:31:40.360015  6673 solver.cpp:228] Iteration 1860, loss = 0.335381
I0625 17:31:40.360039  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:31:40.360045  6673 solver.cpp:244]     Train net output #1: loss_bbox = 9.08494e-05 (* 1 = 9.08494e-05 loss)
I0625 17:31:40.360050  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0521185 (* 1 = 0.0521185 loss)
I0625 17:31:40.360054  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204023 (* 1 = 0.0204023 loss)
I0625 17:31:40.360056  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110791 (* 1 = 0.0110791 loss)
I0625 17:31:40.360061  6673 sgd_solver.cpp:106] Iteration 1860, lr = 0.0002
I0625 17:33:18.310104  6673 solver.cpp:228] Iteration 1880, loss = 0.39796
I0625 17:33:18.310132  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0625 17:33:18.310138  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.231254 (* 1 = 0.231254 loss)
I0625 17:33:18.310142  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.494934 (* 1 = 0.494934 loss)
I0625 17:33:18.310147  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0511085 (* 1 = 0.0511085 loss)
I0625 17:33:18.310149  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111645 (* 1 = 0.111645 loss)
I0625 17:33:18.310154  6673 sgd_solver.cpp:106] Iteration 1880, lr = 0.0002
I0625 17:34:56.369575  6673 solver.cpp:228] Iteration 1900, loss = 0.419034
I0625 17:34:56.369621  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 17:34:56.369632  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.157122 (* 1 = 0.157122 loss)
I0625 17:34:56.369637  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.239532 (* 1 = 0.239532 loss)
I0625 17:34:56.369642  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0409897 (* 1 = 0.0409897 loss)
I0625 17:34:56.369645  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.064626 (* 1 = 0.064626 loss)
I0625 17:34:56.369652  6673 sgd_solver.cpp:106] Iteration 1900, lr = 0.0002
I0625 17:36:34.372234  6673 solver.cpp:228] Iteration 1920, loss = 0.311942
I0625 17:36:34.372257  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 17:36:34.372265  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0810672 (* 1 = 0.0810672 loss)
I0625 17:36:34.372268  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130487 (* 1 = 0.130487 loss)
I0625 17:36:34.372272  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0060199 (* 1 = 0.0060199 loss)
I0625 17:36:34.372275  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00342237 (* 1 = 0.00342237 loss)
I0625 17:36:34.372280  6673 sgd_solver.cpp:106] Iteration 1920, lr = 0.0002
I0625 17:38:12.401407  6673 solver.cpp:228] Iteration 1940, loss = 0.263037
I0625 17:38:12.401433  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:38:12.401440  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0692506 (* 1 = 0.0692506 loss)
I0625 17:38:12.401445  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161099 (* 1 = 0.161099 loss)
I0625 17:38:12.401449  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00628979 (* 1 = 0.00628979 loss)
I0625 17:38:12.401453  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012379 (* 1 = 0.012379 loss)
I0625 17:38:12.401458  6673 sgd_solver.cpp:106] Iteration 1940, lr = 0.0002
I0625 17:39:50.348412  6673 solver.cpp:228] Iteration 1960, loss = 0.310237
I0625 17:39:50.348436  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 17:39:50.348443  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.225663 (* 1 = 0.225663 loss)
I0625 17:39:50.348448  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.508701 (* 1 = 0.508701 loss)
I0625 17:39:50.348451  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202431 (* 1 = 0.0202431 loss)
I0625 17:39:50.348454  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0524758 (* 1 = 0.0524758 loss)
I0625 17:39:50.348459  6673 sgd_solver.cpp:106] Iteration 1960, lr = 0.0002
I0625 17:41:28.309162  6673 solver.cpp:228] Iteration 1980, loss = 0.306908
I0625 17:41:28.309186  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 17:41:28.309193  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.193524 (* 1 = 0.193524 loss)
I0625 17:41:28.309197  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.248544 (* 1 = 0.248544 loss)
I0625 17:41:28.309201  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0345563 (* 1 = 0.0345563 loss)
I0625 17:41:28.309204  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00656926 (* 1 = 0.00656926 loss)
I0625 17:41:28.309208  6673 sgd_solver.cpp:106] Iteration 1980, lr = 0.0002
speed: 4.899s / iter
I0625 17:43:06.240005  6673 solver.cpp:228] Iteration 2000, loss = 0.437882
I0625 17:43:06.240029  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 17:43:06.240039  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625047 (* 1 = 0.0625047 loss)
I0625 17:43:06.240044  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.177617 (* 1 = 0.177617 loss)
I0625 17:43:06.240049  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154605 (* 1 = 0.0154605 loss)
I0625 17:43:06.240056  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272088 (* 1 = 0.0272088 loss)
I0625 17:43:06.240062  6673 sgd_solver.cpp:106] Iteration 2000, lr = 0.0002
I0625 17:44:44.157568  6673 solver.cpp:228] Iteration 2020, loss = 0.254054
I0625 17:44:44.157594  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:44:44.157604  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00236145 (* 1 = 0.00236145 loss)
I0625 17:44:44.157611  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0565764 (* 1 = 0.0565764 loss)
I0625 17:44:44.157618  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246477 (* 1 = 0.0246477 loss)
I0625 17:44:44.157624  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018164 (* 1 = 0.018164 loss)
I0625 17:44:44.157630  6673 sgd_solver.cpp:106] Iteration 2020, lr = 0.0002
I0625 17:46:22.074609  6673 solver.cpp:228] Iteration 2040, loss = 0.447168
I0625 17:46:22.074635  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 17:46:22.074642  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.149292 (* 1 = 0.149292 loss)
I0625 17:46:22.074646  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.238691 (* 1 = 0.238691 loss)
I0625 17:46:22.074651  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00965141 (* 1 = 0.00965141 loss)
I0625 17:46:22.074653  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.032211 (* 1 = 0.032211 loss)
I0625 17:46:22.074658  6673 sgd_solver.cpp:106] Iteration 2040, lr = 0.0002
I0625 17:47:59.981961  6673 solver.cpp:228] Iteration 2060, loss = 0.303953
I0625 17:47:59.981986  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:47:59.981994  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00131032 (* 1 = 0.00131032 loss)
I0625 17:47:59.981998  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0626637 (* 1 = 0.0626637 loss)
I0625 17:47:59.982002  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011379 (* 1 = 0.011379 loss)
I0625 17:47:59.982004  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165722 (* 1 = 0.0165722 loss)
I0625 17:47:59.982009  6673 sgd_solver.cpp:106] Iteration 2060, lr = 0.0002
I0625 17:49:37.984632  6673 solver.cpp:228] Iteration 2080, loss = 0.59974
I0625 17:49:37.984658  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 17:49:37.984669  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187622 (* 1 = 0.0187622 loss)
I0625 17:49:37.984675  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0774312 (* 1 = 0.0774312 loss)
I0625 17:49:37.984681  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00472825 (* 1 = 0.00472825 loss)
I0625 17:49:37.984688  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110167 (* 1 = 0.0110167 loss)
I0625 17:49:37.984694  6673 sgd_solver.cpp:106] Iteration 2080, lr = 0.0002
I0625 17:51:15.901101  6673 solver.cpp:228] Iteration 2100, loss = 0.460613
I0625 17:51:15.901129  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:51:15.901139  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0018088 (* 1 = 0.0018088 loss)
I0625 17:51:15.901147  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0634263 (* 1 = 0.0634263 loss)
I0625 17:51:15.901154  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00708183 (* 1 = 0.00708183 loss)
I0625 17:51:15.901160  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190452 (* 1 = 0.0190452 loss)
I0625 17:51:15.901166  6673 sgd_solver.cpp:106] Iteration 2100, lr = 0.0002
I0625 17:52:53.836395  6673 solver.cpp:228] Iteration 2120, loss = 0.290146
I0625 17:52:53.836421  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:52:53.836428  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00494734 (* 1 = 0.00494734 loss)
I0625 17:52:53.836432  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0565358 (* 1 = 0.0565358 loss)
I0625 17:52:53.836436  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292896 (* 1 = 0.00292896 loss)
I0625 17:52:53.836441  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224989 (* 1 = 0.0224989 loss)
I0625 17:52:53.836446  6673 sgd_solver.cpp:106] Iteration 2120, lr = 0.0002
I0625 17:54:31.760479  6673 solver.cpp:228] Iteration 2140, loss = 0.250229
I0625 17:54:31.760509  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:54:31.760516  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00124647 (* 1 = 0.00124647 loss)
I0625 17:54:31.760521  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0567637 (* 1 = 0.0567637 loss)
I0625 17:54:31.760525  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00841482 (* 1 = 0.00841482 loss)
I0625 17:54:31.760529  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138431 (* 1 = 0.0138431 loss)
I0625 17:54:31.760535  6673 sgd_solver.cpp:106] Iteration 2140, lr = 0.0002
I0625 17:56:09.676023  6673 solver.cpp:228] Iteration 2160, loss = 0.455089
I0625 17:56:09.676045  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 17:56:09.676053  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.147545 (* 1 = 0.147545 loss)
I0625 17:56:09.676055  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.389446 (* 1 = 0.389446 loss)
I0625 17:56:09.676059  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0320349 (* 1 = 0.0320349 loss)
I0625 17:56:09.676062  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0313681 (* 1 = 0.0313681 loss)
I0625 17:56:09.676067  6673 sgd_solver.cpp:106] Iteration 2160, lr = 0.0002
I0625 17:57:47.606467  6673 solver.cpp:228] Iteration 2180, loss = 0.601392
I0625 17:57:47.606492  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 17:57:47.606500  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0647627 (* 1 = 0.0647627 loss)
I0625 17:57:47.606506  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.236399 (* 1 = 0.236399 loss)
I0625 17:57:47.606511  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151713 (* 1 = 0.0151713 loss)
I0625 17:57:47.606518  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0617218 (* 1 = 0.0617218 loss)
I0625 17:57:47.606523  6673 sgd_solver.cpp:106] Iteration 2180, lr = 0.0002
speed: 4.899s / iter
I0625 17:59:25.542726  6673 solver.cpp:228] Iteration 2200, loss = 0.428686
I0625 17:59:25.542752  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 17:59:25.542760  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00210077 (* 1 = 0.00210077 loss)
I0625 17:59:25.542764  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0619487 (* 1 = 0.0619487 loss)
I0625 17:59:25.542768  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204375 (* 1 = 0.0204375 loss)
I0625 17:59:25.542773  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00557306 (* 1 = 0.00557306 loss)
I0625 17:59:25.542778  6673 sgd_solver.cpp:106] Iteration 2200, lr = 0.0002
I0625 18:01:03.457640  6673 solver.cpp:228] Iteration 2220, loss = 0.282506
I0625 18:01:03.457690  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 18:01:03.457700  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839095 (* 1 = 0.0839095 loss)
I0625 18:01:03.457705  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.169348 (* 1 = 0.169348 loss)
I0625 18:01:03.457708  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.025936 (* 1 = 0.025936 loss)
I0625 18:01:03.457713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157597 (* 1 = 0.0157597 loss)
I0625 18:01:03.457721  6673 sgd_solver.cpp:106] Iteration 2220, lr = 0.0002
I0625 18:02:41.364253  6673 solver.cpp:228] Iteration 2240, loss = 0.541079
I0625 18:02:41.364275  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.460938
I0625 18:02:41.364282  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.454372 (* 1 = 0.454372 loss)
I0625 18:02:41.364286  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.856248 (* 1 = 0.856248 loss)
I0625 18:02:41.364289  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0419688 (* 1 = 0.0419688 loss)
I0625 18:02:41.364292  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109761 (* 1 = 0.109761 loss)
I0625 18:02:41.364297  6673 sgd_solver.cpp:106] Iteration 2240, lr = 0.0002
I0625 18:04:19.285986  6673 solver.cpp:228] Iteration 2260, loss = 0.453067
I0625 18:04:19.286010  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 18:04:19.286020  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00158307 (* 1 = 0.00158307 loss)
I0625 18:04:19.286026  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0571067 (* 1 = 0.0571067 loss)
I0625 18:04:19.286031  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136289 (* 1 = 0.0136289 loss)
I0625 18:04:19.286036  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139148 (* 1 = 0.0139148 loss)
I0625 18:04:19.286041  6673 sgd_solver.cpp:106] Iteration 2260, lr = 0.0002
I0625 18:05:57.186713  6673 solver.cpp:228] Iteration 2280, loss = 0.440605
I0625 18:05:57.186738  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 18:05:57.186745  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.047794 (* 1 = 0.047794 loss)
I0625 18:05:57.186749  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.174436 (* 1 = 0.174436 loss)
I0625 18:05:57.186754  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00597169 (* 1 = 0.00597169 loss)
I0625 18:05:57.186758  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00614152 (* 1 = 0.00614152 loss)
I0625 18:05:57.186761  6673 sgd_solver.cpp:106] Iteration 2280, lr = 0.0002
I0625 18:07:35.120674  6673 solver.cpp:228] Iteration 2300, loss = 0.186353
I0625 18:07:35.120704  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 18:07:35.120712  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331955 (* 1 = 0.0331955 loss)
I0625 18:07:35.120715  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.158777 (* 1 = 0.158777 loss)
I0625 18:07:35.120719  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191756 (* 1 = 0.0191756 loss)
I0625 18:07:35.120723  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218279 (* 1 = 0.0218279 loss)
I0625 18:07:35.120728  6673 sgd_solver.cpp:106] Iteration 2300, lr = 0.0002
I0625 18:09:13.025779  6673 solver.cpp:228] Iteration 2320, loss = 0.563312
I0625 18:09:13.025804  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 18:09:13.025811  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0981562 (* 1 = 0.0981562 loss)
I0625 18:09:13.025815  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.198598 (* 1 = 0.198598 loss)
I0625 18:09:13.025818  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0190776 (* 1 = 0.0190776 loss)
I0625 18:09:13.025821  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024834 (* 1 = 0.024834 loss)
I0625 18:09:13.025826  6673 sgd_solver.cpp:106] Iteration 2320, lr = 0.0002
I0625 18:10:50.901623  6673 solver.cpp:228] Iteration 2340, loss = 0.379383
I0625 18:10:50.901652  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 18:10:50.901660  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195875 (* 1 = 0.0195875 loss)
I0625 18:10:50.901665  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0629495 (* 1 = 0.0629495 loss)
I0625 18:10:50.901669  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00344597 (* 1 = 0.00344597 loss)
I0625 18:10:50.901674  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00695306 (* 1 = 0.00695306 loss)
I0625 18:10:50.901679  6673 sgd_solver.cpp:106] Iteration 2340, lr = 0.0002
I0625 18:12:28.820030  6673 solver.cpp:228] Iteration 2360, loss = 0.484486
I0625 18:12:28.820053  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 18:12:28.820060  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0277748 (* 1 = 0.0277748 loss)
I0625 18:12:28.820065  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0793915 (* 1 = 0.0793915 loss)
I0625 18:12:28.820068  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737687 (* 1 = 0.00737687 loss)
I0625 18:12:28.820071  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0084484 (* 1 = 0.0084484 loss)
I0625 18:12:28.820076  6673 sgd_solver.cpp:106] Iteration 2360, lr = 0.0002
I0625 18:14:06.882925  6673 solver.cpp:228] Iteration 2380, loss = 0.298442
I0625 18:14:06.882954  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 18:14:06.882966  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00218347 (* 1 = 0.00218347 loss)
I0625 18:14:06.882972  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0543675 (* 1 = 0.0543675 loss)
I0625 18:14:06.882977  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00487013 (* 1 = 0.00487013 loss)
I0625 18:14:06.882982  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138334 (* 1 = 0.0138334 loss)
I0625 18:14:06.882989  6673 sgd_solver.cpp:106] Iteration 2380, lr = 0.0002
speed: 4.898s / iter
I0625 18:15:44.817657  6673 solver.cpp:228] Iteration 2400, loss = 0.666901
I0625 18:15:44.817679  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:15:44.817687  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369799 (* 1 = 0.0369799 loss)
I0625 18:15:44.817692  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0805507 (* 1 = 0.0805507 loss)
I0625 18:15:44.817694  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00332558 (* 1 = 0.00332558 loss)
I0625 18:15:44.817698  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00513171 (* 1 = 0.00513171 loss)
I0625 18:15:44.817703  6673 sgd_solver.cpp:106] Iteration 2400, lr = 0.0002
I0625 18:17:22.799371  6673 solver.cpp:228] Iteration 2420, loss = 0.269126
I0625 18:17:22.799397  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 18:17:22.799404  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0478821 (* 1 = 0.0478821 loss)
I0625 18:17:22.799409  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130008 (* 1 = 0.130008 loss)
I0625 18:17:22.799413  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00529416 (* 1 = 0.00529416 loss)
I0625 18:17:22.799417  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119583 (* 1 = 0.0119583 loss)
I0625 18:17:22.799422  6673 sgd_solver.cpp:106] Iteration 2420, lr = 0.0002
I0625 18:19:00.715481  6673 solver.cpp:228] Iteration 2440, loss = 0.235673
I0625 18:19:00.715509  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:19:00.715520  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0382709 (* 1 = 0.0382709 loss)
I0625 18:19:00.715528  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161981 (* 1 = 0.161981 loss)
I0625 18:19:00.715535  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0434747 (* 1 = 0.0434747 loss)
I0625 18:19:00.715543  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0592648 (* 1 = 0.0592648 loss)
I0625 18:19:00.715550  6673 sgd_solver.cpp:106] Iteration 2440, lr = 0.0002
I0625 18:20:38.616808  6673 solver.cpp:228] Iteration 2460, loss = 0.451377
I0625 18:20:38.616833  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 18:20:38.616840  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.143887 (* 1 = 0.143887 loss)
I0625 18:20:38.616844  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.476685 (* 1 = 0.476685 loss)
I0625 18:20:38.616848  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0590918 (* 1 = 0.0590918 loss)
I0625 18:20:38.616852  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.184784 (* 1 = 0.184784 loss)
I0625 18:20:38.616858  6673 sgd_solver.cpp:106] Iteration 2460, lr = 0.0002
I0625 18:22:16.513854  6673 solver.cpp:228] Iteration 2480, loss = 0.238507
I0625 18:22:16.513880  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 18:22:16.513890  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0947041 (* 1 = 0.0947041 loss)
I0625 18:22:16.513895  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.201762 (* 1 = 0.201762 loss)
I0625 18:22:16.513901  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00852835 (* 1 = 0.00852835 loss)
I0625 18:22:16.513907  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163706 (* 1 = 0.0163706 loss)
I0625 18:22:16.513914  6673 sgd_solver.cpp:106] Iteration 2480, lr = 0.0002
I0625 18:23:54.442454  6673 solver.cpp:228] Iteration 2500, loss = 0.48024
I0625 18:23:54.442477  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:23:54.442486  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378118 (* 1 = 0.0378118 loss)
I0625 18:23:54.442492  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0896243 (* 1 = 0.0896243 loss)
I0625 18:23:54.442497  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00670913 (* 1 = 0.00670913 loss)
I0625 18:23:54.442502  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00599805 (* 1 = 0.00599805 loss)
I0625 18:23:54.442508  6673 sgd_solver.cpp:106] Iteration 2500, lr = 0.0002
I0625 18:25:32.335678  6673 solver.cpp:228] Iteration 2520, loss = 0.40744
I0625 18:25:32.335702  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 18:25:32.335710  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0883195 (* 1 = 0.0883195 loss)
I0625 18:25:32.335714  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.188297 (* 1 = 0.188297 loss)
I0625 18:25:32.335718  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00821548 (* 1 = 0.00821548 loss)
I0625 18:25:32.335721  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128064 (* 1 = 0.0128064 loss)
I0625 18:25:32.335726  6673 sgd_solver.cpp:106] Iteration 2520, lr = 0.0002
I0625 18:27:10.266755  6673 solver.cpp:228] Iteration 2540, loss = 0.201756
I0625 18:27:10.266782  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:27:10.266789  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460789 (* 1 = 0.0460789 loss)
I0625 18:27:10.266793  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.145157 (* 1 = 0.145157 loss)
I0625 18:27:10.266798  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110847 (* 1 = 0.0110847 loss)
I0625 18:27:10.266801  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0513703 (* 1 = 0.0513703 loss)
I0625 18:27:10.266805  6673 sgd_solver.cpp:106] Iteration 2540, lr = 0.0002
I0625 18:28:48.157529  6673 solver.cpp:228] Iteration 2560, loss = 0.349392
I0625 18:28:48.157553  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:28:48.157562  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0344757 (* 1 = 0.0344757 loss)
I0625 18:28:48.157565  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.145977 (* 1 = 0.145977 loss)
I0625 18:28:48.157568  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0076995 (* 1 = 0.0076995 loss)
I0625 18:28:48.157572  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00907471 (* 1 = 0.00907471 loss)
I0625 18:28:48.157577  6673 sgd_solver.cpp:106] Iteration 2560, lr = 0.0002
I0625 18:30:26.116701  6673 solver.cpp:228] Iteration 2580, loss = 0.445061
I0625 18:30:26.116725  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:30:26.116732  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.111646 (* 1 = 0.111646 loss)
I0625 18:30:26.116736  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130749 (* 1 = 0.130749 loss)
I0625 18:30:26.116739  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104942 (* 1 = 0.0104942 loss)
I0625 18:30:26.116744  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180603 (* 1 = 0.0180603 loss)
I0625 18:30:26.116747  6673 sgd_solver.cpp:106] Iteration 2580, lr = 0.0002
speed: 4.898s / iter
I0625 18:32:04.005709  6673 solver.cpp:228] Iteration 2600, loss = 0.286613
I0625 18:32:04.005738  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:32:04.005744  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407998 (* 1 = 0.0407998 loss)
I0625 18:32:04.005748  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0564617 (* 1 = 0.0564617 loss)
I0625 18:32:04.005753  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00477596 (* 1 = 0.00477596 loss)
I0625 18:32:04.005755  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00529088 (* 1 = 0.00529088 loss)
I0625 18:32:04.005760  6673 sgd_solver.cpp:106] Iteration 2600, lr = 0.0002
I0625 18:33:41.882107  6673 solver.cpp:228] Iteration 2620, loss = 0.499388
I0625 18:33:41.882134  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 18:33:41.882140  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.102555 (* 1 = 0.102555 loss)
I0625 18:33:41.882144  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.25624 (* 1 = 0.25624 loss)
I0625 18:33:41.882148  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145997 (* 1 = 0.0145997 loss)
I0625 18:33:41.882150  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207079 (* 1 = 0.0207079 loss)
I0625 18:33:41.882155  6673 sgd_solver.cpp:106] Iteration 2620, lr = 0.0002
I0625 18:35:19.744793  6673 solver.cpp:228] Iteration 2640, loss = 0.39354
I0625 18:35:19.744818  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 18:35:19.744825  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.109611 (* 1 = 0.109611 loss)
I0625 18:35:19.744829  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.327854 (* 1 = 0.327854 loss)
I0625 18:35:19.744833  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119062 (* 1 = 0.0119062 loss)
I0625 18:35:19.744837  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012574 (* 1 = 0.012574 loss)
I0625 18:35:19.744843  6673 sgd_solver.cpp:106] Iteration 2640, lr = 0.0002
I0625 18:36:57.675338  6673 solver.cpp:228] Iteration 2660, loss = 0.433756
I0625 18:36:57.675361  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 18:36:57.675369  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0729785 (* 1 = 0.0729785 loss)
I0625 18:36:57.675372  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.170272 (* 1 = 0.170272 loss)
I0625 18:36:57.675375  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398571 (* 1 = 0.00398571 loss)
I0625 18:36:57.675379  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257487 (* 1 = 0.0257487 loss)
I0625 18:36:57.675384  6673 sgd_solver.cpp:106] Iteration 2660, lr = 0.0002
I0625 18:38:35.589043  6673 solver.cpp:228] Iteration 2680, loss = 0.246348
I0625 18:38:35.589071  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 18:38:35.589078  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.108512 (* 1 = 0.108512 loss)
I0625 18:38:35.589082  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.195712 (* 1 = 0.195712 loss)
I0625 18:38:35.589087  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00652684 (* 1 = 0.00652684 loss)
I0625 18:38:35.589092  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247641 (* 1 = 0.0247641 loss)
I0625 18:38:35.589097  6673 sgd_solver.cpp:106] Iteration 2680, lr = 0.0002
I0625 18:40:13.512357  6673 solver.cpp:228] Iteration 2700, loss = 0.357982
I0625 18:40:13.512383  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:40:13.512392  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.079512 (* 1 = 0.079512 loss)
I0625 18:40:13.512398  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.183499 (* 1 = 0.183499 loss)
I0625 18:40:13.512403  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152119 (* 1 = 0.0152119 loss)
I0625 18:40:13.512408  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125064 (* 1 = 0.0125064 loss)
I0625 18:40:13.512415  6673 sgd_solver.cpp:106] Iteration 2700, lr = 0.0002
I0625 18:41:51.424787  6673 solver.cpp:228] Iteration 2720, loss = 0.23942
I0625 18:41:51.424809  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:41:51.424818  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0658831 (* 1 = 0.0658831 loss)
I0625 18:41:51.424824  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.230215 (* 1 = 0.230215 loss)
I0625 18:41:51.424829  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212776 (* 1 = 0.0212776 loss)
I0625 18:41:51.424834  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161665 (* 1 = 0.0161665 loss)
I0625 18:41:51.424840  6673 sgd_solver.cpp:106] Iteration 2720, lr = 0.0002
I0625 18:43:29.339360  6673 solver.cpp:228] Iteration 2740, loss = 0.277069
I0625 18:43:29.339387  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 18:43:29.339397  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174952 (* 1 = 0.0174952 loss)
I0625 18:43:29.339404  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0869852 (* 1 = 0.0869852 loss)
I0625 18:43:29.339411  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00733903 (* 1 = 0.00733903 loss)
I0625 18:43:29.339417  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129769 (* 1 = 0.0129769 loss)
I0625 18:43:29.339423  6673 sgd_solver.cpp:106] Iteration 2740, lr = 0.0002
I0625 18:45:07.253006  6673 solver.cpp:228] Iteration 2760, loss = 0.534008
I0625 18:45:07.253031  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 18:45:07.253038  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.139704 (* 1 = 0.139704 loss)
I0625 18:45:07.253042  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.258517 (* 1 = 0.258517 loss)
I0625 18:45:07.253046  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817212 (* 1 = 0.00817212 loss)
I0625 18:45:07.253049  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.04628 (* 1 = 0.04628 loss)
I0625 18:45:07.253053  6673 sgd_solver.cpp:106] Iteration 2760, lr = 0.0002
I0625 18:46:45.166484  6673 solver.cpp:228] Iteration 2780, loss = 0.308741
I0625 18:46:45.166508  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 18:46:45.166517  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498031 (* 1 = 0.0498031 loss)
I0625 18:46:45.166519  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.164254 (* 1 = 0.164254 loss)
I0625 18:46:45.166523  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121941 (* 1 = 0.0121941 loss)
I0625 18:46:45.166527  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0505564 (* 1 = 0.0505564 loss)
I0625 18:46:45.166532  6673 sgd_solver.cpp:106] Iteration 2780, lr = 0.0002
speed: 4.898s / iter
I0625 18:48:23.123842  6673 solver.cpp:228] Iteration 2800, loss = 0.583871
I0625 18:48:23.123867  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 18:48:23.123878  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.16352 (* 1 = 0.16352 loss)
I0625 18:48:23.123883  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.307133 (* 1 = 0.307133 loss)
I0625 18:48:23.123888  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198703 (* 1 = 0.0198703 loss)
I0625 18:48:23.123893  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0588527 (* 1 = 0.0588527 loss)
I0625 18:48:23.123899  6673 sgd_solver.cpp:106] Iteration 2800, lr = 0.0002
I0625 18:50:01.050966  6673 solver.cpp:228] Iteration 2820, loss = 0.461158
I0625 18:50:01.050993  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0625 18:50:01.051000  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.231684 (* 1 = 0.231684 loss)
I0625 18:50:01.051004  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.496717 (* 1 = 0.496717 loss)
I0625 18:50:01.051008  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00746769 (* 1 = 0.00746769 loss)
I0625 18:50:01.051012  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0598536 (* 1 = 0.0598536 loss)
I0625 18:50:01.051017  6673 sgd_solver.cpp:106] Iteration 2820, lr = 0.0002
I0625 18:51:38.956913  6673 solver.cpp:228] Iteration 2840, loss = 0.352145
I0625 18:51:38.956938  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 18:51:38.956944  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.158152 (* 1 = 0.158152 loss)
I0625 18:51:38.956948  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.343915 (* 1 = 0.343915 loss)
I0625 18:51:38.956953  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00830614 (* 1 = 0.00830614 loss)
I0625 18:51:38.956956  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329853 (* 1 = 0.0329853 loss)
I0625 18:51:38.956961  6673 sgd_solver.cpp:106] Iteration 2840, lr = 0.0002
I0625 18:53:16.840131  6673 solver.cpp:228] Iteration 2860, loss = 0.462204
I0625 18:53:16.840155  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 18:53:16.840162  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0917606 (* 1 = 0.0917606 loss)
I0625 18:53:16.840167  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.165641 (* 1 = 0.165641 loss)
I0625 18:53:16.840169  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00635856 (* 1 = 0.00635856 loss)
I0625 18:53:16.840173  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261739 (* 1 = 0.0261739 loss)
I0625 18:53:16.840178  6673 sgd_solver.cpp:106] Iteration 2860, lr = 0.0002
I0625 18:54:54.730028  6673 solver.cpp:228] Iteration 2880, loss = 0.35584
I0625 18:54:54.730057  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 18:54:54.730065  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.036286 (* 1 = 0.036286 loss)
I0625 18:54:54.730069  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122486 (* 1 = 0.122486 loss)
I0625 18:54:54.730073  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193689 (* 1 = 0.00193689 loss)
I0625 18:54:54.730078  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017461 (* 1 = 0.017461 loss)
I0625 18:54:54.730084  6673 sgd_solver.cpp:106] Iteration 2880, lr = 0.0002
I0625 18:56:32.604185  6673 solver.cpp:228] Iteration 2900, loss = 0.79432
I0625 18:56:32.604210  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 18:56:32.604218  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.169173 (* 1 = 0.169173 loss)
I0625 18:56:32.604221  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.382039 (* 1 = 0.382039 loss)
I0625 18:56:32.604224  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101225 (* 1 = 0.0101225 loss)
I0625 18:56:32.604228  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0417479 (* 1 = 0.0417479 loss)
I0625 18:56:32.604233  6673 sgd_solver.cpp:106] Iteration 2900, lr = 0.0002
I0625 18:58:10.413000  6673 solver.cpp:228] Iteration 2920, loss = 0.625215
I0625 18:58:10.413025  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0625 18:58:10.413033  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.279956 (* 1 = 0.279956 loss)
I0625 18:58:10.413038  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.596239 (* 1 = 0.596239 loss)
I0625 18:58:10.413041  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0571873 (* 1 = 0.0571873 loss)
I0625 18:58:10.413044  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.196815 (* 1 = 0.196815 loss)
I0625 18:58:10.413049  6673 sgd_solver.cpp:106] Iteration 2920, lr = 0.0002
I0625 18:59:48.348395  6673 solver.cpp:228] Iteration 2940, loss = 0.464285
I0625 18:59:48.348421  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 18:59:48.348428  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.107337 (* 1 = 0.107337 loss)
I0625 18:59:48.348433  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.31302 (* 1 = 0.31302 loss)
I0625 18:59:48.348436  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0084766 (* 1 = 0.0084766 loss)
I0625 18:59:48.348440  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00953634 (* 1 = 0.00953634 loss)
I0625 18:59:48.348445  6673 sgd_solver.cpp:106] Iteration 2940, lr = 0.0002
I0625 19:01:26.240012  6673 solver.cpp:228] Iteration 2960, loss = 0.507139
I0625 19:01:26.240037  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 19:01:26.240046  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.129851 (* 1 = 0.129851 loss)
I0625 19:01:26.240049  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.346094 (* 1 = 0.346094 loss)
I0625 19:01:26.240053  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165594 (* 1 = 0.0165594 loss)
I0625 19:01:26.240056  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210175 (* 1 = 0.0210175 loss)
I0625 19:01:26.240061  6673 sgd_solver.cpp:106] Iteration 2960, lr = 0.0002
I0625 19:03:04.164192  6673 solver.cpp:228] Iteration 2980, loss = 0.583285
I0625 19:03:04.164217  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 19:03:04.164225  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134361 (* 1 = 0.134361 loss)
I0625 19:03:04.164230  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.339445 (* 1 = 0.339445 loss)
I0625 19:03:04.164234  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0318107 (* 1 = 0.0318107 loss)
I0625 19:03:04.164237  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0921225 (* 1 = 0.0921225 loss)
I0625 19:03:04.164242  6673 sgd_solver.cpp:106] Iteration 2980, lr = 0.0002
speed: 4.898s / iter
I0625 19:04:42.059845  6673 solver.cpp:228] Iteration 3000, loss = 0.313078
I0625 19:04:42.059875  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 19:04:42.059882  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.113137 (* 1 = 0.113137 loss)
I0625 19:04:42.059887  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.137061 (* 1 = 0.137061 loss)
I0625 19:04:42.059892  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208561 (* 1 = 0.00208561 loss)
I0625 19:04:42.059897  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118197 (* 1 = 0.0118197 loss)
I0625 19:04:42.059903  6673 sgd_solver.cpp:106] Iteration 3000, lr = 0.0002
I0625 19:06:19.969539  6673 solver.cpp:228] Iteration 3020, loss = 0.372266
I0625 19:06:19.969564  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 19:06:19.969571  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.198691 (* 1 = 0.198691 loss)
I0625 19:06:19.969575  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.4418 (* 1 = 0.4418 loss)
I0625 19:06:19.969578  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015884 (* 1 = 0.015884 loss)
I0625 19:06:19.969583  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049951 (* 1 = 0.049951 loss)
I0625 19:06:19.969588  6673 sgd_solver.cpp:106] Iteration 3020, lr = 0.0002
I0625 19:07:57.825477  6673 solver.cpp:228] Iteration 3040, loss = 0.293777
I0625 19:07:57.825500  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 19:07:57.825506  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.124132 (* 1 = 0.124132 loss)
I0625 19:07:57.825510  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.241761 (* 1 = 0.241761 loss)
I0625 19:07:57.825513  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00688327 (* 1 = 0.00688327 loss)
I0625 19:07:57.825517  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135641 (* 1 = 0.0135641 loss)
I0625 19:07:57.825521  6673 sgd_solver.cpp:106] Iteration 3040, lr = 0.0002
I0625 19:09:35.663339  6673 solver.cpp:228] Iteration 3060, loss = 0.359125
I0625 19:09:35.663363  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0625 19:09:35.663370  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.300344 (* 1 = 0.300344 loss)
I0625 19:09:35.663375  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.715584 (* 1 = 0.715584 loss)
I0625 19:09:35.663379  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174004 (* 1 = 0.0174004 loss)
I0625 19:09:35.663383  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0669032 (* 1 = 0.0669032 loss)
I0625 19:09:35.663386  6673 sgd_solver.cpp:106] Iteration 3060, lr = 0.0002
I0625 19:11:13.567162  6673 solver.cpp:228] Iteration 3080, loss = 0.274174
I0625 19:11:13.567188  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:11:13.567198  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144906 (* 1 = 0.0144906 loss)
I0625 19:11:13.567204  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.126437 (* 1 = 0.126437 loss)
I0625 19:11:13.567209  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00618558 (* 1 = 0.00618558 loss)
I0625 19:11:13.567215  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00790225 (* 1 = 0.00790225 loss)
I0625 19:11:13.567220  6673 sgd_solver.cpp:106] Iteration 3080, lr = 0.0002
I0625 19:12:51.419328  6673 solver.cpp:228] Iteration 3100, loss = 0.464974
I0625 19:12:51.419351  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 19:12:51.419358  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0641083 (* 1 = 0.0641083 loss)
I0625 19:12:51.419361  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100852 (* 1 = 0.100852 loss)
I0625 19:12:51.419364  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154556 (* 1 = 0.00154556 loss)
I0625 19:12:51.419368  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151717 (* 1 = 0.0151717 loss)
I0625 19:12:51.419373  6673 sgd_solver.cpp:106] Iteration 3100, lr = 0.0002
I0625 19:14:29.338111  6673 solver.cpp:228] Iteration 3120, loss = 0.29146
I0625 19:14:29.338135  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 19:14:29.338142  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000330376 (* 1 = 0.000330376 loss)
I0625 19:14:29.338146  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0346859 (* 1 = 0.0346859 loss)
I0625 19:14:29.338150  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167084 (* 1 = 0.0167084 loss)
I0625 19:14:29.338153  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275702 (* 1 = 0.0275702 loss)
I0625 19:14:29.338157  6673 sgd_solver.cpp:106] Iteration 3120, lr = 0.0002
I0625 19:16:07.244129  6673 solver.cpp:228] Iteration 3140, loss = 0.292284
I0625 19:16:07.244153  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:16:07.244161  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0164101 (* 1 = 0.0164101 loss)
I0625 19:16:07.244166  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.064197 (* 1 = 0.064197 loss)
I0625 19:16:07.244170  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296698 (* 1 = 0.00296698 loss)
I0625 19:16:07.244174  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310077 (* 1 = 0.0310077 loss)
I0625 19:16:07.244179  6673 sgd_solver.cpp:106] Iteration 3140, lr = 0.0002
I0625 19:17:45.127058  6673 solver.cpp:228] Iteration 3160, loss = 0.226219
I0625 19:17:45.127085  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:17:45.127095  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220593 (* 1 = 0.0220593 loss)
I0625 19:17:45.127101  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.146461 (* 1 = 0.146461 loss)
I0625 19:17:45.127107  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00512824 (* 1 = 0.00512824 loss)
I0625 19:17:45.127113  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139933 (* 1 = 0.0139933 loss)
I0625 19:17:45.127120  6673 sgd_solver.cpp:106] Iteration 3160, lr = 0.0002
I0625 19:19:23.022603  6673 solver.cpp:228] Iteration 3180, loss = 0.352881
I0625 19:19:23.022626  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 19:19:23.022634  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.074966 (* 1 = 0.074966 loss)
I0625 19:19:23.022637  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.164707 (* 1 = 0.164707 loss)
I0625 19:19:23.022640  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00683575 (* 1 = 0.00683575 loss)
I0625 19:19:23.022644  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010096 (* 1 = 0.010096 loss)
I0625 19:19:23.022650  6673 sgd_solver.cpp:106] Iteration 3180, lr = 0.0002
speed: 4.898s / iter
I0625 19:21:00.902410  6673 solver.cpp:228] Iteration 3200, loss = 0.175974
I0625 19:21:00.902434  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:21:00.902441  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.013438 (* 1 = 0.013438 loss)
I0625 19:21:00.902446  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.120588 (* 1 = 0.120588 loss)
I0625 19:21:00.902448  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00732111 (* 1 = 0.00732111 loss)
I0625 19:21:00.902452  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267153 (* 1 = 0.0267153 loss)
I0625 19:21:00.902456  6673 sgd_solver.cpp:106] Iteration 3200, lr = 0.0002
I0625 19:22:38.779793  6673 solver.cpp:228] Iteration 3220, loss = 0.511092
I0625 19:22:38.779815  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 19:22:38.779822  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393387 (* 1 = 0.0393387 loss)
I0625 19:22:38.779827  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.123098 (* 1 = 0.123098 loss)
I0625 19:22:38.779830  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0784757 (* 1 = 0.0784757 loss)
I0625 19:22:38.779834  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0884978 (* 1 = 0.0884978 loss)
I0625 19:22:38.779839  6673 sgd_solver.cpp:106] Iteration 3220, lr = 0.0002
I0625 19:24:16.720890  6673 solver.cpp:228] Iteration 3240, loss = 0.371586
I0625 19:24:16.720913  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 19:24:16.720921  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142769 (* 1 = 0.0142769 loss)
I0625 19:24:16.720924  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106187 (* 1 = 0.106187 loss)
I0625 19:24:16.720928  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00391918 (* 1 = 0.00391918 loss)
I0625 19:24:16.720932  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00783991 (* 1 = 0.00783991 loss)
I0625 19:24:16.720935  6673 sgd_solver.cpp:106] Iteration 3240, lr = 0.0002
I0625 19:25:54.624469  6673 solver.cpp:228] Iteration 3260, loss = 0.473805
I0625 19:25:54.624495  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 19:25:54.624505  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0489417 (* 1 = 0.0489417 loss)
I0625 19:25:54.624511  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0700817 (* 1 = 0.0700817 loss)
I0625 19:25:54.624516  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237842 (* 1 = 0.00237842 loss)
I0625 19:25:54.624523  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120332 (* 1 = 0.0120332 loss)
I0625 19:25:54.624529  6673 sgd_solver.cpp:106] Iteration 3260, lr = 0.0002
I0625 19:27:32.547035  6673 solver.cpp:228] Iteration 3280, loss = 0.228786
I0625 19:27:32.547060  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 19:27:32.547067  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0648922 (* 1 = 0.0648922 loss)
I0625 19:27:32.547071  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.127092 (* 1 = 0.127092 loss)
I0625 19:27:32.547075  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114819 (* 1 = 0.0114819 loss)
I0625 19:27:32.547078  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00897687 (* 1 = 0.00897687 loss)
I0625 19:27:32.547083  6673 sgd_solver.cpp:106] Iteration 3280, lr = 0.0002
I0625 19:29:10.472990  6673 solver.cpp:228] Iteration 3300, loss = 0.292786
I0625 19:29:10.473018  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 19:29:10.473026  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276986 (* 1 = 0.0276986 loss)
I0625 19:29:10.473029  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109786 (* 1 = 0.109786 loss)
I0625 19:29:10.473033  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169954 (* 1 = 0.00169954 loss)
I0625 19:29:10.473037  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163804 (* 1 = 0.0163804 loss)
I0625 19:29:10.473042  6673 sgd_solver.cpp:106] Iteration 3300, lr = 0.0002
I0625 19:30:48.340003  6673 solver.cpp:228] Iteration 3320, loss = 0.487168
I0625 19:30:48.340028  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 19:30:48.340034  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105172 (* 1 = 0.105172 loss)
I0625 19:30:48.340037  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.274323 (* 1 = 0.274323 loss)
I0625 19:30:48.340041  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00901902 (* 1 = 0.00901902 loss)
I0625 19:30:48.340045  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00781184 (* 1 = 0.00781184 loss)
I0625 19:30:48.340049  6673 sgd_solver.cpp:106] Iteration 3320, lr = 0.0002
I0625 19:32:26.221781  6673 solver.cpp:228] Iteration 3340, loss = 0.242786
I0625 19:32:26.221808  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 19:32:26.221817  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0683791 (* 1 = 0.0683791 loss)
I0625 19:32:26.221824  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.199666 (* 1 = 0.199666 loss)
I0625 19:32:26.221830  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00821025 (* 1 = 0.00821025 loss)
I0625 19:32:26.221837  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0489746 (* 1 = 0.0489746 loss)
I0625 19:32:26.221843  6673 sgd_solver.cpp:106] Iteration 3340, lr = 0.0002
I0625 19:34:04.379694  6673 solver.cpp:228] Iteration 3360, loss = 0.366489
I0625 19:34:04.379721  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 19:34:04.379729  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189438 (* 1 = 0.0189438 loss)
I0625 19:34:04.379734  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0685333 (* 1 = 0.0685333 loss)
I0625 19:34:04.379739  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00357074 (* 1 = 0.00357074 loss)
I0625 19:34:04.379741  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00355837 (* 1 = 0.00355837 loss)
I0625 19:34:04.379747  6673 sgd_solver.cpp:106] Iteration 3360, lr = 0.0002
I0625 19:35:42.524129  6673 solver.cpp:228] Iteration 3380, loss = 0.293344
I0625 19:35:42.524154  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 19:35:42.524163  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0706425 (* 1 = 0.0706425 loss)
I0625 19:35:42.524168  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.226454 (* 1 = 0.226454 loss)
I0625 19:35:42.524170  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147843 (* 1 = 0.0147843 loss)
I0625 19:35:42.524174  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342998 (* 1 = 0.0342998 loss)
I0625 19:35:42.524179  6673 sgd_solver.cpp:106] Iteration 3380, lr = 0.0002
speed: 4.898s / iter
I0625 19:37:20.598438  6673 solver.cpp:228] Iteration 3400, loss = 0.220249
I0625 19:37:20.598466  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 19:37:20.598474  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.126367 (* 1 = 0.126367 loss)
I0625 19:37:20.598477  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.306714 (* 1 = 0.306714 loss)
I0625 19:37:20.598481  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0411169 (* 1 = 0.0411169 loss)
I0625 19:37:20.598485  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229032 (* 1 = 0.0229032 loss)
I0625 19:37:20.598490  6673 sgd_solver.cpp:106] Iteration 3400, lr = 0.0002
I0625 19:38:58.658628  6673 solver.cpp:228] Iteration 3420, loss = 0.32276
I0625 19:38:58.658653  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 19:38:58.658660  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323093 (* 1 = 0.0323093 loss)
I0625 19:38:58.658664  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0887572 (* 1 = 0.0887572 loss)
I0625 19:38:58.658668  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00345792 (* 1 = 0.00345792 loss)
I0625 19:38:58.658671  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134183 (* 1 = 0.0134183 loss)
I0625 19:38:58.658676  6673 sgd_solver.cpp:106] Iteration 3420, lr = 0.0002
I0625 19:40:36.898545  6673 solver.cpp:228] Iteration 3440, loss = 0.360681
I0625 19:40:36.898569  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 19:40:36.898577  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.117551 (* 1 = 0.117551 loss)
I0625 19:40:36.898581  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.162995 (* 1 = 0.162995 loss)
I0625 19:40:36.898584  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00117568 (* 1 = 0.00117568 loss)
I0625 19:40:36.898588  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00646405 (* 1 = 0.00646405 loss)
I0625 19:40:36.898592  6673 sgd_solver.cpp:106] Iteration 3440, lr = 0.0002
I0625 19:42:14.986764  6673 solver.cpp:228] Iteration 3460, loss = 0.296641
I0625 19:42:14.986790  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 19:42:14.986798  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0726704 (* 1 = 0.0726704 loss)
I0625 19:42:14.986804  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.111177 (* 1 = 0.111177 loss)
I0625 19:42:14.986809  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361838 (* 1 = 0.00361838 loss)
I0625 19:42:14.986815  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00482935 (* 1 = 0.00482935 loss)
I0625 19:42:14.986820  6673 sgd_solver.cpp:106] Iteration 3460, lr = 0.0002
I0625 19:43:53.043411  6673 solver.cpp:228] Iteration 3480, loss = 0.408796
I0625 19:43:53.043435  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 19:43:53.043443  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0545984 (* 1 = 0.0545984 loss)
I0625 19:43:53.043447  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.110199 (* 1 = 0.110199 loss)
I0625 19:43:53.043452  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00308898 (* 1 = 0.00308898 loss)
I0625 19:43:53.043455  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00882363 (* 1 = 0.00882363 loss)
I0625 19:43:53.043460  6673 sgd_solver.cpp:106] Iteration 3480, lr = 0.0002
I0625 19:45:31.070840  6673 solver.cpp:228] Iteration 3500, loss = 0.380701
I0625 19:45:31.070868  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 19:45:31.070874  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.171343 (* 1 = 0.171343 loss)
I0625 19:45:31.070878  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.377399 (* 1 = 0.377399 loss)
I0625 19:45:31.070881  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116873 (* 1 = 0.0116873 loss)
I0625 19:45:31.070884  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451674 (* 1 = 0.0451674 loss)
I0625 19:45:31.070889  6673 sgd_solver.cpp:106] Iteration 3500, lr = 0.0002
I0625 19:47:09.130281  6673 solver.cpp:228] Iteration 3520, loss = 0.294207
I0625 19:47:09.130304  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 19:47:09.130311  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.178083 (* 1 = 0.178083 loss)
I0625 19:47:09.130316  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.21658 (* 1 = 0.21658 loss)
I0625 19:47:09.130318  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00851215 (* 1 = 0.00851215 loss)
I0625 19:47:09.130322  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0385231 (* 1 = 0.0385231 loss)
I0625 19:47:09.130326  6673 sgd_solver.cpp:106] Iteration 3520, lr = 0.0002
I0625 19:48:47.379145  6673 solver.cpp:228] Iteration 3540, loss = 0.255989
I0625 19:48:47.379170  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 19:48:47.379178  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0971647 (* 1 = 0.0971647 loss)
I0625 19:48:47.379182  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.208392 (* 1 = 0.208392 loss)
I0625 19:48:47.379186  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00480596 (* 1 = 0.00480596 loss)
I0625 19:48:47.379189  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148736 (* 1 = 0.0148736 loss)
I0625 19:48:47.379194  6673 sgd_solver.cpp:106] Iteration 3540, lr = 0.0002
I0625 19:50:25.443857  6673 solver.cpp:228] Iteration 3560, loss = 0.206976
I0625 19:50:25.443882  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 19:50:25.443889  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0545559 (* 1 = 0.0545559 loss)
I0625 19:50:25.443893  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.111401 (* 1 = 0.111401 loss)
I0625 19:50:25.443898  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300869 (* 1 = 0.00300869 loss)
I0625 19:50:25.443902  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112299 (* 1 = 0.0112299 loss)
I0625 19:50:25.443907  6673 sgd_solver.cpp:106] Iteration 3560, lr = 0.0002
I0625 19:52:03.471734  6673 solver.cpp:228] Iteration 3580, loss = 0.328241
I0625 19:52:03.471760  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 19:52:03.471768  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.260475 (* 1 = 0.260475 loss)
I0625 19:52:03.471772  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.427549 (* 1 = 0.427549 loss)
I0625 19:52:03.471776  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131821 (* 1 = 0.0131821 loss)
I0625 19:52:03.471779  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438604 (* 1 = 0.0438604 loss)
I0625 19:52:03.471784  6673 sgd_solver.cpp:106] Iteration 3580, lr = 0.0002
speed: 4.898s / iter
I0625 19:53:41.453166  6673 solver.cpp:228] Iteration 3600, loss = 0.504689
I0625 19:53:41.453189  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 19:53:41.453197  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.15498 (* 1 = 0.15498 loss)
I0625 19:53:41.453202  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.244791 (* 1 = 0.244791 loss)
I0625 19:53:41.453207  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194701 (* 1 = 0.00194701 loss)
I0625 19:53:41.453212  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116019 (* 1 = 0.0116019 loss)
I0625 19:53:41.453217  6673 sgd_solver.cpp:106] Iteration 3600, lr = 0.0002
I0625 19:55:19.392514  6673 solver.cpp:228] Iteration 3620, loss = 0.266151
I0625 19:55:19.392540  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 19:55:19.392549  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392643 (* 1 = 0.0392643 loss)
I0625 19:55:19.392552  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.23019 (* 1 = 0.23019 loss)
I0625 19:55:19.392556  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00675991 (* 1 = 0.00675991 loss)
I0625 19:55:19.392560  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00294608 (* 1 = 0.00294608 loss)
I0625 19:55:19.392565  6673 sgd_solver.cpp:106] Iteration 3620, lr = 0.0002
I0625 19:56:57.344415  6673 solver.cpp:228] Iteration 3640, loss = 0.3394
I0625 19:56:57.344439  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 19:56:57.344447  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.019964 (* 1 = 0.019964 loss)
I0625 19:56:57.344451  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0565599 (* 1 = 0.0565599 loss)
I0625 19:56:57.344455  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0051028 (* 1 = 0.0051028 loss)
I0625 19:56:57.344460  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130493 (* 1 = 0.0130493 loss)
I0625 19:56:57.344465  6673 sgd_solver.cpp:106] Iteration 3640, lr = 0.0002
I0625 19:58:35.253454  6673 solver.cpp:228] Iteration 3660, loss = 0.436903
I0625 19:58:35.253479  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 19:58:35.253486  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.186458 (* 1 = 0.186458 loss)
I0625 19:58:35.253490  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.320135 (* 1 = 0.320135 loss)
I0625 19:58:35.253494  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00864067 (* 1 = 0.00864067 loss)
I0625 19:58:35.253497  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0483329 (* 1 = 0.0483329 loss)
I0625 19:58:35.253501  6673 sgd_solver.cpp:106] Iteration 3660, lr = 0.0002
I0625 20:00:13.181110  6673 solver.cpp:228] Iteration 3680, loss = 0.52998
I0625 20:00:13.181136  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 20:00:13.181144  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.186565 (* 1 = 0.186565 loss)
I0625 20:00:13.181150  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.309588 (* 1 = 0.309588 loss)
I0625 20:00:13.181155  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116843 (* 1 = 0.0116843 loss)
I0625 20:00:13.181159  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020306 (* 1 = 0.020306 loss)
I0625 20:00:13.181165  6673 sgd_solver.cpp:106] Iteration 3680, lr = 0.0002
I0625 20:01:51.113510  6673 solver.cpp:228] Iteration 3700, loss = 0.30649
I0625 20:01:51.113535  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0625 20:01:51.113543  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.232634 (* 1 = 0.232634 loss)
I0625 20:01:51.113545  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.454006 (* 1 = 0.454006 loss)
I0625 20:01:51.113549  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213132 (* 1 = 0.0213132 loss)
I0625 20:01:51.113553  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0751918 (* 1 = 0.0751918 loss)
I0625 20:01:51.113557  6673 sgd_solver.cpp:106] Iteration 3700, lr = 0.0002
I0625 20:03:29.073267  6673 solver.cpp:228] Iteration 3720, loss = 0.402735
I0625 20:03:29.073290  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 20:03:29.073297  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.120498 (* 1 = 0.120498 loss)
I0625 20:03:29.073300  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.40067 (* 1 = 0.40067 loss)
I0625 20:03:29.073304  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0371554 (* 1 = 0.0371554 loss)
I0625 20:03:29.073307  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0607528 (* 1 = 0.0607528 loss)
I0625 20:03:29.073312  6673 sgd_solver.cpp:106] Iteration 3720, lr = 0.0002
I0625 20:05:07.039068  6673 solver.cpp:228] Iteration 3740, loss = 0.404722
I0625 20:05:07.039093  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 20:05:07.039100  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128964 (* 1 = 0.0128964 loss)
I0625 20:05:07.039104  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0593252 (* 1 = 0.0593252 loss)
I0625 20:05:07.039108  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00513153 (* 1 = 0.00513153 loss)
I0625 20:05:07.039111  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00677421 (* 1 = 0.00677421 loss)
I0625 20:05:07.039115  6673 sgd_solver.cpp:106] Iteration 3740, lr = 0.0002
I0625 20:06:45.027539  6673 solver.cpp:228] Iteration 3760, loss = 0.211526
I0625 20:06:45.027565  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:06:45.027571  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309687 (* 1 = 0.0309687 loss)
I0625 20:06:45.027576  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0851799 (* 1 = 0.0851799 loss)
I0625 20:06:45.027580  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035274 (* 1 = 0.0035274 loss)
I0625 20:06:45.027585  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00348806 (* 1 = 0.00348806 loss)
I0625 20:06:45.027588  6673 sgd_solver.cpp:106] Iteration 3760, lr = 0.0002
I0625 20:08:23.004932  6673 solver.cpp:228] Iteration 3780, loss = 0.484225
I0625 20:08:23.004963  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 20:08:23.004974  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.068281 (* 1 = 0.068281 loss)
I0625 20:08:23.004981  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.366444 (* 1 = 0.366444 loss)
I0625 20:08:23.004987  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0586098 (* 1 = 0.0586098 loss)
I0625 20:08:23.004992  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.175827 (* 1 = 0.175827 loss)
I0625 20:08:23.005002  6673 sgd_solver.cpp:106] Iteration 3780, lr = 0.0002
speed: 4.898s / iter
I0625 20:10:01.084578  6673 solver.cpp:228] Iteration 3800, loss = 0.27818
I0625 20:10:01.084609  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 20:10:01.084617  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105753 (* 1 = 0.105753 loss)
I0625 20:10:01.084622  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.184644 (* 1 = 0.184644 loss)
I0625 20:10:01.084626  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132492 (* 1 = 0.0132492 loss)
I0625 20:10:01.084631  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124088 (* 1 = 0.0124088 loss)
I0625 20:10:01.084636  6673 sgd_solver.cpp:106] Iteration 3800, lr = 0.0002
I0625 20:11:39.059790  6673 solver.cpp:228] Iteration 3820, loss = 0.550726
I0625 20:11:39.059814  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 20:11:39.059821  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.1083 (* 1 = 0.1083 loss)
I0625 20:11:39.059825  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.24574 (* 1 = 0.24574 loss)
I0625 20:11:39.059829  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103165 (* 1 = 0.0103165 loss)
I0625 20:11:39.059833  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237881 (* 1 = 0.0237881 loss)
I0625 20:11:39.059836  6673 sgd_solver.cpp:106] Iteration 3820, lr = 0.0002
I0625 20:13:17.094378  6673 solver.cpp:228] Iteration 3840, loss = 0.529313
I0625 20:13:17.094406  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0625 20:13:17.094414  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.238529 (* 1 = 0.238529 loss)
I0625 20:13:17.094419  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.46086 (* 1 = 0.46086 loss)
I0625 20:13:17.094424  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00703715 (* 1 = 0.00703715 loss)
I0625 20:13:17.094429  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351374 (* 1 = 0.0351374 loss)
I0625 20:13:17.094435  6673 sgd_solver.cpp:106] Iteration 3840, lr = 0.0002
I0625 20:14:55.080739  6673 solver.cpp:228] Iteration 3860, loss = 0.316639
I0625 20:14:55.080765  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 20:14:55.080770  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.13619 (* 1 = 0.13619 loss)
I0625 20:14:55.080775  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.369593 (* 1 = 0.369593 loss)
I0625 20:14:55.080778  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00129396 (* 1 = 0.00129396 loss)
I0625 20:14:55.080781  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147116 (* 1 = 0.0147116 loss)
I0625 20:14:55.080786  6673 sgd_solver.cpp:106] Iteration 3860, lr = 0.0002
I0625 20:16:33.007779  6673 solver.cpp:228] Iteration 3880, loss = 0.338365
I0625 20:16:33.007807  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 20:16:33.007813  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.135222 (* 1 = 0.135222 loss)
I0625 20:16:33.007818  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.261124 (* 1 = 0.261124 loss)
I0625 20:16:33.007822  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103331 (* 1 = 0.0103331 loss)
I0625 20:16:33.007827  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0933658 (* 1 = 0.0933658 loss)
I0625 20:16:33.007831  6673 sgd_solver.cpp:106] Iteration 3880, lr = 0.0002
I0625 20:18:11.175123  6673 solver.cpp:228] Iteration 3900, loss = 0.353078
I0625 20:18:11.175148  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0625 20:18:11.175158  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.404694 (* 1 = 0.404694 loss)
I0625 20:18:11.175164  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.600299 (* 1 = 0.600299 loss)
I0625 20:18:11.175170  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246767 (* 1 = 0.0246767 loss)
I0625 20:18:11.175177  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0949091 (* 1 = 0.0949091 loss)
I0625 20:18:11.175184  6673 sgd_solver.cpp:106] Iteration 3900, lr = 0.0002
I0625 20:19:49.116356  6673 solver.cpp:228] Iteration 3920, loss = 0.520533
I0625 20:19:49.116382  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 20:19:49.116390  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743358 (* 1 = 0.0743358 loss)
I0625 20:19:49.116394  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.142759 (* 1 = 0.142759 loss)
I0625 20:19:49.116397  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251261 (* 1 = 0.0251261 loss)
I0625 20:19:49.116400  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136004 (* 1 = 0.0136004 loss)
I0625 20:19:49.116406  6673 sgd_solver.cpp:106] Iteration 3920, lr = 0.0002
I0625 20:21:27.061719  6673 solver.cpp:228] Iteration 3940, loss = 0.395702
I0625 20:21:27.061743  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:21:27.061749  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0450577 (* 1 = 0.0450577 loss)
I0625 20:21:27.061753  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0873345 (* 1 = 0.0873345 loss)
I0625 20:21:27.061758  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000335595 (* 1 = 0.000335595 loss)
I0625 20:21:27.061760  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00639734 (* 1 = 0.00639734 loss)
I0625 20:21:27.061765  6673 sgd_solver.cpp:106] Iteration 3940, lr = 0.0002
I0625 20:23:05.216264  6673 solver.cpp:228] Iteration 3960, loss = 0.257568
I0625 20:23:05.216291  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 20:23:05.216300  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.028776 (* 1 = 0.028776 loss)
I0625 20:23:05.216305  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0473953 (* 1 = 0.0473953 loss)
I0625 20:23:05.216307  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00077791 (* 1 = 0.00077791 loss)
I0625 20:23:05.216311  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00501523 (* 1 = 0.00501523 loss)
I0625 20:23:05.216316  6673 sgd_solver.cpp:106] Iteration 3960, lr = 0.0002
I0625 20:24:43.785627  6673 solver.cpp:228] Iteration 3980, loss = 0.455554
I0625 20:24:43.785651  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 20:24:43.785660  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758795 (* 1 = 0.0758795 loss)
I0625 20:24:43.785665  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0829621 (* 1 = 0.0829621 loss)
I0625 20:24:43.785668  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00858997 (* 1 = 0.00858997 loss)
I0625 20:24:43.785671  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101552 (* 1 = 0.0101552 loss)
I0625 20:24:43.785676  6673 sgd_solver.cpp:106] Iteration 3980, lr = 0.0002
speed: 4.898s / iter
I0625 20:26:22.277915  6673 solver.cpp:228] Iteration 4000, loss = 0.381132
I0625 20:26:22.277938  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:26:22.277945  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0648897 (* 1 = 0.0648897 loss)
I0625 20:26:22.277951  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.146417 (* 1 = 0.146417 loss)
I0625 20:26:22.277954  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0504348 (* 1 = 0.0504348 loss)
I0625 20:26:22.277957  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291679 (* 1 = 0.0291679 loss)
I0625 20:26:22.277964  6673 sgd_solver.cpp:106] Iteration 4000, lr = 0.0002
I0625 20:28:00.978112  6673 solver.cpp:228] Iteration 4020, loss = 0.370657
I0625 20:28:00.978143  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:28:00.978152  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0354291 (* 1 = 0.0354291 loss)
I0625 20:28:00.978157  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.13422 (* 1 = 0.13422 loss)
I0625 20:28:00.978161  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377133 (* 1 = 0.00377133 loss)
I0625 20:28:00.978166  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00609681 (* 1 = 0.00609681 loss)
I0625 20:28:00.978171  6673 sgd_solver.cpp:106] Iteration 4020, lr = 0.0002
I0625 20:29:39.237740  6673 solver.cpp:228] Iteration 4040, loss = 0.224892
I0625 20:29:39.237764  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 20:29:39.237772  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0880281 (* 1 = 0.0880281 loss)
I0625 20:29:39.237778  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.154001 (* 1 = 0.154001 loss)
I0625 20:29:39.237783  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00605845 (* 1 = 0.00605845 loss)
I0625 20:29:39.237789  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00407789 (* 1 = 0.00407789 loss)
I0625 20:29:39.237795  6673 sgd_solver.cpp:106] Iteration 4040, lr = 0.0002
I0625 20:31:17.402788  6673 solver.cpp:228] Iteration 4060, loss = 0.455575
I0625 20:31:17.402814  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0625 20:31:17.402822  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.584335 (* 1 = 0.584335 loss)
I0625 20:31:17.402825  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.728679 (* 1 = 0.728679 loss)
I0625 20:31:17.402828  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0802718 (* 1 = 0.0802718 loss)
I0625 20:31:17.402832  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.217018 (* 1 = 0.217018 loss)
I0625 20:31:17.402837  6673 sgd_solver.cpp:106] Iteration 4060, lr = 0.0002
I0625 20:32:55.390103  6673 solver.cpp:228] Iteration 4080, loss = 0.290831
I0625 20:32:55.390133  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:32:55.390142  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314863 (* 1 = 0.0314863 loss)
I0625 20:32:55.390149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.133167 (* 1 = 0.133167 loss)
I0625 20:32:55.390154  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113218 (* 1 = 0.0113218 loss)
I0625 20:32:55.390161  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101699 (* 1 = 0.0101699 loss)
I0625 20:32:55.390167  6673 sgd_solver.cpp:106] Iteration 4080, lr = 0.0002
I0625 20:34:33.333628  6673 solver.cpp:228] Iteration 4100, loss = 0.368453
I0625 20:34:33.333652  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 20:34:33.333662  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.129304 (* 1 = 0.129304 loss)
I0625 20:34:33.333668  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.208711 (* 1 = 0.208711 loss)
I0625 20:34:33.333675  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00187384 (* 1 = 0.00187384 loss)
I0625 20:34:33.333683  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228649 (* 1 = 0.0228649 loss)
I0625 20:34:33.333688  6673 sgd_solver.cpp:106] Iteration 4100, lr = 0.0002
I0625 20:36:11.558404  6673 solver.cpp:228] Iteration 4120, loss = 0.360356
I0625 20:36:11.558432  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:36:11.558441  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402353 (* 1 = 0.0402353 loss)
I0625 20:36:11.558447  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100155 (* 1 = 0.100155 loss)
I0625 20:36:11.558452  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0071136 (* 1 = 0.0071136 loss)
I0625 20:36:11.558457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168718 (* 1 = 0.0168718 loss)
I0625 20:36:11.558465  6673 sgd_solver.cpp:106] Iteration 4120, lr = 0.0002
I0625 20:37:49.543766  6673 solver.cpp:228] Iteration 4140, loss = 0.229176
I0625 20:37:49.543788  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 20:37:49.543797  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0844955 (* 1 = 0.0844955 loss)
I0625 20:37:49.543800  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138323 (* 1 = 0.138323 loss)
I0625 20:37:49.543803  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00284565 (* 1 = 0.00284565 loss)
I0625 20:37:49.543807  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153961 (* 1 = 0.0153961 loss)
I0625 20:37:49.543812  6673 sgd_solver.cpp:106] Iteration 4140, lr = 0.0002
I0625 20:39:27.422678  6673 solver.cpp:228] Iteration 4160, loss = 0.32514
I0625 20:39:27.422700  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 20:39:27.422708  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0239598 (* 1 = 0.0239598 loss)
I0625 20:39:27.422713  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0980423 (* 1 = 0.0980423 loss)
I0625 20:39:27.422716  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296925 (* 1 = 0.00296925 loss)
I0625 20:39:27.422719  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00152428 (* 1 = 0.00152428 loss)
I0625 20:39:27.422724  6673 sgd_solver.cpp:106] Iteration 4160, lr = 0.0002
I0625 20:41:05.319361  6673 solver.cpp:228] Iteration 4180, loss = 0.323438
I0625 20:41:05.319383  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 20:41:05.319391  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625629 (* 1 = 0.0625629 loss)
I0625 20:41:05.319393  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.262317 (* 1 = 0.262317 loss)
I0625 20:41:05.319397  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156867 (* 1 = 0.0156867 loss)
I0625 20:41:05.319401  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257605 (* 1 = 0.0257605 loss)
I0625 20:41:05.319406  6673 sgd_solver.cpp:106] Iteration 4180, lr = 0.0002
speed: 4.899s / iter
I0625 20:42:43.226289  6673 solver.cpp:228] Iteration 4200, loss = 0.292325
I0625 20:42:43.226316  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 20:42:43.226323  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0863726 (* 1 = 0.0863726 loss)
I0625 20:42:43.226327  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.237345 (* 1 = 0.237345 loss)
I0625 20:42:43.226330  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0290865 (* 1 = 0.0290865 loss)
I0625 20:42:43.226335  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.10032 (* 1 = 0.10032 loss)
I0625 20:42:43.226339  6673 sgd_solver.cpp:106] Iteration 4200, lr = 0.0002
I0625 20:44:21.091493  6673 solver.cpp:228] Iteration 4220, loss = 0.259782
I0625 20:44:21.091521  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 20:44:21.091529  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.112137 (* 1 = 0.112137 loss)
I0625 20:44:21.091534  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.160743 (* 1 = 0.160743 loss)
I0625 20:44:21.091539  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193617 (* 1 = 0.00193617 loss)
I0625 20:44:21.091543  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163758 (* 1 = 0.0163758 loss)
I0625 20:44:21.091549  6673 sgd_solver.cpp:106] Iteration 4220, lr = 0.0002
I0625 20:45:58.995992  6673 solver.cpp:228] Iteration 4240, loss = 0.415292
I0625 20:45:58.996019  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 20:45:58.996026  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0800887 (* 1 = 0.0800887 loss)
I0625 20:45:58.996031  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.187504 (* 1 = 0.187504 loss)
I0625 20:45:58.996035  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00454945 (* 1 = 0.00454945 loss)
I0625 20:45:58.996038  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00426186 (* 1 = 0.00426186 loss)
I0625 20:45:58.996044  6673 sgd_solver.cpp:106] Iteration 4240, lr = 0.0002
I0625 20:47:36.880270  6673 solver.cpp:228] Iteration 4260, loss = 0.269313
I0625 20:47:36.880295  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 20:47:36.880302  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385226 (* 1 = 0.0385226 loss)
I0625 20:47:36.880306  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0786614 (* 1 = 0.0786614 loss)
I0625 20:47:36.880311  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134226 (* 1 = 0.00134226 loss)
I0625 20:47:36.880314  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00874313 (* 1 = 0.00874313 loss)
I0625 20:47:36.880319  6673 sgd_solver.cpp:106] Iteration 4260, lr = 0.0002
I0625 20:49:14.801112  6673 solver.cpp:228] Iteration 4280, loss = 0.398012
I0625 20:49:14.801137  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0625 20:49:14.801144  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.214815 (* 1 = 0.214815 loss)
I0625 20:49:14.801149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.341146 (* 1 = 0.341146 loss)
I0625 20:49:14.801152  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0086647 (* 1 = 0.0086647 loss)
I0625 20:49:14.801156  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405674 (* 1 = 0.0405674 loss)
I0625 20:49:14.801162  6673 sgd_solver.cpp:106] Iteration 4280, lr = 0.0002
I0625 20:50:52.729614  6673 solver.cpp:228] Iteration 4300, loss = 0.482779
I0625 20:50:52.729640  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:50:52.729647  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0249316 (* 1 = 0.0249316 loss)
I0625 20:50:52.729651  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0923559 (* 1 = 0.0923559 loss)
I0625 20:50:52.729655  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00482106 (* 1 = 0.00482106 loss)
I0625 20:50:52.729660  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102716 (* 1 = 0.0102716 loss)
I0625 20:50:52.729665  6673 sgd_solver.cpp:106] Iteration 4300, lr = 0.0002
I0625 20:52:30.744396  6673 solver.cpp:228] Iteration 4320, loss = 0.421807
I0625 20:52:30.744421  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 20:52:30.744427  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0934819 (* 1 = 0.0934819 loss)
I0625 20:52:30.744432  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.13953 (* 1 = 0.13953 loss)
I0625 20:52:30.744436  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102196 (* 1 = 0.0102196 loss)
I0625 20:52:30.744438  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123291 (* 1 = 0.0123291 loss)
I0625 20:52:30.744443  6673 sgd_solver.cpp:106] Iteration 4320, lr = 0.0002
I0625 20:54:08.615015  6673 solver.cpp:228] Iteration 4340, loss = 0.369761
I0625 20:54:08.615041  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 20:54:08.615048  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.111597 (* 1 = 0.111597 loss)
I0625 20:54:08.615052  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.257056 (* 1 = 0.257056 loss)
I0625 20:54:08.615057  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00783332 (* 1 = 0.00783332 loss)
I0625 20:54:08.615061  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178397 (* 1 = 0.0178397 loss)
I0625 20:54:08.615067  6673 sgd_solver.cpp:106] Iteration 4340, lr = 0.0002
I0625 20:55:46.535485  6673 solver.cpp:228] Iteration 4360, loss = 0.253183
I0625 20:55:46.535512  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 20:55:46.535518  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199834 (* 1 = 0.0199834 loss)
I0625 20:55:46.535522  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0444785 (* 1 = 0.0444785 loss)
I0625 20:55:46.535526  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000862121 (* 1 = 0.000862121 loss)
I0625 20:55:46.535531  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00795493 (* 1 = 0.00795493 loss)
I0625 20:55:46.535535  6673 sgd_solver.cpp:106] Iteration 4360, lr = 0.0002
I0625 20:57:24.462309  6673 solver.cpp:228] Iteration 4380, loss = 0.490389
I0625 20:57:24.462332  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 20:57:24.462339  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400636 (* 1 = 0.0400636 loss)
I0625 20:57:24.462343  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138901 (* 1 = 0.138901 loss)
I0625 20:57:24.462347  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0063404 (* 1 = 0.0063404 loss)
I0625 20:57:24.462350  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00739363 (* 1 = 0.00739363 loss)
I0625 20:57:24.462354  6673 sgd_solver.cpp:106] Iteration 4380, lr = 0.0002
speed: 4.899s / iter
I0625 20:59:02.315511  6673 solver.cpp:228] Iteration 4400, loss = 0.267433
I0625 20:59:02.315538  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 20:59:02.315546  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197929 (* 1 = 0.0197929 loss)
I0625 20:59:02.315552  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0889731 (* 1 = 0.0889731 loss)
I0625 20:59:02.315557  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0083197 (* 1 = 0.0083197 loss)
I0625 20:59:02.315562  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108936 (* 1 = 0.0108936 loss)
I0625 20:59:02.315567  6673 sgd_solver.cpp:106] Iteration 4400, lr = 0.0002
I0625 21:00:40.250953  6673 solver.cpp:228] Iteration 4420, loss = 0.208458
I0625 21:00:40.250977  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 21:00:40.250983  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256776 (* 1 = 0.0256776 loss)
I0625 21:00:40.250988  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0692959 (* 1 = 0.0692959 loss)
I0625 21:00:40.250990  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107617 (* 1 = 0.0107617 loss)
I0625 21:00:40.250993  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940615 (* 1 = 0.00940615 loss)
I0625 21:00:40.250998  6673 sgd_solver.cpp:106] Iteration 4420, lr = 0.0002
I0625 21:02:18.248126  6673 solver.cpp:228] Iteration 4440, loss = 0.330802
I0625 21:02:18.248150  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 21:02:18.248160  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.051857 (* 1 = 0.051857 loss)
I0625 21:02:18.248167  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.14553 (* 1 = 0.14553 loss)
I0625 21:02:18.248172  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292815 (* 1 = 0.00292815 loss)
I0625 21:02:18.248180  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104508 (* 1 = 0.0104508 loss)
I0625 21:02:18.248186  6673 sgd_solver.cpp:106] Iteration 4440, lr = 0.0002
I0625 21:03:56.309353  6673 solver.cpp:228] Iteration 4460, loss = 0.263618
I0625 21:03:56.309379  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 21:03:56.309387  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268402 (* 1 = 0.0268402 loss)
I0625 21:03:56.309391  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0739114 (* 1 = 0.0739114 loss)
I0625 21:03:56.309396  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000394374 (* 1 = 0.000394374 loss)
I0625 21:03:56.309399  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00635377 (* 1 = 0.00635377 loss)
I0625 21:03:56.309404  6673 sgd_solver.cpp:106] Iteration 4460, lr = 0.0002
I0625 21:05:34.312095  6673 solver.cpp:228] Iteration 4480, loss = 0.180584
I0625 21:05:34.312119  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:05:34.312127  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216558 (* 1 = 0.0216558 loss)
I0625 21:05:34.312132  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0907303 (* 1 = 0.0907303 loss)
I0625 21:05:34.312136  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00986231 (* 1 = 0.00986231 loss)
I0625 21:05:34.312139  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125362 (* 1 = 0.0125362 loss)
I0625 21:05:34.312144  6673 sgd_solver.cpp:106] Iteration 4480, lr = 0.0002
I0625 21:07:12.337410  6673 solver.cpp:228] Iteration 4500, loss = 0.237098
I0625 21:07:12.337436  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 21:07:12.337445  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.142499 (* 1 = 0.142499 loss)
I0625 21:07:12.337450  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.27437 (* 1 = 0.27437 loss)
I0625 21:07:12.337455  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00617002 (* 1 = 0.00617002 loss)
I0625 21:07:12.337460  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240756 (* 1 = 0.0240756 loss)
I0625 21:07:12.337465  6673 sgd_solver.cpp:106] Iteration 4500, lr = 0.0002
I0625 21:08:50.310223  6673 solver.cpp:228] Iteration 4520, loss = 0.392263
I0625 21:08:50.310250  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 21:08:50.310259  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297123 (* 1 = 0.0297123 loss)
I0625 21:08:50.310266  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0752551 (* 1 = 0.0752551 loss)
I0625 21:08:50.310272  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143484 (* 1 = 0.00143484 loss)
I0625 21:08:50.310278  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00338419 (* 1 = 0.00338419 loss)
I0625 21:08:50.310286  6673 sgd_solver.cpp:106] Iteration 4520, lr = 0.0002
I0625 21:10:28.358402  6673 solver.cpp:228] Iteration 4540, loss = 0.432783
I0625 21:10:28.358428  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 21:10:28.358434  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0861837 (* 1 = 0.0861837 loss)
I0625 21:10:28.358438  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.131063 (* 1 = 0.131063 loss)
I0625 21:10:28.358443  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361679 (* 1 = 0.00361679 loss)
I0625 21:10:28.358445  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243102 (* 1 = 0.0243102 loss)
I0625 21:10:28.358450  6673 sgd_solver.cpp:106] Iteration 4540, lr = 0.0002
I0625 21:12:06.471187  6673 solver.cpp:228] Iteration 4560, loss = 0.44532
I0625 21:12:06.471211  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 21:12:06.471218  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.158263 (* 1 = 0.158263 loss)
I0625 21:12:06.471222  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.284497 (* 1 = 0.284497 loss)
I0625 21:12:06.471225  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00559804 (* 1 = 0.00559804 loss)
I0625 21:12:06.471230  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116473 (* 1 = 0.0116473 loss)
I0625 21:12:06.471233  6673 sgd_solver.cpp:106] Iteration 4560, lr = 0.0002
I0625 21:13:44.618162  6673 solver.cpp:228] Iteration 4580, loss = 0.311155
I0625 21:13:44.618202  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 21:13:44.618211  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.078972 (* 1 = 0.078972 loss)
I0625 21:13:44.618216  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.223357 (* 1 = 0.223357 loss)
I0625 21:13:44.618221  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000512924 (* 1 = 0.000512924 loss)
I0625 21:13:44.618224  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0094728 (* 1 = 0.0094728 loss)
I0625 21:13:44.618232  6673 sgd_solver.cpp:106] Iteration 4580, lr = 0.0002
speed: 4.899s / iter
I0625 21:15:23.322770  6673 solver.cpp:228] Iteration 4600, loss = 0.31417
I0625 21:15:23.322794  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 21:15:23.322801  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.130329 (* 1 = 0.130329 loss)
I0625 21:15:23.322805  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.158283 (* 1 = 0.158283 loss)
I0625 21:15:23.322808  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00383206 (* 1 = 0.00383206 loss)
I0625 21:15:23.322813  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146597 (* 1 = 0.0146597 loss)
I0625 21:15:23.322816  6673 sgd_solver.cpp:106] Iteration 4600, lr = 0.0002
I0625 21:17:02.424278  6673 solver.cpp:228] Iteration 4620, loss = 0.398599
I0625 21:17:02.424300  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 21:17:02.424307  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589297 (* 1 = 0.0589297 loss)
I0625 21:17:02.424311  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.17016 (* 1 = 0.17016 loss)
I0625 21:17:02.424315  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00837528 (* 1 = 0.00837528 loss)
I0625 21:17:02.424319  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115472 (* 1 = 0.0115472 loss)
I0625 21:17:02.424322  6673 sgd_solver.cpp:106] Iteration 4620, lr = 0.0002
I0625 21:18:41.450944  6673 solver.cpp:228] Iteration 4640, loss = 0.269828
I0625 21:18:41.450969  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 21:18:41.450978  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0418883 (* 1 = 0.0418883 loss)
I0625 21:18:41.450984  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.135728 (* 1 = 0.135728 loss)
I0625 21:18:41.450989  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.045947 (* 1 = 0.045947 loss)
I0625 21:18:41.450994  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0848642 (* 1 = 0.0848642 loss)
I0625 21:18:41.451000  6673 sgd_solver.cpp:106] Iteration 4640, lr = 0.0002
I0625 21:20:20.441376  6673 solver.cpp:228] Iteration 4660, loss = 0.24862
I0625 21:20:20.441398  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 21:20:20.441406  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0544943 (* 1 = 0.0544943 loss)
I0625 21:20:20.441408  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.183885 (* 1 = 0.183885 loss)
I0625 21:20:20.441412  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00566254 (* 1 = 0.00566254 loss)
I0625 21:20:20.441416  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106975 (* 1 = 0.0106975 loss)
I0625 21:20:20.441421  6673 sgd_solver.cpp:106] Iteration 4660, lr = 0.0002
I0625 21:21:59.329370  6673 solver.cpp:228] Iteration 4680, loss = 0.396334
I0625 21:21:59.329392  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 21:21:59.329401  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0361914 (* 1 = 0.0361914 loss)
I0625 21:21:59.329404  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.163101 (* 1 = 0.163101 loss)
I0625 21:21:59.329407  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00497398 (* 1 = 0.00497398 loss)
I0625 21:21:59.329411  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163557 (* 1 = 0.0163557 loss)
I0625 21:21:59.329416  6673 sgd_solver.cpp:106] Iteration 4680, lr = 0.0002
I0625 21:23:38.164212  6673 solver.cpp:228] Iteration 4700, loss = 0.43655
I0625 21:23:38.164247  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 21:23:38.164258  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0939855 (* 1 = 0.0939855 loss)
I0625 21:23:38.164265  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.287256 (* 1 = 0.287256 loss)
I0625 21:23:38.164270  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164193 (* 1 = 0.0164193 loss)
I0625 21:23:38.164273  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.145234 (* 1 = 0.145234 loss)
I0625 21:23:38.164279  6673 sgd_solver.cpp:106] Iteration 4700, lr = 0.0002
I0625 21:25:17.327002  6673 solver.cpp:228] Iteration 4720, loss = 0.268503
I0625 21:25:17.327024  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 21:25:17.327031  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353228 (* 1 = 0.0353228 loss)
I0625 21:25:17.327035  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0656289 (* 1 = 0.0656289 loss)
I0625 21:25:17.327039  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00092382 (* 1 = 0.00092382 loss)
I0625 21:25:17.327042  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00284297 (* 1 = 0.00284297 loss)
I0625 21:25:17.327046  6673 sgd_solver.cpp:106] Iteration 4720, lr = 0.0002
I0625 21:26:56.318035  6673 solver.cpp:228] Iteration 4740, loss = 0.685014
I0625 21:26:56.318063  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 21:26:56.318071  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0671459 (* 1 = 0.0671459 loss)
I0625 21:26:56.318076  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.145947 (* 1 = 0.145947 loss)
I0625 21:26:56.318081  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00892892 (* 1 = 0.00892892 loss)
I0625 21:26:56.318086  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0021737 (* 1 = 0.0021737 loss)
I0625 21:26:56.318091  6673 sgd_solver.cpp:106] Iteration 4740, lr = 0.0002
I0625 21:28:35.145102  6673 solver.cpp:228] Iteration 4760, loss = 0.275928
I0625 21:28:35.145129  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 21:28:35.145138  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0491519 (* 1 = 0.0491519 loss)
I0625 21:28:35.145141  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.232373 (* 1 = 0.232373 loss)
I0625 21:28:35.145145  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00996523 (* 1 = 0.00996523 loss)
I0625 21:28:35.145149  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145913 (* 1 = 0.0145913 loss)
I0625 21:28:35.145155  6673 sgd_solver.cpp:106] Iteration 4760, lr = 0.0002
I0625 21:30:14.134894  6673 solver.cpp:228] Iteration 4780, loss = 0.58875
I0625 21:30:14.134920  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 21:30:14.134928  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0702416 (* 1 = 0.0702416 loss)
I0625 21:30:14.134933  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.128624 (* 1 = 0.128624 loss)
I0625 21:30:14.134938  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491066 (* 1 = 0.00491066 loss)
I0625 21:30:14.134941  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125829 (* 1 = 0.0125829 loss)
I0625 21:30:14.134946  6673 sgd_solver.cpp:106] Iteration 4780, lr = 0.0002
speed: 4.901s / iter
I0625 21:31:52.922710  6673 solver.cpp:228] Iteration 4800, loss = 0.246191
I0625 21:31:52.922735  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 21:31:52.922742  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0662143 (* 1 = 0.0662143 loss)
I0625 21:31:52.922746  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100388 (* 1 = 0.100388 loss)
I0625 21:31:52.922749  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116653 (* 1 = 0.00116653 loss)
I0625 21:31:52.922754  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00168336 (* 1 = 0.00168336 loss)
I0625 21:31:52.922758  6673 sgd_solver.cpp:106] Iteration 4800, lr = 0.0002
I0625 21:33:31.759961  6673 solver.cpp:228] Iteration 4820, loss = 0.205588
I0625 21:33:31.759989  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 21:33:31.759995  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.017387 (* 1 = 0.017387 loss)
I0625 21:33:31.759999  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0908355 (* 1 = 0.0908355 loss)
I0625 21:33:31.760004  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00297522 (* 1 = 0.00297522 loss)
I0625 21:33:31.760006  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321745 (* 1 = 0.0321745 loss)
I0625 21:33:31.760011  6673 sgd_solver.cpp:106] Iteration 4820, lr = 0.0002
I0625 21:35:10.371419  6673 solver.cpp:228] Iteration 4840, loss = 0.341626
I0625 21:35:10.371450  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 21:35:10.371461  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.107495 (* 1 = 0.107495 loss)
I0625 21:35:10.371466  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.166609 (* 1 = 0.166609 loss)
I0625 21:35:10.371474  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00261048 (* 1 = 0.00261048 loss)
I0625 21:35:10.371479  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269098 (* 1 = 0.0269098 loss)
I0625 21:35:10.371486  6673 sgd_solver.cpp:106] Iteration 4840, lr = 0.0002
I0625 21:36:48.850533  6673 solver.cpp:228] Iteration 4860, loss = 0.335258
I0625 21:36:48.850561  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 21:36:48.850570  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.132576 (* 1 = 0.132576 loss)
I0625 21:36:48.850575  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.146292 (* 1 = 0.146292 loss)
I0625 21:36:48.850579  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00756451 (* 1 = 0.00756451 loss)
I0625 21:36:48.850584  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388844 (* 1 = 0.0388844 loss)
I0625 21:36:48.850589  6673 sgd_solver.cpp:106] Iteration 4860, lr = 0.0002
I0625 21:38:27.023639  6673 solver.cpp:228] Iteration 4880, loss = 0.37325
I0625 21:38:27.023669  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 21:38:27.023679  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0910523 (* 1 = 0.0910523 loss)
I0625 21:38:27.023684  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.260338 (* 1 = 0.260338 loss)
I0625 21:38:27.023690  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00809441 (* 1 = 0.00809441 loss)
I0625 21:38:27.023695  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0584012 (* 1 = 0.0584012 loss)
I0625 21:38:27.023701  6673 sgd_solver.cpp:106] Iteration 4880, lr = 0.0002
I0625 21:40:05.296736  6673 solver.cpp:228] Iteration 4900, loss = 0.288966
I0625 21:40:05.296758  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0625 21:40:05.296766  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.175642 (* 1 = 0.175642 loss)
I0625 21:40:05.296771  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.319824 (* 1 = 0.319824 loss)
I0625 21:40:05.296774  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0454488 (* 1 = 0.0454488 loss)
I0625 21:40:05.296778  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103514 (* 1 = 0.103514 loss)
I0625 21:40:05.296783  6673 sgd_solver.cpp:106] Iteration 4900, lr = 0.0002
I0625 21:41:43.356781  6673 solver.cpp:228] Iteration 4920, loss = 0.30705
I0625 21:41:43.356806  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 21:41:43.356813  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.068654 (* 1 = 0.068654 loss)
I0625 21:41:43.356817  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.153866 (* 1 = 0.153866 loss)
I0625 21:41:43.356822  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00428829 (* 1 = 0.00428829 loss)
I0625 21:41:43.356825  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00855339 (* 1 = 0.00855339 loss)
I0625 21:41:43.356830  6673 sgd_solver.cpp:106] Iteration 4920, lr = 0.0002
I0625 21:43:21.613235  6673 solver.cpp:228] Iteration 4940, loss = 0.381785
I0625 21:43:21.613260  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 21:43:21.613267  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397808 (* 1 = 0.0397808 loss)
I0625 21:43:21.613272  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.104004 (* 1 = 0.104004 loss)
I0625 21:43:21.613276  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000751904 (* 1 = 0.000751904 loss)
I0625 21:43:21.613279  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126069 (* 1 = 0.0126069 loss)
I0625 21:43:21.613284  6673 sgd_solver.cpp:106] Iteration 4940, lr = 0.0002
I0625 21:44:59.815440  6673 solver.cpp:228] Iteration 4960, loss = 0.372097
I0625 21:44:59.815464  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:44:59.815470  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00171621 (* 1 = 0.00171621 loss)
I0625 21:44:59.815474  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0903633 (* 1 = 0.0903633 loss)
I0625 21:44:59.815479  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00626421 (* 1 = 0.00626421 loss)
I0625 21:44:59.815481  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165974 (* 1 = 0.0165974 loss)
I0625 21:44:59.815486  6673 sgd_solver.cpp:106] Iteration 4960, lr = 0.0002
I0625 21:46:38.121332  6673 solver.cpp:228] Iteration 4980, loss = 0.510064
I0625 21:46:38.121356  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 21:46:38.121366  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.110427 (* 1 = 0.110427 loss)
I0625 21:46:38.121373  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.254272 (* 1 = 0.254272 loss)
I0625 21:46:38.121379  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00369888 (* 1 = 0.00369888 loss)
I0625 21:46:38.121385  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124194 (* 1 = 0.0124194 loss)
I0625 21:46:38.121392  6673 sgd_solver.cpp:106] Iteration 4980, lr = 0.0002
speed: 4.902s / iter
I0625 21:48:11.838105  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_5000.caffemodel
I0625 21:48:17.176483  6673 solver.cpp:228] Iteration 5000, loss = 0.4177
I0625 21:48:17.176512  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 21:48:17.176520  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.187431 (* 1 = 0.187431 loss)
I0625 21:48:17.176527  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.332381 (* 1 = 0.332381 loss)
I0625 21:48:17.176532  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00986465 (* 1 = 0.00986465 loss)
I0625 21:48:17.176538  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197397 (* 1 = 0.0197397 loss)
I0625 21:48:17.176544  6673 sgd_solver.cpp:106] Iteration 5000, lr = 0.0002
I0625 21:49:55.692814  6673 solver.cpp:228] Iteration 5020, loss = 0.421224
I0625 21:49:55.692853  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 21:49:55.692863  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.129715 (* 1 = 0.129715 loss)
I0625 21:49:55.692867  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.307568 (* 1 = 0.307568 loss)
I0625 21:49:55.692872  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00505439 (* 1 = 0.00505439 loss)
I0625 21:49:55.692874  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293245 (* 1 = 0.0293245 loss)
I0625 21:49:55.692883  6673 sgd_solver.cpp:106] Iteration 5020, lr = 0.0002
I0625 21:51:34.185171  6673 solver.cpp:228] Iteration 5040, loss = 0.277347
I0625 21:51:34.185196  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 21:51:34.185204  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00014276 (* 1 = 0.00014276 loss)
I0625 21:51:34.185209  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0469032 (* 1 = 0.0469032 loss)
I0625 21:51:34.185212  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00810442 (* 1 = 0.00810442 loss)
I0625 21:51:34.185216  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015706 (* 1 = 0.015706 loss)
I0625 21:51:34.185220  6673 sgd_solver.cpp:106] Iteration 5040, lr = 0.0002
I0625 21:53:12.841285  6673 solver.cpp:228] Iteration 5060, loss = 0.269474
I0625 21:53:12.841311  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 21:53:12.841318  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430938 (* 1 = 0.0430938 loss)
I0625 21:53:12.841322  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0782294 (* 1 = 0.0782294 loss)
I0625 21:53:12.841326  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106703 (* 1 = 0.00106703 loss)
I0625 21:53:12.841331  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00774657 (* 1 = 0.00774657 loss)
I0625 21:53:12.841336  6673 sgd_solver.cpp:106] Iteration 5060, lr = 0.0002
I0625 21:54:51.209920  6673 solver.cpp:228] Iteration 5080, loss = 0.226032
I0625 21:54:51.209946  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 21:54:51.209954  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.034456 (* 1 = 0.034456 loss)
I0625 21:54:51.209959  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122189 (* 1 = 0.122189 loss)
I0625 21:54:51.209962  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160864 (* 1 = 0.00160864 loss)
I0625 21:54:51.209966  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00460504 (* 1 = 0.00460504 loss)
I0625 21:54:51.209971  6673 sgd_solver.cpp:106] Iteration 5080, lr = 0.0002
I0625 21:56:30.257300  6673 solver.cpp:228] Iteration 5100, loss = 0.266807
I0625 21:56:30.257328  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 21:56:30.257336  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.138374 (* 1 = 0.138374 loss)
I0625 21:56:30.257340  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.213299 (* 1 = 0.213299 loss)
I0625 21:56:30.257345  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110343 (* 1 = 0.0110343 loss)
I0625 21:56:30.257350  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188811 (* 1 = 0.0188811 loss)
I0625 21:56:30.257355  6673 sgd_solver.cpp:106] Iteration 5100, lr = 0.0002
I0625 21:58:08.927068  6673 solver.cpp:228] Iteration 5120, loss = 0.408694
I0625 21:58:08.927091  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 21:58:08.927099  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486628 (* 1 = 0.0486628 loss)
I0625 21:58:08.927105  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0871944 (* 1 = 0.0871944 loss)
I0625 21:58:08.927110  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275563 (* 1 = 0.00275563 loss)
I0625 21:58:08.927114  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00375077 (* 1 = 0.00375077 loss)
I0625 21:58:08.927119  6673 sgd_solver.cpp:106] Iteration 5120, lr = 0.0002
I0625 21:59:47.790019  6673 solver.cpp:228] Iteration 5140, loss = 0.38739
I0625 21:59:47.790043  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 21:59:47.790050  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.21331 (* 1 = 0.21331 loss)
I0625 21:59:47.790055  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.329608 (* 1 = 0.329608 loss)
I0625 21:59:47.790058  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00454946 (* 1 = 0.00454946 loss)
I0625 21:59:47.790061  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0397979 (* 1 = 0.0397979 loss)
I0625 21:59:47.790066  6673 sgd_solver.cpp:106] Iteration 5140, lr = 0.0002
I0625 22:01:26.476603  6673 solver.cpp:228] Iteration 5160, loss = 0.345213
I0625 22:01:26.476629  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 22:01:26.476639  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.114443 (* 1 = 0.114443 loss)
I0625 22:01:26.476646  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.213522 (* 1 = 0.213522 loss)
I0625 22:01:26.476652  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00623905 (* 1 = 0.00623905 loss)
I0625 22:01:26.476660  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268618 (* 1 = 0.0268618 loss)
I0625 22:01:26.476666  6673 sgd_solver.cpp:106] Iteration 5160, lr = 0.0002
I0625 22:03:05.616609  6673 solver.cpp:228] Iteration 5180, loss = 0.376898
I0625 22:03:05.616638  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 22:03:05.616648  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.250171 (* 1 = 0.250171 loss)
I0625 22:03:05.616655  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.552774 (* 1 = 0.552774 loss)
I0625 22:03:05.616660  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0714395 (* 1 = 0.0714395 loss)
I0625 22:03:05.616667  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0939215 (* 1 = 0.0939215 loss)
I0625 22:03:05.616674  6673 sgd_solver.cpp:106] Iteration 5180, lr = 0.0002
speed: 4.903s / iter
I0625 22:04:45.476061  6673 solver.cpp:228] Iteration 5200, loss = 0.38672
I0625 22:04:45.476086  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:04:45.476094  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134779 (* 1 = 0.134779 loss)
I0625 22:04:45.476099  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.164925 (* 1 = 0.164925 loss)
I0625 22:04:45.476102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00267051 (* 1 = 0.00267051 loss)
I0625 22:04:45.476106  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00876893 (* 1 = 0.00876893 loss)
I0625 22:04:45.476111  6673 sgd_solver.cpp:106] Iteration 5200, lr = 0.0002
I0625 22:06:25.289582  6673 solver.cpp:228] Iteration 5220, loss = 0.266838
I0625 22:06:25.289605  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:06:25.289611  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0414033 (* 1 = 0.0414033 loss)
I0625 22:06:25.289615  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0970838 (* 1 = 0.0970838 loss)
I0625 22:06:25.289619  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00789012 (* 1 = 0.00789012 loss)
I0625 22:06:25.289623  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130446 (* 1 = 0.0130446 loss)
I0625 22:06:25.289628  6673 sgd_solver.cpp:106] Iteration 5220, lr = 0.0002
I0625 22:08:05.087049  6673 solver.cpp:228] Iteration 5240, loss = 0.280224
I0625 22:08:05.087082  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 22:08:05.087091  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.172834 (* 1 = 0.172834 loss)
I0625 22:08:05.087097  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.31448 (* 1 = 0.31448 loss)
I0625 22:08:05.087102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116924 (* 1 = 0.0116924 loss)
I0625 22:08:05.087107  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012552 (* 1 = 0.012552 loss)
I0625 22:08:05.087113  6673 sgd_solver.cpp:106] Iteration 5240, lr = 0.0002
I0625 22:09:44.884332  6673 solver.cpp:228] Iteration 5260, loss = 0.4817
I0625 22:09:44.884361  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 22:09:44.884369  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.116494 (* 1 = 0.116494 loss)
I0625 22:09:44.884374  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.203258 (* 1 = 0.203258 loss)
I0625 22:09:44.884378  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023258 (* 1 = 0.0023258 loss)
I0625 22:09:44.884382  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180865 (* 1 = 0.0180865 loss)
I0625 22:09:44.884388  6673 sgd_solver.cpp:106] Iteration 5260, lr = 0.0002
I0625 22:11:24.390368  6673 solver.cpp:228] Iteration 5280, loss = 0.246566
I0625 22:11:24.390394  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 22:11:24.390401  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0772145 (* 1 = 0.0772145 loss)
I0625 22:11:24.390406  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.192569 (* 1 = 0.192569 loss)
I0625 22:11:24.390409  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00733886 (* 1 = 0.00733886 loss)
I0625 22:11:24.390413  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286754 (* 1 = 0.0286754 loss)
I0625 22:11:24.390419  6673 sgd_solver.cpp:106] Iteration 5280, lr = 0.0002
I0625 22:13:04.025569  6673 solver.cpp:228] Iteration 5300, loss = 0.345563
I0625 22:13:04.025594  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0625 22:13:04.025602  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.13451 (* 1 = 0.13451 loss)
I0625 22:13:04.025606  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.351726 (* 1 = 0.351726 loss)
I0625 22:13:04.025610  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00530656 (* 1 = 0.00530656 loss)
I0625 22:13:04.025614  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252841 (* 1 = 0.0252841 loss)
I0625 22:13:04.025619  6673 sgd_solver.cpp:106] Iteration 5300, lr = 0.0002
I0625 22:14:43.451606  6673 solver.cpp:228] Iteration 5320, loss = 0.427285
I0625 22:14:43.451635  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.59375
I0625 22:14:43.451644  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.368112 (* 1 = 0.368112 loss)
I0625 22:14:43.451650  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.657264 (* 1 = 0.657264 loss)
I0625 22:14:43.451655  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0611031 (* 1 = 0.0611031 loss)
I0625 22:14:43.451660  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.338418 (* 1 = 0.338418 loss)
I0625 22:14:43.451666  6673 sgd_solver.cpp:106] Iteration 5320, lr = 0.0002
I0625 22:16:22.628523  6673 solver.cpp:228] Iteration 5340, loss = 0.413058
I0625 22:16:22.628547  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0625 22:16:22.628556  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.193371 (* 1 = 0.193371 loss)
I0625 22:16:22.628559  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.447812 (* 1 = 0.447812 loss)
I0625 22:16:22.628563  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0356767 (* 1 = 0.0356767 loss)
I0625 22:16:22.628568  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0470588 (* 1 = 0.0470588 loss)
I0625 22:16:22.628573  6673 sgd_solver.cpp:106] Iteration 5340, lr = 0.0002
I0625 22:18:02.022552  6673 solver.cpp:228] Iteration 5360, loss = 0.246652
I0625 22:18:02.022574  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 22:18:02.022583  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.241221 (* 1 = 0.241221 loss)
I0625 22:18:02.022586  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.309886 (* 1 = 0.309886 loss)
I0625 22:18:02.022590  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0207769 (* 1 = 0.0207769 loss)
I0625 22:18:02.022593  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162122 (* 1 = 0.0162122 loss)
I0625 22:18:02.022598  6673 sgd_solver.cpp:106] Iteration 5360, lr = 0.0002
I0625 22:19:41.251037  6673 solver.cpp:228] Iteration 5380, loss = 0.453068
I0625 22:19:41.251070  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 22:19:41.251078  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0939055 (* 1 = 0.0939055 loss)
I0625 22:19:41.251083  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.274795 (* 1 = 0.274795 loss)
I0625 22:19:41.251087  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0315021 (* 1 = 0.0315021 loss)
I0625 22:19:41.251091  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149744 (* 1 = 0.149744 loss)
I0625 22:19:41.251097  6673 sgd_solver.cpp:106] Iteration 5380, lr = 0.0002
speed: 4.906s / iter
I0625 22:21:20.379907  6673 solver.cpp:228] Iteration 5400, loss = 0.235388
I0625 22:21:20.379935  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 22:21:20.379941  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000393104 (* 1 = 0.000393104 loss)
I0625 22:21:20.379945  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0534775 (* 1 = 0.0534775 loss)
I0625 22:21:20.379950  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00682694 (* 1 = 0.00682694 loss)
I0625 22:21:20.379953  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372736 (* 1 = 0.0372736 loss)
I0625 22:21:20.379958  6673 sgd_solver.cpp:106] Iteration 5400, lr = 0.0002
I0625 22:23:00.486760  6673 solver.cpp:228] Iteration 5420, loss = 0.216324
I0625 22:23:00.486788  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:23:00.486795  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0246337 (* 1 = 0.0246337 loss)
I0625 22:23:00.486799  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0945355 (* 1 = 0.0945355 loss)
I0625 22:23:00.486804  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028822 (* 1 = 0.0028822 loss)
I0625 22:23:00.486806  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00156671 (* 1 = 0.00156671 loss)
I0625 22:23:00.486812  6673 sgd_solver.cpp:106] Iteration 5420, lr = 0.0002
I0625 22:24:39.791332  6673 solver.cpp:228] Iteration 5440, loss = 0.261168
I0625 22:24:39.791363  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0625 22:24:39.791371  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0271423 (* 1 = 0.0271423 loss)
I0625 22:24:39.791376  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0555136 (* 1 = 0.0555136 loss)
I0625 22:24:39.791380  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237121 (* 1 = 0.00237121 loss)
I0625 22:24:39.791385  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0080781 (* 1 = 0.0080781 loss)
I0625 22:24:39.791391  6673 sgd_solver.cpp:106] Iteration 5440, lr = 0.0002
I0625 22:26:18.834956  6673 solver.cpp:228] Iteration 5460, loss = 0.502796
I0625 22:26:18.834981  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 22:26:18.834987  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0582978 (* 1 = 0.0582978 loss)
I0625 22:26:18.834991  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138297 (* 1 = 0.138297 loss)
I0625 22:26:18.834995  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0503285 (* 1 = 0.0503285 loss)
I0625 22:26:18.834998  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325889 (* 1 = 0.0325889 loss)
I0625 22:26:18.835003  6673 sgd_solver.cpp:106] Iteration 5460, lr = 0.0002
I0625 22:27:57.715340  6673 solver.cpp:228] Iteration 5480, loss = 0.463132
I0625 22:27:57.715366  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 22:27:57.715374  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.335462 (* 1 = 0.335462 loss)
I0625 22:27:57.715378  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.385533 (* 1 = 0.385533 loss)
I0625 22:27:57.715382  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00230328 (* 1 = 0.00230328 loss)
I0625 22:27:57.715386  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375982 (* 1 = 0.0375982 loss)
I0625 22:27:57.715391  6673 sgd_solver.cpp:106] Iteration 5480, lr = 0.0002
I0625 22:29:36.278589  6673 solver.cpp:228] Iteration 5500, loss = 0.286822
I0625 22:29:36.278622  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 22:29:36.278631  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00941256 (* 1 = 0.00941256 loss)
I0625 22:29:36.278635  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0495583 (* 1 = 0.0495583 loss)
I0625 22:29:36.278638  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000719804 (* 1 = 0.000719804 loss)
I0625 22:29:36.278642  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00728975 (* 1 = 0.00728975 loss)
I0625 22:29:36.278648  6673 sgd_solver.cpp:106] Iteration 5500, lr = 0.0002
I0625 22:31:15.170076  6673 solver.cpp:228] Iteration 5520, loss = 0.20943
I0625 22:31:15.170099  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 22:31:15.170106  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140646 (* 1 = 0.0140646 loss)
I0625 22:31:15.170110  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0372149 (* 1 = 0.0372149 loss)
I0625 22:31:15.170114  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128678 (* 1 = 0.00128678 loss)
I0625 22:31:15.170117  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00468729 (* 1 = 0.00468729 loss)
I0625 22:31:15.170122  6673 sgd_solver.cpp:106] Iteration 5520, lr = 0.0002
I0625 22:32:53.703320  6673 solver.cpp:228] Iteration 5540, loss = 0.314944
I0625 22:32:53.703341  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 22:32:53.703348  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.129129 (* 1 = 0.129129 loss)
I0625 22:32:53.703352  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.223988 (* 1 = 0.223988 loss)
I0625 22:32:53.703356  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00131738 (* 1 = 0.00131738 loss)
I0625 22:32:53.703359  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00736637 (* 1 = 0.00736637 loss)
I0625 22:32:53.703363  6673 sgd_solver.cpp:106] Iteration 5540, lr = 0.0002
I0625 22:34:32.325022  6673 solver.cpp:228] Iteration 5560, loss = 0.245029
I0625 22:34:32.325047  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 22:34:32.325053  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297894 (* 1 = 0.0297894 loss)
I0625 22:34:32.325057  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106501 (* 1 = 0.106501 loss)
I0625 22:34:32.325060  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305624 (* 1 = 0.00305624 loss)
I0625 22:34:32.325064  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00757151 (* 1 = 0.00757151 loss)
I0625 22:34:32.325068  6673 sgd_solver.cpp:106] Iteration 5560, lr = 0.0002
I0625 22:36:11.247182  6673 solver.cpp:228] Iteration 5580, loss = 0.277973
I0625 22:36:11.247206  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0625 22:36:11.247215  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.110391 (* 1 = 0.110391 loss)
I0625 22:36:11.247217  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.376941 (* 1 = 0.376941 loss)
I0625 22:36:11.247221  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388583 (* 1 = 0.00388583 loss)
I0625 22:36:11.247225  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165025 (* 1 = 0.0165025 loss)
I0625 22:36:11.247229  6673 sgd_solver.cpp:106] Iteration 5580, lr = 0.0002
speed: 4.907s / iter
I0625 22:37:49.749887  6673 solver.cpp:228] Iteration 5600, loss = 0.385555
I0625 22:37:49.749909  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:37:49.749917  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529454 (* 1 = 0.0529454 loss)
I0625 22:37:49.749922  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.175692 (* 1 = 0.175692 loss)
I0625 22:37:49.749924  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112758 (* 1 = 0.0112758 loss)
I0625 22:37:49.749927  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0704182 (* 1 = 0.0704182 loss)
I0625 22:37:49.749931  6673 sgd_solver.cpp:106] Iteration 5600, lr = 0.0002
I0625 22:39:28.451498  6673 solver.cpp:228] Iteration 5620, loss = 0.421911
I0625 22:39:28.451526  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 22:39:28.451536  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341485 (* 1 = 0.0341485 loss)
I0625 22:39:28.451542  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.116757 (* 1 = 0.116757 loss)
I0625 22:39:28.451548  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000384876 (* 1 = 0.000384876 loss)
I0625 22:39:28.451555  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00639522 (* 1 = 0.00639522 loss)
I0625 22:39:28.451561  6673 sgd_solver.cpp:106] Iteration 5620, lr = 0.0002
I0625 22:41:07.091644  6673 solver.cpp:228] Iteration 5640, loss = 0.281951
I0625 22:41:07.091670  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 22:41:07.091676  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0732757 (* 1 = 0.0732757 loss)
I0625 22:41:07.091681  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.107553 (* 1 = 0.107553 loss)
I0625 22:41:07.091684  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.003353 (* 1 = 0.003353 loss)
I0625 22:41:07.091689  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015442 (* 1 = 0.015442 loss)
I0625 22:41:07.091694  6673 sgd_solver.cpp:106] Iteration 5640, lr = 0.0002
I0625 22:42:45.925664  6673 solver.cpp:228] Iteration 5660, loss = 0.346516
I0625 22:42:45.925688  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 22:42:45.925696  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.138926 (* 1 = 0.138926 loss)
I0625 22:42:45.925700  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.253389 (* 1 = 0.253389 loss)
I0625 22:42:45.925704  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00750994 (* 1 = 0.00750994 loss)
I0625 22:42:45.925709  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255206 (* 1 = 0.0255206 loss)
I0625 22:42:45.925714  6673 sgd_solver.cpp:106] Iteration 5660, lr = 0.0002
I0625 22:44:24.739822  6673 solver.cpp:228] Iteration 5680, loss = 0.339477
I0625 22:44:24.739864  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0625 22:44:24.739876  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.173346 (* 1 = 0.173346 loss)
I0625 22:44:24.739881  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.319432 (* 1 = 0.319432 loss)
I0625 22:44:24.739887  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140216 (* 1 = 0.0140216 loss)
I0625 22:44:24.739892  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495064 (* 1 = 0.0495064 loss)
I0625 22:44:24.739900  6673 sgd_solver.cpp:106] Iteration 5680, lr = 0.0002
I0625 22:46:03.454748  6673 solver.cpp:228] Iteration 5700, loss = 0.34345
I0625 22:46:03.454774  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 22:46:03.454784  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0501326 (* 1 = 0.0501326 loss)
I0625 22:46:03.454792  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122667 (* 1 = 0.122667 loss)
I0625 22:46:03.454797  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140905 (* 1 = 0.0140905 loss)
I0625 22:46:03.454803  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023735 (* 1 = 0.023735 loss)
I0625 22:46:03.454813  6673 sgd_solver.cpp:106] Iteration 5700, lr = 0.0002
I0625 22:47:42.309278  6673 solver.cpp:228] Iteration 5720, loss = 0.465693
I0625 22:47:42.309301  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 22:47:42.309309  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.1667 (* 1 = 0.1667 loss)
I0625 22:47:42.309312  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.261895 (* 1 = 0.261895 loss)
I0625 22:47:42.309316  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00222475 (* 1 = 0.00222475 loss)
I0625 22:47:42.309320  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049487 (* 1 = 0.049487 loss)
I0625 22:47:42.309325  6673 sgd_solver.cpp:106] Iteration 5720, lr = 0.0002
I0625 22:49:21.146347  6673 solver.cpp:228] Iteration 5740, loss = 0.22927
I0625 22:49:21.146373  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 22:49:21.146380  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00890914 (* 1 = 0.00890914 loss)
I0625 22:49:21.146384  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0436408 (* 1 = 0.0436408 loss)
I0625 22:49:21.146389  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100033 (* 1 = 0.00100033 loss)
I0625 22:49:21.146392  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00179982 (* 1 = 0.00179982 loss)
I0625 22:49:21.146399  6673 sgd_solver.cpp:106] Iteration 5740, lr = 0.0002
I0625 22:51:00.188341  6673 solver.cpp:228] Iteration 5760, loss = 0.296253
I0625 22:51:00.188366  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 22:51:00.188374  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191799 (* 1 = 0.0191799 loss)
I0625 22:51:00.188380  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0788613 (* 1 = 0.0788613 loss)
I0625 22:51:00.188386  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538402 (* 1 = 0.00538402 loss)
I0625 22:51:00.188391  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00662446 (* 1 = 0.00662446 loss)
I0625 22:51:00.188395  6673 sgd_solver.cpp:106] Iteration 5760, lr = 0.0002
I0625 22:52:39.781975  6673 solver.cpp:228] Iteration 5780, loss = 0.234629
I0625 22:52:39.782002  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 22:52:39.782012  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000348417 (* 1 = 0.000348417 loss)
I0625 22:52:39.782018  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.056217 (* 1 = 0.056217 loss)
I0625 22:52:39.782024  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018133 (* 1 = 0.018133 loss)
I0625 22:52:39.782032  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142138 (* 1 = 0.0142138 loss)
I0625 22:52:39.782037  6673 sgd_solver.cpp:106] Iteration 5780, lr = 0.0002
speed: 4.909s / iter
I0625 22:54:19.545501  6673 solver.cpp:228] Iteration 5800, loss = 0.371754
I0625 22:54:19.545528  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 22:54:19.545536  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0149703 (* 1 = 0.0149703 loss)
I0625 22:54:19.545539  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0883971 (* 1 = 0.0883971 loss)
I0625 22:54:19.545543  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00725003 (* 1 = 0.00725003 loss)
I0625 22:54:19.545547  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138623 (* 1 = 0.0138623 loss)
I0625 22:54:19.545552  6673 sgd_solver.cpp:106] Iteration 5800, lr = 0.0002
I0625 22:55:59.270015  6673 solver.cpp:228] Iteration 5820, loss = 0.565536
I0625 22:55:59.270040  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 22:55:59.270047  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270172 (* 1 = 0.0270172 loss)
I0625 22:55:59.270051  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0349758 (* 1 = 0.0349758 loss)
I0625 22:55:59.270054  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000881343 (* 1 = 0.000881343 loss)
I0625 22:55:59.270057  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107291 (* 1 = 0.0107291 loss)
I0625 22:55:59.270062  6673 sgd_solver.cpp:106] Iteration 5820, lr = 0.0002
I0625 22:57:38.766702  6673 solver.cpp:228] Iteration 5840, loss = 0.385456
I0625 22:57:38.766727  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 22:57:38.766734  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.109292 (* 1 = 0.109292 loss)
I0625 22:57:38.766738  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.212254 (* 1 = 0.212254 loss)
I0625 22:57:38.766742  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117377 (* 1 = 0.0117377 loss)
I0625 22:57:38.766746  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189894 (* 1 = 0.0189894 loss)
I0625 22:57:38.766752  6673 sgd_solver.cpp:106] Iteration 5840, lr = 0.0002
I0625 22:59:18.401192  6673 solver.cpp:228] Iteration 5860, loss = 0.274152
I0625 22:59:18.401219  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 22:59:18.401230  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434705 (* 1 = 0.0434705 loss)
I0625 22:59:18.401237  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0735222 (* 1 = 0.0735222 loss)
I0625 22:59:18.401245  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110127 (* 1 = 0.00110127 loss)
I0625 22:59:18.401253  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117449 (* 1 = 0.0117449 loss)
I0625 22:59:18.401260  6673 sgd_solver.cpp:106] Iteration 5860, lr = 0.0002
I0625 23:00:57.802474  6673 solver.cpp:228] Iteration 5880, loss = 0.746153
I0625 23:00:57.802496  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:00:57.802503  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0650831 (* 1 = 0.0650831 loss)
I0625 23:00:57.802507  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.1368 (* 1 = 0.1368 loss)
I0625 23:00:57.802510  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244317 (* 1 = 0.0244317 loss)
I0625 23:00:57.802515  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.057622 (* 1 = 0.057622 loss)
I0625 23:00:57.802518  6673 sgd_solver.cpp:106] Iteration 5880, lr = 0.0002
I0625 23:02:37.240146  6673 solver.cpp:228] Iteration 5900, loss = 0.402141
I0625 23:02:37.240176  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 23:02:37.240187  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205199 (* 1 = 0.0205199 loss)
I0625 23:02:37.240192  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0608181 (* 1 = 0.0608181 loss)
I0625 23:02:37.240198  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000483517 (* 1 = 0.000483517 loss)
I0625 23:02:37.240203  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00791253 (* 1 = 0.00791253 loss)
I0625 23:02:37.240209  6673 sgd_solver.cpp:106] Iteration 5900, lr = 0.0002
I0625 23:04:16.318967  6673 solver.cpp:228] Iteration 5920, loss = 0.433689
I0625 23:04:16.318994  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 23:04:16.319001  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.108698 (* 1 = 0.108698 loss)
I0625 23:04:16.319006  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.153673 (* 1 = 0.153673 loss)
I0625 23:04:16.319010  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350641 (* 1 = 0.00350641 loss)
I0625 23:04:16.319015  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167248 (* 1 = 0.0167248 loss)
I0625 23:04:16.319018  6673 sgd_solver.cpp:106] Iteration 5920, lr = 0.0002
I0625 23:05:55.435631  6673 solver.cpp:228] Iteration 5940, loss = 0.236731
I0625 23:05:55.435653  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 23:05:55.435662  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000222694 (* 1 = 0.000222694 loss)
I0625 23:05:55.435665  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0701843 (* 1 = 0.0701843 loss)
I0625 23:05:55.435670  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139418 (* 1 = 0.0139418 loss)
I0625 23:05:55.435673  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216226 (* 1 = 0.0216226 loss)
I0625 23:05:55.435678  6673 sgd_solver.cpp:106] Iteration 5940, lr = 0.0002
I0625 23:07:34.745851  6673 solver.cpp:228] Iteration 5960, loss = 0.345315
I0625 23:07:34.745875  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:07:34.745882  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437939 (* 1 = 0.0437939 loss)
I0625 23:07:34.745887  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.135763 (* 1 = 0.135763 loss)
I0625 23:07:34.745892  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235317 (* 1 = 0.00235317 loss)
I0625 23:07:34.745894  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122058 (* 1 = 0.0122058 loss)
I0625 23:07:34.745899  6673 sgd_solver.cpp:106] Iteration 5960, lr = 0.0002
I0625 23:09:13.860640  6673 solver.cpp:228] Iteration 5980, loss = 0.215202
I0625 23:09:13.860662  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 23:09:13.860669  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182942 (* 1 = 0.0182942 loss)
I0625 23:09:13.860673  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0767551 (* 1 = 0.0767551 loss)
I0625 23:09:13.860677  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00155244 (* 1 = 0.00155244 loss)
I0625 23:09:13.860680  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.003339 (* 1 = 0.003339 loss)
I0625 23:09:13.860685  6673 sgd_solver.cpp:106] Iteration 5980, lr = 0.0002
speed: 4.911s / iter
I0625 23:10:52.961166  6673 solver.cpp:228] Iteration 6000, loss = 0.263563
I0625 23:10:52.961190  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 23:10:52.961197  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325369 (* 1 = 0.0325369 loss)
I0625 23:10:52.961201  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.132458 (* 1 = 0.132458 loss)
I0625 23:10:52.961205  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000790838 (* 1 = 0.000790838 loss)
I0625 23:10:52.961208  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00467157 (* 1 = 0.00467157 loss)
I0625 23:10:52.961212  6673 sgd_solver.cpp:106] Iteration 6000, lr = 0.0002
I0625 23:12:31.760745  6673 solver.cpp:228] Iteration 6020, loss = 0.394602
I0625 23:12:31.760768  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0625 23:12:31.760776  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0209288 (* 1 = 0.0209288 loss)
I0625 23:12:31.760779  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0369186 (* 1 = 0.0369186 loss)
I0625 23:12:31.760782  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0001674 (* 1 = 0.0001674 loss)
I0625 23:12:31.760787  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00531435 (* 1 = 0.00531435 loss)
I0625 23:12:31.760790  6673 sgd_solver.cpp:106] Iteration 6020, lr = 0.0002
I0625 23:14:10.357931  6673 solver.cpp:228] Iteration 6040, loss = 0.23292
I0625 23:14:10.357957  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0625 23:14:10.357964  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0585829 (* 1 = 0.0585829 loss)
I0625 23:14:10.357969  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.141161 (* 1 = 0.141161 loss)
I0625 23:14:10.357973  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000703428 (* 1 = 0.000703428 loss)
I0625 23:14:10.357977  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00642715 (* 1 = 0.00642715 loss)
I0625 23:14:10.357981  6673 sgd_solver.cpp:106] Iteration 6040, lr = 0.0002
I0625 23:15:48.898926  6673 solver.cpp:228] Iteration 6060, loss = 0.286816
I0625 23:15:48.898953  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:15:48.898963  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447371 (* 1 = 0.0447371 loss)
I0625 23:15:48.898970  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0871022 (* 1 = 0.0871022 loss)
I0625 23:15:48.898977  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000386315 (* 1 = 0.000386315 loss)
I0625 23:15:48.898983  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00969412 (* 1 = 0.00969412 loss)
I0625 23:15:48.898990  6673 sgd_solver.cpp:106] Iteration 6060, lr = 0.0002
I0625 23:17:27.333595  6673 solver.cpp:228] Iteration 6080, loss = 0.622329
I0625 23:17:27.333624  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 23:17:27.333631  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.126948 (* 1 = 0.126948 loss)
I0625 23:17:27.333636  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.273238 (* 1 = 0.273238 loss)
I0625 23:17:27.333640  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00613431 (* 1 = 0.00613431 loss)
I0625 23:17:27.333644  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211161 (* 1 = 0.0211161 loss)
I0625 23:17:27.333649  6673 sgd_solver.cpp:106] Iteration 6080, lr = 0.0002
I0625 23:19:05.764338  6673 solver.cpp:228] Iteration 6100, loss = 0.458552
I0625 23:19:05.764362  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0625 23:19:05.764369  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.332731 (* 1 = 0.332731 loss)
I0625 23:19:05.764374  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.57838 (* 1 = 0.57838 loss)
I0625 23:19:05.764377  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00837481 (* 1 = 0.00837481 loss)
I0625 23:19:05.764380  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0522951 (* 1 = 0.0522951 loss)
I0625 23:19:05.764385  6673 sgd_solver.cpp:106] Iteration 6100, lr = 0.0002
I0625 23:20:44.308449  6673 solver.cpp:228] Iteration 6120, loss = 0.358009
I0625 23:20:44.308473  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:20:44.308480  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566072 (* 1 = 0.0566072 loss)
I0625 23:20:44.308485  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138099 (* 1 = 0.138099 loss)
I0625 23:20:44.308487  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000352615 (* 1 = 0.000352615 loss)
I0625 23:20:44.308491  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00356125 (* 1 = 0.00356125 loss)
I0625 23:20:44.308496  6673 sgd_solver.cpp:106] Iteration 6120, lr = 0.0002
I0625 23:22:22.770423  6673 solver.cpp:228] Iteration 6140, loss = 0.263365
I0625 23:22:22.770449  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0625 23:22:22.770457  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174518 (* 1 = 0.0174518 loss)
I0625 23:22:22.770462  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.11139 (* 1 = 0.11139 loss)
I0625 23:22:22.770465  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00787103 (* 1 = 0.00787103 loss)
I0625 23:22:22.770469  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125555 (* 1 = 0.0125555 loss)
I0625 23:22:22.770474  6673 sgd_solver.cpp:106] Iteration 6140, lr = 0.0002
I0625 23:24:01.343469  6673 solver.cpp:228] Iteration 6160, loss = 0.272503
I0625 23:24:01.343495  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 23:24:01.343503  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628019 (* 1 = 0.0628019 loss)
I0625 23:24:01.343508  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.263491 (* 1 = 0.263491 loss)
I0625 23:24:01.343511  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00943131 (* 1 = 0.00943131 loss)
I0625 23:24:01.343515  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0080841 (* 1 = 0.0080841 loss)
I0625 23:24:01.343519  6673 sgd_solver.cpp:106] Iteration 6160, lr = 0.0002
I0625 23:25:40.002956  6673 solver.cpp:228] Iteration 6180, loss = 0.314684
I0625 23:25:40.002981  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0625 23:25:40.002987  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.106346 (* 1 = 0.106346 loss)
I0625 23:25:40.002991  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.196678 (* 1 = 0.196678 loss)
I0625 23:25:40.002995  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00312494 (* 1 = 0.00312494 loss)
I0625 23:25:40.002998  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304872 (* 1 = 0.0304872 loss)
I0625 23:25:40.003002  6673 sgd_solver.cpp:106] Iteration 6180, lr = 0.0002
speed: 4.911s / iter
I0625 23:27:18.637713  6673 solver.cpp:228] Iteration 6200, loss = 0.477607
I0625 23:27:18.637737  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0625 23:27:18.637744  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513154 (* 1 = 0.0513154 loss)
I0625 23:27:18.637749  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.398214 (* 1 = 0.398214 loss)
I0625 23:27:18.637753  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00426742 (* 1 = 0.00426742 loss)
I0625 23:27:18.637758  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00929266 (* 1 = 0.00929266 loss)
I0625 23:27:18.637761  6673 sgd_solver.cpp:106] Iteration 6200, lr = 0.0002
I0625 23:28:57.382174  6673 solver.cpp:228] Iteration 6220, loss = 0.398497
I0625 23:28:57.382199  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0625 23:28:57.382208  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00858032 (* 1 = 0.00858032 loss)
I0625 23:28:57.382215  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0386867 (* 1 = 0.0386867 loss)
I0625 23:28:57.382220  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00306417 (* 1 = 0.00306417 loss)
I0625 23:28:57.382225  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00513669 (* 1 = 0.00513669 loss)
I0625 23:28:57.382232  6673 sgd_solver.cpp:106] Iteration 6220, lr = 0.0002
I0625 23:30:36.279865  6673 solver.cpp:228] Iteration 6240, loss = 0.318214
I0625 23:30:36.279889  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0625 23:30:36.279896  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.222747 (* 1 = 0.222747 loss)
I0625 23:30:36.279901  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.60292 (* 1 = 0.60292 loss)
I0625 23:30:36.279906  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165293 (* 1 = 0.0165293 loss)
I0625 23:30:36.279908  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296558 (* 1 = 0.0296558 loss)
I0625 23:30:36.279913  6673 sgd_solver.cpp:106] Iteration 6240, lr = 0.0002
I0625 23:32:14.997169  6673 solver.cpp:228] Iteration 6260, loss = 0.243738
I0625 23:32:14.997193  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0625 23:32:14.997200  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322425 (* 1 = 0.0322425 loss)
I0625 23:32:14.997205  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.178855 (* 1 = 0.178855 loss)
I0625 23:32:14.997210  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00389086 (* 1 = 0.00389086 loss)
I0625 23:32:14.997212  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241932 (* 1 = 0.0241932 loss)
I0625 23:32:14.997218  6673 sgd_solver.cpp:106] Iteration 6260, lr = 0.0002
I0625 23:33:54.052225  6673 solver.cpp:228] Iteration 6280, loss = 0.320702
I0625 23:33:54.052250  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:33:54.052258  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.116267 (* 1 = 0.116267 loss)
I0625 23:33:54.052264  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.173874 (* 1 = 0.173874 loss)
I0625 23:33:54.052269  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00687287 (* 1 = 0.00687287 loss)
I0625 23:33:54.052275  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414068 (* 1 = 0.0414068 loss)
I0625 23:33:54.052281  6673 sgd_solver.cpp:106] Iteration 6280, lr = 0.0002
I0625 23:35:32.873618  6673 solver.cpp:228] Iteration 6300, loss = 0.230356
I0625 23:35:32.873643  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 23:35:32.873651  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.112849 (* 1 = 0.112849 loss)
I0625 23:35:32.873656  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.261554 (* 1 = 0.261554 loss)
I0625 23:35:32.873659  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231128 (* 1 = 0.00231128 loss)
I0625 23:35:32.873662  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183768 (* 1 = 0.0183768 loss)
I0625 23:35:32.873667  6673 sgd_solver.cpp:106] Iteration 6300, lr = 0.0002
I0625 23:37:11.733886  6673 solver.cpp:228] Iteration 6320, loss = 0.365947
I0625 23:37:11.733911  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0625 23:37:11.733917  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.196669 (* 1 = 0.196669 loss)
I0625 23:37:11.733922  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.231319 (* 1 = 0.231319 loss)
I0625 23:37:11.733925  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336196 (* 1 = 0.00336196 loss)
I0625 23:37:11.733928  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133807 (* 1 = 0.0133807 loss)
I0625 23:37:11.733932  6673 sgd_solver.cpp:106] Iteration 6320, lr = 0.0002
I0625 23:38:50.637501  6673 solver.cpp:228] Iteration 6340, loss = 0.214766
I0625 23:38:50.637526  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:38:50.637533  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400602 (* 1 = 0.0400602 loss)
I0625 23:38:50.637537  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0972549 (* 1 = 0.0972549 loss)
I0625 23:38:50.637542  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101314 (* 1 = 0.00101314 loss)
I0625 23:38:50.637545  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00313412 (* 1 = 0.00313412 loss)
I0625 23:38:50.637550  6673 sgd_solver.cpp:106] Iteration 6340, lr = 0.0002
I0625 23:40:30.372164  6673 solver.cpp:228] Iteration 6360, loss = 0.297328
I0625 23:40:30.372190  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0625 23:40:30.372198  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.104554 (* 1 = 0.104554 loss)
I0625 23:40:30.372203  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.249571 (* 1 = 0.249571 loss)
I0625 23:40:30.372208  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00214831 (* 1 = 0.00214831 loss)
I0625 23:40:30.372213  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119744 (* 1 = 0.0119744 loss)
I0625 23:40:30.372218  6673 sgd_solver.cpp:106] Iteration 6360, lr = 0.0002
I0625 23:42:09.868463  6673 solver.cpp:228] Iteration 6380, loss = 0.225644
I0625 23:42:09.868487  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:42:09.868494  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187389 (* 1 = 0.0187389 loss)
I0625 23:42:09.868499  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0699631 (* 1 = 0.0699631 loss)
I0625 23:42:09.868502  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0635779 (* 1 = 0.0635779 loss)
I0625 23:42:09.868505  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0793784 (* 1 = 0.0793784 loss)
I0625 23:42:09.868510  6673 sgd_solver.cpp:106] Iteration 6380, lr = 0.0002
speed: 4.912s / iter
I0625 23:43:49.693848  6673 solver.cpp:228] Iteration 6400, loss = 0.356743
I0625 23:43:49.693876  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0625 23:43:49.693886  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.087148 (* 1 = 0.087148 loss)
I0625 23:43:49.693892  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.217873 (* 1 = 0.217873 loss)
I0625 23:43:49.693899  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118887 (* 1 = 0.0118887 loss)
I0625 23:43:49.693907  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114054 (* 1 = 0.0114054 loss)
I0625 23:43:49.693917  6673 sgd_solver.cpp:106] Iteration 6400, lr = 0.0002
I0625 23:45:29.149000  6673 solver.cpp:228] Iteration 6420, loss = 0.351556
I0625 23:45:29.149025  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0625 23:45:29.149034  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390092 (* 1 = 0.0390092 loss)
I0625 23:45:29.149039  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.113844 (* 1 = 0.113844 loss)
I0625 23:45:29.149045  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204933 (* 1 = 0.00204933 loss)
I0625 23:45:29.149051  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023673 (* 1 = 0.023673 loss)
I0625 23:45:29.149057  6673 sgd_solver.cpp:106] Iteration 6420, lr = 0.0002
I0625 23:47:08.897541  6673 solver.cpp:228] Iteration 6440, loss = 0.389547
I0625 23:47:08.897567  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0625 23:47:08.897574  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.119969 (* 1 = 0.119969 loss)
I0625 23:47:08.897578  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.27146 (* 1 = 0.27146 loss)
I0625 23:47:08.897583  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117884 (* 1 = 0.0117884 loss)
I0625 23:47:08.897588  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215346 (* 1 = 0.0215346 loss)
I0625 23:47:08.897593  6673 sgd_solver.cpp:106] Iteration 6440, lr = 0.0002
I0625 23:48:48.591522  6673 solver.cpp:228] Iteration 6460, loss = 0.222022
I0625 23:48:48.591552  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0625 23:48:48.591562  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0500209 (* 1 = 0.0500209 loss)
I0625 23:48:48.591567  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0402109 (* 1 = 0.0402109 loss)
I0625 23:48:48.591570  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165391 (* 1 = 0.00165391 loss)
I0625 23:48:48.591575  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00493321 (* 1 = 0.00493321 loss)
I0625 23:48:48.591581  6673 sgd_solver.cpp:106] Iteration 6460, lr = 0.0002
I0625 23:50:27.919582  6673 solver.cpp:228] Iteration 6480, loss = 0.394273
I0625 23:50:27.919612  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0625 23:50:27.919622  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437036 (* 1 = 0.0437036 loss)
I0625 23:50:27.919628  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.070958 (* 1 = 0.070958 loss)
I0625 23:50:27.919633  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000675833 (* 1 = 0.000675833 loss)
I0625 23:50:27.919638  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00830401 (* 1 = 0.00830401 loss)
I0625 23:50:27.919643  6673 sgd_solver.cpp:106] Iteration 6480, lr = 0.0002
I0625 23:52:07.338119  6673 solver.cpp:228] Iteration 6500, loss = 0.353444
I0625 23:52:07.338142  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0625 23:52:07.338150  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.07404 (* 1 = 0.07404 loss)
I0625 23:52:07.338153  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.206069 (* 1 = 0.206069 loss)
I0625 23:52:07.338156  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0220418 (* 1 = 0.0220418 loss)
I0625 23:52:07.338160  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0521134 (* 1 = 0.0521134 loss)
I0625 23:52:07.338165  6673 sgd_solver.cpp:106] Iteration 6500, lr = 0.0002
I0625 23:53:46.697465  6673 solver.cpp:228] Iteration 6520, loss = 0.242797
I0625 23:53:46.697491  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0625 23:53:46.697499  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0504264 (* 1 = 0.0504264 loss)
I0625 23:53:46.697502  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.214743 (* 1 = 0.214743 loss)
I0625 23:53:46.697506  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0090615 (* 1 = 0.0090615 loss)
I0625 23:53:46.697510  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172296 (* 1 = 0.0172296 loss)
I0625 23:53:46.697515  6673 sgd_solver.cpp:106] Iteration 6520, lr = 0.0002
I0625 23:55:25.701426  6673 solver.cpp:228] Iteration 6540, loss = 0.457186
I0625 23:55:25.701450  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0625 23:55:25.701458  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.153764 (* 1 = 0.153764 loss)
I0625 23:55:25.701462  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.389926 (* 1 = 0.389926 loss)
I0625 23:55:25.701467  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00990909 (* 1 = 0.00990909 loss)
I0625 23:55:25.701469  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218371 (* 1 = 0.0218371 loss)
I0625 23:55:25.701475  6673 sgd_solver.cpp:106] Iteration 6540, lr = 0.0002
I0625 23:57:04.961983  6673 solver.cpp:228] Iteration 6560, loss = 0.362782
I0625 23:57:04.962008  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0625 23:57:04.962015  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0694506 (* 1 = 0.0694506 loss)
I0625 23:57:04.962020  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0940643 (* 1 = 0.0940643 loss)
I0625 23:57:04.962024  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000886276 (* 1 = 0.000886276 loss)
I0625 23:57:04.962028  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133804 (* 1 = 0.0133804 loss)
I0625 23:57:04.962033  6673 sgd_solver.cpp:106] Iteration 6560, lr = 0.0002
I0625 23:58:44.018615  6673 solver.cpp:228] Iteration 6580, loss = 0.401706
I0625 23:58:44.018638  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0625 23:58:44.018646  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0917534 (* 1 = 0.0917534 loss)
I0625 23:58:44.018649  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.252566 (* 1 = 0.252566 loss)
I0625 23:58:44.018653  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123104 (* 1 = 0.0123104 loss)
I0625 23:58:44.018656  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227791 (* 1 = 0.0227791 loss)
I0625 23:58:44.018661  6673 sgd_solver.cpp:106] Iteration 6580, lr = 0.0002
speed: 4.914s / iter
I0626 00:00:22.977224  6673 solver.cpp:228] Iteration 6600, loss = 0.258574
I0626 00:00:22.977252  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 00:00:22.977258  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134244 (* 1 = 0.134244 loss)
I0626 00:00:22.977264  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.302494 (* 1 = 0.302494 loss)
I0626 00:00:22.977272  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126955 (* 1 = 0.00126955 loss)
I0626 00:00:22.977277  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117688 (* 1 = 0.0117688 loss)
I0626 00:00:22.977285  6673 sgd_solver.cpp:106] Iteration 6600, lr = 0.0002
I0626 00:02:01.574157  6673 solver.cpp:228] Iteration 6620, loss = 0.602296
I0626 00:02:01.574182  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.578125
I0626 00:02:01.574190  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.658754 (* 1 = 0.658754 loss)
I0626 00:02:01.574195  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.676752 (* 1 = 0.676752 loss)
I0626 00:02:01.574200  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197812 (* 1 = 0.0197812 loss)
I0626 00:02:01.574206  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.223425 (* 1 = 0.223425 loss)
I0626 00:02:01.574213  6673 sgd_solver.cpp:106] Iteration 6620, lr = 0.0002
I0626 00:03:39.887498  6673 solver.cpp:228] Iteration 6640, loss = 0.322931
I0626 00:03:39.887526  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 00:03:39.887532  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134936 (* 1 = 0.134936 loss)
I0626 00:03:39.887537  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.287637 (* 1 = 0.287637 loss)
I0626 00:03:39.887540  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0723533 (* 1 = 0.0723533 loss)
I0626 00:03:39.887544  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.154627 (* 1 = 0.154627 loss)
I0626 00:03:39.887549  6673 sgd_solver.cpp:106] Iteration 6640, lr = 0.0002
I0626 00:05:18.185129  6673 solver.cpp:228] Iteration 6660, loss = 0.316569
I0626 00:05:18.185155  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:05:18.185163  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0668756 (* 1 = 0.0668756 loss)
I0626 00:05:18.185169  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161401 (* 1 = 0.161401 loss)
I0626 00:05:18.185176  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00925018 (* 1 = 0.00925018 loss)
I0626 00:05:18.185180  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167341 (* 1 = 0.0167341 loss)
I0626 00:05:18.185186  6673 sgd_solver.cpp:106] Iteration 6660, lr = 0.0002
I0626 00:06:56.746992  6673 solver.cpp:228] Iteration 6680, loss = 0.263252
I0626 00:06:56.747017  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:06:56.747025  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264043 (* 1 = 0.0264043 loss)
I0626 00:06:56.747028  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138108 (* 1 = 0.138108 loss)
I0626 00:06:56.747031  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237302 (* 1 = 0.00237302 loss)
I0626 00:06:56.747035  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258984 (* 1 = 0.0258984 loss)
I0626 00:06:56.747040  6673 sgd_solver.cpp:106] Iteration 6680, lr = 0.0002
I0626 00:08:35.290890  6673 solver.cpp:228] Iteration 6700, loss = 0.28655
I0626 00:08:35.290916  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:08:35.290925  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453139 (* 1 = 0.0453139 loss)
I0626 00:08:35.290930  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0482354 (* 1 = 0.0482354 loss)
I0626 00:08:35.290933  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143477 (* 1 = 0.00143477 loss)
I0626 00:08:35.290937  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00816256 (* 1 = 0.00816256 loss)
I0626 00:08:35.290943  6673 sgd_solver.cpp:106] Iteration 6700, lr = 0.0002
I0626 00:10:13.781622  6673 solver.cpp:228] Iteration 6720, loss = 0.372015
I0626 00:10:13.781646  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 00:10:13.781653  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166848 (* 1 = 0.0166848 loss)
I0626 00:10:13.781657  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0472797 (* 1 = 0.0472797 loss)
I0626 00:10:13.781661  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0022519 (* 1 = 0.0022519 loss)
I0626 00:10:13.781663  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00325029 (* 1 = 0.00325029 loss)
I0626 00:10:13.781668  6673 sgd_solver.cpp:106] Iteration 6720, lr = 0.0002
I0626 00:11:52.358640  6673 solver.cpp:228] Iteration 6740, loss = 0.172114
I0626 00:11:52.358665  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:11:52.358674  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486619 (* 1 = 0.0486619 loss)
I0626 00:11:52.358677  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.09932 (* 1 = 0.09932 loss)
I0626 00:11:52.358681  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00043694 (* 1 = 0.00043694 loss)
I0626 00:11:52.358685  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00107711 (* 1 = 0.00107711 loss)
I0626 00:11:52.358690  6673 sgd_solver.cpp:106] Iteration 6740, lr = 0.0002
I0626 00:13:30.992341  6673 solver.cpp:228] Iteration 6760, loss = 0.39174
I0626 00:13:30.992364  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 00:13:30.992372  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.11119 (* 1 = 0.11119 loss)
I0626 00:13:30.992377  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.191556 (* 1 = 0.191556 loss)
I0626 00:13:30.992380  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000393176 (* 1 = 0.000393176 loss)
I0626 00:13:30.992384  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029426 (* 1 = 0.029426 loss)
I0626 00:13:30.992389  6673 sgd_solver.cpp:106] Iteration 6760, lr = 0.0002
I0626 00:15:09.746074  6673 solver.cpp:228] Iteration 6780, loss = 0.272383
I0626 00:15:09.746098  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 00:15:09.746109  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0788614 (* 1 = 0.0788614 loss)
I0626 00:15:09.746115  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102458 (* 1 = 0.102458 loss)
I0626 00:15:09.746121  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233506 (* 1 = 0.00233506 loss)
I0626 00:15:09.746129  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142279 (* 1 = 0.0142279 loss)
I0626 00:15:09.746135  6673 sgd_solver.cpp:106] Iteration 6780, lr = 0.0002
speed: 4.915s / iter
I0626 00:16:48.423660  6673 solver.cpp:228] Iteration 6800, loss = 0.378641
I0626 00:16:48.423682  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 00:16:48.423691  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0774406 (* 1 = 0.0774406 loss)
I0626 00:16:48.423697  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.139396 (* 1 = 0.139396 loss)
I0626 00:16:48.423703  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233223 (* 1 = 0.00233223 loss)
I0626 00:16:48.423710  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00352049 (* 1 = 0.00352049 loss)
I0626 00:16:48.423718  6673 sgd_solver.cpp:106] Iteration 6800, lr = 0.0002
I0626 00:18:27.343967  6673 solver.cpp:228] Iteration 6820, loss = 0.608265
I0626 00:18:27.343993  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 00:18:27.344002  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.255033 (* 1 = 0.255033 loss)
I0626 00:18:27.344005  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.298891 (* 1 = 0.298891 loss)
I0626 00:18:27.344009  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00241812 (* 1 = 0.00241812 loss)
I0626 00:18:27.344013  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369973 (* 1 = 0.0369973 loss)
I0626 00:18:27.344018  6673 sgd_solver.cpp:106] Iteration 6820, lr = 0.0002
I0626 00:20:06.081251  6673 solver.cpp:228] Iteration 6840, loss = 0.390908
I0626 00:20:06.081276  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 00:20:06.081285  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.11677 (* 1 = 0.11677 loss)
I0626 00:20:06.081291  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.202834 (* 1 = 0.202834 loss)
I0626 00:20:06.081296  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363903 (* 1 = 0.00363903 loss)
I0626 00:20:06.081302  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131249 (* 1 = 0.0131249 loss)
I0626 00:20:06.081308  6673 sgd_solver.cpp:106] Iteration 6840, lr = 0.0002
I0626 00:21:44.911854  6673 solver.cpp:228] Iteration 6860, loss = 0.272387
I0626 00:21:44.911877  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 00:21:44.911885  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0687232 (* 1 = 0.0687232 loss)
I0626 00:21:44.911888  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0999634 (* 1 = 0.0999634 loss)
I0626 00:21:44.911892  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139819 (* 1 = 0.0139819 loss)
I0626 00:21:44.911895  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0510607 (* 1 = 0.0510607 loss)
I0626 00:21:44.911900  6673 sgd_solver.cpp:106] Iteration 6860, lr = 0.0002
I0626 00:23:23.744860  6673 solver.cpp:228] Iteration 6880, loss = 0.322157
I0626 00:23:23.744891  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 00:23:23.744904  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371227 (* 1 = 0.0371227 loss)
I0626 00:23:23.744915  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.11158 (* 1 = 0.11158 loss)
I0626 00:23:23.744922  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00267805 (* 1 = 0.00267805 loss)
I0626 00:23:23.744933  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939935 (* 1 = 0.00939935 loss)
I0626 00:23:23.744943  6673 sgd_solver.cpp:106] Iteration 6880, lr = 0.0002
I0626 00:25:02.761546  6673 solver.cpp:228] Iteration 6900, loss = 0.184351
I0626 00:25:02.761570  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 00:25:02.761577  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440359 (* 1 = 0.0440359 loss)
I0626 00:25:02.761580  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.073143 (* 1 = 0.073143 loss)
I0626 00:25:02.761584  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00298629 (* 1 = 0.00298629 loss)
I0626 00:25:02.761587  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135104 (* 1 = 0.0135104 loss)
I0626 00:25:02.761591  6673 sgd_solver.cpp:106] Iteration 6900, lr = 0.0002
I0626 00:26:41.904345  6673 solver.cpp:228] Iteration 6920, loss = 0.322354
I0626 00:26:41.904377  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 00:26:41.904386  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175628 (* 1 = 0.0175628 loss)
I0626 00:26:41.904389  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0480144 (* 1 = 0.0480144 loss)
I0626 00:26:41.904393  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116651 (* 1 = 0.00116651 loss)
I0626 00:26:41.904398  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00263288 (* 1 = 0.00263288 loss)
I0626 00:26:41.904403  6673 sgd_solver.cpp:106] Iteration 6920, lr = 0.0002
I0626 00:28:21.429147  6673 solver.cpp:228] Iteration 6940, loss = 0.428217
I0626 00:28:21.429172  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.695312
I0626 00:28:21.429179  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.323555 (* 1 = 0.323555 loss)
I0626 00:28:21.429183  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.620877 (* 1 = 0.620877 loss)
I0626 00:28:21.429188  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196761 (* 1 = 0.0196761 loss)
I0626 00:28:21.429191  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0604892 (* 1 = 0.0604892 loss)
I0626 00:28:21.429196  6673 sgd_solver.cpp:106] Iteration 6940, lr = 0.0002
I0626 00:30:01.222575  6673 solver.cpp:228] Iteration 6960, loss = 0.344618
I0626 00:30:01.222599  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 00:30:01.222607  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441894 (* 1 = 0.0441894 loss)
I0626 00:30:01.222612  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.132246 (* 1 = 0.132246 loss)
I0626 00:30:01.222616  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00786002 (* 1 = 0.00786002 loss)
I0626 00:30:01.222620  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401173 (* 1 = 0.0401173 loss)
I0626 00:30:01.222625  6673 sgd_solver.cpp:106] Iteration 6960, lr = 0.0002
I0626 00:31:41.042098  6673 solver.cpp:228] Iteration 6980, loss = 0.42685
I0626 00:31:41.042122  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:31:41.042129  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0217623 (* 1 = 0.0217623 loss)
I0626 00:31:41.042134  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0632896 (* 1 = 0.0632896 loss)
I0626 00:31:41.042138  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403404 (* 1 = 0.00403404 loss)
I0626 00:31:41.042141  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00854452 (* 1 = 0.00854452 loss)
I0626 00:31:41.042146  6673 sgd_solver.cpp:106] Iteration 6980, lr = 0.0002
speed: 4.916s / iter
I0626 00:33:20.938501  6673 solver.cpp:228] Iteration 7000, loss = 0.395566
I0626 00:33:20.938529  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 00:33:20.938535  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105137 (* 1 = 0.105137 loss)
I0626 00:33:20.938540  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.332884 (* 1 = 0.332884 loss)
I0626 00:33:20.938544  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152544 (* 1 = 0.0152544 loss)
I0626 00:33:20.938547  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0496599 (* 1 = 0.0496599 loss)
I0626 00:33:20.938552  6673 sgd_solver.cpp:106] Iteration 7000, lr = 0.0002
I0626 00:35:00.548945  6673 solver.cpp:228] Iteration 7020, loss = 0.344476
I0626 00:35:00.548974  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0626 00:35:00.548986  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.42615 (* 1 = 0.42615 loss)
I0626 00:35:00.548993  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.620202 (* 1 = 0.620202 loss)
I0626 00:35:00.549000  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136697 (* 1 = 0.0136697 loss)
I0626 00:35:00.549008  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0836482 (* 1 = 0.0836482 loss)
I0626 00:35:00.549017  6673 sgd_solver.cpp:106] Iteration 7020, lr = 0.0002
I0626 00:36:39.833417  6673 solver.cpp:228] Iteration 7040, loss = 0.288988
I0626 00:36:39.833442  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:36:39.833451  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320974 (* 1 = 0.0320974 loss)
I0626 00:36:39.833457  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106549 (* 1 = 0.106549 loss)
I0626 00:36:39.833463  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00893589 (* 1 = 0.00893589 loss)
I0626 00:36:39.833468  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118071 (* 1 = 0.0118071 loss)
I0626 00:36:39.833474  6673 sgd_solver.cpp:106] Iteration 7040, lr = 0.0002
I0626 00:38:19.412621  6673 solver.cpp:228] Iteration 7060, loss = 0.250497
I0626 00:38:19.412647  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:38:19.412653  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0285323 (* 1 = 0.0285323 loss)
I0626 00:38:19.412658  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102118 (* 1 = 0.102118 loss)
I0626 00:38:19.412662  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807804 (* 1 = 0.00807804 loss)
I0626 00:38:19.412667  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111047 (* 1 = 0.0111047 loss)
I0626 00:38:19.412672  6673 sgd_solver.cpp:106] Iteration 7060, lr = 0.0002
I0626 00:39:58.911586  6673 solver.cpp:228] Iteration 7080, loss = 0.198412
I0626 00:39:58.911615  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 00:39:58.911628  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0365767 (* 1 = 0.0365767 loss)
I0626 00:39:58.911635  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.101369 (* 1 = 0.101369 loss)
I0626 00:39:58.911643  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178319 (* 1 = 0.0178319 loss)
I0626 00:39:58.911650  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178076 (* 1 = 0.0178076 loss)
I0626 00:39:58.911660  6673 sgd_solver.cpp:106] Iteration 7080, lr = 0.0002
I0626 00:41:38.415483  6673 solver.cpp:228] Iteration 7100, loss = 0.208565
I0626 00:41:38.415513  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 00:41:38.415520  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.176706 (* 1 = 0.176706 loss)
I0626 00:41:38.415525  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.318749 (* 1 = 0.318749 loss)
I0626 00:41:38.415530  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00549303 (* 1 = 0.00549303 loss)
I0626 00:41:38.415535  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225448 (* 1 = 0.0225448 loss)
I0626 00:41:38.415540  6673 sgd_solver.cpp:106] Iteration 7100, lr = 0.0002
I0626 00:43:17.763831  6673 solver.cpp:228] Iteration 7120, loss = 0.449622
I0626 00:43:17.763855  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 00:43:17.763862  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0914873 (* 1 = 0.0914873 loss)
I0626 00:43:17.763866  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.11061 (* 1 = 0.11061 loss)
I0626 00:43:17.763870  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00429312 (* 1 = 0.00429312 loss)
I0626 00:43:17.763873  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00258515 (* 1 = 0.00258515 loss)
I0626 00:43:17.763878  6673 sgd_solver.cpp:106] Iteration 7120, lr = 0.0002
I0626 00:44:56.890578  6673 solver.cpp:228] Iteration 7140, loss = 0.481738
I0626 00:44:56.890604  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.703125
I0626 00:44:56.890611  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.530081 (* 1 = 0.530081 loss)
I0626 00:44:56.890615  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.702548 (* 1 = 0.702548 loss)
I0626 00:44:56.890619  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152622 (* 1 = 0.0152622 loss)
I0626 00:44:56.890624  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.140487 (* 1 = 0.140487 loss)
I0626 00:44:56.890627  6673 sgd_solver.cpp:106] Iteration 7140, lr = 0.0002
I0626 00:46:35.952790  6673 solver.cpp:228] Iteration 7160, loss = 0.296887
I0626 00:46:35.952816  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 00:46:35.952823  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576326 (* 1 = 0.0576326 loss)
I0626 00:46:35.952828  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.131742 (* 1 = 0.131742 loss)
I0626 00:46:35.952832  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232315 (* 1 = 0.00232315 loss)
I0626 00:46:35.952836  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00843945 (* 1 = 0.00843945 loss)
I0626 00:46:35.952841  6673 sgd_solver.cpp:106] Iteration 7160, lr = 0.0002
I0626 00:48:14.864341  6673 solver.cpp:228] Iteration 7180, loss = 0.265124
I0626 00:48:14.864364  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 00:48:14.864372  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.396359 (* 1 = 0.396359 loss)
I0626 00:48:14.864377  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.468406 (* 1 = 0.468406 loss)
I0626 00:48:14.864380  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0707713 (* 1 = 0.0707713 loss)
I0626 00:48:14.864384  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.264529 (* 1 = 0.264529 loss)
I0626 00:48:14.864389  6673 sgd_solver.cpp:106] Iteration 7180, lr = 0.0002
speed: 4.917s / iter
I0626 00:49:53.623592  6673 solver.cpp:228] Iteration 7200, loss = 0.291763
I0626 00:49:53.623616  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 00:49:53.623625  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.2011 (* 1 = 0.2011 loss)
I0626 00:49:53.623631  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.335924 (* 1 = 0.335924 loss)
I0626 00:49:53.623636  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00289944 (* 1 = 0.00289944 loss)
I0626 00:49:53.623642  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0332777 (* 1 = 0.0332777 loss)
I0626 00:49:53.623647  6673 sgd_solver.cpp:106] Iteration 7200, lr = 0.0002
I0626 00:51:32.186287  6673 solver.cpp:228] Iteration 7220, loss = 0.200088
I0626 00:51:32.186311  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 00:51:32.186317  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0139131 (* 1 = 0.0139131 loss)
I0626 00:51:32.186321  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0453806 (* 1 = 0.0453806 loss)
I0626 00:51:32.186326  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000394398 (* 1 = 0.000394398 loss)
I0626 00:51:32.186329  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0047283 (* 1 = 0.0047283 loss)
I0626 00:51:32.186333  6673 sgd_solver.cpp:106] Iteration 7220, lr = 0.0002
I0626 00:53:10.707195  6673 solver.cpp:228] Iteration 7240, loss = 0.375931
I0626 00:53:10.707221  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 00:53:10.707228  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.148575 (* 1 = 0.148575 loss)
I0626 00:53:10.707232  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.306107 (* 1 = 0.306107 loss)
I0626 00:53:10.707237  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00153406 (* 1 = 0.00153406 loss)
I0626 00:53:10.707240  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244215 (* 1 = 0.0244215 loss)
I0626 00:53:10.707245  6673 sgd_solver.cpp:106] Iteration 7240, lr = 0.0002
I0626 00:54:49.294204  6673 solver.cpp:228] Iteration 7260, loss = 0.216291
I0626 00:54:49.294231  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 00:54:49.294239  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339881 (* 1 = 0.0339881 loss)
I0626 00:54:49.294243  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.147412 (* 1 = 0.147412 loss)
I0626 00:54:49.294247  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00388663 (* 1 = 0.00388663 loss)
I0626 00:54:49.294251  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00783913 (* 1 = 0.00783913 loss)
I0626 00:54:49.294256  6673 sgd_solver.cpp:106] Iteration 7260, lr = 0.0002
I0626 00:56:27.916777  6673 solver.cpp:228] Iteration 7280, loss = 0.422311
I0626 00:56:27.916803  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 00:56:27.916810  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.121147 (* 1 = 0.121147 loss)
I0626 00:56:27.916815  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.242183 (* 1 = 0.242183 loss)
I0626 00:56:27.916820  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106754 (* 1 = 0.0106754 loss)
I0626 00:56:27.916823  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.123577 (* 1 = 0.123577 loss)
I0626 00:56:27.916828  6673 sgd_solver.cpp:106] Iteration 7280, lr = 0.0002
I0626 00:58:06.855486  6673 solver.cpp:228] Iteration 7300, loss = 0.257666
I0626 00:58:06.855511  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 00:58:06.855518  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000169146 (* 1 = 0.000169146 loss)
I0626 00:58:06.855522  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0388721 (* 1 = 0.0388721 loss)
I0626 00:58:06.855526  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00833598 (* 1 = 0.00833598 loss)
I0626 00:58:06.855530  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184535 (* 1 = 0.0184535 loss)
I0626 00:58:06.855535  6673 sgd_solver.cpp:106] Iteration 7300, lr = 0.0002
I0626 00:59:45.419623  6673 solver.cpp:228] Iteration 7320, loss = 0.342446
I0626 00:59:45.419648  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 00:59:45.419657  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.166538 (* 1 = 0.166538 loss)
I0626 00:59:45.419662  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.388729 (* 1 = 0.388729 loss)
I0626 00:59:45.419668  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648018 (* 1 = 0.00648018 loss)
I0626 00:59:45.419673  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364652 (* 1 = 0.0364652 loss)
I0626 00:59:45.419679  6673 sgd_solver.cpp:106] Iteration 7320, lr = 0.0002
I0626 01:01:24.195713  6673 solver.cpp:228] Iteration 7340, loss = 0.233392
I0626 01:01:24.195739  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:01:24.195746  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455473 (* 1 = 0.0455473 loss)
I0626 01:01:24.195750  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0690534 (* 1 = 0.0690534 loss)
I0626 01:01:24.195755  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356495 (* 1 = 0.00356495 loss)
I0626 01:01:24.195758  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00553135 (* 1 = 0.00553135 loss)
I0626 01:01:24.195763  6673 sgd_solver.cpp:106] Iteration 7340, lr = 0.0002
I0626 01:03:02.884129  6673 solver.cpp:228] Iteration 7360, loss = 0.294524
I0626 01:03:02.884152  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:03:02.884160  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0553999 (* 1 = 0.0553999 loss)
I0626 01:03:02.884165  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100263 (* 1 = 0.100263 loss)
I0626 01:03:02.884168  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00124388 (* 1 = 0.00124388 loss)
I0626 01:03:02.884172  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136004 (* 1 = 0.0136004 loss)
I0626 01:03:02.884177  6673 sgd_solver.cpp:106] Iteration 7360, lr = 0.0002
I0626 01:04:41.844120  6673 solver.cpp:228] Iteration 7380, loss = 0.315714
I0626 01:04:41.844148  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:04:41.844158  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326858 (* 1 = 0.0326858 loss)
I0626 01:04:41.844164  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0563549 (* 1 = 0.0563549 loss)
I0626 01:04:41.844169  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000614481 (* 1 = 0.000614481 loss)
I0626 01:04:41.844174  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00911486 (* 1 = 0.00911486 loss)
I0626 01:04:41.844182  6673 sgd_solver.cpp:106] Iteration 7380, lr = 0.0002
speed: 4.918s / iter
I0626 01:06:20.731792  6673 solver.cpp:228] Iteration 7400, loss = 0.29196
I0626 01:06:20.731815  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:06:20.731823  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390324 (* 1 = 0.0390324 loss)
I0626 01:06:20.731827  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.104281 (* 1 = 0.104281 loss)
I0626 01:06:20.731830  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0014869 (* 1 = 0.0014869 loss)
I0626 01:06:20.731834  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00625138 (* 1 = 0.00625138 loss)
I0626 01:06:20.731839  6673 sgd_solver.cpp:106] Iteration 7400, lr = 0.0002
I0626 01:07:59.468716  6673 solver.cpp:228] Iteration 7420, loss = 0.282471
I0626 01:07:59.468740  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 01:07:59.468749  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.116901 (* 1 = 0.116901 loss)
I0626 01:07:59.468752  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.290432 (* 1 = 0.290432 loss)
I0626 01:07:59.468756  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103159 (* 1 = 0.0103159 loss)
I0626 01:07:59.468760  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135287 (* 1 = 0.0135287 loss)
I0626 01:07:59.468765  6673 sgd_solver.cpp:106] Iteration 7420, lr = 0.0002
I0626 01:09:38.278306  6673 solver.cpp:228] Iteration 7440, loss = 0.397564
I0626 01:09:38.278329  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:09:38.278337  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329306 (* 1 = 0.0329306 loss)
I0626 01:09:38.278340  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0735447 (* 1 = 0.0735447 loss)
I0626 01:09:38.278343  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208276 (* 1 = 0.00208276 loss)
I0626 01:09:38.278347  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00766665 (* 1 = 0.00766665 loss)
I0626 01:09:38.278352  6673 sgd_solver.cpp:106] Iteration 7440, lr = 0.0002
I0626 01:11:17.264976  6673 solver.cpp:228] Iteration 7460, loss = 0.376808
I0626 01:11:17.265002  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 01:11:17.265009  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0934597 (* 1 = 0.0934597 loss)
I0626 01:11:17.265014  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161462 (* 1 = 0.161462 loss)
I0626 01:11:17.265018  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000915421 (* 1 = 0.000915421 loss)
I0626 01:11:17.265022  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110453 (* 1 = 0.0110453 loss)
I0626 01:11:17.265027  6673 sgd_solver.cpp:106] Iteration 7460, lr = 0.0002
I0626 01:12:56.211640  6673 solver.cpp:228] Iteration 7480, loss = 0.392698
I0626 01:12:56.211663  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 01:12:56.211670  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.221649 (* 1 = 0.221649 loss)
I0626 01:12:56.211673  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.375338 (* 1 = 0.375338 loss)
I0626 01:12:56.211678  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104452 (* 1 = 0.0104452 loss)
I0626 01:12:56.211680  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369665 (* 1 = 0.0369665 loss)
I0626 01:12:56.211685  6673 sgd_solver.cpp:106] Iteration 7480, lr = 0.0002
I0626 01:14:35.348109  6673 solver.cpp:228] Iteration 7500, loss = 0.154014
I0626 01:14:35.348134  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:14:35.348143  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0398743 (* 1 = 0.0398743 loss)
I0626 01:14:35.348150  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0841004 (* 1 = 0.0841004 loss)
I0626 01:14:35.348155  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0011622 (* 1 = 0.0011622 loss)
I0626 01:14:35.348162  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00655409 (* 1 = 0.00655409 loss)
I0626 01:14:35.348170  6673 sgd_solver.cpp:106] Iteration 7500, lr = 0.0002
I0626 01:16:14.619534  6673 solver.cpp:228] Iteration 7520, loss = 0.353779
I0626 01:16:14.619559  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:16:14.619565  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.143881 (* 1 = 0.143881 loss)
I0626 01:16:14.619570  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.121253 (* 1 = 0.121253 loss)
I0626 01:16:14.619572  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00842218 (* 1 = 0.00842218 loss)
I0626 01:16:14.619576  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191129 (* 1 = 0.0191129 loss)
I0626 01:16:14.619581  6673 sgd_solver.cpp:106] Iteration 7520, lr = 0.0002
I0626 01:17:54.531234  6673 solver.cpp:228] Iteration 7540, loss = 0.313703
I0626 01:17:54.531258  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 01:17:54.531265  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134089 (* 1 = 0.134089 loss)
I0626 01:17:54.531268  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.310358 (* 1 = 0.310358 loss)
I0626 01:17:54.531272  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00934318 (* 1 = 0.00934318 loss)
I0626 01:17:54.531275  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240748 (* 1 = 0.0240748 loss)
I0626 01:17:54.531280  6673 sgd_solver.cpp:106] Iteration 7540, lr = 0.0002
I0626 01:19:34.391695  6673 solver.cpp:228] Iteration 7560, loss = 0.442662
I0626 01:19:34.391721  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0626 01:19:34.391729  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.229357 (* 1 = 0.229357 loss)
I0626 01:19:34.391733  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.38471 (* 1 = 0.38471 loss)
I0626 01:19:34.391737  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150573 (* 1 = 0.0150573 loss)
I0626 01:19:34.391741  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405227 (* 1 = 0.0405227 loss)
I0626 01:19:34.391746  6673 sgd_solver.cpp:106] Iteration 7560, lr = 0.0002
I0626 01:21:14.003228  6673 solver.cpp:228] Iteration 7580, loss = 0.258242
I0626 01:21:14.003254  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 01:21:14.003262  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.122846 (* 1 = 0.122846 loss)
I0626 01:21:14.003268  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.249602 (* 1 = 0.249602 loss)
I0626 01:21:14.003271  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0370535 (* 1 = 0.0370535 loss)
I0626 01:21:14.003274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.143051 (* 1 = 0.143051 loss)
I0626 01:21:14.003280  6673 sgd_solver.cpp:106] Iteration 7580, lr = 0.0002
speed: 4.919s / iter
I0626 01:22:53.672682  6673 solver.cpp:228] Iteration 7600, loss = 0.349561
I0626 01:22:53.672708  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 01:22:53.672716  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.113722 (* 1 = 0.113722 loss)
I0626 01:22:53.672721  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.198167 (* 1 = 0.198167 loss)
I0626 01:22:53.672726  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215162 (* 1 = 0.00215162 loss)
I0626 01:22:53.672730  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161208 (* 1 = 0.0161208 loss)
I0626 01:22:53.672735  6673 sgd_solver.cpp:106] Iteration 7600, lr = 0.0002
I0626 01:24:33.228833  6673 solver.cpp:228] Iteration 7620, loss = 0.239025
I0626 01:24:33.228859  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 01:24:33.228866  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0673711 (* 1 = 0.0673711 loss)
I0626 01:24:33.228870  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.22429 (* 1 = 0.22429 loss)
I0626 01:24:33.228875  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00822344 (* 1 = 0.00822344 loss)
I0626 01:24:33.228879  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010529 (* 1 = 0.010529 loss)
I0626 01:24:33.228883  6673 sgd_solver.cpp:106] Iteration 7620, lr = 0.0002
I0626 01:26:12.751292  6673 solver.cpp:228] Iteration 7640, loss = 0.280199
I0626 01:26:12.751317  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:26:12.751324  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0223192 (* 1 = 0.0223192 loss)
I0626 01:26:12.751328  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0590085 (* 1 = 0.0590085 loss)
I0626 01:26:12.751332  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000583314 (* 1 = 0.000583314 loss)
I0626 01:26:12.751336  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00300057 (* 1 = 0.00300057 loss)
I0626 01:26:12.751340  6673 sgd_solver.cpp:106] Iteration 7640, lr = 0.0002
I0626 01:27:52.179075  6673 solver.cpp:228] Iteration 7660, loss = 0.296059
I0626 01:27:52.179100  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 01:27:52.179111  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.292755 (* 1 = 0.292755 loss)
I0626 01:27:52.179116  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.355102 (* 1 = 0.355102 loss)
I0626 01:27:52.179122  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0066858 (* 1 = 0.0066858 loss)
I0626 01:27:52.179128  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027959 (* 1 = 0.027959 loss)
I0626 01:27:52.179136  6673 sgd_solver.cpp:106] Iteration 7660, lr = 0.0002
I0626 01:29:31.647729  6673 solver.cpp:228] Iteration 7680, loss = 0.321633
I0626 01:29:31.647753  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 01:29:31.647760  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.101961 (* 1 = 0.101961 loss)
I0626 01:29:31.647764  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.141294 (* 1 = 0.141294 loss)
I0626 01:29:31.647768  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149793 (* 1 = 0.00149793 loss)
I0626 01:29:31.647773  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233811 (* 1 = 0.0233811 loss)
I0626 01:29:31.647778  6673 sgd_solver.cpp:106] Iteration 7680, lr = 0.0002
I0626 01:31:10.850852  6673 solver.cpp:228] Iteration 7700, loss = 0.386704
I0626 01:31:10.850879  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 01:31:10.850886  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.124436 (* 1 = 0.124436 loss)
I0626 01:31:10.850890  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.135746 (* 1 = 0.135746 loss)
I0626 01:31:10.850894  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217559 (* 1 = 0.00217559 loss)
I0626 01:31:10.850898  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168487 (* 1 = 0.0168487 loss)
I0626 01:31:10.850903  6673 sgd_solver.cpp:106] Iteration 7700, lr = 0.0002
I0626 01:32:49.980895  6673 solver.cpp:228] Iteration 7720, loss = 0.267893
I0626 01:32:49.980923  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 01:32:49.980934  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331348 (* 1 = 0.0331348 loss)
I0626 01:32:49.980940  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0744983 (* 1 = 0.0744983 loss)
I0626 01:32:49.980947  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00014013 (* 1 = 0.00014013 loss)
I0626 01:32:49.980953  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570547 (* 1 = 0.00570547 loss)
I0626 01:32:49.980960  6673 sgd_solver.cpp:106] Iteration 7720, lr = 0.0002
I0626 01:34:29.206109  6673 solver.cpp:228] Iteration 7740, loss = 0.306784
I0626 01:34:29.206138  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 01:34:29.206147  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634291 (* 1 = 0.0634291 loss)
I0626 01:34:29.206151  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.149954 (* 1 = 0.149954 loss)
I0626 01:34:29.206156  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132557 (* 1 = 0.00132557 loss)
I0626 01:34:29.206161  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123429 (* 1 = 0.0123429 loss)
I0626 01:34:29.206166  6673 sgd_solver.cpp:106] Iteration 7740, lr = 0.0002
I0626 01:36:08.332000  6673 solver.cpp:228] Iteration 7760, loss = 0.220826
I0626 01:36:08.332027  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 01:36:08.332036  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758715 (* 1 = 0.0758715 loss)
I0626 01:36:08.332042  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0989726 (* 1 = 0.0989726 loss)
I0626 01:36:08.332048  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026446 (* 1 = 0.0026446 loss)
I0626 01:36:08.332053  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228011 (* 1 = 0.0228011 loss)
I0626 01:36:08.332059  6673 sgd_solver.cpp:106] Iteration 7760, lr = 0.0002
I0626 01:37:46.995261  6673 solver.cpp:228] Iteration 7780, loss = 0.339997
I0626 01:37:46.995285  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 01:37:46.995291  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0332858 (* 1 = 0.0332858 loss)
I0626 01:37:46.995296  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0812652 (* 1 = 0.0812652 loss)
I0626 01:37:46.995299  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00975916 (* 1 = 0.00975916 loss)
I0626 01:37:46.995302  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00401577 (* 1 = 0.00401577 loss)
I0626 01:37:46.995307  6673 sgd_solver.cpp:106] Iteration 7780, lr = 0.0002
speed: 4.920s / iter
I0626 01:39:25.517257  6673 solver.cpp:228] Iteration 7800, loss = 0.357975
I0626 01:39:25.517285  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 01:39:25.517292  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.106818 (* 1 = 0.106818 loss)
I0626 01:39:25.517297  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138895 (* 1 = 0.138895 loss)
I0626 01:39:25.517300  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00177044 (* 1 = 0.00177044 loss)
I0626 01:39:25.517304  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00847801 (* 1 = 0.00847801 loss)
I0626 01:39:25.517309  6673 sgd_solver.cpp:106] Iteration 7800, lr = 0.0002
I0626 01:41:04.135454  6673 solver.cpp:228] Iteration 7820, loss = 0.191127
I0626 01:41:04.135479  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 01:41:04.135488  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454857 (* 1 = 0.0454857 loss)
I0626 01:41:04.135491  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.139916 (* 1 = 0.139916 loss)
I0626 01:41:04.135495  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000267952 (* 1 = 0.000267952 loss)
I0626 01:41:04.135499  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0047876 (* 1 = 0.0047876 loss)
I0626 01:41:04.135504  6673 sgd_solver.cpp:106] Iteration 7820, lr = 0.0002
I0626 01:42:42.622499  6673 solver.cpp:228] Iteration 7840, loss = 0.193216
I0626 01:42:42.622524  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 01:42:42.622530  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0546113 (* 1 = 0.0546113 loss)
I0626 01:42:42.622534  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.24173 (* 1 = 0.24173 loss)
I0626 01:42:42.622537  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0371284 (* 1 = 0.0371284 loss)
I0626 01:42:42.622541  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0682512 (* 1 = 0.0682512 loss)
I0626 01:42:42.622545  6673 sgd_solver.cpp:106] Iteration 7840, lr = 0.0002
I0626 01:44:21.303278  6673 solver.cpp:228] Iteration 7860, loss = 0.283831
I0626 01:44:21.303303  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 01:44:21.303310  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.145469 (* 1 = 0.145469 loss)
I0626 01:44:21.303314  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.285917 (* 1 = 0.285917 loss)
I0626 01:44:21.303318  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00648069 (* 1 = 0.00648069 loss)
I0626 01:44:21.303321  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402511 (* 1 = 0.0402511 loss)
I0626 01:44:21.303325  6673 sgd_solver.cpp:106] Iteration 7860, lr = 0.0002
I0626 01:46:00.171432  6673 solver.cpp:228] Iteration 7880, loss = 0.251929
I0626 01:46:00.171460  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0626 01:46:00.171471  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.210482 (* 1 = 0.210482 loss)
I0626 01:46:00.171478  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.472442 (* 1 = 0.472442 loss)
I0626 01:46:00.171483  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0444763 (* 1 = 0.0444763 loss)
I0626 01:46:00.171489  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600429 (* 1 = 0.0600429 loss)
I0626 01:46:00.171496  6673 sgd_solver.cpp:106] Iteration 7880, lr = 0.0002
I0626 01:47:38.958118  6673 solver.cpp:228] Iteration 7900, loss = 0.20599
I0626 01:47:38.958149  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 01:47:38.958160  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133314 (* 1 = 0.0133314 loss)
I0626 01:47:38.958168  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0529561 (* 1 = 0.0529561 loss)
I0626 01:47:38.958174  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00340945 (* 1 = 0.00340945 loss)
I0626 01:47:38.958180  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110303 (* 1 = 0.0110303 loss)
I0626 01:47:38.958187  6673 sgd_solver.cpp:106] Iteration 7900, lr = 0.0002
I0626 01:49:17.560302  6673 solver.cpp:228] Iteration 7920, loss = 0.248709
I0626 01:49:17.560328  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 01:49:17.560336  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291204 (* 1 = 0.0291204 loss)
I0626 01:49:17.560340  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0714843 (* 1 = 0.0714843 loss)
I0626 01:49:17.560344  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000408333 (* 1 = 0.000408333 loss)
I0626 01:49:17.560348  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00237378 (* 1 = 0.00237378 loss)
I0626 01:49:17.560353  6673 sgd_solver.cpp:106] Iteration 7920, lr = 0.0002
I0626 01:50:56.256995  6673 solver.cpp:228] Iteration 7940, loss = 0.418797
I0626 01:50:56.257019  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 01:50:56.257026  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274382 (* 1 = 0.0274382 loss)
I0626 01:50:56.257030  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.101282 (* 1 = 0.101282 loss)
I0626 01:50:56.257033  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139449 (* 1 = 0.0139449 loss)
I0626 01:50:56.257037  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00567041 (* 1 = 0.00567041 loss)
I0626 01:50:56.257041  6673 sgd_solver.cpp:106] Iteration 7940, lr = 0.0002
I0626 01:52:34.831450  6673 solver.cpp:228] Iteration 7960, loss = 0.315954
I0626 01:52:34.831478  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 01:52:34.831486  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.034112 (* 1 = 0.034112 loss)
I0626 01:52:34.831490  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.105595 (* 1 = 0.105595 loss)
I0626 01:52:34.831495  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000326681 (* 1 = 0.000326681 loss)
I0626 01:52:34.831498  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00633946 (* 1 = 0.00633946 loss)
I0626 01:52:34.831504  6673 sgd_solver.cpp:106] Iteration 7960, lr = 0.0002
I0626 01:54:13.726372  6673 solver.cpp:228] Iteration 7980, loss = 0.319076
I0626 01:54:13.726397  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0626 01:54:13.726404  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.212073 (* 1 = 0.212073 loss)
I0626 01:54:13.726408  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.472312 (* 1 = 0.472312 loss)
I0626 01:54:13.726411  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263387 (* 1 = 0.0263387 loss)
I0626 01:54:13.726414  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0437015 (* 1 = 0.0437015 loss)
I0626 01:54:13.726419  6673 sgd_solver.cpp:106] Iteration 7980, lr = 0.0002
speed: 4.920s / iter
I0626 01:55:52.451947  6673 solver.cpp:228] Iteration 8000, loss = 0.44865
I0626 01:55:52.451972  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 01:55:52.451979  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134225 (* 1 = 0.134225 loss)
I0626 01:55:52.451983  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.272197 (* 1 = 0.272197 loss)
I0626 01:55:52.451987  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023643 (* 1 = 0.023643 loss)
I0626 01:55:52.451992  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.139842 (* 1 = 0.139842 loss)
I0626 01:55:52.451995  6673 sgd_solver.cpp:106] Iteration 8000, lr = 0.0002
I0626 01:57:31.486001  6673 solver.cpp:228] Iteration 8020, loss = 0.538184
I0626 01:57:31.486028  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0626 01:57:31.486037  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.367314 (* 1 = 0.367314 loss)
I0626 01:57:31.486043  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.681854 (* 1 = 0.681854 loss)
I0626 01:57:31.486049  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0337256 (* 1 = 0.0337256 loss)
I0626 01:57:31.486055  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191342 (* 1 = 0.191342 loss)
I0626 01:57:31.486062  6673 sgd_solver.cpp:106] Iteration 8020, lr = 0.0002
I0626 01:59:10.296950  6673 solver.cpp:228] Iteration 8040, loss = 0.260156
I0626 01:59:10.296974  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 01:59:10.296983  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0612083 (* 1 = 0.0612083 loss)
I0626 01:59:10.296986  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.16168 (* 1 = 0.16168 loss)
I0626 01:59:10.296990  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00732165 (* 1 = 0.00732165 loss)
I0626 01:59:10.296994  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01073 (* 1 = 0.01073 loss)
I0626 01:59:10.296999  6673 sgd_solver.cpp:106] Iteration 8040, lr = 0.0002
I0626 02:00:49.210222  6673 solver.cpp:228] Iteration 8060, loss = 0.253363
I0626 02:00:49.210245  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 02:00:49.210253  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0249713 (* 1 = 0.0249713 loss)
I0626 02:00:49.210256  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0619406 (* 1 = 0.0619406 loss)
I0626 02:00:49.210259  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0042886 (* 1 = 0.0042886 loss)
I0626 02:00:49.210263  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00798437 (* 1 = 0.00798437 loss)
I0626 02:00:49.210268  6673 sgd_solver.cpp:106] Iteration 8060, lr = 0.0002
I0626 02:02:28.293543  6673 solver.cpp:228] Iteration 8080, loss = 0.203384
I0626 02:02:28.293573  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 02:02:28.293581  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0111301 (* 1 = 0.0111301 loss)
I0626 02:02:28.293584  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0254036 (* 1 = 0.0254036 loss)
I0626 02:02:28.293588  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000277951 (* 1 = 0.000277951 loss)
I0626 02:02:28.293592  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00722024 (* 1 = 0.00722024 loss)
I0626 02:02:28.293597  6673 sgd_solver.cpp:106] Iteration 8080, lr = 0.0002
I0626 02:04:07.910869  6673 solver.cpp:228] Iteration 8100, loss = 0.408941
I0626 02:04:07.910894  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 02:04:07.910902  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.157081 (* 1 = 0.157081 loss)
I0626 02:04:07.910905  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.274702 (* 1 = 0.274702 loss)
I0626 02:04:07.910909  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106977 (* 1 = 0.0106977 loss)
I0626 02:04:07.910913  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037453 (* 1 = 0.037453 loss)
I0626 02:04:07.910918  6673 sgd_solver.cpp:106] Iteration 8100, lr = 0.0002
I0626 02:05:47.918049  6673 solver.cpp:228] Iteration 8120, loss = 0.303965
I0626 02:05:47.918074  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 02:05:47.918084  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.282751 (* 1 = 0.282751 loss)
I0626 02:05:47.918089  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.255108 (* 1 = 0.255108 loss)
I0626 02:05:47.918094  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00452278 (* 1 = 0.00452278 loss)
I0626 02:05:47.918100  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281166 (* 1 = 0.0281166 loss)
I0626 02:05:47.918107  6673 sgd_solver.cpp:106] Iteration 8120, lr = 0.0002
I0626 02:07:27.541841  6673 solver.cpp:228] Iteration 8140, loss = 0.256964
I0626 02:07:27.541868  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:07:27.541877  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203452 (* 1 = 0.0203452 loss)
I0626 02:07:27.541882  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0916486 (* 1 = 0.0916486 loss)
I0626 02:07:27.541887  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000191616 (* 1 = 0.000191616 loss)
I0626 02:07:27.541891  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00395821 (* 1 = 0.00395821 loss)
I0626 02:07:27.541896  6673 sgd_solver.cpp:106] Iteration 8140, lr = 0.0002
I0626 02:09:07.257583  6673 solver.cpp:228] Iteration 8160, loss = 0.22334
I0626 02:09:07.257606  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:09:07.257614  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485667 (* 1 = 0.0485667 loss)
I0626 02:09:07.257618  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0861772 (* 1 = 0.0861772 loss)
I0626 02:09:07.257622  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102236 (* 1 = 0.00102236 loss)
I0626 02:09:07.257625  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133911 (* 1 = 0.0133911 loss)
I0626 02:09:07.257629  6673 sgd_solver.cpp:106] Iteration 8160, lr = 0.0002
I0626 02:10:46.893448  6673 solver.cpp:228] Iteration 8180, loss = 0.301491
I0626 02:10:46.893476  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 02:10:46.893482  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187056 (* 1 = 0.0187056 loss)
I0626 02:10:46.893486  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0813418 (* 1 = 0.0813418 loss)
I0626 02:10:46.893491  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208284 (* 1 = 0.00208284 loss)
I0626 02:10:46.893494  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00635268 (* 1 = 0.00635268 loss)
I0626 02:10:46.893498  6673 sgd_solver.cpp:106] Iteration 8180, lr = 0.0002
speed: 4.922s / iter
I0626 02:12:26.420106  6673 solver.cpp:228] Iteration 8200, loss = 0.227895
I0626 02:12:26.420130  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 02:12:26.420141  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0728063 (* 1 = 0.0728063 loss)
I0626 02:12:26.420147  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0990868 (* 1 = 0.0990868 loss)
I0626 02:12:26.420153  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149774 (* 1 = 0.00149774 loss)
I0626 02:12:26.420161  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00730047 (* 1 = 0.00730047 loss)
I0626 02:12:26.420168  6673 sgd_solver.cpp:106] Iteration 8200, lr = 0.0002
I0626 02:14:06.030498  6673 solver.cpp:228] Iteration 8220, loss = 0.446962
I0626 02:14:06.030525  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0626 02:14:06.030534  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.292747 (* 1 = 0.292747 loss)
I0626 02:14:06.030539  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.441218 (* 1 = 0.441218 loss)
I0626 02:14:06.030542  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132842 (* 1 = 0.0132842 loss)
I0626 02:14:06.030546  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0470211 (* 1 = 0.0470211 loss)
I0626 02:14:06.030552  6673 sgd_solver.cpp:106] Iteration 8220, lr = 0.0002
I0626 02:15:45.655058  6673 solver.cpp:228] Iteration 8240, loss = 0.164444
I0626 02:15:45.655092  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:15:45.655104  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.060038 (* 1 = 0.060038 loss)
I0626 02:15:45.655112  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0798829 (* 1 = 0.0798829 loss)
I0626 02:15:45.655120  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00402544 (* 1 = 0.00402544 loss)
I0626 02:15:45.655128  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136893 (* 1 = 0.0136893 loss)
I0626 02:15:45.655136  6673 sgd_solver.cpp:106] Iteration 8240, lr = 0.0002
I0626 02:17:25.100996  6673 solver.cpp:228] Iteration 8260, loss = 0.142372
I0626 02:17:25.101019  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:17:25.101027  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0785233 (* 1 = 0.0785233 loss)
I0626 02:17:25.101030  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.129698 (* 1 = 0.129698 loss)
I0626 02:17:25.101034  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137481 (* 1 = 0.00137481 loss)
I0626 02:17:25.101037  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00664554 (* 1 = 0.00664554 loss)
I0626 02:17:25.101042  6673 sgd_solver.cpp:106] Iteration 8260, lr = 0.0002
I0626 02:19:04.397284  6673 solver.cpp:228] Iteration 8280, loss = 0.404414
I0626 02:19:04.397311  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0626 02:19:04.397320  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.308151 (* 1 = 0.308151 loss)
I0626 02:19:04.397326  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.496837 (* 1 = 0.496837 loss)
I0626 02:19:04.397332  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196142 (* 1 = 0.0196142 loss)
I0626 02:19:04.397338  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0539197 (* 1 = 0.0539197 loss)
I0626 02:19:04.397346  6673 sgd_solver.cpp:106] Iteration 8280, lr = 0.0002
I0626 02:20:43.500370  6673 solver.cpp:228] Iteration 8300, loss = 0.246983
I0626 02:20:43.500402  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:20:43.500416  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.050787 (* 1 = 0.050787 loss)
I0626 02:20:43.500424  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.119464 (* 1 = 0.119464 loss)
I0626 02:20:43.500432  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0033725 (* 1 = 0.0033725 loss)
I0626 02:20:43.500442  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0290946 (* 1 = 0.0290946 loss)
I0626 02:20:43.500449  6673 sgd_solver.cpp:106] Iteration 8300, lr = 0.0002
I0626 02:22:22.849555  6673 solver.cpp:228] Iteration 8320, loss = 0.19712
I0626 02:22:22.849580  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:22:22.849587  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0192094 (* 1 = 0.0192094 loss)
I0626 02:22:22.849591  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0872669 (* 1 = 0.0872669 loss)
I0626 02:22:22.849596  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276835 (* 1 = 0.00276835 loss)
I0626 02:22:22.849599  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205299 (* 1 = 0.0205299 loss)
I0626 02:22:22.849604  6673 sgd_solver.cpp:106] Iteration 8320, lr = 0.0002
I0626 02:24:01.673723  6673 solver.cpp:228] Iteration 8340, loss = 0.468274
I0626 02:24:01.673749  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:24:01.673756  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0223884 (* 1 = 0.0223884 loss)
I0626 02:24:01.673760  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0391563 (* 1 = 0.0391563 loss)
I0626 02:24:01.673764  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000908061 (* 1 = 0.000908061 loss)
I0626 02:24:01.673768  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00164081 (* 1 = 0.00164081 loss)
I0626 02:24:01.673774  6673 sgd_solver.cpp:106] Iteration 8340, lr = 0.0002
I0626 02:25:40.380671  6673 solver.cpp:228] Iteration 8360, loss = 0.28695
I0626 02:25:40.380697  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:25:40.380705  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268171 (* 1 = 0.0268171 loss)
I0626 02:25:40.380710  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0797271 (* 1 = 0.0797271 loss)
I0626 02:25:40.380713  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301776 (* 1 = 0.00301776 loss)
I0626 02:25:40.380717  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00464954 (* 1 = 0.00464954 loss)
I0626 02:25:40.380722  6673 sgd_solver.cpp:106] Iteration 8360, lr = 0.0002
I0626 02:27:19.142861  6673 solver.cpp:228] Iteration 8380, loss = 0.25293
I0626 02:27:19.142885  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 02:27:19.142892  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000619195 (* 1 = 0.000619195 loss)
I0626 02:27:19.142896  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.059118 (* 1 = 0.059118 loss)
I0626 02:27:19.142900  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026935 (* 1 = 0.026935 loss)
I0626 02:27:19.142904  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00821222 (* 1 = 0.00821222 loss)
I0626 02:27:19.142908  6673 sgd_solver.cpp:106] Iteration 8380, lr = 0.0002
speed: 4.922s / iter
I0626 02:28:57.755208  6673 solver.cpp:228] Iteration 8400, loss = 0.595749
I0626 02:28:57.755234  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 02:28:57.755240  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.117646 (* 1 = 0.117646 loss)
I0626 02:28:57.755244  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.180384 (* 1 = 0.180384 loss)
I0626 02:28:57.755249  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139911 (* 1 = 0.00139911 loss)
I0626 02:28:57.755252  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114846 (* 1 = 0.0114846 loss)
I0626 02:28:57.755257  6673 sgd_solver.cpp:106] Iteration 8400, lr = 0.0002
I0626 02:30:36.382808  6673 solver.cpp:228] Iteration 8420, loss = 0.206087
I0626 02:30:36.382833  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 02:30:36.382839  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182564 (* 1 = 0.0182564 loss)
I0626 02:30:36.382843  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0892284 (* 1 = 0.0892284 loss)
I0626 02:30:36.382848  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159939 (* 1 = 0.0159939 loss)
I0626 02:30:36.382850  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171303 (* 1 = 0.0171303 loss)
I0626 02:30:36.382854  6673 sgd_solver.cpp:106] Iteration 8420, lr = 0.0002
I0626 02:32:14.960409  6673 solver.cpp:228] Iteration 8440, loss = 0.269515
I0626 02:32:14.960435  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 02:32:14.960441  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.122658 (* 1 = 0.122658 loss)
I0626 02:32:14.960446  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.32803 (* 1 = 0.32803 loss)
I0626 02:32:14.960449  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182415 (* 1 = 0.0182415 loss)
I0626 02:32:14.960453  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.135683 (* 1 = 0.135683 loss)
I0626 02:32:14.960458  6673 sgd_solver.cpp:106] Iteration 8440, lr = 0.0002
I0626 02:33:53.614907  6673 solver.cpp:228] Iteration 8460, loss = 0.423904
I0626 02:33:53.614931  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0626 02:33:53.614939  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.46335 (* 1 = 0.46335 loss)
I0626 02:33:53.614943  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.626823 (* 1 = 0.626823 loss)
I0626 02:33:53.614948  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0523116 (* 1 = 0.0523116 loss)
I0626 02:33:53.614950  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.155734 (* 1 = 0.155734 loss)
I0626 02:33:53.614955  6673 sgd_solver.cpp:106] Iteration 8460, lr = 0.0002
I0626 02:35:32.353961  6673 solver.cpp:228] Iteration 8480, loss = 0.374856
I0626 02:35:32.353986  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 02:35:32.353993  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254102 (* 1 = 0.0254102 loss)
I0626 02:35:32.353999  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.252127 (* 1 = 0.252127 loss)
I0626 02:35:32.354005  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000673635 (* 1 = 0.000673635 loss)
I0626 02:35:32.354012  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00797423 (* 1 = 0.00797423 loss)
I0626 02:35:32.354015  6673 sgd_solver.cpp:106] Iteration 8480, lr = 0.0002
I0626 02:37:11.069797  6673 solver.cpp:228] Iteration 8500, loss = 0.328202
I0626 02:37:11.069825  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 02:37:11.069838  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.130968 (* 1 = 0.130968 loss)
I0626 02:37:11.069844  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.199393 (* 1 = 0.199393 loss)
I0626 02:37:11.069850  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109516 (* 1 = 0.0109516 loss)
I0626 02:37:11.069857  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177902 (* 1 = 0.0177902 loss)
I0626 02:37:11.069864  6673 sgd_solver.cpp:106] Iteration 8500, lr = 0.0002
I0626 02:38:49.863656  6673 solver.cpp:228] Iteration 8520, loss = 0.26884
I0626 02:38:49.863680  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 02:38:49.863687  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.101405 (* 1 = 0.101405 loss)
I0626 02:38:49.863692  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.158297 (* 1 = 0.158297 loss)
I0626 02:38:49.863694  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00375944 (* 1 = 0.00375944 loss)
I0626 02:38:49.863698  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129091 (* 1 = 0.0129091 loss)
I0626 02:38:49.863703  6673 sgd_solver.cpp:106] Iteration 8520, lr = 0.0002
I0626 02:40:28.764830  6673 solver.cpp:228] Iteration 8540, loss = 0.287677
I0626 02:40:28.764853  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 02:40:28.764860  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269597 (* 1 = 0.0269597 loss)
I0626 02:40:28.764864  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0550745 (* 1 = 0.0550745 loss)
I0626 02:40:28.764868  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129791 (* 1 = 0.0129791 loss)
I0626 02:40:28.764871  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215878 (* 1 = 0.0215878 loss)
I0626 02:40:28.764876  6673 sgd_solver.cpp:106] Iteration 8540, lr = 0.0002
I0626 02:42:07.575748  6673 solver.cpp:228] Iteration 8560, loss = 0.287055
I0626 02:42:07.575773  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 02:42:07.575780  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843073 (* 1 = 0.0843073 loss)
I0626 02:42:07.575784  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.157806 (* 1 = 0.157806 loss)
I0626 02:42:07.575788  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00152984 (* 1 = 0.00152984 loss)
I0626 02:42:07.575793  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015258 (* 1 = 0.015258 loss)
I0626 02:42:07.575798  6673 sgd_solver.cpp:106] Iteration 8560, lr = 0.0002
I0626 02:43:46.417695  6673 solver.cpp:228] Iteration 8580, loss = 0.226253
I0626 02:43:46.417721  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 02:43:46.417731  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432856 (* 1 = 0.0432856 loss)
I0626 02:43:46.417737  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0848653 (* 1 = 0.0848653 loss)
I0626 02:43:46.417742  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000468575 (* 1 = 0.000468575 loss)
I0626 02:43:46.417747  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00278385 (* 1 = 0.00278385 loss)
I0626 02:43:46.417753  6673 sgd_solver.cpp:106] Iteration 8580, lr = 0.0002
speed: 4.923s / iter
I0626 02:45:25.554216  6673 solver.cpp:228] Iteration 8600, loss = 0.255725
I0626 02:45:25.554246  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 02:45:25.554255  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591923 (* 1 = 0.0591923 loss)
I0626 02:45:25.554261  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0748796 (* 1 = 0.0748796 loss)
I0626 02:45:25.554265  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194696 (* 1 = 0.00194696 loss)
I0626 02:45:25.554270  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250761 (* 1 = 0.0250761 loss)
I0626 02:45:25.554275  6673 sgd_solver.cpp:106] Iteration 8600, lr = 0.0002
I0626 02:47:04.350469  6673 solver.cpp:228] Iteration 8620, loss = 0.320184
I0626 02:47:04.350493  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 02:47:04.350502  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499987 (* 1 = 0.0499987 loss)
I0626 02:47:04.350504  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.153921 (* 1 = 0.153921 loss)
I0626 02:47:04.350508  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114129 (* 1 = 0.00114129 loss)
I0626 02:47:04.350512  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00963007 (* 1 = 0.00963007 loss)
I0626 02:47:04.350517  6673 sgd_solver.cpp:106] Iteration 8620, lr = 0.0002
I0626 02:48:43.429450  6673 solver.cpp:228] Iteration 8640, loss = 0.209226
I0626 02:48:43.429472  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 02:48:43.429479  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690909 (* 1 = 0.0690909 loss)
I0626 02:48:43.429483  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.203372 (* 1 = 0.203372 loss)
I0626 02:48:43.429486  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00571937 (* 1 = 0.00571937 loss)
I0626 02:48:43.429491  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100247 (* 1 = 0.0100247 loss)
I0626 02:48:43.429494  6673 sgd_solver.cpp:106] Iteration 8640, lr = 0.0002
I0626 02:50:22.600982  6673 solver.cpp:228] Iteration 8660, loss = 0.343058
I0626 02:50:22.601009  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 02:50:22.601019  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160265 (* 1 = 0.0160265 loss)
I0626 02:50:22.601024  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0455369 (* 1 = 0.0455369 loss)
I0626 02:50:22.601030  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000359653 (* 1 = 0.000359653 loss)
I0626 02:50:22.601037  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00736641 (* 1 = 0.00736641 loss)
I0626 02:50:22.601043  6673 sgd_solver.cpp:106] Iteration 8660, lr = 0.0002
I0626 02:52:02.124145  6673 solver.cpp:228] Iteration 8680, loss = 0.350077
I0626 02:52:02.124171  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 02:52:02.124177  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0289211 (* 1 = 0.0289211 loss)
I0626 02:52:02.124182  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0454862 (* 1 = 0.0454862 loss)
I0626 02:52:02.124186  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162952 (* 1 = 0.00162952 loss)
I0626 02:52:02.124191  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00970713 (* 1 = 0.00970713 loss)
I0626 02:52:02.124195  6673 sgd_solver.cpp:106] Iteration 8680, lr = 0.0002
I0626 02:53:41.814407  6673 solver.cpp:228] Iteration 8700, loss = 0.427866
I0626 02:53:41.814435  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 02:53:41.814441  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0350507 (* 1 = 0.0350507 loss)
I0626 02:53:41.814445  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106989 (* 1 = 0.106989 loss)
I0626 02:53:41.814450  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542762 (* 1 = 0.00542762 loss)
I0626 02:53:41.814453  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00537641 (* 1 = 0.00537641 loss)
I0626 02:53:41.814458  6673 sgd_solver.cpp:106] Iteration 8700, lr = 0.0002
I0626 02:55:21.548856  6673 solver.cpp:228] Iteration 8720, loss = 0.228796
I0626 02:55:21.548888  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 02:55:21.548897  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0700816 (* 1 = 0.0700816 loss)
I0626 02:55:21.548903  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0849001 (* 1 = 0.0849001 loss)
I0626 02:55:21.548908  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00164613 (* 1 = 0.00164613 loss)
I0626 02:55:21.548914  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00964163 (* 1 = 0.00964163 loss)
I0626 02:55:21.548920  6673 sgd_solver.cpp:106] Iteration 8720, lr = 0.0002
I0626 02:57:01.298682  6673 solver.cpp:228] Iteration 8740, loss = 0.275123
I0626 02:57:01.298707  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 02:57:01.298714  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0629356 (* 1 = 0.0629356 loss)
I0626 02:57:01.298718  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0614075 (* 1 = 0.0614075 loss)
I0626 02:57:01.298722  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253591 (* 1 = 0.00253591 loss)
I0626 02:57:01.298725  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00825502 (* 1 = 0.00825502 loss)
I0626 02:57:01.298730  6673 sgd_solver.cpp:106] Iteration 8740, lr = 0.0002
I0626 02:58:41.133348  6673 solver.cpp:228] Iteration 8760, loss = 0.537927
I0626 02:58:41.133376  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.710938
I0626 02:58:41.133385  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.47705 (* 1 = 0.47705 loss)
I0626 02:58:41.133390  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.603445 (* 1 = 0.603445 loss)
I0626 02:58:41.133394  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0418009 (* 1 = 0.0418009 loss)
I0626 02:58:41.133400  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109957 (* 1 = 0.109957 loss)
I0626 02:58:41.133405  6673 sgd_solver.cpp:106] Iteration 8760, lr = 0.0002
I0626 03:00:20.708659  6673 solver.cpp:228] Iteration 8780, loss = 0.294814
I0626 03:00:20.708683  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 03:00:20.708691  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0769369 (* 1 = 0.0769369 loss)
I0626 03:00:20.708695  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.108745 (* 1 = 0.108745 loss)
I0626 03:00:20.708699  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00124801 (* 1 = 0.00124801 loss)
I0626 03:00:20.708703  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0082251 (* 1 = 0.0082251 loss)
I0626 03:00:20.708709  6673 sgd_solver.cpp:106] Iteration 8780, lr = 0.0002
speed: 4.924s / iter
I0626 03:02:00.284723  6673 solver.cpp:228] Iteration 8800, loss = 0.188265
I0626 03:02:00.284747  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 03:02:00.284755  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.284898 (* 1 = 0.284898 loss)
I0626 03:02:00.284760  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.451586 (* 1 = 0.451586 loss)
I0626 03:02:00.284763  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376942 (* 1 = 0.00376942 loss)
I0626 03:02:00.284768  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371314 (* 1 = 0.0371314 loss)
I0626 03:02:00.284772  6673 sgd_solver.cpp:106] Iteration 8800, lr = 0.0002
I0626 03:03:39.789299  6673 solver.cpp:228] Iteration 8820, loss = 0.466099
I0626 03:03:39.789322  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 03:03:39.789330  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.262445 (* 1 = 0.262445 loss)
I0626 03:03:39.789335  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.397435 (* 1 = 0.397435 loss)
I0626 03:03:39.789338  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00319949 (* 1 = 0.00319949 loss)
I0626 03:03:39.789342  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414133 (* 1 = 0.0414133 loss)
I0626 03:03:39.789347  6673 sgd_solver.cpp:106] Iteration 8820, lr = 0.0002
I0626 03:05:19.127871  6673 solver.cpp:228] Iteration 8840, loss = 0.304265
I0626 03:05:19.127899  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 03:05:19.127909  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383388 (* 1 = 0.0383388 loss)
I0626 03:05:19.127915  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.094508 (* 1 = 0.094508 loss)
I0626 03:05:19.127921  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00080253 (* 1 = 0.00080253 loss)
I0626 03:05:19.127926  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233695 (* 1 = 0.0233695 loss)
I0626 03:05:19.127933  6673 sgd_solver.cpp:106] Iteration 8840, lr = 0.0002
I0626 03:06:58.402585  6673 solver.cpp:228] Iteration 8860, loss = 0.165151
I0626 03:06:58.402612  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:06:58.402619  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0213152 (* 1 = 0.0213152 loss)
I0626 03:06:58.402624  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0347576 (* 1 = 0.0347576 loss)
I0626 03:06:58.402627  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000250544 (* 1 = 0.000250544 loss)
I0626 03:06:58.402631  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0062309 (* 1 = 0.0062309 loss)
I0626 03:06:58.402637  6673 sgd_solver.cpp:106] Iteration 8860, lr = 0.0002
I0626 03:08:37.619846  6673 solver.cpp:228] Iteration 8880, loss = 0.240716
I0626 03:08:37.619870  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 03:08:37.619879  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0731203 (* 1 = 0.0731203 loss)
I0626 03:08:37.619882  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.159112 (* 1 = 0.159112 loss)
I0626 03:08:37.619885  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0244661 (* 1 = 0.0244661 loss)
I0626 03:08:37.619889  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040985 (* 1 = 0.040985 loss)
I0626 03:08:37.619894  6673 sgd_solver.cpp:106] Iteration 8880, lr = 0.0002
I0626 03:10:16.797662  6673 solver.cpp:228] Iteration 8900, loss = 0.225741
I0626 03:10:16.797685  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 03:10:16.797693  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.136448 (* 1 = 0.136448 loss)
I0626 03:10:16.797698  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.14788 (* 1 = 0.14788 loss)
I0626 03:10:16.797701  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00224942 (* 1 = 0.00224942 loss)
I0626 03:10:16.797705  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330462 (* 1 = 0.0330462 loss)
I0626 03:10:16.797710  6673 sgd_solver.cpp:106] Iteration 8900, lr = 0.0002
I0626 03:11:55.846513  6673 solver.cpp:228] Iteration 8920, loss = 0.300531
I0626 03:11:55.846536  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 03:11:55.846542  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0446097 (* 1 = 0.0446097 loss)
I0626 03:11:55.846546  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.191422 (* 1 = 0.191422 loss)
I0626 03:11:55.846550  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155732 (* 1 = 0.0155732 loss)
I0626 03:11:55.846554  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0568942 (* 1 = 0.0568942 loss)
I0626 03:11:55.846559  6673 sgd_solver.cpp:106] Iteration 8920, lr = 0.0002
I0626 03:13:34.714936  6673 solver.cpp:228] Iteration 8940, loss = 0.312756
I0626 03:13:34.714959  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 03:13:34.714967  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494525 (* 1 = 0.0494525 loss)
I0626 03:13:34.714970  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.174053 (* 1 = 0.174053 loss)
I0626 03:13:34.714974  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013196 (* 1 = 0.013196 loss)
I0626 03:13:34.714978  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368828 (* 1 = 0.0368828 loss)
I0626 03:13:34.714983  6673 sgd_solver.cpp:106] Iteration 8940, lr = 0.0002
I0626 03:15:13.376477  6673 solver.cpp:228] Iteration 8960, loss = 0.277374
I0626 03:15:13.376507  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 03:15:13.376518  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0604891 (* 1 = 0.0604891 loss)
I0626 03:15:13.376523  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.155952 (* 1 = 0.155952 loss)
I0626 03:15:13.376528  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138204 (* 1 = 0.0138204 loss)
I0626 03:15:13.376533  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00999175 (* 1 = 0.00999175 loss)
I0626 03:15:13.376538  6673 sgd_solver.cpp:106] Iteration 8960, lr = 0.0002
I0626 03:16:51.861366  6673 solver.cpp:228] Iteration 8980, loss = 0.240627
I0626 03:16:51.861388  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 03:16:51.861395  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155231 (* 1 = 0.0155231 loss)
I0626 03:16:51.861399  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0923173 (* 1 = 0.0923173 loss)
I0626 03:16:51.861402  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00254833 (* 1 = 0.00254833 loss)
I0626 03:16:51.861407  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0026202 (* 1 = 0.0026202 loss)
I0626 03:16:51.861410  6673 sgd_solver.cpp:106] Iteration 8980, lr = 0.0002
speed: 4.925s / iter
I0626 03:18:30.646818  6673 solver.cpp:228] Iteration 9000, loss = 0.223071
I0626 03:18:30.646842  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 03:18:30.646848  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0491938 (* 1 = 0.0491938 loss)
I0626 03:18:30.646852  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.124192 (* 1 = 0.124192 loss)
I0626 03:18:30.646857  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289717 (* 1 = 0.0289717 loss)
I0626 03:18:30.646862  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144699 (* 1 = 0.0144699 loss)
I0626 03:18:30.646867  6673 sgd_solver.cpp:106] Iteration 9000, lr = 0.0002
I0626 03:20:09.299602  6673 solver.cpp:228] Iteration 9020, loss = 0.219935
I0626 03:20:09.299626  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 03:20:09.299633  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0603627 (* 1 = 0.0603627 loss)
I0626 03:20:09.299638  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.150265 (* 1 = 0.150265 loss)
I0626 03:20:09.299640  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000984941 (* 1 = 0.000984941 loss)
I0626 03:20:09.299644  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105188 (* 1 = 0.0105188 loss)
I0626 03:20:09.299649  6673 sgd_solver.cpp:106] Iteration 9020, lr = 0.0002
I0626 03:21:47.796478  6673 solver.cpp:228] Iteration 9040, loss = 0.316374
I0626 03:21:47.796509  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 03:21:47.796517  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.115522 (* 1 = 0.115522 loss)
I0626 03:21:47.796521  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.191281 (* 1 = 0.191281 loss)
I0626 03:21:47.796525  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00346362 (* 1 = 0.00346362 loss)
I0626 03:21:47.796530  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183366 (* 1 = 0.0183366 loss)
I0626 03:21:47.796535  6673 sgd_solver.cpp:106] Iteration 9040, lr = 0.0002
I0626 03:23:26.388325  6673 solver.cpp:228] Iteration 9060, loss = 0.313119
I0626 03:23:26.388360  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 03:23:26.388367  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.205508 (* 1 = 0.205508 loss)
I0626 03:23:26.388371  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.403493 (* 1 = 0.403493 loss)
I0626 03:23:26.388375  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119564 (* 1 = 0.0119564 loss)
I0626 03:23:26.388379  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0417577 (* 1 = 0.0417577 loss)
I0626 03:23:26.388386  6673 sgd_solver.cpp:106] Iteration 9060, lr = 0.0002
I0626 03:25:05.034893  6673 solver.cpp:228] Iteration 9080, loss = 0.248373
I0626 03:25:05.034916  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 03:25:05.034922  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0692389 (* 1 = 0.0692389 loss)
I0626 03:25:05.034926  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.155427 (* 1 = 0.155427 loss)
I0626 03:25:05.034930  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.006224 (* 1 = 0.006224 loss)
I0626 03:25:05.034934  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130202 (* 1 = 0.0130202 loss)
I0626 03:25:05.034938  6673 sgd_solver.cpp:106] Iteration 9080, lr = 0.0002
I0626 03:26:43.728935  6673 solver.cpp:228] Iteration 9100, loss = 0.264309
I0626 03:26:43.728967  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 03:26:43.728976  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937635 (* 1 = 0.0937635 loss)
I0626 03:26:43.728981  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106764 (* 1 = 0.106764 loss)
I0626 03:26:43.728984  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147873 (* 1 = 0.00147873 loss)
I0626 03:26:43.728988  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211437 (* 1 = 0.0211437 loss)
I0626 03:26:43.728993  6673 sgd_solver.cpp:106] Iteration 9100, lr = 0.0002
I0626 03:28:22.653872  6673 solver.cpp:228] Iteration 9120, loss = 0.20099
I0626 03:28:22.653898  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:28:22.653904  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0213741 (* 1 = 0.0213741 loss)
I0626 03:28:22.653910  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0814356 (* 1 = 0.0814356 loss)
I0626 03:28:22.653916  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000765079 (* 1 = 0.000765079 loss)
I0626 03:28:22.653920  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512979 (* 1 = 0.00512979 loss)
I0626 03:28:22.653925  6673 sgd_solver.cpp:106] Iteration 9120, lr = 0.0002
I0626 03:30:01.577771  6673 solver.cpp:228] Iteration 9140, loss = 0.228317
I0626 03:30:01.577795  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 03:30:01.577803  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324667 (* 1 = 0.0324667 loss)
I0626 03:30:01.577807  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0962331 (* 1 = 0.0962331 loss)
I0626 03:30:01.577811  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000409153 (* 1 = 0.000409153 loss)
I0626 03:30:01.577816  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00678808 (* 1 = 0.00678808 loss)
I0626 03:30:01.577821  6673 sgd_solver.cpp:106] Iteration 9140, lr = 0.0002
I0626 03:31:40.497015  6673 solver.cpp:228] Iteration 9160, loss = 0.199574
I0626 03:31:40.497042  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 03:31:40.497051  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0651865 (* 1 = 0.0651865 loss)
I0626 03:31:40.497054  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.166687 (* 1 = 0.166687 loss)
I0626 03:31:40.497058  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00441271 (* 1 = 0.00441271 loss)
I0626 03:31:40.497062  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00682568 (* 1 = 0.00682568 loss)
I0626 03:31:40.497067  6673 sgd_solver.cpp:106] Iteration 9160, lr = 0.0002
I0626 03:33:19.565853  6673 solver.cpp:228] Iteration 9180, loss = 0.151245
I0626 03:33:19.565877  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 03:33:19.565884  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0423481 (* 1 = 0.0423481 loss)
I0626 03:33:19.565887  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0623864 (* 1 = 0.0623864 loss)
I0626 03:33:19.565891  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00067736 (* 1 = 0.00067736 loss)
I0626 03:33:19.565896  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112872 (* 1 = 0.0112872 loss)
I0626 03:33:19.565899  6673 sgd_solver.cpp:106] Iteration 9180, lr = 0.0002
speed: 4.925s / iter
I0626 03:34:58.226778  6673 solver.cpp:228] Iteration 9200, loss = 0.237275
I0626 03:34:58.226801  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 03:34:58.226810  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0559324 (* 1 = 0.0559324 loss)
I0626 03:34:58.226816  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.270429 (* 1 = 0.270429 loss)
I0626 03:34:58.226821  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00611327 (* 1 = 0.00611327 loss)
I0626 03:34:58.226827  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261379 (* 1 = 0.0261379 loss)
I0626 03:34:58.226833  6673 sgd_solver.cpp:106] Iteration 9200, lr = 0.0002
I0626 03:36:37.098702  6673 solver.cpp:228] Iteration 9220, loss = 0.349482
I0626 03:36:37.098726  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 03:36:37.098732  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.194178 (* 1 = 0.194178 loss)
I0626 03:36:37.098737  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.24593 (* 1 = 0.24593 loss)
I0626 03:36:37.098740  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191689 (* 1 = 0.00191689 loss)
I0626 03:36:37.098744  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030361 (* 1 = 0.030361 loss)
I0626 03:36:37.098749  6673 sgd_solver.cpp:106] Iteration 9220, lr = 0.0002
I0626 03:38:15.962637  6673 solver.cpp:228] Iteration 9240, loss = 0.31647
I0626 03:38:15.962663  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:38:15.962673  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222045 (* 1 = 0.0222045 loss)
I0626 03:38:15.962678  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0750511 (* 1 = 0.0750511 loss)
I0626 03:38:15.962684  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00778562 (* 1 = 0.00778562 loss)
I0626 03:38:15.962689  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112075 (* 1 = 0.0112075 loss)
I0626 03:38:15.962697  6673 sgd_solver.cpp:106] Iteration 9240, lr = 0.0002
I0626 03:39:55.419832  6673 solver.cpp:228] Iteration 9260, loss = 0.330806
I0626 03:39:55.419857  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 03:39:55.419863  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198329 (* 1 = 0.0198329 loss)
I0626 03:39:55.419867  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.043905 (* 1 = 0.043905 loss)
I0626 03:39:55.419870  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000305577 (* 1 = 0.000305577 loss)
I0626 03:39:55.419874  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000776303 (* 1 = 0.000776303 loss)
I0626 03:39:55.419878  6673 sgd_solver.cpp:106] Iteration 9260, lr = 0.0002
I0626 03:41:35.282424  6673 solver.cpp:228] Iteration 9280, loss = 0.220533
I0626 03:41:35.282449  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 03:41:35.282457  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447004 (* 1 = 0.0447004 loss)
I0626 03:41:35.282461  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.128245 (* 1 = 0.128245 loss)
I0626 03:41:35.282465  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00786683 (* 1 = 0.00786683 loss)
I0626 03:41:35.282469  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111257 (* 1 = 0.0111257 loss)
I0626 03:41:35.282474  6673 sgd_solver.cpp:106] Iteration 9280, lr = 0.0002
I0626 03:43:15.182070  6673 solver.cpp:228] Iteration 9300, loss = 0.333174
I0626 03:43:15.182093  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 03:43:15.182101  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.200987 (* 1 = 0.200987 loss)
I0626 03:43:15.182106  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.303704 (* 1 = 0.303704 loss)
I0626 03:43:15.182111  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019784 (* 1 = 0.0019784 loss)
I0626 03:43:15.182113  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251911 (* 1 = 0.0251911 loss)
I0626 03:43:15.182121  6673 sgd_solver.cpp:106] Iteration 9300, lr = 0.0002
I0626 03:44:54.844451  6673 solver.cpp:228] Iteration 9320, loss = 0.285637
I0626 03:44:54.844480  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 03:44:54.844491  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.305585 (* 1 = 0.305585 loss)
I0626 03:44:54.844496  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.356453 (* 1 = 0.356453 loss)
I0626 03:44:54.844501  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151611 (* 1 = 0.00151611 loss)
I0626 03:44:54.844506  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451947 (* 1 = 0.0451947 loss)
I0626 03:44:54.844512  6673 sgd_solver.cpp:106] Iteration 9320, lr = 0.0002
I0626 03:46:34.606550  6673 solver.cpp:228] Iteration 9340, loss = 0.244835
I0626 03:46:34.606578  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 03:46:34.606585  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.14002 (* 1 = 0.14002 loss)
I0626 03:46:34.606590  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.153042 (* 1 = 0.153042 loss)
I0626 03:46:34.606593  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00935977 (* 1 = 0.00935977 loss)
I0626 03:46:34.606596  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031372 (* 1 = 0.031372 loss)
I0626 03:46:34.606601  6673 sgd_solver.cpp:106] Iteration 9340, lr = 0.0002
I0626 03:48:14.249333  6673 solver.cpp:228] Iteration 9360, loss = 0.181144
I0626 03:48:14.249363  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 03:48:14.249372  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181303 (* 1 = 0.0181303 loss)
I0626 03:48:14.249375  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.10731 (* 1 = 0.10731 loss)
I0626 03:48:14.249379  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141375 (* 1 = 0.0141375 loss)
I0626 03:48:14.249383  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00624747 (* 1 = 0.00624747 loss)
I0626 03:48:14.249388  6673 sgd_solver.cpp:106] Iteration 9360, lr = 0.0002
I0626 03:49:53.872472  6673 solver.cpp:228] Iteration 9380, loss = 0.25376
I0626 03:49:53.872496  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 03:49:53.872503  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.014985 (* 1 = 0.014985 loss)
I0626 03:49:53.872509  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0834279 (* 1 = 0.0834279 loss)
I0626 03:49:53.872512  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00822971 (* 1 = 0.00822971 loss)
I0626 03:49:53.872516  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00787283 (* 1 = 0.00787283 loss)
I0626 03:49:53.872521  6673 sgd_solver.cpp:106] Iteration 9380, lr = 0.0002
speed: 4.926s / iter
I0626 03:51:33.331295  6673 solver.cpp:228] Iteration 9400, loss = 0.326769
I0626 03:51:33.331318  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 03:51:33.331327  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.084074 (* 1 = 0.084074 loss)
I0626 03:51:33.331333  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.143648 (* 1 = 0.143648 loss)
I0626 03:51:33.331339  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107957 (* 1 = 0.00107957 loss)
I0626 03:51:33.331344  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00775243 (* 1 = 0.00775243 loss)
I0626 03:51:33.331353  6673 sgd_solver.cpp:106] Iteration 9400, lr = 0.0002
I0626 03:53:12.682570  6673 solver.cpp:228] Iteration 9420, loss = 0.195988
I0626 03:53:12.682595  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 03:53:12.682602  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0778547 (* 1 = 0.0778547 loss)
I0626 03:53:12.682606  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.169668 (* 1 = 0.169668 loss)
I0626 03:53:12.682610  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00468659 (* 1 = 0.00468659 loss)
I0626 03:53:12.682615  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190965 (* 1 = 0.0190965 loss)
I0626 03:53:12.682620  6673 sgd_solver.cpp:106] Iteration 9420, lr = 0.0002
I0626 03:54:51.839076  6673 solver.cpp:228] Iteration 9440, loss = 0.245676
I0626 03:54:51.839100  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0626 03:54:51.839108  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.21757 (* 1 = 0.21757 loss)
I0626 03:54:51.839112  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.427899 (* 1 = 0.427899 loss)
I0626 03:54:51.839116  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119631 (* 1 = 0.0119631 loss)
I0626 03:54:51.839120  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0610708 (* 1 = 0.0610708 loss)
I0626 03:54:51.839125  6673 sgd_solver.cpp:106] Iteration 9440, lr = 0.0002
I0626 03:56:31.165328  6673 solver.cpp:228] Iteration 9460, loss = 0.357795
I0626 03:56:31.165355  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 03:56:31.165365  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.17119 (* 1 = 0.17119 loss)
I0626 03:56:31.165371  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.23941 (* 1 = 0.23941 loss)
I0626 03:56:31.165376  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026036 (* 1 = 0.0026036 loss)
I0626 03:56:31.165381  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.051895 (* 1 = 0.051895 loss)
I0626 03:56:31.165387  6673 sgd_solver.cpp:106] Iteration 9460, lr = 0.0002
I0626 03:58:10.638659  6673 solver.cpp:228] Iteration 9480, loss = 0.282464
I0626 03:58:10.638687  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 03:58:10.638695  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00146713 (* 1 = 0.00146713 loss)
I0626 03:58:10.638700  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0647684 (* 1 = 0.0647684 loss)
I0626 03:58:10.638705  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101498 (* 1 = 0.0101498 loss)
I0626 03:58:10.638708  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226156 (* 1 = 0.0226156 loss)
I0626 03:58:10.638713  6673 sgd_solver.cpp:106] Iteration 9480, lr = 0.0002
I0626 03:59:49.723917  6673 solver.cpp:228] Iteration 9500, loss = 0.124536
I0626 03:59:49.723942  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 03:59:49.723949  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.023948 (* 1 = 0.023948 loss)
I0626 03:59:49.723953  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0647801 (* 1 = 0.0647801 loss)
I0626 03:59:49.723956  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713668 (* 1 = 0.00713668 loss)
I0626 03:59:49.723960  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127037 (* 1 = 0.0127037 loss)
I0626 03:59:49.723964  6673 sgd_solver.cpp:106] Iteration 9500, lr = 0.0002
I0626 04:01:28.505882  6673 solver.cpp:228] Iteration 9520, loss = 0.457282
I0626 04:01:28.505908  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 04:01:28.505914  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.233162 (* 1 = 0.233162 loss)
I0626 04:01:28.505918  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.406417 (* 1 = 0.406417 loss)
I0626 04:01:28.505921  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186659 (* 1 = 0.0186659 loss)
I0626 04:01:28.505924  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127826 (* 1 = 0.127826 loss)
I0626 04:01:28.505930  6673 sgd_solver.cpp:106] Iteration 9520, lr = 0.0002
I0626 04:03:07.165448  6673 solver.cpp:228] Iteration 9540, loss = 0.36667
I0626 04:03:07.165472  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 04:03:07.165478  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.131858 (* 1 = 0.131858 loss)
I0626 04:03:07.165482  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.2151 (* 1 = 0.2151 loss)
I0626 04:03:07.165486  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0031305 (* 1 = 0.0031305 loss)
I0626 04:03:07.165489  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104055 (* 1 = 0.0104055 loss)
I0626 04:03:07.165494  6673 sgd_solver.cpp:106] Iteration 9540, lr = 0.0002
I0626 04:04:45.753679  6673 solver.cpp:228] Iteration 9560, loss = 0.187232
I0626 04:04:45.753702  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 04:04:45.753710  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0470151 (* 1 = 0.0470151 loss)
I0626 04:04:45.753715  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.127904 (* 1 = 0.127904 loss)
I0626 04:04:45.753718  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00293742 (* 1 = 0.00293742 loss)
I0626 04:04:45.753722  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00924915 (* 1 = 0.00924915 loss)
I0626 04:04:45.753727  6673 sgd_solver.cpp:106] Iteration 9560, lr = 0.0002
I0626 04:06:24.190871  6673 solver.cpp:228] Iteration 9580, loss = 0.146828
I0626 04:06:24.190903  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:06:24.190912  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0019523 (* 1 = 0.0019523 loss)
I0626 04:06:24.190917  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0494744 (* 1 = 0.0494744 loss)
I0626 04:06:24.190922  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000233942 (* 1 = 0.000233942 loss)
I0626 04:06:24.190925  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00534777 (* 1 = 0.00534777 loss)
I0626 04:06:24.190932  6673 sgd_solver.cpp:106] Iteration 9580, lr = 0.0002
speed: 4.926s / iter
I0626 04:08:02.728621  6673 solver.cpp:228] Iteration 9600, loss = 0.549198
I0626 04:08:02.728646  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 04:08:02.728652  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0502761 (* 1 = 0.0502761 loss)
I0626 04:08:02.728657  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0808344 (* 1 = 0.0808344 loss)
I0626 04:08:02.728660  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00172454 (* 1 = 0.00172454 loss)
I0626 04:08:02.728663  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106093 (* 1 = 0.0106093 loss)
I0626 04:08:02.728668  6673 sgd_solver.cpp:106] Iteration 9600, lr = 0.0002
I0626 04:09:41.517673  6673 solver.cpp:228] Iteration 9620, loss = 0.200603
I0626 04:09:41.517698  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:09:41.517704  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415878 (* 1 = 0.0415878 loss)
I0626 04:09:41.517707  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0718908 (* 1 = 0.0718908 loss)
I0626 04:09:41.517711  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00384066 (* 1 = 0.00384066 loss)
I0626 04:09:41.517714  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156871 (* 1 = 0.0156871 loss)
I0626 04:09:41.517719  6673 sgd_solver.cpp:106] Iteration 9620, lr = 0.0002
I0626 04:11:20.254283  6673 solver.cpp:228] Iteration 9640, loss = 0.469715
I0626 04:11:20.254309  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0626 04:11:20.254318  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.471357 (* 1 = 0.471357 loss)
I0626 04:11:20.254324  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.497054 (* 1 = 0.497054 loss)
I0626 04:11:20.254331  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0897192 (* 1 = 0.0897192 loss)
I0626 04:11:20.254338  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.323407 (* 1 = 0.323407 loss)
I0626 04:11:20.254344  6673 sgd_solver.cpp:106] Iteration 9640, lr = 0.0002
I0626 04:12:58.864230  6673 solver.cpp:228] Iteration 9660, loss = 0.247243
I0626 04:12:58.864255  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:12:58.864262  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0239209 (* 1 = 0.0239209 loss)
I0626 04:12:58.864266  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0642813 (* 1 = 0.0642813 loss)
I0626 04:12:58.864270  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00948705 (* 1 = 0.00948705 loss)
I0626 04:12:58.864274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117514 (* 1 = 0.0117514 loss)
I0626 04:12:58.864280  6673 sgd_solver.cpp:106] Iteration 9660, lr = 0.0002
I0626 04:14:37.624948  6673 solver.cpp:228] Iteration 9680, loss = 0.318154
I0626 04:14:37.624977  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 04:14:37.624989  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251219 (* 1 = 0.0251219 loss)
I0626 04:14:37.624994  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0225218 (* 1 = 0.0225218 loss)
I0626 04:14:37.625000  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000137001 (* 1 = 0.000137001 loss)
I0626 04:14:37.625006  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00268421 (* 1 = 0.00268421 loss)
I0626 04:14:37.625015  6673 sgd_solver.cpp:106] Iteration 9680, lr = 0.0002
I0626 04:16:16.320900  6673 solver.cpp:228] Iteration 9700, loss = 0.276008
I0626 04:16:16.320928  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 04:16:16.320935  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0688514 (* 1 = 0.0688514 loss)
I0626 04:16:16.320940  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.115678 (* 1 = 0.115678 loss)
I0626 04:16:16.320942  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00352095 (* 1 = 0.00352095 loss)
I0626 04:16:16.320946  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335015 (* 1 = 0.0335015 loss)
I0626 04:16:16.320951  6673 sgd_solver.cpp:106] Iteration 9700, lr = 0.0002
I0626 04:17:55.113729  6673 solver.cpp:228] Iteration 9720, loss = 0.291972
I0626 04:17:55.113754  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:17:55.113761  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295653 (* 1 = 0.0295653 loss)
I0626 04:17:55.113766  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0315573 (* 1 = 0.0315573 loss)
I0626 04:17:55.113770  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000224998 (* 1 = 0.000224998 loss)
I0626 04:17:55.113775  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00654979 (* 1 = 0.00654979 loss)
I0626 04:17:55.113778  6673 sgd_solver.cpp:106] Iteration 9720, lr = 0.0002
I0626 04:19:33.989094  6673 solver.cpp:228] Iteration 9740, loss = 0.312647
I0626 04:19:33.989117  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 04:19:33.989125  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.119214 (* 1 = 0.119214 loss)
I0626 04:19:33.989128  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.330872 (* 1 = 0.330872 loss)
I0626 04:19:33.989131  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000681212 (* 1 = 0.000681212 loss)
I0626 04:19:33.989135  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179922 (* 1 = 0.0179922 loss)
I0626 04:19:33.989140  6673 sgd_solver.cpp:106] Iteration 9740, lr = 0.0002
I0626 04:21:12.835533  6673 solver.cpp:228] Iteration 9760, loss = 0.177445
I0626 04:21:12.835559  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 04:21:12.835567  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627719 (* 1 = 0.0627719 loss)
I0626 04:21:12.835570  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0866903 (* 1 = 0.0866903 loss)
I0626 04:21:12.835574  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032463 (* 1 = 0.0032463 loss)
I0626 04:21:12.835577  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203915 (* 1 = 0.0203915 loss)
I0626 04:21:12.835582  6673 sgd_solver.cpp:106] Iteration 9760, lr = 0.0002
I0626 04:22:51.736232  6673 solver.cpp:228] Iteration 9780, loss = 0.251134
I0626 04:22:51.736255  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:22:51.736263  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248083 (* 1 = 0.0248083 loss)
I0626 04:22:51.736268  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0343069 (* 1 = 0.0343069 loss)
I0626 04:22:51.736270  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00068783 (* 1 = 0.00068783 loss)
I0626 04:22:51.736274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127031 (* 1 = 0.0127031 loss)
I0626 04:22:51.736279  6673 sgd_solver.cpp:106] Iteration 9780, lr = 0.0002
speed: 4.927s / iter
I0626 04:24:30.657760  6673 solver.cpp:228] Iteration 9800, loss = 0.214457
I0626 04:24:30.657786  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 04:24:30.657796  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707796 (* 1 = 0.0707796 loss)
I0626 04:24:30.657804  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.2733 (* 1 = 0.2733 loss)
I0626 04:24:30.657809  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0217208 (* 1 = 0.0217208 loss)
I0626 04:24:30.657815  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0409621 (* 1 = 0.0409621 loss)
I0626 04:24:30.657822  6673 sgd_solver.cpp:106] Iteration 9800, lr = 0.0002
I0626 04:26:09.656589  6673 solver.cpp:228] Iteration 9820, loss = 0.308834
I0626 04:26:09.656612  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 04:26:09.656620  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0285318 (* 1 = 0.0285318 loss)
I0626 04:26:09.656625  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0908416 (* 1 = 0.0908416 loss)
I0626 04:26:09.656628  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00178605 (* 1 = 0.00178605 loss)
I0626 04:26:09.656632  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00166343 (* 1 = 0.00166343 loss)
I0626 04:26:09.656636  6673 sgd_solver.cpp:106] Iteration 9820, lr = 0.0002
I0626 04:27:48.968248  6673 solver.cpp:228] Iteration 9840, loss = 0.27867
I0626 04:27:48.968273  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 04:27:48.968281  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.311677 (* 1 = 0.311677 loss)
I0626 04:27:48.968283  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.439083 (* 1 = 0.439083 loss)
I0626 04:27:48.968287  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00498577 (* 1 = 0.00498577 loss)
I0626 04:27:48.968291  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0532572 (* 1 = 0.0532572 loss)
I0626 04:27:48.968295  6673 sgd_solver.cpp:106] Iteration 9840, lr = 0.0002
I0626 04:29:28.778704  6673 solver.cpp:228] Iteration 9860, loss = 0.346128
I0626 04:29:28.778729  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:29:28.778738  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.12852 (* 1 = 0.12852 loss)
I0626 04:29:28.778743  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.107326 (* 1 = 0.107326 loss)
I0626 04:29:28.778746  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000973867 (* 1 = 0.000973867 loss)
I0626 04:29:28.778749  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107358 (* 1 = 0.0107358 loss)
I0626 04:29:28.778754  6673 sgd_solver.cpp:106] Iteration 9860, lr = 0.0002
I0626 04:31:08.484063  6673 solver.cpp:228] Iteration 9880, loss = 0.181556
I0626 04:31:08.484088  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 04:31:08.484097  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181924 (* 1 = 0.0181924 loss)
I0626 04:31:08.484103  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.054764 (* 1 = 0.054764 loss)
I0626 04:31:08.484109  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100326 (* 1 = 0.00100326 loss)
I0626 04:31:08.484114  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0034645 (* 1 = 0.0034645 loss)
I0626 04:31:08.484120  6673 sgd_solver.cpp:106] Iteration 9880, lr = 0.0002
I0626 04:32:48.305440  6673 solver.cpp:228] Iteration 9900, loss = 0.244997
I0626 04:32:48.305466  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:32:48.305474  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0141015 (* 1 = 0.0141015 loss)
I0626 04:32:48.305479  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0736621 (* 1 = 0.0736621 loss)
I0626 04:32:48.305482  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00581601 (* 1 = 0.00581601 loss)
I0626 04:32:48.305486  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0034033 (* 1 = 0.0034033 loss)
I0626 04:32:48.305492  6673 sgd_solver.cpp:106] Iteration 9900, lr = 0.0002
I0626 04:34:27.893534  6673 solver.cpp:228] Iteration 9920, loss = 0.341068
I0626 04:34:27.893558  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 04:34:27.893565  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.126913 (* 1 = 0.126913 loss)
I0626 04:34:27.893569  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.303021 (* 1 = 0.303021 loss)
I0626 04:34:27.893573  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00720589 (* 1 = 0.00720589 loss)
I0626 04:34:27.893576  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033733 (* 1 = 0.033733 loss)
I0626 04:34:27.893581  6673 sgd_solver.cpp:106] Iteration 9920, lr = 0.0002
I0626 04:36:07.453253  6673 solver.cpp:228] Iteration 9940, loss = 0.236029
I0626 04:36:07.453275  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0626 04:36:07.453282  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.30182 (* 1 = 0.30182 loss)
I0626 04:36:07.453286  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.546756 (* 1 = 0.546756 loss)
I0626 04:36:07.453289  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154699 (* 1 = 0.0154699 loss)
I0626 04:36:07.453294  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362745 (* 1 = 0.0362745 loss)
I0626 04:36:07.453297  6673 sgd_solver.cpp:106] Iteration 9940, lr = 0.0002
I0626 04:37:46.790700  6673 solver.cpp:228] Iteration 9960, loss = 0.262616
I0626 04:37:46.790724  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 04:37:46.790730  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0607146 (* 1 = 0.0607146 loss)
I0626 04:37:46.790735  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109533 (* 1 = 0.109533 loss)
I0626 04:37:46.790738  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0060367 (* 1 = 0.0060367 loss)
I0626 04:37:46.790741  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114198 (* 1 = 0.0114198 loss)
I0626 04:37:46.790746  6673 sgd_solver.cpp:106] Iteration 9960, lr = 0.0002
I0626 04:39:26.170464  6673 solver.cpp:228] Iteration 9980, loss = 0.22423
I0626 04:39:26.170488  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 04:39:26.170495  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148492 (* 1 = 0.0148492 loss)
I0626 04:39:26.170500  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0335946 (* 1 = 0.0335946 loss)
I0626 04:39:26.170503  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137423 (* 1 = 0.00137423 loss)
I0626 04:39:26.170508  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00254629 (* 1 = 0.00254629 loss)
I0626 04:39:26.170512  6673 sgd_solver.cpp:106] Iteration 9980, lr = 0.0002
speed: 4.928s / iter
I0626 04:41:00.876744  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_10000.caffemodel
I0626 04:41:06.316467  6673 solver.cpp:228] Iteration 10000, loss = 0.360563
I0626 04:41:06.316491  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 04:41:06.316499  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.115675 (* 1 = 0.115675 loss)
I0626 04:41:06.316505  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.406054 (* 1 = 0.406054 loss)
I0626 04:41:06.316511  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00507743 (* 1 = 0.00507743 loss)
I0626 04:41:06.316517  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338427 (* 1 = 0.0338427 loss)
I0626 04:41:06.316524  6673 sgd_solver.cpp:106] Iteration 10000, lr = 0.0002
I0626 04:42:45.675137  6673 solver.cpp:228] Iteration 10020, loss = 0.390882
I0626 04:42:45.675161  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 04:42:45.675168  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0119627 (* 1 = 0.0119627 loss)
I0626 04:42:45.675173  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0284704 (* 1 = 0.0284704 loss)
I0626 04:42:45.675177  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000189051 (* 1 = 0.000189051 loss)
I0626 04:42:45.675180  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00429746 (* 1 = 0.00429746 loss)
I0626 04:42:45.675185  6673 sgd_solver.cpp:106] Iteration 10020, lr = 0.0002
I0626 04:44:24.885289  6673 solver.cpp:228] Iteration 10040, loss = 0.257373
I0626 04:44:24.885314  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:44:24.885324  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00872628 (* 1 = 0.00872628 loss)
I0626 04:44:24.885330  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0927595 (* 1 = 0.0927595 loss)
I0626 04:44:24.885335  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000409267 (* 1 = 0.000409267 loss)
I0626 04:44:24.885341  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00282416 (* 1 = 0.00282416 loss)
I0626 04:44:24.885347  6673 sgd_solver.cpp:106] Iteration 10040, lr = 0.0002
I0626 04:46:04.135715  6673 solver.cpp:228] Iteration 10060, loss = 0.360009
I0626 04:46:04.135740  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:46:04.135746  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.015718 (* 1 = 0.015718 loss)
I0626 04:46:04.135751  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0758197 (* 1 = 0.0758197 loss)
I0626 04:46:04.135756  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000710934 (* 1 = 0.000710934 loss)
I0626 04:46:04.135759  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00685832 (* 1 = 0.00685832 loss)
I0626 04:46:04.135763  6673 sgd_solver.cpp:106] Iteration 10060, lr = 0.0002
I0626 04:47:43.150225  6673 solver.cpp:228] Iteration 10080, loss = 0.230025
I0626 04:47:43.150249  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 04:47:43.150259  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.025445 (* 1 = 0.025445 loss)
I0626 04:47:43.150264  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0278103 (* 1 = 0.0278103 loss)
I0626 04:47:43.150269  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0049044 (* 1 = 0.0049044 loss)
I0626 04:47:43.150274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00962068 (* 1 = 0.00962068 loss)
I0626 04:47:43.150280  6673 sgd_solver.cpp:106] Iteration 10080, lr = 0.0002
I0626 04:49:21.921721  6673 solver.cpp:228] Iteration 10100, loss = 0.232184
I0626 04:49:21.921746  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 04:49:21.921753  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541783 (* 1 = 0.0541783 loss)
I0626 04:49:21.921757  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.179116 (* 1 = 0.179116 loss)
I0626 04:49:21.921761  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956012 (* 1 = 0.00956012 loss)
I0626 04:49:21.921766  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0615282 (* 1 = 0.0615282 loss)
I0626 04:49:21.921771  6673 sgd_solver.cpp:106] Iteration 10100, lr = 0.0002
I0626 04:51:00.613739  6673 solver.cpp:228] Iteration 10120, loss = 0.248198
I0626 04:51:00.613770  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 04:51:00.613778  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134227 (* 1 = 0.134227 loss)
I0626 04:51:00.613785  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.199759 (* 1 = 0.199759 loss)
I0626 04:51:00.613790  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00507955 (* 1 = 0.00507955 loss)
I0626 04:51:00.613795  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201267 (* 1 = 0.0201267 loss)
I0626 04:51:00.613801  6673 sgd_solver.cpp:106] Iteration 10120, lr = 0.0002
I0626 04:52:39.172202  6673 solver.cpp:228] Iteration 10140, loss = 0.210955
I0626 04:52:39.172227  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:52:39.172237  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205558 (* 1 = 0.0205558 loss)
I0626 04:52:39.172243  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0787952 (* 1 = 0.0787952 loss)
I0626 04:52:39.172247  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202295 (* 1 = 0.0202295 loss)
I0626 04:52:39.172251  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014176 (* 1 = 0.014176 loss)
I0626 04:52:39.172255  6673 sgd_solver.cpp:106] Iteration 10140, lr = 0.0002
I0626 04:54:17.659839  6673 solver.cpp:228] Iteration 10160, loss = 0.270241
I0626 04:54:17.659867  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 04:54:17.659876  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.123423 (* 1 = 0.123423 loss)
I0626 04:54:17.659883  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.311034 (* 1 = 0.311034 loss)
I0626 04:54:17.659888  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00744415 (* 1 = 0.00744415 loss)
I0626 04:54:17.659895  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031927 (* 1 = 0.031927 loss)
I0626 04:54:17.659903  6673 sgd_solver.cpp:106] Iteration 10160, lr = 0.0002
I0626 04:55:56.160346  6673 solver.cpp:228] Iteration 10180, loss = 0.299292
I0626 04:55:56.160370  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 04:55:56.160382  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179833 (* 1 = 0.0179833 loss)
I0626 04:55:56.160385  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0623564 (* 1 = 0.0623564 loss)
I0626 04:55:56.160389  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00039188 (* 1 = 0.00039188 loss)
I0626 04:55:56.160392  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00368192 (* 1 = 0.00368192 loss)
I0626 04:55:56.160398  6673 sgd_solver.cpp:106] Iteration 10180, lr = 0.0002
speed: 4.928s / iter
I0626 04:57:34.671892  6673 solver.cpp:228] Iteration 10200, loss = 0.42426
I0626 04:57:34.671916  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 04:57:34.671923  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0479508 (* 1 = 0.0479508 loss)
I0626 04:57:34.671927  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0747082 (* 1 = 0.0747082 loss)
I0626 04:57:34.671931  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000377612 (* 1 = 0.000377612 loss)
I0626 04:57:34.671934  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00896695 (* 1 = 0.00896695 loss)
I0626 04:57:34.671939  6673 sgd_solver.cpp:106] Iteration 10200, lr = 0.0002
I0626 04:59:13.307193  6673 solver.cpp:228] Iteration 10220, loss = 0.161078
I0626 04:59:13.307219  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 04:59:13.307225  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215112 (* 1 = 0.0215112 loss)
I0626 04:59:13.307229  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0757054 (* 1 = 0.0757054 loss)
I0626 04:59:13.307234  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000224881 (* 1 = 0.000224881 loss)
I0626 04:59:13.307237  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0064102 (* 1 = 0.0064102 loss)
I0626 04:59:13.307243  6673 sgd_solver.cpp:106] Iteration 10220, lr = 0.0002
I0626 05:00:51.940237  6673 solver.cpp:228] Iteration 10240, loss = 0.194144
I0626 05:00:51.940263  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:00:51.940270  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167641 (* 1 = 0.0167641 loss)
I0626 05:00:51.940274  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0608299 (* 1 = 0.0608299 loss)
I0626 05:00:51.940279  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000205014 (* 1 = 0.000205014 loss)
I0626 05:00:51.940282  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00412747 (* 1 = 0.00412747 loss)
I0626 05:00:51.940287  6673 sgd_solver.cpp:106] Iteration 10240, lr = 0.0002
I0626 05:02:30.554504  6673 solver.cpp:228] Iteration 10260, loss = 0.424768
I0626 05:02:30.554528  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:02:30.554535  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464826 (* 1 = 0.0464826 loss)
I0626 05:02:30.554539  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0519964 (* 1 = 0.0519964 loss)
I0626 05:02:30.554543  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000459782 (* 1 = 0.000459782 loss)
I0626 05:02:30.554545  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00710118 (* 1 = 0.00710118 loss)
I0626 05:02:30.554550  6673 sgd_solver.cpp:106] Iteration 10260, lr = 0.0002
I0626 05:04:09.345223  6673 solver.cpp:228] Iteration 10280, loss = 0.200373
I0626 05:04:09.345252  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 05:04:09.345263  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.165166 (* 1 = 0.165166 loss)
I0626 05:04:09.345270  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.365581 (* 1 = 0.365581 loss)
I0626 05:04:09.345276  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00854441 (* 1 = 0.00854441 loss)
I0626 05:04:09.345283  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0755309 (* 1 = 0.0755309 loss)
I0626 05:04:09.345290  6673 sgd_solver.cpp:106] Iteration 10280, lr = 0.0002
I0626 05:05:48.267978  6673 solver.cpp:228] Iteration 10300, loss = 0.342677
I0626 05:05:48.268007  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:05:48.268014  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171431 (* 1 = 0.0171431 loss)
I0626 05:05:48.268018  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.045675 (* 1 = 0.045675 loss)
I0626 05:05:48.268023  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00512005 (* 1 = 0.00512005 loss)
I0626 05:05:48.268026  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00569894 (* 1 = 0.00569894 loss)
I0626 05:05:48.268033  6673 sgd_solver.cpp:106] Iteration 10300, lr = 0.0002
I0626 05:07:27.158128  6673 solver.cpp:228] Iteration 10320, loss = 0.153721
I0626 05:07:27.158156  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 05:07:27.158164  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0332228 (* 1 = 0.0332228 loss)
I0626 05:07:27.158167  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.118632 (* 1 = 0.118632 loss)
I0626 05:07:27.158170  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00313171 (* 1 = 0.00313171 loss)
I0626 05:07:27.158174  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261478 (* 1 = 0.0261478 loss)
I0626 05:07:27.158179  6673 sgd_solver.cpp:106] Iteration 10320, lr = 0.0002
I0626 05:09:06.094956  6673 solver.cpp:228] Iteration 10340, loss = 0.362983
I0626 05:09:06.094980  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:09:06.094988  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0222172 (* 1 = 0.0222172 loss)
I0626 05:09:06.094993  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0517941 (* 1 = 0.0517941 loss)
I0626 05:09:06.094997  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00064664 (* 1 = 0.00064664 loss)
I0626 05:09:06.095001  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00580429 (* 1 = 0.00580429 loss)
I0626 05:09:06.095006  6673 sgd_solver.cpp:106] Iteration 10340, lr = 0.0002
I0626 05:10:44.954996  6673 solver.cpp:228] Iteration 10360, loss = 0.344102
I0626 05:10:44.955019  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:10:44.955026  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179126 (* 1 = 0.0179126 loss)
I0626 05:10:44.955030  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0805473 (* 1 = 0.0805473 loss)
I0626 05:10:44.955034  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00429269 (* 1 = 0.00429269 loss)
I0626 05:10:44.955037  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491731 (* 1 = 0.0491731 loss)
I0626 05:10:44.955041  6673 sgd_solver.cpp:106] Iteration 10360, lr = 0.0002
I0626 05:12:23.853655  6673 solver.cpp:228] Iteration 10380, loss = 0.190265
I0626 05:12:23.853679  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:12:23.853687  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0531821 (* 1 = 0.0531821 loss)
I0626 05:12:23.853689  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0705681 (* 1 = 0.0705681 loss)
I0626 05:12:23.853693  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000841246 (* 1 = 0.000841246 loss)
I0626 05:12:23.853698  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00903015 (* 1 = 0.00903015 loss)
I0626 05:12:23.853701  6673 sgd_solver.cpp:106] Iteration 10380, lr = 0.0002
speed: 4.928s / iter
I0626 05:14:02.848635  6673 solver.cpp:228] Iteration 10400, loss = 0.203362
I0626 05:14:02.848661  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 05:14:02.848668  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0876902 (* 1 = 0.0876902 loss)
I0626 05:14:02.848673  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.148328 (* 1 = 0.148328 loss)
I0626 05:14:02.848677  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00244401 (* 1 = 0.00244401 loss)
I0626 05:14:02.848681  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167505 (* 1 = 0.0167505 loss)
I0626 05:14:02.848686  6673 sgd_solver.cpp:106] Iteration 10400, lr = 0.0002
I0626 05:15:42.424618  6673 solver.cpp:228] Iteration 10420, loss = 0.246178
I0626 05:15:42.424643  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 05:15:42.424650  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822998 (* 1 = 0.0822998 loss)
I0626 05:15:42.424655  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.248951 (* 1 = 0.248951 loss)
I0626 05:15:42.424659  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00579074 (* 1 = 0.00579074 loss)
I0626 05:15:42.424664  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145952 (* 1 = 0.0145952 loss)
I0626 05:15:42.424669  6673 sgd_solver.cpp:106] Iteration 10420, lr = 0.0002
I0626 05:17:22.198855  6673 solver.cpp:228] Iteration 10440, loss = 0.179613
I0626 05:17:22.198904  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:17:22.198912  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0701678 (* 1 = 0.0701678 loss)
I0626 05:17:22.198917  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0512791 (* 1 = 0.0512791 loss)
I0626 05:17:22.198921  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000226295 (* 1 = 0.000226295 loss)
I0626 05:17:22.198925  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011122 (* 1 = 0.011122 loss)
I0626 05:17:22.198930  6673 sgd_solver.cpp:106] Iteration 10440, lr = 0.0002
I0626 05:19:02.000784  6673 solver.cpp:228] Iteration 10460, loss = 0.421394
I0626 05:19:02.000810  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 05:19:02.000818  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320895 (* 1 = 0.0320895 loss)
I0626 05:19:02.000823  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.116198 (* 1 = 0.116198 loss)
I0626 05:19:02.000826  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00869513 (* 1 = 0.00869513 loss)
I0626 05:19:02.000830  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108261 (* 1 = 0.0108261 loss)
I0626 05:19:02.000835  6673 sgd_solver.cpp:106] Iteration 10460, lr = 0.0002
I0626 05:20:41.758246  6673 solver.cpp:228] Iteration 10480, loss = 0.323435
I0626 05:20:41.758271  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 05:20:41.758278  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381074 (* 1 = 0.0381074 loss)
I0626 05:20:41.758282  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.195425 (* 1 = 0.195425 loss)
I0626 05:20:41.758285  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0336322 (* 1 = 0.0336322 loss)
I0626 05:20:41.758289  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0320649 (* 1 = 0.0320649 loss)
I0626 05:20:41.758293  6673 sgd_solver.cpp:106] Iteration 10480, lr = 0.0002
I0626 05:22:21.462497  6673 solver.cpp:228] Iteration 10500, loss = 0.246334
I0626 05:22:21.462522  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:22:21.462529  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197359 (* 1 = 0.0197359 loss)
I0626 05:22:21.462532  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0783282 (* 1 = 0.0783282 loss)
I0626 05:22:21.462536  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00444791 (* 1 = 0.00444791 loss)
I0626 05:22:21.462539  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115897 (* 1 = 0.0115897 loss)
I0626 05:22:21.462545  6673 sgd_solver.cpp:106] Iteration 10500, lr = 0.0002
I0626 05:24:00.943493  6673 solver.cpp:228] Iteration 10520, loss = 0.281848
I0626 05:24:00.943518  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 05:24:00.943526  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.039109 (* 1 = 0.039109 loss)
I0626 05:24:00.943529  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0845012 (* 1 = 0.0845012 loss)
I0626 05:24:00.943533  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136486 (* 1 = 0.00136486 loss)
I0626 05:24:00.943537  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00494294 (* 1 = 0.00494294 loss)
I0626 05:24:00.943542  6673 sgd_solver.cpp:106] Iteration 10520, lr = 0.0002
I0626 05:25:40.461396  6673 solver.cpp:228] Iteration 10540, loss = 0.243084
I0626 05:25:40.461421  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 05:25:40.461429  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0431866 (* 1 = 0.0431866 loss)
I0626 05:25:40.461433  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0948366 (* 1 = 0.0948366 loss)
I0626 05:25:40.461437  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00415922 (* 1 = 0.00415922 loss)
I0626 05:25:40.461441  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01137 (* 1 = 0.01137 loss)
I0626 05:25:40.461447  6673 sgd_solver.cpp:106] Iteration 10540, lr = 0.0002
I0626 05:27:19.825554  6673 solver.cpp:228] Iteration 10560, loss = 0.234291
I0626 05:27:19.825580  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:27:19.825590  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162289 (* 1 = 0.0162289 loss)
I0626 05:27:19.825597  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0421323 (* 1 = 0.0421323 loss)
I0626 05:27:19.825603  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000915326 (* 1 = 0.000915326 loss)
I0626 05:27:19.825609  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00284956 (* 1 = 0.00284956 loss)
I0626 05:27:19.825615  6673 sgd_solver.cpp:106] Iteration 10560, lr = 0.0002
I0626 05:28:59.061686  6673 solver.cpp:228] Iteration 10580, loss = 0.205273
I0626 05:28:59.061710  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0626 05:28:59.061718  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.230163 (* 1 = 0.230163 loss)
I0626 05:28:59.061723  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.486517 (* 1 = 0.486517 loss)
I0626 05:28:59.061728  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00447231 (* 1 = 0.00447231 loss)
I0626 05:28:59.061731  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487835 (* 1 = 0.0487835 loss)
I0626 05:28:59.061736  6673 sgd_solver.cpp:106] Iteration 10580, lr = 0.0002
speed: 4.929s / iter
I0626 05:30:38.425508  6673 solver.cpp:228] Iteration 10600, loss = 0.304439
I0626 05:30:38.425534  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 05:30:38.425542  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.058588 (* 1 = 0.058588 loss)
I0626 05:30:38.425547  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.164557 (* 1 = 0.164557 loss)
I0626 05:30:38.425551  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00129898 (* 1 = 0.00129898 loss)
I0626 05:30:38.425555  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.006595 (* 1 = 0.006595 loss)
I0626 05:30:38.425561  6673 sgd_solver.cpp:106] Iteration 10600, lr = 0.0002
I0626 05:32:17.496690  6673 solver.cpp:228] Iteration 10620, loss = 0.34324
I0626 05:32:17.496712  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 05:32:17.496719  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0328137 (* 1 = 0.0328137 loss)
I0626 05:32:17.496723  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.110621 (* 1 = 0.110621 loss)
I0626 05:32:17.496727  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00073667 (* 1 = 0.00073667 loss)
I0626 05:32:17.496731  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156272 (* 1 = 0.0156272 loss)
I0626 05:32:17.496736  6673 sgd_solver.cpp:106] Iteration 10620, lr = 0.0002
I0626 05:33:56.859676  6673 solver.cpp:228] Iteration 10640, loss = 0.215997
I0626 05:33:56.859700  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 05:33:56.859707  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.063464 (* 1 = 0.063464 loss)
I0626 05:33:56.859711  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122503 (* 1 = 0.122503 loss)
I0626 05:33:56.859714  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131826 (* 1 = 0.0131826 loss)
I0626 05:33:56.859719  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0440221 (* 1 = 0.0440221 loss)
I0626 05:33:56.859722  6673 sgd_solver.cpp:106] Iteration 10640, lr = 0.0002
I0626 05:35:35.974552  6673 solver.cpp:228] Iteration 10660, loss = 0.161463
I0626 05:35:35.974582  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 05:35:35.974589  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0672652 (* 1 = 0.0672652 loss)
I0626 05:35:35.974593  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.138167 (* 1 = 0.138167 loss)
I0626 05:35:35.974596  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00877882 (* 1 = 0.00877882 loss)
I0626 05:35:35.974601  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155783 (* 1 = 0.0155783 loss)
I0626 05:35:35.974606  6673 sgd_solver.cpp:106] Iteration 10660, lr = 0.0002
I0626 05:37:14.789122  6673 solver.cpp:228] Iteration 10680, loss = 0.373147
I0626 05:37:14.789149  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 05:37:14.789158  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518827 (* 1 = 0.0518827 loss)
I0626 05:37:14.789165  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.172015 (* 1 = 0.172015 loss)
I0626 05:37:14.789170  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00332845 (* 1 = 0.00332845 loss)
I0626 05:37:14.789176  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277393 (* 1 = 0.0277393 loss)
I0626 05:37:14.789183  6673 sgd_solver.cpp:106] Iteration 10680, lr = 0.0002
I0626 05:38:53.429056  6673 solver.cpp:228] Iteration 10700, loss = 0.198393
I0626 05:38:53.429082  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 05:38:53.429092  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00178227 (* 1 = 0.00178227 loss)
I0626 05:38:53.429100  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0527173 (* 1 = 0.0527173 loss)
I0626 05:38:53.429105  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00521455 (* 1 = 0.00521455 loss)
I0626 05:38:53.429111  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128047 (* 1 = 0.0128047 loss)
I0626 05:38:53.429119  6673 sgd_solver.cpp:106] Iteration 10700, lr = 0.0002
I0626 05:40:32.029693  6673 solver.cpp:228] Iteration 10720, loss = 0.174454
I0626 05:40:32.029719  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:40:32.029727  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185204 (* 1 = 0.0185204 loss)
I0626 05:40:32.029731  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0529667 (* 1 = 0.0529667 loss)
I0626 05:40:32.029736  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000197415 (* 1 = 0.000197415 loss)
I0626 05:40:32.029739  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0020611 (* 1 = 0.0020611 loss)
I0626 05:40:32.029744  6673 sgd_solver.cpp:106] Iteration 10720, lr = 0.0002
I0626 05:42:10.542778  6673 solver.cpp:228] Iteration 10740, loss = 0.208455
I0626 05:42:10.542804  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 05:42:10.542810  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0344137 (* 1 = 0.0344137 loss)
I0626 05:42:10.542815  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0785957 (* 1 = 0.0785957 loss)
I0626 05:42:10.542819  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113854 (* 1 = 0.0113854 loss)
I0626 05:42:10.542822  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115554 (* 1 = 0.0115554 loss)
I0626 05:42:10.542829  6673 sgd_solver.cpp:106] Iteration 10740, lr = 0.0002
I0626 05:43:49.294838  6673 solver.cpp:228] Iteration 10760, loss = 0.254897
I0626 05:43:49.294865  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 05:43:49.294872  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415735 (* 1 = 0.0415735 loss)
I0626 05:43:49.294878  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.10581 (* 1 = 0.10581 loss)
I0626 05:43:49.294880  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376526 (* 1 = 0.00376526 loss)
I0626 05:43:49.294883  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00923809 (* 1 = 0.00923809 loss)
I0626 05:43:49.294888  6673 sgd_solver.cpp:106] Iteration 10760, lr = 0.0002
I0626 05:45:28.063755  6673 solver.cpp:228] Iteration 10780, loss = 0.322255
I0626 05:45:28.063779  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:45:28.063786  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413147 (* 1 = 0.0413147 loss)
I0626 05:45:28.063789  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0652858 (* 1 = 0.0652858 loss)
I0626 05:45:28.063793  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000694306 (* 1 = 0.000694306 loss)
I0626 05:45:28.063797  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166488 (* 1 = 0.0166488 loss)
I0626 05:45:28.063802  6673 sgd_solver.cpp:106] Iteration 10780, lr = 0.0002
speed: 4.929s / iter
I0626 05:47:06.786264  6673 solver.cpp:228] Iteration 10800, loss = 0.303577
I0626 05:47:06.786289  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 05:47:06.786296  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.10463 (* 1 = 0.10463 loss)
I0626 05:47:06.786300  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.215035 (* 1 = 0.215035 loss)
I0626 05:47:06.786304  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000911631 (* 1 = 0.000911631 loss)
I0626 05:47:06.786307  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146873 (* 1 = 0.0146873 loss)
I0626 05:47:06.786312  6673 sgd_solver.cpp:106] Iteration 10800, lr = 0.0002
I0626 05:48:45.553275  6673 solver.cpp:228] Iteration 10820, loss = 0.279087
I0626 05:48:45.553300  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:48:45.553308  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475759 (* 1 = 0.0475759 loss)
I0626 05:48:45.553311  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0647464 (* 1 = 0.0647464 loss)
I0626 05:48:45.553315  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00102612 (* 1 = 0.00102612 loss)
I0626 05:48:45.553318  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00423051 (* 1 = 0.00423051 loss)
I0626 05:48:45.553323  6673 sgd_solver.cpp:106] Iteration 10820, lr = 0.0002
I0626 05:50:24.362076  6673 solver.cpp:228] Iteration 10840, loss = 0.34377
I0626 05:50:24.362108  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 05:50:24.362115  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0072258 (* 1 = 0.0072258 loss)
I0626 05:50:24.362120  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0585883 (* 1 = 0.0585883 loss)
I0626 05:50:24.362125  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00586479 (* 1 = 0.00586479 loss)
I0626 05:50:24.362129  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00662332 (* 1 = 0.00662332 loss)
I0626 05:50:24.362134  6673 sgd_solver.cpp:106] Iteration 10840, lr = 0.0002
I0626 05:52:03.234086  6673 solver.cpp:228] Iteration 10860, loss = 0.215501
I0626 05:52:03.234113  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 05:52:03.234122  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325745 (* 1 = 0.0325745 loss)
I0626 05:52:03.234125  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102091 (* 1 = 0.102091 loss)
I0626 05:52:03.234129  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148943 (* 1 = 0.0148943 loss)
I0626 05:52:03.234133  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0497917 (* 1 = 0.0497917 loss)
I0626 05:52:03.234138  6673 sgd_solver.cpp:106] Iteration 10860, lr = 0.0002
I0626 05:53:42.238565  6673 solver.cpp:228] Iteration 10880, loss = 0.21132
I0626 05:53:42.238598  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 05:53:42.238610  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165356 (* 1 = 0.0165356 loss)
I0626 05:53:42.238616  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0543653 (* 1 = 0.0543653 loss)
I0626 05:53:42.238625  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158255 (* 1 = 0.00158255 loss)
I0626 05:53:42.238631  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112704 (* 1 = 0.0112704 loss)
I0626 05:53:42.238639  6673 sgd_solver.cpp:106] Iteration 10880, lr = 0.0002
I0626 05:55:21.323626  6673 solver.cpp:228] Iteration 10900, loss = 0.194177
I0626 05:55:21.323650  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0626 05:55:21.323658  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.294685 (* 1 = 0.294685 loss)
I0626 05:55:21.323662  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.572492 (* 1 = 0.572492 loss)
I0626 05:55:21.323667  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0225772 (* 1 = 0.0225772 loss)
I0626 05:55:21.323670  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.131323 (* 1 = 0.131323 loss)
I0626 05:55:21.323675  6673 sgd_solver.cpp:106] Iteration 10900, lr = 0.0002
I0626 05:57:00.343102  6673 solver.cpp:228] Iteration 10920, loss = 0.213345
I0626 05:57:00.343132  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 05:57:00.343140  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.10034 (* 1 = 0.10034 loss)
I0626 05:57:00.343147  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.131298 (* 1 = 0.131298 loss)
I0626 05:57:00.343152  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207923 (* 1 = 0.00207923 loss)
I0626 05:57:00.343156  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0286336 (* 1 = 0.0286336 loss)
I0626 05:57:00.343163  6673 sgd_solver.cpp:106] Iteration 10920, lr = 0.0002
I0626 05:58:39.375608  6673 solver.cpp:228] Iteration 10940, loss = 0.223505
I0626 05:58:39.375634  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 05:58:39.375643  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244893 (* 1 = 0.0244893 loss)
I0626 05:58:39.375646  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0708031 (* 1 = 0.0708031 loss)
I0626 05:58:39.375650  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000731379 (* 1 = 0.000731379 loss)
I0626 05:58:39.375654  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143877 (* 1 = 0.0143877 loss)
I0626 05:58:39.375658  6673 sgd_solver.cpp:106] Iteration 10940, lr = 0.0002
I0626 06:00:18.272557  6673 solver.cpp:228] Iteration 10960, loss = 0.25158
I0626 06:00:18.272579  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 06:00:18.272586  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.12339 (* 1 = 0.12339 loss)
I0626 06:00:18.272590  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.383072 (* 1 = 0.383072 loss)
I0626 06:00:18.272594  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264253 (* 1 = 0.00264253 loss)
I0626 06:00:18.272598  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212678 (* 1 = 0.0212678 loss)
I0626 06:00:18.272603  6673 sgd_solver.cpp:106] Iteration 10960, lr = 0.0002
I0626 06:01:57.145087  6673 solver.cpp:228] Iteration 10980, loss = 0.271351
I0626 06:01:57.145112  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 06:01:57.145119  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.152131 (* 1 = 0.152131 loss)
I0626 06:01:57.145123  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.282443 (* 1 = 0.282443 loss)
I0626 06:01:57.145126  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154981 (* 1 = 0.0154981 loss)
I0626 06:01:57.145130  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.055625 (* 1 = 0.055625 loss)
I0626 06:01:57.145136  6673 sgd_solver.cpp:106] Iteration 10980, lr = 0.0002
speed: 4.930s / iter
I0626 06:03:36.301576  6673 solver.cpp:228] Iteration 11000, loss = 0.218749
I0626 06:03:36.301628  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 06:03:36.301636  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0872993 (* 1 = 0.0872993 loss)
I0626 06:03:36.301641  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.227553 (* 1 = 0.227553 loss)
I0626 06:03:36.301645  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00642352 (* 1 = 0.00642352 loss)
I0626 06:03:36.301648  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175955 (* 1 = 0.0175955 loss)
I0626 06:03:36.301656  6673 sgd_solver.cpp:106] Iteration 11000, lr = 0.0002
I0626 06:05:15.482854  6673 solver.cpp:228] Iteration 11020, loss = 0.448721
I0626 06:05:15.482883  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:05:15.482890  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472713 (* 1 = 0.0472713 loss)
I0626 06:05:15.482894  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0635095 (* 1 = 0.0635095 loss)
I0626 06:05:15.482899  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137406 (* 1 = 0.00137406 loss)
I0626 06:05:15.482903  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164412 (* 1 = 0.0164412 loss)
I0626 06:05:15.482908  6673 sgd_solver.cpp:106] Iteration 11020, lr = 0.0002
I0626 06:06:54.602161  6673 solver.cpp:228] Iteration 11040, loss = 0.200791
I0626 06:06:54.602190  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:06:54.602196  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0612952 (* 1 = 0.0612952 loss)
I0626 06:06:54.602200  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.047894 (* 1 = 0.047894 loss)
I0626 06:06:54.602205  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338092 (* 1 = 0.00338092 loss)
I0626 06:06:54.602208  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00544416 (* 1 = 0.00544416 loss)
I0626 06:06:54.602213  6673 sgd_solver.cpp:106] Iteration 11040, lr = 0.0002
I0626 06:08:33.231431  6673 solver.cpp:228] Iteration 11060, loss = 0.275989
I0626 06:08:33.231453  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:08:33.231462  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.031641 (* 1 = 0.031641 loss)
I0626 06:08:33.231464  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0650877 (* 1 = 0.0650877 loss)
I0626 06:08:33.231468  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000166745 (* 1 = 0.000166745 loss)
I0626 06:08:33.231472  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00230778 (* 1 = 0.00230778 loss)
I0626 06:08:33.231477  6673 sgd_solver.cpp:106] Iteration 11060, lr = 0.0002
I0626 06:10:11.559648  6673 solver.cpp:228] Iteration 11080, loss = 0.235817
I0626 06:10:11.559674  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:10:11.559682  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499759 (* 1 = 0.0499759 loss)
I0626 06:10:11.559689  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0936396 (* 1 = 0.0936396 loss)
I0626 06:10:11.559695  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00281151 (* 1 = 0.00281151 loss)
I0626 06:10:11.559700  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00640309 (* 1 = 0.00640309 loss)
I0626 06:10:11.559708  6673 sgd_solver.cpp:106] Iteration 11080, lr = 0.0002
I0626 06:11:49.824177  6673 solver.cpp:228] Iteration 11100, loss = 0.245899
I0626 06:11:49.824203  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 06:11:49.824209  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.223712 (* 1 = 0.223712 loss)
I0626 06:11:49.824213  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.234455 (* 1 = 0.234455 loss)
I0626 06:11:49.824218  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00371817 (* 1 = 0.00371817 loss)
I0626 06:11:49.824223  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252938 (* 1 = 0.0252938 loss)
I0626 06:11:49.824226  6673 sgd_solver.cpp:106] Iteration 11100, lr = 0.0002
I0626 06:13:27.904817  6673 solver.cpp:228] Iteration 11120, loss = 0.34922
I0626 06:13:27.904844  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:13:27.904851  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266515 (* 1 = 0.0266515 loss)
I0626 06:13:27.904855  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0402251 (* 1 = 0.0402251 loss)
I0626 06:13:27.904860  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0056754 (* 1 = 0.0056754 loss)
I0626 06:13:27.904863  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00665786 (* 1 = 0.00665786 loss)
I0626 06:13:27.904868  6673 sgd_solver.cpp:106] Iteration 11120, lr = 0.0002
I0626 06:15:05.850421  6673 solver.cpp:228] Iteration 11140, loss = 0.241449
I0626 06:15:05.850446  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 06:15:05.850453  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.148775 (* 1 = 0.148775 loss)
I0626 06:15:05.850457  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.193368 (* 1 = 0.193368 loss)
I0626 06:15:05.850461  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171928 (* 1 = 0.00171928 loss)
I0626 06:15:05.850464  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189938 (* 1 = 0.0189938 loss)
I0626 06:15:05.850469  6673 sgd_solver.cpp:106] Iteration 11140, lr = 0.0002
I0626 06:16:43.744467  6673 solver.cpp:228] Iteration 11160, loss = 0.243812
I0626 06:16:43.744489  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:16:43.744498  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0452888 (* 1 = 0.0452888 loss)
I0626 06:16:43.744501  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.116096 (* 1 = 0.116096 loss)
I0626 06:16:43.744504  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0045096 (* 1 = 0.0045096 loss)
I0626 06:16:43.744508  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220869 (* 1 = 0.0220869 loss)
I0626 06:16:43.744511  6673 sgd_solver.cpp:106] Iteration 11160, lr = 0.0002
I0626 06:18:21.885824  6673 solver.cpp:228] Iteration 11180, loss = 0.186729
I0626 06:18:21.885850  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:18:21.885859  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0651586 (* 1 = 0.0651586 loss)
I0626 06:18:21.885862  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.104558 (* 1 = 0.104558 loss)
I0626 06:18:21.885866  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124468 (* 1 = 0.0124468 loss)
I0626 06:18:21.885870  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.20387 (* 1 = 0.20387 loss)
I0626 06:18:21.885875  6673 sgd_solver.cpp:106] Iteration 11180, lr = 0.0002
speed: 4.929s / iter
I0626 06:20:00.145970  6673 solver.cpp:228] Iteration 11200, loss = 0.280603
I0626 06:20:00.145995  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 06:20:00.146003  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.181476 (* 1 = 0.181476 loss)
I0626 06:20:00.146008  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.258149 (* 1 = 0.258149 loss)
I0626 06:20:00.146011  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737405 (* 1 = 0.00737405 loss)
I0626 06:20:00.146015  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282267 (* 1 = 0.0282267 loss)
I0626 06:20:00.146020  6673 sgd_solver.cpp:106] Iteration 11200, lr = 0.0002
I0626 06:21:38.474197  6673 solver.cpp:228] Iteration 11220, loss = 0.375114
I0626 06:21:38.474220  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 06:21:38.474227  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.125842 (* 1 = 0.125842 loss)
I0626 06:21:38.474231  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.23077 (* 1 = 0.23077 loss)
I0626 06:21:38.474236  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232372 (* 1 = 0.0232372 loss)
I0626 06:21:38.474238  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0920931 (* 1 = 0.0920931 loss)
I0626 06:21:38.474243  6673 sgd_solver.cpp:106] Iteration 11220, lr = 0.0002
I0626 06:23:16.781155  6673 solver.cpp:228] Iteration 11240, loss = 0.249842
I0626 06:23:16.781179  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 06:23:16.781185  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.233245 (* 1 = 0.233245 loss)
I0626 06:23:16.781189  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.417236 (* 1 = 0.417236 loss)
I0626 06:23:16.781193  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0058903 (* 1 = 0.0058903 loss)
I0626 06:23:16.781196  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108078 (* 1 = 0.108078 loss)
I0626 06:23:16.781201  6673 sgd_solver.cpp:106] Iteration 11240, lr = 0.0002
I0626 06:24:54.915551  6673 solver.cpp:228] Iteration 11260, loss = 0.457156
I0626 06:24:54.915575  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:24:54.915582  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0364824 (* 1 = 0.0364824 loss)
I0626 06:24:54.915586  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0800852 (* 1 = 0.0800852 loss)
I0626 06:24:54.915591  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00344716 (* 1 = 0.00344716 loss)
I0626 06:24:54.915594  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282346 (* 1 = 0.0282346 loss)
I0626 06:24:54.915599  6673 sgd_solver.cpp:106] Iteration 11260, lr = 0.0002
I0626 06:26:32.983012  6673 solver.cpp:228] Iteration 11280, loss = 0.229113
I0626 06:26:32.983038  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 06:26:32.983047  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0579731 (* 1 = 0.0579731 loss)
I0626 06:26:32.983050  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.134764 (* 1 = 0.134764 loss)
I0626 06:26:32.983053  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00858354 (* 1 = 0.00858354 loss)
I0626 06:26:32.983057  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00669288 (* 1 = 0.00669288 loss)
I0626 06:26:32.983062  6673 sgd_solver.cpp:106] Iteration 11280, lr = 0.0002
I0626 06:28:10.930727  6673 solver.cpp:228] Iteration 11300, loss = 0.397191
I0626 06:28:10.930750  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 06:28:10.930759  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0712086 (* 1 = 0.0712086 loss)
I0626 06:28:10.930763  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0979241 (* 1 = 0.0979241 loss)
I0626 06:28:10.930768  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000462416 (* 1 = 0.000462416 loss)
I0626 06:28:10.930770  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150441 (* 1 = 0.0150441 loss)
I0626 06:28:10.930776  6673 sgd_solver.cpp:106] Iteration 11300, lr = 0.0002
I0626 06:29:48.860146  6673 solver.cpp:228] Iteration 11320, loss = 0.295872
I0626 06:29:48.860172  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 06:29:48.860179  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0311154 (* 1 = 0.0311154 loss)
I0626 06:29:48.860183  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0934787 (* 1 = 0.0934787 loss)
I0626 06:29:48.860188  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179791 (* 1 = 0.00179791 loss)
I0626 06:29:48.860191  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00560016 (* 1 = 0.00560016 loss)
I0626 06:29:48.860196  6673 sgd_solver.cpp:106] Iteration 11320, lr = 0.0002
I0626 06:31:27.036794  6673 solver.cpp:228] Iteration 11340, loss = 0.177081
I0626 06:31:27.036845  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:31:27.036857  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175781 (* 1 = 0.0175781 loss)
I0626 06:31:27.036864  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0962697 (* 1 = 0.0962697 loss)
I0626 06:31:27.036870  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026603 (* 1 = 0.0026603 loss)
I0626 06:31:27.036875  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240493 (* 1 = 0.0240493 loss)
I0626 06:31:27.036882  6673 sgd_solver.cpp:106] Iteration 11340, lr = 0.0002
I0626 06:33:05.016574  6673 solver.cpp:228] Iteration 11360, loss = 0.221562
I0626 06:33:05.016599  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 06:33:05.016607  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.124625 (* 1 = 0.124625 loss)
I0626 06:33:05.016610  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.240338 (* 1 = 0.240338 loss)
I0626 06:33:05.016613  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0066876 (* 1 = 0.0066876 loss)
I0626 06:33:05.016618  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034142 (* 1 = 0.034142 loss)
I0626 06:33:05.016623  6673 sgd_solver.cpp:106] Iteration 11360, lr = 0.0002
I0626 06:34:43.034793  6673 solver.cpp:228] Iteration 11380, loss = 0.361677
I0626 06:34:43.034819  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 06:34:43.034827  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0131638 (* 1 = 0.0131638 loss)
I0626 06:34:43.034832  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0974447 (* 1 = 0.0974447 loss)
I0626 06:34:43.034835  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010113 (* 1 = 0.010113 loss)
I0626 06:34:43.034838  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00548681 (* 1 = 0.00548681 loss)
I0626 06:34:43.034844  6673 sgd_solver.cpp:106] Iteration 11380, lr = 0.0002
speed: 4.929s / iter
I0626 06:36:21.026336  6673 solver.cpp:228] Iteration 11400, loss = 0.234861
I0626 06:36:21.026360  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:36:21.026367  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0503101 (* 1 = 0.0503101 loss)
I0626 06:36:21.026371  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0433842 (* 1 = 0.0433842 loss)
I0626 06:36:21.026376  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000880861 (* 1 = 0.000880861 loss)
I0626 06:36:21.026379  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00753644 (* 1 = 0.00753644 loss)
I0626 06:36:21.026384  6673 sgd_solver.cpp:106] Iteration 11400, lr = 0.0002
I0626 06:37:59.183755  6673 solver.cpp:228] Iteration 11420, loss = 0.206395
I0626 06:37:59.183781  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:37:59.183790  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0324301 (* 1 = 0.0324301 loss)
I0626 06:37:59.183796  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.041122 (* 1 = 0.041122 loss)
I0626 06:37:59.183801  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0039249 (* 1 = 0.0039249 loss)
I0626 06:37:59.183806  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00741419 (* 1 = 0.00741419 loss)
I0626 06:37:59.183814  6673 sgd_solver.cpp:106] Iteration 11420, lr = 0.0002
I0626 06:39:37.505518  6673 solver.cpp:228] Iteration 11440, loss = 0.283254
I0626 06:39:37.505545  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 06:39:37.505553  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.12154 (* 1 = 0.12154 loss)
I0626 06:39:37.505556  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.162892 (* 1 = 0.162892 loss)
I0626 06:39:37.505560  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000582548 (* 1 = 0.000582548 loss)
I0626 06:39:37.505564  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00857829 (* 1 = 0.00857829 loss)
I0626 06:39:37.505569  6673 sgd_solver.cpp:106] Iteration 11440, lr = 0.0002
I0626 06:41:15.806100  6673 solver.cpp:228] Iteration 11460, loss = 0.278179
I0626 06:41:15.806128  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 06:41:15.806138  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0211309 (* 1 = 0.0211309 loss)
I0626 06:41:15.806144  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.1106 (* 1 = 0.1106 loss)
I0626 06:41:15.806150  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00790003 (* 1 = 0.00790003 loss)
I0626 06:41:15.806156  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131932 (* 1 = 0.0131932 loss)
I0626 06:41:15.806164  6673 sgd_solver.cpp:106] Iteration 11460, lr = 0.0002
I0626 06:42:54.051853  6673 solver.cpp:228] Iteration 11480, loss = 0.543584
I0626 06:42:54.051884  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 06:42:54.051892  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0964252 (* 1 = 0.0964252 loss)
I0626 06:42:54.051895  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.12098 (* 1 = 0.12098 loss)
I0626 06:42:54.051899  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00417884 (* 1 = 0.00417884 loss)
I0626 06:42:54.051903  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141892 (* 1 = 0.0141892 loss)
I0626 06:42:54.051908  6673 sgd_solver.cpp:106] Iteration 11480, lr = 0.0002
I0626 06:44:32.459841  6673 solver.cpp:228] Iteration 11500, loss = 0.194286
I0626 06:44:32.459867  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 06:44:32.459877  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0969109 (* 1 = 0.0969109 loss)
I0626 06:44:32.459882  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.15278 (* 1 = 0.15278 loss)
I0626 06:44:32.459887  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00551051 (* 1 = 0.00551051 loss)
I0626 06:44:32.459892  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00879941 (* 1 = 0.00879941 loss)
I0626 06:44:32.459898  6673 sgd_solver.cpp:106] Iteration 11500, lr = 0.0002
I0626 06:46:10.802284  6673 solver.cpp:228] Iteration 11520, loss = 0.272703
I0626 06:46:10.802307  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 06:46:10.802315  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105769 (* 1 = 0.105769 loss)
I0626 06:46:10.802320  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.277234 (* 1 = 0.277234 loss)
I0626 06:46:10.802323  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126157 (* 1 = 0.00126157 loss)
I0626 06:46:10.802328  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207145 (* 1 = 0.0207145 loss)
I0626 06:46:10.802333  6673 sgd_solver.cpp:106] Iteration 11520, lr = 0.0002
I0626 06:47:49.309813  6673 solver.cpp:228] Iteration 11540, loss = 0.302777
I0626 06:47:49.309839  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 06:47:49.309846  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.127639 (* 1 = 0.127639 loss)
I0626 06:47:49.309850  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.327006 (* 1 = 0.327006 loss)
I0626 06:47:49.309854  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00594807 (* 1 = 0.00594807 loss)
I0626 06:47:49.309859  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019672 (* 1 = 0.019672 loss)
I0626 06:47:49.309864  6673 sgd_solver.cpp:106] Iteration 11540, lr = 0.0002
I0626 06:49:27.789158  6673 solver.cpp:228] Iteration 11560, loss = 0.348107
I0626 06:49:27.789202  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 06:49:27.789209  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286105 (* 1 = 0.0286105 loss)
I0626 06:49:27.789214  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.087981 (* 1 = 0.087981 loss)
I0626 06:49:27.789218  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000882333 (* 1 = 0.000882333 loss)
I0626 06:49:27.789222  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197519 (* 1 = 0.0197519 loss)
I0626 06:49:27.789229  6673 sgd_solver.cpp:106] Iteration 11560, lr = 0.0002
I0626 06:51:06.203132  6673 solver.cpp:228] Iteration 11580, loss = 0.35045
I0626 06:51:06.203155  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 06:51:06.203162  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322202 (* 1 = 0.0322202 loss)
I0626 06:51:06.203166  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0894654 (* 1 = 0.0894654 loss)
I0626 06:51:06.203171  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160088 (* 1 = 0.00160088 loss)
I0626 06:51:06.203173  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103044 (* 1 = 0.0103044 loss)
I0626 06:51:06.203178  6673 sgd_solver.cpp:106] Iteration 11580, lr = 0.0002
speed: 4.929s / iter
I0626 06:52:45.140234  6673 solver.cpp:228] Iteration 11600, loss = 0.212559
I0626 06:52:45.140259  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:52:45.140267  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0957855 (* 1 = 0.0957855 loss)
I0626 06:52:45.140271  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.137348 (* 1 = 0.137348 loss)
I0626 06:52:45.140275  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000268916 (* 1 = 0.000268916 loss)
I0626 06:52:45.140280  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121215 (* 1 = 0.0121215 loss)
I0626 06:52:45.140285  6673 sgd_solver.cpp:106] Iteration 11600, lr = 0.0002
I0626 06:54:24.389303  6673 solver.cpp:228] Iteration 11620, loss = 0.19488
I0626 06:54:24.389327  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 06:54:24.389336  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.11421 (* 1 = 0.11421 loss)
I0626 06:54:24.389343  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.224427 (* 1 = 0.224427 loss)
I0626 06:54:24.389348  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00062892 (* 1 = 0.00062892 loss)
I0626 06:54:24.389353  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198313 (* 1 = 0.0198313 loss)
I0626 06:54:24.389361  6673 sgd_solver.cpp:106] Iteration 11620, lr = 0.0002
I0626 06:56:03.390898  6673 solver.cpp:228] Iteration 11640, loss = 0.304804
I0626 06:56:03.390925  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 06:56:03.390933  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.144885 (* 1 = 0.144885 loss)
I0626 06:56:03.390939  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.236144 (* 1 = 0.236144 loss)
I0626 06:56:03.390946  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0458188 (* 1 = 0.0458188 loss)
I0626 06:56:03.390950  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.221551 (* 1 = 0.221551 loss)
I0626 06:56:03.390955  6673 sgd_solver.cpp:106] Iteration 11640, lr = 0.0002
I0626 06:57:42.434459  6673 solver.cpp:228] Iteration 11660, loss = 0.298448
I0626 06:57:42.434495  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 06:57:42.434505  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00773537 (* 1 = 0.00773537 loss)
I0626 06:57:42.434511  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0392004 (* 1 = 0.0392004 loss)
I0626 06:57:42.434517  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183791 (* 1 = 0.00183791 loss)
I0626 06:57:42.434523  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00610236 (* 1 = 0.00610236 loss)
I0626 06:57:42.434530  6673 sgd_solver.cpp:106] Iteration 11660, lr = 0.0002
I0626 06:59:21.613242  6673 solver.cpp:228] Iteration 11680, loss = 0.222284
I0626 06:59:21.613267  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 06:59:21.613276  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229707 (* 1 = 0.0229707 loss)
I0626 06:59:21.613282  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0950767 (* 1 = 0.0950767 loss)
I0626 06:59:21.613287  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00143717 (* 1 = 0.00143717 loss)
I0626 06:59:21.613292  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134064 (* 1 = 0.0134064 loss)
I0626 06:59:21.613301  6673 sgd_solver.cpp:106] Iteration 11680, lr = 0.0002
I0626 07:01:00.489524  6673 solver.cpp:228] Iteration 11700, loss = 0.251441
I0626 07:01:00.489549  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 07:01:00.489557  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0796311 (* 1 = 0.0796311 loss)
I0626 07:01:00.489560  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.14537 (* 1 = 0.14537 loss)
I0626 07:01:00.489564  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000285136 (* 1 = 0.000285136 loss)
I0626 07:01:00.489567  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0066772 (* 1 = 0.0066772 loss)
I0626 07:01:00.489572  6673 sgd_solver.cpp:106] Iteration 11700, lr = 0.0002
I0626 07:02:39.246875  6673 solver.cpp:228] Iteration 11720, loss = 0.13864
I0626 07:02:39.246898  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 07:02:39.246906  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.007169 (* 1 = 0.007169 loss)
I0626 07:02:39.246909  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0289992 (* 1 = 0.0289992 loss)
I0626 07:02:39.246913  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00308604 (* 1 = 0.00308604 loss)
I0626 07:02:39.246917  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00380963 (* 1 = 0.00380963 loss)
I0626 07:02:39.246920  6673 sgd_solver.cpp:106] Iteration 11720, lr = 0.0002
I0626 07:04:17.829589  6673 solver.cpp:228] Iteration 11740, loss = 0.453094
I0626 07:04:17.829617  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0626 07:04:17.829625  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.505974 (* 1 = 0.505974 loss)
I0626 07:04:17.829630  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.678349 (* 1 = 0.678349 loss)
I0626 07:04:17.829636  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0473285 (* 1 = 0.0473285 loss)
I0626 07:04:17.829641  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.189469 (* 1 = 0.189469 loss)
I0626 07:04:17.829648  6673 sgd_solver.cpp:106] Iteration 11740, lr = 0.0002
I0626 07:05:56.656579  6673 solver.cpp:228] Iteration 11760, loss = 0.135594
I0626 07:05:56.656605  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:05:56.656612  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791816 (* 1 = 0.0791816 loss)
I0626 07:05:56.656616  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.053387 (* 1 = 0.053387 loss)
I0626 07:05:56.656620  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00580808 (* 1 = 0.00580808 loss)
I0626 07:05:56.656625  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570681 (* 1 = 0.00570681 loss)
I0626 07:05:56.656630  6673 sgd_solver.cpp:106] Iteration 11760, lr = 0.0002
I0626 07:07:35.329505  6673 solver.cpp:228] Iteration 11780, loss = 0.20103
I0626 07:07:35.329530  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 07:07:35.329538  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465168 (* 1 = 0.0465168 loss)
I0626 07:07:35.329542  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0949474 (* 1 = 0.0949474 loss)
I0626 07:07:35.329546  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026433 (* 1 = 0.0026433 loss)
I0626 07:07:35.329550  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01075 (* 1 = 0.01075 loss)
I0626 07:07:35.329555  6673 sgd_solver.cpp:106] Iteration 11780, lr = 0.0002
speed: 4.929s / iter
I0626 07:09:14.063458  6673 solver.cpp:228] Iteration 11800, loss = 0.358649
I0626 07:09:14.063490  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 07:09:14.063501  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.208024 (* 1 = 0.208024 loss)
I0626 07:09:14.063508  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.443005 (* 1 = 0.443005 loss)
I0626 07:09:14.063516  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00536856 (* 1 = 0.00536856 loss)
I0626 07:09:14.063524  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402674 (* 1 = 0.0402674 loss)
I0626 07:09:14.063531  6673 sgd_solver.cpp:106] Iteration 11800, lr = 0.0002
I0626 07:10:52.543706  6673 solver.cpp:228] Iteration 11820, loss = 0.192762
I0626 07:10:52.543735  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:10:52.543743  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360975 (* 1 = 0.0360975 loss)
I0626 07:10:52.543750  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0791807 (* 1 = 0.0791807 loss)
I0626 07:10:52.543756  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105979 (* 1 = 0.0105979 loss)
I0626 07:10:52.543761  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00443761 (* 1 = 0.00443761 loss)
I0626 07:10:52.543771  6673 sgd_solver.cpp:106] Iteration 11820, lr = 0.0002
I0626 07:12:31.010520  6673 solver.cpp:228] Iteration 11840, loss = 0.239807
I0626 07:12:31.010545  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:12:31.010552  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228398 (* 1 = 0.0228398 loss)
I0626 07:12:31.010556  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0458304 (* 1 = 0.0458304 loss)
I0626 07:12:31.010560  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00988657 (* 1 = 0.00988657 loss)
I0626 07:12:31.010563  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00198118 (* 1 = 0.00198118 loss)
I0626 07:12:31.010568  6673 sgd_solver.cpp:106] Iteration 11840, lr = 0.0002
I0626 07:14:09.037156  6673 solver.cpp:228] Iteration 11860, loss = 0.164516
I0626 07:14:09.037181  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:14:09.037191  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595693 (* 1 = 0.0595693 loss)
I0626 07:14:09.037199  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0987955 (* 1 = 0.0987955 loss)
I0626 07:14:09.037204  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00216665 (* 1 = 0.00216665 loss)
I0626 07:14:09.037210  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127835 (* 1 = 0.0127835 loss)
I0626 07:14:09.037217  6673 sgd_solver.cpp:106] Iteration 11860, lr = 0.0002
I0626 07:15:47.028278  6673 solver.cpp:228] Iteration 11880, loss = 0.241044
I0626 07:15:47.028304  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:15:47.028314  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120483 (* 1 = 0.0120483 loss)
I0626 07:15:47.028321  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0486752 (* 1 = 0.0486752 loss)
I0626 07:15:47.028327  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00147244 (* 1 = 0.00147244 loss)
I0626 07:15:47.028333  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00968641 (* 1 = 0.00968641 loss)
I0626 07:15:47.028339  6673 sgd_solver.cpp:106] Iteration 11880, lr = 0.0002
I0626 07:17:25.052809  6673 solver.cpp:228] Iteration 11900, loss = 0.374909
I0626 07:17:25.052835  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:17:25.052842  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791771 (* 1 = 0.0791771 loss)
I0626 07:17:25.052847  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.101718 (* 1 = 0.101718 loss)
I0626 07:17:25.052851  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000442582 (* 1 = 0.000442582 loss)
I0626 07:17:25.052855  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00949195 (* 1 = 0.00949195 loss)
I0626 07:17:25.052860  6673 sgd_solver.cpp:106] Iteration 11900, lr = 0.0002
I0626 07:19:03.078035  6673 solver.cpp:228] Iteration 11920, loss = 0.434029
I0626 07:19:03.078059  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:19:03.078068  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0528054 (* 1 = 0.0528054 loss)
I0626 07:19:03.078073  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.113765 (* 1 = 0.113765 loss)
I0626 07:19:03.078078  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169417 (* 1 = 0.0169417 loss)
I0626 07:19:03.078083  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197622 (* 1 = 0.0197622 loss)
I0626 07:19:03.078090  6673 sgd_solver.cpp:106] Iteration 11920, lr = 0.0002
I0626 07:20:40.999840  6673 solver.cpp:228] Iteration 11940, loss = 0.316619
I0626 07:20:40.999864  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 07:20:40.999872  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855111 (* 1 = 0.0855111 loss)
I0626 07:20:40.999876  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.117276 (* 1 = 0.117276 loss)
I0626 07:20:40.999881  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00527508 (* 1 = 0.00527508 loss)
I0626 07:20:40.999884  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186294 (* 1 = 0.0186294 loss)
I0626 07:20:40.999888  6673 sgd_solver.cpp:106] Iteration 11940, lr = 0.0002
I0626 07:22:18.980267  6673 solver.cpp:228] Iteration 11960, loss = 0.301884
I0626 07:22:18.980290  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 07:22:18.980298  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.169978 (* 1 = 0.169978 loss)
I0626 07:22:18.980303  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.250988 (* 1 = 0.250988 loss)
I0626 07:22:18.980306  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247464 (* 1 = 0.0247464 loss)
I0626 07:22:18.980310  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0694776 (* 1 = 0.0694776 loss)
I0626 07:22:18.980315  6673 sgd_solver.cpp:106] Iteration 11960, lr = 0.0002
I0626 07:23:57.066546  6673 solver.cpp:228] Iteration 11980, loss = 0.181552
I0626 07:23:57.066571  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:23:57.066581  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0366186 (* 1 = 0.0366186 loss)
I0626 07:23:57.066586  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0829254 (* 1 = 0.0829254 loss)
I0626 07:23:57.066591  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231311 (* 1 = 0.00231311 loss)
I0626 07:23:57.066597  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326532 (* 1 = 0.0326532 loss)
I0626 07:23:57.066603  6673 sgd_solver.cpp:106] Iteration 11980, lr = 0.0002
speed: 4.929s / iter
I0626 07:25:35.250284  6673 solver.cpp:228] Iteration 12000, loss = 0.353733
I0626 07:25:35.250306  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:25:35.250313  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0775301 (* 1 = 0.0775301 loss)
I0626 07:25:35.250317  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109528 (* 1 = 0.109528 loss)
I0626 07:25:35.250321  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00490954 (* 1 = 0.00490954 loss)
I0626 07:25:35.250324  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137059 (* 1 = 0.0137059 loss)
I0626 07:25:35.250329  6673 sgd_solver.cpp:106] Iteration 12000, lr = 0.0002
I0626 07:27:13.328043  6673 solver.cpp:228] Iteration 12020, loss = 0.422889
I0626 07:27:13.328070  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:27:13.328080  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0611408 (* 1 = 0.0611408 loss)
I0626 07:27:13.328088  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0545896 (* 1 = 0.0545896 loss)
I0626 07:27:13.328094  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126827 (* 1 = 0.00126827 loss)
I0626 07:27:13.328099  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109066 (* 1 = 0.0109066 loss)
I0626 07:27:13.328106  6673 sgd_solver.cpp:106] Iteration 12020, lr = 0.0002
I0626 07:28:51.403151  6673 solver.cpp:228] Iteration 12040, loss = 0.212566
I0626 07:28:51.403177  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 07:28:51.403183  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322477 (* 1 = 0.0322477 loss)
I0626 07:28:51.403187  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.120072 (* 1 = 0.120072 loss)
I0626 07:28:51.403192  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00180715 (* 1 = 0.00180715 loss)
I0626 07:28:51.403196  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035358 (* 1 = 0.035358 loss)
I0626 07:28:51.403201  6673 sgd_solver.cpp:106] Iteration 12040, lr = 0.0002
I0626 07:30:29.623204  6673 solver.cpp:228] Iteration 12060, loss = 0.309757
I0626 07:30:29.623229  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:30:29.623235  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609534 (* 1 = 0.0609534 loss)
I0626 07:30:29.623239  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0680877 (* 1 = 0.0680877 loss)
I0626 07:30:29.623242  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000720929 (* 1 = 0.000720929 loss)
I0626 07:30:29.623246  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00670971 (* 1 = 0.00670971 loss)
I0626 07:30:29.623250  6673 sgd_solver.cpp:106] Iteration 12060, lr = 0.0002
I0626 07:32:07.879133  6673 solver.cpp:228] Iteration 12080, loss = 0.31127
I0626 07:32:07.879158  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 07:32:07.879165  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0732375 (* 1 = 0.0732375 loss)
I0626 07:32:07.879169  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.324989 (* 1 = 0.324989 loss)
I0626 07:32:07.879173  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00918058 (* 1 = 0.00918058 loss)
I0626 07:32:07.879176  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306421 (* 1 = 0.0306421 loss)
I0626 07:32:07.879181  6673 sgd_solver.cpp:106] Iteration 12080, lr = 0.0002
I0626 07:33:46.067942  6673 solver.cpp:228] Iteration 12100, loss = 0.160072
I0626 07:33:46.067967  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 07:33:46.067975  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0788156 (* 1 = 0.0788156 loss)
I0626 07:33:46.067979  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.137094 (* 1 = 0.137094 loss)
I0626 07:33:46.067983  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012819 (* 1 = 0.012819 loss)
I0626 07:33:46.067987  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165964 (* 1 = 0.0165964 loss)
I0626 07:33:46.067991  6673 sgd_solver.cpp:106] Iteration 12100, lr = 0.0002
I0626 07:35:24.005298  6673 solver.cpp:228] Iteration 12120, loss = 0.273759
I0626 07:35:24.005323  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:35:24.005331  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360248 (* 1 = 0.0360248 loss)
I0626 07:35:24.005336  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0516368 (* 1 = 0.0516368 loss)
I0626 07:35:24.005340  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000641195 (* 1 = 0.000641195 loss)
I0626 07:35:24.005343  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167555 (* 1 = 0.0167555 loss)
I0626 07:35:24.005348  6673 sgd_solver.cpp:106] Iteration 12120, lr = 0.0002
I0626 07:37:01.921756  6673 solver.cpp:228] Iteration 12140, loss = 0.101875
I0626 07:37:01.921779  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:37:01.921787  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174958 (* 1 = 0.0174958 loss)
I0626 07:37:01.921790  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0364634 (* 1 = 0.0364634 loss)
I0626 07:37:01.921794  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00092169 (* 1 = 0.00092169 loss)
I0626 07:37:01.921797  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00711114 (* 1 = 0.00711114 loss)
I0626 07:37:01.921802  6673 sgd_solver.cpp:106] Iteration 12140, lr = 0.0002
I0626 07:38:39.830835  6673 solver.cpp:228] Iteration 12160, loss = 0.22184
I0626 07:38:39.830869  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 07:38:39.830879  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0444473 (* 1 = 0.0444473 loss)
I0626 07:38:39.830886  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.177939 (* 1 = 0.177939 loss)
I0626 07:38:39.830891  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00459871 (* 1 = 0.00459871 loss)
I0626 07:38:39.830898  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00661789 (* 1 = 0.00661789 loss)
I0626 07:38:39.830904  6673 sgd_solver.cpp:106] Iteration 12160, lr = 0.0002
I0626 07:40:17.760531  6673 solver.cpp:228] Iteration 12180, loss = 0.275226
I0626 07:40:17.760555  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 07:40:17.760562  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743368 (* 1 = 0.0743368 loss)
I0626 07:40:17.760566  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.268165 (* 1 = 0.268165 loss)
I0626 07:40:17.760571  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.001797 (* 1 = 0.001797 loss)
I0626 07:40:17.760573  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326094 (* 1 = 0.0326094 loss)
I0626 07:40:17.760578  6673 sgd_solver.cpp:106] Iteration 12180, lr = 0.0002
speed: 4.928s / iter
I0626 07:41:55.639359  6673 solver.cpp:228] Iteration 12200, loss = 0.308784
I0626 07:41:55.639381  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:41:55.639389  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453344 (* 1 = 0.0453344 loss)
I0626 07:41:55.639392  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0371756 (* 1 = 0.0371756 loss)
I0626 07:41:55.639396  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296067 (* 1 = 0.00296067 loss)
I0626 07:41:55.639400  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00660981 (* 1 = 0.00660981 loss)
I0626 07:41:55.639405  6673 sgd_solver.cpp:106] Iteration 12200, lr = 0.0002
I0626 07:43:33.666561  6673 solver.cpp:228] Iteration 12220, loss = 0.18463
I0626 07:43:33.666585  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 07:43:33.666594  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0230016 (* 1 = 0.0230016 loss)
I0626 07:43:33.666597  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0479144 (* 1 = 0.0479144 loss)
I0626 07:43:33.666601  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00302564 (* 1 = 0.00302564 loss)
I0626 07:43:33.666605  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00751661 (* 1 = 0.00751661 loss)
I0626 07:43:33.666610  6673 sgd_solver.cpp:106] Iteration 12220, lr = 0.0002
I0626 07:45:11.796495  6673 solver.cpp:228] Iteration 12240, loss = 0.195076
I0626 07:45:11.796520  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:45:11.796528  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.010041 (* 1 = 0.010041 loss)
I0626 07:45:11.796532  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0361214 (* 1 = 0.0361214 loss)
I0626 07:45:11.796536  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239243 (* 1 = 0.00239243 loss)
I0626 07:45:11.796541  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00925841 (* 1 = 0.00925841 loss)
I0626 07:45:11.796546  6673 sgd_solver.cpp:106] Iteration 12240, lr = 0.0002
I0626 07:46:49.681545  6673 solver.cpp:228] Iteration 12260, loss = 0.409493
I0626 07:46:49.681571  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 07:46:49.681577  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.149596 (* 1 = 0.149596 loss)
I0626 07:46:49.681582  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.270031 (* 1 = 0.270031 loss)
I0626 07:46:49.681586  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00986214 (* 1 = 0.00986214 loss)
I0626 07:46:49.681591  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375193 (* 1 = 0.0375193 loss)
I0626 07:46:49.681596  6673 sgd_solver.cpp:106] Iteration 12260, lr = 0.0002
I0626 07:48:27.612931  6673 solver.cpp:228] Iteration 12280, loss = 0.180394
I0626 07:48:27.612957  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 07:48:27.612963  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151031 (* 1 = 0.0151031 loss)
I0626 07:48:27.612967  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.036436 (* 1 = 0.036436 loss)
I0626 07:48:27.612972  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000232025 (* 1 = 0.000232025 loss)
I0626 07:48:27.612974  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00333478 (* 1 = 0.00333478 loss)
I0626 07:48:27.612979  6673 sgd_solver.cpp:106] Iteration 12280, lr = 0.0002
I0626 07:50:05.489094  6673 solver.cpp:228] Iteration 12300, loss = 0.24257
I0626 07:50:05.489117  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 07:50:05.489125  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509702 (* 1 = 0.0509702 loss)
I0626 07:50:05.489128  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0930113 (* 1 = 0.0930113 loss)
I0626 07:50:05.489131  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000876321 (* 1 = 0.000876321 loss)
I0626 07:50:05.489135  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125412 (* 1 = 0.0125412 loss)
I0626 07:50:05.489140  6673 sgd_solver.cpp:106] Iteration 12300, lr = 0.0002
I0626 07:51:43.406327  6673 solver.cpp:228] Iteration 12320, loss = 0.140299
I0626 07:51:43.406349  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 07:51:43.406357  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.039232 (* 1 = 0.039232 loss)
I0626 07:51:43.406360  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0752433 (* 1 = 0.0752433 loss)
I0626 07:51:43.406364  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016125 (* 1 = 0.0016125 loss)
I0626 07:51:43.406368  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263973 (* 1 = 0.0263973 loss)
I0626 07:51:43.406374  6673 sgd_solver.cpp:106] Iteration 12320, lr = 0.0002
I0626 07:53:21.297567  6673 solver.cpp:228] Iteration 12340, loss = 0.209089
I0626 07:53:21.297591  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 07:53:21.297598  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244164 (* 1 = 0.0244164 loss)
I0626 07:53:21.297602  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0398072 (* 1 = 0.0398072 loss)
I0626 07:53:21.297606  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.56408e-05 (* 1 = 8.56408e-05 loss)
I0626 07:53:21.297610  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00457912 (* 1 = 0.00457912 loss)
I0626 07:53:21.297613  6673 sgd_solver.cpp:106] Iteration 12340, lr = 0.0002
I0626 07:54:59.182234  6673 solver.cpp:228] Iteration 12360, loss = 0.257486
I0626 07:54:59.182257  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 07:54:59.182265  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0396828 (* 1 = 0.0396828 loss)
I0626 07:54:59.182269  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.103691 (* 1 = 0.103691 loss)
I0626 07:54:59.182273  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484359 (* 1 = 0.00484359 loss)
I0626 07:54:59.182277  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00411555 (* 1 = 0.00411555 loss)
I0626 07:54:59.182282  6673 sgd_solver.cpp:106] Iteration 12360, lr = 0.0002
I0626 07:56:37.103492  6673 solver.cpp:228] Iteration 12380, loss = 0.163706
I0626 07:56:37.103518  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 07:56:37.103528  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0420181 (* 1 = 0.0420181 loss)
I0626 07:56:37.103534  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.158119 (* 1 = 0.158119 loss)
I0626 07:56:37.103540  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108357 (* 1 = 0.00108357 loss)
I0626 07:56:37.103546  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113108 (* 1 = 0.0113108 loss)
I0626 07:56:37.103552  6673 sgd_solver.cpp:106] Iteration 12380, lr = 0.0002
speed: 4.928s / iter
I0626 07:58:15.007925  6673 solver.cpp:228] Iteration 12400, loss = 0.334833
I0626 07:58:15.007949  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 07:58:15.007957  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199578 (* 1 = 0.0199578 loss)
I0626 07:58:15.007961  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0639466 (* 1 = 0.0639466 loss)
I0626 07:58:15.007966  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000258704 (* 1 = 0.000258704 loss)
I0626 07:58:15.007969  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00148345 (* 1 = 0.00148345 loss)
I0626 07:58:15.007974  6673 sgd_solver.cpp:106] Iteration 12400, lr = 0.0002
I0626 07:59:52.918763  6673 solver.cpp:228] Iteration 12420, loss = 0.156624
I0626 07:59:52.918789  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 07:59:52.918798  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0784971 (* 1 = 0.0784971 loss)
I0626 07:59:52.918804  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.162931 (* 1 = 0.162931 loss)
I0626 07:59:52.918809  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226359 (* 1 = 0.00226359 loss)
I0626 07:59:52.918815  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014488 (* 1 = 0.014488 loss)
I0626 07:59:52.918821  6673 sgd_solver.cpp:106] Iteration 12420, lr = 0.0002
I0626 08:01:30.881682  6673 solver.cpp:228] Iteration 12440, loss = 0.2312
I0626 08:01:30.881706  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 08:01:30.881714  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481789 (* 1 = 0.0481789 loss)
I0626 08:01:30.881718  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.14148 (* 1 = 0.14148 loss)
I0626 08:01:30.881722  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218327 (* 1 = 0.0218327 loss)
I0626 08:01:30.881726  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414425 (* 1 = 0.0414425 loss)
I0626 08:01:30.881731  6673 sgd_solver.cpp:106] Iteration 12440, lr = 0.0002
I0626 08:03:08.756582  6673 solver.cpp:228] Iteration 12460, loss = 0.242037
I0626 08:03:08.756605  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:03:08.756613  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0612903 (* 1 = 0.0612903 loss)
I0626 08:03:08.756618  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0818053 (* 1 = 0.0818053 loss)
I0626 08:03:08.756621  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0041279 (* 1 = 0.0041279 loss)
I0626 08:03:08.756625  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235769 (* 1 = 0.0235769 loss)
I0626 08:03:08.756630  6673 sgd_solver.cpp:106] Iteration 12460, lr = 0.0002
I0626 08:04:46.653611  6673 solver.cpp:228] Iteration 12480, loss = 0.280427
I0626 08:04:46.653635  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:04:46.653643  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340454 (* 1 = 0.0340454 loss)
I0626 08:04:46.653648  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0561592 (* 1 = 0.0561592 loss)
I0626 08:04:46.653652  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000703936 (* 1 = 0.000703936 loss)
I0626 08:04:46.653656  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00997518 (* 1 = 0.00997518 loss)
I0626 08:04:46.653661  6673 sgd_solver.cpp:106] Iteration 12480, lr = 0.0002
I0626 08:06:24.589807  6673 solver.cpp:228] Iteration 12500, loss = 0.308279
I0626 08:06:24.589830  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 08:06:24.589839  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157825 (* 1 = 0.0157825 loss)
I0626 08:06:24.589843  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.11208 (* 1 = 0.11208 loss)
I0626 08:06:24.589848  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00393926 (* 1 = 0.00393926 loss)
I0626 08:06:24.589851  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033147 (* 1 = 0.033147 loss)
I0626 08:06:24.589856  6673 sgd_solver.cpp:106] Iteration 12500, lr = 0.0002
I0626 08:08:02.539111  6673 solver.cpp:228] Iteration 12520, loss = 0.333153
I0626 08:08:02.539134  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:08:02.539141  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0146375 (* 1 = 0.0146375 loss)
I0626 08:08:02.539145  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0408461 (* 1 = 0.0408461 loss)
I0626 08:08:02.539149  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.20258e-05 (* 1 = 7.20258e-05 loss)
I0626 08:08:02.539152  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00337427 (* 1 = 0.00337427 loss)
I0626 08:08:02.539156  6673 sgd_solver.cpp:106] Iteration 12520, lr = 0.0002
I0626 08:09:40.365005  6673 solver.cpp:228] Iteration 12540, loss = 0.121225
I0626 08:09:40.365028  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:09:40.365036  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0136086 (* 1 = 0.0136086 loss)
I0626 08:09:40.365039  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0408342 (* 1 = 0.0408342 loss)
I0626 08:09:40.365042  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108996 (* 1 = 0.00108996 loss)
I0626 08:09:40.365046  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0062631 (* 1 = 0.0062631 loss)
I0626 08:09:40.365051  6673 sgd_solver.cpp:106] Iteration 12540, lr = 0.0002
I0626 08:11:18.347383  6673 solver.cpp:228] Iteration 12560, loss = 0.255765
I0626 08:11:18.347409  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:11:18.347415  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199556 (* 1 = 0.0199556 loss)
I0626 08:11:18.347419  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0368945 (* 1 = 0.0368945 loss)
I0626 08:11:18.347424  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000338108 (* 1 = 0.000338108 loss)
I0626 08:11:18.347426  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00796254 (* 1 = 0.00796254 loss)
I0626 08:11:18.347430  6673 sgd_solver.cpp:106] Iteration 12560, lr = 0.0002
I0626 08:12:56.127727  6673 solver.cpp:228] Iteration 12580, loss = 0.24726
I0626 08:12:56.127753  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 08:12:56.127761  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0846018 (* 1 = 0.0846018 loss)
I0626 08:12:56.127768  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.171376 (* 1 = 0.171376 loss)
I0626 08:12:56.127774  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000693779 (* 1 = 0.000693779 loss)
I0626 08:12:56.127781  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160458 (* 1 = 0.0160458 loss)
I0626 08:12:56.127789  6673 sgd_solver.cpp:106] Iteration 12580, lr = 0.0002
speed: 4.927s / iter
I0626 08:14:33.926017  6673 solver.cpp:228] Iteration 12600, loss = 0.22116
I0626 08:14:33.926044  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:14:33.926053  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.015373 (* 1 = 0.015373 loss)
I0626 08:14:33.926057  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.121293 (* 1 = 0.121293 loss)
I0626 08:14:33.926062  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363901 (* 1 = 0.00363901 loss)
I0626 08:14:33.926067  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00120608 (* 1 = 0.00120608 loss)
I0626 08:14:33.926072  6673 sgd_solver.cpp:106] Iteration 12600, lr = 0.0002
I0626 08:16:11.751925  6673 solver.cpp:228] Iteration 12620, loss = 0.195443
I0626 08:16:11.751947  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 08:16:11.751955  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00717569 (* 1 = 0.00717569 loss)
I0626 08:16:11.751957  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0393296 (* 1 = 0.0393296 loss)
I0626 08:16:11.751961  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.67609e-05 (* 1 = 5.67609e-05 loss)
I0626 08:16:11.751965  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00290393 (* 1 = 0.00290393 loss)
I0626 08:16:11.751968  6673 sgd_solver.cpp:106] Iteration 12620, lr = 0.0002
I0626 08:17:49.648373  6673 solver.cpp:228] Iteration 12640, loss = 0.18275
I0626 08:17:49.648396  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 08:17:49.648403  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.118718 (* 1 = 0.118718 loss)
I0626 08:17:49.648407  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.241038 (* 1 = 0.241038 loss)
I0626 08:17:49.648411  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264022 (* 1 = 0.00264022 loss)
I0626 08:17:49.648414  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196968 (* 1 = 0.0196968 loss)
I0626 08:17:49.648419  6673 sgd_solver.cpp:106] Iteration 12640, lr = 0.0002
I0626 08:19:27.490093  6673 solver.cpp:228] Iteration 12660, loss = 0.237268
I0626 08:19:27.490123  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:19:27.490129  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261528 (* 1 = 0.0261528 loss)
I0626 08:19:27.490134  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0317529 (* 1 = 0.0317529 loss)
I0626 08:19:27.490137  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000319963 (* 1 = 0.000319963 loss)
I0626 08:19:27.490141  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00446753 (* 1 = 0.00446753 loss)
I0626 08:19:27.490145  6673 sgd_solver.cpp:106] Iteration 12660, lr = 0.0002
I0626 08:21:05.294003  6673 solver.cpp:228] Iteration 12680, loss = 0.32542
I0626 08:21:05.294028  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0626 08:21:05.294034  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.315539 (* 1 = 0.315539 loss)
I0626 08:21:05.294039  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.506227 (* 1 = 0.506227 loss)
I0626 08:21:05.294044  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232156 (* 1 = 0.0232156 loss)
I0626 08:21:05.294049  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112396 (* 1 = 0.112396 loss)
I0626 08:21:05.294055  6673 sgd_solver.cpp:106] Iteration 12680, lr = 0.0002
I0626 08:22:42.998060  6673 solver.cpp:228] Iteration 12700, loss = 0.165531
I0626 08:22:42.998085  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:22:42.998091  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0745038 (* 1 = 0.0745038 loss)
I0626 08:22:42.998095  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0868692 (* 1 = 0.0868692 loss)
I0626 08:22:42.998098  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00298995 (* 1 = 0.00298995 loss)
I0626 08:22:42.998102  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128281 (* 1 = 0.0128281 loss)
I0626 08:22:42.998106  6673 sgd_solver.cpp:106] Iteration 12700, lr = 0.0002
I0626 08:24:20.808137  6673 solver.cpp:228] Iteration 12720, loss = 0.217868
I0626 08:24:20.808163  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:24:20.808173  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0479768 (* 1 = 0.0479768 loss)
I0626 08:24:20.808181  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0672218 (* 1 = 0.0672218 loss)
I0626 08:24:20.808187  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000793991 (* 1 = 0.000793991 loss)
I0626 08:24:20.808192  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120825 (* 1 = 0.0120825 loss)
I0626 08:24:20.808200  6673 sgd_solver.cpp:106] Iteration 12720, lr = 0.0002
I0626 08:25:58.611368  6673 solver.cpp:228] Iteration 12740, loss = 0.239402
I0626 08:25:58.611390  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 08:25:58.611397  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0658397 (* 1 = 0.0658397 loss)
I0626 08:25:58.611400  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.134576 (* 1 = 0.134576 loss)
I0626 08:25:58.611403  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153403 (* 1 = 0.0153403 loss)
I0626 08:25:58.611407  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.112606 (* 1 = 0.112606 loss)
I0626 08:25:58.611410  6673 sgd_solver.cpp:106] Iteration 12740, lr = 0.0002
I0626 08:27:36.467193  6673 solver.cpp:228] Iteration 12760, loss = 0.167127
I0626 08:27:36.467217  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 08:27:36.467224  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0471847 (* 1 = 0.0471847 loss)
I0626 08:27:36.467227  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0519432 (* 1 = 0.0519432 loss)
I0626 08:27:36.467231  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000738283 (* 1 = 0.000738283 loss)
I0626 08:27:36.467234  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151248 (* 1 = 0.0151248 loss)
I0626 08:27:36.467238  6673 sgd_solver.cpp:106] Iteration 12760, lr = 0.0002
I0626 08:29:14.277253  6673 solver.cpp:228] Iteration 12780, loss = 0.374625
I0626 08:29:14.277279  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 08:29:14.277287  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0541881 (* 1 = 0.0541881 loss)
I0626 08:29:14.277289  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.184644 (* 1 = 0.184644 loss)
I0626 08:29:14.277293  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00523357 (* 1 = 0.00523357 loss)
I0626 08:29:14.277297  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0496778 (* 1 = 0.0496778 loss)
I0626 08:29:14.277302  6673 sgd_solver.cpp:106] Iteration 12780, lr = 0.0002
speed: 4.927s / iter
I0626 08:30:52.085325  6673 solver.cpp:228] Iteration 12800, loss = 0.359895
I0626 08:30:52.085355  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 08:30:52.085362  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.143164 (* 1 = 0.143164 loss)
I0626 08:30:52.085366  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.170765 (* 1 = 0.170765 loss)
I0626 08:30:52.085371  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115063 (* 1 = 0.00115063 loss)
I0626 08:30:52.085373  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370713 (* 1 = 0.0370713 loss)
I0626 08:30:52.085378  6673 sgd_solver.cpp:106] Iteration 12800, lr = 0.0002
I0626 08:32:29.844177  6673 solver.cpp:228] Iteration 12820, loss = 0.177068
I0626 08:32:29.844204  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:32:29.844211  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291448 (* 1 = 0.0291448 loss)
I0626 08:32:29.844215  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0844777 (* 1 = 0.0844777 loss)
I0626 08:32:29.844219  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000568724 (* 1 = 0.000568724 loss)
I0626 08:32:29.844223  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00756992 (* 1 = 0.00756992 loss)
I0626 08:32:29.844228  6673 sgd_solver.cpp:106] Iteration 12820, lr = 0.0002
I0626 08:34:07.642639  6673 solver.cpp:228] Iteration 12840, loss = 0.148752
I0626 08:34:07.642664  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 08:34:07.642673  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.119866 (* 1 = 0.119866 loss)
I0626 08:34:07.642676  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.195648 (* 1 = 0.195648 loss)
I0626 08:34:07.642680  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.005363 (* 1 = 0.005363 loss)
I0626 08:34:07.642684  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348836 (* 1 = 0.0348836 loss)
I0626 08:34:07.642689  6673 sgd_solver.cpp:106] Iteration 12840, lr = 0.0002
I0626 08:35:45.524786  6673 solver.cpp:228] Iteration 12860, loss = 0.338457
I0626 08:35:45.524821  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:35:45.524829  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.033197 (* 1 = 0.033197 loss)
I0626 08:35:45.524834  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0626931 (* 1 = 0.0626931 loss)
I0626 08:35:45.524839  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00205844 (* 1 = 0.00205844 loss)
I0626 08:35:45.524844  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00603603 (* 1 = 0.00603603 loss)
I0626 08:35:45.524850  6673 sgd_solver.cpp:106] Iteration 12860, lr = 0.0002
I0626 08:37:23.417878  6673 solver.cpp:228] Iteration 12880, loss = 0.210933
I0626 08:37:23.417907  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 08:37:23.417914  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00596158 (* 1 = 0.00596158 loss)
I0626 08:37:23.417919  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0238293 (* 1 = 0.0238293 loss)
I0626 08:37:23.417922  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000210657 (* 1 = 0.000210657 loss)
I0626 08:37:23.417927  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00473408 (* 1 = 0.00473408 loss)
I0626 08:37:23.417932  6673 sgd_solver.cpp:106] Iteration 12880, lr = 0.0002
I0626 08:39:01.267307  6673 solver.cpp:228] Iteration 12900, loss = 0.268165
I0626 08:39:01.267331  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 08:39:01.267338  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.037576 (* 1 = 0.037576 loss)
I0626 08:39:01.267343  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0817894 (* 1 = 0.0817894 loss)
I0626 08:39:01.267347  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00173233 (* 1 = 0.00173233 loss)
I0626 08:39:01.267351  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141593 (* 1 = 0.0141593 loss)
I0626 08:39:01.267356  6673 sgd_solver.cpp:106] Iteration 12900, lr = 0.0002
I0626 08:40:39.137434  6673 solver.cpp:228] Iteration 12920, loss = 0.172903
I0626 08:40:39.137456  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:40:39.137464  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.021344 (* 1 = 0.021344 loss)
I0626 08:40:39.137467  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130612 (* 1 = 0.130612 loss)
I0626 08:40:39.137471  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0085523 (* 1 = 0.0085523 loss)
I0626 08:40:39.137475  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136679 (* 1 = 0.0136679 loss)
I0626 08:40:39.137480  6673 sgd_solver.cpp:106] Iteration 12920, lr = 0.0002
I0626 08:42:16.970881  6673 solver.cpp:228] Iteration 12940, loss = 0.182215
I0626 08:42:16.970911  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:42:16.970921  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473549 (* 1 = 0.0473549 loss)
I0626 08:42:16.970926  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0877358 (* 1 = 0.0877358 loss)
I0626 08:42:16.970932  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338005 (* 1 = 0.00338005 loss)
I0626 08:42:16.970938  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170477 (* 1 = 0.0170477 loss)
I0626 08:42:16.970943  6673 sgd_solver.cpp:106] Iteration 12940, lr = 0.0002
I0626 08:43:54.759790  6673 solver.cpp:228] Iteration 12960, loss = 0.193082
I0626 08:43:54.759812  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 08:43:54.759819  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.17573 (* 1 = 0.17573 loss)
I0626 08:43:54.759822  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.342507 (* 1 = 0.342507 loss)
I0626 08:43:54.759826  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424847 (* 1 = 0.00424847 loss)
I0626 08:43:54.759829  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401969 (* 1 = 0.0401969 loss)
I0626 08:43:54.759833  6673 sgd_solver.cpp:106] Iteration 12960, lr = 0.0002
I0626 08:45:32.608647  6673 solver.cpp:228] Iteration 12980, loss = 0.350191
I0626 08:45:32.608674  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 08:45:32.608680  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.158304 (* 1 = 0.158304 loss)
I0626 08:45:32.608685  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.206799 (* 1 = 0.206799 loss)
I0626 08:45:32.608688  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00836878 (* 1 = 0.00836878 loss)
I0626 08:45:32.608692  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0615189 (* 1 = 0.0615189 loss)
I0626 08:45:32.608697  6673 sgd_solver.cpp:106] Iteration 12980, lr = 0.0002
speed: 4.926s / iter
I0626 08:47:10.372314  6673 solver.cpp:228] Iteration 13000, loss = 0.238417
I0626 08:47:10.372337  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 08:47:10.372344  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.112604 (* 1 = 0.112604 loss)
I0626 08:47:10.372347  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.170987 (* 1 = 0.170987 loss)
I0626 08:47:10.372351  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000704594 (* 1 = 0.000704594 loss)
I0626 08:47:10.372354  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00867444 (* 1 = 0.00867444 loss)
I0626 08:47:10.372359  6673 sgd_solver.cpp:106] Iteration 13000, lr = 0.0002
I0626 08:48:48.221845  6673 solver.cpp:228] Iteration 13020, loss = 0.264114
I0626 08:48:48.221874  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 08:48:48.221882  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448631 (* 1 = 0.0448631 loss)
I0626 08:48:48.221887  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.148433 (* 1 = 0.148433 loss)
I0626 08:48:48.221891  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168118 (* 1 = 0.00168118 loss)
I0626 08:48:48.221896  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175679 (* 1 = 0.0175679 loss)
I0626 08:48:48.221901  6673 sgd_solver.cpp:106] Iteration 13020, lr = 0.0002
I0626 08:50:26.051254  6673 solver.cpp:228] Iteration 13040, loss = 0.171768
I0626 08:50:26.051280  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:50:26.051290  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540194 (* 1 = 0.0540194 loss)
I0626 08:50:26.051295  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0906171 (* 1 = 0.0906171 loss)
I0626 08:50:26.051300  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474918 (* 1 = 0.00474918 loss)
I0626 08:50:26.051303  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010963 (* 1 = 0.010963 loss)
I0626 08:50:26.051309  6673 sgd_solver.cpp:106] Iteration 13040, lr = 0.0002
I0626 08:52:03.938853  6673 solver.cpp:228] Iteration 13060, loss = 0.243253
I0626 08:52:03.938879  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 08:52:03.938884  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.125144 (* 1 = 0.125144 loss)
I0626 08:52:03.938889  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.169333 (* 1 = 0.169333 loss)
I0626 08:52:03.938892  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0030672 (* 1 = 0.0030672 loss)
I0626 08:52:03.938895  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282817 (* 1 = 0.0282817 loss)
I0626 08:52:03.938900  6673 sgd_solver.cpp:106] Iteration 13060, lr = 0.0002
I0626 08:53:41.752293  6673 solver.cpp:228] Iteration 13080, loss = 0.202239
I0626 08:53:41.752315  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 08:53:41.752321  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0565302 (* 1 = 0.0565302 loss)
I0626 08:53:41.752324  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0749816 (* 1 = 0.0749816 loss)
I0626 08:53:41.752327  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133973 (* 1 = 0.00133973 loss)
I0626 08:53:41.752331  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122139 (* 1 = 0.0122139 loss)
I0626 08:53:41.752334  6673 sgd_solver.cpp:106] Iteration 13080, lr = 0.0002
I0626 08:55:19.527441  6673 solver.cpp:228] Iteration 13100, loss = 0.289577
I0626 08:55:19.527465  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:55:19.527474  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0611446 (* 1 = 0.0611446 loss)
I0626 08:55:19.527480  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0784374 (* 1 = 0.0784374 loss)
I0626 08:55:19.527485  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000931544 (* 1 = 0.000931544 loss)
I0626 08:55:19.527492  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00748855 (* 1 = 0.00748855 loss)
I0626 08:55:19.527498  6673 sgd_solver.cpp:106] Iteration 13100, lr = 0.0002
I0626 08:56:57.405095  6673 solver.cpp:228] Iteration 13120, loss = 0.211444
I0626 08:56:57.405122  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 08:56:57.405129  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0993784 (* 1 = 0.0993784 loss)
I0626 08:56:57.405133  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0934061 (* 1 = 0.0934061 loss)
I0626 08:56:57.405138  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260098 (* 1 = 0.00260098 loss)
I0626 08:56:57.405140  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00777767 (* 1 = 0.00777767 loss)
I0626 08:56:57.405146  6673 sgd_solver.cpp:106] Iteration 13120, lr = 0.0002
I0626 08:58:35.134435  6673 solver.cpp:228] Iteration 13140, loss = 0.239538
I0626 08:58:35.134459  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 08:58:35.134465  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181312 (* 1 = 0.0181312 loss)
I0626 08:58:35.134469  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0515492 (* 1 = 0.0515492 loss)
I0626 08:58:35.134472  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183147 (* 1 = 0.00183147 loss)
I0626 08:58:35.134476  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0037834 (* 1 = 0.0037834 loss)
I0626 08:58:35.134481  6673 sgd_solver.cpp:106] Iteration 13140, lr = 0.0002
I0626 09:00:12.980952  6673 solver.cpp:228] Iteration 13160, loss = 0.146568
I0626 09:00:12.980974  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:00:12.980980  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0230053 (* 1 = 0.0230053 loss)
I0626 09:00:12.980984  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0362641 (* 1 = 0.0362641 loss)
I0626 09:00:12.980988  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120419 (* 1 = 0.00120419 loss)
I0626 09:00:12.980991  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00090892 (* 1 = 0.00090892 loss)
I0626 09:00:12.980996  6673 sgd_solver.cpp:106] Iteration 13160, lr = 0.0002
I0626 09:01:50.868415  6673 solver.cpp:228] Iteration 13180, loss = 0.24955
I0626 09:01:50.868438  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 09:01:50.868445  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199436 (* 1 = 0.0199436 loss)
I0626 09:01:50.868448  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.025136 (* 1 = 0.025136 loss)
I0626 09:01:50.868453  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000301351 (* 1 = 0.000301351 loss)
I0626 09:01:50.868455  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00213638 (* 1 = 0.00213638 loss)
I0626 09:01:50.868459  6673 sgd_solver.cpp:106] Iteration 13180, lr = 0.0002
speed: 4.926s / iter
I0626 09:03:28.756283  6673 solver.cpp:228] Iteration 13200, loss = 0.148922
I0626 09:03:28.756305  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:03:28.756312  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0315108 (* 1 = 0.0315108 loss)
I0626 09:03:28.756316  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0793647 (* 1 = 0.0793647 loss)
I0626 09:03:28.756320  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229657 (* 1 = 0.00229657 loss)
I0626 09:03:28.756323  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00880383 (* 1 = 0.00880383 loss)
I0626 09:03:28.756328  6673 sgd_solver.cpp:106] Iteration 13200, lr = 0.0002
I0626 09:05:06.613896  6673 solver.cpp:228] Iteration 13220, loss = 0.220751
I0626 09:05:06.613924  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:05:06.613932  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197939 (* 1 = 0.0197939 loss)
I0626 09:05:06.613937  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.063748 (* 1 = 0.063748 loss)
I0626 09:05:06.613942  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000329861 (* 1 = 0.000329861 loss)
I0626 09:05:06.613946  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147105 (* 1 = 0.0147105 loss)
I0626 09:05:06.613951  6673 sgd_solver.cpp:106] Iteration 13220, lr = 0.0002
I0626 09:06:44.468726  6673 solver.cpp:228] Iteration 13240, loss = 0.195504
I0626 09:06:44.468753  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:06:44.468760  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166304 (* 1 = 0.0166304 loss)
I0626 09:06:44.468765  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0773782 (* 1 = 0.0773782 loss)
I0626 09:06:44.468768  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000259037 (* 1 = 0.000259037 loss)
I0626 09:06:44.468771  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00614096 (* 1 = 0.00614096 loss)
I0626 09:06:44.468775  6673 sgd_solver.cpp:106] Iteration 13240, lr = 0.0002
I0626 09:08:22.435338  6673 solver.cpp:228] Iteration 13260, loss = 0.143503
I0626 09:08:22.435361  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:08:22.435369  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232387 (* 1 = 0.0232387 loss)
I0626 09:08:22.435372  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0647534 (* 1 = 0.0647534 loss)
I0626 09:08:22.435375  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000105061 (* 1 = 0.000105061 loss)
I0626 09:08:22.435379  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00649036 (* 1 = 0.00649036 loss)
I0626 09:08:22.435384  6673 sgd_solver.cpp:106] Iteration 13260, lr = 0.0002
I0626 09:10:00.393821  6673 solver.cpp:228] Iteration 13280, loss = 0.204979
I0626 09:10:00.393846  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 09:10:00.393854  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0144622 (* 1 = 0.0144622 loss)
I0626 09:10:00.393860  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0333443 (* 1 = 0.0333443 loss)
I0626 09:10:00.393865  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139942 (* 1 = 0.00139942 loss)
I0626 09:10:00.393869  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00202291 (* 1 = 0.00202291 loss)
I0626 09:10:00.393877  6673 sgd_solver.cpp:106] Iteration 13280, lr = 0.0002
I0626 09:11:38.384884  6673 solver.cpp:228] Iteration 13300, loss = 0.178411
I0626 09:11:38.384917  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:11:38.384927  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526264 (* 1 = 0.0526264 loss)
I0626 09:11:38.384934  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0671298 (* 1 = 0.0671298 loss)
I0626 09:11:38.384940  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120438 (* 1 = 0.00120438 loss)
I0626 09:11:38.384946  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00663322 (* 1 = 0.00663322 loss)
I0626 09:11:38.384953  6673 sgd_solver.cpp:106] Iteration 13300, lr = 0.0002
I0626 09:13:16.272658  6673 solver.cpp:228] Iteration 13320, loss = 0.190481
I0626 09:13:16.272686  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 09:13:16.272692  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.115933 (* 1 = 0.115933 loss)
I0626 09:13:16.272696  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.228091 (* 1 = 0.228091 loss)
I0626 09:13:16.272701  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158481 (* 1 = 0.00158481 loss)
I0626 09:13:16.272703  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024852 (* 1 = 0.024852 loss)
I0626 09:13:16.272707  6673 sgd_solver.cpp:106] Iteration 13320, lr = 0.0002
I0626 09:14:54.549072  6673 solver.cpp:228] Iteration 13340, loss = 0.208204
I0626 09:14:54.549094  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 09:14:54.549101  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0614989 (* 1 = 0.0614989 loss)
I0626 09:14:54.549105  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.127103 (* 1 = 0.127103 loss)
I0626 09:14:54.549108  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010332 (* 1 = 0.0010332 loss)
I0626 09:14:54.549113  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00510474 (* 1 = 0.00510474 loss)
I0626 09:14:54.549118  6673 sgd_solver.cpp:106] Iteration 13340, lr = 0.0002
I0626 09:16:32.605942  6673 solver.cpp:228] Iteration 13360, loss = 0.191147
I0626 09:16:32.605967  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 09:16:32.605974  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105098 (* 1 = 0.105098 loss)
I0626 09:16:32.605978  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.205801 (* 1 = 0.205801 loss)
I0626 09:16:32.605983  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000588723 (* 1 = 0.000588723 loss)
I0626 09:16:32.605985  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144162 (* 1 = 0.0144162 loss)
I0626 09:16:32.605991  6673 sgd_solver.cpp:106] Iteration 13360, lr = 0.0002
I0626 09:18:10.659229  6673 solver.cpp:228] Iteration 13380, loss = 0.145193
I0626 09:18:10.659253  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 09:18:10.659263  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400524 (* 1 = 0.0400524 loss)
I0626 09:18:10.659270  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.105572 (* 1 = 0.105572 loss)
I0626 09:18:10.659276  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377737 (* 1 = 0.00377737 loss)
I0626 09:18:10.659281  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00573291 (* 1 = 0.00573291 loss)
I0626 09:18:10.659289  6673 sgd_solver.cpp:106] Iteration 13380, lr = 0.0002
speed: 4.925s / iter
I0626 09:19:48.776463  6673 solver.cpp:228] Iteration 13400, loss = 0.138709
I0626 09:19:48.776489  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 09:19:48.776499  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169819 (* 1 = 0.0169819 loss)
I0626 09:19:48.776504  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0382302 (* 1 = 0.0382302 loss)
I0626 09:19:48.776511  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000123851 (* 1 = 0.000123851 loss)
I0626 09:19:48.776520  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104933 (* 1 = 0.0104933 loss)
I0626 09:19:48.776527  6673 sgd_solver.cpp:106] Iteration 13400, lr = 0.0002
I0626 09:21:26.762207  6673 solver.cpp:228] Iteration 13420, loss = 0.345402
I0626 09:21:26.762235  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 09:21:26.762245  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.118848 (* 1 = 0.118848 loss)
I0626 09:21:26.762251  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.270042 (* 1 = 0.270042 loss)
I0626 09:21:26.762257  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186117 (* 1 = 0.00186117 loss)
I0626 09:21:26.762264  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0502807 (* 1 = 0.0502807 loss)
I0626 09:21:26.762272  6673 sgd_solver.cpp:106] Iteration 13420, lr = 0.0002
I0626 09:23:04.567325  6673 solver.cpp:228] Iteration 13440, loss = 0.242959
I0626 09:23:04.567353  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 09:23:04.567361  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937961 (* 1 = 0.0937961 loss)
I0626 09:23:04.567365  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.286721 (* 1 = 0.286721 loss)
I0626 09:23:04.567369  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282711 (* 1 = 0.00282711 loss)
I0626 09:23:04.567373  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487476 (* 1 = 0.0487476 loss)
I0626 09:23:04.567378  6673 sgd_solver.cpp:106] Iteration 13440, lr = 0.0002
I0626 09:24:42.573182  6673 solver.cpp:228] Iteration 13460, loss = 0.322515
I0626 09:24:42.573210  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 09:24:42.573217  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0671044 (* 1 = 0.0671044 loss)
I0626 09:24:42.573222  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.156315 (* 1 = 0.156315 loss)
I0626 09:24:42.573227  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00244588 (* 1 = 0.00244588 loss)
I0626 09:24:42.573232  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143064 (* 1 = 0.0143064 loss)
I0626 09:24:42.573238  6673 sgd_solver.cpp:106] Iteration 13460, lr = 0.0002
I0626 09:26:20.596829  6673 solver.cpp:228] Iteration 13480, loss = 0.338683
I0626 09:26:20.596853  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 09:26:20.596860  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468644 (* 1 = 0.0468644 loss)
I0626 09:26:20.596864  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0755326 (* 1 = 0.0755326 loss)
I0626 09:26:20.596868  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000552521 (* 1 = 0.000552521 loss)
I0626 09:26:20.596873  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00963112 (* 1 = 0.00963112 loss)
I0626 09:26:20.596877  6673 sgd_solver.cpp:106] Iteration 13480, lr = 0.0002
I0626 09:27:58.555404  6673 solver.cpp:228] Iteration 13500, loss = 0.164395
I0626 09:27:58.555428  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 09:27:58.555435  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0612221 (* 1 = 0.0612221 loss)
I0626 09:27:58.555439  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109224 (* 1 = 0.109224 loss)
I0626 09:27:58.555444  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171296 (* 1 = 0.00171296 loss)
I0626 09:27:58.555449  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205037 (* 1 = 0.0205037 loss)
I0626 09:27:58.555452  6673 sgd_solver.cpp:106] Iteration 13500, lr = 0.0002
I0626 09:29:36.501435  6673 solver.cpp:228] Iteration 13520, loss = 0.274032
I0626 09:29:36.501459  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 09:29:36.501466  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.127966 (* 1 = 0.127966 loss)
I0626 09:29:36.501471  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.17424 (* 1 = 0.17424 loss)
I0626 09:29:36.501473  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000926253 (* 1 = 0.000926253 loss)
I0626 09:29:36.501477  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00875895 (* 1 = 0.00875895 loss)
I0626 09:29:36.501482  6673 sgd_solver.cpp:106] Iteration 13520, lr = 0.0002
I0626 09:31:14.444147  6673 solver.cpp:228] Iteration 13540, loss = 0.207636
I0626 09:31:14.444171  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 09:31:14.444178  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0242257 (* 1 = 0.0242257 loss)
I0626 09:31:14.444182  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0722988 (* 1 = 0.0722988 loss)
I0626 09:31:14.444185  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00694719 (* 1 = 0.00694719 loss)
I0626 09:31:14.444188  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00835006 (* 1 = 0.00835006 loss)
I0626 09:31:14.444193  6673 sgd_solver.cpp:106] Iteration 13540, lr = 0.0002
I0626 09:32:52.462756  6673 solver.cpp:228] Iteration 13560, loss = 0.215461
I0626 09:32:52.462785  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:32:52.462793  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346038 (* 1 = 0.0346038 loss)
I0626 09:32:52.462797  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.108114 (* 1 = 0.108114 loss)
I0626 09:32:52.462802  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00640951 (* 1 = 0.00640951 loss)
I0626 09:32:52.462806  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247685 (* 1 = 0.0247685 loss)
I0626 09:32:52.462811  6673 sgd_solver.cpp:106] Iteration 13560, lr = 0.0002
I0626 09:34:30.451105  6673 solver.cpp:228] Iteration 13580, loss = 0.278836
I0626 09:34:30.451128  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 09:34:30.451135  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.143257 (* 1 = 0.143257 loss)
I0626 09:34:30.451139  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.317497 (* 1 = 0.317497 loss)
I0626 09:34:30.451143  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00952542 (* 1 = 0.00952542 loss)
I0626 09:34:30.451146  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0651738 (* 1 = 0.0651738 loss)
I0626 09:34:30.451150  6673 sgd_solver.cpp:106] Iteration 13580, lr = 0.0002
speed: 4.925s / iter
I0626 09:36:08.442275  6673 solver.cpp:228] Iteration 13600, loss = 0.292082
I0626 09:36:08.442313  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 09:36:08.442323  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.134285 (* 1 = 0.134285 loss)
I0626 09:36:08.442329  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.266096 (* 1 = 0.266096 loss)
I0626 09:36:08.442335  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271397 (* 1 = 0.00271397 loss)
I0626 09:36:08.442342  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023613 (* 1 = 0.023613 loss)
I0626 09:36:08.442349  6673 sgd_solver.cpp:106] Iteration 13600, lr = 0.0002
I0626 09:37:46.417057  6673 solver.cpp:228] Iteration 13620, loss = 0.243576
I0626 09:37:46.417083  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 09:37:46.417089  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.133861 (* 1 = 0.133861 loss)
I0626 09:37:46.417094  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.310695 (* 1 = 0.310695 loss)
I0626 09:37:46.417098  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00418267 (* 1 = 0.00418267 loss)
I0626 09:37:46.417102  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284297 (* 1 = 0.0284297 loss)
I0626 09:37:46.417107  6673 sgd_solver.cpp:106] Iteration 13620, lr = 0.0002
I0626 09:39:24.404093  6673 solver.cpp:228] Iteration 13640, loss = 0.24979
I0626 09:39:24.404116  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 09:39:24.404122  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0423797 (* 1 = 0.0423797 loss)
I0626 09:39:24.404126  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0798102 (* 1 = 0.0798102 loss)
I0626 09:39:24.404130  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000106546 (* 1 = 0.000106546 loss)
I0626 09:39:24.404134  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192664 (* 1 = 0.0192664 loss)
I0626 09:39:24.404139  6673 sgd_solver.cpp:106] Iteration 13640, lr = 0.0002
I0626 09:41:02.464927  6673 solver.cpp:228] Iteration 13660, loss = 0.289002
I0626 09:41:02.464954  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 09:41:02.464962  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.309082 (* 1 = 0.309082 loss)
I0626 09:41:02.464965  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.22687 (* 1 = 0.22687 loss)
I0626 09:41:02.464969  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00058831 (* 1 = 0.00058831 loss)
I0626 09:41:02.464974  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379054 (* 1 = 0.0379054 loss)
I0626 09:41:02.464978  6673 sgd_solver.cpp:106] Iteration 13660, lr = 0.0002
I0626 09:42:40.354393  6673 solver.cpp:228] Iteration 13680, loss = 0.18309
I0626 09:42:40.354419  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 09:42:40.354426  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.151997 (* 1 = 0.151997 loss)
I0626 09:42:40.354431  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.29082 (* 1 = 0.29082 loss)
I0626 09:42:40.354434  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184859 (* 1 = 0.00184859 loss)
I0626 09:42:40.354439  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305282 (* 1 = 0.0305282 loss)
I0626 09:42:40.354444  6673 sgd_solver.cpp:106] Iteration 13680, lr = 0.0002
I0626 09:44:18.265666  6673 solver.cpp:228] Iteration 13700, loss = 0.158148
I0626 09:44:18.265694  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 09:44:18.265702  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0200629 (* 1 = 0.0200629 loss)
I0626 09:44:18.265707  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0584045 (* 1 = 0.0584045 loss)
I0626 09:44:18.265709  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000397171 (* 1 = 0.000397171 loss)
I0626 09:44:18.265713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00604306 (* 1 = 0.00604306 loss)
I0626 09:44:18.265717  6673 sgd_solver.cpp:106] Iteration 13700, lr = 0.0002
I0626 09:45:56.253767  6673 solver.cpp:228] Iteration 13720, loss = 0.181475
I0626 09:45:56.253789  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:45:56.253796  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400742 (* 1 = 0.0400742 loss)
I0626 09:45:56.253799  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0789785 (* 1 = 0.0789785 loss)
I0626 09:45:56.253803  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511921 (* 1 = 0.00511921 loss)
I0626 09:45:56.253806  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163105 (* 1 = 0.0163105 loss)
I0626 09:45:56.253809  6673 sgd_solver.cpp:106] Iteration 13720, lr = 0.0002
I0626 09:47:34.306742  6673 solver.cpp:228] Iteration 13740, loss = 0.234071
I0626 09:47:34.306769  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 09:47:34.306777  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0718448 (* 1 = 0.0718448 loss)
I0626 09:47:34.306780  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.198116 (* 1 = 0.198116 loss)
I0626 09:47:34.306783  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115565 (* 1 = 0.0115565 loss)
I0626 09:47:34.306787  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133569 (* 1 = 0.0133569 loss)
I0626 09:47:34.306792  6673 sgd_solver.cpp:106] Iteration 13740, lr = 0.0002
I0626 09:49:12.349766  6673 solver.cpp:228] Iteration 13760, loss = 0.0983946
I0626 09:49:12.349830  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:49:12.349841  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459461 (* 1 = 0.0459461 loss)
I0626 09:49:12.349848  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0643009 (* 1 = 0.0643009 loss)
I0626 09:49:12.349853  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000145063 (* 1 = 0.000145063 loss)
I0626 09:49:12.349858  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512117 (* 1 = 0.00512117 loss)
I0626 09:49:12.349866  6673 sgd_solver.cpp:106] Iteration 13760, lr = 0.0002
I0626 09:50:50.312393  6673 solver.cpp:228] Iteration 13780, loss = 0.146528
I0626 09:50:50.312417  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 09:50:50.312423  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133806 (* 1 = 0.0133806 loss)
I0626 09:50:50.312428  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0449677 (* 1 = 0.0449677 loss)
I0626 09:50:50.312431  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000399147 (* 1 = 0.000399147 loss)
I0626 09:50:50.312435  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00769133 (* 1 = 0.00769133 loss)
I0626 09:50:50.312439  6673 sgd_solver.cpp:106] Iteration 13780, lr = 0.0002
speed: 4.924s / iter
I0626 09:52:28.413641  6673 solver.cpp:228] Iteration 13800, loss = 0.203277
I0626 09:52:28.413666  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:52:28.413674  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0913987 (* 1 = 0.0913987 loss)
I0626 09:52:28.413678  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.090881 (* 1 = 0.090881 loss)
I0626 09:52:28.413682  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133056 (* 1 = 0.00133056 loss)
I0626 09:52:28.413686  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00645845 (* 1 = 0.00645845 loss)
I0626 09:52:28.413691  6673 sgd_solver.cpp:106] Iteration 13800, lr = 0.0002
I0626 09:54:06.373373  6673 solver.cpp:228] Iteration 13820, loss = 0.158043
I0626 09:54:06.373401  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 09:54:06.373412  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00635134 (* 1 = 0.00635134 loss)
I0626 09:54:06.373420  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0566937 (* 1 = 0.0566937 loss)
I0626 09:54:06.373428  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000889589 (* 1 = 0.000889589 loss)
I0626 09:54:06.373436  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00271891 (* 1 = 0.00271891 loss)
I0626 09:54:06.373446  6673 sgd_solver.cpp:106] Iteration 13820, lr = 0.0002
I0626 09:55:44.324156  6673 solver.cpp:228] Iteration 13840, loss = 0.284251
I0626 09:55:44.324177  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0626 09:55:44.324183  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.459666 (* 1 = 0.459666 loss)
I0626 09:55:44.324187  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.523434 (* 1 = 0.523434 loss)
I0626 09:55:44.324190  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00400833 (* 1 = 0.00400833 loss)
I0626 09:55:44.324193  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0755287 (* 1 = 0.0755287 loss)
I0626 09:55:44.324198  6673 sgd_solver.cpp:106] Iteration 13840, lr = 0.0002
I0626 09:57:22.303704  6673 solver.cpp:228] Iteration 13860, loss = 0.21376
I0626 09:57:22.303727  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 09:57:22.303736  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0933601 (* 1 = 0.0933601 loss)
I0626 09:57:22.303742  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0875787 (* 1 = 0.0875787 loss)
I0626 09:57:22.303747  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028791 (* 1 = 0.0028791 loss)
I0626 09:57:22.303752  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00994496 (* 1 = 0.00994496 loss)
I0626 09:57:22.303758  6673 sgd_solver.cpp:106] Iteration 13860, lr = 0.0002
I0626 09:59:00.195159  6673 solver.cpp:228] Iteration 13880, loss = 0.420915
I0626 09:59:00.195183  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 09:59:00.195192  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274394 (* 1 = 0.0274394 loss)
I0626 09:59:00.195199  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.110965 (* 1 = 0.110965 loss)
I0626 09:59:00.195204  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00313422 (* 1 = 0.00313422 loss)
I0626 09:59:00.195210  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00566775 (* 1 = 0.00566775 loss)
I0626 09:59:00.195216  6673 sgd_solver.cpp:106] Iteration 13880, lr = 0.0002
I0626 10:00:38.081876  6673 solver.cpp:228] Iteration 13900, loss = 0.139226
I0626 10:00:38.081902  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:00:38.081912  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161301 (* 1 = 0.0161301 loss)
I0626 10:00:38.081918  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0453199 (* 1 = 0.0453199 loss)
I0626 10:00:38.081923  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00079898 (* 1 = 0.00079898 loss)
I0626 10:00:38.081929  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00345207 (* 1 = 0.00345207 loss)
I0626 10:00:38.081936  6673 sgd_solver.cpp:106] Iteration 13900, lr = 0.0002
I0626 10:02:15.994853  6673 solver.cpp:228] Iteration 13920, loss = 0.149563
I0626 10:02:15.994887  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:02:15.994897  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0330906 (* 1 = 0.0330906 loss)
I0626 10:02:15.994901  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0363377 (* 1 = 0.0363377 loss)
I0626 10:02:15.994905  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000287918 (* 1 = 0.000287918 loss)
I0626 10:02:15.994909  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00186421 (* 1 = 0.00186421 loss)
I0626 10:02:15.994913  6673 sgd_solver.cpp:106] Iteration 13920, lr = 0.0002
I0626 10:03:53.838340  6673 solver.cpp:228] Iteration 13940, loss = 0.296035
I0626 10:03:53.838366  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 10:03:53.838374  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0689381 (* 1 = 0.0689381 loss)
I0626 10:03:53.838378  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161563 (* 1 = 0.161563 loss)
I0626 10:03:53.838382  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00836539 (* 1 = 0.00836539 loss)
I0626 10:03:53.838387  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321757 (* 1 = 0.0321757 loss)
I0626 10:03:53.838390  6673 sgd_solver.cpp:106] Iteration 13940, lr = 0.0002
I0626 10:05:31.701655  6673 solver.cpp:228] Iteration 13960, loss = 0.169222
I0626 10:05:31.701680  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:05:31.701687  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719822 (* 1 = 0.0719822 loss)
I0626 10:05:31.701691  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.104743 (* 1 = 0.104743 loss)
I0626 10:05:31.701696  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00333141 (* 1 = 0.00333141 loss)
I0626 10:05:31.701699  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0093079 (* 1 = 0.0093079 loss)
I0626 10:05:31.701704  6673 sgd_solver.cpp:106] Iteration 13960, lr = 0.0002
I0626 10:07:09.806350  6673 solver.cpp:228] Iteration 13980, loss = 0.162119
I0626 10:07:09.806378  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 10:07:09.806388  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.119481 (* 1 = 0.119481 loss)
I0626 10:07:09.806394  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0814154 (* 1 = 0.0814154 loss)
I0626 10:07:09.806401  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000646649 (* 1 = 0.000646649 loss)
I0626 10:07:09.806407  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159724 (* 1 = 0.0159724 loss)
I0626 10:07:09.806414  6673 sgd_solver.cpp:106] Iteration 13980, lr = 0.0002
speed: 4.924s / iter
I0626 10:08:47.726507  6673 solver.cpp:228] Iteration 14000, loss = 0.335202
I0626 10:08:47.726534  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0626 10:08:47.726542  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.102086 (* 1 = 0.102086 loss)
I0626 10:08:47.726547  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.333578 (* 1 = 0.333578 loss)
I0626 10:08:47.726549  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163448 (* 1 = 0.0163448 loss)
I0626 10:08:47.726553  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401239 (* 1 = 0.0401239 loss)
I0626 10:08:47.726558  6673 sgd_solver.cpp:106] Iteration 14000, lr = 0.0002
I0626 10:10:25.798056  6673 solver.cpp:228] Iteration 14020, loss = 0.259614
I0626 10:10:25.798081  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 10:10:25.798090  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.250307 (* 1 = 0.250307 loss)
I0626 10:10:25.798096  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.276931 (* 1 = 0.276931 loss)
I0626 10:10:25.798101  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00635009 (* 1 = 0.00635009 loss)
I0626 10:10:25.798106  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0608334 (* 1 = 0.0608334 loss)
I0626 10:10:25.798112  6673 sgd_solver.cpp:106] Iteration 14020, lr = 0.0002
I0626 10:12:03.723218  6673 solver.cpp:228] Iteration 14040, loss = 0.189039
I0626 10:12:03.723242  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 10:12:03.723249  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523969 (* 1 = 0.0523969 loss)
I0626 10:12:03.723255  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.188924 (* 1 = 0.188924 loss)
I0626 10:12:03.723260  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173817 (* 1 = 0.0173817 loss)
I0626 10:12:03.723265  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0385228 (* 1 = 0.0385228 loss)
I0626 10:12:03.723271  6673 sgd_solver.cpp:106] Iteration 14040, lr = 0.0002
I0626 10:13:41.858253  6673 solver.cpp:228] Iteration 14060, loss = 0.0917769
I0626 10:13:41.858278  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 10:13:41.858284  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675527 (* 1 = 0.0675527 loss)
I0626 10:13:41.858289  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0238159 (* 1 = 0.0238159 loss)
I0626 10:13:41.858294  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00478974 (* 1 = 0.00478974 loss)
I0626 10:13:41.858296  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00282998 (* 1 = 0.00282998 loss)
I0626 10:13:41.858301  6673 sgd_solver.cpp:106] Iteration 14060, lr = 0.0002
I0626 10:15:19.873086  6673 solver.cpp:228] Iteration 14080, loss = 0.332346
I0626 10:15:19.873113  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:15:19.873121  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259261 (* 1 = 0.0259261 loss)
I0626 10:15:19.873126  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0765595 (* 1 = 0.0765595 loss)
I0626 10:15:19.873129  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131741 (* 1 = 0.0131741 loss)
I0626 10:15:19.873133  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00842698 (* 1 = 0.00842698 loss)
I0626 10:15:19.873138  6673 sgd_solver.cpp:106] Iteration 14080, lr = 0.0002
I0626 10:16:57.939138  6673 solver.cpp:228] Iteration 14100, loss = 0.241915
I0626 10:16:57.939162  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 10:16:57.939169  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0654355 (* 1 = 0.0654355 loss)
I0626 10:16:57.939173  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0817989 (* 1 = 0.0817989 loss)
I0626 10:16:57.939177  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00215433 (* 1 = 0.00215433 loss)
I0626 10:16:57.939179  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00905757 (* 1 = 0.00905757 loss)
I0626 10:16:57.939184  6673 sgd_solver.cpp:106] Iteration 14100, lr = 0.0002
I0626 10:18:35.895133  6673 solver.cpp:228] Iteration 14120, loss = 0.220498
I0626 10:18:35.895159  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:18:35.895165  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0353247 (* 1 = 0.0353247 loss)
I0626 10:18:35.895169  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0851363 (* 1 = 0.0851363 loss)
I0626 10:18:35.895172  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000726834 (* 1 = 0.000726834 loss)
I0626 10:18:35.895176  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00282478 (* 1 = 0.00282478 loss)
I0626 10:18:35.895180  6673 sgd_solver.cpp:106] Iteration 14120, lr = 0.0002
I0626 10:20:13.915982  6673 solver.cpp:228] Iteration 14140, loss = 0.110793
I0626 10:20:13.916007  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:20:13.916015  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.048328 (* 1 = 0.048328 loss)
I0626 10:20:13.916019  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0757944 (* 1 = 0.0757944 loss)
I0626 10:20:13.916023  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000297734 (* 1 = 0.000297734 loss)
I0626 10:20:13.916028  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108402 (* 1 = 0.0108402 loss)
I0626 10:20:13.916033  6673 sgd_solver.cpp:106] Iteration 14140, lr = 0.0002
I0626 10:21:51.795620  6673 solver.cpp:228] Iteration 14160, loss = 0.2291
I0626 10:21:51.795642  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:21:51.795650  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0267036 (* 1 = 0.0267036 loss)
I0626 10:21:51.795652  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0554262 (* 1 = 0.0554262 loss)
I0626 10:21:51.795656  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00487459 (* 1 = 0.00487459 loss)
I0626 10:21:51.795660  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00296484 (* 1 = 0.00296484 loss)
I0626 10:21:51.795663  6673 sgd_solver.cpp:106] Iteration 14160, lr = 0.0002
I0626 10:23:29.762454  6673 solver.cpp:228] Iteration 14180, loss = 0.226945
I0626 10:23:29.762477  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:23:29.762485  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248527 (* 1 = 0.0248527 loss)
I0626 10:23:29.762488  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0288347 (* 1 = 0.0288347 loss)
I0626 10:23:29.762491  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026849 (* 1 = 0.0026849 loss)
I0626 10:23:29.762495  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000658796 (* 1 = 0.000658796 loss)
I0626 10:23:29.762500  6673 sgd_solver.cpp:106] Iteration 14180, lr = 0.0002
speed: 4.924s / iter
I0626 10:25:07.747678  6673 solver.cpp:228] Iteration 14200, loss = 0.179392
I0626 10:25:07.747702  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:25:07.747709  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248294 (* 1 = 0.0248294 loss)
I0626 10:25:07.747712  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0412708 (* 1 = 0.0412708 loss)
I0626 10:25:07.747716  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000305737 (* 1 = 0.000305737 loss)
I0626 10:25:07.747720  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00325798 (* 1 = 0.00325798 loss)
I0626 10:25:07.747725  6673 sgd_solver.cpp:106] Iteration 14200, lr = 0.0002
I0626 10:26:45.659755  6673 solver.cpp:228] Iteration 14220, loss = 0.216633
I0626 10:26:45.659781  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:26:45.659788  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0342508 (* 1 = 0.0342508 loss)
I0626 10:26:45.659792  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0420567 (* 1 = 0.0420567 loss)
I0626 10:26:45.659796  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000222286 (* 1 = 0.000222286 loss)
I0626 10:26:45.659801  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00731795 (* 1 = 0.00731795 loss)
I0626 10:26:45.659806  6673 sgd_solver.cpp:106] Iteration 14220, lr = 0.0002
I0626 10:28:23.590759  6673 solver.cpp:228] Iteration 14240, loss = 0.188303
I0626 10:28:23.590787  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:28:23.590795  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0110411 (* 1 = 0.0110411 loss)
I0626 10:28:23.590800  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0451275 (* 1 = 0.0451275 loss)
I0626 10:28:23.590803  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249946 (* 1 = 0.00249946 loss)
I0626 10:28:23.590807  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00232595 (* 1 = 0.00232595 loss)
I0626 10:28:23.590812  6673 sgd_solver.cpp:106] Iteration 14240, lr = 0.0002
I0626 10:30:01.662796  6673 solver.cpp:228] Iteration 14260, loss = 0.315173
I0626 10:30:01.662827  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0626 10:30:01.662834  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.319897 (* 1 = 0.319897 loss)
I0626 10:30:01.662842  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.471005 (* 1 = 0.471005 loss)
I0626 10:30:01.662847  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00407845 (* 1 = 0.00407845 loss)
I0626 10:30:01.662852  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0880908 (* 1 = 0.0880908 loss)
I0626 10:30:01.662863  6673 sgd_solver.cpp:106] Iteration 14260, lr = 0.0002
I0626 10:31:40.223031  6673 solver.cpp:228] Iteration 14280, loss = 0.188467
I0626 10:31:40.223063  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 10:31:40.223070  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0554024 (* 1 = 0.0554024 loss)
I0626 10:31:40.223075  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0833224 (* 1 = 0.0833224 loss)
I0626 10:31:40.223079  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.009959 (* 1 = 0.009959 loss)
I0626 10:31:40.223083  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145389 (* 1 = 0.0145389 loss)
I0626 10:31:40.223088  6673 sgd_solver.cpp:106] Iteration 14280, lr = 0.0002
I0626 10:33:18.592842  6673 solver.cpp:228] Iteration 14300, loss = 0.256592
I0626 10:33:18.592873  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0626 10:33:18.592881  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.180201 (* 1 = 0.180201 loss)
I0626 10:33:18.592885  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.42229 (* 1 = 0.42229 loss)
I0626 10:33:18.592890  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018656 (* 1 = 0.018656 loss)
I0626 10:33:18.592893  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0412719 (* 1 = 0.0412719 loss)
I0626 10:33:18.592900  6673 sgd_solver.cpp:106] Iteration 14300, lr = 0.0002
I0626 10:34:56.858661  6673 solver.cpp:228] Iteration 14320, loss = 0.216891
I0626 10:34:56.858695  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 10:34:56.858702  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391649 (* 1 = 0.0391649 loss)
I0626 10:34:56.858706  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0877647 (* 1 = 0.0877647 loss)
I0626 10:34:56.858709  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00466675 (* 1 = 0.00466675 loss)
I0626 10:34:56.858713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0726576 (* 1 = 0.0726576 loss)
I0626 10:34:56.858718  6673 sgd_solver.cpp:106] Iteration 14320, lr = 0.0002
I0626 10:36:35.368147  6673 solver.cpp:228] Iteration 14340, loss = 0.147738
I0626 10:36:35.368180  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 10:36:35.368188  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00866847 (* 1 = 0.00866847 loss)
I0626 10:36:35.368194  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0414949 (* 1 = 0.0414949 loss)
I0626 10:36:35.368201  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000270979 (* 1 = 0.000270979 loss)
I0626 10:36:35.368207  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00295316 (* 1 = 0.00295316 loss)
I0626 10:36:35.368214  6673 sgd_solver.cpp:106] Iteration 14340, lr = 0.0002
I0626 10:38:13.655280  6673 solver.cpp:228] Iteration 14360, loss = 0.281452
I0626 10:38:13.655303  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:38:13.655311  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256958 (* 1 = 0.0256958 loss)
I0626 10:38:13.655315  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0434161 (* 1 = 0.0434161 loss)
I0626 10:38:13.655319  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000237757 (* 1 = 0.000237757 loss)
I0626 10:38:13.655323  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00464839 (* 1 = 0.00464839 loss)
I0626 10:38:13.655328  6673 sgd_solver.cpp:106] Iteration 14360, lr = 0.0002
I0626 10:39:51.895218  6673 solver.cpp:228] Iteration 14380, loss = 0.239574
I0626 10:39:51.895242  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:39:51.895251  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172052 (* 1 = 0.0172052 loss)
I0626 10:39:51.895254  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0681012 (* 1 = 0.0681012 loss)
I0626 10:39:51.895258  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00071781 (* 1 = 0.00071781 loss)
I0626 10:39:51.895262  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00714319 (* 1 = 0.00714319 loss)
I0626 10:39:51.895267  6673 sgd_solver.cpp:106] Iteration 14380, lr = 0.0002
speed: 4.924s / iter
I0626 10:41:30.019865  6673 solver.cpp:228] Iteration 14400, loss = 0.119888
I0626 10:41:30.019891  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 10:41:30.019897  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0101616 (* 1 = 0.0101616 loss)
I0626 10:41:30.019901  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0379903 (* 1 = 0.0379903 loss)
I0626 10:41:30.019906  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.96523e-05 (* 1 = 4.96523e-05 loss)
I0626 10:41:30.019908  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00427977 (* 1 = 0.00427977 loss)
I0626 10:41:30.019913  6673 sgd_solver.cpp:106] Iteration 14400, lr = 0.0002
I0626 10:43:07.966583  6673 solver.cpp:228] Iteration 14420, loss = 0.172342
I0626 10:43:07.966605  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 10:43:07.966612  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000661849 (* 1 = 0.000661849 loss)
I0626 10:43:07.966617  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0383652 (* 1 = 0.0383652 loss)
I0626 10:43:07.966620  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012709 (* 1 = 0.012709 loss)
I0626 10:43:07.966624  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240429 (* 1 = 0.0240429 loss)
I0626 10:43:07.966629  6673 sgd_solver.cpp:106] Iteration 14420, lr = 0.0002
I0626 10:44:45.931742  6673 solver.cpp:228] Iteration 14440, loss = 0.229261
I0626 10:44:45.931768  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 10:44:45.931776  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216746 (* 1 = 0.0216746 loss)
I0626 10:44:45.931779  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0336242 (* 1 = 0.0336242 loss)
I0626 10:44:45.931783  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000991506 (* 1 = 0.000991506 loss)
I0626 10:44:45.931787  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00158559 (* 1 = 0.00158559 loss)
I0626 10:44:45.931792  6673 sgd_solver.cpp:106] Iteration 14440, lr = 0.0002
I0626 10:46:24.028899  6673 solver.cpp:228] Iteration 14460, loss = 0.184371
I0626 10:46:24.028924  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:46:24.028930  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156292 (* 1 = 0.0156292 loss)
I0626 10:46:24.028934  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0495002 (* 1 = 0.0495002 loss)
I0626 10:46:24.028939  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.26736e-05 (* 1 = 5.26736e-05 loss)
I0626 10:46:24.028942  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.002402 (* 1 = 0.002402 loss)
I0626 10:46:24.028947  6673 sgd_solver.cpp:106] Iteration 14460, lr = 0.0002
I0626 10:48:02.015987  6673 solver.cpp:228] Iteration 14480, loss = 0.333508
I0626 10:48:02.016011  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:48:02.016018  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433607 (* 1 = 0.0433607 loss)
I0626 10:48:02.016022  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0877143 (* 1 = 0.0877143 loss)
I0626 10:48:02.016026  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182321 (* 1 = 0.0182321 loss)
I0626 10:48:02.016028  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375396 (* 1 = 0.0375396 loss)
I0626 10:48:02.016033  6673 sgd_solver.cpp:106] Iteration 14480, lr = 0.0002
I0626 10:49:40.049368  6673 solver.cpp:228] Iteration 14500, loss = 0.129063
I0626 10:49:40.049393  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 10:49:40.049401  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156854 (* 1 = 0.0156854 loss)
I0626 10:49:40.049405  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0362717 (* 1 = 0.0362717 loss)
I0626 10:49:40.049408  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132355 (* 1 = 0.00132355 loss)
I0626 10:49:40.049412  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00476249 (* 1 = 0.00476249 loss)
I0626 10:49:40.049417  6673 sgd_solver.cpp:106] Iteration 14500, lr = 0.0002
I0626 10:51:18.058722  6673 solver.cpp:228] Iteration 14520, loss = 0.188513
I0626 10:51:18.058764  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 10:51:18.058774  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.068831 (* 1 = 0.068831 loss)
I0626 10:51:18.058779  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.132933 (* 1 = 0.132933 loss)
I0626 10:51:18.058785  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000469255 (* 1 = 0.000469255 loss)
I0626 10:51:18.058789  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116514 (* 1 = 0.0116514 loss)
I0626 10:51:18.058797  6673 sgd_solver.cpp:106] Iteration 14520, lr = 0.0002
I0626 10:52:56.039882  6673 solver.cpp:228] Iteration 14540, loss = 0.132104
I0626 10:52:56.039908  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 10:52:56.039916  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362432 (* 1 = 0.0362432 loss)
I0626 10:52:56.039921  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.124836 (* 1 = 0.124836 loss)
I0626 10:52:56.039924  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00683827 (* 1 = 0.00683827 loss)
I0626 10:52:56.039928  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152554 (* 1 = 0.0152554 loss)
I0626 10:52:56.039933  6673 sgd_solver.cpp:106] Iteration 14540, lr = 0.0002
I0626 10:54:33.961498  6673 solver.cpp:228] Iteration 14560, loss = 0.361336
I0626 10:54:33.961520  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 10:54:33.961529  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.166514 (* 1 = 0.166514 loss)
I0626 10:54:33.961532  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.340625 (* 1 = 0.340625 loss)
I0626 10:54:33.961536  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00784742 (* 1 = 0.00784742 loss)
I0626 10:54:33.961539  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036564 (* 1 = 0.036564 loss)
I0626 10:54:33.961544  6673 sgd_solver.cpp:106] Iteration 14560, lr = 0.0002
I0626 10:56:11.944234  6673 solver.cpp:228] Iteration 14580, loss = 0.218965
I0626 10:56:11.944259  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:56:11.944267  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142591 (* 1 = 0.0142591 loss)
I0626 10:56:11.944272  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0385029 (* 1 = 0.0385029 loss)
I0626 10:56:11.944277  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000801278 (* 1 = 0.000801278 loss)
I0626 10:56:11.944279  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00133399 (* 1 = 0.00133399 loss)
I0626 10:56:11.944284  6673 sgd_solver.cpp:106] Iteration 14580, lr = 0.0002
speed: 4.923s / iter
I0626 10:57:49.926801  6673 solver.cpp:228] Iteration 14600, loss = 0.204344
I0626 10:57:49.926826  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 10:57:49.926833  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00433332 (* 1 = 0.00433332 loss)
I0626 10:57:49.926838  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0575179 (* 1 = 0.0575179 loss)
I0626 10:57:49.926842  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0067951 (* 1 = 0.0067951 loss)
I0626 10:57:49.926846  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00740745 (* 1 = 0.00740745 loss)
I0626 10:57:49.926851  6673 sgd_solver.cpp:106] Iteration 14600, lr = 0.0002
I0626 10:59:27.889454  6673 solver.cpp:228] Iteration 14620, loss = 0.302194
I0626 10:59:27.889479  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 10:59:27.889485  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397927 (* 1 = 0.0397927 loss)
I0626 10:59:27.889489  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.182842 (* 1 = 0.182842 loss)
I0626 10:59:27.889493  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000608283 (* 1 = 0.000608283 loss)
I0626 10:59:27.889497  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00896932 (* 1 = 0.00896932 loss)
I0626 10:59:27.889502  6673 sgd_solver.cpp:106] Iteration 14620, lr = 0.0002
I0626 11:01:05.911116  6673 solver.cpp:228] Iteration 14640, loss = 0.356738
I0626 11:01:05.911139  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:01:05.911146  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397748 (* 1 = 0.0397748 loss)
I0626 11:01:05.911149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0353642 (* 1 = 0.0353642 loss)
I0626 11:01:05.911154  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00982469 (* 1 = 0.00982469 loss)
I0626 11:01:05.911156  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940915 (* 1 = 0.00940915 loss)
I0626 11:01:05.911161  6673 sgd_solver.cpp:106] Iteration 14640, lr = 0.0002
I0626 11:02:44.007267  6673 solver.cpp:228] Iteration 14660, loss = 0.237612
I0626 11:02:44.007292  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:02:44.007299  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122375 (* 1 = 0.0122375 loss)
I0626 11:02:44.007306  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0648065 (* 1 = 0.0648065 loss)
I0626 11:02:44.007313  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000773167 (* 1 = 0.000773167 loss)
I0626 11:02:44.007318  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00462742 (* 1 = 0.00462742 loss)
I0626 11:02:44.007323  6673 sgd_solver.cpp:106] Iteration 14660, lr = 0.0002
I0626 11:04:22.050556  6673 solver.cpp:228] Iteration 14680, loss = 0.301691
I0626 11:04:22.050581  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:04:22.050588  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518291 (* 1 = 0.0518291 loss)
I0626 11:04:22.050592  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100991 (* 1 = 0.100991 loss)
I0626 11:04:22.050596  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000654216 (* 1 = 0.000654216 loss)
I0626 11:04:22.050599  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122692 (* 1 = 0.0122692 loss)
I0626 11:04:22.050604  6673 sgd_solver.cpp:106] Iteration 14680, lr = 0.0002
I0626 11:06:00.035101  6673 solver.cpp:228] Iteration 14700, loss = 0.190992
I0626 11:06:00.035127  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:06:00.035135  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0109419 (* 1 = 0.0109419 loss)
I0626 11:06:00.035138  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0927217 (* 1 = 0.0927217 loss)
I0626 11:06:00.035141  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114798 (* 1 = 0.0114798 loss)
I0626 11:06:00.035145  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163178 (* 1 = 0.0163178 loss)
I0626 11:06:00.035151  6673 sgd_solver.cpp:106] Iteration 14700, lr = 0.0002
I0626 11:07:37.986883  6673 solver.cpp:228] Iteration 14720, loss = 0.0790188
I0626 11:07:37.986914  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:07:37.986922  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237131 (* 1 = 0.0237131 loss)
I0626 11:07:37.986925  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0406717 (* 1 = 0.0406717 loss)
I0626 11:07:37.986929  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000182525 (* 1 = 0.000182525 loss)
I0626 11:07:37.986932  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00398358 (* 1 = 0.00398358 loss)
I0626 11:07:37.986937  6673 sgd_solver.cpp:106] Iteration 14720, lr = 0.0002
I0626 11:09:15.980331  6673 solver.cpp:228] Iteration 14740, loss = 0.276968
I0626 11:09:15.980363  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 11:09:15.980371  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.109072 (* 1 = 0.109072 loss)
I0626 11:09:15.980376  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.207741 (* 1 = 0.207741 loss)
I0626 11:09:15.980379  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00467485 (* 1 = 0.00467485 loss)
I0626 11:09:15.980383  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0633595 (* 1 = 0.0633595 loss)
I0626 11:09:15.980389  6673 sgd_solver.cpp:106] Iteration 14740, lr = 0.0002
I0626 11:10:54.064412  6673 solver.cpp:228] Iteration 14760, loss = 0.237658
I0626 11:10:54.064437  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 11:10:54.064445  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0911883 (* 1 = 0.0911883 loss)
I0626 11:10:54.064448  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.142553 (* 1 = 0.142553 loss)
I0626 11:10:54.064452  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00093821 (* 1 = 0.00093821 loss)
I0626 11:10:54.064455  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101855 (* 1 = 0.0101855 loss)
I0626 11:10:54.064460  6673 sgd_solver.cpp:106] Iteration 14760, lr = 0.0002
I0626 11:12:32.441563  6673 solver.cpp:228] Iteration 14780, loss = 0.181533
I0626 11:12:32.441596  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:12:32.441602  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261822 (* 1 = 0.0261822 loss)
I0626 11:12:32.441606  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.043173 (* 1 = 0.043173 loss)
I0626 11:12:32.441610  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00803684 (* 1 = 0.00803684 loss)
I0626 11:12:32.441614  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00589388 (* 1 = 0.00589388 loss)
I0626 11:12:32.441619  6673 sgd_solver.cpp:106] Iteration 14780, lr = 0.0002
speed: 4.923s / iter
I0626 11:14:10.480245  6673 solver.cpp:228] Iteration 14800, loss = 0.256838
I0626 11:14:10.480271  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:14:10.480279  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140447 (* 1 = 0.0140447 loss)
I0626 11:14:10.480284  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0254014 (* 1 = 0.0254014 loss)
I0626 11:14:10.480288  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.28416e-05 (* 1 = 8.28416e-05 loss)
I0626 11:14:10.480293  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00448885 (* 1 = 0.00448885 loss)
I0626 11:14:10.480299  6673 sgd_solver.cpp:106] Iteration 14800, lr = 0.0002
I0626 11:15:48.872835  6673 solver.cpp:228] Iteration 14820, loss = 0.200184
I0626 11:15:48.872860  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 11:15:48.872869  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105188 (* 1 = 0.105188 loss)
I0626 11:15:48.872872  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.192508 (* 1 = 0.192508 loss)
I0626 11:15:48.872876  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00883299 (* 1 = 0.00883299 loss)
I0626 11:15:48.872880  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0366573 (* 1 = 0.0366573 loss)
I0626 11:15:48.872886  6673 sgd_solver.cpp:106] Iteration 14820, lr = 0.0002
I0626 11:17:27.549415  6673 solver.cpp:228] Iteration 14840, loss = 0.195849
I0626 11:17:27.549441  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:17:27.549449  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0502476 (* 1 = 0.0502476 loss)
I0626 11:17:27.549453  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0379333 (* 1 = 0.0379333 loss)
I0626 11:17:27.549456  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000402482 (* 1 = 0.000402482 loss)
I0626 11:17:27.549460  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00329644 (* 1 = 0.00329644 loss)
I0626 11:17:27.549464  6673 sgd_solver.cpp:106] Iteration 14840, lr = 0.0002
I0626 11:19:05.842514  6673 solver.cpp:228] Iteration 14860, loss = 0.237152
I0626 11:19:05.842537  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0626 11:19:05.842545  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.27171 (* 1 = 0.27171 loss)
I0626 11:19:05.842547  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.470696 (* 1 = 0.470696 loss)
I0626 11:19:05.842551  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00302212 (* 1 = 0.00302212 loss)
I0626 11:19:05.842555  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394824 (* 1 = 0.0394824 loss)
I0626 11:19:05.842559  6673 sgd_solver.cpp:106] Iteration 14860, lr = 0.0002
I0626 11:20:44.015712  6673 solver.cpp:228] Iteration 14880, loss = 0.355327
I0626 11:20:44.015739  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 11:20:44.015748  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347968 (* 1 = 0.0347968 loss)
I0626 11:20:44.015754  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.137968 (* 1 = 0.137968 loss)
I0626 11:20:44.015759  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135046 (* 1 = 0.0135046 loss)
I0626 11:20:44.015764  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223845 (* 1 = 0.0223845 loss)
I0626 11:20:44.015771  6673 sgd_solver.cpp:106] Iteration 14880, lr = 0.0002
I0626 11:22:23.218304  6673 solver.cpp:228] Iteration 14900, loss = 0.147633
I0626 11:22:23.218391  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 11:22:23.218425  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.130614 (* 1 = 0.130614 loss)
I0626 11:22:23.218452  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.262578 (* 1 = 0.262578 loss)
I0626 11:22:23.218477  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00697154 (* 1 = 0.00697154 loss)
I0626 11:22:23.218498  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0341034 (* 1 = 0.0341034 loss)
I0626 11:22:23.218520  6673 sgd_solver.cpp:106] Iteration 14900, lr = 0.0002
I0626 11:24:04.464367  6673 solver.cpp:228] Iteration 14920, loss = 0.179296
I0626 11:24:04.464452  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 11:24:04.464483  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432945 (* 1 = 0.0432945 loss)
I0626 11:24:04.464505  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0945052 (* 1 = 0.0945052 loss)
I0626 11:24:04.464527  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000776382 (* 1 = 0.000776382 loss)
I0626 11:24:04.464548  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00652227 (* 1 = 0.00652227 loss)
I0626 11:24:04.464568  6673 sgd_solver.cpp:106] Iteration 14920, lr = 0.0002
I0626 11:25:45.686167  6673 solver.cpp:228] Iteration 14940, loss = 0.137136
I0626 11:25:45.686216  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:25:45.686233  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0518485 (* 1 = 0.0518485 loss)
I0626 11:25:45.686244  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0539768 (* 1 = 0.0539768 loss)
I0626 11:25:45.686252  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0004203 (* 1 = 0.0004203 loss)
I0626 11:25:45.686260  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178375 (* 1 = 0.0178375 loss)
I0626 11:25:45.686270  6673 sgd_solver.cpp:106] Iteration 14940, lr = 0.0002
I0626 11:27:26.128093  6673 solver.cpp:228] Iteration 14960, loss = 0.187768
I0626 11:27:26.128118  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 11:27:26.128126  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0678309 (* 1 = 0.0678309 loss)
I0626 11:27:26.128131  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.1102 (* 1 = 0.1102 loss)
I0626 11:27:26.128134  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000787204 (* 1 = 0.000787204 loss)
I0626 11:27:26.128139  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124921 (* 1 = 0.0124921 loss)
I0626 11:27:26.128144  6673 sgd_solver.cpp:106] Iteration 14960, lr = 0.0002
I0626 11:29:04.416388  6673 solver.cpp:228] Iteration 14980, loss = 0.363734
I0626 11:29:04.416416  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 11:29:04.416425  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0547448 (* 1 = 0.0547448 loss)
I0626 11:29:04.416432  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0954103 (* 1 = 0.0954103 loss)
I0626 11:29:04.416437  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248476 (* 1 = 0.00248476 loss)
I0626 11:29:04.416443  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233443 (* 1 = 0.0233443 loss)
I0626 11:29:04.416450  6673 sgd_solver.cpp:106] Iteration 14980, lr = 0.0002
speed: 4.923s / iter
I0626 11:30:38.151319  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_15000.caffemodel
I0626 11:30:43.852577  6673 solver.cpp:228] Iteration 15000, loss = 0.167947
I0626 11:30:43.852603  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 11:30:43.852612  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.123612 (* 1 = 0.123612 loss)
I0626 11:30:43.852617  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.207511 (* 1 = 0.207511 loss)
I0626 11:30:43.852622  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0369807 (* 1 = 0.0369807 loss)
I0626 11:30:43.852627  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.145997 (* 1 = 0.145997 loss)
I0626 11:30:43.852632  6673 sgd_solver.cpp:106] Iteration 15000, lr = 0.0002
I0626 11:32:21.856020  6673 solver.cpp:228] Iteration 15020, loss = 0.235166
I0626 11:32:21.856070  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 11:32:21.856079  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537113 (* 1 = 0.0537113 loss)
I0626 11:32:21.856086  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.233402 (* 1 = 0.233402 loss)
I0626 11:32:21.856091  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229128 (* 1 = 0.00229128 loss)
I0626 11:32:21.856096  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255636 (* 1 = 0.0255636 loss)
I0626 11:32:21.856104  6673 sgd_solver.cpp:106] Iteration 15020, lr = 0.0002
I0626 11:33:59.766180  6673 solver.cpp:228] Iteration 15040, loss = 0.239354
I0626 11:33:59.766206  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 11:33:59.766212  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0814386 (* 1 = 0.0814386 loss)
I0626 11:33:59.766217  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.200712 (* 1 = 0.200712 loss)
I0626 11:33:59.766222  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128822 (* 1 = 0.00128822 loss)
I0626 11:33:59.766225  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00854689 (* 1 = 0.00854689 loss)
I0626 11:33:59.766230  6673 sgd_solver.cpp:106] Iteration 15040, lr = 0.0002
I0626 11:35:37.688341  6673 solver.cpp:228] Iteration 15060, loss = 0.144106
I0626 11:35:37.688366  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:35:37.688374  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204963 (* 1 = 0.0204963 loss)
I0626 11:35:37.688379  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0488486 (* 1 = 0.0488486 loss)
I0626 11:35:37.688382  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118582 (* 1 = 0.00118582 loss)
I0626 11:35:37.688386  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135875 (* 1 = 0.0135875 loss)
I0626 11:35:37.688391  6673 sgd_solver.cpp:106] Iteration 15060, lr = 0.0002
I0626 11:37:15.674994  6673 solver.cpp:228] Iteration 15080, loss = 0.169853
I0626 11:37:15.675022  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 11:37:15.675030  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.178088 (* 1 = 0.178088 loss)
I0626 11:37:15.675035  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.208056 (* 1 = 0.208056 loss)
I0626 11:37:15.675040  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00460649 (* 1 = 0.00460649 loss)
I0626 11:37:15.675042  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485235 (* 1 = 0.0485235 loss)
I0626 11:37:15.675050  6673 sgd_solver.cpp:106] Iteration 15080, lr = 0.0002
I0626 11:38:53.743167  6673 solver.cpp:228] Iteration 15100, loss = 0.367837
I0626 11:38:53.743192  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 11:38:53.743199  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308707 (* 1 = 0.0308707 loss)
I0626 11:38:53.743203  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122046 (* 1 = 0.122046 loss)
I0626 11:38:53.743206  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000134953 (* 1 = 0.000134953 loss)
I0626 11:38:53.743211  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168763 (* 1 = 0.0168763 loss)
I0626 11:38:53.743214  6673 sgd_solver.cpp:106] Iteration 15100, lr = 0.0002
I0626 11:40:31.795487  6673 solver.cpp:228] Iteration 15120, loss = 0.173984
I0626 11:40:31.795511  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 11:40:31.795517  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440375 (* 1 = 0.0440375 loss)
I0626 11:40:31.795521  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0750598 (* 1 = 0.0750598 loss)
I0626 11:40:31.795526  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00349837 (* 1 = 0.00349837 loss)
I0626 11:40:31.795528  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00615375 (* 1 = 0.00615375 loss)
I0626 11:40:31.795532  6673 sgd_solver.cpp:106] Iteration 15120, lr = 0.0002
I0626 11:42:09.750375  6673 solver.cpp:228] Iteration 15140, loss = 0.237785
I0626 11:42:09.750401  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:42:09.750408  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.052447 (* 1 = 0.052447 loss)
I0626 11:42:09.750413  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0969527 (* 1 = 0.0969527 loss)
I0626 11:42:09.750417  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00011025 (* 1 = 0.00011025 loss)
I0626 11:42:09.750422  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142513 (* 1 = 0.0142513 loss)
I0626 11:42:09.750425  6673 sgd_solver.cpp:106] Iteration 15140, lr = 0.0002
I0626 11:43:47.653038  6673 solver.cpp:228] Iteration 15160, loss = 0.174277
I0626 11:43:47.653059  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:43:47.653066  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261426 (* 1 = 0.0261426 loss)
I0626 11:43:47.653070  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0410507 (* 1 = 0.0410507 loss)
I0626 11:43:47.653074  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00029128 (* 1 = 0.00029128 loss)
I0626 11:43:47.653077  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00705441 (* 1 = 0.00705441 loss)
I0626 11:43:47.653082  6673 sgd_solver.cpp:106] Iteration 15160, lr = 0.0002
I0626 11:45:25.806022  6673 solver.cpp:228] Iteration 15180, loss = 0.116223
I0626 11:45:25.806046  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 11:45:25.806054  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0678886 (* 1 = 0.0678886 loss)
I0626 11:45:25.806061  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.101863 (* 1 = 0.101863 loss)
I0626 11:45:25.806066  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144868 (* 1 = 0.00144868 loss)
I0626 11:45:25.806071  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100835 (* 1 = 0.0100835 loss)
I0626 11:45:25.806077  6673 sgd_solver.cpp:106] Iteration 15180, lr = 0.0002
speed: 4.923s / iter
I0626 11:47:03.807358  6673 solver.cpp:228] Iteration 15200, loss = 0.187166
I0626 11:47:03.807399  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 11:47:03.807407  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.146778 (* 1 = 0.146778 loss)
I0626 11:47:03.807411  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.256492 (* 1 = 0.256492 loss)
I0626 11:47:03.807415  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00170651 (* 1 = 0.00170651 loss)
I0626 11:47:03.807420  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268037 (* 1 = 0.0268037 loss)
I0626 11:47:03.807426  6673 sgd_solver.cpp:106] Iteration 15200, lr = 0.0002
I0626 11:48:41.783143  6673 solver.cpp:228] Iteration 15220, loss = 0.114156
I0626 11:48:41.783167  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 11:48:41.783174  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00938324 (* 1 = 0.00938324 loss)
I0626 11:48:41.783179  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0213844 (* 1 = 0.0213844 loss)
I0626 11:48:41.783181  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000215789 (* 1 = 0.000215789 loss)
I0626 11:48:41.783185  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0091787 (* 1 = 0.0091787 loss)
I0626 11:48:41.783190  6673 sgd_solver.cpp:106] Iteration 15220, lr = 0.0002
I0626 11:50:19.686064  6673 solver.cpp:228] Iteration 15240, loss = 0.28177
I0626 11:50:19.686089  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 11:50:19.686095  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0903982 (* 1 = 0.0903982 loss)
I0626 11:50:19.686100  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.157232 (* 1 = 0.157232 loss)
I0626 11:50:19.686102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0064001 (* 1 = 0.0064001 loss)
I0626 11:50:19.686106  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211985 (* 1 = 0.0211985 loss)
I0626 11:50:19.686110  6673 sgd_solver.cpp:106] Iteration 15240, lr = 0.0002
I0626 11:51:57.686918  6673 solver.cpp:228] Iteration 15260, loss = 0.187939
I0626 11:51:57.686944  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 11:51:57.686951  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0573469 (* 1 = 0.0573469 loss)
I0626 11:51:57.686955  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0815901 (* 1 = 0.0815901 loss)
I0626 11:51:57.686959  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000451022 (* 1 = 0.000451022 loss)
I0626 11:51:57.686962  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00613326 (* 1 = 0.00613326 loss)
I0626 11:51:57.686967  6673 sgd_solver.cpp:106] Iteration 15260, lr = 0.0002
I0626 11:53:35.704233  6673 solver.cpp:228] Iteration 15280, loss = 0.143852
I0626 11:53:35.704257  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:53:35.704263  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314869 (* 1 = 0.0314869 loss)
I0626 11:53:35.704267  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0491133 (* 1 = 0.0491133 loss)
I0626 11:53:35.704270  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000671328 (* 1 = 0.000671328 loss)
I0626 11:53:35.704274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00438798 (* 1 = 0.00438798 loss)
I0626 11:53:35.704278  6673 sgd_solver.cpp:106] Iteration 15280, lr = 0.0002
I0626 11:55:13.724421  6673 solver.cpp:228] Iteration 15300, loss = 0.252102
I0626 11:55:13.724443  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 11:55:13.724452  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571059 (* 1 = 0.0571059 loss)
I0626 11:55:13.724458  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.072852 (* 1 = 0.072852 loss)
I0626 11:55:13.724463  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282279 (* 1 = 0.00282279 loss)
I0626 11:55:13.724469  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196139 (* 1 = 0.0196139 loss)
I0626 11:55:13.724475  6673 sgd_solver.cpp:106] Iteration 15300, lr = 0.0002
I0626 11:56:51.704527  6673 solver.cpp:228] Iteration 15320, loss = 0.200455
I0626 11:56:51.704555  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 11:56:51.704562  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0897046 (* 1 = 0.0897046 loss)
I0626 11:56:51.704567  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.156377 (* 1 = 0.156377 loss)
I0626 11:56:51.704572  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00627558 (* 1 = 0.00627558 loss)
I0626 11:56:51.704577  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303491 (* 1 = 0.0303491 loss)
I0626 11:56:51.704582  6673 sgd_solver.cpp:106] Iteration 15320, lr = 0.0002
I0626 11:58:30.003373  6673 solver.cpp:228] Iteration 15340, loss = 0.208233
I0626 11:58:30.003398  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 11:58:30.003408  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0375182 (* 1 = 0.0375182 loss)
I0626 11:58:30.003414  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0294083 (* 1 = 0.0294083 loss)
I0626 11:58:30.003422  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000367447 (* 1 = 0.000367447 loss)
I0626 11:58:30.003427  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176743 (* 1 = 0.0176743 loss)
I0626 11:58:30.003433  6673 sgd_solver.cpp:106] Iteration 15340, lr = 0.0002
I0626 12:00:07.940328  6673 solver.cpp:228] Iteration 15360, loss = 0.210194
I0626 12:00:07.940352  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 12:00:07.940361  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272202 (* 1 = 0.0272202 loss)
I0626 12:00:07.940364  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0984158 (* 1 = 0.0984158 loss)
I0626 12:00:07.940368  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113723 (* 1 = 0.00113723 loss)
I0626 12:00:07.940372  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224403 (* 1 = 0.0224403 loss)
I0626 12:00:07.940377  6673 sgd_solver.cpp:106] Iteration 15360, lr = 0.0002
I0626 12:01:45.854743  6673 solver.cpp:228] Iteration 15380, loss = 0.159822
I0626 12:01:45.854763  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 12:01:45.854770  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737981 (* 1 = 0.0737981 loss)
I0626 12:01:45.854776  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106247 (* 1 = 0.106247 loss)
I0626 12:01:45.854781  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000499349 (* 1 = 0.000499349 loss)
I0626 12:01:45.854784  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00935567 (* 1 = 0.00935567 loss)
I0626 12:01:45.854789  6673 sgd_solver.cpp:106] Iteration 15380, lr = 0.0002
speed: 4.923s / iter
I0626 12:03:23.926918  6673 solver.cpp:228] Iteration 15400, loss = 0.187162
I0626 12:03:23.926939  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 12:03:23.926949  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526579 (* 1 = 0.0526579 loss)
I0626 12:03:23.926954  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0876716 (* 1 = 0.0876716 loss)
I0626 12:03:23.926959  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000324276 (* 1 = 0.000324276 loss)
I0626 12:03:23.926965  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00780066 (* 1 = 0.00780066 loss)
I0626 12:03:23.926971  6673 sgd_solver.cpp:106] Iteration 15400, lr = 0.0002
I0626 12:05:01.809425  6673 solver.cpp:228] Iteration 15420, loss = 0.180335
I0626 12:05:01.809448  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 12:05:01.809454  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.112541 (* 1 = 0.112541 loss)
I0626 12:05:01.809458  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.147595 (* 1 = 0.147595 loss)
I0626 12:05:01.809463  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00112963 (* 1 = 0.00112963 loss)
I0626 12:05:01.809465  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217318 (* 1 = 0.0217318 loss)
I0626 12:05:01.809469  6673 sgd_solver.cpp:106] Iteration 15420, lr = 0.0002
I0626 12:06:39.772276  6673 solver.cpp:228] Iteration 15440, loss = 0.257437
I0626 12:06:39.772303  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 12:06:39.772311  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.173561 (* 1 = 0.173561 loss)
I0626 12:06:39.772315  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.263922 (* 1 = 0.263922 loss)
I0626 12:06:39.772320  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210901 (* 1 = 0.0210901 loss)
I0626 12:06:39.772323  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0546632 (* 1 = 0.0546632 loss)
I0626 12:06:39.772327  6673 sgd_solver.cpp:106] Iteration 15440, lr = 0.0002
I0626 12:08:17.713147  6673 solver.cpp:228] Iteration 15460, loss = 0.151357
I0626 12:08:17.713172  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 12:08:17.713181  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0409667 (* 1 = 0.0409667 loss)
I0626 12:08:17.713186  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.06255 (* 1 = 0.06255 loss)
I0626 12:08:17.713191  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000211514 (* 1 = 0.000211514 loss)
I0626 12:08:17.713196  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00511412 (* 1 = 0.00511412 loss)
I0626 12:08:17.713201  6673 sgd_solver.cpp:106] Iteration 15460, lr = 0.0002
I0626 12:09:55.637924  6673 solver.cpp:228] Iteration 15480, loss = 0.188354
I0626 12:09:55.637948  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 12:09:55.637956  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.062737 (* 1 = 0.062737 loss)
I0626 12:09:55.637962  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0812755 (* 1 = 0.0812755 loss)
I0626 12:09:55.637967  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000439525 (* 1 = 0.000439525 loss)
I0626 12:09:55.637974  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00592354 (* 1 = 0.00592354 loss)
I0626 12:09:55.637980  6673 sgd_solver.cpp:106] Iteration 15480, lr = 0.0002
I0626 12:11:33.545199  6673 solver.cpp:228] Iteration 15500, loss = 0.0828753
I0626 12:11:33.545220  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:11:33.545228  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173415 (* 1 = 0.0173415 loss)
I0626 12:11:33.545231  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0435032 (* 1 = 0.0435032 loss)
I0626 12:11:33.545235  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130802 (* 1 = 0.00130802 loss)
I0626 12:11:33.545238  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00566129 (* 1 = 0.00566129 loss)
I0626 12:11:33.545243  6673 sgd_solver.cpp:106] Iteration 15500, lr = 0.0002
I0626 12:13:11.487751  6673 solver.cpp:228] Iteration 15520, loss = 0.233062
I0626 12:13:11.487774  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 12:13:11.487782  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.223548 (* 1 = 0.223548 loss)
I0626 12:13:11.487787  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.395877 (* 1 = 0.395877 loss)
I0626 12:13:11.487792  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192409 (* 1 = 0.0192409 loss)
I0626 12:13:11.487797  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373968 (* 1 = 0.0373968 loss)
I0626 12:13:11.487802  6673 sgd_solver.cpp:106] Iteration 15520, lr = 0.0002
I0626 12:14:49.402531  6673 solver.cpp:228] Iteration 15540, loss = 0.308861
I0626 12:14:49.402557  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 12:14:49.402567  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466458 (* 1 = 0.0466458 loss)
I0626 12:14:49.402573  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.167013 (* 1 = 0.167013 loss)
I0626 12:14:49.402578  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120317 (* 1 = 0.0120317 loss)
I0626 12:14:49.402585  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514138 (* 1 = 0.0514138 loss)
I0626 12:14:49.402591  6673 sgd_solver.cpp:106] Iteration 15540, lr = 0.0002
I0626 12:16:27.343502  6673 solver.cpp:228] Iteration 15560, loss = 0.290362
I0626 12:16:27.343526  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 12:16:27.343533  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0995423 (* 1 = 0.0995423 loss)
I0626 12:16:27.343540  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.222073 (* 1 = 0.222073 loss)
I0626 12:16:27.343546  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00738681 (* 1 = 0.00738681 loss)
I0626 12:16:27.343550  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.133195 (* 1 = 0.133195 loss)
I0626 12:16:27.343555  6673 sgd_solver.cpp:106] Iteration 15560, lr = 0.0002
I0626 12:18:05.249416  6673 solver.cpp:228] Iteration 15580, loss = 0.189964
I0626 12:18:05.249439  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:18:05.249446  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215845 (* 1 = 0.0215845 loss)
I0626 12:18:05.249450  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0390171 (* 1 = 0.0390171 loss)
I0626 12:18:05.249454  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000972635 (* 1 = 0.000972635 loss)
I0626 12:18:05.249457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00499395 (* 1 = 0.00499395 loss)
I0626 12:18:05.249461  6673 sgd_solver.cpp:106] Iteration 15580, lr = 0.0002
speed: 4.923s / iter
I0626 12:19:43.204226  6673 solver.cpp:228] Iteration 15600, loss = 0.153363
I0626 12:19:43.204250  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:19:43.204257  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00675019 (* 1 = 0.00675019 loss)
I0626 12:19:43.204262  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0485828 (* 1 = 0.0485828 loss)
I0626 12:19:43.204265  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000777422 (* 1 = 0.000777422 loss)
I0626 12:19:43.204269  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00339052 (* 1 = 0.00339052 loss)
I0626 12:19:43.204274  6673 sgd_solver.cpp:106] Iteration 15600, lr = 0.0002
I0626 12:21:21.121124  6673 solver.cpp:228] Iteration 15620, loss = 0.311899
I0626 12:21:21.121147  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 12:21:21.121155  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0695552 (* 1 = 0.0695552 loss)
I0626 12:21:21.121158  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102992 (* 1 = 0.102992 loss)
I0626 12:21:21.121161  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118068 (* 1 = 0.0118068 loss)
I0626 12:21:21.121165  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224652 (* 1 = 0.0224652 loss)
I0626 12:21:21.121170  6673 sgd_solver.cpp:106] Iteration 15620, lr = 0.0002
I0626 12:22:59.039561  6673 solver.cpp:228] Iteration 15640, loss = 0.158996
I0626 12:22:59.039583  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 12:22:59.039590  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0421875 (* 1 = 0.0421875 loss)
I0626 12:22:59.039593  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.088513 (* 1 = 0.088513 loss)
I0626 12:22:59.039597  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115288 (* 1 = 0.00115288 loss)
I0626 12:22:59.039600  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00893515 (* 1 = 0.00893515 loss)
I0626 12:22:59.039603  6673 sgd_solver.cpp:106] Iteration 15640, lr = 0.0002
I0626 12:24:36.976323  6673 solver.cpp:228] Iteration 15660, loss = 0.23586
I0626 12:24:36.976346  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 12:24:36.976353  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228355 (* 1 = 0.0228355 loss)
I0626 12:24:36.976357  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0639427 (* 1 = 0.0639427 loss)
I0626 12:24:36.976361  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000888539 (* 1 = 0.000888539 loss)
I0626 12:24:36.976366  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00250381 (* 1 = 0.00250381 loss)
I0626 12:24:36.976371  6673 sgd_solver.cpp:106] Iteration 15660, lr = 0.0002
I0626 12:26:14.877995  6673 solver.cpp:228] Iteration 15680, loss = 0.303602
I0626 12:26:14.878016  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 12:26:14.878023  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445869 (* 1 = 0.0445869 loss)
I0626 12:26:14.878027  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0955929 (* 1 = 0.0955929 loss)
I0626 12:26:14.878031  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182468 (* 1 = 0.0182468 loss)
I0626 12:26:14.878034  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0279548 (* 1 = 0.0279548 loss)
I0626 12:26:14.878038  6673 sgd_solver.cpp:106] Iteration 15680, lr = 0.0002
I0626 12:27:52.823760  6673 solver.cpp:228] Iteration 15700, loss = 0.191617
I0626 12:27:52.823782  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 12:27:52.823791  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0815602 (* 1 = 0.0815602 loss)
I0626 12:27:52.823793  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.260761 (* 1 = 0.260761 loss)
I0626 12:27:52.823797  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0458272 (* 1 = 0.0458272 loss)
I0626 12:27:52.823801  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.182873 (* 1 = 0.182873 loss)
I0626 12:27:52.823806  6673 sgd_solver.cpp:106] Iteration 15700, lr = 0.0002
I0626 12:29:30.767266  6673 solver.cpp:228] Iteration 15720, loss = 0.235967
I0626 12:29:30.767287  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:29:30.767293  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0252944 (* 1 = 0.0252944 loss)
I0626 12:29:30.767297  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0603624 (* 1 = 0.0603624 loss)
I0626 12:29:30.767302  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000290647 (* 1 = 0.000290647 loss)
I0626 12:29:30.767304  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00518445 (* 1 = 0.00518445 loss)
I0626 12:29:30.767308  6673 sgd_solver.cpp:106] Iteration 15720, lr = 0.0002
I0626 12:31:08.706097  6673 solver.cpp:228] Iteration 15740, loss = 0.382835
I0626 12:31:08.706120  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:31:08.706127  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454963 (* 1 = 0.0454963 loss)
I0626 12:31:08.706130  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0523442 (* 1 = 0.0523442 loss)
I0626 12:31:08.706135  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00242269 (* 1 = 0.00242269 loss)
I0626 12:31:08.706137  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128739 (* 1 = 0.0128739 loss)
I0626 12:31:08.706142  6673 sgd_solver.cpp:106] Iteration 15740, lr = 0.0002
I0626 12:32:46.653739  6673 solver.cpp:228] Iteration 15760, loss = 0.17223
I0626 12:32:46.653764  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:32:46.653771  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0492418 (* 1 = 0.0492418 loss)
I0626 12:32:46.653775  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0742645 (* 1 = 0.0742645 loss)
I0626 12:32:46.653779  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00326066 (* 1 = 0.00326066 loss)
I0626 12:32:46.653784  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110742 (* 1 = 0.0110742 loss)
I0626 12:32:46.653787  6673 sgd_solver.cpp:106] Iteration 15760, lr = 0.0002
I0626 12:34:24.567358  6673 solver.cpp:228] Iteration 15780, loss = 0.133766
I0626 12:34:24.567381  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:34:24.567389  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448507 (* 1 = 0.0448507 loss)
I0626 12:34:24.567391  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0501717 (* 1 = 0.0501717 loss)
I0626 12:34:24.567394  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116449 (* 1 = 0.0116449 loss)
I0626 12:34:24.567397  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00912564 (* 1 = 0.00912564 loss)
I0626 12:34:24.567402  6673 sgd_solver.cpp:106] Iteration 15780, lr = 0.0002
speed: 4.922s / iter
I0626 12:36:02.484506  6673 solver.cpp:228] Iteration 15800, loss = 0.405471
I0626 12:36:02.484536  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 12:36:02.484544  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0946729 (* 1 = 0.0946729 loss)
I0626 12:36:02.484547  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.112755 (* 1 = 0.112755 loss)
I0626 12:36:02.484551  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000486664 (* 1 = 0.000486664 loss)
I0626 12:36:02.484555  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235515 (* 1 = 0.0235515 loss)
I0626 12:36:02.484560  6673 sgd_solver.cpp:106] Iteration 15800, lr = 0.0002
I0626 12:37:40.446687  6673 solver.cpp:228] Iteration 15820, loss = 0.279565
I0626 12:37:40.446728  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:37:40.446738  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.022169 (* 1 = 0.022169 loss)
I0626 12:37:40.446741  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0587237 (* 1 = 0.0587237 loss)
I0626 12:37:40.446745  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000188622 (* 1 = 0.000188622 loss)
I0626 12:37:40.446749  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00397625 (* 1 = 0.00397625 loss)
I0626 12:37:40.446755  6673 sgd_solver.cpp:106] Iteration 15820, lr = 0.0002
I0626 12:39:18.392514  6673 solver.cpp:228] Iteration 15840, loss = 0.177805
I0626 12:39:18.392535  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:39:18.392542  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0311522 (* 1 = 0.0311522 loss)
I0626 12:39:18.392545  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0418537 (* 1 = 0.0418537 loss)
I0626 12:39:18.392549  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000105403 (* 1 = 0.000105403 loss)
I0626 12:39:18.392552  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00224105 (* 1 = 0.00224105 loss)
I0626 12:39:18.392556  6673 sgd_solver.cpp:106] Iteration 15840, lr = 0.0002
I0626 12:40:56.326238  6673 solver.cpp:228] Iteration 15860, loss = 0.203753
I0626 12:40:56.326262  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 12:40:56.326270  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138476 (* 1 = 0.0138476 loss)
I0626 12:40:56.326277  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0332836 (* 1 = 0.0332836 loss)
I0626 12:40:56.326283  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000793698 (* 1 = 0.000793698 loss)
I0626 12:40:56.326287  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00121397 (* 1 = 0.00121397 loss)
I0626 12:40:56.326293  6673 sgd_solver.cpp:106] Iteration 15860, lr = 0.0002
I0626 12:42:34.253932  6673 solver.cpp:228] Iteration 15880, loss = 0.244181
I0626 12:42:34.253957  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 12:42:34.253965  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.26472 (* 1 = 0.26472 loss)
I0626 12:42:34.253971  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.31497 (* 1 = 0.31497 loss)
I0626 12:42:34.253976  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00111362 (* 1 = 0.00111362 loss)
I0626 12:42:34.253983  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0568509 (* 1 = 0.0568509 loss)
I0626 12:42:34.253989  6673 sgd_solver.cpp:106] Iteration 15880, lr = 0.0002
I0626 12:44:12.161377  6673 solver.cpp:228] Iteration 15900, loss = 0.16472
I0626 12:44:12.161401  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 12:44:12.161408  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407844 (* 1 = 0.0407844 loss)
I0626 12:44:12.161412  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.146063 (* 1 = 0.146063 loss)
I0626 12:44:12.161415  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129268 (* 1 = 0.0129268 loss)
I0626 12:44:12.161419  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049602 (* 1 = 0.049602 loss)
I0626 12:44:12.161423  6673 sgd_solver.cpp:106] Iteration 15900, lr = 0.0002
I0626 12:45:50.106043  6673 solver.cpp:228] Iteration 15920, loss = 0.217987
I0626 12:45:50.106065  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 12:45:50.106070  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220059 (* 1 = 0.0220059 loss)
I0626 12:45:50.106075  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.02487 (* 1 = 0.02487 loss)
I0626 12:45:50.106077  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000947147 (* 1 = 0.000947147 loss)
I0626 12:45:50.106081  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122712 (* 1 = 0.0122712 loss)
I0626 12:45:50.106086  6673 sgd_solver.cpp:106] Iteration 15920, lr = 0.0002
I0626 12:47:28.076623  6673 solver.cpp:228] Iteration 15940, loss = 0.307186
I0626 12:47:28.076647  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 12:47:28.076654  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133295 (* 1 = 0.0133295 loss)
I0626 12:47:28.076659  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0336734 (* 1 = 0.0336734 loss)
I0626 12:47:28.076663  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00776648 (* 1 = 0.00776648 loss)
I0626 12:47:28.076666  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00563858 (* 1 = 0.00563858 loss)
I0626 12:47:28.076671  6673 sgd_solver.cpp:106] Iteration 15940, lr = 0.0002
I0626 12:49:05.945509  6673 solver.cpp:228] Iteration 15960, loss = 0.267597
I0626 12:49:05.945533  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:49:05.945539  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0304687 (* 1 = 0.0304687 loss)
I0626 12:49:05.945544  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0212251 (* 1 = 0.0212251 loss)
I0626 12:49:05.945547  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000438203 (* 1 = 0.000438203 loss)
I0626 12:49:05.945551  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00297755 (* 1 = 0.00297755 loss)
I0626 12:49:05.945555  6673 sgd_solver.cpp:106] Iteration 15960, lr = 0.0002
I0626 12:50:43.865800  6673 solver.cpp:228] Iteration 15980, loss = 0.115466
I0626 12:50:43.865823  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 12:50:43.865830  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321612 (* 1 = 0.0321612 loss)
I0626 12:50:43.865834  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122376 (* 1 = 0.122376 loss)
I0626 12:50:43.865837  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013967 (* 1 = 0.013967 loss)
I0626 12:50:43.865841  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0740493 (* 1 = 0.0740493 loss)
I0626 12:50:43.865845  6673 sgd_solver.cpp:106] Iteration 15980, lr = 0.0002
speed: 4.922s / iter
I0626 12:52:21.797677  6673 solver.cpp:228] Iteration 16000, loss = 0.191042
I0626 12:52:21.797699  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 12:52:21.797705  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234663 (* 1 = 0.0234663 loss)
I0626 12:52:21.797709  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0165807 (* 1 = 0.0165807 loss)
I0626 12:52:21.797713  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000665595 (* 1 = 0.000665595 loss)
I0626 12:52:21.797716  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00351779 (* 1 = 0.00351779 loss)
I0626 12:52:21.797720  6673 sgd_solver.cpp:106] Iteration 16000, lr = 0.0002
I0626 12:53:59.681453  6673 solver.cpp:228] Iteration 16020, loss = 0.182599
I0626 12:53:59.681478  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:53:59.681485  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0393457 (* 1 = 0.0393457 loss)
I0626 12:53:59.681489  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0869639 (* 1 = 0.0869639 loss)
I0626 12:53:59.681493  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000734129 (* 1 = 0.000734129 loss)
I0626 12:53:59.681496  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141602 (* 1 = 0.0141602 loss)
I0626 12:53:59.681501  6673 sgd_solver.cpp:106] Iteration 16020, lr = 0.0002
I0626 12:55:37.555375  6673 solver.cpp:228] Iteration 16040, loss = 0.173063
I0626 12:55:37.555404  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:55:37.555411  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359848 (* 1 = 0.0359848 loss)
I0626 12:55:37.555415  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0797684 (* 1 = 0.0797684 loss)
I0626 12:55:37.555419  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00227436 (* 1 = 0.00227436 loss)
I0626 12:55:37.555423  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310362 (* 1 = 0.0310362 loss)
I0626 12:55:37.555426  6673 sgd_solver.cpp:106] Iteration 16040, lr = 0.0002
I0626 12:57:15.502351  6673 solver.cpp:228] Iteration 16060, loss = 0.160777
I0626 12:57:15.502375  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 12:57:15.502382  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224528 (* 1 = 0.0224528 loss)
I0626 12:57:15.502385  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0717986 (* 1 = 0.0717986 loss)
I0626 12:57:15.502389  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00112933 (* 1 = 0.00112933 loss)
I0626 12:57:15.502393  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00281172 (* 1 = 0.00281172 loss)
I0626 12:57:15.502398  6673 sgd_solver.cpp:106] Iteration 16060, lr = 0.0002
I0626 12:58:53.414384  6673 solver.cpp:228] Iteration 16080, loss = 0.282129
I0626 12:58:53.414419  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 12:58:53.414429  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.072795 (* 1 = 0.072795 loss)
I0626 12:58:53.414436  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.160059 (* 1 = 0.160059 loss)
I0626 12:58:53.414443  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134751 (* 1 = 0.00134751 loss)
I0626 12:58:53.414449  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00482169 (* 1 = 0.00482169 loss)
I0626 12:58:53.414458  6673 sgd_solver.cpp:106] Iteration 16080, lr = 0.0002
I0626 13:00:31.853621  6673 solver.cpp:228] Iteration 16100, loss = 0.161236
I0626 13:00:31.853646  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:00:31.853654  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0345012 (* 1 = 0.0345012 loss)
I0626 13:00:31.853660  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0559376 (* 1 = 0.0559376 loss)
I0626 13:00:31.853665  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150221 (* 1 = 0.00150221 loss)
I0626 13:00:31.853672  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00902005 (* 1 = 0.00902005 loss)
I0626 13:00:31.853677  6673 sgd_solver.cpp:106] Iteration 16100, lr = 0.0002
I0626 13:02:10.537370  6673 solver.cpp:228] Iteration 16120, loss = 0.258792
I0626 13:02:10.537392  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:02:10.537400  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299051 (* 1 = 0.0299051 loss)
I0626 13:02:10.537403  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0718863 (* 1 = 0.0718863 loss)
I0626 13:02:10.537407  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00013712 (* 1 = 0.00013712 loss)
I0626 13:02:10.537410  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00323462 (* 1 = 0.00323462 loss)
I0626 13:02:10.537415  6673 sgd_solver.cpp:106] Iteration 16120, lr = 0.0002
I0626 13:03:48.796803  6673 solver.cpp:228] Iteration 16140, loss = 0.554713
I0626 13:03:48.796828  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0626 13:03:48.796835  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.505015 (* 1 = 0.505015 loss)
I0626 13:03:48.796839  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.616433 (* 1 = 0.616433 loss)
I0626 13:03:48.796844  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0304412 (* 1 = 0.0304412 loss)
I0626 13:03:48.796847  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.201016 (* 1 = 0.201016 loss)
I0626 13:03:48.796851  6673 sgd_solver.cpp:106] Iteration 16140, lr = 0.0002
I0626 13:05:26.977458  6673 solver.cpp:228] Iteration 16160, loss = 0.255866
I0626 13:05:26.977481  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:05:26.977488  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231612 (* 1 = 0.0231612 loss)
I0626 13:05:26.977493  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0495313 (* 1 = 0.0495313 loss)
I0626 13:05:26.977495  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000794861 (* 1 = 0.000794861 loss)
I0626 13:05:26.977499  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010458 (* 1 = 0.010458 loss)
I0626 13:05:26.977504  6673 sgd_solver.cpp:106] Iteration 16160, lr = 0.0002
I0626 13:07:05.065647  6673 solver.cpp:228] Iteration 16180, loss = 0.244753
I0626 13:07:05.065670  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 13:07:05.065677  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.110082 (* 1 = 0.110082 loss)
I0626 13:07:05.065681  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.226436 (* 1 = 0.226436 loss)
I0626 13:07:05.065685  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0254066 (* 1 = 0.0254066 loss)
I0626 13:07:05.065688  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00916011 (* 1 = 0.00916011 loss)
I0626 13:07:05.065692  6673 sgd_solver.cpp:106] Iteration 16180, lr = 0.0002
speed: 4.922s / iter
I0626 13:08:42.993086  6673 solver.cpp:228] Iteration 16200, loss = 0.177017
I0626 13:08:42.993111  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:08:42.993119  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159889 (* 1 = 0.0159889 loss)
I0626 13:08:42.993124  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0569571 (* 1 = 0.0569571 loss)
I0626 13:08:42.993126  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00197241 (* 1 = 0.00197241 loss)
I0626 13:08:42.993130  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00841001 (* 1 = 0.00841001 loss)
I0626 13:08:42.993135  6673 sgd_solver.cpp:106] Iteration 16200, lr = 0.0002
I0626 13:10:20.916333  6673 solver.cpp:228] Iteration 16220, loss = 0.19295
I0626 13:10:20.916357  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 13:10:20.916363  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00638707 (* 1 = 0.00638707 loss)
I0626 13:10:20.916368  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0298082 (* 1 = 0.0298082 loss)
I0626 13:10:20.916371  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115132 (* 1 = 0.0115132 loss)
I0626 13:10:20.916374  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00457291 (* 1 = 0.00457291 loss)
I0626 13:10:20.916379  6673 sgd_solver.cpp:106] Iteration 16220, lr = 0.0002
I0626 13:11:58.849099  6673 solver.cpp:228] Iteration 16240, loss = 0.248265
I0626 13:11:58.849122  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:11:58.849128  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.045153 (* 1 = 0.045153 loss)
I0626 13:11:58.849133  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0795747 (* 1 = 0.0795747 loss)
I0626 13:11:58.849136  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000757605 (* 1 = 0.000757605 loss)
I0626 13:11:58.849139  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0403284 (* 1 = 0.0403284 loss)
I0626 13:11:58.849143  6673 sgd_solver.cpp:106] Iteration 16240, lr = 0.0002
I0626 13:13:36.784657  6673 solver.cpp:228] Iteration 16260, loss = 0.238835
I0626 13:13:36.784684  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:13:36.784694  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292124 (* 1 = 0.0292124 loss)
I0626 13:13:36.784699  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0768415 (* 1 = 0.0768415 loss)
I0626 13:13:36.784705  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110951 (* 1 = 0.00110951 loss)
I0626 13:13:36.784710  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121416 (* 1 = 0.0121416 loss)
I0626 13:13:36.784716  6673 sgd_solver.cpp:106] Iteration 16260, lr = 0.0002
I0626 13:15:14.725482  6673 solver.cpp:228] Iteration 16280, loss = 0.263071
I0626 13:15:14.725505  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:15:14.725514  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0366319 (* 1 = 0.0366319 loss)
I0626 13:15:14.725520  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0365067 (* 1 = 0.0365067 loss)
I0626 13:15:14.725527  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000668764 (* 1 = 0.000668764 loss)
I0626 13:15:14.725531  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00341955 (* 1 = 0.00341955 loss)
I0626 13:15:14.725538  6673 sgd_solver.cpp:106] Iteration 16280, lr = 0.0002
I0626 13:16:52.629462  6673 solver.cpp:228] Iteration 16300, loss = 0.163283
I0626 13:16:52.629487  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:16:52.629494  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536714 (* 1 = 0.0536714 loss)
I0626 13:16:52.629498  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0747619 (* 1 = 0.0747619 loss)
I0626 13:16:52.629503  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00501104 (* 1 = 0.00501104 loss)
I0626 13:16:52.629506  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022308 (* 1 = 0.022308 loss)
I0626 13:16:52.629513  6673 sgd_solver.cpp:106] Iteration 16300, lr = 0.0002
I0626 13:18:30.546190  6673 solver.cpp:228] Iteration 16320, loss = 0.10317
I0626 13:18:30.546213  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:18:30.546221  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0567983 (* 1 = 0.0567983 loss)
I0626 13:18:30.546226  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0955781 (* 1 = 0.0955781 loss)
I0626 13:18:30.546229  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189048 (* 1 = 0.00189048 loss)
I0626 13:18:30.546233  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00755431 (* 1 = 0.00755431 loss)
I0626 13:18:30.546238  6673 sgd_solver.cpp:106] Iteration 16320, lr = 0.0002
I0626 13:20:08.486448  6673 solver.cpp:228] Iteration 16340, loss = 0.227288
I0626 13:20:08.486470  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 13:20:08.486477  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441092 (* 1 = 0.0441092 loss)
I0626 13:20:08.486481  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.261908 (* 1 = 0.261908 loss)
I0626 13:20:08.486485  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.002255 (* 1 = 0.002255 loss)
I0626 13:20:08.486487  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171629 (* 1 = 0.0171629 loss)
I0626 13:20:08.486492  6673 sgd_solver.cpp:106] Iteration 16340, lr = 0.0002
I0626 13:21:46.424237  6673 solver.cpp:228] Iteration 16360, loss = 0.164064
I0626 13:21:46.424259  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 13:21:46.424268  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0389278 (* 1 = 0.0389278 loss)
I0626 13:21:46.424274  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0539338 (* 1 = 0.0539338 loss)
I0626 13:21:46.424280  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000263375 (* 1 = 0.000263375 loss)
I0626 13:21:46.424284  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00344976 (* 1 = 0.00344976 loss)
I0626 13:21:46.424289  6673 sgd_solver.cpp:106] Iteration 16360, lr = 0.0002
I0626 13:23:24.346273  6673 solver.cpp:228] Iteration 16380, loss = 0.244051
I0626 13:23:24.346297  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:23:24.346303  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0546282 (* 1 = 0.0546282 loss)
I0626 13:23:24.346307  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0770445 (* 1 = 0.0770445 loss)
I0626 13:23:24.346310  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000518844 (* 1 = 0.000518844 loss)
I0626 13:23:24.346314  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00850126 (* 1 = 0.00850126 loss)
I0626 13:23:24.346318  6673 sgd_solver.cpp:106] Iteration 16380, lr = 0.0002
speed: 4.921s / iter
I0626 13:25:02.272934  6673 solver.cpp:228] Iteration 16400, loss = 0.313944
I0626 13:25:02.272959  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 13:25:02.272970  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206179 (* 1 = 0.0206179 loss)
I0626 13:25:02.272976  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0853065 (* 1 = 0.0853065 loss)
I0626 13:25:02.272982  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.51352e-05 (* 1 = 7.51352e-05 loss)
I0626 13:25:02.272989  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229417 (* 1 = 0.00229417 loss)
I0626 13:25:02.272995  6673 sgd_solver.cpp:106] Iteration 16400, lr = 0.0002
I0626 13:26:40.121366  6673 solver.cpp:228] Iteration 16420, loss = 0.205911
I0626 13:26:40.121388  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:26:40.121397  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634586 (* 1 = 0.0634586 loss)
I0626 13:26:40.121402  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0621915 (* 1 = 0.0621915 loss)
I0626 13:26:40.121407  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00662833 (* 1 = 0.00662833 loss)
I0626 13:26:40.121412  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00990223 (* 1 = 0.00990223 loss)
I0626 13:26:40.121417  6673 sgd_solver.cpp:106] Iteration 16420, lr = 0.0002
I0626 13:28:18.079099  6673 solver.cpp:228] Iteration 16440, loss = 0.132132
I0626 13:28:18.079123  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 13:28:18.079131  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795245 (* 1 = 0.0795245 loss)
I0626 13:28:18.079135  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.16101 (* 1 = 0.16101 loss)
I0626 13:28:18.079139  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00989456 (* 1 = 0.00989456 loss)
I0626 13:28:18.079144  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0543132 (* 1 = 0.0543132 loss)
I0626 13:28:18.079149  6673 sgd_solver.cpp:106] Iteration 16440, lr = 0.0002
I0626 13:29:55.987262  6673 solver.cpp:228] Iteration 16460, loss = 0.154668
I0626 13:29:55.987285  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:29:55.987293  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00711717 (* 1 = 0.00711717 loss)
I0626 13:29:55.987296  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0583185 (* 1 = 0.0583185 loss)
I0626 13:29:55.987300  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00693501 (* 1 = 0.00693501 loss)
I0626 13:29:55.987303  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338681 (* 1 = 0.0338681 loss)
I0626 13:29:55.987308  6673 sgd_solver.cpp:106] Iteration 16460, lr = 0.0002
I0626 13:31:33.911878  6673 solver.cpp:228] Iteration 16480, loss = 0.190192
I0626 13:31:33.911901  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 13:31:33.911908  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0665853 (* 1 = 0.0665853 loss)
I0626 13:31:33.911912  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.162339 (* 1 = 0.162339 loss)
I0626 13:31:33.911916  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149088 (* 1 = 0.00149088 loss)
I0626 13:31:33.911919  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102191 (* 1 = 0.0102191 loss)
I0626 13:31:33.911923  6673 sgd_solver.cpp:106] Iteration 16480, lr = 0.0002
I0626 13:33:11.660004  6673 solver.cpp:228] Iteration 16500, loss = 0.162535
I0626 13:33:11.660027  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 13:33:11.660037  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.109744 (* 1 = 0.109744 loss)
I0626 13:33:11.660043  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.191701 (* 1 = 0.191701 loss)
I0626 13:33:11.660048  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000642962 (* 1 = 0.000642962 loss)
I0626 13:33:11.660053  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159034 (* 1 = 0.0159034 loss)
I0626 13:33:11.660059  6673 sgd_solver.cpp:106] Iteration 16500, lr = 0.0002
I0626 13:34:49.586769  6673 solver.cpp:228] Iteration 16520, loss = 0.148845
I0626 13:34:49.586792  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:34:49.586799  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0238844 (* 1 = 0.0238844 loss)
I0626 13:34:49.586804  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0448086 (* 1 = 0.0448086 loss)
I0626 13:34:49.586807  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00484532 (* 1 = 0.00484532 loss)
I0626 13:34:49.586812  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010408 (* 1 = 0.010408 loss)
I0626 13:34:49.586815  6673 sgd_solver.cpp:106] Iteration 16520, lr = 0.0002
I0626 13:36:27.545701  6673 solver.cpp:228] Iteration 16540, loss = 0.146714
I0626 13:36:27.545724  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:36:27.545732  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.020389 (* 1 = 0.020389 loss)
I0626 13:36:27.545737  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0463853 (* 1 = 0.0463853 loss)
I0626 13:36:27.545740  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121902 (* 1 = 0.00121902 loss)
I0626 13:36:27.545744  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00202104 (* 1 = 0.00202104 loss)
I0626 13:36:27.545749  6673 sgd_solver.cpp:106] Iteration 16540, lr = 0.0002
I0626 13:38:05.452960  6673 solver.cpp:228] Iteration 16560, loss = 0.207644
I0626 13:38:05.452985  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 13:38:05.452994  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.177919 (* 1 = 0.177919 loss)
I0626 13:38:05.453001  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.173931 (* 1 = 0.173931 loss)
I0626 13:38:05.453006  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013508 (* 1 = 0.0013508 loss)
I0626 13:38:05.453012  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172167 (* 1 = 0.0172167 loss)
I0626 13:38:05.453019  6673 sgd_solver.cpp:106] Iteration 16560, lr = 0.0002
I0626 13:39:43.382462  6673 solver.cpp:228] Iteration 16580, loss = 0.186038
I0626 13:39:43.382483  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:39:43.382488  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0164496 (* 1 = 0.0164496 loss)
I0626 13:39:43.382493  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0345988 (* 1 = 0.0345988 loss)
I0626 13:39:43.382495  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0085811 (* 1 = 0.0085811 loss)
I0626 13:39:43.382498  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00772553 (* 1 = 0.00772553 loss)
I0626 13:39:43.382503  6673 sgd_solver.cpp:106] Iteration 16580, lr = 0.0002
speed: 4.921s / iter
I0626 13:41:21.352890  6673 solver.cpp:228] Iteration 16600, loss = 0.252587
I0626 13:41:21.352916  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 13:41:21.352926  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703388 (* 1 = 0.0703388 loss)
I0626 13:41:21.352931  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.165842 (* 1 = 0.165842 loss)
I0626 13:41:21.352937  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00908496 (* 1 = 0.00908496 loss)
I0626 13:41:21.352943  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221803 (* 1 = 0.0221803 loss)
I0626 13:41:21.352949  6673 sgd_solver.cpp:106] Iteration 16600, lr = 0.0002
I0626 13:42:59.127555  6673 solver.cpp:228] Iteration 16620, loss = 0.142762
I0626 13:42:59.127579  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:42:59.127586  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151016 (* 1 = 0.0151016 loss)
I0626 13:42:59.127589  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0334914 (* 1 = 0.0334914 loss)
I0626 13:42:59.127593  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000406256 (* 1 = 0.000406256 loss)
I0626 13:42:59.127596  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00409725 (* 1 = 0.00409725 loss)
I0626 13:42:59.127601  6673 sgd_solver.cpp:106] Iteration 16620, lr = 0.0002
I0626 13:44:37.052215  6673 solver.cpp:228] Iteration 16640, loss = 0.153952
I0626 13:44:37.052238  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 13:44:37.052248  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325233 (* 1 = 0.0325233 loss)
I0626 13:44:37.052253  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.077744 (* 1 = 0.077744 loss)
I0626 13:44:37.052258  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.03157 (* 1 = 0.03157 loss)
I0626 13:44:37.052263  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227316 (* 1 = 0.0227316 loss)
I0626 13:44:37.052269  6673 sgd_solver.cpp:106] Iteration 16640, lr = 0.0002
I0626 13:46:15.007129  6673 solver.cpp:228] Iteration 16660, loss = 0.200271
I0626 13:46:15.007153  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:46:15.007160  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460961 (* 1 = 0.0460961 loss)
I0626 13:46:15.007164  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0523156 (* 1 = 0.0523156 loss)
I0626 13:46:15.007167  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275258 (* 1 = 0.00275258 loss)
I0626 13:46:15.007171  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00977826 (* 1 = 0.00977826 loss)
I0626 13:46:15.007176  6673 sgd_solver.cpp:106] Iteration 16660, lr = 0.0002
I0626 13:47:52.947561  6673 solver.cpp:228] Iteration 16680, loss = 0.172924
I0626 13:47:52.947584  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 13:47:52.947593  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000450587 (* 1 = 0.000450587 loss)
I0626 13:47:52.947600  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0245743 (* 1 = 0.0245743 loss)
I0626 13:47:52.947605  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0094424 (* 1 = 0.0094424 loss)
I0626 13:47:52.947610  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276566 (* 1 = 0.0276566 loss)
I0626 13:47:52.947616  6673 sgd_solver.cpp:106] Iteration 16680, lr = 0.0002
I0626 13:49:30.873258  6673 solver.cpp:228] Iteration 16700, loss = 0.140055
I0626 13:49:30.873281  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 13:49:30.873289  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0454097 (* 1 = 0.0454097 loss)
I0626 13:49:30.873296  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.11461 (* 1 = 0.11461 loss)
I0626 13:49:30.873302  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132542 (* 1 = 0.00132542 loss)
I0626 13:49:30.873307  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191852 (* 1 = 0.0191852 loss)
I0626 13:49:30.873313  6673 sgd_solver.cpp:106] Iteration 16700, lr = 0.0002
I0626 13:51:08.827255  6673 solver.cpp:228] Iteration 16720, loss = 0.335933
I0626 13:51:08.827276  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:51:08.827283  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265428 (* 1 = 0.0265428 loss)
I0626 13:51:08.827287  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0529001 (* 1 = 0.0529001 loss)
I0626 13:51:08.827291  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132872 (* 1 = 0.00132872 loss)
I0626 13:51:08.827294  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00744335 (* 1 = 0.00744335 loss)
I0626 13:51:08.827298  6673 sgd_solver.cpp:106] Iteration 16720, lr = 0.0002
I0626 13:52:46.777402  6673 solver.cpp:228] Iteration 16740, loss = 0.16796
I0626 13:52:46.777426  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 13:52:46.777432  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0525956 (* 1 = 0.0525956 loss)
I0626 13:52:46.777436  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.08404 (* 1 = 0.08404 loss)
I0626 13:52:46.777441  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00561939 (* 1 = 0.00561939 loss)
I0626 13:52:46.777443  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00245656 (* 1 = 0.00245656 loss)
I0626 13:52:46.777448  6673 sgd_solver.cpp:106] Iteration 16740, lr = 0.0002
I0626 13:54:24.703645  6673 solver.cpp:228] Iteration 16760, loss = 0.425763
I0626 13:54:24.703668  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0626 13:54:24.703675  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.435154 (* 1 = 0.435154 loss)
I0626 13:54:24.703680  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.505 (* 1 = 0.505 loss)
I0626 13:54:24.703682  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00622266 (* 1 = 0.00622266 loss)
I0626 13:54:24.703686  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0713262 (* 1 = 0.0713262 loss)
I0626 13:54:24.703691  6673 sgd_solver.cpp:106] Iteration 16760, lr = 0.0002
I0626 13:56:02.623095  6673 solver.cpp:228] Iteration 16780, loss = 0.232955
I0626 13:56:02.623117  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 13:56:02.623124  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309305 (* 1 = 0.0309305 loss)
I0626 13:56:02.623128  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100911 (* 1 = 0.100911 loss)
I0626 13:56:02.623132  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000540974 (* 1 = 0.000540974 loss)
I0626 13:56:02.623136  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109924 (* 1 = 0.0109924 loss)
I0626 13:56:02.623140  6673 sgd_solver.cpp:106] Iteration 16780, lr = 0.0002
speed: 4.921s / iter
I0626 13:57:40.531930  6673 solver.cpp:228] Iteration 16800, loss = 0.27072
I0626 13:57:40.531953  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 13:57:40.531960  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.256512 (* 1 = 0.256512 loss)
I0626 13:57:40.531963  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.272226 (* 1 = 0.272226 loss)
I0626 13:57:40.531967  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028635 (* 1 = 0.0028635 loss)
I0626 13:57:40.531970  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0357352 (* 1 = 0.0357352 loss)
I0626 13:57:40.531975  6673 sgd_solver.cpp:106] Iteration 16800, lr = 0.0002
I0626 13:59:18.454146  6673 solver.cpp:228] Iteration 16820, loss = 0.0811498
I0626 13:59:18.454169  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 13:59:18.454179  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0252208 (* 1 = 0.0252208 loss)
I0626 13:59:18.454185  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0283582 (* 1 = 0.0283582 loss)
I0626 13:59:18.454190  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000364152 (* 1 = 0.000364152 loss)
I0626 13:59:18.454195  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00424423 (* 1 = 0.00424423 loss)
I0626 13:59:18.454201  6673 sgd_solver.cpp:106] Iteration 16820, lr = 0.0002
I0626 14:00:56.390888  6673 solver.cpp:228] Iteration 16840, loss = 0.196868
I0626 14:00:56.390914  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 14:00:56.390921  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.117363 (* 1 = 0.117363 loss)
I0626 14:00:56.390925  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.297474 (* 1 = 0.297474 loss)
I0626 14:00:56.390929  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154449 (* 1 = 0.0154449 loss)
I0626 14:00:56.390933  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419013 (* 1 = 0.0419013 loss)
I0626 14:00:56.390936  6673 sgd_solver.cpp:106] Iteration 16840, lr = 0.0002
I0626 14:02:34.317981  6673 solver.cpp:228] Iteration 16860, loss = 0.321693
I0626 14:02:34.318003  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0626 14:02:34.318011  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.215185 (* 1 = 0.215185 loss)
I0626 14:02:34.318013  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.342599 (* 1 = 0.342599 loss)
I0626 14:02:34.318017  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136896 (* 1 = 0.00136896 loss)
I0626 14:02:34.318022  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293641 (* 1 = 0.0293641 loss)
I0626 14:02:34.318027  6673 sgd_solver.cpp:106] Iteration 16860, lr = 0.0002
I0626 14:04:12.245409  6673 solver.cpp:228] Iteration 16880, loss = 0.108837
I0626 14:04:12.245431  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 14:04:12.245440  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198067 (* 1 = 0.0198067 loss)
I0626 14:04:12.245443  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0894212 (* 1 = 0.0894212 loss)
I0626 14:04:12.245447  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119823 (* 1 = 0.00119823 loss)
I0626 14:04:12.245451  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00377934 (* 1 = 0.00377934 loss)
I0626 14:04:12.245457  6673 sgd_solver.cpp:106] Iteration 16880, lr = 0.0002
I0626 14:05:50.144779  6673 solver.cpp:228] Iteration 16900, loss = 0.126459
I0626 14:05:50.144803  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:05:50.144809  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113466 (* 1 = 0.0113466 loss)
I0626 14:05:50.144814  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0680654 (* 1 = 0.0680654 loss)
I0626 14:05:50.144816  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173524 (* 1 = 0.0173524 loss)
I0626 14:05:50.144819  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278542 (* 1 = 0.0278542 loss)
I0626 14:05:50.144824  6673 sgd_solver.cpp:106] Iteration 16900, lr = 0.0002
I0626 14:07:28.069336  6673 solver.cpp:228] Iteration 16920, loss = 0.236679
I0626 14:07:28.069358  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:07:28.069365  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274545 (* 1 = 0.0274545 loss)
I0626 14:07:28.069370  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0597583 (* 1 = 0.0597583 loss)
I0626 14:07:28.069373  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.54087e-05 (* 1 = 8.54087e-05 loss)
I0626 14:07:28.069377  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00316417 (* 1 = 0.00316417 loss)
I0626 14:07:28.069381  6673 sgd_solver.cpp:106] Iteration 16920, lr = 0.0002
I0626 14:09:05.991232  6673 solver.cpp:228] Iteration 16940, loss = 0.128255
I0626 14:09:05.991257  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 14:09:05.991266  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261948 (* 1 = 0.0261948 loss)
I0626 14:09:05.991269  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0705358 (* 1 = 0.0705358 loss)
I0626 14:09:05.991273  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00219181 (* 1 = 0.00219181 loss)
I0626 14:09:05.991277  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104714 (* 1 = 0.0104714 loss)
I0626 14:09:05.991282  6673 sgd_solver.cpp:106] Iteration 16940, lr = 0.0002
I0626 14:10:43.907768  6673 solver.cpp:228] Iteration 16960, loss = 0.224562
I0626 14:10:43.907791  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 14:10:43.907799  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0775756 (* 1 = 0.0775756 loss)
I0626 14:10:43.907802  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130473 (* 1 = 0.130473 loss)
I0626 14:10:43.907806  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122647 (* 1 = 0.00122647 loss)
I0626 14:10:43.907809  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03203 (* 1 = 0.03203 loss)
I0626 14:10:43.907814  6673 sgd_solver.cpp:106] Iteration 16960, lr = 0.0002
I0626 14:12:21.812604  6673 solver.cpp:228] Iteration 16980, loss = 0.257975
I0626 14:12:21.812628  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:12:21.812634  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386618 (* 1 = 0.0386618 loss)
I0626 14:12:21.812638  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0627541 (* 1 = 0.0627541 loss)
I0626 14:12:21.812642  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266929 (* 1 = 0.00266929 loss)
I0626 14:12:21.812645  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172725 (* 1 = 0.0172725 loss)
I0626 14:12:21.812650  6673 sgd_solver.cpp:106] Iteration 16980, lr = 0.0002
speed: 4.920s / iter
I0626 14:13:59.739652  6673 solver.cpp:228] Iteration 17000, loss = 0.182513
I0626 14:13:59.739675  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 14:13:59.739683  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.036043 (* 1 = 0.036043 loss)
I0626 14:13:59.739687  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0810215 (* 1 = 0.0810215 loss)
I0626 14:13:59.739691  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106159 (* 1 = 0.00106159 loss)
I0626 14:13:59.739696  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132481 (* 1 = 0.0132481 loss)
I0626 14:13:59.739701  6673 sgd_solver.cpp:106] Iteration 17000, lr = 0.0002
I0626 14:15:37.675942  6673 solver.cpp:228] Iteration 17020, loss = 0.19545
I0626 14:15:37.675966  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 14:15:37.675974  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0478011 (* 1 = 0.0478011 loss)
I0626 14:15:37.675978  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0906064 (* 1 = 0.0906064 loss)
I0626 14:15:37.675982  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000332467 (* 1 = 0.000332467 loss)
I0626 14:15:37.675987  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163279 (* 1 = 0.0163279 loss)
I0626 14:15:37.675992  6673 sgd_solver.cpp:106] Iteration 17020, lr = 0.0002
I0626 14:17:15.616392  6673 solver.cpp:228] Iteration 17040, loss = 0.263714
I0626 14:17:15.616415  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:17:15.616421  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467668 (* 1 = 0.0467668 loss)
I0626 14:17:15.616425  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0738586 (* 1 = 0.0738586 loss)
I0626 14:17:15.616428  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0021421 (* 1 = 0.0021421 loss)
I0626 14:17:15.616432  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131014 (* 1 = 0.0131014 loss)
I0626 14:17:15.616436  6673 sgd_solver.cpp:106] Iteration 17040, lr = 0.0002
I0626 14:18:53.526738  6673 solver.cpp:228] Iteration 17060, loss = 0.141377
I0626 14:18:53.526762  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:18:53.526770  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.041837 (* 1 = 0.041837 loss)
I0626 14:18:53.526774  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.121631 (* 1 = 0.121631 loss)
I0626 14:18:53.526777  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266615 (* 1 = 0.0266615 loss)
I0626 14:18:53.526782  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.086327 (* 1 = 0.086327 loss)
I0626 14:18:53.526787  6673 sgd_solver.cpp:106] Iteration 17060, lr = 0.0002
I0626 14:20:31.388849  6673 solver.cpp:228] Iteration 17080, loss = 0.239868
I0626 14:20:31.388876  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:20:31.388885  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00812071 (* 1 = 0.00812071 loss)
I0626 14:20:31.388890  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0461078 (* 1 = 0.0461078 loss)
I0626 14:20:31.388895  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000409979 (* 1 = 0.000409979 loss)
I0626 14:20:31.388900  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00632437 (* 1 = 0.00632437 loss)
I0626 14:20:31.388906  6673 sgd_solver.cpp:106] Iteration 17080, lr = 0.0002
I0626 14:22:09.326676  6673 solver.cpp:228] Iteration 17100, loss = 0.128113
I0626 14:22:09.326701  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:22:09.326709  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0214022 (* 1 = 0.0214022 loss)
I0626 14:22:09.326712  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0484353 (* 1 = 0.0484353 loss)
I0626 14:22:09.326716  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000667643 (* 1 = 0.000667643 loss)
I0626 14:22:09.326719  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00683861 (* 1 = 0.00683861 loss)
I0626 14:22:09.326725  6673 sgd_solver.cpp:106] Iteration 17100, lr = 0.0002
I0626 14:23:47.254073  6673 solver.cpp:228] Iteration 17120, loss = 0.156135
I0626 14:23:47.254099  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:23:47.254109  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0965028 (* 1 = 0.0965028 loss)
I0626 14:23:47.254117  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0465278 (* 1 = 0.0465278 loss)
I0626 14:23:47.254122  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00310674 (* 1 = 0.00310674 loss)
I0626 14:23:47.254129  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00810401 (* 1 = 0.00810401 loss)
I0626 14:23:47.254135  6673 sgd_solver.cpp:106] Iteration 17120, lr = 0.0002
I0626 14:25:25.151677  6673 solver.cpp:228] Iteration 17140, loss = 0.206451
I0626 14:25:25.151701  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:25:25.151710  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00960153 (* 1 = 0.00960153 loss)
I0626 14:25:25.151715  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0628 (* 1 = 0.0628 loss)
I0626 14:25:25.151718  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00025199 (* 1 = 0.00025199 loss)
I0626 14:25:25.151721  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108472 (* 1 = 0.0108472 loss)
I0626 14:25:25.151726  6673 sgd_solver.cpp:106] Iteration 17140, lr = 0.0002
I0626 14:27:03.073237  6673 solver.cpp:228] Iteration 17160, loss = 0.210864
I0626 14:27:03.073261  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:27:03.073268  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0357892 (* 1 = 0.0357892 loss)
I0626 14:27:03.073272  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0275468 (* 1 = 0.0275468 loss)
I0626 14:27:03.073276  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125353 (* 1 = 0.00125353 loss)
I0626 14:27:03.073279  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00314012 (* 1 = 0.00314012 loss)
I0626 14:27:03.073283  6673 sgd_solver.cpp:106] Iteration 17160, lr = 0.0002
I0626 14:28:40.953605  6673 solver.cpp:228] Iteration 17180, loss = 0.0755792
I0626 14:28:40.953629  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:28:40.953639  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319339 (* 1 = 0.0319339 loss)
I0626 14:28:40.953646  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0539495 (* 1 = 0.0539495 loss)
I0626 14:28:40.953652  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000146187 (* 1 = 0.000146187 loss)
I0626 14:28:40.953658  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00758835 (* 1 = 0.00758835 loss)
I0626 14:28:40.953665  6673 sgd_solver.cpp:106] Iteration 17180, lr = 0.0002
speed: 4.920s / iter
I0626 14:30:18.909669  6673 solver.cpp:228] Iteration 17200, loss = 0.201463
I0626 14:30:18.909695  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 14:30:18.909703  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0283572 (* 1 = 0.0283572 loss)
I0626 14:30:18.909706  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0150753 (* 1 = 0.0150753 loss)
I0626 14:30:18.909710  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000717981 (* 1 = 0.000717981 loss)
I0626 14:30:18.909714  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117306 (* 1 = 0.0117306 loss)
I0626 14:30:18.909719  6673 sgd_solver.cpp:106] Iteration 17200, lr = 0.0002
I0626 14:31:56.811460  6673 solver.cpp:228] Iteration 17220, loss = 0.181066
I0626 14:31:56.811483  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 14:31:56.811491  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325023 (* 1 = 0.0325023 loss)
I0626 14:31:56.811494  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0961327 (* 1 = 0.0961327 loss)
I0626 14:31:56.811497  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000675209 (* 1 = 0.000675209 loss)
I0626 14:31:56.811501  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107623 (* 1 = 0.0107623 loss)
I0626 14:31:56.811504  6673 sgd_solver.cpp:106] Iteration 17220, lr = 0.0002
I0626 14:33:34.724364  6673 solver.cpp:228] Iteration 17240, loss = 0.18341
I0626 14:33:34.724390  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:33:34.724398  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0506481 (* 1 = 0.0506481 loss)
I0626 14:33:34.724404  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0680659 (* 1 = 0.0680659 loss)
I0626 14:33:34.724409  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000716827 (* 1 = 0.000716827 loss)
I0626 14:33:34.724414  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00639595 (* 1 = 0.00639595 loss)
I0626 14:33:34.724419  6673 sgd_solver.cpp:106] Iteration 17240, lr = 0.0002
I0626 14:35:12.648141  6673 solver.cpp:228] Iteration 17260, loss = 0.314386
I0626 14:35:12.648162  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 14:35:12.648169  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0196055 (* 1 = 0.0196055 loss)
I0626 14:35:12.648172  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0802329 (* 1 = 0.0802329 loss)
I0626 14:35:12.648175  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00154506 (* 1 = 0.00154506 loss)
I0626 14:35:12.648180  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229292 (* 1 = 0.0229292 loss)
I0626 14:35:12.648183  6673 sgd_solver.cpp:106] Iteration 17260, lr = 0.0002
I0626 14:36:50.559783  6673 solver.cpp:228] Iteration 17280, loss = 0.164789
I0626 14:36:50.559806  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 14:36:50.559814  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807678 (* 1 = 0.0807678 loss)
I0626 14:36:50.559818  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0892214 (* 1 = 0.0892214 loss)
I0626 14:36:50.559823  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000828667 (* 1 = 0.000828667 loss)
I0626 14:36:50.559826  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00720566 (* 1 = 0.00720566 loss)
I0626 14:36:50.559830  6673 sgd_solver.cpp:106] Iteration 17280, lr = 0.0002
I0626 14:38:28.424263  6673 solver.cpp:228] Iteration 17300, loss = 0.145758
I0626 14:38:28.424288  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:38:28.424295  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486602 (* 1 = 0.0486602 loss)
I0626 14:38:28.424300  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0992105 (* 1 = 0.0992105 loss)
I0626 14:38:28.424304  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00052022 (* 1 = 0.00052022 loss)
I0626 14:38:28.424307  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159729 (* 1 = 0.0159729 loss)
I0626 14:38:28.424312  6673 sgd_solver.cpp:106] Iteration 17300, lr = 0.0002
I0626 14:40:06.363183  6673 solver.cpp:228] Iteration 17320, loss = 0.358922
I0626 14:40:06.363205  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:40:06.363214  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199168 (* 1 = 0.0199168 loss)
I0626 14:40:06.363219  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0852441 (* 1 = 0.0852441 loss)
I0626 14:40:06.363222  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253196 (* 1 = 0.00253196 loss)
I0626 14:40:06.363225  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104967 (* 1 = 0.0104967 loss)
I0626 14:40:06.363230  6673 sgd_solver.cpp:106] Iteration 17320, lr = 0.0002
I0626 14:41:44.258074  6673 solver.cpp:228] Iteration 17340, loss = 0.150402
I0626 14:41:44.258096  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 14:41:44.258103  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108534 (* 1 = 0.0108534 loss)
I0626 14:41:44.258108  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0706697 (* 1 = 0.0706697 loss)
I0626 14:41:44.258114  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0300686 (* 1 = 0.0300686 loss)
I0626 14:41:44.258118  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167157 (* 1 = 0.0167157 loss)
I0626 14:41:44.258122  6673 sgd_solver.cpp:106] Iteration 17340, lr = 0.0002
I0626 14:43:22.214941  6673 solver.cpp:228] Iteration 17360, loss = 0.127661
I0626 14:43:22.214964  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 14:43:22.214972  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204439 (* 1 = 0.0204439 loss)
I0626 14:43:22.214977  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0271063 (* 1 = 0.0271063 loss)
I0626 14:43:22.214980  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.84617e-05 (* 1 = 3.84617e-05 loss)
I0626 14:43:22.214984  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00924124 (* 1 = 0.00924124 loss)
I0626 14:43:22.214990  6673 sgd_solver.cpp:106] Iteration 17360, lr = 0.0002
I0626 14:45:00.147492  6673 solver.cpp:228] Iteration 17380, loss = 0.178166
I0626 14:45:00.147516  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:45:00.147523  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0570025 (* 1 = 0.0570025 loss)
I0626 14:45:00.147528  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0761181 (* 1 = 0.0761181 loss)
I0626 14:45:00.147531  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027928 (* 1 = 0.027928 loss)
I0626 14:45:00.147536  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162817 (* 1 = 0.0162817 loss)
I0626 14:45:00.147541  6673 sgd_solver.cpp:106] Iteration 17380, lr = 0.0002
speed: 4.920s / iter
I0626 14:46:38.045038  6673 solver.cpp:228] Iteration 17400, loss = 0.222641
I0626 14:46:38.045066  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 14:46:38.045073  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0706736 (* 1 = 0.0706736 loss)
I0626 14:46:38.045078  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.200542 (* 1 = 0.200542 loss)
I0626 14:46:38.045081  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016619 (* 1 = 0.016619 loss)
I0626 14:46:38.045084  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109171 (* 1 = 0.109171 loss)
I0626 14:46:38.045089  6673 sgd_solver.cpp:106] Iteration 17400, lr = 0.0002
I0626 14:48:15.953136  6673 solver.cpp:228] Iteration 17420, loss = 0.145573
I0626 14:48:15.953183  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 14:48:15.953196  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0660966 (* 1 = 0.0660966 loss)
I0626 14:48:15.953202  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122312 (* 1 = 0.122312 loss)
I0626 14:48:15.953208  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000873066 (* 1 = 0.000873066 loss)
I0626 14:48:15.953214  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015806 (* 1 = 0.015806 loss)
I0626 14:48:15.953222  6673 sgd_solver.cpp:106] Iteration 17420, lr = 0.0002
I0626 14:49:53.872229  6673 solver.cpp:228] Iteration 17440, loss = 0.103921
I0626 14:49:53.872261  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 14:49:53.872268  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0631737 (* 1 = 0.0631737 loss)
I0626 14:49:53.872273  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.116752 (* 1 = 0.116752 loss)
I0626 14:49:53.872277  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00380877 (* 1 = 0.00380877 loss)
I0626 14:49:53.872280  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00702376 (* 1 = 0.00702376 loss)
I0626 14:49:53.872287  6673 sgd_solver.cpp:106] Iteration 17440, lr = 0.0002
I0626 14:51:31.794204  6673 solver.cpp:228] Iteration 17460, loss = 0.278181
I0626 14:51:31.794229  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:51:31.794236  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0143974 (* 1 = 0.0143974 loss)
I0626 14:51:31.794241  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0436303 (* 1 = 0.0436303 loss)
I0626 14:51:31.794245  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139285 (* 1 = 0.00139285 loss)
I0626 14:51:31.794248  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0046368 (* 1 = 0.0046368 loss)
I0626 14:51:31.794255  6673 sgd_solver.cpp:106] Iteration 17460, lr = 0.0002
I0626 14:53:09.700618  6673 solver.cpp:228] Iteration 17480, loss = 0.233502
I0626 14:53:09.700642  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:53:09.700649  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0112014 (* 1 = 0.0112014 loss)
I0626 14:53:09.700652  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0414152 (* 1 = 0.0414152 loss)
I0626 14:53:09.700655  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000419143 (* 1 = 0.000419143 loss)
I0626 14:53:09.700659  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0053947 (* 1 = 0.0053947 loss)
I0626 14:53:09.700664  6673 sgd_solver.cpp:106] Iteration 17480, lr = 0.0002
I0626 14:54:47.626261  6673 solver.cpp:228] Iteration 17500, loss = 0.15185
I0626 14:54:47.626286  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 14:54:47.626292  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159152 (* 1 = 0.0159152 loss)
I0626 14:54:47.626296  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0503358 (* 1 = 0.0503358 loss)
I0626 14:54:47.626299  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138484 (* 1 = 0.0138484 loss)
I0626 14:54:47.626302  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0583199 (* 1 = 0.0583199 loss)
I0626 14:54:47.626307  6673 sgd_solver.cpp:106] Iteration 17500, lr = 0.0002
I0626 14:56:25.542090  6673 solver.cpp:228] Iteration 17520, loss = 0.241326
I0626 14:56:25.542115  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 14:56:25.542124  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161654 (* 1 = 0.0161654 loss)
I0626 14:56:25.542127  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0471522 (* 1 = 0.0471522 loss)
I0626 14:56:25.542131  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00555895 (* 1 = 0.00555895 loss)
I0626 14:56:25.542135  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362604 (* 1 = 0.0362604 loss)
I0626 14:56:25.542140  6673 sgd_solver.cpp:106] Iteration 17520, lr = 0.0002
I0626 14:58:03.511116  6673 solver.cpp:228] Iteration 17540, loss = 0.126196
I0626 14:58:03.511138  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 14:58:03.511145  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0631447 (* 1 = 0.0631447 loss)
I0626 14:58:03.511149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.125102 (* 1 = 0.125102 loss)
I0626 14:58:03.511152  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00714158 (* 1 = 0.00714158 loss)
I0626 14:58:03.511155  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238041 (* 1 = 0.0238041 loss)
I0626 14:58:03.511160  6673 sgd_solver.cpp:106] Iteration 17540, lr = 0.0002
I0626 14:59:41.510186  6673 solver.cpp:228] Iteration 17560, loss = 0.18008
I0626 14:59:41.510210  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 14:59:41.510218  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0210641 (* 1 = 0.0210641 loss)
I0626 14:59:41.510222  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0187774 (* 1 = 0.0187774 loss)
I0626 14:59:41.510226  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000897046 (* 1 = 0.000897046 loss)
I0626 14:59:41.510231  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127462 (* 1 = 0.0127462 loss)
I0626 14:59:41.510236  6673 sgd_solver.cpp:106] Iteration 17560, lr = 0.0002
I0626 15:01:19.448535  6673 solver.cpp:228] Iteration 17580, loss = 0.161947
I0626 15:01:19.448565  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:01:19.448572  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566203 (* 1 = 0.0566203 loss)
I0626 15:01:19.448576  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0980007 (* 1 = 0.0980007 loss)
I0626 15:01:19.448581  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191525 (* 1 = 0.00191525 loss)
I0626 15:01:19.448585  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198557 (* 1 = 0.0198557 loss)
I0626 15:01:19.448590  6673 sgd_solver.cpp:106] Iteration 17580, lr = 0.0002
speed: 4.920s / iter
I0626 15:02:57.405441  6673 solver.cpp:228] Iteration 17600, loss = 0.229322
I0626 15:02:57.405468  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:02:57.405478  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.078517 (* 1 = 0.078517 loss)
I0626 15:02:57.405485  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0975596 (* 1 = 0.0975596 loss)
I0626 15:02:57.405490  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293685 (* 1 = 0.0293685 loss)
I0626 15:02:57.405498  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106459 (* 1 = 0.106459 loss)
I0626 15:02:57.405503  6673 sgd_solver.cpp:106] Iteration 17600, lr = 0.0002
I0626 15:04:35.345548  6673 solver.cpp:228] Iteration 17620, loss = 0.207408
I0626 15:04:35.345576  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:04:35.345583  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440133 (* 1 = 0.0440133 loss)
I0626 15:04:35.345587  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0399106 (* 1 = 0.0399106 loss)
I0626 15:04:35.345590  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000690249 (* 1 = 0.000690249 loss)
I0626 15:04:35.345594  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132585 (* 1 = 0.0132585 loss)
I0626 15:04:35.345599  6673 sgd_solver.cpp:106] Iteration 17620, lr = 0.0002
I0626 15:06:13.331990  6673 solver.cpp:228] Iteration 17640, loss = 0.148639
I0626 15:06:13.332017  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 15:06:13.332026  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0670993 (* 1 = 0.0670993 loss)
I0626 15:06:13.332029  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161568 (* 1 = 0.161568 loss)
I0626 15:06:13.332033  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00609827 (* 1 = 0.00609827 loss)
I0626 15:06:13.332037  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0480531 (* 1 = 0.0480531 loss)
I0626 15:06:13.332042  6673 sgd_solver.cpp:106] Iteration 17640, lr = 0.0002
I0626 15:07:51.297228  6673 solver.cpp:228] Iteration 17660, loss = 0.185916
I0626 15:07:51.297260  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:07:51.297271  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235088 (* 1 = 0.0235088 loss)
I0626 15:07:51.297278  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.10312 (* 1 = 0.10312 loss)
I0626 15:07:51.297284  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000443008 (* 1 = 0.000443008 loss)
I0626 15:07:51.297291  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235113 (* 1 = 0.0235113 loss)
I0626 15:07:51.297298  6673 sgd_solver.cpp:106] Iteration 17660, lr = 0.0002
I0626 15:09:29.266144  6673 solver.cpp:228] Iteration 17680, loss = 0.159924
I0626 15:09:29.266168  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 15:09:29.266175  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.107128 (* 1 = 0.107128 loss)
I0626 15:09:29.266180  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.157345 (* 1 = 0.157345 loss)
I0626 15:09:29.266182  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0418394 (* 1 = 0.0418394 loss)
I0626 15:09:29.266186  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106573 (* 1 = 0.106573 loss)
I0626 15:09:29.266191  6673 sgd_solver.cpp:106] Iteration 17680, lr = 0.0002
I0626 15:11:07.188561  6673 solver.cpp:228] Iteration 17700, loss = 0.121291
I0626 15:11:07.188583  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:11:07.188591  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0109465 (* 1 = 0.0109465 loss)
I0626 15:11:07.188593  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0226339 (* 1 = 0.0226339 loss)
I0626 15:11:07.188597  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.35781e-05 (* 1 = 7.35781e-05 loss)
I0626 15:11:07.188601  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00094138 (* 1 = 0.00094138 loss)
I0626 15:11:07.188604  6673 sgd_solver.cpp:106] Iteration 17700, lr = 0.0002
I0626 15:12:45.167652  6673 solver.cpp:228] Iteration 17720, loss = 0.252699
I0626 15:12:45.167677  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:12:45.167685  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132669 (* 1 = 0.0132669 loss)
I0626 15:12:45.167690  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0473102 (* 1 = 0.0473102 loss)
I0626 15:12:45.167695  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.39592e-05 (* 1 = 6.39592e-05 loss)
I0626 15:12:45.167697  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00355166 (* 1 = 0.00355166 loss)
I0626 15:12:45.167702  6673 sgd_solver.cpp:106] Iteration 17720, lr = 0.0002
I0626 15:14:23.162659  6673 solver.cpp:228] Iteration 17740, loss = 0.165368
I0626 15:14:23.162683  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:14:23.162689  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0871187 (* 1 = 0.0871187 loss)
I0626 15:14:23.162693  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100531 (* 1 = 0.100531 loss)
I0626 15:14:23.162698  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129244 (* 1 = 0.0129244 loss)
I0626 15:14:23.162700  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221088 (* 1 = 0.0221088 loss)
I0626 15:14:23.162704  6673 sgd_solver.cpp:106] Iteration 17740, lr = 0.0002
I0626 15:16:01.153389  6673 solver.cpp:228] Iteration 17760, loss = 0.289681
I0626 15:16:01.153415  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:16:01.153422  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0184906 (* 1 = 0.0184906 loss)
I0626 15:16:01.153426  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0475796 (* 1 = 0.0475796 loss)
I0626 15:16:01.153430  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000249997 (* 1 = 0.000249997 loss)
I0626 15:16:01.153434  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00770439 (* 1 = 0.00770439 loss)
I0626 15:16:01.153439  6673 sgd_solver.cpp:106] Iteration 17760, lr = 0.0002
I0626 15:17:39.170454  6673 solver.cpp:228] Iteration 17780, loss = 0.182308
I0626 15:17:39.170483  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 15:17:39.170491  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0638148 (* 1 = 0.0638148 loss)
I0626 15:17:39.170496  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.156244 (* 1 = 0.156244 loss)
I0626 15:17:39.170500  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00595049 (* 1 = 0.00595049 loss)
I0626 15:17:39.170503  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0477514 (* 1 = 0.0477514 loss)
I0626 15:17:39.170509  6673 sgd_solver.cpp:106] Iteration 17780, lr = 0.0002
speed: 4.919s / iter
I0626 15:19:17.133589  6673 solver.cpp:228] Iteration 17800, loss = 0.174995
I0626 15:19:17.133613  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:19:17.133621  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0398438 (* 1 = 0.0398438 loss)
I0626 15:19:17.133625  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.106939 (* 1 = 0.106939 loss)
I0626 15:19:17.133630  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169309 (* 1 = 0.00169309 loss)
I0626 15:19:17.133632  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246155 (* 1 = 0.0246155 loss)
I0626 15:19:17.133637  6673 sgd_solver.cpp:106] Iteration 17800, lr = 0.0002
I0626 15:20:55.110636  6673 solver.cpp:228] Iteration 17820, loss = 0.193614
I0626 15:20:55.110664  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 15:20:55.110671  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0219033 (* 1 = 0.0219033 loss)
I0626 15:20:55.110677  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0360248 (* 1 = 0.0360248 loss)
I0626 15:20:55.110680  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00010499 (* 1 = 0.00010499 loss)
I0626 15:20:55.110684  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00524158 (* 1 = 0.00524158 loss)
I0626 15:20:55.110689  6673 sgd_solver.cpp:106] Iteration 17820, lr = 0.0002
I0626 15:22:33.101546  6673 solver.cpp:228] Iteration 17840, loss = 0.197225
I0626 15:22:33.101568  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0626 15:22:33.101575  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.359287 (* 1 = 0.359287 loss)
I0626 15:22:33.101578  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.367067 (* 1 = 0.367067 loss)
I0626 15:22:33.101583  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0249279 (* 1 = 0.0249279 loss)
I0626 15:22:33.101585  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117863 (* 1 = 0.117863 loss)
I0626 15:22:33.101590  6673 sgd_solver.cpp:106] Iteration 17840, lr = 0.0002
I0626 15:24:11.079171  6673 solver.cpp:228] Iteration 17860, loss = 0.209865
I0626 15:24:11.079196  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 15:24:11.079203  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.102345 (* 1 = 0.102345 loss)
I0626 15:24:11.079207  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.284636 (* 1 = 0.284636 loss)
I0626 15:24:11.079211  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000649073 (* 1 = 0.000649073 loss)
I0626 15:24:11.079216  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030615 (* 1 = 0.030615 loss)
I0626 15:24:11.079221  6673 sgd_solver.cpp:106] Iteration 17860, lr = 0.0002
I0626 15:25:49.036667  6673 solver.cpp:228] Iteration 17880, loss = 0.108349
I0626 15:25:49.036692  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 15:25:49.036700  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0239812 (* 1 = 0.0239812 loss)
I0626 15:25:49.036703  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0191793 (* 1 = 0.0191793 loss)
I0626 15:25:49.036707  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000316317 (* 1 = 0.000316317 loss)
I0626 15:25:49.036710  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00475353 (* 1 = 0.00475353 loss)
I0626 15:25:49.036715  6673 sgd_solver.cpp:106] Iteration 17880, lr = 0.0002
I0626 15:27:27.076444  6673 solver.cpp:228] Iteration 17900, loss = 0.20223
I0626 15:27:27.076472  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 15:27:27.076479  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.12654 (* 1 = 0.12654 loss)
I0626 15:27:27.076483  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.243263 (* 1 = 0.243263 loss)
I0626 15:27:27.076488  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0430698 (* 1 = 0.0430698 loss)
I0626 15:27:27.076491  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.270978 (* 1 = 0.270978 loss)
I0626 15:27:27.076498  6673 sgd_solver.cpp:106] Iteration 17900, lr = 0.0002
I0626 15:29:05.047500  6673 solver.cpp:228] Iteration 17920, loss = 0.211974
I0626 15:29:05.047525  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:29:05.047535  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0348165 (* 1 = 0.0348165 loss)
I0626 15:29:05.047541  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0835468 (* 1 = 0.0835468 loss)
I0626 15:29:05.047547  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000143363 (* 1 = 0.000143363 loss)
I0626 15:29:05.047554  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00374462 (* 1 = 0.00374462 loss)
I0626 15:29:05.047561  6673 sgd_solver.cpp:106] Iteration 17920, lr = 0.0002
I0626 15:30:43.297621  6673 solver.cpp:228] Iteration 17940, loss = 0.152762
I0626 15:30:43.297655  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:30:43.297665  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0636058 (* 1 = 0.0636058 loss)
I0626 15:30:43.297672  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0918602 (* 1 = 0.0918602 loss)
I0626 15:30:43.297677  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000511063 (* 1 = 0.000511063 loss)
I0626 15:30:43.297682  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00867713 (* 1 = 0.00867713 loss)
I0626 15:30:43.297688  6673 sgd_solver.cpp:106] Iteration 17940, lr = 0.0002
I0626 15:32:21.580021  6673 solver.cpp:228] Iteration 17960, loss = 0.258106
I0626 15:32:21.580051  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0626 15:32:21.580060  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.324853 (* 1 = 0.324853 loss)
I0626 15:32:21.580063  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.521829 (* 1 = 0.521829 loss)
I0626 15:32:21.580067  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261069 (* 1 = 0.0261069 loss)
I0626 15:32:21.580070  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.123033 (* 1 = 0.123033 loss)
I0626 15:32:21.580075  6673 sgd_solver.cpp:106] Iteration 17960, lr = 0.0002
I0626 15:33:59.888890  6673 solver.cpp:228] Iteration 17980, loss = 0.183333
I0626 15:33:59.888917  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 15:33:59.888926  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298618 (* 1 = 0.0298618 loss)
I0626 15:33:59.888929  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0627212 (* 1 = 0.0627212 loss)
I0626 15:33:59.888933  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0288245 (* 1 = 0.0288245 loss)
I0626 15:33:59.888937  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230719 (* 1 = 0.0230719 loss)
I0626 15:33:59.888943  6673 sgd_solver.cpp:106] Iteration 17980, lr = 0.0002
speed: 4.919s / iter
I0626 15:35:38.381867  6673 solver.cpp:228] Iteration 18000, loss = 0.153026
I0626 15:35:38.381899  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 15:35:38.381911  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0785169 (* 1 = 0.0785169 loss)
I0626 15:35:38.381916  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.153524 (* 1 = 0.153524 loss)
I0626 15:35:38.381922  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134578 (* 1 = 0.0134578 loss)
I0626 15:35:38.381928  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190448 (* 1 = 0.0190448 loss)
I0626 15:35:38.381937  6673 sgd_solver.cpp:106] Iteration 18000, lr = 0.0002
I0626 15:37:16.891125  6673 solver.cpp:228] Iteration 18020, loss = 0.133757
I0626 15:37:16.891150  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 15:37:16.891158  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178141 (* 1 = 0.0178141 loss)
I0626 15:37:16.891162  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0941897 (* 1 = 0.0941897 loss)
I0626 15:37:16.891166  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00884474 (* 1 = 0.00884474 loss)
I0626 15:37:16.891170  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125756 (* 1 = 0.0125756 loss)
I0626 15:37:16.891175  6673 sgd_solver.cpp:106] Iteration 18020, lr = 0.0002
I0626 15:38:55.164868  6673 solver.cpp:228] Iteration 18040, loss = 0.182667
I0626 15:38:55.164898  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 15:38:55.164906  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.152243 (* 1 = 0.152243 loss)
I0626 15:38:55.164911  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.157773 (* 1 = 0.157773 loss)
I0626 15:38:55.164913  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108831 (* 1 = 0.00108831 loss)
I0626 15:38:55.164917  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0411262 (* 1 = 0.0411262 loss)
I0626 15:38:55.164922  6673 sgd_solver.cpp:106] Iteration 18040, lr = 0.0002
I0626 15:40:33.615219  6673 solver.cpp:228] Iteration 18060, loss = 0.158977
I0626 15:40:33.615247  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 15:40:33.615254  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.119412 (* 1 = 0.119412 loss)
I0626 15:40:33.615260  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.158778 (* 1 = 0.158778 loss)
I0626 15:40:33.615267  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118194 (* 1 = 0.0118194 loss)
I0626 15:40:33.615270  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022134 (* 1 = 0.022134 loss)
I0626 15:40:33.615275  6673 sgd_solver.cpp:106] Iteration 18060, lr = 0.0002
I0626 15:42:12.035132  6673 solver.cpp:228] Iteration 18080, loss = 0.259909
I0626 15:42:12.035162  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 15:42:12.035171  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.127895 (* 1 = 0.127895 loss)
I0626 15:42:12.035174  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.231812 (* 1 = 0.231812 loss)
I0626 15:42:12.035178  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103595 (* 1 = 0.0103595 loss)
I0626 15:42:12.035182  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300687 (* 1 = 0.0300687 loss)
I0626 15:42:12.035187  6673 sgd_solver.cpp:106] Iteration 18080, lr = 0.0002
I0626 15:43:50.090283  6673 solver.cpp:228] Iteration 18100, loss = 0.11578
I0626 15:43:50.090310  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:43:50.090318  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154883 (* 1 = 0.0154883 loss)
I0626 15:43:50.090323  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.025125 (* 1 = 0.025125 loss)
I0626 15:43:50.090327  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000169056 (* 1 = 0.000169056 loss)
I0626 15:43:50.090330  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00128731 (* 1 = 0.00128731 loss)
I0626 15:43:50.090337  6673 sgd_solver.cpp:106] Iteration 18100, lr = 0.0002
I0626 15:45:28.362974  6673 solver.cpp:228] Iteration 18120, loss = 0.270828
I0626 15:45:28.363003  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0626 15:45:28.363009  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.21668 (* 1 = 0.21668 loss)
I0626 15:45:28.363013  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.329104 (* 1 = 0.329104 loss)
I0626 15:45:28.363018  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181965 (* 1 = 0.0181965 loss)
I0626 15:45:28.363020  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105921 (* 1 = 0.105921 loss)
I0626 15:45:28.363025  6673 sgd_solver.cpp:106] Iteration 18120, lr = 0.0002
I0626 15:47:06.727869  6673 solver.cpp:228] Iteration 18140, loss = 0.131936
I0626 15:47:06.727893  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:47:06.727900  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445253 (* 1 = 0.0445253 loss)
I0626 15:47:06.727905  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0335424 (* 1 = 0.0335424 loss)
I0626 15:47:06.727908  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000624176 (* 1 = 0.000624176 loss)
I0626 15:47:06.727912  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00123387 (* 1 = 0.00123387 loss)
I0626 15:47:06.727917  6673 sgd_solver.cpp:106] Iteration 18140, lr = 0.0002
I0626 15:48:44.908059  6673 solver.cpp:228] Iteration 18160, loss = 0.136551
I0626 15:48:44.908087  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 15:48:44.908094  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232901 (* 1 = 0.0232901 loss)
I0626 15:48:44.908098  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0288665 (* 1 = 0.0288665 loss)
I0626 15:48:44.908102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0323235 (* 1 = 0.0323235 loss)
I0626 15:48:44.908107  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00789856 (* 1 = 0.00789856 loss)
I0626 15:48:44.908113  6673 sgd_solver.cpp:106] Iteration 18160, lr = 0.0002
I0626 15:50:23.234091  6673 solver.cpp:228] Iteration 18180, loss = 0.268942
I0626 15:50:23.234120  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 15:50:23.234131  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0775773 (* 1 = 0.0775773 loss)
I0626 15:50:23.234138  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.112376 (* 1 = 0.112376 loss)
I0626 15:50:23.234143  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00227885 (* 1 = 0.00227885 loss)
I0626 15:50:23.234150  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017395 (* 1 = 0.017395 loss)
I0626 15:50:23.234158  6673 sgd_solver.cpp:106] Iteration 18180, lr = 0.0002
speed: 4.919s / iter
I0626 15:52:01.432410  6673 solver.cpp:228] Iteration 18200, loss = 0.238776
I0626 15:52:01.432438  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 15:52:01.432446  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359263 (* 1 = 0.0359263 loss)
I0626 15:52:01.432451  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0645192 (* 1 = 0.0645192 loss)
I0626 15:52:01.432454  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104704 (* 1 = 0.00104704 loss)
I0626 15:52:01.432458  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120703 (* 1 = 0.0120703 loss)
I0626 15:52:01.432463  6673 sgd_solver.cpp:106] Iteration 18200, lr = 0.0002
I0626 15:53:39.812351  6673 solver.cpp:228] Iteration 18220, loss = 0.211748
I0626 15:53:39.812379  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0626 15:53:39.812386  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.268887 (* 1 = 0.268887 loss)
I0626 15:53:39.812391  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.41019 (* 1 = 0.41019 loss)
I0626 15:53:39.812394  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880806 (* 1 = 0.00880806 loss)
I0626 15:53:39.812398  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0523437 (* 1 = 0.0523437 loss)
I0626 15:53:39.812403  6673 sgd_solver.cpp:106] Iteration 18220, lr = 0.0002
I0626 15:55:18.109844  6673 solver.cpp:228] Iteration 18240, loss = 0.373012
I0626 15:55:18.109869  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 15:55:18.109876  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.193958 (* 1 = 0.193958 loss)
I0626 15:55:18.109880  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.318698 (* 1 = 0.318698 loss)
I0626 15:55:18.109884  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208931 (* 1 = 0.00208931 loss)
I0626 15:55:18.109889  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263741 (* 1 = 0.0263741 loss)
I0626 15:55:18.109892  6673 sgd_solver.cpp:106] Iteration 18240, lr = 0.0002
I0626 15:56:56.245846  6673 solver.cpp:228] Iteration 18260, loss = 0.129028
I0626 15:56:56.245879  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 15:56:56.245890  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00145837 (* 1 = 0.00145837 loss)
I0626 15:56:56.245896  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0400896 (* 1 = 0.0400896 loss)
I0626 15:56:56.245903  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604068 (* 1 = 0.00604068 loss)
I0626 15:56:56.245908  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147639 (* 1 = 0.0147639 loss)
I0626 15:56:56.245918  6673 sgd_solver.cpp:106] Iteration 18260, lr = 0.0002
I0626 15:58:34.525259  6673 solver.cpp:228] Iteration 18280, loss = 0.22445
I0626 15:58:34.525305  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 15:58:34.525318  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0998368 (* 1 = 0.0998368 loss)
I0626 15:58:34.525326  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0997754 (* 1 = 0.0997754 loss)
I0626 15:58:34.525331  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00106413 (* 1 = 0.00106413 loss)
I0626 15:58:34.525336  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138111 (* 1 = 0.0138111 loss)
I0626 15:58:34.525346  6673 sgd_solver.cpp:106] Iteration 18280, lr = 0.0002
I0626 16:00:12.851339  6673 solver.cpp:228] Iteration 18300, loss = 0.326533
I0626 16:00:12.851425  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 16:00:12.851454  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0760586 (* 1 = 0.0760586 loss)
I0626 16:00:12.851474  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.173658 (* 1 = 0.173658 loss)
I0626 16:00:12.851491  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184437 (* 1 = 0.0184437 loss)
I0626 16:00:12.851510  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.051248 (* 1 = 0.051248 loss)
I0626 16:00:12.851531  6673 sgd_solver.cpp:106] Iteration 18300, lr = 0.0002
I0626 16:01:51.172994  6673 solver.cpp:228] Iteration 18320, loss = 0.089528
I0626 16:01:51.173020  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:01:51.173029  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237645 (* 1 = 0.0237645 loss)
I0626 16:01:51.173035  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0447735 (* 1 = 0.0447735 loss)
I0626 16:01:51.173040  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000427276 (* 1 = 0.000427276 loss)
I0626 16:01:51.173046  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105568 (* 1 = 0.0105568 loss)
I0626 16:01:51.173053  6673 sgd_solver.cpp:106] Iteration 18320, lr = 0.0002
I0626 16:03:29.552094  6673 solver.cpp:228] Iteration 18340, loss = 0.188776
I0626 16:03:29.552120  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 16:03:29.552129  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183449 (* 1 = 0.0183449 loss)
I0626 16:03:29.552134  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0632046 (* 1 = 0.0632046 loss)
I0626 16:03:29.552137  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103441 (* 1 = 0.0103441 loss)
I0626 16:03:29.552141  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0072488 (* 1 = 0.0072488 loss)
I0626 16:03:29.552147  6673 sgd_solver.cpp:106] Iteration 18340, lr = 0.0002
I0626 16:05:07.817119  6673 solver.cpp:228] Iteration 18360, loss = 0.160208
I0626 16:05:07.817147  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:05:07.817155  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0484701 (* 1 = 0.0484701 loss)
I0626 16:05:07.817159  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.06019 (* 1 = 0.06019 loss)
I0626 16:05:07.817163  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000150867 (* 1 = 0.000150867 loss)
I0626 16:05:07.817167  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00832064 (* 1 = 0.00832064 loss)
I0626 16:05:07.817171  6673 sgd_solver.cpp:106] Iteration 18360, lr = 0.0002
I0626 16:06:46.111949  6673 solver.cpp:228] Iteration 18380, loss = 0.190103
I0626 16:06:46.111979  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 16:06:46.111986  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.131164 (* 1 = 0.131164 loss)
I0626 16:06:46.111990  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.254239 (* 1 = 0.254239 loss)
I0626 16:06:46.111994  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00418519 (* 1 = 0.00418519 loss)
I0626 16:06:46.111999  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0396195 (* 1 = 0.0396195 loss)
I0626 16:06:46.112004  6673 sgd_solver.cpp:106] Iteration 18380, lr = 0.0002
speed: 4.919s / iter
I0626 16:08:24.441265  6673 solver.cpp:228] Iteration 18400, loss = 0.280955
I0626 16:08:24.441293  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 16:08:24.441301  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513593 (* 1 = 0.0513593 loss)
I0626 16:08:24.441306  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0277088 (* 1 = 0.0277088 loss)
I0626 16:08:24.441310  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00306033 (* 1 = 0.00306033 loss)
I0626 16:08:24.441314  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00667291 (* 1 = 0.00667291 loss)
I0626 16:08:24.441319  6673 sgd_solver.cpp:106] Iteration 18400, lr = 0.0002
I0626 16:10:02.741540  6673 solver.cpp:228] Iteration 18420, loss = 0.126578
I0626 16:10:02.741569  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:10:02.741580  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0576744 (* 1 = 0.0576744 loss)
I0626 16:10:02.741586  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100055 (* 1 = 0.100055 loss)
I0626 16:10:02.741592  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00560189 (* 1 = 0.00560189 loss)
I0626 16:10:02.741597  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228591 (* 1 = 0.0228591 loss)
I0626 16:10:02.741606  6673 sgd_solver.cpp:106] Iteration 18420, lr = 0.0002
I0626 16:11:41.015710  6673 solver.cpp:228] Iteration 18440, loss = 0.16047
I0626 16:11:41.015736  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 16:11:41.015743  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.197997 (* 1 = 0.197997 loss)
I0626 16:11:41.015748  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.222705 (* 1 = 0.222705 loss)
I0626 16:11:41.015751  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00699101 (* 1 = 0.00699101 loss)
I0626 16:11:41.015754  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.073419 (* 1 = 0.073419 loss)
I0626 16:11:41.015759  6673 sgd_solver.cpp:106] Iteration 18440, lr = 0.0002
I0626 16:13:19.306257  6673 solver.cpp:228] Iteration 18460, loss = 0.279881
I0626 16:13:19.306282  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 16:13:19.306290  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.152017 (* 1 = 0.152017 loss)
I0626 16:13:19.306294  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.205278 (* 1 = 0.205278 loss)
I0626 16:13:19.306299  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132062 (* 1 = 0.00132062 loss)
I0626 16:13:19.306304  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345119 (* 1 = 0.0345119 loss)
I0626 16:13:19.306309  6673 sgd_solver.cpp:106] Iteration 18460, lr = 0.0002
I0626 16:14:57.638772  6673 solver.cpp:228] Iteration 18480, loss = 0.161417
I0626 16:14:57.638798  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:14:57.638806  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00965672 (* 1 = 0.00965672 loss)
I0626 16:14:57.638810  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.070689 (* 1 = 0.070689 loss)
I0626 16:14:57.638814  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188836 (* 1 = 0.0188836 loss)
I0626 16:14:57.638818  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00169416 (* 1 = 0.00169416 loss)
I0626 16:14:57.638823  6673 sgd_solver.cpp:106] Iteration 18480, lr = 0.0002
I0626 16:16:35.915649  6673 solver.cpp:228] Iteration 18500, loss = 0.138255
I0626 16:16:35.915674  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:16:35.915683  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206385 (* 1 = 0.0206385 loss)
I0626 16:16:35.915686  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.05099 (* 1 = 0.05099 loss)
I0626 16:16:35.915690  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000603255 (* 1 = 0.000603255 loss)
I0626 16:16:35.915693  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00377755 (* 1 = 0.00377755 loss)
I0626 16:16:35.915699  6673 sgd_solver.cpp:106] Iteration 18500, lr = 0.0002
I0626 16:18:14.243182  6673 solver.cpp:228] Iteration 18520, loss = 0.0893648
I0626 16:18:14.243211  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:18:14.243218  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171797 (* 1 = 0.0171797 loss)
I0626 16:18:14.243223  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0378941 (* 1 = 0.0378941 loss)
I0626 16:18:14.243227  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000228562 (* 1 = 0.000228562 loss)
I0626 16:18:14.243232  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00986154 (* 1 = 0.00986154 loss)
I0626 16:18:14.243237  6673 sgd_solver.cpp:106] Iteration 18520, lr = 0.0002
I0626 16:19:52.476512  6673 solver.cpp:228] Iteration 18540, loss = 0.170774
I0626 16:19:52.476557  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 16:19:52.476565  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0904505 (* 1 = 0.0904505 loss)
I0626 16:19:52.476570  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.170556 (* 1 = 0.170556 loss)
I0626 16:19:52.476575  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000609466 (* 1 = 0.000609466 loss)
I0626 16:19:52.476579  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00870858 (* 1 = 0.00870858 loss)
I0626 16:19:52.476589  6673 sgd_solver.cpp:106] Iteration 18540, lr = 0.0002
I0626 16:21:30.633317  6673 solver.cpp:228] Iteration 18560, loss = 0.426078
I0626 16:21:30.633343  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0626 16:21:30.633350  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.302599 (* 1 = 0.302599 loss)
I0626 16:21:30.633353  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.51354 (* 1 = 0.51354 loss)
I0626 16:21:30.633358  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0425407 (* 1 = 0.0425407 loss)
I0626 16:21:30.633361  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.232796 (* 1 = 0.232796 loss)
I0626 16:21:30.633365  6673 sgd_solver.cpp:106] Iteration 18560, lr = 0.0002
I0626 16:23:08.850242  6673 solver.cpp:228] Iteration 18580, loss = 0.241465
I0626 16:23:08.850273  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 16:23:08.850283  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00949994 (* 1 = 0.00949994 loss)
I0626 16:23:08.850289  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0912754 (* 1 = 0.0912754 loss)
I0626 16:23:08.850294  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000139102 (* 1 = 0.000139102 loss)
I0626 16:23:08.850301  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00286727 (* 1 = 0.00286727 loss)
I0626 16:23:08.850308  6673 sgd_solver.cpp:106] Iteration 18580, lr = 0.0002
speed: 4.919s / iter
I0626 16:24:47.178162  6673 solver.cpp:228] Iteration 18600, loss = 0.253318
I0626 16:24:47.178192  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0626 16:24:47.178200  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.24905 (* 1 = 0.24905 loss)
I0626 16:24:47.178205  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.363938 (* 1 = 0.363938 loss)
I0626 16:24:47.178208  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00963283 (* 1 = 0.00963283 loss)
I0626 16:24:47.178212  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0502021 (* 1 = 0.0502021 loss)
I0626 16:24:47.178218  6673 sgd_solver.cpp:106] Iteration 18600, lr = 0.0002
I0626 16:26:25.697329  6673 solver.cpp:228] Iteration 18620, loss = 0.25866
I0626 16:26:25.697357  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 16:26:25.697365  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703689 (* 1 = 0.0703689 loss)
I0626 16:26:25.697372  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.124599 (* 1 = 0.124599 loss)
I0626 16:26:25.697378  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179074 (* 1 = 0.00179074 loss)
I0626 16:26:25.697382  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157129 (* 1 = 0.0157129 loss)
I0626 16:26:25.697387  6673 sgd_solver.cpp:106] Iteration 18620, lr = 0.0002
I0626 16:28:04.273232  6673 solver.cpp:228] Iteration 18640, loss = 0.309278
I0626 16:28:04.273262  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 16:28:04.273270  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0315104 (* 1 = 0.0315104 loss)
I0626 16:28:04.273274  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0289888 (* 1 = 0.0289888 loss)
I0626 16:28:04.273278  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491006 (* 1 = 0.00491006 loss)
I0626 16:28:04.273283  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00756507 (* 1 = 0.00756507 loss)
I0626 16:28:04.273288  6673 sgd_solver.cpp:106] Iteration 18640, lr = 0.0002
I0626 16:29:42.475946  6673 solver.cpp:228] Iteration 18660, loss = 0.111307
I0626 16:29:42.475970  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 16:29:42.475976  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0630428 (* 1 = 0.0630428 loss)
I0626 16:29:42.475980  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.174636 (* 1 = 0.174636 loss)
I0626 16:29:42.475983  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000759945 (* 1 = 0.000759945 loss)
I0626 16:29:42.475987  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113551 (* 1 = 0.0113551 loss)
I0626 16:29:42.475992  6673 sgd_solver.cpp:106] Iteration 18660, lr = 0.0002
I0626 16:31:20.540774  6673 solver.cpp:228] Iteration 18680, loss = 0.220554
I0626 16:31:20.540797  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:31:20.540804  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0307767 (* 1 = 0.0307767 loss)
I0626 16:31:20.540808  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0712325 (* 1 = 0.0712325 loss)
I0626 16:31:20.540812  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000629432 (* 1 = 0.000629432 loss)
I0626 16:31:20.540815  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00326372 (* 1 = 0.00326372 loss)
I0626 16:31:20.540820  6673 sgd_solver.cpp:106] Iteration 18680, lr = 0.0002
I0626 16:32:58.594954  6673 solver.cpp:228] Iteration 18700, loss = 0.133085
I0626 16:32:58.594983  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:32:58.594991  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170681 (* 1 = 0.0170681 loss)
I0626 16:32:58.594995  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0376798 (* 1 = 0.0376798 loss)
I0626 16:32:58.595000  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000170144 (* 1 = 0.000170144 loss)
I0626 16:32:58.595005  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00325001 (* 1 = 0.00325001 loss)
I0626 16:32:58.595010  6673 sgd_solver.cpp:106] Iteration 18700, lr = 0.0002
I0626 16:34:36.687043  6673 solver.cpp:228] Iteration 18720, loss = 0.213887
I0626 16:34:36.687072  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 16:34:36.687081  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.173619 (* 1 = 0.173619 loss)
I0626 16:34:36.687088  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.148604 (* 1 = 0.148604 loss)
I0626 16:34:36.687095  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000671679 (* 1 = 0.000671679 loss)
I0626 16:34:36.687103  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0531632 (* 1 = 0.0531632 loss)
I0626 16:34:36.687109  6673 sgd_solver.cpp:106] Iteration 18720, lr = 0.0002
I0626 16:36:14.765919  6673 solver.cpp:228] Iteration 18740, loss = 0.250012
I0626 16:36:14.765945  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:36:14.765952  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0786388 (* 1 = 0.0786388 loss)
I0626 16:36:14.765956  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0335981 (* 1 = 0.0335981 loss)
I0626 16:36:14.765959  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035962 (* 1 = 0.0035962 loss)
I0626 16:36:14.765962  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00623798 (* 1 = 0.00623798 loss)
I0626 16:36:14.765967  6673 sgd_solver.cpp:106] Iteration 18740, lr = 0.0002
I0626 16:37:52.798406  6673 solver.cpp:228] Iteration 18760, loss = 0.166237
I0626 16:37:52.798429  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 16:37:52.798436  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186512 (* 1 = 0.0186512 loss)
I0626 16:37:52.798440  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0715688 (* 1 = 0.0715688 loss)
I0626 16:37:52.798444  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104091 (* 1 = 0.00104091 loss)
I0626 16:37:52.798447  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149907 (* 1 = 0.0149907 loss)
I0626 16:37:52.798451  6673 sgd_solver.cpp:106] Iteration 18760, lr = 0.0002
I0626 16:39:30.816612  6673 solver.cpp:228] Iteration 18780, loss = 0.146372
I0626 16:39:30.816642  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 16:39:30.816649  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0840736 (* 1 = 0.0840736 loss)
I0626 16:39:30.816653  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.248351 (* 1 = 0.248351 loss)
I0626 16:39:30.816658  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232572 (* 1 = 0.00232572 loss)
I0626 16:39:30.816661  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211123 (* 1 = 0.0211123 loss)
I0626 16:39:30.816666  6673 sgd_solver.cpp:106] Iteration 18780, lr = 0.0002
speed: 4.919s / iter
I0626 16:41:08.842401  6673 solver.cpp:228] Iteration 18800, loss = 0.267155
I0626 16:41:08.842427  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 16:41:08.842434  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0510452 (* 1 = 0.0510452 loss)
I0626 16:41:08.842438  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0780796 (* 1 = 0.0780796 loss)
I0626 16:41:08.842442  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00209576 (* 1 = 0.00209576 loss)
I0626 16:41:08.842447  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124047 (* 1 = 0.0124047 loss)
I0626 16:41:08.842452  6673 sgd_solver.cpp:106] Iteration 18800, lr = 0.0002
I0626 16:42:46.939574  6673 solver.cpp:228] Iteration 18820, loss = 0.305373
I0626 16:42:46.939607  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 16:42:46.939617  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174868 (* 1 = 0.0174868 loss)
I0626 16:42:46.939622  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0891399 (* 1 = 0.0891399 loss)
I0626 16:42:46.939628  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107948 (* 1 = 0.0107948 loss)
I0626 16:42:46.939633  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230681 (* 1 = 0.0230681 loss)
I0626 16:42:46.939640  6673 sgd_solver.cpp:106] Iteration 18820, lr = 0.0002
I0626 16:44:25.313138  6673 solver.cpp:228] Iteration 18840, loss = 0.162949
I0626 16:44:25.313170  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:44:25.313177  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0287224 (* 1 = 0.0287224 loss)
I0626 16:44:25.313184  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.042577 (* 1 = 0.042577 loss)
I0626 16:44:25.313189  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221704 (* 1 = 0.00221704 loss)
I0626 16:44:25.313195  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0081693 (* 1 = 0.0081693 loss)
I0626 16:44:25.313201  6673 sgd_solver.cpp:106] Iteration 18840, lr = 0.0002
I0626 16:46:03.681682  6673 solver.cpp:228] Iteration 18860, loss = 0.0829715
I0626 16:46:03.681713  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:46:03.681722  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00939766 (* 1 = 0.00939766 loss)
I0626 16:46:03.681726  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.040968 (* 1 = 0.040968 loss)
I0626 16:46:03.681730  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00500159 (* 1 = 0.00500159 loss)
I0626 16:46:03.681735  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000982388 (* 1 = 0.000982388 loss)
I0626 16:46:03.681740  6673 sgd_solver.cpp:106] Iteration 18860, lr = 0.0002
I0626 16:47:42.000496  6673 solver.cpp:228] Iteration 18880, loss = 0.244826
I0626 16:47:42.000594  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:47:42.000622  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0219418 (* 1 = 0.0219418 loss)
I0626 16:47:42.000639  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0479384 (* 1 = 0.0479384 loss)
I0626 16:47:42.000658  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126214 (* 1 = 0.0126214 loss)
I0626 16:47:42.000674  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136909 (* 1 = 0.0136909 loss)
I0626 16:47:42.000691  6673 sgd_solver.cpp:106] Iteration 18880, lr = 0.0002
I0626 16:49:20.307334  6673 solver.cpp:228] Iteration 18900, loss = 0.178815
I0626 16:49:20.307363  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 16:49:20.307374  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00257191 (* 1 = 0.00257191 loss)
I0626 16:49:20.307379  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0133547 (* 1 = 0.0133547 loss)
I0626 16:49:20.307384  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000317107 (* 1 = 0.000317107 loss)
I0626 16:49:20.307390  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111868 (* 1 = 0.0111868 loss)
I0626 16:49:20.307397  6673 sgd_solver.cpp:106] Iteration 18900, lr = 0.0002
I0626 16:50:58.513875  6673 solver.cpp:228] Iteration 18920, loss = 0.0995949
I0626 16:50:58.513897  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:50:58.513905  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179323 (* 1 = 0.0179323 loss)
I0626 16:50:58.513908  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0373874 (* 1 = 0.0373874 loss)
I0626 16:50:58.513911  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000269514 (* 1 = 0.000269514 loss)
I0626 16:50:58.513914  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00203661 (* 1 = 0.00203661 loss)
I0626 16:50:58.513919  6673 sgd_solver.cpp:106] Iteration 18920, lr = 0.0002
I0626 16:52:36.829741  6673 solver.cpp:228] Iteration 18940, loss = 0.221579
I0626 16:52:36.829779  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 16:52:36.829790  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0184996 (* 1 = 0.0184996 loss)
I0626 16:52:36.829797  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0120856 (* 1 = 0.0120856 loss)
I0626 16:52:36.829805  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122888 (* 1 = 0.00122888 loss)
I0626 16:52:36.829810  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00511999 (* 1 = 0.00511999 loss)
I0626 16:52:36.829818  6673 sgd_solver.cpp:106] Iteration 18940, lr = 0.0002
I0626 16:54:15.173621  6673 solver.cpp:228] Iteration 18960, loss = 0.19626
I0626 16:54:15.173682  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 16:54:15.173691  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.111611 (* 1 = 0.111611 loss)
I0626 16:54:15.173696  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.121584 (* 1 = 0.121584 loss)
I0626 16:54:15.173701  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00122099 (* 1 = 0.00122099 loss)
I0626 16:54:15.173705  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266561 (* 1 = 0.0266561 loss)
I0626 16:54:15.173714  6673 sgd_solver.cpp:106] Iteration 18960, lr = 0.0002
I0626 16:55:53.211323  6673 solver.cpp:228] Iteration 18980, loss = 0.081676
I0626 16:55:53.211349  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 16:55:53.211356  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0428491 (* 1 = 0.0428491 loss)
I0626 16:55:53.211360  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0509749 (* 1 = 0.0509749 loss)
I0626 16:55:53.211364  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000161217 (* 1 = 0.000161217 loss)
I0626 16:55:53.211366  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101451 (* 1 = 0.0101451 loss)
I0626 16:55:53.211371  6673 sgd_solver.cpp:106] Iteration 18980, lr = 0.0002
speed: 4.919s / iter
I0626 16:57:31.200269  6673 solver.cpp:228] Iteration 19000, loss = 0.228179
I0626 16:57:31.200294  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:57:31.200299  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157355 (* 1 = 0.0157355 loss)
I0626 16:57:31.200304  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0476346 (* 1 = 0.0476346 loss)
I0626 16:57:31.200307  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000272686 (* 1 = 0.000272686 loss)
I0626 16:57:31.200310  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00838633 (* 1 = 0.00838633 loss)
I0626 16:57:31.200314  6673 sgd_solver.cpp:106] Iteration 19000, lr = 0.0002
I0626 16:59:09.246861  6673 solver.cpp:228] Iteration 19020, loss = 0.117829
I0626 16:59:09.246887  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 16:59:09.246896  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156354 (* 1 = 0.0156354 loss)
I0626 16:59:09.246899  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.048508 (* 1 = 0.048508 loss)
I0626 16:59:09.246904  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000438588 (* 1 = 0.000438588 loss)
I0626 16:59:09.246907  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00674975 (* 1 = 0.00674975 loss)
I0626 16:59:09.246912  6673 sgd_solver.cpp:106] Iteration 19020, lr = 0.0002
I0626 17:00:47.280489  6673 solver.cpp:228] Iteration 19040, loss = 0.164627
I0626 17:00:47.280514  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 17:00:47.280522  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447322 (* 1 = 0.0447322 loss)
I0626 17:00:47.280529  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.140392 (* 1 = 0.140392 loss)
I0626 17:00:47.280534  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000251376 (* 1 = 0.000251376 loss)
I0626 17:00:47.280539  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114248 (* 1 = 0.0114248 loss)
I0626 17:00:47.280545  6673 sgd_solver.cpp:106] Iteration 19040, lr = 0.0002
I0626 17:02:25.301162  6673 solver.cpp:228] Iteration 19060, loss = 0.195218
I0626 17:02:25.301185  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:02:25.301193  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156216 (* 1 = 0.0156216 loss)
I0626 17:02:25.301198  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0444253 (* 1 = 0.0444253 loss)
I0626 17:02:25.301201  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00384325 (* 1 = 0.00384325 loss)
I0626 17:02:25.301205  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00810364 (* 1 = 0.00810364 loss)
I0626 17:02:25.301210  6673 sgd_solver.cpp:106] Iteration 19060, lr = 0.0002
I0626 17:04:03.314528  6673 solver.cpp:228] Iteration 19080, loss = 0.189625
I0626 17:04:03.314555  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 17:04:03.314563  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0515243 (* 1 = 0.0515243 loss)
I0626 17:04:03.314568  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0699111 (* 1 = 0.0699111 loss)
I0626 17:04:03.314570  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00408836 (* 1 = 0.00408836 loss)
I0626 17:04:03.314574  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023804 (* 1 = 0.023804 loss)
I0626 17:04:03.314579  6673 sgd_solver.cpp:106] Iteration 19080, lr = 0.0002
I0626 17:05:41.383227  6673 solver.cpp:228] Iteration 19100, loss = 0.10239
I0626 17:05:41.383253  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 17:05:41.383260  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410434 (* 1 = 0.0410434 loss)
I0626 17:05:41.383265  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0308066 (* 1 = 0.0308066 loss)
I0626 17:05:41.383268  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000867549 (* 1 = 0.000867549 loss)
I0626 17:05:41.383271  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00780606 (* 1 = 0.00780606 loss)
I0626 17:05:41.383276  6673 sgd_solver.cpp:106] Iteration 19100, lr = 0.0002
I0626 17:07:19.433296  6673 solver.cpp:228] Iteration 19120, loss = 0.184205
I0626 17:07:19.433320  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:07:19.433327  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383635 (* 1 = 0.0383635 loss)
I0626 17:07:19.433331  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.066725 (* 1 = 0.066725 loss)
I0626 17:07:19.433334  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000106486 (* 1 = 0.000106486 loss)
I0626 17:07:19.433338  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00930926 (* 1 = 0.00930926 loss)
I0626 17:07:19.433343  6673 sgd_solver.cpp:106] Iteration 19120, lr = 0.0002
I0626 17:08:57.455936  6673 solver.cpp:228] Iteration 19140, loss = 0.207597
I0626 17:08:57.455963  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 17:08:57.455971  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.104745 (* 1 = 0.104745 loss)
I0626 17:08:57.455974  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.13894 (* 1 = 0.13894 loss)
I0626 17:08:57.455978  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00159849 (* 1 = 0.00159849 loss)
I0626 17:08:57.455982  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192842 (* 1 = 0.0192842 loss)
I0626 17:08:57.455986  6673 sgd_solver.cpp:106] Iteration 19140, lr = 0.0002
I0626 17:10:35.456820  6673 solver.cpp:228] Iteration 19160, loss = 0.207191
I0626 17:10:35.456845  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 17:10:35.456851  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.201622 (* 1 = 0.201622 loss)
I0626 17:10:35.456856  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.270189 (* 1 = 0.270189 loss)
I0626 17:10:35.456859  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171912 (* 1 = 0.00171912 loss)
I0626 17:10:35.456863  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.046472 (* 1 = 0.046472 loss)
I0626 17:10:35.456868  6673 sgd_solver.cpp:106] Iteration 19160, lr = 0.0002
I0626 17:12:13.461237  6673 solver.cpp:228] Iteration 19180, loss = 0.180429
I0626 17:12:13.461263  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:12:13.461271  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135553 (* 1 = 0.0135553 loss)
I0626 17:12:13.461274  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0305674 (* 1 = 0.0305674 loss)
I0626 17:12:13.461278  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0087404 (* 1 = 0.0087404 loss)
I0626 17:12:13.461282  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00593294 (* 1 = 0.00593294 loss)
I0626 17:12:13.461287  6673 sgd_solver.cpp:106] Iteration 19180, lr = 0.0002
speed: 4.919s / iter
I0626 17:13:51.490255  6673 solver.cpp:228] Iteration 19200, loss = 0.110373
I0626 17:13:51.490278  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:13:51.490285  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0270545 (* 1 = 0.0270545 loss)
I0626 17:13:51.490289  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0707419 (* 1 = 0.0707419 loss)
I0626 17:13:51.490293  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00432281 (* 1 = 0.00432281 loss)
I0626 17:13:51.490298  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00563463 (* 1 = 0.00563463 loss)
I0626 17:13:51.490301  6673 sgd_solver.cpp:106] Iteration 19200, lr = 0.0002
I0626 17:15:29.490825  6673 solver.cpp:228] Iteration 19220, loss = 0.128494
I0626 17:15:29.490852  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 17:15:29.490864  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0698466 (* 1 = 0.0698466 loss)
I0626 17:15:29.490869  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.190912 (* 1 = 0.190912 loss)
I0626 17:15:29.490873  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000386491 (* 1 = 0.000386491 loss)
I0626 17:15:29.490877  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00960121 (* 1 = 0.00960121 loss)
I0626 17:15:29.490882  6673 sgd_solver.cpp:106] Iteration 19220, lr = 0.0002
I0626 17:17:07.464704  6673 solver.cpp:228] Iteration 19240, loss = 0.123182
I0626 17:17:07.464731  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:17:07.464741  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203127 (* 1 = 0.0203127 loss)
I0626 17:17:07.464748  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.04613 (* 1 = 0.04613 loss)
I0626 17:17:07.464754  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00807342 (* 1 = 0.00807342 loss)
I0626 17:17:07.464761  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00571144 (* 1 = 0.00571144 loss)
I0626 17:17:07.464767  6673 sgd_solver.cpp:106] Iteration 19240, lr = 0.0002
I0626 17:18:45.453433  6673 solver.cpp:228] Iteration 19260, loss = 0.127704
I0626 17:18:45.453456  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 17:18:45.453464  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0661289 (* 1 = 0.0661289 loss)
I0626 17:18:45.453469  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.179507 (* 1 = 0.179507 loss)
I0626 17:18:45.453472  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00444132 (* 1 = 0.00444132 loss)
I0626 17:18:45.453475  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251576 (* 1 = 0.0251576 loss)
I0626 17:18:45.453480  6673 sgd_solver.cpp:106] Iteration 19260, lr = 0.0002
I0626 17:20:23.439198  6673 solver.cpp:228] Iteration 19280, loss = 0.0965488
I0626 17:20:23.439224  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 17:20:23.439229  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291611 (* 1 = 0.0291611 loss)
I0626 17:20:23.439234  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0743663 (* 1 = 0.0743663 loss)
I0626 17:20:23.439237  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00282797 (* 1 = 0.00282797 loss)
I0626 17:20:23.439240  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0585468 (* 1 = 0.0585468 loss)
I0626 17:20:23.439245  6673 sgd_solver.cpp:106] Iteration 19280, lr = 0.0002
I0626 17:22:01.438369  6673 solver.cpp:228] Iteration 19300, loss = 0.453636
I0626 17:22:01.438395  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:22:01.438405  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0810167 (* 1 = 0.0810167 loss)
I0626 17:22:01.438411  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0613108 (* 1 = 0.0613108 loss)
I0626 17:22:01.438417  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179013 (* 1 = 0.00179013 loss)
I0626 17:22:01.438423  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00602071 (* 1 = 0.00602071 loss)
I0626 17:22:01.438431  6673 sgd_solver.cpp:106] Iteration 19300, lr = 0.0002
I0626 17:23:39.465576  6673 solver.cpp:228] Iteration 19320, loss = 0.14739
I0626 17:23:39.465601  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:23:39.465608  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0490067 (* 1 = 0.0490067 loss)
I0626 17:23:39.465613  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0589936 (* 1 = 0.0589936 loss)
I0626 17:23:39.465617  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00702276 (* 1 = 0.00702276 loss)
I0626 17:23:39.465620  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00807569 (* 1 = 0.00807569 loss)
I0626 17:23:39.465626  6673 sgd_solver.cpp:106] Iteration 19320, lr = 0.0002
I0626 17:25:17.418159  6673 solver.cpp:228] Iteration 19340, loss = 0.148639
I0626 17:25:17.418184  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 17:25:17.418190  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0682142 (* 1 = 0.0682142 loss)
I0626 17:25:17.418195  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.098372 (* 1 = 0.098372 loss)
I0626 17:25:17.418197  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00522908 (* 1 = 0.00522908 loss)
I0626 17:25:17.418201  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379042 (* 1 = 0.0379042 loss)
I0626 17:25:17.418205  6673 sgd_solver.cpp:106] Iteration 19340, lr = 0.0002
I0626 17:26:55.364493  6673 solver.cpp:228] Iteration 19360, loss = 0.165026
I0626 17:26:55.364521  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:26:55.364528  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0208649 (* 1 = 0.0208649 loss)
I0626 17:26:55.364531  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0279492 (* 1 = 0.0279492 loss)
I0626 17:26:55.364536  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00322454 (* 1 = 0.00322454 loss)
I0626 17:26:55.364538  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00417615 (* 1 = 0.00417615 loss)
I0626 17:26:55.364543  6673 sgd_solver.cpp:106] Iteration 19360, lr = 0.0002
I0626 17:28:33.308210  6673 solver.cpp:228] Iteration 19380, loss = 0.136969
I0626 17:28:33.308254  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:28:33.308261  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182754 (* 1 = 0.0182754 loss)
I0626 17:28:33.308266  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0283573 (* 1 = 0.0283573 loss)
I0626 17:28:33.308270  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120012 (* 1 = 0.00120012 loss)
I0626 17:28:33.308274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000831891 (* 1 = 0.000831891 loss)
I0626 17:28:33.308282  6673 sgd_solver.cpp:106] Iteration 19380, lr = 0.0002
speed: 4.919s / iter
I0626 17:30:11.274726  6673 solver.cpp:228] Iteration 19400, loss = 0.0772305
I0626 17:30:11.274752  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:30:11.274760  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174561 (* 1 = 0.0174561 loss)
I0626 17:30:11.274765  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0292391 (* 1 = 0.0292391 loss)
I0626 17:30:11.274770  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270292 (* 1 = 0.00270292 loss)
I0626 17:30:11.274772  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00355022 (* 1 = 0.00355022 loss)
I0626 17:30:11.274777  6673 sgd_solver.cpp:106] Iteration 19400, lr = 0.0002
I0626 17:31:49.344933  6673 solver.cpp:228] Iteration 19420, loss = 0.203149
I0626 17:31:49.344960  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:31:49.344969  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276075 (* 1 = 0.0276075 loss)
I0626 17:31:49.344972  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0537489 (* 1 = 0.0537489 loss)
I0626 17:31:49.344976  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000122552 (* 1 = 0.000122552 loss)
I0626 17:31:49.344980  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00602507 (* 1 = 0.00602507 loss)
I0626 17:31:49.344986  6673 sgd_solver.cpp:106] Iteration 19420, lr = 0.0002
I0626 17:33:27.418872  6673 solver.cpp:228] Iteration 19440, loss = 0.1982
I0626 17:33:27.418902  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 17:33:27.418911  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0667205 (* 1 = 0.0667205 loss)
I0626 17:33:27.418917  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.114292 (* 1 = 0.114292 loss)
I0626 17:33:27.418922  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0025125 (* 1 = 0.0025125 loss)
I0626 17:33:27.418928  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310006 (* 1 = 0.0310006 loss)
I0626 17:33:27.418934  6673 sgd_solver.cpp:106] Iteration 19440, lr = 0.0002
I0626 17:35:05.495551  6673 solver.cpp:228] Iteration 19460, loss = 0.141781
I0626 17:35:05.495577  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 17:35:05.495584  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0957594 (* 1 = 0.0957594 loss)
I0626 17:35:05.495589  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.1193 (* 1 = 0.1193 loss)
I0626 17:35:05.495592  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000431038 (* 1 = 0.000431038 loss)
I0626 17:35:05.495595  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305569 (* 1 = 0.0305569 loss)
I0626 17:35:05.495600  6673 sgd_solver.cpp:106] Iteration 19460, lr = 0.0002
I0626 17:36:43.497123  6673 solver.cpp:228] Iteration 19480, loss = 0.204776
I0626 17:36:43.497145  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:36:43.497151  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0252073 (* 1 = 0.0252073 loss)
I0626 17:36:43.497156  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0723538 (* 1 = 0.0723538 loss)
I0626 17:36:43.497159  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00339912 (* 1 = 0.00339912 loss)
I0626 17:36:43.497164  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00756263 (* 1 = 0.00756263 loss)
I0626 17:36:43.497167  6673 sgd_solver.cpp:106] Iteration 19480, lr = 0.0002
I0626 17:38:21.455498  6673 solver.cpp:228] Iteration 19500, loss = 0.270083
I0626 17:38:21.455523  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:38:21.455529  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0510285 (* 1 = 0.0510285 loss)
I0626 17:38:21.455533  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0937309 (* 1 = 0.0937309 loss)
I0626 17:38:21.455536  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445669 (* 1 = 0.00445669 loss)
I0626 17:38:21.455540  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00862021 (* 1 = 0.00862021 loss)
I0626 17:38:21.455545  6673 sgd_solver.cpp:106] Iteration 19500, lr = 0.0002
I0626 17:39:59.551650  6673 solver.cpp:228] Iteration 19520, loss = 0.207817
I0626 17:39:59.551672  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 17:39:59.551679  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.100465 (* 1 = 0.100465 loss)
I0626 17:39:59.551683  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.159783 (* 1 = 0.159783 loss)
I0626 17:39:59.551687  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174422 (* 1 = 0.0174422 loss)
I0626 17:39:59.551690  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285238 (* 1 = 0.0285238 loss)
I0626 17:39:59.551694  6673 sgd_solver.cpp:106] Iteration 19520, lr = 0.0002
I0626 17:41:37.586328  6673 solver.cpp:228] Iteration 19540, loss = 0.203813
I0626 17:41:37.586352  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 17:41:37.586360  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0623391 (* 1 = 0.0623391 loss)
I0626 17:41:37.586365  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.231395 (* 1 = 0.231395 loss)
I0626 17:41:37.586369  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219298 (* 1 = 0.0219298 loss)
I0626 17:41:37.586372  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153985 (* 1 = 0.153985 loss)
I0626 17:41:37.586378  6673 sgd_solver.cpp:106] Iteration 19540, lr = 0.0002
I0626 17:43:15.631714  6673 solver.cpp:228] Iteration 19560, loss = 0.113194
I0626 17:43:15.631739  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 17:43:15.631747  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0376676 (* 1 = 0.0376676 loss)
I0626 17:43:15.631750  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0503085 (* 1 = 0.0503085 loss)
I0626 17:43:15.631754  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00199999 (* 1 = 0.00199999 loss)
I0626 17:43:15.631757  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00669007 (* 1 = 0.00669007 loss)
I0626 17:43:15.631762  6673 sgd_solver.cpp:106] Iteration 19560, lr = 0.0002
I0626 17:44:53.608541  6673 solver.cpp:228] Iteration 19580, loss = 0.10321
I0626 17:44:53.608568  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:44:53.608575  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291424 (* 1 = 0.0291424 loss)
I0626 17:44:53.608580  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0625506 (* 1 = 0.0625506 loss)
I0626 17:44:53.608584  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000429958 (* 1 = 0.000429958 loss)
I0626 17:44:53.608587  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0087528 (* 1 = 0.0087528 loss)
I0626 17:44:53.608592  6673 sgd_solver.cpp:106] Iteration 19580, lr = 0.0002
speed: 4.918s / iter
I0626 17:46:31.553436  6673 solver.cpp:228] Iteration 19600, loss = 0.0751967
I0626 17:46:31.553467  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 17:46:31.553477  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562847 (* 1 = 0.0562847 loss)
I0626 17:46:31.553481  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0590863 (* 1 = 0.0590863 loss)
I0626 17:46:31.553488  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000600541 (* 1 = 0.000600541 loss)
I0626 17:46:31.553494  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200596 (* 1 = 0.0200596 loss)
I0626 17:46:31.553499  6673 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I0626 17:48:09.490068  6673 solver.cpp:228] Iteration 19620, loss = 0.125945
I0626 17:48:09.490092  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 17:48:09.490099  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229955 (* 1 = 0.0229955 loss)
I0626 17:48:09.490104  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0411834 (* 1 = 0.0411834 loss)
I0626 17:48:09.490108  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00486362 (* 1 = 0.00486362 loss)
I0626 17:48:09.490111  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165358 (* 1 = 0.0165358 loss)
I0626 17:48:09.490116  6673 sgd_solver.cpp:106] Iteration 19620, lr = 0.0002
I0626 17:49:47.429033  6673 solver.cpp:228] Iteration 19640, loss = 0.100863
I0626 17:49:47.429059  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:49:47.429067  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0296342 (* 1 = 0.0296342 loss)
I0626 17:49:47.429075  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.053436 (* 1 = 0.053436 loss)
I0626 17:49:47.429080  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013368 (* 1 = 0.0013368 loss)
I0626 17:49:47.429085  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218476 (* 1 = 0.0218476 loss)
I0626 17:49:47.429090  6673 sgd_solver.cpp:106] Iteration 19640, lr = 0.0002
I0626 17:51:25.368589  6673 solver.cpp:228] Iteration 19660, loss = 0.135555
I0626 17:51:25.368615  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 17:51:25.368625  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0767833 (* 1 = 0.0767833 loss)
I0626 17:51:25.368629  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102921 (* 1 = 0.102921 loss)
I0626 17:51:25.368633  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000854639 (* 1 = 0.000854639 loss)
I0626 17:51:25.368638  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285814 (* 1 = 0.0285814 loss)
I0626 17:51:25.368643  6673 sgd_solver.cpp:106] Iteration 19660, lr = 0.0002
I0626 17:53:03.275941  6673 solver.cpp:228] Iteration 19680, loss = 0.231396
I0626 17:53:03.275966  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:53:03.275974  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286128 (* 1 = 0.0286128 loss)
I0626 17:53:03.275979  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0440363 (* 1 = 0.0440363 loss)
I0626 17:53:03.275981  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128272 (* 1 = 0.0128272 loss)
I0626 17:53:03.275985  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00500588 (* 1 = 0.00500588 loss)
I0626 17:53:03.275990  6673 sgd_solver.cpp:106] Iteration 19680, lr = 0.0002
I0626 17:54:41.157219  6673 solver.cpp:228] Iteration 19700, loss = 0.175604
I0626 17:54:41.157243  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 17:54:41.157249  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0499138 (* 1 = 0.0499138 loss)
I0626 17:54:41.157253  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0968099 (* 1 = 0.0968099 loss)
I0626 17:54:41.157258  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0020238 (* 1 = 0.0020238 loss)
I0626 17:54:41.157260  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282881 (* 1 = 0.0282881 loss)
I0626 17:54:41.157265  6673 sgd_solver.cpp:106] Iteration 19700, lr = 0.0002
I0626 17:56:19.114794  6673 solver.cpp:228] Iteration 19720, loss = 0.160948
I0626 17:56:19.114819  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 17:56:19.114826  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0118328 (* 1 = 0.0118328 loss)
I0626 17:56:19.114830  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0256923 (* 1 = 0.0256923 loss)
I0626 17:56:19.114835  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412721 (* 1 = 0.00412721 loss)
I0626 17:56:19.114838  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00222269 (* 1 = 0.00222269 loss)
I0626 17:56:19.114843  6673 sgd_solver.cpp:106] Iteration 19720, lr = 0.0002
I0626 17:57:57.041533  6673 solver.cpp:228] Iteration 19740, loss = 0.217601
I0626 17:57:57.041556  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 17:57:57.041563  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0647303 (* 1 = 0.0647303 loss)
I0626 17:57:57.041568  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0882118 (* 1 = 0.0882118 loss)
I0626 17:57:57.041571  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239461 (* 1 = 0.00239461 loss)
I0626 17:57:57.041574  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024226 (* 1 = 0.024226 loss)
I0626 17:57:57.041579  6673 sgd_solver.cpp:106] Iteration 19740, lr = 0.0002
I0626 17:59:34.951642  6673 solver.cpp:228] Iteration 19760, loss = 0.18161
I0626 17:59:34.951668  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 17:59:34.951676  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.047201 (* 1 = 0.047201 loss)
I0626 17:59:34.951683  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0405727 (* 1 = 0.0405727 loss)
I0626 17:59:34.951687  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121754 (* 1 = 0.0121754 loss)
I0626 17:59:34.951692  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271086 (* 1 = 0.0271086 loss)
I0626 17:59:34.951699  6673 sgd_solver.cpp:106] Iteration 19760, lr = 0.0002
I0626 18:01:12.864609  6673 solver.cpp:228] Iteration 19780, loss = 0.103468
I0626 18:01:12.864634  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:01:12.864642  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498885 (* 1 = 0.0498885 loss)
I0626 18:01:12.864646  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0904172 (* 1 = 0.0904172 loss)
I0626 18:01:12.864650  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00136291 (* 1 = 0.00136291 loss)
I0626 18:01:12.864653  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015188 (* 1 = 0.015188 loss)
I0626 18:01:12.864658  6673 sgd_solver.cpp:106] Iteration 19780, lr = 0.0002
speed: 4.918s / iter
I0626 18:02:50.761586  6673 solver.cpp:228] Iteration 19800, loss = 0.0777672
I0626 18:02:50.761613  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:02:50.761621  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0492678 (* 1 = 0.0492678 loss)
I0626 18:02:50.761626  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0388903 (* 1 = 0.0388903 loss)
I0626 18:02:50.761631  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125194 (* 1 = 0.00125194 loss)
I0626 18:02:50.761636  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00419571 (* 1 = 0.00419571 loss)
I0626 18:02:50.761641  6673 sgd_solver.cpp:106] Iteration 19800, lr = 0.0002
I0626 18:04:28.713292  6673 solver.cpp:228] Iteration 19820, loss = 0.212104
I0626 18:04:28.713313  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:04:28.713320  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0366835 (* 1 = 0.0366835 loss)
I0626 18:04:28.713323  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0593469 (* 1 = 0.0593469 loss)
I0626 18:04:28.713326  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00801288 (* 1 = 0.00801288 loss)
I0626 18:04:28.713330  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00816137 (* 1 = 0.00816137 loss)
I0626 18:04:28.713333  6673 sgd_solver.cpp:106] Iteration 19820, lr = 0.0002
I0626 18:06:06.664597  6673 solver.cpp:228] Iteration 19840, loss = 0.105675
I0626 18:06:06.664620  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:06:06.664628  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195552 (* 1 = 0.0195552 loss)
I0626 18:06:06.664630  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0228555 (* 1 = 0.0228555 loss)
I0626 18:06:06.664634  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116343 (* 1 = 0.00116343 loss)
I0626 18:06:06.664638  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00592861 (* 1 = 0.00592861 loss)
I0626 18:06:06.664643  6673 sgd_solver.cpp:106] Iteration 19840, lr = 0.0002
I0626 18:07:44.593461  6673 solver.cpp:228] Iteration 19860, loss = 0.182409
I0626 18:07:44.593488  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 18:07:44.593497  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.028439 (* 1 = 0.028439 loss)
I0626 18:07:44.593500  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0716553 (* 1 = 0.0716553 loss)
I0626 18:07:44.593504  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108651 (* 1 = 0.00108651 loss)
I0626 18:07:44.593508  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00480444 (* 1 = 0.00480444 loss)
I0626 18:07:44.593514  6673 sgd_solver.cpp:106] Iteration 19860, lr = 0.0002
I0626 18:09:22.517652  6673 solver.cpp:228] Iteration 19880, loss = 0.281557
I0626 18:09:22.517675  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 18:09:22.517683  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.057415 (* 1 = 0.057415 loss)
I0626 18:09:22.517688  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.148585 (* 1 = 0.148585 loss)
I0626 18:09:22.517690  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0382031 (* 1 = 0.0382031 loss)
I0626 18:09:22.517694  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111136 (* 1 = 0.111136 loss)
I0626 18:09:22.517699  6673 sgd_solver.cpp:106] Iteration 19880, lr = 0.0002
I0626 18:11:00.442312  6673 solver.cpp:228] Iteration 19900, loss = 0.189948
I0626 18:11:00.442335  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:11:00.442342  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278468 (* 1 = 0.0278468 loss)
I0626 18:11:00.442345  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0254927 (* 1 = 0.0254927 loss)
I0626 18:11:00.442349  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000470414 (* 1 = 0.000470414 loss)
I0626 18:11:00.442353  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00820747 (* 1 = 0.00820747 loss)
I0626 18:11:00.442358  6673 sgd_solver.cpp:106] Iteration 19900, lr = 0.0002
I0626 18:12:38.366549  6673 solver.cpp:228] Iteration 19920, loss = 0.0959527
I0626 18:12:38.366576  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:12:38.366585  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0255566 (* 1 = 0.0255566 loss)
I0626 18:12:38.366590  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.028113 (* 1 = 0.028113 loss)
I0626 18:12:38.366595  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.58161e-05 (* 1 = 3.58161e-05 loss)
I0626 18:12:38.366600  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00500471 (* 1 = 0.00500471 loss)
I0626 18:12:38.366605  6673 sgd_solver.cpp:106] Iteration 19920, lr = 0.0002
I0626 18:14:16.319677  6673 solver.cpp:228] Iteration 19940, loss = 0.27573
I0626 18:14:16.319701  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:14:16.319710  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0322986 (* 1 = 0.0322986 loss)
I0626 18:14:16.319713  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0527768 (* 1 = 0.0527768 loss)
I0626 18:14:16.319717  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000314158 (* 1 = 0.000314158 loss)
I0626 18:14:16.319721  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107248 (* 1 = 0.0107248 loss)
I0626 18:14:16.319725  6673 sgd_solver.cpp:106] Iteration 19940, lr = 0.0002
I0626 18:15:54.246186  6673 solver.cpp:228] Iteration 19960, loss = 0.160009
I0626 18:15:54.246210  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:15:54.246217  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000155651 (* 1 = 0.000155651 loss)
I0626 18:15:54.246222  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0408407 (* 1 = 0.0408407 loss)
I0626 18:15:54.246227  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0258916 (* 1 = 0.0258916 loss)
I0626 18:15:54.246229  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104453 (* 1 = 0.0104453 loss)
I0626 18:15:54.246234  6673 sgd_solver.cpp:106] Iteration 19960, lr = 0.0002
I0626 18:17:32.173573  6673 solver.cpp:228] Iteration 19980, loss = 0.156167
I0626 18:17:32.173596  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 18:17:32.173604  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0421023 (* 1 = 0.0421023 loss)
I0626 18:17:32.173607  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.127576 (* 1 = 0.127576 loss)
I0626 18:17:32.173611  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179841 (* 1 = 0.00179841 loss)
I0626 18:17:32.173614  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198641 (* 1 = 0.0198641 loss)
I0626 18:17:32.173619  6673 sgd_solver.cpp:106] Iteration 19980, lr = 0.0002
speed: 4.918s / iter
I0626 18:19:05.519035  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_20000.caffemodel
I0626 18:19:10.897348  6673 solver.cpp:228] Iteration 20000, loss = 0.146578
I0626 18:19:10.897372  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:19:10.897380  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0494129 (* 1 = 0.0494129 loss)
I0626 18:19:10.897387  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0417825 (* 1 = 0.0417825 loss)
I0626 18:19:10.897392  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000466616 (* 1 = 0.000466616 loss)
I0626 18:19:10.897397  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00914585 (* 1 = 0.00914585 loss)
I0626 18:19:10.897403  6673 sgd_solver.cpp:106] Iteration 20000, lr = 0.0002
I0626 18:20:48.854007  6673 solver.cpp:228] Iteration 20020, loss = 0.152886
I0626 18:20:48.854032  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 18:20:48.854041  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0941065 (* 1 = 0.0941065 loss)
I0626 18:20:48.854048  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.197984 (* 1 = 0.197984 loss)
I0626 18:20:48.854054  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217282 (* 1 = 0.00217282 loss)
I0626 18:20:48.854060  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249981 (* 1 = 0.0249981 loss)
I0626 18:20:48.854066  6673 sgd_solver.cpp:106] Iteration 20020, lr = 0.0002
I0626 18:22:26.803082  6673 solver.cpp:228] Iteration 20040, loss = 0.0803919
I0626 18:22:26.803105  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:22:26.803113  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142969 (* 1 = 0.0142969 loss)
I0626 18:22:26.803117  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0341608 (* 1 = 0.0341608 loss)
I0626 18:22:26.803122  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118639 (* 1 = 0.00118639 loss)
I0626 18:22:26.803125  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00803579 (* 1 = 0.00803579 loss)
I0626 18:22:26.803130  6673 sgd_solver.cpp:106] Iteration 20040, lr = 0.0002
I0626 18:24:04.724071  6673 solver.cpp:228] Iteration 20060, loss = 0.190126
I0626 18:24:04.724093  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:24:04.724100  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108982 (* 1 = 0.0108982 loss)
I0626 18:24:04.724104  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0336461 (* 1 = 0.0336461 loss)
I0626 18:24:04.724107  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266985 (* 1 = 0.0266985 loss)
I0626 18:24:04.724112  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488967 (* 1 = 0.0488967 loss)
I0626 18:24:04.724115  6673 sgd_solver.cpp:106] Iteration 20060, lr = 0.0002
I0626 18:25:42.689656  6673 solver.cpp:228] Iteration 20080, loss = 0.177993
I0626 18:25:42.689678  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:25:42.689685  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443732 (* 1 = 0.0443732 loss)
I0626 18:25:42.689689  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0380766 (* 1 = 0.0380766 loss)
I0626 18:25:42.689693  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000339598 (* 1 = 0.000339598 loss)
I0626 18:25:42.689697  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00203277 (* 1 = 0.00203277 loss)
I0626 18:25:42.689702  6673 sgd_solver.cpp:106] Iteration 20080, lr = 0.0002
I0626 18:27:20.622956  6673 solver.cpp:228] Iteration 20100, loss = 0.215239
I0626 18:27:20.622983  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 18:27:20.622990  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.145723 (* 1 = 0.145723 loss)
I0626 18:27:20.622994  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.237892 (* 1 = 0.237892 loss)
I0626 18:27:20.622998  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194256 (* 1 = 0.00194256 loss)
I0626 18:27:20.623003  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0526642 (* 1 = 0.0526642 loss)
I0626 18:27:20.623008  6673 sgd_solver.cpp:106] Iteration 20100, lr = 0.0002
I0626 18:28:58.555869  6673 solver.cpp:228] Iteration 20120, loss = 0.158564
I0626 18:28:58.555894  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 18:28:58.555902  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.06807 (* 1 = 0.06807 loss)
I0626 18:28:58.555905  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102494 (* 1 = 0.102494 loss)
I0626 18:28:58.555909  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000392322 (* 1 = 0.000392322 loss)
I0626 18:28:58.555912  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189688 (* 1 = 0.0189688 loss)
I0626 18:28:58.555917  6673 sgd_solver.cpp:106] Iteration 20120, lr = 0.0002
I0626 18:30:36.499639  6673 solver.cpp:228] Iteration 20140, loss = 0.116906
I0626 18:30:36.499662  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:30:36.499670  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178963 (* 1 = 0.0178963 loss)
I0626 18:30:36.499675  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0445859 (* 1 = 0.0445859 loss)
I0626 18:30:36.499678  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.73959e-05 (* 1 = 7.73959e-05 loss)
I0626 18:30:36.499682  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00647091 (* 1 = 0.00647091 loss)
I0626 18:30:36.499686  6673 sgd_solver.cpp:106] Iteration 20140, lr = 0.0002
I0626 18:32:14.425324  6673 solver.cpp:228] Iteration 20160, loss = 0.119867
I0626 18:32:14.425348  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:32:14.425355  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0853855 (* 1 = 0.0853855 loss)
I0626 18:32:14.425359  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0804233 (* 1 = 0.0804233 loss)
I0626 18:32:14.425364  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000816514 (* 1 = 0.000816514 loss)
I0626 18:32:14.425367  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126181 (* 1 = 0.0126181 loss)
I0626 18:32:14.425372  6673 sgd_solver.cpp:106] Iteration 20160, lr = 0.0002
I0626 18:33:52.410073  6673 solver.cpp:228] Iteration 20180, loss = 0.153217
I0626 18:33:52.410095  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 18:33:52.410104  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.139111 (* 1 = 0.139111 loss)
I0626 18:33:52.410109  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.145461 (* 1 = 0.145461 loss)
I0626 18:33:52.410114  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179745 (* 1 = 0.0179745 loss)
I0626 18:33:52.410120  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310551 (* 1 = 0.0310551 loss)
I0626 18:33:52.410125  6673 sgd_solver.cpp:106] Iteration 20180, lr = 0.0002
speed: 4.918s / iter
I0626 18:35:30.328721  6673 solver.cpp:228] Iteration 20200, loss = 0.215902
I0626 18:35:30.328742  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:35:30.328748  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.021726 (* 1 = 0.021726 loss)
I0626 18:35:30.328752  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0227073 (* 1 = 0.0227073 loss)
I0626 18:35:30.328755  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016779 (* 1 = 0.0016779 loss)
I0626 18:35:30.328759  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000938356 (* 1 = 0.000938356 loss)
I0626 18:35:30.328763  6673 sgd_solver.cpp:106] Iteration 20200, lr = 0.0002
I0626 18:37:08.242668  6673 solver.cpp:228] Iteration 20220, loss = 0.120199
I0626 18:37:08.242693  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 18:37:08.242702  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0127002 (* 1 = 0.0127002 loss)
I0626 18:37:08.242705  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0224558 (* 1 = 0.0224558 loss)
I0626 18:37:08.242709  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.42177e-05 (* 1 = 7.42177e-05 loss)
I0626 18:37:08.242713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00402556 (* 1 = 0.00402556 loss)
I0626 18:37:08.242718  6673 sgd_solver.cpp:106] Iteration 20220, lr = 0.0002
I0626 18:38:46.158550  6673 solver.cpp:228] Iteration 20240, loss = 0.149115
I0626 18:38:46.158572  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:38:46.158581  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233361 (* 1 = 0.0233361 loss)
I0626 18:38:46.158584  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0471695 (* 1 = 0.0471695 loss)
I0626 18:38:46.158588  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236973 (* 1 = 0.00236973 loss)
I0626 18:38:46.158592  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013928 (* 1 = 0.013928 loss)
I0626 18:38:46.158597  6673 sgd_solver.cpp:106] Iteration 20240, lr = 0.0002
I0626 18:40:24.088737  6673 solver.cpp:228] Iteration 20260, loss = 0.15566
I0626 18:40:24.088762  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:40:24.088769  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00454315 (* 1 = 0.00454315 loss)
I0626 18:40:24.088773  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0259541 (* 1 = 0.0259541 loss)
I0626 18:40:24.088778  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000358803 (* 1 = 0.000358803 loss)
I0626 18:40:24.088781  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179254 (* 1 = 0.0179254 loss)
I0626 18:40:24.088786  6673 sgd_solver.cpp:106] Iteration 20260, lr = 0.0002
I0626 18:42:02.024320  6673 solver.cpp:228] Iteration 20280, loss = 0.185409
I0626 18:42:02.024348  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 18:42:02.024355  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147678 (* 1 = 0.0147678 loss)
I0626 18:42:02.024359  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00749453 (* 1 = 0.00749453 loss)
I0626 18:42:02.024363  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000614312 (* 1 = 0.000614312 loss)
I0626 18:42:02.024368  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114523 (* 1 = 0.0114523 loss)
I0626 18:42:02.024374  6673 sgd_solver.cpp:106] Iteration 20280, lr = 0.0002
I0626 18:43:39.941181  6673 solver.cpp:228] Iteration 20300, loss = 0.151099
I0626 18:43:39.941205  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 18:43:39.941210  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0115854 (* 1 = 0.0115854 loss)
I0626 18:43:39.941215  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0377967 (* 1 = 0.0377967 loss)
I0626 18:43:39.941218  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000365531 (* 1 = 0.000365531 loss)
I0626 18:43:39.941221  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00519797 (* 1 = 0.00519797 loss)
I0626 18:43:39.941226  6673 sgd_solver.cpp:106] Iteration 20300, lr = 0.0002
I0626 18:45:17.811561  6673 solver.cpp:228] Iteration 20320, loss = 0.115915
I0626 18:45:17.811586  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 18:45:17.811595  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.13234 (* 1 = 0.13234 loss)
I0626 18:45:17.811599  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.229555 (* 1 = 0.229555 loss)
I0626 18:45:17.811604  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157752 (* 1 = 0.00157752 loss)
I0626 18:45:17.811610  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281236 (* 1 = 0.0281236 loss)
I0626 18:45:17.811615  6673 sgd_solver.cpp:106] Iteration 20320, lr = 0.0002
I0626 18:46:55.737653  6673 solver.cpp:228] Iteration 20340, loss = 0.154318
I0626 18:46:55.737676  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 18:46:55.737684  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0127005 (* 1 = 0.0127005 loss)
I0626 18:46:55.737689  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0524694 (* 1 = 0.0524694 loss)
I0626 18:46:55.737694  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00932603 (* 1 = 0.00932603 loss)
I0626 18:46:55.737699  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00776869 (* 1 = 0.00776869 loss)
I0626 18:46:55.737702  6673 sgd_solver.cpp:106] Iteration 20340, lr = 0.0002
I0626 18:48:33.714292  6673 solver.cpp:228] Iteration 20360, loss = 0.361842
I0626 18:48:33.714314  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 18:48:33.714321  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0487888 (* 1 = 0.0487888 loss)
I0626 18:48:33.714325  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.127967 (* 1 = 0.127967 loss)
I0626 18:48:33.714329  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000371843 (* 1 = 0.000371843 loss)
I0626 18:48:33.714332  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00949119 (* 1 = 0.00949119 loss)
I0626 18:48:33.714336  6673 sgd_solver.cpp:106] Iteration 20360, lr = 0.0002
I0626 18:50:11.620007  6673 solver.cpp:228] Iteration 20380, loss = 0.357301
I0626 18:50:11.620033  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 18:50:11.620041  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.12415 (* 1 = 0.12415 loss)
I0626 18:50:11.620048  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.260007 (* 1 = 0.260007 loss)
I0626 18:50:11.620052  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00252582 (* 1 = 0.00252582 loss)
I0626 18:50:11.620057  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0313993 (* 1 = 0.0313993 loss)
I0626 18:50:11.620062  6673 sgd_solver.cpp:106] Iteration 20380, lr = 0.0002
speed: 4.917s / iter
I0626 18:51:49.568353  6673 solver.cpp:228] Iteration 20400, loss = 0.191865
I0626 18:51:49.568377  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:51:49.568384  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0462887 (* 1 = 0.0462887 loss)
I0626 18:51:49.568387  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0232359 (* 1 = 0.0232359 loss)
I0626 18:51:49.568392  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000105481 (* 1 = 0.000105481 loss)
I0626 18:51:49.568394  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229218 (* 1 = 0.00229218 loss)
I0626 18:51:49.568399  6673 sgd_solver.cpp:106] Iteration 20400, lr = 0.0002
I0626 18:53:27.520228  6673 solver.cpp:228] Iteration 20420, loss = 0.176205
I0626 18:53:27.520252  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 18:53:27.520261  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155874 (* 1 = 0.0155874 loss)
I0626 18:53:27.520264  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0802563 (* 1 = 0.0802563 loss)
I0626 18:53:27.520268  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019914 (* 1 = 0.0019914 loss)
I0626 18:53:27.520272  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020093 (* 1 = 0.020093 loss)
I0626 18:53:27.520277  6673 sgd_solver.cpp:106] Iteration 20420, lr = 0.0002
I0626 18:55:05.446861  6673 solver.cpp:228] Iteration 20440, loss = 0.118788
I0626 18:55:05.446884  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 18:55:05.446890  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0103299 (* 1 = 0.0103299 loss)
I0626 18:55:05.446894  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0159918 (* 1 = 0.0159918 loss)
I0626 18:55:05.446898  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000138726 (* 1 = 0.000138726 loss)
I0626 18:55:05.446902  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00230644 (* 1 = 0.00230644 loss)
I0626 18:55:05.446905  6673 sgd_solver.cpp:106] Iteration 20440, lr = 0.0002
I0626 18:56:43.345964  6673 solver.cpp:228] Iteration 20460, loss = 0.102331
I0626 18:56:43.345988  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:56:43.345994  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0208731 (* 1 = 0.0208731 loss)
I0626 18:56:43.345998  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0294519 (* 1 = 0.0294519 loss)
I0626 18:56:43.346001  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162387 (* 1 = 0.00162387 loss)
I0626 18:56:43.346005  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00241657 (* 1 = 0.00241657 loss)
I0626 18:56:43.346009  6673 sgd_solver.cpp:106] Iteration 20460, lr = 0.0002
I0626 18:58:21.285419  6673 solver.cpp:228] Iteration 20480, loss = 0.108545
I0626 18:58:21.285442  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 18:58:21.285449  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121757 (* 1 = 0.0121757 loss)
I0626 18:58:21.285452  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0219282 (* 1 = 0.0219282 loss)
I0626 18:58:21.285455  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000237135 (* 1 = 0.000237135 loss)
I0626 18:58:21.285459  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00763785 (* 1 = 0.00763785 loss)
I0626 18:58:21.285465  6673 sgd_solver.cpp:106] Iteration 20480, lr = 0.0002
I0626 18:59:59.196152  6673 solver.cpp:228] Iteration 20500, loss = 0.257921
I0626 18:59:59.196178  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 18:59:59.196187  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0626475 (* 1 = 0.0626475 loss)
I0626 18:59:59.196192  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.155885 (* 1 = 0.155885 loss)
I0626 18:59:59.196197  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00621852 (* 1 = 0.00621852 loss)
I0626 18:59:59.196202  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0579634 (* 1 = 0.0579634 loss)
I0626 18:59:59.196208  6673 sgd_solver.cpp:106] Iteration 20500, lr = 0.0002
I0626 19:01:37.173985  6673 solver.cpp:228] Iteration 20520, loss = 0.185441
I0626 19:01:37.174006  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 19:01:37.174012  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229525 (* 1 = 0.0229525 loss)
I0626 19:01:37.174016  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0943028 (* 1 = 0.0943028 loss)
I0626 19:01:37.174021  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000267558 (* 1 = 0.000267558 loss)
I0626 19:01:37.174023  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00960171 (* 1 = 0.00960171 loss)
I0626 19:01:37.174028  6673 sgd_solver.cpp:106] Iteration 20520, lr = 0.0002
I0626 19:03:15.119379  6673 solver.cpp:228] Iteration 20540, loss = 0.147205
I0626 19:03:15.119402  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:03:15.119410  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00895056 (* 1 = 0.00895056 loss)
I0626 19:03:15.119415  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0218764 (* 1 = 0.0218764 loss)
I0626 19:03:15.119418  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000668683 (* 1 = 0.000668683 loss)
I0626 19:03:15.119422  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.002627 (* 1 = 0.002627 loss)
I0626 19:03:15.119426  6673 sgd_solver.cpp:106] Iteration 20540, lr = 0.0002
I0626 19:04:53.028388  6673 solver.cpp:228] Iteration 20560, loss = 0.323417
I0626 19:04:53.028411  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 19:04:53.028419  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0255147 (* 1 = 0.0255147 loss)
I0626 19:04:53.028424  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0877436 (* 1 = 0.0877436 loss)
I0626 19:04:53.028427  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000163264 (* 1 = 0.000163264 loss)
I0626 19:04:53.028431  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939929 (* 1 = 0.00939929 loss)
I0626 19:04:53.028436  6673 sgd_solver.cpp:106] Iteration 20560, lr = 0.0002
I0626 19:06:30.947083  6673 solver.cpp:228] Iteration 20580, loss = 0.159386
I0626 19:06:30.947106  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:06:30.947114  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0109736 (* 1 = 0.0109736 loss)
I0626 19:06:30.947118  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.019786 (* 1 = 0.019786 loss)
I0626 19:06:30.947121  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.003222 (* 1 = 0.003222 loss)
I0626 19:06:30.947124  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00997953 (* 1 = 0.00997953 loss)
I0626 19:06:30.947129  6673 sgd_solver.cpp:106] Iteration 20580, lr = 0.0002
speed: 4.917s / iter
I0626 19:08:08.878317  6673 solver.cpp:228] Iteration 20600, loss = 0.279169
I0626 19:08:08.878346  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:08:08.878355  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.053306 (* 1 = 0.053306 loss)
I0626 19:08:08.878358  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0456919 (* 1 = 0.0456919 loss)
I0626 19:08:08.878361  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000293062 (* 1 = 0.000293062 loss)
I0626 19:08:08.878365  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101552 (* 1 = 0.0101552 loss)
I0626 19:08:08.878371  6673 sgd_solver.cpp:106] Iteration 20600, lr = 0.0002
I0626 19:09:46.828608  6673 solver.cpp:228] Iteration 20620, loss = 0.212696
I0626 19:09:46.828636  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0626 19:09:46.828644  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.276986 (* 1 = 0.276986 loss)
I0626 19:09:46.828649  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.304635 (* 1 = 0.304635 loss)
I0626 19:09:46.828652  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00451321 (* 1 = 0.00451321 loss)
I0626 19:09:46.828656  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0520778 (* 1 = 0.0520778 loss)
I0626 19:09:46.828662  6673 sgd_solver.cpp:106] Iteration 20620, lr = 0.0002
I0626 19:11:24.756871  6673 solver.cpp:228] Iteration 20640, loss = 0.204607
I0626 19:11:24.756897  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 19:11:24.756904  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.096546 (* 1 = 0.096546 loss)
I0626 19:11:24.756908  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.126369 (* 1 = 0.126369 loss)
I0626 19:11:24.756912  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157 (* 1 = 0.00157 loss)
I0626 19:11:24.756916  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176202 (* 1 = 0.0176202 loss)
I0626 19:11:24.756920  6673 sgd_solver.cpp:106] Iteration 20640, lr = 0.0002
I0626 19:13:02.700438  6673 solver.cpp:228] Iteration 20660, loss = 0.144605
I0626 19:13:02.700462  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 19:13:02.700470  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0864307 (* 1 = 0.0864307 loss)
I0626 19:13:02.700474  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.210221 (* 1 = 0.210221 loss)
I0626 19:13:02.700479  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817133 (* 1 = 0.00817133 loss)
I0626 19:13:02.700482  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418224 (* 1 = 0.0418224 loss)
I0626 19:13:02.700487  6673 sgd_solver.cpp:106] Iteration 20660, lr = 0.0002
I0626 19:14:40.631475  6673 solver.cpp:228] Iteration 20680, loss = 0.146677
I0626 19:14:40.631498  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:14:40.631505  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244148 (* 1 = 0.0244148 loss)
I0626 19:14:40.631510  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0209024 (* 1 = 0.0209024 loss)
I0626 19:14:40.631513  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.19532e-05 (* 1 = 8.19532e-05 loss)
I0626 19:14:40.631516  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00110165 (* 1 = 0.00110165 loss)
I0626 19:14:40.631521  6673 sgd_solver.cpp:106] Iteration 20680, lr = 0.0002
I0626 19:16:18.549316  6673 solver.cpp:228] Iteration 20700, loss = 0.114854
I0626 19:16:18.549340  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:16:18.549347  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113104 (* 1 = 0.0113104 loss)
I0626 19:16:18.549351  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0365441 (* 1 = 0.0365441 loss)
I0626 19:16:18.549355  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000371528 (* 1 = 0.000371528 loss)
I0626 19:16:18.549360  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00309921 (* 1 = 0.00309921 loss)
I0626 19:16:18.549365  6673 sgd_solver.cpp:106] Iteration 20700, lr = 0.0002
I0626 19:17:56.488782  6673 solver.cpp:228] Iteration 20720, loss = 0.277665
I0626 19:17:56.488806  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:17:56.488812  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000272966 (* 1 = 0.000272966 loss)
I0626 19:17:56.488816  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0242426 (* 1 = 0.0242426 loss)
I0626 19:17:56.488819  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0275521 (* 1 = 0.0275521 loss)
I0626 19:17:56.488822  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108306 (* 1 = 0.0108306 loss)
I0626 19:17:56.488827  6673 sgd_solver.cpp:106] Iteration 20720, lr = 0.0002
I0626 19:19:34.407754  6673 solver.cpp:228] Iteration 20740, loss = 0.113191
I0626 19:19:34.407778  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 19:19:34.407784  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316299 (* 1 = 0.0316299 loss)
I0626 19:19:34.407788  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0520946 (* 1 = 0.0520946 loss)
I0626 19:19:34.407791  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00468406 (* 1 = 0.00468406 loss)
I0626 19:19:34.407795  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00614552 (* 1 = 0.00614552 loss)
I0626 19:19:34.407799  6673 sgd_solver.cpp:106] Iteration 20740, lr = 0.0002
I0626 19:21:12.311363  6673 solver.cpp:228] Iteration 20760, loss = 0.209474
I0626 19:21:12.311388  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:21:12.311393  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0506966 (* 1 = 0.0506966 loss)
I0626 19:21:12.311398  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0585134 (* 1 = 0.0585134 loss)
I0626 19:21:12.311401  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000248531 (* 1 = 0.000248531 loss)
I0626 19:21:12.311404  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00808741 (* 1 = 0.00808741 loss)
I0626 19:21:12.311409  6673 sgd_solver.cpp:106] Iteration 20760, lr = 0.0002
I0626 19:22:50.214434  6673 solver.cpp:228] Iteration 20780, loss = 0.26998
I0626 19:22:50.214455  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 19:22:50.214462  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0500451 (* 1 = 0.0500451 loss)
I0626 19:22:50.214465  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0710554 (* 1 = 0.0710554 loss)
I0626 19:22:50.214469  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00197316 (* 1 = 0.00197316 loss)
I0626 19:22:50.214473  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126892 (* 1 = 0.0126892 loss)
I0626 19:22:50.214476  6673 sgd_solver.cpp:106] Iteration 20780, lr = 0.0002
speed: 4.917s / iter
I0626 19:24:28.134395  6673 solver.cpp:228] Iteration 20800, loss = 0.140669
I0626 19:24:28.134418  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 19:24:28.134424  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0794019 (* 1 = 0.0794019 loss)
I0626 19:24:28.134428  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.157484 (* 1 = 0.157484 loss)
I0626 19:24:28.134430  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0019451 (* 1 = 0.0019451 loss)
I0626 19:24:28.134434  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137524 (* 1 = 0.0137524 loss)
I0626 19:24:28.134438  6673 sgd_solver.cpp:106] Iteration 20800, lr = 0.0002
I0626 19:26:06.017704  6673 solver.cpp:228] Iteration 20820, loss = 0.194691
I0626 19:26:06.017729  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:26:06.017737  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707463 (* 1 = 0.0707463 loss)
I0626 19:26:06.017741  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0850778 (* 1 = 0.0850778 loss)
I0626 19:26:06.017745  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115331 (* 1 = 0.00115331 loss)
I0626 19:26:06.017750  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167885 (* 1 = 0.0167885 loss)
I0626 19:26:06.017755  6673 sgd_solver.cpp:106] Iteration 20820, lr = 0.0002
I0626 19:27:43.938488  6673 solver.cpp:228] Iteration 20840, loss = 0.225178
I0626 19:27:43.938513  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 19:27:43.938521  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0503429 (* 1 = 0.0503429 loss)
I0626 19:27:43.938526  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0211903 (* 1 = 0.0211903 loss)
I0626 19:27:43.938531  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.29335e-05 (* 1 = 6.29335e-05 loss)
I0626 19:27:43.938536  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123671 (* 1 = 0.0123671 loss)
I0626 19:27:43.938542  6673 sgd_solver.cpp:106] Iteration 20840, lr = 0.0002
I0626 19:29:21.901195  6673 solver.cpp:228] Iteration 20860, loss = 0.0887233
I0626 19:29:21.901218  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:29:21.901226  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0172192 (* 1 = 0.0172192 loss)
I0626 19:29:21.901229  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0564725 (* 1 = 0.0564725 loss)
I0626 19:29:21.901234  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000302699 (* 1 = 0.000302699 loss)
I0626 19:29:21.901237  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00183682 (* 1 = 0.00183682 loss)
I0626 19:29:21.901243  6673 sgd_solver.cpp:106] Iteration 20860, lr = 0.0002
I0626 19:30:59.832708  6673 solver.cpp:228] Iteration 20880, loss = 0.204931
I0626 19:30:59.832733  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:30:59.832741  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743728 (* 1 = 0.0743728 loss)
I0626 19:30:59.832746  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0627354 (* 1 = 0.0627354 loss)
I0626 19:30:59.832749  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00287509 (* 1 = 0.00287509 loss)
I0626 19:30:59.832753  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00985635 (* 1 = 0.00985635 loss)
I0626 19:30:59.832758  6673 sgd_solver.cpp:106] Iteration 20880, lr = 0.0002
I0626 19:32:37.706482  6673 solver.cpp:228] Iteration 20900, loss = 0.216074
I0626 19:32:37.706506  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 19:32:37.706513  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.122722 (* 1 = 0.122722 loss)
I0626 19:32:37.706517  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.190043 (* 1 = 0.190043 loss)
I0626 19:32:37.706521  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116966 (* 1 = 0.00116966 loss)
I0626 19:32:37.706524  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233684 (* 1 = 0.0233684 loss)
I0626 19:32:37.706529  6673 sgd_solver.cpp:106] Iteration 20900, lr = 0.0002
I0626 19:34:15.758136  6673 solver.cpp:228] Iteration 20920, loss = 0.116638
I0626 19:34:15.758162  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 19:34:15.758168  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0899844 (* 1 = 0.0899844 loss)
I0626 19:34:15.758172  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.16239 (* 1 = 0.16239 loss)
I0626 19:34:15.758177  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0024466 (* 1 = 0.0024466 loss)
I0626 19:34:15.758179  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117007 (* 1 = 0.0117007 loss)
I0626 19:34:15.758184  6673 sgd_solver.cpp:106] Iteration 20920, lr = 0.0002
I0626 19:35:53.791246  6673 solver.cpp:228] Iteration 20940, loss = 0.212338
I0626 19:35:53.791275  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:35:53.791286  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245752 (* 1 = 0.0245752 loss)
I0626 19:35:53.791294  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0733526 (* 1 = 0.0733526 loss)
I0626 19:35:53.791301  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120087 (* 1 = 0.00120087 loss)
I0626 19:35:53.791309  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011532 (* 1 = 0.011532 loss)
I0626 19:35:53.791317  6673 sgd_solver.cpp:106] Iteration 20940, lr = 0.0002
I0626 19:37:31.734732  6673 solver.cpp:228] Iteration 20960, loss = 0.0943506
I0626 19:37:31.734755  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:37:31.734761  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0200764 (* 1 = 0.0200764 loss)
I0626 19:37:31.734764  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0519007 (* 1 = 0.0519007 loss)
I0626 19:37:31.734767  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194603 (* 1 = 0.00194603 loss)
I0626 19:37:31.734771  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00807127 (* 1 = 0.00807127 loss)
I0626 19:37:31.734776  6673 sgd_solver.cpp:106] Iteration 20960, lr = 0.0002
I0626 19:39:09.687541  6673 solver.cpp:228] Iteration 20980, loss = 0.197684
I0626 19:39:09.687566  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:39:09.687572  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0420715 (* 1 = 0.0420715 loss)
I0626 19:39:09.687577  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0584664 (* 1 = 0.0584664 loss)
I0626 19:39:09.687579  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140838 (* 1 = 0.00140838 loss)
I0626 19:39:09.687583  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179508 (* 1 = 0.0179508 loss)
I0626 19:39:09.687588  6673 sgd_solver.cpp:106] Iteration 20980, lr = 0.0002
speed: 4.917s / iter
I0626 19:40:47.870654  6673 solver.cpp:228] Iteration 21000, loss = 0.107051
I0626 19:40:47.870687  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 19:40:47.870694  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0163212 (* 1 = 0.0163212 loss)
I0626 19:40:47.870699  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0136587 (* 1 = 0.0136587 loss)
I0626 19:40:47.870703  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292345 (* 1 = 0.00292345 loss)
I0626 19:40:47.870707  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122119 (* 1 = 0.0122119 loss)
I0626 19:40:47.870712  6673 sgd_solver.cpp:106] Iteration 21000, lr = 0.0002
I0626 19:42:25.877420  6673 solver.cpp:228] Iteration 21020, loss = 0.267424
I0626 19:42:25.877449  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 19:42:25.877456  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0368304 (* 1 = 0.0368304 loss)
I0626 19:42:25.877460  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.146582 (* 1 = 0.146582 loss)
I0626 19:42:25.877463  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017483 (* 1 = 0.017483 loss)
I0626 19:42:25.877466  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115892 (* 1 = 0.115892 loss)
I0626 19:42:25.877471  6673 sgd_solver.cpp:106] Iteration 21020, lr = 0.0002
I0626 19:44:03.896682  6673 solver.cpp:228] Iteration 21040, loss = 0.132862
I0626 19:44:03.896708  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:44:03.896715  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140757 (* 1 = 0.0140757 loss)
I0626 19:44:03.896719  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.031168 (* 1 = 0.031168 loss)
I0626 19:44:03.896723  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00295018 (* 1 = 0.00295018 loss)
I0626 19:44:03.896726  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00168453 (* 1 = 0.00168453 loss)
I0626 19:44:03.896731  6673 sgd_solver.cpp:106] Iteration 21040, lr = 0.0002
I0626 19:45:41.890333  6673 solver.cpp:228] Iteration 21060, loss = 0.127892
I0626 19:45:41.890360  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 19:45:41.890369  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476961 (* 1 = 0.0476961 loss)
I0626 19:45:41.890374  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.210166 (* 1 = 0.210166 loss)
I0626 19:45:41.890379  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00495644 (* 1 = 0.00495644 loss)
I0626 19:45:41.890383  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185387 (* 1 = 0.0185387 loss)
I0626 19:45:41.890389  6673 sgd_solver.cpp:106] Iteration 21060, lr = 0.0002
I0626 19:47:19.845491  6673 solver.cpp:228] Iteration 21080, loss = 0.290546
I0626 19:47:19.845515  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 19:47:19.845521  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0753752 (* 1 = 0.0753752 loss)
I0626 19:47:19.845525  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.134049 (* 1 = 0.134049 loss)
I0626 19:47:19.845528  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000332926 (* 1 = 0.000332926 loss)
I0626 19:47:19.845532  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00982729 (* 1 = 0.00982729 loss)
I0626 19:47:19.845536  6673 sgd_solver.cpp:106] Iteration 21080, lr = 0.0002
I0626 19:48:57.840929  6673 solver.cpp:228] Iteration 21100, loss = 0.135495
I0626 19:48:57.840958  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:48:57.840966  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.023534 (* 1 = 0.023534 loss)
I0626 19:48:57.840971  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0399616 (* 1 = 0.0399616 loss)
I0626 19:48:57.840975  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000409113 (* 1 = 0.000409113 loss)
I0626 19:48:57.840979  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00311273 (* 1 = 0.00311273 loss)
I0626 19:48:57.840984  6673 sgd_solver.cpp:106] Iteration 21100, lr = 0.0002
I0626 19:50:35.803984  6673 solver.cpp:228] Iteration 21120, loss = 0.162825
I0626 19:50:35.804008  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:50:35.804016  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0370432 (* 1 = 0.0370432 loss)
I0626 19:50:35.804020  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.041194 (* 1 = 0.041194 loss)
I0626 19:50:35.804024  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000356192 (* 1 = 0.000356192 loss)
I0626 19:50:35.804028  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00374504 (* 1 = 0.00374504 loss)
I0626 19:50:35.804033  6673 sgd_solver.cpp:106] Iteration 21120, lr = 0.0002
I0626 19:52:13.806411  6673 solver.cpp:228] Iteration 21140, loss = 0.215106
I0626 19:52:13.806438  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 19:52:13.806447  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413827 (* 1 = 0.0413827 loss)
I0626 19:52:13.806452  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.12533 (* 1 = 0.12533 loss)
I0626 19:52:13.806455  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00632409 (* 1 = 0.00632409 loss)
I0626 19:52:13.806458  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164935 (* 1 = 0.0164935 loss)
I0626 19:52:13.806464  6673 sgd_solver.cpp:106] Iteration 21140, lr = 0.0002
I0626 19:53:51.810706  6673 solver.cpp:228] Iteration 21160, loss = 0.210448
I0626 19:53:51.810732  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0626 19:53:51.810739  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.294992 (* 1 = 0.294992 loss)
I0626 19:53:51.810745  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.326591 (* 1 = 0.326591 loss)
I0626 19:53:51.810747  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0269652 (* 1 = 0.0269652 loss)
I0626 19:53:51.810751  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.206264 (* 1 = 0.206264 loss)
I0626 19:53:51.810756  6673 sgd_solver.cpp:106] Iteration 21160, lr = 0.0002
I0626 19:55:29.796394  6673 solver.cpp:228] Iteration 21180, loss = 0.114352
I0626 19:55:29.796419  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 19:55:29.796425  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536101 (* 1 = 0.0536101 loss)
I0626 19:55:29.796429  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0369983 (* 1 = 0.0369983 loss)
I0626 19:55:29.796433  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000895367 (* 1 = 0.000895367 loss)
I0626 19:55:29.796437  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00543724 (* 1 = 0.00543724 loss)
I0626 19:55:29.796440  6673 sgd_solver.cpp:106] Iteration 21180, lr = 0.0002
speed: 4.917s / iter
I0626 19:57:07.777835  6673 solver.cpp:228] Iteration 21200, loss = 0.164333
I0626 19:57:07.777859  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0626 19:57:07.777868  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.288957 (* 1 = 0.288957 loss)
I0626 19:57:07.777871  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.515641 (* 1 = 0.515641 loss)
I0626 19:57:07.777875  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00602267 (* 1 = 0.00602267 loss)
I0626 19:57:07.777879  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0766848 (* 1 = 0.0766848 loss)
I0626 19:57:07.777884  6673 sgd_solver.cpp:106] Iteration 21200, lr = 0.0002
I0626 19:58:45.757621  6673 solver.cpp:228] Iteration 21220, loss = 0.175836
I0626 19:58:45.757643  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 19:58:45.757650  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0905598 (* 1 = 0.0905598 loss)
I0626 19:58:45.757654  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.17286 (* 1 = 0.17286 loss)
I0626 19:58:45.757658  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00117611 (* 1 = 0.00117611 loss)
I0626 19:58:45.757663  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304069 (* 1 = 0.0304069 loss)
I0626 19:58:45.757666  6673 sgd_solver.cpp:106] Iteration 21220, lr = 0.0002
I0626 20:00:23.792853  6673 solver.cpp:228] Iteration 21240, loss = 0.232325
I0626 20:00:23.792881  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0626 20:00:23.792891  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.168089 (* 1 = 0.168089 loss)
I0626 20:00:23.792896  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.256297 (* 1 = 0.256297 loss)
I0626 20:00:23.792901  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217733 (* 1 = 0.00217733 loss)
I0626 20:00:23.792907  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0422276 (* 1 = 0.0422276 loss)
I0626 20:00:23.792914  6673 sgd_solver.cpp:106] Iteration 21240, lr = 0.0002
I0626 20:02:01.777207  6673 solver.cpp:228] Iteration 21260, loss = 0.173504
I0626 20:02:01.777235  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:02:01.777242  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0119957 (* 1 = 0.0119957 loss)
I0626 20:02:01.777246  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0503125 (* 1 = 0.0503125 loss)
I0626 20:02:01.777251  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000134819 (* 1 = 0.000134819 loss)
I0626 20:02:01.777254  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00365912 (* 1 = 0.00365912 loss)
I0626 20:02:01.777261  6673 sgd_solver.cpp:106] Iteration 21260, lr = 0.0002
I0626 20:03:39.780447  6673 solver.cpp:228] Iteration 21280, loss = 0.274698
I0626 20:03:39.780472  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0626 20:03:39.780478  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.295188 (* 1 = 0.295188 loss)
I0626 20:03:39.780481  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.32423 (* 1 = 0.32423 loss)
I0626 20:03:39.780485  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169504 (* 1 = 0.0169504 loss)
I0626 20:03:39.780488  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0662462 (* 1 = 0.0662462 loss)
I0626 20:03:39.780493  6673 sgd_solver.cpp:106] Iteration 21280, lr = 0.0002
I0626 20:05:17.843407  6673 solver.cpp:228] Iteration 21300, loss = 0.248582
I0626 20:05:17.843430  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 20:05:17.843436  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0569302 (* 1 = 0.0569302 loss)
I0626 20:05:17.843441  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.116039 (* 1 = 0.116039 loss)
I0626 20:05:17.843443  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000502927 (* 1 = 0.000502927 loss)
I0626 20:05:17.843446  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173816 (* 1 = 0.0173816 loss)
I0626 20:05:17.843451  6673 sgd_solver.cpp:106] Iteration 21300, lr = 0.0002
I0626 20:06:55.892990  6673 solver.cpp:228] Iteration 21320, loss = 0.142353
I0626 20:06:55.893019  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:06:55.893028  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205257 (* 1 = 0.0205257 loss)
I0626 20:06:55.893034  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0186937 (* 1 = 0.0186937 loss)
I0626 20:06:55.893039  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000323074 (* 1 = 0.000323074 loss)
I0626 20:06:55.893045  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00382411 (* 1 = 0.00382411 loss)
I0626 20:06:55.893051  6673 sgd_solver.cpp:106] Iteration 21320, lr = 0.0002
I0626 20:08:33.835717  6673 solver.cpp:228] Iteration 21340, loss = 0.174765
I0626 20:08:33.835741  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:08:33.835749  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.019063 (* 1 = 0.019063 loss)
I0626 20:08:33.835753  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0221175 (* 1 = 0.0221175 loss)
I0626 20:08:33.835757  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000532467 (* 1 = 0.000532467 loss)
I0626 20:08:33.835762  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00663885 (* 1 = 0.00663885 loss)
I0626 20:08:33.835765  6673 sgd_solver.cpp:106] Iteration 21340, lr = 0.0002
I0626 20:10:11.764235  6673 solver.cpp:228] Iteration 21360, loss = 0.186437
I0626 20:10:11.764258  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:10:11.764266  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0277342 (* 1 = 0.0277342 loss)
I0626 20:10:11.764269  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0189257 (* 1 = 0.0189257 loss)
I0626 20:10:11.764272  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000313243 (* 1 = 0.000313243 loss)
I0626 20:10:11.764276  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00252826 (* 1 = 0.00252826 loss)
I0626 20:10:11.764281  6673 sgd_solver.cpp:106] Iteration 21360, lr = 0.0002
I0626 20:11:49.845357  6673 solver.cpp:228] Iteration 21380, loss = 0.171217
I0626 20:11:49.845382  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0626 20:11:49.845388  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.122813 (* 1 = 0.122813 loss)
I0626 20:11:49.845392  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.196525 (* 1 = 0.196525 loss)
I0626 20:11:49.845396  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00610539 (* 1 = 0.00610539 loss)
I0626 20:11:49.845401  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0470478 (* 1 = 0.0470478 loss)
I0626 20:11:49.845404  6673 sgd_solver.cpp:106] Iteration 21380, lr = 0.0002
speed: 4.917s / iter
I0626 20:13:27.869204  6673 solver.cpp:228] Iteration 21400, loss = 0.23434
I0626 20:13:27.869230  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:13:27.869237  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.011127 (* 1 = 0.011127 loss)
I0626 20:13:27.869242  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0423032 (* 1 = 0.0423032 loss)
I0626 20:13:27.869246  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.27012e-05 (* 1 = 7.27012e-05 loss)
I0626 20:13:27.869249  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00188618 (* 1 = 0.00188618 loss)
I0626 20:13:27.869254  6673 sgd_solver.cpp:106] Iteration 21400, lr = 0.0002
I0626 20:15:05.948428  6673 solver.cpp:228] Iteration 21420, loss = 0.129994
I0626 20:15:05.948462  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:15:05.948472  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226837 (* 1 = 0.0226837 loss)
I0626 20:15:05.948478  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0655616 (* 1 = 0.0655616 loss)
I0626 20:15:05.948484  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000102619 (* 1 = 0.000102619 loss)
I0626 20:15:05.948490  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00807164 (* 1 = 0.00807164 loss)
I0626 20:15:05.948498  6673 sgd_solver.cpp:106] Iteration 21420, lr = 0.0002
I0626 20:16:43.982736  6673 solver.cpp:228] Iteration 21440, loss = 0.168672
I0626 20:16:43.982770  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 20:16:43.982782  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121614 (* 1 = 0.0121614 loss)
I0626 20:16:43.982790  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0660344 (* 1 = 0.0660344 loss)
I0626 20:16:43.982798  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000110655 (* 1 = 0.000110655 loss)
I0626 20:16:43.982806  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.001667 (* 1 = 0.001667 loss)
I0626 20:16:43.982815  6673 sgd_solver.cpp:106] Iteration 21440, lr = 0.0002
I0626 20:18:22.306020  6673 solver.cpp:228] Iteration 21460, loss = 0.27918
I0626 20:18:22.306046  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:18:22.306054  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148947 (* 1 = 0.0148947 loss)
I0626 20:18:22.306061  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0403126 (* 1 = 0.0403126 loss)
I0626 20:18:22.306067  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336237 (* 1 = 0.00336237 loss)
I0626 20:18:22.306071  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138103 (* 1 = 0.0138103 loss)
I0626 20:18:22.306078  6673 sgd_solver.cpp:106] Iteration 21460, lr = 0.0002
I0626 20:20:00.291582  6673 solver.cpp:228] Iteration 21480, loss = 0.139129
I0626 20:20:00.291610  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 20:20:00.291618  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.022081 (* 1 = 0.022081 loss)
I0626 20:20:00.291625  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0545728 (* 1 = 0.0545728 loss)
I0626 20:20:00.291630  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.19529e-05 (* 1 = 7.19529e-05 loss)
I0626 20:20:00.291633  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00258261 (* 1 = 0.00258261 loss)
I0626 20:20:00.291640  6673 sgd_solver.cpp:106] Iteration 21480, lr = 0.0002
I0626 20:21:38.404320  6673 solver.cpp:228] Iteration 21500, loss = 0.130084
I0626 20:21:38.404343  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 20:21:38.404352  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496581 (* 1 = 0.0496581 loss)
I0626 20:21:38.404358  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0982514 (* 1 = 0.0982514 loss)
I0626 20:21:38.404363  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00656324 (* 1 = 0.00656324 loss)
I0626 20:21:38.404368  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182855 (* 1 = 0.0182855 loss)
I0626 20:21:38.404374  6673 sgd_solver.cpp:106] Iteration 21500, lr = 0.0002
I0626 20:23:16.368295  6673 solver.cpp:228] Iteration 21520, loss = 0.177235
I0626 20:23:16.368319  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:23:16.368326  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189978 (* 1 = 0.0189978 loss)
I0626 20:23:16.368330  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0248444 (* 1 = 0.0248444 loss)
I0626 20:23:16.368333  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000525891 (* 1 = 0.000525891 loss)
I0626 20:23:16.368336  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00168267 (* 1 = 0.00168267 loss)
I0626 20:23:16.368341  6673 sgd_solver.cpp:106] Iteration 21520, lr = 0.0002
I0626 20:24:54.353994  6673 solver.cpp:228] Iteration 21540, loss = 0.128422
I0626 20:24:54.354017  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:24:54.354024  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000563537 (* 1 = 0.000563537 loss)
I0626 20:24:54.354028  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.024646 (* 1 = 0.024646 loss)
I0626 20:24:54.354032  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014728 (* 1 = 0.014728 loss)
I0626 20:24:54.354035  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157835 (* 1 = 0.0157835 loss)
I0626 20:24:54.354039  6673 sgd_solver.cpp:106] Iteration 21540, lr = 0.0002
I0626 20:26:32.362682  6673 solver.cpp:228] Iteration 21560, loss = 0.139979
I0626 20:26:32.362706  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:26:32.362713  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286247 (* 1 = 0.0286247 loss)
I0626 20:26:32.362717  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0759364 (* 1 = 0.0759364 loss)
I0626 20:26:32.362720  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023083 (* 1 = 0.0023083 loss)
I0626 20:26:32.362725  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330873 (* 1 = 0.0330873 loss)
I0626 20:26:32.362728  6673 sgd_solver.cpp:106] Iteration 21560, lr = 0.0002
I0626 20:28:10.295372  6673 solver.cpp:228] Iteration 21580, loss = 0.188776
I0626 20:28:10.295394  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:28:10.295401  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0123737 (* 1 = 0.0123737 loss)
I0626 20:28:10.295404  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0253199 (* 1 = 0.0253199 loss)
I0626 20:28:10.295408  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000916721 (* 1 = 0.000916721 loss)
I0626 20:28:10.295411  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00196834 (* 1 = 0.00196834 loss)
I0626 20:28:10.295414  6673 sgd_solver.cpp:106] Iteration 21580, lr = 0.0002
speed: 4.916s / iter
I0626 20:29:48.310279  6673 solver.cpp:228] Iteration 21600, loss = 0.175894
I0626 20:29:48.310302  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 20:29:48.310309  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0784129 (* 1 = 0.0784129 loss)
I0626 20:29:48.310313  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.201365 (* 1 = 0.201365 loss)
I0626 20:29:48.310317  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00436667 (* 1 = 0.00436667 loss)
I0626 20:29:48.310320  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324761 (* 1 = 0.0324761 loss)
I0626 20:29:48.310324  6673 sgd_solver.cpp:106] Iteration 21600, lr = 0.0002
I0626 20:31:26.286116  6673 solver.cpp:228] Iteration 21620, loss = 0.130582
I0626 20:31:26.286139  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 20:31:26.286149  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0242813 (* 1 = 0.0242813 loss)
I0626 20:31:26.286154  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0702784 (* 1 = 0.0702784 loss)
I0626 20:31:26.286159  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193075 (* 1 = 0.0193075 loss)
I0626 20:31:26.286164  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00989542 (* 1 = 0.00989542 loss)
I0626 20:31:26.286171  6673 sgd_solver.cpp:106] Iteration 21620, lr = 0.0002
I0626 20:33:04.270954  6673 solver.cpp:228] Iteration 21640, loss = 0.128025
I0626 20:33:04.270980  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:33:04.270987  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0274971 (* 1 = 0.0274971 loss)
I0626 20:33:04.270992  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0222811 (* 1 = 0.0222811 loss)
I0626 20:33:04.270997  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0018469 (* 1 = 0.0018469 loss)
I0626 20:33:04.271001  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00532068 (* 1 = 0.00532068 loss)
I0626 20:33:04.271008  6673 sgd_solver.cpp:106] Iteration 21640, lr = 0.0002
I0626 20:34:42.280004  6673 solver.cpp:228] Iteration 21660, loss = 0.100113
I0626 20:34:42.280030  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:34:42.280036  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00368445 (* 1 = 0.00368445 loss)
I0626 20:34:42.280040  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0313954 (* 1 = 0.0313954 loss)
I0626 20:34:42.280045  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000194834 (* 1 = 0.000194834 loss)
I0626 20:34:42.280047  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00627306 (* 1 = 0.00627306 loss)
I0626 20:34:42.280051  6673 sgd_solver.cpp:106] Iteration 21660, lr = 0.0002
I0626 20:36:20.448316  6673 solver.cpp:228] Iteration 21680, loss = 0.136112
I0626 20:36:20.448344  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 20:36:20.448352  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.035057 (* 1 = 0.035057 loss)
I0626 20:36:20.448356  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0971181 (* 1 = 0.0971181 loss)
I0626 20:36:20.448359  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00161246 (* 1 = 0.00161246 loss)
I0626 20:36:20.448364  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351156 (* 1 = 0.0351156 loss)
I0626 20:36:20.448369  6673 sgd_solver.cpp:106] Iteration 21680, lr = 0.0002
I0626 20:37:58.594974  6673 solver.cpp:228] Iteration 21700, loss = 0.119271
I0626 20:37:58.595001  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:37:58.595010  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0196907 (* 1 = 0.0196907 loss)
I0626 20:37:58.595013  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0296533 (* 1 = 0.0296533 loss)
I0626 20:37:58.595018  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.07922e-05 (* 1 = 5.07922e-05 loss)
I0626 20:37:58.595022  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00296394 (* 1 = 0.00296394 loss)
I0626 20:37:58.595027  6673 sgd_solver.cpp:106] Iteration 21700, lr = 0.0002
I0626 20:39:36.712450  6673 solver.cpp:228] Iteration 21720, loss = 0.125287
I0626 20:39:36.712476  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:39:36.712482  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174302 (* 1 = 0.0174302 loss)
I0626 20:39:36.712486  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0343381 (* 1 = 0.0343381 loss)
I0626 20:39:36.712489  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00171571 (* 1 = 0.00171571 loss)
I0626 20:39:36.712493  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027591 (* 1 = 0.027591 loss)
I0626 20:39:36.712498  6673 sgd_solver.cpp:106] Iteration 21720, lr = 0.0002
I0626 20:41:14.841717  6673 solver.cpp:228] Iteration 21740, loss = 0.380683
I0626 20:41:14.841750  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 20:41:14.841759  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455238 (* 1 = 0.0455238 loss)
I0626 20:41:14.841765  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0833256 (* 1 = 0.0833256 loss)
I0626 20:41:14.841771  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000489723 (* 1 = 0.000489723 loss)
I0626 20:41:14.841776  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00793727 (* 1 = 0.00793727 loss)
I0626 20:41:14.841784  6673 sgd_solver.cpp:106] Iteration 21740, lr = 0.0002
I0626 20:42:53.041471  6673 solver.cpp:228] Iteration 21760, loss = 0.18759
I0626 20:42:53.041505  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:42:53.041514  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.013412 (* 1 = 0.013412 loss)
I0626 20:42:53.041520  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0494582 (* 1 = 0.0494582 loss)
I0626 20:42:53.041525  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.6568e-05 (* 1 = 7.6568e-05 loss)
I0626 20:42:53.041532  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000908434 (* 1 = 0.000908434 loss)
I0626 20:42:53.041538  6673 sgd_solver.cpp:106] Iteration 21760, lr = 0.0002
I0626 20:44:31.160789  6673 solver.cpp:228] Iteration 21780, loss = 0.106656
I0626 20:44:31.160816  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:44:31.160827  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0607309 (* 1 = 0.0607309 loss)
I0626 20:44:31.160835  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0507526 (* 1 = 0.0507526 loss)
I0626 20:44:31.160840  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000437701 (* 1 = 0.000437701 loss)
I0626 20:44:31.160847  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246812 (* 1 = 0.0246812 loss)
I0626 20:44:31.160856  6673 sgd_solver.cpp:106] Iteration 21780, lr = 0.0002
speed: 4.916s / iter
I0626 20:46:09.320600  6673 solver.cpp:228] Iteration 21800, loss = 0.133731
I0626 20:46:09.320626  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:46:09.320633  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0112745 (* 1 = 0.0112745 loss)
I0626 20:46:09.320637  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0670769 (* 1 = 0.0670769 loss)
I0626 20:46:09.320641  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286258 (* 1 = 0.00286258 loss)
I0626 20:46:09.320646  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00906216 (* 1 = 0.00906216 loss)
I0626 20:46:09.320649  6673 sgd_solver.cpp:106] Iteration 21800, lr = 0.0002
I0626 20:47:47.327412  6673 solver.cpp:228] Iteration 21820, loss = 0.218341
I0626 20:47:47.327437  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 20:47:47.327445  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0348987 (* 1 = 0.0348987 loss)
I0626 20:47:47.327450  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0744561 (* 1 = 0.0744561 loss)
I0626 20:47:47.327453  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253578 (* 1 = 0.00253578 loss)
I0626 20:47:47.327457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117609 (* 1 = 0.0117609 loss)
I0626 20:47:47.327462  6673 sgd_solver.cpp:106] Iteration 21820, lr = 0.0002
I0626 20:49:25.447878  6673 solver.cpp:228] Iteration 21840, loss = 0.189589
I0626 20:49:25.447903  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 20:49:25.447911  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.101281 (* 1 = 0.101281 loss)
I0626 20:49:25.447913  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.105434 (* 1 = 0.105434 loss)
I0626 20:49:25.447917  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000543304 (* 1 = 0.000543304 loss)
I0626 20:49:25.447921  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162252 (* 1 = 0.0162252 loss)
I0626 20:49:25.447926  6673 sgd_solver.cpp:106] Iteration 21840, lr = 0.0002
I0626 20:51:03.499161  6673 solver.cpp:228] Iteration 21860, loss = 0.114934
I0626 20:51:03.499186  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 20:51:03.499193  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00710815 (* 1 = 0.00710815 loss)
I0626 20:51:03.499197  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0141753 (* 1 = 0.0141753 loss)
I0626 20:51:03.499202  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00166434 (* 1 = 0.00166434 loss)
I0626 20:51:03.499204  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00278182 (* 1 = 0.00278182 loss)
I0626 20:51:03.499209  6673 sgd_solver.cpp:106] Iteration 21860, lr = 0.0002
I0626 20:52:41.599630  6673 solver.cpp:228] Iteration 21880, loss = 0.119977
I0626 20:52:41.599656  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 20:52:41.599664  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.047872 (* 1 = 0.047872 loss)
I0626 20:52:41.599668  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.111475 (* 1 = 0.111475 loss)
I0626 20:52:41.599673  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00316817 (* 1 = 0.00316817 loss)
I0626 20:52:41.599676  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184415 (* 1 = 0.0184415 loss)
I0626 20:52:41.599683  6673 sgd_solver.cpp:106] Iteration 21880, lr = 0.0002
I0626 20:54:19.677103  6673 solver.cpp:228] Iteration 21900, loss = 0.302605
I0626 20:54:19.677134  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 20:54:19.677141  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216789 (* 1 = 0.0216789 loss)
I0626 20:54:19.677146  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0522851 (* 1 = 0.0522851 loss)
I0626 20:54:19.677150  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000149153 (* 1 = 0.000149153 loss)
I0626 20:54:19.677155  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0030989 (* 1 = 0.0030989 loss)
I0626 20:54:19.677160  6673 sgd_solver.cpp:106] Iteration 21900, lr = 0.0002
I0626 20:55:58.395054  6673 solver.cpp:228] Iteration 21920, loss = 0.109963
I0626 20:55:58.395082  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 20:55:58.395090  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748957 (* 1 = 0.0748957 loss)
I0626 20:55:58.395097  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0983946 (* 1 = 0.0983946 loss)
I0626 20:55:58.395102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162534 (* 1 = 0.00162534 loss)
I0626 20:55:58.395109  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0256287 (* 1 = 0.0256287 loss)
I0626 20:55:58.395117  6673 sgd_solver.cpp:106] Iteration 21920, lr = 0.0002
I0626 20:57:36.363811  6673 solver.cpp:228] Iteration 21940, loss = 0.205201
I0626 20:57:36.363838  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0626 20:57:36.363845  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.338269 (* 1 = 0.338269 loss)
I0626 20:57:36.363849  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.33502 (* 1 = 0.33502 loss)
I0626 20:57:36.363853  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00617807 (* 1 = 0.00617807 loss)
I0626 20:57:36.363857  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0657212 (* 1 = 0.0657212 loss)
I0626 20:57:36.363862  6673 sgd_solver.cpp:106] Iteration 21940, lr = 0.0002
I0626 20:59:14.386569  6673 solver.cpp:228] Iteration 21960, loss = 0.13814
I0626 20:59:14.386603  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 20:59:14.386611  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0125788 (* 1 = 0.0125788 loss)
I0626 20:59:14.386615  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0245346 (* 1 = 0.0245346 loss)
I0626 20:59:14.386620  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131445 (* 1 = 0.0131445 loss)
I0626 20:59:14.386623  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00421977 (* 1 = 0.00421977 loss)
I0626 20:59:14.386628  6673 sgd_solver.cpp:106] Iteration 21960, lr = 0.0002
I0626 21:00:52.343323  6673 solver.cpp:228] Iteration 21980, loss = 0.108085
I0626 21:00:52.343348  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 21:00:52.343354  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0119089 (* 1 = 0.0119089 loss)
I0626 21:00:52.343358  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0099253 (* 1 = 0.0099253 loss)
I0626 21:00:52.343363  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000818021 (* 1 = 0.000818021 loss)
I0626 21:00:52.343365  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0035422 (* 1 = 0.0035422 loss)
I0626 21:00:52.343370  6673 sgd_solver.cpp:106] Iteration 21980, lr = 0.0002
speed: 4.916s / iter
I0626 21:02:30.438004  6673 solver.cpp:228] Iteration 22000, loss = 0.199454
I0626 21:02:30.438032  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:02:30.438040  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0218452 (* 1 = 0.0218452 loss)
I0626 21:02:30.438045  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.051446 (* 1 = 0.051446 loss)
I0626 21:02:30.438048  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00580236 (* 1 = 0.00580236 loss)
I0626 21:02:30.438052  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158418 (* 1 = 0.0158418 loss)
I0626 21:02:30.438058  6673 sgd_solver.cpp:106] Iteration 22000, lr = 0.0002
I0626 21:04:08.400192  6673 solver.cpp:228] Iteration 22020, loss = 0.166213
I0626 21:04:08.400218  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 21:04:08.400224  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0410581 (* 1 = 0.0410581 loss)
I0626 21:04:08.400228  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0655992 (* 1 = 0.0655992 loss)
I0626 21:04:08.400231  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00435033 (* 1 = 0.00435033 loss)
I0626 21:04:08.400235  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106693 (* 1 = 0.0106693 loss)
I0626 21:04:08.400239  6673 sgd_solver.cpp:106] Iteration 22020, lr = 0.0002
I0626 21:05:46.408367  6673 solver.cpp:228] Iteration 22040, loss = 0.145781
I0626 21:05:46.408396  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 21:05:46.408403  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.038745 (* 1 = 0.038745 loss)
I0626 21:05:46.408409  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0154659 (* 1 = 0.0154659 loss)
I0626 21:05:46.408413  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00905653 (* 1 = 0.00905653 loss)
I0626 21:05:46.408418  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106867 (* 1 = 0.0106867 loss)
I0626 21:05:46.408423  6673 sgd_solver.cpp:106] Iteration 22040, lr = 0.0002
I0626 21:07:24.445279  6673 solver.cpp:228] Iteration 22060, loss = 0.158382
I0626 21:07:24.445305  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:07:24.445313  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171644 (* 1 = 0.0171644 loss)
I0626 21:07:24.445317  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0214794 (* 1 = 0.0214794 loss)
I0626 21:07:24.445322  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000212833 (* 1 = 0.000212833 loss)
I0626 21:07:24.445325  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00458259 (* 1 = 0.00458259 loss)
I0626 21:07:24.445329  6673 sgd_solver.cpp:106] Iteration 22060, lr = 0.0002
I0626 21:09:02.443302  6673 solver.cpp:228] Iteration 22080, loss = 0.148072
I0626 21:09:02.443331  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:09:02.443339  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178339 (* 1 = 0.0178339 loss)
I0626 21:09:02.443346  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00939385 (* 1 = 0.00939385 loss)
I0626 21:09:02.443351  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151151 (* 1 = 0.0151151 loss)
I0626 21:09:02.443357  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00398716 (* 1 = 0.00398716 loss)
I0626 21:09:02.443364  6673 sgd_solver.cpp:106] Iteration 22080, lr = 0.0002
I0626 21:10:40.488351  6673 solver.cpp:228] Iteration 22100, loss = 0.140275
I0626 21:10:40.488378  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:10:40.488385  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0364239 (* 1 = 0.0364239 loss)
I0626 21:10:40.488389  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0560309 (* 1 = 0.0560309 loss)
I0626 21:10:40.488394  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00462472 (* 1 = 0.00462472 loss)
I0626 21:10:40.488397  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010999 (* 1 = 0.010999 loss)
I0626 21:10:40.488402  6673 sgd_solver.cpp:106] Iteration 22100, lr = 0.0002
I0626 21:12:18.473806  6673 solver.cpp:228] Iteration 22120, loss = 0.128117
I0626 21:12:18.473827  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:12:18.473835  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279954 (* 1 = 0.0279954 loss)
I0626 21:12:18.473841  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0180434 (* 1 = 0.0180434 loss)
I0626 21:12:18.473845  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00542551 (* 1 = 0.00542551 loss)
I0626 21:12:18.473850  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00613136 (* 1 = 0.00613136 loss)
I0626 21:12:18.473855  6673 sgd_solver.cpp:106] Iteration 22120, lr = 0.0002
I0626 21:13:56.573968  6673 solver.cpp:228] Iteration 22140, loss = 0.188321
I0626 21:13:56.573993  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 21:13:56.574002  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0423159 (* 1 = 0.0423159 loss)
I0626 21:13:56.574005  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.173637 (* 1 = 0.173637 loss)
I0626 21:13:56.574009  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0382569 (* 1 = 0.0382569 loss)
I0626 21:13:56.574013  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.228567 (* 1 = 0.228567 loss)
I0626 21:13:56.574018  6673 sgd_solver.cpp:106] Iteration 22140, lr = 0.0002
I0626 21:15:34.577265  6673 solver.cpp:228] Iteration 22160, loss = 0.118177
I0626 21:15:34.577291  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:15:34.577297  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000740429 (* 1 = 0.000740429 loss)
I0626 21:15:34.577301  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0230226 (* 1 = 0.0230226 loss)
I0626 21:15:34.577304  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238359 (* 1 = 0.00238359 loss)
I0626 21:15:34.577308  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142759 (* 1 = 0.0142759 loss)
I0626 21:15:34.577312  6673 sgd_solver.cpp:106] Iteration 22160, lr = 0.0002
I0626 21:17:12.542438  6673 solver.cpp:228] Iteration 22180, loss = 0.108373
I0626 21:17:12.542461  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 21:17:12.542469  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0736115 (* 1 = 0.0736115 loss)
I0626 21:17:12.542472  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.190985 (* 1 = 0.190985 loss)
I0626 21:17:12.542476  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00277962 (* 1 = 0.00277962 loss)
I0626 21:17:12.542479  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207059 (* 1 = 0.0207059 loss)
I0626 21:17:12.542484  6673 sgd_solver.cpp:106] Iteration 22180, lr = 0.0002
speed: 4.916s / iter
I0626 21:18:50.548815  6673 solver.cpp:228] Iteration 22200, loss = 0.159108
I0626 21:18:50.548840  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 21:18:50.548846  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336136 (* 1 = 0.0336136 loss)
I0626 21:18:50.548851  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.165337 (* 1 = 0.165337 loss)
I0626 21:18:50.548853  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0168888 (* 1 = 0.0168888 loss)
I0626 21:18:50.548856  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352367 (* 1 = 0.0352367 loss)
I0626 21:18:50.548861  6673 sgd_solver.cpp:106] Iteration 22200, lr = 0.0002
I0626 21:20:28.481928  6673 solver.cpp:228] Iteration 22220, loss = 0.176759
I0626 21:20:28.481954  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 21:20:28.481962  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0722825 (* 1 = 0.0722825 loss)
I0626 21:20:28.481966  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0876577 (* 1 = 0.0876577 loss)
I0626 21:20:28.481971  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000337159 (* 1 = 0.000337159 loss)
I0626 21:20:28.481974  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107324 (* 1 = 0.0107324 loss)
I0626 21:20:28.481979  6673 sgd_solver.cpp:106] Iteration 22220, lr = 0.0002
I0626 21:22:06.494045  6673 solver.cpp:228] Iteration 22240, loss = 0.163256
I0626 21:22:06.494069  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:22:06.494077  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.013898 (* 1 = 0.013898 loss)
I0626 21:22:06.494081  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0533009 (* 1 = 0.0533009 loss)
I0626 21:22:06.494086  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000122105 (* 1 = 0.000122105 loss)
I0626 21:22:06.494089  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00338947 (* 1 = 0.00338947 loss)
I0626 21:22:06.494094  6673 sgd_solver.cpp:106] Iteration 22240, lr = 0.0002
I0626 21:23:44.413961  6673 solver.cpp:228] Iteration 22260, loss = 0.266358
I0626 21:23:44.413985  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:23:44.413993  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.015467 (* 1 = 0.015467 loss)
I0626 21:23:44.413998  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0584081 (* 1 = 0.0584081 loss)
I0626 21:23:44.414001  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491122 (* 1 = 0.00491122 loss)
I0626 21:23:44.414005  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195412 (* 1 = 0.0195412 loss)
I0626 21:23:44.414011  6673 sgd_solver.cpp:106] Iteration 22260, lr = 0.0002
I0626 21:25:22.370674  6673 solver.cpp:228] Iteration 22280, loss = 0.236826
I0626 21:25:22.370697  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:25:22.370704  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.128923 (* 1 = 0.128923 loss)
I0626 21:25:22.370708  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0922254 (* 1 = 0.0922254 loss)
I0626 21:25:22.370712  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109896 (* 1 = 0.0109896 loss)
I0626 21:25:22.370714  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370762 (* 1 = 0.0370762 loss)
I0626 21:25:22.370718  6673 sgd_solver.cpp:106] Iteration 22280, lr = 0.0002
I0626 21:27:00.280030  6673 solver.cpp:228] Iteration 22300, loss = 0.12424
I0626 21:27:00.280056  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:27:00.280063  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537273 (* 1 = 0.0537273 loss)
I0626 21:27:00.280067  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0920911 (* 1 = 0.0920911 loss)
I0626 21:27:00.280071  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000301293 (* 1 = 0.000301293 loss)
I0626 21:27:00.280076  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00922947 (* 1 = 0.00922947 loss)
I0626 21:27:00.280081  6673 sgd_solver.cpp:106] Iteration 22300, lr = 0.0002
I0626 21:28:38.284945  6673 solver.cpp:228] Iteration 22320, loss = 0.146236
I0626 21:28:38.284976  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 21:28:38.284984  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0773132 (* 1 = 0.0773132 loss)
I0626 21:28:38.284988  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.123729 (* 1 = 0.123729 loss)
I0626 21:28:38.284992  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00408948 (* 1 = 0.00408948 loss)
I0626 21:28:38.284997  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250912 (* 1 = 0.0250912 loss)
I0626 21:28:38.285003  6673 sgd_solver.cpp:106] Iteration 22320, lr = 0.0002
I0626 21:30:16.243839  6673 solver.cpp:228] Iteration 22340, loss = 0.156979
I0626 21:30:16.243863  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:30:16.243871  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496969 (* 1 = 0.0496969 loss)
I0626 21:30:16.243875  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0427056 (* 1 = 0.0427056 loss)
I0626 21:30:16.243878  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0546517 (* 1 = 0.0546517 loss)
I0626 21:30:16.243881  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177726 (* 1 = 0.0177726 loss)
I0626 21:30:16.243886  6673 sgd_solver.cpp:106] Iteration 22340, lr = 0.0002
I0626 21:31:54.197181  6673 solver.cpp:228] Iteration 22360, loss = 0.157377
I0626 21:31:54.197206  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 21:31:54.197213  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521446 (* 1 = 0.0521446 loss)
I0626 21:31:54.197218  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0691642 (* 1 = 0.0691642 loss)
I0626 21:31:54.197222  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00342592 (* 1 = 0.00342592 loss)
I0626 21:31:54.197226  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295603 (* 1 = 0.0295603 loss)
I0626 21:31:54.197230  6673 sgd_solver.cpp:106] Iteration 22360, lr = 0.0002
I0626 21:33:32.135535  6673 solver.cpp:228] Iteration 22380, loss = 0.108301
I0626 21:33:32.135560  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0626 21:33:32.135566  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.104301 (* 1 = 0.104301 loss)
I0626 21:33:32.135571  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.161619 (* 1 = 0.161619 loss)
I0626 21:33:32.135574  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0395012 (* 1 = 0.0395012 loss)
I0626 21:33:32.135577  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146224 (* 1 = 0.0146224 loss)
I0626 21:33:32.135582  6673 sgd_solver.cpp:106] Iteration 22380, lr = 0.0002
speed: 4.916s / iter
I0626 21:35:10.304451  6673 solver.cpp:228] Iteration 22400, loss = 0.215582
I0626 21:35:10.304473  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:35:10.304481  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363306 (* 1 = 0.0363306 loss)
I0626 21:35:10.304484  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0427616 (* 1 = 0.0427616 loss)
I0626 21:35:10.304488  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000292917 (* 1 = 0.000292917 loss)
I0626 21:35:10.304491  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00855052 (* 1 = 0.00855052 loss)
I0626 21:35:10.304497  6673 sgd_solver.cpp:106] Iteration 22400, lr = 0.0002
I0626 21:36:48.505069  6673 solver.cpp:228] Iteration 22420, loss = 0.208739
I0626 21:36:48.505092  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:36:48.505100  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511121 (* 1 = 0.0511121 loss)
I0626 21:36:48.505103  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0775127 (* 1 = 0.0775127 loss)
I0626 21:36:48.505106  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140726 (* 1 = 0.0140726 loss)
I0626 21:36:48.505110  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142477 (* 1 = 0.0142477 loss)
I0626 21:36:48.505115  6673 sgd_solver.cpp:106] Iteration 22420, lr = 0.0002
I0626 21:38:26.550163  6673 solver.cpp:228] Iteration 22440, loss = 0.18195
I0626 21:38:26.550189  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:38:26.550197  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00130286 (* 1 = 0.00130286 loss)
I0626 21:38:26.550202  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0293298 (* 1 = 0.0293298 loss)
I0626 21:38:26.550206  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151758 (* 1 = 0.0151758 loss)
I0626 21:38:26.550209  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162206 (* 1 = 0.0162206 loss)
I0626 21:38:26.550215  6673 sgd_solver.cpp:106] Iteration 22440, lr = 0.0002
I0626 21:40:04.497637  6673 solver.cpp:228] Iteration 22460, loss = 0.199659
I0626 21:40:04.497663  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 21:40:04.497669  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0163095 (* 1 = 0.0163095 loss)
I0626 21:40:04.497673  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0137177 (* 1 = 0.0137177 loss)
I0626 21:40:04.497678  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.56143e-05 (* 1 = 5.56143e-05 loss)
I0626 21:40:04.497681  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114053 (* 1 = 0.0114053 loss)
I0626 21:40:04.497686  6673 sgd_solver.cpp:106] Iteration 22460, lr = 0.0002
I0626 21:41:42.500077  6673 solver.cpp:228] Iteration 22480, loss = 0.226516
I0626 21:41:42.500100  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:41:42.500107  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0104945 (* 1 = 0.0104945 loss)
I0626 21:41:42.500110  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.019268 (* 1 = 0.019268 loss)
I0626 21:41:42.500114  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0033342 (* 1 = 0.0033342 loss)
I0626 21:41:42.500118  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00227498 (* 1 = 0.00227498 loss)
I0626 21:41:42.500123  6673 sgd_solver.cpp:106] Iteration 22480, lr = 0.0002
I0626 21:43:20.452935  6673 solver.cpp:228] Iteration 22500, loss = 0.233929
I0626 21:43:20.452965  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:43:20.452973  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474279 (* 1 = 0.0474279 loss)
I0626 21:43:20.452978  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0559215 (* 1 = 0.0559215 loss)
I0626 21:43:20.452983  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000394899 (* 1 = 0.000394899 loss)
I0626 21:43:20.452987  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125101 (* 1 = 0.0125101 loss)
I0626 21:43:20.452993  6673 sgd_solver.cpp:106] Iteration 22500, lr = 0.0002
I0626 21:44:58.420405  6673 solver.cpp:228] Iteration 22520, loss = 0.150139
I0626 21:44:58.420429  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 21:44:58.420435  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707394 (* 1 = 0.0707394 loss)
I0626 21:44:58.420440  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.122767 (* 1 = 0.122767 loss)
I0626 21:44:58.420444  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00191955 (* 1 = 0.00191955 loss)
I0626 21:44:58.420447  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179967 (* 1 = 0.0179967 loss)
I0626 21:44:58.420451  6673 sgd_solver.cpp:106] Iteration 22520, lr = 0.0002
I0626 21:46:36.366554  6673 solver.cpp:228] Iteration 22540, loss = 0.176363
I0626 21:46:36.366578  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:46:36.366585  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0608492 (* 1 = 0.0608492 loss)
I0626 21:46:36.366590  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0614536 (* 1 = 0.0614536 loss)
I0626 21:46:36.366593  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108376 (* 1 = 0.00108376 loss)
I0626 21:46:36.366596  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113034 (* 1 = 0.0113034 loss)
I0626 21:46:36.366600  6673 sgd_solver.cpp:106] Iteration 22540, lr = 0.0002
I0626 21:48:14.358556  6673 solver.cpp:228] Iteration 22560, loss = 0.198219
I0626 21:48:14.358583  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:48:14.358593  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132178 (* 1 = 0.0132178 loss)
I0626 21:48:14.358599  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.032787 (* 1 = 0.032787 loss)
I0626 21:48:14.358604  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000111304 (* 1 = 0.000111304 loss)
I0626 21:48:14.358610  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00632473 (* 1 = 0.00632473 loss)
I0626 21:48:14.358618  6673 sgd_solver.cpp:106] Iteration 22560, lr = 0.0002
I0626 21:49:52.333271  6673 solver.cpp:228] Iteration 22580, loss = 0.24751
I0626 21:49:52.333302  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 21:49:52.333312  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.186715 (* 1 = 0.186715 loss)
I0626 21:49:52.333317  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.263663 (* 1 = 0.263663 loss)
I0626 21:49:52.333323  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00840616 (* 1 = 0.00840616 loss)
I0626 21:49:52.333328  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100253 (* 1 = 0.100253 loss)
I0626 21:49:52.333334  6673 sgd_solver.cpp:106] Iteration 22580, lr = 0.0002
speed: 4.916s / iter
I0626 21:51:30.283202  6673 solver.cpp:228] Iteration 22600, loss = 0.165465
I0626 21:51:30.283227  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 21:51:30.283234  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0926776 (* 1 = 0.0926776 loss)
I0626 21:51:30.283239  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100288 (* 1 = 0.100288 loss)
I0626 21:51:30.283243  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226518 (* 1 = 0.00226518 loss)
I0626 21:51:30.283247  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210188 (* 1 = 0.0210188 loss)
I0626 21:51:30.283252  6673 sgd_solver.cpp:106] Iteration 22600, lr = 0.0002
I0626 21:53:08.199105  6673 solver.cpp:228] Iteration 22620, loss = 0.059486
I0626 21:53:08.199129  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:53:08.199136  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178536 (* 1 = 0.0178536 loss)
I0626 21:53:08.199141  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0303321 (* 1 = 0.0303321 loss)
I0626 21:53:08.199146  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00168574 (* 1 = 0.00168574 loss)
I0626 21:53:08.199149  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00213137 (* 1 = 0.00213137 loss)
I0626 21:53:08.199154  6673 sgd_solver.cpp:106] Iteration 22620, lr = 0.0002
I0626 21:54:46.186707  6673 solver.cpp:228] Iteration 22640, loss = 0.212349
I0626 21:54:46.186735  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:54:46.186743  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182684 (* 1 = 0.0182684 loss)
I0626 21:54:46.186748  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0404003 (* 1 = 0.0404003 loss)
I0626 21:54:46.186753  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000136649 (* 1 = 0.000136649 loss)
I0626 21:54:46.186756  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00424971 (* 1 = 0.00424971 loss)
I0626 21:54:46.186761  6673 sgd_solver.cpp:106] Iteration 22640, lr = 0.0002
I0626 21:56:24.282155  6673 solver.cpp:228] Iteration 22660, loss = 0.194732
I0626 21:56:24.282181  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 21:56:24.282187  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0360101 (* 1 = 0.0360101 loss)
I0626 21:56:24.282191  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.128088 (* 1 = 0.128088 loss)
I0626 21:56:24.282194  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00769968 (* 1 = 0.00769968 loss)
I0626 21:56:24.282198  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0425093 (* 1 = 0.0425093 loss)
I0626 21:56:24.282202  6673 sgd_solver.cpp:106] Iteration 22660, lr = 0.0002
I0626 21:58:02.222998  6673 solver.cpp:228] Iteration 22680, loss = 0.156566
I0626 21:58:02.223026  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 21:58:02.223033  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0243148 (* 1 = 0.0243148 loss)
I0626 21:58:02.223038  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0428813 (* 1 = 0.0428813 loss)
I0626 21:58:02.223042  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208455 (* 1 = 0.00208455 loss)
I0626 21:58:02.223045  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205868 (* 1 = 0.0205868 loss)
I0626 21:58:02.223052  6673 sgd_solver.cpp:106] Iteration 22680, lr = 0.0002
I0626 21:59:40.180658  6673 solver.cpp:228] Iteration 22700, loss = 0.113867
I0626 21:59:40.180681  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 21:59:40.180688  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.012118 (* 1 = 0.012118 loss)
I0626 21:59:40.180691  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.029334 (* 1 = 0.029334 loss)
I0626 21:59:40.180696  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000358885 (* 1 = 0.000358885 loss)
I0626 21:59:40.180699  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0071718 (* 1 = 0.0071718 loss)
I0626 21:59:40.180703  6673 sgd_solver.cpp:106] Iteration 22700, lr = 0.0002
I0626 22:01:18.194787  6673 solver.cpp:228] Iteration 22720, loss = 0.245062
I0626 22:01:18.194813  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0626 22:01:18.194820  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.286429 (* 1 = 0.286429 loss)
I0626 22:01:18.194826  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.407524 (* 1 = 0.407524 loss)
I0626 22:01:18.194833  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0233051 (* 1 = 0.0233051 loss)
I0626 22:01:18.194838  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.161445 (* 1 = 0.161445 loss)
I0626 22:01:18.194844  6673 sgd_solver.cpp:106] Iteration 22720, lr = 0.0002
I0626 22:02:56.198263  6673 solver.cpp:228] Iteration 22740, loss = 0.155974
I0626 22:02:56.198292  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:02:56.198298  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160458 (* 1 = 0.0160458 loss)
I0626 22:02:56.198302  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0142654 (* 1 = 0.0142654 loss)
I0626 22:02:56.198307  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000246159 (* 1 = 0.000246159 loss)
I0626 22:02:56.198309  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00330764 (* 1 = 0.00330764 loss)
I0626 22:02:56.198314  6673 sgd_solver.cpp:106] Iteration 22740, lr = 0.0002
I0626 22:04:34.206961  6673 solver.cpp:228] Iteration 22760, loss = 0.18395
I0626 22:04:34.206990  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:04:34.206997  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0928799 (* 1 = 0.0928799 loss)
I0626 22:04:34.207002  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109022 (* 1 = 0.109022 loss)
I0626 22:04:34.207006  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591666 (* 1 = 0.00591666 loss)
I0626 22:04:34.207010  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266476 (* 1 = 0.0266476 loss)
I0626 22:04:34.207015  6673 sgd_solver.cpp:106] Iteration 22760, lr = 0.0002
I0626 22:06:12.268394  6673 solver.cpp:228] Iteration 22780, loss = 0.117924
I0626 22:06:12.268419  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:06:12.268425  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381573 (* 1 = 0.0381573 loss)
I0626 22:06:12.268429  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0374859 (* 1 = 0.0374859 loss)
I0626 22:06:12.268432  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179231 (* 1 = 0.00179231 loss)
I0626 22:06:12.268438  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00944803 (* 1 = 0.00944803 loss)
I0626 22:06:12.268445  6673 sgd_solver.cpp:106] Iteration 22780, lr = 0.0002
speed: 4.916s / iter
I0626 22:07:50.365463  6673 solver.cpp:228] Iteration 22800, loss = 0.240728
I0626 22:07:50.365490  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:07:50.365497  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0799611 (* 1 = 0.0799611 loss)
I0626 22:07:50.365502  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109367 (* 1 = 0.109367 loss)
I0626 22:07:50.365506  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000795727 (* 1 = 0.000795727 loss)
I0626 22:07:50.365509  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00787373 (* 1 = 0.00787373 loss)
I0626 22:07:50.365515  6673 sgd_solver.cpp:106] Iteration 22800, lr = 0.0002
I0626 22:09:28.338827  6673 solver.cpp:228] Iteration 22820, loss = 0.122637
I0626 22:09:28.338853  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:09:28.338866  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0253416 (* 1 = 0.0253416 loss)
I0626 22:09:28.338873  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0438684 (* 1 = 0.0438684 loss)
I0626 22:09:28.338881  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000378911 (* 1 = 0.000378911 loss)
I0626 22:09:28.338887  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00244067 (* 1 = 0.00244067 loss)
I0626 22:09:28.338894  6673 sgd_solver.cpp:106] Iteration 22820, lr = 0.0002
I0626 22:11:06.312254  6673 solver.cpp:228] Iteration 22840, loss = 0.201622
I0626 22:11:06.312280  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:11:06.312288  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176432 (* 1 = 0.0176432 loss)
I0626 22:11:06.312292  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0172418 (* 1 = 0.0172418 loss)
I0626 22:11:06.312296  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000216072 (* 1 = 0.000216072 loss)
I0626 22:11:06.312300  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00103639 (* 1 = 0.00103639 loss)
I0626 22:11:06.312305  6673 sgd_solver.cpp:106] Iteration 22840, lr = 0.0002
I0626 22:12:44.351950  6673 solver.cpp:228] Iteration 22860, loss = 0.161973
I0626 22:12:44.351972  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 22:12:44.351979  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.290141 (* 1 = 0.290141 loss)
I0626 22:12:44.351981  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.26097 (* 1 = 0.26097 loss)
I0626 22:12:44.351984  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228649 (* 1 = 0.00228649 loss)
I0626 22:12:44.351987  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.046659 (* 1 = 0.046659 loss)
I0626 22:12:44.351991  6673 sgd_solver.cpp:106] Iteration 22860, lr = 0.0002
I0626 22:14:22.342434  6673 solver.cpp:228] Iteration 22880, loss = 0.232215
I0626 22:14:22.342459  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0626 22:14:22.342466  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.145245 (* 1 = 0.145245 loss)
I0626 22:14:22.342473  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.312855 (* 1 = 0.312855 loss)
I0626 22:14:22.342480  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0351296 (* 1 = 0.0351296 loss)
I0626 22:14:22.342484  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107254 (* 1 = 0.107254 loss)
I0626 22:14:22.342489  6673 sgd_solver.cpp:106] Iteration 22880, lr = 0.0002
I0626 22:16:00.318233  6673 solver.cpp:228] Iteration 22900, loss = 0.0916595
I0626 22:16:00.318260  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:16:00.318269  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00915511 (* 1 = 0.00915511 loss)
I0626 22:16:00.318274  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0190875 (* 1 = 0.0190875 loss)
I0626 22:16:00.318281  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.60666e-05 (* 1 = 8.60666e-05 loss)
I0626 22:16:00.318285  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00897518 (* 1 = 0.00897518 loss)
I0626 22:16:00.318291  6673 sgd_solver.cpp:106] Iteration 22900, lr = 0.0002
I0626 22:17:38.275100  6673 solver.cpp:228] Iteration 22920, loss = 0.180047
I0626 22:17:38.275130  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:17:38.275136  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107409 (* 1 = 0.0107409 loss)
I0626 22:17:38.275141  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0107251 (* 1 = 0.0107251 loss)
I0626 22:17:38.275143  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000440759 (* 1 = 0.000440759 loss)
I0626 22:17:38.275146  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00816561 (* 1 = 0.00816561 loss)
I0626 22:17:38.275151  6673 sgd_solver.cpp:106] Iteration 22920, lr = 0.0002
I0626 22:19:16.269223  6673 solver.cpp:228] Iteration 22940, loss = 0.0831374
I0626 22:19:16.269248  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 22:19:16.269258  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407862 (* 1 = 0.0407862 loss)
I0626 22:19:16.269264  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0473919 (* 1 = 0.0473919 loss)
I0626 22:19:16.269269  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.51428e-05 (* 1 = 6.51428e-05 loss)
I0626 22:19:16.269276  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228129 (* 1 = 0.0228129 loss)
I0626 22:19:16.269284  6673 sgd_solver.cpp:106] Iteration 22940, lr = 0.0002
I0626 22:20:54.263208  6673 solver.cpp:228] Iteration 22960, loss = 0.143516
I0626 22:20:54.263233  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:20:54.263242  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178829 (* 1 = 0.0178829 loss)
I0626 22:20:54.263247  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0148357 (* 1 = 0.0148357 loss)
I0626 22:20:54.263250  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000236392 (* 1 = 0.000236392 loss)
I0626 22:20:54.263254  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00344692 (* 1 = 0.00344692 loss)
I0626 22:20:54.263259  6673 sgd_solver.cpp:106] Iteration 22960, lr = 0.0002
I0626 22:22:32.246368  6673 solver.cpp:228] Iteration 22980, loss = 0.109593
I0626 22:22:32.246392  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:22:32.246398  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241973 (* 1 = 0.0241973 loss)
I0626 22:22:32.246403  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0350826 (* 1 = 0.0350826 loss)
I0626 22:22:32.246409  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00476514 (* 1 = 0.00476514 loss)
I0626 22:22:32.246414  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114553 (* 1 = 0.0114553 loss)
I0626 22:22:32.246419  6673 sgd_solver.cpp:106] Iteration 22980, lr = 0.0002
speed: 4.916s / iter
I0626 22:24:10.461539  6673 solver.cpp:228] Iteration 23000, loss = 0.0887009
I0626 22:24:10.461563  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:24:10.461571  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198449 (* 1 = 0.0198449 loss)
I0626 22:24:10.461575  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0365478 (* 1 = 0.0365478 loss)
I0626 22:24:10.461580  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000112962 (* 1 = 0.000112962 loss)
I0626 22:24:10.461583  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00488012 (* 1 = 0.00488012 loss)
I0626 22:24:10.461588  6673 sgd_solver.cpp:106] Iteration 23000, lr = 0.0002
I0626 22:25:48.710366  6673 solver.cpp:228] Iteration 23020, loss = 0.24083
I0626 22:25:48.710391  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:25:48.710398  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0488896 (* 1 = 0.0488896 loss)
I0626 22:25:48.710403  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0612838 (* 1 = 0.0612838 loss)
I0626 22:25:48.710407  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000530617 (* 1 = 0.000530617 loss)
I0626 22:25:48.710410  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00996387 (* 1 = 0.00996387 loss)
I0626 22:25:48.710417  6673 sgd_solver.cpp:106] Iteration 23020, lr = 0.0002
I0626 22:27:27.100505  6673 solver.cpp:228] Iteration 23040, loss = 0.230981
I0626 22:27:27.100533  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 22:27:27.100539  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.146595 (* 1 = 0.146595 loss)
I0626 22:27:27.100544  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.190563 (* 1 = 0.190563 loss)
I0626 22:27:27.100548  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00529535 (* 1 = 0.00529535 loss)
I0626 22:27:27.100551  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319579 (* 1 = 0.0319579 loss)
I0626 22:27:27.100556  6673 sgd_solver.cpp:106] Iteration 23040, lr = 0.0002
I0626 22:29:05.292474  6673 solver.cpp:228] Iteration 23060, loss = 0.0794821
I0626 22:29:05.292505  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:29:05.292512  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156144 (* 1 = 0.0156144 loss)
I0626 22:29:05.292516  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0160866 (* 1 = 0.0160866 loss)
I0626 22:29:05.292520  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000134948 (* 1 = 0.000134948 loss)
I0626 22:29:05.292523  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00545818 (* 1 = 0.00545818 loss)
I0626 22:29:05.292528  6673 sgd_solver.cpp:106] Iteration 23060, lr = 0.0002
I0626 22:30:43.681874  6673 solver.cpp:228] Iteration 23080, loss = 0.0920528
I0626 22:30:43.681900  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:30:43.681908  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318119 (* 1 = 0.0318119 loss)
I0626 22:30:43.681912  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0622289 (* 1 = 0.0622289 loss)
I0626 22:30:43.681915  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00283153 (* 1 = 0.00283153 loss)
I0626 22:30:43.681919  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00832568 (* 1 = 0.00832568 loss)
I0626 22:30:43.681924  6673 sgd_solver.cpp:106] Iteration 23080, lr = 0.0002
I0626 22:32:22.074425  6673 solver.cpp:228] Iteration 23100, loss = 0.0942365
I0626 22:32:22.074450  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:32:22.074456  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121406 (* 1 = 0.0121406 loss)
I0626 22:32:22.074460  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0325644 (* 1 = 0.0325644 loss)
I0626 22:32:22.074463  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00304329 (* 1 = 0.00304329 loss)
I0626 22:32:22.074466  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302853 (* 1 = 0.0302853 loss)
I0626 22:32:22.074471  6673 sgd_solver.cpp:106] Iteration 23100, lr = 0.0002
I0626 22:34:00.499061  6673 solver.cpp:228] Iteration 23120, loss = 0.148794
I0626 22:34:00.499086  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 22:34:00.499094  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0260908 (* 1 = 0.0260908 loss)
I0626 22:34:00.499099  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.015683 (* 1 = 0.015683 loss)
I0626 22:34:00.499102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.93924e-05 (* 1 = 8.93924e-05 loss)
I0626 22:34:00.499106  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00899089 (* 1 = 0.00899089 loss)
I0626 22:34:00.499111  6673 sgd_solver.cpp:106] Iteration 23120, lr = 0.0002
I0626 22:35:39.005901  6673 solver.cpp:228] Iteration 23140, loss = 0.106086
I0626 22:35:39.005928  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:35:39.005935  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00919413 (* 1 = 0.00919413 loss)
I0626 22:35:39.005939  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0144327 (* 1 = 0.0144327 loss)
I0626 22:35:39.005944  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029393 (* 1 = 0.0029393 loss)
I0626 22:35:39.005946  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00451563 (* 1 = 0.00451563 loss)
I0626 22:35:39.005951  6673 sgd_solver.cpp:106] Iteration 23140, lr = 0.0002
I0626 22:37:17.413242  6673 solver.cpp:228] Iteration 23160, loss = 0.225962
I0626 22:37:17.413266  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:37:17.413272  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.157655 (* 1 = 0.157655 loss)
I0626 22:37:17.413276  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.154777 (* 1 = 0.154777 loss)
I0626 22:37:17.413280  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00521357 (* 1 = 0.00521357 loss)
I0626 22:37:17.413283  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353291 (* 1 = 0.0353291 loss)
I0626 22:37:17.413288  6673 sgd_solver.cpp:106] Iteration 23160, lr = 0.0002
I0626 22:38:55.854003  6673 solver.cpp:228] Iteration 23180, loss = 0.199397
I0626 22:38:55.854028  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 22:38:55.854038  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0637403 (* 1 = 0.0637403 loss)
I0626 22:38:55.854045  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.156253 (* 1 = 0.156253 loss)
I0626 22:38:55.854050  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000132702 (* 1 = 0.000132702 loss)
I0626 22:38:55.854058  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175765 (* 1 = 0.0175765 loss)
I0626 22:38:55.854066  6673 sgd_solver.cpp:106] Iteration 23180, lr = 0.0002
speed: 4.916s / iter
I0626 22:40:34.353273  6673 solver.cpp:228] Iteration 23200, loss = 0.200524
I0626 22:40:34.353298  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 22:40:34.353307  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0483182 (* 1 = 0.0483182 loss)
I0626 22:40:34.353310  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100911 (* 1 = 0.100911 loss)
I0626 22:40:34.353314  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000479868 (* 1 = 0.000479868 loss)
I0626 22:40:34.353318  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132084 (* 1 = 0.0132084 loss)
I0626 22:40:34.353324  6673 sgd_solver.cpp:106] Iteration 23200, lr = 0.0002
I0626 22:42:12.838932  6673 solver.cpp:228] Iteration 23220, loss = 0.0744485
I0626 22:42:12.838958  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:42:12.838966  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0585318 (* 1 = 0.0585318 loss)
I0626 22:42:12.838971  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.109402 (* 1 = 0.109402 loss)
I0626 22:42:12.838975  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186551 (* 1 = 0.00186551 loss)
I0626 22:42:12.838979  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.048137 (* 1 = 0.048137 loss)
I0626 22:42:12.838984  6673 sgd_solver.cpp:106] Iteration 23220, lr = 0.0002
I0626 22:43:51.137590  6673 solver.cpp:228] Iteration 23240, loss = 0.14374
I0626 22:43:51.137615  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:43:51.137622  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140896 (* 1 = 0.0140896 loss)
I0626 22:43:51.137627  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0603178 (* 1 = 0.0603178 loss)
I0626 22:43:51.137631  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00198252 (* 1 = 0.00198252 loss)
I0626 22:43:51.137634  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00231291 (* 1 = 0.00231291 loss)
I0626 22:43:51.137640  6673 sgd_solver.cpp:106] Iteration 23240, lr = 0.0002
I0626 22:45:29.377218  6673 solver.cpp:228] Iteration 23260, loss = 0.331106
I0626 22:45:29.377243  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 22:45:29.377250  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0699223 (* 1 = 0.0699223 loss)
I0626 22:45:29.377254  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.141255 (* 1 = 0.141255 loss)
I0626 22:45:29.377259  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130411 (* 1 = 0.00130411 loss)
I0626 22:45:29.377262  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170097 (* 1 = 0.0170097 loss)
I0626 22:45:29.377267  6673 sgd_solver.cpp:106] Iteration 23260, lr = 0.0002
I0626 22:47:07.322702  6673 solver.cpp:228] Iteration 23280, loss = 0.12094
I0626 22:47:07.322727  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 22:47:07.322734  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613656 (* 1 = 0.0613656 loss)
I0626 22:47:07.322738  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0864037 (* 1 = 0.0864037 loss)
I0626 22:47:07.322742  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00150822 (* 1 = 0.00150822 loss)
I0626 22:47:07.322746  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00254502 (* 1 = 0.00254502 loss)
I0626 22:47:07.322751  6673 sgd_solver.cpp:106] Iteration 23280, lr = 0.0002
I0626 22:48:45.364903  6673 solver.cpp:228] Iteration 23300, loss = 0.15618
I0626 22:48:45.364928  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 22:48:45.364935  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150746 (* 1 = 0.0150746 loss)
I0626 22:48:45.364939  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0456715 (* 1 = 0.0456715 loss)
I0626 22:48:45.364943  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.81208e-05 (* 1 = 2.81208e-05 loss)
I0626 22:48:45.364948  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00402735 (* 1 = 0.00402735 loss)
I0626 22:48:45.364953  6673 sgd_solver.cpp:106] Iteration 23300, lr = 0.0002
I0626 22:50:23.581786  6673 solver.cpp:228] Iteration 23320, loss = 0.116163
I0626 22:50:23.581823  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 22:50:23.581836  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0801317 (* 1 = 0.0801317 loss)
I0626 22:50:23.581843  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.105227 (* 1 = 0.105227 loss)
I0626 22:50:23.581851  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128943 (* 1 = 0.00128943 loss)
I0626 22:50:23.581857  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167387 (* 1 = 0.0167387 loss)
I0626 22:50:23.581866  6673 sgd_solver.cpp:106] Iteration 23320, lr = 0.0002
I0626 22:52:01.811301  6673 solver.cpp:228] Iteration 23340, loss = 0.113294
I0626 22:52:01.811326  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:52:01.811333  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205436 (* 1 = 0.0205436 loss)
I0626 22:52:01.811337  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0430114 (* 1 = 0.0430114 loss)
I0626 22:52:01.811342  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000557949 (* 1 = 0.000557949 loss)
I0626 22:52:01.811344  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149664 (* 1 = 0.0149664 loss)
I0626 22:52:01.811349  6673 sgd_solver.cpp:106] Iteration 23340, lr = 0.0002
I0626 22:53:39.986618  6673 solver.cpp:228] Iteration 23360, loss = 0.0842081
I0626 22:53:39.986644  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 22:53:39.986650  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468868 (* 1 = 0.0468868 loss)
I0626 22:53:39.986655  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0214676 (* 1 = 0.0214676 loss)
I0626 22:53:39.986660  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.59905e-05 (* 1 = 9.59905e-05 loss)
I0626 22:53:39.986662  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107901 (* 1 = 0.0107901 loss)
I0626 22:53:39.986668  6673 sgd_solver.cpp:106] Iteration 23360, lr = 0.0002
I0626 22:55:18.134590  6673 solver.cpp:228] Iteration 23380, loss = 0.129806
I0626 22:55:18.134616  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 22:55:18.134625  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174932 (* 1 = 0.0174932 loss)
I0626 22:55:18.134632  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0502195 (* 1 = 0.0502195 loss)
I0626 22:55:18.134639  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000429877 (* 1 = 0.000429877 loss)
I0626 22:55:18.134645  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0032442 (* 1 = 0.0032442 loss)
I0626 22:55:18.134651  6673 sgd_solver.cpp:106] Iteration 23380, lr = 0.0002
speed: 4.916s / iter
I0626 22:56:56.360812  6673 solver.cpp:228] Iteration 23400, loss = 0.0750579
I0626 22:56:56.360849  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0626 22:56:56.360857  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433154 (* 1 = 0.0433154 loss)
I0626 22:56:56.360860  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0793824 (* 1 = 0.0793824 loss)
I0626 22:56:56.360865  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00029776 (* 1 = 0.00029776 loss)
I0626 22:56:56.360872  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116883 (* 1 = 0.0116883 loss)
I0626 22:56:56.360878  6673 sgd_solver.cpp:106] Iteration 23400, lr = 0.0002
I0626 22:58:34.652091  6673 solver.cpp:228] Iteration 23420, loss = 0.0783541
I0626 22:58:34.652117  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 22:58:34.652123  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165938 (* 1 = 0.0165938 loss)
I0626 22:58:34.652127  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0228349 (* 1 = 0.0228349 loss)
I0626 22:58:34.652130  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000578487 (* 1 = 0.000578487 loss)
I0626 22:58:34.652133  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0047007 (* 1 = 0.0047007 loss)
I0626 22:58:34.652138  6673 sgd_solver.cpp:106] Iteration 23420, lr = 0.0002
I0626 23:00:13.019071  6673 solver.cpp:228] Iteration 23440, loss = 0.207332
I0626 23:00:13.019102  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:00:13.019112  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106443 (* 1 = 0.0106443 loss)
I0626 23:00:13.019119  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0487274 (* 1 = 0.0487274 loss)
I0626 23:00:13.019124  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00228668 (* 1 = 0.00228668 loss)
I0626 23:00:13.019130  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026347 (* 1 = 0.026347 loss)
I0626 23:00:13.019137  6673 sgd_solver.cpp:106] Iteration 23440, lr = 0.0002
I0626 23:01:51.455904  6673 solver.cpp:228] Iteration 23460, loss = 0.281396
I0626 23:01:51.455927  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:01:51.455935  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481521 (* 1 = 0.0481521 loss)
I0626 23:01:51.455940  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0646159 (* 1 = 0.0646159 loss)
I0626 23:01:51.455943  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000206576 (* 1 = 0.000206576 loss)
I0626 23:01:51.455947  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100444 (* 1 = 0.0100444 loss)
I0626 23:01:51.455952  6673 sgd_solver.cpp:106] Iteration 23460, lr = 0.0002
I0626 23:03:29.939652  6673 solver.cpp:228] Iteration 23480, loss = 0.11156
I0626 23:03:29.939677  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:03:29.939683  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273949 (* 1 = 0.0273949 loss)
I0626 23:03:29.939687  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.047251 (* 1 = 0.047251 loss)
I0626 23:03:29.939690  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237758 (* 1 = 0.00237758 loss)
I0626 23:03:29.939694  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00993009 (* 1 = 0.00993009 loss)
I0626 23:03:29.939698  6673 sgd_solver.cpp:106] Iteration 23480, lr = 0.0002
I0626 23:05:08.456610  6673 solver.cpp:228] Iteration 23500, loss = 0.139777
I0626 23:05:08.456637  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 23:05:08.456647  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.17938 (* 1 = 0.17938 loss)
I0626 23:05:08.456653  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.189225 (* 1 = 0.189225 loss)
I0626 23:05:08.456660  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00974302 (* 1 = 0.00974302 loss)
I0626 23:05:08.456666  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045309 (* 1 = 0.045309 loss)
I0626 23:05:08.456676  6673 sgd_solver.cpp:106] Iteration 23500, lr = 0.0002
I0626 23:06:47.005350  6673 solver.cpp:228] Iteration 23520, loss = 0.171726
I0626 23:06:47.005373  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 23:06:47.005380  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231881 (* 1 = 0.0231881 loss)
I0626 23:06:47.005385  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.120298 (* 1 = 0.120298 loss)
I0626 23:06:47.005389  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00289596 (* 1 = 0.00289596 loss)
I0626 23:06:47.005393  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146447 (* 1 = 0.0146447 loss)
I0626 23:06:47.005398  6673 sgd_solver.cpp:106] Iteration 23520, lr = 0.0002
I0626 23:08:25.593372  6673 solver.cpp:228] Iteration 23540, loss = 0.214729
I0626 23:08:25.593399  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0626 23:08:25.593406  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.164541 (* 1 = 0.164541 loss)
I0626 23:08:25.593413  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.250657 (* 1 = 0.250657 loss)
I0626 23:08:25.593420  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00983236 (* 1 = 0.00983236 loss)
I0626 23:08:25.593425  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443572 (* 1 = 0.0443572 loss)
I0626 23:08:25.593430  6673 sgd_solver.cpp:106] Iteration 23540, lr = 0.0002
I0626 23:10:04.234449  6673 solver.cpp:228] Iteration 23560, loss = 0.123595
I0626 23:10:04.234474  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:10:04.234483  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0129106 (* 1 = 0.0129106 loss)
I0626 23:10:04.234489  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0254673 (* 1 = 0.0254673 loss)
I0626 23:10:04.234494  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000216541 (* 1 = 0.000216541 loss)
I0626 23:10:04.234500  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00558856 (* 1 = 0.00558856 loss)
I0626 23:10:04.234505  6673 sgd_solver.cpp:106] Iteration 23560, lr = 0.0002
I0626 23:11:42.831109  6673 solver.cpp:228] Iteration 23580, loss = 0.084219
I0626 23:11:42.831131  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:11:42.831138  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466591 (* 1 = 0.0466591 loss)
I0626 23:11:42.831142  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.105175 (* 1 = 0.105175 loss)
I0626 23:11:42.831146  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000331283 (* 1 = 0.000331283 loss)
I0626 23:11:42.831149  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00875086 (* 1 = 0.00875086 loss)
I0626 23:11:42.831153  6673 sgd_solver.cpp:106] Iteration 23580, lr = 0.0002
speed: 4.916s / iter
I0626 23:13:21.871119  6673 solver.cpp:228] Iteration 23600, loss = 0.186646
I0626 23:13:21.871140  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:13:21.871147  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521616 (* 1 = 0.0521616 loss)
I0626 23:13:21.871152  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0624321 (* 1 = 0.0624321 loss)
I0626 23:13:21.871155  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178215 (* 1 = 0.0178215 loss)
I0626 23:13:21.871158  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0713023 (* 1 = 0.0713023 loss)
I0626 23:13:21.871163  6673 sgd_solver.cpp:106] Iteration 23600, lr = 0.0002
I0626 23:15:01.205754  6673 solver.cpp:228] Iteration 23620, loss = 0.124863
I0626 23:15:01.205781  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:15:01.205793  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0515784 (* 1 = 0.0515784 loss)
I0626 23:15:01.205801  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0804225 (* 1 = 0.0804225 loss)
I0626 23:15:01.205808  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00198996 (* 1 = 0.00198996 loss)
I0626 23:15:01.205816  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022816 (* 1 = 0.022816 loss)
I0626 23:15:01.205824  6673 sgd_solver.cpp:106] Iteration 23620, lr = 0.0002
I0626 23:16:40.806135  6673 solver.cpp:228] Iteration 23640, loss = 0.212497
I0626 23:16:40.806165  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:16:40.806174  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0288291 (* 1 = 0.0288291 loss)
I0626 23:16:40.806179  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.028573 (* 1 = 0.028573 loss)
I0626 23:16:40.806182  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00105755 (* 1 = 0.00105755 loss)
I0626 23:16:40.806187  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00965234 (* 1 = 0.00965234 loss)
I0626 23:16:40.806193  6673 sgd_solver.cpp:106] Iteration 23640, lr = 0.0002
I0626 23:18:20.111326  6673 solver.cpp:228] Iteration 23660, loss = 0.14008
I0626 23:18:20.111352  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:18:20.111362  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187605 (* 1 = 0.0187605 loss)
I0626 23:18:20.111369  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0191963 (* 1 = 0.0191963 loss)
I0626 23:18:20.111376  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00067712 (* 1 = 0.00067712 loss)
I0626 23:18:20.111382  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145936 (* 1 = 0.0145936 loss)
I0626 23:18:20.111390  6673 sgd_solver.cpp:106] Iteration 23660, lr = 0.0002
I0626 23:19:59.504457  6673 solver.cpp:228] Iteration 23680, loss = 0.207712
I0626 23:19:59.504482  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:19:59.504489  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0193907 (* 1 = 0.0193907 loss)
I0626 23:19:59.504493  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0511674 (* 1 = 0.0511674 loss)
I0626 23:19:59.504498  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000460958 (* 1 = 0.000460958 loss)
I0626 23:19:59.504501  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00429849 (* 1 = 0.00429849 loss)
I0626 23:19:59.504506  6673 sgd_solver.cpp:106] Iteration 23680, lr = 0.0002
I0626 23:21:38.668884  6673 solver.cpp:228] Iteration 23700, loss = 0.175382
I0626 23:21:38.668910  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:21:38.668916  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00862798 (* 1 = 0.00862798 loss)
I0626 23:21:38.668922  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0310077 (* 1 = 0.0310077 loss)
I0626 23:21:38.668929  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.9915e-05 (* 1 = 3.9915e-05 loss)
I0626 23:21:38.668934  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00510405 (* 1 = 0.00510405 loss)
I0626 23:21:38.668939  6673 sgd_solver.cpp:106] Iteration 23700, lr = 0.0002
I0626 23:23:17.803269  6673 solver.cpp:228] Iteration 23720, loss = 0.164979
I0626 23:23:17.803295  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 23:23:17.803304  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.113737 (* 1 = 0.113737 loss)
I0626 23:23:17.803310  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0932598 (* 1 = 0.0932598 loss)
I0626 23:23:17.803315  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00984074 (* 1 = 0.00984074 loss)
I0626 23:23:17.803321  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295318 (* 1 = 0.0295318 loss)
I0626 23:23:17.803326  6673 sgd_solver.cpp:106] Iteration 23720, lr = 0.0002
I0626 23:24:56.850652  6673 solver.cpp:228] Iteration 23740, loss = 0.0903698
I0626 23:24:56.850675  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:24:56.850685  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00796205 (* 1 = 0.00796205 loss)
I0626 23:24:56.850690  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0470028 (* 1 = 0.0470028 loss)
I0626 23:24:56.850697  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00773194 (* 1 = 0.00773194 loss)
I0626 23:24:56.850703  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0092503 (* 1 = 0.0092503 loss)
I0626 23:24:56.850708  6673 sgd_solver.cpp:106] Iteration 23740, lr = 0.0002
I0626 23:26:35.567354  6673 solver.cpp:228] Iteration 23760, loss = 0.0849537
I0626 23:26:35.567379  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:26:35.567386  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0257998 (* 1 = 0.0257998 loss)
I0626 23:26:35.567391  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0253858 (* 1 = 0.0253858 loss)
I0626 23:26:35.567394  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.49744e-05 (* 1 = 9.49744e-05 loss)
I0626 23:26:35.567399  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104482 (* 1 = 0.0104482 loss)
I0626 23:26:35.567402  6673 sgd_solver.cpp:106] Iteration 23760, lr = 0.0002
I0626 23:28:14.550082  6673 solver.cpp:228] Iteration 23780, loss = 0.199363
I0626 23:28:14.550107  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0626 23:28:14.550114  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132495 (* 1 = 0.0132495 loss)
I0626 23:28:14.550119  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0694287 (* 1 = 0.0694287 loss)
I0626 23:28:14.550123  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186367 (* 1 = 0.00186367 loss)
I0626 23:28:14.550127  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00432227 (* 1 = 0.00432227 loss)
I0626 23:28:14.550132  6673 sgd_solver.cpp:106] Iteration 23780, lr = 0.0002
speed: 4.916s / iter
I0626 23:29:53.270494  6673 solver.cpp:228] Iteration 23800, loss = 0.154537
I0626 23:29:53.270530  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:29:53.270542  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233275 (* 1 = 0.0233275 loss)
I0626 23:29:53.270551  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0311182 (* 1 = 0.0311182 loss)
I0626 23:29:53.270560  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.33628e-05 (* 1 = 8.33628e-05 loss)
I0626 23:29:53.270570  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00514979 (* 1 = 0.00514979 loss)
I0626 23:29:53.270579  6673 sgd_solver.cpp:106] Iteration 23800, lr = 0.0002
I0626 23:31:32.247848  6673 solver.cpp:228] Iteration 23820, loss = 0.106912
I0626 23:31:32.247876  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:31:32.247885  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166021 (* 1 = 0.0166021 loss)
I0626 23:31:32.247892  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0415898 (* 1 = 0.0415898 loss)
I0626 23:31:32.247897  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000944836 (* 1 = 0.000944836 loss)
I0626 23:31:32.247905  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00953296 (* 1 = 0.00953296 loss)
I0626 23:31:32.247912  6673 sgd_solver.cpp:106] Iteration 23820, lr = 0.0002
I0626 23:33:10.860337  6673 solver.cpp:228] Iteration 23840, loss = 0.0897544
I0626 23:33:10.860361  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:33:10.860371  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00997253 (* 1 = 0.00997253 loss)
I0626 23:33:10.860378  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0193711 (* 1 = 0.0193711 loss)
I0626 23:33:10.860384  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000102324 (* 1 = 0.000102324 loss)
I0626 23:33:10.860390  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0043626 (* 1 = 0.0043626 loss)
I0626 23:33:10.860396  6673 sgd_solver.cpp:106] Iteration 23840, lr = 0.0002
I0626 23:34:49.333915  6673 solver.cpp:228] Iteration 23860, loss = 0.268471
I0626 23:34:49.333942  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 23:34:49.333952  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0879187 (* 1 = 0.0879187 loss)
I0626 23:34:49.333959  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.147808 (* 1 = 0.147808 loss)
I0626 23:34:49.333966  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135415 (* 1 = 0.00135415 loss)
I0626 23:34:49.333972  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181498 (* 1 = 0.0181498 loss)
I0626 23:34:49.333978  6673 sgd_solver.cpp:106] Iteration 23860, lr = 0.0002
I0626 23:36:27.544879  6673 solver.cpp:228] Iteration 23880, loss = 0.146026
I0626 23:36:27.544903  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:36:27.544911  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175113 (* 1 = 0.0175113 loss)
I0626 23:36:27.544915  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0175272 (* 1 = 0.0175272 loss)
I0626 23:36:27.544919  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108228 (* 1 = 0.00108228 loss)
I0626 23:36:27.544924  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110192 (* 1 = 0.0110192 loss)
I0626 23:36:27.544929  6673 sgd_solver.cpp:106] Iteration 23880, lr = 0.0002
I0626 23:38:05.756436  6673 solver.cpp:228] Iteration 23900, loss = 0.138695
I0626 23:38:05.756460  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0626 23:38:05.756469  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440183 (* 1 = 0.0440183 loss)
I0626 23:38:05.756472  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0929582 (* 1 = 0.0929582 loss)
I0626 23:38:05.756475  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148457 (* 1 = 0.0148457 loss)
I0626 23:38:05.756479  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0891004 (* 1 = 0.0891004 loss)
I0626 23:38:05.756484  6673 sgd_solver.cpp:106] Iteration 23900, lr = 0.0002
I0626 23:39:44.087934  6673 solver.cpp:228] Iteration 23920, loss = 0.120743
I0626 23:39:44.087956  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:39:44.087962  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0405681 (* 1 = 0.0405681 loss)
I0626 23:39:44.087966  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0647892 (* 1 = 0.0647892 loss)
I0626 23:39:44.087970  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000323386 (* 1 = 0.000323386 loss)
I0626 23:39:44.087973  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148555 (* 1 = 0.0148555 loss)
I0626 23:39:44.087978  6673 sgd_solver.cpp:106] Iteration 23920, lr = 0.0002
I0626 23:41:22.539759  6673 solver.cpp:228] Iteration 23940, loss = 0.136858
I0626 23:41:22.539783  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:41:22.539790  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00890704 (* 1 = 0.00890704 loss)
I0626 23:41:22.539794  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0151286 (* 1 = 0.0151286 loss)
I0626 23:41:22.539798  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270762 (* 1 = 0.00270762 loss)
I0626 23:41:22.539801  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00908168 (* 1 = 0.00908168 loss)
I0626 23:41:22.539806  6673 sgd_solver.cpp:106] Iteration 23940, lr = 0.0002
I0626 23:43:00.819981  6673 solver.cpp:228] Iteration 23960, loss = 0.112426
I0626 23:43:00.820004  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:43:00.820011  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0057108 (* 1 = 0.0057108 loss)
I0626 23:43:00.820015  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0210709 (* 1 = 0.0210709 loss)
I0626 23:43:00.820019  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00889673 (* 1 = 0.00889673 loss)
I0626 23:43:00.820022  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00551416 (* 1 = 0.00551416 loss)
I0626 23:43:00.820027  6673 sgd_solver.cpp:106] Iteration 23960, lr = 0.0002
I0626 23:44:39.264343  6673 solver.cpp:228] Iteration 23980, loss = 0.181563
I0626 23:44:39.264370  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0626 23:44:39.264379  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240071 (* 1 = 0.0240071 loss)
I0626 23:44:39.264384  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.020746 (* 1 = 0.020746 loss)
I0626 23:44:39.264386  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.24925e-05 (* 1 = 5.24925e-05 loss)
I0626 23:44:39.264390  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00276987 (* 1 = 0.00276987 loss)
I0626 23:44:39.264396  6673 sgd_solver.cpp:106] Iteration 23980, lr = 0.0002
speed: 4.916s / iter
I0626 23:46:17.901643  6673 solver.cpp:228] Iteration 24000, loss = 0.1204
I0626 23:46:17.901684  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0626 23:46:17.901693  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549387 (* 1 = 0.0549387 loss)
I0626 23:46:17.901698  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.151516 (* 1 = 0.151516 loss)
I0626 23:46:17.901702  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00460283 (* 1 = 0.00460283 loss)
I0626 23:46:17.901707  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183233 (* 1 = 0.0183233 loss)
I0626 23:46:17.901715  6673 sgd_solver.cpp:106] Iteration 24000, lr = 0.0002
I0626 23:47:56.494364  6673 solver.cpp:228] Iteration 24020, loss = 0.278214
I0626 23:47:56.494390  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0626 23:47:56.494400  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529165 (* 1 = 0.0529165 loss)
I0626 23:47:56.494405  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.209442 (* 1 = 0.209442 loss)
I0626 23:47:56.494411  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246249 (* 1 = 0.0246249 loss)
I0626 23:47:56.494417  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113333 (* 1 = 0.113333 loss)
I0626 23:47:56.494423  6673 sgd_solver.cpp:106] Iteration 24020, lr = 0.0002
I0626 23:49:34.956826  6673 solver.cpp:228] Iteration 24040, loss = 0.19108
I0626 23:49:34.956851  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:49:34.956858  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0343706 (* 1 = 0.0343706 loss)
I0626 23:49:34.956862  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0587684 (* 1 = 0.0587684 loss)
I0626 23:49:34.956866  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00497649 (* 1 = 0.00497649 loss)
I0626 23:49:34.956871  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163036 (* 1 = 0.0163036 loss)
I0626 23:49:34.956876  6673 sgd_solver.cpp:106] Iteration 24040, lr = 0.0002
I0626 23:51:13.635242  6673 solver.cpp:228] Iteration 24060, loss = 0.115536
I0626 23:51:13.635267  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0626 23:51:13.635274  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.036235 (* 1 = 0.036235 loss)
I0626 23:51:13.635278  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.038106 (* 1 = 0.038106 loss)
I0626 23:51:13.635282  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000505885 (* 1 = 0.000505885 loss)
I0626 23:51:13.635287  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104735 (* 1 = 0.0104735 loss)
I0626 23:51:13.635291  6673 sgd_solver.cpp:106] Iteration 24060, lr = 0.0002
I0626 23:52:52.305235  6673 solver.cpp:228] Iteration 24080, loss = 0.114957
I0626 23:52:52.305266  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0626 23:52:52.305274  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00556986 (* 1 = 0.00556986 loss)
I0626 23:52:52.305277  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0171552 (* 1 = 0.0171552 loss)
I0626 23:52:52.305281  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000792944 (* 1 = 0.000792944 loss)
I0626 23:52:52.305284  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00296185 (* 1 = 0.00296185 loss)
I0626 23:52:52.305289  6673 sgd_solver.cpp:106] Iteration 24080, lr = 0.0002
I0626 23:54:31.050618  6673 solver.cpp:228] Iteration 24100, loss = 0.139053
I0626 23:54:31.050643  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:54:31.050652  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140881 (* 1 = 0.0140881 loss)
I0626 23:54:31.050655  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0810828 (* 1 = 0.0810828 loss)
I0626 23:54:31.050659  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0277534 (* 1 = 0.0277534 loss)
I0626 23:54:31.050663  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137951 (* 1 = 0.0137951 loss)
I0626 23:54:31.050668  6673 sgd_solver.cpp:106] Iteration 24100, lr = 0.0002
I0626 23:56:09.642622  6673 solver.cpp:228] Iteration 24120, loss = 0.18153
I0626 23:56:09.642647  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0626 23:56:09.642654  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625725 (* 1 = 0.0625725 loss)
I0626 23:56:09.642659  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0775604 (* 1 = 0.0775604 loss)
I0626 23:56:09.642663  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000347673 (* 1 = 0.000347673 loss)
I0626 23:56:09.642666  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106095 (* 1 = 0.0106095 loss)
I0626 23:56:09.642673  6673 sgd_solver.cpp:106] Iteration 24120, lr = 0.0002
I0626 23:57:48.591071  6673 solver.cpp:228] Iteration 24140, loss = 0.161747
I0626 23:57:48.591099  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0626 23:57:48.591106  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.118553 (* 1 = 0.118553 loss)
I0626 23:57:48.591111  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.177621 (* 1 = 0.177621 loss)
I0626 23:57:48.591115  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00316358 (* 1 = 0.00316358 loss)
I0626 23:57:48.591120  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254622 (* 1 = 0.0254622 loss)
I0626 23:57:48.591125  6673 sgd_solver.cpp:106] Iteration 24140, lr = 0.0002
I0626 23:59:27.405411  6673 solver.cpp:228] Iteration 24160, loss = 0.16454
I0626 23:59:27.405437  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0626 23:59:27.405445  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.106296 (* 1 = 0.106296 loss)
I0626 23:59:27.405450  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.170495 (* 1 = 0.170495 loss)
I0626 23:59:27.405453  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144273 (* 1 = 0.0144273 loss)
I0626 23:59:27.405457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0499142 (* 1 = 0.0499142 loss)
I0626 23:59:27.405462  6673 sgd_solver.cpp:106] Iteration 24160, lr = 0.0002
I0627 00:01:06.199610  6673 solver.cpp:228] Iteration 24180, loss = 0.119677
I0627 00:01:06.199638  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 00:01:06.199646  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.061294 (* 1 = 0.061294 loss)
I0627 00:01:06.199651  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.112544 (* 1 = 0.112544 loss)
I0627 00:01:06.199656  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000464345 (* 1 = 0.000464345 loss)
I0627 00:01:06.199661  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00836188 (* 1 = 0.00836188 loss)
I0627 00:01:06.199666  6673 sgd_solver.cpp:106] Iteration 24180, lr = 0.0002
speed: 4.916s / iter
I0627 00:02:45.920752  6673 solver.cpp:228] Iteration 24200, loss = 0.179895
I0627 00:02:45.920783  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:02:45.920791  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162254 (* 1 = 0.0162254 loss)
I0627 00:02:45.920795  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.016325 (* 1 = 0.016325 loss)
I0627 00:02:45.920799  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.64767e-05 (* 1 = 7.64767e-05 loss)
I0627 00:02:45.920804  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00186666 (* 1 = 0.00186666 loss)
I0627 00:02:45.920811  6673 sgd_solver.cpp:106] Iteration 24200, lr = 0.0002
I0627 00:04:25.514382  6673 solver.cpp:228] Iteration 24220, loss = 0.181655
I0627 00:04:25.514410  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 00:04:25.514417  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336684 (* 1 = 0.0336684 loss)
I0627 00:04:25.514421  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0959427 (* 1 = 0.0959427 loss)
I0627 00:04:25.514425  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000909975 (* 1 = 0.000909975 loss)
I0627 00:04:25.514430  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262993 (* 1 = 0.0262993 loss)
I0627 00:04:25.514434  6673 sgd_solver.cpp:106] Iteration 24220, lr = 0.0002
I0627 00:06:05.087766  6673 solver.cpp:228] Iteration 24240, loss = 0.157268
I0627 00:06:05.087790  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:06:05.087797  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0332739 (* 1 = 0.0332739 loss)
I0627 00:06:05.087802  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0371726 (* 1 = 0.0371726 loss)
I0627 00:06:05.087806  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000194069 (* 1 = 0.000194069 loss)
I0627 00:06:05.087810  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118295 (* 1 = 0.0118295 loss)
I0627 00:06:05.087815  6673 sgd_solver.cpp:106] Iteration 24240, lr = 0.0002
I0627 00:07:44.572968  6673 solver.cpp:228] Iteration 24260, loss = 0.140808
I0627 00:07:44.572993  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:07:44.573000  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128403 (* 1 = 0.0128403 loss)
I0627 00:07:44.573004  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.064843 (* 1 = 0.064843 loss)
I0627 00:07:44.573007  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000679227 (* 1 = 0.000679227 loss)
I0627 00:07:44.573011  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00719503 (* 1 = 0.00719503 loss)
I0627 00:07:44.573016  6673 sgd_solver.cpp:106] Iteration 24260, lr = 0.0002
I0627 00:09:23.946399  6673 solver.cpp:228] Iteration 24280, loss = 0.102093
I0627 00:09:23.946424  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 00:09:23.946429  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0209566 (* 1 = 0.0209566 loss)
I0627 00:09:23.946435  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.087464 (* 1 = 0.087464 loss)
I0627 00:09:23.946441  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00211922 (* 1 = 0.00211922 loss)
I0627 00:09:23.946445  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01202 (* 1 = 0.01202 loss)
I0627 00:09:23.946450  6673 sgd_solver.cpp:106] Iteration 24280, lr = 0.0002
I0627 00:11:03.437068  6673 solver.cpp:228] Iteration 24300, loss = 0.171426
I0627 00:11:03.437093  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 00:11:03.437104  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.219777 (* 1 = 0.219777 loss)
I0627 00:11:03.437110  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.191201 (* 1 = 0.191201 loss)
I0627 00:11:03.437117  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00245156 (* 1 = 0.00245156 loss)
I0627 00:11:03.437124  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0567014 (* 1 = 0.0567014 loss)
I0627 00:11:03.437132  6673 sgd_solver.cpp:106] Iteration 24300, lr = 0.0002
I0627 00:12:42.753051  6673 solver.cpp:228] Iteration 24320, loss = 0.0890409
I0627 00:12:42.753077  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:12:42.753085  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00161942 (* 1 = 0.00161942 loss)
I0627 00:12:42.753089  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.017328 (* 1 = 0.017328 loss)
I0627 00:12:42.753093  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000420885 (* 1 = 0.000420885 loss)
I0627 00:12:42.753098  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137747 (* 1 = 0.0137747 loss)
I0627 00:12:42.753103  6673 sgd_solver.cpp:106] Iteration 24320, lr = 0.0002
I0627 00:14:21.987547  6673 solver.cpp:228] Iteration 24340, loss = 0.0851236
I0627 00:14:21.987571  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 00:14:21.987577  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0463673 (* 1 = 0.0463673 loss)
I0627 00:14:21.987581  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.126574 (* 1 = 0.126574 loss)
I0627 00:14:21.987584  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000237667 (* 1 = 0.000237667 loss)
I0627 00:14:21.987588  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109778 (* 1 = 0.0109778 loss)
I0627 00:14:21.987592  6673 sgd_solver.cpp:106] Iteration 24340, lr = 0.0002
I0627 00:16:01.352968  6673 solver.cpp:228] Iteration 24360, loss = 0.269878
I0627 00:16:01.352993  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 00:16:01.353001  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.111828 (* 1 = 0.111828 loss)
I0627 00:16:01.353005  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130436 (* 1 = 0.130436 loss)
I0627 00:16:01.353009  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000653916 (* 1 = 0.000653916 loss)
I0627 00:16:01.353013  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216886 (* 1 = 0.0216886 loss)
I0627 00:16:01.353018  6673 sgd_solver.cpp:106] Iteration 24360, lr = 0.0002
I0627 00:17:40.415558  6673 solver.cpp:228] Iteration 24380, loss = 0.115525
I0627 00:17:40.415586  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 00:17:40.415594  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325636 (* 1 = 0.0325636 loss)
I0627 00:17:40.415598  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.121956 (* 1 = 0.121956 loss)
I0627 00:17:40.415601  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111299 (* 1 = 0.0111299 loss)
I0627 00:17:40.415604  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120912 (* 1 = 0.120912 loss)
I0627 00:17:40.415609  6673 sgd_solver.cpp:106] Iteration 24380, lr = 0.0002
speed: 4.917s / iter
I0627 00:19:19.555222  6673 solver.cpp:228] Iteration 24400, loss = 0.0979989
I0627 00:19:19.555245  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 00:19:19.555253  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.112388 (* 1 = 0.112388 loss)
I0627 00:19:19.555258  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.16042 (* 1 = 0.16042 loss)
I0627 00:19:19.555263  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000398519 (* 1 = 0.000398519 loss)
I0627 00:19:19.555266  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276938 (* 1 = 0.0276938 loss)
I0627 00:19:19.555270  6673 sgd_solver.cpp:106] Iteration 24400, lr = 0.0002
I0627 00:20:58.824697  6673 solver.cpp:228] Iteration 24420, loss = 0.208169
I0627 00:20:58.824723  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:20:58.824730  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0301152 (* 1 = 0.0301152 loss)
I0627 00:20:58.824736  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0369245 (* 1 = 0.0369245 loss)
I0627 00:20:58.824743  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00025344 (* 1 = 0.00025344 loss)
I0627 00:20:58.824748  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00247565 (* 1 = 0.00247565 loss)
I0627 00:20:58.824755  6673 sgd_solver.cpp:106] Iteration 24420, lr = 0.0002
I0627 00:22:37.657873  6673 solver.cpp:228] Iteration 24440, loss = 0.100805
I0627 00:22:37.657898  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:22:37.657905  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0372846 (* 1 = 0.0372846 loss)
I0627 00:22:37.657909  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0703907 (* 1 = 0.0703907 loss)
I0627 00:22:37.657912  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034809 (* 1 = 0.0034809 loss)
I0627 00:22:37.657917  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00858889 (* 1 = 0.00858889 loss)
I0627 00:22:37.657920  6673 sgd_solver.cpp:106] Iteration 24440, lr = 0.0002
I0627 00:24:16.265211  6673 solver.cpp:228] Iteration 24460, loss = 0.0949597
I0627 00:24:16.265240  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:24:16.265247  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.042854 (* 1 = 0.042854 loss)
I0627 00:24:16.265252  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0341714 (* 1 = 0.0341714 loss)
I0627 00:24:16.265256  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000184987 (* 1 = 0.000184987 loss)
I0627 00:24:16.265259  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00662694 (* 1 = 0.00662694 loss)
I0627 00:24:16.265265  6673 sgd_solver.cpp:106] Iteration 24460, lr = 0.0002
I0627 00:25:54.902173  6673 solver.cpp:228] Iteration 24480, loss = 0.161121
I0627 00:25:54.902196  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:25:54.902202  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310852 (* 1 = 0.0310852 loss)
I0627 00:25:54.902206  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0364049 (* 1 = 0.0364049 loss)
I0627 00:25:54.902210  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000824725 (* 1 = 0.000824725 loss)
I0627 00:25:54.902215  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00832877 (* 1 = 0.00832877 loss)
I0627 00:25:54.902217  6673 sgd_solver.cpp:106] Iteration 24480, lr = 0.0002
I0627 00:27:33.319797  6673 solver.cpp:228] Iteration 24500, loss = 0.191324
I0627 00:27:33.319821  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:27:33.319828  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241922 (* 1 = 0.0241922 loss)
I0627 00:27:33.319833  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0424559 (* 1 = 0.0424559 loss)
I0627 00:27:33.319838  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00177683 (* 1 = 0.00177683 loss)
I0627 00:27:33.319841  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124362 (* 1 = 0.0124362 loss)
I0627 00:27:33.319846  6673 sgd_solver.cpp:106] Iteration 24500, lr = 0.0002
I0627 00:29:11.880476  6673 solver.cpp:228] Iteration 24520, loss = 0.243932
I0627 00:29:11.880502  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:29:11.880511  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00997621 (* 1 = 0.00997621 loss)
I0627 00:29:11.880514  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.033547 (* 1 = 0.033547 loss)
I0627 00:29:11.880518  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00082467 (* 1 = 0.00082467 loss)
I0627 00:29:11.880522  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157404 (* 1 = 0.0157404 loss)
I0627 00:29:11.880527  6673 sgd_solver.cpp:106] Iteration 24520, lr = 0.0002
I0627 00:30:50.319250  6673 solver.cpp:228] Iteration 24540, loss = 0.119831
I0627 00:30:50.319273  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 00:30:50.319281  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0283222 (* 1 = 0.0283222 loss)
I0627 00:30:50.319285  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0642083 (* 1 = 0.0642083 loss)
I0627 00:30:50.319288  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000515688 (* 1 = 0.000515688 loss)
I0627 00:30:50.319291  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170504 (* 1 = 0.0170504 loss)
I0627 00:30:50.319296  6673 sgd_solver.cpp:106] Iteration 24540, lr = 0.0002
I0627 00:32:28.798987  6673 solver.cpp:228] Iteration 24560, loss = 0.146197
I0627 00:32:28.799012  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0627 00:32:28.799019  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.142028 (* 1 = 0.142028 loss)
I0627 00:32:28.799024  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.335868 (* 1 = 0.335868 loss)
I0627 00:32:28.799028  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0259775 (* 1 = 0.0259775 loss)
I0627 00:32:28.799032  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0444678 (* 1 = 0.0444678 loss)
I0627 00:32:28.799036  6673 sgd_solver.cpp:106] Iteration 24560, lr = 0.0002
I0627 00:34:07.413853  6673 solver.cpp:228] Iteration 24580, loss = 0.0915054
I0627 00:34:07.413880  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:34:07.413889  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00895696 (* 1 = 0.00895696 loss)
I0627 00:34:07.413895  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0505276 (* 1 = 0.0505276 loss)
I0627 00:34:07.413900  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00130069 (* 1 = 0.00130069 loss)
I0627 00:34:07.413906  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203622 (* 1 = 0.0203622 loss)
I0627 00:34:07.413913  6673 sgd_solver.cpp:106] Iteration 24580, lr = 0.0002
speed: 4.917s / iter
I0627 00:35:45.972877  6673 solver.cpp:228] Iteration 24600, loss = 0.119972
I0627 00:35:45.972903  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 00:35:45.972910  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0236519 (* 1 = 0.0236519 loss)
I0627 00:35:45.972914  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.076925 (* 1 = 0.076925 loss)
I0627 00:35:45.972918  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000969841 (* 1 = 0.000969841 loss)
I0627 00:35:45.972923  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00899531 (* 1 = 0.00899531 loss)
I0627 00:35:45.972928  6673 sgd_solver.cpp:106] Iteration 24600, lr = 0.0002
I0627 00:37:24.821493  6673 solver.cpp:228] Iteration 24620, loss = 0.136088
I0627 00:37:24.821518  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:37:24.821525  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0202773 (* 1 = 0.0202773 loss)
I0627 00:37:24.821529  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0371103 (* 1 = 0.0371103 loss)
I0627 00:37:24.821532  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000355539 (* 1 = 0.000355539 loss)
I0627 00:37:24.821537  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00963019 (* 1 = 0.00963019 loss)
I0627 00:37:24.821540  6673 sgd_solver.cpp:106] Iteration 24620, lr = 0.0002
I0627 00:39:03.641070  6673 solver.cpp:228] Iteration 24640, loss = 0.176403
I0627 00:39:03.641095  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:39:03.641103  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247706 (* 1 = 0.0247706 loss)
I0627 00:39:03.641106  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0312364 (* 1 = 0.0312364 loss)
I0627 00:39:03.641110  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000697042 (* 1 = 0.000697042 loss)
I0627 00:39:03.641113  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00940087 (* 1 = 0.00940087 loss)
I0627 00:39:03.641119  6673 sgd_solver.cpp:106] Iteration 24640, lr = 0.0002
I0627 00:40:42.467381  6673 solver.cpp:228] Iteration 24660, loss = 0.078575
I0627 00:40:42.467404  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 00:40:42.467412  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133379 (* 1 = 0.0133379 loss)
I0627 00:40:42.467417  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0472942 (* 1 = 0.0472942 loss)
I0627 00:40:42.467420  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000343456 (* 1 = 0.000343456 loss)
I0627 00:40:42.467424  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00238546 (* 1 = 0.00238546 loss)
I0627 00:40:42.467429  6673 sgd_solver.cpp:106] Iteration 24660, lr = 0.0002
I0627 00:42:21.219830  6673 solver.cpp:228] Iteration 24680, loss = 0.102343
I0627 00:42:21.219854  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:42:21.219861  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0343285 (* 1 = 0.0343285 loss)
I0627 00:42:21.219864  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0421958 (* 1 = 0.0421958 loss)
I0627 00:42:21.219868  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101501 (* 1 = 0.0101501 loss)
I0627 00:42:21.219871  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0073283 (* 1 = 0.0073283 loss)
I0627 00:42:21.219877  6673 sgd_solver.cpp:106] Iteration 24680, lr = 0.0002
I0627 00:44:00.078572  6673 solver.cpp:228] Iteration 24700, loss = 0.158715
I0627 00:44:00.078594  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:44:00.078601  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161184 (* 1 = 0.0161184 loss)
I0627 00:44:00.078605  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0167979 (* 1 = 0.0167979 loss)
I0627 00:44:00.078608  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000276629 (* 1 = 0.000276629 loss)
I0627 00:44:00.078613  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0044396 (* 1 = 0.0044396 loss)
I0627 00:44:00.078616  6673 sgd_solver.cpp:106] Iteration 24700, lr = 0.0002
I0627 00:45:38.935539  6673 solver.cpp:228] Iteration 24720, loss = 0.224249
I0627 00:45:38.935569  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:45:38.935576  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225959 (* 1 = 0.0225959 loss)
I0627 00:45:38.935581  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0632095 (* 1 = 0.0632095 loss)
I0627 00:45:38.935585  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193108 (* 1 = 0.00193108 loss)
I0627 00:45:38.935590  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220622 (* 1 = 0.0220622 loss)
I0627 00:45:38.935595  6673 sgd_solver.cpp:106] Iteration 24720, lr = 0.0002
I0627 00:47:17.819586  6673 solver.cpp:228] Iteration 24740, loss = 0.0845317
I0627 00:47:17.819612  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:47:17.819618  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0110407 (* 1 = 0.0110407 loss)
I0627 00:47:17.819622  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0276375 (* 1 = 0.0276375 loss)
I0627 00:47:17.819627  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.68548e-05 (* 1 = 7.68548e-05 loss)
I0627 00:47:17.819629  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00143113 (* 1 = 0.00143113 loss)
I0627 00:47:17.819634  6673 sgd_solver.cpp:106] Iteration 24740, lr = 0.0002
I0627 00:48:56.636236  6673 solver.cpp:228] Iteration 24760, loss = 0.160599
I0627 00:48:56.636260  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0627 00:48:56.636265  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.138969 (* 1 = 0.138969 loss)
I0627 00:48:56.636270  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.235928 (* 1 = 0.235928 loss)
I0627 00:48:56.636273  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238595 (* 1 = 0.00238595 loss)
I0627 00:48:56.636276  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0615431 (* 1 = 0.0615431 loss)
I0627 00:48:56.636281  6673 sgd_solver.cpp:106] Iteration 24760, lr = 0.0002
I0627 00:50:35.911449  6673 solver.cpp:228] Iteration 24780, loss = 0.215311
I0627 00:50:35.911481  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 00:50:35.911491  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453603 (* 1 = 0.0453603 loss)
I0627 00:50:35.911499  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.137192 (* 1 = 0.137192 loss)
I0627 00:50:35.911504  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202922 (* 1 = 0.00202922 loss)
I0627 00:50:35.911510  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368307 (* 1 = 0.0368307 loss)
I0627 00:50:35.911518  6673 sgd_solver.cpp:106] Iteration 24780, lr = 0.0002
speed: 4.917s / iter
I0627 00:52:15.693428  6673 solver.cpp:228] Iteration 24800, loss = 0.145475
I0627 00:52:15.693459  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:52:15.693472  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0194609 (* 1 = 0.0194609 loss)
I0627 00:52:15.693481  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0426582 (* 1 = 0.0426582 loss)
I0627 00:52:15.693490  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00310033 (* 1 = 0.00310033 loss)
I0627 00:52:15.693502  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318554 (* 1 = 0.0318554 loss)
I0627 00:52:15.693512  6673 sgd_solver.cpp:106] Iteration 24800, lr = 0.0002
I0627 00:53:55.406383  6673 solver.cpp:228] Iteration 24820, loss = 0.173875
I0627 00:53:55.406409  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0627 00:53:55.406417  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.331834 (* 1 = 0.331834 loss)
I0627 00:53:55.406422  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.451845 (* 1 = 0.451845 loss)
I0627 00:53:55.406427  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0665992 (* 1 = 0.0665992 loss)
I0627 00:53:55.406433  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115118 (* 1 = 0.115118 loss)
I0627 00:53:55.406438  6673 sgd_solver.cpp:106] Iteration 24820, lr = 0.0002
I0627 00:55:35.005300  6673 solver.cpp:228] Iteration 24840, loss = 0.188238
I0627 00:55:35.005326  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 00:55:35.005334  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0253548 (* 1 = 0.0253548 loss)
I0627 00:55:35.005339  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0277225 (* 1 = 0.0277225 loss)
I0627 00:55:35.005344  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.39614e-05 (* 1 = 9.39614e-05 loss)
I0627 00:55:35.005350  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00205922 (* 1 = 0.00205922 loss)
I0627 00:55:35.005357  6673 sgd_solver.cpp:106] Iteration 24840, lr = 0.0002
I0627 00:57:14.377817  6673 solver.cpp:228] Iteration 24860, loss = 0.0841826
I0627 00:57:14.377840  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 00:57:14.377847  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434143 (* 1 = 0.0434143 loss)
I0627 00:57:14.377851  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0634082 (* 1 = 0.0634082 loss)
I0627 00:57:14.377856  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000128581 (* 1 = 0.000128581 loss)
I0627 00:57:14.377858  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142034 (* 1 = 0.0142034 loss)
I0627 00:57:14.377862  6673 sgd_solver.cpp:106] Iteration 24860, lr = 0.0002
I0627 00:58:53.858394  6673 solver.cpp:228] Iteration 24880, loss = 0.091377
I0627 00:58:53.858420  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 00:58:53.858428  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.027208 (* 1 = 0.027208 loss)
I0627 00:58:53.858433  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0310148 (* 1 = 0.0310148 loss)
I0627 00:58:53.858436  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.50775e-05 (* 1 = 7.50775e-05 loss)
I0627 00:58:53.858440  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00252546 (* 1 = 0.00252546 loss)
I0627 00:58:53.858444  6673 sgd_solver.cpp:106] Iteration 24880, lr = 0.0002
I0627 01:00:33.240108  6673 solver.cpp:228] Iteration 24900, loss = 0.182197
I0627 01:00:33.240134  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:00:33.240140  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0340292 (* 1 = 0.0340292 loss)
I0627 01:00:33.240144  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0778035 (* 1 = 0.0778035 loss)
I0627 01:00:33.240149  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00196553 (* 1 = 0.00196553 loss)
I0627 01:00:33.240152  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153593 (* 1 = 0.0153593 loss)
I0627 01:00:33.240159  6673 sgd_solver.cpp:106] Iteration 24900, lr = 0.0002
I0627 01:02:12.433435  6673 solver.cpp:228] Iteration 24920, loss = 0.166836
I0627 01:02:12.433459  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 01:02:12.433466  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150228 (* 1 = 0.0150228 loss)
I0627 01:02:12.433470  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00923317 (* 1 = 0.00923317 loss)
I0627 01:02:12.433473  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000872153 (* 1 = 0.000872153 loss)
I0627 01:02:12.433476  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010439 (* 1 = 0.010439 loss)
I0627 01:02:12.433481  6673 sgd_solver.cpp:106] Iteration 24920, lr = 0.0002
I0627 01:03:51.711272  6673 solver.cpp:228] Iteration 24940, loss = 0.143835
I0627 01:03:51.711294  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0627 01:03:51.711302  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.179286 (* 1 = 0.179286 loss)
I0627 01:03:51.711307  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.306623 (* 1 = 0.306623 loss)
I0627 01:03:51.711310  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00243734 (* 1 = 0.00243734 loss)
I0627 01:03:51.711313  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0461894 (* 1 = 0.0461894 loss)
I0627 01:03:51.711319  6673 sgd_solver.cpp:106] Iteration 24940, lr = 0.0002
I0627 01:05:30.691761  6673 solver.cpp:228] Iteration 24960, loss = 0.280107
I0627 01:05:30.691787  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0627 01:05:30.691794  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.178733 (* 1 = 0.178733 loss)
I0627 01:05:30.691798  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.320521 (* 1 = 0.320521 loss)
I0627 01:05:30.691802  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0439362 (* 1 = 0.0439362 loss)
I0627 01:05:30.691807  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.24115 (* 1 = 0.24115 loss)
I0627 01:05:30.691812  6673 sgd_solver.cpp:106] Iteration 24960, lr = 0.0002
I0627 01:07:09.748872  6673 solver.cpp:228] Iteration 24980, loss = 0.0854287
I0627 01:07:09.748898  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:07:09.748906  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0584591 (* 1 = 0.0584591 loss)
I0627 01:07:09.748911  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0487352 (* 1 = 0.0487352 loss)
I0627 01:07:09.748914  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259637 (* 1 = 0.00259637 loss)
I0627 01:07:09.748919  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103146 (* 1 = 0.0103146 loss)
I0627 01:07:09.748924  6673 sgd_solver.cpp:106] Iteration 24980, lr = 0.0002
speed: 4.917s / iter
I0627 01:08:44.087291  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_25000.caffemodel
I0627 01:08:49.393673  6673 solver.cpp:228] Iteration 25000, loss = 0.17324
I0627 01:08:49.393698  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 01:08:49.393707  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0304222 (* 1 = 0.0304222 loss)
I0627 01:08:49.393710  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0205335 (* 1 = 0.0205335 loss)
I0627 01:08:49.393714  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000465576 (* 1 = 0.000465576 loss)
I0627 01:08:49.393718  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010955 (* 1 = 0.010955 loss)
I0627 01:08:49.393723  6673 sgd_solver.cpp:106] Iteration 25000, lr = 0.0002
I0627 01:10:28.224273  6673 solver.cpp:228] Iteration 25020, loss = 0.124643
I0627 01:10:28.224297  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 01:10:28.224303  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248443 (* 1 = 0.0248443 loss)
I0627 01:10:28.224308  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0829348 (* 1 = 0.0829348 loss)
I0627 01:10:28.224311  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00458177 (* 1 = 0.00458177 loss)
I0627 01:10:28.224314  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00554499 (* 1 = 0.00554499 loss)
I0627 01:10:28.224319  6673 sgd_solver.cpp:106] Iteration 25020, lr = 0.0002
I0627 01:12:06.581969  6673 solver.cpp:228] Iteration 25040, loss = 0.223636
I0627 01:12:06.581997  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:12:06.582005  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168682 (* 1 = 0.0168682 loss)
I0627 01:12:06.582010  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0224836 (* 1 = 0.0224836 loss)
I0627 01:12:06.582013  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000266716 (* 1 = 0.000266716 loss)
I0627 01:12:06.582018  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00135175 (* 1 = 0.00135175 loss)
I0627 01:12:06.582024  6673 sgd_solver.cpp:106] Iteration 25040, lr = 0.0002
I0627 01:13:44.980491  6673 solver.cpp:228] Iteration 25060, loss = 0.12891
I0627 01:13:44.980517  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 01:13:44.980525  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156758 (* 1 = 0.0156758 loss)
I0627 01:13:44.980530  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.016523 (* 1 = 0.016523 loss)
I0627 01:13:44.980535  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00272199 (* 1 = 0.00272199 loss)
I0627 01:13:44.980537  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00707583 (* 1 = 0.00707583 loss)
I0627 01:13:44.980543  6673 sgd_solver.cpp:106] Iteration 25060, lr = 0.0002
I0627 01:15:23.493360  6673 solver.cpp:228] Iteration 25080, loss = 0.102285
I0627 01:15:23.493386  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:15:23.493396  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.105526 (* 1 = 0.105526 loss)
I0627 01:15:23.493402  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.064508 (* 1 = 0.064508 loss)
I0627 01:15:23.493408  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00224757 (* 1 = 0.00224757 loss)
I0627 01:15:23.493415  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.039701 (* 1 = 0.039701 loss)
I0627 01:15:23.493422  6673 sgd_solver.cpp:106] Iteration 25080, lr = 0.0002
I0627 01:17:01.887218  6673 solver.cpp:228] Iteration 25100, loss = 0.117292
I0627 01:17:01.887243  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:17:01.887250  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0736404 (* 1 = 0.0736404 loss)
I0627 01:17:01.887255  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0762994 (* 1 = 0.0762994 loss)
I0627 01:17:01.887259  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000248973 (* 1 = 0.000248973 loss)
I0627 01:17:01.887262  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113342 (* 1 = 0.0113342 loss)
I0627 01:17:01.887269  6673 sgd_solver.cpp:106] Iteration 25100, lr = 0.0002
I0627 01:18:40.233027  6673 solver.cpp:228] Iteration 25120, loss = 0.0875424
I0627 01:18:40.233052  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:18:40.233058  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121563 (* 1 = 0.0121563 loss)
I0627 01:18:40.233062  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0324765 (* 1 = 0.0324765 loss)
I0627 01:18:40.233067  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000276529 (* 1 = 0.000276529 loss)
I0627 01:18:40.233069  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00430305 (* 1 = 0.00430305 loss)
I0627 01:18:40.233074  6673 sgd_solver.cpp:106] Iteration 25120, lr = 0.0002
I0627 01:20:18.726263  6673 solver.cpp:228] Iteration 25140, loss = 0.125149
I0627 01:20:18.726287  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:20:18.726294  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0124341 (* 1 = 0.0124341 loss)
I0627 01:20:18.726299  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0257854 (* 1 = 0.0257854 loss)
I0627 01:20:18.726302  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000264718 (* 1 = 0.000264718 loss)
I0627 01:20:18.726305  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00407982 (* 1 = 0.00407982 loss)
I0627 01:20:18.726310  6673 sgd_solver.cpp:106] Iteration 25140, lr = 0.0002
I0627 01:21:57.303704  6673 solver.cpp:228] Iteration 25160, loss = 0.16996
I0627 01:21:57.303728  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:21:57.303736  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183056 (* 1 = 0.0183056 loss)
I0627 01:21:57.303740  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0668219 (* 1 = 0.0668219 loss)
I0627 01:21:57.303743  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0036882 (* 1 = 0.0036882 loss)
I0627 01:21:57.303747  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220663 (* 1 = 0.0220663 loss)
I0627 01:21:57.303752  6673 sgd_solver.cpp:106] Iteration 25160, lr = 0.0002
I0627 01:23:35.733297  6673 solver.cpp:228] Iteration 25180, loss = 0.132703
I0627 01:23:35.733322  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:23:35.733330  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0257904 (* 1 = 0.0257904 loss)
I0627 01:23:35.733333  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0234121 (* 1 = 0.0234121 loss)
I0627 01:23:35.733337  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000752715 (* 1 = 0.000752715 loss)
I0627 01:23:35.733340  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149063 (* 1 = 0.0149063 loss)
I0627 01:23:35.733345  6673 sgd_solver.cpp:106] Iteration 25180, lr = 0.0002
speed: 4.917s / iter
I0627 01:25:14.442523  6673 solver.cpp:228] Iteration 25200, loss = 0.0779682
I0627 01:25:14.442546  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:25:14.442553  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0137293 (* 1 = 0.0137293 loss)
I0627 01:25:14.442556  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0391996 (* 1 = 0.0391996 loss)
I0627 01:25:14.442560  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000332117 (* 1 = 0.000332117 loss)
I0627 01:25:14.442564  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00598488 (* 1 = 0.00598488 loss)
I0627 01:25:14.442569  6673 sgd_solver.cpp:106] Iteration 25200, lr = 0.0002
I0627 01:26:53.128566  6673 solver.cpp:228] Iteration 25220, loss = 0.138522
I0627 01:26:53.128592  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 01:26:53.128602  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0957237 (* 1 = 0.0957237 loss)
I0627 01:26:53.128608  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.184334 (* 1 = 0.184334 loss)
I0627 01:26:53.128615  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00290898 (* 1 = 0.00290898 loss)
I0627 01:26:53.128621  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0466602 (* 1 = 0.0466602 loss)
I0627 01:26:53.128628  6673 sgd_solver.cpp:106] Iteration 25220, lr = 0.0002
I0627 01:28:31.753741  6673 solver.cpp:228] Iteration 25240, loss = 0.0865829
I0627 01:28:31.753765  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 01:28:31.753772  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0457959 (* 1 = 0.0457959 loss)
I0627 01:28:31.753777  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0766051 (* 1 = 0.0766051 loss)
I0627 01:28:31.753779  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000857925 (* 1 = 0.000857925 loss)
I0627 01:28:31.753783  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180995 (* 1 = 0.0180995 loss)
I0627 01:28:31.753787  6673 sgd_solver.cpp:106] Iteration 25240, lr = 0.0002
I0627 01:30:10.360958  6673 solver.cpp:228] Iteration 25260, loss = 0.151071
I0627 01:30:10.360981  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 01:30:10.360990  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327727 (* 1 = 0.0327727 loss)
I0627 01:30:10.360992  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.105805 (* 1 = 0.105805 loss)
I0627 01:30:10.360996  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00785782 (* 1 = 0.00785782 loss)
I0627 01:30:10.360999  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00468146 (* 1 = 0.00468146 loss)
I0627 01:30:10.361004  6673 sgd_solver.cpp:106] Iteration 25260, lr = 0.0002
I0627 01:31:49.174762  6673 solver.cpp:228] Iteration 25280, loss = 0.256758
I0627 01:31:49.174788  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:31:49.174798  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0286542 (* 1 = 0.0286542 loss)
I0627 01:31:49.174805  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0655145 (* 1 = 0.0655145 loss)
I0627 01:31:49.174810  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053224 (* 1 = 0.0053224 loss)
I0627 01:31:49.174818  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167 (* 1 = 0.0167 loss)
I0627 01:31:49.174826  6673 sgd_solver.cpp:106] Iteration 25280, lr = 0.0002
I0627 01:33:27.891595  6673 solver.cpp:228] Iteration 25300, loss = 0.176367
I0627 01:33:27.891623  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:33:27.891631  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00341492 (* 1 = 0.00341492 loss)
I0627 01:33:27.891636  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0295607 (* 1 = 0.0295607 loss)
I0627 01:33:27.891640  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.90466e-05 (* 1 = 8.90466e-05 loss)
I0627 01:33:27.891644  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00649447 (* 1 = 0.00649447 loss)
I0627 01:33:27.891649  6673 sgd_solver.cpp:106] Iteration 25300, lr = 0.0002
I0627 01:35:06.601043  6673 solver.cpp:228] Iteration 25320, loss = 0.0983354
I0627 01:35:06.601069  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:35:06.601078  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00860736 (* 1 = 0.00860736 loss)
I0627 01:35:06.601081  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0263024 (* 1 = 0.0263024 loss)
I0627 01:35:06.601085  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00342504 (* 1 = 0.00342504 loss)
I0627 01:35:06.601089  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0057246 (* 1 = 0.0057246 loss)
I0627 01:35:06.601094  6673 sgd_solver.cpp:106] Iteration 25320, lr = 0.0002
I0627 01:36:45.450803  6673 solver.cpp:228] Iteration 25340, loss = 0.143305
I0627 01:36:45.450829  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 01:36:45.450835  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0656041 (* 1 = 0.0656041 loss)
I0627 01:36:45.450839  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0491006 (* 1 = 0.0491006 loss)
I0627 01:36:45.450844  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00913312 (* 1 = 0.00913312 loss)
I0627 01:36:45.450846  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206999 (* 1 = 0.0206999 loss)
I0627 01:36:45.450851  6673 sgd_solver.cpp:106] Iteration 25340, lr = 0.0002
I0627 01:38:24.381485  6673 solver.cpp:228] Iteration 25360, loss = 0.182505
I0627 01:38:24.381510  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:38:24.381517  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0514246 (* 1 = 0.0514246 loss)
I0627 01:38:24.381525  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.104967 (* 1 = 0.104967 loss)
I0627 01:38:24.381531  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00935913 (* 1 = 0.00935913 loss)
I0627 01:38:24.381534  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394976 (* 1 = 0.0394976 loss)
I0627 01:38:24.381539  6673 sgd_solver.cpp:106] Iteration 25360, lr = 0.0002
I0627 01:40:03.824630  6673 solver.cpp:228] Iteration 25380, loss = 0.157434
I0627 01:40:03.824654  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:40:03.824662  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00997304 (* 1 = 0.00997304 loss)
I0627 01:40:03.824667  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0270593 (* 1 = 0.0270593 loss)
I0627 01:40:03.824671  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260681 (* 1 = 0.00260681 loss)
I0627 01:40:03.824674  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00957784 (* 1 = 0.00957784 loss)
I0627 01:40:03.824679  6673 sgd_solver.cpp:106] Iteration 25380, lr = 0.0002
speed: 4.918s / iter
I0627 01:41:43.320628  6673 solver.cpp:228] Iteration 25400, loss = 0.118568
I0627 01:41:43.320653  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 01:41:43.320660  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0185821 (* 1 = 0.0185821 loss)
I0627 01:41:43.320664  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0188249 (* 1 = 0.0188249 loss)
I0627 01:41:43.320667  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.79043e-05 (* 1 = 8.79043e-05 loss)
I0627 01:41:43.320672  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00552483 (* 1 = 0.00552483 loss)
I0627 01:41:43.320677  6673 sgd_solver.cpp:106] Iteration 25400, lr = 0.0002
I0627 01:43:22.968600  6673 solver.cpp:228] Iteration 25420, loss = 0.148994
I0627 01:43:22.968623  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:43:22.968632  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00992511 (* 1 = 0.00992511 loss)
I0627 01:43:22.968638  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0578443 (* 1 = 0.0578443 loss)
I0627 01:43:22.968643  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00213243 (* 1 = 0.00213243 loss)
I0627 01:43:22.968648  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00141624 (* 1 = 0.00141624 loss)
I0627 01:43:22.968655  6673 sgd_solver.cpp:106] Iteration 25420, lr = 0.0002
I0627 01:45:02.566711  6673 solver.cpp:228] Iteration 25440, loss = 0.132639
I0627 01:45:02.566735  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:45:02.566741  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00950906 (* 1 = 0.00950906 loss)
I0627 01:45:02.566746  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0261476 (* 1 = 0.0261476 loss)
I0627 01:45:02.566750  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000112974 (* 1 = 0.000112974 loss)
I0627 01:45:02.566752  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00481929 (* 1 = 0.00481929 loss)
I0627 01:45:02.566757  6673 sgd_solver.cpp:106] Iteration 25440, lr = 0.0002
I0627 01:46:42.133103  6673 solver.cpp:228] Iteration 25460, loss = 0.102031
I0627 01:46:42.133127  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:46:42.133137  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0193145 (* 1 = 0.0193145 loss)
I0627 01:46:42.133143  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0712902 (* 1 = 0.0712902 loss)
I0627 01:46:42.133149  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000508829 (* 1 = 0.000508829 loss)
I0627 01:46:42.133157  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00506001 (* 1 = 0.00506001 loss)
I0627 01:46:42.133165  6673 sgd_solver.cpp:106] Iteration 25460, lr = 0.0002
I0627 01:48:21.353174  6673 solver.cpp:228] Iteration 25480, loss = 0.150179
I0627 01:48:21.353199  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 01:48:21.353207  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562564 (* 1 = 0.0562564 loss)
I0627 01:48:21.353211  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0741462 (* 1 = 0.0741462 loss)
I0627 01:48:21.353215  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250962 (* 1 = 0.00250962 loss)
I0627 01:48:21.353219  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020746 (* 1 = 0.020746 loss)
I0627 01:48:21.353224  6673 sgd_solver.cpp:106] Iteration 25480, lr = 0.0002
I0627 01:50:00.793735  6673 solver.cpp:228] Iteration 25500, loss = 0.161716
I0627 01:50:00.793764  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0627 01:50:00.793773  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.13404 (* 1 = 0.13404 loss)
I0627 01:50:00.793778  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.236151 (* 1 = 0.236151 loss)
I0627 01:50:00.793783  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0075214 (* 1 = 0.0075214 loss)
I0627 01:50:00.793788  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414305 (* 1 = 0.0414305 loss)
I0627 01:50:00.793794  6673 sgd_solver.cpp:106] Iteration 25500, lr = 0.0002
I0627 01:51:39.959645  6673 solver.cpp:228] Iteration 25520, loss = 0.114066
I0627 01:51:39.959674  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 01:51:39.959686  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170437 (* 1 = 0.0170437 loss)
I0627 01:51:39.959695  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.132373 (* 1 = 0.132373 loss)
I0627 01:51:39.959704  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000700313 (* 1 = 0.000700313 loss)
I0627 01:51:39.959713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00775781 (* 1 = 0.00775781 loss)
I0627 01:51:39.959723  6673 sgd_solver.cpp:106] Iteration 25520, lr = 0.0002
I0627 01:53:19.274689  6673 solver.cpp:228] Iteration 25540, loss = 0.153343
I0627 01:53:19.274726  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:53:19.274735  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703311 (* 1 = 0.0703311 loss)
I0627 01:53:19.274740  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.121524 (* 1 = 0.121524 loss)
I0627 01:53:19.274744  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0374074 (* 1 = 0.0374074 loss)
I0627 01:53:19.274747  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.166212 (* 1 = 0.166212 loss)
I0627 01:53:19.274755  6673 sgd_solver.cpp:106] Iteration 25540, lr = 0.0002
I0627 01:54:58.336052  6673 solver.cpp:228] Iteration 25560, loss = 0.0746024
I0627 01:54:58.336076  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 01:54:58.336082  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0462929 (* 1 = 0.0462929 loss)
I0627 01:54:58.336086  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.108571 (* 1 = 0.108571 loss)
I0627 01:54:58.336091  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0002901 (* 1 = 0.0002901 loss)
I0627 01:54:58.336093  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00785962 (* 1 = 0.00785962 loss)
I0627 01:54:58.336098  6673 sgd_solver.cpp:106] Iteration 25560, lr = 0.0002
I0627 01:56:37.342813  6673 solver.cpp:228] Iteration 25580, loss = 0.145385
I0627 01:56:37.342839  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:56:37.342846  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113952 (* 1 = 0.0113952 loss)
I0627 01:56:37.342850  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0348312 (* 1 = 0.0348312 loss)
I0627 01:56:37.342854  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000718251 (* 1 = 0.000718251 loss)
I0627 01:56:37.342861  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00529683 (* 1 = 0.00529683 loss)
I0627 01:56:37.342866  6673 sgd_solver.cpp:106] Iteration 25580, lr = 0.0002
speed: 4.918s / iter
I0627 01:58:16.219434  6673 solver.cpp:228] Iteration 25600, loss = 0.11302
I0627 01:58:16.219461  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 01:58:16.219470  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333207 (* 1 = 0.0333207 loss)
I0627 01:58:16.219476  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0643991 (* 1 = 0.0643991 loss)
I0627 01:58:16.219481  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00553216 (* 1 = 0.00553216 loss)
I0627 01:58:16.219488  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0072548 (* 1 = 0.0072548 loss)
I0627 01:58:16.219496  6673 sgd_solver.cpp:106] Iteration 25600, lr = 0.0002
I0627 01:59:55.027130  6673 solver.cpp:228] Iteration 25620, loss = 0.119178
I0627 01:59:55.027154  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 01:59:55.027161  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.023259 (* 1 = 0.023259 loss)
I0627 01:59:55.027165  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0297615 (* 1 = 0.0297615 loss)
I0627 01:59:55.027169  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000198923 (* 1 = 0.000198923 loss)
I0627 01:59:55.027173  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00542725 (* 1 = 0.00542725 loss)
I0627 01:59:55.027176  6673 sgd_solver.cpp:106] Iteration 25620, lr = 0.0002
I0627 02:01:33.792809  6673 solver.cpp:228] Iteration 25640, loss = 0.234964
I0627 02:01:33.792834  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:01:33.792840  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203679 (* 1 = 0.0203679 loss)
I0627 02:01:33.792845  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0761703 (* 1 = 0.0761703 loss)
I0627 02:01:33.792848  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00026291 (* 1 = 0.00026291 loss)
I0627 02:01:33.792853  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00840929 (* 1 = 0.00840929 loss)
I0627 02:01:33.792858  6673 sgd_solver.cpp:106] Iteration 25640, lr = 0.0002
I0627 02:03:12.367661  6673 solver.cpp:228] Iteration 25660, loss = 0.17163
I0627 02:03:12.367683  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0627 02:03:12.367691  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.218247 (* 1 = 0.218247 loss)
I0627 02:03:12.367696  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.32697 (* 1 = 0.32697 loss)
I0627 02:03:12.367698  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00753698 (* 1 = 0.00753698 loss)
I0627 02:03:12.367702  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101678 (* 1 = 0.101678 loss)
I0627 02:03:12.367707  6673 sgd_solver.cpp:106] Iteration 25660, lr = 0.0002
I0627 02:04:50.898437  6673 solver.cpp:228] Iteration 25680, loss = 0.14913
I0627 02:04:50.898463  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:04:50.898471  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166164 (* 1 = 0.0166164 loss)
I0627 02:04:50.898478  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0282651 (* 1 = 0.0282651 loss)
I0627 02:04:50.898483  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00658417 (* 1 = 0.00658417 loss)
I0627 02:04:50.898488  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00542087 (* 1 = 0.00542087 loss)
I0627 02:04:50.898494  6673 sgd_solver.cpp:106] Iteration 25680, lr = 0.0002
I0627 02:06:29.420647  6673 solver.cpp:228] Iteration 25700, loss = 0.148931
I0627 02:06:29.420672  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 02:06:29.420680  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0629408 (* 1 = 0.0629408 loss)
I0627 02:06:29.420683  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.203974 (* 1 = 0.203974 loss)
I0627 02:06:29.420687  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000444203 (* 1 = 0.000444203 loss)
I0627 02:06:29.420691  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193315 (* 1 = 0.0193315 loss)
I0627 02:06:29.420696  6673 sgd_solver.cpp:106] Iteration 25700, lr = 0.0002
I0627 02:08:07.910537  6673 solver.cpp:228] Iteration 25720, loss = 0.125388
I0627 02:08:07.910562  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 02:08:07.910571  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333241 (* 1 = 0.0333241 loss)
I0627 02:08:07.910578  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0935401 (* 1 = 0.0935401 loss)
I0627 02:08:07.910583  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000339428 (* 1 = 0.000339428 loss)
I0627 02:08:07.910588  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00606938 (* 1 = 0.00606938 loss)
I0627 02:08:07.910594  6673 sgd_solver.cpp:106] Iteration 25720, lr = 0.0002
I0627 02:09:46.429561  6673 solver.cpp:228] Iteration 25740, loss = 0.170063
I0627 02:09:46.429587  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:09:46.429595  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.021469 (* 1 = 0.021469 loss)
I0627 02:09:46.429600  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0374197 (* 1 = 0.0374197 loss)
I0627 02:09:46.429603  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.17569e-05 (* 1 = 9.17569e-05 loss)
I0627 02:09:46.429607  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00240316 (* 1 = 0.00240316 loss)
I0627 02:09:46.429612  6673 sgd_solver.cpp:106] Iteration 25740, lr = 0.0002
I0627 02:11:24.939045  6673 solver.cpp:228] Iteration 25760, loss = 0.0952666
I0627 02:11:24.939070  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:11:24.939079  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0302285 (* 1 = 0.0302285 loss)
I0627 02:11:24.939082  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0383113 (* 1 = 0.0383113 loss)
I0627 02:11:24.939086  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.95548e-05 (* 1 = 8.95548e-05 loss)
I0627 02:11:24.939090  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00428047 (* 1 = 0.00428047 loss)
I0627 02:11:24.939095  6673 sgd_solver.cpp:106] Iteration 25760, lr = 0.0002
I0627 02:13:03.579247  6673 solver.cpp:228] Iteration 25780, loss = 0.149374
I0627 02:13:03.579308  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:13:03.579322  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590592 (* 1 = 0.0590592 loss)
I0627 02:13:03.579330  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0301429 (* 1 = 0.0301429 loss)
I0627 02:13:03.579337  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00108234 (* 1 = 0.00108234 loss)
I0627 02:13:03.579344  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196891 (* 1 = 0.0196891 loss)
I0627 02:13:03.579355  6673 sgd_solver.cpp:106] Iteration 25780, lr = 0.0002
speed: 4.918s / iter
I0627 02:14:42.293356  6673 solver.cpp:228] Iteration 25800, loss = 0.0598978
I0627 02:14:42.293381  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:14:42.293388  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122811 (* 1 = 0.0122811 loss)
I0627 02:14:42.293392  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0711802 (* 1 = 0.0711802 loss)
I0627 02:14:42.293396  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265611 (* 1 = 0.00265611 loss)
I0627 02:14:42.293400  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122301 (* 1 = 0.0122301 loss)
I0627 02:14:42.293403  6673 sgd_solver.cpp:106] Iteration 25800, lr = 0.0002
I0627 02:16:21.009395  6673 solver.cpp:228] Iteration 25820, loss = 0.140627
I0627 02:16:21.009419  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:16:21.009428  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0235247 (* 1 = 0.0235247 loss)
I0627 02:16:21.009431  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0258721 (* 1 = 0.0258721 loss)
I0627 02:16:21.009434  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000607308 (* 1 = 0.000607308 loss)
I0627 02:16:21.009438  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00288854 (* 1 = 0.00288854 loss)
I0627 02:16:21.009443  6673 sgd_solver.cpp:106] Iteration 25820, lr = 0.0002
I0627 02:17:59.707772  6673 solver.cpp:228] Iteration 25840, loss = 0.119516
I0627 02:17:59.707798  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 02:17:59.707804  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0906852 (* 1 = 0.0906852 loss)
I0627 02:17:59.707809  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.126281 (* 1 = 0.126281 loss)
I0627 02:17:59.707813  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00051685 (* 1 = 0.00051685 loss)
I0627 02:17:59.707816  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022739 (* 1 = 0.022739 loss)
I0627 02:17:59.707821  6673 sgd_solver.cpp:106] Iteration 25840, lr = 0.0002
I0627 02:19:38.569170  6673 solver.cpp:228] Iteration 25860, loss = 0.111061
I0627 02:19:38.569193  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:19:38.569200  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190136 (* 1 = 0.0190136 loss)
I0627 02:19:38.569205  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0362158 (* 1 = 0.0362158 loss)
I0627 02:19:38.569208  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000125537 (* 1 = 0.000125537 loss)
I0627 02:19:38.569211  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0015145 (* 1 = 0.0015145 loss)
I0627 02:19:38.569216  6673 sgd_solver.cpp:106] Iteration 25860, lr = 0.0002
I0627 02:21:17.417196  6673 solver.cpp:228] Iteration 25880, loss = 0.101188
I0627 02:21:17.417220  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 02:21:17.417227  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.028841 (* 1 = 0.028841 loss)
I0627 02:21:17.417232  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0819838 (* 1 = 0.0819838 loss)
I0627 02:21:17.417235  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218335 (* 1 = 0.00218335 loss)
I0627 02:21:17.417239  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100281 (* 1 = 0.0100281 loss)
I0627 02:21:17.417243  6673 sgd_solver.cpp:106] Iteration 25880, lr = 0.0002
I0627 02:22:56.423660  6673 solver.cpp:228] Iteration 25900, loss = 0.135341
I0627 02:22:56.423683  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:22:56.423691  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362344 (* 1 = 0.0362344 loss)
I0627 02:22:56.423696  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0169635 (* 1 = 0.0169635 loss)
I0627 02:22:56.423699  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017945 (* 1 = 0.0017945 loss)
I0627 02:22:56.423702  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124743 (* 1 = 0.0124743 loss)
I0627 02:22:56.423707  6673 sgd_solver.cpp:106] Iteration 25900, lr = 0.0002
I0627 02:24:35.287911  6673 solver.cpp:228] Iteration 25920, loss = 0.126555
I0627 02:24:35.287935  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 02:24:35.287941  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309721 (* 1 = 0.0309721 loss)
I0627 02:24:35.287946  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0745034 (* 1 = 0.0745034 loss)
I0627 02:24:35.287950  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00932578 (* 1 = 0.00932578 loss)
I0627 02:24:35.287953  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018189 (* 1 = 0.018189 loss)
I0627 02:24:35.287958  6673 sgd_solver.cpp:106] Iteration 25920, lr = 0.0002
I0627 02:26:14.147356  6673 solver.cpp:228] Iteration 25940, loss = 0.112007
I0627 02:26:14.147382  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:26:14.147388  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00752218 (* 1 = 0.00752218 loss)
I0627 02:26:14.147392  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0207888 (* 1 = 0.0207888 loss)
I0627 02:26:14.147397  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0323633 (* 1 = 0.0323633 loss)
I0627 02:26:14.147400  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03222 (* 1 = 0.03222 loss)
I0627 02:26:14.147405  6673 sgd_solver.cpp:106] Iteration 25940, lr = 0.0002
I0627 02:27:53.359773  6673 solver.cpp:228] Iteration 25960, loss = 0.20596
I0627 02:27:53.359799  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:27:53.359808  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.124721 (* 1 = 0.124721 loss)
I0627 02:27:53.359814  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0300417 (* 1 = 0.0300417 loss)
I0627 02:27:53.359820  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000101343 (* 1 = 0.000101343 loss)
I0627 02:27:53.359825  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131777 (* 1 = 0.0131777 loss)
I0627 02:27:53.359832  6673 sgd_solver.cpp:106] Iteration 25960, lr = 0.0002
I0627 02:29:32.911263  6673 solver.cpp:228] Iteration 25980, loss = 0.205664
I0627 02:29:32.911288  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 02:29:32.911294  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.036325 (* 1 = 0.036325 loss)
I0627 02:29:32.911298  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0930271 (* 1 = 0.0930271 loss)
I0627 02:29:32.911303  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000615186 (* 1 = 0.000615186 loss)
I0627 02:29:32.911305  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00874119 (* 1 = 0.00874119 loss)
I0627 02:29:32.911310  6673 sgd_solver.cpp:106] Iteration 25980, lr = 0.0002
speed: 4.918s / iter
I0627 02:31:12.595490  6673 solver.cpp:228] Iteration 26000, loss = 0.0910552
I0627 02:31:12.595516  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:31:12.595523  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0129016 (* 1 = 0.0129016 loss)
I0627 02:31:12.595528  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0334887 (* 1 = 0.0334887 loss)
I0627 02:31:12.595532  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082105 (* 1 = 0.0082105 loss)
I0627 02:31:12.595537  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00333763 (* 1 = 0.00333763 loss)
I0627 02:31:12.595543  6673 sgd_solver.cpp:106] Iteration 26000, lr = 0.0002
I0627 02:32:52.178552  6673 solver.cpp:228] Iteration 26020, loss = 0.0902413
I0627 02:32:52.178575  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:32:52.178582  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245905 (* 1 = 0.0245905 loss)
I0627 02:32:52.178586  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0318249 (* 1 = 0.0318249 loss)
I0627 02:32:52.178591  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.682e-05 (* 1 = 8.682e-05 loss)
I0627 02:32:52.178594  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00429443 (* 1 = 0.00429443 loss)
I0627 02:32:52.178598  6673 sgd_solver.cpp:106] Iteration 26020, lr = 0.0002
I0627 02:34:31.779664  6673 solver.cpp:228] Iteration 26040, loss = 0.156427
I0627 02:34:31.779690  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:34:31.779697  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0153907 (* 1 = 0.0153907 loss)
I0627 02:34:31.779701  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0414497 (* 1 = 0.0414497 loss)
I0627 02:34:31.779706  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000197481 (* 1 = 0.000197481 loss)
I0627 02:34:31.779709  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00401911 (* 1 = 0.00401911 loss)
I0627 02:34:31.779714  6673 sgd_solver.cpp:106] Iteration 26040, lr = 0.0002
I0627 02:36:11.217669  6673 solver.cpp:228] Iteration 26060, loss = 0.110527
I0627 02:36:11.217694  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:36:11.217702  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0403128 (* 1 = 0.0403128 loss)
I0627 02:36:11.217706  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0439323 (* 1 = 0.0439323 loss)
I0627 02:36:11.217710  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139459 (* 1 = 0.0139459 loss)
I0627 02:36:11.217713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0219862 (* 1 = 0.0219862 loss)
I0627 02:36:11.217718  6673 sgd_solver.cpp:106] Iteration 26060, lr = 0.0002
I0627 02:37:50.412825  6673 solver.cpp:228] Iteration 26080, loss = 0.0946667
I0627 02:37:50.412849  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 02:37:50.412856  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0452685 (* 1 = 0.0452685 loss)
I0627 02:37:50.412860  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.04758 (* 1 = 0.04758 loss)
I0627 02:37:50.412864  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00691066 (* 1 = 0.00691066 loss)
I0627 02:37:50.412868  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135978 (* 1 = 0.0135978 loss)
I0627 02:37:50.412871  6673 sgd_solver.cpp:106] Iteration 26080, lr = 0.0002
I0627 02:39:29.742274  6673 solver.cpp:228] Iteration 26100, loss = 0.254578
I0627 02:39:29.742305  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0627 02:39:29.742314  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.240407 (* 1 = 0.240407 loss)
I0627 02:39:29.742321  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.257834 (* 1 = 0.257834 loss)
I0627 02:39:29.742326  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00242339 (* 1 = 0.00242339 loss)
I0627 02:39:29.742331  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044726 (* 1 = 0.044726 loss)
I0627 02:39:29.742338  6673 sgd_solver.cpp:106] Iteration 26100, lr = 0.0002
I0627 02:41:09.105753  6673 solver.cpp:228] Iteration 26120, loss = 0.145764
I0627 02:41:09.105782  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:41:09.105790  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0125195 (* 1 = 0.0125195 loss)
I0627 02:41:09.105798  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0358662 (* 1 = 0.0358662 loss)
I0627 02:41:09.105803  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000574205 (* 1 = 0.000574205 loss)
I0627 02:41:09.105809  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0028362 (* 1 = 0.0028362 loss)
I0627 02:41:09.105816  6673 sgd_solver.cpp:106] Iteration 26120, lr = 0.0002
I0627 02:42:48.261642  6673 solver.cpp:228] Iteration 26140, loss = 0.146032
I0627 02:42:48.261668  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:42:48.261679  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120845 (* 1 = 0.0120845 loss)
I0627 02:42:48.261685  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0385888 (* 1 = 0.0385888 loss)
I0627 02:42:48.261692  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000225636 (* 1 = 0.000225636 loss)
I0627 02:42:48.261698  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00727271 (* 1 = 0.00727271 loss)
I0627 02:42:48.261704  6673 sgd_solver.cpp:106] Iteration 26140, lr = 0.0002
I0627 02:44:27.358095  6673 solver.cpp:228] Iteration 26160, loss = 0.198009
I0627 02:44:27.358121  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 02:44:27.358130  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251667 (* 1 = 0.0251667 loss)
I0627 02:44:27.358137  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0600034 (* 1 = 0.0600034 loss)
I0627 02:44:27.358144  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179683 (* 1 = 0.00179683 loss)
I0627 02:44:27.358150  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00201182 (* 1 = 0.00201182 loss)
I0627 02:44:27.358158  6673 sgd_solver.cpp:106] Iteration 26160, lr = 0.0002
I0627 02:46:06.697901  6673 solver.cpp:228] Iteration 26180, loss = 0.132848
I0627 02:46:06.697929  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:46:06.697940  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176641 (* 1 = 0.0176641 loss)
I0627 02:46:06.697948  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0157126 (* 1 = 0.0157126 loss)
I0627 02:46:06.697955  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248468 (* 1 = 0.00248468 loss)
I0627 02:46:06.697963  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00444647 (* 1 = 0.00444647 loss)
I0627 02:46:06.697971  6673 sgd_solver.cpp:106] Iteration 26180, lr = 0.0002
speed: 4.919s / iter
I0627 02:47:45.558272  6673 solver.cpp:228] Iteration 26200, loss = 0.159144
I0627 02:47:45.558298  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 02:47:45.558305  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132146 (* 1 = 0.0132146 loss)
I0627 02:47:45.558310  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0218727 (* 1 = 0.0218727 loss)
I0627 02:47:45.558313  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184213 (* 1 = 0.00184213 loss)
I0627 02:47:45.558317  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00224657 (* 1 = 0.00224657 loss)
I0627 02:47:45.558321  6673 sgd_solver.cpp:106] Iteration 26200, lr = 0.0002
I0627 02:49:24.143692  6673 solver.cpp:228] Iteration 26220, loss = 0.117237
I0627 02:49:24.143714  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 02:49:24.143721  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379834 (* 1 = 0.0379834 loss)
I0627 02:49:24.143725  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.120571 (* 1 = 0.120571 loss)
I0627 02:49:24.143728  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0014896 (* 1 = 0.0014896 loss)
I0627 02:49:24.143733  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251622 (* 1 = 0.0251622 loss)
I0627 02:49:24.143736  6673 sgd_solver.cpp:106] Iteration 26220, lr = 0.0002
I0627 02:51:02.655807  6673 solver.cpp:228] Iteration 26240, loss = 0.0946712
I0627 02:51:02.655836  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:51:02.655844  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106744 (* 1 = 0.0106744 loss)
I0627 02:51:02.655849  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00682745 (* 1 = 0.00682745 loss)
I0627 02:51:02.655853  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00139142 (* 1 = 0.00139142 loss)
I0627 02:51:02.655858  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00477184 (* 1 = 0.00477184 loss)
I0627 02:51:02.655864  6673 sgd_solver.cpp:106] Iteration 26240, lr = 0.0002
I0627 02:52:41.213902  6673 solver.cpp:228] Iteration 26260, loss = 0.18018
I0627 02:52:41.213927  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 02:52:41.213935  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.156164 (* 1 = 0.156164 loss)
I0627 02:52:41.213939  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.239027 (* 1 = 0.239027 loss)
I0627 02:52:41.213943  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000889491 (* 1 = 0.000889491 loss)
I0627 02:52:41.213948  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438303 (* 1 = 0.0438303 loss)
I0627 02:52:41.213953  6673 sgd_solver.cpp:106] Iteration 26260, lr = 0.0002
I0627 02:54:19.708056  6673 solver.cpp:228] Iteration 26280, loss = 0.203923
I0627 02:54:19.708081  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:54:19.708087  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.022118 (* 1 = 0.022118 loss)
I0627 02:54:19.708092  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0301047 (* 1 = 0.0301047 loss)
I0627 02:54:19.708096  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.62368e-05 (* 1 = 2.62368e-05 loss)
I0627 02:54:19.708101  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00557903 (* 1 = 0.00557903 loss)
I0627 02:54:19.708104  6673 sgd_solver.cpp:106] Iteration 26280, lr = 0.0002
I0627 02:55:58.527281  6673 solver.cpp:228] Iteration 26300, loss = 0.167128
I0627 02:55:58.527307  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 02:55:58.527314  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.170358 (* 1 = 0.170358 loss)
I0627 02:55:58.527318  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.275756 (* 1 = 0.275756 loss)
I0627 02:55:58.527323  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00310206 (* 1 = 0.00310206 loss)
I0627 02:55:58.527326  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387316 (* 1 = 0.0387316 loss)
I0627 02:55:58.527330  6673 sgd_solver.cpp:106] Iteration 26300, lr = 0.0002
I0627 02:57:36.987929  6673 solver.cpp:228] Iteration 26320, loss = 0.065442
I0627 02:57:36.987952  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 02:57:36.987959  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00737503 (* 1 = 0.00737503 loss)
I0627 02:57:36.987963  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0218559 (* 1 = 0.0218559 loss)
I0627 02:57:36.987967  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00418197 (* 1 = 0.00418197 loss)
I0627 02:57:36.987970  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00306975 (* 1 = 0.00306975 loss)
I0627 02:57:36.987974  6673 sgd_solver.cpp:106] Iteration 26320, lr = 0.0002
I0627 02:59:15.479116  6673 solver.cpp:228] Iteration 26340, loss = 0.0765789
I0627 02:59:15.479140  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 02:59:15.479146  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142024 (* 1 = 0.0142024 loss)
I0627 02:59:15.479151  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0131842 (* 1 = 0.0131842 loss)
I0627 02:59:15.479154  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000124167 (* 1 = 0.000124167 loss)
I0627 02:59:15.479158  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000921209 (* 1 = 0.000921209 loss)
I0627 02:59:15.479162  6673 sgd_solver.cpp:106] Iteration 26340, lr = 0.0002
I0627 03:00:54.271946  6673 solver.cpp:228] Iteration 26360, loss = 0.0939978
I0627 03:00:54.271971  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:00:54.271980  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132084 (* 1 = 0.0132084 loss)
I0627 03:00:54.271983  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0482275 (* 1 = 0.0482275 loss)
I0627 03:00:54.271986  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00531465 (* 1 = 0.00531465 loss)
I0627 03:00:54.271991  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00342824 (* 1 = 0.00342824 loss)
I0627 03:00:54.271996  6673 sgd_solver.cpp:106] Iteration 26360, lr = 0.0002
I0627 03:02:32.908375  6673 solver.cpp:228] Iteration 26380, loss = 0.105003
I0627 03:02:32.908398  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:02:32.908406  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386386 (* 1 = 0.0386386 loss)
I0627 03:02:32.908411  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.10301 (* 1 = 0.10301 loss)
I0627 03:02:32.908413  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0272008 (* 1 = 0.0272008 loss)
I0627 03:02:32.908417  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186588 (* 1 = 0.0186588 loss)
I0627 03:02:32.908421  6673 sgd_solver.cpp:106] Iteration 26380, lr = 0.0002
speed: 4.919s / iter
I0627 03:04:11.684950  6673 solver.cpp:228] Iteration 26400, loss = 0.111593
I0627 03:04:11.684975  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:04:11.684983  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0281744 (* 1 = 0.0281744 loss)
I0627 03:04:11.684988  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.04269 (* 1 = 0.04269 loss)
I0627 03:04:11.684993  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.95139e-05 (* 1 = 9.95139e-05 loss)
I0627 03:04:11.684996  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00412921 (* 1 = 0.00412921 loss)
I0627 03:04:11.685000  6673 sgd_solver.cpp:106] Iteration 26400, lr = 0.0002
I0627 03:05:50.406782  6673 solver.cpp:228] Iteration 26420, loss = 0.161697
I0627 03:05:50.406807  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 03:05:50.406816  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0319486 (* 1 = 0.0319486 loss)
I0627 03:05:50.406819  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0882087 (* 1 = 0.0882087 loss)
I0627 03:05:50.406823  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178228 (* 1 = 0.0178228 loss)
I0627 03:05:50.406827  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237561 (* 1 = 0.0237561 loss)
I0627 03:05:50.406832  6673 sgd_solver.cpp:106] Iteration 26420, lr = 0.0002
I0627 03:07:29.147649  6673 solver.cpp:228] Iteration 26440, loss = 0.0911862
I0627 03:07:29.147677  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:07:29.147686  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.03566 (* 1 = 0.03566 loss)
I0627 03:07:29.147689  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.040762 (* 1 = 0.040762 loss)
I0627 03:07:29.147693  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00202327 (* 1 = 0.00202327 loss)
I0627 03:07:29.147696  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00527172 (* 1 = 0.00527172 loss)
I0627 03:07:29.147702  6673 sgd_solver.cpp:106] Iteration 26440, lr = 0.0002
I0627 03:09:08.180646  6673 solver.cpp:228] Iteration 26460, loss = 0.149205
I0627 03:09:08.180671  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:09:08.180680  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120605 (* 1 = 0.0120605 loss)
I0627 03:09:08.180685  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.047506 (* 1 = 0.047506 loss)
I0627 03:09:08.180687  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000229067 (* 1 = 0.000229067 loss)
I0627 03:09:08.180691  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00872296 (* 1 = 0.00872296 loss)
I0627 03:09:08.180696  6673 sgd_solver.cpp:106] Iteration 26460, lr = 0.0002
I0627 03:10:47.056843  6673 solver.cpp:228] Iteration 26480, loss = 0.200747
I0627 03:10:47.056867  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:10:47.056874  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0152992 (* 1 = 0.0152992 loss)
I0627 03:10:47.056879  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0146364 (* 1 = 0.0146364 loss)
I0627 03:10:47.056882  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.06789e-05 (* 1 = 2.06789e-05 loss)
I0627 03:10:47.056885  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000290101 (* 1 = 0.000290101 loss)
I0627 03:10:47.056890  6673 sgd_solver.cpp:106] Iteration 26480, lr = 0.0002
I0627 03:12:26.079370  6673 solver.cpp:228] Iteration 26500, loss = 0.179322
I0627 03:12:26.079394  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:12:26.079402  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0152939 (* 1 = 0.0152939 loss)
I0627 03:12:26.079406  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0158774 (* 1 = 0.0158774 loss)
I0627 03:12:26.079411  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.15059e-05 (* 1 = 9.15059e-05 loss)
I0627 03:12:26.079413  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229838 (* 1 = 0.00229838 loss)
I0627 03:12:26.079418  6673 sgd_solver.cpp:106] Iteration 26500, lr = 0.0002
I0627 03:14:04.965041  6673 solver.cpp:228] Iteration 26520, loss = 0.0922037
I0627 03:14:04.965065  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:14:04.965072  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203316 (* 1 = 0.0203316 loss)
I0627 03:14:04.965076  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.01639 (* 1 = 0.01639 loss)
I0627 03:14:04.965080  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.70046e-05 (* 1 = 5.70046e-05 loss)
I0627 03:14:04.965083  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101925 (* 1 = 0.0101925 loss)
I0627 03:14:04.965088  6673 sgd_solver.cpp:106] Iteration 26520, lr = 0.0002
I0627 03:15:44.185720  6673 solver.cpp:228] Iteration 26540, loss = 0.179936
I0627 03:15:44.185745  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:15:44.185752  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540656 (* 1 = 0.0540656 loss)
I0627 03:15:44.185756  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0550832 (* 1 = 0.0550832 loss)
I0627 03:15:44.185760  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000579052 (* 1 = 0.000579052 loss)
I0627 03:15:44.185765  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00748916 (* 1 = 0.00748916 loss)
I0627 03:15:44.185770  6673 sgd_solver.cpp:106] Iteration 26540, lr = 0.0002
I0627 03:17:23.808233  6673 solver.cpp:228] Iteration 26560, loss = 0.113435
I0627 03:17:23.808257  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:17:23.808264  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.117346 (* 1 = 0.117346 loss)
I0627 03:17:23.808267  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0552 (* 1 = 0.0552 loss)
I0627 03:17:23.808271  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00337617 (* 1 = 0.00337617 loss)
I0627 03:17:23.808275  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430117 (* 1 = 0.0430117 loss)
I0627 03:17:23.808279  6673 sgd_solver.cpp:106] Iteration 26560, lr = 0.0002
I0627 03:19:03.796890  6673 solver.cpp:228] Iteration 26580, loss = 0.135174
I0627 03:19:03.796914  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 03:19:03.796921  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.153996 (* 1 = 0.153996 loss)
I0627 03:19:03.796926  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.180306 (* 1 = 0.180306 loss)
I0627 03:19:03.796931  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00666184 (* 1 = 0.00666184 loss)
I0627 03:19:03.796934  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.063581 (* 1 = 0.063581 loss)
I0627 03:19:03.796939  6673 sgd_solver.cpp:106] Iteration 26580, lr = 0.0002
speed: 4.919s / iter
I0627 03:20:43.563446  6673 solver.cpp:228] Iteration 26600, loss = 0.0824579
I0627 03:20:43.563470  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:20:43.563478  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0999015 (* 1 = 0.0999015 loss)
I0627 03:20:43.563483  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0928598 (* 1 = 0.0928598 loss)
I0627 03:20:43.563486  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134396 (* 1 = 0.0134396 loss)
I0627 03:20:43.563490  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200961 (* 1 = 0.0200961 loss)
I0627 03:20:43.563495  6673 sgd_solver.cpp:106] Iteration 26600, lr = 0.0002
I0627 03:22:23.142102  6673 solver.cpp:228] Iteration 26620, loss = 0.152817
I0627 03:22:23.142125  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:22:23.142132  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167893 (* 1 = 0.0167893 loss)
I0627 03:22:23.142136  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0547996 (* 1 = 0.0547996 loss)
I0627 03:22:23.142139  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123853 (* 1 = 0.0123853 loss)
I0627 03:22:23.142143  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109297 (* 1 = 0.109297 loss)
I0627 03:22:23.142148  6673 sgd_solver.cpp:106] Iteration 26620, lr = 0.0002
I0627 03:24:02.590445  6673 solver.cpp:228] Iteration 26640, loss = 0.104792
I0627 03:24:02.590474  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:24:02.590483  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00677124 (* 1 = 0.00677124 loss)
I0627 03:24:02.590489  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0331772 (* 1 = 0.0331772 loss)
I0627 03:24:02.590493  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00811822 (* 1 = 0.00811822 loss)
I0627 03:24:02.590498  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0284923 (* 1 = 0.0284923 loss)
I0627 03:24:02.590504  6673 sgd_solver.cpp:106] Iteration 26640, lr = 0.0002
I0627 03:25:42.133980  6673 solver.cpp:228] Iteration 26660, loss = 0.158205
I0627 03:25:42.134003  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 03:25:42.134011  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.056472 (* 1 = 0.056472 loss)
I0627 03:25:42.134016  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0734835 (* 1 = 0.0734835 loss)
I0627 03:25:42.134018  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151368 (* 1 = 0.0151368 loss)
I0627 03:25:42.134022  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102615 (* 1 = 0.0102615 loss)
I0627 03:25:42.134027  6673 sgd_solver.cpp:106] Iteration 26660, lr = 0.0002
I0627 03:27:21.542896  6673 solver.cpp:228] Iteration 26680, loss = 0.0714856
I0627 03:27:21.542922  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:27:21.542929  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220036 (* 1 = 0.0220036 loss)
I0627 03:27:21.542933  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0845282 (* 1 = 0.0845282 loss)
I0627 03:27:21.542937  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0017409 (* 1 = 0.0017409 loss)
I0627 03:27:21.542942  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239709 (* 1 = 0.0239709 loss)
I0627 03:27:21.542945  6673 sgd_solver.cpp:106] Iteration 26680, lr = 0.0002
I0627 03:29:00.857342  6673 solver.cpp:228] Iteration 26700, loss = 0.135003
I0627 03:29:00.857365  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:29:00.857373  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156184 (* 1 = 0.0156184 loss)
I0627 03:29:00.857378  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0141165 (* 1 = 0.0141165 loss)
I0627 03:29:00.857380  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000452164 (* 1 = 0.000452164 loss)
I0627 03:29:00.857383  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105378 (* 1 = 0.0105378 loss)
I0627 03:29:00.857389  6673 sgd_solver.cpp:106] Iteration 26700, lr = 0.0002
I0627 03:30:40.226384  6673 solver.cpp:228] Iteration 26720, loss = 0.142304
I0627 03:30:40.226409  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 03:30:40.226416  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839225 (* 1 = 0.0839225 loss)
I0627 03:30:40.226420  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0854853 (* 1 = 0.0854853 loss)
I0627 03:30:40.226424  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000713453 (* 1 = 0.000713453 loss)
I0627 03:30:40.226428  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133863 (* 1 = 0.0133863 loss)
I0627 03:30:40.226431  6673 sgd_solver.cpp:106] Iteration 26720, lr = 0.0002
I0627 03:32:19.381580  6673 solver.cpp:228] Iteration 26740, loss = 0.11782
I0627 03:32:19.381605  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 03:32:19.381613  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386393 (* 1 = 0.0386393 loss)
I0627 03:32:19.381616  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.129061 (* 1 = 0.129061 loss)
I0627 03:32:19.381619  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000238531 (* 1 = 0.000238531 loss)
I0627 03:32:19.381623  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161438 (* 1 = 0.0161438 loss)
I0627 03:32:19.381628  6673 sgd_solver.cpp:106] Iteration 26740, lr = 0.0002
I0627 03:33:58.442587  6673 solver.cpp:228] Iteration 26760, loss = 0.115911
I0627 03:33:58.442613  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:33:58.442621  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571542 (* 1 = 0.0571542 loss)
I0627 03:33:58.442625  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0214218 (* 1 = 0.0214218 loss)
I0627 03:33:58.442629  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000233326 (* 1 = 0.000233326 loss)
I0627 03:33:58.442633  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169876 (* 1 = 0.0169876 loss)
I0627 03:33:58.442638  6673 sgd_solver.cpp:106] Iteration 26760, lr = 0.0002
I0627 03:35:37.518069  6673 solver.cpp:228] Iteration 26780, loss = 0.115673
I0627 03:35:37.518095  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:35:37.518102  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160418 (* 1 = 0.0160418 loss)
I0627 03:35:37.518106  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0400453 (* 1 = 0.0400453 loss)
I0627 03:35:37.518110  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134558 (* 1 = 0.00134558 loss)
I0627 03:35:37.518115  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00363765 (* 1 = 0.00363765 loss)
I0627 03:35:37.518119  6673 sgd_solver.cpp:106] Iteration 26780, lr = 0.0002
speed: 4.919s / iter
I0627 03:37:16.158430  6673 solver.cpp:228] Iteration 26800, loss = 0.185178
I0627 03:37:16.158455  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:37:16.158463  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00143284 (* 1 = 0.00143284 loss)
I0627 03:37:16.158468  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0392853 (* 1 = 0.0392853 loss)
I0627 03:37:16.158471  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00558315 (* 1 = 0.00558315 loss)
I0627 03:37:16.158474  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220571 (* 1 = 0.0220571 loss)
I0627 03:37:16.158479  6673 sgd_solver.cpp:106] Iteration 26800, lr = 0.0002
I0627 03:38:54.946593  6673 solver.cpp:228] Iteration 26820, loss = 0.161813
I0627 03:38:54.946617  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 03:38:54.946624  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0302184 (* 1 = 0.0302184 loss)
I0627 03:38:54.946629  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0571404 (* 1 = 0.0571404 loss)
I0627 03:38:54.946632  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000785522 (* 1 = 0.000785522 loss)
I0627 03:38:54.946635  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155394 (* 1 = 0.0155394 loss)
I0627 03:38:54.946640  6673 sgd_solver.cpp:106] Iteration 26820, lr = 0.0002
I0627 03:40:33.432731  6673 solver.cpp:228] Iteration 26840, loss = 0.114462
I0627 03:40:33.432757  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 03:40:33.432766  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298293 (* 1 = 0.0298293 loss)
I0627 03:40:33.432772  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00375636 (* 1 = 0.00375636 loss)
I0627 03:40:33.432777  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000133304 (* 1 = 0.000133304 loss)
I0627 03:40:33.432783  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014617 (* 1 = 0.014617 loss)
I0627 03:40:33.432790  6673 sgd_solver.cpp:106] Iteration 26840, lr = 0.0002
I0627 03:42:12.277987  6673 solver.cpp:228] Iteration 26860, loss = 0.116122
I0627 03:42:12.278010  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 03:42:12.278018  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0790106 (* 1 = 0.0790106 loss)
I0627 03:42:12.278023  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.102969 (* 1 = 0.102969 loss)
I0627 03:42:12.278028  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103389 (* 1 = 0.00103389 loss)
I0627 03:42:12.278033  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267701 (* 1 = 0.0267701 loss)
I0627 03:42:12.278038  6673 sgd_solver.cpp:106] Iteration 26860, lr = 0.0002
I0627 03:43:50.880913  6673 solver.cpp:228] Iteration 26880, loss = 0.159947
I0627 03:43:50.880940  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:43:50.880949  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0336747 (* 1 = 0.0336747 loss)
I0627 03:43:50.880954  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0541631 (* 1 = 0.0541631 loss)
I0627 03:43:50.880957  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00187967 (* 1 = 0.00187967 loss)
I0627 03:43:50.880960  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014713 (* 1 = 0.014713 loss)
I0627 03:43:50.880965  6673 sgd_solver.cpp:106] Iteration 26880, lr = 0.0002
I0627 03:45:29.623883  6673 solver.cpp:228] Iteration 26900, loss = 0.130236
I0627 03:45:29.623909  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 03:45:29.623916  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245543 (* 1 = 0.0245543 loss)
I0627 03:45:29.623922  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0683315 (* 1 = 0.0683315 loss)
I0627 03:45:29.623929  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119425 (* 1 = 0.00119425 loss)
I0627 03:45:29.623934  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179033 (* 1 = 0.0179033 loss)
I0627 03:45:29.623939  6673 sgd_solver.cpp:106] Iteration 26900, lr = 0.0002
I0627 03:47:08.259656  6673 solver.cpp:228] Iteration 26920, loss = 0.131868
I0627 03:47:08.259681  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 03:47:08.259690  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0853608 (* 1 = 0.0853608 loss)
I0627 03:47:08.259693  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.125159 (* 1 = 0.125159 loss)
I0627 03:47:08.259697  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000164102 (* 1 = 0.000164102 loss)
I0627 03:47:08.259701  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111557 (* 1 = 0.0111557 loss)
I0627 03:47:08.259706  6673 sgd_solver.cpp:106] Iteration 26920, lr = 0.0002
I0627 03:48:47.373215  6673 solver.cpp:228] Iteration 26940, loss = 0.259094
I0627 03:48:47.373241  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 03:48:47.373250  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817446 (* 1 = 0.0817446 loss)
I0627 03:48:47.373253  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100886 (* 1 = 0.100886 loss)
I0627 03:48:47.373257  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00140499 (* 1 = 0.00140499 loss)
I0627 03:48:47.373260  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115106 (* 1 = 0.0115106 loss)
I0627 03:48:47.373266  6673 sgd_solver.cpp:106] Iteration 26940, lr = 0.0002
I0627 03:50:26.227360  6673 solver.cpp:228] Iteration 26960, loss = 0.17845
I0627 03:50:26.227383  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:50:26.227389  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453289 (* 1 = 0.0453289 loss)
I0627 03:50:26.227394  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0436715 (* 1 = 0.0436715 loss)
I0627 03:50:26.227397  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000758248 (* 1 = 0.000758248 loss)
I0627 03:50:26.227401  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00684079 (* 1 = 0.00684079 loss)
I0627 03:50:26.227406  6673 sgd_solver.cpp:106] Iteration 26960, lr = 0.0002
I0627 03:52:05.117502  6673 solver.cpp:228] Iteration 26980, loss = 0.120938
I0627 03:52:05.117532  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:52:05.117539  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0889535 (* 1 = 0.0889535 loss)
I0627 03:52:05.117542  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0570272 (* 1 = 0.0570272 loss)
I0627 03:52:05.117547  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000416728 (* 1 = 0.000416728 loss)
I0627 03:52:05.117550  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187481 (* 1 = 0.0187481 loss)
I0627 03:52:05.117555  6673 sgd_solver.cpp:106] Iteration 26980, lr = 0.0002
speed: 4.920s / iter
I0627 03:53:43.891914  6673 solver.cpp:228] Iteration 27000, loss = 0.0886712
I0627 03:53:43.891939  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 03:53:43.891947  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.017254 (* 1 = 0.017254 loss)
I0627 03:53:43.891952  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0332024 (* 1 = 0.0332024 loss)
I0627 03:53:43.891955  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000121948 (* 1 = 0.000121948 loss)
I0627 03:53:43.891959  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00226972 (* 1 = 0.00226972 loss)
I0627 03:53:43.891964  6673 sgd_solver.cpp:106] Iteration 27000, lr = 0.0002
I0627 03:55:22.905438  6673 solver.cpp:228] Iteration 27020, loss = 0.0691447
I0627 03:55:22.905462  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 03:55:22.905469  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0204507 (* 1 = 0.0204507 loss)
I0627 03:55:22.905474  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0644409 (* 1 = 0.0644409 loss)
I0627 03:55:22.905478  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00421124 (* 1 = 0.00421124 loss)
I0627 03:55:22.905481  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113171 (* 1 = 0.0113171 loss)
I0627 03:55:22.905488  6673 sgd_solver.cpp:106] Iteration 27020, lr = 0.0002
I0627 03:57:01.856307  6673 solver.cpp:228] Iteration 27040, loss = 0.0861987
I0627 03:57:01.856331  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 03:57:01.856339  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0130699 (* 1 = 0.0130699 loss)
I0627 03:57:01.856343  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.112451 (* 1 = 0.112451 loss)
I0627 03:57:01.856348  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306263 (* 1 = 0.0306263 loss)
I0627 03:57:01.856351  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011222 (* 1 = 0.011222 loss)
I0627 03:57:01.856356  6673 sgd_solver.cpp:106] Iteration 27040, lr = 0.0002
I0627 03:58:40.834892  6673 solver.cpp:228] Iteration 27060, loss = 0.0874701
I0627 03:58:40.834918  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 03:58:40.834925  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0403496 (* 1 = 0.0403496 loss)
I0627 03:58:40.834929  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100646 (* 1 = 0.100646 loss)
I0627 03:58:40.834933  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737042 (* 1 = 0.00737042 loss)
I0627 03:58:40.834938  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371022 (* 1 = 0.0371022 loss)
I0627 03:58:40.834942  6673 sgd_solver.cpp:106] Iteration 27060, lr = 0.0002
I0627 04:00:19.925923  6673 solver.cpp:228] Iteration 27080, loss = 0.210501
I0627 04:00:19.925947  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:00:19.925956  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126351 (* 1 = 0.0126351 loss)
I0627 04:00:19.925962  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0191482 (* 1 = 0.0191482 loss)
I0627 04:00:19.925967  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000283573 (* 1 = 0.000283573 loss)
I0627 04:00:19.925972  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011037 (* 1 = 0.011037 loss)
I0627 04:00:19.925979  6673 sgd_solver.cpp:106] Iteration 27080, lr = 0.0002
I0627 04:01:59.113304  6673 solver.cpp:228] Iteration 27100, loss = 0.114072
I0627 04:01:59.113330  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:01:59.113338  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0109775 (* 1 = 0.0109775 loss)
I0627 04:01:59.113343  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00815476 (* 1 = 0.00815476 loss)
I0627 04:01:59.113346  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00866786 (* 1 = 0.00866786 loss)
I0627 04:01:59.113350  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0021253 (* 1 = 0.0021253 loss)
I0627 04:01:59.113355  6673 sgd_solver.cpp:106] Iteration 27100, lr = 0.0002
I0627 04:03:38.578435  6673 solver.cpp:228] Iteration 27120, loss = 0.165953
I0627 04:03:38.578460  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 04:03:38.578469  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142154 (* 1 = 0.0142154 loss)
I0627 04:03:38.578472  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0520009 (* 1 = 0.0520009 loss)
I0627 04:03:38.578476  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.08234e-05 (* 1 = 4.08234e-05 loss)
I0627 04:03:38.578480  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0029026 (* 1 = 0.0029026 loss)
I0627 04:03:38.578485  6673 sgd_solver.cpp:106] Iteration 27120, lr = 0.0002
I0627 04:05:18.400192  6673 solver.cpp:228] Iteration 27140, loss = 0.111845
I0627 04:05:18.400218  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:05:18.400223  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160625 (* 1 = 0.0160625 loss)
I0627 04:05:18.400228  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0100348 (* 1 = 0.0100348 loss)
I0627 04:05:18.400231  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.43359e-05 (* 1 = 8.43359e-05 loss)
I0627 04:05:18.400235  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00213064 (* 1 = 0.00213064 loss)
I0627 04:05:18.400240  6673 sgd_solver.cpp:106] Iteration 27140, lr = 0.0002
I0627 04:06:58.171185  6673 solver.cpp:228] Iteration 27160, loss = 0.18213
I0627 04:06:58.171213  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:06:58.171226  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121326 (* 1 = 0.0121326 loss)
I0627 04:06:58.171236  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0217628 (* 1 = 0.0217628 loss)
I0627 04:06:58.171244  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.91413e-05 (* 1 = 7.91413e-05 loss)
I0627 04:06:58.171253  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00180491 (* 1 = 0.00180491 loss)
I0627 04:06:58.171264  6673 sgd_solver.cpp:106] Iteration 27160, lr = 0.0002
I0627 04:08:38.038852  6673 solver.cpp:228] Iteration 27180, loss = 0.207835
I0627 04:08:38.038887  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 04:08:38.038899  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191131 (* 1 = 0.0191131 loss)
I0627 04:08:38.038908  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0486147 (* 1 = 0.0486147 loss)
I0627 04:08:38.038916  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.12041e-05 (* 1 = 5.12041e-05 loss)
I0627 04:08:38.038925  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00459152 (* 1 = 0.00459152 loss)
I0627 04:08:38.038933  6673 sgd_solver.cpp:106] Iteration 27180, lr = 0.0002
speed: 4.920s / iter
I0627 04:10:17.779637  6673 solver.cpp:228] Iteration 27200, loss = 0.268149
I0627 04:10:17.779665  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:10:17.779673  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00548112 (* 1 = 0.00548112 loss)
I0627 04:10:17.779678  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0206449 (* 1 = 0.0206449 loss)
I0627 04:10:17.779683  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000196923 (* 1 = 0.000196923 loss)
I0627 04:10:17.779687  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229844 (* 1 = 0.00229844 loss)
I0627 04:10:17.779693  6673 sgd_solver.cpp:106] Iteration 27200, lr = 0.0002
I0627 04:11:57.304301  6673 solver.cpp:228] Iteration 27220, loss = 0.145965
I0627 04:11:57.304327  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:11:57.304333  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758576 (* 1 = 0.0758576 loss)
I0627 04:11:57.304338  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0949447 (* 1 = 0.0949447 loss)
I0627 04:11:57.304342  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133485 (* 1 = 0.0133485 loss)
I0627 04:11:57.304345  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0292838 (* 1 = 0.0292838 loss)
I0627 04:11:57.304352  6673 sgd_solver.cpp:106] Iteration 27220, lr = 0.0002
I0627 04:13:37.031168  6673 solver.cpp:228] Iteration 27240, loss = 0.128508
I0627 04:13:37.031190  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:13:37.031198  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0139116 (* 1 = 0.0139116 loss)
I0627 04:13:37.031201  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0150481 (* 1 = 0.0150481 loss)
I0627 04:13:37.031205  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00726715 (* 1 = 0.00726715 loss)
I0627 04:13:37.031208  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00307302 (* 1 = 0.00307302 loss)
I0627 04:13:37.031213  6673 sgd_solver.cpp:106] Iteration 27240, lr = 0.0002
I0627 04:15:16.607410  6673 solver.cpp:228] Iteration 27260, loss = 0.0867383
I0627 04:15:16.607437  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 04:15:16.607445  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0660916 (* 1 = 0.0660916 loss)
I0627 04:15:16.607450  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.167915 (* 1 = 0.167915 loss)
I0627 04:15:16.607453  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194222 (* 1 = 0.00194222 loss)
I0627 04:15:16.607457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128373 (* 1 = 0.0128373 loss)
I0627 04:15:16.607461  6673 sgd_solver.cpp:106] Iteration 27260, lr = 0.0002
I0627 04:16:56.273659  6673 solver.cpp:228] Iteration 27280, loss = 0.12796
I0627 04:16:56.273689  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 04:16:56.273700  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0964475 (* 1 = 0.0964475 loss)
I0627 04:16:56.273708  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0750997 (* 1 = 0.0750997 loss)
I0627 04:16:56.273715  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000928261 (* 1 = 0.000928261 loss)
I0627 04:16:56.273722  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209911 (* 1 = 0.0209911 loss)
I0627 04:16:56.273730  6673 sgd_solver.cpp:106] Iteration 27280, lr = 0.0002
I0627 04:18:35.666740  6673 solver.cpp:228] Iteration 27300, loss = 0.226407
I0627 04:18:35.666769  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:18:35.666780  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.053347 (* 1 = 0.053347 loss)
I0627 04:18:35.666786  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0486191 (* 1 = 0.0486191 loss)
I0627 04:18:35.666791  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000398463 (* 1 = 0.000398463 loss)
I0627 04:18:35.666796  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154285 (* 1 = 0.0154285 loss)
I0627 04:18:35.666802  6673 sgd_solver.cpp:106] Iteration 27300, lr = 0.0002
I0627 04:20:15.054615  6673 solver.cpp:228] Iteration 27320, loss = 0.106453
I0627 04:20:15.054641  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 04:20:15.054651  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.032413 (* 1 = 0.032413 loss)
I0627 04:20:15.054656  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0591597 (* 1 = 0.0591597 loss)
I0627 04:20:15.054661  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000145777 (* 1 = 0.000145777 loss)
I0627 04:20:15.054666  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013119 (* 1 = 0.013119 loss)
I0627 04:20:15.054671  6673 sgd_solver.cpp:106] Iteration 27320, lr = 0.0002
I0627 04:21:54.394145  6673 solver.cpp:228] Iteration 27340, loss = 0.115122
I0627 04:21:54.394176  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:21:54.394184  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138705 (* 1 = 0.0138705 loss)
I0627 04:21:54.394188  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0240064 (* 1 = 0.0240064 loss)
I0627 04:21:54.394193  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.42893e-05 (* 1 = 8.42893e-05 loss)
I0627 04:21:54.394197  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00150339 (* 1 = 0.00150339 loss)
I0627 04:21:54.394203  6673 sgd_solver.cpp:106] Iteration 27340, lr = 0.0002
I0627 04:23:33.541419  6673 solver.cpp:228] Iteration 27360, loss = 0.157002
I0627 04:23:33.541442  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 04:23:33.541450  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0601366 (* 1 = 0.0601366 loss)
I0627 04:23:33.541453  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0552253 (* 1 = 0.0552253 loss)
I0627 04:23:33.541457  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151879 (* 1 = 0.00151879 loss)
I0627 04:23:33.541461  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103251 (* 1 = 0.0103251 loss)
I0627 04:23:33.541466  6673 sgd_solver.cpp:106] Iteration 27360, lr = 0.0002
I0627 04:25:12.212563  6673 solver.cpp:228] Iteration 27380, loss = 0.155134
I0627 04:25:12.212589  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:25:12.212596  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0358819 (* 1 = 0.0358819 loss)
I0627 04:25:12.212600  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0994328 (* 1 = 0.0994328 loss)
I0627 04:25:12.212604  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347635 (* 1 = 0.00347635 loss)
I0627 04:25:12.212608  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122907 (* 1 = 0.0122907 loss)
I0627 04:25:12.212613  6673 sgd_solver.cpp:106] Iteration 27380, lr = 0.0002
speed: 4.920s / iter
I0627 04:26:50.935034  6673 solver.cpp:228] Iteration 27400, loss = 0.119647
I0627 04:26:50.935060  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 04:26:50.935066  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0717507 (* 1 = 0.0717507 loss)
I0627 04:26:50.935071  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.131097 (* 1 = 0.131097 loss)
I0627 04:26:50.935075  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00165795 (* 1 = 0.00165795 loss)
I0627 04:26:50.935078  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121496 (* 1 = 0.0121496 loss)
I0627 04:26:50.935084  6673 sgd_solver.cpp:106] Iteration 27400, lr = 0.0002
I0627 04:28:29.659209  6673 solver.cpp:228] Iteration 27420, loss = 0.154271
I0627 04:28:29.659235  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 04:28:29.659243  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0980825 (* 1 = 0.0980825 loss)
I0627 04:28:29.659247  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.167203 (* 1 = 0.167203 loss)
I0627 04:28:29.659251  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116516 (* 1 = 0.00116516 loss)
I0627 04:28:29.659255  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182658 (* 1 = 0.0182658 loss)
I0627 04:28:29.659260  6673 sgd_solver.cpp:106] Iteration 27420, lr = 0.0002
I0627 04:30:08.365643  6673 solver.cpp:228] Iteration 27440, loss = 0.150492
I0627 04:30:08.365672  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:30:08.365682  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0111842 (* 1 = 0.0111842 loss)
I0627 04:30:08.365689  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0529262 (* 1 = 0.0529262 loss)
I0627 04:30:08.365694  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00125224 (* 1 = 0.00125224 loss)
I0627 04:30:08.365700  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195344 (* 1 = 0.0195344 loss)
I0627 04:30:08.365706  6673 sgd_solver.cpp:106] Iteration 27440, lr = 0.0002
I0627 04:31:47.010221  6673 solver.cpp:228] Iteration 27460, loss = 0.205546
I0627 04:31:47.010246  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0627 04:31:47.010255  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.164897 (* 1 = 0.164897 loss)
I0627 04:31:47.010260  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.327269 (* 1 = 0.327269 loss)
I0627 04:31:47.010264  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00399201 (* 1 = 0.00399201 loss)
I0627 04:31:47.010269  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0375014 (* 1 = 0.0375014 loss)
I0627 04:31:47.010274  6673 sgd_solver.cpp:106] Iteration 27460, lr = 0.0002
I0627 04:33:25.857501  6673 solver.cpp:228] Iteration 27480, loss = 0.141836
I0627 04:33:25.857527  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:33:25.857533  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148945 (* 1 = 0.0148945 loss)
I0627 04:33:25.857537  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0136734 (* 1 = 0.0136734 loss)
I0627 04:33:25.857542  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350782 (* 1 = 0.00350782 loss)
I0627 04:33:25.857544  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00195472 (* 1 = 0.00195472 loss)
I0627 04:33:25.857548  6673 sgd_solver.cpp:106] Iteration 27480, lr = 0.0002
I0627 04:35:04.470706  6673 solver.cpp:228] Iteration 27500, loss = 0.206943
I0627 04:35:04.470734  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:35:04.470741  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0123659 (* 1 = 0.0123659 loss)
I0627 04:35:04.470746  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0190625 (* 1 = 0.0190625 loss)
I0627 04:35:04.470749  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000486326 (* 1 = 0.000486326 loss)
I0627 04:35:04.470752  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00300706 (* 1 = 0.00300706 loss)
I0627 04:35:04.470757  6673 sgd_solver.cpp:106] Iteration 27500, lr = 0.0002
I0627 04:36:43.384613  6673 solver.cpp:228] Iteration 27520, loss = 0.32897
I0627 04:36:43.384639  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0627 04:36:43.384645  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.192417 (* 1 = 0.192417 loss)
I0627 04:36:43.384649  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.323856 (* 1 = 0.323856 loss)
I0627 04:36:43.384654  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0573476 (* 1 = 0.0573476 loss)
I0627 04:36:43.384657  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.160364 (* 1 = 0.160364 loss)
I0627 04:36:43.384662  6673 sgd_solver.cpp:106] Iteration 27520, lr = 0.0002
I0627 04:38:22.336088  6673 solver.cpp:228] Iteration 27540, loss = 0.177432
I0627 04:38:22.336113  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:38:22.336122  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.109361 (* 1 = 0.109361 loss)
I0627 04:38:22.336125  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0895262 (* 1 = 0.0895262 loss)
I0627 04:38:22.336129  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000494274 (* 1 = 0.000494274 loss)
I0627 04:38:22.336133  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322713 (* 1 = 0.0322713 loss)
I0627 04:38:22.336138  6673 sgd_solver.cpp:106] Iteration 27540, lr = 0.0002
I0627 04:40:01.236490  6673 solver.cpp:228] Iteration 27560, loss = 0.155738
I0627 04:40:01.236521  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:40:01.236529  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156034 (* 1 = 0.0156034 loss)
I0627 04:40:01.236533  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0253406 (* 1 = 0.0253406 loss)
I0627 04:40:01.236537  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000932007 (* 1 = 0.000932007 loss)
I0627 04:40:01.236541  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00575062 (* 1 = 0.00575062 loss)
I0627 04:40:01.236547  6673 sgd_solver.cpp:106] Iteration 27560, lr = 0.0002
I0627 04:41:40.097448  6673 solver.cpp:228] Iteration 27580, loss = 0.117372
I0627 04:41:40.097473  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 04:41:40.097482  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.102553 (* 1 = 0.102553 loss)
I0627 04:41:40.097487  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.139922 (* 1 = 0.139922 loss)
I0627 04:41:40.097493  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.054231 (* 1 = 0.054231 loss)
I0627 04:41:40.097498  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171681 (* 1 = 0.0171681 loss)
I0627 04:41:40.097504  6673 sgd_solver.cpp:106] Iteration 27580, lr = 0.0002
speed: 4.920s / iter
I0627 04:43:19.024639  6673 solver.cpp:228] Iteration 27600, loss = 0.0964752
I0627 04:43:19.024665  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 04:43:19.024673  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0143884 (* 1 = 0.0143884 loss)
I0627 04:43:19.024677  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0207684 (* 1 = 0.0207684 loss)
I0627 04:43:19.024682  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.18855e-05 (* 1 = 3.18855e-05 loss)
I0627 04:43:19.024685  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00327274 (* 1 = 0.00327274 loss)
I0627 04:43:19.024690  6673 sgd_solver.cpp:106] Iteration 27600, lr = 0.0002
I0627 04:44:58.114220  6673 solver.cpp:228] Iteration 27620, loss = 0.0952925
I0627 04:44:58.114246  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 04:44:58.114254  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132 (* 1 = 0.0132 loss)
I0627 04:44:58.114261  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0340416 (* 1 = 0.0340416 loss)
I0627 04:44:58.114267  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000285754 (* 1 = 0.000285754 loss)
I0627 04:44:58.114271  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0059481 (* 1 = 0.0059481 loss)
I0627 04:44:58.114277  6673 sgd_solver.cpp:106] Iteration 27620, lr = 0.0002
I0627 04:46:37.038132  6673 solver.cpp:228] Iteration 27640, loss = 0.0750049
I0627 04:46:37.038158  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:46:37.038167  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0104528 (* 1 = 0.0104528 loss)
I0627 04:46:37.038173  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00387026 (* 1 = 0.00387026 loss)
I0627 04:46:37.038178  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 1.56966e-05 (* 1 = 1.56966e-05 loss)
I0627 04:46:37.038184  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00329355 (* 1 = 0.00329355 loss)
I0627 04:46:37.038189  6673 sgd_solver.cpp:106] Iteration 27640, lr = 0.0002
I0627 04:48:15.976809  6673 solver.cpp:228] Iteration 27660, loss = 0.10892
I0627 04:48:15.976832  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:48:15.976840  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256535 (* 1 = 0.0256535 loss)
I0627 04:48:15.976845  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.035169 (* 1 = 0.035169 loss)
I0627 04:48:15.976848  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0010679 (* 1 = 0.0010679 loss)
I0627 04:48:15.976852  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00584068 (* 1 = 0.00584068 loss)
I0627 04:48:15.976857  6673 sgd_solver.cpp:106] Iteration 27660, lr = 0.0002
I0627 04:49:55.140969  6673 solver.cpp:228] Iteration 27680, loss = 0.118768
I0627 04:49:55.140993  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 04:49:55.141000  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308189 (* 1 = 0.0308189 loss)
I0627 04:49:55.141005  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.112513 (* 1 = 0.112513 loss)
I0627 04:49:55.141007  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000131576 (* 1 = 0.000131576 loss)
I0627 04:49:55.141011  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00531311 (* 1 = 0.00531311 loss)
I0627 04:49:55.141016  6673 sgd_solver.cpp:106] Iteration 27680, lr = 0.0002
I0627 04:51:34.396744  6673 solver.cpp:228] Iteration 27700, loss = 0.206253
I0627 04:51:34.396770  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 04:51:34.396777  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120252 (* 1 = 0.0120252 loss)
I0627 04:51:34.396781  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0508711 (* 1 = 0.0508711 loss)
I0627 04:51:34.396785  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239631 (* 1 = 0.00239631 loss)
I0627 04:51:34.396790  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0532961 (* 1 = 0.0532961 loss)
I0627 04:51:34.396795  6673 sgd_solver.cpp:106] Iteration 27700, lr = 0.0002
I0627 04:53:14.096177  6673 solver.cpp:228] Iteration 27720, loss = 0.0528498
I0627 04:53:14.096206  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:53:14.096215  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0223332 (* 1 = 0.0223332 loss)
I0627 04:53:14.096220  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0172505 (* 1 = 0.0172505 loss)
I0627 04:53:14.096225  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.88147e-05 (* 1 = 5.88147e-05 loss)
I0627 04:53:14.096230  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00229871 (* 1 = 0.00229871 loss)
I0627 04:53:14.096235  6673 sgd_solver.cpp:106] Iteration 27720, lr = 0.0002
I0627 04:54:53.907467  6673 solver.cpp:228] Iteration 27740, loss = 0.201828
I0627 04:54:53.907500  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0627 04:54:53.907510  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.14655 (* 1 = 0.14655 loss)
I0627 04:54:53.907516  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.384795 (* 1 = 0.384795 loss)
I0627 04:54:53.907523  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107129 (* 1 = 0.0107129 loss)
I0627 04:54:53.907529  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0704805 (* 1 = 0.0704805 loss)
I0627 04:54:53.907536  6673 sgd_solver.cpp:106] Iteration 27740, lr = 0.0002
I0627 04:56:33.808794  6673 solver.cpp:228] Iteration 27760, loss = 0.0916719
I0627 04:56:33.808818  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 04:56:33.808825  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155266 (* 1 = 0.0155266 loss)
I0627 04:56:33.808828  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0214276 (* 1 = 0.0214276 loss)
I0627 04:56:33.808831  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000858127 (* 1 = 0.000858127 loss)
I0627 04:56:33.808835  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174305 (* 1 = 0.0174305 loss)
I0627 04:56:33.808840  6673 sgd_solver.cpp:106] Iteration 27760, lr = 0.0002
I0627 04:58:13.495664  6673 solver.cpp:228] Iteration 27780, loss = 0.264869
I0627 04:58:13.495692  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 04:58:13.495702  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0462992 (* 1 = 0.0462992 loss)
I0627 04:58:13.495705  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0955829 (* 1 = 0.0955829 loss)
I0627 04:58:13.495709  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231354 (* 1 = 0.00231354 loss)
I0627 04:58:13.495713  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115874 (* 1 = 0.0115874 loss)
I0627 04:58:13.495718  6673 sgd_solver.cpp:106] Iteration 27780, lr = 0.0002
speed: 4.921s / iter
I0627 04:59:53.083184  6673 solver.cpp:228] Iteration 27800, loss = 0.103403
I0627 04:59:53.083206  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 04:59:53.083214  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0306751 (* 1 = 0.0306751 loss)
I0627 04:59:53.083217  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0184984 (* 1 = 0.0184984 loss)
I0627 04:59:53.083220  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00084652 (* 1 = 0.00084652 loss)
I0627 04:59:53.083225  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00594388 (* 1 = 0.00594388 loss)
I0627 04:59:53.083228  6673 sgd_solver.cpp:106] Iteration 27800, lr = 0.0002
I0627 05:01:32.730738  6673 solver.cpp:228] Iteration 27820, loss = 0.0434794
I0627 05:01:32.730763  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:01:32.730772  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00884035 (* 1 = 0.00884035 loss)
I0627 05:01:32.730777  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0148844 (* 1 = 0.0148844 loss)
I0627 05:01:32.730780  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265209 (* 1 = 0.00265209 loss)
I0627 05:01:32.730784  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00178479 (* 1 = 0.00178479 loss)
I0627 05:01:32.730788  6673 sgd_solver.cpp:106] Iteration 27820, lr = 0.0002
I0627 05:03:12.383756  6673 solver.cpp:228] Iteration 27840, loss = 0.115725
I0627 05:03:12.383781  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 05:03:12.383788  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0870629 (* 1 = 0.0870629 loss)
I0627 05:03:12.383792  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.172076 (* 1 = 0.172076 loss)
I0627 05:03:12.383796  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00152559 (* 1 = 0.00152559 loss)
I0627 05:03:12.383800  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024612 (* 1 = 0.024612 loss)
I0627 05:03:12.383805  6673 sgd_solver.cpp:106] Iteration 27840, lr = 0.0002
I0627 05:04:51.902107  6673 solver.cpp:228] Iteration 27860, loss = 0.16024
I0627 05:04:51.902135  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:04:51.902144  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0718337 (* 1 = 0.0718337 loss)
I0627 05:04:51.902149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0924338 (* 1 = 0.0924338 loss)
I0627 05:04:51.902154  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320485 (* 1 = 0.00320485 loss)
I0627 05:04:51.902158  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374501 (* 1 = 0.0374501 loss)
I0627 05:04:51.902164  6673 sgd_solver.cpp:106] Iteration 27860, lr = 0.0002
I0627 05:06:31.368706  6673 solver.cpp:228] Iteration 27880, loss = 0.125924
I0627 05:06:31.368736  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 05:06:31.368746  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0523849 (* 1 = 0.0523849 loss)
I0627 05:06:31.368751  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.207284 (* 1 = 0.207284 loss)
I0627 05:06:31.368755  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010089 (* 1 = 0.010089 loss)
I0627 05:06:31.368759  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305466 (* 1 = 0.0305466 loss)
I0627 05:06:31.368765  6673 sgd_solver.cpp:106] Iteration 27880, lr = 0.0002
I0627 05:08:10.786666  6673 solver.cpp:228] Iteration 27900, loss = 0.132981
I0627 05:08:10.786691  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 05:08:10.786698  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472468 (* 1 = 0.0472468 loss)
I0627 05:08:10.786702  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0679442 (* 1 = 0.0679442 loss)
I0627 05:08:10.786707  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00590064 (* 1 = 0.00590064 loss)
I0627 05:08:10.786711  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132194 (* 1 = 0.0132194 loss)
I0627 05:08:10.786715  6673 sgd_solver.cpp:106] Iteration 27900, lr = 0.0002
I0627 05:09:49.791012  6673 solver.cpp:228] Iteration 27920, loss = 0.104638
I0627 05:09:49.791043  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:09:49.791051  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.048847 (* 1 = 0.048847 loss)
I0627 05:09:49.791057  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0684959 (* 1 = 0.0684959 loss)
I0627 05:09:49.791062  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000768646 (* 1 = 0.000768646 loss)
I0627 05:09:49.791067  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232521 (* 1 = 0.0232521 loss)
I0627 05:09:49.791074  6673 sgd_solver.cpp:106] Iteration 27920, lr = 0.0002
I0627 05:11:28.967898  6673 solver.cpp:228] Iteration 27940, loss = 0.0882663
I0627 05:11:28.967923  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:11:28.967931  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0198768 (* 1 = 0.0198768 loss)
I0627 05:11:28.967936  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0260446 (* 1 = 0.0260446 loss)
I0627 05:11:28.967939  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713445 (* 1 = 0.00713445 loss)
I0627 05:11:28.967943  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147059 (* 1 = 0.0147059 loss)
I0627 05:11:28.967948  6673 sgd_solver.cpp:106] Iteration 27940, lr = 0.0002
I0627 05:13:07.926024  6673 solver.cpp:228] Iteration 27960, loss = 0.156463
I0627 05:13:07.926053  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:13:07.926061  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254071 (* 1 = 0.0254071 loss)
I0627 05:13:07.926066  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0306072 (* 1 = 0.0306072 loss)
I0627 05:13:07.926070  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0069466 (* 1 = 0.0069466 loss)
I0627 05:13:07.926075  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106525 (* 1 = 0.0106525 loss)
I0627 05:13:07.926080  6673 sgd_solver.cpp:106] Iteration 27960, lr = 0.0002
I0627 05:14:46.727459  6673 solver.cpp:228] Iteration 27980, loss = 0.173989
I0627 05:14:46.727483  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:14:46.727489  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00897645 (* 1 = 0.00897645 loss)
I0627 05:14:46.727494  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0298155 (* 1 = 0.0298155 loss)
I0627 05:14:46.727500  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000677487 (* 1 = 0.000677487 loss)
I0627 05:14:46.727505  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00157286 (* 1 = 0.00157286 loss)
I0627 05:14:46.727510  6673 sgd_solver.cpp:106] Iteration 27980, lr = 0.0002
speed: 4.921s / iter
I0627 05:16:25.644814  6673 solver.cpp:228] Iteration 28000, loss = 0.11439
I0627 05:16:25.644840  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:16:25.644847  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.040641 (* 1 = 0.040641 loss)
I0627 05:16:25.644851  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0841906 (* 1 = 0.0841906 loss)
I0627 05:16:25.644855  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000159582 (* 1 = 0.000159582 loss)
I0627 05:16:25.644860  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00907943 (* 1 = 0.00907943 loss)
I0627 05:16:25.644865  6673 sgd_solver.cpp:106] Iteration 28000, lr = 0.0002
I0627 05:18:04.290249  6673 solver.cpp:228] Iteration 28020, loss = 0.128777
I0627 05:18:04.290278  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 05:18:04.290289  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.072808 (* 1 = 0.072808 loss)
I0627 05:18:04.290294  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.163862 (* 1 = 0.163862 loss)
I0627 05:18:04.290299  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260751 (* 1 = 0.00260751 loss)
I0627 05:18:04.290305  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234294 (* 1 = 0.0234294 loss)
I0627 05:18:04.290311  6673 sgd_solver.cpp:106] Iteration 28020, lr = 0.0002
I0627 05:19:42.995550  6673 solver.cpp:228] Iteration 28040, loss = 0.229555
I0627 05:19:42.995577  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 05:19:42.995587  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195574 (* 1 = 0.0195574 loss)
I0627 05:19:42.995594  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0504056 (* 1 = 0.0504056 loss)
I0627 05:19:42.995599  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300606 (* 1 = 0.00300606 loss)
I0627 05:19:42.995606  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00197981 (* 1 = 0.00197981 loss)
I0627 05:19:42.995612  6673 sgd_solver.cpp:106] Iteration 28040, lr = 0.0002
I0627 05:21:21.943076  6673 solver.cpp:228] Iteration 28060, loss = 0.18246
I0627 05:21:21.943100  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:21:21.943107  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140648 (* 1 = 0.0140648 loss)
I0627 05:21:21.943111  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00317525 (* 1 = 0.00317525 loss)
I0627 05:21:21.943114  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000349979 (* 1 = 0.000349979 loss)
I0627 05:21:21.943119  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00625744 (* 1 = 0.00625744 loss)
I0627 05:21:21.943122  6673 sgd_solver.cpp:106] Iteration 28060, lr = 0.0002
I0627 05:23:00.778831  6673 solver.cpp:228] Iteration 28080, loss = 0.100049
I0627 05:23:00.778862  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:23:00.778873  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107944 (* 1 = 0.0107944 loss)
I0627 05:23:00.778879  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0107411 (* 1 = 0.0107411 loss)
I0627 05:23:00.778885  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00053012 (* 1 = 0.00053012 loss)
I0627 05:23:00.778892  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00830702 (* 1 = 0.00830702 loss)
I0627 05:23:00.778898  6673 sgd_solver.cpp:106] Iteration 28080, lr = 0.0002
I0627 05:24:39.538384  6673 solver.cpp:228] Iteration 28100, loss = 0.118727
I0627 05:24:39.538410  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:24:39.538420  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0612114 (* 1 = 0.0612114 loss)
I0627 05:24:39.538427  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0607673 (* 1 = 0.0607673 loss)
I0627 05:24:39.538432  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164889 (* 1 = 0.0164889 loss)
I0627 05:24:39.538439  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0392182 (* 1 = 0.0392182 loss)
I0627 05:24:39.538446  6673 sgd_solver.cpp:106] Iteration 28100, lr = 0.0002
I0627 05:26:18.483907  6673 solver.cpp:228] Iteration 28120, loss = 0.140789
I0627 05:26:18.483938  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 05:26:18.483947  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0575039 (* 1 = 0.0575039 loss)
I0627 05:26:18.483952  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.120895 (* 1 = 0.120895 loss)
I0627 05:26:18.483958  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000170728 (* 1 = 0.000170728 loss)
I0627 05:26:18.483961  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106688 (* 1 = 0.0106688 loss)
I0627 05:26:18.483968  6673 sgd_solver.cpp:106] Iteration 28120, lr = 0.0002
I0627 05:27:57.642932  6673 solver.cpp:228] Iteration 28140, loss = 0.167585
I0627 05:27:57.642957  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:27:57.642966  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383755 (* 1 = 0.0383755 loss)
I0627 05:27:57.642971  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0187298 (* 1 = 0.0187298 loss)
I0627 05:27:57.642977  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229747 (* 1 = 0.00229747 loss)
I0627 05:27:57.642983  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00517468 (* 1 = 0.00517468 loss)
I0627 05:27:57.642989  6673 sgd_solver.cpp:106] Iteration 28140, lr = 0.0002
I0627 05:29:36.651590  6673 solver.cpp:228] Iteration 28160, loss = 0.178586
I0627 05:29:36.651618  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:29:36.651628  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0414357 (* 1 = 0.0414357 loss)
I0627 05:29:36.651634  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0816699 (* 1 = 0.0816699 loss)
I0627 05:29:36.651640  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160556 (* 1 = 0.00160556 loss)
I0627 05:29:36.651646  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125405 (* 1 = 0.0125405 loss)
I0627 05:29:36.651654  6673 sgd_solver.cpp:106] Iteration 28160, lr = 0.0002
I0627 05:31:15.572137  6673 solver.cpp:228] Iteration 28180, loss = 0.0843447
I0627 05:31:15.572160  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:31:15.572167  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175491 (* 1 = 0.0175491 loss)
I0627 05:31:15.572171  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0275864 (* 1 = 0.0275864 loss)
I0627 05:31:15.572175  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158344 (* 1 = 0.00158344 loss)
I0627 05:31:15.572178  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00448953 (* 1 = 0.00448953 loss)
I0627 05:31:15.572182  6673 sgd_solver.cpp:106] Iteration 28180, lr = 0.0002
speed: 4.921s / iter
I0627 05:32:54.593019  6673 solver.cpp:228] Iteration 28200, loss = 0.0507337
I0627 05:32:54.593049  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:32:54.593058  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176359 (* 1 = 0.0176359 loss)
I0627 05:32:54.593065  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0114482 (* 1 = 0.0114482 loss)
I0627 05:32:54.593072  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000301538 (* 1 = 0.000301538 loss)
I0627 05:32:54.593080  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00513213 (* 1 = 0.00513213 loss)
I0627 05:32:54.593088  6673 sgd_solver.cpp:106] Iteration 28200, lr = 0.0002
I0627 05:34:33.930563  6673 solver.cpp:228] Iteration 28220, loss = 0.174158
I0627 05:34:33.930590  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 05:34:33.930598  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.051535 (* 1 = 0.051535 loss)
I0627 05:34:33.930603  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.14655 (* 1 = 0.14655 loss)
I0627 05:34:33.930608  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026664 (* 1 = 0.0026664 loss)
I0627 05:34:33.930613  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142005 (* 1 = 0.0142005 loss)
I0627 05:34:33.930619  6673 sgd_solver.cpp:106] Iteration 28220, lr = 0.0002
I0627 05:36:13.099176  6673 solver.cpp:228] Iteration 28240, loss = 0.109294
I0627 05:36:13.099200  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 05:36:13.099206  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162699 (* 1 = 0.0162699 loss)
I0627 05:36:13.099210  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.03982 (* 1 = 0.03982 loss)
I0627 05:36:13.099213  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000678872 (* 1 = 0.000678872 loss)
I0627 05:36:13.099217  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00491029 (* 1 = 0.00491029 loss)
I0627 05:36:13.099222  6673 sgd_solver.cpp:106] Iteration 28240, lr = 0.0002
I0627 05:37:52.150068  6673 solver.cpp:228] Iteration 28260, loss = 0.104999
I0627 05:37:52.150099  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:37:52.150110  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374517 (* 1 = 0.0374517 loss)
I0627 05:37:52.150117  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0708025 (* 1 = 0.0708025 loss)
I0627 05:37:52.150125  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000261861 (* 1 = 0.000261861 loss)
I0627 05:37:52.150130  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137654 (* 1 = 0.0137654 loss)
I0627 05:37:52.150140  6673 sgd_solver.cpp:106] Iteration 28260, lr = 0.0002
I0627 05:39:31.939086  6673 solver.cpp:228] Iteration 28280, loss = 0.151647
I0627 05:39:31.939111  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:39:31.939119  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.012136 (* 1 = 0.012136 loss)
I0627 05:39:31.939123  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0279893 (* 1 = 0.0279893 loss)
I0627 05:39:31.939127  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.36127e-05 (* 1 = 4.36127e-05 loss)
I0627 05:39:31.939131  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00114264 (* 1 = 0.00114264 loss)
I0627 05:39:31.939137  6673 sgd_solver.cpp:106] Iteration 28280, lr = 0.0002
I0627 05:41:11.969007  6673 solver.cpp:228] Iteration 28300, loss = 0.0898887
I0627 05:41:11.969036  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 05:41:11.969044  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00836954 (* 1 = 0.00836954 loss)
I0627 05:41:11.969048  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0548454 (* 1 = 0.0548454 loss)
I0627 05:41:11.969051  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00100371 (* 1 = 0.00100371 loss)
I0627 05:41:11.969055  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178225 (* 1 = 0.0178225 loss)
I0627 05:41:11.969061  6673 sgd_solver.cpp:106] Iteration 28300, lr = 0.0002
I0627 05:42:52.051590  6673 solver.cpp:228] Iteration 28320, loss = 0.0761521
I0627 05:42:52.051616  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 05:42:52.051625  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325616 (* 1 = 0.0325616 loss)
I0627 05:42:52.051630  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0731956 (* 1 = 0.0731956 loss)
I0627 05:42:52.051633  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000760399 (* 1 = 0.000760399 loss)
I0627 05:42:52.051636  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202838 (* 1 = 0.0202838 loss)
I0627 05:42:52.051641  6673 sgd_solver.cpp:106] Iteration 28320, lr = 0.0002
I0627 05:44:32.043586  6673 solver.cpp:228] Iteration 28340, loss = 0.16037
I0627 05:44:32.043611  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 05:44:32.043619  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201788 (* 1 = 0.0201788 loss)
I0627 05:44:32.043625  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0249129 (* 1 = 0.0249129 loss)
I0627 05:44:32.043630  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00115959 (* 1 = 0.00115959 loss)
I0627 05:44:32.043637  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00526115 (* 1 = 0.00526115 loss)
I0627 05:44:32.043642  6673 sgd_solver.cpp:106] Iteration 28340, lr = 0.0002
I0627 05:46:11.844189  6673 solver.cpp:228] Iteration 28360, loss = 0.126501
I0627 05:46:11.844236  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:46:11.844249  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0166955 (* 1 = 0.0166955 loss)
I0627 05:46:11.844259  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0129429 (* 1 = 0.0129429 loss)
I0627 05:46:11.844266  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.84651e-05 (* 1 = 5.84651e-05 loss)
I0627 05:46:11.844274  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00617768 (* 1 = 0.00617768 loss)
I0627 05:46:11.844285  6673 sgd_solver.cpp:106] Iteration 28360, lr = 0.0002
I0627 05:47:51.609858  6673 solver.cpp:228] Iteration 28380, loss = 0.108295
I0627 05:47:51.609890  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:47:51.609900  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0153311 (* 1 = 0.0153311 loss)
I0627 05:47:51.609905  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00961502 (* 1 = 0.00961502 loss)
I0627 05:47:51.609910  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000105827 (* 1 = 0.000105827 loss)
I0627 05:47:51.609916  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00286977 (* 1 = 0.00286977 loss)
I0627 05:47:51.609922  6673 sgd_solver.cpp:106] Iteration 28380, lr = 0.0002
speed: 4.922s / iter
I0627 05:49:31.233904  6673 solver.cpp:228] Iteration 28400, loss = 0.116834
I0627 05:49:31.233932  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 05:49:31.233945  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0292419 (* 1 = 0.0292419 loss)
I0627 05:49:31.233952  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0879636 (* 1 = 0.0879636 loss)
I0627 05:49:31.233960  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000412414 (* 1 = 0.000412414 loss)
I0627 05:49:31.233969  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139709 (* 1 = 0.0139709 loss)
I0627 05:49:31.233978  6673 sgd_solver.cpp:106] Iteration 28400, lr = 0.0002
I0627 05:51:10.826383  6673 solver.cpp:228] Iteration 28420, loss = 0.116269
I0627 05:51:10.826412  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:51:10.826422  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203688 (* 1 = 0.0203688 loss)
I0627 05:51:10.826428  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0183235 (* 1 = 0.0183235 loss)
I0627 05:51:10.826433  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264749 (* 1 = 0.00264749 loss)
I0627 05:51:10.826438  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196521 (* 1 = 0.0196521 loss)
I0627 05:51:10.826444  6673 sgd_solver.cpp:106] Iteration 28420, lr = 0.0002
I0627 05:52:50.577720  6673 solver.cpp:228] Iteration 28440, loss = 0.17896
I0627 05:52:50.577747  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:52:50.577754  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0136194 (* 1 = 0.0136194 loss)
I0627 05:52:50.577759  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0261887 (* 1 = 0.0261887 loss)
I0627 05:52:50.577764  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00907673 (* 1 = 0.00907673 loss)
I0627 05:52:50.577767  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00493548 (* 1 = 0.00493548 loss)
I0627 05:52:50.577772  6673 sgd_solver.cpp:106] Iteration 28440, lr = 0.0002
I0627 05:54:30.060468  6673 solver.cpp:228] Iteration 28460, loss = 0.13567
I0627 05:54:30.060503  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 05:54:30.060511  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339032 (* 1 = 0.0339032 loss)
I0627 05:54:30.060516  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0311193 (* 1 = 0.0311193 loss)
I0627 05:54:30.060521  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000163495 (* 1 = 0.000163495 loss)
I0627 05:54:30.060525  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00336778 (* 1 = 0.00336778 loss)
I0627 05:54:30.060531  6673 sgd_solver.cpp:106] Iteration 28460, lr = 0.0002
I0627 05:56:09.509994  6673 solver.cpp:228] Iteration 28480, loss = 0.142232
I0627 05:56:09.510018  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:56:09.510026  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000937635 (* 1 = 0.000937635 loss)
I0627 05:56:09.510031  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0178412 (* 1 = 0.0178412 loss)
I0627 05:56:09.510035  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00113901 (* 1 = 0.00113901 loss)
I0627 05:56:09.510038  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0232443 (* 1 = 0.0232443 loss)
I0627 05:56:09.510043  6673 sgd_solver.cpp:106] Iteration 28480, lr = 0.0002
I0627 05:57:49.064435  6673 solver.cpp:228] Iteration 28500, loss = 0.0978939
I0627 05:57:49.064460  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 05:57:49.064465  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00939147 (* 1 = 0.00939147 loss)
I0627 05:57:49.064471  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0238353 (* 1 = 0.0238353 loss)
I0627 05:57:49.064473  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.84337e-05 (* 1 = 6.84337e-05 loss)
I0627 05:57:49.064477  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00523059 (* 1 = 0.00523059 loss)
I0627 05:57:49.064481  6673 sgd_solver.cpp:106] Iteration 28500, lr = 0.0002
I0627 05:59:28.145787  6673 solver.cpp:228] Iteration 28520, loss = 0.0830737
I0627 05:59:28.145812  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 05:59:28.145818  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402188 (* 1 = 0.0402188 loss)
I0627 05:59:28.145823  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0516569 (* 1 = 0.0516569 loss)
I0627 05:59:28.145828  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000263227 (* 1 = 0.000263227 loss)
I0627 05:59:28.145833  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00301569 (* 1 = 0.00301569 loss)
I0627 05:59:28.145838  6673 sgd_solver.cpp:106] Iteration 28520, lr = 0.0002
I0627 06:01:06.672471  6673 solver.cpp:228] Iteration 28540, loss = 0.0802033
I0627 06:01:06.672497  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:01:06.672504  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.031899 (* 1 = 0.031899 loss)
I0627 06:01:06.672508  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0464317 (* 1 = 0.0464317 loss)
I0627 06:01:06.672513  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00354335 (* 1 = 0.00354335 loss)
I0627 06:01:06.672516  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348227 (* 1 = 0.0348227 loss)
I0627 06:01:06.672521  6673 sgd_solver.cpp:106] Iteration 28540, lr = 0.0002
I0627 06:02:44.956202  6673 solver.cpp:228] Iteration 28560, loss = 0.133911
I0627 06:02:44.956230  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 06:02:44.956238  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0787469 (* 1 = 0.0787469 loss)
I0627 06:02:44.956243  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.090582 (* 1 = 0.090582 loss)
I0627 06:02:44.956245  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000466767 (* 1 = 0.000466767 loss)
I0627 06:02:44.956249  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295384 (* 1 = 0.0295384 loss)
I0627 06:02:44.956255  6673 sgd_solver.cpp:106] Iteration 28560, lr = 0.0002
I0627 06:04:23.050577  6673 solver.cpp:228] Iteration 28580, loss = 0.114462
I0627 06:04:23.050601  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:04:23.050608  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.026646 (* 1 = 0.026646 loss)
I0627 06:04:23.050613  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0817347 (* 1 = 0.0817347 loss)
I0627 06:04:23.050616  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00094084 (* 1 = 0.00094084 loss)
I0627 06:04:23.050621  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00749576 (* 1 = 0.00749576 loss)
I0627 06:04:23.050624  6673 sgd_solver.cpp:106] Iteration 28580, lr = 0.0002
speed: 4.922s / iter
I0627 06:06:01.034590  6673 solver.cpp:228] Iteration 28600, loss = 0.122057
I0627 06:06:01.034613  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:06:01.034621  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.016553 (* 1 = 0.016553 loss)
I0627 06:06:01.034626  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00666665 (* 1 = 0.00666665 loss)
I0627 06:06:01.034628  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00060869 (* 1 = 0.00060869 loss)
I0627 06:06:01.034632  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110453 (* 1 = 0.0110453 loss)
I0627 06:06:01.034637  6673 sgd_solver.cpp:106] Iteration 28600, lr = 0.0002
I0627 06:07:38.950829  6673 solver.cpp:228] Iteration 28620, loss = 0.18464
I0627 06:07:38.950855  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:07:38.950868  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231456 (* 1 = 0.0231456 loss)
I0627 06:07:38.950875  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0389309 (* 1 = 0.0389309 loss)
I0627 06:07:38.950881  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00826655 (* 1 = 0.00826655 loss)
I0627 06:07:38.950886  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00652062 (* 1 = 0.00652062 loss)
I0627 06:07:38.950891  6673 sgd_solver.cpp:106] Iteration 28620, lr = 0.0002
I0627 06:09:16.891623  6673 solver.cpp:228] Iteration 28640, loss = 0.180074
I0627 06:09:16.891647  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:09:16.891655  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.000758663 (* 1 = 0.000758663 loss)
I0627 06:09:16.891659  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0151833 (* 1 = 0.0151833 loss)
I0627 06:09:16.891664  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265851 (* 1 = 0.0265851 loss)
I0627 06:09:16.891667  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00698872 (* 1 = 0.00698872 loss)
I0627 06:09:16.891672  6673 sgd_solver.cpp:106] Iteration 28640, lr = 0.0002
I0627 06:10:54.858197  6673 solver.cpp:228] Iteration 28660, loss = 0.157748
I0627 06:10:54.858223  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:10:54.858230  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0411178 (* 1 = 0.0411178 loss)
I0627 06:10:54.858235  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0165171 (* 1 = 0.0165171 loss)
I0627 06:10:54.858239  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000175593 (* 1 = 0.000175593 loss)
I0627 06:10:54.858243  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103553 (* 1 = 0.0103553 loss)
I0627 06:10:54.858247  6673 sgd_solver.cpp:106] Iteration 28660, lr = 0.0002
I0627 06:12:32.800441  6673 solver.cpp:228] Iteration 28680, loss = 0.0944282
I0627 06:12:32.800464  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 06:12:32.800474  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0750879 (* 1 = 0.0750879 loss)
I0627 06:12:32.800479  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0900024 (* 1 = 0.0900024 loss)
I0627 06:12:32.800485  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00312032 (* 1 = 0.00312032 loss)
I0627 06:12:32.800490  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224163 (* 1 = 0.0224163 loss)
I0627 06:12:32.800496  6673 sgd_solver.cpp:106] Iteration 28680, lr = 0.0002
I0627 06:14:10.756332  6673 solver.cpp:228] Iteration 28700, loss = 0.177984
I0627 06:14:10.756357  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0627 06:14:10.756366  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.128294 (* 1 = 0.128294 loss)
I0627 06:14:10.756372  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.192286 (* 1 = 0.192286 loss)
I0627 06:14:10.756377  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385451 (* 1 = 0.00385451 loss)
I0627 06:14:10.756383  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265184 (* 1 = 0.0265184 loss)
I0627 06:14:10.756389  6673 sgd_solver.cpp:106] Iteration 28700, lr = 0.0002
I0627 06:15:48.707713  6673 solver.cpp:228] Iteration 28720, loss = 0.0706944
I0627 06:15:48.707739  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:15:48.707747  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232925 (* 1 = 0.0232925 loss)
I0627 06:15:48.707754  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00975765 (* 1 = 0.00975765 loss)
I0627 06:15:48.707761  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115895 (* 1 = 0.0115895 loss)
I0627 06:15:48.707765  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0047992 (* 1 = 0.0047992 loss)
I0627 06:15:48.707774  6673 sgd_solver.cpp:106] Iteration 28720, lr = 0.0002
I0627 06:17:26.669651  6673 solver.cpp:228] Iteration 28740, loss = 0.152883
I0627 06:17:26.669674  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:17:26.669682  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481168 (* 1 = 0.0481168 loss)
I0627 06:17:26.669687  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0607321 (* 1 = 0.0607321 loss)
I0627 06:17:26.669690  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183255 (* 1 = 0.00183255 loss)
I0627 06:17:26.669694  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239696 (* 1 = 0.0239696 loss)
I0627 06:17:26.669698  6673 sgd_solver.cpp:106] Iteration 28740, lr = 0.0002
I0627 06:19:04.597265  6673 solver.cpp:228] Iteration 28760, loss = 0.159773
I0627 06:19:04.597291  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:19:04.597301  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0277737 (* 1 = 0.0277737 loss)
I0627 06:19:04.597307  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0301327 (* 1 = 0.0301327 loss)
I0627 06:19:04.597312  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000197687 (* 1 = 0.000197687 loss)
I0627 06:19:04.597318  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00882838 (* 1 = 0.00882838 loss)
I0627 06:19:04.597326  6673 sgd_solver.cpp:106] Iteration 28760, lr = 0.0002
I0627 06:20:42.527667  6673 solver.cpp:228] Iteration 28780, loss = 0.0760568
I0627 06:20:42.527691  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 06:20:42.527698  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224362 (* 1 = 0.0224362 loss)
I0627 06:20:42.527703  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0649872 (* 1 = 0.0649872 loss)
I0627 06:20:42.527706  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00765174 (* 1 = 0.00765174 loss)
I0627 06:20:42.527709  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151383 (* 1 = 0.0151383 loss)
I0627 06:20:42.527714  6673 sgd_solver.cpp:106] Iteration 28780, lr = 0.0002
speed: 4.922s / iter
I0627 06:22:20.482779  6673 solver.cpp:228] Iteration 28800, loss = 0.147413
I0627 06:22:20.482807  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:22:20.482818  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0883661 (* 1 = 0.0883661 loss)
I0627 06:22:20.482825  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0990696 (* 1 = 0.0990696 loss)
I0627 06:22:20.482831  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052727 (* 1 = 0.0052727 loss)
I0627 06:22:20.482836  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223106 (* 1 = 0.0223106 loss)
I0627 06:22:20.482841  6673 sgd_solver.cpp:106] Iteration 28800, lr = 0.0002
I0627 06:23:58.418244  6673 solver.cpp:228] Iteration 28820, loss = 0.132649
I0627 06:23:58.418270  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 06:23:58.418280  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0128311 (* 1 = 0.0128311 loss)
I0627 06:23:58.418287  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0559894 (* 1 = 0.0559894 loss)
I0627 06:23:58.418293  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151401 (* 1 = 0.00151401 loss)
I0627 06:23:58.418299  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121265 (* 1 = 0.0121265 loss)
I0627 06:23:58.418306  6673 sgd_solver.cpp:106] Iteration 28820, lr = 0.0002
I0627 06:25:36.354182  6673 solver.cpp:228] Iteration 28840, loss = 0.0910998
I0627 06:25:36.354208  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:25:36.354218  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.035268 (* 1 = 0.035268 loss)
I0627 06:25:36.354224  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0159023 (* 1 = 0.0159023 loss)
I0627 06:25:36.354230  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376494 (* 1 = 0.00376494 loss)
I0627 06:25:36.354236  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132915 (* 1 = 0.0132915 loss)
I0627 06:25:36.354243  6673 sgd_solver.cpp:106] Iteration 28840, lr = 0.0002
I0627 06:27:14.296771  6673 solver.cpp:228] Iteration 28860, loss = 0.170921
I0627 06:27:14.296795  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 06:27:14.296803  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0604158 (* 1 = 0.0604158 loss)
I0627 06:27:14.296808  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0938937 (* 1 = 0.0938937 loss)
I0627 06:27:14.296811  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159823 (* 1 = 0.0159823 loss)
I0627 06:27:14.296815  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159248 (* 1 = 0.0159248 loss)
I0627 06:27:14.296820  6673 sgd_solver.cpp:106] Iteration 28860, lr = 0.0002
I0627 06:28:52.665313  6673 solver.cpp:228] Iteration 28880, loss = 0.102176
I0627 06:28:52.665336  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:28:52.665343  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151854 (* 1 = 0.0151854 loss)
I0627 06:28:52.665347  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0229079 (* 1 = 0.0229079 loss)
I0627 06:28:52.665350  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.26626e-05 (* 1 = 4.26626e-05 loss)
I0627 06:28:52.665354  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00505419 (* 1 = 0.00505419 loss)
I0627 06:28:52.665359  6673 sgd_solver.cpp:106] Iteration 28880, lr = 0.0002
I0627 06:30:30.780441  6673 solver.cpp:228] Iteration 28900, loss = 0.137786
I0627 06:30:30.780465  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:30:30.780472  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0285459 (* 1 = 0.0285459 loss)
I0627 06:30:30.780477  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.013585 (* 1 = 0.013585 loss)
I0627 06:30:30.780480  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000545579 (* 1 = 0.000545579 loss)
I0627 06:30:30.780483  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00667906 (* 1 = 0.00667906 loss)
I0627 06:30:30.780488  6673 sgd_solver.cpp:106] Iteration 28900, lr = 0.0002
I0627 06:32:08.835165  6673 solver.cpp:228] Iteration 28920, loss = 0.101963
I0627 06:32:08.835191  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:32:08.835198  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142614 (* 1 = 0.0142614 loss)
I0627 06:32:08.835202  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0424378 (* 1 = 0.0424378 loss)
I0627 06:32:08.835206  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0383947 (* 1 = 0.0383947 loss)
I0627 06:32:08.835211  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101485 (* 1 = 0.0101485 loss)
I0627 06:32:08.835214  6673 sgd_solver.cpp:106] Iteration 28920, lr = 0.0002
I0627 06:33:46.887573  6673 solver.cpp:228] Iteration 28940, loss = 0.080849
I0627 06:33:46.887600  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:33:46.887610  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161927 (* 1 = 0.0161927 loss)
I0627 06:33:46.887616  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0326798 (* 1 = 0.0326798 loss)
I0627 06:33:46.887622  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00386462 (* 1 = 0.00386462 loss)
I0627 06:33:46.887629  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00523182 (* 1 = 0.00523182 loss)
I0627 06:33:46.887637  6673 sgd_solver.cpp:106] Iteration 28940, lr = 0.0002
I0627 06:35:24.838975  6673 solver.cpp:228] Iteration 28960, loss = 0.216774
I0627 06:35:24.838999  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:35:24.839005  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0148765 (* 1 = 0.0148765 loss)
I0627 06:35:24.839010  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0375913 (* 1 = 0.0375913 loss)
I0627 06:35:24.839012  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00557637 (* 1 = 0.00557637 loss)
I0627 06:35:24.839016  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00608786 (* 1 = 0.00608786 loss)
I0627 06:35:24.839021  6673 sgd_solver.cpp:106] Iteration 28960, lr = 0.0002
I0627 06:37:02.763025  6673 solver.cpp:228] Iteration 28980, loss = 0.116485
I0627 06:37:02.763051  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:37:02.763057  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284275 (* 1 = 0.0284275 loss)
I0627 06:37:02.763062  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00628608 (* 1 = 0.00628608 loss)
I0627 06:37:02.763067  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000232119 (* 1 = 0.000232119 loss)
I0627 06:37:02.763070  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00286841 (* 1 = 0.00286841 loss)
I0627 06:37:02.763074  6673 sgd_solver.cpp:106] Iteration 28980, lr = 0.0002
speed: 4.922s / iter
I0627 06:38:40.703712  6673 solver.cpp:228] Iteration 29000, loss = 0.156733
I0627 06:38:40.703740  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 06:38:40.703747  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.046224 (* 1 = 0.046224 loss)
I0627 06:38:40.703752  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.183713 (* 1 = 0.183713 loss)
I0627 06:38:40.703755  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103464 (* 1 = 0.0103464 loss)
I0627 06:38:40.703759  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0962104 (* 1 = 0.0962104 loss)
I0627 06:38:40.703764  6673 sgd_solver.cpp:106] Iteration 29000, lr = 0.0002
I0627 06:40:18.644807  6673 solver.cpp:228] Iteration 29020, loss = 0.119714
I0627 06:40:18.644834  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:40:18.644841  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0337415 (* 1 = 0.0337415 loss)
I0627 06:40:18.644845  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0554833 (* 1 = 0.0554833 loss)
I0627 06:40:18.644850  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.10655e-05 (* 1 = 5.10655e-05 loss)
I0627 06:40:18.644853  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169334 (* 1 = 0.0169334 loss)
I0627 06:40:18.644858  6673 sgd_solver.cpp:106] Iteration 29020, lr = 0.0002
I0627 06:41:56.678009  6673 solver.cpp:228] Iteration 29040, loss = 0.263684
I0627 06:41:56.678031  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 06:41:56.678040  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0263918 (* 1 = 0.0263918 loss)
I0627 06:41:56.678043  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.10806 (* 1 = 0.10806 loss)
I0627 06:41:56.678046  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218395 (* 1 = 0.00218395 loss)
I0627 06:41:56.678050  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158533 (* 1 = 0.0158533 loss)
I0627 06:41:56.678055  6673 sgd_solver.cpp:106] Iteration 29040, lr = 0.0002
I0627 06:43:34.644126  6673 solver.cpp:228] Iteration 29060, loss = 0.0734636
I0627 06:43:34.644151  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 06:43:34.644160  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0101787 (* 1 = 0.0101787 loss)
I0627 06:43:34.644165  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00981597 (* 1 = 0.00981597 loss)
I0627 06:43:34.644167  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00175326 (* 1 = 0.00175326 loss)
I0627 06:43:34.644171  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010597 (* 1 = 0.010597 loss)
I0627 06:43:34.644176  6673 sgd_solver.cpp:106] Iteration 29060, lr = 0.0002
I0627 06:45:12.572371  6673 solver.cpp:228] Iteration 29080, loss = 0.214448
I0627 06:45:12.572401  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 06:45:12.572409  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0680754 (* 1 = 0.0680754 loss)
I0627 06:45:12.572414  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100304 (* 1 = 0.100304 loss)
I0627 06:45:12.572419  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00192952 (* 1 = 0.00192952 loss)
I0627 06:45:12.572424  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245813 (* 1 = 0.0245813 loss)
I0627 06:45:12.572429  6673 sgd_solver.cpp:106] Iteration 29080, lr = 0.0002
I0627 06:46:50.481649  6673 solver.cpp:228] Iteration 29100, loss = 0.112205
I0627 06:46:50.481673  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:46:50.481679  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.011678 (* 1 = 0.011678 loss)
I0627 06:46:50.481683  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0465044 (* 1 = 0.0465044 loss)
I0627 06:46:50.481686  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.75284e-05 (* 1 = 4.75284e-05 loss)
I0627 06:46:50.481689  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00274082 (* 1 = 0.00274082 loss)
I0627 06:46:50.481693  6673 sgd_solver.cpp:106] Iteration 29100, lr = 0.0002
I0627 06:48:28.440773  6673 solver.cpp:228] Iteration 29120, loss = 0.0714787
I0627 06:48:28.440795  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:48:28.440802  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108316 (* 1 = 0.0108316 loss)
I0627 06:48:28.440806  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0633584 (* 1 = 0.0633584 loss)
I0627 06:48:28.440809  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.96667e-05 (* 1 = 3.96667e-05 loss)
I0627 06:48:28.440814  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00237951 (* 1 = 0.00237951 loss)
I0627 06:48:28.440817  6673 sgd_solver.cpp:106] Iteration 29120, lr = 0.0002
I0627 06:50:06.349090  6673 solver.cpp:228] Iteration 29140, loss = 0.153463
I0627 06:50:06.349115  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:50:06.349123  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0290175 (* 1 = 0.0290175 loss)
I0627 06:50:06.349128  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0438351 (* 1 = 0.0438351 loss)
I0627 06:50:06.349131  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120726 (* 1 = 0.0120726 loss)
I0627 06:50:06.349134  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171675 (* 1 = 0.0171675 loss)
I0627 06:50:06.349139  6673 sgd_solver.cpp:106] Iteration 29140, lr = 0.0002
I0627 06:51:44.278515  6673 solver.cpp:228] Iteration 29160, loss = 0.153425
I0627 06:51:44.278540  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 06:51:44.278548  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561411 (* 1 = 0.0561411 loss)
I0627 06:51:44.278553  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0967329 (* 1 = 0.0967329 loss)
I0627 06:51:44.278556  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000765148 (* 1 = 0.000765148 loss)
I0627 06:51:44.278560  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103694 (* 1 = 0.0103694 loss)
I0627 06:51:44.278565  6673 sgd_solver.cpp:106] Iteration 29160, lr = 0.0002
I0627 06:53:22.215924  6673 solver.cpp:228] Iteration 29180, loss = 0.0796405
I0627 06:53:22.215950  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 06:53:22.215956  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0259873 (* 1 = 0.0259873 loss)
I0627 06:53:22.215960  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0323005 (* 1 = 0.0323005 loss)
I0627 06:53:22.215963  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015093 (* 1 = 0.0015093 loss)
I0627 06:53:22.215967  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174571 (* 1 = 0.0174571 loss)
I0627 06:53:22.215971  6673 sgd_solver.cpp:106] Iteration 29180, lr = 0.0002
speed: 4.921s / iter
I0627 06:55:00.085120  6673 solver.cpp:228] Iteration 29200, loss = 0.121208
I0627 06:55:00.085147  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:55:00.085157  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0865005 (* 1 = 0.0865005 loss)
I0627 06:55:00.085162  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0326884 (* 1 = 0.0326884 loss)
I0627 06:55:00.085168  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330435 (* 1 = 0.00330435 loss)
I0627 06:55:00.085177  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152079 (* 1 = 0.0152079 loss)
I0627 06:55:00.085186  6673 sgd_solver.cpp:106] Iteration 29200, lr = 0.0002
I0627 06:56:38.031255  6673 solver.cpp:228] Iteration 29220, loss = 0.146559
I0627 06:56:38.031280  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:56:38.031289  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262756 (* 1 = 0.0262756 loss)
I0627 06:56:38.031296  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0255891 (* 1 = 0.0255891 loss)
I0627 06:56:38.031302  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000422926 (* 1 = 0.000422926 loss)
I0627 06:56:38.031308  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0097722 (* 1 = 0.0097722 loss)
I0627 06:56:38.031314  6673 sgd_solver.cpp:106] Iteration 29220, lr = 0.0002
I0627 06:58:15.985771  6673 solver.cpp:228] Iteration 29240, loss = 0.0801523
I0627 06:58:15.985797  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 06:58:15.985806  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00952261 (* 1 = 0.00952261 loss)
I0627 06:58:15.985812  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0120766 (* 1 = 0.0120766 loss)
I0627 06:58:15.985818  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.45218e-05 (* 1 = 3.45218e-05 loss)
I0627 06:58:15.985824  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00230433 (* 1 = 0.00230433 loss)
I0627 06:58:15.985831  6673 sgd_solver.cpp:106] Iteration 29240, lr = 0.0002
I0627 06:59:53.930950  6673 solver.cpp:228] Iteration 29260, loss = 0.111443
I0627 06:59:53.930980  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 06:59:53.930991  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0280287 (* 1 = 0.0280287 loss)
I0627 06:59:53.930997  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0617917 (* 1 = 0.0617917 loss)
I0627 06:59:53.931005  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000665377 (* 1 = 0.000665377 loss)
I0627 06:59:53.931010  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00675519 (* 1 = 0.00675519 loss)
I0627 06:59:53.931016  6673 sgd_solver.cpp:106] Iteration 29260, lr = 0.0002
I0627 07:01:31.850037  6673 solver.cpp:228] Iteration 29280, loss = 0.200199
I0627 07:01:31.850065  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:01:31.850073  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00893992 (* 1 = 0.00893992 loss)
I0627 07:01:31.850077  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0487483 (* 1 = 0.0487483 loss)
I0627 07:01:31.850081  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000269931 (* 1 = 0.000269931 loss)
I0627 07:01:31.850085  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0028783 (* 1 = 0.0028783 loss)
I0627 07:01:31.850090  6673 sgd_solver.cpp:106] Iteration 29280, lr = 0.0002
I0627 07:03:09.776054  6673 solver.cpp:228] Iteration 29300, loss = 0.255046
I0627 07:03:09.776078  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:03:09.776085  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0102394 (* 1 = 0.0102394 loss)
I0627 07:03:09.776090  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00726453 (* 1 = 0.00726453 loss)
I0627 07:03:09.776094  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270775 (* 1 = 0.00270775 loss)
I0627 07:03:09.776098  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00406976 (* 1 = 0.00406976 loss)
I0627 07:03:09.776103  6673 sgd_solver.cpp:106] Iteration 29300, lr = 0.0002
I0627 07:04:47.686059  6673 solver.cpp:228] Iteration 29320, loss = 0.204753
I0627 07:04:47.686086  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 07:04:47.686094  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378231 (* 1 = 0.0378231 loss)
I0627 07:04:47.686098  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.166889 (* 1 = 0.166889 loss)
I0627 07:04:47.686102  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156721 (* 1 = 0.0156721 loss)
I0627 07:04:47.686106  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0554668 (* 1 = 0.0554668 loss)
I0627 07:04:47.686110  6673 sgd_solver.cpp:106] Iteration 29320, lr = 0.0002
I0627 07:06:25.574466  6673 solver.cpp:228] Iteration 29340, loss = 0.136781
I0627 07:06:25.574491  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0627 07:06:25.574498  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.194393 (* 1 = 0.194393 loss)
I0627 07:06:25.574502  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.223296 (* 1 = 0.223296 loss)
I0627 07:06:25.574506  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170783 (* 1 = 0.0170783 loss)
I0627 07:06:25.574510  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0803903 (* 1 = 0.0803903 loss)
I0627 07:06:25.574515  6673 sgd_solver.cpp:106] Iteration 29340, lr = 0.0002
I0627 07:08:03.503643  6673 solver.cpp:228] Iteration 29360, loss = 0.074069
I0627 07:08:03.503667  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:08:03.503674  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0229931 (* 1 = 0.0229931 loss)
I0627 07:08:03.503679  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0424939 (* 1 = 0.0424939 loss)
I0627 07:08:03.503684  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103293 (* 1 = 0.00103293 loss)
I0627 07:08:03.503687  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0082414 (* 1 = 0.0082414 loss)
I0627 07:08:03.503692  6673 sgd_solver.cpp:106] Iteration 29360, lr = 0.0002
I0627 07:09:41.437253  6673 solver.cpp:228] Iteration 29380, loss = 0.108686
I0627 07:09:41.437278  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:09:41.437284  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0275495 (* 1 = 0.0275495 loss)
I0627 07:09:41.437288  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0241119 (* 1 = 0.0241119 loss)
I0627 07:09:41.437292  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361937 (* 1 = 0.00361937 loss)
I0627 07:09:41.437295  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010158 (* 1 = 0.010158 loss)
I0627 07:09:41.437300  6673 sgd_solver.cpp:106] Iteration 29380, lr = 0.0002
speed: 4.921s / iter
I0627 07:11:19.381628  6673 solver.cpp:228] Iteration 29400, loss = 0.106251
I0627 07:11:19.381650  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:11:19.381656  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0141688 (* 1 = 0.0141688 loss)
I0627 07:11:19.381660  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0117503 (* 1 = 0.0117503 loss)
I0627 07:11:19.381664  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.45902e-05 (* 1 = 9.45902e-05 loss)
I0627 07:11:19.381666  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000247918 (* 1 = 0.000247918 loss)
I0627 07:11:19.381671  6673 sgd_solver.cpp:106] Iteration 29400, lr = 0.0002
I0627 07:12:57.306188  6673 solver.cpp:228] Iteration 29420, loss = 0.154928
I0627 07:12:57.306211  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 07:12:57.306218  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0566266 (* 1 = 0.0566266 loss)
I0627 07:12:57.306222  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.120047 (* 1 = 0.120047 loss)
I0627 07:12:57.306226  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183336 (* 1 = 0.0183336 loss)
I0627 07:12:57.306228  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512427 (* 1 = 0.0512427 loss)
I0627 07:12:57.306232  6673 sgd_solver.cpp:106] Iteration 29420, lr = 0.0002
I0627 07:14:35.290721  6673 solver.cpp:228] Iteration 29440, loss = 0.211136
I0627 07:14:35.290745  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:14:35.290756  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187573 (* 1 = 0.0187573 loss)
I0627 07:14:35.290762  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0271855 (* 1 = 0.0271855 loss)
I0627 07:14:35.290768  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00646753 (* 1 = 0.00646753 loss)
I0627 07:14:35.290774  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00123021 (* 1 = 0.00123021 loss)
I0627 07:14:35.290782  6673 sgd_solver.cpp:106] Iteration 29440, lr = 0.0002
I0627 07:16:13.218942  6673 solver.cpp:228] Iteration 29460, loss = 0.163425
I0627 07:16:13.218968  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:16:13.218976  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00801509 (* 1 = 0.00801509 loss)
I0627 07:16:13.218981  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0415031 (* 1 = 0.0415031 loss)
I0627 07:16:13.218984  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000664679 (* 1 = 0.000664679 loss)
I0627 07:16:13.218988  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00209794 (* 1 = 0.00209794 loss)
I0627 07:16:13.218993  6673 sgd_solver.cpp:106] Iteration 29460, lr = 0.0002
I0627 07:17:51.175377  6673 solver.cpp:228] Iteration 29480, loss = 0.119517
I0627 07:17:51.175402  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 07:17:51.175410  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.082634 (* 1 = 0.082634 loss)
I0627 07:17:51.175415  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.134098 (* 1 = 0.134098 loss)
I0627 07:17:51.175418  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000233725 (* 1 = 0.000233725 loss)
I0627 07:17:51.175422  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205677 (* 1 = 0.0205677 loss)
I0627 07:17:51.175427  6673 sgd_solver.cpp:106] Iteration 29480, lr = 0.0002
I0627 07:19:29.109300  6673 solver.cpp:228] Iteration 29500, loss = 0.174645
I0627 07:19:29.109324  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:19:29.109331  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599596 (* 1 = 0.0599596 loss)
I0627 07:19:29.109334  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0547089 (* 1 = 0.0547089 loss)
I0627 07:19:29.109338  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00017506 (* 1 = 0.00017506 loss)
I0627 07:19:29.109342  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00852906 (* 1 = 0.00852906 loss)
I0627 07:19:29.109346  6673 sgd_solver.cpp:106] Iteration 29500, lr = 0.0002
I0627 07:21:07.022341  6673 solver.cpp:228] Iteration 29520, loss = 0.127415
I0627 07:21:07.022366  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:21:07.022372  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00668663 (* 1 = 0.00668663 loss)
I0627 07:21:07.022377  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0311856 (* 1 = 0.0311856 loss)
I0627 07:21:07.022382  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133942 (* 1 = 0.00133942 loss)
I0627 07:21:07.022385  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00515093 (* 1 = 0.00515093 loss)
I0627 07:21:07.022390  6673 sgd_solver.cpp:106] Iteration 29520, lr = 0.0002
I0627 07:22:44.946249  6673 solver.cpp:228] Iteration 29540, loss = 0.0948086
I0627 07:22:44.946275  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 07:22:44.946283  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0689487 (* 1 = 0.0689487 loss)
I0627 07:22:44.946288  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.128622 (* 1 = 0.128622 loss)
I0627 07:22:44.946293  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0013593 (* 1 = 0.0013593 loss)
I0627 07:22:44.946298  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192817 (* 1 = 0.0192817 loss)
I0627 07:22:44.946303  6673 sgd_solver.cpp:106] Iteration 29540, lr = 0.0002
I0627 07:24:22.885486  6673 solver.cpp:228] Iteration 29560, loss = 0.236224
I0627 07:24:22.885510  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0627 07:24:22.885517  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.183497 (* 1 = 0.183497 loss)
I0627 07:24:22.885521  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.340756 (* 1 = 0.340756 loss)
I0627 07:24:22.885525  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0382515 (* 1 = 0.0382515 loss)
I0627 07:24:22.885529  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.161418 (* 1 = 0.161418 loss)
I0627 07:24:22.885532  6673 sgd_solver.cpp:106] Iteration 29560, lr = 0.0002
I0627 07:26:00.791024  6673 solver.cpp:228] Iteration 29580, loss = 0.151144
I0627 07:26:00.791049  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 07:26:00.791056  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0211141 (* 1 = 0.0211141 loss)
I0627 07:26:00.791060  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0793864 (* 1 = 0.0793864 loss)
I0627 07:26:00.791064  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000154288 (* 1 = 0.000154288 loss)
I0627 07:26:00.791069  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145354 (* 1 = 0.0145354 loss)
I0627 07:26:00.791074  6673 sgd_solver.cpp:106] Iteration 29580, lr = 0.0002
speed: 4.921s / iter
I0627 07:27:38.738288  6673 solver.cpp:228] Iteration 29600, loss = 0.181809
I0627 07:27:38.738313  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:27:38.738322  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154409 (* 1 = 0.0154409 loss)
I0627 07:27:38.738325  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0495434 (* 1 = 0.0495434 loss)
I0627 07:27:38.738329  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000331311 (* 1 = 0.000331311 loss)
I0627 07:27:38.738334  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00251131 (* 1 = 0.00251131 loss)
I0627 07:27:38.738339  6673 sgd_solver.cpp:106] Iteration 29600, lr = 0.0002
I0627 07:29:16.670622  6673 solver.cpp:228] Iteration 29620, loss = 0.102093
I0627 07:29:16.670647  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:29:16.670655  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273201 (* 1 = 0.0273201 loss)
I0627 07:29:16.670660  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0192186 (* 1 = 0.0192186 loss)
I0627 07:29:16.670663  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.2607e-05 (* 1 = 5.2607e-05 loss)
I0627 07:29:16.670667  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00488718 (* 1 = 0.00488718 loss)
I0627 07:29:16.670672  6673 sgd_solver.cpp:106] Iteration 29620, lr = 0.0002
I0627 07:30:54.585675  6673 solver.cpp:228] Iteration 29640, loss = 0.121441
I0627 07:30:54.585702  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:30:54.585711  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0161519 (* 1 = 0.0161519 loss)
I0627 07:30:54.585716  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00661664 (* 1 = 0.00661664 loss)
I0627 07:30:54.585719  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000109058 (* 1 = 0.000109058 loss)
I0627 07:30:54.585723  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00132145 (* 1 = 0.00132145 loss)
I0627 07:30:54.585728  6673 sgd_solver.cpp:106] Iteration 29640, lr = 0.0002
I0627 07:32:32.503690  6673 solver.cpp:228] Iteration 29660, loss = 0.104027
I0627 07:32:32.503713  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 07:32:32.503720  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0613719 (* 1 = 0.0613719 loss)
I0627 07:32:32.503723  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0813394 (* 1 = 0.0813394 loss)
I0627 07:32:32.503727  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00264079 (* 1 = 0.00264079 loss)
I0627 07:32:32.503731  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176846 (* 1 = 0.0176846 loss)
I0627 07:32:32.503736  6673 sgd_solver.cpp:106] Iteration 29660, lr = 0.0002
I0627 07:34:10.439790  6673 solver.cpp:228] Iteration 29680, loss = 0.121236
I0627 07:34:10.439815  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:34:10.439821  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0137177 (* 1 = 0.0137177 loss)
I0627 07:34:10.439826  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.055205 (* 1 = 0.055205 loss)
I0627 07:34:10.439829  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000377324 (* 1 = 0.000377324 loss)
I0627 07:34:10.439832  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00114222 (* 1 = 0.00114222 loss)
I0627 07:34:10.439837  6673 sgd_solver.cpp:106] Iteration 29680, lr = 0.0002
I0627 07:35:48.362118  6673 solver.cpp:228] Iteration 29700, loss = 0.0862767
I0627 07:35:48.362143  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:35:48.362151  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00359362 (* 1 = 0.00359362 loss)
I0627 07:35:48.362156  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00792459 (* 1 = 0.00792459 loss)
I0627 07:35:48.362159  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000180522 (* 1 = 0.000180522 loss)
I0627 07:35:48.362164  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00561501 (* 1 = 0.00561501 loss)
I0627 07:35:48.362169  6673 sgd_solver.cpp:106] Iteration 29700, lr = 0.0002
I0627 07:37:26.319181  6673 solver.cpp:228] Iteration 29720, loss = 0.118986
I0627 07:37:26.319207  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:37:26.319214  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.018922 (* 1 = 0.018922 loss)
I0627 07:37:26.319218  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.050087 (* 1 = 0.050087 loss)
I0627 07:37:26.319222  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000312961 (* 1 = 0.000312961 loss)
I0627 07:37:26.319226  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00402282 (* 1 = 0.00402282 loss)
I0627 07:37:26.319232  6673 sgd_solver.cpp:106] Iteration 29720, lr = 0.0002
I0627 07:39:04.260864  6673 solver.cpp:228] Iteration 29740, loss = 0.152297
I0627 07:39:04.260888  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 07:39:04.260895  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0174485 (* 1 = 0.0174485 loss)
I0627 07:39:04.260898  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0490801 (* 1 = 0.0490801 loss)
I0627 07:39:04.260902  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000598542 (* 1 = 0.000598542 loss)
I0627 07:39:04.260906  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00316937 (* 1 = 0.00316937 loss)
I0627 07:39:04.260910  6673 sgd_solver.cpp:106] Iteration 29740, lr = 0.0002
I0627 07:40:42.202850  6673 solver.cpp:228] Iteration 29760, loss = 0.162644
I0627 07:40:42.202880  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0627 07:40:42.202888  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0990366 (* 1 = 0.0990366 loss)
I0627 07:40:42.202893  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.271484 (* 1 = 0.271484 loss)
I0627 07:40:42.202895  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00362186 (* 1 = 0.00362186 loss)
I0627 07:40:42.202899  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108057 (* 1 = 0.108057 loss)
I0627 07:40:42.202904  6673 sgd_solver.cpp:106] Iteration 29760, lr = 0.0002
I0627 07:42:20.137887  6673 solver.cpp:228] Iteration 29780, loss = 0.157227
I0627 07:42:20.137909  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:42:20.137917  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0405195 (* 1 = 0.0405195 loss)
I0627 07:42:20.137922  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0717315 (* 1 = 0.0717315 loss)
I0627 07:42:20.137925  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000538594 (* 1 = 0.000538594 loss)
I0627 07:42:20.137929  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151002 (* 1 = 0.0151002 loss)
I0627 07:42:20.137933  6673 sgd_solver.cpp:106] Iteration 29780, lr = 0.0002
speed: 4.921s / iter
I0627 07:43:58.088450  6673 solver.cpp:228] Iteration 29800, loss = 0.100012
I0627 07:43:58.088475  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:43:58.088484  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120339 (* 1 = 0.0120339 loss)
I0627 07:43:58.088487  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0712417 (* 1 = 0.0712417 loss)
I0627 07:43:58.088491  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294967 (* 1 = 0.00294967 loss)
I0627 07:43:58.088495  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00556882 (* 1 = 0.00556882 loss)
I0627 07:43:58.088500  6673 sgd_solver.cpp:106] Iteration 29800, lr = 0.0002
I0627 07:45:36.047943  6673 solver.cpp:228] Iteration 29820, loss = 0.097205
I0627 07:45:36.047967  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 07:45:36.047976  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314614 (* 1 = 0.0314614 loss)
I0627 07:45:36.047979  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0551579 (* 1 = 0.0551579 loss)
I0627 07:45:36.047983  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00044566 (* 1 = 0.00044566 loss)
I0627 07:45:36.047987  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00445612 (* 1 = 0.00445612 loss)
I0627 07:45:36.047992  6673 sgd_solver.cpp:106] Iteration 29820, lr = 0.0002
I0627 07:47:13.992238  6673 solver.cpp:228] Iteration 29840, loss = 0.224283
I0627 07:47:13.992260  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 07:47:13.992267  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0418082 (* 1 = 0.0418082 loss)
I0627 07:47:13.992271  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0544466 (* 1 = 0.0544466 loss)
I0627 07:47:13.992275  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000645865 (* 1 = 0.000645865 loss)
I0627 07:47:13.992278  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266386 (* 1 = 0.0266386 loss)
I0627 07:47:13.992282  6673 sgd_solver.cpp:106] Iteration 29840, lr = 0.0002
I0627 07:48:51.953433  6673 solver.cpp:228] Iteration 29860, loss = 0.173586
I0627 07:48:51.953459  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:48:51.953465  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234819 (* 1 = 0.0234819 loss)
I0627 07:48:51.953469  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0348194 (* 1 = 0.0348194 loss)
I0627 07:48:51.953474  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000942498 (* 1 = 0.000942498 loss)
I0627 07:48:51.953477  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00724497 (* 1 = 0.00724497 loss)
I0627 07:48:51.953482  6673 sgd_solver.cpp:106] Iteration 29860, lr = 0.0002
I0627 07:50:29.829205  6673 solver.cpp:228] Iteration 29880, loss = 0.114042
I0627 07:50:29.829234  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 07:50:29.829242  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0389256 (* 1 = 0.0389256 loss)
I0627 07:50:29.829247  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0946731 (* 1 = 0.0946731 loss)
I0627 07:50:29.829252  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232935 (* 1 = 0.0232935 loss)
I0627 07:50:29.829257  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224335 (* 1 = 0.0224335 loss)
I0627 07:50:29.829263  6673 sgd_solver.cpp:106] Iteration 29880, lr = 0.0002
I0627 07:52:07.813402  6673 solver.cpp:228] Iteration 29900, loss = 0.0859096
I0627 07:52:07.813427  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 07:52:07.813437  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132547 (* 1 = 0.0132547 loss)
I0627 07:52:07.813443  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0120443 (* 1 = 0.0120443 loss)
I0627 07:52:07.813449  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.25971e-05 (* 1 = 5.25971e-05 loss)
I0627 07:52:07.813457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00220715 (* 1 = 0.00220715 loss)
I0627 07:52:07.813463  6673 sgd_solver.cpp:106] Iteration 29900, lr = 0.0002
I0627 07:53:45.711696  6673 solver.cpp:228] Iteration 29920, loss = 0.106853
I0627 07:53:45.711719  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:53:45.711724  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0242309 (* 1 = 0.0242309 loss)
I0627 07:53:45.711729  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0308355 (* 1 = 0.0308355 loss)
I0627 07:53:45.711731  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000301504 (* 1 = 0.000301504 loss)
I0627 07:53:45.711735  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512332 (* 1 = 0.00512332 loss)
I0627 07:53:45.711740  6673 sgd_solver.cpp:106] Iteration 29920, lr = 0.0002
I0627 07:55:23.639984  6673 solver.cpp:228] Iteration 29940, loss = 0.114674
I0627 07:55:23.640010  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 07:55:23.640017  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.04865 (* 1 = 0.04865 loss)
I0627 07:55:23.640022  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0572215 (* 1 = 0.0572215 loss)
I0627 07:55:23.640027  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000604305 (* 1 = 0.000604305 loss)
I0627 07:55:23.640029  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00648715 (* 1 = 0.00648715 loss)
I0627 07:55:23.640034  6673 sgd_solver.cpp:106] Iteration 29940, lr = 0.0002
I0627 07:57:01.572762  6673 solver.cpp:228] Iteration 29960, loss = 0.19035
I0627 07:57:01.572789  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 07:57:01.572798  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465643 (* 1 = 0.0465643 loss)
I0627 07:57:01.572805  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0347135 (* 1 = 0.0347135 loss)
I0627 07:57:01.572811  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00015971 (* 1 = 0.00015971 loss)
I0627 07:57:01.572818  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0269315 (* 1 = 0.0269315 loss)
I0627 07:57:01.572824  6673 sgd_solver.cpp:106] Iteration 29960, lr = 0.0002
I0627 07:58:39.511651  6673 solver.cpp:228] Iteration 29980, loss = 0.082137
I0627 07:58:39.511675  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 07:58:39.511683  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331607 (* 1 = 0.0331607 loss)
I0627 07:58:39.511687  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0433013 (* 1 = 0.0433013 loss)
I0627 07:58:39.511690  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.25224e-05 (* 1 = 4.25224e-05 loss)
I0627 07:58:39.511694  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00906199 (* 1 = 0.00906199 loss)
I0627 07:58:39.511698  6673 sgd_solver.cpp:106] Iteration 29980, lr = 0.0002
speed: 4.921s / iter
I0627 08:00:12.906278  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_30000.caffemodel
I0627 08:00:18.211105  6673 solver.cpp:228] Iteration 30000, loss = 0.103849
I0627 08:00:18.211133  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:00:18.211143  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228787 (* 1 = 0.0228787 loss)
I0627 08:00:18.211149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0285546 (* 1 = 0.0285546 loss)
I0627 08:00:18.211155  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000129051 (* 1 = 0.000129051 loss)
I0627 08:00:18.211163  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00391724 (* 1 = 0.00391724 loss)
I0627 08:00:18.211169  6673 sgd_solver.cpp:106] Iteration 30000, lr = 0.0002
I0627 08:01:56.186324  6673 solver.cpp:228] Iteration 30020, loss = 0.147721
I0627 08:01:56.186348  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:01:56.186355  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0721711 (* 1 = 0.0721711 loss)
I0627 08:01:56.186359  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0759843 (* 1 = 0.0759843 loss)
I0627 08:01:56.186362  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133051 (* 1 = 0.00133051 loss)
I0627 08:01:56.186367  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200141 (* 1 = 0.0200141 loss)
I0627 08:01:56.186372  6673 sgd_solver.cpp:106] Iteration 30020, lr = 0.0002
I0627 08:03:34.152279  6673 solver.cpp:228] Iteration 30040, loss = 0.101648
I0627 08:03:34.152302  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:03:34.152309  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0118977 (* 1 = 0.0118977 loss)
I0627 08:03:34.152314  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0421698 (* 1 = 0.0421698 loss)
I0627 08:03:34.152318  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000587385 (* 1 = 0.000587385 loss)
I0627 08:03:34.152321  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000600499 (* 1 = 0.000600499 loss)
I0627 08:03:34.152325  6673 sgd_solver.cpp:106] Iteration 30040, lr = 0.0002
I0627 08:05:12.192019  6673 solver.cpp:228] Iteration 30060, loss = 0.204078
I0627 08:05:12.192045  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 08:05:12.192052  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0461634 (* 1 = 0.0461634 loss)
I0627 08:05:12.192057  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0694528 (* 1 = 0.0694528 loss)
I0627 08:05:12.192061  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000515145 (* 1 = 0.000515145 loss)
I0627 08:05:12.192065  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00846312 (* 1 = 0.00846312 loss)
I0627 08:05:12.192070  6673 sgd_solver.cpp:106] Iteration 30060, lr = 0.0002
I0627 08:06:50.623577  6673 solver.cpp:228] Iteration 30080, loss = 0.194066
I0627 08:06:50.623601  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 08:06:50.623608  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0869496 (* 1 = 0.0869496 loss)
I0627 08:06:50.623612  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.187662 (* 1 = 0.187662 loss)
I0627 08:06:50.623615  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00194948 (* 1 = 0.00194948 loss)
I0627 08:06:50.623620  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281216 (* 1 = 0.0281216 loss)
I0627 08:06:50.623625  6673 sgd_solver.cpp:106] Iteration 30080, lr = 0.0002
I0627 08:08:29.162580  6673 solver.cpp:228] Iteration 30100, loss = 0.128292
I0627 08:08:29.162603  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 08:08:29.162611  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0107096 (* 1 = 0.0107096 loss)
I0627 08:08:29.162614  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00803427 (* 1 = 0.00803427 loss)
I0627 08:08:29.162617  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000761636 (* 1 = 0.000761636 loss)
I0627 08:08:29.162621  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00355234 (* 1 = 0.00355234 loss)
I0627 08:08:29.162626  6673 sgd_solver.cpp:106] Iteration 30100, lr = 0.0002
I0627 08:10:07.521706  6673 solver.cpp:228] Iteration 30120, loss = 0.0987468
I0627 08:10:07.521731  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:10:07.521739  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402792 (* 1 = 0.0402792 loss)
I0627 08:10:07.521744  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0629438 (* 1 = 0.0629438 loss)
I0627 08:10:07.521747  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00104299 (* 1 = 0.00104299 loss)
I0627 08:10:07.521750  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013943 (* 1 = 0.013943 loss)
I0627 08:10:07.521755  6673 sgd_solver.cpp:106] Iteration 30120, lr = 0.0002
I0627 08:11:45.896414  6673 solver.cpp:228] Iteration 30140, loss = 0.0557321
I0627 08:11:45.896440  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 08:11:45.896446  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157493 (* 1 = 0.0157493 loss)
I0627 08:11:45.896450  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0134231 (* 1 = 0.0134231 loss)
I0627 08:11:45.896453  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 9.0833e-05 (* 1 = 9.0833e-05 loss)
I0627 08:11:45.896457  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000903598 (* 1 = 0.000903598 loss)
I0627 08:11:45.896462  6673 sgd_solver.cpp:106] Iteration 30140, lr = 0.0002
I0627 08:13:24.341724  6673 solver.cpp:228] Iteration 30160, loss = 0.148917
I0627 08:13:24.341748  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 08:13:24.341756  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0252504 (* 1 = 0.0252504 loss)
I0627 08:13:24.341761  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0815682 (* 1 = 0.0815682 loss)
I0627 08:13:24.341765  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000766613 (* 1 = 0.000766613 loss)
I0627 08:13:24.341769  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000573594 (* 1 = 0.000573594 loss)
I0627 08:13:24.341774  6673 sgd_solver.cpp:106] Iteration 30160, lr = 0.0002
I0627 08:15:02.432512  6673 solver.cpp:228] Iteration 30180, loss = 0.126493
I0627 08:15:02.432535  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:15:02.432543  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0639742 (* 1 = 0.0639742 loss)
I0627 08:15:02.432546  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0589845 (* 1 = 0.0589845 loss)
I0627 08:15:02.432550  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015933 (* 1 = 0.0015933 loss)
I0627 08:15:02.432554  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00969933 (* 1 = 0.00969933 loss)
I0627 08:15:02.432559  6673 sgd_solver.cpp:106] Iteration 30180, lr = 0.0002
speed: 4.921s / iter
I0627 08:16:40.614929  6673 solver.cpp:228] Iteration 30200, loss = 0.150543
I0627 08:16:40.614954  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:16:40.614964  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108285 (* 1 = 0.0108285 loss)
I0627 08:16:40.614969  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0240617 (* 1 = 0.0240617 loss)
I0627 08:16:40.614975  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.19317e-05 (* 1 = 2.19317e-05 loss)
I0627 08:16:40.614980  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000684307 (* 1 = 0.000684307 loss)
I0627 08:16:40.614989  6673 sgd_solver.cpp:106] Iteration 30200, lr = 0.0002
I0627 08:18:18.671046  6673 solver.cpp:228] Iteration 30220, loss = 0.151975
I0627 08:18:18.671072  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 08:18:18.671078  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.069532 (* 1 = 0.069532 loss)
I0627 08:18:18.671082  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.104977 (* 1 = 0.104977 loss)
I0627 08:18:18.671087  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00349763 (* 1 = 0.00349763 loss)
I0627 08:18:18.671090  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346321 (* 1 = 0.0346321 loss)
I0627 08:18:18.671095  6673 sgd_solver.cpp:106] Iteration 30220, lr = 0.0002
I0627 08:19:56.732488  6673 solver.cpp:228] Iteration 30240, loss = 0.0964559
I0627 08:19:56.732518  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:19:56.732527  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.01345 (* 1 = 0.01345 loss)
I0627 08:19:56.732530  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.021186 (* 1 = 0.021186 loss)
I0627 08:19:56.732534  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000313971 (* 1 = 0.000313971 loss)
I0627 08:19:56.732538  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00847159 (* 1 = 0.00847159 loss)
I0627 08:19:56.732544  6673 sgd_solver.cpp:106] Iteration 30240, lr = 0.0002
I0627 08:21:34.810498  6673 solver.cpp:228] Iteration 30260, loss = 0.114497
I0627 08:21:34.810524  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:21:34.810534  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0633532 (* 1 = 0.0633532 loss)
I0627 08:21:34.810539  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0789091 (* 1 = 0.0789091 loss)
I0627 08:21:34.810544  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.12568e-05 (* 1 = 6.12568e-05 loss)
I0627 08:21:34.810550  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00597743 (* 1 = 0.00597743 loss)
I0627 08:21:34.810556  6673 sgd_solver.cpp:106] Iteration 30260, lr = 0.0002
I0627 08:23:12.857429  6673 solver.cpp:228] Iteration 30280, loss = 0.216075
I0627 08:23:12.857451  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:23:12.857458  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173526 (* 1 = 0.0173526 loss)
I0627 08:23:12.857462  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0383066 (* 1 = 0.0383066 loss)
I0627 08:23:12.857465  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114761 (* 1 = 0.00114761 loss)
I0627 08:23:12.857470  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00493388 (* 1 = 0.00493388 loss)
I0627 08:23:12.857473  6673 sgd_solver.cpp:106] Iteration 30280, lr = 0.0002
I0627 08:24:50.866464  6673 solver.cpp:228] Iteration 30300, loss = 0.118867
I0627 08:24:50.866489  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0627 08:24:50.866497  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.136324 (* 1 = 0.136324 loss)
I0627 08:24:50.866502  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.171345 (* 1 = 0.171345 loss)
I0627 08:24:50.866505  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00209266 (* 1 = 0.00209266 loss)
I0627 08:24:50.866509  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307479 (* 1 = 0.0307479 loss)
I0627 08:24:50.866514  6673 sgd_solver.cpp:106] Iteration 30300, lr = 0.0002
I0627 08:26:28.798197  6673 solver.cpp:228] Iteration 30320, loss = 0.0835345
I0627 08:26:28.798221  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:26:28.798229  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.010944 (* 1 = 0.010944 loss)
I0627 08:26:28.798233  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0161883 (* 1 = 0.0161883 loss)
I0627 08:26:28.798238  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.37926e-05 (* 1 = 2.37926e-05 loss)
I0627 08:26:28.798241  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00146791 (* 1 = 0.00146791 loss)
I0627 08:26:28.798246  6673 sgd_solver.cpp:106] Iteration 30320, lr = 0.0002
I0627 08:28:06.766599  6673 solver.cpp:228] Iteration 30340, loss = 0.174686
I0627 08:28:06.766623  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 08:28:06.766631  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00983235 (* 1 = 0.00983235 loss)
I0627 08:28:06.766635  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0159949 (* 1 = 0.0159949 loss)
I0627 08:28:06.766638  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000268372 (* 1 = 0.000268372 loss)
I0627 08:28:06.766641  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00370161 (* 1 = 0.00370161 loss)
I0627 08:28:06.766646  6673 sgd_solver.cpp:106] Iteration 30340, lr = 0.0002
I0627 08:29:44.685225  6673 solver.cpp:228] Iteration 30360, loss = 0.12621
I0627 08:29:44.685250  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:29:44.685256  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0138223 (* 1 = 0.0138223 loss)
I0627 08:29:44.685261  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.035912 (* 1 = 0.035912 loss)
I0627 08:29:44.685264  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00915167 (* 1 = 0.00915167 loss)
I0627 08:29:44.685268  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130002 (* 1 = 0.0130002 loss)
I0627 08:29:44.685272  6673 sgd_solver.cpp:106] Iteration 30360, lr = 0.0002
I0627 08:31:22.649598  6673 solver.cpp:228] Iteration 30380, loss = 0.168128
I0627 08:31:22.649623  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:31:22.649631  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233322 (* 1 = 0.0233322 loss)
I0627 08:31:22.649636  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0756953 (* 1 = 0.0756953 loss)
I0627 08:31:22.649639  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000231182 (* 1 = 0.000231182 loss)
I0627 08:31:22.649642  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0077226 (* 1 = 0.0077226 loss)
I0627 08:31:22.649647  6673 sgd_solver.cpp:106] Iteration 30380, lr = 0.0002
speed: 4.921s / iter
I0627 08:33:00.624913  6673 solver.cpp:228] Iteration 30400, loss = 0.105508
I0627 08:33:00.624938  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:33:00.624945  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355162 (* 1 = 0.0355162 loss)
I0627 08:33:00.624949  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0801573 (* 1 = 0.0801573 loss)
I0627 08:33:00.624953  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000232751 (* 1 = 0.000232751 loss)
I0627 08:33:00.624956  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00347555 (* 1 = 0.00347555 loss)
I0627 08:33:00.624960  6673 sgd_solver.cpp:106] Iteration 30400, lr = 0.0002
I0627 08:34:38.536453  6673 solver.cpp:228] Iteration 30420, loss = 0.111235
I0627 08:34:38.536475  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:34:38.536484  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.010614 (* 1 = 0.010614 loss)
I0627 08:34:38.536486  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00735338 (* 1 = 0.00735338 loss)
I0627 08:34:38.536490  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.83843e-05 (* 1 = 4.83843e-05 loss)
I0627 08:34:38.536494  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00174996 (* 1 = 0.00174996 loss)
I0627 08:34:38.536499  6673 sgd_solver.cpp:106] Iteration 30420, lr = 0.0002
I0627 08:36:16.469775  6673 solver.cpp:228] Iteration 30440, loss = 0.115914
I0627 08:36:16.469800  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:36:16.469807  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0109269 (* 1 = 0.0109269 loss)
I0627 08:36:16.469811  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0375878 (* 1 = 0.0375878 loss)
I0627 08:36:16.469815  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000109021 (* 1 = 0.000109021 loss)
I0627 08:36:16.469818  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00408722 (* 1 = 0.00408722 loss)
I0627 08:36:16.469822  6673 sgd_solver.cpp:106] Iteration 30440, lr = 0.0002
I0627 08:37:54.403980  6673 solver.cpp:228] Iteration 30460, loss = 0.109039
I0627 08:37:54.404002  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 08:37:54.404011  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0633893 (* 1 = 0.0633893 loss)
I0627 08:37:54.404013  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0975443 (* 1 = 0.0975443 loss)
I0627 08:37:54.404017  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000309696 (* 1 = 0.000309696 loss)
I0627 08:37:54.404021  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311952 (* 1 = 0.0311952 loss)
I0627 08:37:54.404026  6673 sgd_solver.cpp:106] Iteration 30460, lr = 0.0002
I0627 08:39:32.366822  6673 solver.cpp:228] Iteration 30480, loss = 0.0557474
I0627 08:39:32.366848  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 08:39:32.366856  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0125168 (* 1 = 0.0125168 loss)
I0627 08:39:32.366864  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0102613 (* 1 = 0.0102613 loss)
I0627 08:39:32.366868  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000595918 (* 1 = 0.000595918 loss)
I0627 08:39:32.366873  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00441365 (* 1 = 0.00441365 loss)
I0627 08:39:32.366879  6673 sgd_solver.cpp:106] Iteration 30480, lr = 0.0002
I0627 08:41:10.326576  6673 solver.cpp:228] Iteration 30500, loss = 0.174026
I0627 08:41:10.326599  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 08:41:10.326607  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591065 (* 1 = 0.0591065 loss)
I0627 08:41:10.326611  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.10477 (* 1 = 0.10477 loss)
I0627 08:41:10.326614  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128724 (* 1 = 0.0128724 loss)
I0627 08:41:10.326618  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101247 (* 1 = 0.0101247 loss)
I0627 08:41:10.326622  6673 sgd_solver.cpp:106] Iteration 30500, lr = 0.0002
I0627 08:42:48.284871  6673 solver.cpp:228] Iteration 30520, loss = 0.0474814
I0627 08:42:48.284899  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:42:48.284907  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00435263 (* 1 = 0.00435263 loss)
I0627 08:42:48.284911  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0238459 (* 1 = 0.0238459 loss)
I0627 08:42:48.284915  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 2.39466e-05 (* 1 = 2.39466e-05 loss)
I0627 08:42:48.284919  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00538496 (* 1 = 0.00538496 loss)
I0627 08:42:48.284924  6673 sgd_solver.cpp:106] Iteration 30520, lr = 0.0002
I0627 08:44:26.322196  6673 solver.cpp:228] Iteration 30540, loss = 0.097524
I0627 08:44:26.322221  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:44:26.322228  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.164961 (* 1 = 0.164961 loss)
I0627 08:44:26.322232  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0905765 (* 1 = 0.0905765 loss)
I0627 08:44:26.322237  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00127747 (* 1 = 0.00127747 loss)
I0627 08:44:26.322242  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153025 (* 1 = 0.0153025 loss)
I0627 08:44:26.322245  6673 sgd_solver.cpp:106] Iteration 30540, lr = 0.0002
I0627 08:46:04.463197  6673 solver.cpp:228] Iteration 30560, loss = 0.0682183
I0627 08:46:04.463222  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:46:04.463228  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0120866 (* 1 = 0.0120866 loss)
I0627 08:46:04.463232  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0415203 (* 1 = 0.0415203 loss)
I0627 08:46:04.463235  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.21171e-05 (* 1 = 4.21171e-05 loss)
I0627 08:46:04.463239  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00122354 (* 1 = 0.00122354 loss)
I0627 08:46:04.463243  6673 sgd_solver.cpp:106] Iteration 30560, lr = 0.0002
I0627 08:47:42.476472  6673 solver.cpp:228] Iteration 30580, loss = 0.0722523
I0627 08:47:42.476497  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:47:42.476505  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00803221 (* 1 = 0.00803221 loss)
I0627 08:47:42.476510  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0198109 (* 1 = 0.0198109 loss)
I0627 08:47:42.476513  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 1.69849e-05 (* 1 = 1.69849e-05 loss)
I0627 08:47:42.476516  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00322768 (* 1 = 0.00322768 loss)
I0627 08:47:42.476522  6673 sgd_solver.cpp:106] Iteration 30580, lr = 0.0002
speed: 4.920s / iter
I0627 08:49:20.508946  6673 solver.cpp:228] Iteration 30600, loss = 0.100857
I0627 08:49:20.508970  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:49:20.508978  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0563232 (* 1 = 0.0563232 loss)
I0627 08:49:20.508982  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0404716 (* 1 = 0.0404716 loss)
I0627 08:49:20.508986  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00334188 (* 1 = 0.00334188 loss)
I0627 08:49:20.508991  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164354 (* 1 = 0.0164354 loss)
I0627 08:49:20.508996  6673 sgd_solver.cpp:106] Iteration 30600, lr = 0.0002
I0627 08:50:58.477995  6673 solver.cpp:228] Iteration 30620, loss = 0.146471
I0627 08:50:58.478024  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 08:50:58.478031  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533484 (* 1 = 0.0533484 loss)
I0627 08:50:58.478035  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0766624 (* 1 = 0.0766624 loss)
I0627 08:50:58.478040  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.001365 (* 1 = 0.001365 loss)
I0627 08:50:58.478044  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240027 (* 1 = 0.0240027 loss)
I0627 08:50:58.478049  6673 sgd_solver.cpp:106] Iteration 30620, lr = 0.0002
I0627 08:52:36.427554  6673 solver.cpp:228] Iteration 30640, loss = 0.11882
I0627 08:52:36.427588  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 08:52:36.427597  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0151317 (* 1 = 0.0151317 loss)
I0627 08:52:36.427603  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0446614 (* 1 = 0.0446614 loss)
I0627 08:52:36.427608  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00207289 (* 1 = 0.00207289 loss)
I0627 08:52:36.427614  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200738 (* 1 = 0.0200738 loss)
I0627 08:52:36.427621  6673 sgd_solver.cpp:106] Iteration 30640, lr = 0.0002
I0627 08:54:14.373191  6673 solver.cpp:228] Iteration 30660, loss = 0.109244
I0627 08:54:14.373214  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 08:54:14.373221  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.015825 (* 1 = 0.015825 loss)
I0627 08:54:14.373225  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0530113 (* 1 = 0.0530113 loss)
I0627 08:54:14.373229  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000470722 (* 1 = 0.000470722 loss)
I0627 08:54:14.373232  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00618697 (* 1 = 0.00618697 loss)
I0627 08:54:14.373237  6673 sgd_solver.cpp:106] Iteration 30660, lr = 0.0002
I0627 08:55:52.528164  6673 solver.cpp:228] Iteration 30680, loss = 0.124295
I0627 08:55:52.528188  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 08:55:52.528196  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465072 (* 1 = 0.0465072 loss)
I0627 08:55:52.528200  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.119151 (* 1 = 0.119151 loss)
I0627 08:55:52.528204  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.20339e-05 (* 1 = 8.20339e-05 loss)
I0627 08:55:52.528208  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126919 (* 1 = 0.0126919 loss)
I0627 08:55:52.528213  6673 sgd_solver.cpp:106] Iteration 30680, lr = 0.0002
I0627 08:57:31.334973  6673 solver.cpp:228] Iteration 30700, loss = 0.0771903
I0627 08:57:31.334997  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 08:57:31.335005  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169679 (* 1 = 0.0169679 loss)
I0627 08:57:31.335008  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0085737 (* 1 = 0.0085737 loss)
I0627 08:57:31.335013  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141695 (* 1 = 0.00141695 loss)
I0627 08:57:31.335016  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00422443 (* 1 = 0.00422443 loss)
I0627 08:57:31.335021  6673 sgd_solver.cpp:106] Iteration 30700, lr = 0.0002
I0627 08:59:09.901783  6673 solver.cpp:228] Iteration 30720, loss = 0.105643
I0627 08:59:09.901809  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 08:59:09.901818  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0785939 (* 1 = 0.0785939 loss)
I0627 08:59:09.901820  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.130243 (* 1 = 0.130243 loss)
I0627 08:59:09.901824  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00129378 (* 1 = 0.00129378 loss)
I0627 08:59:09.901829  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335251 (* 1 = 0.0335251 loss)
I0627 08:59:09.901834  6673 sgd_solver.cpp:106] Iteration 30720, lr = 0.0002
I0627 09:00:48.438618  6673 solver.cpp:228] Iteration 30740, loss = 0.0732368
I0627 09:00:48.438643  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:00:48.438652  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294947 (* 1 = 0.0294947 loss)
I0627 09:00:48.438658  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0288149 (* 1 = 0.0288149 loss)
I0627 09:00:48.438664  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000280442 (* 1 = 0.000280442 loss)
I0627 09:00:48.438670  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00850678 (* 1 = 0.00850678 loss)
I0627 09:00:48.438676  6673 sgd_solver.cpp:106] Iteration 30740, lr = 0.0002
I0627 09:02:27.080241  6673 solver.cpp:228] Iteration 30760, loss = 0.15625
I0627 09:02:27.080271  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0627 09:02:27.080277  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0740608 (* 1 = 0.0740608 loss)
I0627 09:02:27.080282  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.129834 (* 1 = 0.129834 loss)
I0627 09:02:27.080286  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108102 (* 1 = 0.0108102 loss)
I0627 09:02:27.080291  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.154113 (* 1 = 0.154113 loss)
I0627 09:02:27.080296  6673 sgd_solver.cpp:106] Iteration 30760, lr = 0.0002
I0627 09:04:05.599468  6673 solver.cpp:228] Iteration 30780, loss = 0.126936
I0627 09:04:05.599495  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0627 09:04:05.599503  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0490328 (* 1 = 0.0490328 loss)
I0627 09:04:05.599506  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.153266 (* 1 = 0.153266 loss)
I0627 09:04:05.599510  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00298298 (* 1 = 0.00298298 loss)
I0627 09:04:05.599514  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122306 (* 1 = 0.0122306 loss)
I0627 09:04:05.599519  6673 sgd_solver.cpp:106] Iteration 30780, lr = 0.0002
speed: 4.920s / iter
I0627 09:05:43.875962  6673 solver.cpp:228] Iteration 30800, loss = 0.196313
I0627 09:05:43.875988  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 09:05:43.875993  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170685 (* 1 = 0.0170685 loss)
I0627 09:05:43.875998  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0660216 (* 1 = 0.0660216 loss)
I0627 09:05:43.876001  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00020974 (* 1 = 0.00020974 loss)
I0627 09:05:43.876004  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129701 (* 1 = 0.0129701 loss)
I0627 09:05:43.876009  6673 sgd_solver.cpp:106] Iteration 30800, lr = 0.0002
I0627 09:07:22.404486  6673 solver.cpp:228] Iteration 30820, loss = 0.153921
I0627 09:07:22.404515  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:07:22.404522  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0155638 (* 1 = 0.0155638 loss)
I0627 09:07:22.404526  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0227246 (* 1 = 0.0227246 loss)
I0627 09:07:22.404531  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000206216 (* 1 = 0.000206216 loss)
I0627 09:07:22.404534  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0010913 (* 1 = 0.0010913 loss)
I0627 09:07:22.404541  6673 sgd_solver.cpp:106] Iteration 30820, lr = 0.0002
I0627 09:09:00.604707  6673 solver.cpp:228] Iteration 30840, loss = 0.166138
I0627 09:09:00.604732  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 09:09:00.604738  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108327 (* 1 = 0.0108327 loss)
I0627 09:09:00.604743  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00735727 (* 1 = 0.00735727 loss)
I0627 09:09:00.604746  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00101399 (* 1 = 0.00101399 loss)
I0627 09:09:00.604749  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00702278 (* 1 = 0.00702278 loss)
I0627 09:09:00.604754  6673 sgd_solver.cpp:106] Iteration 30840, lr = 0.0002
I0627 09:10:38.795136  6673 solver.cpp:228] Iteration 30860, loss = 0.164626
I0627 09:10:38.795162  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:10:38.795172  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.018763 (* 1 = 0.018763 loss)
I0627 09:10:38.795178  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0338334 (* 1 = 0.0338334 loss)
I0627 09:10:38.795186  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000631065 (* 1 = 0.000631065 loss)
I0627 09:10:38.795192  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00878347 (* 1 = 0.00878347 loss)
I0627 09:10:38.795200  6673 sgd_solver.cpp:106] Iteration 30860, lr = 0.0002
I0627 09:12:17.118533  6673 solver.cpp:228] Iteration 30880, loss = 0.10474
I0627 09:12:17.118561  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0627 09:12:17.118571  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791495 (* 1 = 0.0791495 loss)
I0627 09:12:17.118577  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.152947 (* 1 = 0.152947 loss)
I0627 09:12:17.118582  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120031 (* 1 = 0.0120031 loss)
I0627 09:12:17.118588  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235941 (* 1 = 0.0235941 loss)
I0627 09:12:17.118595  6673 sgd_solver.cpp:106] Iteration 30880, lr = 0.0002
I0627 09:13:55.271284  6673 solver.cpp:228] Iteration 30900, loss = 0.118572
I0627 09:13:55.271309  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:13:55.271317  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0385875 (* 1 = 0.0385875 loss)
I0627 09:13:55.271322  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0463951 (* 1 = 0.0463951 loss)
I0627 09:13:55.271325  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00222329 (* 1 = 0.00222329 loss)
I0627 09:13:55.271329  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171041 (* 1 = 0.0171041 loss)
I0627 09:13:55.271334  6673 sgd_solver.cpp:106] Iteration 30900, lr = 0.0002
I0627 09:15:33.376174  6673 solver.cpp:228] Iteration 30920, loss = 0.0825646
I0627 09:15:33.376199  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:15:33.376204  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00972543 (* 1 = 0.00972543 loss)
I0627 09:15:33.376209  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0362105 (* 1 = 0.0362105 loss)
I0627 09:15:33.376212  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00146703 (* 1 = 0.00146703 loss)
I0627 09:15:33.376216  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000514501 (* 1 = 0.000514501 loss)
I0627 09:15:33.376220  6673 sgd_solver.cpp:106] Iteration 30920, lr = 0.0002
I0627 09:17:11.415524  6673 solver.cpp:228] Iteration 30940, loss = 0.12201
I0627 09:17:11.415549  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:17:11.415555  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113148 (* 1 = 0.0113148 loss)
I0627 09:17:11.415560  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0549831 (* 1 = 0.0549831 loss)
I0627 09:17:11.415563  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 8.39859e-05 (* 1 = 8.39859e-05 loss)
I0627 09:17:11.415566  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00172941 (* 1 = 0.00172941 loss)
I0627 09:17:11.415571  6673 sgd_solver.cpp:106] Iteration 30940, lr = 0.0002
I0627 09:18:49.446096  6673 solver.cpp:228] Iteration 30960, loss = 0.120618
I0627 09:18:49.446122  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 09:18:49.446130  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.114583 (* 1 = 0.114583 loss)
I0627 09:18:49.446133  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.225517 (* 1 = 0.225517 loss)
I0627 09:18:49.446136  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00479574 (* 1 = 0.00479574 loss)
I0627 09:18:49.446141  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288799 (* 1 = 0.0288799 loss)
I0627 09:18:49.446146  6673 sgd_solver.cpp:106] Iteration 30960, lr = 0.0002
I0627 09:20:27.481806  6673 solver.cpp:228] Iteration 30980, loss = 0.183148
I0627 09:20:27.481830  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:20:27.481838  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0821798 (* 1 = 0.0821798 loss)
I0627 09:20:27.481842  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0470171 (* 1 = 0.0470171 loss)
I0627 09:20:27.481847  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000110818 (* 1 = 0.000110818 loss)
I0627 09:20:27.481850  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0220689 (* 1 = 0.0220689 loss)
I0627 09:20:27.481854  6673 sgd_solver.cpp:106] Iteration 30980, lr = 0.0002
speed: 4.920s / iter
I0627 09:22:05.478255  6673 solver.cpp:228] Iteration 31000, loss = 0.15815
I0627 09:22:05.478281  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:22:05.478289  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339823 (* 1 = 0.0339823 loss)
I0627 09:22:05.478297  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0409188 (* 1 = 0.0409188 loss)
I0627 09:22:05.478307  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000516504 (* 1 = 0.000516504 loss)
I0627 09:22:05.478312  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108978 (* 1 = 0.0108978 loss)
I0627 09:22:05.478318  6673 sgd_solver.cpp:106] Iteration 31000, lr = 0.0002
I0627 09:23:43.487560  6673 solver.cpp:228] Iteration 31020, loss = 0.0963438
I0627 09:23:43.487586  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:23:43.487593  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157722 (* 1 = 0.0157722 loss)
I0627 09:23:43.487597  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0223802 (* 1 = 0.0223802 loss)
I0627 09:23:43.487602  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000158138 (* 1 = 0.000158138 loss)
I0627 09:23:43.487606  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00879922 (* 1 = 0.00879922 loss)
I0627 09:23:43.487610  6673 sgd_solver.cpp:106] Iteration 31020, lr = 0.0002
I0627 09:25:21.532923  6673 solver.cpp:228] Iteration 31040, loss = 0.116002
I0627 09:25:21.532950  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:25:21.532960  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.022554 (* 1 = 0.022554 loss)
I0627 09:25:21.532968  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0153602 (* 1 = 0.0153602 loss)
I0627 09:25:21.532974  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000835568 (* 1 = 0.000835568 loss)
I0627 09:25:21.532980  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00160404 (* 1 = 0.00160404 loss)
I0627 09:25:21.532986  6673 sgd_solver.cpp:106] Iteration 31040, lr = 0.0002
I0627 09:26:59.512058  6673 solver.cpp:228] Iteration 31060, loss = 0.124865
I0627 09:26:59.512080  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 09:26:59.512089  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0261231 (* 1 = 0.0261231 loss)
I0627 09:26:59.512092  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0556885 (* 1 = 0.0556885 loss)
I0627 09:26:59.512095  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000836613 (* 1 = 0.000836613 loss)
I0627 09:26:59.512099  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261836 (* 1 = 0.0261836 loss)
I0627 09:26:59.512104  6673 sgd_solver.cpp:106] Iteration 31060, lr = 0.0002
I0627 09:28:37.476681  6673 solver.cpp:228] Iteration 31080, loss = 0.171262
I0627 09:28:37.476706  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 09:28:37.476714  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142061 (* 1 = 0.0142061 loss)
I0627 09:28:37.476721  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0110504 (* 1 = 0.0110504 loss)
I0627 09:28:37.476725  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000419077 (* 1 = 0.000419077 loss)
I0627 09:28:37.476732  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00342599 (* 1 = 0.00342599 loss)
I0627 09:28:37.476737  6673 sgd_solver.cpp:106] Iteration 31080, lr = 0.0002
I0627 09:30:15.436882  6673 solver.cpp:228] Iteration 31100, loss = 0.141365
I0627 09:30:15.436904  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0627 09:30:15.436913  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.04068 (* 1 = 0.04068 loss)
I0627 09:30:15.436916  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.168903 (* 1 = 0.168903 loss)
I0627 09:30:15.436920  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0320311 (* 1 = 0.0320311 loss)
I0627 09:30:15.436923  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.172542 (* 1 = 0.172542 loss)
I0627 09:30:15.436928  6673 sgd_solver.cpp:106] Iteration 31100, lr = 0.0002
I0627 09:31:53.435225  6673 solver.cpp:228] Iteration 31120, loss = 0.151072
I0627 09:31:53.435251  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:31:53.435258  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.117879 (* 1 = 0.117879 loss)
I0627 09:31:53.435263  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0648944 (* 1 = 0.0648944 loss)
I0627 09:31:53.435267  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00163674 (* 1 = 0.00163674 loss)
I0627 09:31:53.435271  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.03163 (* 1 = 0.03163 loss)
I0627 09:31:53.435276  6673 sgd_solver.cpp:106] Iteration 31120, lr = 0.0002
I0627 09:33:31.431210  6673 solver.cpp:228] Iteration 31140, loss = 0.118993
I0627 09:33:31.431239  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0627 09:33:31.431248  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.109669 (* 1 = 0.109669 loss)
I0627 09:33:31.431254  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.149018 (* 1 = 0.149018 loss)
I0627 09:33:31.431260  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000786474 (* 1 = 0.000786474 loss)
I0627 09:33:31.431265  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237253 (* 1 = 0.0237253 loss)
I0627 09:33:31.431272  6673 sgd_solver.cpp:106] Iteration 31140, lr = 0.0002
I0627 09:35:09.437888  6673 solver.cpp:228] Iteration 31160, loss = 0.133996
I0627 09:35:09.437916  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:35:09.437922  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0205697 (* 1 = 0.0205697 loss)
I0627 09:35:09.437927  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0593158 (* 1 = 0.0593158 loss)
I0627 09:35:09.437930  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000723812 (* 1 = 0.000723812 loss)
I0627 09:35:09.437933  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144957 (* 1 = 0.0144957 loss)
I0627 09:35:09.437938  6673 sgd_solver.cpp:106] Iteration 31160, lr = 0.0002
I0627 09:36:47.476460  6673 solver.cpp:228] Iteration 31180, loss = 0.123679
I0627 09:36:47.476488  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 09:36:47.476498  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00948726 (* 1 = 0.00948726 loss)
I0627 09:36:47.476505  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0113217 (* 1 = 0.0113217 loss)
I0627 09:36:47.476511  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000696789 (* 1 = 0.000696789 loss)
I0627 09:36:47.476516  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00460488 (* 1 = 0.00460488 loss)
I0627 09:36:47.476524  6673 sgd_solver.cpp:106] Iteration 31180, lr = 0.0002
speed: 4.920s / iter
I0627 09:38:25.677677  6673 solver.cpp:228] Iteration 31200, loss = 0.142517
I0627 09:38:25.677750  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 09:38:25.677773  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276515 (* 1 = 0.0276515 loss)
I0627 09:38:25.677789  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.101568 (* 1 = 0.101568 loss)
I0627 09:38:25.677804  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00266249 (* 1 = 0.00266249 loss)
I0627 09:38:25.677820  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115769 (* 1 = 0.0115769 loss)
I0627 09:38:25.677836  6673 sgd_solver.cpp:106] Iteration 31200, lr = 0.0002
I0627 09:40:03.788064  6673 solver.cpp:228] Iteration 31220, loss = 0.0886717
I0627 09:40:03.788086  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:40:03.788094  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247881 (* 1 = 0.0247881 loss)
I0627 09:40:03.788097  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0524423 (* 1 = 0.0524423 loss)
I0627 09:40:03.788101  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000524469 (* 1 = 0.000524469 loss)
I0627 09:40:03.788105  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00959843 (* 1 = 0.00959843 loss)
I0627 09:40:03.788110  6673 sgd_solver.cpp:106] Iteration 31220, lr = 0.0002
I0627 09:41:41.923944  6673 solver.cpp:228] Iteration 31240, loss = 0.135561
I0627 09:41:41.923971  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:41:41.923979  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0470914 (* 1 = 0.0470914 loss)
I0627 09:41:41.923985  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0490394 (* 1 = 0.0490394 loss)
I0627 09:41:41.923987  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179383 (* 1 = 0.0179383 loss)
I0627 09:41:41.923991  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141275 (* 1 = 0.0141275 loss)
I0627 09:41:41.923997  6673 sgd_solver.cpp:106] Iteration 31240, lr = 0.0002
I0627 09:43:19.919864  6673 solver.cpp:228] Iteration 31260, loss = 0.134689
I0627 09:43:19.919888  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:43:19.919895  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.1104 (* 1 = 0.1104 loss)
I0627 09:43:19.919899  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0617268 (* 1 = 0.0617268 loss)
I0627 09:43:19.919903  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00419018 (* 1 = 0.00419018 loss)
I0627 09:43:19.919906  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239562 (* 1 = 0.0239562 loss)
I0627 09:43:19.919911  6673 sgd_solver.cpp:106] Iteration 31260, lr = 0.0002
I0627 09:44:58.231075  6673 solver.cpp:228] Iteration 31280, loss = 0.126232
I0627 09:44:58.231099  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:44:58.231107  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390165 (* 1 = 0.0390165 loss)
I0627 09:44:58.231112  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0373972 (* 1 = 0.0373972 loss)
I0627 09:44:58.231115  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00021149 (* 1 = 0.00021149 loss)
I0627 09:44:58.231119  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00316304 (* 1 = 0.00316304 loss)
I0627 09:44:58.231124  6673 sgd_solver.cpp:106] Iteration 31280, lr = 0.0002
I0627 09:46:36.402868  6673 solver.cpp:228] Iteration 31300, loss = 0.132168
I0627 09:46:36.402895  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:46:36.402902  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.02969 (* 1 = 0.02969 loss)
I0627 09:46:36.402907  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0203068 (* 1 = 0.0203068 loss)
I0627 09:46:36.402910  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00555599 (* 1 = 0.00555599 loss)
I0627 09:46:36.402915  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00679432 (* 1 = 0.00679432 loss)
I0627 09:46:36.402920  6673 sgd_solver.cpp:106] Iteration 31300, lr = 0.0002
I0627 09:48:14.991438  6673 solver.cpp:228] Iteration 31320, loss = 0.0666357
I0627 09:48:14.991472  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:48:14.991479  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0153047 (* 1 = 0.0153047 loss)
I0627 09:48:14.991483  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0195244 (* 1 = 0.0195244 loss)
I0627 09:48:14.991487  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.43898e-05 (* 1 = 5.43898e-05 loss)
I0627 09:48:14.991492  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00491423 (* 1 = 0.00491423 loss)
I0627 09:48:14.991497  6673 sgd_solver.cpp:106] Iteration 31320, lr = 0.0002
I0627 09:49:53.879452  6673 solver.cpp:228] Iteration 31340, loss = 0.146549
I0627 09:49:53.879475  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0627 09:49:53.879482  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.177415 (* 1 = 0.177415 loss)
I0627 09:49:53.879485  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.241143 (* 1 = 0.241143 loss)
I0627 09:49:53.879489  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00142107 (* 1 = 0.00142107 loss)
I0627 09:49:53.879493  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198919 (* 1 = 0.0198919 loss)
I0627 09:49:53.879498  6673 sgd_solver.cpp:106] Iteration 31340, lr = 0.0002
I0627 09:51:32.751358  6673 solver.cpp:228] Iteration 31360, loss = 0.08923
I0627 09:51:32.751384  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 09:51:32.751391  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0195826 (* 1 = 0.0195826 loss)
I0627 09:51:32.751395  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0275062 (* 1 = 0.0275062 loss)
I0627 09:51:32.751399  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000177811 (* 1 = 0.000177811 loss)
I0627 09:51:32.751404  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00697176 (* 1 = 0.00697176 loss)
I0627 09:51:32.751408  6673 sgd_solver.cpp:106] Iteration 31360, lr = 0.0002
I0627 09:53:11.585741  6673 solver.cpp:228] Iteration 31380, loss = 0.0708193
I0627 09:53:11.585767  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 09:53:11.585773  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206593 (* 1 = 0.0206593 loss)
I0627 09:53:11.585777  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0279665 (* 1 = 0.0279665 loss)
I0627 09:53:11.585781  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 3.76935e-05 (* 1 = 3.76935e-05 loss)
I0627 09:53:11.585784  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0039987 (* 1 = 0.0039987 loss)
I0627 09:53:11.585789  6673 sgd_solver.cpp:106] Iteration 31380, lr = 0.0002
speed: 4.920s / iter
I0627 09:54:50.371057  6673 solver.cpp:228] Iteration 31400, loss = 0.0759888
I0627 09:54:50.371085  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 09:54:50.371093  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162402 (* 1 = 0.0162402 loss)
I0627 09:54:50.371098  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0148697 (* 1 = 0.0148697 loss)
I0627 09:54:50.371101  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00491021 (* 1 = 0.00491021 loss)
I0627 09:54:50.371105  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00982024 (* 1 = 0.00982024 loss)
I0627 09:54:50.371110  6673 sgd_solver.cpp:106] Iteration 31400, lr = 0.0002
I0627 09:56:28.982848  6673 solver.cpp:228] Iteration 31420, loss = 0.146937
I0627 09:56:28.982877  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 09:56:28.982883  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0288388 (* 1 = 0.0288388 loss)
I0627 09:56:28.982887  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0105648 (* 1 = 0.0105648 loss)
I0627 09:56:28.982892  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197485 (* 1 = 0.0197485 loss)
I0627 09:56:28.982895  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00243639 (* 1 = 0.00243639 loss)
I0627 09:56:28.982900  6673 sgd_solver.cpp:106] Iteration 31420, lr = 0.0002
I0627 09:58:07.569802  6673 solver.cpp:228] Iteration 31440, loss = 0.216834
I0627 09:58:07.569826  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0627 09:58:07.569835  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0672313 (* 1 = 0.0672313 loss)
I0627 09:58:07.569841  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.190656 (* 1 = 0.190656 loss)
I0627 09:58:07.569847  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00579588 (* 1 = 0.00579588 loss)
I0627 09:58:07.569852  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0296191 (* 1 = 0.0296191 loss)
I0627 09:58:07.569859  6673 sgd_solver.cpp:106] Iteration 31440, lr = 0.0002
I0627 09:59:46.166111  6673 solver.cpp:228] Iteration 31460, loss = 0.122354
I0627 09:59:46.166138  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0627 09:59:46.166146  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599462 (* 1 = 0.0599462 loss)
I0627 09:59:46.166149  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.143014 (* 1 = 0.143014 loss)
I0627 09:59:46.166152  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032145 (* 1 = 0.0032145 loss)
I0627 09:59:46.166157  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0335451 (* 1 = 0.0335451 loss)
I0627 09:59:46.166162  6673 sgd_solver.cpp:106] Iteration 31460, lr = 0.0002
I0627 10:01:24.647236  6673 solver.cpp:228] Iteration 31480, loss = 0.163206
I0627 10:01:24.647261  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0627 10:01:24.647269  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.145334 (* 1 = 0.145334 loss)
I0627 10:01:24.647274  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.206911 (* 1 = 0.206911 loss)
I0627 10:01:24.647276  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00371648 (* 1 = 0.00371648 loss)
I0627 10:01:24.647280  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0592828 (* 1 = 0.0592828 loss)
I0627 10:01:24.647285  6673 sgd_solver.cpp:106] Iteration 31480, lr = 0.0002
I0627 10:03:02.816807  6673 solver.cpp:228] Iteration 31500, loss = 0.0808879
I0627 10:03:02.816831  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:03:02.816838  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0069168 (* 1 = 0.0069168 loss)
I0627 10:03:02.816843  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0157042 (* 1 = 0.0157042 loss)
I0627 10:03:02.816846  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347257 (* 1 = 0.00347257 loss)
I0627 10:03:02.816849  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0059572 (* 1 = 0.0059572 loss)
I0627 10:03:02.816855  6673 sgd_solver.cpp:106] Iteration 31500, lr = 0.0002
I0627 10:04:41.062914  6673 solver.cpp:228] Iteration 31520, loss = 0.170665
I0627 10:04:41.062950  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:04:41.062963  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216458 (* 1 = 0.0216458 loss)
I0627 10:04:41.062968  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0199441 (* 1 = 0.0199441 loss)
I0627 10:04:41.062974  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.001825 (* 1 = 0.001825 loss)
I0627 10:04:41.062981  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00254102 (* 1 = 0.00254102 loss)
I0627 10:04:41.062989  6673 sgd_solver.cpp:106] Iteration 31520, lr = 0.0002
I0627 10:06:19.276844  6673 solver.cpp:228] Iteration 31540, loss = 0.189174
I0627 10:06:19.276870  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:06:19.276880  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00085207 (* 1 = 0.00085207 loss)
I0627 10:06:19.276885  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0128716 (* 1 = 0.0128716 loss)
I0627 10:06:19.276890  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0307999 (* 1 = 0.0307999 loss)
I0627 10:06:19.276896  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00841487 (* 1 = 0.00841487 loss)
I0627 10:06:19.276902  6673 sgd_solver.cpp:106] Iteration 31540, lr = 0.0002
I0627 10:07:57.360785  6673 solver.cpp:228] Iteration 31560, loss = 0.0450829
I0627 10:07:57.360810  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:07:57.360817  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226112 (* 1 = 0.0226112 loss)
I0627 10:07:57.360821  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0240016 (* 1 = 0.0240016 loss)
I0627 10:07:57.360826  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000165571 (* 1 = 0.000165571 loss)
I0627 10:07:57.360829  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00475549 (* 1 = 0.00475549 loss)
I0627 10:07:57.360834  6673 sgd_solver.cpp:106] Iteration 31560, lr = 0.0002
I0627 10:09:35.471213  6673 solver.cpp:228] Iteration 31580, loss = 0.118289
I0627 10:09:35.471240  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:09:35.471248  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188893 (* 1 = 0.0188893 loss)
I0627 10:09:35.471252  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0274083 (* 1 = 0.0274083 loss)
I0627 10:09:35.471257  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000181728 (* 1 = 0.000181728 loss)
I0627 10:09:35.471261  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512089 (* 1 = 0.00512089 loss)
I0627 10:09:35.471266  6673 sgd_solver.cpp:106] Iteration 31580, lr = 0.0002
speed: 4.920s / iter
I0627 10:11:13.473577  6673 solver.cpp:228] Iteration 31600, loss = 0.127753
I0627 10:11:13.473600  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:11:13.473608  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890585 (* 1 = 0.0890585 loss)
I0627 10:11:13.473611  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.063104 (* 1 = 0.063104 loss)
I0627 10:11:13.473614  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00618539 (* 1 = 0.00618539 loss)
I0627 10:11:13.473618  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194686 (* 1 = 0.0194686 loss)
I0627 10:11:13.473623  6673 sgd_solver.cpp:106] Iteration 31600, lr = 0.0002
I0627 10:12:51.482888  6673 solver.cpp:228] Iteration 31620, loss = 0.182888
I0627 10:12:51.482911  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0627 10:12:51.482918  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0141096 (* 1 = 0.0141096 loss)
I0627 10:12:51.482921  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0341403 (* 1 = 0.0341403 loss)
I0627 10:12:51.482925  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00148424 (* 1 = 0.00148424 loss)
I0627 10:12:51.482929  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131651 (* 1 = 0.0131651 loss)
I0627 10:12:51.482934  6673 sgd_solver.cpp:106] Iteration 31620, lr = 0.0002
I0627 10:14:29.491922  6673 solver.cpp:228] Iteration 31640, loss = 0.109517
I0627 10:14:29.491945  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:14:29.491951  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0194575 (* 1 = 0.0194575 loss)
I0627 10:14:29.491957  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0282727 (* 1 = 0.0282727 loss)
I0627 10:14:29.491963  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000199433 (* 1 = 0.000199433 loss)
I0627 10:14:29.491968  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00510201 (* 1 = 0.00510201 loss)
I0627 10:14:29.491973  6673 sgd_solver.cpp:106] Iteration 31640, lr = 0.0002
I0627 10:16:07.478291  6673 solver.cpp:228] Iteration 31660, loss = 0.102453
I0627 10:16:07.478315  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 10:16:07.478323  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.065197 (* 1 = 0.065197 loss)
I0627 10:16:07.478327  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.100672 (* 1 = 0.100672 loss)
I0627 10:16:07.478332  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00568459 (* 1 = 0.00568459 loss)
I0627 10:16:07.478335  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0384166 (* 1 = 0.0384166 loss)
I0627 10:16:07.478340  6673 sgd_solver.cpp:106] Iteration 31660, lr = 0.0002
I0627 10:17:45.461225  6673 solver.cpp:228] Iteration 31680, loss = 0.11978
I0627 10:17:45.461251  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 10:17:45.461259  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305677 (* 1 = 0.0305677 loss)
I0627 10:17:45.461266  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.101986 (* 1 = 0.101986 loss)
I0627 10:17:45.461272  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000281523 (* 1 = 0.000281523 loss)
I0627 10:17:45.461277  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135382 (* 1 = 0.0135382 loss)
I0627 10:17:45.461282  6673 sgd_solver.cpp:106] Iteration 31680, lr = 0.0002
I0627 10:19:23.490926  6673 solver.cpp:228] Iteration 31700, loss = 0.161713
I0627 10:19:23.490960  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:19:23.490972  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.015598 (* 1 = 0.015598 loss)
I0627 10:19:23.490978  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0269674 (* 1 = 0.0269674 loss)
I0627 10:19:23.490983  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000131411 (* 1 = 0.000131411 loss)
I0627 10:19:23.490989  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00379138 (* 1 = 0.00379138 loss)
I0627 10:19:23.490998  6673 sgd_solver.cpp:106] Iteration 31700, lr = 0.0002
I0627 10:21:01.565654  6673 solver.cpp:228] Iteration 31720, loss = 0.0852368
I0627 10:21:01.565682  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:21:01.565690  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0170076 (* 1 = 0.0170076 loss)
I0627 10:21:01.565696  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.033851 (* 1 = 0.033851 loss)
I0627 10:21:01.565702  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 1.76706e-05 (* 1 = 1.76706e-05 loss)
I0627 10:21:01.565708  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00495485 (* 1 = 0.00495485 loss)
I0627 10:21:01.565714  6673 sgd_solver.cpp:106] Iteration 31720, lr = 0.0002
I0627 10:22:39.606715  6673 solver.cpp:228] Iteration 31740, loss = 0.129864
I0627 10:22:39.606742  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 10:22:39.606750  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467522 (* 1 = 0.0467522 loss)
I0627 10:22:39.606753  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0973002 (* 1 = 0.0973002 loss)
I0627 10:22:39.606757  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000207874 (* 1 = 0.000207874 loss)
I0627 10:22:39.606761  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100166 (* 1 = 0.0100166 loss)
I0627 10:22:39.606766  6673 sgd_solver.cpp:106] Iteration 31740, lr = 0.0002
I0627 10:24:17.639358  6673 solver.cpp:228] Iteration 31760, loss = 0.134733
I0627 10:24:17.639382  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0627 10:24:17.639389  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.200304 (* 1 = 0.200304 loss)
I0627 10:24:17.639394  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.304661 (* 1 = 0.304661 loss)
I0627 10:24:17.639397  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00174735 (* 1 = 0.00174735 loss)
I0627 10:24:17.639402  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372997 (* 1 = 0.0372997 loss)
I0627 10:24:17.639407  6673 sgd_solver.cpp:106] Iteration 31760, lr = 0.0002
I0627 10:25:55.662133  6673 solver.cpp:228] Iteration 31780, loss = 0.0997672
I0627 10:25:55.662160  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 10:25:55.662170  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363949 (* 1 = 0.0363949 loss)
I0627 10:25:55.662178  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0683909 (* 1 = 0.0683909 loss)
I0627 10:25:55.662183  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000392909 (* 1 = 0.000392909 loss)
I0627 10:25:55.662189  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017352 (* 1 = 0.017352 loss)
I0627 10:25:55.662197  6673 sgd_solver.cpp:106] Iteration 31780, lr = 0.0002
speed: 4.920s / iter
I0627 10:27:33.732072  6673 solver.cpp:228] Iteration 31800, loss = 0.169095
I0627 10:27:33.732097  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:27:33.732105  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00696368 (* 1 = 0.00696368 loss)
I0627 10:27:33.732108  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00491493 (* 1 = 0.00491493 loss)
I0627 10:27:33.732111  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 4.09355e-05 (* 1 = 4.09355e-05 loss)
I0627 10:27:33.732115  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00743149 (* 1 = 0.00743149 loss)
I0627 10:27:33.732120  6673 sgd_solver.cpp:106] Iteration 31800, lr = 0.0002
I0627 10:29:11.812700  6673 solver.cpp:228] Iteration 31820, loss = 0.127292
I0627 10:29:11.812724  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:29:11.812731  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197412 (* 1 = 0.0197412 loss)
I0627 10:29:11.812734  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.00684984 (* 1 = 0.00684984 loss)
I0627 10:29:11.812738  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000738531 (* 1 = 0.000738531 loss)
I0627 10:29:11.812741  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00359083 (* 1 = 0.00359083 loss)
I0627 10:29:11.812747  6673 sgd_solver.cpp:106] Iteration 31820, lr = 0.0002
I0627 10:30:49.995764  6673 solver.cpp:228] Iteration 31840, loss = 0.102665
I0627 10:30:49.995791  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:30:49.995800  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0266207 (* 1 = 0.0266207 loss)
I0627 10:30:49.995805  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0162859 (* 1 = 0.0162859 loss)
I0627 10:30:49.995808  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00292841 (* 1 = 0.00292841 loss)
I0627 10:30:49.995812  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163174 (* 1 = 0.0163174 loss)
I0627 10:30:49.995817  6673 sgd_solver.cpp:106] Iteration 31840, lr = 0.0002
I0627 10:32:28.137336  6673 solver.cpp:228] Iteration 31860, loss = 0.102763
I0627 10:32:28.137367  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:32:28.137374  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00653498 (* 1 = 0.00653498 loss)
I0627 10:32:28.137379  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0306016 (* 1 = 0.0306016 loss)
I0627 10:32:28.137383  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000771281 (* 1 = 0.000771281 loss)
I0627 10:32:28.137387  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00286635 (* 1 = 0.00286635 loss)
I0627 10:32:28.137393  6673 sgd_solver.cpp:106] Iteration 31860, lr = 0.0002
I0627 10:34:06.407073  6673 solver.cpp:228] Iteration 31880, loss = 0.119079
I0627 10:34:06.407097  6673 solver.cpp:244]     Train net output #0: accuarcy = 1
I0627 10:34:06.407104  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0101188 (* 1 = 0.0101188 loss)
I0627 10:34:06.407109  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.010938 (* 1 = 0.010938 loss)
I0627 10:34:06.407112  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000236952 (* 1 = 0.000236952 loss)
I0627 10:34:06.407115  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0042993 (* 1 = 0.0042993 loss)
I0627 10:34:06.407119  6673 sgd_solver.cpp:106] Iteration 31880, lr = 0.0002
I0627 10:35:44.642668  6673 solver.cpp:228] Iteration 31900, loss = 0.123658
I0627 10:35:44.642695  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:35:44.642705  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.00593708 (* 1 = 0.00593708 loss)
I0627 10:35:44.642711  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0230344 (* 1 = 0.0230344 loss)
I0627 10:35:44.642719  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000426548 (* 1 = 0.000426548 loss)
I0627 10:35:44.642725  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00311428 (* 1 = 0.00311428 loss)
I0627 10:35:44.642732  6673 sgd_solver.cpp:106] Iteration 31900, lr = 0.0002
I0627 10:37:23.336685  6673 solver.cpp:228] Iteration 31920, loss = 0.100725
I0627 10:37:23.336709  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0627 10:37:23.336716  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0111524 (* 1 = 0.0111524 loss)
I0627 10:37:23.336720  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0180723 (* 1 = 0.0180723 loss)
I0627 10:37:23.336724  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.33312e-05 (* 1 = 7.33312e-05 loss)
I0627 10:37:23.336727  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.000278285 (* 1 = 0.000278285 loss)
I0627 10:37:23.336731  6673 sgd_solver.cpp:106] Iteration 31920, lr = 0.0002
I0627 10:39:02.465872  6673 solver.cpp:228] Iteration 31940, loss = 0.122604
I0627 10:39:02.465895  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0627 10:39:02.465903  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186116 (* 1 = 0.0186116 loss)
I0627 10:39:02.465906  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0248351 (* 1 = 0.0248351 loss)
I0627 10:39:02.465910  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 1.75978e-05 (* 1 = 1.75978e-05 loss)
I0627 10:39:02.465914  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00533739 (* 1 = 0.00533739 loss)
I0627 10:39:02.465919  6673 sgd_solver.cpp:106] Iteration 31940, lr = 0.0002
I0627 10:40:41.701256  6673 solver.cpp:228] Iteration 31960, loss = 0.0668014
I0627 10:40:41.701288  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0627 10:40:41.701297  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327429 (* 1 = 0.0327429 loss)
I0627 10:40:41.701300  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0838322 (* 1 = 0.0838322 loss)
I0627 10:40:41.701304  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 5.37897e-05 (* 1 = 5.37897e-05 loss)
I0627 10:40:41.701308  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143222 (* 1 = 0.0143222 loss)
I0627 10:40:41.701314  6673 sgd_solver.cpp:106] Iteration 31960, lr = 0.0002
I0627 10:42:20.923669  6673 solver.cpp:228] Iteration 31980, loss = 0.12401
I0627 10:42:20.923693  6673 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0627 10:42:20.923701  6673 solver.cpp:244]     Train net output #1: loss_bbox = 0.0466892 (* 1 = 0.0466892 loss)
I0627 10:42:20.923704  6673 solver.cpp:244]     Train net output #2: loss_cls = 0.0620031 (* 1 = 0.0620031 loss)
I0627 10:42:20.923708  6673 solver.cpp:244]     Train net output #3: rpn_cls_loss = 7.98722e-05 (* 1 = 7.98722e-05 loss)
I0627 10:42:20.923712  6673 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00595977 (* 1 = 0.00595977 loss)
I0627 10:42:20.923717  6673 sgd_solver.cpp:106] Iteration 31980, lr = 0.0002
speed: 4.920s / iter
I0627 10:43:55.456634  6673 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_32000.caffemodel
done solving

real	2624m16.414s
user	2212m26.772s
sys	434m43.444s
+ set +x
+ ./tools/test_net.py --gpu 1 --def experiments/6_25_upper/test_agnostic.prototxt --net /home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_32000.caffemodel --imdb voc_0712_test --cfg experiments/6_25_upper/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='/home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_32000.caffemodel', cfg_file='experiments/6_25_upper/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=1, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/6_25_upper/test_agnostic.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '6_25_upper/model',
 'GPU_ID': 1,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [960],
          'SOFT_NMS': 0,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [960],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0627 10:43:57.661554 23737 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0627 10:43:57.661576 23737 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0627 10:43:57.661578 23737 _caffe.cpp:125] Net('experiments/6_25_upper/test_agnostic.prototxt', 1, weights='/home/user/Disk1.8T/py-R-FCN/experiments/6_25_upper/model/resnet50_rfcn_ohem_iter_32000.caffemodel')
I0627 10:43:57.678083 23737 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/6_25_upper/test_agnostic.prototxt
I0627 10:43:57.678272 23737 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0627 10:43:57.678275 23737 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0627 10:43:57.679461 23737 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "r
I0627 10:43:57.681076 23737 layer_factory.hpp:77] Creating layer input
I0627 10:43:57.681103 23737 net.cpp:100] Creating Layer input
I0627 10:43:57.681110 23737 net.cpp:418] input -> data
I0627 10:43:57.681144 23737 net.cpp:418] input -> im_info
I0627 10:43:57.702451 23737 net.cpp:150] Setting up input
I0627 10:43:57.702483 23737 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0627 10:43:57.702488 23737 net.cpp:157] Top shape: 1 3 (3)
I0627 10:43:57.702491 23737 net.cpp:165] Memory required for data: 602124
I0627 10:43:57.702512 23737 layer_factory.hpp:77] Creating layer conv1
I0627 10:43:57.702564 23737 net.cpp:100] Creating Layer conv1
I0627 10:43:57.702576 23737 net.cpp:444] conv1 <- data
I0627 10:43:57.702596 23737 net.cpp:418] conv1 -> conv1
I0627 10:43:58.005234 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 225816
I0627 10:43:58.005538 23737 net.cpp:150] Setting up conv1
I0627 10:43:58.005560 23737 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:43:58.005563 23737 net.cpp:165] Memory required for data: 3813388
I0627 10:43:58.005612 23737 layer_factory.hpp:77] Creating layer bn_conv1
I0627 10:43:58.005647 23737 net.cpp:100] Creating Layer bn_conv1
I0627 10:43:58.005659 23737 net.cpp:444] bn_conv1 <- conv1
I0627 10:43:58.005674 23737 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0627 10:43:58.005955 23737 net.cpp:150] Setting up bn_conv1
I0627 10:43:58.005964 23737 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:43:58.005965 23737 net.cpp:165] Memory required for data: 7024652
I0627 10:43:58.005993 23737 layer_factory.hpp:77] Creating layer scale_conv1
I0627 10:43:58.006011 23737 net.cpp:100] Creating Layer scale_conv1
I0627 10:43:58.006017 23737 net.cpp:444] scale_conv1 <- conv1
I0627 10:43:58.006031 23737 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0627 10:43:58.006096 23737 layer_factory.hpp:77] Creating layer scale_conv1
I0627 10:43:58.006299 23737 net.cpp:150] Setting up scale_conv1
I0627 10:43:58.006307 23737 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:43:58.006310 23737 net.cpp:165] Memory required for data: 10235916
I0627 10:43:58.006320 23737 layer_factory.hpp:77] Creating layer conv1_relu
I0627 10:43:58.006336 23737 net.cpp:100] Creating Layer conv1_relu
I0627 10:43:58.006342 23737 net.cpp:444] conv1_relu <- conv1
I0627 10:43:58.006355 23737 net.cpp:405] conv1_relu -> conv1 (in-place)
I0627 10:43:58.006508 23737 net.cpp:150] Setting up conv1_relu
I0627 10:43:58.006515 23737 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0627 10:43:58.006518 23737 net.cpp:165] Memory required for data: 13447180
I0627 10:43:58.006522 23737 layer_factory.hpp:77] Creating layer pool1
I0627 10:43:58.006536 23737 net.cpp:100] Creating Layer pool1
I0627 10:43:58.006541 23737 net.cpp:444] pool1 <- conv1
I0627 10:43:58.006556 23737 net.cpp:418] pool1 -> pool1
I0627 10:43:58.006618 23737 net.cpp:150] Setting up pool1
I0627 10:43:58.006626 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.006629 23737 net.cpp:165] Memory required for data: 14249996
I0627 10:43:58.006633 23737 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0627 10:43:58.006644 23737 net.cpp:100] Creating Layer pool1_pool1_0_split
I0627 10:43:58.006649 23737 net.cpp:444] pool1_pool1_0_split <- pool1
I0627 10:43:58.006660 23737 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0627 10:43:58.006678 23737 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0627 10:43:58.006729 23737 net.cpp:150] Setting up pool1_pool1_0_split
I0627 10:43:58.006738 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.006742 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.006745 23737 net.cpp:165] Memory required for data: 15855628
I0627 10:43:58.006748 23737 layer_factory.hpp:77] Creating layer res2a_branch1
I0627 10:43:58.006765 23737 net.cpp:100] Creating Layer res2a_branch1
I0627 10:43:58.006772 23737 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0627 10:43:58.006785 23737 net.cpp:418] res2a_branch1 -> res2a_branch1
I0627 10:43:58.007781 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.007798 23737 net.cpp:150] Setting up res2a_branch1
I0627 10:43:58.007807 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.007810 23737 net.cpp:165] Memory required for data: 19066892
I0627 10:43:58.007820 23737 layer_factory.hpp:77] Creating layer bn2a_branch1
I0627 10:43:58.007839 23737 net.cpp:100] Creating Layer bn2a_branch1
I0627 10:43:58.007846 23737 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0627 10:43:58.007859 23737 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0627 10:43:58.008867 23737 net.cpp:150] Setting up bn2a_branch1
I0627 10:43:58.008877 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.008879 23737 net.cpp:165] Memory required for data: 22278156
I0627 10:43:58.008908 23737 layer_factory.hpp:77] Creating layer scale2a_branch1
I0627 10:43:58.008926 23737 net.cpp:100] Creating Layer scale2a_branch1
I0627 10:43:58.008934 23737 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0627 10:43:58.008945 23737 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0627 10:43:58.009011 23737 layer_factory.hpp:77] Creating layer scale2a_branch1
I0627 10:43:58.009182 23737 net.cpp:150] Setting up scale2a_branch1
I0627 10:43:58.009191 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.009193 23737 net.cpp:165] Memory required for data: 25489420
I0627 10:43:58.009204 23737 layer_factory.hpp:77] Creating layer res2a_branch2a
I0627 10:43:58.009220 23737 net.cpp:100] Creating Layer res2a_branch2a
I0627 10:43:58.009227 23737 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0627 10:43:58.009241 23737 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0627 10:43:58.010218 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.010236 23737 net.cpp:150] Setting up res2a_branch2a
I0627 10:43:58.010244 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.010247 23737 net.cpp:165] Memory required for data: 26292236
I0627 10:43:58.010258 23737 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0627 10:43:58.010272 23737 net.cpp:100] Creating Layer bn2a_branch2a
I0627 10:43:58.010278 23737 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0627 10:43:58.010293 23737 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0627 10:43:58.010552 23737 net.cpp:150] Setting up bn2a_branch2a
I0627 10:43:58.010560 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.010562 23737 net.cpp:165] Memory required for data: 27095052
I0627 10:43:58.010588 23737 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0627 10:43:58.010603 23737 net.cpp:100] Creating Layer scale2a_branch2a
I0627 10:43:58.010609 23737 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0627 10:43:58.010622 23737 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0627 10:43:58.010687 23737 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0627 10:43:58.010870 23737 net.cpp:150] Setting up scale2a_branch2a
I0627 10:43:58.010886 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.010890 23737 net.cpp:165] Memory required for data: 27897868
I0627 10:43:58.010900 23737 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0627 10:43:58.010911 23737 net.cpp:100] Creating Layer res2a_branch2a_relu
I0627 10:43:58.010917 23737 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0627 10:43:58.010928 23737 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0627 10:43:58.011080 23737 net.cpp:150] Setting up res2a_branch2a_relu
I0627 10:43:58.011087 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.011091 23737 net.cpp:165] Memory required for data: 28700684
I0627 10:43:58.011096 23737 layer_factory.hpp:77] Creating layer res2a_branch2b
I0627 10:43:58.011109 23737 net.cpp:100] Creating Layer res2a_branch2b
I0627 10:43:58.011116 23737 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0627 10:43:58.011132 23737 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0627 10:43:58.012974 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0627 10:43:58.013250 23737 net.cpp:150] Setting up res2a_branch2b
I0627 10:43:58.013264 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.013268 23737 net.cpp:165] Memory required for data: 29503500
I0627 10:43:58.013281 23737 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0627 10:43:58.013299 23737 net.cpp:100] Creating Layer bn2a_branch2b
I0627 10:43:58.013305 23737 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0627 10:43:58.013320 23737 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0627 10:43:58.013597 23737 net.cpp:150] Setting up bn2a_branch2b
I0627 10:43:58.013603 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.013607 23737 net.cpp:165] Memory required for data: 30306316
I0627 10:43:58.013623 23737 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0627 10:43:58.013645 23737 net.cpp:100] Creating Layer scale2a_branch2b
I0627 10:43:58.013650 23737 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0627 10:43:58.013662 23737 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0627 10:43:58.013727 23737 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0627 10:43:58.013911 23737 net.cpp:150] Setting up scale2a_branch2b
I0627 10:43:58.013918 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.013921 23737 net.cpp:165] Memory required for data: 31109132
I0627 10:43:58.013932 23737 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0627 10:43:58.013943 23737 net.cpp:100] Creating Layer res2a_branch2b_relu
I0627 10:43:58.013948 23737 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0627 10:43:58.013962 23737 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0627 10:43:58.014380 23737 net.cpp:150] Setting up res2a_branch2b_relu
I0627 10:43:58.014389 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.014392 23737 net.cpp:165] Memory required for data: 31911948
I0627 10:43:58.014397 23737 layer_factory.hpp:77] Creating layer res2a_branch2c
I0627 10:43:58.014415 23737 net.cpp:100] Creating Layer res2a_branch2c
I0627 10:43:58.014421 23737 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0627 10:43:58.014437 23737 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0627 10:43:58.015475 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.015494 23737 net.cpp:150] Setting up res2a_branch2c
I0627 10:43:58.015503 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.015506 23737 net.cpp:165] Memory required for data: 35123212
I0627 10:43:58.015517 23737 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0627 10:43:58.015534 23737 net.cpp:100] Creating Layer bn2a_branch2c
I0627 10:43:58.015542 23737 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0627 10:43:58.015555 23737 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0627 10:43:58.015817 23737 net.cpp:150] Setting up bn2a_branch2c
I0627 10:43:58.015825 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.015827 23737 net.cpp:165] Memory required for data: 38334476
I0627 10:43:58.015843 23737 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0627 10:43:58.015858 23737 net.cpp:100] Creating Layer scale2a_branch2c
I0627 10:43:58.015864 23737 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0627 10:43:58.015877 23737 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0627 10:43:58.015941 23737 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0627 10:43:58.016118 23737 net.cpp:150] Setting up scale2a_branch2c
I0627 10:43:58.016125 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.016129 23737 net.cpp:165] Memory required for data: 41545740
I0627 10:43:58.016139 23737 layer_factory.hpp:77] Creating layer res2a
I0627 10:43:58.016150 23737 net.cpp:100] Creating Layer res2a
I0627 10:43:58.016156 23737 net.cpp:444] res2a <- res2a_branch1
I0627 10:43:58.016165 23737 net.cpp:444] res2a <- res2a_branch2c
I0627 10:43:58.016175 23737 net.cpp:418] res2a -> res2a
I0627 10:43:58.016216 23737 net.cpp:150] Setting up res2a
I0627 10:43:58.016224 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.016227 23737 net.cpp:165] Memory required for data: 44757004
I0627 10:43:58.016232 23737 layer_factory.hpp:77] Creating layer res2a_relu
I0627 10:43:58.016242 23737 net.cpp:100] Creating Layer res2a_relu
I0627 10:43:58.016247 23737 net.cpp:444] res2a_relu <- res2a
I0627 10:43:58.016258 23737 net.cpp:405] res2a_relu -> res2a (in-place)
I0627 10:43:58.016413 23737 net.cpp:150] Setting up res2a_relu
I0627 10:43:58.016422 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.016427 23737 net.cpp:165] Memory required for data: 47968268
I0627 10:43:58.016432 23737 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0627 10:43:58.016445 23737 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0627 10:43:58.016453 23737 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0627 10:43:58.016471 23737 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0627 10:43:58.016491 23737 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0627 10:43:58.016568 23737 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0627 10:43:58.016579 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.016597 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.016600 23737 net.cpp:165] Memory required for data: 54390796
I0627 10:43:58.016607 23737 layer_factory.hpp:77] Creating layer res2b_branch2a
I0627 10:43:58.016626 23737 net.cpp:100] Creating Layer res2b_branch2a
I0627 10:43:58.016633 23737 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0627 10:43:58.016652 23737 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0627 10:43:58.017699 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.017720 23737 net.cpp:150] Setting up res2b_branch2a
I0627 10:43:58.017731 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.017735 23737 net.cpp:165] Memory required for data: 55193612
I0627 10:43:58.017750 23737 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0627 10:43:58.017768 23737 net.cpp:100] Creating Layer bn2b_branch2a
I0627 10:43:58.017776 23737 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0627 10:43:58.017794 23737 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0627 10:43:58.018069 23737 net.cpp:150] Setting up bn2b_branch2a
I0627 10:43:58.018077 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.018081 23737 net.cpp:165] Memory required for data: 55996428
I0627 10:43:58.018116 23737 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0627 10:43:58.018136 23737 net.cpp:100] Creating Layer scale2b_branch2a
I0627 10:43:58.018143 23737 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0627 10:43:58.018160 23737 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0627 10:43:58.018232 23737 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0627 10:43:58.018424 23737 net.cpp:150] Setting up scale2b_branch2a
I0627 10:43:58.018432 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.018436 23737 net.cpp:165] Memory required for data: 56799244
I0627 10:43:58.018451 23737 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0627 10:43:58.018465 23737 net.cpp:100] Creating Layer res2b_branch2a_relu
I0627 10:43:58.018472 23737 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0627 10:43:58.018488 23737 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0627 10:43:58.018656 23737 net.cpp:150] Setting up res2b_branch2a_relu
I0627 10:43:58.018664 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.018668 23737 net.cpp:165] Memory required for data: 57602060
I0627 10:43:58.018674 23737 layer_factory.hpp:77] Creating layer res2b_branch2b
I0627 10:43:58.018693 23737 net.cpp:100] Creating Layer res2b_branch2b
I0627 10:43:58.018700 23737 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0627 10:43:58.018720 23737 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0627 10:43:58.019852 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0627 10:43:58.019873 23737 net.cpp:150] Setting up res2b_branch2b
I0627 10:43:58.019884 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.019888 23737 net.cpp:165] Memory required for data: 58404876
I0627 10:43:58.019902 23737 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0627 10:43:58.019920 23737 net.cpp:100] Creating Layer bn2b_branch2b
I0627 10:43:58.019928 23737 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0627 10:43:58.019946 23737 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0627 10:43:58.020226 23737 net.cpp:150] Setting up bn2b_branch2b
I0627 10:43:58.020233 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.020237 23737 net.cpp:165] Memory required for data: 59207692
I0627 10:43:58.020258 23737 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0627 10:43:58.020277 23737 net.cpp:100] Creating Layer scale2b_branch2b
I0627 10:43:58.020284 23737 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0627 10:43:58.020300 23737 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0627 10:43:58.020371 23737 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0627 10:43:58.020576 23737 net.cpp:150] Setting up scale2b_branch2b
I0627 10:43:58.020584 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.020588 23737 net.cpp:165] Memory required for data: 60010508
I0627 10:43:58.020602 23737 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0627 10:43:58.020619 23737 net.cpp:100] Creating Layer res2b_branch2b_relu
I0627 10:43:58.020627 23737 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0627 10:43:58.020642 23737 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0627 10:43:58.021235 23737 net.cpp:150] Setting up res2b_branch2b_relu
I0627 10:43:58.021248 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.021253 23737 net.cpp:165] Memory required for data: 60813324
I0627 10:43:58.021260 23737 layer_factory.hpp:77] Creating layer res2b_branch2c
I0627 10:43:58.021301 23737 net.cpp:100] Creating Layer res2b_branch2c
I0627 10:43:58.021311 23737 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0627 10:43:58.021330 23737 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0627 10:43:58.022459 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.022481 23737 net.cpp:150] Setting up res2b_branch2c
I0627 10:43:58.022495 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.022498 23737 net.cpp:165] Memory required for data: 64024588
I0627 10:43:58.022511 23737 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0627 10:43:58.022531 23737 net.cpp:100] Creating Layer bn2b_branch2c
I0627 10:43:58.022538 23737 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0627 10:43:58.022557 23737 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0627 10:43:58.022830 23737 net.cpp:150] Setting up bn2b_branch2c
I0627 10:43:58.022838 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.022842 23737 net.cpp:165] Memory required for data: 67235852
I0627 10:43:58.022869 23737 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0627 10:43:58.022891 23737 net.cpp:100] Creating Layer scale2b_branch2c
I0627 10:43:58.022922 23737 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0627 10:43:58.022938 23737 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0627 10:43:58.023007 23737 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0627 10:43:58.023190 23737 net.cpp:150] Setting up scale2b_branch2c
I0627 10:43:58.023200 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.023203 23737 net.cpp:165] Memory required for data: 70447116
I0627 10:43:58.023218 23737 layer_factory.hpp:77] Creating layer res2b
I0627 10:43:58.023236 23737 net.cpp:100] Creating Layer res2b
I0627 10:43:58.023244 23737 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0627 10:43:58.023259 23737 net.cpp:444] res2b <- res2b_branch2c
I0627 10:43:58.023272 23737 net.cpp:418] res2b -> res2b
I0627 10:43:58.023329 23737 net.cpp:150] Setting up res2b
I0627 10:43:58.023341 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.023346 23737 net.cpp:165] Memory required for data: 73658380
I0627 10:43:58.023352 23737 layer_factory.hpp:77] Creating layer res2b_relu
I0627 10:43:58.023365 23737 net.cpp:100] Creating Layer res2b_relu
I0627 10:43:58.023372 23737 net.cpp:444] res2b_relu <- res2b
I0627 10:43:58.023389 23737 net.cpp:405] res2b_relu -> res2b (in-place)
I0627 10:43:58.023566 23737 net.cpp:150] Setting up res2b_relu
I0627 10:43:58.023574 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.023577 23737 net.cpp:165] Memory required for data: 76869644
I0627 10:43:58.023583 23737 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0627 10:43:58.023598 23737 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0627 10:43:58.023605 23737 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0627 10:43:58.023622 23737 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0627 10:43:58.023643 23737 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0627 10:43:58.023706 23737 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0627 10:43:58.023716 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.023725 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.023728 23737 net.cpp:165] Memory required for data: 83292172
I0627 10:43:58.023733 23737 layer_factory.hpp:77] Creating layer res2c_branch2a
I0627 10:43:58.023753 23737 net.cpp:100] Creating Layer res2c_branch2a
I0627 10:43:58.023761 23737 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0627 10:43:58.023779 23737 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0627 10:43:58.027456 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.027480 23737 net.cpp:150] Setting up res2c_branch2a
I0627 10:43:58.027493 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.027498 23737 net.cpp:165] Memory required for data: 84094988
I0627 10:43:58.027514 23737 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0627 10:43:58.027536 23737 net.cpp:100] Creating Layer bn2c_branch2a
I0627 10:43:58.027544 23737 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0627 10:43:58.027565 23737 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0627 10:43:58.027853 23737 net.cpp:150] Setting up bn2c_branch2a
I0627 10:43:58.027861 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.027865 23737 net.cpp:165] Memory required for data: 84897804
I0627 10:43:58.027886 23737 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0627 10:43:58.027904 23737 net.cpp:100] Creating Layer scale2c_branch2a
I0627 10:43:58.027911 23737 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0627 10:43:58.027928 23737 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0627 10:43:58.028000 23737 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0627 10:43:58.028198 23737 net.cpp:150] Setting up scale2c_branch2a
I0627 10:43:58.028206 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.028210 23737 net.cpp:165] Memory required for data: 85700620
I0627 10:43:58.028224 23737 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0627 10:43:58.028237 23737 net.cpp:100] Creating Layer res2c_branch2a_relu
I0627 10:43:58.028244 23737 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0627 10:43:58.028259 23737 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0627 10:43:58.028426 23737 net.cpp:150] Setting up res2c_branch2a_relu
I0627 10:43:58.028434 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.028439 23737 net.cpp:165] Memory required for data: 86503436
I0627 10:43:58.028443 23737 layer_factory.hpp:77] Creating layer res2c_branch2b
I0627 10:43:58.028463 23737 net.cpp:100] Creating Layer res2c_branch2b
I0627 10:43:58.028470 23737 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0627 10:43:58.028488 23737 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0627 10:43:58.029592 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0627 10:43:58.029878 23737 net.cpp:150] Setting up res2c_branch2b
I0627 10:43:58.029893 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.029898 23737 net.cpp:165] Memory required for data: 87306252
I0627 10:43:58.029913 23737 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0627 10:43:58.029929 23737 net.cpp:100] Creating Layer bn2c_branch2b
I0627 10:43:58.029937 23737 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0627 10:43:58.029955 23737 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0627 10:43:58.030242 23737 net.cpp:150] Setting up bn2c_branch2b
I0627 10:43:58.030251 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.030254 23737 net.cpp:165] Memory required for data: 88109068
I0627 10:43:58.030274 23737 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0627 10:43:58.030292 23737 net.cpp:100] Creating Layer scale2c_branch2b
I0627 10:43:58.030300 23737 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0627 10:43:58.030316 23737 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0627 10:43:58.030390 23737 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0627 10:43:58.030582 23737 net.cpp:150] Setting up scale2c_branch2b
I0627 10:43:58.030591 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.030596 23737 net.cpp:165] Memory required for data: 88911884
I0627 10:43:58.030609 23737 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0627 10:43:58.030623 23737 net.cpp:100] Creating Layer res2c_branch2b_relu
I0627 10:43:58.030630 23737 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0627 10:43:58.030644 23737 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0627 10:43:58.030810 23737 net.cpp:150] Setting up res2c_branch2b_relu
I0627 10:43:58.030819 23737 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0627 10:43:58.030823 23737 net.cpp:165] Memory required for data: 89714700
I0627 10:43:58.030829 23737 layer_factory.hpp:77] Creating layer res2c_branch2c
I0627 10:43:58.030848 23737 net.cpp:100] Creating Layer res2c_branch2c
I0627 10:43:58.030856 23737 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0627 10:43:58.030901 23737 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0627 10:43:58.031935 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0627 10:43:58.031955 23737 net.cpp:150] Setting up res2c_branch2c
I0627 10:43:58.031967 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.031972 23737 net.cpp:165] Memory required for data: 92925964
I0627 10:43:58.031985 23737 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0627 10:43:58.032002 23737 net.cpp:100] Creating Layer bn2c_branch2c
I0627 10:43:58.032011 23737 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0627 10:43:58.032029 23737 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0627 10:43:58.032301 23737 net.cpp:150] Setting up bn2c_branch2c
I0627 10:43:58.032310 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.032315 23737 net.cpp:165] Memory required for data: 96137228
I0627 10:43:58.032356 23737 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0627 10:43:58.032374 23737 net.cpp:100] Creating Layer scale2c_branch2c
I0627 10:43:58.032382 23737 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0627 10:43:58.032397 23737 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0627 10:43:58.032469 23737 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0627 10:43:58.032654 23737 net.cpp:150] Setting up scale2c_branch2c
I0627 10:43:58.032662 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.032666 23737 net.cpp:165] Memory required for data: 99348492
I0627 10:43:58.032680 23737 layer_factory.hpp:77] Creating layer res2c
I0627 10:43:58.032696 23737 net.cpp:100] Creating Layer res2c
I0627 10:43:58.032703 23737 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0627 10:43:58.032716 23737 net.cpp:444] res2c <- res2c_branch2c
I0627 10:43:58.032729 23737 net.cpp:418] res2c -> res2c
I0627 10:43:58.032776 23737 net.cpp:150] Setting up res2c
I0627 10:43:58.032788 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.032791 23737 net.cpp:165] Memory required for data: 102559756
I0627 10:43:58.032797 23737 layer_factory.hpp:77] Creating layer res2c_relu
I0627 10:43:58.032809 23737 net.cpp:100] Creating Layer res2c_relu
I0627 10:43:58.032816 23737 net.cpp:444] res2c_relu <- res2c
I0627 10:43:58.032830 23737 net.cpp:405] res2c_relu -> res2c (in-place)
I0627 10:43:58.033280 23737 net.cpp:150] Setting up res2c_relu
I0627 10:43:58.033290 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.033294 23737 net.cpp:165] Memory required for data: 105771020
I0627 10:43:58.033301 23737 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0627 10:43:58.033315 23737 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0627 10:43:58.033323 23737 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0627 10:43:58.033340 23737 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0627 10:43:58.033360 23737 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0627 10:43:58.033424 23737 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0627 10:43:58.033435 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.033442 23737 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0627 10:43:58.033447 23737 net.cpp:165] Memory required for data: 112193548
I0627 10:43:58.033452 23737 layer_factory.hpp:77] Creating layer res3a_branch1
I0627 10:43:58.033471 23737 net.cpp:100] Creating Layer res3a_branch1
I0627 10:43:58.033478 23737 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0627 10:43:58.033499 23737 net.cpp:418] res3a_branch1 -> res3a_branch1
I0627 10:43:58.035532 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0627 10:43:58.035822 23737 net.cpp:150] Setting up res3a_branch1
I0627 10:43:58.035835 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.035841 23737 net.cpp:165] Memory required for data: 113799180
I0627 10:43:58.035857 23737 layer_factory.hpp:77] Creating layer bn3a_branch1
I0627 10:43:58.035878 23737 net.cpp:100] Creating Layer bn3a_branch1
I0627 10:43:58.035887 23737 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0627 10:43:58.035908 23737 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0627 10:43:58.037055 23737 net.cpp:150] Setting up bn3a_branch1
I0627 10:43:58.037070 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.037073 23737 net.cpp:165] Memory required for data: 115404812
I0627 10:43:58.037101 23737 layer_factory.hpp:77] Creating layer scale3a_branch1
I0627 10:43:58.037128 23737 net.cpp:100] Creating Layer scale3a_branch1
I0627 10:43:58.037138 23737 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0627 10:43:58.037158 23737 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0627 10:43:58.037241 23737 layer_factory.hpp:77] Creating layer scale3a_branch1
I0627 10:43:58.037425 23737 net.cpp:150] Setting up scale3a_branch1
I0627 10:43:58.037433 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.037436 23737 net.cpp:165] Memory required for data: 117010444
I0627 10:43:58.037451 23737 layer_factory.hpp:77] Creating layer res3a_branch2a
I0627 10:43:58.037473 23737 net.cpp:100] Creating Layer res3a_branch2a
I0627 10:43:58.037482 23737 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0627 10:43:58.037503 23737 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0627 10:43:58.038669 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0627 10:43:58.038697 23737 net.cpp:150] Setting up res3a_branch2a
I0627 10:43:58.038708 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.038713 23737 net.cpp:165] Memory required for data: 117411852
I0627 10:43:58.038727 23737 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0627 10:43:58.038745 23737 net.cpp:100] Creating Layer bn3a_branch2a
I0627 10:43:58.038753 23737 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0627 10:43:58.038771 23737 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0627 10:43:58.039080 23737 net.cpp:150] Setting up bn3a_branch2a
I0627 10:43:58.039090 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.039094 23737 net.cpp:165] Memory required for data: 117813260
I0627 10:43:58.039116 23737 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0627 10:43:58.039134 23737 net.cpp:100] Creating Layer scale3a_branch2a
I0627 10:43:58.039142 23737 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0627 10:43:58.039160 23737 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0627 10:43:58.039230 23737 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0627 10:43:58.039409 23737 net.cpp:150] Setting up scale3a_branch2a
I0627 10:43:58.039418 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.039422 23737 net.cpp:165] Memory required for data: 118214668
I0627 10:43:58.039436 23737 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0627 10:43:58.039453 23737 net.cpp:100] Creating Layer res3a_branch2a_relu
I0627 10:43:58.039460 23737 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0627 10:43:58.039475 23737 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0627 10:43:58.039919 23737 net.cpp:150] Setting up res3a_branch2a_relu
I0627 10:43:58.039929 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.039933 23737 net.cpp:165] Memory required for data: 118616076
I0627 10:43:58.039940 23737 layer_factory.hpp:77] Creating layer res3a_branch2b
I0627 10:43:58.039961 23737 net.cpp:100] Creating Layer res3a_branch2b
I0627 10:43:58.039969 23737 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0627 10:43:58.039988 23737 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0627 10:43:58.041265 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:43:58.041548 23737 net.cpp:150] Setting up res3a_branch2b
I0627 10:43:58.041564 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.041569 23737 net.cpp:165] Memory required for data: 119017484
I0627 10:43:58.041584 23737 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0627 10:43:58.041600 23737 net.cpp:100] Creating Layer bn3a_branch2b
I0627 10:43:58.041609 23737 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0627 10:43:58.041627 23737 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0627 10:43:58.041908 23737 net.cpp:150] Setting up bn3a_branch2b
I0627 10:43:58.041918 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.041923 23737 net.cpp:165] Memory required for data: 119418892
I0627 10:43:58.041942 23737 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0627 10:43:58.041960 23737 net.cpp:100] Creating Layer scale3a_branch2b
I0627 10:43:58.041966 23737 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0627 10:43:58.041983 23737 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0627 10:43:58.042055 23737 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0627 10:43:58.042235 23737 net.cpp:150] Setting up scale3a_branch2b
I0627 10:43:58.042244 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.042248 23737 net.cpp:165] Memory required for data: 119820300
I0627 10:43:58.042263 23737 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0627 10:43:58.042276 23737 net.cpp:100] Creating Layer res3a_branch2b_relu
I0627 10:43:58.042284 23737 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0627 10:43:58.042299 23737 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0627 10:43:58.042462 23737 net.cpp:150] Setting up res3a_branch2b_relu
I0627 10:43:58.042470 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.042474 23737 net.cpp:165] Memory required for data: 120221708
I0627 10:43:58.042480 23737 layer_factory.hpp:77] Creating layer res3a_branch2c
I0627 10:43:58.042500 23737 net.cpp:100] Creating Layer res3a_branch2c
I0627 10:43:58.042507 23737 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0627 10:43:58.042526 23737 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0627 10:43:58.043653 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.043671 23737 net.cpp:150] Setting up res3a_branch2c
I0627 10:43:58.043684 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.043689 23737 net.cpp:165] Memory required for data: 121827340
I0627 10:43:58.043702 23737 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0627 10:43:58.043731 23737 net.cpp:100] Creating Layer bn3a_branch2c
I0627 10:43:58.043740 23737 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0627 10:43:58.043757 23737 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0627 10:43:58.044036 23737 net.cpp:150] Setting up bn3a_branch2c
I0627 10:43:58.044045 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.044049 23737 net.cpp:165] Memory required for data: 123432972
I0627 10:43:58.044070 23737 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0627 10:43:58.044093 23737 net.cpp:100] Creating Layer scale3a_branch2c
I0627 10:43:58.044101 23737 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0627 10:43:58.044119 23737 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0627 10:43:58.044193 23737 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0627 10:43:58.044374 23737 net.cpp:150] Setting up scale3a_branch2c
I0627 10:43:58.044384 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.044387 23737 net.cpp:165] Memory required for data: 125038604
I0627 10:43:58.044402 23737 layer_factory.hpp:77] Creating layer res3a
I0627 10:43:58.044418 23737 net.cpp:100] Creating Layer res3a
I0627 10:43:58.044425 23737 net.cpp:444] res3a <- res3a_branch1
I0627 10:43:58.044440 23737 net.cpp:444] res3a <- res3a_branch2c
I0627 10:43:58.044452 23737 net.cpp:418] res3a -> res3a
I0627 10:43:58.044499 23737 net.cpp:150] Setting up res3a
I0627 10:43:58.044509 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.044514 23737 net.cpp:165] Memory required for data: 126644236
I0627 10:43:58.044520 23737 layer_factory.hpp:77] Creating layer res3a_relu
I0627 10:43:58.044533 23737 net.cpp:100] Creating Layer res3a_relu
I0627 10:43:58.044540 23737 net.cpp:444] res3a_relu <- res3a
I0627 10:43:58.044559 23737 net.cpp:405] res3a_relu -> res3a (in-place)
I0627 10:43:58.044996 23737 net.cpp:150] Setting up res3a_relu
I0627 10:43:58.045006 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.045011 23737 net.cpp:165] Memory required for data: 128249868
I0627 10:43:58.045018 23737 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0627 10:43:58.045032 23737 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0627 10:43:58.045039 23737 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0627 10:43:58.045059 23737 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0627 10:43:58.045078 23737 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0627 10:43:58.045145 23737 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0627 10:43:58.045156 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.045162 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.045167 23737 net.cpp:165] Memory required for data: 131461132
I0627 10:43:58.045173 23737 layer_factory.hpp:77] Creating layer res3b_branch2a
I0627 10:43:58.045192 23737 net.cpp:100] Creating Layer res3b_branch2a
I0627 10:43:58.045199 23737 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0627 10:43:58.045219 23737 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0627 10:43:58.046337 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.046355 23737 net.cpp:150] Setting up res3b_branch2a
I0627 10:43:58.046368 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.046372 23737 net.cpp:165] Memory required for data: 131862540
I0627 10:43:58.046386 23737 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0627 10:43:58.046403 23737 net.cpp:100] Creating Layer bn3b_branch2a
I0627 10:43:58.046411 23737 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0627 10:43:58.046429 23737 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0627 10:43:58.046702 23737 net.cpp:150] Setting up bn3b_branch2a
I0627 10:43:58.046711 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.046715 23737 net.cpp:165] Memory required for data: 132263948
I0627 10:43:58.046736 23737 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0627 10:43:58.046752 23737 net.cpp:100] Creating Layer scale3b_branch2a
I0627 10:43:58.046759 23737 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0627 10:43:58.046777 23737 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0627 10:43:58.046849 23737 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0627 10:43:58.047039 23737 net.cpp:150] Setting up scale3b_branch2a
I0627 10:43:58.047049 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.047053 23737 net.cpp:165] Memory required for data: 132665356
I0627 10:43:58.047068 23737 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0627 10:43:58.047081 23737 net.cpp:100] Creating Layer res3b_branch2a_relu
I0627 10:43:58.047088 23737 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0627 10:43:58.047104 23737 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0627 10:43:58.047269 23737 net.cpp:150] Setting up res3b_branch2a_relu
I0627 10:43:58.047277 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.047281 23737 net.cpp:165] Memory required for data: 133066764
I0627 10:43:58.047287 23737 layer_factory.hpp:77] Creating layer res3b_branch2b
I0627 10:43:58.047307 23737 net.cpp:100] Creating Layer res3b_branch2b
I0627 10:43:58.047314 23737 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0627 10:43:58.047333 23737 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0627 10:43:58.048593 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:43:58.048883 23737 net.cpp:150] Setting up res3b_branch2b
I0627 10:43:58.048897 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.048902 23737 net.cpp:165] Memory required for data: 133468172
I0627 10:43:58.048915 23737 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0627 10:43:58.048933 23737 net.cpp:100] Creating Layer bn3b_branch2b
I0627 10:43:58.048941 23737 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0627 10:43:58.048959 23737 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0627 10:43:58.049242 23737 net.cpp:150] Setting up bn3b_branch2b
I0627 10:43:58.049252 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.049254 23737 net.cpp:165] Memory required for data: 133869580
I0627 10:43:58.049275 23737 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0627 10:43:58.049293 23737 net.cpp:100] Creating Layer scale3b_branch2b
I0627 10:43:58.049300 23737 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0627 10:43:58.049317 23737 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0627 10:43:58.049389 23737 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0627 10:43:58.049573 23737 net.cpp:150] Setting up scale3b_branch2b
I0627 10:43:58.049582 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.049585 23737 net.cpp:165] Memory required for data: 134270988
I0627 10:43:58.049600 23737 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0627 10:43:58.049614 23737 net.cpp:100] Creating Layer res3b_branch2b_relu
I0627 10:43:58.049623 23737 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0627 10:43:58.049638 23737 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0627 10:43:58.049803 23737 net.cpp:150] Setting up res3b_branch2b_relu
I0627 10:43:58.049811 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.049815 23737 net.cpp:165] Memory required for data: 134672396
I0627 10:43:58.049821 23737 layer_factory.hpp:77] Creating layer res3b_branch2c
I0627 10:43:58.049841 23737 net.cpp:100] Creating Layer res3b_branch2c
I0627 10:43:58.049849 23737 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0627 10:43:58.049866 23737 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0627 10:43:58.051002 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.051019 23737 net.cpp:150] Setting up res3b_branch2c
I0627 10:43:58.051030 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.051035 23737 net.cpp:165] Memory required for data: 136278028
I0627 10:43:58.051049 23737 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0627 10:43:58.051066 23737 net.cpp:100] Creating Layer bn3b_branch2c
I0627 10:43:58.051074 23737 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0627 10:43:58.051093 23737 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0627 10:43:58.051376 23737 net.cpp:150] Setting up bn3b_branch2c
I0627 10:43:58.051384 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.051388 23737 net.cpp:165] Memory required for data: 137883660
I0627 10:43:58.051409 23737 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0627 10:43:58.051426 23737 net.cpp:100] Creating Layer scale3b_branch2c
I0627 10:43:58.051434 23737 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0627 10:43:58.051450 23737 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0627 10:43:58.051522 23737 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0627 10:43:58.051708 23737 net.cpp:150] Setting up scale3b_branch2c
I0627 10:43:58.051717 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.051720 23737 net.cpp:165] Memory required for data: 139489292
I0627 10:43:58.051735 23737 layer_factory.hpp:77] Creating layer res3b
I0627 10:43:58.051750 23737 net.cpp:100] Creating Layer res3b
I0627 10:43:58.051757 23737 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0627 10:43:58.051771 23737 net.cpp:444] res3b <- res3b_branch2c
I0627 10:43:58.051784 23737 net.cpp:418] res3b -> res3b
I0627 10:43:58.051831 23737 net.cpp:150] Setting up res3b
I0627 10:43:58.051841 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.051846 23737 net.cpp:165] Memory required for data: 141094924
I0627 10:43:58.051852 23737 layer_factory.hpp:77] Creating layer res3b_relu
I0627 10:43:58.051864 23737 net.cpp:100] Creating Layer res3b_relu
I0627 10:43:58.051870 23737 net.cpp:444] res3b_relu <- res3b
I0627 10:43:58.051885 23737 net.cpp:405] res3b_relu -> res3b (in-place)
I0627 10:43:58.052326 23737 net.cpp:150] Setting up res3b_relu
I0627 10:43:58.052336 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.052340 23737 net.cpp:165] Memory required for data: 142700556
I0627 10:43:58.052347 23737 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0627 10:43:58.052362 23737 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0627 10:43:58.052371 23737 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0627 10:43:58.052388 23737 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0627 10:43:58.052407 23737 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0627 10:43:58.052474 23737 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0627 10:43:58.052484 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.052491 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.052495 23737 net.cpp:165] Memory required for data: 145911820
I0627 10:43:58.052501 23737 layer_factory.hpp:77] Creating layer res3c_branch2a
I0627 10:43:58.052520 23737 net.cpp:100] Creating Layer res3c_branch2a
I0627 10:43:58.052527 23737 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0627 10:43:58.052546 23737 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0627 10:43:58.053680 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.053699 23737 net.cpp:150] Setting up res3c_branch2a
I0627 10:43:58.053710 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.053714 23737 net.cpp:165] Memory required for data: 146313228
I0627 10:43:58.053728 23737 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0627 10:43:58.053745 23737 net.cpp:100] Creating Layer bn3c_branch2a
I0627 10:43:58.053753 23737 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0627 10:43:58.053771 23737 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0627 10:43:58.054051 23737 net.cpp:150] Setting up bn3c_branch2a
I0627 10:43:58.054060 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.054064 23737 net.cpp:165] Memory required for data: 146714636
I0627 10:43:58.054085 23737 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0627 10:43:58.054102 23737 net.cpp:100] Creating Layer scale3c_branch2a
I0627 10:43:58.054111 23737 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0627 10:43:58.054127 23737 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0627 10:43:58.054198 23737 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0627 10:43:58.054380 23737 net.cpp:150] Setting up scale3c_branch2a
I0627 10:43:58.054389 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.054392 23737 net.cpp:165] Memory required for data: 147116044
I0627 10:43:58.054407 23737 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0627 10:43:58.054420 23737 net.cpp:100] Creating Layer res3c_branch2a_relu
I0627 10:43:58.054427 23737 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0627 10:43:58.054445 23737 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0627 10:43:58.054610 23737 net.cpp:150] Setting up res3c_branch2a_relu
I0627 10:43:58.054617 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.054621 23737 net.cpp:165] Memory required for data: 147517452
I0627 10:43:58.054627 23737 layer_factory.hpp:77] Creating layer res3c_branch2b
I0627 10:43:58.054648 23737 net.cpp:100] Creating Layer res3c_branch2b
I0627 10:43:58.054656 23737 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0627 10:43:58.054674 23737 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0627 10:43:58.056766 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:43:58.057056 23737 net.cpp:150] Setting up res3c_branch2b
I0627 10:43:58.057070 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.057075 23737 net.cpp:165] Memory required for data: 147918860
I0627 10:43:58.057090 23737 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0627 10:43:58.057107 23737 net.cpp:100] Creating Layer bn3c_branch2b
I0627 10:43:58.057116 23737 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0627 10:43:58.057135 23737 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0627 10:43:58.057428 23737 net.cpp:150] Setting up bn3c_branch2b
I0627 10:43:58.057436 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.057440 23737 net.cpp:165] Memory required for data: 148320268
I0627 10:43:58.057461 23737 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0627 10:43:58.057478 23737 net.cpp:100] Creating Layer scale3c_branch2b
I0627 10:43:58.057485 23737 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0627 10:43:58.057504 23737 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0627 10:43:58.057579 23737 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0627 10:43:58.057763 23737 net.cpp:150] Setting up scale3c_branch2b
I0627 10:43:58.057772 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.057776 23737 net.cpp:165] Memory required for data: 148721676
I0627 10:43:58.057791 23737 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0627 10:43:58.057804 23737 net.cpp:100] Creating Layer res3c_branch2b_relu
I0627 10:43:58.057811 23737 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0627 10:43:58.057828 23737 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0627 10:43:58.057996 23737 net.cpp:150] Setting up res3c_branch2b_relu
I0627 10:43:58.058004 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.058007 23737 net.cpp:165] Memory required for data: 149123084
I0627 10:43:58.058014 23737 layer_factory.hpp:77] Creating layer res3c_branch2c
I0627 10:43:58.058034 23737 net.cpp:100] Creating Layer res3c_branch2c
I0627 10:43:58.058042 23737 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0627 10:43:58.058060 23737 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0627 10:43:58.059224 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.059243 23737 net.cpp:150] Setting up res3c_branch2c
I0627 10:43:58.059254 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.059258 23737 net.cpp:165] Memory required for data: 150728716
I0627 10:43:58.059273 23737 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0627 10:43:58.059291 23737 net.cpp:100] Creating Layer bn3c_branch2c
I0627 10:43:58.059299 23737 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0627 10:43:58.059316 23737 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0627 10:43:58.059603 23737 net.cpp:150] Setting up bn3c_branch2c
I0627 10:43:58.059612 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.059617 23737 net.cpp:165] Memory required for data: 152334348
I0627 10:43:58.059635 23737 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0627 10:43:58.059651 23737 net.cpp:100] Creating Layer scale3c_branch2c
I0627 10:43:58.059659 23737 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0627 10:43:58.059676 23737 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0627 10:43:58.059751 23737 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0627 10:43:58.059936 23737 net.cpp:150] Setting up scale3c_branch2c
I0627 10:43:58.059944 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.059948 23737 net.cpp:165] Memory required for data: 153939980
I0627 10:43:58.059962 23737 layer_factory.hpp:77] Creating layer res3c
I0627 10:43:58.059976 23737 net.cpp:100] Creating Layer res3c
I0627 10:43:58.059984 23737 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0627 10:43:58.059998 23737 net.cpp:444] res3c <- res3c_branch2c
I0627 10:43:58.060012 23737 net.cpp:418] res3c -> res3c
I0627 10:43:58.060060 23737 net.cpp:150] Setting up res3c
I0627 10:43:58.060070 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.060073 23737 net.cpp:165] Memory required for data: 155545612
I0627 10:43:58.060079 23737 layer_factory.hpp:77] Creating layer res3c_relu
I0627 10:43:58.060093 23737 net.cpp:100] Creating Layer res3c_relu
I0627 10:43:58.060101 23737 net.cpp:444] res3c_relu <- res3c
I0627 10:43:58.060115 23737 net.cpp:405] res3c_relu -> res3c (in-place)
I0627 10:43:58.060281 23737 net.cpp:150] Setting up res3c_relu
I0627 10:43:58.060289 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.060293 23737 net.cpp:165] Memory required for data: 157151244
I0627 10:43:58.060299 23737 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0627 10:43:58.060313 23737 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0627 10:43:58.060320 23737 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0627 10:43:58.060338 23737 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0627 10:43:58.060356 23737 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0627 10:43:58.060422 23737 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0627 10:43:58.060432 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.060439 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.060443 23737 net.cpp:165] Memory required for data: 160362508
I0627 10:43:58.060449 23737 layer_factory.hpp:77] Creating layer res3d_branch2a
I0627 10:43:58.060467 23737 net.cpp:100] Creating Layer res3d_branch2a
I0627 10:43:58.060475 23737 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0627 10:43:58.060493 23737 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0627 10:43:58.062427 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.062448 23737 net.cpp:150] Setting up res3d_branch2a
I0627 10:43:58.062458 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.062463 23737 net.cpp:165] Memory required for data: 160763916
I0627 10:43:58.062476 23737 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0627 10:43:58.062495 23737 net.cpp:100] Creating Layer bn3d_branch2a
I0627 10:43:58.062503 23737 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0627 10:43:58.062520 23737 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0627 10:43:58.062811 23737 net.cpp:150] Setting up bn3d_branch2a
I0627 10:43:58.062820 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.062824 23737 net.cpp:165] Memory required for data: 161165324
I0627 10:43:58.062875 23737 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0627 10:43:58.062906 23737 net.cpp:100] Creating Layer scale3d_branch2a
I0627 10:43:58.062916 23737 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0627 10:43:58.062932 23737 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0627 10:43:58.063006 23737 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0627 10:43:58.063195 23737 net.cpp:150] Setting up scale3d_branch2a
I0627 10:43:58.063205 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.063208 23737 net.cpp:165] Memory required for data: 161566732
I0627 10:43:58.063223 23737 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0627 10:43:58.063236 23737 net.cpp:100] Creating Layer res3d_branch2a_relu
I0627 10:43:58.063243 23737 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0627 10:43:58.063258 23737 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0627 10:43:58.063709 23737 net.cpp:150] Setting up res3d_branch2a_relu
I0627 10:43:58.063719 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.063724 23737 net.cpp:165] Memory required for data: 161968140
I0627 10:43:58.063730 23737 layer_factory.hpp:77] Creating layer res3d_branch2b
I0627 10:43:58.063751 23737 net.cpp:100] Creating Layer res3d_branch2b
I0627 10:43:58.063760 23737 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0627 10:43:58.063778 23737 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0627 10:43:58.065070 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0627 10:43:58.065361 23737 net.cpp:150] Setting up res3d_branch2b
I0627 10:43:58.065374 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.065379 23737 net.cpp:165] Memory required for data: 162369548
I0627 10:43:58.065394 23737 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0627 10:43:58.065412 23737 net.cpp:100] Creating Layer bn3d_branch2b
I0627 10:43:58.065419 23737 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0627 10:43:58.065439 23737 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0627 10:43:58.065735 23737 net.cpp:150] Setting up bn3d_branch2b
I0627 10:43:58.065743 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.065747 23737 net.cpp:165] Memory required for data: 162770956
I0627 10:43:58.065770 23737 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0627 10:43:58.065788 23737 net.cpp:100] Creating Layer scale3d_branch2b
I0627 10:43:58.065795 23737 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0627 10:43:58.065812 23737 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0627 10:43:58.065886 23737 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0627 10:43:58.066072 23737 net.cpp:150] Setting up scale3d_branch2b
I0627 10:43:58.066082 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.066085 23737 net.cpp:165] Memory required for data: 163172364
I0627 10:43:58.066100 23737 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0627 10:43:58.066115 23737 net.cpp:100] Creating Layer res3d_branch2b_relu
I0627 10:43:58.066123 23737 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0627 10:43:58.066138 23737 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0627 10:43:58.066308 23737 net.cpp:150] Setting up res3d_branch2b_relu
I0627 10:43:58.066316 23737 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0627 10:43:58.066320 23737 net.cpp:165] Memory required for data: 163573772
I0627 10:43:58.066326 23737 layer_factory.hpp:77] Creating layer res3d_branch2c
I0627 10:43:58.066349 23737 net.cpp:100] Creating Layer res3d_branch2c
I0627 10:43:58.066355 23737 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0627 10:43:58.066373 23737 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0627 10:43:58.067549 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0627 10:43:58.067569 23737 net.cpp:150] Setting up res3d_branch2c
I0627 10:43:58.067580 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.067584 23737 net.cpp:165] Memory required for data: 165179404
I0627 10:43:58.067597 23737 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0627 10:43:58.067617 23737 net.cpp:100] Creating Layer bn3d_branch2c
I0627 10:43:58.067625 23737 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0627 10:43:58.067646 23737 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0627 10:43:58.067937 23737 net.cpp:150] Setting up bn3d_branch2c
I0627 10:43:58.067946 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.067950 23737 net.cpp:165] Memory required for data: 166785036
I0627 10:43:58.067971 23737 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0627 10:43:58.067989 23737 net.cpp:100] Creating Layer scale3d_branch2c
I0627 10:43:58.067997 23737 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0627 10:43:58.068014 23737 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0627 10:43:58.068090 23737 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0627 10:43:58.068279 23737 net.cpp:150] Setting up scale3d_branch2c
I0627 10:43:58.068289 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.068291 23737 net.cpp:165] Memory required for data: 168390668
I0627 10:43:58.068306 23737 layer_factory.hpp:77] Creating layer res3d
I0627 10:43:58.068320 23737 net.cpp:100] Creating Layer res3d
I0627 10:43:58.068327 23737 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0627 10:43:58.068341 23737 net.cpp:444] res3d <- res3d_branch2c
I0627 10:43:58.068354 23737 net.cpp:418] res3d -> res3d
I0627 10:43:58.068403 23737 net.cpp:150] Setting up res3d
I0627 10:43:58.068414 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.068419 23737 net.cpp:165] Memory required for data: 169996300
I0627 10:43:58.068425 23737 layer_factory.hpp:77] Creating layer res3d_relu
I0627 10:43:58.068437 23737 net.cpp:100] Creating Layer res3d_relu
I0627 10:43:58.068444 23737 net.cpp:444] res3d_relu <- res3d
I0627 10:43:58.068460 23737 net.cpp:405] res3d_relu -> res3d (in-place)
I0627 10:43:58.068632 23737 net.cpp:150] Setting up res3d_relu
I0627 10:43:58.068640 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.068645 23737 net.cpp:165] Memory required for data: 171601932
I0627 10:43:58.068650 23737 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0627 10:43:58.068665 23737 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0627 10:43:58.068671 23737 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0627 10:43:58.068688 23737 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0627 10:43:58.068708 23737 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0627 10:43:58.068773 23737 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0627 10:43:58.068784 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.068791 23737 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0627 10:43:58.068795 23737 net.cpp:165] Memory required for data: 174813196
I0627 10:43:58.068801 23737 layer_factory.hpp:77] Creating layer res4a_branch1
I0627 10:43:58.068821 23737 net.cpp:100] Creating Layer res4a_branch1
I0627 10:43:58.068828 23737 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0627 10:43:58.068846 23737 net.cpp:418] res4a_branch1 -> res4a_branch1
I0627 10:43:58.071622 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7416
I0627 10:43:58.071660 23737 net.cpp:150] Setting up res4a_branch1
I0627 10:43:58.071674 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.071679 23737 net.cpp:165] Memory required for data: 175616012
I0627 10:43:58.071701 23737 layer_factory.hpp:77] Creating layer bn4a_branch1
I0627 10:43:58.071728 23737 net.cpp:100] Creating Layer bn4a_branch1
I0627 10:43:58.071739 23737 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0627 10:43:58.071763 23737 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0627 10:43:58.072089 23737 net.cpp:150] Setting up bn4a_branch1
I0627 10:43:58.072098 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.072103 23737 net.cpp:165] Memory required for data: 176418828
I0627 10:43:58.072124 23737 layer_factory.hpp:77] Creating layer scale4a_branch1
I0627 10:43:58.072140 23737 net.cpp:100] Creating Layer scale4a_branch1
I0627 10:43:58.072149 23737 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0627 10:43:58.072165 23737 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0627 10:43:58.072239 23737 layer_factory.hpp:77] Creating layer scale4a_branch1
I0627 10:43:58.072437 23737 net.cpp:150] Setting up scale4a_branch1
I0627 10:43:58.072445 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.072449 23737 net.cpp:165] Memory required for data: 177221644
I0627 10:43:58.072464 23737 layer_factory.hpp:77] Creating layer res4a_branch2a
I0627 10:43:58.072485 23737 net.cpp:100] Creating Layer res4a_branch2a
I0627 10:43:58.072494 23737 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0627 10:43:58.072512 23737 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0627 10:43:58.073828 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7032
I0627 10:43:58.073854 23737 net.cpp:150] Setting up res4a_branch2a
I0627 10:43:58.073865 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.073869 23737 net.cpp:165] Memory required for data: 177422348
I0627 10:43:58.073884 23737 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0627 10:43:58.073900 23737 net.cpp:100] Creating Layer bn4a_branch2a
I0627 10:43:58.073909 23737 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0627 10:43:58.073926 23737 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0627 10:43:58.074223 23737 net.cpp:150] Setting up bn4a_branch2a
I0627 10:43:58.074231 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.074234 23737 net.cpp:165] Memory required for data: 177623052
I0627 10:43:58.074254 23737 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0627 10:43:58.074271 23737 net.cpp:100] Creating Layer scale4a_branch2a
I0627 10:43:58.074280 23737 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0627 10:43:58.074295 23737 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0627 10:43:58.074368 23737 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0627 10:43:58.074554 23737 net.cpp:150] Setting up scale4a_branch2a
I0627 10:43:58.074563 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.074568 23737 net.cpp:165] Memory required for data: 177823756
I0627 10:43:58.074581 23737 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0627 10:43:58.074596 23737 net.cpp:100] Creating Layer res4a_branch2a_relu
I0627 10:43:58.074604 23737 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0627 10:43:58.074620 23737 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0627 10:43:58.075083 23737 net.cpp:150] Setting up res4a_branch2a_relu
I0627 10:43:58.075094 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.075098 23737 net.cpp:165] Memory required for data: 178024460
I0627 10:43:58.075105 23737 layer_factory.hpp:77] Creating layer res4a_branch2b
I0627 10:43:58.075125 23737 net.cpp:100] Creating Layer res4a_branch2b
I0627 10:43:58.075134 23737 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0627 10:43:58.075153 23737 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0627 10:43:58.078048 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:43:58.078351 23737 net.cpp:150] Setting up res4a_branch2b
I0627 10:43:58.078366 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.078372 23737 net.cpp:165] Memory required for data: 178225164
I0627 10:43:58.078387 23737 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0627 10:43:58.078408 23737 net.cpp:100] Creating Layer bn4a_branch2b
I0627 10:43:58.078418 23737 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0627 10:43:58.078435 23737 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0627 10:43:58.078742 23737 net.cpp:150] Setting up bn4a_branch2b
I0627 10:43:58.078749 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.078753 23737 net.cpp:165] Memory required for data: 178425868
I0627 10:43:58.078773 23737 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0627 10:43:58.078793 23737 net.cpp:100] Creating Layer scale4a_branch2b
I0627 10:43:58.078799 23737 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0627 10:43:58.078819 23737 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0627 10:43:58.078902 23737 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0627 10:43:58.079094 23737 net.cpp:150] Setting up scale4a_branch2b
I0627 10:43:58.079103 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.079107 23737 net.cpp:165] Memory required for data: 178626572
I0627 10:43:58.079121 23737 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0627 10:43:58.079136 23737 net.cpp:100] Creating Layer res4a_branch2b_relu
I0627 10:43:58.079144 23737 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0627 10:43:58.079159 23737 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0627 10:43:58.079336 23737 net.cpp:150] Setting up res4a_branch2b_relu
I0627 10:43:58.079344 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.079349 23737 net.cpp:165] Memory required for data: 178827276
I0627 10:43:58.079355 23737 layer_factory.hpp:77] Creating layer res4a_branch2c
I0627 10:43:58.079375 23737 net.cpp:100] Creating Layer res4a_branch2c
I0627 10:43:58.079382 23737 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0627 10:43:58.079401 23737 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0627 10:43:58.081720 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.081748 23737 net.cpp:150] Setting up res4a_branch2c
I0627 10:43:58.081760 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.081764 23737 net.cpp:165] Memory required for data: 179630092
I0627 10:43:58.081779 23737 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0627 10:43:58.081799 23737 net.cpp:100] Creating Layer bn4a_branch2c
I0627 10:43:58.081806 23737 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0627 10:43:58.081825 23737 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0627 10:43:58.082132 23737 net.cpp:150] Setting up bn4a_branch2c
I0627 10:43:58.082142 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.082147 23737 net.cpp:165] Memory required for data: 180432908
I0627 10:43:58.082167 23737 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0627 10:43:58.082185 23737 net.cpp:100] Creating Layer scale4a_branch2c
I0627 10:43:58.082192 23737 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0627 10:43:58.082211 23737 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0627 10:43:58.082283 23737 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0627 10:43:58.082482 23737 net.cpp:150] Setting up scale4a_branch2c
I0627 10:43:58.082490 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.082494 23737 net.cpp:165] Memory required for data: 181235724
I0627 10:43:58.082509 23737 layer_factory.hpp:77] Creating layer res4a
I0627 10:43:58.082523 23737 net.cpp:100] Creating Layer res4a
I0627 10:43:58.082530 23737 net.cpp:444] res4a <- res4a_branch1
I0627 10:43:58.082545 23737 net.cpp:444] res4a <- res4a_branch2c
I0627 10:43:58.082556 23737 net.cpp:418] res4a -> res4a
I0627 10:43:58.082607 23737 net.cpp:150] Setting up res4a
I0627 10:43:58.082618 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.082623 23737 net.cpp:165] Memory required for data: 182038540
I0627 10:43:58.082628 23737 layer_factory.hpp:77] Creating layer res4a_relu
I0627 10:43:58.082641 23737 net.cpp:100] Creating Layer res4a_relu
I0627 10:43:58.082648 23737 net.cpp:444] res4a_relu <- res4a
I0627 10:43:58.082664 23737 net.cpp:405] res4a_relu -> res4a (in-place)
I0627 10:43:58.083114 23737 net.cpp:150] Setting up res4a_relu
I0627 10:43:58.083125 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.083129 23737 net.cpp:165] Memory required for data: 182841356
I0627 10:43:58.083137 23737 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0627 10:43:58.083153 23737 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0627 10:43:58.083160 23737 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0627 10:43:58.083178 23737 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0627 10:43:58.083200 23737 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0627 10:43:58.083273 23737 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0627 10:43:58.083284 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.083292 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.083297 23737 net.cpp:165] Memory required for data: 184446988
I0627 10:43:58.083302 23737 layer_factory.hpp:77] Creating layer res4b_branch2a
I0627 10:43:58.083338 23737 net.cpp:100] Creating Layer res4b_branch2a
I0627 10:43:58.083348 23737 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0627 10:43:58.083365 23737 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0627 10:43:58.084847 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.084877 23737 net.cpp:150] Setting up res4b_branch2a
I0627 10:43:58.084888 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.084893 23737 net.cpp:165] Memory required for data: 184647692
I0627 10:43:58.084909 23737 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0627 10:43:58.084928 23737 net.cpp:100] Creating Layer bn4b_branch2a
I0627 10:43:58.084935 23737 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0627 10:43:58.084954 23737 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0627 10:43:58.085249 23737 net.cpp:150] Setting up bn4b_branch2a
I0627 10:43:58.085258 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.085263 23737 net.cpp:165] Memory required for data: 184848396
I0627 10:43:58.085283 23737 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0627 10:43:58.085300 23737 net.cpp:100] Creating Layer scale4b_branch2a
I0627 10:43:58.085307 23737 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0627 10:43:58.085324 23737 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0627 10:43:58.085398 23737 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0627 10:43:58.085588 23737 net.cpp:150] Setting up scale4b_branch2a
I0627 10:43:58.085597 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.085602 23737 net.cpp:165] Memory required for data: 185049100
I0627 10:43:58.085615 23737 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0627 10:43:58.085630 23737 net.cpp:100] Creating Layer res4b_branch2a_relu
I0627 10:43:58.085638 23737 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0627 10:43:58.085654 23737 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0627 10:43:58.086103 23737 net.cpp:150] Setting up res4b_branch2a_relu
I0627 10:43:58.086113 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.086117 23737 net.cpp:165] Memory required for data: 185249804
I0627 10:43:58.086124 23737 layer_factory.hpp:77] Creating layer res4b_branch2b
I0627 10:43:58.086145 23737 net.cpp:100] Creating Layer res4b_branch2b
I0627 10:43:58.086154 23737 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0627 10:43:58.086174 23737 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0627 10:43:58.089104 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:43:58.089427 23737 net.cpp:150] Setting up res4b_branch2b
I0627 10:43:58.089443 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.089450 23737 net.cpp:165] Memory required for data: 185450508
I0627 10:43:58.089469 23737 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0627 10:43:58.089493 23737 net.cpp:100] Creating Layer bn4b_branch2b
I0627 10:43:58.089504 23737 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0627 10:43:58.089524 23737 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0627 10:43:58.089838 23737 net.cpp:150] Setting up bn4b_branch2b
I0627 10:43:58.089846 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.089849 23737 net.cpp:165] Memory required for data: 185651212
I0627 10:43:58.089870 23737 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0627 10:43:58.089890 23737 net.cpp:100] Creating Layer scale4b_branch2b
I0627 10:43:58.089897 23737 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0627 10:43:58.089915 23737 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0627 10:43:58.089994 23737 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0627 10:43:58.090186 23737 net.cpp:150] Setting up scale4b_branch2b
I0627 10:43:58.090195 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.090198 23737 net.cpp:165] Memory required for data: 185851916
I0627 10:43:58.090214 23737 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0627 10:43:58.090229 23737 net.cpp:100] Creating Layer res4b_branch2b_relu
I0627 10:43:58.090236 23737 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0627 10:43:58.090250 23737 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0627 10:43:58.090427 23737 net.cpp:150] Setting up res4b_branch2b_relu
I0627 10:43:58.090436 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.090440 23737 net.cpp:165] Memory required for data: 186052620
I0627 10:43:58.090445 23737 layer_factory.hpp:77] Creating layer res4b_branch2c
I0627 10:43:58.090466 23737 net.cpp:100] Creating Layer res4b_branch2c
I0627 10:43:58.090474 23737 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0627 10:43:58.090492 23737 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0627 10:43:58.092836 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.092867 23737 net.cpp:150] Setting up res4b_branch2c
I0627 10:43:58.092880 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.092883 23737 net.cpp:165] Memory required for data: 186855436
I0627 10:43:58.092897 23737 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0627 10:43:58.092918 23737 net.cpp:100] Creating Layer bn4b_branch2c
I0627 10:43:58.092926 23737 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0627 10:43:58.092944 23737 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0627 10:43:58.093257 23737 net.cpp:150] Setting up bn4b_branch2c
I0627 10:43:58.093266 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.093271 23737 net.cpp:165] Memory required for data: 187658252
I0627 10:43:58.093291 23737 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0627 10:43:58.093309 23737 net.cpp:100] Creating Layer scale4b_branch2c
I0627 10:43:58.093317 23737 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0627 10:43:58.093334 23737 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0627 10:43:58.093406 23737 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0627 10:43:58.093610 23737 net.cpp:150] Setting up scale4b_branch2c
I0627 10:43:58.093618 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.093622 23737 net.cpp:165] Memory required for data: 188461068
I0627 10:43:58.093636 23737 layer_factory.hpp:77] Creating layer res4b
I0627 10:43:58.093650 23737 net.cpp:100] Creating Layer res4b
I0627 10:43:58.093658 23737 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0627 10:43:58.093672 23737 net.cpp:444] res4b <- res4b_branch2c
I0627 10:43:58.093686 23737 net.cpp:418] res4b -> res4b
I0627 10:43:58.093736 23737 net.cpp:150] Setting up res4b
I0627 10:43:58.093747 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.093751 23737 net.cpp:165] Memory required for data: 189263884
I0627 10:43:58.093757 23737 layer_factory.hpp:77] Creating layer res4b_relu
I0627 10:43:58.093770 23737 net.cpp:100] Creating Layer res4b_relu
I0627 10:43:58.093777 23737 net.cpp:444] res4b_relu <- res4b
I0627 10:43:58.093793 23737 net.cpp:405] res4b_relu -> res4b (in-place)
I0627 10:43:58.093963 23737 net.cpp:150] Setting up res4b_relu
I0627 10:43:58.093971 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.093976 23737 net.cpp:165] Memory required for data: 190066700
I0627 10:43:58.093981 23737 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0627 10:43:58.093997 23737 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0627 10:43:58.094002 23737 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0627 10:43:58.094022 23737 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0627 10:43:58.094040 23737 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0627 10:43:58.094110 23737 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0627 10:43:58.094120 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.094127 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.094131 23737 net.cpp:165] Memory required for data: 191672332
I0627 10:43:58.094137 23737 layer_factory.hpp:77] Creating layer res4c_branch2a
I0627 10:43:58.094157 23737 net.cpp:100] Creating Layer res4c_branch2a
I0627 10:43:58.094164 23737 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0627 10:43:58.094182 23737 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0627 10:43:58.095691 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.095719 23737 net.cpp:150] Setting up res4c_branch2a
I0627 10:43:58.095731 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.095734 23737 net.cpp:165] Memory required for data: 191873036
I0627 10:43:58.095748 23737 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0627 10:43:58.095767 23737 net.cpp:100] Creating Layer bn4c_branch2a
I0627 10:43:58.095775 23737 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0627 10:43:58.095793 23737 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0627 10:43:58.096103 23737 net.cpp:150] Setting up bn4c_branch2a
I0627 10:43:58.096113 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.096119 23737 net.cpp:165] Memory required for data: 192073740
I0627 10:43:58.096139 23737 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0627 10:43:58.096158 23737 net.cpp:100] Creating Layer scale4c_branch2a
I0627 10:43:58.096165 23737 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0627 10:43:58.096182 23737 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0627 10:43:58.096257 23737 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0627 10:43:58.096452 23737 net.cpp:150] Setting up scale4c_branch2a
I0627 10:43:58.096462 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.096467 23737 net.cpp:165] Memory required for data: 192274444
I0627 10:43:58.096482 23737 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0627 10:43:58.096495 23737 net.cpp:100] Creating Layer res4c_branch2a_relu
I0627 10:43:58.096503 23737 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0627 10:43:58.096518 23737 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0627 10:43:58.096685 23737 net.cpp:150] Setting up res4c_branch2a_relu
I0627 10:43:58.096694 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.096698 23737 net.cpp:165] Memory required for data: 192475148
I0627 10:43:58.096704 23737 layer_factory.hpp:77] Creating layer res4c_branch2b
I0627 10:43:58.096722 23737 net.cpp:100] Creating Layer res4c_branch2b
I0627 10:43:58.096730 23737 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0627 10:43:58.096750 23737 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0627 10:43:58.099726 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:43:58.100044 23737 net.cpp:150] Setting up res4c_branch2b
I0627 10:43:58.100064 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.100067 23737 net.cpp:165] Memory required for data: 192675852
I0627 10:43:58.100086 23737 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0627 10:43:58.100111 23737 net.cpp:100] Creating Layer bn4c_branch2b
I0627 10:43:58.100121 23737 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0627 10:43:58.100142 23737 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0627 10:43:58.100462 23737 net.cpp:150] Setting up bn4c_branch2b
I0627 10:43:58.100471 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.100474 23737 net.cpp:165] Memory required for data: 192876556
I0627 10:43:58.100495 23737 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0627 10:43:58.100514 23737 net.cpp:100] Creating Layer scale4c_branch2b
I0627 10:43:58.100522 23737 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0627 10:43:58.100538 23737 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0627 10:43:58.100618 23737 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0627 10:43:58.100818 23737 net.cpp:150] Setting up scale4c_branch2b
I0627 10:43:58.100827 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.100831 23737 net.cpp:165] Memory required for data: 193077260
I0627 10:43:58.100845 23737 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0627 10:43:58.100860 23737 net.cpp:100] Creating Layer res4c_branch2b_relu
I0627 10:43:58.100868 23737 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0627 10:43:58.100883 23737 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0627 10:43:58.101351 23737 net.cpp:150] Setting up res4c_branch2b_relu
I0627 10:43:58.101362 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.101366 23737 net.cpp:165] Memory required for data: 193277964
I0627 10:43:58.101373 23737 layer_factory.hpp:77] Creating layer res4c_branch2c
I0627 10:43:58.101397 23737 net.cpp:100] Creating Layer res4c_branch2c
I0627 10:43:58.101404 23737 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0627 10:43:58.101426 23737 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0627 10:43:58.103855 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.103890 23737 net.cpp:150] Setting up res4c_branch2c
I0627 10:43:58.103904 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.103909 23737 net.cpp:165] Memory required for data: 194080780
I0627 10:43:58.103926 23737 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0627 10:43:58.103950 23737 net.cpp:100] Creating Layer bn4c_branch2c
I0627 10:43:58.103960 23737 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0627 10:43:58.103979 23737 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0627 10:43:58.104302 23737 net.cpp:150] Setting up bn4c_branch2c
I0627 10:43:58.104312 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.104317 23737 net.cpp:165] Memory required for data: 194883596
I0627 10:43:58.104338 23737 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0627 10:43:58.104355 23737 net.cpp:100] Creating Layer scale4c_branch2c
I0627 10:43:58.104363 23737 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0627 10:43:58.104382 23737 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0627 10:43:58.104457 23737 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0627 10:43:58.104666 23737 net.cpp:150] Setting up scale4c_branch2c
I0627 10:43:58.104676 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.104679 23737 net.cpp:165] Memory required for data: 195686412
I0627 10:43:58.104694 23737 layer_factory.hpp:77] Creating layer res4c
I0627 10:43:58.104709 23737 net.cpp:100] Creating Layer res4c
I0627 10:43:58.104717 23737 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0627 10:43:58.104732 23737 net.cpp:444] res4c <- res4c_branch2c
I0627 10:43:58.104744 23737 net.cpp:418] res4c -> res4c
I0627 10:43:58.104796 23737 net.cpp:150] Setting up res4c
I0627 10:43:58.104807 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.104811 23737 net.cpp:165] Memory required for data: 196489228
I0627 10:43:58.104817 23737 layer_factory.hpp:77] Creating layer res4c_relu
I0627 10:43:58.104830 23737 net.cpp:100] Creating Layer res4c_relu
I0627 10:43:58.104836 23737 net.cpp:444] res4c_relu <- res4c
I0627 10:43:58.104853 23737 net.cpp:405] res4c_relu -> res4c (in-place)
I0627 10:43:58.105020 23737 net.cpp:150] Setting up res4c_relu
I0627 10:43:58.105029 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.105033 23737 net.cpp:165] Memory required for data: 197292044
I0627 10:43:58.105039 23737 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0627 10:43:58.105053 23737 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0627 10:43:58.105060 23737 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0627 10:43:58.105077 23737 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0627 10:43:58.105095 23737 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0627 10:43:58.105166 23737 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0627 10:43:58.105176 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.105182 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.105186 23737 net.cpp:165] Memory required for data: 198897676
I0627 10:43:58.105191 23737 layer_factory.hpp:77] Creating layer res4d_branch2a
I0627 10:43:58.105211 23737 net.cpp:100] Creating Layer res4d_branch2a
I0627 10:43:58.105221 23737 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0627 10:43:58.105238 23737 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0627 10:43:58.106814 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.106845 23737 net.cpp:150] Setting up res4d_branch2a
I0627 10:43:58.106861 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.106889 23737 net.cpp:165] Memory required for data: 199098380
I0627 10:43:58.106905 23737 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0627 10:43:58.106926 23737 net.cpp:100] Creating Layer bn4d_branch2a
I0627 10:43:58.106935 23737 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0627 10:43:58.106954 23737 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0627 10:43:58.107270 23737 net.cpp:150] Setting up bn4d_branch2a
I0627 10:43:58.107278 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.107281 23737 net.cpp:165] Memory required for data: 199299084
I0627 10:43:58.107302 23737 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0627 10:43:58.107321 23737 net.cpp:100] Creating Layer scale4d_branch2a
I0627 10:43:58.107329 23737 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0627 10:43:58.107345 23737 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0627 10:43:58.107422 23737 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0627 10:43:58.107619 23737 net.cpp:150] Setting up scale4d_branch2a
I0627 10:43:58.107627 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.107631 23737 net.cpp:165] Memory required for data: 199499788
I0627 10:43:58.107645 23737 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0627 10:43:58.107661 23737 net.cpp:100] Creating Layer res4d_branch2a_relu
I0627 10:43:58.107667 23737 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0627 10:43:58.107682 23737 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0627 10:43:58.107851 23737 net.cpp:150] Setting up res4d_branch2a_relu
I0627 10:43:58.107861 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.107863 23737 net.cpp:165] Memory required for data: 199700492
I0627 10:43:58.107869 23737 layer_factory.hpp:77] Creating layer res4d_branch2b
I0627 10:43:58.107889 23737 net.cpp:100] Creating Layer res4d_branch2b
I0627 10:43:58.107897 23737 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0627 10:43:58.107916 23737 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0627 10:43:58.110867 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:43:58.111182 23737 net.cpp:150] Setting up res4d_branch2b
I0627 10:43:58.111198 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.111202 23737 net.cpp:165] Memory required for data: 199901196
I0627 10:43:58.111219 23737 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0627 10:43:58.111241 23737 net.cpp:100] Creating Layer bn4d_branch2b
I0627 10:43:58.111249 23737 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0627 10:43:58.111270 23737 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0627 10:43:58.111593 23737 net.cpp:150] Setting up bn4d_branch2b
I0627 10:43:58.111601 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.111605 23737 net.cpp:165] Memory required for data: 200101900
I0627 10:43:58.111626 23737 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0627 10:43:58.111645 23737 net.cpp:100] Creating Layer scale4d_branch2b
I0627 10:43:58.111652 23737 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0627 10:43:58.111670 23737 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0627 10:43:58.111748 23737 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0627 10:43:58.111945 23737 net.cpp:150] Setting up scale4d_branch2b
I0627 10:43:58.111954 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.111958 23737 net.cpp:165] Memory required for data: 200302604
I0627 10:43:58.111973 23737 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0627 10:43:58.111986 23737 net.cpp:100] Creating Layer res4d_branch2b_relu
I0627 10:43:58.111994 23737 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0627 10:43:58.112010 23737 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0627 10:43:58.112474 23737 net.cpp:150] Setting up res4d_branch2b_relu
I0627 10:43:58.112484 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.112488 23737 net.cpp:165] Memory required for data: 200503308
I0627 10:43:58.112495 23737 layer_factory.hpp:77] Creating layer res4d_branch2c
I0627 10:43:58.112516 23737 net.cpp:100] Creating Layer res4d_branch2c
I0627 10:43:58.112524 23737 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0627 10:43:58.112545 23737 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0627 10:43:58.114886 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.114923 23737 net.cpp:150] Setting up res4d_branch2c
I0627 10:43:58.114934 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.114939 23737 net.cpp:165] Memory required for data: 201306124
I0627 10:43:58.114953 23737 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0627 10:43:58.114972 23737 net.cpp:100] Creating Layer bn4d_branch2c
I0627 10:43:58.114981 23737 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0627 10:43:58.115000 23737 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0627 10:43:58.115324 23737 net.cpp:150] Setting up bn4d_branch2c
I0627 10:43:58.115334 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.115337 23737 net.cpp:165] Memory required for data: 202108940
I0627 10:43:58.115358 23737 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0627 10:43:58.115375 23737 net.cpp:100] Creating Layer scale4d_branch2c
I0627 10:43:58.115382 23737 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0627 10:43:58.115399 23737 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0627 10:43:58.115475 23737 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0627 10:43:58.115684 23737 net.cpp:150] Setting up scale4d_branch2c
I0627 10:43:58.115692 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.115696 23737 net.cpp:165] Memory required for data: 202911756
I0627 10:43:58.115711 23737 layer_factory.hpp:77] Creating layer res4d
I0627 10:43:58.115725 23737 net.cpp:100] Creating Layer res4d
I0627 10:43:58.115733 23737 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0627 10:43:58.115746 23737 net.cpp:444] res4d <- res4d_branch2c
I0627 10:43:58.115761 23737 net.cpp:418] res4d -> res4d
I0627 10:43:58.115811 23737 net.cpp:150] Setting up res4d
I0627 10:43:58.115823 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.115826 23737 net.cpp:165] Memory required for data: 203714572
I0627 10:43:58.115833 23737 layer_factory.hpp:77] Creating layer res4d_relu
I0627 10:43:58.115844 23737 net.cpp:100] Creating Layer res4d_relu
I0627 10:43:58.115851 23737 net.cpp:444] res4d_relu <- res4d
I0627 10:43:58.115867 23737 net.cpp:405] res4d_relu -> res4d (in-place)
I0627 10:43:58.116035 23737 net.cpp:150] Setting up res4d_relu
I0627 10:43:58.116044 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.116047 23737 net.cpp:165] Memory required for data: 204517388
I0627 10:43:58.116053 23737 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0627 10:43:58.116067 23737 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0627 10:43:58.116075 23737 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0627 10:43:58.116091 23737 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0627 10:43:58.116109 23737 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0627 10:43:58.116179 23737 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0627 10:43:58.116189 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.116196 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.116200 23737 net.cpp:165] Memory required for data: 206123020
I0627 10:43:58.116205 23737 layer_factory.hpp:77] Creating layer res4e_branch2a
I0627 10:43:58.116226 23737 net.cpp:100] Creating Layer res4e_branch2a
I0627 10:43:58.116233 23737 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0627 10:43:58.116251 23737 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0627 10:43:58.117761 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.117790 23737 net.cpp:150] Setting up res4e_branch2a
I0627 10:43:58.117800 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.117805 23737 net.cpp:165] Memory required for data: 206323724
I0627 10:43:58.117818 23737 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0627 10:43:58.117836 23737 net.cpp:100] Creating Layer bn4e_branch2a
I0627 10:43:58.117844 23737 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0627 10:43:58.117863 23737 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0627 10:43:58.118172 23737 net.cpp:150] Setting up bn4e_branch2a
I0627 10:43:58.118180 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.118185 23737 net.cpp:165] Memory required for data: 206524428
I0627 10:43:58.118204 23737 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0627 10:43:58.118222 23737 net.cpp:100] Creating Layer scale4e_branch2a
I0627 10:43:58.118230 23737 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0627 10:43:58.118247 23737 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0627 10:43:58.118321 23737 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0627 10:43:58.118518 23737 net.cpp:150] Setting up scale4e_branch2a
I0627 10:43:58.118527 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.118530 23737 net.cpp:165] Memory required for data: 206725132
I0627 10:43:58.118544 23737 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0627 10:43:58.118559 23737 net.cpp:100] Creating Layer res4e_branch2a_relu
I0627 10:43:58.118566 23737 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0627 10:43:58.118582 23737 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0627 10:43:58.118747 23737 net.cpp:150] Setting up res4e_branch2a_relu
I0627 10:43:58.118757 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.118760 23737 net.cpp:165] Memory required for data: 206925836
I0627 10:43:58.118767 23737 layer_factory.hpp:77] Creating layer res4e_branch2b
I0627 10:43:58.118784 23737 net.cpp:100] Creating Layer res4e_branch2b
I0627 10:43:58.118791 23737 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0627 10:43:58.118813 23737 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0627 10:43:58.121727 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:43:58.122040 23737 net.cpp:150] Setting up res4e_branch2b
I0627 10:43:58.122056 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.122061 23737 net.cpp:165] Memory required for data: 207126540
I0627 10:43:58.122076 23737 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0627 10:43:58.122097 23737 net.cpp:100] Creating Layer bn4e_branch2b
I0627 10:43:58.122107 23737 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0627 10:43:58.122125 23737 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0627 10:43:58.122448 23737 net.cpp:150] Setting up bn4e_branch2b
I0627 10:43:58.122458 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.122463 23737 net.cpp:165] Memory required for data: 207327244
I0627 10:43:58.122484 23737 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0627 10:43:58.122501 23737 net.cpp:100] Creating Layer scale4e_branch2b
I0627 10:43:58.122509 23737 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0627 10:43:58.122526 23737 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0627 10:43:58.122606 23737 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0627 10:43:58.122803 23737 net.cpp:150] Setting up scale4e_branch2b
I0627 10:43:58.122812 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.122815 23737 net.cpp:165] Memory required for data: 207527948
I0627 10:43:58.122831 23737 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0627 10:43:58.122845 23737 net.cpp:100] Creating Layer res4e_branch2b_relu
I0627 10:43:58.122853 23737 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0627 10:43:58.122874 23737 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0627 10:43:58.123344 23737 net.cpp:150] Setting up res4e_branch2b_relu
I0627 10:43:58.123355 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.123359 23737 net.cpp:165] Memory required for data: 207728652
I0627 10:43:58.123366 23737 layer_factory.hpp:77] Creating layer res4e_branch2c
I0627 10:43:58.123389 23737 net.cpp:100] Creating Layer res4e_branch2c
I0627 10:43:58.123396 23737 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0627 10:43:58.123415 23737 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0627 10:43:58.125764 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.125797 23737 net.cpp:150] Setting up res4e_branch2c
I0627 10:43:58.125808 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.125813 23737 net.cpp:165] Memory required for data: 208531468
I0627 10:43:58.125828 23737 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0627 10:43:58.125847 23737 net.cpp:100] Creating Layer bn4e_branch2c
I0627 10:43:58.125856 23737 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0627 10:43:58.125874 23737 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0627 10:43:58.126201 23737 net.cpp:150] Setting up bn4e_branch2c
I0627 10:43:58.126210 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.126214 23737 net.cpp:165] Memory required for data: 209334284
I0627 10:43:58.126235 23737 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0627 10:43:58.126251 23737 net.cpp:100] Creating Layer scale4e_branch2c
I0627 10:43:58.126260 23737 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0627 10:43:58.126277 23737 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0627 10:43:58.126350 23737 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0627 10:43:58.126560 23737 net.cpp:150] Setting up scale4e_branch2c
I0627 10:43:58.126569 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.126572 23737 net.cpp:165] Memory required for data: 210137100
I0627 10:43:58.126587 23737 layer_factory.hpp:77] Creating layer res4e
I0627 10:43:58.126600 23737 net.cpp:100] Creating Layer res4e
I0627 10:43:58.126610 23737 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0627 10:43:58.126622 23737 net.cpp:444] res4e <- res4e_branch2c
I0627 10:43:58.126636 23737 net.cpp:418] res4e -> res4e
I0627 10:43:58.126688 23737 net.cpp:150] Setting up res4e
I0627 10:43:58.126698 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.126703 23737 net.cpp:165] Memory required for data: 210939916
I0627 10:43:58.126708 23737 layer_factory.hpp:77] Creating layer res4e_relu
I0627 10:43:58.126720 23737 net.cpp:100] Creating Layer res4e_relu
I0627 10:43:58.126729 23737 net.cpp:444] res4e_relu <- res4e
I0627 10:43:58.126744 23737 net.cpp:405] res4e_relu -> res4e (in-place)
I0627 10:43:58.126921 23737 net.cpp:150] Setting up res4e_relu
I0627 10:43:58.126930 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.126935 23737 net.cpp:165] Memory required for data: 211742732
I0627 10:43:58.126940 23737 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0627 10:43:58.126955 23737 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0627 10:43:58.126961 23737 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0627 10:43:58.126979 23737 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0627 10:43:58.126998 23737 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0627 10:43:58.127069 23737 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0627 10:43:58.127079 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.127086 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.127090 23737 net.cpp:165] Memory required for data: 213348364
I0627 10:43:58.127095 23737 layer_factory.hpp:77] Creating layer res4f_branch2a
I0627 10:43:58.127115 23737 net.cpp:100] Creating Layer res4f_branch2a
I0627 10:43:58.127122 23737 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0627 10:43:58.127140 23737 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0627 10:43:58.128655 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.128684 23737 net.cpp:150] Setting up res4f_branch2a
I0627 10:43:58.128695 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.128700 23737 net.cpp:165] Memory required for data: 213549068
I0627 10:43:58.128712 23737 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0627 10:43:58.128731 23737 net.cpp:100] Creating Layer bn4f_branch2a
I0627 10:43:58.128738 23737 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0627 10:43:58.128756 23737 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0627 10:43:58.129077 23737 net.cpp:150] Setting up bn4f_branch2a
I0627 10:43:58.129086 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.129091 23737 net.cpp:165] Memory required for data: 213749772
I0627 10:43:58.129110 23737 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0627 10:43:58.129128 23737 net.cpp:100] Creating Layer scale4f_branch2a
I0627 10:43:58.129135 23737 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0627 10:43:58.129153 23737 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0627 10:43:58.129230 23737 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0627 10:43:58.129429 23737 net.cpp:150] Setting up scale4f_branch2a
I0627 10:43:58.129439 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.129443 23737 net.cpp:165] Memory required for data: 213950476
I0627 10:43:58.129457 23737 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0627 10:43:58.129470 23737 net.cpp:100] Creating Layer res4f_branch2a_relu
I0627 10:43:58.129478 23737 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0627 10:43:58.129493 23737 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0627 10:43:58.129662 23737 net.cpp:150] Setting up res4f_branch2a_relu
I0627 10:43:58.129671 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.129675 23737 net.cpp:165] Memory required for data: 214151180
I0627 10:43:58.129683 23737 layer_factory.hpp:77] Creating layer res4f_branch2b
I0627 10:43:58.129700 23737 net.cpp:100] Creating Layer res4f_branch2b
I0627 10:43:58.129707 23737 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0627 10:43:58.129727 23737 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0627 10:43:58.132679 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0627 10:43:58.133003 23737 net.cpp:150] Setting up res4f_branch2b
I0627 10:43:58.133019 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.133023 23737 net.cpp:165] Memory required for data: 214351884
I0627 10:43:58.133040 23737 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0627 10:43:58.133062 23737 net.cpp:100] Creating Layer bn4f_branch2b
I0627 10:43:58.133072 23737 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0627 10:43:58.133092 23737 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0627 10:43:58.133421 23737 net.cpp:150] Setting up bn4f_branch2b
I0627 10:43:58.133431 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.133436 23737 net.cpp:165] Memory required for data: 214552588
I0627 10:43:58.133456 23737 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0627 10:43:58.133473 23737 net.cpp:100] Creating Layer scale4f_branch2b
I0627 10:43:58.133481 23737 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0627 10:43:58.133498 23737 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0627 10:43:58.133577 23737 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0627 10:43:58.133786 23737 net.cpp:150] Setting up scale4f_branch2b
I0627 10:43:58.133795 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.133800 23737 net.cpp:165] Memory required for data: 214753292
I0627 10:43:58.133816 23737 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0627 10:43:58.133831 23737 net.cpp:100] Creating Layer res4f_branch2b_relu
I0627 10:43:58.133837 23737 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0627 10:43:58.133852 23737 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0627 10:43:58.134025 23737 net.cpp:150] Setting up res4f_branch2b_relu
I0627 10:43:58.134035 23737 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0627 10:43:58.134038 23737 net.cpp:165] Memory required for data: 214953996
I0627 10:43:58.134047 23737 layer_factory.hpp:77] Creating layer res4f_branch2c
I0627 10:43:58.134066 23737 net.cpp:100] Creating Layer res4f_branch2c
I0627 10:43:58.134074 23737 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0627 10:43:58.134093 23737 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0627 10:43:58.136498 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.136530 23737 net.cpp:150] Setting up res4f_branch2c
I0627 10:43:58.136544 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.136548 23737 net.cpp:165] Memory required for data: 215756812
I0627 10:43:58.136564 23737 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0627 10:43:58.136585 23737 net.cpp:100] Creating Layer bn4f_branch2c
I0627 10:43:58.136595 23737 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0627 10:43:58.136613 23737 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0627 10:43:58.136946 23737 net.cpp:150] Setting up bn4f_branch2c
I0627 10:43:58.136955 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.136958 23737 net.cpp:165] Memory required for data: 216559628
I0627 10:43:58.137019 23737 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0627 10:43:58.137038 23737 net.cpp:100] Creating Layer scale4f_branch2c
I0627 10:43:58.137046 23737 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0627 10:43:58.137063 23737 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0627 10:43:58.137137 23737 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0627 10:43:58.137352 23737 net.cpp:150] Setting up scale4f_branch2c
I0627 10:43:58.137362 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.137364 23737 net.cpp:165] Memory required for data: 217362444
I0627 10:43:58.137379 23737 layer_factory.hpp:77] Creating layer res4f
I0627 10:43:58.137393 23737 net.cpp:100] Creating Layer res4f
I0627 10:43:58.137401 23737 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0627 10:43:58.137415 23737 net.cpp:444] res4f <- res4f_branch2c
I0627 10:43:58.137428 23737 net.cpp:418] res4f -> res4f
I0627 10:43:58.137480 23737 net.cpp:150] Setting up res4f
I0627 10:43:58.137490 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.137495 23737 net.cpp:165] Memory required for data: 218165260
I0627 10:43:58.137501 23737 layer_factory.hpp:77] Creating layer res4f_relu
I0627 10:43:58.137513 23737 net.cpp:100] Creating Layer res4f_relu
I0627 10:43:58.137521 23737 net.cpp:444] res4f_relu <- res4f
I0627 10:43:58.137536 23737 net.cpp:405] res4f_relu -> res4f (in-place)
I0627 10:43:58.138046 23737 net.cpp:150] Setting up res4f_relu
I0627 10:43:58.138058 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.138062 23737 net.cpp:165] Memory required for data: 218968076
I0627 10:43:58.138068 23737 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0627 10:43:58.138084 23737 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0627 10:43:58.138092 23737 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0627 10:43:58.138110 23737 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0627 10:43:58.138130 23737 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0627 10:43:58.138146 23737 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0627 10:43:58.138247 23737 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0627 10:43:58.138258 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.138265 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.138270 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:58.138274 23737 net.cpp:165] Memory required for data: 221376524
I0627 10:43:58.138279 23737 layer_factory.hpp:77] Creating layer res5a_branch1
I0627 10:43:58.138301 23737 net.cpp:100] Creating Layer res5a_branch1
I0627 10:43:58.138309 23737 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0627 10:43:58.138327 23737 net.cpp:418] res5a_branch1 -> res5a_branch1
I0627 10:43:58.145140 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 8568
I0627 10:43:58.145182 23737 net.cpp:150] Setting up res5a_branch1
I0627 10:43:58.145200 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.145205 23737 net.cpp:165] Memory required for data: 222982156
I0627 10:43:58.145228 23737 layer_factory.hpp:77] Creating layer bn5a_branch1
I0627 10:43:58.145262 23737 net.cpp:100] Creating Layer bn5a_branch1
I0627 10:43:58.145273 23737 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0627 10:43:58.145298 23737 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0627 10:43:58.145665 23737 net.cpp:150] Setting up bn5a_branch1
I0627 10:43:58.145674 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.145679 23737 net.cpp:165] Memory required for data: 224587788
I0627 10:43:58.145700 23737 layer_factory.hpp:77] Creating layer scale5a_branch1
I0627 10:43:58.145718 23737 net.cpp:100] Creating Layer scale5a_branch1
I0627 10:43:58.145725 23737 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0627 10:43:58.145742 23737 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0627 10:43:58.145820 23737 layer_factory.hpp:77] Creating layer scale5a_branch1
I0627 10:43:58.146041 23737 net.cpp:150] Setting up scale5a_branch1
I0627 10:43:58.146050 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.146054 23737 net.cpp:165] Memory required for data: 226193420
I0627 10:43:58.146070 23737 layer_factory.hpp:77] Creating layer res5a_branch2a
I0627 10:43:58.146090 23737 net.cpp:100] Creating Layer res5a_branch2a
I0627 10:43:58.146098 23737 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0627 10:43:58.146116 23737 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0627 10:43:58.149273 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.149305 23737 net.cpp:150] Setting up res5a_branch2a
I0627 10:43:58.149318 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.149322 23737 net.cpp:165] Memory required for data: 226594828
I0627 10:43:58.149338 23737 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0627 10:43:58.149358 23737 net.cpp:100] Creating Layer bn5a_branch2a
I0627 10:43:58.149366 23737 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0627 10:43:58.149384 23737 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0627 10:43:58.149721 23737 net.cpp:150] Setting up bn5a_branch2a
I0627 10:43:58.149729 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.149734 23737 net.cpp:165] Memory required for data: 226996236
I0627 10:43:58.149755 23737 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0627 10:43:58.149772 23737 net.cpp:100] Creating Layer scale5a_branch2a
I0627 10:43:58.149780 23737 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0627 10:43:58.149796 23737 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0627 10:43:58.149871 23737 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0627 10:43:58.150082 23737 net.cpp:150] Setting up scale5a_branch2a
I0627 10:43:58.150091 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.150094 23737 net.cpp:165] Memory required for data: 227397644
I0627 10:43:58.150110 23737 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0627 10:43:58.150122 23737 net.cpp:100] Creating Layer res5a_branch2a_relu
I0627 10:43:58.150130 23737 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0627 10:43:58.150146 23737 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0627 10:43:58.150315 23737 net.cpp:150] Setting up res5a_branch2a_relu
I0627 10:43:58.150323 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.150326 23737 net.cpp:165] Memory required for data: 227799052
I0627 10:43:58.150333 23737 layer_factory.hpp:77] Creating layer res5a_branch2b
I0627 10:43:58.150352 23737 net.cpp:100] Creating Layer res5a_branch2b
I0627 10:43:58.150360 23737 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0627 10:43:58.150378 23737 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0627 10:43:58.156919 23737 net.cpp:150] Setting up res5a_branch2b
I0627 10:43:58.156953 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.156957 23737 net.cpp:165] Memory required for data: 228200460
I0627 10:43:58.156982 23737 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0627 10:43:58.157018 23737 net.cpp:100] Creating Layer bn5a_branch2b
I0627 10:43:58.157032 23737 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0627 10:43:58.157057 23737 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0627 10:43:58.157424 23737 net.cpp:150] Setting up bn5a_branch2b
I0627 10:43:58.157434 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.157438 23737 net.cpp:165] Memory required for data: 228601868
I0627 10:43:58.157459 23737 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0627 10:43:58.157479 23737 net.cpp:100] Creating Layer scale5a_branch2b
I0627 10:43:58.157485 23737 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0627 10:43:58.157502 23737 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0627 10:43:58.157582 23737 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0627 10:43:58.157800 23737 net.cpp:150] Setting up scale5a_branch2b
I0627 10:43:58.157810 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.157815 23737 net.cpp:165] Memory required for data: 229003276
I0627 10:43:58.157829 23737 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0627 10:43:58.157842 23737 net.cpp:100] Creating Layer res5a_branch2b_relu
I0627 10:43:58.157850 23737 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0627 10:43:58.157863 23737 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0627 10:43:58.158073 23737 net.cpp:150] Setting up res5a_branch2b_relu
I0627 10:43:58.158082 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.158087 23737 net.cpp:165] Memory required for data: 229404684
I0627 10:43:58.158092 23737 layer_factory.hpp:77] Creating layer res5a_branch2c
I0627 10:43:58.158113 23737 net.cpp:100] Creating Layer res5a_branch2c
I0627 10:43:58.158120 23737 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0627 10:43:58.158139 23737 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0627 10:43:58.162343 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0627 10:43:58.162380 23737 net.cpp:150] Setting up res5a_branch2c
I0627 10:43:58.162395 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.162400 23737 net.cpp:165] Memory required for data: 231010316
I0627 10:43:58.162418 23737 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0627 10:43:58.162441 23737 net.cpp:100] Creating Layer bn5a_branch2c
I0627 10:43:58.162452 23737 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0627 10:43:58.162473 23737 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0627 10:43:58.162814 23737 net.cpp:150] Setting up bn5a_branch2c
I0627 10:43:58.162823 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.162827 23737 net.cpp:165] Memory required for data: 232615948
I0627 10:43:58.162847 23737 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0627 10:43:58.162871 23737 net.cpp:100] Creating Layer scale5a_branch2c
I0627 10:43:58.162889 23737 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0627 10:43:58.162906 23737 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0627 10:43:58.162986 23737 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0627 10:43:58.163205 23737 net.cpp:150] Setting up scale5a_branch2c
I0627 10:43:58.163214 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.163218 23737 net.cpp:165] Memory required for data: 234221580
I0627 10:43:58.163233 23737 layer_factory.hpp:77] Creating layer res5a
I0627 10:43:58.163249 23737 net.cpp:100] Creating Layer res5a
I0627 10:43:58.163256 23737 net.cpp:444] res5a <- res5a_branch1
I0627 10:43:58.163269 23737 net.cpp:444] res5a <- res5a_branch2c
I0627 10:43:58.163281 23737 net.cpp:418] res5a -> res5a
I0627 10:43:58.163334 23737 net.cpp:150] Setting up res5a
I0627 10:43:58.163344 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.163348 23737 net.cpp:165] Memory required for data: 235827212
I0627 10:43:58.163354 23737 layer_factory.hpp:77] Creating layer res5a_relu
I0627 10:43:58.163367 23737 net.cpp:100] Creating Layer res5a_relu
I0627 10:43:58.163372 23737 net.cpp:444] res5a_relu <- res5a
I0627 10:43:58.163388 23737 net.cpp:405] res5a_relu -> res5a (in-place)
I0627 10:43:58.163890 23737 net.cpp:150] Setting up res5a_relu
I0627 10:43:58.163902 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.163904 23737 net.cpp:165] Memory required for data: 237432844
I0627 10:43:58.163911 23737 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0627 10:43:58.163926 23737 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0627 10:43:58.163933 23737 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0627 10:43:58.163950 23737 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0627 10:43:58.163969 23737 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0627 10:43:58.164044 23737 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0627 10:43:58.164054 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.164062 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.164065 23737 net.cpp:165] Memory required for data: 240644108
I0627 10:43:58.164070 23737 layer_factory.hpp:77] Creating layer res5b_branch2a
I0627 10:43:58.164090 23737 net.cpp:100] Creating Layer res5b_branch2a
I0627 10:43:58.164098 23737 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0627 10:43:58.164115 23737 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0627 10:43:58.168231 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.168269 23737 net.cpp:150] Setting up res5b_branch2a
I0627 10:43:58.168283 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.168287 23737 net.cpp:165] Memory required for data: 241045516
I0627 10:43:58.168306 23737 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0627 10:43:58.168334 23737 net.cpp:100] Creating Layer bn5b_branch2a
I0627 10:43:58.168344 23737 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0627 10:43:58.168365 23737 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0627 10:43:58.168714 23737 net.cpp:150] Setting up bn5b_branch2a
I0627 10:43:58.168722 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.168726 23737 net.cpp:165] Memory required for data: 241446924
I0627 10:43:58.168750 23737 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0627 10:43:58.168768 23737 net.cpp:100] Creating Layer scale5b_branch2a
I0627 10:43:58.168776 23737 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0627 10:43:58.168792 23737 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0627 10:43:58.168870 23737 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0627 10:43:58.169087 23737 net.cpp:150] Setting up scale5b_branch2a
I0627 10:43:58.169096 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.169100 23737 net.cpp:165] Memory required for data: 241848332
I0627 10:43:58.169114 23737 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0627 10:43:58.169127 23737 net.cpp:100] Creating Layer res5b_branch2a_relu
I0627 10:43:58.169136 23737 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0627 10:43:58.169149 23737 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0627 10:43:58.169322 23737 net.cpp:150] Setting up res5b_branch2a_relu
I0627 10:43:58.169330 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.169334 23737 net.cpp:165] Memory required for data: 242249740
I0627 10:43:58.169342 23737 layer_factory.hpp:77] Creating layer res5b_branch2b
I0627 10:43:58.169359 23737 net.cpp:100] Creating Layer res5b_branch2b
I0627 10:43:58.169368 23737 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0627 10:43:58.169386 23737 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0627 10:43:58.175850 23737 net.cpp:150] Setting up res5b_branch2b
I0627 10:43:58.175881 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.175885 23737 net.cpp:165] Memory required for data: 242651148
I0627 10:43:58.175911 23737 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0627 10:43:58.175948 23737 net.cpp:100] Creating Layer bn5b_branch2b
I0627 10:43:58.175961 23737 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0627 10:43:58.175987 23737 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0627 10:43:58.176348 23737 net.cpp:150] Setting up bn5b_branch2b
I0627 10:43:58.176357 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.176362 23737 net.cpp:165] Memory required for data: 243052556
I0627 10:43:58.176381 23737 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0627 10:43:58.176400 23737 net.cpp:100] Creating Layer scale5b_branch2b
I0627 10:43:58.176409 23737 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0627 10:43:58.176425 23737 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0627 10:43:58.176504 23737 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0627 10:43:58.176724 23737 net.cpp:150] Setting up scale5b_branch2b
I0627 10:43:58.176733 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.176738 23737 net.cpp:165] Memory required for data: 243453964
I0627 10:43:58.176753 23737 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0627 10:43:58.176765 23737 net.cpp:100] Creating Layer res5b_branch2b_relu
I0627 10:43:58.176772 23737 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0627 10:43:58.176787 23737 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0627 10:43:58.177002 23737 net.cpp:150] Setting up res5b_branch2b_relu
I0627 10:43:58.177011 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.177014 23737 net.cpp:165] Memory required for data: 243855372
I0627 10:43:58.177021 23737 layer_factory.hpp:77] Creating layer res5b_branch2c
I0627 10:43:58.177042 23737 net.cpp:100] Creating Layer res5b_branch2c
I0627 10:43:58.177049 23737 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0627 10:43:58.177068 23737 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0627 10:43:58.181324 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0627 10:43:58.181362 23737 net.cpp:150] Setting up res5b_branch2c
I0627 10:43:58.181378 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.181382 23737 net.cpp:165] Memory required for data: 245461004
I0627 10:43:58.181403 23737 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0627 10:43:58.181430 23737 net.cpp:100] Creating Layer bn5b_branch2c
I0627 10:43:58.181442 23737 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0627 10:43:58.181462 23737 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0627 10:43:58.181823 23737 net.cpp:150] Setting up bn5b_branch2c
I0627 10:43:58.181833 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.181836 23737 net.cpp:165] Memory required for data: 247066636
I0627 10:43:58.181857 23737 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0627 10:43:58.181875 23737 net.cpp:100] Creating Layer scale5b_branch2c
I0627 10:43:58.181882 23737 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0627 10:43:58.181900 23737 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0627 10:43:58.181979 23737 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0627 10:43:58.182199 23737 net.cpp:150] Setting up scale5b_branch2c
I0627 10:43:58.182209 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.182212 23737 net.cpp:165] Memory required for data: 248672268
I0627 10:43:58.182226 23737 layer_factory.hpp:77] Creating layer res5b
I0627 10:43:58.182240 23737 net.cpp:100] Creating Layer res5b
I0627 10:43:58.182248 23737 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0627 10:43:58.182262 23737 net.cpp:444] res5b <- res5b_branch2c
I0627 10:43:58.182276 23737 net.cpp:418] res5b -> res5b
I0627 10:43:58.182327 23737 net.cpp:150] Setting up res5b
I0627 10:43:58.182337 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.182341 23737 net.cpp:165] Memory required for data: 250277900
I0627 10:43:58.182348 23737 layer_factory.hpp:77] Creating layer res5b_relu
I0627 10:43:58.182360 23737 net.cpp:100] Creating Layer res5b_relu
I0627 10:43:58.182368 23737 net.cpp:444] res5b_relu <- res5b
I0627 10:43:58.182382 23737 net.cpp:405] res5b_relu -> res5b (in-place)
I0627 10:43:58.182914 23737 net.cpp:150] Setting up res5b_relu
I0627 10:43:58.182925 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.182929 23737 net.cpp:165] Memory required for data: 251883532
I0627 10:43:58.182937 23737 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0627 10:43:58.182951 23737 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0627 10:43:58.182958 23737 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0627 10:43:58.182977 23737 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0627 10:43:58.182997 23737 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0627 10:43:58.183074 23737 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0627 10:43:58.183084 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.183092 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.183096 23737 net.cpp:165] Memory required for data: 255094796
I0627 10:43:58.183102 23737 layer_factory.hpp:77] Creating layer res5c_branch2a
I0627 10:43:58.183122 23737 net.cpp:100] Creating Layer res5c_branch2a
I0627 10:43:58.183130 23737 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0627 10:43:58.183149 23737 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0627 10:43:58.187268 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.187306 23737 net.cpp:150] Setting up res5c_branch2a
I0627 10:43:58.187320 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.187325 23737 net.cpp:165] Memory required for data: 255496204
I0627 10:43:58.187345 23737 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0627 10:43:58.187369 23737 net.cpp:100] Creating Layer bn5c_branch2a
I0627 10:43:58.187381 23737 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0627 10:43:58.187402 23737 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0627 10:43:58.187757 23737 net.cpp:150] Setting up bn5c_branch2a
I0627 10:43:58.187765 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.187769 23737 net.cpp:165] Memory required for data: 255897612
I0627 10:43:58.187790 23737 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0627 10:43:58.187809 23737 net.cpp:100] Creating Layer scale5c_branch2a
I0627 10:43:58.187816 23737 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0627 10:43:58.187834 23737 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0627 10:43:58.187913 23737 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0627 10:43:58.188164 23737 net.cpp:150] Setting up scale5c_branch2a
I0627 10:43:58.188174 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.188177 23737 net.cpp:165] Memory required for data: 256299020
I0627 10:43:58.188192 23737 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0627 10:43:58.188207 23737 net.cpp:100] Creating Layer res5c_branch2a_relu
I0627 10:43:58.188215 23737 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0627 10:43:58.188228 23737 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0627 10:43:58.188417 23737 net.cpp:150] Setting up res5c_branch2a_relu
I0627 10:43:58.188426 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.188429 23737 net.cpp:165] Memory required for data: 256700428
I0627 10:43:58.188436 23737 layer_factory.hpp:77] Creating layer res5c_branch2b
I0627 10:43:58.188458 23737 net.cpp:100] Creating Layer res5c_branch2b
I0627 10:43:58.188465 23737 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0627 10:43:58.188485 23737 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0627 10:43:58.194967 23737 net.cpp:150] Setting up res5c_branch2b
I0627 10:43:58.195003 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.195005 23737 net.cpp:165] Memory required for data: 257101836
I0627 10:43:58.195032 23737 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0627 10:43:58.195068 23737 net.cpp:100] Creating Layer bn5c_branch2b
I0627 10:43:58.195082 23737 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0627 10:43:58.195104 23737 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0627 10:43:58.195472 23737 net.cpp:150] Setting up bn5c_branch2b
I0627 10:43:58.195480 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.195484 23737 net.cpp:165] Memory required for data: 257503244
I0627 10:43:58.195505 23737 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0627 10:43:58.195524 23737 net.cpp:100] Creating Layer scale5c_branch2b
I0627 10:43:58.195533 23737 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0627 10:43:58.195549 23737 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0627 10:43:58.195629 23737 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0627 10:43:58.195850 23737 net.cpp:150] Setting up scale5c_branch2b
I0627 10:43:58.195859 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.195863 23737 net.cpp:165] Memory required for data: 257904652
I0627 10:43:58.195878 23737 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0627 10:43:58.195893 23737 net.cpp:100] Creating Layer res5c_branch2b_relu
I0627 10:43:58.195900 23737 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0627 10:43:58.195915 23737 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0627 10:43:58.196135 23737 net.cpp:150] Setting up res5c_branch2b_relu
I0627 10:43:58.196143 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.196146 23737 net.cpp:165] Memory required for data: 258306060
I0627 10:43:58.196153 23737 layer_factory.hpp:77] Creating layer res5c_branch2c
I0627 10:43:58.196175 23737 net.cpp:100] Creating Layer res5c_branch2c
I0627 10:43:58.196183 23737 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0627 10:43:58.196202 23737 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0627 10:43:58.200470 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0627 10:43:58.200508 23737 net.cpp:150] Setting up res5c_branch2c
I0627 10:43:58.200522 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.200526 23737 net.cpp:165] Memory required for data: 259911692
I0627 10:43:58.200546 23737 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0627 10:43:58.200570 23737 net.cpp:100] Creating Layer bn5c_branch2c
I0627 10:43:58.200580 23737 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0627 10:43:58.200603 23737 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0627 10:43:58.200965 23737 net.cpp:150] Setting up bn5c_branch2c
I0627 10:43:58.200974 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.200978 23737 net.cpp:165] Memory required for data: 261517324
I0627 10:43:58.200999 23737 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0627 10:43:58.201019 23737 net.cpp:100] Creating Layer scale5c_branch2c
I0627 10:43:58.201026 23737 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0627 10:43:58.201043 23737 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0627 10:43:58.201126 23737 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0627 10:43:58.201356 23737 net.cpp:150] Setting up scale5c_branch2c
I0627 10:43:58.201365 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.201370 23737 net.cpp:165] Memory required for data: 263122956
I0627 10:43:58.201383 23737 layer_factory.hpp:77] Creating layer res5c
I0627 10:43:58.201397 23737 net.cpp:100] Creating Layer res5c
I0627 10:43:58.201406 23737 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0627 10:43:58.201419 23737 net.cpp:444] res5c <- res5c_branch2c
I0627 10:43:58.201432 23737 net.cpp:418] res5c -> res5c
I0627 10:43:58.201488 23737 net.cpp:150] Setting up res5c
I0627 10:43:58.201498 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.201503 23737 net.cpp:165] Memory required for data: 264728588
I0627 10:43:58.201509 23737 layer_factory.hpp:77] Creating layer res5c_relu
I0627 10:43:58.201521 23737 net.cpp:100] Creating Layer res5c_relu
I0627 10:43:58.201529 23737 net.cpp:444] res5c_relu <- res5c
I0627 10:43:58.201545 23737 net.cpp:405] res5c_relu -> res5c (in-place)
I0627 10:43:58.201719 23737 net.cpp:150] Setting up res5c_relu
I0627 10:43:58.201727 23737 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0627 10:43:58.201730 23737 net.cpp:165] Memory required for data: 266334220
I0627 10:43:58.201737 23737 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0627 10:43:58.201759 23737 net.cpp:100] Creating Layer rpn_conv/3x3
I0627 10:43:58.201767 23737 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0627 10:43:58.201789 23737 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0627 10:43:58.789348 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0627 10:43:58.789762 23737 net.cpp:150] Setting up rpn_conv/3x3
I0627 10:43:58.789784 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.789789 23737 net.cpp:165] Memory required for data: 266735628
I0627 10:43:58.789818 23737 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0627 10:43:58.789844 23737 net.cpp:100] Creating Layer rpn_relu/3x3
I0627 10:43:58.789857 23737 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0627 10:43:58.789881 23737 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0627 10:43:58.790410 23737 net.cpp:150] Setting up rpn_relu/3x3
I0627 10:43:58.790419 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.790424 23737 net.cpp:165] Memory required for data: 267137036
I0627 10:43:58.790431 23737 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0627 10:43:58.790448 23737 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0627 10:43:58.790457 23737 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0627 10:43:58.790474 23737 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0627 10:43:58.790496 23737 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0627 10:43:58.790601 23737 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0627 10:43:58.790612 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.790619 23737 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0627 10:43:58.790623 23737 net.cpp:165] Memory required for data: 267939852
I0627 10:43:58.790628 23737 layer_factory.hpp:77] Creating layer rpn_cls_score
I0627 10:43:58.790657 23737 net.cpp:100] Creating Layer rpn_cls_score
I0627 10:43:58.790664 23737 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0627 10:43:58.790683 23737 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0627 10:43:58.793421 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.793452 23737 net.cpp:150] Setting up rpn_cls_score
I0627 10:43:58.793463 23737 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0627 10:43:58.793467 23737 net.cpp:165] Memory required for data: 267957100
I0627 10:43:58.793483 23737 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0627 10:43:58.793506 23737 net.cpp:100] Creating Layer rpn_bbox_pred
I0627 10:43:58.793514 23737 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0627 10:43:58.793534 23737 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0627 10:43:58.798508 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:58.798550 23737 net.cpp:150] Setting up rpn_bbox_pred
I0627 10:43:58.798583 23737 net.cpp:157] Top shape: 1 44 14 14 (8624)
I0627 10:43:58.798588 23737 net.cpp:165] Memory required for data: 267991596
I0627 10:43:58.798614 23737 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0627 10:43:58.798645 23737 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0627 10:43:58.798657 23737 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score
I0627 10:43:58.798682 23737 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0627 10:43:58.798756 23737 net.cpp:150] Setting up rpn_cls_score_reshape
I0627 10:43:58.798768 23737 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0627 10:43:58.798771 23737 net.cpp:165] Memory required for data: 268008844
I0627 10:43:58.798777 23737 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0627 10:43:58.798790 23737 net.cpp:100] Creating Layer rpn_cls_prob
I0627 10:43:58.798797 23737 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape
I0627 10:43:58.798813 23737 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0627 10:43:58.799136 23737 net.cpp:150] Setting up rpn_cls_prob
I0627 10:43:58.799149 23737 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0627 10:43:58.799154 23737 net.cpp:165] Memory required for data: 268026092
I0627 10:43:58.799160 23737 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0627 10:43:58.799176 23737 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0627 10:43:58.799185 23737 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0627 10:43:58.799203 23737 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0627 10:43:58.799258 23737 net.cpp:150] Setting up rpn_cls_prob_reshape
I0627 10:43:58.799268 23737 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0627 10:43:58.799273 23737 net.cpp:165] Memory required for data: 268043340
I0627 10:43:58.799278 23737 layer_factory.hpp:77] Creating layer proposal
I0627 10:43:58.799623 23737 net.cpp:100] Creating Layer proposal
I0627 10:43:58.799634 23737 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0627 10:43:58.799651 23737 net.cpp:444] proposal <- rpn_bbox_pred
I0627 10:43:58.799661 23737 net.cpp:444] proposal <- im_info
I0627 10:43:58.799675 23737 net.cpp:418] proposal -> rois
I0627 10:43:58.801177 23737 net.cpp:150] Setting up proposal
I0627 10:43:58.801208 23737 net.cpp:157] Top shape: 1 5 (5)
I0627 10:43:58.801213 23737 net.cpp:165] Memory required for data: 268043360
I0627 10:43:58.801228 23737 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0627 10:43:58.801255 23737 net.cpp:100] Creating Layer rois_proposal_0_split
I0627 10:43:58.801268 23737 net.cpp:444] rois_proposal_0_split <- rois
I0627 10:43:58.801298 23737 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_0
I0627 10:43:58.801326 23737 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_1
I0627 10:43:58.801451 23737 net.cpp:150] Setting up rois_proposal_0_split
I0627 10:43:58.801462 23737 net.cpp:157] Top shape: 1 5 (5)
I0627 10:43:58.801468 23737 net.cpp:157] Top shape: 1 5 (5)
I0627 10:43:58.801472 23737 net.cpp:165] Memory required for data: 268043400
I0627 10:43:58.801478 23737 layer_factory.hpp:77] Creating layer conv_new_1
I0627 10:43:58.801508 23737 net.cpp:100] Creating Layer conv_new_1
I0627 10:43:58.801517 23737 net.cpp:444] conv_new_1 <- res5c
I0627 10:43:58.801537 23737 net.cpp:418] conv_new_1 -> conv_new_1
I0627 10:43:59.068290 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:59.068331 23737 net.cpp:150] Setting up conv_new_1
I0627 10:43:59.068351 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:59.068356 23737 net.cpp:165] Memory required for data: 268846216
I0627 10:43:59.068384 23737 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0627 10:43:59.068413 23737 net.cpp:100] Creating Layer conv_new_1_relu
I0627 10:43:59.068425 23737 net.cpp:444] conv_new_1_relu <- conv_new_1
I0627 10:43:59.068447 23737 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0627 10:43:59.068622 23737 net.cpp:150] Setting up conv_new_1_relu
I0627 10:43:59.068629 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:59.068631 23737 net.cpp:165] Memory required for data: 269649032
I0627 10:43:59.068636 23737 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0627 10:43:59.068647 23737 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0627 10:43:59.068652 23737 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0627 10:43:59.068666 23737 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0627 10:43:59.068682 23737 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0627 10:43:59.068768 23737 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0627 10:43:59.068775 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:59.068779 23737 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0627 10:43:59.068781 23737 net.cpp:165] Memory required for data: 271254664
I0627 10:43:59.068812 23737 layer_factory.hpp:77] Creating layer rfcn_cls
I0627 10:43:59.068843 23737 net.cpp:100] Creating Layer rfcn_cls
I0627 10:43:59.068852 23737 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0627 10:43:59.068876 23737 net.cpp:418] rfcn_cls -> rfcn_cls
I0627 10:43:59.083149 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:59.083194 23737 net.cpp:150] Setting up rfcn_cls
I0627 10:43:59.083212 23737 net.cpp:157] Top shape: 1 98 14 14 (19208)
I0627 10:43:59.083216 23737 net.cpp:165] Memory required for data: 271331496
I0627 10:43:59.083243 23737 layer_factory.hpp:77] Creating layer rfcn_bbox
I0627 10:43:59.083310 23737 net.cpp:100] Creating Layer rfcn_bbox
I0627 10:43:59.083323 23737 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0627 10:43:59.083350 23737 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0627 10:43:59.136816 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0627 10:43:59.136860 23737 net.cpp:150] Setting up rfcn_bbox
I0627 10:43:59.136879 23737 net.cpp:157] Top shape: 1 392 14 14 (76832)
I0627 10:43:59.136888 23737 net.cpp:165] Memory required for data: 271638824
I0627 10:43:59.136916 23737 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0627 10:43:59.136946 23737 net.cpp:100] Creating Layer psroipooled_cls_rois
I0627 10:43:59.136960 23737 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0627 10:43:59.136978 23737 net.cpp:444] psroipooled_cls_rois <- rois_proposal_0_split_0
I0627 10:43:59.136996 23737 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0627 10:43:59.137022 23737 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0627 10:43:59.137115 23737 net.cpp:150] Setting up psroipooled_cls_rois
I0627 10:43:59.137126 23737 net.cpp:157] Top shape: 1 2 7 7 (98)
I0627 10:43:59.137130 23737 net.cpp:165] Memory required for data: 271639216
I0627 10:43:59.137135 23737 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0627 10:43:59.137153 23737 net.cpp:100] Creating Layer ave_cls_score_rois
I0627 10:43:59.137161 23737 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0627 10:43:59.137179 23737 net.cpp:418] ave_cls_score_rois -> cls_score
I0627 10:43:59.137778 23737 net.cpp:150] Setting up ave_cls_score_rois
I0627 10:43:59.137791 23737 net.cpp:157] Top shape: 1 2 1 1 (2)
I0627 10:43:59.137797 23737 net.cpp:165] Memory required for data: 271639224
I0627 10:43:59.137804 23737 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0627 10:43:59.137820 23737 net.cpp:100] Creating Layer psroipooled_loc_rois
I0627 10:43:59.137830 23737 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0627 10:43:59.137845 23737 net.cpp:444] psroipooled_loc_rois <- rois_proposal_0_split_1
I0627 10:43:59.137862 23737 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0627 10:43:59.137886 23737 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0627 10:43:59.137964 23737 net.cpp:150] Setting up psroipooled_loc_rois
I0627 10:43:59.137974 23737 net.cpp:157] Top shape: 1 8 7 7 (392)
I0627 10:43:59.137979 23737 net.cpp:165] Memory required for data: 271640792
I0627 10:43:59.137985 23737 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0627 10:43:59.138002 23737 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0627 10:43:59.138010 23737 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0627 10:43:59.138028 23737 net.cpp:418] ave_bbox_pred_rois -> bbox_pred_pre
I0627 10:43:59.138240 23737 net.cpp:150] Setting up ave_bbox_pred_rois
I0627 10:43:59.138252 23737 net.cpp:157] Top shape: 1 8 1 1 (8)
I0627 10:43:59.138255 23737 net.cpp:165] Memory required for data: 271640824
I0627 10:43:59.138262 23737 layer_factory.hpp:77] Creating layer cls_prob
I0627 10:43:59.138276 23737 net.cpp:100] Creating Layer cls_prob
I0627 10:43:59.138283 23737 net.cpp:444] cls_prob <- cls_score
I0627 10:43:59.138301 23737 net.cpp:418] cls_prob -> cls_prob_pre
I0627 10:43:59.138587 23737 net.cpp:150] Setting up cls_prob
I0627 10:43:59.138599 23737 net.cpp:157] Top shape: 1 2 1 1 (2)
I0627 10:43:59.138603 23737 net.cpp:165] Memory required for data: 271640832
I0627 10:43:59.138609 23737 layer_factory.hpp:77] Creating layer cls_prob_reshape
I0627 10:43:59.138628 23737 net.cpp:100] Creating Layer cls_prob_reshape
I0627 10:43:59.138635 23737 net.cpp:444] cls_prob_reshape <- cls_prob_pre
I0627 10:43:59.138655 23737 net.cpp:418] cls_prob_reshape -> cls_prob
I0627 10:43:59.138713 23737 net.cpp:150] Setting up cls_prob_reshape
I0627 10:43:59.138722 23737 net.cpp:157] Top shape: 1 2 (2)
I0627 10:43:59.138727 23737 net.cpp:165] Memory required for data: 271640840
I0627 10:43:59.138733 23737 layer_factory.hpp:77] Creating layer bbox_pred_reshape
I0627 10:43:59.138747 23737 net.cpp:100] Creating Layer bbox_pred_reshape
I0627 10:43:59.138754 23737 net.cpp:444] bbox_pred_reshape <- bbox_pred_pre
I0627 10:43:59.138773 23737 net.cpp:418] bbox_pred_reshape -> bbox_pred
I0627 10:43:59.138830 23737 net.cpp:150] Setting up bbox_pred_reshape
I0627 10:43:59.138841 23737 net.cpp:157] Top shape: 1 8 (8)
I0627 10:43:59.138845 23737 net.cpp:165] Memory required for data: 271640872
I0627 10:43:59.138852 23737 net.cpp:228] bbox_pred_reshape does not need backward computation.
I0627 10:43:59.138864 23737 net.cpp:228] cls_prob_reshape does not need backward computation.
I0627 10:43:59.138870 23737 net.cpp:228] cls_prob does not need backward computation.
I0627 10:43:59.138875 23737 net.cpp:228] ave_bbox_pred_rois does not need backward computation.
I0627 10:43:59.138880 23737 net.cpp:228] psroipooled_loc_rois does not need backward computation.
I0627 10:43:59.138885 23737 net.cpp:228] ave_cls_score_rois does not need backward computation.
I0627 10:43:59.138890 23737 net.cpp:228] psroipooled_cls_rois does not need backward computation.
I0627 10:43:59.138895 23737 net.cpp:228] rfcn_bbox does not need backward computation.
I0627 10:43:59.138900 23737 net.cpp:228] rfcn_cls does not need backward computation.
I0627 10:43:59.138907 23737 net.cpp:228] conv_new_1_conv_new_1_relu_0_split does not need backward computation.
I0627 10:43:59.138913 23737 net.cpp:228] conv_new_1_relu does not need backward computation.
I0627 10:43:59.138918 23737 net.cpp:228] conv_new_1 does not need backward computation.
I0627 10:43:59.138924 23737 net.cpp:228] rois_proposal_0_split does not need backward computation.
I0627 10:43:59.138931 23737 net.cpp:228] proposal does not need backward computation.
I0627 10:43:59.138938 23737 net.cpp:228] rpn_cls_prob_reshape does not need backward computation.
I0627 10:43:59.138943 23737 net.cpp:228] rpn_cls_prob does not need backward computation.
I0627 10:43:59.138949 23737 net.cpp:228] rpn_cls_score_reshape does not need backward computation.
I0627 10:43:59.138955 23737 net.cpp:228] rpn_bbox_pred does not need backward computation.
I0627 10:43:59.138962 23737 net.cpp:228] rpn_cls_score does not need backward computation.
I0627 10:43:59.138968 23737 net.cpp:228] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0627 10:43:59.138974 23737 net.cpp:228] rpn_relu/3x3 does not need backward computation.
I0627 10:43:59.138978 23737 net.cpp:228] rpn_conv/3x3 does not need backward computation.
I0627 10:43:59.138985 23737 net.cpp:228] res5c_relu does not need backward computation.
I0627 10:43:59.138991 23737 net.cpp:228] res5c does not need backward computation.
I0627 10:43:59.138998 23737 net.cpp:228] scale5c_branch2c does not need backward computation.
I0627 10:43:59.139003 23737 net.cpp:228] bn5c_branch2c does not need backward computation.
I0627 10:43:59.139008 23737 net.cpp:228] res5c_branch2c does not need backward computation.
I0627 10:43:59.139014 23737 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I0627 10:43:59.139019 23737 net.cpp:228] scale5c_branch2b does not need backward computation.
I0627 10:43:59.139024 23737 net.cpp:228] bn5c_branch2b does not need backward computation.
I0627 10:43:59.139027 23737 net.cpp:228] res5c_branch2b does not need backward computation.
I0627 10:43:59.139034 23737 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I0627 10:43:59.139039 23737 net.cpp:228] scale5c_branch2a does not need backward computation.
I0627 10:43:59.139045 23737 net.cpp:228] bn5c_branch2a does not need backward computation.
I0627 10:43:59.139050 23737 net.cpp:228] res5c_branch2a does not need backward computation.
I0627 10:43:59.139056 23737 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I0627 10:43:59.139062 23737 net.cpp:228] res5b_relu does not need backward computation.
I0627 10:43:59.139067 23737 net.cpp:228] res5b does not need backward computation.
I0627 10:43:59.139076 23737 net.cpp:228] scale5b_branch2c does not need backward computation.
I0627 10:43:59.139081 23737 net.cpp:228] bn5b_branch2c does not need backward computation.
I0627 10:43:59.139086 23737 net.cpp:228] res5b_branch2c does not need backward computation.
I0627 10:43:59.139092 23737 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I0627 10:43:59.139098 23737 net.cpp:228] scale5b_branch2b does not need backward computation.
I0627 10:43:59.139103 23737 net.cpp:228] bn5b_branch2b does not need backward computation.
I0627 10:43:59.139108 23737 net.cpp:228] res5b_branch2b does not need backward computation.
I0627 10:43:59.139114 23737 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I0627 10:43:59.139120 23737 net.cpp:228] scale5b_branch2a does not need backward computation.
I0627 10:43:59.139125 23737 net.cpp:228] bn5b_branch2a does not need backward computation.
I0627 10:43:59.139130 23737 net.cpp:228] res5b_branch2a does not need backward computation.
I0627 10:43:59.139137 23737 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I0627 10:43:59.139143 23737 net.cpp:228] res5a_relu does not need backward computation.
I0627 10:43:59.139148 23737 net.cpp:228] res5a does not need backward computation.
I0627 10:43:59.139155 23737 net.cpp:228] scale5a_branch2c does not need backward computation.
I0627 10:43:59.139160 23737 net.cpp:228] bn5a_branch2c does not need backward computation.
I0627 10:43:59.139165 23737 net.cpp:228] res5a_branch2c does not need backward computation.
I0627 10:43:59.139173 23737 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I0627 10:43:59.139178 23737 net.cpp:228] scale5a_branch2b does not need backward computation.
I0627 10:43:59.139183 23737 net.cpp:228] bn5a_branch2b does not need backward computation.
I0627 10:43:59.139189 23737 net.cpp:228] res5a_branch2b does not need backward computation.
I0627 10:43:59.139194 23737 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I0627 10:43:59.139199 23737 net.cpp:228] scale5a_branch2a does not need backward computation.
I0627 10:43:59.139204 23737 net.cpp:228] bn5a_branch2a does not need backward computation.
I0627 10:43:59.139210 23737 net.cpp:228] res5a_branch2a does not need backward computation.
I0627 10:43:59.139216 23737 net.cpp:228] scale5a_branch1 does not need backward computation.
I0627 10:43:59.139221 23737 net.cpp:228] bn5a_branch1 does not need backward computation.
I0627 10:43:59.139226 23737 net.cpp:228] res5a_branch1 does not need backward computation.
I0627 10:43:59.139235 23737 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I0627 10:43:59.139240 23737 net.cpp:228] res4f_relu does not need backward computation.
I0627 10:43:59.139245 23737 net.cpp:228] res4f does not need backward computation.
I0627 10:43:59.139252 23737 net.cpp:228] scale4f_branch2c does not need backward computation.
I0627 10:43:59.139258 23737 net.cpp:228] bn4f_branch2c does not need backward computation.
I0627 10:43:59.139263 23737 net.cpp:228] res4f_branch2c does not need backward computation.
I0627 10:43:59.139269 23737 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I0627 10:43:59.139274 23737 net.cpp:228] scale4f_branch2b does not need backward computation.
I0627 10:43:59.139279 23737 net.cpp:228] bn4f_branch2b does not need backward computation.
I0627 10:43:59.139286 23737 net.cpp:228] res4f_branch2b does not need backward computation.
I0627 10:43:59.139292 23737 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I0627 10:43:59.139297 23737 net.cpp:228] scale4f_branch2a does not need backward computation.
I0627 10:43:59.139302 23737 net.cpp:228] bn4f_branch2a does not need backward computation.
I0627 10:43:59.139308 23737 net.cpp:228] res4f_branch2a does not need backward computation.
I0627 10:43:59.139314 23737 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I0627 10:43:59.139320 23737 net.cpp:228] res4e_relu does not need backward computation.
I0627 10:43:59.139327 23737 net.cpp:228] res4e does not need backward computation.
I0627 10:43:59.139334 23737 net.cpp:228] scale4e_branch2c does not need backward computation.
I0627 10:43:59.139339 23737 net.cpp:228] bn4e_branch2c does not need backward computation.
I0627 10:43:59.139344 23737 net.cpp:228] res4e_branch2c does not need backward computation.
I0627 10:43:59.139351 23737 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I0627 10:43:59.139358 23737 net.cpp:228] scale4e_branch2b does not need backward computation.
I0627 10:43:59.139362 23737 net.cpp:228] bn4e_branch2b does not need backward computation.
I0627 10:43:59.139367 23737 net.cpp:228] res4e_branch2b does not need backward computation.
I0627 10:43:59.139374 23737 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I0627 10:43:59.139379 23737 net.cpp:228] scale4e_branch2a does not need backward computation.
I0627 10:43:59.139384 23737 net.cpp:228] bn4e_branch2a does not need backward computation.
I0627 10:43:59.139389 23737 net.cpp:228] res4e_branch2a does not need backward computation.
I0627 10:43:59.139396 23737 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I0627 10:43:59.139401 23737 net.cpp:228] res4d_relu does not need backward computation.
I0627 10:43:59.139407 23737 net.cpp:228] res4d does not need backward computation.
I0627 10:43:59.139415 23737 net.cpp:228] scale4d_branch2c does not need backward computation.
I0627 10:43:59.139420 23737 net.cpp:228] bn4d_branch2c does not need backward computation.
I0627 10:43:59.139425 23737 net.cpp:228] res4d_branch2c does not need backward computation.
I0627 10:43:59.139430 23737 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I0627 10:43:59.139436 23737 net.cpp:228] scale4d_branch2b does not need backward computation.
I0627 10:43:59.139441 23737 net.cpp:228] bn4d_branch2b does not need backward computation.
I0627 10:43:59.139446 23737 net.cpp:228] res4d_branch2b does not need backward computation.
I0627 10:43:59.139452 23737 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I0627 10:43:59.139456 23737 net.cpp:228] scale4d_branch2a does not need backward computation.
I0627 10:43:59.139458 23737 net.cpp:228] bn4d_branch2a does not need backward computation.
I0627 10:43:59.139461 23737 net.cpp:228] res4d_branch2a does not need backward computation.
I0627 10:43:59.139467 23737 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I0627 10:43:59.139472 23737 net.cpp:228] res4c_relu does not need backward computation.
I0627 10:43:59.139478 23737 net.cpp:228] res4c does not need backward computation.
I0627 10:43:59.139485 23737 net.cpp:228] scale4c_branch2c does not need backward computation.
I0627 10:43:59.139490 23737 net.cpp:228] bn4c_branch2c does not need backward computation.
I0627 10:43:59.139495 23737 net.cpp:228] res4c_branch2c does not need backward computation.
I0627 10:43:59.139502 23737 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I0627 10:43:59.139505 23737 net.cpp:228] scale4c_branch2b does not need backward computation.
I0627 10:43:59.139508 23737 net.cpp:228] bn4c_branch2b does not need backward computation.
I0627 10:43:59.139511 23737 net.cpp:228] res4c_branch2b does not need backward computation.
I0627 10:43:59.139514 23737 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I0627 10:43:59.139518 23737 net.cpp:228] scale4c_branch2a does not need backward computation.
I0627 10:43:59.139521 23737 net.cpp:228] bn4c_branch2a does not need backward computation.
I0627 10:43:59.139525 23737 net.cpp:228] res4c_branch2a does not need backward computation.
I0627 10:43:59.139533 23737 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I0627 10:43:59.139539 23737 net.cpp:228] res4b_relu does not need backward computation.
I0627 10:43:59.139544 23737 net.cpp:228] res4b does not need backward computation.
I0627 10:43:59.139550 23737 net.cpp:228] scale4b_branch2c does not need backward computation.
I0627 10:43:59.139555 23737 net.cpp:228] bn4b_branch2c does not need backward computation.
I0627 10:43:59.139561 23737 net.cpp:228] res4b_branch2c does not need backward computation.
I0627 10:43:59.139567 23737 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I0627 10:43:59.139572 23737 net.cpp:228] scale4b_branch2b does not need backward computation.
I0627 10:43:59.139578 23737 net.cpp:228] bn4b_branch2b does not need backward computation.
I0627 10:43:59.139583 23737 net.cpp:228] res4b_branch2b does not need backward computation.
I0627 10:43:59.139590 23737 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I0627 10:43:59.139595 23737 net.cpp:228] scale4b_branch2a does not need backward computation.
I0627 10:43:59.139600 23737 net.cpp:228] bn4b_branch2a does not need backward computation.
I0627 10:43:59.139605 23737 net.cpp:228] res4b_branch2a does not need backward computation.
I0627 10:43:59.139612 23737 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I0627 10:43:59.139618 23737 net.cpp:228] res4a_relu does not need backward computation.
I0627 10:43:59.139623 23737 net.cpp:228] res4a does not need backward computation.
I0627 10:43:59.139632 23737 net.cpp:228] scale4a_branch2c does not need backward computation.
I0627 10:43:59.139637 23737 net.cpp:228] bn4a_branch2c does not need backward computation.
I0627 10:43:59.139643 23737 net.cpp:228] res4a_branch2c does not need backward computation.
I0627 10:43:59.139649 23737 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I0627 10:43:59.139654 23737 net.cpp:228] scale4a_branch2b does not need backward computation.
I0627 10:43:59.139660 23737 net.cpp:228] bn4a_branch2b does not need backward computation.
I0627 10:43:59.139665 23737 net.cpp:228] res4a_branch2b does not need backward computation.
I0627 10:43:59.139672 23737 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I0627 10:43:59.139678 23737 net.cpp:228] scale4a_branch2a does not need backward computation.
I0627 10:43:59.139683 23737 net.cpp:228] bn4a_branch2a does not need backward computation.
I0627 10:43:59.139688 23737 net.cpp:228] res4a_branch2a does not need backward computation.
I0627 10:43:59.139694 23737 net.cpp:228] scale4a_branch1 does not need backward computation.
I0627 10:43:59.139699 23737 net.cpp:228] bn4a_branch1 does not need backward computation.
I0627 10:43:59.139705 23737 net.cpp:228] res4a_branch1 does not need backward computation.
I0627 10:43:59.139713 23737 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I0627 10:43:59.139719 23737 net.cpp:228] res3d_relu does not need backward computation.
I0627 10:43:59.139724 23737 net.cpp:228] res3d does not need backward computation.
I0627 10:43:59.139731 23737 net.cpp:228] scale3d_branch2c does not need backward computation.
I0627 10:43:59.139736 23737 net.cpp:228] bn3d_branch2c does not need backward computation.
I0627 10:43:59.139741 23737 net.cpp:228] res3d_branch2c does not need backward computation.
I0627 10:43:59.139747 23737 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I0627 10:43:59.139752 23737 net.cpp:228] scale3d_branch2b does not need backward computation.
I0627 10:43:59.139758 23737 net.cpp:228] bn3d_branch2b does not need backward computation.
I0627 10:43:59.139763 23737 net.cpp:228] res3d_branch2b does not need backward computation.
I0627 10:43:59.139770 23737 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I0627 10:43:59.139775 23737 net.cpp:228] scale3d_branch2a does not need backward computation.
I0627 10:43:59.139780 23737 net.cpp:228] bn3d_branch2a does not need backward computation.
I0627 10:43:59.139786 23737 net.cpp:228] res3d_branch2a does not need backward computation.
I0627 10:43:59.139793 23737 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I0627 10:43:59.139799 23737 net.cpp:228] res3c_relu does not need backward computation.
I0627 10:43:59.139804 23737 net.cpp:228] res3c does not need backward computation.
I0627 10:43:59.139812 23737 net.cpp:228] scale3c_branch2c does not need backward computation.
I0627 10:43:59.139817 23737 net.cpp:228] bn3c_branch2c does not need backward computation.
I0627 10:43:59.139822 23737 net.cpp:228] res3c_branch2c does not need backward computation.
I0627 10:43:59.139828 23737 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I0627 10:43:59.139834 23737 net.cpp:228] scale3c_branch2b does not need backward computation.
I0627 10:43:59.139839 23737 net.cpp:228] bn3c_branch2b does not need backward computation.
I0627 10:43:59.139845 23737 net.cpp:228] res3c_branch2b does not need backward computation.
I0627 10:43:59.139852 23737 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I0627 10:43:59.139858 23737 net.cpp:228] scale3c_branch2a does not need backward computation.
I0627 10:43:59.139863 23737 net.cpp:228] bn3c_branch2a does not need backward computation.
I0627 10:43:59.139868 23737 net.cpp:228] res3c_branch2a does not need backward computation.
I0627 10:43:59.139875 23737 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I0627 10:43:59.139881 23737 net.cpp:228] res3b_relu does not need backward computation.
I0627 10:43:59.139889 23737 net.cpp:228] res3b does not need backward computation.
I0627 10:43:59.139896 23737 net.cpp:228] scale3b_branch2c does not need backward computation.
I0627 10:43:59.139901 23737 net.cpp:228] bn3b_branch2c does not need backward computation.
I0627 10:43:59.139906 23737 net.cpp:228] res3b_branch2c does not need backward computation.
I0627 10:43:59.139914 23737 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I0627 10:43:59.139919 23737 net.cpp:228] scale3b_branch2b does not need backward computation.
I0627 10:43:59.139924 23737 net.cpp:228] bn3b_branch2b does not need backward computation.
I0627 10:43:59.139930 23737 net.cpp:228] res3b_branch2b does not need backward computation.
I0627 10:43:59.139935 23737 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I0627 10:43:59.139941 23737 net.cpp:228] scale3b_branch2a does not need backward computation.
I0627 10:43:59.139946 23737 net.cpp:228] bn3b_branch2a does not need backward computation.
I0627 10:43:59.139952 23737 net.cpp:228] res3b_branch2a does not need backward computation.
I0627 10:43:59.139959 23737 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I0627 10:43:59.139967 23737 net.cpp:228] res3a_relu does not need backward computation.
I0627 10:43:59.139972 23737 net.cpp:228] res3a does not need backward computation.
I0627 10:43:59.139981 23737 net.cpp:228] scale3a_branch2c does not need backward computation.
I0627 10:43:59.139987 23737 net.cpp:228] bn3a_branch2c does not need backward computation.
I0627 10:43:59.139993 23737 net.cpp:228] res3a_branch2c does not need backward computation.
I0627 10:43:59.140000 23737 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I0627 10:43:59.140007 23737 net.cpp:228] scale3a_branch2b does not need backward computation.
I0627 10:43:59.140012 23737 net.cpp:228] bn3a_branch2b does not need backward computation.
I0627 10:43:59.140017 23737 net.cpp:228] res3a_branch2b does not need backward computation.
I0627 10:43:59.140023 23737 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I0627 10:43:59.140029 23737 net.cpp:228] scale3a_branch2a does not need backward computation.
I0627 10:43:59.140035 23737 net.cpp:228] bn3a_branch2a does not need backward computation.
I0627 10:43:59.140041 23737 net.cpp:228] res3a_branch2a does not need backward computation.
I0627 10:43:59.140048 23737 net.cpp:228] scale3a_branch1 does not need backward computation.
I0627 10:43:59.140054 23737 net.cpp:228] bn3a_branch1 does not need backward computation.
I0627 10:43:59.140060 23737 net.cpp:228] res3a_branch1 does not need backward computation.
I0627 10:43:59.140069 23737 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0627 10:43:59.140074 23737 net.cpp:228] res2c_relu does not need backward computation.
I0627 10:43:59.140080 23737 net.cpp:228] res2c does not need backward computation.
I0627 10:43:59.140089 23737 net.cpp:228] scale2c_branch2c does not need backward computation.
I0627 10:43:59.140094 23737 net.cpp:228] bn2c_branch2c does not need backward computation.
I0627 10:43:59.140100 23737 net.cpp:228] res2c_branch2c does not need backward computation.
I0627 10:43:59.140105 23737 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0627 10:43:59.140111 23737 net.cpp:228] scale2c_branch2b does not need backward computation.
I0627 10:43:59.140117 23737 net.cpp:228] bn2c_branch2b does not need backward computation.
I0627 10:43:59.140123 23737 net.cpp:228] res2c_branch2b does not need backward computation.
I0627 10:43:59.140130 23737 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0627 10:43:59.140136 23737 net.cpp:228] scale2c_branch2a does not need backward computation.
I0627 10:43:59.140142 23737 net.cpp:228] bn2c_branch2a does not need backward computation.
I0627 10:43:59.140147 23737 net.cpp:228] res2c_branch2a does not need backward computation.
I0627 10:43:59.140156 23737 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0627 10:43:59.140162 23737 net.cpp:228] res2b_relu does not need backward computation.
I0627 10:43:59.140167 23737 net.cpp:228] res2b does not need backward computation.
I0627 10:43:59.140177 23737 net.cpp:228] scale2b_branch2c does not need backward computation.
I0627 10:43:59.140182 23737 net.cpp:228] bn2b_branch2c does not need backward computation.
I0627 10:43:59.140188 23737 net.cpp:228] res2b_branch2c does not need backward computation.
I0627 10:43:59.140195 23737 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0627 10:43:59.140202 23737 net.cpp:228] scale2b_branch2b does not need backward computation.
I0627 10:43:59.140208 23737 net.cpp:228] bn2b_branch2b does not need backward computation.
I0627 10:43:59.140213 23737 net.cpp:228] res2b_branch2b does not need backward computation.
I0627 10:43:59.140219 23737 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0627 10:43:59.140225 23737 net.cpp:228] scale2b_branch2a does not need backward computation.
I0627 10:43:59.140231 23737 net.cpp:228] bn2b_branch2a does not need backward computation.
I0627 10:43:59.140238 23737 net.cpp:228] res2b_branch2a does not need backward computation.
I0627 10:43:59.140245 23737 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0627 10:43:59.140252 23737 net.cpp:228] res2a_relu does not need backward computation.
I0627 10:43:59.140259 23737 net.cpp:228] res2a does not need backward computation.
I0627 10:43:59.140266 23737 net.cpp:228] scale2a_branch2c does not need backward computation.
I0627 10:43:59.140272 23737 net.cpp:228] bn2a_branch2c does not need backward computation.
I0627 10:43:59.140277 23737 net.cpp:228] res2a_branch2c does not need backward computation.
I0627 10:43:59.140285 23737 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0627 10:43:59.140290 23737 net.cpp:228] scale2a_branch2b does not need backward computation.
I0627 10:43:59.140296 23737 net.cpp:228] bn2a_branch2b does not need backward computation.
I0627 10:43:59.140301 23737 net.cpp:228] res2a_branch2b does not need backward computation.
I0627 10:43:59.140308 23737 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0627 10:43:59.140314 23737 net.cpp:228] scale2a_branch2a does not need backward computation.
I0627 10:43:59.140319 23737 net.cpp:228] bn2a_branch2a does not need backward computation.
I0627 10:43:59.140326 23737 net.cpp:228] res2a_branch2a does not need backward computation.
I0627 10:43:59.140332 23737 net.cpp:228] scale2a_branch1 does not need backward computation.
I0627 10:43:59.140338 23737 net.cpp:228] bn2a_branch1 does not need backward computation.
I0627 10:43:59.140344 23737 net.cpp:228] res2a_branch1 does not need backward computation.
I0627 10:43:59.140352 23737 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0627 10:43:59.140359 23737 net.cpp:228] pool1 does not need backward computation.
I0627 10:43:59.140365 23737 net.cpp:228] conv1_relu does not need backward computation.
I0627 10:43:59.140372 23737 net.cpp:228] scale_conv1 does not need backward computation.
I0627 10:43:59.140377 23737 net.cpp:228] bn_conv1 does not need backward computation.
I0627 10:43:59.140383 23737 net.cpp:228] conv1 does not need backward computation.
I0627 10:43:59.140390 23737 net.cpp:228] input does not need backward computation.
I0627 10:43:59.140394 23737 net.cpp:270] This network produces output bbox_pred
I0627 10:43:59.140403 23737 net.cpp:270] This network produces output cls_prob
I0627 10:43:59.140715 23737 net.cpp:283] Network initialization done.
I0627 10:43:59.250113 23737 net.cpp:771] Ignoring source layer input-data
I0627 10:43:59.250136 23737 net.cpp:771] Ignoring source layer data_input-data_0_split
I0627 10:43:59.250144 23737 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I0627 10:43:59.250150 23737 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I0627 10:43:59.250154 23737 net.cpp:774] Copying source layer conv1
I0627 10:43:59.250257 23737 net.cpp:774] Copying source layer bn_conv1
I0627 10:43:59.250268 23737 net.cpp:774] Copying source layer scale_conv1
I0627 10:43:59.250278 23737 net.cpp:774] Copying source layer conv1_relu
I0627 10:43:59.250283 23737 net.cpp:774] Copying source layer pool1
I0627 10:43:59.250286 23737 net.cpp:774] Copying source layer pool1_pool1_0_split
I0627 10:43:59.250289 23737 net.cpp:774] Copying source layer res2a_branch1
I0627 10:43:59.250433 23737 net.cpp:774] Copying source layer bn2a_branch1
I0627 10:43:59.250449 23737 net.cpp:774] Copying source layer scale2a_branch1
I0627 10:43:59.250463 23737 net.cpp:774] Copying source layer res2a_branch2a
I0627 10:43:59.250505 23737 net.cpp:774] Copying source layer bn2a_branch2a
I0627 10:43:59.250517 23737 net.cpp:774] Copying source layer scale2a_branch2a
I0627 10:43:59.250527 23737 net.cpp:774] Copying source layer res2a_branch2a_relu
I0627 10:43:59.250531 23737 net.cpp:774] Copying source layer res2a_branch2b
I0627 10:43:59.250844 23737 net.cpp:774] Copying source layer bn2a_branch2b
I0627 10:43:59.250855 23737 net.cpp:774] Copying source layer scale2a_branch2b
I0627 10:43:59.250903 23737 net.cpp:774] Copying source layer res2a_branch2b_relu
I0627 10:43:59.250908 23737 net.cpp:774] Copying source layer res2a_branch2c
I0627 10:43:59.251051 23737 net.cpp:774] Copying source layer bn2a_branch2c
I0627 10:43:59.251066 23737 net.cpp:774] Copying source layer scale2a_branch2c
I0627 10:43:59.251080 23737 net.cpp:774] Copying source layer res2a
I0627 10:43:59.251085 23737 net.cpp:774] Copying source layer res2a_relu
I0627 10:43:59.251088 23737 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0627 10:43:59.251093 23737 net.cpp:774] Copying source layer res2b_branch2a
I0627 10:43:59.251237 23737 net.cpp:774] Copying source layer bn2b_branch2a
I0627 10:43:59.251250 23737 net.cpp:774] Copying source layer scale2b_branch2a
I0627 10:43:59.251260 23737 net.cpp:774] Copying source layer res2b_branch2a_relu
I0627 10:43:59.251263 23737 net.cpp:774] Copying source layer res2b_branch2b
I0627 10:43:59.251579 23737 net.cpp:774] Copying source layer bn2b_branch2b
I0627 10:43:59.251591 23737 net.cpp:774] Copying source layer scale2b_branch2b
I0627 10:43:59.251601 23737 net.cpp:774] Copying source layer res2b_branch2b_relu
I0627 10:43:59.251606 23737 net.cpp:774] Copying source layer res2b_branch2c
I0627 10:43:59.251750 23737 net.cpp:774] Copying source layer bn2b_branch2c
I0627 10:43:59.251765 23737 net.cpp:774] Copying source layer scale2b_branch2c
I0627 10:43:59.251780 23737 net.cpp:774] Copying source layer res2b
I0627 10:43:59.251785 23737 net.cpp:774] Copying source layer res2b_relu
I0627 10:43:59.251788 23737 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0627 10:43:59.251793 23737 net.cpp:774] Copying source layer res2c_branch2a
I0627 10:43:59.251936 23737 net.cpp:774] Copying source layer bn2c_branch2a
I0627 10:43:59.251948 23737 net.cpp:774] Copying source layer scale2c_branch2a
I0627 10:43:59.251958 23737 net.cpp:774] Copying source layer res2c_branch2a_relu
I0627 10:43:59.251963 23737 net.cpp:774] Copying source layer res2c_branch2b
I0627 10:43:59.252275 23737 net.cpp:774] Copying source layer bn2c_branch2b
I0627 10:43:59.252287 23737 net.cpp:774] Copying source layer scale2c_branch2b
I0627 10:43:59.252298 23737 net.cpp:774] Copying source layer res2c_branch2b_relu
I0627 10:43:59.252302 23737 net.cpp:774] Copying source layer res2c_branch2c
I0627 10:43:59.252446 23737 net.cpp:774] Copying source layer bn2c_branch2c
I0627 10:43:59.252461 23737 net.cpp:774] Copying source layer scale2c_branch2c
I0627 10:43:59.252475 23737 net.cpp:774] Copying source layer res2c
I0627 10:43:59.252480 23737 net.cpp:774] Copying source layer res2c_relu
I0627 10:43:59.252485 23737 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0627 10:43:59.252490 23737 net.cpp:774] Copying source layer res3a_branch1
I0627 10:43:59.253582 23737 net.cpp:774] Copying source layer bn3a_branch1
I0627 10:43:59.253602 23737 net.cpp:774] Copying source layer scale3a_branch1
I0627 10:43:59.253621 23737 net.cpp:774] Copying source layer res3a_branch2a
I0627 10:43:59.253901 23737 net.cpp:774] Copying source layer bn3a_branch2a
I0627 10:43:59.253916 23737 net.cpp:774] Copying source layer scale3a_branch2a
I0627 10:43:59.253927 23737 net.cpp:774] Copying source layer res3a_branch2a_relu
I0627 10:43:59.253932 23737 net.cpp:774] Copying source layer res3a_branch2b
I0627 10:43:59.255162 23737 net.cpp:774] Copying source layer bn3a_branch2b
I0627 10:43:59.255177 23737 net.cpp:774] Copying source layer scale3a_branch2b
I0627 10:43:59.255190 23737 net.cpp:774] Copying source layer res3a_branch2b_relu
I0627 10:43:59.255195 23737 net.cpp:774] Copying source layer res3a_branch2c
I0627 10:43:59.255746 23737 net.cpp:774] Copying source layer bn3a_branch2c
I0627 10:43:59.255766 23737 net.cpp:774] Copying source layer scale3a_branch2c
I0627 10:43:59.255785 23737 net.cpp:774] Copying source layer res3a
I0627 10:43:59.255791 23737 net.cpp:774] Copying source layer res3a_relu
I0627 10:43:59.255795 23737 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0627 10:43:59.255801 23737 net.cpp:774] Copying source layer res3b_branch2a
I0627 10:43:59.256352 23737 net.cpp:774] Copying source layer bn3b_branch2a
I0627 10:43:59.256367 23737 net.cpp:774] Copying source layer scale3b_branch2a
I0627 10:43:59.256378 23737 net.cpp:774] Copying source layer res3b_branch2a_relu
I0627 10:43:59.256384 23737 net.cpp:774] Copying source layer res3b_branch2b
I0627 10:43:59.257612 23737 net.cpp:774] Copying source layer bn3b_branch2b
I0627 10:43:59.257627 23737 net.cpp:774] Copying source layer scale3b_branch2b
I0627 10:43:59.257639 23737 net.cpp:774] Copying source layer res3b_branch2b_relu
I0627 10:43:59.257645 23737 net.cpp:774] Copying source layer res3b_branch2c
I0627 10:43:59.258195 23737 net.cpp:774] Copying source layer bn3b_branch2c
I0627 10:43:59.258217 23737 net.cpp:774] Copying source layer scale3b_branch2c
I0627 10:43:59.258235 23737 net.cpp:774] Copying source layer res3b
I0627 10:43:59.258241 23737 net.cpp:774] Copying source layer res3b_relu
I0627 10:43:59.258246 23737 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0627 10:43:59.258252 23737 net.cpp:774] Copying source layer res3c_branch2a
I0627 10:43:59.258803 23737 net.cpp:774] Copying source layer bn3c_branch2a
I0627 10:43:59.258818 23737 net.cpp:774] Copying source layer scale3c_branch2a
I0627 10:43:59.258831 23737 net.cpp:774] Copying source layer res3c_branch2a_relu
I0627 10:43:59.258836 23737 net.cpp:774] Copying source layer res3c_branch2b
I0627 10:43:59.260068 23737 net.cpp:774] Copying source layer bn3c_branch2b
I0627 10:43:59.260083 23737 net.cpp:774] Copying source layer scale3c_branch2b
I0627 10:43:59.260097 23737 net.cpp:774] Copying source layer res3c_branch2b_relu
I0627 10:43:59.260102 23737 net.cpp:774] Copying source layer res3c_branch2c
I0627 10:43:59.260653 23737 net.cpp:774] Copying source layer bn3c_branch2c
I0627 10:43:59.260674 23737 net.cpp:774] Copying source layer scale3c_branch2c
I0627 10:43:59.260692 23737 net.cpp:774] Copying source layer res3c
I0627 10:43:59.260699 23737 net.cpp:774] Copying source layer res3c_relu
I0627 10:43:59.260705 23737 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0627 10:43:59.260711 23737 net.cpp:774] Copying source layer res3d_branch2a
I0627 10:43:59.261262 23737 net.cpp:774] Copying source layer bn3d_branch2a
I0627 10:43:59.261277 23737 net.cpp:774] Copying source layer scale3d_branch2a
I0627 10:43:59.261289 23737 net.cpp:774] Copying source layer res3d_branch2a_relu
I0627 10:43:59.261296 23737 net.cpp:774] Copying source layer res3d_branch2b
I0627 10:43:59.262543 23737 net.cpp:774] Copying source layer bn3d_branch2b
I0627 10:43:59.262562 23737 net.cpp:774] Copying source layer scale3d_branch2b
I0627 10:43:59.262575 23737 net.cpp:774] Copying source layer res3d_branch2b_relu
I0627 10:43:59.262583 23737 net.cpp:774] Copying source layer res3d_branch2c
I0627 10:43:59.263147 23737 net.cpp:774] Copying source layer bn3d_branch2c
I0627 10:43:59.263175 23737 net.cpp:774] Copying source layer scale3d_branch2c
I0627 10:43:59.263193 23737 net.cpp:774] Copying source layer res3d
I0627 10:43:59.263200 23737 net.cpp:774] Copying source layer res3d_relu
I0627 10:43:59.263206 23737 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0627 10:43:59.263209 23737 net.cpp:774] Copying source layer res4a_branch1
I0627 10:43:59.267786 23737 net.cpp:774] Copying source layer bn4a_branch1
I0627 10:43:59.267822 23737 net.cpp:774] Copying source layer scale4a_branch1
I0627 10:43:59.267848 23737 net.cpp:774] Copying source layer res4a_branch2a
I0627 10:43:59.268937 23737 net.cpp:774] Copying source layer bn4a_branch2a
I0627 10:43:59.268951 23737 net.cpp:774] Copying source layer scale4a_branch2a
I0627 10:43:59.268963 23737 net.cpp:774] Copying source layer res4a_branch2a_relu
I0627 10:43:59.268967 23737 net.cpp:774] Copying source layer res4a_branch2b
I0627 10:43:59.273856 23737 net.cpp:774] Copying source layer bn4a_branch2b
I0627 10:43:59.273872 23737 net.cpp:774] Copying source layer scale4a_branch2b
I0627 10:43:59.273885 23737 net.cpp:774] Copying source layer res4a_branch2b_relu
I0627 10:43:59.273888 23737 net.cpp:774] Copying source layer res4a_branch2c
I0627 10:43:59.276064 23737 net.cpp:774] Copying source layer bn4a_branch2c
I0627 10:43:59.276093 23737 net.cpp:774] Copying source layer scale4a_branch2c
I0627 10:43:59.276116 23737 net.cpp:774] Copying source layer res4a
I0627 10:43:59.276121 23737 net.cpp:774] Copying source layer res4a_relu
I0627 10:43:59.276125 23737 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0627 10:43:59.276129 23737 net.cpp:774] Copying source layer res4b_branch2a
I0627 10:43:59.278314 23737 net.cpp:774] Copying source layer bn4b_branch2a
I0627 10:43:59.278331 23737 net.cpp:774] Copying source layer scale4b_branch2a
I0627 10:43:59.278344 23737 net.cpp:774] Copying source layer res4b_branch2a_relu
I0627 10:43:59.278348 23737 net.cpp:774] Copying source layer res4b_branch2b
I0627 10:43:59.283471 23737 net.cpp:774] Copying source layer bn4b_branch2b
I0627 10:43:59.283499 23737 net.cpp:774] Copying source layer scale4b_branch2b
I0627 10:43:59.283511 23737 net.cpp:774] Copying source layer res4b_branch2b_relu
I0627 10:43:59.283515 23737 net.cpp:774] Copying source layer res4b_branch2c
I0627 10:43:59.285689 23737 net.cpp:774] Copying source layer bn4b_branch2c
I0627 10:43:59.285717 23737 net.cpp:774] Copying source layer scale4b_branch2c
I0627 10:43:59.285742 23737 net.cpp:774] Copying source layer res4b
I0627 10:43:59.285746 23737 net.cpp:774] Copying source layer res4b_relu
I0627 10:43:59.285750 23737 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0627 10:43:59.285754 23737 net.cpp:774] Copying source layer res4c_branch2a
I0627 10:43:59.287937 23737 net.cpp:774] Copying source layer bn4c_branch2a
I0627 10:43:59.287952 23737 net.cpp:774] Copying source layer scale4c_branch2a
I0627 10:43:59.287966 23737 net.cpp:774] Copying source layer res4c_branch2a_relu
I0627 10:43:59.287971 23737 net.cpp:774] Copying source layer res4c_branch2b
I0627 10:43:59.292856 23737 net.cpp:774] Copying source layer bn4c_branch2b
I0627 10:43:59.292873 23737 net.cpp:774] Copying source layer scale4c_branch2b
I0627 10:43:59.292886 23737 net.cpp:774] Copying source layer res4c_branch2b_relu
I0627 10:43:59.292891 23737 net.cpp:774] Copying source layer res4c_branch2c
I0627 10:43:59.295065 23737 net.cpp:774] Copying source layer bn4c_branch2c
I0627 10:43:59.295094 23737 net.cpp:774] Copying source layer scale4c_branch2c
I0627 10:43:59.295117 23737 net.cpp:774] Copying source layer res4c
I0627 10:43:59.295122 23737 net.cpp:774] Copying source layer res4c_relu
I0627 10:43:59.295127 23737 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0627 10:43:59.295131 23737 net.cpp:774] Copying source layer res4d_branch2a
I0627 10:43:59.297305 23737 net.cpp:774] Copying source layer bn4d_branch2a
I0627 10:43:59.297319 23737 net.cpp:774] Copying source layer scale4d_branch2a
I0627 10:43:59.297333 23737 net.cpp:774] Copying source layer res4d_branch2a_relu
I0627 10:43:59.297338 23737 net.cpp:774] Copying source layer res4d_branch2b
I0627 10:43:59.302220 23737 net.cpp:774] Copying source layer bn4d_branch2b
I0627 10:43:59.302237 23737 net.cpp:774] Copying source layer scale4d_branch2b
I0627 10:43:59.302249 23737 net.cpp:774] Copying source layer res4d_branch2b_relu
I0627 10:43:59.302254 23737 net.cpp:774] Copying source layer res4d_branch2c
I0627 10:43:59.304430 23737 net.cpp:774] Copying source layer bn4d_branch2c
I0627 10:43:59.304460 23737 net.cpp:774] Copying source layer scale4d_branch2c
I0627 10:43:59.304483 23737 net.cpp:774] Copying source layer res4d
I0627 10:43:59.304488 23737 net.cpp:774] Copying source layer res4d_relu
I0627 10:43:59.304493 23737 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0627 10:43:59.304498 23737 net.cpp:774] Copying source layer res4e_branch2a
I0627 10:43:59.306671 23737 net.cpp:774] Copying source layer bn4e_branch2a
I0627 10:43:59.306685 23737 net.cpp:774] Copying source layer scale4e_branch2a
I0627 10:43:59.306699 23737 net.cpp:774] Copying source layer res4e_branch2a_relu
I0627 10:43:59.306704 23737 net.cpp:774] Copying source layer res4e_branch2b
I0627 10:43:59.311658 23737 net.cpp:774] Copying source layer bn4e_branch2b
I0627 10:43:59.311679 23737 net.cpp:774] Copying source layer scale4e_branch2b
I0627 10:43:59.311692 23737 net.cpp:774] Copying source layer res4e_branch2b_relu
I0627 10:43:59.311697 23737 net.cpp:774] Copying source layer res4e_branch2c
I0627 10:43:59.314110 23737 net.cpp:774] Copying source layer bn4e_branch2c
I0627 10:43:59.314149 23737 net.cpp:774] Copying source layer scale4e_branch2c
I0627 10:43:59.314177 23737 net.cpp:774] Copying source layer res4e
I0627 10:43:59.314182 23737 net.cpp:774] Copying source layer res4e_relu
I0627 10:43:59.314188 23737 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0627 10:43:59.314194 23737 net.cpp:774] Copying source layer res4f_branch2a
I0627 10:43:59.316372 23737 net.cpp:774] Copying source layer bn4f_branch2a
I0627 10:43:59.316388 23737 net.cpp:774] Copying source layer scale4f_branch2a
I0627 10:43:59.316402 23737 net.cpp:774] Copying source layer res4f_branch2a_relu
I0627 10:43:59.316408 23737 net.cpp:774] Copying source layer res4f_branch2b
I0627 10:43:59.321293 23737 net.cpp:774] Copying source layer bn4f_branch2b
I0627 10:43:59.321311 23737 net.cpp:774] Copying source layer scale4f_branch2b
I0627 10:43:59.321324 23737 net.cpp:774] Copying source layer res4f_branch2b_relu
I0627 10:43:59.321329 23737 net.cpp:774] Copying source layer res4f_branch2c
I0627 10:43:59.323511 23737 net.cpp:774] Copying source layer bn4f_branch2c
I0627 10:43:59.323544 23737 net.cpp:774] Copying source layer scale4f_branch2c
I0627 10:43:59.323570 23737 net.cpp:774] Copying source layer res4f
I0627 10:43:59.323576 23737 net.cpp:774] Copying source layer res4f_relu
I0627 10:43:59.323583 23737 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0627 10:43:59.323588 23737 net.cpp:774] Copying source layer res5a_branch1
I0627 10:43:59.341076 23737 net.cpp:774] Copying source layer bn5a_branch1
I0627 10:43:59.341140 23737 net.cpp:774] Copying source layer scale5a_branch1
I0627 10:43:59.341182 23737 net.cpp:774] Copying source layer res5a_branch2a
I0627 10:43:59.345851 23737 net.cpp:774] Copying source layer bn5a_branch2a
I0627 10:43:59.345911 23737 net.cpp:774] Copying source layer scale5a_branch2a
I0627 10:43:59.345929 23737 net.cpp:774] Copying source layer res5a_branch2a_relu
I0627 10:43:59.345937 23737 net.cpp:774] Copying source layer res5a_branch2b
I0627 10:43:59.365548 23737 net.cpp:774] Copying source layer bn5a_branch2b
I0627 10:43:59.365584 23737 net.cpp:774] Copying source layer scale5a_branch2b
I0627 10:43:59.365603 23737 net.cpp:774] Copying source layer res5a_branch2b_relu
I0627 10:43:59.365608 23737 net.cpp:774] Copying source layer res5a_branch2c
I0627 10:43:59.374320 23737 net.cpp:774] Copying source layer bn5a_branch2c
I0627 10:43:59.374384 23737 net.cpp:774] Copying source layer scale5a_branch2c
I0627 10:43:59.374428 23737 net.cpp:774] Copying source layer res5a
I0627 10:43:59.374433 23737 net.cpp:774] Copying source layer res5a_relu
I0627 10:43:59.374440 23737 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0627 10:43:59.374445 23737 net.cpp:774] Copying source layer res5b_branch2a
I0627 10:43:59.383636 23737 net.cpp:774] Copying source layer bn5b_branch2a
I0627 10:43:59.383705 23737 net.cpp:774] Copying source layer scale5b_branch2a
I0627 10:43:59.383728 23737 net.cpp:774] Copying source layer res5b_branch2a_relu
I0627 10:43:59.383733 23737 net.cpp:774] Copying source layer res5b_branch2b
I0627 10:43:59.403329 23737 net.cpp:774] Copying source layer bn5b_branch2b
I0627 10:43:59.403357 23737 net.cpp:774] Copying source layer scale5b_branch2b
I0627 10:43:59.403375 23737 net.cpp:774] Copying source layer res5b_branch2b_relu
I0627 10:43:59.403383 23737 net.cpp:774] Copying source layer res5b_branch2c
I0627 10:43:59.412710 23737 net.cpp:774] Copying source layer bn5b_branch2c
I0627 10:43:59.412780 23737 net.cpp:774] Copying source layer scale5b_branch2c
I0627 10:43:59.412823 23737 net.cpp:774] Copying source layer res5b
I0627 10:43:59.412829 23737 net.cpp:774] Copying source layer res5b_relu
I0627 10:43:59.412837 23737 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0627 10:43:59.412843 23737 net.cpp:774] Copying source layer res5c_branch2a
I0627 10:43:59.421541 23737 net.cpp:774] Copying source layer bn5c_branch2a
I0627 10:43:59.421566 23737 net.cpp:774] Copying source layer scale5c_branch2a
I0627 10:43:59.421586 23737 net.cpp:774] Copying source layer res5c_branch2a_relu
I0627 10:43:59.421594 23737 net.cpp:774] Copying source layer res5c_branch2b
I0627 10:43:59.441460 23737 net.cpp:774] Copying source layer bn5c_branch2b
I0627 10:43:59.441509 23737 net.cpp:774] Copying source layer scale5c_branch2b
I0627 10:43:59.441529 23737 net.cpp:774] Copying source layer res5c_branch2b_relu
I0627 10:43:59.441536 23737 net.cpp:774] Copying source layer res5c_branch2c
I0627 10:43:59.450238 23737 net.cpp:774] Copying source layer bn5c_branch2c
I0627 10:43:59.450294 23737 net.cpp:774] Copying source layer scale5c_branch2c
I0627 10:43:59.450337 23737 net.cpp:774] Copying source layer res5c
I0627 10:43:59.450345 23737 net.cpp:774] Copying source layer res5c_relu
I0627 10:43:59.450350 23737 net.cpp:774] Copying source layer rpn_conv/3x3
I0627 10:43:59.489814 23737 net.cpp:774] Copying source layer rpn_relu/3x3
I0627 10:43:59.489837 23737 net.cpp:774] Copying source layer rpn/output_rpn_relu/3x3_0_split
I0627 10:43:59.489843 23737 net.cpp:774] Copying source layer rpn_cls_score
I0627 10:43:59.489945 23737 net.cpp:771] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0627 10:43:59.489953 23737 net.cpp:774] Copying source layer rpn_bbox_pred
I0627 10:43:59.490147 23737 net.cpp:771] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0627 10:43:59.490154 23737 net.cpp:774] Copying source layer rpn_cls_score_reshape
I0627 10:43:59.490159 23737 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0627 10:43:59.490164 23737 net.cpp:771] Ignoring source layer rpn-data
I0627 10:43:59.490170 23737 net.cpp:771] Ignoring source layer rpn_loss_cls
I0627 10:43:59.490175 23737 net.cpp:771] Ignoring source layer rpn_loss_bbox
I0627 10:43:59.490180 23737 net.cpp:774] Copying source layer rpn_cls_prob
I0627 10:43:59.490185 23737 net.cpp:774] Copying source layer rpn_cls_prob_reshape
I0627 10:43:59.490190 23737 net.cpp:774] Copying source layer proposal
I0627 10:43:59.490195 23737 net.cpp:771] Ignoring source layer roi-data
I0627 10:43:59.490200 23737 net.cpp:771] Ignoring source layer rois_roi-data_0_split
I0627 10:43:59.490205 23737 net.cpp:771] Ignoring source layer labels_roi-data_1_split
I0627 10:43:59.490209 23737 net.cpp:771] Ignoring source layer bbox_targets_roi-data_2_split
I0627 10:43:59.490214 23737 net.cpp:771] Ignoring source layer bbox_inside_weights_roi-data_3_split
I0627 10:43:59.490218 23737 net.cpp:774] Copying source layer conv_new_1
I0627 10:43:59.507781 23737 net.cpp:774] Copying source layer conv_new_1_relu
I0627 10:43:59.507804 23737 net.cpp:774] Copying source layer conv_new_1_conv_new_1_relu_0_split
I0627 10:43:59.507809 23737 net.cpp:774] Copying source layer rfcn_cls
I0627 10:43:59.508648 23737 net.cpp:774] Copying source layer rfcn_bbox
I0627 10:43:59.512497 23737 net.cpp:774] Copying source layer psroipooled_cls_rois
I0627 10:43:59.512519 23737 net.cpp:774] Copying source layer ave_cls_score_rois
I0627 10:43:59.512527 23737 net.cpp:771] Ignoring source layer cls_score_ave_cls_score_rois_0_split
I0627 10:43:59.512534 23737 net.cpp:774] Copying source layer psroipooled_loc_rois
I0627 10:43:59.512542 23737 net.cpp:774] Copying source layer ave_bbox_pred_rois
I0627 10:43:59.512550 23737 net.cpp:771] Ignoring source layer bbox_pred_ave_bbox_pred_rois_0_split
I0627 10:43:59.512567 23737 net.cpp:771] Ignoring source layer per_roi_loss_cls
I0627 10:43:59.512573 23737 net.cpp:771] Ignoring source layer per_roi_loss_bbox
I0627 10:43:59.512583 23737 net.cpp:771] Ignoring source layer per_roi_loss
I0627 10:43:59.512589 23737 net.cpp:771] Ignoring source layer annotator_detector
I0627 10:43:59.512598 23737 net.cpp:771] Ignoring source layer labels_ohem_annotator_detector_0_split
I0627 10:43:59.512606 23737 net.cpp:771] Ignoring source layer silence
I0627 10:43:59.512615 23737 net.cpp:771] Ignoring source layer loss
I0627 10:43:59.512624 23737 net.cpp:771] Ignoring source layer accuarcy
I0627 10:43:59.512631 23737 net.cpp:771] Ignoring source layer loss_bbox
I0627 10:43:59.825480 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 5529624
I0627 10:43:59.843046 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.863420 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.876986 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.885507 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.903080 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.912144 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.929661 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 1388952
I0627 10:43:59.938290 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0627 10:43:59.951925 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 345624
I0627 10:43:59.959949 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:43:59.964337 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:43:59.973043 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:43:59.977421 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:43:59.987365 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:43:59.991904 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:44:00.000622 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 352152
I0627 10:44:00.004982 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:44:00.012575 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:44:00.018165 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.021618 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.028314 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.031672 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.038012 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.041363 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.047703 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.051364 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.057847 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.061092 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.067325 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.070561 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:44:00.079363 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.097934 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:44:00.104682 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.125952 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:44:00.132251 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.153357 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 86424
I0627 10:44:00.173344 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.173627 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.191287 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.196559 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
I0627 10:44:00.197356 23737 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 92952
im_detect: 1/4024 0.401s 0.000s
im_detect: 2/4024 0.336s 0.000s
im_detect: 3/4024 0.315s 0.000s
im_detect: 4/4024 0.304s 0.000s
im_detect: 5/4024 0.298s 0.000s
im_detect: 6/4024 0.294s 0.000s
im_detect: 7/4024 0.290s 0.000s
im_detect: 8/4024 0.288s 0.000s
im_detect: 9/4024 0.287s 0.000s
im_detect: 10/4024 0.285s 0.000s
im_detect: 11/4024 0.284s 0.000s
im_detect: 12/4024 0.282s 0.000s
im_detect: 13/4024 0.281s 0.000s
im_detect: 14/4024 0.281s 0.000s
im_detect: 15/4024 0.280s 0.000s
im_detect: 16/4024 0.279s 0.000s
im_detect: 17/4024 0.279s 0.000s
im_detect: 18/4024 0.278s 0.000s
im_detect: 19/4024 0.278s 0.000s
im_detect: 20/4024 0.277s 0.000s
im_detect: 21/4024 0.277s 0.000s
im_detect: 22/4024 0.276s 0.000s
im_detect: 23/4024 0.277s 0.000s
im_detect: 24/4024 0.276s 0.000s
im_detect: 25/4024 0.276s 0.000s
im_detect: 26/4024 0.276s 0.000s
im_detect: 27/4024 0.276s 0.000s
im_detect: 28/4024 0.276s 0.000s
im_detect: 29/4024 0.275s 0.000s
im_detect: 30/4024 0.275s 0.000s
im_detect: 31/4024 0.275s 0.000s
im_detect: 32/4024 0.275s 0.000s
im_detect: 33/4024 0.275s 0.000s
im_detect: 34/4024 0.275s 0.000s
im_detect: 35/4024 0.275s 0.000s
im_detect: 36/4024 0.275s 0.000s
im_detect: 37/4024 0.274s 0.000s
im_detect: 38/4024 0.274s 0.000s
im_detect: 39/4024 0.274s 0.000s
im_detect: 40/4024 0.274s 0.000s
im_detect: 41/4024 0.274s 0.000s
im_detect: 42/4024 0.274s 0.000s
im_detect: 43/4024 0.274s 0.000s
im_detect: 44/4024 0.274s 0.000s
im_detect: 45/4024 0.273s 0.000s
im_detect: 46/4024 0.273s 0.000s
im_detect: 47/4024 0.273s 0.000s
im_detect: 48/4024 0.273s 0.000s
im_detect: 49/4024 0.273s 0.000s
im_detect: 50/4024 0.273s 0.000s
im_detect: 51/4024 0.273s 0.000s
im_detect: 52/4024 0.273s 0.000s
im_detect: 53/4024 0.273s 0.000s
im_detect: 54/4024 0.273s 0.000s
im_detect: 55/4024 0.273s 0.000s
im_detect: 56/4024 0.273s 0.000s
im_detect: 57/4024 0.273s 0.000s
im_detect: 58/4024 0.273s 0.000s
im_detect: 59/4024 0.273s 0.000s
im_detect: 60/4024 0.273s 0.000s
im_detect: 61/4024 0.273s 0.000s
im_detect: 62/4024 0.273s 0.000s
im_detect: 63/4024 0.273s 0.000s
im_detect: 64/4024 0.273s 0.000s
im_detect: 65/4024 0.273s 0.000s
im_detect: 66/4024 0.272s 0.000s
im_detect: 67/4024 0.272s 0.000s
im_detect: 68/4024 0.272s 0.000s
im_detect: 69/4024 0.272s 0.000s
im_detect: 70/4024 0.272s 0.000s
im_detect: 71/4024 0.272s 0.000s
im_detect: 72/4024 0.272s 0.000s
im_detect: 73/4024 0.272s 0.000s
im_detect: 74/4024 0.272s 0.000s
im_detect: 75/4024 0.272s 0.000s
im_detect: 76/4024 0.272s 0.000s
im_detect: 77/4024 0.272s 0.000s
im_detect: 78/4024 0.272s 0.000s
im_detect: 79/4024 0.272s 0.000s
im_detect: 80/4024 0.272s 0.000s
im_detect: 81/4024 0.272s 0.000s
im_detect: 82/4024 0.272s 0.000s
im_detect: 83/4024 0.272s 0.000s
im_detect: 84/4024 0.272s 0.000s
im_detect: 85/4024 0.272s 0.000s
im_detect: 86/4024 0.272s 0.000s
im_detect: 87/4024 0.272s 0.000s
im_detect: 88/4024 0.272s 0.000s
im_detect: 89/4024 0.272s 0.000s
im_detect: 90/4024 0.272s 0.000s
im_detect: 91/4024 0.272s 0.000s
im_detect: 92/4024 0.272s 0.000s
im_detect: 93/4024 0.272s 0.000s
im_detect: 94/4024 0.272s 0.000s
im_detect: 95/4024 0.272s 0.000s
im_detect: 96/4024 0.272s 0.000s
im_detect: 97/4024 0.272s 0.000s
im_detect: 98/4024 0.272s 0.000s
im_detect: 99/4024 0.272s 0.000s
im_detect: 100/4024 0.272s 0.000s
im_detect: 101/4024 0.272s 0.000s
im_detect: 102/4024 0.272s 0.000s
im_detect: 103/4024 0.272s 0.000s
im_detect: 104/4024 0.272s 0.000s
im_detect: 105/4024 0.272s 0.000s
im_detect: 106/4024 0.272s 0.000s
im_detect: 107/4024 0.272s 0.000s
im_detect: 108/4024 0.272s 0.000s
im_detect: 109/4024 0.272s 0.000s
im_detect: 110/4024 0.272s 0.000s
im_detect: 111/4024 0.272s 0.000s
im_detect: 112/4024 0.272s 0.000s
im_detect: 113/4024 0.272s 0.000s
im_detect: 114/4024 0.272s 0.000s
im_detect: 115/4024 0.272s 0.000s
im_detect: 116/4024 0.272s 0.000s
im_detect: 117/4024 0.272s 0.000s
im_detect: 118/4024 0.272s 0.000s
im_detect: 119/4024 0.272s 0.000s
im_detect: 120/4024 0.272s 0.000s
im_detect: 121/4024 0.271s 0.000s
im_detect: 122/4024 0.271s 0.000s
im_detect: 123/4024 0.271s 0.000s
im_detect: 124/4024 0.271s 0.000s
im_detect: 125/4024 0.271s 0.000s
im_detect: 126/4024 0.271s 0.000s
im_detect: 127/4024 0.271s 0.000s
im_detect: 128/4024 0.271s 0.000s
im_detect: 129/4024 0.271s 0.000s
im_detect: 130/4024 0.271s 0.000s
im_detect: 131/4024 0.271s 0.000s
im_detect: 132/4024 0.271s 0.000s
im_detect: 133/4024 0.271s 0.000s
im_detect: 134/4024 0.271s 0.000s
im_detect: 135/4024 0.271s 0.000s
im_detect: 136/4024 0.271s 0.000s
im_detect: 137/4024 0.271s 0.000s
im_detect: 138/4024 0.271s 0.000s
im_detect: 139/4024 0.271s 0.000s
im_detect: 140/4024 0.271s 0.000s
im_detect: 141/4024 0.271s 0.000s
im_detect: 142/4024 0.271s 0.000s
im_detect: 143/4024 0.271s 0.000s
im_detect: 144/4024 0.271s 0.000s
im_detect: 145/4024 0.271s 0.000s
im_detect: 146/4024 0.271s 0.000s
im_detect: 147/4024 0.271s 0.000s
im_detect: 148/4024 0.271s 0.000s
im_detect: 149/4024 0.271s 0.000s
im_detect: 150/4024 0.271s 0.000s
im_detect: 151/4024 0.271s 0.000s
im_detect: 152/4024 0.271s 0.000s
im_detect: 153/4024 0.271s 0.000s
im_detect: 154/4024 0.271s 0.000s
im_detect: 155/4024 0.271s 0.000s
im_detect: 156/4024 0.271s 0.000s
im_detect: 157/4024 0.271s 0.000s
im_detect: 158/4024 0.271s 0.000s
im_detect: 159/4024 0.271s 0.000s
im_detect: 160/4024 0.271s 0.000s
im_detect: 161/4024 0.271s 0.000s
im_detect: 162/4024 0.271s 0.000s
im_detect: 163/4024 0.271s 0.000s
im_detect: 164/4024 0.271s 0.000s
im_detect: 165/4024 0.271s 0.000s
im_detect: 166/4024 0.271s 0.000s
im_detect: 167/4024 0.271s 0.000s
im_detect: 168/4024 0.271s 0.000s
im_detect: 169/4024 0.271s 0.000s
im_detect: 170/4024 0.271s 0.000s
im_detect: 171/4024 0.271s 0.000s
im_detect: 172/4024 0.271s 0.000s
im_detect: 173/4024 0.271s 0.000s
im_detect: 174/4024 0.271s 0.000s
im_detect: 175/4024 0.271s 0.000s
im_detect: 176/4024 0.271s 0.000s
im_detect: 177/4024 0.271s 0.000s
im_detect: 178/4024 0.271s 0.000s
im_detect: 179/4024 0.271s 0.000s
im_detect: 180/4024 0.271s 0.000s
im_detect: 181/4024 0.271s 0.000s
im_detect: 182/4024 0.271s 0.000s
im_detect: 183/4024 0.271s 0.000s
im_detect: 184/4024 0.271s 0.000s
im_detect: 185/4024 0.271s 0.000s
im_detect: 186/4024 0.271s 0.000s
im_detect: 187/4024 0.271s 0.000s
im_detect: 188/4024 0.271s 0.000s
im_detect: 189/4024 0.271s 0.000s
im_detect: 190/4024 0.271s 0.000s
im_detect: 191/4024 0.271s 0.000s
im_detect: 192/4024 0.271s 0.000s
im_detect: 193/4024 0.271s 0.000s
im_detect: 194/4024 0.271s 0.000s
im_detect: 195/4024 0.271s 0.000s
im_detect: 196/4024 0.271s 0.000s
im_detect: 197/4024 0.271s 0.000s
im_detect: 198/4024 0.271s 0.000s
im_detect: 199/4024 0.271s 0.000s
im_detect: 200/4024 0.271s 0.000s
im_detect: 201/4024 0.271s 0.000s
im_detect: 202/4024 0.271s 0.000s
im_detect: 203/4024 0.271s 0.000s
im_detect: 204/4024 0.271s 0.000s
im_detect: 205/4024 0.271s 0.000s
im_detect: 206/4024 0.271s 0.000s
im_detect: 207/4024 0.271s 0.000s
im_detect: 208/4024 0.271s 0.000s
im_detect: 209/4024 0.271s 0.000s
im_detect: 210/4024 0.271s 0.000s
im_detect: 211/4024 0.271s 0.000s
im_detect: 212/4024 0.271s 0.000s
im_detect: 213/4024 0.271s 0.000s
im_detect: 214/4024 0.271s 0.000s
im_detect: 215/4024 0.271s 0.000s
im_detect: 216/4024 0.271s 0.000s
im_detect: 217/4024 0.271s 0.000s
im_detect: 218/4024 0.271s 0.000s
im_detect: 219/4024 0.271s 0.000s
im_detect: 220/4024 0.271s 0.000s
im_detect: 221/4024 0.271s 0.000s
im_detect: 222/4024 0.271s 0.000s
im_detect: 223/4024 0.271s 0.000s
im_detect: 224/4024 0.271s 0.000s
im_detect: 225/4024 0.271s 0.000s
im_detect: 226/4024 0.271s 0.000s
im_detect: 227/4024 0.271s 0.000s
im_detect: 228/4024 0.271s 0.000s
im_detect: 229/4024 0.271s 0.000s
im_detect: 230/4024 0.271s 0.000s
im_detect: 231/4024 0.271s 0.000s
im_detect: 232/4024 0.271s 0.000s
im_detect: 233/4024 0.271s 0.000s
im_detect: 234/4024 0.271s 0.000s
im_detect: 235/4024 0.271s 0.000s
im_detect: 236/4024 0.271s 0.000s
im_detect: 237/4024 0.271s 0.000s
im_detect: 238/4024 0.271s 0.000s
im_detect: 239/4024 0.271s 0.000s
im_detect: 240/4024 0.271s 0.000s
im_detect: 241/4024 0.271s 0.000s
im_detect: 242/4024 0.271s 0.000s
im_detect: 243/4024 0.271s 0.000s
im_detect: 244/4024 0.271s 0.000s
im_detect: 245/4024 0.271s 0.000s
im_detect: 246/4024 0.271s 0.000s
im_detect: 247/4024 0.271s 0.000s
im_detect: 248/4024 0.271s 0.000s
im_detect: 249/4024 0.271s 0.000s
im_detect: 250/4024 0.271s 0.000s
im_detect: 251/4024 0.271s 0.000s
im_detect: 252/4024 0.271s 0.000s
im_detect: 253/4024 0.271s 0.000s
im_detect: 254/4024 0.271s 0.000s
im_detect: 255/4024 0.271s 0.000s
im_detect: 256/4024 0.271s 0.000s
im_detect: 257/4024 0.271s 0.000s
im_detect: 258/4024 0.271s 0.000s
im_detect: 259/4024 0.271s 0.000s
im_detect: 260/4024 0.271s 0.000s
im_detect: 261/4024 0.271s 0.000s
im_detect: 262/4024 0.271s 0.000s
im_detect: 263/4024 0.271s 0.000s
im_detect: 264/4024 0.271s 0.000s
im_detect: 265/4024 0.271s 0.000s
im_detect: 266/4024 0.271s 0.000s
im_detect: 267/4024 0.271s 0.000s
im_detect: 268/4024 0.271s 0.000s
im_detect: 269/4024 0.271s 0.000s
im_detect: 270/4024 0.271s 0.000s
im_detect: 271/4024 0.271s 0.000s
im_detect: 272/4024 0.271s 0.000s
im_detect: 273/4024 0.271s 0.000s
im_detect: 274/4024 0.271s 0.000s
im_detect: 275/4024 0.271s 0.000s
im_detect: 276/4024 0.271s 0.000s
im_detect: 277/4024 0.271s 0.000s
im_detect: 278/4024 0.271s 0.000s
im_detect: 279/4024 0.271s 0.000s
im_detect: 280/4024 0.271s 0.000s
im_detect: 281/4024 0.271s 0.000s
im_detect: 282/4024 0.271s 0.000s
im_detect: 283/4024 0.271s 0.000s
im_detect: 284/4024 0.271s 0.000s
im_detect: 285/4024 0.271s 0.000s
im_detect: 286/4024 0.271s 0.000s
im_detect: 287/4024 0.271s 0.000s
im_detect: 288/4024 0.271s 0.000s
im_detect: 289/4024 0.271s 0.000s
im_detect: 290/4024 0.271s 0.000s
im_detect: 291/4024 0.271s 0.000s
im_detect: 292/4024 0.271s 0.000s
im_detect: 293/4024 0.271s 0.000s
im_detect: 294/4024 0.271s 0.000s
im_detect: 295/4024 0.271s 0.000s
im_detect: 296/4024 0.271s 0.000s
im_detect: 297/4024 0.271s 0.000s
im_detect: 298/4024 0.271s 0.000s
im_detect: 299/4024 0.271s 0.000s
im_detect: 300/4024 0.271s 0.000s
im_detect: 301/4024 0.271s 0.000s
im_detect: 302/4024 0.271s 0.000s
im_detect: 303/4024 0.271s 0.000s
im_detect: 304/4024 0.271s 0.000s
im_detect: 305/4024 0.271s 0.000s
im_detect: 306/4024 0.271s 0.000s
im_detect: 307/4024 0.271s 0.000s
im_detect: 308/4024 0.271s 0.000s
im_detect: 309/4024 0.271s 0.000s
im_detect: 310/4024 0.271s 0.000s
im_detect: 311/4024 0.271s 0.000s
im_detect: 312/4024 0.271s 0.000s
im_detect: 313/4024 0.271s 0.000s
im_detect: 314/4024 0.271s 0.000s
im_detect: 315/4024 0.271s 0.000s
im_detect: 316/4024 0.271s 0.000s
im_detect: 317/4024 0.271s 0.000s
im_detect: 318/4024 0.271s 0.000s
im_detect: 319/4024 0.271s 0.000s
im_detect: 320/4024 0.271s 0.000s
im_detect: 321/4024 0.271s 0.000s
im_detect: 322/4024 0.271s 0.000s
im_detect: 323/4024 0.271s 0.000s
im_detect: 324/4024 0.271s 0.000s
im_detect: 325/4024 0.271s 0.000s
im_detect: 326/4024 0.271s 0.000s
im_detect: 327/4024 0.271s 0.000s
im_detect: 328/4024 0.271s 0.000s
im_detect: 329/4024 0.271s 0.000s
im_detect: 330/4024 0.271s 0.000s
im_detect: 331/4024 0.271s 0.000s
im_detect: 332/4024 0.271s 0.000s
im_detect: 333/4024 0.271s 0.000s
im_detect: 334/4024 0.271s 0.000s
im_detect: 335/4024 0.271s 0.000s
im_detect: 336/4024 0.271s 0.000s
im_detect: 337/4024 0.271s 0.000s
im_detect: 338/4024 0.271s 0.000s
im_detect: 339/4024 0.271s 0.000s
im_detect: 340/4024 0.271s 0.000s
im_detect: 341/4024 0.271s 0.000s
im_detect: 342/4024 0.271s 0.000s
im_detect: 343/4024 0.271s 0.000s
im_detect: 344/4024 0.271s 0.000s
im_detect: 345/4024 0.271s 0.000s
im_detect: 346/4024 0.271s 0.000s
im_detect: 347/4024 0.271s 0.000s
im_detect: 348/4024 0.271s 0.000s
im_detect: 349/4024 0.271s 0.000s
im_detect: 350/4024 0.271s 0.000s
im_detect: 351/4024 0.271s 0.000s
im_detect: 352/4024 0.271s 0.000s
im_detect: 353/4024 0.271s 0.000s
im_detect: 354/4024 0.271s 0.000s
im_detect: 355/4024 0.271s 0.000s
im_detect: 356/4024 0.271s 0.000s
im_detect: 357/4024 0.271s 0.000s
im_detect: 358/4024 0.271s 0.000s
im_detect: 359/4024 0.271s 0.000s
im_detect: 360/4024 0.271s 0.000s
im_detect: 361/4024 0.271s 0.000s
im_detect: 362/4024 0.271s 0.000s
im_detect: 363/4024 0.271s 0.000s
im_detect: 364/4024 0.271s 0.000s
im_detect: 365/4024 0.271s 0.000s
im_detect: 366/4024 0.271s 0.000s
im_detect: 367/4024 0.271s 0.000s
im_detect: 368/4024 0.271s 0.000s
im_detect: 369/4024 0.271s 0.000s
im_detect: 370/4024 0.271s 0.000s
im_detect: 371/4024 0.272s 0.000s
im_detect: 372/4024 0.272s 0.000s
im_detect: 373/4024 0.272s 0.000s
im_detect: 374/4024 0.272s 0.000s
im_detect: 375/4024 0.272s 0.000s
im_detect: 376/4024 0.272s 0.000s
im_detect: 377/4024 0.272s 0.000s
im_detect: 378/4024 0.272s 0.000s
im_detect: 379/4024 0.272s 0.000s
im_detect: 380/4024 0.272s 0.000s
im_detect: 381/4024 0.272s 0.000s
im_detect: 382/4024 0.272s 0.000s
im_detect: 383/4024 0.272s 0.000s
im_detect: 384/4024 0.272s 0.000s
im_detect: 385/4024 0.272s 0.000s
im_detect: 386/4024 0.272s 0.000s
im_detect: 387/4024 0.272s 0.000s
im_detect: 388/4024 0.272s 0.000s
im_detect: 389/4024 0.272s 0.000s
im_detect: 390/4024 0.272s 0.000s
im_detect: 391/4024 0.272s 0.000s
im_detect: 392/4024 0.272s 0.000s
im_detect: 393/4024 0.272s 0.000s
im_detect: 394/4024 0.272s 0.000s
im_detect: 395/4024 0.272s 0.000s
im_detect: 396/4024 0.272s 0.000s
im_detect: 397/4024 0.272s 0.000s
im_detect: 398/4024 0.271s 0.000s
im_detect: 399/4024 0.271s 0.000s
im_detect: 400/4024 0.271s 0.000s
im_detect: 401/4024 0.271s 0.000s
im_detect: 402/4024 0.271s 0.000s
im_detect: 403/4024 0.271s 0.000s
im_detect: 404/4024 0.271s 0.000s
im_detect: 405/4024 0.271s 0.000s
im_detect: 406/4024 0.271s 0.000s
im_detect: 407/4024 0.271s 0.000s
im_detect: 408/4024 0.271s 0.000s
im_detect: 409/4024 0.271s 0.000s
im_detect: 410/4024 0.271s 0.000s
im_detect: 411/4024 0.271s 0.000s
im_detect: 412/4024 0.271s 0.000s
im_detect: 413/4024 0.271s 0.000s
im_detect: 414/4024 0.271s 0.000s
im_detect: 415/4024 0.271s 0.000s
im_detect: 416/4024 0.271s 0.000s
im_detect: 417/4024 0.271s 0.000s
im_detect: 418/4024 0.271s 0.000s
im_detect: 419/4024 0.271s 0.000s
im_detect: 420/4024 0.271s 0.000s
im_detect: 421/4024 0.271s 0.000s
im_detect: 422/4024 0.271s 0.000s
im_detect: 423/4024 0.271s 0.000s
im_detect: 424/4024 0.271s 0.000s
im_detect: 425/4024 0.271s 0.000s
im_detect: 426/4024 0.271s 0.000s
im_detect: 427/4024 0.271s 0.000s
im_detect: 428/4024 0.271s 0.000s
im_detect: 429/4024 0.271s 0.000s
im_detect: 430/4024 0.271s 0.000s
im_detect: 431/4024 0.271s 0.000s
im_detect: 432/4024 0.271s 0.000s
im_detect: 433/4024 0.271s 0.000s
im_detect: 434/4024 0.271s 0.000s
im_detect: 435/4024 0.271s 0.000s
im_detect: 436/4024 0.271s 0.000s
im_detect: 437/4024 0.271s 0.000s
im_detect: 438/4024 0.271s 0.000s
im_detect: 439/4024 0.271s 0.000s
im_detect: 440/4024 0.271s 0.000s
im_detect: 441/4024 0.271s 0.000s
im_detect: 442/4024 0.271s 0.000s
im_detect: 443/4024 0.271s 0.000s
im_detect: 444/4024 0.271s 0.000s
im_detect: 445/4024 0.271s 0.000s
im_detect: 446/4024 0.271s 0.000s
im_detect: 447/4024 0.271s 0.000s
im_detect: 448/4024 0.271s 0.000s
im_detect: 449/4024 0.271s 0.000s
im_detect: 450/4024 0.271s 0.000s
im_detect: 451/4024 0.271s 0.000s
im_detect: 452/4024 0.271s 0.000s
im_detect: 453/4024 0.271s 0.000s
im_detect: 454/4024 0.271s 0.000s
im_detect: 455/4024 0.271s 0.000s
im_detect: 456/4024 0.271s 0.000s
im_detect: 457/4024 0.271s 0.000s
im_detect: 458/4024 0.271s 0.000s
im_detect: 459/4024 0.271s 0.000s
im_detect: 460/4024 0.271s 0.000s
im_detect: 461/4024 0.271s 0.000s
im_detect: 462/4024 0.271s 0.000s
im_detect: 463/4024 0.271s 0.000s
im_detect: 464/4024 0.271s 0.000s
im_detect: 465/4024 0.271s 0.000s
im_detect: 466/4024 0.271s 0.000s
im_detect: 467/4024 0.271s 0.000s
im_detect: 468/4024 0.271s 0.000s
im_detect: 469/4024 0.271s 0.000s
im_detect: 470/4024 0.271s 0.000s
im_detect: 471/4024 0.271s 0.000s
im_detect: 472/4024 0.271s 0.000s
im_detect: 473/4024 0.271s 0.000s
im_detect: 474/4024 0.271s 0.000s
im_detect: 475/4024 0.271s 0.000s
im_detect: 476/4024 0.271s 0.000s
im_detect: 477/4024 0.271s 0.000s
im_detect: 478/4024 0.271s 0.000s
im_detect: 479/4024 0.271s 0.000s
im_detect: 480/4024 0.271s 0.000s
im_detect: 481/4024 0.271s 0.000s
im_detect: 482/4024 0.271s 0.000s
im_detect: 483/4024 0.271s 0.000s
im_detect: 484/4024 0.271s 0.000s
im_detect: 485/4024 0.271s 0.000s
im_detect: 486/4024 0.271s 0.000s
im_detect: 487/4024 0.271s 0.000s
im_detect: 488/4024 0.271s 0.000s
im_detect: 489/4024 0.271s 0.000s
im_detect: 490/4024 0.271s 0.000s
im_detect: 491/4024 0.271s 0.000s
im_detect: 492/4024 0.271s 0.000s
im_detect: 493/4024 0.271s 0.000s
im_detect: 494/4024 0.271s 0.000s
im_detect: 495/4024 0.271s 0.000s
im_detect: 496/4024 0.271s 0.000s
im_detect: 497/4024 0.271s 0.000s
im_detect: 498/4024 0.271s 0.000s
im_detect: 499/4024 0.271s 0.000s
im_detect: 500/4024 0.271s 0.000s
im_detect: 501/4024 0.271s 0.000s
im_detect: 502/4024 0.271s 0.000s
im_detect: 503/4024 0.271s 0.000s
im_detect: 504/4024 0.271s 0.000s
im_detect: 505/4024 0.271s 0.000s
im_detect: 506/4024 0.271s 0.000s
im_detect: 507/4024 0.271s 0.000s
im_detect: 508/4024 0.271s 0.000s
im_detect: 509/4024 0.271s 0.000s
im_detect: 510/4024 0.271s 0.000s
im_detect: 511/4024 0.271s 0.000s
im_detect: 512/4024 0.271s 0.000s
im_detect: 513/4024 0.271s 0.000s
im_detect: 514/4024 0.271s 0.000s
im_detect: 515/4024 0.271s 0.000s
im_detect: 516/4024 0.271s 0.000s
im_detect: 517/4024 0.271s 0.000s
im_detect: 518/4024 0.271s 0.000s
im_detect: 519/4024 0.271s 0.000s
im_detect: 520/4024 0.271s 0.000s
im_detect: 521/4024 0.271s 0.000s
im_detect: 522/4024 0.271s 0.000s
im_detect: 523/4024 0.271s 0.000s
im_detect: 524/4024 0.271s 0.000s
im_detect: 525/4024 0.272s 0.000s
im_detect: 526/4024 0.272s 0.000s
im_detect: 527/4024 0.272s 0.000s
im_detect: 528/4024 0.272s 0.000s
im_detect: 529/4024 0.272s 0.000s
im_detect: 530/4024 0.272s 0.000s
im_detect: 531/4024 0.272s 0.000s
im_detect: 532/4024 0.272s 0.000s
im_detect: 533/4024 0.272s 0.000s
im_detect: 534/4024 0.272s 0.000s
im_detect: 535/4024 0.272s 0.000s
im_detect: 536/4024 0.272s 0.000s
im_detect: 537/4024 0.272s 0.000s
im_detect: 538/4024 0.272s 0.000s
im_detect: 539/4024 0.272s 0.000s
im_detect: 540/4024 0.272s 0.000s
im_detect: 541/4024 0.272s 0.000s
im_detect: 542/4024 0.272s 0.000s
im_detect: 543/4024 0.272s 0.000s
im_detect: 544/4024 0.272s 0.000s
im_detect: 545/4024 0.272s 0.000s
im_detect: 546/4024 0.272s 0.000s
im_detect: 547/4024 0.272s 0.000s
im_detect: 548/4024 0.272s 0.000s
im_detect: 549/4024 0.272s 0.000s
im_detect: 550/4024 0.272s 0.000s
im_detect: 551/4024 0.272s 0.000s
im_detect: 552/4024 0.272s 0.000s
im_detect: 553/4024 0.272s 0.000s
im_detect: 554/4024 0.272s 0.000s
im_detect: 555/4024 0.272s 0.000s
im_detect: 556/4024 0.272s 0.000s
im_detect: 557/4024 0.272s 0.000s
im_detect: 558/4024 0.272s 0.000s
im_detect: 559/4024 0.272s 0.000s
im_detect: 560/4024 0.272s 0.000s
im_detect: 561/4024 0.272s 0.000s
im_detect: 562/4024 0.272s 0.000s
im_detect: 563/4024 0.272s 0.000s
im_detect: 564/4024 0.272s 0.000s
im_detect: 565/4024 0.272s 0.000s
im_detect: 566/4024 0.272s 0.000s
im_detect: 567/4024 0.272s 0.000s
im_detect: 568/4024 0.272s 0.000s
im_detect: 569/4024 0.272s 0.000s
im_detect: 570/4024 0.272s 0.000s
im_detect: 571/4024 0.272s 0.000s
im_detect: 572/4024 0.272s 0.000s
im_detect: 573/4024 0.272s 0.000s
im_detect: 574/4024 0.272s 0.000s
im_detect: 575/4024 0.272s 0.000s
im_detect: 576/4024 0.272s 0.000s
im_detect: 577/4024 0.272s 0.000s
im_detect: 578/4024 0.272s 0.000s
im_detect: 579/4024 0.272s 0.000s
im_detect: 580/4024 0.272s 0.000s
im_detect: 581/4024 0.272s 0.000s
im_detect: 582/4024 0.272s 0.000s
im_detect: 583/4024 0.272s 0.000s
im_detect: 584/4024 0.272s 0.000s
im_detect: 585/4024 0.272s 0.000s
im_detect: 586/4024 0.272s 0.000s
im_detect: 587/4024 0.272s 0.000s
im_detect: 588/4024 0.272s 0.000s
im_detect: 589/4024 0.272s 0.000s
im_detect: 590/4024 0.272s 0.000s
im_detect: 591/4024 0.272s 0.000s
im_detect: 592/4024 0.272s 0.000s
im_detect: 593/4024 0.272s 0.000s
im_detect: 594/4024 0.272s 0.000s
im_detect: 595/4024 0.272s 0.000s
im_detect: 596/4024 0.272s 0.000s
im_detect: 597/4024 0.272s 0.000s
im_detect: 598/4024 0.272s 0.000s
im_detect: 599/4024 0.272s 0.000s
im_detect: 600/4024 0.272s 0.000s
im_detect: 601/4024 0.272s 0.000s
im_detect: 602/4024 0.272s 0.000s
im_detect: 603/4024 0.272s 0.000s
im_detect: 604/4024 0.272s 0.000s
im_detect: 605/4024 0.272s 0.000s
im_detect: 606/4024 0.272s 0.000s
im_detect: 607/4024 0.272s 0.000s
im_detect: 608/4024 0.272s 0.000s
im_detect: 609/4024 0.272s 0.000s
im_detect: 610/4024 0.272s 0.000s
im_detect: 611/4024 0.272s 0.000s
im_detect: 612/4024 0.272s 0.000s
im_detect: 613/4024 0.272s 0.000s
im_detect: 614/4024 0.272s 0.000s
im_detect: 615/4024 0.272s 0.000s
im_detect: 616/4024 0.272s 0.000s
im_detect: 617/4024 0.272s 0.000s
im_detect: 618/4024 0.271s 0.000s
im_detect: 619/4024 0.271s 0.000s
im_detect: 620/4024 0.272s 0.000s
im_detect: 621/4024 0.272s 0.000s
im_detect: 622/4024 0.272s 0.000s
im_detect: 623/4024 0.272s 0.000s
im_detect: 624/4024 0.272s 0.000s
im_detect: 625/4024 0.272s 0.000s
im_detect: 626/4024 0.271s 0.000s
im_detect: 627/4024 0.271s 0.000s
im_detect: 628/4024 0.271s 0.000s
im_detect: 629/4024 0.271s 0.000s
im_detect: 630/4024 0.271s 0.000s
im_detect: 631/4024 0.271s 0.000s
im_detect: 632/4024 0.271s 0.000s
im_detect: 633/4024 0.271s 0.000s
im_detect: 634/4024 0.271s 0.000s
im_detect: 635/4024 0.271s 0.000s
im_detect: 636/4024 0.271s 0.000s
im_detect: 637/4024 0.271s 0.000s
im_detect: 638/4024 0.271s 0.000s
im_detect: 639/4024 0.271s 0.000s
im_detect: 640/4024 0.271s 0.000s
im_detect: 641/4024 0.271s 0.000s
im_detect: 642/4024 0.271s 0.000s
im_detect: 643/4024 0.271s 0.000s
im_detect: 644/4024 0.271s 0.000s
im_detect: 645/4024 0.271s 0.000s
im_detect: 646/4024 0.271s 0.000s
im_detect: 647/4024 0.271s 0.000s
im_detect: 648/4024 0.271s 0.000s
im_detect: 649/4024 0.271s 0.000s
im_detect: 650/4024 0.271s 0.000s
im_detect: 651/4024 0.271s 0.000s
im_detect: 652/4024 0.271s 0.000s
im_detect: 653/4024 0.271s 0.000s
im_detect: 654/4024 0.271s 0.000s
im_detect: 655/4024 0.271s 0.000s
im_detect: 656/4024 0.271s 0.000s
im_detect: 657/4024 0.271s 0.000s
im_detect: 658/4024 0.271s 0.000s
im_detect: 659/4024 0.271s 0.000s
im_detect: 660/4024 0.271s 0.000s
im_detect: 661/4024 0.271s 0.000s
im_detect: 662/4024 0.271s 0.000s
im_detect: 663/4024 0.271s 0.000s
im_detect: 664/4024 0.271s 0.000s
im_detect: 665/4024 0.271s 0.000s
im_detect: 666/4024 0.271s 0.000s
im_detect: 667/4024 0.271s 0.000s
im_detect: 668/4024 0.271s 0.000s
im_detect: 669/4024 0.271s 0.000s
im_detect: 670/4024 0.271s 0.000s
im_detect: 671/4024 0.271s 0.000s
im_detect: 672/4024 0.271s 0.000s
im_detect: 673/4024 0.271s 0.000s
im_detect: 674/4024 0.271s 0.000s
im_detect: 675/4024 0.271s 0.000s
im_detect: 676/4024 0.271s 0.000s
im_detect: 677/4024 0.271s 0.000s
im_detect: 678/4024 0.271s 0.000s
im_detect: 679/4024 0.271s 0.000s
im_detect: 680/4024 0.271s 0.000s
im_detect: 681/4024 0.271s 0.000s
im_detect: 682/4024 0.271s 0.000s
im_detect: 683/4024 0.271s 0.000s
im_detect: 684/4024 0.271s 0.000s
im_detect: 685/4024 0.271s 0.000s
im_detect: 686/4024 0.271s 0.000s
im_detect: 687/4024 0.271s 0.000s
im_detect: 688/4024 0.271s 0.000s
im_detect: 689/4024 0.271s 0.000s
im_detect: 690/4024 0.271s 0.000s
im_detect: 691/4024 0.271s 0.000s
im_detect: 692/4024 0.271s 0.000s
im_detect: 693/4024 0.271s 0.000s
im_detect: 694/4024 0.271s 0.000s
im_detect: 695/4024 0.271s 0.000s
im_detect: 696/4024 0.271s 0.000s
im_detect: 697/4024 0.271s 0.000s
im_detect: 698/4024 0.271s 0.000s
im_detect: 699/4024 0.271s 0.000s
im_detect: 700/4024 0.271s 0.000s
im_detect: 701/4024 0.271s 0.000s
im_detect: 702/4024 0.271s 0.000s
im_detect: 703/4024 0.271s 0.000s
im_detect: 704/4024 0.271s 0.000s
im_detect: 705/4024 0.271s 0.000s
im_detect: 706/4024 0.271s 0.000s
im_detect: 707/4024 0.271s 0.000s
im_detect: 708/4024 0.271s 0.000s
im_detect: 709/4024 0.271s 0.000s
im_detect: 710/4024 0.271s 0.000s
im_detect: 711/4024 0.271s 0.000s
im_detect: 712/4024 0.271s 0.000s
im_detect: 713/4024 0.271s 0.000s
im_detect: 714/4024 0.271s 0.000s
im_detect: 715/4024 0.271s 0.000s
im_detect: 716/4024 0.271s 0.000s
im_detect: 717/4024 0.271s 0.000s
im_detect: 718/4024 0.271s 0.000s
im_detect: 719/4024 0.271s 0.000s
im_detect: 720/4024 0.271s 0.000s
im_detect: 721/4024 0.271s 0.000s
im_detect: 722/4024 0.271s 0.000s
im_detect: 723/4024 0.271s 0.000s
im_detect: 724/4024 0.271s 0.000s
im_detect: 725/4024 0.271s 0.000s
im_detect: 726/4024 0.271s 0.000s
im_detect: 727/4024 0.271s 0.000s
im_detect: 728/4024 0.271s 0.000s
im_detect: 729/4024 0.271s 0.000s
im_detect: 730/4024 0.271s 0.000s
im_detect: 731/4024 0.271s 0.000s
im_detect: 732/4024 0.271s 0.000s
im_detect: 733/4024 0.271s 0.000s
im_detect: 734/4024 0.271s 0.000s
im_detect: 735/4024 0.271s 0.000s
im_detect: 736/4024 0.271s 0.000s
im_detect: 737/4024 0.271s 0.000s
im_detect: 738/4024 0.271s 0.000s
im_detect: 739/4024 0.271s 0.000s
im_detect: 740/4024 0.271s 0.000s
im_detect: 741/4024 0.271s 0.000s
im_detect: 742/4024 0.271s 0.000s
im_detect: 743/4024 0.271s 0.000s
im_detect: 744/4024 0.271s 0.000s
im_detect: 745/4024 0.271s 0.000s
im_detect: 746/4024 0.271s 0.000s
im_detect: 747/4024 0.271s 0.000s
im_detect: 748/4024 0.271s 0.000s
im_detect: 749/4024 0.271s 0.000s
im_detect: 750/4024 0.271s 0.000s
im_detect: 751/4024 0.271s 0.000s
im_detect: 752/4024 0.271s 0.000s
im_detect: 753/4024 0.271s 0.000s
im_detect: 754/4024 0.271s 0.000s
im_detect: 755/4024 0.271s 0.000s
im_detect: 756/4024 0.271s 0.000s
im_detect: 757/4024 0.271s 0.000s
im_detect: 758/4024 0.271s 0.000s
im_detect: 759/4024 0.271s 0.000s
im_detect: 760/4024 0.271s 0.000s
im_detect: 761/4024 0.271s 0.000s
im_detect: 762/4024 0.271s 0.000s
im_detect: 763/4024 0.271s 0.000s
im_detect: 764/4024 0.271s 0.000s
im_detect: 765/4024 0.271s 0.000s
im_detect: 766/4024 0.271s 0.000s
im_detect: 767/4024 0.271s 0.000s
im_detect: 768/4024 0.271s 0.000s
im_detect: 769/4024 0.271s 0.000s
im_detect: 770/4024 0.271s 0.000s
im_detect: 771/4024 0.271s 0.000s
im_detect: 772/4024 0.271s 0.000s
im_detect: 773/4024 0.271s 0.000s
im_detect: 774/4024 0.271s 0.000s
im_detect: 775/4024 0.271s 0.000s
im_detect: 776/4024 0.271s 0.000s
im_detect: 777/4024 0.271s 0.000s
im_detect: 778/4024 0.271s 0.000s
im_detect: 779/4024 0.271s 0.000s
im_detect: 780/4024 0.271s 0.000s
im_detect: 781/4024 0.271s 0.000s
im_detect: 782/4024 0.271s 0.000s
im_detect: 783/4024 0.271s 0.000s
im_detect: 784/4024 0.271s 0.000s
im_detect: 785/4024 0.271s 0.000s
im_detect: 786/4024 0.271s 0.000s
im_detect: 787/4024 0.271s 0.000s
im_detect: 788/4024 0.271s 0.000s
im_detect: 789/4024 0.271s 0.000s
im_detect: 790/4024 0.271s 0.000s
im_detect: 791/4024 0.271s 0.000s
im_detect: 792/4024 0.271s 0.000s
im_detect: 793/4024 0.271s 0.000s
im_detect: 794/4024 0.271s 0.000s
im_detect: 795/4024 0.271s 0.000s
im_detect: 796/4024 0.271s 0.000s
im_detect: 797/4024 0.271s 0.000s
im_detect: 798/4024 0.271s 0.000s
im_detect: 799/4024 0.271s 0.000s
im_detect: 800/4024 0.271s 0.000s
im_detect: 801/4024 0.271s 0.000s
im_detect: 802/4024 0.271s 0.000s
im_detect: 803/4024 0.271s 0.000s
im_detect: 804/4024 0.271s 0.000s
im_detect: 805/4024 0.271s 0.000s
im_detect: 806/4024 0.271s 0.000s
im_detect: 807/4024 0.271s 0.000s
im_detect: 808/4024 0.271s 0.000s
im_detect: 809/4024 0.271s 0.000s
im_detect: 810/4024 0.271s 0.000s
im_detect: 811/4024 0.271s 0.000s
im_detect: 812/4024 0.271s 0.000s
im_detect: 813/4024 0.271s 0.000s
im_detect: 814/4024 0.271s 0.000s
im_detect: 815/4024 0.271s 0.000s
im_detect: 816/4024 0.271s 0.000s
im_detect: 817/4024 0.271s 0.000s
im_detect: 818/4024 0.271s 0.000s
im_detect: 819/4024 0.271s 0.000s
im_detect: 820/4024 0.271s 0.000s
im_detect: 821/4024 0.271s 0.000s
im_detect: 822/4024 0.271s 0.000s
im_detect: 823/4024 0.271s 0.000s
im_detect: 824/4024 0.271s 0.000s
im_detect: 825/4024 0.271s 0.000s
im_detect: 826/4024 0.271s 0.000s
im_detect: 827/4024 0.271s 0.000s
im_detect: 828/4024 0.271s 0.000s
im_detect: 829/4024 0.271s 0.000s
im_detect: 830/4024 0.271s 0.000s
im_detect: 831/4024 0.271s 0.000s
im_detect: 832/4024 0.271s 0.000s
im_detect: 833/4024 0.271s 0.000s
im_detect: 834/4024 0.271s 0.000s
im_detect: 835/4024 0.271s 0.000s
im_detect: 836/4024 0.271s 0.000s
im_detect: 837/4024 0.271s 0.000s
im_detect: 838/4024 0.271s 0.000s
im_detect: 839/4024 0.271s 0.000s
im_detect: 840/4024 0.271s 0.000s
im_detect: 841/4024 0.271s 0.000s
im_detect: 842/4024 0.271s 0.000s
im_detect: 843/4024 0.271s 0.000s
im_detect: 844/4024 0.271s 0.000s
im_detect: 845/4024 0.271s 0.000s
im_detect: 846/4024 0.271s 0.000s
im_detect: 847/4024 0.271s 0.000s
im_detect: 848/4024 0.271s 0.000s
im_detect: 849/4024 0.271s 0.000s
im_detect: 850/4024 0.271s 0.000s
im_detect: 851/4024 0.271s 0.000s
im_detect: 852/4024 0.271s 0.000s
im_detect: 853/4024 0.271s 0.000s
im_detect: 854/4024 0.271s 0.000s
im_detect: 855/4024 0.271s 0.000s
im_detect: 856/4024 0.271s 0.000s
im_detect: 857/4024 0.271s 0.000s
im_detect: 858/4024 0.271s 0.000s
im_detect: 859/4024 0.271s 0.000s
im_detect: 860/4024 0.271s 0.000s
im_detect: 861/4024 0.271s 0.000s
im_detect: 862/4024 0.271s 0.000s
im_detect: 863/4024 0.271s 0.000s
im_detect: 864/4024 0.271s 0.000s
im_detect: 865/4024 0.271s 0.000s
im_detect: 866/4024 0.271s 0.000s
im_detect: 867/4024 0.271s 0.000s
im_detect: 868/4024 0.271s 0.000s
im_detect: 869/4024 0.271s 0.000s
im_detect: 870/4024 0.271s 0.000s
im_detect: 871/4024 0.271s 0.000s
im_detect: 872/4024 0.271s 0.000s
im_detect: 873/4024 0.271s 0.000s
im_detect: 874/4024 0.271s 0.000s
im_detect: 875/4024 0.271s 0.000s
im_detect: 876/4024 0.271s 0.000s
im_detect: 877/4024 0.271s 0.000s
im_detect: 878/4024 0.271s 0.000s
im_detect: 879/4024 0.271s 0.000s
im_detect: 880/4024 0.271s 0.000s
im_detect: 881/4024 0.271s 0.000s
im_detect: 882/4024 0.271s 0.000s
im_detect: 883/4024 0.271s 0.000s
im_detect: 884/4024 0.271s 0.000s
im_detect: 885/4024 0.271s 0.000s
im_detect: 886/4024 0.271s 0.000s
im_detect: 887/4024 0.271s 0.000s
im_detect: 888/4024 0.271s 0.000s
im_detect: 889/4024 0.271s 0.000s
im_detect: 890/4024 0.271s 0.000s
im_detect: 891/4024 0.271s 0.000s
im_detect: 892/4024 0.271s 0.000s
im_detect: 893/4024 0.271s 0.000s
im_detect: 894/4024 0.271s 0.000s
im_detect: 895/4024 0.271s 0.000s
im_detect: 896/4024 0.271s 0.000s
im_detect: 897/4024 0.271s 0.000s
im_detect: 898/4024 0.271s 0.000s
im_detect: 899/4024 0.271s 0.000s
im_detect: 900/4024 0.271s 0.000s
im_detect: 901/4024 0.271s 0.000s
im_detect: 902/4024 0.271s 0.000s
im_detect: 903/4024 0.271s 0.000s
im_detect: 904/4024 0.271s 0.000s
im_detect: 905/4024 0.271s 0.000s
im_detect: 906/4024 0.271s 0.000s
im_detect: 907/4024 0.271s 0.000s
im_detect: 908/4024 0.271s 0.000s
im_detect: 909/4024 0.271s 0.000s
im_detect: 910/4024 0.271s 0.000s
im_detect: 911/4024 0.271s 0.000s
im_detect: 912/4024 0.271s 0.000s
im_detect: 913/4024 0.271s 0.000s
im_detect: 914/4024 0.271s 0.000s
im_detect: 915/4024 0.271s 0.000s
im_detect: 916/4024 0.271s 0.000s
im_detect: 917/4024 0.271s 0.000s
im_detect: 918/4024 0.271s 0.000s
im_detect: 919/4024 0.271s 0.000s
im_detect: 920/4024 0.271s 0.000s
im_detect: 921/4024 0.271s 0.000s
im_detect: 922/4024 0.271s 0.000s
im_detect: 923/4024 0.271s 0.000s
im_detect: 924/4024 0.271s 0.000s
im_detect: 925/4024 0.271s 0.000s
im_detect: 926/4024 0.271s 0.000s
im_detect: 927/4024 0.271s 0.000s
im_detect: 928/4024 0.271s 0.000s
im_detect: 929/4024 0.271s 0.000s
im_detect: 930/4024 0.271s 0.000s
im_detect: 931/4024 0.271s 0.000s
im_detect: 932/4024 0.271s 0.000s
im_detect: 933/4024 0.271s 0.000s
im_detect: 934/4024 0.271s 0.000s
im_detect: 935/4024 0.271s 0.000s
im_detect: 936/4024 0.271s 0.000s
im_detect: 937/4024 0.271s 0.000s
im_detect: 938/4024 0.271s 0.000s
im_detect: 939/4024 0.271s 0.000s
im_detect: 940/4024 0.271s 0.000s
im_detect: 941/4024 0.271s 0.000s
im_detect: 942/4024 0.271s 0.000s
im_detect: 943/4024 0.271s 0.000s
im_detect: 944/4024 0.271s 0.000s
im_detect: 945/4024 0.271s 0.000s
im_detect: 946/4024 0.271s 0.000s
im_detect: 947/4024 0.271s 0.000s
im_detect: 948/4024 0.271s 0.000s
im_detect: 949/4024 0.271s 0.000s
im_detect: 950/4024 0.271s 0.000s
im_detect: 951/4024 0.271s 0.000s
im_detect: 952/4024 0.271s 0.000s
im_detect: 953/4024 0.271s 0.000s
im_detect: 954/4024 0.271s 0.000s
im_detect: 955/4024 0.271s 0.000s
im_detect: 956/4024 0.271s 0.000s
im_detect: 957/4024 0.271s 0.000s
im_detect: 958/4024 0.271s 0.000s
im_detect: 959/4024 0.271s 0.000s
im_detect: 960/4024 0.271s 0.000s
im_detect: 961/4024 0.271s 0.000s
im_detect: 962/4024 0.271s 0.000s
im_detect: 963/4024 0.271s 0.000s
im_detect: 964/4024 0.271s 0.000s
im_detect: 965/4024 0.271s 0.000s
im_detect: 966/4024 0.271s 0.000s
im_detect: 967/4024 0.271s 0.000s
im_detect: 968/4024 0.271s 0.000s
im_detect: 969/4024 0.271s 0.000s
im_detect: 970/4024 0.271s 0.000s
im_detect: 971/4024 0.271s 0.000s
im_detect: 972/4024 0.271s 0.000s
im_detect: 973/4024 0.271s 0.000s
im_detect: 974/4024 0.271s 0.000s
im_detect: 975/4024 0.271s 0.000s
im_detect: 976/4024 0.271s 0.000s
im_detect: 977/4024 0.271s 0.000s
im_detect: 978/4024 0.271s 0.000s
im_detect: 979/4024 0.271s 0.000s
im_detect: 980/4024 0.271s 0.000s
im_detect: 981/4024 0.271s 0.000s
im_detect: 982/4024 0.271s 0.000s
im_detect: 983/4024 0.271s 0.000s
im_detect: 984/4024 0.271s 0.000s
im_detect: 985/4024 0.271s 0.000s
im_detect: 986/4024 0.271s 0.000s
im_detect: 987/4024 0.271s 0.000s
im_detect: 988/4024 0.271s 0.000s
im_detect: 989/4024 0.271s 0.000s
im_detect: 990/4024 0.271s 0.000s
im_detect: 991/4024 0.271s 0.000s
im_detect: 992/4024 0.271s 0.000s
im_detect: 993/4024 0.271s 0.000s
im_detect: 994/4024 0.271s 0.000s
im_detect: 995/4024 0.271s 0.000s
im_detect: 996/4024 0.271s 0.000s
im_detect: 997/4024 0.271s 0.000s
im_detect: 998/4024 0.271s 0.000s
im_detect: 999/4024 0.271s 0.000s
im_detect: 1000/4024 0.271s 0.000s
im_detect: 1001/4024 0.271s 0.000s
im_detect: 1002/4024 0.271s 0.000s
im_detect: 1003/4024 0.271s 0.000s
im_detect: 1004/4024 0.271s 0.000s
im_detect: 1005/4024 0.271s 0.000s
im_detect: 1006/4024 0.271s 0.000s
im_detect: 1007/4024 0.271s 0.000s
im_detect: 1008/4024 0.271s 0.000s
im_detect: 1009/4024 0.271s 0.000s
im_detect: 1010/4024 0.271s 0.000s
im_detect: 1011/4024 0.271s 0.000s
im_detect: 1012/4024 0.271s 0.000s
im_detect: 1013/4024 0.271s 0.000s
im_detect: 1014/4024 0.271s 0.000s
im_detect: 1015/4024 0.271s 0.000s
im_detect: 1016/4024 0.271s 0.000s
im_detect: 1017/4024 0.271s 0.000s
im_detect: 1018/4024 0.271s 0.000s
im_detect: 1019/4024 0.271s 0.000s
im_detect: 1020/4024 0.271s 0.000s
im_detect: 1021/4024 0.271s 0.000s
im_detect: 1022/4024 0.271s 0.000s
im_detect: 1023/4024 0.271s 0.000s
im_detect: 1024/4024 0.271s 0.000s
im_detect: 1025/4024 0.271s 0.000s
im_detect: 1026/4024 0.271s 0.000s
im_detect: 1027/4024 0.271s 0.000s
im_detect: 1028/4024 0.271s 0.000s
im_detect: 1029/4024 0.271s 0.000s
im_detect: 1030/4024 0.271s 0.000s
im_detect: 1031/4024 0.271s 0.000s
im_detect: 1032/4024 0.271s 0.000s
im_detect: 1033/4024 0.271s 0.000s
im_detect: 1034/4024 0.271s 0.000s
im_detect: 1035/4024 0.271s 0.000s
im_detect: 1036/4024 0.271s 0.000s
im_detect: 1037/4024 0.271s 0.000s
im_detect: 1038/4024 0.271s 0.000s
im_detect: 1039/4024 0.271s 0.000s
im_detect: 1040/4024 0.271s 0.000s
im_detect: 1041/4024 0.271s 0.000s
im_detect: 1042/4024 0.271s 0.000s
im_detect: 1043/4024 0.271s 0.000s
im_detect: 1044/4024 0.271s 0.000s
im_detect: 1045/4024 0.271s 0.000s
im_detect: 1046/4024 0.271s 0.000s
im_detect: 1047/4024 0.271s 0.000s
im_detect: 1048/4024 0.271s 0.000s
im_detect: 1049/4024 0.271s 0.000s
im_detect: 1050/4024 0.271s 0.000s
im_detect: 1051/4024 0.271s 0.000s
im_detect: 1052/4024 0.271s 0.000s
im_detect: 1053/4024 0.271s 0.000s
im_detect: 1054/4024 0.271s 0.000s
im_detect: 1055/4024 0.271s 0.000s
im_detect: 1056/4024 0.271s 0.000s
im_detect: 1057/4024 0.271s 0.000s
im_detect: 1058/4024 0.271s 0.000s
im_detect: 1059/4024 0.271s 0.000s
im_detect: 1060/4024 0.271s 0.000s
im_detect: 1061/4024 0.271s 0.000s
im_detect: 1062/4024 0.271s 0.000s
im_detect: 1063/4024 0.271s 0.000s
im_detect: 1064/4024 0.271s 0.000s
im_detect: 1065/4024 0.271s 0.000s
im_detect: 1066/4024 0.271s 0.000s
im_detect: 1067/4024 0.271s 0.000s
im_detect: 1068/4024 0.271s 0.000s
im_detect: 1069/4024 0.271s 0.000s
im_detect: 1070/4024 0.271s 0.000s
im_detect: 1071/4024 0.271s 0.000s
im_detect: 1072/4024 0.271s 0.000s
im_detect: 1073/4024 0.271s 0.000s
im_detect: 1074/4024 0.271s 0.000s
im_detect: 1075/4024 0.271s 0.000s
im_detect: 1076/4024 0.271s 0.000s
im_detect: 1077/4024 0.271s 0.000s
im_detect: 1078/4024 0.271s 0.000s
im_detect: 1079/4024 0.271s 0.000s
im_detect: 1080/4024 0.271s 0.000s
im_detect: 1081/4024 0.271s 0.000s
im_detect: 1082/4024 0.271s 0.000s
im_detect: 1083/4024 0.271s 0.000s
im_detect: 1084/4024 0.271s 0.000s
im_detect: 1085/4024 0.271s 0.000s
im_detect: 1086/4024 0.271s 0.000s
im_detect: 1087/4024 0.271s 0.000s
im_detect: 1088/4024 0.271s 0.000s
im_detect: 1089/4024 0.271s 0.000s
im_detect: 1090/4024 0.271s 0.000s
im_detect: 1091/4024 0.271s 0.000s
im_detect: 1092/4024 0.271s 0.000s
im_detect: 1093/4024 0.271s 0.000s
im_detect: 1094/4024 0.271s 0.000s
im_detect: 1095/4024 0.271s 0.000s
im_detect: 1096/4024 0.271s 0.000s
im_detect: 1097/4024 0.271s 0.000s
im_detect: 1098/4024 0.271s 0.000s
im_detect: 1099/4024 0.271s 0.000s
im_detect: 1100/4024 0.271s 0.000s
im_detect: 1101/4024 0.271s 0.000s
im_detect: 1102/4024 0.271s 0.000s
im_detect: 1103/4024 0.271s 0.000s
im_detect: 1104/4024 0.271s 0.000s
im_detect: 1105/4024 0.271s 0.000s
im_detect: 1106/4024 0.271s 0.000s
im_detect: 1107/4024 0.271s 0.000s
im_detect: 1108/4024 0.271s 0.000s
im_detect: 1109/4024 0.271s 0.000s
im_detect: 1110/4024 0.271s 0.000s
im_detect: 1111/4024 0.271s 0.000s
im_detect: 1112/4024 0.271s 0.000s
im_detect: 1113/4024 0.271s 0.000s
im_detect: 1114/4024 0.271s 0.000s
im_detect: 1115/4024 0.271s 0.000s
im_detect: 1116/4024 0.271s 0.000s
im_detect: 1117/4024 0.271s 0.000s
im_detect: 1118/4024 0.271s 0.000s
im_detect: 1119/4024 0.271s 0.000s
im_detect: 1120/4024 0.271s 0.000s
im_detect: 1121/4024 0.271s 0.000s
im_detect: 1122/4024 0.271s 0.000s
im_detect: 1123/4024 0.271s 0.000s
im_detect: 1124/4024 0.271s 0.000s
im_detect: 1125/4024 0.271s 0.000s
im_detect: 1126/4024 0.271s 0.000s
im_detect: 1127/4024 0.271s 0.000s
im_detect: 1128/4024 0.271s 0.000s
im_detect: 1129/4024 0.271s 0.000s
im_detect: 1130/4024 0.271s 0.000s
im_detect: 1131/4024 0.271s 0.000s
im_detect: 1132/4024 0.271s 0.000s
im_detect: 1133/4024 0.271s 0.000s
im_detect: 1134/4024 0.271s 0.000s
im_detect: 1135/4024 0.271s 0.000s
im_detect: 1136/4024 0.271s 0.000s
im_detect: 1137/4024 0.271s 0.000s
im_detect: 1138/4024 0.271s 0.000s
im_detect: 1139/4024 0.271s 0.000s
im_detect: 1140/4024 0.271s 0.000s
im_detect: 1141/4024 0.271s 0.000s
im_detect: 1142/4024 0.271s 0.000s
im_detect: 1143/4024 0.271s 0.000s
im_detect: 1144/4024 0.271s 0.000s
im_detect: 1145/4024 0.271s 0.000s
im_detect: 1146/4024 0.271s 0.000s
im_detect: 1147/4024 0.271s 0.000s
im_detect: 1148/4024 0.271s 0.000s
im_detect: 1149/4024 0.271s 0.000s
im_detect: 1150/4024 0.271s 0.000s
im_detect: 1151/4024 0.271s 0.000s
im_detect: 1152/4024 0.271s 0.000s
im_detect: 1153/4024 0.271s 0.000s
im_detect: 1154/4024 0.271s 0.000s
im_detect: 1155/4024 0.271s 0.000s
im_detect: 1156/4024 0.271s 0.000s
im_detect: 1157/4024 0.271s 0.000s
im_detect: 1158/4024 0.271s 0.000s
im_detect: 1159/4024 0.271s 0.000s
im_detect: 1160/4024 0.271s 0.000s
im_detect: 1161/4024 0.271s 0.000s
im_detect: 1162/4024 0.271s 0.000s
im_detect: 1163/4024 0.271s 0.000s
im_detect: 1164/4024 0.271s 0.000s
im_detect: 1165/4024 0.271s 0.000s
im_detect: 1166/4024 0.271s 0.000s
im_detect: 1167/4024 0.271s 0.000s
im_detect: 1168/4024 0.271s 0.000s
im_detect: 1169/4024 0.271s 0.000s
im_detect: 1170/4024 0.271s 0.000s
im_detect: 1171/4024 0.271s 0.000s
im_detect: 1172/4024 0.271s 0.000s
im_detect: 1173/4024 0.271s 0.000s
im_detect: 1174/4024 0.271s 0.000s
im_detect: 1175/4024 0.271s 0.000s
im_detect: 1176/4024 0.271s 0.000s
im_detect: 1177/4024 0.271s 0.000s
im_detect: 1178/4024 0.271s 0.000s
im_detect: 1179/4024 0.271s 0.000s
im_detect: 1180/4024 0.271s 0.000s
im_detect: 1181/4024 0.271s 0.000s
im_detect: 1182/4024 0.271s 0.000s
im_detect: 1183/4024 0.271s 0.000s
im_detect: 1184/4024 0.271s 0.000s
im_detect: 1185/4024 0.271s 0.000s
im_detect: 1186/4024 0.271s 0.000s
im_detect: 1187/4024 0.271s 0.000s
im_detect: 1188/4024 0.271s 0.000s
im_detect: 1189/4024 0.271s 0.000s
im_detect: 1190/4024 0.271s 0.000s
im_detect: 1191/4024 0.271s 0.000s
im_detect: 1192/4024 0.271s 0.000s
im_detect: 1193/4024 0.271s 0.000s
im_detect: 1194/4024 0.271s 0.000s
im_detect: 1195/4024 0.271s 0.000s
im_detect: 1196/4024 0.271s 0.000s
im_detect: 1197/4024 0.271s 0.000s
im_detect: 1198/4024 0.271s 0.000s
im_detect: 1199/4024 0.271s 0.000s
im_detect: 1200/4024 0.271s 0.000s
im_detect: 1201/4024 0.271s 0.000s
im_detect: 1202/4024 0.271s 0.000s
im_detect: 1203/4024 0.271s 0.000s
im_detect: 1204/4024 0.271s 0.000s
im_detect: 1205/4024 0.271s 0.000s
im_detect: 1206/4024 0.271s 0.000s
im_detect: 1207/4024 0.271s 0.000s
im_detect: 1208/4024 0.271s 0.000s
im_detect: 1209/4024 0.271s 0.000s
im_detect: 1210/4024 0.271s 0.000s
im_detect: 1211/4024 0.271s 0.000s
im_detect: 1212/4024 0.271s 0.000s
im_detect: 1213/4024 0.271s 0.000s
im_detect: 1214/4024 0.271s 0.000s
im_detect: 1215/4024 0.271s 0.000s
im_detect: 1216/4024 0.271s 0.000s
im_detect: 1217/4024 0.271s 0.000s
im_detect: 1218/4024 0.271s 0.000s
im_detect: 1219/4024 0.271s 0.000s
im_detect: 1220/4024 0.271s 0.000s
im_detect: 1221/4024 0.271s 0.000s
im_detect: 1222/4024 0.271s 0.000s
im_detect: 1223/4024 0.271s 0.000s
im_detect: 1224/4024 0.271s 0.000s
im_detect: 1225/4024 0.271s 0.000s
im_detect: 1226/4024 0.271s 0.000s
im_detect: 1227/4024 0.271s 0.000s
im_detect: 1228/4024 0.271s 0.000s
im_detect: 1229/4024 0.271s 0.000s
im_detect: 1230/4024 0.271s 0.000s
im_detect: 1231/4024 0.271s 0.000s
im_detect: 1232/4024 0.271s 0.000s
im_detect: 1233/4024 0.271s 0.000s
im_detect: 1234/4024 0.271s 0.000s
im_detect: 1235/4024 0.271s 0.000s
im_detect: 1236/4024 0.271s 0.000s
im_detect: 1237/4024 0.271s 0.000s
im_detect: 1238/4024 0.271s 0.000s
im_detect: 1239/4024 0.271s 0.000s
im_detect: 1240/4024 0.271s 0.000s
im_detect: 1241/4024 0.271s 0.000s
im_detect: 1242/4024 0.271s 0.000s
im_detect: 1243/4024 0.271s 0.000s
im_detect: 1244/4024 0.271s 0.000s
im_detect: 1245/4024 0.271s 0.000s
im_detect: 1246/4024 0.271s 0.000s
im_detect: 1247/4024 0.271s 0.000s
im_detect: 1248/4024 0.271s 0.000s
im_detect: 1249/4024 0.271s 0.000s
im_detect: 1250/4024 0.271s 0.000s
im_detect: 1251/4024 0.271s 0.000s
im_detect: 1252/4024 0.271s 0.000s
im_detect: 1253/4024 0.271s 0.000s
im_detect: 1254/4024 0.271s 0.000s
im_detect: 1255/4024 0.271s 0.000s
im_detect: 1256/4024 0.271s 0.000s
im_detect: 1257/4024 0.271s 0.000s
im_detect: 1258/4024 0.271s 0.000s
im_detect: 1259/4024 0.271s 0.000s
im_detect: 1260/4024 0.271s 0.000s
im_detect: 1261/4024 0.271s 0.000s
im_detect: 1262/4024 0.271s 0.000s
im_detect: 1263/4024 0.271s 0.000s
im_detect: 1264/4024 0.271s 0.000s
im_detect: 1265/4024 0.271s 0.000s
im_detect: 1266/4024 0.271s 0.000s
im_detect: 1267/4024 0.271s 0.000s
im_detect: 1268/4024 0.271s 0.000s
im_detect: 1269/4024 0.271s 0.000s
im_detect: 1270/4024 0.271s 0.000s
im_detect: 1271/4024 0.271s 0.000s
im_detect: 1272/4024 0.271s 0.000s
im_detect: 1273/4024 0.271s 0.000s
im_detect: 1274/4024 0.271s 0.000s
im_detect: 1275/4024 0.271s 0.000s
im_detect: 1276/4024 0.271s 0.000s
im_detect: 1277/4024 0.271s 0.000s
im_detect: 1278/4024 0.271s 0.000s
im_detect: 1279/4024 0.271s 0.000s
im_detect: 1280/4024 0.271s 0.000s
im_detect: 1281/4024 0.271s 0.000s
im_detect: 1282/4024 0.271s 0.000s
im_detect: 1283/4024 0.271s 0.000s
im_detect: 1284/4024 0.271s 0.000s
im_detect: 1285/4024 0.271s 0.000s
im_detect: 1286/4024 0.271s 0.000s
im_detect: 1287/4024 0.271s 0.000s
im_detect: 1288/4024 0.271s 0.000s
im_detect: 1289/4024 0.271s 0.000s
im_detect: 1290/4024 0.271s 0.000s
im_detect: 1291/4024 0.271s 0.000s
im_detect: 1292/4024 0.271s 0.000s
im_detect: 1293/4024 0.271s 0.000s
im_detect: 1294/4024 0.271s 0.000s
im_detect: 1295/4024 0.271s 0.000s
im_detect: 1296/4024 0.271s 0.000s
im_detect: 1297/4024 0.271s 0.000s
im_detect: 1298/4024 0.271s 0.000s
im_detect: 1299/4024 0.271s 0.000s
im_detect: 1300/4024 0.271s 0.000s
im_detect: 1301/4024 0.271s 0.000s
im_detect: 1302/4024 0.271s 0.000s
im_detect: 1303/4024 0.271s 0.000s
im_detect: 1304/4024 0.271s 0.000s
im_detect: 1305/4024 0.271s 0.000s
im_detect: 1306/4024 0.271s 0.000s
im_detect: 1307/4024 0.271s 0.000s
im_detect: 1308/4024 0.271s 0.000s
im_detect: 1309/4024 0.271s 0.000s
im_detect: 1310/4024 0.271s 0.000s
im_detect: 1311/4024 0.271s 0.000s
im_detect: 1312/4024 0.271s 0.000s
im_detect: 1313/4024 0.271s 0.000s
im_detect: 1314/4024 0.271s 0.000s
im_detect: 1315/4024 0.271s 0.000s
im_detect: 1316/4024 0.271s 0.000s
im_detect: 1317/4024 0.271s 0.000s
im_detect: 1318/4024 0.271s 0.000s
im_detect: 1319/4024 0.271s 0.000s
im_detect: 1320/4024 0.271s 0.000s
im_detect: 1321/4024 0.271s 0.000s
im_detect: 1322/4024 0.271s 0.000s
im_detect: 1323/4024 0.271s 0.000s
im_detect: 1324/4024 0.271s 0.000s
im_detect: 1325/4024 0.271s 0.000s
im_detect: 1326/4024 0.271s 0.000s
im_detect: 1327/4024 0.271s 0.000s
im_detect: 1328/4024 0.271s 0.000s
im_detect: 1329/4024 0.271s 0.000s
im_detect: 1330/4024 0.271s 0.000s
im_detect: 1331/4024 0.271s 0.000s
im_detect: 1332/4024 0.271s 0.000s
im_detect: 1333/4024 0.271s 0.000s
im_detect: 1334/4024 0.271s 0.000s
im_detect: 1335/4024 0.271s 0.000s
im_detect: 1336/4024 0.271s 0.000s
im_detect: 1337/4024 0.271s 0.000s
im_detect: 1338/4024 0.271s 0.000s
im_detect: 1339/4024 0.271s 0.000s
im_detect: 1340/4024 0.271s 0.000s
im_detect: 1341/4024 0.271s 0.000s
im_detect: 1342/4024 0.271s 0.000s
im_detect: 1343/4024 0.271s 0.000s
im_detect: 1344/4024 0.271s 0.000s
im_detect: 1345/4024 0.271s 0.000s
im_detect: 1346/4024 0.271s 0.000s
im_detect: 1347/4024 0.271s 0.000s
im_detect: 1348/4024 0.271s 0.000s
im_detect: 1349/4024 0.271s 0.000s
im_detect: 1350/4024 0.271s 0.000s
im_detect: 1351/4024 0.271s 0.000s
im_detect: 1352/4024 0.271s 0.000s
im_detect: 1353/4024 0.271s 0.000s
im_detect: 1354/4024 0.271s 0.000s
im_detect: 1355/4024 0.271s 0.000s
im_detect: 1356/4024 0.271s 0.000s
im_detect: 1357/4024 0.271s 0.000s
im_detect: 1358/4024 0.271s 0.000s
im_detect: 1359/4024 0.271s 0.000s
im_detect: 1360/4024 0.271s 0.000s
im_detect: 1361/4024 0.271s 0.000s
im_detect: 1362/4024 0.271s 0.000s
im_detect: 1363/4024 0.271s 0.000s
im_detect: 1364/4024 0.271s 0.000s
im_detect: 1365/4024 0.271s 0.000s
im_detect: 1366/4024 0.271s 0.000s
im_detect: 1367/4024 0.271s 0.000s
im_detect: 1368/4024 0.271s 0.000s
im_detect: 1369/4024 0.271s 0.000s
im_detect: 1370/4024 0.271s 0.000s
im_detect: 1371/4024 0.271s 0.000s
im_detect: 1372/4024 0.271s 0.000s
im_detect: 1373/4024 0.271s 0.000s
im_detect: 1374/4024 0.271s 0.000s
im_detect: 1375/4024 0.271s 0.000s
im_detect: 1376/4024 0.271s 0.000s
im_detect: 1377/4024 0.271s 0.000s
im_detect: 1378/4024 0.271s 0.000s
im_detect: 1379/4024 0.271s 0.000s
im_detect: 1380/4024 0.271s 0.000s
im_detect: 1381/4024 0.271s 0.000s
im_detect: 1382/4024 0.271s 0.000s
im_detect: 1383/4024 0.271s 0.000s
im_detect: 1384/4024 0.271s 0.000s
im_detect: 1385/4024 0.271s 0.000s
im_detect: 1386/4024 0.271s 0.000s
im_detect: 1387/4024 0.271s 0.000s
im_detect: 1388/4024 0.271s 0.000s
im_detect: 1389/4024 0.271s 0.000s
im_detect: 1390/4024 0.271s 0.000s
im_detect: 1391/4024 0.271s 0.000s
im_detect: 1392/4024 0.271s 0.000s
im_detect: 1393/4024 0.271s 0.000s
im_detect: 1394/4024 0.271s 0.000s
im_detect: 1395/4024 0.271s 0.000s
im_detect: 1396/4024 0.271s 0.000s
im_detect: 1397/4024 0.271s 0.000s
im_detect: 1398/4024 0.271s 0.000s
im_detect: 1399/4024 0.271s 0.000s
im_detect: 1400/4024 0.271s 0.000s
im_detect: 1401/4024 0.271s 0.000s
im_detect: 1402/4024 0.271s 0.000s
im_detect: 1403/4024 0.271s 0.000s
im_detect: 1404/4024 0.271s 0.000s
im_detect: 1405/4024 0.271s 0.000s
im_detect: 1406/4024 0.271s 0.000s
im_detect: 1407/4024 0.271s 0.000s
im_detect: 1408/4024 0.271s 0.000s
im_detect: 1409/4024 0.271s 0.000s
im_detect: 1410/4024 0.271s 0.000s
im_detect: 1411/4024 0.271s 0.000s
im_detect: 1412/4024 0.271s 0.000s
im_detect: 1413/4024 0.271s 0.000s
im_detect: 1414/4024 0.271s 0.000s
im_detect: 1415/4024 0.271s 0.000s
im_detect: 1416/4024 0.271s 0.000s
im_detect: 1417/4024 0.271s 0.000s
im_detect: 1418/4024 0.271s 0.000s
im_detect: 1419/4024 0.271s 0.000s
im_detect: 1420/4024 0.271s 0.000s
im_detect: 1421/4024 0.271s 0.000s
im_detect: 1422/4024 0.271s 0.000s
im_detect: 1423/4024 0.271s 0.000s
im_detect: 1424/4024 0.271s 0.000s
im_detect: 1425/4024 0.271s 0.000s
im_detect: 1426/4024 0.271s 0.000s
im_detect: 1427/4024 0.271s 0.000s
im_detect: 1428/4024 0.271s 0.000s
im_detect: 1429/4024 0.271s 0.000s
im_detect: 1430/4024 0.271s 0.000s
im_detect: 1431/4024 0.271s 0.000s
im_detect: 1432/4024 0.271s 0.000s
im_detect: 1433/4024 0.271s 0.000s
im_detect: 1434/4024 0.271s 0.000s
im_detect: 1435/4024 0.271s 0.000s
im_detect: 1436/4024 0.271s 0.000s
im_detect: 1437/4024 0.271s 0.000s
im_detect: 1438/4024 0.271s 0.000s
im_detect: 1439/4024 0.271s 0.000s
im_detect: 1440/4024 0.271s 0.000s
im_detect: 1441/4024 0.271s 0.000s
im_detect: 1442/4024 0.271s 0.000s
im_detect: 1443/4024 0.271s 0.000s
im_detect: 1444/4024 0.271s 0.000s
im_detect: 1445/4024 0.271s 0.000s
im_detect: 1446/4024 0.271s 0.000s
im_detect: 1447/4024 0.271s 0.000s
im_detect: 1448/4024 0.271s 0.000s
im_detect: 1449/4024 0.271s 0.000s
im_detect: 1450/4024 0.271s 0.000s
im_detect: 1451/4024 0.271s 0.000s
im_detect: 1452/4024 0.271s 0.000s
im_detect: 1453/4024 0.271s 0.000s
im_detect: 1454/4024 0.271s 0.000s
im_detect: 1455/4024 0.271s 0.000s
im_detect: 1456/4024 0.271s 0.000s
im_detect: 1457/4024 0.271s 0.000s
im_detect: 1458/4024 0.271s 0.000s
im_detect: 1459/4024 0.271s 0.000s
im_detect: 1460/4024 0.271s 0.000s
im_detect: 1461/4024 0.271s 0.000s
im_detect: 1462/4024 0.271s 0.000s
im_detect: 1463/4024 0.271s 0.000s
im_detect: 1464/4024 0.271s 0.000s
im_detect: 1465/4024 0.271s 0.000s
im_detect: 1466/4024 0.271s 0.000s
im_detect: 1467/4024 0.271s 0.000s
im_detect: 1468/4024 0.271s 0.000s
im_detect: 1469/4024 0.271s 0.000s
im_detect: 1470/4024 0.271s 0.000s
im_detect: 1471/4024 0.271s 0.000s
im_detect: 1472/4024 0.271s 0.000s
im_detect: 1473/4024 0.271s 0.000s
im_detect: 1474/4024 0.271s 0.000s
im_detect: 1475/4024 0.271s 0.000s
im_detect: 1476/4024 0.271s 0.000s
im_detect: 1477/4024 0.271s 0.000s
im_detect: 1478/4024 0.271s 0.000s
im_detect: 1479/4024 0.271s 0.000s
im_detect: 1480/4024 0.271s 0.000s
im_detect: 1481/4024 0.271s 0.000s
im_detect: 1482/4024 0.271s 0.000s
im_detect: 1483/4024 0.271s 0.000s
im_detect: 1484/4024 0.271s 0.000s
im_detect: 1485/4024 0.271s 0.000s
im_detect: 1486/4024 0.271s 0.000s
im_detect: 1487/4024 0.271s 0.000s
im_detect: 1488/4024 0.271s 0.000s
im_detect: 1489/4024 0.271s 0.000s
im_detect: 1490/4024 0.271s 0.000s
im_detect: 1491/4024 0.271s 0.000s
im_detect: 1492/4024 0.271s 0.000s
im_detect: 1493/4024 0.271s 0.000s
im_detect: 1494/4024 0.271s 0.000s
im_detect: 1495/4024 0.271s 0.000s
im_detect: 1496/4024 0.271s 0.000s
im_detect: 1497/4024 0.271s 0.000s
im_detect: 1498/4024 0.271s 0.000s
im_detect: 1499/4024 0.271s 0.000s
im_detect: 1500/4024 0.271s 0.000s
im_detect: 1501/4024 0.271s 0.000s
im_detect: 1502/4024 0.271s 0.000s
im_detect: 1503/4024 0.271s 0.000s
im_detect: 1504/4024 0.271s 0.000s
im_detect: 1505/4024 0.271s 0.000s
im_detect: 1506/4024 0.271s 0.000s
im_detect: 1507/4024 0.271s 0.000s
im_detect: 1508/4024 0.271s 0.000s
im_detect: 1509/4024 0.271s 0.000s
im_detect: 1510/4024 0.271s 0.000s
im_detect: 1511/4024 0.271s 0.000s
im_detect: 1512/4024 0.271s 0.000s
im_detect: 1513/4024 0.271s 0.000s
im_detect: 1514/4024 0.271s 0.000s
im_detect: 1515/4024 0.271s 0.000s
im_detect: 1516/4024 0.271s 0.000s
im_detect: 1517/4024 0.271s 0.000s
im_detect: 1518/4024 0.271s 0.000s
im_detect: 1519/4024 0.271s 0.000s
im_detect: 1520/4024 0.271s 0.000s
im_detect: 1521/4024 0.271s 0.000s
im_detect: 1522/4024 0.271s 0.000s
im_detect: 1523/4024 0.271s 0.000s
im_detect: 1524/4024 0.271s 0.000s
im_detect: 1525/4024 0.271s 0.000s
im_detect: 1526/4024 0.271s 0.000s
im_detect: 1527/4024 0.271s 0.000s
im_detect: 1528/4024 0.271s 0.000s
im_detect: 1529/4024 0.271s 0.000s
im_detect: 1530/4024 0.271s 0.000s
im_detect: 1531/4024 0.271s 0.000s
im_detect: 1532/4024 0.271s 0.000s
im_detect: 1533/4024 0.271s 0.000s
im_detect: 1534/4024 0.271s 0.000s
im_detect: 1535/4024 0.271s 0.000s
im_detect: 1536/4024 0.271s 0.000s
im_detect: 1537/4024 0.271s 0.000s
im_detect: 1538/4024 0.271s 0.000s
im_detect: 1539/4024 0.271s 0.000s
im_detect: 1540/4024 0.271s 0.000s
im_detect: 1541/4024 0.271s 0.000s
im_detect: 1542/4024 0.271s 0.000s
im_detect: 1543/4024 0.271s 0.000s
im_detect: 1544/4024 0.271s 0.000s
im_detect: 1545/4024 0.271s 0.000s
im_detect: 1546/4024 0.271s 0.000s
im_detect: 1547/4024 0.271s 0.000s
im_detect: 1548/4024 0.271s 0.000s
im_detect: 1549/4024 0.271s 0.000s
im_detect: 1550/4024 0.271s 0.000s
im_detect: 1551/4024 0.271s 0.000s
im_detect: 1552/4024 0.271s 0.000s
im_detect: 1553/4024 0.271s 0.000s
im_detect: 1554/4024 0.271s 0.000s
im_detect: 1555/4024 0.271s 0.000s
im_detect: 1556/4024 0.271s 0.000s
im_detect: 1557/4024 0.271s 0.000s
im_detect: 1558/4024 0.271s 0.000s
im_detect: 1559/4024 0.271s 0.000s
im_detect: 1560/4024 0.271s 0.000s
im_detect: 1561/4024 0.271s 0.000s
im_detect: 1562/4024 0.271s 0.000s
im_detect: 1563/4024 0.271s 0.000s
im_detect: 1564/4024 0.271s 0.000s
im_detect: 1565/4024 0.271s 0.000s
im_detect: 1566/4024 0.271s 0.000s
im_detect: 1567/4024 0.271s 0.000s
im_detect: 1568/4024 0.271s 0.000s
im_detect: 1569/4024 0.271s 0.000s
im_detect: 1570/4024 0.271s 0.000s
im_detect: 1571/4024 0.271s 0.000s
im_detect: 1572/4024 0.271s 0.000s
im_detect: 1573/4024 0.271s 0.000s
im_detect: 1574/4024 0.271s 0.000s
im_detect: 1575/4024 0.271s 0.000s
im_detect: 1576/4024 0.271s 0.000s
im_detect: 1577/4024 0.271s 0.000s
im_detect: 1578/4024 0.271s 0.000s
im_detect: 1579/4024 0.271s 0.000s
im_detect: 1580/4024 0.271s 0.000s
im_detect: 1581/4024 0.271s 0.000s
im_detect: 1582/4024 0.271s 0.000s
im_detect: 1583/4024 0.271s 0.000s
im_detect: 1584/4024 0.271s 0.000s
im_detect: 1585/4024 0.271s 0.000s
im_detect: 1586/4024 0.271s 0.000s
im_detect: 1587/4024 0.271s 0.000s
im_detect: 1588/4024 0.271s 0.000s
im_detect: 1589/4024 0.271s 0.000s
im_detect: 1590/4024 0.271s 0.000s
im_detect: 1591/4024 0.271s 0.000s
im_detect: 1592/4024 0.271s 0.000s
im_detect: 1593/4024 0.271s 0.000s
im_detect: 1594/4024 0.271s 0.000s
im_detect: 1595/4024 0.271s 0.000s
im_detect: 1596/4024 0.271s 0.000s
im_detect: 1597/4024 0.271s 0.000s
im_detect: 1598/4024 0.271s 0.000s
im_detect: 1599/4024 0.271s 0.000s
im_detect: 1600/4024 0.271s 0.000s
im_detect: 1601/4024 0.271s 0.000s
im_detect: 1602/4024 0.271s 0.000s
im_detect: 1603/4024 0.271s 0.000s
im_detect: 1604/4024 0.271s 0.000s
im_detect: 1605/4024 0.271s 0.000s
im_detect: 1606/4024 0.271s 0.000s
im_detect: 1607/4024 0.271s 0.000s
im_detect: 1608/4024 0.271s 0.000s
im_detect: 1609/4024 0.271s 0.000s
im_detect: 1610/4024 0.271s 0.000s
im_detect: 1611/4024 0.271s 0.000s
im_detect: 1612/4024 0.271s 0.000s
im_detect: 1613/4024 0.271s 0.000s
im_detect: 1614/4024 0.271s 0.000s
im_detect: 1615/4024 0.271s 0.000s
im_detect: 1616/4024 0.271s 0.000s
im_detect: 1617/4024 0.271s 0.000s
im_detect: 1618/4024 0.271s 0.000s
im_detect: 1619/4024 0.271s 0.000s
im_detect: 1620/4024 0.271s 0.000s
im_detect: 1621/4024 0.271s 0.000s
im_detect: 1622/4024 0.271s 0.000s
im_detect: 1623/4024 0.271s 0.000s
im_detect: 1624/4024 0.271s 0.000s
im_detect: 1625/4024 0.271s 0.000s
im_detect: 1626/4024 0.271s 0.000s
im_detect: 1627/4024 0.271s 0.000s
im_detect: 1628/4024 0.271s 0.000s
im_detect: 1629/4024 0.271s 0.000s
im_detect: 1630/4024 0.271s 0.000s
im_detect: 1631/4024 0.271s 0.000s
im_detect: 1632/4024 0.271s 0.000s
im_detect: 1633/4024 0.271s 0.000s
im_detect: 1634/4024 0.271s 0.000s
im_detect: 1635/4024 0.271s 0.000s
im_detect: 1636/4024 0.271s 0.000s
im_detect: 1637/4024 0.271s 0.000s
im_detect: 1638/4024 0.271s 0.000s
im_detect: 1639/4024 0.271s 0.000s
im_detect: 1640/4024 0.271s 0.000s
im_detect: 1641/4024 0.271s 0.000s
im_detect: 1642/4024 0.271s 0.000s
im_detect: 1643/4024 0.271s 0.000s
im_detect: 1644/4024 0.271s 0.000s
im_detect: 1645/4024 0.271s 0.000s
im_detect: 1646/4024 0.271s 0.000s
im_detect: 1647/4024 0.271s 0.000s
im_detect: 1648/4024 0.271s 0.000s
im_detect: 1649/4024 0.271s 0.000s
im_detect: 1650/4024 0.271s 0.000s
im_detect: 1651/4024 0.271s 0.000s
im_detect: 1652/4024 0.271s 0.000s
im_detect: 1653/4024 0.271s 0.000s
im_detect: 1654/4024 0.271s 0.000s
im_detect: 1655/4024 0.271s 0.000s
im_detect: 1656/4024 0.271s 0.000s
im_detect: 1657/4024 0.271s 0.000s
im_detect: 1658/4024 0.271s 0.000s
im_detect: 1659/4024 0.271s 0.000s
im_detect: 1660/4024 0.271s 0.000s
im_detect: 1661/4024 0.271s 0.000s
im_detect: 1662/4024 0.271s 0.000s
im_detect: 1663/4024 0.271s 0.000s
im_detect: 1664/4024 0.271s 0.000s
im_detect: 1665/4024 0.271s 0.000s
im_detect: 1666/4024 0.271s 0.000s
im_detect: 1667/4024 0.271s 0.000s
im_detect: 1668/4024 0.271s 0.000s
im_detect: 1669/4024 0.271s 0.000s
im_detect: 1670/4024 0.271s 0.000s
im_detect: 1671/4024 0.271s 0.000s
im_detect: 1672/4024 0.271s 0.000s
im_detect: 1673/4024 0.271s 0.000s
im_detect: 1674/4024 0.271s 0.000s
im_detect: 1675/4024 0.271s 0.000s
im_detect: 1676/4024 0.271s 0.000s
im_detect: 1677/4024 0.271s 0.000s
im_detect: 1678/4024 0.271s 0.000s
im_detect: 1679/4024 0.271s 0.000s
im_detect: 1680/4024 0.271s 0.000s
im_detect: 1681/4024 0.271s 0.000s
im_detect: 1682/4024 0.271s 0.000s
im_detect: 1683/4024 0.271s 0.000s
im_detect: 1684/4024 0.271s 0.000s
im_detect: 1685/4024 0.271s 0.000s
im_detect: 1686/4024 0.271s 0.000s
im_detect: 1687/4024 0.271s 0.000s
im_detect: 1688/4024 0.271s 0.000s
im_detect: 1689/4024 0.271s 0.000s
im_detect: 1690/4024 0.271s 0.000s
im_detect: 1691/4024 0.271s 0.000s
im_detect: 1692/4024 0.271s 0.000s
im_detect: 1693/4024 0.271s 0.000s
im_detect: 1694/4024 0.271s 0.000s
im_detect: 1695/4024 0.271s 0.000s
im_detect: 1696/4024 0.271s 0.000s
im_detect: 1697/4024 0.271s 0.000s
im_detect: 1698/4024 0.271s 0.000s
im_detect: 1699/4024 0.271s 0.000s
im_detect: 1700/4024 0.271s 0.000s
im_detect: 1701/4024 0.271s 0.000s
im_detect: 1702/4024 0.271s 0.000s
im_detect: 1703/4024 0.271s 0.000s
im_detect: 1704/4024 0.271s 0.000s
im_detect: 1705/4024 0.271s 0.000s
im_detect: 1706/4024 0.271s 0.000s
im_detect: 1707/4024 0.271s 0.000s
im_detect: 1708/4024 0.271s 0.000s
im_detect: 1709/4024 0.271s 0.000s
im_detect: 1710/4024 0.271s 0.000s
im_detect: 1711/4024 0.271s 0.000s
im_detect: 1712/4024 0.271s 0.000s
im_detect: 1713/4024 0.271s 0.000s
im_detect: 1714/4024 0.271s 0.000s
im_detect: 1715/4024 0.271s 0.000s
im_detect: 1716/4024 0.271s 0.000s
im_detect: 1717/4024 0.271s 0.000s
im_detect: 1718/4024 0.271s 0.000s
im_detect: 1719/4024 0.271s 0.000s
im_detect: 1720/4024 0.271s 0.000s
im_detect: 1721/4024 0.271s 0.000s
im_detect: 1722/4024 0.271s 0.000s
im_detect: 1723/4024 0.271s 0.000s
im_detect: 1724/4024 0.271s 0.000s
im_detect: 1725/4024 0.271s 0.000s
im_detect: 1726/4024 0.271s 0.000s
im_detect: 1727/4024 0.271s 0.000s
im_detect: 1728/4024 0.271s 0.000s
im_detect: 1729/4024 0.271s 0.000s
im_detect: 1730/4024 0.271s 0.000s
im_detect: 1731/4024 0.271s 0.000s
im_detect: 1732/4024 0.271s 0.000s
im_detect: 1733/4024 0.271s 0.000s
im_detect: 1734/4024 0.271s 0.000s
im_detect: 1735/4024 0.271s 0.000s
im_detect: 1736/4024 0.271s 0.000s
im_detect: 1737/4024 0.271s 0.000s
im_detect: 1738/4024 0.271s 0.000s
im_detect: 1739/4024 0.271s 0.000s
im_detect: 1740/4024 0.271s 0.000s
im_detect: 1741/4024 0.271s 0.000s
im_detect: 1742/4024 0.271s 0.000s
im_detect: 1743/4024 0.271s 0.000s
im_detect: 1744/4024 0.271s 0.000s
im_detect: 1745/4024 0.271s 0.000s
im_detect: 1746/4024 0.271s 0.000s
im_detect: 1747/4024 0.271s 0.000s
im_detect: 1748/4024 0.271s 0.000s
im_detect: 1749/4024 0.271s 0.000s
im_detect: 1750/4024 0.271s 0.000s
im_detect: 1751/4024 0.271s 0.000s
im_detect: 1752/4024 0.271s 0.000s
im_detect: 1753/4024 0.271s 0.000s
im_detect: 1754/4024 0.271s 0.000s
im_detect: 1755/4024 0.271s 0.000s
im_detect: 1756/4024 0.271s 0.000s
im_detect: 1757/4024 0.271s 0.000s
im_detect: 1758/4024 0.271s 0.000s
im_detect: 1759/4024 0.271s 0.000s
im_detect: 1760/4024 0.271s 0.000s
im_detect: 1761/4024 0.271s 0.000s
im_detect: 1762/4024 0.271s 0.000s
im_detect: 1763/4024 0.271s 0.000s
im_detect: 1764/4024 0.271s 0.000s
im_detect: 1765/4024 0.271s 0.000s
im_detect: 1766/4024 0.271s 0.000s
im_detect: 1767/4024 0.271s 0.000s
im_detect: 1768/4024 0.271s 0.000s
im_detect: 1769/4024 0.271s 0.000s
im_detect: 1770/4024 0.271s 0.000s
im_detect: 1771/4024 0.271s 0.000s
im_detect: 1772/4024 0.271s 0.000s
im_detect: 1773/4024 0.271s 0.000s
im_detect: 1774/4024 0.271s 0.000s
im_detect: 1775/4024 0.271s 0.000s
im_detect: 1776/4024 0.271s 0.000s
im_detect: 1777/4024 0.271s 0.000s
im_detect: 1778/4024 0.271s 0.000s
im_detect: 1779/4024 0.271s 0.000s
im_detect: 1780/4024 0.271s 0.000s
im_detect: 1781/4024 0.271s 0.000s
im_detect: 1782/4024 0.271s 0.000s
im_detect: 1783/4024 0.271s 0.000s
im_detect: 1784/4024 0.271s 0.000s
im_detect: 1785/4024 0.271s 0.000s
im_detect: 1786/4024 0.271s 0.000s
im_detect: 1787/4024 0.271s 0.000s
im_detect: 1788/4024 0.271s 0.000s
im_detect: 1789/4024 0.271s 0.000s
im_detect: 1790/4024 0.271s 0.000s
im_detect: 1791/4024 0.271s 0.000s
im_detect: 1792/4024 0.271s 0.000s
im_detect: 1793/4024 0.271s 0.000s
im_detect: 1794/4024 0.271s 0.000s
im_detect: 1795/4024 0.271s 0.000s
im_detect: 1796/4024 0.271s 0.000s
im_detect: 1797/4024 0.271s 0.000s
im_detect: 1798/4024 0.271s 0.000s
im_detect: 1799/4024 0.271s 0.000s
im_detect: 1800/4024 0.271s 0.000s
im_detect: 1801/4024 0.271s 0.000s
im_detect: 1802/4024 0.271s 0.000s
im_detect: 1803/4024 0.271s 0.000s
im_detect: 1804/4024 0.271s 0.000s
im_detect: 1805/4024 0.271s 0.000s
im_detect: 1806/4024 0.271s 0.000s
im_detect: 1807/4024 0.271s 0.000s
im_detect: 1808/4024 0.271s 0.000s
im_detect: 1809/4024 0.271s 0.000s
im_detect: 1810/4024 0.271s 0.000s
im_detect: 1811/4024 0.271s 0.000s
im_detect: 1812/4024 0.271s 0.000s
im_detect: 1813/4024 0.271s 0.000s
im_detect: 1814/4024 0.271s 0.000s
im_detect: 1815/4024 0.271s 0.000s
im_detect: 1816/4024 0.271s 0.000s
im_detect: 1817/4024 0.271s 0.000s
im_detect: 1818/4024 0.271s 0.000s
im_detect: 1819/4024 0.271s 0.000s
im_detect: 1820/4024 0.271s 0.000s
im_detect: 1821/4024 0.271s 0.000s
im_detect: 1822/4024 0.271s 0.000s
im_detect: 1823/4024 0.271s 0.000s
im_detect: 1824/4024 0.271s 0.000s
im_detect: 1825/4024 0.271s 0.000s
im_detect: 1826/4024 0.271s 0.000s
im_detect: 1827/4024 0.271s 0.000s
im_detect: 1828/4024 0.271s 0.000s
im_detect: 1829/4024 0.271s 0.000s
im_detect: 1830/4024 0.271s 0.000s
im_detect: 1831/4024 0.271s 0.000s
im_detect: 1832/4024 0.271s 0.000s
im_detect: 1833/4024 0.271s 0.000s
im_detect: 1834/4024 0.271s 0.000s
im_detect: 1835/4024 0.271s 0.000s
im_detect: 1836/4024 0.271s 0.000s
im_detect: 1837/4024 0.271s 0.000s
im_detect: 1838/4024 0.271s 0.000s
im_detect: 1839/4024 0.271s 0.000s
im_detect: 1840/4024 0.271s 0.000s
im_detect: 1841/4024 0.271s 0.000s
im_detect: 1842/4024 0.271s 0.000s
im_detect: 1843/4024 0.271s 0.000s
im_detect: 1844/4024 0.271s 0.000s
im_detect: 1845/4024 0.271s 0.000s
im_detect: 1846/4024 0.271s 0.000s
im_detect: 1847/4024 0.271s 0.000s
im_detect: 1848/4024 0.271s 0.000s
im_detect: 1849/4024 0.271s 0.000s
im_detect: 1850/4024 0.271s 0.000s
im_detect: 1851/4024 0.271s 0.000s
im_detect: 1852/4024 0.271s 0.000s
im_detect: 1853/4024 0.271s 0.000s
im_detect: 1854/4024 0.271s 0.000s
im_detect: 1855/4024 0.271s 0.000s
im_detect: 1856/4024 0.271s 0.000s
im_detect: 1857/4024 0.271s 0.000s
im_detect: 1858/4024 0.271s 0.000s
im_detect: 1859/4024 0.271s 0.000s
im_detect: 1860/4024 0.271s 0.000s
im_detect: 1861/4024 0.271s 0.000s
im_detect: 1862/4024 0.271s 0.000s
im_detect: 1863/4024 0.271s 0.000s
im_detect: 1864/4024 0.271s 0.000s
im_detect: 1865/4024 0.271s 0.000s
im_detect: 1866/4024 0.271s 0.000s
im_detect: 1867/4024 0.271s 0.000s
im_detect: 1868/4024 0.271s 0.000s
im_detect: 1869/4024 0.271s 0.000s
im_detect: 1870/4024 0.271s 0.000s
im_detect: 1871/4024 0.271s 0.000s
im_detect: 1872/4024 0.271s 0.000s
im_detect: 1873/4024 0.271s 0.000s
im_detect: 1874/4024 0.271s 0.000s
im_detect: 1875/4024 0.271s 0.000s
im_detect: 1876/4024 0.271s 0.000s
im_detect: 1877/4024 0.271s 0.000s
im_detect: 1878/4024 0.271s 0.000s
im_detect: 1879/4024 0.271s 0.000s
im_detect: 1880/4024 0.271s 0.000s
im_detect: 1881/4024 0.271s 0.000s
im_detect: 1882/4024 0.271s 0.000s
im_detect: 1883/4024 0.271s 0.000s
im_detect: 1884/4024 0.271s 0.000s
im_detect: 1885/4024 0.271s 0.000s
im_detect: 1886/4024 0.271s 0.000s
im_detect: 1887/4024 0.271s 0.000s
im_detect: 1888/4024 0.271s 0.000s
im_detect: 1889/4024 0.271s 0.000s
im_detect: 1890/4024 0.271s 0.000s
im_detect: 1891/4024 0.271s 0.000s
im_detect: 1892/4024 0.271s 0.000s
im_detect: 1893/4024 0.271s 0.000s
im_detect: 1894/4024 0.271s 0.000s
im_detect: 1895/4024 0.271s 0.000s
im_detect: 1896/4024 0.271s 0.000s
im_detect: 1897/4024 0.271s 0.000s
im_detect: 1898/4024 0.271s 0.000s
im_detect: 1899/4024 0.271s 0.000s
im_detect: 1900/4024 0.271s 0.000s
im_detect: 1901/4024 0.271s 0.000s
im_detect: 1902/4024 0.271s 0.000s
im_detect: 1903/4024 0.271s 0.000s
im_detect: 1904/4024 0.271s 0.000s
im_detect: 1905/4024 0.271s 0.000s
im_detect: 1906/4024 0.271s 0.000s
im_detect: 1907/4024 0.271s 0.000s
im_detect: 1908/4024 0.271s 0.000s
im_detect: 1909/4024 0.271s 0.000s
im_detect: 1910/4024 0.271s 0.000s
im_detect: 1911/4024 0.271s 0.000s
im_detect: 1912/4024 0.271s 0.000s
im_detect: 1913/4024 0.271s 0.000s
im_detect: 1914/4024 0.271s 0.000s
im_detect: 1915/4024 0.271s 0.000s
im_detect: 1916/4024 0.271s 0.000s
im_detect: 1917/4024 0.271s 0.000s
im_detect: 1918/4024 0.271s 0.000s
im_detect: 1919/4024 0.271s 0.000s
im_detect: 1920/4024 0.271s 0.000s
im_detect: 1921/4024 0.271s 0.000s
im_detect: 1922/4024 0.271s 0.000s
im_detect: 1923/4024 0.271s 0.000s
im_detect: 1924/4024 0.271s 0.000s
im_detect: 1925/4024 0.271s 0.000s
im_detect: 1926/4024 0.271s 0.000s
im_detect: 1927/4024 0.271s 0.000s
im_detect: 1928/4024 0.271s 0.000s
im_detect: 1929/4024 0.271s 0.000s
im_detect: 1930/4024 0.271s 0.000s
im_detect: 1931/4024 0.271s 0.000s
im_detect: 1932/4024 0.271s 0.000s
im_detect: 1933/4024 0.271s 0.000s
im_detect: 1934/4024 0.271s 0.000s
im_detect: 1935/4024 0.271s 0.000s
im_detect: 1936/4024 0.271s 0.000s
im_detect: 1937/4024 0.271s 0.000s
im_detect: 1938/4024 0.271s 0.000s
im_detect: 1939/4024 0.271s 0.000s
im_detect: 1940/4024 0.271s 0.000s
im_detect: 1941/4024 0.271s 0.000s
im_detect: 1942/4024 0.271s 0.000s
im_detect: 1943/4024 0.271s 0.000s
im_detect: 1944/4024 0.271s 0.000s
im_detect: 1945/4024 0.271s 0.000s
im_detect: 1946/4024 0.271s 0.000s
im_detect: 1947/4024 0.271s 0.000s
im_detect: 1948/4024 0.271s 0.000s
im_detect: 1949/4024 0.271s 0.000s
im_detect: 1950/4024 0.271s 0.000s
im_detect: 1951/4024 0.271s 0.000s
im_detect: 1952/4024 0.271s 0.000s
im_detect: 1953/4024 0.271s 0.000s
im_detect: 1954/4024 0.271s 0.000s
im_detect: 1955/4024 0.271s 0.000s
im_detect: 1956/4024 0.271s 0.000s
im_detect: 1957/4024 0.271s 0.000s
im_detect: 1958/4024 0.271s 0.000s
im_detect: 1959/4024 0.271s 0.000s
im_detect: 1960/4024 0.271s 0.000s
im_detect: 1961/4024 0.271s 0.000s
im_detect: 1962/4024 0.271s 0.000s
im_detect: 1963/4024 0.271s 0.000s
im_detect: 1964/4024 0.271s 0.000s
im_detect: 1965/4024 0.271s 0.000s
im_detect: 1966/4024 0.271s 0.000s
im_detect: 1967/4024 0.271s 0.000s
im_detect: 1968/4024 0.271s 0.000s
im_detect: 1969/4024 0.271s 0.000s
im_detect: 1970/4024 0.271s 0.000s
im_detect: 1971/4024 0.271s 0.000s
im_detect: 1972/4024 0.271s 0.000s
im_detect: 1973/4024 0.271s 0.000s
im_detect: 1974/4024 0.271s 0.000s
im_detect: 1975/4024 0.271s 0.000s
im_detect: 1976/4024 0.271s 0.000s
im_detect: 1977/4024 0.271s 0.000s
im_detect: 1978/4024 0.271s 0.000s
im_detect: 1979/4024 0.271s 0.000s
im_detect: 1980/4024 0.271s 0.000s
im_detect: 1981/4024 0.271s 0.000s
im_detect: 1982/4024 0.271s 0.000s
im_detect: 1983/4024 0.271s 0.000s
im_detect: 1984/4024 0.271s 0.000s
im_detect: 1985/4024 0.271s 0.000s
im_detect: 1986/4024 0.271s 0.000s
im_detect: 1987/4024 0.271s 0.000s
im_detect: 1988/4024 0.271s 0.000s
im_detect: 1989/4024 0.271s 0.000s
im_detect: 1990/4024 0.271s 0.000s
im_detect: 1991/4024 0.271s 0.000s
im_detect: 1992/4024 0.271s 0.000s
im_detect: 1993/4024 0.271s 0.000s
im_detect: 1994/4024 0.271s 0.000s
im_detect: 1995/4024 0.271s 0.000s
im_detect: 1996/4024 0.271s 0.000s
im_detect: 1997/4024 0.271s 0.000s
im_detect: 1998/4024 0.271s 0.000s
im_detect: 1999/4024 0.271s 0.000s
im_detect: 2000/4024 0.271s 0.000s
im_detect: 2001/4024 0.271s 0.000s
im_detect: 2002/4024 0.271s 0.000s
im_detect: 2003/4024 0.271s 0.000s
im_detect: 2004/4024 0.271s 0.000s
im_detect: 2005/4024 0.271s 0.000s
im_detect: 2006/4024 0.271s 0.000s
im_detect: 2007/4024 0.271s 0.000s
im_detect: 2008/4024 0.271s 0.000s
im_detect: 2009/4024 0.271s 0.000s
im_detect: 2010/4024 0.271s 0.000s
im_detect: 2011/4024 0.271s 0.000s
im_detect: 2012/4024 0.271s 0.000s
im_detect: 2013/4024 0.271s 0.000s
im_detect: 2014/4024 0.271s 0.000s
im_detect: 2015/4024 0.271s 0.000s
im_detect: 2016/4024 0.271s 0.000s
im_detect: 2017/4024 0.271s 0.000s
im_detect: 2018/4024 0.271s 0.000s
im_detect: 2019/4024 0.271s 0.000s
im_detect: 2020/4024 0.271s 0.000s
im_detect: 2021/4024 0.271s 0.000s
im_detect: 2022/4024 0.271s 0.000s
im_detect: 2023/4024 0.271s 0.000s
im_detect: 2024/4024 0.271s 0.000s
im_detect: 2025/4024 0.271s 0.000s
im_detect: 2026/4024 0.271s 0.000s
im_detect: 2027/4024 0.271s 0.000s
im_detect: 2028/4024 0.271s 0.000s
im_detect: 2029/4024 0.271s 0.000s
im_detect: 2030/4024 0.271s 0.000s
im_detect: 2031/4024 0.271s 0.000s
im_detect: 2032/4024 0.271s 0.000s
im_detect: 2033/4024 0.271s 0.000s
im_detect: 2034/4024 0.271s 0.000s
im_detect: 2035/4024 0.271s 0.000s
im_detect: 2036/4024 0.271s 0.000s
im_detect: 2037/4024 0.271s 0.000s
im_detect: 2038/4024 0.271s 0.000s
im_detect: 2039/4024 0.271s 0.000s
im_detect: 2040/4024 0.271s 0.000s
im_detect: 2041/4024 0.271s 0.000s
im_detect: 2042/4024 0.271s 0.000s
im_detect: 2043/4024 0.271s 0.000s
im_detect: 2044/4024 0.271s 0.000s
im_detect: 2045/4024 0.271s 0.000s
im_detect: 2046/4024 0.271s 0.000s
im_detect: 2047/4024 0.271s 0.000s
im_detect: 2048/4024 0.271s 0.000s
im_detect: 2049/4024 0.271s 0.000s
im_detect: 2050/4024 0.271s 0.000s
im_detect: 2051/4024 0.271s 0.000s
im_detect: 2052/4024 0.271s 0.000s
im_detect: 2053/4024 0.271s 0.000s
im_detect: 2054/4024 0.271s 0.000s
im_detect: 2055/4024 0.271s 0.000s
im_detect: 2056/4024 0.271s 0.000s
im_detect: 2057/4024 0.271s 0.000s
im_detect: 2058/4024 0.271s 0.000s
im_detect: 2059/4024 0.271s 0.000s
im_detect: 2060/4024 0.271s 0.000s
im_detect: 2061/4024 0.271s 0.000s
im_detect: 2062/4024 0.271s 0.000s
im_detect: 2063/4024 0.271s 0.000s
im_detect: 2064/4024 0.271s 0.000s
im_detect: 2065/4024 0.271s 0.000s
im_detect: 2066/4024 0.271s 0.000s
im_detect: 2067/4024 0.271s 0.000s
im_detect: 2068/4024 0.271s 0.000s
im_detect: 2069/4024 0.271s 0.000s
im_detect: 2070/4024 0.271s 0.000s
im_detect: 2071/4024 0.271s 0.000s
im_detect: 2072/4024 0.271s 0.000s
im_detect: 2073/4024 0.271s 0.000s
im_detect: 2074/4024 0.271s 0.000s
im_detect: 2075/4024 0.271s 0.000s
im_detect: 2076/4024 0.271s 0.000s
im_detect: 2077/4024 0.271s 0.000s
im_detect: 2078/4024 0.271s 0.000s
im_detect: 2079/4024 0.271s 0.000s
im_detect: 2080/4024 0.271s 0.000s
im_detect: 2081/4024 0.271s 0.000s
im_detect: 2082/4024 0.271s 0.000s
im_detect: 2083/4024 0.271s 0.000s
im_detect: 2084/4024 0.271s 0.000s
im_detect: 2085/4024 0.271s 0.000s
im_detect: 2086/4024 0.271s 0.000s
im_detect: 2087/4024 0.271s 0.000s
im_detect: 2088/4024 0.271s 0.000s
im_detect: 2089/4024 0.271s 0.000s
im_detect: 2090/4024 0.271s 0.000s
im_detect: 2091/4024 0.271s 0.000s
im_detect: 2092/4024 0.271s 0.000s
im_detect: 2093/4024 0.271s 0.000s
im_detect: 2094/4024 0.271s 0.000s
im_detect: 2095/4024 0.271s 0.000s
im_detect: 2096/4024 0.271s 0.000s
im_detect: 2097/4024 0.271s 0.000s
im_detect: 2098/4024 0.271s 0.000s
im_detect: 2099/4024 0.271s 0.000s
im_detect: 2100/4024 0.271s 0.000s
im_detect: 2101/4024 0.271s 0.000s
im_detect: 2102/4024 0.271s 0.000s
im_detect: 2103/4024 0.271s 0.000s
im_detect: 2104/4024 0.271s 0.000s
im_detect: 2105/4024 0.271s 0.000s
im_detect: 2106/4024 0.271s 0.000s
im_detect: 2107/4024 0.271s 0.000s
im_detect: 2108/4024 0.271s 0.000s
im_detect: 2109/4024 0.271s 0.000s
im_detect: 2110/4024 0.271s 0.000s
im_detect: 2111/4024 0.271s 0.000s
im_detect: 2112/4024 0.271s 0.000s
im_detect: 2113/4024 0.271s 0.000s
im_detect: 2114/4024 0.271s 0.000s
im_detect: 2115/4024 0.271s 0.000s
im_detect: 2116/4024 0.271s 0.000s
im_detect: 2117/4024 0.271s 0.000s
im_detect: 2118/4024 0.271s 0.000s
im_detect: 2119/4024 0.271s 0.000s
im_detect: 2120/4024 0.271s 0.000s
im_detect: 2121/4024 0.271s 0.000s
im_detect: 2122/4024 0.271s 0.000s
im_detect: 2123/4024 0.271s 0.000s
im_detect: 2124/4024 0.271s 0.000s
im_detect: 2125/4024 0.271s 0.000s
im_detect: 2126/4024 0.271s 0.000s
im_detect: 2127/4024 0.271s 0.000s
im_detect: 2128/4024 0.271s 0.000s
im_detect: 2129/4024 0.271s 0.000s
im_detect: 2130/4024 0.271s 0.000s
im_detect: 2131/4024 0.271s 0.000s
im_detect: 2132/4024 0.271s 0.000s
im_detect: 2133/4024 0.271s 0.000s
im_detect: 2134/4024 0.271s 0.000s
im_detect: 2135/4024 0.271s 0.000s
im_detect: 2136/4024 0.271s 0.000s
im_detect: 2137/4024 0.271s 0.000s
im_detect: 2138/4024 0.271s 0.000s
im_detect: 2139/4024 0.271s 0.000s
im_detect: 2140/4024 0.271s 0.000s
im_detect: 2141/4024 0.271s 0.000s
im_detect: 2142/4024 0.271s 0.000s
im_detect: 2143/4024 0.271s 0.000s
im_detect: 2144/4024 0.271s 0.000s
im_detect: 2145/4024 0.271s 0.000s
im_detect: 2146/4024 0.271s 0.000s
im_detect: 2147/4024 0.271s 0.000s
im_detect: 2148/4024 0.271s 0.000s
im_detect: 2149/4024 0.271s 0.000s
im_detect: 2150/4024 0.271s 0.000s
im_detect: 2151/4024 0.271s 0.000s
im_detect: 2152/4024 0.271s 0.000s
im_detect: 2153/4024 0.271s 0.000s
im_detect: 2154/4024 0.271s 0.000s
im_detect: 2155/4024 0.271s 0.000s
im_detect: 2156/4024 0.271s 0.000s
im_detect: 2157/4024 0.271s 0.000s
im_detect: 2158/4024 0.271s 0.000s
im_detect: 2159/4024 0.271s 0.000s
im_detect: 2160/4024 0.271s 0.000s
im_detect: 2161/4024 0.271s 0.000s
im_detect: 2162/4024 0.271s 0.000s
im_detect: 2163/4024 0.271s 0.000s
im_detect: 2164/4024 0.271s 0.000s
im_detect: 2165/4024 0.271s 0.000s
im_detect: 2166/4024 0.271s 0.000s
im_detect: 2167/4024 0.271s 0.000s
im_detect: 2168/4024 0.271s 0.000s
im_detect: 2169/4024 0.271s 0.000s
im_detect: 2170/4024 0.271s 0.000s
im_detect: 2171/4024 0.271s 0.000s
im_detect: 2172/4024 0.271s 0.000s
im_detect: 2173/4024 0.271s 0.000s
im_detect: 2174/4024 0.271s 0.000s
im_detect: 2175/4024 0.271s 0.000s
im_detect: 2176/4024 0.271s 0.000s
im_detect: 2177/4024 0.271s 0.000s
im_detect: 2178/4024 0.271s 0.000s
im_detect: 2179/4024 0.271s 0.000s
im_detect: 2180/4024 0.271s 0.000s
im_detect: 2181/4024 0.271s 0.000s
im_detect: 2182/4024 0.271s 0.000s
im_detect: 2183/4024 0.271s 0.000s
im_detect: 2184/4024 0.271s 0.000s
im_detect: 2185/4024 0.271s 0.000s
im_detect: 2186/4024 0.271s 0.000s
im_detect: 2187/4024 0.271s 0.000s
im_detect: 2188/4024 0.271s 0.000s
im_detect: 2189/4024 0.271s 0.000s
im_detect: 2190/4024 0.271s 0.000s
im_detect: 2191/4024 0.271s 0.000s
im_detect: 2192/4024 0.271s 0.000s
im_detect: 2193/4024 0.271s 0.000s
im_detect: 2194/4024 0.271s 0.000s
im_detect: 2195/4024 0.271s 0.000s
im_detect: 2196/4024 0.271s 0.000s
im_detect: 2197/4024 0.271s 0.000s
im_detect: 2198/4024 0.271s 0.000s
im_detect: 2199/4024 0.271s 0.000s
im_detect: 2200/4024 0.271s 0.000s
im_detect: 2201/4024 0.271s 0.000s
im_detect: 2202/4024 0.271s 0.000s
im_detect: 2203/4024 0.271s 0.000s
im_detect: 2204/4024 0.271s 0.000s
im_detect: 2205/4024 0.271s 0.000s
im_detect: 2206/4024 0.271s 0.000s
im_detect: 2207/4024 0.271s 0.000s
im_detect: 2208/4024 0.271s 0.000s
im_detect: 2209/4024 0.271s 0.000s
im_detect: 2210/4024 0.271s 0.000s
im_detect: 2211/4024 0.271s 0.000s
im_detect: 2212/4024 0.271s 0.000s
im_detect: 2213/4024 0.271s 0.000s
im_detect: 2214/4024 0.271s 0.000s
im_detect: 2215/4024 0.271s 0.000s
im_detect: 2216/4024 0.271s 0.000s
im_detect: 2217/4024 0.271s 0.000s
im_detect: 2218/4024 0.271s 0.000s
im_detect: 2219/4024 0.271s 0.000s
im_detect: 2220/4024 0.271s 0.000s
im_detect: 2221/4024 0.271s 0.000s
im_detect: 2222/4024 0.271s 0.000s
im_detect: 2223/4024 0.271s 0.000s
im_detect: 2224/4024 0.271s 0.000s
im_detect: 2225/4024 0.271s 0.000s
im_detect: 2226/4024 0.271s 0.000s
im_detect: 2227/4024 0.271s 0.000s
im_detect: 2228/4024 0.271s 0.000s
im_detect: 2229/4024 0.271s 0.000s
im_detect: 2230/4024 0.271s 0.000s
im_detect: 2231/4024 0.271s 0.000s
im_detect: 2232/4024 0.271s 0.000s
im_detect: 2233/4024 0.271s 0.000s
im_detect: 2234/4024 0.271s 0.000s
im_detect: 2235/4024 0.271s 0.000s
im_detect: 2236/4024 0.271s 0.000s
im_detect: 2237/4024 0.271s 0.000s
im_detect: 2238/4024 0.271s 0.000s
im_detect: 2239/4024 0.271s 0.000s
im_detect: 2240/4024 0.271s 0.000s
im_detect: 2241/4024 0.271s 0.000s
im_detect: 2242/4024 0.271s 0.000s
im_detect: 2243/4024 0.271s 0.000s
im_detect: 2244/4024 0.271s 0.000s
im_detect: 2245/4024 0.271s 0.000s
im_detect: 2246/4024 0.271s 0.000s
im_detect: 2247/4024 0.271s 0.000s
im_detect: 2248/4024 0.271s 0.000s
im_detect: 2249/4024 0.271s 0.000s
im_detect: 2250/4024 0.271s 0.000s
im_detect: 2251/4024 0.271s 0.000s
im_detect: 2252/4024 0.271s 0.000s
im_detect: 2253/4024 0.271s 0.000s
im_detect: 2254/4024 0.271s 0.000s
im_detect: 2255/4024 0.271s 0.000s
im_detect: 2256/4024 0.271s 0.000s
im_detect: 2257/4024 0.271s 0.000s
im_detect: 2258/4024 0.271s 0.000s
im_detect: 2259/4024 0.271s 0.000s
im_detect: 2260/4024 0.271s 0.000s
im_detect: 2261/4024 0.271s 0.000s
im_detect: 2262/4024 0.271s 0.000s
im_detect: 2263/4024 0.271s 0.000s
im_detect: 2264/4024 0.271s 0.000s
im_detect: 2265/4024 0.271s 0.000s
im_detect: 2266/4024 0.271s 0.000s
im_detect: 2267/4024 0.271s 0.000s
im_detect: 2268/4024 0.271s 0.000s
im_detect: 2269/4024 0.271s 0.000s
im_detect: 2270/4024 0.271s 0.000s
im_detect: 2271/4024 0.271s 0.000s
im_detect: 2272/4024 0.271s 0.000s
im_detect: 2273/4024 0.271s 0.000s
im_detect: 2274/4024 0.271s 0.000s
im_detect: 2275/4024 0.271s 0.000s
im_detect: 2276/4024 0.271s 0.000s
im_detect: 2277/4024 0.271s 0.000s
im_detect: 2278/4024 0.271s 0.000s
im_detect: 2279/4024 0.271s 0.000s
im_detect: 2280/4024 0.271s 0.000s
im_detect: 2281/4024 0.271s 0.000s
im_detect: 2282/4024 0.271s 0.000s
im_detect: 2283/4024 0.271s 0.000s
im_detect: 2284/4024 0.271s 0.000s
im_detect: 2285/4024 0.271s 0.000s
im_detect: 2286/4024 0.271s 0.000s
im_detect: 2287/4024 0.271s 0.000s
im_detect: 2288/4024 0.271s 0.000s
im_detect: 2289/4024 0.271s 0.000s
im_detect: 2290/4024 0.271s 0.000s
im_detect: 2291/4024 0.271s 0.000s
im_detect: 2292/4024 0.271s 0.000s
im_detect: 2293/4024 0.271s 0.000s
im_detect: 2294/4024 0.271s 0.000s
im_detect: 2295/4024 0.271s 0.000s
im_detect: 2296/4024 0.271s 0.000s
im_detect: 2297/4024 0.271s 0.000s
im_detect: 2298/4024 0.271s 0.000s
im_detect: 2299/4024 0.271s 0.000s
im_detect: 2300/4024 0.271s 0.000s
im_detect: 2301/4024 0.271s 0.000s
im_detect: 2302/4024 0.271s 0.000s
im_detect: 2303/4024 0.271s 0.000s
im_detect: 2304/4024 0.271s 0.000s
im_detect: 2305/4024 0.271s 0.000s
im_detect: 2306/4024 0.271s 0.000s
im_detect: 2307/4024 0.271s 0.000s
im_detect: 2308/4024 0.271s 0.000s
im_detect: 2309/4024 0.271s 0.000s
im_detect: 2310/4024 0.271s 0.000s
im_detect: 2311/4024 0.271s 0.000s
im_detect: 2312/4024 0.271s 0.000s
im_detect: 2313/4024 0.271s 0.000s
im_detect: 2314/4024 0.271s 0.000s
im_detect: 2315/4024 0.271s 0.000s
im_detect: 2316/4024 0.271s 0.000s
im_detect: 2317/4024 0.271s 0.000s
im_detect: 2318/4024 0.271s 0.000s
im_detect: 2319/4024 0.271s 0.000s
im_detect: 2320/4024 0.271s 0.000s
im_detect: 2321/4024 0.271s 0.000s
im_detect: 2322/4024 0.271s 0.000s
im_detect: 2323/4024 0.271s 0.000s
im_detect: 2324/4024 0.271s 0.000s
im_detect: 2325/4024 0.271s 0.000s
im_detect: 2326/4024 0.271s 0.000s
im_detect: 2327/4024 0.271s 0.000s
im_detect: 2328/4024 0.271s 0.000s
im_detect: 2329/4024 0.271s 0.000s
im_detect: 2330/4024 0.271s 0.000s
im_detect: 2331/4024 0.271s 0.000s
im_detect: 2332/4024 0.271s 0.000s
im_detect: 2333/4024 0.271s 0.000s
im_detect: 2334/4024 0.271s 0.000s
im_detect: 2335/4024 0.271s 0.000s
im_detect: 2336/4024 0.271s 0.000s
im_detect: 2337/4024 0.271s 0.000s
im_detect: 2338/4024 0.271s 0.000s
im_detect: 2339/4024 0.271s 0.000s
im_detect: 2340/4024 0.271s 0.000s
im_detect: 2341/4024 0.271s 0.000s
im_detect: 2342/4024 0.271s 0.000s
im_detect: 2343/4024 0.271s 0.000s
im_detect: 2344/4024 0.271s 0.000s
im_detect: 2345/4024 0.271s 0.000s
im_detect: 2346/4024 0.271s 0.000s
im_detect: 2347/4024 0.271s 0.000s
im_detect: 2348/4024 0.271s 0.000s
im_detect: 2349/4024 0.271s 0.000s
im_detect: 2350/4024 0.271s 0.000s
im_detect: 2351/4024 0.271s 0.000s
im_detect: 2352/4024 0.271s 0.000s
im_detect: 2353/4024 0.271s 0.000s
im_detect: 2354/4024 0.271s 0.000s
im_detect: 2355/4024 0.271s 0.000s
im_detect: 2356/4024 0.271s 0.000s
im_detect: 2357/4024 0.271s 0.000s
im_detect: 2358/4024 0.271s 0.000s
im_detect: 2359/4024 0.271s 0.000s
im_detect: 2360/4024 0.271s 0.000s
im_detect: 2361/4024 0.271s 0.000s
im_detect: 2362/4024 0.271s 0.000s
im_detect: 2363/4024 0.271s 0.000s
im_detect: 2364/4024 0.271s 0.000s
im_detect: 2365/4024 0.271s 0.000s
im_detect: 2366/4024 0.271s 0.000s
im_detect: 2367/4024 0.271s 0.000s
im_detect: 2368/4024 0.271s 0.000s
im_detect: 2369/4024 0.271s 0.000s
im_detect: 2370/4024 0.271s 0.000s
im_detect: 2371/4024 0.271s 0.000s
im_detect: 2372/4024 0.271s 0.000s
im_detect: 2373/4024 0.271s 0.000s
im_detect: 2374/4024 0.271s 0.000s
im_detect: 2375/4024 0.271s 0.000s
im_detect: 2376/4024 0.271s 0.000s
im_detect: 2377/4024 0.271s 0.000s
im_detect: 2378/4024 0.271s 0.000s
im_detect: 2379/4024 0.271s 0.000s
im_detect: 2380/4024 0.271s 0.000s
im_detect: 2381/4024 0.271s 0.000s
im_detect: 2382/4024 0.271s 0.000s
im_detect: 2383/4024 0.271s 0.000s
im_detect: 2384/4024 0.271s 0.000s
im_detect: 2385/4024 0.271s 0.000s
im_detect: 2386/4024 0.271s 0.000s
im_detect: 2387/4024 0.271s 0.000s
im_detect: 2388/4024 0.271s 0.000s
im_detect: 2389/4024 0.271s 0.000s
im_detect: 2390/4024 0.271s 0.000s
im_detect: 2391/4024 0.271s 0.000s
im_detect: 2392/4024 0.271s 0.000s
im_detect: 2393/4024 0.271s 0.000s
im_detect: 2394/4024 0.271s 0.000s
im_detect: 2395/4024 0.271s 0.000s
im_detect: 2396/4024 0.271s 0.000s
im_detect: 2397/4024 0.271s 0.000s
im_detect: 2398/4024 0.271s 0.000s
im_detect: 2399/4024 0.271s 0.000s
im_detect: 2400/4024 0.271s 0.000s
im_detect: 2401/4024 0.271s 0.000s
im_detect: 2402/4024 0.271s 0.000s
im_detect: 2403/4024 0.271s 0.000s
im_detect: 2404/4024 0.271s 0.000s
im_detect: 2405/4024 0.271s 0.000s
im_detect: 2406/4024 0.271s 0.000s
im_detect: 2407/4024 0.271s 0.000s
im_detect: 2408/4024 0.271s 0.000s
im_detect: 2409/4024 0.271s 0.000s
im_detect: 2410/4024 0.271s 0.000s
im_detect: 2411/4024 0.271s 0.000s
im_detect: 2412/4024 0.271s 0.000s
im_detect: 2413/4024 0.271s 0.000s
im_detect: 2414/4024 0.271s 0.000s
im_detect: 2415/4024 0.271s 0.000s
im_detect: 2416/4024 0.271s 0.000s
im_detect: 2417/4024 0.271s 0.000s
im_detect: 2418/4024 0.271s 0.000s
im_detect: 2419/4024 0.271s 0.000s
im_detect: 2420/4024 0.271s 0.000s
im_detect: 2421/4024 0.271s 0.000s
im_detect: 2422/4024 0.271s 0.000s
im_detect: 2423/4024 0.271s 0.000s
im_detect: 2424/4024 0.271s 0.000s
im_detect: 2425/4024 0.271s 0.000s
im_detect: 2426/4024 0.271s 0.000s
im_detect: 2427/4024 0.271s 0.000s
im_detect: 2428/4024 0.271s 0.000s
im_detect: 2429/4024 0.271s 0.000s
im_detect: 2430/4024 0.271s 0.000s
im_detect: 2431/4024 0.271s 0.000s
im_detect: 2432/4024 0.271s 0.000s
im_detect: 2433/4024 0.271s 0.000s
im_detect: 2434/4024 0.271s 0.000s
im_detect: 2435/4024 0.271s 0.000s
im_detect: 2436/4024 0.271s 0.000s
im_detect: 2437/4024 0.271s 0.000s
im_detect: 2438/4024 0.271s 0.000s
im_detect: 2439/4024 0.271s 0.000s
im_detect: 2440/4024 0.271s 0.000s
im_detect: 2441/4024 0.271s 0.000s
im_detect: 2442/4024 0.271s 0.000s
im_detect: 2443/4024 0.271s 0.000s
im_detect: 2444/4024 0.271s 0.000s
im_detect: 2445/4024 0.271s 0.000s
im_detect: 2446/4024 0.271s 0.000s
im_detect: 2447/4024 0.271s 0.000s
im_detect: 2448/4024 0.271s 0.000s
im_detect: 2449/4024 0.271s 0.000s
im_detect: 2450/4024 0.271s 0.000s
im_detect: 2451/4024 0.271s 0.000s
im_detect: 2452/4024 0.271s 0.000s
im_detect: 2453/4024 0.271s 0.000s
im_detect: 2454/4024 0.271s 0.000s
im_detect: 2455/4024 0.271s 0.000s
im_detect: 2456/4024 0.271s 0.000s
im_detect: 2457/4024 0.271s 0.000s
im_detect: 2458/4024 0.271s 0.000s
im_detect: 2459/4024 0.271s 0.000s
im_detect: 2460/4024 0.271s 0.000s
im_detect: 2461/4024 0.271s 0.000s
im_detect: 2462/4024 0.271s 0.000s
im_detect: 2463/4024 0.271s 0.000s
im_detect: 2464/4024 0.271s 0.000s
im_detect: 2465/4024 0.271s 0.000s
im_detect: 2466/4024 0.271s 0.000s
im_detect: 2467/4024 0.271s 0.000s
im_detect: 2468/4024 0.271s 0.000s
im_detect: 2469/4024 0.271s 0.000s
im_detect: 2470/4024 0.271s 0.000s
im_detect: 2471/4024 0.271s 0.000s
im_detect: 2472/4024 0.271s 0.000s
im_detect: 2473/4024 0.271s 0.000s
im_detect: 2474/4024 0.271s 0.000s
im_detect: 2475/4024 0.271s 0.000s
im_detect: 2476/4024 0.271s 0.000s
im_detect: 2477/4024 0.271s 0.000s
im_detect: 2478/4024 0.271s 0.000s
im_detect: 2479/4024 0.271s 0.000s
im_detect: 2480/4024 0.271s 0.000s
im_detect: 2481/4024 0.271s 0.000s
im_detect: 2482/4024 0.271s 0.000s
im_detect: 2483/4024 0.271s 0.000s
im_detect: 2484/4024 0.271s 0.000s
im_detect: 2485/4024 0.271s 0.000s
im_detect: 2486/4024 0.271s 0.000s
im_detect: 2487/4024 0.271s 0.000s
im_detect: 2488/4024 0.271s 0.000s
im_detect: 2489/4024 0.271s 0.000s
im_detect: 2490/4024 0.271s 0.000s
im_detect: 2491/4024 0.271s 0.000s
im_detect: 2492/4024 0.271s 0.000s
im_detect: 2493/4024 0.271s 0.000s
im_detect: 2494/4024 0.271s 0.000s
im_detect: 2495/4024 0.271s 0.000s
im_detect: 2496/4024 0.271s 0.000s
im_detect: 2497/4024 0.271s 0.000s
im_detect: 2498/4024 0.271s 0.000s
im_detect: 2499/4024 0.271s 0.000s
im_detect: 2500/4024 0.271s 0.000s
im_detect: 2501/4024 0.271s 0.000s
im_detect: 2502/4024 0.271s 0.000s
im_detect: 2503/4024 0.271s 0.000s
im_detect: 2504/4024 0.271s 0.000s
im_detect: 2505/4024 0.271s 0.000s
im_detect: 2506/4024 0.271s 0.000s
im_detect: 2507/4024 0.271s 0.000s
im_detect: 2508/4024 0.271s 0.000s
im_detect: 2509/4024 0.271s 0.000s
im_detect: 2510/4024 0.271s 0.000s
im_detect: 2511/4024 0.271s 0.000s
im_detect: 2512/4024 0.271s 0.000s
im_detect: 2513/4024 0.271s 0.000s
im_detect: 2514/4024 0.271s 0.000s
im_detect: 2515/4024 0.271s 0.000s
im_detect: 2516/4024 0.271s 0.000s
im_detect: 2517/4024 0.271s 0.000s
im_detect: 2518/4024 0.271s 0.000s
im_detect: 2519/4024 0.271s 0.000s
im_detect: 2520/4024 0.271s 0.000s
im_detect: 2521/4024 0.271s 0.000s
im_detect: 2522/4024 0.271s 0.000s
im_detect: 2523/4024 0.271s 0.000s
im_detect: 2524/4024 0.271s 0.000s
im_detect: 2525/4024 0.271s 0.000s
im_detect: 2526/4024 0.271s 0.000s
im_detect: 2527/4024 0.271s 0.000s
im_detect: 2528/4024 0.271s 0.000s
im_detect: 2529/4024 0.271s 0.000s
im_detect: 2530/4024 0.271s 0.000s
im_detect: 2531/4024 0.271s 0.000s
im_detect: 2532/4024 0.271s 0.000s
im_detect: 2533/4024 0.271s 0.000s
im_detect: 2534/4024 0.271s 0.000s
im_detect: 2535/4024 0.271s 0.000s
im_detect: 2536/4024 0.271s 0.000s
im_detect: 2537/4024 0.271s 0.000s
im_detect: 2538/4024 0.271s 0.000s
im_detect: 2539/4024 0.271s 0.000s
im_detect: 2540/4024 0.271s 0.000s
im_detect: 2541/4024 0.271s 0.000s
im_detect: 2542/4024 0.271s 0.000s
im_detect: 2543/4024 0.271s 0.000s
im_detect: 2544/4024 0.271s 0.000s
im_detect: 2545/4024 0.271s 0.000s
im_detect: 2546/4024 0.271s 0.000s
im_detect: 2547/4024 0.271s 0.000s
im_detect: 2548/4024 0.271s 0.000s
im_detect: 2549/4024 0.271s 0.000s
im_detect: 2550/4024 0.271s 0.000s
im_detect: 2551/4024 0.271s 0.000s
im_detect: 2552/4024 0.271s 0.000s
im_detect: 2553/4024 0.271s 0.000s
im_detect: 2554/4024 0.271s 0.000s
im_detect: 2555/4024 0.271s 0.000s
im_detect: 2556/4024 0.271s 0.000s
im_detect: 2557/4024 0.271s 0.000s
im_detect: 2558/4024 0.271s 0.000s
im_detect: 2559/4024 0.271s 0.000s
im_detect: 2560/4024 0.271s 0.000s
im_detect: 2561/4024 0.271s 0.000s
im_detect: 2562/4024 0.271s 0.000s
im_detect: 2563/4024 0.271s 0.000s
im_detect: 2564/4024 0.271s 0.000s
im_detect: 2565/4024 0.271s 0.000s
im_detect: 2566/4024 0.271s 0.000s
im_detect: 2567/4024 0.271s 0.000s
im_detect: 2568/4024 0.271s 0.000s
im_detect: 2569/4024 0.271s 0.000s
im_detect: 2570/4024 0.271s 0.000s
im_detect: 2571/4024 0.271s 0.000s
im_detect: 2572/4024 0.271s 0.000s
im_detect: 2573/4024 0.271s 0.000s
im_detect: 2574/4024 0.271s 0.000s
im_detect: 2575/4024 0.271s 0.000s
im_detect: 2576/4024 0.271s 0.000s
im_detect: 2577/4024 0.271s 0.000s
im_detect: 2578/4024 0.271s 0.000s
im_detect: 2579/4024 0.271s 0.000s
im_detect: 2580/4024 0.271s 0.000s
im_detect: 2581/4024 0.271s 0.000s
im_detect: 2582/4024 0.271s 0.000s
im_detect: 2583/4024 0.271s 0.000s
im_detect: 2584/4024 0.271s 0.000s
im_detect: 2585/4024 0.271s 0.000s
im_detect: 2586/4024 0.271s 0.000s
im_detect: 2587/4024 0.271s 0.000s
im_detect: 2588/4024 0.271s 0.000s
im_detect: 2589/4024 0.271s 0.000s
im_detect: 2590/4024 0.271s 0.000s
im_detect: 2591/4024 0.271s 0.000s
im_detect: 2592/4024 0.271s 0.000s
im_detect: 2593/4024 0.271s 0.000s
im_detect: 2594/4024 0.271s 0.000s
im_detect: 2595/4024 0.271s 0.000s
im_detect: 2596/4024 0.271s 0.000s
im_detect: 2597/4024 0.271s 0.000s
im_detect: 2598/4024 0.271s 0.000s
im_detect: 2599/4024 0.271s 0.000s
im_detect: 2600/4024 0.271s 0.000s
im_detect: 2601/4024 0.271s 0.000s
im_detect: 2602/4024 0.271s 0.000s
im_detect: 2603/4024 0.271s 0.000s
im_detect: 2604/4024 0.271s 0.000s
im_detect: 2605/4024 0.271s 0.000s
im_detect: 2606/4024 0.271s 0.000s
im_detect: 2607/4024 0.271s 0.000s
im_detect: 2608/4024 0.271s 0.000s
im_detect: 2609/4024 0.271s 0.000s
im_detect: 2610/4024 0.271s 0.000s
im_detect: 2611/4024 0.271s 0.000s
im_detect: 2612/4024 0.271s 0.000s
im_detect: 2613/4024 0.271s 0.000s
im_detect: 2614/4024 0.271s 0.000s
im_detect: 2615/4024 0.271s 0.000s
im_detect: 2616/4024 0.271s 0.000s
im_detect: 2617/4024 0.271s 0.000s
im_detect: 2618/4024 0.271s 0.000s
im_detect: 2619/4024 0.271s 0.000s
im_detect: 2620/4024 0.271s 0.000s
im_detect: 2621/4024 0.271s 0.000s
im_detect: 2622/4024 0.271s 0.000s
im_detect: 2623/4024 0.271s 0.000s
im_detect: 2624/4024 0.271s 0.000s
im_detect: 2625/4024 0.271s 0.000s
im_detect: 2626/4024 0.271s 0.000s
im_detect: 2627/4024 0.271s 0.000s
im_detect: 2628/4024 0.271s 0.000s
im_detect: 2629/4024 0.271s 0.000s
im_detect: 2630/4024 0.271s 0.000s
im_detect: 2631/4024 0.271s 0.000s
im_detect: 2632/4024 0.271s 0.000s
im_detect: 2633/4024 0.271s 0.000s
im_detect: 2634/4024 0.271s 0.000s
im_detect: 2635/4024 0.271s 0.000s
im_detect: 2636/4024 0.271s 0.000s
im_detect: 2637/4024 0.271s 0.000s
im_detect: 2638/4024 0.271s 0.000s
im_detect: 2639/4024 0.271s 0.000s
im_detect: 2640/4024 0.271s 0.000s
im_detect: 2641/4024 0.271s 0.000s
im_detect: 2642/4024 0.271s 0.000s
im_detect: 2643/4024 0.271s 0.000s
im_detect: 2644/4024 0.271s 0.000s
im_detect: 2645/4024 0.271s 0.000s
im_detect: 2646/4024 0.271s 0.000s
im_detect: 2647/4024 0.271s 0.000s
im_detect: 2648/4024 0.271s 0.000s
im_detect: 2649/4024 0.271s 0.000s
im_detect: 2650/4024 0.271s 0.000s
im_detect: 2651/4024 0.271s 0.000s
im_detect: 2652/4024 0.271s 0.000s
im_detect: 2653/4024 0.271s 0.000s
im_detect: 2654/4024 0.271s 0.000s
im_detect: 2655/4024 0.271s 0.000s
im_detect: 2656/4024 0.271s 0.000s
im_detect: 2657/4024 0.271s 0.000s
im_detect: 2658/4024 0.271s 0.000s
im_detect: 2659/4024 0.271s 0.000s
im_detect: 2660/4024 0.271s 0.000s
im_detect: 2661/4024 0.271s 0.000s
im_detect: 2662/4024 0.271s 0.000s
im_detect: 2663/4024 0.271s 0.000s
im_detect: 2664/4024 0.271s 0.000s
im_detect: 2665/4024 0.271s 0.000s
im_detect: 2666/4024 0.271s 0.000s
im_detect: 2667/4024 0.271s 0.000s
im_detect: 2668/4024 0.271s 0.000s
im_detect: 2669/4024 0.271s 0.000s
im_detect: 2670/4024 0.271s 0.000s
im_detect: 2671/4024 0.271s 0.000s
im_detect: 2672/4024 0.271s 0.000s
im_detect: 2673/4024 0.271s 0.000s
im_detect: 2674/4024 0.271s 0.000s
im_detect: 2675/4024 0.271s 0.000s
im_detect: 2676/4024 0.271s 0.000s
im_detect: 2677/4024 0.271s 0.000s
im_detect: 2678/4024 0.271s 0.000s
im_detect: 2679/4024 0.271s 0.000s
im_detect: 2680/4024 0.271s 0.000s
im_detect: 2681/4024 0.271s 0.000s
im_detect: 2682/4024 0.271s 0.000s
im_detect: 2683/4024 0.271s 0.000s
im_detect: 2684/4024 0.271s 0.000s
im_detect: 2685/4024 0.271s 0.000s
im_detect: 2686/4024 0.271s 0.000s
im_detect: 2687/4024 0.271s 0.000s
im_detect: 2688/4024 0.271s 0.000s
im_detect: 2689/4024 0.271s 0.000s
im_detect: 2690/4024 0.271s 0.000s
im_detect: 2691/4024 0.271s 0.000s
im_detect: 2692/4024 0.271s 0.000s
im_detect: 2693/4024 0.271s 0.000s
im_detect: 2694/4024 0.271s 0.000s
im_detect: 2695/4024 0.271s 0.000s
im_detect: 2696/4024 0.271s 0.000s
im_detect: 2697/4024 0.271s 0.000s
im_detect: 2698/4024 0.271s 0.000s
im_detect: 2699/4024 0.271s 0.000s
im_detect: 2700/4024 0.271s 0.000s
im_detect: 2701/4024 0.271s 0.000s
im_detect: 2702/4024 0.271s 0.000s
im_detect: 2703/4024 0.271s 0.000s
im_detect: 2704/4024 0.271s 0.000s
im_detect: 2705/4024 0.271s 0.000s
im_detect: 2706/4024 0.271s 0.000s
im_detect: 2707/4024 0.271s 0.000s
im_detect: 2708/4024 0.271s 0.000s
im_detect: 2709/4024 0.271s 0.000s
im_detect: 2710/4024 0.271s 0.000s
im_detect: 2711/4024 0.271s 0.000s
im_detect: 2712/4024 0.271s 0.000s
im_detect: 2713/4024 0.271s 0.000s
im_detect: 2714/4024 0.271s 0.000s
im_detect: 2715/4024 0.271s 0.000s
im_detect: 2716/4024 0.271s 0.000s
im_detect: 2717/4024 0.271s 0.000s
im_detect: 2718/4024 0.271s 0.000s
im_detect: 2719/4024 0.271s 0.000s
im_detect: 2720/4024 0.271s 0.000s
im_detect: 2721/4024 0.271s 0.000s
im_detect: 2722/4024 0.271s 0.000s
im_detect: 2723/4024 0.271s 0.000s
im_detect: 2724/4024 0.271s 0.000s
im_detect: 2725/4024 0.271s 0.000s
im_detect: 2726/4024 0.271s 0.000s
im_detect: 2727/4024 0.271s 0.000s
im_detect: 2728/4024 0.271s 0.000s
im_detect: 2729/4024 0.271s 0.000s
im_detect: 2730/4024 0.271s 0.000s
im_detect: 2731/4024 0.271s 0.000s
im_detect: 2732/4024 0.271s 0.000s
im_detect: 2733/4024 0.271s 0.000s
im_detect: 2734/4024 0.271s 0.000s
im_detect: 2735/4024 0.271s 0.000s
im_detect: 2736/4024 0.271s 0.000s
im_detect: 2737/4024 0.271s 0.000s
im_detect: 2738/4024 0.271s 0.000s
im_detect: 2739/4024 0.271s 0.000s
im_detect: 2740/4024 0.271s 0.000s
im_detect: 2741/4024 0.271s 0.000s
im_detect: 2742/4024 0.271s 0.000s
im_detect: 2743/4024 0.271s 0.000s
im_detect: 2744/4024 0.271s 0.000s
im_detect: 2745/4024 0.271s 0.000s
im_detect: 2746/4024 0.271s 0.000s
im_detect: 2747/4024 0.271s 0.000s
im_detect: 2748/4024 0.271s 0.000s
im_detect: 2749/4024 0.271s 0.000s
im_detect: 2750/4024 0.271s 0.000s
im_detect: 2751/4024 0.271s 0.000s
im_detect: 2752/4024 0.271s 0.000s
im_detect: 2753/4024 0.271s 0.000s
im_detect: 2754/4024 0.271s 0.000s
im_detect: 2755/4024 0.271s 0.000s
im_detect: 2756/4024 0.271s 0.000s
im_detect: 2757/4024 0.271s 0.000s
im_detect: 2758/4024 0.271s 0.000s
im_detect: 2759/4024 0.271s 0.000s
im_detect: 2760/4024 0.271s 0.000s
im_detect: 2761/4024 0.271s 0.000s
im_detect: 2762/4024 0.271s 0.000s
im_detect: 2763/4024 0.271s 0.000s
im_detect: 2764/4024 0.271s 0.000s
im_detect: 2765/4024 0.271s 0.000s
im_detect: 2766/4024 0.271s 0.000s
im_detect: 2767/4024 0.271s 0.000s
im_detect: 2768/4024 0.271s 0.000s
im_detect: 2769/4024 0.271s 0.000s
im_detect: 2770/4024 0.271s 0.000s
im_detect: 2771/4024 0.271s 0.000s
im_detect: 2772/4024 0.271s 0.000s
im_detect: 2773/4024 0.271s 0.000s
im_detect: 2774/4024 0.271s 0.000s
im_detect: 2775/4024 0.271s 0.000s
im_detect: 2776/4024 0.271s 0.000s
im_detect: 2777/4024 0.271s 0.000s
im_detect: 2778/4024 0.271s 0.000s
im_detect: 2779/4024 0.271s 0.000s
im_detect: 2780/4024 0.271s 0.000s
im_detect: 2781/4024 0.271s 0.000s
im_detect: 2782/4024 0.271s 0.000s
im_detect: 2783/4024 0.271s 0.000s
im_detect: 2784/4024 0.271s 0.000s
im_detect: 2785/4024 0.271s 0.000s
im_detect: 2786/4024 0.271s 0.000s
im_detect: 2787/4024 0.271s 0.000s
im_detect: 2788/4024 0.271s 0.000s
im_detect: 2789/4024 0.271s 0.000s
im_detect: 2790/4024 0.271s 0.000s
im_detect: 2791/4024 0.271s 0.000s
im_detect: 2792/4024 0.271s 0.000s
im_detect: 2793/4024 0.271s 0.000s
im_detect: 2794/4024 0.271s 0.000s
im_detect: 2795/4024 0.271s 0.000s
im_detect: 2796/4024 0.271s 0.000s
im_detect: 2797/4024 0.271s 0.000s
im_detect: 2798/4024 0.271s 0.000s
im_detect: 2799/4024 0.271s 0.000s
im_detect: 2800/4024 0.271s 0.000s
im_detect: 2801/4024 0.271s 0.000s
im_detect: 2802/4024 0.271s 0.000s
im_detect: 2803/4024 0.271s 0.000s
im_detect: 2804/4024 0.271s 0.000s
im_detect: 2805/4024 0.271s 0.000s
im_detect: 2806/4024 0.271s 0.000s
im_detect: 2807/4024 0.271s 0.000s
im_detect: 2808/4024 0.271s 0.000s
im_detect: 2809/4024 0.271s 0.000s
im_detect: 2810/4024 0.271s 0.000s
im_detect: 2811/4024 0.271s 0.000s
im_detect: 2812/4024 0.271s 0.000s
im_detect: 2813/4024 0.271s 0.000s
im_detect: 2814/4024 0.271s 0.000s
im_detect: 2815/4024 0.271s 0.000s
im_detect: 2816/4024 0.271s 0.000s
im_detect: 2817/4024 0.271s 0.000s
im_detect: 2818/4024 0.271s 0.000s
im_detect: 2819/4024 0.271s 0.000s
im_detect: 2820/4024 0.271s 0.000s
im_detect: 2821/4024 0.271s 0.000s
im_detect: 2822/4024 0.271s 0.000s
im_detect: 2823/4024 0.271s 0.000s
im_detect: 2824/4024 0.271s 0.000s
im_detect: 2825/4024 0.271s 0.000s
im_detect: 2826/4024 0.271s 0.000s
im_detect: 2827/4024 0.271s 0.000s
im_detect: 2828/4024 0.271s 0.000s
im_detect: 2829/4024 0.271s 0.000s
im_detect: 2830/4024 0.271s 0.000s
im_detect: 2831/4024 0.271s 0.000s
im_detect: 2832/4024 0.271s 0.000s
im_detect: 2833/4024 0.271s 0.000s
im_detect: 2834/4024 0.271s 0.000s
im_detect: 2835/4024 0.271s 0.000s
im_detect: 2836/4024 0.271s 0.000s
im_detect: 2837/4024 0.271s 0.000s
im_detect: 2838/4024 0.271s 0.000s
im_detect: 2839/4024 0.271s 0.000s
im_detect: 2840/4024 0.271s 0.000s
im_detect: 2841/4024 0.271s 0.000s
im_detect: 2842/4024 0.271s 0.000s
im_detect: 2843/4024 0.271s 0.000s
im_detect: 2844/4024 0.271s 0.000s
im_detect: 2845/4024 0.271s 0.000s
im_detect: 2846/4024 0.271s 0.000s
im_detect: 2847/4024 0.271s 0.000s
im_detect: 2848/4024 0.271s 0.000s
im_detect: 2849/4024 0.271s 0.000s
im_detect: 2850/4024 0.271s 0.000s
im_detect: 2851/4024 0.271s 0.000s
im_detect: 2852/4024 0.271s 0.000s
im_detect: 2853/4024 0.271s 0.000s
im_detect: 2854/4024 0.271s 0.000s
im_detect: 2855/4024 0.271s 0.000s
im_detect: 2856/4024 0.271s 0.000s
im_detect: 2857/4024 0.271s 0.000s
im_detect: 2858/4024 0.271s 0.000s
im_detect: 2859/4024 0.271s 0.000s
im_detect: 2860/4024 0.271s 0.000s
im_detect: 2861/4024 0.271s 0.000s
im_detect: 2862/4024 0.271s 0.000s
im_detect: 2863/4024 0.271s 0.000s
im_detect: 2864/4024 0.271s 0.000s
im_detect: 2865/4024 0.271s 0.000s
im_detect: 2866/4024 0.271s 0.000s
im_detect: 2867/4024 0.271s 0.000s
im_detect: 2868/4024 0.271s 0.000s
im_detect: 2869/4024 0.271s 0.000s
im_detect: 2870/4024 0.271s 0.000s
im_detect: 2871/4024 0.271s 0.000s
im_detect: 2872/4024 0.271s 0.000s
im_detect: 2873/4024 0.271s 0.000s
im_detect: 2874/4024 0.271s 0.000s
im_detect: 2875/4024 0.271s 0.000s
im_detect: 2876/4024 0.271s 0.000s
im_detect: 2877/4024 0.271s 0.000s
im_detect: 2878/4024 0.271s 0.000s
im_detect: 2879/4024 0.271s 0.000s
im_detect: 2880/4024 0.271s 0.000s
im_detect: 2881/4024 0.271s 0.000s
im_detect: 2882/4024 0.271s 0.000s
im_detect: 2883/4024 0.271s 0.000s
im_detect: 2884/4024 0.271s 0.000s
im_detect: 2885/4024 0.271s 0.000s
im_detect: 2886/4024 0.271s 0.000s
im_detect: 2887/4024 0.271s 0.000s
im_detect: 2888/4024 0.271s 0.000s
im_detect: 2889/4024 0.271s 0.000s
im_detect: 2890/4024 0.271s 0.000s
im_detect: 2891/4024 0.271s 0.000s
im_detect: 2892/4024 0.271s 0.000s
im_detect: 2893/4024 0.271s 0.000s
im_detect: 2894/4024 0.271s 0.000s
im_detect: 2895/4024 0.271s 0.000s
im_detect: 2896/4024 0.271s 0.000s
im_detect: 2897/4024 0.271s 0.000s
im_detect: 2898/4024 0.271s 0.000s
im_detect: 2899/4024 0.271s 0.000s
im_detect: 2900/4024 0.271s 0.000s
im_detect: 2901/4024 0.271s 0.000s
im_detect: 2902/4024 0.271s 0.000s
im_detect: 2903/4024 0.271s 0.000s
im_detect: 2904/4024 0.271s 0.000s
im_detect: 2905/4024 0.271s 0.000s
im_detect: 2906/4024 0.271s 0.000s
im_detect: 2907/4024 0.271s 0.000s
im_detect: 2908/4024 0.271s 0.000s
im_detect: 2909/4024 0.271s 0.000s
im_detect: 2910/4024 0.271s 0.000s
im_detect: 2911/4024 0.271s 0.000s
im_detect: 2912/4024 0.271s 0.000s
im_detect: 2913/4024 0.271s 0.000s
im_detect: 2914/4024 0.271s 0.000s
im_detect: 2915/4024 0.271s 0.000s
im_detect: 2916/4024 0.271s 0.000s
im_detect: 2917/4024 0.271s 0.000s
im_detect: 2918/4024 0.271s 0.000s
im_detect: 2919/4024 0.271s 0.000s
im_detect: 2920/4024 0.271s 0.000s
im_detect: 2921/4024 0.271s 0.000s
im_detect: 2922/4024 0.271s 0.000s
im_detect: 2923/4024 0.271s 0.000s
im_detect: 2924/4024 0.271s 0.000s
im_detect: 2925/4024 0.271s 0.000s
im_detect: 2926/4024 0.271s 0.000s
im_detect: 2927/4024 0.271s 0.000s
im_detect: 2928/4024 0.271s 0.000s
im_detect: 2929/4024 0.271s 0.000s
im_detect: 2930/4024 0.271s 0.000s
im_detect: 2931/4024 0.271s 0.000s
im_detect: 2932/4024 0.271s 0.000s
im_detect: 2933/4024 0.271s 0.000s
im_detect: 2934/4024 0.271s 0.000s
im_detect: 2935/4024 0.271s 0.000s
im_detect: 2936/4024 0.271s 0.000s
im_detect: 2937/4024 0.271s 0.000s
im_detect: 2938/4024 0.271s 0.000s
im_detect: 2939/4024 0.271s 0.000s
im_detect: 2940/4024 0.271s 0.000s
im_detect: 2941/4024 0.271s 0.000s
im_detect: 2942/4024 0.271s 0.000s
im_detect: 2943/4024 0.271s 0.000s
im_detect: 2944/4024 0.271s 0.000s
im_detect: 2945/4024 0.271s 0.000s
im_detect: 2946/4024 0.271s 0.000s
im_detect: 2947/4024 0.271s 0.000s
im_detect: 2948/4024 0.271s 0.000s
im_detect: 2949/4024 0.271s 0.000s
im_detect: 2950/4024 0.271s 0.000s
im_detect: 2951/4024 0.271s 0.000s
im_detect: 2952/4024 0.271s 0.000s
im_detect: 2953/4024 0.271s 0.000s
im_detect: 2954/4024 0.271s 0.000s
im_detect: 2955/4024 0.271s 0.000s
im_detect: 2956/4024 0.271s 0.000s
im_detect: 2957/4024 0.271s 0.000s
im_detect: 2958/4024 0.271s 0.000s
im_detect: 2959/4024 0.271s 0.000s
im_detect: 2960/4024 0.271s 0.000s
im_detect: 2961/4024 0.271s 0.000s
im_detect: 2962/4024 0.271s 0.000s
im_detect: 2963/4024 0.271s 0.000s
im_detect: 2964/4024 0.271s 0.000s
im_detect: 2965/4024 0.271s 0.000s
im_detect: 2966/4024 0.271s 0.000s
im_detect: 2967/4024 0.271s 0.000s
im_detect: 2968/4024 0.271s 0.000s
im_detect: 2969/4024 0.271s 0.000s
im_detect: 2970/4024 0.271s 0.000s
im_detect: 2971/4024 0.271s 0.000s
im_detect: 2972/4024 0.271s 0.000s
im_detect: 2973/4024 0.271s 0.000s
im_detect: 2974/4024 0.271s 0.000s
im_detect: 2975/4024 0.271s 0.000s
im_detect: 2976/4024 0.271s 0.000s
im_detect: 2977/4024 0.271s 0.000s
im_detect: 2978/4024 0.271s 0.000s
im_detect: 2979/4024 0.271s 0.000s
im_detect: 2980/4024 0.271s 0.000s
im_detect: 2981/4024 0.271s 0.000s
im_detect: 2982/4024 0.271s 0.000s
im_detect: 2983/4024 0.271s 0.000s
im_detect: 2984/4024 0.271s 0.000s
im_detect: 2985/4024 0.271s 0.000s
im_detect: 2986/4024 0.271s 0.000s
im_detect: 2987/4024 0.271s 0.000s
im_detect: 2988/4024 0.271s 0.000s
im_detect: 2989/4024 0.271s 0.000s
im_detect: 2990/4024 0.271s 0.000s
im_detect: 2991/4024 0.271s 0.000s
im_detect: 2992/4024 0.271s 0.000s
im_detect: 2993/4024 0.271s 0.000s
im_detect: 2994/4024 0.271s 0.000s
im_detect: 2995/4024 0.271s 0.000s
im_detect: 2996/4024 0.271s 0.000s
im_detect: 2997/4024 0.271s 0.000s
im_detect: 2998/4024 0.271s 0.000s
im_detect: 2999/4024 0.271s 0.000s
im_detect: 3000/4024 0.271s 0.000s
im_detect: 3001/4024 0.271s 0.000s
im_detect: 3002/4024 0.271s 0.000s
im_detect: 3003/4024 0.271s 0.000s
im_detect: 3004/4024 0.271s 0.000s
im_detect: 3005/4024 0.271s 0.000s
im_detect: 3006/4024 0.271s 0.000s
im_detect: 3007/4024 0.271s 0.000s
im_detect: 3008/4024 0.271s 0.000s
im_detect: 3009/4024 0.271s 0.000s
im_detect: 3010/4024 0.271s 0.000s
im_detect: 3011/4024 0.271s 0.000s
im_detect: 3012/4024 0.271s 0.000s
im_detect: 3013/4024 0.271s 0.000s
im_detect: 3014/4024 0.271s 0.000s
im_detect: 3015/4024 0.271s 0.000s
im_detect: 3016/4024 0.271s 0.000s
im_detect: 3017/4024 0.271s 0.000s
im_detect: 3018/4024 0.271s 0.000s
im_detect: 3019/4024 0.271s 0.000s
im_detect: 3020/4024 0.271s 0.000s
im_detect: 3021/4024 0.271s 0.000s
im_detect: 3022/4024 0.271s 0.000s
im_detect: 3023/4024 0.271s 0.000s
im_detect: 3024/4024 0.271s 0.000s
im_detect: 3025/4024 0.271s 0.000s
im_detect: 3026/4024 0.271s 0.000s
im_detect: 3027/4024 0.271s 0.000s
im_detect: 3028/4024 0.271s 0.000s
im_detect: 3029/4024 0.271s 0.000s
im_detect: 3030/4024 0.271s 0.000s
im_detect: 3031/4024 0.271s 0.000s
im_detect: 3032/4024 0.271s 0.000s
im_detect: 3033/4024 0.271s 0.000s
im_detect: 3034/4024 0.271s 0.000s
im_detect: 3035/4024 0.271s 0.000s
im_detect: 3036/4024 0.271s 0.000s
im_detect: 3037/4024 0.271s 0.000s
im_detect: 3038/4024 0.271s 0.000s
im_detect: 3039/4024 0.271s 0.000s
im_detect: 3040/4024 0.271s 0.000s
im_detect: 3041/4024 0.271s 0.000s
im_detect: 3042/4024 0.271s 0.000s
im_detect: 3043/4024 0.271s 0.000s
im_detect: 3044/4024 0.271s 0.000s
im_detect: 3045/4024 0.271s 0.000s
im_detect: 3046/4024 0.271s 0.000s
im_detect: 3047/4024 0.271s 0.000s
im_detect: 3048/4024 0.271s 0.000s
im_detect: 3049/4024 0.271s 0.000s
im_detect: 3050/4024 0.271s 0.000s
im_detect: 3051/4024 0.271s 0.000s
im_detect: 3052/4024 0.271s 0.000s
im_detect: 3053/4024 0.271s 0.000s
im_detect: 3054/4024 0.271s 0.000s
im_detect: 3055/4024 0.271s 0.000s
im_detect: 3056/4024 0.271s 0.000s
im_detect: 3057/4024 0.271s 0.000s
im_detect: 3058/4024 0.271s 0.000s
im_detect: 3059/4024 0.271s 0.000s
im_detect: 3060/4024 0.271s 0.000s
im_detect: 3061/4024 0.271s 0.000s
im_detect: 3062/4024 0.271s 0.000s
im_detect: 3063/4024 0.271s 0.000s
im_detect: 3064/4024 0.271s 0.000s
im_detect: 3065/4024 0.271s 0.000s
im_detect: 3066/4024 0.271s 0.000s
im_detect: 3067/4024 0.271s 0.000s
im_detect: 3068/4024 0.271s 0.000s
im_detect: 3069/4024 0.271s 0.000s
im_detect: 3070/4024 0.271s 0.000s
im_detect: 3071/4024 0.271s 0.000s
im_detect: 3072/4024 0.271s 0.000s
im_detect: 3073/4024 0.271s 0.000s
im_detect: 3074/4024 0.271s 0.000s
im_detect: 3075/4024 0.271s 0.000s
im_detect: 3076/4024 0.271s 0.000s
im_detect: 3077/4024 0.271s 0.000s
im_detect: 3078/4024 0.271s 0.000s
im_detect: 3079/4024 0.271s 0.000s
im_detect: 3080/4024 0.271s 0.000s
im_detect: 3081/4024 0.271s 0.000s
im_detect: 3082/4024 0.271s 0.000s
im_detect: 3083/4024 0.271s 0.000s
im_detect: 3084/4024 0.271s 0.000s
im_detect: 3085/4024 0.271s 0.000s
im_detect: 3086/4024 0.271s 0.000s
im_detect: 3087/4024 0.271s 0.000s
im_detect: 3088/4024 0.271s 0.000s
im_detect: 3089/4024 0.271s 0.000s
im_detect: 3090/4024 0.271s 0.000s
im_detect: 3091/4024 0.271s 0.000s
im_detect: 3092/4024 0.271s 0.000s
im_detect: 3093/4024 0.271s 0.000s
im_detect: 3094/4024 0.271s 0.000s
im_detect: 3095/4024 0.271s 0.000s
im_detect: 3096/4024 0.271s 0.000s
im_detect: 3097/4024 0.271s 0.000s
im_detect: 3098/4024 0.271s 0.000s
im_detect: 3099/4024 0.271s 0.000s
im_detect: 3100/4024 0.271s 0.000s
im_detect: 3101/4024 0.271s 0.000s
im_detect: 3102/4024 0.271s 0.000s
im_detect: 3103/4024 0.271s 0.000s
im_detect: 3104/4024 0.271s 0.000s
im_detect: 3105/4024 0.271s 0.000s
im_detect: 3106/4024 0.271s 0.000s
im_detect: 3107/4024 0.271s 0.000s
im_detect: 3108/4024 0.271s 0.000s
im_detect: 3109/4024 0.271s 0.000s
im_detect: 3110/4024 0.271s 0.000s
im_detect: 3111/4024 0.271s 0.000s
im_detect: 3112/4024 0.271s 0.000s
im_detect: 3113/4024 0.271s 0.000s
im_detect: 3114/4024 0.271s 0.000s
im_detect: 3115/4024 0.271s 0.000s
im_detect: 3116/4024 0.271s 0.000s
im_detect: 3117/4024 0.271s 0.000s
im_detect: 3118/4024 0.271s 0.000s
im_detect: 3119/4024 0.271s 0.000s
im_detect: 3120/4024 0.271s 0.000s
im_detect: 3121/4024 0.271s 0.000s
im_detect: 3122/4024 0.271s 0.000s
im_detect: 3123/4024 0.271s 0.000s
im_detect: 3124/4024 0.271s 0.000s
im_detect: 3125/4024 0.271s 0.000s
im_detect: 3126/4024 0.271s 0.000s
im_detect: 3127/4024 0.271s 0.000s
im_detect: 3128/4024 0.271s 0.000s
im_detect: 3129/4024 0.271s 0.000s
im_detect: 3130/4024 0.271s 0.000s
im_detect: 3131/4024 0.271s 0.000s
im_detect: 3132/4024 0.271s 0.000s
im_detect: 3133/4024 0.271s 0.000s
im_detect: 3134/4024 0.271s 0.000s
im_detect: 3135/4024 0.271s 0.000s
im_detect: 3136/4024 0.271s 0.000s
im_detect: 3137/4024 0.271s 0.000s
im_detect: 3138/4024 0.271s 0.000s
im_detect: 3139/4024 0.271s 0.000s
im_detect: 3140/4024 0.271s 0.000s
im_detect: 3141/4024 0.271s 0.000s
im_detect: 3142/4024 0.271s 0.000s
im_detect: 3143/4024 0.271s 0.000s
im_detect: 3144/4024 0.271s 0.000s
im_detect: 3145/4024 0.271s 0.000s
im_detect: 3146/4024 0.271s 0.000s
im_detect: 3147/4024 0.271s 0.000s
im_detect: 3148/4024 0.271s 0.000s
im_detect: 3149/4024 0.271s 0.000s
im_detect: 3150/4024 0.271s 0.000s
im_detect: 3151/4024 0.271s 0.000s
im_detect: 3152/4024 0.271s 0.000s
im_detect: 3153/4024 0.271s 0.000s
im_detect: 3154/4024 0.271s 0.000s
im_detect: 3155/4024 0.271s 0.000s
im_detect: 3156/4024 0.271s 0.000s
im_detect: 3157/4024 0.271s 0.000s
im_detect: 3158/4024 0.271s 0.000s
im_detect: 3159/4024 0.271s 0.000s
im_detect: 3160/4024 0.271s 0.000s
im_detect: 3161/4024 0.271s 0.000s
im_detect: 3162/4024 0.271s 0.000s
im_detect: 3163/4024 0.271s 0.000s
im_detect: 3164/4024 0.271s 0.000s
im_detect: 3165/4024 0.271s 0.000s
im_detect: 3166/4024 0.271s 0.000s
im_detect: 3167/4024 0.271s 0.000s
im_detect: 3168/4024 0.271s 0.000s
im_detect: 3169/4024 0.271s 0.000s
im_detect: 3170/4024 0.271s 0.000s
im_detect: 3171/4024 0.271s 0.000s
im_detect: 3172/4024 0.271s 0.000s
im_detect: 3173/4024 0.271s 0.000s
im_detect: 3174/4024 0.271s 0.000s
im_detect: 3175/4024 0.271s 0.000s
im_detect: 3176/4024 0.271s 0.000s
im_detect: 3177/4024 0.271s 0.000s
im_detect: 3178/4024 0.271s 0.000s
im_detect: 3179/4024 0.271s 0.000s
im_detect: 3180/4024 0.271s 0.000s
im_detect: 3181/4024 0.271s 0.000s
im_detect: 3182/4024 0.271s 0.000s
im_detect: 3183/4024 0.271s 0.000s
im_detect: 3184/4024 0.271s 0.000s
im_detect: 3185/4024 0.271s 0.000s
im_detect: 3186/4024 0.271s 0.000s
im_detect: 3187/4024 0.271s 0.000s
im_detect: 3188/4024 0.271s 0.000s
im_detect: 3189/4024 0.271s 0.000s
im_detect: 3190/4024 0.271s 0.000s
im_detect: 3191/4024 0.271s 0.000s
im_detect: 3192/4024 0.271s 0.000s
im_detect: 3193/4024 0.271s 0.000s
im_detect: 3194/4024 0.271s 0.000s
im_detect: 3195/4024 0.271s 0.000s
im_detect: 3196/4024 0.271s 0.000s
im_detect: 3197/4024 0.271s 0.000s
im_detect: 3198/4024 0.271s 0.000s
im_detect: 3199/4024 0.271s 0.000s
im_detect: 3200/4024 0.271s 0.000s
im_detect: 3201/4024 0.271s 0.000s
im_detect: 3202/4024 0.271s 0.000s
im_detect: 3203/4024 0.271s 0.000s
im_detect: 3204/4024 0.271s 0.000s
im_detect: 3205/4024 0.271s 0.000s
im_detect: 3206/4024 0.271s 0.000s
im_detect: 3207/4024 0.271s 0.000s
im_detect: 3208/4024 0.271s 0.000s
im_detect: 3209/4024 0.271s 0.000s
im_detect: 3210/4024 0.271s 0.000s
im_detect: 3211/4024 0.271s 0.000s
im_detect: 3212/4024 0.271s 0.000s
im_detect: 3213/4024 0.271s 0.000s
im_detect: 3214/4024 0.271s 0.000s
im_detect: 3215/4024 0.271s 0.000s
im_detect: 3216/4024 0.271s 0.000s
im_detect: 3217/4024 0.271s 0.000s
im_detect: 3218/4024 0.271s 0.000s
im_detect: 3219/4024 0.271s 0.000s
im_detect: 3220/4024 0.271s 0.000s
im_detect: 3221/4024 0.271s 0.000s
im_detect: 3222/4024 0.271s 0.000s
im_detect: 3223/4024 0.271s 0.000s
im_detect: 3224/4024 0.271s 0.000s
im_detect: 3225/4024 0.271s 0.000s
im_detect: 3226/4024 0.271s 0.000s
im_detect: 3227/4024 0.271s 0.000s
im_detect: 3228/4024 0.271s 0.000s
im_detect: 3229/4024 0.271s 0.000s
im_detect: 3230/4024 0.271s 0.000s
im_detect: 3231/4024 0.271s 0.000s
im_detect: 3232/4024 0.271s 0.000s
im_detect: 3233/4024 0.271s 0.000s
im_detect: 3234/4024 0.271s 0.000s
im_detect: 3235/4024 0.271s 0.000s
im_detect: 3236/4024 0.271s 0.000s
im_detect: 3237/4024 0.271s 0.000s
im_detect: 3238/4024 0.271s 0.000s
im_detect: 3239/4024 0.271s 0.000s
im_detect: 3240/4024 0.271s 0.000s
im_detect: 3241/4024 0.271s 0.000s
im_detect: 3242/4024 0.271s 0.000s
im_detect: 3243/4024 0.271s 0.000s
im_detect: 3244/4024 0.271s 0.000s
im_detect: 3245/4024 0.271s 0.000s
im_detect: 3246/4024 0.271s 0.000s
im_detect: 3247/4024 0.271s 0.000s
im_detect: 3248/4024 0.271s 0.000s
im_detect: 3249/4024 0.271s 0.000s
im_detect: 3250/4024 0.271s 0.000s
im_detect: 3251/4024 0.271s 0.000s
im_detect: 3252/4024 0.271s 0.000s
im_detect: 3253/4024 0.271s 0.000s
im_detect: 3254/4024 0.271s 0.000s
im_detect: 3255/4024 0.271s 0.000s
im_detect: 3256/4024 0.271s 0.000s
im_detect: 3257/4024 0.271s 0.000s
im_detect: 3258/4024 0.271s 0.000s
im_detect: 3259/4024 0.271s 0.000s
im_detect: 3260/4024 0.271s 0.000s
im_detect: 3261/4024 0.271s 0.000s
im_detect: 3262/4024 0.271s 0.000s
im_detect: 3263/4024 0.271s 0.000s
im_detect: 3264/4024 0.271s 0.000s
im_detect: 3265/4024 0.271s 0.000s
im_detect: 3266/4024 0.271s 0.000s
im_detect: 3267/4024 0.271s 0.000s
im_detect: 3268/4024 0.271s 0.000s
im_detect: 3269/4024 0.271s 0.000s
im_detect: 3270/4024 0.271s 0.000s
im_detect: 3271/4024 0.271s 0.000s
im_detect: 3272/4024 0.271s 0.000s
im_detect: 3273/4024 0.271s 0.000s
im_detect: 3274/4024 0.271s 0.000s
im_detect: 3275/4024 0.271s 0.000s
im_detect: 3276/4024 0.271s 0.000s
im_detect: 3277/4024 0.271s 0.000s
im_detect: 3278/4024 0.271s 0.000s
im_detect: 3279/4024 0.271s 0.000s
im_detect: 3280/4024 0.271s 0.000s
im_detect: 3281/4024 0.271s 0.000s
im_detect: 3282/4024 0.271s 0.000s
im_detect: 3283/4024 0.271s 0.000s
im_detect: 3284/4024 0.271s 0.000s
im_detect: 3285/4024 0.271s 0.000s
im_detect: 3286/4024 0.271s 0.000s
im_detect: 3287/4024 0.271s 0.000s
im_detect: 3288/4024 0.271s 0.000s
im_detect: 3289/4024 0.271s 0.000s
im_detect: 3290/4024 0.271s 0.000s
im_detect: 3291/4024 0.271s 0.000s
im_detect: 3292/4024 0.271s 0.000s
im_detect: 3293/4024 0.271s 0.000s
im_detect: 3294/4024 0.271s 0.000s
im_detect: 3295/4024 0.271s 0.000s
im_detect: 3296/4024 0.271s 0.000s
im_detect: 3297/4024 0.271s 0.000s
im_detect: 3298/4024 0.271s 0.000s
im_detect: 3299/4024 0.271s 0.000s
im_detect: 3300/4024 0.271s 0.000s
im_detect: 3301/4024 0.271s 0.000s
im_detect: 3302/4024 0.271s 0.000s
im_detect: 3303/4024 0.271s 0.000s
im_detect: 3304/4024 0.271s 0.000s
im_detect: 3305/4024 0.271s 0.000s
im_detect: 3306/4024 0.271s 0.000s
im_detect: 3307/4024 0.271s 0.000s
im_detect: 3308/4024 0.271s 0.000s
im_detect: 3309/4024 0.271s 0.000s
im_detect: 3310/4024 0.271s 0.000s
im_detect: 3311/4024 0.271s 0.000s
im_detect: 3312/4024 0.271s 0.000s
im_detect: 3313/4024 0.271s 0.000s
im_detect: 3314/4024 0.271s 0.000s
im_detect: 3315/4024 0.271s 0.000s
im_detect: 3316/4024 0.271s 0.000s
im_detect: 3317/4024 0.271s 0.000s
im_detect: 3318/4024 0.271s 0.000s
im_detect: 3319/4024 0.271s 0.000s
im_detect: 3320/4024 0.271s 0.000s
im_detect: 3321/4024 0.271s 0.000s
im_detect: 3322/4024 0.271s 0.000s
im_detect: 3323/4024 0.271s 0.000s
im_detect: 3324/4024 0.271s 0.000s
im_detect: 3325/4024 0.271s 0.000s
im_detect: 3326/4024 0.271s 0.000s
im_detect: 3327/4024 0.271s 0.000s
im_detect: 3328/4024 0.271s 0.000s
im_detect: 3329/4024 0.271s 0.000s
im_detect: 3330/4024 0.271s 0.000s
im_detect: 3331/4024 0.271s 0.000s
im_detect: 3332/4024 0.271s 0.000s
im_detect: 3333/4024 0.271s 0.000s
im_detect: 3334/4024 0.271s 0.000s
im_detect: 3335/4024 0.271s 0.000s
im_detect: 3336/4024 0.271s 0.000s
im_detect: 3337/4024 0.271s 0.000s
im_detect: 3338/4024 0.271s 0.000s
im_detect: 3339/4024 0.271s 0.000s
im_detect: 3340/4024 0.271s 0.000s
im_detect: 3341/4024 0.271s 0.000s
im_detect: 3342/4024 0.271s 0.000s
im_detect: 3343/4024 0.271s 0.000s
im_detect: 3344/4024 0.271s 0.000s
im_detect: 3345/4024 0.271s 0.000s
im_detect: 3346/4024 0.271s 0.000s
im_detect: 3347/4024 0.271s 0.000s
im_detect: 3348/4024 0.271s 0.000s
im_detect: 3349/4024 0.271s 0.000s
im_detect: 3350/4024 0.271s 0.000s
im_detect: 3351/4024 0.271s 0.000s
im_detect: 3352/4024 0.271s 0.000s
im_detect: 3353/4024 0.271s 0.000s
im_detect: 3354/4024 0.271s 0.000s
im_detect: 3355/4024 0.271s 0.000s
im_detect: 3356/4024 0.271s 0.000s
im_detect: 3357/4024 0.271s 0.000s
im_detect: 3358/4024 0.271s 0.000s
im_detect: 3359/4024 0.271s 0.000s
im_detect: 3360/4024 0.271s 0.000s
im_detect: 3361/4024 0.271s 0.000s
im_detect: 3362/4024 0.271s 0.000s
im_detect: 3363/4024 0.271s 0.000s
im_detect: 3364/4024 0.271s 0.000s
im_detect: 3365/4024 0.271s 0.000s
im_detect: 3366/4024 0.271s 0.000s
im_detect: 3367/4024 0.271s 0.000s
im_detect: 3368/4024 0.271s 0.000s
im_detect: 3369/4024 0.271s 0.000s
im_detect: 3370/4024 0.271s 0.000s
im_detect: 3371/4024 0.271s 0.000s
im_detect: 3372/4024 0.271s 0.000s
im_detect: 3373/4024 0.271s 0.000s
im_detect: 3374/4024 0.271s 0.000s
im_detect: 3375/4024 0.271s 0.000s
im_detect: 3376/4024 0.271s 0.000s
im_detect: 3377/4024 0.271s 0.000s
im_detect: 3378/4024 0.271s 0.000s
im_detect: 3379/4024 0.271s 0.000s
im_detect: 3380/4024 0.271s 0.000s
im_detect: 3381/4024 0.271s 0.000s
im_detect: 3382/4024 0.271s 0.000s
im_detect: 3383/4024 0.271s 0.000s
im_detect: 3384/4024 0.271s 0.000s
im_detect: 3385/4024 0.271s 0.000s
im_detect: 3386/4024 0.271s 0.000s
im_detect: 3387/4024 0.271s 0.000s
im_detect: 3388/4024 0.271s 0.000s
im_detect: 3389/4024 0.271s 0.000s
im_detect: 3390/4024 0.271s 0.000s
im_detect: 3391/4024 0.271s 0.000s
im_detect: 3392/4024 0.271s 0.000s
im_detect: 3393/4024 0.271s 0.000s
im_detect: 3394/4024 0.271s 0.000s
im_detect: 3395/4024 0.271s 0.000s
im_detect: 3396/4024 0.271s 0.000s
im_detect: 3397/4024 0.271s 0.000s
im_detect: 3398/4024 0.271s 0.000s
im_detect: 3399/4024 0.271s 0.000s
im_detect: 3400/4024 0.271s 0.000s
im_detect: 3401/4024 0.271s 0.000s
im_detect: 3402/4024 0.271s 0.000s
im_detect: 3403/4024 0.271s 0.000s
im_detect: 3404/4024 0.271s 0.000s
im_detect: 3405/4024 0.271s 0.000s
im_detect: 3406/4024 0.271s 0.000s
im_detect: 3407/4024 0.271s 0.000s
im_detect: 3408/4024 0.271s 0.000s
im_detect: 3409/4024 0.271s 0.000s
im_detect: 3410/4024 0.271s 0.000s
im_detect: 3411/4024 0.271s 0.000s
im_detect: 3412/4024 0.271s 0.000s
im_detect: 3413/4024 0.271s 0.000s
im_detect: 3414/4024 0.271s 0.000s
im_detect: 3415/4024 0.271s 0.000s
im_detect: 3416/4024 0.271s 0.000s
im_detect: 3417/4024 0.271s 0.000s
im_detect: 3418/4024 0.271s 0.000s
im_detect: 3419/4024 0.271s 0.000s
im_detect: 3420/4024 0.271s 0.000s
im_detect: 3421/4024 0.271s 0.000s
im_detect: 3422/4024 0.271s 0.000s
im_detect: 3423/4024 0.271s 0.000s
im_detect: 3424/4024 0.271s 0.000s
im_detect: 3425/4024 0.271s 0.000s
im_detect: 3426/4024 0.271s 0.000s
im_detect: 3427/4024 0.271s 0.000s
im_detect: 3428/4024 0.271s 0.000s
im_detect: 3429/4024 0.271s 0.000s
im_detect: 3430/4024 0.271s 0.000s
im_detect: 3431/4024 0.271s 0.000s
im_detect: 3432/4024 0.271s 0.000s
im_detect: 3433/4024 0.271s 0.000s
im_detect: 3434/4024 0.271s 0.000s
im_detect: 3435/4024 0.271s 0.000s
im_detect: 3436/4024 0.271s 0.000s
im_detect: 3437/4024 0.271s 0.000s
im_detect: 3438/4024 0.271s 0.000s
im_detect: 3439/4024 0.271s 0.000s
im_detect: 3440/4024 0.271s 0.000s
im_detect: 3441/4024 0.271s 0.000s
im_detect: 3442/4024 0.271s 0.000s
im_detect: 3443/4024 0.271s 0.000s
im_detect: 3444/4024 0.271s 0.000s
im_detect: 3445/4024 0.271s 0.000s
im_detect: 3446/4024 0.271s 0.000s
im_detect: 3447/4024 0.271s 0.000s
im_detect: 3448/4024 0.271s 0.000s
im_detect: 3449/4024 0.271s 0.000s
im_detect: 3450/4024 0.271s 0.000s
im_detect: 3451/4024 0.271s 0.000s
im_detect: 3452/4024 0.271s 0.000s
im_detect: 3453/4024 0.271s 0.000s
im_detect: 3454/4024 0.271s 0.000s
im_detect: 3455/4024 0.271s 0.000s
im_detect: 3456/4024 0.271s 0.000s
im_detect: 3457/4024 0.271s 0.000s
im_detect: 3458/4024 0.271s 0.000s
im_detect: 3459/4024 0.271s 0.000s
im_detect: 3460/4024 0.271s 0.000s
im_detect: 3461/4024 0.271s 0.000s
im_detect: 3462/4024 0.271s 0.000s
im_detect: 3463/4024 0.271s 0.000s
im_detect: 3464/4024 0.271s 0.000s
im_detect: 3465/4024 0.271s 0.000s
im_detect: 3466/4024 0.271s 0.000s
im_detect: 3467/4024 0.271s 0.000s
im_detect: 3468/4024 0.271s 0.000s
im_detect: 3469/4024 0.271s 0.000s
im_detect: 3470/4024 0.271s 0.000s
im_detect: 3471/4024 0.271s 0.000s
im_detect: 3472/4024 0.271s 0.000s
im_detect: 3473/4024 0.271s 0.000s
im_detect: 3474/4024 0.271s 0.000s
im_detect: 3475/4024 0.271s 0.000s
im_detect: 3476/4024 0.271s 0.000s
im_detect: 3477/4024 0.271s 0.000s
im_detect: 3478/4024 0.271s 0.000s
im_detect: 3479/4024 0.271s 0.000s
im_detect: 3480/4024 0.271s 0.000s
im_detect: 3481/4024 0.271s 0.000s
im_detect: 3482/4024 0.271s 0.000s
im_detect: 3483/4024 0.271s 0.000s
im_detect: 3484/4024 0.271s 0.000s
im_detect: 3485/4024 0.271s 0.000s
im_detect: 3486/4024 0.271s 0.000s
im_detect: 3487/4024 0.271s 0.000s
im_detect: 3488/4024 0.271s 0.000s
im_detect: 3489/4024 0.271s 0.000s
im_detect: 3490/4024 0.271s 0.000s
im_detect: 3491/4024 0.271s 0.000s
im_detect: 3492/4024 0.271s 0.000s
im_detect: 3493/4024 0.271s 0.000s
im_detect: 3494/4024 0.271s 0.000s
im_detect: 3495/4024 0.271s 0.000s
im_detect: 3496/4024 0.271s 0.000s
im_detect: 3497/4024 0.271s 0.000s
im_detect: 3498/4024 0.271s 0.000s
im_detect: 3499/4024 0.271s 0.000s
im_detect: 3500/4024 0.271s 0.000s
im_detect: 3501/4024 0.271s 0.000s
im_detect: 3502/4024 0.271s 0.000s
im_detect: 3503/4024 0.271s 0.000s
im_detect: 3504/4024 0.271s 0.000s
im_detect: 3505/4024 0.271s 0.000s
im_detect: 3506/4024 0.271s 0.000s
im_detect: 3507/4024 0.271s 0.000s
im_detect: 3508/4024 0.271s 0.000s
im_detect: 3509/4024 0.271s 0.000s
im_detect: 3510/4024 0.271s 0.000s
im_detect: 3511/4024 0.271s 0.000s
im_detect: 3512/4024 0.271s 0.000s
im_detect: 3513/4024 0.271s 0.000s
im_detect: 3514/4024 0.271s 0.000s
im_detect: 3515/4024 0.271s 0.000s
im_detect: 3516/4024 0.271s 0.000s
im_detect: 3517/4024 0.271s 0.000s
im_detect: 3518/4024 0.271s 0.000s
im_detect: 3519/4024 0.271s 0.000s
im_detect: 3520/4024 0.271s 0.000s
im_detect: 3521/4024 0.271s 0.000s
im_detect: 3522/4024 0.271s 0.000s
im_detect: 3523/4024 0.271s 0.000s
im_detect: 3524/4024 0.271s 0.000s
im_detect: 3525/4024 0.271s 0.000s
im_detect: 3526/4024 0.271s 0.000s
im_detect: 3527/4024 0.271s 0.000s
im_detect: 3528/4024 0.271s 0.000s
im_detect: 3529/4024 0.271s 0.000s
im_detect: 3530/4024 0.271s 0.000s
im_detect: 3531/4024 0.271s 0.000s
im_detect: 3532/4024 0.271s 0.000s
im_detect: 3533/4024 0.271s 0.000s
im_detect: 3534/4024 0.271s 0.000s
im_detect: 3535/4024 0.271s 0.000s
im_detect: 3536/4024 0.271s 0.000s
im_detect: 3537/4024 0.271s 0.000s
im_detect: 3538/4024 0.271s 0.000s
im_detect: 3539/4024 0.271s 0.000s
im_detect: 3540/4024 0.271s 0.000s
im_detect: 3541/4024 0.271s 0.000s
im_detect: 3542/4024 0.271s 0.000s
im_detect: 3543/4024 0.271s 0.000s
im_detect: 3544/4024 0.271s 0.000s
im_detect: 3545/4024 0.271s 0.000s
im_detect: 3546/4024 0.271s 0.000s
im_detect: 3547/4024 0.271s 0.000s
im_detect: 3548/4024 0.271s 0.000s
im_detect: 3549/4024 0.271s 0.000s
im_detect: 3550/4024 0.271s 0.000s
im_detect: 3551/4024 0.271s 0.000s
im_detect: 3552/4024 0.271s 0.000s
im_detect: 3553/4024 0.271s 0.000s
im_detect: 3554/4024 0.271s 0.000s
im_detect: 3555/4024 0.271s 0.000s
im_detect: 3556/4024 0.271s 0.000s
im_detect: 3557/4024 0.271s 0.000s
im_detect: 3558/4024 0.271s 0.000s
im_detect: 3559/4024 0.271s 0.000s
im_detect: 3560/4024 0.271s 0.000s
im_detect: 3561/4024 0.271s 0.000s
im_detect: 3562/4024 0.271s 0.000s
im_detect: 3563/4024 0.271s 0.000s
im_detect: 3564/4024 0.271s 0.000s
im_detect: 3565/4024 0.271s 0.000s
im_detect: 3566/4024 0.271s 0.000s
im_detect: 3567/4024 0.271s 0.000s
im_detect: 3568/4024 0.271s 0.000s
im_detect: 3569/4024 0.271s 0.000s
im_detect: 3570/4024 0.271s 0.000s
im_detect: 3571/4024 0.271s 0.000s
im_detect: 3572/4024 0.271s 0.000s
im_detect: 3573/4024 0.271s 0.000s
im_detect: 3574/4024 0.271s 0.000s
im_detect: 3575/4024 0.271s 0.000s
im_detect: 3576/4024 0.271s 0.000s
im_detect: 3577/4024 0.271s 0.000s
im_detect: 3578/4024 0.271s 0.000s
im_detect: 3579/4024 0.271s 0.000s
im_detect: 3580/4024 0.271s 0.000s
im_detect: 3581/4024 0.271s 0.000s
im_detect: 3582/4024 0.271s 0.000s
im_detect: 3583/4024 0.271s 0.000s
im_detect: 3584/4024 0.271s 0.000s
im_detect: 3585/4024 0.271s 0.000s
im_detect: 3586/4024 0.271s 0.000s
im_detect: 3587/4024 0.271s 0.000s
im_detect: 3588/4024 0.271s 0.000s
im_detect: 3589/4024 0.271s 0.000s
im_detect: 3590/4024 0.271s 0.000s
im_detect: 3591/4024 0.271s 0.000s
im_detect: 3592/4024 0.271s 0.000s
im_detect: 3593/4024 0.271s 0.000s
im_detect: 3594/4024 0.271s 0.000s
im_detect: 3595/4024 0.271s 0.000s
im_detect: 3596/4024 0.271s 0.000s
im_detect: 3597/4024 0.271s 0.000s
im_detect: 3598/4024 0.271s 0.000s
im_detect: 3599/4024 0.271s 0.000s
im_detect: 3600/4024 0.271s 0.000s
im_detect: 3601/4024 0.271s 0.000s
im_detect: 3602/4024 0.271s 0.000s
im_detect: 3603/4024 0.271s 0.000s
im_detect: 3604/4024 0.271s 0.000s
im_detect: 3605/4024 0.271s 0.000s
im_detect: 3606/4024 0.271s 0.000s
im_detect: 3607/4024 0.271s 0.000s
im_detect: 3608/4024 0.271s 0.000s
im_detect: 3609/4024 0.271s 0.000s
im_detect: 3610/4024 0.271s 0.000s
im_detect: 3611/4024 0.271s 0.000s
im_detect: 3612/4024 0.271s 0.000s
im_detect: 3613/4024 0.271s 0.000s
im_detect: 3614/4024 0.271s 0.000s
im_detect: 3615/4024 0.271s 0.000s
im_detect: 3616/4024 0.271s 0.000s
im_detect: 3617/4024 0.271s 0.000s
im_detect: 3618/4024 0.271s 0.000s
im_detect: 3619/4024 0.271s 0.000s
im_detect: 3620/4024 0.271s 0.000s
im_detect: 3621/4024 0.271s 0.000s
im_detect: 3622/4024 0.271s 0.000s
im_detect: 3623/4024 0.271s 0.000s
im_detect: 3624/4024 0.271s 0.000s
im_detect: 3625/4024 0.271s 0.000s
im_detect: 3626/4024 0.271s 0.000s
im_detect: 3627/4024 0.271s 0.000s
im_detect: 3628/4024 0.271s 0.000s
im_detect: 3629/4024 0.271s 0.000s
im_detect: 3630/4024 0.271s 0.000s
im_detect: 3631/4024 0.271s 0.000s
im_detect: 3632/4024 0.271s 0.000s
im_detect: 3633/4024 0.271s 0.000s
im_detect: 3634/4024 0.271s 0.000s
im_detect: 3635/4024 0.271s 0.000s
im_detect: 3636/4024 0.271s 0.000s
im_detect: 3637/4024 0.271s 0.000s
im_detect: 3638/4024 0.271s 0.000s
im_detect: 3639/4024 0.271s 0.000s
im_detect: 3640/4024 0.271s 0.000s
im_detect: 3641/4024 0.271s 0.000s
im_detect: 3642/4024 0.271s 0.000s
im_detect: 3643/4024 0.271s 0.000s
im_detect: 3644/4024 0.271s 0.000s
im_detect: 3645/4024 0.271s 0.000s
im_detect: 3646/4024 0.271s 0.000s
im_detect: 3647/4024 0.271s 0.000s
im_detect: 3648/4024 0.271s 0.000s
im_detect: 3649/4024 0.271s 0.000s
im_detect: 3650/4024 0.271s 0.000s
im_detect: 3651/4024 0.271s 0.000s
im_detect: 3652/4024 0.271s 0.000s
im_detect: 3653/4024 0.271s 0.000s
im_detect: 3654/4024 0.271s 0.000s
im_detect: 3655/4024 0.271s 0.000s
im_detect: 3656/4024 0.271s 0.000s
im_detect: 3657/4024 0.271s 0.000s
im_detect: 3658/4024 0.271s 0.000s
im_detect: 3659/4024 0.271s 0.000s
im_detect: 3660/4024 0.271s 0.000s
im_detect: 3661/4024 0.271s 0.000s
im_detect: 3662/4024 0.271s 0.000s
im_detect: 3663/4024 0.271s 0.000s
im_detect: 3664/4024 0.271s 0.000s
im_detect: 3665/4024 0.271s 0.000s
im_detect: 3666/4024 0.271s 0.000s
im_detect: 3667/4024 0.271s 0.000s
im_detect: 3668/4024 0.271s 0.000s
im_detect: 3669/4024 0.271s 0.000s
im_detect: 3670/4024 0.271s 0.000s
im_detect: 3671/4024 0.271s 0.000s
im_detect: 3672/4024 0.271s 0.000s
im_detect: 3673/4024 0.271s 0.000s
im_detect: 3674/4024 0.271s 0.000s
im_detect: 3675/4024 0.271s 0.000s
im_detect: 3676/4024 0.271s 0.000s
im_detect: 3677/4024 0.271s 0.000s
im_detect: 3678/4024 0.271s 0.000s
im_detect: 3679/4024 0.271s 0.000s
im_detect: 3680/4024 0.271s 0.000s
im_detect: 3681/4024 0.271s 0.000s
im_detect: 3682/4024 0.271s 0.000s
im_detect: 3683/4024 0.271s 0.000s
im_detect: 3684/4024 0.271s 0.000s
im_detect: 3685/4024 0.271s 0.000s
im_detect: 3686/4024 0.271s 0.000s
im_detect: 3687/4024 0.271s 0.000s
im_detect: 3688/4024 0.271s 0.000s
im_detect: 3689/4024 0.271s 0.000s
im_detect: 3690/4024 0.271s 0.000s
im_detect: 3691/4024 0.271s 0.000s
im_detect: 3692/4024 0.271s 0.000s
im_detect: 3693/4024 0.271s 0.000s
im_detect: 3694/4024 0.271s 0.000s
im_detect: 3695/4024 0.271s 0.000s
im_detect: 3696/4024 0.271s 0.000s
im_detect: 3697/4024 0.271s 0.000s
im_detect: 3698/4024 0.271s 0.000s
im_detect: 3699/4024 0.271s 0.000s
im_detect: 3700/4024 0.271s 0.000s
im_detect: 3701/4024 0.271s 0.000s
im_detect: 3702/4024 0.271s 0.000s
im_detect: 3703/4024 0.271s 0.000s
im_detect: 3704/4024 0.271s 0.000s
im_detect: 3705/4024 0.271s 0.000s
im_detect: 3706/4024 0.271s 0.000s
im_detect: 3707/4024 0.271s 0.000s
im_detect: 3708/4024 0.271s 0.000s
im_detect: 3709/4024 0.271s 0.000s
im_detect: 3710/4024 0.271s 0.000s
im_detect: 3711/4024 0.271s 0.000s
im_detect: 3712/4024 0.271s 0.000s
im_detect: 3713/4024 0.271s 0.000s
im_detect: 3714/4024 0.271s 0.000s
im_detect: 3715/4024 0.271s 0.000s
im_detect: 3716/4024 0.271s 0.000s
im_detect: 3717/4024 0.271s 0.000s
im_detect: 3718/4024 0.271s 0.000s
im_detect: 3719/4024 0.271s 0.000s
im_detect: 3720/4024 0.271s 0.000s
im_detect: 3721/4024 0.271s 0.000s
im_detect: 3722/4024 0.271s 0.000s
im_detect: 3723/4024 0.271s 0.000s
im_detect: 3724/4024 0.271s 0.000s
im_detect: 3725/4024 0.271s 0.000s
im_detect: 3726/4024 0.271s 0.000s
im_detect: 3727/4024 0.271s 0.000s
im_detect: 3728/4024 0.271s 0.000s
im_detect: 3729/4024 0.271s 0.000s
im_detect: 3730/4024 0.271s 0.000s
im_detect: 3731/4024 0.271s 0.000s
im_detect: 3732/4024 0.271s 0.000s
im_detect: 3733/4024 0.271s 0.000s
im_detect: 3734/4024 0.271s 0.000s
im_detect: 3735/4024 0.271s 0.000s
im_detect: 3736/4024 0.271s 0.000s
im_detect: 3737/4024 0.271s 0.000s
im_detect: 3738/4024 0.271s 0.000s
im_detect: 3739/4024 0.271s 0.000s
im_detect: 3740/4024 0.271s 0.000s
im_detect: 3741/4024 0.271s 0.000s
im_detect: 3742/4024 0.271s 0.000s
im_detect: 3743/4024 0.271s 0.000s
im_detect: 3744/4024 0.271s 0.000s
im_detect: 3745/4024 0.271s 0.000s
im_detect: 3746/4024 0.271s 0.000s
im_detect: 3747/4024 0.271s 0.000s
im_detect: 3748/4024 0.271s 0.000s
im_detect: 3749/4024 0.271s 0.000s
im_detect: 3750/4024 0.271s 0.000s
im_detect: 3751/4024 0.271s 0.000s
im_detect: 3752/4024 0.271s 0.000s
im_detect: 3753/4024 0.271s 0.000s
im_detect: 3754/4024 0.271s 0.000s
im_detect: 3755/4024 0.271s 0.000s
im_detect: 3756/4024 0.271s 0.000s
im_detect: 3757/4024 0.271s 0.000s
im_detect: 3758/4024 0.271s 0.000s
im_detect: 3759/4024 0.271s 0.000s
im_detect: 3760/4024 0.271s 0.000s
im_detect: 3761/4024 0.271s 0.000s
im_detect: 3762/4024 0.271s 0.000s
im_detect: 3763/4024 0.271s 0.000s
im_detect: 3764/4024 0.271s 0.000s
im_detect: 3765/4024 0.271s 0.000s
im_detect: 3766/4024 0.271s 0.000s
im_detect: 3767/4024 0.271s 0.000s
im_detect: 3768/4024 0.271s 0.000s
im_detect: 3769/4024 0.271s 0.000s
im_detect: 3770/4024 0.271s 0.000s
im_detect: 3771/4024 0.271s 0.000s
im_detect: 3772/4024 0.271s 0.000s
im_detect: 3773/4024 0.271s 0.000s
im_detect: 3774/4024 0.271s 0.000s
im_detect: 3775/4024 0.271s 0.000s
im_detect: 3776/4024 0.271s 0.000s
im_detect: 3777/4024 0.271s 0.000s
im_detect: 3778/4024 0.271s 0.000s
im_detect: 3779/4024 0.271s 0.000s
im_detect: 3780/4024 0.271s 0.000s
im_detect: 3781/4024 0.271s 0.000s
im_detect: 3782/4024 0.271s 0.000s
im_detect: 3783/4024 0.271s 0.000s
im_detect: 3784/4024 0.271s 0.000s
im_detect: 3785/4024 0.271s 0.000s
im_detect: 3786/4024 0.271s 0.000s
im_detect: 3787/4024 0.271s 0.000s
im_detect: 3788/4024 0.271s 0.000s
im_detect: 3789/4024 0.271s 0.000s
im_detect: 3790/4024 0.271s 0.000s
im_detect: 3791/4024 0.271s 0.000s
im_detect: 3792/4024 0.271s 0.000s
im_detect: 3793/4024 0.271s 0.000s
im_detect: 3794/4024 0.271s 0.000s
im_detect: 3795/4024 0.271s 0.000s
im_detect: 3796/4024 0.271s 0.000s
im_detect: 3797/4024 0.271s 0.000s
im_detect: 3798/4024 0.271s 0.000s
im_detect: 3799/4024 0.271s 0.000s
im_detect: 3800/4024 0.271s 0.000s
im_detect: 3801/4024 0.271s 0.000s
im_detect: 3802/4024 0.271s 0.000s
im_detect: 3803/4024 0.271s 0.000s
im_detect: 3804/4024 0.271s 0.000s
im_detect: 3805/4024 0.271s 0.000s
im_detect: 3806/4024 0.271s 0.000s
im_detect: 3807/4024 0.271s 0.000s
im_detect: 3808/4024 0.271s 0.000s
im_detect: 3809/4024 0.271s 0.000s
im_detect: 3810/4024 0.271s 0.000s
im_detect: 3811/4024 0.271s 0.000s
im_detect: 3812/4024 0.271s 0.000s
im_detect: 3813/4024 0.271s 0.000s
im_detect: 3814/4024 0.271s 0.000s
im_detect: 3815/4024 0.271s 0.000s
im_detect: 3816/4024 0.271s 0.000s
im_detect: 3817/4024 0.271s 0.000s
im_detect: 3818/4024 0.271s 0.000s
im_detect: 3819/4024 0.271s 0.000s
im_detect: 3820/4024 0.271s 0.000s
im_detect: 3821/4024 0.271s 0.000s
im_detect: 3822/4024 0.271s 0.000s
im_detect: 3823/4024 0.271s 0.000s
im_detect: 3824/4024 0.271s 0.000s
im_detect: 3825/4024 0.271s 0.000s
im_detect: 3826/4024 0.271s 0.000s
im_detect: 3827/4024 0.271s 0.000s
im_detect: 3828/4024 0.271s 0.000s
im_detect: 3829/4024 0.271s 0.000s
im_detect: 3830/4024 0.271s 0.000s
im_detect: 3831/4024 0.271s 0.000s
im_detect: 3832/4024 0.271s 0.000s
im_detect: 3833/4024 0.271s 0.000s
im_detect: 3834/4024 0.271s 0.000s
im_detect: 3835/4024 0.271s 0.000s
im_detect: 3836/4024 0.271s 0.000s
im_detect: 3837/4024 0.271s 0.000s
im_detect: 3838/4024 0.271s 0.000s
im_detect: 3839/4024 0.271s 0.000s
im_detect: 3840/4024 0.271s 0.000s
im_detect: 3841/4024 0.271s 0.000s
im_detect: 3842/4024 0.271s 0.000s
im_detect: 3843/4024 0.271s 0.000s
im_detect: 3844/4024 0.271s 0.000s
im_detect: 3845/4024 0.271s 0.000s
im_detect: 3846/4024 0.271s 0.000s
im_detect: 3847/4024 0.271s 0.000s
im_detect: 3848/4024 0.271s 0.000s
im_detect: 3849/4024 0.271s 0.000s
im_detect: 3850/4024 0.271s 0.000s
im_detect: 3851/4024 0.271s 0.000s
im_detect: 3852/4024 0.271s 0.000s
im_detect: 3853/4024 0.271s 0.000s
im_detect: 3854/4024 0.271s 0.000s
im_detect: 3855/4024 0.271s 0.000s
im_detect: 3856/4024 0.271s 0.000s
im_detect: 3857/4024 0.271s 0.000s
im_detect: 3858/4024 0.271s 0.000s
im_detect: 3859/4024 0.271s 0.000s
im_detect: 3860/4024 0.271s 0.000s
im_detect: 3861/4024 0.271s 0.000s
im_detect: 3862/4024 0.271s 0.000s
im_detect: 3863/4024 0.271s 0.000s
im_detect: 3864/4024 0.271s 0.000s
im_detect: 3865/4024 0.271s 0.000s
im_detect: 3866/4024 0.271s 0.000s
im_detect: 3867/4024 0.271s 0.000s
im_detect: 3868/4024 0.271s 0.000s
im_detect: 3869/4024 0.271s 0.000s
im_detect: 3870/4024 0.271s 0.000s
im_detect: 3871/4024 0.271s 0.000s
im_detect: 3872/4024 0.271s 0.000s
im_detect: 3873/4024 0.271s 0.000s
im_detect: 3874/4024 0.271s 0.000s
im_detect: 3875/4024 0.271s 0.000s
im_detect: 3876/4024 0.271s 0.000s
im_detect: 3877/4024 0.271s 0.000s
im_detect: 3878/4024 0.271s 0.000s
im_detect: 3879/4024 0.271s 0.000s
im_detect: 3880/4024 0.271s 0.000s
im_detect: 3881/4024 0.271s 0.000s
im_detect: 3882/4024 0.271s 0.000s
im_detect: 3883/4024 0.271s 0.000s
im_detect: 3884/4024 0.271s 0.000s
im_detect: 3885/4024 0.271s 0.000s
im_detect: 3886/4024 0.271s 0.000s
im_detect: 3887/4024 0.271s 0.000s
im_detect: 3888/4024 0.271s 0.000s
im_detect: 3889/4024 0.271s 0.000s
im_detect: 3890/4024 0.271s 0.000s
im_detect: 3891/4024 0.271s 0.000s
im_detect: 3892/4024 0.271s 0.000s
im_detect: 3893/4024 0.271s 0.000s
im_detect: 3894/4024 0.271s 0.000s
im_detect: 3895/4024 0.271s 0.000s
im_detect: 3896/4024 0.271s 0.000s
im_detect: 3897/4024 0.271s 0.000s
im_detect: 3898/4024 0.271s 0.000s
im_detect: 3899/4024 0.271s 0.000s
im_detect: 3900/4024 0.271s 0.000s
im_detect: 3901/4024 0.271s 0.000s
im_detect: 3902/4024 0.271s 0.000s
im_detect: 3903/4024 0.271s 0.000s
im_detect: 3904/4024 0.271s 0.000s
im_detect: 3905/4024 0.271s 0.000s
im_detect: 3906/4024 0.271s 0.000s
im_detect: 3907/4024 0.271s 0.000s
im_detect: 3908/4024 0.271s 0.000s
im_detect: 3909/4024 0.271s 0.000s
im_detect: 3910/4024 0.271s 0.000s
im_detect: 3911/4024 0.271s 0.000s
im_detect: 3912/4024 0.271s 0.000s
im_detect: 3913/4024 0.271s 0.000s
im_detect: 3914/4024 0.271s 0.000s
im_detect: 3915/4024 0.271s 0.000s
im_detect: 3916/4024 0.271s 0.000s
im_detect: 3917/4024 0.271s 0.000s
im_detect: 3918/4024 0.271s 0.000s
im_detect: 3919/4024 0.271s 0.000s
im_detect: 3920/4024 0.271s 0.000s
im_detect: 3921/4024 0.271s 0.000s
im_detect: 3922/4024 0.271s 0.000s
im_detect: 3923/4024 0.271s 0.000s
im_detect: 3924/4024 0.271s 0.000s
im_detect: 3925/4024 0.271s 0.000s
im_detect: 3926/4024 0.271s 0.000s
im_detect: 3927/4024 0.271s 0.000s
im_detect: 3928/4024 0.271s 0.000s
im_detect: 3929/4024 0.271s 0.000s
im_detect: 3930/4024 0.271s 0.000s
im_detect: 3931/4024 0.271s 0.000s
im_detect: 3932/4024 0.271s 0.000s
im_detect: 3933/4024 0.271s 0.000s
im_detect: 3934/4024 0.271s 0.000s
im_detect: 3935/4024 0.271s 0.000s
im_detect: 3936/4024 0.271s 0.000s
im_detect: 3937/4024 0.271s 0.000s
im_detect: 3938/4024 0.271s 0.000s
im_detect: 3939/4024 0.271s 0.000s
im_detect: 3940/4024 0.271s 0.000s
im_detect: 3941/4024 0.271s 0.000s
im_detect: 3942/4024 0.271s 0.000s
im_detect: 3943/4024 0.271s 0.000s
im_detect: 3944/4024 0.271s 0.000s
im_detect: 3945/4024 0.271s 0.000s
im_detect: 3946/4024 0.271s 0.000s
im_detect: 3947/4024 0.271s 0.000s
im_detect: 3948/4024 0.271s 0.000s
im_detect: 3949/4024 0.271s 0.000s
im_detect: 3950/4024 0.271s 0.000s
im_detect: 3951/4024 0.271s 0.000s
im_detect: 3952/4024 0.271s 0.000s
im_detect: 3953/4024 0.271s 0.000s
im_detect: 3954/4024 0.271s 0.000s
im_detect: 3955/4024 0.271s 0.000s
im_detect: 3956/4024 0.271s 0.000s
im_detect: 3957/4024 0.271s 0.000s
im_detect: 3958/4024 0.271s 0.000s
im_detect: 3959/4024 0.271s 0.000s
im_detect: 3960/4024 0.271s 0.000s
im_detect: 3961/4024 0.271s 0.000s
im_detect: 3962/4024 0.271s 0.000s
im_detect: 3963/4024 0.271s 0.000s
im_detect: 3964/4024 0.271s 0.000s
im_detect: 3965/4024 0.271s 0.000s
im_detect: 3966/4024 0.271s 0.000s
im_detect: 3967/4024 0.271s 0.000s
im_detect: 3968/4024 0.271s 0.000s
im_detect: 3969/4024 0.271s 0.000s
im_detect: 3970/4024 0.271s 0.000s
im_detect: 3971/4024 0.271s 0.000s
im_detect: 3972/4024 0.271s 0.000s
im_detect: 3973/4024 0.271s 0.000s
im_detect: 3974/4024 0.271s 0.000s
im_detect: 3975/4024 0.271s 0.000s
im_detect: 3976/4024 0.271s 0.000s
im_detect: 3977/4024 0.271s 0.000s
im_detect: 3978/4024 0.271s 0.000s
im_detect: 3979/4024 0.271s 0.000s
im_detect: 3980/4024 0.271s 0.000s
im_detect: 3981/4024 0.271s 0.000s
im_detect: 3982/4024 0.271s 0.000s
im_detect: 3983/4024 0.271s 0.000s
im_detect: 3984/4024 0.271s 0.000s
im_detect: 3985/4024 0.271s 0.000s
im_detect: 3986/4024 0.271s 0.000s
im_detect: 3987/4024 0.271s 0.000s
im_detect: 3988/4024 0.271s 0.000s
im_detect: 3989/4024 0.271s 0.000s
im_detect: 3990/4024 0.271s 0.000s
im_detect: 3991/4024 0.271s 0.000s
im_detect: 3992/4024 0.271s 0.000s
im_detect: 3993/4024 0.271s 0.000s
im_detect: 3994/4024 0.271s 0.000s
im_detect: 3995/4024 0.271s 0.000s
im_detect: 3996/4024 0.271s 0.000s
im_detect: 3997/4024 0.271s 0.000s
im_detect: 3998/4024 0.271s 0.000s
im_detect: 3999/4024 0.271s 0.000s
im_detect: 4000/4024 0.271s 0.000s
im_detect: 4001/4024 0.271s 0.000s
im_detect: 4002/4024 0.271s 0.000s
im_detect: 4003/4024 0.271s 0.000s
im_detect: 4004/4024 0.271s 0.000s
im_detect: 4005/4024 0.271s 0.000s
im_detect: 4006/4024 0.271s 0.000s
im_detect: 4007/4024 0.271s 0.000s
im_detect: 4008/4024 0.271s 0.000s
im_detect: 4009/4024 0.271s 0.000s
im_detect: 4010/4024 0.271s 0.000s
im_detect: 4011/4024 0.271s 0.000s
im_detect: 4012/4024 0.271s 0.000s
im_detect: 4013/4024 0.271s 0.000s
im_detect: 4014/4024 0.271s 0.000s
im_detect: 4015/4024 0.271s 0.000s
im_detect: 4016/4024 0.271s 0.000s
im_detect: 4017/4024 0.271s 0.000s
im_detect: 4018/4024 0.271s 0.000s
im_detect: 4019/4024 0.271s 0.000s
im_detect: 4020/4024 0.271s 0.000s
im_detect: 4021/4024 0.271s 0.000s
im_detect: 4022/4024 0.271s 0.000s
im_detect: 4023/4024 0.271s 0.000s
im_detect: 4024/4024 0.271s 0.000s
Evaluating detections
Writing upper VOC results file
VOC07 metric? Yes
Traceback (most recent call last):
  File "./tools/test_net.py", line 95, in <module>
    test_net(net, imdb, max_per_image=args.max_per_image, vis=args.vis)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/fast_rcnn/test.py", line 318, in test_net
    imdb.evaluate_detections(all_boxes, output_dir)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/pascal_voc.py", line 330, in evaluate_detections
    self._do_python_eval(output_dir)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/pascal_voc.py", line 293, in _do_python_eval
    use_07_metric=use_07_metric)
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/voc_eval.py", line 110, in voc_eval
    recs[imagename] = parse_rec(annopath.format(imagename))
  File "/home/user/Disk1.8T/py-R-FCN/tools/../lib/datasets/voc_eval.py", line 14, in parse_rec
    tree = ET.parse(filename)
  File "/usr/lib/python2.7/xml/etree/ElementTree.py", line 1182, in parse
    tree.parse(source, parser)
  File "/usr/lib/python2.7/xml/etree/ElementTree.py", line 647, in parse
    source = open(source, "rb")
IOError: [Errno 2] No such file or directory: '/home/user/Disk1.8T/py-R-FCN/data/VOCdevkit0712/VOC0712/Annotations/set08_V003_I00689.xml'
