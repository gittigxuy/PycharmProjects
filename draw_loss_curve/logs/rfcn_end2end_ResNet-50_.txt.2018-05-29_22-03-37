+ echo Logging output to experiments/5_28_original/logs/rfcn_end2end_ResNet-50_.txt.2018-05-29_22-03-37
Logging output to experiments/5_28_original/logs/rfcn_end2end_ResNet-50_.txt.2018-05-29_22-03-37
+ ./tools/train_net.py --gpu 0 --solver experiments/5_28_original/solver_ohem.prototxt --weights data/imagenet_models/ResNet-50-model.caffemodel --imdb voc_0712_trainval --iters 32000 --cfg experiments/5_28_original/rfcn_end2end_ohem.yml
Called with args:
Namespace(cfg_file='experiments/5_28_original/rfcn_end2end_ohem.yml', gpu_id=0, imdb_name='voc_0712_trainval', max_iters=32000, pretrained_model='data/imagenet_models/ResNet-50-model.caffemodel', randomize=False, set_cfgs=None, solver='experiments/5_28_original/solver_ohem.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '5_28_original/model',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [640],
          'SOFT_NMS': 1,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [640],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_0712_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_0712_trainval gt roidb loaded from /home/user/Disk1.8T/py-R-FCN/data/cache/voc_0712_trainval_gt_roidb.pkl
done
Preparing training data...
done
44712 roidb entries
Output will be saved to `/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model`
Filtered 4858 roidb entries: 44712 -> 39854
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0529 22:03:46.334507 24924 solver.cpp:48] Initializing solver from parameters: 
train_net: "/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/train_agnostic_ohem.prototxt"
base_lr: 0.0002
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "resnet50_rfcn_ohem"
iter_size: 8
I0529 22:03:46.334553 24924 solver.cpp:81] Creating training net from train_net file: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/train_agnostic_ohem.prototxt
I0529 22:03:46.336557 24924 net.cpp:58] Initializing net from parameters: 
name: "ResNet-50"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "res4c_
I0529 22:03:46.338222 24924 layer_factory.hpp:77] Creating layer input-data
I0529 22:03:46.347692 24924 net.cpp:100] Creating Layer input-data
I0529 22:03:46.347713 24924 net.cpp:418] input-data -> data
I0529 22:03:46.347748 24924 net.cpp:418] input-data -> im_info
I0529 22:03:46.347764 24924 net.cpp:418] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'im_info': 1}
I0529 22:03:46.367921 24924 net.cpp:150] Setting up input-data
I0529 22:03:46.367944 24924 net.cpp:157] Top shape: 1 3 640 1280 (2457600)
I0529 22:03:46.367949 24924 net.cpp:157] Top shape: 1 3 (3)
I0529 22:03:46.367951 24924 net.cpp:157] Top shape: 1 4 (4)
I0529 22:03:46.367952 24924 net.cpp:165] Memory required for data: 9830428
I0529 22:03:46.367967 24924 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0529 22:03:46.367995 24924 net.cpp:100] Creating Layer data_input-data_0_split
I0529 22:03:46.368003 24924 net.cpp:444] data_input-data_0_split <- data
I0529 22:03:46.368019 24924 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_0
I0529 22:03:46.368039 24924 net.cpp:418] data_input-data_0_split -> data_input-data_0_split_1
I0529 22:03:46.368072 24924 net.cpp:150] Setting up data_input-data_0_split
I0529 22:03:46.368078 24924 net.cpp:157] Top shape: 1 3 640 1280 (2457600)
I0529 22:03:46.368083 24924 net.cpp:157] Top shape: 1 3 640 1280 (2457600)
I0529 22:03:46.368084 24924 net.cpp:165] Memory required for data: 29491228
I0529 22:03:46.368086 24924 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0529 22:03:46.368095 24924 net.cpp:100] Creating Layer im_info_input-data_1_split
I0529 22:03:46.368099 24924 net.cpp:444] im_info_input-data_1_split <- im_info
I0529 22:03:46.368108 24924 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0529 22:03:46.368119 24924 net.cpp:418] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0529 22:03:46.368142 24924 net.cpp:150] Setting up im_info_input-data_1_split
I0529 22:03:46.368149 24924 net.cpp:157] Top shape: 1 3 (3)
I0529 22:03:46.368151 24924 net.cpp:157] Top shape: 1 3 (3)
I0529 22:03:46.368152 24924 net.cpp:165] Memory required for data: 29491252
I0529 22:03:46.368155 24924 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0529 22:03:46.368161 24924 net.cpp:100] Creating Layer gt_boxes_input-data_2_split
I0529 22:03:46.368165 24924 net.cpp:444] gt_boxes_input-data_2_split <- gt_boxes
I0529 22:03:46.368173 24924 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0529 22:03:46.368182 24924 net.cpp:418] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0529 22:03:46.368209 24924 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0529 22:03:46.368216 24924 net.cpp:157] Top shape: 1 4 (4)
I0529 22:03:46.368219 24924 net.cpp:157] Top shape: 1 4 (4)
I0529 22:03:46.368221 24924 net.cpp:165] Memory required for data: 29491284
I0529 22:03:46.368223 24924 layer_factory.hpp:77] Creating layer conv1
I0529 22:03:46.368242 24924 net.cpp:100] Creating Layer conv1
I0529 22:03:46.368247 24924 net.cpp:444] conv1 <- data_input-data_0_split_0
I0529 22:03:46.368257 24924 net.cpp:418] conv1 -> conv1
I0529 22:03:46.658150 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3686424
I0529 22:03:46.658372 24924 net.cpp:150] Setting up conv1
I0529 22:03:46.658403 24924 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0529 22:03:46.658406 24924 net.cpp:165] Memory required for data: 81920084
I0529 22:03:46.658452 24924 layer_factory.hpp:77] Creating layer bn_conv1
I0529 22:03:46.658479 24924 net.cpp:100] Creating Layer bn_conv1
I0529 22:03:46.658488 24924 net.cpp:444] bn_conv1 <- conv1
I0529 22:03:46.658499 24924 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0529 22:03:46.658905 24924 net.cpp:150] Setting up bn_conv1
I0529 22:03:46.658910 24924 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0529 22:03:46.658926 24924 net.cpp:165] Memory required for data: 134348884
I0529 22:03:46.658948 24924 layer_factory.hpp:77] Creating layer scale_conv1
I0529 22:03:46.658962 24924 net.cpp:100] Creating Layer scale_conv1
I0529 22:03:46.658967 24924 net.cpp:444] scale_conv1 <- conv1
I0529 22:03:46.658974 24924 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0529 22:03:46.659015 24924 layer_factory.hpp:77] Creating layer scale_conv1
I0529 22:03:46.660130 24924 net.cpp:150] Setting up scale_conv1
I0529 22:03:46.660138 24924 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0529 22:03:46.660140 24924 net.cpp:165] Memory required for data: 186777684
I0529 22:03:46.660151 24924 layer_factory.hpp:77] Creating layer conv1_relu
I0529 22:03:46.660162 24924 net.cpp:100] Creating Layer conv1_relu
I0529 22:03:46.660167 24924 net.cpp:444] conv1_relu <- conv1
I0529 22:03:46.660177 24924 net.cpp:405] conv1_relu -> conv1 (in-place)
I0529 22:03:46.660320 24924 net.cpp:150] Setting up conv1_relu
I0529 22:03:46.660326 24924 net.cpp:157] Top shape: 1 64 320 640 (13107200)
I0529 22:03:46.660328 24924 net.cpp:165] Memory required for data: 239206484
I0529 22:03:46.660332 24924 layer_factory.hpp:77] Creating layer pool1
I0529 22:03:46.660348 24924 net.cpp:100] Creating Layer pool1
I0529 22:03:46.660353 24924 net.cpp:444] pool1 <- conv1
I0529 22:03:46.660364 24924 net.cpp:418] pool1 -> pool1
I0529 22:03:46.660404 24924 net.cpp:150] Setting up pool1
I0529 22:03:46.660413 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.660414 24924 net.cpp:165] Memory required for data: 252313684
I0529 22:03:46.660418 24924 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0529 22:03:46.660426 24924 net.cpp:100] Creating Layer pool1_pool1_0_split
I0529 22:03:46.660429 24924 net.cpp:444] pool1_pool1_0_split <- pool1
I0529 22:03:46.660439 24924 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0529 22:03:46.660449 24924 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0529 22:03:46.660477 24924 net.cpp:150] Setting up pool1_pool1_0_split
I0529 22:03:46.660483 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.660486 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.660488 24924 net.cpp:165] Memory required for data: 278528084
I0529 22:03:46.660491 24924 layer_factory.hpp:77] Creating layer res2a_branch1
I0529 22:03:46.660503 24924 net.cpp:100] Creating Layer res2a_branch1
I0529 22:03:46.660508 24924 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0529 22:03:46.660518 24924 net.cpp:418] res2a_branch1 -> res2a_branch1
I0529 22:03:46.661231 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.661420 24924 net.cpp:150] Setting up res2a_branch1
I0529 22:03:46.661429 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.661432 24924 net.cpp:165] Memory required for data: 330956884
I0529 22:03:46.661442 24924 layer_factory.hpp:77] Creating layer bn2a_branch1
I0529 22:03:46.661453 24924 net.cpp:100] Creating Layer bn2a_branch1
I0529 22:03:46.661458 24924 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0529 22:03:46.661469 24924 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0529 22:03:46.662148 24924 net.cpp:150] Setting up bn2a_branch1
I0529 22:03:46.662156 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.662158 24924 net.cpp:165] Memory required for data: 383385684
I0529 22:03:46.662184 24924 layer_factory.hpp:77] Creating layer scale2a_branch1
I0529 22:03:46.662199 24924 net.cpp:100] Creating Layer scale2a_branch1
I0529 22:03:46.662204 24924 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0529 22:03:46.662212 24924 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0529 22:03:46.662253 24924 layer_factory.hpp:77] Creating layer scale2a_branch1
I0529 22:03:46.662470 24924 net.cpp:150] Setting up scale2a_branch1
I0529 22:03:46.662477 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.662478 24924 net.cpp:165] Memory required for data: 435814484
I0529 22:03:46.662487 24924 layer_factory.hpp:77] Creating layer res2a_branch2a
I0529 22:03:46.662499 24924 net.cpp:100] Creating Layer res2a_branch2a
I0529 22:03:46.662504 24924 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0529 22:03:46.662515 24924 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0529 22:03:46.663697 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.663714 24924 net.cpp:150] Setting up res2a_branch2a
I0529 22:03:46.663722 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.663723 24924 net.cpp:165] Memory required for data: 448921684
I0529 22:03:46.663733 24924 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0529 22:03:46.663744 24924 net.cpp:100] Creating Layer bn2a_branch2a
I0529 22:03:46.663749 24924 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0529 22:03:46.663759 24924 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0529 22:03:46.663959 24924 net.cpp:150] Setting up bn2a_branch2a
I0529 22:03:46.663964 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.663966 24924 net.cpp:165] Memory required for data: 462028884
I0529 22:03:46.663987 24924 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0529 22:03:46.664000 24924 net.cpp:100] Creating Layer scale2a_branch2a
I0529 22:03:46.664005 24924 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0529 22:03:46.664012 24924 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0529 22:03:46.664052 24924 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0529 22:03:46.664275 24924 net.cpp:150] Setting up scale2a_branch2a
I0529 22:03:46.664281 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.664283 24924 net.cpp:165] Memory required for data: 475136084
I0529 22:03:46.664291 24924 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0529 22:03:46.664305 24924 net.cpp:100] Creating Layer res2a_branch2a_relu
I0529 22:03:46.664310 24924 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0529 22:03:46.664319 24924 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0529 22:03:46.664439 24924 net.cpp:150] Setting up res2a_branch2a_relu
I0529 22:03:46.664444 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.664446 24924 net.cpp:165] Memory required for data: 488243284
I0529 22:03:46.664449 24924 layer_factory.hpp:77] Creating layer res2a_branch2b
I0529 22:03:46.664461 24924 net.cpp:100] Creating Layer res2a_branch2b
I0529 22:03:46.664466 24924 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0529 22:03:46.664477 24924 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0529 22:03:46.665197 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0529 22:03:46.665387 24924 net.cpp:150] Setting up res2a_branch2b
I0529 22:03:46.665396 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.665398 24924 net.cpp:165] Memory required for data: 501350484
I0529 22:03:46.665407 24924 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0529 22:03:46.665419 24924 net.cpp:100] Creating Layer bn2a_branch2b
I0529 22:03:46.665424 24924 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0529 22:03:46.665434 24924 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0529 22:03:46.665637 24924 net.cpp:150] Setting up bn2a_branch2b
I0529 22:03:46.665642 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.665645 24924 net.cpp:165] Memory required for data: 514457684
I0529 22:03:46.665658 24924 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0529 22:03:46.665668 24924 net.cpp:100] Creating Layer scale2a_branch2b
I0529 22:03:46.665673 24924 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0529 22:03:46.665683 24924 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0529 22:03:46.665721 24924 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0529 22:03:46.665946 24924 net.cpp:150] Setting up scale2a_branch2b
I0529 22:03:46.665951 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.665954 24924 net.cpp:165] Memory required for data: 527564884
I0529 22:03:46.665962 24924 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0529 22:03:46.665971 24924 net.cpp:100] Creating Layer res2a_branch2b_relu
I0529 22:03:46.665976 24924 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0529 22:03:46.665983 24924 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0529 22:03:46.666287 24924 net.cpp:150] Setting up res2a_branch2b_relu
I0529 22:03:46.666294 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.666296 24924 net.cpp:165] Memory required for data: 540672084
I0529 22:03:46.666301 24924 layer_factory.hpp:77] Creating layer res2a_branch2c
I0529 22:03:46.666312 24924 net.cpp:100] Creating Layer res2a_branch2c
I0529 22:03:46.666317 24924 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0529 22:03:46.666329 24924 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0529 22:03:46.667023 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.667035 24924 net.cpp:150] Setting up res2a_branch2c
I0529 22:03:46.667042 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.667044 24924 net.cpp:165] Memory required for data: 593100884
I0529 22:03:46.667053 24924 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0529 22:03:46.667064 24924 net.cpp:100] Creating Layer bn2a_branch2c
I0529 22:03:46.667069 24924 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0529 22:03:46.667079 24924 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0529 22:03:46.667778 24924 net.cpp:150] Setting up bn2a_branch2c
I0529 22:03:46.667785 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.667788 24924 net.cpp:165] Memory required for data: 645529684
I0529 22:03:46.667804 24924 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0529 22:03:46.667815 24924 net.cpp:100] Creating Layer scale2a_branch2c
I0529 22:03:46.667820 24924 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0529 22:03:46.667830 24924 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0529 22:03:46.667871 24924 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0529 22:03:46.668089 24924 net.cpp:150] Setting up scale2a_branch2c
I0529 22:03:46.668095 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.668098 24924 net.cpp:165] Memory required for data: 697958484
I0529 22:03:46.668107 24924 layer_factory.hpp:77] Creating layer res2a
I0529 22:03:46.668115 24924 net.cpp:100] Creating Layer res2a
I0529 22:03:46.668119 24924 net.cpp:444] res2a <- res2a_branch1
I0529 22:03:46.668126 24924 net.cpp:444] res2a <- res2a_branch2c
I0529 22:03:46.668133 24924 net.cpp:418] res2a -> res2a
I0529 22:03:46.668161 24924 net.cpp:150] Setting up res2a
I0529 22:03:46.668167 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.668170 24924 net.cpp:165] Memory required for data: 750387284
I0529 22:03:46.668172 24924 layer_factory.hpp:77] Creating layer res2a_relu
I0529 22:03:46.668180 24924 net.cpp:100] Creating Layer res2a_relu
I0529 22:03:46.668184 24924 net.cpp:444] res2a_relu <- res2a
I0529 22:03:46.668192 24924 net.cpp:405] res2a_relu -> res2a (in-place)
I0529 22:03:46.668318 24924 net.cpp:150] Setting up res2a_relu
I0529 22:03:46.668323 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.668325 24924 net.cpp:165] Memory required for data: 802816084
I0529 22:03:46.668329 24924 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0529 22:03:46.668336 24924 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0529 22:03:46.668341 24924 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0529 22:03:46.668350 24924 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0529 22:03:46.668361 24924 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0529 22:03:46.668392 24924 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0529 22:03:46.668400 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.668402 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.668403 24924 net.cpp:165] Memory required for data: 907673684
I0529 22:03:46.668406 24924 layer_factory.hpp:77] Creating layer res2b_branch2a
I0529 22:03:46.668417 24924 net.cpp:100] Creating Layer res2b_branch2a
I0529 22:03:46.668421 24924 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0529 22:03:46.668431 24924 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0529 22:03:46.669198 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.669399 24924 net.cpp:150] Setting up res2b_branch2a
I0529 22:03:46.669409 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.669411 24924 net.cpp:165] Memory required for data: 920780884
I0529 22:03:46.669421 24924 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0529 22:03:46.669435 24924 net.cpp:100] Creating Layer bn2b_branch2a
I0529 22:03:46.669440 24924 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0529 22:03:46.669451 24924 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0529 22:03:46.669662 24924 net.cpp:150] Setting up bn2b_branch2a
I0529 22:03:46.669668 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.669669 24924 net.cpp:165] Memory required for data: 933888084
I0529 22:03:46.669693 24924 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0529 22:03:46.669706 24924 net.cpp:100] Creating Layer scale2b_branch2a
I0529 22:03:46.669710 24924 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0529 22:03:46.669719 24924 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0529 22:03:46.669759 24924 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0529 22:03:46.669984 24924 net.cpp:150] Setting up scale2b_branch2a
I0529 22:03:46.669991 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.669993 24924 net.cpp:165] Memory required for data: 946995284
I0529 22:03:46.670001 24924 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0529 22:03:46.670009 24924 net.cpp:100] Creating Layer res2b_branch2a_relu
I0529 22:03:46.670014 24924 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0529 22:03:46.670022 24924 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0529 22:03:46.670150 24924 net.cpp:150] Setting up res2b_branch2a_relu
I0529 22:03:46.670156 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.670158 24924 net.cpp:165] Memory required for data: 960102484
I0529 22:03:46.670161 24924 layer_factory.hpp:77] Creating layer res2b_branch2b
I0529 22:03:46.670173 24924 net.cpp:100] Creating Layer res2b_branch2b
I0529 22:03:46.670178 24924 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0529 22:03:46.670189 24924 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0529 22:03:46.670927 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0529 22:03:46.670943 24924 net.cpp:150] Setting up res2b_branch2b
I0529 22:03:46.670949 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.670953 24924 net.cpp:165] Memory required for data: 973209684
I0529 22:03:46.670960 24924 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0529 22:03:46.670977 24924 net.cpp:100] Creating Layer bn2b_branch2b
I0529 22:03:46.670982 24924 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0529 22:03:46.670994 24924 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0529 22:03:46.671196 24924 net.cpp:150] Setting up bn2b_branch2b
I0529 22:03:46.671201 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.671203 24924 net.cpp:165] Memory required for data: 986316884
I0529 22:03:46.671216 24924 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0529 22:03:46.671227 24924 net.cpp:100] Creating Layer scale2b_branch2b
I0529 22:03:46.671232 24924 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0529 22:03:46.671241 24924 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0529 22:03:46.671280 24924 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0529 22:03:46.671507 24924 net.cpp:150] Setting up scale2b_branch2b
I0529 22:03:46.671514 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.671515 24924 net.cpp:165] Memory required for data: 999424084
I0529 22:03:46.671524 24924 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0529 22:03:46.671532 24924 net.cpp:100] Creating Layer res2b_branch2b_relu
I0529 22:03:46.671536 24924 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0529 22:03:46.671545 24924 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0529 22:03:46.671883 24924 net.cpp:150] Setting up res2b_branch2b_relu
I0529 22:03:46.671890 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.671892 24924 net.cpp:165] Memory required for data: 1012531284
I0529 22:03:46.671896 24924 layer_factory.hpp:77] Creating layer res2b_branch2c
I0529 22:03:46.671910 24924 net.cpp:100] Creating Layer res2b_branch2c
I0529 22:03:46.671916 24924 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0529 22:03:46.671926 24924 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0529 22:03:46.672652 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.672896 24924 net.cpp:150] Setting up res2b_branch2c
I0529 22:03:46.672907 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.672956 24924 net.cpp:165] Memory required for data: 1064960084
I0529 22:03:46.672969 24924 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0529 22:03:46.672983 24924 net.cpp:100] Creating Layer bn2b_branch2c
I0529 22:03:46.672988 24924 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0529 22:03:46.672999 24924 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0529 22:03:46.673734 24924 net.cpp:150] Setting up bn2b_branch2c
I0529 22:03:46.673743 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.673745 24924 net.cpp:165] Memory required for data: 1117388884
I0529 22:03:46.673763 24924 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0529 22:03:46.673775 24924 net.cpp:100] Creating Layer scale2b_branch2c
I0529 22:03:46.673780 24924 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0529 22:03:46.673790 24924 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0529 22:03:46.673833 24924 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0529 22:03:46.674054 24924 net.cpp:150] Setting up scale2b_branch2c
I0529 22:03:46.674060 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.674062 24924 net.cpp:165] Memory required for data: 1169817684
I0529 22:03:46.674070 24924 layer_factory.hpp:77] Creating layer res2b
I0529 22:03:46.674079 24924 net.cpp:100] Creating Layer res2b
I0529 22:03:46.674083 24924 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0529 22:03:46.674090 24924 net.cpp:444] res2b <- res2b_branch2c
I0529 22:03:46.674098 24924 net.cpp:418] res2b -> res2b
I0529 22:03:46.674125 24924 net.cpp:150] Setting up res2b
I0529 22:03:46.674132 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.674134 24924 net.cpp:165] Memory required for data: 1222246484
I0529 22:03:46.674137 24924 layer_factory.hpp:77] Creating layer res2b_relu
I0529 22:03:46.674144 24924 net.cpp:100] Creating Layer res2b_relu
I0529 22:03:46.674147 24924 net.cpp:444] res2b_relu <- res2b
I0529 22:03:46.674155 24924 net.cpp:405] res2b_relu -> res2b (in-place)
I0529 22:03:46.674293 24924 net.cpp:150] Setting up res2b_relu
I0529 22:03:46.674299 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.674299 24924 net.cpp:165] Memory required for data: 1274675284
I0529 22:03:46.674304 24924 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0529 22:03:46.674310 24924 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0529 22:03:46.674314 24924 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0529 22:03:46.674324 24924 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0529 22:03:46.674334 24924 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0529 22:03:46.674366 24924 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0529 22:03:46.674372 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.674376 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.674378 24924 net.cpp:165] Memory required for data: 1379532884
I0529 22:03:46.674381 24924 layer_factory.hpp:77] Creating layer res2c_branch2a
I0529 22:03:46.674392 24924 net.cpp:100] Creating Layer res2c_branch2a
I0529 22:03:46.674397 24924 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0529 22:03:46.674407 24924 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0529 22:03:46.675134 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.675151 24924 net.cpp:150] Setting up res2c_branch2a
I0529 22:03:46.675158 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.675160 24924 net.cpp:165] Memory required for data: 1392640084
I0529 22:03:46.675169 24924 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0529 22:03:46.675180 24924 net.cpp:100] Creating Layer bn2c_branch2a
I0529 22:03:46.675184 24924 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0529 22:03:46.675195 24924 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0529 22:03:46.675401 24924 net.cpp:150] Setting up bn2c_branch2a
I0529 22:03:46.675406 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.675408 24924 net.cpp:165] Memory required for data: 1405747284
I0529 22:03:46.675422 24924 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0529 22:03:46.675432 24924 net.cpp:100] Creating Layer scale2c_branch2a
I0529 22:03:46.675436 24924 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0529 22:03:46.675446 24924 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0529 22:03:46.675485 24924 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0529 22:03:46.675709 24924 net.cpp:150] Setting up scale2c_branch2a
I0529 22:03:46.675714 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.675716 24924 net.cpp:165] Memory required for data: 1418854484
I0529 22:03:46.675725 24924 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0529 22:03:46.675732 24924 net.cpp:100] Creating Layer res2c_branch2a_relu
I0529 22:03:46.675737 24924 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0529 22:03:46.675745 24924 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0529 22:03:46.675868 24924 net.cpp:150] Setting up res2c_branch2a_relu
I0529 22:03:46.675873 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.675875 24924 net.cpp:165] Memory required for data: 1431961684
I0529 22:03:46.675879 24924 layer_factory.hpp:77] Creating layer res2c_branch2b
I0529 22:03:46.675891 24924 net.cpp:100] Creating Layer res2c_branch2b
I0529 22:03:46.675895 24924 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0529 22:03:46.675906 24924 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0529 22:03:46.676635 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0529 22:03:46.676826 24924 net.cpp:150] Setting up res2c_branch2b
I0529 22:03:46.676834 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.676836 24924 net.cpp:165] Memory required for data: 1445068884
I0529 22:03:46.676846 24924 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0529 22:03:46.676856 24924 net.cpp:100] Creating Layer bn2c_branch2b
I0529 22:03:46.676861 24924 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0529 22:03:46.676870 24924 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0529 22:03:46.677084 24924 net.cpp:150] Setting up bn2c_branch2b
I0529 22:03:46.677090 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.677093 24924 net.cpp:165] Memory required for data: 1458176084
I0529 22:03:46.677105 24924 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0529 22:03:46.677115 24924 net.cpp:100] Creating Layer scale2c_branch2b
I0529 22:03:46.677119 24924 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0529 22:03:46.677127 24924 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0529 22:03:46.677167 24924 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0529 22:03:46.677394 24924 net.cpp:150] Setting up scale2c_branch2b
I0529 22:03:46.677400 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.677402 24924 net.cpp:165] Memory required for data: 1471283284
I0529 22:03:46.677412 24924 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0529 22:03:46.677419 24924 net.cpp:100] Creating Layer res2c_branch2b_relu
I0529 22:03:46.677423 24924 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0529 22:03:46.677433 24924 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0529 22:03:46.677561 24924 net.cpp:150] Setting up res2c_branch2b_relu
I0529 22:03:46.677565 24924 net.cpp:157] Top shape: 1 64 160 320 (3276800)
I0529 22:03:46.677568 24924 net.cpp:165] Memory required for data: 1484390484
I0529 22:03:46.677572 24924 layer_factory.hpp:77] Creating layer res2c_branch2c
I0529 22:03:46.677582 24924 net.cpp:100] Creating Layer res2c_branch2c
I0529 22:03:46.677587 24924 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0529 22:03:46.677598 24924 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0529 22:03:46.678310 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 928152
I0529 22:03:46.678323 24924 net.cpp:150] Setting up res2c_branch2c
I0529 22:03:46.678328 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.678330 24924 net.cpp:165] Memory required for data: 1536819284
I0529 22:03:46.678339 24924 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0529 22:03:46.678351 24924 net.cpp:100] Creating Layer bn2c_branch2c
I0529 22:03:46.678356 24924 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0529 22:03:46.678369 24924 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0529 22:03:46.679080 24924 net.cpp:150] Setting up bn2c_branch2c
I0529 22:03:46.679088 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.679090 24924 net.cpp:165] Memory required for data: 1589248084
I0529 22:03:46.679123 24924 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0529 22:03:46.679137 24924 net.cpp:100] Creating Layer scale2c_branch2c
I0529 22:03:46.679143 24924 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0529 22:03:46.679153 24924 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0529 22:03:46.679206 24924 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0529 22:03:46.679442 24924 net.cpp:150] Setting up scale2c_branch2c
I0529 22:03:46.679450 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.679451 24924 net.cpp:165] Memory required for data: 1641676884
I0529 22:03:46.679464 24924 layer_factory.hpp:77] Creating layer res2c
I0529 22:03:46.679476 24924 net.cpp:100] Creating Layer res2c
I0529 22:03:46.679482 24924 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0529 22:03:46.679493 24924 net.cpp:444] res2c <- res2c_branch2c
I0529 22:03:46.679503 24924 net.cpp:418] res2c -> res2c
I0529 22:03:46.679536 24924 net.cpp:150] Setting up res2c
I0529 22:03:46.679545 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.679548 24924 net.cpp:165] Memory required for data: 1694105684
I0529 22:03:46.679553 24924 layer_factory.hpp:77] Creating layer res2c_relu
I0529 22:03:46.679563 24924 net.cpp:100] Creating Layer res2c_relu
I0529 22:03:46.679569 24924 net.cpp:444] res2c_relu <- res2c
I0529 22:03:46.679581 24924 net.cpp:405] res2c_relu -> res2c (in-place)
I0529 22:03:46.679913 24924 net.cpp:150] Setting up res2c_relu
I0529 22:03:46.679920 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.679924 24924 net.cpp:165] Memory required for data: 1746534484
I0529 22:03:46.679929 24924 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0529 22:03:46.679940 24924 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0529 22:03:46.679947 24924 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0529 22:03:46.679961 24924 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0529 22:03:46.679977 24924 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0529 22:03:46.680019 24924 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0529 22:03:46.680027 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.680033 24924 net.cpp:157] Top shape: 1 256 160 320 (13107200)
I0529 22:03:46.680037 24924 net.cpp:165] Memory required for data: 1851392084
I0529 22:03:46.680040 24924 layer_factory.hpp:77] Creating layer res3a_branch1
I0529 22:03:46.680058 24924 net.cpp:100] Creating Layer res3a_branch1
I0529 22:03:46.680063 24924 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0529 22:03:46.680079 24924 net.cpp:418] res3a_branch1 -> res3a_branch1
I0529 22:03:46.681488 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 230424
I0529 22:03:46.681685 24924 net.cpp:150] Setting up res3a_branch1
I0529 22:03:46.681696 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.681700 24924 net.cpp:165] Memory required for data: 1877606484
I0529 22:03:46.681712 24924 layer_factory.hpp:77] Creating layer bn3a_branch1
I0529 22:03:46.681730 24924 net.cpp:100] Creating Layer bn3a_branch1
I0529 22:03:46.681735 24924 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0529 22:03:46.681751 24924 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0529 22:03:46.682410 24924 net.cpp:150] Setting up bn3a_branch1
I0529 22:03:46.682418 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.682421 24924 net.cpp:165] Memory required for data: 1903820884
I0529 22:03:46.682440 24924 layer_factory.hpp:77] Creating layer scale3a_branch1
I0529 22:03:46.682454 24924 net.cpp:100] Creating Layer scale3a_branch1
I0529 22:03:46.682461 24924 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0529 22:03:46.682476 24924 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0529 22:03:46.682521 24924 layer_factory.hpp:77] Creating layer scale3a_branch1
I0529 22:03:46.682663 24924 net.cpp:150] Setting up scale3a_branch1
I0529 22:03:46.682672 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.682674 24924 net.cpp:165] Memory required for data: 1930035284
I0529 22:03:46.682685 24924 layer_factory.hpp:77] Creating layer res3a_branch2a
I0529 22:03:46.682701 24924 net.cpp:100] Creating Layer res3a_branch2a
I0529 22:03:46.682708 24924 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0529 22:03:46.682724 24924 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0529 22:03:46.683506 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 230424
I0529 22:03:46.683522 24924 net.cpp:150] Setting up res3a_branch2a
I0529 22:03:46.683531 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.683534 24924 net.cpp:165] Memory required for data: 1936588884
I0529 22:03:46.683544 24924 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0529 22:03:46.683559 24924 net.cpp:100] Creating Layer bn3a_branch2a
I0529 22:03:46.683565 24924 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0529 22:03:46.683581 24924 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0529 22:03:46.683745 24924 net.cpp:150] Setting up bn3a_branch2a
I0529 22:03:46.683753 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.683755 24924 net.cpp:165] Memory required for data: 1943142484
I0529 22:03:46.683773 24924 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0529 22:03:46.683787 24924 net.cpp:100] Creating Layer scale3a_branch2a
I0529 22:03:46.683794 24924 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0529 22:03:46.683807 24924 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0529 22:03:46.683853 24924 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0529 22:03:46.683990 24924 net.cpp:150] Setting up scale3a_branch2a
I0529 22:03:46.683996 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.684000 24924 net.cpp:165] Memory required for data: 1949696084
I0529 22:03:46.684010 24924 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0529 22:03:46.684021 24924 net.cpp:100] Creating Layer res3a_branch2a_relu
I0529 22:03:46.684027 24924 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0529 22:03:46.684041 24924 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0529 22:03:46.684173 24924 net.cpp:150] Setting up res3a_branch2a_relu
I0529 22:03:46.684180 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.684182 24924 net.cpp:165] Memory required for data: 1956249684
I0529 22:03:46.684188 24924 layer_factory.hpp:77] Creating layer res3a_branch2b
I0529 22:03:46.684203 24924 net.cpp:100] Creating Layer res3a_branch2b
I0529 22:03:46.684209 24924 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0529 22:03:46.684226 24924 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0529 22:03:46.685170 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 22:03:46.685369 24924 net.cpp:150] Setting up res3a_branch2b
I0529 22:03:46.685379 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.685382 24924 net.cpp:165] Memory required for data: 1962803284
I0529 22:03:46.685395 24924 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0529 22:03:46.685410 24924 net.cpp:100] Creating Layer bn3a_branch2b
I0529 22:03:46.685416 24924 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0529 22:03:46.685431 24924 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0529 22:03:46.685601 24924 net.cpp:150] Setting up bn3a_branch2b
I0529 22:03:46.685607 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.685611 24924 net.cpp:165] Memory required for data: 1969356884
I0529 22:03:46.685627 24924 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0529 22:03:46.685652 24924 net.cpp:100] Creating Layer scale3a_branch2b
I0529 22:03:46.685657 24924 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0529 22:03:46.685672 24924 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0529 22:03:46.685719 24924 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0529 22:03:46.685856 24924 net.cpp:150] Setting up scale3a_branch2b
I0529 22:03:46.685863 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.685866 24924 net.cpp:165] Memory required for data: 1975910484
I0529 22:03:46.685879 24924 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0529 22:03:46.685891 24924 net.cpp:100] Creating Layer res3a_branch2b_relu
I0529 22:03:46.685897 24924 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0529 22:03:46.685910 24924 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0529 22:03:46.686050 24924 net.cpp:150] Setting up res3a_branch2b_relu
I0529 22:03:46.686058 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.686060 24924 net.cpp:165] Memory required for data: 1982464084
I0529 22:03:46.686065 24924 layer_factory.hpp:77] Creating layer res3a_branch2c
I0529 22:03:46.686081 24924 net.cpp:100] Creating Layer res3a_branch2c
I0529 22:03:46.686087 24924 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0529 22:03:46.686103 24924 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0529 22:03:46.686931 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.686949 24924 net.cpp:150] Setting up res3a_branch2c
I0529 22:03:46.686959 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.686961 24924 net.cpp:165] Memory required for data: 2008678484
I0529 22:03:46.686974 24924 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0529 22:03:46.686988 24924 net.cpp:100] Creating Layer bn3a_branch2c
I0529 22:03:46.686995 24924 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0529 22:03:46.687010 24924 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0529 22:03:46.687175 24924 net.cpp:150] Setting up bn3a_branch2c
I0529 22:03:46.687182 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.687186 24924 net.cpp:165] Memory required for data: 2034892884
I0529 22:03:46.687201 24924 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0529 22:03:46.687216 24924 net.cpp:100] Creating Layer scale3a_branch2c
I0529 22:03:46.687222 24924 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0529 22:03:46.687235 24924 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0529 22:03:46.687278 24924 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0529 22:03:46.687417 24924 net.cpp:150] Setting up scale3a_branch2c
I0529 22:03:46.687424 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.687427 24924 net.cpp:165] Memory required for data: 2061107284
I0529 22:03:46.687439 24924 layer_factory.hpp:77] Creating layer res3a
I0529 22:03:46.687450 24924 net.cpp:100] Creating Layer res3a
I0529 22:03:46.687455 24924 net.cpp:444] res3a <- res3a_branch1
I0529 22:03:46.687467 24924 net.cpp:444] res3a <- res3a_branch2c
I0529 22:03:46.687477 24924 net.cpp:418] res3a -> res3a
I0529 22:03:46.687510 24924 net.cpp:150] Setting up res3a
I0529 22:03:46.687520 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.687523 24924 net.cpp:165] Memory required for data: 2087321684
I0529 22:03:46.687527 24924 layer_factory.hpp:77] Creating layer res3a_relu
I0529 22:03:46.687537 24924 net.cpp:100] Creating Layer res3a_relu
I0529 22:03:46.687542 24924 net.cpp:444] res3a_relu <- res3a
I0529 22:03:46.687556 24924 net.cpp:405] res3a_relu -> res3a (in-place)
I0529 22:03:46.687880 24924 net.cpp:150] Setting up res3a_relu
I0529 22:03:46.687889 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.687892 24924 net.cpp:165] Memory required for data: 2113536084
I0529 22:03:46.687898 24924 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0529 22:03:46.687911 24924 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0529 22:03:46.687916 24924 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0529 22:03:46.687932 24924 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0529 22:03:46.687947 24924 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0529 22:03:46.687988 24924 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0529 22:03:46.687997 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.688002 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.688006 24924 net.cpp:165] Memory required for data: 2165964884
I0529 22:03:46.688010 24924 layer_factory.hpp:77] Creating layer res3b_branch2a
I0529 22:03:46.688026 24924 net.cpp:100] Creating Layer res3b_branch2a
I0529 22:03:46.688032 24924 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0529 22:03:46.688047 24924 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0529 22:03:46.688876 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.688899 24924 net.cpp:150] Setting up res3b_branch2a
I0529 22:03:46.688906 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.688916 24924 net.cpp:165] Memory required for data: 2172518484
I0529 22:03:46.688930 24924 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0529 22:03:46.688947 24924 net.cpp:100] Creating Layer bn3b_branch2a
I0529 22:03:46.688954 24924 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0529 22:03:46.688968 24924 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0529 22:03:46.689142 24924 net.cpp:150] Setting up bn3b_branch2a
I0529 22:03:46.689149 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.689152 24924 net.cpp:165] Memory required for data: 2179072084
I0529 22:03:46.689169 24924 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0529 22:03:46.689185 24924 net.cpp:100] Creating Layer scale3b_branch2a
I0529 22:03:46.689193 24924 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0529 22:03:46.689205 24924 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0529 22:03:46.689252 24924 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0529 22:03:46.689393 24924 net.cpp:150] Setting up scale3b_branch2a
I0529 22:03:46.689399 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.689401 24924 net.cpp:165] Memory required for data: 2185625684
I0529 22:03:46.689414 24924 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0529 22:03:46.689424 24924 net.cpp:100] Creating Layer res3b_branch2a_relu
I0529 22:03:46.689430 24924 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0529 22:03:46.689443 24924 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0529 22:03:46.689584 24924 net.cpp:150] Setting up res3b_branch2a_relu
I0529 22:03:46.689590 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.689594 24924 net.cpp:165] Memory required for data: 2192179284
I0529 22:03:46.689599 24924 layer_factory.hpp:77] Creating layer res3b_branch2b
I0529 22:03:46.689615 24924 net.cpp:100] Creating Layer res3b_branch2b
I0529 22:03:46.689621 24924 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0529 22:03:46.689637 24924 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0529 22:03:46.690789 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 22:03:46.690984 24924 net.cpp:150] Setting up res3b_branch2b
I0529 22:03:46.690997 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.691001 24924 net.cpp:165] Memory required for data: 2198732884
I0529 22:03:46.691013 24924 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0529 22:03:46.691027 24924 net.cpp:100] Creating Layer bn3b_branch2b
I0529 22:03:46.691035 24924 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0529 22:03:46.691048 24924 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0529 22:03:46.691218 24924 net.cpp:150] Setting up bn3b_branch2b
I0529 22:03:46.691226 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.691227 24924 net.cpp:165] Memory required for data: 2205286484
I0529 22:03:46.691244 24924 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0529 22:03:46.691257 24924 net.cpp:100] Creating Layer scale3b_branch2b
I0529 22:03:46.691263 24924 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0529 22:03:46.691277 24924 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0529 22:03:46.691323 24924 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0529 22:03:46.691462 24924 net.cpp:150] Setting up scale3b_branch2b
I0529 22:03:46.691469 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.691473 24924 net.cpp:165] Memory required for data: 2211840084
I0529 22:03:46.691484 24924 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0529 22:03:46.691494 24924 net.cpp:100] Creating Layer res3b_branch2b_relu
I0529 22:03:46.691500 24924 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0529 22:03:46.691514 24924 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0529 22:03:46.691653 24924 net.cpp:150] Setting up res3b_branch2b_relu
I0529 22:03:46.691659 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.691663 24924 net.cpp:165] Memory required for data: 2218393684
I0529 22:03:46.691668 24924 layer_factory.hpp:77] Creating layer res3b_branch2c
I0529 22:03:46.691684 24924 net.cpp:100] Creating Layer res3b_branch2c
I0529 22:03:46.691689 24924 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0529 22:03:46.691705 24924 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0529 22:03:46.692535 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.692557 24924 net.cpp:150] Setting up res3b_branch2c
I0529 22:03:46.692565 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.692569 24924 net.cpp:165] Memory required for data: 2244608084
I0529 22:03:46.692580 24924 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0529 22:03:46.692593 24924 net.cpp:100] Creating Layer bn3b_branch2c
I0529 22:03:46.692600 24924 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0529 22:03:46.692616 24924 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0529 22:03:46.692785 24924 net.cpp:150] Setting up bn3b_branch2c
I0529 22:03:46.692791 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.692795 24924 net.cpp:165] Memory required for data: 2270822484
I0529 22:03:46.692811 24924 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0529 22:03:46.692823 24924 net.cpp:100] Creating Layer scale3b_branch2c
I0529 22:03:46.692829 24924 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0529 22:03:46.692843 24924 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0529 22:03:46.692888 24924 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0529 22:03:46.693032 24924 net.cpp:150] Setting up scale3b_branch2c
I0529 22:03:46.693039 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.693042 24924 net.cpp:165] Memory required for data: 2297036884
I0529 22:03:46.693055 24924 layer_factory.hpp:77] Creating layer res3b
I0529 22:03:46.693066 24924 net.cpp:100] Creating Layer res3b
I0529 22:03:46.693073 24924 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0529 22:03:46.693084 24924 net.cpp:444] res3b <- res3b_branch2c
I0529 22:03:46.693094 24924 net.cpp:418] res3b -> res3b
I0529 22:03:46.693127 24924 net.cpp:150] Setting up res3b
I0529 22:03:46.693135 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.693138 24924 net.cpp:165] Memory required for data: 2323251284
I0529 22:03:46.693143 24924 layer_factory.hpp:77] Creating layer res3b_relu
I0529 22:03:46.693156 24924 net.cpp:100] Creating Layer res3b_relu
I0529 22:03:46.693161 24924 net.cpp:444] res3b_relu <- res3b
I0529 22:03:46.693172 24924 net.cpp:405] res3b_relu -> res3b (in-place)
I0529 22:03:46.693495 24924 net.cpp:150] Setting up res3b_relu
I0529 22:03:46.693502 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.693506 24924 net.cpp:165] Memory required for data: 2349465684
I0529 22:03:46.693511 24924 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0529 22:03:46.693524 24924 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0529 22:03:46.693531 24924 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0529 22:03:46.693545 24924 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0529 22:03:46.693562 24924 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0529 22:03:46.693601 24924 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0529 22:03:46.693611 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.693616 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.693619 24924 net.cpp:165] Memory required for data: 2401894484
I0529 22:03:46.693624 24924 layer_factory.hpp:77] Creating layer res3c_branch2a
I0529 22:03:46.693639 24924 net.cpp:100] Creating Layer res3c_branch2a
I0529 22:03:46.693645 24924 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0529 22:03:46.693660 24924 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0529 22:03:46.694463 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.694480 24924 net.cpp:150] Setting up res3c_branch2a
I0529 22:03:46.694489 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.694491 24924 net.cpp:165] Memory required for data: 2408448084
I0529 22:03:46.694504 24924 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0529 22:03:46.694517 24924 net.cpp:100] Creating Layer bn3c_branch2a
I0529 22:03:46.694525 24924 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0529 22:03:46.694538 24924 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0529 22:03:46.694706 24924 net.cpp:150] Setting up bn3c_branch2a
I0529 22:03:46.694712 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.694715 24924 net.cpp:165] Memory required for data: 2415001684
I0529 22:03:46.694731 24924 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0529 22:03:46.694746 24924 net.cpp:100] Creating Layer scale3c_branch2a
I0529 22:03:46.694752 24924 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0529 22:03:46.694766 24924 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0529 22:03:46.694813 24924 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0529 22:03:46.694952 24924 net.cpp:150] Setting up scale3c_branch2a
I0529 22:03:46.694957 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.694960 24924 net.cpp:165] Memory required for data: 2421555284
I0529 22:03:46.694972 24924 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0529 22:03:46.694983 24924 net.cpp:100] Creating Layer res3c_branch2a_relu
I0529 22:03:46.694988 24924 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0529 22:03:46.695001 24924 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0529 22:03:46.695132 24924 net.cpp:150] Setting up res3c_branch2a_relu
I0529 22:03:46.695138 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.695140 24924 net.cpp:165] Memory required for data: 2428108884
I0529 22:03:46.695145 24924 layer_factory.hpp:77] Creating layer res3c_branch2b
I0529 22:03:46.695161 24924 net.cpp:100] Creating Layer res3c_branch2b
I0529 22:03:46.695168 24924 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0529 22:03:46.695183 24924 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0529 22:03:46.696621 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 22:03:46.696825 24924 net.cpp:150] Setting up res3c_branch2b
I0529 22:03:46.696837 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.696841 24924 net.cpp:165] Memory required for data: 2434662484
I0529 22:03:46.696854 24924 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0529 22:03:46.696869 24924 net.cpp:100] Creating Layer bn3c_branch2b
I0529 22:03:46.696876 24924 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0529 22:03:46.696890 24924 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0529 22:03:46.697068 24924 net.cpp:150] Setting up bn3c_branch2b
I0529 22:03:46.697077 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.697079 24924 net.cpp:165] Memory required for data: 2441216084
I0529 22:03:46.697096 24924 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0529 22:03:46.697109 24924 net.cpp:100] Creating Layer scale3c_branch2b
I0529 22:03:46.697115 24924 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0529 22:03:46.697130 24924 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0529 22:03:46.697178 24924 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0529 22:03:46.697319 24924 net.cpp:150] Setting up scale3c_branch2b
I0529 22:03:46.697325 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.697329 24924 net.cpp:165] Memory required for data: 2447769684
I0529 22:03:46.697340 24924 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0529 22:03:46.697351 24924 net.cpp:100] Creating Layer res3c_branch2b_relu
I0529 22:03:46.697357 24924 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0529 22:03:46.697371 24924 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0529 22:03:46.697511 24924 net.cpp:150] Setting up res3c_branch2b_relu
I0529 22:03:46.697518 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.697520 24924 net.cpp:165] Memory required for data: 2454323284
I0529 22:03:46.697526 24924 layer_factory.hpp:77] Creating layer res3c_branch2c
I0529 22:03:46.697542 24924 net.cpp:100] Creating Layer res3c_branch2c
I0529 22:03:46.697548 24924 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0529 22:03:46.697564 24924 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0529 22:03:46.698398 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.698417 24924 net.cpp:150] Setting up res3c_branch2c
I0529 22:03:46.698426 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.698428 24924 net.cpp:165] Memory required for data: 2480537684
I0529 22:03:46.698441 24924 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0529 22:03:46.698454 24924 net.cpp:100] Creating Layer bn3c_branch2c
I0529 22:03:46.698462 24924 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0529 22:03:46.698477 24924 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0529 22:03:46.698645 24924 net.cpp:150] Setting up bn3c_branch2c
I0529 22:03:46.698652 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.698655 24924 net.cpp:165] Memory required for data: 2506752084
I0529 22:03:46.698671 24924 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0529 22:03:46.698686 24924 net.cpp:100] Creating Layer scale3c_branch2c
I0529 22:03:46.698693 24924 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0529 22:03:46.698705 24924 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0529 22:03:46.698750 24924 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0529 22:03:46.698891 24924 net.cpp:150] Setting up scale3c_branch2c
I0529 22:03:46.698899 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.698901 24924 net.cpp:165] Memory required for data: 2532966484
I0529 22:03:46.698913 24924 layer_factory.hpp:77] Creating layer res3c
I0529 22:03:46.698925 24924 net.cpp:100] Creating Layer res3c
I0529 22:03:46.698930 24924 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0529 22:03:46.698941 24924 net.cpp:444] res3c <- res3c_branch2c
I0529 22:03:46.698953 24924 net.cpp:418] res3c -> res3c
I0529 22:03:46.698985 24924 net.cpp:150] Setting up res3c
I0529 22:03:46.698995 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.698998 24924 net.cpp:165] Memory required for data: 2559180884
I0529 22:03:46.699003 24924 layer_factory.hpp:77] Creating layer res3c_relu
I0529 22:03:46.699013 24924 net.cpp:100] Creating Layer res3c_relu
I0529 22:03:46.699018 24924 net.cpp:444] res3c_relu <- res3c
I0529 22:03:46.699030 24924 net.cpp:405] res3c_relu -> res3c (in-place)
I0529 22:03:46.699162 24924 net.cpp:150] Setting up res3c_relu
I0529 22:03:46.699167 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.699170 24924 net.cpp:165] Memory required for data: 2585395284
I0529 22:03:46.699175 24924 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0529 22:03:46.699187 24924 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0529 22:03:46.699192 24924 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0529 22:03:46.699206 24924 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0529 22:03:46.699221 24924 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0529 22:03:46.699261 24924 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0529 22:03:46.699270 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.699275 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.699278 24924 net.cpp:165] Memory required for data: 2637824084
I0529 22:03:46.699282 24924 layer_factory.hpp:77] Creating layer res3d_branch2a
I0529 22:03:46.699298 24924 net.cpp:100] Creating Layer res3d_branch2a
I0529 22:03:46.699304 24924 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0529 22:03:46.699319 24924 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0529 22:03:46.700649 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.700675 24924 net.cpp:150] Setting up res3d_branch2a
I0529 22:03:46.700685 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.700687 24924 net.cpp:165] Memory required for data: 2644377684
I0529 22:03:46.700700 24924 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0529 22:03:46.700714 24924 net.cpp:100] Creating Layer bn3d_branch2a
I0529 22:03:46.700721 24924 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0529 22:03:46.700736 24924 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0529 22:03:46.700906 24924 net.cpp:150] Setting up bn3d_branch2a
I0529 22:03:46.700920 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.700923 24924 net.cpp:165] Memory required for data: 2650931284
I0529 22:03:46.700963 24924 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0529 22:03:46.700979 24924 net.cpp:100] Creating Layer scale3d_branch2a
I0529 22:03:46.700986 24924 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0529 22:03:46.701000 24924 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0529 22:03:46.701048 24924 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0529 22:03:46.701694 24924 net.cpp:150] Setting up scale3d_branch2a
I0529 22:03:46.701704 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.701706 24924 net.cpp:165] Memory required for data: 2657484884
I0529 22:03:46.701719 24924 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0529 22:03:46.701732 24924 net.cpp:100] Creating Layer res3d_branch2a_relu
I0529 22:03:46.701738 24924 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0529 22:03:46.701753 24924 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0529 22:03:46.702093 24924 net.cpp:150] Setting up res3d_branch2a_relu
I0529 22:03:46.702101 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.702105 24924 net.cpp:165] Memory required for data: 2664038484
I0529 22:03:46.702111 24924 layer_factory.hpp:77] Creating layer res3d_branch2b
I0529 22:03:46.702127 24924 net.cpp:100] Creating Layer res3d_branch2b
I0529 22:03:46.702133 24924 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0529 22:03:46.702150 24924 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0529 22:03:46.703091 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0529 22:03:46.703291 24924 net.cpp:150] Setting up res3d_branch2b
I0529 22:03:46.703302 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.703305 24924 net.cpp:165] Memory required for data: 2670592084
I0529 22:03:46.703317 24924 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0529 22:03:46.703332 24924 net.cpp:100] Creating Layer bn3d_branch2b
I0529 22:03:46.703338 24924 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0529 22:03:46.703353 24924 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0529 22:03:46.703529 24924 net.cpp:150] Setting up bn3d_branch2b
I0529 22:03:46.703536 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.703538 24924 net.cpp:165] Memory required for data: 2677145684
I0529 22:03:46.703555 24924 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0529 22:03:46.703568 24924 net.cpp:100] Creating Layer scale3d_branch2b
I0529 22:03:46.703574 24924 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0529 22:03:46.703588 24924 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0529 22:03:46.703637 24924 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0529 22:03:46.703776 24924 net.cpp:150] Setting up scale3d_branch2b
I0529 22:03:46.703784 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.703788 24924 net.cpp:165] Memory required for data: 2683699284
I0529 22:03:46.703799 24924 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0529 22:03:46.703810 24924 net.cpp:100] Creating Layer res3d_branch2b_relu
I0529 22:03:46.703815 24924 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0529 22:03:46.703827 24924 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0529 22:03:46.703965 24924 net.cpp:150] Setting up res3d_branch2b_relu
I0529 22:03:46.703971 24924 net.cpp:157] Top shape: 1 128 80 160 (1638400)
I0529 22:03:46.703975 24924 net.cpp:165] Memory required for data: 2690252884
I0529 22:03:46.703980 24924 layer_factory.hpp:77] Creating layer res3d_branch2c
I0529 22:03:46.703995 24924 net.cpp:100] Creating Layer res3d_branch2c
I0529 22:03:46.704001 24924 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0529 22:03:46.704016 24924 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0529 22:03:46.704860 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 236952
I0529 22:03:46.705070 24924 net.cpp:150] Setting up res3d_branch2c
I0529 22:03:46.705080 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705085 24924 net.cpp:165] Memory required for data: 2716467284
I0529 22:03:46.705096 24924 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0529 22:03:46.705112 24924 net.cpp:100] Creating Layer bn3d_branch2c
I0529 22:03:46.705118 24924 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0529 22:03:46.705133 24924 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0529 22:03:46.705312 24924 net.cpp:150] Setting up bn3d_branch2c
I0529 22:03:46.705317 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705320 24924 net.cpp:165] Memory required for data: 2742681684
I0529 22:03:46.705337 24924 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0529 22:03:46.705349 24924 net.cpp:100] Creating Layer scale3d_branch2c
I0529 22:03:46.705355 24924 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0529 22:03:46.705370 24924 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0529 22:03:46.705416 24924 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0529 22:03:46.705556 24924 net.cpp:150] Setting up scale3d_branch2c
I0529 22:03:46.705564 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705566 24924 net.cpp:165] Memory required for data: 2768896084
I0529 22:03:46.705579 24924 layer_factory.hpp:77] Creating layer res3d
I0529 22:03:46.705590 24924 net.cpp:100] Creating Layer res3d
I0529 22:03:46.705596 24924 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0529 22:03:46.705607 24924 net.cpp:444] res3d <- res3d_branch2c
I0529 22:03:46.705617 24924 net.cpp:418] res3d -> res3d
I0529 22:03:46.705651 24924 net.cpp:150] Setting up res3d
I0529 22:03:46.705658 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705662 24924 net.cpp:165] Memory required for data: 2795110484
I0529 22:03:46.705667 24924 layer_factory.hpp:77] Creating layer res3d_relu
I0529 22:03:46.705677 24924 net.cpp:100] Creating Layer res3d_relu
I0529 22:03:46.705682 24924 net.cpp:444] res3d_relu <- res3d
I0529 22:03:46.705695 24924 net.cpp:405] res3d_relu -> res3d (in-place)
I0529 22:03:46.705832 24924 net.cpp:150] Setting up res3d_relu
I0529 22:03:46.705839 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705842 24924 net.cpp:165] Memory required for data: 2821324884
I0529 22:03:46.705847 24924 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0529 22:03:46.705858 24924 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0529 22:03:46.705864 24924 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0529 22:03:46.705878 24924 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0529 22:03:46.705893 24924 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0529 22:03:46.705935 24924 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0529 22:03:46.705942 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705947 24924 net.cpp:157] Top shape: 1 512 80 160 (6553600)
I0529 22:03:46.705950 24924 net.cpp:165] Memory required for data: 2873753684
I0529 22:03:46.705955 24924 layer_factory.hpp:77] Creating layer res4a_branch1
I0529 22:03:46.705971 24924 net.cpp:100] Creating Layer res4a_branch1
I0529 22:03:46.705976 24924 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0529 22:03:46.705992 24924 net.cpp:418] res4a_branch1 -> res4a_branch1
I0529 22:03:46.707922 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0529 22:03:46.707938 24924 net.cpp:150] Setting up res4a_branch1
I0529 22:03:46.707947 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.707950 24924 net.cpp:165] Memory required for data: 2886860884
I0529 22:03:46.707963 24924 layer_factory.hpp:77] Creating layer bn4a_branch1
I0529 22:03:46.707979 24924 net.cpp:100] Creating Layer bn4a_branch1
I0529 22:03:46.707986 24924 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0529 22:03:46.708001 24924 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0529 22:03:46.708168 24924 net.cpp:150] Setting up bn4a_branch1
I0529 22:03:46.708174 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.708178 24924 net.cpp:165] Memory required for data: 2899968084
I0529 22:03:46.708194 24924 layer_factory.hpp:77] Creating layer scale4a_branch1
I0529 22:03:46.708209 24924 net.cpp:100] Creating Layer scale4a_branch1
I0529 22:03:46.708214 24924 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0529 22:03:46.708228 24924 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0529 22:03:46.708273 24924 layer_factory.hpp:77] Creating layer scale4a_branch1
I0529 22:03:46.708392 24924 net.cpp:150] Setting up scale4a_branch1
I0529 22:03:46.708400 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.708403 24924 net.cpp:165] Memory required for data: 2913075284
I0529 22:03:46.708415 24924 layer_factory.hpp:77] Creating layer res4a_branch2a
I0529 22:03:46.708431 24924 net.cpp:100] Creating Layer res4a_branch2a
I0529 22:03:46.708436 24924 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0529 22:03:46.708452 24924 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0529 22:03:46.709386 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0529 22:03:46.709403 24924 net.cpp:150] Setting up res4a_branch2a
I0529 22:03:46.709410 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.709414 24924 net.cpp:165] Memory required for data: 2916352084
I0529 22:03:46.709425 24924 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0529 22:03:46.709439 24924 net.cpp:100] Creating Layer bn4a_branch2a
I0529 22:03:46.709446 24924 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0529 22:03:46.709461 24924 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0529 22:03:46.709623 24924 net.cpp:150] Setting up bn4a_branch2a
I0529 22:03:46.709630 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.709632 24924 net.cpp:165] Memory required for data: 2919628884
I0529 22:03:46.709648 24924 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0529 22:03:46.709662 24924 net.cpp:100] Creating Layer scale4a_branch2a
I0529 22:03:46.709668 24924 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0529 22:03:46.709682 24924 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0529 22:03:46.709729 24924 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0529 22:03:46.709843 24924 net.cpp:150] Setting up scale4a_branch2a
I0529 22:03:46.709851 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.709853 24924 net.cpp:165] Memory required for data: 2922905684
I0529 22:03:46.709866 24924 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0529 22:03:46.709875 24924 net.cpp:100] Creating Layer res4a_branch2a_relu
I0529 22:03:46.709882 24924 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0529 22:03:46.709895 24924 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0529 22:03:46.710237 24924 net.cpp:150] Setting up res4a_branch2a_relu
I0529 22:03:46.710245 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.710248 24924 net.cpp:165] Memory required for data: 2926182484
I0529 22:03:46.710253 24924 layer_factory.hpp:77] Creating layer res4a_branch2b
I0529 22:03:46.710270 24924 net.cpp:100] Creating Layer res4a_branch2b
I0529 22:03:46.710278 24924 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0529 22:03:46.710294 24924 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0529 22:03:46.712369 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 22:03:46.712581 24924 net.cpp:150] Setting up res4a_branch2b
I0529 22:03:46.712594 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.712599 24924 net.cpp:165] Memory required for data: 2929459284
I0529 22:03:46.712611 24924 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0529 22:03:46.712627 24924 net.cpp:100] Creating Layer bn4a_branch2b
I0529 22:03:46.712635 24924 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0529 22:03:46.712648 24924 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0529 22:03:46.712817 24924 net.cpp:150] Setting up bn4a_branch2b
I0529 22:03:46.712823 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.712826 24924 net.cpp:165] Memory required for data: 2932736084
I0529 22:03:46.712842 24924 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0529 22:03:46.712857 24924 net.cpp:100] Creating Layer scale4a_branch2b
I0529 22:03:46.712863 24924 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0529 22:03:46.712877 24924 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0529 22:03:46.712934 24924 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0529 22:03:46.713053 24924 net.cpp:150] Setting up scale4a_branch2b
I0529 22:03:46.713060 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.713063 24924 net.cpp:165] Memory required for data: 2936012884
I0529 22:03:46.713075 24924 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0529 22:03:46.713086 24924 net.cpp:100] Creating Layer res4a_branch2b_relu
I0529 22:03:46.713093 24924 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0529 22:03:46.713106 24924 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0529 22:03:46.713264 24924 net.cpp:150] Setting up res4a_branch2b_relu
I0529 22:03:46.713271 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.713274 24924 net.cpp:165] Memory required for data: 2939289684
I0529 22:03:46.713279 24924 layer_factory.hpp:77] Creating layer res4a_branch2c
I0529 22:03:46.713295 24924 net.cpp:100] Creating Layer res4a_branch2c
I0529 22:03:46.713301 24924 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0529 22:03:46.713317 24924 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0529 22:03:46.714941 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.714957 24924 net.cpp:150] Setting up res4a_branch2c
I0529 22:03:46.714967 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.714970 24924 net.cpp:165] Memory required for data: 2952396884
I0529 22:03:46.714982 24924 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0529 22:03:46.714996 24924 net.cpp:100] Creating Layer bn4a_branch2c
I0529 22:03:46.715003 24924 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0529 22:03:46.715019 24924 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0529 22:03:46.715188 24924 net.cpp:150] Setting up bn4a_branch2c
I0529 22:03:46.715194 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.715198 24924 net.cpp:165] Memory required for data: 2965504084
I0529 22:03:46.715214 24924 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0529 22:03:46.715227 24924 net.cpp:100] Creating Layer scale4a_branch2c
I0529 22:03:46.715234 24924 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0529 22:03:46.715247 24924 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0529 22:03:46.715294 24924 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0529 22:03:46.715416 24924 net.cpp:150] Setting up scale4a_branch2c
I0529 22:03:46.715423 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.715426 24924 net.cpp:165] Memory required for data: 2978611284
I0529 22:03:46.715437 24924 layer_factory.hpp:77] Creating layer res4a
I0529 22:03:46.715462 24924 net.cpp:100] Creating Layer res4a
I0529 22:03:46.715469 24924 net.cpp:444] res4a <- res4a_branch1
I0529 22:03:46.715481 24924 net.cpp:444] res4a <- res4a_branch2c
I0529 22:03:46.715492 24924 net.cpp:418] res4a -> res4a
I0529 22:03:46.715524 24924 net.cpp:150] Setting up res4a
I0529 22:03:46.715533 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.715536 24924 net.cpp:165] Memory required for data: 2991718484
I0529 22:03:46.715544 24924 layer_factory.hpp:77] Creating layer res4a_relu
I0529 22:03:46.715554 24924 net.cpp:100] Creating Layer res4a_relu
I0529 22:03:46.715559 24924 net.cpp:444] res4a_relu <- res4a
I0529 22:03:46.715571 24924 net.cpp:405] res4a_relu -> res4a (in-place)
I0529 22:03:46.715713 24924 net.cpp:150] Setting up res4a_relu
I0529 22:03:46.715720 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.715723 24924 net.cpp:165] Memory required for data: 3004825684
I0529 22:03:46.715728 24924 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0529 22:03:46.715739 24924 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0529 22:03:46.715744 24924 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0529 22:03:46.715760 24924 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0529 22:03:46.715776 24924 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0529 22:03:46.715818 24924 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0529 22:03:46.715827 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.715832 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.715837 24924 net.cpp:165] Memory required for data: 3031040084
I0529 22:03:46.715840 24924 layer_factory.hpp:77] Creating layer res4b_branch2a
I0529 22:03:46.715857 24924 net.cpp:100] Creating Layer res4b_branch2a
I0529 22:03:46.715863 24924 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0529 22:03:46.715878 24924 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0529 22:03:46.716976 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.716992 24924 net.cpp:150] Setting up res4b_branch2a
I0529 22:03:46.717002 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.717005 24924 net.cpp:165] Memory required for data: 3034316884
I0529 22:03:46.717016 24924 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0529 22:03:46.717031 24924 net.cpp:100] Creating Layer bn4b_branch2a
I0529 22:03:46.717037 24924 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0529 22:03:46.717052 24924 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0529 22:03:46.717216 24924 net.cpp:150] Setting up bn4b_branch2a
I0529 22:03:46.717223 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.717226 24924 net.cpp:165] Memory required for data: 3037593684
I0529 22:03:46.717242 24924 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0529 22:03:46.717255 24924 net.cpp:100] Creating Layer scale4b_branch2a
I0529 22:03:46.717262 24924 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0529 22:03:46.717277 24924 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0529 22:03:46.717324 24924 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0529 22:03:46.717440 24924 net.cpp:150] Setting up scale4b_branch2a
I0529 22:03:46.717448 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.717452 24924 net.cpp:165] Memory required for data: 3040870484
I0529 22:03:46.717463 24924 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0529 22:03:46.717473 24924 net.cpp:100] Creating Layer res4b_branch2a_relu
I0529 22:03:46.717479 24924 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0529 22:03:46.717491 24924 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0529 22:03:46.717828 24924 net.cpp:150] Setting up res4b_branch2a_relu
I0529 22:03:46.717836 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.717839 24924 net.cpp:165] Memory required for data: 3044147284
I0529 22:03:46.717845 24924 layer_factory.hpp:77] Creating layer res4b_branch2b
I0529 22:03:46.717861 24924 net.cpp:100] Creating Layer res4b_branch2b
I0529 22:03:46.717869 24924 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0529 22:03:46.717885 24924 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0529 22:03:46.720052 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 22:03:46.720278 24924 net.cpp:150] Setting up res4b_branch2b
I0529 22:03:46.720295 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.720299 24924 net.cpp:165] Memory required for data: 3047424084
I0529 22:03:46.720319 24924 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0529 22:03:46.720342 24924 net.cpp:100] Creating Layer bn4b_branch2b
I0529 22:03:46.720352 24924 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0529 22:03:46.720371 24924 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0529 22:03:46.720556 24924 net.cpp:150] Setting up bn4b_branch2b
I0529 22:03:46.720562 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.720566 24924 net.cpp:165] Memory required for data: 3050700884
I0529 22:03:46.720582 24924 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0529 22:03:46.720597 24924 net.cpp:100] Creating Layer scale4b_branch2b
I0529 22:03:46.720602 24924 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0529 22:03:46.720618 24924 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0529 22:03:46.720675 24924 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0529 22:03:46.720798 24924 net.cpp:150] Setting up scale4b_branch2b
I0529 22:03:46.720804 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.720808 24924 net.cpp:165] Memory required for data: 3053977684
I0529 22:03:46.720819 24924 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0529 22:03:46.720830 24924 net.cpp:100] Creating Layer res4b_branch2b_relu
I0529 22:03:46.720836 24924 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0529 22:03:46.720849 24924 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0529 22:03:46.721005 24924 net.cpp:150] Setting up res4b_branch2b_relu
I0529 22:03:46.721012 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.721015 24924 net.cpp:165] Memory required for data: 3057254484
I0529 22:03:46.721020 24924 layer_factory.hpp:77] Creating layer res4b_branch2c
I0529 22:03:46.721038 24924 net.cpp:100] Creating Layer res4b_branch2c
I0529 22:03:46.721045 24924 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0529 22:03:46.721060 24924 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0529 22:03:46.722987 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.723007 24924 net.cpp:150] Setting up res4b_branch2c
I0529 22:03:46.723021 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723024 24924 net.cpp:165] Memory required for data: 3070361684
I0529 22:03:46.723043 24924 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0529 22:03:46.723067 24924 net.cpp:100] Creating Layer bn4b_branch2c
I0529 22:03:46.723076 24924 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0529 22:03:46.723094 24924 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0529 22:03:46.723278 24924 net.cpp:150] Setting up bn4b_branch2c
I0529 22:03:46.723285 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723289 24924 net.cpp:165] Memory required for data: 3083468884
I0529 22:03:46.723305 24924 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0529 22:03:46.723322 24924 net.cpp:100] Creating Layer scale4b_branch2c
I0529 22:03:46.723328 24924 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0529 22:03:46.723342 24924 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0529 22:03:46.723392 24924 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0529 22:03:46.723517 24924 net.cpp:150] Setting up scale4b_branch2c
I0529 22:03:46.723525 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723527 24924 net.cpp:165] Memory required for data: 3096576084
I0529 22:03:46.723539 24924 layer_factory.hpp:77] Creating layer res4b
I0529 22:03:46.723551 24924 net.cpp:100] Creating Layer res4b
I0529 22:03:46.723557 24924 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0529 22:03:46.723569 24924 net.cpp:444] res4b <- res4b_branch2c
I0529 22:03:46.723579 24924 net.cpp:418] res4b -> res4b
I0529 22:03:46.723614 24924 net.cpp:150] Setting up res4b
I0529 22:03:46.723623 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723626 24924 net.cpp:165] Memory required for data: 3109683284
I0529 22:03:46.723630 24924 layer_factory.hpp:77] Creating layer res4b_relu
I0529 22:03:46.723641 24924 net.cpp:100] Creating Layer res4b_relu
I0529 22:03:46.723646 24924 net.cpp:444] res4b_relu <- res4b
I0529 22:03:46.723659 24924 net.cpp:405] res4b_relu -> res4b (in-place)
I0529 22:03:46.723809 24924 net.cpp:150] Setting up res4b_relu
I0529 22:03:46.723816 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723819 24924 net.cpp:165] Memory required for data: 3122790484
I0529 22:03:46.723824 24924 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0529 22:03:46.723836 24924 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0529 22:03:46.723841 24924 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0529 22:03:46.723856 24924 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0529 22:03:46.723872 24924 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0529 22:03:46.723917 24924 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0529 22:03:46.723925 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723932 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.723934 24924 net.cpp:165] Memory required for data: 3149004884
I0529 22:03:46.723939 24924 layer_factory.hpp:77] Creating layer res4c_branch2a
I0529 22:03:46.723954 24924 net.cpp:100] Creating Layer res4c_branch2a
I0529 22:03:46.723960 24924 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0529 22:03:46.723976 24924 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0529 22:03:46.725131 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.725145 24924 net.cpp:150] Setting up res4c_branch2a
I0529 22:03:46.725153 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.725157 24924 net.cpp:165] Memory required for data: 3152281684
I0529 22:03:46.725168 24924 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0529 22:03:46.725183 24924 net.cpp:100] Creating Layer bn4c_branch2a
I0529 22:03:46.725188 24924 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0529 22:03:46.725203 24924 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0529 22:03:46.725371 24924 net.cpp:150] Setting up bn4c_branch2a
I0529 22:03:46.725378 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.725380 24924 net.cpp:165] Memory required for data: 3155558484
I0529 22:03:46.725396 24924 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0529 22:03:46.725410 24924 net.cpp:100] Creating Layer scale4c_branch2a
I0529 22:03:46.725415 24924 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0529 22:03:46.725430 24924 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0529 22:03:46.725478 24924 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0529 22:03:46.725597 24924 net.cpp:150] Setting up scale4c_branch2a
I0529 22:03:46.725605 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.725608 24924 net.cpp:165] Memory required for data: 3158835284
I0529 22:03:46.725620 24924 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0529 22:03:46.725630 24924 net.cpp:100] Creating Layer res4c_branch2a_relu
I0529 22:03:46.725636 24924 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0529 22:03:46.725648 24924 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0529 22:03:46.725790 24924 net.cpp:150] Setting up res4c_branch2a_relu
I0529 22:03:46.725796 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.725800 24924 net.cpp:165] Memory required for data: 3162112084
I0529 22:03:46.725805 24924 layer_factory.hpp:77] Creating layer res4c_branch2b
I0529 22:03:46.725819 24924 net.cpp:100] Creating Layer res4c_branch2b
I0529 22:03:46.725826 24924 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0529 22:03:46.725842 24924 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0529 22:03:46.727936 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 22:03:46.728152 24924 net.cpp:150] Setting up res4c_branch2b
I0529 22:03:46.728163 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.728166 24924 net.cpp:165] Memory required for data: 3165388884
I0529 22:03:46.728178 24924 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0529 22:03:46.728193 24924 net.cpp:100] Creating Layer bn4c_branch2b
I0529 22:03:46.728201 24924 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0529 22:03:46.728217 24924 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0529 22:03:46.728394 24924 net.cpp:150] Setting up bn4c_branch2b
I0529 22:03:46.728399 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.728402 24924 net.cpp:165] Memory required for data: 3168665684
I0529 22:03:46.728420 24924 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0529 22:03:46.728433 24924 net.cpp:100] Creating Layer scale4c_branch2b
I0529 22:03:46.728440 24924 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0529 22:03:46.728453 24924 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0529 22:03:46.728504 24924 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0529 22:03:46.728626 24924 net.cpp:150] Setting up scale4c_branch2b
I0529 22:03:46.728632 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.728636 24924 net.cpp:165] Memory required for data: 3171942484
I0529 22:03:46.728647 24924 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0529 22:03:46.728658 24924 net.cpp:100] Creating Layer res4c_branch2b_relu
I0529 22:03:46.728664 24924 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0529 22:03:46.728678 24924 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0529 22:03:46.729024 24924 net.cpp:150] Setting up res4c_branch2b_relu
I0529 22:03:46.729033 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.729037 24924 net.cpp:165] Memory required for data: 3175219284
I0529 22:03:46.729043 24924 layer_factory.hpp:77] Creating layer res4c_branch2c
I0529 22:03:46.729058 24924 net.cpp:100] Creating Layer res4c_branch2c
I0529 22:03:46.729064 24924 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0529 22:03:46.729080 24924 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0529 22:03:46.730733 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.730751 24924 net.cpp:150] Setting up res4c_branch2c
I0529 22:03:46.730759 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.730762 24924 net.cpp:165] Memory required for data: 3188326484
I0529 22:03:46.730775 24924 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0529 22:03:46.730792 24924 net.cpp:100] Creating Layer bn4c_branch2c
I0529 22:03:46.730799 24924 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0529 22:03:46.730814 24924 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0529 22:03:46.730991 24924 net.cpp:150] Setting up bn4c_branch2c
I0529 22:03:46.730998 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.731000 24924 net.cpp:165] Memory required for data: 3201433684
I0529 22:03:46.731016 24924 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0529 22:03:46.731030 24924 net.cpp:100] Creating Layer scale4c_branch2c
I0529 22:03:46.731036 24924 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0529 22:03:46.731051 24924 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0529 22:03:46.731097 24924 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0529 22:03:46.731220 24924 net.cpp:150] Setting up scale4c_branch2c
I0529 22:03:46.731227 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.731230 24924 net.cpp:165] Memory required for data: 3214540884
I0529 22:03:46.731242 24924 layer_factory.hpp:77] Creating layer res4c
I0529 22:03:46.731254 24924 net.cpp:100] Creating Layer res4c
I0529 22:03:46.731261 24924 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0529 22:03:46.731272 24924 net.cpp:444] res4c <- res4c_branch2c
I0529 22:03:46.731282 24924 net.cpp:418] res4c -> res4c
I0529 22:03:46.731318 24924 net.cpp:150] Setting up res4c
I0529 22:03:46.731326 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.731329 24924 net.cpp:165] Memory required for data: 3227648084
I0529 22:03:46.731334 24924 layer_factory.hpp:77] Creating layer res4c_relu
I0529 22:03:46.731344 24924 net.cpp:100] Creating Layer res4c_relu
I0529 22:03:46.731350 24924 net.cpp:444] res4c_relu <- res4c
I0529 22:03:46.731364 24924 net.cpp:405] res4c_relu -> res4c (in-place)
I0529 22:03:46.731508 24924 net.cpp:150] Setting up res4c_relu
I0529 22:03:46.731515 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.731518 24924 net.cpp:165] Memory required for data: 3240755284
I0529 22:03:46.731523 24924 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0529 22:03:46.731535 24924 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0529 22:03:46.731541 24924 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0529 22:03:46.731554 24924 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0529 22:03:46.731572 24924 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0529 22:03:46.731616 24924 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0529 22:03:46.731624 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.731631 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.731633 24924 net.cpp:165] Memory required for data: 3266969684
I0529 22:03:46.731638 24924 layer_factory.hpp:77] Creating layer res4d_branch2a
I0529 22:03:46.731653 24924 net.cpp:100] Creating Layer res4d_branch2a
I0529 22:03:46.731659 24924 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0529 22:03:46.731675 24924 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0529 22:03:46.732792 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.732807 24924 net.cpp:150] Setting up res4d_branch2a
I0529 22:03:46.732815 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.732818 24924 net.cpp:165] Memory required for data: 3270246484
I0529 22:03:46.732831 24924 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0529 22:03:46.732844 24924 net.cpp:100] Creating Layer bn4d_branch2a
I0529 22:03:46.732851 24924 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0529 22:03:46.732864 24924 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0529 22:03:46.733044 24924 net.cpp:150] Setting up bn4d_branch2a
I0529 22:03:46.733052 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.733055 24924 net.cpp:165] Memory required for data: 3273523284
I0529 22:03:46.733072 24924 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0529 22:03:46.733085 24924 net.cpp:100] Creating Layer scale4d_branch2a
I0529 22:03:46.733091 24924 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0529 22:03:46.733104 24924 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0529 22:03:46.733155 24924 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0529 22:03:46.733275 24924 net.cpp:150] Setting up scale4d_branch2a
I0529 22:03:46.733283 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.733285 24924 net.cpp:165] Memory required for data: 3276800084
I0529 22:03:46.733297 24924 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0529 22:03:46.733309 24924 net.cpp:100] Creating Layer res4d_branch2a_relu
I0529 22:03:46.733314 24924 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0529 22:03:46.733327 24924 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0529 22:03:46.733467 24924 net.cpp:150] Setting up res4d_branch2a_relu
I0529 22:03:46.733474 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.733476 24924 net.cpp:165] Memory required for data: 3280076884
I0529 22:03:46.733481 24924 layer_factory.hpp:77] Creating layer res4d_branch2b
I0529 22:03:46.733496 24924 net.cpp:100] Creating Layer res4d_branch2b
I0529 22:03:46.733502 24924 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0529 22:03:46.733518 24924 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0529 22:03:46.735608 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 22:03:46.735827 24924 net.cpp:150] Setting up res4d_branch2b
I0529 22:03:46.735838 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.735843 24924 net.cpp:165] Memory required for data: 3283353684
I0529 22:03:46.735857 24924 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0529 22:03:46.735872 24924 net.cpp:100] Creating Layer bn4d_branch2b
I0529 22:03:46.735878 24924 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0529 22:03:46.735894 24924 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0529 22:03:46.736073 24924 net.cpp:150] Setting up bn4d_branch2b
I0529 22:03:46.736078 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.736081 24924 net.cpp:165] Memory required for data: 3286630484
I0529 22:03:46.736099 24924 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0529 22:03:46.736112 24924 net.cpp:100] Creating Layer scale4d_branch2b
I0529 22:03:46.736119 24924 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0529 22:03:46.736133 24924 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0529 22:03:46.736186 24924 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0529 22:03:46.736308 24924 net.cpp:150] Setting up scale4d_branch2b
I0529 22:03:46.736315 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.736318 24924 net.cpp:165] Memory required for data: 3289907284
I0529 22:03:46.736330 24924 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0529 22:03:46.736341 24924 net.cpp:100] Creating Layer res4d_branch2b_relu
I0529 22:03:46.736347 24924 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0529 22:03:46.736359 24924 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0529 22:03:46.736713 24924 net.cpp:150] Setting up res4d_branch2b_relu
I0529 22:03:46.736721 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.736724 24924 net.cpp:165] Memory required for data: 3293184084
I0529 22:03:46.736729 24924 layer_factory.hpp:77] Creating layer res4d_branch2c
I0529 22:03:46.736747 24924 net.cpp:100] Creating Layer res4d_branch2c
I0529 22:03:46.736754 24924 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0529 22:03:46.736770 24924 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0529 22:03:46.738471 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.738489 24924 net.cpp:150] Setting up res4d_branch2c
I0529 22:03:46.738499 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.738502 24924 net.cpp:165] Memory required for data: 3306291284
I0529 22:03:46.738514 24924 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0529 22:03:46.738533 24924 net.cpp:100] Creating Layer bn4d_branch2c
I0529 22:03:46.738539 24924 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0529 22:03:46.738554 24924 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0529 22:03:46.738735 24924 net.cpp:150] Setting up bn4d_branch2c
I0529 22:03:46.738742 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.738745 24924 net.cpp:165] Memory required for data: 3319398484
I0529 22:03:46.738762 24924 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0529 22:03:46.738777 24924 net.cpp:100] Creating Layer scale4d_branch2c
I0529 22:03:46.738783 24924 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0529 22:03:46.738797 24924 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0529 22:03:46.738848 24924 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0529 22:03:46.738976 24924 net.cpp:150] Setting up scale4d_branch2c
I0529 22:03:46.738983 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.738986 24924 net.cpp:165] Memory required for data: 3332505684
I0529 22:03:46.738998 24924 layer_factory.hpp:77] Creating layer res4d
I0529 22:03:46.739009 24924 net.cpp:100] Creating Layer res4d
I0529 22:03:46.739017 24924 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0529 22:03:46.739028 24924 net.cpp:444] res4d <- res4d_branch2c
I0529 22:03:46.739040 24924 net.cpp:418] res4d -> res4d
I0529 22:03:46.739076 24924 net.cpp:150] Setting up res4d
I0529 22:03:46.739085 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.739089 24924 net.cpp:165] Memory required for data: 3345612884
I0529 22:03:46.739094 24924 layer_factory.hpp:77] Creating layer res4d_relu
I0529 22:03:46.739104 24924 net.cpp:100] Creating Layer res4d_relu
I0529 22:03:46.739109 24924 net.cpp:444] res4d_relu <- res4d
I0529 22:03:46.739123 24924 net.cpp:405] res4d_relu -> res4d (in-place)
I0529 22:03:46.739271 24924 net.cpp:150] Setting up res4d_relu
I0529 22:03:46.739279 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.739281 24924 net.cpp:165] Memory required for data: 3358720084
I0529 22:03:46.739286 24924 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0529 22:03:46.739298 24924 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0529 22:03:46.739303 24924 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0529 22:03:46.739317 24924 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0529 22:03:46.739336 24924 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0529 22:03:46.739380 24924 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0529 22:03:46.739388 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.739394 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.739398 24924 net.cpp:165] Memory required for data: 3384934484
I0529 22:03:46.739403 24924 layer_factory.hpp:77] Creating layer res4e_branch2a
I0529 22:03:46.739419 24924 net.cpp:100] Creating Layer res4e_branch2a
I0529 22:03:46.739425 24924 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0529 22:03:46.739442 24924 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0529 22:03:46.740653 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.740671 24924 net.cpp:150] Setting up res4e_branch2a
I0529 22:03:46.740681 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.740684 24924 net.cpp:165] Memory required for data: 3388211284
I0529 22:03:46.740697 24924 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0529 22:03:46.740713 24924 net.cpp:100] Creating Layer bn4e_branch2a
I0529 22:03:46.740721 24924 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0529 22:03:46.740736 24924 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0529 22:03:46.740921 24924 net.cpp:150] Setting up bn4e_branch2a
I0529 22:03:46.740928 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.740931 24924 net.cpp:165] Memory required for data: 3391488084
I0529 22:03:46.740949 24924 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0529 22:03:46.740964 24924 net.cpp:100] Creating Layer scale4e_branch2a
I0529 22:03:46.740970 24924 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0529 22:03:46.740984 24924 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0529 22:03:46.741034 24924 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0529 22:03:46.741156 24924 net.cpp:150] Setting up scale4e_branch2a
I0529 22:03:46.741163 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.741166 24924 net.cpp:165] Memory required for data: 3394764884
I0529 22:03:46.741178 24924 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0529 22:03:46.741190 24924 net.cpp:100] Creating Layer res4e_branch2a_relu
I0529 22:03:46.741196 24924 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0529 22:03:46.741209 24924 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0529 22:03:46.741358 24924 net.cpp:150] Setting up res4e_branch2a_relu
I0529 22:03:46.741365 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.741369 24924 net.cpp:165] Memory required for data: 3398041684
I0529 22:03:46.741374 24924 layer_factory.hpp:77] Creating layer res4e_branch2b
I0529 22:03:46.741389 24924 net.cpp:100] Creating Layer res4e_branch2b
I0529 22:03:46.741395 24924 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0529 22:03:46.741410 24924 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0529 22:03:46.743541 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 22:03:46.743758 24924 net.cpp:150] Setting up res4e_branch2b
I0529 22:03:46.743769 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.743772 24924 net.cpp:165] Memory required for data: 3401318484
I0529 22:03:46.743784 24924 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0529 22:03:46.743800 24924 net.cpp:100] Creating Layer bn4e_branch2b
I0529 22:03:46.743808 24924 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0529 22:03:46.743824 24924 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0529 22:03:46.744002 24924 net.cpp:150] Setting up bn4e_branch2b
I0529 22:03:46.744009 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.744012 24924 net.cpp:165] Memory required for data: 3404595284
I0529 22:03:46.744029 24924 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0529 22:03:46.744045 24924 net.cpp:100] Creating Layer scale4e_branch2b
I0529 22:03:46.744050 24924 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0529 22:03:46.744063 24924 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0529 22:03:46.744117 24924 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0529 22:03:46.744240 24924 net.cpp:150] Setting up scale4e_branch2b
I0529 22:03:46.744248 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.744251 24924 net.cpp:165] Memory required for data: 3407872084
I0529 22:03:46.744262 24924 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0529 22:03:46.744274 24924 net.cpp:100] Creating Layer res4e_branch2b_relu
I0529 22:03:46.744280 24924 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0529 22:03:46.744293 24924 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0529 22:03:46.744640 24924 net.cpp:150] Setting up res4e_branch2b_relu
I0529 22:03:46.744648 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.744652 24924 net.cpp:165] Memory required for data: 3411148884
I0529 22:03:46.744657 24924 layer_factory.hpp:77] Creating layer res4e_branch2c
I0529 22:03:46.744674 24924 net.cpp:100] Creating Layer res4e_branch2c
I0529 22:03:46.744681 24924 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0529 22:03:46.744699 24924 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0529 22:03:46.746356 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.746371 24924 net.cpp:150] Setting up res4e_branch2c
I0529 22:03:46.746382 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.746387 24924 net.cpp:165] Memory required for data: 3424256084
I0529 22:03:46.746398 24924 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0529 22:03:46.746412 24924 net.cpp:100] Creating Layer bn4e_branch2c
I0529 22:03:46.746419 24924 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0529 22:03:46.746434 24924 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0529 22:03:46.746616 24924 net.cpp:150] Setting up bn4e_branch2c
I0529 22:03:46.746623 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.746626 24924 net.cpp:165] Memory required for data: 3437363284
I0529 22:03:46.746644 24924 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0529 22:03:46.746656 24924 net.cpp:100] Creating Layer scale4e_branch2c
I0529 22:03:46.746662 24924 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0529 22:03:46.746676 24924 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0529 22:03:46.746726 24924 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0529 22:03:46.746852 24924 net.cpp:150] Setting up scale4e_branch2c
I0529 22:03:46.746860 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.746862 24924 net.cpp:165] Memory required for data: 3450470484
I0529 22:03:46.746875 24924 layer_factory.hpp:77] Creating layer res4e
I0529 22:03:46.746886 24924 net.cpp:100] Creating Layer res4e
I0529 22:03:46.746891 24924 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0529 22:03:46.746902 24924 net.cpp:444] res4e <- res4e_branch2c
I0529 22:03:46.746915 24924 net.cpp:418] res4e -> res4e
I0529 22:03:46.746949 24924 net.cpp:150] Setting up res4e
I0529 22:03:46.746958 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.746961 24924 net.cpp:165] Memory required for data: 3463577684
I0529 22:03:46.746966 24924 layer_factory.hpp:77] Creating layer res4e_relu
I0529 22:03:46.746978 24924 net.cpp:100] Creating Layer res4e_relu
I0529 22:03:46.746982 24924 net.cpp:444] res4e_relu <- res4e
I0529 22:03:46.746995 24924 net.cpp:405] res4e_relu -> res4e (in-place)
I0529 22:03:46.747139 24924 net.cpp:150] Setting up res4e_relu
I0529 22:03:46.747146 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.747149 24924 net.cpp:165] Memory required for data: 3476684884
I0529 22:03:46.747154 24924 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0529 22:03:46.747166 24924 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0529 22:03:46.747171 24924 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0529 22:03:46.747185 24924 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0529 22:03:46.747200 24924 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0529 22:03:46.747246 24924 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0529 22:03:46.747254 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.747259 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.747262 24924 net.cpp:165] Memory required for data: 3502899284
I0529 22:03:46.747267 24924 layer_factory.hpp:77] Creating layer res4f_branch2a
I0529 22:03:46.747283 24924 net.cpp:100] Creating Layer res4f_branch2a
I0529 22:03:46.747289 24924 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0529 22:03:46.747305 24924 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0529 22:03:46.748419 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.748433 24924 net.cpp:150] Setting up res4f_branch2a
I0529 22:03:46.748441 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.748445 24924 net.cpp:165] Memory required for data: 3506176084
I0529 22:03:46.748456 24924 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0529 22:03:46.748471 24924 net.cpp:100] Creating Layer bn4f_branch2a
I0529 22:03:46.748476 24924 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0529 22:03:46.748491 24924 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0529 22:03:46.748668 24924 net.cpp:150] Setting up bn4f_branch2a
I0529 22:03:46.748674 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.748677 24924 net.cpp:165] Memory required for data: 3509452884
I0529 22:03:46.748694 24924 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0529 22:03:46.748708 24924 net.cpp:100] Creating Layer scale4f_branch2a
I0529 22:03:46.748714 24924 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0529 22:03:46.748728 24924 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0529 22:03:46.748777 24924 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0529 22:03:46.748903 24924 net.cpp:150] Setting up scale4f_branch2a
I0529 22:03:46.748914 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.748917 24924 net.cpp:165] Memory required for data: 3512729684
I0529 22:03:46.748929 24924 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0529 22:03:46.748939 24924 net.cpp:100] Creating Layer res4f_branch2a_relu
I0529 22:03:46.748945 24924 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0529 22:03:46.748956 24924 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0529 22:03:46.749100 24924 net.cpp:150] Setting up res4f_branch2a_relu
I0529 22:03:46.749107 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.749110 24924 net.cpp:165] Memory required for data: 3516006484
I0529 22:03:46.749115 24924 layer_factory.hpp:77] Creating layer res4f_branch2b
I0529 22:03:46.749131 24924 net.cpp:100] Creating Layer res4f_branch2b
I0529 22:03:46.749137 24924 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0529 22:03:46.749152 24924 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0529 22:03:46.751281 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0529 22:03:46.751503 24924 net.cpp:150] Setting up res4f_branch2b
I0529 22:03:46.751515 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.751519 24924 net.cpp:165] Memory required for data: 3519283284
I0529 22:03:46.751533 24924 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0529 22:03:46.751552 24924 net.cpp:100] Creating Layer bn4f_branch2b
I0529 22:03:46.751560 24924 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0529 22:03:46.751576 24924 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0529 22:03:46.751765 24924 net.cpp:150] Setting up bn4f_branch2b
I0529 22:03:46.751771 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.751775 24924 net.cpp:165] Memory required for data: 3522560084
I0529 22:03:46.751791 24924 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0529 22:03:46.751806 24924 net.cpp:100] Creating Layer scale4f_branch2b
I0529 22:03:46.751811 24924 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0529 22:03:46.751827 24924 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0529 22:03:46.751879 24924 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0529 22:03:46.752005 24924 net.cpp:150] Setting up scale4f_branch2b
I0529 22:03:46.752012 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.752015 24924 net.cpp:165] Memory required for data: 3525836884
I0529 22:03:46.752027 24924 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0529 22:03:46.752039 24924 net.cpp:100] Creating Layer res4f_branch2b_relu
I0529 22:03:46.752045 24924 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0529 22:03:46.752058 24924 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0529 22:03:46.752204 24924 net.cpp:150] Setting up res4f_branch2b_relu
I0529 22:03:46.752213 24924 net.cpp:157] Top shape: 1 256 40 80 (819200)
I0529 22:03:46.752214 24924 net.cpp:165] Memory required for data: 3529113684
I0529 22:03:46.752221 24924 layer_factory.hpp:77] Creating layer res4f_branch2c
I0529 22:03:46.752238 24924 net.cpp:100] Creating Layer res4f_branch2c
I0529 22:03:46.752243 24924 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0529 22:03:46.752259 24924 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0529 22:03:46.754206 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.754225 24924 net.cpp:150] Setting up res4f_branch2c
I0529 22:03:46.754235 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.754238 24924 net.cpp:165] Memory required for data: 3542220884
I0529 22:03:46.754253 24924 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0529 22:03:46.754276 24924 net.cpp:100] Creating Layer bn4f_branch2c
I0529 22:03:46.754283 24924 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0529 22:03:46.754300 24924 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0529 22:03:46.754492 24924 net.cpp:150] Setting up bn4f_branch2c
I0529 22:03:46.754498 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.754500 24924 net.cpp:165] Memory required for data: 3555328084
I0529 22:03:46.754549 24924 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0529 22:03:46.754567 24924 net.cpp:100] Creating Layer scale4f_branch2c
I0529 22:03:46.754573 24924 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0529 22:03:46.754586 24924 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0529 22:03:46.754637 24924 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0529 22:03:46.754768 24924 net.cpp:150] Setting up scale4f_branch2c
I0529 22:03:46.754776 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.754778 24924 net.cpp:165] Memory required for data: 3568435284
I0529 22:03:46.754791 24924 layer_factory.hpp:77] Creating layer res4f
I0529 22:03:46.754802 24924 net.cpp:100] Creating Layer res4f
I0529 22:03:46.754808 24924 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0529 22:03:46.754819 24924 net.cpp:444] res4f <- res4f_branch2c
I0529 22:03:46.754832 24924 net.cpp:418] res4f -> res4f
I0529 22:03:46.754868 24924 net.cpp:150] Setting up res4f
I0529 22:03:46.754876 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.754879 24924 net.cpp:165] Memory required for data: 3581542484
I0529 22:03:46.754884 24924 layer_factory.hpp:77] Creating layer res4f_relu
I0529 22:03:46.754894 24924 net.cpp:100] Creating Layer res4f_relu
I0529 22:03:46.754899 24924 net.cpp:444] res4f_relu <- res4f
I0529 22:03:46.754914 24924 net.cpp:405] res4f_relu -> res4f (in-place)
I0529 22:03:46.755285 24924 net.cpp:150] Setting up res4f_relu
I0529 22:03:46.755293 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.755296 24924 net.cpp:165] Memory required for data: 3594649684
I0529 22:03:46.755301 24924 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0529 22:03:46.755316 24924 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0529 22:03:46.755321 24924 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0529 22:03:46.755336 24924 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0529 22:03:46.755352 24924 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0529 22:03:46.755367 24924 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0529 22:03:46.755425 24924 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0529 22:03:46.755434 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.755439 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.755445 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:46.755448 24924 net.cpp:165] Memory required for data: 3633971284
I0529 22:03:46.755452 24924 layer_factory.hpp:77] Creating layer res5a_branch1
I0529 22:03:46.755470 24924 net.cpp:100] Creating Layer res5a_branch1
I0529 22:03:46.755476 24924 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0529 22:03:46.755492 24924 net.cpp:418] res5a_branch1 -> res5a_branch1
I0529 22:03:46.760749 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0529 22:03:46.760771 24924 net.cpp:150] Setting up res5a_branch1
I0529 22:03:46.760787 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.760790 24924 net.cpp:165] Memory required for data: 3660185684
I0529 22:03:46.760812 24924 layer_factory.hpp:77] Creating layer bn5a_branch1
I0529 22:03:46.760840 24924 net.cpp:100] Creating Layer bn5a_branch1
I0529 22:03:46.760851 24924 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0529 22:03:46.760871 24924 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0529 22:03:46.761075 24924 net.cpp:150] Setting up bn5a_branch1
I0529 22:03:46.761082 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.761085 24924 net.cpp:165] Memory required for data: 3686400084
I0529 22:03:46.761102 24924 layer_factory.hpp:77] Creating layer scale5a_branch1
I0529 22:03:46.761118 24924 net.cpp:100] Creating Layer scale5a_branch1
I0529 22:03:46.761124 24924 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0529 22:03:46.761137 24924 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0529 22:03:46.761190 24924 layer_factory.hpp:77] Creating layer scale5a_branch1
I0529 22:03:46.761323 24924 net.cpp:150] Setting up scale5a_branch1
I0529 22:03:46.761330 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.761333 24924 net.cpp:165] Memory required for data: 3712614484
I0529 22:03:46.761345 24924 layer_factory.hpp:77] Creating layer res5a_branch2a
I0529 22:03:46.761363 24924 net.cpp:100] Creating Layer res5a_branch2a
I0529 22:03:46.761370 24924 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0529 22:03:46.761385 24924 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0529 22:03:46.763447 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.763464 24924 net.cpp:150] Setting up res5a_branch2a
I0529 22:03:46.763474 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.763478 24924 net.cpp:165] Memory required for data: 3719168084
I0529 22:03:46.763490 24924 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0529 22:03:46.763507 24924 net.cpp:100] Creating Layer bn5a_branch2a
I0529 22:03:46.763514 24924 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0529 22:03:46.763530 24924 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0529 22:03:46.763720 24924 net.cpp:150] Setting up bn5a_branch2a
I0529 22:03:46.763726 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.763730 24924 net.cpp:165] Memory required for data: 3725721684
I0529 22:03:46.763746 24924 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0529 22:03:46.763761 24924 net.cpp:100] Creating Layer scale5a_branch2a
I0529 22:03:46.763767 24924 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0529 22:03:46.763780 24924 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0529 22:03:46.763830 24924 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0529 22:03:46.763962 24924 net.cpp:150] Setting up scale5a_branch2a
I0529 22:03:46.763968 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.763972 24924 net.cpp:165] Memory required for data: 3732275284
I0529 22:03:46.763983 24924 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0529 22:03:46.763995 24924 net.cpp:100] Creating Layer res5a_branch2a_relu
I0529 22:03:46.764001 24924 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0529 22:03:46.764015 24924 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0529 22:03:46.764158 24924 net.cpp:150] Setting up res5a_branch2a_relu
I0529 22:03:46.764165 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.764168 24924 net.cpp:165] Memory required for data: 3738828884
I0529 22:03:46.764173 24924 layer_factory.hpp:77] Creating layer res5a_branch2b
I0529 22:03:46.764190 24924 net.cpp:100] Creating Layer res5a_branch2b
I0529 22:03:46.764196 24924 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0529 22:03:46.764211 24924 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0529 22:03:46.769266 24924 net.cpp:150] Setting up res5a_branch2b
I0529 22:03:46.769297 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.769300 24924 net.cpp:165] Memory required for data: 3745382484
I0529 22:03:46.769326 24924 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0529 22:03:46.769356 24924 net.cpp:100] Creating Layer bn5a_branch2b
I0529 22:03:46.769366 24924 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0529 22:03:46.769385 24924 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0529 22:03:46.769594 24924 net.cpp:150] Setting up bn5a_branch2b
I0529 22:03:46.769601 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.769603 24924 net.cpp:165] Memory required for data: 3751936084
I0529 22:03:46.769621 24924 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0529 22:03:46.769637 24924 net.cpp:100] Creating Layer scale5a_branch2b
I0529 22:03:46.769644 24924 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0529 22:03:46.769657 24924 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0529 22:03:46.769709 24924 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0529 22:03:46.769843 24924 net.cpp:150] Setting up scale5a_branch2b
I0529 22:03:46.769850 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.769853 24924 net.cpp:165] Memory required for data: 3758489684
I0529 22:03:46.769865 24924 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0529 22:03:46.769877 24924 net.cpp:100] Creating Layer res5a_branch2b_relu
I0529 22:03:46.769883 24924 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0529 22:03:46.769896 24924 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0529 22:03:46.770083 24924 net.cpp:150] Setting up res5a_branch2b_relu
I0529 22:03:46.770090 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.770093 24924 net.cpp:165] Memory required for data: 3765043284
I0529 22:03:46.770097 24924 layer_factory.hpp:77] Creating layer res5a_branch2c
I0529 22:03:46.770117 24924 net.cpp:100] Creating Layer res5a_branch2c
I0529 22:03:46.770123 24924 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0529 22:03:46.770138 24924 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0529 22:03:46.773452 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0529 22:03:46.773473 24924 net.cpp:150] Setting up res5a_branch2c
I0529 22:03:46.773488 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.773491 24924 net.cpp:165] Memory required for data: 3791257684
I0529 22:03:46.773511 24924 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0529 22:03:46.773540 24924 net.cpp:100] Creating Layer bn5a_branch2c
I0529 22:03:46.773550 24924 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0529 22:03:46.773572 24924 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0529 22:03:46.773784 24924 net.cpp:150] Setting up bn5a_branch2c
I0529 22:03:46.773792 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.773795 24924 net.cpp:165] Memory required for data: 3817472084
I0529 22:03:46.773813 24924 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0529 22:03:46.773828 24924 net.cpp:100] Creating Layer scale5a_branch2c
I0529 22:03:46.773834 24924 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0529 22:03:46.773849 24924 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0529 22:03:46.773902 24924 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0529 22:03:46.774035 24924 net.cpp:150] Setting up scale5a_branch2c
I0529 22:03:46.774044 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.774046 24924 net.cpp:165] Memory required for data: 3843686484
I0529 22:03:46.774058 24924 layer_factory.hpp:77] Creating layer res5a
I0529 22:03:46.774070 24924 net.cpp:100] Creating Layer res5a
I0529 22:03:46.774075 24924 net.cpp:444] res5a <- res5a_branch1
I0529 22:03:46.774086 24924 net.cpp:444] res5a <- res5a_branch2c
I0529 22:03:46.774097 24924 net.cpp:418] res5a -> res5a
I0529 22:03:46.774133 24924 net.cpp:150] Setting up res5a
I0529 22:03:46.774142 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.774145 24924 net.cpp:165] Memory required for data: 3869900884
I0529 22:03:46.774150 24924 layer_factory.hpp:77] Creating layer res5a_relu
I0529 22:03:46.774160 24924 net.cpp:100] Creating Layer res5a_relu
I0529 22:03:46.774166 24924 net.cpp:444] res5a_relu <- res5a
I0529 22:03:46.774178 24924 net.cpp:405] res5a_relu -> res5a (in-place)
I0529 22:03:46.774585 24924 net.cpp:150] Setting up res5a_relu
I0529 22:03:46.774592 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.774596 24924 net.cpp:165] Memory required for data: 3896115284
I0529 22:03:46.774601 24924 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0529 22:03:46.774613 24924 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0529 22:03:46.774621 24924 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0529 22:03:46.774636 24924 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0529 22:03:46.774652 24924 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0529 22:03:46.774699 24924 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0529 22:03:46.774708 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.774713 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.774716 24924 net.cpp:165] Memory required for data: 3948544084
I0529 22:03:46.774721 24924 layer_factory.hpp:77] Creating layer res5b_branch2a
I0529 22:03:46.774739 24924 net.cpp:100] Creating Layer res5b_branch2a
I0529 22:03:46.774744 24924 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0529 22:03:46.774760 24924 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0529 22:03:46.778038 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.778060 24924 net.cpp:150] Setting up res5b_branch2a
I0529 22:03:46.778075 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.778079 24924 net.cpp:165] Memory required for data: 3955097684
I0529 22:03:46.778100 24924 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0529 22:03:46.778126 24924 net.cpp:100] Creating Layer bn5b_branch2a
I0529 22:03:46.778137 24924 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0529 22:03:46.778157 24924 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0529 22:03:46.778359 24924 net.cpp:150] Setting up bn5b_branch2a
I0529 22:03:46.778367 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.778369 24924 net.cpp:165] Memory required for data: 3961651284
I0529 22:03:46.778386 24924 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0529 22:03:46.778403 24924 net.cpp:100] Creating Layer scale5b_branch2a
I0529 22:03:46.778409 24924 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0529 22:03:46.778424 24924 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0529 22:03:46.778473 24924 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0529 22:03:46.778607 24924 net.cpp:150] Setting up scale5b_branch2a
I0529 22:03:46.778615 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.778618 24924 net.cpp:165] Memory required for data: 3968204884
I0529 22:03:46.778630 24924 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0529 22:03:46.778641 24924 net.cpp:100] Creating Layer res5b_branch2a_relu
I0529 22:03:46.778647 24924 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0529 22:03:46.778661 24924 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0529 22:03:46.778807 24924 net.cpp:150] Setting up res5b_branch2a_relu
I0529 22:03:46.778815 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.778817 24924 net.cpp:165] Memory required for data: 3974758484
I0529 22:03:46.778822 24924 layer_factory.hpp:77] Creating layer res5b_branch2b
I0529 22:03:46.778839 24924 net.cpp:100] Creating Layer res5b_branch2b
I0529 22:03:46.778846 24924 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0529 22:03:46.778861 24924 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0529 22:03:46.783946 24924 net.cpp:150] Setting up res5b_branch2b
I0529 22:03:46.783977 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.783980 24924 net.cpp:165] Memory required for data: 3981312084
I0529 22:03:46.784005 24924 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0529 22:03:46.784036 24924 net.cpp:100] Creating Layer bn5b_branch2b
I0529 22:03:46.784047 24924 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0529 22:03:46.784066 24924 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0529 22:03:46.784276 24924 net.cpp:150] Setting up bn5b_branch2b
I0529 22:03:46.784282 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.784284 24924 net.cpp:165] Memory required for data: 3987865684
I0529 22:03:46.784301 24924 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0529 22:03:46.784317 24924 net.cpp:100] Creating Layer scale5b_branch2b
I0529 22:03:46.784323 24924 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0529 22:03:46.784338 24924 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0529 22:03:46.784389 24924 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0529 22:03:46.784523 24924 net.cpp:150] Setting up scale5b_branch2b
I0529 22:03:46.784530 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.784533 24924 net.cpp:165] Memory required for data: 3994419284
I0529 22:03:46.784545 24924 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0529 22:03:46.784556 24924 net.cpp:100] Creating Layer res5b_branch2b_relu
I0529 22:03:46.784562 24924 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0529 22:03:46.784575 24924 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0529 22:03:46.784759 24924 net.cpp:150] Setting up res5b_branch2b_relu
I0529 22:03:46.784766 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.784770 24924 net.cpp:165] Memory required for data: 4000972884
I0529 22:03:46.784775 24924 layer_factory.hpp:77] Creating layer res5b_branch2c
I0529 22:03:46.784792 24924 net.cpp:100] Creating Layer res5b_branch2c
I0529 22:03:46.784798 24924 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0529 22:03:46.784814 24924 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0529 22:03:46.788132 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0529 22:03:46.788156 24924 net.cpp:150] Setting up res5b_branch2c
I0529 22:03:46.788168 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.788172 24924 net.cpp:165] Memory required for data: 4027187284
I0529 22:03:46.788194 24924 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0529 22:03:46.788220 24924 net.cpp:100] Creating Layer bn5b_branch2c
I0529 22:03:46.788231 24924 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0529 22:03:46.788251 24924 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0529 22:03:46.788455 24924 net.cpp:150] Setting up bn5b_branch2c
I0529 22:03:46.788462 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.788465 24924 net.cpp:165] Memory required for data: 4053401684
I0529 22:03:46.788482 24924 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0529 22:03:46.788498 24924 net.cpp:100] Creating Layer scale5b_branch2c
I0529 22:03:46.788504 24924 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0529 22:03:46.788518 24924 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0529 22:03:46.788571 24924 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0529 22:03:46.788707 24924 net.cpp:150] Setting up scale5b_branch2c
I0529 22:03:46.788714 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.788717 24924 net.cpp:165] Memory required for data: 4079616084
I0529 22:03:46.788729 24924 layer_factory.hpp:77] Creating layer res5b
I0529 22:03:46.788743 24924 net.cpp:100] Creating Layer res5b
I0529 22:03:46.788748 24924 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0529 22:03:46.788760 24924 net.cpp:444] res5b <- res5b_branch2c
I0529 22:03:46.788771 24924 net.cpp:418] res5b -> res5b
I0529 22:03:46.788808 24924 net.cpp:150] Setting up res5b
I0529 22:03:46.788817 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.788820 24924 net.cpp:165] Memory required for data: 4105830484
I0529 22:03:46.788825 24924 layer_factory.hpp:77] Creating layer res5b_relu
I0529 22:03:46.788836 24924 net.cpp:100] Creating Layer res5b_relu
I0529 22:03:46.788841 24924 net.cpp:444] res5b_relu <- res5b
I0529 22:03:46.788856 24924 net.cpp:405] res5b_relu -> res5b (in-place)
I0529 22:03:46.789301 24924 net.cpp:150] Setting up res5b_relu
I0529 22:03:46.789310 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.789314 24924 net.cpp:165] Memory required for data: 4132044884
I0529 22:03:46.789319 24924 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0529 22:03:46.789331 24924 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0529 22:03:46.789338 24924 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0529 22:03:46.789352 24924 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0529 22:03:46.789371 24924 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0529 22:03:46.789420 24924 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0529 22:03:46.789429 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.789434 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.789438 24924 net.cpp:165] Memory required for data: 4184473684
I0529 22:03:46.789443 24924 layer_factory.hpp:77] Creating layer res5c_branch2a
I0529 22:03:46.789461 24924 net.cpp:100] Creating Layer res5c_branch2a
I0529 22:03:46.789468 24924 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0529 22:03:46.789484 24924 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0529 22:03:46.792680 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:46.792701 24924 net.cpp:150] Setting up res5c_branch2a
I0529 22:03:46.792714 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.792718 24924 net.cpp:165] Memory required for data: 4191027284
I0529 22:03:46.792737 24924 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0529 22:03:46.792760 24924 net.cpp:100] Creating Layer bn5c_branch2a
I0529 22:03:46.792770 24924 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0529 22:03:46.792788 24924 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0529 22:03:46.792999 24924 net.cpp:150] Setting up bn5c_branch2a
I0529 22:03:46.793007 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.793010 24924 net.cpp:165] Memory required for data: 4197580884
I0529 22:03:46.793027 24924 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0529 22:03:46.793043 24924 net.cpp:100] Creating Layer scale5c_branch2a
I0529 22:03:46.793049 24924 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0529 22:03:46.793063 24924 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0529 22:03:46.793115 24924 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0529 22:03:46.793251 24924 net.cpp:150] Setting up scale5c_branch2a
I0529 22:03:46.793258 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.793262 24924 net.cpp:165] Memory required for data: 4204134484
I0529 22:03:46.793273 24924 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0529 22:03:46.793287 24924 net.cpp:100] Creating Layer res5c_branch2a_relu
I0529 22:03:46.793292 24924 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0529 22:03:46.793304 24924 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0529 22:03:46.793452 24924 net.cpp:150] Setting up res5c_branch2a_relu
I0529 22:03:46.793459 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.793462 24924 net.cpp:165] Memory required for data: 4210688084
I0529 22:03:46.793467 24924 layer_factory.hpp:77] Creating layer res5c_branch2b
I0529 22:03:46.793483 24924 net.cpp:100] Creating Layer res5c_branch2b
I0529 22:03:46.793490 24924 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0529 22:03:46.793504 24924 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0529 22:03:46.798547 24924 net.cpp:150] Setting up res5c_branch2b
I0529 22:03:46.798578 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.798580 24924 net.cpp:165] Memory required for data: 4217241684
I0529 22:03:46.798602 24924 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0529 22:03:46.798630 24924 net.cpp:100] Creating Layer bn5c_branch2b
I0529 22:03:46.798642 24924 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0529 22:03:46.798663 24924 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0529 22:03:46.798876 24924 net.cpp:150] Setting up bn5c_branch2b
I0529 22:03:46.798882 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.798885 24924 net.cpp:165] Memory required for data: 4223795284
I0529 22:03:46.798902 24924 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0529 22:03:46.798918 24924 net.cpp:100] Creating Layer scale5c_branch2b
I0529 22:03:46.798923 24924 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0529 22:03:46.798938 24924 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0529 22:03:46.798990 24924 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0529 22:03:46.799136 24924 net.cpp:150] Setting up scale5c_branch2b
I0529 22:03:46.799144 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.799146 24924 net.cpp:165] Memory required for data: 4230348884
I0529 22:03:46.799160 24924 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0529 22:03:46.799170 24924 net.cpp:100] Creating Layer res5c_branch2b_relu
I0529 22:03:46.799176 24924 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0529 22:03:46.799190 24924 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0529 22:03:46.799378 24924 net.cpp:150] Setting up res5c_branch2b_relu
I0529 22:03:46.799384 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:46.799387 24924 net.cpp:165] Memory required for data: 4236902484
I0529 22:03:46.799392 24924 layer_factory.hpp:77] Creating layer res5c_branch2c
I0529 22:03:46.799409 24924 net.cpp:100] Creating Layer res5c_branch2c
I0529 22:03:46.799417 24924 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0529 22:03:46.799432 24924 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0529 22:03:46.802639 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 57624
I0529 22:03:46.802659 24924 net.cpp:150] Setting up res5c_branch2c
I0529 22:03:46.802671 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.802675 24924 net.cpp:165] Memory required for data: 4263116884
I0529 22:03:46.802691 24924 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0529 22:03:46.802713 24924 net.cpp:100] Creating Layer bn5c_branch2c
I0529 22:03:46.802722 24924 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0529 22:03:46.802739 24924 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0529 22:03:46.802937 24924 net.cpp:150] Setting up bn5c_branch2c
I0529 22:03:46.802944 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.802947 24924 net.cpp:165] Memory required for data: 4289331284
I0529 22:03:46.802963 24924 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0529 22:03:46.802979 24924 net.cpp:100] Creating Layer scale5c_branch2c
I0529 22:03:46.802985 24924 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0529 22:03:46.802999 24924 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0529 22:03:46.803051 24924 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0529 22:03:46.803186 24924 net.cpp:150] Setting up scale5c_branch2c
I0529 22:03:46.803194 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.803196 24924 net.cpp:165] Memory required for data: 4315545684
I0529 22:03:46.803208 24924 layer_factory.hpp:77] Creating layer res5c
I0529 22:03:46.803221 24924 net.cpp:100] Creating Layer res5c
I0529 22:03:46.803227 24924 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0529 22:03:46.803239 24924 net.cpp:444] res5c <- res5c_branch2c
I0529 22:03:46.803249 24924 net.cpp:418] res5c -> res5c
I0529 22:03:46.803287 24924 net.cpp:150] Setting up res5c
I0529 22:03:46.803294 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.803298 24924 net.cpp:165] Memory required for data: 4341760084
I0529 22:03:46.803303 24924 layer_factory.hpp:77] Creating layer res5c_relu
I0529 22:03:46.803313 24924 net.cpp:100] Creating Layer res5c_relu
I0529 22:03:46.803318 24924 net.cpp:444] res5c_relu <- res5c
I0529 22:03:46.803331 24924 net.cpp:405] res5c_relu -> res5c (in-place)
I0529 22:03:46.803477 24924 net.cpp:150] Setting up res5c_relu
I0529 22:03:46.803483 24924 net.cpp:157] Top shape: 1 2048 40 80 (6553600)
I0529 22:03:46.803486 24924 net.cpp:165] Memory required for data: 4367974484
I0529 22:03:46.803491 24924 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0529 22:03:46.803511 24924 net.cpp:100] Creating Layer rpn_conv/3x3
I0529 22:03:46.803517 24924 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0529 22:03:46.803534 24924 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0529 22:03:47.278401 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:47.278426 24924 net.cpp:150] Setting up rpn_conv/3x3
I0529 22:03:47.278456 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:47.278461 24924 net.cpp:165] Memory required for data: 4374528084
I0529 22:03:47.278483 24924 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0529 22:03:47.278506 24924 net.cpp:100] Creating Layer rpn_relu/3x3
I0529 22:03:47.278515 24924 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0529 22:03:47.278534 24924 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0529 22:03:47.278970 24924 net.cpp:150] Setting up rpn_relu/3x3
I0529 22:03:47.278977 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:47.278980 24924 net.cpp:165] Memory required for data: 4381081684
I0529 22:03:47.279000 24924 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0529 22:03:47.279012 24924 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0529 22:03:47.279018 24924 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0529 22:03:47.279033 24924 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0529 22:03:47.279052 24924 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0529 22:03:47.279101 24924 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0529 22:03:47.279110 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:47.279115 24924 net.cpp:157] Top shape: 1 512 40 80 (1638400)
I0529 22:03:47.279119 24924 net.cpp:165] Memory required for data: 4394188884
I0529 22:03:47.279124 24924 layer_factory.hpp:77] Creating layer rpn_cls_score
I0529 22:03:47.279146 24924 net.cpp:100] Creating Layer rpn_cls_score
I0529 22:03:47.279152 24924 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0529 22:03:47.279170 24924 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0529 22:03:47.281188 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:47.281204 24924 net.cpp:150] Setting up rpn_cls_score
I0529 22:03:47.281213 24924 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0529 22:03:47.281216 24924 net.cpp:165] Memory required for data: 4394470484
I0529 22:03:47.281229 24924 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0529 22:03:47.281241 24924 net.cpp:100] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0529 22:03:47.281249 24924 net.cpp:444] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0529 22:03:47.281263 24924 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0529 22:03:47.281280 24924 net.cpp:418] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0529 22:03:47.281327 24924 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0529 22:03:47.281337 24924 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0529 22:03:47.281342 24924 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0529 22:03:47.281345 24924 net.cpp:165] Memory required for data: 4395033684
I0529 22:03:47.281350 24924 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0529 22:03:47.281366 24924 net.cpp:100] Creating Layer rpn_bbox_pred
I0529 22:03:47.281373 24924 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0529 22:03:47.281389 24924 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0529 22:03:47.284543 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:47.284557 24924 net.cpp:150] Setting up rpn_bbox_pred
I0529 22:03:47.284566 24924 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0529 22:03:47.284569 24924 net.cpp:165] Memory required for data: 4395596884
I0529 22:03:47.284581 24924 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0529 22:03:47.284593 24924 net.cpp:100] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0529 22:03:47.284600 24924 net.cpp:444] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0529 22:03:47.284615 24924 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0529 22:03:47.284631 24924 net.cpp:418] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0529 22:03:47.284678 24924 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0529 22:03:47.284687 24924 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0529 22:03:47.284692 24924 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0529 22:03:47.284695 24924 net.cpp:165] Memory required for data: 4396723284
I0529 22:03:47.284699 24924 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0529 22:03:47.284714 24924 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0529 22:03:47.284720 24924 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0529 22:03:47.284734 24924 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0529 22:03:47.284773 24924 net.cpp:150] Setting up rpn_cls_score_reshape
I0529 22:03:47.284781 24924 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0529 22:03:47.284785 24924 net.cpp:165] Memory required for data: 4397004884
I0529 22:03:47.284790 24924 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0529 22:03:47.284801 24924 net.cpp:100] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0529 22:03:47.284808 24924 net.cpp:444] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0529 22:03:47.284821 24924 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0529 22:03:47.284837 24924 net.cpp:418] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0529 22:03:47.284880 24924 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0529 22:03:47.284888 24924 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0529 22:03:47.284893 24924 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0529 22:03:47.284898 24924 net.cpp:165] Memory required for data: 4397568084
I0529 22:03:47.284901 24924 layer_factory.hpp:77] Creating layer rpn-data
I0529 22:03:47.285217 24924 net.cpp:100] Creating Layer rpn-data
I0529 22:03:47.285226 24924 net.cpp:444] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0529 22:03:47.285240 24924 net.cpp:444] rpn-data <- gt_boxes_input-data_2_split_0
I0529 22:03:47.285249 24924 net.cpp:444] rpn-data <- im_info_input-data_1_split_0
I0529 22:03:47.285259 24924 net.cpp:444] rpn-data <- data_input-data_0_split_1
I0529 22:03:47.285269 24924 net.cpp:418] rpn-data -> rpn_labels
I0529 22:03:47.285286 24924 net.cpp:418] rpn-data -> rpn_bbox_targets
I0529 22:03:47.285302 24924 net.cpp:418] rpn-data -> rpn_bbox_inside_weights
I0529 22:03:47.285320 24924 net.cpp:418] rpn-data -> rpn_bbox_outside_weights
I0529 22:03:47.285799 24924 net.cpp:150] Setting up rpn-data
I0529 22:03:47.285810 24924 net.cpp:157] Top shape: 1 1 440 80 (35200)
I0529 22:03:47.285816 24924 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0529 22:03:47.285821 24924 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0529 22:03:47.285826 24924 net.cpp:157] Top shape: 1 44 40 80 (140800)
I0529 22:03:47.285830 24924 net.cpp:165] Memory required for data: 4399398484
I0529 22:03:47.285835 24924 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0529 22:03:47.285851 24924 net.cpp:100] Creating Layer rpn_loss_cls
I0529 22:03:47.285857 24924 net.cpp:444] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0529 22:03:47.285871 24924 net.cpp:444] rpn_loss_cls <- rpn_labels
I0529 22:03:47.285881 24924 net.cpp:418] rpn_loss_cls -> rpn_cls_loss
I0529 22:03:47.285915 24924 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0529 22:03:47.286283 24924 net.cpp:150] Setting up rpn_loss_cls
I0529 22:03:47.286293 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.286295 24924 net.cpp:160]     with loss weight 1
I0529 22:03:47.286304 24924 net.cpp:165] Memory required for data: 4399398488
I0529 22:03:47.286309 24924 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0529 22:03:47.286342 24924 net.cpp:100] Creating Layer rpn_loss_bbox
I0529 22:03:47.286350 24924 net.cpp:444] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0529 22:03:47.286362 24924 net.cpp:444] rpn_loss_bbox <- rpn_bbox_targets
I0529 22:03:47.286370 24924 net.cpp:444] rpn_loss_bbox <- rpn_bbox_inside_weights
I0529 22:03:47.286378 24924 net.cpp:444] rpn_loss_bbox <- rpn_bbox_outside_weights
I0529 22:03:47.286388 24924 net.cpp:418] rpn_loss_bbox -> rpn_loss_bbox
I0529 22:03:47.288640 24924 net.cpp:150] Setting up rpn_loss_bbox
I0529 22:03:47.288650 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.288653 24924 net.cpp:160]     with loss weight 1
I0529 22:03:47.288658 24924 net.cpp:165] Memory required for data: 4399398492
I0529 22:03:47.288668 24924 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0529 22:03:47.288681 24924 net.cpp:100] Creating Layer rpn_cls_prob
I0529 22:03:47.288687 24924 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0529 22:03:47.288703 24924 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0529 22:03:47.289165 24924 net.cpp:150] Setting up rpn_cls_prob
I0529 22:03:47.289175 24924 net.cpp:157] Top shape: 1 2 440 80 (70400)
I0529 22:03:47.289178 24924 net.cpp:165] Memory required for data: 4399680092
I0529 22:03:47.289183 24924 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0529 22:03:47.289199 24924 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0529 22:03:47.289206 24924 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0529 22:03:47.289222 24924 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0529 22:03:47.289261 24924 net.cpp:150] Setting up rpn_cls_prob_reshape
I0529 22:03:47.289270 24924 net.cpp:157] Top shape: 1 22 40 80 (70400)
I0529 22:03:47.289274 24924 net.cpp:165] Memory required for data: 4399961692
I0529 22:03:47.289278 24924 layer_factory.hpp:77] Creating layer proposal
I0529 22:03:47.291462 24924 net.cpp:100] Creating Layer proposal
I0529 22:03:47.291487 24924 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0529 22:03:47.291513 24924 net.cpp:444] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0529 22:03:47.291523 24924 net.cpp:444] proposal <- im_info_input-data_1_split_1
I0529 22:03:47.291537 24924 net.cpp:418] proposal -> rpn_rois
I0529 22:03:47.292825 24924 net.cpp:150] Setting up proposal
I0529 22:03:47.292845 24924 net.cpp:157] Top shape: 1 5 (5)
I0529 22:03:47.292850 24924 net.cpp:165] Memory required for data: 4399961712
I0529 22:03:47.292858 24924 layer_factory.hpp:77] Creating layer roi-data
I0529 22:03:47.292999 24924 net.cpp:100] Creating Layer roi-data
I0529 22:03:47.293011 24924 net.cpp:444] roi-data <- rpn_rois
I0529 22:03:47.293028 24924 net.cpp:444] roi-data <- gt_boxes_input-data_2_split_1
I0529 22:03:47.293042 24924 net.cpp:418] roi-data -> rois
I0529 22:03:47.293063 24924 net.cpp:418] roi-data -> labels
I0529 22:03:47.293078 24924 net.cpp:418] roi-data -> bbox_targets
I0529 22:03:47.293093 24924 net.cpp:418] roi-data -> bbox_inside_weights
I0529 22:03:47.293107 24924 net.cpp:418] roi-data -> bbox_outside_weights
I0529 22:03:47.293437 24924 net.cpp:150] Setting up roi-data
I0529 22:03:47.293447 24924 net.cpp:157] Top shape: 1 5 1 1 (5)
I0529 22:03:47.293453 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.293459 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293464 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293469 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293473 24924 net.cpp:165] Memory required for data: 4399961832
I0529 22:03:47.293479 24924 layer_factory.hpp:77] Creating layer rois_roi-data_0_split
I0529 22:03:47.293491 24924 net.cpp:100] Creating Layer rois_roi-data_0_split
I0529 22:03:47.293498 24924 net.cpp:444] rois_roi-data_0_split <- rois
I0529 22:03:47.293512 24924 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_0
I0529 22:03:47.293529 24924 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_1
I0529 22:03:47.293542 24924 net.cpp:418] rois_roi-data_0_split -> rois_roi-data_0_split_2
I0529 22:03:47.293598 24924 net.cpp:150] Setting up rois_roi-data_0_split
I0529 22:03:47.293606 24924 net.cpp:157] Top shape: 1 5 1 1 (5)
I0529 22:03:47.293612 24924 net.cpp:157] Top shape: 1 5 1 1 (5)
I0529 22:03:47.293617 24924 net.cpp:157] Top shape: 1 5 1 1 (5)
I0529 22:03:47.293619 24924 net.cpp:165] Memory required for data: 4399961892
I0529 22:03:47.293624 24924 layer_factory.hpp:77] Creating layer labels_roi-data_1_split
I0529 22:03:47.293634 24924 net.cpp:100] Creating Layer labels_roi-data_1_split
I0529 22:03:47.293640 24924 net.cpp:444] labels_roi-data_1_split <- labels
I0529 22:03:47.293654 24924 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_0
I0529 22:03:47.293669 24924 net.cpp:418] labels_roi-data_1_split -> labels_roi-data_1_split_1
I0529 22:03:47.293711 24924 net.cpp:150] Setting up labels_roi-data_1_split
I0529 22:03:47.293720 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.293725 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.293727 24924 net.cpp:165] Memory required for data: 4399961900
I0529 22:03:47.293732 24924 layer_factory.hpp:77] Creating layer bbox_targets_roi-data_2_split
I0529 22:03:47.293743 24924 net.cpp:100] Creating Layer bbox_targets_roi-data_2_split
I0529 22:03:47.293750 24924 net.cpp:444] bbox_targets_roi-data_2_split <- bbox_targets
I0529 22:03:47.293762 24924 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_0
I0529 22:03:47.293776 24924 net.cpp:418] bbox_targets_roi-data_2_split -> bbox_targets_roi-data_2_split_1
I0529 22:03:47.293820 24924 net.cpp:150] Setting up bbox_targets_roi-data_2_split
I0529 22:03:47.293828 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293833 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293836 24924 net.cpp:165] Memory required for data: 4399961964
I0529 22:03:47.293840 24924 layer_factory.hpp:77] Creating layer bbox_inside_weights_roi-data_3_split
I0529 22:03:47.293850 24924 net.cpp:100] Creating Layer bbox_inside_weights_roi-data_3_split
I0529 22:03:47.293855 24924 net.cpp:444] bbox_inside_weights_roi-data_3_split <- bbox_inside_weights
I0529 22:03:47.293869 24924 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_0
I0529 22:03:47.293884 24924 net.cpp:418] bbox_inside_weights_roi-data_3_split -> bbox_inside_weights_roi-data_3_split_1
I0529 22:03:47.293926 24924 net.cpp:150] Setting up bbox_inside_weights_roi-data_3_split
I0529 22:03:47.293934 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293939 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.293943 24924 net.cpp:165] Memory required for data: 4399962028
I0529 22:03:47.293947 24924 layer_factory.hpp:77] Creating layer conv_new_1
I0529 22:03:47.293970 24924 net.cpp:100] Creating Layer conv_new_1
I0529 22:03:47.293977 24924 net.cpp:444] conv_new_1 <- res5c
I0529 22:03:47.293993 24924 net.cpp:418] conv_new_1 -> conv_new_1
I0529 22:03:47.506202 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:47.506227 24924 net.cpp:150] Setting up conv_new_1
I0529 22:03:47.506255 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:47.506259 24924 net.cpp:165] Memory required for data: 4413069228
I0529 22:03:47.506280 24924 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0529 22:03:47.506304 24924 net.cpp:100] Creating Layer conv_new_1_relu
I0529 22:03:47.506315 24924 net.cpp:444] conv_new_1_relu <- conv_new_1
I0529 22:03:47.506335 24924 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0529 22:03:47.506748 24924 net.cpp:150] Setting up conv_new_1_relu
I0529 22:03:47.506757 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:47.506759 24924 net.cpp:165] Memory required for data: 4426176428
I0529 22:03:47.506779 24924 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0529 22:03:47.506793 24924 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0529 22:03:47.506800 24924 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0529 22:03:47.506814 24924 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0529 22:03:47.506832 24924 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0529 22:03:47.506883 24924 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0529 22:03:47.506891 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:47.506897 24924 net.cpp:157] Top shape: 1 1024 40 80 (3276800)
I0529 22:03:47.506901 24924 net.cpp:165] Memory required for data: 4452390828
I0529 22:03:47.506906 24924 layer_factory.hpp:77] Creating layer rfcn_cls
I0529 22:03:47.506927 24924 net.cpp:100] Creating Layer rfcn_cls
I0529 22:03:47.506933 24924 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0529 22:03:47.506950 24924 net.cpp:418] rfcn_cls -> rfcn_cls
I0529 22:03:47.517961 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:47.517977 24924 net.cpp:150] Setting up rfcn_cls
I0529 22:03:47.517987 24924 net.cpp:157] Top shape: 1 98 40 80 (313600)
I0529 22:03:47.517989 24924 net.cpp:165] Memory required for data: 4453645228
I0529 22:03:47.518002 24924 layer_factory.hpp:77] Creating layer rfcn_bbox
I0529 22:03:47.518023 24924 net.cpp:100] Creating Layer rfcn_bbox
I0529 22:03:47.518030 24924 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0529 22:03:47.518049 24924 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0529 22:03:47.560094 24924 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 64152
I0529 22:03:47.560115 24924 net.cpp:150] Setting up rfcn_bbox
I0529 22:03:47.560145 24924 net.cpp:157] Top shape: 1 392 40 80 (1254400)
I0529 22:03:47.560149 24924 net.cpp:165] Memory required for data: 4458662828
I0529 22:03:47.560169 24924 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0529 22:03:47.560194 24924 net.cpp:100] Creating Layer psroipooled_cls_rois
I0529 22:03:47.560205 24924 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0529 22:03:47.560222 24924 net.cpp:444] psroipooled_cls_rois <- rois_roi-data_0_split_0
I0529 22:03:47.560235 24924 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0529 22:03:47.560257 24924 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0529 22:03:47.560307 24924 net.cpp:150] Setting up psroipooled_cls_rois
I0529 22:03:47.560314 24924 net.cpp:157] Top shape: 1 2 7 7 (98)
I0529 22:03:47.560317 24924 net.cpp:165] Memory required for data: 4458663220
I0529 22:03:47.560322 24924 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0529 22:03:47.560336 24924 net.cpp:100] Creating Layer ave_cls_score_rois
I0529 22:03:47.560343 24924 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0529 22:03:47.560356 24924 net.cpp:418] ave_cls_score_rois -> cls_score
I0529 22:03:47.560534 24924 net.cpp:150] Setting up ave_cls_score_rois
I0529 22:03:47.560544 24924 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 22:03:47.560561 24924 net.cpp:165] Memory required for data: 4458663228
I0529 22:03:47.560566 24924 layer_factory.hpp:77] Creating layer cls_score_ave_cls_score_rois_0_split
I0529 22:03:47.560578 24924 net.cpp:100] Creating Layer cls_score_ave_cls_score_rois_0_split
I0529 22:03:47.560585 24924 net.cpp:444] cls_score_ave_cls_score_rois_0_split <- cls_score
I0529 22:03:47.560600 24924 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_0
I0529 22:03:47.560614 24924 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_1
I0529 22:03:47.560628 24924 net.cpp:418] cls_score_ave_cls_score_rois_0_split -> cls_score_ave_cls_score_rois_0_split_2
I0529 22:03:47.560686 24924 net.cpp:150] Setting up cls_score_ave_cls_score_rois_0_split
I0529 22:03:47.560694 24924 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 22:03:47.560699 24924 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 22:03:47.560705 24924 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 22:03:47.560708 24924 net.cpp:165] Memory required for data: 4458663252
I0529 22:03:47.560714 24924 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0529 22:03:47.560724 24924 net.cpp:100] Creating Layer psroipooled_loc_rois
I0529 22:03:47.560731 24924 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0529 22:03:47.560742 24924 net.cpp:444] psroipooled_loc_rois <- rois_roi-data_0_split_1
I0529 22:03:47.560755 24924 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0529 22:03:47.560770 24924 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0529 22:03:47.560812 24924 net.cpp:150] Setting up psroipooled_loc_rois
I0529 22:03:47.560820 24924 net.cpp:157] Top shape: 1 8 7 7 (392)
I0529 22:03:47.560823 24924 net.cpp:165] Memory required for data: 4458664820
I0529 22:03:47.560828 24924 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0529 22:03:47.560839 24924 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0529 22:03:47.560845 24924 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0529 22:03:47.560860 24924 net.cpp:418] ave_bbox_pred_rois -> bbox_pred
I0529 22:03:47.561024 24924 net.cpp:150] Setting up ave_bbox_pred_rois
I0529 22:03:47.561034 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.561038 24924 net.cpp:165] Memory required for data: 4458664852
I0529 22:03:47.561043 24924 layer_factory.hpp:77] Creating layer bbox_pred_ave_bbox_pred_rois_0_split
I0529 22:03:47.561054 24924 net.cpp:100] Creating Layer bbox_pred_ave_bbox_pred_rois_0_split
I0529 22:03:47.561060 24924 net.cpp:444] bbox_pred_ave_bbox_pred_rois_0_split <- bbox_pred
I0529 22:03:47.561074 24924 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_0
I0529 22:03:47.561090 24924 net.cpp:418] bbox_pred_ave_bbox_pred_rois_0_split -> bbox_pred_ave_bbox_pred_rois_0_split_1
I0529 22:03:47.561136 24924 net.cpp:150] Setting up bbox_pred_ave_bbox_pred_rois_0_split
I0529 22:03:47.561143 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.561148 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.561152 24924 net.cpp:165] Memory required for data: 4458664916
I0529 22:03:47.561156 24924 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0529 22:03:47.561170 24924 net.cpp:100] Creating Layer per_roi_loss_cls
I0529 22:03:47.561177 24924 net.cpp:444] per_roi_loss_cls <- cls_score_ave_cls_score_rois_0_split_0
I0529 22:03:47.561188 24924 net.cpp:444] per_roi_loss_cls <- labels_roi-data_1_split_0
I0529 22:03:47.561200 24924 net.cpp:418] per_roi_loss_cls -> temp_loss_cls
I0529 22:03:47.561216 24924 net.cpp:418] per_roi_loss_cls -> temp_prob_cls
I0529 22:03:47.561229 24924 net.cpp:418] per_roi_loss_cls -> per_roi_loss_cls
I0529 22:03:47.561244 24924 layer_factory.hpp:77] Creating layer per_roi_loss_cls
I0529 22:03:47.561733 24924 net.cpp:150] Setting up per_roi_loss_cls
I0529 22:03:47.561743 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.561748 24924 net.cpp:157] Top shape: 1 2 1 1 (2)
I0529 22:03:47.561754 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.561758 24924 net.cpp:165] Memory required for data: 4458664932
I0529 22:03:47.561764 24924 layer_factory.hpp:77] Creating layer per_roi_loss_bbox
I0529 22:03:47.561776 24924 net.cpp:100] Creating Layer per_roi_loss_bbox
I0529 22:03:47.561784 24924 net.cpp:444] per_roi_loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_0
I0529 22:03:47.561795 24924 net.cpp:444] per_roi_loss_bbox <- bbox_targets_roi-data_2_split_0
I0529 22:03:47.561805 24924 net.cpp:444] per_roi_loss_bbox <- bbox_inside_weights_roi-data_3_split_0
I0529 22:03:47.561816 24924 net.cpp:418] per_roi_loss_bbox -> temp_loss_bbox
I0529 22:03:47.561833 24924 net.cpp:418] per_roi_loss_bbox -> per_roi_loss_bbox
I0529 22:03:47.561897 24924 net.cpp:150] Setting up per_roi_loss_bbox
I0529 22:03:47.561905 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.561911 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.561914 24924 net.cpp:165] Memory required for data: 4458664940
I0529 22:03:47.561919 24924 layer_factory.hpp:77] Creating layer per_roi_loss
I0529 22:03:47.561931 24924 net.cpp:100] Creating Layer per_roi_loss
I0529 22:03:47.561938 24924 net.cpp:444] per_roi_loss <- per_roi_loss_cls
I0529 22:03:47.561949 24924 net.cpp:444] per_roi_loss <- per_roi_loss_bbox
I0529 22:03:47.561959 24924 net.cpp:418] per_roi_loss -> per_roi_loss
I0529 22:03:47.561995 24924 net.cpp:150] Setting up per_roi_loss
I0529 22:03:47.562003 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.562007 24924 net.cpp:165] Memory required for data: 4458664944
I0529 22:03:47.562012 24924 layer_factory.hpp:77] Creating layer annotator_detector
I0529 22:03:47.562026 24924 net.cpp:100] Creating Layer annotator_detector
I0529 22:03:47.562032 24924 net.cpp:444] annotator_detector <- rois_roi-data_0_split_2
I0529 22:03:47.562044 24924 net.cpp:444] annotator_detector <- per_roi_loss
I0529 22:03:47.562052 24924 net.cpp:444] annotator_detector <- labels_roi-data_1_split_1
I0529 22:03:47.562060 24924 net.cpp:444] annotator_detector <- bbox_inside_weights_roi-data_3_split_1
I0529 22:03:47.562070 24924 net.cpp:418] annotator_detector -> labels_ohem
I0529 22:03:47.562088 24924 net.cpp:418] annotator_detector -> bbox_loss_weights_ohem
I0529 22:03:47.562135 24924 net.cpp:150] Setting up annotator_detector
I0529 22:03:47.562144 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.562149 24924 net.cpp:157] Top shape: 1 8 1 1 (8)
I0529 22:03:47.562152 24924 net.cpp:165] Memory required for data: 4458664980
I0529 22:03:47.562156 24924 layer_factory.hpp:77] Creating layer labels_ohem_annotator_detector_0_split
I0529 22:03:47.562167 24924 net.cpp:100] Creating Layer labels_ohem_annotator_detector_0_split
I0529 22:03:47.562173 24924 net.cpp:444] labels_ohem_annotator_detector_0_split <- labels_ohem
I0529 22:03:47.562186 24924 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_0
I0529 22:03:47.562201 24924 net.cpp:418] labels_ohem_annotator_detector_0_split -> labels_ohem_annotator_detector_0_split_1
I0529 22:03:47.562247 24924 net.cpp:150] Setting up labels_ohem_annotator_detector_0_split
I0529 22:03:47.562254 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.562260 24924 net.cpp:157] Top shape: 1 1 1 1 (1)
I0529 22:03:47.562263 24924 net.cpp:165] Memory required for data: 4458664988
I0529 22:03:47.562268 24924 layer_factory.hpp:77] Creating layer silence
I0529 22:03:47.562279 24924 net.cpp:100] Creating Layer silence
I0529 22:03:47.562285 24924 net.cpp:444] silence <- bbox_outside_weights
I0529 22:03:47.562296 24924 net.cpp:444] silence <- temp_loss_cls
I0529 22:03:47.562304 24924 net.cpp:444] silence <- temp_prob_cls
I0529 22:03:47.562312 24924 net.cpp:444] silence <- temp_loss_bbox
I0529 22:03:47.562319 24924 net.cpp:150] Setting up silence
I0529 22:03:47.562321 24924 net.cpp:165] Memory required for data: 4458664988
I0529 22:03:47.562325 24924 layer_factory.hpp:77] Creating layer loss
I0529 22:03:47.562336 24924 net.cpp:100] Creating Layer loss
I0529 22:03:47.562341 24924 net.cpp:444] loss <- cls_score_ave_cls_score_rois_0_split_1
I0529 22:03:47.562350 24924 net.cpp:444] loss <- labels_ohem_annotator_detector_0_split_0
I0529 22:03:47.562361 24924 net.cpp:418] loss -> loss_cls
I0529 22:03:47.562379 24924 layer_factory.hpp:77] Creating layer loss
I0529 22:03:47.562609 24924 net.cpp:150] Setting up loss
I0529 22:03:47.562618 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.562620 24924 net.cpp:160]     with loss weight 1
I0529 22:03:47.562625 24924 net.cpp:165] Memory required for data: 4458664992
I0529 22:03:47.562631 24924 layer_factory.hpp:77] Creating layer accuarcy
I0529 22:03:47.562644 24924 net.cpp:100] Creating Layer accuarcy
I0529 22:03:47.562650 24924 net.cpp:444] accuarcy <- cls_score_ave_cls_score_rois_0_split_2
I0529 22:03:47.562662 24924 net.cpp:444] accuarcy <- labels_ohem_annotator_detector_0_split_1
I0529 22:03:47.562674 24924 net.cpp:418] accuarcy -> accuarcy
I0529 22:03:47.562692 24924 net.cpp:150] Setting up accuarcy
I0529 22:03:47.562700 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.562703 24924 net.cpp:165] Memory required for data: 4458664996
I0529 22:03:47.562707 24924 layer_factory.hpp:77] Creating layer loss_bbox
I0529 22:03:47.562721 24924 net.cpp:100] Creating Layer loss_bbox
I0529 22:03:47.562726 24924 net.cpp:444] loss_bbox <- bbox_pred_ave_bbox_pred_rois_0_split_1
I0529 22:03:47.562737 24924 net.cpp:444] loss_bbox <- bbox_targets_roi-data_2_split_1
I0529 22:03:47.562746 24924 net.cpp:444] loss_bbox <- bbox_loss_weights_ohem
I0529 22:03:47.562757 24924 net.cpp:418] loss_bbox -> loss_bbox
I0529 22:03:47.562822 24924 net.cpp:150] Setting up loss_bbox
I0529 22:03:47.562829 24924 net.cpp:157] Top shape: (1)
I0529 22:03:47.562832 24924 net.cpp:160]     with loss weight 1
I0529 22:03:47.562837 24924 net.cpp:165] Memory required for data: 4458665000
I0529 22:03:47.562842 24924 net.cpp:226] loss_bbox needs backward computation.
I0529 22:03:47.562851 24924 net.cpp:228] accuarcy does not need backward computation.
I0529 22:03:47.562856 24924 net.cpp:226] loss needs backward computation.
I0529 22:03:47.562862 24924 net.cpp:228] silence does not need backward computation.
I0529 22:03:47.562870 24924 net.cpp:228] labels_ohem_annotator_detector_0_split does not need backward computation.
I0529 22:03:47.562875 24924 net.cpp:228] annotator_detector does not need backward computation.
I0529 22:03:47.562886 24924 net.cpp:228] per_roi_loss does not need backward computation.
I0529 22:03:47.562894 24924 net.cpp:228] per_roi_loss_bbox does not need backward computation.
I0529 22:03:47.562904 24924 net.cpp:228] per_roi_loss_cls does not need backward computation.
I0529 22:03:47.562911 24924 net.cpp:226] bbox_pred_ave_bbox_pred_rois_0_split needs backward computation.
I0529 22:03:47.562916 24924 net.cpp:226] ave_bbox_pred_rois needs backward computation.
I0529 22:03:47.562922 24924 net.cpp:226] psroipooled_loc_rois needs backward computation.
I0529 22:03:47.562929 24924 net.cpp:226] cls_score_ave_cls_score_rois_0_split needs backward computation.
I0529 22:03:47.562934 24924 net.cpp:226] ave_cls_score_rois needs backward computation.
I0529 22:03:47.562939 24924 net.cpp:226] psroipooled_cls_rois needs backward computation.
I0529 22:03:47.562947 24924 net.cpp:226] rfcn_bbox needs backward computation.
I0529 22:03:47.562952 24924 net.cpp:226] rfcn_cls needs backward computation.
I0529 22:03:47.562957 24924 net.cpp:226] conv_new_1_conv_new_1_relu_0_split needs backward computation.
I0529 22:03:47.562963 24924 net.cpp:226] conv_new_1_relu needs backward computation.
I0529 22:03:47.562968 24924 net.cpp:226] conv_new_1 needs backward computation.
I0529 22:03:47.562974 24924 net.cpp:228] bbox_inside_weights_roi-data_3_split does not need backward computation.
I0529 22:03:47.562980 24924 net.cpp:228] bbox_targets_roi-data_2_split does not need backward computation.
I0529 22:03:47.562988 24924 net.cpp:228] labels_roi-data_1_split does not need backward computation.
I0529 22:03:47.562994 24924 net.cpp:226] rois_roi-data_0_split needs backward computation.
I0529 22:03:47.563000 24924 net.cpp:226] roi-data needs backward computation.
I0529 22:03:47.563007 24924 net.cpp:226] proposal needs backward computation.
I0529 22:03:47.563015 24924 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0529 22:03:47.563021 24924 net.cpp:226] rpn_cls_prob needs backward computation.
I0529 22:03:47.563026 24924 net.cpp:226] rpn_loss_bbox needs backward computation.
I0529 22:03:47.563035 24924 net.cpp:226] rpn_loss_cls needs backward computation.
I0529 22:03:47.563043 24924 net.cpp:226] rpn-data needs backward computation.
I0529 22:03:47.563053 24924 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0529 22:03:47.563058 24924 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0529 22:03:47.563064 24924 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0529 22:03:47.563071 24924 net.cpp:226] rpn_bbox_pred needs backward computation.
I0529 22:03:47.563076 24924 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0529 22:03:47.563081 24924 net.cpp:226] rpn_cls_score needs backward computation.
I0529 22:03:47.563087 24924 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0529 22:03:47.563093 24924 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0529 22:03:47.563098 24924 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0529 22:03:47.563103 24924 net.cpp:226] res5c_relu needs backward computation.
I0529 22:03:47.563108 24924 net.cpp:226] res5c needs backward computation.
I0529 22:03:47.563117 24924 net.cpp:226] scale5c_branch2c needs backward computation.
I0529 22:03:47.563122 24924 net.cpp:226] bn5c_branch2c needs backward computation.
I0529 22:03:47.563125 24924 net.cpp:226] res5c_branch2c needs backward computation.
I0529 22:03:47.563132 24924 net.cpp:226] res5c_branch2b_relu needs backward computation.
I0529 22:03:47.563136 24924 net.cpp:226] scale5c_branch2b needs backward computation.
I0529 22:03:47.563141 24924 net.cpp:226] bn5c_branch2b needs backward computation.
I0529 22:03:47.563146 24924 net.cpp:226] res5c_branch2b needs backward computation.
I0529 22:03:47.563151 24924 net.cpp:226] res5c_branch2a_relu needs backward computation.
I0529 22:03:47.563158 24924 net.cpp:226] scale5c_branch2a needs backward computation.
I0529 22:03:47.563161 24924 net.cpp:226] bn5c_branch2a needs backward computation.
I0529 22:03:47.563166 24924 net.cpp:226] res5c_branch2a needs backward computation.
I0529 22:03:47.563172 24924 net.cpp:226] res5b_res5b_relu_0_split needs backward computation.
I0529 22:03:47.563179 24924 net.cpp:226] res5b_relu needs backward computation.
I0529 22:03:47.563182 24924 net.cpp:226] res5b needs backward computation.
I0529 22:03:47.563189 24924 net.cpp:226] scale5b_branch2c needs backward computation.
I0529 22:03:47.563194 24924 net.cpp:226] bn5b_branch2c needs backward computation.
I0529 22:03:47.563199 24924 net.cpp:226] res5b_branch2c needs backward computation.
I0529 22:03:47.563205 24924 net.cpp:226] res5b_branch2b_relu needs backward computation.
I0529 22:03:47.563210 24924 net.cpp:226] scale5b_branch2b needs backward computation.
I0529 22:03:47.563215 24924 net.cpp:226] bn5b_branch2b needs backward computation.
I0529 22:03:47.563220 24924 net.cpp:226] res5b_branch2b needs backward computation.
I0529 22:03:47.563225 24924 net.cpp:226] res5b_branch2a_relu needs backward computation.
I0529 22:03:47.563230 24924 net.cpp:226] scale5b_branch2a needs backward computation.
I0529 22:03:47.563235 24924 net.cpp:226] bn5b_branch2a needs backward computation.
I0529 22:03:47.563241 24924 net.cpp:226] res5b_branch2a needs backward computation.
I0529 22:03:47.563246 24924 net.cpp:226] res5a_res5a_relu_0_split needs backward computation.
I0529 22:03:47.563252 24924 net.cpp:226] res5a_relu needs backward computation.
I0529 22:03:47.563256 24924 net.cpp:226] res5a needs backward computation.
I0529 22:03:47.563263 24924 net.cpp:226] scale5a_branch2c needs backward computation.
I0529 22:03:47.563268 24924 net.cpp:226] bn5a_branch2c needs backward computation.
I0529 22:03:47.563273 24924 net.cpp:226] res5a_branch2c needs backward computation.
I0529 22:03:47.563278 24924 net.cpp:226] res5a_branch2b_relu needs backward computation.
I0529 22:03:47.563283 24924 net.cpp:226] scale5a_branch2b needs backward computation.
I0529 22:03:47.563288 24924 net.cpp:226] bn5a_branch2b needs backward computation.
I0529 22:03:47.563292 24924 net.cpp:226] res5a_branch2b needs backward computation.
I0529 22:03:47.563298 24924 net.cpp:226] res5a_branch2a_relu needs backward computation.
I0529 22:03:47.563303 24924 net.cpp:226] scale5a_branch2a needs backward computation.
I0529 22:03:47.563308 24924 net.cpp:226] bn5a_branch2a needs backward computation.
I0529 22:03:47.563313 24924 net.cpp:226] res5a_branch2a needs backward computation.
I0529 22:03:47.563319 24924 net.cpp:226] scale5a_branch1 needs backward computation.
I0529 22:03:47.563324 24924 net.cpp:226] bn5a_branch1 needs backward computation.
I0529 22:03:47.563329 24924 net.cpp:226] res5a_branch1 needs backward computation.
I0529 22:03:47.563335 24924 net.cpp:226] res4f_res4f_relu_0_split needs backward computation.
I0529 22:03:47.563341 24924 net.cpp:226] res4f_relu needs backward computation.
I0529 22:03:47.563346 24924 net.cpp:226] res4f needs backward computation.
I0529 22:03:47.563354 24924 net.cpp:226] scale4f_branch2c needs backward computation.
I0529 22:03:47.563359 24924 net.cpp:226] bn4f_branch2c needs backward computation.
I0529 22:03:47.563364 24924 net.cpp:226] res4f_branch2c needs backward computation.
I0529 22:03:47.563369 24924 net.cpp:226] res4f_branch2b_relu needs backward computation.
I0529 22:03:47.563374 24924 net.cpp:226] scale4f_branch2b needs backward computation.
I0529 22:03:47.563380 24924 net.cpp:226] bn4f_branch2b needs backward computation.
I0529 22:03:47.563385 24924 net.cpp:226] res4f_branch2b needs backward computation.
I0529 22:03:47.563390 24924 net.cpp:226] res4f_branch2a_relu needs backward computation.
I0529 22:03:47.563395 24924 net.cpp:226] scale4f_branch2a needs backward computation.
I0529 22:03:47.563400 24924 net.cpp:226] bn4f_branch2a needs backward computation.
I0529 22:03:47.563405 24924 net.cpp:226] res4f_branch2a needs backward computation.
I0529 22:03:47.563411 24924 net.cpp:226] res4e_res4e_relu_0_split needs backward computation.
I0529 22:03:47.563417 24924 net.cpp:226] res4e_relu needs backward computation.
I0529 22:03:47.563422 24924 net.cpp:226] res4e needs backward computation.
I0529 22:03:47.563428 24924 net.cpp:226] scale4e_branch2c needs backward computation.
I0529 22:03:47.563433 24924 net.cpp:226] bn4e_branch2c needs backward computation.
I0529 22:03:47.563438 24924 net.cpp:226] res4e_branch2c needs backward computation.
I0529 22:03:47.563443 24924 net.cpp:226] res4e_branch2b_relu needs backward computation.
I0529 22:03:47.563449 24924 net.cpp:226] scale4e_branch2b needs backward computation.
I0529 22:03:47.563454 24924 net.cpp:226] bn4e_branch2b needs backward computation.
I0529 22:03:47.563459 24924 net.cpp:226] res4e_branch2b needs backward computation.
I0529 22:03:47.563464 24924 net.cpp:226] res4e_branch2a_relu needs backward computation.
I0529 22:03:47.563469 24924 net.cpp:226] scale4e_branch2a needs backward computation.
I0529 22:03:47.563474 24924 net.cpp:226] bn4e_branch2a needs backward computation.
I0529 22:03:47.563479 24924 net.cpp:226] res4e_branch2a needs backward computation.
I0529 22:03:47.563485 24924 net.cpp:226] res4d_res4d_relu_0_split needs backward computation.
I0529 22:03:47.563491 24924 net.cpp:226] res4d_relu needs backward computation.
I0529 22:03:47.563496 24924 net.cpp:226] res4d needs backward computation.
I0529 22:03:47.563503 24924 net.cpp:226] scale4d_branch2c needs backward computation.
I0529 22:03:47.563508 24924 net.cpp:226] bn4d_branch2c needs backward computation.
I0529 22:03:47.563513 24924 net.cpp:226] res4d_branch2c needs backward computation.
I0529 22:03:47.563519 24924 net.cpp:226] res4d_branch2b_relu needs backward computation.
I0529 22:03:47.563524 24924 net.cpp:226] scale4d_branch2b needs backward computation.
I0529 22:03:47.563529 24924 net.cpp:226] bn4d_branch2b needs backward computation.
I0529 22:03:47.563534 24924 net.cpp:226] res4d_branch2b needs backward computation.
I0529 22:03:47.563540 24924 net.cpp:226] res4d_branch2a_relu needs backward computation.
I0529 22:03:47.563545 24924 net.cpp:226] scale4d_branch2a needs backward computation.
I0529 22:03:47.563550 24924 net.cpp:226] bn4d_branch2a needs backward computation.
I0529 22:03:47.563555 24924 net.cpp:226] res4d_branch2a needs backward computation.
I0529 22:03:47.563561 24924 net.cpp:226] res4c_res4c_relu_0_split needs backward computation.
I0529 22:03:47.563567 24924 net.cpp:226] res4c_relu needs backward computation.
I0529 22:03:47.563572 24924 net.cpp:226] res4c needs backward computation.
I0529 22:03:47.563578 24924 net.cpp:226] scale4c_branch2c needs backward computation.
I0529 22:03:47.563583 24924 net.cpp:226] bn4c_branch2c needs backward computation.
I0529 22:03:47.563588 24924 net.cpp:226] res4c_branch2c needs backward computation.
I0529 22:03:47.563594 24924 net.cpp:226] res4c_branch2b_relu needs backward computation.
I0529 22:03:47.563599 24924 net.cpp:226] scale4c_branch2b needs backward computation.
I0529 22:03:47.563604 24924 net.cpp:226] bn4c_branch2b needs backward computation.
I0529 22:03:47.563609 24924 net.cpp:226] res4c_branch2b needs backward computation.
I0529 22:03:47.563616 24924 net.cpp:226] res4c_branch2a_relu needs backward computation.
I0529 22:03:47.563621 24924 net.cpp:226] scale4c_branch2a needs backward computation.
I0529 22:03:47.563627 24924 net.cpp:226] bn4c_branch2a needs backward computation.
I0529 22:03:47.563630 24924 net.cpp:226] res4c_branch2a needs backward computation.
I0529 22:03:47.563637 24924 net.cpp:226] res4b_res4b_relu_0_split needs backward computation.
I0529 22:03:47.563642 24924 net.cpp:226] res4b_relu needs backward computation.
I0529 22:03:47.563647 24924 net.cpp:226] res4b needs backward computation.
I0529 22:03:47.563655 24924 net.cpp:226] scale4b_branch2c needs backward computation.
I0529 22:03:47.563659 24924 net.cpp:226] bn4b_branch2c needs backward computation.
I0529 22:03:47.563664 24924 net.cpp:226] res4b_branch2c needs backward computation.
I0529 22:03:47.563669 24924 net.cpp:226] res4b_branch2b_relu needs backward computation.
I0529 22:03:47.563675 24924 net.cpp:226] scale4b_branch2b needs backward computation.
I0529 22:03:47.563680 24924 net.cpp:226] bn4b_branch2b needs backward computation.
I0529 22:03:47.563685 24924 net.cpp:226] res4b_branch2b needs backward computation.
I0529 22:03:47.563690 24924 net.cpp:226] res4b_branch2a_relu needs backward computation.
I0529 22:03:47.563696 24924 net.cpp:226] scale4b_branch2a needs backward computation.
I0529 22:03:47.563701 24924 net.cpp:226] bn4b_branch2a needs backward computation.
I0529 22:03:47.563706 24924 net.cpp:226] res4b_branch2a needs backward computation.
I0529 22:03:47.563712 24924 net.cpp:226] res4a_res4a_relu_0_split needs backward computation.
I0529 22:03:47.563719 24924 net.cpp:226] res4a_relu needs backward computation.
I0529 22:03:47.563724 24924 net.cpp:226] res4a needs backward computation.
I0529 22:03:47.563730 24924 net.cpp:226] scale4a_branch2c needs backward computation.
I0529 22:03:47.563735 24924 net.cpp:226] bn4a_branch2c needs backward computation.
I0529 22:03:47.563740 24924 net.cpp:226] res4a_branch2c needs backward computation.
I0529 22:03:47.563745 24924 net.cpp:226] res4a_branch2b_relu needs backward computation.
I0529 22:03:47.563750 24924 net.cpp:226] scale4a_branch2b needs backward computation.
I0529 22:03:47.563755 24924 net.cpp:226] bn4a_branch2b needs backward computation.
I0529 22:03:47.563760 24924 net.cpp:226] res4a_branch2b needs backward computation.
I0529 22:03:47.563766 24924 net.cpp:226] res4a_branch2a_relu needs backward computation.
I0529 22:03:47.563771 24924 net.cpp:226] scale4a_branch2a needs backward computation.
I0529 22:03:47.563777 24924 net.cpp:226] bn4a_branch2a needs backward computation.
I0529 22:03:47.563782 24924 net.cpp:226] res4a_branch2a needs backward computation.
I0529 22:03:47.563788 24924 net.cpp:226] scale4a_branch1 needs backward computation.
I0529 22:03:47.563793 24924 net.cpp:226] bn4a_branch1 needs backward computation.
I0529 22:03:47.563798 24924 net.cpp:226] res4a_branch1 needs backward computation.
I0529 22:03:47.563805 24924 net.cpp:226] res3d_res3d_relu_0_split needs backward computation.
I0529 22:03:47.563812 24924 net.cpp:226] res3d_relu needs backward computation.
I0529 22:03:47.563817 24924 net.cpp:226] res3d needs backward computation.
I0529 22:03:47.563823 24924 net.cpp:226] scale3d_branch2c needs backward computation.
I0529 22:03:47.563828 24924 net.cpp:226] bn3d_branch2c needs backward computation.
I0529 22:03:47.563833 24924 net.cpp:226] res3d_branch2c needs backward computation.
I0529 22:03:47.563839 24924 net.cpp:226] res3d_branch2b_relu needs backward computation.
I0529 22:03:47.563844 24924 net.cpp:226] scale3d_branch2b needs backward computation.
I0529 22:03:47.563849 24924 net.cpp:226] bn3d_branch2b needs backward computation.
I0529 22:03:47.563855 24924 net.cpp:226] res3d_branch2b needs backward computation.
I0529 22:03:47.563860 24924 net.cpp:226] res3d_branch2a_relu needs backward computation.
I0529 22:03:47.563866 24924 net.cpp:226] scale3d_branch2a needs backward computation.
I0529 22:03:47.563871 24924 net.cpp:226] bn3d_branch2a needs backward computation.
I0529 22:03:47.563876 24924 net.cpp:226] res3d_branch2a needs backward computation.
I0529 22:03:47.563882 24924 net.cpp:226] res3c_res3c_relu_0_split needs backward computation.
I0529 22:03:47.563889 24924 net.cpp:226] res3c_relu needs backward computation.
I0529 22:03:47.563892 24924 net.cpp:226] res3c needs backward computation.
I0529 22:03:47.563900 24924 net.cpp:226] scale3c_branch2c needs backward computation.
I0529 22:03:47.563905 24924 net.cpp:226] bn3c_branch2c needs backward computation.
I0529 22:03:47.563911 24924 net.cpp:226] res3c_branch2c needs backward computation.
I0529 22:03:47.563916 24924 net.cpp:226] res3c_branch2b_relu needs backward computation.
I0529 22:03:47.563921 24924 net.cpp:226] scale3c_branch2b needs backward computation.
I0529 22:03:47.563927 24924 net.cpp:226] bn3c_branch2b needs backward computation.
I0529 22:03:47.563932 24924 net.cpp:226] res3c_branch2b needs backward computation.
I0529 22:03:47.563938 24924 net.cpp:226] res3c_branch2a_relu needs backward computation.
I0529 22:03:47.563943 24924 net.cpp:226] scale3c_branch2a needs backward computation.
I0529 22:03:47.563948 24924 net.cpp:226] bn3c_branch2a needs backward computation.
I0529 22:03:47.563953 24924 net.cpp:226] res3c_branch2a needs backward computation.
I0529 22:03:47.563959 24924 net.cpp:226] res3b_res3b_relu_0_split needs backward computation.
I0529 22:03:47.563966 24924 net.cpp:226] res3b_relu needs backward computation.
I0529 22:03:47.563971 24924 net.cpp:226] res3b needs backward computation.
I0529 22:03:47.563977 24924 net.cpp:226] scale3b_branch2c needs backward computation.
I0529 22:03:47.563982 24924 net.cpp:226] bn3b_branch2c needs backward computation.
I0529 22:03:47.563987 24924 net.cpp:226] res3b_branch2c needs backward computation.
I0529 22:03:47.563993 24924 net.cpp:226] res3b_branch2b_relu needs backward computation.
I0529 22:03:47.563998 24924 net.cpp:226] scale3b_branch2b needs backward computation.
I0529 22:03:47.564003 24924 net.cpp:226] bn3b_branch2b needs backward computation.
I0529 22:03:47.564008 24924 net.cpp:226] res3b_branch2b needs backward computation.
I0529 22:03:47.564014 24924 net.cpp:226] res3b_branch2a_relu needs backward computation.
I0529 22:03:47.564019 24924 net.cpp:226] scale3b_branch2a needs backward computation.
I0529 22:03:47.564024 24924 net.cpp:226] bn3b_branch2a needs backward computation.
I0529 22:03:47.564029 24924 net.cpp:226] res3b_branch2a needs backward computation.
I0529 22:03:47.564036 24924 net.cpp:226] res3a_res3a_relu_0_split needs backward computation.
I0529 22:03:47.564041 24924 net.cpp:226] res3a_relu needs backward computation.
I0529 22:03:47.564046 24924 net.cpp:226] res3a needs backward computation.
I0529 22:03:47.564054 24924 net.cpp:226] scale3a_branch2c needs backward computation.
I0529 22:03:47.564059 24924 net.cpp:226] bn3a_branch2c needs backward computation.
I0529 22:03:47.564064 24924 net.cpp:226] res3a_branch2c needs backward computation.
I0529 22:03:47.564069 24924 net.cpp:226] res3a_branch2b_relu needs backward computation.
I0529 22:03:47.564074 24924 net.cpp:226] scale3a_branch2b needs backward computation.
I0529 22:03:47.564079 24924 net.cpp:226] bn3a_branch2b needs backward computation.
I0529 22:03:47.564085 24924 net.cpp:226] res3a_branch2b needs backward computation.
I0529 22:03:47.564090 24924 net.cpp:226] res3a_branch2a_relu needs backward computation.
I0529 22:03:47.564095 24924 net.cpp:226] scale3a_branch2a needs backward computation.
I0529 22:03:47.564100 24924 net.cpp:226] bn3a_branch2a needs backward computation.
I0529 22:03:47.564105 24924 net.cpp:226] res3a_branch2a needs backward computation.
I0529 22:03:47.564112 24924 net.cpp:226] scale3a_branch1 needs backward computation.
I0529 22:03:47.564117 24924 net.cpp:226] bn3a_branch1 needs backward computation.
I0529 22:03:47.564122 24924 net.cpp:226] res3a_branch1 needs backward computation.
I0529 22:03:47.564131 24924 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0529 22:03:47.564136 24924 net.cpp:228] res2c_relu does not need backward computation.
I0529 22:03:47.564142 24924 net.cpp:228] res2c does not need backward computation.
I0529 22:03:47.564152 24924 net.cpp:228] scale2c_branch2c does not need backward computation.
I0529 22:03:47.564157 24924 net.cpp:228] bn2c_branch2c does not need backward computation.
I0529 22:03:47.564162 24924 net.cpp:228] res2c_branch2c does not need backward computation.
I0529 22:03:47.564168 24924 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0529 22:03:47.564174 24924 net.cpp:228] scale2c_branch2b does not need backward computation.
I0529 22:03:47.564180 24924 net.cpp:228] bn2c_branch2b does not need backward computation.
I0529 22:03:47.564185 24924 net.cpp:228] res2c_branch2b does not need backward computation.
I0529 22:03:47.564193 24924 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0529 22:03:47.564198 24924 net.cpp:228] scale2c_branch2a does not need backward computation.
I0529 22:03:47.564203 24924 net.cpp:228] bn2c_branch2a does not need backward computation.
I0529 22:03:47.564209 24924 net.cpp:228] res2c_branch2a does not need backward computation.
I0529 22:03:47.564216 24924 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0529 22:03:47.564222 24924 net.cpp:228] res2b_relu does not need backward computation.
I0529 22:03:47.564227 24924 net.cpp:228] res2b does not need backward computation.
I0529 22:03:47.564236 24924 net.cpp:228] scale2b_branch2c does not need backward computation.
I0529 22:03:47.564241 24924 net.cpp:228] bn2b_branch2c does not need backward computation.
I0529 22:03:47.564246 24924 net.cpp:228] res2b_branch2c does not need backward computation.
I0529 22:03:47.564254 24924 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0529 22:03:47.564258 24924 net.cpp:228] scale2b_branch2b does not need backward computation.
I0529 22:03:47.564265 24924 net.cpp:228] bn2b_branch2b does not need backward computation.
I0529 22:03:47.564270 24924 net.cpp:228] res2b_branch2b does not need backward computation.
I0529 22:03:47.564276 24924 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0529 22:03:47.564281 24924 net.cpp:228] scale2b_branch2a does not need backward computation.
I0529 22:03:47.564287 24924 net.cpp:228] bn2b_branch2a does not need backward computation.
I0529 22:03:47.564292 24924 net.cpp:228] res2b_branch2a does not need backward computation.
I0529 22:03:47.564301 24924 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0529 22:03:47.564306 24924 net.cpp:228] res2a_relu does not need backward computation.
I0529 22:03:47.564312 24924 net.cpp:228] res2a does not need backward computation.
I0529 22:03:47.564321 24924 net.cpp:228] scale2a_branch2c does not need backward computation.
I0529 22:03:47.564326 24924 net.cpp:228] bn2a_branch2c does not need backward computation.
I0529 22:03:47.564330 24924 net.cpp:228] res2a_branch2c does not need backward computation.
I0529 22:03:47.564337 24924 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0529 22:03:47.564343 24924 net.cpp:228] scale2a_branch2b does not need backward computation.
I0529 22:03:47.564349 24924 net.cpp:228] bn2a_branch2b does not need backward computation.
I0529 22:03:47.564355 24924 net.cpp:228] res2a_branch2b does not need backward computation.
I0529 22:03:47.564362 24924 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0529 22:03:47.564368 24924 net.cpp:228] scale2a_branch2a does not need backward computation.
I0529 22:03:47.564373 24924 net.cpp:228] bn2a_branch2a does not need backward computation.
I0529 22:03:47.564378 24924 net.cpp:228] res2a_branch2a does not need backward computation.
I0529 22:03:47.564385 24924 net.cpp:228] scale2a_branch1 does not need backward computation.
I0529 22:03:47.564391 24924 net.cpp:228] bn2a_branch1 does not need backward computation.
I0529 22:03:47.564397 24924 net.cpp:228] res2a_branch1 does not need backward computation.
I0529 22:03:47.564405 24924 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0529 22:03:47.564411 24924 net.cpp:228] pool1 does not need backward computation.
I0529 22:03:47.564417 24924 net.cpp:228] conv1_relu does not need backward computation.
I0529 22:03:47.564422 24924 net.cpp:228] scale_conv1 does not need backward computation.
I0529 22:03:47.564427 24924 net.cpp:228] bn_conv1 does not need backward computation.
I0529 22:03:47.564433 24924 net.cpp:228] conv1 does not need backward computation.
I0529 22:03:47.564441 24924 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0529 22:03:47.564448 24924 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0529 22:03:47.564455 24924 net.cpp:228] data_input-data_0_split does not need backward computation.
I0529 22:03:47.564465 24924 net.cpp:228] input-data does not need backward computation.
I0529 22:03:47.564467 24924 net.cpp:270] This network produces output accuarcy
I0529 22:03:47.564476 24924 net.cpp:270] This network produces output loss_bbox
I0529 22:03:47.564481 24924 net.cpp:270] This network produces output loss_cls
I0529 22:03:47.564487 24924 net.cpp:270] This network produces output rpn_cls_loss
I0529 22:03:47.564492 24924 net.cpp:270] This network produces output rpn_loss_bbox
I0529 22:03:47.564791 24924 net.cpp:283] Network initialization done.
I0529 22:03:47.565337 24924 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/ResNet-50-model.caffemodel
I0529 22:03:47.658633 24924 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/ResNet-50-model.caffemodel
I0529 22:03:47.658655 24924 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0529 22:03:47.658658 24924 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0529 22:03:47.658663 24924 net.cpp:774] Copying source layer conv1
I0529 22:03:47.658766 24924 net.cpp:774] Copying source layer bn_conv1
I0529 22:03:47.658776 24924 net.cpp:774] Copying source layer scale_conv1
I0529 22:03:47.658797 24924 net.cpp:774] Copying source layer conv1_relu
I0529 22:03:47.658800 24924 net.cpp:774] Copying source layer pool1
I0529 22:03:47.658803 24924 net.cpp:774] Copying source layer pool1_pool1_0_split
I0529 22:03:47.658820 24924 net.cpp:774] Copying source layer res2a_branch1
I0529 22:03:47.658949 24924 net.cpp:774] Copying source layer bn2a_branch1
I0529 22:03:47.658977 24924 net.cpp:774] Copying source layer scale2a_branch1
I0529 22:03:47.658987 24924 net.cpp:774] Copying source layer res2a_branch2a
I0529 22:03:47.659034 24924 net.cpp:774] Copying source layer bn2a_branch2a
I0529 22:03:47.659057 24924 net.cpp:774] Copying source layer scale2a_branch2a
I0529 22:03:47.659065 24924 net.cpp:774] Copying source layer res2a_branch2a_relu
I0529 22:03:47.659068 24924 net.cpp:774] Copying source layer res2a_branch2b
I0529 22:03:47.659333 24924 net.cpp:774] Copying source layer bn2a_branch2b
I0529 22:03:47.659358 24924 net.cpp:774] Copying source layer scale2a_branch2b
I0529 22:03:47.659365 24924 net.cpp:774] Copying source layer res2a_branch2b_relu
I0529 22:03:47.659369 24924 net.cpp:774] Copying source layer res2a_branch2c
I0529 22:03:47.659498 24924 net.cpp:774] Copying source layer bn2a_branch2c
I0529 22:03:47.659524 24924 net.cpp:774] Copying source layer scale2a_branch2c
I0529 22:03:47.659536 24924 net.cpp:774] Copying source layer res2a
I0529 22:03:47.659539 24924 net.cpp:774] Copying source layer res2a_relu
I0529 22:03:47.659543 24924 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0529 22:03:47.659546 24924 net.cpp:774] Copying source layer res2b_branch2a
I0529 22:03:47.659664 24924 net.cpp:774] Copying source layer bn2b_branch2a
I0529 22:03:47.659674 24924 net.cpp:774] Copying source layer scale2b_branch2a
I0529 22:03:47.659682 24924 net.cpp:774] Copying source layer res2b_branch2a_relu
I0529 22:03:47.659687 24924 net.cpp:774] Copying source layer res2b_branch2b
I0529 22:03:47.659942 24924 net.cpp:774] Copying source layer bn2b_branch2b
I0529 22:03:47.659953 24924 net.cpp:774] Copying source layer scale2b_branch2b
I0529 22:03:47.659961 24924 net.cpp:774] Copying source layer res2b_branch2b_relu
I0529 22:03:47.659965 24924 net.cpp:774] Copying source layer res2b_branch2c
I0529 22:03:47.660082 24924 net.cpp:774] Copying source layer bn2b_branch2c
I0529 22:03:47.660095 24924 net.cpp:774] Copying source layer scale2b_branch2c
I0529 22:03:47.660106 24924 net.cpp:774] Copying source layer res2b
I0529 22:03:47.660110 24924 net.cpp:774] Copying source layer res2b_relu
I0529 22:03:47.660115 24924 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0529 22:03:47.660118 24924 net.cpp:774] Copying source layer res2c_branch2a
I0529 22:03:47.660248 24924 net.cpp:774] Copying source layer bn2c_branch2a
I0529 22:03:47.660270 24924 net.cpp:774] Copying source layer scale2c_branch2a
I0529 22:03:47.660279 24924 net.cpp:774] Copying source layer res2c_branch2a_relu
I0529 22:03:47.660284 24924 net.cpp:774] Copying source layer res2c_branch2b
I0529 22:03:47.660539 24924 net.cpp:774] Copying source layer bn2c_branch2b
I0529 22:03:47.660549 24924 net.cpp:774] Copying source layer scale2c_branch2b
I0529 22:03:47.660558 24924 net.cpp:774] Copying source layer res2c_branch2b_relu
I0529 22:03:47.660562 24924 net.cpp:774] Copying source layer res2c_branch2c
I0529 22:03:47.660691 24924 net.cpp:774] Copying source layer bn2c_branch2c
I0529 22:03:47.660717 24924 net.cpp:774] Copying source layer scale2c_branch2c
I0529 22:03:47.660728 24924 net.cpp:774] Copying source layer res2c
I0529 22:03:47.660732 24924 net.cpp:774] Copying source layer res2c_relu
I0529 22:03:47.660737 24924 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0529 22:03:47.660742 24924 net.cpp:774] Copying source layer res3a_branch1
I0529 22:03:47.661661 24924 net.cpp:774] Copying source layer bn3a_branch1
I0529 22:03:47.661679 24924 net.cpp:774] Copying source layer scale3a_branch1
I0529 22:03:47.661706 24924 net.cpp:774] Copying source layer res3a_branch2a
I0529 22:03:47.661944 24924 net.cpp:774] Copying source layer bn3a_branch2a
I0529 22:03:47.661955 24924 net.cpp:774] Copying source layer scale3a_branch2a
I0529 22:03:47.661978 24924 net.cpp:774] Copying source layer res3a_branch2a_relu
I0529 22:03:47.661981 24924 net.cpp:774] Copying source layer res3a_branch2b
I0529 22:03:47.662976 24924 net.cpp:774] Copying source layer bn3a_branch2b
I0529 22:03:47.662987 24924 net.cpp:774] Copying source layer scale3a_branch2b
I0529 22:03:47.663009 24924 net.cpp:774] Copying source layer res3a_branch2b_relu
I0529 22:03:47.663013 24924 net.cpp:774] Copying source layer res3a_branch2c
I0529 22:03:47.663468 24924 net.cpp:774] Copying source layer bn3a_branch2c
I0529 22:03:47.663486 24924 net.cpp:774] Copying source layer scale3a_branch2c
I0529 22:03:47.663512 24924 net.cpp:774] Copying source layer res3a
I0529 22:03:47.663517 24924 net.cpp:774] Copying source layer res3a_relu
I0529 22:03:47.663522 24924 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0529 22:03:47.663525 24924 net.cpp:774] Copying source layer res3b_branch2a
I0529 22:03:47.663980 24924 net.cpp:774] Copying source layer bn3b_branch2a
I0529 22:03:47.663990 24924 net.cpp:774] Copying source layer scale3b_branch2a
I0529 22:03:47.664013 24924 net.cpp:774] Copying source layer res3b_branch2a_relu
I0529 22:03:47.664017 24924 net.cpp:774] Copying source layer res3b_branch2b
I0529 22:03:47.665017 24924 net.cpp:774] Copying source layer bn3b_branch2b
I0529 22:03:47.665030 24924 net.cpp:774] Copying source layer scale3b_branch2b
I0529 22:03:47.665051 24924 net.cpp:774] Copying source layer res3b_branch2b_relu
I0529 22:03:47.665056 24924 net.cpp:774] Copying source layer res3b_branch2c
I0529 22:03:47.665578 24924 net.cpp:774] Copying source layer bn3b_branch2c
I0529 22:03:47.665619 24924 net.cpp:774] Copying source layer scale3b_branch2c
I0529 22:03:47.665635 24924 net.cpp:774] Copying source layer res3b
I0529 22:03:47.665639 24924 net.cpp:774] Copying source layer res3b_relu
I0529 22:03:47.665644 24924 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0529 22:03:47.665649 24924 net.cpp:774] Copying source layer res3c_branch2a
I0529 22:03:47.666106 24924 net.cpp:774] Copying source layer bn3c_branch2a
I0529 22:03:47.666118 24924 net.cpp:774] Copying source layer scale3c_branch2a
I0529 22:03:47.666141 24924 net.cpp:774] Copying source layer res3c_branch2a_relu
I0529 22:03:47.666144 24924 net.cpp:774] Copying source layer res3c_branch2b
I0529 22:03:47.667194 24924 net.cpp:774] Copying source layer bn3c_branch2b
I0529 22:03:47.667207 24924 net.cpp:774] Copying source layer scale3c_branch2b
I0529 22:03:47.667228 24924 net.cpp:774] Copying source layer res3c_branch2b_relu
I0529 22:03:47.667233 24924 net.cpp:774] Copying source layer res3c_branch2c
I0529 22:03:47.667690 24924 net.cpp:774] Copying source layer bn3c_branch2c
I0529 22:03:47.667706 24924 net.cpp:774] Copying source layer scale3c_branch2c
I0529 22:03:47.667735 24924 net.cpp:774] Copying source layer res3c
I0529 22:03:47.667740 24924 net.cpp:774] Copying source layer res3c_relu
I0529 22:03:47.667745 24924 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0529 22:03:47.667750 24924 net.cpp:774] Copying source layer res3d_branch2a
I0529 22:03:47.668213 24924 net.cpp:774] Copying source layer bn3d_branch2a
I0529 22:03:47.668226 24924 net.cpp:774] Copying source layer scale3d_branch2a
I0529 22:03:47.668248 24924 net.cpp:774] Copying source layer res3d_branch2a_relu
I0529 22:03:47.668252 24924 net.cpp:774] Copying source layer res3d_branch2b
I0529 22:03:47.669278 24924 net.cpp:774] Copying source layer bn3d_branch2b
I0529 22:03:47.669291 24924 net.cpp:774] Copying source layer scale3d_branch2b
I0529 22:03:47.669313 24924 net.cpp:774] Copying source layer res3d_branch2b_relu
I0529 22:03:47.669319 24924 net.cpp:774] Copying source layer res3d_branch2c
I0529 22:03:47.669771 24924 net.cpp:774] Copying source layer bn3d_branch2c
I0529 22:03:47.669788 24924 net.cpp:774] Copying source layer scale3d_branch2c
I0529 22:03:47.669805 24924 net.cpp:774] Copying source layer res3d
I0529 22:03:47.669809 24924 net.cpp:774] Copying source layer res3d_relu
I0529 22:03:47.669816 24924 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0529 22:03:47.669821 24924 net.cpp:774] Copying source layer res4a_branch1
I0529 22:03:47.673393 24924 net.cpp:774] Copying source layer bn4a_branch1
I0529 22:03:47.673424 24924 net.cpp:774] Copying source layer scale4a_branch1
I0529 22:03:47.673447 24924 net.cpp:774] Copying source layer res4a_branch2a
I0529 22:03:47.674342 24924 net.cpp:774] Copying source layer bn4a_branch2a
I0529 22:03:47.674358 24924 net.cpp:774] Copying source layer scale4a_branch2a
I0529 22:03:47.674371 24924 net.cpp:774] Copying source layer res4a_branch2a_relu
I0529 22:03:47.674376 24924 net.cpp:774] Copying source layer res4a_branch2b
I0529 22:03:47.678378 24924 net.cpp:774] Copying source layer bn4a_branch2b
I0529 22:03:47.678397 24924 net.cpp:774] Copying source layer scale4a_branch2b
I0529 22:03:47.678411 24924 net.cpp:774] Copying source layer res4a_branch2b_relu
I0529 22:03:47.678416 24924 net.cpp:774] Copying source layer res4a_branch2c
I0529 22:03:47.680197 24924 net.cpp:774] Copying source layer bn4a_branch2c
I0529 22:03:47.680222 24924 net.cpp:774] Copying source layer scale4a_branch2c
I0529 22:03:47.680245 24924 net.cpp:774] Copying source layer res4a
I0529 22:03:47.680250 24924 net.cpp:774] Copying source layer res4a_relu
I0529 22:03:47.680258 24924 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0529 22:03:47.680263 24924 net.cpp:774] Copying source layer res4b_branch2a
I0529 22:03:47.682045 24924 net.cpp:774] Copying source layer bn4b_branch2a
I0529 22:03:47.682060 24924 net.cpp:774] Copying source layer scale4b_branch2a
I0529 22:03:47.682073 24924 net.cpp:774] Copying source layer res4b_branch2a_relu
I0529 22:03:47.682080 24924 net.cpp:774] Copying source layer res4b_branch2b
I0529 22:03:47.686089 24924 net.cpp:774] Copying source layer bn4b_branch2b
I0529 22:03:47.686105 24924 net.cpp:774] Copying source layer scale4b_branch2b
I0529 22:03:47.686118 24924 net.cpp:774] Copying source layer res4b_branch2b_relu
I0529 22:03:47.686125 24924 net.cpp:774] Copying source layer res4b_branch2c
I0529 22:03:47.687894 24924 net.cpp:774] Copying source layer bn4b_branch2c
I0529 22:03:47.687933 24924 net.cpp:774] Copying source layer scale4b_branch2c
I0529 22:03:47.687957 24924 net.cpp:774] Copying source layer res4b
I0529 22:03:47.687961 24924 net.cpp:774] Copying source layer res4b_relu
I0529 22:03:47.687968 24924 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0529 22:03:47.687973 24924 net.cpp:774] Copying source layer res4c_branch2a
I0529 22:03:47.689761 24924 net.cpp:774] Copying source layer bn4c_branch2a
I0529 22:03:47.689779 24924 net.cpp:774] Copying source layer scale4c_branch2a
I0529 22:03:47.689793 24924 net.cpp:774] Copying source layer res4c_branch2a_relu
I0529 22:03:47.689800 24924 net.cpp:774] Copying source layer res4c_branch2b
I0529 22:03:47.693845 24924 net.cpp:774] Copying source layer bn4c_branch2b
I0529 22:03:47.693864 24924 net.cpp:774] Copying source layer scale4c_branch2b
I0529 22:03:47.693877 24924 net.cpp:774] Copying source layer res4c_branch2b_relu
I0529 22:03:47.693883 24924 net.cpp:774] Copying source layer res4c_branch2c
I0529 22:03:47.695665 24924 net.cpp:774] Copying source layer bn4c_branch2c
I0529 22:03:47.695690 24924 net.cpp:774] Copying source layer scale4c_branch2c
I0529 22:03:47.695713 24924 net.cpp:774] Copying source layer res4c
I0529 22:03:47.695719 24924 net.cpp:774] Copying source layer res4c_relu
I0529 22:03:47.695726 24924 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0529 22:03:47.695732 24924 net.cpp:774] Copying source layer res4d_branch2a
I0529 22:03:47.697516 24924 net.cpp:774] Copying source layer bn4d_branch2a
I0529 22:03:47.697532 24924 net.cpp:774] Copying source layer scale4d_branch2a
I0529 22:03:47.697546 24924 net.cpp:774] Copying source layer res4d_branch2a_relu
I0529 22:03:47.697552 24924 net.cpp:774] Copying source layer res4d_branch2b
I0529 22:03:47.701552 24924 net.cpp:774] Copying source layer bn4d_branch2b
I0529 22:03:47.701570 24924 net.cpp:774] Copying source layer scale4d_branch2b
I0529 22:03:47.701583 24924 net.cpp:774] Copying source layer res4d_branch2b_relu
I0529 22:03:47.701591 24924 net.cpp:774] Copying source layer res4d_branch2c
I0529 22:03:47.703379 24924 net.cpp:774] Copying source layer bn4d_branch2c
I0529 22:03:47.703419 24924 net.cpp:774] Copying source layer scale4d_branch2c
I0529 22:03:47.703442 24924 net.cpp:774] Copying source layer res4d
I0529 22:03:47.703449 24924 net.cpp:774] Copying source layer res4d_relu
I0529 22:03:47.703455 24924 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0529 22:03:47.703461 24924 net.cpp:774] Copying source layer res4e_branch2a
I0529 22:03:47.705246 24924 net.cpp:774] Copying source layer bn4e_branch2a
I0529 22:03:47.705262 24924 net.cpp:774] Copying source layer scale4e_branch2a
I0529 22:03:47.705289 24924 net.cpp:774] Copying source layer res4e_branch2a_relu
I0529 22:03:47.705296 24924 net.cpp:774] Copying source layer res4e_branch2b
I0529 22:03:47.709306 24924 net.cpp:774] Copying source layer bn4e_branch2b
I0529 22:03:47.709323 24924 net.cpp:774] Copying source layer scale4e_branch2b
I0529 22:03:47.709350 24924 net.cpp:774] Copying source layer res4e_branch2b_relu
I0529 22:03:47.709357 24924 net.cpp:774] Copying source layer res4e_branch2c
I0529 22:03:47.711113 24924 net.cpp:774] Copying source layer bn4e_branch2c
I0529 22:03:47.711153 24924 net.cpp:774] Copying source layer scale4e_branch2c
I0529 22:03:47.711177 24924 net.cpp:774] Copying source layer res4e
I0529 22:03:47.711184 24924 net.cpp:774] Copying source layer res4e_relu
I0529 22:03:47.711191 24924 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0529 22:03:47.711199 24924 net.cpp:774] Copying source layer res4f_branch2a
I0529 22:03:47.712955 24924 net.cpp:774] Copying source layer bn4f_branch2a
I0529 22:03:47.712971 24924 net.cpp:774] Copying source layer scale4f_branch2a
I0529 22:03:47.712999 24924 net.cpp:774] Copying source layer res4f_branch2a_relu
I0529 22:03:47.713006 24924 net.cpp:774] Copying source layer res4f_branch2b
I0529 22:03:47.716974 24924 net.cpp:774] Copying source layer bn4f_branch2b
I0529 22:03:47.716992 24924 net.cpp:774] Copying source layer scale4f_branch2b
I0529 22:03:47.717006 24924 net.cpp:774] Copying source layer res4f_branch2b_relu
I0529 22:03:47.717012 24924 net.cpp:774] Copying source layer res4f_branch2c
I0529 22:03:47.718796 24924 net.cpp:774] Copying source layer bn4f_branch2c
I0529 22:03:47.718822 24924 net.cpp:774] Copying source layer scale4f_branch2c
I0529 22:03:47.718845 24924 net.cpp:774] Copying source layer res4f
I0529 22:03:47.718852 24924 net.cpp:774] Copying source layer res4f_relu
I0529 22:03:47.718859 24924 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0529 22:03:47.718866 24924 net.cpp:774] Copying source layer res5a_branch1
I0529 22:03:47.733099 24924 net.cpp:774] Copying source layer bn5a_branch1
I0529 22:03:47.733152 24924 net.cpp:774] Copying source layer scale5a_branch1
I0529 22:03:47.733191 24924 net.cpp:774] Copying source layer res5a_branch2a
I0529 22:03:47.736735 24924 net.cpp:774] Copying source layer bn5a_branch2a
I0529 22:03:47.736773 24924 net.cpp:774] Copying source layer scale5a_branch2a
I0529 22:03:47.736793 24924 net.cpp:774] Copying source layer res5a_branch2a_relu
I0529 22:03:47.736800 24924 net.cpp:774] Copying source layer res5a_branch2b
I0529 22:03:47.752724 24924 net.cpp:774] Copying source layer bn5a_branch2b
I0529 22:03:47.752776 24924 net.cpp:774] Copying source layer scale5a_branch2b
I0529 22:03:47.752795 24924 net.cpp:774] Copying source layer res5a_branch2b_relu
I0529 22:03:47.752802 24924 net.cpp:774] Copying source layer res5a_branch2c
I0529 22:03:47.759893 24924 net.cpp:774] Copying source layer bn5a_branch2c
I0529 22:03:47.759959 24924 net.cpp:774] Copying source layer scale5a_branch2c
I0529 22:03:47.759997 24924 net.cpp:774] Copying source layer res5a
I0529 22:03:47.760004 24924 net.cpp:774] Copying source layer res5a_relu
I0529 22:03:47.760012 24924 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0529 22:03:47.760020 24924 net.cpp:774] Copying source layer res5b_branch2a
I0529 22:03:47.767215 24924 net.cpp:774] Copying source layer bn5b_branch2a
I0529 22:03:47.767251 24924 net.cpp:774] Copying source layer scale5b_branch2a
I0529 22:03:47.767271 24924 net.cpp:774] Copying source layer res5b_branch2a_relu
I0529 22:03:47.767278 24924 net.cpp:774] Copying source layer res5b_branch2b
I0529 22:03:47.783186 24924 net.cpp:774] Copying source layer bn5b_branch2b
I0529 22:03:47.783212 24924 net.cpp:774] Copying source layer scale5b_branch2b
I0529 22:03:47.783231 24924 net.cpp:774] Copying source layer res5b_branch2b_relu
I0529 22:03:47.783237 24924 net.cpp:774] Copying source layer res5b_branch2c
I0529 22:03:47.790349 24924 net.cpp:774] Copying source layer bn5b_branch2c
I0529 22:03:47.790406 24924 net.cpp:774] Copying source layer scale5b_branch2c
I0529 22:03:47.790446 24924 net.cpp:774] Copying source layer res5b
I0529 22:03:47.790452 24924 net.cpp:774] Copying source layer res5b_relu
I0529 22:03:47.790460 24924 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0529 22:03:47.790468 24924 net.cpp:774] Copying source layer res5c_branch2a
I0529 22:03:47.797572 24924 net.cpp:774] Copying source layer bn5c_branch2a
I0529 22:03:47.797596 24924 net.cpp:774] Copying source layer scale5c_branch2a
I0529 22:03:47.797616 24924 net.cpp:774] Copying source layer res5c_branch2a_relu
I0529 22:03:47.797624 24924 net.cpp:774] Copying source layer res5c_branch2b
I0529 22:03:47.813611 24924 net.cpp:774] Copying source layer bn5c_branch2b
I0529 22:03:47.813652 24924 net.cpp:774] Copying source layer scale5c_branch2b
I0529 22:03:47.813673 24924 net.cpp:774] Copying source layer res5c_branch2b_relu
I0529 22:03:47.813679 24924 net.cpp:774] Copying source layer res5c_branch2c
I0529 22:03:47.820785 24924 net.cpp:774] Copying source layer bn5c_branch2c
I0529 22:03:47.820858 24924 net.cpp:774] Copying source layer scale5c_branch2c
I0529 22:03:47.820897 24924 net.cpp:774] Copying source layer res5c
I0529 22:03:47.820904 24924 net.cpp:774] Copying source layer res5c_relu
I0529 22:03:47.820916 24924 net.cpp:771] Ignoring source layer pool5
I0529 22:03:47.820924 24924 net.cpp:771] Ignoring source layer fc1000
I0529 22:03:47.820930 24924 net.cpp:771] Ignoring source layer prob
Solving...
I0529 22:03:50.136123 24924 solver.cpp:228] Iteration 0, loss = 1.45713
I0529 22:03:50.136145 24924 solver.cpp:244]     Train net output #0: accuarcy = 0
I0529 22:03:50.136153 24924 solver.cpp:244]     Train net output #1: loss_bbox = 6.89928e-05 (* 1 = 6.89928e-05 loss)
I0529 22:03:50.136173 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.702885 (* 1 = 0.702885 loss)
I0529 22:03:50.136178 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.677366 (* 1 = 0.677366 loss)
I0529 22:03:50.136183 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128022 (* 1 = 0.128022 loss)
I0529 22:03:50.136188 24924 sgd_solver.cpp:106] Iteration 0, lr = 0.0002
I0529 22:04:39.062430 24924 solver.cpp:228] Iteration 20, loss = 1.18807
I0529 22:04:39.062459 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:04:39.062470 24924 solver.cpp:244]     Train net output #1: loss_bbox = 2.23566e-05 (* 1 = 2.23566e-05 loss)
I0529 22:04:39.062475 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.681105 (* 1 = 0.681105 loss)
I0529 22:04:39.062481 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.477412 (* 1 = 0.477412 loss)
I0529 22:04:39.062485 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028096 (* 1 = 0.028096 loss)
I0529 22:04:39.062491 24924 sgd_solver.cpp:106] Iteration 20, lr = 0.0002
I0529 22:05:27.230959 24924 solver.cpp:228] Iteration 40, loss = 0.946768
I0529 22:05:27.230994 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:05:27.231000 24924 solver.cpp:244]     Train net output #1: loss_bbox = 1.06675e-05 (* 1 = 1.06675e-05 loss)
I0529 22:05:27.231004 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.651759 (* 1 = 0.651759 loss)
I0529 22:05:27.231007 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.265685 (* 1 = 0.265685 loss)
I0529 22:05:27.231011 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020591 (* 1 = 0.020591 loss)
I0529 22:05:27.231015 24924 sgd_solver.cpp:106] Iteration 40, lr = 0.0002
I0529 22:06:15.692153 24924 solver.cpp:228] Iteration 60, loss = 0.864826
I0529 22:06:15.692188 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:06:15.692195 24924 solver.cpp:244]     Train net output #1: loss_bbox = 2.03002e-05 (* 1 = 2.03002e-05 loss)
I0529 22:06:15.692198 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.611433 (* 1 = 0.611433 loss)
I0529 22:06:15.692201 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.15298 (* 1 = 0.15298 loss)
I0529 22:06:15.692204 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240041 (* 1 = 0.0240041 loss)
I0529 22:06:15.692209 24924 sgd_solver.cpp:106] Iteration 60, lr = 0.0002
I0529 22:07:04.182813 24924 solver.cpp:228] Iteration 80, loss = 0.919738
I0529 22:07:04.182842 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:07:04.182849 24924 solver.cpp:244]     Train net output #1: loss_bbox = 3.22893e-05 (* 1 = 3.22893e-05 loss)
I0529 22:07:04.182853 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.573412 (* 1 = 0.573412 loss)
I0529 22:07:04.182857 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.101728 (* 1 = 0.101728 loss)
I0529 22:07:04.182859 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291631 (* 1 = 0.0291631 loss)
I0529 22:07:04.182864 24924 sgd_solver.cpp:106] Iteration 80, lr = 0.0002
I0529 22:07:52.730882 24924 solver.cpp:228] Iteration 100, loss = 0.622673
I0529 22:07:52.730906 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:07:52.730927 24924 solver.cpp:244]     Train net output #1: loss_bbox = 4.46007e-06 (* 1 = 4.46007e-06 loss)
I0529 22:07:52.730931 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.478856 (* 1 = 0.478856 loss)
I0529 22:07:52.730934 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0614107 (* 1 = 0.0614107 loss)
I0529 22:07:52.730937 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224617 (* 1 = 0.0224617 loss)
I0529 22:07:52.730942 24924 sgd_solver.cpp:106] Iteration 100, lr = 0.0002
I0529 22:08:40.969053 24924 solver.cpp:228] Iteration 120, loss = 0.380079
I0529 22:08:40.969089 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:08:40.969096 24924 solver.cpp:244]     Train net output #1: loss_bbox = 5.51012e-05 (* 1 = 5.51012e-05 loss)
I0529 22:08:40.969100 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.264475 (* 1 = 0.264475 loss)
I0529 22:08:40.969105 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0417662 (* 1 = 0.0417662 loss)
I0529 22:08:40.969110 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00839674 (* 1 = 0.00839674 loss)
I0529 22:08:40.969115 24924 sgd_solver.cpp:106] Iteration 120, lr = 0.0002
I0529 22:09:29.471323 24924 solver.cpp:228] Iteration 140, loss = 0.552745
I0529 22:09:29.471345 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 22:09:29.471354 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0848606 (* 1 = 0.0848606 loss)
I0529 22:09:29.471357 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.172457 (* 1 = 0.172457 loss)
I0529 22:09:29.471360 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.209142 (* 1 = 0.209142 loss)
I0529 22:09:29.471364 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0708208 (* 1 = 0.0708208 loss)
I0529 22:09:29.471369 24924 sgd_solver.cpp:106] Iteration 140, lr = 0.0002
/home/user/Disk1.8T/py-R-FCN/tools/../lib/fast_rcnn/bbox_transform.py:23: RuntimeWarning: invalid value encountered in log
  targets_dw = np.log(gt_widths / ex_widths)
I0529 22:10:17.724670 24924 solver.cpp:228] Iteration 160, loss = 0.184183
I0529 22:10:17.724694 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:10:17.724699 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000149233 (* 1 = 0.000149233 loss)
I0529 22:10:17.724704 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0507622 (* 1 = 0.0507622 loss)
I0529 22:10:17.724706 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.034222 (* 1 = 0.034222 loss)
I0529 22:10:17.724709 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195743 (* 1 = 0.0195743 loss)
I0529 22:10:17.724714 24924 sgd_solver.cpp:106] Iteration 160, lr = 0.0002
I0529 22:11:06.190572 24924 solver.cpp:228] Iteration 180, loss = 0.209757
I0529 22:11:06.190609 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:11:06.190615 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000109893 (* 1 = 0.000109893 loss)
I0529 22:11:06.190619 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0996028 (* 1 = 0.0996028 loss)
I0529 22:11:06.190623 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0895827 (* 1 = 0.0895827 loss)
I0529 22:11:06.190626 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0885668 (* 1 = 0.0885668 loss)
I0529 22:11:06.190630 24924 sgd_solver.cpp:106] Iteration 180, lr = 0.0002
speed: 2.426s / iter
I0529 22:11:55.246825 24924 solver.cpp:228] Iteration 200, loss = 0.20073
I0529 22:11:55.246852 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:11:55.246860 24924 solver.cpp:244]     Train net output #1: loss_bbox = 2.66748e-05 (* 1 = 2.66748e-05 loss)
I0529 22:11:55.246863 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0606211 (* 1 = 0.0606211 loss)
I0529 22:11:55.246866 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0452847 (* 1 = 0.0452847 loss)
I0529 22:11:55.246870 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181682 (* 1 = 0.0181682 loss)
I0529 22:11:55.246876 24924 sgd_solver.cpp:106] Iteration 200, lr = 0.0002
I0529 22:12:44.165747 24924 solver.cpp:228] Iteration 220, loss = 0.2135
I0529 22:12:44.165781 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:12:44.165793 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000107546 (* 1 = 0.000107546 loss)
I0529 22:12:44.165801 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0726584 (* 1 = 0.0726584 loss)
I0529 22:12:44.165805 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0722921 (* 1 = 0.0722921 loss)
I0529 22:12:44.165812 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0780568 (* 1 = 0.0780568 loss)
I0529 22:12:44.165819 24924 sgd_solver.cpp:106] Iteration 220, lr = 0.0002
I0529 22:13:34.084434 24924 solver.cpp:228] Iteration 240, loss = 0.152041
I0529 22:13:34.084468 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:13:34.084475 24924 solver.cpp:244]     Train net output #1: loss_bbox = 7.04338e-06 (* 1 = 7.04338e-06 loss)
I0529 22:13:34.084480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.028072 (* 1 = 0.028072 loss)
I0529 22:13:34.084482 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251275 (* 1 = 0.0251275 loss)
I0529 22:13:34.084486 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00620913 (* 1 = 0.00620913 loss)
I0529 22:13:34.084489 24924 sgd_solver.cpp:106] Iteration 240, lr = 0.0002
I0529 22:14:23.134821 24924 solver.cpp:228] Iteration 260, loss = 0.644889
I0529 22:14:23.134842 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:14:23.134863 24924 solver.cpp:244]     Train net output #1: loss_bbox = 9.65705e-05 (* 1 = 9.65705e-05 loss)
I0529 22:14:23.134867 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0935104 (* 1 = 0.0935104 loss)
I0529 22:14:23.134871 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0599559 (* 1 = 0.0599559 loss)
I0529 22:14:23.134874 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0445127 (* 1 = 0.0445127 loss)
I0529 22:14:23.134878 24924 sgd_solver.cpp:106] Iteration 260, lr = 0.0002
I0529 22:15:12.421654 24924 solver.cpp:228] Iteration 280, loss = 0.350368
I0529 22:15:12.421677 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:15:12.421699 24924 solver.cpp:244]     Train net output #1: loss_bbox = 3.02101e-05 (* 1 = 3.02101e-05 loss)
I0529 22:15:12.421702 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.107494 (* 1 = 0.107494 loss)
I0529 22:15:12.421705 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.103019 (* 1 = 0.103019 loss)
I0529 22:15:12.421708 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.131681 (* 1 = 0.131681 loss)
I0529 22:15:12.421713 24924 sgd_solver.cpp:106] Iteration 280, lr = 0.0002
I0529 22:16:01.572005 24924 solver.cpp:228] Iteration 300, loss = 0.189403
I0529 22:16:01.572044 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:16:01.572052 24924 solver.cpp:244]     Train net output #1: loss_bbox = 5.63068e-06 (* 1 = 5.63068e-06 loss)
I0529 22:16:01.572057 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0487975 (* 1 = 0.0487975 loss)
I0529 22:16:01.572059 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039838 (* 1 = 0.039838 loss)
I0529 22:16:01.572062 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274904 (* 1 = 0.0274904 loss)
I0529 22:16:01.572067 24924 sgd_solver.cpp:106] Iteration 300, lr = 0.0002
I0529 22:16:51.281590 24924 solver.cpp:228] Iteration 320, loss = 0.680275
I0529 22:16:51.281626 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 22:16:51.281635 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.333225 (* 1 = 0.333225 loss)
I0529 22:16:51.281638 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.620931 (* 1 = 0.620931 loss)
I0529 22:16:51.281641 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.419318 (* 1 = 0.419318 loss)
I0529 22:16:51.281644 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.340387 (* 1 = 0.340387 loss)
I0529 22:16:51.281648 24924 sgd_solver.cpp:106] Iteration 320, lr = 0.0002
I0529 22:17:41.681740 24924 solver.cpp:228] Iteration 340, loss = 0.486287
I0529 22:17:41.681776 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:17:41.681782 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.057516 (* 1 = 0.057516 loss)
I0529 22:17:41.681785 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0860185 (* 1 = 0.0860185 loss)
I0529 22:17:41.681788 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265412 (* 1 = 0.0265412 loss)
I0529 22:17:41.681792 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00731978 (* 1 = 0.00731978 loss)
I0529 22:17:41.681797 24924 sgd_solver.cpp:106] Iteration 340, lr = 0.0002
I0529 22:18:30.825686 24924 solver.cpp:228] Iteration 360, loss = 0.141512
I0529 22:18:30.825722 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:18:30.825729 24924 solver.cpp:244]     Train net output #1: loss_bbox = 3.74219e-05 (* 1 = 3.74219e-05 loss)
I0529 22:18:30.825733 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0360534 (* 1 = 0.0360534 loss)
I0529 22:18:30.825736 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0412263 (* 1 = 0.0412263 loss)
I0529 22:18:30.825740 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222617 (* 1 = 0.0222617 loss)
I0529 22:18:30.825744 24924 sgd_solver.cpp:106] Iteration 360, lr = 0.0002
I0529 22:19:19.922982 24924 solver.cpp:228] Iteration 380, loss = 0.314221
I0529 22:19:19.923018 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:19:19.923027 24924 solver.cpp:244]     Train net output #1: loss_bbox = 6.13714e-06 (* 1 = 6.13714e-06 loss)
I0529 22:19:19.923030 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0453899 (* 1 = 0.0453899 loss)
I0529 22:19:19.923033 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266463 (* 1 = 0.0266463 loss)
I0529 22:19:19.923036 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119754 (* 1 = 0.0119754 loss)
I0529 22:19:19.923041 24924 sgd_solver.cpp:106] Iteration 380, lr = 0.0002
speed: 2.449s / iter
I0529 22:20:09.831135 24924 solver.cpp:228] Iteration 400, loss = 0.22159
I0529 22:20:09.831157 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:20:09.831164 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0374647 (* 1 = 0.0374647 loss)
I0529 22:20:09.831168 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.125224 (* 1 = 0.125224 loss)
I0529 22:20:09.831172 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0457849 (* 1 = 0.0457849 loss)
I0529 22:20:09.831176 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329163 (* 1 = 0.0329163 loss)
I0529 22:20:09.831179 24924 sgd_solver.cpp:106] Iteration 400, lr = 0.0002
I0529 22:21:01.078300 24924 solver.cpp:228] Iteration 420, loss = 0.232767
I0529 22:21:01.078336 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:21:01.078343 24924 solver.cpp:244]     Train net output #1: loss_bbox = 3.79063e-06 (* 1 = 3.79063e-06 loss)
I0529 22:21:01.078347 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0506563 (* 1 = 0.0506563 loss)
I0529 22:21:01.078351 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263088 (* 1 = 0.0263088 loss)
I0529 22:21:01.078353 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0094887 (* 1 = 0.0094887 loss)
I0529 22:21:01.078357 24924 sgd_solver.cpp:106] Iteration 420, lr = 0.0002
I0529 22:21:50.911715 24924 solver.cpp:228] Iteration 440, loss = 0.245722
I0529 22:21:50.911751 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:21:50.911758 24924 solver.cpp:244]     Train net output #1: loss_bbox = 9.90188e-05 (* 1 = 9.90188e-05 loss)
I0529 22:21:50.911762 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0545821 (* 1 = 0.0545821 loss)
I0529 22:21:50.911765 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0511278 (* 1 = 0.0511278 loss)
I0529 22:21:50.911768 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512575 (* 1 = 0.0512575 loss)
I0529 22:21:50.911773 24924 sgd_solver.cpp:106] Iteration 440, lr = 0.0002
I0529 22:22:40.648417 24924 solver.cpp:228] Iteration 460, loss = 0.579029
I0529 22:22:40.648442 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 22:22:40.648449 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.351028 (* 1 = 0.351028 loss)
I0529 22:22:40.648453 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.723642 (* 1 = 0.723642 loss)
I0529 22:22:40.648456 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.411155 (* 1 = 0.411155 loss)
I0529 22:22:40.648460 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.238158 (* 1 = 0.238158 loss)
I0529 22:22:40.648466 24924 sgd_solver.cpp:106] Iteration 460, lr = 0.0002
I0529 22:23:30.695549 24924 solver.cpp:228] Iteration 480, loss = 0.41636
I0529 22:23:30.695572 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:23:30.695580 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384742 (* 1 = 0.0384742 loss)
I0529 22:23:30.695583 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0714 (* 1 = 0.0714 loss)
I0529 22:23:30.695586 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221901 (* 1 = 0.0221901 loss)
I0529 22:23:30.695590 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105487 (* 1 = 0.0105487 loss)
I0529 22:23:30.695595 24924 sgd_solver.cpp:106] Iteration 480, lr = 0.0002
I0529 22:24:23.047401 24924 solver.cpp:228] Iteration 500, loss = 0.28737
I0529 22:24:23.047426 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:24:23.047433 24924 solver.cpp:244]     Train net output #1: loss_bbox = 2.82874e-05 (* 1 = 2.82874e-05 loss)
I0529 22:24:23.047437 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0200248 (* 1 = 0.0200248 loss)
I0529 22:24:23.047441 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252777 (* 1 = 0.0252777 loss)
I0529 22:24:23.047444 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149485 (* 1 = 0.0149485 loss)
I0529 22:24:23.047451 24924 sgd_solver.cpp:106] Iteration 500, lr = 0.0002
I0529 22:25:16.955214 24924 solver.cpp:228] Iteration 520, loss = 0.373903
I0529 22:25:16.955236 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:25:16.955242 24924 solver.cpp:244]     Train net output #1: loss_bbox = 3.33792e-05 (* 1 = 3.33792e-05 loss)
I0529 22:25:16.955246 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0923916 (* 1 = 0.0923916 loss)
I0529 22:25:16.955250 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0512626 (* 1 = 0.0512626 loss)
I0529 22:25:16.955253 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178675 (* 1 = 0.0178675 loss)
I0529 22:25:16.955257 24924 sgd_solver.cpp:106] Iteration 520, lr = 0.0002
I0529 22:26:11.811013 24924 solver.cpp:228] Iteration 540, loss = 0.446174
I0529 22:26:11.811040 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:26:11.811048 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140229 (* 1 = 0.0140229 loss)
I0529 22:26:11.811053 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0565344 (* 1 = 0.0565344 loss)
I0529 22:26:11.811055 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263231 (* 1 = 0.0263231 loss)
I0529 22:26:11.811059 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012034 (* 1 = 0.012034 loss)
I0529 22:26:11.811064 24924 sgd_solver.cpp:106] Iteration 540, lr = 0.0002
I0529 22:27:04.038789 24924 solver.cpp:228] Iteration 560, loss = 0.222783
I0529 22:27:04.038825 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 22:27:04.038831 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0646308 (* 1 = 0.0646308 loss)
I0529 22:27:04.038836 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134615 (* 1 = 0.134615 loss)
I0529 22:27:04.038838 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246677 (* 1 = 0.0246677 loss)
I0529 22:27:04.038842 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00868729 (* 1 = 0.00868729 loss)
I0529 22:27:04.038846 24924 sgd_solver.cpp:106] Iteration 560, lr = 0.0002
I0529 22:27:56.322995 24924 solver.cpp:228] Iteration 580, loss = 0.339488
I0529 22:27:56.323019 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:27:56.323026 24924 solver.cpp:244]     Train net output #1: loss_bbox = 8.74714e-05 (* 1 = 8.74714e-05 loss)
I0529 22:27:56.323030 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.148853 (* 1 = 0.148853 loss)
I0529 22:27:56.323035 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0479386 (* 1 = 0.0479386 loss)
I0529 22:27:56.323037 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0313745 (* 1 = 0.0313745 loss)
I0529 22:27:56.323041 24924 sgd_solver.cpp:106] Iteration 580, lr = 0.0002
speed: 2.497s / iter
I0529 22:28:48.267017 24924 solver.cpp:228] Iteration 600, loss = 0.409343
I0529 22:28:48.267041 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 22:28:48.267050 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.164969 (* 1 = 0.164969 loss)
I0529 22:28:48.267055 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.313624 (* 1 = 0.313624 loss)
I0529 22:28:48.267060 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0881696 (* 1 = 0.0881696 loss)
I0529 22:28:48.267065 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663183 (* 1 = 0.0663183 loss)
I0529 22:28:48.267069 24924 sgd_solver.cpp:106] Iteration 600, lr = 0.0002
I0529 22:29:38.871095 24924 solver.cpp:228] Iteration 620, loss = 0.441068
I0529 22:29:38.871130 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 22:29:38.871137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0802445 (* 1 = 0.0802445 loss)
I0529 22:29:38.871141 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.206151 (* 1 = 0.206151 loss)
I0529 22:29:38.871145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0187423 (* 1 = 0.0187423 loss)
I0529 22:29:38.871147 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00285959 (* 1 = 0.00285959 loss)
I0529 22:29:38.871152 24924 sgd_solver.cpp:106] Iteration 620, lr = 0.0002
I0529 22:30:29.574638 24924 solver.cpp:228] Iteration 640, loss = 0.392936
I0529 22:30:29.574678 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 22:30:29.574685 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.062089 (* 1 = 0.062089 loss)
I0529 22:30:29.574689 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.220599 (* 1 = 0.220599 loss)
I0529 22:30:29.574693 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0621168 (* 1 = 0.0621168 loss)
I0529 22:30:29.574697 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0495971 (* 1 = 0.0495971 loss)
I0529 22:30:29.574702 24924 sgd_solver.cpp:106] Iteration 640, lr = 0.0002
I0529 22:31:19.846794 24924 solver.cpp:228] Iteration 660, loss = 0.520735
I0529 22:31:19.846817 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:31:19.846824 24924 solver.cpp:244]     Train net output #1: loss_bbox = 4.84531e-05 (* 1 = 4.84531e-05 loss)
I0529 22:31:19.846828 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0482095 (* 1 = 0.0482095 loss)
I0529 22:31:19.846832 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0423723 (* 1 = 0.0423723 loss)
I0529 22:31:19.846835 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371644 (* 1 = 0.0371644 loss)
I0529 22:31:19.846839 24924 sgd_solver.cpp:106] Iteration 660, lr = 0.0002
I0529 22:32:09.834159 24924 solver.cpp:228] Iteration 680, loss = 0.311592
I0529 22:32:09.834189 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:32:09.834197 24924 solver.cpp:244]     Train net output #1: loss_bbox = 6.02621e-05 (* 1 = 6.02621e-05 loss)
I0529 22:32:09.834201 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0431453 (* 1 = 0.0431453 loss)
I0529 22:32:09.834204 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0452075 (* 1 = 0.0452075 loss)
I0529 22:32:09.834208 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136823 (* 1 = 0.0136823 loss)
I0529 22:32:09.834213 24924 sgd_solver.cpp:106] Iteration 680, lr = 0.0002
I0529 22:33:00.432633 24924 solver.cpp:228] Iteration 700, loss = 0.391965
I0529 22:33:00.432668 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 22:33:00.432674 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843884 (* 1 = 0.0843884 loss)
I0529 22:33:00.432678 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.254827 (* 1 = 0.254827 loss)
I0529 22:33:00.432682 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0443205 (* 1 = 0.0443205 loss)
I0529 22:33:00.432684 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0281337 (* 1 = 0.0281337 loss)
I0529 22:33:00.432689 24924 sgd_solver.cpp:106] Iteration 700, lr = 0.0002
I0529 22:33:50.335841 24924 solver.cpp:228] Iteration 720, loss = 0.213139
I0529 22:33:50.335870 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:33:50.335878 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157172 (* 1 = 0.0157172 loss)
I0529 22:33:50.335882 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0727911 (* 1 = 0.0727911 loss)
I0529 22:33:50.335886 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188402 (* 1 = 0.0188402 loss)
I0529 22:33:50.335888 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011932 (* 1 = 0.011932 loss)
I0529 22:33:50.335893 24924 sgd_solver.cpp:106] Iteration 720, lr = 0.0002
I0529 22:34:42.390512 24924 solver.cpp:228] Iteration 740, loss = 0.583106
I0529 22:34:42.390542 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:34:42.390549 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549954 (* 1 = 0.0549954 loss)
I0529 22:34:42.390553 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.18408 (* 1 = 0.18408 loss)
I0529 22:34:42.390556 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364255 (* 1 = 0.0364255 loss)
I0529 22:34:42.390560 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346268 (* 1 = 0.0346268 loss)
I0529 22:34:42.390566 24924 sgd_solver.cpp:106] Iteration 740, lr = 0.0002
I0529 22:35:32.243664 24924 solver.cpp:228] Iteration 760, loss = 0.380469
I0529 22:35:32.243695 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 22:35:32.243702 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.175204 (* 1 = 0.175204 loss)
I0529 22:35:32.243707 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.463062 (* 1 = 0.463062 loss)
I0529 22:35:32.243710 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.154898 (* 1 = 0.154898 loss)
I0529 22:35:32.243715 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.152055 (* 1 = 0.152055 loss)
I0529 22:35:32.243719 24924 sgd_solver.cpp:106] Iteration 760, lr = 0.0002
I0529 22:36:21.610142 24924 solver.cpp:228] Iteration 780, loss = 0.314837
I0529 22:36:21.610172 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:36:21.610180 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0705991 (* 1 = 0.0705991 loss)
I0529 22:36:21.610184 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.164578 (* 1 = 0.164578 loss)
I0529 22:36:21.610188 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0188663 (* 1 = 0.0188663 loss)
I0529 22:36:21.610190 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00641639 (* 1 = 0.00641639 loss)
I0529 22:36:21.610196 24924 sgd_solver.cpp:106] Iteration 780, lr = 0.0002
speed: 2.502s / iter
I0529 22:37:11.864480 24924 solver.cpp:228] Iteration 800, loss = 0.353334
I0529 22:37:11.864518 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 22:37:11.864529 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.164366 (* 1 = 0.164366 loss)
I0529 22:37:11.864536 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272944 (* 1 = 0.272944 loss)
I0529 22:37:11.864542 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214399 (* 1 = 0.0214399 loss)
I0529 22:37:11.864547 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180372 (* 1 = 0.0180372 loss)
I0529 22:37:11.864555 24924 sgd_solver.cpp:106] Iteration 800, lr = 0.0002
I0529 22:38:02.405402 24924 solver.cpp:228] Iteration 820, loss = 0.386389
I0529 22:38:02.405438 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 22:38:02.405445 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.150835 (* 1 = 0.150835 loss)
I0529 22:38:02.405448 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.322325 (* 1 = 0.322325 loss)
I0529 22:38:02.405452 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0464055 (* 1 = 0.0464055 loss)
I0529 22:38:02.405455 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0709512 (* 1 = 0.0709512 loss)
I0529 22:38:02.405459 24924 sgd_solver.cpp:106] Iteration 820, lr = 0.0002
I0529 22:38:51.777442 24924 solver.cpp:228] Iteration 840, loss = 0.594376
I0529 22:38:51.777465 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 22:38:51.777472 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.187562 (* 1 = 0.187562 loss)
I0529 22:38:51.777475 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.423179 (* 1 = 0.423179 loss)
I0529 22:38:51.777478 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0781107 (* 1 = 0.0781107 loss)
I0529 22:38:51.777482 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0473429 (* 1 = 0.0473429 loss)
I0529 22:38:51.777487 24924 sgd_solver.cpp:106] Iteration 840, lr = 0.0002
I0529 22:39:40.888805 24924 solver.cpp:228] Iteration 860, loss = 0.488089
I0529 22:39:40.888842 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 22:39:40.888850 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0569155 (* 1 = 0.0569155 loss)
I0529 22:39:40.888854 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152185 (* 1 = 0.152185 loss)
I0529 22:39:40.888857 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0404183 (* 1 = 0.0404183 loss)
I0529 22:39:40.888860 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0531162 (* 1 = 0.0531162 loss)
I0529 22:39:40.888864 24924 sgd_solver.cpp:106] Iteration 860, lr = 0.0002
I0529 22:40:30.004895 24924 solver.cpp:228] Iteration 880, loss = 0.244522
I0529 22:40:30.004935 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 22:40:30.004940 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.079742 (* 1 = 0.079742 loss)
I0529 22:40:30.004945 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.183388 (* 1 = 0.183388 loss)
I0529 22:40:30.004947 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268361 (* 1 = 0.0268361 loss)
I0529 22:40:30.004951 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311285 (* 1 = 0.0311285 loss)
I0529 22:40:30.004954 24924 sgd_solver.cpp:106] Iteration 880, lr = 0.0002
I0529 22:41:19.032934 24924 solver.cpp:228] Iteration 900, loss = 0.503098
I0529 22:41:19.032956 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 22:41:19.032963 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.244277 (* 1 = 0.244277 loss)
I0529 22:41:19.032965 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.466658 (* 1 = 0.466658 loss)
I0529 22:41:19.032969 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0728965 (* 1 = 0.0728965 loss)
I0529 22:41:19.032972 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0698875 (* 1 = 0.0698875 loss)
I0529 22:41:19.032976 24924 sgd_solver.cpp:106] Iteration 900, lr = 0.0002
I0529 22:42:08.126574 24924 solver.cpp:228] Iteration 920, loss = 0.417284
I0529 22:42:08.126600 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 22:42:08.126608 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627871 (* 1 = 0.0627871 loss)
I0529 22:42:08.126613 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.181324 (* 1 = 0.181324 loss)
I0529 22:42:08.126618 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378086 (* 1 = 0.0378086 loss)
I0529 22:42:08.126622 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0267927 (* 1 = 0.0267927 loss)
I0529 22:42:08.126629 24924 sgd_solver.cpp:106] Iteration 920, lr = 0.0002
I0529 22:42:57.144526 24924 solver.cpp:228] Iteration 940, loss = 0.416931
I0529 22:42:57.144562 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 22:42:57.144569 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103131 (* 1 = 0.103131 loss)
I0529 22:42:57.144573 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291352 (* 1 = 0.291352 loss)
I0529 22:42:57.144577 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0386711 (* 1 = 0.0386711 loss)
I0529 22:42:57.144579 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185116 (* 1 = 0.0185116 loss)
I0529 22:42:57.144584 24924 sgd_solver.cpp:106] Iteration 940, lr = 0.0002
I0529 22:43:46.158042 24924 solver.cpp:228] Iteration 960, loss = 0.342897
I0529 22:43:46.158064 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 22:43:46.158084 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0795905 (* 1 = 0.0795905 loss)
I0529 22:43:46.158088 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.157186 (* 1 = 0.157186 loss)
I0529 22:43:46.158092 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0206872 (* 1 = 0.0206872 loss)
I0529 22:43:46.158094 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00939993 (* 1 = 0.00939993 loss)
I0529 22:43:46.158098 24924 sgd_solver.cpp:106] Iteration 960, lr = 0.0002
I0529 22:44:35.138640 24924 solver.cpp:228] Iteration 980, loss = 0.520095
I0529 22:44:35.138676 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 22:44:35.138682 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0885783 (* 1 = 0.0885783 loss)
I0529 22:44:35.138686 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.158752 (* 1 = 0.158752 loss)
I0529 22:44:35.138690 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0301936 (* 1 = 0.0301936 loss)
I0529 22:44:35.138694 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234677 (* 1 = 0.0234677 loss)
I0529 22:44:35.138697 24924 sgd_solver.cpp:106] Iteration 980, lr = 0.0002
speed: 2.494s / iter
I0529 22:45:24.079982 24924 solver.cpp:228] Iteration 1000, loss = 0.4768
I0529 22:45:24.080003 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 22:45:24.080024 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.155122 (* 1 = 0.155122 loss)
I0529 22:45:24.080026 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.323878 (* 1 = 0.323878 loss)
I0529 22:45:24.080030 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0388642 (* 1 = 0.0388642 loss)
I0529 22:45:24.080034 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0319906 (* 1 = 0.0319906 loss)
I0529 22:45:24.080037 24924 sgd_solver.cpp:106] Iteration 1000, lr = 0.0002
I0529 22:46:13.028080 24924 solver.cpp:228] Iteration 1020, loss = 0.383594
I0529 22:46:13.028105 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0529 22:46:13.028113 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.317549 (* 1 = 0.317549 loss)
I0529 22:46:13.028133 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.563447 (* 1 = 0.563447 loss)
I0529 22:46:13.028138 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0736185 (* 1 = 0.0736185 loss)
I0529 22:46:13.028142 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0569279 (* 1 = 0.0569279 loss)
I0529 22:46:13.028148 24924 sgd_solver.cpp:106] Iteration 1020, lr = 0.0002
I0529 22:47:01.949167 24924 solver.cpp:228] Iteration 1040, loss = 0.176126
I0529 22:47:01.949203 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:47:01.949209 24924 solver.cpp:244]     Train net output #1: loss_bbox = 5.21069e-05 (* 1 = 5.21069e-05 loss)
I0529 22:47:01.949213 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0493495 (* 1 = 0.0493495 loss)
I0529 22:47:01.949216 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203421 (* 1 = 0.0203421 loss)
I0529 22:47:01.949220 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00796674 (* 1 = 0.00796674 loss)
I0529 22:47:01.949224 24924 sgd_solver.cpp:106] Iteration 1040, lr = 0.0002
I0529 22:47:50.838094 24924 solver.cpp:228] Iteration 1060, loss = 0.869156
I0529 22:47:50.838131 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.6875
I0529 22:47:50.838138 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.341707 (* 1 = 0.341707 loss)
I0529 22:47:50.838142 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.774262 (* 1 = 0.774262 loss)
I0529 22:47:50.838145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.496964 (* 1 = 0.496964 loss)
I0529 22:47:50.838148 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.504791 (* 1 = 0.504791 loss)
I0529 22:47:50.838152 24924 sgd_solver.cpp:106] Iteration 1060, lr = 0.0002
I0529 22:48:39.747511 24924 solver.cpp:228] Iteration 1080, loss = 0.537055
I0529 22:48:39.747547 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0529 22:48:39.747555 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.269263 (* 1 = 0.269263 loss)
I0529 22:48:39.747558 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.43697 (* 1 = 0.43697 loss)
I0529 22:48:39.747562 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0562306 (* 1 = 0.0562306 loss)
I0529 22:48:39.747565 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109751 (* 1 = 0.109751 loss)
I0529 22:48:39.747570 24924 sgd_solver.cpp:106] Iteration 1080, lr = 0.0002
I0529 22:49:28.587473 24924 solver.cpp:228] Iteration 1100, loss = 0.211032
I0529 22:49:28.587496 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:49:28.587503 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278598 (* 1 = 0.0278598 loss)
I0529 22:49:28.587507 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0764052 (* 1 = 0.0764052 loss)
I0529 22:49:28.587510 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173844 (* 1 = 0.0173844 loss)
I0529 22:49:28.587512 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126224 (* 1 = 0.0126224 loss)
I0529 22:49:28.587517 24924 sgd_solver.cpp:106] Iteration 1100, lr = 0.0002
I0529 22:50:17.321445 24924 solver.cpp:228] Iteration 1120, loss = 0.487132
I0529 22:50:17.321480 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:50:17.321488 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162253 (* 1 = 0.0162253 loss)
I0529 22:50:17.321492 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113544 (* 1 = 0.113544 loss)
I0529 22:50:17.321496 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0248098 (* 1 = 0.0248098 loss)
I0529 22:50:17.321498 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333191 (* 1 = 0.0333191 loss)
I0529 22:50:17.321502 24924 sgd_solver.cpp:106] Iteration 1120, lr = 0.0002
I0529 22:51:06.125389 24924 solver.cpp:228] Iteration 1140, loss = 0.364414
I0529 22:51:06.125425 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:51:06.125432 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0525506 (* 1 = 0.0525506 loss)
I0529 22:51:06.125435 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.146263 (* 1 = 0.146263 loss)
I0529 22:51:06.125438 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0390964 (* 1 = 0.0390964 loss)
I0529 22:51:06.125442 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0485229 (* 1 = 0.0485229 loss)
I0529 22:51:06.125447 24924 sgd_solver.cpp:106] Iteration 1140, lr = 0.0002
I0529 22:51:54.904299 24924 solver.cpp:228] Iteration 1160, loss = 0.601219
I0529 22:51:54.904337 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 22:51:54.904345 24924 solver.cpp:244]     Train net output #1: loss_bbox = 3.59047e-05 (* 1 = 3.59047e-05 loss)
I0529 22:51:54.904348 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0539114 (* 1 = 0.0539114 loss)
I0529 22:51:54.904351 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133893 (* 1 = 0.0133893 loss)
I0529 22:51:54.904355 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180549 (* 1 = 0.0180549 loss)
I0529 22:51:54.904359 24924 sgd_solver.cpp:106] Iteration 1160, lr = 0.0002
I0529 22:52:43.630563 24924 solver.cpp:228] Iteration 1180, loss = 0.323418
I0529 22:52:43.630599 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:52:43.630606 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737443 (* 1 = 0.0737443 loss)
I0529 22:52:43.630610 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.163601 (* 1 = 0.163601 loss)
I0529 22:52:43.630614 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192534 (* 1 = 0.0192534 loss)
I0529 22:52:43.630616 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010502 (* 1 = 0.010502 loss)
I0529 22:52:43.630620 24924 sgd_solver.cpp:106] Iteration 1180, lr = 0.0002
speed: 2.485s / iter
I0529 22:53:32.281328 24924 solver.cpp:228] Iteration 1200, loss = 0.388185
I0529 22:53:32.281363 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:53:32.281370 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293965 (* 1 = 0.0293965 loss)
I0529 22:53:32.281374 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.138148 (* 1 = 0.138148 loss)
I0529 22:53:32.281378 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160116 (* 1 = 0.0160116 loss)
I0529 22:53:32.281380 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117125 (* 1 = 0.0117125 loss)
I0529 22:53:32.281384 24924 sgd_solver.cpp:106] Iteration 1200, lr = 0.0002
I0529 22:54:21.024339 24924 solver.cpp:228] Iteration 1220, loss = 0.22838
I0529 22:54:21.024374 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 22:54:21.024380 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.16518 (* 1 = 0.16518 loss)
I0529 22:54:21.024384 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.297489 (* 1 = 0.297489 loss)
I0529 22:54:21.024389 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.035527 (* 1 = 0.035527 loss)
I0529 22:54:21.024391 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663006 (* 1 = 0.0663006 loss)
I0529 22:54:21.024395 24924 sgd_solver.cpp:106] Iteration 1220, lr = 0.0002
I0529 22:55:09.740420 24924 solver.cpp:228] Iteration 1240, loss = 0.67936
I0529 22:55:09.740456 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 22:55:09.740463 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305042 (* 1 = 0.0305042 loss)
I0529 22:55:09.740468 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0923263 (* 1 = 0.0923263 loss)
I0529 22:55:09.740470 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327394 (* 1 = 0.0327394 loss)
I0529 22:55:09.740473 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0425688 (* 1 = 0.0425688 loss)
I0529 22:55:09.740478 24924 sgd_solver.cpp:106] Iteration 1240, lr = 0.0002
I0529 22:55:58.392827 24924 solver.cpp:228] Iteration 1260, loss = 0.518343
I0529 22:55:58.392864 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 22:55:58.392871 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297244 (* 1 = 0.0297244 loss)
I0529 22:55:58.392875 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.195698 (* 1 = 0.195698 loss)
I0529 22:55:58.392879 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0363993 (* 1 = 0.0363993 loss)
I0529 22:55:58.392881 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289264 (* 1 = 0.0289264 loss)
I0529 22:55:58.392885 24924 sgd_solver.cpp:106] Iteration 1260, lr = 0.0002
I0529 22:56:47.066884 24924 solver.cpp:228] Iteration 1280, loss = 0.444733
I0529 22:56:47.066905 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 22:56:47.066926 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0288157 (* 1 = 0.0288157 loss)
I0529 22:56:47.066929 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123449 (* 1 = 0.123449 loss)
I0529 22:56:47.066933 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231566 (* 1 = 0.0231566 loss)
I0529 22:56:47.066938 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196255 (* 1 = 0.0196255 loss)
I0529 22:56:47.066943 24924 sgd_solver.cpp:106] Iteration 1280, lr = 0.0002
I0529 22:57:35.686120 24924 solver.cpp:228] Iteration 1300, loss = 0.373216
I0529 22:57:35.686156 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 22:57:35.686163 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.130198 (* 1 = 0.130198 loss)
I0529 22:57:35.686167 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.281255 (* 1 = 0.281255 loss)
I0529 22:57:35.686169 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.036761 (* 1 = 0.036761 loss)
I0529 22:57:35.686173 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481643 (* 1 = 0.0481643 loss)
I0529 22:57:35.686177 24924 sgd_solver.cpp:106] Iteration 1300, lr = 0.0002
I0529 22:58:24.277066 24924 solver.cpp:228] Iteration 1320, loss = 0.277533
I0529 22:58:24.277099 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 22:58:24.277107 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0173861 (* 1 = 0.0173861 loss)
I0529 22:58:24.277109 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127398 (* 1 = 0.127398 loss)
I0529 22:58:24.277113 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015265 (* 1 = 0.015265 loss)
I0529 22:58:24.277117 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123774 (* 1 = 0.0123774 loss)
I0529 22:58:24.277120 24924 sgd_solver.cpp:106] Iteration 1320, lr = 0.0002
I0529 22:59:12.913893 24924 solver.cpp:228] Iteration 1340, loss = 0.873485
I0529 22:59:12.913931 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0529 22:59:12.913938 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.622285 (* 1 = 0.622285 loss)
I0529 22:59:12.913941 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.787918 (* 1 = 0.787918 loss)
I0529 22:59:12.913944 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.125209 (* 1 = 0.125209 loss)
I0529 22:59:12.913947 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.428321 (* 1 = 0.428321 loss)
I0529 22:59:12.913952 24924 sgd_solver.cpp:106] Iteration 1340, lr = 0.0002
I0529 23:00:01.482450 24924 solver.cpp:228] Iteration 1360, loss = 0.462231
I0529 23:00:01.482486 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 23:00:01.482491 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.228465 (* 1 = 0.228465 loss)
I0529 23:00:01.482496 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.406413 (* 1 = 0.406413 loss)
I0529 23:00:01.482498 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039669 (* 1 = 0.039669 loss)
I0529 23:00:01.482501 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0550415 (* 1 = 0.0550415 loss)
I0529 23:00:01.482506 24924 sgd_solver.cpp:106] Iteration 1360, lr = 0.0002
I0529 23:00:50.064782 24924 solver.cpp:228] Iteration 1380, loss = 0.50692
I0529 23:00:50.064819 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:00:50.064827 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595193 (* 1 = 0.0595193 loss)
I0529 23:00:50.064831 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152416 (* 1 = 0.152416 loss)
I0529 23:00:50.064834 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114562 (* 1 = 0.0114562 loss)
I0529 23:00:50.064838 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0081706 (* 1 = 0.0081706 loss)
I0529 23:00:50.064842 24924 sgd_solver.cpp:106] Iteration 1380, lr = 0.0002
speed: 2.477s / iter
I0529 23:01:38.612460 24924 solver.cpp:228] Iteration 1400, loss = 0.382402
I0529 23:01:38.612483 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 23:01:38.612488 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.104693 (* 1 = 0.104693 loss)
I0529 23:01:38.612493 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.19709 (* 1 = 0.19709 loss)
I0529 23:01:38.612495 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0214051 (* 1 = 0.0214051 loss)
I0529 23:01:38.612499 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00751478 (* 1 = 0.00751478 loss)
I0529 23:01:38.612504 24924 sgd_solver.cpp:106] Iteration 1400, lr = 0.0002
I0529 23:02:27.149536 24924 solver.cpp:228] Iteration 1420, loss = 0.674324
I0529 23:02:27.149572 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 23:02:27.149579 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0738832 (* 1 = 0.0738832 loss)
I0529 23:02:27.149582 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.163648 (* 1 = 0.163648 loss)
I0529 23:02:27.149585 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103104 (* 1 = 0.0103104 loss)
I0529 23:02:27.149588 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00909137 (* 1 = 0.00909137 loss)
I0529 23:02:27.149593 24924 sgd_solver.cpp:106] Iteration 1420, lr = 0.0002
I0529 23:03:15.661058 24924 solver.cpp:228] Iteration 1440, loss = 0.388443
I0529 23:03:15.661094 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:03:15.661103 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000162861 (* 1 = 0.000162861 loss)
I0529 23:03:15.661106 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0768987 (* 1 = 0.0768987 loss)
I0529 23:03:15.661109 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226661 (* 1 = 0.0226661 loss)
I0529 23:03:15.661113 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00843398 (* 1 = 0.00843398 loss)
I0529 23:03:15.661118 24924 sgd_solver.cpp:106] Iteration 1440, lr = 0.0002
I0529 23:04:04.207288 24924 solver.cpp:228] Iteration 1460, loss = 0.274643
I0529 23:04:04.207322 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 23:04:04.207330 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.031363 (* 1 = 0.031363 loss)
I0529 23:04:04.207334 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.103586 (* 1 = 0.103586 loss)
I0529 23:04:04.207337 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296379 (* 1 = 0.0296379 loss)
I0529 23:04:04.207340 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272523 (* 1 = 0.0272523 loss)
I0529 23:04:04.207345 24924 sgd_solver.cpp:106] Iteration 1460, lr = 0.0002
I0529 23:04:52.705432 24924 solver.cpp:228] Iteration 1480, loss = 0.312267
I0529 23:04:52.705469 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 23:04:52.705477 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.033441 (* 1 = 0.033441 loss)
I0529 23:04:52.705482 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.192623 (* 1 = 0.192623 loss)
I0529 23:04:52.705484 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251386 (* 1 = 0.0251386 loss)
I0529 23:04:52.705487 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190229 (* 1 = 0.0190229 loss)
I0529 23:04:52.705492 24924 sgd_solver.cpp:106] Iteration 1480, lr = 0.0002
I0529 23:05:41.137950 24924 solver.cpp:228] Iteration 1500, loss = 0.301674
I0529 23:05:41.137986 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:05:41.137995 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00292326 (* 1 = 0.00292326 loss)
I0529 23:05:41.137997 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0620434 (* 1 = 0.0620434 loss)
I0529 23:05:41.138000 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0332846 (* 1 = 0.0332846 loss)
I0529 23:05:41.138005 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0603401 (* 1 = 0.0603401 loss)
I0529 23:05:41.138010 24924 sgd_solver.cpp:106] Iteration 1500, lr = 0.0002
I0529 23:06:29.643182 24924 solver.cpp:228] Iteration 1520, loss = 0.495235
I0529 23:06:29.643218 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 23:06:29.643226 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0969668 (* 1 = 0.0969668 loss)
I0529 23:06:29.643230 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.231253 (* 1 = 0.231253 loss)
I0529 23:06:29.643234 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166263 (* 1 = 0.0166263 loss)
I0529 23:06:29.643236 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0342803 (* 1 = 0.0342803 loss)
I0529 23:06:29.643240 24924 sgd_solver.cpp:106] Iteration 1520, lr = 0.0002
I0529 23:07:18.166764 24924 solver.cpp:228] Iteration 1540, loss = 0.591108
I0529 23:07:18.166800 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:07:18.166807 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0686065 (* 1 = 0.0686065 loss)
I0529 23:07:18.166811 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160346 (* 1 = 0.160346 loss)
I0529 23:07:18.166815 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0736875 (* 1 = 0.0736875 loss)
I0529 23:07:18.166818 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0329287 (* 1 = 0.0329287 loss)
I0529 23:07:18.166822 24924 sgd_solver.cpp:106] Iteration 1540, lr = 0.0002
I0529 23:08:06.681169 24924 solver.cpp:228] Iteration 1560, loss = 0.3218
I0529 23:08:06.681193 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 23:08:06.681200 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890695 (* 1 = 0.0890695 loss)
I0529 23:08:06.681203 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.212018 (* 1 = 0.212018 loss)
I0529 23:08:06.681207 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144977 (* 1 = 0.0144977 loss)
I0529 23:08:06.681210 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323451 (* 1 = 0.0323451 loss)
I0529 23:08:06.681215 24924 sgd_solver.cpp:106] Iteration 1560, lr = 0.0002
I0529 23:08:55.251883 24924 solver.cpp:228] Iteration 1580, loss = 0.436686
I0529 23:08:55.251919 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:08:55.251926 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00110838 (* 1 = 0.00110838 loss)
I0529 23:08:55.251930 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.047611 (* 1 = 0.047611 loss)
I0529 23:08:55.251933 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219233 (* 1 = 0.0219233 loss)
I0529 23:08:55.251936 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00432554 (* 1 = 0.00432554 loss)
I0529 23:08:55.251941 24924 sgd_solver.cpp:106] Iteration 1580, lr = 0.0002
speed: 2.471s / iter
I0529 23:09:43.782232 24924 solver.cpp:228] Iteration 1600, loss = 0.309707
I0529 23:09:43.782266 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:09:43.782274 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00191227 (* 1 = 0.00191227 loss)
I0529 23:09:43.782279 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0736763 (* 1 = 0.0736763 loss)
I0529 23:09:43.782281 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0369653 (* 1 = 0.0369653 loss)
I0529 23:09:43.782284 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00513962 (* 1 = 0.00513962 loss)
I0529 23:09:43.782289 24924 sgd_solver.cpp:106] Iteration 1600, lr = 0.0002
I0529 23:10:32.279657 24924 solver.cpp:228] Iteration 1620, loss = 0.360198
I0529 23:10:32.279695 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 23:10:32.279700 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.134481 (* 1 = 0.134481 loss)
I0529 23:10:32.279705 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.316848 (* 1 = 0.316848 loss)
I0529 23:10:32.279707 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0229824 (* 1 = 0.0229824 loss)
I0529 23:10:32.279711 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0471888 (* 1 = 0.0471888 loss)
I0529 23:10:32.279716 24924 sgd_solver.cpp:106] Iteration 1620, lr = 0.0002
I0529 23:11:20.797475 24924 solver.cpp:228] Iteration 1640, loss = 0.440495
I0529 23:11:20.797510 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 23:11:20.797518 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0772615 (* 1 = 0.0772615 loss)
I0529 23:11:20.797520 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.228111 (* 1 = 0.228111 loss)
I0529 23:11:20.797523 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160279 (* 1 = 0.0160279 loss)
I0529 23:11:20.797528 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206767 (* 1 = 0.0206767 loss)
I0529 23:11:20.797531 24924 sgd_solver.cpp:106] Iteration 1640, lr = 0.0002
I0529 23:12:09.339313 24924 solver.cpp:228] Iteration 1660, loss = 0.610246
I0529 23:12:09.339351 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0529 23:12:09.339357 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.159304 (* 1 = 0.159304 loss)
I0529 23:12:09.339361 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.330358 (* 1 = 0.330358 loss)
I0529 23:12:09.339365 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0535322 (* 1 = 0.0535322 loss)
I0529 23:12:09.339367 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0843275 (* 1 = 0.0843275 loss)
I0529 23:12:09.339372 24924 sgd_solver.cpp:106] Iteration 1660, lr = 0.0002
I0529 23:12:57.880789 24924 solver.cpp:228] Iteration 1680, loss = 0.559426
I0529 23:12:57.880826 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0529 23:12:57.880832 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.095222 (* 1 = 0.095222 loss)
I0529 23:12:57.880836 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.349377 (* 1 = 0.349377 loss)
I0529 23:12:57.880839 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327257 (* 1 = 0.0327257 loss)
I0529 23:12:57.880842 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197308 (* 1 = 0.0197308 loss)
I0529 23:12:57.880847 24924 sgd_solver.cpp:106] Iteration 1680, lr = 0.0002
I0529 23:13:46.481760 24924 solver.cpp:228] Iteration 1700, loss = 0.410065
I0529 23:13:46.481796 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 23:13:46.481802 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0244781 (* 1 = 0.0244781 loss)
I0529 23:13:46.481806 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.071057 (* 1 = 0.071057 loss)
I0529 23:13:46.481809 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0166614 (* 1 = 0.0166614 loss)
I0529 23:13:46.481812 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177443 (* 1 = 0.0177443 loss)
I0529 23:13:46.481817 24924 sgd_solver.cpp:106] Iteration 1700, lr = 0.0002
I0529 23:14:35.012821 24924 solver.cpp:228] Iteration 1720, loss = 0.558984
I0529 23:14:35.012857 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 23:14:35.012864 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108214 (* 1 = 0.0108214 loss)
I0529 23:14:35.012868 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0727317 (* 1 = 0.0727317 loss)
I0529 23:14:35.012871 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116294 (* 1 = 0.0116294 loss)
I0529 23:14:35.012874 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104217 (* 1 = 0.0104217 loss)
I0529 23:14:35.012878 24924 sgd_solver.cpp:106] Iteration 1720, lr = 0.0002
I0529 23:15:23.571831 24924 solver.cpp:228] Iteration 1740, loss = 0.457537
I0529 23:15:23.571871 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0529 23:15:23.571877 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.119941 (* 1 = 0.119941 loss)
I0529 23:15:23.571882 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.302102 (* 1 = 0.302102 loss)
I0529 23:15:23.571884 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0280947 (* 1 = 0.0280947 loss)
I0529 23:15:23.571887 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0518824 (* 1 = 0.0518824 loss)
I0529 23:15:23.571892 24924 sgd_solver.cpp:106] Iteration 1740, lr = 0.0002
I0529 23:16:12.096868 24924 solver.cpp:228] Iteration 1760, loss = 0.640117
I0529 23:16:12.096890 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0529 23:16:12.096896 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.497294 (* 1 = 0.497294 loss)
I0529 23:16:12.096900 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.702258 (* 1 = 0.702258 loss)
I0529 23:16:12.096904 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.608571 (* 1 = 0.608571 loss)
I0529 23:16:12.096906 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.95641 (* 1 = 0.95641 loss)
I0529 23:16:12.096915 24924 sgd_solver.cpp:106] Iteration 1760, lr = 0.0002
I0529 23:17:00.657058 24924 solver.cpp:228] Iteration 1780, loss = 0.297968
I0529 23:17:00.657094 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 23:17:00.657101 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.091933 (* 1 = 0.091933 loss)
I0529 23:17:00.657104 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.177954 (* 1 = 0.177954 loss)
I0529 23:17:00.657109 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143895 (* 1 = 0.0143895 loss)
I0529 23:17:00.657111 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147177 (* 1 = 0.0147177 loss)
I0529 23:17:00.657115 24924 sgd_solver.cpp:106] Iteration 1780, lr = 0.0002
speed: 2.466s / iter
I0529 23:17:49.199864 24924 solver.cpp:228] Iteration 1800, loss = 0.420484
I0529 23:17:49.199899 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0529 23:17:49.199906 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.171027 (* 1 = 0.171027 loss)
I0529 23:17:49.199909 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.361527 (* 1 = 0.361527 loss)
I0529 23:17:49.199913 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0710829 (* 1 = 0.0710829 loss)
I0529 23:17:49.199916 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117603 (* 1 = 0.117603 loss)
I0529 23:17:49.199920 24924 sgd_solver.cpp:106] Iteration 1800, lr = 0.0002
I0529 23:18:37.763126 24924 solver.cpp:228] Iteration 1820, loss = 0.205683
I0529 23:18:37.763162 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:18:37.763170 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165037 (* 1 = 0.0165037 loss)
I0529 23:18:37.763175 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127108 (* 1 = 0.127108 loss)
I0529 23:18:37.763177 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00615607 (* 1 = 0.00615607 loss)
I0529 23:18:37.763180 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00831453 (* 1 = 0.00831453 loss)
I0529 23:18:37.763185 24924 sgd_solver.cpp:106] Iteration 1820, lr = 0.0002
I0529 23:19:26.367286 24924 solver.cpp:228] Iteration 1840, loss = 0.627263
I0529 23:19:26.367322 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:19:26.367329 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339383 (* 1 = 0.0339383 loss)
I0529 23:19:26.367333 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.138227 (* 1 = 0.138227 loss)
I0529 23:19:26.367336 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00610039 (* 1 = 0.00610039 loss)
I0529 23:19:26.367339 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.004564 (* 1 = 0.004564 loss)
I0529 23:19:26.367343 24924 sgd_solver.cpp:106] Iteration 1840, lr = 0.0002
I0529 23:20:14.925825 24924 solver.cpp:228] Iteration 1860, loss = 0.269904
I0529 23:20:14.925863 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 23:20:14.925869 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400466 (* 1 = 0.0400466 loss)
I0529 23:20:14.925873 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.183977 (* 1 = 0.183977 loss)
I0529 23:20:14.925878 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00896837 (* 1 = 0.00896837 loss)
I0529 23:20:14.925880 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00410894 (* 1 = 0.00410894 loss)
I0529 23:20:14.925885 24924 sgd_solver.cpp:106] Iteration 1860, lr = 0.0002
I0529 23:21:03.432951 24924 solver.cpp:228] Iteration 1880, loss = 0.352278
I0529 23:21:03.432999 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:21:03.433007 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00267172 (* 1 = 0.00267172 loss)
I0529 23:21:03.433010 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0495596 (* 1 = 0.0495596 loss)
I0529 23:21:03.433014 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0389881 (* 1 = 0.0389881 loss)
I0529 23:21:03.433017 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214725 (* 1 = 0.0214725 loss)
I0529 23:21:03.433022 24924 sgd_solver.cpp:106] Iteration 1880, lr = 0.0002
I0529 23:21:51.971554 24924 solver.cpp:228] Iteration 1900, loss = 0.658375
I0529 23:21:51.971590 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0529 23:21:51.971597 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.430676 (* 1 = 0.430676 loss)
I0529 23:21:51.971601 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.657777 (* 1 = 0.657777 loss)
I0529 23:21:51.971604 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0671331 (* 1 = 0.0671331 loss)
I0529 23:21:51.971607 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.108924 (* 1 = 0.108924 loss)
I0529 23:21:51.971611 24924 sgd_solver.cpp:106] Iteration 1900, lr = 0.0002
I0529 23:22:40.549870 24924 solver.cpp:228] Iteration 1920, loss = 0.334127
I0529 23:22:40.549906 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0529 23:22:40.549914 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325358 (* 1 = 0.0325358 loss)
I0529 23:22:40.549918 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.16065 (* 1 = 0.16065 loss)
I0529 23:22:40.549921 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201319 (* 1 = 0.0201319 loss)
I0529 23:22:40.549924 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563675 (* 1 = 0.0563675 loss)
I0529 23:22:40.549928 24924 sgd_solver.cpp:106] Iteration 1920, lr = 0.0002
I0529 23:23:29.083956 24924 solver.cpp:228] Iteration 1940, loss = 0.357026
I0529 23:23:29.083990 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:23:29.083997 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.054327 (* 1 = 0.054327 loss)
I0529 23:23:29.084000 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144744 (* 1 = 0.144744 loss)
I0529 23:23:29.084003 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255698 (* 1 = 0.0255698 loss)
I0529 23:23:29.084007 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183878 (* 1 = 0.0183878 loss)
I0529 23:23:29.084010 24924 sgd_solver.cpp:106] Iteration 1940, lr = 0.0002
I0529 23:24:17.660394 24924 solver.cpp:228] Iteration 1960, loss = 0.166374
I0529 23:24:17.660430 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0529 23:24:17.660439 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.055313 (* 1 = 0.055313 loss)
I0529 23:24:17.660441 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.1002 (* 1 = 0.1002 loss)
I0529 23:24:17.660445 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00984327 (* 1 = 0.00984327 loss)
I0529 23:24:17.660449 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160901 (* 1 = 0.0160901 loss)
I0529 23:24:17.660452 24924 sgd_solver.cpp:106] Iteration 1960, lr = 0.0002
I0529 23:25:06.242424 24924 solver.cpp:228] Iteration 1980, loss = 0.46612
I0529 23:25:06.242446 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 23:25:06.242468 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0918508 (* 1 = 0.0918508 loss)
I0529 23:25:06.242471 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.379713 (* 1 = 0.379713 loss)
I0529 23:25:06.242475 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0551137 (* 1 = 0.0551137 loss)
I0529 23:25:06.242477 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101456 (* 1 = 0.101456 loss)
I0529 23:25:06.242482 24924 sgd_solver.cpp:106] Iteration 1980, lr = 0.0002
speed: 2.462s / iter
I0529 23:25:54.793833 24924 solver.cpp:228] Iteration 2000, loss = 0.309296
I0529 23:25:54.793867 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 23:25:54.793874 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.073162 (* 1 = 0.073162 loss)
I0529 23:25:54.793879 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.178668 (* 1 = 0.178668 loss)
I0529 23:25:54.793881 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112987 (* 1 = 0.0112987 loss)
I0529 23:25:54.793884 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108176 (* 1 = 0.0108176 loss)
I0529 23:25:54.793889 24924 sgd_solver.cpp:106] Iteration 2000, lr = 0.0002
I0529 23:26:43.358196 24924 solver.cpp:228] Iteration 2020, loss = 0.583347
I0529 23:26:43.358219 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 23:26:43.358227 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.245257 (* 1 = 0.245257 loss)
I0529 23:26:43.358230 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.432299 (* 1 = 0.432299 loss)
I0529 23:26:43.358233 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021279 (* 1 = 0.021279 loss)
I0529 23:26:43.358237 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0423079 (* 1 = 0.0423079 loss)
I0529 23:26:43.358242 24924 sgd_solver.cpp:106] Iteration 2020, lr = 0.0002
I0529 23:27:31.915125 24924 solver.cpp:228] Iteration 2040, loss = 0.408967
I0529 23:27:31.915146 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 23:27:31.915153 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00494495 (* 1 = 0.00494495 loss)
I0529 23:27:31.915158 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0940025 (* 1 = 0.0940025 loss)
I0529 23:27:31.915160 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0231677 (* 1 = 0.0231677 loss)
I0529 23:27:31.915163 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512588 (* 1 = 0.0512588 loss)
I0529 23:27:31.915168 24924 sgd_solver.cpp:106] Iteration 2040, lr = 0.0002
I0529 23:28:20.515215 24924 solver.cpp:228] Iteration 2060, loss = 0.25177
I0529 23:28:20.515254 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 23:28:20.515260 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.16019 (* 1 = 0.16019 loss)
I0529 23:28:20.515264 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.295247 (* 1 = 0.295247 loss)
I0529 23:28:20.515266 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256558 (* 1 = 0.0256558 loss)
I0529 23:28:20.515269 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491378 (* 1 = 0.0491378 loss)
I0529 23:28:20.515275 24924 sgd_solver.cpp:106] Iteration 2060, lr = 0.0002
I0529 23:29:09.093425 24924 solver.cpp:228] Iteration 2080, loss = 0.509153
I0529 23:29:09.093472 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:29:09.093479 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00172255 (* 1 = 0.00172255 loss)
I0529 23:29:09.093484 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0544706 (* 1 = 0.0544706 loss)
I0529 23:29:09.093487 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155169 (* 1 = 0.0155169 loss)
I0529 23:29:09.093490 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0476383 (* 1 = 0.0476383 loss)
I0529 23:29:09.093494 24924 sgd_solver.cpp:106] Iteration 2080, lr = 0.0002
I0529 23:29:57.694700 24924 solver.cpp:228] Iteration 2100, loss = 0.445933
I0529 23:29:57.694736 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 23:29:57.694743 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.170418 (* 1 = 0.170418 loss)
I0529 23:29:57.694746 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.344631 (* 1 = 0.344631 loss)
I0529 23:29:57.694751 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0240947 (* 1 = 0.0240947 loss)
I0529 23:29:57.694753 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449377 (* 1 = 0.0449377 loss)
I0529 23:29:57.694757 24924 sgd_solver.cpp:106] Iteration 2100, lr = 0.0002
I0529 23:30:46.249526 24924 solver.cpp:228] Iteration 2120, loss = 0.422689
I0529 23:30:46.249563 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0529 23:30:46.249572 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.267246 (* 1 = 0.267246 loss)
I0529 23:30:46.249574 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.462691 (* 1 = 0.462691 loss)
I0529 23:30:46.249577 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0384283 (* 1 = 0.0384283 loss)
I0529 23:30:46.249581 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0626207 (* 1 = 0.0626207 loss)
I0529 23:30:46.249585 24924 sgd_solver.cpp:106] Iteration 2120, lr = 0.0002
I0529 23:31:34.807696 24924 solver.cpp:228] Iteration 2140, loss = 0.540993
I0529 23:31:34.807731 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0529 23:31:34.807739 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.303369 (* 1 = 0.303369 loss)
I0529 23:31:34.807744 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.505617 (* 1 = 0.505617 loss)
I0529 23:31:34.807746 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0626729 (* 1 = 0.0626729 loss)
I0529 23:31:34.807749 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.164008 (* 1 = 0.164008 loss)
I0529 23:31:34.807754 24924 sgd_solver.cpp:106] Iteration 2140, lr = 0.0002
I0529 23:32:23.408615 24924 solver.cpp:228] Iteration 2160, loss = 0.322125
I0529 23:32:23.408653 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 23:32:23.408660 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.143056 (* 1 = 0.143056 loss)
I0529 23:32:23.408664 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.322627 (* 1 = 0.322627 loss)
I0529 23:32:23.408668 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0506976 (* 1 = 0.0506976 loss)
I0529 23:32:23.408670 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0595409 (* 1 = 0.0595409 loss)
I0529 23:32:23.408675 24924 sgd_solver.cpp:106] Iteration 2160, lr = 0.0002
I0529 23:33:11.938946 24924 solver.cpp:228] Iteration 2180, loss = 0.240089
I0529 23:33:11.938982 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 23:33:11.938988 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0140955 (* 1 = 0.0140955 loss)
I0529 23:33:11.938992 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.071832 (* 1 = 0.071832 loss)
I0529 23:33:11.938995 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149192 (* 1 = 0.0149192 loss)
I0529 23:33:11.938997 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127829 (* 1 = 0.0127829 loss)
I0529 23:33:11.939002 24924 sgd_solver.cpp:106] Iteration 2180, lr = 0.0002
speed: 2.459s / iter
I0529 23:34:00.529312 24924 solver.cpp:228] Iteration 2200, loss = 0.704527
I0529 23:34:00.529348 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:34:00.529355 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00183918 (* 1 = 0.00183918 loss)
I0529 23:34:00.529358 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0511952 (* 1 = 0.0511952 loss)
I0529 23:34:00.529361 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0277574 (* 1 = 0.0277574 loss)
I0529 23:34:00.529366 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00860367 (* 1 = 0.00860367 loss)
I0529 23:34:00.529369 24924 sgd_solver.cpp:106] Iteration 2200, lr = 0.0002
I0529 23:34:49.112854 24924 solver.cpp:228] Iteration 2220, loss = 0.308215
I0529 23:34:49.112888 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:34:49.112895 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0301968 (* 1 = 0.0301968 loss)
I0529 23:34:49.112898 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.162011 (* 1 = 0.162011 loss)
I0529 23:34:49.112901 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018446 (* 1 = 0.018446 loss)
I0529 23:34:49.112905 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134903 (* 1 = 0.0134903 loss)
I0529 23:34:49.112910 24924 sgd_solver.cpp:106] Iteration 2220, lr = 0.0002
I0529 23:35:37.689702 24924 solver.cpp:228] Iteration 2240, loss = 0.361232
I0529 23:35:37.689738 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 23:35:37.689744 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.223545 (* 1 = 0.223545 loss)
I0529 23:35:37.689749 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.477875 (* 1 = 0.477875 loss)
I0529 23:35:37.689751 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.108186 (* 1 = 0.108186 loss)
I0529 23:35:37.689754 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0974671 (* 1 = 0.0974671 loss)
I0529 23:35:37.689759 24924 sgd_solver.cpp:106] Iteration 2240, lr = 0.0002
I0529 23:36:26.307461 24924 solver.cpp:228] Iteration 2260, loss = 0.434268
I0529 23:36:26.307497 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 23:36:26.307504 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912563 (* 1 = 0.0912563 loss)
I0529 23:36:26.307508 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.2371 (* 1 = 0.2371 loss)
I0529 23:36:26.307512 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155823 (* 1 = 0.0155823 loss)
I0529 23:36:26.307514 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0266599 (* 1 = 0.0266599 loss)
I0529 23:36:26.307519 24924 sgd_solver.cpp:106] Iteration 2260, lr = 0.0002
I0529 23:37:14.868455 24924 solver.cpp:228] Iteration 2280, loss = 0.386901
I0529 23:37:14.868477 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:37:14.868486 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0289027 (* 1 = 0.0289027 loss)
I0529 23:37:14.868505 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.169169 (* 1 = 0.169169 loss)
I0529 23:37:14.868510 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107374 (* 1 = 0.0107374 loss)
I0529 23:37:14.868515 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00806602 (* 1 = 0.00806602 loss)
I0529 23:37:14.868521 24924 sgd_solver.cpp:106] Iteration 2280, lr = 0.0002
I0529 23:38:03.499773 24924 solver.cpp:228] Iteration 2300, loss = 0.294871
I0529 23:38:03.499807 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:38:03.499815 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0828097 (* 1 = 0.0828097 loss)
I0529 23:38:03.499819 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160741 (* 1 = 0.160741 loss)
I0529 23:38:03.499822 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0286055 (* 1 = 0.0286055 loss)
I0529 23:38:03.499825 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181533 (* 1 = 0.0181533 loss)
I0529 23:38:03.499830 24924 sgd_solver.cpp:106] Iteration 2300, lr = 0.0002
I0529 23:38:52.064882 24924 solver.cpp:228] Iteration 2320, loss = 0.557935
I0529 23:38:52.064919 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0529 23:38:52.064927 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0556077 (* 1 = 0.0556077 loss)
I0529 23:38:52.064931 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143195 (* 1 = 0.143195 loss)
I0529 23:38:52.064934 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0370912 (* 1 = 0.0370912 loss)
I0529 23:38:52.064937 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306474 (* 1 = 0.0306474 loss)
I0529 23:38:52.064941 24924 sgd_solver.cpp:106] Iteration 2320, lr = 0.0002
I0529 23:39:40.678472 24924 solver.cpp:228] Iteration 2340, loss = 0.516422
I0529 23:39:40.678508 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 23:39:40.678514 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0486722 (* 1 = 0.0486722 loss)
I0529 23:39:40.678519 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.15565 (* 1 = 0.15565 loss)
I0529 23:39:40.678521 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136563 (* 1 = 0.0136563 loss)
I0529 23:39:40.678524 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383112 (* 1 = 0.0383112 loss)
I0529 23:39:40.678529 24924 sgd_solver.cpp:106] Iteration 2340, lr = 0.0002
I0529 23:40:29.311137 24924 solver.cpp:228] Iteration 2360, loss = 0.487321
I0529 23:40:29.311172 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 23:40:29.311179 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.157077 (* 1 = 0.157077 loss)
I0529 23:40:29.311182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.377472 (* 1 = 0.377472 loss)
I0529 23:40:29.311185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0524645 (* 1 = 0.0524645 loss)
I0529 23:40:29.311188 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0530523 (* 1 = 0.0530523 loss)
I0529 23:40:29.311192 24924 sgd_solver.cpp:106] Iteration 2360, lr = 0.0002
I0529 23:41:17.912824 24924 solver.cpp:228] Iteration 2380, loss = 0.383666
I0529 23:41:17.912860 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 23:41:17.912868 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0849002 (* 1 = 0.0849002 loss)
I0529 23:41:17.912871 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.33332 (* 1 = 0.33332 loss)
I0529 23:41:17.912875 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.155205 (* 1 = 0.155205 loss)
I0529 23:41:17.912878 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0928362 (* 1 = 0.0928362 loss)
I0529 23:41:17.912883 24924 sgd_solver.cpp:106] Iteration 2380, lr = 0.0002
speed: 2.457s / iter
I0529 23:42:06.484112 24924 solver.cpp:228] Iteration 2400, loss = 0.425598
I0529 23:42:06.484148 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0529 23:42:06.484155 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.2341 (* 1 = 0.2341 loss)
I0529 23:42:06.484159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.335804 (* 1 = 0.335804 loss)
I0529 23:42:06.484163 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0354866 (* 1 = 0.0354866 loss)
I0529 23:42:06.484165 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624014 (* 1 = 0.0624014 loss)
I0529 23:42:06.484169 24924 sgd_solver.cpp:106] Iteration 2400, lr = 0.0002
I0529 23:42:55.156728 24924 solver.cpp:228] Iteration 2420, loss = 0.408037
I0529 23:42:55.156749 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:42:55.156770 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399103 (* 1 = 0.0399103 loss)
I0529 23:42:55.156774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143634 (* 1 = 0.143634 loss)
I0529 23:42:55.156777 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153804 (* 1 = 0.0153804 loss)
I0529 23:42:55.156780 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00981229 (* 1 = 0.00981229 loss)
I0529 23:42:55.156785 24924 sgd_solver.cpp:106] Iteration 2420, lr = 0.0002
I0529 23:43:43.716168 24924 solver.cpp:228] Iteration 2440, loss = 0.262559
I0529 23:43:43.716204 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 23:43:43.716210 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160399 (* 1 = 0.160399 loss)
I0529 23:43:43.716214 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291816 (* 1 = 0.291816 loss)
I0529 23:43:43.716217 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0404506 (* 1 = 0.0404506 loss)
I0529 23:43:43.716222 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0439822 (* 1 = 0.0439822 loss)
I0529 23:43:43.716225 24924 sgd_solver.cpp:106] Iteration 2440, lr = 0.0002
I0529 23:44:32.287816 24924 solver.cpp:228] Iteration 2460, loss = 0.334712
I0529 23:44:32.287852 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 23:44:32.287858 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.1157 (* 1 = 0.1157 loss)
I0529 23:44:32.287863 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.172082 (* 1 = 0.172082 loss)
I0529 23:44:32.287865 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0292498 (* 1 = 0.0292498 loss)
I0529 23:44:32.287869 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0177185 (* 1 = 0.0177185 loss)
I0529 23:44:32.287875 24924 sgd_solver.cpp:106] Iteration 2460, lr = 0.0002
I0529 23:45:20.857410 24924 solver.cpp:228] Iteration 2480, loss = 0.4499
I0529 23:45:20.857446 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0529 23:45:20.857453 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.175871 (* 1 = 0.175871 loss)
I0529 23:45:20.857456 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.344859 (* 1 = 0.344859 loss)
I0529 23:45:20.857460 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167689 (* 1 = 0.0167689 loss)
I0529 23:45:20.857463 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315194 (* 1 = 0.0315194 loss)
I0529 23:45:20.857467 24924 sgd_solver.cpp:106] Iteration 2480, lr = 0.0002
I0529 23:46:09.515830 24924 solver.cpp:228] Iteration 2500, loss = 0.274933
I0529 23:46:09.515866 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0529 23:46:09.515874 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00144936 (* 1 = 0.00144936 loss)
I0529 23:46:09.515877 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101522 (* 1 = 0.101522 loss)
I0529 23:46:09.515882 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199298 (* 1 = 0.0199298 loss)
I0529 23:46:09.515884 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358663 (* 1 = 0.0358663 loss)
I0529 23:46:09.515888 24924 sgd_solver.cpp:106] Iteration 2500, lr = 0.0002
I0529 23:46:58.095252 24924 solver.cpp:228] Iteration 2520, loss = 0.35236
I0529 23:46:58.095288 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 23:46:58.095295 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.185329 (* 1 = 0.185329 loss)
I0529 23:46:58.095299 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.375447 (* 1 = 0.375447 loss)
I0529 23:46:58.095301 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0445134 (* 1 = 0.0445134 loss)
I0529 23:46:58.095305 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0566858 (* 1 = 0.0566858 loss)
I0529 23:46:58.095309 24924 sgd_solver.cpp:106] Iteration 2520, lr = 0.0002
I0529 23:47:46.653113 24924 solver.cpp:228] Iteration 2540, loss = 0.357688
I0529 23:47:46.653149 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:47:46.653156 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0434396 (* 1 = 0.0434396 loss)
I0529 23:47:46.653159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.172615 (* 1 = 0.172615 loss)
I0529 23:47:46.653162 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141397 (* 1 = 0.0141397 loss)
I0529 23:47:46.653165 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0294086 (* 1 = 0.0294086 loss)
I0529 23:47:46.653169 24924 sgd_solver.cpp:106] Iteration 2540, lr = 0.0002
I0529 23:48:35.249760 24924 solver.cpp:228] Iteration 2560, loss = 0.401367
I0529 23:48:35.249796 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 23:48:35.249804 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.119518 (* 1 = 0.119518 loss)
I0529 23:48:35.249806 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.282378 (* 1 = 0.282378 loss)
I0529 23:48:35.249810 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145708 (* 1 = 0.0145708 loss)
I0529 23:48:35.249812 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0129824 (* 1 = 0.0129824 loss)
I0529 23:48:35.249817 24924 sgd_solver.cpp:106] Iteration 2560, lr = 0.0002
I0529 23:49:23.833921 24924 solver.cpp:228] Iteration 2580, loss = 0.375991
I0529 23:49:23.833956 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0529 23:49:23.833963 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.18269 (* 1 = 0.18269 loss)
I0529 23:49:23.833966 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.324771 (* 1 = 0.324771 loss)
I0529 23:49:23.833971 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162835 (* 1 = 0.0162835 loss)
I0529 23:49:23.833973 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346633 (* 1 = 0.0346633 loss)
I0529 23:49:23.833977 24924 sgd_solver.cpp:106] Iteration 2580, lr = 0.0002
speed: 2.455s / iter
I0529 23:50:12.420521 24924 solver.cpp:228] Iteration 2600, loss = 0.685659
I0529 23:50:12.420543 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0529 23:50:12.420550 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0730206 (* 1 = 0.0730206 loss)
I0529 23:50:12.420553 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.192064 (* 1 = 0.192064 loss)
I0529 23:50:12.420557 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120912 (* 1 = 0.0120912 loss)
I0529 23:50:12.420559 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0412995 (* 1 = 0.0412995 loss)
I0529 23:50:12.420564 24924 sgd_solver.cpp:106] Iteration 2600, lr = 0.0002
I0529 23:51:00.983609 24924 solver.cpp:228] Iteration 2620, loss = 0.439254
I0529 23:51:00.983644 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0529 23:51:00.983652 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000403913 (* 1 = 0.000403913 loss)
I0529 23:51:00.983656 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0730531 (* 1 = 0.0730531 loss)
I0529 23:51:00.983659 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260392 (* 1 = 0.0260392 loss)
I0529 23:51:00.983662 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00931888 (* 1 = 0.00931888 loss)
I0529 23:51:00.983667 24924 sgd_solver.cpp:106] Iteration 2620, lr = 0.0002
I0529 23:51:49.588356 24924 solver.cpp:228] Iteration 2640, loss = 0.377554
I0529 23:51:49.588392 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 23:51:49.588399 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.110932 (* 1 = 0.110932 loss)
I0529 23:51:49.588403 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.244864 (* 1 = 0.244864 loss)
I0529 23:51:49.588407 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191533 (* 1 = 0.0191533 loss)
I0529 23:51:49.588409 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180199 (* 1 = 0.0180199 loss)
I0529 23:51:49.588413 24924 sgd_solver.cpp:106] Iteration 2640, lr = 0.0002
I0529 23:52:38.292716 24924 solver.cpp:228] Iteration 2660, loss = 0.259443
I0529 23:52:38.292752 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0529 23:52:38.292758 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.18908 (* 1 = 0.18908 loss)
I0529 23:52:38.292762 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.346967 (* 1 = 0.346967 loss)
I0529 23:52:38.292765 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268662 (* 1 = 0.0268662 loss)
I0529 23:52:38.292768 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275905 (* 1 = 0.0275905 loss)
I0529 23:52:38.292773 24924 sgd_solver.cpp:106] Iteration 2660, lr = 0.0002
I0529 23:53:27.001312 24924 solver.cpp:228] Iteration 2680, loss = 0.265008
I0529 23:53:27.001334 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0529 23:53:27.001343 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0933323 (* 1 = 0.0933323 loss)
I0529 23:53:27.001363 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.218151 (* 1 = 0.218151 loss)
I0529 23:53:27.001368 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772154 (* 1 = 0.00772154 loss)
I0529 23:53:27.001372 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321081 (* 1 = 0.0321081 loss)
I0529 23:53:27.001379 24924 sgd_solver.cpp:106] Iteration 2680, lr = 0.0002
I0529 23:54:15.803349 24924 solver.cpp:228] Iteration 2700, loss = 0.28949
I0529 23:54:15.803372 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:54:15.803381 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0661292 (* 1 = 0.0661292 loss)
I0529 23:54:15.803401 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.170938 (* 1 = 0.170938 loss)
I0529 23:54:15.803406 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128341 (* 1 = 0.0128341 loss)
I0529 23:54:15.803411 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140556 (* 1 = 0.0140556 loss)
I0529 23:54:15.803416 24924 sgd_solver.cpp:106] Iteration 2700, lr = 0.0002
I0529 23:55:04.599617 24924 solver.cpp:228] Iteration 2720, loss = 0.490801
I0529 23:55:04.599639 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0529 23:55:04.599647 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0661113 (* 1 = 0.0661113 loss)
I0529 23:55:04.599668 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.118139 (* 1 = 0.118139 loss)
I0529 23:55:04.599673 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00811815 (* 1 = 0.00811815 loss)
I0529 23:55:04.599676 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00930871 (* 1 = 0.00930871 loss)
I0529 23:55:04.599681 24924 sgd_solver.cpp:106] Iteration 2720, lr = 0.0002
I0529 23:55:53.364730 24924 solver.cpp:228] Iteration 2740, loss = 0.595584
I0529 23:55:53.364766 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0529 23:55:53.364773 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.306513 (* 1 = 0.306513 loss)
I0529 23:55:53.364776 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.555144 (* 1 = 0.555144 loss)
I0529 23:55:53.364779 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.316506 (* 1 = 0.316506 loss)
I0529 23:55:53.364783 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.262688 (* 1 = 0.262688 loss)
I0529 23:55:53.364786 24924 sgd_solver.cpp:106] Iteration 2740, lr = 0.0002
I0529 23:56:42.135233 24924 solver.cpp:228] Iteration 2760, loss = 0.551134
I0529 23:56:42.135257 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 23:56:42.135265 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.11086 (* 1 = 0.11086 loss)
I0529 23:56:42.135284 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.248618 (* 1 = 0.248618 loss)
I0529 23:56:42.135289 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017372 (* 1 = 0.017372 loss)
I0529 23:56:42.135294 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0479941 (* 1 = 0.0479941 loss)
I0529 23:56:42.135299 24924 sgd_solver.cpp:106] Iteration 2760, lr = 0.0002
I0529 23:57:30.999572 24924 solver.cpp:228] Iteration 2780, loss = 0.328279
I0529 23:57:30.999608 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0529 23:57:30.999614 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102277 (* 1 = 0.102277 loss)
I0529 23:57:30.999619 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.327551 (* 1 = 0.327551 loss)
I0529 23:57:30.999621 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0719386 (* 1 = 0.0719386 loss)
I0529 23:57:30.999624 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0510453 (* 1 = 0.0510453 loss)
I0529 23:57:30.999629 24924 sgd_solver.cpp:106] Iteration 2780, lr = 0.0002
speed: 2.453s / iter
I0529 23:58:19.862337 24924 solver.cpp:228] Iteration 2800, loss = 0.427224
I0529 23:58:19.862359 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0529 23:58:19.862366 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0596241 (* 1 = 0.0596241 loss)
I0529 23:58:19.862372 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165968 (* 1 = 0.165968 loss)
I0529 23:58:19.862376 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111047 (* 1 = 0.0111047 loss)
I0529 23:58:19.862382 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150616 (* 1 = 0.0150616 loss)
I0529 23:58:19.862387 24924 sgd_solver.cpp:106] Iteration 2800, lr = 0.0002
I0529 23:59:08.783771 24924 solver.cpp:228] Iteration 2820, loss = 0.500182
I0529 23:59:08.783797 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0529 23:59:08.783804 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.281369 (* 1 = 0.281369 loss)
I0529 23:59:08.783823 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.421214 (* 1 = 0.421214 loss)
I0529 23:59:08.783828 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0246709 (* 1 = 0.0246709 loss)
I0529 23:59:08.783833 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395151 (* 1 = 0.0395151 loss)
I0529 23:59:08.783839 24924 sgd_solver.cpp:106] Iteration 2820, lr = 0.0002
I0529 23:59:57.637336 24924 solver.cpp:228] Iteration 2840, loss = 0.264171
I0529 23:59:57.637358 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0529 23:59:57.637367 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.140596 (* 1 = 0.140596 loss)
I0529 23:59:57.637387 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.232181 (* 1 = 0.232181 loss)
I0529 23:59:57.637392 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00935387 (* 1 = 0.00935387 loss)
I0529 23:59:57.637396 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383027 (* 1 = 0.0383027 loss)
I0529 23:59:57.637403 24924 sgd_solver.cpp:106] Iteration 2840, lr = 0.0002
I0530 00:00:46.514967 24924 solver.cpp:228] Iteration 2860, loss = 0.42192
I0530 00:00:46.514989 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 00:00:46.515010 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.177971 (* 1 = 0.177971 loss)
I0530 00:00:46.515013 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.224793 (* 1 = 0.224793 loss)
I0530 00:00:46.515017 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073593 (* 1 = 0.0073593 loss)
I0530 00:00:46.515020 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191835 (* 1 = 0.0191835 loss)
I0530 00:00:46.515024 24924 sgd_solver.cpp:106] Iteration 2860, lr = 0.0002
I0530 00:01:35.371551 24924 solver.cpp:228] Iteration 2880, loss = 0.33239
I0530 00:01:35.371587 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:01:35.371594 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0246708 (* 1 = 0.0246708 loss)
I0530 00:01:35.371598 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.189183 (* 1 = 0.189183 loss)
I0530 00:01:35.371601 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165723 (* 1 = 0.0165723 loss)
I0530 00:01:35.371604 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00663364 (* 1 = 0.00663364 loss)
I0530 00:01:35.371608 24924 sgd_solver.cpp:106] Iteration 2880, lr = 0.0002
I0530 00:02:24.213167 24924 solver.cpp:228] Iteration 2900, loss = 0.309388
I0530 00:02:24.213191 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:02:24.213198 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0212866 (* 1 = 0.0212866 loss)
I0530 00:02:24.213203 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.111746 (* 1 = 0.111746 loss)
I0530 00:02:24.213207 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00695332 (* 1 = 0.00695332 loss)
I0530 00:02:24.213210 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942987 (* 1 = 0.00942987 loss)
I0530 00:02:24.213214 24924 sgd_solver.cpp:106] Iteration 2900, lr = 0.0002
I0530 00:03:13.001062 24924 solver.cpp:228] Iteration 2920, loss = 0.402641
I0530 00:03:13.001099 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 00:03:13.001106 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122067 (* 1 = 0.122067 loss)
I0530 00:03:13.001109 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.324152 (* 1 = 0.324152 loss)
I0530 00:03:13.001113 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170262 (* 1 = 0.0170262 loss)
I0530 00:03:13.001117 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327835 (* 1 = 0.0327835 loss)
I0530 00:03:13.001123 24924 sgd_solver.cpp:106] Iteration 2920, lr = 0.0002
I0530 00:04:01.837277 24924 solver.cpp:228] Iteration 2940, loss = 0.316679
I0530 00:04:01.837313 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 00:04:01.837321 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0876731 (* 1 = 0.0876731 loss)
I0530 00:04:01.837324 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.29203 (* 1 = 0.29203 loss)
I0530 00:04:01.837327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0525016 (* 1 = 0.0525016 loss)
I0530 00:04:01.837330 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0943026 (* 1 = 0.0943026 loss)
I0530 00:04:01.837335 24924 sgd_solver.cpp:106] Iteration 2940, lr = 0.0002
I0530 00:04:50.690259 24924 solver.cpp:228] Iteration 2960, loss = 0.296942
I0530 00:04:50.690295 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 00:04:50.690302 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.101125 (* 1 = 0.101125 loss)
I0530 00:04:50.690306 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.226697 (* 1 = 0.226697 loss)
I0530 00:04:50.690310 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131854 (* 1 = 0.0131854 loss)
I0530 00:04:50.690312 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0202054 (* 1 = 0.0202054 loss)
I0530 00:04:50.690316 24924 sgd_solver.cpp:106] Iteration 2960, lr = 0.0002
I0530 00:05:39.453150 24924 solver.cpp:228] Iteration 2980, loss = 0.412995
I0530 00:05:39.453184 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:05:39.453192 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233779 (* 1 = 0.0233779 loss)
I0530 00:05:39.453196 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.083182 (* 1 = 0.083182 loss)
I0530 00:05:39.453199 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124741 (* 1 = 0.0124741 loss)
I0530 00:05:39.453202 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157699 (* 1 = 0.0157699 loss)
I0530 00:05:39.453207 24924 sgd_solver.cpp:106] Iteration 2980, lr = 0.0002
speed: 2.453s / iter
I0530 00:06:28.256057 24924 solver.cpp:228] Iteration 3000, loss = 0.323209
I0530 00:06:28.256094 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 00:06:28.256100 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0774526 (* 1 = 0.0774526 loss)
I0530 00:06:28.256104 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.238874 (* 1 = 0.238874 loss)
I0530 00:06:28.256108 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141206 (* 1 = 0.0141206 loss)
I0530 00:06:28.256110 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315077 (* 1 = 0.0315077 loss)
I0530 00:06:28.256114 24924 sgd_solver.cpp:106] Iteration 3000, lr = 0.0002
I0530 00:07:17.094223 24924 solver.cpp:228] Iteration 3020, loss = 0.540316
I0530 00:07:17.094259 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 00:07:17.094265 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.148681 (* 1 = 0.148681 loss)
I0530 00:07:17.094269 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.240068 (* 1 = 0.240068 loss)
I0530 00:07:17.094272 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115982 (* 1 = 0.0115982 loss)
I0530 00:07:17.094275 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126425 (* 1 = 0.0126425 loss)
I0530 00:07:17.094280 24924 sgd_solver.cpp:106] Iteration 3020, lr = 0.0002
I0530 00:08:05.869364 24924 solver.cpp:228] Iteration 3040, loss = 0.534436
I0530 00:08:05.869397 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0530 00:08:05.869405 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.56319 (* 1 = 0.56319 loss)
I0530 00:08:05.869408 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.682828 (* 1 = 0.682828 loss)
I0530 00:08:05.869411 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.268348 (* 1 = 0.268348 loss)
I0530 00:08:05.869415 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.939399 (* 1 = 0.939399 loss)
I0530 00:08:05.869419 24924 sgd_solver.cpp:106] Iteration 3040, lr = 0.0002
I0530 00:08:54.639217 24924 solver.cpp:228] Iteration 3060, loss = 0.291036
I0530 00:08:54.639253 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 00:08:54.639261 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109939 (* 1 = 0.109939 loss)
I0530 00:08:54.639263 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.281872 (* 1 = 0.281872 loss)
I0530 00:08:54.639267 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171973 (* 1 = 0.0171973 loss)
I0530 00:08:54.639271 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0651129 (* 1 = 0.0651129 loss)
I0530 00:08:54.639274 24924 sgd_solver.cpp:106] Iteration 3060, lr = 0.0002
I0530 00:09:43.415693 24924 solver.cpp:228] Iteration 3080, loss = 0.353426
I0530 00:09:43.415714 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:09:43.415735 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0530329 (* 1 = 0.0530329 loss)
I0530 00:09:43.415738 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.110396 (* 1 = 0.110396 loss)
I0530 00:09:43.415741 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00556405 (* 1 = 0.00556405 loss)
I0530 00:09:43.415745 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00416152 (* 1 = 0.00416152 loss)
I0530 00:09:43.415750 24924 sgd_solver.cpp:106] Iteration 3080, lr = 0.0002
I0530 00:10:32.130136 24924 solver.cpp:228] Iteration 3100, loss = 0.272603
I0530 00:10:32.130172 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:10:32.130178 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0132876 (* 1 = 0.0132876 loss)
I0530 00:10:32.130182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0759561 (* 1 = 0.0759561 loss)
I0530 00:10:32.130185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00838377 (* 1 = 0.00838377 loss)
I0530 00:10:32.130189 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223723 (* 1 = 0.0223723 loss)
I0530 00:10:32.130193 24924 sgd_solver.cpp:106] Iteration 3100, lr = 0.0002
I0530 00:11:20.872076 24924 solver.cpp:228] Iteration 3120, loss = 0.549702
I0530 00:11:20.872098 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 00:11:20.872119 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.018801 (* 1 = 0.018801 loss)
I0530 00:11:20.872123 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.158923 (* 1 = 0.158923 loss)
I0530 00:11:20.872126 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106896 (* 1 = 0.0106896 loss)
I0530 00:11:20.872129 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0245021 (* 1 = 0.0245021 loss)
I0530 00:11:20.872133 24924 sgd_solver.cpp:106] Iteration 3120, lr = 0.0002
I0530 00:12:09.600888 24924 solver.cpp:228] Iteration 3140, loss = 0.305273
I0530 00:12:09.600925 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 00:12:09.600934 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0830993 (* 1 = 0.0830993 loss)
I0530 00:12:09.600937 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132361 (* 1 = 0.132361 loss)
I0530 00:12:09.600940 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00426341 (* 1 = 0.00426341 loss)
I0530 00:12:09.600944 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178784 (* 1 = 0.0178784 loss)
I0530 00:12:09.600949 24924 sgd_solver.cpp:106] Iteration 3140, lr = 0.0002
I0530 00:12:58.250114 24924 solver.cpp:228] Iteration 3160, loss = 0.516364
I0530 00:12:58.250136 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:12:58.250144 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0527568 (* 1 = 0.0527568 loss)
I0530 00:12:58.250147 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156408 (* 1 = 0.156408 loss)
I0530 00:12:58.250150 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013548 (* 1 = 0.013548 loss)
I0530 00:12:58.250154 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167882 (* 1 = 0.0167882 loss)
I0530 00:12:58.250157 24924 sgd_solver.cpp:106] Iteration 3160, lr = 0.0002
I0530 00:13:46.901425 24924 solver.cpp:228] Iteration 3180, loss = 0.326413
I0530 00:13:46.901448 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 00:13:46.901456 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.049206 (* 1 = 0.049206 loss)
I0530 00:13:46.901475 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0938849 (* 1 = 0.0938849 loss)
I0530 00:13:46.901480 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00871016 (* 1 = 0.00871016 loss)
I0530 00:13:46.901485 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134844 (* 1 = 0.0134844 loss)
I0530 00:13:46.901491 24924 sgd_solver.cpp:106] Iteration 3180, lr = 0.0002
speed: 2.452s / iter
I0530 00:14:35.520766 24924 solver.cpp:228] Iteration 3200, loss = 0.383954
I0530 00:14:35.520790 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 00:14:35.520798 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.115436 (* 1 = 0.115436 loss)
I0530 00:14:35.520804 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.270527 (* 1 = 0.270527 loss)
I0530 00:14:35.520809 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.04984 (* 1 = 0.04984 loss)
I0530 00:14:35.520814 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327616 (* 1 = 0.0327616 loss)
I0530 00:14:35.520823 24924 sgd_solver.cpp:106] Iteration 3200, lr = 0.0002
I0530 00:15:24.149633 24924 solver.cpp:228] Iteration 3220, loss = 0.310193
I0530 00:15:24.149657 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 00:15:24.149665 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0825809 (* 1 = 0.0825809 loss)
I0530 00:15:24.149684 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.21025 (* 1 = 0.21025 loss)
I0530 00:15:24.149689 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112053 (* 1 = 0.0112053 loss)
I0530 00:15:24.149693 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181153 (* 1 = 0.0181153 loss)
I0530 00:15:24.149699 24924 sgd_solver.cpp:106] Iteration 3220, lr = 0.0002
I0530 00:16:12.721679 24924 solver.cpp:228] Iteration 3240, loss = 0.296365
I0530 00:16:12.721702 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 00:16:12.721710 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.200864 (* 1 = 0.200864 loss)
I0530 00:16:12.721729 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.386246 (* 1 = 0.386246 loss)
I0530 00:16:12.721735 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151876 (* 1 = 0.0151876 loss)
I0530 00:16:12.721740 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207036 (* 1 = 0.0207036 loss)
I0530 00:16:12.721745 24924 sgd_solver.cpp:106] Iteration 3240, lr = 0.0002
I0530 00:17:01.293400 24924 solver.cpp:228] Iteration 3260, loss = 0.343867
I0530 00:17:01.293422 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 00:17:01.293431 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.114944 (* 1 = 0.114944 loss)
I0530 00:17:01.293450 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.223371 (* 1 = 0.223371 loss)
I0530 00:17:01.293455 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023467 (* 1 = 0.023467 loss)
I0530 00:17:01.293460 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240728 (* 1 = 0.0240728 loss)
I0530 00:17:01.293467 24924 sgd_solver.cpp:106] Iteration 3260, lr = 0.0002
I0530 00:17:49.895617 24924 solver.cpp:228] Iteration 3280, loss = 0.259789
I0530 00:17:49.895640 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 00:17:49.895648 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.126012 (* 1 = 0.126012 loss)
I0530 00:17:49.895668 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.320247 (* 1 = 0.320247 loss)
I0530 00:17:49.895673 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0677311 (* 1 = 0.0677311 loss)
I0530 00:17:49.895676 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153676 (* 1 = 0.153676 loss)
I0530 00:17:49.895682 24924 sgd_solver.cpp:106] Iteration 3280, lr = 0.0002
I0530 00:18:38.457988 24924 solver.cpp:228] Iteration 3300, loss = 0.410261
I0530 00:18:38.458010 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.664062
I0530 00:18:38.458019 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.30631 (* 1 = 0.30631 loss)
I0530 00:18:38.458039 24924 solver.cpp:244]     Train net output #2: loss_cls = 1.11147 (* 1 = 1.11147 loss)
I0530 00:18:38.458043 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0525853 (* 1 = 0.0525853 loss)
I0530 00:18:38.458048 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.107553 (* 1 = 0.107553 loss)
I0530 00:18:38.458053 24924 sgd_solver.cpp:106] Iteration 3300, lr = 0.0002
I0530 00:19:27.023828 24924 solver.cpp:228] Iteration 3320, loss = 0.442416
I0530 00:19:27.023864 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 00:19:27.023871 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.158603 (* 1 = 0.158603 loss)
I0530 00:19:27.023875 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.21293 (* 1 = 0.21293 loss)
I0530 00:19:27.023878 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00958838 (* 1 = 0.00958838 loss)
I0530 00:19:27.023882 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0463599 (* 1 = 0.0463599 loss)
I0530 00:19:27.023886 24924 sgd_solver.cpp:106] Iteration 3320, lr = 0.0002
I0530 00:20:15.561259 24924 solver.cpp:228] Iteration 3340, loss = 0.404389
I0530 00:20:15.561295 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 00:20:15.561303 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183155 (* 1 = 0.0183155 loss)
I0530 00:20:15.561307 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.120926 (* 1 = 0.120926 loss)
I0530 00:20:15.561311 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0272915 (* 1 = 0.0272915 loss)
I0530 00:20:15.561313 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161725 (* 1 = 0.0161725 loss)
I0530 00:20:15.561317 24924 sgd_solver.cpp:106] Iteration 3340, lr = 0.0002
I0530 00:21:04.145630 24924 solver.cpp:228] Iteration 3360, loss = 0.462525
I0530 00:21:04.145666 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:21:04.145673 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0844297 (* 1 = 0.0844297 loss)
I0530 00:21:04.145678 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.187991 (* 1 = 0.187991 loss)
I0530 00:21:04.145680 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.114988 (* 1 = 0.114988 loss)
I0530 00:21:04.145684 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049977 (* 1 = 0.049977 loss)
I0530 00:21:04.145689 24924 sgd_solver.cpp:106] Iteration 3360, lr = 0.0002
I0530 00:21:52.706102 24924 solver.cpp:228] Iteration 3380, loss = 0.510745
I0530 00:21:52.706138 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 00:21:52.706146 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.078586 (* 1 = 0.078586 loss)
I0530 00:21:52.706149 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.236172 (* 1 = 0.236172 loss)
I0530 00:21:52.706152 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0709415 (* 1 = 0.0709415 loss)
I0530 00:21:52.706156 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045563 (* 1 = 0.045563 loss)
I0530 00:21:52.706159 24924 sgd_solver.cpp:106] Iteration 3380, lr = 0.0002
speed: 2.450s / iter
I0530 00:22:41.280268 24924 solver.cpp:228] Iteration 3400, loss = 0.247431
I0530 00:22:41.280304 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 00:22:41.280311 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0839849 (* 1 = 0.0839849 loss)
I0530 00:22:41.280314 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.213752 (* 1 = 0.213752 loss)
I0530 00:22:41.280318 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138344 (* 1 = 0.0138344 loss)
I0530 00:22:41.280321 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331422 (* 1 = 0.0331422 loss)
I0530 00:22:41.280325 24924 sgd_solver.cpp:106] Iteration 3400, lr = 0.0002
I0530 00:23:29.847079 24924 solver.cpp:228] Iteration 3420, loss = 0.326234
I0530 00:23:29.847115 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:23:29.847123 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318119 (* 1 = 0.0318119 loss)
I0530 00:23:29.847126 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147352 (* 1 = 0.147352 loss)
I0530 00:23:29.847129 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0196667 (* 1 = 0.0196667 loss)
I0530 00:23:29.847133 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225411 (* 1 = 0.0225411 loss)
I0530 00:23:29.847137 24924 sgd_solver.cpp:106] Iteration 3420, lr = 0.0002
I0530 00:24:18.372474 24924 solver.cpp:228] Iteration 3440, loss = 0.391442
I0530 00:24:18.372509 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 00:24:18.372516 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269245 (* 1 = 0.0269245 loss)
I0530 00:24:18.372520 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0748071 (* 1 = 0.0748071 loss)
I0530 00:24:18.372524 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02238 (* 1 = 0.02238 loss)
I0530 00:24:18.372526 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00434589 (* 1 = 0.00434589 loss)
I0530 00:24:18.372530 24924 sgd_solver.cpp:106] Iteration 3440, lr = 0.0002
I0530 00:25:06.958787 24924 solver.cpp:228] Iteration 3460, loss = 0.542676
I0530 00:25:06.958822 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 00:25:06.958828 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.115293 (* 1 = 0.115293 loss)
I0530 00:25:06.958832 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.228733 (* 1 = 0.228733 loss)
I0530 00:25:06.958834 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247319 (* 1 = 0.0247319 loss)
I0530 00:25:06.958838 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102208 (* 1 = 0.0102208 loss)
I0530 00:25:06.958842 24924 sgd_solver.cpp:106] Iteration 3460, lr = 0.0002
I0530 00:25:55.475517 24924 solver.cpp:228] Iteration 3480, loss = 0.318417
I0530 00:25:55.475554 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:25:55.475561 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0582465 (* 1 = 0.0582465 loss)
I0530 00:25:55.475564 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156808 (* 1 = 0.156808 loss)
I0530 00:25:55.475567 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163427 (* 1 = 0.0163427 loss)
I0530 00:25:55.475571 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138429 (* 1 = 0.0138429 loss)
I0530 00:25:55.475574 24924 sgd_solver.cpp:106] Iteration 3480, lr = 0.0002
I0530 00:26:44.112736 24924 solver.cpp:228] Iteration 3500, loss = 0.313024
I0530 00:26:44.112772 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 00:26:44.112781 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0990386 (* 1 = 0.0990386 loss)
I0530 00:26:44.112783 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152642 (* 1 = 0.152642 loss)
I0530 00:26:44.112787 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00813854 (* 1 = 0.00813854 loss)
I0530 00:26:44.112790 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00955454 (* 1 = 0.00955454 loss)
I0530 00:26:44.112794 24924 sgd_solver.cpp:106] Iteration 3500, lr = 0.0002
I0530 00:27:32.677817 24924 solver.cpp:228] Iteration 3520, loss = 0.253184
I0530 00:27:32.677839 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:27:32.677860 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00368963 (* 1 = 0.00368963 loss)
I0530 00:27:32.677863 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0797554 (* 1 = 0.0797554 loss)
I0530 00:27:32.677866 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0504727 (* 1 = 0.0504727 loss)
I0530 00:27:32.677870 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167953 (* 1 = 0.0167953 loss)
I0530 00:27:32.677873 24924 sgd_solver.cpp:106] Iteration 3520, lr = 0.0002
I0530 00:28:21.239910 24924 solver.cpp:228] Iteration 3540, loss = 0.349043
I0530 00:28:21.239948 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 00:28:21.239954 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0405398 (* 1 = 0.0405398 loss)
I0530 00:28:21.239959 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.251285 (* 1 = 0.251285 loss)
I0530 00:28:21.239961 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208693 (* 1 = 0.0208693 loss)
I0530 00:28:21.239964 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114296 (* 1 = 0.0114296 loss)
I0530 00:28:21.239969 24924 sgd_solver.cpp:106] Iteration 3540, lr = 0.0002
I0530 00:29:09.735610 24924 solver.cpp:228] Iteration 3560, loss = 0.247482
I0530 00:29:09.735647 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 00:29:09.735654 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0165825 (* 1 = 0.0165825 loss)
I0530 00:29:09.735657 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133256 (* 1 = 0.133256 loss)
I0530 00:29:09.735661 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013955 (* 1 = 0.013955 loss)
I0530 00:29:09.735664 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0508154 (* 1 = 0.0508154 loss)
I0530 00:29:09.735668 24924 sgd_solver.cpp:106] Iteration 3560, lr = 0.0002
I0530 00:29:58.259965 24924 solver.cpp:228] Iteration 3580, loss = 0.405571
I0530 00:29:58.260001 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:29:58.260008 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0463265 (* 1 = 0.0463265 loss)
I0530 00:29:58.260011 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.221505 (* 1 = 0.221505 loss)
I0530 00:29:58.260015 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00976758 (* 1 = 0.00976758 loss)
I0530 00:29:58.260018 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0091155 (* 1 = 0.0091155 loss)
I0530 00:29:58.260022 24924 sgd_solver.cpp:106] Iteration 3580, lr = 0.0002
speed: 2.449s / iter
I0530 00:30:46.802628 24924 solver.cpp:228] Iteration 3600, loss = 0.391052
I0530 00:30:46.802649 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:30:46.802670 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369562 (* 1 = 0.0369562 loss)
I0530 00:30:46.802675 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160325 (* 1 = 0.160325 loss)
I0530 00:30:46.802677 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0469606 (* 1 = 0.0469606 loss)
I0530 00:30:46.802680 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0481271 (* 1 = 0.0481271 loss)
I0530 00:30:46.802685 24924 sgd_solver.cpp:106] Iteration 3600, lr = 0.0002
I0530 00:31:35.347779 24924 solver.cpp:228] Iteration 3620, loss = 0.433474
I0530 00:31:35.347802 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 00:31:35.347810 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0791875 (* 1 = 0.0791875 loss)
I0530 00:31:35.347831 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.217542 (* 1 = 0.217542 loss)
I0530 00:31:35.347836 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00576507 (* 1 = 0.00576507 loss)
I0530 00:31:35.347841 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0416241 (* 1 = 0.0416241 loss)
I0530 00:31:35.347846 24924 sgd_solver.cpp:106] Iteration 3620, lr = 0.0002
I0530 00:32:23.852680 24924 solver.cpp:228] Iteration 3640, loss = 0.805994
I0530 00:32:23.852705 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 00:32:23.852725 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203186 (* 1 = 0.0203186 loss)
I0530 00:32:23.852730 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0969336 (* 1 = 0.0969336 loss)
I0530 00:32:23.852749 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00768549 (* 1 = 0.00768549 loss)
I0530 00:32:23.852754 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0293057 (* 1 = 0.0293057 loss)
I0530 00:32:23.852761 24924 sgd_solver.cpp:106] Iteration 3640, lr = 0.0002
I0530 00:33:12.371647 24924 solver.cpp:228] Iteration 3660, loss = 0.536489
I0530 00:33:12.371670 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:33:12.371680 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0721684 (* 1 = 0.0721684 loss)
I0530 00:33:12.371698 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.122982 (* 1 = 0.122982 loss)
I0530 00:33:12.371703 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00517351 (* 1 = 0.00517351 loss)
I0530 00:33:12.371708 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100997 (* 1 = 0.0100997 loss)
I0530 00:33:12.371714 24924 sgd_solver.cpp:106] Iteration 3660, lr = 0.0002
I0530 00:34:00.885869 24924 solver.cpp:228] Iteration 3680, loss = 0.327905
I0530 00:34:00.885892 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:34:00.885900 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384703 (* 1 = 0.0384703 loss)
I0530 00:34:00.885920 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.207312 (* 1 = 0.207312 loss)
I0530 00:34:00.885924 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128639 (* 1 = 0.0128639 loss)
I0530 00:34:00.885929 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102936 (* 1 = 0.0102936 loss)
I0530 00:34:00.885934 24924 sgd_solver.cpp:106] Iteration 3680, lr = 0.0002
I0530 00:34:49.405513 24924 solver.cpp:228] Iteration 3700, loss = 0.433534
I0530 00:34:49.405535 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:34:49.405544 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.049689 (* 1 = 0.049689 loss)
I0530 00:34:49.405562 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.166269 (* 1 = 0.166269 loss)
I0530 00:34:49.405567 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251342 (* 1 = 0.0251342 loss)
I0530 00:34:49.405572 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0228503 (* 1 = 0.0228503 loss)
I0530 00:34:49.405578 24924 sgd_solver.cpp:106] Iteration 3700, lr = 0.0002
I0530 00:35:37.946611 24924 solver.cpp:228] Iteration 3720, loss = 0.29591
I0530 00:35:37.946633 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:35:37.946642 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0113276 (* 1 = 0.0113276 loss)
I0530 00:35:37.946661 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0893632 (* 1 = 0.0893632 loss)
I0530 00:35:37.946666 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128467 (* 1 = 0.0128467 loss)
I0530 00:35:37.946671 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00784973 (* 1 = 0.00784973 loss)
I0530 00:35:37.946677 24924 sgd_solver.cpp:106] Iteration 3720, lr = 0.0002
I0530 00:36:26.476419 24924 solver.cpp:228] Iteration 3740, loss = 0.294573
I0530 00:36:26.476455 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 00:36:26.476462 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.125935 (* 1 = 0.125935 loss)
I0530 00:36:26.476465 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.25962 (* 1 = 0.25962 loss)
I0530 00:36:26.476469 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263575 (* 1 = 0.0263575 loss)
I0530 00:36:26.476472 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259422 (* 1 = 0.0259422 loss)
I0530 00:36:26.476476 24924 sgd_solver.cpp:106] Iteration 3740, lr = 0.0002
I0530 00:37:15.001482 24924 solver.cpp:228] Iteration 3760, loss = 0.242074
I0530 00:37:15.001518 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:37:15.001525 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0588577 (* 1 = 0.0588577 loss)
I0530 00:37:15.001528 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0884062 (* 1 = 0.0884062 loss)
I0530 00:37:15.001533 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00670358 (* 1 = 0.00670358 loss)
I0530 00:37:15.001535 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102503 (* 1 = 0.0102503 loss)
I0530 00:37:15.001539 24924 sgd_solver.cpp:106] Iteration 3760, lr = 0.0002
I0530 00:38:03.510761 24924 solver.cpp:228] Iteration 3780, loss = 0.277355
I0530 00:38:03.510783 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:38:03.510790 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0468546 (* 1 = 0.0468546 loss)
I0530 00:38:03.510794 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.172893 (* 1 = 0.172893 loss)
I0530 00:38:03.510797 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296046 (* 1 = 0.0296046 loss)
I0530 00:38:03.510800 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300965 (* 1 = 0.0300965 loss)
I0530 00:38:03.510804 24924 sgd_solver.cpp:106] Iteration 3780, lr = 0.0002
speed: 2.448s / iter
I0530 00:38:52.092612 24924 solver.cpp:228] Iteration 3800, loss = 0.319405
I0530 00:38:52.092648 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 00:38:52.092654 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407689 (* 1 = 0.0407689 loss)
I0530 00:38:52.092658 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113784 (* 1 = 0.113784 loss)
I0530 00:38:52.092661 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00874014 (* 1 = 0.00874014 loss)
I0530 00:38:52.092665 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132615 (* 1 = 0.0132615 loss)
I0530 00:38:52.092669 24924 sgd_solver.cpp:106] Iteration 3800, lr = 0.0002
I0530 00:39:40.601336 24924 solver.cpp:228] Iteration 3820, loss = 0.298724
I0530 00:39:40.601372 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 00:39:40.601378 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562953 (* 1 = 0.0562953 loss)
I0530 00:39:40.601382 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.151034 (* 1 = 0.151034 loss)
I0530 00:39:40.601385 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00838593 (* 1 = 0.00838593 loss)
I0530 00:39:40.601388 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.02376 (* 1 = 0.02376 loss)
I0530 00:39:40.601393 24924 sgd_solver.cpp:106] Iteration 3820, lr = 0.0002
I0530 00:40:29.203532 24924 solver.cpp:228] Iteration 3840, loss = 0.350836
I0530 00:40:29.203553 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:40:29.203562 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0289543 (* 1 = 0.0289543 loss)
I0530 00:40:29.203582 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.114054 (* 1 = 0.114054 loss)
I0530 00:40:29.203586 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219437 (* 1 = 0.0219437 loss)
I0530 00:40:29.203590 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0921444 (* 1 = 0.0921444 loss)
I0530 00:40:29.203596 24924 sgd_solver.cpp:106] Iteration 3840, lr = 0.0002
I0530 00:41:17.728935 24924 solver.cpp:228] Iteration 3860, loss = 0.253203
I0530 00:41:17.728956 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 00:41:17.728977 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.107423 (* 1 = 0.107423 loss)
I0530 00:41:17.728996 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.210827 (* 1 = 0.210827 loss)
I0530 00:41:17.729002 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00919303 (* 1 = 0.00919303 loss)
I0530 00:41:17.729007 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142587 (* 1 = 0.0142587 loss)
I0530 00:41:17.729013 24924 sgd_solver.cpp:106] Iteration 3860, lr = 0.0002
I0530 00:42:06.289187 24924 solver.cpp:228] Iteration 3880, loss = 0.283856
I0530 00:42:06.289211 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:42:06.289219 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00349075 (* 1 = 0.00349075 loss)
I0530 00:42:06.289238 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.106375 (* 1 = 0.106375 loss)
I0530 00:42:06.289243 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118654 (* 1 = 0.0118654 loss)
I0530 00:42:06.289248 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213955 (* 1 = 0.0213955 loss)
I0530 00:42:06.289254 24924 sgd_solver.cpp:106] Iteration 3880, lr = 0.0002
I0530 00:42:54.800971 24924 solver.cpp:228] Iteration 3900, loss = 0.474838
I0530 00:42:54.801007 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:42:54.801014 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0581334 (* 1 = 0.0581334 loss)
I0530 00:42:54.801019 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.169791 (* 1 = 0.169791 loss)
I0530 00:42:54.801038 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192599 (* 1 = 0.0192599 loss)
I0530 00:42:54.801043 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315545 (* 1 = 0.0315545 loss)
I0530 00:42:54.801049 24924 sgd_solver.cpp:106] Iteration 3900, lr = 0.0002
I0530 00:43:43.362169 24924 solver.cpp:228] Iteration 3920, loss = 0.341567
I0530 00:43:43.362190 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0530 00:43:43.362198 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.301648 (* 1 = 0.301648 loss)
I0530 00:43:43.362218 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.586854 (* 1 = 0.586854 loss)
I0530 00:43:43.362223 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306535 (* 1 = 0.0306535 loss)
I0530 00:43:43.362228 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443647 (* 1 = 0.0443647 loss)
I0530 00:43:43.362233 24924 sgd_solver.cpp:106] Iteration 3920, lr = 0.0002
I0530 00:44:31.948845 24924 solver.cpp:228] Iteration 3940, loss = 0.333618
I0530 00:44:31.948868 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:44:31.948876 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0226329 (* 1 = 0.0226329 loss)
I0530 00:44:31.948896 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113331 (* 1 = 0.113331 loss)
I0530 00:44:31.948901 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0175999 (* 1 = 0.0175999 loss)
I0530 00:44:31.948905 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487676 (* 1 = 0.0487676 loss)
I0530 00:44:31.948915 24924 sgd_solver.cpp:106] Iteration 3940, lr = 0.0002
I0530 00:45:20.519183 24924 solver.cpp:228] Iteration 3960, loss = 0.790378
I0530 00:45:20.519206 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:45:20.519214 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262793 (* 1 = 0.0262793 loss)
I0530 00:45:20.519233 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0906345 (* 1 = 0.0906345 loss)
I0530 00:45:20.519238 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191225 (* 1 = 0.0191225 loss)
I0530 00:45:20.519243 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138241 (* 1 = 0.0138241 loss)
I0530 00:45:20.519249 24924 sgd_solver.cpp:106] Iteration 3960, lr = 0.0002
I0530 00:46:09.084493 24924 solver.cpp:228] Iteration 3980, loss = 0.865759
I0530 00:46:09.084517 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:46:09.084524 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0224535 (* 1 = 0.0224535 loss)
I0530 00:46:09.084544 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102782 (* 1 = 0.102782 loss)
I0530 00:46:09.084549 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00561367 (* 1 = 0.00561367 loss)
I0530 00:46:09.084554 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116571 (* 1 = 0.0116571 loss)
I0530 00:46:09.084560 24924 sgd_solver.cpp:106] Iteration 3980, lr = 0.0002
speed: 2.447s / iter
I0530 00:46:57.630960 24924 solver.cpp:228] Iteration 4000, loss = 0.354671
I0530 00:46:57.630983 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 00:46:57.630991 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0732436 (* 1 = 0.0732436 loss)
I0530 00:46:57.630997 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101811 (* 1 = 0.101811 loss)
I0530 00:46:57.631002 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00805688 (* 1 = 0.00805688 loss)
I0530 00:46:57.631007 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0092954 (* 1 = 0.0092954 loss)
I0530 00:46:57.631012 24924 sgd_solver.cpp:106] Iteration 4000, lr = 0.0002
I0530 00:47:46.199704 24924 solver.cpp:228] Iteration 4020, loss = 0.61189
I0530 00:47:46.199740 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 00:47:46.199748 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.334762 (* 1 = 0.334762 loss)
I0530 00:47:46.199767 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.446822 (* 1 = 0.446822 loss)
I0530 00:47:46.199772 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0867893 (* 1 = 0.0867893 loss)
I0530 00:47:46.199776 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.147788 (* 1 = 0.147788 loss)
I0530 00:47:46.199781 24924 sgd_solver.cpp:106] Iteration 4020, lr = 0.0002
I0530 00:48:34.741461 24924 solver.cpp:228] Iteration 4040, loss = 0.305575
I0530 00:48:34.741482 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:48:34.741490 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0154658 (* 1 = 0.0154658 loss)
I0530 00:48:34.741509 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0667276 (* 1 = 0.0667276 loss)
I0530 00:48:34.741514 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00997243 (* 1 = 0.00997243 loss)
I0530 00:48:34.741520 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134676 (* 1 = 0.0134676 loss)
I0530 00:48:34.741526 24924 sgd_solver.cpp:106] Iteration 4040, lr = 0.0002
I0530 00:49:23.342566 24924 solver.cpp:228] Iteration 4060, loss = 0.322609
I0530 00:49:23.342588 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 00:49:23.342597 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0287489 (* 1 = 0.0287489 loss)
I0530 00:49:23.342602 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109407 (* 1 = 0.109407 loss)
I0530 00:49:23.342607 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00804329 (* 1 = 0.00804329 loss)
I0530 00:49:23.342612 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014887 (* 1 = 0.014887 loss)
I0530 00:49:23.342618 24924 sgd_solver.cpp:106] Iteration 4060, lr = 0.0002
I0530 00:50:11.971046 24924 solver.cpp:228] Iteration 4080, loss = 0.390068
I0530 00:50:11.971067 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 00:50:11.971076 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.244752 (* 1 = 0.244752 loss)
I0530 00:50:11.971096 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.38243 (* 1 = 0.38243 loss)
I0530 00:50:11.971101 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0580583 (* 1 = 0.0580583 loss)
I0530 00:50:11.971105 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.330943 (* 1 = 0.330943 loss)
I0530 00:50:11.971110 24924 sgd_solver.cpp:106] Iteration 4080, lr = 0.0002
I0530 00:51:00.552278 24924 solver.cpp:228] Iteration 4100, loss = 0.553179
I0530 00:51:00.552299 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 00:51:00.552306 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.225722 (* 1 = 0.225722 loss)
I0530 00:51:00.552311 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.452101 (* 1 = 0.452101 loss)
I0530 00:51:00.552331 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.040404 (* 1 = 0.040404 loss)
I0530 00:51:00.552336 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.117077 (* 1 = 0.117077 loss)
I0530 00:51:00.552341 24924 sgd_solver.cpp:106] Iteration 4100, lr = 0.0002
I0530 00:51:49.180940 24924 solver.cpp:228] Iteration 4120, loss = 0.338029
I0530 00:51:49.180964 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 00:51:49.180984 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.29202 (* 1 = 0.29202 loss)
I0530 00:51:49.181004 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.373525 (* 1 = 0.373525 loss)
I0530 00:51:49.181008 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0397172 (* 1 = 0.0397172 loss)
I0530 00:51:49.181013 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0583609 (* 1 = 0.0583609 loss)
I0530 00:51:49.181020 24924 sgd_solver.cpp:106] Iteration 4120, lr = 0.0002
I0530 00:52:37.784534 24924 solver.cpp:228] Iteration 4140, loss = 0.382906
I0530 00:52:37.784556 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:52:37.784565 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0395734 (* 1 = 0.0395734 loss)
I0530 00:52:37.784584 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.159295 (* 1 = 0.159295 loss)
I0530 00:52:37.784590 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0782025 (* 1 = 0.0782025 loss)
I0530 00:52:37.784595 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433672 (* 1 = 0.0433672 loss)
I0530 00:52:37.784600 24924 sgd_solver.cpp:106] Iteration 4140, lr = 0.0002
I0530 00:53:26.406091 24924 solver.cpp:228] Iteration 4160, loss = 0.428516
I0530 00:53:26.406116 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:53:26.406124 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0433815 (* 1 = 0.0433815 loss)
I0530 00:53:26.406143 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0936126 (* 1 = 0.0936126 loss)
I0530 00:53:26.406148 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00943908 (* 1 = 0.00943908 loss)
I0530 00:53:26.406153 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118566 (* 1 = 0.0118566 loss)
I0530 00:53:26.406159 24924 sgd_solver.cpp:106] Iteration 4160, lr = 0.0002
I0530 00:54:14.983572 24924 solver.cpp:228] Iteration 4180, loss = 0.441784
I0530 00:54:14.983593 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 00:54:14.983603 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0881489 (* 1 = 0.0881489 loss)
I0530 00:54:14.983621 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.175095 (* 1 = 0.175095 loss)
I0530 00:54:14.983626 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0607137 (* 1 = 0.0607137 loss)
I0530 00:54:14.983631 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345575 (* 1 = 0.0345575 loss)
I0530 00:54:14.983636 24924 sgd_solver.cpp:106] Iteration 4180, lr = 0.0002
speed: 2.446s / iter
I0530 00:55:03.579479 24924 solver.cpp:228] Iteration 4200, loss = 0.343506
I0530 00:55:03.579501 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 00:55:03.579510 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0546697 (* 1 = 0.0546697 loss)
I0530 00:55:03.579530 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.238233 (* 1 = 0.238233 loss)
I0530 00:55:03.579535 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0183051 (* 1 = 0.0183051 loss)
I0530 00:55:03.579540 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00375312 (* 1 = 0.00375312 loss)
I0530 00:55:03.579547 24924 sgd_solver.cpp:106] Iteration 4200, lr = 0.0002
I0530 00:55:52.232440 24924 solver.cpp:228] Iteration 4220, loss = 0.169687
I0530 00:55:52.232475 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:55:52.232482 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0177422 (* 1 = 0.0177422 loss)
I0530 00:55:52.232487 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0770154 (* 1 = 0.0770154 loss)
I0530 00:55:52.232491 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119304 (* 1 = 0.0119304 loss)
I0530 00:55:52.232493 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155828 (* 1 = 0.0155828 loss)
I0530 00:55:52.232497 24924 sgd_solver.cpp:106] Iteration 4220, lr = 0.0002
I0530 00:56:40.848757 24924 solver.cpp:228] Iteration 4240, loss = 0.489962
I0530 00:56:40.848793 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 00:56:40.848800 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.26733 (* 1 = 0.26733 loss)
I0530 00:56:40.848804 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.444733 (* 1 = 0.444733 loss)
I0530 00:56:40.848807 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.019704 (* 1 = 0.019704 loss)
I0530 00:56:40.848810 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683495 (* 1 = 0.0683495 loss)
I0530 00:56:40.848814 24924 sgd_solver.cpp:106] Iteration 4240, lr = 0.0002
I0530 00:57:29.476589 24924 solver.cpp:228] Iteration 4260, loss = 0.376823
I0530 00:57:29.476625 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:57:29.476632 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258041 (* 1 = 0.0258041 loss)
I0530 00:57:29.476636 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0588613 (* 1 = 0.0588613 loss)
I0530 00:57:29.476639 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155792 (* 1 = 0.0155792 loss)
I0530 00:57:29.476642 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0140012 (* 1 = 0.0140012 loss)
I0530 00:57:29.476646 24924 sgd_solver.cpp:106] Iteration 4260, lr = 0.0002
I0530 00:58:18.123090 24924 solver.cpp:228] Iteration 4280, loss = 0.364935
I0530 00:58:18.123124 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 00:58:18.123132 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0567359 (* 1 = 0.0567359 loss)
I0530 00:58:18.123136 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.170744 (* 1 = 0.170744 loss)
I0530 00:58:18.123139 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165706 (* 1 = 0.0165706 loss)
I0530 00:58:18.123142 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301251 (* 1 = 0.0301251 loss)
I0530 00:58:18.123147 24924 sgd_solver.cpp:106] Iteration 4280, lr = 0.0002
I0530 00:59:06.719108 24924 solver.cpp:228] Iteration 4300, loss = 0.431325
I0530 00:59:06.719130 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 00:59:06.719151 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0363282 (* 1 = 0.0363282 loss)
I0530 00:59:06.719156 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0905725 (* 1 = 0.0905725 loss)
I0530 00:59:06.719159 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153451 (* 1 = 0.0153451 loss)
I0530 00:59:06.719162 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119779 (* 1 = 0.0119779 loss)
I0530 00:59:06.719166 24924 sgd_solver.cpp:106] Iteration 4300, lr = 0.0002
I0530 00:59:55.314532 24924 solver.cpp:228] Iteration 4320, loss = 0.313906
I0530 00:59:55.314554 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 00:59:55.314563 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256658 (* 1 = 0.0256658 loss)
I0530 00:59:55.314581 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.093184 (* 1 = 0.093184 loss)
I0530 00:59:55.314586 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0416648 (* 1 = 0.0416648 loss)
I0530 00:59:55.314591 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022064 (* 1 = 0.022064 loss)
I0530 00:59:55.314597 24924 sgd_solver.cpp:106] Iteration 4320, lr = 0.0002
I0530 01:00:43.889045 24924 solver.cpp:228] Iteration 4340, loss = 0.3496
I0530 01:00:43.889067 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:00:43.889076 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00128864 (* 1 = 0.00128864 loss)
I0530 01:00:43.889096 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0777334 (* 1 = 0.0777334 loss)
I0530 01:00:43.889101 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293698 (* 1 = 0.0293698 loss)
I0530 01:00:43.889106 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0748028 (* 1 = 0.0748028 loss)
I0530 01:00:43.889111 24924 sgd_solver.cpp:106] Iteration 4340, lr = 0.0002
I0530 01:01:32.506093 24924 solver.cpp:228] Iteration 4360, loss = 0.23708
I0530 01:01:32.506116 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:01:32.506125 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0432204 (* 1 = 0.0432204 loss)
I0530 01:01:32.506130 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0950768 (* 1 = 0.0950768 loss)
I0530 01:01:32.506135 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00988432 (* 1 = 0.00988432 loss)
I0530 01:01:32.506140 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325895 (* 1 = 0.0325895 loss)
I0530 01:01:32.506148 24924 sgd_solver.cpp:106] Iteration 4360, lr = 0.0002
I0530 01:02:21.135445 24924 solver.cpp:228] Iteration 4380, loss = 0.356968
I0530 01:02:21.135483 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 01:02:21.135489 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459307 (* 1 = 0.0459307 loss)
I0530 01:02:21.135493 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.217877 (* 1 = 0.217877 loss)
I0530 01:02:21.135496 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147353 (* 1 = 0.0147353 loss)
I0530 01:02:21.135500 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017708 (* 1 = 0.017708 loss)
I0530 01:02:21.135504 24924 sgd_solver.cpp:106] Iteration 4380, lr = 0.0002
speed: 2.445s / iter
I0530 01:03:09.757457 24924 solver.cpp:228] Iteration 4400, loss = 0.466911
I0530 01:03:09.757484 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:03:09.757493 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0241349 (* 1 = 0.0241349 loss)
I0530 01:03:09.757498 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0857169 (* 1 = 0.0857169 loss)
I0530 01:03:09.757503 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116742 (* 1 = 0.0116742 loss)
I0530 01:03:09.757509 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137635 (* 1 = 0.0137635 loss)
I0530 01:03:09.757514 24924 sgd_solver.cpp:106] Iteration 4400, lr = 0.0002
I0530 01:03:58.363595 24924 solver.cpp:228] Iteration 4420, loss = 0.454566
I0530 01:03:58.363617 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:03:58.363625 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0126707 (* 1 = 0.0126707 loss)
I0530 01:03:58.363628 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0796933 (* 1 = 0.0796933 loss)
I0530 01:03:58.363631 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0168629 (* 1 = 0.0168629 loss)
I0530 01:03:58.363636 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127365 (* 1 = 0.0127365 loss)
I0530 01:03:58.363639 24924 sgd_solver.cpp:106] Iteration 4420, lr = 0.0002
I0530 01:04:46.975863 24924 solver.cpp:228] Iteration 4440, loss = 0.278035
I0530 01:04:46.975899 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 01:04:46.975906 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0339436 (* 1 = 0.0339436 loss)
I0530 01:04:46.975910 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145309 (* 1 = 0.145309 loss)
I0530 01:04:46.975914 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00911923 (* 1 = 0.00911923 loss)
I0530 01:04:46.975917 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244394 (* 1 = 0.0244394 loss)
I0530 01:04:46.975921 24924 sgd_solver.cpp:106] Iteration 4440, lr = 0.0002
I0530 01:05:35.572371 24924 solver.cpp:228] Iteration 4460, loss = 0.47211
I0530 01:05:35.572396 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:05:35.572402 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590897 (* 1 = 0.0590897 loss)
I0530 01:05:35.572407 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.128278 (* 1 = 0.128278 loss)
I0530 01:05:35.572409 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023486 (* 1 = 0.023486 loss)
I0530 01:05:35.572412 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0347692 (* 1 = 0.0347692 loss)
I0530 01:05:35.572417 24924 sgd_solver.cpp:106] Iteration 4460, lr = 0.0002
I0530 01:06:24.169754 24924 solver.cpp:228] Iteration 4480, loss = 0.308099
I0530 01:06:24.169790 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 01:06:24.169796 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.219139 (* 1 = 0.219139 loss)
I0530 01:06:24.169800 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.329774 (* 1 = 0.329774 loss)
I0530 01:06:24.169805 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119731 (* 1 = 0.0119731 loss)
I0530 01:06:24.169807 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0522995 (* 1 = 0.0522995 loss)
I0530 01:06:24.169811 24924 sgd_solver.cpp:106] Iteration 4480, lr = 0.0002
I0530 01:07:12.784323 24924 solver.cpp:228] Iteration 4500, loss = 0.337334
I0530 01:07:12.784346 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:07:12.784354 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.031534 (* 1 = 0.031534 loss)
I0530 01:07:12.784374 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0894859 (* 1 = 0.0894859 loss)
I0530 01:07:12.784379 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109094 (* 1 = 0.0109094 loss)
I0530 01:07:12.784384 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115253 (* 1 = 0.0115253 loss)
I0530 01:07:12.784389 24924 sgd_solver.cpp:106] Iteration 4500, lr = 0.0002
I0530 01:08:01.544018 24924 solver.cpp:228] Iteration 4520, loss = 0.275519
I0530 01:08:01.544041 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:08:01.544050 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00320473 (* 1 = 0.00320473 loss)
I0530 01:08:01.544070 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0586235 (* 1 = 0.0586235 loss)
I0530 01:08:01.544075 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0263842 (* 1 = 0.0263842 loss)
I0530 01:08:01.544080 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302884 (* 1 = 0.0302884 loss)
I0530 01:08:01.544085 24924 sgd_solver.cpp:106] Iteration 4520, lr = 0.0002
I0530 01:08:50.348335 24924 solver.cpp:228] Iteration 4540, loss = 0.599392
I0530 01:08:50.348358 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:08:50.348366 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00366883 (* 1 = 0.00366883 loss)
I0530 01:08:50.348371 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0758182 (* 1 = 0.0758182 loss)
I0530 01:08:50.348374 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262726 (* 1 = 0.0262726 loss)
I0530 01:08:50.348377 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408982 (* 1 = 0.0408982 loss)
I0530 01:08:50.348381 24924 sgd_solver.cpp:106] Iteration 4540, lr = 0.0002
I0530 01:09:39.136639 24924 solver.cpp:228] Iteration 4560, loss = 0.433539
I0530 01:09:39.136675 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 01:09:39.136683 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.061478 (* 1 = 0.061478 loss)
I0530 01:09:39.136687 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101313 (* 1 = 0.101313 loss)
I0530 01:09:39.136690 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00516509 (* 1 = 0.00516509 loss)
I0530 01:09:39.136693 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113928 (* 1 = 0.0113928 loss)
I0530 01:09:39.136698 24924 sgd_solver.cpp:106] Iteration 4560, lr = 0.0002
I0530 01:10:27.939502 24924 solver.cpp:228] Iteration 4580, loss = 0.304443
I0530 01:10:27.939538 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 01:10:27.939546 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.255392 (* 1 = 0.255392 loss)
I0530 01:10:27.939549 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.509629 (* 1 = 0.509629 loss)
I0530 01:10:27.939553 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0571913 (* 1 = 0.0571913 loss)
I0530 01:10:27.939556 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0660233 (* 1 = 0.0660233 loss)
I0530 01:10:27.939560 24924 sgd_solver.cpp:106] Iteration 4580, lr = 0.0002
speed: 2.445s / iter
I0530 01:11:16.809273 24924 solver.cpp:228] Iteration 4600, loss = 0.211983
I0530 01:11:16.809294 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:11:16.809303 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176422 (* 1 = 0.0176422 loss)
I0530 01:11:16.809322 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0643751 (* 1 = 0.0643751 loss)
I0530 01:11:16.809327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106183 (* 1 = 0.0106183 loss)
I0530 01:11:16.809332 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126992 (* 1 = 0.0126992 loss)
I0530 01:11:16.809340 24924 sgd_solver.cpp:106] Iteration 4600, lr = 0.0002
I0530 01:12:05.641598 24924 solver.cpp:228] Iteration 4620, loss = 0.303806
I0530 01:12:05.641621 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 01:12:05.641630 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.138493 (* 1 = 0.138493 loss)
I0530 01:12:05.641649 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.335704 (* 1 = 0.335704 loss)
I0530 01:12:05.641654 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00980634 (* 1 = 0.00980634 loss)
I0530 01:12:05.641659 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419858 (* 1 = 0.0419858 loss)
I0530 01:12:05.641665 24924 sgd_solver.cpp:106] Iteration 4620, lr = 0.0002
I0530 01:12:54.443341 24924 solver.cpp:228] Iteration 4640, loss = 0.438989
I0530 01:12:54.443375 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 01:12:54.443382 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.136032 (* 1 = 0.136032 loss)
I0530 01:12:54.443387 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.303008 (* 1 = 0.303008 loss)
I0530 01:12:54.443389 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289402 (* 1 = 0.0289402 loss)
I0530 01:12:54.443392 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400848 (* 1 = 0.0400848 loss)
I0530 01:12:54.443397 24924 sgd_solver.cpp:106] Iteration 4640, lr = 0.0002
I0530 01:13:43.255839 24924 solver.cpp:228] Iteration 4660, loss = 0.474145
I0530 01:13:43.255874 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 01:13:43.255882 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102321 (* 1 = 0.102321 loss)
I0530 01:13:43.255884 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.300895 (* 1 = 0.300895 loss)
I0530 01:13:43.255887 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228904 (* 1 = 0.0228904 loss)
I0530 01:13:43.255890 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402355 (* 1 = 0.0402355 loss)
I0530 01:13:43.255894 24924 sgd_solver.cpp:106] Iteration 4660, lr = 0.0002
I0530 01:14:32.093786 24924 solver.cpp:228] Iteration 4680, loss = 0.441507
I0530 01:14:32.093822 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:14:32.093828 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0280011 (* 1 = 0.0280011 loss)
I0530 01:14:32.093832 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141564 (* 1 = 0.141564 loss)
I0530 01:14:32.093835 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00559842 (* 1 = 0.00559842 loss)
I0530 01:14:32.093838 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116939 (* 1 = 0.0116939 loss)
I0530 01:14:32.093843 24924 sgd_solver.cpp:106] Iteration 4680, lr = 0.0002
I0530 01:15:20.993137 24924 solver.cpp:228] Iteration 4700, loss = 0.443981
I0530 01:15:20.993171 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:15:20.993178 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0192619 (* 1 = 0.0192619 loss)
I0530 01:15:20.993182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123417 (* 1 = 0.123417 loss)
I0530 01:15:20.993185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00358634 (* 1 = 0.00358634 loss)
I0530 01:15:20.993189 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118307 (* 1 = 0.0118307 loss)
I0530 01:15:20.993193 24924 sgd_solver.cpp:106] Iteration 4700, lr = 0.0002
I0530 01:16:09.710820 24924 solver.cpp:228] Iteration 4720, loss = 0.272401
I0530 01:16:09.710856 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:16:09.710865 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.026811 (* 1 = 0.026811 loss)
I0530 01:16:09.710868 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0789926 (* 1 = 0.0789926 loss)
I0530 01:16:09.710872 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00467369 (* 1 = 0.00467369 loss)
I0530 01:16:09.710875 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205089 (* 1 = 0.0205089 loss)
I0530 01:16:09.710880 24924 sgd_solver.cpp:106] Iteration 4720, lr = 0.0002
I0530 01:16:58.506522 24924 solver.cpp:228] Iteration 4740, loss = 0.251924
I0530 01:16:58.506558 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 01:16:58.506566 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.15678 (* 1 = 0.15678 loss)
I0530 01:16:58.506568 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.302746 (* 1 = 0.302746 loss)
I0530 01:16:58.506572 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014371 (* 1 = 0.014371 loss)
I0530 01:16:58.506575 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248666 (* 1 = 0.0248666 loss)
I0530 01:16:58.506579 24924 sgd_solver.cpp:106] Iteration 4740, lr = 0.0002
I0530 01:17:47.309094 24924 solver.cpp:228] Iteration 4760, loss = 0.221479
I0530 01:17:47.309129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 01:17:47.309137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459566 (* 1 = 0.0459566 loss)
I0530 01:17:47.309140 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.130156 (* 1 = 0.130156 loss)
I0530 01:17:47.309144 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00300567 (* 1 = 0.00300567 loss)
I0530 01:17:47.309146 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00538612 (* 1 = 0.00538612 loss)
I0530 01:17:47.309151 24924 sgd_solver.cpp:106] Iteration 4760, lr = 0.0002
I0530 01:18:36.048590 24924 solver.cpp:228] Iteration 4780, loss = 0.506001
I0530 01:18:36.048629 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 01:18:36.048635 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.169242 (* 1 = 0.169242 loss)
I0530 01:18:36.048640 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.432597 (* 1 = 0.432597 loss)
I0530 01:18:36.048642 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296861 (* 1 = 0.0296861 loss)
I0530 01:18:36.048645 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0766342 (* 1 = 0.0766342 loss)
I0530 01:18:36.048650 24924 sgd_solver.cpp:106] Iteration 4780, lr = 0.0002
speed: 2.445s / iter
I0530 01:19:24.821363 24924 solver.cpp:228] Iteration 4800, loss = 0.649934
I0530 01:19:24.821398 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 01:19:24.821406 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.131312 (* 1 = 0.131312 loss)
I0530 01:19:24.821409 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.281594 (* 1 = 0.281594 loss)
I0530 01:19:24.821413 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262127 (* 1 = 0.0262127 loss)
I0530 01:19:24.821416 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433428 (* 1 = 0.0433428 loss)
I0530 01:19:24.821420 24924 sgd_solver.cpp:106] Iteration 4800, lr = 0.0002
I0530 01:20:13.615849 24924 solver.cpp:228] Iteration 4820, loss = 0.297013
I0530 01:20:13.615883 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 01:20:13.615891 24924 solver.cpp:244]     Train net output #1: loss_bbox = 8.71761e-05 (* 1 = 8.71761e-05 loss)
I0530 01:20:13.615895 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0461533 (* 1 = 0.0461533 loss)
I0530 01:20:13.615898 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0338899 (* 1 = 0.0338899 loss)
I0530 01:20:13.615901 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0366122 (* 1 = 0.0366122 loss)
I0530 01:20:13.615906 24924 sgd_solver.cpp:106] Iteration 4820, lr = 0.0002
I0530 01:21:02.372336 24924 solver.cpp:228] Iteration 4840, loss = 0.44541
I0530 01:21:02.372371 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:21:02.372378 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.066378 (* 1 = 0.066378 loss)
I0530 01:21:02.372381 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.169894 (* 1 = 0.169894 loss)
I0530 01:21:02.372385 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00498767 (* 1 = 0.00498767 loss)
I0530 01:21:02.372387 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227302 (* 1 = 0.0227302 loss)
I0530 01:21:02.372392 24924 sgd_solver.cpp:106] Iteration 4840, lr = 0.0002
I0530 01:21:51.118491 24924 solver.cpp:228] Iteration 4860, loss = 0.323421
I0530 01:21:51.118515 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:21:51.118521 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.10504 (* 1 = 0.10504 loss)
I0530 01:21:51.118525 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165783 (* 1 = 0.165783 loss)
I0530 01:21:51.118528 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00776169 (* 1 = 0.00776169 loss)
I0530 01:21:51.118531 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00645928 (* 1 = 0.00645928 loss)
I0530 01:21:51.118536 24924 sgd_solver.cpp:106] Iteration 4860, lr = 0.0002
I0530 01:22:39.928927 24924 solver.cpp:228] Iteration 4880, loss = 0.344729
I0530 01:22:39.928948 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 01:22:39.928969 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540081 (* 1 = 0.0540081 loss)
I0530 01:22:39.928973 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.136087 (* 1 = 0.136087 loss)
I0530 01:22:39.928977 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115977 (* 1 = 0.0115977 loss)
I0530 01:22:39.928979 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230778 (* 1 = 0.0230778 loss)
I0530 01:22:39.928983 24924 sgd_solver.cpp:106] Iteration 4880, lr = 0.0002
I0530 01:23:28.706141 24924 solver.cpp:228] Iteration 4900, loss = 0.352924
I0530 01:23:28.706174 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 01:23:28.706182 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0378757 (* 1 = 0.0378757 loss)
I0530 01:23:28.706185 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.114568 (* 1 = 0.114568 loss)
I0530 01:23:28.706189 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00258592 (* 1 = 0.00258592 loss)
I0530 01:23:28.706192 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127442 (* 1 = 0.0127442 loss)
I0530 01:23:28.706197 24924 sgd_solver.cpp:106] Iteration 4900, lr = 0.0002
I0530 01:24:17.409405 24924 solver.cpp:228] Iteration 4920, loss = 0.34073
I0530 01:24:17.409442 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:24:17.409449 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.017506 (* 1 = 0.017506 loss)
I0530 01:24:17.409453 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0735733 (* 1 = 0.0735733 loss)
I0530 01:24:17.409456 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0076208 (* 1 = 0.0076208 loss)
I0530 01:24:17.409459 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00803373 (* 1 = 0.00803373 loss)
I0530 01:24:17.409464 24924 sgd_solver.cpp:106] Iteration 4920, lr = 0.0002
I0530 01:25:06.129041 24924 solver.cpp:228] Iteration 4940, loss = 0.361815
I0530 01:25:06.129076 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:25:06.129083 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349055 (* 1 = 0.0349055 loss)
I0530 01:25:06.129086 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0954933 (* 1 = 0.0954933 loss)
I0530 01:25:06.129091 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00891962 (* 1 = 0.00891962 loss)
I0530 01:25:06.129093 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0334516 (* 1 = 0.0334516 loss)
I0530 01:25:06.129097 24924 sgd_solver.cpp:106] Iteration 4940, lr = 0.0002
I0530 01:25:54.867323 24924 solver.cpp:228] Iteration 4960, loss = 0.631494
I0530 01:25:54.867344 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:25:54.867365 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310988 (* 1 = 0.0310988 loss)
I0530 01:25:54.867369 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0955979 (* 1 = 0.0955979 loss)
I0530 01:25:54.867372 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115187 (* 1 = 0.0115187 loss)
I0530 01:25:54.867375 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942651 (* 1 = 0.00942651 loss)
I0530 01:25:54.867379 24924 sgd_solver.cpp:106] Iteration 4960, lr = 0.0002
I0530 01:26:43.668644 24924 solver.cpp:228] Iteration 4980, loss = 0.38589
I0530 01:26:43.668681 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 01:26:43.668689 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109557 (* 1 = 0.109557 loss)
I0530 01:26:43.668692 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.3471 (* 1 = 0.3471 loss)
I0530 01:26:43.668696 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0461675 (* 1 = 0.0461675 loss)
I0530 01:26:43.668699 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563178 (* 1 = 0.0563178 loss)
I0530 01:26:43.668704 24924 sgd_solver.cpp:106] Iteration 4980, lr = 0.0002
speed: 2.444s / iter
I0530 01:27:30.092634 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_5000.caffemodel
I0530 01:27:33.228289 24924 solver.cpp:228] Iteration 5000, loss = 0.456022
I0530 01:27:33.228312 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 01:27:33.228319 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.108765 (* 1 = 0.108765 loss)
I0530 01:27:33.228323 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.211278 (* 1 = 0.211278 loss)
I0530 01:27:33.228327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00975433 (* 1 = 0.00975433 loss)
I0530 01:27:33.228332 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040438 (* 1 = 0.040438 loss)
I0530 01:27:33.228335 24924 sgd_solver.cpp:106] Iteration 5000, lr = 0.0002
I0530 01:28:21.809619 24924 solver.cpp:228] Iteration 5020, loss = 0.379571
I0530 01:28:21.809655 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:28:21.809664 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0143206 (* 1 = 0.0143206 loss)
I0530 01:28:21.809666 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0799218 (* 1 = 0.0799218 loss)
I0530 01:28:21.809669 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123724 (* 1 = 0.0123724 loss)
I0530 01:28:21.809672 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139962 (* 1 = 0.0139962 loss)
I0530 01:28:21.809677 24924 sgd_solver.cpp:106] Iteration 5020, lr = 0.0002
I0530 01:29:10.466135 24924 solver.cpp:228] Iteration 5040, loss = 0.2842
I0530 01:29:10.466156 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:29:10.466161 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.095782 (* 1 = 0.095782 loss)
I0530 01:29:10.466166 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.264507 (* 1 = 0.264507 loss)
I0530 01:29:10.466168 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185649 (* 1 = 0.0185649 loss)
I0530 01:29:10.466171 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020645 (* 1 = 0.020645 loss)
I0530 01:29:10.466176 24924 sgd_solver.cpp:106] Iteration 5040, lr = 0.0002
I0530 01:29:59.112524 24924 solver.cpp:228] Iteration 5060, loss = 0.408365
I0530 01:29:59.112558 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:29:59.112566 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.053632 (* 1 = 0.053632 loss)
I0530 01:29:59.112570 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156435 (* 1 = 0.156435 loss)
I0530 01:29:59.112573 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111334 (* 1 = 0.0111334 loss)
I0530 01:29:59.112576 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190311 (* 1 = 0.0190311 loss)
I0530 01:29:59.112581 24924 sgd_solver.cpp:106] Iteration 5060, lr = 0.0002
I0530 01:30:47.720984 24924 solver.cpp:228] Iteration 5080, loss = 0.802144
I0530 01:30:47.721034 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.585938
I0530 01:30:47.721040 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.756298 (* 1 = 0.756298 loss)
I0530 01:30:47.721043 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.83135 (* 1 = 0.83135 loss)
I0530 01:30:47.721045 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.210934 (* 1 = 0.210934 loss)
I0530 01:30:47.721050 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.438173 (* 1 = 0.438173 loss)
I0530 01:30:47.721053 24924 sgd_solver.cpp:106] Iteration 5080, lr = 0.0002
I0530 01:31:36.293879 24924 solver.cpp:228] Iteration 5100, loss = 0.372053
I0530 01:31:36.293915 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 01:31:36.293936 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0770816 (* 1 = 0.0770816 loss)
I0530 01:31:36.293939 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.157288 (* 1 = 0.157288 loss)
I0530 01:31:36.293943 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00884149 (* 1 = 0.00884149 loss)
I0530 01:31:36.293946 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155553 (* 1 = 0.0155553 loss)
I0530 01:31:36.293951 24924 sgd_solver.cpp:106] Iteration 5100, lr = 0.0002
I0530 01:32:24.868379 24924 solver.cpp:228] Iteration 5120, loss = 0.353208
I0530 01:32:24.868402 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 01:32:24.868409 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0956715 (* 1 = 0.0956715 loss)
I0530 01:32:24.868412 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.199285 (* 1 = 0.199285 loss)
I0530 01:32:24.868415 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163149 (* 1 = 0.0163149 loss)
I0530 01:32:24.868418 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179446 (* 1 = 0.0179446 loss)
I0530 01:32:24.868422 24924 sgd_solver.cpp:106] Iteration 5120, lr = 0.0002
I0530 01:33:13.437836 24924 solver.cpp:228] Iteration 5140, loss = 0.233834
I0530 01:33:13.437875 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:33:13.437882 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561806 (* 1 = 0.0561806 loss)
I0530 01:33:13.437887 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.151183 (* 1 = 0.151183 loss)
I0530 01:33:13.437892 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00801216 (* 1 = 0.00801216 loss)
I0530 01:33:13.437896 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128638 (* 1 = 0.0128638 loss)
I0530 01:33:13.437901 24924 sgd_solver.cpp:106] Iteration 5140, lr = 0.0002
I0530 01:34:02.049365 24924 solver.cpp:228] Iteration 5160, loss = 0.365744
I0530 01:34:02.049399 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:34:02.049407 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0212774 (* 1 = 0.0212774 loss)
I0530 01:34:02.049410 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.120355 (* 1 = 0.120355 loss)
I0530 01:34:02.049413 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140577 (* 1 = 0.0140577 loss)
I0530 01:34:02.049417 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155469 (* 1 = 0.0155469 loss)
I0530 01:34:02.049422 24924 sgd_solver.cpp:106] Iteration 5160, lr = 0.0002
I0530 01:34:50.652863 24924 solver.cpp:228] Iteration 5180, loss = 0.341773
I0530 01:34:50.652897 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:34:50.652906 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00410489 (* 1 = 0.00410489 loss)
I0530 01:34:50.652912 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144986 (* 1 = 0.144986 loss)
I0530 01:34:50.652916 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0459878 (* 1 = 0.0459878 loss)
I0530 01:34:50.652920 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525549 (* 1 = 0.0525549 loss)
I0530 01:34:50.652923 24924 sgd_solver.cpp:106] Iteration 5180, lr = 0.0002
speed: 2.444s / iter
I0530 01:35:39.185288 24924 solver.cpp:228] Iteration 5200, loss = 0.375
I0530 01:35:39.185324 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0530 01:35:39.185331 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.377117 (* 1 = 0.377117 loss)
I0530 01:35:39.185335 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.523271 (* 1 = 0.523271 loss)
I0530 01:35:39.185338 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.148454 (* 1 = 0.148454 loss)
I0530 01:35:39.185341 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.205149 (* 1 = 0.205149 loss)
I0530 01:35:39.185345 24924 sgd_solver.cpp:106] Iteration 5200, lr = 0.0002
I0530 01:36:27.781327 24924 solver.cpp:228] Iteration 5220, loss = 0.470191
I0530 01:36:27.781363 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 01:36:27.781370 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609733 (* 1 = 0.0609733 loss)
I0530 01:36:27.781374 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.11107 (* 1 = 0.11107 loss)
I0530 01:36:27.781378 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00518559 (* 1 = 0.00518559 loss)
I0530 01:36:27.781381 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0420684 (* 1 = 0.0420684 loss)
I0530 01:36:27.781385 24924 sgd_solver.cpp:106] Iteration 5220, lr = 0.0002
I0530 01:37:16.314203 24924 solver.cpp:228] Iteration 5240, loss = 0.579469
I0530 01:37:16.314225 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 01:37:16.314245 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.242081 (* 1 = 0.242081 loss)
I0530 01:37:16.314250 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.425869 (* 1 = 0.425869 loss)
I0530 01:37:16.314254 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215074 (* 1 = 0.0215074 loss)
I0530 01:37:16.314256 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0906124 (* 1 = 0.0906124 loss)
I0530 01:37:16.314260 24924 sgd_solver.cpp:106] Iteration 5240, lr = 0.0002
I0530 01:38:04.828025 24924 solver.cpp:228] Iteration 5260, loss = 0.231649
I0530 01:38:04.828059 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:38:04.828068 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314735 (* 1 = 0.0314735 loss)
I0530 01:38:04.828070 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113464 (* 1 = 0.113464 loss)
I0530 01:38:04.828074 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00846326 (* 1 = 0.00846326 loss)
I0530 01:38:04.828078 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0099748 (* 1 = 0.0099748 loss)
I0530 01:38:04.828081 24924 sgd_solver.cpp:106] Iteration 5260, lr = 0.0002
I0530 01:38:53.404348 24924 solver.cpp:228] Iteration 5280, loss = 0.193363
I0530 01:38:53.404384 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:38:53.404392 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474287 (* 1 = 0.0474287 loss)
I0530 01:38:53.404395 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101637 (* 1 = 0.101637 loss)
I0530 01:38:53.404398 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018606 (* 1 = 0.018606 loss)
I0530 01:38:53.404402 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165317 (* 1 = 0.0165317 loss)
I0530 01:38:53.404405 24924 sgd_solver.cpp:106] Iteration 5280, lr = 0.0002
I0530 01:39:41.939478 24924 solver.cpp:228] Iteration 5300, loss = 0.502173
I0530 01:39:41.939513 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 01:39:41.939520 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.085165 (* 1 = 0.085165 loss)
I0530 01:39:41.939523 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.211636 (* 1 = 0.211636 loss)
I0530 01:39:41.939527 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00443541 (* 1 = 0.00443541 loss)
I0530 01:39:41.939530 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408526 (* 1 = 0.0408526 loss)
I0530 01:39:41.939533 24924 sgd_solver.cpp:106] Iteration 5300, lr = 0.0002
I0530 01:40:30.466702 24924 solver.cpp:228] Iteration 5320, loss = 0.374333
I0530 01:40:30.466738 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 01:40:30.466745 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0897382 (* 1 = 0.0897382 loss)
I0530 01:40:30.466748 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.171847 (* 1 = 0.171847 loss)
I0530 01:40:30.466753 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00390884 (* 1 = 0.00390884 loss)
I0530 01:40:30.466758 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172682 (* 1 = 0.0172682 loss)
I0530 01:40:30.466763 24924 sgd_solver.cpp:106] Iteration 5320, lr = 0.0002
I0530 01:41:18.979915 24924 solver.cpp:228] Iteration 5340, loss = 0.511015
I0530 01:41:18.979951 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 01:41:18.979959 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381856 (* 1 = 0.0381856 loss)
I0530 01:41:18.979964 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.105904 (* 1 = 0.105904 loss)
I0530 01:41:18.979967 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010032 (* 1 = 0.010032 loss)
I0530 01:41:18.979972 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00873187 (* 1 = 0.00873187 loss)
I0530 01:41:18.979979 24924 sgd_solver.cpp:106] Iteration 5340, lr = 0.0002
I0530 01:42:07.538399 24924 solver.cpp:228] Iteration 5360, loss = 0.56572
I0530 01:42:07.538420 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:42:07.538441 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325951 (* 1 = 0.0325951 loss)
I0530 01:42:07.538444 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.128706 (* 1 = 0.128706 loss)
I0530 01:42:07.538449 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252435 (* 1 = 0.0252435 loss)
I0530 01:42:07.538451 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362077 (* 1 = 0.0362077 loss)
I0530 01:42:07.538455 24924 sgd_solver.cpp:106] Iteration 5360, lr = 0.0002
I0530 01:42:56.094712 24924 solver.cpp:228] Iteration 5380, loss = 0.329534
I0530 01:42:56.094748 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:42:56.094754 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0551104 (* 1 = 0.0551104 loss)
I0530 01:42:56.094758 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0943614 (* 1 = 0.0943614 loss)
I0530 01:42:56.094763 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00831228 (* 1 = 0.00831228 loss)
I0530 01:42:56.094765 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106309 (* 1 = 0.0106309 loss)
I0530 01:42:56.094769 24924 sgd_solver.cpp:106] Iteration 5380, lr = 0.0002
speed: 2.443s / iter
I0530 01:43:44.675920 24924 solver.cpp:228] Iteration 5400, loss = 0.30706
I0530 01:43:44.675956 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 01:43:44.675963 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000916451 (* 1 = 0.000916451 loss)
I0530 01:43:44.675966 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0410364 (* 1 = 0.0410364 loss)
I0530 01:43:44.675971 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00694691 (* 1 = 0.00694691 loss)
I0530 01:43:44.675973 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0518246 (* 1 = 0.0518246 loss)
I0530 01:43:44.675977 24924 sgd_solver.cpp:106] Iteration 5400, lr = 0.0002
I0530 01:44:33.191723 24924 solver.cpp:228] Iteration 5420, loss = 0.522305
I0530 01:44:33.191759 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 01:44:33.191766 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.11526 (* 1 = 0.11526 loss)
I0530 01:44:33.191771 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113286 (* 1 = 0.113286 loss)
I0530 01:44:33.191773 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131041 (* 1 = 0.0131041 loss)
I0530 01:44:33.191776 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142346 (* 1 = 0.0142346 loss)
I0530 01:44:33.191781 24924 sgd_solver.cpp:106] Iteration 5420, lr = 0.0002
I0530 01:45:21.818755 24924 solver.cpp:228] Iteration 5440, loss = 0.325959
I0530 01:45:21.818792 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 01:45:21.818799 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13529 (* 1 = 0.13529 loss)
I0530 01:45:21.818802 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.28371 (* 1 = 0.28371 loss)
I0530 01:45:21.818806 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342901 (* 1 = 0.0342901 loss)
I0530 01:45:21.818811 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0414018 (* 1 = 0.0414018 loss)
I0530 01:45:21.818816 24924 sgd_solver.cpp:106] Iteration 5440, lr = 0.0002
I0530 01:46:10.348978 24924 solver.cpp:228] Iteration 5460, loss = 0.32776
I0530 01:46:10.349010 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:46:10.349031 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251335 (* 1 = 0.0251335 loss)
I0530 01:46:10.349035 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.047953 (* 1 = 0.047953 loss)
I0530 01:46:10.349040 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0614913 (* 1 = 0.0614913 loss)
I0530 01:46:10.349042 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.15718 (* 1 = 0.15718 loss)
I0530 01:46:10.349046 24924 sgd_solver.cpp:106] Iteration 5460, lr = 0.0002
I0530 01:46:58.949515 24924 solver.cpp:228] Iteration 5480, loss = 0.41607
I0530 01:46:58.949537 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:46:58.949544 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314829 (* 1 = 0.0314829 loss)
I0530 01:46:58.949548 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142679 (* 1 = 0.142679 loss)
I0530 01:46:58.949551 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.040629 (* 1 = 0.040629 loss)
I0530 01:46:58.949554 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176349 (* 1 = 0.0176349 loss)
I0530 01:46:58.949558 24924 sgd_solver.cpp:106] Iteration 5480, lr = 0.0002
I0530 01:47:47.533792 24924 solver.cpp:228] Iteration 5500, loss = 0.374135
I0530 01:47:47.533828 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 01:47:47.533835 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00158041 (* 1 = 0.00158041 loss)
I0530 01:47:47.533838 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0443688 (* 1 = 0.0443688 loss)
I0530 01:47:47.533841 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017623 (* 1 = 0.017623 loss)
I0530 01:47:47.533844 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0673726 (* 1 = 0.0673726 loss)
I0530 01:47:47.533849 24924 sgd_solver.cpp:106] Iteration 5500, lr = 0.0002
I0530 01:48:36.042132 24924 solver.cpp:228] Iteration 5520, loss = 0.893928
I0530 01:48:36.042166 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 01:48:36.042173 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.185786 (* 1 = 0.185786 loss)
I0530 01:48:36.042177 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186459 (* 1 = 0.186459 loss)
I0530 01:48:36.042182 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131778 (* 1 = 0.0131778 loss)
I0530 01:48:36.042187 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.038042 (* 1 = 0.038042 loss)
I0530 01:48:36.042192 24924 sgd_solver.cpp:106] Iteration 5520, lr = 0.0002
I0530 01:49:24.600463 24924 solver.cpp:228] Iteration 5540, loss = 0.367365
I0530 01:49:24.600498 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:49:24.600505 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251098 (* 1 = 0.0251098 loss)
I0530 01:49:24.600509 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109965 (* 1 = 0.109965 loss)
I0530 01:49:24.600512 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00709112 (* 1 = 0.00709112 loss)
I0530 01:49:24.600515 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00355546 (* 1 = 0.00355546 loss)
I0530 01:49:24.600519 24924 sgd_solver.cpp:106] Iteration 5540, lr = 0.0002
I0530 01:50:13.153165 24924 solver.cpp:228] Iteration 5560, loss = 0.273107
I0530 01:50:13.153200 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 01:50:13.153208 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0420742 (* 1 = 0.0420742 loss)
I0530 01:50:13.153210 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0651108 (* 1 = 0.0651108 loss)
I0530 01:50:13.153213 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00457782 (* 1 = 0.00457782 loss)
I0530 01:50:13.153218 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105212 (* 1 = 0.0105212 loss)
I0530 01:50:13.153221 24924 sgd_solver.cpp:106] Iteration 5560, lr = 0.0002
I0530 01:51:01.737335 24924 solver.cpp:228] Iteration 5580, loss = 0.370531
I0530 01:51:01.737370 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 01:51:01.737377 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.193155 (* 1 = 0.193155 loss)
I0530 01:51:01.737381 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.243169 (* 1 = 0.243169 loss)
I0530 01:51:01.737385 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162972 (* 1 = 0.0162972 loss)
I0530 01:51:01.737387 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330286 (* 1 = 0.0330286 loss)
I0530 01:51:01.737391 24924 sgd_solver.cpp:106] Iteration 5580, lr = 0.0002
speed: 2.443s / iter
I0530 01:51:50.263865 24924 solver.cpp:228] Iteration 5600, loss = 0.320904
I0530 01:51:50.263900 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 01:51:50.263907 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.141021 (* 1 = 0.141021 loss)
I0530 01:51:50.263911 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.294357 (* 1 = 0.294357 loss)
I0530 01:51:50.263914 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00760929 (* 1 = 0.00760929 loss)
I0530 01:51:50.263917 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016958 (* 1 = 0.016958 loss)
I0530 01:51:50.263921 24924 sgd_solver.cpp:106] Iteration 5600, lr = 0.0002
I0530 01:52:38.807235 24924 solver.cpp:228] Iteration 5620, loss = 0.283826
I0530 01:52:38.807271 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:52:38.807277 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0127192 (* 1 = 0.0127192 loss)
I0530 01:52:38.807281 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100022 (* 1 = 0.100022 loss)
I0530 01:52:38.807286 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137897 (* 1 = 0.0137897 loss)
I0530 01:52:38.807288 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00768021 (* 1 = 0.00768021 loss)
I0530 01:52:38.807292 24924 sgd_solver.cpp:106] Iteration 5620, lr = 0.0002
I0530 01:53:27.377552 24924 solver.cpp:228] Iteration 5640, loss = 0.368768
I0530 01:53:27.377588 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 01:53:27.377595 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.244343 (* 1 = 0.244343 loss)
I0530 01:53:27.377599 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.402333 (* 1 = 0.402333 loss)
I0530 01:53:27.377602 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0472841 (* 1 = 0.0472841 loss)
I0530 01:53:27.377605 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402027 (* 1 = 0.0402027 loss)
I0530 01:53:27.377609 24924 sgd_solver.cpp:106] Iteration 5640, lr = 0.0002
I0530 01:54:15.963455 24924 solver.cpp:228] Iteration 5660, loss = 0.38764
I0530 01:54:15.963493 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 01:54:15.963501 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0025477 (* 1 = 0.0025477 loss)
I0530 01:54:15.963506 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.081049 (* 1 = 0.081049 loss)
I0530 01:54:15.963510 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128769 (* 1 = 0.0128769 loss)
I0530 01:54:15.963515 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0452046 (* 1 = 0.0452046 loss)
I0530 01:54:15.963520 24924 sgd_solver.cpp:106] Iteration 5660, lr = 0.0002
I0530 01:55:04.549526 24924 solver.cpp:228] Iteration 5680, loss = 0.342834
I0530 01:55:04.549562 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 01:55:04.549571 24924 solver.cpp:244]     Train net output #1: loss_bbox = 8.26545e-05 (* 1 = 8.26545e-05 loss)
I0530 01:55:04.549574 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0410598 (* 1 = 0.0410598 loss)
I0530 01:55:04.549577 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200933 (* 1 = 0.0200933 loss)
I0530 01:55:04.549580 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0305341 (* 1 = 0.0305341 loss)
I0530 01:55:04.549584 24924 sgd_solver.cpp:106] Iteration 5680, lr = 0.0002
I0530 01:55:53.134218 24924 solver.cpp:228] Iteration 5700, loss = 0.343748
I0530 01:55:53.134255 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 01:55:53.134263 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0956096 (* 1 = 0.0956096 loss)
I0530 01:55:53.134266 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.241458 (* 1 = 0.241458 loss)
I0530 01:55:53.134269 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126737 (* 1 = 0.0126737 loss)
I0530 01:55:53.134272 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0193131 (* 1 = 0.0193131 loss)
I0530 01:55:53.134277 24924 sgd_solver.cpp:106] Iteration 5700, lr = 0.0002
I0530 01:56:41.682848 24924 solver.cpp:228] Iteration 5720, loss = 0.645782
I0530 01:56:41.682885 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 01:56:41.682893 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0562803 (* 1 = 0.0562803 loss)
I0530 01:56:41.682896 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.317686 (* 1 = 0.317686 loss)
I0530 01:56:41.682899 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0567155 (* 1 = 0.0567155 loss)
I0530 01:56:41.682902 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345589 (* 1 = 0.0345589 loss)
I0530 01:56:41.682906 24924 sgd_solver.cpp:106] Iteration 5720, lr = 0.0002
I0530 01:57:30.247686 24924 solver.cpp:228] Iteration 5740, loss = 0.333044
I0530 01:57:30.247722 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 01:57:30.247730 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.107099 (* 1 = 0.107099 loss)
I0530 01:57:30.247732 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.279021 (* 1 = 0.279021 loss)
I0530 01:57:30.247735 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0356211 (* 1 = 0.0356211 loss)
I0530 01:57:30.247738 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0446041 (* 1 = 0.0446041 loss)
I0530 01:57:30.247743 24924 sgd_solver.cpp:106] Iteration 5740, lr = 0.0002
I0530 01:58:18.855515 24924 solver.cpp:228] Iteration 5760, loss = 0.298122
I0530 01:58:18.855549 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 01:58:18.855556 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.131798 (* 1 = 0.131798 loss)
I0530 01:58:18.855559 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.151299 (* 1 = 0.151299 loss)
I0530 01:58:18.855562 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00687725 (* 1 = 0.00687725 loss)
I0530 01:58:18.855566 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0564238 (* 1 = 0.0564238 loss)
I0530 01:58:18.855571 24924 sgd_solver.cpp:106] Iteration 5760, lr = 0.0002
I0530 01:59:07.444743 24924 solver.cpp:228] Iteration 5780, loss = 0.320668
I0530 01:59:07.444766 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 01:59:07.444787 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122606 (* 1 = 0.122606 loss)
I0530 01:59:07.444789 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.157498 (* 1 = 0.157498 loss)
I0530 01:59:07.444793 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012008 (* 1 = 0.012008 loss)
I0530 01:59:07.444797 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208649 (* 1 = 0.0208649 loss)
I0530 01:59:07.444800 24924 sgd_solver.cpp:106] Iteration 5780, lr = 0.0002
speed: 2.442s / iter
I0530 01:59:56.028398 24924 solver.cpp:228] Iteration 5800, loss = 0.26377
I0530 01:59:56.028434 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 01:59:56.028441 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220317 (* 1 = 0.0220317 loss)
I0530 01:59:56.028445 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117759 (* 1 = 0.117759 loss)
I0530 01:59:56.028448 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00775566 (* 1 = 0.00775566 loss)
I0530 01:59:56.028452 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105663 (* 1 = 0.0105663 loss)
I0530 01:59:56.028456 24924 sgd_solver.cpp:106] Iteration 5800, lr = 0.0002
I0530 02:00:44.645723 24924 solver.cpp:228] Iteration 5820, loss = 0.170834
I0530 02:00:44.645761 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:00:44.645767 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00146611 (* 1 = 0.00146611 loss)
I0530 02:00:44.645771 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0795153 (* 1 = 0.0795153 loss)
I0530 02:00:44.645774 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378185 (* 1 = 0.0378185 loss)
I0530 02:00:44.645777 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241956 (* 1 = 0.0241956 loss)
I0530 02:00:44.645782 24924 sgd_solver.cpp:106] Iteration 5820, lr = 0.0002
I0530 02:01:33.249963 24924 solver.cpp:228] Iteration 5840, loss = 0.262368
I0530 02:01:33.249999 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 02:01:33.250005 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00106122 (* 1 = 0.00106122 loss)
I0530 02:01:33.250010 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0392755 (* 1 = 0.0392755 loss)
I0530 02:01:33.250015 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00895033 (* 1 = 0.00895033 loss)
I0530 02:01:33.250020 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0640192 (* 1 = 0.0640192 loss)
I0530 02:01:33.250025 24924 sgd_solver.cpp:106] Iteration 5840, lr = 0.0002
I0530 02:02:21.818397 24924 solver.cpp:228] Iteration 5860, loss = 0.197022
I0530 02:02:21.818434 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 02:02:21.818440 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0879143 (* 1 = 0.0879143 loss)
I0530 02:02:21.818444 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.318434 (* 1 = 0.318434 loss)
I0530 02:02:21.818447 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0305744 (* 1 = 0.0305744 loss)
I0530 02:02:21.818450 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438874 (* 1 = 0.0438874 loss)
I0530 02:02:21.818454 24924 sgd_solver.cpp:106] Iteration 5860, lr = 0.0002
I0530 02:03:10.408918 24924 solver.cpp:228] Iteration 5880, loss = 0.22464
I0530 02:03:10.408952 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 02:03:10.408960 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0214685 (* 1 = 0.0214685 loss)
I0530 02:03:10.408963 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.161523 (* 1 = 0.161523 loss)
I0530 02:03:10.408967 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0413031 (* 1 = 0.0413031 loss)
I0530 02:03:10.408970 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024396 (* 1 = 0.024396 loss)
I0530 02:03:10.408974 24924 sgd_solver.cpp:106] Iteration 5880, lr = 0.0002
I0530 02:03:58.996053 24924 solver.cpp:228] Iteration 5900, loss = 0.487767
I0530 02:03:58.996088 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 02:03:58.996096 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0979558 (* 1 = 0.0979558 loss)
I0530 02:03:58.996100 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.320887 (* 1 = 0.320887 loss)
I0530 02:03:58.996104 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201692 (* 1 = 0.0201692 loss)
I0530 02:03:58.996106 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271826 (* 1 = 0.0271826 loss)
I0530 02:03:58.996111 24924 sgd_solver.cpp:106] Iteration 5900, lr = 0.0002
I0530 02:04:47.569118 24924 solver.cpp:228] Iteration 5920, loss = 0.216884
I0530 02:04:47.569155 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:04:47.569176 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0156729 (* 1 = 0.0156729 loss)
I0530 02:04:47.569180 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0796243 (* 1 = 0.0796243 loss)
I0530 02:04:47.569185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140696 (* 1 = 0.0140696 loss)
I0530 02:04:47.569186 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0142807 (* 1 = 0.0142807 loss)
I0530 02:04:47.569191 24924 sgd_solver.cpp:106] Iteration 5920, lr = 0.0002
I0530 02:05:36.139483 24924 solver.cpp:228] Iteration 5940, loss = 0.250182
I0530 02:05:36.139520 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 02:05:36.139528 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258652 (* 1 = 0.0258652 loss)
I0530 02:05:36.139531 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0895126 (* 1 = 0.0895126 loss)
I0530 02:05:36.139535 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104541 (* 1 = 0.0104541 loss)
I0530 02:05:36.139540 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168393 (* 1 = 0.0168393 loss)
I0530 02:05:36.139545 24924 sgd_solver.cpp:106] Iteration 5940, lr = 0.0002
I0530 02:06:24.738891 24924 solver.cpp:228] Iteration 5960, loss = 0.305195
I0530 02:06:24.738914 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 02:06:24.738921 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.123814 (* 1 = 0.123814 loss)
I0530 02:06:24.738925 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.370349 (* 1 = 0.370349 loss)
I0530 02:06:24.738929 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0297726 (* 1 = 0.0297726 loss)
I0530 02:06:24.738932 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0683357 (* 1 = 0.0683357 loss)
I0530 02:06:24.738936 24924 sgd_solver.cpp:106] Iteration 5960, lr = 0.0002
I0530 02:07:13.423869 24924 solver.cpp:228] Iteration 5980, loss = 0.364273
I0530 02:07:13.423892 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 02:07:13.423898 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.170238 (* 1 = 0.170238 loss)
I0530 02:07:13.423903 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.395791 (* 1 = 0.395791 loss)
I0530 02:07:13.423908 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0303554 (* 1 = 0.0303554 loss)
I0530 02:07:13.423913 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372682 (* 1 = 0.0372682 loss)
I0530 02:07:13.423918 24924 sgd_solver.cpp:106] Iteration 5980, lr = 0.0002
speed: 2.442s / iter
I0530 02:08:02.034616 24924 solver.cpp:228] Iteration 6000, loss = 0.211796
I0530 02:08:02.034651 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:08:02.034657 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0187674 (* 1 = 0.0187674 loss)
I0530 02:08:02.034662 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0631537 (* 1 = 0.0631537 loss)
I0530 02:08:02.034664 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0314879 (* 1 = 0.0314879 loss)
I0530 02:08:02.034667 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205253 (* 1 = 0.0205253 loss)
I0530 02:08:02.034672 24924 sgd_solver.cpp:106] Iteration 6000, lr = 0.0002
I0530 02:08:50.621577 24924 solver.cpp:228] Iteration 6020, loss = 0.188378
I0530 02:08:50.621613 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 02:08:50.621620 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0575044 (* 1 = 0.0575044 loss)
I0530 02:08:50.621624 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101873 (* 1 = 0.101873 loss)
I0530 02:08:50.621628 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012723 (* 1 = 0.012723 loss)
I0530 02:08:50.621630 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185569 (* 1 = 0.0185569 loss)
I0530 02:08:50.621635 24924 sgd_solver.cpp:106] Iteration 6020, lr = 0.0002
I0530 02:09:39.219869 24924 solver.cpp:228] Iteration 6040, loss = 0.355984
I0530 02:09:39.219907 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 02:09:39.219913 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103009 (* 1 = 0.103009 loss)
I0530 02:09:39.219918 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.201984 (* 1 = 0.201984 loss)
I0530 02:09:39.219920 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.10322 (* 1 = 0.10322 loss)
I0530 02:09:39.219923 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0611187 (* 1 = 0.0611187 loss)
I0530 02:09:39.219928 24924 sgd_solver.cpp:106] Iteration 6040, lr = 0.0002
I0530 02:10:27.799535 24924 solver.cpp:228] Iteration 6060, loss = 0.279402
I0530 02:10:27.799572 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 02:10:27.799579 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708377 (* 1 = 0.0708377 loss)
I0530 02:10:27.799583 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.198129 (* 1 = 0.198129 loss)
I0530 02:10:27.799587 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245204 (* 1 = 0.0245204 loss)
I0530 02:10:27.799589 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190662 (* 1 = 0.0190662 loss)
I0530 02:10:27.799593 24924 sgd_solver.cpp:106] Iteration 6060, lr = 0.0002
I0530 02:11:16.419402 24924 solver.cpp:228] Iteration 6080, loss = 0.277696
I0530 02:11:16.419437 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 02:11:16.419445 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.121019 (* 1 = 0.121019 loss)
I0530 02:11:16.419448 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0793289 (* 1 = 0.0793289 loss)
I0530 02:11:16.419451 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00426672 (* 1 = 0.00426672 loss)
I0530 02:11:16.419454 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146851 (* 1 = 0.0146851 loss)
I0530 02:11:16.419458 24924 sgd_solver.cpp:106] Iteration 6080, lr = 0.0002
I0530 02:12:04.992409 24924 solver.cpp:228] Iteration 6100, loss = 0.283968
I0530 02:12:04.992444 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 02:12:04.992451 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0548988 (* 1 = 0.0548988 loss)
I0530 02:12:04.992455 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.20096 (* 1 = 0.20096 loss)
I0530 02:12:04.992458 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242009 (* 1 = 0.0242009 loss)
I0530 02:12:04.992461 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101071 (* 1 = 0.101071 loss)
I0530 02:12:04.992465 24924 sgd_solver.cpp:106] Iteration 6100, lr = 0.0002
I0530 02:12:53.622578 24924 solver.cpp:228] Iteration 6120, loss = 0.495573
I0530 02:12:53.622615 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 02:12:53.622622 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.22804 (* 1 = 0.22804 loss)
I0530 02:12:53.622625 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.408674 (* 1 = 0.408674 loss)
I0530 02:12:53.622628 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0694912 (* 1 = 0.0694912 loss)
I0530 02:12:53.622632 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0956175 (* 1 = 0.0956175 loss)
I0530 02:12:53.622637 24924 sgd_solver.cpp:106] Iteration 6120, lr = 0.0002
I0530 02:13:42.230634 24924 solver.cpp:228] Iteration 6140, loss = 0.569064
I0530 02:13:42.230659 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:13:42.230665 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634868 (* 1 = 0.0634868 loss)
I0530 02:13:42.230669 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0898807 (* 1 = 0.0898807 loss)
I0530 02:13:42.230674 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00822483 (* 1 = 0.00822483 loss)
I0530 02:13:42.230676 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144296 (* 1 = 0.0144296 loss)
I0530 02:13:42.230681 24924 sgd_solver.cpp:106] Iteration 6140, lr = 0.0002
I0530 02:14:30.821276 24924 solver.cpp:228] Iteration 6160, loss = 0.421526
I0530 02:14:30.821300 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 02:14:30.821305 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0757814 (* 1 = 0.0757814 loss)
I0530 02:14:30.821310 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152657 (* 1 = 0.152657 loss)
I0530 02:14:30.821313 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713748 (* 1 = 0.00713748 loss)
I0530 02:14:30.821316 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179662 (* 1 = 0.0179662 loss)
I0530 02:14:30.821321 24924 sgd_solver.cpp:106] Iteration 6160, lr = 0.0002
I0530 02:15:19.391136 24924 solver.cpp:228] Iteration 6180, loss = 0.401885
I0530 02:15:19.391172 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 02:15:19.391178 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0712201 (* 1 = 0.0712201 loss)
I0530 02:15:19.391182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.17879 (* 1 = 0.17879 loss)
I0530 02:15:19.391186 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02004 (* 1 = 0.02004 loss)
I0530 02:15:19.391189 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.04782 (* 1 = 0.04782 loss)
I0530 02:15:19.391193 24924 sgd_solver.cpp:106] Iteration 6180, lr = 0.0002
speed: 2.441s / iter
I0530 02:16:07.993705 24924 solver.cpp:228] Iteration 6200, loss = 0.319115
I0530 02:16:07.993741 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0530 02:16:07.993748 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.245311 (* 1 = 0.245311 loss)
I0530 02:16:07.993752 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.436043 (* 1 = 0.436043 loss)
I0530 02:16:07.993755 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.047037 (* 1 = 0.047037 loss)
I0530 02:16:07.993758 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0621822 (* 1 = 0.0621822 loss)
I0530 02:16:07.993762 24924 sgd_solver.cpp:106] Iteration 6200, lr = 0.0002
I0530 02:16:56.602959 24924 solver.cpp:228] Iteration 6220, loss = 0.486712
I0530 02:16:56.602982 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 02:16:56.602989 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.110453 (* 1 = 0.110453 loss)
I0530 02:16:56.602993 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.260366 (* 1 = 0.260366 loss)
I0530 02:16:56.602998 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00716435 (* 1 = 0.00716435 loss)
I0530 02:16:56.603001 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149982 (* 1 = 0.0149982 loss)
I0530 02:16:56.603005 24924 sgd_solver.cpp:106] Iteration 6220, lr = 0.0002
I0530 02:17:45.203696 24924 solver.cpp:228] Iteration 6240, loss = 0.282598
I0530 02:17:45.203730 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:17:45.203738 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0209106 (* 1 = 0.0209106 loss)
I0530 02:17:45.203742 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0856722 (* 1 = 0.0856722 loss)
I0530 02:17:45.203747 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00998812 (* 1 = 0.00998812 loss)
I0530 02:17:45.203749 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156994 (* 1 = 0.0156994 loss)
I0530 02:17:45.203753 24924 sgd_solver.cpp:106] Iteration 6240, lr = 0.0002
I0530 02:18:33.820374 24924 solver.cpp:228] Iteration 6260, loss = 0.36945
I0530 02:18:33.820410 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 02:18:33.820415 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0310921 (* 1 = 0.0310921 loss)
I0530 02:18:33.820420 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152368 (* 1 = 0.152368 loss)
I0530 02:18:33.820422 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136105 (* 1 = 0.0136105 loss)
I0530 02:18:33.820425 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.041828 (* 1 = 0.041828 loss)
I0530 02:18:33.820430 24924 sgd_solver.cpp:106] Iteration 6260, lr = 0.0002
I0530 02:19:22.407472 24924 solver.cpp:228] Iteration 6280, loss = 0.391823
I0530 02:19:22.407507 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 02:19:22.407515 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.039078 (* 1 = 0.039078 loss)
I0530 02:19:22.407518 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0854595 (* 1 = 0.0854595 loss)
I0530 02:19:22.407521 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766129 (* 1 = 0.00766129 loss)
I0530 02:19:22.407524 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188753 (* 1 = 0.0188753 loss)
I0530 02:19:22.407528 24924 sgd_solver.cpp:106] Iteration 6280, lr = 0.0002
I0530 02:20:10.979461 24924 solver.cpp:228] Iteration 6300, loss = 0.326221
I0530 02:20:10.979497 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 02:20:10.979504 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309642 (* 1 = 0.0309642 loss)
I0530 02:20:10.979508 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0943121 (* 1 = 0.0943121 loss)
I0530 02:20:10.979511 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017941 (* 1 = 0.017941 loss)
I0530 02:20:10.979514 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126701 (* 1 = 0.0126701 loss)
I0530 02:20:10.979519 24924 sgd_solver.cpp:106] Iteration 6300, lr = 0.0002
I0530 02:20:59.620826 24924 solver.cpp:228] Iteration 6320, loss = 0.169531
I0530 02:20:59.620860 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:20:59.620867 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0146861 (* 1 = 0.0146861 loss)
I0530 02:20:59.620872 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0632609 (* 1 = 0.0632609 loss)
I0530 02:20:59.620874 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00495027 (* 1 = 0.00495027 loss)
I0530 02:20:59.620877 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157181 (* 1 = 0.0157181 loss)
I0530 02:20:59.620882 24924 sgd_solver.cpp:106] Iteration 6320, lr = 0.0002
I0530 02:21:48.215538 24924 solver.cpp:228] Iteration 6340, loss = 0.324971
I0530 02:21:48.215574 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 02:21:48.215579 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.113993 (* 1 = 0.113993 loss)
I0530 02:21:48.215584 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.226596 (* 1 = 0.226596 loss)
I0530 02:21:48.215586 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00772742 (* 1 = 0.00772742 loss)
I0530 02:21:48.215590 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133108 (* 1 = 0.0133108 loss)
I0530 02:21:48.215595 24924 sgd_solver.cpp:106] Iteration 6340, lr = 0.0002
I0530 02:22:36.837254 24924 solver.cpp:228] Iteration 6360, loss = 0.429745
I0530 02:22:36.837275 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:22:36.837283 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.029389 (* 1 = 0.029389 loss)
I0530 02:22:36.837286 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.177005 (* 1 = 0.177005 loss)
I0530 02:22:36.837291 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0265766 (* 1 = 0.0265766 loss)
I0530 02:22:36.837293 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00550083 (* 1 = 0.00550083 loss)
I0530 02:22:36.837298 24924 sgd_solver.cpp:106] Iteration 6360, lr = 0.0002
I0530 02:23:25.463346 24924 solver.cpp:228] Iteration 6380, loss = 0.313172
I0530 02:23:25.463366 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 02:23:25.463387 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0441063 (* 1 = 0.0441063 loss)
I0530 02:23:25.463392 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0813028 (* 1 = 0.0813028 loss)
I0530 02:23:25.463394 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155604 (* 1 = 0.0155604 loss)
I0530 02:23:25.463397 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308039 (* 1 = 0.0308039 loss)
I0530 02:23:25.463402 24924 sgd_solver.cpp:106] Iteration 6380, lr = 0.0002
speed: 2.441s / iter
I0530 02:24:14.245303 24924 solver.cpp:228] Iteration 6400, loss = 0.468369
I0530 02:24:14.245324 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 02:24:14.245332 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.11632 (* 1 = 0.11632 loss)
I0530 02:24:14.245334 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.404946 (* 1 = 0.404946 loss)
I0530 02:24:14.245338 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00954503 (* 1 = 0.00954503 loss)
I0530 02:24:14.245342 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0524526 (* 1 = 0.0524526 loss)
I0530 02:24:14.245345 24924 sgd_solver.cpp:106] Iteration 6400, lr = 0.0002
I0530 02:25:03.084214 24924 solver.cpp:228] Iteration 6420, loss = 0.503819
I0530 02:25:03.084249 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 02:25:03.084256 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0400008 (* 1 = 0.0400008 loss)
I0530 02:25:03.084260 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165015 (* 1 = 0.165015 loss)
I0530 02:25:03.084264 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0151902 (* 1 = 0.0151902 loss)
I0530 02:25:03.084266 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241764 (* 1 = 0.0241764 loss)
I0530 02:25:03.084270 24924 sgd_solver.cpp:106] Iteration 6420, lr = 0.0002
I0530 02:25:51.863793 24924 solver.cpp:228] Iteration 6440, loss = 0.511407
I0530 02:25:51.863819 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 02:25:51.863826 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0369476 (* 1 = 0.0369476 loss)
I0530 02:25:51.863831 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0804324 (* 1 = 0.0804324 loss)
I0530 02:25:51.863833 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010128 (* 1 = 0.010128 loss)
I0530 02:25:51.863837 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149068 (* 1 = 0.0149068 loss)
I0530 02:25:51.863842 24924 sgd_solver.cpp:106] Iteration 6440, lr = 0.0002
I0530 02:26:40.679709 24924 solver.cpp:228] Iteration 6460, loss = 0.302415
I0530 02:26:40.679733 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 02:26:40.679739 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0528369 (* 1 = 0.0528369 loss)
I0530 02:26:40.679744 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165757 (* 1 = 0.165757 loss)
I0530 02:26:40.679747 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342041 (* 1 = 0.0342041 loss)
I0530 02:26:40.679750 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0331465 (* 1 = 0.0331465 loss)
I0530 02:26:40.679755 24924 sgd_solver.cpp:106] Iteration 6460, lr = 0.0002
I0530 02:27:29.546568 24924 solver.cpp:228] Iteration 6480, loss = 0.438105
I0530 02:27:29.546604 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 02:27:29.546612 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0845575 (* 1 = 0.0845575 loss)
I0530 02:27:29.546614 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.212867 (* 1 = 0.212867 loss)
I0530 02:27:29.546617 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115501 (* 1 = 0.0115501 loss)
I0530 02:27:29.546620 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107603 (* 1 = 0.0107603 loss)
I0530 02:27:29.546624 24924 sgd_solver.cpp:106] Iteration 6480, lr = 0.0002
I0530 02:28:18.328676 24924 solver.cpp:228] Iteration 6500, loss = 0.360301
I0530 02:28:18.328712 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 02:28:18.328719 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.300652 (* 1 = 0.300652 loss)
I0530 02:28:18.328722 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.422542 (* 1 = 0.422542 loss)
I0530 02:28:18.328727 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0824461 (* 1 = 0.0824461 loss)
I0530 02:28:18.328729 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105379 (* 1 = 0.105379 loss)
I0530 02:28:18.328733 24924 sgd_solver.cpp:106] Iteration 6500, lr = 0.0002
I0530 02:29:07.169555 24924 solver.cpp:228] Iteration 6520, loss = 0.746724
I0530 02:29:07.169592 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 02:29:07.169600 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0841835 (* 1 = 0.0841835 loss)
I0530 02:29:07.169602 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.171635 (* 1 = 0.171635 loss)
I0530 02:29:07.169605 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0340551 (* 1 = 0.0340551 loss)
I0530 02:29:07.169610 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022124 (* 1 = 0.022124 loss)
I0530 02:29:07.169613 24924 sgd_solver.cpp:106] Iteration 6520, lr = 0.0002
I0530 02:29:56.002919 24924 solver.cpp:228] Iteration 6540, loss = 0.305419
I0530 02:29:56.002955 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 02:29:56.002964 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00220704 (* 1 = 0.00220704 loss)
I0530 02:29:56.002967 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0551301 (* 1 = 0.0551301 loss)
I0530 02:29:56.002970 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146074 (* 1 = 0.0146074 loss)
I0530 02:29:56.002972 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226011 (* 1 = 0.0226011 loss)
I0530 02:29:56.002977 24924 sgd_solver.cpp:106] Iteration 6540, lr = 0.0002
I0530 02:30:44.790132 24924 solver.cpp:228] Iteration 6560, loss = 0.253602
I0530 02:30:44.790166 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 02:30:44.790172 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109078 (* 1 = 0.109078 loss)
I0530 02:30:44.790176 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143369 (* 1 = 0.143369 loss)
I0530 02:30:44.790180 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00359479 (* 1 = 0.00359479 loss)
I0530 02:30:44.790184 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00971682 (* 1 = 0.00971682 loss)
I0530 02:30:44.790187 24924 sgd_solver.cpp:106] Iteration 6560, lr = 0.0002
I0530 02:31:33.533911 24924 solver.cpp:228] Iteration 6580, loss = 0.350767
I0530 02:31:33.533947 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 02:31:33.533954 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.138895 (* 1 = 0.138895 loss)
I0530 02:31:33.533957 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.407875 (* 1 = 0.407875 loss)
I0530 02:31:33.533962 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366536 (* 1 = 0.0366536 loss)
I0530 02:31:33.533964 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448236 (* 1 = 0.0448236 loss)
I0530 02:31:33.533968 24924 sgd_solver.cpp:106] Iteration 6580, lr = 0.0002
speed: 2.441s / iter
I0530 02:32:22.329039 24924 solver.cpp:228] Iteration 6600, loss = 0.304938
I0530 02:32:22.329064 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 02:32:22.329071 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0737474 (* 1 = 0.0737474 loss)
I0530 02:32:22.329074 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.339155 (* 1 = 0.339155 loss)
I0530 02:32:22.329078 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0305906 (* 1 = 0.0305906 loss)
I0530 02:32:22.329082 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303125 (* 1 = 0.0303125 loss)
I0530 02:32:22.329087 24924 sgd_solver.cpp:106] Iteration 6600, lr = 0.0002
I0530 02:33:11.208649 24924 solver.cpp:228] Iteration 6620, loss = 0.397217
I0530 02:33:11.208673 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 02:33:11.208680 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.045054 (* 1 = 0.045054 loss)
I0530 02:33:11.208684 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.118363 (* 1 = 0.118363 loss)
I0530 02:33:11.208688 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0455691 (* 1 = 0.0455691 loss)
I0530 02:33:11.208691 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.109178 (* 1 = 0.109178 loss)
I0530 02:33:11.208696 24924 sgd_solver.cpp:106] Iteration 6620, lr = 0.0002
I0530 02:34:00.062902 24924 solver.cpp:228] Iteration 6640, loss = 0.248525
I0530 02:34:00.062925 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:34:00.062932 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0354842 (* 1 = 0.0354842 loss)
I0530 02:34:00.062937 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0982751 (* 1 = 0.0982751 loss)
I0530 02:34:00.062940 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134339 (* 1 = 0.0134339 loss)
I0530 02:34:00.062943 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114237 (* 1 = 0.0114237 loss)
I0530 02:34:00.062947 24924 sgd_solver.cpp:106] Iteration 6640, lr = 0.0002
I0530 02:34:48.863451 24924 solver.cpp:228] Iteration 6660, loss = 0.500789
I0530 02:34:48.863487 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 02:34:48.863494 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.119114 (* 1 = 0.119114 loss)
I0530 02:34:48.863497 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.234451 (* 1 = 0.234451 loss)
I0530 02:34:48.863500 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.034629 (* 1 = 0.034629 loss)
I0530 02:34:48.863504 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0786305 (* 1 = 0.0786305 loss)
I0530 02:34:48.863508 24924 sgd_solver.cpp:106] Iteration 6660, lr = 0.0002
I0530 02:35:37.700100 24924 solver.cpp:228] Iteration 6680, loss = 0.544313
I0530 02:35:37.700137 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 02:35:37.700145 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.176319 (* 1 = 0.176319 loss)
I0530 02:35:37.700147 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272018 (* 1 = 0.272018 loss)
I0530 02:35:37.700151 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0314299 (* 1 = 0.0314299 loss)
I0530 02:35:37.700156 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171088 (* 1 = 0.0171088 loss)
I0530 02:35:37.700162 24924 sgd_solver.cpp:106] Iteration 6680, lr = 0.0002
I0530 02:36:26.490413 24924 solver.cpp:228] Iteration 6700, loss = 0.536523
I0530 02:36:26.490437 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0530 02:36:26.490443 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.220514 (* 1 = 0.220514 loss)
I0530 02:36:26.490447 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.391747 (* 1 = 0.391747 loss)
I0530 02:36:26.490453 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0366709 (* 1 = 0.0366709 loss)
I0530 02:36:26.490458 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0754582 (* 1 = 0.0754582 loss)
I0530 02:36:26.490464 24924 sgd_solver.cpp:106] Iteration 6700, lr = 0.0002
I0530 02:37:15.358579 24924 solver.cpp:228] Iteration 6720, loss = 0.50283
I0530 02:37:15.358603 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 02:37:15.358609 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.112961 (* 1 = 0.112961 loss)
I0530 02:37:15.358614 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186331 (* 1 = 0.186331 loss)
I0530 02:37:15.358618 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181779 (* 1 = 0.0181779 loss)
I0530 02:37:15.358620 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369924 (* 1 = 0.0369924 loss)
I0530 02:37:15.358626 24924 sgd_solver.cpp:106] Iteration 6720, lr = 0.0002
I0530 02:38:04.205569 24924 solver.cpp:228] Iteration 6740, loss = 0.604611
I0530 02:38:04.205605 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 02:38:04.205611 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.057052 (* 1 = 0.057052 loss)
I0530 02:38:04.205615 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.267135 (* 1 = 0.267135 loss)
I0530 02:38:04.205618 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212633 (* 1 = 0.0212633 loss)
I0530 02:38:04.205621 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116891 (* 1 = 0.0116891 loss)
I0530 02:38:04.205626 24924 sgd_solver.cpp:106] Iteration 6740, lr = 0.0002
I0530 02:38:52.893988 24924 solver.cpp:228] Iteration 6760, loss = 0.305409
I0530 02:38:52.894014 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 02:38:52.894021 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.126079 (* 1 = 0.126079 loss)
I0530 02:38:52.894026 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.276834 (* 1 = 0.276834 loss)
I0530 02:38:52.894028 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215264 (* 1 = 0.0215264 loss)
I0530 02:38:52.894032 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0791785 (* 1 = 0.0791785 loss)
I0530 02:38:52.894037 24924 sgd_solver.cpp:106] Iteration 6760, lr = 0.0002
I0530 02:39:41.711587 24924 solver.cpp:228] Iteration 6780, loss = 0.443209
I0530 02:39:41.711609 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 02:39:41.711616 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.25765 (* 1 = 0.25765 loss)
I0530 02:39:41.711621 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.382807 (* 1 = 0.382807 loss)
I0530 02:39:41.711624 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02088 (* 1 = 0.02088 loss)
I0530 02:39:41.711627 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0536356 (* 1 = 0.0536356 loss)
I0530 02:39:41.711632 24924 sgd_solver.cpp:106] Iteration 6780, lr = 0.0002
speed: 2.441s / iter
I0530 02:40:30.403873 24924 solver.cpp:228] Iteration 6800, loss = 0.333564
I0530 02:40:30.403897 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0530 02:40:30.403903 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.254446 (* 1 = 0.254446 loss)
I0530 02:40:30.403906 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.46776 (* 1 = 0.46776 loss)
I0530 02:40:30.403910 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0464912 (* 1 = 0.0464912 loss)
I0530 02:40:30.403913 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.151987 (* 1 = 0.151987 loss)
I0530 02:40:30.403918 24924 sgd_solver.cpp:106] Iteration 6800, lr = 0.0002
I0530 02:41:19.115674 24924 solver.cpp:228] Iteration 6820, loss = 0.540274
I0530 02:41:19.115696 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 02:41:19.115702 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0818953 (* 1 = 0.0818953 loss)
I0530 02:41:19.115706 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.240169 (* 1 = 0.240169 loss)
I0530 02:41:19.115710 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00712562 (* 1 = 0.00712562 loss)
I0530 02:41:19.115712 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0371995 (* 1 = 0.0371995 loss)
I0530 02:41:19.115716 24924 sgd_solver.cpp:106] Iteration 6820, lr = 0.0002
I0530 02:42:07.843804 24924 solver.cpp:228] Iteration 6840, loss = 0.690377
I0530 02:42:07.843840 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 02:42:07.843847 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13699 (* 1 = 0.13699 loss)
I0530 02:42:07.843852 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.320332 (* 1 = 0.320332 loss)
I0530 02:42:07.843854 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0228294 (* 1 = 0.0228294 loss)
I0530 02:42:07.843858 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0702461 (* 1 = 0.0702461 loss)
I0530 02:42:07.843863 24924 sgd_solver.cpp:106] Iteration 6840, lr = 0.0002
I0530 02:42:56.580513 24924 solver.cpp:228] Iteration 6860, loss = 0.304281
I0530 02:42:56.580549 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 02:42:56.580556 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00119689 (* 1 = 0.00119689 loss)
I0530 02:42:56.580560 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0261139 (* 1 = 0.0261139 loss)
I0530 02:42:56.580564 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0628242 (* 1 = 0.0628242 loss)
I0530 02:42:56.580566 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208806 (* 1 = 0.0208806 loss)
I0530 02:42:56.580570 24924 sgd_solver.cpp:106] Iteration 6860, lr = 0.0002
I0530 02:43:45.242841 24924 solver.cpp:228] Iteration 6880, loss = 0.555519
I0530 02:43:45.242875 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 02:43:45.242882 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.144859 (* 1 = 0.144859 loss)
I0530 02:43:45.242885 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.332754 (* 1 = 0.332754 loss)
I0530 02:43:45.242889 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0094415 (* 1 = 0.0094415 loss)
I0530 02:43:45.242892 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274139 (* 1 = 0.0274139 loss)
I0530 02:43:45.242897 24924 sgd_solver.cpp:106] Iteration 6880, lr = 0.0002
I0530 02:44:33.881013 24924 solver.cpp:228] Iteration 6900, loss = 0.275356
I0530 02:44:33.881036 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 02:44:33.881043 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459928 (* 1 = 0.0459928 loss)
I0530 02:44:33.881047 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115069 (* 1 = 0.115069 loss)
I0530 02:44:33.881050 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013944 (* 1 = 0.013944 loss)
I0530 02:44:33.881053 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031019 (* 1 = 0.031019 loss)
I0530 02:44:33.881058 24924 sgd_solver.cpp:106] Iteration 6900, lr = 0.0002
I0530 02:45:22.476070 24924 solver.cpp:228] Iteration 6920, loss = 0.245596
I0530 02:45:22.476106 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 02:45:22.476114 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0279214 (* 1 = 0.0279214 loss)
I0530 02:45:22.476117 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0771142 (* 1 = 0.0771142 loss)
I0530 02:45:22.476120 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00375749 (* 1 = 0.00375749 loss)
I0530 02:45:22.476124 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110127 (* 1 = 0.0110127 loss)
I0530 02:45:22.476127 24924 sgd_solver.cpp:106] Iteration 6920, lr = 0.0002
I0530 02:46:11.063783 24924 solver.cpp:228] Iteration 6940, loss = 0.405261
I0530 02:46:11.063818 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:46:11.063827 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0460595 (* 1 = 0.0460595 loss)
I0530 02:46:11.063829 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.162665 (* 1 = 0.162665 loss)
I0530 02:46:11.063833 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00972057 (* 1 = 0.00972057 loss)
I0530 02:46:11.063836 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120728 (* 1 = 0.0120728 loss)
I0530 02:46:11.063840 24924 sgd_solver.cpp:106] Iteration 6940, lr = 0.0002
I0530 02:46:59.638228 24924 solver.cpp:228] Iteration 6960, loss = 0.448217
I0530 02:46:59.638263 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 02:46:59.638269 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0571479 (* 1 = 0.0571479 loss)
I0530 02:46:59.638273 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.118278 (* 1 = 0.118278 loss)
I0530 02:46:59.638278 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105063 (* 1 = 0.0105063 loss)
I0530 02:46:59.638280 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276906 (* 1 = 0.0276906 loss)
I0530 02:46:59.638284 24924 sgd_solver.cpp:106] Iteration 6960, lr = 0.0002
I0530 02:47:48.211743 24924 solver.cpp:228] Iteration 6980, loss = 0.214362
I0530 02:47:48.211767 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 02:47:48.211774 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.077998 (* 1 = 0.077998 loss)
I0530 02:47:48.211777 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.146577 (* 1 = 0.146577 loss)
I0530 02:47:48.211781 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179004 (* 1 = 0.0179004 loss)
I0530 02:47:48.211784 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027574 (* 1 = 0.027574 loss)
I0530 02:47:48.211788 24924 sgd_solver.cpp:106] Iteration 6980, lr = 0.0002
speed: 2.441s / iter
I0530 02:48:36.734558 24924 solver.cpp:228] Iteration 7000, loss = 0.277995
I0530 02:48:36.734594 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 02:48:36.734601 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.146823 (* 1 = 0.146823 loss)
I0530 02:48:36.734604 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.300367 (* 1 = 0.300367 loss)
I0530 02:48:36.734607 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135386 (* 1 = 0.0135386 loss)
I0530 02:48:36.734611 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301878 (* 1 = 0.0301878 loss)
I0530 02:48:36.734616 24924 sgd_solver.cpp:106] Iteration 7000, lr = 0.0002
I0530 02:49:25.306416 24924 solver.cpp:228] Iteration 7020, loss = 0.280547
I0530 02:49:25.306452 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 02:49:25.306459 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0488505 (* 1 = 0.0488505 loss)
I0530 02:49:25.306463 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.10326 (* 1 = 0.10326 loss)
I0530 02:49:25.306466 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00401265 (* 1 = 0.00401265 loss)
I0530 02:49:25.306469 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00554814 (* 1 = 0.00554814 loss)
I0530 02:49:25.306474 24924 sgd_solver.cpp:106] Iteration 7020, lr = 0.0002
I0530 02:50:13.827560 24924 solver.cpp:228] Iteration 7040, loss = 0.471276
I0530 02:50:13.827596 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 02:50:13.827603 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0923994 (* 1 = 0.0923994 loss)
I0530 02:50:13.827607 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.194361 (* 1 = 0.194361 loss)
I0530 02:50:13.827610 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00447898 (* 1 = 0.00447898 loss)
I0530 02:50:13.827613 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0259235 (* 1 = 0.0259235 loss)
I0530 02:50:13.827617 24924 sgd_solver.cpp:106] Iteration 7040, lr = 0.0002
I0530 02:51:02.331934 24924 solver.cpp:228] Iteration 7060, loss = 0.204327
I0530 02:51:02.331970 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 02:51:02.331976 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.119527 (* 1 = 0.119527 loss)
I0530 02:51:02.331980 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.225358 (* 1 = 0.225358 loss)
I0530 02:51:02.331984 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00911179 (* 1 = 0.00911179 loss)
I0530 02:51:02.331987 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184525 (* 1 = 0.0184525 loss)
I0530 02:51:02.331991 24924 sgd_solver.cpp:106] Iteration 7060, lr = 0.0002
I0530 02:51:50.847872 24924 solver.cpp:228] Iteration 7080, loss = 0.595172
I0530 02:51:50.847893 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:51:50.847899 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0426904 (* 1 = 0.0426904 loss)
I0530 02:51:50.847903 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.149328 (* 1 = 0.149328 loss)
I0530 02:51:50.847905 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013138 (* 1 = 0.013138 loss)
I0530 02:51:50.847909 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00460798 (* 1 = 0.00460798 loss)
I0530 02:51:50.847913 24924 sgd_solver.cpp:106] Iteration 7080, lr = 0.0002
I0530 02:52:39.321516 24924 solver.cpp:228] Iteration 7100, loss = 0.183438
I0530 02:52:39.321550 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 02:52:39.321557 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.117997 (* 1 = 0.117997 loss)
I0530 02:52:39.321561 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.174552 (* 1 = 0.174552 loss)
I0530 02:52:39.321564 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013604 (* 1 = 0.013604 loss)
I0530 02:52:39.321568 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380005 (* 1 = 0.0380005 loss)
I0530 02:52:39.321571 24924 sgd_solver.cpp:106] Iteration 7100, lr = 0.0002
I0530 02:53:27.852293 24924 solver.cpp:228] Iteration 7120, loss = 0.409979
I0530 02:53:27.852313 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:53:27.852319 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0789643 (* 1 = 0.0789643 loss)
I0530 02:53:27.852324 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.111278 (* 1 = 0.111278 loss)
I0530 02:53:27.852327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00414881 (* 1 = 0.00414881 loss)
I0530 02:53:27.852330 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138578 (* 1 = 0.0138578 loss)
I0530 02:53:27.852334 24924 sgd_solver.cpp:106] Iteration 7120, lr = 0.0002
I0530 02:54:16.382684 24924 solver.cpp:228] Iteration 7140, loss = 0.237133
I0530 02:54:16.382720 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:54:16.382726 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232455 (* 1 = 0.0232455 loss)
I0530 02:54:16.382730 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.129957 (* 1 = 0.129957 loss)
I0530 02:54:16.382733 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0252189 (* 1 = 0.0252189 loss)
I0530 02:54:16.382736 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369987 (* 1 = 0.0369987 loss)
I0530 02:54:16.382740 24924 sgd_solver.cpp:106] Iteration 7140, lr = 0.0002
I0530 02:55:04.881014 24924 solver.cpp:228] Iteration 7160, loss = 0.416128
I0530 02:55:04.881049 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 02:55:04.881057 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0450795 (* 1 = 0.0450795 loss)
I0530 02:55:04.881059 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.121028 (* 1 = 0.121028 loss)
I0530 02:55:04.881062 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0217896 (* 1 = 0.0217896 loss)
I0530 02:55:04.881067 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209924 (* 1 = 0.0209924 loss)
I0530 02:55:04.881070 24924 sgd_solver.cpp:106] Iteration 7160, lr = 0.0002
I0530 02:55:53.382606 24924 solver.cpp:228] Iteration 7180, loss = 0.53808
I0530 02:55:53.382640 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 02:55:53.382647 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.263275 (* 1 = 0.263275 loss)
I0530 02:55:53.382650 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.3406 (* 1 = 0.3406 loss)
I0530 02:55:53.382653 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508411 (* 1 = 0.00508411 loss)
I0530 02:55:53.382656 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0334064 (* 1 = 0.0334064 loss)
I0530 02:55:53.382660 24924 sgd_solver.cpp:106] Iteration 7180, lr = 0.0002
speed: 2.440s / iter
I0530 02:56:41.913107 24924 solver.cpp:228] Iteration 7200, loss = 0.389967
I0530 02:56:41.913142 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 02:56:41.913149 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.211313 (* 1 = 0.211313 loss)
I0530 02:56:41.913153 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.310294 (* 1 = 0.310294 loss)
I0530 02:56:41.913157 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00640681 (* 1 = 0.00640681 loss)
I0530 02:56:41.913161 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0480933 (* 1 = 0.0480933 loss)
I0530 02:56:41.913164 24924 sgd_solver.cpp:106] Iteration 7200, lr = 0.0002
I0530 02:57:30.426568 24924 solver.cpp:228] Iteration 7220, loss = 0.280152
I0530 02:57:30.426601 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 02:57:30.426607 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0697268 (* 1 = 0.0697268 loss)
I0530 02:57:30.426611 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.157357 (* 1 = 0.157357 loss)
I0530 02:57:30.426614 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0285493 (* 1 = 0.0285493 loss)
I0530 02:57:30.426617 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325766 (* 1 = 0.0325766 loss)
I0530 02:57:30.426622 24924 sgd_solver.cpp:106] Iteration 7220, lr = 0.0002
I0530 02:58:18.917042 24924 solver.cpp:228] Iteration 7240, loss = 0.19304
I0530 02:58:18.917078 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 02:58:18.917085 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103665 (* 1 = 0.103665 loss)
I0530 02:58:18.917088 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.166472 (* 1 = 0.166472 loss)
I0530 02:58:18.917093 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0340012 (* 1 = 0.0340012 loss)
I0530 02:58:18.917095 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0381269 (* 1 = 0.0381269 loss)
I0530 02:58:18.917099 24924 sgd_solver.cpp:106] Iteration 7240, lr = 0.0002
I0530 02:59:07.454951 24924 solver.cpp:228] Iteration 7260, loss = 0.273358
I0530 02:59:07.454987 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 02:59:07.454993 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254149 (* 1 = 0.0254149 loss)
I0530 02:59:07.454998 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134563 (* 1 = 0.134563 loss)
I0530 02:59:07.455000 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128849 (* 1 = 0.0128849 loss)
I0530 02:59:07.455003 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00839937 (* 1 = 0.00839937 loss)
I0530 02:59:07.455008 24924 sgd_solver.cpp:106] Iteration 7260, lr = 0.0002
I0530 02:59:55.972224 24924 solver.cpp:228] Iteration 7280, loss = 0.602372
I0530 02:59:55.972261 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0530 02:59:55.972268 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.363444 (* 1 = 0.363444 loss)
I0530 02:59:55.972271 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.427514 (* 1 = 0.427514 loss)
I0530 02:59:55.972275 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00832062 (* 1 = 0.00832062 loss)
I0530 02:59:55.972278 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.064782 (* 1 = 0.064782 loss)
I0530 02:59:55.972282 24924 sgd_solver.cpp:106] Iteration 7280, lr = 0.0002
I0530 03:00:44.455245 24924 solver.cpp:228] Iteration 7300, loss = 0.321578
I0530 03:00:44.455279 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 03:00:44.455286 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.161303 (* 1 = 0.161303 loss)
I0530 03:00:44.455289 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.366665 (* 1 = 0.366665 loss)
I0530 03:00:44.455293 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139768 (* 1 = 0.0139768 loss)
I0530 03:00:44.455296 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380749 (* 1 = 0.0380749 loss)
I0530 03:00:44.455301 24924 sgd_solver.cpp:106] Iteration 7300, lr = 0.0002
I0530 03:01:33.008324 24924 solver.cpp:228] Iteration 7320, loss = 0.529365
I0530 03:01:33.008348 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 03:01:33.008354 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0180715 (* 1 = 0.0180715 loss)
I0530 03:01:33.008359 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.044817 (* 1 = 0.044817 loss)
I0530 03:01:33.008365 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00557564 (* 1 = 0.00557564 loss)
I0530 03:01:33.008371 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144855 (* 1 = 0.0144855 loss)
I0530 03:01:33.008376 24924 sgd_solver.cpp:106] Iteration 7320, lr = 0.0002
I0530 03:02:21.629927 24924 solver.cpp:228] Iteration 7340, loss = 0.411191
I0530 03:02:21.629951 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 03:02:21.629958 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.167611 (* 1 = 0.167611 loss)
I0530 03:02:21.629961 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.296194 (* 1 = 0.296194 loss)
I0530 03:02:21.629966 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.020051 (* 1 = 0.020051 loss)
I0530 03:02:21.629968 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0288401 (* 1 = 0.0288401 loss)
I0530 03:02:21.629972 24924 sgd_solver.cpp:106] Iteration 7340, lr = 0.0002
I0530 03:03:10.190755 24924 solver.cpp:228] Iteration 7360, loss = 0.238997
I0530 03:03:10.190791 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 03:03:10.190798 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13005 (* 1 = 0.13005 loss)
I0530 03:03:10.190802 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.243538 (* 1 = 0.243538 loss)
I0530 03:03:10.190806 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0420079 (* 1 = 0.0420079 loss)
I0530 03:03:10.190809 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433011 (* 1 = 0.0433011 loss)
I0530 03:03:10.190814 24924 sgd_solver.cpp:106] Iteration 7360, lr = 0.0002
I0530 03:03:58.725129 24924 solver.cpp:228] Iteration 7380, loss = 0.249117
I0530 03:03:58.725150 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 03:03:58.725157 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0585599 (* 1 = 0.0585599 loss)
I0530 03:03:58.725160 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.18982 (* 1 = 0.18982 loss)
I0530 03:03:58.725163 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262538 (* 1 = 0.0262538 loss)
I0530 03:03:58.725167 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027059 (* 1 = 0.027059 loss)
I0530 03:03:58.725172 24924 sgd_solver.cpp:106] Iteration 7380, lr = 0.0002
speed: 2.440s / iter
I0530 03:04:47.332087 24924 solver.cpp:228] Iteration 7400, loss = 0.683563
I0530 03:04:47.332124 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 03:04:47.332132 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.178094 (* 1 = 0.178094 loss)
I0530 03:04:47.332135 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.394597 (* 1 = 0.394597 loss)
I0530 03:04:47.332139 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0564421 (* 1 = 0.0564421 loss)
I0530 03:04:47.332142 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.224642 (* 1 = 0.224642 loss)
I0530 03:04:47.332146 24924 sgd_solver.cpp:106] Iteration 7400, lr = 0.0002
I0530 03:05:35.903414 24924 solver.cpp:228] Iteration 7420, loss = 0.39514
I0530 03:05:35.903450 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 03:05:35.903457 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0512923 (* 1 = 0.0512923 loss)
I0530 03:05:35.903460 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.110614 (* 1 = 0.110614 loss)
I0530 03:05:35.903465 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00325118 (* 1 = 0.00325118 loss)
I0530 03:05:35.903467 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159441 (* 1 = 0.0159441 loss)
I0530 03:05:35.903471 24924 sgd_solver.cpp:106] Iteration 7420, lr = 0.0002
I0530 03:06:24.445482 24924 solver.cpp:228] Iteration 7440, loss = 0.348773
I0530 03:06:24.445518 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 03:06:24.445524 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.157587 (* 1 = 0.157587 loss)
I0530 03:06:24.445528 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.317094 (* 1 = 0.317094 loss)
I0530 03:06:24.445531 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0326035 (* 1 = 0.0326035 loss)
I0530 03:06:24.445534 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0829927 (* 1 = 0.0829927 loss)
I0530 03:06:24.445538 24924 sgd_solver.cpp:106] Iteration 7440, lr = 0.0002
I0530 03:07:13.012236 24924 solver.cpp:228] Iteration 7460, loss = 0.32342
I0530 03:07:13.012272 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 03:07:13.012279 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.195948 (* 1 = 0.195948 loss)
I0530 03:07:13.012284 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.415738 (* 1 = 0.415738 loss)
I0530 03:07:13.012287 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0298119 (* 1 = 0.0298119 loss)
I0530 03:07:13.012290 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0868139 (* 1 = 0.0868139 loss)
I0530 03:07:13.012295 24924 sgd_solver.cpp:106] Iteration 7460, lr = 0.0002
I0530 03:08:01.601655 24924 solver.cpp:228] Iteration 7480, loss = 0.579214
I0530 03:08:01.601691 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 03:08:01.601697 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.213934 (* 1 = 0.213934 loss)
I0530 03:08:01.601701 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.501025 (* 1 = 0.501025 loss)
I0530 03:08:01.601704 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186435 (* 1 = 0.0186435 loss)
I0530 03:08:01.601707 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0309932 (* 1 = 0.0309932 loss)
I0530 03:08:01.601711 24924 sgd_solver.cpp:106] Iteration 7480, lr = 0.0002
I0530 03:08:50.141278 24924 solver.cpp:228] Iteration 7500, loss = 0.249027
I0530 03:08:50.141314 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:08:50.141321 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440273 (* 1 = 0.0440273 loss)
I0530 03:08:50.141325 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.177131 (* 1 = 0.177131 loss)
I0530 03:08:50.141329 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00309402 (* 1 = 0.00309402 loss)
I0530 03:08:50.141331 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101173 (* 1 = 0.0101173 loss)
I0530 03:08:50.141336 24924 sgd_solver.cpp:106] Iteration 7500, lr = 0.0002
I0530 03:09:38.641139 24924 solver.cpp:228] Iteration 7520, loss = 0.512612
I0530 03:09:38.641173 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 03:09:38.641181 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.095255 (* 1 = 0.095255 loss)
I0530 03:09:38.641185 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0742357 (* 1 = 0.0742357 loss)
I0530 03:09:38.641188 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00206286 (* 1 = 0.00206286 loss)
I0530 03:09:38.641191 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119526 (* 1 = 0.0119526 loss)
I0530 03:09:38.641196 24924 sgd_solver.cpp:106] Iteration 7520, lr = 0.0002
I0530 03:10:27.154400 24924 solver.cpp:228] Iteration 7540, loss = 0.327254
I0530 03:10:27.154438 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0530 03:10:27.154445 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.409946 (* 1 = 0.409946 loss)
I0530 03:10:27.154448 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.604685 (* 1 = 0.604685 loss)
I0530 03:10:27.154453 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0468965 (* 1 = 0.0468965 loss)
I0530 03:10:27.154455 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.116188 (* 1 = 0.116188 loss)
I0530 03:10:27.154460 24924 sgd_solver.cpp:106] Iteration 7540, lr = 0.0002
I0530 03:11:15.710206 24924 solver.cpp:228] Iteration 7560, loss = 0.353037
I0530 03:11:15.710242 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:11:15.710248 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0655329 (* 1 = 0.0655329 loss)
I0530 03:11:15.710252 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.1777 (* 1 = 0.1777 loss)
I0530 03:11:15.710254 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128442 (* 1 = 0.0128442 loss)
I0530 03:11:15.710258 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278409 (* 1 = 0.0278409 loss)
I0530 03:11:15.710263 24924 sgd_solver.cpp:106] Iteration 7560, lr = 0.0002
I0530 03:12:04.270063 24924 solver.cpp:228] Iteration 7580, loss = 0.582063
I0530 03:12:04.270102 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 03:12:04.270110 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.196328 (* 1 = 0.196328 loss)
I0530 03:12:04.270115 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.377011 (* 1 = 0.377011 loss)
I0530 03:12:04.270119 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0303231 (* 1 = 0.0303231 loss)
I0530 03:12:04.270123 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0684662 (* 1 = 0.0684662 loss)
I0530 03:12:04.270128 24924 sgd_solver.cpp:106] Iteration 7580, lr = 0.0002
speed: 2.440s / iter
I0530 03:12:52.807250 24924 solver.cpp:228] Iteration 7600, loss = 0.385885
I0530 03:12:52.807271 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:12:52.807278 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521336 (* 1 = 0.0521336 loss)
I0530 03:12:52.807282 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113172 (* 1 = 0.113172 loss)
I0530 03:12:52.807286 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00477173 (* 1 = 0.00477173 loss)
I0530 03:12:52.807289 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00634245 (* 1 = 0.00634245 loss)
I0530 03:12:52.807293 24924 sgd_solver.cpp:106] Iteration 7600, lr = 0.0002
I0530 03:13:41.379801 24924 solver.cpp:228] Iteration 7620, loss = 0.302065
I0530 03:13:41.379835 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 03:13:41.379843 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0133822 (* 1 = 0.0133822 loss)
I0530 03:13:41.379847 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0359961 (* 1 = 0.0359961 loss)
I0530 03:13:41.379850 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000742619 (* 1 = 0.000742619 loss)
I0530 03:13:41.379853 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00403911 (* 1 = 0.00403911 loss)
I0530 03:13:41.379858 24924 sgd_solver.cpp:106] Iteration 7620, lr = 0.0002
I0530 03:14:29.949802 24924 solver.cpp:228] Iteration 7640, loss = 0.432193
I0530 03:14:29.949825 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:14:29.949831 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0498468 (* 1 = 0.0498468 loss)
I0530 03:14:29.949834 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142991 (* 1 = 0.142991 loss)
I0530 03:14:29.949837 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00733132 (* 1 = 0.00733132 loss)
I0530 03:14:29.949841 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00861091 (* 1 = 0.00861091 loss)
I0530 03:14:29.949846 24924 sgd_solver.cpp:106] Iteration 7640, lr = 0.0002
I0530 03:15:18.509027 24924 solver.cpp:228] Iteration 7660, loss = 0.553477
I0530 03:15:18.509063 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 03:15:18.509070 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.210449 (* 1 = 0.210449 loss)
I0530 03:15:18.509073 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.295251 (* 1 = 0.295251 loss)
I0530 03:15:18.509076 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0319521 (* 1 = 0.0319521 loss)
I0530 03:15:18.509079 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0729041 (* 1 = 0.0729041 loss)
I0530 03:15:18.509084 24924 sgd_solver.cpp:106] Iteration 7660, lr = 0.0002
I0530 03:16:07.064322 24924 solver.cpp:228] Iteration 7680, loss = 0.490003
I0530 03:16:07.064358 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 03:16:07.064365 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0095973 (* 1 = 0.0095973 loss)
I0530 03:16:07.064369 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115996 (* 1 = 0.115996 loss)
I0530 03:16:07.064373 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174566 (* 1 = 0.0174566 loss)
I0530 03:16:07.064376 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0276446 (* 1 = 0.0276446 loss)
I0530 03:16:07.064380 24924 sgd_solver.cpp:106] Iteration 7680, lr = 0.0002
I0530 03:16:55.602222 24924 solver.cpp:228] Iteration 7700, loss = 0.417492
I0530 03:16:55.602260 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 03:16:55.602267 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.23278 (* 1 = 0.23278 loss)
I0530 03:16:55.602270 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.24296 (* 1 = 0.24296 loss)
I0530 03:16:55.602275 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.023798 (* 1 = 0.023798 loss)
I0530 03:16:55.602280 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0506905 (* 1 = 0.0506905 loss)
I0530 03:16:55.602285 24924 sgd_solver.cpp:106] Iteration 7700, lr = 0.0002
I0530 03:17:44.177884 24924 solver.cpp:228] Iteration 7720, loss = 0.293601
I0530 03:17:44.177919 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 03:17:44.177927 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0240732 (* 1 = 0.0240732 loss)
I0530 03:17:44.177930 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109284 (* 1 = 0.109284 loss)
I0530 03:17:44.177934 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0227411 (* 1 = 0.0227411 loss)
I0530 03:17:44.177939 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00872777 (* 1 = 0.00872777 loss)
I0530 03:17:44.177945 24924 sgd_solver.cpp:106] Iteration 7720, lr = 0.0002
I0530 03:18:32.756326 24924 solver.cpp:228] Iteration 7740, loss = 0.330798
I0530 03:18:32.756362 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:18:32.756369 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0894292 (* 1 = 0.0894292 loss)
I0530 03:18:32.756373 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.228725 (* 1 = 0.228725 loss)
I0530 03:18:32.756376 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00928225 (* 1 = 0.00928225 loss)
I0530 03:18:32.756381 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0238476 (* 1 = 0.0238476 loss)
I0530 03:18:32.756384 24924 sgd_solver.cpp:106] Iteration 7740, lr = 0.0002
I0530 03:19:21.302902 24924 solver.cpp:228] Iteration 7760, loss = 0.342819
I0530 03:19:21.302938 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 03:19:21.302944 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00455974 (* 1 = 0.00455974 loss)
I0530 03:19:21.302949 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0694776 (* 1 = 0.0694776 loss)
I0530 03:19:21.302953 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0514611 (* 1 = 0.0514611 loss)
I0530 03:19:21.302955 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00944376 (* 1 = 0.00944376 loss)
I0530 03:19:21.302960 24924 sgd_solver.cpp:106] Iteration 7760, lr = 0.0002
I0530 03:20:09.906975 24924 solver.cpp:228] Iteration 7780, loss = 0.628677
I0530 03:20:09.907011 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:20:09.907018 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707357 (* 1 = 0.0707357 loss)
I0530 03:20:09.907022 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.236086 (* 1 = 0.236086 loss)
I0530 03:20:09.907025 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262239 (* 1 = 0.0262239 loss)
I0530 03:20:09.907028 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196588 (* 1 = 0.0196588 loss)
I0530 03:20:09.907032 24924 sgd_solver.cpp:106] Iteration 7780, lr = 0.0002
speed: 2.439s / iter
I0530 03:20:58.536006 24924 solver.cpp:228] Iteration 7800, loss = 0.294473
I0530 03:20:58.536041 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 03:20:58.536048 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.141374 (* 1 = 0.141374 loss)
I0530 03:20:58.536052 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.15755 (* 1 = 0.15755 loss)
I0530 03:20:58.536056 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00633276 (* 1 = 0.00633276 loss)
I0530 03:20:58.536059 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310022 (* 1 = 0.0310022 loss)
I0530 03:20:58.536063 24924 sgd_solver.cpp:106] Iteration 7800, lr = 0.0002
I0530 03:21:47.124346 24924 solver.cpp:228] Iteration 7820, loss = 0.32649
I0530 03:21:47.124368 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 03:21:47.124389 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.281917 (* 1 = 0.281917 loss)
I0530 03:21:47.124393 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.251257 (* 1 = 0.251257 loss)
I0530 03:21:47.124397 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00456395 (* 1 = 0.00456395 loss)
I0530 03:21:47.124399 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0605254 (* 1 = 0.0605254 loss)
I0530 03:21:47.124404 24924 sgd_solver.cpp:106] Iteration 7820, lr = 0.0002
I0530 03:22:35.708266 24924 solver.cpp:228] Iteration 7840, loss = 0.49156
I0530 03:22:35.708302 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 03:22:35.708307 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526184 (* 1 = 0.0526184 loss)
I0530 03:22:35.708312 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127454 (* 1 = 0.127454 loss)
I0530 03:22:35.708314 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00706279 (* 1 = 0.00706279 loss)
I0530 03:22:35.708317 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00744362 (* 1 = 0.00744362 loss)
I0530 03:22:35.708323 24924 sgd_solver.cpp:106] Iteration 7840, lr = 0.0002
I0530 03:23:24.232338 24924 solver.cpp:228] Iteration 7860, loss = 0.371728
I0530 03:23:24.232375 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 03:23:24.232383 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.123191 (* 1 = 0.123191 loss)
I0530 03:23:24.232385 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.195798 (* 1 = 0.195798 loss)
I0530 03:23:24.232389 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144395 (* 1 = 0.0144395 loss)
I0530 03:23:24.232393 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218287 (* 1 = 0.0218287 loss)
I0530 03:23:24.232396 24924 sgd_solver.cpp:106] Iteration 7860, lr = 0.0002
I0530 03:24:12.776304 24924 solver.cpp:228] Iteration 7880, loss = 0.613585
I0530 03:24:12.776338 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.460938
I0530 03:24:12.776345 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.874716 (* 1 = 0.874716 loss)
I0530 03:24:12.776348 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.780505 (* 1 = 0.780505 loss)
I0530 03:24:12.776351 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.205077 (* 1 = 0.205077 loss)
I0530 03:24:12.776355 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.898896 (* 1 = 0.898896 loss)
I0530 03:24:12.776360 24924 sgd_solver.cpp:106] Iteration 7880, lr = 0.0002
I0530 03:25:01.358484 24924 solver.cpp:228] Iteration 7900, loss = 0.329322
I0530 03:25:01.358506 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 03:25:01.358527 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000761344 (* 1 = 0.000761344 loss)
I0530 03:25:01.358530 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0396322 (* 1 = 0.0396322 loss)
I0530 03:25:01.358534 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00496098 (* 1 = 0.00496098 loss)
I0530 03:25:01.358537 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0459629 (* 1 = 0.0459629 loss)
I0530 03:25:01.358541 24924 sgd_solver.cpp:106] Iteration 7900, lr = 0.0002
I0530 03:25:49.950965 24924 solver.cpp:228] Iteration 7920, loss = 0.380059
I0530 03:25:49.951000 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 03:25:49.951007 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0849343 (* 1 = 0.0849343 loss)
I0530 03:25:49.951011 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.170115 (* 1 = 0.170115 loss)
I0530 03:25:49.951014 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109891 (* 1 = 0.0109891 loss)
I0530 03:25:49.951017 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0310473 (* 1 = 0.0310473 loss)
I0530 03:25:49.951021 24924 sgd_solver.cpp:106] Iteration 7920, lr = 0.0002
I0530 03:26:38.568243 24924 solver.cpp:228] Iteration 7940, loss = 0.434538
I0530 03:26:38.568267 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 03:26:38.568274 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.275833 (* 1 = 0.275833 loss)
I0530 03:26:38.568279 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.438172 (* 1 = 0.438172 loss)
I0530 03:26:38.568282 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136764 (* 1 = 0.0136764 loss)
I0530 03:26:38.568285 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0780548 (* 1 = 0.0780548 loss)
I0530 03:26:38.568289 24924 sgd_solver.cpp:106] Iteration 7940, lr = 0.0002
I0530 03:27:27.182876 24924 solver.cpp:228] Iteration 7960, loss = 0.293624
I0530 03:27:27.182899 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 03:27:27.182920 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.05402 (* 1 = 0.05402 loss)
I0530 03:27:27.182924 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.069213 (* 1 = 0.069213 loss)
I0530 03:27:27.182926 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00263185 (* 1 = 0.00263185 loss)
I0530 03:27:27.182930 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258184 (* 1 = 0.0258184 loss)
I0530 03:27:27.182934 24924 sgd_solver.cpp:106] Iteration 7960, lr = 0.0002
I0530 03:28:15.810492 24924 solver.cpp:228] Iteration 7980, loss = 0.426743
I0530 03:28:15.810528 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 03:28:15.810534 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0030568 (* 1 = 0.0030568 loss)
I0530 03:28:15.810539 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0992823 (* 1 = 0.0992823 loss)
I0530 03:28:15.810541 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0216688 (* 1 = 0.0216688 loss)
I0530 03:28:15.810544 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.205956 (* 1 = 0.205956 loss)
I0530 03:28:15.810549 24924 sgd_solver.cpp:106] Iteration 7980, lr = 0.0002
speed: 2.439s / iter
I0530 03:29:04.373328 24924 solver.cpp:228] Iteration 8000, loss = 0.257153
I0530 03:29:04.373364 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:29:04.373371 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0974481 (* 1 = 0.0974481 loss)
I0530 03:29:04.373375 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.137148 (* 1 = 0.137148 loss)
I0530 03:29:04.373378 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00941385 (* 1 = 0.00941385 loss)
I0530 03:29:04.373381 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0921327 (* 1 = 0.0921327 loss)
I0530 03:29:04.373386 24924 sgd_solver.cpp:106] Iteration 8000, lr = 0.0002
I0530 03:29:52.928184 24924 solver.cpp:228] Iteration 8020, loss = 0.273522
I0530 03:29:52.928218 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 03:29:52.928225 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.212197 (* 1 = 0.212197 loss)
I0530 03:29:52.928227 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.36775 (* 1 = 0.36775 loss)
I0530 03:29:52.928231 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255416 (* 1 = 0.0255416 loss)
I0530 03:29:52.928234 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0353295 (* 1 = 0.0353295 loss)
I0530 03:29:52.928239 24924 sgd_solver.cpp:106] Iteration 8020, lr = 0.0002
I0530 03:30:41.473470 24924 solver.cpp:228] Iteration 8040, loss = 0.418726
I0530 03:30:41.473507 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 03:30:41.473513 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.213887 (* 1 = 0.213887 loss)
I0530 03:30:41.473517 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.329226 (* 1 = 0.329226 loss)
I0530 03:30:41.473520 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342439 (* 1 = 0.0342439 loss)
I0530 03:30:41.473523 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0679482 (* 1 = 0.0679482 loss)
I0530 03:30:41.473527 24924 sgd_solver.cpp:106] Iteration 8040, lr = 0.0002
I0530 03:31:30.107810 24924 solver.cpp:228] Iteration 8060, loss = 0.257353
I0530 03:31:30.107846 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:31:30.107852 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0919285 (* 1 = 0.0919285 loss)
I0530 03:31:30.107856 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.137125 (* 1 = 0.137125 loss)
I0530 03:31:30.107859 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0072572 (* 1 = 0.0072572 loss)
I0530 03:31:30.107862 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0073515 (* 1 = 0.0073515 loss)
I0530 03:31:30.107867 24924 sgd_solver.cpp:106] Iteration 8060, lr = 0.0002
I0530 03:32:18.701805 24924 solver.cpp:228] Iteration 8080, loss = 0.417273
I0530 03:32:18.701839 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 03:32:18.701846 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.133645 (* 1 = 0.133645 loss)
I0530 03:32:18.701850 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291813 (* 1 = 0.291813 loss)
I0530 03:32:18.701853 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0297764 (* 1 = 0.0297764 loss)
I0530 03:32:18.701856 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0803699 (* 1 = 0.0803699 loss)
I0530 03:32:18.701860 24924 sgd_solver.cpp:106] Iteration 8080, lr = 0.0002
I0530 03:33:07.302546 24924 solver.cpp:228] Iteration 8100, loss = 0.279905
I0530 03:33:07.302580 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 03:33:07.302587 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442225 (* 1 = 0.0442225 loss)
I0530 03:33:07.302592 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0912533 (* 1 = 0.0912533 loss)
I0530 03:33:07.302595 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00991168 (* 1 = 0.00991168 loss)
I0530 03:33:07.302598 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163739 (* 1 = 0.0163739 loss)
I0530 03:33:07.302603 24924 sgd_solver.cpp:106] Iteration 8100, lr = 0.0002
I0530 03:33:55.904273 24924 solver.cpp:228] Iteration 8120, loss = 0.327458
I0530 03:33:55.904307 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:33:55.904314 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0762092 (* 1 = 0.0762092 loss)
I0530 03:33:55.904319 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.119586 (* 1 = 0.119586 loss)
I0530 03:33:55.904321 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00579895 (* 1 = 0.00579895 loss)
I0530 03:33:55.904325 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139958 (* 1 = 0.0139958 loss)
I0530 03:33:55.904328 24924 sgd_solver.cpp:106] Iteration 8120, lr = 0.0002
I0530 03:34:44.482085 24924 solver.cpp:228] Iteration 8140, loss = 0.319064
I0530 03:34:44.482122 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 03:34:44.482129 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.117627 (* 1 = 0.117627 loss)
I0530 03:34:44.482132 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.200139 (* 1 = 0.200139 loss)
I0530 03:34:44.482136 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00687458 (* 1 = 0.00687458 loss)
I0530 03:34:44.482139 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0657741 (* 1 = 0.0657741 loss)
I0530 03:34:44.482143 24924 sgd_solver.cpp:106] Iteration 8140, lr = 0.0002
I0530 03:35:33.049098 24924 solver.cpp:228] Iteration 8160, loss = 0.289532
I0530 03:35:33.049135 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 03:35:33.049141 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0712491 (* 1 = 0.0712491 loss)
I0530 03:35:33.049145 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144463 (* 1 = 0.144463 loss)
I0530 03:35:33.049149 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00606759 (* 1 = 0.00606759 loss)
I0530 03:35:33.049151 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00974067 (* 1 = 0.00974067 loss)
I0530 03:35:33.049156 24924 sgd_solver.cpp:106] Iteration 8160, lr = 0.0002
I0530 03:36:21.587512 24924 solver.cpp:228] Iteration 8180, loss = 0.294171
I0530 03:36:21.587548 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:36:21.587555 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.100239 (* 1 = 0.100239 loss)
I0530 03:36:21.587559 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145003 (* 1 = 0.145003 loss)
I0530 03:36:21.587563 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511374 (* 1 = 0.00511374 loss)
I0530 03:36:21.587566 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243041 (* 1 = 0.0243041 loss)
I0530 03:36:21.587570 24924 sgd_solver.cpp:106] Iteration 8180, lr = 0.0002
speed: 2.439s / iter
I0530 03:37:10.167992 24924 solver.cpp:228] Iteration 8200, loss = 0.381042
I0530 03:37:10.168026 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 03:37:10.168033 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.188758 (* 1 = 0.188758 loss)
I0530 03:37:10.168036 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.319965 (* 1 = 0.319965 loss)
I0530 03:37:10.168040 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101719 (* 1 = 0.0101719 loss)
I0530 03:37:10.168042 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0443406 (* 1 = 0.0443406 loss)
I0530 03:37:10.168047 24924 sgd_solver.cpp:106] Iteration 8200, lr = 0.0002
I0530 03:37:58.723846 24924 solver.cpp:228] Iteration 8220, loss = 0.360472
I0530 03:37:58.723881 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:37:58.723889 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739209 (* 1 = 0.0739209 loss)
I0530 03:37:58.723892 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134719 (* 1 = 0.134719 loss)
I0530 03:37:58.723896 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00804694 (* 1 = 0.00804694 loss)
I0530 03:37:58.723898 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123977 (* 1 = 0.0123977 loss)
I0530 03:37:58.723903 24924 sgd_solver.cpp:106] Iteration 8220, lr = 0.0002
I0530 03:38:47.306012 24924 solver.cpp:228] Iteration 8240, loss = 0.346719
I0530 03:38:47.306035 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 03:38:47.306041 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.037063 (* 1 = 0.037063 loss)
I0530 03:38:47.306046 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.23683 (* 1 = 0.23683 loss)
I0530 03:38:47.306048 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00538058 (* 1 = 0.00538058 loss)
I0530 03:38:47.306051 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198381 (* 1 = 0.0198381 loss)
I0530 03:38:47.306056 24924 sgd_solver.cpp:106] Iteration 8240, lr = 0.0002
I0530 03:39:35.947504 24924 solver.cpp:228] Iteration 8260, loss = 0.406194
I0530 03:39:35.947540 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 03:39:35.947546 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.141735 (* 1 = 0.141735 loss)
I0530 03:39:35.947549 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.24602 (* 1 = 0.24602 loss)
I0530 03:39:35.947553 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016117 (* 1 = 0.016117 loss)
I0530 03:39:35.947556 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0684024 (* 1 = 0.0684024 loss)
I0530 03:39:35.947561 24924 sgd_solver.cpp:106] Iteration 8260, lr = 0.0002
I0530 03:40:24.647898 24924 solver.cpp:228] Iteration 8280, loss = 0.335028
I0530 03:40:24.647935 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 03:40:24.647943 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0320661 (* 1 = 0.0320661 loss)
I0530 03:40:24.647945 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.11506 (* 1 = 0.11506 loss)
I0530 03:40:24.647948 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00472609 (* 1 = 0.00472609 loss)
I0530 03:40:24.647953 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00617009 (* 1 = 0.00617009 loss)
I0530 03:40:24.647956 24924 sgd_solver.cpp:106] Iteration 8280, lr = 0.0002
I0530 03:41:13.381675 24924 solver.cpp:228] Iteration 8300, loss = 0.507121
I0530 03:41:13.381724 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:41:13.381732 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628877 (* 1 = 0.0628877 loss)
I0530 03:41:13.381736 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0983008 (* 1 = 0.0983008 loss)
I0530 03:41:13.381739 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142642 (* 1 = 0.0142642 loss)
I0530 03:41:13.381742 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00843206 (* 1 = 0.00843206 loss)
I0530 03:41:13.381747 24924 sgd_solver.cpp:106] Iteration 8300, lr = 0.0002
I0530 03:42:02.085680 24924 solver.cpp:228] Iteration 8320, loss = 0.30483
I0530 03:42:02.085705 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 03:42:02.085711 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.105362 (* 1 = 0.105362 loss)
I0530 03:42:02.085716 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.299941 (* 1 = 0.299941 loss)
I0530 03:42:02.085719 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161749 (* 1 = 0.0161749 loss)
I0530 03:42:02.085722 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0410972 (* 1 = 0.0410972 loss)
I0530 03:42:02.085726 24924 sgd_solver.cpp:106] Iteration 8320, lr = 0.0002
I0530 03:42:50.842087 24924 solver.cpp:228] Iteration 8340, loss = 0.748204
I0530 03:42:50.842110 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:42:50.842116 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.107453 (* 1 = 0.107453 loss)
I0530 03:42:50.842120 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.177171 (* 1 = 0.177171 loss)
I0530 03:42:50.842125 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382389 (* 1 = 0.00382389 loss)
I0530 03:42:50.842128 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145445 (* 1 = 0.0145445 loss)
I0530 03:42:50.842133 24924 sgd_solver.cpp:106] Iteration 8340, lr = 0.0002
I0530 03:43:39.634814 24924 solver.cpp:228] Iteration 8360, loss = 0.7609
I0530 03:43:39.634850 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 03:43:39.634857 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.270004 (* 1 = 0.270004 loss)
I0530 03:43:39.634861 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.371779 (* 1 = 0.371779 loss)
I0530 03:43:39.634865 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0638264 (* 1 = 0.0638264 loss)
I0530 03:43:39.634867 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.22321 (* 1 = 0.22321 loss)
I0530 03:43:39.634871 24924 sgd_solver.cpp:106] Iteration 8360, lr = 0.0002
I0530 03:44:28.453598 24924 solver.cpp:228] Iteration 8380, loss = 0.287248
I0530 03:44:28.453634 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 03:44:28.453640 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0958178 (* 1 = 0.0958178 loss)
I0530 03:44:28.453644 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.120105 (* 1 = 0.120105 loss)
I0530 03:44:28.453647 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296726 (* 1 = 0.00296726 loss)
I0530 03:44:28.453650 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149629 (* 1 = 0.0149629 loss)
I0530 03:44:28.453655 24924 sgd_solver.cpp:106] Iteration 8380, lr = 0.0002
speed: 2.439s / iter
I0530 03:45:17.179711 24924 solver.cpp:228] Iteration 8400, loss = 0.286406
I0530 03:45:17.179749 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 03:45:17.179756 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.181164 (* 1 = 0.181164 loss)
I0530 03:45:17.179760 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.377515 (* 1 = 0.377515 loss)
I0530 03:45:17.179764 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169795 (* 1 = 0.0169795 loss)
I0530 03:45:17.179767 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0721153 (* 1 = 0.0721153 loss)
I0530 03:45:17.179771 24924 sgd_solver.cpp:106] Iteration 8400, lr = 0.0002
I0530 03:46:06.007189 24924 solver.cpp:228] Iteration 8420, loss = 0.270448
I0530 03:46:06.007225 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:46:06.007233 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391777 (* 1 = 0.0391777 loss)
I0530 03:46:06.007237 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.163211 (* 1 = 0.163211 loss)
I0530 03:46:06.007241 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0172963 (* 1 = 0.0172963 loss)
I0530 03:46:06.007243 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600115 (* 1 = 0.0600115 loss)
I0530 03:46:06.007248 24924 sgd_solver.cpp:106] Iteration 8420, lr = 0.0002
I0530 03:46:54.758384 24924 solver.cpp:228] Iteration 8440, loss = 0.305812
I0530 03:46:54.758409 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 03:46:54.758414 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485848 (* 1 = 0.0485848 loss)
I0530 03:46:54.758419 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0533637 (* 1 = 0.0533637 loss)
I0530 03:46:54.758422 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00563401 (* 1 = 0.00563401 loss)
I0530 03:46:54.758426 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00864446 (* 1 = 0.00864446 loss)
I0530 03:46:54.758430 24924 sgd_solver.cpp:106] Iteration 8440, lr = 0.0002
I0530 03:47:43.551337 24924 solver.cpp:228] Iteration 8460, loss = 0.381957
I0530 03:47:43.551373 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 03:47:43.551380 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.157602 (* 1 = 0.157602 loss)
I0530 03:47:43.551384 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.325507 (* 1 = 0.325507 loss)
I0530 03:47:43.551388 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00607025 (* 1 = 0.00607025 loss)
I0530 03:47:43.551390 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217617 (* 1 = 0.0217617 loss)
I0530 03:47:43.551395 24924 sgd_solver.cpp:106] Iteration 8460, lr = 0.0002
I0530 03:48:32.396826 24924 solver.cpp:228] Iteration 8480, loss = 0.398794
I0530 03:48:32.396862 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 03:48:32.396868 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.132458 (* 1 = 0.132458 loss)
I0530 03:48:32.396872 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.252357 (* 1 = 0.252357 loss)
I0530 03:48:32.396876 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138813 (* 1 = 0.0138813 loss)
I0530 03:48:32.396879 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0211265 (* 1 = 0.0211265 loss)
I0530 03:48:32.396883 24924 sgd_solver.cpp:106] Iteration 8480, lr = 0.0002
I0530 03:49:21.125306 24924 solver.cpp:228] Iteration 8500, loss = 0.377357
I0530 03:49:21.125342 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 03:49:21.125349 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.233983 (* 1 = 0.233983 loss)
I0530 03:49:21.125352 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.223624 (* 1 = 0.223624 loss)
I0530 03:49:21.125356 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0113733 (* 1 = 0.0113733 loss)
I0530 03:49:21.125360 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0350043 (* 1 = 0.0350043 loss)
I0530 03:49:21.125363 24924 sgd_solver.cpp:106] Iteration 8500, lr = 0.0002
I0530 03:50:09.883365 24924 solver.cpp:228] Iteration 8520, loss = 0.463396
I0530 03:50:09.883400 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 03:50:09.883406 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.111834 (* 1 = 0.111834 loss)
I0530 03:50:09.883410 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.283684 (* 1 = 0.283684 loss)
I0530 03:50:09.883414 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00462346 (* 1 = 0.00462346 loss)
I0530 03:50:09.883417 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0307169 (* 1 = 0.0307169 loss)
I0530 03:50:09.883421 24924 sgd_solver.cpp:106] Iteration 8520, lr = 0.0002
I0530 03:50:58.621181 24924 solver.cpp:228] Iteration 8540, loss = 0.339142
I0530 03:50:58.621217 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:50:58.621225 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536724 (* 1 = 0.0536724 loss)
I0530 03:50:58.621228 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.17907 (* 1 = 0.17907 loss)
I0530 03:50:58.621232 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012354 (* 1 = 0.012354 loss)
I0530 03:50:58.621234 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0223337 (* 1 = 0.0223337 loss)
I0530 03:50:58.621239 24924 sgd_solver.cpp:106] Iteration 8540, lr = 0.0002
I0530 03:51:47.377493 24924 solver.cpp:228] Iteration 8560, loss = 0.351999
I0530 03:51:47.377528 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 03:51:47.377535 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0331112 (* 1 = 0.0331112 loss)
I0530 03:51:47.377539 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.110719 (* 1 = 0.110719 loss)
I0530 03:51:47.377543 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00875577 (* 1 = 0.00875577 loss)
I0530 03:51:47.377547 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00613983 (* 1 = 0.00613983 loss)
I0530 03:51:47.377550 24924 sgd_solver.cpp:106] Iteration 8560, lr = 0.0002
I0530 03:52:36.121253 24924 solver.cpp:228] Iteration 8580, loss = 0.325101
I0530 03:52:36.121289 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 03:52:36.121296 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381073 (* 1 = 0.0381073 loss)
I0530 03:52:36.121300 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0880537 (* 1 = 0.0880537 loss)
I0530 03:52:36.121304 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00522702 (* 1 = 0.00522702 loss)
I0530 03:52:36.121306 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00619425 (* 1 = 0.00619425 loss)
I0530 03:52:36.121311 24924 sgd_solver.cpp:106] Iteration 8580, lr = 0.0002
speed: 2.439s / iter
I0530 03:53:24.812386 24924 solver.cpp:228] Iteration 8600, loss = 0.405531
I0530 03:53:24.812407 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 03:53:24.812428 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00103563 (* 1 = 0.00103563 loss)
I0530 03:53:24.812431 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0307533 (* 1 = 0.0307533 loss)
I0530 03:53:24.812434 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00837379 (* 1 = 0.00837379 loss)
I0530 03:53:24.812438 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0277672 (* 1 = 0.0277672 loss)
I0530 03:53:24.812443 24924 sgd_solver.cpp:106] Iteration 8600, lr = 0.0002
I0530 03:54:13.468224 24924 solver.cpp:228] Iteration 8620, loss = 0.306994
I0530 03:54:13.468260 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 03:54:13.468266 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.070479 (* 1 = 0.070479 loss)
I0530 03:54:13.468271 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.218239 (* 1 = 0.218239 loss)
I0530 03:54:13.468273 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073706 (* 1 = 0.0073706 loss)
I0530 03:54:13.468276 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303602 (* 1 = 0.0303602 loss)
I0530 03:54:13.468281 24924 sgd_solver.cpp:106] Iteration 8620, lr = 0.0002
I0530 03:55:02.180069 24924 solver.cpp:228] Iteration 8640, loss = 0.312433
I0530 03:55:02.180105 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 03:55:02.180111 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.118101 (* 1 = 0.118101 loss)
I0530 03:55:02.180115 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.228737 (* 1 = 0.228737 loss)
I0530 03:55:02.180119 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0224063 (* 1 = 0.0224063 loss)
I0530 03:55:02.180122 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0106168 (* 1 = 0.0106168 loss)
I0530 03:55:02.180126 24924 sgd_solver.cpp:106] Iteration 8640, lr = 0.0002
I0530 03:55:50.897725 24924 solver.cpp:228] Iteration 8660, loss = 0.298653
I0530 03:55:50.897760 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 03:55:50.897768 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.124904 (* 1 = 0.124904 loss)
I0530 03:55:50.897771 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.223896 (* 1 = 0.223896 loss)
I0530 03:55:50.897775 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0143357 (* 1 = 0.0143357 loss)
I0530 03:55:50.897778 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247762 (* 1 = 0.0247762 loss)
I0530 03:55:50.897783 24924 sgd_solver.cpp:106] Iteration 8660, lr = 0.0002
I0530 03:56:39.601068 24924 solver.cpp:228] Iteration 8680, loss = 0.297077
I0530 03:56:39.601104 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 03:56:39.601111 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00261435 (* 1 = 0.00261435 loss)
I0530 03:56:39.601114 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0628944 (* 1 = 0.0628944 loss)
I0530 03:56:39.601117 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424114 (* 1 = 0.00424114 loss)
I0530 03:56:39.601121 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189522 (* 1 = 0.0189522 loss)
I0530 03:56:39.601125 24924 sgd_solver.cpp:106] Iteration 8680, lr = 0.0002
I0530 03:57:28.270364 24924 solver.cpp:228] Iteration 8700, loss = 0.378042
I0530 03:57:28.270400 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0530 03:57:28.270407 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.393483 (* 1 = 0.393483 loss)
I0530 03:57:28.270411 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.509442 (* 1 = 0.509442 loss)
I0530 03:57:28.270414 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0515765 (* 1 = 0.0515765 loss)
I0530 03:57:28.270417 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12116 (* 1 = 0.12116 loss)
I0530 03:57:28.270422 24924 sgd_solver.cpp:106] Iteration 8700, lr = 0.0002
I0530 03:58:16.964112 24924 solver.cpp:228] Iteration 8720, loss = 0.558344
I0530 03:58:16.964148 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 03:58:16.964155 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.223445 (* 1 = 0.223445 loss)
I0530 03:58:16.964159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.319112 (* 1 = 0.319112 loss)
I0530 03:58:16.964164 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109545 (* 1 = 0.0109545 loss)
I0530 03:58:16.964166 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0580428 (* 1 = 0.0580428 loss)
I0530 03:58:16.964171 24924 sgd_solver.cpp:106] Iteration 8720, lr = 0.0002
I0530 03:59:05.658727 24924 solver.cpp:228] Iteration 8740, loss = 0.236601
I0530 03:59:05.658751 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 03:59:05.658757 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0538575 (* 1 = 0.0538575 loss)
I0530 03:59:05.658761 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123925 (* 1 = 0.123925 loss)
I0530 03:59:05.658766 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00151099 (* 1 = 0.00151099 loss)
I0530 03:59:05.658768 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00732264 (* 1 = 0.00732264 loss)
I0530 03:59:05.658772 24924 sgd_solver.cpp:106] Iteration 8740, lr = 0.0002
I0530 03:59:54.265815 24924 solver.cpp:228] Iteration 8760, loss = 0.256356
I0530 03:59:54.265851 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 03:59:54.265858 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0276646 (* 1 = 0.0276646 loss)
I0530 03:59:54.265861 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113412 (* 1 = 0.113412 loss)
I0530 03:59:54.265866 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604764 (* 1 = 0.00604764 loss)
I0530 03:59:54.265868 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0447561 (* 1 = 0.0447561 loss)
I0530 03:59:54.265872 24924 sgd_solver.cpp:106] Iteration 8760, lr = 0.0002
I0530 04:00:42.887671 24924 solver.cpp:228] Iteration 8780, loss = 0.531336
I0530 04:00:42.887694 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 04:00:42.887701 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0417114 (* 1 = 0.0417114 loss)
I0530 04:00:42.887706 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0712811 (* 1 = 0.0712811 loss)
I0530 04:00:42.887708 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126486 (* 1 = 0.0126486 loss)
I0530 04:00:42.887712 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0088949 (* 1 = 0.0088949 loss)
I0530 04:00:42.887717 24924 sgd_solver.cpp:106] Iteration 8780, lr = 0.0002
speed: 2.439s / iter
I0530 04:01:31.438524 24924 solver.cpp:228] Iteration 8800, loss = 0.347831
I0530 04:01:31.438545 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 04:01:31.438554 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.129095 (* 1 = 0.129095 loss)
I0530 04:01:31.438557 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.269567 (* 1 = 0.269567 loss)
I0530 04:01:31.438560 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104582 (* 1 = 0.0104582 loss)
I0530 04:01:31.438563 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0482564 (* 1 = 0.0482564 loss)
I0530 04:01:31.438567 24924 sgd_solver.cpp:106] Iteration 8800, lr = 0.0002
I0530 04:02:19.936661 24924 solver.cpp:228] Iteration 8820, loss = 0.286025
I0530 04:02:19.936697 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:02:19.936703 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0539611 (* 1 = 0.0539611 loss)
I0530 04:02:19.936707 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0983553 (* 1 = 0.0983553 loss)
I0530 04:02:19.936710 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0030888 (* 1 = 0.0030888 loss)
I0530 04:02:19.936713 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163155 (* 1 = 0.0163155 loss)
I0530 04:02:19.936718 24924 sgd_solver.cpp:106] Iteration 8820, lr = 0.0002
I0530 04:03:08.462324 24924 solver.cpp:228] Iteration 8840, loss = 0.316213
I0530 04:03:08.462359 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 04:03:08.462365 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.140615 (* 1 = 0.140615 loss)
I0530 04:03:08.462369 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.263238 (* 1 = 0.263238 loss)
I0530 04:03:08.462373 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111515 (* 1 = 0.0111515 loss)
I0530 04:03:08.462375 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240729 (* 1 = 0.0240729 loss)
I0530 04:03:08.462380 24924 sgd_solver.cpp:106] Iteration 8840, lr = 0.0002
I0530 04:03:57.028281 24924 solver.cpp:228] Iteration 8860, loss = 0.399298
I0530 04:03:57.028317 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 04:03:57.028324 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843818 (* 1 = 0.0843818 loss)
I0530 04:03:57.028328 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.310969 (* 1 = 0.310969 loss)
I0530 04:03:57.028331 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189556 (* 1 = 0.0189556 loss)
I0530 04:03:57.028334 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200569 (* 1 = 0.0200569 loss)
I0530 04:03:57.028339 24924 sgd_solver.cpp:106] Iteration 8860, lr = 0.0002
I0530 04:04:45.496588 24924 solver.cpp:228] Iteration 8880, loss = 0.281321
I0530 04:04:45.496625 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 04:04:45.496634 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0334633 (* 1 = 0.0334633 loss)
I0530 04:04:45.496637 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117564 (* 1 = 0.117564 loss)
I0530 04:04:45.496640 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00433897 (* 1 = 0.00433897 loss)
I0530 04:04:45.496644 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143399 (* 1 = 0.0143399 loss)
I0530 04:04:45.496647 24924 sgd_solver.cpp:106] Iteration 8880, lr = 0.0002
I0530 04:05:33.987828 24924 solver.cpp:228] Iteration 8900, loss = 0.566933
I0530 04:05:33.987849 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 04:05:33.987869 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00227521 (* 1 = 0.00227521 loss)
I0530 04:05:33.987874 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0823416 (* 1 = 0.0823416 loss)
I0530 04:05:33.987876 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137954 (* 1 = 0.0137954 loss)
I0530 04:05:33.987879 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0444036 (* 1 = 0.0444036 loss)
I0530 04:05:33.987884 24924 sgd_solver.cpp:106] Iteration 8900, lr = 0.0002
I0530 04:06:22.480576 24924 solver.cpp:228] Iteration 8920, loss = 0.333542
I0530 04:06:22.480612 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 04:06:22.480619 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.226795 (* 1 = 0.226795 loss)
I0530 04:06:22.480623 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.36521 (* 1 = 0.36521 loss)
I0530 04:06:22.480626 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00868982 (* 1 = 0.00868982 loss)
I0530 04:06:22.480629 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280695 (* 1 = 0.0280695 loss)
I0530 04:06:22.480633 24924 sgd_solver.cpp:106] Iteration 8920, lr = 0.0002
I0530 04:07:10.930572 24924 solver.cpp:228] Iteration 8940, loss = 0.362342
I0530 04:07:10.930608 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0530 04:07:10.930615 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.257646 (* 1 = 0.257646 loss)
I0530 04:07:10.930619 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.512745 (* 1 = 0.512745 loss)
I0530 04:07:10.930622 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011192 (* 1 = 0.011192 loss)
I0530 04:07:10.930625 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0400317 (* 1 = 0.0400317 loss)
I0530 04:07:10.930629 24924 sgd_solver.cpp:106] Iteration 8940, lr = 0.0002
I0530 04:07:59.473284 24924 solver.cpp:228] Iteration 8960, loss = 0.352512
I0530 04:07:59.473320 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 04:07:59.473325 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0698978 (* 1 = 0.0698978 loss)
I0530 04:07:59.473330 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0718928 (* 1 = 0.0718928 loss)
I0530 04:07:59.473332 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161583 (* 1 = 0.0161583 loss)
I0530 04:07:59.473335 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103523 (* 1 = 0.0103523 loss)
I0530 04:07:59.473340 24924 sgd_solver.cpp:106] Iteration 8960, lr = 0.0002
I0530 04:08:47.905412 24924 solver.cpp:228] Iteration 8980, loss = 0.243599
I0530 04:08:47.905449 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 04:08:47.905457 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0974461 (* 1 = 0.0974461 loss)
I0530 04:08:47.905460 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.294628 (* 1 = 0.294628 loss)
I0530 04:08:47.905464 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713603 (* 1 = 0.00713603 loss)
I0530 04:08:47.905467 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.041065 (* 1 = 0.041065 loss)
I0530 04:08:47.905472 24924 sgd_solver.cpp:106] Iteration 8980, lr = 0.0002
speed: 2.438s / iter
I0530 04:09:36.367411 24924 solver.cpp:228] Iteration 9000, loss = 0.305423
I0530 04:09:36.367449 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 04:09:36.367455 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171672 (* 1 = 0.0171672 loss)
I0530 04:09:36.367460 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0829447 (* 1 = 0.0829447 loss)
I0530 04:09:36.367462 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154126 (* 1 = 0.0154126 loss)
I0530 04:09:36.367465 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137682 (* 1 = 0.0137682 loss)
I0530 04:09:36.367470 24924 sgd_solver.cpp:106] Iteration 9000, lr = 0.0002
I0530 04:10:24.840093 24924 solver.cpp:228] Iteration 9020, loss = 0.555754
I0530 04:10:24.840129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 04:10:24.840137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0598222 (* 1 = 0.0598222 loss)
I0530 04:10:24.840140 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139086 (* 1 = 0.139086 loss)
I0530 04:10:24.840143 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140203 (* 1 = 0.0140203 loss)
I0530 04:10:24.840147 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250152 (* 1 = 0.0250152 loss)
I0530 04:10:24.840152 24924 sgd_solver.cpp:106] Iteration 9020, lr = 0.0002
I0530 04:11:13.299692 24924 solver.cpp:228] Iteration 9040, loss = 0.30026
I0530 04:11:13.299729 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 04:11:13.299736 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675832 (* 1 = 0.0675832 loss)
I0530 04:11:13.299739 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0615801 (* 1 = 0.0615801 loss)
I0530 04:11:13.299743 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012707 (* 1 = 0.0012707 loss)
I0530 04:11:13.299746 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158732 (* 1 = 0.0158732 loss)
I0530 04:11:13.299749 24924 sgd_solver.cpp:106] Iteration 9040, lr = 0.0002
I0530 04:12:01.796613 24924 solver.cpp:228] Iteration 9060, loss = 0.42561
I0530 04:12:01.796649 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 04:12:01.796656 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.12265 (* 1 = 0.12265 loss)
I0530 04:12:01.796660 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.254208 (* 1 = 0.254208 loss)
I0530 04:12:01.796664 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268721 (* 1 = 0.0268721 loss)
I0530 04:12:01.796667 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0977356 (* 1 = 0.0977356 loss)
I0530 04:12:01.796671 24924 sgd_solver.cpp:106] Iteration 9060, lr = 0.0002
I0530 04:12:50.314970 24924 solver.cpp:228] Iteration 9080, loss = 0.702293
I0530 04:12:50.315004 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:12:50.315011 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0787826 (* 1 = 0.0787826 loss)
I0530 04:12:50.315014 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.192205 (* 1 = 0.192205 loss)
I0530 04:12:50.315017 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185465 (* 1 = 0.0185465 loss)
I0530 04:12:50.315021 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260999 (* 1 = 0.0260999 loss)
I0530 04:12:50.315026 24924 sgd_solver.cpp:106] Iteration 9080, lr = 0.0002
I0530 04:13:38.770777 24924 solver.cpp:228] Iteration 9100, loss = 0.270896
I0530 04:13:38.770812 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:13:38.770820 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.039575 (* 1 = 0.039575 loss)
I0530 04:13:38.770823 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.176884 (* 1 = 0.176884 loss)
I0530 04:13:38.770828 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179598 (* 1 = 0.0179598 loss)
I0530 04:13:38.770830 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373584 (* 1 = 0.0373584 loss)
I0530 04:13:38.770834 24924 sgd_solver.cpp:106] Iteration 9100, lr = 0.0002
I0530 04:14:27.274534 24924 solver.cpp:228] Iteration 9120, loss = 0.477554
I0530 04:14:27.274555 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 04:14:27.274562 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.276134 (* 1 = 0.276134 loss)
I0530 04:14:27.274566 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.275687 (* 1 = 0.275687 loss)
I0530 04:14:27.274569 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0346984 (* 1 = 0.0346984 loss)
I0530 04:14:27.274572 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0764686 (* 1 = 0.0764686 loss)
I0530 04:14:27.274576 24924 sgd_solver.cpp:106] Iteration 9120, lr = 0.0002
I0530 04:15:15.752048 24924 solver.cpp:228] Iteration 9140, loss = 0.296262
I0530 04:15:15.752084 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 04:15:15.752090 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.150613 (* 1 = 0.150613 loss)
I0530 04:15:15.752094 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.363742 (* 1 = 0.363742 loss)
I0530 04:15:15.752097 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138613 (* 1 = 0.0138613 loss)
I0530 04:15:15.752100 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351134 (* 1 = 0.0351134 loss)
I0530 04:15:15.752104 24924 sgd_solver.cpp:106] Iteration 9140, lr = 0.0002
I0530 04:16:04.325003 24924 solver.cpp:228] Iteration 9160, loss = 0.538387
I0530 04:16:04.325040 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 04:16:04.325047 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.206159 (* 1 = 0.206159 loss)
I0530 04:16:04.325050 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.486239 (* 1 = 0.486239 loss)
I0530 04:16:04.325053 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0361638 (* 1 = 0.0361638 loss)
I0530 04:16:04.325057 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0777658 (* 1 = 0.0777658 loss)
I0530 04:16:04.325064 24924 sgd_solver.cpp:106] Iteration 9160, lr = 0.0002
I0530 04:16:52.856735 24924 solver.cpp:228] Iteration 9180, loss = 0.426376
I0530 04:16:52.856760 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:16:52.856766 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0416066 (* 1 = 0.0416066 loss)
I0530 04:16:52.856770 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.196242 (* 1 = 0.196242 loss)
I0530 04:16:52.856773 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242836 (* 1 = 0.0242836 loss)
I0530 04:16:52.856777 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214655 (* 1 = 0.0214655 loss)
I0530 04:16:52.856781 24924 sgd_solver.cpp:106] Iteration 9180, lr = 0.0002
speed: 2.438s / iter
I0530 04:17:41.388007 24924 solver.cpp:228] Iteration 9200, loss = 0.284203
I0530 04:17:41.388043 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 04:17:41.388051 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.042478 (* 1 = 0.042478 loss)
I0530 04:17:41.388054 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0571335 (* 1 = 0.0571335 loss)
I0530 04:17:41.388058 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00260075 (* 1 = 0.00260075 loss)
I0530 04:17:41.388061 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137688 (* 1 = 0.0137688 loss)
I0530 04:17:41.388065 24924 sgd_solver.cpp:106] Iteration 9200, lr = 0.0002
I0530 04:18:29.911382 24924 solver.cpp:228] Iteration 9220, loss = 0.240825
I0530 04:18:29.911417 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 04:18:29.911425 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0913081 (* 1 = 0.0913081 loss)
I0530 04:18:29.911428 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.188707 (* 1 = 0.188707 loss)
I0530 04:18:29.911432 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00475685 (* 1 = 0.00475685 loss)
I0530 04:18:29.911435 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370625 (* 1 = 0.0370625 loss)
I0530 04:18:29.911439 24924 sgd_solver.cpp:106] Iteration 9220, lr = 0.0002
I0530 04:19:18.449301 24924 solver.cpp:228] Iteration 9240, loss = 0.399891
I0530 04:19:18.449337 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 04:19:18.449344 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.226633 (* 1 = 0.226633 loss)
I0530 04:19:18.449348 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.353722 (* 1 = 0.353722 loss)
I0530 04:19:18.449352 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00676719 (* 1 = 0.00676719 loss)
I0530 04:19:18.449354 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306295 (* 1 = 0.0306295 loss)
I0530 04:19:18.449359 24924 sgd_solver.cpp:106] Iteration 9240, lr = 0.0002
I0530 04:20:07.033021 24924 solver.cpp:228] Iteration 9260, loss = 0.343411
I0530 04:20:07.033043 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 04:20:07.033052 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0481059 (* 1 = 0.0481059 loss)
I0530 04:20:07.033056 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152948 (* 1 = 0.152948 loss)
I0530 04:20:07.033059 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00936365 (* 1 = 0.00936365 loss)
I0530 04:20:07.033063 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0880801 (* 1 = 0.0880801 loss)
I0530 04:20:07.033068 24924 sgd_solver.cpp:106] Iteration 9260, lr = 0.0002
I0530 04:20:55.585813 24924 solver.cpp:228] Iteration 9280, loss = 0.39274
I0530 04:20:55.585834 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 04:20:55.585841 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0755163 (* 1 = 0.0755163 loss)
I0530 04:20:55.585845 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.110272 (* 1 = 0.110272 loss)
I0530 04:20:55.585850 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00699173 (* 1 = 0.00699173 loss)
I0530 04:20:55.585852 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0056388 (* 1 = 0.0056388 loss)
I0530 04:20:55.585856 24924 sgd_solver.cpp:106] Iteration 9280, lr = 0.0002
I0530 04:21:44.091920 24924 solver.cpp:228] Iteration 9300, loss = 0.426109
I0530 04:21:44.091955 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 04:21:44.091962 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.121618 (* 1 = 0.121618 loss)
I0530 04:21:44.091966 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.215364 (* 1 = 0.215364 loss)
I0530 04:21:44.091970 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674244 (* 1 = 0.00674244 loss)
I0530 04:21:44.091974 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0244242 (* 1 = 0.0244242 loss)
I0530 04:21:44.091977 24924 sgd_solver.cpp:106] Iteration 9300, lr = 0.0002
I0530 04:22:32.623297 24924 solver.cpp:228] Iteration 9320, loss = 0.198793
I0530 04:22:32.623322 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 04:22:32.623328 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0519165 (* 1 = 0.0519165 loss)
I0530 04:22:32.623332 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.116981 (* 1 = 0.116981 loss)
I0530 04:22:32.623337 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485096 (* 1 = 0.00485096 loss)
I0530 04:22:32.623339 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168661 (* 1 = 0.0168661 loss)
I0530 04:22:32.623343 24924 sgd_solver.cpp:106] Iteration 9320, lr = 0.0002
I0530 04:23:21.202832 24924 solver.cpp:228] Iteration 9340, loss = 0.515625
I0530 04:23:21.202867 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 04:23:21.202875 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.02998 (* 1 = 0.02998 loss)
I0530 04:23:21.202878 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.112138 (* 1 = 0.112138 loss)
I0530 04:23:21.202881 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0186359 (* 1 = 0.0186359 loss)
I0530 04:23:21.202885 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00695861 (* 1 = 0.00695861 loss)
I0530 04:23:21.202889 24924 sgd_solver.cpp:106] Iteration 9340, lr = 0.0002
I0530 04:24:09.746873 24924 solver.cpp:228] Iteration 9360, loss = 0.407242
I0530 04:24:09.746909 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:24:09.746917 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0477082 (* 1 = 0.0477082 loss)
I0530 04:24:09.746920 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0772503 (* 1 = 0.0772503 loss)
I0530 04:24:09.746923 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00327459 (* 1 = 0.00327459 loss)
I0530 04:24:09.746927 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0148677 (* 1 = 0.0148677 loss)
I0530 04:24:09.746932 24924 sgd_solver.cpp:106] Iteration 9360, lr = 0.0002
I0530 04:24:58.297106 24924 solver.cpp:228] Iteration 9380, loss = 0.235026
I0530 04:24:58.297142 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 04:24:58.297148 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.10284 (* 1 = 0.10284 loss)
I0530 04:24:58.297152 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.27141 (* 1 = 0.27141 loss)
I0530 04:24:58.297155 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00801058 (* 1 = 0.00801058 loss)
I0530 04:24:58.297158 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0239603 (* 1 = 0.0239603 loss)
I0530 04:24:58.297163 24924 sgd_solver.cpp:106] Iteration 9380, lr = 0.0002
speed: 2.438s / iter
I0530 04:25:46.839496 24924 solver.cpp:228] Iteration 9400, loss = 0.336099
I0530 04:25:46.839519 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 04:25:46.839526 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0372293 (* 1 = 0.0372293 loss)
I0530 04:25:46.839529 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0901038 (* 1 = 0.0901038 loss)
I0530 04:25:46.839532 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00712533 (* 1 = 0.00712533 loss)
I0530 04:25:46.839536 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134887 (* 1 = 0.0134887 loss)
I0530 04:25:46.839540 24924 sgd_solver.cpp:106] Iteration 9400, lr = 0.0002
I0530 04:26:35.386466 24924 solver.cpp:228] Iteration 9420, loss = 0.615677
I0530 04:26:35.386499 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 04:26:35.386507 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0573748 (* 1 = 0.0573748 loss)
I0530 04:26:35.386510 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109978 (* 1 = 0.109978 loss)
I0530 04:26:35.386513 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0043116 (* 1 = 0.0043116 loss)
I0530 04:26:35.386517 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0068318 (* 1 = 0.0068318 loss)
I0530 04:26:35.386520 24924 sgd_solver.cpp:106] Iteration 9420, lr = 0.0002
I0530 04:27:23.944901 24924 solver.cpp:228] Iteration 9440, loss = 0.555373
I0530 04:27:23.944941 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 04:27:23.944947 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0391785 (* 1 = 0.0391785 loss)
I0530 04:27:23.944952 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0582054 (* 1 = 0.0582054 loss)
I0530 04:27:23.944954 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351246 (* 1 = 0.00351246 loss)
I0530 04:27:23.944958 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00758861 (* 1 = 0.00758861 loss)
I0530 04:27:23.944962 24924 sgd_solver.cpp:106] Iteration 9440, lr = 0.0002
I0530 04:28:12.505091 24924 solver.cpp:228] Iteration 9460, loss = 0.394078
I0530 04:28:12.505129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 04:28:12.505137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0263602 (* 1 = 0.0263602 loss)
I0530 04:28:12.505142 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.125484 (* 1 = 0.125484 loss)
I0530 04:28:12.505147 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00883521 (* 1 = 0.00883521 loss)
I0530 04:28:12.505151 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00413359 (* 1 = 0.00413359 loss)
I0530 04:28:12.505156 24924 sgd_solver.cpp:106] Iteration 9460, lr = 0.0002
I0530 04:29:01.045233 24924 solver.cpp:228] Iteration 9480, loss = 0.334948
I0530 04:29:01.045269 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:29:01.045276 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0417372 (* 1 = 0.0417372 loss)
I0530 04:29:01.045279 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101567 (* 1 = 0.101567 loss)
I0530 04:29:01.045284 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00540939 (* 1 = 0.00540939 loss)
I0530 04:29:01.045286 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00431355 (* 1 = 0.00431355 loss)
I0530 04:29:01.045290 24924 sgd_solver.cpp:106] Iteration 9480, lr = 0.0002
I0530 04:29:49.567579 24924 solver.cpp:228] Iteration 9500, loss = 0.41392
I0530 04:29:49.567618 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 04:29:49.567625 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0233071 (* 1 = 0.0233071 loss)
I0530 04:29:49.567629 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145339 (* 1 = 0.145339 loss)
I0530 04:29:49.567632 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0180456 (* 1 = 0.0180456 loss)
I0530 04:29:49.567636 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024464 (* 1 = 0.024464 loss)
I0530 04:29:49.567641 24924 sgd_solver.cpp:106] Iteration 9500, lr = 0.0002
I0530 04:30:38.182968 24924 solver.cpp:228] Iteration 9520, loss = 0.718672
I0530 04:30:38.183006 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 04:30:38.183012 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0439692 (* 1 = 0.0439692 loss)
I0530 04:30:38.183017 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0901054 (* 1 = 0.0901054 loss)
I0530 04:30:38.183019 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253477 (* 1 = 0.00253477 loss)
I0530 04:30:38.183022 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00830487 (* 1 = 0.00830487 loss)
I0530 04:30:38.183027 24924 sgd_solver.cpp:106] Iteration 9520, lr = 0.0002
I0530 04:31:26.739606 24924 solver.cpp:228] Iteration 9540, loss = 0.226742
I0530 04:31:26.739641 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:31:26.739648 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0431378 (* 1 = 0.0431378 loss)
I0530 04:31:26.739652 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133081 (* 1 = 0.133081 loss)
I0530 04:31:26.739655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00158605 (* 1 = 0.00158605 loss)
I0530 04:31:26.739660 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103866 (* 1 = 0.0103866 loss)
I0530 04:31:26.739663 24924 sgd_solver.cpp:106] Iteration 9540, lr = 0.0002
I0530 04:32:15.287267 24924 solver.cpp:228] Iteration 9560, loss = 0.245334
I0530 04:32:15.287303 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 04:32:15.287309 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.194703 (* 1 = 0.194703 loss)
I0530 04:32:15.287312 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.297477 (* 1 = 0.297477 loss)
I0530 04:32:15.287317 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0124636 (* 1 = 0.0124636 loss)
I0530 04:32:15.287319 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0366026 (* 1 = 0.0366026 loss)
I0530 04:32:15.287324 24924 sgd_solver.cpp:106] Iteration 9560, lr = 0.0002
I0530 04:33:03.907953 24924 solver.cpp:228] Iteration 9580, loss = 0.461789
I0530 04:33:03.907987 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 04:33:03.907995 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0754581 (* 1 = 0.0754581 loss)
I0530 04:33:03.907999 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.177722 (* 1 = 0.177722 loss)
I0530 04:33:03.908002 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165353 (* 1 = 0.0165353 loss)
I0530 04:33:03.908005 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128739 (* 1 = 0.0128739 loss)
I0530 04:33:03.908010 24924 sgd_solver.cpp:106] Iteration 9580, lr = 0.0002
speed: 2.438s / iter
I0530 04:33:52.483404 24924 solver.cpp:228] Iteration 9600, loss = 0.394469
I0530 04:33:52.483428 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 04:33:52.483433 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0243553 (* 1 = 0.0243553 loss)
I0530 04:33:52.483438 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0558102 (* 1 = 0.0558102 loss)
I0530 04:33:52.483440 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00103201 (* 1 = 0.00103201 loss)
I0530 04:33:52.483443 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0104647 (* 1 = 0.0104647 loss)
I0530 04:33:52.483448 24924 sgd_solver.cpp:106] Iteration 9600, lr = 0.0002
I0530 04:34:41.075037 24924 solver.cpp:228] Iteration 9620, loss = 0.403144
I0530 04:34:41.075060 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 04:34:41.075069 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159564 (* 1 = 0.0159564 loss)
I0530 04:34:41.075075 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0643508 (* 1 = 0.0643508 loss)
I0530 04:34:41.075081 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00951991 (* 1 = 0.00951991 loss)
I0530 04:34:41.075086 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015033 (* 1 = 0.015033 loss)
I0530 04:34:41.075093 24924 sgd_solver.cpp:106] Iteration 9620, lr = 0.0002
I0530 04:35:29.659955 24924 solver.cpp:228] Iteration 9640, loss = 0.335012
I0530 04:35:29.659979 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 04:35:29.659988 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.061186 (* 1 = 0.061186 loss)
I0530 04:35:29.660007 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.212995 (* 1 = 0.212995 loss)
I0530 04:35:29.660012 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289567 (* 1 = 0.0289567 loss)
I0530 04:35:29.660017 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214887 (* 1 = 0.0214887 loss)
I0530 04:35:29.660022 24924 sgd_solver.cpp:106] Iteration 9640, lr = 0.0002
I0530 04:36:18.240392 24924 solver.cpp:228] Iteration 9660, loss = 0.641035
I0530 04:36:18.240414 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 04:36:18.240423 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0519717 (* 1 = 0.0519717 loss)
I0530 04:36:18.240442 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142728 (* 1 = 0.142728 loss)
I0530 04:36:18.240447 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00919503 (* 1 = 0.00919503 loss)
I0530 04:36:18.240453 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109077 (* 1 = 0.0109077 loss)
I0530 04:36:18.240458 24924 sgd_solver.cpp:106] Iteration 9660, lr = 0.0002
I0530 04:37:06.811893 24924 solver.cpp:228] Iteration 9680, loss = 0.301334
I0530 04:37:06.811916 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:37:06.811924 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298678 (* 1 = 0.0298678 loss)
I0530 04:37:06.811944 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134225 (* 1 = 0.134225 loss)
I0530 04:37:06.811949 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205622 (* 1 = 0.0205622 loss)
I0530 04:37:06.811952 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0294358 (* 1 = 0.0294358 loss)
I0530 04:37:06.811959 24924 sgd_solver.cpp:106] Iteration 9680, lr = 0.0002
I0530 04:37:55.334944 24924 solver.cpp:228] Iteration 9700, loss = 0.28822
I0530 04:37:55.334967 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:37:55.334976 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0338086 (* 1 = 0.0338086 loss)
I0530 04:37:55.334995 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.11576 (* 1 = 0.11576 loss)
I0530 04:37:55.335001 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00702203 (* 1 = 0.00702203 loss)
I0530 04:37:55.335006 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100012 (* 1 = 0.0100012 loss)
I0530 04:37:55.335011 24924 sgd_solver.cpp:106] Iteration 9700, lr = 0.0002
I0530 04:38:43.907259 24924 solver.cpp:228] Iteration 9720, loss = 0.273454
I0530 04:38:43.907280 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:38:43.907289 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0318569 (* 1 = 0.0318569 loss)
I0530 04:38:43.907307 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0873554 (* 1 = 0.0873554 loss)
I0530 04:38:43.907312 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135206 (* 1 = 0.0135206 loss)
I0530 04:38:43.907316 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117193 (* 1 = 0.0117193 loss)
I0530 04:38:43.907322 24924 sgd_solver.cpp:106] Iteration 9720, lr = 0.0002
I0530 04:39:32.464390 24924 solver.cpp:228] Iteration 9740, loss = 0.320409
I0530 04:39:32.464412 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 04:39:32.464421 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.161666 (* 1 = 0.161666 loss)
I0530 04:39:32.464439 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147099 (* 1 = 0.147099 loss)
I0530 04:39:32.464444 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0341067 (* 1 = 0.0341067 loss)
I0530 04:39:32.464449 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0516439 (* 1 = 0.0516439 loss)
I0530 04:39:32.464454 24924 sgd_solver.cpp:106] Iteration 9740, lr = 0.0002
I0530 04:40:21.029039 24924 solver.cpp:228] Iteration 9760, loss = 0.372326
I0530 04:40:21.029063 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 04:40:21.029072 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.296627 (* 1 = 0.296627 loss)
I0530 04:40:21.029091 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.529942 (* 1 = 0.529942 loss)
I0530 04:40:21.029095 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0334632 (* 1 = 0.0334632 loss)
I0530 04:40:21.029100 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0907807 (* 1 = 0.0907807 loss)
I0530 04:40:21.029106 24924 sgd_solver.cpp:106] Iteration 9760, lr = 0.0002
I0530 04:41:09.620707 24924 solver.cpp:228] Iteration 9780, loss = 0.600246
I0530 04:41:09.620743 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.632812
I0530 04:41:09.620749 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.604451 (* 1 = 0.604451 loss)
I0530 04:41:09.620753 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.652992 (* 1 = 0.652992 loss)
I0530 04:41:09.620756 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0373953 (* 1 = 0.0373953 loss)
I0530 04:41:09.620759 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.258851 (* 1 = 0.258851 loss)
I0530 04:41:09.620764 24924 sgd_solver.cpp:106] Iteration 9780, lr = 0.0002
speed: 2.437s / iter
I0530 04:41:58.160382 24924 solver.cpp:228] Iteration 9800, loss = 0.182145
I0530 04:41:58.160418 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 04:41:58.160424 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.025422 (* 1 = 0.025422 loss)
I0530 04:41:58.160429 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132644 (* 1 = 0.132644 loss)
I0530 04:41:58.160431 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00758487 (* 1 = 0.00758487 loss)
I0530 04:41:58.160434 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158194 (* 1 = 0.0158194 loss)
I0530 04:41:58.160439 24924 sgd_solver.cpp:106] Iteration 9800, lr = 0.0002
I0530 04:42:46.704591 24924 solver.cpp:228] Iteration 9820, loss = 0.3607
I0530 04:42:46.704613 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0530 04:42:46.704622 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.228786 (* 1 = 0.228786 loss)
I0530 04:42:46.704624 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.514197 (* 1 = 0.514197 loss)
I0530 04:42:46.704628 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0192176 (* 1 = 0.0192176 loss)
I0530 04:42:46.704632 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681808 (* 1 = 0.0681808 loss)
I0530 04:42:46.704636 24924 sgd_solver.cpp:106] Iteration 9820, lr = 0.0002
I0530 04:43:35.277740 24924 solver.cpp:228] Iteration 9840, loss = 0.255561
I0530 04:43:35.277776 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 04:43:35.277782 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0372004 (* 1 = 0.0372004 loss)
I0530 04:43:35.277786 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.052383 (* 1 = 0.052383 loss)
I0530 04:43:35.277791 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0026261 (* 1 = 0.0026261 loss)
I0530 04:43:35.277793 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137327 (* 1 = 0.0137327 loss)
I0530 04:43:35.277797 24924 sgd_solver.cpp:106] Iteration 9840, lr = 0.0002
I0530 04:44:23.856191 24924 solver.cpp:228] Iteration 9860, loss = 0.157973
I0530 04:44:23.856227 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:44:23.856235 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.092217 (* 1 = 0.092217 loss)
I0530 04:44:23.856238 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.2123 (* 1 = 0.2123 loss)
I0530 04:44:23.856242 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0774319 (* 1 = 0.0774319 loss)
I0530 04:44:23.856245 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0627194 (* 1 = 0.0627194 loss)
I0530 04:44:23.856250 24924 sgd_solver.cpp:106] Iteration 9860, lr = 0.0002
I0530 04:45:12.408530 24924 solver.cpp:228] Iteration 9880, loss = 0.36001
I0530 04:45:12.408565 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 04:45:12.408572 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.232807 (* 1 = 0.232807 loss)
I0530 04:45:12.408576 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.465629 (* 1 = 0.465629 loss)
I0530 04:45:12.408578 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170542 (* 1 = 0.0170542 loss)
I0530 04:45:12.408582 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0574596 (* 1 = 0.0574596 loss)
I0530 04:45:12.408586 24924 sgd_solver.cpp:106] Iteration 9880, lr = 0.0002
I0530 04:46:00.972009 24924 solver.cpp:228] Iteration 9900, loss = 0.310811
I0530 04:46:00.972036 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 04:46:00.972043 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.140305 (* 1 = 0.140305 loss)
I0530 04:46:00.972048 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.253777 (* 1 = 0.253777 loss)
I0530 04:46:00.972050 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116155 (* 1 = 0.0116155 loss)
I0530 04:46:00.972054 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231095 (* 1 = 0.0231095 loss)
I0530 04:46:00.972059 24924 sgd_solver.cpp:106] Iteration 9900, lr = 0.0002
I0530 04:46:49.572327 24924 solver.cpp:228] Iteration 9920, loss = 0.177199
I0530 04:46:49.572351 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:46:49.572360 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0858268 (* 1 = 0.0858268 loss)
I0530 04:46:49.572379 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.162008 (* 1 = 0.162008 loss)
I0530 04:46:49.572383 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361005 (* 1 = 0.00361005 loss)
I0530 04:46:49.572388 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103695 (* 1 = 0.0103695 loss)
I0530 04:46:49.572394 24924 sgd_solver.cpp:106] Iteration 9920, lr = 0.0002
I0530 04:47:38.159364 24924 solver.cpp:228] Iteration 9940, loss = 0.198037
I0530 04:47:38.159389 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 04:47:38.159397 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.112282 (* 1 = 0.112282 loss)
I0530 04:47:38.159416 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0797225 (* 1 = 0.0797225 loss)
I0530 04:47:38.159422 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142142 (* 1 = 0.0142142 loss)
I0530 04:47:38.159426 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260253 (* 1 = 0.0260253 loss)
I0530 04:47:38.159432 24924 sgd_solver.cpp:106] Iteration 9940, lr = 0.0002
I0530 04:48:26.694325 24924 solver.cpp:228] Iteration 9960, loss = 0.378242
I0530 04:48:26.694347 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:48:26.694356 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.064113 (* 1 = 0.064113 loss)
I0530 04:48:26.694375 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133659 (* 1 = 0.133659 loss)
I0530 04:48:26.694380 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103876 (* 1 = 0.0103876 loss)
I0530 04:48:26.694386 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150725 (* 1 = 0.0150725 loss)
I0530 04:48:26.694391 24924 sgd_solver.cpp:106] Iteration 9960, lr = 0.0002
I0530 04:49:15.264374 24924 solver.cpp:228] Iteration 9980, loss = 0.357379
I0530 04:49:15.264395 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 04:49:15.264405 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0530717 (* 1 = 0.0530717 loss)
I0530 04:49:15.264423 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.107114 (* 1 = 0.107114 loss)
I0530 04:49:15.264428 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00838335 (* 1 = 0.00838335 loss)
I0530 04:49:15.264432 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00353156 (* 1 = 0.00353156 loss)
I0530 04:49:15.264438 24924 sgd_solver.cpp:106] Iteration 9980, lr = 0.0002
speed: 2.437s / iter
I0530 04:50:01.583832 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_10000.caffemodel
I0530 04:50:04.499596 24924 solver.cpp:228] Iteration 10000, loss = 0.557667
I0530 04:50:04.499632 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 04:50:04.499642 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0998553 (* 1 = 0.0998553 loss)
I0530 04:50:04.499647 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.224673 (* 1 = 0.224673 loss)
I0530 04:50:04.499652 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232804 (* 1 = 0.0232804 loss)
I0530 04:50:04.499657 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369213 (* 1 = 0.0369213 loss)
I0530 04:50:04.499665 24924 sgd_solver.cpp:106] Iteration 10000, lr = 0.0002
I0530 04:50:53.018072 24924 solver.cpp:228] Iteration 10020, loss = 0.340671
I0530 04:50:53.018095 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 04:50:53.018102 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.030247 (* 1 = 0.030247 loss)
I0530 04:50:53.018107 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113709 (* 1 = 0.113709 loss)
I0530 04:50:53.018126 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0291767 (* 1 = 0.0291767 loss)
I0530 04:50:53.018131 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0411885 (* 1 = 0.0411885 loss)
I0530 04:50:53.018136 24924 sgd_solver.cpp:106] Iteration 10020, lr = 0.0002
I0530 04:51:41.596539 24924 solver.cpp:228] Iteration 10040, loss = 0.580398
I0530 04:51:41.596561 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 04:51:41.596570 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0526572 (* 1 = 0.0526572 loss)
I0530 04:51:41.596590 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0916185 (* 1 = 0.0916185 loss)
I0530 04:51:41.596596 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00323434 (* 1 = 0.00323434 loss)
I0530 04:51:41.596599 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00537856 (* 1 = 0.00537856 loss)
I0530 04:51:41.596606 24924 sgd_solver.cpp:106] Iteration 10040, lr = 0.0002
I0530 04:52:30.189208 24924 solver.cpp:228] Iteration 10060, loss = 0.295609
I0530 04:52:30.189231 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 04:52:30.189239 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0679462 (* 1 = 0.0679462 loss)
I0530 04:52:30.189260 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113078 (* 1 = 0.113078 loss)
I0530 04:52:30.189263 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00679148 (* 1 = 0.00679148 loss)
I0530 04:52:30.189268 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0302344 (* 1 = 0.0302344 loss)
I0530 04:52:30.189275 24924 sgd_solver.cpp:106] Iteration 10060, lr = 0.0002
I0530 04:53:18.762473 24924 solver.cpp:228] Iteration 10080, loss = 0.37609
I0530 04:53:18.762498 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 04:53:18.762507 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.046595 (* 1 = 0.046595 loss)
I0530 04:53:18.762512 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.178897 (* 1 = 0.178897 loss)
I0530 04:53:18.762517 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377209 (* 1 = 0.00377209 loss)
I0530 04:53:18.762521 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00785545 (* 1 = 0.00785545 loss)
I0530 04:53:18.762528 24924 sgd_solver.cpp:106] Iteration 10080, lr = 0.0002
I0530 04:54:07.344281 24924 solver.cpp:228] Iteration 10100, loss = 0.347293
I0530 04:54:07.344305 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:54:07.344313 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.045298 (* 1 = 0.045298 loss)
I0530 04:54:07.344333 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.225861 (* 1 = 0.225861 loss)
I0530 04:54:07.344337 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011851 (* 1 = 0.011851 loss)
I0530 04:54:07.344342 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0194643 (* 1 = 0.0194643 loss)
I0530 04:54:07.344348 24924 sgd_solver.cpp:106] Iteration 10100, lr = 0.0002
I0530 04:54:55.968546 24924 solver.cpp:228] Iteration 10120, loss = 0.270178
I0530 04:54:55.968582 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 04:54:55.968590 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.171852 (* 1 = 0.171852 loss)
I0530 04:54:55.968592 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.285395 (* 1 = 0.285395 loss)
I0530 04:54:55.968596 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0289898 (* 1 = 0.0289898 loss)
I0530 04:54:55.968600 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490033 (* 1 = 0.0490033 loss)
I0530 04:54:55.968603 24924 sgd_solver.cpp:106] Iteration 10120, lr = 0.0002
I0530 04:55:44.632325 24924 solver.cpp:228] Iteration 10140, loss = 0.32858
I0530 04:55:44.632361 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 04:55:44.632367 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937288 (* 1 = 0.0937288 loss)
I0530 04:55:44.632371 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.338659 (* 1 = 0.338659 loss)
I0530 04:55:44.632375 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0464273 (* 1 = 0.0464273 loss)
I0530 04:55:44.632377 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0500011 (* 1 = 0.0500011 loss)
I0530 04:55:44.632381 24924 sgd_solver.cpp:106] Iteration 10140, lr = 0.0002
I0530 04:56:33.335206 24924 solver.cpp:228] Iteration 10160, loss = 0.24245
I0530 04:56:33.335229 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 04:56:33.335237 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.146248 (* 1 = 0.146248 loss)
I0530 04:56:33.335240 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.225732 (* 1 = 0.225732 loss)
I0530 04:56:33.335244 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00738373 (* 1 = 0.00738373 loss)
I0530 04:56:33.335247 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0517562 (* 1 = 0.0517562 loss)
I0530 04:56:33.335253 24924 sgd_solver.cpp:106] Iteration 10160, lr = 0.0002
I0530 04:57:22.154719 24924 solver.cpp:228] Iteration 10180, loss = 0.284183
I0530 04:57:22.154757 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 04:57:22.154762 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.142673 (* 1 = 0.142673 loss)
I0530 04:57:22.154767 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.225057 (* 1 = 0.225057 loss)
I0530 04:57:22.154769 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114297 (* 1 = 0.0114297 loss)
I0530 04:57:22.154772 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0348743 (* 1 = 0.0348743 loss)
I0530 04:57:22.154777 24924 sgd_solver.cpp:106] Iteration 10180, lr = 0.0002
speed: 2.437s / iter
I0530 04:58:10.927024 24924 solver.cpp:228] Iteration 10200, loss = 0.409485
I0530 04:58:10.927060 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 04:58:10.927067 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0959696 (* 1 = 0.0959696 loss)
I0530 04:58:10.927070 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.140011 (* 1 = 0.140011 loss)
I0530 04:58:10.927074 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00297163 (* 1 = 0.00297163 loss)
I0530 04:58:10.927078 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0234875 (* 1 = 0.0234875 loss)
I0530 04:58:10.927081 24924 sgd_solver.cpp:106] Iteration 10200, lr = 0.0002
I0530 04:58:59.748908 24924 solver.cpp:228] Iteration 10220, loss = 0.382505
I0530 04:58:59.748967 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 04:58:59.748975 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0866064 (* 1 = 0.0866064 loss)
I0530 04:58:59.748977 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.310851 (* 1 = 0.310851 loss)
I0530 04:58:59.748980 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0251338 (* 1 = 0.0251338 loss)
I0530 04:58:59.748984 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00765223 (* 1 = 0.00765223 loss)
I0530 04:58:59.748988 24924 sgd_solver.cpp:106] Iteration 10220, lr = 0.0002
I0530 04:59:48.520452 24924 solver.cpp:228] Iteration 10240, loss = 0.267275
I0530 04:59:48.520474 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 04:59:48.520481 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.100283 (* 1 = 0.100283 loss)
I0530 04:59:48.520485 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.111543 (* 1 = 0.111543 loss)
I0530 04:59:48.520488 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00532561 (* 1 = 0.00532561 loss)
I0530 04:59:48.520491 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152913 (* 1 = 0.0152913 loss)
I0530 04:59:48.520495 24924 sgd_solver.cpp:106] Iteration 10240, lr = 0.0002
I0530 05:00:37.357857 24924 solver.cpp:228] Iteration 10260, loss = 0.365649
I0530 05:00:37.357893 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 05:00:37.357899 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102771 (* 1 = 0.102771 loss)
I0530 05:00:37.357903 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139453 (* 1 = 0.139453 loss)
I0530 05:00:37.357906 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112444 (* 1 = 0.0112444 loss)
I0530 05:00:37.357909 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00730601 (* 1 = 0.00730601 loss)
I0530 05:00:37.357913 24924 sgd_solver.cpp:106] Iteration 10260, lr = 0.0002
I0530 05:01:26.239316 24924 solver.cpp:228] Iteration 10280, loss = 0.270232
I0530 05:01:26.239352 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:01:26.239358 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0437679 (* 1 = 0.0437679 loss)
I0530 05:01:26.239362 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115864 (* 1 = 0.115864 loss)
I0530 05:01:26.239365 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00424033 (* 1 = 0.00424033 loss)
I0530 05:01:26.239368 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111213 (* 1 = 0.0111213 loss)
I0530 05:01:26.239372 24924 sgd_solver.cpp:106] Iteration 10280, lr = 0.0002
I0530 05:02:14.986709 24924 solver.cpp:228] Iteration 10300, loss = 0.318714
I0530 05:02:14.986732 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 05:02:14.986739 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.145577 (* 1 = 0.145577 loss)
I0530 05:02:14.986743 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.20649 (* 1 = 0.20649 loss)
I0530 05:02:14.986747 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00476717 (* 1 = 0.00476717 loss)
I0530 05:02:14.986752 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0343321 (* 1 = 0.0343321 loss)
I0530 05:02:14.986755 24924 sgd_solver.cpp:106] Iteration 10300, lr = 0.0002
I0530 05:03:03.794646 24924 solver.cpp:228] Iteration 10320, loss = 0.459692
I0530 05:03:03.794668 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 05:03:03.794675 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.186184 (* 1 = 0.186184 loss)
I0530 05:03:03.794679 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.19436 (* 1 = 0.19436 loss)
I0530 05:03:03.794683 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00502131 (* 1 = 0.00502131 loss)
I0530 05:03:03.794687 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013008 (* 1 = 0.013008 loss)
I0530 05:03:03.794692 24924 sgd_solver.cpp:106] Iteration 10320, lr = 0.0002
I0530 05:03:52.636009 24924 solver.cpp:228] Iteration 10340, loss = 0.405878
I0530 05:03:52.636031 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 05:03:52.636039 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0763219 (* 1 = 0.0763219 loss)
I0530 05:03:52.636042 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.150818 (* 1 = 0.150818 loss)
I0530 05:03:52.636046 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00887511 (* 1 = 0.00887511 loss)
I0530 05:03:52.636049 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024332 (* 1 = 0.024332 loss)
I0530 05:03:52.636054 24924 sgd_solver.cpp:106] Iteration 10340, lr = 0.0002
I0530 05:04:41.453619 24924 solver.cpp:228] Iteration 10360, loss = 0.251065
I0530 05:04:41.453655 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:04:41.453662 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.114537 (* 1 = 0.114537 loss)
I0530 05:04:41.453666 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.197945 (* 1 = 0.197945 loss)
I0530 05:04:41.453670 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00578659 (* 1 = 0.00578659 loss)
I0530 05:04:41.453672 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372181 (* 1 = 0.0372181 loss)
I0530 05:04:41.453676 24924 sgd_solver.cpp:106] Iteration 10360, lr = 0.0002
I0530 05:05:30.301394 24924 solver.cpp:228] Iteration 10380, loss = 0.438961
I0530 05:05:30.301419 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 05:05:30.301424 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.142345 (* 1 = 0.142345 loss)
I0530 05:05:30.301429 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.221019 (* 1 = 0.221019 loss)
I0530 05:05:30.301431 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00898565 (* 1 = 0.00898565 loss)
I0530 05:05:30.301435 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187532 (* 1 = 0.0187532 loss)
I0530 05:05:30.301440 24924 sgd_solver.cpp:106] Iteration 10380, lr = 0.0002
speed: 2.437s / iter
I0530 05:06:19.139250 24924 solver.cpp:228] Iteration 10400, loss = 0.236765
I0530 05:06:19.139273 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:06:19.139281 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0830978 (* 1 = 0.0830978 loss)
I0530 05:06:19.139284 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.167231 (* 1 = 0.167231 loss)
I0530 05:06:19.139288 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00674116 (* 1 = 0.00674116 loss)
I0530 05:06:19.139292 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0337501 (* 1 = 0.0337501 loss)
I0530 05:06:19.139297 24924 sgd_solver.cpp:106] Iteration 10400, lr = 0.0002
I0530 05:07:07.916776 24924 solver.cpp:228] Iteration 10420, loss = 0.363608
I0530 05:07:07.916800 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 05:07:07.916807 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00861493 (* 1 = 0.00861493 loss)
I0530 05:07:07.916811 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.150896 (* 1 = 0.150896 loss)
I0530 05:07:07.916815 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0587279 (* 1 = 0.0587279 loss)
I0530 05:07:07.916818 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021204 (* 1 = 0.021204 loss)
I0530 05:07:07.916823 24924 sgd_solver.cpp:106] Iteration 10420, lr = 0.0002
I0530 05:07:56.652353 24924 solver.cpp:228] Iteration 10440, loss = 0.376931
I0530 05:07:56.652387 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 05:07:56.652393 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0890405 (* 1 = 0.0890405 loss)
I0530 05:07:56.652397 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.195308 (* 1 = 0.195308 loss)
I0530 05:07:56.652400 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00723088 (* 1 = 0.00723088 loss)
I0530 05:07:56.652403 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272738 (* 1 = 0.0272738 loss)
I0530 05:07:56.652407 24924 sgd_solver.cpp:106] Iteration 10440, lr = 0.0002
I0530 05:08:45.428000 24924 solver.cpp:228] Iteration 10460, loss = 0.426848
I0530 05:08:45.428036 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:08:45.428042 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.037452 (* 1 = 0.037452 loss)
I0530 05:08:45.428046 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0840421 (* 1 = 0.0840421 loss)
I0530 05:08:45.428050 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018719 (* 1 = 0.018719 loss)
I0530 05:08:45.428052 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.021304 (* 1 = 0.021304 loss)
I0530 05:08:45.428057 24924 sgd_solver.cpp:106] Iteration 10460, lr = 0.0002
I0530 05:09:34.219631 24924 solver.cpp:228] Iteration 10480, loss = 0.216274
I0530 05:09:34.219668 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 05:09:34.219674 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0272164 (* 1 = 0.0272164 loss)
I0530 05:09:34.219678 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.137211 (* 1 = 0.137211 loss)
I0530 05:09:34.219681 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126529 (* 1 = 0.0126529 loss)
I0530 05:09:34.219684 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00454967 (* 1 = 0.00454967 loss)
I0530 05:09:34.219689 24924 sgd_solver.cpp:106] Iteration 10480, lr = 0.0002
I0530 05:10:22.968282 24924 solver.cpp:228] Iteration 10500, loss = 0.245068
I0530 05:10:22.968304 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 05:10:22.968324 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160621 (* 1 = 0.160621 loss)
I0530 05:10:22.968328 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.263934 (* 1 = 0.263934 loss)
I0530 05:10:22.968333 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135793 (* 1 = 0.0135793 loss)
I0530 05:10:22.968335 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030789 (* 1 = 0.030789 loss)
I0530 05:10:22.968339 24924 sgd_solver.cpp:106] Iteration 10500, lr = 0.0002
I0530 05:11:11.720358 24924 solver.cpp:228] Iteration 10520, loss = 0.326392
I0530 05:11:11.720381 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0530 05:11:11.720388 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.231168 (* 1 = 0.231168 loss)
I0530 05:11:11.720408 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.411689 (* 1 = 0.411689 loss)
I0530 05:11:11.720413 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01459 (* 1 = 0.01459 loss)
I0530 05:11:11.720417 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658855 (* 1 = 0.0658855 loss)
I0530 05:11:11.720423 24924 sgd_solver.cpp:106] Iteration 10520, lr = 0.0002
I0530 05:12:00.426692 24924 solver.cpp:228] Iteration 10540, loss = 0.265946
I0530 05:12:00.426715 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:12:00.426723 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0663714 (* 1 = 0.0663714 loss)
I0530 05:12:00.426726 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0741867 (* 1 = 0.0741867 loss)
I0530 05:12:00.426729 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338052 (* 1 = 0.00338052 loss)
I0530 05:12:00.426733 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00884197 (* 1 = 0.00884197 loss)
I0530 05:12:00.426738 24924 sgd_solver.cpp:106] Iteration 10540, lr = 0.0002
I0530 05:12:49.253039 24924 solver.cpp:228] Iteration 10560, loss = 0.376436
I0530 05:12:49.253075 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 05:12:49.253082 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335097 (* 1 = 0.0335097 loss)
I0530 05:12:49.253087 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142583 (* 1 = 0.142583 loss)
I0530 05:12:49.253089 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200049 (* 1 = 0.0200049 loss)
I0530 05:12:49.253093 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016393 (* 1 = 0.016393 loss)
I0530 05:12:49.253096 24924 sgd_solver.cpp:106] Iteration 10560, lr = 0.0002
I0530 05:13:37.966892 24924 solver.cpp:228] Iteration 10580, loss = 0.315461
I0530 05:13:37.966913 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:13:37.966922 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0208337 (* 1 = 0.0208337 loss)
I0530 05:13:37.966941 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0771914 (* 1 = 0.0771914 loss)
I0530 05:13:37.966945 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158133 (* 1 = 0.0158133 loss)
I0530 05:13:37.966949 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0363587 (* 1 = 0.0363587 loss)
I0530 05:13:37.966954 24924 sgd_solver.cpp:106] Iteration 10580, lr = 0.0002
speed: 2.437s / iter
I0530 05:14:26.669782 24924 solver.cpp:228] Iteration 10600, loss = 0.405515
I0530 05:14:26.669806 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 05:14:26.669814 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.302709 (* 1 = 0.302709 loss)
I0530 05:14:26.669819 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.36857 (* 1 = 0.36857 loss)
I0530 05:14:26.669826 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0545994 (* 1 = 0.0545994 loss)
I0530 05:14:26.669831 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0890731 (* 1 = 0.0890731 loss)
I0530 05:14:26.669838 24924 sgd_solver.cpp:106] Iteration 10600, lr = 0.0002
I0530 05:15:15.389513 24924 solver.cpp:228] Iteration 10620, loss = 0.559999
I0530 05:15:15.389534 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 05:15:15.389555 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.10309 (* 1 = 0.10309 loss)
I0530 05:15:15.389559 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.175511 (* 1 = 0.175511 loss)
I0530 05:15:15.389562 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0194547 (* 1 = 0.0194547 loss)
I0530 05:15:15.389565 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274413 (* 1 = 0.0274413 loss)
I0530 05:15:15.389570 24924 sgd_solver.cpp:106] Iteration 10620, lr = 0.0002
I0530 05:16:04.046432 24924 solver.cpp:228] Iteration 10640, loss = 0.290653
I0530 05:16:04.046468 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:16:04.046476 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0842637 (* 1 = 0.0842637 loss)
I0530 05:16:04.046480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.126927 (* 1 = 0.126927 loss)
I0530 05:16:04.046483 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00133884 (* 1 = 0.00133884 loss)
I0530 05:16:04.046488 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0093749 (* 1 = 0.0093749 loss)
I0530 05:16:04.046491 24924 sgd_solver.cpp:106] Iteration 10640, lr = 0.0002
I0530 05:16:52.681599 24924 solver.cpp:228] Iteration 10660, loss = 0.442209
I0530 05:16:52.681622 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 05:16:52.681627 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.212726 (* 1 = 0.212726 loss)
I0530 05:16:52.681632 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.316445 (* 1 = 0.316445 loss)
I0530 05:16:52.681634 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0631881 (* 1 = 0.0631881 loss)
I0530 05:16:52.681638 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.151361 (* 1 = 0.151361 loss)
I0530 05:16:52.681640 24924 sgd_solver.cpp:106] Iteration 10660, lr = 0.0002
I0530 05:17:41.265857 24924 solver.cpp:228] Iteration 10680, loss = 0.246476
I0530 05:17:41.265893 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:17:41.265900 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359769 (* 1 = 0.0359769 loss)
I0530 05:17:41.265904 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0950921 (* 1 = 0.0950921 loss)
I0530 05:17:41.265908 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134388 (* 1 = 0.0134388 loss)
I0530 05:17:41.265910 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0246433 (* 1 = 0.0246433 loss)
I0530 05:17:41.265914 24924 sgd_solver.cpp:106] Iteration 10680, lr = 0.0002
I0530 05:18:29.837679 24924 solver.cpp:228] Iteration 10700, loss = 0.342797
I0530 05:18:29.837714 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 05:18:29.837720 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.14626 (* 1 = 0.14626 loss)
I0530 05:18:29.837724 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.419028 (* 1 = 0.419028 loss)
I0530 05:18:29.837728 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00739332 (* 1 = 0.00739332 loss)
I0530 05:18:29.837730 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0274299 (* 1 = 0.0274299 loss)
I0530 05:18:29.837734 24924 sgd_solver.cpp:106] Iteration 10700, lr = 0.0002
I0530 05:19:18.425712 24924 solver.cpp:228] Iteration 10720, loss = 0.359956
I0530 05:19:18.425736 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 05:19:18.425745 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000348399 (* 1 = 0.000348399 loss)
I0530 05:19:18.425765 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0356353 (* 1 = 0.0356353 loss)
I0530 05:19:18.425768 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00647921 (* 1 = 0.00647921 loss)
I0530 05:19:18.425773 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213882 (* 1 = 0.0213882 loss)
I0530 05:19:18.425779 24924 sgd_solver.cpp:106] Iteration 10720, lr = 0.0002
I0530 05:20:06.969784 24924 solver.cpp:228] Iteration 10740, loss = 0.32109
I0530 05:20:06.969806 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 05:20:06.969815 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0676446 (* 1 = 0.0676446 loss)
I0530 05:20:06.969835 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0813687 (* 1 = 0.0813687 loss)
I0530 05:20:06.969840 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00471002 (* 1 = 0.00471002 loss)
I0530 05:20:06.969844 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00707236 (* 1 = 0.00707236 loss)
I0530 05:20:06.969849 24924 sgd_solver.cpp:106] Iteration 10740, lr = 0.0002
I0530 05:20:55.476107 24924 solver.cpp:228] Iteration 10760, loss = 0.224648
I0530 05:20:55.476130 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:20:55.476137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0941367 (* 1 = 0.0941367 loss)
I0530 05:20:55.476157 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.170404 (* 1 = 0.170404 loss)
I0530 05:20:55.476162 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117193 (* 1 = 0.0117193 loss)
I0530 05:20:55.476166 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132759 (* 1 = 0.0132759 loss)
I0530 05:20:55.476172 24924 sgd_solver.cpp:106] Iteration 10760, lr = 0.0002
I0530 05:21:44.142585 24924 solver.cpp:228] Iteration 10780, loss = 0.279491
I0530 05:21:44.142621 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 05:21:44.142628 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.035085 (* 1 = 0.035085 loss)
I0530 05:21:44.142632 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100814 (* 1 = 0.100814 loss)
I0530 05:21:44.142635 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237916 (* 1 = 0.00237916 loss)
I0530 05:21:44.142638 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0117451 (* 1 = 0.0117451 loss)
I0530 05:21:44.142642 24924 sgd_solver.cpp:106] Iteration 10780, lr = 0.0002
speed: 2.437s / iter
I0530 05:22:32.705098 24924 solver.cpp:228] Iteration 10800, loss = 0.309273
I0530 05:22:32.705135 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 05:22:32.705142 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.397261 (* 1 = 0.397261 loss)
I0530 05:22:32.705145 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.446046 (* 1 = 0.446046 loss)
I0530 05:22:32.705148 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0461056 (* 1 = 0.0461056 loss)
I0530 05:22:32.705152 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134748 (* 1 = 0.134748 loss)
I0530 05:22:32.705157 24924 sgd_solver.cpp:106] Iteration 10800, lr = 0.0002
I0530 05:23:21.185096 24924 solver.cpp:228] Iteration 10820, loss = 0.205876
I0530 05:23:21.185134 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 05:23:21.185142 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308808 (* 1 = 0.0308808 loss)
I0530 05:23:21.185144 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147928 (* 1 = 0.147928 loss)
I0530 05:23:21.185148 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0215792 (* 1 = 0.0215792 loss)
I0530 05:23:21.185153 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0262105 (* 1 = 0.0262105 loss)
I0530 05:23:21.185159 24924 sgd_solver.cpp:106] Iteration 10820, lr = 0.0002
I0530 05:24:09.770157 24924 solver.cpp:228] Iteration 10840, loss = 0.444893
I0530 05:24:09.770195 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 05:24:09.770201 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.130618 (* 1 = 0.130618 loss)
I0530 05:24:09.770205 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.372112 (* 1 = 0.372112 loss)
I0530 05:24:09.770208 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154117 (* 1 = 0.0154117 loss)
I0530 05:24:09.770213 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0415588 (* 1 = 0.0415588 loss)
I0530 05:24:09.770220 24924 sgd_solver.cpp:106] Iteration 10840, lr = 0.0002
I0530 05:24:58.374446 24924 solver.cpp:228] Iteration 10860, loss = 0.402529
I0530 05:24:58.374469 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 05:24:58.374475 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0634034 (* 1 = 0.0634034 loss)
I0530 05:24:58.374478 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.277587 (* 1 = 0.277587 loss)
I0530 05:24:58.374481 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0179586 (* 1 = 0.0179586 loss)
I0530 05:24:58.374485 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102343 (* 1 = 0.0102343 loss)
I0530 05:24:58.374488 24924 sgd_solver.cpp:106] Iteration 10860, lr = 0.0002
I0530 05:25:46.906724 24924 solver.cpp:228] Iteration 10880, loss = 0.567541
I0530 05:25:46.906747 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 05:25:46.906754 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.259101 (* 1 = 0.259101 loss)
I0530 05:25:46.906759 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.293129 (* 1 = 0.293129 loss)
I0530 05:25:46.906761 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167502 (* 1 = 0.0167502 loss)
I0530 05:25:46.906765 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0861413 (* 1 = 0.0861413 loss)
I0530 05:25:46.906769 24924 sgd_solver.cpp:106] Iteration 10880, lr = 0.0002
I0530 05:26:35.445066 24924 solver.cpp:228] Iteration 10900, loss = 0.801136
I0530 05:26:35.445103 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.507812
I0530 05:26:35.445111 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.802823 (* 1 = 0.802823 loss)
I0530 05:26:35.445113 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.825985 (* 1 = 0.825985 loss)
I0530 05:26:35.445117 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.165258 (* 1 = 0.165258 loss)
I0530 05:26:35.445119 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.592087 (* 1 = 0.592087 loss)
I0530 05:26:35.445123 24924 sgd_solver.cpp:106] Iteration 10900, lr = 0.0002
I0530 05:27:23.981531 24924 solver.cpp:228] Iteration 10920, loss = 0.409811
I0530 05:27:23.981554 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 05:27:23.981560 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0405786 (* 1 = 0.0405786 loss)
I0530 05:27:23.981564 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165872 (* 1 = 0.165872 loss)
I0530 05:27:23.981567 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030768 (* 1 = 0.030768 loss)
I0530 05:27:23.981570 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0392517 (* 1 = 0.0392517 loss)
I0530 05:27:23.981575 24924 sgd_solver.cpp:106] Iteration 10920, lr = 0.0002
I0530 05:28:12.502599 24924 solver.cpp:228] Iteration 10940, loss = 0.292141
I0530 05:28:12.502635 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:28:12.502641 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0247062 (* 1 = 0.0247062 loss)
I0530 05:28:12.502645 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0548976 (* 1 = 0.0548976 loss)
I0530 05:28:12.502648 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144317 (* 1 = 0.00144317 loss)
I0530 05:28:12.502651 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180533 (* 1 = 0.0180533 loss)
I0530 05:28:12.502656 24924 sgd_solver.cpp:106] Iteration 10940, lr = 0.0002
I0530 05:29:00.950677 24924 solver.cpp:228] Iteration 10960, loss = 0.231157
I0530 05:29:00.950713 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:29:00.950721 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.065726 (* 1 = 0.065726 loss)
I0530 05:29:00.950723 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152925 (* 1 = 0.152925 loss)
I0530 05:29:00.950726 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100012 (* 1 = 0.0100012 loss)
I0530 05:29:00.950729 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.134256 (* 1 = 0.134256 loss)
I0530 05:29:00.950733 24924 sgd_solver.cpp:106] Iteration 10960, lr = 0.0002
I0530 05:29:49.485402 24924 solver.cpp:228] Iteration 10980, loss = 0.277339
I0530 05:29:49.485440 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:29:49.485445 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245551 (* 1 = 0.0245551 loss)
I0530 05:29:49.485450 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0940897 (* 1 = 0.0940897 loss)
I0530 05:29:49.485453 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0054244 (* 1 = 0.0054244 loss)
I0530 05:29:49.485456 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00371817 (* 1 = 0.00371817 loss)
I0530 05:29:49.485460 24924 sgd_solver.cpp:106] Iteration 10980, lr = 0.0002
speed: 2.437s / iter
I0530 05:30:38.011204 24924 solver.cpp:228] Iteration 11000, loss = 0.419599
I0530 05:30:38.011241 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 05:30:38.011247 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.127157 (* 1 = 0.127157 loss)
I0530 05:30:38.011251 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.239626 (* 1 = 0.239626 loss)
I0530 05:30:38.011255 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880964 (* 1 = 0.00880964 loss)
I0530 05:30:38.011258 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131927 (* 1 = 0.0131927 loss)
I0530 05:30:38.011262 24924 sgd_solver.cpp:106] Iteration 11000, lr = 0.0002
I0530 05:31:26.533262 24924 solver.cpp:228] Iteration 11020, loss = 0.386375
I0530 05:31:26.533296 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 05:31:26.533304 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0309812 (* 1 = 0.0309812 loss)
I0530 05:31:26.533308 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0891912 (* 1 = 0.0891912 loss)
I0530 05:31:26.533311 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403105 (* 1 = 0.00403105 loss)
I0530 05:31:26.533314 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00582325 (* 1 = 0.00582325 loss)
I0530 05:31:26.533318 24924 sgd_solver.cpp:106] Iteration 11020, lr = 0.0002
I0530 05:32:15.090808 24924 solver.cpp:228] Iteration 11040, loss = 0.415323
I0530 05:32:15.090845 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 05:32:15.090852 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.204489 (* 1 = 0.204489 loss)
I0530 05:32:15.090855 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.290821 (* 1 = 0.290821 loss)
I0530 05:32:15.090858 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0540163 (* 1 = 0.0540163 loss)
I0530 05:32:15.090862 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.187443 (* 1 = 0.187443 loss)
I0530 05:32:15.090867 24924 sgd_solver.cpp:106] Iteration 11040, lr = 0.0002
I0530 05:33:03.669325 24924 solver.cpp:228] Iteration 11060, loss = 0.412616
I0530 05:33:03.669347 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 05:33:03.669353 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.156209 (* 1 = 0.156209 loss)
I0530 05:33:03.669356 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.305556 (* 1 = 0.305556 loss)
I0530 05:33:03.669359 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0226836 (* 1 = 0.0226836 loss)
I0530 05:33:03.669363 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0532037 (* 1 = 0.0532037 loss)
I0530 05:33:03.669366 24924 sgd_solver.cpp:106] Iteration 11060, lr = 0.0002
I0530 05:33:52.182519 24924 solver.cpp:228] Iteration 11080, loss = 0.178633
I0530 05:33:52.182555 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 05:33:52.182562 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0329074 (* 1 = 0.0329074 loss)
I0530 05:33:52.182566 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127925 (* 1 = 0.127925 loss)
I0530 05:33:52.182569 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00992696 (* 1 = 0.00992696 loss)
I0530 05:33:52.182572 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00427787 (* 1 = 0.00427787 loss)
I0530 05:33:52.182577 24924 sgd_solver.cpp:106] Iteration 11080, lr = 0.0002
I0530 05:34:40.804674 24924 solver.cpp:228] Iteration 11100, loss = 0.586462
I0530 05:34:40.804709 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 05:34:40.804716 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0520778 (* 1 = 0.0520778 loss)
I0530 05:34:40.804720 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139828 (* 1 = 0.139828 loss)
I0530 05:34:40.804723 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125991 (* 1 = 0.0125991 loss)
I0530 05:34:40.804726 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351113 (* 1 = 0.0351113 loss)
I0530 05:34:40.804730 24924 sgd_solver.cpp:106] Iteration 11100, lr = 0.0002
I0530 05:35:29.369154 24924 solver.cpp:228] Iteration 11120, loss = 0.436859
I0530 05:35:29.369177 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 05:35:29.369184 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346071 (* 1 = 0.0346071 loss)
I0530 05:35:29.369189 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160021 (* 1 = 0.160021 loss)
I0530 05:35:29.369192 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109273 (* 1 = 0.0109273 loss)
I0530 05:35:29.369195 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147541 (* 1 = 0.0147541 loss)
I0530 05:35:29.369199 24924 sgd_solver.cpp:106] Iteration 11120, lr = 0.0002
I0530 05:36:17.949368 24924 solver.cpp:228] Iteration 11140, loss = 0.463564
I0530 05:36:17.949404 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 05:36:17.949412 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.315553 (* 1 = 0.315553 loss)
I0530 05:36:17.949416 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.297813 (* 1 = 0.297813 loss)
I0530 05:36:17.949419 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121832 (* 1 = 0.0121832 loss)
I0530 05:36:17.949422 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0543768 (* 1 = 0.0543768 loss)
I0530 05:36:17.949426 24924 sgd_solver.cpp:106] Iteration 11140, lr = 0.0002
I0530 05:37:06.521029 24924 solver.cpp:228] Iteration 11160, loss = 0.256304
I0530 05:37:06.521065 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 05:37:06.521072 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0607372 (* 1 = 0.0607372 loss)
I0530 05:37:06.521075 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.21448 (* 1 = 0.21448 loss)
I0530 05:37:06.521080 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0352225 (* 1 = 0.0352225 loss)
I0530 05:37:06.521082 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0583313 (* 1 = 0.0583313 loss)
I0530 05:37:06.521086 24924 sgd_solver.cpp:106] Iteration 11160, lr = 0.0002
I0530 05:37:55.085918 24924 solver.cpp:228] Iteration 11180, loss = 0.300479
I0530 05:37:55.085953 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:37:55.085961 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0482503 (* 1 = 0.0482503 loss)
I0530 05:37:55.085965 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.114438 (* 1 = 0.114438 loss)
I0530 05:37:55.085968 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00834485 (* 1 = 0.00834485 loss)
I0530 05:37:55.085971 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179107 (* 1 = 0.0179107 loss)
I0530 05:37:55.085975 24924 sgd_solver.cpp:106] Iteration 11180, lr = 0.0002
speed: 2.437s / iter
I0530 05:38:43.703050 24924 solver.cpp:228] Iteration 11200, loss = 0.589981
I0530 05:38:43.703085 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.65625
I0530 05:38:43.703092 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.594914 (* 1 = 0.594914 loss)
I0530 05:38:43.703096 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.671451 (* 1 = 0.671451 loss)
I0530 05:38:43.703100 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0691995 (* 1 = 0.0691995 loss)
I0530 05:38:43.703102 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.268856 (* 1 = 0.268856 loss)
I0530 05:38:43.703107 24924 sgd_solver.cpp:106] Iteration 11200, lr = 0.0002
I0530 05:39:32.313657 24924 solver.cpp:228] Iteration 11220, loss = 0.388728
I0530 05:39:32.313678 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 05:39:32.313686 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.223068 (* 1 = 0.223068 loss)
I0530 05:39:32.313705 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.346616 (* 1 = 0.346616 loss)
I0530 05:39:32.313710 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0220462 (* 1 = 0.0220462 loss)
I0530 05:39:32.313715 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102379 (* 1 = 0.102379 loss)
I0530 05:39:32.313720 24924 sgd_solver.cpp:106] Iteration 11220, lr = 0.0002
I0530 05:40:20.858665 24924 solver.cpp:228] Iteration 11240, loss = 0.331973
I0530 05:40:20.858700 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 05:40:20.858708 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.28598 (* 1 = 0.28598 loss)
I0530 05:40:20.858711 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.454592 (* 1 = 0.454592 loss)
I0530 05:40:20.858716 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0876507 (* 1 = 0.0876507 loss)
I0530 05:40:20.858721 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.193893 (* 1 = 0.193893 loss)
I0530 05:40:20.858726 24924 sgd_solver.cpp:106] Iteration 11240, lr = 0.0002
I0530 05:41:09.464722 24924 solver.cpp:228] Iteration 11260, loss = 0.43307
I0530 05:41:09.464757 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:41:09.464764 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0462744 (* 1 = 0.0462744 loss)
I0530 05:41:09.464767 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165264 (* 1 = 0.165264 loss)
I0530 05:41:09.464771 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00929641 (* 1 = 0.00929641 loss)
I0530 05:41:09.464773 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0396176 (* 1 = 0.0396176 loss)
I0530 05:41:09.464778 24924 sgd_solver.cpp:106] Iteration 11260, lr = 0.0002
I0530 05:41:58.053319 24924 solver.cpp:228] Iteration 11280, loss = 0.202235
I0530 05:41:58.053355 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 05:41:58.053362 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.079441 (* 1 = 0.079441 loss)
I0530 05:41:58.053366 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.174478 (* 1 = 0.174478 loss)
I0530 05:41:58.053369 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010642 (* 1 = 0.010642 loss)
I0530 05:41:58.053372 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203139 (* 1 = 0.0203139 loss)
I0530 05:41:58.053376 24924 sgd_solver.cpp:106] Iteration 11280, lr = 0.0002
I0530 05:42:46.632149 24924 solver.cpp:228] Iteration 11300, loss = 0.222788
I0530 05:42:46.632171 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 05:42:46.632179 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245696 (* 1 = 0.0245696 loss)
I0530 05:42:46.632181 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0904565 (* 1 = 0.0904565 loss)
I0530 05:42:46.632185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00350352 (* 1 = 0.00350352 loss)
I0530 05:42:46.632189 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00346377 (* 1 = 0.00346377 loss)
I0530 05:42:46.632192 24924 sgd_solver.cpp:106] Iteration 11300, lr = 0.0002
I0530 05:43:35.217447 24924 solver.cpp:228] Iteration 11320, loss = 0.277019
I0530 05:43:35.217483 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 05:43:35.217489 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.166291 (* 1 = 0.166291 loss)
I0530 05:43:35.217492 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.210148 (* 1 = 0.210148 loss)
I0530 05:43:35.217496 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0184107 (* 1 = 0.0184107 loss)
I0530 05:43:35.217499 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.069689 (* 1 = 0.069689 loss)
I0530 05:43:35.217504 24924 sgd_solver.cpp:106] Iteration 11320, lr = 0.0002
I0530 05:44:23.812916 24924 solver.cpp:228] Iteration 11340, loss = 0.256788
I0530 05:44:23.812954 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 05:44:23.812961 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0330975 (* 1 = 0.0330975 loss)
I0530 05:44:23.812965 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0880707 (* 1 = 0.0880707 loss)
I0530 05:44:23.812968 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00289217 (* 1 = 0.00289217 loss)
I0530 05:44:23.812973 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00897499 (* 1 = 0.00897499 loss)
I0530 05:44:23.812975 24924 sgd_solver.cpp:106] Iteration 11340, lr = 0.0002
I0530 05:45:12.367681 24924 solver.cpp:228] Iteration 11360, loss = 0.275551
I0530 05:45:12.367717 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 05:45:12.367725 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00202481 (* 1 = 0.00202481 loss)
I0530 05:45:12.367729 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0306411 (* 1 = 0.0306411 loss)
I0530 05:45:12.367733 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00479105 (* 1 = 0.00479105 loss)
I0530 05:45:12.367735 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0465197 (* 1 = 0.0465197 loss)
I0530 05:45:12.367740 24924 sgd_solver.cpp:106] Iteration 11360, lr = 0.0002
I0530 05:46:00.936846 24924 solver.cpp:228] Iteration 11380, loss = 0.409869
I0530 05:46:00.936882 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 05:46:00.936889 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.407657 (* 1 = 0.407657 loss)
I0530 05:46:00.936893 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.414963 (* 1 = 0.414963 loss)
I0530 05:46:00.936897 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171271 (* 1 = 0.0171271 loss)
I0530 05:46:00.936899 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0685607 (* 1 = 0.0685607 loss)
I0530 05:46:00.936903 24924 sgd_solver.cpp:106] Iteration 11380, lr = 0.0002
speed: 2.437s / iter
I0530 05:46:49.506327 24924 solver.cpp:228] Iteration 11400, loss = 0.341301
I0530 05:46:49.506366 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:46:49.506372 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.051042 (* 1 = 0.051042 loss)
I0530 05:46:49.506376 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.103587 (* 1 = 0.103587 loss)
I0530 05:46:49.506379 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235276 (* 1 = 0.00235276 loss)
I0530 05:46:49.506382 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013814 (* 1 = 0.013814 loss)
I0530 05:46:49.506386 24924 sgd_solver.cpp:106] Iteration 11400, lr = 0.0002
I0530 05:47:38.088049 24924 solver.cpp:228] Iteration 11420, loss = 0.29134
I0530 05:47:38.088085 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 05:47:38.088093 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0616363 (* 1 = 0.0616363 loss)
I0530 05:47:38.088096 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.208483 (* 1 = 0.208483 loss)
I0530 05:47:38.088099 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363553 (* 1 = 0.00363553 loss)
I0530 05:47:38.088102 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322187 (* 1 = 0.0322187 loss)
I0530 05:47:38.088107 24924 sgd_solver.cpp:106] Iteration 11420, lr = 0.0002
I0530 05:48:26.668568 24924 solver.cpp:228] Iteration 11440, loss = 0.496571
I0530 05:48:26.668604 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 05:48:26.668612 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00309718 (* 1 = 0.00309718 loss)
I0530 05:48:26.668615 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0670013 (* 1 = 0.0670013 loss)
I0530 05:48:26.668619 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0266378 (* 1 = 0.0266378 loss)
I0530 05:48:26.668622 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113397 (* 1 = 0.113397 loss)
I0530 05:48:26.668627 24924 sgd_solver.cpp:106] Iteration 11440, lr = 0.0002
I0530 05:49:15.303611 24924 solver.cpp:228] Iteration 11460, loss = 0.279612
I0530 05:49:15.303645 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 05:49:15.303652 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.232775 (* 1 = 0.232775 loss)
I0530 05:49:15.303655 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.340558 (* 1 = 0.340558 loss)
I0530 05:49:15.303659 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00863771 (* 1 = 0.00863771 loss)
I0530 05:49:15.303663 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0885769 (* 1 = 0.0885769 loss)
I0530 05:49:15.303666 24924 sgd_solver.cpp:106] Iteration 11460, lr = 0.0002
I0530 05:50:03.881520 24924 solver.cpp:228] Iteration 11480, loss = 0.501636
I0530 05:50:03.881556 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 05:50:03.881562 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.292343 (* 1 = 0.292343 loss)
I0530 05:50:03.881566 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.392651 (* 1 = 0.392651 loss)
I0530 05:50:03.881569 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122757 (* 1 = 0.0122757 loss)
I0530 05:50:03.881572 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0548741 (* 1 = 0.0548741 loss)
I0530 05:50:03.881577 24924 sgd_solver.cpp:106] Iteration 11480, lr = 0.0002
I0530 05:50:52.500212 24924 solver.cpp:228] Iteration 11500, loss = 0.318049
I0530 05:50:52.500247 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:50:52.500253 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00291788 (* 1 = 0.00291788 loss)
I0530 05:50:52.500257 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0670926 (* 1 = 0.0670926 loss)
I0530 05:50:52.500260 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0067256 (* 1 = 0.0067256 loss)
I0530 05:50:52.500263 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00377624 (* 1 = 0.00377624 loss)
I0530 05:50:52.500267 24924 sgd_solver.cpp:106] Iteration 11500, lr = 0.0002
I0530 05:51:41.038625 24924 solver.cpp:228] Iteration 11520, loss = 0.359915
I0530 05:51:41.038646 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 05:51:41.038667 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0797702 (* 1 = 0.0797702 loss)
I0530 05:51:41.038671 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.118532 (* 1 = 0.118532 loss)
I0530 05:51:41.038674 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00249907 (* 1 = 0.00249907 loss)
I0530 05:51:41.038677 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222665 (* 1 = 0.0222665 loss)
I0530 05:51:41.038681 24924 sgd_solver.cpp:106] Iteration 11520, lr = 0.0002
I0530 05:52:29.598569 24924 solver.cpp:228] Iteration 11540, loss = 0.294229
I0530 05:52:29.598592 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 05:52:29.598598 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509258 (* 1 = 0.0509258 loss)
I0530 05:52:29.598603 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.182753 (* 1 = 0.182753 loss)
I0530 05:52:29.598605 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197812 (* 1 = 0.0197812 loss)
I0530 05:52:29.598608 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0837841 (* 1 = 0.0837841 loss)
I0530 05:52:29.598613 24924 sgd_solver.cpp:106] Iteration 11540, lr = 0.0002
I0530 05:53:18.190773 24924 solver.cpp:228] Iteration 11560, loss = 0.336137
I0530 05:53:18.190809 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 05:53:18.190816 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0631561 (* 1 = 0.0631561 loss)
I0530 05:53:18.190820 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.07018 (* 1 = 0.07018 loss)
I0530 05:53:18.190824 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0347589 (* 1 = 0.0347589 loss)
I0530 05:53:18.190826 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.150124 (* 1 = 0.150124 loss)
I0530 05:53:18.190830 24924 sgd_solver.cpp:106] Iteration 11560, lr = 0.0002
I0530 05:54:06.762733 24924 solver.cpp:228] Iteration 11580, loss = 0.303438
I0530 05:54:06.762758 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 05:54:06.762768 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0381987 (* 1 = 0.0381987 loss)
I0530 05:54:06.762773 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0970628 (* 1 = 0.0970628 loss)
I0530 05:54:06.762778 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00578092 (* 1 = 0.00578092 loss)
I0530 05:54:06.762782 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00900456 (* 1 = 0.00900456 loss)
I0530 05:54:06.762789 24924 sgd_solver.cpp:106] Iteration 11580, lr = 0.0002
speed: 2.436s / iter
I0530 05:54:55.341037 24924 solver.cpp:228] Iteration 11600, loss = 0.203704
I0530 05:54:55.341058 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 05:54:55.341065 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0232308 (* 1 = 0.0232308 loss)
I0530 05:54:55.341069 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.120697 (* 1 = 0.120697 loss)
I0530 05:54:55.341073 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0242845 (* 1 = 0.0242845 loss)
I0530 05:54:55.341074 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229997 (* 1 = 0.0229997 loss)
I0530 05:54:55.341078 24924 sgd_solver.cpp:106] Iteration 11600, lr = 0.0002
I0530 05:55:43.940773 24924 solver.cpp:228] Iteration 11620, loss = 0.392598
I0530 05:55:43.940809 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 05:55:43.940814 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.169965 (* 1 = 0.169965 loss)
I0530 05:55:43.940819 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.323648 (* 1 = 0.323648 loss)
I0530 05:55:43.940821 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0432134 (* 1 = 0.0432134 loss)
I0530 05:55:43.940824 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0573196 (* 1 = 0.0573196 loss)
I0530 05:55:43.940829 24924 sgd_solver.cpp:106] Iteration 11620, lr = 0.0002
I0530 05:56:32.524870 24924 solver.cpp:228] Iteration 11640, loss = 0.221561
I0530 05:56:32.524906 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 05:56:32.524915 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.200541 (* 1 = 0.200541 loss)
I0530 05:56:32.524919 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.299818 (* 1 = 0.299818 loss)
I0530 05:56:32.524924 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116565 (* 1 = 0.0116565 loss)
I0530 05:56:32.524926 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141571 (* 1 = 0.0141571 loss)
I0530 05:56:32.524930 24924 sgd_solver.cpp:106] Iteration 11640, lr = 0.0002
I0530 05:57:21.138592 24924 solver.cpp:228] Iteration 11660, loss = 0.31396
I0530 05:57:21.138628 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 05:57:21.138635 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00108339 (* 1 = 0.00108339 loss)
I0530 05:57:21.138639 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0380202 (* 1 = 0.0380202 loss)
I0530 05:57:21.138643 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.034909 (* 1 = 0.034909 loss)
I0530 05:57:21.138645 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105442 (* 1 = 0.0105442 loss)
I0530 05:57:21.138650 24924 sgd_solver.cpp:106] Iteration 11660, lr = 0.0002
I0530 05:58:09.749730 24924 solver.cpp:228] Iteration 11680, loss = 0.256609
I0530 05:58:09.749766 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 05:58:09.749774 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.104492 (* 1 = 0.104492 loss)
I0530 05:58:09.749778 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272086 (* 1 = 0.272086 loss)
I0530 05:58:09.749781 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171916 (* 1 = 0.0171916 loss)
I0530 05:58:09.749784 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023333 (* 1 = 0.023333 loss)
I0530 05:58:09.749789 24924 sgd_solver.cpp:106] Iteration 11680, lr = 0.0002
I0530 05:58:58.351013 24924 solver.cpp:228] Iteration 11700, loss = 0.294853
I0530 05:58:58.351049 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 05:58:58.351058 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00257852 (* 1 = 0.00257852 loss)
I0530 05:58:58.351061 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0749356 (* 1 = 0.0749356 loss)
I0530 05:58:58.351065 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0430475 (* 1 = 0.0430475 loss)
I0530 05:58:58.351071 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170864 (* 1 = 0.0170864 loss)
I0530 05:58:58.351078 24924 sgd_solver.cpp:106] Iteration 11700, lr = 0.0002
I0530 05:59:47.034998 24924 solver.cpp:228] Iteration 11720, loss = 0.2889
I0530 05:59:47.035034 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 05:59:47.035040 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0654691 (* 1 = 0.0654691 loss)
I0530 05:59:47.035044 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0982786 (* 1 = 0.0982786 loss)
I0530 05:59:47.035048 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00628268 (* 1 = 0.00628268 loss)
I0530 05:59:47.035053 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164549 (* 1 = 0.0164549 loss)
I0530 05:59:47.035058 24924 sgd_solver.cpp:106] Iteration 11720, lr = 0.0002
I0530 06:00:35.673259 24924 solver.cpp:228] Iteration 11740, loss = 0.629497
I0530 06:00:35.673285 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 06:00:35.673291 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.26554 (* 1 = 0.26554 loss)
I0530 06:00:35.673295 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.493555 (* 1 = 0.493555 loss)
I0530 06:00:35.673300 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185301 (* 1 = 0.0185301 loss)
I0530 06:00:35.673302 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275378 (* 1 = 0.0275378 loss)
I0530 06:00:35.673307 24924 sgd_solver.cpp:106] Iteration 11740, lr = 0.0002
I0530 06:01:24.296988 24924 solver.cpp:228] Iteration 11760, loss = 0.192653
I0530 06:01:24.297011 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:01:24.297031 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0579873 (* 1 = 0.0579873 loss)
I0530 06:01:24.297035 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142767 (* 1 = 0.142767 loss)
I0530 06:01:24.297039 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0325392 (* 1 = 0.0325392 loss)
I0530 06:01:24.297041 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195444 (* 1 = 0.0195444 loss)
I0530 06:01:24.297045 24924 sgd_solver.cpp:106] Iteration 11760, lr = 0.0002
I0530 06:02:12.943174 24924 solver.cpp:228] Iteration 11780, loss = 0.374974
I0530 06:02:12.943210 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:02:12.943217 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0668399 (* 1 = 0.0668399 loss)
I0530 06:02:12.943222 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.191303 (* 1 = 0.191303 loss)
I0530 06:02:12.943224 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0164548 (* 1 = 0.0164548 loss)
I0530 06:02:12.943228 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0138833 (* 1 = 0.0138833 loss)
I0530 06:02:12.943231 24924 sgd_solver.cpp:106] Iteration 11780, lr = 0.0002
speed: 2.436s / iter
I0530 06:03:01.536644 24924 solver.cpp:228] Iteration 11800, loss = 0.251465
I0530 06:03:01.536680 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:03:01.536687 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0439387 (* 1 = 0.0439387 loss)
I0530 06:03:01.536690 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109282 (* 1 = 0.109282 loss)
I0530 06:03:01.536695 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000745597 (* 1 = 0.000745597 loss)
I0530 06:03:01.536697 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125221 (* 1 = 0.0125221 loss)
I0530 06:03:01.536701 24924 sgd_solver.cpp:106] Iteration 11800, lr = 0.0002
I0530 06:03:50.250823 24924 solver.cpp:228] Iteration 11820, loss = 0.189503
I0530 06:03:50.250857 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 06:03:50.250864 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0896946 (* 1 = 0.0896946 loss)
I0530 06:03:50.250869 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.146943 (* 1 = 0.146943 loss)
I0530 06:03:50.250871 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00475907 (* 1 = 0.00475907 loss)
I0530 06:03:50.250874 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0121218 (* 1 = 0.0121218 loss)
I0530 06:03:50.250879 24924 sgd_solver.cpp:106] Iteration 11820, lr = 0.0002
I0530 06:04:38.984956 24924 solver.cpp:228] Iteration 11840, loss = 0.346184
I0530 06:04:38.984982 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:04:38.984988 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589824 (* 1 = 0.0589824 loss)
I0530 06:04:38.984992 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123585 (* 1 = 0.123585 loss)
I0530 06:04:38.984995 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0240164 (* 1 = 0.0240164 loss)
I0530 06:04:38.984998 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263113 (* 1 = 0.0263113 loss)
I0530 06:04:38.985002 24924 sgd_solver.cpp:106] Iteration 11840, lr = 0.0002
I0530 06:05:27.685930 24924 solver.cpp:228] Iteration 11860, loss = 0.29395
I0530 06:05:27.685966 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 06:05:27.685973 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316153 (* 1 = 0.0316153 loss)
I0530 06:05:27.685977 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0964029 (* 1 = 0.0964029 loss)
I0530 06:05:27.685981 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032909 (* 1 = 0.0032909 loss)
I0530 06:05:27.685983 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218189 (* 1 = 0.0218189 loss)
I0530 06:05:27.685987 24924 sgd_solver.cpp:106] Iteration 11860, lr = 0.0002
I0530 06:06:16.358537 24924 solver.cpp:228] Iteration 11880, loss = 0.382388
I0530 06:06:16.358572 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 06:06:16.358579 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.105641 (* 1 = 0.105641 loss)
I0530 06:06:16.358582 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.215155 (* 1 = 0.215155 loss)
I0530 06:06:16.358587 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00973259 (* 1 = 0.00973259 loss)
I0530 06:06:16.358589 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.050798 (* 1 = 0.050798 loss)
I0530 06:06:16.358593 24924 sgd_solver.cpp:106] Iteration 11880, lr = 0.0002
I0530 06:07:05.029469 24924 solver.cpp:228] Iteration 11900, loss = 0.354228
I0530 06:07:05.029506 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 06:07:05.029513 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207605 (* 1 = 0.0207605 loss)
I0530 06:07:05.029516 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.158678 (* 1 = 0.158678 loss)
I0530 06:07:05.029520 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0189751 (* 1 = 0.0189751 loss)
I0530 06:07:05.029523 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0295413 (* 1 = 0.0295413 loss)
I0530 06:07:05.029527 24924 sgd_solver.cpp:106] Iteration 11900, lr = 0.0002
I0530 06:07:53.736737 24924 solver.cpp:228] Iteration 11920, loss = 0.283997
I0530 06:07:53.736758 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 06:07:53.736764 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.185956 (* 1 = 0.185956 loss)
I0530 06:07:53.736768 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.364559 (* 1 = 0.364559 loss)
I0530 06:07:53.736771 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0258808 (* 1 = 0.0258808 loss)
I0530 06:07:53.736774 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0427885 (* 1 = 0.0427885 loss)
I0530 06:07:53.736778 24924 sgd_solver.cpp:106] Iteration 11920, lr = 0.0002
I0530 06:08:42.407862 24924 solver.cpp:228] Iteration 11940, loss = 0.283994
I0530 06:08:42.407886 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 06:08:42.407894 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000534102 (* 1 = 0.000534102 loss)
I0530 06:08:42.407898 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0522442 (* 1 = 0.0522442 loss)
I0530 06:08:42.407902 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00539192 (* 1 = 0.00539192 loss)
I0530 06:08:42.407905 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190961 (* 1 = 0.0190961 loss)
I0530 06:08:42.407909 24924 sgd_solver.cpp:106] Iteration 11940, lr = 0.0002
I0530 06:09:31.161355 24924 solver.cpp:228] Iteration 11960, loss = 0.371707
I0530 06:09:31.161391 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 06:09:31.161399 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.221248 (* 1 = 0.221248 loss)
I0530 06:09:31.161402 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.196547 (* 1 = 0.196547 loss)
I0530 06:09:31.161406 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167995 (* 1 = 0.0167995 loss)
I0530 06:09:31.161409 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0543537 (* 1 = 0.0543537 loss)
I0530 06:09:31.161413 24924 sgd_solver.cpp:106] Iteration 11960, lr = 0.0002
I0530 06:10:19.862241 24924 solver.cpp:228] Iteration 11980, loss = 0.566272
I0530 06:10:19.862277 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 06:10:19.862283 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.210661 (* 1 = 0.210661 loss)
I0530 06:10:19.862287 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.308294 (* 1 = 0.308294 loss)
I0530 06:10:19.862289 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0275093 (* 1 = 0.0275093 loss)
I0530 06:10:19.862293 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0914392 (* 1 = 0.0914392 loss)
I0530 06:10:19.862298 24924 sgd_solver.cpp:106] Iteration 11980, lr = 0.0002
speed: 2.436s / iter
I0530 06:11:08.604765 24924 solver.cpp:228] Iteration 12000, loss = 0.708339
I0530 06:11:08.604801 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 06:11:08.604807 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.14846 (* 1 = 0.14846 loss)
I0530 06:11:08.604811 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.199926 (* 1 = 0.199926 loss)
I0530 06:11:08.604815 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053937 (* 1 = 0.0053937 loss)
I0530 06:11:08.604817 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0563413 (* 1 = 0.0563413 loss)
I0530 06:11:08.604821 24924 sgd_solver.cpp:106] Iteration 12000, lr = 0.0002
I0530 06:11:57.442679 24924 solver.cpp:228] Iteration 12020, loss = 0.319663
I0530 06:11:57.442714 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 06:11:57.442720 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.159547 (* 1 = 0.159547 loss)
I0530 06:11:57.442724 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.328235 (* 1 = 0.328235 loss)
I0530 06:11:57.442728 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142028 (* 1 = 0.0142028 loss)
I0530 06:11:57.442730 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0556028 (* 1 = 0.0556028 loss)
I0530 06:11:57.442734 24924 sgd_solver.cpp:106] Iteration 12020, lr = 0.0002
I0530 06:12:46.240116 24924 solver.cpp:228] Iteration 12040, loss = 0.212313
I0530 06:12:46.240152 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 06:12:46.240159 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627426 (* 1 = 0.0627426 loss)
I0530 06:12:46.240164 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.203004 (* 1 = 0.203004 loss)
I0530 06:12:46.240166 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0282465 (* 1 = 0.0282465 loss)
I0530 06:12:46.240170 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00433762 (* 1 = 0.00433762 loss)
I0530 06:12:46.240175 24924 sgd_solver.cpp:106] Iteration 12040, lr = 0.0002
I0530 06:13:35.161149 24924 solver.cpp:228] Iteration 12060, loss = 0.528391
I0530 06:13:35.161171 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 06:13:35.161178 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.235694 (* 1 = 0.235694 loss)
I0530 06:13:35.161182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.377634 (* 1 = 0.377634 loss)
I0530 06:13:35.161185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00936803 (* 1 = 0.00936803 loss)
I0530 06:13:35.161190 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0435602 (* 1 = 0.0435602 loss)
I0530 06:13:35.161193 24924 sgd_solver.cpp:106] Iteration 12060, lr = 0.0002
I0530 06:14:24.084985 24924 solver.cpp:228] Iteration 12080, loss = 0.225197
I0530 06:14:24.085019 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 06:14:24.085026 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.108586 (* 1 = 0.108586 loss)
I0530 06:14:24.085029 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272353 (* 1 = 0.272353 loss)
I0530 06:14:24.085032 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00599347 (* 1 = 0.00599347 loss)
I0530 06:14:24.085036 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0415247 (* 1 = 0.0415247 loss)
I0530 06:14:24.085039 24924 sgd_solver.cpp:106] Iteration 12080, lr = 0.0002
I0530 06:15:13.021065 24924 solver.cpp:228] Iteration 12100, loss = 0.217642
I0530 06:15:13.021090 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 06:15:13.021098 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.017919 (* 1 = 0.017919 loss)
I0530 06:15:13.021104 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0394839 (* 1 = 0.0394839 loss)
I0530 06:15:13.021109 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122902 (* 1 = 0.0122902 loss)
I0530 06:15:13.021114 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00712019 (* 1 = 0.00712019 loss)
I0530 06:15:13.021121 24924 sgd_solver.cpp:106] Iteration 12100, lr = 0.0002
I0530 06:16:01.905251 24924 solver.cpp:228] Iteration 12120, loss = 0.432182
I0530 06:16:01.905285 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 06:16:01.905292 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.203546 (* 1 = 0.203546 loss)
I0530 06:16:01.905294 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.307071 (* 1 = 0.307071 loss)
I0530 06:16:01.905298 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010365 (* 1 = 0.010365 loss)
I0530 06:16:01.905302 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.076069 (* 1 = 0.076069 loss)
I0530 06:16:01.905305 24924 sgd_solver.cpp:106] Iteration 12120, lr = 0.0002
I0530 06:16:50.781431 24924 solver.cpp:228] Iteration 12140, loss = 0.512019
I0530 06:16:50.781467 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 06:16:50.781473 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.157435 (* 1 = 0.157435 loss)
I0530 06:16:50.781477 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.224434 (* 1 = 0.224434 loss)
I0530 06:16:50.781481 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129446 (* 1 = 0.0129446 loss)
I0530 06:16:50.781483 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.035081 (* 1 = 0.035081 loss)
I0530 06:16:50.781487 24924 sgd_solver.cpp:106] Iteration 12140, lr = 0.0002
I0530 06:17:39.765774 24924 solver.cpp:228] Iteration 12160, loss = 0.326266
I0530 06:17:39.765796 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 06:17:39.765805 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.272496 (* 1 = 0.272496 loss)
I0530 06:17:39.765810 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.477168 (* 1 = 0.477168 loss)
I0530 06:17:39.765815 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00311556 (* 1 = 0.00311556 loss)
I0530 06:17:39.765820 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0594679 (* 1 = 0.0594679 loss)
I0530 06:17:39.765825 24924 sgd_solver.cpp:106] Iteration 12160, lr = 0.0002
I0530 06:18:28.655903 24924 solver.cpp:228] Iteration 12180, loss = 0.618914
I0530 06:18:28.655938 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0530 06:18:28.655946 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.253893 (* 1 = 0.253893 loss)
I0530 06:18:28.655948 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.460699 (* 1 = 0.460699 loss)
I0530 06:18:28.655951 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027449 (* 1 = 0.027449 loss)
I0530 06:18:28.655954 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.240542 (* 1 = 0.240542 loss)
I0530 06:18:28.655959 24924 sgd_solver.cpp:106] Iteration 12180, lr = 0.0002
speed: 2.437s / iter
I0530 06:19:17.610139 24924 solver.cpp:228] Iteration 12200, loss = 0.376794
I0530 06:19:17.610162 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 06:19:17.610168 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0188043 (* 1 = 0.0188043 loss)
I0530 06:19:17.610172 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.091427 (* 1 = 0.091427 loss)
I0530 06:19:17.610175 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00329453 (* 1 = 0.00329453 loss)
I0530 06:19:17.610178 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00786828 (* 1 = 0.00786828 loss)
I0530 06:19:17.610183 24924 sgd_solver.cpp:106] Iteration 12200, lr = 0.0002
I0530 06:20:06.545339 24924 solver.cpp:228] Iteration 12220, loss = 0.360334
I0530 06:20:06.545362 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 06:20:06.545369 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.15602 (* 1 = 0.15602 loss)
I0530 06:20:06.545372 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147844 (* 1 = 0.147844 loss)
I0530 06:20:06.545377 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00131151 (* 1 = 0.00131151 loss)
I0530 06:20:06.545380 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113516 (* 1 = 0.0113516 loss)
I0530 06:20:06.545384 24924 sgd_solver.cpp:106] Iteration 12220, lr = 0.0002
I0530 06:20:55.547482 24924 solver.cpp:228] Iteration 12240, loss = 0.311539
I0530 06:20:55.547505 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 06:20:55.547513 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.04978 (* 1 = 0.04978 loss)
I0530 06:20:55.547518 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.170624 (* 1 = 0.170624 loss)
I0530 06:20:55.547520 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0277109 (* 1 = 0.0277109 loss)
I0530 06:20:55.547523 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210989 (* 1 = 0.0210989 loss)
I0530 06:20:55.547528 24924 sgd_solver.cpp:106] Iteration 12240, lr = 0.0002
I0530 06:21:44.554824 24924 solver.cpp:228] Iteration 12260, loss = 0.236795
I0530 06:21:44.554847 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 06:21:44.554857 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312558 (* 1 = 0.0312558 loss)
I0530 06:21:44.554862 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0613213 (* 1 = 0.0613213 loss)
I0530 06:21:44.554867 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00223011 (* 1 = 0.00223011 loss)
I0530 06:21:44.554873 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00791356 (* 1 = 0.00791356 loss)
I0530 06:21:44.554882 24924 sgd_solver.cpp:106] Iteration 12260, lr = 0.0002
I0530 06:22:33.446555 24924 solver.cpp:228] Iteration 12280, loss = 0.270582
I0530 06:22:33.446590 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 06:22:33.446597 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.063408 (* 1 = 0.063408 loss)
I0530 06:22:33.446600 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.209712 (* 1 = 0.209712 loss)
I0530 06:22:33.446604 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178752 (* 1 = 0.0178752 loss)
I0530 06:22:33.446607 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00837866 (* 1 = 0.00837866 loss)
I0530 06:22:33.446611 24924 sgd_solver.cpp:106] Iteration 12280, lr = 0.0002
I0530 06:23:22.374852 24924 solver.cpp:228] Iteration 12300, loss = 0.461433
I0530 06:23:22.374876 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.546875
I0530 06:23:22.374883 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.741717 (* 1 = 0.741717 loss)
I0530 06:23:22.374902 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.726238 (* 1 = 0.726238 loss)
I0530 06:23:22.374907 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.077961 (* 1 = 0.077961 loss)
I0530 06:23:22.374912 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.505443 (* 1 = 0.505443 loss)
I0530 06:23:22.374918 24924 sgd_solver.cpp:106] Iteration 12300, lr = 0.0002
I0530 06:24:11.285389 24924 solver.cpp:228] Iteration 12320, loss = 0.416233
I0530 06:24:11.285413 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 06:24:11.285423 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0653432 (* 1 = 0.0653432 loss)
I0530 06:24:11.285429 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.103448 (* 1 = 0.103448 loss)
I0530 06:24:11.285434 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00427127 (* 1 = 0.00427127 loss)
I0530 06:24:11.285439 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112172 (* 1 = 0.0112172 loss)
I0530 06:24:11.285447 24924 sgd_solver.cpp:106] Iteration 12320, lr = 0.0002
I0530 06:25:00.201009 24924 solver.cpp:228] Iteration 12340, loss = 0.46245
I0530 06:25:00.201045 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 06:25:00.201052 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327724 (* 1 = 0.0327724 loss)
I0530 06:25:00.201056 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.14513 (* 1 = 0.14513 loss)
I0530 06:25:00.201059 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162445 (* 1 = 0.0162445 loss)
I0530 06:25:00.201062 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159172 (* 1 = 0.0159172 loss)
I0530 06:25:00.201067 24924 sgd_solver.cpp:106] Iteration 12340, lr = 0.0002
I0530 06:25:49.029855 24924 solver.cpp:228] Iteration 12360, loss = 0.251937
I0530 06:25:49.029891 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 06:25:49.029897 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.108098 (* 1 = 0.108098 loss)
I0530 06:25:49.029901 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.198698 (* 1 = 0.198698 loss)
I0530 06:25:49.029904 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0200233 (* 1 = 0.0200233 loss)
I0530 06:25:49.029907 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136272 (* 1 = 0.0136272 loss)
I0530 06:25:49.029911 24924 sgd_solver.cpp:106] Iteration 12360, lr = 0.0002
I0530 06:26:37.915565 24924 solver.cpp:228] Iteration 12380, loss = 0.353624
I0530 06:26:37.915588 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 06:26:37.915596 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0257496 (* 1 = 0.0257496 loss)
I0530 06:26:37.915599 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0422366 (* 1 = 0.0422366 loss)
I0530 06:26:37.915602 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00672739 (* 1 = 0.00672739 loss)
I0530 06:26:37.915606 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174585 (* 1 = 0.0174585 loss)
I0530 06:26:37.915611 24924 sgd_solver.cpp:106] Iteration 12380, lr = 0.0002
speed: 2.437s / iter
I0530 06:27:26.795135 24924 solver.cpp:228] Iteration 12400, loss = 0.310799
I0530 06:27:26.795171 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 06:27:26.795177 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.24509 (* 1 = 0.24509 loss)
I0530 06:27:26.795181 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.307853 (* 1 = 0.307853 loss)
I0530 06:27:26.795184 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133097 (* 1 = 0.0133097 loss)
I0530 06:27:26.795189 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0899798 (* 1 = 0.0899798 loss)
I0530 06:27:26.795195 24924 sgd_solver.cpp:106] Iteration 12400, lr = 0.0002
I0530 06:28:15.696215 24924 solver.cpp:228] Iteration 12420, loss = 0.367664
I0530 06:28:15.696250 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 06:28:15.696259 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0964282 (* 1 = 0.0964282 loss)
I0530 06:28:15.696262 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.111149 (* 1 = 0.111149 loss)
I0530 06:28:15.696265 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0156769 (* 1 = 0.0156769 loss)
I0530 06:28:15.696269 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0655967 (* 1 = 0.0655967 loss)
I0530 06:28:15.696274 24924 sgd_solver.cpp:106] Iteration 12420, lr = 0.0002
I0530 06:29:04.515676 24924 solver.cpp:228] Iteration 12440, loss = 0.39475
I0530 06:29:04.515712 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 06:29:04.515719 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000427037 (* 1 = 0.000427037 loss)
I0530 06:29:04.515722 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0628116 (* 1 = 0.0628116 loss)
I0530 06:29:04.515727 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191115 (* 1 = 0.0191115 loss)
I0530 06:29:04.515729 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116165 (* 1 = 0.0116165 loss)
I0530 06:29:04.515733 24924 sgd_solver.cpp:106] Iteration 12440, lr = 0.0002
I0530 06:29:53.324054 24924 solver.cpp:228] Iteration 12460, loss = 0.373285
I0530 06:29:53.324090 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 06:29:53.324097 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0465205 (* 1 = 0.0465205 loss)
I0530 06:29:53.324101 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.158692 (* 1 = 0.158692 loss)
I0530 06:29:53.324105 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136558 (* 1 = 0.0136558 loss)
I0530 06:29:53.324107 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0068539 (* 1 = 0.0068539 loss)
I0530 06:29:53.324111 24924 sgd_solver.cpp:106] Iteration 12460, lr = 0.0002
I0530 06:30:42.203384 24924 solver.cpp:228] Iteration 12480, loss = 0.413744
I0530 06:30:42.203408 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 06:30:42.203415 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182685 (* 1 = 0.0182685 loss)
I0530 06:30:42.203419 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124571 (* 1 = 0.124571 loss)
I0530 06:30:42.203423 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134952 (* 1 = 0.0134952 loss)
I0530 06:30:42.203425 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136168 (* 1 = 0.0136168 loss)
I0530 06:30:42.203430 24924 sgd_solver.cpp:106] Iteration 12480, lr = 0.0002
I0530 06:31:30.998176 24924 solver.cpp:228] Iteration 12500, loss = 0.261137
I0530 06:31:30.998198 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 06:31:30.998205 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511973 (* 1 = 0.0511973 loss)
I0530 06:31:30.998209 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.136399 (* 1 = 0.136399 loss)
I0530 06:31:30.998214 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00368005 (* 1 = 0.00368005 loss)
I0530 06:31:30.998216 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101261 (* 1 = 0.0101261 loss)
I0530 06:31:30.998222 24924 sgd_solver.cpp:106] Iteration 12500, lr = 0.0002
I0530 06:32:19.731467 24924 solver.cpp:228] Iteration 12520, loss = 0.311007
I0530 06:32:19.731503 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 06:32:19.731510 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.1138 (* 1 = 0.1138 loss)
I0530 06:32:19.731513 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.210753 (* 1 = 0.210753 loss)
I0530 06:32:19.731518 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149221 (* 1 = 0.0149221 loss)
I0530 06:32:19.731520 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0455277 (* 1 = 0.0455277 loss)
I0530 06:32:19.731524 24924 sgd_solver.cpp:106] Iteration 12520, lr = 0.0002
I0530 06:33:08.467756 24924 solver.cpp:228] Iteration 12540, loss = 0.318044
I0530 06:33:08.467779 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 06:33:08.467787 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0628176 (* 1 = 0.0628176 loss)
I0530 06:33:08.467790 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0812183 (* 1 = 0.0812183 loss)
I0530 06:33:08.467793 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00638603 (* 1 = 0.00638603 loss)
I0530 06:33:08.467797 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205136 (* 1 = 0.0205136 loss)
I0530 06:33:08.467802 24924 sgd_solver.cpp:106] Iteration 12540, lr = 0.0002
I0530 06:33:57.161334 24924 solver.cpp:228] Iteration 12560, loss = 0.263773
I0530 06:33:57.161370 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 06:33:57.161376 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0981809 (* 1 = 0.0981809 loss)
I0530 06:33:57.161381 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0714166 (* 1 = 0.0714166 loss)
I0530 06:33:57.161383 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00603117 (* 1 = 0.00603117 loss)
I0530 06:33:57.161386 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201465 (* 1 = 0.0201465 loss)
I0530 06:33:57.161391 24924 sgd_solver.cpp:106] Iteration 12560, lr = 0.0002
I0530 06:34:45.813828 24924 solver.cpp:228] Iteration 12580, loss = 0.326377
I0530 06:34:45.813864 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 06:34:45.813871 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.281399 (* 1 = 0.281399 loss)
I0530 06:34:45.813875 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.364558 (* 1 = 0.364558 loss)
I0530 06:34:45.813879 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0219528 (* 1 = 0.0219528 loss)
I0530 06:34:45.813881 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0564245 (* 1 = 0.0564245 loss)
I0530 06:34:45.813885 24924 sgd_solver.cpp:106] Iteration 12580, lr = 0.0002
speed: 2.437s / iter
I0530 06:35:34.389550 24924 solver.cpp:228] Iteration 12600, loss = 0.367216
I0530 06:35:34.389585 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 06:35:34.389591 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.378537 (* 1 = 0.378537 loss)
I0530 06:35:34.389595 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.528007 (* 1 = 0.528007 loss)
I0530 06:35:34.389598 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0168636 (* 1 = 0.0168636 loss)
I0530 06:35:34.389601 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0685742 (* 1 = 0.0685742 loss)
I0530 06:35:34.389606 24924 sgd_solver.cpp:106] Iteration 12600, lr = 0.0002
I0530 06:36:23.083415 24924 solver.cpp:228] Iteration 12620, loss = 0.482811
I0530 06:36:23.083436 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 06:36:23.083443 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0853252 (* 1 = 0.0853252 loss)
I0530 06:36:23.083447 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102682 (* 1 = 0.102682 loss)
I0530 06:36:23.083451 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00870486 (* 1 = 0.00870486 loss)
I0530 06:36:23.083453 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00965064 (* 1 = 0.00965064 loss)
I0530 06:36:23.083457 24924 sgd_solver.cpp:106] Iteration 12620, lr = 0.0002
I0530 06:37:11.738276 24924 solver.cpp:228] Iteration 12640, loss = 0.43555
I0530 06:37:11.738312 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 06:37:11.738319 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335102 (* 1 = 0.0335102 loss)
I0530 06:37:11.738323 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0516916 (* 1 = 0.0516916 loss)
I0530 06:37:11.738327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00225446 (* 1 = 0.00225446 loss)
I0530 06:37:11.738329 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00407185 (* 1 = 0.00407185 loss)
I0530 06:37:11.738333 24924 sgd_solver.cpp:106] Iteration 12640, lr = 0.0002
I0530 06:38:00.338348 24924 solver.cpp:228] Iteration 12660, loss = 0.32116
I0530 06:38:00.338383 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 06:38:00.338390 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.006111 (* 1 = 0.006111 loss)
I0530 06:38:00.338394 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0539581 (* 1 = 0.0539581 loss)
I0530 06:38:00.338397 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0270975 (* 1 = 0.0270975 loss)
I0530 06:38:00.338400 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0364335 (* 1 = 0.0364335 loss)
I0530 06:38:00.338404 24924 sgd_solver.cpp:106] Iteration 12660, lr = 0.0002
I0530 06:38:48.935278 24924 solver.cpp:228] Iteration 12680, loss = 0.330627
I0530 06:38:48.935302 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 06:38:48.935308 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.193393 (* 1 = 0.193393 loss)
I0530 06:38:48.935312 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.323202 (* 1 = 0.323202 loss)
I0530 06:38:48.935315 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010073 (* 1 = 0.010073 loss)
I0530 06:38:48.935318 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0461494 (* 1 = 0.0461494 loss)
I0530 06:38:48.935323 24924 sgd_solver.cpp:106] Iteration 12680, lr = 0.0002
I0530 06:39:37.597734 24924 solver.cpp:228] Iteration 12700, loss = 0.522005
I0530 06:39:37.597770 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 06:39:37.597777 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00524146 (* 1 = 0.00524146 loss)
I0530 06:39:37.597780 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0720908 (* 1 = 0.0720908 loss)
I0530 06:39:37.597784 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0308576 (* 1 = 0.0308576 loss)
I0530 06:39:37.597787 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0336118 (* 1 = 0.0336118 loss)
I0530 06:39:37.597792 24924 sgd_solver.cpp:106] Iteration 12700, lr = 0.0002
I0530 06:40:26.169112 24924 solver.cpp:228] Iteration 12720, loss = 0.475421
I0530 06:40:26.169148 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 06:40:26.169157 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.468659 (* 1 = 0.468659 loss)
I0530 06:40:26.169159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.481123 (* 1 = 0.481123 loss)
I0530 06:40:26.169163 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0581594 (* 1 = 0.0581594 loss)
I0530 06:40:26.169167 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.1948 (* 1 = 0.1948 loss)
I0530 06:40:26.169170 24924 sgd_solver.cpp:106] Iteration 12720, lr = 0.0002
I0530 06:41:14.850787 24924 solver.cpp:228] Iteration 12740, loss = 0.412007
I0530 06:41:14.850823 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 06:41:14.850831 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0115876 (* 1 = 0.0115876 loss)
I0530 06:41:14.850834 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104941 (* 1 = 0.104941 loss)
I0530 06:41:14.850837 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117979 (* 1 = 0.0117979 loss)
I0530 06:41:14.850841 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00928384 (* 1 = 0.00928384 loss)
I0530 06:41:14.850844 24924 sgd_solver.cpp:106] Iteration 12740, lr = 0.0002
I0530 06:42:03.468168 24924 solver.cpp:228] Iteration 12760, loss = 0.31548
I0530 06:42:03.468202 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:42:03.468210 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341161 (* 1 = 0.0341161 loss)
I0530 06:42:03.468214 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.12623 (* 1 = 0.12623 loss)
I0530 06:42:03.468217 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00596553 (* 1 = 0.00596553 loss)
I0530 06:42:03.468220 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00787591 (* 1 = 0.00787591 loss)
I0530 06:42:03.468225 24924 sgd_solver.cpp:106] Iteration 12760, lr = 0.0002
I0530 06:42:52.042340 24924 solver.cpp:228] Iteration 12780, loss = 0.363142
I0530 06:42:52.042374 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:42:52.042382 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0836626 (* 1 = 0.0836626 loss)
I0530 06:42:52.042385 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144825 (* 1 = 0.144825 loss)
I0530 06:42:52.042388 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0123304 (* 1 = 0.0123304 loss)
I0530 06:42:52.042392 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182179 (* 1 = 0.0182179 loss)
I0530 06:42:52.042397 24924 sgd_solver.cpp:106] Iteration 12780, lr = 0.0002
speed: 2.437s / iter
I0530 06:43:40.731729 24924 solver.cpp:228] Iteration 12800, loss = 0.314948
I0530 06:43:40.731765 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 06:43:40.731772 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0757829 (* 1 = 0.0757829 loss)
I0530 06:43:40.731775 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113732 (* 1 = 0.113732 loss)
I0530 06:43:40.731779 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00306885 (* 1 = 0.00306885 loss)
I0530 06:43:40.731782 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187848 (* 1 = 0.0187848 loss)
I0530 06:43:40.731786 24924 sgd_solver.cpp:106] Iteration 12800, lr = 0.0002
I0530 06:44:29.343895 24924 solver.cpp:228] Iteration 12820, loss = 0.350625
I0530 06:44:29.343931 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 06:44:29.343938 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474553 (* 1 = 0.0474553 loss)
I0530 06:44:29.343942 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.184064 (* 1 = 0.184064 loss)
I0530 06:44:29.343945 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00672263 (* 1 = 0.00672263 loss)
I0530 06:44:29.343948 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356932 (* 1 = 0.0356932 loss)
I0530 06:44:29.343953 24924 sgd_solver.cpp:106] Iteration 12820, lr = 0.0002
I0530 06:45:18.033205 24924 solver.cpp:228] Iteration 12840, loss = 0.437016
I0530 06:45:18.033241 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 06:45:18.033247 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0905243 (* 1 = 0.0905243 loss)
I0530 06:45:18.033251 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.202312 (* 1 = 0.202312 loss)
I0530 06:45:18.033253 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0247547 (* 1 = 0.0247547 loss)
I0530 06:45:18.033257 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272599 (* 1 = 0.0272599 loss)
I0530 06:45:18.033262 24924 sgd_solver.cpp:106] Iteration 12840, lr = 0.0002
I0530 06:46:06.624377 24924 solver.cpp:228] Iteration 12860, loss = 0.274277
I0530 06:46:06.624413 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 06:46:06.624420 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00606226 (* 1 = 0.00606226 loss)
I0530 06:46:06.624424 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0320366 (* 1 = 0.0320366 loss)
I0530 06:46:06.624428 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00925705 (* 1 = 0.00925705 loss)
I0530 06:46:06.624430 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213698 (* 1 = 0.0213698 loss)
I0530 06:46:06.624434 24924 sgd_solver.cpp:106] Iteration 12860, lr = 0.0002
I0530 06:46:55.247889 24924 solver.cpp:228] Iteration 12880, loss = 0.312523
I0530 06:46:55.247923 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 06:46:55.247930 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.198289 (* 1 = 0.198289 loss)
I0530 06:46:55.247933 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.348222 (* 1 = 0.348222 loss)
I0530 06:46:55.247936 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0262371 (* 1 = 0.0262371 loss)
I0530 06:46:55.247939 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.05211 (* 1 = 0.05211 loss)
I0530 06:46:55.247943 24924 sgd_solver.cpp:106] Iteration 12880, lr = 0.0002
I0530 06:47:43.848569 24924 solver.cpp:228] Iteration 12900, loss = 0.347444
I0530 06:47:43.848605 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 06:47:43.848613 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855393 (* 1 = 0.0855393 loss)
I0530 06:47:43.848615 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.239675 (* 1 = 0.239675 loss)
I0530 06:47:43.848619 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0245752 (* 1 = 0.0245752 loss)
I0530 06:47:43.848621 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0564988 (* 1 = 0.0564988 loss)
I0530 06:47:43.848626 24924 sgd_solver.cpp:106] Iteration 12900, lr = 0.0002
I0530 06:48:32.455574 24924 solver.cpp:228] Iteration 12920, loss = 0.268785
I0530 06:48:32.455610 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 06:48:32.455616 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.143785 (* 1 = 0.143785 loss)
I0530 06:48:32.455619 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.266183 (* 1 = 0.266183 loss)
I0530 06:48:32.455622 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0401881 (* 1 = 0.0401881 loss)
I0530 06:48:32.455626 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0437374 (* 1 = 0.0437374 loss)
I0530 06:48:32.455629 24924 sgd_solver.cpp:106] Iteration 12920, lr = 0.0002
I0530 06:49:21.082458 24924 solver.cpp:228] Iteration 12940, loss = 0.527532
I0530 06:49:21.082494 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.601562
I0530 06:49:21.082499 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.649787 (* 1 = 0.649787 loss)
I0530 06:49:21.082504 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.957031 (* 1 = 0.957031 loss)
I0530 06:49:21.082506 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154453 (* 1 = 0.0154453 loss)
I0530 06:49:21.082509 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.139295 (* 1 = 0.139295 loss)
I0530 06:49:21.082514 24924 sgd_solver.cpp:106] Iteration 12940, lr = 0.0002
I0530 06:50:09.714843 24924 solver.cpp:228] Iteration 12960, loss = 0.608668
I0530 06:50:09.714879 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 06:50:09.714886 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.117492 (* 1 = 0.117492 loss)
I0530 06:50:09.714890 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.370966 (* 1 = 0.370966 loss)
I0530 06:50:09.714892 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128502 (* 1 = 0.0128502 loss)
I0530 06:50:09.714895 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0362292 (* 1 = 0.0362292 loss)
I0530 06:50:09.714900 24924 sgd_solver.cpp:106] Iteration 12960, lr = 0.0002
I0530 06:50:58.368976 24924 solver.cpp:228] Iteration 12980, loss = 0.37426
I0530 06:50:58.369011 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 06:50:58.369019 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.147101 (* 1 = 0.147101 loss)
I0530 06:50:58.369021 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.331704 (* 1 = 0.331704 loss)
I0530 06:50:58.369025 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0365428 (* 1 = 0.0365428 loss)
I0530 06:50:58.369029 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0598047 (* 1 = 0.0598047 loss)
I0530 06:50:58.369032 24924 sgd_solver.cpp:106] Iteration 12980, lr = 0.0002
speed: 2.437s / iter
I0530 06:51:47.001700 24924 solver.cpp:228] Iteration 13000, loss = 0.258713
I0530 06:51:47.001736 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 06:51:47.001744 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561417 (* 1 = 0.0561417 loss)
I0530 06:51:47.001747 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144579 (* 1 = 0.144579 loss)
I0530 06:51:47.001751 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128468 (* 1 = 0.0128468 loss)
I0530 06:51:47.001754 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010577 (* 1 = 0.010577 loss)
I0530 06:51:47.001758 24924 sgd_solver.cpp:106] Iteration 13000, lr = 0.0002
I0530 06:52:35.656502 24924 solver.cpp:228] Iteration 13020, loss = 0.275366
I0530 06:52:35.656538 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 06:52:35.656544 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179184 (* 1 = 0.0179184 loss)
I0530 06:52:35.656548 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0859376 (* 1 = 0.0859376 loss)
I0530 06:52:35.656551 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00356319 (* 1 = 0.00356319 loss)
I0530 06:52:35.656555 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00237212 (* 1 = 0.00237212 loss)
I0530 06:52:35.656559 24924 sgd_solver.cpp:106] Iteration 13020, lr = 0.0002
I0530 06:53:24.271945 24924 solver.cpp:228] Iteration 13040, loss = 0.372449
I0530 06:53:24.271982 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 06:53:24.271989 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.143589 (* 1 = 0.143589 loss)
I0530 06:53:24.271992 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.203272 (* 1 = 0.203272 loss)
I0530 06:53:24.271996 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0194507 (* 1 = 0.0194507 loss)
I0530 06:53:24.271999 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184735 (* 1 = 0.0184735 loss)
I0530 06:53:24.272003 24924 sgd_solver.cpp:106] Iteration 13040, lr = 0.0002
I0530 06:54:12.863421 24924 solver.cpp:228] Iteration 13060, loss = 0.193687
I0530 06:54:12.863456 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 06:54:12.863463 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0341258 (* 1 = 0.0341258 loss)
I0530 06:54:12.863467 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0648383 (* 1 = 0.0648383 loss)
I0530 06:54:12.863471 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00720396 (* 1 = 0.00720396 loss)
I0530 06:54:12.863473 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161968 (* 1 = 0.0161968 loss)
I0530 06:54:12.863477 24924 sgd_solver.cpp:106] Iteration 13060, lr = 0.0002
I0530 06:55:01.535532 24924 solver.cpp:228] Iteration 13080, loss = 0.491559
I0530 06:55:01.535555 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 06:55:01.535563 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.124454 (* 1 = 0.124454 loss)
I0530 06:55:01.535567 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.321484 (* 1 = 0.321484 loss)
I0530 06:55:01.535570 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0207052 (* 1 = 0.0207052 loss)
I0530 06:55:01.535573 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0448438 (* 1 = 0.0448438 loss)
I0530 06:55:01.535578 24924 sgd_solver.cpp:106] Iteration 13080, lr = 0.0002
I0530 06:55:50.114933 24924 solver.cpp:228] Iteration 13100, loss = 0.402481
I0530 06:55:50.114955 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 06:55:50.114975 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937318 (* 1 = 0.0937318 loss)
I0530 06:55:50.114979 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.18766 (* 1 = 0.18766 loss)
I0530 06:55:50.114982 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0359733 (* 1 = 0.0359733 loss)
I0530 06:55:50.114985 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0318122 (* 1 = 0.0318122 loss)
I0530 06:55:50.114989 24924 sgd_solver.cpp:106] Iteration 13100, lr = 0.0002
I0530 06:56:38.801831 24924 solver.cpp:228] Iteration 13120, loss = 0.429764
I0530 06:56:38.801851 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 06:56:38.801857 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00145535 (* 1 = 0.00145535 loss)
I0530 06:56:38.801862 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0319661 (* 1 = 0.0319661 loss)
I0530 06:56:38.801864 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00525339 (* 1 = 0.00525339 loss)
I0530 06:56:38.801867 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200881 (* 1 = 0.0200881 loss)
I0530 06:56:38.801872 24924 sgd_solver.cpp:106] Iteration 13120, lr = 0.0002
I0530 06:57:27.416802 24924 solver.cpp:228] Iteration 13140, loss = 0.325555
I0530 06:57:27.416838 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 06:57:27.416846 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392348 (* 1 = 0.0392348 loss)
I0530 06:57:27.416849 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0807664 (* 1 = 0.0807664 loss)
I0530 06:57:27.416853 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00641608 (* 1 = 0.00641608 loss)
I0530 06:57:27.416857 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.005661 (* 1 = 0.005661 loss)
I0530 06:57:27.416860 24924 sgd_solver.cpp:106] Iteration 13140, lr = 0.0002
I0530 06:58:16.066682 24924 solver.cpp:228] Iteration 13160, loss = 0.23205
I0530 06:58:16.066718 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 06:58:16.066725 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.138711 (* 1 = 0.138711 loss)
I0530 06:58:16.066728 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133773 (* 1 = 0.133773 loss)
I0530 06:58:16.066732 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00786819 (* 1 = 0.00786819 loss)
I0530 06:58:16.066735 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0349648 (* 1 = 0.0349648 loss)
I0530 06:58:16.066740 24924 sgd_solver.cpp:106] Iteration 13160, lr = 0.0002
I0530 06:59:04.707285 24924 solver.cpp:228] Iteration 13180, loss = 0.326319
I0530 06:59:04.707321 24924 solver.cpp:244]     Train net output #0: accuarcy = 1
I0530 06:59:04.707329 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0129392 (* 1 = 0.0129392 loss)
I0530 06:59:04.707331 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0431124 (* 1 = 0.0431124 loss)
I0530 06:59:04.707334 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00223893 (* 1 = 0.00223893 loss)
I0530 06:59:04.707339 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00487629 (* 1 = 0.00487629 loss)
I0530 06:59:04.707342 24924 sgd_solver.cpp:106] Iteration 13180, lr = 0.0002
speed: 2.436s / iter
I0530 06:59:53.352124 24924 solver.cpp:228] Iteration 13200, loss = 0.435855
I0530 06:59:53.352160 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 06:59:53.352167 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13497 (* 1 = 0.13497 loss)
I0530 06:59:53.352171 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272574 (* 1 = 0.272574 loss)
I0530 06:59:53.352174 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0319265 (* 1 = 0.0319265 loss)
I0530 06:59:53.352177 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378133 (* 1 = 0.0378133 loss)
I0530 06:59:53.352181 24924 sgd_solver.cpp:106] Iteration 13200, lr = 0.0002
I0530 07:00:42.104410 24924 solver.cpp:228] Iteration 13220, loss = 0.343884
I0530 07:00:42.104446 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 07:00:42.104454 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0707886 (* 1 = 0.0707886 loss)
I0530 07:00:42.104457 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.1526 (* 1 = 0.1526 loss)
I0530 07:00:42.104460 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173722 (* 1 = 0.0173722 loss)
I0530 07:00:42.104463 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247626 (* 1 = 0.0247626 loss)
I0530 07:00:42.104468 24924 sgd_solver.cpp:106] Iteration 13220, lr = 0.0002
I0530 07:01:30.767215 24924 solver.cpp:228] Iteration 13240, loss = 0.368465
I0530 07:01:30.767249 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 07:01:30.767256 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.308039 (* 1 = 0.308039 loss)
I0530 07:01:30.767261 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.441388 (* 1 = 0.441388 loss)
I0530 07:01:30.767263 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.100506 (* 1 = 0.100506 loss)
I0530 07:01:30.767266 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.180281 (* 1 = 0.180281 loss)
I0530 07:01:30.767271 24924 sgd_solver.cpp:106] Iteration 13240, lr = 0.0002
I0530 07:02:19.467373 24924 solver.cpp:228] Iteration 13260, loss = 0.222945
I0530 07:02:19.467409 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:02:19.467416 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0317096 (* 1 = 0.0317096 loss)
I0530 07:02:19.467419 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0409087 (* 1 = 0.0409087 loss)
I0530 07:02:19.467422 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00153614 (* 1 = 0.00153614 loss)
I0530 07:02:19.467427 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00296071 (* 1 = 0.00296071 loss)
I0530 07:02:19.467433 24924 sgd_solver.cpp:106] Iteration 13260, lr = 0.0002
I0530 07:03:08.135509 24924 solver.cpp:228] Iteration 13280, loss = 0.249298
I0530 07:03:08.135531 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 07:03:08.135538 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.111702 (* 1 = 0.111702 loss)
I0530 07:03:08.135542 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.249995 (* 1 = 0.249995 loss)
I0530 07:03:08.135546 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149049 (* 1 = 0.0149049 loss)
I0530 07:03:08.135550 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255587 (* 1 = 0.0255587 loss)
I0530 07:03:08.135555 24924 sgd_solver.cpp:106] Iteration 13280, lr = 0.0002
I0530 07:03:56.876621 24924 solver.cpp:228] Iteration 13300, loss = 0.366835
I0530 07:03:56.876643 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 07:03:56.876651 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.174707 (* 1 = 0.174707 loss)
I0530 07:03:56.876655 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.354862 (* 1 = 0.354862 loss)
I0530 07:03:56.876658 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0199468 (* 1 = 0.0199468 loss)
I0530 07:03:56.876662 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0627917 (* 1 = 0.0627917 loss)
I0530 07:03:56.876667 24924 sgd_solver.cpp:106] Iteration 13300, lr = 0.0002
I0530 07:04:45.648473 24924 solver.cpp:228] Iteration 13320, loss = 0.269133
I0530 07:04:45.648509 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 07:04:45.648515 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0505084 (* 1 = 0.0505084 loss)
I0530 07:04:45.648519 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.13535 (* 1 = 0.13535 loss)
I0530 07:04:45.648522 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155897 (* 1 = 0.0155897 loss)
I0530 07:04:45.648525 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118198 (* 1 = 0.118198 loss)
I0530 07:04:45.648530 24924 sgd_solver.cpp:106] Iteration 13320, lr = 0.0002
I0530 07:05:34.363987 24924 solver.cpp:228] Iteration 13340, loss = 0.261538
I0530 07:05:34.364022 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:05:34.364030 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0355682 (* 1 = 0.0355682 loss)
I0530 07:05:34.364033 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0675005 (* 1 = 0.0675005 loss)
I0530 07:05:34.364037 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00440053 (* 1 = 0.00440053 loss)
I0530 07:05:34.364040 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153524 (* 1 = 0.0153524 loss)
I0530 07:05:34.364044 24924 sgd_solver.cpp:106] Iteration 13340, lr = 0.0002
I0530 07:06:23.085616 24924 solver.cpp:228] Iteration 13360, loss = 0.592207
I0530 07:06:23.085638 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 07:06:23.085644 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.10557 (* 1 = 0.10557 loss)
I0530 07:06:23.085649 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.202783 (* 1 = 0.202783 loss)
I0530 07:06:23.085651 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137833 (* 1 = 0.0137833 loss)
I0530 07:06:23.085654 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275823 (* 1 = 0.0275823 loss)
I0530 07:06:23.085659 24924 sgd_solver.cpp:106] Iteration 13360, lr = 0.0002
I0530 07:07:11.772873 24924 solver.cpp:228] Iteration 13380, loss = 0.409348
I0530 07:07:11.772912 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 07:07:11.772920 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.046999 (* 1 = 0.046999 loss)
I0530 07:07:11.772924 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0924154 (* 1 = 0.0924154 loss)
I0530 07:07:11.772927 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000521769 (* 1 = 0.000521769 loss)
I0530 07:07:11.772930 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00566218 (* 1 = 0.00566218 loss)
I0530 07:07:11.772934 24924 sgd_solver.cpp:106] Iteration 13380, lr = 0.0002
speed: 2.436s / iter
I0530 07:08:00.493103 24924 solver.cpp:228] Iteration 13400, loss = 0.275898
I0530 07:08:00.493137 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 07:08:00.493144 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.20868 (* 1 = 0.20868 loss)
I0530 07:08:00.493146 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.407519 (* 1 = 0.407519 loss)
I0530 07:08:00.493150 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0462599 (* 1 = 0.0462599 loss)
I0530 07:08:00.493154 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0778902 (* 1 = 0.0778902 loss)
I0530 07:08:00.493157 24924 sgd_solver.cpp:106] Iteration 13400, lr = 0.0002
I0530 07:08:49.210947 24924 solver.cpp:228] Iteration 13420, loss = 0.338252
I0530 07:08:49.210983 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 07:08:49.210989 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0563988 (* 1 = 0.0563988 loss)
I0530 07:08:49.210992 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.269954 (* 1 = 0.269954 loss)
I0530 07:08:49.210995 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134725 (* 1 = 0.0134725 loss)
I0530 07:08:49.210999 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0696576 (* 1 = 0.0696576 loss)
I0530 07:08:49.211004 24924 sgd_solver.cpp:106] Iteration 13420, lr = 0.0002
I0530 07:09:37.924690 24924 solver.cpp:228] Iteration 13440, loss = 0.407386
I0530 07:09:37.924726 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 07:09:37.924733 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0998103 (* 1 = 0.0998103 loss)
I0530 07:09:37.924736 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291779 (* 1 = 0.291779 loss)
I0530 07:09:37.924741 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0293422 (* 1 = 0.0293422 loss)
I0530 07:09:37.924742 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0378865 (* 1 = 0.0378865 loss)
I0530 07:09:37.924747 24924 sgd_solver.cpp:106] Iteration 13440, lr = 0.0002
I0530 07:10:26.679889 24924 solver.cpp:228] Iteration 13460, loss = 0.633356
I0530 07:10:26.679925 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 07:10:26.679932 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256659 (* 1 = 0.0256659 loss)
I0530 07:10:26.679935 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0769582 (* 1 = 0.0769582 loss)
I0530 07:10:26.679940 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00257331 (* 1 = 0.00257331 loss)
I0530 07:10:26.679945 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0152092 (* 1 = 0.0152092 loss)
I0530 07:10:26.679951 24924 sgd_solver.cpp:106] Iteration 13460, lr = 0.0002
I0530 07:11:15.415061 24924 solver.cpp:228] Iteration 13480, loss = 0.346539
I0530 07:11:15.415098 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:11:15.415105 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0414725 (* 1 = 0.0414725 loss)
I0530 07:11:15.415109 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0687641 (* 1 = 0.0687641 loss)
I0530 07:11:15.415112 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00633706 (* 1 = 0.00633706 loss)
I0530 07:11:15.415115 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198234 (* 1 = 0.0198234 loss)
I0530 07:11:15.415120 24924 sgd_solver.cpp:106] Iteration 13480, lr = 0.0002
I0530 07:12:04.134543 24924 solver.cpp:228] Iteration 13500, loss = 0.312235
I0530 07:12:04.134578 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 07:12:04.134585 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.139978 (* 1 = 0.139978 loss)
I0530 07:12:04.134589 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.199406 (* 1 = 0.199406 loss)
I0530 07:12:04.134593 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00630792 (* 1 = 0.00630792 loss)
I0530 07:12:04.134595 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.030098 (* 1 = 0.030098 loss)
I0530 07:12:04.134600 24924 sgd_solver.cpp:106] Iteration 13500, lr = 0.0002
I0530 07:12:52.909565 24924 solver.cpp:228] Iteration 13520, loss = 0.48042
I0530 07:12:52.909587 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 07:12:52.909593 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.2919 (* 1 = 0.2919 loss)
I0530 07:12:52.909597 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.307415 (* 1 = 0.307415 loss)
I0530 07:12:52.909601 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00834589 (* 1 = 0.00834589 loss)
I0530 07:12:52.909605 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036527 (* 1 = 0.036527 loss)
I0530 07:12:52.909608 24924 sgd_solver.cpp:106] Iteration 13520, lr = 0.0002
I0530 07:13:41.651928 24924 solver.cpp:228] Iteration 13540, loss = 0.33856
I0530 07:13:41.651963 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 07:13:41.651970 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.11412 (* 1 = 0.11412 loss)
I0530 07:13:41.651974 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.213828 (* 1 = 0.213828 loss)
I0530 07:13:41.651978 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011016 (* 1 = 0.011016 loss)
I0530 07:13:41.651980 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0196407 (* 1 = 0.0196407 loss)
I0530 07:13:41.651984 24924 sgd_solver.cpp:106] Iteration 13540, lr = 0.0002
I0530 07:14:30.434789 24924 solver.cpp:228] Iteration 13560, loss = 0.246443
I0530 07:14:30.434810 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 07:14:30.434818 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00779571 (* 1 = 0.00779571 loss)
I0530 07:14:30.434821 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0468967 (* 1 = 0.0468967 loss)
I0530 07:14:30.434825 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0080476 (* 1 = 0.0080476 loss)
I0530 07:14:30.434828 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00080035 (* 1 = 0.00080035 loss)
I0530 07:14:30.434834 24924 sgd_solver.cpp:106] Iteration 13560, lr = 0.0002
I0530 07:15:19.216702 24924 solver.cpp:228] Iteration 13580, loss = 0.300768
I0530 07:15:19.216725 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 07:15:19.216732 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.230392 (* 1 = 0.230392 loss)
I0530 07:15:19.216735 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.352219 (* 1 = 0.352219 loss)
I0530 07:15:19.216739 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149889 (* 1 = 0.0149889 loss)
I0530 07:15:19.216742 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383885 (* 1 = 0.0383885 loss)
I0530 07:15:19.216747 24924 sgd_solver.cpp:106] Iteration 13580, lr = 0.0002
speed: 2.436s / iter
I0530 07:16:08.012589 24924 solver.cpp:228] Iteration 13600, loss = 0.288925
I0530 07:16:08.012611 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 07:16:08.012619 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00316909 (* 1 = 0.00316909 loss)
I0530 07:16:08.012624 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0544063 (* 1 = 0.0544063 loss)
I0530 07:16:08.012626 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107726 (* 1 = 0.0107726 loss)
I0530 07:16:08.012629 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0809936 (* 1 = 0.0809936 loss)
I0530 07:16:08.012634 24924 sgd_solver.cpp:106] Iteration 13600, lr = 0.0002
I0530 07:16:56.825100 24924 solver.cpp:228] Iteration 13620, loss = 0.185362
I0530 07:16:56.825122 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:16:56.825145 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000267385 (* 1 = 0.000267385 loss)
I0530 07:16:56.825148 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.051065 (* 1 = 0.051065 loss)
I0530 07:16:56.825151 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0326116 (* 1 = 0.0326116 loss)
I0530 07:16:56.825155 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0715372 (* 1 = 0.0715372 loss)
I0530 07:16:56.825158 24924 sgd_solver.cpp:106] Iteration 13620, lr = 0.0002
I0530 07:17:45.657878 24924 solver.cpp:228] Iteration 13640, loss = 0.164063
I0530 07:17:45.657902 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:17:45.657908 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00321098 (* 1 = 0.00321098 loss)
I0530 07:17:45.657912 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0413642 (* 1 = 0.0413642 loss)
I0530 07:17:45.657917 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0235343 (* 1 = 0.0235343 loss)
I0530 07:17:45.657919 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00751116 (* 1 = 0.00751116 loss)
I0530 07:17:45.657924 24924 sgd_solver.cpp:106] Iteration 13640, lr = 0.0002
I0530 07:18:34.480254 24924 solver.cpp:228] Iteration 13660, loss = 0.282595
I0530 07:18:34.480278 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 07:18:34.480284 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.116503 (* 1 = 0.116503 loss)
I0530 07:18:34.480288 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.20468 (* 1 = 0.20468 loss)
I0530 07:18:34.480290 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00676839 (* 1 = 0.00676839 loss)
I0530 07:18:34.480294 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0171237 (* 1 = 0.0171237 loss)
I0530 07:18:34.480298 24924 sgd_solver.cpp:106] Iteration 13660, lr = 0.0002
I0530 07:19:23.260258 24924 solver.cpp:228] Iteration 13680, loss = 0.507952
I0530 07:19:23.260294 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 07:19:23.260303 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0984256 (* 1 = 0.0984256 loss)
I0530 07:19:23.260306 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.284145 (* 1 = 0.284145 loss)
I0530 07:19:23.260309 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121602 (* 1 = 0.0121602 loss)
I0530 07:19:23.260313 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0435672 (* 1 = 0.0435672 loss)
I0530 07:19:23.260316 24924 sgd_solver.cpp:106] Iteration 13680, lr = 0.0002
I0530 07:20:12.080492 24924 solver.cpp:228] Iteration 13700, loss = 0.36263
I0530 07:20:12.080528 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 07:20:12.080534 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0817328 (* 1 = 0.0817328 loss)
I0530 07:20:12.080538 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.211757 (* 1 = 0.211757 loss)
I0530 07:20:12.080541 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160932 (* 1 = 0.0160932 loss)
I0530 07:20:12.080544 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261318 (* 1 = 0.0261318 loss)
I0530 07:20:12.080549 24924 sgd_solver.cpp:106] Iteration 13700, lr = 0.0002
I0530 07:21:00.936281 24924 solver.cpp:228] Iteration 13720, loss = 0.290951
I0530 07:21:00.936318 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 07:21:00.936326 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.284226 (* 1 = 0.284226 loss)
I0530 07:21:00.936329 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.417822 (* 1 = 0.417822 loss)
I0530 07:21:00.936332 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134548 (* 1 = 0.0134548 loss)
I0530 07:21:00.936336 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0451186 (* 1 = 0.0451186 loss)
I0530 07:21:00.936341 24924 sgd_solver.cpp:106] Iteration 13720, lr = 0.0002
I0530 07:21:49.766633 24924 solver.cpp:228] Iteration 13740, loss = 0.280879
I0530 07:21:49.766669 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:21:49.766675 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186248 (* 1 = 0.0186248 loss)
I0530 07:21:49.766680 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0997198 (* 1 = 0.0997198 loss)
I0530 07:21:49.766682 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0288616 (* 1 = 0.0288616 loss)
I0530 07:21:49.766685 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105015 (* 1 = 0.0105015 loss)
I0530 07:21:49.766690 24924 sgd_solver.cpp:106] Iteration 13740, lr = 0.0002
I0530 07:22:38.525164 24924 solver.cpp:228] Iteration 13760, loss = 0.173346
I0530 07:22:38.525187 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 07:22:38.525194 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0492313 (* 1 = 0.0492313 loss)
I0530 07:22:38.525198 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143188 (* 1 = 0.143188 loss)
I0530 07:22:38.525202 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00980562 (* 1 = 0.00980562 loss)
I0530 07:22:38.525204 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128716 (* 1 = 0.0128716 loss)
I0530 07:22:38.525209 24924 sgd_solver.cpp:106] Iteration 13760, lr = 0.0002
I0530 07:23:27.319562 24924 solver.cpp:228] Iteration 13780, loss = 0.428008
I0530 07:23:27.319597 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 07:23:27.319605 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.191798 (* 1 = 0.191798 loss)
I0530 07:23:27.319609 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.268136 (* 1 = 0.268136 loss)
I0530 07:23:27.319613 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00822273 (* 1 = 0.00822273 loss)
I0530 07:23:27.319618 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221912 (* 1 = 0.0221912 loss)
I0530 07:23:27.319623 24924 sgd_solver.cpp:106] Iteration 13780, lr = 0.0002
speed: 2.437s / iter
I0530 07:24:16.124924 24924 solver.cpp:228] Iteration 13800, loss = 0.351254
I0530 07:24:16.124948 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:24:16.124955 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00213151 (* 1 = 0.00213151 loss)
I0530 07:24:16.124959 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0642723 (* 1 = 0.0642723 loss)
I0530 07:24:16.124963 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00369855 (* 1 = 0.00369855 loss)
I0530 07:24:16.124966 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180706 (* 1 = 0.0180706 loss)
I0530 07:24:16.124970 24924 sgd_solver.cpp:106] Iteration 13800, lr = 0.0002
I0530 07:25:04.878214 24924 solver.cpp:228] Iteration 13820, loss = 0.552865
I0530 07:25:04.878237 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 07:25:04.878243 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0666767 (* 1 = 0.0666767 loss)
I0530 07:25:04.878247 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.19753 (* 1 = 0.19753 loss)
I0530 07:25:04.878250 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0144729 (* 1 = 0.0144729 loss)
I0530 07:25:04.878254 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0370848 (* 1 = 0.0370848 loss)
I0530 07:25:04.878258 24924 sgd_solver.cpp:106] Iteration 13820, lr = 0.0002
I0530 07:25:53.740676 24924 solver.cpp:228] Iteration 13840, loss = 0.301472
I0530 07:25:53.740712 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:25:53.740720 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0870657 (* 1 = 0.0870657 loss)
I0530 07:25:53.740722 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0966735 (* 1 = 0.0966735 loss)
I0530 07:25:53.740725 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102383 (* 1 = 0.0102383 loss)
I0530 07:25:53.740728 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141464 (* 1 = 0.0141464 loss)
I0530 07:25:53.740732 24924 sgd_solver.cpp:106] Iteration 13840, lr = 0.0002
I0530 07:26:42.651742 24924 solver.cpp:228] Iteration 13860, loss = 0.348245
I0530 07:26:42.651764 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:26:42.651772 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0740623 (* 1 = 0.0740623 loss)
I0530 07:26:42.651775 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.080827 (* 1 = 0.080827 loss)
I0530 07:26:42.651778 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00378547 (* 1 = 0.00378547 loss)
I0530 07:26:42.651782 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00435367 (* 1 = 0.00435367 loss)
I0530 07:26:42.651785 24924 sgd_solver.cpp:106] Iteration 13860, lr = 0.0002
I0530 07:27:31.568750 24924 solver.cpp:228] Iteration 13880, loss = 0.226868
I0530 07:27:31.568801 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 07:27:31.568809 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176437 (* 1 = 0.0176437 loss)
I0530 07:27:31.568812 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.129556 (* 1 = 0.129556 loss)
I0530 07:27:31.568816 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.010175 (* 1 = 0.010175 loss)
I0530 07:27:31.568819 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143213 (* 1 = 0.0143213 loss)
I0530 07:27:31.568823 24924 sgd_solver.cpp:106] Iteration 13880, lr = 0.0002
I0530 07:28:20.595966 24924 solver.cpp:228] Iteration 13900, loss = 0.338952
I0530 07:28:20.596004 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 07:28:20.596010 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0312914 (* 1 = 0.0312914 loss)
I0530 07:28:20.596014 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0929475 (* 1 = 0.0929475 loss)
I0530 07:28:20.596017 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00242079 (* 1 = 0.00242079 loss)
I0530 07:28:20.596020 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00526916 (* 1 = 0.00526916 loss)
I0530 07:28:20.596024 24924 sgd_solver.cpp:106] Iteration 13900, lr = 0.0002
I0530 07:29:09.573766 24924 solver.cpp:228] Iteration 13920, loss = 0.197897
I0530 07:29:09.573793 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:29:09.573801 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256988 (* 1 = 0.0256988 loss)
I0530 07:29:09.573804 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0627637 (* 1 = 0.0627637 loss)
I0530 07:29:09.573808 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00504582 (* 1 = 0.00504582 loss)
I0530 07:29:09.573812 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109167 (* 1 = 0.0109167 loss)
I0530 07:29:09.573817 24924 sgd_solver.cpp:106] Iteration 13920, lr = 0.0002
I0530 07:29:58.518584 24924 solver.cpp:228] Iteration 13940, loss = 0.329999
I0530 07:29:58.518620 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 07:29:58.518627 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.138435 (* 1 = 0.138435 loss)
I0530 07:29:58.518631 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.450028 (* 1 = 0.450028 loss)
I0530 07:29:58.518635 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.042462 (* 1 = 0.042462 loss)
I0530 07:29:58.518637 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0487938 (* 1 = 0.0487938 loss)
I0530 07:29:58.518641 24924 sgd_solver.cpp:106] Iteration 13940, lr = 0.0002
I0530 07:30:47.554795 24924 solver.cpp:228] Iteration 13960, loss = 0.359835
I0530 07:30:47.554816 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 07:30:47.554823 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.166705 (* 1 = 0.166705 loss)
I0530 07:30:47.554826 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.187769 (* 1 = 0.187769 loss)
I0530 07:30:47.554831 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600665 (* 1 = 0.00600665 loss)
I0530 07:30:47.554833 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210393 (* 1 = 0.0210393 loss)
I0530 07:30:47.554837 24924 sgd_solver.cpp:106] Iteration 13960, lr = 0.0002
I0530 07:31:36.551728 24924 solver.cpp:228] Iteration 13980, loss = 0.289609
I0530 07:31:36.551764 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 07:31:36.551770 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.21399 (* 1 = 0.21399 loss)
I0530 07:31:36.551774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.330779 (* 1 = 0.330779 loss)
I0530 07:31:36.551777 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0388724 (* 1 = 0.0388724 loss)
I0530 07:31:36.551780 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0619467 (* 1 = 0.0619467 loss)
I0530 07:31:36.551784 24924 sgd_solver.cpp:106] Iteration 13980, lr = 0.0002
speed: 2.437s / iter
I0530 07:32:25.658596 24924 solver.cpp:228] Iteration 14000, loss = 0.339822
I0530 07:32:25.658630 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 07:32:25.658638 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0564237 (* 1 = 0.0564237 loss)
I0530 07:32:25.658643 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141707 (* 1 = 0.141707 loss)
I0530 07:32:25.658645 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00660744 (* 1 = 0.00660744 loss)
I0530 07:32:25.658648 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00767458 (* 1 = 0.00767458 loss)
I0530 07:32:25.658653 24924 sgd_solver.cpp:106] Iteration 14000, lr = 0.0002
I0530 07:33:14.656283 24924 solver.cpp:228] Iteration 14020, loss = 0.609185
I0530 07:33:14.656306 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:33:14.656313 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00396269 (* 1 = 0.00396269 loss)
I0530 07:33:14.656317 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.126736 (* 1 = 0.126736 loss)
I0530 07:33:14.656322 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00887964 (* 1 = 0.00887964 loss)
I0530 07:33:14.656324 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201754 (* 1 = 0.0201754 loss)
I0530 07:33:14.656328 24924 sgd_solver.cpp:106] Iteration 14020, lr = 0.0002
I0530 07:34:03.698787 24924 solver.cpp:228] Iteration 14040, loss = 0.348214
I0530 07:34:03.698822 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 07:34:03.698828 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.347808 (* 1 = 0.347808 loss)
I0530 07:34:03.698832 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.390247 (* 1 = 0.390247 loss)
I0530 07:34:03.698835 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.043585 (* 1 = 0.043585 loss)
I0530 07:34:03.698838 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0934376 (* 1 = 0.0934376 loss)
I0530 07:34:03.698843 24924 sgd_solver.cpp:106] Iteration 14040, lr = 0.0002
I0530 07:34:52.723440 24924 solver.cpp:228] Iteration 14060, loss = 0.258384
I0530 07:34:52.723465 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 07:34:52.723474 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0395581 (* 1 = 0.0395581 loss)
I0530 07:34:52.723480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.069463 (* 1 = 0.069463 loss)
I0530 07:34:52.723486 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00443416 (* 1 = 0.00443416 loss)
I0530 07:34:52.723492 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00578042 (* 1 = 0.00578042 loss)
I0530 07:34:52.723498 24924 sgd_solver.cpp:106] Iteration 14060, lr = 0.0002
I0530 07:35:41.804316 24924 solver.cpp:228] Iteration 14080, loss = 0.319681
I0530 07:35:41.804338 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 07:35:41.804348 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.210397 (* 1 = 0.210397 loss)
I0530 07:35:41.804353 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.318809 (* 1 = 0.318809 loss)
I0530 07:35:41.804359 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0383347 (* 1 = 0.0383347 loss)
I0530 07:35:41.804364 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0488231 (* 1 = 0.0488231 loss)
I0530 07:35:41.804370 24924 sgd_solver.cpp:106] Iteration 14080, lr = 0.0002
I0530 07:36:30.841390 24924 solver.cpp:228] Iteration 14100, loss = 0.274954
I0530 07:36:30.841426 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 07:36:30.841434 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0401151 (* 1 = 0.0401151 loss)
I0530 07:36:30.841437 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.175479 (* 1 = 0.175479 loss)
I0530 07:36:30.841441 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039748 (* 1 = 0.039748 loss)
I0530 07:36:30.841446 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0272775 (* 1 = 0.0272775 loss)
I0530 07:36:30.841452 24924 sgd_solver.cpp:106] Iteration 14100, lr = 0.0002
I0530 07:37:19.802729 24924 solver.cpp:228] Iteration 14120, loss = 0.540138
I0530 07:37:19.802764 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:37:19.802772 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0258814 (* 1 = 0.0258814 loss)
I0530 07:37:19.802774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0571818 (* 1 = 0.0571818 loss)
I0530 07:37:19.802778 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00599293 (* 1 = 0.00599293 loss)
I0530 07:37:19.802783 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0060651 (* 1 = 0.0060651 loss)
I0530 07:37:19.802788 24924 sgd_solver.cpp:106] Iteration 14120, lr = 0.0002
I0530 07:38:08.799903 24924 solver.cpp:228] Iteration 14140, loss = 0.267632
I0530 07:38:08.799938 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 07:38:08.799944 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0206203 (* 1 = 0.0206203 loss)
I0530 07:38:08.799948 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.116394 (* 1 = 0.116394 loss)
I0530 07:38:08.799952 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161828 (* 1 = 0.0161828 loss)
I0530 07:38:08.799955 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0265721 (* 1 = 0.0265721 loss)
I0530 07:38:08.799959 24924 sgd_solver.cpp:106] Iteration 14140, lr = 0.0002
I0530 07:38:57.817030 24924 solver.cpp:228] Iteration 14160, loss = 0.424995
I0530 07:38:57.817065 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0530 07:38:57.817072 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.294413 (* 1 = 0.294413 loss)
I0530 07:38:57.817076 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.516454 (* 1 = 0.516454 loss)
I0530 07:38:57.817080 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176817 (* 1 = 0.0176817 loss)
I0530 07:38:57.817082 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0357126 (* 1 = 0.0357126 loss)
I0530 07:38:57.817087 24924 sgd_solver.cpp:106] Iteration 14160, lr = 0.0002
I0530 07:39:46.789669 24924 solver.cpp:228] Iteration 14180, loss = 0.293707
I0530 07:39:46.789691 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:39:46.789697 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0245887 (* 1 = 0.0245887 loss)
I0530 07:39:46.789702 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0984247 (* 1 = 0.0984247 loss)
I0530 07:39:46.789705 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616163 (* 1 = 0.00616163 loss)
I0530 07:39:46.789708 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00383603 (* 1 = 0.00383603 loss)
I0530 07:39:46.789713 24924 sgd_solver.cpp:106] Iteration 14180, lr = 0.0002
speed: 2.437s / iter
I0530 07:40:35.748168 24924 solver.cpp:228] Iteration 14200, loss = 0.391316
I0530 07:40:35.748204 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 07:40:35.748210 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.029823 (* 1 = 0.029823 loss)
I0530 07:40:35.748214 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0897187 (* 1 = 0.0897187 loss)
I0530 07:40:35.748217 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412559 (* 1 = 0.00412559 loss)
I0530 07:40:35.748220 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00748904 (* 1 = 0.00748904 loss)
I0530 07:40:35.748225 24924 sgd_solver.cpp:106] Iteration 14200, lr = 0.0002
I0530 07:41:24.713847 24924 solver.cpp:228] Iteration 14220, loss = 0.296574
I0530 07:41:24.713871 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:41:24.713877 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0220491 (* 1 = 0.0220491 loss)
I0530 07:41:24.713881 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0724156 (* 1 = 0.0724156 loss)
I0530 07:41:24.713884 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104541 (* 1 = 0.0104541 loss)
I0530 07:41:24.713888 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00281936 (* 1 = 0.00281936 loss)
I0530 07:41:24.713893 24924 sgd_solver.cpp:106] Iteration 14220, lr = 0.0002
I0530 07:42:13.727746 24924 solver.cpp:228] Iteration 14240, loss = 0.241808
I0530 07:42:13.727782 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:42:13.727789 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0314075 (* 1 = 0.0314075 loss)
I0530 07:42:13.727793 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0636911 (* 1 = 0.0636911 loss)
I0530 07:42:13.727797 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00483294 (* 1 = 0.00483294 loss)
I0530 07:42:13.727799 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00466276 (* 1 = 0.00466276 loss)
I0530 07:42:13.727804 24924 sgd_solver.cpp:106] Iteration 14240, lr = 0.0002
I0530 07:43:02.651628 24924 solver.cpp:228] Iteration 14260, loss = 0.207903
I0530 07:43:02.651651 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 07:43:02.651659 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.174377 (* 1 = 0.174377 loss)
I0530 07:43:02.651662 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.231303 (* 1 = 0.231303 loss)
I0530 07:43:02.651666 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00262575 (* 1 = 0.00262575 loss)
I0530 07:43:02.651669 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110935 (* 1 = 0.0110935 loss)
I0530 07:43:02.651674 24924 sgd_solver.cpp:106] Iteration 14260, lr = 0.0002
I0530 07:43:51.656332 24924 solver.cpp:228] Iteration 14280, loss = 0.319215
I0530 07:43:51.656366 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 07:43:51.656373 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.148158 (* 1 = 0.148158 loss)
I0530 07:43:51.656378 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.187189 (* 1 = 0.187189 loss)
I0530 07:43:51.656380 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140249 (* 1 = 0.0140249 loss)
I0530 07:43:51.656383 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212033 (* 1 = 0.0212033 loss)
I0530 07:43:51.656388 24924 sgd_solver.cpp:106] Iteration 14280, lr = 0.0002
I0530 07:44:40.622426 24924 solver.cpp:228] Iteration 14300, loss = 0.289594
I0530 07:44:40.622462 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0530 07:44:40.622467 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.480158 (* 1 = 0.480158 loss)
I0530 07:44:40.622470 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.473809 (* 1 = 0.473809 loss)
I0530 07:44:40.622473 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0395606 (* 1 = 0.0395606 loss)
I0530 07:44:40.622478 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0663401 (* 1 = 0.0663401 loss)
I0530 07:44:40.622481 24924 sgd_solver.cpp:106] Iteration 14300, lr = 0.0002
I0530 07:45:29.567461 24924 solver.cpp:228] Iteration 14320, loss = 0.236925
I0530 07:45:29.567499 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 07:45:29.567507 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0716081 (* 1 = 0.0716081 loss)
I0530 07:45:29.567510 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.172419 (* 1 = 0.172419 loss)
I0530 07:45:29.567513 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145601 (* 1 = 0.0145601 loss)
I0530 07:45:29.567517 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0411904 (* 1 = 0.0411904 loss)
I0530 07:45:29.567522 24924 sgd_solver.cpp:106] Iteration 14320, lr = 0.0002
I0530 07:46:18.547693 24924 solver.cpp:228] Iteration 14340, loss = 0.214926
I0530 07:46:18.547715 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:46:18.547724 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0448124 (* 1 = 0.0448124 loss)
I0530 07:46:18.547744 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0873734 (* 1 = 0.0873734 loss)
I0530 07:46:18.547749 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00482631 (* 1 = 0.00482631 loss)
I0530 07:46:18.547754 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0420461 (* 1 = 0.0420461 loss)
I0530 07:46:18.547758 24924 sgd_solver.cpp:106] Iteration 14340, lr = 0.0002
I0530 07:47:07.444365 24924 solver.cpp:228] Iteration 14360, loss = 0.387196
I0530 07:47:07.444387 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:47:07.444396 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0164625 (* 1 = 0.0164625 loss)
I0530 07:47:07.444402 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0599886 (* 1 = 0.0599886 loss)
I0530 07:47:07.444407 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00335433 (* 1 = 0.00335433 loss)
I0530 07:47:07.444413 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512831 (* 1 = 0.00512831 loss)
I0530 07:47:07.444419 24924 sgd_solver.cpp:106] Iteration 14360, lr = 0.0002
I0530 07:47:56.332085 24924 solver.cpp:228] Iteration 14380, loss = 0.329695
I0530 07:47:56.332108 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 07:47:56.332116 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0425482 (* 1 = 0.0425482 loss)
I0530 07:47:56.332123 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0994849 (* 1 = 0.0994849 loss)
I0530 07:47:56.332126 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181195 (* 1 = 0.00181195 loss)
I0530 07:47:56.332131 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254474 (* 1 = 0.0254474 loss)
I0530 07:47:56.332137 24924 sgd_solver.cpp:106] Iteration 14380, lr = 0.0002
speed: 2.437s / iter
I0530 07:48:45.250636 24924 solver.cpp:228] Iteration 14400, loss = 0.340934
I0530 07:48:45.250660 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 07:48:45.250669 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.238823 (* 1 = 0.238823 loss)
I0530 07:48:45.250675 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.375498 (* 1 = 0.375498 loss)
I0530 07:48:45.250681 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162867 (* 1 = 0.0162867 loss)
I0530 07:48:45.250689 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0314615 (* 1 = 0.0314615 loss)
I0530 07:48:45.250697 24924 sgd_solver.cpp:106] Iteration 14400, lr = 0.0002
I0530 07:49:34.085943 24924 solver.cpp:228] Iteration 14420, loss = 0.361123
I0530 07:49:34.085966 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 07:49:34.085975 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.380837 (* 1 = 0.380837 loss)
I0530 07:49:34.085981 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.342706 (* 1 = 0.342706 loss)
I0530 07:49:34.085986 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0315773 (* 1 = 0.0315773 loss)
I0530 07:49:34.085991 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0889948 (* 1 = 0.0889948 loss)
I0530 07:49:34.085997 24924 sgd_solver.cpp:106] Iteration 14420, lr = 0.0002
I0530 07:50:22.901597 24924 solver.cpp:228] Iteration 14440, loss = 0.243926
I0530 07:50:22.901631 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:50:22.901638 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00708544 (* 1 = 0.00708544 loss)
I0530 07:50:22.901643 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0266498 (* 1 = 0.0266498 loss)
I0530 07:50:22.901648 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00234747 (* 1 = 0.00234747 loss)
I0530 07:50:22.901652 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00311162 (* 1 = 0.00311162 loss)
I0530 07:50:22.901659 24924 sgd_solver.cpp:106] Iteration 14440, lr = 0.0002
I0530 07:51:11.661187 24924 solver.cpp:228] Iteration 14460, loss = 0.261659
I0530 07:51:11.661222 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:51:11.661229 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0428869 (* 1 = 0.0428869 loss)
I0530 07:51:11.661232 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0409051 (* 1 = 0.0409051 loss)
I0530 07:51:11.661237 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00814648 (* 1 = 0.00814648 loss)
I0530 07:51:11.661242 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00809164 (* 1 = 0.00809164 loss)
I0530 07:51:11.661247 24924 sgd_solver.cpp:106] Iteration 14460, lr = 0.0002
I0530 07:52:00.515434 24924 solver.cpp:228] Iteration 14480, loss = 0.346641
I0530 07:52:00.515468 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:52:00.515476 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485002 (* 1 = 0.0485002 loss)
I0530 07:52:00.515480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.121381 (* 1 = 0.121381 loss)
I0530 07:52:00.515485 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296604 (* 1 = 0.0296604 loss)
I0530 07:52:00.515489 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150713 (* 1 = 0.0150713 loss)
I0530 07:52:00.515494 24924 sgd_solver.cpp:106] Iteration 14480, lr = 0.0002
I0530 07:52:49.227713 24924 solver.cpp:228] Iteration 14500, loss = 0.242413
I0530 07:52:49.227749 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 07:52:49.227756 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0415069 (* 1 = 0.0415069 loss)
I0530 07:52:49.227761 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.119618 (* 1 = 0.119618 loss)
I0530 07:52:49.227763 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00348793 (* 1 = 0.00348793 loss)
I0530 07:52:49.227766 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00854675 (* 1 = 0.00854675 loss)
I0530 07:52:49.227771 24924 sgd_solver.cpp:106] Iteration 14500, lr = 0.0002
I0530 07:53:37.988757 24924 solver.cpp:228] Iteration 14520, loss = 0.541905
I0530 07:53:37.988780 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:53:37.988787 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.028924 (* 1 = 0.028924 loss)
I0530 07:53:37.988791 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.118628 (* 1 = 0.118628 loss)
I0530 07:53:37.988795 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114541 (* 1 = 0.0114541 loss)
I0530 07:53:37.988798 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100692 (* 1 = 0.0100692 loss)
I0530 07:53:37.988802 24924 sgd_solver.cpp:106] Iteration 14520, lr = 0.0002
I0530 07:54:26.725790 24924 solver.cpp:228] Iteration 14540, loss = 0.322729
I0530 07:54:26.725816 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 07:54:26.725822 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.119645 (* 1 = 0.119645 loss)
I0530 07:54:26.725826 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.178431 (* 1 = 0.178431 loss)
I0530 07:54:26.725829 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00394374 (* 1 = 0.00394374 loss)
I0530 07:54:26.725833 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215295 (* 1 = 0.0215295 loss)
I0530 07:54:26.725838 24924 sgd_solver.cpp:106] Iteration 14540, lr = 0.0002
I0530 07:55:15.424772 24924 solver.cpp:228] Iteration 14560, loss = 11.1165
I0530 07:55:15.424808 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.601562
I0530 07:55:15.424815 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.515756 (* 1 = 0.515756 loss)
I0530 07:55:15.424819 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.714891 (* 1 = 0.714891 loss)
I0530 07:55:15.424823 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 6.74104 (* 1 = 6.74104 loss)
I0530 07:55:15.424829 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 78.2092 (* 1 = 78.2092 loss)
I0530 07:55:15.424834 24924 sgd_solver.cpp:106] Iteration 14560, lr = 0.0002
I0530 07:56:04.155401 24924 solver.cpp:228] Iteration 14580, loss = 0.347825
I0530 07:56:04.155437 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 07:56:04.155444 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.134655 (* 1 = 0.134655 loss)
I0530 07:56:04.155448 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.283957 (* 1 = 0.283957 loss)
I0530 07:56:04.155453 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153282 (* 1 = 0.0153282 loss)
I0530 07:56:04.155458 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185376 (* 1 = 0.0185376 loss)
I0530 07:56:04.155463 24924 sgd_solver.cpp:106] Iteration 14580, lr = 0.0002
speed: 2.437s / iter
I0530 07:56:52.852002 24924 solver.cpp:228] Iteration 14600, loss = 0.517118
I0530 07:56:52.852025 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 07:56:52.852046 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0501894 (* 1 = 0.0501894 loss)
I0530 07:56:52.852049 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0813259 (* 1 = 0.0813259 loss)
I0530 07:56:52.852052 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00445274 (* 1 = 0.00445274 loss)
I0530 07:56:52.852057 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110412 (* 1 = 0.0110412 loss)
I0530 07:56:52.852062 24924 sgd_solver.cpp:106] Iteration 14600, lr = 0.0002
I0530 07:57:41.568500 24924 solver.cpp:228] Iteration 14620, loss = 0.256336
I0530 07:57:41.568538 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 07:57:41.568545 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305157 (* 1 = 0.0305157 loss)
I0530 07:57:41.568549 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.080465 (* 1 = 0.080465 loss)
I0530 07:57:41.568554 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00982184 (* 1 = 0.00982184 loss)
I0530 07:57:41.568559 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112526 (* 1 = 0.0112526 loss)
I0530 07:57:41.568564 24924 sgd_solver.cpp:106] Iteration 14620, lr = 0.0002
I0530 07:58:30.267966 24924 solver.cpp:228] Iteration 14640, loss = 0.28362
I0530 07:58:30.268002 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 07:58:30.268009 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00291651 (* 1 = 0.00291651 loss)
I0530 07:58:30.268013 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0389536 (* 1 = 0.0389536 loss)
I0530 07:58:30.268016 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00423729 (* 1 = 0.00423729 loss)
I0530 07:58:30.268019 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206554 (* 1 = 0.0206554 loss)
I0530 07:58:30.268024 24924 sgd_solver.cpp:106] Iteration 14640, lr = 0.0002
I0530 07:59:19.026885 24924 solver.cpp:228] Iteration 14660, loss = 0.262493
I0530 07:59:19.026907 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 07:59:19.026914 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0874727 (* 1 = 0.0874727 loss)
I0530 07:59:19.026918 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142526 (* 1 = 0.142526 loss)
I0530 07:59:19.026922 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817414 (* 1 = 0.00817414 loss)
I0530 07:59:19.026926 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278534 (* 1 = 0.0278534 loss)
I0530 07:59:19.026929 24924 sgd_solver.cpp:106] Iteration 14660, lr = 0.0002
I0530 08:00:07.761530 24924 solver.cpp:228] Iteration 14680, loss = 0.247266
I0530 08:00:07.761566 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 08:00:07.761572 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.190939 (* 1 = 0.190939 loss)
I0530 08:00:07.761576 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.268665 (* 1 = 0.268665 loss)
I0530 08:00:07.761580 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00541094 (* 1 = 0.00541094 loss)
I0530 08:00:07.761584 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0173544 (* 1 = 0.0173544 loss)
I0530 08:00:07.761587 24924 sgd_solver.cpp:106] Iteration 14680, lr = 0.0002
I0530 08:00:56.437388 24924 solver.cpp:228] Iteration 14700, loss = 0.464443
I0530 08:00:56.437412 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:00:56.437418 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0648156 (* 1 = 0.0648156 loss)
I0530 08:00:56.437422 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.086393 (* 1 = 0.086393 loss)
I0530 08:00:56.437427 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00362808 (* 1 = 0.00362808 loss)
I0530 08:00:56.437429 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0059791 (* 1 = 0.0059791 loss)
I0530 08:00:56.437434 24924 sgd_solver.cpp:106] Iteration 14700, lr = 0.0002
I0530 08:01:45.172914 24924 solver.cpp:228] Iteration 14720, loss = 0.343296
I0530 08:01:45.172953 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:01:45.172960 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0617024 (* 1 = 0.0617024 loss)
I0530 08:01:45.172963 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0769672 (* 1 = 0.0769672 loss)
I0530 08:01:45.172967 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00708408 (* 1 = 0.00708408 loss)
I0530 08:01:45.172971 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0128178 (* 1 = 0.0128178 loss)
I0530 08:01:45.172974 24924 sgd_solver.cpp:106] Iteration 14720, lr = 0.0002
I0530 08:02:33.902797 24924 solver.cpp:228] Iteration 14740, loss = 0.614431
I0530 08:02:33.902833 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.5
I0530 08:02:33.902840 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.971465 (* 1 = 0.971465 loss)
I0530 08:02:33.902844 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.758958 (* 1 = 0.758958 loss)
I0530 08:02:33.902848 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.133029 (* 1 = 0.133029 loss)
I0530 08:02:33.902850 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.537389 (* 1 = 0.537389 loss)
I0530 08:02:33.902854 24924 sgd_solver.cpp:106] Iteration 14740, lr = 0.0002
I0530 08:03:22.667115 24924 solver.cpp:228] Iteration 14760, loss = 0.178819
I0530 08:03:22.667151 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 08:03:22.667158 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.131958 (* 1 = 0.131958 loss)
I0530 08:03:22.667162 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115804 (* 1 = 0.115804 loss)
I0530 08:03:22.667165 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00747441 (* 1 = 0.00747441 loss)
I0530 08:03:22.667168 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163475 (* 1 = 0.0163475 loss)
I0530 08:03:22.667173 24924 sgd_solver.cpp:106] Iteration 14760, lr = 0.0002
I0530 08:04:11.343852 24924 solver.cpp:228] Iteration 14780, loss = 0.369132
I0530 08:04:11.343888 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 08:04:11.343895 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.162168 (* 1 = 0.162168 loss)
I0530 08:04:11.343899 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.266177 (* 1 = 0.266177 loss)
I0530 08:04:11.343902 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00219953 (* 1 = 0.00219953 loss)
I0530 08:04:11.343906 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022471 (* 1 = 0.022471 loss)
I0530 08:04:11.343910 24924 sgd_solver.cpp:106] Iteration 14780, lr = 0.0002
speed: 2.437s / iter
I0530 08:05:00.080102 24924 solver.cpp:228] Iteration 14800, loss = 0.240311
I0530 08:05:00.080124 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 08:05:00.080133 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000196187 (* 1 = 0.000196187 loss)
I0530 08:05:00.080138 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0570291 (* 1 = 0.0570291 loss)
I0530 08:05:00.080143 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0077185 (* 1 = 0.0077185 loss)
I0530 08:05:00.080148 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0180802 (* 1 = 0.0180802 loss)
I0530 08:05:00.080154 24924 sgd_solver.cpp:106] Iteration 14800, lr = 0.0002
I0530 08:05:48.793495 24924 solver.cpp:228] Iteration 14820, loss = 0.682243
I0530 08:05:48.793517 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0530 08:05:48.793526 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.284776 (* 1 = 0.284776 loss)
I0530 08:05:48.793546 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.359015 (* 1 = 0.359015 loss)
I0530 08:05:48.793551 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0133941 (* 1 = 0.0133941 loss)
I0530 08:05:48.793555 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0883573 (* 1 = 0.0883573 loss)
I0530 08:05:48.793561 24924 sgd_solver.cpp:106] Iteration 14820, lr = 0.0002
I0530 08:06:37.430491 24924 solver.cpp:228] Iteration 14840, loss = 0.34358
I0530 08:06:37.430513 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 08:06:37.430521 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.174272 (* 1 = 0.174272 loss)
I0530 08:06:37.430526 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.394717 (* 1 = 0.394717 loss)
I0530 08:06:37.430546 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147049 (* 1 = 0.0147049 loss)
I0530 08:06:37.430549 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.080309 (* 1 = 0.080309 loss)
I0530 08:06:37.430555 24924 sgd_solver.cpp:106] Iteration 14840, lr = 0.0002
I0530 08:07:26.128551 24924 solver.cpp:228] Iteration 14860, loss = 0.533641
I0530 08:07:26.128576 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.554688
I0530 08:07:26.128584 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.799953 (* 1 = 0.799953 loss)
I0530 08:07:26.128603 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.693841 (* 1 = 0.693841 loss)
I0530 08:07:26.128608 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0784582 (* 1 = 0.0784582 loss)
I0530 08:07:26.128613 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.386254 (* 1 = 0.386254 loss)
I0530 08:07:26.128620 24924 sgd_solver.cpp:106] Iteration 14860, lr = 0.0002
I0530 08:08:14.815309 24924 solver.cpp:228] Iteration 14880, loss = 0.248011
I0530 08:08:14.815330 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 08:08:14.815340 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.226287 (* 1 = 0.226287 loss)
I0530 08:08:14.815358 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.236913 (* 1 = 0.236913 loss)
I0530 08:08:14.815363 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00425023 (* 1 = 0.00425023 loss)
I0530 08:08:14.815368 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0374479 (* 1 = 0.0374479 loss)
I0530 08:08:14.815374 24924 sgd_solver.cpp:106] Iteration 14880, lr = 0.0002
I0530 08:09:03.518275 24924 solver.cpp:228] Iteration 14900, loss = 0.319086
I0530 08:09:03.518297 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 08:09:03.518306 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0808033 (* 1 = 0.0808033 loss)
I0530 08:09:03.518326 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.230164 (* 1 = 0.230164 loss)
I0530 08:09:03.518329 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103447 (* 1 = 0.0103447 loss)
I0530 08:09:03.518334 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124663 (* 1 = 0.0124663 loss)
I0530 08:09:03.518339 24924 sgd_solver.cpp:106] Iteration 14900, lr = 0.0002
I0530 08:09:52.150884 24924 solver.cpp:228] Iteration 14920, loss = 0.305117
I0530 08:09:52.150907 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:09:52.150914 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0201562 (* 1 = 0.0201562 loss)
I0530 08:09:52.150934 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0764395 (* 1 = 0.0764395 loss)
I0530 08:09:52.150939 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00451521 (* 1 = 0.00451521 loss)
I0530 08:09:52.150943 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271342 (* 1 = 0.0271342 loss)
I0530 08:09:52.150949 24924 sgd_solver.cpp:106] Iteration 14920, lr = 0.0002
I0530 08:10:40.811630 24924 solver.cpp:228] Iteration 14940, loss = 0.304898
I0530 08:10:40.811653 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:10:40.811661 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0399211 (* 1 = 0.0399211 loss)
I0530 08:10:40.811681 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.216176 (* 1 = 0.216176 loss)
I0530 08:10:40.811684 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938175 (* 1 = 0.00938175 loss)
I0530 08:10:40.811689 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108364 (* 1 = 0.0108364 loss)
I0530 08:10:40.811694 24924 sgd_solver.cpp:106] Iteration 14940, lr = 0.0002
I0530 08:11:29.466820 24924 solver.cpp:228] Iteration 14960, loss = 0.228047
I0530 08:11:29.466856 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 08:11:29.466864 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0901358 (* 1 = 0.0901358 loss)
I0530 08:11:29.466868 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.221986 (* 1 = 0.221986 loss)
I0530 08:11:29.466871 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108365 (* 1 = 0.0108365 loss)
I0530 08:11:29.466874 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308887 (* 1 = 0.0308887 loss)
I0530 08:11:29.466879 24924 sgd_solver.cpp:106] Iteration 14960, lr = 0.0002
I0530 08:12:18.248174 24924 solver.cpp:228] Iteration 14980, loss = 0.473798
I0530 08:12:18.248198 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:12:18.248204 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0431248 (* 1 = 0.0431248 loss)
I0530 08:12:18.248208 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115335 (* 1 = 0.115335 loss)
I0530 08:12:18.248212 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0092022 (* 1 = 0.0092022 loss)
I0530 08:12:18.248215 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942354 (* 1 = 0.00942354 loss)
I0530 08:12:18.248219 24924 sgd_solver.cpp:106] Iteration 14980, lr = 0.0002
speed: 2.437s / iter
I0530 08:13:04.652016 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_15000.caffemodel
I0530 08:13:07.798931 24924 solver.cpp:228] Iteration 15000, loss = 0.175533
I0530 08:13:07.798955 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:13:07.798964 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0765346 (* 1 = 0.0765346 loss)
I0530 08:13:07.798970 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0503135 (* 1 = 0.0503135 loss)
I0530 08:13:07.798976 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00866388 (* 1 = 0.00866388 loss)
I0530 08:13:07.798985 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00845322 (* 1 = 0.00845322 loss)
I0530 08:13:07.798991 24924 sgd_solver.cpp:106] Iteration 15000, lr = 0.0002
I0530 08:13:56.402477 24924 solver.cpp:228] Iteration 15020, loss = 0.185345
I0530 08:13:56.402501 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:13:56.402509 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0163265 (* 1 = 0.0163265 loss)
I0530 08:13:56.402529 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0605058 (* 1 = 0.0605058 loss)
I0530 08:13:56.402534 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00777874 (* 1 = 0.00777874 loss)
I0530 08:13:56.402539 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00895533 (* 1 = 0.00895533 loss)
I0530 08:13:56.402544 24924 sgd_solver.cpp:106] Iteration 15020, lr = 0.0002
I0530 08:14:45.083019 24924 solver.cpp:228] Iteration 15040, loss = 0.357379
I0530 08:14:45.083040 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:14:45.083048 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0443682 (* 1 = 0.0443682 loss)
I0530 08:14:45.083067 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0765178 (* 1 = 0.0765178 loss)
I0530 08:14:45.083072 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00614557 (* 1 = 0.00614557 loss)
I0530 08:14:45.083077 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00420844 (* 1 = 0.00420844 loss)
I0530 08:14:45.083083 24924 sgd_solver.cpp:106] Iteration 15040, lr = 0.0002
I0530 08:15:33.774881 24924 solver.cpp:228] Iteration 15060, loss = 0.389144
I0530 08:15:33.774904 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 08:15:33.774912 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000703046 (* 1 = 0.000703046 loss)
I0530 08:15:33.774932 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.024101 (* 1 = 0.024101 loss)
I0530 08:15:33.774937 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00394634 (* 1 = 0.00394634 loss)
I0530 08:15:33.774943 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172128 (* 1 = 0.0172128 loss)
I0530 08:15:33.774950 24924 sgd_solver.cpp:106] Iteration 15060, lr = 0.0002
I0530 08:16:22.442054 24924 solver.cpp:228] Iteration 15080, loss = 0.303065
I0530 08:16:22.442076 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 08:16:22.442085 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.3109 (* 1 = 0.3109 loss)
I0530 08:16:22.442104 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.435959 (* 1 = 0.435959 loss)
I0530 08:16:22.442109 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01328 (* 1 = 0.01328 loss)
I0530 08:16:22.442113 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.145872 (* 1 = 0.145872 loss)
I0530 08:16:22.442118 24924 sgd_solver.cpp:106] Iteration 15080, lr = 0.0002
I0530 08:17:11.149396 24924 solver.cpp:228] Iteration 15100, loss = 0.422843
I0530 08:17:11.149420 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 08:17:11.149427 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.239142 (* 1 = 0.239142 loss)
I0530 08:17:11.149446 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.403025 (* 1 = 0.403025 loss)
I0530 08:17:11.149452 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0332914 (* 1 = 0.0332914 loss)
I0530 08:17:11.149457 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.238746 (* 1 = 0.238746 loss)
I0530 08:17:11.149462 24924 sgd_solver.cpp:106] Iteration 15100, lr = 0.0002
I0530 08:17:59.783308 24924 solver.cpp:228] Iteration 15120, loss = 0.351378
I0530 08:17:59.783329 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:17:59.783339 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0663564 (* 1 = 0.0663564 loss)
I0530 08:17:59.783357 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.097892 (* 1 = 0.097892 loss)
I0530 08:17:59.783362 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00808806 (* 1 = 0.00808806 loss)
I0530 08:17:59.783367 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258693 (* 1 = 0.0258693 loss)
I0530 08:17:59.783373 24924 sgd_solver.cpp:106] Iteration 15120, lr = 0.0002
I0530 08:18:48.467134 24924 solver.cpp:228] Iteration 15140, loss = 0.242834
I0530 08:18:48.467170 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:18:48.467177 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0411245 (* 1 = 0.0411245 loss)
I0530 08:18:48.467181 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.136908 (* 1 = 0.136908 loss)
I0530 08:18:48.467185 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111733 (* 1 = 0.0111733 loss)
I0530 08:18:48.467187 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00935492 (* 1 = 0.00935492 loss)
I0530 08:18:48.467192 24924 sgd_solver.cpp:106] Iteration 15140, lr = 0.0002
I0530 08:19:37.161200 24924 solver.cpp:228] Iteration 15160, loss = 0.27036
I0530 08:19:37.161222 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 08:19:37.161231 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.090045 (* 1 = 0.090045 loss)
I0530 08:19:37.161250 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.217539 (* 1 = 0.217539 loss)
I0530 08:19:37.161255 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0501552 (* 1 = 0.0501552 loss)
I0530 08:19:37.161260 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.139226 (* 1 = 0.139226 loss)
I0530 08:19:37.161267 24924 sgd_solver.cpp:106] Iteration 15160, lr = 0.0002
I0530 08:20:25.860383 24924 solver.cpp:228] Iteration 15180, loss = 0.295747
I0530 08:20:25.860404 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0530 08:20:25.860424 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.3377 (* 1 = 0.3377 loss)
I0530 08:20:25.860429 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.493252 (* 1 = 0.493252 loss)
I0530 08:20:25.860431 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024658 (* 1 = 0.024658 loss)
I0530 08:20:25.860435 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0513542 (* 1 = 0.0513542 loss)
I0530 08:20:25.860440 24924 sgd_solver.cpp:106] Iteration 15180, lr = 0.0002
speed: 2.437s / iter
I0530 08:21:14.557150 24924 solver.cpp:228] Iteration 15200, loss = 0.236589
I0530 08:21:14.557186 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 08:21:14.557193 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0941927 (* 1 = 0.0941927 loss)
I0530 08:21:14.557198 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134464 (* 1 = 0.134464 loss)
I0530 08:21:14.557200 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0050018 (* 1 = 0.0050018 loss)
I0530 08:21:14.557204 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0250111 (* 1 = 0.0250111 loss)
I0530 08:21:14.557207 24924 sgd_solver.cpp:106] Iteration 15200, lr = 0.0002
I0530 08:22:03.287340 24924 solver.cpp:228] Iteration 15220, loss = 0.238685
I0530 08:22:03.287375 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:22:03.287384 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0181216 (* 1 = 0.0181216 loss)
I0530 08:22:03.287387 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0928692 (* 1 = 0.0928692 loss)
I0530 08:22:03.287390 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00190694 (* 1 = 0.00190694 loss)
I0530 08:22:03.287394 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0057622 (* 1 = 0.0057622 loss)
I0530 08:22:03.287397 24924 sgd_solver.cpp:106] Iteration 15220, lr = 0.0002
I0530 08:22:51.909646 24924 solver.cpp:228] Iteration 15240, loss = 0.351149
I0530 08:22:51.909667 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:22:51.909687 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561462 (* 1 = 0.0561462 loss)
I0530 08:22:51.909692 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0453814 (* 1 = 0.0453814 loss)
I0530 08:22:51.909694 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00550868 (* 1 = 0.00550868 loss)
I0530 08:22:51.909698 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133369 (* 1 = 0.0133369 loss)
I0530 08:22:51.909703 24924 sgd_solver.cpp:106] Iteration 15240, lr = 0.0002
I0530 08:23:40.573884 24924 solver.cpp:228] Iteration 15260, loss = 0.291674
I0530 08:23:40.573922 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 08:23:40.573930 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.161234 (* 1 = 0.161234 loss)
I0530 08:23:40.573933 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.234241 (* 1 = 0.234241 loss)
I0530 08:23:40.573937 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00438547 (* 1 = 0.00438547 loss)
I0530 08:23:40.573940 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031618 (* 1 = 0.031618 loss)
I0530 08:23:40.573945 24924 sgd_solver.cpp:106] Iteration 15260, lr = 0.0002
I0530 08:24:29.247226 24924 solver.cpp:228] Iteration 15280, loss = 0.338322
I0530 08:24:29.247249 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 08:24:29.247257 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0701675 (* 1 = 0.0701675 loss)
I0530 08:24:29.247262 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.171993 (* 1 = 0.171993 loss)
I0530 08:24:29.247282 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0302533 (* 1 = 0.0302533 loss)
I0530 08:24:29.247285 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0893142 (* 1 = 0.0893142 loss)
I0530 08:24:29.247292 24924 sgd_solver.cpp:106] Iteration 15280, lr = 0.0002
I0530 08:25:17.913075 24924 solver.cpp:228] Iteration 15300, loss = 0.434693
I0530 08:25:17.913100 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:25:17.913108 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0537582 (* 1 = 0.0537582 loss)
I0530 08:25:17.913113 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0587353 (* 1 = 0.0587353 loss)
I0530 08:25:17.913118 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276517 (* 1 = 0.00276517 loss)
I0530 08:25:17.913123 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144507 (* 1 = 0.0144507 loss)
I0530 08:25:17.913130 24924 sgd_solver.cpp:106] Iteration 15300, lr = 0.0002
I0530 08:26:06.593919 24924 solver.cpp:228] Iteration 15320, loss = 0.307425
I0530 08:26:06.593955 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 08:26:06.593962 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.146449 (* 1 = 0.146449 loss)
I0530 08:26:06.593966 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.345751 (* 1 = 0.345751 loss)
I0530 08:26:06.593971 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0341658 (* 1 = 0.0341658 loss)
I0530 08:26:06.593976 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.104011 (* 1 = 0.104011 loss)
I0530 08:26:06.593983 24924 sgd_solver.cpp:106] Iteration 15320, lr = 0.0002
I0530 08:26:55.221536 24924 solver.cpp:228] Iteration 15340, loss = 0.40119
I0530 08:26:55.221571 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 08:26:55.221577 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.16191 (* 1 = 0.16191 loss)
I0530 08:26:55.221581 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.218249 (* 1 = 0.218249 loss)
I0530 08:26:55.221585 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256792 (* 1 = 0.0256792 loss)
I0530 08:26:55.221587 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0391789 (* 1 = 0.0391789 loss)
I0530 08:26:55.221591 24924 sgd_solver.cpp:106] Iteration 15340, lr = 0.0002
I0530 08:27:43.924263 24924 solver.cpp:228] Iteration 15360, loss = 0.174115
I0530 08:27:43.924299 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 08:27:43.924305 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00783151 (* 1 = 0.00783151 loss)
I0530 08:27:43.924309 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.112189 (* 1 = 0.112189 loss)
I0530 08:27:43.924312 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737215 (* 1 = 0.00737215 loss)
I0530 08:27:43.924315 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00746439 (* 1 = 0.00746439 loss)
I0530 08:27:43.924319 24924 sgd_solver.cpp:106] Iteration 15360, lr = 0.0002
I0530 08:28:32.618988 24924 solver.cpp:228] Iteration 15380, loss = 0.268568
I0530 08:28:32.619024 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 08:28:32.619030 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.104578 (* 1 = 0.104578 loss)
I0530 08:28:32.619033 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.253223 (* 1 = 0.253223 loss)
I0530 08:28:32.619037 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00474367 (* 1 = 0.00474367 loss)
I0530 08:28:32.619040 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252109 (* 1 = 0.0252109 loss)
I0530 08:28:32.619045 24924 sgd_solver.cpp:106] Iteration 15380, lr = 0.0002
speed: 2.437s / iter
I0530 08:29:21.317800 24924 solver.cpp:228] Iteration 15400, loss = 0.291309
I0530 08:29:21.317836 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 08:29:21.317842 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0497835 (* 1 = 0.0497835 loss)
I0530 08:29:21.317847 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.281632 (* 1 = 0.281632 loss)
I0530 08:29:21.317849 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0269251 (* 1 = 0.0269251 loss)
I0530 08:29:21.317853 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159957 (* 1 = 0.0159957 loss)
I0530 08:29:21.317857 24924 sgd_solver.cpp:106] Iteration 15400, lr = 0.0002
I0530 08:30:10.008935 24924 solver.cpp:228] Iteration 15420, loss = 0.327989
I0530 08:30:10.008957 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 08:30:10.008963 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.22553 (* 1 = 0.22553 loss)
I0530 08:30:10.008967 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.265835 (* 1 = 0.265835 loss)
I0530 08:30:10.008970 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021157 (* 1 = 0.021157 loss)
I0530 08:30:10.008973 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514573 (* 1 = 0.0514573 loss)
I0530 08:30:10.008977 24924 sgd_solver.cpp:106] Iteration 15420, lr = 0.0002
I0530 08:30:58.752857 24924 solver.cpp:228] Iteration 15440, loss = 0.396788
I0530 08:30:58.752897 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 08:30:58.752904 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102913 (* 1 = 0.102913 loss)
I0530 08:30:58.752909 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.220486 (* 1 = 0.220486 loss)
I0530 08:30:58.752918 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00744068 (* 1 = 0.00744068 loss)
I0530 08:30:58.752921 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0255656 (* 1 = 0.0255656 loss)
I0530 08:30:58.752926 24924 sgd_solver.cpp:106] Iteration 15440, lr = 0.0002
I0530 08:31:47.367388 24924 solver.cpp:228] Iteration 15460, loss = 0.253237
I0530 08:31:47.367410 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 08:31:47.367419 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.185098 (* 1 = 0.185098 loss)
I0530 08:31:47.367439 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.281186 (* 1 = 0.281186 loss)
I0530 08:31:47.367442 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195895 (* 1 = 0.0195895 loss)
I0530 08:31:47.367447 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0530773 (* 1 = 0.0530773 loss)
I0530 08:31:47.367453 24924 sgd_solver.cpp:106] Iteration 15460, lr = 0.0002
I0530 08:32:36.029765 24924 solver.cpp:228] Iteration 15480, loss = 0.377043
I0530 08:32:36.029788 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 08:32:36.029796 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.132922 (* 1 = 0.132922 loss)
I0530 08:32:36.029816 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.246322 (* 1 = 0.246322 loss)
I0530 08:32:36.029821 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106317 (* 1 = 0.0106317 loss)
I0530 08:32:36.029826 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316774 (* 1 = 0.0316774 loss)
I0530 08:32:36.029832 24924 sgd_solver.cpp:106] Iteration 15480, lr = 0.0002
I0530 08:33:24.737114 24924 solver.cpp:228] Iteration 15500, loss = 0.271906
I0530 08:33:24.737150 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 08:33:24.737157 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.107527 (* 1 = 0.107527 loss)
I0530 08:33:24.737160 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.223136 (* 1 = 0.223136 loss)
I0530 08:33:24.737164 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00952188 (* 1 = 0.00952188 loss)
I0530 08:33:24.737167 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204176 (* 1 = 0.0204176 loss)
I0530 08:33:24.737171 24924 sgd_solver.cpp:106] Iteration 15500, lr = 0.0002
I0530 08:34:13.360450 24924 solver.cpp:228] Iteration 15520, loss = 0.664105
I0530 08:34:13.360486 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.585938
I0530 08:34:13.360491 24924 solver.cpp:244]     Train net output #1: loss_bbox = 1.04712 (* 1 = 1.04712 loss)
I0530 08:34:13.360496 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.677566 (* 1 = 0.677566 loss)
I0530 08:34:13.360498 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0834927 (* 1 = 0.0834927 loss)
I0530 08:34:13.360502 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.372324 (* 1 = 0.372324 loss)
I0530 08:34:13.360505 24924 sgd_solver.cpp:106] Iteration 15520, lr = 0.0002
I0530 08:35:02.026777 24924 solver.cpp:228] Iteration 15540, loss = 0.420714
I0530 08:35:02.026800 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.734375
I0530 08:35:02.026806 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.55726 (* 1 = 0.55726 loss)
I0530 08:35:02.026810 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.549468 (* 1 = 0.549468 loss)
I0530 08:35:02.026813 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0540415 (* 1 = 0.0540415 loss)
I0530 08:35:02.026816 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.168793 (* 1 = 0.168793 loss)
I0530 08:35:02.026820 24924 sgd_solver.cpp:106] Iteration 15540, lr = 0.0002
I0530 08:35:50.723237 24924 solver.cpp:228] Iteration 15560, loss = 0.225769
I0530 08:35:50.723258 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 08:35:50.723279 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.106682 (* 1 = 0.106682 loss)
I0530 08:35:50.723284 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.209913 (* 1 = 0.209913 loss)
I0530 08:35:50.723286 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107628 (* 1 = 0.0107628 loss)
I0530 08:35:50.723289 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172105 (* 1 = 0.0172105 loss)
I0530 08:35:50.723294 24924 sgd_solver.cpp:106] Iteration 15560, lr = 0.0002
I0530 08:36:39.374135 24924 solver.cpp:228] Iteration 15580, loss = 0.168278
I0530 08:36:39.374155 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 08:36:39.374163 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.156986 (* 1 = 0.156986 loss)
I0530 08:36:39.374182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.176809 (* 1 = 0.176809 loss)
I0530 08:36:39.374187 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153232 (* 1 = 0.0153232 loss)
I0530 08:36:39.374192 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.050356 (* 1 = 0.050356 loss)
I0530 08:36:39.374198 24924 sgd_solver.cpp:106] Iteration 15580, lr = 0.0002
speed: 2.437s / iter
I0530 08:37:28.101850 24924 solver.cpp:228] Iteration 15600, loss = 0.304129
I0530 08:37:28.101872 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 08:37:28.101881 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0771777 (* 1 = 0.0771777 loss)
I0530 08:37:28.101900 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.17999 (* 1 = 0.17999 loss)
I0530 08:37:28.101905 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00997641 (* 1 = 0.00997641 loss)
I0530 08:37:28.101910 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00610021 (* 1 = 0.00610021 loss)
I0530 08:37:28.101917 24924 sgd_solver.cpp:106] Iteration 15600, lr = 0.0002
I0530 08:38:16.764715 24924 solver.cpp:228] Iteration 15620, loss = 0.303905
I0530 08:38:16.764740 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 08:38:16.764748 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121236 (* 1 = 0.0121236 loss)
I0530 08:38:16.764768 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0751393 (* 1 = 0.0751393 loss)
I0530 08:38:16.764773 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160936 (* 1 = 0.0160936 loss)
I0530 08:38:16.764777 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00885467 (* 1 = 0.00885467 loss)
I0530 08:38:16.764784 24924 sgd_solver.cpp:106] Iteration 15620, lr = 0.0002
I0530 08:39:05.486937 24924 solver.cpp:228] Iteration 15640, loss = 0.346072
I0530 08:39:05.486963 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 08:39:05.486970 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0722743 (* 1 = 0.0722743 loss)
I0530 08:39:05.486990 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.180157 (* 1 = 0.180157 loss)
I0530 08:39:05.486995 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161633 (* 1 = 0.0161633 loss)
I0530 08:39:05.486999 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0460401 (* 1 = 0.0460401 loss)
I0530 08:39:05.487005 24924 sgd_solver.cpp:106] Iteration 15640, lr = 0.0002
I0530 08:39:54.166534 24924 solver.cpp:228] Iteration 15660, loss = 0.526259
I0530 08:39:54.166558 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:39:54.166568 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0801397 (* 1 = 0.0801397 loss)
I0530 08:39:54.166574 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.120708 (* 1 = 0.120708 loss)
I0530 08:39:54.166579 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108638 (* 1 = 0.0108638 loss)
I0530 08:39:54.166584 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235917 (* 1 = 0.0235917 loss)
I0530 08:39:54.166590 24924 sgd_solver.cpp:106] Iteration 15660, lr = 0.0002
I0530 08:40:43.029652 24924 solver.cpp:228] Iteration 15680, loss = 0.671538
I0530 08:40:43.029677 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:40:43.029686 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0313091 (* 1 = 0.0313091 loss)
I0530 08:40:43.029692 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0732551 (* 1 = 0.0732551 loss)
I0530 08:40:43.029697 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00457261 (* 1 = 0.00457261 loss)
I0530 08:40:43.029703 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00812668 (* 1 = 0.00812668 loss)
I0530 08:40:43.029709 24924 sgd_solver.cpp:106] Iteration 15680, lr = 0.0002
I0530 08:41:31.849802 24924 solver.cpp:228] Iteration 15700, loss = 0.242581
I0530 08:41:31.849825 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:41:31.849835 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0693006 (* 1 = 0.0693006 loss)
I0530 08:41:31.849841 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0679835 (* 1 = 0.0679835 loss)
I0530 08:41:31.849846 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0024034 (* 1 = 0.0024034 loss)
I0530 08:41:31.849851 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109586 (* 1 = 0.0109586 loss)
I0530 08:41:31.849858 24924 sgd_solver.cpp:106] Iteration 15700, lr = 0.0002
I0530 08:42:20.739403 24924 solver.cpp:228] Iteration 15720, loss = 0.247221
I0530 08:42:20.739428 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 08:42:20.739436 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.08431 (* 1 = 0.08431 loss)
I0530 08:42:20.739444 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.236064 (* 1 = 0.236064 loss)
I0530 08:42:20.739449 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.031947 (* 1 = 0.031947 loss)
I0530 08:42:20.739454 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0404722 (* 1 = 0.0404722 loss)
I0530 08:42:20.739459 24924 sgd_solver.cpp:106] Iteration 15720, lr = 0.0002
I0530 08:43:09.583200 24924 solver.cpp:228] Iteration 15740, loss = 0.345186
I0530 08:43:09.583223 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 08:43:09.583230 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0904176 (* 1 = 0.0904176 loss)
I0530 08:43:09.583235 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160898 (* 1 = 0.160898 loss)
I0530 08:43:09.583238 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286925 (* 1 = 0.00286925 loss)
I0530 08:43:09.583241 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163968 (* 1 = 0.0163968 loss)
I0530 08:43:09.583246 24924 sgd_solver.cpp:106] Iteration 15740, lr = 0.0002
I0530 08:43:58.504040 24924 solver.cpp:228] Iteration 15760, loss = 0.239292
I0530 08:43:58.504062 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 08:43:58.504070 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0260054 (* 1 = 0.0260054 loss)
I0530 08:43:58.504073 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0885726 (* 1 = 0.0885726 loss)
I0530 08:43:58.504077 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181023 (* 1 = 0.00181023 loss)
I0530 08:43:58.504081 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.040149 (* 1 = 0.040149 loss)
I0530 08:43:58.504086 24924 sgd_solver.cpp:106] Iteration 15760, lr = 0.0002
I0530 08:44:47.470296 24924 solver.cpp:228] Iteration 15780, loss = 0.731298
I0530 08:44:47.470331 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:44:47.470338 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0183409 (* 1 = 0.0183409 loss)
I0530 08:44:47.470342 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0808381 (* 1 = 0.0808381 loss)
I0530 08:44:47.470345 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00343642 (* 1 = 0.00343642 loss)
I0530 08:44:47.470348 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226323 (* 1 = 0.0226323 loss)
I0530 08:44:47.470353 24924 sgd_solver.cpp:106] Iteration 15780, lr = 0.0002
speed: 2.437s / iter
I0530 08:45:36.364809 24924 solver.cpp:228] Iteration 15800, loss = 0.431559
I0530 08:45:36.364831 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 08:45:36.364838 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.113301 (* 1 = 0.113301 loss)
I0530 08:45:36.364842 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.170688 (* 1 = 0.170688 loss)
I0530 08:45:36.364846 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00366555 (* 1 = 0.00366555 loss)
I0530 08:45:36.364850 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0179512 (* 1 = 0.0179512 loss)
I0530 08:45:36.364853 24924 sgd_solver.cpp:106] Iteration 15800, lr = 0.0002
I0530 08:46:25.341466 24924 solver.cpp:228] Iteration 15820, loss = 0.152648
I0530 08:46:25.341503 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:46:25.341509 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912308 (* 1 = 0.0912308 loss)
I0530 08:46:25.341513 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0764967 (* 1 = 0.0764967 loss)
I0530 08:46:25.341517 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00301197 (* 1 = 0.00301197 loss)
I0530 08:46:25.341521 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00959167 (* 1 = 0.00959167 loss)
I0530 08:46:25.341524 24924 sgd_solver.cpp:106] Iteration 15820, lr = 0.0002
I0530 08:47:14.264398 24924 solver.cpp:228] Iteration 15840, loss = 0.312129
I0530 08:47:14.264421 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:47:14.264441 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0803309 (* 1 = 0.0803309 loss)
I0530 08:47:14.264446 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.126231 (* 1 = 0.126231 loss)
I0530 08:47:14.264448 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0327451 (* 1 = 0.0327451 loss)
I0530 08:47:14.264451 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0394305 (* 1 = 0.0394305 loss)
I0530 08:47:14.264456 24924 sgd_solver.cpp:106] Iteration 15840, lr = 0.0002
I0530 08:48:03.292104 24924 solver.cpp:228] Iteration 15860, loss = 0.311882
I0530 08:48:03.292140 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:48:03.292147 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215779 (* 1 = 0.0215779 loss)
I0530 08:48:03.292151 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0646257 (* 1 = 0.0646257 loss)
I0530 08:48:03.292155 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0068912 (* 1 = 0.0068912 loss)
I0530 08:48:03.292160 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154977 (* 1 = 0.0154977 loss)
I0530 08:48:03.292166 24924 sgd_solver.cpp:106] Iteration 15860, lr = 0.0002
I0530 08:48:52.210789 24924 solver.cpp:228] Iteration 15880, loss = 0.396904
I0530 08:48:52.210813 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:48:52.210819 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0565611 (* 1 = 0.0565611 loss)
I0530 08:48:52.210824 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102609 (* 1 = 0.102609 loss)
I0530 08:48:52.210826 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00510024 (* 1 = 0.00510024 loss)
I0530 08:48:52.210829 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00921939 (* 1 = 0.00921939 loss)
I0530 08:48:52.210834 24924 sgd_solver.cpp:106] Iteration 15880, lr = 0.0002
I0530 08:49:41.201200 24924 solver.cpp:228] Iteration 15900, loss = 0.535067
I0530 08:49:41.201233 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 08:49:41.201239 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0119855 (* 1 = 0.0119855 loss)
I0530 08:49:41.201243 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0479826 (* 1 = 0.0479826 loss)
I0530 08:49:41.201246 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00820292 (* 1 = 0.00820292 loss)
I0530 08:49:41.201249 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213083 (* 1 = 0.0213083 loss)
I0530 08:49:41.201253 24924 sgd_solver.cpp:106] Iteration 15900, lr = 0.0002
I0530 08:50:30.164916 24924 solver.cpp:228] Iteration 15920, loss = 0.383795
I0530 08:50:30.164958 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 08:50:30.164963 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.108005 (* 1 = 0.108005 loss)
I0530 08:50:30.164968 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.20842 (* 1 = 0.20842 loss)
I0530 08:50:30.164970 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00988961 (* 1 = 0.00988961 loss)
I0530 08:50:30.164973 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387097 (* 1 = 0.0387097 loss)
I0530 08:50:30.164978 24924 sgd_solver.cpp:106] Iteration 15920, lr = 0.0002
I0530 08:51:19.077121 24924 solver.cpp:228] Iteration 15940, loss = 0.557657
I0530 08:51:19.077157 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 08:51:19.077163 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.195368 (* 1 = 0.195368 loss)
I0530 08:51:19.077167 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.189929 (* 1 = 0.189929 loss)
I0530 08:51:19.077170 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00642534 (* 1 = 0.00642534 loss)
I0530 08:51:19.077173 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.044831 (* 1 = 0.044831 loss)
I0530 08:51:19.077178 24924 sgd_solver.cpp:106] Iteration 15940, lr = 0.0002
I0530 08:52:07.980943 24924 solver.cpp:228] Iteration 15960, loss = 0.240065
I0530 08:52:07.980965 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 08:52:07.980971 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0531429 (* 1 = 0.0531429 loss)
I0530 08:52:07.980975 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.163158 (* 1 = 0.163158 loss)
I0530 08:52:07.980978 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0198386 (* 1 = 0.0198386 loss)
I0530 08:52:07.980981 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00926925 (* 1 = 0.00926925 loss)
I0530 08:52:07.980985 24924 sgd_solver.cpp:106] Iteration 15960, lr = 0.0002
I0530 08:52:56.885166 24924 solver.cpp:228] Iteration 15980, loss = 0.345595
I0530 08:52:56.885188 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 08:52:56.885195 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822901 (* 1 = 0.0822901 loss)
I0530 08:52:56.885198 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113164 (* 1 = 0.113164 loss)
I0530 08:52:56.885201 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0296265 (* 1 = 0.0296265 loss)
I0530 08:52:56.885205 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.063461 (* 1 = 0.063461 loss)
I0530 08:52:56.885208 24924 sgd_solver.cpp:106] Iteration 15980, lr = 0.0002
speed: 2.437s / iter
I0530 08:53:45.695508 24924 solver.cpp:228] Iteration 16000, loss = 0.31663
I0530 08:53:45.695544 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 08:53:45.695551 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.101693 (* 1 = 0.101693 loss)
I0530 08:53:45.695555 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.234935 (* 1 = 0.234935 loss)
I0530 08:53:45.695559 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0255976 (* 1 = 0.0255976 loss)
I0530 08:53:45.695561 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0908695 (* 1 = 0.0908695 loss)
I0530 08:53:45.695565 24924 sgd_solver.cpp:106] Iteration 16000, lr = 0.0002
I0530 08:54:34.538085 24924 solver.cpp:228] Iteration 16020, loss = 0.261687
I0530 08:54:34.538120 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:54:34.538126 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0751121 (* 1 = 0.0751121 loss)
I0530 08:54:34.538130 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142926 (* 1 = 0.142926 loss)
I0530 08:54:34.538133 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141209 (* 1 = 0.0141209 loss)
I0530 08:54:34.538136 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205595 (* 1 = 0.0205595 loss)
I0530 08:54:34.538141 24924 sgd_solver.cpp:106] Iteration 16020, lr = 0.0002
I0530 08:55:23.351172 24924 solver.cpp:228] Iteration 16040, loss = 0.205856
I0530 08:55:23.351208 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 08:55:23.351214 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228067 (* 1 = 0.0228067 loss)
I0530 08:55:23.351218 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0834615 (* 1 = 0.0834615 loss)
I0530 08:55:23.351222 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00799347 (* 1 = 0.00799347 loss)
I0530 08:55:23.351224 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183613 (* 1 = 0.0183613 loss)
I0530 08:55:23.351228 24924 sgd_solver.cpp:106] Iteration 16040, lr = 0.0002
I0530 08:56:12.187696 24924 solver.cpp:228] Iteration 16060, loss = 0.237426
I0530 08:56:12.187731 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 08:56:12.187739 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0922261 (* 1 = 0.0922261 loss)
I0530 08:56:12.187742 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.198994 (* 1 = 0.198994 loss)
I0530 08:56:12.187747 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00829807 (* 1 = 0.00829807 loss)
I0530 08:56:12.187749 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0368871 (* 1 = 0.0368871 loss)
I0530 08:56:12.187753 24924 sgd_solver.cpp:106] Iteration 16060, lr = 0.0002
I0530 08:57:01.032419 24924 solver.cpp:228] Iteration 16080, loss = 0.292681
I0530 08:57:01.032455 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 08:57:01.032462 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574074 (* 1 = 0.0574074 loss)
I0530 08:57:01.032465 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0663784 (* 1 = 0.0663784 loss)
I0530 08:57:01.032469 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00163299 (* 1 = 0.00163299 loss)
I0530 08:57:01.032472 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0055336 (* 1 = 0.0055336 loss)
I0530 08:57:01.032476 24924 sgd_solver.cpp:106] Iteration 16080, lr = 0.0002
I0530 08:57:49.907445 24924 solver.cpp:228] Iteration 16100, loss = 0.625236
I0530 08:57:49.907481 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 08:57:49.907488 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0652295 (* 1 = 0.0652295 loss)
I0530 08:57:49.907491 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.136326 (* 1 = 0.136326 loss)
I0530 08:57:49.907495 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127058 (* 1 = 0.0127058 loss)
I0530 08:57:49.907497 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323579 (* 1 = 0.0323579 loss)
I0530 08:57:49.907502 24924 sgd_solver.cpp:106] Iteration 16100, lr = 0.0002
I0530 08:58:38.744534 24924 solver.cpp:228] Iteration 16120, loss = 0.285698
I0530 08:58:38.744559 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 08:58:38.744565 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0579897 (* 1 = 0.0579897 loss)
I0530 08:58:38.744570 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.169329 (* 1 = 0.169329 loss)
I0530 08:58:38.744572 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00701711 (* 1 = 0.00701711 loss)
I0530 08:58:38.744576 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241611 (* 1 = 0.0241611 loss)
I0530 08:58:38.744580 24924 sgd_solver.cpp:106] Iteration 16120, lr = 0.0002
I0530 08:59:27.646944 24924 solver.cpp:228] Iteration 16140, loss = 0.320169
I0530 08:59:27.646981 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 08:59:27.646987 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473203 (* 1 = 0.0473203 loss)
I0530 08:59:27.646991 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0915265 (* 1 = 0.0915265 loss)
I0530 08:59:27.646994 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145014 (* 1 = 0.0145014 loss)
I0530 08:59:27.646997 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0539914 (* 1 = 0.0539914 loss)
I0530 08:59:27.647001 24924 sgd_solver.cpp:106] Iteration 16140, lr = 0.0002
I0530 09:00:16.406560 24924 solver.cpp:228] Iteration 16160, loss = 0.271415
I0530 09:00:16.406596 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 09:00:16.406602 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.128709 (* 1 = 0.128709 loss)
I0530 09:00:16.406606 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.185638 (* 1 = 0.185638 loss)
I0530 09:00:16.406610 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101512 (* 1 = 0.0101512 loss)
I0530 09:00:16.406612 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231546 (* 1 = 0.0231546 loss)
I0530 09:00:16.406616 24924 sgd_solver.cpp:106] Iteration 16160, lr = 0.0002
I0530 09:01:05.157135 24924 solver.cpp:228] Iteration 16180, loss = 0.408034
I0530 09:01:05.157171 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 09:01:05.157177 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.265837 (* 1 = 0.265837 loss)
I0530 09:01:05.157181 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.286846 (* 1 = 0.286846 loss)
I0530 09:01:05.157184 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00254697 (* 1 = 0.00254697 loss)
I0530 09:01:05.157187 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0395324 (* 1 = 0.0395324 loss)
I0530 09:01:05.157192 24924 sgd_solver.cpp:106] Iteration 16180, lr = 0.0002
speed: 2.437s / iter
I0530 09:01:53.912950 24924 solver.cpp:228] Iteration 16200, loss = 0.390213
I0530 09:01:53.912984 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 09:01:53.912992 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.121182 (* 1 = 0.121182 loss)
I0530 09:01:53.912995 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.129494 (* 1 = 0.129494 loss)
I0530 09:01:53.912998 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011785 (* 1 = 0.011785 loss)
I0530 09:01:53.913002 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146507 (* 1 = 0.0146507 loss)
I0530 09:01:53.913005 24924 sgd_solver.cpp:106] Iteration 16200, lr = 0.0002
I0530 09:02:42.681520 24924 solver.cpp:228] Iteration 16220, loss = 0.267079
I0530 09:02:42.681555 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:02:42.681562 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0739294 (* 1 = 0.0739294 loss)
I0530 09:02:42.681565 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109693 (* 1 = 0.109693 loss)
I0530 09:02:42.681569 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178349 (* 1 = 0.0178349 loss)
I0530 09:02:42.681572 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100513 (* 1 = 0.0100513 loss)
I0530 09:02:42.681576 24924 sgd_solver.cpp:106] Iteration 16220, lr = 0.0002
I0530 09:03:31.352039 24924 solver.cpp:228] Iteration 16240, loss = 0.458164
I0530 09:03:31.352074 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:03:31.352082 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0502575 (* 1 = 0.0502575 loss)
I0530 09:03:31.352084 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0849831 (* 1 = 0.0849831 loss)
I0530 09:03:31.352087 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0034528 (* 1 = 0.0034528 loss)
I0530 09:03:31.352092 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0268052 (* 1 = 0.0268052 loss)
I0530 09:03:31.352095 24924 sgd_solver.cpp:106] Iteration 16240, lr = 0.0002
I0530 09:04:20.003648 24924 solver.cpp:228] Iteration 16260, loss = 0.403911
I0530 09:04:20.003671 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 09:04:20.003679 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.216621 (* 1 = 0.216621 loss)
I0530 09:04:20.003681 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291414 (* 1 = 0.291414 loss)
I0530 09:04:20.003684 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0273809 (* 1 = 0.0273809 loss)
I0530 09:04:20.003687 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0690508 (* 1 = 0.0690508 loss)
I0530 09:04:20.003692 24924 sgd_solver.cpp:106] Iteration 16260, lr = 0.0002
I0530 09:05:08.654899 24924 solver.cpp:228] Iteration 16280, loss = 0.234117
I0530 09:05:08.654934 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 09:05:08.654942 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00985721 (* 1 = 0.00985721 loss)
I0530 09:05:08.654945 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0569489 (* 1 = 0.0569489 loss)
I0530 09:05:08.654948 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00666935 (* 1 = 0.00666935 loss)
I0530 09:05:08.654952 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013225 (* 1 = 0.013225 loss)
I0530 09:05:08.654955 24924 sgd_solver.cpp:106] Iteration 16280, lr = 0.0002
I0530 09:05:57.337451 24924 solver.cpp:228] Iteration 16300, loss = 0.259487
I0530 09:05:57.337487 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 09:05:57.337493 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0880422 (* 1 = 0.0880422 loss)
I0530 09:05:57.337497 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.11136 (* 1 = 0.11136 loss)
I0530 09:05:57.337501 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0147775 (* 1 = 0.0147775 loss)
I0530 09:05:57.337503 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0707479 (* 1 = 0.0707479 loss)
I0530 09:05:57.337507 24924 sgd_solver.cpp:106] Iteration 16300, lr = 0.0002
I0530 09:06:45.920825 24924 solver.cpp:228] Iteration 16320, loss = 0.433544
I0530 09:06:45.920862 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0530 09:06:45.920868 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.509795 (* 1 = 0.509795 loss)
I0530 09:06:45.920871 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.658531 (* 1 = 0.658531 loss)
I0530 09:06:45.920876 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0268736 (* 1 = 0.0268736 loss)
I0530 09:06:45.920878 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.191091 (* 1 = 0.191091 loss)
I0530 09:06:45.920882 24924 sgd_solver.cpp:106] Iteration 16320, lr = 0.0002
I0530 09:07:34.519148 24924 solver.cpp:228] Iteration 16340, loss = 0.382678
I0530 09:07:34.519171 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:07:34.519181 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0542949 (* 1 = 0.0542949 loss)
I0530 09:07:34.519199 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0819662 (* 1 = 0.0819662 loss)
I0530 09:07:34.519204 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00769988 (* 1 = 0.00769988 loss)
I0530 09:07:34.519208 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0139815 (* 1 = 0.0139815 loss)
I0530 09:07:34.519215 24924 sgd_solver.cpp:106] Iteration 16340, lr = 0.0002
I0530 09:08:23.131928 24924 solver.cpp:228] Iteration 16360, loss = 0.186433
I0530 09:08:23.131953 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:08:23.131961 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0807042 (* 1 = 0.0807042 loss)
I0530 09:08:23.131968 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.129777 (* 1 = 0.129777 loss)
I0530 09:08:23.131973 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616892 (* 1 = 0.00616892 loss)
I0530 09:08:23.131978 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203044 (* 1 = 0.0203044 loss)
I0530 09:08:23.131984 24924 sgd_solver.cpp:106] Iteration 16360, lr = 0.0002
I0530 09:09:11.820096 24924 solver.cpp:228] Iteration 16380, loss = 0.41328
I0530 09:09:11.820118 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 09:09:11.820127 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.180312 (* 1 = 0.180312 loss)
I0530 09:09:11.820145 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.334244 (* 1 = 0.334244 loss)
I0530 09:09:11.820150 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00789205 (* 1 = 0.00789205 loss)
I0530 09:09:11.820154 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0453435 (* 1 = 0.0453435 loss)
I0530 09:09:11.820160 24924 sgd_solver.cpp:106] Iteration 16380, lr = 0.0002
speed: 2.437s / iter
I0530 09:10:00.441629 24924 solver.cpp:228] Iteration 16400, loss = 0.302299
I0530 09:10:00.441653 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 09:10:00.441663 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.104451 (* 1 = 0.104451 loss)
I0530 09:10:00.441668 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.312009 (* 1 = 0.312009 loss)
I0530 09:10:00.441673 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0258985 (* 1 = 0.0258985 loss)
I0530 09:10:00.441679 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0472509 (* 1 = 0.0472509 loss)
I0530 09:10:00.441685 24924 sgd_solver.cpp:106] Iteration 16400, lr = 0.0002
I0530 09:10:49.024729 24924 solver.cpp:228] Iteration 16420, loss = 0.282025
I0530 09:10:49.024765 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:10:49.024772 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362094 (* 1 = 0.0362094 loss)
I0530 09:10:49.024776 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0742762 (* 1 = 0.0742762 loss)
I0530 09:10:49.024780 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0320978 (* 1 = 0.0320978 loss)
I0530 09:10:49.024782 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124236 (* 1 = 0.0124236 loss)
I0530 09:10:49.024786 24924 sgd_solver.cpp:106] Iteration 16420, lr = 0.0002
I0530 09:11:37.655237 24924 solver.cpp:228] Iteration 16440, loss = 0.213272
I0530 09:11:37.655274 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:11:37.655282 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0828498 (* 1 = 0.0828498 loss)
I0530 09:11:37.655284 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143258 (* 1 = 0.143258 loss)
I0530 09:11:37.655288 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120582 (* 1 = 0.0120582 loss)
I0530 09:11:37.655290 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0344773 (* 1 = 0.0344773 loss)
I0530 09:11:37.655295 24924 sgd_solver.cpp:106] Iteration 16440, lr = 0.0002
I0530 09:12:26.275676 24924 solver.cpp:228] Iteration 16460, loss = 0.36505
I0530 09:12:26.275712 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 09:12:26.275719 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.45298 (* 1 = 0.45298 loss)
I0530 09:12:26.275722 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.482197 (* 1 = 0.482197 loss)
I0530 09:12:26.275727 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0276021 (* 1 = 0.0276021 loss)
I0530 09:12:26.275729 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106891 (* 1 = 0.106891 loss)
I0530 09:12:26.275733 24924 sgd_solver.cpp:106] Iteration 16460, lr = 0.0002
I0530 09:13:14.902930 24924 solver.cpp:228] Iteration 16480, loss = 0.529142
I0530 09:13:14.902954 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 09:13:14.902961 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0966573 (* 1 = 0.0966573 loss)
I0530 09:13:14.902966 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.24289 (* 1 = 0.24289 loss)
I0530 09:13:14.902968 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0460058 (* 1 = 0.0460058 loss)
I0530 09:13:14.902972 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.032041 (* 1 = 0.032041 loss)
I0530 09:13:14.902976 24924 sgd_solver.cpp:106] Iteration 16480, lr = 0.0002
I0530 09:14:03.484164 24924 solver.cpp:228] Iteration 16500, loss = 0.197365
I0530 09:14:03.484200 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 09:14:03.484207 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0010515 (* 1 = 0.0010515 loss)
I0530 09:14:03.484210 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0409114 (* 1 = 0.0409114 loss)
I0530 09:14:03.484213 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134935 (* 1 = 0.0134935 loss)
I0530 09:14:03.484216 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150163 (* 1 = 0.0150163 loss)
I0530 09:14:03.484220 24924 sgd_solver.cpp:106] Iteration 16500, lr = 0.0002
I0530 09:14:52.060878 24924 solver.cpp:228] Iteration 16520, loss = 0.27573
I0530 09:14:52.060899 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 09:14:52.060905 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.178641 (* 1 = 0.178641 loss)
I0530 09:14:52.060909 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.353927 (* 1 = 0.353927 loss)
I0530 09:14:52.060915 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134369 (* 1 = 0.0134369 loss)
I0530 09:14:52.060919 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0355426 (* 1 = 0.0355426 loss)
I0530 09:14:52.060922 24924 sgd_solver.cpp:106] Iteration 16520, lr = 0.0002
I0530 09:15:40.649732 24924 solver.cpp:228] Iteration 16540, loss = 0.571412
I0530 09:15:40.649768 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:15:40.649775 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0716 (* 1 = 0.0716 loss)
I0530 09:15:40.649780 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.103336 (* 1 = 0.103336 loss)
I0530 09:15:40.649782 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00246823 (* 1 = 0.00246823 loss)
I0530 09:15:40.649786 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143376 (* 1 = 0.0143376 loss)
I0530 09:15:40.649791 24924 sgd_solver.cpp:106] Iteration 16540, lr = 0.0002
I0530 09:16:29.186009 24924 solver.cpp:228] Iteration 16560, loss = 0.171273
I0530 09:16:29.186030 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:16:29.186054 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333218 (* 1 = 0.0333218 loss)
I0530 09:16:29.186058 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0898209 (* 1 = 0.0898209 loss)
I0530 09:16:29.186060 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182929 (* 1 = 0.0182929 loss)
I0530 09:16:29.186064 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00385285 (* 1 = 0.00385285 loss)
I0530 09:16:29.186069 24924 sgd_solver.cpp:106] Iteration 16560, lr = 0.0002
I0530 09:17:17.817605 24924 solver.cpp:228] Iteration 16580, loss = 0.391637
I0530 09:17:17.817626 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:17:17.817633 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0857143 (* 1 = 0.0857143 loss)
I0530 09:17:17.817637 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.105913 (* 1 = 0.105913 loss)
I0530 09:17:17.817641 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00633395 (* 1 = 0.00633395 loss)
I0530 09:17:17.817644 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0141538 (* 1 = 0.0141538 loss)
I0530 09:17:17.817648 24924 sgd_solver.cpp:106] Iteration 16580, lr = 0.0002
speed: 2.437s / iter
I0530 09:18:06.404227 24924 solver.cpp:228] Iteration 16600, loss = 0.333836
I0530 09:18:06.404263 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 09:18:06.404270 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.256111 (* 1 = 0.256111 loss)
I0530 09:18:06.404274 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.333691 (* 1 = 0.333691 loss)
I0530 09:18:06.404279 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00497216 (* 1 = 0.00497216 loss)
I0530 09:18:06.404284 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0416407 (* 1 = 0.0416407 loss)
I0530 09:18:06.404290 24924 sgd_solver.cpp:106] Iteration 16600, lr = 0.0002
I0530 09:18:54.974534 24924 solver.cpp:228] Iteration 16620, loss = 0.27972
I0530 09:18:54.974556 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:18:54.974577 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475063 (* 1 = 0.0475063 loss)
I0530 09:18:54.974581 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.181533 (* 1 = 0.181533 loss)
I0530 09:18:54.974584 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0178139 (* 1 = 0.0178139 loss)
I0530 09:18:54.974587 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00749822 (* 1 = 0.00749822 loss)
I0530 09:18:54.974591 24924 sgd_solver.cpp:106] Iteration 16620, lr = 0.0002
I0530 09:19:43.608314 24924 solver.cpp:228] Iteration 16640, loss = 0.378149
I0530 09:19:43.608350 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 09:19:43.608356 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.195593 (* 1 = 0.195593 loss)
I0530 09:19:43.608361 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.253022 (* 1 = 0.253022 loss)
I0530 09:19:43.608364 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232192 (* 1 = 0.0232192 loss)
I0530 09:19:43.608369 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0516287 (* 1 = 0.0516287 loss)
I0530 09:19:43.608376 24924 sgd_solver.cpp:106] Iteration 16640, lr = 0.0002
I0530 09:20:32.224174 24924 solver.cpp:228] Iteration 16660, loss = 0.24254
I0530 09:20:32.224208 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:20:32.224216 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0313739 (* 1 = 0.0313739 loss)
I0530 09:20:32.224220 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.106247 (* 1 = 0.106247 loss)
I0530 09:20:32.224225 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139413 (* 1 = 0.0139413 loss)
I0530 09:20:32.224229 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00768735 (* 1 = 0.00768735 loss)
I0530 09:20:32.224236 24924 sgd_solver.cpp:106] Iteration 16660, lr = 0.0002
I0530 09:21:20.878490 24924 solver.cpp:228] Iteration 16680, loss = 0.378206
I0530 09:21:20.878515 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:21:20.878521 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0251969 (* 1 = 0.0251969 loss)
I0530 09:21:20.878527 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0790242 (* 1 = 0.0790242 loss)
I0530 09:21:20.878533 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00416138 (* 1 = 0.00416138 loss)
I0530 09:21:20.878537 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00447878 (* 1 = 0.00447878 loss)
I0530 09:21:20.878542 24924 sgd_solver.cpp:106] Iteration 16680, lr = 0.0002
I0530 09:22:09.954246 24924 solver.cpp:228] Iteration 16700, loss = 0.272592
I0530 09:22:09.954282 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:22:09.954288 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160331 (* 1 = 0.0160331 loss)
I0530 09:22:09.954291 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0885958 (* 1 = 0.0885958 loss)
I0530 09:22:09.954295 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956453 (* 1 = 0.00956453 loss)
I0530 09:22:09.954298 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00827269 (* 1 = 0.00827269 loss)
I0530 09:22:09.954303 24924 sgd_solver.cpp:106] Iteration 16700, lr = 0.0002
I0530 09:22:59.423157 24924 solver.cpp:228] Iteration 16720, loss = 0.513494
I0530 09:22:59.423179 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:22:59.423187 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0551734 (* 1 = 0.0551734 loss)
I0530 09:22:59.423190 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.164207 (* 1 = 0.164207 loss)
I0530 09:22:59.423193 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.15398 (* 1 = 0.15398 loss)
I0530 09:22:59.423197 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.521033 (* 1 = 0.521033 loss)
I0530 09:22:59.423202 24924 sgd_solver.cpp:106] Iteration 16720, lr = 0.0002
I0530 09:23:48.432447 24924 solver.cpp:228] Iteration 16740, loss = 0.490518
I0530 09:23:48.432469 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:23:48.432476 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383931 (* 1 = 0.0383931 loss)
I0530 09:23:48.432479 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.062383 (* 1 = 0.062383 loss)
I0530 09:23:48.432482 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00071396 (* 1 = 0.00071396 loss)
I0530 09:23:48.432487 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00576879 (* 1 = 0.00576879 loss)
I0530 09:23:48.432490 24924 sgd_solver.cpp:106] Iteration 16740, lr = 0.0002
I0530 09:24:37.892392 24924 solver.cpp:228] Iteration 16760, loss = 0.423002
I0530 09:24:37.892431 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:24:37.892438 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0087224 (* 1 = 0.0087224 loss)
I0530 09:24:37.892442 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.126831 (* 1 = 0.126831 loss)
I0530 09:24:37.892446 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0157219 (* 1 = 0.0157219 loss)
I0530 09:24:37.892452 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108108 (* 1 = 0.0108108 loss)
I0530 09:24:37.892457 24924 sgd_solver.cpp:106] Iteration 16760, lr = 0.0002
I0530 09:25:27.757534 24924 solver.cpp:228] Iteration 16780, loss = 0.428475
I0530 09:25:27.757556 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:25:27.757563 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435765 (* 1 = 0.0435765 loss)
I0530 09:25:27.757567 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0872061 (* 1 = 0.0872061 loss)
I0530 09:25:27.757571 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00262926 (* 1 = 0.00262926 loss)
I0530 09:25:27.757575 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0056169 (* 1 = 0.0056169 loss)
I0530 09:25:27.757578 24924 sgd_solver.cpp:106] Iteration 16780, lr = 0.0002
speed: 2.437s / iter
I0530 09:26:17.697227 24924 solver.cpp:228] Iteration 16800, loss = 0.527818
I0530 09:26:17.697252 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.640625
I0530 09:26:17.697257 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.590442 (* 1 = 0.590442 loss)
I0530 09:26:17.697262 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.698807 (* 1 = 0.698807 loss)
I0530 09:26:17.697264 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0744717 (* 1 = 0.0744717 loss)
I0530 09:26:17.697268 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.329799 (* 1 = 0.329799 loss)
I0530 09:26:17.697271 24924 sgd_solver.cpp:106] Iteration 16800, lr = 0.0002
I0530 09:27:08.464972 24924 solver.cpp:228] Iteration 16820, loss = 0.516867
I0530 09:27:08.464995 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:27:08.465013 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937678 (* 1 = 0.0937678 loss)
I0530 09:27:08.465018 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.150619 (* 1 = 0.150619 loss)
I0530 09:27:08.465020 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00386686 (* 1 = 0.00386686 loss)
I0530 09:27:08.465037 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.023378 (* 1 = 0.023378 loss)
I0530 09:27:08.465042 24924 sgd_solver.cpp:106] Iteration 16820, lr = 0.0002
I0530 09:27:57.343694 24924 solver.cpp:228] Iteration 16840, loss = 0.308567
I0530 09:27:57.343730 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 09:27:57.343739 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.197032 (* 1 = 0.197032 loss)
I0530 09:27:57.343742 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.332108 (* 1 = 0.332108 loss)
I0530 09:27:57.343745 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0350312 (* 1 = 0.0350312 loss)
I0530 09:27:57.343749 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.160721 (* 1 = 0.160721 loss)
I0530 09:27:57.343752 24924 sgd_solver.cpp:106] Iteration 16840, lr = 0.0002
I0530 09:28:46.677448 24924 solver.cpp:228] Iteration 16860, loss = 0.510719
I0530 09:28:46.677474 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:28:46.677480 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912498 (* 1 = 0.0912498 loss)
I0530 09:28:46.677484 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.402967 (* 1 = 0.402967 loss)
I0530 09:28:46.677487 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0315156 (* 1 = 0.0315156 loss)
I0530 09:28:46.677492 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019639 (* 1 = 0.019639 loss)
I0530 09:28:46.677500 24924 sgd_solver.cpp:106] Iteration 16860, lr = 0.0002
I0530 09:29:36.343233 24924 solver.cpp:228] Iteration 16880, loss = 0.371572
I0530 09:29:36.343257 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 09:29:36.343264 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.193476 (* 1 = 0.193476 loss)
I0530 09:29:36.343267 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.279764 (* 1 = 0.279764 loss)
I0530 09:29:36.343271 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00848627 (* 1 = 0.00848627 loss)
I0530 09:29:36.343276 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029823 (* 1 = 0.029823 loss)
I0530 09:29:36.343279 24924 sgd_solver.cpp:106] Iteration 16880, lr = 0.0002
I0530 09:30:25.687126 24924 solver.cpp:228] Iteration 16900, loss = 0.261695
I0530 09:30:25.687160 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:30:25.687182 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0124842 (* 1 = 0.0124842 loss)
I0530 09:30:25.687186 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0570297 (* 1 = 0.0570297 loss)
I0530 09:30:25.687189 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238086 (* 1 = 0.00238086 loss)
I0530 09:30:25.687192 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136197 (* 1 = 0.0136197 loss)
I0530 09:30:25.687196 24924 sgd_solver.cpp:106] Iteration 16900, lr = 0.0002
I0530 09:31:15.999266 24924 solver.cpp:228] Iteration 16920, loss = 0.210262
I0530 09:31:15.999289 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 09:31:15.999297 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0967972 (* 1 = 0.0967972 loss)
I0530 09:31:15.999316 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.191618 (* 1 = 0.191618 loss)
I0530 09:31:15.999321 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122762 (* 1 = 0.0122762 loss)
I0530 09:31:15.999326 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300993 (* 1 = 0.0300993 loss)
I0530 09:31:15.999332 24924 sgd_solver.cpp:106] Iteration 16920, lr = 0.0002
I0530 09:32:07.357920 24924 solver.cpp:228] Iteration 16940, loss = 0.436987
I0530 09:32:07.357944 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 09:32:07.357949 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.20655 (* 1 = 0.20655 loss)
I0530 09:32:07.357954 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.287218 (* 1 = 0.287218 loss)
I0530 09:32:07.357956 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01702 (* 1 = 0.01702 loss)
I0530 09:32:07.357959 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.055612 (* 1 = 0.055612 loss)
I0530 09:32:07.357964 24924 sgd_solver.cpp:106] Iteration 16940, lr = 0.0002
I0530 09:32:57.312949 24924 solver.cpp:228] Iteration 16960, loss = 0.230652
I0530 09:32:57.312971 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:32:57.312990 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0822856 (* 1 = 0.0822856 loss)
I0530 09:32:57.312994 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133674 (* 1 = 0.133674 loss)
I0530 09:32:57.312997 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00132396 (* 1 = 0.00132396 loss)
I0530 09:32:57.313014 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00851736 (* 1 = 0.00851736 loss)
I0530 09:32:57.313019 24924 sgd_solver.cpp:106] Iteration 16960, lr = 0.0002
I0530 09:33:46.752099 24924 solver.cpp:228] Iteration 16980, loss = 0.333758
I0530 09:33:46.752135 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 09:33:46.752141 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0793667 (* 1 = 0.0793667 loss)
I0530 09:33:46.752146 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.153632 (* 1 = 0.153632 loss)
I0530 09:33:46.752148 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00880988 (* 1 = 0.00880988 loss)
I0530 09:33:46.752151 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187869 (* 1 = 0.0187869 loss)
I0530 09:33:46.752156 24924 sgd_solver.cpp:106] Iteration 16980, lr = 0.0002
speed: 2.438s / iter
I0530 09:34:35.988634 24924 solver.cpp:228] Iteration 17000, loss = 0.348401
I0530 09:34:35.988657 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:34:35.988663 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00256487 (* 1 = 0.00256487 loss)
I0530 09:34:35.988667 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0879015 (* 1 = 0.0879015 loss)
I0530 09:34:35.988670 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0250074 (* 1 = 0.0250074 loss)
I0530 09:34:35.988673 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0334016 (* 1 = 0.0334016 loss)
I0530 09:34:35.988677 24924 sgd_solver.cpp:106] Iteration 17000, lr = 0.0002
I0530 09:35:25.045812 24924 solver.cpp:228] Iteration 17020, loss = 0.216881
I0530 09:35:25.045840 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 09:35:25.045846 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0169549 (* 1 = 0.0169549 loss)
I0530 09:35:25.045850 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0354435 (* 1 = 0.0354435 loss)
I0530 09:35:25.045853 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00827877 (* 1 = 0.00827877 loss)
I0530 09:35:25.045856 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01306 (* 1 = 0.01306 loss)
I0530 09:35:25.045861 24924 sgd_solver.cpp:106] Iteration 17020, lr = 0.0002
I0530 09:36:14.155258 24924 solver.cpp:228] Iteration 17040, loss = 0.332744
I0530 09:36:14.155299 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:36:14.155306 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0159568 (* 1 = 0.0159568 loss)
I0530 09:36:14.155309 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0798642 (* 1 = 0.0798642 loss)
I0530 09:36:14.155313 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118649 (* 1 = 0.0118649 loss)
I0530 09:36:14.155315 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0847629 (* 1 = 0.0847629 loss)
I0530 09:36:14.155320 24924 sgd_solver.cpp:106] Iteration 17040, lr = 0.0002
I0530 09:37:03.271088 24924 solver.cpp:228] Iteration 17060, loss = 0.323754
I0530 09:37:03.271117 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:37:03.271124 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0572859 (* 1 = 0.0572859 loss)
I0530 09:37:03.271129 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115992 (* 1 = 0.115992 loss)
I0530 09:37:03.271132 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00351732 (* 1 = 0.00351732 loss)
I0530 09:37:03.271136 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00254195 (* 1 = 0.00254195 loss)
I0530 09:37:03.271142 24924 sgd_solver.cpp:106] Iteration 17060, lr = 0.0002
I0530 09:37:52.418154 24924 solver.cpp:228] Iteration 17080, loss = 0.259804
I0530 09:37:52.418180 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:37:52.418189 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0836296 (* 1 = 0.0836296 loss)
I0530 09:37:52.418193 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.13372 (* 1 = 0.13372 loss)
I0530 09:37:52.418196 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107902 (* 1 = 0.0107902 loss)
I0530 09:37:52.418200 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0545899 (* 1 = 0.0545899 loss)
I0530 09:37:52.418205 24924 sgd_solver.cpp:106] Iteration 17080, lr = 0.0002
I0530 09:38:41.550593 24924 solver.cpp:228] Iteration 17100, loss = 0.222722
I0530 09:38:41.550621 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:38:41.550626 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0664486 (* 1 = 0.0664486 loss)
I0530 09:38:41.550631 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.121122 (* 1 = 0.121122 loss)
I0530 09:38:41.550633 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109742 (* 1 = 0.0109742 loss)
I0530 09:38:41.550637 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0635314 (* 1 = 0.0635314 loss)
I0530 09:38:41.550642 24924 sgd_solver.cpp:106] Iteration 17100, lr = 0.0002
I0530 09:39:30.684801 24924 solver.cpp:228] Iteration 17120, loss = 0.286426
I0530 09:39:30.684825 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 09:39:30.684833 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.110021 (* 1 = 0.110021 loss)
I0530 09:39:30.684836 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139945 (* 1 = 0.139945 loss)
I0530 09:39:30.684839 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115374 (* 1 = 0.0115374 loss)
I0530 09:39:30.684842 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.025211 (* 1 = 0.025211 loss)
I0530 09:39:30.684847 24924 sgd_solver.cpp:106] Iteration 17120, lr = 0.0002
I0530 09:40:19.805981 24924 solver.cpp:228] Iteration 17140, loss = 0.284108
I0530 09:40:19.806010 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:40:19.806020 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256227 (* 1 = 0.0256227 loss)
I0530 09:40:19.806025 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0888552 (* 1 = 0.0888552 loss)
I0530 09:40:19.806030 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00440194 (* 1 = 0.00440194 loss)
I0530 09:40:19.806035 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00190041 (* 1 = 0.00190041 loss)
I0530 09:40:19.806041 24924 sgd_solver.cpp:106] Iteration 17140, lr = 0.0002
I0530 09:41:08.950038 24924 solver.cpp:228] Iteration 17160, loss = 0.284494
I0530 09:41:08.950063 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 09:41:08.950070 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264288 (* 1 = 0.0264288 loss)
I0530 09:41:08.950074 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.146145 (* 1 = 0.146145 loss)
I0530 09:41:08.950078 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00692663 (* 1 = 0.00692663 loss)
I0530 09:41:08.950081 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112504 (* 1 = 0.0112504 loss)
I0530 09:41:08.950085 24924 sgd_solver.cpp:106] Iteration 17160, lr = 0.0002
I0530 09:41:58.098677 24924 solver.cpp:228] Iteration 17180, loss = 0.462041
I0530 09:41:58.098703 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 09:41:58.098711 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00457755 (* 1 = 0.00457755 loss)
I0530 09:41:58.098716 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0575357 (* 1 = 0.0575357 loss)
I0530 09:41:58.098719 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0109809 (* 1 = 0.0109809 loss)
I0530 09:41:58.098722 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372928 (* 1 = 0.0372928 loss)
I0530 09:41:58.098727 24924 sgd_solver.cpp:106] Iteration 17180, lr = 0.0002
speed: 2.438s / iter
I0530 09:42:47.229050 24924 solver.cpp:228] Iteration 17200, loss = 0.574224
I0530 09:42:47.229076 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:42:47.229084 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0624772 (* 1 = 0.0624772 loss)
I0530 09:42:47.229087 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.105623 (* 1 = 0.105623 loss)
I0530 09:42:47.229090 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00372367 (* 1 = 0.00372367 loss)
I0530 09:42:47.229094 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.010774 (* 1 = 0.010774 loss)
I0530 09:42:47.229099 24924 sgd_solver.cpp:106] Iteration 17200, lr = 0.0002
I0530 09:43:36.134129 24924 solver.cpp:228] Iteration 17220, loss = 0.189147
I0530 09:43:36.134165 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:43:36.134171 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0326754 (* 1 = 0.0326754 loss)
I0530 09:43:36.134174 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0861847 (* 1 = 0.0861847 loss)
I0530 09:43:36.134177 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00544766 (* 1 = 0.00544766 loss)
I0530 09:43:36.134181 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168026 (* 1 = 0.0168026 loss)
I0530 09:43:36.134186 24924 sgd_solver.cpp:106] Iteration 17220, lr = 0.0002
I0530 09:44:25.309219 24924 solver.cpp:228] Iteration 17240, loss = 0.362497
I0530 09:44:25.309242 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 09:44:25.309249 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.18279 (* 1 = 0.18279 loss)
I0530 09:44:25.309253 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.352707 (* 1 = 0.352707 loss)
I0530 09:44:25.309257 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.018421 (* 1 = 0.018421 loss)
I0530 09:44:25.309259 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0570091 (* 1 = 0.0570091 loss)
I0530 09:44:25.309264 24924 sgd_solver.cpp:106] Iteration 17240, lr = 0.0002
I0530 09:45:14.427181 24924 solver.cpp:228] Iteration 17260, loss = 0.25909
I0530 09:45:14.427248 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:45:14.427269 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.05096 (* 1 = 0.05096 loss)
I0530 09:45:14.427284 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144819 (* 1 = 0.144819 loss)
I0530 09:45:14.427299 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131657 (* 1 = 0.0131657 loss)
I0530 09:45:14.427311 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027118 (* 1 = 0.027118 loss)
I0530 09:45:14.427325 24924 sgd_solver.cpp:106] Iteration 17260, lr = 0.0002
I0530 09:46:04.535830 24924 solver.cpp:228] Iteration 17280, loss = 0.385955
I0530 09:46:04.535858 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:46:04.535866 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0891996 (* 1 = 0.0891996 loss)
I0530 09:46:04.535871 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.09495 (* 1 = 0.09495 loss)
I0530 09:46:04.535873 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00899919 (* 1 = 0.00899919 loss)
I0530 09:46:04.535878 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00984393 (* 1 = 0.00984393 loss)
I0530 09:46:04.535883 24924 sgd_solver.cpp:106] Iteration 17280, lr = 0.0002
I0530 09:46:54.064462 24924 solver.cpp:228] Iteration 17300, loss = 0.41095
I0530 09:46:54.064488 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 09:46:54.064496 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0605226 (* 1 = 0.0605226 loss)
I0530 09:46:54.064499 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.131307 (* 1 = 0.131307 loss)
I0530 09:46:54.064502 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126154 (* 1 = 0.0126154 loss)
I0530 09:46:54.064505 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013398 (* 1 = 0.013398 loss)
I0530 09:46:54.064510 24924 sgd_solver.cpp:106] Iteration 17300, lr = 0.0002
I0530 09:47:44.422518 24924 solver.cpp:228] Iteration 17320, loss = 0.305969
I0530 09:47:44.422555 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 09:47:44.422564 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00151657 (* 1 = 0.00151657 loss)
I0530 09:47:44.422567 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0604483 (* 1 = 0.0604483 loss)
I0530 09:47:44.422571 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00294434 (* 1 = 0.00294434 loss)
I0530 09:47:44.422574 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013495 (* 1 = 0.013495 loss)
I0530 09:47:44.422580 24924 sgd_solver.cpp:106] Iteration 17320, lr = 0.0002
I0530 09:48:33.791307 24924 solver.cpp:228] Iteration 17340, loss = 0.233407
I0530 09:48:33.791332 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:48:33.791340 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0757117 (* 1 = 0.0757117 loss)
I0530 09:48:33.791344 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.209148 (* 1 = 0.209148 loss)
I0530 09:48:33.791347 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125443 (* 1 = 0.0125443 loss)
I0530 09:48:33.791350 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111713 (* 1 = 0.0111713 loss)
I0530 09:48:33.791354 24924 sgd_solver.cpp:106] Iteration 17340, lr = 0.0002
I0530 09:49:23.861744 24924 solver.cpp:228] Iteration 17360, loss = 0.232325
I0530 09:49:23.861773 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 09:49:23.861783 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0524035 (* 1 = 0.0524035 loss)
I0530 09:49:23.861788 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.151634 (* 1 = 0.151634 loss)
I0530 09:49:23.861793 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00612799 (* 1 = 0.00612799 loss)
I0530 09:49:23.861799 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012009 (* 1 = 0.012009 loss)
I0530 09:49:23.861805 24924 sgd_solver.cpp:106] Iteration 17360, lr = 0.0002
I0530 09:50:13.704484 24924 solver.cpp:228] Iteration 17380, loss = 0.224886
I0530 09:50:13.704507 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:50:13.704516 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459535 (* 1 = 0.0459535 loss)
I0530 09:50:13.704522 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117032 (* 1 = 0.117032 loss)
I0530 09:50:13.704527 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118503 (* 1 = 0.0118503 loss)
I0530 09:50:13.704532 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120526 (* 1 = 0.0120526 loss)
I0530 09:50:13.704540 24924 sgd_solver.cpp:106] Iteration 17380, lr = 0.0002
speed: 2.439s / iter
I0530 09:51:03.596089 24924 solver.cpp:228] Iteration 17400, loss = 0.341963
I0530 09:51:03.596113 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 09:51:03.596120 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122507 (* 1 = 0.122507 loss)
I0530 09:51:03.596125 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133697 (* 1 = 0.133697 loss)
I0530 09:51:03.596128 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154801 (* 1 = 0.0154801 loss)
I0530 09:51:03.596132 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321297 (* 1 = 0.0321297 loss)
I0530 09:51:03.596137 24924 sgd_solver.cpp:106] Iteration 17400, lr = 0.0002
I0530 09:51:53.792654 24924 solver.cpp:228] Iteration 17420, loss = 0.227431
I0530 09:51:53.792677 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 09:51:53.792685 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599336 (* 1 = 0.0599336 loss)
I0530 09:51:53.792688 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.18005 (* 1 = 0.18005 loss)
I0530 09:51:53.792692 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00671381 (* 1 = 0.00671381 loss)
I0530 09:51:53.792695 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339983 (* 1 = 0.0339983 loss)
I0530 09:51:53.792699 24924 sgd_solver.cpp:106] Iteration 17420, lr = 0.0002
I0530 09:52:43.414634 24924 solver.cpp:228] Iteration 17440, loss = 0.462472
I0530 09:52:43.414674 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 09:52:43.414680 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472282 (* 1 = 0.0472282 loss)
I0530 09:52:43.414685 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.121665 (* 1 = 0.121665 loss)
I0530 09:52:43.414687 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103347 (* 1 = 0.0103347 loss)
I0530 09:52:43.414690 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0787281 (* 1 = 0.0787281 loss)
I0530 09:52:43.414695 24924 sgd_solver.cpp:106] Iteration 17440, lr = 0.0002
I0530 09:53:32.783625 24924 solver.cpp:228] Iteration 17460, loss = 0.256893
I0530 09:53:32.783648 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 09:53:32.783656 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.074121 (* 1 = 0.074121 loss)
I0530 09:53:32.783675 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.11044 (* 1 = 0.11044 loss)
I0530 09:53:32.783680 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766802 (* 1 = 0.00766802 loss)
I0530 09:53:32.783684 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00682472 (* 1 = 0.00682472 loss)
I0530 09:53:32.783690 24924 sgd_solver.cpp:106] Iteration 17460, lr = 0.0002
I0530 09:54:22.646963 24924 solver.cpp:228] Iteration 17480, loss = 0.274528
I0530 09:54:22.646988 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:54:22.646996 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0379325 (* 1 = 0.0379325 loss)
I0530 09:54:22.646999 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.237948 (* 1 = 0.237948 loss)
I0530 09:54:22.647003 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00403014 (* 1 = 0.00403014 loss)
I0530 09:54:22.647006 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0479442 (* 1 = 0.0479442 loss)
I0530 09:54:22.647011 24924 sgd_solver.cpp:106] Iteration 17480, lr = 0.0002
I0530 09:55:12.391710 24924 solver.cpp:228] Iteration 17500, loss = 0.266474
I0530 09:55:12.391748 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 09:55:12.391755 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.165798 (* 1 = 0.165798 loss)
I0530 09:55:12.391759 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.283819 (* 1 = 0.283819 loss)
I0530 09:55:12.391762 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137021 (* 1 = 0.0137021 loss)
I0530 09:55:12.391767 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0494035 (* 1 = 0.0494035 loss)
I0530 09:55:12.391770 24924 sgd_solver.cpp:106] Iteration 17500, lr = 0.0002
I0530 09:56:02.279675 24924 solver.cpp:228] Iteration 17520, loss = 0.274677
I0530 09:56:02.279700 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 09:56:02.279707 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000620727 (* 1 = 0.000620727 loss)
I0530 09:56:02.279711 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0419373 (* 1 = 0.0419373 loss)
I0530 09:56:02.279714 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0191576 (* 1 = 0.0191576 loss)
I0530 09:56:02.279717 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103146 (* 1 = 0.0103146 loss)
I0530 09:56:02.279722 24924 sgd_solver.cpp:106] Iteration 17520, lr = 0.0002
I0530 09:56:51.790299 24924 solver.cpp:228] Iteration 17540, loss = 0.437162
I0530 09:56:51.790323 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 09:56:51.790330 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485037 (* 1 = 0.0485037 loss)
I0530 09:56:51.790350 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.108123 (* 1 = 0.108123 loss)
I0530 09:56:51.790355 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.013604 (* 1 = 0.013604 loss)
I0530 09:56:51.790359 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0256397 (* 1 = 0.0256397 loss)
I0530 09:56:51.790365 24924 sgd_solver.cpp:106] Iteration 17540, lr = 0.0002
I0530 09:57:41.876513 24924 solver.cpp:228] Iteration 17560, loss = 0.340687
I0530 09:57:41.876534 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 09:57:41.876540 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0685157 (* 1 = 0.0685157 loss)
I0530 09:57:41.876544 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123308 (* 1 = 0.123308 loss)
I0530 09:57:41.876547 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00488375 (* 1 = 0.00488375 loss)
I0530 09:57:41.876550 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0086952 (* 1 = 0.0086952 loss)
I0530 09:57:41.876555 24924 sgd_solver.cpp:106] Iteration 17560, lr = 0.0002
I0530 09:58:31.702354 24924 solver.cpp:228] Iteration 17580, loss = 0.420187
I0530 09:58:31.702389 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 09:58:31.702396 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.121517 (* 1 = 0.121517 loss)
I0530 09:58:31.702399 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.154006 (* 1 = 0.154006 loss)
I0530 09:58:31.702404 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00804365 (* 1 = 0.00804365 loss)
I0530 09:58:31.702406 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024686 (* 1 = 0.024686 loss)
I0530 09:58:31.702410 24924 sgd_solver.cpp:106] Iteration 17580, lr = 0.0002
speed: 2.439s / iter
I0530 09:59:22.334744 24924 solver.cpp:228] Iteration 17600, loss = 0.392549
I0530 09:59:22.334767 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 09:59:22.334776 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.236566 (* 1 = 0.236566 loss)
I0530 09:59:22.334795 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.332605 (* 1 = 0.332605 loss)
I0530 09:59:22.334800 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140481 (* 1 = 0.0140481 loss)
I0530 09:59:22.334805 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113697 (* 1 = 0.113697 loss)
I0530 09:59:22.334811 24924 sgd_solver.cpp:106] Iteration 17600, lr = 0.0002
I0530 10:00:11.995643 24924 solver.cpp:228] Iteration 17620, loss = 0.450446
I0530 10:00:11.995671 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 10:00:11.995678 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0012564 (* 1 = 0.0012564 loss)
I0530 10:00:11.995684 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0412645 (* 1 = 0.0412645 loss)
I0530 10:00:11.995689 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00769825 (* 1 = 0.00769825 loss)
I0530 10:00:11.995694 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184235 (* 1 = 0.0184235 loss)
I0530 10:00:11.995700 24924 sgd_solver.cpp:106] Iteration 17620, lr = 0.0002
I0530 10:01:02.364238 24924 solver.cpp:228] Iteration 17640, loss = 0.278985
I0530 10:01:02.364261 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 10:01:02.364269 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0675748 (* 1 = 0.0675748 loss)
I0530 10:01:02.364272 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.114455 (* 1 = 0.114455 loss)
I0530 10:01:02.364276 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00284255 (* 1 = 0.00284255 loss)
I0530 10:01:02.364279 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0260598 (* 1 = 0.0260598 loss)
I0530 10:01:02.364285 24924 sgd_solver.cpp:106] Iteration 17640, lr = 0.0002
I0530 10:01:53.195901 24924 solver.cpp:228] Iteration 17660, loss = 0.501264
I0530 10:01:53.195927 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0530 10:01:53.195936 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.438617 (* 1 = 0.438617 loss)
I0530 10:01:53.195941 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.729605 (* 1 = 0.729605 loss)
I0530 10:01:53.195946 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0532566 (* 1 = 0.0532566 loss)
I0530 10:01:53.195951 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.233539 (* 1 = 0.233539 loss)
I0530 10:01:53.195957 24924 sgd_solver.cpp:106] Iteration 17660, lr = 0.0002
I0530 10:02:42.929524 24924 solver.cpp:228] Iteration 17680, loss = 0.226813
I0530 10:02:42.929560 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:02:42.929567 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0228808 (* 1 = 0.0228808 loss)
I0530 10:02:42.929571 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0623852 (* 1 = 0.0623852 loss)
I0530 10:02:42.929574 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0040227 (* 1 = 0.0040227 loss)
I0530 10:02:42.929577 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00779198 (* 1 = 0.00779198 loss)
I0530 10:02:42.929582 24924 sgd_solver.cpp:106] Iteration 17680, lr = 0.0002
I0530 10:03:32.427067 24924 solver.cpp:228] Iteration 17700, loss = 0.201527
I0530 10:03:32.427103 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:03:32.427110 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0638294 (* 1 = 0.0638294 loss)
I0530 10:03:32.427114 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0746925 (* 1 = 0.0746925 loss)
I0530 10:03:32.427117 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291828 (* 1 = 0.00291828 loss)
I0530 10:03:32.427120 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206673 (* 1 = 0.0206673 loss)
I0530 10:03:32.427125 24924 sgd_solver.cpp:106] Iteration 17700, lr = 0.0002
I0530 10:04:22.198806 24924 solver.cpp:228] Iteration 17720, loss = 0.237994
I0530 10:04:22.198839 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 10:04:22.198848 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0525469 (* 1 = 0.0525469 loss)
I0530 10:04:22.198851 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141061 (* 1 = 0.141061 loss)
I0530 10:04:22.198854 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129562 (* 1 = 0.0129562 loss)
I0530 10:04:22.198858 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229652 (* 1 = 0.0229652 loss)
I0530 10:04:22.198861 24924 sgd_solver.cpp:106] Iteration 17720, lr = 0.0002
I0530 10:05:11.994622 24924 solver.cpp:228] Iteration 17740, loss = 0.358149
I0530 10:05:11.994647 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:05:11.994655 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0517007 (* 1 = 0.0517007 loss)
I0530 10:05:11.994674 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104681 (* 1 = 0.104681 loss)
I0530 10:05:11.994679 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00181628 (* 1 = 0.00181628 loss)
I0530 10:05:11.994684 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158052 (* 1 = 0.0158052 loss)
I0530 10:05:11.994689 24924 sgd_solver.cpp:106] Iteration 17740, lr = 0.0002
I0530 10:06:01.693517 24924 solver.cpp:228] Iteration 17760, loss = 0.310046
I0530 10:06:01.693553 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0530 10:06:01.693560 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.178843 (* 1 = 0.178843 loss)
I0530 10:06:01.693564 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.529623 (* 1 = 0.529623 loss)
I0530 10:06:01.693567 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145413 (* 1 = 0.0145413 loss)
I0530 10:06:01.693570 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0825211 (* 1 = 0.0825211 loss)
I0530 10:06:01.693575 24924 sgd_solver.cpp:106] Iteration 17760, lr = 0.0002
I0530 10:06:51.501494 24924 solver.cpp:228] Iteration 17780, loss = 0.180898
I0530 10:06:51.501518 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 10:06:51.501525 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0125246 (* 1 = 0.0125246 loss)
I0530 10:06:51.501529 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0304512 (* 1 = 0.0304512 loss)
I0530 10:06:51.501533 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00235686 (* 1 = 0.00235686 loss)
I0530 10:06:51.501535 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00650352 (* 1 = 0.00650352 loss)
I0530 10:06:51.501540 24924 sgd_solver.cpp:106] Iteration 17780, lr = 0.0002
speed: 2.440s / iter
I0530 10:07:40.767740 24924 solver.cpp:228] Iteration 17800, loss = 0.415126
I0530 10:07:40.767763 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 10:07:40.767771 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.163177 (* 1 = 0.163177 loss)
I0530 10:07:40.767774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.159372 (* 1 = 0.159372 loss)
I0530 10:07:40.767777 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0165435 (* 1 = 0.0165435 loss)
I0530 10:07:40.767781 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0833968 (* 1 = 0.0833968 loss)
I0530 10:07:40.767786 24924 sgd_solver.cpp:106] Iteration 17800, lr = 0.0002
I0530 10:08:30.414041 24924 solver.cpp:228] Iteration 17820, loss = 0.262581
I0530 10:08:30.414078 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 10:08:30.414085 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0840967 (* 1 = 0.0840967 loss)
I0530 10:08:30.414089 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.105023 (* 1 = 0.105023 loss)
I0530 10:08:30.414093 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00996222 (* 1 = 0.00996222 loss)
I0530 10:08:30.414095 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212033 (* 1 = 0.0212033 loss)
I0530 10:08:30.414100 24924 sgd_solver.cpp:106] Iteration 17820, lr = 0.0002
I0530 10:09:20.260624 24924 solver.cpp:228] Iteration 17840, loss = 0.580721
I0530 10:09:20.260649 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 10:09:20.260656 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.101866 (* 1 = 0.101866 loss)
I0530 10:09:20.260660 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.261282 (* 1 = 0.261282 loss)
I0530 10:09:20.260663 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122914 (* 1 = 0.0122914 loss)
I0530 10:09:20.260668 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195917 (* 1 = 0.0195917 loss)
I0530 10:09:20.260673 24924 sgd_solver.cpp:106] Iteration 17840, lr = 0.0002
I0530 10:10:09.340004 24924 solver.cpp:228] Iteration 17860, loss = 0.267793
I0530 10:10:09.340025 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 10:10:09.340032 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0954923 (* 1 = 0.0954923 loss)
I0530 10:10:09.340035 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.17119 (* 1 = 0.17119 loss)
I0530 10:10:09.340039 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591529 (* 1 = 0.00591529 loss)
I0530 10:10:09.340041 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013941 (* 1 = 0.013941 loss)
I0530 10:10:09.340046 24924 sgd_solver.cpp:106] Iteration 17860, lr = 0.0002
I0530 10:10:58.393792 24924 solver.cpp:228] Iteration 17880, loss = 0.256919
I0530 10:10:58.393815 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 10:10:58.393822 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0731938 (* 1 = 0.0731938 loss)
I0530 10:10:58.393842 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0752313 (* 1 = 0.0752313 loss)
I0530 10:10:58.393847 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00727353 (* 1 = 0.00727353 loss)
I0530 10:10:58.393852 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00973272 (* 1 = 0.00973272 loss)
I0530 10:10:58.393857 24924 sgd_solver.cpp:106] Iteration 17880, lr = 0.0002
I0530 10:11:47.764006 24924 solver.cpp:228] Iteration 17900, loss = 0.227157
I0530 10:11:47.764030 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:11:47.764039 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00758391 (* 1 = 0.00758391 loss)
I0530 10:11:47.764042 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0756158 (* 1 = 0.0756158 loss)
I0530 10:11:47.764045 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0136896 (* 1 = 0.0136896 loss)
I0530 10:11:47.764050 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0777241 (* 1 = 0.0777241 loss)
I0530 10:11:47.764053 24924 sgd_solver.cpp:106] Iteration 17900, lr = 0.0002
I0530 10:12:37.410951 24924 solver.cpp:228] Iteration 17920, loss = 0.536697
I0530 10:12:37.410974 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 10:12:37.410980 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.136584 (* 1 = 0.136584 loss)
I0530 10:12:37.410984 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.280793 (* 1 = 0.280793 loss)
I0530 10:12:37.410987 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00929895 (* 1 = 0.00929895 loss)
I0530 10:12:37.410990 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0271387 (* 1 = 0.0271387 loss)
I0530 10:12:37.410995 24924 sgd_solver.cpp:106] Iteration 17920, lr = 0.0002
I0530 10:13:27.770484 24924 solver.cpp:228] Iteration 17940, loss = 0.319828
I0530 10:13:27.770510 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 10:13:27.770519 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.132668 (* 1 = 0.132668 loss)
I0530 10:13:27.770522 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.154025 (* 1 = 0.154025 loss)
I0530 10:13:27.770525 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00355965 (* 1 = 0.00355965 loss)
I0530 10:13:27.770529 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147169 (* 1 = 0.0147169 loss)
I0530 10:13:27.770534 24924 sgd_solver.cpp:106] Iteration 17940, lr = 0.0002
I0530 10:14:17.700541 24924 solver.cpp:228] Iteration 17960, loss = 0.352995
I0530 10:14:17.700562 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:14:17.700583 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.053907 (* 1 = 0.053907 loss)
I0530 10:14:17.700587 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104077 (* 1 = 0.104077 loss)
I0530 10:14:17.700590 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306585 (* 1 = 0.0306585 loss)
I0530 10:14:17.700593 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0599043 (* 1 = 0.0599043 loss)
I0530 10:14:17.700598 24924 sgd_solver.cpp:106] Iteration 17960, lr = 0.0002
I0530 10:15:06.808490 24924 solver.cpp:228] Iteration 17980, loss = 0.242991
I0530 10:15:06.808524 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 10:15:06.808532 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103786 (* 1 = 0.103786 loss)
I0530 10:15:06.808535 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.158704 (* 1 = 0.158704 loss)
I0530 10:15:06.808538 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0155118 (* 1 = 0.0155118 loss)
I0530 10:15:06.808542 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0936905 (* 1 = 0.0936905 loss)
I0530 10:15:06.808545 24924 sgd_solver.cpp:106] Iteration 17980, lr = 0.0002
speed: 2.440s / iter
I0530 10:15:56.433368 24924 solver.cpp:228] Iteration 18000, loss = 0.657101
I0530 10:15:56.433393 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:15:56.433399 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0895177 (* 1 = 0.0895177 loss)
I0530 10:15:56.433403 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.094144 (* 1 = 0.094144 loss)
I0530 10:15:56.433406 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511035 (* 1 = 0.00511035 loss)
I0530 10:15:56.433410 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0060166 (* 1 = 0.0060166 loss)
I0530 10:15:56.433414 24924 sgd_solver.cpp:106] Iteration 18000, lr = 0.0002
I0530 10:16:46.143215 24924 solver.cpp:228] Iteration 18020, loss = 0.227962
I0530 10:16:46.143241 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 10:16:46.143247 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0666403 (* 1 = 0.0666403 loss)
I0530 10:16:46.143251 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0516693 (* 1 = 0.0516693 loss)
I0530 10:16:46.143255 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00364466 (* 1 = 0.00364466 loss)
I0530 10:16:46.143259 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00616177 (* 1 = 0.00616177 loss)
I0530 10:16:46.143262 24924 sgd_solver.cpp:106] Iteration 18020, lr = 0.0002
I0530 10:17:35.450875 24924 solver.cpp:228] Iteration 18040, loss = 0.300571
I0530 10:17:35.450911 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 10:17:35.450917 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0507151 (* 1 = 0.0507151 loss)
I0530 10:17:35.450922 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145706 (* 1 = 0.145706 loss)
I0530 10:17:35.450925 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00881387 (* 1 = 0.00881387 loss)
I0530 10:17:35.450930 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153995 (* 1 = 0.0153995 loss)
I0530 10:17:35.450935 24924 sgd_solver.cpp:106] Iteration 18040, lr = 0.0002
I0530 10:18:25.008050 24924 solver.cpp:228] Iteration 18060, loss = 0.186505
I0530 10:18:25.008088 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:18:25.008096 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0275422 (* 1 = 0.0275422 loss)
I0530 10:18:25.008100 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0651908 (* 1 = 0.0651908 loss)
I0530 10:18:25.008105 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00189499 (* 1 = 0.00189499 loss)
I0530 10:18:25.008111 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00525123 (* 1 = 0.00525123 loss)
I0530 10:18:25.008116 24924 sgd_solver.cpp:106] Iteration 18060, lr = 0.0002
I0530 10:19:14.425380 24924 solver.cpp:228] Iteration 18080, loss = 0.409397
I0530 10:19:14.425415 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 10:19:14.425421 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.155033 (* 1 = 0.155033 loss)
I0530 10:19:14.425426 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.103845 (* 1 = 0.103845 loss)
I0530 10:19:14.425429 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00771808 (* 1 = 0.00771808 loss)
I0530 10:19:14.425432 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00825349 (* 1 = 0.00825349 loss)
I0530 10:19:14.425438 24924 sgd_solver.cpp:106] Iteration 18080, lr = 0.0002
I0530 10:20:03.879395 24924 solver.cpp:228] Iteration 18100, loss = 0.36687
I0530 10:20:03.879417 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 10:20:03.879423 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.144355 (* 1 = 0.144355 loss)
I0530 10:20:03.879427 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.349308 (* 1 = 0.349308 loss)
I0530 10:20:03.879431 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0270848 (* 1 = 0.0270848 loss)
I0530 10:20:03.879433 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303358 (* 1 = 0.0303358 loss)
I0530 10:20:03.879438 24924 sgd_solver.cpp:106] Iteration 18100, lr = 0.0002
I0530 10:20:53.926218 24924 solver.cpp:228] Iteration 18120, loss = 0.425416
I0530 10:20:53.926240 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 10:20:53.926247 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0814165 (* 1 = 0.0814165 loss)
I0530 10:20:53.926250 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141311 (* 1 = 0.141311 loss)
I0530 10:20:53.926254 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00269233 (* 1 = 0.00269233 loss)
I0530 10:20:53.926257 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016576 (* 1 = 0.016576 loss)
I0530 10:20:53.926261 24924 sgd_solver.cpp:106] Iteration 18120, lr = 0.0002
I0530 10:21:45.089047 24924 solver.cpp:228] Iteration 18140, loss = 0.263282
I0530 10:21:45.089073 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 10:21:45.089081 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.219779 (* 1 = 0.219779 loss)
I0530 10:21:45.089084 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.249964 (* 1 = 0.249964 loss)
I0530 10:21:45.089088 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0076307 (* 1 = 0.0076307 loss)
I0530 10:21:45.089092 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033066 (* 1 = 0.033066 loss)
I0530 10:21:45.089097 24924 sgd_solver.cpp:106] Iteration 18140, lr = 0.0002
I0530 10:22:37.207170 24924 solver.cpp:228] Iteration 18160, loss = 0.31459
I0530 10:22:37.207192 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:22:37.207199 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00985878 (* 1 = 0.00985878 loss)
I0530 10:22:37.207203 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0678658 (* 1 = 0.0678658 loss)
I0530 10:22:37.207206 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0335643 (* 1 = 0.0335643 loss)
I0530 10:22:37.207209 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146057 (* 1 = 0.0146057 loss)
I0530 10:22:37.207213 24924 sgd_solver.cpp:106] Iteration 18160, lr = 0.0002
I0530 10:23:30.033293 24924 solver.cpp:228] Iteration 18180, loss = 0.237672
I0530 10:23:30.033316 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 10:23:30.033324 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0590298 (* 1 = 0.0590298 loss)
I0530 10:23:30.033329 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0668596 (* 1 = 0.0668596 loss)
I0530 10:23:30.033331 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0044985 (* 1 = 0.0044985 loss)
I0530 10:23:30.033334 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122623 (* 1 = 0.0122623 loss)
I0530 10:23:30.033340 24924 sgd_solver.cpp:106] Iteration 18180, lr = 0.0002
speed: 2.441s / iter
I0530 10:24:23.902657 24924 solver.cpp:228] Iteration 18200, loss = 0.399495
I0530 10:24:23.902683 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 10:24:23.902688 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0186162 (* 1 = 0.0186162 loss)
I0530 10:24:23.902693 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0919886 (* 1 = 0.0919886 loss)
I0530 10:24:23.902696 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00375148 (* 1 = 0.00375148 loss)
I0530 10:24:23.902699 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241301 (* 1 = 0.0241301 loss)
I0530 10:24:23.902704 24924 sgd_solver.cpp:106] Iteration 18200, lr = 0.0002
I0530 10:25:18.346504 24924 solver.cpp:228] Iteration 18220, loss = 0.280612
I0530 10:25:18.346526 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:25:18.346534 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383171 (* 1 = 0.0383171 loss)
I0530 10:25:18.346537 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0585297 (* 1 = 0.0585297 loss)
I0530 10:25:18.346541 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0012505 (* 1 = 0.0012505 loss)
I0530 10:25:18.346544 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00457517 (* 1 = 0.00457517 loss)
I0530 10:25:18.346549 24924 sgd_solver.cpp:106] Iteration 18220, lr = 0.0002
I0530 10:26:11.616667 24924 solver.cpp:228] Iteration 18240, loss = 0.256234
I0530 10:26:11.616691 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 10:26:11.616699 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.003128 (* 1 = 0.003128 loss)
I0530 10:26:11.616703 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0766117 (* 1 = 0.0766117 loss)
I0530 10:26:11.616706 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126881 (* 1 = 0.0126881 loss)
I0530 10:26:11.616709 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00664943 (* 1 = 0.00664943 loss)
I0530 10:26:11.616714 24924 sgd_solver.cpp:106] Iteration 18240, lr = 0.0002
I0530 10:27:04.524654 24924 solver.cpp:228] Iteration 18260, loss = 0.201567
I0530 10:27:04.524683 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:27:04.524691 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102422 (* 1 = 0.102422 loss)
I0530 10:27:04.524695 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0851353 (* 1 = 0.0851353 loss)
I0530 10:27:04.524698 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00379298 (* 1 = 0.00379298 loss)
I0530 10:27:04.524703 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134313 (* 1 = 0.0134313 loss)
I0530 10:27:04.524708 24924 sgd_solver.cpp:106] Iteration 18260, lr = 0.0002
I0530 10:27:58.161087 24924 solver.cpp:228] Iteration 18280, loss = 0.154564
I0530 10:27:58.161128 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 10:27:58.161139 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0435833 (* 1 = 0.0435833 loss)
I0530 10:27:58.161145 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0889246 (* 1 = 0.0889246 loss)
I0530 10:27:58.161150 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00544204 (* 1 = 0.00544204 loss)
I0530 10:27:58.161155 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00848946 (* 1 = 0.00848946 loss)
I0530 10:27:58.161161 24924 sgd_solver.cpp:106] Iteration 18280, lr = 0.0002
I0530 10:28:51.190686 24924 solver.cpp:228] Iteration 18300, loss = 0.406233
I0530 10:28:51.190712 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 10:28:51.190718 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254866 (* 1 = 0.0254866 loss)
I0530 10:28:51.190722 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.039938 (* 1 = 0.039938 loss)
I0530 10:28:51.190726 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000825647 (* 1 = 0.000825647 loss)
I0530 10:28:51.190729 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00217908 (* 1 = 0.00217908 loss)
I0530 10:28:51.190733 24924 sgd_solver.cpp:106] Iteration 18300, lr = 0.0002
I0530 10:29:43.785609 24924 solver.cpp:228] Iteration 18320, loss = 0.344895
I0530 10:29:43.785635 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 10:29:43.785645 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0689082 (* 1 = 0.0689082 loss)
I0530 10:29:43.785650 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133004 (* 1 = 0.133004 loss)
I0530 10:29:43.785655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00591563 (* 1 = 0.00591563 loss)
I0530 10:29:43.785660 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178082 (* 1 = 0.0178082 loss)
I0530 10:29:43.785666 24924 sgd_solver.cpp:106] Iteration 18320, lr = 0.0002
I0530 10:30:36.575310 24924 solver.cpp:228] Iteration 18340, loss = 0.320439
I0530 10:30:36.575338 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 10:30:36.575345 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109119 (* 1 = 0.109119 loss)
I0530 10:30:36.575348 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.227074 (* 1 = 0.227074 loss)
I0530 10:30:36.575352 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00665629 (* 1 = 0.00665629 loss)
I0530 10:30:36.575356 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0351379 (* 1 = 0.0351379 loss)
I0530 10:30:36.575361 24924 sgd_solver.cpp:106] Iteration 18340, lr = 0.0002
I0530 10:31:29.207160 24924 solver.cpp:228] Iteration 18360, loss = 0.415469
I0530 10:31:29.207185 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 10:31:29.207193 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595693 (* 1 = 0.0595693 loss)
I0530 10:31:29.207197 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104924 (* 1 = 0.104924 loss)
I0530 10:31:29.207201 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137463 (* 1 = 0.0137463 loss)
I0530 10:31:29.207206 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00585496 (* 1 = 0.00585496 loss)
I0530 10:31:29.207211 24924 sgd_solver.cpp:106] Iteration 18360, lr = 0.0002
I0530 10:32:23.388478 24924 solver.cpp:228] Iteration 18380, loss = 0.332035
I0530 10:32:23.388504 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 10:32:23.388510 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.284578 (* 1 = 0.284578 loss)
I0530 10:32:23.388514 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.331196 (* 1 = 0.331196 loss)
I0530 10:32:23.388519 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.069155 (* 1 = 0.069155 loss)
I0530 10:32:23.388521 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0675739 (* 1 = 0.0675739 loss)
I0530 10:32:23.388526 24924 sgd_solver.cpp:106] Iteration 18380, lr = 0.0002
speed: 2.444s / iter
I0530 10:33:17.163015 24924 solver.cpp:228] Iteration 18400, loss = 0.650899
I0530 10:33:17.163038 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 10:33:17.163045 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.290183 (* 1 = 0.290183 loss)
I0530 10:33:17.163049 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.230508 (* 1 = 0.230508 loss)
I0530 10:33:17.163053 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336008 (* 1 = 0.00336008 loss)
I0530 10:33:17.163056 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0330937 (* 1 = 0.0330937 loss)
I0530 10:33:17.163060 24924 sgd_solver.cpp:106] Iteration 18400, lr = 0.0002
I0530 10:34:09.830987 24924 solver.cpp:228] Iteration 18420, loss = 0.309478
I0530 10:34:09.831014 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 10:34:09.831022 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160817 (* 1 = 0.160817 loss)
I0530 10:34:09.831025 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.229834 (* 1 = 0.229834 loss)
I0530 10:34:09.831028 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101217 (* 1 = 0.0101217 loss)
I0530 10:34:09.831032 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327822 (* 1 = 0.0327822 loss)
I0530 10:34:09.831037 24924 sgd_solver.cpp:106] Iteration 18420, lr = 0.0002
I0530 10:35:02.930781 24924 solver.cpp:228] Iteration 18440, loss = 0.268632
I0530 10:35:02.930807 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 10:35:02.930814 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122386 (* 1 = 0.122386 loss)
I0530 10:35:02.930819 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165034 (* 1 = 0.165034 loss)
I0530 10:35:02.930821 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00508067 (* 1 = 0.00508067 loss)
I0530 10:35:02.930824 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158541 (* 1 = 0.0158541 loss)
I0530 10:35:02.930829 24924 sgd_solver.cpp:106] Iteration 18440, lr = 0.0002
I0530 10:35:55.809522 24924 solver.cpp:228] Iteration 18460, loss = 0.289763
I0530 10:35:55.809548 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:35:55.809556 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.105382 (* 1 = 0.105382 loss)
I0530 10:35:55.809558 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.106635 (* 1 = 0.106635 loss)
I0530 10:35:55.809562 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213725 (* 1 = 0.0213725 loss)
I0530 10:35:55.809566 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0190059 (* 1 = 0.0190059 loss)
I0530 10:35:55.809571 24924 sgd_solver.cpp:106] Iteration 18460, lr = 0.0002
I0530 10:36:48.502152 24924 solver.cpp:228] Iteration 18480, loss = 0.247663
I0530 10:36:48.502178 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:36:48.502185 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.029704 (* 1 = 0.029704 loss)
I0530 10:36:48.502189 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.14965 (* 1 = 0.14965 loss)
I0530 10:36:48.502193 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0093344 (* 1 = 0.0093344 loss)
I0530 10:36:48.502197 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00747592 (* 1 = 0.00747592 loss)
I0530 10:36:48.502202 24924 sgd_solver.cpp:106] Iteration 18480, lr = 0.0002
I0530 10:37:40.857990 24924 solver.cpp:228] Iteration 18500, loss = 0.216631
I0530 10:37:40.858016 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 10:37:40.858022 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.196547 (* 1 = 0.196547 loss)
I0530 10:37:40.858026 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.238939 (* 1 = 0.238939 loss)
I0530 10:37:40.858029 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00412663 (* 1 = 0.00412663 loss)
I0530 10:37:40.858032 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0406711 (* 1 = 0.0406711 loss)
I0530 10:37:40.858037 24924 sgd_solver.cpp:106] Iteration 18500, lr = 0.0002
I0530 10:38:34.140117 24924 solver.cpp:228] Iteration 18520, loss = 0.485019
I0530 10:38:34.140141 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 10:38:34.140148 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0678418 (* 1 = 0.0678418 loss)
I0530 10:38:34.140152 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.173499 (* 1 = 0.173499 loss)
I0530 10:38:34.140156 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128805 (* 1 = 0.0128805 loss)
I0530 10:38:34.140158 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00952173 (* 1 = 0.00952173 loss)
I0530 10:38:34.140162 24924 sgd_solver.cpp:106] Iteration 18520, lr = 0.0002
I0530 10:39:27.036856 24924 solver.cpp:228] Iteration 18540, loss = 0.450782
I0530 10:39:27.036885 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 10:39:27.036891 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.249739 (* 1 = 0.249739 loss)
I0530 10:39:27.036895 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.364471 (* 1 = 0.364471 loss)
I0530 10:39:27.036900 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0329377 (* 1 = 0.0329377 loss)
I0530 10:39:27.036903 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.162425 (* 1 = 0.162425 loss)
I0530 10:39:27.036908 24924 sgd_solver.cpp:106] Iteration 18540, lr = 0.0002
I0530 10:40:20.284446 24924 solver.cpp:228] Iteration 18560, loss = 0.207392
I0530 10:40:20.284472 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 10:40:20.284483 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00142976 (* 1 = 0.00142976 loss)
I0530 10:40:20.284490 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0488517 (* 1 = 0.0488517 loss)
I0530 10:40:20.284495 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0089155 (* 1 = 0.0089155 loss)
I0530 10:40:20.284502 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0226053 (* 1 = 0.0226053 loss)
I0530 10:40:20.284508 24924 sgd_solver.cpp:106] Iteration 18560, lr = 0.0002
I0530 10:41:13.340538 24924 solver.cpp:228] Iteration 18580, loss = 0.278419
I0530 10:41:13.340564 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 10:41:13.340571 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000106125 (* 1 = 0.000106125 loss)
I0530 10:41:13.340576 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.023958 (* 1 = 0.023958 loss)
I0530 10:41:13.340580 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00288617 (* 1 = 0.00288617 loss)
I0530 10:41:13.340584 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0166744 (* 1 = 0.0166744 loss)
I0530 10:41:13.340590 24924 sgd_solver.cpp:106] Iteration 18580, lr = 0.0002
speed: 2.446s / iter
I0530 10:42:06.109300 24924 solver.cpp:228] Iteration 18600, loss = 0.260728
I0530 10:42:06.109326 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 10:42:06.109334 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.020745 (* 1 = 0.020745 loss)
I0530 10:42:06.109340 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0522788 (* 1 = 0.0522788 loss)
I0530 10:42:06.109345 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00630974 (* 1 = 0.00630974 loss)
I0530 10:42:06.109350 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00993417 (* 1 = 0.00993417 loss)
I0530 10:42:06.109357 24924 sgd_solver.cpp:106] Iteration 18600, lr = 0.0002
I0530 10:42:58.938822 24924 solver.cpp:228] Iteration 18620, loss = 0.250837
I0530 10:42:58.938848 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 10:42:58.938854 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.082147 (* 1 = 0.082147 loss)
I0530 10:42:58.938858 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141026 (* 1 = 0.141026 loss)
I0530 10:42:58.938861 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00686617 (* 1 = 0.00686617 loss)
I0530 10:42:58.938864 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208889 (* 1 = 0.0208889 loss)
I0530 10:42:58.938869 24924 sgd_solver.cpp:106] Iteration 18620, lr = 0.0002
I0530 10:43:52.262933 24924 solver.cpp:228] Iteration 18640, loss = 0.376884
I0530 10:43:52.262958 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 10:43:52.262965 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0932322 (* 1 = 0.0932322 loss)
I0530 10:43:52.262969 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.136454 (* 1 = 0.136454 loss)
I0530 10:43:52.262972 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00261975 (* 1 = 0.00261975 loss)
I0530 10:43:52.262975 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00613351 (* 1 = 0.00613351 loss)
I0530 10:43:52.262980 24924 sgd_solver.cpp:106] Iteration 18640, lr = 0.0002
I0530 10:44:45.060781 24924 solver.cpp:228] Iteration 18660, loss = 0.637134
I0530 10:44:45.060811 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:44:45.060819 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536096 (* 1 = 0.0536096 loss)
I0530 10:44:45.060823 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0650596 (* 1 = 0.0650596 loss)
I0530 10:44:45.060827 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102341 (* 1 = 0.0102341 loss)
I0530 10:44:45.060832 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240368 (* 1 = 0.0240368 loss)
I0530 10:44:45.060837 24924 sgd_solver.cpp:106] Iteration 18660, lr = 0.0002
I0530 10:45:37.506093 24924 solver.cpp:228] Iteration 18680, loss = 0.294142
I0530 10:45:37.506119 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 10:45:37.506125 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.141536 (* 1 = 0.141536 loss)
I0530 10:45:37.506129 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.166254 (* 1 = 0.166254 loss)
I0530 10:45:37.506134 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00747373 (* 1 = 0.00747373 loss)
I0530 10:45:37.506136 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027375 (* 1 = 0.027375 loss)
I0530 10:45:37.506141 24924 sgd_solver.cpp:106] Iteration 18680, lr = 0.0002
I0530 10:46:29.810019 24924 solver.cpp:228] Iteration 18700, loss = 0.350397
I0530 10:46:29.810043 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 10:46:29.810050 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00220677 (* 1 = 0.00220677 loss)
I0530 10:46:29.810055 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0356731 (* 1 = 0.0356731 loss)
I0530 10:46:29.810058 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221007 (* 1 = 0.0221007 loss)
I0530 10:46:29.810061 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130331 (* 1 = 0.0130331 loss)
I0530 10:46:29.810066 24924 sgd_solver.cpp:106] Iteration 18700, lr = 0.0002
I0530 10:47:23.127020 24924 solver.cpp:228] Iteration 18720, loss = 0.216752
I0530 10:47:23.127046 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:47:23.127053 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203258 (* 1 = 0.0203258 loss)
I0530 10:47:23.127058 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145363 (* 1 = 0.145363 loss)
I0530 10:47:23.127060 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02845 (* 1 = 0.02845 loss)
I0530 10:47:23.127063 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136124 (* 1 = 0.0136124 loss)
I0530 10:47:23.127068 24924 sgd_solver.cpp:106] Iteration 18720, lr = 0.0002
I0530 10:48:16.959672 24924 solver.cpp:228] Iteration 18740, loss = 0.430401
I0530 10:48:16.959700 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 10:48:16.959707 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.193655 (* 1 = 0.193655 loss)
I0530 10:48:16.959712 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.246793 (* 1 = 0.246793 loss)
I0530 10:48:16.959715 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115045 (* 1 = 0.0115045 loss)
I0530 10:48:16.959718 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.043298 (* 1 = 0.043298 loss)
I0530 10:48:16.959724 24924 sgd_solver.cpp:106] Iteration 18740, lr = 0.0002
I0530 10:49:12.778514 24924 solver.cpp:228] Iteration 18760, loss = 0.488196
I0530 10:49:12.778544 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 10:49:12.778553 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.126481 (* 1 = 0.126481 loss)
I0530 10:49:12.778558 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.182747 (* 1 = 0.182747 loss)
I0530 10:49:12.778563 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00134365 (* 1 = 0.00134365 loss)
I0530 10:49:12.778566 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161412 (* 1 = 0.0161412 loss)
I0530 10:49:12.778573 24924 sgd_solver.cpp:106] Iteration 18760, lr = 0.0002
I0530 10:50:08.621728 24924 solver.cpp:228] Iteration 18780, loss = 0.334356
I0530 10:50:08.621757 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:50:08.621763 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0578784 (* 1 = 0.0578784 loss)
I0530 10:50:08.621767 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0765518 (* 1 = 0.0765518 loss)
I0530 10:50:08.621771 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00433772 (* 1 = 0.00433772 loss)
I0530 10:50:08.621775 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137804 (* 1 = 0.0137804 loss)
I0530 10:50:08.621781 24924 sgd_solver.cpp:106] Iteration 18780, lr = 0.0002
speed: 2.448s / iter
I0530 10:51:03.457288 24924 solver.cpp:228] Iteration 18800, loss = 0.262222
I0530 10:51:03.457319 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 10:51:03.457327 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0657391 (* 1 = 0.0657391 loss)
I0530 10:51:03.457332 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.239868 (* 1 = 0.239868 loss)
I0530 10:51:03.457337 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0429445 (* 1 = 0.0429445 loss)
I0530 10:51:03.457341 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0567288 (* 1 = 0.0567288 loss)
I0530 10:51:03.457348 24924 sgd_solver.cpp:106] Iteration 18800, lr = 0.0002
I0530 10:51:58.241055 24924 solver.cpp:228] Iteration 18820, loss = 0.28797
I0530 10:51:58.241082 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:51:58.241091 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0203063 (* 1 = 0.0203063 loss)
I0530 10:51:58.241094 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100968 (* 1 = 0.100968 loss)
I0530 10:51:58.241098 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0046972 (* 1 = 0.0046972 loss)
I0530 10:51:58.241101 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0090973 (* 1 = 0.0090973 loss)
I0530 10:51:58.241107 24924 sgd_solver.cpp:106] Iteration 18820, lr = 0.0002
I0530 10:52:53.594367 24924 solver.cpp:228] Iteration 18840, loss = 0.368041
I0530 10:52:53.594394 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 10:52:53.594401 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0563667 (* 1 = 0.0563667 loss)
I0530 10:52:53.594406 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0734666 (* 1 = 0.0734666 loss)
I0530 10:52:53.594409 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00144756 (* 1 = 0.00144756 loss)
I0530 10:52:53.594413 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109266 (* 1 = 0.0109266 loss)
I0530 10:52:53.594419 24924 sgd_solver.cpp:106] Iteration 18840, lr = 0.0002
I0530 10:53:49.215910 24924 solver.cpp:228] Iteration 18860, loss = 0.411237
I0530 10:53:49.215939 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 10:53:49.215947 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0765238 (* 1 = 0.0765238 loss)
I0530 10:53:49.215952 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.221831 (* 1 = 0.221831 loss)
I0530 10:53:49.215956 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0261266 (* 1 = 0.0261266 loss)
I0530 10:53:49.215960 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0434978 (* 1 = 0.0434978 loss)
I0530 10:53:49.215965 24924 sgd_solver.cpp:106] Iteration 18860, lr = 0.0002
I0530 10:54:44.854334 24924 solver.cpp:228] Iteration 18880, loss = 0.284155
I0530 10:54:44.854365 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 10:54:44.854372 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649038 (* 1 = 0.0649038 loss)
I0530 10:54:44.854377 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0797736 (* 1 = 0.0797736 loss)
I0530 10:54:44.854380 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035667 (* 1 = 0.0035667 loss)
I0530 10:54:44.854383 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373341 (* 1 = 0.0373341 loss)
I0530 10:54:44.854389 24924 sgd_solver.cpp:106] Iteration 18880, lr = 0.0002
I0530 10:55:40.272457 24924 solver.cpp:228] Iteration 18900, loss = 0.319014
I0530 10:55:40.272487 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:55:40.272498 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0506207 (* 1 = 0.0506207 loss)
I0530 10:55:40.272505 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115688 (* 1 = 0.115688 loss)
I0530 10:55:40.272511 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00977113 (* 1 = 0.00977113 loss)
I0530 10:55:40.272516 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016791 (* 1 = 0.016791 loss)
I0530 10:55:40.272524 24924 sgd_solver.cpp:106] Iteration 18900, lr = 0.0002
I0530 10:56:35.425823 24924 solver.cpp:228] Iteration 18920, loss = 0.402643
I0530 10:56:35.425850 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 10:56:35.425858 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0766838 (* 1 = 0.0766838 loss)
I0530 10:56:35.425863 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.12089 (* 1 = 0.12089 loss)
I0530 10:56:35.425866 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011429 (* 1 = 0.011429 loss)
I0530 10:56:35.425870 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0028763 (* 1 = 0.0028763 loss)
I0530 10:56:35.425875 24924 sgd_solver.cpp:106] Iteration 18920, lr = 0.0002
I0530 10:57:30.747525 24924 solver.cpp:228] Iteration 18940, loss = 0.261685
I0530 10:57:30.747552 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 10:57:30.747560 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0484983 (* 1 = 0.0484983 loss)
I0530 10:57:30.747563 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.138536 (* 1 = 0.138536 loss)
I0530 10:57:30.747567 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00754395 (* 1 = 0.00754395 loss)
I0530 10:57:30.747570 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00923542 (* 1 = 0.00923542 loss)
I0530 10:57:30.747576 24924 sgd_solver.cpp:106] Iteration 18940, lr = 0.0002
I0530 10:58:25.901432 24924 solver.cpp:228] Iteration 18960, loss = 0.248638
I0530 10:58:25.901475 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 10:58:25.901489 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278499 (* 1 = 0.0278499 loss)
I0530 10:58:25.901496 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147035 (* 1 = 0.147035 loss)
I0530 10:58:25.901502 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100275 (* 1 = 0.0100275 loss)
I0530 10:58:25.901510 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0057275 (* 1 = 0.0057275 loss)
I0530 10:58:25.901518 24924 sgd_solver.cpp:106] Iteration 18960, lr = 0.0002
I0530 10:59:21.337169 24924 solver.cpp:228] Iteration 18980, loss = 0.395757
I0530 10:59:21.337196 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 10:59:21.337204 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0388645 (* 1 = 0.0388645 loss)
I0530 10:59:21.337208 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0593696 (* 1 = 0.0593696 loss)
I0530 10:59:21.337213 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000664812 (* 1 = 0.000664812 loss)
I0530 10:59:21.337215 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00997754 (* 1 = 0.00997754 loss)
I0530 10:59:21.337220 24924 sgd_solver.cpp:106] Iteration 18980, lr = 0.0002
speed: 2.452s / iter
I0530 11:00:17.174055 24924 solver.cpp:228] Iteration 19000, loss = 0.389197
I0530 11:00:17.174087 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 11:00:17.174098 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0914055 (* 1 = 0.0914055 loss)
I0530 11:00:17.174104 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.27379 (* 1 = 0.27379 loss)
I0530 11:00:17.174111 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00195325 (* 1 = 0.00195325 loss)
I0530 11:00:17.174118 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174773 (* 1 = 0.0174773 loss)
I0530 11:00:17.174129 24924 sgd_solver.cpp:106] Iteration 19000, lr = 0.0002
I0530 11:01:12.417934 24924 solver.cpp:228] Iteration 19020, loss = 0.40024
I0530 11:01:12.417961 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 11:01:12.417969 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0802356 (* 1 = 0.0802356 loss)
I0530 11:01:12.417974 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.154685 (* 1 = 0.154685 loss)
I0530 11:01:12.417979 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.02599 (* 1 = 0.02599 loss)
I0530 11:01:12.417981 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0316906 (* 1 = 0.0316906 loss)
I0530 11:01:12.417987 24924 sgd_solver.cpp:106] Iteration 19020, lr = 0.0002
I0530 11:02:07.617980 24924 solver.cpp:228] Iteration 19040, loss = 0.39301
I0530 11:02:07.618016 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 11:02:07.618026 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000622467 (* 1 = 0.000622467 loss)
I0530 11:02:07.618031 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0563657 (* 1 = 0.0563657 loss)
I0530 11:02:07.618036 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163287 (* 1 = 0.0163287 loss)
I0530 11:02:07.618042 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154702 (* 1 = 0.0154702 loss)
I0530 11:02:07.618048 24924 sgd_solver.cpp:106] Iteration 19040, lr = 0.0002
I0530 11:03:02.889335 24924 solver.cpp:228] Iteration 19060, loss = 0.251949
I0530 11:03:02.889360 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 11:03:02.889369 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0277848 (* 1 = 0.0277848 loss)
I0530 11:03:02.889372 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0661161 (* 1 = 0.0661161 loss)
I0530 11:03:02.889376 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00665557 (* 1 = 0.00665557 loss)
I0530 11:03:02.889379 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0060585 (* 1 = 0.0060585 loss)
I0530 11:03:02.889384 24924 sgd_solver.cpp:106] Iteration 19060, lr = 0.0002
I0530 11:03:57.685318 24924 solver.cpp:228] Iteration 19080, loss = 0.184384
I0530 11:03:57.685345 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 11:03:57.685354 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.06543 (* 1 = 0.06543 loss)
I0530 11:03:57.685359 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141447 (* 1 = 0.141447 loss)
I0530 11:03:57.685362 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00483447 (* 1 = 0.00483447 loss)
I0530 11:03:57.685365 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00426544 (* 1 = 0.00426544 loss)
I0530 11:03:57.685371 24924 sgd_solver.cpp:106] Iteration 19080, lr = 0.0002
I0530 11:04:53.312281 24924 solver.cpp:228] Iteration 19100, loss = 0.520106
I0530 11:04:53.312309 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 11:04:53.312319 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.128757 (* 1 = 0.128757 loss)
I0530 11:04:53.312325 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.247516 (* 1 = 0.247516 loss)
I0530 11:04:53.312332 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00727104 (* 1 = 0.00727104 loss)
I0530 11:04:53.312338 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0418332 (* 1 = 0.0418332 loss)
I0530 11:04:53.312345 24924 sgd_solver.cpp:106] Iteration 19100, lr = 0.0002
I0530 11:05:48.616842 24924 solver.cpp:228] Iteration 19120, loss = 0.249634
I0530 11:05:48.616868 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 11:05:48.616878 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0264349 (* 1 = 0.0264349 loss)
I0530 11:05:48.616881 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0293883 (* 1 = 0.0293883 loss)
I0530 11:05:48.616885 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00278854 (* 1 = 0.00278854 loss)
I0530 11:05:48.616890 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00280535 (* 1 = 0.00280535 loss)
I0530 11:05:48.616895 24924 sgd_solver.cpp:106] Iteration 19120, lr = 0.0002
I0530 11:06:43.525504 24924 solver.cpp:228] Iteration 19140, loss = 0.280392
I0530 11:06:43.525534 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 11:06:43.525542 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0346317 (* 1 = 0.0346317 loss)
I0530 11:06:43.525547 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0998744 (* 1 = 0.0998744 loss)
I0530 11:06:43.525552 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134194 (* 1 = 0.0134194 loss)
I0530 11:06:43.525555 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0453235 (* 1 = 0.0453235 loss)
I0530 11:06:43.525562 24924 sgd_solver.cpp:106] Iteration 19140, lr = 0.0002
I0530 11:07:39.026810 24924 solver.cpp:228] Iteration 19160, loss = 0.304985
I0530 11:07:39.026840 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 11:07:39.026849 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.126396 (* 1 = 0.126396 loss)
I0530 11:07:39.026854 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186138 (* 1 = 0.186138 loss)
I0530 11:07:39.026857 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218848 (* 1 = 0.0218848 loss)
I0530 11:07:39.026860 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225009 (* 1 = 0.0225009 loss)
I0530 11:07:39.026867 24924 sgd_solver.cpp:106] Iteration 19160, lr = 0.0002
I0530 11:08:34.771404 24924 solver.cpp:228] Iteration 19180, loss = 0.314999
I0530 11:08:34.771433 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 11:08:34.771442 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0611943 (* 1 = 0.0611943 loss)
I0530 11:08:34.771446 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.223256 (* 1 = 0.223256 loss)
I0530 11:08:34.771450 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122845 (* 1 = 0.0122845 loss)
I0530 11:08:34.771455 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188817 (* 1 = 0.0188817 loss)
I0530 11:08:34.771459 24924 sgd_solver.cpp:106] Iteration 19180, lr = 0.0002
speed: 2.455s / iter
I0530 11:09:30.127991 24924 solver.cpp:228] Iteration 19200, loss = 0.302446
I0530 11:09:30.128023 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 11:09:30.128031 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.106326 (* 1 = 0.106326 loss)
I0530 11:09:30.128036 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.200919 (* 1 = 0.200919 loss)
I0530 11:09:30.128039 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0253389 (* 1 = 0.0253389 loss)
I0530 11:09:30.128042 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0667502 (* 1 = 0.0667502 loss)
I0530 11:09:30.128048 24924 sgd_solver.cpp:106] Iteration 19200, lr = 0.0002
I0530 11:10:25.775185 24924 solver.cpp:228] Iteration 19220, loss = 0.361373
I0530 11:10:25.775221 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 11:10:25.775234 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.123194 (* 1 = 0.123194 loss)
I0530 11:10:25.775243 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.235267 (* 1 = 0.235267 loss)
I0530 11:10:25.775249 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115661 (* 1 = 0.0115661 loss)
I0530 11:10:25.775256 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0376611 (* 1 = 0.0376611 loss)
I0530 11:10:25.775266 24924 sgd_solver.cpp:106] Iteration 19220, lr = 0.0002
I0530 11:11:21.182194 24924 solver.cpp:228] Iteration 19240, loss = 0.306432
I0530 11:11:21.182222 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 11:11:21.182230 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.138684 (* 1 = 0.138684 loss)
I0530 11:11:21.182235 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.165914 (* 1 = 0.165914 loss)
I0530 11:11:21.182240 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00949937 (* 1 = 0.00949937 loss)
I0530 11:11:21.182243 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163264 (* 1 = 0.0163264 loss)
I0530 11:11:21.182248 24924 sgd_solver.cpp:106] Iteration 19240, lr = 0.0002
I0530 11:12:16.059082 24924 solver.cpp:228] Iteration 19260, loss = 0.594846
I0530 11:12:16.059106 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 11:12:16.059113 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.219874 (* 1 = 0.219874 loss)
I0530 11:12:16.059115 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.36894 (* 1 = 0.36894 loss)
I0530 11:12:16.059118 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0362719 (* 1 = 0.0362719 loss)
I0530 11:12:16.059123 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.162117 (* 1 = 0.162117 loss)
I0530 11:12:16.059126 24924 sgd_solver.cpp:106] Iteration 19260, lr = 0.0002
I0530 11:13:09.815301 24924 solver.cpp:228] Iteration 19280, loss = 0.37844
I0530 11:13:09.815322 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 11:13:09.815330 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0756203 (* 1 = 0.0756203 loss)
I0530 11:13:09.815335 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186937 (* 1 = 0.186937 loss)
I0530 11:13:09.815337 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0016967 (* 1 = 0.0016967 loss)
I0530 11:13:09.815340 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0136372 (* 1 = 0.0136372 loss)
I0530 11:13:09.815346 24924 sgd_solver.cpp:106] Iteration 19280, lr = 0.0002
I0530 11:14:02.440917 24924 solver.cpp:228] Iteration 19300, loss = 0.287394
I0530 11:14:02.440944 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 11:14:02.440951 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0777337 (* 1 = 0.0777337 loss)
I0530 11:14:02.440955 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145564 (* 1 = 0.145564 loss)
I0530 11:14:02.440959 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0235181 (* 1 = 0.0235181 loss)
I0530 11:14:02.440963 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0407133 (* 1 = 0.0407133 loss)
I0530 11:14:02.440968 24924 sgd_solver.cpp:106] Iteration 19300, lr = 0.0002
I0530 11:14:54.849858 24924 solver.cpp:228] Iteration 19320, loss = 0.33065
I0530 11:14:54.849889 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 11:14:54.849900 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000549747 (* 1 = 0.000549747 loss)
I0530 11:14:54.849905 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0431681 (* 1 = 0.0431681 loss)
I0530 11:14:54.849910 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127444 (* 1 = 0.0127444 loss)
I0530 11:14:54.849915 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0182675 (* 1 = 0.0182675 loss)
I0530 11:14:54.849922 24924 sgd_solver.cpp:106] Iteration 19320, lr = 0.0002
I0530 11:15:47.143491 24924 solver.cpp:228] Iteration 19340, loss = 0.284898
I0530 11:15:47.143513 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 11:15:47.143520 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.174315 (* 1 = 0.174315 loss)
I0530 11:15:47.143524 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.204222 (* 1 = 0.204222 loss)
I0530 11:15:47.143527 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126575 (* 1 = 0.0126575 loss)
I0530 11:15:47.143530 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.042026 (* 1 = 0.042026 loss)
I0530 11:15:47.143535 24924 sgd_solver.cpp:106] Iteration 19340, lr = 0.0002
I0530 11:16:39.798593 24924 solver.cpp:228] Iteration 19360, loss = 0.37238
I0530 11:16:39.798615 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 11:16:39.798622 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.177284 (* 1 = 0.177284 loss)
I0530 11:16:39.798626 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.265381 (* 1 = 0.265381 loss)
I0530 11:16:39.798629 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338935 (* 1 = 0.00338935 loss)
I0530 11:16:39.798633 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0408974 (* 1 = 0.0408974 loss)
I0530 11:16:39.798638 24924 sgd_solver.cpp:106] Iteration 19360, lr = 0.0002
I0530 11:17:32.429301 24924 solver.cpp:228] Iteration 19380, loss = 0.314007
I0530 11:17:32.429327 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 11:17:32.429335 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0134751 (* 1 = 0.0134751 loss)
I0530 11:17:32.429340 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.119414 (* 1 = 0.119414 loss)
I0530 11:17:32.429344 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00517682 (* 1 = 0.00517682 loss)
I0530 11:17:32.429347 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00304221 (* 1 = 0.00304221 loss)
I0530 11:17:32.429352 24924 sgd_solver.cpp:106] Iteration 19380, lr = 0.0002
speed: 2.457s / iter
I0530 11:18:24.968686 24924 solver.cpp:228] Iteration 19400, loss = 0.300952
I0530 11:18:24.968709 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 11:18:24.968716 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0162723 (* 1 = 0.0162723 loss)
I0530 11:18:24.968720 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0388794 (* 1 = 0.0388794 loss)
I0530 11:18:24.968724 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122461 (* 1 = 0.0122461 loss)
I0530 11:18:24.968727 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024165 (* 1 = 0.024165 loss)
I0530 11:18:24.968731 24924 sgd_solver.cpp:106] Iteration 19400, lr = 0.0002
I0530 11:19:18.346683 24924 solver.cpp:228] Iteration 19420, loss = 0.362255
I0530 11:19:18.346711 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 11:19:18.346719 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0389123 (* 1 = 0.0389123 loss)
I0530 11:19:18.346724 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104609 (* 1 = 0.104609 loss)
I0530 11:19:18.346729 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00234343 (* 1 = 0.00234343 loss)
I0530 11:19:18.346732 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132652 (* 1 = 0.0132652 loss)
I0530 11:19:18.346738 24924 sgd_solver.cpp:106] Iteration 19420, lr = 0.0002
I0530 11:20:11.460007 24924 solver.cpp:228] Iteration 19440, loss = 0.302597
I0530 11:20:11.460031 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.828125
I0530 11:20:11.460037 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.264412 (* 1 = 0.264412 loss)
I0530 11:20:11.460041 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.366254 (* 1 = 0.366254 loss)
I0530 11:20:11.460045 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00190681 (* 1 = 0.00190681 loss)
I0530 11:20:11.460048 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0581155 (* 1 = 0.0581155 loss)
I0530 11:20:11.460053 24924 sgd_solver.cpp:106] Iteration 19440, lr = 0.0002
I0530 11:21:05.581040 24924 solver.cpp:228] Iteration 19460, loss = 0.354347
I0530 11:21:05.581071 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 11:21:05.581079 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.219449 (* 1 = 0.219449 loss)
I0530 11:21:05.581084 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.205818 (* 1 = 0.205818 loss)
I0530 11:21:05.581086 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00363109 (* 1 = 0.00363109 loss)
I0530 11:21:05.581090 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.101321 (* 1 = 0.101321 loss)
I0530 11:21:05.581095 24924 sgd_solver.cpp:106] Iteration 19460, lr = 0.0002
I0530 11:22:00.574198 24924 solver.cpp:228] Iteration 19480, loss = 0.337164
I0530 11:22:00.574224 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 11:22:00.574232 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.112061 (* 1 = 0.112061 loss)
I0530 11:22:00.574237 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.295881 (* 1 = 0.295881 loss)
I0530 11:22:00.574241 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00810883 (* 1 = 0.00810883 loss)
I0530 11:22:00.574244 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191381 (* 1 = 0.0191381 loss)
I0530 11:22:00.574250 24924 sgd_solver.cpp:106] Iteration 19480, lr = 0.0002
I0530 11:22:55.707978 24924 solver.cpp:228] Iteration 19500, loss = 0.29596
I0530 11:22:55.708004 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 11:22:55.708011 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0665393 (* 1 = 0.0665393 loss)
I0530 11:22:55.708016 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.183372 (* 1 = 0.183372 loss)
I0530 11:22:55.708019 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0448273 (* 1 = 0.0448273 loss)
I0530 11:22:55.708024 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0429544 (* 1 = 0.0429544 loss)
I0530 11:22:55.708029 24924 sgd_solver.cpp:106] Iteration 19500, lr = 0.0002
I0530 11:23:50.892558 24924 solver.cpp:228] Iteration 19520, loss = 0.366413
I0530 11:23:50.892585 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 11:23:50.892593 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.121487 (* 1 = 0.121487 loss)
I0530 11:23:50.892597 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.227716 (* 1 = 0.227716 loss)
I0530 11:23:50.892601 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0065385 (* 1 = 0.0065385 loss)
I0530 11:23:50.892606 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0224715 (* 1 = 0.0224715 loss)
I0530 11:23:50.892611 24924 sgd_solver.cpp:106] Iteration 19520, lr = 0.0002
I0530 11:24:45.931793 24924 solver.cpp:228] Iteration 19540, loss = 0.311192
I0530 11:24:45.931821 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 11:24:45.931829 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00281926 (* 1 = 0.00281926 loss)
I0530 11:24:45.931834 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0344424 (* 1 = 0.0344424 loss)
I0530 11:24:45.931838 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00705238 (* 1 = 0.00705238 loss)
I0530 11:24:45.931841 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197337 (* 1 = 0.0197337 loss)
I0530 11:24:45.931848 24924 sgd_solver.cpp:106] Iteration 19540, lr = 0.0002
I0530 11:25:40.931852 24924 solver.cpp:228] Iteration 19560, loss = 0.408478
I0530 11:25:40.931879 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 11:25:40.931887 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0994332 (* 1 = 0.0994332 loss)
I0530 11:25:40.931891 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133182 (* 1 = 0.133182 loss)
I0530 11:25:40.931895 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0210472 (* 1 = 0.0210472 loss)
I0530 11:25:40.931898 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216453 (* 1 = 0.0216453 loss)
I0530 11:25:40.931903 24924 sgd_solver.cpp:106] Iteration 19560, lr = 0.0002
I0530 11:26:35.573556 24924 solver.cpp:228] Iteration 19580, loss = 0.328881
I0530 11:26:35.573582 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 11:26:35.573590 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0674249 (* 1 = 0.0674249 loss)
I0530 11:26:35.573593 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.175044 (* 1 = 0.175044 loss)
I0530 11:26:35.573596 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148292 (* 1 = 0.0148292 loss)
I0530 11:26:35.573599 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0257839 (* 1 = 0.0257839 loss)
I0530 11:26:35.573604 24924 sgd_solver.cpp:106] Iteration 19580, lr = 0.0002
speed: 2.460s / iter
I0530 11:27:30.510289 24924 solver.cpp:228] Iteration 19600, loss = 0.201915
I0530 11:27:30.510320 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 11:27:30.510331 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0388511 (* 1 = 0.0388511 loss)
I0530 11:27:30.510339 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109064 (* 1 = 0.109064 loss)
I0530 11:27:30.510344 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00514167 (* 1 = 0.00514167 loss)
I0530 11:27:30.510354 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258594 (* 1 = 0.0258594 loss)
I0530 11:27:30.510362 24924 sgd_solver.cpp:106] Iteration 19600, lr = 0.0002
I0530 11:28:25.186043 24924 solver.cpp:228] Iteration 19620, loss = 0.366624
I0530 11:28:25.186069 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 11:28:25.186075 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.049763 (* 1 = 0.049763 loss)
I0530 11:28:25.186079 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.175982 (* 1 = 0.175982 loss)
I0530 11:28:25.186082 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00973904 (* 1 = 0.00973904 loss)
I0530 11:28:25.186086 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186424 (* 1 = 0.0186424 loss)
I0530 11:28:25.186090 24924 sgd_solver.cpp:106] Iteration 19620, lr = 0.0002
I0530 11:29:19.940403 24924 solver.cpp:228] Iteration 19640, loss = 0.237824
I0530 11:29:19.940428 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 11:29:19.940435 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0625942 (* 1 = 0.0625942 loss)
I0530 11:29:19.940439 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.072365 (* 1 = 0.072365 loss)
I0530 11:29:19.940443 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00210838 (* 1 = 0.00210838 loss)
I0530 11:29:19.940446 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151958 (* 1 = 0.0151958 loss)
I0530 11:29:19.940451 24924 sgd_solver.cpp:106] Iteration 19640, lr = 0.0002
I0530 11:30:15.303704 24924 solver.cpp:228] Iteration 19660, loss = 0.223093
I0530 11:30:15.303735 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 11:30:15.303747 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122163 (* 1 = 0.122163 loss)
I0530 11:30:15.303753 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.246089 (* 1 = 0.246089 loss)
I0530 11:30:15.303759 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0150473 (* 1 = 0.0150473 loss)
I0530 11:30:15.303766 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0446289 (* 1 = 0.0446289 loss)
I0530 11:30:15.303776 24924 sgd_solver.cpp:106] Iteration 19660, lr = 0.0002
I0530 11:31:10.630555 24924 solver.cpp:228] Iteration 19680, loss = 0.274278
I0530 11:31:10.630584 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 11:31:10.630592 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00882083 (* 1 = 0.00882083 loss)
I0530 11:31:10.630596 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0500349 (* 1 = 0.0500349 loss)
I0530 11:31:10.630600 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00274481 (* 1 = 0.00274481 loss)
I0530 11:31:10.630604 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00330928 (* 1 = 0.00330928 loss)
I0530 11:31:10.630609 24924 sgd_solver.cpp:106] Iteration 19680, lr = 0.0002
I0530 11:32:06.027709 24924 solver.cpp:228] Iteration 19700, loss = 0.25369
I0530 11:32:06.027736 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 11:32:06.027745 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182606 (* 1 = 0.0182606 loss)
I0530 11:32:06.027748 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0503022 (* 1 = 0.0503022 loss)
I0530 11:32:06.027752 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00503424 (* 1 = 0.00503424 loss)
I0530 11:32:06.027755 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0132982 (* 1 = 0.0132982 loss)
I0530 11:32:06.027760 24924 sgd_solver.cpp:106] Iteration 19700, lr = 0.0002
I0530 11:33:00.757041 24924 solver.cpp:228] Iteration 19720, loss = 0.42145
I0530 11:33:00.757071 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 11:33:00.757077 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0806743 (* 1 = 0.0806743 loss)
I0530 11:33:00.757081 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.167794 (* 1 = 0.167794 loss)
I0530 11:33:00.757086 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00237001 (* 1 = 0.00237001 loss)
I0530 11:33:00.757088 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0324812 (* 1 = 0.0324812 loss)
I0530 11:33:00.757093 24924 sgd_solver.cpp:106] Iteration 19720, lr = 0.0002
I0530 11:33:54.979614 24924 solver.cpp:228] Iteration 19740, loss = 0.403576
I0530 11:33:54.979640 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 11:33:54.979646 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0521207 (* 1 = 0.0521207 loss)
I0530 11:33:54.979650 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115837 (* 1 = 0.115837 loss)
I0530 11:33:54.979655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00607352 (* 1 = 0.00607352 loss)
I0530 11:33:54.979657 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175468 (* 1 = 0.0175468 loss)
I0530 11:33:54.979662 24924 sgd_solver.cpp:106] Iteration 19740, lr = 0.0002
I0530 11:34:47.018098 24924 solver.cpp:228] Iteration 19760, loss = 0.378642
I0530 11:34:47.018123 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 11:34:47.018133 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.117334 (* 1 = 0.117334 loss)
I0530 11:34:47.018141 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.213 (* 1 = 0.213 loss)
I0530 11:34:47.018146 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0209657 (* 1 = 0.0209657 loss)
I0530 11:34:47.018152 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0464919 (* 1 = 0.0464919 loss)
I0530 11:34:47.018159 24924 sgd_solver.cpp:106] Iteration 19760, lr = 0.0002
I0530 11:35:38.807852 24924 solver.cpp:228] Iteration 19780, loss = 0.289059
I0530 11:35:38.807879 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 11:35:38.807886 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.143255 (* 1 = 0.143255 loss)
I0530 11:35:38.807890 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.201417 (* 1 = 0.201417 loss)
I0530 11:35:38.807894 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129504 (* 1 = 0.0129504 loss)
I0530 11:35:38.807898 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298999 (* 1 = 0.0298999 loss)
I0530 11:35:38.807902 24924 sgd_solver.cpp:106] Iteration 19780, lr = 0.0002
speed: 2.462s / iter
I0530 11:36:30.652576 24924 solver.cpp:228] Iteration 19800, loss = 0.262018
I0530 11:36:30.652600 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 11:36:30.652607 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.135241 (* 1 = 0.135241 loss)
I0530 11:36:30.652611 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.293643 (* 1 = 0.293643 loss)
I0530 11:36:30.652616 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00571875 (* 1 = 0.00571875 loss)
I0530 11:36:30.652618 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243643 (* 1 = 0.0243643 loss)
I0530 11:36:30.652623 24924 sgd_solver.cpp:106] Iteration 19800, lr = 0.0002
I0530 11:37:22.430150 24924 solver.cpp:228] Iteration 19820, loss = 0.243002
I0530 11:37:22.430174 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 11:37:22.430182 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513673 (* 1 = 0.0513673 loss)
I0530 11:37:22.430186 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.079203 (* 1 = 0.079203 loss)
I0530 11:37:22.430189 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00118992 (* 1 = 0.00118992 loss)
I0530 11:37:22.430193 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0199929 (* 1 = 0.0199929 loss)
I0530 11:37:22.430197 24924 sgd_solver.cpp:106] Iteration 19820, lr = 0.0002
I0530 11:38:14.329738 24924 solver.cpp:228] Iteration 19840, loss = 0.268298
I0530 11:38:14.329763 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 11:38:14.329771 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0643779 (* 1 = 0.0643779 loss)
I0530 11:38:14.329776 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0718586 (* 1 = 0.0718586 loss)
I0530 11:38:14.329779 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00315447 (* 1 = 0.00315447 loss)
I0530 11:38:14.329782 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214107 (* 1 = 0.0214107 loss)
I0530 11:38:14.329788 24924 sgd_solver.cpp:106] Iteration 19840, lr = 0.0002
I0530 11:39:06.170789 24924 solver.cpp:228] Iteration 19860, loss = 0.459916
I0530 11:39:06.170811 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 11:39:06.170817 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.127089 (* 1 = 0.127089 loss)
I0530 11:39:06.170821 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.388451 (* 1 = 0.388451 loss)
I0530 11:39:06.170825 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.225196 (* 1 = 0.225196 loss)
I0530 11:39:06.170827 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.18016 (* 1 = 0.18016 loss)
I0530 11:39:06.170831 24924 sgd_solver.cpp:106] Iteration 19860, lr = 0.0002
I0530 11:39:58.079394 24924 solver.cpp:228] Iteration 19880, loss = 0.437233
I0530 11:39:58.079416 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 11:39:58.079423 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.249614 (* 1 = 0.249614 loss)
I0530 11:39:58.079428 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.426354 (* 1 = 0.426354 loss)
I0530 11:39:58.079432 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015896 (* 1 = 0.015896 loss)
I0530 11:39:58.079435 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0671597 (* 1 = 0.0671597 loss)
I0530 11:39:58.079440 24924 sgd_solver.cpp:106] Iteration 19880, lr = 0.0002
I0530 11:40:49.979605 24924 solver.cpp:228] Iteration 19900, loss = 0.300434
I0530 11:40:49.979627 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 11:40:49.979635 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.141464 (* 1 = 0.141464 loss)
I0530 11:40:49.979638 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.288664 (* 1 = 0.288664 loss)
I0530 11:40:49.979641 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0256692 (* 1 = 0.0256692 loss)
I0530 11:40:49.979645 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0595734 (* 1 = 0.0595734 loss)
I0530 11:40:49.979650 24924 sgd_solver.cpp:106] Iteration 19900, lr = 0.0002
I0530 11:41:41.784024 24924 solver.cpp:228] Iteration 19920, loss = 0.337631
I0530 11:41:41.784046 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 11:41:41.784054 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.183639 (* 1 = 0.183639 loss)
I0530 11:41:41.784057 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.376987 (* 1 = 0.376987 loss)
I0530 11:41:41.784060 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0328438 (* 1 = 0.0328438 loss)
I0530 11:41:41.784065 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103213 (* 1 = 0.103213 loss)
I0530 11:41:41.784068 24924 sgd_solver.cpp:106] Iteration 19920, lr = 0.0002
I0530 11:42:33.669906 24924 solver.cpp:228] Iteration 19940, loss = 0.401996
I0530 11:42:33.669932 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 11:42:33.669940 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.113577 (* 1 = 0.113577 loss)
I0530 11:42:33.669945 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134332 (* 1 = 0.134332 loss)
I0530 11:42:33.669950 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126399 (* 1 = 0.0126399 loss)
I0530 11:42:33.669953 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0697809 (* 1 = 0.0697809 loss)
I0530 11:42:33.669957 24924 sgd_solver.cpp:106] Iteration 19940, lr = 0.0002
I0530 11:43:25.541718 24924 solver.cpp:228] Iteration 19960, loss = 0.2821
I0530 11:43:25.541741 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 11:43:25.541749 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0645024 (* 1 = 0.0645024 loss)
I0530 11:43:25.541754 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102773 (* 1 = 0.102773 loss)
I0530 11:43:25.541756 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00271712 (* 1 = 0.00271712 loss)
I0530 11:43:25.541760 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.031518 (* 1 = 0.031518 loss)
I0530 11:43:25.541764 24924 sgd_solver.cpp:106] Iteration 19960, lr = 0.0002
I0530 11:44:17.485646 24924 solver.cpp:228] Iteration 19980, loss = 0.321691
I0530 11:44:17.485669 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 11:44:17.485677 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.020388 (* 1 = 0.020388 loss)
I0530 11:44:17.485680 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0824091 (* 1 = 0.0824091 loss)
I0530 11:44:17.485684 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00376097 (* 1 = 0.00376097 loss)
I0530 11:44:17.485688 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327582 (* 1 = 0.0327582 loss)
I0530 11:44:17.485693 24924 sgd_solver.cpp:106] Iteration 19980, lr = 0.0002
speed: 2.464s / iter
I0530 11:45:07.007524 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_20000.caffemodel
I0530 11:45:10.201552 24924 solver.cpp:228] Iteration 20000, loss = 0.29529
I0530 11:45:10.201578 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 11:45:10.201586 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.248434 (* 1 = 0.248434 loss)
I0530 11:45:10.201591 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.230678 (* 1 = 0.230678 loss)
I0530 11:45:10.201594 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0053207 (* 1 = 0.0053207 loss)
I0530 11:45:10.201598 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280355 (* 1 = 0.0280355 loss)
I0530 11:45:10.201603 24924 sgd_solver.cpp:106] Iteration 20000, lr = 0.0002
I0530 11:46:02.093852 24924 solver.cpp:228] Iteration 20020, loss = 0.368309
I0530 11:46:02.093873 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 11:46:02.093880 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.152755 (* 1 = 0.152755 loss)
I0530 11:46:02.093884 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.343944 (* 1 = 0.343944 loss)
I0530 11:46:02.093888 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0746922 (* 1 = 0.0746922 loss)
I0530 11:46:02.093891 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0986888 (* 1 = 0.0986888 loss)
I0530 11:46:02.093895 24924 sgd_solver.cpp:106] Iteration 20020, lr = 0.0002
I0530 11:46:53.963907 24924 solver.cpp:228] Iteration 20040, loss = 0.382585
I0530 11:46:53.963933 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 11:46:53.963941 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.237267 (* 1 = 0.237267 loss)
I0530 11:46:53.963946 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.362946 (* 1 = 0.362946 loss)
I0530 11:46:53.963951 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112012 (* 1 = 0.0112012 loss)
I0530 11:46:53.963955 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0559372 (* 1 = 0.0559372 loss)
I0530 11:46:53.963961 24924 sgd_solver.cpp:106] Iteration 20040, lr = 0.0002
I0530 11:47:45.834848 24924 solver.cpp:228] Iteration 20060, loss = 0.163553
I0530 11:47:45.834870 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 11:47:45.834877 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0857417 (* 1 = 0.0857417 loss)
I0530 11:47:45.834880 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.182404 (* 1 = 0.182404 loss)
I0530 11:47:45.834884 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00618356 (* 1 = 0.00618356 loss)
I0530 11:47:45.834887 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0513442 (* 1 = 0.0513442 loss)
I0530 11:47:45.834892 24924 sgd_solver.cpp:106] Iteration 20060, lr = 0.0002
I0530 11:48:37.735251 24924 solver.cpp:228] Iteration 20080, loss = 0.490148
I0530 11:48:37.735277 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 11:48:37.735288 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.216329 (* 1 = 0.216329 loss)
I0530 11:48:37.735294 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.307408 (* 1 = 0.307408 loss)
I0530 11:48:37.735301 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00666479 (* 1 = 0.00666479 loss)
I0530 11:48:37.735306 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0460971 (* 1 = 0.0460971 loss)
I0530 11:48:37.735313 24924 sgd_solver.cpp:106] Iteration 20080, lr = 0.0002
I0530 11:49:29.658905 24924 solver.cpp:228] Iteration 20100, loss = 0.314541
I0530 11:49:29.658927 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 11:49:29.658936 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0639638 (* 1 = 0.0639638 loss)
I0530 11:49:29.658941 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.126873 (* 1 = 0.126873 loss)
I0530 11:49:29.658948 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134098 (* 1 = 0.0134098 loss)
I0530 11:49:29.658952 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163584 (* 1 = 0.0163584 loss)
I0530 11:49:29.658958 24924 sgd_solver.cpp:106] Iteration 20100, lr = 0.0002
I0530 11:50:21.558364 24924 solver.cpp:228] Iteration 20120, loss = 0.274151
I0530 11:50:21.558390 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 11:50:21.558398 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.045893 (* 1 = 0.045893 loss)
I0530 11:50:21.558403 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.145985 (* 1 = 0.145985 loss)
I0530 11:50:21.558406 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.037177 (* 1 = 0.037177 loss)
I0530 11:50:21.558410 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178273 (* 1 = 0.0178273 loss)
I0530 11:50:21.558415 24924 sgd_solver.cpp:106] Iteration 20120, lr = 0.0002
I0530 11:51:13.462795 24924 solver.cpp:228] Iteration 20140, loss = 0.365189
I0530 11:51:13.462819 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 11:51:13.462826 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0122883 (* 1 = 0.0122883 loss)
I0530 11:51:13.462831 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.130967 (* 1 = 0.130967 loss)
I0530 11:51:13.462833 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00259593 (* 1 = 0.00259593 loss)
I0530 11:51:13.462837 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150001 (* 1 = 0.0150001 loss)
I0530 11:51:13.462841 24924 sgd_solver.cpp:106] Iteration 20140, lr = 0.0002
I0530 11:52:05.339272 24924 solver.cpp:228] Iteration 20160, loss = 0.282142
I0530 11:52:05.339295 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 11:52:05.339301 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.244175 (* 1 = 0.244175 loss)
I0530 11:52:05.339305 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.313494 (* 1 = 0.313494 loss)
I0530 11:52:05.339309 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00352017 (* 1 = 0.00352017 loss)
I0530 11:52:05.339313 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0728874 (* 1 = 0.0728874 loss)
I0530 11:52:05.339318 24924 sgd_solver.cpp:106] Iteration 20160, lr = 0.0002
I0530 11:52:57.219000 24924 solver.cpp:228] Iteration 20180, loss = 0.374246
I0530 11:52:57.219024 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 11:52:57.219033 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0724468 (* 1 = 0.0724468 loss)
I0530 11:52:57.219036 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127727 (* 1 = 0.127727 loss)
I0530 11:52:57.219040 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0335051 (* 1 = 0.0335051 loss)
I0530 11:52:57.219044 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358537 (* 1 = 0.0358537 loss)
I0530 11:52:57.219049 24924 sgd_solver.cpp:106] Iteration 20180, lr = 0.0002
speed: 2.465s / iter
I0530 11:53:49.113732 24924 solver.cpp:228] Iteration 20200, loss = 0.289515
I0530 11:53:49.113754 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 11:53:49.113761 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.123392 (* 1 = 0.123392 loss)
I0530 11:53:49.113765 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.135796 (* 1 = 0.135796 loss)
I0530 11:53:49.113770 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00489837 (* 1 = 0.00489837 loss)
I0530 11:53:49.113773 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0165269 (* 1 = 0.0165269 loss)
I0530 11:53:49.113777 24924 sgd_solver.cpp:106] Iteration 20200, lr = 0.0002
I0530 11:54:40.996536 24924 solver.cpp:228] Iteration 20220, loss = 0.312885
I0530 11:54:40.996562 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0530 11:54:40.996572 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.226286 (* 1 = 0.226286 loss)
I0530 11:54:40.996579 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.43208 (* 1 = 0.43208 loss)
I0530 11:54:40.996587 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0387037 (* 1 = 0.0387037 loss)
I0530 11:54:40.996592 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0326099 (* 1 = 0.0326099 loss)
I0530 11:54:40.996600 24924 sgd_solver.cpp:106] Iteration 20220, lr = 0.0002
I0530 11:55:32.897707 24924 solver.cpp:228] Iteration 20240, loss = 0.281134
I0530 11:55:32.897735 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 11:55:32.897743 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189033 (* 1 = 0.0189033 loss)
I0530 11:55:32.897748 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0582239 (* 1 = 0.0582239 loss)
I0530 11:55:32.897753 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00492995 (* 1 = 0.00492995 loss)
I0530 11:55:32.897756 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00209867 (* 1 = 0.00209867 loss)
I0530 11:55:32.897761 24924 sgd_solver.cpp:106] Iteration 20240, lr = 0.0002
I0530 11:56:24.788738 24924 solver.cpp:228] Iteration 20260, loss = 0.248818
I0530 11:56:24.788761 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 11:56:24.788769 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.283478 (* 1 = 0.283478 loss)
I0530 11:56:24.788774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272758 (* 1 = 0.272758 loss)
I0530 11:56:24.788777 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00755249 (* 1 = 0.00755249 loss)
I0530 11:56:24.788781 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0493054 (* 1 = 0.0493054 loss)
I0530 11:56:24.788786 24924 sgd_solver.cpp:106] Iteration 20260, lr = 0.0002
I0530 11:57:16.680428 24924 solver.cpp:228] Iteration 20280, loss = 0.261003
I0530 11:57:16.680454 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 11:57:16.680464 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.205496 (* 1 = 0.205496 loss)
I0530 11:57:16.680471 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.276096 (* 1 = 0.276096 loss)
I0530 11:57:16.680477 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0223955 (* 1 = 0.0223955 loss)
I0530 11:57:16.680483 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0438101 (* 1 = 0.0438101 loss)
I0530 11:57:16.680491 24924 sgd_solver.cpp:106] Iteration 20280, lr = 0.0002
I0530 11:58:08.592476 24924 solver.cpp:228] Iteration 20300, loss = 0.189514
I0530 11:58:08.592502 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 11:58:08.592512 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0594485 (* 1 = 0.0594485 loss)
I0530 11:58:08.592519 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.135601 (* 1 = 0.135601 loss)
I0530 11:58:08.592525 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00715684 (* 1 = 0.00715684 loss)
I0530 11:58:08.592530 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205918 (* 1 = 0.0205918 loss)
I0530 11:58:08.592537 24924 sgd_solver.cpp:106] Iteration 20300, lr = 0.0002
I0530 11:59:00.509357 24924 solver.cpp:228] Iteration 20320, loss = 0.365865
I0530 11:59:00.509384 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 11:59:00.509394 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.309182 (* 1 = 0.309182 loss)
I0530 11:59:00.509400 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.286246 (* 1 = 0.286246 loss)
I0530 11:59:00.509407 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00391967 (* 1 = 0.00391967 loss)
I0530 11:59:00.509413 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0381245 (* 1 = 0.0381245 loss)
I0530 11:59:00.509420 24924 sgd_solver.cpp:106] Iteration 20320, lr = 0.0002
I0530 11:59:52.429153 24924 solver.cpp:228] Iteration 20340, loss = 0.456344
I0530 11:59:52.429180 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 11:59:52.429188 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0127579 (* 1 = 0.0127579 loss)
I0530 11:59:52.429191 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139518 (* 1 = 0.139518 loss)
I0530 11:59:52.429195 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00296245 (* 1 = 0.00296245 loss)
I0530 11:59:52.429198 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00833854 (* 1 = 0.00833854 loss)
I0530 11:59:52.429204 24924 sgd_solver.cpp:106] Iteration 20340, lr = 0.0002
I0530 12:00:44.327821 24924 solver.cpp:228] Iteration 20360, loss = 0.262251
I0530 12:00:44.327852 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 12:00:44.327862 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.138835 (* 1 = 0.138835 loss)
I0530 12:00:44.327868 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.198638 (* 1 = 0.198638 loss)
I0530 12:00:44.327874 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250248 (* 1 = 0.00250248 loss)
I0530 12:00:44.327880 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291415 (* 1 = 0.0291415 loss)
I0530 12:00:44.327888 24924 sgd_solver.cpp:106] Iteration 20360, lr = 0.0002
I0530 12:01:36.233922 24924 solver.cpp:228] Iteration 20380, loss = 0.183485
I0530 12:01:36.233945 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:01:36.233952 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0591777 (* 1 = 0.0591777 loss)
I0530 12:01:36.233956 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0602793 (* 1 = 0.0602793 loss)
I0530 12:01:36.233960 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00656207 (* 1 = 0.00656207 loss)
I0530 12:01:36.233963 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00521626 (* 1 = 0.00521626 loss)
I0530 12:01:36.233969 24924 sgd_solver.cpp:106] Iteration 20380, lr = 0.0002
speed: 2.466s / iter
I0530 12:02:28.103893 24924 solver.cpp:228] Iteration 20400, loss = 0.206697
I0530 12:02:28.103916 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:02:28.103924 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0373141 (* 1 = 0.0373141 loss)
I0530 12:02:28.103927 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0570163 (* 1 = 0.0570163 loss)
I0530 12:02:28.103931 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00382726 (* 1 = 0.00382726 loss)
I0530 12:02:28.103935 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0233206 (* 1 = 0.0233206 loss)
I0530 12:02:28.103940 24924 sgd_solver.cpp:106] Iteration 20400, lr = 0.0002
I0530 12:03:19.876370 24924 solver.cpp:228] Iteration 20420, loss = 0.235399
I0530 12:03:19.876397 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 12:03:19.876407 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160303 (* 1 = 0.160303 loss)
I0530 12:03:19.876411 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.280033 (* 1 = 0.280033 loss)
I0530 12:03:19.876416 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146793 (* 1 = 0.0146793 loss)
I0530 12:03:19.876420 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0502144 (* 1 = 0.0502144 loss)
I0530 12:03:19.876426 24924 sgd_solver.cpp:106] Iteration 20420, lr = 0.0002
I0530 12:04:11.757742 24924 solver.cpp:228] Iteration 20440, loss = 0.345954
I0530 12:04:11.757764 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 12:04:11.757771 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00461562 (* 1 = 0.00461562 loss)
I0530 12:04:11.757776 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0412389 (* 1 = 0.0412389 loss)
I0530 12:04:11.757779 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0684973 (* 1 = 0.0684973 loss)
I0530 12:04:11.757782 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214103 (* 1 = 0.0214103 loss)
I0530 12:04:11.757788 24924 sgd_solver.cpp:106] Iteration 20440, lr = 0.0002
I0530 12:05:03.214375 24924 solver.cpp:228] Iteration 20460, loss = 0.3257
I0530 12:05:03.214402 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 12:05:03.214411 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.136356 (* 1 = 0.136356 loss)
I0530 12:05:03.214416 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160332 (* 1 = 0.160332 loss)
I0530 12:05:03.214421 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0135101 (* 1 = 0.0135101 loss)
I0530 12:05:03.214426 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.045541 (* 1 = 0.045541 loss)
I0530 12:05:03.214432 24924 sgd_solver.cpp:106] Iteration 20460, lr = 0.0002
I0530 12:05:54.952118 24924 solver.cpp:228] Iteration 20480, loss = 0.207461
I0530 12:05:54.952142 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:05:54.952149 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0961675 (* 1 = 0.0961675 loss)
I0530 12:05:54.952153 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0840021 (* 1 = 0.0840021 loss)
I0530 12:05:54.952157 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00373799 (* 1 = 0.00373799 loss)
I0530 12:05:54.952160 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.018574 (* 1 = 0.018574 loss)
I0530 12:05:54.952164 24924 sgd_solver.cpp:106] Iteration 20480, lr = 0.0002
I0530 12:06:46.814095 24924 solver.cpp:228] Iteration 20500, loss = 0.149279
I0530 12:06:46.814121 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 12:06:46.814128 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.191792 (* 1 = 0.191792 loss)
I0530 12:06:46.814132 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.327306 (* 1 = 0.327306 loss)
I0530 12:06:46.814136 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126677 (* 1 = 0.0126677 loss)
I0530 12:06:46.814141 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206971 (* 1 = 0.0206971 loss)
I0530 12:06:46.814146 24924 sgd_solver.cpp:106] Iteration 20500, lr = 0.0002
I0530 12:07:38.660352 24924 solver.cpp:228] Iteration 20520, loss = 0.28136
I0530 12:07:38.660377 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 12:07:38.660385 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.170758 (* 1 = 0.170758 loss)
I0530 12:07:38.660390 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.265656 (* 1 = 0.265656 loss)
I0530 12:07:38.660394 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00379265 (* 1 = 0.00379265 loss)
I0530 12:07:38.660398 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.034266 (* 1 = 0.034266 loss)
I0530 12:07:38.660403 24924 sgd_solver.cpp:106] Iteration 20520, lr = 0.0002
I0530 12:08:30.372623 24924 solver.cpp:228] Iteration 20540, loss = 0.85556
I0530 12:08:30.372648 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:08:30.372655 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0777652 (* 1 = 0.0777652 loss)
I0530 12:08:30.372659 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.183099 (* 1 = 0.183099 loss)
I0530 12:08:30.372663 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00321119 (* 1 = 0.00321119 loss)
I0530 12:08:30.372668 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0109723 (* 1 = 0.0109723 loss)
I0530 12:08:30.372671 24924 sgd_solver.cpp:106] Iteration 20540, lr = 0.0002
I0530 12:09:22.190613 24924 solver.cpp:228] Iteration 20560, loss = 0.460597
I0530 12:09:22.190639 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 12:09:22.190647 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.225378 (* 1 = 0.225378 loss)
I0530 12:09:22.190651 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147203 (* 1 = 0.147203 loss)
I0530 12:09:22.190655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00534158 (* 1 = 0.00534158 loss)
I0530 12:09:22.190659 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221095 (* 1 = 0.0221095 loss)
I0530 12:09:22.190665 24924 sgd_solver.cpp:106] Iteration 20560, lr = 0.0002
I0530 12:10:13.987707 24924 solver.cpp:228] Iteration 20580, loss = 0.295342
I0530 12:10:13.987730 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:10:13.987736 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0926191 (* 1 = 0.0926191 loss)
I0530 12:10:13.987740 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142241 (* 1 = 0.142241 loss)
I0530 12:10:13.987743 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0280111 (* 1 = 0.0280111 loss)
I0530 12:10:13.987746 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0530377 (* 1 = 0.0530377 loss)
I0530 12:10:13.987751 24924 sgd_solver.cpp:106] Iteration 20580, lr = 0.0002
speed: 2.468s / iter
I0530 12:11:05.833405 24924 solver.cpp:228] Iteration 20600, loss = 0.31738
I0530 12:11:05.833431 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 12:11:05.833437 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00245096 (* 1 = 0.00245096 loss)
I0530 12:11:05.833442 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.043814 (* 1 = 0.043814 loss)
I0530 12:11:05.833446 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00511958 (* 1 = 0.00511958 loss)
I0530 12:11:05.833448 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118563 (* 1 = 0.0118563 loss)
I0530 12:11:05.833453 24924 sgd_solver.cpp:106] Iteration 20600, lr = 0.0002
I0530 12:11:57.634582 24924 solver.cpp:228] Iteration 20620, loss = 0.370035
I0530 12:11:57.634608 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 12:11:57.634616 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.17957 (* 1 = 0.17957 loss)
I0530 12:11:57.634620 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.415937 (* 1 = 0.415937 loss)
I0530 12:11:57.634624 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0235255 (* 1 = 0.0235255 loss)
I0530 12:11:57.634629 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0886261 (* 1 = 0.0886261 loss)
I0530 12:11:57.634634 24924 sgd_solver.cpp:106] Iteration 20620, lr = 0.0002
I0530 12:12:49.490636 24924 solver.cpp:228] Iteration 20640, loss = 0.22574
I0530 12:12:49.490659 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 12:12:49.490667 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.040818 (* 1 = 0.040818 loss)
I0530 12:12:49.490671 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132802 (* 1 = 0.132802 loss)
I0530 12:12:49.490674 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00486696 (* 1 = 0.00486696 loss)
I0530 12:12:49.490679 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0523786 (* 1 = 0.0523786 loss)
I0530 12:12:49.490682 24924 sgd_solver.cpp:106] Iteration 20640, lr = 0.0002
I0530 12:13:41.350980 24924 solver.cpp:228] Iteration 20660, loss = 0.280611
I0530 12:13:41.351002 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:13:41.351012 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0294931 (* 1 = 0.0294931 loss)
I0530 12:13:41.351018 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.068618 (* 1 = 0.068618 loss)
I0530 12:13:41.351022 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105704 (* 1 = 0.0105704 loss)
I0530 12:13:41.351028 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00658968 (* 1 = 0.00658968 loss)
I0530 12:13:41.351035 24924 sgd_solver.cpp:106] Iteration 20660, lr = 0.0002
I0530 12:14:33.167527 24924 solver.cpp:228] Iteration 20680, loss = 0.229919
I0530 12:14:33.167551 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 12:14:33.167559 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0700993 (* 1 = 0.0700993 loss)
I0530 12:14:33.167563 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186638 (* 1 = 0.186638 loss)
I0530 12:14:33.167567 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211997 (* 1 = 0.0211997 loss)
I0530 12:14:33.167572 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0135796 (* 1 = 0.0135796 loss)
I0530 12:14:33.167577 24924 sgd_solver.cpp:106] Iteration 20680, lr = 0.0002
I0530 12:15:25.020781 24924 solver.cpp:228] Iteration 20700, loss = 0.367716
I0530 12:15:25.020803 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 12:15:25.020809 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.057218 (* 1 = 0.057218 loss)
I0530 12:15:25.020813 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.176003 (* 1 = 0.176003 loss)
I0530 12:15:25.020817 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0389767 (* 1 = 0.0389767 loss)
I0530 12:15:25.020820 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0715449 (* 1 = 0.0715449 loss)
I0530 12:15:25.020824 24924 sgd_solver.cpp:106] Iteration 20700, lr = 0.0002
I0530 12:16:16.749189 24924 solver.cpp:228] Iteration 20720, loss = 0.236146
I0530 12:16:16.749210 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 12:16:16.749217 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442471 (* 1 = 0.0442471 loss)
I0530 12:16:16.749220 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0951194 (* 1 = 0.0951194 loss)
I0530 12:16:16.749223 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052434 (* 1 = 0.0052434 loss)
I0530 12:16:16.749228 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116071 (* 1 = 0.0116071 loss)
I0530 12:16:16.749231 24924 sgd_solver.cpp:106] Iteration 20720, lr = 0.0002
I0530 12:17:08.429541 24924 solver.cpp:228] Iteration 20740, loss = 0.171903
I0530 12:17:08.429565 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:17:08.429572 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0216315 (* 1 = 0.0216315 loss)
I0530 12:17:08.429576 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0747187 (* 1 = 0.0747187 loss)
I0530 12:17:08.429579 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114629 (* 1 = 0.00114629 loss)
I0530 12:17:08.429584 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134066 (* 1 = 0.0134066 loss)
I0530 12:17:08.429587 24924 sgd_solver.cpp:106] Iteration 20740, lr = 0.0002
I0530 12:18:00.160543 24924 solver.cpp:228] Iteration 20760, loss = 0.404426
I0530 12:18:00.160567 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 12:18:00.160573 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0199325 (* 1 = 0.0199325 loss)
I0530 12:18:00.160578 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0715549 (* 1 = 0.0715549 loss)
I0530 12:18:00.160581 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119721 (* 1 = 0.0119721 loss)
I0530 12:18:00.160584 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184001 (* 1 = 0.0184001 loss)
I0530 12:18:00.160588 24924 sgd_solver.cpp:106] Iteration 20760, lr = 0.0002
I0530 12:18:52.027432 24924 solver.cpp:228] Iteration 20780, loss = 0.182687
I0530 12:18:52.027456 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:18:52.027463 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0710134 (* 1 = 0.0710134 loss)
I0530 12:18:52.027467 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0597028 (* 1 = 0.0597028 loss)
I0530 12:18:52.027472 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104091 (* 1 = 0.0104091 loss)
I0530 12:18:52.027474 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00962502 (* 1 = 0.00962502 loss)
I0530 12:18:52.027479 24924 sgd_solver.cpp:106] Iteration 20780, lr = 0.0002
speed: 2.469s / iter
I0530 12:19:43.778998 24924 solver.cpp:228] Iteration 20800, loss = 0.165397
I0530 12:19:43.779021 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:19:43.779028 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0545309 (* 1 = 0.0545309 loss)
I0530 12:19:43.779032 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0587018 (* 1 = 0.0587018 loss)
I0530 12:19:43.779036 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00497737 (* 1 = 0.00497737 loss)
I0530 12:19:43.779039 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172808 (* 1 = 0.0172808 loss)
I0530 12:19:43.779043 24924 sgd_solver.cpp:106] Iteration 20800, lr = 0.0002
I0530 12:20:35.598650 24924 solver.cpp:228] Iteration 20820, loss = 0.327729
I0530 12:20:35.598675 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:20:35.598681 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.105256 (* 1 = 0.105256 loss)
I0530 12:20:35.598685 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.199479 (* 1 = 0.199479 loss)
I0530 12:20:35.598688 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0654648 (* 1 = 0.0654648 loss)
I0530 12:20:35.598691 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0855155 (* 1 = 0.0855155 loss)
I0530 12:20:35.598695 24924 sgd_solver.cpp:106] Iteration 20820, lr = 0.0002
I0530 12:21:27.461565 24924 solver.cpp:228] Iteration 20840, loss = 0.329968
I0530 12:21:27.461591 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 12:21:27.461601 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00153507 (* 1 = 0.00153507 loss)
I0530 12:21:27.461607 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0448389 (* 1 = 0.0448389 loss)
I0530 12:21:27.461612 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00518453 (* 1 = 0.00518453 loss)
I0530 12:21:27.461617 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321029 (* 1 = 0.0321029 loss)
I0530 12:21:27.461624 24924 sgd_solver.cpp:106] Iteration 20840, lr = 0.0002
I0530 12:22:19.322453 24924 solver.cpp:228] Iteration 20860, loss = 0.531878
I0530 12:22:19.322480 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 12:22:19.322489 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.228729 (* 1 = 0.228729 loss)
I0530 12:22:19.322494 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.200149 (* 1 = 0.200149 loss)
I0530 12:22:19.322497 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202221 (* 1 = 0.0202221 loss)
I0530 12:22:19.322501 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383688 (* 1 = 0.0383688 loss)
I0530 12:22:19.322506 24924 sgd_solver.cpp:106] Iteration 20860, lr = 0.0002
I0530 12:23:11.195116 24924 solver.cpp:228] Iteration 20880, loss = 0.185497
I0530 12:23:11.195139 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:23:11.195147 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0843388 (* 1 = 0.0843388 loss)
I0530 12:23:11.195150 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141175 (* 1 = 0.141175 loss)
I0530 12:23:11.195153 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00193177 (* 1 = 0.00193177 loss)
I0530 12:23:11.195158 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167383 (* 1 = 0.0167383 loss)
I0530 12:23:11.195163 24924 sgd_solver.cpp:106] Iteration 20880, lr = 0.0002
I0530 12:24:03.045624 24924 solver.cpp:228] Iteration 20900, loss = 0.217912
I0530 12:24:03.045647 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:24:03.045655 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0189403 (* 1 = 0.0189403 loss)
I0530 12:24:03.045658 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0445598 (* 1 = 0.0445598 loss)
I0530 12:24:03.045662 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00456769 (* 1 = 0.00456769 loss)
I0530 12:24:03.045665 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146955 (* 1 = 0.0146955 loss)
I0530 12:24:03.045670 24924 sgd_solver.cpp:106] Iteration 20900, lr = 0.0002
I0530 12:24:54.867733 24924 solver.cpp:228] Iteration 20920, loss = 0.314944
I0530 12:24:54.867763 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 12:24:54.867774 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103536 (* 1 = 0.103536 loss)
I0530 12:24:54.867781 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.259128 (* 1 = 0.259128 loss)
I0530 12:24:54.867789 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.044078 (* 1 = 0.044078 loss)
I0530 12:24:54.867795 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0510631 (* 1 = 0.0510631 loss)
I0530 12:24:54.867802 24924 sgd_solver.cpp:106] Iteration 20920, lr = 0.0002
I0530 12:25:46.703424 24924 solver.cpp:228] Iteration 20940, loss = 0.210059
I0530 12:25:46.703449 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 12:25:46.703456 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0273311 (* 1 = 0.0273311 loss)
I0530 12:25:46.703460 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.14867 (* 1 = 0.14867 loss)
I0530 12:25:46.703464 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279201 (* 1 = 0.0279201 loss)
I0530 12:25:46.703467 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0170277 (* 1 = 0.0170277 loss)
I0530 12:25:46.703471 24924 sgd_solver.cpp:106] Iteration 20940, lr = 0.0002
I0530 12:26:38.552153 24924 solver.cpp:228] Iteration 20960, loss = 0.334756
I0530 12:26:38.552176 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0530 12:26:38.552186 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.395139 (* 1 = 0.395139 loss)
I0530 12:26:38.552192 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.509354 (* 1 = 0.509354 loss)
I0530 12:26:38.552197 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00907544 (* 1 = 0.00907544 loss)
I0530 12:26:38.552203 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0702376 (* 1 = 0.0702376 loss)
I0530 12:26:38.552209 24924 sgd_solver.cpp:106] Iteration 20960, lr = 0.0002
I0530 12:27:30.310945 24924 solver.cpp:228] Iteration 20980, loss = 0.32476
I0530 12:27:30.310969 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 12:27:30.310978 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.127463 (* 1 = 0.127463 loss)
I0530 12:27:30.310984 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.149581 (* 1 = 0.149581 loss)
I0530 12:27:30.310989 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0071811 (* 1 = 0.0071811 loss)
I0530 12:27:30.310995 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369989 (* 1 = 0.0369989 loss)
I0530 12:27:30.311002 24924 sgd_solver.cpp:106] Iteration 20980, lr = 0.0002
speed: 2.470s / iter
I0530 12:28:22.231082 24924 solver.cpp:228] Iteration 21000, loss = 0.388863
I0530 12:28:22.231106 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 12:28:22.231113 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.100569 (* 1 = 0.100569 loss)
I0530 12:28:22.231117 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.166452 (* 1 = 0.166452 loss)
I0530 12:28:22.231122 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00664597 (* 1 = 0.00664597 loss)
I0530 12:28:22.231124 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.038936 (* 1 = 0.038936 loss)
I0530 12:28:22.231129 24924 sgd_solver.cpp:106] Iteration 21000, lr = 0.0002
I0530 12:29:14.061347 24924 solver.cpp:228] Iteration 21020, loss = 0.323942
I0530 12:29:14.061375 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 12:29:14.061383 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0609589 (* 1 = 0.0609589 loss)
I0530 12:29:14.061386 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0731044 (* 1 = 0.0731044 loss)
I0530 12:29:14.061390 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0079933 (* 1 = 0.0079933 loss)
I0530 12:29:14.061394 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00248315 (* 1 = 0.00248315 loss)
I0530 12:29:14.061399 24924 sgd_solver.cpp:106] Iteration 21020, lr = 0.0002
I0530 12:30:05.940434 24924 solver.cpp:228] Iteration 21040, loss = 0.360585
I0530 12:30:05.940461 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 12:30:05.940471 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.31544 (* 1 = 0.31544 loss)
I0530 12:30:05.940477 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.477148 (* 1 = 0.477148 loss)
I0530 12:30:05.940484 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0582662 (* 1 = 0.0582662 loss)
I0530 12:30:05.940490 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.127021 (* 1 = 0.127021 loss)
I0530 12:30:05.940497 24924 sgd_solver.cpp:106] Iteration 21040, lr = 0.0002
I0530 12:30:57.801326 24924 solver.cpp:228] Iteration 21060, loss = 0.29066
I0530 12:30:57.801348 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 12:30:57.801358 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00376624 (* 1 = 0.00376624 loss)
I0530 12:30:57.801364 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.061459 (* 1 = 0.061459 loss)
I0530 12:30:57.801369 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0368503 (* 1 = 0.0368503 loss)
I0530 12:30:57.801375 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022081 (* 1 = 0.022081 loss)
I0530 12:30:57.801381 24924 sgd_solver.cpp:106] Iteration 21060, lr = 0.0002
I0530 12:31:49.665217 24924 solver.cpp:228] Iteration 21080, loss = 0.347862
I0530 12:31:49.665243 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:31:49.665254 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0472403 (* 1 = 0.0472403 loss)
I0530 12:31:49.665261 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0839 (* 1 = 0.0839 loss)
I0530 12:31:49.665267 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00400918 (* 1 = 0.00400918 loss)
I0530 12:31:49.665273 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167 (* 1 = 0.0167 loss)
I0530 12:31:49.665280 24924 sgd_solver.cpp:106] Iteration 21080, lr = 0.0002
I0530 12:32:41.534523 24924 solver.cpp:228] Iteration 21100, loss = 0.216652
I0530 12:32:41.534545 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 12:32:41.534554 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.114977 (* 1 = 0.114977 loss)
I0530 12:32:41.534557 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186928 (* 1 = 0.186928 loss)
I0530 12:32:41.534560 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012786 (* 1 = 0.012786 loss)
I0530 12:32:41.534564 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208089 (* 1 = 0.0208089 loss)
I0530 12:32:41.534569 24924 sgd_solver.cpp:106] Iteration 21100, lr = 0.0002
I0530 12:33:33.347645 24924 solver.cpp:228] Iteration 21120, loss = 0.337676
I0530 12:33:33.347677 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 12:33:33.347687 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587278 (* 1 = 0.0587278 loss)
I0530 12:33:33.347692 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0731709 (* 1 = 0.0731709 loss)
I0530 12:33:33.347697 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233292 (* 1 = 0.00233292 loss)
I0530 12:33:33.347702 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00565409 (* 1 = 0.00565409 loss)
I0530 12:33:33.347707 24924 sgd_solver.cpp:106] Iteration 21120, lr = 0.0002
I0530 12:34:25.254755 24924 solver.cpp:228] Iteration 21140, loss = 0.435264
I0530 12:34:25.254777 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 12:34:25.254784 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.193757 (* 1 = 0.193757 loss)
I0530 12:34:25.254787 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.336798 (* 1 = 0.336798 loss)
I0530 12:34:25.254791 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0660279 (* 1 = 0.0660279 loss)
I0530 12:34:25.254793 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.181702 (* 1 = 0.181702 loss)
I0530 12:34:25.254797 24924 sgd_solver.cpp:106] Iteration 21140, lr = 0.0002
I0530 12:35:17.150939 24924 solver.cpp:228] Iteration 21160, loss = 0.24513
I0530 12:35:17.150964 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 12:35:17.150971 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.165434 (* 1 = 0.165434 loss)
I0530 12:35:17.150975 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.374959 (* 1 = 0.374959 loss)
I0530 12:35:17.150979 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0149277 (* 1 = 0.0149277 loss)
I0530 12:35:17.150982 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0702546 (* 1 = 0.0702546 loss)
I0530 12:35:17.150987 24924 sgd_solver.cpp:106] Iteration 21160, lr = 0.0002
I0530 12:36:09.069628 24924 solver.cpp:228] Iteration 21180, loss = 0.322422
I0530 12:36:09.069653 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:36:09.069659 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0587145 (* 1 = 0.0587145 loss)
I0530 12:36:09.069664 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.164497 (* 1 = 0.164497 loss)
I0530 12:36:09.069667 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00467659 (* 1 = 0.00467659 loss)
I0530 12:36:09.069670 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00994492 (* 1 = 0.00994492 loss)
I0530 12:36:09.069674 24924 sgd_solver.cpp:106] Iteration 21180, lr = 0.0002
speed: 2.471s / iter
I0530 12:37:00.960867 24924 solver.cpp:228] Iteration 21200, loss = 0.283988
I0530 12:37:00.960891 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 12:37:00.960898 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0179265 (* 1 = 0.0179265 loss)
I0530 12:37:00.960901 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0436511 (* 1 = 0.0436511 loss)
I0530 12:37:00.960906 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125824 (* 1 = 0.0125824 loss)
I0530 12:37:00.960908 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00706642 (* 1 = 0.00706642 loss)
I0530 12:37:00.960953 24924 sgd_solver.cpp:106] Iteration 21200, lr = 0.0002
I0530 12:37:52.737540 24924 solver.cpp:228] Iteration 21220, loss = 0.501319
I0530 12:37:52.737565 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:37:52.737571 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0358325 (* 1 = 0.0358325 loss)
I0530 12:37:52.737576 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0867052 (* 1 = 0.0867052 loss)
I0530 12:37:52.737578 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121339 (* 1 = 0.0121339 loss)
I0530 12:37:52.737582 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0240138 (* 1 = 0.0240138 loss)
I0530 12:37:52.737586 24924 sgd_solver.cpp:106] Iteration 21220, lr = 0.0002
I0530 12:38:44.632377 24924 solver.cpp:228] Iteration 21240, loss = 0.564405
I0530 12:38:44.632402 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 12:38:44.632411 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0901031 (* 1 = 0.0901031 loss)
I0530 12:38:44.632419 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.13101 (* 1 = 0.13101 loss)
I0530 12:38:44.632424 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00784259 (* 1 = 0.00784259 loss)
I0530 12:38:44.632431 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0178484 (* 1 = 0.0178484 loss)
I0530 12:38:44.632438 24924 sgd_solver.cpp:106] Iteration 21240, lr = 0.0002
I0530 12:39:36.510706 24924 solver.cpp:228] Iteration 21260, loss = 0.450386
I0530 12:39:36.510731 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 12:39:36.510738 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.250409 (* 1 = 0.250409 loss)
I0530 12:39:36.510742 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.351504 (* 1 = 0.351504 loss)
I0530 12:39:36.510746 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0410401 (* 1 = 0.0410401 loss)
I0530 12:39:36.510749 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.105065 (* 1 = 0.105065 loss)
I0530 12:39:36.510754 24924 sgd_solver.cpp:106] Iteration 21260, lr = 0.0002
I0530 12:40:28.410780 24924 solver.cpp:228] Iteration 21280, loss = 0.284526
I0530 12:40:28.410805 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 12:40:28.410812 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.167016 (* 1 = 0.167016 loss)
I0530 12:40:28.410816 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.268512 (* 1 = 0.268512 loss)
I0530 12:40:28.410820 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0118969 (* 1 = 0.0118969 loss)
I0530 12:40:28.410825 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0221265 (* 1 = 0.0221265 loss)
I0530 12:40:28.410830 24924 sgd_solver.cpp:106] Iteration 21280, lr = 0.0002
I0530 12:41:20.289710 24924 solver.cpp:228] Iteration 21300, loss = 0.478561
I0530 12:41:20.289736 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 12:41:20.289744 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0457871 (* 1 = 0.0457871 loss)
I0530 12:41:20.289748 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0876249 (* 1 = 0.0876249 loss)
I0530 12:41:20.289752 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398337 (* 1 = 0.00398337 loss)
I0530 12:41:20.289755 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00948854 (* 1 = 0.00948854 loss)
I0530 12:41:20.289760 24924 sgd_solver.cpp:106] Iteration 21300, lr = 0.0002
I0530 12:42:12.206930 24924 solver.cpp:228] Iteration 21320, loss = 0.425854
I0530 12:42:12.206956 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 12:42:12.206964 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0405743 (* 1 = 0.0405743 loss)
I0530 12:42:12.206969 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.15784 (* 1 = 0.15784 loss)
I0530 12:42:12.206972 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00573766 (* 1 = 0.00573766 loss)
I0530 12:42:12.206976 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0346116 (* 1 = 0.0346116 loss)
I0530 12:42:12.206981 24924 sgd_solver.cpp:106] Iteration 21320, lr = 0.0002
I0530 12:43:04.061414 24924 solver.cpp:228] Iteration 21340, loss = 0.252466
I0530 12:43:04.061437 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 12:43:04.061444 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0439767 (* 1 = 0.0439767 loss)
I0530 12:43:04.061448 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0859714 (* 1 = 0.0859714 loss)
I0530 12:43:04.061452 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.011951 (* 1 = 0.011951 loss)
I0530 12:43:04.061455 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361057 (* 1 = 0.0361057 loss)
I0530 12:43:04.061460 24924 sgd_solver.cpp:106] Iteration 21340, lr = 0.0002
I0530 12:43:55.948484 24924 solver.cpp:228] Iteration 21360, loss = 0.475392
I0530 12:43:55.948510 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 12:43:55.948518 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00054455 (* 1 = 0.00054455 loss)
I0530 12:43:55.948523 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0513386 (* 1 = 0.0513386 loss)
I0530 12:43:55.948526 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030605 (* 1 = 0.030605 loss)
I0530 12:43:55.948530 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0600754 (* 1 = 0.0600754 loss)
I0530 12:43:55.948535 24924 sgd_solver.cpp:106] Iteration 21360, lr = 0.0002
I0530 12:44:47.828857 24924 solver.cpp:228] Iteration 21380, loss = 0.208309
I0530 12:44:47.828881 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:44:47.828889 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509755 (* 1 = 0.0509755 loss)
I0530 12:44:47.828893 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0852088 (* 1 = 0.0852088 loss)
I0530 12:44:47.828897 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00192269 (* 1 = 0.00192269 loss)
I0530 12:44:47.828902 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289356 (* 1 = 0.0289356 loss)
I0530 12:44:47.828907 24924 sgd_solver.cpp:106] Iteration 21380, lr = 0.0002
speed: 2.472s / iter
I0530 12:45:39.736147 24924 solver.cpp:228] Iteration 21400, loss = 0.557392
I0530 12:45:39.736172 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 12:45:39.736179 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.153374 (* 1 = 0.153374 loss)
I0530 12:45:39.736183 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.301529 (* 1 = 0.301529 loss)
I0530 12:45:39.736186 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0222293 (* 1 = 0.0222293 loss)
I0530 12:45:39.736189 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.071931 (* 1 = 0.071931 loss)
I0530 12:45:39.736194 24924 sgd_solver.cpp:106] Iteration 21400, lr = 0.0002
I0530 12:46:31.634851 24924 solver.cpp:228] Iteration 21420, loss = 0.488816
I0530 12:46:31.634881 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 12:46:31.634887 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00100546 (* 1 = 0.00100546 loss)
I0530 12:46:31.634891 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0406106 (* 1 = 0.0406106 loss)
I0530 12:46:31.634896 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00646648 (* 1 = 0.00646648 loss)
I0530 12:46:31.634898 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0212739 (* 1 = 0.0212739 loss)
I0530 12:46:31.634905 24924 sgd_solver.cpp:106] Iteration 21420, lr = 0.0002
I0530 12:47:23.534154 24924 solver.cpp:228] Iteration 21440, loss = 0.359022
I0530 12:47:23.534176 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 12:47:23.534184 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.177262 (* 1 = 0.177262 loss)
I0530 12:47:23.534188 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.399695 (* 1 = 0.399695 loss)
I0530 12:47:23.534191 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260058 (* 1 = 0.0260058 loss)
I0530 12:47:23.534195 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.103756 (* 1 = 0.103756 loss)
I0530 12:47:23.534199 24924 sgd_solver.cpp:106] Iteration 21440, lr = 0.0002
I0530 12:48:15.407496 24924 solver.cpp:228] Iteration 21460, loss = 0.304867
I0530 12:48:15.407522 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 12:48:15.407532 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0540527 (* 1 = 0.0540527 loss)
I0530 12:48:15.407538 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.125946 (* 1 = 0.125946 loss)
I0530 12:48:15.407544 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00958269 (* 1 = 0.00958269 loss)
I0530 12:48:15.407550 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157344 (* 1 = 0.0157344 loss)
I0530 12:48:15.407558 24924 sgd_solver.cpp:106] Iteration 21460, lr = 0.0002
I0530 12:49:07.284588 24924 solver.cpp:228] Iteration 21480, loss = 0.251107
I0530 12:49:07.284612 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:49:07.284620 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.172952 (* 1 = 0.172952 loss)
I0530 12:49:07.284623 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.158301 (* 1 = 0.158301 loss)
I0530 12:49:07.284626 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0286471 (* 1 = 0.0286471 loss)
I0530 12:49:07.284631 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0944847 (* 1 = 0.0944847 loss)
I0530 12:49:07.284634 24924 sgd_solver.cpp:106] Iteration 21480, lr = 0.0002
I0530 12:49:59.139487 24924 solver.cpp:228] Iteration 21500, loss = 0.227908
I0530 12:49:59.139511 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 12:49:59.139519 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.110819 (* 1 = 0.110819 loss)
I0530 12:49:59.139523 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.228659 (* 1 = 0.228659 loss)
I0530 12:49:59.139528 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0233732 (* 1 = 0.0233732 loss)
I0530 12:49:59.139531 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0149529 (* 1 = 0.0149529 loss)
I0530 12:49:59.139536 24924 sgd_solver.cpp:106] Iteration 21500, lr = 0.0002
I0530 12:50:51.003460 24924 solver.cpp:228] Iteration 21520, loss = 0.278265
I0530 12:50:51.003484 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:50:51.003492 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0513215 (* 1 = 0.0513215 loss)
I0530 12:50:51.003496 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.230002 (* 1 = 0.230002 loss)
I0530 12:50:51.003500 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218482 (* 1 = 0.0218482 loss)
I0530 12:50:51.003504 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304255 (* 1 = 0.0304255 loss)
I0530 12:50:51.003509 24924 sgd_solver.cpp:106] Iteration 21520, lr = 0.0002
I0530 12:51:42.857131 24924 solver.cpp:228] Iteration 21540, loss = 0.26891
I0530 12:51:42.857159 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 12:51:42.857167 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0884388 (* 1 = 0.0884388 loss)
I0530 12:51:42.857172 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117642 (* 1 = 0.117642 loss)
I0530 12:51:42.857175 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.024708 (* 1 = 0.024708 loss)
I0530 12:51:42.857178 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222124 (* 1 = 0.0222124 loss)
I0530 12:51:42.857184 24924 sgd_solver.cpp:106] Iteration 21540, lr = 0.0002
I0530 12:52:34.488765 24924 solver.cpp:228] Iteration 21560, loss = 0.257193
I0530 12:52:34.488786 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 12:52:34.488795 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0578685 (* 1 = 0.0578685 loss)
I0530 12:52:34.488801 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160709 (* 1 = 0.160709 loss)
I0530 12:52:34.488806 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0274769 (* 1 = 0.0274769 loss)
I0530 12:52:34.488809 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421918 (* 1 = 0.0421918 loss)
I0530 12:52:34.488816 24924 sgd_solver.cpp:106] Iteration 21560, lr = 0.0002
I0530 12:53:26.321122 24924 solver.cpp:228] Iteration 21580, loss = 0.301156
I0530 12:53:26.321147 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 12:53:26.321156 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109961 (* 1 = 0.109961 loss)
I0530 12:53:26.321159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.201265 (* 1 = 0.201265 loss)
I0530 12:53:26.321163 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0154042 (* 1 = 0.0154042 loss)
I0530 12:53:26.321167 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0209613 (* 1 = 0.0209613 loss)
I0530 12:53:26.321172 24924 sgd_solver.cpp:106] Iteration 21580, lr = 0.0002
speed: 2.473s / iter
I0530 12:54:18.101708 24924 solver.cpp:228] Iteration 21600, loss = 0.355463
I0530 12:54:18.101732 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 12:54:18.101738 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.126825 (* 1 = 0.126825 loss)
I0530 12:54:18.101742 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.280561 (* 1 = 0.280561 loss)
I0530 12:54:18.101745 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00722276 (* 1 = 0.00722276 loss)
I0530 12:54:18.101749 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207263 (* 1 = 0.0207263 loss)
I0530 12:54:18.101753 24924 sgd_solver.cpp:106] Iteration 21600, lr = 0.0002
I0530 12:55:10.016665 24924 solver.cpp:228] Iteration 21620, loss = 0.171828
I0530 12:55:10.016690 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 12:55:10.016698 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.10616 (* 1 = 0.10616 loss)
I0530 12:55:10.016703 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0999864 (* 1 = 0.0999864 loss)
I0530 12:55:10.016706 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0087992 (* 1 = 0.0087992 loss)
I0530 12:55:10.016710 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0183503 (* 1 = 0.0183503 loss)
I0530 12:55:10.016716 24924 sgd_solver.cpp:106] Iteration 21620, lr = 0.0002
I0530 12:56:01.793097 24924 solver.cpp:228] Iteration 21640, loss = 0.34382
I0530 12:56:01.793121 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 12:56:01.793129 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.176371 (* 1 = 0.176371 loss)
I0530 12:56:01.793134 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.176631 (* 1 = 0.176631 loss)
I0530 12:56:01.793138 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116785 (* 1 = 0.0116785 loss)
I0530 12:56:01.793141 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0501501 (* 1 = 0.0501501 loss)
I0530 12:56:01.793148 24924 sgd_solver.cpp:106] Iteration 21640, lr = 0.0002
I0530 12:56:53.595170 24924 solver.cpp:228] Iteration 21660, loss = 0.256666
I0530 12:56:53.595194 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 12:56:53.595202 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0710312 (* 1 = 0.0710312 loss)
I0530 12:56:53.595206 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0712763 (* 1 = 0.0712763 loss)
I0530 12:56:53.595211 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0050637 (* 1 = 0.0050637 loss)
I0530 12:56:53.595213 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00321593 (* 1 = 0.00321593 loss)
I0530 12:56:53.595217 24924 sgd_solver.cpp:106] Iteration 21660, lr = 0.0002
I0530 12:57:45.332382 24924 solver.cpp:228] Iteration 21680, loss = 0.340528
I0530 12:57:45.332407 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 12:57:45.332414 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0883013 (* 1 = 0.0883013 loss)
I0530 12:57:45.332418 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.220149 (* 1 = 0.220149 loss)
I0530 12:57:45.332422 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0234497 (* 1 = 0.0234497 loss)
I0530 12:57:45.332425 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0840527 (* 1 = 0.0840527 loss)
I0530 12:57:45.332430 24924 sgd_solver.cpp:106] Iteration 21680, lr = 0.0002
I0530 12:58:37.155464 24924 solver.cpp:228] Iteration 21700, loss = 0.229944
I0530 12:58:37.155494 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 12:58:37.155503 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000821883 (* 1 = 0.000821883 loss)
I0530 12:58:37.155509 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0996933 (* 1 = 0.0996933 loss)
I0530 12:58:37.155514 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0379532 (* 1 = 0.0379532 loss)
I0530 12:58:37.155517 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169969 (* 1 = 0.0169969 loss)
I0530 12:58:37.155524 24924 sgd_solver.cpp:106] Iteration 21700, lr = 0.0002
I0530 12:59:29.045552 24924 solver.cpp:228] Iteration 21720, loss = 0.300308
I0530 12:59:29.045577 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 12:59:29.045584 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.144925 (* 1 = 0.144925 loss)
I0530 12:59:29.045589 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.287675 (* 1 = 0.287675 loss)
I0530 12:59:29.045593 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106401 (* 1 = 0.0106401 loss)
I0530 12:59:29.045598 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0634504 (* 1 = 0.0634504 loss)
I0530 12:59:29.045603 24924 sgd_solver.cpp:106] Iteration 21720, lr = 0.0002
I0530 13:00:20.859853 24924 solver.cpp:228] Iteration 21740, loss = 0.269878
I0530 13:00:20.859881 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 13:00:20.859890 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.188401 (* 1 = 0.188401 loss)
I0530 13:00:20.859895 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.199242 (* 1 = 0.199242 loss)
I0530 13:00:20.859900 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00560777 (* 1 = 0.00560777 loss)
I0530 13:00:20.859905 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0253348 (* 1 = 0.0253348 loss)
I0530 13:00:20.859910 24924 sgd_solver.cpp:106] Iteration 21740, lr = 0.0002
I0530 13:01:12.710506 24924 solver.cpp:228] Iteration 21760, loss = 0.195887
I0530 13:01:12.710530 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:01:12.710537 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.137617 (* 1 = 0.137617 loss)
I0530 13:01:12.710541 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.154986 (* 1 = 0.154986 loss)
I0530 13:01:12.710544 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0035738 (* 1 = 0.0035738 loss)
I0530 13:01:12.710548 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122939 (* 1 = 0.0122939 loss)
I0530 13:01:12.710552 24924 sgd_solver.cpp:106] Iteration 21760, lr = 0.0002
I0530 13:02:04.527859 24924 solver.cpp:228] Iteration 21780, loss = 0.340575
I0530 13:02:04.527881 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 13:02:04.527889 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0142098 (* 1 = 0.0142098 loss)
I0530 13:02:04.527892 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.311267 (* 1 = 0.311267 loss)
I0530 13:02:04.527895 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213417 (* 1 = 0.0213417 loss)
I0530 13:02:04.527899 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00415815 (* 1 = 0.00415815 loss)
I0530 13:02:04.527904 24924 sgd_solver.cpp:106] Iteration 21780, lr = 0.0002
speed: 2.474s / iter
I0530 13:02:56.329255 24924 solver.cpp:228] Iteration 21800, loss = 0.29514
I0530 13:02:56.329277 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 13:02:56.329284 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.176466 (* 1 = 0.176466 loss)
I0530 13:02:56.329290 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.245878 (* 1 = 0.245878 loss)
I0530 13:02:56.329295 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00668208 (* 1 = 0.00668208 loss)
I0530 13:02:56.329300 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.041737 (* 1 = 0.041737 loss)
I0530 13:02:56.329308 24924 sgd_solver.cpp:106] Iteration 21800, lr = 0.0002
I0530 13:03:48.145761 24924 solver.cpp:228] Iteration 21820, loss = 0.320929
I0530 13:03:48.145783 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 13:03:48.145790 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0555494 (* 1 = 0.0555494 loss)
I0530 13:03:48.145793 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156824 (* 1 = 0.156824 loss)
I0530 13:03:48.145797 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00635334 (* 1 = 0.00635334 loss)
I0530 13:03:48.145800 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00900913 (* 1 = 0.00900913 loss)
I0530 13:03:48.145804 24924 sgd_solver.cpp:106] Iteration 21820, lr = 0.0002
I0530 13:04:39.993422 24924 solver.cpp:228] Iteration 21840, loss = 0.290533
I0530 13:04:39.993443 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.796875
I0530 13:04:39.993450 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.438314 (* 1 = 0.438314 loss)
I0530 13:04:39.993454 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.543327 (* 1 = 0.543327 loss)
I0530 13:04:39.993458 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.107177 (* 1 = 0.107177 loss)
I0530 13:04:39.993460 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.19598 (* 1 = 0.19598 loss)
I0530 13:04:39.993464 24924 sgd_solver.cpp:106] Iteration 21840, lr = 0.0002
I0530 13:05:31.865355 24924 solver.cpp:228] Iteration 21860, loss = 0.251377
I0530 13:05:31.865378 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 13:05:31.865386 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0953381 (* 1 = 0.0953381 loss)
I0530 13:05:31.865389 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.203144 (* 1 = 0.203144 loss)
I0530 13:05:31.865392 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.016127 (* 1 = 0.016127 loss)
I0530 13:05:31.865396 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0475493 (* 1 = 0.0475493 loss)
I0530 13:05:31.865401 24924 sgd_solver.cpp:106] Iteration 21860, lr = 0.0002
I0530 13:06:23.614063 24924 solver.cpp:228] Iteration 21880, loss = 0.318164
I0530 13:06:23.614087 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 13:06:23.614096 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0836971 (* 1 = 0.0836971 loss)
I0530 13:06:23.614104 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.197669 (* 1 = 0.197669 loss)
I0530 13:06:23.614109 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342597 (* 1 = 0.0342597 loss)
I0530 13:06:23.614114 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0457383 (* 1 = 0.0457383 loss)
I0530 13:06:23.614120 24924 sgd_solver.cpp:106] Iteration 21880, lr = 0.0002
I0530 13:07:15.441876 24924 solver.cpp:228] Iteration 21900, loss = 0.255902
I0530 13:07:15.441902 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 13:07:15.441912 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0703825 (* 1 = 0.0703825 loss)
I0530 13:07:15.441918 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.266343 (* 1 = 0.266343 loss)
I0530 13:07:15.441925 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0471378 (* 1 = 0.0471378 loss)
I0530 13:07:15.441929 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0466777 (* 1 = 0.0466777 loss)
I0530 13:07:15.441936 24924 sgd_solver.cpp:106] Iteration 21900, lr = 0.0002
I0530 13:08:07.314532 24924 solver.cpp:228] Iteration 21920, loss = 0.309133
I0530 13:08:07.314555 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 13:08:07.314563 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.177921 (* 1 = 0.177921 loss)
I0530 13:08:07.314566 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.20794 (* 1 = 0.20794 loss)
I0530 13:08:07.314569 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250986 (* 1 = 0.00250986 loss)
I0530 13:08:07.314574 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333276 (* 1 = 0.0333276 loss)
I0530 13:08:07.314577 24924 sgd_solver.cpp:106] Iteration 21920, lr = 0.0002
I0530 13:08:59.104460 24924 solver.cpp:228] Iteration 21940, loss = 0.33199
I0530 13:08:59.104485 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 13:08:59.104492 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0557571 (* 1 = 0.0557571 loss)
I0530 13:08:59.104496 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.153856 (* 1 = 0.153856 loss)
I0530 13:08:59.104499 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00860041 (* 1 = 0.00860041 loss)
I0530 13:08:59.104502 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145953 (* 1 = 0.0145953 loss)
I0530 13:08:59.104508 24924 sgd_solver.cpp:106] Iteration 21940, lr = 0.0002
I0530 13:09:50.942194 24924 solver.cpp:228] Iteration 21960, loss = 0.239595
I0530 13:09:50.942222 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 13:09:50.942230 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160767 (* 1 = 0.0160767 loss)
I0530 13:09:50.942234 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.051592 (* 1 = 0.051592 loss)
I0530 13:09:50.942237 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00305848 (* 1 = 0.00305848 loss)
I0530 13:09:50.942240 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00577092 (* 1 = 0.00577092 loss)
I0530 13:09:50.942245 24924 sgd_solver.cpp:106] Iteration 21960, lr = 0.0002
I0530 13:10:42.801666 24924 solver.cpp:228] Iteration 21980, loss = 0.213724
I0530 13:10:42.801690 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 13:10:42.801697 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.217914 (* 1 = 0.217914 loss)
I0530 13:10:42.801702 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.294355 (* 1 = 0.294355 loss)
I0530 13:10:42.801705 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0274756 (* 1 = 0.0274756 loss)
I0530 13:10:42.801708 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.058388 (* 1 = 0.058388 loss)
I0530 13:10:42.801713 24924 sgd_solver.cpp:106] Iteration 21980, lr = 0.0002
speed: 2.475s / iter
I0530 13:11:34.700160 24924 solver.cpp:228] Iteration 22000, loss = 0.180047
I0530 13:11:34.700186 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 13:11:34.700196 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0622438 (* 1 = 0.0622438 loss)
I0530 13:11:34.700203 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0847218 (* 1 = 0.0847218 loss)
I0530 13:11:34.700209 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218479 (* 1 = 0.00218479 loss)
I0530 13:11:34.700217 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00664114 (* 1 = 0.00664114 loss)
I0530 13:11:34.700224 24924 sgd_solver.cpp:106] Iteration 22000, lr = 0.0002
I0530 13:12:26.523859 24924 solver.cpp:228] Iteration 22020, loss = 0.329474
I0530 13:12:26.523882 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 13:12:26.523890 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.212969 (* 1 = 0.212969 loss)
I0530 13:12:26.523895 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.284761 (* 1 = 0.284761 loss)
I0530 13:12:26.523897 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0140943 (* 1 = 0.0140943 loss)
I0530 13:12:26.523901 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191648 (* 1 = 0.0191648 loss)
I0530 13:12:26.523906 24924 sgd_solver.cpp:106] Iteration 22020, lr = 0.0002
I0530 13:13:18.365145 24924 solver.cpp:228] Iteration 22040, loss = 0.233376
I0530 13:13:18.365170 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 13:13:18.365178 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349358 (* 1 = 0.0349358 loss)
I0530 13:13:18.365185 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0680204 (* 1 = 0.0680204 loss)
I0530 13:13:18.365188 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00710124 (* 1 = 0.00710124 loss)
I0530 13:13:18.365193 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00705675 (* 1 = 0.00705675 loss)
I0530 13:13:18.365200 24924 sgd_solver.cpp:106] Iteration 22040, lr = 0.0002
I0530 13:14:10.245726 24924 solver.cpp:228] Iteration 22060, loss = 0.354477
I0530 13:14:10.245753 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:14:10.245762 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191252 (* 1 = 0.0191252 loss)
I0530 13:14:10.245769 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0600965 (* 1 = 0.0600965 loss)
I0530 13:14:10.245775 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00208511 (* 1 = 0.00208511 loss)
I0530 13:14:10.245781 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0075644 (* 1 = 0.0075644 loss)
I0530 13:14:10.245790 24924 sgd_solver.cpp:106] Iteration 22060, lr = 0.0002
I0530 13:15:02.117489 24924 solver.cpp:228] Iteration 22080, loss = 0.280383
I0530 13:15:02.117516 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:15:02.117524 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0982636 (* 1 = 0.0982636 loss)
I0530 13:15:02.117528 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.128475 (* 1 = 0.128475 loss)
I0530 13:15:02.117532 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00233718 (* 1 = 0.00233718 loss)
I0530 13:15:02.117537 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0176864 (* 1 = 0.0176864 loss)
I0530 13:15:02.117542 24924 sgd_solver.cpp:106] Iteration 22080, lr = 0.0002
I0530 13:15:53.991235 24924 solver.cpp:228] Iteration 22100, loss = 0.440163
I0530 13:15:53.991256 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 13:15:53.991263 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0986947 (* 1 = 0.0986947 loss)
I0530 13:15:53.991267 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.271544 (* 1 = 0.271544 loss)
I0530 13:15:53.991271 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218918 (* 1 = 0.0218918 loss)
I0530 13:15:53.991274 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.046048 (* 1 = 0.046048 loss)
I0530 13:15:53.991278 24924 sgd_solver.cpp:106] Iteration 22100, lr = 0.0002
I0530 13:16:45.848917 24924 solver.cpp:228] Iteration 22120, loss = 0.316739
I0530 13:16:45.848942 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 13:16:45.848949 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.14904 (* 1 = 0.14904 loss)
I0530 13:16:45.848954 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.295857 (* 1 = 0.295857 loss)
I0530 13:16:45.848961 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00607305 (* 1 = 0.00607305 loss)
I0530 13:16:45.848966 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0264437 (* 1 = 0.0264437 loss)
I0530 13:16:45.848973 24924 sgd_solver.cpp:106] Iteration 22120, lr = 0.0002
I0530 13:17:37.682121 24924 solver.cpp:228] Iteration 22140, loss = 0.253246
I0530 13:17:37.682144 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 13:17:37.682150 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.03575 (* 1 = 0.03575 loss)
I0530 13:17:37.682154 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.108468 (* 1 = 0.108468 loss)
I0530 13:17:37.682157 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0239584 (* 1 = 0.0239584 loss)
I0530 13:17:37.682160 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0557212 (* 1 = 0.0557212 loss)
I0530 13:17:37.682164 24924 sgd_solver.cpp:106] Iteration 22140, lr = 0.0002
I0530 13:18:29.550482 24924 solver.cpp:228] Iteration 22160, loss = 0.287042
I0530 13:18:29.550508 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 13:18:29.550516 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.227722 (* 1 = 0.227722 loss)
I0530 13:18:29.550520 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139415 (* 1 = 0.139415 loss)
I0530 13:18:29.550524 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00969361 (* 1 = 0.00969361 loss)
I0530 13:18:29.550529 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0583583 (* 1 = 0.0583583 loss)
I0530 13:18:29.550534 24924 sgd_solver.cpp:106] Iteration 22160, lr = 0.0002
I0530 13:19:21.455799 24924 solver.cpp:228] Iteration 22180, loss = 0.292251
I0530 13:19:21.455829 24924 solver.cpp:244]     Train net output #0: accuarcy = 1
I0530 13:19:21.455837 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0192368 (* 1 = 0.0192368 loss)
I0530 13:19:21.455840 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0334144 (* 1 = 0.0334144 loss)
I0530 13:19:21.455844 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0029981 (* 1 = 0.0029981 loss)
I0530 13:19:21.455847 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00912904 (* 1 = 0.00912904 loss)
I0530 13:19:21.455853 24924 sgd_solver.cpp:106] Iteration 22180, lr = 0.0002
speed: 2.477s / iter
I0530 13:20:13.338079 24924 solver.cpp:228] Iteration 22200, loss = 0.245666
I0530 13:20:13.338106 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 13:20:13.338114 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0316323 (* 1 = 0.0316323 loss)
I0530 13:20:13.338119 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0263758 (* 1 = 0.0263758 loss)
I0530 13:20:13.338124 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00617442 (* 1 = 0.00617442 loss)
I0530 13:20:13.338127 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00664681 (* 1 = 0.00664681 loss)
I0530 13:20:13.338132 24924 sgd_solver.cpp:106] Iteration 22200, lr = 0.0002
I0530 13:21:05.242063 24924 solver.cpp:228] Iteration 22220, loss = 0.429027
I0530 13:21:05.242089 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:21:05.242097 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000562328 (* 1 = 0.000562328 loss)
I0530 13:21:05.242101 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0800832 (* 1 = 0.0800832 loss)
I0530 13:21:05.242106 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00993015 (* 1 = 0.00993015 loss)
I0530 13:21:05.242111 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0315172 (* 1 = 0.0315172 loss)
I0530 13:21:05.242116 24924 sgd_solver.cpp:106] Iteration 22220, lr = 0.0002
I0530 13:21:57.116432 24924 solver.cpp:228] Iteration 22240, loss = 0.285296
I0530 13:21:57.116456 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:21:57.116463 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00197543 (* 1 = 0.00197543 loss)
I0530 13:21:57.116467 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.195779 (* 1 = 0.195779 loss)
I0530 13:21:57.116470 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0562879 (* 1 = 0.0562879 loss)
I0530 13:21:57.116474 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.104906 (* 1 = 0.104906 loss)
I0530 13:21:57.116479 24924 sgd_solver.cpp:106] Iteration 22240, lr = 0.0002
I0530 13:22:48.998989 24924 solver.cpp:228] Iteration 22260, loss = 0.21761
I0530 13:22:48.999014 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 13:22:48.999022 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0937945 (* 1 = 0.0937945 loss)
I0530 13:22:48.999027 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.202475 (* 1 = 0.202475 loss)
I0530 13:22:48.999030 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212974 (* 1 = 0.0212974 loss)
I0530 13:22:48.999034 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0621133 (* 1 = 0.0621133 loss)
I0530 13:22:48.999039 24924 sgd_solver.cpp:106] Iteration 22260, lr = 0.0002
I0530 13:23:40.898272 24924 solver.cpp:228] Iteration 22280, loss = 0.208388
I0530 13:23:40.898298 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 13:23:40.898304 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0533115 (* 1 = 0.0533115 loss)
I0530 13:23:40.898308 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0761948 (* 1 = 0.0761948 loss)
I0530 13:23:40.898313 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00135573 (* 1 = 0.00135573 loss)
I0530 13:23:40.898315 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0184341 (* 1 = 0.0184341 loss)
I0530 13:23:40.898320 24924 sgd_solver.cpp:106] Iteration 22280, lr = 0.0002
I0530 13:24:32.814003 24924 solver.cpp:228] Iteration 22300, loss = 0.395572
I0530 13:24:32.814029 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 13:24:32.814038 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.154287 (* 1 = 0.154287 loss)
I0530 13:24:32.814041 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.305932 (* 1 = 0.305932 loss)
I0530 13:24:32.814045 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0363601 (* 1 = 0.0363601 loss)
I0530 13:24:32.814049 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.125619 (* 1 = 0.125619 loss)
I0530 13:24:32.814054 24924 sgd_solver.cpp:106] Iteration 22300, lr = 0.0002
I0530 13:25:24.723744 24924 solver.cpp:228] Iteration 22320, loss = 0.370798
I0530 13:25:24.723768 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 13:25:24.723776 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.11663 (* 1 = 0.11663 loss)
I0530 13:25:24.723780 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.292166 (* 1 = 0.292166 loss)
I0530 13:25:24.723783 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0169289 (* 1 = 0.0169289 loss)
I0530 13:25:24.723786 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0428806 (* 1 = 0.0428806 loss)
I0530 13:25:24.723791 24924 sgd_solver.cpp:106] Iteration 22320, lr = 0.0002
I0530 13:26:16.650888 24924 solver.cpp:228] Iteration 22340, loss = 0.305982
I0530 13:26:16.650918 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 13:26:16.650928 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0546101 (* 1 = 0.0546101 loss)
I0530 13:26:16.650933 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.149778 (* 1 = 0.149778 loss)
I0530 13:26:16.650938 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00828108 (* 1 = 0.00828108 loss)
I0530 13:26:16.650941 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0523088 (* 1 = 0.0523088 loss)
I0530 13:26:16.650948 24924 sgd_solver.cpp:106] Iteration 22340, lr = 0.0002
I0530 13:27:08.567369 24924 solver.cpp:228] Iteration 22360, loss = 0.41082
I0530 13:27:08.567399 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 13:27:08.567407 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.463478 (* 1 = 0.463478 loss)
I0530 13:27:08.567412 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.544273 (* 1 = 0.544273 loss)
I0530 13:27:08.567416 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0597673 (* 1 = 0.0597673 loss)
I0530 13:27:08.567421 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.119142 (* 1 = 0.119142 loss)
I0530 13:27:08.567427 24924 sgd_solver.cpp:106] Iteration 22360, lr = 0.0002
I0530 13:28:00.473568 24924 solver.cpp:228] Iteration 22380, loss = 0.286329
I0530 13:28:00.473593 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 13:28:00.473601 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0814818 (* 1 = 0.0814818 loss)
I0530 13:28:00.473605 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109579 (* 1 = 0.109579 loss)
I0530 13:28:00.473609 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01576 (* 1 = 0.01576 loss)
I0530 13:28:00.473613 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242848 (* 1 = 0.0242848 loss)
I0530 13:28:00.473618 24924 sgd_solver.cpp:106] Iteration 22380, lr = 0.0002
speed: 2.478s / iter
I0530 13:28:52.356262 24924 solver.cpp:228] Iteration 22400, loss = 0.38796
I0530 13:28:52.356286 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.71875
I0530 13:28:52.356292 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.388111 (* 1 = 0.388111 loss)
I0530 13:28:52.356297 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.549073 (* 1 = 0.549073 loss)
I0530 13:28:52.356299 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0642982 (* 1 = 0.0642982 loss)
I0530 13:28:52.356303 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.276048 (* 1 = 0.276048 loss)
I0530 13:28:52.356308 24924 sgd_solver.cpp:106] Iteration 22400, lr = 0.0002
I0530 13:29:44.209017 24924 solver.cpp:228] Iteration 22420, loss = 0.266258
I0530 13:29:44.209043 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 13:29:44.209050 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0599727 (* 1 = 0.0599727 loss)
I0530 13:29:44.209055 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0314377 (* 1 = 0.0314377 loss)
I0530 13:29:44.209059 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00736545 (* 1 = 0.00736545 loss)
I0530 13:29:44.209064 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163618 (* 1 = 0.0163618 loss)
I0530 13:29:44.209067 24924 sgd_solver.cpp:106] Iteration 22420, lr = 0.0002
I0530 13:30:35.797376 24924 solver.cpp:228] Iteration 22440, loss = 0.350081
I0530 13:30:35.797407 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 13:30:35.797417 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0698184 (* 1 = 0.0698184 loss)
I0530 13:30:35.797425 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.228828 (* 1 = 0.228828 loss)
I0530 13:30:35.797430 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0093172 (* 1 = 0.0093172 loss)
I0530 13:30:35.797436 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019589 (* 1 = 0.019589 loss)
I0530 13:30:35.797444 24924 sgd_solver.cpp:106] Iteration 22440, lr = 0.0002
I0530 13:31:27.729863 24924 solver.cpp:228] Iteration 22460, loss = 0.396487
I0530 13:31:27.729888 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 13:31:27.729897 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102337 (* 1 = 0.102337 loss)
I0530 13:31:27.729904 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0881269 (* 1 = 0.0881269 loss)
I0530 13:31:27.729909 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0037114 (* 1 = 0.0037114 loss)
I0530 13:31:27.729915 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0153982 (* 1 = 0.0153982 loss)
I0530 13:31:27.729921 24924 sgd_solver.cpp:106] Iteration 22460, lr = 0.0002
I0530 13:32:19.633946 24924 solver.cpp:228] Iteration 22480, loss = 0.553823
I0530 13:32:19.633970 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 13:32:19.633978 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.106371 (* 1 = 0.106371 loss)
I0530 13:32:19.633983 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.312772 (* 1 = 0.312772 loss)
I0530 13:32:19.633987 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0477956 (* 1 = 0.0477956 loss)
I0530 13:32:19.633991 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430025 (* 1 = 0.0430025 loss)
I0530 13:32:19.633996 24924 sgd_solver.cpp:106] Iteration 22480, lr = 0.0002
I0530 13:33:11.534636 24924 solver.cpp:228] Iteration 22500, loss = 0.214296
I0530 13:33:11.534662 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 13:33:11.534672 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00023222 (* 1 = 0.00023222 loss)
I0530 13:33:11.534677 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0391622 (* 1 = 0.0391622 loss)
I0530 13:33:11.534683 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082919 (* 1 = 0.0082919 loss)
I0530 13:33:11.534688 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.020441 (* 1 = 0.020441 loss)
I0530 13:33:11.534694 24924 sgd_solver.cpp:106] Iteration 22500, lr = 0.0002
I0530 13:34:03.396760 24924 solver.cpp:228] Iteration 22520, loss = 0.18909
I0530 13:34:03.396787 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 13:34:03.396795 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0225045 (* 1 = 0.0225045 loss)
I0530 13:34:03.396800 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104684 (* 1 = 0.104684 loss)
I0530 13:34:03.396805 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00654268 (* 1 = 0.00654268 loss)
I0530 13:34:03.396808 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01291 (* 1 = 0.01291 loss)
I0530 13:34:03.396813 24924 sgd_solver.cpp:106] Iteration 22520, lr = 0.0002
I0530 13:34:55.308884 24924 solver.cpp:228] Iteration 22540, loss = 0.200948
I0530 13:34:55.308914 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:34:55.308923 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.013866 (* 1 = 0.013866 loss)
I0530 13:34:55.308926 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0486068 (* 1 = 0.0486068 loss)
I0530 13:34:55.308930 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00609853 (* 1 = 0.00609853 loss)
I0530 13:34:55.308933 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108948 (* 1 = 0.0108948 loss)
I0530 13:34:55.308938 24924 sgd_solver.cpp:106] Iteration 22540, lr = 0.0002
I0530 13:35:47.217393 24924 solver.cpp:228] Iteration 22560, loss = 0.1887
I0530 13:35:47.217417 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 13:35:47.217427 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.140233 (* 1 = 0.140233 loss)
I0530 13:35:47.217432 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.222806 (* 1 = 0.222806 loss)
I0530 13:35:47.217437 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0281395 (* 1 = 0.0281395 loss)
I0530 13:35:47.217443 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291106 (* 1 = 0.0291106 loss)
I0530 13:35:47.217449 24924 sgd_solver.cpp:106] Iteration 22560, lr = 0.0002
I0530 13:36:39.091270 24924 solver.cpp:228] Iteration 22580, loss = 0.309239
I0530 13:36:39.091297 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 13:36:39.091307 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.159616 (* 1 = 0.159616 loss)
I0530 13:36:39.091315 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.220039 (* 1 = 0.220039 loss)
I0530 13:36:39.091320 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.027126 (* 1 = 0.027126 loss)
I0530 13:36:39.091326 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0508081 (* 1 = 0.0508081 loss)
I0530 13:36:39.091332 24924 sgd_solver.cpp:106] Iteration 22580, lr = 0.0002
speed: 2.479s / iter
I0530 13:37:30.980294 24924 solver.cpp:228] Iteration 22600, loss = 0.514625
I0530 13:37:30.980317 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 13:37:30.980324 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0349072 (* 1 = 0.0349072 loss)
I0530 13:37:30.980329 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127824 (* 1 = 0.127824 loss)
I0530 13:37:30.980332 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0313018 (* 1 = 0.0313018 loss)
I0530 13:37:30.980335 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0155253 (* 1 = 0.0155253 loss)
I0530 13:37:30.980340 24924 sgd_solver.cpp:106] Iteration 22600, lr = 0.0002
I0530 13:38:22.870239 24924 solver.cpp:228] Iteration 22620, loss = 0.263876
I0530 13:38:22.870263 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:38:22.870270 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333331 (* 1 = 0.0333331 loss)
I0530 13:38:22.870275 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0535455 (* 1 = 0.0535455 loss)
I0530 13:38:22.870280 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00286491 (* 1 = 0.00286491 loss)
I0530 13:38:22.870283 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00403199 (* 1 = 0.00403199 loss)
I0530 13:38:22.870288 24924 sgd_solver.cpp:106] Iteration 22620, lr = 0.0002
I0530 13:39:14.759464 24924 solver.cpp:228] Iteration 22640, loss = 0.597173
I0530 13:39:14.759490 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.515625
I0530 13:39:14.759500 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.995057 (* 1 = 0.995057 loss)
I0530 13:39:14.759506 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.785703 (* 1 = 0.785703 loss)
I0530 13:39:14.759512 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.145372 (* 1 = 0.145372 loss)
I0530 13:39:14.759518 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.489265 (* 1 = 0.489265 loss)
I0530 13:39:14.759526 24924 sgd_solver.cpp:106] Iteration 22640, lr = 0.0002
I0530 13:40:06.624291 24924 solver.cpp:228] Iteration 22660, loss = 0.193712
I0530 13:40:06.624316 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 13:40:06.624323 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0436986 (* 1 = 0.0436986 loss)
I0530 13:40:06.624328 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.068264 (* 1 = 0.068264 loss)
I0530 13:40:06.624331 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181015 (* 1 = 0.0181015 loss)
I0530 13:40:06.624336 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00842565 (* 1 = 0.00842565 loss)
I0530 13:40:06.624341 24924 sgd_solver.cpp:106] Iteration 22660, lr = 0.0002
I0530 13:40:58.500634 24924 solver.cpp:228] Iteration 22680, loss = 0.205487
I0530 13:40:58.500658 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 13:40:58.500664 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.120678 (* 1 = 0.120678 loss)
I0530 13:40:58.500668 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.204975 (* 1 = 0.204975 loss)
I0530 13:40:58.500671 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174814 (* 1 = 0.0174814 loss)
I0530 13:40:58.500674 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258298 (* 1 = 0.0258298 loss)
I0530 13:40:58.500679 24924 sgd_solver.cpp:106] Iteration 22680, lr = 0.0002
I0530 13:41:50.434489 24924 solver.cpp:228] Iteration 22700, loss = 0.189239
I0530 13:41:50.434521 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:41:50.434530 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0686066 (* 1 = 0.0686066 loss)
I0530 13:41:50.434535 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102848 (* 1 = 0.102848 loss)
I0530 13:41:50.434538 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00479807 (* 1 = 0.00479807 loss)
I0530 13:41:50.434542 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570242 (* 1 = 0.00570242 loss)
I0530 13:41:50.434548 24924 sgd_solver.cpp:106] Iteration 22700, lr = 0.0002
I0530 13:42:42.314508 24924 solver.cpp:228] Iteration 22720, loss = 0.228608
I0530 13:42:42.314533 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 13:42:42.314541 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0630459 (* 1 = 0.0630459 loss)
I0530 13:42:42.314545 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.166781 (* 1 = 0.166781 loss)
I0530 13:42:42.314548 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183276 (* 1 = 0.00183276 loss)
I0530 13:42:42.314553 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00529388 (* 1 = 0.00529388 loss)
I0530 13:42:42.314558 24924 sgd_solver.cpp:106] Iteration 22720, lr = 0.0002
I0530 13:43:34.158499 24924 solver.cpp:228] Iteration 22740, loss = 0.326192
I0530 13:43:34.158521 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 13:43:34.158529 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.265312 (* 1 = 0.265312 loss)
I0530 13:43:34.158531 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.388633 (* 1 = 0.388633 loss)
I0530 13:43:34.158535 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0387956 (* 1 = 0.0387956 loss)
I0530 13:43:34.158538 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0751972 (* 1 = 0.0751972 loss)
I0530 13:43:34.158542 24924 sgd_solver.cpp:106] Iteration 22740, lr = 0.0002
I0530 13:44:26.032021 24924 solver.cpp:228] Iteration 22760, loss = 0.211869
I0530 13:44:26.032045 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 13:44:26.032053 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.108562 (* 1 = 0.108562 loss)
I0530 13:44:26.032058 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.249964 (* 1 = 0.249964 loss)
I0530 13:44:26.032063 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161174 (* 1 = 0.0161174 loss)
I0530 13:44:26.032065 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0838378 (* 1 = 0.0838378 loss)
I0530 13:44:26.032070 24924 sgd_solver.cpp:106] Iteration 22760, lr = 0.0002
I0530 13:45:17.880841 24924 solver.cpp:228] Iteration 22780, loss = 0.240414
I0530 13:45:17.880867 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:45:17.880874 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0900182 (* 1 = 0.0900182 loss)
I0530 13:45:17.880879 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134914 (* 1 = 0.134914 loss)
I0530 13:45:17.880882 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00762021 (* 1 = 0.00762021 loss)
I0530 13:45:17.880887 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306451 (* 1 = 0.0306451 loss)
I0530 13:45:17.880892 24924 sgd_solver.cpp:106] Iteration 22780, lr = 0.0002
speed: 2.480s / iter
I0530 13:46:09.715662 24924 solver.cpp:228] Iteration 22800, loss = 0.251646
I0530 13:46:09.715692 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:46:09.715700 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00281152 (* 1 = 0.00281152 loss)
I0530 13:46:09.715703 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0686036 (* 1 = 0.0686036 loss)
I0530 13:46:09.715706 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.038356 (* 1 = 0.038356 loss)
I0530 13:46:09.715709 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.111515 (* 1 = 0.111515 loss)
I0530 13:46:09.715714 24924 sgd_solver.cpp:106] Iteration 22800, lr = 0.0002
I0530 13:47:01.593971 24924 solver.cpp:228] Iteration 22820, loss = 0.233887
I0530 13:47:01.593997 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 13:47:01.594004 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.290743 (* 1 = 0.290743 loss)
I0530 13:47:01.594009 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.509153 (* 1 = 0.509153 loss)
I0530 13:47:01.594013 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260277 (* 1 = 0.0260277 loss)
I0530 13:47:01.594017 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0341897 (* 1 = 0.0341897 loss)
I0530 13:47:01.594022 24924 sgd_solver.cpp:106] Iteration 22820, lr = 0.0002
I0530 13:47:53.447229 24924 solver.cpp:228] Iteration 22840, loss = 0.292367
I0530 13:47:53.447255 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 13:47:53.447265 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0616858 (* 1 = 0.0616858 loss)
I0530 13:47:53.447271 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0749763 (* 1 = 0.0749763 loss)
I0530 13:47:53.447278 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00611565 (* 1 = 0.00611565 loss)
I0530 13:47:53.447283 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00728745 (* 1 = 0.00728745 loss)
I0530 13:47:53.447288 24924 sgd_solver.cpp:106] Iteration 22840, lr = 0.0002
I0530 13:48:45.272152 24924 solver.cpp:228] Iteration 22860, loss = 0.272222
I0530 13:48:45.272177 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 13:48:45.272184 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0903781 (* 1 = 0.0903781 loss)
I0530 13:48:45.272188 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102279 (* 1 = 0.102279 loss)
I0530 13:48:45.272193 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00495122 (* 1 = 0.00495122 loss)
I0530 13:48:45.272198 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0172138 (* 1 = 0.0172138 loss)
I0530 13:48:45.272203 24924 sgd_solver.cpp:106] Iteration 22860, lr = 0.0002
I0530 13:49:37.150418 24924 solver.cpp:228] Iteration 22880, loss = 0.497176
I0530 13:49:37.150444 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 13:49:37.150452 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109204 (* 1 = 0.109204 loss)
I0530 13:49:37.150456 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.252582 (* 1 = 0.252582 loss)
I0530 13:49:37.150460 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0041521 (* 1 = 0.0041521 loss)
I0530 13:49:37.150465 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123923 (* 1 = 0.0123923 loss)
I0530 13:49:37.150470 24924 sgd_solver.cpp:106] Iteration 22880, lr = 0.0002
I0530 13:50:29.022663 24924 solver.cpp:228] Iteration 22900, loss = 0.37417
I0530 13:50:29.022691 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 13:50:29.022699 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.190048 (* 1 = 0.190048 loss)
I0530 13:50:29.022703 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.248938 (* 1 = 0.248938 loss)
I0530 13:50:29.022707 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0031361 (* 1 = 0.0031361 loss)
I0530 13:50:29.022711 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0470732 (* 1 = 0.0470732 loss)
I0530 13:50:29.022716 24924 sgd_solver.cpp:106] Iteration 22900, lr = 0.0002
I0530 13:51:20.832651 24924 solver.cpp:228] Iteration 22920, loss = 0.258676
I0530 13:51:20.832677 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:51:20.832684 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.075984 (* 1 = 0.075984 loss)
I0530 13:51:20.832689 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.137741 (* 1 = 0.137741 loss)
I0530 13:51:20.832692 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129721 (* 1 = 0.0129721 loss)
I0530 13:51:20.832695 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197158 (* 1 = 0.0197158 loss)
I0530 13:51:20.832700 24924 sgd_solver.cpp:106] Iteration 22920, lr = 0.0002
I0530 13:52:12.690536 24924 solver.cpp:228] Iteration 22940, loss = 0.238626
I0530 13:52:12.690562 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 13:52:12.690569 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000130763 (* 1 = 0.000130763 loss)
I0530 13:52:12.690573 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0333048 (* 1 = 0.0333048 loss)
I0530 13:52:12.690577 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00588039 (* 1 = 0.00588039 loss)
I0530 13:52:12.690582 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207045 (* 1 = 0.0207045 loss)
I0530 13:52:12.690587 24924 sgd_solver.cpp:106] Iteration 22940, lr = 0.0002
I0530 13:53:04.541838 24924 solver.cpp:228] Iteration 22960, loss = 0.292992
I0530 13:53:04.541862 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:53:04.541870 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00892045 (* 1 = 0.00892045 loss)
I0530 13:53:04.541875 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0467325 (* 1 = 0.0467325 loss)
I0530 13:53:04.541880 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0649415 (* 1 = 0.0649415 loss)
I0530 13:53:04.541885 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369447 (* 1 = 0.0369447 loss)
I0530 13:53:04.541891 24924 sgd_solver.cpp:106] Iteration 22960, lr = 0.0002
I0530 13:53:56.395349 24924 solver.cpp:228] Iteration 22980, loss = 0.316194
I0530 13:53:56.395372 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 13:53:56.395380 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.101093 (* 1 = 0.101093 loss)
I0530 13:53:56.395383 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.370537 (* 1 = 0.370537 loss)
I0530 13:53:56.395386 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00996987 (* 1 = 0.00996987 loss)
I0530 13:53:56.395390 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0282417 (* 1 = 0.0282417 loss)
I0530 13:53:56.395395 24924 sgd_solver.cpp:106] Iteration 22980, lr = 0.0002
speed: 2.481s / iter
I0530 13:54:48.240089 24924 solver.cpp:228] Iteration 23000, loss = 0.240692
I0530 13:54:48.240114 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 13:54:48.240123 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0608073 (* 1 = 0.0608073 loss)
I0530 13:54:48.240129 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0594418 (* 1 = 0.0594418 loss)
I0530 13:54:48.240135 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00915776 (* 1 = 0.00915776 loss)
I0530 13:54:48.240140 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0114251 (* 1 = 0.0114251 loss)
I0530 13:54:48.240149 24924 sgd_solver.cpp:106] Iteration 23000, lr = 0.0002
I0530 13:55:40.071064 24924 solver.cpp:228] Iteration 23020, loss = 0.283598
I0530 13:55:40.071090 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 13:55:40.071097 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0600697 (* 1 = 0.0600697 loss)
I0530 13:55:40.071101 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124798 (* 1 = 0.124798 loss)
I0530 13:55:40.071105 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.022477 (* 1 = 0.022477 loss)
I0530 13:55:40.071108 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0627447 (* 1 = 0.0627447 loss)
I0530 13:55:40.071112 24924 sgd_solver.cpp:106] Iteration 23020, lr = 0.0002
I0530 13:56:31.973747 24924 solver.cpp:228] Iteration 23040, loss = 0.278604
I0530 13:56:31.973770 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 13:56:31.973778 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.260775 (* 1 = 0.260775 loss)
I0530 13:56:31.973781 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.250354 (* 1 = 0.250354 loss)
I0530 13:56:31.973785 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142393 (* 1 = 0.0142393 loss)
I0530 13:56:31.973788 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525708 (* 1 = 0.0525708 loss)
I0530 13:56:31.973793 24924 sgd_solver.cpp:106] Iteration 23040, lr = 0.0002
I0530 13:57:23.858671 24924 solver.cpp:228] Iteration 23060, loss = 0.157299
I0530 13:57:23.858695 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 13:57:23.858705 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0262471 (* 1 = 0.0262471 loss)
I0530 13:57:23.858711 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0910882 (* 1 = 0.0910882 loss)
I0530 13:57:23.858716 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00903432 (* 1 = 0.00903432 loss)
I0530 13:57:23.858721 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110067 (* 1 = 0.0110067 loss)
I0530 13:57:23.858727 24924 sgd_solver.cpp:106] Iteration 23060, lr = 0.0002
I0530 13:58:15.596462 24924 solver.cpp:228] Iteration 23080, loss = 0.328874
I0530 13:58:15.596484 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 13:58:15.596491 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.162843 (* 1 = 0.162843 loss)
I0530 13:58:15.596495 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.213503 (* 1 = 0.213503 loss)
I0530 13:58:15.596498 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00314427 (* 1 = 0.00314427 loss)
I0530 13:58:15.596503 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0200104 (* 1 = 0.0200104 loss)
I0530 13:58:15.596508 24924 sgd_solver.cpp:106] Iteration 23080, lr = 0.0002
I0530 13:59:07.448314 24924 solver.cpp:228] Iteration 23100, loss = 0.276067
I0530 13:59:07.448338 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 13:59:07.448348 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.213931 (* 1 = 0.213931 loss)
I0530 13:59:07.448354 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.358804 (* 1 = 0.358804 loss)
I0530 13:59:07.448359 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00466376 (* 1 = 0.00466376 loss)
I0530 13:59:07.448365 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.049085 (* 1 = 0.049085 loss)
I0530 13:59:07.448371 24924 sgd_solver.cpp:106] Iteration 23100, lr = 0.0002
I0530 13:59:59.354341 24924 solver.cpp:228] Iteration 23120, loss = 0.268671
I0530 13:59:59.354370 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 13:59:59.354380 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00988305 (* 1 = 0.00988305 loss)
I0530 13:59:59.354384 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0395814 (* 1 = 0.0395814 loss)
I0530 13:59:59.354388 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00221442 (* 1 = 0.00221442 loss)
I0530 13:59:59.354393 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160252 (* 1 = 0.0160252 loss)
I0530 13:59:59.354398 24924 sgd_solver.cpp:106] Iteration 23120, lr = 0.0002
I0530 14:00:51.242218 24924 solver.cpp:228] Iteration 23140, loss = 0.129242
I0530 14:00:51.242254 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:00:51.242265 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0637384 (* 1 = 0.0637384 loss)
I0530 14:00:51.242272 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0416787 (* 1 = 0.0416787 loss)
I0530 14:00:51.242278 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000737372 (* 1 = 0.000737372 loss)
I0530 14:00:51.242285 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00188236 (* 1 = 0.00188236 loss)
I0530 14:00:51.242291 24924 sgd_solver.cpp:106] Iteration 23140, lr = 0.0002
I0530 14:01:43.066124 24924 solver.cpp:228] Iteration 23160, loss = 0.402964
I0530 14:01:43.066148 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:01:43.066154 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0896955 (* 1 = 0.0896955 loss)
I0530 14:01:43.066159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.222577 (* 1 = 0.222577 loss)
I0530 14:01:43.066161 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00874783 (* 1 = 0.00874783 loss)
I0530 14:01:43.066164 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0453247 (* 1 = 0.0453247 loss)
I0530 14:01:43.066169 24924 sgd_solver.cpp:106] Iteration 23160, lr = 0.0002
I0530 14:02:34.933650 24924 solver.cpp:228] Iteration 23180, loss = 0.26729
I0530 14:02:34.933670 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 14:02:34.933676 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231851 (* 1 = 0.0231851 loss)
I0530 14:02:34.933681 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0327366 (* 1 = 0.0327366 loss)
I0530 14:02:34.933683 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0107477 (* 1 = 0.0107477 loss)
I0530 14:02:34.933686 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00942538 (* 1 = 0.00942538 loss)
I0530 14:02:34.933691 24924 sgd_solver.cpp:106] Iteration 23180, lr = 0.0002
speed: 2.482s / iter
I0530 14:03:26.760745 24924 solver.cpp:228] Iteration 23200, loss = 0.299034
I0530 14:03:26.760769 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.75
I0530 14:03:26.760777 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.266317 (* 1 = 0.266317 loss)
I0530 14:03:26.760782 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.417776 (* 1 = 0.417776 loss)
I0530 14:03:26.760785 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0278964 (* 1 = 0.0278964 loss)
I0530 14:03:26.760789 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.157455 (* 1 = 0.157455 loss)
I0530 14:03:26.760794 24924 sgd_solver.cpp:106] Iteration 23200, lr = 0.0002
I0530 14:04:18.614092 24924 solver.cpp:228] Iteration 23220, loss = 0.351503
I0530 14:04:18.614116 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 14:04:18.614123 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.116374 (* 1 = 0.116374 loss)
I0530 14:04:18.614127 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.220726 (* 1 = 0.220726 loss)
I0530 14:04:18.614131 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00507646 (* 1 = 0.00507646 loss)
I0530 14:04:18.614135 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195745 (* 1 = 0.0195745 loss)
I0530 14:04:18.614140 24924 sgd_solver.cpp:106] Iteration 23220, lr = 0.0002
I0530 14:05:10.494737 24924 solver.cpp:228] Iteration 23240, loss = 0.282888
I0530 14:05:10.494760 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:05:10.494767 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0275107 (* 1 = 0.0275107 loss)
I0530 14:05:10.494771 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0553568 (* 1 = 0.0553568 loss)
I0530 14:05:10.494776 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141553 (* 1 = 0.00141553 loss)
I0530 14:05:10.494779 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00789423 (* 1 = 0.00789423 loss)
I0530 14:05:10.494784 24924 sgd_solver.cpp:106] Iteration 23240, lr = 0.0002
I0530 14:06:02.360520 24924 solver.cpp:228] Iteration 23260, loss = 0.251613
I0530 14:06:02.360546 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 14:06:02.360558 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0994677 (* 1 = 0.0994677 loss)
I0530 14:06:02.360564 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.217962 (* 1 = 0.217962 loss)
I0530 14:06:02.360570 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00407461 (* 1 = 0.00407461 loss)
I0530 14:06:02.360576 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0185307 (* 1 = 0.0185307 loss)
I0530 14:06:02.360584 24924 sgd_solver.cpp:106] Iteration 23260, lr = 0.0002
I0530 14:06:54.233145 24924 solver.cpp:228] Iteration 23280, loss = 0.352544
I0530 14:06:54.233168 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 14:06:54.233175 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0371162 (* 1 = 0.0371162 loss)
I0530 14:06:54.233180 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0669437 (* 1 = 0.0669437 loss)
I0530 14:06:54.233182 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.017895 (* 1 = 0.017895 loss)
I0530 14:06:54.233186 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01896 (* 1 = 0.01896 loss)
I0530 14:06:54.233191 24924 sgd_solver.cpp:106] Iteration 23280, lr = 0.0002
I0530 14:07:46.172097 24924 solver.cpp:228] Iteration 23300, loss = 0.308922
I0530 14:07:46.172122 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:07:46.172128 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0421625 (* 1 = 0.0421625 loss)
I0530 14:07:46.172132 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0806661 (* 1 = 0.0806661 loss)
I0530 14:07:46.172135 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0393621 (* 1 = 0.0393621 loss)
I0530 14:07:46.172139 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0215962 (* 1 = 0.0215962 loss)
I0530 14:07:46.172143 24924 sgd_solver.cpp:106] Iteration 23300, lr = 0.0002
I0530 14:08:38.011584 24924 solver.cpp:228] Iteration 23320, loss = 0.273189
I0530 14:08:38.011608 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 14:08:38.011615 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.191613 (* 1 = 0.191613 loss)
I0530 14:08:38.011620 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.300549 (* 1 = 0.300549 loss)
I0530 14:08:38.011623 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0160739 (* 1 = 0.0160739 loss)
I0530 14:08:38.011626 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0435087 (* 1 = 0.0435087 loss)
I0530 14:08:38.011631 24924 sgd_solver.cpp:106] Iteration 23320, lr = 0.0002
I0530 14:09:29.914932 24924 solver.cpp:228] Iteration 23340, loss = 0.292065
I0530 14:09:29.914958 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:09:29.914968 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297276 (* 1 = 0.0297276 loss)
I0530 14:09:29.914974 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0713907 (* 1 = 0.0713907 loss)
I0530 14:09:29.914979 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00287806 (* 1 = 0.00287806 loss)
I0530 14:09:29.914984 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198399 (* 1 = 0.0198399 loss)
I0530 14:09:29.914991 24924 sgd_solver.cpp:106] Iteration 23340, lr = 0.0002
I0530 14:10:21.825042 24924 solver.cpp:228] Iteration 23360, loss = 0.251063
I0530 14:10:21.825067 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:10:21.825075 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0083273 (* 1 = 0.0083273 loss)
I0530 14:10:21.825079 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0842967 (* 1 = 0.0842967 loss)
I0530 14:10:21.825083 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00377347 (* 1 = 0.00377347 loss)
I0530 14:10:21.825088 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00400726 (* 1 = 0.00400726 loss)
I0530 14:10:21.825093 24924 sgd_solver.cpp:106] Iteration 23360, lr = 0.0002
I0530 14:11:13.763062 24924 solver.cpp:228] Iteration 23380, loss = 0.421219
I0530 14:11:13.763085 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:11:13.763092 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147981 (* 1 = 0.0147981 loss)
I0530 14:11:13.763097 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0696985 (* 1 = 0.0696985 loss)
I0530 14:11:13.763100 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0181128 (* 1 = 0.0181128 loss)
I0530 14:11:13.763103 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197042 (* 1 = 0.0197042 loss)
I0530 14:11:13.763108 24924 sgd_solver.cpp:106] Iteration 23380, lr = 0.0002
speed: 2.483s / iter
I0530 14:12:05.671209 24924 solver.cpp:228] Iteration 23400, loss = 0.47611
I0530 14:12:05.671236 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 14:12:05.671243 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.018269 (* 1 = 0.018269 loss)
I0530 14:12:05.671247 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0605028 (* 1 = 0.0605028 loss)
I0530 14:12:05.671252 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00162567 (* 1 = 0.00162567 loss)
I0530 14:12:05.671255 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00244047 (* 1 = 0.00244047 loss)
I0530 14:12:05.671262 24924 sgd_solver.cpp:106] Iteration 23400, lr = 0.0002
I0530 14:12:57.543105 24924 solver.cpp:228] Iteration 23420, loss = 0.291226
I0530 14:12:57.543129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:12:57.543136 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0720511 (* 1 = 0.0720511 loss)
I0530 14:12:57.543139 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0994598 (* 1 = 0.0994598 loss)
I0530 14:12:57.543144 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00442754 (* 1 = 0.00442754 loss)
I0530 14:12:57.543150 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338101 (* 1 = 0.0338101 loss)
I0530 14:12:57.543154 24924 sgd_solver.cpp:106] Iteration 23420, lr = 0.0002
I0530 14:13:49.429708 24924 solver.cpp:228] Iteration 23440, loss = 0.244147
I0530 14:13:49.429733 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 14:13:49.429742 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0383794 (* 1 = 0.0383794 loss)
I0530 14:13:49.429746 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.061393 (* 1 = 0.061393 loss)
I0530 14:13:49.429750 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00931653 (* 1 = 0.00931653 loss)
I0530 14:13:49.429754 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0433152 (* 1 = 0.0433152 loss)
I0530 14:13:49.429759 24924 sgd_solver.cpp:106] Iteration 23440, lr = 0.0002
I0530 14:14:41.330708 24924 solver.cpp:228] Iteration 23460, loss = 0.245621
I0530 14:14:41.330731 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:14:41.330740 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392001 (* 1 = 0.0392001 loss)
I0530 14:14:41.330746 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0809009 (* 1 = 0.0809009 loss)
I0530 14:14:41.330751 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0101257 (* 1 = 0.0101257 loss)
I0530 14:14:41.330756 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00292376 (* 1 = 0.00292376 loss)
I0530 14:14:41.330762 24924 sgd_solver.cpp:106] Iteration 23460, lr = 0.0002
I0530 14:15:33.210829 24924 solver.cpp:228] Iteration 23480, loss = 0.556084
I0530 14:15:33.210855 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 14:15:33.210862 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.179187 (* 1 = 0.179187 loss)
I0530 14:15:33.210866 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.233016 (* 1 = 0.233016 loss)
I0530 14:15:33.210871 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104682 (* 1 = 0.0104682 loss)
I0530 14:15:33.210875 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0449734 (* 1 = 0.0449734 loss)
I0530 14:15:33.210880 24924 sgd_solver.cpp:106] Iteration 23480, lr = 0.0002
I0530 14:16:25.119972 24924 solver.cpp:228] Iteration 23500, loss = 0.340982
I0530 14:16:25.119997 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:16:25.120005 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509284 (* 1 = 0.0509284 loss)
I0530 14:16:25.120012 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0801479 (* 1 = 0.0801479 loss)
I0530 14:16:25.120018 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00159701 (* 1 = 0.00159701 loss)
I0530 14:16:25.120023 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00266711 (* 1 = 0.00266711 loss)
I0530 14:16:25.120029 24924 sgd_solver.cpp:106] Iteration 23500, lr = 0.0002
I0530 14:17:17.001222 24924 solver.cpp:228] Iteration 23520, loss = 0.255825
I0530 14:17:17.001251 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 14:17:17.001260 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0197374 (* 1 = 0.0197374 loss)
I0530 14:17:17.001265 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.06645 (* 1 = 0.06645 loss)
I0530 14:17:17.001268 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00477142 (* 1 = 0.00477142 loss)
I0530 14:17:17.001272 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00428067 (* 1 = 0.00428067 loss)
I0530 14:17:17.001278 24924 sgd_solver.cpp:106] Iteration 23520, lr = 0.0002
I0530 14:18:08.854825 24924 solver.cpp:228] Iteration 23540, loss = 0.20339
I0530 14:18:08.854851 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 14:18:08.854861 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.301996 (* 1 = 0.301996 loss)
I0530 14:18:08.854866 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.325297 (* 1 = 0.325297 loss)
I0530 14:18:08.854872 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00700456 (* 1 = 0.00700456 loss)
I0530 14:18:08.854878 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0828255 (* 1 = 0.0828255 loss)
I0530 14:18:08.854884 24924 sgd_solver.cpp:106] Iteration 23540, lr = 0.0002
I0530 14:19:00.716272 24924 solver.cpp:228] Iteration 23560, loss = 0.203969
I0530 14:19:00.716302 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 14:19:00.716310 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.09911 (* 1 = 0.09911 loss)
I0530 14:19:00.716315 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.137134 (* 1 = 0.137134 loss)
I0530 14:19:00.716318 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0302324 (* 1 = 0.0302324 loss)
I0530 14:19:00.716322 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0360443 (* 1 = 0.0360443 loss)
I0530 14:19:00.716328 24924 sgd_solver.cpp:106] Iteration 23560, lr = 0.0002
I0530 14:19:52.559110 24924 solver.cpp:228] Iteration 23580, loss = 0.240517
I0530 14:19:52.559136 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:19:52.559147 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0202149 (* 1 = 0.0202149 loss)
I0530 14:19:52.559154 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127235 (* 1 = 0.127235 loss)
I0530 14:19:52.559159 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0152099 (* 1 = 0.0152099 loss)
I0530 14:19:52.559165 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0556711 (* 1 = 0.0556711 loss)
I0530 14:19:52.559175 24924 sgd_solver.cpp:106] Iteration 23580, lr = 0.0002
speed: 2.483s / iter
I0530 14:20:44.378800 24924 solver.cpp:228] Iteration 23600, loss = 0.353048
I0530 14:20:44.378825 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:20:44.378834 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0325747 (* 1 = 0.0325747 loss)
I0530 14:20:44.378839 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156747 (* 1 = 0.156747 loss)
I0530 14:20:44.378841 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0145725 (* 1 = 0.0145725 loss)
I0530 14:20:44.378845 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00448265 (* 1 = 0.00448265 loss)
I0530 14:20:44.378850 24924 sgd_solver.cpp:106] Iteration 23600, lr = 0.0002
I0530 14:21:36.248375 24924 solver.cpp:228] Iteration 23620, loss = 0.314284
I0530 14:21:36.248399 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:21:36.248406 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.16249 (* 1 = 0.16249 loss)
I0530 14:21:36.248409 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.153289 (* 1 = 0.153289 loss)
I0530 14:21:36.248414 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00731751 (* 1 = 0.00731751 loss)
I0530 14:21:36.248417 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024058 (* 1 = 0.024058 loss)
I0530 14:21:36.248421 24924 sgd_solver.cpp:106] Iteration 23620, lr = 0.0002
I0530 14:22:28.136226 24924 solver.cpp:228] Iteration 23640, loss = 0.166042
I0530 14:22:28.136248 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 14:22:28.136256 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0296794 (* 1 = 0.0296794 loss)
I0530 14:22:28.136260 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0711054 (* 1 = 0.0711054 loss)
I0530 14:22:28.136263 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0258196 (* 1 = 0.0258196 loss)
I0530 14:22:28.136267 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0297146 (* 1 = 0.0297146 loss)
I0530 14:22:28.136271 24924 sgd_solver.cpp:106] Iteration 23640, lr = 0.0002
I0530 14:23:20.000219 24924 solver.cpp:228] Iteration 23660, loss = 0.17146
I0530 14:23:20.000244 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:23:20.000252 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.137707 (* 1 = 0.137707 loss)
I0530 14:23:20.000255 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.160594 (* 1 = 0.160594 loss)
I0530 14:23:20.000259 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148449 (* 1 = 0.0148449 loss)
I0530 14:23:20.000262 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0218633 (* 1 = 0.0218633 loss)
I0530 14:23:20.000267 24924 sgd_solver.cpp:106] Iteration 23660, lr = 0.0002
I0530 14:24:11.827924 24924 solver.cpp:228] Iteration 23680, loss = 0.347428
I0530 14:24:11.827952 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 14:24:11.827960 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0698779 (* 1 = 0.0698779 loss)
I0530 14:24:11.827963 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186059 (* 1 = 0.186059 loss)
I0530 14:24:11.827966 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0138958 (* 1 = 0.0138958 loss)
I0530 14:24:11.827970 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036913 (* 1 = 0.036913 loss)
I0530 14:24:11.827975 24924 sgd_solver.cpp:106] Iteration 23680, lr = 0.0002
I0530 14:25:03.723320 24924 solver.cpp:228] Iteration 23700, loss = 0.319844
I0530 14:25:03.723350 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:25:03.723357 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0741763 (* 1 = 0.0741763 loss)
I0530 14:25:03.723361 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0757419 (* 1 = 0.0757419 loss)
I0530 14:25:03.723366 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0492674 (* 1 = 0.0492674 loss)
I0530 14:25:03.723369 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.113917 (* 1 = 0.113917 loss)
I0530 14:25:03.723374 24924 sgd_solver.cpp:106] Iteration 23700, lr = 0.0002
I0530 14:25:55.621191 24924 solver.cpp:228] Iteration 23720, loss = 0.363314
I0530 14:25:55.621212 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 14:25:55.621220 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.136396 (* 1 = 0.136396 loss)
I0530 14:25:55.621224 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.141924 (* 1 = 0.141924 loss)
I0530 14:25:55.621227 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000870787 (* 1 = 0.000870787 loss)
I0530 14:25:55.621232 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.027659 (* 1 = 0.027659 loss)
I0530 14:25:55.621237 24924 sgd_solver.cpp:106] Iteration 23720, lr = 0.0002
I0530 14:26:48.106705 24924 solver.cpp:228] Iteration 23740, loss = 0.308456
I0530 14:26:48.106729 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 14:26:48.106735 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0358932 (* 1 = 0.0358932 loss)
I0530 14:26:48.106739 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0398712 (* 1 = 0.0398712 loss)
I0530 14:26:48.106741 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000408885 (* 1 = 0.000408885 loss)
I0530 14:26:48.106745 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00909379 (* 1 = 0.00909379 loss)
I0530 14:26:48.106750 24924 sgd_solver.cpp:106] Iteration 23740, lr = 0.0002
I0530 14:27:40.938928 24924 solver.cpp:228] Iteration 23760, loss = 0.533945
I0530 14:27:40.938956 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 14:27:40.938966 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.266459 (* 1 = 0.266459 loss)
I0530 14:27:40.938973 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.540206 (* 1 = 0.540206 loss)
I0530 14:27:40.938979 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0284963 (* 1 = 0.0284963 loss)
I0530 14:27:40.938987 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0967911 (* 1 = 0.0967911 loss)
I0530 14:27:40.938994 24924 sgd_solver.cpp:106] Iteration 23760, lr = 0.0002
I0530 14:28:33.175068 24924 solver.cpp:228] Iteration 23780, loss = 0.214583
I0530 14:28:33.175096 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 14:28:33.175103 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000212436 (* 1 = 0.000212436 loss)
I0530 14:28:33.175107 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0272345 (* 1 = 0.0272345 loss)
I0530 14:28:33.175112 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00330301 (* 1 = 0.00330301 loss)
I0530 14:28:33.175117 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0203018 (* 1 = 0.0203018 loss)
I0530 14:28:33.175122 24924 sgd_solver.cpp:106] Iteration 23780, lr = 0.0002
speed: 2.485s / iter
I0530 14:29:25.709084 24924 solver.cpp:228] Iteration 23800, loss = 0.213888
I0530 14:29:25.709113 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:29:25.709125 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0402526 (* 1 = 0.0402526 loss)
I0530 14:29:25.709131 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100457 (* 1 = 0.100457 loss)
I0530 14:29:25.709136 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128212 (* 1 = 0.0128212 loss)
I0530 14:29:25.709144 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.037136 (* 1 = 0.037136 loss)
I0530 14:29:25.709152 24924 sgd_solver.cpp:106] Iteration 23800, lr = 0.0002
I0530 14:30:17.850813 24924 solver.cpp:228] Iteration 23820, loss = 0.372975
I0530 14:30:17.850843 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0530 14:30:17.850852 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.223508 (* 1 = 0.223508 loss)
I0530 14:30:17.850857 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.545427 (* 1 = 0.545427 loss)
I0530 14:30:17.850862 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0279976 (* 1 = 0.0279976 loss)
I0530 14:30:17.850867 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0681153 (* 1 = 0.0681153 loss)
I0530 14:30:17.850872 24924 sgd_solver.cpp:106] Iteration 23820, lr = 0.0002
I0530 14:31:10.323372 24924 solver.cpp:228] Iteration 23840, loss = 0.242825
I0530 14:31:10.323401 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 14:31:10.323410 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.046726 (* 1 = 0.046726 loss)
I0530 14:31:10.323417 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0797615 (* 1 = 0.0797615 loss)
I0530 14:31:10.323423 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116985 (* 1 = 0.0116985 loss)
I0530 14:31:10.323429 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0137648 (* 1 = 0.0137648 loss)
I0530 14:31:10.323437 24924 sgd_solver.cpp:106] Iteration 23840, lr = 0.0002
I0530 14:32:03.160212 24924 solver.cpp:228] Iteration 23860, loss = 0.292521
I0530 14:32:03.160243 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 14:32:03.160251 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.186741 (* 1 = 0.186741 loss)
I0530 14:32:03.160256 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.367866 (* 1 = 0.367866 loss)
I0530 14:32:03.160260 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0614449 (* 1 = 0.0614449 loss)
I0530 14:32:03.160264 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0784828 (* 1 = 0.0784828 loss)
I0530 14:32:03.160269 24924 sgd_solver.cpp:106] Iteration 23860, lr = 0.0002
I0530 14:32:56.455433 24924 solver.cpp:228] Iteration 23880, loss = 0.354125
I0530 14:32:56.455463 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 14:32:56.455471 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.149105 (* 1 = 0.149105 loss)
I0530 14:32:56.455474 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.258435 (* 1 = 0.258435 loss)
I0530 14:32:56.455478 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0286949 (* 1 = 0.0286949 loss)
I0530 14:32:56.455482 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251032 (* 1 = 0.0251032 loss)
I0530 14:32:56.455487 24924 sgd_solver.cpp:106] Iteration 23880, lr = 0.0002
I0530 14:33:49.996796 24924 solver.cpp:228] Iteration 23900, loss = 0.201655
I0530 14:33:49.996824 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 14:33:49.996831 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0455183 (* 1 = 0.0455183 loss)
I0530 14:33:49.996835 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0420745 (* 1 = 0.0420745 loss)
I0530 14:33:49.996839 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00759511 (* 1 = 0.00759511 loss)
I0530 14:33:49.996842 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163959 (* 1 = 0.0163959 loss)
I0530 14:33:49.996847 24924 sgd_solver.cpp:106] Iteration 23900, lr = 0.0002
I0530 14:34:43.421715 24924 solver.cpp:228] Iteration 23920, loss = 0.412751
I0530 14:34:43.421742 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0530 14:34:43.421751 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.280215 (* 1 = 0.280215 loss)
I0530 14:34:43.421756 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.496176 (* 1 = 0.496176 loss)
I0530 14:34:43.421759 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0112378 (* 1 = 0.0112378 loss)
I0530 14:34:43.421762 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.161423 (* 1 = 0.161423 loss)
I0530 14:34:43.421769 24924 sgd_solver.cpp:106] Iteration 23920, lr = 0.0002
I0530 14:35:36.571159 24924 solver.cpp:228] Iteration 23940, loss = 0.389486
I0530 14:35:36.571187 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 14:35:36.571194 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0819631 (* 1 = 0.0819631 loss)
I0530 14:35:36.571198 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.226025 (* 1 = 0.226025 loss)
I0530 14:35:36.571202 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.191513 (* 1 = 0.191513 loss)
I0530 14:35:36.571204 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.206163 (* 1 = 0.206163 loss)
I0530 14:35:36.571209 24924 sgd_solver.cpp:106] Iteration 23940, lr = 0.0002
I0530 14:36:29.452611 24924 solver.cpp:228] Iteration 23960, loss = 0.170666
I0530 14:36:29.452641 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 14:36:29.452651 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0361122 (* 1 = 0.0361122 loss)
I0530 14:36:29.452658 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0548482 (* 1 = 0.0548482 loss)
I0530 14:36:29.452664 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169494 (* 1 = 0.00169494 loss)
I0530 14:36:29.452670 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0108194 (* 1 = 0.0108194 loss)
I0530 14:36:29.452679 24924 sgd_solver.cpp:106] Iteration 23960, lr = 0.0002
I0530 14:37:22.156682 24924 solver.cpp:228] Iteration 23980, loss = 0.201666
I0530 14:37:22.156713 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:37:22.156721 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102005 (* 1 = 0.102005 loss)
I0530 14:37:22.156728 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.212644 (* 1 = 0.212644 loss)
I0530 14:37:22.156735 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121059 (* 1 = 0.0121059 loss)
I0530 14:37:22.156739 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252938 (* 1 = 0.0252938 loss)
I0530 14:37:22.156746 24924 sgd_solver.cpp:106] Iteration 23980, lr = 0.0002
speed: 2.486s / iter
I0530 14:38:14.494858 24924 solver.cpp:228] Iteration 24000, loss = 0.211671
I0530 14:38:14.494884 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:38:14.494891 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122952 (* 1 = 0.122952 loss)
I0530 14:38:14.494896 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.125775 (* 1 = 0.125775 loss)
I0530 14:38:14.494899 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00596432 (* 1 = 0.00596432 loss)
I0530 14:38:14.494904 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0313104 (* 1 = 0.0313104 loss)
I0530 14:38:14.494909 24924 sgd_solver.cpp:106] Iteration 24000, lr = 0.0002
I0530 14:39:06.613773 24924 solver.cpp:228] Iteration 24020, loss = 0.277441
I0530 14:39:06.613801 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 14:39:06.613808 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.16103 (* 1 = 0.16103 loss)
I0530 14:39:06.613812 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.166284 (* 1 = 0.166284 loss)
I0530 14:39:06.613816 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00903614 (* 1 = 0.00903614 loss)
I0530 14:39:06.613821 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249168 (* 1 = 0.0249168 loss)
I0530 14:39:06.613826 24924 sgd_solver.cpp:106] Iteration 24020, lr = 0.0002
I0530 14:39:58.559800 24924 solver.cpp:228] Iteration 24040, loss = 0.255493
I0530 14:39:58.559825 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 14:39:58.559834 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.24145 (* 1 = 0.24145 loss)
I0530 14:39:58.559837 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.307368 (* 1 = 0.307368 loss)
I0530 14:39:58.559841 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0259743 (* 1 = 0.0259743 loss)
I0530 14:39:58.559845 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.102064 (* 1 = 0.102064 loss)
I0530 14:39:58.559850 24924 sgd_solver.cpp:106] Iteration 24040, lr = 0.0002
I0530 14:40:50.215939 24924 solver.cpp:228] Iteration 24060, loss = 0.330364
I0530 14:40:50.215971 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:40:50.215982 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.219094 (* 1 = 0.219094 loss)
I0530 14:40:50.215988 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.209238 (* 1 = 0.209238 loss)
I0530 14:40:50.215994 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014009 (* 1 = 0.014009 loss)
I0530 14:40:50.216001 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0555724 (* 1 = 0.0555724 loss)
I0530 14:40:50.216008 24924 sgd_solver.cpp:106] Iteration 24060, lr = 0.0002
I0530 14:41:42.087499 24924 solver.cpp:228] Iteration 24080, loss = 0.328388
I0530 14:41:42.087524 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 14:41:42.087534 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.212279 (* 1 = 0.212279 loss)
I0530 14:41:42.087541 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.231847 (* 1 = 0.231847 loss)
I0530 14:41:42.087548 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114072 (* 1 = 0.0114072 loss)
I0530 14:41:42.087553 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.059395 (* 1 = 0.059395 loss)
I0530 14:41:42.087560 24924 sgd_solver.cpp:106] Iteration 24080, lr = 0.0002
I0530 14:42:33.917168 24924 solver.cpp:228] Iteration 24100, loss = 0.292857
I0530 14:42:33.917194 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:42:33.917203 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0297433 (* 1 = 0.0297433 loss)
I0530 14:42:33.917209 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0947764 (* 1 = 0.0947764 loss)
I0530 14:42:33.917215 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00378065 (* 1 = 0.00378065 loss)
I0530 14:42:33.917220 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163834 (* 1 = 0.0163834 loss)
I0530 14:42:33.917227 24924 sgd_solver.cpp:106] Iteration 24100, lr = 0.0002
I0530 14:43:26.114533 24924 solver.cpp:228] Iteration 24120, loss = 0.180729
I0530 14:43:26.114564 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:43:26.114573 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0175316 (* 1 = 0.0175316 loss)
I0530 14:43:26.114578 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0757487 (* 1 = 0.0757487 loss)
I0530 14:43:26.114583 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00456289 (* 1 = 0.00456289 loss)
I0530 14:43:26.114586 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0222173 (* 1 = 0.0222173 loss)
I0530 14:43:26.114593 24924 sgd_solver.cpp:106] Iteration 24120, lr = 0.0002
I0530 14:44:19.036468 24924 solver.cpp:228] Iteration 24140, loss = 0.180283
I0530 14:44:19.036494 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 14:44:19.036500 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0835332 (* 1 = 0.0835332 loss)
I0530 14:44:19.036504 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.208901 (* 1 = 0.208901 loss)
I0530 14:44:19.036509 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00080625 (* 1 = 0.00080625 loss)
I0530 14:44:19.036511 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0131194 (* 1 = 0.0131194 loss)
I0530 14:44:19.036517 24924 sgd_solver.cpp:106] Iteration 24140, lr = 0.0002
I0530 14:45:11.525358 24924 solver.cpp:228] Iteration 24160, loss = 0.233712
I0530 14:45:11.525383 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 14:45:11.525393 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748965 (* 1 = 0.0748965 loss)
I0530 14:45:11.525399 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.163338 (* 1 = 0.163338 loss)
I0530 14:45:11.525404 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105646 (* 1 = 0.0105646 loss)
I0530 14:45:11.525409 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01419 (* 1 = 0.01419 loss)
I0530 14:45:11.525416 24924 sgd_solver.cpp:106] Iteration 24160, lr = 0.0002
I0530 14:46:04.260416 24924 solver.cpp:228] Iteration 24180, loss = 0.415752
I0530 14:46:04.260444 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 14:46:04.260452 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0453092 (* 1 = 0.0453092 loss)
I0530 14:46:04.260457 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.236267 (* 1 = 0.236267 loss)
I0530 14:46:04.260460 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185254 (* 1 = 0.0185254 loss)
I0530 14:46:04.260463 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0188833 (* 1 = 0.0188833 loss)
I0530 14:46:04.260468 24924 sgd_solver.cpp:106] Iteration 24180, lr = 0.0002
speed: 2.487s / iter
I0530 14:46:57.059365 24924 solver.cpp:228] Iteration 24200, loss = 0.444475
I0530 14:46:57.059391 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 14:46:57.059398 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.158571 (* 1 = 0.158571 loss)
I0530 14:46:57.059402 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.148914 (* 1 = 0.148914 loss)
I0530 14:46:57.059406 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00931267 (* 1 = 0.00931267 loss)
I0530 14:46:57.059411 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.009295 (* 1 = 0.009295 loss)
I0530 14:46:57.059415 24924 sgd_solver.cpp:106] Iteration 24200, lr = 0.0002
I0530 14:47:49.898483 24924 solver.cpp:228] Iteration 24220, loss = 0.250094
I0530 14:47:49.898505 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 14:47:49.898514 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485784 (* 1 = 0.0485784 loss)
I0530 14:47:49.898517 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0756346 (* 1 = 0.0756346 loss)
I0530 14:47:49.898521 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00265935 (* 1 = 0.00265935 loss)
I0530 14:47:49.898524 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00558545 (* 1 = 0.00558545 loss)
I0530 14:47:49.898530 24924 sgd_solver.cpp:106] Iteration 24220, lr = 0.0002
I0530 14:48:42.572895 24924 solver.cpp:228] Iteration 24240, loss = 0.501472
I0530 14:48:42.572962 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 14:48:42.572973 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0850654 (* 1 = 0.0850654 loss)
I0530 14:48:42.572981 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291014 (* 1 = 0.291014 loss)
I0530 14:48:42.572988 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0121993 (* 1 = 0.0121993 loss)
I0530 14:48:42.572996 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.022717 (* 1 = 0.022717 loss)
I0530 14:48:42.573005 24924 sgd_solver.cpp:106] Iteration 24240, lr = 0.0002
I0530 14:49:35.235103 24924 solver.cpp:228] Iteration 24260, loss = 0.273106
I0530 14:49:35.235129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 14:49:35.235137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0896209 (* 1 = 0.0896209 loss)
I0530 14:49:35.235141 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.243492 (* 1 = 0.243492 loss)
I0530 14:49:35.235146 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0146437 (* 1 = 0.0146437 loss)
I0530 14:49:35.235148 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0391488 (* 1 = 0.0391488 loss)
I0530 14:49:35.235153 24924 sgd_solver.cpp:106] Iteration 24260, lr = 0.0002
I0530 14:50:28.677443 24924 solver.cpp:228] Iteration 24280, loss = 0.18936
I0530 14:50:28.677469 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 14:50:28.677476 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0847535 (* 1 = 0.0847535 loss)
I0530 14:50:28.677480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124024 (* 1 = 0.124024 loss)
I0530 14:50:28.677484 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0015122 (* 1 = 0.0015122 loss)
I0530 14:50:28.677489 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016467 (* 1 = 0.016467 loss)
I0530 14:50:28.677494 24924 sgd_solver.cpp:106] Iteration 24280, lr = 0.0002
I0530 14:51:21.611814 24924 solver.cpp:228] Iteration 24300, loss = 0.370474
I0530 14:51:21.611840 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 14:51:21.611847 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0844772 (* 1 = 0.0844772 loss)
I0530 14:51:21.611851 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.19208 (* 1 = 0.19208 loss)
I0530 14:51:21.611855 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193324 (* 1 = 0.0193324 loss)
I0530 14:51:21.611858 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0168765 (* 1 = 0.0168765 loss)
I0530 14:51:21.611863 24924 sgd_solver.cpp:106] Iteration 24300, lr = 0.0002
I0530 14:52:14.630436 24924 solver.cpp:228] Iteration 24320, loss = 0.434549
I0530 14:52:14.630463 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 14:52:14.630473 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.088828 (* 1 = 0.088828 loss)
I0530 14:52:14.630481 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.176691 (* 1 = 0.176691 loss)
I0530 14:52:14.630486 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00898022 (* 1 = 0.00898022 loss)
I0530 14:52:14.630492 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0162789 (* 1 = 0.0162789 loss)
I0530 14:52:14.630499 24924 sgd_solver.cpp:106] Iteration 24320, lr = 0.0002
I0530 14:53:06.675122 24924 solver.cpp:228] Iteration 24340, loss = 0.342163
I0530 14:53:06.675149 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:53:06.675156 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0332912 (* 1 = 0.0332912 loss)
I0530 14:53:06.675160 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.074373 (* 1 = 0.074373 loss)
I0530 14:53:06.675164 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00896596 (* 1 = 0.00896596 loss)
I0530 14:53:06.675168 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015571 (* 1 = 0.015571 loss)
I0530 14:53:06.675171 24924 sgd_solver.cpp:106] Iteration 24340, lr = 0.0002
I0530 14:53:59.863721 24924 solver.cpp:228] Iteration 24360, loss = 0.238829
I0530 14:53:59.863747 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 14:53:59.863756 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000884481 (* 1 = 0.000884481 loss)
I0530 14:53:59.863761 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0459556 (* 1 = 0.0459556 loss)
I0530 14:53:59.863766 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167743 (* 1 = 0.0167743 loss)
I0530 14:53:59.863771 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00715572 (* 1 = 0.00715572 loss)
I0530 14:53:59.863777 24924 sgd_solver.cpp:106] Iteration 24360, lr = 0.0002
I0530 14:54:53.310590 24924 solver.cpp:228] Iteration 24380, loss = 0.291339
I0530 14:54:53.310618 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 14:54:53.310627 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.016912 (* 1 = 0.016912 loss)
I0530 14:54:53.310631 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0860064 (* 1 = 0.0860064 loss)
I0530 14:54:53.310636 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00304946 (* 1 = 0.00304946 loss)
I0530 14:54:53.310639 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00987625 (* 1 = 0.00987625 loss)
I0530 14:54:53.310647 24924 sgd_solver.cpp:106] Iteration 24380, lr = 0.0002
speed: 2.488s / iter
I0530 14:55:46.682016 24924 solver.cpp:228] Iteration 24400, loss = 0.230415
I0530 14:55:46.682044 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 14:55:46.682050 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.146462 (* 1 = 0.146462 loss)
I0530 14:55:46.682055 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.244205 (* 1 = 0.244205 loss)
I0530 14:55:46.682059 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00691922 (* 1 = 0.00691922 loss)
I0530 14:55:46.682062 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157406 (* 1 = 0.0157406 loss)
I0530 14:55:46.682067 24924 sgd_solver.cpp:106] Iteration 24400, lr = 0.0002
I0530 14:56:39.963940 24924 solver.cpp:228] Iteration 24420, loss = 0.469873
I0530 14:56:39.963965 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 14:56:39.963974 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.120545 (* 1 = 0.120545 loss)
I0530 14:56:39.963980 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.328541 (* 1 = 0.328541 loss)
I0530 14:56:39.963986 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0351552 (* 1 = 0.0351552 loss)
I0530 14:56:39.963991 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.253798 (* 1 = 0.253798 loss)
I0530 14:56:39.963997 24924 sgd_solver.cpp:106] Iteration 24420, lr = 0.0002
I0530 14:57:32.926121 24924 solver.cpp:228] Iteration 24440, loss = 0.366764
I0530 14:57:32.926147 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 14:57:32.926154 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0304927 (* 1 = 0.0304927 loss)
I0530 14:57:32.926158 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.085817 (* 1 = 0.085817 loss)
I0530 14:57:32.926162 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00485442 (* 1 = 0.00485442 loss)
I0530 14:57:32.926165 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00798825 (* 1 = 0.00798825 loss)
I0530 14:57:32.926170 24924 sgd_solver.cpp:106] Iteration 24440, lr = 0.0002
I0530 14:58:25.253129 24924 solver.cpp:228] Iteration 24460, loss = 0.387037
I0530 14:58:25.253151 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 14:58:25.253160 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.27814 (* 1 = 0.27814 loss)
I0530 14:58:25.253165 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.479949 (* 1 = 0.479949 loss)
I0530 14:58:25.253168 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0519939 (* 1 = 0.0519939 loss)
I0530 14:58:25.253171 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0691283 (* 1 = 0.0691283 loss)
I0530 14:58:25.253176 24924 sgd_solver.cpp:106] Iteration 24460, lr = 0.0002
I0530 14:59:17.270943 24924 solver.cpp:228] Iteration 24480, loss = 0.345401
I0530 14:59:17.270967 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 14:59:17.270974 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.135712 (* 1 = 0.135712 loss)
I0530 14:59:17.270978 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.182441 (* 1 = 0.182441 loss)
I0530 14:59:17.270982 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00993753 (* 1 = 0.00993753 loss)
I0530 14:59:17.270984 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0112662 (* 1 = 0.0112662 loss)
I0530 14:59:17.270988 24924 sgd_solver.cpp:106] Iteration 24480, lr = 0.0002
I0530 15:00:09.601732 24924 solver.cpp:228] Iteration 24500, loss = 0.368215
I0530 15:00:09.601757 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 15:00:09.601764 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.101064 (* 1 = 0.101064 loss)
I0530 15:00:09.601768 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.193373 (* 1 = 0.193373 loss)
I0530 15:00:09.601773 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.031996 (* 1 = 0.031996 loss)
I0530 15:00:09.601776 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0321587 (* 1 = 0.0321587 loss)
I0530 15:00:09.601780 24924 sgd_solver.cpp:106] Iteration 24500, lr = 0.0002
I0530 15:01:02.128105 24924 solver.cpp:228] Iteration 24520, loss = 0.199824
I0530 15:01:02.128130 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 15:01:02.128137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0960506 (* 1 = 0.0960506 loss)
I0530 15:01:02.128141 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.173272 (* 1 = 0.173272 loss)
I0530 15:01:02.128145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00473478 (* 1 = 0.00473478 loss)
I0530 15:01:02.128149 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0423846 (* 1 = 0.0423846 loss)
I0530 15:01:02.128154 24924 sgd_solver.cpp:106] Iteration 24520, lr = 0.0002
I0530 15:01:54.443032 24924 solver.cpp:228] Iteration 24540, loss = 0.347794
I0530 15:01:54.443065 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 15:01:54.443075 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.192746 (* 1 = 0.192746 loss)
I0530 15:01:54.443081 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.34545 (* 1 = 0.34545 loss)
I0530 15:01:54.443087 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0280379 (* 1 = 0.0280379 loss)
I0530 15:01:54.443094 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0824811 (* 1 = 0.0824811 loss)
I0530 15:01:54.443099 24924 sgd_solver.cpp:106] Iteration 24540, lr = 0.0002
I0530 15:02:46.744719 24924 solver.cpp:228] Iteration 24560, loss = 0.323051
I0530 15:02:46.744745 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 15:02:46.744752 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.049174 (* 1 = 0.049174 loss)
I0530 15:02:46.744756 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156159 (* 1 = 0.156159 loss)
I0530 15:02:46.744760 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00641213 (* 1 = 0.00641213 loss)
I0530 15:02:46.744763 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00852043 (* 1 = 0.00852043 loss)
I0530 15:02:46.744767 24924 sgd_solver.cpp:106] Iteration 24560, lr = 0.0002
I0530 15:03:39.982843 24924 solver.cpp:228] Iteration 24580, loss = 0.302526
I0530 15:03:39.982872 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 15:03:39.982878 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0864314 (* 1 = 0.0864314 loss)
I0530 15:03:39.982883 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0832927 (* 1 = 0.0832927 loss)
I0530 15:03:39.982889 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132311 (* 1 = 0.0132311 loss)
I0530 15:03:39.982894 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0772071 (* 1 = 0.0772071 loss)
I0530 15:03:39.982900 24924 sgd_solver.cpp:106] Iteration 24580, lr = 0.0002
speed: 2.489s / iter
I0530 15:04:33.598683 24924 solver.cpp:228] Iteration 24600, loss = 0.311481
I0530 15:04:33.598728 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 15:04:33.598747 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0708425 (* 1 = 0.0708425 loss)
I0530 15:04:33.598757 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.164516 (* 1 = 0.164516 loss)
I0530 15:04:33.598764 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173777 (* 1 = 0.0173777 loss)
I0530 15:04:33.598773 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0780795 (* 1 = 0.0780795 loss)
I0530 15:04:33.598785 24924 sgd_solver.cpp:106] Iteration 24600, lr = 0.0002
I0530 15:05:27.802279 24924 solver.cpp:228] Iteration 24620, loss = 0.281281
I0530 15:05:27.802322 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:05:27.802338 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00238328 (* 1 = 0.00238328 loss)
I0530 15:05:27.802347 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.055312 (* 1 = 0.055312 loss)
I0530 15:05:27.802357 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0202913 (* 1 = 0.0202913 loss)
I0530 15:05:27.802364 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361804 (* 1 = 0.0361804 loss)
I0530 15:05:27.802374 24924 sgd_solver.cpp:106] Iteration 24620, lr = 0.0002
I0530 15:06:22.690363 24924 solver.cpp:228] Iteration 24640, loss = 0.319021
I0530 15:06:22.690433 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 15:06:22.690449 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.124755 (* 1 = 0.124755 loss)
I0530 15:06:22.690459 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.271442 (* 1 = 0.271442 loss)
I0530 15:06:22.690466 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0171289 (* 1 = 0.0171289 loss)
I0530 15:06:22.690474 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.028043 (* 1 = 0.028043 loss)
I0530 15:06:22.690491 24924 sgd_solver.cpp:106] Iteration 24640, lr = 0.0002
I0530 15:07:16.994565 24924 solver.cpp:228] Iteration 24660, loss = 0.277093
I0530 15:07:16.994611 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 15:07:16.994628 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0429081 (* 1 = 0.0429081 loss)
I0530 15:07:16.994637 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.11139 (* 1 = 0.11139 loss)
I0530 15:07:16.994650 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00329041 (* 1 = 0.00329041 loss)
I0530 15:07:16.994663 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00551953 (* 1 = 0.00551953 loss)
I0530 15:07:16.994674 24924 sgd_solver.cpp:106] Iteration 24660, lr = 0.0002
I0530 15:08:10.946725 24924 solver.cpp:228] Iteration 24680, loss = 0.195514
I0530 15:08:10.946802 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:08:10.946835 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0473088 (* 1 = 0.0473088 loss)
I0530 15:08:10.946858 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0233464 (* 1 = 0.0233464 loss)
I0530 15:08:10.946878 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00621875 (* 1 = 0.00621875 loss)
I0530 15:08:10.946897 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00924817 (* 1 = 0.00924817 loss)
I0530 15:08:10.946916 24924 sgd_solver.cpp:106] Iteration 24680, lr = 0.0002
I0530 15:09:05.094851 24924 solver.cpp:228] Iteration 24700, loss = 0.452327
I0530 15:09:05.094888 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 15:09:05.094899 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0284943 (* 1 = 0.0284943 loss)
I0530 15:09:05.094907 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0665715 (* 1 = 0.0665715 loss)
I0530 15:09:05.094913 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00395227 (* 1 = 0.00395227 loss)
I0530 15:09:05.094918 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00754145 (* 1 = 0.00754145 loss)
I0530 15:09:05.094925 24924 sgd_solver.cpp:106] Iteration 24700, lr = 0.0002
I0530 15:09:58.841195 24924 solver.cpp:228] Iteration 24720, loss = 0.230361
I0530 15:09:58.841220 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 15:09:58.841229 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0313436 (* 1 = 0.0313436 loss)
I0530 15:09:58.841235 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0958079 (* 1 = 0.0958079 loss)
I0530 15:09:58.841240 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0139219 (* 1 = 0.0139219 loss)
I0530 15:09:58.841245 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0151461 (* 1 = 0.0151461 loss)
I0530 15:09:58.841251 24924 sgd_solver.cpp:106] Iteration 24720, lr = 0.0002
I0530 15:10:50.771832 24924 solver.cpp:228] Iteration 24740, loss = 0.209413
I0530 15:10:50.771873 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 15:10:50.771886 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0495201 (* 1 = 0.0495201 loss)
I0530 15:10:50.771893 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.140199 (* 1 = 0.140199 loss)
I0530 15:10:50.771899 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105602 (* 1 = 0.0105602 loss)
I0530 15:10:50.771904 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0126341 (* 1 = 0.0126341 loss)
I0530 15:10:50.771914 24924 sgd_solver.cpp:106] Iteration 24740, lr = 0.0002
I0530 15:11:43.238515 24924 solver.cpp:228] Iteration 24760, loss = 0.324209
I0530 15:11:43.238541 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:11:43.238548 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.057168 (* 1 = 0.057168 loss)
I0530 15:11:43.238553 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0714851 (* 1 = 0.0714851 loss)
I0530 15:11:43.238555 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00336387 (* 1 = 0.00336387 loss)
I0530 15:11:43.238559 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.015642 (* 1 = 0.015642 loss)
I0530 15:11:43.238565 24924 sgd_solver.cpp:106] Iteration 24760, lr = 0.0002
I0530 15:12:35.340155 24924 solver.cpp:228] Iteration 24780, loss = 0.252007
I0530 15:12:35.340185 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 15:12:35.340193 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0024798 (* 1 = 0.0024798 loss)
I0530 15:12:35.340198 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.110415 (* 1 = 0.110415 loss)
I0530 15:12:35.340201 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0114291 (* 1 = 0.0114291 loss)
I0530 15:12:35.340205 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.036769 (* 1 = 0.036769 loss)
I0530 15:12:35.340211 24924 sgd_solver.cpp:106] Iteration 24780, lr = 0.0002
speed: 2.491s / iter
I0530 15:13:28.573035 24924 solver.cpp:228] Iteration 24800, loss = 0.244946
I0530 15:13:28.573066 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:13:28.573074 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00860996 (* 1 = 0.00860996 loss)
I0530 15:13:28.573079 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0252834 (* 1 = 0.0252834 loss)
I0530 15:13:28.573083 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00157409 (* 1 = 0.00157409 loss)
I0530 15:13:28.573087 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0116705 (* 1 = 0.0116705 loss)
I0530 15:13:28.573093 24924 sgd_solver.cpp:106] Iteration 24800, lr = 0.0002
I0530 15:14:22.324861 24924 solver.cpp:228] Iteration 24820, loss = 0.324593
I0530 15:14:22.324887 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:14:22.324894 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00540098 (* 1 = 0.00540098 loss)
I0530 15:14:22.324899 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0641038 (* 1 = 0.0641038 loss)
I0530 15:14:22.324905 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073214 (* 1 = 0.0073214 loss)
I0530 15:14:22.324914 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298373 (* 1 = 0.0298373 loss)
I0530 15:14:22.324921 24924 sgd_solver.cpp:106] Iteration 24820, lr = 0.0002
I0530 15:15:15.246502 24924 solver.cpp:228] Iteration 24840, loss = 0.317569
I0530 15:15:15.246527 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 15:15:15.246538 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.215555 (* 1 = 0.215555 loss)
I0530 15:15:15.246544 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.201836 (* 1 = 0.201836 loss)
I0530 15:15:15.246551 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00577292 (* 1 = 0.00577292 loss)
I0530 15:15:15.246556 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0303987 (* 1 = 0.0303987 loss)
I0530 15:15:15.246567 24924 sgd_solver.cpp:106] Iteration 24840, lr = 0.0002
I0530 15:16:08.149261 24924 solver.cpp:228] Iteration 24860, loss = 0.257771
I0530 15:16:08.149288 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 15:16:08.149297 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0635897 (* 1 = 0.0635897 loss)
I0530 15:16:08.149303 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117174 (* 1 = 0.117174 loss)
I0530 15:16:08.149307 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0439021 (* 1 = 0.0439021 loss)
I0530 15:16:08.149312 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0390232 (* 1 = 0.0390232 loss)
I0530 15:16:08.149317 24924 sgd_solver.cpp:106] Iteration 24860, lr = 0.0002
I0530 15:17:01.180032 24924 solver.cpp:228] Iteration 24880, loss = 0.182495
I0530 15:17:01.180058 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 15:17:01.180066 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595487 (* 1 = 0.0595487 loss)
I0530 15:17:01.180070 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0705756 (* 1 = 0.0705756 loss)
I0530 15:17:01.180075 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00156013 (* 1 = 0.00156013 loss)
I0530 15:17:01.180079 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0060953 (* 1 = 0.0060953 loss)
I0530 15:17:01.180084 24924 sgd_solver.cpp:106] Iteration 24880, lr = 0.0002
I0530 15:17:53.678700 24924 solver.cpp:228] Iteration 24900, loss = 0.268133
I0530 15:17:53.678730 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:17:53.678737 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0390485 (* 1 = 0.0390485 loss)
I0530 15:17:53.678742 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0560334 (* 1 = 0.0560334 loss)
I0530 15:17:53.678745 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00230136 (* 1 = 0.00230136 loss)
I0530 15:17:53.678750 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00366823 (* 1 = 0.00366823 loss)
I0530 15:17:53.678755 24924 sgd_solver.cpp:106] Iteration 24900, lr = 0.0002
I0530 15:18:46.274340 24924 solver.cpp:228] Iteration 24920, loss = 0.448021
I0530 15:18:46.274364 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0530 15:18:46.274371 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.243606 (* 1 = 0.243606 loss)
I0530 15:18:46.274375 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.366946 (* 1 = 0.366946 loss)
I0530 15:18:46.274379 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014526 (* 1 = 0.014526 loss)
I0530 15:18:46.274381 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.128911 (* 1 = 0.128911 loss)
I0530 15:18:46.274386 24924 sgd_solver.cpp:106] Iteration 24920, lr = 0.0002
I0530 15:19:38.656092 24924 solver.cpp:228] Iteration 24940, loss = 0.21587
I0530 15:19:38.656116 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 15:19:38.656122 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.050805 (* 1 = 0.050805 loss)
I0530 15:19:38.656126 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.155559 (* 1 = 0.155559 loss)
I0530 15:19:38.656129 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0161851 (* 1 = 0.0161851 loss)
I0530 15:19:38.656133 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147867 (* 1 = 0.0147867 loss)
I0530 15:19:38.656137 24924 sgd_solver.cpp:106] Iteration 24940, lr = 0.0002
I0530 15:20:30.924846 24924 solver.cpp:228] Iteration 24960, loss = 0.271556
I0530 15:20:30.924876 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 15:20:30.924885 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.309561 (* 1 = 0.309561 loss)
I0530 15:20:30.924888 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.532558 (* 1 = 0.532558 loss)
I0530 15:20:30.924892 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0553665 (* 1 = 0.0553665 loss)
I0530 15:20:30.924897 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.139636 (* 1 = 0.139636 loss)
I0530 15:20:30.924902 24924 sgd_solver.cpp:106] Iteration 24960, lr = 0.0002
I0530 15:21:22.774859 24924 solver.cpp:228] Iteration 24980, loss = 0.255063
I0530 15:21:22.774886 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:21:22.774894 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00701587 (* 1 = 0.00701587 loss)
I0530 15:21:22.774899 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0466817 (* 1 = 0.0466817 loss)
I0530 15:21:22.774902 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00567977 (* 1 = 0.00567977 loss)
I0530 15:21:22.774906 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0084647 (* 1 = 0.0084647 loss)
I0530 15:21:22.774912 24924 sgd_solver.cpp:106] Iteration 24980, lr = 0.0002
speed: 2.492s / iter
I0530 15:22:12.728448 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_25000.caffemodel
I0530 15:22:15.960664 24924 solver.cpp:228] Iteration 25000, loss = 0.354677
I0530 15:22:15.960690 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.742188
I0530 15:22:15.960697 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.44922 (* 1 = 0.44922 loss)
I0530 15:22:15.960702 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.703199 (* 1 = 0.703199 loss)
I0530 15:22:15.960705 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0212207 (* 1 = 0.0212207 loss)
I0530 15:22:15.960711 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0712677 (* 1 = 0.0712677 loss)
I0530 15:22:15.960714 24924 sgd_solver.cpp:106] Iteration 25000, lr = 0.0002
I0530 15:23:08.277367 24924 solver.cpp:228] Iteration 25020, loss = 0.361943
I0530 15:23:08.277395 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.8125
I0530 15:23:08.277405 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.320187 (* 1 = 0.320187 loss)
I0530 15:23:08.277408 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.410622 (* 1 = 0.410622 loss)
I0530 15:23:08.277412 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0466264 (* 1 = 0.0466264 loss)
I0530 15:23:08.277415 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.153043 (* 1 = 0.153043 loss)
I0530 15:23:08.277421 24924 sgd_solver.cpp:106] Iteration 25020, lr = 0.0002
I0530 15:24:02.783610 24924 solver.cpp:228] Iteration 25040, loss = 0.268524
I0530 15:24:02.783638 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 15:24:02.783646 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.121306 (* 1 = 0.121306 loss)
I0530 15:24:02.783651 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124916 (* 1 = 0.124916 loss)
I0530 15:24:02.783655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00416385 (* 1 = 0.00416385 loss)
I0530 15:24:02.783659 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0213253 (* 1 = 0.0213253 loss)
I0530 15:24:02.783664 24924 sgd_solver.cpp:106] Iteration 25040, lr = 0.0002
I0530 15:24:55.158239 24924 solver.cpp:228] Iteration 25060, loss = 0.477811
I0530 15:24:55.158263 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 15:24:55.158272 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103546 (* 1 = 0.103546 loss)
I0530 15:24:55.158275 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.210532 (* 1 = 0.210532 loss)
I0530 15:24:55.158280 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204981 (* 1 = 0.0204981 loss)
I0530 15:24:55.158283 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0134032 (* 1 = 0.0134032 loss)
I0530 15:24:55.158288 24924 sgd_solver.cpp:106] Iteration 25060, lr = 0.0002
I0530 15:25:48.885614 24924 solver.cpp:228] Iteration 25080, loss = 0.201237
I0530 15:25:48.885640 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 15:25:48.885650 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.153748 (* 1 = 0.153748 loss)
I0530 15:25:48.885658 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.108478 (* 1 = 0.108478 loss)
I0530 15:25:48.885663 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218505 (* 1 = 0.00218505 loss)
I0530 15:25:48.885669 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143235 (* 1 = 0.0143235 loss)
I0530 15:25:48.885675 24924 sgd_solver.cpp:106] Iteration 25080, lr = 0.0002
I0530 15:26:41.356153 24924 solver.cpp:228] Iteration 25100, loss = 0.313677
I0530 15:26:41.356178 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 15:26:41.356185 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0667969 (* 1 = 0.0667969 loss)
I0530 15:26:41.356189 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134864 (* 1 = 0.134864 loss)
I0530 15:26:41.356192 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0127882 (* 1 = 0.0127882 loss)
I0530 15:26:41.356195 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0308144 (* 1 = 0.0308144 loss)
I0530 15:26:41.356200 24924 sgd_solver.cpp:106] Iteration 25100, lr = 0.0002
I0530 15:27:34.479990 24924 solver.cpp:228] Iteration 25120, loss = 0.205063
I0530 15:27:34.480013 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 15:27:34.480021 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160264 (* 1 = 0.160264 loss)
I0530 15:27:34.480026 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.599399 (* 1 = 0.599399 loss)
I0530 15:27:34.480031 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0177949 (* 1 = 0.0177949 loss)
I0530 15:27:34.480033 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0229133 (* 1 = 0.0229133 loss)
I0530 15:27:34.480038 24924 sgd_solver.cpp:106] Iteration 25120, lr = 0.0002
I0530 15:28:27.443348 24924 solver.cpp:228] Iteration 25140, loss = 0.363366
I0530 15:28:27.443373 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.789062
I0530 15:28:27.443382 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.374798 (* 1 = 0.374798 loss)
I0530 15:28:27.443385 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.524265 (* 1 = 0.524265 loss)
I0530 15:28:27.443389 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137148 (* 1 = 0.0137148 loss)
I0530 15:28:27.443393 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0916796 (* 1 = 0.0916796 loss)
I0530 15:28:27.443398 24924 sgd_solver.cpp:106] Iteration 25140, lr = 0.0002
I0530 15:29:20.188185 24924 solver.cpp:228] Iteration 25160, loss = 0.29807
I0530 15:29:20.188217 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 15:29:20.188226 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.105405 (* 1 = 0.105405 loss)
I0530 15:29:20.188231 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.129403 (* 1 = 0.129403 loss)
I0530 15:29:20.188235 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231733 (* 1 = 0.00231733 loss)
I0530 15:29:20.188241 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263106 (* 1 = 0.0263106 loss)
I0530 15:29:20.188246 24924 sgd_solver.cpp:106] Iteration 25160, lr = 0.0002
I0530 15:30:12.515242 24924 solver.cpp:228] Iteration 25180, loss = 0.446108
I0530 15:30:12.515271 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 15:30:12.515280 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0730262 (* 1 = 0.0730262 loss)
I0530 15:30:12.515285 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144582 (* 1 = 0.144582 loss)
I0530 15:30:12.515288 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0314377 (* 1 = 0.0314377 loss)
I0530 15:30:12.515292 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0751946 (* 1 = 0.0751946 loss)
I0530 15:30:12.515298 24924 sgd_solver.cpp:106] Iteration 25180, lr = 0.0002
speed: 2.493s / iter
I0530 15:31:05.423382 24924 solver.cpp:228] Iteration 25200, loss = 0.216965
I0530 15:31:05.423409 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 15:31:05.423416 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00193566 (* 1 = 0.00193566 loss)
I0530 15:31:05.423421 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102633 (* 1 = 0.102633 loss)
I0530 15:31:05.423425 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108007 (* 1 = 0.0108007 loss)
I0530 15:31:05.423429 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278951 (* 1 = 0.0278951 loss)
I0530 15:31:05.423434 24924 sgd_solver.cpp:106] Iteration 25200, lr = 0.0002
I0530 15:31:58.036018 24924 solver.cpp:228] Iteration 25220, loss = 0.260926
I0530 15:31:58.036042 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 15:31:58.036051 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0848921 (* 1 = 0.0848921 loss)
I0530 15:31:58.036056 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0802074 (* 1 = 0.0802074 loss)
I0530 15:31:58.036059 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111661 (* 1 = 0.0111661 loss)
I0530 15:31:58.036063 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0363586 (* 1 = 0.0363586 loss)
I0530 15:31:58.036067 24924 sgd_solver.cpp:106] Iteration 25220, lr = 0.0002
I0530 15:32:50.333994 24924 solver.cpp:228] Iteration 25240, loss = 0.312564
I0530 15:32:50.334019 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:32:50.334026 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0124894 (* 1 = 0.0124894 loss)
I0530 15:32:50.334030 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0448305 (* 1 = 0.0448305 loss)
I0530 15:32:50.334034 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229645 (* 1 = 0.00229645 loss)
I0530 15:32:50.334038 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00212423 (* 1 = 0.00212423 loss)
I0530 15:32:50.334043 24924 sgd_solver.cpp:106] Iteration 25240, lr = 0.0002
I0530 15:33:42.720831 24924 solver.cpp:228] Iteration 25260, loss = 0.255864
I0530 15:33:42.720855 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 15:33:42.720865 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574909 (* 1 = 0.0574909 loss)
I0530 15:33:42.720871 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.146808 (* 1 = 0.146808 loss)
I0530 15:33:42.720876 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00183971 (* 1 = 0.00183971 loss)
I0530 15:33:42.720881 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0076986 (* 1 = 0.0076986 loss)
I0530 15:33:42.720888 24924 sgd_solver.cpp:106] Iteration 25260, lr = 0.0002
I0530 15:34:35.274924 24924 solver.cpp:228] Iteration 25280, loss = 0.48546
I0530 15:34:35.274945 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:34:35.274951 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0283118 (* 1 = 0.0283118 loss)
I0530 15:34:35.274955 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0476817 (* 1 = 0.0476817 loss)
I0530 15:34:35.274958 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0122688 (* 1 = 0.0122688 loss)
I0530 15:34:35.274961 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00585761 (* 1 = 0.00585761 loss)
I0530 15:34:35.274966 24924 sgd_solver.cpp:106] Iteration 25280, lr = 0.0002
I0530 15:35:27.792543 24924 solver.cpp:228] Iteration 25300, loss = 0.341523
I0530 15:35:27.792567 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 15:35:27.792573 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.053707 (* 1 = 0.053707 loss)
I0530 15:35:27.792577 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0931233 (* 1 = 0.0931233 loss)
I0530 15:35:27.792580 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00120532 (* 1 = 0.00120532 loss)
I0530 15:35:27.792583 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0110742 (* 1 = 0.0110742 loss)
I0530 15:35:27.792588 24924 sgd_solver.cpp:106] Iteration 25300, lr = 0.0002
I0530 15:36:20.391991 24924 solver.cpp:228] Iteration 25320, loss = 0.237842
I0530 15:36:20.392017 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:36:20.392024 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0149048 (* 1 = 0.0149048 loss)
I0530 15:36:20.392027 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0551038 (* 1 = 0.0551038 loss)
I0530 15:36:20.392030 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00114801 (* 1 = 0.00114801 loss)
I0530 15:36:20.392035 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570367 (* 1 = 0.00570367 loss)
I0530 15:36:20.392038 24924 sgd_solver.cpp:106] Iteration 25320, lr = 0.0002
I0530 15:37:12.807821 24924 solver.cpp:228] Iteration 25340, loss = 0.255484
I0530 15:37:12.807847 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 15:37:12.807857 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.12381 (* 1 = 0.12381 loss)
I0530 15:37:12.807862 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.517566 (* 1 = 0.517566 loss)
I0530 15:37:12.807866 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0170315 (* 1 = 0.0170315 loss)
I0530 15:37:12.807870 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383639 (* 1 = 0.0383639 loss)
I0530 15:37:12.807876 24924 sgd_solver.cpp:106] Iteration 25340, lr = 0.0002
I0530 15:38:05.428206 24924 solver.cpp:228] Iteration 25360, loss = 0.417832
I0530 15:38:05.428234 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 15:38:05.428242 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0501731 (* 1 = 0.0501731 loss)
I0530 15:38:05.428247 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109464 (* 1 = 0.109464 loss)
I0530 15:38:05.428251 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00119175 (* 1 = 0.00119175 loss)
I0530 15:38:05.428256 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154058 (* 1 = 0.0154058 loss)
I0530 15:38:05.428261 24924 sgd_solver.cpp:106] Iteration 25360, lr = 0.0002
I0530 15:38:58.507678 24924 solver.cpp:228] Iteration 25380, loss = 0.357514
I0530 15:38:58.507702 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:38:58.507710 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.017647 (* 1 = 0.017647 loss)
I0530 15:38:58.507714 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0366625 (* 1 = 0.0366625 loss)
I0530 15:38:58.507719 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00414618 (* 1 = 0.00414618 loss)
I0530 15:38:58.507722 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00623557 (* 1 = 0.00623557 loss)
I0530 15:38:58.507727 24924 sgd_solver.cpp:106] Iteration 25380, lr = 0.0002
speed: 2.494s / iter
I0530 15:39:51.329135 24924 solver.cpp:228] Iteration 25400, loss = 0.370423
I0530 15:39:51.329164 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 15:39:51.329172 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.131028 (* 1 = 0.131028 loss)
I0530 15:39:51.329177 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.258437 (* 1 = 0.258437 loss)
I0530 15:39:51.329180 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158184 (* 1 = 0.0158184 loss)
I0530 15:39:51.329185 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0306043 (* 1 = 0.0306043 loss)
I0530 15:39:51.329190 24924 sgd_solver.cpp:106] Iteration 25400, lr = 0.0002
I0530 15:40:44.331164 24924 solver.cpp:228] Iteration 25420, loss = 0.423748
I0530 15:40:44.331192 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.820312
I0530 15:40:44.331199 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.238637 (* 1 = 0.238637 loss)
I0530 15:40:44.331203 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.423169 (* 1 = 0.423169 loss)
I0530 15:40:44.331207 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.057633 (* 1 = 0.057633 loss)
I0530 15:40:44.331212 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.149709 (* 1 = 0.149709 loss)
I0530 15:40:44.331218 24924 sgd_solver.cpp:106] Iteration 25420, lr = 0.0002
I0530 15:41:36.398463 24924 solver.cpp:228] Iteration 25440, loss = 0.355901
I0530 15:41:36.398489 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 15:41:36.398497 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0851839 (* 1 = 0.0851839 loss)
I0530 15:41:36.398502 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.220736 (* 1 = 0.220736 loss)
I0530 15:41:36.398505 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103734 (* 1 = 0.0103734 loss)
I0530 15:41:36.398509 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387364 (* 1 = 0.0387364 loss)
I0530 15:41:36.398514 24924 sgd_solver.cpp:106] Iteration 25440, lr = 0.0002
I0530 15:42:28.065577 24924 solver.cpp:228] Iteration 25460, loss = 0.166924
I0530 15:42:28.065601 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 15:42:28.065608 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.147353 (* 1 = 0.147353 loss)
I0530 15:42:28.065613 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.214106 (* 1 = 0.214106 loss)
I0530 15:42:28.065615 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174887 (* 1 = 0.0174887 loss)
I0530 15:42:28.065619 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402723 (* 1 = 0.0402723 loss)
I0530 15:42:28.065624 24924 sgd_solver.cpp:106] Iteration 25460, lr = 0.0002
I0530 15:43:20.051410 24924 solver.cpp:228] Iteration 25480, loss = 0.274437
I0530 15:43:20.051435 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 15:43:20.051442 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0011032 (* 1 = 0.0011032 loss)
I0530 15:43:20.051446 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0272506 (* 1 = 0.0272506 loss)
I0530 15:43:20.051450 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320611 (* 1 = 0.00320611 loss)
I0530 15:43:20.051453 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0379417 (* 1 = 0.0379417 loss)
I0530 15:43:20.051458 24924 sgd_solver.cpp:106] Iteration 25480, lr = 0.0002
I0530 15:44:13.049662 24924 solver.cpp:228] Iteration 25500, loss = 0.395192
I0530 15:44:13.049691 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 15:44:13.049700 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0293321 (* 1 = 0.0293321 loss)
I0530 15:44:13.049705 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.427083 (* 1 = 0.427083 loss)
I0530 15:44:13.049708 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0679777 (* 1 = 0.0679777 loss)
I0530 15:44:13.049713 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0419267 (* 1 = 0.0419267 loss)
I0530 15:44:13.049718 24924 sgd_solver.cpp:106] Iteration 25500, lr = 0.0002
I0530 15:45:09.608384 24924 solver.cpp:228] Iteration 25520, loss = 0.313758
I0530 15:45:09.608409 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 15:45:09.608417 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.235023 (* 1 = 0.235023 loss)
I0530 15:45:09.608422 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.628642 (* 1 = 0.628642 loss)
I0530 15:45:09.608427 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0319172 (* 1 = 0.0319172 loss)
I0530 15:45:09.608429 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0475473 (* 1 = 0.0475473 loss)
I0530 15:45:09.608434 24924 sgd_solver.cpp:106] Iteration 25520, lr = 0.0002
I0530 15:46:03.163893 24924 solver.cpp:228] Iteration 25540, loss = 0.201422
I0530 15:46:03.163923 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:46:03.163930 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0150937 (* 1 = 0.0150937 loss)
I0530 15:46:03.163935 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0838856 (* 1 = 0.0838856 loss)
I0530 15:46:03.163939 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0237395 (* 1 = 0.0237395 loss)
I0530 15:46:03.163944 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161604 (* 1 = 0.0161604 loss)
I0530 15:46:03.163949 24924 sgd_solver.cpp:106] Iteration 25540, lr = 0.0002
I0530 15:46:56.964406 24924 solver.cpp:228] Iteration 25560, loss = 0.329704
I0530 15:46:56.964433 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 15:46:56.964440 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0085769 (* 1 = 0.0085769 loss)
I0530 15:46:56.964444 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0884157 (* 1 = 0.0884157 loss)
I0530 15:46:56.964448 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0592948 (* 1 = 0.0592948 loss)
I0530 15:46:56.964452 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0304425 (* 1 = 0.0304425 loss)
I0530 15:46:56.964457 24924 sgd_solver.cpp:106] Iteration 25560, lr = 0.0002
I0530 15:47:49.688213 24924 solver.cpp:228] Iteration 25580, loss = 0.691432
I0530 15:47:49.688239 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 15:47:49.688247 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.20185 (* 1 = 0.20185 loss)
I0530 15:47:49.688251 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.298972 (* 1 = 0.298972 loss)
I0530 15:47:49.688256 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0211908 (* 1 = 0.0211908 loss)
I0530 15:47:49.688258 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280196 (* 1 = 0.0280196 loss)
I0530 15:47:49.688264 24924 sgd_solver.cpp:106] Iteration 25580, lr = 0.0002
speed: 2.496s / iter
I0530 15:48:43.325192 24924 solver.cpp:228] Iteration 25600, loss = 0.7097
I0530 15:48:43.325219 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.4375
I0530 15:48:43.325227 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.959748 (* 1 = 0.959748 loss)
I0530 15:48:43.325232 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.921448 (* 1 = 0.921448 loss)
I0530 15:48:43.325235 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.102098 (* 1 = 0.102098 loss)
I0530 15:48:43.325239 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.515284 (* 1 = 0.515284 loss)
I0530 15:48:43.325244 24924 sgd_solver.cpp:106] Iteration 25600, lr = 0.0002
I0530 15:49:36.328256 24924 solver.cpp:228] Iteration 25620, loss = 0.283643
I0530 15:49:36.328287 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.726562
I0530 15:49:36.328297 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.412458 (* 1 = 0.412458 loss)
I0530 15:49:36.328303 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.604268 (* 1 = 0.604268 loss)
I0530 15:49:36.328310 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00709735 (* 1 = 0.00709735 loss)
I0530 15:49:36.328316 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0619579 (* 1 = 0.0619579 loss)
I0530 15:49:36.328326 24924 sgd_solver.cpp:106] Iteration 25620, lr = 0.0002
I0530 15:50:28.900620 24924 solver.cpp:228] Iteration 25640, loss = 0.221972
I0530 15:50:28.900652 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 15:50:28.900660 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0464219 (* 1 = 0.0464219 loss)
I0530 15:50:28.900665 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0877241 (* 1 = 0.0877241 loss)
I0530 15:50:28.900669 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00332214 (* 1 = 0.00332214 loss)
I0530 15:50:28.900674 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00676821 (* 1 = 0.00676821 loss)
I0530 15:50:28.900679 24924 sgd_solver.cpp:106] Iteration 25640, lr = 0.0002
I0530 15:51:21.806445 24924 solver.cpp:228] Iteration 25660, loss = 0.255562
I0530 15:51:21.806473 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 15:51:21.806480 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0649429 (* 1 = 0.0649429 loss)
I0530 15:51:21.806484 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132599 (* 1 = 0.132599 loss)
I0530 15:51:21.806488 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026535 (* 1 = 0.026535 loss)
I0530 15:51:21.806491 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145568 (* 1 = 0.0145568 loss)
I0530 15:51:21.806497 24924 sgd_solver.cpp:106] Iteration 25660, lr = 0.0002
I0530 15:52:14.617041 24924 solver.cpp:228] Iteration 25680, loss = 0.192499
I0530 15:52:14.617069 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 15:52:14.617077 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0291568 (* 1 = 0.0291568 loss)
I0530 15:52:14.617082 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0663309 (* 1 = 0.0663309 loss)
I0530 15:52:14.617086 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00149812 (* 1 = 0.00149812 loss)
I0530 15:52:14.617090 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00551673 (* 1 = 0.00551673 loss)
I0530 15:52:14.617095 24924 sgd_solver.cpp:106] Iteration 25680, lr = 0.0002
I0530 15:53:07.718832 24924 solver.cpp:228] Iteration 25700, loss = 0.446955
I0530 15:53:07.718857 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 15:53:07.718863 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00294553 (* 1 = 0.00294553 loss)
I0530 15:53:07.718868 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0295326 (* 1 = 0.0295326 loss)
I0530 15:53:07.718871 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000937322 (* 1 = 0.000937322 loss)
I0530 15:53:07.718874 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0333442 (* 1 = 0.0333442 loss)
I0530 15:53:07.718879 24924 sgd_solver.cpp:106] Iteration 25700, lr = 0.0002
I0530 15:53:59.943109 24924 solver.cpp:228] Iteration 25720, loss = 0.272145
I0530 15:53:59.943138 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:53:59.943146 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0581762 (* 1 = 0.0581762 loss)
I0530 15:53:59.943150 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117315 (* 1 = 0.117315 loss)
I0530 15:53:59.943154 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320683 (* 1 = 0.00320683 loss)
I0530 15:53:59.943158 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0118845 (* 1 = 0.0118845 loss)
I0530 15:53:59.943163 24924 sgd_solver.cpp:106] Iteration 25720, lr = 0.0002
I0530 15:54:52.734164 24924 solver.cpp:228] Iteration 25740, loss = 0.429132
I0530 15:54:52.734200 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 15:54:52.734210 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.351139 (* 1 = 0.351139 loss)
I0530 15:54:52.734215 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.403846 (* 1 = 0.403846 loss)
I0530 15:54:52.734220 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0450867 (* 1 = 0.0450867 loss)
I0530 15:54:52.734225 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.12342 (* 1 = 0.12342 loss)
I0530 15:54:52.734233 24924 sgd_solver.cpp:106] Iteration 25740, lr = 0.0002
I0530 15:55:45.789398 24924 solver.cpp:228] Iteration 25760, loss = 0.293665
I0530 15:55:45.789423 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 15:55:45.789432 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0387319 (* 1 = 0.0387319 loss)
I0530 15:55:45.789435 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0343782 (* 1 = 0.0343782 loss)
I0530 15:55:45.789439 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137828 (* 1 = 0.0137828 loss)
I0530 15:55:45.789443 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00478246 (* 1 = 0.00478246 loss)
I0530 15:55:45.789448 24924 sgd_solver.cpp:106] Iteration 25760, lr = 0.0002
I0530 15:56:38.591425 24924 solver.cpp:228] Iteration 25780, loss = 0.337011
I0530 15:56:38.591452 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 15:56:38.591462 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0532453 (* 1 = 0.0532453 loss)
I0530 15:56:38.591470 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0921596 (* 1 = 0.0921596 loss)
I0530 15:56:38.591475 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00566635 (* 1 = 0.00566635 loss)
I0530 15:56:38.591482 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133252 (* 1 = 0.0133252 loss)
I0530 15:56:38.591488 24924 sgd_solver.cpp:106] Iteration 25780, lr = 0.0002
speed: 2.497s / iter
I0530 15:57:31.222218 24924 solver.cpp:228] Iteration 25800, loss = 0.310024
I0530 15:57:31.222242 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 15:57:31.222252 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.123236 (* 1 = 0.123236 loss)
I0530 15:57:31.222257 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100123 (* 1 = 0.100123 loss)
I0530 15:57:31.222263 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398976 (* 1 = 0.00398976 loss)
I0530 15:57:31.222270 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0160987 (* 1 = 0.0160987 loss)
I0530 15:57:31.222276 24924 sgd_solver.cpp:106] Iteration 25800, lr = 0.0002
I0530 15:58:24.215853 24924 solver.cpp:228] Iteration 25820, loss = 0.261756
I0530 15:58:24.215880 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 15:58:24.215889 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0442811 (* 1 = 0.0442811 loss)
I0530 15:58:24.215893 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0531674 (* 1 = 0.0531674 loss)
I0530 15:58:24.215898 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00280593 (* 1 = 0.00280593 loss)
I0530 15:58:24.215901 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00700197 (* 1 = 0.00700197 loss)
I0530 15:58:24.215906 24924 sgd_solver.cpp:106] Iteration 25820, lr = 0.0002
I0530 15:59:17.335932 24924 solver.cpp:228] Iteration 25840, loss = 0.290596
I0530 15:59:17.335961 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 15:59:17.335968 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.156961 (* 1 = 0.156961 loss)
I0530 15:59:17.335973 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.32219 (* 1 = 0.32219 loss)
I0530 15:59:17.335976 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0364575 (* 1 = 0.0364575 loss)
I0530 15:59:17.335979 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0797281 (* 1 = 0.0797281 loss)
I0530 15:59:17.335984 24924 sgd_solver.cpp:106] Iteration 25840, lr = 0.0002
I0530 16:00:10.688985 24924 solver.cpp:228] Iteration 25860, loss = 0.482371
I0530 16:00:10.689018 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:00:10.689028 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.054811 (* 1 = 0.054811 loss)
I0530 16:00:10.689034 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0646373 (* 1 = 0.0646373 loss)
I0530 16:00:10.689040 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00332074 (* 1 = 0.00332074 loss)
I0530 16:00:10.689046 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00688227 (* 1 = 0.00688227 loss)
I0530 16:00:10.689056 24924 sgd_solver.cpp:106] Iteration 25860, lr = 0.0002
I0530 16:01:03.367337 24924 solver.cpp:228] Iteration 25880, loss = 0.426176
I0530 16:01:03.367365 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 16:01:03.367375 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0508588 (* 1 = 0.0508588 loss)
I0530 16:01:03.367382 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0906969 (* 1 = 0.0906969 loss)
I0530 16:01:03.367386 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00766825 (* 1 = 0.00766825 loss)
I0530 16:01:03.367393 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217897 (* 1 = 0.0217897 loss)
I0530 16:01:03.367399 24924 sgd_solver.cpp:106] Iteration 25880, lr = 0.0002
I0530 16:01:56.476585 24924 solver.cpp:228] Iteration 25900, loss = 0.276056
I0530 16:01:56.476613 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 16:01:56.476624 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.166546 (* 1 = 0.166546 loss)
I0530 16:01:56.476631 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.320176 (* 1 = 0.320176 loss)
I0530 16:01:56.476637 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0174129 (* 1 = 0.0174129 loss)
I0530 16:01:56.476644 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0514936 (* 1 = 0.0514936 loss)
I0530 16:01:56.476667 24924 sgd_solver.cpp:106] Iteration 25900, lr = 0.0002
I0530 16:02:49.235538 24924 solver.cpp:228] Iteration 25920, loss = 0.330174
I0530 16:02:49.235561 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 16:02:49.235570 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13636 (* 1 = 0.13636 loss)
I0530 16:02:49.235577 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.187763 (* 1 = 0.187763 loss)
I0530 16:02:49.235582 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00671274 (* 1 = 0.00671274 loss)
I0530 16:02:49.235589 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0369991 (* 1 = 0.0369991 loss)
I0530 16:02:49.235594 24924 sgd_solver.cpp:106] Iteration 25920, lr = 0.0002
I0530 16:03:42.815711 24924 solver.cpp:228] Iteration 25940, loss = 0.320359
I0530 16:03:42.815737 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 16:03:42.815743 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.107066 (* 1 = 0.107066 loss)
I0530 16:03:42.815747 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.151066 (* 1 = 0.151066 loss)
I0530 16:03:42.815752 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00267281 (* 1 = 0.00267281 loss)
I0530 16:03:42.815754 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013643 (* 1 = 0.013643 loss)
I0530 16:03:42.815759 24924 sgd_solver.cpp:106] Iteration 25940, lr = 0.0002
I0530 16:04:36.549119 24924 solver.cpp:228] Iteration 25960, loss = 0.285933
I0530 16:04:36.549154 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 16:04:36.549165 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0350369 (* 1 = 0.0350369 loss)
I0530 16:04:36.549172 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0620195 (* 1 = 0.0620195 loss)
I0530 16:04:36.549178 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0667581 (* 1 = 0.0667581 loss)
I0530 16:04:36.549185 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.219931 (* 1 = 0.219931 loss)
I0530 16:04:36.549193 24924 sgd_solver.cpp:106] Iteration 25960, lr = 0.0002
I0530 16:05:28.942920 24924 solver.cpp:228] Iteration 25980, loss = 0.313905
I0530 16:05:28.942948 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 16:05:28.942956 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160251 (* 1 = 0.160251 loss)
I0530 16:05:28.942960 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.283938 (* 1 = 0.283938 loss)
I0530 16:05:28.942965 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0232244 (* 1 = 0.0232244 loss)
I0530 16:05:28.942967 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0490209 (* 1 = 0.0490209 loss)
I0530 16:05:28.942972 24924 sgd_solver.cpp:106] Iteration 25980, lr = 0.0002
speed: 2.498s / iter
I0530 16:06:21.915933 24924 solver.cpp:228] Iteration 26000, loss = 0.801313
I0530 16:06:21.915961 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:06:21.915969 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0469396 (* 1 = 0.0469396 loss)
I0530 16:06:21.915973 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0373456 (* 1 = 0.0373456 loss)
I0530 16:06:21.915977 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00998047 (* 1 = 0.00998047 loss)
I0530 16:06:21.915982 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00951768 (* 1 = 0.00951768 loss)
I0530 16:06:21.915987 24924 sgd_solver.cpp:106] Iteration 26000, lr = 0.0002
I0530 16:07:14.522014 24924 solver.cpp:228] Iteration 26020, loss = 0.336733
I0530 16:07:14.522038 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 16:07:14.522045 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0709994 (* 1 = 0.0709994 loss)
I0530 16:07:14.522049 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.28036 (* 1 = 0.28036 loss)
I0530 16:07:14.522053 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153225 (* 1 = 0.0153225 loss)
I0530 16:07:14.522056 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0227274 (* 1 = 0.0227274 loss)
I0530 16:07:14.522060 24924 sgd_solver.cpp:106] Iteration 26020, lr = 0.0002
I0530 16:08:06.837553 24924 solver.cpp:228] Iteration 26040, loss = 0.311152
I0530 16:08:06.837577 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 16:08:06.837586 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0756675 (* 1 = 0.0756675 loss)
I0530 16:08:06.837592 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133535 (* 1 = 0.133535 loss)
I0530 16:08:06.837597 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0050128 (* 1 = 0.0050128 loss)
I0530 16:08:06.837604 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00618113 (* 1 = 0.00618113 loss)
I0530 16:08:06.837610 24924 sgd_solver.cpp:106] Iteration 26040, lr = 0.0002
I0530 16:08:59.039291 24924 solver.cpp:228] Iteration 26060, loss = 0.338778
I0530 16:08:59.039317 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 16:08:59.039327 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.217727 (* 1 = 0.217727 loss)
I0530 16:08:59.039333 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.361302 (* 1 = 0.361302 loss)
I0530 16:08:59.039340 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205271 (* 1 = 0.0205271 loss)
I0530 16:08:59.039345 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0567694 (* 1 = 0.0567694 loss)
I0530 16:08:59.039352 24924 sgd_solver.cpp:106] Iteration 26060, lr = 0.0002
I0530 16:09:51.506201 24924 solver.cpp:228] Iteration 26080, loss = 0.43164
I0530 16:09:51.506225 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:09:51.506233 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0196858 (* 1 = 0.0196858 loss)
I0530 16:09:51.506237 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0375701 (* 1 = 0.0375701 loss)
I0530 16:09:51.506242 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000735129 (* 1 = 0.000735129 loss)
I0530 16:09:51.506244 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00745529 (* 1 = 0.00745529 loss)
I0530 16:09:51.506249 24924 sgd_solver.cpp:106] Iteration 26080, lr = 0.0002
I0530 16:10:44.296808 24924 solver.cpp:228] Iteration 26100, loss = 0.331154
I0530 16:10:44.296833 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 16:10:44.296840 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0344293 (* 1 = 0.0344293 loss)
I0530 16:10:44.296844 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0786469 (* 1 = 0.0786469 loss)
I0530 16:10:44.296847 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00421073 (* 1 = 0.00421073 loss)
I0530 16:10:44.296851 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00591936 (* 1 = 0.00591936 loss)
I0530 16:10:44.296855 24924 sgd_solver.cpp:106] Iteration 26100, lr = 0.0002
I0530 16:11:36.800683 24924 solver.cpp:228] Iteration 26120, loss = 0.242494
I0530 16:11:36.800707 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 16:11:36.800715 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0627957 (* 1 = 0.0627957 loss)
I0530 16:11:36.800719 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113933 (* 1 = 0.113933 loss)
I0530 16:11:36.800724 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0205428 (* 1 = 0.0205428 loss)
I0530 16:11:36.800727 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0660871 (* 1 = 0.0660871 loss)
I0530 16:11:36.800731 24924 sgd_solver.cpp:106] Iteration 26120, lr = 0.0002
I0530 16:12:29.397277 24924 solver.cpp:228] Iteration 26140, loss = 0.190622
I0530 16:12:29.397305 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:12:29.397315 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0256412 (* 1 = 0.0256412 loss)
I0530 16:12:29.397321 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0465884 (* 1 = 0.0465884 loss)
I0530 16:12:29.397327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195849 (* 1 = 0.0195849 loss)
I0530 16:12:29.397333 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0144407 (* 1 = 0.0144407 loss)
I0530 16:12:29.397342 24924 sgd_solver.cpp:106] Iteration 26140, lr = 0.0002
I0530 16:13:21.982019 24924 solver.cpp:228] Iteration 26160, loss = 0.261456
I0530 16:13:21.982045 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 16:13:21.982053 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.129625 (* 1 = 0.129625 loss)
I0530 16:13:21.982056 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.223392 (* 1 = 0.223392 loss)
I0530 16:13:21.982060 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0176887 (* 1 = 0.0176887 loss)
I0530 16:13:21.982064 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0441842 (* 1 = 0.0441842 loss)
I0530 16:13:21.982069 24924 sgd_solver.cpp:106] Iteration 26160, lr = 0.0002
I0530 16:14:14.456174 24924 solver.cpp:228] Iteration 26180, loss = 0.266548
I0530 16:14:14.456200 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 16:14:14.456210 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.081871 (* 1 = 0.081871 loss)
I0530 16:14:14.456216 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.111343 (* 1 = 0.111343 loss)
I0530 16:14:14.456223 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0047484 (* 1 = 0.0047484 loss)
I0530 16:14:14.456229 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0167159 (* 1 = 0.0167159 loss)
I0530 16:14:14.456236 24924 sgd_solver.cpp:106] Iteration 26180, lr = 0.0002
speed: 2.499s / iter
I0530 16:15:07.377951 24924 solver.cpp:228] Iteration 26200, loss = 0.278038
I0530 16:15:07.377979 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:15:07.377988 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0377576 (* 1 = 0.0377576 loss)
I0530 16:15:07.377995 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0519429 (* 1 = 0.0519429 loss)
I0530 16:15:07.378002 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00231627 (* 1 = 0.00231627 loss)
I0530 16:15:07.378011 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0123634 (* 1 = 0.0123634 loss)
I0530 16:15:07.378020 24924 sgd_solver.cpp:106] Iteration 26200, lr = 0.0002
I0530 16:16:00.150775 24924 solver.cpp:228] Iteration 26220, loss = 0.280303
I0530 16:16:00.150799 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 16:16:00.150807 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0323094 (* 1 = 0.0323094 loss)
I0530 16:16:00.150810 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.109153 (* 1 = 0.109153 loss)
I0530 16:16:00.150815 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00476859 (* 1 = 0.00476859 loss)
I0530 16:16:00.150817 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00796671 (* 1 = 0.00796671 loss)
I0530 16:16:00.150822 24924 sgd_solver.cpp:106] Iteration 26220, lr = 0.0002
I0530 16:16:52.665069 24924 solver.cpp:228] Iteration 26240, loss = 0.239843
I0530 16:16:52.665094 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 16:16:52.665104 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.066373 (* 1 = 0.066373 loss)
I0530 16:16:52.665112 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0650293 (* 1 = 0.0650293 loss)
I0530 16:16:52.665117 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00547147 (* 1 = 0.00547147 loss)
I0530 16:16:52.665123 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0207885 (* 1 = 0.0207885 loss)
I0530 16:16:52.665132 24924 sgd_solver.cpp:106] Iteration 26240, lr = 0.0002
I0530 16:17:45.489145 24924 solver.cpp:228] Iteration 26260, loss = 0.258182
I0530 16:17:45.489169 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 16:17:45.489177 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0168645 (* 1 = 0.0168645 loss)
I0530 16:17:45.489182 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0789965 (* 1 = 0.0789965 loss)
I0530 16:17:45.489187 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00439059 (* 1 = 0.00439059 loss)
I0530 16:17:45.489190 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00839054 (* 1 = 0.00839054 loss)
I0530 16:17:45.489195 24924 sgd_solver.cpp:106] Iteration 26260, lr = 0.0002
I0530 16:18:38.176409 24924 solver.cpp:228] Iteration 26280, loss = 0.203419
I0530 16:18:38.176434 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 16:18:38.176440 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0557483 (* 1 = 0.0557483 loss)
I0530 16:18:38.176445 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.211478 (* 1 = 0.211478 loss)
I0530 16:18:38.176447 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0141484 (* 1 = 0.0141484 loss)
I0530 16:18:38.176451 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0247944 (* 1 = 0.0247944 loss)
I0530 16:18:38.176456 24924 sgd_solver.cpp:106] Iteration 26280, lr = 0.0002
I0530 16:19:30.541048 24924 solver.cpp:228] Iteration 26300, loss = 0.323454
I0530 16:19:30.541071 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 16:19:30.541079 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0668567 (* 1 = 0.0668567 loss)
I0530 16:19:30.541085 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.138707 (* 1 = 0.138707 loss)
I0530 16:19:30.541087 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0098054 (* 1 = 0.0098054 loss)
I0530 16:19:30.541091 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0454696 (* 1 = 0.0454696 loss)
I0530 16:19:30.541096 24924 sgd_solver.cpp:106] Iteration 26300, lr = 0.0002
I0530 16:20:22.773972 24924 solver.cpp:228] Iteration 26320, loss = 0.360358
I0530 16:20:22.773998 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 16:20:22.774006 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690348 (* 1 = 0.0690348 loss)
I0530 16:20:22.774011 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101566 (* 1 = 0.101566 loss)
I0530 16:20:22.774015 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00141098 (* 1 = 0.00141098 loss)
I0530 16:20:22.774019 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.013133 (* 1 = 0.013133 loss)
I0530 16:20:22.774024 24924 sgd_solver.cpp:106] Iteration 26320, lr = 0.0002
I0530 16:21:15.704618 24924 solver.cpp:228] Iteration 26340, loss = 0.184823
I0530 16:21:15.704649 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 16:21:15.704660 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0121737 (* 1 = 0.0121737 loss)
I0530 16:21:15.704668 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.150859 (* 1 = 0.150859 loss)
I0530 16:21:15.704674 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00740071 (* 1 = 0.00740071 loss)
I0530 16:21:15.704681 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014063 (* 1 = 0.014063 loss)
I0530 16:21:15.704689 24924 sgd_solver.cpp:106] Iteration 26340, lr = 0.0002
I0530 16:22:08.347441 24924 solver.cpp:228] Iteration 26360, loss = 0.359085
I0530 16:22:08.347466 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:22:08.347473 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327412 (* 1 = 0.0327412 loss)
I0530 16:22:08.347477 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0325162 (* 1 = 0.0325162 loss)
I0530 16:22:08.347481 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00338189 (* 1 = 0.00338189 loss)
I0530 16:22:08.347484 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356745 (* 1 = 0.0356745 loss)
I0530 16:22:08.347488 24924 sgd_solver.cpp:106] Iteration 26360, lr = 0.0002
I0530 16:23:01.277761 24924 solver.cpp:228] Iteration 26380, loss = 0.173058
I0530 16:23:01.277786 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:23:01.277793 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333354 (* 1 = 0.0333354 loss)
I0530 16:23:01.277797 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0378606 (* 1 = 0.0378606 loss)
I0530 16:23:01.277801 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00126351 (* 1 = 0.00126351 loss)
I0530 16:23:01.277804 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00928173 (* 1 = 0.00928173 loss)
I0530 16:23:01.277809 24924 sgd_solver.cpp:106] Iteration 26380, lr = 0.0002
speed: 2.500s / iter
I0530 16:23:53.839618 24924 solver.cpp:228] Iteration 26400, loss = 0.331937
I0530 16:23:53.839642 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 16:23:53.839648 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0652731 (* 1 = 0.0652731 loss)
I0530 16:23:53.839651 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.093611 (* 1 = 0.093611 loss)
I0530 16:23:53.839655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00110283 (* 1 = 0.00110283 loss)
I0530 16:23:53.839658 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00283543 (* 1 = 0.00283543 loss)
I0530 16:23:53.839663 24924 sgd_solver.cpp:106] Iteration 26400, lr = 0.0002
I0530 16:24:46.292485 24924 solver.cpp:228] Iteration 26420, loss = 0.240711
I0530 16:24:46.292516 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 16:24:46.292524 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207159 (* 1 = 0.0207159 loss)
I0530 16:24:46.292528 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0806911 (* 1 = 0.0806911 loss)
I0530 16:24:46.292533 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0091403 (* 1 = 0.0091403 loss)
I0530 16:24:46.292537 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0054201 (* 1 = 0.0054201 loss)
I0530 16:24:46.292542 24924 sgd_solver.cpp:106] Iteration 26420, lr = 0.0002
I0530 16:25:38.764860 24924 solver.cpp:228] Iteration 26440, loss = 0.151621
I0530 16:25:38.764888 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:25:38.764894 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0146206 (* 1 = 0.0146206 loss)
I0530 16:25:38.764899 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0391906 (* 1 = 0.0391906 loss)
I0530 16:25:38.764901 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00828833 (* 1 = 0.00828833 loss)
I0530 16:25:38.764904 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0143018 (* 1 = 0.0143018 loss)
I0530 16:25:38.764914 24924 sgd_solver.cpp:106] Iteration 26440, lr = 0.0002
I0530 16:26:31.731937 24924 solver.cpp:228] Iteration 26460, loss = 0.210704
I0530 16:26:31.731964 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 16:26:31.731976 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0816443 (* 1 = 0.0816443 loss)
I0530 16:26:31.731984 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123156 (* 1 = 0.123156 loss)
I0530 16:26:31.731990 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00420452 (* 1 = 0.00420452 loss)
I0530 16:26:31.731997 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00611556 (* 1 = 0.00611556 loss)
I0530 16:26:31.732005 24924 sgd_solver.cpp:106] Iteration 26460, lr = 0.0002
I0530 16:27:24.036279 24924 solver.cpp:228] Iteration 26480, loss = 0.394165
I0530 16:27:24.036301 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 16:27:24.036309 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.133141 (* 1 = 0.133141 loss)
I0530 16:27:24.036314 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.173457 (* 1 = 0.173457 loss)
I0530 16:27:24.036317 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00969182 (* 1 = 0.00969182 loss)
I0530 16:27:24.036321 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0301719 (* 1 = 0.0301719 loss)
I0530 16:27:24.036326 24924 sgd_solver.cpp:106] Iteration 26480, lr = 0.0002
I0530 16:28:16.369335 24924 solver.cpp:228] Iteration 26500, loss = 0.281475
I0530 16:28:16.369364 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 16:28:16.369370 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.166418 (* 1 = 0.166418 loss)
I0530 16:28:16.369374 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.248695 (* 1 = 0.248695 loss)
I0530 16:28:16.369379 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01374 (* 1 = 0.01374 loss)
I0530 16:28:16.369382 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0503864 (* 1 = 0.0503864 loss)
I0530 16:28:16.369387 24924 sgd_solver.cpp:106] Iteration 26500, lr = 0.0002
I0530 16:29:09.825304 24924 solver.cpp:228] Iteration 26520, loss = 0.232598
I0530 16:29:09.825330 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 16:29:09.825337 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0683456 (* 1 = 0.0683456 loss)
I0530 16:29:09.825340 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133142 (* 1 = 0.133142 loss)
I0530 16:29:09.825345 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00687157 (* 1 = 0.00687157 loss)
I0530 16:29:09.825347 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0401192 (* 1 = 0.0401192 loss)
I0530 16:29:09.825352 24924 sgd_solver.cpp:106] Iteration 26520, lr = 0.0002
I0530 16:30:03.510529 24924 solver.cpp:228] Iteration 26540, loss = 0.260535
I0530 16:30:03.510560 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 16:30:03.510571 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0793516 (* 1 = 0.0793516 loss)
I0530 16:30:03.510577 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0947995 (* 1 = 0.0947995 loss)
I0530 16:30:03.510583 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00405036 (* 1 = 0.00405036 loss)
I0530 16:30:03.510588 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0201102 (* 1 = 0.0201102 loss)
I0530 16:30:03.510596 24924 sgd_solver.cpp:106] Iteration 26540, lr = 0.0002
I0530 16:30:59.663061 24924 solver.cpp:228] Iteration 26560, loss = 0.374052
I0530 16:30:59.663087 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 16:30:59.663094 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.268666 (* 1 = 0.268666 loss)
I0530 16:30:59.663098 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.482463 (* 1 = 0.482463 loss)
I0530 16:30:59.663101 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.039802 (* 1 = 0.039802 loss)
I0530 16:30:59.663105 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0820216 (* 1 = 0.0820216 loss)
I0530 16:30:59.663110 24924 sgd_solver.cpp:106] Iteration 26560, lr = 0.0002
I0530 16:31:52.853668 24924 solver.cpp:228] Iteration 26580, loss = 0.299036
I0530 16:31:52.853694 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 16:31:52.853701 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00952238 (* 1 = 0.00952238 loss)
I0530 16:31:52.853706 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.144389 (* 1 = 0.144389 loss)
I0530 16:31:52.853709 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0104833 (* 1 = 0.0104833 loss)
I0530 16:31:52.853713 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00434799 (* 1 = 0.00434799 loss)
I0530 16:31:52.853718 24924 sgd_solver.cpp:106] Iteration 26580, lr = 0.0002
speed: 2.501s / iter
I0530 16:32:45.772317 24924 solver.cpp:228] Iteration 26600, loss = 0.430649
I0530 16:32:45.772349 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.648438
I0530 16:32:45.772359 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.717161 (* 1 = 0.717161 loss)
I0530 16:32:45.772367 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.600046 (* 1 = 0.600046 loss)
I0530 16:32:45.772372 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.075887 (* 1 = 0.075887 loss)
I0530 16:32:45.772379 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.337269 (* 1 = 0.337269 loss)
I0530 16:32:45.772388 24924 sgd_solver.cpp:106] Iteration 26600, lr = 0.0002
I0530 16:33:38.567553 24924 solver.cpp:228] Iteration 26620, loss = 0.210734
I0530 16:33:38.567581 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:33:38.567589 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748046 (* 1 = 0.0748046 loss)
I0530 16:33:38.567595 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0641429 (* 1 = 0.0641429 loss)
I0530 16:33:38.567601 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236391 (* 1 = 0.00236391 loss)
I0530 16:33:38.567605 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0289966 (* 1 = 0.0289966 loss)
I0530 16:33:38.567610 24924 sgd_solver.cpp:106] Iteration 26620, lr = 0.0002
I0530 16:34:30.472296 24924 solver.cpp:228] Iteration 26640, loss = 0.261235
I0530 16:34:30.472321 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 16:34:30.472327 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.204862 (* 1 = 0.204862 loss)
I0530 16:34:30.472332 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.22548 (* 1 = 0.22548 loss)
I0530 16:34:30.472337 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0300269 (* 1 = 0.0300269 loss)
I0530 16:34:30.472339 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0522431 (* 1 = 0.0522431 loss)
I0530 16:34:30.472344 24924 sgd_solver.cpp:106] Iteration 26640, lr = 0.0002
I0530 16:35:22.993242 24924 solver.cpp:228] Iteration 26660, loss = 0.274165
I0530 16:35:22.993266 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 16:35:22.993274 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.042311 (* 1 = 0.042311 loss)
I0530 16:35:22.993278 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.119171 (* 1 = 0.119171 loss)
I0530 16:35:22.993281 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0020342 (* 1 = 0.0020342 loss)
I0530 16:35:22.993284 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0119339 (* 1 = 0.0119339 loss)
I0530 16:35:22.993289 24924 sgd_solver.cpp:106] Iteration 26660, lr = 0.0002
I0530 16:36:15.071705 24924 solver.cpp:228] Iteration 26680, loss = 0.296068
I0530 16:36:15.071734 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 16:36:15.071744 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.144712 (* 1 = 0.144712 loss)
I0530 16:36:15.071750 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.181957 (* 1 = 0.181957 loss)
I0530 16:36:15.071756 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0153067 (* 1 = 0.0153067 loss)
I0530 16:36:15.071763 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0235452 (* 1 = 0.0235452 loss)
I0530 16:36:15.071770 24924 sgd_solver.cpp:106] Iteration 26680, lr = 0.0002
I0530 16:37:07.462339 24924 solver.cpp:228] Iteration 26700, loss = 0.295916
I0530 16:37:07.462363 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 16:37:07.462370 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00038803 (* 1 = 0.00038803 loss)
I0530 16:37:07.462374 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0558382 (* 1 = 0.0558382 loss)
I0530 16:37:07.462378 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.030168 (* 1 = 0.030168 loss)
I0530 16:37:07.462380 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0553388 (* 1 = 0.0553388 loss)
I0530 16:37:07.462385 24924 sgd_solver.cpp:106] Iteration 26700, lr = 0.0002
I0530 16:37:59.881943 24924 solver.cpp:228] Iteration 26720, loss = 0.14247
I0530 16:37:59.881969 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 16:37:59.881978 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0178429 (* 1 = 0.0178429 loss)
I0530 16:37:59.881983 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0329564 (* 1 = 0.0329564 loss)
I0530 16:37:59.881986 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107376 (* 1 = 0.00107376 loss)
I0530 16:37:59.881990 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00581578 (* 1 = 0.00581578 loss)
I0530 16:37:59.881995 24924 sgd_solver.cpp:106] Iteration 26720, lr = 0.0002
I0530 16:38:52.405045 24924 solver.cpp:228] Iteration 26740, loss = 0.455187
I0530 16:38:52.405071 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 16:38:52.405077 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.175742 (* 1 = 0.175742 loss)
I0530 16:38:52.405081 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.186254 (* 1 = 0.186254 loss)
I0530 16:38:52.405086 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00654152 (* 1 = 0.00654152 loss)
I0530 16:38:52.405088 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0405019 (* 1 = 0.0405019 loss)
I0530 16:38:52.405093 24924 sgd_solver.cpp:106] Iteration 26740, lr = 0.0002
I0530 16:39:44.911443 24924 solver.cpp:228] Iteration 26760, loss = 0.368952
I0530 16:39:44.911469 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 16:39:44.911476 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.115417 (* 1 = 0.115417 loss)
I0530 16:39:44.911480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.314919 (* 1 = 0.314919 loss)
I0530 16:39:44.911484 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0342815 (* 1 = 0.0342815 loss)
I0530 16:39:44.911487 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0338741 (* 1 = 0.0338741 loss)
I0530 16:39:44.911492 24924 sgd_solver.cpp:106] Iteration 26760, lr = 0.0002
I0530 16:40:37.003644 24924 solver.cpp:228] Iteration 26780, loss = 0.299947
I0530 16:40:37.003669 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 16:40:37.003676 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.175957 (* 1 = 0.175957 loss)
I0530 16:40:37.003680 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.276439 (* 1 = 0.276439 loss)
I0530 16:40:37.003684 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0307917 (* 1 = 0.0307917 loss)
I0530 16:40:37.003688 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0291938 (* 1 = 0.0291938 loss)
I0530 16:40:37.003693 24924 sgd_solver.cpp:106] Iteration 26780, lr = 0.0002
speed: 2.502s / iter
I0530 16:41:29.711804 24924 solver.cpp:228] Iteration 26800, loss = 0.393386
I0530 16:41:29.711827 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 16:41:29.711834 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0650749 (* 1 = 0.0650749 loss)
I0530 16:41:29.711838 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.176452 (* 1 = 0.176452 loss)
I0530 16:41:29.711841 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0073208 (* 1 = 0.0073208 loss)
I0530 16:41:29.711845 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327632 (* 1 = 0.0327632 loss)
I0530 16:41:29.711849 24924 sgd_solver.cpp:106] Iteration 26800, lr = 0.0002
I0530 16:42:21.684376 24924 solver.cpp:228] Iteration 26820, loss = 0.334697
I0530 16:42:21.684406 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 16:42:21.684417 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0874006 (* 1 = 0.0874006 loss)
I0530 16:42:21.684423 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.169753 (* 1 = 0.169753 loss)
I0530 16:42:21.684429 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00290964 (* 1 = 0.00290964 loss)
I0530 16:42:21.684435 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00902641 (* 1 = 0.00902641 loss)
I0530 16:42:21.684443 24924 sgd_solver.cpp:106] Iteration 26820, lr = 0.0002
I0530 16:43:13.974545 24924 solver.cpp:228] Iteration 26840, loss = 0.52032
I0530 16:43:13.974576 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 16:43:13.974586 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.145361 (* 1 = 0.145361 loss)
I0530 16:43:13.974592 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.239647 (* 1 = 0.239647 loss)
I0530 16:43:13.974598 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0100076 (* 1 = 0.0100076 loss)
I0530 16:43:13.974604 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372885 (* 1 = 0.0372885 loss)
I0530 16:43:13.974611 24924 sgd_solver.cpp:106] Iteration 26840, lr = 0.0002
I0530 16:44:05.954015 24924 solver.cpp:228] Iteration 26860, loss = 0.283016
I0530 16:44:05.954039 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 16:44:05.954048 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0295685 (* 1 = 0.0295685 loss)
I0530 16:44:05.954052 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0904977 (* 1 = 0.0904977 loss)
I0530 16:44:05.954056 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0182533 (* 1 = 0.0182533 loss)
I0530 16:44:05.954059 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0186287 (* 1 = 0.0186287 loss)
I0530 16:44:05.954064 24924 sgd_solver.cpp:106] Iteration 26860, lr = 0.0002
I0530 16:44:58.388342 24924 solver.cpp:228] Iteration 26880, loss = 0.24363
I0530 16:44:58.388370 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 16:44:58.388377 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0574462 (* 1 = 0.0574462 loss)
I0530 16:44:58.388381 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104702 (* 1 = 0.104702 loss)
I0530 16:44:58.388386 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00179285 (* 1 = 0.00179285 loss)
I0530 16:44:58.388388 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00850444 (* 1 = 0.00850444 loss)
I0530 16:44:58.388393 24924 sgd_solver.cpp:106] Iteration 26880, lr = 0.0002
I0530 16:45:50.860363 24924 solver.cpp:228] Iteration 26900, loss = 0.526118
I0530 16:45:50.860388 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 16:45:50.860395 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.126791 (* 1 = 0.126791 loss)
I0530 16:45:50.860400 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.179944 (* 1 = 0.179944 loss)
I0530 16:45:50.860404 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0168739 (* 1 = 0.0168739 loss)
I0530 16:45:50.860409 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0373218 (* 1 = 0.0373218 loss)
I0530 16:45:50.860412 24924 sgd_solver.cpp:106] Iteration 26900, lr = 0.0002
I0530 16:46:43.376581 24924 solver.cpp:228] Iteration 26920, loss = 0.316128
I0530 16:46:43.376610 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 16:46:43.376616 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.142973 (* 1 = 0.142973 loss)
I0530 16:46:43.376621 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.125769 (* 1 = 0.125769 loss)
I0530 16:46:43.376623 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00625823 (* 1 = 0.00625823 loss)
I0530 16:46:43.376627 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0191192 (* 1 = 0.0191192 loss)
I0530 16:46:43.376632 24924 sgd_solver.cpp:106] Iteration 26920, lr = 0.0002
I0530 16:47:37.274953 24924 solver.cpp:228] Iteration 26940, loss = 0.202383
I0530 16:47:37.274981 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 16:47:37.274988 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00526266 (* 1 = 0.00526266 loss)
I0530 16:47:37.274993 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0240393 (* 1 = 0.0240393 loss)
I0530 16:47:37.274996 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00755206 (* 1 = 0.00755206 loss)
I0530 16:47:37.274999 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00643547 (* 1 = 0.00643547 loss)
I0530 16:47:37.275005 24924 sgd_solver.cpp:106] Iteration 26940, lr = 0.0002
I0530 16:48:29.741274 24924 solver.cpp:228] Iteration 26960, loss = 0.281172
I0530 16:48:29.741300 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:48:29.741307 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.111455 (* 1 = 0.111455 loss)
I0530 16:48:29.741312 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.12808 (* 1 = 0.12808 loss)
I0530 16:48:29.741317 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128343 (* 1 = 0.0128343 loss)
I0530 16:48:29.741320 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0300578 (* 1 = 0.0300578 loss)
I0530 16:48:29.741325 24924 sgd_solver.cpp:106] Iteration 26960, lr = 0.0002
I0530 16:49:22.155345 24924 solver.cpp:228] Iteration 26980, loss = 0.263197
I0530 16:49:22.155380 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 16:49:22.155390 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268795 (* 1 = 0.0268795 loss)
I0530 16:49:22.155397 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0991077 (* 1 = 0.0991077 loss)
I0530 16:49:22.155403 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0105882 (* 1 = 0.0105882 loss)
I0530 16:49:22.155409 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00828947 (* 1 = 0.00828947 loss)
I0530 16:49:22.155416 24924 sgd_solver.cpp:106] Iteration 26980, lr = 0.0002
speed: 2.503s / iter
I0530 16:50:15.149441 24924 solver.cpp:228] Iteration 27000, loss = 0.287978
I0530 16:50:15.149471 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 16:50:15.149482 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.196403 (* 1 = 0.196403 loss)
I0530 16:50:15.149488 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.398463 (* 1 = 0.398463 loss)
I0530 16:50:15.149495 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00883607 (* 1 = 0.00883607 loss)
I0530 16:50:15.149503 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0404491 (* 1 = 0.0404491 loss)
I0530 16:50:15.149513 24924 sgd_solver.cpp:106] Iteration 27000, lr = 0.0002
I0530 16:51:08.595266 24924 solver.cpp:228] Iteration 27020, loss = 0.300926
I0530 16:51:08.595291 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:51:08.595299 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0511273 (* 1 = 0.0511273 loss)
I0530 16:51:08.595302 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0870163 (* 1 = 0.0870163 loss)
I0530 16:51:08.595306 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00226521 (* 1 = 0.00226521 loss)
I0530 16:51:08.595309 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102098 (* 1 = 0.0102098 loss)
I0530 16:51:08.595315 24924 sgd_solver.cpp:106] Iteration 27020, lr = 0.0002
I0530 16:52:01.701282 24924 solver.cpp:228] Iteration 27040, loss = 0.189987
I0530 16:52:01.701305 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 16:52:01.701313 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.124075 (* 1 = 0.124075 loss)
I0530 16:52:01.701316 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.28288 (* 1 = 0.28288 loss)
I0530 16:52:01.701320 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00937924 (* 1 = 0.00937924 loss)
I0530 16:52:01.701323 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0691799 (* 1 = 0.0691799 loss)
I0530 16:52:01.701328 24924 sgd_solver.cpp:106] Iteration 27040, lr = 0.0002
I0530 16:52:54.403275 24924 solver.cpp:228] Iteration 27060, loss = 0.245776
I0530 16:52:54.403301 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 16:52:54.403308 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.159569 (* 1 = 0.159569 loss)
I0530 16:52:54.403312 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.334787 (* 1 = 0.334787 loss)
I0530 16:52:54.403317 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0134927 (* 1 = 0.0134927 loss)
I0530 16:52:54.403321 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0512906 (* 1 = 0.0512906 loss)
I0530 16:52:54.403326 24924 sgd_solver.cpp:106] Iteration 27060, lr = 0.0002
I0530 16:53:46.542235 24924 solver.cpp:228] Iteration 27080, loss = 0.291147
I0530 16:53:46.542258 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 16:53:46.542265 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0764146 (* 1 = 0.0764146 loss)
I0530 16:53:46.542269 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0968542 (* 1 = 0.0968542 loss)
I0530 16:53:46.542273 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00854495 (* 1 = 0.00854495 loss)
I0530 16:53:46.542276 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0146913 (* 1 = 0.0146913 loss)
I0530 16:53:46.542281 24924 sgd_solver.cpp:106] Iteration 27080, lr = 0.0002
I0530 16:54:38.402896 24924 solver.cpp:228] Iteration 27100, loss = 0.312255
I0530 16:54:38.402921 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 16:54:38.402928 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109386 (* 1 = 0.109386 loss)
I0530 16:54:38.402933 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.20606 (* 1 = 0.20606 loss)
I0530 16:54:38.402937 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00365239 (* 1 = 0.00365239 loss)
I0530 16:54:38.402941 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189505 (* 1 = 0.0189505 loss)
I0530 16:54:38.402946 24924 sgd_solver.cpp:106] Iteration 27100, lr = 0.0002
I0530 16:55:30.935699 24924 solver.cpp:228] Iteration 27120, loss = 0.229512
I0530 16:55:30.935722 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 16:55:30.935729 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0879228 (* 1 = 0.0879228 loss)
I0530 16:55:30.935734 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.104811 (* 1 = 0.104811 loss)
I0530 16:55:30.935737 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103339 (* 1 = 0.0103339 loss)
I0530 16:55:30.935741 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0163472 (* 1 = 0.0163472 loss)
I0530 16:55:30.935745 24924 sgd_solver.cpp:106] Iteration 27120, lr = 0.0002
I0530 16:56:23.522568 24924 solver.cpp:228] Iteration 27140, loss = 0.279001
I0530 16:56:23.522601 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 16:56:23.522613 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.332468 (* 1 = 0.332468 loss)
I0530 16:56:23.522619 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.438168 (* 1 = 0.438168 loss)
I0530 16:56:23.522626 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0295902 (* 1 = 0.0295902 loss)
I0530 16:56:23.522632 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.166733 (* 1 = 0.166733 loss)
I0530 16:56:23.522642 24924 sgd_solver.cpp:106] Iteration 27140, lr = 0.0002
I0530 16:57:16.225762 24924 solver.cpp:228] Iteration 27160, loss = 0.337597
I0530 16:57:16.225790 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 16:57:16.225797 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.318931 (* 1 = 0.318931 loss)
I0530 16:57:16.225801 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.282831 (* 1 = 0.282831 loss)
I0530 16:57:16.225805 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0120567 (* 1 = 0.0120567 loss)
I0530 16:57:16.225808 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.074031 (* 1 = 0.074031 loss)
I0530 16:57:16.225814 24924 sgd_solver.cpp:106] Iteration 27160, lr = 0.0002
I0530 16:58:08.840494 24924 solver.cpp:228] Iteration 27180, loss = 0.242657
I0530 16:58:08.840520 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 16:58:08.840530 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0559072 (* 1 = 0.0559072 loss)
I0530 16:58:08.840536 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0494277 (* 1 = 0.0494277 loss)
I0530 16:58:08.840541 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00384296 (* 1 = 0.00384296 loss)
I0530 16:58:08.840548 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00640025 (* 1 = 0.00640025 loss)
I0530 16:58:08.840554 24924 sgd_solver.cpp:106] Iteration 27180, lr = 0.0002
speed: 2.504s / iter
I0530 16:59:01.696681 24924 solver.cpp:228] Iteration 27200, loss = 0.324522
I0530 16:59:01.696718 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 16:59:01.696729 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0549058 (* 1 = 0.0549058 loss)
I0530 16:59:01.696738 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0755551 (* 1 = 0.0755551 loss)
I0530 16:59:01.696744 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00509629 (* 1 = 0.00509629 loss)
I0530 16:59:01.696775 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0079063 (* 1 = 0.0079063 loss)
I0530 16:59:01.696792 24924 sgd_solver.cpp:106] Iteration 27200, lr = 0.0002
I0530 16:59:54.535892 24924 solver.cpp:228] Iteration 27220, loss = 0.29447
I0530 16:59:54.535936 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 16:59:54.535945 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0362142 (* 1 = 0.0362142 loss)
I0530 16:59:54.535950 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0788845 (* 1 = 0.0788845 loss)
I0530 16:59:54.535956 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184914 (* 1 = 0.00184914 loss)
I0530 16:59:54.535959 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00946272 (* 1 = 0.00946272 loss)
I0530 16:59:54.535966 24924 sgd_solver.cpp:106] Iteration 27220, lr = 0.0002
I0530 17:00:47.293112 24924 solver.cpp:228] Iteration 27240, loss = 0.38406
I0530 17:00:47.293135 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:00:47.293143 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0845037 (* 1 = 0.0845037 loss)
I0530 17:00:47.293146 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.142185 (* 1 = 0.142185 loss)
I0530 17:00:47.293149 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158218 (* 1 = 0.0158218 loss)
I0530 17:00:47.293154 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0468763 (* 1 = 0.0468763 loss)
I0530 17:00:47.293157 24924 sgd_solver.cpp:106] Iteration 27240, lr = 0.0002
I0530 17:01:40.423199 24924 solver.cpp:228] Iteration 27260, loss = 0.245277
I0530 17:01:40.423228 24924 solver.cpp:244]     Train net output #0: accuarcy = 1
I0530 17:01:40.423239 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0333538 (* 1 = 0.0333538 loss)
I0530 17:01:40.423245 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0324548 (* 1 = 0.0324548 loss)
I0530 17:01:40.423251 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000790933 (* 1 = 0.000790933 loss)
I0530 17:01:40.423257 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00324836 (* 1 = 0.00324836 loss)
I0530 17:01:40.423264 24924 sgd_solver.cpp:106] Iteration 27260, lr = 0.0002
I0530 17:02:33.300027 24924 solver.cpp:228] Iteration 27280, loss = 0.379222
I0530 17:02:33.300050 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:02:33.300057 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0485405 (* 1 = 0.0485405 loss)
I0530 17:02:33.300065 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0543921 (* 1 = 0.0543921 loss)
I0530 17:02:33.300071 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00116069 (* 1 = 0.00116069 loss)
I0530 17:02:33.300074 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00541103 (* 1 = 0.00541103 loss)
I0530 17:02:33.300079 24924 sgd_solver.cpp:106] Iteration 27280, lr = 0.0002
I0530 17:03:26.035544 24924 solver.cpp:228] Iteration 27300, loss = 0.181371
I0530 17:03:26.035567 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 17:03:26.035574 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.133441 (* 1 = 0.133441 loss)
I0530 17:03:26.035578 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.152264 (* 1 = 0.152264 loss)
I0530 17:03:26.035583 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000976658 (* 1 = 0.000976658 loss)
I0530 17:03:26.035585 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0341053 (* 1 = 0.0341053 loss)
I0530 17:03:26.035590 24924 sgd_solver.cpp:106] Iteration 27300, lr = 0.0002
I0530 17:04:19.103442 24924 solver.cpp:228] Iteration 27320, loss = 0.257259
I0530 17:04:19.103467 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 17:04:19.103473 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.128556 (* 1 = 0.128556 loss)
I0530 17:04:19.103477 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.212615 (* 1 = 0.212615 loss)
I0530 17:04:19.103482 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00999003 (* 1 = 0.00999003 loss)
I0530 17:04:19.103484 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0198946 (* 1 = 0.0198946 loss)
I0530 17:04:19.103489 24924 sgd_solver.cpp:106] Iteration 27320, lr = 0.0002
I0530 17:05:11.636672 24924 solver.cpp:228] Iteration 27340, loss = 0.294672
I0530 17:05:11.636703 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 17:05:11.636710 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.109173 (* 1 = 0.109173 loss)
I0530 17:05:11.636714 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.346194 (* 1 = 0.346194 loss)
I0530 17:05:11.636718 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0204238 (* 1 = 0.0204238 loss)
I0530 17:05:11.636723 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0469819 (* 1 = 0.0469819 loss)
I0530 17:05:11.636729 24924 sgd_solver.cpp:106] Iteration 27340, lr = 0.0002
I0530 17:06:04.542882 24924 solver.cpp:228] Iteration 27360, loss = 0.254657
I0530 17:06:04.542906 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 17:06:04.542914 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0123604 (* 1 = 0.0123604 loss)
I0530 17:06:04.542922 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124693 (* 1 = 0.124693 loss)
I0530 17:06:04.542927 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014068 (* 1 = 0.014068 loss)
I0530 17:06:04.542932 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00553883 (* 1 = 0.00553883 loss)
I0530 17:06:04.542938 24924 sgd_solver.cpp:106] Iteration 27360, lr = 0.0002
I0530 17:06:56.696063 24924 solver.cpp:228] Iteration 27380, loss = 0.242481
I0530 17:06:56.696087 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 17:06:56.696095 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.042592 (* 1 = 0.042592 loss)
I0530 17:06:56.696100 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.138813 (* 1 = 0.138813 loss)
I0530 17:06:56.696105 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00217981 (* 1 = 0.00217981 loss)
I0530 17:06:56.696107 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00682844 (* 1 = 0.00682844 loss)
I0530 17:06:56.696112 24924 sgd_solver.cpp:106] Iteration 27380, lr = 0.0002
speed: 2.505s / iter
I0530 17:07:49.054611 24924 solver.cpp:228] Iteration 27400, loss = 0.435909
I0530 17:07:49.054639 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:07:49.054648 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0554444 (* 1 = 0.0554444 loss)
I0530 17:07:49.054652 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0829305 (* 1 = 0.0829305 loss)
I0530 17:07:49.054656 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116484 (* 1 = 0.0116484 loss)
I0530 17:07:49.054661 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0101827 (* 1 = 0.0101827 loss)
I0530 17:07:49.054666 24924 sgd_solver.cpp:106] Iteration 27400, lr = 0.0002
I0530 17:08:42.083679 24924 solver.cpp:228] Iteration 27420, loss = 0.204198
I0530 17:08:42.083703 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:08:42.083711 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.061254 (* 1 = 0.061254 loss)
I0530 17:08:42.083715 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0657983 (* 1 = 0.0657983 loss)
I0530 17:08:42.083719 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00159939 (* 1 = 0.00159939 loss)
I0530 17:08:42.083722 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127342 (* 1 = 0.0127342 loss)
I0530 17:08:42.083726 24924 sgd_solver.cpp:106] Iteration 27420, lr = 0.0002
I0530 17:09:34.561614 24924 solver.cpp:228] Iteration 27440, loss = 0.304465
I0530 17:09:34.561638 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 17:09:34.561645 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.181154 (* 1 = 0.181154 loss)
I0530 17:09:34.561650 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.35176 (* 1 = 0.35176 loss)
I0530 17:09:34.561652 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0346776 (* 1 = 0.0346776 loss)
I0530 17:09:34.561656 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0651594 (* 1 = 0.0651594 loss)
I0530 17:09:34.561661 24924 sgd_solver.cpp:106] Iteration 27440, lr = 0.0002
I0530 17:10:26.957003 24924 solver.cpp:228] Iteration 27460, loss = 0.246294
I0530 17:10:26.957051 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:10:26.957062 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0656627 (* 1 = 0.0656627 loss)
I0530 17:10:26.957068 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0570323 (* 1 = 0.0570323 loss)
I0530 17:10:26.957073 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00223255 (* 1 = 0.00223255 loss)
I0530 17:10:26.957078 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00853494 (* 1 = 0.00853494 loss)
I0530 17:10:26.957087 24924 sgd_solver.cpp:106] Iteration 27460, lr = 0.0002
I0530 17:11:19.392724 24924 solver.cpp:228] Iteration 27480, loss = 0.231574
I0530 17:11:19.392747 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:11:19.392755 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0106598 (* 1 = 0.0106598 loss)
I0530 17:11:19.392758 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0492595 (* 1 = 0.0492595 loss)
I0530 17:11:19.392762 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00794635 (* 1 = 0.00794635 loss)
I0530 17:11:19.392765 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0328218 (* 1 = 0.0328218 loss)
I0530 17:11:19.392769 24924 sgd_solver.cpp:106] Iteration 27480, lr = 0.0002
I0530 17:12:11.773028 24924 solver.cpp:228] Iteration 27500, loss = 0.241323
I0530 17:12:11.773057 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 17:12:11.773068 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0693034 (* 1 = 0.0693034 loss)
I0530 17:12:11.773075 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0948922 (* 1 = 0.0948922 loss)
I0530 17:12:11.773080 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0130149 (* 1 = 0.0130149 loss)
I0530 17:12:11.773087 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0225807 (* 1 = 0.0225807 loss)
I0530 17:12:11.773094 24924 sgd_solver.cpp:106] Iteration 27500, lr = 0.0002
I0530 17:13:04.172374 24924 solver.cpp:228] Iteration 27520, loss = 0.180071
I0530 17:13:04.172402 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 17:13:04.172410 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0476913 (* 1 = 0.0476913 loss)
I0530 17:13:04.172413 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.12606 (* 1 = 0.12606 loss)
I0530 17:13:04.172417 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00329797 (* 1 = 0.00329797 loss)
I0530 17:13:04.172420 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.012213 (* 1 = 0.012213 loss)
I0530 17:13:04.172426 24924 sgd_solver.cpp:106] Iteration 27520, lr = 0.0002
I0530 17:13:56.629240 24924 solver.cpp:228] Iteration 27540, loss = 0.501931
I0530 17:13:56.629267 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.328125
I0530 17:13:56.629277 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.81265 (* 1 = 0.81265 loss)
I0530 17:13:56.629283 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.856531 (* 1 = 0.856531 loss)
I0530 17:13:56.629289 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.147057 (* 1 = 0.147057 loss)
I0530 17:13:56.629297 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.426101 (* 1 = 0.426101 loss)
I0530 17:13:56.629305 24924 sgd_solver.cpp:106] Iteration 27540, lr = 0.0002
I0530 17:14:49.082324 24924 solver.cpp:228] Iteration 27560, loss = 0.152864
I0530 17:14:49.082347 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:14:49.082353 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0798299 (* 1 = 0.0798299 loss)
I0530 17:14:49.082357 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0435867 (* 1 = 0.0435867 loss)
I0530 17:14:49.082360 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0077346 (* 1 = 0.0077346 loss)
I0530 17:14:49.082363 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0231826 (* 1 = 0.0231826 loss)
I0530 17:14:49.082368 24924 sgd_solver.cpp:106] Iteration 27560, lr = 0.0002
I0530 17:15:41.485805 24924 solver.cpp:228] Iteration 27580, loss = 0.235982
I0530 17:15:41.485832 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:15:41.485841 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.10232 (* 1 = 0.10232 loss)
I0530 17:15:41.485844 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143718 (* 1 = 0.143718 loss)
I0530 17:15:41.485848 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.015631 (* 1 = 0.015631 loss)
I0530 17:15:41.485852 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0358508 (* 1 = 0.0358508 loss)
I0530 17:15:41.485857 24924 sgd_solver.cpp:106] Iteration 27580, lr = 0.0002
speed: 2.506s / iter
I0530 17:16:33.868386 24924 solver.cpp:228] Iteration 27600, loss = 0.450893
I0530 17:16:33.868413 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 17:16:33.868422 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.161591 (* 1 = 0.161591 loss)
I0530 17:16:33.868427 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.211766 (* 1 = 0.211766 loss)
I0530 17:16:33.868430 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00592709 (* 1 = 0.00592709 loss)
I0530 17:16:33.868434 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0356993 (* 1 = 0.0356993 loss)
I0530 17:16:33.868439 24924 sgd_solver.cpp:106] Iteration 27600, lr = 0.0002
I0530 17:17:26.236821 24924 solver.cpp:228] Iteration 27620, loss = 0.318583
I0530 17:17:26.236847 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 17:17:26.236855 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.186438 (* 1 = 0.186438 loss)
I0530 17:17:26.236858 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.190104 (* 1 = 0.190104 loss)
I0530 17:17:26.236862 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00360497 (* 1 = 0.00360497 loss)
I0530 17:17:26.236866 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0248599 (* 1 = 0.0248599 loss)
I0530 17:17:26.236871 24924 sgd_solver.cpp:106] Iteration 27620, lr = 0.0002
I0530 17:18:18.712335 24924 solver.cpp:228] Iteration 27640, loss = 0.243547
I0530 17:18:18.712361 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:18:18.712369 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0909036 (* 1 = 0.0909036 loss)
I0530 17:18:18.712373 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0581668 (* 1 = 0.0581668 loss)
I0530 17:18:18.712376 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817504 (* 1 = 0.00817504 loss)
I0530 17:18:18.712380 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206712 (* 1 = 0.0206712 loss)
I0530 17:18:18.712385 24924 sgd_solver.cpp:106] Iteration 27640, lr = 0.0002
I0530 17:19:11.135623 24924 solver.cpp:228] Iteration 27660, loss = 0.29886
I0530 17:19:11.135648 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 17:19:11.135656 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13474 (* 1 = 0.13474 loss)
I0530 17:19:11.135660 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.394151 (* 1 = 0.394151 loss)
I0530 17:19:11.135663 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0426552 (* 1 = 0.0426552 loss)
I0530 17:19:11.135666 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0912158 (* 1 = 0.0912158 loss)
I0530 17:19:11.135671 24924 sgd_solver.cpp:106] Iteration 27660, lr = 0.0002
I0530 17:20:03.579864 24924 solver.cpp:228] Iteration 27680, loss = 0.201015
I0530 17:20:03.579892 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 17:20:03.579900 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000140554 (* 1 = 0.000140554 loss)
I0530 17:20:03.579905 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0316681 (* 1 = 0.0316681 loss)
I0530 17:20:03.579910 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000925407 (* 1 = 0.000925407 loss)
I0530 17:20:03.579913 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0159262 (* 1 = 0.0159262 loss)
I0530 17:20:03.579919 24924 sgd_solver.cpp:106] Iteration 27680, lr = 0.0002
I0530 17:20:56.394743 24924 solver.cpp:228] Iteration 27700, loss = 0.459619
I0530 17:20:56.394767 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 17:20:56.394774 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0496993 (* 1 = 0.0496993 loss)
I0530 17:20:56.394778 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.127392 (* 1 = 0.127392 loss)
I0530 17:20:56.394783 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00391964 (* 1 = 0.00391964 loss)
I0530 17:20:56.394785 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125202 (* 1 = 0.0125202 loss)
I0530 17:20:56.394790 24924 sgd_solver.cpp:106] Iteration 27700, lr = 0.0002
I0530 17:21:49.859220 24924 solver.cpp:228] Iteration 27720, loss = 0.288539
I0530 17:21:49.859258 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 17:21:49.859267 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00729889 (* 1 = 0.00729889 loss)
I0530 17:21:49.859272 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0767429 (* 1 = 0.0767429 loss)
I0530 17:21:49.859277 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00713787 (* 1 = 0.00713787 loss)
I0530 17:21:49.859280 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0347488 (* 1 = 0.0347488 loss)
I0530 17:21:49.859287 24924 sgd_solver.cpp:106] Iteration 27720, lr = 0.0002
I0530 17:22:42.755714 24924 solver.cpp:228] Iteration 27740, loss = 0.280788
I0530 17:22:42.755738 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:22:42.755744 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0490586 (* 1 = 0.0490586 loss)
I0530 17:22:42.755748 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.070835 (* 1 = 0.070835 loss)
I0530 17:22:42.755753 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000475666 (* 1 = 0.000475666 loss)
I0530 17:22:42.755755 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019671 (* 1 = 0.019671 loss)
I0530 17:22:42.755760 24924 sgd_solver.cpp:106] Iteration 27740, lr = 0.0002
I0530 17:23:35.228678 24924 solver.cpp:228] Iteration 27760, loss = 0.283506
I0530 17:23:35.228703 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 17:23:35.228709 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0595944 (* 1 = 0.0595944 loss)
I0530 17:23:35.228713 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124198 (* 1 = 0.124198 loss)
I0530 17:23:35.228716 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148617 (* 1 = 0.0148617 loss)
I0530 17:23:35.228719 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0658343 (* 1 = 0.0658343 loss)
I0530 17:23:35.228724 24924 sgd_solver.cpp:106] Iteration 27760, lr = 0.0002
I0530 17:24:28.095374 24924 solver.cpp:228] Iteration 27780, loss = 0.465583
I0530 17:24:28.095398 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:24:28.095407 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0246151 (* 1 = 0.0246151 loss)
I0530 17:24:28.095410 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100515 (* 1 = 0.100515 loss)
I0530 17:24:28.095414 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0162622 (* 1 = 0.0162622 loss)
I0530 17:24:28.095418 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00563558 (* 1 = 0.00563558 loss)
I0530 17:24:28.095423 24924 sgd_solver.cpp:106] Iteration 27780, lr = 0.0002
speed: 2.507s / iter
I0530 17:25:20.850630 24924 solver.cpp:228] Iteration 27800, loss = 0.343733
I0530 17:25:20.850652 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:25:20.850659 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0671885 (* 1 = 0.0671885 loss)
I0530 17:25:20.850663 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132313 (* 1 = 0.132313 loss)
I0530 17:25:20.850667 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00186052 (* 1 = 0.00186052 loss)
I0530 17:25:20.850672 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0127012 (* 1 = 0.0127012 loss)
I0530 17:25:20.850675 24924 sgd_solver.cpp:106] Iteration 27800, lr = 0.0002
I0530 17:26:12.792275 24924 solver.cpp:228] Iteration 27820, loss = 0.194668
I0530 17:26:12.792300 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 17:26:12.792309 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.055319 (* 1 = 0.055319 loss)
I0530 17:26:12.792313 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0731292 (* 1 = 0.0731292 loss)
I0530 17:26:12.792317 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238408 (* 1 = 0.00238408 loss)
I0530 17:26:12.792321 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0325696 (* 1 = 0.0325696 loss)
I0530 17:26:12.792326 24924 sgd_solver.cpp:106] Iteration 27820, lr = 0.0002
I0530 17:27:05.366149 24924 solver.cpp:228] Iteration 27840, loss = 0.365912
I0530 17:27:05.366176 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.78125
I0530 17:27:05.366184 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.405039 (* 1 = 0.405039 loss)
I0530 17:27:05.366189 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.559877 (* 1 = 0.559877 loss)
I0530 17:27:05.366192 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0306647 (* 1 = 0.0306647 loss)
I0530 17:27:05.366195 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.155899 (* 1 = 0.155899 loss)
I0530 17:27:05.366200 24924 sgd_solver.cpp:106] Iteration 27840, lr = 0.0002
I0530 17:27:57.607439 24924 solver.cpp:228] Iteration 27860, loss = 0.454328
I0530 17:27:57.607465 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 17:27:57.607473 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.029264 (* 1 = 0.029264 loss)
I0530 17:27:57.607477 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113547 (* 1 = 0.113547 loss)
I0530 17:27:57.607481 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00373762 (* 1 = 0.00373762 loss)
I0530 17:27:57.607486 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251609 (* 1 = 0.0251609 loss)
I0530 17:27:57.607491 24924 sgd_solver.cpp:106] Iteration 27860, lr = 0.0002
I0530 17:28:49.949048 24924 solver.cpp:228] Iteration 27880, loss = 0.327559
I0530 17:28:49.949074 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 17:28:49.949080 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298959 (* 1 = 0.0298959 loss)
I0530 17:28:49.949084 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.094487 (* 1 = 0.094487 loss)
I0530 17:28:49.949088 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00123534 (* 1 = 0.00123534 loss)
I0530 17:28:49.949091 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00974195 (* 1 = 0.00974195 loss)
I0530 17:28:49.949096 24924 sgd_solver.cpp:106] Iteration 27880, lr = 0.0002
I0530 17:29:42.729665 24924 solver.cpp:228] Iteration 27900, loss = 0.176084
I0530 17:29:42.729691 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:29:42.729701 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719093 (* 1 = 0.0719093 loss)
I0530 17:29:42.729704 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117697 (* 1 = 0.117697 loss)
I0530 17:29:42.729708 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00121321 (* 1 = 0.00121321 loss)
I0530 17:29:42.729713 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0105788 (* 1 = 0.0105788 loss)
I0530 17:29:42.729718 24924 sgd_solver.cpp:106] Iteration 27900, lr = 0.0002
I0530 17:30:34.903059 24924 solver.cpp:228] Iteration 27920, loss = 0.402542
I0530 17:30:34.903084 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:30:34.903091 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0147205 (* 1 = 0.0147205 loss)
I0530 17:30:34.903095 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0261134 (* 1 = 0.0261134 loss)
I0530 17:30:34.903098 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00416117 (* 1 = 0.00416117 loss)
I0530 17:30:34.903102 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0122922 (* 1 = 0.0122922 loss)
I0530 17:30:34.903106 24924 sgd_solver.cpp:106] Iteration 27920, lr = 0.0002
I0530 17:31:27.079710 24924 solver.cpp:228] Iteration 27940, loss = 0.553112
I0530 17:31:27.079787 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 17:31:27.079810 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0207614 (* 1 = 0.0207614 loss)
I0530 17:31:27.079825 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.059771 (* 1 = 0.059771 loss)
I0530 17:31:27.079840 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00398602 (* 1 = 0.00398602 loss)
I0530 17:31:27.079854 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00536167 (* 1 = 0.00536167 loss)
I0530 17:31:27.079869 24924 sgd_solver.cpp:106] Iteration 27940, lr = 0.0002
I0530 17:32:20.720734 24924 solver.cpp:228] Iteration 27960, loss = 0.229538
I0530 17:32:20.720784 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 17:32:20.720798 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0865458 (* 1 = 0.0865458 loss)
I0530 17:32:20.720804 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0981318 (* 1 = 0.0981318 loss)
I0530 17:32:20.720810 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00450686 (* 1 = 0.00450686 loss)
I0530 17:32:20.720816 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0192354 (* 1 = 0.0192354 loss)
I0530 17:32:20.720825 24924 sgd_solver.cpp:106] Iteration 27960, lr = 0.0002
I0530 17:33:13.927261 24924 solver.cpp:228] Iteration 27980, loss = 0.350586
I0530 17:33:13.927287 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 17:33:13.927295 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.040117 (* 1 = 0.040117 loss)
I0530 17:33:13.927299 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0772157 (* 1 = 0.0772157 loss)
I0530 17:33:13.927302 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00201854 (* 1 = 0.00201854 loss)
I0530 17:33:13.927306 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175606 (* 1 = 0.0175606 loss)
I0530 17:33:13.927311 24924 sgd_solver.cpp:106] Iteration 27980, lr = 0.0002
speed: 2.508s / iter
I0530 17:34:06.924698 24924 solver.cpp:228] Iteration 28000, loss = 0.264904
I0530 17:34:06.924724 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 17:34:06.924733 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0803235 (* 1 = 0.0803235 loss)
I0530 17:34:06.924737 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115963 (* 1 = 0.115963 loss)
I0530 17:34:06.924741 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00532217 (* 1 = 0.00532217 loss)
I0530 17:34:06.924746 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249333 (* 1 = 0.0249333 loss)
I0530 17:34:06.924751 24924 sgd_solver.cpp:106] Iteration 28000, lr = 0.0002
I0530 17:34:59.824465 24924 solver.cpp:228] Iteration 28020, loss = 0.218702
I0530 17:34:59.824491 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 17:34:59.824499 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0690352 (* 1 = 0.0690352 loss)
I0530 17:34:59.824503 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124916 (* 1 = 0.124916 loss)
I0530 17:34:59.824507 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00490597 (* 1 = 0.00490597 loss)
I0530 17:34:59.824512 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0280749 (* 1 = 0.0280749 loss)
I0530 17:34:59.824517 24924 sgd_solver.cpp:106] Iteration 28020, lr = 0.0002
I0530 17:35:54.139961 24924 solver.cpp:228] Iteration 28040, loss = 0.411011
I0530 17:35:54.139989 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 17:35:54.139997 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0958414 (* 1 = 0.0958414 loss)
I0530 17:35:54.140002 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.204977 (* 1 = 0.204977 loss)
I0530 17:35:54.140005 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0250374 (* 1 = 0.0250374 loss)
I0530 17:35:54.140008 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0372353 (* 1 = 0.0372353 loss)
I0530 17:35:54.140013 24924 sgd_solver.cpp:106] Iteration 28040, lr = 0.0002
I0530 17:36:47.837288 24924 solver.cpp:228] Iteration 28060, loss = 0.260697
I0530 17:36:47.837314 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:36:47.837321 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.029471 (* 1 = 0.029471 loss)
I0530 17:36:47.837326 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0476078 (* 1 = 0.0476078 loss)
I0530 17:36:47.837329 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0028017 (* 1 = 0.0028017 loss)
I0530 17:36:47.837332 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00809653 (* 1 = 0.00809653 loss)
I0530 17:36:47.837337 24924 sgd_solver.cpp:106] Iteration 28060, lr = 0.0002
I0530 17:37:42.260885 24924 solver.cpp:228] Iteration 28080, loss = 0.315448
I0530 17:37:42.260917 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 17:37:42.260928 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.183544 (* 1 = 0.183544 loss)
I0530 17:37:42.260936 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.359419 (* 1 = 0.359419 loss)
I0530 17:37:42.260942 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00765528 (* 1 = 0.00765528 loss)
I0530 17:37:42.260947 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.047177 (* 1 = 0.047177 loss)
I0530 17:37:42.260954 24924 sgd_solver.cpp:106] Iteration 28080, lr = 0.0002
I0530 17:38:35.668588 24924 solver.cpp:228] Iteration 28100, loss = 0.310468
I0530 17:38:35.668617 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 17:38:35.668624 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.199373 (* 1 = 0.199373 loss)
I0530 17:38:35.668632 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.302456 (* 1 = 0.302456 loss)
I0530 17:38:35.668637 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00704675 (* 1 = 0.00704675 loss)
I0530 17:38:35.668643 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0402755 (* 1 = 0.0402755 loss)
I0530 17:38:35.668651 24924 sgd_solver.cpp:106] Iteration 28100, lr = 0.0002
I0530 17:39:28.527715 24924 solver.cpp:228] Iteration 28120, loss = 0.279585
I0530 17:39:28.527742 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 17:39:28.527752 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.13044 (* 1 = 0.13044 loss)
I0530 17:39:28.527760 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.258781 (* 1 = 0.258781 loss)
I0530 17:39:28.527765 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0167875 (* 1 = 0.0167875 loss)
I0530 17:39:28.527770 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0436522 (* 1 = 0.0436522 loss)
I0530 17:39:28.527777 24924 sgd_solver.cpp:106] Iteration 28120, lr = 0.0002
I0530 17:40:22.718896 24924 solver.cpp:228] Iteration 28140, loss = 0.217861
I0530 17:40:22.718927 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:40:22.718936 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0878091 (* 1 = 0.0878091 loss)
I0530 17:40:22.718946 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0891371 (* 1 = 0.0891371 loss)
I0530 17:40:22.718953 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00750876 (* 1 = 0.00750876 loss)
I0530 17:40:22.718960 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00426762 (* 1 = 0.00426762 loss)
I0530 17:40:22.718966 24924 sgd_solver.cpp:106] Iteration 28140, lr = 0.0002
I0530 17:41:15.924572 24924 solver.cpp:228] Iteration 28160, loss = 0.365031
I0530 17:41:15.924602 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 17:41:15.924609 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.122622 (* 1 = 0.122622 loss)
I0530 17:41:15.924614 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.250609 (* 1 = 0.250609 loss)
I0530 17:41:15.924618 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0218709 (* 1 = 0.0218709 loss)
I0530 17:41:15.924623 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.081016 (* 1 = 0.081016 loss)
I0530 17:41:15.924628 24924 sgd_solver.cpp:106] Iteration 28160, lr = 0.0002
I0530 17:42:07.780367 24924 solver.cpp:228] Iteration 28180, loss = 0.270926
I0530 17:42:07.780391 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 17:42:07.780398 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589886 (* 1 = 0.0589886 loss)
I0530 17:42:07.780402 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.058486 (* 1 = 0.058486 loss)
I0530 17:42:07.780405 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00269744 (* 1 = 0.00269744 loss)
I0530 17:42:07.780409 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0029751 (* 1 = 0.0029751 loss)
I0530 17:42:07.780413 24924 sgd_solver.cpp:106] Iteration 28180, lr = 0.0002
speed: 2.509s / iter
I0530 17:42:59.719378 24924 solver.cpp:228] Iteration 28200, loss = 0.320366
I0530 17:42:59.719404 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:42:59.719414 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0666102 (* 1 = 0.0666102 loss)
I0530 17:42:59.719421 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0912356 (* 1 = 0.0912356 loss)
I0530 17:42:59.719427 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01304 (* 1 = 0.01304 loss)
I0530 17:42:59.719434 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01356 (* 1 = 0.01356 loss)
I0530 17:42:59.719442 24924 sgd_solver.cpp:106] Iteration 28200, lr = 0.0002
I0530 17:43:51.700742 24924 solver.cpp:228] Iteration 28220, loss = 0.185455
I0530 17:43:51.700769 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 17:43:51.700779 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0418065 (* 1 = 0.0418065 loss)
I0530 17:43:51.700786 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.103427 (* 1 = 0.103427 loss)
I0530 17:43:51.700791 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00624556 (* 1 = 0.00624556 loss)
I0530 17:43:51.700796 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00720353 (* 1 = 0.00720353 loss)
I0530 17:43:51.700804 24924 sgd_solver.cpp:106] Iteration 28220, lr = 0.0002
I0530 17:44:44.057945 24924 solver.cpp:228] Iteration 28240, loss = 0.337102
I0530 17:44:44.057976 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 17:44:44.057984 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0958944 (* 1 = 0.0958944 loss)
I0530 17:44:44.057989 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.18455 (* 1 = 0.18455 loss)
I0530 17:44:44.057993 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163479 (* 1 = 0.0163479 loss)
I0530 17:44:44.057996 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0431915 (* 1 = 0.0431915 loss)
I0530 17:44:44.058002 24924 sgd_solver.cpp:106] Iteration 28240, lr = 0.0002
I0530 17:45:35.926673 24924 solver.cpp:228] Iteration 28260, loss = 0.464113
I0530 17:45:35.926704 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 17:45:35.926713 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265286 (* 1 = 0.0265286 loss)
I0530 17:45:35.926720 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.119518 (* 1 = 0.119518 loss)
I0530 17:45:35.926726 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00496158 (* 1 = 0.00496158 loss)
I0530 17:45:35.926731 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00216699 (* 1 = 0.00216699 loss)
I0530 17:45:35.926739 24924 sgd_solver.cpp:106] Iteration 28260, lr = 0.0002
I0530 17:46:27.823297 24924 solver.cpp:228] Iteration 28280, loss = 0.399481
I0530 17:46:27.823323 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 17:46:27.823330 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.176912 (* 1 = 0.176912 loss)
I0530 17:46:27.823334 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.213111 (* 1 = 0.213111 loss)
I0530 17:46:27.823338 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00291356 (* 1 = 0.00291356 loss)
I0530 17:46:27.823343 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0442627 (* 1 = 0.0442627 loss)
I0530 17:46:27.823348 24924 sgd_solver.cpp:106] Iteration 28280, lr = 0.0002
I0530 17:47:19.713645 24924 solver.cpp:228] Iteration 28300, loss = 0.267381
I0530 17:47:19.713672 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:47:19.713680 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269535 (* 1 = 0.0269535 loss)
I0530 17:47:19.713683 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0479442 (* 1 = 0.0479442 loss)
I0530 17:47:19.713687 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00276798 (* 1 = 0.00276798 loss)
I0530 17:47:19.713690 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0120062 (* 1 = 0.0120062 loss)
I0530 17:47:19.713695 24924 sgd_solver.cpp:106] Iteration 28300, lr = 0.0002
I0530 17:48:11.849670 24924 solver.cpp:228] Iteration 28320, loss = 0.39147
I0530 17:48:11.849695 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 17:48:11.849704 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0805827 (* 1 = 0.0805827 loss)
I0530 17:48:11.849707 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.184229 (* 1 = 0.184229 loss)
I0530 17:48:11.849711 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0221129 (* 1 = 0.0221129 loss)
I0530 17:48:11.849715 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0560597 (* 1 = 0.0560597 loss)
I0530 17:48:11.849720 24924 sgd_solver.cpp:106] Iteration 28320, lr = 0.0002
I0530 17:49:03.735108 24924 solver.cpp:228] Iteration 28340, loss = 0.476772
I0530 17:49:03.735132 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 17:49:03.735139 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.118071 (* 1 = 0.118071 loss)
I0530 17:49:03.735143 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.181505 (* 1 = 0.181505 loss)
I0530 17:49:03.735146 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00506881 (* 1 = 0.00506881 loss)
I0530 17:49:03.735150 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0237896 (* 1 = 0.0237896 loss)
I0530 17:49:03.735154 24924 sgd_solver.cpp:106] Iteration 28340, lr = 0.0002
I0530 17:49:55.607861 24924 solver.cpp:228] Iteration 28360, loss = 0.246357
I0530 17:49:55.607887 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 17:49:55.607894 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299129 (* 1 = 0.0299129 loss)
I0530 17:49:55.607898 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.067375 (* 1 = 0.067375 loss)
I0530 17:49:55.607903 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00616578 (* 1 = 0.00616578 loss)
I0530 17:49:55.607906 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016238 (* 1 = 0.016238 loss)
I0530 17:49:55.607913 24924 sgd_solver.cpp:106] Iteration 28360, lr = 0.0002
I0530 17:50:47.468215 24924 solver.cpp:228] Iteration 28380, loss = 0.268973
I0530 17:50:47.468240 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0530 17:50:47.468246 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.410848 (* 1 = 0.410848 loss)
I0530 17:50:47.468250 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.58657 (* 1 = 0.58657 loss)
I0530 17:50:47.468253 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.026634 (* 1 = 0.026634 loss)
I0530 17:50:47.468257 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.119939 (* 1 = 0.119939 loss)
I0530 17:50:47.468262 24924 sgd_solver.cpp:106] Iteration 28380, lr = 0.0002
speed: 2.509s / iter
I0530 17:51:39.350222 24924 solver.cpp:228] Iteration 28400, loss = 0.265305
I0530 17:51:39.350245 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 17:51:39.350253 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.113167 (* 1 = 0.113167 loss)
I0530 17:51:39.350258 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.078208 (* 1 = 0.078208 loss)
I0530 17:51:39.350262 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0103812 (* 1 = 0.0103812 loss)
I0530 17:51:39.350265 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0430985 (* 1 = 0.0430985 loss)
I0530 17:51:39.350270 24924 sgd_solver.cpp:106] Iteration 28400, lr = 0.0002
I0530 17:52:31.217744 24924 solver.cpp:228] Iteration 28420, loss = 0.462877
I0530 17:52:31.217769 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 17:52:31.217777 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0254432 (* 1 = 0.0254432 loss)
I0530 17:52:31.217780 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0870038 (* 1 = 0.0870038 loss)
I0530 17:52:31.217784 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00966344 (* 1 = 0.00966344 loss)
I0530 17:52:31.217787 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145102 (* 1 = 0.0145102 loss)
I0530 17:52:31.217792 24924 sgd_solver.cpp:106] Iteration 28420, lr = 0.0002
I0530 17:53:23.105270 24924 solver.cpp:228] Iteration 28440, loss = 0.279555
I0530 17:53:23.105298 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 17:53:23.105305 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.130892 (* 1 = 0.130892 loss)
I0530 17:53:23.105309 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.274179 (* 1 = 0.274179 loss)
I0530 17:53:23.105314 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0284508 (* 1 = 0.0284508 loss)
I0530 17:53:23.105316 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0421579 (* 1 = 0.0421579 loss)
I0530 17:53:23.105321 24924 sgd_solver.cpp:106] Iteration 28440, lr = 0.0002
I0530 17:54:14.969794 24924 solver.cpp:228] Iteration 28460, loss = 0.282213
I0530 17:54:14.969818 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 17:54:14.969825 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103459 (* 1 = 0.103459 loss)
I0530 17:54:14.969830 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.229258 (* 1 = 0.229258 loss)
I0530 17:54:14.969833 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00737185 (* 1 = 0.00737185 loss)
I0530 17:54:14.969836 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0476216 (* 1 = 0.0476216 loss)
I0530 17:54:14.969841 24924 sgd_solver.cpp:106] Iteration 28460, lr = 0.0002
I0530 17:55:06.836694 24924 solver.cpp:228] Iteration 28480, loss = 0.302903
I0530 17:55:06.836720 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 17:55:06.836729 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0514218 (* 1 = 0.0514218 loss)
I0530 17:55:06.836732 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0920298 (* 1 = 0.0920298 loss)
I0530 17:55:06.836736 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0173627 (* 1 = 0.0173627 loss)
I0530 17:55:06.836740 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158133 (* 1 = 0.0158133 loss)
I0530 17:55:06.836745 24924 sgd_solver.cpp:106] Iteration 28480, lr = 0.0002
I0530 17:55:58.698024 24924 solver.cpp:228] Iteration 28500, loss = 0.392468
I0530 17:55:58.698048 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 17:55:58.698055 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.270945 (* 1 = 0.270945 loss)
I0530 17:55:58.698060 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.396058 (* 1 = 0.396058 loss)
I0530 17:55:58.698066 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119104 (* 1 = 0.0119104 loss)
I0530 17:55:58.698071 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0453697 (* 1 = 0.0453697 loss)
I0530 17:55:58.698076 24924 sgd_solver.cpp:106] Iteration 28500, lr = 0.0002
I0530 17:56:50.541970 24924 solver.cpp:228] Iteration 28520, loss = 0.208969
I0530 17:56:50.541995 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 17:56:50.542002 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.270494 (* 1 = 0.270494 loss)
I0530 17:56:50.542006 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.189921 (* 1 = 0.189921 loss)
I0530 17:56:50.542011 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0092902 (* 1 = 0.0092902 loss)
I0530 17:56:50.542014 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0637514 (* 1 = 0.0637514 loss)
I0530 17:56:50.542019 24924 sgd_solver.cpp:106] Iteration 28520, lr = 0.0002
I0530 17:57:42.381669 24924 solver.cpp:228] Iteration 28540, loss = 0.160078
I0530 17:57:42.381698 24924 solver.cpp:244]     Train net output #0: accuarcy = 1
I0530 17:57:42.381705 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0327867 (* 1 = 0.0327867 loss)
I0530 17:57:42.381709 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.046022 (* 1 = 0.046022 loss)
I0530 17:57:42.381713 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131553 (* 1 = 0.0131553 loss)
I0530 17:57:42.381716 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014639 (* 1 = 0.014639 loss)
I0530 17:57:42.381721 24924 sgd_solver.cpp:106] Iteration 28540, lr = 0.0002
I0530 17:58:34.252135 24924 solver.cpp:228] Iteration 28560, loss = 0.552934
I0530 17:58:34.252183 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 17:58:34.252193 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0748281 (* 1 = 0.0748281 loss)
I0530 17:58:34.252197 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.206772 (* 1 = 0.206772 loss)
I0530 17:58:34.252202 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0128543 (* 1 = 0.0128543 loss)
I0530 17:58:34.252207 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00790042 (* 1 = 0.00790042 loss)
I0530 17:58:34.252213 24924 sgd_solver.cpp:106] Iteration 28560, lr = 0.0002
I0530 17:59:26.108363 24924 solver.cpp:228] Iteration 28580, loss = 0.234442
I0530 17:59:26.108387 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 17:59:26.108394 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.233771 (* 1 = 0.233771 loss)
I0530 17:59:26.108400 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.232869 (* 1 = 0.232869 loss)
I0530 17:59:26.108407 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00956657 (* 1 = 0.00956657 loss)
I0530 17:59:26.108410 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0788289 (* 1 = 0.0788289 loss)
I0530 17:59:26.108415 24924 sgd_solver.cpp:106] Iteration 28580, lr = 0.0002
speed: 2.510s / iter
I0530 18:00:17.901074 24924 solver.cpp:228] Iteration 28600, loss = 0.19048
I0530 18:00:17.901098 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:00:17.901106 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00249428 (* 1 = 0.00249428 loss)
I0530 18:00:17.901111 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0315973 (* 1 = 0.0315973 loss)
I0530 18:00:17.901114 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0066553 (* 1 = 0.0066553 loss)
I0530 18:00:17.901118 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.115642 (* 1 = 0.115642 loss)
I0530 18:00:17.901124 24924 sgd_solver.cpp:106] Iteration 28600, lr = 0.0002
I0530 18:01:09.784754 24924 solver.cpp:228] Iteration 28620, loss = 0.205765
I0530 18:01:09.784777 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.851562
I0530 18:01:09.784785 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.204101 (* 1 = 0.204101 loss)
I0530 18:01:09.784790 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.286881 (* 1 = 0.286881 loss)
I0530 18:01:09.784792 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0111373 (* 1 = 0.0111373 loss)
I0530 18:01:09.784796 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0734646 (* 1 = 0.0734646 loss)
I0530 18:01:09.784801 24924 sgd_solver.cpp:106] Iteration 28620, lr = 0.0002
I0530 18:02:01.688071 24924 solver.cpp:228] Iteration 28640, loss = 0.266856
I0530 18:02:01.688097 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 18:02:01.688107 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0502931 (* 1 = 0.0502931 loss)
I0530 18:02:01.688113 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.130764 (* 1 = 0.130764 loss)
I0530 18:02:01.688119 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0203574 (* 1 = 0.0203574 loss)
I0530 18:02:01.688125 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0236355 (* 1 = 0.0236355 loss)
I0530 18:02:01.688133 24924 sgd_solver.cpp:106] Iteration 28640, lr = 0.0002
I0530 18:02:53.587476 24924 solver.cpp:228] Iteration 28660, loss = 0.336097
I0530 18:02:53.587502 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 18:02:53.587510 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.111055 (* 1 = 0.111055 loss)
I0530 18:02:53.587517 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.211176 (* 1 = 0.211176 loss)
I0530 18:02:53.587522 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00297359 (* 1 = 0.00297359 loss)
I0530 18:02:53.587527 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103046 (* 1 = 0.0103046 loss)
I0530 18:02:53.587534 24924 sgd_solver.cpp:106] Iteration 28660, lr = 0.0002
I0530 18:03:45.491152 24924 solver.cpp:228] Iteration 28680, loss = 0.324748
I0530 18:03:45.491176 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:03:45.491188 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0372966 (* 1 = 0.0372966 loss)
I0530 18:03:45.491194 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0485485 (* 1 = 0.0485485 loss)
I0530 18:03:45.491200 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00275909 (* 1 = 0.00275909 loss)
I0530 18:03:45.491206 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00435558 (* 1 = 0.00435558 loss)
I0530 18:03:45.491214 24924 sgd_solver.cpp:106] Iteration 28680, lr = 0.0002
I0530 18:04:37.362107 24924 solver.cpp:228] Iteration 28700, loss = 0.442735
I0530 18:04:37.362130 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 18:04:37.362138 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.119771 (* 1 = 0.119771 loss)
I0530 18:04:37.362141 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.191235 (* 1 = 0.191235 loss)
I0530 18:04:37.362145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00675561 (* 1 = 0.00675561 loss)
I0530 18:04:37.362149 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0230692 (* 1 = 0.0230692 loss)
I0530 18:04:37.362152 24924 sgd_solver.cpp:106] Iteration 28700, lr = 0.0002
I0530 18:05:29.229259 24924 solver.cpp:228] Iteration 28720, loss = 0.293999
I0530 18:05:29.229284 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 18:05:29.229290 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0503203 (* 1 = 0.0503203 loss)
I0530 18:05:29.229295 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.129688 (* 1 = 0.129688 loss)
I0530 18:05:29.229300 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00565871 (* 1 = 0.00565871 loss)
I0530 18:05:29.229302 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0158883 (* 1 = 0.0158883 loss)
I0530 18:05:29.229307 24924 sgd_solver.cpp:106] Iteration 28720, lr = 0.0002
I0530 18:06:21.162575 24924 solver.cpp:228] Iteration 28740, loss = 0.269457
I0530 18:06:21.162600 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 18:06:21.162607 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.28974 (* 1 = 0.28974 loss)
I0530 18:06:21.162611 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.322769 (* 1 = 0.322769 loss)
I0530 18:06:21.162616 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00938545 (* 1 = 0.00938545 loss)
I0530 18:06:21.162619 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0856932 (* 1 = 0.0856932 loss)
I0530 18:06:21.162626 24924 sgd_solver.cpp:106] Iteration 28740, lr = 0.0002
I0530 18:07:12.950388 24924 solver.cpp:228] Iteration 28760, loss = 0.318289
I0530 18:07:12.950413 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.671875
I0530 18:07:12.950420 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.395747 (* 1 = 0.395747 loss)
I0530 18:07:12.950424 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.655223 (* 1 = 0.655223 loss)
I0530 18:07:12.950428 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00855978 (* 1 = 0.00855978 loss)
I0530 18:07:12.950431 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100057 (* 1 = 0.100057 loss)
I0530 18:07:12.950436 24924 sgd_solver.cpp:106] Iteration 28760, lr = 0.0002
I0530 18:08:04.810745 24924 solver.cpp:228] Iteration 28780, loss = 0.260473
I0530 18:08:04.810770 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 18:08:04.810776 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0445743 (* 1 = 0.0445743 loss)
I0530 18:08:04.810781 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.148733 (* 1 = 0.148733 loss)
I0530 18:08:04.810784 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0233812 (* 1 = 0.0233812 loss)
I0530 18:08:04.810788 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0214587 (* 1 = 0.0214587 loss)
I0530 18:08:04.810793 24924 sgd_solver.cpp:106] Iteration 28780, lr = 0.0002
speed: 2.510s / iter
I0530 18:08:56.709810 24924 solver.cpp:228] Iteration 28800, loss = 0.245142
I0530 18:08:56.709837 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:08:56.709844 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0530492 (* 1 = 0.0530492 loss)
I0530 18:08:56.709848 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101602 (* 1 = 0.101602 loss)
I0530 18:08:56.709851 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00428883 (* 1 = 0.00428883 loss)
I0530 18:08:56.709856 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0352297 (* 1 = 0.0352297 loss)
I0530 18:08:56.709859 24924 sgd_solver.cpp:106] Iteration 28800, lr = 0.0002
I0530 18:09:48.604593 24924 solver.cpp:228] Iteration 28820, loss = 0.300322
I0530 18:09:48.604619 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 18:09:48.604627 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0598773 (* 1 = 0.0598773 loss)
I0530 18:09:48.604631 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0795513 (* 1 = 0.0795513 loss)
I0530 18:09:48.604635 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000746678 (* 1 = 0.000746678 loss)
I0530 18:09:48.604640 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00570238 (* 1 = 0.00570238 loss)
I0530 18:09:48.604645 24924 sgd_solver.cpp:106] Iteration 28820, lr = 0.0002
I0530 18:10:40.487895 24924 solver.cpp:228] Iteration 28840, loss = 0.198151
I0530 18:10:40.487918 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:10:40.487926 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0397954 (* 1 = 0.0397954 loss)
I0530 18:10:40.487929 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.045859 (* 1 = 0.045859 loss)
I0530 18:10:40.487933 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00302423 (* 1 = 0.00302423 loss)
I0530 18:10:40.487938 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00280829 (* 1 = 0.00280829 loss)
I0530 18:10:40.487944 24924 sgd_solver.cpp:106] Iteration 28840, lr = 0.0002
I0530 18:11:32.398010 24924 solver.cpp:228] Iteration 28860, loss = 0.338901
I0530 18:11:32.398044 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 18:11:32.398056 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.018593 (* 1 = 0.018593 loss)
I0530 18:11:32.398063 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0322706 (* 1 = 0.0322706 loss)
I0530 18:11:32.398069 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00681885 (* 1 = 0.00681885 loss)
I0530 18:11:32.398075 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0398057 (* 1 = 0.0398057 loss)
I0530 18:11:32.398082 24924 sgd_solver.cpp:106] Iteration 28860, lr = 0.0002
I0530 18:12:24.296895 24924 solver.cpp:228] Iteration 28880, loss = 0.243477
I0530 18:12:24.296924 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 18:12:24.296931 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0784087 (* 1 = 0.0784087 loss)
I0530 18:12:24.296936 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.245361 (* 1 = 0.245361 loss)
I0530 18:12:24.296938 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0115463 (* 1 = 0.0115463 loss)
I0530 18:12:24.296942 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0102695 (* 1 = 0.0102695 loss)
I0530 18:12:24.296947 24924 sgd_solver.cpp:106] Iteration 28880, lr = 0.0002
I0530 18:13:16.238924 24924 solver.cpp:228] Iteration 28900, loss = 0.373153
I0530 18:13:16.238951 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 18:13:16.238958 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.194399 (* 1 = 0.194399 loss)
I0530 18:13:16.238962 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.264939 (* 1 = 0.264939 loss)
I0530 18:13:16.238966 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00611449 (* 1 = 0.00611449 loss)
I0530 18:13:16.238970 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0311045 (* 1 = 0.0311045 loss)
I0530 18:13:16.238976 24924 sgd_solver.cpp:106] Iteration 28900, lr = 0.0002
I0530 18:14:08.144846 24924 solver.cpp:228] Iteration 28920, loss = 0.304591
I0530 18:14:08.144870 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.757812
I0530 18:14:08.144877 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.279778 (* 1 = 0.279778 loss)
I0530 18:14:08.144881 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.474775 (* 1 = 0.474775 loss)
I0530 18:14:08.144884 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0336432 (* 1 = 0.0336432 loss)
I0530 18:14:08.144887 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0991039 (* 1 = 0.0991039 loss)
I0530 18:14:08.144892 24924 sgd_solver.cpp:106] Iteration 28920, lr = 0.0002
I0530 18:15:00.058501 24924 solver.cpp:228] Iteration 28940, loss = 0.226518
I0530 18:15:00.058526 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 18:15:00.058535 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0135939 (* 1 = 0.0135939 loss)
I0530 18:15:00.058543 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.154185 (* 1 = 0.154185 loss)
I0530 18:15:00.058549 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.021949 (* 1 = 0.021949 loss)
I0530 18:15:00.058554 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113353 (* 1 = 0.0113353 loss)
I0530 18:15:00.058562 24924 sgd_solver.cpp:106] Iteration 28940, lr = 0.0002
I0530 18:15:51.935607 24924 solver.cpp:228] Iteration 28960, loss = 0.17685
I0530 18:15:51.935631 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:15:51.935639 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0475289 (* 1 = 0.0475289 loss)
I0530 18:15:51.935643 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0590397 (* 1 = 0.0590397 loss)
I0530 18:15:51.935647 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163491 (* 1 = 0.0163491 loss)
I0530 18:15:51.935650 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.019291 (* 1 = 0.019291 loss)
I0530 18:15:51.935654 24924 sgd_solver.cpp:106] Iteration 28960, lr = 0.0002
I0530 18:16:43.799525 24924 solver.cpp:228] Iteration 28980, loss = 0.213854
I0530 18:16:43.799548 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 18:16:43.799556 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.130166 (* 1 = 0.130166 loss)
I0530 18:16:43.799561 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.122059 (* 1 = 0.122059 loss)
I0530 18:16:43.799564 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00906931 (* 1 = 0.00906931 loss)
I0530 18:16:43.799568 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0242693 (* 1 = 0.0242693 loss)
I0530 18:16:43.799573 24924 sgd_solver.cpp:106] Iteration 28980, lr = 0.0002
speed: 2.511s / iter
I0530 18:17:35.662155 24924 solver.cpp:228] Iteration 29000, loss = 0.21613
I0530 18:17:35.662178 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:17:35.662186 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.000556585 (* 1 = 0.000556585 loss)
I0530 18:17:35.662190 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0355115 (* 1 = 0.0355115 loss)
I0530 18:17:35.662194 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195217 (* 1 = 0.0195217 loss)
I0530 18:17:35.662197 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254334 (* 1 = 0.0254334 loss)
I0530 18:17:35.662201 24924 sgd_solver.cpp:106] Iteration 29000, lr = 0.0002
I0530 18:18:27.518824 24924 solver.cpp:228] Iteration 29020, loss = 0.18369
I0530 18:18:27.518852 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:18:27.518862 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589404 (* 1 = 0.0589404 loss)
I0530 18:18:27.518867 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0670635 (* 1 = 0.0670635 loss)
I0530 18:18:27.518870 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00443484 (* 1 = 0.00443484 loss)
I0530 18:18:27.518874 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00753078 (* 1 = 0.00753078 loss)
I0530 18:18:27.518880 24924 sgd_solver.cpp:106] Iteration 29020, lr = 0.0002
I0530 18:19:19.419039 24924 solver.cpp:228] Iteration 29040, loss = 0.280508
I0530 18:19:19.419064 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.773438
I0530 18:19:19.419071 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.346542 (* 1 = 0.346542 loss)
I0530 18:19:19.419075 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.436312 (* 1 = 0.436312 loss)
I0530 18:19:19.419078 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0295349 (* 1 = 0.0295349 loss)
I0530 18:19:19.419081 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.118883 (* 1 = 0.118883 loss)
I0530 18:19:19.419086 24924 sgd_solver.cpp:106] Iteration 29040, lr = 0.0002
I0530 18:20:11.286651 24924 solver.cpp:228] Iteration 29060, loss = 0.222649
I0530 18:20:11.286677 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.875
I0530 18:20:11.286685 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.256906 (* 1 = 0.256906 loss)
I0530 18:20:11.286690 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.291249 (* 1 = 0.291249 loss)
I0530 18:20:11.286694 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0260152 (* 1 = 0.0260152 loss)
I0530 18:20:11.286697 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0569467 (* 1 = 0.0569467 loss)
I0530 18:20:11.286702 24924 sgd_solver.cpp:106] Iteration 29060, lr = 0.0002
I0530 18:21:03.181632 24924 solver.cpp:228] Iteration 29080, loss = 0.203633
I0530 18:21:03.181656 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:21:03.181664 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0696542 (* 1 = 0.0696542 loss)
I0530 18:21:03.181670 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0729967 (* 1 = 0.0729967 loss)
I0530 18:21:03.181675 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0023983 (* 1 = 0.0023983 loss)
I0530 18:21:03.181679 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00994536 (* 1 = 0.00994536 loss)
I0530 18:21:03.181684 24924 sgd_solver.cpp:106] Iteration 29080, lr = 0.0002
I0530 18:21:55.055258 24924 solver.cpp:228] Iteration 29100, loss = 0.239792
I0530 18:21:55.055284 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 18:21:55.055292 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0459192 (* 1 = 0.0459192 loss)
I0530 18:21:55.055296 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.122284 (* 1 = 0.122284 loss)
I0530 18:21:55.055300 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00285233 (* 1 = 0.00285233 loss)
I0530 18:21:55.055305 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0169226 (* 1 = 0.0169226 loss)
I0530 18:21:55.055310 24924 sgd_solver.cpp:106] Iteration 29100, lr = 0.0002
I0530 18:22:46.927413 24924 solver.cpp:228] Iteration 29120, loss = 0.275589
I0530 18:22:46.927438 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 18:22:46.927444 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0268382 (* 1 = 0.0268382 loss)
I0530 18:22:46.927448 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.06348 (* 1 = 0.06348 loss)
I0530 18:22:46.927453 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00295663 (* 1 = 0.00295663 loss)
I0530 18:22:46.927455 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00580908 (* 1 = 0.00580908 loss)
I0530 18:22:46.927460 24924 sgd_solver.cpp:106] Iteration 29120, lr = 0.0002
I0530 18:23:38.783599 24924 solver.cpp:228] Iteration 29140, loss = 0.242974
I0530 18:23:38.783622 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 18:23:38.783630 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0321721 (* 1 = 0.0321721 loss)
I0530 18:23:38.783637 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0760654 (* 1 = 0.0760654 loss)
I0530 18:23:38.783643 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00270994 (* 1 = 0.00270994 loss)
I0530 18:23:38.783648 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111526 (* 1 = 0.0111526 loss)
I0530 18:23:38.783653 24924 sgd_solver.cpp:106] Iteration 29140, lr = 0.0002
I0530 18:24:30.645539 24924 solver.cpp:228] Iteration 29160, loss = 0.169056
I0530 18:24:30.645561 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:24:30.645568 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0376687 (* 1 = 0.0376687 loss)
I0530 18:24:30.645572 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0786297 (* 1 = 0.0786297 loss)
I0530 18:24:30.645576 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00239031 (* 1 = 0.00239031 loss)
I0530 18:24:30.645578 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0252138 (* 1 = 0.0252138 loss)
I0530 18:24:30.645583 24924 sgd_solver.cpp:106] Iteration 29160, lr = 0.0002
I0530 18:25:22.509377 24924 solver.cpp:228] Iteration 29180, loss = 0.26265
I0530 18:25:22.509403 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:25:22.509411 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0701645 (* 1 = 0.0701645 loss)
I0530 18:25:22.509416 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.125694 (* 1 = 0.125694 loss)
I0530 18:25:22.509420 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00385403 (* 1 = 0.00385403 loss)
I0530 18:25:22.509423 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0204059 (* 1 = 0.0204059 loss)
I0530 18:25:22.509428 24924 sgd_solver.cpp:106] Iteration 29180, lr = 0.0002
speed: 2.512s / iter
I0530 18:26:14.380460 24924 solver.cpp:228] Iteration 29200, loss = 0.221744
I0530 18:26:14.380484 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 18:26:14.380493 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.144384 (* 1 = 0.144384 loss)
I0530 18:26:14.380499 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.138205 (* 1 = 0.138205 loss)
I0530 18:26:14.380506 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0106167 (* 1 = 0.0106167 loss)
I0530 18:26:14.380511 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0133028 (* 1 = 0.0133028 loss)
I0530 18:26:14.380519 24924 sgd_solver.cpp:106] Iteration 29200, lr = 0.0002
I0530 18:27:06.239177 24924 solver.cpp:228] Iteration 29220, loss = 0.244923
I0530 18:27:06.239203 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:27:06.239210 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298764 (* 1 = 0.0298764 loss)
I0530 18:27:06.239214 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0570526 (* 1 = 0.0570526 loss)
I0530 18:27:06.239218 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0032503 (* 1 = 0.0032503 loss)
I0530 18:27:06.239223 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00686519 (* 1 = 0.00686519 loss)
I0530 18:27:06.239226 24924 sgd_solver.cpp:106] Iteration 29220, lr = 0.0002
I0530 18:27:58.102957 24924 solver.cpp:228] Iteration 29240, loss = 0.324474
I0530 18:27:58.102982 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 18:27:58.102989 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.174985 (* 1 = 0.174985 loss)
I0530 18:27:58.102993 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.231816 (* 1 = 0.231816 loss)
I0530 18:27:58.102998 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00392118 (* 1 = 0.00392118 loss)
I0530 18:27:58.103001 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0525644 (* 1 = 0.0525644 loss)
I0530 18:27:58.103008 24924 sgd_solver.cpp:106] Iteration 29240, lr = 0.0002
I0530 18:28:50.001674 24924 solver.cpp:228] Iteration 29260, loss = 0.222978
I0530 18:28:50.001698 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 18:28:50.001705 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0558862 (* 1 = 0.0558862 loss)
I0530 18:28:50.001709 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0710067 (* 1 = 0.0710067 loss)
I0530 18:28:50.001713 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00415282 (* 1 = 0.00415282 loss)
I0530 18:28:50.001716 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0210044 (* 1 = 0.0210044 loss)
I0530 18:28:50.001721 24924 sgd_solver.cpp:106] Iteration 29260, lr = 0.0002
I0530 18:29:41.861425 24924 solver.cpp:228] Iteration 29280, loss = 0.224767
I0530 18:29:41.861450 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:29:41.861459 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0407952 (* 1 = 0.0407952 loss)
I0530 18:29:41.861464 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0645842 (* 1 = 0.0645842 loss)
I0530 18:29:41.861470 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00316635 (* 1 = 0.00316635 loss)
I0530 18:29:41.861477 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0107908 (* 1 = 0.0107908 loss)
I0530 18:29:41.861483 24924 sgd_solver.cpp:106] Iteration 29280, lr = 0.0002
I0530 18:30:33.713150 24924 solver.cpp:228] Iteration 29300, loss = 0.414657
I0530 18:30:33.713173 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 18:30:33.713181 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.086181 (* 1 = 0.086181 loss)
I0530 18:30:33.713186 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.183266 (* 1 = 0.183266 loss)
I0530 18:30:33.713189 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00727213 (* 1 = 0.00727213 loss)
I0530 18:30:33.713192 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0205965 (* 1 = 0.0205965 loss)
I0530 18:30:33.713197 24924 sgd_solver.cpp:106] Iteration 29300, lr = 0.0002
I0530 18:31:25.563993 24924 solver.cpp:228] Iteration 29320, loss = 0.294408
I0530 18:31:25.564019 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 18:31:25.564028 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.06004 (* 1 = 0.06004 loss)
I0530 18:31:25.564034 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0925225 (* 1 = 0.0925225 loss)
I0530 18:31:25.564040 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00107156 (* 1 = 0.00107156 loss)
I0530 18:31:25.564045 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00809485 (* 1 = 0.00809485 loss)
I0530 18:31:25.564051 24924 sgd_solver.cpp:106] Iteration 29320, lr = 0.0002
I0530 18:32:17.412379 24924 solver.cpp:228] Iteration 29340, loss = 0.198039
I0530 18:32:17.412401 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:32:17.412410 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0253124 (* 1 = 0.0253124 loss)
I0530 18:32:17.412413 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.102286 (* 1 = 0.102286 loss)
I0530 18:32:17.412416 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00613933 (* 1 = 0.00613933 loss)
I0530 18:32:17.412420 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00503632 (* 1 = 0.00503632 loss)
I0530 18:32:17.412425 24924 sgd_solver.cpp:106] Iteration 29340, lr = 0.0002
I0530 18:33:09.282053 24924 solver.cpp:228] Iteration 29360, loss = 0.274866
I0530 18:33:09.282078 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 18:33:09.282085 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.129864 (* 1 = 0.129864 loss)
I0530 18:33:09.282089 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123181 (* 1 = 0.123181 loss)
I0530 18:33:09.282094 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169395 (* 1 = 0.00169395 loss)
I0530 18:33:09.282097 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0150728 (* 1 = 0.0150728 loss)
I0530 18:33:09.282102 24924 sgd_solver.cpp:106] Iteration 29360, lr = 0.0002
I0530 18:34:01.137846 24924 solver.cpp:228] Iteration 29380, loss = 0.266469
I0530 18:34:01.137871 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 18:34:01.137878 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.199121 (* 1 = 0.199121 loss)
I0530 18:34:01.137881 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.375715 (* 1 = 0.375715 loss)
I0530 18:34:01.137886 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00866184 (* 1 = 0.00866184 loss)
I0530 18:34:01.137889 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0678571 (* 1 = 0.0678571 loss)
I0530 18:34:01.137893 24924 sgd_solver.cpp:106] Iteration 29380, lr = 0.0002
speed: 2.512s / iter
I0530 18:34:52.952265 24924 solver.cpp:228] Iteration 29400, loss = 0.293544
I0530 18:34:52.952288 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 18:34:52.952297 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0746584 (* 1 = 0.0746584 loss)
I0530 18:34:52.952301 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.124408 (* 1 = 0.124408 loss)
I0530 18:34:52.952306 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00439871 (* 1 = 0.00439871 loss)
I0530 18:34:52.952309 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145561 (* 1 = 0.0145561 loss)
I0530 18:34:52.952314 24924 sgd_solver.cpp:106] Iteration 29400, lr = 0.0002
I0530 18:35:44.810991 24924 solver.cpp:228] Iteration 29420, loss = 0.346229
I0530 18:35:44.811014 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 18:35:44.811022 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0789224 (* 1 = 0.0789224 loss)
I0530 18:35:44.811025 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.112195 (* 1 = 0.112195 loss)
I0530 18:35:44.811028 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00923669 (* 1 = 0.00923669 loss)
I0530 18:35:44.811033 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0345499 (* 1 = 0.0345499 loss)
I0530 18:35:44.811038 24924 sgd_solver.cpp:106] Iteration 29420, lr = 0.0002
I0530 18:36:36.699244 24924 solver.cpp:228] Iteration 29440, loss = 0.234819
I0530 18:36:36.699267 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 18:36:36.699275 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0191101 (* 1 = 0.0191101 loss)
I0530 18:36:36.699280 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.040537 (* 1 = 0.040537 loss)
I0530 18:36:36.699283 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125147 (* 1 = 0.0125147 loss)
I0530 18:36:36.699286 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0189321 (* 1 = 0.0189321 loss)
I0530 18:36:36.699291 24924 sgd_solver.cpp:106] Iteration 29440, lr = 0.0002
I0530 18:37:28.558111 24924 solver.cpp:228] Iteration 29460, loss = 0.443046
I0530 18:37:28.558135 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 18:37:28.558142 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.23404 (* 1 = 0.23404 loss)
I0530 18:37:28.558145 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.340776 (* 1 = 0.340776 loss)
I0530 18:37:28.558149 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0646854 (* 1 = 0.0646854 loss)
I0530 18:37:28.558152 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0603819 (* 1 = 0.0603819 loss)
I0530 18:37:28.558157 24924 sgd_solver.cpp:106] Iteration 29460, lr = 0.0002
I0530 18:38:20.421007 24924 solver.cpp:228] Iteration 29480, loss = 0.336388
I0530 18:38:20.421033 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 18:38:20.421043 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.079464 (* 1 = 0.079464 loss)
I0530 18:38:20.421051 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0795114 (* 1 = 0.0795114 loss)
I0530 18:38:20.421056 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00347673 (* 1 = 0.00347673 loss)
I0530 18:38:20.421062 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103071 (* 1 = 0.0103071 loss)
I0530 18:38:20.421070 24924 sgd_solver.cpp:106] Iteration 29480, lr = 0.0002
I0530 18:39:12.276366 24924 solver.cpp:228] Iteration 29500, loss = 0.297613
I0530 18:39:12.276391 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 18:39:12.276401 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.222504 (* 1 = 0.222504 loss)
I0530 18:39:12.276407 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.440014 (* 1 = 0.440014 loss)
I0530 18:39:12.276412 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00987016 (* 1 = 0.00987016 loss)
I0530 18:39:12.276417 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0493822 (* 1 = 0.0493822 loss)
I0530 18:39:12.276422 24924 sgd_solver.cpp:106] Iteration 29500, lr = 0.0002
I0530 18:40:04.167629 24924 solver.cpp:228] Iteration 29520, loss = 0.140889
I0530 18:40:04.167655 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 18:40:04.167665 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0196598 (* 1 = 0.0196598 loss)
I0530 18:40:04.167672 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0621633 (* 1 = 0.0621633 loss)
I0530 18:40:04.167680 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00229867 (* 1 = 0.00229867 loss)
I0530 18:40:04.167685 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.01393 (* 1 = 0.01393 loss)
I0530 18:40:04.167695 24924 sgd_solver.cpp:106] Iteration 29520, lr = 0.0002
I0530 18:40:56.029392 24924 solver.cpp:228] Iteration 29540, loss = 0.207493
I0530 18:40:56.029423 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:40:56.029433 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0167736 (* 1 = 0.0167736 loss)
I0530 18:40:56.029439 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.106406 (* 1 = 0.106406 loss)
I0530 18:40:56.029445 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125007 (* 1 = 0.0125007 loss)
I0530 18:40:56.029450 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0498925 (* 1 = 0.0498925 loss)
I0530 18:40:56.029458 24924 sgd_solver.cpp:106] Iteration 29540, lr = 0.0002
I0530 18:41:47.877086 24924 solver.cpp:228] Iteration 29560, loss = 0.238009
I0530 18:41:47.877116 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:41:47.877126 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0335179 (* 1 = 0.0335179 loss)
I0530 18:41:47.877133 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.057597 (* 1 = 0.057597 loss)
I0530 18:41:47.877140 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.001309 (* 1 = 0.001309 loss)
I0530 18:41:47.877146 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00390971 (* 1 = 0.00390971 loss)
I0530 18:41:47.877152 24924 sgd_solver.cpp:106] Iteration 29560, lr = 0.0002
I0530 18:42:39.747925 24924 solver.cpp:228] Iteration 29580, loss = 0.274281
I0530 18:42:39.747949 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 18:42:39.747956 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.16528 (* 1 = 0.16528 loss)
I0530 18:42:39.747961 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.277207 (* 1 = 0.277207 loss)
I0530 18:42:39.747964 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00289142 (* 1 = 0.00289142 loss)
I0530 18:42:39.747967 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0241174 (* 1 = 0.0241174 loss)
I0530 18:42:39.747972 24924 sgd_solver.cpp:106] Iteration 29580, lr = 0.0002
speed: 2.513s / iter
I0530 18:43:31.529378 24924 solver.cpp:228] Iteration 29600, loss = 0.171219
I0530 18:43:31.529403 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:43:31.529410 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0447049 (* 1 = 0.0447049 loss)
I0530 18:43:31.529414 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0565784 (* 1 = 0.0565784 loss)
I0530 18:43:31.529419 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00817262 (* 1 = 0.00817262 loss)
I0530 18:43:31.529422 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113497 (* 1 = 0.0113497 loss)
I0530 18:43:31.529428 24924 sgd_solver.cpp:106] Iteration 29600, lr = 0.0002
I0530 18:44:23.387104 24924 solver.cpp:228] Iteration 29620, loss = 0.309042
I0530 18:44:23.387125 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:44:23.387133 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.032029 (* 1 = 0.032029 loss)
I0530 18:44:23.387137 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0702373 (* 1 = 0.0702373 loss)
I0530 18:44:23.387140 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0110175 (* 1 = 0.0110175 loss)
I0530 18:44:23.387145 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00936122 (* 1 = 0.00936122 loss)
I0530 18:44:23.387148 24924 sgd_solver.cpp:106] Iteration 29620, lr = 0.0002
I0530 18:45:15.244122 24924 solver.cpp:228] Iteration 29640, loss = 0.37119
I0530 18:45:15.244148 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:45:15.244154 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0299376 (* 1 = 0.0299376 loss)
I0530 18:45:15.244158 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0712999 (* 1 = 0.0712999 loss)
I0530 18:45:15.244163 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0213032 (* 1 = 0.0213032 loss)
I0530 18:45:15.244165 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175067 (* 1 = 0.0175067 loss)
I0530 18:45:15.244170 24924 sgd_solver.cpp:106] Iteration 29640, lr = 0.0002
I0530 18:46:07.152410 24924 solver.cpp:228] Iteration 29660, loss = 0.276702
I0530 18:46:07.152436 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:46:07.152443 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0278873 (* 1 = 0.0278873 loss)
I0530 18:46:07.152451 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0295704 (* 1 = 0.0295704 loss)
I0530 18:46:07.152457 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00654201 (* 1 = 0.00654201 loss)
I0530 18:46:07.152462 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00116428 (* 1 = 0.00116428 loss)
I0530 18:46:07.152467 24924 sgd_solver.cpp:106] Iteration 29660, lr = 0.0002
I0530 18:46:59.041198 24924 solver.cpp:228] Iteration 29680, loss = 0.294583
I0530 18:46:59.041223 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 18:46:59.041230 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.18298 (* 1 = 0.18298 loss)
I0530 18:46:59.041234 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.322006 (* 1 = 0.322006 loss)
I0530 18:46:59.041237 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0197083 (* 1 = 0.0197083 loss)
I0530 18:46:59.041240 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0388739 (* 1 = 0.0388739 loss)
I0530 18:46:59.041246 24924 sgd_solver.cpp:106] Iteration 29680, lr = 0.0002
I0530 18:47:50.889628 24924 solver.cpp:228] Iteration 29700, loss = 0.0929629
I0530 18:47:50.889653 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:47:50.889662 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0250608 (* 1 = 0.0250608 loss)
I0530 18:47:50.889667 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.069252 (* 1 = 0.069252 loss)
I0530 18:47:50.889670 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00184645 (* 1 = 0.00184645 loss)
I0530 18:47:50.889674 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0327853 (* 1 = 0.0327853 loss)
I0530 18:47:50.889679 24924 sgd_solver.cpp:106] Iteration 29700, lr = 0.0002
I0530 18:48:42.748924 24924 solver.cpp:228] Iteration 29720, loss = 0.279143
I0530 18:48:42.748948 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 18:48:42.748956 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0589326 (* 1 = 0.0589326 loss)
I0530 18:48:42.748960 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.143119 (* 1 = 0.143119 loss)
I0530 18:48:42.748965 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0185883 (* 1 = 0.0185883 loss)
I0530 18:48:42.748971 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.120109 (* 1 = 0.120109 loss)
I0530 18:48:42.748977 24924 sgd_solver.cpp:106] Iteration 29720, lr = 0.0002
I0530 18:49:34.625762 24924 solver.cpp:228] Iteration 29740, loss = 0.348255
I0530 18:49:34.625787 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 18:49:34.625794 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0871798 (* 1 = 0.0871798 loss)
I0530 18:49:34.625798 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.23706 (* 1 = 0.23706 loss)
I0530 18:49:34.625802 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00393872 (* 1 = 0.00393872 loss)
I0530 18:49:34.625807 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0157188 (* 1 = 0.0157188 loss)
I0530 18:49:34.625811 24924 sgd_solver.cpp:106] Iteration 29740, lr = 0.0002
I0530 18:50:26.477556 24924 solver.cpp:228] Iteration 29760, loss = 0.280351
I0530 18:50:26.477581 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:50:26.477588 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0440184 (* 1 = 0.0440184 loss)
I0530 18:50:26.477592 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0823157 (* 1 = 0.0823157 loss)
I0530 18:50:26.477596 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0142957 (* 1 = 0.0142957 loss)
I0530 18:50:26.477599 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0624743 (* 1 = 0.0624743 loss)
I0530 18:50:26.477603 24924 sgd_solver.cpp:106] Iteration 29760, lr = 0.0002
I0530 18:51:18.355463 24924 solver.cpp:228] Iteration 29780, loss = 0.376259
I0530 18:51:18.355502 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 18:51:18.355515 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0182486 (* 1 = 0.0182486 loss)
I0530 18:51:18.355522 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.117065 (* 1 = 0.117065 loss)
I0530 18:51:18.355530 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000862355 (* 1 = 0.000862355 loss)
I0530 18:51:18.355535 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0278834 (* 1 = 0.0278834 loss)
I0530 18:51:18.355545 24924 sgd_solver.cpp:106] Iteration 29780, lr = 0.0002
speed: 2.513s / iter
I0530 18:52:10.267913 24924 solver.cpp:228] Iteration 29800, loss = 0.216817
I0530 18:52:10.267941 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 18:52:10.267949 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.190898 (* 1 = 0.190898 loss)
I0530 18:52:10.267953 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.272344 (* 1 = 0.272344 loss)
I0530 18:52:10.267957 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0119706 (* 1 = 0.0119706 loss)
I0530 18:52:10.267961 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0322964 (* 1 = 0.0322964 loss)
I0530 18:52:10.267966 24924 sgd_solver.cpp:106] Iteration 29800, lr = 0.0002
I0530 18:53:02.294065 24924 solver.cpp:228] Iteration 29820, loss = 0.320728
I0530 18:53:02.294097 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 18:53:02.294104 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.340087 (* 1 = 0.340087 loss)
I0530 18:53:02.294108 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.385299 (* 1 = 0.385299 loss)
I0530 18:53:02.294112 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0125028 (* 1 = 0.0125028 loss)
I0530 18:53:02.294116 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0519697 (* 1 = 0.0519697 loss)
I0530 18:53:02.294121 24924 sgd_solver.cpp:106] Iteration 29820, lr = 0.0002
I0530 18:53:54.174690 24924 solver.cpp:228] Iteration 29840, loss = 0.162766
I0530 18:53:54.174718 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 18:53:54.174729 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00155908 (* 1 = 0.00155908 loss)
I0530 18:53:54.174736 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.048439 (* 1 = 0.048439 loss)
I0530 18:53:54.174742 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0163383 (* 1 = 0.0163383 loss)
I0530 18:53:54.174748 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0261764 (* 1 = 0.0261764 loss)
I0530 18:53:54.174757 24924 sgd_solver.cpp:106] Iteration 29840, lr = 0.0002
I0530 18:54:46.031111 24924 solver.cpp:228] Iteration 29860, loss = 0.248077
I0530 18:54:46.031141 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:54:46.031152 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0392983 (* 1 = 0.0392983 loss)
I0530 18:54:46.031155 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0420008 (* 1 = 0.0420008 loss)
I0530 18:54:46.031158 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00361412 (* 1 = 0.00361412 loss)
I0530 18:54:46.031162 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0263739 (* 1 = 0.0263739 loss)
I0530 18:54:46.031167 24924 sgd_solver.cpp:106] Iteration 29860, lr = 0.0002
I0530 18:55:37.906944 24924 solver.cpp:228] Iteration 29880, loss = 0.471663
I0530 18:55:37.906971 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 18:55:37.906980 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0234076 (* 1 = 0.0234076 loss)
I0530 18:55:37.906985 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0885156 (* 1 = 0.0885156 loss)
I0530 18:55:37.906987 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0117016 (* 1 = 0.0117016 loss)
I0530 18:55:37.906991 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00512044 (* 1 = 0.00512044 loss)
I0530 18:55:37.906996 24924 sgd_solver.cpp:106] Iteration 29880, lr = 0.0002
I0530 18:56:29.789047 24924 solver.cpp:228] Iteration 29900, loss = 0.482449
I0530 18:56:29.789072 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 18:56:29.789079 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.040148 (* 1 = 0.040148 loss)
I0530 18:56:29.789083 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.121369 (* 1 = 0.121369 loss)
I0530 18:56:29.789086 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0148905 (* 1 = 0.0148905 loss)
I0530 18:56:29.789089 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275182 (* 1 = 0.0275182 loss)
I0530 18:56:29.789094 24924 sgd_solver.cpp:106] Iteration 29900, lr = 0.0002
I0530 18:57:21.672726 24924 solver.cpp:228] Iteration 29920, loss = 0.220751
I0530 18:57:21.672752 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 18:57:21.672760 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0401973 (* 1 = 0.0401973 loss)
I0530 18:57:21.672765 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101335 (* 1 = 0.101335 loss)
I0530 18:57:21.672768 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0126948 (* 1 = 0.0126948 loss)
I0530 18:57:21.672772 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0312278 (* 1 = 0.0312278 loss)
I0530 18:57:21.672777 24924 sgd_solver.cpp:106] Iteration 29920, lr = 0.0002
I0530 18:58:13.543941 24924 solver.cpp:228] Iteration 29940, loss = 0.259153
I0530 18:58:13.543964 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 18:58:13.543972 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.146613 (* 1 = 0.146613 loss)
I0530 18:58:13.543977 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.185065 (* 1 = 0.185065 loss)
I0530 18:58:13.543979 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00405774 (* 1 = 0.00405774 loss)
I0530 18:58:13.543985 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0279309 (* 1 = 0.0279309 loss)
I0530 18:58:13.543992 24924 sgd_solver.cpp:106] Iteration 29940, lr = 0.0002
I0530 18:59:05.408507 24924 solver.cpp:228] Iteration 29960, loss = 0.291734
I0530 18:59:05.408536 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 18:59:05.408545 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.112782 (* 1 = 0.112782 loss)
I0530 18:59:05.408550 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.139572 (* 1 = 0.139572 loss)
I0530 18:59:05.408553 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00683421 (* 1 = 0.00683421 loss)
I0530 18:59:05.408557 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0258203 (* 1 = 0.0258203 loss)
I0530 18:59:05.408562 24924 sgd_solver.cpp:106] Iteration 29960, lr = 0.0002
I0530 18:59:57.312840 24924 solver.cpp:228] Iteration 29980, loss = 0.258621
I0530 18:59:57.312865 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 18:59:57.312871 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.153062 (* 1 = 0.153062 loss)
I0530 18:59:57.312875 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.190955 (* 1 = 0.190955 loss)
I0530 18:59:57.312880 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.014243 (* 1 = 0.014243 loss)
I0530 18:59:57.312882 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0161177 (* 1 = 0.0161177 loss)
I0530 18:59:57.312887 24924 sgd_solver.cpp:106] Iteration 29980, lr = 0.0002
speed: 2.514s / iter
I0530 19:00:46.809792 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_30000.caffemodel
I0530 19:00:49.981442 24924 solver.cpp:228] Iteration 30000, loss = 0.274377
I0530 19:00:49.981467 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 19:00:49.981475 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0190709 (* 1 = 0.0190709 loss)
I0530 19:00:49.981480 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0276307 (* 1 = 0.0276307 loss)
I0530 19:00:49.981484 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00169878 (* 1 = 0.00169878 loss)
I0530 19:00:49.981488 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0103523 (* 1 = 0.0103523 loss)
I0530 19:00:49.981493 24924 sgd_solver.cpp:106] Iteration 30000, lr = 0.0002
I0530 19:01:41.897749 24924 solver.cpp:228] Iteration 30020, loss = 0.288218
I0530 19:01:41.897773 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 19:01:41.897779 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265539 (* 1 = 0.0265539 loss)
I0530 19:01:41.897783 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.155231 (* 1 = 0.155231 loss)
I0530 19:01:41.897786 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0405133 (* 1 = 0.0405133 loss)
I0530 19:01:41.897790 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0498754 (* 1 = 0.0498754 loss)
I0530 19:01:41.897794 24924 sgd_solver.cpp:106] Iteration 30020, lr = 0.0002
I0530 19:02:33.767531 24924 solver.cpp:228] Iteration 30040, loss = 0.188011
I0530 19:02:33.767562 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:02:33.767573 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0912935 (* 1 = 0.0912935 loss)
I0530 19:02:33.767580 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.257864 (* 1 = 0.257864 loss)
I0530 19:02:33.767586 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.012552 (* 1 = 0.012552 loss)
I0530 19:02:33.767592 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0367808 (* 1 = 0.0367808 loss)
I0530 19:02:33.767599 24924 sgd_solver.cpp:106] Iteration 30040, lr = 0.0002
I0530 19:03:25.697151 24924 solver.cpp:228] Iteration 30060, loss = 0.564219
I0530 19:03:25.697173 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:03:25.697180 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0467151 (* 1 = 0.0467151 loss)
I0530 19:03:25.697185 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0744678 (* 1 = 0.0744678 loss)
I0530 19:03:25.697188 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00238648 (* 1 = 0.00238648 loss)
I0530 19:03:25.697191 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00948206 (* 1 = 0.00948206 loss)
I0530 19:03:25.697196 24924 sgd_solver.cpp:106] Iteration 30060, lr = 0.0002
I0530 19:04:17.564227 24924 solver.cpp:228] Iteration 30080, loss = 0.250357
I0530 19:04:17.564258 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 19:04:17.564268 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.178825 (* 1 = 0.178825 loss)
I0530 19:04:17.564275 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.322068 (* 1 = 0.322068 loss)
I0530 19:04:17.564281 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0282108 (* 1 = 0.0282108 loss)
I0530 19:04:17.564288 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.106732 (* 1 = 0.106732 loss)
I0530 19:04:17.564296 24924 sgd_solver.cpp:106] Iteration 30080, lr = 0.0002
I0530 19:05:09.435490 24924 solver.cpp:228] Iteration 30100, loss = 0.152645
I0530 19:05:09.435513 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:05:09.435520 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0952104 (* 1 = 0.0952104 loss)
I0530 19:05:09.435524 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0917122 (* 1 = 0.0917122 loss)
I0530 19:05:09.435528 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0201586 (* 1 = 0.0201586 loss)
I0530 19:05:09.435531 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0195614 (* 1 = 0.0195614 loss)
I0530 19:05:09.435536 24924 sgd_solver.cpp:106] Iteration 30100, lr = 0.0002
I0530 19:06:01.331948 24924 solver.cpp:228] Iteration 30120, loss = 0.180786
I0530 19:06:01.331974 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 19:06:01.331982 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0359141 (* 1 = 0.0359141 loss)
I0530 19:06:01.331987 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0939246 (* 1 = 0.0939246 loss)
I0530 19:06:01.331990 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00532599 (* 1 = 0.00532599 loss)
I0530 19:06:01.331995 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0298647 (* 1 = 0.0298647 loss)
I0530 19:06:01.332000 24924 sgd_solver.cpp:106] Iteration 30120, lr = 0.0002
I0530 19:06:53.203915 24924 solver.cpp:228] Iteration 30140, loss = 0.121386
I0530 19:06:53.203943 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 19:06:53.203953 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0386823 (* 1 = 0.0386823 loss)
I0530 19:06:53.203959 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0466999 (* 1 = 0.0466999 loss)
I0530 19:06:53.203964 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000923046 (* 1 = 0.000923046 loss)
I0530 19:06:53.203970 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0124047 (* 1 = 0.0124047 loss)
I0530 19:06:53.203976 24924 sgd_solver.cpp:106] Iteration 30140, lr = 0.0002
I0530 19:07:45.090104 24924 solver.cpp:228] Iteration 30160, loss = 0.485156
I0530 19:07:45.090129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:07:45.090137 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0806962 (* 1 = 0.0806962 loss)
I0530 19:07:45.090142 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0854715 (* 1 = 0.0854715 loss)
I0530 19:07:45.090145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00476257 (* 1 = 0.00476257 loss)
I0530 19:07:45.090149 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0174893 (* 1 = 0.0174893 loss)
I0530 19:07:45.090154 24924 sgd_solver.cpp:106] Iteration 30160, lr = 0.0002
I0530 19:08:36.974520 24924 solver.cpp:228] Iteration 30180, loss = 0.227639
I0530 19:08:36.974545 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:08:36.974551 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0758849 (* 1 = 0.0758849 loss)
I0530 19:08:36.974555 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0899836 (* 1 = 0.0899836 loss)
I0530 19:08:36.974560 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00201618 (* 1 = 0.00201618 loss)
I0530 19:08:36.974563 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00799771 (* 1 = 0.00799771 loss)
I0530 19:08:36.974567 24924 sgd_solver.cpp:106] Iteration 30180, lr = 0.0002
speed: 2.514s / iter
I0530 19:09:28.860075 24924 solver.cpp:228] Iteration 30200, loss = 0.371483
I0530 19:09:28.860100 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 19:09:28.860108 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.289931 (* 1 = 0.289931 loss)
I0530 19:09:28.860112 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.321005 (* 1 = 0.321005 loss)
I0530 19:09:28.860116 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0321119 (* 1 = 0.0321119 loss)
I0530 19:09:28.860119 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0886603 (* 1 = 0.0886603 loss)
I0530 19:09:28.860124 24924 sgd_solver.cpp:106] Iteration 30200, lr = 0.0002
I0530 19:10:20.732813 24924 solver.cpp:228] Iteration 30220, loss = 0.237875
I0530 19:10:20.732838 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:10:20.732846 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0358962 (* 1 = 0.0358962 loss)
I0530 19:10:20.732851 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.161737 (* 1 = 0.161737 loss)
I0530 19:10:20.732853 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0159131 (* 1 = 0.0159131 loss)
I0530 19:10:20.732856 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0249265 (* 1 = 0.0249265 loss)
I0530 19:10:20.732861 24924 sgd_solver.cpp:106] Iteration 30220, lr = 0.0002
I0530 19:11:12.599100 24924 solver.cpp:228] Iteration 30240, loss = 0.248762
I0530 19:11:12.599124 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 19:11:12.599133 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0413078 (* 1 = 0.0413078 loss)
I0530 19:11:12.599139 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0756038 (* 1 = 0.0756038 loss)
I0530 19:11:12.599145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000630146 (* 1 = 0.000630146 loss)
I0530 19:11:12.599150 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00646088 (* 1 = 0.00646088 loss)
I0530 19:11:12.599156 24924 sgd_solver.cpp:106] Iteration 30240, lr = 0.0002
I0530 19:12:04.514747 24924 solver.cpp:228] Iteration 30260, loss = 0.289551
I0530 19:12:04.514775 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 19:12:04.514786 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0171708 (* 1 = 0.0171708 loss)
I0530 19:12:04.514791 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0481385 (* 1 = 0.0481385 loss)
I0530 19:12:04.514797 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0116681 (* 1 = 0.0116681 loss)
I0530 19:12:04.514804 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00831597 (* 1 = 0.00831597 loss)
I0530 19:12:04.514813 24924 sgd_solver.cpp:106] Iteration 30260, lr = 0.0002
I0530 19:12:56.374469 24924 solver.cpp:228] Iteration 30280, loss = 0.333828
I0530 19:12:56.374492 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:12:56.374500 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0670138 (* 1 = 0.0670138 loss)
I0530 19:12:56.374503 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.147652 (* 1 = 0.147652 loss)
I0530 19:12:56.374506 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00437904 (* 1 = 0.00437904 loss)
I0530 19:12:56.374511 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130625 (* 1 = 0.0130625 loss)
I0530 19:12:56.374514 24924 sgd_solver.cpp:106] Iteration 30280, lr = 0.0002
I0530 19:13:48.249222 24924 solver.cpp:228] Iteration 30300, loss = 0.324172
I0530 19:13:48.249248 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.859375
I0530 19:13:48.249254 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.276226 (* 1 = 0.276226 loss)
I0530 19:13:48.249259 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.483655 (* 1 = 0.483655 loss)
I0530 19:13:48.249264 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0132618 (* 1 = 0.0132618 loss)
I0530 19:13:48.249267 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0993903 (* 1 = 0.0993903 loss)
I0530 19:13:48.249272 24924 sgd_solver.cpp:106] Iteration 30300, lr = 0.0002
I0530 19:14:40.078991 24924 solver.cpp:228] Iteration 30320, loss = 0.438126
I0530 19:14:40.079015 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 19:14:40.079021 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0637231 (* 1 = 0.0637231 loss)
I0530 19:14:40.079025 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.106623 (* 1 = 0.106623 loss)
I0530 19:14:40.079030 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0195591 (* 1 = 0.0195591 loss)
I0530 19:14:40.079032 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014703 (* 1 = 0.014703 loss)
I0530 19:14:40.079038 24924 sgd_solver.cpp:106] Iteration 30320, lr = 0.0002
I0530 19:15:31.910701 24924 solver.cpp:228] Iteration 30340, loss = 0.326792
I0530 19:15:31.910727 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 19:15:31.910734 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.017149 (* 1 = 0.017149 loss)
I0530 19:15:31.910738 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0427662 (* 1 = 0.0427662 loss)
I0530 19:15:31.910742 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00848534 (* 1 = 0.00848534 loss)
I0530 19:15:31.910748 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.029781 (* 1 = 0.029781 loss)
I0530 19:15:31.910751 24924 sgd_solver.cpp:106] Iteration 30340, lr = 0.0002
I0530 19:16:23.742563 24924 solver.cpp:228] Iteration 30360, loss = 0.383773
I0530 19:16:23.742585 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 19:16:23.742594 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0629159 (* 1 = 0.0629159 loss)
I0530 19:16:23.742596 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0962498 (* 1 = 0.0962498 loss)
I0530 19:16:23.742600 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0193848 (* 1 = 0.0193848 loss)
I0530 19:16:23.742604 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0181978 (* 1 = 0.0181978 loss)
I0530 19:16:23.742609 24924 sgd_solver.cpp:106] Iteration 30360, lr = 0.0002
I0530 19:17:15.610524 24924 solver.cpp:228] Iteration 30380, loss = 0.308176
I0530 19:17:15.610554 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 19:17:15.610563 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0633013 (* 1 = 0.0633013 loss)
I0530 19:17:15.610568 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.133938 (* 1 = 0.133938 loss)
I0530 19:17:15.610571 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00732673 (* 1 = 0.00732673 loss)
I0530 19:17:15.610575 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0187857 (* 1 = 0.0187857 loss)
I0530 19:17:15.610580 24924 sgd_solver.cpp:106] Iteration 30380, lr = 0.0002
speed: 2.515s / iter
I0530 19:18:07.469983 24924 solver.cpp:228] Iteration 30400, loss = 0.297726
I0530 19:18:07.470005 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.804688
I0530 19:18:07.470013 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.178847 (* 1 = 0.178847 loss)
I0530 19:18:07.470016 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.432887 (* 1 = 0.432887 loss)
I0530 19:18:07.470021 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0508395 (* 1 = 0.0508395 loss)
I0530 19:18:07.470024 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0567938 (* 1 = 0.0567938 loss)
I0530 19:18:07.470028 24924 sgd_solver.cpp:106] Iteration 30400, lr = 0.0002
I0530 19:18:59.308094 24924 solver.cpp:228] Iteration 30420, loss = 0.36993
I0530 19:18:59.308120 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 19:18:59.308130 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0231057 (* 1 = 0.0231057 loss)
I0530 19:18:59.308138 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0652508 (* 1 = 0.0652508 loss)
I0530 19:18:59.308145 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0158841 (* 1 = 0.0158841 loss)
I0530 19:18:59.308151 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017345 (* 1 = 0.017345 loss)
I0530 19:18:59.308156 24924 sgd_solver.cpp:106] Iteration 30420, lr = 0.0002
I0530 19:19:51.160833 24924 solver.cpp:228] Iteration 30440, loss = 0.47057
I0530 19:19:51.160861 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 19:19:51.160871 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.254779 (* 1 = 0.254779 loss)
I0530 19:19:51.160876 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.357406 (* 1 = 0.357406 loss)
I0530 19:19:51.160881 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00738587 (* 1 = 0.00738587 loss)
I0530 19:19:51.160887 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270411 (* 1 = 0.0270411 loss)
I0530 19:19:51.160893 24924 sgd_solver.cpp:106] Iteration 30440, lr = 0.0002
I0530 19:20:42.905439 24924 solver.cpp:228] Iteration 30460, loss = 0.251527
I0530 19:20:42.905465 24924 solver.cpp:244]     Train net output #0: accuarcy = 1
I0530 19:20:42.905475 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0300475 (* 1 = 0.0300475 loss)
I0530 19:20:42.905483 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0309202 (* 1 = 0.0309202 loss)
I0530 19:20:42.905488 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253709 (* 1 = 0.00253709 loss)
I0530 19:20:42.905493 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0041543 (* 1 = 0.0041543 loss)
I0530 19:20:42.905500 24924 sgd_solver.cpp:106] Iteration 30460, lr = 0.0002
I0530 19:21:34.722543 24924 solver.cpp:228] Iteration 30480, loss = 0.370958
I0530 19:21:34.722566 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:21:34.722573 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0855714 (* 1 = 0.0855714 loss)
I0530 19:21:34.722578 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.197087 (* 1 = 0.197087 loss)
I0530 19:21:34.722580 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.031337 (* 1 = 0.031337 loss)
I0530 19:21:34.722584 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.026574 (* 1 = 0.026574 loss)
I0530 19:21:34.722589 24924 sgd_solver.cpp:106] Iteration 30480, lr = 0.0002
I0530 19:22:26.605571 24924 solver.cpp:228] Iteration 30500, loss = 0.262428
I0530 19:22:26.605595 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 19:22:26.605602 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.160789 (* 1 = 0.160789 loss)
I0530 19:22:26.605607 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.130393 (* 1 = 0.130393 loss)
I0530 19:22:26.605610 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0378854 (* 1 = 0.0378854 loss)
I0530 19:22:26.605614 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.033653 (* 1 = 0.033653 loss)
I0530 19:22:26.605619 24924 sgd_solver.cpp:106] Iteration 30500, lr = 0.0002
I0530 19:23:18.375849 24924 solver.cpp:228] Iteration 30520, loss = 0.3662
I0530 19:23:18.375874 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:23:18.375881 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.102231 (* 1 = 0.102231 loss)
I0530 19:23:18.375885 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.101451 (* 1 = 0.101451 loss)
I0530 19:23:18.375890 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00499672 (* 1 = 0.00499672 loss)
I0530 19:23:18.375892 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0285444 (* 1 = 0.0285444 loss)
I0530 19:23:18.375896 24924 sgd_solver.cpp:106] Iteration 30520, lr = 0.0002
I0530 19:24:10.257525 24924 solver.cpp:228] Iteration 30540, loss = 0.328532
I0530 19:24:10.257550 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 19:24:10.257557 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.194316 (* 1 = 0.194316 loss)
I0530 19:24:10.257562 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.221186 (* 1 = 0.221186 loss)
I0530 19:24:10.257565 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00739889 (* 1 = 0.00739889 loss)
I0530 19:24:10.257570 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0969723 (* 1 = 0.0969723 loss)
I0530 19:24:10.257575 24924 sgd_solver.cpp:106] Iteration 30540, lr = 0.0002
I0530 19:25:02.140949 24924 solver.cpp:228] Iteration 30560, loss = 0.354973
I0530 19:25:02.140972 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 19:25:02.140980 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0760207 (* 1 = 0.0760207 loss)
I0530 19:25:02.140983 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.119738 (* 1 = 0.119738 loss)
I0530 19:25:02.140987 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00400258 (* 1 = 0.00400258 loss)
I0530 19:25:02.140990 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0147509 (* 1 = 0.0147509 loss)
I0530 19:25:02.140995 24924 sgd_solver.cpp:106] Iteration 30560, lr = 0.0002
I0530 19:25:54.012455 24924 solver.cpp:228] Iteration 30580, loss = 0.16192
I0530 19:25:54.012482 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:25:54.012493 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0529657 (* 1 = 0.0529657 loss)
I0530 19:25:54.012500 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.118451 (* 1 = 0.118451 loss)
I0530 19:25:54.012506 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00250646 (* 1 = 0.00250646 loss)
I0530 19:25:54.012512 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00909024 (* 1 = 0.00909024 loss)
I0530 19:25:54.012519 24924 sgd_solver.cpp:106] Iteration 30580, lr = 0.0002
speed: 2.515s / iter
I0530 19:26:45.870873 24924 solver.cpp:228] Iteration 30600, loss = 0.394807
I0530 19:26:45.870896 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.40625
I0530 19:26:45.870904 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.561471 (* 1 = 0.561471 loss)
I0530 19:26:45.870908 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.846648 (* 1 = 0.846648 loss)
I0530 19:26:45.870911 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.03954 (* 1 = 0.03954 loss)
I0530 19:26:45.870914 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.216761 (* 1 = 0.216761 loss)
I0530 19:26:45.870919 24924 sgd_solver.cpp:106] Iteration 30600, lr = 0.0002
I0530 19:27:37.705996 24924 solver.cpp:228] Iteration 30620, loss = 0.32248
I0530 19:27:37.706022 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:27:37.706030 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0493433 (* 1 = 0.0493433 loss)
I0530 19:27:37.706034 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0833124 (* 1 = 0.0833124 loss)
I0530 19:27:37.706038 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00658599 (* 1 = 0.00658599 loss)
I0530 19:27:37.706043 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0208644 (* 1 = 0.0208644 loss)
I0530 19:27:37.706046 24924 sgd_solver.cpp:106] Iteration 30620, lr = 0.0002
I0530 19:28:29.570114 24924 solver.cpp:228] Iteration 30640, loss = 0.37575
I0530 19:28:29.570145 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 19:28:29.570152 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.156759 (* 1 = 0.156759 loss)
I0530 19:28:29.570158 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.249101 (* 1 = 0.249101 loss)
I0530 19:28:29.570161 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0275833 (* 1 = 0.0275833 loss)
I0530 19:28:29.570165 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0701998 (* 1 = 0.0701998 loss)
I0530 19:28:29.570170 24924 sgd_solver.cpp:106] Iteration 30640, lr = 0.0002
I0530 19:29:21.425957 24924 solver.cpp:228] Iteration 30660, loss = 0.443984
I0530 19:29:21.425981 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.679688
I0530 19:29:21.425990 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.313541 (* 1 = 0.313541 loss)
I0530 19:29:21.425997 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.617836 (* 1 = 0.617836 loss)
I0530 19:29:21.426002 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0704639 (* 1 = 0.0704639 loss)
I0530 19:29:21.426007 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.295568 (* 1 = 0.295568 loss)
I0530 19:29:21.426013 24924 sgd_solver.cpp:106] Iteration 30660, lr = 0.0002
I0530 19:30:13.281999 24924 solver.cpp:228] Iteration 30680, loss = 0.300454
I0530 19:30:13.282024 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 19:30:13.282033 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0158028 (* 1 = 0.0158028 loss)
I0530 19:30:13.282039 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0639901 (* 1 = 0.0639901 loss)
I0530 19:30:13.282045 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00248243 (* 1 = 0.00248243 loss)
I0530 19:30:13.282049 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0270835 (* 1 = 0.0270835 loss)
I0530 19:30:13.282054 24924 sgd_solver.cpp:106] Iteration 30680, lr = 0.0002
I0530 19:31:05.133595 24924 solver.cpp:228] Iteration 30700, loss = 0.184582
I0530 19:31:05.133620 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 19:31:05.133627 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0804865 (* 1 = 0.0804865 loss)
I0530 19:31:05.133631 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.159413 (* 1 = 0.159413 loss)
I0530 19:31:05.133635 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0295762 (* 1 = 0.0295762 loss)
I0530 19:31:05.133638 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0367696 (* 1 = 0.0367696 loss)
I0530 19:31:05.133643 24924 sgd_solver.cpp:106] Iteration 30700, lr = 0.0002
I0530 19:31:56.974449 24924 solver.cpp:228] Iteration 30720, loss = 0.242815
I0530 19:31:56.974472 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 19:31:56.974480 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0474947 (* 1 = 0.0474947 loss)
I0530 19:31:56.974484 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.336276 (* 1 = 0.336276 loss)
I0530 19:31:56.974488 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0419195 (* 1 = 0.0419195 loss)
I0530 19:31:56.974493 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0630695 (* 1 = 0.0630695 loss)
I0530 19:31:56.974496 24924 sgd_solver.cpp:106] Iteration 30720, lr = 0.0002
I0530 19:32:48.812873 24924 solver.cpp:228] Iteration 30740, loss = 0.200542
I0530 19:32:48.812897 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 19:32:48.812904 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0017585 (* 1 = 0.0017585 loss)
I0530 19:32:48.812908 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0456668 (* 1 = 0.0456668 loss)
I0530 19:32:48.812916 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00172075 (* 1 = 0.00172075 loss)
I0530 19:32:48.812919 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0359829 (* 1 = 0.0359829 loss)
I0530 19:32:48.812924 24924 sgd_solver.cpp:106] Iteration 30740, lr = 0.0002
I0530 19:33:40.618175 24924 solver.cpp:228] Iteration 30760, loss = 0.310964
I0530 19:33:40.618201 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 19:33:40.618209 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0860111 (* 1 = 0.0860111 loss)
I0530 19:33:40.618213 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.181727 (* 1 = 0.181727 loss)
I0530 19:33:40.618217 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00273367 (* 1 = 0.00273367 loss)
I0530 19:33:40.618221 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0164554 (* 1 = 0.0164554 loss)
I0530 19:33:40.618225 24924 sgd_solver.cpp:106] Iteration 30760, lr = 0.0002
I0530 19:34:32.476191 24924 solver.cpp:228] Iteration 30780, loss = 0.255019
I0530 19:34:32.476215 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 19:34:32.476224 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.00325289 (* 1 = 0.00325289 loss)
I0530 19:34:32.476230 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0184468 (* 1 = 0.0184468 loss)
I0530 19:34:32.476235 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00232138 (* 1 = 0.00232138 loss)
I0530 19:34:32.476241 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00861738 (* 1 = 0.00861738 loss)
I0530 19:34:32.476246 24924 sgd_solver.cpp:106] Iteration 30780, lr = 0.0002
speed: 2.516s / iter
I0530 19:35:24.350924 24924 solver.cpp:228] Iteration 30800, loss = 0.426882
I0530 19:35:24.350950 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 19:35:24.350960 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.191312 (* 1 = 0.191312 loss)
I0530 19:35:24.350965 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.227106 (* 1 = 0.227106 loss)
I0530 19:35:24.350971 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00662107 (* 1 = 0.00662107 loss)
I0530 19:35:24.350980 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0597581 (* 1 = 0.0597581 loss)
I0530 19:35:24.350986 24924 sgd_solver.cpp:106] Iteration 30800, lr = 0.0002
I0530 19:36:16.226608 24924 solver.cpp:228] Iteration 30820, loss = 0.366161
I0530 19:36:16.226634 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.867188
I0530 19:36:16.226644 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.140293 (* 1 = 0.140293 loss)
I0530 19:36:16.226649 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.361865 (* 1 = 0.361865 loss)
I0530 19:36:16.226655 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00425954 (* 1 = 0.00425954 loss)
I0530 19:36:16.226660 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0708083 (* 1 = 0.0708083 loss)
I0530 19:36:16.226667 24924 sgd_solver.cpp:106] Iteration 30820, lr = 0.0002
I0530 19:37:08.102371 24924 solver.cpp:228] Iteration 30840, loss = 0.279871
I0530 19:37:08.102396 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:37:08.102404 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0510055 (* 1 = 0.0510055 loss)
I0530 19:37:08.102408 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.10492 (* 1 = 0.10492 loss)
I0530 19:37:08.102412 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0044713 (* 1 = 0.0044713 loss)
I0530 19:37:08.102416 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0130805 (* 1 = 0.0130805 loss)
I0530 19:37:08.102421 24924 sgd_solver.cpp:106] Iteration 30840, lr = 0.0002
I0530 19:37:59.980660 24924 solver.cpp:228] Iteration 30860, loss = 0.268376
I0530 19:37:59.980684 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:37:59.980693 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0742639 (* 1 = 0.0742639 loss)
I0530 19:37:59.980700 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0747444 (* 1 = 0.0747444 loss)
I0530 19:37:59.980705 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00319131 (* 1 = 0.00319131 loss)
I0530 19:37:59.980710 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0145661 (* 1 = 0.0145661 loss)
I0530 19:37:59.980716 24924 sgd_solver.cpp:106] Iteration 30860, lr = 0.0002
I0530 19:38:51.848104 24924 solver.cpp:228] Iteration 30880, loss = 0.38471
I0530 19:38:51.848129 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 19:38:51.848135 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.172965 (* 1 = 0.172965 loss)
I0530 19:38:51.848141 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.180379 (* 1 = 0.180379 loss)
I0530 19:38:51.848148 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0241239 (* 1 = 0.0241239 loss)
I0530 19:38:51.848152 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0492892 (* 1 = 0.0492892 loss)
I0530 19:38:51.848157 24924 sgd_solver.cpp:106] Iteration 30880, lr = 0.0002
I0530 19:39:43.766244 24924 solver.cpp:228] Iteration 30900, loss = 0.258798
I0530 19:39:43.766268 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 19:39:43.766275 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0103869 (* 1 = 0.0103869 loss)
I0530 19:39:43.766278 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0120139 (* 1 = 0.0120139 loss)
I0530 19:39:43.766283 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00470402 (* 1 = 0.00470402 loss)
I0530 19:39:43.766286 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0041122 (* 1 = 0.0041122 loss)
I0530 19:39:43.766290 24924 sgd_solver.cpp:106] Iteration 30900, lr = 0.0002
I0530 19:40:35.630004 24924 solver.cpp:228] Iteration 30920, loss = 0.362784
I0530 19:40:35.630030 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 19:40:35.630039 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0659225 (* 1 = 0.0659225 loss)
I0530 19:40:35.630044 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.18796 (* 1 = 0.18796 loss)
I0530 19:40:35.630051 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00137677 (* 1 = 0.00137677 loss)
I0530 19:40:35.630057 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0216761 (* 1 = 0.0216761 loss)
I0530 19:40:35.630064 24924 sgd_solver.cpp:106] Iteration 30920, lr = 0.0002
I0530 19:41:27.485764 24924 solver.cpp:228] Iteration 30940, loss = 0.272441
I0530 19:41:27.485790 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.890625
I0530 19:41:27.485797 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.269706 (* 1 = 0.269706 loss)
I0530 19:41:27.485803 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.353772 (* 1 = 0.353772 loss)
I0530 19:41:27.485808 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0137568 (* 1 = 0.0137568 loss)
I0530 19:41:27.485815 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0387155 (* 1 = 0.0387155 loss)
I0530 19:41:27.485819 24924 sgd_solver.cpp:106] Iteration 30940, lr = 0.0002
I0530 19:42:19.340997 24924 solver.cpp:228] Iteration 30960, loss = 0.283066
I0530 19:42:19.341024 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 19:42:19.341032 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.045817 (* 1 = 0.045817 loss)
I0530 19:42:19.341037 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0557949 (* 1 = 0.0557949 loss)
I0530 19:42:19.341042 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0223914 (* 1 = 0.0223914 loss)
I0530 19:42:19.341044 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0491776 (* 1 = 0.0491776 loss)
I0530 19:42:19.341049 24924 sgd_solver.cpp:106] Iteration 30960, lr = 0.0002
I0530 19:43:11.232468 24924 solver.cpp:228] Iteration 30980, loss = 0.228578
I0530 19:43:11.232496 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:43:11.232506 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0157891 (* 1 = 0.0157891 loss)
I0530 19:43:11.232509 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0781419 (* 1 = 0.0781419 loss)
I0530 19:43:11.232512 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00204196 (* 1 = 0.00204196 loss)
I0530 19:43:11.232517 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00209551 (* 1 = 0.00209551 loss)
I0530 19:43:11.232522 24924 sgd_solver.cpp:106] Iteration 30980, lr = 0.0002
speed: 2.516s / iter
I0530 19:44:03.111518 24924 solver.cpp:228] Iteration 31000, loss = 0.128979
I0530 19:44:03.111542 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 19:44:03.111551 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0825641 (* 1 = 0.0825641 loss)
I0530 19:44:03.111554 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.162877 (* 1 = 0.162877 loss)
I0530 19:44:03.111558 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00762553 (* 1 = 0.00762553 loss)
I0530 19:44:03.111562 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0361351 (* 1 = 0.0361351 loss)
I0530 19:44:03.111567 24924 sgd_solver.cpp:106] Iteration 31000, lr = 0.0002
I0530 19:44:55.011029 24924 solver.cpp:228] Iteration 31020, loss = 0.197509
I0530 19:44:55.011054 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:44:55.011061 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0509038 (* 1 = 0.0509038 loss)
I0530 19:44:55.011065 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.140251 (* 1 = 0.140251 loss)
I0530 19:44:55.011068 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00694791 (* 1 = 0.00694791 loss)
I0530 19:44:55.011072 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0323178 (* 1 = 0.0323178 loss)
I0530 19:44:55.011076 24924 sgd_solver.cpp:106] Iteration 31020, lr = 0.0002
I0530 19:45:46.870988 24924 solver.cpp:228] Iteration 31040, loss = 0.375001
I0530 19:45:46.871014 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.84375
I0530 19:45:46.871021 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.240832 (* 1 = 0.240832 loss)
I0530 19:45:46.871026 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.335831 (* 1 = 0.335831 loss)
I0530 19:45:46.871031 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0240175 (* 1 = 0.0240175 loss)
I0530 19:45:46.871034 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0804272 (* 1 = 0.0804272 loss)
I0530 19:45:46.871038 24924 sgd_solver.cpp:106] Iteration 31040, lr = 0.0002
I0530 19:46:38.749899 24924 solver.cpp:228] Iteration 31060, loss = 0.197916
I0530 19:46:38.749924 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 19:46:38.749933 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0601145 (* 1 = 0.0601145 loss)
I0530 19:46:38.749936 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.153531 (* 1 = 0.153531 loss)
I0530 19:46:38.749939 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00631717 (* 1 = 0.00631717 loss)
I0530 19:46:38.749943 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0115382 (* 1 = 0.0115382 loss)
I0530 19:46:38.749948 24924 sgd_solver.cpp:106] Iteration 31060, lr = 0.0002
I0530 19:47:30.577971 24924 solver.cpp:228] Iteration 31080, loss = 0.155184
I0530 19:47:30.577996 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:47:30.578003 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0827512 (* 1 = 0.0827512 loss)
I0530 19:47:30.578007 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.12571 (* 1 = 0.12571 loss)
I0530 19:47:30.578011 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0082525 (* 1 = 0.0082525 loss)
I0530 19:47:30.578014 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0113288 (* 1 = 0.0113288 loss)
I0530 19:47:30.578019 24924 sgd_solver.cpp:106] Iteration 31080, lr = 0.0002
I0530 19:48:22.450965 24924 solver.cpp:228] Iteration 31100, loss = 0.563992
I0530 19:48:22.450994 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.882812
I0530 19:48:22.451001 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.107354 (* 1 = 0.107354 loss)
I0530 19:48:22.451006 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.179354 (* 1 = 0.179354 loss)
I0530 19:48:22.451010 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00927407 (* 1 = 0.00927407 loss)
I0530 19:48:22.451015 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0156747 (* 1 = 0.0156747 loss)
I0530 19:48:22.451021 24924 sgd_solver.cpp:106] Iteration 31100, lr = 0.0002
I0530 19:49:14.293870 24924 solver.cpp:228] Iteration 31120, loss = 0.215581
I0530 19:49:14.293895 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 19:49:14.293901 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0298502 (* 1 = 0.0298502 loss)
I0530 19:49:14.293905 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0359075 (* 1 = 0.0359075 loss)
I0530 19:49:14.293910 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000466027 (* 1 = 0.000466027 loss)
I0530 19:49:14.293912 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00837998 (* 1 = 0.00837998 loss)
I0530 19:49:14.293916 24924 sgd_solver.cpp:106] Iteration 31120, lr = 0.0002
I0530 19:50:06.167511 24924 solver.cpp:228] Iteration 31140, loss = 0.24034
I0530 19:50:06.167541 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.9375
I0530 19:50:06.167547 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0630458 (* 1 = 0.0630458 loss)
I0530 19:50:06.167552 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.159711 (* 1 = 0.159711 loss)
I0530 19:50:06.167557 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00819681 (* 1 = 0.00819681 loss)
I0530 19:50:06.167560 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0612948 (* 1 = 0.0612948 loss)
I0530 19:50:06.167565 24924 sgd_solver.cpp:106] Iteration 31140, lr = 0.0002
I0530 19:50:58.006186 24924 solver.cpp:228] Iteration 31160, loss = 0.250148
I0530 19:50:58.006206 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:50:58.006214 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0743197 (* 1 = 0.0743197 loss)
I0530 19:50:58.006218 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.122163 (* 1 = 0.122163 loss)
I0530 19:50:58.006222 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00320035 (* 1 = 0.00320035 loss)
I0530 19:50:58.006225 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0383908 (* 1 = 0.0383908 loss)
I0530 19:50:58.006230 24924 sgd_solver.cpp:106] Iteration 31160, lr = 0.0002
I0530 19:51:49.856317 24924 solver.cpp:228] Iteration 31180, loss = 0.316484
I0530 19:51:49.856340 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.835938
I0530 19:51:49.856348 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.174493 (* 1 = 0.174493 loss)
I0530 19:51:49.856351 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.354315 (* 1 = 0.354315 loss)
I0530 19:51:49.856355 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00595544 (* 1 = 0.00595544 loss)
I0530 19:51:49.856359 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0339818 (* 1 = 0.0339818 loss)
I0530 19:51:49.856364 24924 sgd_solver.cpp:106] Iteration 31180, lr = 0.0002
speed: 2.517s / iter
I0530 19:52:41.717118 24924 solver.cpp:228] Iteration 31200, loss = 0.215884
I0530 19:52:41.717149 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 19:52:41.717159 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0384035 (* 1 = 0.0384035 loss)
I0530 19:52:41.717164 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.199783 (* 1 = 0.199783 loss)
I0530 19:52:41.717170 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00793495 (* 1 = 0.00793495 loss)
I0530 19:52:41.717175 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0206157 (* 1 = 0.0206157 loss)
I0530 19:52:41.717183 24924 sgd_solver.cpp:106] Iteration 31200, lr = 0.0002
I0530 19:53:33.584056 24924 solver.cpp:228] Iteration 31220, loss = 0.178359
I0530 19:53:33.584084 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 19:53:33.584091 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0765723 (* 1 = 0.0765723 loss)
I0530 19:53:33.584095 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0607949 (* 1 = 0.0607949 loss)
I0530 19:53:33.584100 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00636758 (* 1 = 0.00636758 loss)
I0530 19:53:33.584103 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0275752 (* 1 = 0.0275752 loss)
I0530 19:53:33.584110 24924 sgd_solver.cpp:106] Iteration 31220, lr = 0.0002
I0530 19:54:25.464751 24924 solver.cpp:228] Iteration 31240, loss = 0.25435
I0530 19:54:25.464781 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.960938
I0530 19:54:25.464788 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.040082 (* 1 = 0.040082 loss)
I0530 19:54:25.464792 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.100842 (* 1 = 0.100842 loss)
I0530 19:54:25.464797 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0052438 (* 1 = 0.0052438 loss)
I0530 19:54:25.464799 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024939 (* 1 = 0.024939 loss)
I0530 19:54:25.464804 24924 sgd_solver.cpp:106] Iteration 31240, lr = 0.0002
I0530 19:55:17.316537 24924 solver.cpp:228] Iteration 31260, loss = 0.252092
I0530 19:55:17.316561 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 19:55:17.316568 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0108354 (* 1 = 0.0108354 loss)
I0530 19:55:17.316573 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.032827 (* 1 = 0.032827 loss)
I0530 19:55:17.316577 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00581283 (* 1 = 0.00581283 loss)
I0530 19:55:17.316581 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00770119 (* 1 = 0.00770119 loss)
I0530 19:55:17.316586 24924 sgd_solver.cpp:106] Iteration 31260, lr = 0.0002
I0530 19:56:09.218195 24924 solver.cpp:228] Iteration 31280, loss = 0.248683
I0530 19:56:09.218217 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:56:09.218225 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0969174 (* 1 = 0.0969174 loss)
I0530 19:56:09.218228 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.17588 (* 1 = 0.17588 loss)
I0530 19:56:09.218231 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0328906 (* 1 = 0.0328906 loss)
I0530 19:56:09.218235 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0251988 (* 1 = 0.0251988 loss)
I0530 19:56:09.218240 24924 sgd_solver.cpp:106] Iteration 31280, lr = 0.0002
I0530 19:57:01.083217 24924 solver.cpp:228] Iteration 31300, loss = 0.489083
I0530 19:57:01.083247 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:57:01.083258 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0308589 (* 1 = 0.0308589 loss)
I0530 19:57:01.083266 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.188361 (* 1 = 0.188361 loss)
I0530 19:57:01.083272 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.01396 (* 1 = 0.01396 loss)
I0530 19:57:01.083279 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0063638 (* 1 = 0.0063638 loss)
I0530 19:57:01.083287 24924 sgd_solver.cpp:106] Iteration 31300, lr = 0.0002
I0530 19:57:52.960669 24924 solver.cpp:228] Iteration 31320, loss = 0.262322
I0530 19:57:52.960695 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 19:57:52.960702 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.111853 (* 1 = 0.111853 loss)
I0530 19:57:52.960706 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132358 (* 1 = 0.132358 loss)
I0530 19:57:52.960711 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0129741 (* 1 = 0.0129741 loss)
I0530 19:57:52.960713 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0243504 (* 1 = 0.0243504 loss)
I0530 19:57:52.960719 24924 sgd_solver.cpp:106] Iteration 31320, lr = 0.0002
I0530 19:58:44.831430 24924 solver.cpp:228] Iteration 31340, loss = 0.221379
I0530 19:58:44.831455 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 19:58:44.831465 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0296819 (* 1 = 0.0296819 loss)
I0530 19:58:44.831471 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0570305 (* 1 = 0.0570305 loss)
I0530 19:58:44.831477 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00177475 (* 1 = 0.00177475 loss)
I0530 19:58:44.831483 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00758643 (* 1 = 0.00758643 loss)
I0530 19:58:44.831491 24924 sgd_solver.cpp:106] Iteration 31340, lr = 0.0002
I0530 19:59:36.700788 24924 solver.cpp:228] Iteration 31360, loss = 0.305718
I0530 19:59:36.700811 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 19:59:36.700819 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0760811 (* 1 = 0.0760811 loss)
I0530 19:59:36.700822 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.22061 (* 1 = 0.22061 loss)
I0530 19:59:36.700826 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0353715 (* 1 = 0.0353715 loss)
I0530 19:59:36.700829 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.017542 (* 1 = 0.017542 loss)
I0530 19:59:36.700834 24924 sgd_solver.cpp:106] Iteration 31360, lr = 0.0002
I0530 20:00:28.552032 24924 solver.cpp:228] Iteration 31380, loss = 0.351523
I0530 20:00:28.552058 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 20:00:28.552068 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0305903 (* 1 = 0.0305903 loss)
I0530 20:00:28.552075 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0887129 (* 1 = 0.0887129 loss)
I0530 20:00:28.552080 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00510277 (* 1 = 0.00510277 loss)
I0530 20:00:28.552086 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0063069 (* 1 = 0.0063069 loss)
I0530 20:00:28.552093 24924 sgd_solver.cpp:106] Iteration 31380, lr = 0.0002
speed: 2.517s / iter
I0530 20:01:20.406633 24924 solver.cpp:228] Iteration 31400, loss = 0.257265
I0530 20:01:20.406656 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 20:01:20.406666 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0160726 (* 1 = 0.0160726 loss)
I0530 20:01:20.406672 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0863743 (* 1 = 0.0863743 loss)
I0530 20:01:20.406677 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102868 (* 1 = 0.0102868 loss)
I0530 20:01:20.406682 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0175134 (* 1 = 0.0175134 loss)
I0530 20:01:20.406689 24924 sgd_solver.cpp:106] Iteration 31400, lr = 0.0002
I0530 20:02:12.236735 24924 solver.cpp:228] Iteration 31420, loss = 0.322184
I0530 20:02:12.236760 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 20:02:12.236768 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.103511 (* 1 = 0.103511 loss)
I0530 20:02:12.236774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.134166 (* 1 = 0.134166 loss)
I0530 20:02:12.236780 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0108916 (* 1 = 0.0108916 loss)
I0530 20:02:12.236785 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0254696 (* 1 = 0.0254696 loss)
I0530 20:02:12.236791 24924 sgd_solver.cpp:106] Iteration 31420, lr = 0.0002
I0530 20:03:04.082150 24924 solver.cpp:228] Iteration 31440, loss = 0.53611
I0530 20:03:04.082175 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 20:03:04.082181 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.013012 (* 1 = 0.013012 loss)
I0530 20:03:04.082185 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0448642 (* 1 = 0.0448642 loss)
I0530 20:03:04.082190 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00236544 (* 1 = 0.00236544 loss)
I0530 20:03:04.082192 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00919992 (* 1 = 0.00919992 loss)
I0530 20:03:04.082197 24924 sgd_solver.cpp:106] Iteration 31440, lr = 0.0002
I0530 20:03:55.921226 24924 solver.cpp:228] Iteration 31460, loss = 0.264062
I0530 20:03:55.921252 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 20:03:55.921260 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0215484 (* 1 = 0.0215484 loss)
I0530 20:03:55.921264 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0314955 (* 1 = 0.0314955 loss)
I0530 20:03:55.921268 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0102738 (* 1 = 0.0102738 loss)
I0530 20:03:55.921272 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.024128 (* 1 = 0.024128 loss)
I0530 20:03:55.921277 24924 sgd_solver.cpp:106] Iteration 31460, lr = 0.0002
I0530 20:04:47.751322 24924 solver.cpp:228] Iteration 31480, loss = 0.257045
I0530 20:04:47.751348 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 20:04:47.751358 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0347179 (* 1 = 0.0347179 loss)
I0530 20:04:47.751364 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0865694 (* 1 = 0.0865694 loss)
I0530 20:04:47.751369 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00253264 (* 1 = 0.00253264 loss)
I0530 20:04:47.751375 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0154384 (* 1 = 0.0154384 loss)
I0530 20:04:47.751382 24924 sgd_solver.cpp:106] Iteration 31480, lr = 0.0002
I0530 20:05:39.593698 24924 solver.cpp:228] Iteration 31500, loss = 0.434605
I0530 20:05:39.593724 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 20:05:39.593732 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0556892 (* 1 = 0.0556892 loss)
I0530 20:05:39.593736 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.113662 (* 1 = 0.113662 loss)
I0530 20:05:39.593741 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00514144 (* 1 = 0.00514144 loss)
I0530 20:05:39.593745 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.007761 (* 1 = 0.007761 loss)
I0530 20:05:39.593750 24924 sgd_solver.cpp:106] Iteration 31500, lr = 0.0002
I0530 20:06:31.431476 24924 solver.cpp:228] Iteration 31520, loss = 0.512681
I0530 20:06:31.431501 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 20:06:31.431509 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.120908 (* 1 = 0.120908 loss)
I0530 20:06:31.431514 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.130998 (* 1 = 0.130998 loss)
I0530 20:06:31.431517 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00462924 (* 1 = 0.00462924 loss)
I0530 20:06:31.431521 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0508072 (* 1 = 0.0508072 loss)
I0530 20:06:31.431525 24924 sgd_solver.cpp:106] Iteration 31520, lr = 0.0002
I0530 20:07:23.269831 24924 solver.cpp:228] Iteration 31540, loss = 0.329523
I0530 20:07:23.269857 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 20:07:23.269865 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0561711 (* 1 = 0.0561711 loss)
I0530 20:07:23.269868 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0361506 (* 1 = 0.0361506 loss)
I0530 20:07:23.269872 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00128343 (* 1 = 0.00128343 loss)
I0530 20:07:23.269876 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00657628 (* 1 = 0.00657628 loss)
I0530 20:07:23.269881 24924 sgd_solver.cpp:106] Iteration 31540, lr = 0.0002
I0530 20:08:15.113359 24924 solver.cpp:228] Iteration 31560, loss = 0.155851
I0530 20:08:15.113384 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 20:08:15.113392 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0237033 (* 1 = 0.0237033 loss)
I0530 20:08:15.113397 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0267223 (* 1 = 0.0267223 loss)
I0530 20:08:15.113401 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00600548 (* 1 = 0.00600548 loss)
I0530 20:08:15.113404 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.011724 (* 1 = 0.011724 loss)
I0530 20:08:15.113409 24924 sgd_solver.cpp:106] Iteration 31560, lr = 0.0002
I0530 20:09:06.932865 24924 solver.cpp:228] Iteration 31580, loss = 0.274262
I0530 20:09:06.932889 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.929688
I0530 20:09:06.932898 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0380392 (* 1 = 0.0380392 loss)
I0530 20:09:06.932901 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.15399 (* 1 = 0.15399 loss)
I0530 20:09:06.932904 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00470611 (* 1 = 0.00470611 loss)
I0530 20:09:06.932909 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0521991 (* 1 = 0.0521991 loss)
I0530 20:09:06.932916 24924 sgd_solver.cpp:106] Iteration 31580, lr = 0.0002
speed: 2.518s / iter
I0530 20:09:58.759335 24924 solver.cpp:228] Iteration 31600, loss = 0.245765
I0530 20:09:58.759359 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 20:09:58.759371 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.173505 (* 1 = 0.173505 loss)
I0530 20:09:58.759377 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.123692 (* 1 = 0.123692 loss)
I0530 20:09:58.759383 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00604933 (* 1 = 0.00604933 loss)
I0530 20:09:58.759389 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0652094 (* 1 = 0.0652094 loss)
I0530 20:09:58.759397 24924 sgd_solver.cpp:106] Iteration 31600, lr = 0.0002
I0530 20:10:50.601804 24924 solver.cpp:228] Iteration 31620, loss = 0.272275
I0530 20:10:50.601830 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.90625
I0530 20:10:50.601838 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0719776 (* 1 = 0.0719776 loss)
I0530 20:10:50.601845 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.156878 (* 1 = 0.156878 loss)
I0530 20:10:50.601850 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00576925 (* 1 = 0.00576925 loss)
I0530 20:10:50.601855 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0427179 (* 1 = 0.0427179 loss)
I0530 20:10:50.601861 24924 sgd_solver.cpp:106] Iteration 31620, lr = 0.0002
I0530 20:11:42.419345 24924 solver.cpp:228] Iteration 31640, loss = 0.126091
I0530 20:11:42.419374 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 20:11:42.419385 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0554269 (* 1 = 0.0554269 loss)
I0530 20:11:42.419391 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0597709 (* 1 = 0.0597709 loss)
I0530 20:11:42.419399 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00160902 (* 1 = 0.00160902 loss)
I0530 20:11:42.419404 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00511417 (* 1 = 0.00511417 loss)
I0530 20:11:42.419414 24924 sgd_solver.cpp:106] Iteration 31640, lr = 0.0002
I0530 20:12:34.250912 24924 solver.cpp:228] Iteration 31660, loss = 0.283068
I0530 20:12:34.250936 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.953125
I0530 20:12:34.250942 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0991783 (* 1 = 0.0991783 loss)
I0530 20:12:34.250946 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0898567 (* 1 = 0.0898567 loss)
I0530 20:12:34.250950 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00625463 (* 1 = 0.00625463 loss)
I0530 20:12:34.250953 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00782268 (* 1 = 0.00782268 loss)
I0530 20:12:34.250958 24924 sgd_solver.cpp:106] Iteration 31660, lr = 0.0002
I0530 20:13:26.092710 24924 solver.cpp:228] Iteration 31680, loss = 0.279682
I0530 20:13:26.092736 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.921875
I0530 20:13:26.092744 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0759367 (* 1 = 0.0759367 loss)
I0530 20:13:26.092749 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.115123 (* 1 = 0.115123 loss)
I0530 20:13:26.092753 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00682776 (* 1 = 0.00682776 loss)
I0530 20:13:26.092757 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00857161 (* 1 = 0.00857161 loss)
I0530 20:13:26.092762 24924 sgd_solver.cpp:106] Iteration 31680, lr = 0.0002
I0530 20:14:17.938148 24924 solver.cpp:228] Iteration 31700, loss = 0.221019
I0530 20:14:17.938179 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 20:14:17.938186 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0430603 (* 1 = 0.0430603 loss)
I0530 20:14:17.938190 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.132537 (* 1 = 0.132537 loss)
I0530 20:14:17.938194 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00218738 (* 1 = 0.00218738 loss)
I0530 20:14:17.938197 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00437168 (* 1 = 0.00437168 loss)
I0530 20:14:17.938202 24924 sgd_solver.cpp:106] Iteration 31700, lr = 0.0002
I0530 20:15:09.787075 24924 solver.cpp:228] Iteration 31720, loss = 0.407248
I0530 20:15:09.787101 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.945312
I0530 20:15:09.787111 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0754344 (* 1 = 0.0754344 loss)
I0530 20:15:09.787114 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.116286 (* 1 = 0.116286 loss)
I0530 20:15:09.787118 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00565792 (* 1 = 0.00565792 loss)
I0530 20:15:09.787122 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0125028 (* 1 = 0.0125028 loss)
I0530 20:15:09.787127 24924 sgd_solver.cpp:106] Iteration 31720, lr = 0.0002
I0530 20:16:01.631738 24924 solver.cpp:228] Iteration 31740, loss = 0.197092
I0530 20:16:01.631763 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 20:16:01.631770 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.022052 (* 1 = 0.022052 loss)
I0530 20:16:01.631774 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0502773 (* 1 = 0.0502773 loss)
I0530 20:16:01.631778 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00322621 (* 1 = 0.00322621 loss)
I0530 20:16:01.631781 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00268751 (* 1 = 0.00268751 loss)
I0530 20:16:01.631786 24924 sgd_solver.cpp:106] Iteration 31740, lr = 0.0002
I0530 20:16:53.485833 24924 solver.cpp:228] Iteration 31760, loss = 0.274475
I0530 20:16:53.485863 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 20:16:53.485872 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0265718 (* 1 = 0.0265718 loss)
I0530 20:16:53.485875 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0509225 (* 1 = 0.0509225 loss)
I0530 20:16:53.485880 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0131324 (* 1 = 0.0131324 loss)
I0530 20:16:53.485884 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0217861 (* 1 = 0.0217861 loss)
I0530 20:16:53.485889 24924 sgd_solver.cpp:106] Iteration 31760, lr = 0.0002
I0530 20:17:45.326122 24924 solver.cpp:228] Iteration 31780, loss = 0.321822
I0530 20:17:45.326148 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 20:17:45.326155 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0084895 (* 1 = 0.0084895 loss)
I0530 20:17:45.326159 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0635315 (* 1 = 0.0635315 loss)
I0530 20:17:45.326164 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0208858 (* 1 = 0.0208858 loss)
I0530 20:17:45.326166 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0197842 (* 1 = 0.0197842 loss)
I0530 20:17:45.326171 24924 sgd_solver.cpp:106] Iteration 31780, lr = 0.0002
speed: 2.518s / iter
I0530 20:18:37.160557 24924 solver.cpp:228] Iteration 31800, loss = 0.249505
I0530 20:18:37.160581 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 20:18:37.160589 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0536299 (* 1 = 0.0536299 loss)
I0530 20:18:37.160594 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0407095 (* 1 = 0.0407095 loss)
I0530 20:18:37.160598 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.000550909 (* 1 = 0.000550909 loss)
I0530 20:18:37.160601 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00542013 (* 1 = 0.00542013 loss)
I0530 20:18:37.160606 24924 sgd_solver.cpp:106] Iteration 31800, lr = 0.0002
I0530 20:19:29.030386 24924 solver.cpp:228] Iteration 31820, loss = 0.152727
I0530 20:19:29.030411 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.984375
I0530 20:19:29.030417 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0269425 (* 1 = 0.0269425 loss)
I0530 20:19:29.030421 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0588867 (* 1 = 0.0588867 loss)
I0530 20:19:29.030426 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00446349 (* 1 = 0.00446349 loss)
I0530 20:19:29.030428 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.014417 (* 1 = 0.014417 loss)
I0530 20:19:29.030433 24924 sgd_solver.cpp:106] Iteration 31820, lr = 0.0002
I0530 20:20:20.885280 24924 solver.cpp:228] Iteration 31840, loss = 0.19973
I0530 20:20:20.885306 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 20:20:20.885315 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0444109 (* 1 = 0.0444109 loss)
I0530 20:20:20.885319 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0486407 (* 1 = 0.0486407 loss)
I0530 20:20:20.885324 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00421314 (* 1 = 0.00421314 loss)
I0530 20:20:20.885327 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00184218 (* 1 = 0.00184218 loss)
I0530 20:20:20.885332 24924 sgd_solver.cpp:106] Iteration 31840, lr = 0.0002
I0530 20:21:12.763782 24924 solver.cpp:228] Iteration 31860, loss = 0.230142
I0530 20:21:12.763808 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 20:21:12.763815 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0534039 (* 1 = 0.0534039 loss)
I0530 20:21:12.763819 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0575356 (* 1 = 0.0575356 loss)
I0530 20:21:12.763823 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00200896 (* 1 = 0.00200896 loss)
I0530 20:21:12.763826 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0111082 (* 1 = 0.0111082 loss)
I0530 20:21:12.763830 24924 sgd_solver.cpp:106] Iteration 31860, lr = 0.0002
I0530 20:22:04.598285 24924 solver.cpp:228] Iteration 31880, loss = 0.314611
I0530 20:22:04.598310 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.976562
I0530 20:22:04.598318 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0248741 (* 1 = 0.0248741 loss)
I0530 20:22:04.598323 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0632662 (* 1 = 0.0632662 loss)
I0530 20:22:04.598327 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00510516 (* 1 = 0.00510516 loss)
I0530 20:22:04.598330 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0100479 (* 1 = 0.0100479 loss)
I0530 20:22:04.598336 24924 sgd_solver.cpp:106] Iteration 31880, lr = 0.0002
I0530 20:22:56.459023 24924 solver.cpp:228] Iteration 31900, loss = 0.399019
I0530 20:22:56.459049 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.765625
I0530 20:22:56.459056 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.255742 (* 1 = 0.255742 loss)
I0530 20:22:56.459061 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.523142 (* 1 = 0.523142 loss)
I0530 20:22:56.459065 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.0325806 (* 1 = 0.0325806 loss)
I0530 20:22:56.459069 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.100283 (* 1 = 0.100283 loss)
I0530 20:22:56.459074 24924 sgd_solver.cpp:106] Iteration 31900, lr = 0.0002
I0530 20:23:48.214191 24924 solver.cpp:228] Iteration 31920, loss = 0.299359
I0530 20:23:48.214215 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.914062
I0530 20:23:48.214221 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0965644 (* 1 = 0.0965644 loss)
I0530 20:23:48.214226 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.206889 (* 1 = 0.206889 loss)
I0530 20:23:48.214229 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00905637 (* 1 = 0.00905637 loss)
I0530 20:23:48.214232 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.016415 (* 1 = 0.016415 loss)
I0530 20:23:48.214236 24924 sgd_solver.cpp:106] Iteration 31920, lr = 0.0002
I0530 20:24:40.088891 24924 solver.cpp:228] Iteration 31940, loss = 0.323589
I0530 20:24:40.088923 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.96875
I0530 20:24:40.088935 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0176912 (* 1 = 0.0176912 loss)
I0530 20:24:40.088943 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0580142 (* 1 = 0.0580142 loss)
I0530 20:24:40.088949 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00438177 (* 1 = 0.00438177 loss)
I0530 20:24:40.088953 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00888666 (* 1 = 0.00888666 loss)
I0530 20:24:40.088959 24924 sgd_solver.cpp:106] Iteration 31940, lr = 0.0002
I0530 20:25:31.920229 24924 solver.cpp:228] Iteration 31960, loss = 0.228489
I0530 20:25:31.920254 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.992188
I0530 20:25:31.920261 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.0223611 (* 1 = 0.0223611 loss)
I0530 20:25:31.920265 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.0324459 (* 1 = 0.0324459 loss)
I0530 20:25:31.920269 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00152378 (* 1 = 0.00152378 loss)
I0530 20:25:31.920272 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.00452006 (* 1 = 0.00452006 loss)
I0530 20:25:31.920279 24924 sgd_solver.cpp:106] Iteration 31960, lr = 0.0002
I0530 20:26:23.795889 24924 solver.cpp:228] Iteration 31980, loss = 0.218012
I0530 20:26:23.795915 24924 solver.cpp:244]     Train net output #0: accuarcy = 0.898438
I0530 20:26:23.795922 24924 solver.cpp:244]     Train net output #1: loss_bbox = 0.133388 (* 1 = 0.133388 loss)
I0530 20:26:23.795928 24924 solver.cpp:244]     Train net output #2: loss_cls = 0.19346 (* 1 = 0.19346 loss)
I0530 20:26:23.795931 24924 solver.cpp:244]     Train net output #3: rpn_cls_loss = 0.00671397 (* 1 = 0.00671397 loss)
I0530 20:26:23.795935 24924 solver.cpp:244]     Train net output #4: rpn_loss_bbox = 0.0380164 (* 1 = 0.0380164 loss)
I0530 20:26:23.795940 24924 sgd_solver.cpp:106] Iteration 31980, lr = 0.0002
speed: 2.519s / iter
I0530 20:27:13.227694 24924 net.cpp:870] Serializing 285 layers
Wrote snapshot to: /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel
done solving

real	1343m36.317s
user	1126m30.816s
sys	228m0.764s
+ set +x
+ ./tools/test_net.py --gpu 0 --def experiments/5_28_original/test_agnostic.prototxt --net /home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel --imdb voc_0712_test --cfg experiments/5_28_original/rfcn_end2end_ohem.yml --set TEST.SOFT_NMS 0
Called with args:
Namespace(caffemodel='/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel', cfg_file='experiments/5_28_original/rfcn_end2end_ohem.yml', comp_mode=False, gpu_id=0, imdb_name='voc_0712_test', max_per_image=400, prototxt='experiments/5_28_original/test_agnostic.prototxt', rpn_file=None, set_cfgs=['TEST.SOFT_NMS', '0'], vis=False, wait=True)
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/user/Disk1.8T/py-R-FCN/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': '5_28_original/model',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/user/Disk1.8T/py-R-FCN/models/pascal_voc',
 'MODEL_PATH': '/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/user/Disk1.8T/py-R-FCN',
 'TEST': {'AGNOSTIC': True,
          'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1280,
          'NMS': 0.4,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 8,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [640],
          'SOFT_NMS': 0,
          'SVM': False},
 'TRAIN': {'AGNOSTIC': True,
           'ASPECT_GROUPING': True,
           'BATCH_SIZE': -1,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.167,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1280,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 8,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'RPN_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'RPN_NORMALIZE_TARGETS': True,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SCALES': [640],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0530 20:27:15.037468 26136 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface
W0530 20:27:15.037492 26136 _caffe.cpp:123] Use this instead (with the named "weights" parameter):
W0530 20:27:15.037492 26136 _caffe.cpp:125] Net('experiments/5_28_original/test_agnostic.prototxt', 1, weights='/home/user/Disk1.8T/py-R-FCN/experiments/5_28_original/model/resnet50_rfcn_ohem_iter_32000.caffemodel')
I0530 20:27:15.061211 26136 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: experiments/5_28_original/test_agnostic.prototxt
I0530 20:27:15.061405 26136 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0530 20:27:15.061409 26136 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0530 20:27:15.062597 26136 net.cpp:58] Initializing net from parameters: 
name: "ResNet50"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2b_relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "res2a_branch2c"
  type: "Convolution"
  bottom: "res2a_branch2b"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2a_branch2c"
  type: "BatchNorm"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2a_branch2c"
  type: "Scale"
  bottom: "res2a_branch2c"
  top: "res2a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2c"
  top: "res2a"
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2b_relu"
  type: "ReLU"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
}
layer {
  name: "res2b_branch2c"
  type: "Convolution"
  bottom: "res2b_branch2b"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2b_branch2c"
  type: "BatchNorm"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2b_branch2c"
  type: "Scale"
  bottom: "res2b_branch2c"
  top: "res2b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2c"
  top: "res2b"
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res2c_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2a"
  type: "BatchNorm"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2a"
  type: "Scale"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2a_relu"
  type: "ReLU"
  bottom: "res2c_branch2a"
  top: "res2c_branch2a"
}
layer {
  name: "res2c_branch2b"
  type: "Convolution"
  bottom: "res2c_branch2a"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn2c_branch2b"
  type: "BatchNorm"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2b"
  type: "Scale"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c_branch2b_relu"
  type: "ReLU"
  bottom: "res2c_branch2b"
  top: "res2c_branch2b"
}
layer {
  name: "res2c_branch2c"
  type: "Convolution"
  bottom: "res2c_branch2b"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn2c_branch2c"
  type: "BatchNorm"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale2c_branch2c"
  type: "Scale"
  bottom: "res2c_branch2c"
  top: "res2c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2c"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "res2c_branch2c"
  top: "res2c"
}
layer {
  name: "res2c_relu"
  type: "ReLU"
  bottom: "res2c"
  top: "res2c"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2c"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2b_relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "res3a_branch2c"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "res3a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3a_branch2c"
  type: "BatchNorm"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3a_branch2c"
  type: "Scale"
  bottom: "res3a_branch2c"
  top: "res3a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2c"
  top: "res3a"
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2b_relu"
  type: "ReLU"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
}
layer {
  name: "res3b_branch2c"
  type: "Convolution"
  bottom: "res3b_branch2b"
  top: "res3b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3b_branch2c"
  type: "BatchNorm"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3b_branch2c"
  type: "Scale"
  bottom: "res3b_branch2c"
  top: "res3b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2c"
  top: "res3b"
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res3c_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res3c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2a"
  type: "BatchNorm"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2a"
  type: "Scale"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2a_relu"
  type: "ReLU"
  bottom: "res3c_branch2a"
  top: "res3c_branch2a"
}
layer {
  name: "res3c_branch2b"
  type: "Convolution"
  bottom: "res3c_branch2a"
  top: "res3c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3c_branch2b"
  type: "BatchNorm"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2b"
  type: "Scale"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c_branch2b_relu"
  type: "ReLU"
  bottom: "res3c_branch2b"
  top: "res3c_branch2b"
}
layer {
  name: "res3c_branch2c"
  type: "Convolution"
  bottom: "res3c_branch2b"
  top: "res3c_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3c_branch2c"
  type: "BatchNorm"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3c_branch2c"
  type: "Scale"
  bottom: "res3c_branch2c"
  top: "res3c_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3c"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "res3c_branch2c"
  top: "res3c"
}
layer {
  name: "res3c_relu"
  type: "ReLU"
  bottom: "res3c"
  top: "res3c"
}
layer {
  name: "res3d_branch2a"
  type: "Convolution"
  bottom: "res3c"
  top: "res3d_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2a"
  type: "BatchNorm"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2a"
  type: "Scale"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2a_relu"
  type: "ReLU"
  bottom: "res3d_branch2a"
  top: "res3d_branch2a"
}
layer {
  name: "res3d_branch2b"
  type: "Convolution"
  bottom: "res3d_branch2a"
  top: "res3d_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn3d_branch2b"
  type: "BatchNorm"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2b"
  type: "Scale"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d_branch2b_relu"
  type: "ReLU"
  bottom: "res3d_branch2b"
  top: "res3d_branch2b"
}
layer {
  name: "res3d_branch2c"
  type: "Convolution"
  bottom: "res3d_branch2b"
  top: "res3d_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn3d_branch2c"
  type: "BatchNorm"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale3d_branch2c"
  type: "Scale"
  bottom: "res3d_branch2c"
  top: "res3d_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3d"
  type: "Eltwise"
  bottom: "res3c"
  bottom: "res3d_branch2c"
  top: "res3d"
}
layer {
  name: "res3d_relu"
  type: "ReLU"
  bottom: "res3d"
  top: "res3d"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3d"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2b_relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "res4a_branch2c"
  type: "Convolution"
  bottom: "res4a_branch2b"
  top: "res4a_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4a_branch2c"
  type: "BatchNorm"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4a_branch2c"
  type: "Scale"
  bottom: "res4a_branch2c"
  top: "res4a_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2c"
  top: "res4a"
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2b_relu"
  type: "ReLU"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
}
layer {
  name: "res4b_branch2c"
  type: "Convolution"
  bottom: "res4b_branch2b"
  top: "res4b_branch2c"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4b_branch2c"
  type: "BatchNorm"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4b_branch2c"
  type: "Scale"
  bottom: "res4b_branch2c"
  top: "res4b_branch2c"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2c"
  top: "res4b"
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res4c_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res4c_branch2a"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "bn4c_branch2a"
  type: "BatchNorm"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2a"
  type: "Scale"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2a_relu"
  type: "ReLU"
  bottom: "res4c_branch2a"
  top: "res4c_branch2a"
}
layer {
  name: "res4c_branch2b"
  type: "Convolution"
  bottom: "res4c_branch2a"
  top: "res4c_branch2b"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "bn4c_branch2b"
  type: "BatchNorm"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "scale4c_branch2b"
  type: "Scale"
  bottom: "res4c_branch2b"
  top: "res4c_branch2b"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4c_branch2b_relu"
  type: "ReLU"
  bottom: "res4c_branch2b"
  top: "r
I0530 20:27:15.064275 26136 layer_factory.hpp:77] Creating layer input
I0530 20:27:15.064304 26136 net.cpp:100] Creating Layer input
I0530 20:27:15.064311 26136 net.cpp:418] input -> data
I0530 20:27:15.064343 26136 net.cpp:418] input -> im_info
I0530 20:27:15.084556 26136 net.cpp:150] Setting up input
I0530 20:27:15.084587 26136 net.cpp:157] Top shape: 1 3 224 224 (150528)
I0530 20:27:15.084592 26136 net.cpp:157] Top shape: 1 3 (3)
I0530 20:27:15.084594 26136 net.cpp:165] Memory required for data: 602124
I0530 20:27:15.084612 26136 layer_factory.hpp:77] Creating layer conv1
I0530 20:27:15.084663 26136 net.cpp:100] Creating Layer conv1
I0530 20:27:15.084674 26136 net.cpp:444] conv1 <- data
I0530 20:27:15.084694 26136 net.cpp:418] conv1 -> conv1
I0530 20:27:15.388769 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 225816
I0530 20:27:15.388999 26136 net.cpp:150] Setting up conv1
I0530 20:27:15.389022 26136 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0530 20:27:15.389025 26136 net.cpp:165] Memory required for data: 3813388
I0530 20:27:15.389075 26136 layer_factory.hpp:77] Creating layer bn_conv1
I0530 20:27:15.389108 26136 net.cpp:100] Creating Layer bn_conv1
I0530 20:27:15.389118 26136 net.cpp:444] bn_conv1 <- conv1
I0530 20:27:15.389132 26136 net.cpp:405] bn_conv1 -> conv1 (in-place)
I0530 20:27:15.389295 26136 net.cpp:150] Setting up bn_conv1
I0530 20:27:15.389302 26136 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0530 20:27:15.389303 26136 net.cpp:165] Memory required for data: 7024652
I0530 20:27:15.389328 26136 layer_factory.hpp:77] Creating layer scale_conv1
I0530 20:27:15.389343 26136 net.cpp:100] Creating Layer scale_conv1
I0530 20:27:15.389348 26136 net.cpp:444] scale_conv1 <- conv1
I0530 20:27:15.389359 26136 net.cpp:405] scale_conv1 -> conv1 (in-place)
I0530 20:27:15.389403 26136 layer_factory.hpp:77] Creating layer scale_conv1
I0530 20:27:15.389534 26136 net.cpp:150] Setting up scale_conv1
I0530 20:27:15.389541 26136 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0530 20:27:15.389544 26136 net.cpp:165] Memory required for data: 10235916
I0530 20:27:15.389554 26136 layer_factory.hpp:77] Creating layer conv1_relu
I0530 20:27:15.389566 26136 net.cpp:100] Creating Layer conv1_relu
I0530 20:27:15.389571 26136 net.cpp:444] conv1_relu <- conv1
I0530 20:27:15.389581 26136 net.cpp:405] conv1_relu -> conv1 (in-place)
I0530 20:27:15.389710 26136 net.cpp:150] Setting up conv1_relu
I0530 20:27:15.389716 26136 net.cpp:157] Top shape: 1 64 112 112 (802816)
I0530 20:27:15.389719 26136 net.cpp:165] Memory required for data: 13447180
I0530 20:27:15.389722 26136 layer_factory.hpp:77] Creating layer pool1
I0530 20:27:15.389734 26136 net.cpp:100] Creating Layer pool1
I0530 20:27:15.389737 26136 net.cpp:444] pool1 <- conv1
I0530 20:27:15.389748 26136 net.cpp:418] pool1 -> pool1
I0530 20:27:15.389788 26136 net.cpp:150] Setting up pool1
I0530 20:27:15.389794 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.389796 26136 net.cpp:165] Memory required for data: 14249996
I0530 20:27:15.389799 26136 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0530 20:27:15.389807 26136 net.cpp:100] Creating Layer pool1_pool1_0_split
I0530 20:27:15.389811 26136 net.cpp:444] pool1_pool1_0_split <- pool1
I0530 20:27:15.389820 26136 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0530 20:27:15.389833 26136 net.cpp:418] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0530 20:27:15.389864 26136 net.cpp:150] Setting up pool1_pool1_0_split
I0530 20:27:15.389871 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.389874 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.389876 26136 net.cpp:165] Memory required for data: 15855628
I0530 20:27:15.389879 26136 layer_factory.hpp:77] Creating layer res2a_branch1
I0530 20:27:15.389894 26136 net.cpp:100] Creating Layer res2a_branch1
I0530 20:27:15.389897 26136 net.cpp:444] res2a_branch1 <- pool1_pool1_0_split_0
I0530 20:27:15.389907 26136 net.cpp:418] res2a_branch1 -> res2a_branch1
I0530 20:27:15.390620 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.390635 26136 net.cpp:150] Setting up res2a_branch1
I0530 20:27:15.390641 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.390645 26136 net.cpp:165] Memory required for data: 19066892
I0530 20:27:15.390655 26136 layer_factory.hpp:77] Creating layer bn2a_branch1
I0530 20:27:15.390669 26136 net.cpp:100] Creating Layer bn2a_branch1
I0530 20:27:15.390676 26136 net.cpp:444] bn2a_branch1 <- res2a_branch1
I0530 20:27:15.390686 26136 net.cpp:405] bn2a_branch1 -> res2a_branch1 (in-place)
I0530 20:27:15.391371 26136 net.cpp:150] Setting up bn2a_branch1
I0530 20:27:15.391378 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.391381 26136 net.cpp:165] Memory required for data: 22278156
I0530 20:27:15.391407 26136 layer_factory.hpp:77] Creating layer scale2a_branch1
I0530 20:27:15.391422 26136 net.cpp:100] Creating Layer scale2a_branch1
I0530 20:27:15.391427 26136 net.cpp:444] scale2a_branch1 <- res2a_branch1
I0530 20:27:15.391436 26136 net.cpp:405] scale2a_branch1 -> res2a_branch1 (in-place)
I0530 20:27:15.391479 26136 layer_factory.hpp:77] Creating layer scale2a_branch1
I0530 20:27:15.391582 26136 net.cpp:150] Setting up scale2a_branch1
I0530 20:27:15.391589 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.391592 26136 net.cpp:165] Memory required for data: 25489420
I0530 20:27:15.391602 26136 layer_factory.hpp:77] Creating layer res2a_branch2a
I0530 20:27:15.391614 26136 net.cpp:100] Creating Layer res2a_branch2a
I0530 20:27:15.391619 26136 net.cpp:444] res2a_branch2a <- pool1_pool1_0_split_1
I0530 20:27:15.391631 26136 net.cpp:418] res2a_branch2a -> res2a_branch2a
I0530 20:27:15.392328 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.392341 26136 net.cpp:150] Setting up res2a_branch2a
I0530 20:27:15.392349 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.392352 26136 net.cpp:165] Memory required for data: 26292236
I0530 20:27:15.392361 26136 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0530 20:27:15.392374 26136 net.cpp:100] Creating Layer bn2a_branch2a
I0530 20:27:15.392379 26136 net.cpp:444] bn2a_branch2a <- res2a_branch2a
I0530 20:27:15.392390 26136 net.cpp:405] bn2a_branch2a -> res2a_branch2a (in-place)
I0530 20:27:15.392526 26136 net.cpp:150] Setting up bn2a_branch2a
I0530 20:27:15.392532 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.392534 26136 net.cpp:165] Memory required for data: 27095052
I0530 20:27:15.392556 26136 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0530 20:27:15.392570 26136 net.cpp:100] Creating Layer scale2a_branch2a
I0530 20:27:15.392575 26136 net.cpp:444] scale2a_branch2a <- res2a_branch2a
I0530 20:27:15.392585 26136 net.cpp:405] scale2a_branch2a -> res2a_branch2a (in-place)
I0530 20:27:15.392627 26136 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0530 20:27:15.392733 26136 net.cpp:150] Setting up scale2a_branch2a
I0530 20:27:15.392740 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.392743 26136 net.cpp:165] Memory required for data: 27897868
I0530 20:27:15.392752 26136 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0530 20:27:15.392761 26136 net.cpp:100] Creating Layer res2a_branch2a_relu
I0530 20:27:15.392766 26136 net.cpp:444] res2a_branch2a_relu <- res2a_branch2a
I0530 20:27:15.392776 26136 net.cpp:405] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0530 20:27:15.392899 26136 net.cpp:150] Setting up res2a_branch2a_relu
I0530 20:27:15.392905 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.392907 26136 net.cpp:165] Memory required for data: 28700684
I0530 20:27:15.392915 26136 layer_factory.hpp:77] Creating layer res2a_branch2b
I0530 20:27:15.392930 26136 net.cpp:100] Creating Layer res2a_branch2b
I0530 20:27:15.392933 26136 net.cpp:444] res2a_branch2b <- res2a_branch2a
I0530 20:27:15.392946 26136 net.cpp:418] res2a_branch2b -> res2a_branch2b
I0530 20:27:15.394232 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0530 20:27:15.394429 26136 net.cpp:150] Setting up res2a_branch2b
I0530 20:27:15.394440 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.394443 26136 net.cpp:165] Memory required for data: 29503500
I0530 20:27:15.394454 26136 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0530 20:27:15.394467 26136 net.cpp:100] Creating Layer bn2a_branch2b
I0530 20:27:15.394474 26136 net.cpp:444] bn2a_branch2b <- res2a_branch2b
I0530 20:27:15.394485 26136 net.cpp:405] bn2a_branch2b -> res2a_branch2b (in-place)
I0530 20:27:15.394637 26136 net.cpp:150] Setting up bn2a_branch2b
I0530 20:27:15.394644 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.394645 26136 net.cpp:165] Memory required for data: 30306316
I0530 20:27:15.394659 26136 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0530 20:27:15.394675 26136 net.cpp:100] Creating Layer scale2a_branch2b
I0530 20:27:15.394680 26136 net.cpp:444] scale2a_branch2b <- res2a_branch2b
I0530 20:27:15.394692 26136 net.cpp:405] scale2a_branch2b -> res2a_branch2b (in-place)
I0530 20:27:15.394737 26136 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0530 20:27:15.394850 26136 net.cpp:150] Setting up scale2a_branch2b
I0530 20:27:15.394857 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.394860 26136 net.cpp:165] Memory required for data: 31109132
I0530 20:27:15.394870 26136 layer_factory.hpp:77] Creating layer res2a_branch2b_relu
I0530 20:27:15.394878 26136 net.cpp:100] Creating Layer res2a_branch2b_relu
I0530 20:27:15.394883 26136 net.cpp:444] res2a_branch2b_relu <- res2a_branch2b
I0530 20:27:15.394893 26136 net.cpp:405] res2a_branch2b_relu -> res2a_branch2b (in-place)
I0530 20:27:15.395215 26136 net.cpp:150] Setting up res2a_branch2b_relu
I0530 20:27:15.395221 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.395225 26136 net.cpp:165] Memory required for data: 31911948
I0530 20:27:15.395228 26136 layer_factory.hpp:77] Creating layer res2a_branch2c
I0530 20:27:15.395242 26136 net.cpp:100] Creating Layer res2a_branch2c
I0530 20:27:15.395248 26136 net.cpp:444] res2a_branch2c <- res2a_branch2b
I0530 20:27:15.395263 26136 net.cpp:418] res2a_branch2c -> res2a_branch2c
I0530 20:27:15.396003 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.396016 26136 net.cpp:150] Setting up res2a_branch2c
I0530 20:27:15.396023 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396026 26136 net.cpp:165] Memory required for data: 35123212
I0530 20:27:15.396036 26136 layer_factory.hpp:77] Creating layer bn2a_branch2c
I0530 20:27:15.396049 26136 net.cpp:100] Creating Layer bn2a_branch2c
I0530 20:27:15.396054 26136 net.cpp:444] bn2a_branch2c <- res2a_branch2c
I0530 20:27:15.396067 26136 net.cpp:405] bn2a_branch2c -> res2a_branch2c (in-place)
I0530 20:27:15.396210 26136 net.cpp:150] Setting up bn2a_branch2c
I0530 20:27:15.396215 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396217 26136 net.cpp:165] Memory required for data: 38334476
I0530 20:27:15.396231 26136 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0530 20:27:15.396245 26136 net.cpp:100] Creating Layer scale2a_branch2c
I0530 20:27:15.396250 26136 net.cpp:444] scale2a_branch2c <- res2a_branch2c
I0530 20:27:15.396260 26136 net.cpp:405] scale2a_branch2c -> res2a_branch2c (in-place)
I0530 20:27:15.396301 26136 layer_factory.hpp:77] Creating layer scale2a_branch2c
I0530 20:27:15.396409 26136 net.cpp:150] Setting up scale2a_branch2c
I0530 20:27:15.396415 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396417 26136 net.cpp:165] Memory required for data: 41545740
I0530 20:27:15.396427 26136 layer_factory.hpp:77] Creating layer res2a
I0530 20:27:15.396438 26136 net.cpp:100] Creating Layer res2a
I0530 20:27:15.396443 26136 net.cpp:444] res2a <- res2a_branch1
I0530 20:27:15.396451 26136 net.cpp:444] res2a <- res2a_branch2c
I0530 20:27:15.396459 26136 net.cpp:418] res2a -> res2a
I0530 20:27:15.396488 26136 net.cpp:150] Setting up res2a
I0530 20:27:15.396495 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396497 26136 net.cpp:165] Memory required for data: 44757004
I0530 20:27:15.396502 26136 layer_factory.hpp:77] Creating layer res2a_relu
I0530 20:27:15.396509 26136 net.cpp:100] Creating Layer res2a_relu
I0530 20:27:15.396514 26136 net.cpp:444] res2a_relu <- res2a
I0530 20:27:15.396523 26136 net.cpp:405] res2a_relu -> res2a (in-place)
I0530 20:27:15.396653 26136 net.cpp:150] Setting up res2a_relu
I0530 20:27:15.396659 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396661 26136 net.cpp:165] Memory required for data: 47968268
I0530 20:27:15.396664 26136 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0530 20:27:15.396674 26136 net.cpp:100] Creating Layer res2a_res2a_relu_0_split
I0530 20:27:15.396678 26136 net.cpp:444] res2a_res2a_relu_0_split <- res2a
I0530 20:27:15.396689 26136 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0530 20:27:15.396703 26136 net.cpp:418] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0530 20:27:15.396736 26136 net.cpp:150] Setting up res2a_res2a_relu_0_split
I0530 20:27:15.396744 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396747 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.396749 26136 net.cpp:165] Memory required for data: 54390796
I0530 20:27:15.396752 26136 layer_factory.hpp:77] Creating layer res2b_branch2a
I0530 20:27:15.396764 26136 net.cpp:100] Creating Layer res2b_branch2a
I0530 20:27:15.396770 26136 net.cpp:444] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0530 20:27:15.396780 26136 net.cpp:418] res2b_branch2a -> res2b_branch2a
I0530 20:27:15.397522 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.397536 26136 net.cpp:150] Setting up res2b_branch2a
I0530 20:27:15.397543 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.397547 26136 net.cpp:165] Memory required for data: 55193612
I0530 20:27:15.397555 26136 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0530 20:27:15.397569 26136 net.cpp:100] Creating Layer bn2b_branch2a
I0530 20:27:15.397574 26136 net.cpp:444] bn2b_branch2a <- res2b_branch2a
I0530 20:27:15.397586 26136 net.cpp:405] bn2b_branch2a -> res2b_branch2a (in-place)
I0530 20:27:15.397739 26136 net.cpp:150] Setting up bn2b_branch2a
I0530 20:27:15.397745 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.397747 26136 net.cpp:165] Memory required for data: 55996428
I0530 20:27:15.397773 26136 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0530 20:27:15.397785 26136 net.cpp:100] Creating Layer scale2b_branch2a
I0530 20:27:15.397790 26136 net.cpp:444] scale2b_branch2a <- res2b_branch2a
I0530 20:27:15.397800 26136 net.cpp:405] scale2b_branch2a -> res2b_branch2a (in-place)
I0530 20:27:15.397842 26136 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0530 20:27:15.397956 26136 net.cpp:150] Setting up scale2b_branch2a
I0530 20:27:15.397964 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.397965 26136 net.cpp:165] Memory required for data: 56799244
I0530 20:27:15.397974 26136 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0530 20:27:15.397984 26136 net.cpp:100] Creating Layer res2b_branch2a_relu
I0530 20:27:15.397989 26136 net.cpp:444] res2b_branch2a_relu <- res2b_branch2a
I0530 20:27:15.398000 26136 net.cpp:405] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0530 20:27:15.398133 26136 net.cpp:150] Setting up res2b_branch2a_relu
I0530 20:27:15.398140 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.398141 26136 net.cpp:165] Memory required for data: 57602060
I0530 20:27:15.398145 26136 layer_factory.hpp:77] Creating layer res2b_branch2b
I0530 20:27:15.398159 26136 net.cpp:100] Creating Layer res2b_branch2b
I0530 20:27:15.398164 26136 net.cpp:444] res2b_branch2b <- res2b_branch2a
I0530 20:27:15.398176 26136 net.cpp:418] res2b_branch2b -> res2b_branch2b
I0530 20:27:15.398948 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0530 20:27:15.398962 26136 net.cpp:150] Setting up res2b_branch2b
I0530 20:27:15.398968 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.398970 26136 net.cpp:165] Memory required for data: 58404876
I0530 20:27:15.398979 26136 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0530 20:27:15.398993 26136 net.cpp:100] Creating Layer bn2b_branch2b
I0530 20:27:15.398999 26136 net.cpp:444] bn2b_branch2b <- res2b_branch2b
I0530 20:27:15.399011 26136 net.cpp:405] bn2b_branch2b -> res2b_branch2b (in-place)
I0530 20:27:15.399161 26136 net.cpp:150] Setting up bn2b_branch2b
I0530 20:27:15.399166 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.399169 26136 net.cpp:165] Memory required for data: 59207692
I0530 20:27:15.399183 26136 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0530 20:27:15.399194 26136 net.cpp:100] Creating Layer scale2b_branch2b
I0530 20:27:15.399199 26136 net.cpp:444] scale2b_branch2b <- res2b_branch2b
I0530 20:27:15.399210 26136 net.cpp:405] scale2b_branch2b -> res2b_branch2b (in-place)
I0530 20:27:15.399253 26136 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0530 20:27:15.399366 26136 net.cpp:150] Setting up scale2b_branch2b
I0530 20:27:15.399374 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.399375 26136 net.cpp:165] Memory required for data: 60010508
I0530 20:27:15.399385 26136 layer_factory.hpp:77] Creating layer res2b_branch2b_relu
I0530 20:27:15.399394 26136 net.cpp:100] Creating Layer res2b_branch2b_relu
I0530 20:27:15.399399 26136 net.cpp:444] res2b_branch2b_relu <- res2b_branch2b
I0530 20:27:15.399411 26136 net.cpp:405] res2b_branch2b_relu -> res2b_branch2b (in-place)
I0530 20:27:15.399729 26136 net.cpp:150] Setting up res2b_branch2b_relu
I0530 20:27:15.399736 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.399739 26136 net.cpp:165] Memory required for data: 60813324
I0530 20:27:15.399744 26136 layer_factory.hpp:77] Creating layer res2b_branch2c
I0530 20:27:15.399765 26136 net.cpp:100] Creating Layer res2b_branch2c
I0530 20:27:15.399770 26136 net.cpp:444] res2b_branch2c <- res2b_branch2b
I0530 20:27:15.399785 26136 net.cpp:418] res2b_branch2c -> res2b_branch2c
I0530 20:27:15.400624 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.400640 26136 net.cpp:150] Setting up res2b_branch2c
I0530 20:27:15.400647 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.400650 26136 net.cpp:165] Memory required for data: 64024588
I0530 20:27:15.400660 26136 layer_factory.hpp:77] Creating layer bn2b_branch2c
I0530 20:27:15.400674 26136 net.cpp:100] Creating Layer bn2b_branch2c
I0530 20:27:15.400681 26136 net.cpp:444] bn2b_branch2c <- res2b_branch2c
I0530 20:27:15.400693 26136 net.cpp:405] bn2b_branch2c -> res2b_branch2c (in-place)
I0530 20:27:15.400844 26136 net.cpp:150] Setting up bn2b_branch2c
I0530 20:27:15.400851 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.400851 26136 net.cpp:165] Memory required for data: 67235852
I0530 20:27:15.400866 26136 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0530 20:27:15.400878 26136 net.cpp:100] Creating Layer scale2b_branch2c
I0530 20:27:15.400883 26136 net.cpp:444] scale2b_branch2c <- res2b_branch2c
I0530 20:27:15.400893 26136 net.cpp:405] scale2b_branch2c -> res2b_branch2c (in-place)
I0530 20:27:15.400952 26136 layer_factory.hpp:77] Creating layer scale2b_branch2c
I0530 20:27:15.401067 26136 net.cpp:150] Setting up scale2b_branch2c
I0530 20:27:15.401073 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.401077 26136 net.cpp:165] Memory required for data: 70447116
I0530 20:27:15.401087 26136 layer_factory.hpp:77] Creating layer res2b
I0530 20:27:15.401096 26136 net.cpp:100] Creating Layer res2b
I0530 20:27:15.401101 26136 net.cpp:444] res2b <- res2a_res2a_relu_0_split_1
I0530 20:27:15.401111 26136 net.cpp:444] res2b <- res2b_branch2c
I0530 20:27:15.401123 26136 net.cpp:418] res2b -> res2b
I0530 20:27:15.401163 26136 net.cpp:150] Setting up res2b
I0530 20:27:15.401172 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.401175 26136 net.cpp:165] Memory required for data: 73658380
I0530 20:27:15.401177 26136 layer_factory.hpp:77] Creating layer res2b_relu
I0530 20:27:15.401185 26136 net.cpp:100] Creating Layer res2b_relu
I0530 20:27:15.401190 26136 net.cpp:444] res2b_relu <- res2b
I0530 20:27:15.401198 26136 net.cpp:405] res2b_relu -> res2b (in-place)
I0530 20:27:15.401350 26136 net.cpp:150] Setting up res2b_relu
I0530 20:27:15.401357 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.401360 26136 net.cpp:165] Memory required for data: 76869644
I0530 20:27:15.401363 26136 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0530 20:27:15.401372 26136 net.cpp:100] Creating Layer res2b_res2b_relu_0_split
I0530 20:27:15.401376 26136 net.cpp:444] res2b_res2b_relu_0_split <- res2b
I0530 20:27:15.401388 26136 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0530 20:27:15.401401 26136 net.cpp:418] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0530 20:27:15.401438 26136 net.cpp:150] Setting up res2b_res2b_relu_0_split
I0530 20:27:15.401445 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.401449 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.401450 26136 net.cpp:165] Memory required for data: 83292172
I0530 20:27:15.401453 26136 layer_factory.hpp:77] Creating layer res2c_branch2a
I0530 20:27:15.401468 26136 net.cpp:100] Creating Layer res2c_branch2a
I0530 20:27:15.401473 26136 net.cpp:444] res2c_branch2a <- res2b_res2b_relu_0_split_0
I0530 20:27:15.401484 26136 net.cpp:418] res2c_branch2a -> res2c_branch2a
I0530 20:27:15.402257 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.402273 26136 net.cpp:150] Setting up res2c_branch2a
I0530 20:27:15.402281 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.402284 26136 net.cpp:165] Memory required for data: 84094988
I0530 20:27:15.402294 26136 layer_factory.hpp:77] Creating layer bn2c_branch2a
I0530 20:27:15.402307 26136 net.cpp:100] Creating Layer bn2c_branch2a
I0530 20:27:15.402312 26136 net.cpp:444] bn2c_branch2a <- res2c_branch2a
I0530 20:27:15.402325 26136 net.cpp:405] bn2c_branch2a -> res2c_branch2a (in-place)
I0530 20:27:15.402482 26136 net.cpp:150] Setting up bn2c_branch2a
I0530 20:27:15.402488 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.402490 26136 net.cpp:165] Memory required for data: 84897804
I0530 20:27:15.402505 26136 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0530 20:27:15.402518 26136 net.cpp:100] Creating Layer scale2c_branch2a
I0530 20:27:15.402523 26136 net.cpp:444] scale2c_branch2a <- res2c_branch2a
I0530 20:27:15.402532 26136 net.cpp:405] scale2c_branch2a -> res2c_branch2a (in-place)
I0530 20:27:15.402576 26136 layer_factory.hpp:77] Creating layer scale2c_branch2a
I0530 20:27:15.402696 26136 net.cpp:150] Setting up scale2c_branch2a
I0530 20:27:15.402704 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.402705 26136 net.cpp:165] Memory required for data: 85700620
I0530 20:27:15.402714 26136 layer_factory.hpp:77] Creating layer res2c_branch2a_relu
I0530 20:27:15.402724 26136 net.cpp:100] Creating Layer res2c_branch2a_relu
I0530 20:27:15.402729 26136 net.cpp:444] res2c_branch2a_relu <- res2c_branch2a
I0530 20:27:15.402740 26136 net.cpp:405] res2c_branch2a_relu -> res2c_branch2a (in-place)
I0530 20:27:15.402874 26136 net.cpp:150] Setting up res2c_branch2a_relu
I0530 20:27:15.402881 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.402884 26136 net.cpp:165] Memory required for data: 86503436
I0530 20:27:15.402887 26136 layer_factory.hpp:77] Creating layer res2c_branch2b
I0530 20:27:15.402900 26136 net.cpp:100] Creating Layer res2c_branch2b
I0530 20:27:15.402905 26136 net.cpp:444] res2c_branch2b <- res2c_branch2a
I0530 20:27:15.402918 26136 net.cpp:418] res2c_branch2b -> res2c_branch2b
I0530 20:27:15.403740 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 786432
I0530 20:27:15.403946 26136 net.cpp:150] Setting up res2c_branch2b
I0530 20:27:15.403957 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.403960 26136 net.cpp:165] Memory required for data: 87306252
I0530 20:27:15.403970 26136 layer_factory.hpp:77] Creating layer bn2c_branch2b
I0530 20:27:15.403985 26136 net.cpp:100] Creating Layer bn2c_branch2b
I0530 20:27:15.403990 26136 net.cpp:444] bn2c_branch2b <- res2c_branch2b
I0530 20:27:15.404004 26136 net.cpp:405] bn2c_branch2b -> res2c_branch2b (in-place)
I0530 20:27:15.404170 26136 net.cpp:150] Setting up bn2c_branch2b
I0530 20:27:15.404176 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.404180 26136 net.cpp:165] Memory required for data: 88109068
I0530 20:27:15.404194 26136 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0530 20:27:15.404211 26136 net.cpp:100] Creating Layer scale2c_branch2b
I0530 20:27:15.404259 26136 net.cpp:444] scale2c_branch2b <- res2c_branch2b
I0530 20:27:15.404275 26136 net.cpp:405] scale2c_branch2b -> res2c_branch2b (in-place)
I0530 20:27:15.404326 26136 layer_factory.hpp:77] Creating layer scale2c_branch2b
I0530 20:27:15.404449 26136 net.cpp:150] Setting up scale2c_branch2b
I0530 20:27:15.404458 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.404460 26136 net.cpp:165] Memory required for data: 88911884
I0530 20:27:15.404474 26136 layer_factory.hpp:77] Creating layer res2c_branch2b_relu
I0530 20:27:15.404485 26136 net.cpp:100] Creating Layer res2c_branch2b_relu
I0530 20:27:15.404491 26136 net.cpp:444] res2c_branch2b_relu <- res2c_branch2b
I0530 20:27:15.404505 26136 net.cpp:405] res2c_branch2b_relu -> res2c_branch2b (in-place)
I0530 20:27:15.404649 26136 net.cpp:150] Setting up res2c_branch2b_relu
I0530 20:27:15.404655 26136 net.cpp:157] Top shape: 1 64 56 56 (200704)
I0530 20:27:15.404659 26136 net.cpp:165] Memory required for data: 89714700
I0530 20:27:15.404664 26136 layer_factory.hpp:77] Creating layer res2c_branch2c
I0530 20:27:15.404680 26136 net.cpp:100] Creating Layer res2c_branch2c
I0530 20:27:15.404687 26136 net.cpp:444] res2c_branch2c <- res2c_branch2b
I0530 20:27:15.404705 26136 net.cpp:418] res2c_branch2c -> res2c_branch2c
I0530 20:27:15.405496 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 63000
I0530 20:27:15.405514 26136 net.cpp:150] Setting up res2c_branch2c
I0530 20:27:15.405524 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.405527 26136 net.cpp:165] Memory required for data: 92925964
I0530 20:27:15.405539 26136 layer_factory.hpp:77] Creating layer bn2c_branch2c
I0530 20:27:15.405555 26136 net.cpp:100] Creating Layer bn2c_branch2c
I0530 20:27:15.405562 26136 net.cpp:444] bn2c_branch2c <- res2c_branch2c
I0530 20:27:15.405578 26136 net.cpp:405] bn2c_branch2c -> res2c_branch2c (in-place)
I0530 20:27:15.405733 26136 net.cpp:150] Setting up bn2c_branch2c
I0530 20:27:15.405740 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.405743 26136 net.cpp:165] Memory required for data: 96137228
I0530 20:27:15.405777 26136 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0530 20:27:15.405792 26136 net.cpp:100] Creating Layer scale2c_branch2c
I0530 20:27:15.405800 26136 net.cpp:444] scale2c_branch2c <- res2c_branch2c
I0530 20:27:15.405814 26136 net.cpp:405] scale2c_branch2c -> res2c_branch2c (in-place)
I0530 20:27:15.405864 26136 layer_factory.hpp:77] Creating layer scale2c_branch2c
I0530 20:27:15.405982 26136 net.cpp:150] Setting up scale2c_branch2c
I0530 20:27:15.405989 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.405994 26136 net.cpp:165] Memory required for data: 99348492
I0530 20:27:15.406006 26136 layer_factory.hpp:77] Creating layer res2c
I0530 20:27:15.406018 26136 net.cpp:100] Creating Layer res2c
I0530 20:27:15.406025 26136 net.cpp:444] res2c <- res2b_res2b_relu_0_split_1
I0530 20:27:15.406038 26136 net.cpp:444] res2c <- res2c_branch2c
I0530 20:27:15.406049 26136 net.cpp:418] res2c -> res2c
I0530 20:27:15.406081 26136 net.cpp:150] Setting up res2c
I0530 20:27:15.406090 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.406093 26136 net.cpp:165] Memory required for data: 102559756
I0530 20:27:15.406098 26136 layer_factory.hpp:77] Creating layer res2c_relu
I0530 20:27:15.406111 26136 net.cpp:100] Creating Layer res2c_relu
I0530 20:27:15.406116 26136 net.cpp:444] res2c_relu <- res2c
I0530 20:27:15.406129 26136 net.cpp:405] res2c_relu -> res2c (in-place)
I0530 20:27:15.406460 26136 net.cpp:150] Setting up res2c_relu
I0530 20:27:15.406468 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.406471 26136 net.cpp:165] Memory required for data: 105771020
I0530 20:27:15.406477 26136 layer_factory.hpp:77] Creating layer res2c_res2c_relu_0_split
I0530 20:27:15.406489 26136 net.cpp:100] Creating Layer res2c_res2c_relu_0_split
I0530 20:27:15.406496 26136 net.cpp:444] res2c_res2c_relu_0_split <- res2c
I0530 20:27:15.406512 26136 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_0
I0530 20:27:15.406528 26136 net.cpp:418] res2c_res2c_relu_0_split -> res2c_res2c_relu_0_split_1
I0530 20:27:15.406570 26136 net.cpp:150] Setting up res2c_res2c_relu_0_split
I0530 20:27:15.406579 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.406584 26136 net.cpp:157] Top shape: 1 256 56 56 (802816)
I0530 20:27:15.406589 26136 net.cpp:165] Memory required for data: 112193548
I0530 20:27:15.406594 26136 layer_factory.hpp:77] Creating layer res3a_branch1
I0530 20:27:15.406610 26136 net.cpp:100] Creating Layer res3a_branch1
I0530 20:27:15.406616 26136 net.cpp:444] res3a_branch1 <- res2c_res2c_relu_0_split_0
I0530 20:27:15.406631 26136 net.cpp:418] res3a_branch1 -> res3a_branch1
I0530 20:27:15.408124 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0530 20:27:15.408334 26136 net.cpp:150] Setting up res3a_branch1
I0530 20:27:15.408344 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.408349 26136 net.cpp:165] Memory required for data: 113799180
I0530 20:27:15.408361 26136 layer_factory.hpp:77] Creating layer bn3a_branch1
I0530 20:27:15.408377 26136 net.cpp:100] Creating Layer bn3a_branch1
I0530 20:27:15.408385 26136 net.cpp:444] bn3a_branch1 <- res3a_branch1
I0530 20:27:15.408401 26136 net.cpp:405] bn3a_branch1 -> res3a_branch1 (in-place)
I0530 20:27:15.409122 26136 net.cpp:150] Setting up bn3a_branch1
I0530 20:27:15.409132 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.409134 26136 net.cpp:165] Memory required for data: 115404812
I0530 20:27:15.409150 26136 layer_factory.hpp:77] Creating layer scale3a_branch1
I0530 20:27:15.409165 26136 net.cpp:100] Creating Layer scale3a_branch1
I0530 20:27:15.409173 26136 net.cpp:444] scale3a_branch1 <- res3a_branch1
I0530 20:27:15.409189 26136 net.cpp:405] scale3a_branch1 -> res3a_branch1 (in-place)
I0530 20:27:15.409248 26136 layer_factory.hpp:77] Creating layer scale3a_branch1
I0530 20:27:15.409366 26136 net.cpp:150] Setting up scale3a_branch1
I0530 20:27:15.409374 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.409379 26136 net.cpp:165] Memory required for data: 117010444
I0530 20:27:15.409394 26136 layer_factory.hpp:77] Creating layer res3a_branch2a
I0530 20:27:15.409412 26136 net.cpp:100] Creating Layer res3a_branch2a
I0530 20:27:15.409421 26136 net.cpp:444] res3a_branch2a <- res2c_res2c_relu_0_split_1
I0530 20:27:15.409440 26136 net.cpp:418] res3a_branch2a -> res3a_branch2a
I0530 20:27:15.410274 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 14136
I0530 20:27:15.410297 26136 net.cpp:150] Setting up res3a_branch2a
I0530 20:27:15.410306 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.410310 26136 net.cpp:165] Memory required for data: 117411852
I0530 20:27:15.410324 26136 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0530 20:27:15.410342 26136 net.cpp:100] Creating Layer bn3a_branch2a
I0530 20:27:15.410351 26136 net.cpp:444] bn3a_branch2a <- res3a_branch2a
I0530 20:27:15.410367 26136 net.cpp:405] bn3a_branch2a -> res3a_branch2a (in-place)
I0530 20:27:15.410531 26136 net.cpp:150] Setting up bn3a_branch2a
I0530 20:27:15.410539 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.410542 26136 net.cpp:165] Memory required for data: 117813260
I0530 20:27:15.410564 26136 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0530 20:27:15.410581 26136 net.cpp:100] Creating Layer scale3a_branch2a
I0530 20:27:15.410589 26136 net.cpp:444] scale3a_branch2a <- res3a_branch2a
I0530 20:27:15.410605 26136 net.cpp:405] scale3a_branch2a -> res3a_branch2a (in-place)
I0530 20:27:15.410665 26136 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0530 20:27:15.410789 26136 net.cpp:150] Setting up scale3a_branch2a
I0530 20:27:15.410797 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.410800 26136 net.cpp:165] Memory required for data: 118214668
I0530 20:27:15.410815 26136 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0530 20:27:15.410827 26136 net.cpp:100] Creating Layer res3a_branch2a_relu
I0530 20:27:15.410835 26136 net.cpp:444] res3a_branch2a_relu <- res3a_branch2a
I0530 20:27:15.410851 26136 net.cpp:405] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0530 20:27:15.411190 26136 net.cpp:150] Setting up res3a_branch2a_relu
I0530 20:27:15.411197 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.411201 26136 net.cpp:165] Memory required for data: 118616076
I0530 20:27:15.411207 26136 layer_factory.hpp:77] Creating layer res3a_branch2b
I0530 20:27:15.411226 26136 net.cpp:100] Creating Layer res3a_branch2b
I0530 20:27:15.411232 26136 net.cpp:444] res3a_branch2b <- res3a_branch2a
I0530 20:27:15.411250 26136 net.cpp:418] res3a_branch2b -> res3a_branch2b
I0530 20:27:15.412236 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0530 20:27:15.412439 26136 net.cpp:150] Setting up res3a_branch2b
I0530 20:27:15.412451 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.412456 26136 net.cpp:165] Memory required for data: 119017484
I0530 20:27:15.412468 26136 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0530 20:27:15.412484 26136 net.cpp:100] Creating Layer bn3a_branch2b
I0530 20:27:15.412490 26136 net.cpp:444] bn3a_branch2b <- res3a_branch2b
I0530 20:27:15.412508 26136 net.cpp:405] bn3a_branch2b -> res3a_branch2b (in-place)
I0530 20:27:15.412665 26136 net.cpp:150] Setting up bn3a_branch2b
I0530 20:27:15.412672 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.412675 26136 net.cpp:165] Memory required for data: 119418892
I0530 20:27:15.412693 26136 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0530 20:27:15.412708 26136 net.cpp:100] Creating Layer scale3a_branch2b
I0530 20:27:15.412715 26136 net.cpp:444] scale3a_branch2b <- res3a_branch2b
I0530 20:27:15.412729 26136 net.cpp:405] scale3a_branch2b -> res3a_branch2b (in-place)
I0530 20:27:15.412778 26136 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0530 20:27:15.412897 26136 net.cpp:150] Setting up scale3a_branch2b
I0530 20:27:15.412905 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.412909 26136 net.cpp:165] Memory required for data: 119820300
I0530 20:27:15.412927 26136 layer_factory.hpp:77] Creating layer res3a_branch2b_relu
I0530 20:27:15.412940 26136 net.cpp:100] Creating Layer res3a_branch2b_relu
I0530 20:27:15.412945 26136 net.cpp:444] res3a_branch2b_relu <- res3a_branch2b
I0530 20:27:15.412961 26136 net.cpp:405] res3a_branch2b_relu -> res3a_branch2b (in-place)
I0530 20:27:15.413100 26136 net.cpp:150] Setting up res3a_branch2b_relu
I0530 20:27:15.413108 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.413111 26136 net.cpp:165] Memory required for data: 120221708
I0530 20:27:15.413116 26136 layer_factory.hpp:77] Creating layer res3a_branch2c
I0530 20:27:15.413133 26136 net.cpp:100] Creating Layer res3a_branch2c
I0530 20:27:15.413141 26136 net.cpp:444] res3a_branch2c <- res3a_branch2b
I0530 20:27:15.413156 26136 net.cpp:418] res3a_branch2c -> res3a_branch2c
I0530 20:27:15.414002 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.414018 26136 net.cpp:150] Setting up res3a_branch2c
I0530 20:27:15.414027 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.414031 26136 net.cpp:165] Memory required for data: 121827340
I0530 20:27:15.414043 26136 layer_factory.hpp:77] Creating layer bn3a_branch2c
I0530 20:27:15.414068 26136 net.cpp:100] Creating Layer bn3a_branch2c
I0530 20:27:15.414075 26136 net.cpp:444] bn3a_branch2c <- res3a_branch2c
I0530 20:27:15.414091 26136 net.cpp:405] bn3a_branch2c -> res3a_branch2c (in-place)
I0530 20:27:15.414248 26136 net.cpp:150] Setting up bn3a_branch2c
I0530 20:27:15.414255 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.414259 26136 net.cpp:165] Memory required for data: 123432972
I0530 20:27:15.414278 26136 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0530 20:27:15.414294 26136 net.cpp:100] Creating Layer scale3a_branch2c
I0530 20:27:15.414300 26136 net.cpp:444] scale3a_branch2c <- res3a_branch2c
I0530 20:27:15.414315 26136 net.cpp:405] scale3a_branch2c -> res3a_branch2c (in-place)
I0530 20:27:15.414363 26136 layer_factory.hpp:77] Creating layer scale3a_branch2c
I0530 20:27:15.414479 26136 net.cpp:150] Setting up scale3a_branch2c
I0530 20:27:15.414487 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.414491 26136 net.cpp:165] Memory required for data: 125038604
I0530 20:27:15.414505 26136 layer_factory.hpp:77] Creating layer res3a
I0530 20:27:15.414516 26136 net.cpp:100] Creating Layer res3a
I0530 20:27:15.414522 26136 net.cpp:444] res3a <- res3a_branch1
I0530 20:27:15.414535 26136 net.cpp:444] res3a <- res3a_branch2c
I0530 20:27:15.414544 26136 net.cpp:418] res3a -> res3a
I0530 20:27:15.414579 26136 net.cpp:150] Setting up res3a
I0530 20:27:15.414588 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.414592 26136 net.cpp:165] Memory required for data: 126644236
I0530 20:27:15.414597 26136 layer_factory.hpp:77] Creating layer res3a_relu
I0530 20:27:15.414608 26136 net.cpp:100] Creating Layer res3a_relu
I0530 20:27:15.414614 26136 net.cpp:444] res3a_relu <- res3a
I0530 20:27:15.414628 26136 net.cpp:405] res3a_relu -> res3a (in-place)
I0530 20:27:15.414988 26136 net.cpp:150] Setting up res3a_relu
I0530 20:27:15.414997 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.415001 26136 net.cpp:165] Memory required for data: 128249868
I0530 20:27:15.415007 26136 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0530 20:27:15.415020 26136 net.cpp:100] Creating Layer res3a_res3a_relu_0_split
I0530 20:27:15.415026 26136 net.cpp:444] res3a_res3a_relu_0_split <- res3a
I0530 20:27:15.415045 26136 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0530 20:27:15.415061 26136 net.cpp:418] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0530 20:27:15.415105 26136 net.cpp:150] Setting up res3a_res3a_relu_0_split
I0530 20:27:15.415114 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.415120 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.415123 26136 net.cpp:165] Memory required for data: 131461132
I0530 20:27:15.415129 26136 layer_factory.hpp:77] Creating layer res3b_branch2a
I0530 20:27:15.415145 26136 net.cpp:100] Creating Layer res3b_branch2a
I0530 20:27:15.415151 26136 net.cpp:444] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0530 20:27:15.415168 26136 net.cpp:418] res3b_branch2a -> res3b_branch2a
I0530 20:27:15.416080 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.416096 26136 net.cpp:150] Setting up res3b_branch2a
I0530 20:27:15.416108 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.416112 26136 net.cpp:165] Memory required for data: 131862540
I0530 20:27:15.416124 26136 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0530 20:27:15.416139 26136 net.cpp:100] Creating Layer bn3b_branch2a
I0530 20:27:15.416146 26136 net.cpp:444] bn3b_branch2a <- res3b_branch2a
I0530 20:27:15.416164 26136 net.cpp:405] bn3b_branch2a -> res3b_branch2a (in-place)
I0530 20:27:15.416327 26136 net.cpp:150] Setting up bn3b_branch2a
I0530 20:27:15.416334 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.416337 26136 net.cpp:165] Memory required for data: 132263948
I0530 20:27:15.416355 26136 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0530 20:27:15.416370 26136 net.cpp:100] Creating Layer scale3b_branch2a
I0530 20:27:15.416376 26136 net.cpp:444] scale3b_branch2a <- res3b_branch2a
I0530 20:27:15.416393 26136 net.cpp:405] scale3b_branch2a -> res3b_branch2a (in-place)
I0530 20:27:15.416440 26136 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0530 20:27:15.416558 26136 net.cpp:150] Setting up scale3b_branch2a
I0530 20:27:15.416564 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.416568 26136 net.cpp:165] Memory required for data: 132665356
I0530 20:27:15.416580 26136 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0530 20:27:15.416591 26136 net.cpp:100] Creating Layer res3b_branch2a_relu
I0530 20:27:15.416599 26136 net.cpp:444] res3b_branch2a_relu <- res3b_branch2a
I0530 20:27:15.416611 26136 net.cpp:405] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0530 20:27:15.416754 26136 net.cpp:150] Setting up res3b_branch2a_relu
I0530 20:27:15.416762 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.416765 26136 net.cpp:165] Memory required for data: 133066764
I0530 20:27:15.416771 26136 layer_factory.hpp:77] Creating layer res3b_branch2b
I0530 20:27:15.416790 26136 net.cpp:100] Creating Layer res3b_branch2b
I0530 20:27:15.416797 26136 net.cpp:444] res3b_branch2b <- res3b_branch2a
I0530 20:27:15.416815 26136 net.cpp:418] res3b_branch2b -> res3b_branch2b
I0530 20:27:15.417834 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0530 20:27:15.418087 26136 net.cpp:150] Setting up res3b_branch2b
I0530 20:27:15.418100 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.418104 26136 net.cpp:165] Memory required for data: 133468172
I0530 20:27:15.418118 26136 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0530 20:27:15.418134 26136 net.cpp:100] Creating Layer bn3b_branch2b
I0530 20:27:15.418141 26136 net.cpp:444] bn3b_branch2b <- res3b_branch2b
I0530 20:27:15.418159 26136 net.cpp:405] bn3b_branch2b -> res3b_branch2b (in-place)
I0530 20:27:15.418325 26136 net.cpp:150] Setting up bn3b_branch2b
I0530 20:27:15.418332 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.418336 26136 net.cpp:165] Memory required for data: 133869580
I0530 20:27:15.418354 26136 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0530 20:27:15.418370 26136 net.cpp:100] Creating Layer scale3b_branch2b
I0530 20:27:15.418376 26136 net.cpp:444] scale3b_branch2b <- res3b_branch2b
I0530 20:27:15.418390 26136 net.cpp:405] scale3b_branch2b -> res3b_branch2b (in-place)
I0530 20:27:15.418442 26136 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0530 20:27:15.418558 26136 net.cpp:150] Setting up scale3b_branch2b
I0530 20:27:15.418566 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.418570 26136 net.cpp:165] Memory required for data: 134270988
I0530 20:27:15.418583 26136 layer_factory.hpp:77] Creating layer res3b_branch2b_relu
I0530 20:27:15.418596 26136 net.cpp:100] Creating Layer res3b_branch2b_relu
I0530 20:27:15.418602 26136 net.cpp:444] res3b_branch2b_relu <- res3b_branch2b
I0530 20:27:15.418615 26136 net.cpp:405] res3b_branch2b_relu -> res3b_branch2b (in-place)
I0530 20:27:15.418758 26136 net.cpp:150] Setting up res3b_branch2b_relu
I0530 20:27:15.418766 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.418768 26136 net.cpp:165] Memory required for data: 134672396
I0530 20:27:15.418776 26136 layer_factory.hpp:77] Creating layer res3b_branch2c
I0530 20:27:15.418793 26136 net.cpp:100] Creating Layer res3b_branch2c
I0530 20:27:15.418800 26136 net.cpp:444] res3b_branch2c <- res3b_branch2b
I0530 20:27:15.418817 26136 net.cpp:418] res3b_branch2c -> res3b_branch2c
I0530 20:27:15.419703 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.419719 26136 net.cpp:150] Setting up res3b_branch2c
I0530 20:27:15.419729 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.419734 26136 net.cpp:165] Memory required for data: 136278028
I0530 20:27:15.419745 26136 layer_factory.hpp:77] Creating layer bn3b_branch2c
I0530 20:27:15.419760 26136 net.cpp:100] Creating Layer bn3b_branch2c
I0530 20:27:15.419767 26136 net.cpp:444] bn3b_branch2c <- res3b_branch2c
I0530 20:27:15.419783 26136 net.cpp:405] bn3b_branch2c -> res3b_branch2c (in-place)
I0530 20:27:15.419946 26136 net.cpp:150] Setting up bn3b_branch2c
I0530 20:27:15.419953 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.419957 26136 net.cpp:165] Memory required for data: 137883660
I0530 20:27:15.419975 26136 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0530 20:27:15.419988 26136 net.cpp:100] Creating Layer scale3b_branch2c
I0530 20:27:15.419996 26136 net.cpp:444] scale3b_branch2c <- res3b_branch2c
I0530 20:27:15.420011 26136 net.cpp:405] scale3b_branch2c -> res3b_branch2c (in-place)
I0530 20:27:15.420060 26136 layer_factory.hpp:77] Creating layer scale3b_branch2c
I0530 20:27:15.420176 26136 net.cpp:150] Setting up scale3b_branch2c
I0530 20:27:15.420183 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.420187 26136 net.cpp:165] Memory required for data: 139489292
I0530 20:27:15.420199 26136 layer_factory.hpp:77] Creating layer res3b
I0530 20:27:15.420212 26136 net.cpp:100] Creating Layer res3b
I0530 20:27:15.420218 26136 net.cpp:444] res3b <- res3a_res3a_relu_0_split_1
I0530 20:27:15.420229 26136 net.cpp:444] res3b <- res3b_branch2c
I0530 20:27:15.420241 26136 net.cpp:418] res3b -> res3b
I0530 20:27:15.420276 26136 net.cpp:150] Setting up res3b
I0530 20:27:15.420287 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.420290 26136 net.cpp:165] Memory required for data: 141094924
I0530 20:27:15.420295 26136 layer_factory.hpp:77] Creating layer res3b_relu
I0530 20:27:15.420306 26136 net.cpp:100] Creating Layer res3b_relu
I0530 20:27:15.420312 26136 net.cpp:444] res3b_relu <- res3b
I0530 20:27:15.420325 26136 net.cpp:405] res3b_relu -> res3b (in-place)
I0530 20:27:15.420691 26136 net.cpp:150] Setting up res3b_relu
I0530 20:27:15.420701 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.420704 26136 net.cpp:165] Memory required for data: 142700556
I0530 20:27:15.420709 26136 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0530 20:27:15.420722 26136 net.cpp:100] Creating Layer res3b_res3b_relu_0_split
I0530 20:27:15.420728 26136 net.cpp:444] res3b_res3b_relu_0_split <- res3b
I0530 20:27:15.420745 26136 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0530 20:27:15.420763 26136 net.cpp:418] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0530 20:27:15.420806 26136 net.cpp:150] Setting up res3b_res3b_relu_0_split
I0530 20:27:15.420815 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.420821 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.420825 26136 net.cpp:165] Memory required for data: 145911820
I0530 20:27:15.420830 26136 layer_factory.hpp:77] Creating layer res3c_branch2a
I0530 20:27:15.420846 26136 net.cpp:100] Creating Layer res3c_branch2a
I0530 20:27:15.420853 26136 net.cpp:444] res3c_branch2a <- res3b_res3b_relu_0_split_0
I0530 20:27:15.420869 26136 net.cpp:418] res3c_branch2a -> res3c_branch2a
I0530 20:27:15.421886 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.421905 26136 net.cpp:150] Setting up res3c_branch2a
I0530 20:27:15.421914 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.421917 26136 net.cpp:165] Memory required for data: 146313228
I0530 20:27:15.421931 26136 layer_factory.hpp:77] Creating layer bn3c_branch2a
I0530 20:27:15.421947 26136 net.cpp:100] Creating Layer bn3c_branch2a
I0530 20:27:15.421955 26136 net.cpp:444] bn3c_branch2a <- res3c_branch2a
I0530 20:27:15.421972 26136 net.cpp:405] bn3c_branch2a -> res3c_branch2a (in-place)
I0530 20:27:15.422134 26136 net.cpp:150] Setting up bn3c_branch2a
I0530 20:27:15.422142 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.422147 26136 net.cpp:165] Memory required for data: 146714636
I0530 20:27:15.422164 26136 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0530 20:27:15.422178 26136 net.cpp:100] Creating Layer scale3c_branch2a
I0530 20:27:15.422185 26136 net.cpp:444] scale3c_branch2a <- res3c_branch2a
I0530 20:27:15.422199 26136 net.cpp:405] scale3c_branch2a -> res3c_branch2a (in-place)
I0530 20:27:15.422250 26136 layer_factory.hpp:77] Creating layer scale3c_branch2a
I0530 20:27:15.422368 26136 net.cpp:150] Setting up scale3c_branch2a
I0530 20:27:15.422374 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.422379 26136 net.cpp:165] Memory required for data: 147116044
I0530 20:27:15.422391 26136 layer_factory.hpp:77] Creating layer res3c_branch2a_relu
I0530 20:27:15.422403 26136 net.cpp:100] Creating Layer res3c_branch2a_relu
I0530 20:27:15.422410 26136 net.cpp:444] res3c_branch2a_relu <- res3c_branch2a
I0530 20:27:15.422423 26136 net.cpp:405] res3c_branch2a_relu -> res3c_branch2a (in-place)
I0530 20:27:15.422565 26136 net.cpp:150] Setting up res3c_branch2a_relu
I0530 20:27:15.422574 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.422577 26136 net.cpp:165] Memory required for data: 147517452
I0530 20:27:15.422583 26136 layer_factory.hpp:77] Creating layer res3c_branch2b
I0530 20:27:15.422598 26136 net.cpp:100] Creating Layer res3c_branch2b
I0530 20:27:15.422605 26136 net.cpp:444] res3c_branch2b <- res3c_branch2a
I0530 20:27:15.422622 26136 net.cpp:418] res3c_branch2b -> res3c_branch2b
I0530 20:27:15.424186 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0530 20:27:15.424403 26136 net.cpp:150] Setting up res3c_branch2b
I0530 20:27:15.424417 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.424420 26136 net.cpp:165] Memory required for data: 147918860
I0530 20:27:15.424435 26136 layer_factory.hpp:77] Creating layer bn3c_branch2b
I0530 20:27:15.424458 26136 net.cpp:100] Creating Layer bn3c_branch2b
I0530 20:27:15.424465 26136 net.cpp:444] bn3c_branch2b <- res3c_branch2b
I0530 20:27:15.424481 26136 net.cpp:405] bn3c_branch2b -> res3c_branch2b (in-place)
I0530 20:27:15.424652 26136 net.cpp:150] Setting up bn3c_branch2b
I0530 20:27:15.424659 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.424664 26136 net.cpp:165] Memory required for data: 148320268
I0530 20:27:15.424681 26136 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0530 20:27:15.424696 26136 net.cpp:100] Creating Layer scale3c_branch2b
I0530 20:27:15.424702 26136 net.cpp:444] scale3c_branch2b <- res3c_branch2b
I0530 20:27:15.424716 26136 net.cpp:405] scale3c_branch2b -> res3c_branch2b (in-place)
I0530 20:27:15.424768 26136 layer_factory.hpp:77] Creating layer scale3c_branch2b
I0530 20:27:15.424890 26136 net.cpp:150] Setting up scale3c_branch2b
I0530 20:27:15.424897 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.424901 26136 net.cpp:165] Memory required for data: 148721676
I0530 20:27:15.424968 26136 layer_factory.hpp:77] Creating layer res3c_branch2b_relu
I0530 20:27:15.424983 26136 net.cpp:100] Creating Layer res3c_branch2b_relu
I0530 20:27:15.424989 26136 net.cpp:444] res3c_branch2b_relu <- res3c_branch2b
I0530 20:27:15.425002 26136 net.cpp:405] res3c_branch2b_relu -> res3c_branch2b (in-place)
I0530 20:27:15.425154 26136 net.cpp:150] Setting up res3c_branch2b_relu
I0530 20:27:15.425163 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.425166 26136 net.cpp:165] Memory required for data: 149123084
I0530 20:27:15.425171 26136 layer_factory.hpp:77] Creating layer res3c_branch2c
I0530 20:27:15.425189 26136 net.cpp:100] Creating Layer res3c_branch2c
I0530 20:27:15.425195 26136 net.cpp:444] res3c_branch2c <- res3c_branch2b
I0530 20:27:15.425213 26136 net.cpp:418] res3c_branch2c -> res3c_branch2c
I0530 20:27:15.426132 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.426148 26136 net.cpp:150] Setting up res3c_branch2c
I0530 20:27:15.426158 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.426162 26136 net.cpp:165] Memory required for data: 150728716
I0530 20:27:15.426173 26136 layer_factory.hpp:77] Creating layer bn3c_branch2c
I0530 20:27:15.426189 26136 net.cpp:100] Creating Layer bn3c_branch2c
I0530 20:27:15.426196 26136 net.cpp:444] bn3c_branch2c <- res3c_branch2c
I0530 20:27:15.426213 26136 net.cpp:405] bn3c_branch2c -> res3c_branch2c (in-place)
I0530 20:27:15.426376 26136 net.cpp:150] Setting up bn3c_branch2c
I0530 20:27:15.426384 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.426388 26136 net.cpp:165] Memory required for data: 152334348
I0530 20:27:15.426406 26136 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0530 20:27:15.426422 26136 net.cpp:100] Creating Layer scale3c_branch2c
I0530 20:27:15.426429 26136 net.cpp:444] scale3c_branch2c <- res3c_branch2c
I0530 20:27:15.426445 26136 net.cpp:405] scale3c_branch2c -> res3c_branch2c (in-place)
I0530 20:27:15.426496 26136 layer_factory.hpp:77] Creating layer scale3c_branch2c
I0530 20:27:15.426614 26136 net.cpp:150] Setting up scale3c_branch2c
I0530 20:27:15.426620 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.426625 26136 net.cpp:165] Memory required for data: 153939980
I0530 20:27:15.426637 26136 layer_factory.hpp:77] Creating layer res3c
I0530 20:27:15.426651 26136 net.cpp:100] Creating Layer res3c
I0530 20:27:15.426657 26136 net.cpp:444] res3c <- res3b_res3b_relu_0_split_1
I0530 20:27:15.426669 26136 net.cpp:444] res3c <- res3c_branch2c
I0530 20:27:15.426681 26136 net.cpp:418] res3c -> res3c
I0530 20:27:15.426717 26136 net.cpp:150] Setting up res3c
I0530 20:27:15.426725 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.426729 26136 net.cpp:165] Memory required for data: 155545612
I0530 20:27:15.426734 26136 layer_factory.hpp:77] Creating layer res3c_relu
I0530 20:27:15.426746 26136 net.cpp:100] Creating Layer res3c_relu
I0530 20:27:15.426753 26136 net.cpp:444] res3c_relu <- res3c
I0530 20:27:15.426764 26136 net.cpp:405] res3c_relu -> res3c (in-place)
I0530 20:27:15.426911 26136 net.cpp:150] Setting up res3c_relu
I0530 20:27:15.426918 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.426921 26136 net.cpp:165] Memory required for data: 157151244
I0530 20:27:15.426928 26136 layer_factory.hpp:77] Creating layer res3c_res3c_relu_0_split
I0530 20:27:15.426939 26136 net.cpp:100] Creating Layer res3c_res3c_relu_0_split
I0530 20:27:15.426945 26136 net.cpp:444] res3c_res3c_relu_0_split <- res3c
I0530 20:27:15.426960 26136 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_0
I0530 20:27:15.426977 26136 net.cpp:418] res3c_res3c_relu_0_split -> res3c_res3c_relu_0_split_1
I0530 20:27:15.427021 26136 net.cpp:150] Setting up res3c_res3c_relu_0_split
I0530 20:27:15.427029 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.427036 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.427038 26136 net.cpp:165] Memory required for data: 160362508
I0530 20:27:15.427043 26136 layer_factory.hpp:77] Creating layer res3d_branch2a
I0530 20:27:15.427059 26136 net.cpp:100] Creating Layer res3d_branch2a
I0530 20:27:15.427065 26136 net.cpp:444] res3d_branch2a <- res3c_res3c_relu_0_split_0
I0530 20:27:15.427081 26136 net.cpp:418] res3d_branch2a -> res3d_branch2a
I0530 20:27:15.428542 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.428560 26136 net.cpp:150] Setting up res3d_branch2a
I0530 20:27:15.428570 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.428573 26136 net.cpp:165] Memory required for data: 160763916
I0530 20:27:15.428586 26136 layer_factory.hpp:77] Creating layer bn3d_branch2a
I0530 20:27:15.428604 26136 net.cpp:100] Creating Layer bn3d_branch2a
I0530 20:27:15.428611 26136 net.cpp:444] bn3d_branch2a <- res3d_branch2a
I0530 20:27:15.428627 26136 net.cpp:405] bn3d_branch2a -> res3d_branch2a (in-place)
I0530 20:27:15.428797 26136 net.cpp:150] Setting up bn3d_branch2a
I0530 20:27:15.428803 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.428807 26136 net.cpp:165] Memory required for data: 161165324
I0530 20:27:15.428848 26136 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0530 20:27:15.428865 26136 net.cpp:100] Creating Layer scale3d_branch2a
I0530 20:27:15.428872 26136 net.cpp:444] scale3d_branch2a <- res3d_branch2a
I0530 20:27:15.428887 26136 net.cpp:405] scale3d_branch2a -> res3d_branch2a (in-place)
I0530 20:27:15.428957 26136 layer_factory.hpp:77] Creating layer scale3d_branch2a
I0530 20:27:15.429085 26136 net.cpp:150] Setting up scale3d_branch2a
I0530 20:27:15.429093 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.429097 26136 net.cpp:165] Memory required for data: 161566732
I0530 20:27:15.429109 26136 layer_factory.hpp:77] Creating layer res3d_branch2a_relu
I0530 20:27:15.429122 26136 net.cpp:100] Creating Layer res3d_branch2a_relu
I0530 20:27:15.429128 26136 net.cpp:444] res3d_branch2a_relu <- res3d_branch2a
I0530 20:27:15.429141 26136 net.cpp:405] res3d_branch2a_relu -> res3d_branch2a (in-place)
I0530 20:27:15.429497 26136 net.cpp:150] Setting up res3d_branch2a_relu
I0530 20:27:15.429507 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.429510 26136 net.cpp:165] Memory required for data: 161968140
I0530 20:27:15.429518 26136 layer_factory.hpp:77] Creating layer res3d_branch2b
I0530 20:27:15.429535 26136 net.cpp:100] Creating Layer res3d_branch2b
I0530 20:27:15.429543 26136 net.cpp:444] res3d_branch2b <- res3d_branch2a
I0530 20:27:15.429559 26136 net.cpp:418] res3d_branch2b -> res3d_branch2b
I0530 20:27:15.430541 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 3145728
I0530 20:27:15.430747 26136 net.cpp:150] Setting up res3d_branch2b
I0530 20:27:15.430760 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.430765 26136 net.cpp:165] Memory required for data: 162369548
I0530 20:27:15.430778 26136 layer_factory.hpp:77] Creating layer bn3d_branch2b
I0530 20:27:15.430794 26136 net.cpp:100] Creating Layer bn3d_branch2b
I0530 20:27:15.430801 26136 net.cpp:444] bn3d_branch2b <- res3d_branch2b
I0530 20:27:15.430816 26136 net.cpp:405] bn3d_branch2b -> res3d_branch2b (in-place)
I0530 20:27:15.430986 26136 net.cpp:150] Setting up bn3d_branch2b
I0530 20:27:15.430994 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.430996 26136 net.cpp:165] Memory required for data: 162770956
I0530 20:27:15.431013 26136 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0530 20:27:15.431030 26136 net.cpp:100] Creating Layer scale3d_branch2b
I0530 20:27:15.431035 26136 net.cpp:444] scale3d_branch2b <- res3d_branch2b
I0530 20:27:15.431049 26136 net.cpp:405] scale3d_branch2b -> res3d_branch2b (in-place)
I0530 20:27:15.431102 26136 layer_factory.hpp:77] Creating layer scale3d_branch2b
I0530 20:27:15.431221 26136 net.cpp:150] Setting up scale3d_branch2b
I0530 20:27:15.431227 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.431231 26136 net.cpp:165] Memory required for data: 163172364
I0530 20:27:15.431243 26136 layer_factory.hpp:77] Creating layer res3d_branch2b_relu
I0530 20:27:15.431254 26136 net.cpp:100] Creating Layer res3d_branch2b_relu
I0530 20:27:15.431262 26136 net.cpp:444] res3d_branch2b_relu <- res3d_branch2b
I0530 20:27:15.431274 26136 net.cpp:405] res3d_branch2b_relu -> res3d_branch2b (in-place)
I0530 20:27:15.431416 26136 net.cpp:150] Setting up res3d_branch2b_relu
I0530 20:27:15.431424 26136 net.cpp:157] Top shape: 1 128 28 28 (100352)
I0530 20:27:15.431427 26136 net.cpp:165] Memory required for data: 163573772
I0530 20:27:15.431433 26136 layer_factory.hpp:77] Creating layer res3d_branch2c
I0530 20:27:15.431449 26136 net.cpp:100] Creating Layer res3d_branch2c
I0530 20:27:15.431457 26136 net.cpp:444] res3d_branch2c <- res3d_branch2b
I0530 20:27:15.431473 26136 net.cpp:418] res3d_branch2c -> res3d_branch2c
I0530 20:27:15.432360 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 20664
I0530 20:27:15.432376 26136 net.cpp:150] Setting up res3d_branch2c
I0530 20:27:15.432386 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.432389 26136 net.cpp:165] Memory required for data: 165179404
I0530 20:27:15.432401 26136 layer_factory.hpp:77] Creating layer bn3d_branch2c
I0530 20:27:15.432417 26136 net.cpp:100] Creating Layer bn3d_branch2c
I0530 20:27:15.432425 26136 net.cpp:444] bn3d_branch2c <- res3d_branch2c
I0530 20:27:15.432440 26136 net.cpp:405] bn3d_branch2c -> res3d_branch2c (in-place)
I0530 20:27:15.432605 26136 net.cpp:150] Setting up bn3d_branch2c
I0530 20:27:15.432611 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.432616 26136 net.cpp:165] Memory required for data: 166785036
I0530 20:27:15.432633 26136 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0530 20:27:15.432648 26136 net.cpp:100] Creating Layer scale3d_branch2c
I0530 20:27:15.432656 26136 net.cpp:444] scale3d_branch2c <- res3d_branch2c
I0530 20:27:15.432669 26136 net.cpp:405] scale3d_branch2c -> res3d_branch2c (in-place)
I0530 20:27:15.432720 26136 layer_factory.hpp:77] Creating layer scale3d_branch2c
I0530 20:27:15.432838 26136 net.cpp:150] Setting up scale3d_branch2c
I0530 20:27:15.432845 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.432849 26136 net.cpp:165] Memory required for data: 168390668
I0530 20:27:15.432862 26136 layer_factory.hpp:77] Creating layer res3d
I0530 20:27:15.432875 26136 net.cpp:100] Creating Layer res3d
I0530 20:27:15.432881 26136 net.cpp:444] res3d <- res3c_res3c_relu_0_split_1
I0530 20:27:15.432893 26136 net.cpp:444] res3d <- res3d_branch2c
I0530 20:27:15.432904 26136 net.cpp:418] res3d -> res3d
I0530 20:27:15.432961 26136 net.cpp:150] Setting up res3d
I0530 20:27:15.432971 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.432976 26136 net.cpp:165] Memory required for data: 169996300
I0530 20:27:15.432981 26136 layer_factory.hpp:77] Creating layer res3d_relu
I0530 20:27:15.432991 26136 net.cpp:100] Creating Layer res3d_relu
I0530 20:27:15.432997 26136 net.cpp:444] res3d_relu <- res3d
I0530 20:27:15.433012 26136 net.cpp:405] res3d_relu -> res3d (in-place)
I0530 20:27:15.433153 26136 net.cpp:150] Setting up res3d_relu
I0530 20:27:15.433161 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.433163 26136 net.cpp:165] Memory required for data: 171601932
I0530 20:27:15.433169 26136 layer_factory.hpp:77] Creating layer res3d_res3d_relu_0_split
I0530 20:27:15.433182 26136 net.cpp:100] Creating Layer res3d_res3d_relu_0_split
I0530 20:27:15.433187 26136 net.cpp:444] res3d_res3d_relu_0_split <- res3d
I0530 20:27:15.433202 26136 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_0
I0530 20:27:15.433218 26136 net.cpp:418] res3d_res3d_relu_0_split -> res3d_res3d_relu_0_split_1
I0530 20:27:15.433260 26136 net.cpp:150] Setting up res3d_res3d_relu_0_split
I0530 20:27:15.433270 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.433275 26136 net.cpp:157] Top shape: 1 512 28 28 (401408)
I0530 20:27:15.433279 26136 net.cpp:165] Memory required for data: 174813196
I0530 20:27:15.433284 26136 layer_factory.hpp:77] Creating layer res4a_branch1
I0530 20:27:15.433300 26136 net.cpp:100] Creating Layer res4a_branch1
I0530 20:27:15.433305 26136 net.cpp:444] res4a_branch1 <- res3d_res3d_relu_0_split_0
I0530 20:27:15.433322 26136 net.cpp:418] res4a_branch1 -> res4a_branch1
I0530 20:27:15.435385 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7416
I0530 20:27:15.435411 26136 net.cpp:150] Setting up res4a_branch1
I0530 20:27:15.435422 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.435425 26136 net.cpp:165] Memory required for data: 175616012
I0530 20:27:15.435438 26136 layer_factory.hpp:77] Creating layer bn4a_branch1
I0530 20:27:15.435453 26136 net.cpp:100] Creating Layer bn4a_branch1
I0530 20:27:15.435461 26136 net.cpp:444] bn4a_branch1 <- res4a_branch1
I0530 20:27:15.435477 26136 net.cpp:405] bn4a_branch1 -> res4a_branch1 (in-place)
I0530 20:27:15.435652 26136 net.cpp:150] Setting up bn4a_branch1
I0530 20:27:15.435660 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.435663 26136 net.cpp:165] Memory required for data: 176418828
I0530 20:27:15.435681 26136 layer_factory.hpp:77] Creating layer scale4a_branch1
I0530 20:27:15.435695 26136 net.cpp:100] Creating Layer scale4a_branch1
I0530 20:27:15.435703 26136 net.cpp:444] scale4a_branch1 <- res4a_branch1
I0530 20:27:15.435717 26136 net.cpp:405] scale4a_branch1 -> res4a_branch1 (in-place)
I0530 20:27:15.435765 26136 layer_factory.hpp:77] Creating layer scale4a_branch1
I0530 20:27:15.435887 26136 net.cpp:150] Setting up scale4a_branch1
I0530 20:27:15.435895 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.435899 26136 net.cpp:165] Memory required for data: 177221644
I0530 20:27:15.435912 26136 layer_factory.hpp:77] Creating layer res4a_branch2a
I0530 20:27:15.435930 26136 net.cpp:100] Creating Layer res4a_branch2a
I0530 20:27:15.435936 26136 net.cpp:444] res4a_branch2a <- res3d_res3d_relu_0_split_1
I0530 20:27:15.435952 26136 net.cpp:418] res4a_branch2a -> res4a_branch2a
I0530 20:27:15.436915 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7032
I0530 20:27:15.436969 26136 net.cpp:150] Setting up res4a_branch2a
I0530 20:27:15.436978 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.436981 26136 net.cpp:165] Memory required for data: 177422348
I0530 20:27:15.436993 26136 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0530 20:27:15.437008 26136 net.cpp:100] Creating Layer bn4a_branch2a
I0530 20:27:15.437016 26136 net.cpp:444] bn4a_branch2a <- res4a_branch2a
I0530 20:27:15.437032 26136 net.cpp:405] bn4a_branch2a -> res4a_branch2a (in-place)
I0530 20:27:15.437198 26136 net.cpp:150] Setting up bn4a_branch2a
I0530 20:27:15.437206 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.437208 26136 net.cpp:165] Memory required for data: 177623052
I0530 20:27:15.437227 26136 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0530 20:27:15.437242 26136 net.cpp:100] Creating Layer scale4a_branch2a
I0530 20:27:15.437248 26136 net.cpp:444] scale4a_branch2a <- res4a_branch2a
I0530 20:27:15.437261 26136 net.cpp:405] scale4a_branch2a -> res4a_branch2a (in-place)
I0530 20:27:15.437311 26136 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0530 20:27:15.437428 26136 net.cpp:150] Setting up scale4a_branch2a
I0530 20:27:15.437436 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.437440 26136 net.cpp:165] Memory required for data: 177823756
I0530 20:27:15.437453 26136 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0530 20:27:15.437464 26136 net.cpp:100] Creating Layer res4a_branch2a_relu
I0530 20:27:15.437470 26136 net.cpp:444] res4a_branch2a_relu <- res4a_branch2a
I0530 20:27:15.437484 26136 net.cpp:405] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0530 20:27:15.437834 26136 net.cpp:150] Setting up res4a_branch2a_relu
I0530 20:27:15.437844 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.437847 26136 net.cpp:165] Memory required for data: 178024460
I0530 20:27:15.437855 26136 layer_factory.hpp:77] Creating layer res4a_branch2b
I0530 20:27:15.437871 26136 net.cpp:100] Creating Layer res4a_branch2b
I0530 20:27:15.437878 26136 net.cpp:444] res4a_branch2b <- res4a_branch2a
I0530 20:27:15.437894 26136 net.cpp:418] res4a_branch2b -> res4a_branch2b
I0530 20:27:15.440126 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0530 20:27:15.440340 26136 net.cpp:150] Setting up res4a_branch2b
I0530 20:27:15.440353 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.440357 26136 net.cpp:165] Memory required for data: 178225164
I0530 20:27:15.440372 26136 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0530 20:27:15.440392 26136 net.cpp:100] Creating Layer bn4a_branch2b
I0530 20:27:15.440400 26136 net.cpp:444] bn4a_branch2b <- res4a_branch2b
I0530 20:27:15.440416 26136 net.cpp:405] bn4a_branch2b -> res4a_branch2b (in-place)
I0530 20:27:15.440588 26136 net.cpp:150] Setting up bn4a_branch2b
I0530 20:27:15.440595 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.440599 26136 net.cpp:165] Memory required for data: 178425868
I0530 20:27:15.440618 26136 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0530 20:27:15.440634 26136 net.cpp:100] Creating Layer scale4a_branch2b
I0530 20:27:15.440640 26136 net.cpp:444] scale4a_branch2b <- res4a_branch2b
I0530 20:27:15.440654 26136 net.cpp:405] scale4a_branch2b -> res4a_branch2b (in-place)
I0530 20:27:15.440706 26136 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0530 20:27:15.440822 26136 net.cpp:150] Setting up scale4a_branch2b
I0530 20:27:15.440830 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.440834 26136 net.cpp:165] Memory required for data: 178626572
I0530 20:27:15.440847 26136 layer_factory.hpp:77] Creating layer res4a_branch2b_relu
I0530 20:27:15.440858 26136 net.cpp:100] Creating Layer res4a_branch2b_relu
I0530 20:27:15.440865 26136 net.cpp:444] res4a_branch2b_relu <- res4a_branch2b
I0530 20:27:15.440879 26136 net.cpp:405] res4a_branch2b_relu -> res4a_branch2b (in-place)
I0530 20:27:15.441094 26136 net.cpp:150] Setting up res4a_branch2b_relu
I0530 20:27:15.441102 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.441107 26136 net.cpp:165] Memory required for data: 178827276
I0530 20:27:15.441112 26136 layer_factory.hpp:77] Creating layer res4a_branch2c
I0530 20:27:15.441129 26136 net.cpp:100] Creating Layer res4a_branch2c
I0530 20:27:15.441136 26136 net.cpp:444] res4a_branch2c <- res4a_branch2b
I0530 20:27:15.441154 26136 net.cpp:418] res4a_branch2c -> res4a_branch2c
I0530 20:27:15.443009 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.443035 26136 net.cpp:150] Setting up res4a_branch2c
I0530 20:27:15.443047 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.443050 26136 net.cpp:165] Memory required for data: 179630092
I0530 20:27:15.443063 26136 layer_factory.hpp:77] Creating layer bn4a_branch2c
I0530 20:27:15.443081 26136 net.cpp:100] Creating Layer bn4a_branch2c
I0530 20:27:15.443089 26136 net.cpp:444] bn4a_branch2c <- res4a_branch2c
I0530 20:27:15.443105 26136 net.cpp:405] bn4a_branch2c -> res4a_branch2c (in-place)
I0530 20:27:15.443279 26136 net.cpp:150] Setting up bn4a_branch2c
I0530 20:27:15.443286 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.443290 26136 net.cpp:165] Memory required for data: 180432908
I0530 20:27:15.443308 26136 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0530 20:27:15.443325 26136 net.cpp:100] Creating Layer scale4a_branch2c
I0530 20:27:15.443332 26136 net.cpp:444] scale4a_branch2c <- res4a_branch2c
I0530 20:27:15.443346 26136 net.cpp:405] scale4a_branch2c -> res4a_branch2c (in-place)
I0530 20:27:15.443395 26136 layer_factory.hpp:77] Creating layer scale4a_branch2c
I0530 20:27:15.443521 26136 net.cpp:150] Setting up scale4a_branch2c
I0530 20:27:15.443528 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.443531 26136 net.cpp:165] Memory required for data: 181235724
I0530 20:27:15.443543 26136 layer_factory.hpp:77] Creating layer res4a
I0530 20:27:15.443555 26136 net.cpp:100] Creating Layer res4a
I0530 20:27:15.443562 26136 net.cpp:444] res4a <- res4a_branch1
I0530 20:27:15.443573 26136 net.cpp:444] res4a <- res4a_branch2c
I0530 20:27:15.443585 26136 net.cpp:418] res4a -> res4a
I0530 20:27:15.443621 26136 net.cpp:150] Setting up res4a
I0530 20:27:15.443630 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.443634 26136 net.cpp:165] Memory required for data: 182038540
I0530 20:27:15.443639 26136 layer_factory.hpp:77] Creating layer res4a_relu
I0530 20:27:15.443651 26136 net.cpp:100] Creating Layer res4a_relu
I0530 20:27:15.443657 26136 net.cpp:444] res4a_relu <- res4a
I0530 20:27:15.443670 26136 net.cpp:405] res4a_relu -> res4a (in-place)
I0530 20:27:15.444010 26136 net.cpp:150] Setting up res4a_relu
I0530 20:27:15.444020 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.444023 26136 net.cpp:165] Memory required for data: 182841356
I0530 20:27:15.444030 26136 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0530 20:27:15.444041 26136 net.cpp:100] Creating Layer res4a_res4a_relu_0_split
I0530 20:27:15.444048 26136 net.cpp:444] res4a_res4a_relu_0_split <- res4a
I0530 20:27:15.444064 26136 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0530 20:27:15.444082 26136 net.cpp:418] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0530 20:27:15.444128 26136 net.cpp:150] Setting up res4a_res4a_relu_0_split
I0530 20:27:15.444137 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.444144 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.444146 26136 net.cpp:165] Memory required for data: 184446988
I0530 20:27:15.444151 26136 layer_factory.hpp:77] Creating layer res4b_branch2a
I0530 20:27:15.444185 26136 net.cpp:100] Creating Layer res4b_branch2a
I0530 20:27:15.444191 26136 net.cpp:444] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0530 20:27:15.444208 26136 net.cpp:418] res4b_branch2a -> res4b_branch2a
I0530 20:27:15.445417 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.445442 26136 net.cpp:150] Setting up res4b_branch2a
I0530 20:27:15.445451 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.445456 26136 net.cpp:165] Memory required for data: 184647692
I0530 20:27:15.445469 26136 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0530 20:27:15.445485 26136 net.cpp:100] Creating Layer bn4b_branch2a
I0530 20:27:15.445492 26136 net.cpp:444] bn4b_branch2a <- res4b_branch2a
I0530 20:27:15.445508 26136 net.cpp:405] bn4b_branch2a -> res4b_branch2a (in-place)
I0530 20:27:15.445677 26136 net.cpp:150] Setting up bn4b_branch2a
I0530 20:27:15.445684 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.445688 26136 net.cpp:165] Memory required for data: 184848396
I0530 20:27:15.445706 26136 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0530 20:27:15.445720 26136 net.cpp:100] Creating Layer scale4b_branch2a
I0530 20:27:15.445726 26136 net.cpp:444] scale4b_branch2a <- res4b_branch2a
I0530 20:27:15.445740 26136 net.cpp:405] scale4b_branch2a -> res4b_branch2a (in-place)
I0530 20:27:15.445793 26136 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0530 20:27:15.445910 26136 net.cpp:150] Setting up scale4b_branch2a
I0530 20:27:15.445919 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.445921 26136 net.cpp:165] Memory required for data: 185049100
I0530 20:27:15.445933 26136 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0530 20:27:15.445945 26136 net.cpp:100] Creating Layer res4b_branch2a_relu
I0530 20:27:15.445952 26136 net.cpp:444] res4b_branch2a_relu <- res4b_branch2a
I0530 20:27:15.445966 26136 net.cpp:405] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0530 20:27:15.446310 26136 net.cpp:150] Setting up res4b_branch2a_relu
I0530 20:27:15.446319 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.446323 26136 net.cpp:165] Memory required for data: 185249804
I0530 20:27:15.446329 26136 layer_factory.hpp:77] Creating layer res4b_branch2b
I0530 20:27:15.446346 26136 net.cpp:100] Creating Layer res4b_branch2b
I0530 20:27:15.446353 26136 net.cpp:444] res4b_branch2b <- res4b_branch2a
I0530 20:27:15.446372 26136 net.cpp:418] res4b_branch2b -> res4b_branch2b
I0530 20:27:15.448618 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0530 20:27:15.448842 26136 net.cpp:150] Setting up res4b_branch2b
I0530 20:27:15.448854 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.448859 26136 net.cpp:165] Memory required for data: 185450508
I0530 20:27:15.448873 26136 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0530 20:27:15.448890 26136 net.cpp:100] Creating Layer bn4b_branch2b
I0530 20:27:15.448899 26136 net.cpp:444] bn4b_branch2b <- res4b_branch2b
I0530 20:27:15.448922 26136 net.cpp:405] bn4b_branch2b -> res4b_branch2b (in-place)
I0530 20:27:15.449137 26136 net.cpp:150] Setting up bn4b_branch2b
I0530 20:27:15.449146 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.449148 26136 net.cpp:165] Memory required for data: 185651212
I0530 20:27:15.449169 26136 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0530 20:27:15.449185 26136 net.cpp:100] Creating Layer scale4b_branch2b
I0530 20:27:15.449192 26136 net.cpp:444] scale4b_branch2b <- res4b_branch2b
I0530 20:27:15.449208 26136 net.cpp:405] scale4b_branch2b -> res4b_branch2b (in-place)
I0530 20:27:15.449260 26136 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0530 20:27:15.449383 26136 net.cpp:150] Setting up scale4b_branch2b
I0530 20:27:15.449391 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.449394 26136 net.cpp:165] Memory required for data: 185851916
I0530 20:27:15.449407 26136 layer_factory.hpp:77] Creating layer res4b_branch2b_relu
I0530 20:27:15.449419 26136 net.cpp:100] Creating Layer res4b_branch2b_relu
I0530 20:27:15.449425 26136 net.cpp:444] res4b_branch2b_relu <- res4b_branch2b
I0530 20:27:15.449440 26136 net.cpp:405] res4b_branch2b_relu -> res4b_branch2b (in-place)
I0530 20:27:15.449591 26136 net.cpp:150] Setting up res4b_branch2b_relu
I0530 20:27:15.449599 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.449602 26136 net.cpp:165] Memory required for data: 186052620
I0530 20:27:15.449607 26136 layer_factory.hpp:77] Creating layer res4b_branch2c
I0530 20:27:15.449626 26136 net.cpp:100] Creating Layer res4b_branch2c
I0530 20:27:15.449632 26136 net.cpp:444] res4b_branch2c <- res4b_branch2b
I0530 20:27:15.449651 26136 net.cpp:418] res4b_branch2c -> res4b_branch2c
I0530 20:27:15.451578 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.451611 26136 net.cpp:150] Setting up res4b_branch2c
I0530 20:27:15.451624 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.451628 26136 net.cpp:165] Memory required for data: 186855436
I0530 20:27:15.451644 26136 layer_factory.hpp:77] Creating layer bn4b_branch2c
I0530 20:27:15.451664 26136 net.cpp:100] Creating Layer bn4b_branch2c
I0530 20:27:15.451674 26136 net.cpp:444] bn4b_branch2c <- res4b_branch2c
I0530 20:27:15.451692 26136 net.cpp:405] bn4b_branch2c -> res4b_branch2c (in-place)
I0530 20:27:15.451875 26136 net.cpp:150] Setting up bn4b_branch2c
I0530 20:27:15.451884 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.451886 26136 net.cpp:165] Memory required for data: 187658252
I0530 20:27:15.451905 26136 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0530 20:27:15.451921 26136 net.cpp:100] Creating Layer scale4b_branch2c
I0530 20:27:15.451928 26136 net.cpp:444] scale4b_branch2c <- res4b_branch2c
I0530 20:27:15.451943 26136 net.cpp:405] scale4b_branch2c -> res4b_branch2c (in-place)
I0530 20:27:15.451994 26136 layer_factory.hpp:77] Creating layer scale4b_branch2c
I0530 20:27:15.452123 26136 net.cpp:150] Setting up scale4b_branch2c
I0530 20:27:15.452131 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.452134 26136 net.cpp:165] Memory required for data: 188461068
I0530 20:27:15.452147 26136 layer_factory.hpp:77] Creating layer res4b
I0530 20:27:15.452160 26136 net.cpp:100] Creating Layer res4b
I0530 20:27:15.452167 26136 net.cpp:444] res4b <- res4a_res4a_relu_0_split_1
I0530 20:27:15.452179 26136 net.cpp:444] res4b <- res4b_branch2c
I0530 20:27:15.452190 26136 net.cpp:418] res4b -> res4b
I0530 20:27:15.452229 26136 net.cpp:150] Setting up res4b
I0530 20:27:15.452237 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.452241 26136 net.cpp:165] Memory required for data: 189263884
I0530 20:27:15.452246 26136 layer_factory.hpp:77] Creating layer res4b_relu
I0530 20:27:15.452257 26136 net.cpp:100] Creating Layer res4b_relu
I0530 20:27:15.452263 26136 net.cpp:444] res4b_relu <- res4b
I0530 20:27:15.452277 26136 net.cpp:405] res4b_relu -> res4b (in-place)
I0530 20:27:15.452420 26136 net.cpp:150] Setting up res4b_relu
I0530 20:27:15.452428 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.452431 26136 net.cpp:165] Memory required for data: 190066700
I0530 20:27:15.452436 26136 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0530 20:27:15.452450 26136 net.cpp:100] Creating Layer res4b_res4b_relu_0_split
I0530 20:27:15.452456 26136 net.cpp:444] res4b_res4b_relu_0_split <- res4b
I0530 20:27:15.452471 26136 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0530 20:27:15.452488 26136 net.cpp:418] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0530 20:27:15.452533 26136 net.cpp:150] Setting up res4b_res4b_relu_0_split
I0530 20:27:15.452541 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.452548 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.452551 26136 net.cpp:165] Memory required for data: 191672332
I0530 20:27:15.452555 26136 layer_factory.hpp:77] Creating layer res4c_branch2a
I0530 20:27:15.452574 26136 net.cpp:100] Creating Layer res4c_branch2a
I0530 20:27:15.452579 26136 net.cpp:444] res4c_branch2a <- res4b_res4b_relu_0_split_0
I0530 20:27:15.452596 26136 net.cpp:418] res4c_branch2a -> res4c_branch2a
I0530 20:27:15.454020 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.454054 26136 net.cpp:150] Setting up res4c_branch2a
I0530 20:27:15.454069 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.454073 26136 net.cpp:165] Memory required for data: 191873036
I0530 20:27:15.454092 26136 layer_factory.hpp:77] Creating layer bn4c_branch2a
I0530 20:27:15.454118 26136 net.cpp:100] Creating Layer bn4c_branch2a
I0530 20:27:15.454128 26136 net.cpp:444] bn4c_branch2a <- res4c_branch2a
I0530 20:27:15.454147 26136 net.cpp:405] bn4c_branch2a -> res4c_branch2a (in-place)
I0530 20:27:15.454335 26136 net.cpp:150] Setting up bn4c_branch2a
I0530 20:27:15.454342 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.454345 26136 net.cpp:165] Memory required for data: 192073740
I0530 20:27:15.454363 26136 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0530 20:27:15.454380 26136 net.cpp:100] Creating Layer scale4c_branch2a
I0530 20:27:15.454386 26136 net.cpp:444] scale4c_branch2a <- res4c_branch2a
I0530 20:27:15.454401 26136 net.cpp:405] scale4c_branch2a -> res4c_branch2a (in-place)
I0530 20:27:15.454454 26136 layer_factory.hpp:77] Creating layer scale4c_branch2a
I0530 20:27:15.454579 26136 net.cpp:150] Setting up scale4c_branch2a
I0530 20:27:15.454586 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.454591 26136 net.cpp:165] Memory required for data: 192274444
I0530 20:27:15.454604 26136 layer_factory.hpp:77] Creating layer res4c_branch2a_relu
I0530 20:27:15.454617 26136 net.cpp:100] Creating Layer res4c_branch2a_relu
I0530 20:27:15.454623 26136 net.cpp:444] res4c_branch2a_relu <- res4c_branch2a
I0530 20:27:15.454636 26136 net.cpp:405] res4c_branch2a_relu -> res4c_branch2a (in-place)
I0530 20:27:15.454782 26136 net.cpp:150] Setting up res4c_branch2a_relu
I0530 20:27:15.454788 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.454792 26136 net.cpp:165] Memory required for data: 192475148
I0530 20:27:15.454797 26136 layer_factory.hpp:77] Creating layer res4c_branch2b
I0530 20:27:15.454816 26136 net.cpp:100] Creating Layer res4c_branch2b
I0530 20:27:15.454823 26136 net.cpp:444] res4c_branch2b <- res4c_branch2a
I0530 20:27:15.454838 26136 net.cpp:418] res4c_branch2b -> res4c_branch2b
I0530 20:27:15.457491 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0530 20:27:15.457762 26136 net.cpp:150] Setting up res4c_branch2b
I0530 20:27:15.457787 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.457792 26136 net.cpp:165] Memory required for data: 192675852
I0530 20:27:15.457816 26136 layer_factory.hpp:77] Creating layer bn4c_branch2b
I0530 20:27:15.457846 26136 net.cpp:100] Creating Layer bn4c_branch2b
I0530 20:27:15.457859 26136 net.cpp:444] bn4c_branch2b <- res4c_branch2b
I0530 20:27:15.457881 26136 net.cpp:405] bn4c_branch2b -> res4c_branch2b (in-place)
I0530 20:27:15.458076 26136 net.cpp:150] Setting up bn4c_branch2b
I0530 20:27:15.458084 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.458088 26136 net.cpp:165] Memory required for data: 192876556
I0530 20:27:15.458108 26136 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0530 20:27:15.458127 26136 net.cpp:100] Creating Layer scale4c_branch2b
I0530 20:27:15.458133 26136 net.cpp:444] scale4c_branch2b <- res4c_branch2b
I0530 20:27:15.458150 26136 net.cpp:405] scale4c_branch2b -> res4c_branch2b (in-place)
I0530 20:27:15.458205 26136 layer_factory.hpp:77] Creating layer scale4c_branch2b
I0530 20:27:15.458333 26136 net.cpp:150] Setting up scale4c_branch2b
I0530 20:27:15.458341 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.458344 26136 net.cpp:165] Memory required for data: 193077260
I0530 20:27:15.458358 26136 layer_factory.hpp:77] Creating layer res4c_branch2b_relu
I0530 20:27:15.458369 26136 net.cpp:100] Creating Layer res4c_branch2b_relu
I0530 20:27:15.458376 26136 net.cpp:444] res4c_branch2b_relu <- res4c_branch2b
I0530 20:27:15.458390 26136 net.cpp:405] res4c_branch2b_relu -> res4c_branch2b (in-place)
I0530 20:27:15.458776 26136 net.cpp:150] Setting up res4c_branch2b_relu
I0530 20:27:15.458787 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.458792 26136 net.cpp:165] Memory required for data: 193277964
I0530 20:27:15.458798 26136 layer_factory.hpp:77] Creating layer res4c_branch2c
I0530 20:27:15.458819 26136 net.cpp:100] Creating Layer res4c_branch2c
I0530 20:27:15.458827 26136 net.cpp:444] res4c_branch2c <- res4c_branch2b
I0530 20:27:15.458843 26136 net.cpp:418] res4c_branch2c -> res4c_branch2c
I0530 20:27:15.460748 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.460785 26136 net.cpp:150] Setting up res4c_branch2c
I0530 20:27:15.460799 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.460803 26136 net.cpp:165] Memory required for data: 194080780
I0530 20:27:15.460822 26136 layer_factory.hpp:77] Creating layer bn4c_branch2c
I0530 20:27:15.460849 26136 net.cpp:100] Creating Layer bn4c_branch2c
I0530 20:27:15.460858 26136 net.cpp:444] bn4c_branch2c <- res4c_branch2c
I0530 20:27:15.460878 26136 net.cpp:405] bn4c_branch2c -> res4c_branch2c (in-place)
I0530 20:27:15.461100 26136 net.cpp:150] Setting up bn4c_branch2c
I0530 20:27:15.461108 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.461112 26136 net.cpp:165] Memory required for data: 194883596
I0530 20:27:15.461130 26136 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0530 20:27:15.461146 26136 net.cpp:100] Creating Layer scale4c_branch2c
I0530 20:27:15.461153 26136 net.cpp:444] scale4c_branch2c <- res4c_branch2c
I0530 20:27:15.461167 26136 net.cpp:405] scale4c_branch2c -> res4c_branch2c (in-place)
I0530 20:27:15.461220 26136 layer_factory.hpp:77] Creating layer scale4c_branch2c
I0530 20:27:15.461350 26136 net.cpp:150] Setting up scale4c_branch2c
I0530 20:27:15.461359 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.461362 26136 net.cpp:165] Memory required for data: 195686412
I0530 20:27:15.461375 26136 layer_factory.hpp:77] Creating layer res4c
I0530 20:27:15.461387 26136 net.cpp:100] Creating Layer res4c
I0530 20:27:15.461395 26136 net.cpp:444] res4c <- res4b_res4b_relu_0_split_1
I0530 20:27:15.461406 26136 net.cpp:444] res4c <- res4c_branch2c
I0530 20:27:15.461417 26136 net.cpp:418] res4c -> res4c
I0530 20:27:15.461455 26136 net.cpp:150] Setting up res4c
I0530 20:27:15.461465 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.461468 26136 net.cpp:165] Memory required for data: 196489228
I0530 20:27:15.461474 26136 layer_factory.hpp:77] Creating layer res4c_relu
I0530 20:27:15.461485 26136 net.cpp:100] Creating Layer res4c_relu
I0530 20:27:15.461493 26136 net.cpp:444] res4c_relu <- res4c
I0530 20:27:15.461504 26136 net.cpp:405] res4c_relu -> res4c (in-place)
I0530 20:27:15.461648 26136 net.cpp:150] Setting up res4c_relu
I0530 20:27:15.461655 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.461658 26136 net.cpp:165] Memory required for data: 197292044
I0530 20:27:15.461664 26136 layer_factory.hpp:77] Creating layer res4c_res4c_relu_0_split
I0530 20:27:15.461678 26136 net.cpp:100] Creating Layer res4c_res4c_relu_0_split
I0530 20:27:15.461684 26136 net.cpp:444] res4c_res4c_relu_0_split <- res4c
I0530 20:27:15.461699 26136 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_0
I0530 20:27:15.461715 26136 net.cpp:418] res4c_res4c_relu_0_split -> res4c_res4c_relu_0_split_1
I0530 20:27:15.461760 26136 net.cpp:150] Setting up res4c_res4c_relu_0_split
I0530 20:27:15.461769 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.461776 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.461779 26136 net.cpp:165] Memory required for data: 198897676
I0530 20:27:15.461784 26136 layer_factory.hpp:77] Creating layer res4d_branch2a
I0530 20:27:15.461802 26136 net.cpp:100] Creating Layer res4d_branch2a
I0530 20:27:15.461809 26136 net.cpp:444] res4d_branch2a <- res4c_res4c_relu_0_split_0
I0530 20:27:15.461827 26136 net.cpp:418] res4d_branch2a -> res4d_branch2a
I0530 20:27:15.465657 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.465689 26136 net.cpp:150] Setting up res4d_branch2a
I0530 20:27:15.465701 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.465705 26136 net.cpp:165] Memory required for data: 199098380
I0530 20:27:15.465721 26136 layer_factory.hpp:77] Creating layer bn4d_branch2a
I0530 20:27:15.465744 26136 net.cpp:100] Creating Layer bn4d_branch2a
I0530 20:27:15.465754 26136 net.cpp:444] bn4d_branch2a <- res4d_branch2a
I0530 20:27:15.465771 26136 net.cpp:405] bn4d_branch2a -> res4d_branch2a (in-place)
I0530 20:27:15.465955 26136 net.cpp:150] Setting up bn4d_branch2a
I0530 20:27:15.465961 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.465965 26136 net.cpp:165] Memory required for data: 199299084
I0530 20:27:15.465982 26136 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0530 20:27:15.465999 26136 net.cpp:100] Creating Layer scale4d_branch2a
I0530 20:27:15.466006 26136 net.cpp:444] scale4d_branch2a <- res4d_branch2a
I0530 20:27:15.466020 26136 net.cpp:405] scale4d_branch2a -> res4d_branch2a (in-place)
I0530 20:27:15.466073 26136 layer_factory.hpp:77] Creating layer scale4d_branch2a
I0530 20:27:15.466197 26136 net.cpp:150] Setting up scale4d_branch2a
I0530 20:27:15.466204 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.466208 26136 net.cpp:165] Memory required for data: 199499788
I0530 20:27:15.466222 26136 layer_factory.hpp:77] Creating layer res4d_branch2a_relu
I0530 20:27:15.466233 26136 net.cpp:100] Creating Layer res4d_branch2a_relu
I0530 20:27:15.466239 26136 net.cpp:444] res4d_branch2a_relu <- res4d_branch2a
I0530 20:27:15.466253 26136 net.cpp:405] res4d_branch2a_relu -> res4d_branch2a (in-place)
I0530 20:27:15.466399 26136 net.cpp:150] Setting up res4d_branch2a_relu
I0530 20:27:15.466408 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.466410 26136 net.cpp:165] Memory required for data: 199700492
I0530 20:27:15.466415 26136 layer_factory.hpp:77] Creating layer res4d_branch2b
I0530 20:27:15.466434 26136 net.cpp:100] Creating Layer res4d_branch2b
I0530 20:27:15.466439 26136 net.cpp:444] res4d_branch2b <- res4d_branch2a
I0530 20:27:15.466456 26136 net.cpp:418] res4d_branch2b -> res4d_branch2b
I0530 20:27:15.468787 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0530 20:27:15.469066 26136 net.cpp:150] Setting up res4d_branch2b
I0530 20:27:15.469084 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.469087 26136 net.cpp:165] Memory required for data: 199901196
I0530 20:27:15.469102 26136 layer_factory.hpp:77] Creating layer bn4d_branch2b
I0530 20:27:15.469123 26136 net.cpp:100] Creating Layer bn4d_branch2b
I0530 20:27:15.469132 26136 net.cpp:444] bn4d_branch2b <- res4d_branch2b
I0530 20:27:15.469151 26136 net.cpp:405] bn4d_branch2b -> res4d_branch2b (in-place)
I0530 20:27:15.469339 26136 net.cpp:150] Setting up bn4d_branch2b
I0530 20:27:15.469347 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.469350 26136 net.cpp:165] Memory required for data: 200101900
I0530 20:27:15.469369 26136 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0530 20:27:15.469385 26136 net.cpp:100] Creating Layer scale4d_branch2b
I0530 20:27:15.469393 26136 net.cpp:444] scale4d_branch2b <- res4d_branch2b
I0530 20:27:15.469408 26136 net.cpp:405] scale4d_branch2b -> res4d_branch2b (in-place)
I0530 20:27:15.469463 26136 layer_factory.hpp:77] Creating layer scale4d_branch2b
I0530 20:27:15.469588 26136 net.cpp:150] Setting up scale4d_branch2b
I0530 20:27:15.469595 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.469599 26136 net.cpp:165] Memory required for data: 200302604
I0530 20:27:15.469611 26136 layer_factory.hpp:77] Creating layer res4d_branch2b_relu
I0530 20:27:15.469624 26136 net.cpp:100] Creating Layer res4d_branch2b_relu
I0530 20:27:15.469630 26136 net.cpp:444] res4d_branch2b_relu <- res4d_branch2b
I0530 20:27:15.469643 26136 net.cpp:405] res4d_branch2b_relu -> res4d_branch2b (in-place)
I0530 20:27:15.470021 26136 net.cpp:150] Setting up res4d_branch2b_relu
I0530 20:27:15.470029 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.470033 26136 net.cpp:165] Memory required for data: 200503308
I0530 20:27:15.470039 26136 layer_factory.hpp:77] Creating layer res4d_branch2c
I0530 20:27:15.470059 26136 net.cpp:100] Creating Layer res4d_branch2c
I0530 20:27:15.470067 26136 net.cpp:444] res4d_branch2c <- res4d_branch2b
I0530 20:27:15.470084 26136 net.cpp:418] res4d_branch2c -> res4d_branch2c
I0530 20:27:15.471879 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.471906 26136 net.cpp:150] Setting up res4d_branch2c
I0530 20:27:15.471917 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.471920 26136 net.cpp:165] Memory required for data: 201306124
I0530 20:27:15.471933 26136 layer_factory.hpp:77] Creating layer bn4d_branch2c
I0530 20:27:15.471951 26136 net.cpp:100] Creating Layer bn4d_branch2c
I0530 20:27:15.471958 26136 net.cpp:444] bn4d_branch2c <- res4d_branch2c
I0530 20:27:15.471974 26136 net.cpp:405] bn4d_branch2c -> res4d_branch2c (in-place)
I0530 20:27:15.472162 26136 net.cpp:150] Setting up bn4d_branch2c
I0530 20:27:15.472168 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.472172 26136 net.cpp:165] Memory required for data: 202108940
I0530 20:27:15.472190 26136 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0530 20:27:15.472208 26136 net.cpp:100] Creating Layer scale4d_branch2c
I0530 20:27:15.472214 26136 net.cpp:444] scale4d_branch2c <- res4d_branch2c
I0530 20:27:15.472229 26136 net.cpp:405] scale4d_branch2c -> res4d_branch2c (in-place)
I0530 20:27:15.472280 26136 layer_factory.hpp:77] Creating layer scale4d_branch2c
I0530 20:27:15.472411 26136 net.cpp:150] Setting up scale4d_branch2c
I0530 20:27:15.472419 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.472422 26136 net.cpp:165] Memory required for data: 202911756
I0530 20:27:15.472434 26136 layer_factory.hpp:77] Creating layer res4d
I0530 20:27:15.472447 26136 net.cpp:100] Creating Layer res4d
I0530 20:27:15.472453 26136 net.cpp:444] res4d <- res4c_res4c_relu_0_split_1
I0530 20:27:15.472465 26136 net.cpp:444] res4d <- res4d_branch2c
I0530 20:27:15.472477 26136 net.cpp:418] res4d -> res4d
I0530 20:27:15.472514 26136 net.cpp:150] Setting up res4d
I0530 20:27:15.472523 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.472527 26136 net.cpp:165] Memory required for data: 203714572
I0530 20:27:15.472532 26136 layer_factory.hpp:77] Creating layer res4d_relu
I0530 20:27:15.472545 26136 net.cpp:100] Creating Layer res4d_relu
I0530 20:27:15.472551 26136 net.cpp:444] res4d_relu <- res4d
I0530 20:27:15.472564 26136 net.cpp:405] res4d_relu -> res4d (in-place)
I0530 20:27:15.472707 26136 net.cpp:150] Setting up res4d_relu
I0530 20:27:15.472715 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.472718 26136 net.cpp:165] Memory required for data: 204517388
I0530 20:27:15.472723 26136 layer_factory.hpp:77] Creating layer res4d_res4d_relu_0_split
I0530 20:27:15.472735 26136 net.cpp:100] Creating Layer res4d_res4d_relu_0_split
I0530 20:27:15.472741 26136 net.cpp:444] res4d_res4d_relu_0_split <- res4d
I0530 20:27:15.472759 26136 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_0
I0530 20:27:15.472775 26136 net.cpp:418] res4d_res4d_relu_0_split -> res4d_res4d_relu_0_split_1
I0530 20:27:15.472820 26136 net.cpp:150] Setting up res4d_res4d_relu_0_split
I0530 20:27:15.472831 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.472836 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.472839 26136 net.cpp:165] Memory required for data: 206123020
I0530 20:27:15.472844 26136 layer_factory.hpp:77] Creating layer res4e_branch2a
I0530 20:27:15.472862 26136 net.cpp:100] Creating Layer res4e_branch2a
I0530 20:27:15.472868 26136 net.cpp:444] res4e_branch2a <- res4d_res4d_relu_0_split_0
I0530 20:27:15.472883 26136 net.cpp:418] res4e_branch2a -> res4e_branch2a
I0530 20:27:15.474114 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.474139 26136 net.cpp:150] Setting up res4e_branch2a
I0530 20:27:15.474149 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.474153 26136 net.cpp:165] Memory required for data: 206323724
I0530 20:27:15.474164 26136 layer_factory.hpp:77] Creating layer bn4e_branch2a
I0530 20:27:15.474181 26136 net.cpp:100] Creating Layer bn4e_branch2a
I0530 20:27:15.474189 26136 net.cpp:444] bn4e_branch2a <- res4e_branch2a
I0530 20:27:15.474205 26136 net.cpp:405] bn4e_branch2a -> res4e_branch2a (in-place)
I0530 20:27:15.474383 26136 net.cpp:150] Setting up bn4e_branch2a
I0530 20:27:15.474390 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.474395 26136 net.cpp:165] Memory required for data: 206524428
I0530 20:27:15.474412 26136 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0530 20:27:15.474428 26136 net.cpp:100] Creating Layer scale4e_branch2a
I0530 20:27:15.474436 26136 net.cpp:444] scale4e_branch2a <- res4e_branch2a
I0530 20:27:15.474449 26136 net.cpp:405] scale4e_branch2a -> res4e_branch2a (in-place)
I0530 20:27:15.474503 26136 layer_factory.hpp:77] Creating layer scale4e_branch2a
I0530 20:27:15.474629 26136 net.cpp:150] Setting up scale4e_branch2a
I0530 20:27:15.474637 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.474640 26136 net.cpp:165] Memory required for data: 206725132
I0530 20:27:15.474653 26136 layer_factory.hpp:77] Creating layer res4e_branch2a_relu
I0530 20:27:15.474664 26136 net.cpp:100] Creating Layer res4e_branch2a_relu
I0530 20:27:15.474671 26136 net.cpp:444] res4e_branch2a_relu <- res4e_branch2a
I0530 20:27:15.474685 26136 net.cpp:405] res4e_branch2a_relu -> res4e_branch2a (in-place)
I0530 20:27:15.474829 26136 net.cpp:150] Setting up res4e_branch2a_relu
I0530 20:27:15.474838 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.474840 26136 net.cpp:165] Memory required for data: 206925836
I0530 20:27:15.474846 26136 layer_factory.hpp:77] Creating layer res4e_branch2b
I0530 20:27:15.474862 26136 net.cpp:100] Creating Layer res4e_branch2b
I0530 20:27:15.474869 26136 net.cpp:444] res4e_branch2b <- res4e_branch2a
I0530 20:27:15.474886 26136 net.cpp:418] res4e_branch2b -> res4e_branch2b
I0530 20:27:15.477286 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0530 20:27:15.477536 26136 net.cpp:150] Setting up res4e_branch2b
I0530 20:27:15.477552 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.477556 26136 net.cpp:165] Memory required for data: 207126540
I0530 20:27:15.477576 26136 layer_factory.hpp:77] Creating layer bn4e_branch2b
I0530 20:27:15.477602 26136 net.cpp:100] Creating Layer bn4e_branch2b
I0530 20:27:15.477613 26136 net.cpp:444] bn4e_branch2b <- res4e_branch2b
I0530 20:27:15.477633 26136 net.cpp:405] bn4e_branch2b -> res4e_branch2b (in-place)
I0530 20:27:15.477828 26136 net.cpp:150] Setting up bn4e_branch2b
I0530 20:27:15.477835 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.477838 26136 net.cpp:165] Memory required for data: 207327244
I0530 20:27:15.477856 26136 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0530 20:27:15.477874 26136 net.cpp:100] Creating Layer scale4e_branch2b
I0530 20:27:15.477881 26136 net.cpp:444] scale4e_branch2b <- res4e_branch2b
I0530 20:27:15.477895 26136 net.cpp:405] scale4e_branch2b -> res4e_branch2b (in-place)
I0530 20:27:15.477952 26136 layer_factory.hpp:77] Creating layer scale4e_branch2b
I0530 20:27:15.478080 26136 net.cpp:150] Setting up scale4e_branch2b
I0530 20:27:15.478087 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.478091 26136 net.cpp:165] Memory required for data: 207527948
I0530 20:27:15.478103 26136 layer_factory.hpp:77] Creating layer res4e_branch2b_relu
I0530 20:27:15.478116 26136 net.cpp:100] Creating Layer res4e_branch2b_relu
I0530 20:27:15.478123 26136 net.cpp:444] res4e_branch2b_relu <- res4e_branch2b
I0530 20:27:15.478137 26136 net.cpp:405] res4e_branch2b_relu -> res4e_branch2b (in-place)
I0530 20:27:15.478512 26136 net.cpp:150] Setting up res4e_branch2b_relu
I0530 20:27:15.478521 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.478525 26136 net.cpp:165] Memory required for data: 207728652
I0530 20:27:15.478533 26136 layer_factory.hpp:77] Creating layer res4e_branch2c
I0530 20:27:15.478550 26136 net.cpp:100] Creating Layer res4e_branch2c
I0530 20:27:15.478557 26136 net.cpp:444] res4e_branch2c <- res4e_branch2b
I0530 20:27:15.478575 26136 net.cpp:418] res4e_branch2c -> res4e_branch2c
I0530 20:27:15.480445 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.480478 26136 net.cpp:150] Setting up res4e_branch2c
I0530 20:27:15.480489 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.480492 26136 net.cpp:165] Memory required for data: 208531468
I0530 20:27:15.480509 26136 layer_factory.hpp:77] Creating layer bn4e_branch2c
I0530 20:27:15.480528 26136 net.cpp:100] Creating Layer bn4e_branch2c
I0530 20:27:15.480537 26136 net.cpp:444] bn4e_branch2c <- res4e_branch2c
I0530 20:27:15.480554 26136 net.cpp:405] bn4e_branch2c -> res4e_branch2c (in-place)
I0530 20:27:15.480743 26136 net.cpp:150] Setting up bn4e_branch2c
I0530 20:27:15.480751 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.480754 26136 net.cpp:165] Memory required for data: 209334284
I0530 20:27:15.480773 26136 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0530 20:27:15.480790 26136 net.cpp:100] Creating Layer scale4e_branch2c
I0530 20:27:15.480798 26136 net.cpp:444] scale4e_branch2c <- res4e_branch2c
I0530 20:27:15.480811 26136 net.cpp:405] scale4e_branch2c -> res4e_branch2c (in-place)
I0530 20:27:15.480865 26136 layer_factory.hpp:77] Creating layer scale4e_branch2c
I0530 20:27:15.481035 26136 net.cpp:150] Setting up scale4e_branch2c
I0530 20:27:15.481045 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.481048 26136 net.cpp:165] Memory required for data: 210137100
I0530 20:27:15.481061 26136 layer_factory.hpp:77] Creating layer res4e
I0530 20:27:15.481076 26136 net.cpp:100] Creating Layer res4e
I0530 20:27:15.481083 26136 net.cpp:444] res4e <- res4d_res4d_relu_0_split_1
I0530 20:27:15.481096 26136 net.cpp:444] res4e <- res4e_branch2c
I0530 20:27:15.481106 26136 net.cpp:418] res4e -> res4e
I0530 20:27:15.481146 26136 net.cpp:150] Setting up res4e
I0530 20:27:15.481155 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.481159 26136 net.cpp:165] Memory required for data: 210939916
I0530 20:27:15.481164 26136 layer_factory.hpp:77] Creating layer res4e_relu
I0530 20:27:15.481175 26136 net.cpp:100] Creating Layer res4e_relu
I0530 20:27:15.481182 26136 net.cpp:444] res4e_relu <- res4e
I0530 20:27:15.481196 26136 net.cpp:405] res4e_relu -> res4e (in-place)
I0530 20:27:15.481345 26136 net.cpp:150] Setting up res4e_relu
I0530 20:27:15.481353 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.481356 26136 net.cpp:165] Memory required for data: 211742732
I0530 20:27:15.481361 26136 layer_factory.hpp:77] Creating layer res4e_res4e_relu_0_split
I0530 20:27:15.481375 26136 net.cpp:100] Creating Layer res4e_res4e_relu_0_split
I0530 20:27:15.481381 26136 net.cpp:444] res4e_res4e_relu_0_split <- res4e
I0530 20:27:15.481397 26136 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_0
I0530 20:27:15.481415 26136 net.cpp:418] res4e_res4e_relu_0_split -> res4e_res4e_relu_0_split_1
I0530 20:27:15.481462 26136 net.cpp:150] Setting up res4e_res4e_relu_0_split
I0530 20:27:15.481470 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.481477 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.481480 26136 net.cpp:165] Memory required for data: 213348364
I0530 20:27:15.481485 26136 layer_factory.hpp:77] Creating layer res4f_branch2a
I0530 20:27:15.481503 26136 net.cpp:100] Creating Layer res4f_branch2a
I0530 20:27:15.481510 26136 net.cpp:444] res4f_branch2a <- res4e_res4e_relu_0_split_0
I0530 20:27:15.481529 26136 net.cpp:418] res4f_branch2a -> res4f_branch2a
I0530 20:27:15.486845 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.486924 26136 net.cpp:150] Setting up res4f_branch2a
I0530 20:27:15.486956 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.486961 26136 net.cpp:165] Memory required for data: 213549068
I0530 20:27:15.487007 26136 layer_factory.hpp:77] Creating layer bn4f_branch2a
I0530 20:27:15.487061 26136 net.cpp:100] Creating Layer bn4f_branch2a
I0530 20:27:15.487074 26136 net.cpp:444] bn4f_branch2a <- res4f_branch2a
I0530 20:27:15.487104 26136 net.cpp:405] bn4f_branch2a -> res4f_branch2a (in-place)
I0530 20:27:15.487422 26136 net.cpp:150] Setting up bn4f_branch2a
I0530 20:27:15.487433 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.487437 26136 net.cpp:165] Memory required for data: 213749772
I0530 20:27:15.487464 26136 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0530 20:27:15.487489 26136 net.cpp:100] Creating Layer scale4f_branch2a
I0530 20:27:15.487498 26136 net.cpp:444] scale4f_branch2a <- res4f_branch2a
I0530 20:27:15.487514 26136 net.cpp:405] scale4f_branch2a -> res4f_branch2a (in-place)
I0530 20:27:15.487592 26136 layer_factory.hpp:77] Creating layer scale4f_branch2a
I0530 20:27:15.487793 26136 net.cpp:150] Setting up scale4f_branch2a
I0530 20:27:15.487802 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.487804 26136 net.cpp:165] Memory required for data: 213950476
I0530 20:27:15.487818 26136 layer_factory.hpp:77] Creating layer res4f_branch2a_relu
I0530 20:27:15.487834 26136 net.cpp:100] Creating Layer res4f_branch2a_relu
I0530 20:27:15.487841 26136 net.cpp:444] res4f_branch2a_relu <- res4f_branch2a
I0530 20:27:15.487854 26136 net.cpp:405] res4f_branch2a_relu -> res4f_branch2a (in-place)
I0530 20:27:15.488099 26136 net.cpp:150] Setting up res4f_branch2a_relu
I0530 20:27:15.488107 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.488111 26136 net.cpp:165] Memory required for data: 214151180
I0530 20:27:15.488116 26136 layer_factory.hpp:77] Creating layer res4f_branch2b
I0530 20:27:15.488142 26136 net.cpp:100] Creating Layer res4f_branch2b
I0530 20:27:15.488152 26136 net.cpp:444] res4f_branch2b <- res4f_branch2a
I0530 20:27:15.488168 26136 net.cpp:418] res4f_branch2b -> res4f_branch2b
I0530 20:27:15.491803 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 12582912
I0530 20:27:15.492149 26136 net.cpp:150] Setting up res4f_branch2b
I0530 20:27:15.492168 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.492172 26136 net.cpp:165] Memory required for data: 214351884
I0530 20:27:15.492197 26136 layer_factory.hpp:77] Creating layer bn4f_branch2b
I0530 20:27:15.492224 26136 net.cpp:100] Creating Layer bn4f_branch2b
I0530 20:27:15.492235 26136 net.cpp:444] bn4f_branch2b <- res4f_branch2b
I0530 20:27:15.492256 26136 net.cpp:405] bn4f_branch2b -> res4f_branch2b (in-place)
I0530 20:27:15.492516 26136 net.cpp:150] Setting up bn4f_branch2b
I0530 20:27:15.492525 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.492528 26136 net.cpp:165] Memory required for data: 214552588
I0530 20:27:15.492548 26136 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0530 20:27:15.492563 26136 net.cpp:100] Creating Layer scale4f_branch2b
I0530 20:27:15.492570 26136 net.cpp:444] scale4f_branch2b <- res4f_branch2b
I0530 20:27:15.492585 26136 net.cpp:405] scale4f_branch2b -> res4f_branch2b (in-place)
I0530 20:27:15.492651 26136 layer_factory.hpp:77] Creating layer scale4f_branch2b
I0530 20:27:15.492816 26136 net.cpp:150] Setting up scale4f_branch2b
I0530 20:27:15.492825 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.492828 26136 net.cpp:165] Memory required for data: 214753292
I0530 20:27:15.492841 26136 layer_factory.hpp:77] Creating layer res4f_branch2b_relu
I0530 20:27:15.492852 26136 net.cpp:100] Creating Layer res4f_branch2b_relu
I0530 20:27:15.492859 26136 net.cpp:444] res4f_branch2b_relu <- res4f_branch2b
I0530 20:27:15.492872 26136 net.cpp:405] res4f_branch2b_relu -> res4f_branch2b (in-place)
I0530 20:27:15.493082 26136 net.cpp:150] Setting up res4f_branch2b_relu
I0530 20:27:15.493090 26136 net.cpp:157] Top shape: 1 256 14 14 (50176)
I0530 20:27:15.493093 26136 net.cpp:165] Memory required for data: 214953996
I0530 20:27:15.493099 26136 layer_factory.hpp:77] Creating layer res4f_branch2c
I0530 20:27:15.493120 26136 net.cpp:100] Creating Layer res4f_branch2c
I0530 20:27:15.493127 26136 net.cpp:444] res4f_branch2c <- res4f_branch2b
I0530 20:27:15.493145 26136 net.cpp:418] res4f_branch2c -> res4f_branch2c
I0530 20:27:15.495627 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.495657 26136 net.cpp:150] Setting up res4f_branch2c
I0530 20:27:15.495667 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.495671 26136 net.cpp:165] Memory required for data: 215756812
I0530 20:27:15.495684 26136 layer_factory.hpp:77] Creating layer bn4f_branch2c
I0530 20:27:15.495703 26136 net.cpp:100] Creating Layer bn4f_branch2c
I0530 20:27:15.495710 26136 net.cpp:444] bn4f_branch2c <- res4f_branch2c
I0530 20:27:15.495728 26136 net.cpp:405] bn4f_branch2c -> res4f_branch2c (in-place)
I0530 20:27:15.495981 26136 net.cpp:150] Setting up bn4f_branch2c
I0530 20:27:15.495990 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.495993 26136 net.cpp:165] Memory required for data: 216559628
I0530 20:27:15.496057 26136 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0530 20:27:15.496073 26136 net.cpp:100] Creating Layer scale4f_branch2c
I0530 20:27:15.496080 26136 net.cpp:444] scale4f_branch2c <- res4f_branch2c
I0530 20:27:15.496093 26136 net.cpp:405] scale4f_branch2c -> res4f_branch2c (in-place)
I0530 20:27:15.496155 26136 layer_factory.hpp:77] Creating layer scale4f_branch2c
I0530 20:27:15.496325 26136 net.cpp:150] Setting up scale4f_branch2c
I0530 20:27:15.496335 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.496338 26136 net.cpp:165] Memory required for data: 217362444
I0530 20:27:15.496351 26136 layer_factory.hpp:77] Creating layer res4f
I0530 20:27:15.496363 26136 net.cpp:100] Creating Layer res4f
I0530 20:27:15.496371 26136 net.cpp:444] res4f <- res4e_res4e_relu_0_split_1
I0530 20:27:15.496381 26136 net.cpp:444] res4f <- res4f_branch2c
I0530 20:27:15.496393 26136 net.cpp:418] res4f -> res4f
I0530 20:27:15.496436 26136 net.cpp:150] Setting up res4f
I0530 20:27:15.496445 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.496448 26136 net.cpp:165] Memory required for data: 218165260
I0530 20:27:15.496454 26136 layer_factory.hpp:77] Creating layer res4f_relu
I0530 20:27:15.496466 26136 net.cpp:100] Creating Layer res4f_relu
I0530 20:27:15.496472 26136 net.cpp:444] res4f_relu <- res4f
I0530 20:27:15.496484 26136 net.cpp:405] res4f_relu -> res4f (in-place)
I0530 20:27:15.497009 26136 net.cpp:150] Setting up res4f_relu
I0530 20:27:15.497022 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.497026 26136 net.cpp:165] Memory required for data: 218968076
I0530 20:27:15.497031 26136 layer_factory.hpp:77] Creating layer res4f_res4f_relu_0_split
I0530 20:27:15.497045 26136 net.cpp:100] Creating Layer res4f_res4f_relu_0_split
I0530 20:27:15.497051 26136 net.cpp:444] res4f_res4f_relu_0_split <- res4f
I0530 20:27:15.497067 26136 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_0
I0530 20:27:15.497086 26136 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_1
I0530 20:27:15.497099 26136 net.cpp:418] res4f_res4f_relu_0_split -> res4f_res4f_relu_0_split_2
I0530 20:27:15.497172 26136 net.cpp:150] Setting up res4f_res4f_relu_0_split
I0530 20:27:15.497182 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.497189 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.497193 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:15.497196 26136 net.cpp:165] Memory required for data: 221376524
I0530 20:27:15.497201 26136 layer_factory.hpp:77] Creating layer res5a_branch1
I0530 20:27:15.497220 26136 net.cpp:100] Creating Layer res5a_branch1
I0530 20:27:15.497225 26136 net.cpp:444] res5a_branch1 <- res4f_res4f_relu_0_split_0
I0530 20:27:15.497241 26136 net.cpp:418] res5a_branch1 -> res5a_branch1
I0530 20:27:15.506830 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 8568
I0530 20:27:15.506871 26136 net.cpp:150] Setting up res5a_branch1
I0530 20:27:15.506888 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.506892 26136 net.cpp:165] Memory required for data: 222982156
I0530 20:27:15.506918 26136 layer_factory.hpp:77] Creating layer bn5a_branch1
I0530 20:27:15.506952 26136 net.cpp:100] Creating Layer bn5a_branch1
I0530 20:27:15.506961 26136 net.cpp:444] bn5a_branch1 <- res5a_branch1
I0530 20:27:15.506985 26136 net.cpp:405] bn5a_branch1 -> res5a_branch1 (in-place)
I0530 20:27:15.507262 26136 net.cpp:150] Setting up bn5a_branch1
I0530 20:27:15.507270 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.507274 26136 net.cpp:165] Memory required for data: 224587788
I0530 20:27:15.507297 26136 layer_factory.hpp:77] Creating layer scale5a_branch1
I0530 20:27:15.507315 26136 net.cpp:100] Creating Layer scale5a_branch1
I0530 20:27:15.507321 26136 net.cpp:444] scale5a_branch1 <- res5a_branch1
I0530 20:27:15.507335 26136 net.cpp:405] scale5a_branch1 -> res5a_branch1 (in-place)
I0530 20:27:15.507401 26136 layer_factory.hpp:77] Creating layer scale5a_branch1
I0530 20:27:15.507576 26136 net.cpp:150] Setting up scale5a_branch1
I0530 20:27:15.507585 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.507588 26136 net.cpp:165] Memory required for data: 226193420
I0530 20:27:15.507601 26136 layer_factory.hpp:77] Creating layer res5a_branch2a
I0530 20:27:15.507622 26136 net.cpp:100] Creating Layer res5a_branch2a
I0530 20:27:15.507628 26136 net.cpp:444] res5a_branch2a <- res4f_res4f_relu_0_split_1
I0530 20:27:15.507645 26136 net.cpp:418] res5a_branch2a -> res5a_branch2a
I0530 20:27:15.511070 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.511102 26136 net.cpp:150] Setting up res5a_branch2a
I0530 20:27:15.511116 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.511121 26136 net.cpp:165] Memory required for data: 226594828
I0530 20:27:15.511137 26136 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0530 20:27:15.511158 26136 net.cpp:100] Creating Layer bn5a_branch2a
I0530 20:27:15.511168 26136 net.cpp:444] bn5a_branch2a <- res5a_branch2a
I0530 20:27:15.511185 26136 net.cpp:405] bn5a_branch2a -> res5a_branch2a (in-place)
I0530 20:27:15.511445 26136 net.cpp:150] Setting up bn5a_branch2a
I0530 20:27:15.511452 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.511456 26136 net.cpp:165] Memory required for data: 226996236
I0530 20:27:15.511476 26136 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0530 20:27:15.511492 26136 net.cpp:100] Creating Layer scale5a_branch2a
I0530 20:27:15.511498 26136 net.cpp:444] scale5a_branch2a <- res5a_branch2a
I0530 20:27:15.511513 26136 net.cpp:405] scale5a_branch2a -> res5a_branch2a (in-place)
I0530 20:27:15.511572 26136 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0530 20:27:15.511742 26136 net.cpp:150] Setting up scale5a_branch2a
I0530 20:27:15.511750 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.511754 26136 net.cpp:165] Memory required for data: 227397644
I0530 20:27:15.511767 26136 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0530 20:27:15.511780 26136 net.cpp:100] Creating Layer res5a_branch2a_relu
I0530 20:27:15.511786 26136 net.cpp:444] res5a_branch2a_relu <- res5a_branch2a
I0530 20:27:15.511798 26136 net.cpp:405] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0530 20:27:15.511991 26136 net.cpp:150] Setting up res5a_branch2a_relu
I0530 20:27:15.512001 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.512003 26136 net.cpp:165] Memory required for data: 227799052
I0530 20:27:15.512008 26136 layer_factory.hpp:77] Creating layer res5a_branch2b
I0530 20:27:15.512027 26136 net.cpp:100] Creating Layer res5a_branch2b
I0530 20:27:15.512033 26136 net.cpp:444] res5a_branch2b <- res5a_branch2a
I0530 20:27:15.512049 26136 net.cpp:418] res5a_branch2b -> res5a_branch2b
I0530 20:27:15.519486 26136 net.cpp:150] Setting up res5a_branch2b
I0530 20:27:15.519518 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.519522 26136 net.cpp:165] Memory required for data: 228200460
I0530 20:27:15.519549 26136 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0530 20:27:15.519583 26136 net.cpp:100] Creating Layer bn5a_branch2b
I0530 20:27:15.519596 26136 net.cpp:444] bn5a_branch2b <- res5a_branch2b
I0530 20:27:15.519618 26136 net.cpp:405] bn5a_branch2b -> res5a_branch2b (in-place)
I0530 20:27:15.519978 26136 net.cpp:150] Setting up bn5a_branch2b
I0530 20:27:15.519986 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.519989 26136 net.cpp:165] Memory required for data: 228601868
I0530 20:27:15.520010 26136 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0530 20:27:15.520030 26136 net.cpp:100] Creating Layer scale5a_branch2b
I0530 20:27:15.520036 26136 net.cpp:444] scale5a_branch2b <- res5a_branch2b
I0530 20:27:15.520051 26136 net.cpp:405] scale5a_branch2b -> res5a_branch2b (in-place)
I0530 20:27:15.520117 26136 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0530 20:27:15.520294 26136 net.cpp:150] Setting up scale5a_branch2b
I0530 20:27:15.520303 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.520306 26136 net.cpp:165] Memory required for data: 229003276
I0530 20:27:15.520319 26136 layer_factory.hpp:77] Creating layer res5a_branch2b_relu
I0530 20:27:15.520332 26136 net.cpp:100] Creating Layer res5a_branch2b_relu
I0530 20:27:15.520339 26136 net.cpp:444] res5a_branch2b_relu <- res5a_branch2b
I0530 20:27:15.520351 26136 net.cpp:405] res5a_branch2b_relu -> res5a_branch2b (in-place)
I0530 20:27:15.520598 26136 net.cpp:150] Setting up res5a_branch2b_relu
I0530 20:27:15.520607 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.520611 26136 net.cpp:165] Memory required for data: 229404684
I0530 20:27:15.520615 26136 layer_factory.hpp:77] Creating layer res5a_branch2c
I0530 20:27:15.520637 26136 net.cpp:100] Creating Layer res5a_branch2c
I0530 20:27:15.520643 26136 net.cpp:444] res5a_branch2c <- res5a_branch2b
I0530 20:27:15.520659 26136 net.cpp:418] res5a_branch2c -> res5a_branch2c
I0530 20:27:15.524803 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0530 20:27:15.524839 26136 net.cpp:150] Setting up res5a_branch2c
I0530 20:27:15.524853 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.524857 26136 net.cpp:165] Memory required for data: 231010316
I0530 20:27:15.524878 26136 layer_factory.hpp:77] Creating layer bn5a_branch2c
I0530 20:27:15.524958 26136 net.cpp:100] Creating Layer bn5a_branch2c
I0530 20:27:15.524972 26136 net.cpp:444] bn5a_branch2c <- res5a_branch2c
I0530 20:27:15.524998 26136 net.cpp:405] bn5a_branch2c -> res5a_branch2c (in-place)
I0530 20:27:15.525223 26136 net.cpp:150] Setting up bn5a_branch2c
I0530 20:27:15.525230 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.525233 26136 net.cpp:165] Memory required for data: 232615948
I0530 20:27:15.525254 26136 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0530 20:27:15.525272 26136 net.cpp:100] Creating Layer scale5a_branch2c
I0530 20:27:15.525277 26136 net.cpp:444] scale5a_branch2c <- res5a_branch2c
I0530 20:27:15.525288 26136 net.cpp:405] scale5a_branch2c -> res5a_branch2c (in-place)
I0530 20:27:15.525352 26136 layer_factory.hpp:77] Creating layer scale5a_branch2c
I0530 20:27:15.525498 26136 net.cpp:150] Setting up scale5a_branch2c
I0530 20:27:15.525506 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.525511 26136 net.cpp:165] Memory required for data: 234221580
I0530 20:27:15.525524 26136 layer_factory.hpp:77] Creating layer res5a
I0530 20:27:15.525539 26136 net.cpp:100] Creating Layer res5a
I0530 20:27:15.525548 26136 net.cpp:444] res5a <- res5a_branch1
I0530 20:27:15.525562 26136 net.cpp:444] res5a <- res5a_branch2c
I0530 20:27:15.525574 26136 net.cpp:418] res5a -> res5a
I0530 20:27:15.525626 26136 net.cpp:150] Setting up res5a
I0530 20:27:15.525636 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.525640 26136 net.cpp:165] Memory required for data: 235827212
I0530 20:27:15.525645 26136 layer_factory.hpp:77] Creating layer res5a_relu
I0530 20:27:15.525658 26136 net.cpp:100] Creating Layer res5a_relu
I0530 20:27:15.525666 26136 net.cpp:444] res5a_relu <- res5a
I0530 20:27:15.525681 26136 net.cpp:405] res5a_relu -> res5a (in-place)
I0530 20:27:15.526111 26136 net.cpp:150] Setting up res5a_relu
I0530 20:27:15.526119 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.526124 26136 net.cpp:165] Memory required for data: 237432844
I0530 20:27:15.526130 26136 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0530 20:27:15.526144 26136 net.cpp:100] Creating Layer res5a_res5a_relu_0_split
I0530 20:27:15.526152 26136 net.cpp:444] res5a_res5a_relu_0_split <- res5a
I0530 20:27:15.526171 26136 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0530 20:27:15.526191 26136 net.cpp:418] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0530 20:27:15.526245 26136 net.cpp:150] Setting up res5a_res5a_relu_0_split
I0530 20:27:15.526254 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.526262 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.526265 26136 net.cpp:165] Memory required for data: 240644108
I0530 20:27:15.526270 26136 layer_factory.hpp:77] Creating layer res5b_branch2a
I0530 20:27:15.526291 26136 net.cpp:100] Creating Layer res5b_branch2a
I0530 20:27:15.526298 26136 net.cpp:444] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0530 20:27:15.526319 26136 net.cpp:418] res5b_branch2a -> res5b_branch2a
I0530 20:27:15.529738 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.529775 26136 net.cpp:150] Setting up res5b_branch2a
I0530 20:27:15.529791 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.529796 26136 net.cpp:165] Memory required for data: 241045516
I0530 20:27:15.529819 26136 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0530 20:27:15.529850 26136 net.cpp:100] Creating Layer bn5b_branch2a
I0530 20:27:15.529861 26136 net.cpp:444] bn5b_branch2a <- res5b_branch2a
I0530 20:27:15.529886 26136 net.cpp:405] bn5b_branch2a -> res5b_branch2a (in-place)
I0530 20:27:15.530097 26136 net.cpp:150] Setting up bn5b_branch2a
I0530 20:27:15.530104 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.530108 26136 net.cpp:165] Memory required for data: 241446924
I0530 20:27:15.530131 26136 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0530 20:27:15.530148 26136 net.cpp:100] Creating Layer scale5b_branch2a
I0530 20:27:15.530156 26136 net.cpp:444] scale5b_branch2a <- res5b_branch2a
I0530 20:27:15.530174 26136 net.cpp:405] scale5b_branch2a -> res5b_branch2a (in-place)
I0530 20:27:15.530234 26136 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0530 20:27:15.530377 26136 net.cpp:150] Setting up scale5b_branch2a
I0530 20:27:15.530388 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.530392 26136 net.cpp:165] Memory required for data: 241848332
I0530 20:27:15.530407 26136 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0530 20:27:15.530421 26136 net.cpp:100] Creating Layer res5b_branch2a_relu
I0530 20:27:15.530429 26136 net.cpp:444] res5b_branch2a_relu <- res5b_branch2a
I0530 20:27:15.530443 26136 net.cpp:405] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0530 20:27:15.530601 26136 net.cpp:150] Setting up res5b_branch2a_relu
I0530 20:27:15.530608 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.530611 26136 net.cpp:165] Memory required for data: 242249740
I0530 20:27:15.530617 26136 layer_factory.hpp:77] Creating layer res5b_branch2b
I0530 20:27:15.530637 26136 net.cpp:100] Creating Layer res5b_branch2b
I0530 20:27:15.530643 26136 net.cpp:444] res5b_branch2b <- res5b_branch2a
I0530 20:27:15.530663 26136 net.cpp:418] res5b_branch2b -> res5b_branch2b
I0530 20:27:15.536309 26136 net.cpp:150] Setting up res5b_branch2b
I0530 20:27:15.536345 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.536350 26136 net.cpp:165] Memory required for data: 242651148
I0530 20:27:15.536376 26136 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0530 20:27:15.536412 26136 net.cpp:100] Creating Layer bn5b_branch2b
I0530 20:27:15.536425 26136 net.cpp:444] bn5b_branch2b <- res5b_branch2b
I0530 20:27:15.536450 26136 net.cpp:405] bn5b_branch2b -> res5b_branch2b (in-place)
I0530 20:27:15.536804 26136 net.cpp:150] Setting up bn5b_branch2b
I0530 20:27:15.536816 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.536821 26136 net.cpp:165] Memory required for data: 243052556
I0530 20:27:15.536846 26136 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0530 20:27:15.536871 26136 net.cpp:100] Creating Layer scale5b_branch2b
I0530 20:27:15.536880 26136 net.cpp:444] scale5b_branch2b <- res5b_branch2b
I0530 20:27:15.536895 26136 net.cpp:405] scale5b_branch2b -> res5b_branch2b (in-place)
I0530 20:27:15.537058 26136 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0530 20:27:15.537264 26136 net.cpp:150] Setting up scale5b_branch2b
I0530 20:27:15.537272 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.537276 26136 net.cpp:165] Memory required for data: 243453964
I0530 20:27:15.537289 26136 layer_factory.hpp:77] Creating layer res5b_branch2b_relu
I0530 20:27:15.537302 26136 net.cpp:100] Creating Layer res5b_branch2b_relu
I0530 20:27:15.537309 26136 net.cpp:444] res5b_branch2b_relu <- res5b_branch2b
I0530 20:27:15.537322 26136 net.cpp:405] res5b_branch2b_relu -> res5b_branch2b (in-place)
I0530 20:27:15.537564 26136 net.cpp:150] Setting up res5b_branch2b_relu
I0530 20:27:15.537570 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.537571 26136 net.cpp:165] Memory required for data: 243855372
I0530 20:27:15.537576 26136 layer_factory.hpp:77] Creating layer res5b_branch2c
I0530 20:27:15.537595 26136 net.cpp:100] Creating Layer res5b_branch2c
I0530 20:27:15.537600 26136 net.cpp:444] res5b_branch2c <- res5b_branch2b
I0530 20:27:15.537613 26136 net.cpp:418] res5b_branch2c -> res5b_branch2c
I0530 20:27:15.541477 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0530 20:27:15.541513 26136 net.cpp:150] Setting up res5b_branch2c
I0530 20:27:15.541543 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.541558 26136 net.cpp:165] Memory required for data: 245461004
I0530 20:27:15.541579 26136 layer_factory.hpp:77] Creating layer bn5b_branch2c
I0530 20:27:15.541606 26136 net.cpp:100] Creating Layer bn5b_branch2c
I0530 20:27:15.541616 26136 net.cpp:444] bn5b_branch2c <- res5b_branch2c
I0530 20:27:15.541633 26136 net.cpp:405] bn5b_branch2c -> res5b_branch2c (in-place)
I0530 20:27:15.541843 26136 net.cpp:150] Setting up bn5b_branch2c
I0530 20:27:15.541848 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.541851 26136 net.cpp:165] Memory required for data: 247066636
I0530 20:27:15.541865 26136 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0530 20:27:15.541879 26136 net.cpp:100] Creating Layer scale5b_branch2c
I0530 20:27:15.541883 26136 net.cpp:444] scale5b_branch2c <- res5b_branch2c
I0530 20:27:15.541893 26136 net.cpp:405] scale5b_branch2c -> res5b_branch2c (in-place)
I0530 20:27:15.541947 26136 layer_factory.hpp:77] Creating layer scale5b_branch2c
I0530 20:27:15.542106 26136 net.cpp:150] Setting up scale5b_branch2c
I0530 20:27:15.542114 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.542114 26136 net.cpp:165] Memory required for data: 248672268
I0530 20:27:15.542124 26136 layer_factory.hpp:77] Creating layer res5b
I0530 20:27:15.542135 26136 net.cpp:100] Creating Layer res5b
I0530 20:27:15.542140 26136 net.cpp:444] res5b <- res5a_res5a_relu_0_split_1
I0530 20:27:15.542147 26136 net.cpp:444] res5b <- res5b_branch2c
I0530 20:27:15.542156 26136 net.cpp:418] res5b -> res5b
I0530 20:27:15.542191 26136 net.cpp:150] Setting up res5b
I0530 20:27:15.542197 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.542199 26136 net.cpp:165] Memory required for data: 250277900
I0530 20:27:15.542202 26136 layer_factory.hpp:77] Creating layer res5b_relu
I0530 20:27:15.542212 26136 net.cpp:100] Creating Layer res5b_relu
I0530 20:27:15.542217 26136 net.cpp:444] res5b_relu <- res5b
I0530 20:27:15.542224 26136 net.cpp:405] res5b_relu -> res5b (in-place)
I0530 20:27:15.542644 26136 net.cpp:150] Setting up res5b_relu
I0530 20:27:15.542654 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.542655 26136 net.cpp:165] Memory required for data: 251883532
I0530 20:27:15.542659 26136 layer_factory.hpp:77] Creating layer res5b_res5b_relu_0_split
I0530 20:27:15.542670 26136 net.cpp:100] Creating Layer res5b_res5b_relu_0_split
I0530 20:27:15.542675 26136 net.cpp:444] res5b_res5b_relu_0_split <- res5b
I0530 20:27:15.542687 26136 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_0
I0530 20:27:15.542702 26136 net.cpp:418] res5b_res5b_relu_0_split -> res5b_res5b_relu_0_split_1
I0530 20:27:15.542748 26136 net.cpp:150] Setting up res5b_res5b_relu_0_split
I0530 20:27:15.542757 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.542760 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.542762 26136 net.cpp:165] Memory required for data: 255094796
I0530 20:27:15.542765 26136 layer_factory.hpp:77] Creating layer res5c_branch2a
I0530 20:27:15.542779 26136 net.cpp:100] Creating Layer res5c_branch2a
I0530 20:27:15.542785 26136 net.cpp:444] res5c_branch2a <- res5b_res5b_relu_0_split_0
I0530 20:27:15.542796 26136 net.cpp:418] res5c_branch2a -> res5c_branch2a
I0530 20:27:15.546188 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:15.546219 26136 net.cpp:150] Setting up res5c_branch2a
I0530 20:27:15.546242 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.546252 26136 net.cpp:165] Memory required for data: 255496204
I0530 20:27:15.546267 26136 layer_factory.hpp:77] Creating layer bn5c_branch2a
I0530 20:27:15.546288 26136 net.cpp:100] Creating Layer bn5c_branch2a
I0530 20:27:15.546298 26136 net.cpp:444] bn5c_branch2a <- res5c_branch2a
I0530 20:27:15.546313 26136 net.cpp:405] bn5c_branch2a -> res5c_branch2a (in-place)
I0530 20:27:15.546514 26136 net.cpp:150] Setting up bn5c_branch2a
I0530 20:27:15.546519 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.546522 26136 net.cpp:165] Memory required for data: 255897612
I0530 20:27:15.546536 26136 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0530 20:27:15.546550 26136 net.cpp:100] Creating Layer scale5c_branch2a
I0530 20:27:15.546556 26136 net.cpp:444] scale5c_branch2a <- res5c_branch2a
I0530 20:27:15.546571 26136 net.cpp:405] scale5c_branch2a -> res5c_branch2a (in-place)
I0530 20:27:15.546653 26136 layer_factory.hpp:77] Creating layer scale5c_branch2a
I0530 20:27:15.546790 26136 net.cpp:150] Setting up scale5c_branch2a
I0530 20:27:15.546797 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.546802 26136 net.cpp:165] Memory required for data: 256299020
I0530 20:27:15.546814 26136 layer_factory.hpp:77] Creating layer res5c_branch2a_relu
I0530 20:27:15.546828 26136 net.cpp:100] Creating Layer res5c_branch2a_relu
I0530 20:27:15.546835 26136 net.cpp:444] res5c_branch2a_relu <- res5c_branch2a
I0530 20:27:15.546849 26136 net.cpp:405] res5c_branch2a_relu -> res5c_branch2a (in-place)
I0530 20:27:15.547000 26136 net.cpp:150] Setting up res5c_branch2a_relu
I0530 20:27:15.547008 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.547011 26136 net.cpp:165] Memory required for data: 256700428
I0530 20:27:15.547017 26136 layer_factory.hpp:77] Creating layer res5c_branch2b
I0530 20:27:15.547035 26136 net.cpp:100] Creating Layer res5c_branch2b
I0530 20:27:15.547041 26136 net.cpp:444] res5c_branch2b <- res5c_branch2a
I0530 20:27:15.547058 26136 net.cpp:418] res5c_branch2b -> res5c_branch2b
I0530 20:27:15.552896 26136 net.cpp:150] Setting up res5c_branch2b
I0530 20:27:15.552997 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.553004 26136 net.cpp:165] Memory required for data: 257101836
I0530 20:27:15.553032 26136 layer_factory.hpp:77] Creating layer bn5c_branch2b
I0530 20:27:15.553067 26136 net.cpp:100] Creating Layer bn5c_branch2b
I0530 20:27:15.553081 26136 net.cpp:444] bn5c_branch2b <- res5c_branch2b
I0530 20:27:15.553105 26136 net.cpp:405] bn5c_branch2b -> res5c_branch2b (in-place)
I0530 20:27:15.553344 26136 net.cpp:150] Setting up bn5c_branch2b
I0530 20:27:15.553350 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.553354 26136 net.cpp:165] Memory required for data: 257503244
I0530 20:27:15.553375 26136 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0530 20:27:15.553391 26136 net.cpp:100] Creating Layer scale5c_branch2b
I0530 20:27:15.553400 26136 net.cpp:444] scale5c_branch2b <- res5c_branch2b
I0530 20:27:15.553416 26136 net.cpp:405] scale5c_branch2b -> res5c_branch2b (in-place)
I0530 20:27:15.553478 26136 layer_factory.hpp:77] Creating layer scale5c_branch2b
I0530 20:27:15.553623 26136 net.cpp:150] Setting up scale5c_branch2b
I0530 20:27:15.553632 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.553634 26136 net.cpp:165] Memory required for data: 257904652
I0530 20:27:15.553648 26136 layer_factory.hpp:77] Creating layer res5c_branch2b_relu
I0530 20:27:15.553663 26136 net.cpp:100] Creating Layer res5c_branch2b_relu
I0530 20:27:15.553669 26136 net.cpp:444] res5c_branch2b_relu <- res5c_branch2b
I0530 20:27:15.553685 26136 net.cpp:405] res5c_branch2b_relu -> res5c_branch2b (in-place)
I0530 20:27:15.553900 26136 net.cpp:150] Setting up res5c_branch2b_relu
I0530 20:27:15.553907 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:15.553911 26136 net.cpp:165] Memory required for data: 258306060
I0530 20:27:15.553917 26136 layer_factory.hpp:77] Creating layer res5c_branch2c
I0530 20:27:15.553936 26136 net.cpp:100] Creating Layer res5c_branch2c
I0530 20:27:15.553943 26136 net.cpp:444] res5c_branch2c <- res5c_branch2b
I0530 20:27:15.553962 26136 net.cpp:418] res5c_branch2c -> res5c_branch2c
I0530 20:27:15.557515 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 7800
I0530 20:27:15.557554 26136 net.cpp:150] Setting up res5c_branch2c
I0530 20:27:15.557571 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.557575 26136 net.cpp:165] Memory required for data: 259911692
I0530 20:27:15.557598 26136 layer_factory.hpp:77] Creating layer bn5c_branch2c
I0530 20:27:15.557626 26136 net.cpp:100] Creating Layer bn5c_branch2c
I0530 20:27:15.557637 26136 net.cpp:444] bn5c_branch2c <- res5c_branch2c
I0530 20:27:15.557657 26136 net.cpp:405] bn5c_branch2c -> res5c_branch2c (in-place)
I0530 20:27:15.557875 26136 net.cpp:150] Setting up bn5c_branch2c
I0530 20:27:15.557883 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.557886 26136 net.cpp:165] Memory required for data: 261517324
I0530 20:27:15.557905 26136 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0530 20:27:15.557922 26136 net.cpp:100] Creating Layer scale5c_branch2c
I0530 20:27:15.557929 26136 net.cpp:444] scale5c_branch2c <- res5c_branch2c
I0530 20:27:15.557945 26136 net.cpp:405] scale5c_branch2c -> res5c_branch2c (in-place)
I0530 20:27:15.558003 26136 layer_factory.hpp:77] Creating layer scale5c_branch2c
I0530 20:27:15.558147 26136 net.cpp:150] Setting up scale5c_branch2c
I0530 20:27:15.558154 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.558158 26136 net.cpp:165] Memory required for data: 263122956
I0530 20:27:15.558172 26136 layer_factory.hpp:77] Creating layer res5c
I0530 20:27:15.558187 26136 net.cpp:100] Creating Layer res5c
I0530 20:27:15.558193 26136 net.cpp:444] res5c <- res5b_res5b_relu_0_split_1
I0530 20:27:15.558205 26136 net.cpp:444] res5c <- res5c_branch2c
I0530 20:27:15.558218 26136 net.cpp:418] res5c -> res5c
I0530 20:27:15.558257 26136 net.cpp:150] Setting up res5c
I0530 20:27:15.558266 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.558270 26136 net.cpp:165] Memory required for data: 264728588
I0530 20:27:15.558275 26136 layer_factory.hpp:77] Creating layer res5c_relu
I0530 20:27:15.558290 26136 net.cpp:100] Creating Layer res5c_relu
I0530 20:27:15.558295 26136 net.cpp:444] res5c_relu <- res5c
I0530 20:27:15.558310 26136 net.cpp:405] res5c_relu -> res5c (in-place)
I0530 20:27:15.558459 26136 net.cpp:150] Setting up res5c_relu
I0530 20:27:15.558466 26136 net.cpp:157] Top shape: 1 2048 14 14 (401408)
I0530 20:27:15.558470 26136 net.cpp:165] Memory required for data: 266334220
I0530 20:27:15.558475 26136 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0530 20:27:15.558497 26136 net.cpp:100] Creating Layer rpn_conv/3x3
I0530 20:27:15.558504 26136 net.cpp:444] rpn_conv/3x3 <- res4f_res4f_relu_0_split_2
I0530 20:27:15.558522 26136 net.cpp:418] rpn_conv/3x3 -> rpn/output
I0530 20:27:16.086249 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 21676032
I0530 20:27:16.086688 26136 net.cpp:150] Setting up rpn_conv/3x3
I0530 20:27:16.086714 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:16.086737 26136 net.cpp:165] Memory required for data: 266735628
I0530 20:27:16.086778 26136 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0530 20:27:16.086823 26136 net.cpp:100] Creating Layer rpn_relu/3x3
I0530 20:27:16.086839 26136 net.cpp:444] rpn_relu/3x3 <- rpn/output
I0530 20:27:16.086879 26136 net.cpp:405] rpn_relu/3x3 -> rpn/output (in-place)
I0530 20:27:16.087406 26136 net.cpp:150] Setting up rpn_relu/3x3
I0530 20:27:16.087440 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:16.087445 26136 net.cpp:165] Memory required for data: 267137036
I0530 20:27:16.087453 26136 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0530 20:27:16.087473 26136 net.cpp:100] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0530 20:27:16.087484 26136 net.cpp:444] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0530 20:27:16.087503 26136 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0530 20:27:16.087528 26136 net.cpp:418] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0530 20:27:16.087625 26136 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0530 20:27:16.087636 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:16.087642 26136 net.cpp:157] Top shape: 1 512 14 14 (100352)
I0530 20:27:16.087646 26136 net.cpp:165] Memory required for data: 267939852
I0530 20:27:16.087651 26136 layer_factory.hpp:77] Creating layer rpn_cls_score
I0530 20:27:16.087693 26136 net.cpp:100] Creating Layer rpn_cls_score
I0530 20:27:16.087700 26136 net.cpp:444] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0530 20:27:16.087720 26136 net.cpp:418] rpn_cls_score -> rpn_cls_score
I0530 20:27:16.090265 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:16.090306 26136 net.cpp:150] Setting up rpn_cls_score
I0530 20:27:16.090324 26136 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0530 20:27:16.090328 26136 net.cpp:165] Memory required for data: 267957100
I0530 20:27:16.090355 26136 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0530 20:27:16.090394 26136 net.cpp:100] Creating Layer rpn_bbox_pred
I0530 20:27:16.090406 26136 net.cpp:444] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0530 20:27:16.090430 26136 net.cpp:418] rpn_bbox_pred -> rpn_bbox_pred
I0530 20:27:16.093948 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:16.093976 26136 net.cpp:150] Setting up rpn_bbox_pred
I0530 20:27:16.093986 26136 net.cpp:157] Top shape: 1 44 14 14 (8624)
I0530 20:27:16.093988 26136 net.cpp:165] Memory required for data: 267991596
I0530 20:27:16.094003 26136 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0530 20:27:16.094022 26136 net.cpp:100] Creating Layer rpn_cls_score_reshape
I0530 20:27:16.094028 26136 net.cpp:444] rpn_cls_score_reshape <- rpn_cls_score
I0530 20:27:16.094046 26136 net.cpp:418] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0530 20:27:16.094091 26136 net.cpp:150] Setting up rpn_cls_score_reshape
I0530 20:27:16.094100 26136 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0530 20:27:16.094105 26136 net.cpp:165] Memory required for data: 268008844
I0530 20:27:16.094110 26136 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0530 20:27:16.094123 26136 net.cpp:100] Creating Layer rpn_cls_prob
I0530 20:27:16.094130 26136 net.cpp:444] rpn_cls_prob <- rpn_cls_score_reshape
I0530 20:27:16.094146 26136 net.cpp:418] rpn_cls_prob -> rpn_cls_prob
I0530 20:27:16.094391 26136 net.cpp:150] Setting up rpn_cls_prob
I0530 20:27:16.094403 26136 net.cpp:157] Top shape: 1 2 154 14 (4312)
I0530 20:27:16.094406 26136 net.cpp:165] Memory required for data: 268026092
I0530 20:27:16.094411 26136 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0530 20:27:16.094425 26136 net.cpp:100] Creating Layer rpn_cls_prob_reshape
I0530 20:27:16.094432 26136 net.cpp:444] rpn_cls_prob_reshape <- rpn_cls_prob
I0530 20:27:16.094449 26136 net.cpp:418] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0530 20:27:16.094486 26136 net.cpp:150] Setting up rpn_cls_prob_reshape
I0530 20:27:16.094496 26136 net.cpp:157] Top shape: 1 22 14 14 (4312)
I0530 20:27:16.094499 26136 net.cpp:165] Memory required for data: 268043340
I0530 20:27:16.094504 26136 layer_factory.hpp:77] Creating layer proposal
I0530 20:27:16.094821 26136 net.cpp:100] Creating Layer proposal
I0530 20:27:16.094832 26136 net.cpp:444] proposal <- rpn_cls_prob_reshape
I0530 20:27:16.094846 26136 net.cpp:444] proposal <- rpn_bbox_pred
I0530 20:27:16.094854 26136 net.cpp:444] proposal <- im_info
I0530 20:27:16.094867 26136 net.cpp:418] proposal -> rois
I0530 20:27:16.095989 26136 net.cpp:150] Setting up proposal
I0530 20:27:16.096002 26136 net.cpp:157] Top shape: 1 5 (5)
I0530 20:27:16.096007 26136 net.cpp:165] Memory required for data: 268043360
I0530 20:27:16.096014 26136 layer_factory.hpp:77] Creating layer rois_proposal_0_split
I0530 20:27:16.096027 26136 net.cpp:100] Creating Layer rois_proposal_0_split
I0530 20:27:16.096035 26136 net.cpp:444] rois_proposal_0_split <- rois
I0530 20:27:16.096050 26136 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_0
I0530 20:27:16.096068 26136 net.cpp:418] rois_proposal_0_split -> rois_proposal_0_split_1
I0530 20:27:16.096117 26136 net.cpp:150] Setting up rois_proposal_0_split
I0530 20:27:16.096127 26136 net.cpp:157] Top shape: 1 5 (5)
I0530 20:27:16.096132 26136 net.cpp:157] Top shape: 1 5 (5)
I0530 20:27:16.096137 26136 net.cpp:165] Memory required for data: 268043400
I0530 20:27:16.096141 26136 layer_factory.hpp:77] Creating layer conv_new_1
I0530 20:27:16.096159 26136 net.cpp:100] Creating Layer conv_new_1
I0530 20:27:16.096166 26136 net.cpp:444] conv_new_1 <- res5c
I0530 20:27:16.096184 26136 net.cpp:418] conv_new_1 -> conv_new_1
I0530 20:27:16.331557 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:16.331594 26136 net.cpp:150] Setting up conv_new_1
I0530 20:27:16.331612 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:16.331615 26136 net.cpp:165] Memory required for data: 268846216
I0530 20:27:16.331640 26136 layer_factory.hpp:77] Creating layer conv_new_1_relu
I0530 20:27:16.331663 26136 net.cpp:100] Creating Layer conv_new_1_relu
I0530 20:27:16.331674 26136 net.cpp:444] conv_new_1_relu <- conv_new_1
I0530 20:27:16.331693 26136 net.cpp:405] conv_new_1_relu -> conv_new_1 (in-place)
I0530 20:27:16.331856 26136 net.cpp:150] Setting up conv_new_1_relu
I0530 20:27:16.331866 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:16.331871 26136 net.cpp:165] Memory required for data: 269649032
I0530 20:27:16.331876 26136 layer_factory.hpp:77] Creating layer conv_new_1_conv_new_1_relu_0_split
I0530 20:27:16.331887 26136 net.cpp:100] Creating Layer conv_new_1_conv_new_1_relu_0_split
I0530 20:27:16.331890 26136 net.cpp:444] conv_new_1_conv_new_1_relu_0_split <- conv_new_1
I0530 20:27:16.331903 26136 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_0
I0530 20:27:16.331918 26136 net.cpp:418] conv_new_1_conv_new_1_relu_0_split -> conv_new_1_conv_new_1_relu_0_split_1
I0530 20:27:16.331979 26136 net.cpp:150] Setting up conv_new_1_conv_new_1_relu_0_split
I0530 20:27:16.331989 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:16.331995 26136 net.cpp:157] Top shape: 1 1024 14 14 (200704)
I0530 20:27:16.331998 26136 net.cpp:165] Memory required for data: 271254664
I0530 20:27:16.332003 26136 layer_factory.hpp:77] Creating layer rfcn_cls
I0530 20:27:16.332024 26136 net.cpp:100] Creating Layer rfcn_cls
I0530 20:27:16.332032 26136 net.cpp:444] rfcn_cls <- conv_new_1_conv_new_1_relu_0_split_0
I0530 20:27:16.332051 26136 net.cpp:418] rfcn_cls -> rfcn_cls
I0530 20:27:16.344354 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:16.344390 26136 net.cpp:150] Setting up rfcn_cls
I0530 20:27:16.344413 26136 net.cpp:157] Top shape: 1 98 14 14 (19208)
I0530 20:27:16.344425 26136 net.cpp:165] Memory required for data: 271331496
I0530 20:27:16.344446 26136 layer_factory.hpp:77] Creating layer rfcn_bbox
I0530 20:27:16.344502 26136 net.cpp:100] Creating Layer rfcn_bbox
I0530 20:27:16.344512 26136 net.cpp:444] rfcn_bbox <- conv_new_1_conv_new_1_relu_0_split_1
I0530 20:27:16.344537 26136 net.cpp:418] rfcn_bbox -> rfcn_bbox
I0530 20:27:16.390916 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 10080
I0530 20:27:16.390955 26136 net.cpp:150] Setting up rfcn_bbox
I0530 20:27:16.390972 26136 net.cpp:157] Top shape: 1 392 14 14 (76832)
I0530 20:27:16.390975 26136 net.cpp:165] Memory required for data: 271638824
I0530 20:27:16.391000 26136 layer_factory.hpp:77] Creating layer psroipooled_cls_rois
I0530 20:27:16.391026 26136 net.cpp:100] Creating Layer psroipooled_cls_rois
I0530 20:27:16.391037 26136 net.cpp:444] psroipooled_cls_rois <- rfcn_cls
I0530 20:27:16.391053 26136 net.cpp:444] psroipooled_cls_rois <- rois_proposal_0_split_0
I0530 20:27:16.391068 26136 net.cpp:418] psroipooled_cls_rois -> psroipooled_cls_rois
I0530 20:27:16.391091 26136 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0530 20:27:16.391149 26136 net.cpp:150] Setting up psroipooled_cls_rois
I0530 20:27:16.391157 26136 net.cpp:157] Top shape: 1 2 7 7 (98)
I0530 20:27:16.391160 26136 net.cpp:165] Memory required for data: 271639216
I0530 20:27:16.391165 26136 layer_factory.hpp:77] Creating layer ave_cls_score_rois
I0530 20:27:16.391180 26136 net.cpp:100] Creating Layer ave_cls_score_rois
I0530 20:27:16.391187 26136 net.cpp:444] ave_cls_score_rois <- psroipooled_cls_rois
I0530 20:27:16.391203 26136 net.cpp:418] ave_cls_score_rois -> cls_score
I0530 20:27:16.391657 26136 net.cpp:150] Setting up ave_cls_score_rois
I0530 20:27:16.391669 26136 net.cpp:157] Top shape: 1 2 1 1 (2)
I0530 20:27:16.391674 26136 net.cpp:165] Memory required for data: 271639224
I0530 20:27:16.391680 26136 layer_factory.hpp:77] Creating layer psroipooled_loc_rois
I0530 20:27:16.391691 26136 net.cpp:100] Creating Layer psroipooled_loc_rois
I0530 20:27:16.391700 26136 net.cpp:444] psroipooled_loc_rois <- rfcn_bbox
I0530 20:27:16.391711 26136 net.cpp:444] psroipooled_loc_rois <- rois_proposal_0_split_1
I0530 20:27:16.391727 26136 net.cpp:418] psroipooled_loc_rois -> psroipooled_loc_rois
I0530 20:27:16.391744 26136 psroi_pooling_layer.cpp:26] Spatial scale: 0.0625
I0530 20:27:16.391789 26136 net.cpp:150] Setting up psroipooled_loc_rois
I0530 20:27:16.391799 26136 net.cpp:157] Top shape: 1 8 7 7 (392)
I0530 20:27:16.391803 26136 net.cpp:165] Memory required for data: 271640792
I0530 20:27:16.391808 26136 layer_factory.hpp:77] Creating layer ave_bbox_pred_rois
I0530 20:27:16.391820 26136 net.cpp:100] Creating Layer ave_bbox_pred_rois
I0530 20:27:16.391827 26136 net.cpp:444] ave_bbox_pred_rois <- psroipooled_loc_rois
I0530 20:27:16.391844 26136 net.cpp:418] ave_bbox_pred_rois -> bbox_pred_pre
I0530 20:27:16.392016 26136 net.cpp:150] Setting up ave_bbox_pred_rois
I0530 20:27:16.392026 26136 net.cpp:157] Top shape: 1 8 1 1 (8)
I0530 20:27:16.392030 26136 net.cpp:165] Memory required for data: 271640824
I0530 20:27:16.392035 26136 layer_factory.hpp:77] Creating layer cls_prob
I0530 20:27:16.392050 26136 net.cpp:100] Creating Layer cls_prob
I0530 20:27:16.392056 26136 net.cpp:444] cls_prob <- cls_score
I0530 20:27:16.392069 26136 net.cpp:418] cls_prob -> cls_prob_pre
I0530 20:27:16.392280 26136 net.cpp:150] Setting up cls_prob
I0530 20:27:16.392290 26136 net.cpp:157] Top shape: 1 2 1 1 (2)
I0530 20:27:16.392294 26136 net.cpp:165] Memory required for data: 271640832
I0530 20:27:16.392300 26136 layer_factory.hpp:77] Creating layer cls_prob_reshape
I0530 20:27:16.392315 26136 net.cpp:100] Creating Layer cls_prob_reshape
I0530 20:27:16.392323 26136 net.cpp:444] cls_prob_reshape <- cls_prob_pre
I0530 20:27:16.392338 26136 net.cpp:418] cls_prob_reshape -> cls_prob
I0530 20:27:16.392379 26136 net.cpp:150] Setting up cls_prob_reshape
I0530 20:27:16.392387 26136 net.cpp:157] Top shape: 1 2 (2)
I0530 20:27:16.392391 26136 net.cpp:165] Memory required for data: 271640840
I0530 20:27:16.392395 26136 layer_factory.hpp:77] Creating layer bbox_pred_reshape
I0530 20:27:16.392407 26136 net.cpp:100] Creating Layer bbox_pred_reshape
I0530 20:27:16.392415 26136 net.cpp:444] bbox_pred_reshape <- bbox_pred_pre
I0530 20:27:16.392431 26136 net.cpp:418] bbox_pred_reshape -> bbox_pred
I0530 20:27:16.392467 26136 net.cpp:150] Setting up bbox_pred_reshape
I0530 20:27:16.392474 26136 net.cpp:157] Top shape: 1 8 (8)
I0530 20:27:16.392478 26136 net.cpp:165] Memory required for data: 271640872
I0530 20:27:16.392484 26136 net.cpp:228] bbox_pred_reshape does not need backward computation.
I0530 20:27:16.392490 26136 net.cpp:228] cls_prob_reshape does not need backward computation.
I0530 20:27:16.392495 26136 net.cpp:228] cls_prob does not need backward computation.
I0530 20:27:16.392500 26136 net.cpp:228] ave_bbox_pred_rois does not need backward computation.
I0530 20:27:16.392506 26136 net.cpp:228] psroipooled_loc_rois does not need backward computation.
I0530 20:27:16.392513 26136 net.cpp:228] ave_cls_score_rois does not need backward computation.
I0530 20:27:16.392518 26136 net.cpp:228] psroipooled_cls_rois does not need backward computation.
I0530 20:27:16.392525 26136 net.cpp:228] rfcn_bbox does not need backward computation.
I0530 20:27:16.392530 26136 net.cpp:228] rfcn_cls does not need backward computation.
I0530 20:27:16.392536 26136 net.cpp:228] conv_new_1_conv_new_1_relu_0_split does not need backward computation.
I0530 20:27:16.392542 26136 net.cpp:228] conv_new_1_relu does not need backward computation.
I0530 20:27:16.392547 26136 net.cpp:228] conv_new_1 does not need backward computation.
I0530 20:27:16.392554 26136 net.cpp:228] rois_proposal_0_split does not need backward computation.
I0530 20:27:16.392560 26136 net.cpp:228] proposal does not need backward computation.
I0530 20:27:16.392566 26136 net.cpp:228] rpn_cls_prob_reshape does not need backward computation.
I0530 20:27:16.392571 26136 net.cpp:228] rpn_cls_prob does not need backward computation.
I0530 20:27:16.392576 26136 net.cpp:228] rpn_cls_score_reshape does not need backward computation.
I0530 20:27:16.392582 26136 net.cpp:228] rpn_bbox_pred does not need backward computation.
I0530 20:27:16.392587 26136 net.cpp:228] rpn_cls_score does not need backward computation.
I0530 20:27:16.392593 26136 net.cpp:228] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0530 20:27:16.392599 26136 net.cpp:228] rpn_relu/3x3 does not need backward computation.
I0530 20:27:16.392604 26136 net.cpp:228] rpn_conv/3x3 does not need backward computation.
I0530 20:27:16.392611 26136 net.cpp:228] res5c_relu does not need backward computation.
I0530 20:27:16.392616 26136 net.cpp:228] res5c does not need backward computation.
I0530 20:27:16.392623 26136 net.cpp:228] scale5c_branch2c does not need backward computation.
I0530 20:27:16.392627 26136 net.cpp:228] bn5c_branch2c does not need backward computation.
I0530 20:27:16.392632 26136 net.cpp:228] res5c_branch2c does not need backward computation.
I0530 20:27:16.392638 26136 net.cpp:228] res5c_branch2b_relu does not need backward computation.
I0530 20:27:16.392643 26136 net.cpp:228] scale5c_branch2b does not need backward computation.
I0530 20:27:16.392648 26136 net.cpp:228] bn5c_branch2b does not need backward computation.
I0530 20:27:16.392653 26136 net.cpp:228] res5c_branch2b does not need backward computation.
I0530 20:27:16.392659 26136 net.cpp:228] res5c_branch2a_relu does not need backward computation.
I0530 20:27:16.392664 26136 net.cpp:228] scale5c_branch2a does not need backward computation.
I0530 20:27:16.392669 26136 net.cpp:228] bn5c_branch2a does not need backward computation.
I0530 20:27:16.392674 26136 net.cpp:228] res5c_branch2a does not need backward computation.
I0530 20:27:16.392681 26136 net.cpp:228] res5b_res5b_relu_0_split does not need backward computation.
I0530 20:27:16.392686 26136 net.cpp:228] res5b_relu does not need backward computation.
I0530 20:27:16.392691 26136 net.cpp:228] res5b does not need backward computation.
I0530 20:27:16.392699 26136 net.cpp:228] scale5b_branch2c does not need backward computation.
I0530 20:27:16.392702 26136 net.cpp:228] bn5b_branch2c does not need backward computation.
I0530 20:27:16.392707 26136 net.cpp:228] res5b_branch2c does not need backward computation.
I0530 20:27:16.392714 26136 net.cpp:228] res5b_branch2b_relu does not need backward computation.
I0530 20:27:16.392719 26136 net.cpp:228] scale5b_branch2b does not need backward computation.
I0530 20:27:16.392724 26136 net.cpp:228] bn5b_branch2b does not need backward computation.
I0530 20:27:16.392729 26136 net.cpp:228] res5b_branch2b does not need backward computation.
I0530 20:27:16.392733 26136 net.cpp:228] res5b_branch2a_relu does not need backward computation.
I0530 20:27:16.392738 26136 net.cpp:228] scale5b_branch2a does not need backward computation.
I0530 20:27:16.392745 26136 net.cpp:228] bn5b_branch2a does not need backward computation.
I0530 20:27:16.392750 26136 net.cpp:228] res5b_branch2a does not need backward computation.
I0530 20:27:16.392756 26136 net.cpp:228] res5a_res5a_relu_0_split does not need backward computation.
I0530 20:27:16.392761 26136 net.cpp:228] res5a_relu does not need backward computation.
I0530 20:27:16.392766 26136 net.cpp:228] res5a does not need backward computation.
I0530 20:27:16.392772 26136 net.cpp:228] scale5a_branch2c does not need backward computation.
I0530 20:27:16.392777 26136 net.cpp:228] bn5a_branch2c does not need backward computation.
I0530 20:27:16.392782 26136 net.cpp:228] res5a_branch2c does not need backward computation.
I0530 20:27:16.392788 26136 net.cpp:228] res5a_branch2b_relu does not need backward computation.
I0530 20:27:16.392793 26136 net.cpp:228] scale5a_branch2b does not need backward computation.
I0530 20:27:16.392798 26136 net.cpp:228] bn5a_branch2b does not need backward computation.
I0530 20:27:16.392803 26136 net.cpp:228] res5a_branch2b does not need backward computation.
I0530 20:27:16.392808 26136 net.cpp:228] res5a_branch2a_relu does not need backward computation.
I0530 20:27:16.392814 26136 net.cpp:228] scale5a_branch2a does not need backward computation.
I0530 20:27:16.392818 26136 net.cpp:228] bn5a_branch2a does not need backward computation.
I0530 20:27:16.392823 26136 net.cpp:228] res5a_branch2a does not need backward computation.
I0530 20:27:16.392830 26136 net.cpp:228] scale5a_branch1 does not need backward computation.
I0530 20:27:16.392835 26136 net.cpp:228] bn5a_branch1 does not need backward computation.
I0530 20:27:16.392840 26136 net.cpp:228] res5a_branch1 does not need backward computation.
I0530 20:27:16.392848 26136 net.cpp:228] res4f_res4f_relu_0_split does not need backward computation.
I0530 20:27:16.392853 26136 net.cpp:228] res4f_relu does not need backward computation.
I0530 20:27:16.392858 26136 net.cpp:228] res4f does not need backward computation.
I0530 20:27:16.392864 26136 net.cpp:228] scale4f_branch2c does not need backward computation.
I0530 20:27:16.392869 26136 net.cpp:228] bn4f_branch2c does not need backward computation.
I0530 20:27:16.392874 26136 net.cpp:228] res4f_branch2c does not need backward computation.
I0530 20:27:16.392880 26136 net.cpp:228] res4f_branch2b_relu does not need backward computation.
I0530 20:27:16.392885 26136 net.cpp:228] scale4f_branch2b does not need backward computation.
I0530 20:27:16.392890 26136 net.cpp:228] bn4f_branch2b does not need backward computation.
I0530 20:27:16.392895 26136 net.cpp:228] res4f_branch2b does not need backward computation.
I0530 20:27:16.392901 26136 net.cpp:228] res4f_branch2a_relu does not need backward computation.
I0530 20:27:16.392906 26136 net.cpp:228] scale4f_branch2a does not need backward computation.
I0530 20:27:16.392915 26136 net.cpp:228] bn4f_branch2a does not need backward computation.
I0530 20:27:16.392920 26136 net.cpp:228] res4f_branch2a does not need backward computation.
I0530 20:27:16.392925 26136 net.cpp:228] res4e_res4e_relu_0_split does not need backward computation.
I0530 20:27:16.392932 26136 net.cpp:228] res4e_relu does not need backward computation.
I0530 20:27:16.392936 26136 net.cpp:228] res4e does not need backward computation.
I0530 20:27:16.392941 26136 net.cpp:228] scale4e_branch2c does not need backward computation.
I0530 20:27:16.392944 26136 net.cpp:228] bn4e_branch2c does not need backward computation.
I0530 20:27:16.392948 26136 net.cpp:228] res4e_branch2c does not need backward computation.
I0530 20:27:16.392953 26136 net.cpp:228] res4e_branch2b_relu does not need backward computation.
I0530 20:27:16.392958 26136 net.cpp:228] scale4e_branch2b does not need backward computation.
I0530 20:27:16.392962 26136 net.cpp:228] bn4e_branch2b does not need backward computation.
I0530 20:27:16.392966 26136 net.cpp:228] res4e_branch2b does not need backward computation.
I0530 20:27:16.392971 26136 net.cpp:228] res4e_branch2a_relu does not need backward computation.
I0530 20:27:16.392976 26136 net.cpp:228] scale4e_branch2a does not need backward computation.
I0530 20:27:16.392980 26136 net.cpp:228] bn4e_branch2a does not need backward computation.
I0530 20:27:16.392984 26136 net.cpp:228] res4e_branch2a does not need backward computation.
I0530 20:27:16.392990 26136 net.cpp:228] res4d_res4d_relu_0_split does not need backward computation.
I0530 20:27:16.392995 26136 net.cpp:228] res4d_relu does not need backward computation.
I0530 20:27:16.393000 26136 net.cpp:228] res4d does not need backward computation.
I0530 20:27:16.393007 26136 net.cpp:228] scale4d_branch2c does not need backward computation.
I0530 20:27:16.393012 26136 net.cpp:228] bn4d_branch2c does not need backward computation.
I0530 20:27:16.393016 26136 net.cpp:228] res4d_branch2c does not need backward computation.
I0530 20:27:16.393020 26136 net.cpp:228] res4d_branch2b_relu does not need backward computation.
I0530 20:27:16.393024 26136 net.cpp:228] scale4d_branch2b does not need backward computation.
I0530 20:27:16.393029 26136 net.cpp:228] bn4d_branch2b does not need backward computation.
I0530 20:27:16.393034 26136 net.cpp:228] res4d_branch2b does not need backward computation.
I0530 20:27:16.393038 26136 net.cpp:228] res4d_branch2a_relu does not need backward computation.
I0530 20:27:16.393043 26136 net.cpp:228] scale4d_branch2a does not need backward computation.
I0530 20:27:16.393048 26136 net.cpp:228] bn4d_branch2a does not need backward computation.
I0530 20:27:16.393052 26136 net.cpp:228] res4d_branch2a does not need backward computation.
I0530 20:27:16.393057 26136 net.cpp:228] res4c_res4c_relu_0_split does not need backward computation.
I0530 20:27:16.393062 26136 net.cpp:228] res4c_relu does not need backward computation.
I0530 20:27:16.393066 26136 net.cpp:228] res4c does not need backward computation.
I0530 20:27:16.393074 26136 net.cpp:228] scale4c_branch2c does not need backward computation.
I0530 20:27:16.393079 26136 net.cpp:228] bn4c_branch2c does not need backward computation.
I0530 20:27:16.393082 26136 net.cpp:228] res4c_branch2c does not need backward computation.
I0530 20:27:16.393087 26136 net.cpp:228] res4c_branch2b_relu does not need backward computation.
I0530 20:27:16.393092 26136 net.cpp:228] scale4c_branch2b does not need backward computation.
I0530 20:27:16.393096 26136 net.cpp:228] bn4c_branch2b does not need backward computation.
I0530 20:27:16.393100 26136 net.cpp:228] res4c_branch2b does not need backward computation.
I0530 20:27:16.393105 26136 net.cpp:228] res4c_branch2a_relu does not need backward computation.
I0530 20:27:16.393110 26136 net.cpp:228] scale4c_branch2a does not need backward computation.
I0530 20:27:16.393115 26136 net.cpp:228] bn4c_branch2a does not need backward computation.
I0530 20:27:16.393119 26136 net.cpp:228] res4c_branch2a does not need backward computation.
I0530 20:27:16.393124 26136 net.cpp:228] res4b_res4b_relu_0_split does not need backward computation.
I0530 20:27:16.393131 26136 net.cpp:228] res4b_relu does not need backward computation.
I0530 20:27:16.393134 26136 net.cpp:228] res4b does not need backward computation.
I0530 20:27:16.393142 26136 net.cpp:228] scale4b_branch2c does not need backward computation.
I0530 20:27:16.393147 26136 net.cpp:228] bn4b_branch2c does not need backward computation.
I0530 20:27:16.393152 26136 net.cpp:228] res4b_branch2c does not need backward computation.
I0530 20:27:16.393157 26136 net.cpp:228] res4b_branch2b_relu does not need backward computation.
I0530 20:27:16.393162 26136 net.cpp:228] scale4b_branch2b does not need backward computation.
I0530 20:27:16.393167 26136 net.cpp:228] bn4b_branch2b does not need backward computation.
I0530 20:27:16.393170 26136 net.cpp:228] res4b_branch2b does not need backward computation.
I0530 20:27:16.393175 26136 net.cpp:228] res4b_branch2a_relu does not need backward computation.
I0530 20:27:16.393180 26136 net.cpp:228] scale4b_branch2a does not need backward computation.
I0530 20:27:16.393184 26136 net.cpp:228] bn4b_branch2a does not need backward computation.
I0530 20:27:16.393189 26136 net.cpp:228] res4b_branch2a does not need backward computation.
I0530 20:27:16.393194 26136 net.cpp:228] res4a_res4a_relu_0_split does not need backward computation.
I0530 20:27:16.393199 26136 net.cpp:228] res4a_relu does not need backward computation.
I0530 20:27:16.393204 26136 net.cpp:228] res4a does not need backward computation.
I0530 20:27:16.393211 26136 net.cpp:228] scale4a_branch2c does not need backward computation.
I0530 20:27:16.393215 26136 net.cpp:228] bn4a_branch2c does not need backward computation.
I0530 20:27:16.393220 26136 net.cpp:228] res4a_branch2c does not need backward computation.
I0530 20:27:16.393225 26136 net.cpp:228] res4a_branch2b_relu does not need backward computation.
I0530 20:27:16.393230 26136 net.cpp:228] scale4a_branch2b does not need backward computation.
I0530 20:27:16.393235 26136 net.cpp:228] bn4a_branch2b does not need backward computation.
I0530 20:27:16.393239 26136 net.cpp:228] res4a_branch2b does not need backward computation.
I0530 20:27:16.393244 26136 net.cpp:228] res4a_branch2a_relu does not need backward computation.
I0530 20:27:16.393249 26136 net.cpp:228] scale4a_branch2a does not need backward computation.
I0530 20:27:16.393254 26136 net.cpp:228] bn4a_branch2a does not need backward computation.
I0530 20:27:16.393259 26136 net.cpp:228] res4a_branch2a does not need backward computation.
I0530 20:27:16.393263 26136 net.cpp:228] scale4a_branch1 does not need backward computation.
I0530 20:27:16.393268 26136 net.cpp:228] bn4a_branch1 does not need backward computation.
I0530 20:27:16.393273 26136 net.cpp:228] res4a_branch1 does not need backward computation.
I0530 20:27:16.393280 26136 net.cpp:228] res3d_res3d_relu_0_split does not need backward computation.
I0530 20:27:16.393285 26136 net.cpp:228] res3d_relu does not need backward computation.
I0530 20:27:16.393290 26136 net.cpp:228] res3d does not need backward computation.
I0530 20:27:16.393296 26136 net.cpp:228] scale3d_branch2c does not need backward computation.
I0530 20:27:16.393301 26136 net.cpp:228] bn3d_branch2c does not need backward computation.
I0530 20:27:16.393306 26136 net.cpp:228] res3d_branch2c does not need backward computation.
I0530 20:27:16.393311 26136 net.cpp:228] res3d_branch2b_relu does not need backward computation.
I0530 20:27:16.393314 26136 net.cpp:228] scale3d_branch2b does not need backward computation.
I0530 20:27:16.393319 26136 net.cpp:228] bn3d_branch2b does not need backward computation.
I0530 20:27:16.393323 26136 net.cpp:228] res3d_branch2b does not need backward computation.
I0530 20:27:16.393329 26136 net.cpp:228] res3d_branch2a_relu does not need backward computation.
I0530 20:27:16.393333 26136 net.cpp:228] scale3d_branch2a does not need backward computation.
I0530 20:27:16.393338 26136 net.cpp:228] bn3d_branch2a does not need backward computation.
I0530 20:27:16.393342 26136 net.cpp:228] res3d_branch2a does not need backward computation.
I0530 20:27:16.393348 26136 net.cpp:228] res3c_res3c_relu_0_split does not need backward computation.
I0530 20:27:16.393353 26136 net.cpp:228] res3c_relu does not need backward computation.
I0530 20:27:16.393357 26136 net.cpp:228] res3c does not need backward computation.
I0530 20:27:16.393363 26136 net.cpp:228] scale3c_branch2c does not need backward computation.
I0530 20:27:16.393368 26136 net.cpp:228] bn3c_branch2c does not need backward computation.
I0530 20:27:16.393373 26136 net.cpp:228] res3c_branch2c does not need backward computation.
I0530 20:27:16.393378 26136 net.cpp:228] res3c_branch2b_relu does not need backward computation.
I0530 20:27:16.393383 26136 net.cpp:228] scale3c_branch2b does not need backward computation.
I0530 20:27:16.393388 26136 net.cpp:228] bn3c_branch2b does not need backward computation.
I0530 20:27:16.393393 26136 net.cpp:228] res3c_branch2b does not need backward computation.
I0530 20:27:16.393398 26136 net.cpp:228] res3c_branch2a_relu does not need backward computation.
I0530 20:27:16.393401 26136 net.cpp:228] scale3c_branch2a does not need backward computation.
I0530 20:27:16.393406 26136 net.cpp:228] bn3c_branch2a does not need backward computation.
I0530 20:27:16.393410 26136 net.cpp:228] res3c_branch2a does not need backward computation.
I0530 20:27:16.393416 26136 net.cpp:228] res3b_res3b_relu_0_split does not need backward computation.
I0530 20:27:16.393424 26136 net.cpp:228] res3b_relu does not need backward computation.
I0530 20:27:16.393429 26136 net.cpp:228] res3b does not need backward computation.
I0530 20:27:16.393436 26136 net.cpp:228] scale3b_branch2c does not need backward computation.
I0530 20:27:16.393440 26136 net.cpp:228] bn3b_branch2c does not need backward computation.
I0530 20:27:16.393446 26136 net.cpp:228] res3b_branch2c does not need backward computation.
I0530 20:27:16.393451 26136 net.cpp:228] res3b_branch2b_relu does not need backward computation.
I0530 20:27:16.393456 26136 net.cpp:228] scale3b_branch2b does not need backward computation.
I0530 20:27:16.393461 26136 net.cpp:228] bn3b_branch2b does not need backward computation.
I0530 20:27:16.393465 26136 net.cpp:228] res3b_branch2b does not need backward computation.
I0530 20:27:16.393471 26136 net.cpp:228] res3b_branch2a_relu does not need backward computation.
I0530 20:27:16.393476 26136 net.cpp:228] scale3b_branch2a does not need backward computation.
I0530 20:27:16.393479 26136 net.cpp:228] bn3b_branch2a does not need backward computation.
I0530 20:27:16.393484 26136 net.cpp:228] res3b_branch2a does not need backward computation.
I0530 20:27:16.393491 26136 net.cpp:228] res3a_res3a_relu_0_split does not need backward computation.
I0530 20:27:16.393496 26136 net.cpp:228] res3a_relu does not need backward computation.
I0530 20:27:16.393501 26136 net.cpp:228] res3a does not need backward computation.
I0530 20:27:16.393507 26136 net.cpp:228] scale3a_branch2c does not need backward computation.
I0530 20:27:16.393512 26136 net.cpp:228] bn3a_branch2c does not need backward computation.
I0530 20:27:16.393517 26136 net.cpp:228] res3a_branch2c does not need backward computation.
I0530 20:27:16.393522 26136 net.cpp:228] res3a_branch2b_relu does not need backward computation.
I0530 20:27:16.393527 26136 net.cpp:228] scale3a_branch2b does not need backward computation.
I0530 20:27:16.393532 26136 net.cpp:228] bn3a_branch2b does not need backward computation.
I0530 20:27:16.393537 26136 net.cpp:228] res3a_branch2b does not need backward computation.
I0530 20:27:16.393541 26136 net.cpp:228] res3a_branch2a_relu does not need backward computation.
I0530 20:27:16.393546 26136 net.cpp:228] scale3a_branch2a does not need backward computation.
I0530 20:27:16.393551 26136 net.cpp:228] bn3a_branch2a does not need backward computation.
I0530 20:27:16.393555 26136 net.cpp:228] res3a_branch2a does not need backward computation.
I0530 20:27:16.393560 26136 net.cpp:228] scale3a_branch1 does not need backward computation.
I0530 20:27:16.393565 26136 net.cpp:228] bn3a_branch1 does not need backward computation.
I0530 20:27:16.393570 26136 net.cpp:228] res3a_branch1 does not need backward computation.
I0530 20:27:16.393576 26136 net.cpp:228] res2c_res2c_relu_0_split does not need backward computation.
I0530 20:27:16.393581 26136 net.cpp:228] res2c_relu does not need backward computation.
I0530 20:27:16.393585 26136 net.cpp:228] res2c does not need backward computation.
I0530 20:27:16.393592 26136 net.cpp:228] scale2c_branch2c does not need backward computation.
I0530 20:27:16.393597 26136 net.cpp:228] bn2c_branch2c does not need backward computation.
I0530 20:27:16.393601 26136 net.cpp:228] res2c_branch2c does not need backward computation.
I0530 20:27:16.393606 26136 net.cpp:228] res2c_branch2b_relu does not need backward computation.
I0530 20:27:16.393611 26136 net.cpp:228] scale2c_branch2b does not need backward computation.
I0530 20:27:16.393615 26136 net.cpp:228] bn2c_branch2b does not need backward computation.
I0530 20:27:16.393620 26136 net.cpp:228] res2c_branch2b does not need backward computation.
I0530 20:27:16.393625 26136 net.cpp:228] res2c_branch2a_relu does not need backward computation.
I0530 20:27:16.393630 26136 net.cpp:228] scale2c_branch2a does not need backward computation.
I0530 20:27:16.393635 26136 net.cpp:228] bn2c_branch2a does not need backward computation.
I0530 20:27:16.393638 26136 net.cpp:228] res2c_branch2a does not need backward computation.
I0530 20:27:16.393645 26136 net.cpp:228] res2b_res2b_relu_0_split does not need backward computation.
I0530 20:27:16.393651 26136 net.cpp:228] res2b_relu does not need backward computation.
I0530 20:27:16.393656 26136 net.cpp:228] res2b does not need backward computation.
I0530 20:27:16.393661 26136 net.cpp:228] scale2b_branch2c does not need backward computation.
I0530 20:27:16.393666 26136 net.cpp:228] bn2b_branch2c does not need backward computation.
I0530 20:27:16.393671 26136 net.cpp:228] res2b_branch2c does not need backward computation.
I0530 20:27:16.393676 26136 net.cpp:228] res2b_branch2b_relu does not need backward computation.
I0530 20:27:16.393681 26136 net.cpp:228] scale2b_branch2b does not need backward computation.
I0530 20:27:16.393685 26136 net.cpp:228] bn2b_branch2b does not need backward computation.
I0530 20:27:16.393689 26136 net.cpp:228] res2b_branch2b does not need backward computation.
I0530 20:27:16.393694 26136 net.cpp:228] res2b_branch2a_relu does not need backward computation.
I0530 20:27:16.393699 26136 net.cpp:228] scale2b_branch2a does not need backward computation.
I0530 20:27:16.393703 26136 net.cpp:228] bn2b_branch2a does not need backward computation.
I0530 20:27:16.393708 26136 net.cpp:228] res2b_branch2a does not need backward computation.
I0530 20:27:16.393714 26136 net.cpp:228] res2a_res2a_relu_0_split does not need backward computation.
I0530 20:27:16.393719 26136 net.cpp:228] res2a_relu does not need backward computation.
I0530 20:27:16.393724 26136 net.cpp:228] res2a does not need backward computation.
I0530 20:27:16.393730 26136 net.cpp:228] scale2a_branch2c does not need backward computation.
I0530 20:27:16.393735 26136 net.cpp:228] bn2a_branch2c does not need backward computation.
I0530 20:27:16.393740 26136 net.cpp:228] res2a_branch2c does not need backward computation.
I0530 20:27:16.393746 26136 net.cpp:228] res2a_branch2b_relu does not need backward computation.
I0530 20:27:16.393750 26136 net.cpp:228] scale2a_branch2b does not need backward computation.
I0530 20:27:16.393755 26136 net.cpp:228] bn2a_branch2b does not need backward computation.
I0530 20:27:16.393759 26136 net.cpp:228] res2a_branch2b does not need backward computation.
I0530 20:27:16.393764 26136 net.cpp:228] res2a_branch2a_relu does not need backward computation.
I0530 20:27:16.393769 26136 net.cpp:228] scale2a_branch2a does not need backward computation.
I0530 20:27:16.393774 26136 net.cpp:228] bn2a_branch2a does not need backward computation.
I0530 20:27:16.393779 26136 net.cpp:228] res2a_branch2a does not need backward computation.
I0530 20:27:16.393784 26136 net.cpp:228] scale2a_branch1 does not need backward computation.
I0530 20:27:16.393787 26136 net.cpp:228] bn2a_branch1 does not need backward computation.
I0530 20:27:16.393792 26136 net.cpp:228] res2a_branch1 does not need backward computation.
I0530 20:27:16.393798 26136 net.cpp:228] pool1_pool1_0_split does not need backward computation.
I0530 20:27:16.393803 26136 net.cpp:228] pool1 does not need backward computation.
I0530 20:27:16.393810 26136 net.cpp:228] conv1_relu does not need backward computation.
I0530 20:27:16.393813 26136 net.cpp:228] scale_conv1 does not need backward computation.
I0530 20:27:16.393817 26136 net.cpp:228] bn_conv1 does not need backward computation.
I0530 20:27:16.393822 26136 net.cpp:228] conv1 does not need backward computation.
I0530 20:27:16.393828 26136 net.cpp:228] input does not need backward computation.
I0530 20:27:16.393831 26136 net.cpp:270] This network produces output bbox_pred
I0530 20:27:16.393839 26136 net.cpp:270] This network produces output cls_prob
I0530 20:27:16.394120 26136 net.cpp:283] Network initialization done.
I0530 20:27:16.496937 26136 net.cpp:771] Ignoring source layer input-data
I0530 20:27:16.496981 26136 net.cpp:771] Ignoring source layer data_input-data_0_split
I0530 20:27:16.496989 26136 net.cpp:771] Ignoring source layer im_info_input-data_1_split
I0530 20:27:16.496994 26136 net.cpp:771] Ignoring source layer gt_boxes_input-data_2_split
I0530 20:27:16.496996 26136 net.cpp:774] Copying source layer conv1
I0530 20:27:16.497107 26136 net.cpp:774] Copying source layer bn_conv1
I0530 20:27:16.497118 26136 net.cpp:774] Copying source layer scale_conv1
I0530 20:27:16.497128 26136 net.cpp:774] Copying source layer conv1_relu
I0530 20:27:16.497131 26136 net.cpp:774] Copying source layer pool1
I0530 20:27:16.497134 26136 net.cpp:774] Copying source layer pool1_pool1_0_split
I0530 20:27:16.497138 26136 net.cpp:774] Copying source layer res2a_branch1
I0530 20:27:16.497267 26136 net.cpp:774] Copying source layer bn2a_branch1
I0530 20:27:16.497279 26136 net.cpp:774] Copying source layer scale2a_branch1
I0530 20:27:16.497292 26136 net.cpp:774] Copying source layer res2a_branch2a
I0530 20:27:16.497329 26136 net.cpp:774] Copying source layer bn2a_branch2a
I0530 20:27:16.497339 26136 net.cpp:774] Copying source layer scale2a_branch2a
I0530 20:27:16.497347 26136 net.cpp:774] Copying source layer res2a_branch2a_relu
I0530 20:27:16.497351 26136 net.cpp:774] Copying source layer res2a_branch2b
I0530 20:27:16.497632 26136 net.cpp:774] Copying source layer bn2a_branch2b
I0530 20:27:16.497643 26136 net.cpp:774] Copying source layer scale2a_branch2b
I0530 20:27:16.497651 26136 net.cpp:774] Copying source layer res2a_branch2b_relu
I0530 20:27:16.497655 26136 net.cpp:774] Copying source layer res2a_branch2c
I0530 20:27:16.497784 26136 net.cpp:774] Copying source layer bn2a_branch2c
I0530 20:27:16.497797 26136 net.cpp:774] Copying source layer scale2a_branch2c
I0530 20:27:16.497808 26136 net.cpp:774] Copying source layer res2a
I0530 20:27:16.497812 26136 net.cpp:774] Copying source layer res2a_relu
I0530 20:27:16.497817 26136 net.cpp:774] Copying source layer res2a_res2a_relu_0_split
I0530 20:27:16.497820 26136 net.cpp:774] Copying source layer res2b_branch2a
I0530 20:27:16.497953 26136 net.cpp:774] Copying source layer bn2b_branch2a
I0530 20:27:16.497964 26136 net.cpp:774] Copying source layer scale2b_branch2a
I0530 20:27:16.497972 26136 net.cpp:774] Copying source layer res2b_branch2a_relu
I0530 20:27:16.497977 26136 net.cpp:774] Copying source layer res2b_branch2b
I0530 20:27:16.498271 26136 net.cpp:774] Copying source layer bn2b_branch2b
I0530 20:27:16.498286 26136 net.cpp:774] Copying source layer scale2b_branch2b
I0530 20:27:16.498296 26136 net.cpp:774] Copying source layer res2b_branch2b_relu
I0530 20:27:16.498299 26136 net.cpp:774] Copying source layer res2b_branch2c
I0530 20:27:16.498428 26136 net.cpp:774] Copying source layer bn2b_branch2c
I0530 20:27:16.498442 26136 net.cpp:774] Copying source layer scale2b_branch2c
I0530 20:27:16.498453 26136 net.cpp:774] Copying source layer res2b
I0530 20:27:16.498457 26136 net.cpp:774] Copying source layer res2b_relu
I0530 20:27:16.498462 26136 net.cpp:774] Copying source layer res2b_res2b_relu_0_split
I0530 20:27:16.498466 26136 net.cpp:774] Copying source layer res2c_branch2a
I0530 20:27:16.498595 26136 net.cpp:774] Copying source layer bn2c_branch2a
I0530 20:27:16.498605 26136 net.cpp:774] Copying source layer scale2c_branch2a
I0530 20:27:16.498615 26136 net.cpp:774] Copying source layer res2c_branch2a_relu
I0530 20:27:16.498618 26136 net.cpp:774] Copying source layer res2c_branch2b
I0530 20:27:16.498899 26136 net.cpp:774] Copying source layer bn2c_branch2b
I0530 20:27:16.498910 26136 net.cpp:774] Copying source layer scale2c_branch2b
I0530 20:27:16.498919 26136 net.cpp:774] Copying source layer res2c_branch2b_relu
I0530 20:27:16.498924 26136 net.cpp:774] Copying source layer res2c_branch2c
I0530 20:27:16.499053 26136 net.cpp:774] Copying source layer bn2c_branch2c
I0530 20:27:16.499065 26136 net.cpp:774] Copying source layer scale2c_branch2c
I0530 20:27:16.499078 26136 net.cpp:774] Copying source layer res2c
I0530 20:27:16.499081 26136 net.cpp:774] Copying source layer res2c_relu
I0530 20:27:16.499086 26136 net.cpp:774] Copying source layer res2c_res2c_relu_0_split
I0530 20:27:16.499090 26136 net.cpp:774] Copying source layer res3a_branch1
I0530 20:27:16.500075 26136 net.cpp:774] Copying source layer bn3a_branch1
I0530 20:27:16.500093 26136 net.cpp:774] Copying source layer scale3a_branch1
I0530 20:27:16.500108 26136 net.cpp:774] Copying source layer res3a_branch2a
I0530 20:27:16.500360 26136 net.cpp:774] Copying source layer bn3a_branch2a
I0530 20:27:16.500371 26136 net.cpp:774] Copying source layer scale3a_branch2a
I0530 20:27:16.500382 26136 net.cpp:774] Copying source layer res3a_branch2a_relu
I0530 20:27:16.500386 26136 net.cpp:774] Copying source layer res3a_branch2b
I0530 20:27:16.501505 26136 net.cpp:774] Copying source layer bn3a_branch2b
I0530 20:27:16.501519 26136 net.cpp:774] Copying source layer scale3a_branch2b
I0530 20:27:16.501530 26136 net.cpp:774] Copying source layer res3a_branch2b_relu
I0530 20:27:16.501535 26136 net.cpp:774] Copying source layer res3a_branch2c
I0530 20:27:16.502032 26136 net.cpp:774] Copying source layer bn3a_branch2c
I0530 20:27:16.502056 26136 net.cpp:774] Copying source layer scale3a_branch2c
I0530 20:27:16.502070 26136 net.cpp:774] Copying source layer res3a
I0530 20:27:16.502074 26136 net.cpp:774] Copying source layer res3a_relu
I0530 20:27:16.502076 26136 net.cpp:774] Copying source layer res3a_res3a_relu_0_split
I0530 20:27:16.502079 26136 net.cpp:774] Copying source layer res3b_branch2a
I0530 20:27:16.502578 26136 net.cpp:774] Copying source layer bn3b_branch2a
I0530 20:27:16.502591 26136 net.cpp:774] Copying source layer scale3b_branch2a
I0530 20:27:16.502602 26136 net.cpp:774] Copying source layer res3b_branch2a_relu
I0530 20:27:16.502606 26136 net.cpp:774] Copying source layer res3b_branch2b
I0530 20:27:16.503712 26136 net.cpp:774] Copying source layer bn3b_branch2b
I0530 20:27:16.503726 26136 net.cpp:774] Copying source layer scale3b_branch2b
I0530 20:27:16.503736 26136 net.cpp:774] Copying source layer res3b_branch2b_relu
I0530 20:27:16.503741 26136 net.cpp:774] Copying source layer res3b_branch2c
I0530 20:27:16.504237 26136 net.cpp:774] Copying source layer bn3b_branch2c
I0530 20:27:16.504256 26136 net.cpp:774] Copying source layer scale3b_branch2c
I0530 20:27:16.504272 26136 net.cpp:774] Copying source layer res3b
I0530 20:27:16.504276 26136 net.cpp:774] Copying source layer res3b_relu
I0530 20:27:16.504281 26136 net.cpp:774] Copying source layer res3b_res3b_relu_0_split
I0530 20:27:16.504287 26136 net.cpp:774] Copying source layer res3c_branch2a
I0530 20:27:16.504782 26136 net.cpp:774] Copying source layer bn3c_branch2a
I0530 20:27:16.504794 26136 net.cpp:774] Copying source layer scale3c_branch2a
I0530 20:27:16.504806 26136 net.cpp:774] Copying source layer res3c_branch2a_relu
I0530 20:27:16.504812 26136 net.cpp:774] Copying source layer res3c_branch2b
I0530 20:27:16.505928 26136 net.cpp:774] Copying source layer bn3c_branch2b
I0530 20:27:16.505944 26136 net.cpp:774] Copying source layer scale3c_branch2b
I0530 20:27:16.505955 26136 net.cpp:774] Copying source layer res3c_branch2b_relu
I0530 20:27:16.505960 26136 net.cpp:774] Copying source layer res3c_branch2c
I0530 20:27:16.506458 26136 net.cpp:774] Copying source layer bn3c_branch2c
I0530 20:27:16.506477 26136 net.cpp:774] Copying source layer scale3c_branch2c
I0530 20:27:16.506494 26136 net.cpp:774] Copying source layer res3c
I0530 20:27:16.506498 26136 net.cpp:774] Copying source layer res3c_relu
I0530 20:27:16.506505 26136 net.cpp:774] Copying source layer res3c_res3c_relu_0_split
I0530 20:27:16.506510 26136 net.cpp:774] Copying source layer res3d_branch2a
I0530 20:27:16.507004 26136 net.cpp:774] Copying source layer bn3d_branch2a
I0530 20:27:16.507019 26136 net.cpp:774] Copying source layer scale3d_branch2a
I0530 20:27:16.507030 26136 net.cpp:774] Copying source layer res3d_branch2a_relu
I0530 20:27:16.507035 26136 net.cpp:774] Copying source layer res3d_branch2b
I0530 20:27:16.508200 26136 net.cpp:774] Copying source layer bn3d_branch2b
I0530 20:27:16.508219 26136 net.cpp:774] Copying source layer scale3d_branch2b
I0530 20:27:16.508231 26136 net.cpp:774] Copying source layer res3d_branch2b_relu
I0530 20:27:16.508237 26136 net.cpp:774] Copying source layer res3d_branch2c
I0530 20:27:16.508733 26136 net.cpp:774] Copying source layer bn3d_branch2c
I0530 20:27:16.508752 26136 net.cpp:774] Copying source layer scale3d_branch2c
I0530 20:27:16.508769 26136 net.cpp:774] Copying source layer res3d
I0530 20:27:16.508775 26136 net.cpp:774] Copying source layer res3d_relu
I0530 20:27:16.508781 26136 net.cpp:774] Copying source layer res3d_res3d_relu_0_split
I0530 20:27:16.508787 26136 net.cpp:774] Copying source layer res4a_branch1
I0530 20:27:16.512729 26136 net.cpp:774] Copying source layer bn4a_branch1
I0530 20:27:16.512768 26136 net.cpp:774] Copying source layer scale4a_branch1
I0530 20:27:16.512801 26136 net.cpp:774] Copying source layer res4a_branch2a
I0530 20:27:16.513828 26136 net.cpp:774] Copying source layer bn4a_branch2a
I0530 20:27:16.513847 26136 net.cpp:774] Copying source layer scale4a_branch2a
I0530 20:27:16.513862 26136 net.cpp:774] Copying source layer res4a_branch2a_relu
I0530 20:27:16.513870 26136 net.cpp:774] Copying source layer res4a_branch2b
I0530 20:27:16.518299 26136 net.cpp:774] Copying source layer bn4a_branch2b
I0530 20:27:16.518318 26136 net.cpp:774] Copying source layer scale4a_branch2b
I0530 20:27:16.518329 26136 net.cpp:774] Copying source layer res4a_branch2b_relu
I0530 20:27:16.518333 26136 net.cpp:774] Copying source layer res4a_branch2c
I0530 20:27:16.520296 26136 net.cpp:774] Copying source layer bn4a_branch2c
I0530 20:27:16.520321 26136 net.cpp:774] Copying source layer scale4a_branch2c
I0530 20:27:16.520347 26136 net.cpp:774] Copying source layer res4a
I0530 20:27:16.520354 26136 net.cpp:774] Copying source layer res4a_relu
I0530 20:27:16.520360 26136 net.cpp:774] Copying source layer res4a_res4a_relu_0_split
I0530 20:27:16.520364 26136 net.cpp:774] Copying source layer res4b_branch2a
I0530 20:27:16.522338 26136 net.cpp:774] Copying source layer bn4b_branch2a
I0530 20:27:16.522353 26136 net.cpp:774] Copying source layer scale4b_branch2a
I0530 20:27:16.522364 26136 net.cpp:774] Copying source layer res4b_branch2a_relu
I0530 20:27:16.522368 26136 net.cpp:774] Copying source layer res4b_branch2b
I0530 20:27:16.527237 26136 net.cpp:774] Copying source layer bn4b_branch2b
I0530 20:27:16.527266 26136 net.cpp:774] Copying source layer scale4b_branch2b
I0530 20:27:16.527283 26136 net.cpp:774] Copying source layer res4b_branch2b_relu
I0530 20:27:16.527290 26136 net.cpp:774] Copying source layer res4b_branch2c
I0530 20:27:16.529276 26136 net.cpp:774] Copying source layer bn4b_branch2c
I0530 20:27:16.529304 26136 net.cpp:774] Copying source layer scale4b_branch2c
I0530 20:27:16.529330 26136 net.cpp:774] Copying source layer res4b
I0530 20:27:16.529337 26136 net.cpp:774] Copying source layer res4b_relu
I0530 20:27:16.529343 26136 net.cpp:774] Copying source layer res4b_res4b_relu_0_split
I0530 20:27:16.529348 26136 net.cpp:774] Copying source layer res4c_branch2a
I0530 20:27:16.531311 26136 net.cpp:774] Copying source layer bn4c_branch2a
I0530 20:27:16.531327 26136 net.cpp:774] Copying source layer scale4c_branch2a
I0530 20:27:16.531337 26136 net.cpp:774] Copying source layer res4c_branch2a_relu
I0530 20:27:16.531342 26136 net.cpp:774] Copying source layer res4c_branch2b
I0530 20:27:16.535754 26136 net.cpp:774] Copying source layer bn4c_branch2b
I0530 20:27:16.535770 26136 net.cpp:774] Copying source layer scale4c_branch2b
I0530 20:27:16.535781 26136 net.cpp:774] Copying source layer res4c_branch2b_relu
I0530 20:27:16.535786 26136 net.cpp:774] Copying source layer res4c_branch2c
I0530 20:27:16.537760 26136 net.cpp:774] Copying source layer bn4c_branch2c
I0530 20:27:16.537786 26136 net.cpp:774] Copying source layer scale4c_branch2c
I0530 20:27:16.537811 26136 net.cpp:774] Copying source layer res4c
I0530 20:27:16.537818 26136 net.cpp:774] Copying source layer res4c_relu
I0530 20:27:16.537825 26136 net.cpp:774] Copying source layer res4c_res4c_relu_0_split
I0530 20:27:16.537829 26136 net.cpp:774] Copying source layer res4d_branch2a
I0530 20:27:16.539793 26136 net.cpp:774] Copying source layer bn4d_branch2a
I0530 20:27:16.539806 26136 net.cpp:774] Copying source layer scale4d_branch2a
I0530 20:27:16.539818 26136 net.cpp:774] Copying source layer res4d_branch2a_relu
I0530 20:27:16.539822 26136 net.cpp:774] Copying source layer res4d_branch2b
I0530 20:27:16.544242 26136 net.cpp:774] Copying source layer bn4d_branch2b
I0530 20:27:16.544261 26136 net.cpp:774] Copying source layer scale4d_branch2b
I0530 20:27:16.544272 26136 net.cpp:774] Copying source layer res4d_branch2b_relu
I0530 20:27:16.544276 26136 net.cpp:774] Copying source layer res4d_branch2c
I0530 20:27:16.546277 26136 net.cpp:774] Copying source layer bn4d_branch2c
I0530 20:27:16.546305 26136 net.cpp:774] Copying source layer scale4d_branch2c
I0530 20:27:16.546332 26136 net.cpp:774] Copying source layer res4d
I0530 20:27:16.546339 26136 net.cpp:774] Copying source layer res4d_relu
I0530 20:27:16.546345 26136 net.cpp:774] Copying source layer res4d_res4d_relu_0_split
I0530 20:27:16.546350 26136 net.cpp:774] Copying source layer res4e_branch2a
I0530 20:27:16.548313 26136 net.cpp:774] Copying source layer bn4e_branch2a
I0530 20:27:16.548328 26136 net.cpp:774] Copying source layer scale4e_branch2a
I0530 20:27:16.548339 26136 net.cpp:774] Copying source layer res4e_branch2a_relu
I0530 20:27:16.548344 26136 net.cpp:774] Copying source layer res4e_branch2b
I0530 20:27:16.552726 26136 net.cpp:774] Copying source layer bn4e_branch2b
I0530 20:27:16.552742 26136 net.cpp:774] Copying source layer scale4e_branch2b
I0530 20:27:16.552752 26136 net.cpp:774] Copying source layer res4e_branch2b_relu
I0530 20:27:16.552757 26136 net.cpp:774] Copying source layer res4e_branch2c
I0530 20:27:16.554723 26136 net.cpp:774] Copying source layer bn4e_branch2c
I0530 20:27:16.554750 26136 net.cpp:774] Copying source layer scale4e_branch2c
I0530 20:27:16.554776 26136 net.cpp:774] Copying source layer res4e
I0530 20:27:16.554783 26136 net.cpp:774] Copying source layer res4e_relu
I0530 20:27:16.554790 26136 net.cpp:774] Copying source layer res4e_res4e_relu_0_split
I0530 20:27:16.554796 26136 net.cpp:774] Copying source layer res4f_branch2a
I0530 20:27:16.557224 26136 net.cpp:774] Copying source layer bn4f_branch2a
I0530 20:27:16.557246 26136 net.cpp:774] Copying source layer scale4f_branch2a
I0530 20:27:16.557258 26136 net.cpp:774] Copying source layer res4f_branch2a_relu
I0530 20:27:16.557262 26136 net.cpp:774] Copying source layer res4f_branch2b
I0530 20:27:16.561671 26136 net.cpp:774] Copying source layer bn4f_branch2b
I0530 20:27:16.561695 26136 net.cpp:774] Copying source layer scale4f_branch2b
I0530 20:27:16.561707 26136 net.cpp:774] Copying source layer res4f_branch2b_relu
I0530 20:27:16.561712 26136 net.cpp:774] Copying source layer res4f_branch2c
I0530 20:27:16.563681 26136 net.cpp:774] Copying source layer bn4f_branch2c
I0530 20:27:16.563709 26136 net.cpp:774] Copying source layer scale4f_branch2c
I0530 20:27:16.563735 26136 net.cpp:774] Copying source layer res4f
I0530 20:27:16.563743 26136 net.cpp:774] Copying source layer res4f_relu
I0530 20:27:16.563751 26136 net.cpp:774] Copying source layer res4f_res4f_relu_0_split
I0530 20:27:16.563756 26136 net.cpp:774] Copying source layer res5a_branch1
I0530 20:27:16.579871 26136 net.cpp:774] Copying source layer bn5a_branch1
I0530 20:27:16.579938 26136 net.cpp:774] Copying source layer scale5a_branch1
I0530 20:27:16.579990 26136 net.cpp:774] Copying source layer res5a_branch2a
I0530 20:27:16.583930 26136 net.cpp:774] Copying source layer bn5a_branch2a
I0530 20:27:16.583957 26136 net.cpp:774] Copying source layer scale5a_branch2a
I0530 20:27:16.583976 26136 net.cpp:774] Copying source layer res5a_branch2a_relu
I0530 20:27:16.583983 26136 net.cpp:774] Copying source layer res5a_branch2b
I0530 20:27:16.602129 26136 net.cpp:774] Copying source layer bn5a_branch2b
I0530 20:27:16.602180 26136 net.cpp:774] Copying source layer scale5a_branch2b
I0530 20:27:16.602200 26136 net.cpp:774] Copying source layer res5a_branch2b_relu
I0530 20:27:16.602208 26136 net.cpp:774] Copying source layer res5a_branch2c
I0530 20:27:16.610059 26136 net.cpp:774] Copying source layer bn5a_branch2c
I0530 20:27:16.610106 26136 net.cpp:774] Copying source layer scale5a_branch2c
I0530 20:27:16.610154 26136 net.cpp:774] Copying source layer res5a
I0530 20:27:16.610162 26136 net.cpp:774] Copying source layer res5a_relu
I0530 20:27:16.610172 26136 net.cpp:774] Copying source layer res5a_res5a_relu_0_split
I0530 20:27:16.610177 26136 net.cpp:774] Copying source layer res5b_branch2a
I0530 20:27:16.618050 26136 net.cpp:774] Copying source layer bn5b_branch2a
I0530 20:27:16.618084 26136 net.cpp:774] Copying source layer scale5b_branch2a
I0530 20:27:16.618103 26136 net.cpp:774] Copying source layer res5b_branch2a_relu
I0530 20:27:16.618113 26136 net.cpp:774] Copying source layer res5b_branch2b
I0530 20:27:16.636188 26136 net.cpp:774] Copying source layer bn5b_branch2b
I0530 20:27:16.636241 26136 net.cpp:774] Copying source layer scale5b_branch2b
I0530 20:27:16.636263 26136 net.cpp:774] Copying source layer res5b_branch2b_relu
I0530 20:27:16.636271 26136 net.cpp:774] Copying source layer res5b_branch2c
I0530 20:27:16.644163 26136 net.cpp:774] Copying source layer bn5b_branch2c
I0530 20:27:16.644238 26136 net.cpp:774] Copying source layer scale5b_branch2c
I0530 20:27:16.644290 26136 net.cpp:774] Copying source layer res5b
I0530 20:27:16.644297 26136 net.cpp:774] Copying source layer res5b_relu
I0530 20:27:16.644304 26136 net.cpp:774] Copying source layer res5b_res5b_relu_0_split
I0530 20:27:16.644309 26136 net.cpp:774] Copying source layer res5c_branch2a
I0530 20:27:16.652447 26136 net.cpp:774] Copying source layer bn5c_branch2a
I0530 20:27:16.652508 26136 net.cpp:774] Copying source layer scale5c_branch2a
I0530 20:27:16.652536 26136 net.cpp:774] Copying source layer res5c_branch2a_relu
I0530 20:27:16.652546 26136 net.cpp:774] Copying source layer res5c_branch2b
I0530 20:27:16.670667 26136 net.cpp:774] Copying source layer bn5c_branch2b
I0530 20:27:16.670735 26136 net.cpp:774] Copying source layer scale5c_branch2b
I0530 20:27:16.670761 26136 net.cpp:774] Copying source layer res5c_branch2b_relu
I0530 20:27:16.670769 26136 net.cpp:774] Copying source layer res5c_branch2c
I0530 20:27:16.678686 26136 net.cpp:774] Copying source layer bn5c_branch2c
I0530 20:27:16.678750 26136 net.cpp:774] Copying source layer scale5c_branch2c
I0530 20:27:16.678799 26136 net.cpp:774] Copying source layer res5c
I0530 20:27:16.678808 26136 net.cpp:774] Copying source layer res5c_relu
I0530 20:27:16.678815 26136 net.cpp:774] Copying source layer rpn_conv/3x3
I0530 20:27:16.714591 26136 net.cpp:774] Copying source layer rpn_relu/3x3
I0530 20:27:16.714613 26136 net.cpp:774] Copying source layer rpn/output_rpn_relu/3x3_0_split
I0530 20:27:16.714618 26136 net.cpp:774] Copying source layer rpn_cls_score
I0530 20:27:16.714725 26136 net.cpp:771] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0530 20:27:16.714731 26136 net.cpp:774] Copying source layer rpn_bbox_pred
I0530 20:27:16.714915 26136 net.cpp:771] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0530 20:27:16.714922 26136 net.cpp:774] Copying source layer rpn_cls_score_reshape
I0530 20:27:16.714927 26136 net.cpp:771] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0530 20:27:16.714931 26136 net.cpp:771] Ignoring source layer rpn-data
I0530 20:27:16.714936 26136 net.cpp:771] Ignoring source layer rpn_loss_cls
I0530 20:27:16.714941 26136 net.cpp:771] Ignoring source layer rpn_loss_bbox
I0530 20:27:16.714946 26136 net.cpp:774] Copying source layer rpn_cls_prob
I0530 20:27:16.714952 26136 net.cpp:774] Copying source layer rpn_cls_prob_reshape
I0530 20:27:16.714958 26136 net.cpp:774] Copying source layer proposal
I0530 20:27:16.714964 26136 net.cpp:771] Ignoring source layer roi-data
I0530 20:27:16.714972 26136 net.cpp:771] Ignoring source layer rois_roi-data_0_split
I0530 20:27:16.714994 26136 net.cpp:771] Ignoring source layer labels_roi-data_1_split
I0530 20:27:16.715009 26136 net.cpp:771] Ignoring source layer bbox_targets_roi-data_2_split
I0530 20:27:16.715018 26136 net.cpp:771] Ignoring source layer bbox_inside_weights_roi-data_3_split
I0530 20:27:16.715025 26136 net.cpp:774] Copying source layer conv_new_1
I0530 20:27:16.731250 26136 net.cpp:774] Copying source layer conv_new_1_relu
I0530 20:27:16.731274 26136 net.cpp:774] Copying source layer conv_new_1_conv_new_1_relu_0_split
I0530 20:27:16.731279 26136 net.cpp:774] Copying source layer rfcn_cls
I0530 20:27:16.732049 26136 net.cpp:774] Copying source layer rfcn_bbox
I0530 20:27:16.735095 26136 net.cpp:774] Copying source layer psroipooled_cls_rois
I0530 20:27:16.735103 26136 net.cpp:774] Copying source layer ave_cls_score_rois
I0530 20:27:16.735108 26136 net.cpp:771] Ignoring source layer cls_score_ave_cls_score_rois_0_split
I0530 20:27:16.735113 26136 net.cpp:774] Copying source layer psroipooled_loc_rois
I0530 20:27:16.735117 26136 net.cpp:774] Copying source layer ave_bbox_pred_rois
I0530 20:27:16.735122 26136 net.cpp:771] Ignoring source layer bbox_pred_ave_bbox_pred_rois_0_split
I0530 20:27:16.735133 26136 net.cpp:771] Ignoring source layer per_roi_loss_cls
I0530 20:27:16.735139 26136 net.cpp:771] Ignoring source layer per_roi_loss_bbox
I0530 20:27:16.735144 26136 net.cpp:771] Ignoring source layer per_roi_loss
I0530 20:27:16.735150 26136 net.cpp:771] Ignoring source layer annotator_detector
I0530 20:27:16.735155 26136 net.cpp:771] Ignoring source layer labels_ohem_annotator_detector_0_split
I0530 20:27:16.735162 26136 net.cpp:771] Ignoring source layer silence
I0530 20:27:16.735167 26136 net.cpp:771] Ignoring source layer loss
I0530 20:27:16.735173 26136 net.cpp:771] Ignoring source layer accuarcy
I0530 20:27:16.735180 26136 net.cpp:771] Ignoring source layer loss_bbox
I0530 20:27:17.029661 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 2459544
I0530 20:27:17.036859 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.047430 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.054399 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.059909 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.068250 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.072207 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.080847 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 619992
I0530 20:27:17.085106 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 154104
I0530 20:27:17.092319 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 154104
I0530 20:27:17.097141 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.099786 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.104743 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.107389 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.112372 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.115231 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.120195 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 160632
I0530 20:27:17.123318 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 38904
I0530 20:27:17.128084 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 38904
I0530 20:27:17.131961 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.134102 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.138204 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.140339 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.144439 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.146570 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.150696 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.152827 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.157939 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.160176 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.164376 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.166544 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 38904
I0530 20:27:17.172231 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.183063 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 38904
I0530 20:27:17.187826 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.200248 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 38904
I0530 20:27:17.204269 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.218657 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 38904
I0530 20:27:17.232165 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.232455 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.240293 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.243887 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
I0530 20:27:17.244266 26136 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 45432
im_detect: 1/4024 0.232s 0.001s
im_detect: 2/4024 0.190s 0.001s
im_detect: 3/4024 0.176s 0.001s
im_detect: 4/4024 0.169s 0.001s
im_detect: 5/4024 0.165s 0.001s
im_detect: 6/4024 0.162s 0.001s
im_detect: 7/4024 0.161s 0.001s
im_detect: 8/4024 0.159s 0.001s
im_detect: 9/4024 0.158s 0.001s
im_detect: 10/4024 0.157s 0.001s
im_detect: 11/4024 0.156s 0.001s
im_detect: 12/4024 0.156s 0.001s
im_detect: 13/4024 0.155s 0.001s
im_detect: 14/4024 0.155s 0.001s
im_detect: 15/4024 0.154s 0.001s
im_detect: 16/4024 0.154s 0.001s
im_detect: 17/4024 0.153s 0.001s
im_detect: 18/4024 0.153s 0.001s
im_detect: 19/4024 0.153s 0.001s
im_detect: 20/4024 0.153s 0.001s
im_detect: 21/4024 0.153s 0.001s
im_detect: 22/4024 0.152s 0.001s
im_detect: 23/4024 0.152s 0.001s
im_detect: 24/4024 0.152s 0.001s
im_detect: 25/4024 0.152s 0.001s
im_detect: 26/4024 0.152s 0.001s
im_detect: 27/4024 0.152s 0.001s
im_detect: 28/4024 0.151s 0.001s
im_detect: 29/4024 0.151s 0.001s
im_detect: 30/4024 0.151s 0.001s
im_detect: 31/4024 0.151s 0.001s
im_detect: 32/4024 0.151s 0.001s
im_detect: 33/4024 0.151s 0.001s
im_detect: 34/4024 0.151s 0.001s
im_detect: 35/4024 0.151s 0.001s
im_detect: 36/4024 0.151s 0.001s
im_detect: 37/4024 0.150s 0.001s
im_detect: 38/4024 0.150s 0.001s
im_detect: 39/4024 0.150s 0.001s
im_detect: 40/4024 0.150s 0.001s
im_detect: 41/4024 0.150s 0.001s
im_detect: 42/4024 0.150s 0.001s
im_detect: 43/4024 0.150s 0.001s
im_detect: 44/4024 0.150s 0.001s
im_detect: 45/4024 0.150s 0.001s
im_detect: 46/4024 0.150s 0.001s
im_detect: 47/4024 0.150s 0.001s
im_detect: 48/4024 0.150s 0.001s
im_detect: 49/4024 0.150s 0.001s
im_detect: 50/4024 0.150s 0.001s
im_detect: 51/4024 0.150s 0.001s
im_detect: 52/4024 0.150s 0.001s
im_detect: 53/4024 0.150s 0.001s
im_detect: 54/4024 0.150s 0.001s
im_detect: 55/4024 0.150s 0.001s
im_detect: 56/4024 0.150s 0.001s
im_detect: 57/4024 0.150s 0.001s
im_detect: 58/4024 0.150s 0.001s
im_detect: 59/4024 0.150s 0.001s
im_detect: 60/4024 0.150s 0.001s
im_detect: 61/4024 0.150s 0.001s
im_detect: 62/4024 0.150s 0.001s
im_detect: 63/4024 0.149s 0.001s
im_detect: 64/4024 0.149s 0.001s
im_detect: 65/4024 0.150s 0.001s
im_detect: 66/4024 0.149s 0.001s
im_detect: 67/4024 0.149s 0.001s
im_detect: 68/4024 0.149s 0.001s
im_detect: 69/4024 0.149s 0.001s
im_detect: 70/4024 0.149s 0.001s
im_detect: 71/4024 0.149s 0.001s
im_detect: 72/4024 0.149s 0.001s
im_detect: 73/4024 0.149s 0.001s
im_detect: 74/4024 0.149s 0.001s
im_detect: 75/4024 0.149s 0.001s
im_detect: 76/4024 0.149s 0.001s
im_detect: 77/4024 0.149s 0.001s
im_detect: 78/4024 0.149s 0.001s
im_detect: 79/4024 0.149s 0.001s
im_detect: 80/4024 0.149s 0.001s
im_detect: 81/4024 0.149s 0.001s
im_detect: 82/4024 0.149s 0.001s
im_detect: 83/4024 0.149s 0.001s
im_detect: 84/4024 0.149s 0.001s
im_detect: 85/4024 0.149s 0.001s
im_detect: 86/4024 0.149s 0.001s
im_detect: 87/4024 0.149s 0.001s
im_detect: 88/4024 0.149s 0.001s
im_detect: 89/4024 0.149s 0.001s
im_detect: 90/4024 0.149s 0.001s
im_detect: 91/4024 0.149s 0.001s
im_detect: 92/4024 0.149s 0.001s
im_detect: 93/4024 0.149s 0.001s
im_detect: 94/4024 0.149s 0.001s
im_detect: 95/4024 0.149s 0.001s
im_detect: 96/4024 0.149s 0.001s
im_detect: 97/4024 0.149s 0.001s
im_detect: 98/4024 0.149s 0.001s
im_detect: 99/4024 0.149s 0.001s
im_detect: 100/4024 0.149s 0.001s
im_detect: 101/4024 0.149s 0.001s
im_detect: 102/4024 0.149s 0.001s
im_detect: 103/4024 0.149s 0.001s
im_detect: 104/4024 0.149s 0.001s
im_detect: 105/4024 0.149s 0.001s
im_detect: 106/4024 0.149s 0.001s
im_detect: 107/4024 0.149s 0.001s
im_detect: 108/4024 0.149s 0.001s
im_detect: 109/4024 0.149s 0.001s
im_detect: 110/4024 0.149s 0.001s
im_detect: 111/4024 0.149s 0.001s
im_detect: 112/4024 0.149s 0.001s
im_detect: 113/4024 0.149s 0.001s
im_detect: 114/4024 0.149s 0.001s
im_detect: 115/4024 0.149s 0.001s
im_detect: 116/4024 0.149s 0.001s
im_detect: 117/4024 0.149s 0.001s
im_detect: 118/4024 0.149s 0.001s
im_detect: 119/4024 0.149s 0.001s
im_detect: 120/4024 0.149s 0.001s
im_detect: 121/4024 0.149s 0.001s
im_detect: 122/4024 0.149s 0.001s
im_detect: 123/4024 0.149s 0.001s
im_detect: 124/4024 0.149s 0.001s
im_detect: 125/4024 0.149s 0.001s
im_detect: 126/4024 0.149s 0.001s
im_detect: 127/4024 0.149s 0.001s
im_detect: 128/4024 0.149s 0.001s
im_detect: 129/4024 0.149s 0.001s
im_detect: 130/4024 0.149s 0.001s
im_detect: 131/4024 0.149s 0.001s
im_detect: 132/4024 0.149s 0.001s
im_detect: 133/4024 0.149s 0.001s
im_detect: 134/4024 0.149s 0.001s
im_detect: 135/4024 0.149s 0.001s
im_detect: 136/4024 0.149s 0.001s
im_detect: 137/4024 0.149s 0.001s
im_detect: 138/4024 0.149s 0.001s
im_detect: 139/4024 0.149s 0.001s
im_detect: 140/4024 0.149s 0.001s
im_detect: 141/4024 0.149s 0.001s
im_detect: 142/4024 0.149s 0.001s
im_detect: 143/4024 0.149s 0.001s
im_detect: 144/4024 0.149s 0.001s
im_detect: 145/4024 0.149s 0.001s
im_detect: 146/4024 0.149s 0.001s
im_detect: 147/4024 0.149s 0.001s
im_detect: 148/4024 0.149s 0.001s
im_detect: 149/4024 0.149s 0.001s
im_detect: 150/4024 0.149s 0.001s
im_detect: 151/4024 0.149s 0.001s
im_detect: 152/4024 0.149s 0.001s
im_detect: 153/4024 0.149s 0.001s
im_detect: 154/4024 0.149s 0.001s
im_detect: 155/4024 0.149s 0.001s
im_detect: 156/4024 0.149s 0.001s
im_detect: 157/4024 0.149s 0.001s
im_detect: 158/4024 0.149s 0.001s
im_detect: 159/4024 0.149s 0.001s
im_detect: 160/4024 0.149s 0.001s
im_detect: 161/4024 0.149s 0.001s
im_detect: 162/4024 0.149s 0.001s
im_detect: 163/4024 0.149s 0.001s
im_detect: 164/4024 0.149s 0.001s
im_detect: 165/4024 0.149s 0.001s
im_detect: 166/4024 0.149s 0.001s
im_detect: 167/4024 0.149s 0.001s
im_detect: 168/4024 0.149s 0.001s
im_detect: 169/4024 0.149s 0.001s
im_detect: 170/4024 0.149s 0.001s
im_detect: 171/4024 0.149s 0.001s
im_detect: 172/4024 0.149s 0.001s
im_detect: 173/4024 0.149s 0.001s
im_detect: 174/4024 0.149s 0.001s
im_detect: 175/4024 0.149s 0.001s
im_detect: 176/4024 0.149s 0.001s
im_detect: 177/4024 0.149s 0.001s
im_detect: 178/4024 0.149s 0.001s
im_detect: 179/4024 0.149s 0.001s
im_detect: 180/4024 0.149s 0.001s
im_detect: 181/4024 0.149s 0.001s
im_detect: 182/4024 0.149s 0.001s
im_detect: 183/4024 0.149s 0.001s
im_detect: 184/4024 0.149s 0.001s
im_detect: 185/4024 0.149s 0.001s
im_detect: 186/4024 0.149s 0.001s
im_detect: 187/4024 0.149s 0.001s
im_detect: 188/4024 0.149s 0.001s
im_detect: 189/4024 0.149s 0.001s
im_detect: 190/4024 0.149s 0.001s
im_detect: 191/4024 0.149s 0.001s
im_detect: 192/4024 0.149s 0.001s
im_detect: 193/4024 0.149s 0.001s
im_detect: 194/4024 0.149s 0.001s
im_detect: 195/4024 0.149s 0.001s
im_detect: 196/4024 0.149s 0.001s
im_detect: 197/4024 0.149s 0.001s
im_detect: 198/4024 0.149s 0.001s
im_detect: 199/4024 0.149s 0.001s
im_detect: 200/4024 0.149s 0.001s
im_detect: 201/4024 0.149s 0.001s
im_detect: 202/4024 0.149s 0.001s
im_detect: 203/4024 0.149s 0.001s
im_detect: 204/4024 0.149s 0.001s
im_detect: 205/4024 0.149s 0.001s
im_detect: 206/4024 0.149s 0.001s
im_detect: 207/4024 0.149s 0.001s
im_detect: 208/4024 0.149s 0.001s
im_detect: 209/4024 0.149s 0.001s
im_detect: 210/4024 0.149s 0.001s
im_detect: 211/4024 0.149s 0.001s
im_detect: 212/4024 0.149s 0.001s
im_detect: 213/4024 0.149s 0.001s
im_detect: 214/4024 0.149s 0.001s
im_detect: 215/4024 0.149s 0.001s
im_detect: 216/4024 0.149s 0.001s
im_detect: 217/4024 0.149s 0.001s
im_detect: 218/4024 0.149s 0.001s
im_detect: 219/4024 0.149s 0.001s
im_detect: 220/4024 0.149s 0.001s
im_detect: 221/4024 0.149s 0.001s
im_detect: 222/4024 0.149s 0.001s
im_detect: 223/4024 0.149s 0.001s
im_detect: 224/4024 0.149s 0.001s
im_detect: 225/4024 0.149s 0.001s
im_detect: 226/4024 0.149s 0.001s
im_detect: 227/4024 0.149s 0.001s
im_detect: 228/4024 0.149s 0.001s
im_detect: 229/4024 0.149s 0.001s
im_detect: 230/4024 0.149s 0.001s
im_detect: 231/4024 0.149s 0.001s
im_detect: 232/4024 0.149s 0.001s
im_detect: 233/4024 0.149s 0.001s
im_detect: 234/4024 0.149s 0.001s
im_detect: 235/4024 0.149s 0.001s
im_detect: 236/4024 0.149s 0.001s
im_detect: 237/4024 0.149s 0.001s
im_detect: 238/4024 0.149s 0.001s
im_detect: 239/4024 0.149s 0.001s
im_detect: 240/4024 0.149s 0.001s
im_detect: 241/4024 0.149s 0.001s
im_detect: 242/4024 0.149s 0.001s
im_detect: 243/4024 0.149s 0.001s
im_detect: 244/4024 0.149s 0.001s
im_detect: 245/4024 0.149s 0.001s
im_detect: 246/4024 0.149s 0.001s
im_detect: 247/4024 0.149s 0.001s
im_detect: 248/4024 0.149s 0.001s
im_detect: 249/4024 0.149s 0.001s
im_detect: 250/4024 0.149s 0.001s
im_detect: 251/4024 0.149s 0.001s
im_detect: 252/4024 0.149s 0.001s
im_detect: 253/4024 0.149s 0.001s
im_detect: 254/4024 0.149s 0.001s
im_detect: 255/4024 0.149s 0.001s
im_detect: 256/4024 0.149s 0.001s
im_detect: 257/4024 0.149s 0.001s
im_detect: 258/4024 0.149s 0.001s
im_detect: 259/4024 0.149s 0.001s
im_detect: 260/4024 0.149s 0.001s
im_detect: 261/4024 0.149s 0.001s
im_detect: 262/4024 0.149s 0.001s
im_detect: 263/4024 0.149s 0.001s
im_detect: 264/4024 0.149s 0.001s
im_detect: 265/4024 0.149s 0.001s
im_detect: 266/4024 0.149s 0.001s
im_detect: 267/4024 0.149s 0.001s
im_detect: 268/4024 0.149s 0.001s
im_detect: 269/4024 0.149s 0.001s
im_detect: 270/4024 0.149s 0.001s
im_detect: 271/4024 0.149s 0.001s
im_detect: 272/4024 0.149s 0.001s
im_detect: 273/4024 0.149s 0.001s
im_detect: 274/4024 0.149s 0.001s
im_detect: 275/4024 0.149s 0.001s
im_detect: 276/4024 0.149s 0.001s
im_detect: 277/4024 0.149s 0.001s
im_detect: 278/4024 0.149s 0.001s
im_detect: 279/4024 0.149s 0.001s
im_detect: 280/4024 0.149s 0.001s
im_detect: 281/4024 0.149s 0.001s
im_detect: 282/4024 0.149s 0.001s
im_detect: 283/4024 0.149s 0.001s
im_detect: 284/4024 0.149s 0.001s
im_detect: 285/4024 0.149s 0.001s
im_detect: 286/4024 0.149s 0.001s
im_detect: 287/4024 0.149s 0.001s
im_detect: 288/4024 0.149s 0.001s
im_detect: 289/4024 0.149s 0.001s
im_detect: 290/4024 0.149s 0.001s
im_detect: 291/4024 0.149s 0.001s
im_detect: 292/4024 0.149s 0.001s
im_detect: 293/4024 0.149s 0.001s
im_detect: 294/4024 0.149s 0.001s
im_detect: 295/4024 0.149s 0.001s
im_detect: 296/4024 0.149s 0.001s
im_detect: 297/4024 0.149s 0.001s
im_detect: 298/4024 0.148s 0.001s
im_detect: 299/4024 0.148s 0.001s
im_detect: 300/4024 0.148s 0.001s
im_detect: 301/4024 0.148s 0.001s
im_detect: 302/4024 0.148s 0.001s
im_detect: 303/4024 0.148s 0.001s
im_detect: 304/4024 0.148s 0.001s
im_detect: 305/4024 0.148s 0.001s
im_detect: 306/4024 0.148s 0.001s
im_detect: 307/4024 0.148s 0.001s
im_detect: 308/4024 0.148s 0.001s
im_detect: 309/4024 0.148s 0.001s
im_detect: 310/4024 0.148s 0.001s
im_detect: 311/4024 0.148s 0.001s
im_detect: 312/4024 0.148s 0.001s
im_detect: 313/4024 0.148s 0.001s
im_detect: 314/4024 0.148s 0.001s
im_detect: 315/4024 0.148s 0.001s
im_detect: 316/4024 0.148s 0.001s
im_detect: 317/4024 0.148s 0.001s
im_detect: 318/4024 0.148s 0.001s
im_detect: 319/4024 0.148s 0.001s
im_detect: 320/4024 0.148s 0.001s
im_detect: 321/4024 0.148s 0.001s
im_detect: 322/4024 0.148s 0.001s
im_detect: 323/4024 0.148s 0.001s
im_detect: 324/4024 0.148s 0.001s
im_detect: 325/4024 0.148s 0.001s
im_detect: 326/4024 0.148s 0.001s
im_detect: 327/4024 0.148s 0.001s
im_detect: 328/4024 0.148s 0.001s
im_detect: 329/4024 0.148s 0.001s
im_detect: 330/4024 0.148s 0.001s
im_detect: 331/4024 0.148s 0.001s
im_detect: 332/4024 0.148s 0.001s
im_detect: 333/4024 0.148s 0.001s
im_detect: 334/4024 0.148s 0.001s
im_detect: 335/4024 0.148s 0.001s
im_detect: 336/4024 0.148s 0.001s
im_detect: 337/4024 0.148s 0.001s
im_detect: 338/4024 0.148s 0.001s
im_detect: 339/4024 0.148s 0.001s
im_detect: 340/4024 0.148s 0.001s
im_detect: 341/4024 0.148s 0.001s
im_detect: 342/4024 0.148s 0.001s
im_detect: 343/4024 0.148s 0.001s
im_detect: 344/4024 0.148s 0.001s
im_detect: 345/4024 0.148s 0.001s
im_detect: 346/4024 0.148s 0.001s
im_detect: 347/4024 0.148s 0.001s
im_detect: 348/4024 0.148s 0.001s
im_detect: 349/4024 0.148s 0.001s
im_detect: 350/4024 0.148s 0.001s
im_detect: 351/4024 0.148s 0.001s
im_detect: 352/4024 0.148s 0.001s
im_detect: 353/4024 0.148s 0.001s
im_detect: 354/4024 0.148s 0.001s
im_detect: 355/4024 0.148s 0.001s
im_detect: 356/4024 0.148s 0.001s
im_detect: 357/4024 0.148s 0.001s
im_detect: 358/4024 0.148s 0.001s
im_detect: 359/4024 0.148s 0.001s
im_detect: 360/4024 0.148s 0.001s
im_detect: 361/4024 0.148s 0.001s
im_detect: 362/4024 0.148s 0.001s
im_detect: 363/4024 0.148s 0.001s
im_detect: 364/4024 0.148s 0.001s
im_detect: 365/4024 0.148s 0.001s
im_detect: 366/4024 0.148s 0.001s
im_detect: 367/4024 0.148s 0.001s
im_detect: 368/4024 0.148s 0.001s
im_detect: 369/4024 0.148s 0.001s
im_detect: 370/4024 0.148s 0.001s
im_detect: 371/4024 0.148s 0.001s
im_detect: 372/4024 0.148s 0.001s
im_detect: 373/4024 0.148s 0.001s
im_detect: 374/4024 0.148s 0.001s
im_detect: 375/4024 0.148s 0.001s
im_detect: 376/4024 0.148s 0.001s
im_detect: 377/4024 0.148s 0.001s
im_detect: 378/4024 0.148s 0.001s
im_detect: 379/4024 0.148s 0.001s
im_detect: 380/4024 0.148s 0.001s
im_detect: 381/4024 0.148s 0.001s
im_detect: 382/4024 0.148s 0.001s
im_detect: 383/4024 0.148s 0.001s
im_detect: 384/4024 0.148s 0.001s
im_detect: 385/4024 0.148s 0.001s
im_detect: 386/4024 0.148s 0.001s
im_detect: 387/4024 0.148s 0.001s
im_detect: 388/4024 0.148s 0.001s
im_detect: 389/4024 0.148s 0.001s
im_detect: 390/4024 0.148s 0.001s
im_detect: 391/4024 0.148s 0.001s
im_detect: 392/4024 0.148s 0.001s
im_detect: 393/4024 0.148s 0.001s
im_detect: 394/4024 0.148s 0.001s
im_detect: 395/4024 0.148s 0.001s
im_detect: 396/4024 0.148s 0.001s
im_detect: 397/4024 0.148s 0.001s
im_detect: 398/4024 0.148s 0.001s
im_detect: 399/4024 0.148s 0.001s
im_detect: 400/4024 0.148s 0.001s
im_detect: 401/4024 0.148s 0.001s
im_detect: 402/4024 0.148s 0.001s
im_detect: 403/4024 0.148s 0.001s
im_detect: 404/4024 0.148s 0.001s
im_detect: 405/4024 0.148s 0.001s
im_detect: 406/4024 0.148s 0.001s
im_detect: 407/4024 0.148s 0.001s
im_detect: 408/4024 0.148s 0.001s
im_detect: 409/4024 0.148s 0.001s
im_detect: 410/4024 0.148s 0.001s
im_detect: 411/4024 0.148s 0.001s
im_detect: 412/4024 0.148s 0.001s
im_detect: 413/4024 0.148s 0.001s
im_detect: 414/4024 0.148s 0.001s
im_detect: 415/4024 0.148s 0.001s
im_detect: 416/4024 0.148s 0.001s
im_detect: 417/4024 0.148s 0.001s
im_detect: 418/4024 0.148s 0.001s
im_detect: 419/4024 0.148s 0.001s
im_detect: 420/4024 0.148s 0.001s
im_detect: 421/4024 0.148s 0.001s
im_detect: 422/4024 0.148s 0.001s
im_detect: 423/4024 0.148s 0.001s
im_detect: 424/4024 0.148s 0.001s
im_detect: 425/4024 0.148s 0.001s
im_detect: 426/4024 0.148s 0.001s
im_detect: 427/4024 0.148s 0.001s
im_detect: 428/4024 0.148s 0.001s
im_detect: 429/4024 0.148s 0.001s
im_detect: 430/4024 0.148s 0.001s
im_detect: 431/4024 0.148s 0.001s
im_detect: 432/4024 0.148s 0.001s
im_detect: 433/4024 0.148s 0.001s
im_detect: 434/4024 0.148s 0.001s
im_detect: 435/4024 0.148s 0.001s
im_detect: 436/4024 0.148s 0.001s
im_detect: 437/4024 0.148s 0.001s
im_detect: 438/4024 0.148s 0.001s
im_detect: 439/4024 0.148s 0.001s
im_detect: 440/4024 0.148s 0.001s
im_detect: 441/4024 0.148s 0.001s
im_detect: 442/4024 0.148s 0.001s
im_detect: 443/4024 0.148s 0.001s
im_detect: 444/4024 0.148s 0.001s
im_detect: 445/4024 0.148s 0.001s
im_detect: 446/4024 0.148s 0.001s
im_detect: 447/4024 0.148s 0.001s
im_detect: 448/4024 0.148s 0.001s
im_detect: 449/4024 0.148s 0.001s
im_detect: 450/4024 0.148s 0.001s
im_detect: 451/4024 0.148s 0.001s
im_detect: 452/4024 0.148s 0.001s
im_detect: 453/4024 0.148s 0.001s
im_detect: 454/4024 0.148s 0.001s
im_detect: 455/4024 0.148s 0.001s
im_detect: 456/4024 0.148s 0.001s
im_detect: 457/4024 0.148s 0.001s
im_detect: 458/4024 0.148s 0.001s
im_detect: 459/4024 0.148s 0.001s
im_detect: 460/4024 0.148s 0.001s
im_detect: 461/4024 0.148s 0.001s
im_detect: 462/4024 0.148s 0.001s
im_detect: 463/4024 0.148s 0.001s
im_detect: 464/4024 0.148s 0.001s
im_detect: 465/4024 0.148s 0.001s
im_detect: 466/4024 0.148s 0.001s
im_detect: 467/4024 0.148s 0.001s
im_detect: 468/4024 0.148s 0.001s
im_detect: 469/4024 0.148s 0.001s
im_detect: 470/4024 0.148s 0.001s
im_detect: 471/4024 0.148s 0.001s
im_detect: 472/4024 0.148s 0.001s
im_detect: 473/4024 0.148s 0.001s
im_detect: 474/4024 0.148s 0.001s
im_detect: 475/4024 0.148s 0.001s
im_detect: 476/4024 0.148s 0.001s
im_detect: 477/4024 0.148s 0.001s
im_detect: 478/4024 0.148s 0.001s
im_detect: 479/4024 0.148s 0.001s
im_detect: 480/4024 0.148s 0.001s
im_detect: 481/4024 0.148s 0.001s
im_detect: 482/4024 0.148s 0.001s
im_detect: 483/4024 0.148s 0.001s
im_detect: 484/4024 0.148s 0.001s
im_detect: 485/4024 0.148s 0.001s
im_detect: 486/4024 0.148s 0.001s
im_detect: 487/4024 0.148s 0.001s
im_detect: 488/4024 0.148s 0.001s
im_detect: 489/4024 0.148s 0.001s
im_detect: 490/4024 0.148s 0.001s
im_detect: 491/4024 0.148s 0.001s
im_detect: 492/4024 0.148s 0.001s
im_detect: 493/4024 0.148s 0.001s
im_detect: 494/4024 0.148s 0.001s
im_detect: 495/4024 0.148s 0.001s
im_detect: 496/4024 0.148s 0.001s
im_detect: 497/4024 0.148s 0.001s
im_detect: 498/4024 0.148s 0.001s
im_detect: 499/4024 0.148s 0.001s
im_detect: 500/4024 0.148s 0.001s
im_detect: 501/4024 0.148s 0.001s
im_detect: 502/4024 0.148s 0.001s
im_detect: 503/4024 0.148s 0.001s
im_detect: 504/4024 0.148s 0.001s
im_detect: 505/4024 0.148s 0.001s
im_detect: 506/4024 0.148s 0.001s
im_detect: 507/4024 0.148s 0.001s
im_detect: 508/4024 0.148s 0.001s
im_detect: 509/4024 0.148s 0.001s
im_detect: 510/4024 0.148s 0.001s
im_detect: 511/4024 0.148s 0.001s
im_detect: 512/4024 0.148s 0.001s
im_detect: 513/4024 0.148s 0.001s
im_detect: 514/4024 0.148s 0.001s
im_detect: 515/4024 0.148s 0.001s
im_detect: 516/4024 0.148s 0.001s
im_detect: 517/4024 0.148s 0.001s
im_detect: 518/4024 0.148s 0.001s
im_detect: 519/4024 0.148s 0.001s
im_detect: 520/4024 0.148s 0.001s
im_detect: 521/4024 0.148s 0.001s
im_detect: 522/4024 0.148s 0.001s
im_detect: 523/4024 0.148s 0.001s
im_detect: 524/4024 0.148s 0.001s
im_detect: 525/4024 0.148s 0.001s
im_detect: 526/4024 0.148s 0.001s
im_detect: 527/4024 0.148s 0.001s
im_detect: 528/4024 0.148s 0.001s
im_detect: 529/4024 0.148s 0.001s
im_detect: 530/4024 0.148s 0.001s
im_detect: 531/4024 0.148s 0.001s
im_detect: 532/4024 0.148s 0.001s
im_detect: 533/4024 0.148s 0.001s
im_detect: 534/4024 0.148s 0.001s
im_detect: 535/4024 0.148s 0.001s
im_detect: 536/4024 0.148s 0.001s
im_detect: 537/4024 0.148s 0.001s
im_detect: 538/4024 0.148s 0.001s
im_detect: 539/4024 0.148s 0.001s
im_detect: 540/4024 0.148s 0.001s
im_detect: 541/4024 0.148s 0.001s
im_detect: 542/4024 0.148s 0.001s
im_detect: 543/4024 0.148s 0.001s
im_detect: 544/4024 0.148s 0.001s
im_detect: 545/4024 0.148s 0.001s
im_detect: 546/4024 0.148s 0.001s
im_detect: 547/4024 0.148s 0.001s
im_detect: 548/4024 0.148s 0.001s
im_detect: 549/4024 0.148s 0.001s
im_detect: 550/4024 0.148s 0.001s
im_detect: 551/4024 0.148s 0.001s
im_detect: 552/4024 0.148s 0.001s
im_detect: 553/4024 0.148s 0.001s
im_detect: 554/4024 0.148s 0.001s
im_detect: 555/4024 0.148s 0.001s
im_detect: 556/4024 0.148s 0.001s
im_detect: 557/4024 0.148s 0.001s
im_detect: 558/4024 0.148s 0.001s
im_detect: 559/4024 0.148s 0.001s
im_detect: 560/4024 0.148s 0.001s
im_detect: 561/4024 0.148s 0.001s
im_detect: 562/4024 0.148s 0.001s
im_detect: 563/4024 0.148s 0.001s
im_detect: 564/4024 0.148s 0.001s
im_detect: 565/4024 0.148s 0.001s
im_detect: 566/4024 0.148s 0.001s
im_detect: 567/4024 0.148s 0.001s
im_detect: 568/4024 0.148s 0.001s
im_detect: 569/4024 0.148s 0.001s
im_detect: 570/4024 0.148s 0.001s
im_detect: 571/4024 0.148s 0.001s
im_detect: 572/4024 0.148s 0.001s
im_detect: 573/4024 0.148s 0.001s
im_detect: 574/4024 0.148s 0.001s
im_detect: 575/4024 0.148s 0.001s
im_detect: 576/4024 0.148s 0.001s
im_detect: 577/4024 0.148s 0.001s
im_detect: 578/4024 0.148s 0.001s
im_detect: 579/4024 0.148s 0.001s
im_detect: 580/4024 0.148s 0.001s
im_detect: 581/4024 0.148s 0.001s
im_detect: 582/4024 0.148s 0.001s
im_detect: 583/4024 0.148s 0.001s
im_detect: 584/4024 0.148s 0.001s
im_detect: 585/4024 0.148s 0.001s
im_detect: 586/4024 0.148s 0.001s
im_detect: 587/4024 0.148s 0.001s
im_detect: 588/4024 0.148s 0.001s
im_detect: 589/4024 0.148s 0.001s
im_detect: 590/4024 0.148s 0.001s
im_detect: 591/4024 0.148s 0.001s
im_detect: 592/4024 0.148s 0.001s
im_detect: 593/4024 0.148s 0.001s
im_detect: 594/4024 0.148s 0.001s
im_detect: 595/4024 0.148s 0.001s
im_detect: 596/4024 0.148s 0.001s
im_detect: 597/4024 0.148s 0.001s
im_detect: 598/4024 0.148s 0.001s
im_detect: 599/4024 0.148s 0.001s
im_detect: 600/4024 0.148s 0.001s
im_detect: 601/4024 0.148s 0.001s
im_detect: 602/4024 0.148s 0.001s
im_detect: 603/4024 0.148s 0.001s
im_detect: 604/4024 0.148s 0.001s
im_detect: 605/4024 0.148s 0.001s
im_detect: 606/4024 0.148s 0.001s
im_detect: 607/4024 0.148s 0.001s
im_detect: 608/4024 0.148s 0.001s
im_detect: 609/4024 0.148s 0.001s
im_detect: 610/4024 0.148s 0.001s
im_detect: 611/4024 0.148s 0.001s
im_detect: 612/4024 0.148s 0.001s
im_detect: 613/4024 0.148s 0.001s
im_detect: 614/4024 0.148s 0.001s
im_detect: 615/4024 0.148s 0.001s
im_detect: 616/4024 0.148s 0.001s
im_detect: 617/4024 0.148s 0.001s
im_detect: 618/4024 0.148s 0.001s
im_detect: 619/4024 0.148s 0.001s
im_detect: 620/4024 0.148s 0.001s
im_detect: 621/4024 0.148s 0.001s
im_detect: 622/4024 0.148s 0.001s
im_detect: 623/4024 0.148s 0.001s
im_detect: 624/4024 0.148s 0.001s
im_detect: 625/4024 0.148s 0.001s
im_detect: 626/4024 0.148s 0.001s
im_detect: 627/4024 0.148s 0.001s
im_detect: 628/4024 0.148s 0.001s
im_detect: 629/4024 0.148s 0.001s
im_detect: 630/4024 0.148s 0.001s
im_detect: 631/4024 0.148s 0.001s
im_detect: 632/4024 0.148s 0.001s
im_detect: 633/4024 0.148s 0.001s
im_detect: 634/4024 0.148s 0.001s
im_detect: 635/4024 0.148s 0.001s
im_detect: 636/4024 0.148s 0.001s
im_detect: 637/4024 0.148s 0.001s
im_detect: 638/4024 0.148s 0.001s
im_detect: 639/4024 0.148s 0.001s
im_detect: 640/4024 0.148s 0.001s
im_detect: 641/4024 0.148s 0.001s
im_detect: 642/4024 0.148s 0.001s
im_detect: 643/4024 0.148s 0.001s
im_detect: 644/4024 0.148s 0.001s
im_detect: 645/4024 0.148s 0.001s
im_detect: 646/4024 0.148s 0.001s
im_detect: 647/4024 0.148s 0.001s
im_detect: 648/4024 0.148s 0.001s
im_detect: 649/4024 0.148s 0.001s
im_detect: 650/4024 0.148s 0.001s
im_detect: 651/4024 0.148s 0.001s
im_detect: 652/4024 0.148s 0.001s
im_detect: 653/4024 0.148s 0.001s
im_detect: 654/4024 0.148s 0.001s
im_detect: 655/4024 0.148s 0.001s
im_detect: 656/4024 0.148s 0.001s
im_detect: 657/4024 0.148s 0.001s
im_detect: 658/4024 0.148s 0.001s
im_detect: 659/4024 0.148s 0.001s
im_detect: 660/4024 0.148s 0.001s
im_detect: 661/4024 0.148s 0.001s
im_detect: 662/4024 0.148s 0.001s
im_detect: 663/4024 0.148s 0.001s
im_detect: 664/4024 0.148s 0.001s
im_detect: 665/4024 0.148s 0.001s
im_detect: 666/4024 0.148s 0.001s
im_detect: 667/4024 0.148s 0.001s
im_detect: 668/4024 0.148s 0.001s
im_detect: 669/4024 0.148s 0.001s
im_detect: 670/4024 0.148s 0.001s
im_detect: 671/4024 0.148s 0.001s
im_detect: 672/4024 0.148s 0.001s
im_detect: 673/4024 0.148s 0.001s
im_detect: 674/4024 0.148s 0.001s
im_detect: 675/4024 0.148s 0.001s
im_detect: 676/4024 0.148s 0.001s
im_detect: 677/4024 0.148s 0.001s
im_detect: 678/4024 0.148s 0.001s
im_detect: 679/4024 0.148s 0.001s
im_detect: 680/4024 0.148s 0.001s
im_detect: 681/4024 0.148s 0.001s
im_detect: 682/4024 0.148s 0.001s
im_detect: 683/4024 0.148s 0.001s
im_detect: 684/4024 0.148s 0.001s
im_detect: 685/4024 0.148s 0.001s
im_detect: 686/4024 0.148s 0.001s
im_detect: 687/4024 0.148s 0.001s
im_detect: 688/4024 0.148s 0.001s
im_detect: 689/4024 0.148s 0.001s
im_detect: 690/4024 0.148s 0.001s
im_detect: 691/4024 0.148s 0.001s
im_detect: 692/4024 0.148s 0.001s
im_detect: 693/4024 0.148s 0.001s
im_detect: 694/4024 0.148s 0.001s
im_detect: 695/4024 0.148s 0.001s
im_detect: 696/4024 0.148s 0.001s
im_detect: 697/4024 0.148s 0.001s
im_detect: 698/4024 0.148s 0.001s
im_detect: 699/4024 0.148s 0.001s
im_detect: 700/4024 0.148s 0.001s
im_detect: 701/4024 0.148s 0.001s
im_detect: 702/4024 0.148s 0.001s
im_detect: 703/4024 0.148s 0.001s
im_detect: 704/4024 0.148s 0.001s
im_detect: 705/4024 0.148s 0.001s
im_detect: 706/4024 0.148s 0.001s
im_detect: 707/4024 0.148s 0.001s
im_detect: 708/4024 0.148s 0.001s
im_detect: 709/4024 0.148s 0.001s
im_detect: 710/4024 0.148s 0.001s
im_detect: 711/4024 0.148s 0.001s
im_detect: 712/4024 0.148s 0.001s
im_detect: 713/4024 0.148s 0.001s
im_detect: 714/4024 0.148s 0.001s
im_detect: 715/4024 0.148s 0.001s
im_detect: 716/4024 0.148s 0.001s
im_detect: 717/4024 0.148s 0.001s
im_detect: 718/4024 0.148s 0.001s
im_detect: 719/4024 0.148s 0.001s
im_detect: 720/4024 0.148s 0.001s
im_detect: 721/4024 0.148s 0.001s
im_detect: 722/4024 0.148s 0.001s
im_detect: 723/4024 0.148s 0.001s
im_detect: 724/4024 0.148s 0.001s
im_detect: 725/4024 0.148s 0.001s
im_detect: 726/4024 0.148s 0.001s
im_detect: 727/4024 0.148s 0.001s
im_detect: 728/4024 0.148s 0.001s
im_detect: 729/4024 0.148s 0.001s
im_detect: 730/4024 0.148s 0.001s
im_detect: 731/4024 0.148s 0.001s
im_detect: 732/4024 0.148s 0.001s
im_detect: 733/4024 0.148s 0.001s
im_detect: 734/4024 0.148s 0.001s
im_detect: 735/4024 0.148s 0.001s
im_detect: 736/4024 0.148s 0.001s
im_detect: 737/4024 0.148s 0.001s
im_detect: 738/4024 0.148s 0.001s
im_detect: 739/4024 0.148s 0.001s
im_detect: 740/4024 0.148s 0.001s
im_detect: 741/4024 0.148s 0.001s
im_detect: 742/4024 0.148s 0.001s
im_detect: 743/4024 0.148s 0.001s
im_detect: 744/4024 0.148s 0.001s
im_detect: 745/4024 0.148s 0.001s
im_detect: 746/4024 0.148s 0.001s
im_detect: 747/4024 0.148s 0.001s
im_detect: 748/4024 0.148s 0.001s
im_detect: 749/4024 0.148s 0.001s
im_detect: 750/4024 0.148s 0.001s
im_detect: 751/4024 0.148s 0.001s
im_detect: 752/4024 0.148s 0.001s
im_detect: 753/4024 0.148s 0.001s
im_detect: 754/4024 0.148s 0.001s
im_detect: 755/4024 0.148s 0.001s
im_detect: 756/4024 0.148s 0.001s
im_detect: 757/4024 0.148s 0.001s
im_detect: 758/4024 0.148s 0.001s
im_detect: 759/4024 0.148s 0.001s
im_detect: 760/4024 0.148s 0.001s
im_detect: 761/4024 0.148s 0.001s
im_detect: 762/4024 0.148s 0.001s
im_detect: 763/4024 0.148s 0.001s
im_detect: 764/4024 0.148s 0.001s
im_detect: 765/4024 0.148s 0.001s
im_detect: 766/4024 0.148s 0.001s
im_detect: 767/4024 0.148s 0.001s
im_detect: 768/4024 0.148s 0.001s
im_detect: 769/4024 0.148s 0.001s
im_detect: 770/4024 0.148s 0.001s
im_detect: 771/4024 0.148s 0.001s
im_detect: 772/4024 0.148s 0.001s
im_detect: 773/4024 0.148s 0.001s
im_detect: 774/4024 0.148s 0.001s
im_detect: 775/4024 0.148s 0.001s
im_detect: 776/4024 0.148s 0.001s
im_detect: 777/4024 0.148s 0.001s
im_detect: 778/4024 0.148s 0.001s
im_detect: 779/4024 0.148s 0.001s
im_detect: 780/4024 0.148s 0.001s
im_detect: 781/4024 0.148s 0.001s
im_detect: 782/4024 0.148s 0.001s
im_detect: 783/4024 0.148s 0.001s
im_detect: 784/4024 0.148s 0.001s
im_detect: 785/4024 0.148s 0.001s
im_detect: 786/4024 0.148s 0.001s
im_detect: 787/4024 0.148s 0.001s
im_detect: 788/4024 0.148s 0.001s
im_detect: 789/4024 0.148s 0.001s
im_detect: 790/4024 0.148s 0.001s
im_detect: 791/4024 0.148s 0.001s
im_detect: 792/4024 0.148s 0.001s
im_detect: 793/4024 0.148s 0.001s
im_detect: 794/4024 0.148s 0.001s
im_detect: 795/4024 0.148s 0.001s
im_detect: 796/4024 0.148s 0.001s
im_detect: 797/4024 0.148s 0.001s
im_detect: 798/4024 0.148s 0.001s
im_detect: 799/4024 0.148s 0.001s
im_detect: 800/4024 0.148s 0.001s
im_detect: 801/4024 0.148s 0.001s
im_detect: 802/4024 0.148s 0.001s
im_detect: 803/4024 0.148s 0.001s
im_detect: 804/4024 0.148s 0.001s
im_detect: 805/4024 0.148s 0.001s
im_detect: 806/4024 0.148s 0.001s
im_detect: 807/4024 0.148s 0.001s
im_detect: 808/4024 0.148s 0.001s
im_detect: 809/4024 0.148s 0.001s
im_detect: 810/4024 0.148s 0.001s
im_detect: 811/4024 0.148s 0.001s
im_detect: 812/4024 0.148s 0.001s
im_detect: 813/4024 0.148s 0.001s
im_detect: 814/4024 0.148s 0.001s
im_detect: 815/4024 0.148s 0.001s
im_detect: 816/4024 0.148s 0.001s
im_detect: 817/4024 0.148s 0.001s
im_detect: 818/4024 0.148s 0.001s
im_detect: 819/4024 0.148s 0.001s
im_detect: 820/4024 0.148s 0.001s
im_detect: 821/4024 0.148s 0.001s
im_detect: 822/4024 0.148s 0.001s
im_detect: 823/4024 0.148s 0.001s
im_detect: 824/4024 0.148s 0.001s
im_detect: 825/4024 0.148s 0.001s
im_detect: 826/4024 0.148s 0.001s
im_detect: 827/4024 0.148s 0.001s
im_detect: 828/4024 0.148s 0.001s
im_detect: 829/4024 0.148s 0.001s
im_detect: 830/4024 0.148s 0.001s
im_detect: 831/4024 0.148s 0.001s
im_detect: 832/4024 0.148s 0.001s
im_detect: 833/4024 0.148s 0.001s
im_detect: 834/4024 0.148s 0.001s
im_detect: 835/4024 0.148s 0.001s
im_detect: 836/4024 0.148s 0.001s
im_detect: 837/4024 0.148s 0.001s
im_detect: 838/4024 0.148s 0.001s
im_detect: 839/4024 0.148s 0.001s
im_detect: 840/4024 0.148s 0.001s
im_detect: 841/4024 0.148s 0.001s
im_detect: 842/4024 0.148s 0.001s
im_detect: 843/4024 0.148s 0.001s
im_detect: 844/4024 0.148s 0.001s
im_detect: 845/4024 0.148s 0.001s
im_detect: 846/4024 0.148s 0.001s
im_detect: 847/4024 0.148s 0.001s
im_detect: 848/4024 0.148s 0.001s
im_detect: 849/4024 0.148s 0.001s
im_detect: 850/4024 0.148s 0.001s
im_detect: 851/4024 0.148s 0.001s
im_detect: 852/4024 0.148s 0.001s
im_detect: 853/4024 0.148s 0.001s
im_detect: 854/4024 0.148s 0.001s
im_detect: 855/4024 0.148s 0.001s
im_detect: 856/4024 0.148s 0.001s
im_detect: 857/4024 0.148s 0.001s
im_detect: 858/4024 0.148s 0.001s
im_detect: 859/4024 0.148s 0.001s
im_detect: 860/4024 0.148s 0.001s
im_detect: 861/4024 0.148s 0.001s
im_detect: 862/4024 0.148s 0.001s
im_detect: 863/4024 0.148s 0.001s
im_detect: 864/4024 0.148s 0.001s
im_detect: 865/4024 0.148s 0.001s
im_detect: 866/4024 0.148s 0.001s
im_detect: 867/4024 0.148s 0.001s
im_detect: 868/4024 0.148s 0.001s
im_detect: 869/4024 0.148s 0.001s
im_detect: 870/4024 0.148s 0.001s
im_detect: 871/4024 0.148s 0.001s
im_detect: 872/4024 0.148s 0.001s
im_detect: 873/4024 0.148s 0.001s
im_detect: 874/4024 0.148s 0.001s
im_detect: 875/4024 0.148s 0.001s
im_detect: 876/4024 0.148s 0.001s
im_detect: 877/4024 0.148s 0.001s
im_detect: 878/4024 0.148s 0.001s
im_detect: 879/4024 0.148s 0.001s
im_detect: 880/4024 0.148s 0.001s
im_detect: 881/4024 0.148s 0.001s
im_detect: 882/4024 0.148s 0.001s
im_detect: 883/4024 0.148s 0.001s
im_detect: 884/4024 0.148s 0.001s
im_detect: 885/4024 0.148s 0.001s
im_detect: 886/4024 0.148s 0.001s
im_detect: 887/4024 0.148s 0.001s
im_detect: 888/4024 0.148s 0.001s
im_detect: 889/4024 0.148s 0.001s
im_detect: 890/4024 0.148s 0.001s
im_detect: 891/4024 0.148s 0.001s
im_detect: 892/4024 0.148s 0.001s
im_detect: 893/4024 0.148s 0.001s
im_detect: 894/4024 0.148s 0.001s
im_detect: 895/4024 0.148s 0.001s
im_detect: 896/4024 0.148s 0.001s
im_detect: 897/4024 0.148s 0.001s
im_detect: 898/4024 0.148s 0.001s
im_detect: 899/4024 0.148s 0.001s
im_detect: 900/4024 0.148s 0.001s
im_detect: 901/4024 0.148s 0.001s
im_detect: 902/4024 0.148s 0.001s
im_detect: 903/4024 0.148s 0.001s
im_detect: 904/4024 0.148s 0.001s
im_detect: 905/4024 0.148s 0.001s
im_detect: 906/4024 0.148s 0.001s
im_detect: 907/4024 0.148s 0.001s
im_detect: 908/4024 0.148s 0.001s
im_detect: 909/4024 0.148s 0.001s
im_detect: 910/4024 0.148s 0.001s
im_detect: 911/4024 0.148s 0.001s
im_detect: 912/4024 0.148s 0.001s
im_detect: 913/4024 0.148s 0.001s
im_detect: 914/4024 0.148s 0.001s
im_detect: 915/4024 0.148s 0.001s
im_detect: 916/4024 0.148s 0.001s
im_detect: 917/4024 0.148s 0.001s
im_detect: 918/4024 0.148s 0.001s
im_detect: 919/4024 0.148s 0.001s
im_detect: 920/4024 0.148s 0.001s
im_detect: 921/4024 0.148s 0.001s
im_detect: 922/4024 0.148s 0.001s
im_detect: 923/4024 0.148s 0.001s
im_detect: 924/4024 0.148s 0.001s
im_detect: 925/4024 0.148s 0.001s
im_detect: 926/4024 0.148s 0.001s
im_detect: 927/4024 0.148s 0.001s
im_detect: 928/4024 0.148s 0.001s
im_detect: 929/4024 0.148s 0.001s
im_detect: 930/4024 0.148s 0.001s
im_detect: 931/4024 0.148s 0.001s
im_detect: 932/4024 0.148s 0.001s
im_detect: 933/4024 0.148s 0.001s
im_detect: 934/4024 0.148s 0.001s
im_detect: 935/4024 0.148s 0.001s
im_detect: 936/4024 0.148s 0.001s
im_detect: 937/4024 0.148s 0.001s
im_detect: 938/4024 0.148s 0.001s
im_detect: 939/4024 0.148s 0.001s
im_detect: 940/4024 0.148s 0.001s
im_detect: 941/4024 0.148s 0.001s
im_detect: 942/4024 0.148s 0.001s
im_detect: 943/4024 0.148s 0.001s
im_detect: 944/4024 0.148s 0.001s
im_detect: 945/4024 0.148s 0.001s
im_detect: 946/4024 0.148s 0.001s
im_detect: 947/4024 0.148s 0.001s
im_detect: 948/4024 0.148s 0.001s
im_detect: 949/4024 0.148s 0.001s
im_detect: 950/4024 0.148s 0.001s
im_detect: 951/4024 0.148s 0.001s
im_detect: 952/4024 0.148s 0.001s
im_detect: 953/4024 0.148s 0.001s
im_detect: 954/4024 0.148s 0.001s
im_detect: 955/4024 0.148s 0.001s
im_detect: 956/4024 0.148s 0.001s
im_detect: 957/4024 0.148s 0.001s
im_detect: 958/4024 0.148s 0.001s
im_detect: 959/4024 0.148s 0.001s
im_detect: 960/4024 0.148s 0.001s
im_detect: 961/4024 0.148s 0.001s
im_detect: 962/4024 0.148s 0.001s
im_detect: 963/4024 0.148s 0.001s
im_detect: 964/4024 0.148s 0.001s
im_detect: 965/4024 0.148s 0.001s
im_detect: 966/4024 0.148s 0.001s
im_detect: 967/4024 0.148s 0.001s
im_detect: 968/4024 0.148s 0.001s
im_detect: 969/4024 0.148s 0.001s
im_detect: 970/4024 0.148s 0.001s
im_detect: 971/4024 0.148s 0.001s
im_detect: 972/4024 0.148s 0.001s
im_detect: 973/4024 0.148s 0.001s
im_detect: 974/4024 0.148s 0.001s
im_detect: 975/4024 0.148s 0.001s
im_detect: 976/4024 0.148s 0.001s
im_detect: 977/4024 0.148s 0.001s
im_detect: 978/4024 0.148s 0.001s
im_detect: 979/4024 0.148s 0.001s
im_detect: 980/4024 0.148s 0.001s
im_detect: 981/4024 0.148s 0.001s
im_detect: 982/4024 0.148s 0.001s
im_detect: 983/4024 0.148s 0.001s
im_detect: 984/4024 0.148s 0.001s
im_detect: 985/4024 0.148s 0.001s
im_detect: 986/4024 0.148s 0.001s
im_detect: 987/4024 0.148s 0.001s
im_detect: 988/4024 0.148s 0.001s
im_detect: 989/4024 0.148s 0.001s
im_detect: 990/4024 0.148s 0.001s
im_detect: 991/4024 0.148s 0.001s
im_detect: 992/4024 0.148s 0.001s
im_detect: 993/4024 0.148s 0.001s
im_detect: 994/4024 0.148s 0.001s
im_detect: 995/4024 0.148s 0.001s
im_detect: 996/4024 0.148s 0.001s
im_detect: 997/4024 0.148s 0.001s
im_detect: 998/4024 0.148s 0.001s
im_detect: 999/4024 0.148s 0.001s
im_detect: 1000/4024 0.148s 0.001s
im_detect: 1001/4024 0.148s 0.001s
im_detect: 1002/4024 0.148s 0.001s
im_detect: 1003/4024 0.148s 0.001s
im_detect: 1004/4024 0.148s 0.001s
im_detect: 1005/4024 0.148s 0.001s
im_detect: 1006/4024 0.148s 0.001s
im_detect: 1007/4024 0.148s 0.001s
im_detect: 1008/4024 0.148s 0.001s
im_detect: 1009/4024 0.148s 0.001s
im_detect: 1010/4024 0.148s 0.001s
im_detect: 1011/4024 0.148s 0.001s
im_detect: 1012/4024 0.148s 0.001s
im_detect: 1013/4024 0.148s 0.001s
im_detect: 1014/4024 0.148s 0.001s
im_detect: 1015/4024 0.148s 0.001s
im_detect: 1016/4024 0.148s 0.001s
im_detect: 1017/4024 0.148s 0.001s
im_detect: 1018/4024 0.148s 0.001s
im_detect: 1019/4024 0.148s 0.001s
im_detect: 1020/4024 0.148s 0.001s
im_detect: 1021/4024 0.148s 0.001s
im_detect: 1022/4024 0.148s 0.001s
im_detect: 1023/4024 0.148s 0.001s
im_detect: 1024/4024 0.148s 0.001s
im_detect: 1025/4024 0.148s 0.001s
im_detect: 1026/4024 0.148s 0.001s
im_detect: 1027/4024 0.148s 0.001s
im_detect: 1028/4024 0.148s 0.001s
im_detect: 1029/4024 0.148s 0.001s
im_detect: 1030/4024 0.148s 0.001s
im_detect: 1031/4024 0.148s 0.001s
im_detect: 1032/4024 0.148s 0.001s
im_detect: 1033/4024 0.148s 0.001s
im_detect: 1034/4024 0.148s 0.001s
im_detect: 1035/4024 0.148s 0.001s
im_detect: 1036/4024 0.148s 0.001s
im_detect: 1037/4024 0.148s 0.001s
im_detect: 1038/4024 0.148s 0.001s
im_detect: 1039/4024 0.148s 0.001s
im_detect: 1040/4024 0.148s 0.001s
im_detect: 1041/4024 0.148s 0.001s
im_detect: 1042/4024 0.148s 0.001s
im_detect: 1043/4024 0.148s 0.001s
im_detect: 1044/4024 0.148s 0.001s
im_detect: 1045/4024 0.148s 0.001s
im_detect: 1046/4024 0.148s 0.001s
im_detect: 1047/4024 0.148s 0.001s
im_detect: 1048/4024 0.148s 0.001s
im_detect: 1049/4024 0.148s 0.001s
im_detect: 1050/4024 0.148s 0.001s
im_detect: 1051/4024 0.148s 0.001s
im_detect: 1052/4024 0.148s 0.001s
im_detect: 1053/4024 0.148s 0.001s
im_detect: 1054/4024 0.148s 0.001s
im_detect: 1055/4024 0.148s 0.001s
im_detect: 1056/4024 0.148s 0.001s
im_detect: 1057/4024 0.148s 0.001s
im_detect: 1058/4024 0.148s 0.001s
im_detect: 1059/4024 0.148s 0.001s
im_detect: 1060/4024 0.148s 0.001s
im_detect: 1061/4024 0.148s 0.001s
im_detect: 1062/4024 0.148s 0.001s
im_detect: 1063/4024 0.148s 0.001s
im_detect: 1064/4024 0.148s 0.001s
im_detect: 1065/4024 0.148s 0.001s
im_detect: 1066/4024 0.148s 0.001s
im_detect: 1067/4024 0.148s 0.001s
im_detect: 1068/4024 0.148s 0.001s
im_detect: 1069/4024 0.148s 0.001s
im_detect: 1070/4024 0.148s 0.001s
im_detect: 1071/4024 0.148s 0.001s
im_detect: 1072/4024 0.148s 0.001s
im_detect: 1073/4024 0.148s 0.001s
im_detect: 1074/4024 0.148s 0.001s
im_detect: 1075/4024 0.148s 0.001s
im_detect: 1076/4024 0.148s 0.001s
im_detect: 1077/4024 0.148s 0.001s
im_detect: 1078/4024 0.148s 0.001s
im_detect: 1079/4024 0.148s 0.001s
im_detect: 1080/4024 0.148s 0.001s
im_detect: 1081/4024 0.148s 0.001s
im_detect: 1082/4024 0.148s 0.001s
im_detect: 1083/4024 0.148s 0.001s
im_detect: 1084/4024 0.148s 0.001s
im_detect: 1085/4024 0.148s 0.001s
im_detect: 1086/4024 0.148s 0.001s
im_detect: 1087/4024 0.148s 0.001s
im_detect: 1088/4024 0.148s 0.001s
im_detect: 1089/4024 0.148s 0.001s
im_detect: 1090/4024 0.148s 0.001s
im_detect: 1091/4024 0.148s 0.001s
im_detect: 1092/4024 0.148s 0.001s
im_detect: 1093/4024 0.148s 0.001s
im_detect: 1094/4024 0.148s 0.001s
im_detect: 1095/4024 0.148s 0.001s
im_detect: 1096/4024 0.148s 0.001s
im_detect: 1097/4024 0.148s 0.001s
im_detect: 1098/4024 0.148s 0.001s
im_detect: 1099/4024 0.148s 0.001s
im_detect: 1100/4024 0.148s 0.001s
im_detect: 1101/4024 0.148s 0.001s
im_detect: 1102/4024 0.148s 0.001s
im_detect: 1103/4024 0.148s 0.001s
im_detect: 1104/4024 0.148s 0.001s
im_detect: 1105/4024 0.148s 0.001s
im_detect: 1106/4024 0.148s 0.001s
im_detect: 1107/4024 0.148s 0.001s
im_detect: 1108/4024 0.148s 0.001s
im_detect: 1109/4024 0.148s 0.001s
im_detect: 1110/4024 0.148s 0.001s
im_detect: 1111/4024 0.148s 0.001s
im_detect: 1112/4024 0.148s 0.001s
im_detect: 1113/4024 0.148s 0.001s
im_detect: 1114/4024 0.148s 0.001s
im_detect: 1115/4024 0.148s 0.001s
im_detect: 1116/4024 0.148s 0.001s
im_detect: 1117/4024 0.148s 0.001s
im_detect: 1118/4024 0.148s 0.001s
im_detect: 1119/4024 0.148s 0.001s
im_detect: 1120/4024 0.148s 0.001s
im_detect: 1121/4024 0.148s 0.001s
im_detect: 1122/4024 0.148s 0.001s
im_detect: 1123/4024 0.148s 0.001s
im_detect: 1124/4024 0.148s 0.001s
im_detect: 1125/4024 0.148s 0.001s
im_detect: 1126/4024 0.148s 0.001s
im_detect: 1127/4024 0.148s 0.001s
im_detect: 1128/4024 0.148s 0.001s
im_detect: 1129/4024 0.148s 0.001s
im_detect: 1130/4024 0.148s 0.001s
im_detect: 1131/4024 0.148s 0.001s
im_detect: 1132/4024 0.148s 0.001s
im_detect: 1133/4024 0.148s 0.001s
im_detect: 1134/4024 0.148s 0.001s
im_detect: 1135/4024 0.148s 0.001s
im_detect: 1136/4024 0.148s 0.001s
im_detect: 1137/4024 0.148s 0.001s
im_detect: 1138/4024 0.148s 0.001s
im_detect: 1139/4024 0.148s 0.001s
im_detect: 1140/4024 0.148s 0.001s
im_detect: 1141/4024 0.148s 0.001s
im_detect: 1142/4024 0.148s 0.001s
im_detect: 1143/4024 0.148s 0.001s
im_detect: 1144/4024 0.148s 0.001s
im_detect: 1145/4024 0.148s 0.001s
im_detect: 1146/4024 0.148s 0.001s
im_detect: 1147/4024 0.148s 0.001s
im_detect: 1148/4024 0.148s 0.001s
im_detect: 1149/4024 0.148s 0.001s
im_detect: 1150/4024 0.148s 0.001s
im_detect: 1151/4024 0.148s 0.001s
im_detect: 1152/4024 0.148s 0.001s
im_detect: 1153/4024 0.148s 0.001s
im_detect: 1154/4024 0.148s 0.001s
im_detect: 1155/4024 0.148s 0.001s
im_detect: 1156/4024 0.148s 0.001s
im_detect: 1157/4024 0.148s 0.001s
im_detect: 1158/4024 0.148s 0.001s
im_detect: 1159/4024 0.148s 0.001s
im_detect: 1160/4024 0.148s 0.001s
im_detect: 1161/4024 0.148s 0.001s
im_detect: 1162/4024 0.148s 0.001s
im_detect: 1163/4024 0.148s 0.001s
im_detect: 1164/4024 0.148s 0.001s
im_detect: 1165/4024 0.148s 0.001s
im_detect: 1166/4024 0.148s 0.001s
im_detect: 1167/4024 0.148s 0.001s
im_detect: 1168/4024 0.148s 0.001s
im_detect: 1169/4024 0.148s 0.001s
im_detect: 1170/4024 0.148s 0.001s
im_detect: 1171/4024 0.148s 0.001s
im_detect: 1172/4024 0.148s 0.001s
im_detect: 1173/4024 0.148s 0.001s
im_detect: 1174/4024 0.148s 0.001s
im_detect: 1175/4024 0.148s 0.001s
im_detect: 1176/4024 0.148s 0.001s
im_detect: 1177/4024 0.148s 0.001s
im_detect: 1178/4024 0.148s 0.001s
im_detect: 1179/4024 0.148s 0.001s
im_detect: 1180/4024 0.148s 0.001s
im_detect: 1181/4024 0.148s 0.001s
im_detect: 1182/4024 0.148s 0.001s
im_detect: 1183/4024 0.148s 0.001s
im_detect: 1184/4024 0.148s 0.001s
im_detect: 1185/4024 0.148s 0.001s
im_detect: 1186/4024 0.148s 0.001s
im_detect: 1187/4024 0.148s 0.001s
im_detect: 1188/4024 0.148s 0.001s
im_detect: 1189/4024 0.148s 0.001s
im_detect: 1190/4024 0.148s 0.001s
im_detect: 1191/4024 0.148s 0.001s
im_detect: 1192/4024 0.148s 0.001s
im_detect: 1193/4024 0.148s 0.001s
im_detect: 1194/4024 0.148s 0.001s
im_detect: 1195/4024 0.148s 0.001s
im_detect: 1196/4024 0.148s 0.001s
im_detect: 1197/4024 0.148s 0.001s
im_detect: 1198/4024 0.148s 0.001s
im_detect: 1199/4024 0.148s 0.001s
im_detect: 1200/4024 0.148s 0.001s
im_detect: 1201/4024 0.148s 0.001s
im_detect: 1202/4024 0.148s 0.001s
im_detect: 1203/4024 0.148s 0.001s
im_detect: 1204/4024 0.148s 0.001s
im_detect: 1205/4024 0.148s 0.001s
im_detect: 1206/4024 0.148s 0.001s
im_detect: 1207/4024 0.148s 0.001s
im_detect: 1208/4024 0.148s 0.001s
im_detect: 1209/4024 0.148s 0.001s
im_detect: 1210/4024 0.148s 0.001s
im_detect: 1211/4024 0.148s 0.001s
im_detect: 1212/4024 0.148s 0.001s
im_detect: 1213/4024 0.148s 0.001s
im_detect: 1214/4024 0.148s 0.001s
im_detect: 1215/4024 0.148s 0.001s
im_detect: 1216/4024 0.148s 0.001s
im_detect: 1217/4024 0.148s 0.001s
im_detect: 1218/4024 0.148s 0.001s
im_detect: 1219/4024 0.148s 0.001s
im_detect: 1220/4024 0.148s 0.001s
im_detect: 1221/4024 0.148s 0.001s
im_detect: 1222/4024 0.148s 0.001s
im_detect: 1223/4024 0.148s 0.001s
im_detect: 1224/4024 0.148s 0.001s
im_detect: 1225/4024 0.148s 0.001s
im_detect: 1226/4024 0.148s 0.001s
im_detect: 1227/4024 0.148s 0.001s
im_detect: 1228/4024 0.148s 0.001s
im_detect: 1229/4024 0.148s 0.001s
im_detect: 1230/4024 0.148s 0.001s
im_detect: 1231/4024 0.148s 0.001s
im_detect: 1232/4024 0.148s 0.001s
im_detect: 1233/4024 0.148s 0.001s
im_detect: 1234/4024 0.148s 0.001s
im_detect: 1235/4024 0.148s 0.001s
im_detect: 1236/4024 0.148s 0.001s
im_detect: 1237/4024 0.148s 0.001s
im_detect: 1238/4024 0.148s 0.001s
im_detect: 1239/4024 0.148s 0.001s
im_detect: 1240/4024 0.148s 0.001s
im_detect: 1241/4024 0.148s 0.001s
im_detect: 1242/4024 0.148s 0.001s
im_detect: 1243/4024 0.148s 0.001s
im_detect: 1244/4024 0.148s 0.001s
im_detect: 1245/4024 0.148s 0.001s
im_detect: 1246/4024 0.148s 0.001s
im_detect: 1247/4024 0.148s 0.001s
im_detect: 1248/4024 0.148s 0.001s
im_detect: 1249/4024 0.148s 0.001s
im_detect: 1250/4024 0.148s 0.001s
im_detect: 1251/4024 0.148s 0.001s
im_detect: 1252/4024 0.148s 0.001s
im_detect: 1253/4024 0.148s 0.001s
im_detect: 1254/4024 0.148s 0.001s
im_detect: 1255/4024 0.148s 0.001s
im_detect: 1256/4024 0.148s 0.001s
im_detect: 1257/4024 0.148s 0.001s
im_detect: 1258/4024 0.148s 0.001s
im_detect: 1259/4024 0.148s 0.001s
im_detect: 1260/4024 0.148s 0.001s
im_detect: 1261/4024 0.148s 0.001s
im_detect: 1262/4024 0.148s 0.001s
im_detect: 1263/4024 0.148s 0.001s
im_detect: 1264/4024 0.148s 0.001s
im_detect: 1265/4024 0.148s 0.001s
im_detect: 1266/4024 0.148s 0.001s
im_detect: 1267/4024 0.148s 0.001s
im_detect: 1268/4024 0.148s 0.001s
im_detect: 1269/4024 0.148s 0.001s
im_detect: 1270/4024 0.148s 0.001s
im_detect: 1271/4024 0.148s 0.001s
im_detect: 1272/4024 0.148s 0.001s
im_detect: 1273/4024 0.148s 0.001s
im_detect: 1274/4024 0.148s 0.001s
im_detect: 1275/4024 0.148s 0.001s
im_detect: 1276/4024 0.148s 0.001s
im_detect: 1277/4024 0.148s 0.001s
im_detect: 1278/4024 0.148s 0.001s
im_detect: 1279/4024 0.148s 0.001s
im_detect: 1280/4024 0.148s 0.001s
im_detect: 1281/4024 0.148s 0.001s
im_detect: 1282/4024 0.148s 0.001s
im_detect: 1283/4024 0.148s 0.001s
im_detect: 1284/4024 0.148s 0.001s
im_detect: 1285/4024 0.148s 0.001s
im_detect: 1286/4024 0.148s 0.001s
im_detect: 1287/4024 0.148s 0.001s
im_detect: 1288/4024 0.148s 0.001s
im_detect: 1289/4024 0.148s 0.001s
im_detect: 1290/4024 0.148s 0.001s
im_detect: 1291/4024 0.148s 0.001s
im_detect: 1292/4024 0.148s 0.001s
im_detect: 1293/4024 0.148s 0.001s
im_detect: 1294/4024 0.148s 0.001s
im_detect: 1295/4024 0.148s 0.001s
im_detect: 1296/4024 0.148s 0.001s
im_detect: 1297/4024 0.148s 0.001s
im_detect: 1298/4024 0.148s 0.001s
im_detect: 1299/4024 0.148s 0.001s
im_detect: 1300/4024 0.148s 0.001s
im_detect: 1301/4024 0.148s 0.001s
im_detect: 1302/4024 0.148s 0.001s
im_detect: 1303/4024 0.148s 0.001s
im_detect: 1304/4024 0.148s 0.001s
im_detect: 1305/4024 0.148s 0.001s
im_detect: 1306/4024 0.148s 0.001s
im_detect: 1307/4024 0.148s 0.001s
im_detect: 1308/4024 0.148s 0.001s
im_detect: 1309/4024 0.148s 0.001s
im_detect: 1310/4024 0.148s 0.001s
im_detect: 1311/4024 0.148s 0.001s
im_detect: 1312/4024 0.148s 0.001s
im_detect: 1313/4024 0.148s 0.001s
im_detect: 1314/4024 0.148s 0.001s
im_detect: 1315/4024 0.148s 0.001s
im_detect: 1316/4024 0.148s 0.001s
im_detect: 1317/4024 0.148s 0.001s
im_detect: 1318/4024 0.148s 0.001s
im_detect: 1319/4024 0.148s 0.001s
im_detect: 1320/4024 0.148s 0.001s
im_detect: 1321/4024 0.148s 0.001s
im_detect: 1322/4024 0.148s 0.001s
im_detect: 1323/4024 0.148s 0.001s
im_detect: 1324/4024 0.148s 0.001s
im_detect: 1325/4024 0.148s 0.001s
im_detect: 1326/4024 0.148s 0.001s
im_detect: 1327/4024 0.148s 0.001s
im_detect: 1328/4024 0.148s 0.001s
im_detect: 1329/4024 0.148s 0.001s
im_detect: 1330/4024 0.148s 0.001s
im_detect: 1331/4024 0.148s 0.001s
im_detect: 1332/4024 0.148s 0.001s
im_detect: 1333/4024 0.148s 0.001s
im_detect: 1334/4024 0.148s 0.001s
im_detect: 1335/4024 0.148s 0.001s
im_detect: 1336/4024 0.148s 0.001s
im_detect: 1337/4024 0.148s 0.001s
im_detect: 1338/4024 0.148s 0.001s
im_detect: 1339/4024 0.148s 0.001s
im_detect: 1340/4024 0.148s 0.001s
im_detect: 1341/4024 0.148s 0.001s
im_detect: 1342/4024 0.148s 0.001s
im_detect: 1343/4024 0.148s 0.001s
im_detect: 1344/4024 0.148s 0.001s
im_detect: 1345/4024 0.148s 0.001s
im_detect: 1346/4024 0.148s 0.001s
im_detect: 1347/4024 0.148s 0.001s
im_detect: 1348/4024 0.148s 0.001s
im_detect: 1349/4024 0.148s 0.001s
im_detect: 1350/4024 0.148s 0.001s
im_detect: 1351/4024 0.148s 0.001s
im_detect: 1352/4024 0.148s 0.001s
im_detect: 1353/4024 0.148s 0.001s
im_detect: 1354/4024 0.148s 0.001s
im_detect: 1355/4024 0.148s 0.001s
im_detect: 1356/4024 0.148s 0.001s
im_detect: 1357/4024 0.148s 0.001s
im_detect: 1358/4024 0.148s 0.001s
im_detect: 1359/4024 0.148s 0.001s
im_detect: 1360/4024 0.148s 0.001s
im_detect: 1361/4024 0.148s 0.001s
im_detect: 1362/4024 0.148s 0.001s
im_detect: 1363/4024 0.148s 0.001s
im_detect: 1364/4024 0.148s 0.001s
im_detect: 1365/4024 0.148s 0.001s
im_detect: 1366/4024 0.148s 0.001s
im_detect: 1367/4024 0.148s 0.001s
im_detect: 1368/4024 0.148s 0.001s
im_detect: 1369/4024 0.148s 0.001s
im_detect: 1370/4024 0.148s 0.001s
im_detect: 1371/4024 0.148s 0.001s
im_detect: 1372/4024 0.148s 0.001s
im_detect: 1373/4024 0.148s 0.001s
im_detect: 1374/4024 0.148s 0.001s
im_detect: 1375/4024 0.148s 0.001s
im_detect: 1376/4024 0.148s 0.001s
im_detect: 1377/4024 0.148s 0.001s
im_detect: 1378/4024 0.148s 0.001s
im_detect: 1379/4024 0.148s 0.001s
im_detect: 1380/4024 0.148s 0.001s
im_detect: 1381/4024 0.148s 0.001s
im_detect: 1382/4024 0.148s 0.001s
im_detect: 1383/4024 0.148s 0.001s
im_detect: 1384/4024 0.148s 0.001s
im_detect: 1385/4024 0.148s 0.001s
im_detect: 1386/4024 0.148s 0.001s
im_detect: 1387/4024 0.148s 0.001s
im_detect: 1388/4024 0.148s 0.001s
im_detect: 1389/4024 0.148s 0.001s
im_detect: 1390/4024 0.148s 0.001s
im_detect: 1391/4024 0.148s 0.001s
im_detect: 1392/4024 0.148s 0.001s
im_detect: 1393/4024 0.148s 0.001s
im_detect: 1394/4024 0.148s 0.001s
im_detect: 1395/4024 0.148s 0.001s
im_detect: 1396/4024 0.148s 0.001s
im_detect: 1397/4024 0.148s 0.001s
im_detect: 1398/4024 0.148s 0.001s
im_detect: 1399/4024 0.148s 0.001s
im_detect: 1400/4024 0.148s 0.001s
im_detect: 1401/4024 0.148s 0.001s
im_detect: 1402/4024 0.148s 0.001s
im_detect: 1403/4024 0.148s 0.001s
im_detect: 1404/4024 0.148s 0.001s
im_detect: 1405/4024 0.148s 0.001s
im_detect: 1406/4024 0.148s 0.001s
im_detect: 1407/4024 0.148s 0.001s
im_detect: 1408/4024 0.148s 0.001s
im_detect: 1409/4024 0.148s 0.001s
im_detect: 1410/4024 0.148s 0.001s
im_detect: 1411/4024 0.148s 0.001s
im_detect: 1412/4024 0.148s 0.001s
im_detect: 1413/4024 0.148s 0.001s
im_detect: 1414/4024 0.148s 0.001s
im_detect: 1415/4024 0.148s 0.001s
im_detect: 1416/4024 0.148s 0.001s
im_detect: 1417/4024 0.148s 0.001s
im_detect: 1418/4024 0.148s 0.001s
im_detect: 1419/4024 0.148s 0.001s
im_detect: 1420/4024 0.148s 0.001s
im_detect: 1421/4024 0.148s 0.001s
im_detect: 1422/4024 0.148s 0.001s
im_detect: 1423/4024 0.148s 0.001s
im_detect: 1424/4024 0.148s 0.001s
im_detect: 1425/4024 0.148s 0.001s
im_detect: 1426/4024 0.148s 0.001s
im_detect: 1427/4024 0.148s 0.001s
im_detect: 1428/4024 0.148s 0.001s
im_detect: 1429/4024 0.148s 0.001s
im_detect: 1430/4024 0.148s 0.001s
im_detect: 1431/4024 0.148s 0.001s
im_detect: 1432/4024 0.148s 0.001s
im_detect: 1433/4024 0.148s 0.001s
im_detect: 1434/4024 0.148s 0.001s
im_detect: 1435/4024 0.148s 0.001s
im_detect: 1436/4024 0.148s 0.001s
im_detect: 1437/4024 0.148s 0.001s
im_detect: 1438/4024 0.148s 0.001s
im_detect: 1439/4024 0.148s 0.001s
im_detect: 1440/4024 0.148s 0.001s
im_detect: 1441/4024 0.148s 0.001s
im_detect: 1442/4024 0.148s 0.001s
im_detect: 1443/4024 0.148s 0.001s
im_detect: 1444/4024 0.148s 0.001s
im_detect: 1445/4024 0.148s 0.001s
im_detect: 1446/4024 0.148s 0.001s
im_detect: 1447/4024 0.148s 0.001s
im_detect: 1448/4024 0.148s 0.001s
im_detect: 1449/4024 0.148s 0.001s
im_detect: 1450/4024 0.148s 0.001s
im_detect: 1451/4024 0.148s 0.001s
im_detect: 1452/4024 0.148s 0.001s
im_detect: 1453/4024 0.148s 0.001s
im_detect: 1454/4024 0.148s 0.001s
im_detect: 1455/4024 0.148s 0.001s
im_detect: 1456/4024 0.148s 0.001s
im_detect: 1457/4024 0.148s 0.001s
im_detect: 1458/4024 0.148s 0.001s
im_detect: 1459/4024 0.148s 0.001s
im_detect: 1460/4024 0.148s 0.001s
im_detect: 1461/4024 0.148s 0.001s
im_detect: 1462/4024 0.148s 0.001s
im_detect: 1463/4024 0.148s 0.001s
im_detect: 1464/4024 0.148s 0.001s
im_detect: 1465/4024 0.148s 0.001s
im_detect: 1466/4024 0.148s 0.001s
im_detect: 1467/4024 0.148s 0.001s
im_detect: 1468/4024 0.148s 0.001s
im_detect: 1469/4024 0.148s 0.001s
im_detect: 1470/4024 0.148s 0.001s
im_detect: 1471/4024 0.148s 0.001s
im_detect: 1472/4024 0.148s 0.001s
im_detect: 1473/4024 0.148s 0.001s
im_detect: 1474/4024 0.148s 0.001s
im_detect: 1475/4024 0.148s 0.001s
im_detect: 1476/4024 0.148s 0.001s
im_detect: 1477/4024 0.148s 0.001s
im_detect: 1478/4024 0.148s 0.001s
im_detect: 1479/4024 0.148s 0.001s
im_detect: 1480/4024 0.148s 0.001s
im_detect: 1481/4024 0.148s 0.001s
im_detect: 1482/4024 0.148s 0.001s
im_detect: 1483/4024 0.148s 0.001s
im_detect: 1484/4024 0.148s 0.001s
im_detect: 1485/4024 0.148s 0.001s
im_detect: 1486/4024 0.148s 0.001s
im_detect: 1487/4024 0.148s 0.001s
im_detect: 1488/4024 0.148s 0.001s
im_detect: 1489/4024 0.148s 0.001s
im_detect: 1490/4024 0.148s 0.001s
im_detect: 1491/4024 0.148s 0.001s
im_detect: 1492/4024 0.148s 0.001s
im_detect: 1493/4024 0.148s 0.001s
im_detect: 1494/4024 0.148s 0.001s
im_detect: 1495/4024 0.148s 0.001s
im_detect: 1496/4024 0.148s 0.001s
im_detect: 1497/4024 0.148s 0.001s
im_detect: 1498/4024 0.148s 0.001s
im_detect: 1499/4024 0.148s 0.001s
im_detect: 1500/4024 0.148s 0.001s
im_detect: 1501/4024 0.148s 0.001s
im_detect: 1502/4024 0.148s 0.001s
im_detect: 1503/4024 0.148s 0.001s
im_detect: 1504/4024 0.148s 0.001s
im_detect: 1505/4024 0.148s 0.001s
im_detect: 1506/4024 0.148s 0.001s
im_detect: 1507/4024 0.148s 0.001s
im_detect: 1508/4024 0.148s 0.001s
im_detect: 1509/4024 0.148s 0.001s
im_detect: 1510/4024 0.148s 0.001s
im_detect: 1511/4024 0.148s 0.001s
im_detect: 1512/4024 0.148s 0.001s
im_detect: 1513/4024 0.148s 0.001s
im_detect: 1514/4024 0.148s 0.001s
im_detect: 1515/4024 0.148s 0.001s
im_detect: 1516/4024 0.148s 0.001s
im_detect: 1517/4024 0.148s 0.001s
im_detect: 1518/4024 0.148s 0.001s
im_detect: 1519/4024 0.148s 0.001s
im_detect: 1520/4024 0.148s 0.001s
im_detect: 1521/4024 0.148s 0.001s
im_detect: 1522/4024 0.148s 0.001s
im_detect: 1523/4024 0.148s 0.001s
im_detect: 1524/4024 0.148s 0.001s
im_detect: 1525/4024 0.148s 0.001s
im_detect: 1526/4024 0.148s 0.001s
im_detect: 1527/4024 0.148s 0.001s
im_detect: 1528/4024 0.148s 0.001s
im_detect: 1529/4024 0.148s 0.001s
im_detect: 1530/4024 0.148s 0.001s
im_detect: 1531/4024 0.148s 0.001s
im_detect: 1532/4024 0.148s 0.001s
im_detect: 1533/4024 0.148s 0.001s
im_detect: 1534/4024 0.148s 0.001s
im_detect: 1535/4024 0.148s 0.001s
im_detect: 1536/4024 0.148s 0.001s
im_detect: 1537/4024 0.148s 0.001s
im_detect: 1538/4024 0.148s 0.001s
im_detect: 1539/4024 0.148s 0.001s
im_detect: 1540/4024 0.148s 0.001s
im_detect: 1541/4024 0.148s 0.001s
im_detect: 1542/4024 0.148s 0.001s
im_detect: 1543/4024 0.148s 0.001s
im_detect: 1544/4024 0.148s 0.001s
im_detect: 1545/4024 0.148s 0.001s
im_detect: 1546/4024 0.148s 0.001s
im_detect: 1547/4024 0.148s 0.001s
im_detect: 1548/4024 0.148s 0.001s
im_detect: 1549/4024 0.148s 0.001s
im_detect: 1550/4024 0.148s 0.001s
im_detect: 1551/4024 0.148s 0.001s
im_detect: 1552/4024 0.148s 0.001s
im_detect: 1553/4024 0.148s 0.001s
im_detect: 1554/4024 0.148s 0.001s
im_detect: 1555/4024 0.148s 0.001s
im_detect: 1556/4024 0.148s 0.001s
im_detect: 1557/4024 0.148s 0.001s
im_detect: 1558/4024 0.148s 0.001s
im_detect: 1559/4024 0.148s 0.001s
im_detect: 1560/4024 0.148s 0.001s
im_detect: 1561/4024 0.148s 0.001s
im_detect: 1562/4024 0.148s 0.001s
im_detect: 1563/4024 0.148s 0.001s
im_detect: 1564/4024 0.148s 0.001s
im_detect: 1565/4024 0.148s 0.001s
im_detect: 1566/4024 0.148s 0.001s
im_detect: 1567/4024 0.148s 0.001s
im_detect: 1568/4024 0.148s 0.001s
im_detect: 1569/4024 0.148s 0.001s
im_detect: 1570/4024 0.148s 0.001s
im_detect: 1571/4024 0.148s 0.001s
im_detect: 1572/4024 0.148s 0.001s
im_detect: 1573/4024 0.148s 0.001s
im_detect: 1574/4024 0.148s 0.001s
im_detect: 1575/4024 0.148s 0.001s
im_detect: 1576/4024 0.148s 0.001s
im_detect: 1577/4024 0.148s 0.001s
im_detect: 1578/4024 0.148s 0.001s
im_detect: 1579/4024 0.148s 0.001s
im_detect: 1580/4024 0.148s 0.001s
im_detect: 1581/4024 0.148s 0.001s
im_detect: 1582/4024 0.148s 0.001s
im_detect: 1583/4024 0.148s 0.001s
im_detect: 1584/4024 0.148s 0.001s
im_detect: 1585/4024 0.148s 0.001s
im_detect: 1586/4024 0.148s 0.001s
im_detect: 1587/4024 0.148s 0.001s
im_detect: 1588/4024 0.148s 0.001s
im_detect: 1589/4024 0.148s 0.001s
im_detect: 1590/4024 0.148s 0.001s
im_detect: 1591/4024 0.148s 0.001s
im_detect: 1592/4024 0.148s 0.001s
im_detect: 1593/4024 0.148s 0.001s
im_detect: 1594/4024 0.148s 0.001s
im_detect: 1595/4024 0.148s 0.001s
im_detect: 1596/4024 0.148s 0.001s
im_detect: 1597/4024 0.148s 0.001s
im_detect: 1598/4024 0.148s 0.001s
im_detect: 1599/4024 0.148s 0.001s
im_detect: 1600/4024 0.148s 0.001s
im_detect: 1601/4024 0.148s 0.001s
im_detect: 1602/4024 0.148s 0.001s
im_detect: 1603/4024 0.148s 0.001s
im_detect: 1604/4024 0.148s 0.001s
im_detect: 1605/4024 0.148s 0.001s
im_detect: 1606/4024 0.148s 0.001s
im_detect: 1607/4024 0.148s 0.001s
im_detect: 1608/4024 0.148s 0.001s
im_detect: 1609/4024 0.148s 0.001s
im_detect: 1610/4024 0.148s 0.001s
im_detect: 1611/4024 0.148s 0.001s
im_detect: 1612/4024 0.148s 0.001s
im_detect: 1613/4024 0.148s 0.001s
im_detect: 1614/4024 0.148s 0.001s
im_detect: 1615/4024 0.148s 0.001s
im_detect: 1616/4024 0.148s 0.001s
im_detect: 1617/4024 0.148s 0.001s
im_detect: 1618/4024 0.148s 0.001s
im_detect: 1619/4024 0.148s 0.001s
im_detect: 1620/4024 0.148s 0.001s
im_detect: 1621/4024 0.148s 0.001s
im_detect: 1622/4024 0.148s 0.001s
im_detect: 1623/4024 0.148s 0.001s
im_detect: 1624/4024 0.148s 0.001s
im_detect: 1625/4024 0.148s 0.001s
im_detect: 1626/4024 0.148s 0.001s
im_detect: 1627/4024 0.148s 0.001s
im_detect: 1628/4024 0.148s 0.001s
im_detect: 1629/4024 0.148s 0.001s
im_detect: 1630/4024 0.148s 0.001s
im_detect: 1631/4024 0.148s 0.001s
im_detect: 1632/4024 0.148s 0.001s
im_detect: 1633/4024 0.148s 0.001s
im_detect: 1634/4024 0.148s 0.001s
im_detect: 1635/4024 0.148s 0.001s
im_detect: 1636/4024 0.148s 0.001s
im_detect: 1637/4024 0.148s 0.001s
im_detect: 1638/4024 0.148s 0.001s
im_detect: 1639/4024 0.148s 0.001s
im_detect: 1640/4024 0.148s 0.001s
im_detect: 1641/4024 0.148s 0.001s
im_detect: 1642/4024 0.148s 0.001s
im_detect: 1643/4024 0.148s 0.001s
im_detect: 1644/4024 0.148s 0.001s
im_detect: 1645/4024 0.148s 0.001s
im_detect: 1646/4024 0.148s 0.001s
im_detect: 1647/4024 0.148s 0.001s
im_detect: 1648/4024 0.148s 0.001s
im_detect: 1649/4024 0.148s 0.001s
im_detect: 1650/4024 0.148s 0.001s
im_detect: 1651/4024 0.148s 0.001s
im_detect: 1652/4024 0.148s 0.001s
im_detect: 1653/4024 0.148s 0.001s
im_detect: 1654/4024 0.148s 0.001s
im_detect: 1655/4024 0.148s 0.001s
im_detect: 1656/4024 0.148s 0.001s
im_detect: 1657/4024 0.148s 0.001s
im_detect: 1658/4024 0.148s 0.001s
im_detect: 1659/4024 0.148s 0.001s
im_detect: 1660/4024 0.148s 0.001s
im_detect: 1661/4024 0.148s 0.001s
im_detect: 1662/4024 0.148s 0.001s
im_detect: 1663/4024 0.148s 0.001s
im_detect: 1664/4024 0.148s 0.001s
im_detect: 1665/4024 0.148s 0.001s
im_detect: 1666/4024 0.148s 0.001s
im_detect: 1667/4024 0.148s 0.001s
im_detect: 1668/4024 0.148s 0.001s
im_detect: 1669/4024 0.148s 0.001s
im_detect: 1670/4024 0.148s 0.001s
im_detect: 1671/4024 0.148s 0.001s
im_detect: 1672/4024 0.148s 0.001s
im_detect: 1673/4024 0.148s 0.001s
im_detect: 1674/4024 0.148s 0.001s
im_detect: 1675/4024 0.148s 0.001s
im_detect: 1676/4024 0.148s 0.001s
im_detect: 1677/4024 0.148s 0.001s
im_detect: 1678/4024 0.148s 0.001s
im_detect: 1679/4024 0.148s 0.001s
im_detect: 1680/4024 0.148s 0.001s
im_detect: 1681/4024 0.148s 0.001s
im_detect: 1682/4024 0.148s 0.001s
im_detect: 1683/4024 0.148s 0.001s
im_detect: 1684/4024 0.148s 0.001s
im_detect: 1685/4024 0.148s 0.001s
im_detect: 1686/4024 0.148s 0.001s
im_detect: 1687/4024 0.148s 0.001s
im_detect: 1688/4024 0.148s 0.001s
im_detect: 1689/4024 0.148s 0.001s
im_detect: 1690/4024 0.148s 0.001s
im_detect: 1691/4024 0.148s 0.001s
im_detect: 1692/4024 0.148s 0.001s
im_detect: 1693/4024 0.148s 0.001s
im_detect: 1694/4024 0.148s 0.001s
im_detect: 1695/4024 0.148s 0.001s
im_detect: 1696/4024 0.148s 0.001s
im_detect: 1697/4024 0.148s 0.001s
im_detect: 1698/4024 0.148s 0.001s
im_detect: 1699/4024 0.148s 0.001s
im_detect: 1700/4024 0.148s 0.001s
im_detect: 1701/4024 0.148s 0.001s
im_detect: 1702/4024 0.148s 0.001s
im_detect: 1703/4024 0.148s 0.001s
im_detect: 1704/4024 0.148s 0.001s
im_detect: 1705/4024 0.148s 0.001s
im_detect: 1706/4024 0.148s 0.001s
im_detect: 1707/4024 0.148s 0.001s
im_detect: 1708/4024 0.148s 0.001s
im_detect: 1709/4024 0.148s 0.001s
im_detect: 1710/4024 0.148s 0.001s
im_detect: 1711/4024 0.148s 0.001s
im_detect: 1712/4024 0.148s 0.001s
im_detect: 1713/4024 0.148s 0.001s
im_detect: 1714/4024 0.148s 0.001s
im_detect: 1715/4024 0.148s 0.001s
im_detect: 1716/4024 0.148s 0.001s
im_detect: 1717/4024 0.148s 0.001s
im_detect: 1718/4024 0.148s 0.001s
im_detect: 1719/4024 0.148s 0.001s
im_detect: 1720/4024 0.148s 0.001s
im_detect: 1721/4024 0.148s 0.001s
im_detect: 1722/4024 0.148s 0.001s
im_detect: 1723/4024 0.148s 0.001s
im_detect: 1724/4024 0.148s 0.001s
im_detect: 1725/4024 0.148s 0.001s
im_detect: 1726/4024 0.148s 0.001s
im_detect: 1727/4024 0.148s 0.001s
im_detect: 1728/4024 0.148s 0.001s
im_detect: 1729/4024 0.148s 0.001s
im_detect: 1730/4024 0.148s 0.001s
im_detect: 1731/4024 0.148s 0.001s
im_detect: 1732/4024 0.148s 0.001s
im_detect: 1733/4024 0.148s 0.001s
im_detect: 1734/4024 0.148s 0.001s
im_detect: 1735/4024 0.148s 0.001s
im_detect: 1736/4024 0.148s 0.001s
im_detect: 1737/4024 0.148s 0.001s
im_detect: 1738/4024 0.148s 0.001s
im_detect: 1739/4024 0.148s 0.001s
im_detect: 1740/4024 0.148s 0.001s
im_detect: 1741/4024 0.148s 0.001s
im_detect: 1742/4024 0.148s 0.001s
im_detect: 1743/4024 0.148s 0.001s
im_detect: 1744/4024 0.148s 0.001s
im_detect: 1745/4024 0.148s 0.001s
im_detect: 1746/4024 0.148s 0.001s
im_detect: 1747/4024 0.148s 0.001s
im_detect: 1748/4024 0.148s 0.001s
im_detect: 1749/4024 0.148s 0.001s
im_detect: 1750/4024 0.148s 0.001s
im_detect: 1751/4024 0.148s 0.001s
im_detect: 1752/4024 0.148s 0.001s
im_detect: 1753/4024 0.148s 0.001s
im_detect: 1754/4024 0.148s 0.001s
im_detect: 1755/4024 0.148s 0.001s
im_detect: 1756/4024 0.148s 0.001s
im_detect: 1757/4024 0.148s 0.001s
im_detect: 1758/4024 0.148s 0.001s
im_detect: 1759/4024 0.148s 0.001s
im_detect: 1760/4024 0.148s 0.001s
im_detect: 1761/4024 0.148s 0.001s
im_detect: 1762/4024 0.148s 0.001s
im_detect: 1763/4024 0.148s 0.001s
im_detect: 1764/4024 0.148s 0.001s
im_detect: 1765/4024 0.148s 0.001s
im_detect: 1766/4024 0.148s 0.001s
im_detect: 1767/4024 0.148s 0.001s
im_detect: 1768/4024 0.148s 0.001s
im_detect: 1769/4024 0.148s 0.001s
im_detect: 1770/4024 0.148s 0.001s
im_detect: 1771/4024 0.148s 0.001s
im_detect: 1772/4024 0.148s 0.001s
im_detect: 1773/4024 0.148s 0.001s
im_detect: 1774/4024 0.148s 0.001s
im_detect: 1775/4024 0.148s 0.001s
im_detect: 1776/4024 0.148s 0.001s
im_detect: 1777/4024 0.148s 0.001s
im_detect: 1778/4024 0.148s 0.001s
im_detect: 1779/4024 0.148s 0.001s
im_detect: 1780/4024 0.148s 0.001s
im_detect: 1781/4024 0.148s 0.001s
im_detect: 1782/4024 0.148s 0.001s
im_detect: 1783/4024 0.148s 0.001s
im_detect: 1784/4024 0.148s 0.001s
im_detect: 1785/4024 0.148s 0.001s
im_detect: 1786/4024 0.148s 0.001s
im_detect: 1787/4024 0.148s 0.001s
im_detect: 1788/4024 0.148s 0.001s
im_detect: 1789/4024 0.148s 0.001s
im_detect: 1790/4024 0.148s 0.001s
im_detect: 1791/4024 0.148s 0.001s
im_detect: 1792/4024 0.148s 0.001s
im_detect: 1793/4024 0.148s 0.001s
im_detect: 1794/4024 0.148s 0.001s
im_detect: 1795/4024 0.148s 0.001s
im_detect: 1796/4024 0.148s 0.001s
im_detect: 1797/4024 0.148s 0.001s
im_detect: 1798/4024 0.148s 0.001s
im_detect: 1799/4024 0.148s 0.001s
im_detect: 1800/4024 0.148s 0.001s
im_detect: 1801/4024 0.148s 0.001s
im_detect: 1802/4024 0.148s 0.001s
im_detect: 1803/4024 0.148s 0.001s
im_detect: 1804/4024 0.148s 0.001s
im_detect: 1805/4024 0.148s 0.001s
im_detect: 1806/4024 0.148s 0.001s
im_detect: 1807/4024 0.148s 0.001s
im_detect: 1808/4024 0.148s 0.001s
im_detect: 1809/4024 0.148s 0.001s
im_detect: 1810/4024 0.148s 0.001s
im_detect: 1811/4024 0.148s 0.001s
im_detect: 1812/4024 0.148s 0.001s
im_detect: 1813/4024 0.148s 0.001s
im_detect: 1814/4024 0.148s 0.001s
im_detect: 1815/4024 0.148s 0.001s
im_detect: 1816/4024 0.148s 0.001s
im_detect: 1817/4024 0.148s 0.001s
im_detect: 1818/4024 0.148s 0.001s
im_detect: 1819/4024 0.148s 0.001s
im_detect: 1820/4024 0.148s 0.001s
im_detect: 1821/4024 0.148s 0.001s
im_detect: 1822/4024 0.148s 0.001s
im_detect: 1823/4024 0.148s 0.001s
im_detect: 1824/4024 0.148s 0.001s
im_detect: 1825/4024 0.148s 0.001s
im_detect: 1826/4024 0.148s 0.001s
im_detect: 1827/4024 0.148s 0.001s
im_detect: 1828/4024 0.148s 0.001s
im_detect: 1829/4024 0.148s 0.001s
im_detect: 1830/4024 0.148s 0.001s
im_detect: 1831/4024 0.148s 0.001s
im_detect: 1832/4024 0.148s 0.001s
im_detect: 1833/4024 0.148s 0.001s
im_detect: 1834/4024 0.148s 0.001s
im_detect: 1835/4024 0.148s 0.001s
im_detect: 1836/4024 0.148s 0.001s
im_detect: 1837/4024 0.148s 0.001s
im_detect: 1838/4024 0.148s 0.001s
im_detect: 1839/4024 0.148s 0.001s
im_detect: 1840/4024 0.148s 0.001s
im_detect: 1841/4024 0.148s 0.001s
im_detect: 1842/4024 0.148s 0.001s
im_detect: 1843/4024 0.148s 0.001s
im_detect: 1844/4024 0.148s 0.001s
im_detect: 1845/4024 0.148s 0.001s
im_detect: 1846/4024 0.148s 0.001s
im_detect: 1847/4024 0.148s 0.001s
im_detect: 1848/4024 0.148s 0.001s
im_detect: 1849/4024 0.148s 0.001s
im_detect: 1850/4024 0.148s 0.001s
im_detect: 1851/4024 0.148s 0.001s
im_detect: 1852/4024 0.148s 0.001s
im_detect: 1853/4024 0.148s 0.001s
im_detect: 1854/4024 0.148s 0.001s
im_detect: 1855/4024 0.148s 0.001s
im_detect: 1856/4024 0.148s 0.001s
im_detect: 1857/4024 0.148s 0.001s
im_detect: 1858/4024 0.148s 0.001s
im_detect: 1859/4024 0.148s 0.001s
im_detect: 1860/4024 0.148s 0.001s
im_detect: 1861/4024 0.148s 0.001s
im_detect: 1862/4024 0.148s 0.001s
im_detect: 1863/4024 0.148s 0.001s
im_detect: 1864/4024 0.148s 0.001s
im_detect: 1865/4024 0.148s 0.001s
im_detect: 1866/4024 0.148s 0.001s
im_detect: 1867/4024 0.148s 0.001s
im_detect: 1868/4024 0.148s 0.001s
im_detect: 1869/4024 0.148s 0.001s
im_detect: 1870/4024 0.148s 0.001s
im_detect: 1871/4024 0.148s 0.001s
im_detect: 1872/4024 0.148s 0.001s
im_detect: 1873/4024 0.148s 0.001s
im_detect: 1874/4024 0.148s 0.001s
im_detect: 1875/4024 0.148s 0.001s
im_detect: 1876/4024 0.148s 0.001s
im_detect: 1877/4024 0.148s 0.001s
im_detect: 1878/4024 0.148s 0.001s
im_detect: 1879/4024 0.148s 0.001s
im_detect: 1880/4024 0.148s 0.001s
im_detect: 1881/4024 0.148s 0.001s
im_detect: 1882/4024 0.148s 0.001s
im_detect: 1883/4024 0.148s 0.001s
im_detect: 1884/4024 0.148s 0.001s
im_detect: 1885/4024 0.148s 0.001s
im_detect: 1886/4024 0.148s 0.001s
im_detect: 1887/4024 0.148s 0.001s
im_detect: 1888/4024 0.148s 0.001s
im_detect: 1889/4024 0.148s 0.001s
im_detect: 1890/4024 0.148s 0.001s
im_detect: 1891/4024 0.148s 0.001s
im_detect: 1892/4024 0.148s 0.001s
im_detect: 1893/4024 0.148s 0.001s
im_detect: 1894/4024 0.148s 0.001s
im_detect: 1895/4024 0.148s 0.001s
im_detect: 1896/4024 0.148s 0.001s
im_detect: 1897/4024 0.148s 0.001s
im_detect: 1898/4024 0.148s 0.001s
im_detect: 1899/4024 0.148s 0.001s
im_detect: 1900/4024 0.148s 0.001s
im_detect: 1901/4024 0.148s 0.001s
im_detect: 1902/4024 0.148s 0.001s
im_detect: 1903/4024 0.148s 0.001s
im_detect: 1904/4024 0.148s 0.001s
im_detect: 1905/4024 0.148s 0.001s
im_detect: 1906/4024 0.148s 0.001s
im_detect: 1907/4024 0.148s 0.001s
im_detect: 1908/4024 0.148s 0.001s
im_detect: 1909/4024 0.148s 0.001s
im_detect: 1910/4024 0.148s 0.001s
im_detect: 1911/4024 0.148s 0.001s
im_detect: 1912/4024 0.148s 0.001s
im_detect: 1913/4024 0.148s 0.001s
im_detect: 1914/4024 0.148s 0.001s
im_detect: 1915/4024 0.148s 0.001s
im_detect: 1916/4024 0.148s 0.001s
im_detect: 1917/4024 0.148s 0.001s
im_detect: 1918/4024 0.148s 0.001s
im_detect: 1919/4024 0.148s 0.001s
im_detect: 1920/4024 0.148s 0.001s
im_detect: 1921/4024 0.148s 0.001s
im_detect: 1922/4024 0.148s 0.001s
im_detect: 1923/4024 0.148s 0.001s
im_detect: 1924/4024 0.148s 0.001s
im_detect: 1925/4024 0.148s 0.001s
im_detect: 1926/4024 0.148s 0.001s
im_detect: 1927/4024 0.148s 0.001s
im_detect: 1928/4024 0.148s 0.001s
im_detect: 1929/4024 0.148s 0.001s
im_detect: 1930/4024 0.148s 0.001s
im_detect: 1931/4024 0.148s 0.001s
im_detect: 1932/4024 0.148s 0.001s
im_detect: 1933/4024 0.148s 0.001s
im_detect: 1934/4024 0.148s 0.001s
im_detect: 1935/4024 0.148s 0.001s
im_detect: 1936/4024 0.148s 0.001s
im_detect: 1937/4024 0.148s 0.001s
im_detect: 1938/4024 0.148s 0.001s
im_detect: 1939/4024 0.148s 0.001s
im_detect: 1940/4024 0.148s 0.001s
im_detect: 1941/4024 0.148s 0.001s
im_detect: 1942/4024 0.148s 0.001s
im_detect: 1943/4024 0.148s 0.001s
im_detect: 1944/4024 0.148s 0.001s
im_detect: 1945/4024 0.148s 0.001s
im_detect: 1946/4024 0.148s 0.001s
im_detect: 1947/4024 0.148s 0.001s
im_detect: 1948/4024 0.148s 0.001s
im_detect: 1949/4024 0.148s 0.001s
im_detect: 1950/4024 0.148s 0.001s
im_detect: 1951/4024 0.148s 0.001s
im_detect: 1952/4024 0.148s 0.001s
im_detect: 1953/4024 0.148s 0.001s
im_detect: 1954/4024 0.148s 0.001s
im_detect: 1955/4024 0.148s 0.001s
im_detect: 1956/4024 0.148s 0.001s
im_detect: 1957/4024 0.148s 0.001s
im_detect: 1958/4024 0.148s 0.001s
im_detect: 1959/4024 0.148s 0.001s
im_detect: 1960/4024 0.148s 0.001s
im_detect: 1961/4024 0.148s 0.001s
im_detect: 1962/4024 0.148s 0.001s
im_detect: 1963/4024 0.148s 0.001s
im_detect: 1964/4024 0.148s 0.001s
im_detect: 1965/4024 0.148s 0.001s
im_detect: 1966/4024 0.148s 0.001s
im_detect: 1967/4024 0.148s 0.001s
im_detect: 1968/4024 0.148s 0.001s
im_detect: 1969/4024 0.148s 0.001s
im_detect: 1970/4024 0.148s 0.001s
im_detect: 1971/4024 0.148s 0.001s
im_detect: 1972/4024 0.148s 0.001s
im_detect: 1973/4024 0.148s 0.001s
im_detect: 1974/4024 0.148s 0.001s
im_detect: 1975/4024 0.148s 0.001s
im_detect: 1976/4024 0.148s 0.001s
im_detect: 1977/4024 0.148s 0.001s
im_detect: 1978/4024 0.148s 0.001s
im_detect: 1979/4024 0.148s 0.001s
im_detect: 1980/4024 0.148s 0.001s
im_detect: 1981/4024 0.148s 0.001s
im_detect: 1982/4024 0.148s 0.001s
im_detect: 1983/4024 0.148s 0.001s
im_detect: 1984/4024 0.148s 0.001s
im_detect: 1985/4024 0.148s 0.001s
im_detect: 1986/4024 0.148s 0.001s
im_detect: 1987/4024 0.148s 0.001s
im_detect: 1988/4024 0.148s 0.001s
im_detect: 1989/4024 0.148s 0.001s
im_detect: 1990/4024 0.148s 0.001s
im_detect: 1991/4024 0.148s 0.001s
im_detect: 1992/4024 0.148s 0.001s
im_detect: 1993/4024 0.148s 0.001s
im_detect: 1994/4024 0.148s 0.001s
im_detect: 1995/4024 0.148s 0.001s
im_detect: 1996/4024 0.148s 0.001s
im_detect: 1997/4024 0.148s 0.001s
im_detect: 1998/4024 0.148s 0.001s
im_detect: 1999/4024 0.148s 0.001s
im_detect: 2000/4024 0.148s 0.001s
im_detect: 2001/4024 0.148s 0.001s
im_detect: 2002/4024 0.148s 0.001s
im_detect: 2003/4024 0.148s 0.001s
im_detect: 2004/4024 0.148s 0.001s
im_detect: 2005/4024 0.148s 0.001s
im_detect: 2006/4024 0.148s 0.001s
im_detect: 2007/4024 0.148s 0.001s
im_detect: 2008/4024 0.148s 0.001s
im_detect: 2009/4024 0.148s 0.001s
im_detect: 2010/4024 0.148s 0.001s
im_detect: 2011/4024 0.148s 0.001s
im_detect: 2012/4024 0.148s 0.001s
im_detect: 2013/4024 0.148s 0.001s
im_detect: 2014/4024 0.148s 0.001s
im_detect: 2015/4024 0.148s 0.001s
im_detect: 2016/4024 0.148s 0.001s
im_detect: 2017/4024 0.148s 0.001s
im_detect: 2018/4024 0.148s 0.001s
im_detect: 2019/4024 0.148s 0.001s
im_detect: 2020/4024 0.148s 0.001s
im_detect: 2021/4024 0.148s 0.001s
im_detect: 2022/4024 0.148s 0.001s
im_detect: 2023/4024 0.148s 0.001s
im_detect: 2024/4024 0.148s 0.001s
im_detect: 2025/4024 0.148s 0.001s
im_detect: 2026/4024 0.148s 0.001s
im_detect: 2027/4024 0.148s 0.001s
im_detect: 2028/4024 0.148s 0.001s
im_detect: 2029/4024 0.148s 0.001s
im_detect: 2030/4024 0.148s 0.001s
im_detect: 2031/4024 0.148s 0.001s
im_detect: 2032/4024 0.148s 0.001s
im_detect: 2033/4024 0.148s 0.001s
im_detect: 2034/4024 0.148s 0.001s
im_detect: 2035/4024 0.148s 0.001s
im_detect: 2036/4024 0.148s 0.001s
im_detect: 2037/4024 0.148s 0.001s
im_detect: 2038/4024 0.148s 0.001s
im_detect: 2039/4024 0.148s 0.001s
im_detect: 2040/4024 0.148s 0.001s
im_detect: 2041/4024 0.148s 0.001s
im_detect: 2042/4024 0.148s 0.001s
im_detect: 2043/4024 0.148s 0.001s
im_detect: 2044/4024 0.148s 0.001s
im_detect: 2045/4024 0.148s 0.001s
im_detect: 2046/4024 0.148s 0.001s
im_detect: 2047/4024 0.148s 0.001s
im_detect: 2048/4024 0.148s 0.001s
im_detect: 2049/4024 0.148s 0.001s
im_detect: 2050/4024 0.148s 0.001s
im_detect: 2051/4024 0.148s 0.001s
im_detect: 2052/4024 0.148s 0.001s
im_detect: 2053/4024 0.148s 0.001s
im_detect: 2054/4024 0.148s 0.001s
im_detect: 2055/4024 0.148s 0.001s
im_detect: 2056/4024 0.148s 0.001s
im_detect: 2057/4024 0.148s 0.001s
im_detect: 2058/4024 0.148s 0.001s
im_detect: 2059/4024 0.148s 0.001s
im_detect: 2060/4024 0.148s 0.001s
im_detect: 2061/4024 0.148s 0.001s
im_detect: 2062/4024 0.148s 0.001s
im_detect: 2063/4024 0.148s 0.001s
im_detect: 2064/4024 0.148s 0.001s
im_detect: 2065/4024 0.148s 0.001s
im_detect: 2066/4024 0.148s 0.001s
im_detect: 2067/4024 0.148s 0.001s
im_detect: 2068/4024 0.148s 0.001s
im_detect: 2069/4024 0.148s 0.001s
im_detect: 2070/4024 0.148s 0.001s
im_detect: 2071/4024 0.148s 0.001s
im_detect: 2072/4024 0.148s 0.001s
im_detect: 2073/4024 0.148s 0.001s
im_detect: 2074/4024 0.148s 0.001s
im_detect: 2075/4024 0.148s 0.001s
im_detect: 2076/4024 0.148s 0.001s
im_detect: 2077/4024 0.148s 0.001s
im_detect: 2078/4024 0.148s 0.001s
im_detect: 2079/4024 0.148s 0.001s
im_detect: 2080/4024 0.148s 0.001s
im_detect: 2081/4024 0.148s 0.001s
im_detect: 2082/4024 0.148s 0.001s
im_detect: 2083/4024 0.148s 0.001s
im_detect: 2084/4024 0.148s 0.001s
im_detect: 2085/4024 0.148s 0.001s
im_detect: 2086/4024 0.148s 0.001s
im_detect: 2087/4024 0.148s 0.001s
im_detect: 2088/4024 0.148s 0.001s
im_detect: 2089/4024 0.148s 0.001s
im_detect: 2090/4024 0.148s 0.001s
im_detect: 2091/4024 0.148s 0.001s
im_detect: 2092/4024 0.148s 0.001s
im_detect: 2093/4024 0.148s 0.001s
im_detect: 2094/4024 0.148s 0.001s
im_detect: 2095/4024 0.148s 0.001s
im_detect: 2096/4024 0.148s 0.001s
im_detect: 2097/4024 0.148s 0.001s
im_detect: 2098/4024 0.148s 0.001s
im_detect: 2099/4024 0.148s 0.001s
im_detect: 2100/4024 0.148s 0.001s
im_detect: 2101/4024 0.148s 0.001s
im_detect: 2102/4024 0.148s 0.001s
im_detect: 2103/4024 0.148s 0.001s
im_detect: 2104/4024 0.148s 0.001s
im_detect: 2105/4024 0.148s 0.001s
im_detect: 2106/4024 0.148s 0.001s
im_detect: 2107/4024 0.148s 0.001s
im_detect: 2108/4024 0.148s 0.001s
im_detect: 2109/4024 0.148s 0.001s
im_detect: 2110/4024 0.148s 0.001s
im_detect: 2111/4024 0.148s 0.001s
im_detect: 2112/4024 0.148s 0.001s
im_detect: 2113/4024 0.148s 0.001s
im_detect: 2114/4024 0.148s 0.001s
im_detect: 2115/4024 0.148s 0.001s
im_detect: 2116/4024 0.148s 0.001s
im_detect: 2117/4024 0.148s 0.001s
im_detect: 2118/4024 0.148s 0.001s
im_detect: 2119/4024 0.148s 0.001s
im_detect: 2120/4024 0.148s 0.001s
im_detect: 2121/4024 0.148s 0.001s
im_detect: 2122/4024 0.148s 0.001s
im_detect: 2123/4024 0.148s 0.001s
im_detect: 2124/4024 0.148s 0.001s
im_detect: 2125/4024 0.148s 0.001s
im_detect: 2126/4024 0.148s 0.001s
im_detect: 2127/4024 0.148s 0.001s
im_detect: 2128/4024 0.148s 0.001s
im_detect: 2129/4024 0.148s 0.001s
im_detect: 2130/4024 0.148s 0.001s
im_detect: 2131/4024 0.148s 0.001s
im_detect: 2132/4024 0.148s 0.001s
im_detect: 2133/4024 0.148s 0.001s
im_detect: 2134/4024 0.148s 0.001s
im_detect: 2135/4024 0.148s 0.001s
im_detect: 2136/4024 0.148s 0.001s
im_detect: 2137/4024 0.148s 0.001s
im_detect: 2138/4024 0.148s 0.001s
im_detect: 2139/4024 0.148s 0.001s
im_detect: 2140/4024 0.148s 0.001s
im_detect: 2141/4024 0.148s 0.001s
im_detect: 2142/4024 0.148s 0.001s
im_detect: 2143/4024 0.148s 0.001s
im_detect: 2144/4024 0.148s 0.001s
im_detect: 2145/4024 0.148s 0.001s
im_detect: 2146/4024 0.148s 0.001s
im_detect: 2147/4024 0.148s 0.001s
im_detect: 2148/4024 0.148s 0.001s
im_detect: 2149/4024 0.148s 0.001s
im_detect: 2150/4024 0.148s 0.001s
im_detect: 2151/4024 0.148s 0.001s
im_detect: 2152/4024 0.148s 0.001s
im_detect: 2153/4024 0.148s 0.001s
im_detect: 2154/4024 0.148s 0.001s
im_detect: 2155/4024 0.148s 0.001s
im_detect: 2156/4024 0.148s 0.001s
im_detect: 2157/4024 0.148s 0.001s
im_detect: 2158/4024 0.148s 0.001s
im_detect: 2159/4024 0.148s 0.001s
im_detect: 2160/4024 0.148s 0.001s
im_detect: 2161/4024 0.148s 0.001s
im_detect: 2162/4024 0.148s 0.001s
im_detect: 2163/4024 0.148s 0.001s
im_detect: 2164/4024 0.148s 0.001s
im_detect: 2165/4024 0.148s 0.001s
im_detect: 2166/4024 0.148s 0.001s
im_detect: 2167/4024 0.148s 0.001s
im_detect: 2168/4024 0.148s 0.001s
im_detect: 2169/4024 0.148s 0.001s
im_detect: 2170/4024 0.148s 0.001s
im_detect: 2171/4024 0.148s 0.001s
im_detect: 2172/4024 0.148s 0.001s
im_detect: 2173/4024 0.148s 0.001s
im_detect: 2174/4024 0.148s 0.001s
im_detect: 2175/4024 0.148s 0.001s
im_detect: 2176/4024 0.148s 0.001s
im_detect: 2177/4024 0.148s 0.001s
im_detect: 2178/4024 0.148s 0.001s
im_detect: 2179/4024 0.148s 0.001s
im_detect: 2180/4024 0.148s 0.001s
im_detect: 2181/4024 0.148s 0.001s
im_detect: 2182/4024 0.148s 0.001s
im_detect: 2183/4024 0.148s 0.001s
im_detect: 2184/4024 0.148s 0.001s
im_detect: 2185/4024 0.148s 0.001s
im_detect: 2186/4024 0.148s 0.001s
im_detect: 2187/4024 0.148s 0.001s
im_detect: 2188/4024 0.148s 0.001s
im_detect: 2189/4024 0.148s 0.001s
im_detect: 2190/4024 0.148s 0.001s
im_detect: 2191/4024 0.148s 0.001s
im_detect: 2192/4024 0.148s 0.001s
im_detect: 2193/4024 0.148s 0.001s
im_detect: 2194/4024 0.148s 0.001s
im_detect: 2195/4024 0.148s 0.001s
im_detect: 2196/4024 0.148s 0.001s
im_detect: 2197/4024 0.148s 0.001s
im_detect: 2198/4024 0.148s 0.001s
im_detect: 2199/4024 0.148s 0.001s
im_detect: 2200/4024 0.148s 0.001s
im_detect: 2201/4024 0.148s 0.001s
im_detect: 2202/4024 0.148s 0.001s
im_detect: 2203/4024 0.148s 0.001s
im_detect: 2204/4024 0.148s 0.001s
im_detect: 2205/4024 0.148s 0.001s
im_detect: 2206/4024 0.148s 0.001s
im_detect: 2207/4024 0.148s 0.001s
im_detect: 2208/4024 0.148s 0.001s
im_detect: 2209/4024 0.148s 0.001s
im_detect: 2210/4024 0.148s 0.001s
im_detect: 2211/4024 0.148s 0.001s
im_detect: 2212/4024 0.148s 0.001s
im_detect: 2213/4024 0.148s 0.001s
im_detect: 2214/4024 0.148s 0.001s
im_detect: 2215/4024 0.148s 0.001s
im_detect: 2216/4024 0.148s 0.001s
im_detect: 2217/4024 0.148s 0.001s
im_detect: 2218/4024 0.148s 0.001s
im_detect: 2219/4024 0.148s 0.001s
im_detect: 2220/4024 0.148s 0.001s
im_detect: 2221/4024 0.148s 0.001s
im_detect: 2222/4024 0.148s 0.001s
im_detect: 2223/4024 0.148s 0.001s
im_detect: 2224/4024 0.148s 0.001s
im_detect: 2225/4024 0.148s 0.001s
im_detect: 2226/4024 0.148s 0.001s
im_detect: 2227/4024 0.148s 0.001s
im_detect: 2228/4024 0.148s 0.001s
im_detect: 2229/4024 0.148s 0.001s
im_detect: 2230/4024 0.148s 0.001s
im_detect: 2231/4024 0.148s 0.001s
im_detect: 2232/4024 0.148s 0.001s
im_detect: 2233/4024 0.148s 0.001s
im_detect: 2234/4024 0.148s 0.001s
im_detect: 2235/4024 0.148s 0.001s
im_detect: 2236/4024 0.148s 0.001s
im_detect: 2237/4024 0.148s 0.001s
im_detect: 2238/4024 0.148s 0.001s
im_detect: 2239/4024 0.148s 0.001s
im_detect: 2240/4024 0.148s 0.001s
im_detect: 2241/4024 0.148s 0.001s
im_detect: 2242/4024 0.148s 0.001s
im_detect: 2243/4024 0.148s 0.001s
im_detect: 2244/4024 0.148s 0.001s
im_detect: 2245/4024 0.148s 0.001s
im_detect: 2246/4024 0.148s 0.001s
im_detect: 2247/4024 0.148s 0.001s
im_detect: 2248/4024 0.148s 0.001s
im_detect: 2249/4024 0.148s 0.001s
im_detect: 2250/4024 0.148s 0.001s
im_detect: 2251/4024 0.148s 0.001s
im_detect: 2252/4024 0.148s 0.001s
im_detect: 2253/4024 0.148s 0.001s
im_detect: 2254/4024 0.148s 0.001s
im_detect: 2255/4024 0.148s 0.001s
im_detect: 2256/4024 0.148s 0.001s
im_detect: 2257/4024 0.148s 0.001s
im_detect: 2258/4024 0.148s 0.001s
im_detect: 2259/4024 0.148s 0.001s
im_detect: 2260/4024 0.148s 0.001s
im_detect: 2261/4024 0.148s 0.001s
im_detect: 2262/4024 0.148s 0.001s
im_detect: 2263/4024 0.148s 0.001s
im_detect: 2264/4024 0.148s 0.001s
im_detect: 2265/4024 0.148s 0.001s
im_detect: 2266/4024 0.148s 0.001s
im_detect: 2267/4024 0.148s 0.001s
im_detect: 2268/4024 0.148s 0.001s
im_detect: 2269/4024 0.148s 0.001s
im_detect: 2270/4024 0.148s 0.001s
im_detect: 2271/4024 0.148s 0.001s
im_detect: 2272/4024 0.148s 0.001s
im_detect: 2273/4024 0.148s 0.001s
im_detect: 2274/4024 0.148s 0.001s
im_detect: 2275/4024 0.148s 0.001s
im_detect: 2276/4024 0.148s 0.001s
im_detect: 2277/4024 0.148s 0.001s
im_detect: 2278/4024 0.148s 0.001s
im_detect: 2279/4024 0.148s 0.001s
im_detect: 2280/4024 0.148s 0.001s
im_detect: 2281/4024 0.148s 0.001s
im_detect: 2282/4024 0.148s 0.001s
im_detect: 2283/4024 0.148s 0.001s
im_detect: 2284/4024 0.148s 0.001s
im_detect: 2285/4024 0.148s 0.001s
im_detect: 2286/4024 0.148s 0.001s
im_detect: 2287/4024 0.148s 0.001s
im_detect: 2288/4024 0.148s 0.001s
im_detect: 2289/4024 0.148s 0.001s
im_detect: 2290/4024 0.148s 0.001s
im_detect: 2291/4024 0.148s 0.001s
im_detect: 2292/4024 0.148s 0.001s
im_detect: 2293/4024 0.148s 0.001s
im_detect: 2294/4024 0.148s 0.001s
im_detect: 2295/4024 0.148s 0.001s
im_detect: 2296/4024 0.148s 0.001s
im_detect: 2297/4024 0.148s 0.001s
im_detect: 2298/4024 0.148s 0.001s
im_detect: 2299/4024 0.148s 0.001s
im_detect: 2300/4024 0.148s 0.001s
im_detect: 2301/4024 0.148s 0.001s
im_detect: 2302/4024 0.148s 0.001s
im_detect: 2303/4024 0.148s 0.001s
im_detect: 2304/4024 0.148s 0.001s
im_detect: 2305/4024 0.148s 0.001s
im_detect: 2306/4024 0.148s 0.001s
im_detect: 2307/4024 0.148s 0.001s
im_detect: 2308/4024 0.148s 0.001s
im_detect: 2309/4024 0.148s 0.001s
im_detect: 2310/4024 0.148s 0.001s
im_detect: 2311/4024 0.148s 0.001s
im_detect: 2312/4024 0.148s 0.001s
im_detect: 2313/4024 0.148s 0.001s
im_detect: 2314/4024 0.148s 0.001s
im_detect: 2315/4024 0.148s 0.001s
im_detect: 2316/4024 0.148s 0.001s
im_detect: 2317/4024 0.148s 0.001s
im_detect: 2318/4024 0.148s 0.001s
im_detect: 2319/4024 0.148s 0.001s
im_detect: 2320/4024 0.148s 0.001s
im_detect: 2321/4024 0.148s 0.001s
im_detect: 2322/4024 0.148s 0.001s
im_detect: 2323/4024 0.148s 0.001s
im_detect: 2324/4024 0.148s 0.001s
im_detect: 2325/4024 0.148s 0.001s
im_detect: 2326/4024 0.148s 0.001s
im_detect: 2327/4024 0.148s 0.001s
im_detect: 2328/4024 0.148s 0.001s
im_detect: 2329/4024 0.148s 0.001s
im_detect: 2330/4024 0.148s 0.001s
im_detect: 2331/4024 0.148s 0.001s
im_detect: 2332/4024 0.148s 0.001s
im_detect: 2333/4024 0.148s 0.001s
im_detect: 2334/4024 0.148s 0.001s
im_detect: 2335/4024 0.148s 0.001s
im_detect: 2336/4024 0.148s 0.001s
im_detect: 2337/4024 0.148s 0.001s
im_detect: 2338/4024 0.148s 0.001s
im_detect: 2339/4024 0.148s 0.001s
im_detect: 2340/4024 0.148s 0.001s
im_detect: 2341/4024 0.148s 0.001s
im_detect: 2342/4024 0.148s 0.001s
im_detect: 2343/4024 0.148s 0.001s
im_detect: 2344/4024 0.148s 0.001s
im_detect: 2345/4024 0.148s 0.001s
im_detect: 2346/4024 0.148s 0.001s
im_detect: 2347/4024 0.148s 0.001s
im_detect: 2348/4024 0.148s 0.001s
im_detect: 2349/4024 0.148s 0.001s
im_detect: 2350/4024 0.148s 0.001s
im_detect: 2351/4024 0.148s 0.001s
im_detect: 2352/4024 0.148s 0.001s
im_detect: 2353/4024 0.148s 0.001s
im_detect: 2354/4024 0.148s 0.001s
im_detect: 2355/4024 0.148s 0.001s
im_detect: 2356/4024 0.148s 0.001s
im_detect: 2357/4024 0.148s 0.001s
im_detect: 2358/4024 0.148s 0.001s
im_detect: 2359/4024 0.148s 0.001s
im_detect: 2360/4024 0.148s 0.001s
im_detect: 2361/4024 0.148s 0.001s
im_detect: 2362/4024 0.148s 0.001s
im_detect: 2363/4024 0.148s 0.001s
im_detect: 2364/4024 0.148s 0.001s
im_detect: 2365/4024 0.148s 0.001s
im_detect: 2366/4024 0.148s 0.001s
im_detect: 2367/4024 0.148s 0.001s
im_detect: 2368/4024 0.148s 0.001s
im_detect: 2369/4024 0.148s 0.001s
im_detect: 2370/4024 0.148s 0.001s
im_detect: 2371/4024 0.148s 0.001s
im_detect: 2372/4024 0.148s 0.001s
im_detect: 2373/4024 0.148s 0.001s
im_detect: 2374/4024 0.148s 0.001s
im_detect: 2375/4024 0.148s 0.001s
im_detect: 2376/4024 0.148s 0.001s
im_detect: 2377/4024 0.148s 0.001s
im_detect: 2378/4024 0.148s 0.001s
im_detect: 2379/4024 0.148s 0.001s
im_detect: 2380/4024 0.148s 0.001s
im_detect: 2381/4024 0.148s 0.001s
im_detect: 2382/4024 0.148s 0.001s
im_detect: 2383/4024 0.148s 0.001s
im_detect: 2384/4024 0.148s 0.001s
im_detect: 2385/4024 0.148s 0.001s
im_detect: 2386/4024 0.148s 0.001s
im_detect: 2387/4024 0.148s 0.001s
im_detect: 2388/4024 0.148s 0.001s
im_detect: 2389/4024 0.148s 0.001s
im_detect: 2390/4024 0.148s 0.001s
im_detect: 2391/4024 0.148s 0.001s
im_detect: 2392/4024 0.148s 0.001s
im_detect: 2393/4024 0.148s 0.001s
im_detect: 2394/4024 0.148s 0.001s
im_detect: 2395/4024 0.148s 0.001s
im_detect: 2396/4024 0.148s 0.001s
im_detect: 2397/4024 0.148s 0.001s
im_detect: 2398/4024 0.148s 0.001s
im_detect: 2399/4024 0.148s 0.001s
im_detect: 2400/4024 0.148s 0.001s
im_detect: 2401/4024 0.148s 0.001s
im_detect: 2402/4024 0.148s 0.001s
im_detect: 2403/4024 0.148s 0.001s
im_detect: 2404/4024 0.148s 0.001s
im_detect: 2405/4024 0.148s 0.001s
im_detect: 2406/4024 0.148s 0.001s
im_detect: 2407/4024 0.148s 0.001s
im_detect: 2408/4024 0.148s 0.001s
im_detect: 2409/4024 0.148s 0.001s
im_detect: 2410/4024 0.148s 0.001s
im_detect: 2411/4024 0.148s 0.001s
im_detect: 2412/4024 0.148s 0.001s
im_detect: 2413/4024 0.148s 0.001s
im_detect: 2414/4024 0.148s 0.001s
im_detect: 2415/4024 0.148s 0.001s
im_detect: 2416/4024 0.148s 0.001s
im_detect: 2417/4024 0.148s 0.001s
im_detect: 2418/4024 0.148s 0.001s
im_detect: 2419/4024 0.148s 0.001s
im_detect: 2420/4024 0.148s 0.001s
im_detect: 2421/4024 0.148s 0.001s
im_detect: 2422/4024 0.148s 0.001s
im_detect: 2423/4024 0.148s 0.001s
im_detect: 2424/4024 0.148s 0.001s
im_detect: 2425/4024 0.148s 0.001s
im_detect: 2426/4024 0.148s 0.001s
im_detect: 2427/4024 0.148s 0.001s
im_detect: 2428/4024 0.148s 0.001s
im_detect: 2429/4024 0.148s 0.001s
im_detect: 2430/4024 0.148s 0.001s
im_detect: 2431/4024 0.148s 0.001s
im_detect: 2432/4024 0.148s 0.001s
im_detect: 2433/4024 0.148s 0.001s
im_detect: 2434/4024 0.148s 0.001s
im_detect: 2435/4024 0.148s 0.001s
im_detect: 2436/4024 0.148s 0.001s
im_detect: 2437/4024 0.148s 0.001s
im_detect: 2438/4024 0.148s 0.001s
im_detect: 2439/4024 0.148s 0.001s
im_detect: 2440/4024 0.148s 0.001s
im_detect: 2441/4024 0.148s 0.001s
im_detect: 2442/4024 0.148s 0.001s
im_detect: 2443/4024 0.148s 0.001s
im_detect: 2444/4024 0.148s 0.001s
im_detect: 2445/4024 0.148s 0.001s
im_detect: 2446/4024 0.148s 0.001s
im_detect: 2447/4024 0.148s 0.001s
im_detect: 2448/4024 0.148s 0.001s
im_detect: 2449/4024 0.148s 0.001s
im_detect: 2450/4024 0.148s 0.001s
im_detect: 2451/4024 0.148s 0.001s
im_detect: 2452/4024 0.148s 0.001s
im_detect: 2453/4024 0.148s 0.001s
im_detect: 2454/4024 0.148s 0.001s
im_detect: 2455/4024 0.148s 0.001s
im_detect: 2456/4024 0.148s 0.001s
im_detect: 2457/4024 0.148s 0.001s
im_detect: 2458/4024 0.148s 0.001s
im_detect: 2459/4024 0.148s 0.001s
im_detect: 2460/4024 0.148s 0.001s
im_detect: 2461/4024 0.148s 0.001s
im_detect: 2462/4024 0.148s 0.001s
im_detect: 2463/4024 0.148s 0.001s
im_detect: 2464/4024 0.148s 0.001s
im_detect: 2465/4024 0.148s 0.001s
im_detect: 2466/4024 0.148s 0.001s
im_detect: 2467/4024 0.148s 0.001s
im_detect: 2468/4024 0.148s 0.001s
im_detect: 2469/4024 0.148s 0.001s
im_detect: 2470/4024 0.148s 0.001s
im_detect: 2471/4024 0.148s 0.001s
im_detect: 2472/4024 0.148s 0.001s
im_detect: 2473/4024 0.148s 0.001s
im_detect: 2474/4024 0.148s 0.001s
im_detect: 2475/4024 0.148s 0.001s
im_detect: 2476/4024 0.148s 0.001s
im_detect: 2477/4024 0.148s 0.001s
im_detect: 2478/4024 0.148s 0.001s
im_detect: 2479/4024 0.148s 0.001s
im_detect: 2480/4024 0.148s 0.001s
im_detect: 2481/4024 0.148s 0.001s
im_detect: 2482/4024 0.148s 0.001s
im_detect: 2483/4024 0.148s 0.001s
im_detect: 2484/4024 0.148s 0.001s
im_detect: 2485/4024 0.148s 0.001s
im_detect: 2486/4024 0.148s 0.001s
im_detect: 2487/4024 0.148s 0.001s
im_detect: 2488/4024 0.148s 0.001s
im_detect: 2489/4024 0.148s 0.001s
im_detect: 2490/4024 0.148s 0.001s
im_detect: 2491/4024 0.148s 0.001s
im_detect: 2492/4024 0.148s 0.001s
im_detect: 2493/4024 0.148s 0.001s
im_detect: 2494/4024 0.148s 0.001s
im_detect: 2495/4024 0.148s 0.001s
im_detect: 2496/4024 0.148s 0.001s
im_detect: 2497/4024 0.148s 0.001s
im_detect: 2498/4024 0.148s 0.001s
im_detect: 2499/4024 0.148s 0.001s
im_detect: 2500/4024 0.148s 0.001s
im_detect: 2501/4024 0.148s 0.001s
im_detect: 2502/4024 0.148s 0.001s
im_detect: 2503/4024 0.148s 0.001s
im_detect: 2504/4024 0.148s 0.001s
im_detect: 2505/4024 0.148s 0.001s
im_detect: 2506/4024 0.148s 0.001s
im_detect: 2507/4024 0.148s 0.001s
im_detect: 2508/4024 0.148s 0.001s
im_detect: 2509/4024 0.148s 0.001s
im_detect: 2510/4024 0.148s 0.001s
im_detect: 2511/4024 0.148s 0.001s
im_detect: 2512/4024 0.148s 0.001s
im_detect: 2513/4024 0.148s 0.001s
im_detect: 2514/4024 0.148s 0.001s
im_detect: 2515/4024 0.148s 0.001s
im_detect: 2516/4024 0.148s 0.001s
im_detect: 2517/4024 0.148s 0.001s
im_detect: 2518/4024 0.148s 0.001s
im_detect: 2519/4024 0.148s 0.001s
im_detect: 2520/4024 0.148s 0.001s
im_detect: 2521/4024 0.148s 0.001s
im_detect: 2522/4024 0.148s 0.001s
im_detect: 2523/4024 0.148s 0.001s
im_detect: 2524/4024 0.148s 0.001s
im_detect: 2525/4024 0.148s 0.001s
im_detect: 2526/4024 0.148s 0.001s
im_detect: 2527/4024 0.148s 0.001s
im_detect: 2528/4024 0.148s 0.001s
im_detect: 2529/4024 0.148s 0.001s
im_detect: 2530/4024 0.148s 0.001s
im_detect: 2531/4024 0.148s 0.001s
im_detect: 2532/4024 0.148s 0.001s
im_detect: 2533/4024 0.148s 0.001s
im_detect: 2534/4024 0.148s 0.001s
im_detect: 2535/4024 0.148s 0.001s
im_detect: 2536/4024 0.148s 0.001s
im_detect: 2537/4024 0.148s 0.001s
im_detect: 2538/4024 0.148s 0.001s
im_detect: 2539/4024 0.148s 0.001s
im_detect: 2540/4024 0.148s 0.001s
im_detect: 2541/4024 0.148s 0.001s
im_detect: 2542/4024 0.148s 0.001s
im_detect: 2543/4024 0.148s 0.001s
im_detect: 2544/4024 0.148s 0.001s
im_detect: 2545/4024 0.148s 0.001s
im_detect: 2546/4024 0.148s 0.001s
im_detect: 2547/4024 0.148s 0.001s
im_detect: 2548/4024 0.148s 0.001s
im_detect: 2549/4024 0.148s 0.001s
im_detect: 2550/4024 0.148s 0.001s
im_detect: 2551/4024 0.148s 0.001s
im_detect: 2552/4024 0.148s 0.001s
im_detect: 2553/4024 0.148s 0.001s
im_detect: 2554/4024 0.148s 0.001s
im_detect: 2555/4024 0.148s 0.001s
im_detect: 2556/4024 0.148s 0.001s
im_detect: 2557/4024 0.148s 0.001s
im_detect: 2558/4024 0.148s 0.001s
im_detect: 2559/4024 0.148s 0.001s
im_detect: 2560/4024 0.148s 0.001s
im_detect: 2561/4024 0.148s 0.001s
im_detect: 2562/4024 0.148s 0.001s
im_detect: 2563/4024 0.148s 0.001s
im_detect: 2564/4024 0.148s 0.001s
im_detect: 2565/4024 0.148s 0.001s
im_detect: 2566/4024 0.148s 0.001s
im_detect: 2567/4024 0.148s 0.001s
im_detect: 2568/4024 0.148s 0.001s
im_detect: 2569/4024 0.148s 0.001s
im_detect: 2570/4024 0.148s 0.001s
im_detect: 2571/4024 0.148s 0.001s
im_detect: 2572/4024 0.148s 0.001s
im_detect: 2573/4024 0.148s 0.001s
im_detect: 2574/4024 0.148s 0.001s
im_detect: 2575/4024 0.148s 0.001s
im_detect: 2576/4024 0.148s 0.001s
im_detect: 2577/4024 0.148s 0.001s
im_detect: 2578/4024 0.148s 0.001s
im_detect: 2579/4024 0.148s 0.001s
im_detect: 2580/4024 0.148s 0.001s
im_detect: 2581/4024 0.148s 0.001s
im_detect: 2582/4024 0.148s 0.001s
im_detect: 2583/4024 0.148s 0.001s
im_detect: 2584/4024 0.148s 0.001s
im_detect: 2585/4024 0.148s 0.001s
im_detect: 2586/4024 0.148s 0.001s
im_detect: 2587/4024 0.148s 0.001s
im_detect: 2588/4024 0.148s 0.001s
im_detect: 2589/4024 0.148s 0.001s
im_detect: 2590/4024 0.148s 0.001s
im_detect: 2591/4024 0.148s 0.001s
im_detect: 2592/4024 0.148s 0.001s
im_detect: 2593/4024 0.148s 0.001s
im_detect: 2594/4024 0.148s 0.001s
im_detect: 2595/4024 0.148s 0.001s
im_detect: 2596/4024 0.148s 0.001s
im_detect: 2597/4024 0.148s 0.001s
im_detect: 2598/4024 0.148s 0.001s
im_detect: 2599/4024 0.148s 0.001s
im_detect: 2600/4024 0.148s 0.001s
im_detect: 2601/4024 0.148s 0.001s
im_detect: 2602/4024 0.148s 0.001s
im_detect: 2603/4024 0.148s 0.001s
im_detect: 2604/4024 0.148s 0.001s
im_detect: 2605/4024 0.148s 0.001s
im_detect: 2606/4024 0.148s 0.001s
im_detect: 2607/4024 0.148s 0.001s
im_detect: 2608/4024 0.148s 0.001s
im_detect: 2609/4024 0.148s 0.001s
im_detect: 2610/4024 0.148s 0.001s
im_detect: 2611/4024 0.148s 0.001s
im_detect: 2612/4024 0.148s 0.001s
im_detect: 2613/4024 0.148s 0.001s
im_detect: 2614/4024 0.148s 0.001s
im_detect: 2615/4024 0.148s 0.001s
im_detect: 2616/4024 0.148s 0.001s
im_detect: 2617/4024 0.148s 0.001s
im_detect: 2618/4024 0.148s 0.001s
im_detect: 2619/4024 0.148s 0.001s
im_detect: 2620/4024 0.148s 0.001s
im_detect: 2621/4024 0.148s 0.001s
im_detect: 2622/4024 0.148s 0.001s
im_detect: 2623/4024 0.148s 0.001s
im_detect: 2624/4024 0.148s 0.001s
im_detect: 2625/4024 0.148s 0.001s
im_detect: 2626/4024 0.148s 0.001s
im_detect: 2627/4024 0.148s 0.001s
im_detect: 2628/4024 0.148s 0.001s
im_detect: 2629/4024 0.148s 0.001s
im_detect: 2630/4024 0.148s 0.001s
im_detect: 2631/4024 0.148s 0.001s
im_detect: 2632/4024 0.148s 0.001s
im_detect: 2633/4024 0.148s 0.001s
im_detect: 2634/4024 0.148s 0.001s
im_detect: 2635/4024 0.148s 0.001s
im_detect: 2636/4024 0.148s 0.001s
im_detect: 2637/4024 0.148s 0.001s
im_detect: 2638/4024 0.148s 0.001s
im_detect: 2639/4024 0.148s 0.001s
im_detect: 2640/4024 0.148s 0.001s
im_detect: 2641/4024 0.148s 0.001s
im_detect: 2642/4024 0.148s 0.001s
im_detect: 2643/4024 0.148s 0.001s
im_detect: 2644/4024 0.148s 0.001s
im_detect: 2645/4024 0.148s 0.001s
im_detect: 2646/4024 0.148s 0.001s
im_detect: 2647/4024 0.148s 0.001s
im_detect: 2648/4024 0.148s 0.001s
im_detect: 2649/4024 0.148s 0.001s
im_detect: 2650/4024 0.148s 0.001s
im_detect: 2651/4024 0.148s 0.001s
im_detect: 2652/4024 0.148s 0.001s
im_detect: 2653/4024 0.148s 0.001s
im_detect: 2654/4024 0.148s 0.001s
im_detect: 2655/4024 0.148s 0.001s
im_detect: 2656/4024 0.148s 0.001s
im_detect: 2657/4024 0.148s 0.001s
im_detect: 2658/4024 0.148s 0.001s
im_detect: 2659/4024 0.148s 0.001s
im_detect: 2660/4024 0.148s 0.001s
im_detect: 2661/4024 0.148s 0.001s
im_detect: 2662/4024 0.148s 0.001s
im_detect: 2663/4024 0.148s 0.001s
im_detect: 2664/4024 0.148s 0.001s
im_detect: 2665/4024 0.148s 0.001s
im_detect: 2666/4024 0.148s 0.001s
im_detect: 2667/4024 0.148s 0.001s
im_detect: 2668/4024 0.148s 0.001s
im_detect: 2669/4024 0.148s 0.001s
im_detect: 2670/4024 0.148s 0.001s
im_detect: 2671/4024 0.148s 0.001s
im_detect: 2672/4024 0.148s 0.001s
im_detect: 2673/4024 0.148s 0.001s
im_detect: 2674/4024 0.148s 0.001s
im_detect: 2675/4024 0.148s 0.001s
im_detect: 2676/4024 0.148s 0.001s
im_detect: 2677/4024 0.148s 0.001s
im_detect: 2678/4024 0.148s 0.001s
im_detect: 2679/4024 0.148s 0.001s
im_detect: 2680/4024 0.148s 0.001s
im_detect: 2681/4024 0.148s 0.001s
im_detect: 2682/4024 0.148s 0.001s
im_detect: 2683/4024 0.148s 0.001s
im_detect: 2684/4024 0.148s 0.001s
im_detect: 2685/4024 0.148s 0.001s
im_detect: 2686/4024 0.148s 0.001s
im_detect: 2687/4024 0.148s 0.001s
im_detect: 2688/4024 0.148s 0.001s
im_detect: 2689/4024 0.148s 0.001s
im_detect: 2690/4024 0.148s 0.001s
im_detect: 2691/4024 0.148s 0.001s
im_detect: 2692/4024 0.148s 0.001s
im_detect: 2693/4024 0.148s 0.001s
im_detect: 2694/4024 0.148s 0.001s
im_detect: 2695/4024 0.148s 0.001s
im_detect: 2696/4024 0.148s 0.001s
im_detect: 2697/4024 0.148s 0.001s
im_detect: 2698/4024 0.148s 0.001s
im_detect: 2699/4024 0.148s 0.001s
im_detect: 2700/4024 0.148s 0.001s
im_detect: 2701/4024 0.148s 0.001s
im_detect: 2702/4024 0.148s 0.001s
im_detect: 2703/4024 0.148s 0.001s
im_detect: 2704/4024 0.148s 0.001s
im_detect: 2705/4024 0.148s 0.001s
im_detect: 2706/4024 0.148s 0.001s
im_detect: 2707/4024 0.148s 0.001s
im_detect: 2708/4024 0.148s 0.001s
im_detect: 2709/4024 0.148s 0.001s
im_detect: 2710/4024 0.148s 0.001s
im_detect: 2711/4024 0.148s 0.001s
im_detect: 2712/4024 0.148s 0.001s
im_detect: 2713/4024 0.148s 0.001s
im_detect: 2714/4024 0.148s 0.001s
im_detect: 2715/4024 0.148s 0.001s
im_detect: 2716/4024 0.148s 0.001s
im_detect: 2717/4024 0.148s 0.001s
im_detect: 2718/4024 0.148s 0.001s
im_detect: 2719/4024 0.148s 0.001s
im_detect: 2720/4024 0.148s 0.001s
im_detect: 2721/4024 0.148s 0.001s
im_detect: 2722/4024 0.148s 0.001s
im_detect: 2723/4024 0.148s 0.001s
im_detect: 2724/4024 0.148s 0.001s
im_detect: 2725/4024 0.148s 0.001s
im_detect: 2726/4024 0.148s 0.001s
im_detect: 2727/4024 0.148s 0.001s
im_detect: 2728/4024 0.148s 0.001s
im_detect: 2729/4024 0.148s 0.001s
im_detect: 2730/4024 0.148s 0.001s
im_detect: 2731/4024 0.148s 0.001s
im_detect: 2732/4024 0.148s 0.001s
im_detect: 2733/4024 0.148s 0.001s
im_detect: 2734/4024 0.148s 0.001s
im_detect: 2735/4024 0.148s 0.001s
im_detect: 2736/4024 0.148s 0.001s
im_detect: 2737/4024 0.148s 0.001s
im_detect: 2738/4024 0.148s 0.001s
im_detect: 2739/4024 0.148s 0.001s
im_detect: 2740/4024 0.148s 0.001s
im_detect: 2741/4024 0.148s 0.001s
im_detect: 2742/4024 0.148s 0.001s
im_detect: 2743/4024 0.148s 0.001s
im_detect: 2744/4024 0.148s 0.001s
im_detect: 2745/4024 0.148s 0.001s
im_detect: 2746/4024 0.148s 0.001s
im_detect: 2747/4024 0.148s 0.001s
im_detect: 2748/4024 0.148s 0.001s
im_detect: 2749/4024 0.148s 0.001s
im_detect: 2750/4024 0.148s 0.001s
im_detect: 2751/4024 0.148s 0.001s
im_detect: 2752/4024 0.148s 0.001s
im_detect: 2753/4024 0.148s 0.001s
im_detect: 2754/4024 0.148s 0.001s
im_detect: 2755/4024 0.148s 0.001s
im_detect: 2756/4024 0.148s 0.001s
im_detect: 2757/4024 0.148s 0.001s
im_detect: 2758/4024 0.148s 0.001s
im_detect: 2759/4024 0.148s 0.001s
im_detect: 2760/4024 0.148s 0.001s
im_detect: 2761/4024 0.148s 0.001s
im_detect: 2762/4024 0.148s 0.001s
im_detect: 2763/4024 0.148s 0.001s
im_detect: 2764/4024 0.148s 0.001s
im_detect: 2765/4024 0.148s 0.001s
im_detect: 2766/4024 0.148s 0.001s
im_detect: 2767/4024 0.148s 0.001s
im_detect: 2768/4024 0.148s 0.001s
im_detect: 2769/4024 0.148s 0.001s
im_detect: 2770/4024 0.148s 0.001s
im_detect: 2771/4024 0.148s 0.001s
im_detect: 2772/4024 0.148s 0.001s
im_detect: 2773/4024 0.148s 0.001s
im_detect: 2774/4024 0.148s 0.001s
im_detect: 2775/4024 0.148s 0.001s
im_detect: 2776/4024 0.148s 0.001s
im_detect: 2777/4024 0.148s 0.001s
im_detect: 2778/4024 0.148s 0.001s
im_detect: 2779/4024 0.148s 0.001s
im_detect: 2780/4024 0.148s 0.001s
im_detect: 2781/4024 0.148s 0.001s
im_detect: 2782/4024 0.148s 0.001s
im_detect: 2783/4024 0.148s 0.001s
im_detect: 2784/4024 0.148s 0.001s
im_detect: 2785/4024 0.148s 0.001s
im_detect: 2786/4024 0.148s 0.001s
im_detect: 2787/4024 0.148s 0.001s
im_detect: 2788/4024 0.148s 0.001s
im_detect: 2789/4024 0.148s 0.001s
im_detect: 2790/4024 0.148s 0.001s
im_detect: 2791/4024 0.148s 0.001s
im_detect: 2792/4024 0.148s 0.001s
im_detect: 2793/4024 0.148s 0.001s
im_detect: 2794/4024 0.148s 0.001s
im_detect: 2795/4024 0.148s 0.001s
im_detect: 2796/4024 0.148s 0.001s
im_detect: 2797/4024 0.148s 0.001s
im_detect: 2798/4024 0.148s 0.001s
im_detect: 2799/4024 0.148s 0.001s
im_detect: 2800/4024 0.148s 0.001s
im_detect: 2801/4024 0.148s 0.001s
im_detect: 2802/4024 0.148s 0.001s
im_detect: 2803/4024 0.148s 0.001s
im_detect: 2804/4024 0.148s 0.001s
im_detect: 2805/4024 0.148s 0.001s
im_detect: 2806/4024 0.148s 0.001s
im_detect: 2807/4024 0.148s 0.001s
im_detect: 2808/4024 0.148s 0.001s
im_detect: 2809/4024 0.148s 0.001s
im_detect: 2810/4024 0.148s 0.001s
im_detect: 2811/4024 0.148s 0.001s
im_detect: 2812/4024 0.148s 0.001s
im_detect: 2813/4024 0.148s 0.001s
im_detect: 2814/4024 0.148s 0.001s
im_detect: 2815/4024 0.148s 0.001s
im_detect: 2816/4024 0.148s 0.001s
im_detect: 2817/4024 0.148s 0.001s
im_detect: 2818/4024 0.148s 0.001s
im_detect: 2819/4024 0.148s 0.001s
im_detect: 2820/4024 0.148s 0.001s
im_detect: 2821/4024 0.148s 0.001s
im_detect: 2822/4024 0.148s 0.001s
im_detect: 2823/4024 0.148s 0.001s
im_detect: 2824/4024 0.148s 0.001s
im_detect: 2825/4024 0.148s 0.001s
im_detect: 2826/4024 0.148s 0.001s
im_detect: 2827/4024 0.148s 0.001s
im_detect: 2828/4024 0.148s 0.001s
im_detect: 2829/4024 0.148s 0.001s
im_detect: 2830/4024 0.148s 0.001s
im_detect: 2831/4024 0.148s 0.001s
im_detect: 2832/4024 0.148s 0.001s
im_detect: 2833/4024 0.148s 0.001s
im_detect: 2834/4024 0.148s 0.001s
im_detect: 2835/4024 0.148s 0.001s
im_detect: 2836/4024 0.148s 0.001s
im_detect: 2837/4024 0.148s 0.001s
im_detect: 2838/4024 0.148s 0.001s
im_detect: 2839/4024 0.148s 0.001s
im_detect: 2840/4024 0.148s 0.001s
im_detect: 2841/4024 0.148s 0.001s
im_detect: 2842/4024 0.148s 0.001s
im_detect: 2843/4024 0.148s 0.001s
im_detect: 2844/4024 0.148s 0.001s
im_detect: 2845/4024 0.148s 0.001s
im_detect: 2846/4024 0.148s 0.001s
im_detect: 2847/4024 0.148s 0.001s
im_detect: 2848/4024 0.148s 0.001s
im_detect: 2849/4024 0.148s 0.001s
im_detect: 2850/4024 0.148s 0.001s
im_detect: 2851/4024 0.148s 0.001s
im_detect: 2852/4024 0.148s 0.001s
im_detect: 2853/4024 0.148s 0.001s
im_detect: 2854/4024 0.148s 0.001s
im_detect: 2855/4024 0.148s 0.001s
im_detect: 2856/4024 0.148s 0.001s
im_detect: 2857/4024 0.148s 0.001s
im_detect: 2858/4024 0.148s 0.001s
im_detect: 2859/4024 0.148s 0.001s
im_detect: 2860/4024 0.148s 0.001s
im_detect: 2861/4024 0.148s 0.001s
im_detect: 2862/4024 0.148s 0.001s
im_detect: 2863/4024 0.148s 0.001s
im_detect: 2864/4024 0.148s 0.001s
im_detect: 2865/4024 0.148s 0.001s
im_detect: 2866/4024 0.148s 0.001s
im_detect: 2867/4024 0.148s 0.001s
im_detect: 2868/4024 0.148s 0.001s
im_detect: 2869/4024 0.148s 0.001s
im_detect: 2870/4024 0.148s 0.001s
im_detect: 2871/4024 0.148s 0.001s
im_detect: 2872/4024 0.148s 0.001s
im_detect: 2873/4024 0.148s 0.001s
im_detect: 2874/4024 0.148s 0.001s
im_detect: 2875/4024 0.148s 0.001s
im_detect: 2876/4024 0.148s 0.001s
im_detect: 2877/4024 0.148s 0.001s
im_detect: 2878/4024 0.148s 0.001s
im_detect: 2879/4024 0.148s 0.001s
im_detect: 2880/4024 0.148s 0.001s
im_detect: 2881/4024 0.148s 0.001s
im_detect: 2882/4024 0.148s 0.001s
im_detect: 2883/4024 0.148s 0.001s
im_detect: 2884/4024 0.148s 0.001s
im_detect: 2885/4024 0.148s 0.001s
im_detect: 2886/4024 0.148s 0.001s
im_detect: 2887/4024 0.148s 0.001s
im_detect: 2888/4024 0.148s 0.001s
im_detect: 2889/4024 0.148s 0.001s
im_detect: 2890/4024 0.148s 0.001s
im_detect: 2891/4024 0.148s 0.001s
im_detect: 2892/4024 0.148s 0.001s
im_detect: 2893/4024 0.148s 0.001s
im_detect: 2894/4024 0.148s 0.001s
im_detect: 2895/4024 0.148s 0.001s
im_detect: 2896/4024 0.148s 0.001s
im_detect: 2897/4024 0.148s 0.001s
im_detect: 2898/4024 0.148s 0.001s
im_detect: 2899/4024 0.148s 0.001s
im_detect: 2900/4024 0.148s 0.001s
im_detect: 2901/4024 0.148s 0.001s
im_detect: 2902/4024 0.148s 0.001s
im_detect: 2903/4024 0.148s 0.001s
im_detect: 2904/4024 0.148s 0.001s
im_detect: 2905/4024 0.148s 0.001s
im_detect: 2906/4024 0.148s 0.001s
im_detect: 2907/4024 0.148s 0.001s
im_detect: 2908/4024 0.148s 0.001s
im_detect: 2909/4024 0.148s 0.001s
im_detect: 2910/4024 0.148s 0.001s
im_detect: 2911/4024 0.148s 0.001s
im_detect: 2912/4024 0.148s 0.001s
im_detect: 2913/4024 0.148s 0.001s
im_detect: 2914/4024 0.148s 0.001s
im_detect: 2915/4024 0.148s 0.001s
im_detect: 2916/4024 0.148s 0.001s
im_detect: 2917/4024 0.148s 0.001s
im_detect: 2918/4024 0.148s 0.001s
im_detect: 2919/4024 0.148s 0.001s
im_detect: 2920/4024 0.148s 0.001s
im_detect: 2921/4024 0.148s 0.001s
im_detect: 2922/4024 0.148s 0.001s
im_detect: 2923/4024 0.148s 0.001s
im_detect: 2924/4024 0.148s 0.001s
im_detect: 2925/4024 0.148s 0.001s
im_detect: 2926/4024 0.148s 0.001s
im_detect: 2927/4024 0.148s 0.001s
im_detect: 2928/4024 0.148s 0.001s
im_detect: 2929/4024 0.148s 0.001s
im_detect: 2930/4024 0.148s 0.001s
im_detect: 2931/4024 0.148s 0.001s
im_detect: 2932/4024 0.148s 0.001s
im_detect: 2933/4024 0.148s 0.001s
im_detect: 2934/4024 0.148s 0.001s
im_detect: 2935/4024 0.148s 0.001s
im_detect: 2936/4024 0.148s 0.001s
im_detect: 2937/4024 0.148s 0.001s
im_detect: 2938/4024 0.148s 0.001s
im_detect: 2939/4024 0.148s 0.001s
im_detect: 2940/4024 0.148s 0.001s
im_detect: 2941/4024 0.148s 0.001s
im_detect: 2942/4024 0.148s 0.001s
im_detect: 2943/4024 0.148s 0.001s
im_detect: 2944/4024 0.148s 0.001s
im_detect: 2945/4024 0.148s 0.001s
im_detect: 2946/4024 0.148s 0.001s
im_detect: 2947/4024 0.148s 0.001s
im_detect: 2948/4024 0.148s 0.001s
im_detect: 2949/4024 0.148s 0.001s
im_detect: 2950/4024 0.148s 0.001s
im_detect: 2951/4024 0.148s 0.001s
im_detect: 2952/4024 0.148s 0.001s
im_detect: 2953/4024 0.148s 0.001s
im_detect: 2954/4024 0.148s 0.001s
im_detect: 2955/4024 0.148s 0.001s
im_detect: 2956/4024 0.148s 0.001s
im_detect: 2957/4024 0.148s 0.001s
im_detect: 2958/4024 0.148s 0.001s
im_detect: 2959/4024 0.148s 0.001s
im_detect: 2960/4024 0.148s 0.001s
im_detect: 2961/4024 0.148s 0.001s
im_detect: 2962/4024 0.148s 0.001s
im_detect: 2963/4024 0.148s 0.001s
im_detect: 2964/4024 0.148s 0.001s
im_detect: 2965/4024 0.148s 0.001s
im_detect: 2966/4024 0.148s 0.001s
im_detect: 2967/4024 0.148s 0.001s
im_detect: 2968/4024 0.148s 0.001s
im_detect: 2969/4024 0.148s 0.001s
im_detect: 2970/4024 0.148s 0.001s
im_detect: 2971/4024 0.148s 0.001s
im_detect: 2972/4024 0.148s 0.001s
im_detect: 2973/4024 0.148s 0.001s
im_detect: 2974/4024 0.148s 0.001s
im_detect: 2975/4024 0.148s 0.001s
im_detect: 2976/4024 0.148s 0.001s
im_detect: 2977/4024 0.148s 0.001s
im_detect: 2978/4024 0.148s 0.001s
im_detect: 2979/4024 0.148s 0.001s
im_detect: 2980/4024 0.148s 0.001s
im_detect: 2981/4024 0.148s 0.001s
im_detect: 2982/4024 0.148s 0.001s
im_detect: 2983/4024 0.148s 0.001s
im_detect: 2984/4024 0.148s 0.001s
im_detect: 2985/4024 0.148s 0.001s
im_detect: 2986/4024 0.148s 0.001s
im_detect: 2987/4024 0.148s 0.001s
im_detect: 2988/4024 0.148s 0.001s
im_detect: 2989/4024 0.148s 0.001s
im_detect: 2990/4024 0.148s 0.001s
im_detect: 2991/4024 0.148s 0.001s
im_detect: 2992/4024 0.148s 0.001s
im_detect: 2993/4024 0.148s 0.001s
im_detect: 2994/4024 0.148s 0.001s
im_detect: 2995/4024 0.148s 0.001s
im_detect: 2996/4024 0.148s 0.001s
im_detect: 2997/4024 0.148s 0.001s
im_detect: 2998/4024 0.148s 0.001s
im_detect: 2999/4024 0.149s 0.001s
im_detect: 3000/4024 0.148s 0.001s
im_detect: 3001/4024 0.148s 0.001s
im_detect: 3002/4024 0.148s 0.001s
im_detect: 3003/4024 0.148s 0.001s
im_detect: 3004/4024 0.148s 0.001s
im_detect: 3005/4024 0.148s 0.001s
im_detect: 3006/4024 0.148s 0.001s
im_detect: 3007/4024 0.148s 0.001s
im_detect: 3008/4024 0.148s 0.001s
im_detect: 3009/4024 0.148s 0.001s
im_detect: 3010/4024 0.148s 0.001s
im_detect: 3011/4024 0.148s 0.001s
im_detect: 3012/4024 0.148s 0.001s
im_detect: 3013/4024 0.148s 0.001s
im_detect: 3014/4024 0.148s 0.001s
im_detect: 3015/4024 0.148s 0.001s
im_detect: 3016/4024 0.148s 0.001s
im_detect: 3017/4024 0.148s 0.001s
im_detect: 3018/4024 0.148s 0.001s
im_detect: 3019/4024 0.148s 0.001s
im_detect: 3020/4024 0.148s 0.001s
im_detect: 3021/4024 0.148s 0.001s
im_detect: 3022/4024 0.148s 0.001s
im_detect: 3023/4024 0.148s 0.001s
im_detect: 3024/4024 0.148s 0.001s
im_detect: 3025/4024 0.148s 0.001s
im_detect: 3026/4024 0.148s 0.001s
im_detect: 3027/4024 0.148s 0.001s
im_detect: 3028/4024 0.148s 0.001s
im_detect: 3029/4024 0.148s 0.001s
im_detect: 3030/4024 0.148s 0.001s
im_detect: 3031/4024 0.148s 0.001s
im_detect: 3032/4024 0.148s 0.001s
im_detect: 3033/4024 0.148s 0.001s
im_detect: 3034/4024 0.148s 0.001s
im_detect: 3035/4024 0.148s 0.001s
im_detect: 3036/4024 0.148s 0.001s
im_detect: 3037/4024 0.148s 0.001s
im_detect: 3038/4024 0.148s 0.001s
im_detect: 3039/4024 0.148s 0.001s
im_detect: 3040/4024 0.148s 0.001s
im_detect: 3041/4024 0.148s 0.001s
im_detect: 3042/4024 0.148s 0.001s
im_detect: 3043/4024 0.148s 0.001s
im_detect: 3044/4024 0.148s 0.001s
im_detect: 3045/4024 0.148s 0.001s
im_detect: 3046/4024 0.148s 0.001s
im_detect: 3047/4024 0.148s 0.001s
im_detect: 3048/4024 0.148s 0.001s
im_detect: 3049/4024 0.148s 0.001s
im_detect: 3050/4024 0.148s 0.001s
im_detect: 3051/4024 0.148s 0.001s
im_detect: 3052/4024 0.148s 0.001s
im_detect: 3053/4024 0.148s 0.001s
im_detect: 3054/4024 0.148s 0.001s
im_detect: 3055/4024 0.148s 0.001s
im_detect: 3056/4024 0.148s 0.001s
im_detect: 3057/4024 0.148s 0.001s
im_detect: 3058/4024 0.148s 0.001s
im_detect: 3059/4024 0.148s 0.001s
im_detect: 3060/4024 0.148s 0.001s
im_detect: 3061/4024 0.148s 0.001s
im_detect: 3062/4024 0.148s 0.001s
im_detect: 3063/4024 0.148s 0.001s
im_detect: 3064/4024 0.148s 0.001s
im_detect: 3065/4024 0.148s 0.001s
im_detect: 3066/4024 0.148s 0.001s
im_detect: 3067/4024 0.148s 0.001s
im_detect: 3068/4024 0.148s 0.001s
im_detect: 3069/4024 0.148s 0.001s
im_detect: 3070/4024 0.148s 0.001s
im_detect: 3071/4024 0.148s 0.001s
im_detect: 3072/4024 0.148s 0.001s
im_detect: 3073/4024 0.148s 0.001s
im_detect: 3074/4024 0.148s 0.001s
im_detect: 3075/4024 0.148s 0.001s
im_detect: 3076/4024 0.148s 0.001s
im_detect: 3077/4024 0.148s 0.001s
im_detect: 3078/4024 0.148s 0.001s
im_detect: 3079/4024 0.148s 0.001s
im_detect: 3080/4024 0.148s 0.001s
im_detect: 3081/4024 0.148s 0.001s
im_detect: 3082/4024 0.148s 0.001s
im_detect: 3083/4024 0.148s 0.001s
im_detect: 3084/4024 0.148s 0.001s
im_detect: 3085/4024 0.148s 0.001s
im_detect: 3086/4024 0.148s 0.001s
im_detect: 3087/4024 0.148s 0.001s
im_detect: 3088/4024 0.148s 0.001s
im_detect: 3089/4024 0.148s 0.001s
im_detect: 3090/4024 0.148s 0.001s
im_detect: 3091/4024 0.148s 0.001s
im_detect: 3092/4024 0.148s 0.001s
im_detect: 3093/4024 0.148s 0.001s
im_detect: 3094/4024 0.148s 0.001s
im_detect: 3095/4024 0.148s 0.001s
im_detect: 3096/4024 0.148s 0.001s
im_detect: 3097/4024 0.148s 0.001s
im_detect: 3098/4024 0.148s 0.001s
im_detect: 3099/4024 0.148s 0.001s
im_detect: 3100/4024 0.148s 0.001s
im_detect: 3101/4024 0.148s 0.001s
im_detect: 3102/4024 0.148s 0.001s
im_detect: 3103/4024 0.148s 0.001s
im_detect: 3104/4024 0.148s 0.001s
im_detect: 3105/4024 0.148s 0.001s
im_detect: 3106/4024 0.148s 0.001s
im_detect: 3107/4024 0.148s 0.001s
im_detect: 3108/4024 0.148s 0.001s
im_detect: 3109/4024 0.148s 0.001s
im_detect: 3110/4024 0.148s 0.001s
im_detect: 3111/4024 0.148s 0.001s
im_detect: 3112/4024 0.148s 0.001s
im_detect: 3113/4024 0.148s 0.001s
im_detect: 3114/4024 0.148s 0.001s
im_detect: 3115/4024 0.148s 0.001s
im_detect: 3116/4024 0.148s 0.001s
im_detect: 3117/4024 0.148s 0.001s
im_detect: 3118/4024 0.148s 0.001s
im_detect: 3119/4024 0.148s 0.001s
im_detect: 3120/4024 0.148s 0.001s
im_detect: 3121/4024 0.148s 0.001s
im_detect: 3122/4024 0.148s 0.001s
im_detect: 3123/4024 0.148s 0.001s
im_detect: 3124/4024 0.148s 0.001s
im_detect: 3125/4024 0.148s 0.001s
im_detect: 3126/4024 0.148s 0.001s
im_detect: 3127/4024 0.148s 0.001s
im_detect: 3128/4024 0.148s 0.001s
im_detect: 3129/4024 0.148s 0.001s
im_detect: 3130/4024 0.148s 0.001s
im_detect: 3131/4024 0.148s 0.001s
im_detect: 3132/4024 0.148s 0.001s
im_detect: 3133/4024 0.148s 0.001s
im_detect: 3134/4024 0.148s 0.001s
im_detect: 3135/4024 0.148s 0.001s
im_detect: 3136/4024 0.148s 0.001s
im_detect: 3137/4024 0.148s 0.001s
im_detect: 3138/4024 0.148s 0.001s
im_detect: 3139/4024 0.148s 0.001s
im_detect: 3140/4024 0.148s 0.001s
im_detect: 3141/4024 0.148s 0.001s
im_detect: 3142/4024 0.148s 0.001s
im_detect: 3143/4024 0.148s 0.001s
im_detect: 3144/4024 0.148s 0.001s
im_detect: 3145/4024 0.148s 0.001s
im_detect: 3146/4024 0.148s 0.001s
im_detect: 3147/4024 0.148s 0.001s
im_detect: 3148/4024 0.148s 0.001s
im_detect: 3149/4024 0.148s 0.001s
im_detect: 3150/4024 0.148s 0.001s
im_detect: 3151/4024 0.148s 0.001s
im_detect: 3152/4024 0.148s 0.001s
im_detect: 3153/4024 0.148s 0.001s
im_detect: 3154/4024 0.148s 0.001s
im_detect: 3155/4024 0.148s 0.001s
im_detect: 3156/4024 0.148s 0.001s
im_detect: 3157/4024 0.148s 0.001s
im_detect: 3158/4024 0.148s 0.001s
im_detect: 3159/4024 0.148s 0.001s
im_detect: 3160/4024 0.148s 0.001s
im_detect: 3161/4024 0.148s 0.001s
im_detect: 3162/4024 0.148s 0.001s
im_detect: 3163/4024 0.148s 0.001s
im_detect: 3164/4024 0.148s 0.001s
im_detect: 3165/4024 0.148s 0.001s
im_detect: 3166/4024 0.148s 0.001s
im_detect: 3167/4024 0.148s 0.001s
im_detect: 3168/4024 0.148s 0.001s
im_detect: 3169/4024 0.148s 0.001s
im_detect: 3170/4024 0.148s 0.001s
im_detect: 3171/4024 0.148s 0.001s
im_detect: 3172/4024 0.148s 0.001s
im_detect: 3173/4024 0.148s 0.001s
im_detect: 3174/4024 0.148s 0.001s
im_detect: 3175/4024 0.148s 0.001s
im_detect: 3176/4024 0.148s 0.001s
im_detect: 3177/4024 0.148s 0.001s
im_detect: 3178/4024 0.148s 0.001s
im_detect: 3179/4024 0.148s 0.001s
im_detect: 3180/4024 0.148s 0.001s
im_detect: 3181/4024 0.148s 0.001s
im_detect: 3182/4024 0.148s 0.001s
im_detect: 3183/4024 0.148s 0.001s
im_detect: 3184/4024 0.148s 0.001s
im_detect: 3185/4024 0.148s 0.001s
im_detect: 3186/4024 0.148s 0.001s
im_detect: 3187/4024 0.148s 0.001s
im_detect: 3188/4024 0.148s 0.001s
im_detect: 3189/4024 0.148s 0.001s
im_detect: 3190/4024 0.148s 0.001s
im_detect: 3191/4024 0.148s 0.001s
im_detect: 3192/4024 0.148s 0.001s
im_detect: 3193/4024 0.148s 0.001s
im_detect: 3194/4024 0.148s 0.001s
im_detect: 3195/4024 0.148s 0.001s
im_detect: 3196/4024 0.148s 0.001s
im_detect: 3197/4024 0.148s 0.001s
im_detect: 3198/4024 0.148s 0.001s
im_detect: 3199/4024 0.148s 0.001s
im_detect: 3200/4024 0.148s 0.001s
im_detect: 3201/4024 0.148s 0.001s
im_detect: 3202/4024 0.148s 0.001s
im_detect: 3203/4024 0.148s 0.001s
im_detect: 3204/4024 0.148s 0.001s
im_detect: 3205/4024 0.148s 0.001s
im_detect: 3206/4024 0.148s 0.001s
im_detect: 3207/4024 0.148s 0.001s
im_detect: 3208/4024 0.148s 0.001s
im_detect: 3209/4024 0.148s 0.001s
im_detect: 3210/4024 0.148s 0.001s
im_detect: 3211/4024 0.148s 0.001s
im_detect: 3212/4024 0.148s 0.001s
im_detect: 3213/4024 0.148s 0.001s
im_detect: 3214/4024 0.148s 0.001s
im_detect: 3215/4024 0.148s 0.001s
im_detect: 3216/4024 0.148s 0.001s
im_detect: 3217/4024 0.148s 0.001s
im_detect: 3218/4024 0.148s 0.001s
im_detect: 3219/4024 0.148s 0.001s
im_detect: 3220/4024 0.148s 0.001s
im_detect: 3221/4024 0.148s 0.001s
im_detect: 3222/4024 0.148s 0.001s
im_detect: 3223/4024 0.148s 0.001s
im_detect: 3224/4024 0.148s 0.001s
im_detect: 3225/4024 0.148s 0.001s
im_detect: 3226/4024 0.148s 0.001s
im_detect: 3227/4024 0.148s 0.001s
im_detect: 3228/4024 0.148s 0.001s
im_detect: 3229/4024 0.148s 0.001s
im_detect: 3230/4024 0.148s 0.001s
im_detect: 3231/4024 0.148s 0.001s
im_detect: 3232/4024 0.148s 0.001s
im_detect: 3233/4024 0.148s 0.001s
im_detect: 3234/4024 0.148s 0.001s
im_detect: 3235/4024 0.148s 0.001s
im_detect: 3236/4024 0.148s 0.001s
im_detect: 3237/4024 0.148s 0.001s
im_detect: 3238/4024 0.148s 0.001s
im_detect: 3239/4024 0.148s 0.001s
im_detect: 3240/4024 0.148s 0.001s
im_detect: 3241/4024 0.148s 0.001s
im_detect: 3242/4024 0.148s 0.001s
im_detect: 3243/4024 0.148s 0.001s
im_detect: 3244/4024 0.148s 0.001s
im_detect: 3245/4024 0.148s 0.001s
im_detect: 3246/4024 0.148s 0.001s
im_detect: 3247/4024 0.148s 0.001s
im_detect: 3248/4024 0.148s 0.001s
im_detect: 3249/4024 0.148s 0.001s
im_detect: 3250/4024 0.148s 0.001s
im_detect: 3251/4024 0.148s 0.001s
im_detect: 3252/4024 0.148s 0.001s
im_detect: 3253/4024 0.148s 0.001s
im_detect: 3254/4024 0.148s 0.001s
im_detect: 3255/4024 0.148s 0.001s
im_detect: 3256/4024 0.148s 0.001s
im_detect: 3257/4024 0.148s 0.001s
im_detect: 3258/4024 0.148s 0.001s
im_detect: 3259/4024 0.148s 0.001s
im_detect: 3260/4024 0.148s 0.001s
im_detect: 3261/4024 0.148s 0.001s
im_detect: 3262/4024 0.148s 0.001s
im_detect: 3263/4024 0.148s 0.001s
im_detect: 3264/4024 0.148s 0.001s
im_detect: 3265/4024 0.148s 0.001s
im_detect: 3266/4024 0.148s 0.001s
im_detect: 3267/4024 0.148s 0.001s
im_detect: 3268/4024 0.148s 0.001s
im_detect: 3269/4024 0.148s 0.001s
im_detect: 3270/4024 0.148s 0.001s
im_detect: 3271/4024 0.148s 0.001s
im_detect: 3272/4024 0.148s 0.001s
im_detect: 3273/4024 0.148s 0.001s
im_detect: 3274/4024 0.148s 0.001s
im_detect: 3275/4024 0.148s 0.001s
im_detect: 3276/4024 0.148s 0.001s
im_detect: 3277/4024 0.148s 0.001s
im_detect: 3278/4024 0.148s 0.001s
im_detect: 3279/4024 0.148s 0.001s
im_detect: 3280/4024 0.148s 0.001s
im_detect: 3281/4024 0.148s 0.001s
im_detect: 3282/4024 0.148s 0.001s
im_detect: 3283/4024 0.148s 0.001s
im_detect: 3284/4024 0.148s 0.001s
im_detect: 3285/4024 0.148s 0.001s
im_detect: 3286/4024 0.148s 0.001s
im_detect: 3287/4024 0.148s 0.001s
im_detect: 3288/4024 0.148s 0.001s
im_detect: 3289/4024 0.148s 0.001s
im_detect: 3290/4024 0.148s 0.001s
im_detect: 3291/4024 0.148s 0.001s
im_detect: 3292/4024 0.148s 0.001s
im_detect: 3293/4024 0.148s 0.001s
im_detect: 3294/4024 0.148s 0.001s
im_detect: 3295/4024 0.148s 0.001s
im_detect: 3296/4024 0.148s 0.001s
im_detect: 3297/4024 0.148s 0.001s
im_detect: 3298/4024 0.148s 0.001s
im_detect: 3299/4024 0.148s 0.001s
im_detect: 3300/4024 0.148s 0.001s
im_detect: 3301/4024 0.148s 0.001s
im_detect: 3302/4024 0.148s 0.001s
im_detect: 3303/4024 0.148s 0.001s
im_detect: 3304/4024 0.148s 0.001s
im_detect: 3305/4024 0.148s 0.001s
im_detect: 3306/4024 0.148s 0.001s
im_detect: 3307/4024 0.148s 0.001s
im_detect: 3308/4024 0.148s 0.001s
im_detect: 3309/4024 0.148s 0.001s
im_detect: 3310/4024 0.148s 0.001s
im_detect: 3311/4024 0.148s 0.001s
im_detect: 3312/4024 0.148s 0.001s
im_detect: 3313/4024 0.148s 0.001s
im_detect: 3314/4024 0.148s 0.001s
im_detect: 3315/4024 0.148s 0.001s
im_detect: 3316/4024 0.148s 0.001s
im_detect: 3317/4024 0.148s 0.001s
im_detect: 3318/4024 0.148s 0.001s
im_detect: 3319/4024 0.148s 0.001s
im_detect: 3320/4024 0.148s 0.001s
im_detect: 3321/4024 0.148s 0.001s
im_detect: 3322/4024 0.148s 0.001s
im_detect: 3323/4024 0.148s 0.001s
im_detect: 3324/4024 0.148s 0.001s
im_detect: 3325/4024 0.148s 0.001s
im_detect: 3326/4024 0.148s 0.001s
im_detect: 3327/4024 0.148s 0.001s
im_detect: 3328/4024 0.148s 0.001s
im_detect: 3329/4024 0.148s 0.001s
im_detect: 3330/4024 0.148s 0.001s
im_detect: 3331/4024 0.148s 0.001s
im_detect: 3332/4024 0.148s 0.001s
im_detect: 3333/4024 0.148s 0.001s
im_detect: 3334/4024 0.148s 0.001s
im_detect: 3335/4024 0.148s 0.001s
im_detect: 3336/4024 0.148s 0.001s
im_detect: 3337/4024 0.148s 0.001s
im_detect: 3338/4024 0.148s 0.001s
im_detect: 3339/4024 0.148s 0.001s
im_detect: 3340/4024 0.148s 0.001s
im_detect: 3341/4024 0.148s 0.001s
im_detect: 3342/4024 0.148s 0.001s
im_detect: 3343/4024 0.148s 0.001s
im_detect: 3344/4024 0.148s 0.001s
im_detect: 3345/4024 0.148s 0.001s
im_detect: 3346/4024 0.148s 0.001s
im_detect: 3347/4024 0.148s 0.001s
im_detect: 3348/4024 0.148s 0.001s
im_detect: 3349/4024 0.148s 0.001s
im_detect: 3350/4024 0.148s 0.001s
im_detect: 3351/4024 0.148s 0.001s
im_detect: 3352/4024 0.148s 0.001s
im_detect: 3353/4024 0.148s 0.001s
im_detect: 3354/4024 0.148s 0.001s
im_detect: 3355/4024 0.148s 0.001s
im_detect: 3356/4024 0.148s 0.001s
im_detect: 3357/4024 0.148s 0.001s
im_detect: 3358/4024 0.148s 0.001s
im_detect: 3359/4024 0.148s 0.001s
im_detect: 3360/4024 0.148s 0.001s
im_detect: 3361/4024 0.148s 0.001s
im_detect: 3362/4024 0.148s 0.001s
im_detect: 3363/4024 0.148s 0.001s
im_detect: 3364/4024 0.148s 0.001s
im_detect: 3365/4024 0.148s 0.001s
im_detect: 3366/4024 0.148s 0.001s
im_detect: 3367/4024 0.148s 0.001s
im_detect: 3368/4024 0.148s 0.001s
im_detect: 3369/4024 0.148s 0.001s
im_detect: 3370/4024 0.148s 0.001s
im_detect: 3371/4024 0.148s 0.001s
im_detect: 3372/4024 0.148s 0.001s
im_detect: 3373/4024 0.148s 0.001s
im_detect: 3374/4024 0.148s 0.001s
im_detect: 3375/4024 0.148s 0.001s
im_detect: 3376/4024 0.148s 0.001s
im_detect: 3377/4024 0.148s 0.001s
im_detect: 3378/4024 0.148s 0.001s
im_detect: 3379/4024 0.148s 0.001s
im_detect: 3380/4024 0.148s 0.001s
im_detect: 3381/4024 0.148s 0.001s
im_detect: 3382/4024 0.148s 0.001s
im_detect: 3383/4024 0.148s 0.001s
im_detect: 3384/4024 0.148s 0.001s
im_detect: 3385/4024 0.148s 0.001s
im_detect: 3386/4024 0.148s 0.001s
im_detect: 3387/4024 0.148s 0.001s
im_detect: 3388/4024 0.148s 0.001s
im_detect: 3389/4024 0.148s 0.001s
im_detect: 3390/4024 0.148s 0.001s
im_detect: 3391/4024 0.148s 0.001s
im_detect: 3392/4024 0.148s 0.001s
im_detect: 3393/4024 0.148s 0.001s
im_detect: 3394/4024 0.148s 0.001s
im_detect: 3395/4024 0.148s 0.001s
im_detect: 3396/4024 0.148s 0.001s
im_detect: 3397/4024 0.148s 0.001s
im_detect: 3398/4024 0.148s 0.001s
im_detect: 3399/4024 0.148s 0.001s
im_detect: 3400/4024 0.148s 0.001s
im_detect: 3401/4024 0.148s 0.001s
im_detect: 3402/4024 0.148s 0.001s
im_detect: 3403/4024 0.148s 0.001s
im_detect: 3404/4024 0.148s 0.001s
im_detect: 3405/4024 0.148s 0.001s
im_detect: 3406/4024 0.148s 0.001s
im_detect: 3407/4024 0.148s 0.001s
im_detect: 3408/4024 0.148s 0.001s
im_detect: 3409/4024 0.148s 0.001s
im_detect: 3410/4024 0.148s 0.001s
im_detect: 3411/4024 0.148s 0.001s
im_detect: 3412/4024 0.148s 0.001s
im_detect: 3413/4024 0.148s 0.001s
im_detect: 3414/4024 0.148s 0.001s
im_detect: 3415/4024 0.148s 0.001s
im_detect: 3416/4024 0.148s 0.001s
im_detect: 3417/4024 0.148s 0.001s
im_detect: 3418/4024 0.148s 0.001s
im_detect: 3419/4024 0.148s 0.001s
im_detect: 3420/4024 0.148s 0.001s
im_detect: 3421/4024 0.148s 0.001s
im_detect: 3422/4024 0.148s 0.001s
im_detect: 3423/4024 0.148s 0.001s
im_detect: 3424/4024 0.148s 0.001s
im_detect: 3425/4024 0.148s 0.001s
im_detect: 3426/4024 0.148s 0.001s
im_detect: 3427/4024 0.148s 0.001s
im_detect: 3428/4024 0.148s 0.001s
im_detect: 3429/4024 0.148s 0.001s
im_detect: 3430/4024 0.148s 0.001s
im_detect: 3431/4024 0.148s 0.001s
im_detect: 3432/4024 0.148s 0.001s
im_detect: 3433/4024 0.148s 0.001s
im_detect: 3434/4024 0.148s 0.001s
im_detect: 3435/4024 0.148s 0.001s
im_detect: 3436/4024 0.148s 0.001s
im_detect: 3437/4024 0.148s 0.001s
im_detect: 3438/4024 0.148s 0.001s
im_detect: 3439/4024 0.148s 0.001s
im_detect: 3440/4024 0.148s 0.001s
im_detect: 3441/4024 0.148s 0.001s
im_detect: 3442/4024 0.148s 0.001s
im_detect: 3443/4024 0.148s 0.001s
im_detect: 3444/4024 0.148s 0.001s
im_detect: 3445/4024 0.148s 0.001s
im_detect: 3446/4024 0.148s 0.001s
im_detect: 3447/4024 0.148s 0.001s
im_detect: 3448/4024 0.148s 0.001s
im_detect: 3449/4024 0.148s 0.001s
im_detect: 3450/4024 0.148s 0.001s
im_detect: 3451/4024 0.148s 0.001s
im_detect: 3452/4024 0.148s 0.001s
im_detect: 3453/4024 0.148s 0.001s
im_detect: 3454/4024 0.148s 0.001s
im_detect: 3455/4024 0.148s 0.001s
im_detect: 3456/4024 0.148s 0.001s
im_detect: 3457/4024 0.148s 0.001s
im_detect: 3458/4024 0.148s 0.001s
im_detect: 3459/4024 0.148s 0.001s
im_detect: 3460/4024 0.148s 0.001s
im_detect: 3461/4024 0.148s 0.001s
im_detect: 3462/4024 0.148s 0.001s
im_detect: 3463/4024 0.148s 0.001s
im_detect: 3464/4024 0.148s 0.001s
im_detect: 3465/4024 0.148s 0.001s
im_detect: 3466/4024 0.148s 0.001s
im_detect: 3467/4024 0.148s 0.001s
im_detect: 3468/4024 0.148s 0.001s
im_detect: 3469/4024 0.148s 0.001s
im_detect: 3470/4024 0.148s 0.001s
im_detect: 3471/4024 0.148s 0.001s
im_detect: 3472/4024 0.148s 0.001s
im_detect: 3473/4024 0.148s 0.001s
im_detect: 3474/4024 0.148s 0.001s
im_detect: 3475/4024 0.148s 0.001s
im_detect: 3476/4024 0.148s 0.001s
im_detect: 3477/4024 0.148s 0.001s
im_detect: 3478/4024 0.148s 0.001s
im_detect: 3479/4024 0.148s 0.001s
im_detect: 3480/4024 0.148s 0.001s
im_detect: 3481/4024 0.148s 0.001s
im_detect: 3482/4024 0.148s 0.001s
im_detect: 3483/4024 0.148s 0.001s
im_detect: 3484/4024 0.148s 0.001s
im_detect: 3485/4024 0.148s 0.001s
im_detect: 3486/4024 0.148s 0.001s
im_detect: 3487/4024 0.148s 0.001s
im_detect: 3488/4024 0.148s 0.001s
im_detect: 3489/4024 0.148s 0.001s
im_detect: 3490/4024 0.148s 0.001s
im_detect: 3491/4024 0.148s 0.001s
im_detect: 3492/4024 0.148s 0.001s
im_detect: 3493/4024 0.148s 0.001s
im_detect: 3494/4024 0.148s 0.001s
im_detect: 3495/4024 0.148s 0.001s
im_detect: 3496/4024 0.148s 0.001s
im_detect: 3497/4024 0.148s 0.001s
im_detect: 3498/4024 0.148s 0.001s
im_detect: 3499/4024 0.148s 0.001s
im_detect: 3500/4024 0.148s 0.001s
im_detect: 3501/4024 0.148s 0.001s
im_detect: 3502/4024 0.148s 0.001s
im_detect: 3503/4024 0.148s 0.001s
im_detect: 3504/4024 0.148s 0.001s
im_detect: 3505/4024 0.148s 0.001s
im_detect: 3506/4024 0.148s 0.001s
im_detect: 3507/4024 0.148s 0.001s
im_detect: 3508/4024 0.148s 0.001s
im_detect: 3509/4024 0.148s 0.001s
im_detect: 3510/4024 0.148s 0.001s
im_detect: 3511/4024 0.148s 0.001s
im_detect: 3512/4024 0.148s 0.001s
im_detect: 3513/4024 0.148s 0.001s
im_detect: 3514/4024 0.148s 0.001s
im_detect: 3515/4024 0.148s 0.001s
im_detect: 3516/4024 0.148s 0.001s
im_detect: 3517/4024 0.148s 0.001s
im_detect: 3518/4024 0.148s 0.001s
im_detect: 3519/4024 0.148s 0.001s
im_detect: 3520/4024 0.148s 0.001s
im_detect: 3521/4024 0.148s 0.001s
im_detect: 3522/4024 0.148s 0.001s
im_detect: 3523/4024 0.148s 0.001s
im_detect: 3524/4024 0.148s 0.001s
im_detect: 3525/4024 0.148s 0.001s
im_detect: 3526/4024 0.148s 0.001s
im_detect: 3527/4024 0.148s 0.001s
im_detect: 3528/4024 0.148s 0.001s
im_detect: 3529/4024 0.148s 0.001s
im_detect: 3530/4024 0.148s 0.001s
im_detect: 3531/4024 0.148s 0.001s
im_detect: 3532/4024 0.148s 0.001s
im_detect: 3533/4024 0.148s 0.001s
im_detect: 3534/4024 0.148s 0.001s
im_detect: 3535/4024 0.148s 0.001s
im_detect: 3536/4024 0.148s 0.001s
im_detect: 3537/4024 0.148s 0.001s
im_detect: 3538/4024 0.148s 0.001s
im_detect: 3539/4024 0.148s 0.001s
im_detect: 3540/4024 0.148s 0.001s
im_detect: 3541/4024 0.148s 0.001s
im_detect: 3542/4024 0.148s 0.001s
im_detect: 3543/4024 0.148s 0.001s
im_detect: 3544/4024 0.148s 0.001s
im_detect: 3545/4024 0.148s 0.001s
im_detect: 3546/4024 0.148s 0.001s
im_detect: 3547/4024 0.148s 0.001s
im_detect: 3548/4024 0.148s 0.001s
im_detect: 3549/4024 0.148s 0.001s
im_detect: 3550/4024 0.148s 0.001s
im_detect: 3551/4024 0.148s 0.001s
im_detect: 3552/4024 0.148s 0.001s
im_detect: 3553/4024 0.148s 0.001s
im_detect: 3554/4024 0.148s 0.001s
im_detect: 3555/4024 0.148s 0.001s
im_detect: 3556/4024 0.148s 0.001s
im_detect: 3557/4024 0.148s 0.001s
im_detect: 3558/4024 0.149s 0.001s
im_detect: 3559/4024 0.149s 0.001s
im_detect: 3560/4024 0.149s 0.001s
im_detect: 3561/4024 0.149s 0.001s
im_detect: 3562/4024 0.149s 0.001s
im_detect: 3563/4024 0.149s 0.001s
im_detect: 3564/4024 0.149s 0.001s
im_detect: 3565/4024 0.149s 0.001s
im_detect: 3566/4024 0.149s 0.001s
im_detect: 3567/4024 0.149s 0.001s
im_detect: 3568/4024 0.149s 0.001s
im_detect: 3569/4024 0.149s 0.001s
im_detect: 3570/4024 0.149s 0.001s
im_detect: 3571/4024 0.149s 0.001s
im_detect: 3572/4024 0.149s 0.001s
im_detect: 3573/4024 0.149s 0.001s
im_detect: 3574/4024 0.149s 0.001s
im_detect: 3575/4024 0.149s 0.001s
im_detect: 3576/4024 0.149s 0.001s
im_detect: 3577/4024 0.149s 0.001s
im_detect: 3578/4024 0.149s 0.001s
im_detect: 3579/4024 0.149s 0.001s
im_detect: 3580/4024 0.149s 0.001s
im_detect: 3581/4024 0.149s 0.001s
im_detect: 3582/4024 0.149s 0.001s
im_detect: 3583/4024 0.149s 0.001s
im_detect: 3584/4024 0.149s 0.001s
im_detect: 3585/4024 0.149s 0.001s
im_detect: 3586/4024 0.149s 0.001s
im_detect: 3587/4024 0.149s 0.001s
im_detect: 3588/4024 0.149s 0.001s
im_detect: 3589/4024 0.149s 0.001s
im_detect: 3590/4024 0.149s 0.001s
im_detect: 3591/4024 0.149s 0.001s
im_detect: 3592/4024 0.149s 0.001s
im_detect: 3593/4024 0.149s 0.001s
im_detect: 3594/4024 0.149s 0.001s
im_detect: 3595/4024 0.149s 0.001s
im_detect: 3596/4024 0.149s 0.001s
im_detect: 3597/4024 0.149s 0.001s
im_detect: 3598/4024 0.149s 0.001s
im_detect: 3599/4024 0.149s 0.001s
im_detect: 3600/4024 0.149s 0.001s
im_detect: 3601/4024 0.149s 0.001s
im_detect: 3602/4024 0.149s 0.001s
im_detect: 3603/4024 0.149s 0.001s
im_detect: 3604/4024 0.149s 0.001s
im_detect: 3605/4024 0.149s 0.001s
im_detect: 3606/4024 0.149s 0.001s
im_detect: 3607/4024 0.149s 0.001s
im_detect: 3608/4024 0.149s 0.001s
im_detect: 3609/4024 0.149s 0.001s
im_detect: 3610/4024 0.149s 0.001s
im_detect: 3611/4024 0.149s 0.001s
im_detect: 3612/4024 0.149s 0.001s
im_detect: 3613/4024 0.149s 0.001s
im_detect: 3614/4024 0.149s 0.001s
im_detect: 3615/4024 0.149s 0.001s
im_detect: 3616/4024 0.149s 0.001s
im_detect: 3617/4024 0.149s 0.001s
im_detect: 3618/4024 0.149s 0.001s
im_detect: 3619/4024 0.149s 0.001s
im_detect: 3620/4024 0.149s 0.001s
im_detect: 3621/4024 0.149s 0.001s
im_detect: 3622/4024 0.149s 0.001s
im_detect: 3623/4024 0.149s 0.001s
im_detect: 3624/4024 0.149s 0.001s
im_detect: 3625/4024 0.149s 0.001s
im_detect: 3626/4024 0.149s 0.001s
im_detect: 3627/4024 0.149s 0.001s
im_detect: 3628/4024 0.149s 0.001s
im_detect: 3629/4024 0.149s 0.001s
im_detect: 3630/4024 0.149s 0.001s
im_detect: 3631/4024 0.149s 0.001s
im_detect: 3632/4024 0.149s 0.001s
im_detect: 3633/4024 0.149s 0.001s
im_detect: 3634/4024 0.149s 0.001s
im_detect: 3635/4024 0.149s 0.001s
im_detect: 3636/4024 0.149s 0.001s
im_detect: 3637/4024 0.149s 0.001s
im_detect: 3638/4024 0.149s 0.001s
im_detect: 3639/4024 0.149s 0.001s
im_detect: 3640/4024 0.149s 0.001s
im_detect: 3641/4024 0.149s 0.001s
im_detect: 3642/4024 0.149s 0.001s
im_detect: 3643/4024 0.149s 0.001s
im_detect: 3644/4024 0.149s 0.001s
im_detect: 3645/4024 0.149s 0.001s
im_detect: 3646/4024 0.149s 0.001s
im_detect: 3647/4024 0.149s 0.001s
im_detect: 3648/4024 0.149s 0.001s
im_detect: 3649/4024 0.149s 0.001s
im_detect: 3650/4024 0.149s 0.001s
im_detect: 3651/4024 0.149s 0.001s
im_detect: 3652/4024 0.149s 0.001s
im_detect: 3653/4024 0.149s 0.001s
im_detect: 3654/4024 0.149s 0.001s
im_detect: 3655/4024 0.149s 0.001s
im_detect: 3656/4024 0.149s 0.001s
im_detect: 3657/4024 0.149s 0.001s
im_detect: 3658/4024 0.149s 0.001s
im_detect: 3659/4024 0.149s 0.001s
im_detect: 3660/4024 0.149s 0.001s
im_detect: 3661/4024 0.149s 0.001s
im_detect: 3662/4024 0.149s 0.001s
im_detect: 3663/4024 0.149s 0.001s
im_detect: 3664/4024 0.149s 0.001s
im_detect: 3665/4024 0.149s 0.001s
im_detect: 3666/4024 0.149s 0.001s
im_detect: 3667/4024 0.149s 0.001s
im_detect: 3668/4024 0.149s 0.001s
im_detect: 3669/4024 0.149s 0.001s
im_detect: 3670/4024 0.149s 0.001s
im_detect: 3671/4024 0.149s 0.001s
im_detect: 3672/4024 0.149s 0.001s
im_detect: 3673/4024 0.149s 0.001s
im_detect: 3674/4024 0.149s 0.001s
im_detect: 3675/4024 0.149s 0.001s
im_detect: 3676/4024 0.149s 0.001s
im_detect: 3677/4024 0.149s 0.001s
im_detect: 3678/4024 0.149s 0.001s
im_detect: 3679/4024 0.149s 0.001s
im_detect: 3680/4024 0.149s 0.001s
im_detect: 3681/4024 0.149s 0.001s
im_detect: 3682/4024 0.149s 0.001s
im_detect: 3683/4024 0.149s 0.001s
im_detect: 3684/4024 0.149s 0.001s
im_detect: 3685/4024 0.149s 0.001s
im_detect: 3686/4024 0.149s 0.001s
im_detect: 3687/4024 0.149s 0.001s
im_detect: 3688/4024 0.149s 0.001s
im_detect: 3689/4024 0.149s 0.001s
im_detect: 3690/4024 0.149s 0.001s
im_detect: 3691/4024 0.149s 0.001s
im_detect: 3692/4024 0.149s 0.001s
im_detect: 3693/4024 0.149s 0.001s
im_detect: 3694/4024 0.149s 0.001s
im_detect: 3695/4024 0.149s 0.001s
im_detect: 3696/4024 0.149s 0.001s
im_detect: 3697/4024 0.149s 0.001s
im_detect: 3698/4024 0.149s 0.001s
im_detect: 3699/4024 0.149s 0.001s
im_detect: 3700/4024 0.149s 0.001s
im_detect: 3701/4024 0.149s 0.001s
im_detect: 3702/4024 0.149s 0.001s
im_detect: 3703/4024 0.149s 0.001s
im_detect: 3704/4024 0.149s 0.001s
im_detect: 3705/4024 0.149s 0.001s
im_detect: 3706/4024 0.149s 0.001s
im_detect: 3707/4024 0.149s 0.001s
im_detect: 3708/4024 0.149s 0.001s
im_detect: 3709/4024 0.149s 0.001s
im_detect: 3710/4024 0.149s 0.001s
im_detect: 3711/4024 0.149s 0.001s
im_detect: 3712/4024 0.149s 0.001s
im_detect: 3713/4024 0.149s 0.001s
im_detect: 3714/4024 0.149s 0.001s
im_detect: 3715/4024 0.149s 0.001s
im_detect: 3716/4024 0.149s 0.001s
im_detect: 3717/4024 0.149s 0.001s
im_detect: 3718/4024 0.149s 0.001s
im_detect: 3719/4024 0.149s 0.001s
im_detect: 3720/4024 0.149s 0.001s
im_detect: 3721/4024 0.149s 0.001s
im_detect: 3722/4024 0.149s 0.001s
im_detect: 3723/4024 0.149s 0.001s
im_detect: 3724/4024 0.149s 0.001s
im_detect: 3725/4024 0.149s 0.001s
im_detect: 3726/4024 0.149s 0.001s
im_detect: 3727/4024 0.149s 0.001s
im_detect: 3728/4024 0.149s 0.001s
im_detect: 3729/4024 0.149s 0.001s
im_detect: 3730/4024 0.149s 0.001s
im_detect: 3731/4024 0.149s 0.001s
im_detect: 3732/4024 0.149s 0.001s
im_detect: 3733/4024 0.149s 0.001s
im_detect: 3734/4024 0.149s 0.001s
im_detect: 3735/4024 0.149s 0.001s
im_detect: 3736/4024 0.149s 0.001s
im_detect: 3737/4024 0.149s 0.001s
im_detect: 3738/4024 0.149s 0.001s
im_detect: 3739/4024 0.149s 0.001s
im_detect: 3740/4024 0.149s 0.001s
im_detect: 3741/4024 0.149s 0.001s
im_detect: 3742/4024 0.149s 0.001s
im_detect: 3743/4024 0.149s 0.001s
im_detect: 3744/4024 0.149s 0.001s
im_detect: 3745/4024 0.149s 0.001s
im_detect: 3746/4024 0.149s 0.001s
im_detect: 3747/4024 0.149s 0.001s
im_detect: 3748/4024 0.149s 0.001s
im_detect: 3749/4024 0.149s 0.001s
im_detect: 3750/4024 0.149s 0.001s
im_detect: 3751/4024 0.149s 0.001s
im_detect: 3752/4024 0.149s 0.001s
im_detect: 3753/4024 0.149s 0.001s
im_detect: 3754/4024 0.149s 0.001s
im_detect: 3755/4024 0.149s 0.001s
im_detect: 3756/4024 0.149s 0.001s
im_detect: 3757/4024 0.149s 0.001s
im_detect: 3758/4024 0.149s 0.001s
im_detect: 3759/4024 0.149s 0.001s
im_detect: 3760/4024 0.149s 0.001s
im_detect: 3761/4024 0.149s 0.001s
im_detect: 3762/4024 0.149s 0.001s
im_detect: 3763/4024 0.149s 0.001s
im_detect: 3764/4024 0.149s 0.001s
im_detect: 3765/4024 0.149s 0.001s
im_detect: 3766/4024 0.149s 0.001s
im_detect: 3767/4024 0.149s 0.001s
im_detect: 3768/4024 0.149s 0.001s
im_detect: 3769/4024 0.149s 0.001s
im_detect: 3770/4024 0.149s 0.001s
im_detect: 3771/4024 0.149s 0.001s
im_detect: 3772/4024 0.149s 0.001s
im_detect: 3773/4024 0.149s 0.001s
im_detect: 3774/4024 0.149s 0.001s
im_detect: 3775/4024 0.149s 0.001s
im_detect: 3776/4024 0.149s 0.001s
im_detect: 3777/4024 0.149s 0.001s
im_detect: 3778/4024 0.149s 0.001s
im_detect: 3779/4024 0.149s 0.001s
im_detect: 3780/4024 0.149s 0.001s
im_detect: 3781/4024 0.149s 0.001s
im_detect: 3782/4024 0.149s 0.001s
im_detect: 3783/4024 0.149s 0.001s
im_detect: 3784/4024 0.149s 0.001s
im_detect: 3785/4024 0.149s 0.001s
im_detect: 3786/4024 0.149s 0.001s
im_detect: 3787/4024 0.149s 0.001s
im_detect: 3788/4024 0.149s 0.001s
im_detect: 3789/4024 0.149s 0.001s
im_detect: 3790/4024 0.149s 0.001s
im_detect: 3791/4024 0.149s 0.001s
im_detect: 3792/4024 0.149s 0.001s
im_detect: 3793/4024 0.149s 0.001s
im_detect: 3794/4024 0.149s 0.001s
im_detect: 3795/4024 0.149s 0.001s
im_detect: 3796/4024 0.149s 0.001s
im_detect: 3797/4024 0.149s 0.001s
im_detect: 3798/4024 0.149s 0.001s
im_detect: 3799/4024 0.149s 0.001s
im_detect: 3800/4024 0.149s 0.001s
im_detect: 3801/4024 0.149s 0.001s
im_detect: 3802/4024 0.149s 0.001s
im_detect: 3803/4024 0.149s 0.001s
im_detect: 3804/4024 0.149s 0.001s
im_detect: 3805/4024 0.149s 0.001s
im_detect: 3806/4024 0.149s 0.001s
im_detect: 3807/4024 0.149s 0.001s
im_detect: 3808/4024 0.149s 0.001s
im_detect: 3809/4024 0.149s 0.001s
im_detect: 3810/4024 0.149s 0.001s
im_detect: 3811/4024 0.149s 0.001s
im_detect: 3812/4024 0.149s 0.001s
im_detect: 3813/4024 0.149s 0.001s
im_detect: 3814/4024 0.149s 0.001s
im_detect: 3815/4024 0.149s 0.001s
im_detect: 3816/4024 0.149s 0.001s
im_detect: 3817/4024 0.149s 0.001s
im_detect: 3818/4024 0.149s 0.001s
im_detect: 3819/4024 0.149s 0.001s
im_detect: 3820/4024 0.149s 0.001s
im_detect: 3821/4024 0.149s 0.001s
im_detect: 3822/4024 0.149s 0.001s
im_detect: 3823/4024 0.149s 0.001s
im_detect: 3824/4024 0.149s 0.001s
im_detect: 3825/4024 0.149s 0.001s
im_detect: 3826/4024 0.149s 0.001s
im_detect: 3827/4024 0.149s 0.001s
im_detect: 3828/4024 0.149s 0.001s
im_detect: 3829/4024 0.149s 0.001s
im_detect: 3830/4024 0.149s 0.001s
im_detect: 3831/4024 0.149s 0.001s
im_detect: 3832/4024 0.149s 0.001s
im_detect: 3833/4024 0.149s 0.001s
im_detect: 3834/4024 0.149s 0.001s
im_detect: 3835/4024 0.149s 0.001s
im_detect: 3836/4024 0.149s 0.001s
im_detect: 3837/4024 0.149s 0.001s
im_detect: 3838/4024 0.149s 0.001s
im_detect: 3839/4024 0.149s 0.001s
im_detect: 3840/4024 0.149s 0.001s
im_detect: 3841/4024 0.149s 0.001s
im_detect: 3842/4024 0.149s 0.001s
im_detect: 3843/4024 0.149s 0.001s
im_detect: 3844/4024 0.149s 0.001s
im_detect: 3845/4024 0.149s 0.001s
im_detect: 3846/4024 0.149s 0.001s
im_detect: 3847/4024 0.149s 0.001s
im_detect: 3848/4024 0.149s 0.001s
im_detect: 3849/4024 0.149s 0.001s
im_detect: 3850/4024 0.149s 0.001s
im_detect: 3851/4024 0.149s 0.001s
im_detect: 3852/4024 0.149s 0.001s
im_detect: 3853/4024 0.149s 0.001s
im_detect: 3854/4024 0.149s 0.001s
im_detect: 3855/4024 0.149s 0.001s
im_detect: 3856/4024 0.149s 0.001s
im_detect: 3857/4024 0.149s 0.001s
im_detect: 3858/4024 0.149s 0.001s
im_detect: 3859/4024 0.149s 0.001s
im_detect: 3860/4024 0.149s 0.001s
im_detect: 3861/4024 0.149s 0.001s
im_detect: 3862/4024 0.149s 0.001s
im_detect: 3863/4024 0.149s 0.001s
im_detect: 3864/4024 0.149s 0.001s
im_detect: 3865/4024 0.149s 0.001s
im_detect: 3866/4024 0.149s 0.001s
im_detect: 3867/4024 0.149s 0.001s
im_detect: 3868/4024 0.149s 0.001s
im_detect: 3869/4024 0.149s 0.001s
im_detect: 3870/4024 0.149s 0.001s
im_detect: 3871/4024 0.149s 0.001s
im_detect: 3872/4024 0.149s 0.001s
im_detect: 3873/4024 0.149s 0.001s
im_detect: 3874/4024 0.149s 0.001s
im_detect: 3875/4024 0.149s 0.001s
im_detect: 3876/4024 0.149s 0.001s
im_detect: 3877/4024 0.149s 0.001s
im_detect: 3878/4024 0.149s 0.001s
im_detect: 3879/4024 0.149s 0.001s
im_detect: 3880/4024 0.149s 0.001s
im_detect: 3881/4024 0.149s 0.001s
im_detect: 3882/4024 0.149s 0.001s
im_detect: 3883/4024 0.149s 0.001s
im_detect: 3884/4024 0.149s 0.001s
im_detect: 3885/4024 0.149s 0.001s
im_detect: 3886/4024 0.149s 0.001s
im_detect: 3887/4024 0.149s 0.001s
im_detect: 3888/4024 0.149s 0.001s
im_detect: 3889/4024 0.149s 0.001s
im_detect: 3890/4024 0.149s 0.001s
im_detect: 3891/4024 0.149s 0.001s
im_detect: 3892/4024 0.149s 0.001s
im_detect: 3893/4024 0.149s 0.001s
im_detect: 3894/4024 0.149s 0.001s
im_detect: 3895/4024 0.149s 0.001s
im_detect: 3896/4024 0.149s 0.001s
im_detect: 3897/4024 0.149s 0.001s
im_detect: 3898/4024 0.149s 0.001s
im_detect: 3899/4024 0.149s 0.001s
im_detect: 3900/4024 0.149s 0.001s
im_detect: 3901/4024 0.149s 0.001s
im_detect: 3902/4024 0.149s 0.001s
im_detect: 3903/4024 0.149s 0.001s
im_detect: 3904/4024 0.149s 0.001s
im_detect: 3905/4024 0.149s 0.001s
im_detect: 3906/4024 0.149s 0.001s
im_detect: 3907/4024 0.149s 0.001s
im_detect: 3908/4024 0.149s 0.001s
im_detect: 3909/4024 0.149s 0.001s
im_detect: 3910/4024 0.149s 0.001s
im_detect: 3911/4024 0.149s 0.001s
im_detect: 3912/4024 0.149s 0.001s
im_detect: 3913/4024 0.149s 0.001s
im_detect: 3914/4024 0.149s 0.001s
im_detect: 3915/4024 0.149s 0.001s
im_detect: 3916/4024 0.149s 0.001s
im_detect: 3917/4024 0.149s 0.001s
im_detect: 3918/4024 0.149s 0.001s
im_detect: 3919/4024 0.149s 0.001s
im_detect: 3920/4024 0.149s 0.001s
im_detect: 3921/4024 0.149s 0.001s
im_detect: 3922/4024 0.149s 0.001s
im_detect: 3923/4024 0.149s 0.001s
im_detect: 3924/4024 0.149s 0.001s
im_detect: 3925/4024 0.149s 0.001s
im_detect: 3926/4024 0.149s 0.001s
im_detect: 3927/4024 0.149s 0.001s
im_detect: 3928/4024 0.149s 0.001s
im_detect: 3929/4024 0.149s 0.001s
im_detect: 3930/4024 0.149s 0.001s
im_detect: 3931/4024 0.149s 0.001s
im_detect: 3932/4024 0.149s 0.001s
im_detect: 3933/4024 0.149s 0.001s
im_detect: 3934/4024 0.149s 0.001s
im_detect: 3935/4024 0.149s 0.001s
im_detect: 3936/4024 0.149s 0.001s
im_detect: 3937/4024 0.149s 0.001s
im_detect: 3938/4024 0.149s 0.001s
im_detect: 3939/4024 0.149s 0.001s
im_detect: 3940/4024 0.149s 0.001s
im_detect: 3941/4024 0.149s 0.001s
im_detect: 3942/4024 0.149s 0.001s
im_detect: 3943/4024 0.149s 0.001s
im_detect: 3944/4024 0.149s 0.001s
im_detect: 3945/4024 0.149s 0.001s
im_detect: 3946/4024 0.149s 0.001s
im_detect: 3947/4024 0.149s 0.001s
im_detect: 3948/4024 0.149s 0.001s
im_detect: 3949/4024 0.149s 0.001s
im_detect: 3950/4024 0.149s 0.001s
im_detect: 3951/4024 0.149s 0.001s
im_detect: 3952/4024 0.149s 0.001s
im_detect: 3953/4024 0.149s 0.001s
im_detect: 3954/4024 0.149s 0.001s
im_detect: 3955/4024 0.149s 0.001s
im_detect: 3956/4024 0.149s 0.001s
im_detect: 3957/4024 0.149s 0.001s
im_detect: 3958/4024 0.149s 0.001s
im_detect: 3959/4024 0.149s 0.001s
im_detect: 3960/4024 0.149s 0.001s
im_detect: 3961/4024 0.149s 0.001s
im_detect: 3962/4024 0.149s 0.001s
im_detect: 3963/4024 0.149s 0.001s
im_detect: 3964/4024 0.149s 0.001s
im_detect: 3965/4024 0.149s 0.001s
im_detect: 3966/4024 0.149s 0.001s
im_detect: 3967/4024 0.149s 0.001s
im_detect: 3968/4024 0.149s 0.001s
im_detect: 3969/4024 0.149s 0.001s
im_detect: 3970/4024 0.149s 0.001s
im_detect: 3971/4024 0.149s 0.001s
im_detect: 3972/4024 0.149s 0.001s
im_detect: 3973/4024 0.149s 0.001s
im_detect: 3974/4024 0.149s 0.001s
im_detect: 3975/4024 0.149s 0.001s
im_detect: 3976/4024 0.149s 0.001s
im_detect: 3977/4024 0.149s 0.001s
im_detect: 3978/4024 0.149s 0.001s
im_detect: 3979/4024 0.149s 0.001s
im_detect: 3980/4024 0.149s 0.001s
im_detect: 3981/4024 0.149s 0.001s
im_detect: 3982/4024 0.149s 0.001s
im_detect: 3983/4024 0.149s 0.001s
im_detect: 3984/4024 0.149s 0.001s
im_detect: 3985/4024 0.149s 0.001s
im_detect: 3986/4024 0.149s 0.001s
im_detect: 3987/4024 0.149s 0.001s
im_detect: 3988/4024 0.149s 0.001s
im_detect: 3989/4024 0.149s 0.001s
im_detect: 3990/4024 0.149s 0.001s
im_detect: 3991/4024 0.149s 0.001s
im_detect: 3992/4024 0.149s 0.001s
im_detect: 3993/4024 0.149s 0.001s
im_detect: 3994/4024 0.149s 0.001s
im_detect: 3995/4024 0.149s 0.001s
im_detect: 3996/4024 0.149s 0.001s
im_detect: 3997/4024 0.149s 0.001s
im_detect: 3998/4024 0.149s 0.001s
im_detect: 3999/4024 0.149s 0.001s
im_detect: 4000/4024 0.149s 0.001s
im_detect: 4001/4024 0.149s 0.001s
im_detect: 4002/4024 0.149s 0.001s
im_detect: 4003/4024 0.149s 0.001s
im_detect: 4004/4024 0.149s 0.001s
im_detect: 4005/4024 0.149s 0.001s
im_detect: 4006/4024 0.149s 0.001s
im_detect: 4007/4024 0.149s 0.001s
im_detect: 4008/4024 0.149s 0.001s
im_detect: 4009/4024 0.149s 0.001s
im_detect: 4010/4024 0.149s 0.001s
im_detect: 4011/4024 0.149s 0.001s
im_detect: 4012/4024 0.149s 0.001s
im_detect: 4013/4024 0.149s 0.001s
im_detect: 4014/4024 0.149s 0.001s
im_detect: 4015/4024 0.149s 0.001s
im_detect: 4016/4024 0.149s 0.001s
im_detect: 4017/4024 0.149s 0.001s
im_detect: 4018/4024 0.149s 0.001s
im_detect: 4019/4024 0.149s 0.001s
im_detect: 4020/4024 0.149s 0.001s
im_detect: 4021/4024 0.149s 0.001s
im_detect: 4022/4024 0.149s 0.001s
im_detect: 4023/4024 0.149s 0.001s
im_detect: 4024/4024 0.149s 0.001s
Evaluating detections
Writing person VOC results file
VOC07 metric? Yes
fp [    0.     0.     0. ... 92028. 92029. 92030.]
tp[1.000e+00 2.000e+00 3.000e+00 ... 3.085e+03 3.085e+03 3.085e+03]
npos: 4401
AP for person = 0.4003
Mean AP = 0.4003
~~~~~~~~
Results:
0.400
0.400
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	10m13.247s
user	8m37.800s
sys	1m44.584s
